Under review as a conference paper at ICLR 2022
Neuro-Symbolic Forward Reasoning
Anonymous authors
Paper under double-blind review
Ab stract
Reasoning is an essential part of human intelligence and thus has been a long-
standing goal in artificial intelligence research. With the recent success of deep
learning, incorporating reasoning with deep learning systems, i.e., neuro-symbolic
AI has become a major field of interest. We propose the Neuro-Symbolic Forward
Reasoner (NSFR), a new approach for reasoning tasks taking advantage of differ-
entiable forward-chaining using first-order logic. The key idea is to combine dif-
ferentiable forward-chaining reasoning with object-centric (deep) learning. Dif-
ferentiable forward-chaining reasoning computes logical entailments smoothly,
i.e., it deduces new facts from given facts and rules in a differentiable manner.
The object-centric learning approach factorizes raw inputs into representations
in terms of objects. Thus, it allows us to provide a consistent framework to
perform the forward-chaining inference from raw inputs. NSFR factorizes the
raw inputs into the object-centric representations, converts them into probabilistic
ground atoms, and finally performs differentiable forward-chaining inference us-
ing weighted rules for inference. Our comprehensive experimental evaluations on
object-centric reasoning data sets, 2D Kandinsky patterns and 3D CLEVR-Hans,
and a variety of tasks show the effectiveness and advantage of our approach.
1 INTRODUCTION
Right from the time of Aristotle, reasoning has been in the center of the study of human behavior
(Miller, 1984). Reasoning can be defined as the process of deriving conclusions and predictions from
available data. The long-lasting goal of artificial intelligence has been to develop rational agents akin
to humans, and reasoning is considered to be a major part of achieving rationality (Johnson-Laird,
2010). Logic, both propositional and first-order, is an established framework to perform reasoning
on machines (Boole, 1847). Such logical reasoning has been an essential part of the growth of
machine learning over the years (Poole et al., 1987; Bottou, 2014; Dai et al., 2019) and has also
given rise to statistical relational learning (Koller et al., 2007; Raedt et al., 2016) and probabilistic
logic programming (Lukasiewicz, 1998; De Raedt & Kersting, 2003; De Raedt & Kimmig, 2015).
Object-centric reasoning has been widely addressed (Johnson et al., 2017; Mao et al., 2019; Chen
et al., 2021; Han et al., 2019), where the task is to perform reasoning to answer the questions that are
about the objects and its attributes. However, the task is challenging because the models should per-
form low-level visual perception and reasoning on high-level concepts. To mitigate this challenge,
with the recent success of deep learning, incorporating logical reasoning with deep learning systems,
i.e., neuro-symbolic AI has become a major field of interest (De Raedt et al., 2019; Garcez et al.,
2019). It has the advantage of combining the expressivity of neural networks with the reasoning of
symbolic methods.
Various benchmarks and methods have been developed for object-centric reasoning (Locatello et al.,
2020b; Nanbo et al., 2020). Recently, data sets such as Kandinsky patterns (Mueller & Holzinger,
2019; Holzinger et al., 2019; 2021) and CLEVR (Johnson et al., 2017) have been proposed to assess
the performance of the machine learning systems in object-centric reasoning tasks. For example,
Figure 1 shows an example of the Kandinsky pattern: ”the figure has two pairs of objects with the
same shape” where Fig. (a) is following the pattern and Fig. (b) is not. Kandinsky patterns are
inspired by human IQ-tests (Bruner et al., 1956; Dowe & Hernandez-Orallo, 2012; LiU et al., 2019),
which require humans to think on abstract patterns. The key feature of Kandinsky Patterns is its
complexity, e.g., the arrangement of objects, closure or symmetry, and a group of objects.
1
Under review as a conference paper at ICLR 2022
Many approaches have been investigated for object-centric reason-
ing under the umbrella of neuro-Symbolic learning (Rocktaschel &
Riedel, 2017; Yang et al., 2017; Sourek et al., 2018; Manhaeve
et al., 2018; Si et al., 2019; Mao et al., 2019; Cohen et al., 2020;
Riegel et al., 2020). However, using these approaches it is diffi-
cult, if not impossible, to solve object-centric reasoning tasks such
as Kandinsky patterns due to several underlying challenges: (i) the
perception of the objects from the raw inputs and (ii) the reasoning
on the attributes and the relations to capture the complex patterns
(of varying size).
In this work, we propose the Neuro-Symbolic Forward Reasoner
(NSFR), a novel neuro-symbolic learning framework for complex
(a)	(b)
Figure 1: Examples of
Kandinsky patterns. (a) fol-
lows the pattern: ”the figure
has 2 pairs of objects with the
same shape”, but (b) isn’t
object-centric reasoning tasks. The key idea is to combine neural-based object-centric learning
models with the differentiable implementation of first-order logic. It has three main components: (i)
object-centric perception module, (ii) facts converter, and (iii) differentiable reasoning module. The
object-centric perception module extracts information for each object and has been widely addressed
in the computer vision community (Locatello et al., 2020a; Redmon et al., 2016). Facts converter
converts the output of the visual perception module into the form of probabilistic logical atoms,
which can be fed into the reasoning module. Finally, differentiable reasoning module performs
the differentiable forward-chaining inference from a given input. It computes the set of ground
atoms that can be deduced from the given set of ground atoms and weighted logical rules (Evans &
Grefenstette, 2018; Shindo et al., 2021). The final prediction can be made based on the result of the
forward-chaining inference.
Overall, we make the following contributions: (1) We propose Neuro-Symbolic Forward Reasoner
(NSFR), a new neuro-symbolic learning framework that performs differentiable forward-chaining
inference from visual data using object-centric models. NSFR can solve problems involving com-
plex patterns on objects and attributes, such as the arrangement of objects, closure, or symmetry.
(2) To establish NSFR, we show an extended implementation of the differentiable forward-chaining
inference to overcome the scalability problem. Moreover, NSFR can take advantage of some es-
sential features of the underlying neural network, such as batch computation, for logical reasoning.
(3) To establish NSFR, we provide a conversion algorithm from object-centric representations to
probabilistic facts. We propose neural predicates, which are associated with a function to produce
a probability of a fact and yield a seamless combination of sub-symbolic and symbolic represen-
tations. (4) We empirically show that NSFR solves object-centric reasoning tasks more effectively
than the SOTA logical and deep learning models. Furthermore, NSFR classifies complex patterns
with high accuracy for 2D and 3D data sets, outperforming pure neural-based approaches for image
recognition.
2	Background and Related Work
Notation. We use bold lowercase letters v, w, . . . for vectors and the functions that return vectors.
We use bold capital letters X, . . . for tensors. We use calibrate letters C, A, . . . for (ordered) sets and
typewriter font p(X, Y) for terms and predicates in logical expressions (Appendix A.1 for details).
Preliminaries. We consider function-free first-order logic. Language L is a tuple (P, T, V), where
P is a set of predicates, T is a set of constants, and V is a set of variables. A term is a constant
or a variable. We assume that each term has a datatype. A datatype dt specifies a set of constants
dom (dt) = Tdt ⊆ T. We denote n-ary predicate p by p/(n, [dt1, . . . , dtn]), where dti is the
datatype of i-th argument. An atom is a formula p(t1, . . . , tn), where p is an n-ary predicate symbol
and t1, . . . , tn are terms. A ground atom or simply a fact is an atom with no variables. A literal
is an atom or its negation. A positive literal is just an atom. A negative literal is the negation of
an atom. A clause is a finite disjunction (∨) of literals. A definite clause is a clause with exactly
one positive literal. If A, B1 , . . . , Bn are atoms, then A ∨ B1 ∨ . . . ∨ Bn is a definite clause.
We write definite clauses in the form of A : -B1 , . . . , Bn. Atom A is called the head, and set of
negative atoms {B1, . . . , Bn} is called the body. We denote special constant true as > and false
as ⊥. Substitution θ = {X1 = t1, ..., Xn = tn} is an assignment of term ti to variable Xi. An
application of substitution θ to atom A is written as Aθ.
2
Under review as a conference paper at ICLR 2022
Related Work. Reasoning with neuro-symbolic systems has been studied extensively for various
applications such as ocean study (Corchado, 1995), business internal control (Corchado et al., 2004)
and forecasting (Fdez-Riverola et al., 2002). More recently, several neuro-symbolic techniques
for commonsense reasoning (Arabshahi et al., 2021), visual question answering (Mao et al., 2019;
Amizadeh et al., 2020) and multimedia tasks (Khan & Curry, 2020) have been developed. They
either do not employ a differentiable forward reasoner or miss objet-centric learning in the end-to-
end reasoning architecture.
Object-centric learning is an approach to decompose an input image into representations in terms
of objects (Dittadi et al., 2021). This problem has been widely addressed in the computer vision
community. The typical approach is the object detection (or supervised) approach such as Faster-
RCNN (Ren et al., 2015) and YOLO (Redmon et al., 2016). Another approach is the unsupervised
approach (Burgess et al., 2019; Engelcke et al., 2020; Locatello et al., 2020a), where the models
acquire the ability of object-perception without or fewer annotations. These two different paradigms
have different advantages. NSFR encapsulates different object-perception models, thus allows us to
choose a proper model depending on the situation and the problem to be solved.
Also, the integration of symbolic logic and neural networks has been addressed, see e.g. Deep-
Problog (Manhaeve et al., 2018) and NeurASP (Yang et al., 2020). The key difference from the past
approaches is that NSFR supports essential features of neural networks such as batch computation
and that it is fully differentiable. Thus it scales well to large data sets, leading to several avenues for
future work learning neural networks with logical constraints (Hu et al., 2016; Xu et al., 2018).
3	The Neuro-Symbolic Forward Reasoner (NSFR)
Let us now introduce the Neuro-Symbolic Forward Reasoner (NSFR) in four steps. First, we give
an overview of the problem setting and the framework. Second, we specify a language of first-order
logic focusing on the object-centric reasoning tasks. Third, we explain the facts converter. Finally,
we show the differentiable forward-chaining inference algorithm, an extended implementation from
the previous approaches.
3.1	Overview
Problem Scenario. We address the image classification problem, where each image contains ob-
jects, and the classification rules are defined on the relations of objects and their attributes. We
define the object-centric reasoning problem as follows:
Definition 1 An Object-Centric Reasoning Problem Q is a tuple (I+, I-, P), where I+ is a set
of images that follow pattern P, I- is a set of images that do not follow pattern P. Each image
X ∈ I+ ∪ I- contains several objcets, and each object has its attributes. Pattern P is a pattern
that is described as logical rules or natural language sentence, which is defined on the attributes
and relations of objects. The solution of problem Q is a set of binary labels Y = {yi}i=0 ...N for
each image Xi ∈ I+ ∪ I-, where N = |I+ ∪ I- |.
Architecture Overview. NSFR performs object-centric perception from raw input and reasoning
on the extracted high-level concepts. Figure 2 presents an overview of NSFR. First, NSFR perceives
objects from raw input whose output is a set of vectors, called object-centric representations, where
each vector represents each object in the input. Then, the fact converter takes these object-centric
representations as input and returns a set of probabilistic facts. The probabilistic facts are then fed
into the reasoning module, which performs differentiable forward-chaining inference using weighted
rules. Finally, the final prediction is made on the result of the inference. We briefly summarize the
steps of the process as follows:
Step 1: Let X ∈ RB×N be a batch of input images. Perception function fpercept : RB×N →
RB×E×D factorizes input X into a set of object-centric representations Z ∈ RB×E×D , where
E ∈ N is the number of objects, D ∈ N is the dimension of object-centric vector.
Step 2: Let G be a set of ground atoms. Convert function fconvert : RB ×E ×D × G → RB×G
generates a probabilistic vector representation of facts, where G = |G|.
Step 3: Infer function finfer : RB ×G → RB×G computes forward-chaining inference using
weighted clauses C .
3
Under review as a conference paper at ICLR 2022
clauses
ground
atoms
kp(X) : —in(01,X), in(D2, ɪ), Bamβ-βlιape-pair(01,02),
in(03, ɪ), in(04, X), same-shape-pair(03,04).
Same-ShaPe-Pair (X, Y): — shape(X, Z), shape (Y, Z).
legend
differentiable
function
non-differentiable
function
G ∣color(obj 1 ,red),color(objl,blue),color(obj1,yellow),.∙. j^
Z ∈ Rs×β×β	V0 ∈ IRBXG
Figure 2: An overview of NSFR. The object-centric model produces outputs in terms of objects. The
facts converter obtains probabilistic facts from the object-centric representation. The differentiable
forward-chaining inference computes the logical entailment softly from the probabilistic facts and
weighted rules. The final prediction is computed based on the entailed facts.
Step 4: Predict function fpredict : RB×G → RB computes the probability of target facts. The
probability of the labels y of the batch of input X is computed as:
p(y|X) = fpred(finfer (fconvert (fpercept (X; Φ), G; Θ); C, W)),	(1)
where Φ, Θ, and W are learnable parameters.
We now present each component of our architecture in detail.
index tensor
I∈N*xSxeJ
ILJ Vτ ∈ Rs×σ
3.2	Object-centric reasoning language
We have to define a first-order logic language to build a consistent neuro-symbolic framework for
object-centric reasoning. Intuitively, we assume that all constants are divided into inputs, objects,
and attributes, and the attribute constants have different data types such as colors and shapes.
Definition 2 An Object-Centric Reasoning Language is a function-free language L = (P, T, V),
where P is a set of predicates, T is a set of constants, andV is a set of variables. The set of constants
T is divided to a set of inputs X, a set of objects O, anda set of attributes A, i.e., T = X ∪O∪A. The
attribute constants A is devided into a set of constants for each datatype, i.e., A = Adt1 ∪. . .∪Adtn,
where Adti is a set of constants of the i-th datatype dti.
Example 1: The language for Figure 2 can be represented as L1 = (P, T, V),
where P = {kp/(1, [image]), in/(2, [object, image]), color/(2, [object, color]),
shape∕(2, [object, shape]), same_shape_pair(2, [object, object])}, andT = X∪O∪Acoior∪
Ashape where X = {img}, O = {obj1, obj2, obj3, obj4}, Acolor = {red, yellow, blue} where
Ashape = {square, ciecle, triangle}, and V = {X, Y, Z, O1, O2, O3, O4}.
3.3	Object-centric Perception
We make the minimum assumption that the perception function takes an image and returns a set of
object-centric vectors, where each of the vectors represents each object. For simplicity, we assume
that each dimension of the vector represents the probability of the attributes for each object. For
example, suppose each object has color, shape, position as attributes. The color varies red, blue,
yellow, the shape varies square, circle, triangle, and position is represented as a (x, y)-coordinates.
In this case, each object can be represented as an 8-dim vector, as illustrated in Figure 2.
Let N be the input size, E be the maximum number of objects that can appear in one image, and
D be the number of attributes for each object. For a batch of input images X ∈ RB×N, the object-
centric perception function fpercept : RB×N → RB×E ×D parameterized Φ produces a batch of
object-centric representations Z ∈ RB×E×D: Z = fpercept (X; Φ). We note that each value Zi,j,k
represents the probability of the k-th attribute on the j-th object in the i-th image in the batch. We
denote the tensor for j-th object as Z(j) = Z:,j,: ∈ RB×D.
4
Under review as a conference paper at ICLR 2022
ground atoms Q
object-centric
representation
attribute
one-hot
encoding IAredl
& I
color(obj3, red), shape(objl； circle),...
∣81or(obj3,red) ∣ facts converter
(Z(3), Ared)=	0 曰)=∙
probabilistic facts
(valuation tensor)
v(。)∈ rs×g
0.98 : color(jθbJ3^∣red)
A 0.98 : shape(∣objincircle)
• ∙	□ O A
E Aclrcl,FB
shape(obj 1, circle)
--------------- □ o ∆	□ o ∆
OShaPe (Za), ACirCie)=S(HjH θ HiH)=[r
□ O Δ ɪ y	∙ ∙ □ O Δ x y
z(1)l Illlll zwJ-™+⅛
0.01: color(jδbJ3^red)
0.98 : shape(∣obj IJcircle)
Figure 3: An overview of the facts-converting process. NSFR decomposes the raw-input images
into the object-centric representations (left). The valuation functions are called to compute the
probability of ground atoms (middle). The result is converted into the form of vector representations
of the probabilistic ground atoms (right).
3.4	Facts Converter
After the object-centric perception, NSFR obtains the logical representation, i.e., a set of probabilis-
tic ground atoms. We propose a new type of predicate that can refer to differentiable functions to
compute the probability and a seamless converting algorithm from the perception result to proba-
bilistic ground atoms.
3.4.1	Tensor Representations of Constants
Specifically, in NSFR, constants are mapped to tensors as described below.
Objects. We map the object constants to the object-centric representation from the visual-perception
module. The output of the visual-perception module is already factorized in terms of objects. There-
fore the tensor for each object is extracted easily by slicing the output.
Attributes. We map the attribute constants to their corresponding one-hot encoding and assume
that it is expanded to the batch size. Let EL be the set of one-hot encoding of attribute constants
in language L. For e.g., for language L1 in Example 1, color red has tensor representation as
Ared = [[1, 0, 0], [1, 0, 0]] ∈ R2×3, where the batch size is 2. We assume that we have the encoding
for each attribute, i.e., EL1
Ared , Ayellow , Ablue , Asquare , Acircle , Atriangle .
In summary, we define the tensor representations for each object and attribute constant t as:
fto_tensor(t;Z,EL)
if t = obji ∈ O
if t = attri ∈ Adt
(2)
where A(dit) ∈ EL is the one-hot encoding of the i-th attribute of datatype dt. For example,
fto.tensor (θbj1 Z, ?Li) = Z ⑴ and fto.tensor (red； Z, ?Li) = Ared = [[1, 0, 0],[1, 0, 0]].
3.4.2	Neural Predicate
To solve the object-centric reasoning tasks, the model should capture the relation that is character-
ized by continuous features, for e.g., the close by relation between two objects. To encode such
concepts into the form of logical facts, we introduce neural predicate that composes a ground atom
associated with a differentiable function. Neural predicates computes the probability of the ground
atoms using the object-centric representations from the visual perception module.
Definition 3 A neural predicate p/(n, [dt1, . . . , dtn]) is a n-ary predicate associated with a func-
tion VP : Rdι×∙∙∙×dn → RB, where dti is the datatype of the i-th argument, and di ∈ N is the
dimension of the tensor representation of the constant whose datatype is dti
Example 2: Figure 3 illustrates how the neural predicates and the valuation functions are
computed. (1) For neural predicate color/(2, [object, color]), the probability of ground
atom color(obj3, red) is computed by valuation function vcolor : R2×5 × R2×3 → R2 as
5
Under review as a conference paper at ICLR 2022
vcolor(Z(3), Ared) = sum1(Z:(,30):3	Ared), where Ared ∈ {0, 1}2×3 is a one-hot encoding of the
color of red that is expanded to the batch size, sum1 is the sum operation for the dimension 1, and
is the element-wise multiplication. (2) Likewise, for neural predicate shape/(2, [object, shape]),
the probability of ground atom shape(obj1, circle) is computed by valuation function vshape :
R2×5 × R2×3 → R2 as vshape(Z(1) , Acircle) = sum1 (Z:(,13):6 Acircle). (3) For neural pred-
icate closeby(2/[object, object]), the probability of ground atom closeby(obj1, obj2) is
computed by valuation functioin vcloseby : R2×5 × R2×5 → R as: vcloseby(Z(1) , Z(2)) =
σ norm0 Z:(,14):6 - Z:(,24):6 ; w , where norm0 is the norm function along dimension 0, σ is the
sigmoid function for each element of the input, and w is the trainable parameter. By adapting the
parameters in neural predicates, NSFR can learn the concepts determined by numerical attributes
and their relations. We note that valuation functions of neural predicates can be replaced by other
differentiable functions, e.g., multilayer perceptrons.
3.4.3	Conversion Algorithm to Valuation Tensors
The facts converter produces a set of probabilistic ground atoms that are fed into the reasoning
module. In NSFR, the probabilistic facts are represented in the form of tensors called valuation
tensors.
Valuation. Valuation tensor V(t) ∈ RB ×G maps each ground atom into a continuous value at
each time step t. Each value Vi(,tj) represents the probability of ground atom Fj ∈ G for the i-th
example in the batch. The output of the perception module Z ∈ RB ×E ×D is compiled into initial
valuation tensor V(0). The differentiable inference function is performed based on valuation tensors.
To compute the T -step forward-chaining inference, we compute the sequence of valuation tensors
V(0),...,V(T).
Conversion into Valuation Tensors. Neural predicates yield a seamless conversion algorithm from
the object-centric vectors into the probabilistic facts. Algorithm 1 (see Appendix B) describes the
converting procedure. For each ground atom, if it consists of a neural predicate, then the valua-
tion function is called to compute the probability of the atom. We note that the valuation function
computes probability in batch. NSFR allows background knowledge as a set of ground atoms. The
probability of background knowledge is set to 1.0.
3.5	Differentiable Forward-chaining Inference
NSFR performs reasoning based on the differentiable forward-chaining inference approach (Evans
& Grefenstette, 2018; Shindo et al., 2021). The key idea is to implement the forward reasoning of
first-order logic using tensors and operations between them using the following steps: (Step 1) Ten-
sor I, which is called index tensor, is built from given set of clauses C and fixed set of ground atoms
G . It holds the relationships between clauses C and ground atoms G . Its dimension is proportional
to |C | and |G |. (Step 2) A computational graph is constructed from I and clause weights W. The
weights define probability distributions over clauses C, approximating a logic program softly. The
probabilistic forward-chaining inference is performed by the forwarding algorithm on the computa-
tional graph with input V(0), which is the output of the fact converter. We now step-wise describe
the process.
3.5.1	Tensor Encoding
We build a tensor that holds the relationships between clauses C and ground atoms G . We assume
that C and G are an ordered set, i.e., where every element has its own index. Let L be the maximum
body length in C , S be the maximum number of substitutions for existentially quantified variables
in clauses C , C = |C|, and G = |G |. Index tensor I ∈ NC ×G×S ×L contains the indices of the
ground atoms to compute forward inferences. Intuitively, Ii,j,k,l is the index of the l-th ground atom
(subgoal) in the body of the i-th clause to derive the j -th ground atom with the k-th substitution for
existentially quantified variables.
Example 3: Let R0 = kp(X) : -in(O1, X), shape(O1, square) ∈ C and F2 = kp(img) ∈ G,
and we assume that object constants are {obj1, obj2}. To deduce fact F2 using clause R0,
6
Under review as a conference paper at ICLR 2022
F2 and the head atom can be unified by substitution θ = {X = img}. By applying θ to body
atoms, we get clause kp(img) : -in(O1, img), shape(O1, square)., which has an existentially
quantified variable O1. By considering the possible substituions for O1, we have grounded clauses as
kp(img) : -in(obj1, img), shape(obj1, square), kp(img) : -in(obj2, img), shape(obj2, square).
Then the following table shows tensor I0,:,0,: and I0,:,1,::
j	0	1	2	3	4	5	...
G	⊥	>	kp(img)	in(obj1, img)	in(obj2, img)	shape(obj1, square)	. . .
I0,j,0,:	Wr	[1, 1]	[3, 5]	[070	[0, 0]	[0, 0]	. . .
I0,j,1,:	[0,0]	[1, 1]	[4, 6]	[0, 0]	[0, 0]	[0, 0]	. . .
Ground atoms G and the indices are represented on the upper rows in the table. For ex-
ample, I0,2,0,: = [3, 5] because R0 entails kp(img) with substitution θ = {O1 = obj1}.
Then the subgoal atoms are {in(obj1, img1), shape(obj1, square)}, which have indices
[3, 5], respectively. With another substitution θ = {O1 = obj2}, the subgoal atoms are
{in(obj2, img1), shape(obj1, square)}, which have indices [4, 6], respectively. The atoms which
have a different predicate, e.g., shape(obj1, square), will never be entailed by clause R0. There-
fore, the corresponding values are filled with 0, which represents the index of the false atom.
3.5.2	Differentiable Inference
Using the encoded index tensor, NSFR performs differentiable forward-chaining reasoning. We
briefly summarize the steps as follows. (Step 1): Each clause is compiled into a function that per-
forms forward reasoning. (Step 2): The weighted sum of the results from each clause is computed.
(Step 3): T -time step inference is computed by amalgamating the inference results recursively. We
extend previous approaches (Evans & Grefenstette, 2018; Shindo et al., 2021) for batch computation.
Clause Function. Each clause Ri ∈ C is compiled in to a clause function. The clause function
takes valuation tensor V(t), and returns valuation tensor Ci(t)RB×G, which is the result of 1-step
forward reasoning using Ri and V(t) . The clause function is computed as follows. First, tensor
Ii ∈ rg×s×l is extended for batches, i.e., Ii ∈ nb×g×s×l, and V ∈ Rb×g is extended to the
same shape, i.e., V ∈ rb×g×s×l. Using these tensors, the clause function is computed as:
Cit)= SoftorY (Prod 2 (gather I(V,I)),	⑶
where gather1(X, Y)i,j,k,l = Xi,Yi,j,k,l,k,l, and prod 2 returns the product along dimension 2.
softor γd is a function for taking logical or softly along dimension d:
softorY(X) = 1 Y log (sumd exp (X∕γ)),	(4)
S
where γ > 0 is a smooth parameter, sumd is the sum function for tensors along dimension d, and
1.0	if max (γ log sumd exp (X∕γ)) ≤ 1.0
max (γ log sumd exp (X∕γ)) otherwise
(5)
Normalization term S ensures that the function returns the normalized probabilistic values. We
refer appendix I for more details about the softor dY function. In Eq. 3, applying the softor 3Y function
corresponds to considering all possible substitutions for existentially quantified variables in the body
atoms of the clause and taking logical or softly over the results of possible substitutions. The results
from each clause is stacked into tensor C(t) ∈ RC×B×G, i.e., C(t) = stack0(C(1t), . . . , C(Ct)),
where stack 0 is a stack function for tensors along dimension 0.
Soft (Logic) Program Composition. In NSFR, a logic program is represented smoothly as a
weighted sum of the clause functions following (Shindo et al., 2021). Intuitively, NSFR has M
distinct weights for each clauses, i.e., W ∈ RM×C. By taking softmax of W along dimension 1,
M clauses are softly chosen from C clauses. The weighted sum of clause functions are computed
as follows. First, We take the softmax of the clause weights W ∈ RM×c: W* = SoftmaxI(W)
where softmax 1 is a softmax function over the dimension 1. The clause weights W* ∈ RM×c
and the output of the clause function C(t) ∈ Rc×b×g are expanded to the same shape W*, C(t) ∈
7
Under review as a conference paper at ICLR 2022
	Training Data			Test Data		
	NSFR	ResNet50	YOLO+MLP	NSFR	ResNet50	YOLO+MLP
Twopairs	-10^^	1.0	10	-1.0^^	0.50	0.98
Threepairs	1.0	1.0	1.0	1.0	0.515	0.912
Closeby	1.0	1.0	1.0	1.0	0.54	0.91
Red-Triangle	0.958	1.0	1.0	0.956	0.57	0.79
Online/Pair	0.997	1.0	1.0	1.0	0.52	0.66
9-Circles	0.964	1.0	1.0	0.952	0.50	0.50
Table 1: The classification accuracy in each data set. NSFR outperforms the considered baselines.
Neural networks over-fit while training and perform poorly with testing data. Best results are bold.
RM×c×b×g. Then We compute tensor H(t) ∈ RM×B×G: H(t) = sumι(W* Θ C), where Θ
is element-wise multiplication, and sum1 is a summation along dimension 1. Each value Hi(t) k
i,j,k
represents the probability of k-th ground atom using i-th clause weights for the j -th example in the
batch. Finally, we compute tensor R(t) ∈ RB×G corresponding to the fact that logic program is a
set of clauses: R(t) = softor 0γ (H).
Multi-step Forward-Chaining Reasoning. We define the 1-step forward-chaining reason-
ing function as: r(V(t) ; I, W) = R(t) and compute the T -step reasoning by: V(t+1) =
softor 1γ (stack 1 (V(t), r(V(t); I, W))), where I ∈ NC×G×S×L is a precomputed index tensor, and
W ∈ RM ×C is clause weights.
4	Experimental Evaluation
We empirically demonstrate the following desired properties of NSFR on 2 data sets (see App. C):
(i) NSFR solves object-centric reasoning tasks with complex abstract patterns, (ii) NSFR can handle
complex 3d scenes, and (iii) NSFR can perform fast reasoning with the batch computation.
4.1	S olving Kandinsky patterns
Data. We adopted Kandinsky pattern data sets (Mueller & Holzinger, 2019; Holzinger et al., 2019;
2021), a relatively new benchmark for object-centric reasoning tasks and use 6 Kandinsky patterns.
Model. We used YOLO (Redmon et al., 2016) as a perception module and trained it on the pattern-
free figures, which are randomly generated. The correct rules are given to classify the figures, and
clause weights are initialized to choose each of them. For e.g., the classification rule of the twopairs
data set is : “the Kandinsky Figure has two pairs of objects with the same shape, in one pair the
objects have the same colors in the other pair different colors, two pairs are always disjunct, i.e.
they don’t share objects.”. This can be represented as a logic program containing four clauses:
1 kp(X):-in(O1,X),in(O2,X),in(O3,X),in(O4,X),same_Shape_Pair(O1,O2),
Same color_Pair(O1,O2),same Shape_Pair(O3,O4),diff color_Pair(O3,O4).
2	same_shape_pair(X,Y):-Shape(X,Z),shape(Y,Z).
3	same_color_pair(X,Y):-color(X,Z),color(Y,Z).
4	diff_color_pair(X,Y):-Color(X,Z),color(Y,W),diff_Color(Z,W).
Pre-training. We generated 15k pattern-free figures for pre-training of the visual perception mod-
ule. Each object has the class label and the bounding box as an annotation. We generated 5k concept
examples for neural predicate closeby and online.
Baselines. We adopted ResNet (He et al., 2016) as a benchmark and also compare against
YOLO+MLP, where the input figure is fed to the pre-trained YOLO model, and a simple MLP
module predicts the class label from the YOLO outputs.
Results. Table 1 shows the results for each Kandinsky data set. The Resnet50 model overfits while
training and thus performs poorly in every test data. The YOLO+MLP model performs compara-
tively better and achieves greater than 90% accuracy in twopairs, threepairs, and closeby data set.
However, in relatively complex patterns of red-traignle, online/pair, and 9-cicle data sets the per-
formance degrades. On the contrary, NSFR outperforms the considered baselines significantly and
achieves perfect classification in 4 out of the 6 data sets.
8
Under review as a conference paper at ICLR 2022
Model	Validation	Test	Vandation	I Test
	CLEVR-Hans3		CLEVR-Hans7	
CNN	99.55	70.34	96.09	84.50
NeSy (Default)	98.55	81.71	96.88	90.97
NeSy-XIL	100.00	91.31	98.76	94.96
NS-FR	-9818^^	98.40	-93.60^^	92.19
Table 2: Classification accuracy for CLEVR-Hans data sets com-
pared to baselines.
Figure 4: The inference time
with different batch sizes.
4.2	Reasoning on the 3D-World: Solving CLEVR-Hans problems
Data. The CLEVR-Hans data set (Stammer et al., 2021) contains confounded CLEVR (Johnson
et al., 2017) images, and each image is associated with a class label. The CLEVR-Hans3 data set
has three classes, and the CLEVR-Hans7 data set has seven classes.
Model. We adopted Slot Attention (Locatello et al., 2020a) as a visual perception module and used
a set prediction architecture, where each slot representation is fed to MLPs to predict attributes.
Pre-training. The slot attention model was pre-trained following (Locatello et al., 2020a) using
the set prediction setting on the CLEVR (Johnson et al., 2017) data set. In the concept learning
process, we trained rightside, leftside, and front using the scene data in the CLEVR data set.
We generated 10k positive and negative examples for each concept, respectively.
Baselines. The considered baselines are the ResNet34-based CNN model (Hu et al., 2016), and the
Neuro-Symbolic model (NeSy) (Stammer et al., 2021). The NeSy model was trained in two different
settings: (1) training using classification rules (NeSy-default), and (2) training using classification
rules and example-based explanation labels (NeSy-XIL).
Results. Table 2 shows the classification accuracy in the CLEVR-Hans data sets. The results of
baselines have been presented in (Stammer et al., 2021). In the CLEVR-Hans3 data set, NSFR
achieved more than 98% in each split. In the CLEVR-Hans7 data set, NSFR achieved more than
92%, that is > NeSy-Default. Note that, NeSy-XIL model exploits example-based labels about
the explanation, whereas NeSy-Default and NSFR do not. Thus NeSy-XIL outperforms NSFR
marginally. The empirical result shows that NSFR (i) handles different types of the perception
models (YOLO and Slot Attention), (ii) can effectively handle 3D images, and more importantly,
(iii) is robust to confounded data if the classification rules are available in the form of logic programs.
4.3	Fast Inference by Batch Computation
We show that NSFR can perform fast inference by batch computation. Figure 4 shows the inference
time with different batch sizes in Kandinsky data sets. We change the batch size from 1 to 50 by
increments of 5 and run the experiment in each Kandinsky data set. The magenta line represents
mean running time, and the shade represents the standard deviation over the data sets. The empirical
result shows that NSFR can perform fast reasoning using batch computation, which is the essential
nature of deep neural networks.
5 Conclusion and Future Work
We proposed Neuro-Symbolic Forward Reasoner (NSFR), a novel framework for object-centric rea-
soning tasks. NSFR perceives raw input images using an object-centric model, converts the output
into the probabilistic ground atoms, and performs the differentiable forward-chaining inference.
Furthermore, NSFR supports batch computation. Thus it combines the perception module and the
reasoning module seamlessly. In our experiments, NSFR outperformed conventional CNN-based
models in 2D Kandinsky patterns and 3D CLEVR-Hans data sets, where the classification rules are
defined on the high-level concepts. There are several avenues for future work. If we set the clause
weights as trainable parameters, NSFR can perform structure learning of logic programs from visual
inputs, which is a promising way of extending Inductive Logic Programming and differentiable ap-
proaches. Likewise, if we set the parameters of the perception model as trainable parameters, NSFR
can train perception models with logical constraints.
9
Under review as a conference paper at ICLR 2022
Ethics S tatement
With our work, we have shown that we can seamlessly combine symbolic and sub-symbolic systems.
Combining neural models with symbolic models can lead to better generalization and handle a
wider variety of problems.The major impact that our work aims is enabling coherent quantitative
inquiries that encompass multiple data dimension types across object-centric reasoning tasks. This
can have several implications on studying how scientific fields evolve and can produce validated
signatures predictive of the emergence and success of new fields or discoveries. The results can
also be leveraged to create metrics and methods to estimate the innovation potential of scientific
enterprises. To the best of our knowledge, our study does not raise any ethical, privacy or conflict of
interest concerns.
Reproducibility S tatement
Upon acceptance, an official GitHub repository will be made public, containing the code of NSFR,
and scripts to reproduce the experiments and generate data sets. In addition to this, architectural
details and hyper-parameters are included in the appendix. Preliminary code will be uploaded upon
submission. Lastly, details on the evaluation metrics and relevant data sets, including the relevant
symbolic rules, are given in the main text as well as the appendix.
References
Saeed Amizadeh, Hamid Palangi, Oleksandr Polozov, Yichen Huang, and Kazuhito Koishida.
Neuro-symbolic visual reasoning: Disentangling “visual” from “reasoning”. In ICML. 2020.
Forough Arabshahi, Jennifer Lee, Mikayla Gawarecki, Kathryn Mazaitis, Amos Azaria, and Tom
Mitchell. Conversational neuro-symbolic commonsense reasoning. AAAI, 2021.
George Boole. The Mathematical Analysis of Logic: Being an Essay Towards a Calculus of De-
ductive Reasoning. Cambridge Library Collection - Mathematics. Cambridge University Press,
1847.
Leon Bottou. From machine learning to machine reasoning. Machine learning, 2014.
J. S. Bruner, J. J. Goodnow, and G. A. Austin. A Study of Thinking. Wiley, 1956.
Christopher P Burgess, Loic Matthey, Nicholas Watters, Rishabh Kabra, Irina Higgins, Matt
Botvinick, and Alexander Lerchner. Monet: Unsupervised scene decomposition and represen-
tation. arXiv preprint arXiv:1901.11390, 2019.
Zhenfang Chen, Jiayuan Mao, Jiajun Wu, Kwan-Yee Kenneth Wong, Joshua B. Tenenbaum, and
Chuang Gan. Grounding physical concepts of objects and events through dynamic visual reason-
ing. In ICLR, 2021.
William W. Cohen, Fan Yang, and Kathryn Mazaitis. Tensorlog: A probabilistic database imple-
mented using deep-learning infrastructure. JAIR, 2020.
JM Corchado. Neuro-symbolic reasoning-a solution for complex problemas. In International Con-
ference on Intelligent Systems, 1995.
Juan M Corchado, M Lourdes Borrajo, Maria A Pellicer, and J Carlos Yafiez. NeUro-Symbolic
system for business internal control. In ICDM, 2004.
Wang-Zhou Dai, Qiuling Xu, Yang Yu, and Zhi-Hua Zhou. Bridging machine learning and logical
reasoning by abductive learning. 2019.
Luc De Raedt and Kristian Kersting. Probabilistic logic learning. ACM SIGKDD Explorations
Newsletter, 2003.
Luc De Raedt and Angelika Kimmig. Probabilistic (logic) programming concepts. Machine Learn-
ing, 2015.
10
Under review as a conference paper at ICLR 2022
Luc De Raedt, Robin Manhaeve, Sebastijan Dumancic, Thomas Demeester, and Angelika Kimmig.
Neuro-symbolic= neural+ logical+ probabilistic. In NeSy’19@ IJCAI, the 14th International
Workshop on Neural-Symbolic Learning and Reasoning, 2019.
Andrea Dittadi, Samuele Papa, Michele De Vita, Bernhard Scholkopf, Ole Winther, and Francesco
Locatello. Generalization and robustness implications in object-centric learning. arXiv preprint
arXiv:2107.00637, 2021.
David L DoWe and Jose Hernandez-Orallo. Iq tests are not for machines, yet. Intelligence, 2012.
Martin Engelcke, Adam R. Kosiorek, Oiwi Parker Jones, and Ingmar Posner. Genesis: Generative
scene inference and sampling With object-centric latent representations. In ICLR, 2020.
Richard Evans and EdWard Grefenstette. Learning explanatory rules from noisy data. JAIR, 2018.
Florentino Fdez-Riverola, Juan M Corchado, and Jesus M Torres. NeUro-SymboliC system for fore-
casting red tides. In Irish Conference on Artificial Intelligence and Cognitive Science, 2002.
Artur d’Avila Garcez, Marco Gori, Luis C Lamb, Luciano Serafini, Michael Spranger, and Son N
Tran. Neural-symbolic computing: An effective methodology for principled integration of ma-
chine learning and reasoning. arXiv preprint arXiv:1905.06088, 2019.
Chi Han, Jiayuan Mao, Chuang Gan, Joshua B. Tenenbaum, and Jiajun Wu. Visual concept-
metaconcept learning. NeurIPS, 2019.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In CVPR, 2016.
Andreas Holzinger, Michael Kickmeier-Rust, and Heimo Muller. Kandinsky patterns as iq-test for
machine learning. In Andreas Holzinger, Peter Kieseberg, A Min Tjoa, and Edgar Weippl (eds.),
Machine Learning and Knowledge Extraction, 2019.
Andreas Holzinger, Anna Saranti, and Heimo Mueller. Kandinskypatterns-an experimen-
tal exploration environment for pattern analysis and machine intelligence. arXiv preprint
arXiv:2103.00519, 2021.
Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, and Eric Xing. Harnessing deep neural
netWorks With logic rules. In ACL, 2016.
Zhengyao Jiang and Shan Luo. Neural logic reinforcement learning. In ICML 2019, 2019.
Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C LaWrence Zitnick, and
Ross Girshick. Clevr: A diagnostic dataset for compositional language and elementary visual
reasoning. In CVPR, 2017.
Philip N Johnson-Laird. Mental models and human reasoning. Proceedings of the National Academy
of Sciences, 2010.
Muhammad Jaleed Khan and EdWard Curry. Neuro-symbolic visual reasoning for multimedia event
processing: OvervieW, prospects and challenges. In CIKM (Workshops), 2020.
Daphne Koller, Nir Friedman, Saso Dzeroski, Charles Sutton, Andrew McCallum, Avi Pfeffer, Pieter
Abbeel, Ming-Fai Wong, Chris Meek, Jennifer Neville, et al. Introduction to statistical relational
learning. MIT press, 2007.
Yusen Liu, Fangyuan He, Haodi Zhang, Guozheng Rao, Zhiyong Feng, and Yi Zhou. How well do
machines perform on iq tests: a comparison study on a large-scale dataset. In IJCAI, 2019.
Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran, Georg Heigold,
Jakob Uszkoreit, Alexey Dosovitskiy, and Thomas Kipf. Object-centric learning with slot atten-
tion. In NeurIPS, 2020a.
Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran, Georg Heigold,
Jakob Uszkoreit, Alexey Dosovitskiy, and Thomas Kipf. Object-centric learning with slot atten-
tion. 2020b.
11
Under review as a conference paper at ICLR 2022
Thomas Lukasiewicz. Probabilistic logic programming. In ECAI, 1998.
Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt.
Deepproblog: Neural probabilistic logic programming. In NeurIPS 2018, 2018.
Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B. Tenenbaum, and Jiajun Wu. The Neuro-
Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervi-
sion. In ICLR 2019, 2019.
Fred D Miller. Aristotle on rationality in action. The Review of Metaphysics, 1984.
Heimo Mueller and Andreas Holzinger. Kandinsky patterns, 2019.
Li Nanbo, Cian Eastwood, and Robert B Fisher. Learning object-centric representations of multi-
object scenes from multiple views. In NeurIPS, 2020.
David Poole, Randy Goebel, and Romas Aleliunas. Theorist: A logical reasoning system for defaults
and diagnosis. In The Knowledge Frontier. 1987.
Luc De Raedt, Kristian Kersting, Sriraam Natarajan, and David Poole. Statistical relational artificial
intelligence: Logic, probability, and computation. Synthesis Lectures on Artificial Intelligence
and Machine Learning, 2016.
Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Unified,
real-time object detection. In CVPR, June 2016.
Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. Faster r-cnn: Towards real-time object
detection with region proposal networks. In NIPS, 2015.
Ryan Riegel, Alexander Gray, Francois Luus, Naweed Khan, Ndivhuwo Makondo, Ismail Yunus
Akhalwaya, Haifeng Qian, Ronald Fagin, Francisco Barahona, Udit Sharma, et al. Logical neural
networks. arXiv preprint arXiv:2006.13155, 2020.
Tim Rocktaschel and Sebastian Riedel. End-to-end Differentiable Proving. In NeurIPS 2017, 2017.
Hikaru Shindo, Masaaki Nishino, and Akihiro Yamamoto. Differentiable inductive logic program-
ming for structured examples. In AAAI 2021, 2021.
Xujie Si, Mukund Raghothaman, Kihong Heo, and Mayur Naik. Synthesizing datalog programs
using numerical relaxation. In IJCAI 2019, 2019.
Wolfgang Stammer, Patrick Schramowski, and Kristian Kersting. Right for the right concept: Re-
vising neuro-symbolic concepts by interacting with their explanations. In CVPR 2021, 2021.
Gustav Sourek, VoJtech Aschenbrenner, FiliP Zelezny, Steven Schockaert, and OndreJ Kuzelka.
Lifted relational neural networks: Efficient learning of latent relational structures. JAIR, 2018.
Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Van den Broeck. A semantic loss
function for deeP learning with symbolic knowledge. In ICML, 2018.
Fan Yang, Zhilin Yang, and William W. Cohen. Differentiable learning of logical rules for knowl-
edge base reasoning. In NeurIPS, 2017.
Zhun Yang, Adam Ishay, and Joohyung Lee. NeurasP: Embracing neural networks into answer set
Programming. In IJCAI, 2020.
12
Under review as a conference paper at ICLR 2022
A Notation
A. 1 Notation
Term
Explanation
⊥
>
p/(n, [dt1, . . . ,dtn])
p(X, Y)
p(X, Y) : -q(X, Y).
dt vpTTdOAXVCGPLE
x
X
Z ∈ RB×E×D
Z(i) ∈ RB×D
Aattr
V(0) ∈ RB×G
V(t) ∈ RB×G
I ∈ RC×G×S×L
Φ
Θ
W ∈ RM×C
G
C
B
S
L
E
D
M
N
γ
softor γd
stack d
θ
a special atom that is always false
a special atom that is always true
a neural predicate
an atom
a clause
a datatype, e.g., color, shape
valuation function
a set of constants
a set of constants of datatype dt, i.e., dom(dt)
a set of object constants
a set of attribute constants
a set of input constants
a set of variables
a set of clauses
a set of ground atoms
a set of predicates P
a language (P, T,V)
a set of attribute encoding on language L
a substitution
a vector
a tensor
an object-centric representation
an object-centric representation of the i-th object, i.e., Z:,i,:
one-hot encoding of attr
an initial valuation vector in batch
a valuation vector in batch at time-step t
an index tensor
the parameter in object-centric models
the parameter in neural predicates
clause weights
the number of ground atoms, i.e., |G|
the number of clauses, i.e., |C|
batch size of the input
the maximum number of substitutions for existentially quantified variables
the maximum number of body atoms
the maximum number of objects in an image
the dimension object-centric representation
the size of logic program, i.e., the number of distinct clause weights
input dimension
the smooth parameter for softor function
the softor fucntion for dimension d with a smooth parameter γ
the stack method to concatenate tensors along a new dimension d
element-wise multiplication between two tensors
Table 3: Notations in this paper.
13
Under review as a conference paper at ICLR 2022
B Facts Converting Algorithm
Algorithm 1 Convert the object-centric representation into probabilistic facts
Input: object-centric representation Z ∈ RB ×E ×D, a set of ground atoms G, background knowl-
1:
2:
3:
4:
5:
6:
7:
8:
9:
edge B, a set of one-hot encoding of attributes EL
initialize V(0) ∈ RB×lGl as a zero tensor
for Fi = p(t1 , . . . , tn) ∈ G do
if p is a neural predicate then
for tj in [t1 , . . . , tn] do
fto-tensor
(tj;Z,EL)
V:(,0i) = vp(T1, . . . , Tn) // call the valuation function for neural predicate p
else if Fi ∈ B then
V:(,0i) = 1.0 // set background knowlege
return V(0)
C Data sets in Experiments
We make the data sets used in the paper available at: https://bit.ly/3FhTeOY.
C.1 Kandinsky Dataset Summary
	TWOPairs	ThreePairs	ClOseby	Red-Triangle	Online-Pair	9-Circles
Combination	Yes (Hard)	Yes (Hard)	no	Yes (Easy)	Yes (Easy)	Yes (Hard)
Spatial	No	No	Yes (Easy)	Yes (Easy)	Yes (Hard)	No
objects	4	6	4	6	5	9
training data	5000	5000	5000	5000	5000	1000
test/val data	2000	2000	2000	2000	2000	500
Table 4: Kandinsky patterns data set summary. Each data set is different in terms of combinatorial
or spatial patterns.
C.2 Classification Rules
TwoPairs The pattern for positive figures is: “the Kandinsky Figure has two pairs of objects with
the same shape. In one pair, the objects have the same colors in the other pair different colors.
Two pairs are always disjunct, i.e., they do not share objects.”. This can be represented as a logic
program containing four clauses:
1 kp(X):-in(O1,X),in(O2,X),in(O3,X),in(O4,X),same_Shape_Pair(O1,O2),
Same color_Pair(O1,O2),same Shape_Pair(O3,O4),diff color_Pair(O3,O4).
2	same_shape_pair(X,Y):-Shape(X,Z),shape(Y,Z).
3	same_color_pair(X,Y):-color(X,Z),color(Y,Z).
4	diff_color_pair(X,Y):-Color(X,Z),color(Y,W),diff_Color(Z,W).
ThreePairs The pattern for positive figures is: “the Kandinsky Figure has three pairs of objects
with the same shape. In one pair, the objects have the same colors in other pairs different colors.
Three pairs are always disjunct, i.e., they do not share objects.”. This can be represented as a logic
program containing four clauses:
1 kp(X):-in(O1,X),in(O2,X),in(O3,X),in(O4,X),in(O5,X),in(O6,X),
Same Shape_Pair(O1,O2),same Color_Pair(O1,O2),same Shape_Pair(O3,O4),
diff Color_Pair(O3,O4),same Shape_Pair(O5,O6),diff Color_Pair(O5,O6).
2	same_shape_pair(X,Y):-Shape(X,Z),shape(Y,Z).
3	same_color_pair(X,Y):-COlOr(X,Z),color(Y,Z).
4	diff_color_pair(X,Y):-color(X,Z),color(Y,W),diff_color(Z,W).
14
Under review as a conference paper at ICLR 2022
1
1
2
3
1
2
3
1
2
3
4
1
2
3
1
2
3
4
5
Closeby The pattern for positive figures is: “the Kandinsky Figure has a pair of objects that are
close by each other.”. This can be represented as a logic program containing one clause:
kp(X) :- in(O1,X),in(O2,X),closeby(O1,O2).
Red-Triangle The pattern for positive figures is: “the Kandinsky figure has a pair of objects that
are close by each other, and the one object of the pair is a red triangle, and the other object has a
different color and different shape.”. This can be represented as a logic program containing three
clauses:
kp(X) :- in(O1,X),in(O2,X),closeby(O1,O2),color(O1,red),shape(O1,triangle
),diff Shape_Pair(O1,O2),diff ColoC_Pair(O1,O2).
diff_Shape_Pair(X,Y) :- ShaPe(X,Z),shape(Y,W),diff_ShaPe(Z,W).
diff_Color_Pair(X,Y):-Color(X,Z),color(Y,W),diff_Color(Z,W).
Online/Pair The pattern for positive figures is: “the Kandinsky figure has five objects that are
aligning on a line, and it contains at least one pair of objects that have the same shape and the same
color.”. This can be represented as a logic program containing three clauses:
kP(X) :- in(O1,X),in(O2,X),in(O3,X),in(O4,X),in(O5,X),online(O1,O2,O3,O4,
O5),same Shape_Pair(O1,O2),same Color_Pair(O1,O2).
Same_Shape_Pair(X,Y) :- Shape(X,Z),ShaPe(Y,Z).
Same_Color_Pair(X,Y) :- Color(X,Z),Cθlor(Y,Z).
9-Circles The pattern for positive figures is: “the Kandinsky figure has three red objects, three
blue objects, and three yellow objects.”1. This can be represented as a logic program containing four
clauses:
kp(X):-haS red triple(X),haS_yellow triple(X),haS blue triple(X).
haS_red_triple(X):-in(O1,X),in(O2,X),in(O3,X),Color(O1,red),Color(O2,red)
,Cθlοr(O3,red).
haS_yellow_triple(X):-in(O1,X),in(O2,X),in(O3,X),Color(O1,yellow),Color(
O2,yellοw),Cθlοr(O3,yellοw).
haS_blue_triple(X):-in(O1,X),in(O2,X),in(O3,X),Color(O1,blue),Color(O2,
blue),Color(O3,blue).
CLEVR-Hans3 The data set has three classification rules. We refer to (Stammer et al., 2021) for
more details. We used the following logic program in NSFR:
kp1(X):-in(O1,X),in(O2,X),Size(O1,large),Shape(O1,Cube),Size(O2,large),
Shape(O2,Cylinder).
kp2(X):-in(O1,X),in(O2,X),Size(O1,Small),material(O1,metal),Shape(O1,Cube
),Size(O2,Small),Shape(O2,Sphere).
kp3(X):-in(O1,X),in(O2,X),Size(O1,large),Color(O1,blue),Shape(O1,Sphere),
Size(O2,Small),Cθlor(O2,yellow),Shape(O2,Sphere).
CLEVR-Hans7 The data set has seven classification rules. We refer to (Stammer et al., 2021) for
more details. We used the following logic program in NSFR:
kp1(X):-in(O1,X),in(O2,X),Size(O1,large),Shape(O1,Cube),Size(O2,large),
Shape(O2,Cylinder).
kp2(X):-in(O1,X),in(O2,X),Size(O1,Small),material(O1,metal),Shape(O1,Cube
),Size(O2,Small),Shape(O2,Sphere).
kp3(X):-in(O1,X),in(O2,X),in(O3,X),Color(O1,Cyan),front(O1,O2),front(O1,
O3),Cθlor(O2,red),Cθlor(O3,red).
kp4(X):-in(O1,X),in(O2,X),in(O3,X),in(O4,X),Size(O1,Small),Color(O1,green
),Size(O2,Small),Cθlοr(O2,brοwn),Size(O3,Small),Cθlοr(O3,purple),Size
(O4,Small).
kp5(X):-haS_3_SphereS_left(X).
1The 9-circles data set has been public as a challenge data set (https://github.com/human-centered-ai-
lab/dat-kandinsky-patterns). The original data set contains counterfactual examples that falsify a simple hy-
pothesis. We excluded the counterfactual examples to simplify the problem.
15
Under review as a conference paper at ICLR 2022
6 kp5(X):-has_3_Spheres_left(X),has_3_metal_cylinders_right(X).
7 kp6(X):-has_3_metal_cylinders_right(X).
8 kp7(X):-in(O1,X),in(O2,X),size(O1,large),color(O1,blue),shape(O1,sphere),
Size(O2,small),color(O2,yellow),shape(O2,sphere).
9 has_3_Spheres_left(X):-in(O1,X),in(O2,X),in(O3,X),shape(O1,sphere),shape(
O2,sphere),shape(O3,sphere),leftside(O1),leftside(O2),leftside(O3).
10 has_3_metal_cylinders_right(X):-in(O1,X),in(O2,X),in(O3,X),shape(O1,
Cylinder),shape(O2,cylinder),shape(O3,cylinder),material(O1,metal),
material(Ο2,metal),material(Ο3,metal),rightside(Ο1),rightside(Ο2),
rightside(O3).
TwoPairs
ThreePairs
Closeby
Red-Triangle
Online/Pair
9-Circles
Figure 5: Training examples in each Kandinsky data set. The left three images are positive examples,
and the right three images are negative examples.
16
Under review as a conference paper at ICLR 2022
CLEVR-Hans3
CLEVR-Hans7
Figure 6: Examples in the CLEVR-Hans data set. CLEVR-Hans3 has three classes and CLEVR-
Hans7 has seven classes, respectively. Each example represents each class in the data set.
D	Object-centric Perception Models in Experiments
We used different object-centric perception models for Kandinsky and CLEVR-Hans data sets. In
this section, we describe model details and the pre-training setting. All experiments were performed
on one NVIDIA A100-SXM4-40GB GPU with 40 GB of RAM.
D.1 YOLO for Kandinsky data set
We used YOLOv52 model, whose implementation is publicly available. We adopted the YOLOv5s
model, which has 7.3M parameters.
Pre-training We generated 15, 000 pattern-free figures for training, 5000 figures for validation.
Figure 7 shows the statistics of the pre-training data set. The class labels and positions are generated
randomly. The original image size is 620 × 620, and resized into 128 × 128. The label consists of the
class labels and the bounding box for each object. The class label is generated by the combination
of the shape and the color of the object, e.g., red circle and blue square. The number of classes is 9.
Each image contains at least 2 objects, and at most 10 objects. Figure 8 shows the confusion matrix
for the pre-trained model. The confusion matrix of the pre-training data set of the YOLOv5 model.
The pre-trained YOLOv5 model classifies the objects correctly in Kandinsky patterns.
D.2 Slot Attention for CLEVR-Hans data set
We used the same setup as (Stammer et al., 2021). In the preprocessing, we downscaled the CLEVR-
Hans images to visual dimensions 128 × 128 and normalized the images to lie between -1 and 1.
For training the slot-attention module, an object is represented as a vector of binary values for the
shape, size, color, and material attributes and continuous values between 0 and 1 for the x, y, and z
positions. We refer to (Locatello et al., 2020a) for more details.
2https://github.com/ultralytics/yolov5
17
Under review as a conference paper at ICLR 2022
10000 -
8000 -
6000-
4000-
2000-
Figure 7: The statistics of the pre-training data set in Kandinsky Patterns tasks. The distribution of
the class label (left) and the distribution of the position of the objects (right). The class labels and
the positions are generated randomly.
yellow circle
yellow square
yellow triangle
blue triangle
background FN
0.02
①-:U-ɔ PΦJ
ΦJenbs Pφ.J
φ-6ue∙iz4 P ①」
①-ɔ,joMo--əA
θ-6ueμl MO-aA
e
Tru
①」enbs Mo--əA
əfu 史B① n-q
du_PUn0」6>peq
Pgɔ-p①」d
①p」©①n_q
aιenbs ①n-q
Figure 8: The confusion matrix of the YOLOv5 model in the test split after the pre-training
trained YOLOv5 model classifies the objects in Kandinsky figures correctly.
. The
E Languages in Experiments
In this section, we show the language settings we used in each data set.
18
Under review as a conference paper at ICLR 2022
E.1 Data types and Constants
Tab. 5 and Tab. 6 shows the constants and their data types for each Kandinsky and CLEVR data set,
respectively.
Datatype	Terms
image	img
object	obj1, obj2, . . ., obj9
color	red, blue, yellow
shape	square, circle, triangle
Table 5:	Datatype and constants in Kandinsky data set.
Datatype Terms
object obj1, obj2, . .., obj9
color	cyan, blue, yellow, purple, red, green, gray, brown
shape	sphere, cube, cylinder
size	large, small
material rubber, metal
side	right, left
Table 6:	Datatype and constants in CLEVR data set.
E.2 Predicates
Predicate
kp/[image]
same_shape_pair/[object, object]
same_color_pair/[object, object]
diff_shape_pair/[object, object]
diff_color_pair/[object, object]
Explanation
The image belongs to a pattern.
The two objects have a same shape.
The two objects have a same color.
The two objects have different shapes.
The two objects have different colors.
Table 7:	Predicates in Kandinsky data set.
Neural Predicate
in/[object, image]
shape/[object, shape]
color/[object, color]
closeby/[object, object]
online/[object, . . . , object]
Explanation
The object is in the image.
The object has the shape of shape.
The object has the color of color.
The two objects are located close by each other.
The objects are aligned on a line.
Table 8:	Neural predicates in Kandinsky data set.
Predicate
kpi/[image]
same_shape_pair/[object, object]
same_color_pair/[object, object]
has3 ,spheres_left/[iamge]
has_3_metal_cylinders_right / [iamge]
Explanation
The image belongs to the i-th pattern.
The two objects have a same shape.
The two objects have a same color.
The image has three spheres on the left side.
The image has three metal cylinders on the right side.
Table 9:	Predicates in CLEVR-Hans data set.
19
Under review as a conference paper at ICLR 2022
Neural Predicate
in/[object, image]
shape/[object, shape]
color/[object, color]
material/[object, material]
size/[object, size]
leftside/[object]
rightside/[object]
front/[object, object]
Explanation
The object is in the image.
The object has the shape of shape.
The object has the color of color.
The object has the color of material.
The object has the color of size.
The object is on leftside.
The object is on rightside.
The first object is front of the second object.
Table 10:	Neural predicates in CLEVR-Hans data set.
E.3 Background Knowledge
In TwoPairs, ThreePairs, and Red-Triangle data sets, we prepared back-
ground knowledge for NSFR about predicate diff_color and diffshape as
B =	{diff_color(red, blue), diff_color(blue, red), diff_color(red, yellow),
diff .color (yellow, red), diff .color (blue, yellow), diff .color (yellow, blue),
diff .shape (circle, square), diff .shape (square, circle), diff .shape (circle, triangle),
diff .shape (triangle, circle), diff .shape (square, triangle),
diff .shape (triangle, square)}.
F Valuation Functions
F.1 Valuation functions for Kandinsky Patterns with YOLO
In our experiments, the output format of the YOLO model is as in the following table.
index ∣01234	5	6	7	8	9	10
attribute ∣ xι y1 X2 y2 red	yellow	blue	square	circle	triangle	objectness
Here, (x1, y1) and (x1, y2) is the coordinates of the top-left and bottom-right points of the bounding
box. Each attribute dimension contains each probability.
The valuation function for each neural predicate is shown in Tab. 11. Tensor Z(cie)nter for predicate
closeby represents the center coordinate of the bounding box for the i-th object. Function flinear
for predicate online computes the closed-form solutions of linear regression in batch and returns
the error values.
Atom
in(obj1, img)
shape(obj1, circle)
color(obj2, red)
closeby(obj1, obj2)
online(obj1, . . . , obj5)
Valuation Function
Vin(Z(1), X) = Z(II)0 ∈ RB〃 return the Objectness
vshape (Z , Acircle ) = sum 1 (Z1,8:11	Acircle ) ∈ R
vcolor (Z , Ared) = sum1 (Z:,4:7	Ared) ∈ R
vcloseby(Z(1), Z(2)) = σ(norm0(Z(c1e)nter - Z(c2e)nter); w) ∈ RB
Vonline(Z ⑴，∙∙∙，Z⑸)=σ (力inear(Z ⑴，...,Z ⑸)；W)∈ RB
Table 11: Valuation functions for each neural predicate in Kandinsky data set. Each neural predicate
is associated with a valuation function. In the forward-chaining reasoning step, the probability for
each ground atom is computed using the valuation function. The parameterized neural predicates
are trained using the concept examples.
F.2 Valuation functions for CLEVR-Hans with Slot Attention
In our experiments, the output format of the slot attention model is as in the following table.
20
Under review as a conference paper at ICLR 2022
index	IOI	234	5	6	7	8	9	10
attribute	∣ objectness	x	y	z sphere	cube	cylinder	large	small	rubber	metal
11	12	13	14	15	16	17	18
cyan	blue	yellow	purple	red	green	gray	brown
The valuation function for each neural predicate is shown in Tab.12.
Atom	Valuation Function
in(obj1, img) shape(obj1, sphere) size(obj1, large) material(obj1, metal) color(obj1, red) leftside(obj1) rightside(obj1) front(obj1, obj2)	V	in(Z⑴,X) = Z(,0) ∈ RB〃return OtjectneSS vshape(Z(1), Asphere) = sum1 (Z:(,4):7	Acircle ) ∈ RB vsize(Z(1), Alarge) = sum1(Z:(,17):9	Alarge) ∈ RB vmaterial (Z	, Ametal ) = sum 1 (Z:,9:11	Acircle ) ∈ R vcolor(Z(1), Ared) = sum1(Z:(,11)1:19	Ared) ∈ RB V	leftside(Z⑴)=σ(Z(,1); W) Θ Z(,0) ∈ RB // the objectness is multiplied V	rightside(Z(I)) = σ(Z(IL); w) Θ Z(O) ∈ RB // the objectness is multiplied V	front(Z⑴,Z(2)) = σ ([z*4, z124] ; w) Θ Z(IO) Θ Zgl) ∈ RB
Table 12: Valuation functions for each neural predicate in CLEVR-Hans data set. Each neural pred-
icate is associated with a valuation function. In the forward-chaining reasoning step, the probability
for each ground atom is computed using the valuation function. The parameterized neural predicates
are trained using the concept examples.
G Details of Tensor Encoding
Preliminaries. A unifier for the set of expressions {A1, . . . , An} is a substitution θ such that
A1θ = A2θ = . . . = Anθ, written as θ = σ({A1, . . . , An}), where σ is a unification function. A
unification function returns the (most general) unifier for the expressions if they are unifiable. Deci-
sion function σ({Aι,..., An}) returns a Boolean value whether or not Aι,...,An are unifiable.
Dealing with Existentially Quantified Variables. We extend the differentiable forward-chaining
inference to deal with a flexible number of existentially quantified variables. For example, let clause
Ci = kp(X) : -in(O1, X).. The clause has the existentially quantified variable O1. First we consider
the possible substitutions for O1, e.g., {O1/obj1, O1/obj2}. For ground atom kp(img), by applying
these substitutions to the body atoms, we get the grounded clauses as:
kp(img) : -in(obj1, img).	(6)
kp(img) : -in(obj2, img).	(7)
In this case, the maximum number of substitutions S = 2. Using these grounded clauses, we can
build the index tensor for the differentiable inference function.
Formally, for each pair of Fj ∈ G and Ci = A : -B1 . . . Bn ∈ C, let θhead = funify ({Fj, A}).
For body atoms {Bι,..., Bn}, We compute {B；,..., Bn} where Bi = Biθhead. Let Vi,j =
V(Bi)∪,..., ∪V(Bn), where V is a function that returns a set of variables in the input atom. The
set of possible substitutions S is computed as:
Si,j = {X/t | X ∈ Vi,j ∧ t ∈ dom (dt)},	(8)
where dt is a datatype for constant t, which can be determined from the definition of the predicate.
The maximum number of substitutions for body atoms (subgoals) equals to the maximum size of the
set S = maxi,j |Si,j |. If there is a lot of possible substitutions for body atoms, NSFR can consume
a lot of memories because the size of the index tensor is proportional to S . In the computation
of possible substitutions, we assume that different constants are substituted for different variables,
respectively.
21
Under review as a conference paper at ICLR 2022
Tensor Encoding (Formal). We build a tensor that holds the relationships between clauses C
and ground atoms G. We assume that C and G are an ordered set, i.e., where every element has
its own index. Let L be the maximum body length in C , C = |C |, and G = |G|. Index tensor
I ∈ NC×G×S×L contains the indices of the ground atoms to compute forward inferences. Intuitively,
Ii,j,k,l is the index of the l-th ground atom in the i-th clause to derive the j-th ground atom with the
k-th substitution for existentially quantified variables.
For clause Ci = A : -B1, ..., Bn ∈ C and ground atom Fj ∈ G, let the body substitutions Si,j. We
compute tensor I ∈ RC×G×S×L :
IG(Blθk) if σ({A, Fj}) ∧ l ≤ n
Iij,k,ι =	IG (>)if σ({A,Fj }) ∧ k>n
IIG(⊥) if -σ({A,Fj})
(9)
where θk ∈ Si,j, 0 ≤ l ≤ L - 1, θ = σ({A, Fj}), and IG(F) returns the index of F in G. If clause
head A and ground atom Fj are unifiable, then we put the index of subgoal Bkθ into the tensor (line
1 in Eq. 9). If the clause has fewer body atoms than the longest clause in C , we fill the gap with the
index of > (line 2 in Eq. 9). If clause head A and ground atom Gj are not unifiable, then we place
the index of ⊥ (line 3 in Eq. 9).
H Learning and Reasoning on NSFR
In NSFR, we adopt the curriculum learning approach as illus-
trated in Figure 9.
Step1: Training visual-perception model The visual-
perception module is trained on pattern-free figures. Each fig-
ure is generated randomly without any patterns. Depending on
the specific type of the visual-perception model, each object
has its annotation.
Step2: Concept Learning Neural predicates are trained us-
ing the pre-trained perception module. Then the parameter-
ized neural predicates are trained on figures prepared for each
concept.
Step3: Reasoning on figures on patterns On the reason-
ing step, NSFR performs reasoning using the trained visual-
perception model and neural predicates. The logical rules are
given as weighted clauses.
pattern-free figures
training
object-perception
model
figures for concepts
ClOseby<obj i,obj2) ∣
figures with patterns
reasoning
on
visual input
positive negative
training
neural
predicates
Figure 9: Curriculum learning and
reasoning in NSFR.
I DETAILS ON THE softor dγ FUNCTION
I.0.1 THE softor dγ FUNCTION
In the differentiable inference process, NSFR often computes logical or for probabilistic values.
Taking max repeatedly can violate the gradients flow. The softor dγ function approximates the or
computation softly. The key idea is to use the log-sum-exp technique. We define the softor dγ func-
tion as follows:
SoftorY(X) = 1 Y log (sumd exp (X∕γ)),	(10)
S
where sumd is the sum function for tensors along dimension d, and
1.0
max (γ log sumd exp (X∕γ))
S
if max (γ log sumd exp (X∕γ)) ≤ 1.0
otherwise
(11)
The normalization term ensures that the softor γd function returns a normalized probabilistic values.
The dimension d specifies the dimension to ta be removed.
22
Under review as a conference paper at ICLR 2022
A popular choice is the probabilistic sum function: fprob_Sum (X, Y) = X + Y 一 X Θ Y, which
was adopted in (Evans & Grefenstette, 2018) and (Jiang & Luo, 2019). We compare these functions
with the proposed approach. Fig.11 visualizes each function, and Fig.11 visualizes the difference of
each function from the original logical or function, i.e., the max function. With a sufficiently small
smooth parameter, the softor dγ function approximates the original max function. In our experiments
in Kandinsky and CLEVR-Hans data sets, we consistently set γ = 0.01.
0.0
0.0
0.5
probabilistic sum (x + y - xy)
(max=1.0, min=0.0)
logical or (max(x,y))
(max=1.0, min=0.0)
1.0
1.0
0.0
0.5
x
0.5
x
1.0
softor (γ=1.0)
1 0	(max=1.0, min=0.6931)
softor (γ=0.1)
1 0	(max=1.0, min=0.0693)
softor (γ=0.05)
1 0	(max=1.0, min=0.0347)
0.5
0.5
0.5
0.0 V
0.0
0.5
x
1.0
0.0「
0.0
0.5
x
1.0
0.0「
0.0
0.5
x
1.0
softor (γ=0.01)
(max=1.0, min=0.0069)
1.0ι-------------------------
softor (γ=0.005)
(max=1.0, min=0.0035)
1.0η-------------------------
softor (γ=0.0001)
(max=1.0, min=0.0001)
1.0η-------------------------
0.5
0.5
0.5
0.0 V
0.0
0.5
x
1.0
0.0「
0.0
0.5
x
1.0
0.0「
0.0
0.5
x
1.0
Figure 10:	The visualization of various or functions. The maximum and minimum values for each
image is shown on top. The softor dγ function with a sufficiently small smooth parameter approxi-
mates the logical or function for probabilistic values.
23
Under review as a conference paper at ICLR 2022
1.0
0.0
1.0
0.5
0.0
softor (γ=0.1)
(max=0.0693, min=0.0)
0.5
softor (γ=0.05)
(max=0.0347, min=0.0)
softor (γ=1.0)
(max=0.6931, min=0.0)
0.0	0.5
1.0	0.0	0.5	1.0	0.0	0.5	1.0
softor (γ=0.01)
softor (γ=0.005)	softor (γ=0.0001)
(max=0.0001, min=0.0)
1.0η-------------------------
(max=0.0035, min=0.0)
1.0η------------------------
(max=0.0069, min=0.0)
0.5
0.0	0.5
0.0
0.0
1.0	0.0	0.5	1.0	0.0	0.5	1.0
Figure 11:	The visualization of the difference between the original or function and other or func-
tions, i.e., probabilistic sum and softor γd . The maximum and minimum values in each image is
shown on top. The softor dγ function with a sufficiently small smooth parameter approximates the
logical or function for probabilistic values.
24