Under review as a conference paper at ICLR 2022
Federated Learning via Plurality Vote
Anonymous authors
Paper under double-blind review
Ab stract
Federated learning allows collaborative workers to solve a machine learning prob-
lem while preserving data privacy. Recent studies have tackled various chal-
lenges in federated learning, but the joint optimization of communication over-
head, learning reliability, and deployment efficiency is still an open problem.
To this end, we propose a new scheme named federated learning via plurality
vote (FedVote). In each communication round of FedVote, workers transmit bi-
nary or ternary weights to the server with low communication overhead. The
model parameters are aggregated via weighted voting to enhance the resilience
against Byzantine attacks. When deployed for inference, the model with binary
or ternary weights is resource-friendly to edge devices. We show that our pro-
posed method can reduce quantization error and converges faster compared to the
methods directly quantizing the model updates.
1	Introduction
Federated learning enables multiple workers to solve a machine learning problem under the coor-
dination of a central server (Kairouz et al., 2021). Throughout the training stage, client data will
be kept locally and only model weights or model updates will be shared with the server. Fed-
erated averaging (FedAvg) (McMahan et al., 2017) was proposed as a generic federated learning
solution. Although FedAvg takes advantage of distributed client data while maintaining their pri-
vacy, it leaves the following two challenges unsolved. First, transmitting high-dimensional messages
between a client and the server for multiple rounds can incur significant communication overhead.
Quantization has been incorporated into federated learning in recent studies (Reisizadeh et al., 2020;
Haddadpour et al., 2021). However, directly quantizing the gradient vector may not provide the op-
timal trade-off between communication efficiency and model accuracy 1. Second, the aggregation
rule in FedAvg is vulnerable to Byzantine attacks (Blanchard et al., 2017). Prior works tackled this
issue by using robust statistics such as coordinate-wise median and geometric median in the aggre-
gation step (Blanchard et al., 2017; Yin et al., 2018). Another strategy is to detect and reject updates
from malicious attackers (MUnoz-Gonzalez et al., 2019; Sattler et al., 2020). The robustness of the
algorithm is enhanced at the cost of additional computation and increased complexity of algorithms.
In this paper, we propose a new method called federated learning via plurality vote (FedVote). We
train a neural network at each worker with a range normalization function applied to model param-
eters. After local updating, binary/ternary weight vectors are obtained via stochastic rounding and
sent to the server. The global model is updated by a voting procedure, and the voting results are sent
back to each worker for further optimization in the next round. The contributions of the paper are
summarized as follows.
1.	We present FedVote as a novel federated learning solution to jointly optimize the commu-
nication overhead, learning reliability, and deployment efficiency.
2.	We theoretically and experimentally verify the effectiveness of our FedVote design.
In bandwidth-limited scenarios, FedVote is particularly advantageous in simultaneously
achieving a high compression ratio and good test accuracy. Given a fixed communica-
tion cost, FedVote improves model accuracy on the CIFAR-10 dataset by 5-10%, 15-20%,
1Predictive coding in video and image compression (Li et al., 2015; Gonzalez & Woods, 2014) is an example
that directly quantizing the raw signal we intend to transmit does not provide the best trade-off between the
coding efficiency and the utility/bitrate.
1
Under review as a conference paper at ICLR 2022
and 25-30% compared with FedPAQ (Reisizadeh et al., 2020), SignSGD (Bernstein et al.,
2018), and FedAvg, respectively.
3.	We extend FedVote to incorporate reputation-based voting. The proposed method,
Byzantine-FedVote, exhibits much better resilience to Byzantine attacks in the presence
of close to half attackers without incurring excessive computation compared with existing
algorithms.
2	Related Work
Communication-Efficient Federated Learning. In the prior study of federated learning, various
strategies have been proposed to reduce communication cost. One research direction is to reduce the
size of messages in each round. For example, Bernstein et al. (2018) showed that sign-based gradient
descent schemes can converge well in the homogeneous data distribution scenario, while Chen et al.
(2020); Jin et al. (2020); Safaryan & Richtarik (2021) extended it to the heterogeneous data distri-
bution setting. In parallel, FedAvg adopts a periodic averaging scheme and targets at reducing the
number of communication rounds (McMahan et al., 2017). Hybrid methods consider simultaneous
local updates and accumulative gradient compression (Reisizadeh et al., 2020; Haddadpour et al.,
2021). In this work, we improve communication efficiency by employing binary/ternary weights in
the neural network.
Quantized Neural Networks. Quantized neural networks aim to approximate the full-precision
networks using quantized weights while keeping their generalizability. As a special case, binary
neural networks (BNNs) are gaining popularity in recent years. By restricting model weight values
to {-1, +1}, BNNs can reduce computational cost, memory requirement, and energy consumption.
Hubara et al. (2016) introduced real-valued latent weights and used the sign operator for binarization.
In contrast, Shayer et al. (2018) let the neural network learn the distribution of the binary or ternary
weights. Gong et al. (2019) added a soft quantization function to the real-valued weights, thus
avoiding the gradient mismatch between the forward and the backward passes. A more thorough
survey on BNN optimization can be found in Qin et al. (2020a).
Distributed Optimization of Quantized Neural Networks. A few recent works have explored
BNN optimization in a distributed setting, which is more relevant to our work. Lin et al. (2020)
conducted the case study of 1-bit quantized local models aggregated via ensemble distillation. The
aggregation becomes complicated due to the separate optimization stage of knowledge distillation,
especially when the distillation algorithm does not converge well in practice. In addition, their
BNN optimization is not tailored to the federated learning setting. Hou et al. (2019) theoretically
analyzed the convergence of distributed quantized neural networks, which was later implemented in
the application of intrusion detection (Qin et al., 2020b). In comparison, FedVote is presented as
a new algorithm by leveraging client local updates to accelerate the training. Different from Hou
et al. (2019), we do not assume a convex and twice differentiable objective function and bounded
gradients. Therefore, the analyses in Hou et al. (2019) cannot be directly applied to our study.
Byzantine Resilience in Federated Learning. An attack is Byzantine if arbitrary outputs are
produced due to the adversary (Kairouz et al., 2021). Blanchard et al. (2017) showed that FedAvg
cannot tolerate a single Byzantine attacker. They proposed an aggregation-rule-based remedy using
the similarity of local updates. Similarly, Yin et al. (2018) took the advantage of coordinatewise
median and trimmed-mean to robustify the aggregation. MUnoz-Gonzalez et aɪ. (2019) and Sattler
et al. (2020) detected the adversaries and filtered out their model updates. In this paper, we propose
a repUtation-based voting strategy for FedVote that is shown to have good convergence performance
in the Byzantine setting.
3	Preliminaries
Symbol conventions are as follows. Bold lower cases of letters sUch as vm denote colUmn vectors,
and vm,i is Used to denote its ith entry. For a scalar fUnction, it applies elementwise operation when
a vector inpUt is given. 1 = [1, . . . , 1]> denotes a vector with all entries eqUal to 1.
2
Under review as a conference paper at ICLR 2022
3.1	Federated Learning
The goal of federated learning is to build a machine learning model based on the training data
distributed among multiple workers. To facilitate the learning procedure, a server will coordinate
the training without seeing the raw data (Kairouz et al., 2021). In a supervised learning scenario, let
Dm = {(xm,j, ym,j)}jn=m1 denote the training dataset on the mth worker, with the input xm,j ∈ Rd1
and the label ym,j ∈ Rd2 in each training pair. The local objective function fm with a model weight
vector θ ∈ Rd is given by
1 nm
fm(θ)，fm(。； Dm) =——X '(θ; (Xm,j, Ymj )),	(1)
nm j=1
where ` is a loss function quantifying the error of model θ predicting the label ym,j for an input
Xm,j . A global objective function may be formulated as
min f(θ) = -1 X fm(θ).
θ∈Rd	M
m=1
(2)
3.2 Quantized Neural Networks
Consider a neural network g with the weight vector θ ∈ Rd . A forward pass for an input X ∈ Rd1
and a prediction y ∈ Rd2 can be written as y = g(θ, x). In quantized neural networks, the real-
valued θ is replaced by w ∈ Ddn , where Dn is a discrete set with a number n of quantization levels.
For example, we may have D2 = {-1, 1} for a binary neural network. For a given training set
{(xj, Zj)}n=i and the loss function ', the goal is to find an optimal W such that the averaged loss
is minimized over a search space of quantized weight vectors:
w
(3)
Prior studies tried to solve (3) by optimizing a real-valued latent weight vector h ∈ Rd (Hubara
et al., 2016; Shayer et al., 2018; Gong et al., 2019). The interpretations of the latent weight vary
when viewed from different perspectives. Hubara et al. (2016) used the sign operation to quantize
the latent weight into two levels during the forward pass. The binary weights can be viewed as an ap-
proximation of their latent real-valued counterparts. Shayer et al. (2018) trained a stochastic binary
neural network, and the normalized latent parameters are interpreted as the Bernoulli distribution
parameter 必：
必，P(Wi = 1) = S(hi), Wi ∈ {0, 1},	(4)
where S : R → (0, 1) is the sigmoid function. In the forward pass, instead of using the binary vector
w, its expected value,
westo-bnn，E[w] = -1×[1-S(h)] +1×S(h) =2S(h) - 1,	(5)
will participate in the actual convolution or matrix multiplication operations. In other words, the
neural network function becomes y = g(Wsto-bnn, x). Likewise, Gong et al. (2019) normalized
the latent weight but interpreted it from a different viewpoint. They approximated the staircase
quantization function with a differentiable soft quantization (DSQ) function, i.e.,
we dsq ， tanh(ah),	(6)
where tanh : R → (-1, 1) is the hyperbolic tangent function, and a controls the shape of the
function. The neural network function thus becomes y = g(Wdsq, x).
We now summarize the latent-weight-based BNN training methods and depict an example of a
single-layer network in Figure 1. First, a real-valued vector h ∈ Rd is introduced and its range is
restricted using a differentiable and invertible normalization function 夕：R → (-1,1). The forward
pass is then calculated with the normalized weight vector we . The procedure is described as：
y = g(W, x),	W，φ(h).
(7)
Second, in the back propagation, the latent weight vector h is updated with its gradient, i.e.,
h(t+1) = h(t) - ηVh'. Finally, the normalized weight vector W are mapped to the discrete space
to approximate W via thresholding or stochastic rounding.
3
Under review as a conference paper at ICLR 2022
Figure 1: Example of a single-layer quantized
neural network with a latent weight vector h ∈
Rd. h is normalized to generate we ∈ (-1, 1)d,
and the output is y = σ (W>x). A binary
weight wq can be obtained by thresholding or
rounding We to the discrete space D2d .
③
server calculates the
voting statistics
// sends quantized ∣
weight w(k,τ)
D□
-1 +1
receives the
S soft vote results
local updates ——	mth
that yields W(k,τ)I Dml ∣~r~∣ WOrker	∣	∣
Figure 2: One round of FedVote is composed of
four steps. Each worker first updates the local
(k,τ)
model and then sends the quantized weight Wm ,
to the server. Later, the server calculates the vot-
ing statistics and sends back the soft voting results
p(k+1) to each worker.
②
I④
4 Proposed FedVote Algorithm
In this section, we present our proposed method with an emphasis on uplink communication effi-
ciency and enhanced Byzantine resilience. We follow the widely adopted analysis framework in
wireless communication to investigate only the worker uplink overhead, assuming that the downlink
bandwidth is much larger and the server will have enough transmission power (Tran et al., 2019). To
reduce the message size per round, we train a quantized neural network under the federated learning
framework. The goal is to find a quantized weight vector w* that minimizes the global objective
function f formulated in (2), i.e.,
W* = argmin f (W).	(8)
w∈Ddn
For the simplicity of presentation, we mainly focus on the BNN case with D2 = {-1, 1}. We
illustrate the procedure in Figure 2 and provide the pseudo code in Appendix B. Below, we explain
each step in more detail.
4.1	Local Model Training and Transmission
We optimize a neural network with a learnable latent weight vector h. In the kth communication
round, we assume all workers are identically initialized by the server, namely, ∀ m ∈ {1, . . . , M},
h(mk,0) = h(k) . To reduce the total number of communication rounds, we first let each worker
conduct local updates to learn the binary weights. For each local iteration step, the local latent
weight vector h(k,t+1) is updated by the gradient descent:
h(kt+1) = h产一η Vh fm G(hT)); ξkt) , t ∈{0,...,τ - 1},	⑼
where ξm(k,t) is a mini-batch randomly drawn from Dm at the tth iteration of round k. After updating
for τ steps, we obtain h(mk,τ) and the corresponding normalized weight vector We m(k,τ) ∈ (-1, 1)d
defined as follows:
w (k,τ t，夕(hk,T t).	(10)
To reduce the message size, we use the stochastic rounding to draw a randomly quantized version
wm(k,τt using wem(k,τt, namely,
W(k,τt = ( +1, withProbability πt? = 1 Iwemk,τt + 1],
m,i -1, with probability 1 - πm(k,,iτt.
(11)
It can be shown that the stochastic rounding is an unbiased procedure, i.e., E[wm(k,τt wem(k,τt] =
(k,τt	(k,τt
we m , . After quantization, the local worker will send the binary weights wm , to the server for the
global model aggregation.
4
Under review as a conference paper at ICLR 2022
4.2	Global Model Aggregation and Broadcast
Once the server gathers the binary weights from all workers, it will perform the aggregation via
plurality vote, i.e., w(k+1) = sign PmM=1 w(mk,τ) . A tie in vote will be broken randomly. In
the following lemma, we show that the probability of error reduces exponentially as the number of
workers increases. The proof can be found in Appendix D.1.
Lemma 1 (One-Shot FedVote) Let w* ∈ Dd be the optimal solution defined in (8). For the mth
worker, εm,i，P(w(k,T) = w*) denotes the error probability of the voting result of the i th coordi-
nate. Suppose the error events {wm(k,,iτ) 6= wi*}mM=1 are mutually independent, and the mean error
probability Si =吉 PMM=I εm,i is SmaIIer than 11. For the voted weight w(k+1), we have
P (w(k+1) = Wi) 6 [2si exp(1 - 2si)] MM.	(12)
In practice, the number of available workers may be limited in each round, and the local data distri-
bution is often heterogenous or even time-variant. Therefore, it is almost always desirable to execute
FedVote in a multiple-round fashion. In this case, we first use the soft voting to build an empirical
distribution of global weight w, i.e.,
M
P(w(k+1) = 1) = M Xl (Wm,T) = l) ,	(13)
m=1
where 1 (∙) ∈ {0, 1} is the indicator function. Let pik+1) ，P(w(k+1) = 1) and p(k+1) =
[p(1k+1), . . . ,p(dk+1)]>. The global latent parameters can be constructed by following (10):
h(k+1)=夕-1(2p(k+1) - 1),	(14)
where 夕-1 : (-1,1) → R is the inverse of the normalization function 夕. We further apply clip-
ping to restrict the range of the probability, namely, clip(pi(k+1)) = max(pmin, min(pmax,pi(k+1))),
where pmin, pmax ∈ (0, 1) are predefined thresholds. To keep the notation consistent, we denote
W(k+1),夕(h(k+1)) as the global normalized weight. After broadcasting the soft voting results
p(k+1), all workers are synchronized with the same latent weight h(k+1) and normalized weight
we (k+1). The learning procedure will repeat until a termination condition is satisfied. We relate
FedVote to FedAvg in the following lemma. The detailed proof can be found in Appendix D.2.
Lemma 2 (Relationship with FedAvg) For the normalized weights, FedVote recovers FedAvg in
expectation: E [W(k+1)] = M P WM,τ), where W(k+1) = ^(h(k+1)) and W(k,τ) =夕(hk,T)).
m=1
4.3	Reputation-Based Byzantine-FedVote
Lemma 2 shows that FedVote is related to FedAvg in expectation. As we have reviewed in Section
2, FedAvg cannot tolerate a single Byzantine attacker. It indicates that FedVote will exhibit similar
poor performance in the presence of multiple adversaries (see Appendix C.2). We improve the
design of FedVote based on a reputation voting mechanism, which in essence is a variant of the
weighted soft voting method.
Reputation-based voting was presented in failure-robust large scale grids (Bendahmane et al., 2014).
In our design, We modify (13) to P(w(k+1) = 1) = PM=I λM)l (w(k,τ) = 1), where λM) is
proportional to a credibility score. In Byzantine-resilient FedVote (Byzantine-FedVote), we assume
that at least 50% of the workers behave normally and treat the plurality vote result as the correct
decision. The credibility score of the mth worker is calculated by counting the number of correct
votes it makes: CRM+1) = d Pd=I 1 (w(k'T) = w(k+1)). Through multiple rounds, We track
the credibility of a local worker by taking an exponential moving average over the communication
rounds, namely, νm(k+1) = β νm(k) + (1 - β) CR(mk+1), where β ∈ (0, 1) is a predefined coefficient.
The weight λ(mk) is designed as λ(mk) = νm(k)/ PmM=1 νm(k).
5
Under review as a conference paper at ICLR 2022
Even though the presentation in this section focuses on the binary weights, the scheme can be nat-
urally extended to quantized neural networks of more discrete levels. We will briefly discuss the
implementation for ternary weights in Section 6.
5 Analysis of Algorithm
In this section, we present the theoretical analysis of FedVote when local data are independent
and identically distributed (i.i.d.). The empirical results in the non-i.i.d. setting will be discussed
in Section 6, and the corresponding analyses are left for future work. We use the gradient norm
expectation as an indicator of convergence, which is commonly adopted in nonconvex optimization
literature (Reisizadeh et al., 2020; Haddadpour et al., 2021). To simplify the notation, we first
denote the stochastic local gradient by gm,t)，Vhfm (夕(hm,t)); £*"'). The local true gradient and
global true gradient will be denoted by gmk,tt，Eξ [gmk,t)], g⑹，Vhf (^(h(k))), respectively. In
addition, let ζ(mk) , we(mk,τ) - wm(k,τ) denote the error introduced by stochastic rounding. According
to the unbiased property of stochastic rounding, we have Eπ[ζ(mk)] = 0. With the aforementioned
notations, we state five assumptions for the convergence analysis.
5.1	Assumptions
Assumption 1 (Lower bound) ∀ h ∈ Rd, we ∈ (-1, 1)d, the objective function is lower bounded
by a constant f *, i.e., f (W) > f * = minh∈Rd f 3(h)).
Assumption 2 (L-smoothness) ∀ we1, we2 ∈ (-1, 1)d, m ∈ {1, . . . , M}, there exists some non-
negative L such that kVfm(we1) - Vfm (we 2)k2 6 L kwe1 - we2k2.
Assumptions 1 to 2 are common for necessary analyses (Wang & Joshi, 2018). We limit the range
of the normalized weight we while in a typical setting there is no restriction to the model weight.
Assumption 3 The normalization function 夕：R → ( — 1,1) is strictly increasing. In particular,
we assume its first derivative is bounded for all hmt, i.e., dh ^(hmk,t)) ∈ [ci, c2], where ci, c2 are
positive parameters independent of k, t, m, and i.
Assumption 3 is not difficult to satisfy in practice. For example, let 4(h) = tanh(ah), We have
夕0(h) = a [1 — tanh2(ah)], with c2 = a. Note that φ quickly saturates with a large h in the local
updating. On the other hand, the empirical Bernoulli parameter pi will be clipped for stability,
which indicates that h(mk,,it) will be upper bounded by certain hB. In this sense, we have ci =
a 1 — tanh2 (ahB) . The next two assumptions bound the variance of the stochastic gradient and
quantization noise.
Assumption 4 The stochastic gradient has bounded variance, i.e., Eg(mk,t)—gmk,t)∣∣2 6 σ2, where
σε2 is a fixed variance independent of k, t and m.
Assumption 5 The quantization error ζ (mk) has bounded variance, i.e., E∣∣ζ(mk) ∣∣22 6 σk2, where σk2
is a fixed variance independent of m.
Note that quantization error is affected by the quantizer type and the corresponding input. For
example, if the normalization function 夕 approximates the sign function very well, the stochastic
quantization error will be close to zero. Formally, the upper bound σζ2 can be viewed as a function
of input dimension d, which we formulate in the following lemma. The proof is in Appendix D.3.
Lemma 3 Suppose we have an input a ∈ (—1, 1)d for the quantizer Qsr defined in (11), then the
quantization error
satisfies E ∣∣Qsr(a) —
a∣∣22a
d — ∣∣a∣∣22.
For existing algorithms quantizing the model update δ(mk) , θ(k) — θ(mk,τ), the quantizer has the
property E ∣∣Q(x) — x∣∣22x
6 q∣∣x∣∣22. With a fixed quantization step, q increases when the input
dimension d increases (Basu et al., 2020). We state the result for a widely-used quantizer, QSGD
(Alistarh et al., 2017), which has been adopted in FedPAQ, in the following lemma.
Lemma 4 Suppose we have an input x ∈ Rd for the QSGD quantizer Q. In the coarse quantization
scenario, the quantization error satisfies E
[∣∣Q(X)-x∣2Ix= o(d 2) ∣∣x∣∣2.
6
Under review as a conference paper at ICLR 2022
5.2	Convergence Analysis
We state the convergence results in the following theorem. The proof can be found in Appendix D.5.
Theorem 1 ForFedVote underAssumptions 1 to 5, let the learning rate η = O ((C1 )2 lt√^ ) ,then
after K rounds of communication, we have
K-1
K X ciEWf(w"12 6
k=0
2 f(W⑼)-f(W*)]
L
十 ητKM
ητK
K-1
X σk2 +
k=0
2	1	c12Lη(τ - 1)
+ c2Lη M + ɪɪ^
τMK
K-1 M
X X R(mk).
k=0 m=1
σε2
(15)
where R(mk) , - P
t=0
P Ek▽/(W(k)))i(W(Wmk,t)))i] andZmM，｛i | 或或?
i∈ιmk,t)
>0.
Remark 1 When there is no normalization function and quantization, i.e.,夕(x) = X with ci
c2 = 1, σk2 = 0, Theorem 1 recovers the result obtained in Wang & Joshi (2018).
ie5
1.4
1.2
首1.0
ðo.e
0.β
0.4
0.2
0
(a)
Figure 3: Histograms of (a) model updates δm(k,)i
and (b) binary weight probabilities πm(k,,iτ). We
trained a LeNet on MNIST for a single commu-
nication round.
2.
5
；15
1.0
0.5
0.0
铲。
(b)
To discuss the impact of quantization error, con-
sider the distribution of different inputs. For the
model update δ(mk), we expect the central limit
theorem to render its distribution shape, where
each entry δm(k,)i follows the Gaussian distribu-
tion. For the Bernoulli probability π(mk,τ), we ex-
pect the Beta distribution as the conjugate prior
to render its distribution shape, where each entry
πm(k,,iτ) follows the symmetric Beta distribution.
See Figure 3 for the empirical results.
Remark 2 Following the analysis framework in Theorem 1, the order-wise convergence rate is
K^ PK=-01 E Il Vf (w(k)) ∣∣2 = O( √=) + E (d), where E(d) is the error introduced by the quantiza-
tion. For FedVote with the normalized weight We(mk,τ) as the input, when πm(k,,iτ) ’s follow the symmetric
Beta distribution, it can be shown that Ekζ (mk) k22 = O (d) based on Lemma 3. For algorithms such
as FedPAQ with the model update δ(mk) as the input, when δm(k,)i ’s follow the Gaussian distribution, it
can be shown that E∣∣Q(δmk)) 一 6年 ∣∣2 = O (d3/2) based on Lemma 4. When the weight dimension
d is sufficiently large, FedVote converges faster.
Remark 3 The value of the positive scalar error term Rm(k) in (15) depends on the gradient dissim-
ilarity. If the angle between the local gradient Vfm (We m(k,t)) and the global gradient Vf (We (k,t)) is
not large, R(mk) can be treated as a bounded variable.
Remark 4 The choice of nonlinear function 夕：Rd → (一1,1)d will affect the convergence. If 夕
behaves more like the sign(∙) function, e.g., when a increases in tanh(ax), the quantization error
will be reduced. In other words, we expect a smaller σk2 according to Lemma 3, which leads to a
tighter bound in (15). Meanwhile, a larger c will negatively influence the convergence.
6 Experimental Results
Data and Models. We choose image classification datasets Fashion-MNIST (Xiao et al., 2017)
and CIFAR-10 (Krizhevsky, 2009). Both of them have a total of C = 10 classes. We consider two
data partition strategies: (i) i.i.d. setting where the whole dataset is randomly shuffled and assigned
to each worker without overlap; (ii) non-i.i.d. setting where we follow Hsu et al. (2019) and use the
Dirichlet distribution to simulate the heterogeneity. In particular, for the mth worker we draw a ran-
dom vector qm 〜Dir(α), where qm = [qm,ι,…,qm,c]> belongs to the standard (C一 1)-simplex.
We then assign data samples from different classes to the mth worker following the distribution of
7
Under review as a conference paper at ICLR 2022
_ ____
Xrnun 8 < EI
0.5-
0	20	40 . . 60 BO
Communicatkn Round
(a)
0.5-
100
(b)
°-7°-6
(c)

Figure 4: Learning curves of different methods on CIFAR-10 with (a) the i.i.d. setting and (b) the
Dirichlet non-i.i.d. setting. Compared with the gradient quantization methods such as signSGD
(Bernstein et al., 2018) and the model update quantization methods such as FedPAQ (Reisizadeh
et al., 2020), FedVote achieves higher accuracy given the same number of communication rounds.
(c) Test accuracy versus accumulative uplink communication cost on the i.i.d. CIFAR dataset. Fed-
Vote achieves the best accuracy given the transmitted data size.
Table 1: Test Accuracy in the Byzantine Setting
Dataset	Distri- bution	sign- SGD	Co- Med	Pro- posed
Fashion-	i.i.d.	61.5%	77.7%	91.4%
MNIST	non-i.i.d	61.0%	73.4%	89.4%
CIFAR-	i.i.d.	13.5%	29.3%	76.6%
10	non-i.i.d	11.0%	28.7%	72.0%
Table 2: Effect of the Normalization Function
Fashion- MNIST	a			
	0.5	1.5	2.5	10
float i.i.d. binary	90.7%	90.6%	90.0%	88.2%
	88.7%	90.4%	89.9%	88.2%
non- float	87.3%	86.9%	85.7%	85.0%
i.i.d. binary 83.3%		85.5%	85.2%	84.6%
qm. We set α = 0.5 unless noted otherwise. We use a LeNet-5 architecture for Fashion-MNIST
and a VGG-7 architecture for CIFAR-10. Results are obtained over three repetitions.
Implementation Details. We provide implementation details in the proposed FedVote design.
First, following prior works (Shayer et al., 2018; Gong et al., 2019), we keep the weights of the
BNN final layer as floating-point values for the sake of the model performance. The weights of
the final layer are randomly initialized with a shared seed and will be fixed during the training
process. Second, we notice that for quantized neural networks, the batch normalization (BN) (Ioffe
& Szegedy, 2015) after the convolutional layer is necessary to scale the activation. We use the
static BN without learnable parameters and local statistics (Diao et al., 2021) to ensure the voting
aggregation of binary weights. For the normalization function, We choose 夕(x) = tanh(3x∕2)
unless noted otherwise. More details of the experimental setup can be found in Appendix C.1.
Communication Efficiency and Convergence Rate. In this experiment, we consider M = 31
workers with full participation and compare FedVote to different methods within N = 100 com-
munication rounds. The results of partial participation can be found in Appendix C.3. The com-
munication cost is calculated as the accumulative uplink message size from all workers. Figure 4
reveals that FedVote outperforms the gradient-quantization-based methods such as signSGD (Bern-
stein et al., 2018) that quantizes gradients to 1 bit signs, and FedPAQ (Reisizadeh et al., 2020) that
quantizes the updates to 2 bits integers. Compared with FedPAQ, signSGD, and FedAvg, FedVote
improves the test accuracy by 5-10%, 15-20%, and 25-30%, respectively, given the fixed commu-
nication costs of 1.5/.7 GB.
Byzantine Resilience. This experiment validates the effectiveness of Byzantine-FedVote. We
consider omniscient attackers who can access the datasets of normal workers and send the opposite
of the aggregated results to the server. The number of attackers is 15, and the remaining 16 clients are
normal workers. We compare the proposed method with coordinate-wise median based (CoMed)
gradient descent (Yin et al., 2018) and signSGD (Bernstein et al., 2018), and report the testing
accuracy after 100 communication rounds. We do not compare with FedAvg and FedPAQ, as they
are fragile to Byzantine failure. The results are shown in Table 1. It can be observed that Byzantine-
FedVote exhibits much better resilience to Byzantine attacks with close to half adversaries.
8
Under review as a conference paper at ICLR 2022
Table 3: Test Accuracy of TNN and BNN	Table 4: Forward Pass Efficiency
D ∙	∙ Distri-	BNN TNN ataset bution	Neural Weight Adds Muls Energy Net	Type	(mJ)
Fashion- i.i.d.	91.1%	91.9% MNIST	non-i.i.d	88.3%	89.4%	τ z∙u float	1.7×109 1.8×109 8.1 LeNet5 binary 1.7 × 109 1.0 × 10* 1 * * * 5 * 7 1.5
CIFAR- i.i.d.	80.5%	82.5% 10	non-i.i.d	74.6%	77.6%	「r float	4.8×1010 5.4×1010 242.9 VGG-7 binary	4.8×1010 2.1×105 43.3
Normalization Function. From Remark 4, we know that the normalization function can influence
the model convergence. We empirically examine the impact in this experiment. For normalization
function 夕(x) = tanh(ax), We choose a from {0.5,1.5, 2.5,10}. We test the model accuracy after
20 communication rounds on Fashion-MNIST. The results are shown in Table 2. As a increases,
the linear region of the normalization function shrinks, and the algorithm converges sloWer due
to a larger c2 . On the other hand, the gap betWeen the model With normalized Weight we and the
one With binary Weight w also decreases due to smaller quantization errors. A good choice of the
normalization function should take this trade-off into consideration.
Ternary Neural Network Extension. In the previous sections, We focus on the BNNs. We ex-
tend FedVote to ternary neural netWorks (TNNs) and empirically verify its performance. Training
and transmitting the categorical distribution parameters of the ternary Weight may bring additional
communication and computation cost to edge devices, We therefore simplify the procedure as fol-
loWs. For each ternary Weight wm(k,,it), We still keep a latent parameter h(mk,,it) to optimize. After τ
local steps, we use the stochastic rounding to the normalized weight Wm,τ) =夕(hm,T)) and obtain
quantized Weight wm(k,τ). At the aggregation stage on the server, instead of calculating the vote dis-
tribution, we directly compute the global normalized weight as we (k+1) =MM PM=I w(k,τ) . More
details can be found in Appendix C.4. The training results are shown in Table 3. As TNNs can fur-
ther reduce the quantization error, their performance is better than the BNNs at the cost of additional
1 bit/dimension communication overhead.
Deployment Efficiency. We highlight the advantages of BNNs during deployment on edge de-
vices. In FedVote, we intend to deploy lightweight quantized neural networks on the workers after
the training procedure. BNNs require 32 × smaller memory size, which can save storage and en-
ergy consumption for memory access (Hubara et al., 2016). As we do not quantize the activations,
the advantage of BNNs inference mainly lies in the replacement of multiplications by summations.
Consider the matrix multiplication in a neural network with an input x ∈ Rd1 and output y ∈ Rd2 :
y = W>x. For a floating-point weight matrix W ∈ Rd1×d2, the number of multiplications is d1d2,
whereas for a binary matrix Wb ∈ D2d1×d2 all multiplication operations can be replaced by additions.
We investigate the number of real multiplications and additions in the forward pass of different mod-
els and present the results in Table 4. We use the CIFAR-10 dataset and set the batch size to 100. As
to the energy consumption calculation, we use 3.7 pJ and 0.9 pJ as in Hubara et al. (2016) for each
floating-point multiplication and addition, respectively.
7 Conclusion
In this work, we have proposed FedVote to jointly optimize communication overhead, learning re-
liability, and deployment efficiency. In FedVote, the server aggregates neural networks with bi-
nary/ternary weights via voting. We have verified that FedVote can achieve good model accuracy
even in coarse quantization settings. Compared with gradient quantization, model quantization is a
more effective design that achieves better trade-offs between communication efficiency and model
accuracy. With the voting-based aggregation mechanism, FedVote enjoys the flexibility to incorpo-
rate various voting protocols to increase the resilience against Byzantine attacks. We have demon-
strated that Byzantine-FedVote exhibits much better Byzantine resilience in the presence of close to
half attackers compared to the existing algorithms.
9
Under review as a conference paper at ICLR 2022
References
Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. QSGD:
Communication-efficient SGD via gradient quantization and encoding. In Advances in Neural
Information Processing Systems,pp. 1709-1720, 2017.
Debraj Basu, Deepesh Data, Can Karakus, and Suhas N Diggavi. Qsparse-local-sgd: Distributed
sgd with quantization, sparsification, and local computations. IEEE Journal on Selected Areas in
Information Theory, 1(1):217-226, 2020.
Ahmed Bendahmane, Mohamed Essaaidi, Ahmed El Moussaoui, and Ali Younes. The effectiveness
of reputation-based voting for collusion tolerance in large-scale grids. IEEE Transactions on
Dependable and Secure Computing, 12(6):665-674, 2014.
Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, and Animashree Anandkumar.
signSGD: Compressed optimisation for non-convex problems. In International Conference on
Machine Learning, 2018.
Peva Blanchard, Rachid Guerraoui, Julien Stainer, et al. Machine learning with adversaries: Byzan-
tine tolerant gradient descent. In Advances in Neural Information Processing Systems, 2017.
Xiangyi Chen, Tiancong Chen, Haoran Sun, Steven Z. Wu, and Mingyi Hong. Distributed training
with heterogeneous data: Bridging median- and mean-based algorithms. In Neural Information
Processing Systems, 2020.
Enmao Diao, Jie Ding, and Vahid Tarokh. Heterofl: Computation and communication efficient
federated learning for heterogeneous clients. In International Conference on Learning Represen-
tations, 2021.
Ruihao Gong, Xianglong Liu, Shenghu Jiang, Tianxiang Li, Peng Hu, Jiazhen Lin, Fengwei Yu, and
Junjie Yan. Differentiable soft quantization: Bridging full-precision and low-bit neural networks.
In International Conference on Computer Vision, 2019.
Rafael C. Gonzalez and Richard E. Woods. Digital Image Processing 3rd Edition. 2014.
Farzin Haddadpour, Mohammad Mahdi Kamani, Aryan Mokhtari, and Mehrdad Mahdavi. Feder-
ated learning with compression: Unified analysis and sharp guarantees. In International Confer-
ence on Artificial Intelligence and Statistics, 2021.
Lu Hou, Ruiliang Zhang, and James T Kwok. Analysis of quantized models. In International
Conference on Learning Representations, 2019.
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical data
distribution for federated visual classification. arXiv preprint arXiv:1909.06335, 2019.
Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized
neural networks. In Advances in Neural Information Processing Systems, 2016.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
Richeng Jin, Yufan Huang, Xiaofan He, Huaiyu Dai, and Tianfu Wu. Stochastic-sign sgd for feder-
ated learning with theoretical guarantees. arXiv preprint arXiv:2002.10940, 2020.
Peter Kairouz, H Brendan McMahan, Brendan Avent, AUrelien BelleL Mehdi Bennis, Arjun Nitin
Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances
and open problems in federated learning. Foundations and Trends in Machine Learning, 14(1),
2021.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Master thesis, Dept. of
Comput. Sci., Univ. of Toronto, Toronto, Canada, 2009.
Shuai Li, Ce Zhu, Yanbo Gao, Yimin Zhou, Frederic Dufaux, and Ming-Ting Sun. Lagrangian multi-
plier adaptation for rate-distortion optimization with inter-frame dependency. IEEE Transactions
on Circuits and Systems for Video Technology, 26(1):117-129, 2015.
10
Under review as a conference paper at ICLR 2022
Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin Jaggi. Ensemble distillation for robust model
fusion in federated learning. Advances in Neural Information Processing Systems, 2020.
H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In International
Conference on Artificial Intelligence and Statistics, pp.1273-1282, 2017.
LUis Munoz-Gonzalez, Kenneth T Co, and Emil C Lupu. Byzantine-robust federated machine learn-
ing through adaptive model averaging. arXiv preprint arXiv:1909.05125, 2019.
Haotong Qin, Ruihao Gong, Xianglong Liu, Xiao Bai, Jingkuan Song, and Nicu Sebe. Binary neural
networks: A survey. Pattern Recognition, pp. 107281, 2020a.
Qiaofeng Qin, Konstantinos Poularakis, Kin K Leung, and Leandros Tassiulas. Line-speed and scal-
able intrusion detection at the network edge via federated learning. In International Federation
for Information Processing Networking Conference, 2020b.
Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and Ramtin Pedarsani.
FedPAQ: A communication-efficient federated learning method with periodic averaging and quan-
tization. In International Conference on Artificial Intelligence and Statistics, 2020.
Mher Safaryan and Peter Richtarik. Stochastic sign descent methods: New algorithms and better
theory. In International Conference on Machine Learning, 2021.
Felix Sattler, Klaus-Robert Muller, Thomas Wiegand, and Wojciech Samek. On the byzantine ro-
bustness of clustered federated learning. In International Conference on Acoustics, Speech and
Signal Processing, 2020.
Oran Shayer, Dan Levi, and Ethan Fetaya. Learning discrete weights using the local reparameteri-
zation trick. In International Conference on Learning Representations, 2018.
Nguyen H Tran, Wei Bao, Albert Zomaya, Minh NH Nguyen, and Choong Seon Hong. Feder-
ated learning over wireless networks: Optimization model design and analysis. In International
Conference on Computer Communications, 2019.
Jianyu Wang and Gauri Joshi. Cooperative SGD: A unified framework for the design and analysis
of communication-efficient SGD algorithms. arXiv preprint arXiv:1808.07576, 2018.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmark-
ing machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.
Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Byzantine-robust distributed
learning: Towards optimal statistical rates. In International Conference on Machine Learning,
2018.
Zhi-Hua Zhou. Ensemble methods: foundations and algorithms. Chapman and Hall/CRC, 2019.
11
Under review as a conference paper at ICLR 2022
A Voting Methods
We review the definitions of several voting methods (Zhou, 2019). Suppose we have a set of M
individual voters and C candidate output labels {ψ1 , . . . , ψC}. For the mth voter, it will output
result vm = [vm,1, . . . , vm,C]>. Here, the ith entry vm,i ∈ {0, 1}, which takes the value one if the
voter chooses the candidate ψi and zero otherwise.
Majority vote requires the winner to receive more than half of the votes; if none of the candidates
receives more than half of the votes, a rejection option will be given. The majority vote result can
be written as
{M	ι C M
ψi, if Xvm,i > 2XXvm,j,	(16)
m=1	j=1 m=1
rejection, otherwise.
Plurality vote takes the class label that receives the largest number of votes as the final winner, i.e.,
Ψplurality = ψargmax PmM=1 vm,i .	(17)
i
In the binary case with C = 2, plurality vote resembles majority vote except that it does not have a
rejection option. If more than two candidates receive the same number of votes, we randomly select
one of them as the final results. Weighted vote assigns different weights for voters and the result can
be written as
Ψweighted = ψargmax PmM=1 λmvm,i,	(18)
i
where λm is the weight assigned to the mth voter. In contrast to the aforementioned vote methods,
soft vote produces the probability output. The probability that the ith candidate wins is calculated as
1M
P(Wsoft = ψi) = ME vm,i.	(19)
m=1
B FedVote ALgorithm
We summarize the proposed FedVote method and its Byzantine-resilient variant in Algorithm 1.
When there are no attackers involved, we use Option I. When we require the resilience against
Byzantine failure, we choose Option II.
C Setup and Additional Experiments
C.1 Hyperparameters
For the clipping thresholds, we set pmin = 0.001 and pmax = 1 -pmin. The thresholds are introduced
for numerical stability and have little impact on performance. We use β = 0.5 in Byzantine-FedVote.
The choice of the smoothing factor β has little impact on the final test accuracy, as the credibility
score decays exponentially for adversaries over multiple communication rounds. We use the Adam
optimizer and search using the learning rate η over the set {10-4, 3×10-4, 10-3, 3×10-3, 10-2, 3×
10-2, 10-1, 3 × 10-1}. We set the number of local iterations τ to 40 and the local batch size to 100.
C.2 Comparison of Vanilla FedVote and Byzantine-FedVote
Lemma 2 shows that FedVote is related to FedAvg in expectation. Adversaries sending the opposite
results will negatively affect the estimation of the weight distribution and impede the convergence
in multiple rounds. We compare the test accuracy of Byzantine-FedVote, Vanilla FedVote, and
signSGD on the non-i.i.d. CIFAR-10 dataset (α = 0.5) with various numbers of omniscient attack-
ers. Figure 6 reveals that the test accuracy of Vanilla FedVote drops severely when the number of
adversaries increases, which is consistent with our analysis. In contrast, the drop of accuracy in
Byzantine-FedVote is negligible, confirming its resilience to omniscient attackers.
12
Under review as a conference paper at ICLR 2022
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Algorithm 1: Binary-Weight FedVote with/without Byzantine Tolerance
initialize p(0) and broadcast
for k = 0, 1, . . . , N - 1 do
on mth worker:
receive p(k) from the server
initialize latent weight hm,0) =夕-1(2p⑹一1)
for t = 0 : τ - 1 do
gm,t)=Vhfmw同㈤)；ξm,r))
h(k,t+I) = h(k,t) _ n(k,t) G(k,t)
m = m - η gm
We mk,τ) =P(h(k，T))
WmK) = sto_rounding(W (k,τ))	. Eq. (11)
send wm(k,τ) to server
on server:
{w(k+1), p(k+1)} = vote({wmm,τ )}M=ι)
broadcast p(k+1) to workers
function vote({w(mk,τ)}mM=1)
for i = 1 : d do
(k+1)	(k,τ)
wi = sign wm,i
m=1
Γ-----------------------------
!p(fc+1) = M PI (Wm,τ) = 1)	. OptiOnI
m=1
p(k+1) = p λmrn)ι (Wm,τ) = 1). OptiOn II
m=1
return {w(k+1), p(k+1)} to the server
0.2
7∙63 4 3
Ooooo
x3BJn8<0I
0.1
6	20	40	60	80
Communication Round
100
Figure 5: Test accuracy versus communication
round of different methods on the non-i.i.d. CI-
FAR dataset (α = 0.5). We use 100 workers
and sample 20 of them in each round.
0.45
6
0.50
1	2
Number OfByzantme Wbrfcrs
3
Figure 6: Test accuracy versus the number of
Byzantine workers. As the number of adver-
saries increases, the test accuracy of FedVote
drops rapidly.
C.3 Convergence of FedVote with Partial Participation
We increase the number of workers to 100 and sample 20 of them in each communication round.
We compare FedVote with FedAvg McMahan et al. (2017), FedPAQ (Reisizadeh et al., 2020), and
signSGD (Bernstein et al., 2018) in Figure 5 on the non-i.i.d. CIFAR-10 dataset (α = 0.5) without
changing other experimental setups. The observation is consistent with the results in Figure 4.
FedVote outperforms gradient quantization methods such as FedPAQ and signSGD.
13
Under review as a conference paper at ICLR 2022
C.4 Extension to Ternary Neural Networks
The stochastic rounding used in the ternary neural networks, wi = Qsr (we), is an extension of (11):
{+1, with probability ∏ι = Wi I(Wi > 0),
-1, with probability 不2 = -Wi I(Wi < 0),
0,	with probability 1 - (π1 + π2 ).
(20)
One can modify the normalization function to optimize neural networks with multiple quantization
levels. For example, consider quaternary weight Wi ∈ {-2, -1, 1, 2}, the normalization function
夕(x) can be modified to 夕(x) = 2 tanh(ax).
C.5 Batch Normalization in FedVote
Below we review the commonly-adopted BN function for convenience of presentation. For a one-
dimensional input x(j) from the current batch B = {x(1),…,x(nb)}, the output of BN layer is
formulated as
y, BNγ,b(Xj))=Y √σ⅛+b,
(21)
where γ,b are learnable affine transformation parameters, and μ,σ2 are the mean and variance
calculated over the batch samples. Note that the normal BN layer will introduce the real-valued pa-
rameters and track the statistics of the input, all of which may cause problems when being binarized
in FedVote. Therefore, we choose to set the parameter-free static BN, i.e.,
y0 , BN(x(j))
X — EB [x(j)]
√VarB [x(j) ] + e
(22)
D Missing Proofs
D.1 Proof of Lemma 1
Lemma 1 (One-Shot FedVote) Let w* ∈ Dd be the optimal solution defined in (8). For the mth
worker, εm,i，P(WmkT) = w*) denotes the error probability of the voting result of the i Ih coordi-
nate. Suppose the error events {Wm(k,,iτ) 6= Wi*}mM=1 are mutually independent, and the mean error
probability Si = 吉 PM=I ɛm,i is smaller than 1/2. For the voted weight w(k+1), we have
P(W(k+1) = Wi) 6 [2si exp(1 - 2si)] MM.	(23)
Proof. Let Xm,i，1 (Wm,? = w*), following Bernoulli distribution with parameter εm,i. Let
Yi = PmM=1 Xm,i, we have
P(W(k+1) = Wi)= P(Yi > M) .	(24)
14
Under review as a conference paper at ICLR 2022
With independent vote results from workers, Yi follows Poisson binomial distribution with mean
μYi = PM=I εm,i. ∀ a > 0, the Chernoff bound can be derived as
②
6
P(Yi >M
=P(eaM > eaM)
①
6
exp
- εm,i + e εm,i)
exp
M
+ X ln (1 + εm,i(ea
m=1
- 1))
exp
M
+	εm,i(ea
m=1
- 1)
(25a)
(25b)
(25c)
(25d)
(25e)
(25f)
where ① is based on Markov’s inequality.② holds due to ln(1+ x) 6 X for all X ∈ (-1, ∞).
By assumption We have μ居 < M. Let a = ln ^Mr, We have
Let Si = μM = MM PM=I εm,i and substitute it into (26b), the proof is complete.
(26a)
(26b)
□
D.2 Proof of Lemma 2
Lemma 2 (Relationship with FedAvg) For the normalized weights, FedVote recovers FedAvg in
expectation: E [W(k+1)] = MM P Wm,τ), where W(k+1) = ^(h(k+1)) and W(k,τ) =夕(hm,τ)).
m=1
Proof. From the inverse normalization in (14), We have We (k+1) = 2p(k+1) - 1. Recall the definition
of the empirical Bernoulli parameter p(k+1) given by (13), We have the elementWise expectation
M
Enhw(	i = MM X (2P(w(k,,T) = 1) - 1)	(27a)
m=1
M
=M X 奴 hm,,τ)),	(27b)
m=1
where ① follows from stochastic rounding defined in (11). Based on the definition of range normal-
ization in (10), for local normalized weight we have w(k,T) =4(鹏？). Substituting the result into
(27b) we have
M
En [w	i= MM X Wm,τ),	(28)
m=1
which completes the proof.	□
D.3 Proof of Lemma 3
Lemma 3 Suppose we have an input a ∈ (-1, 1)d for the quantizer Qsr defined in (11), then the
quantization error satisfies E Qsr(a) - a22 a =d- a22.
15
Under review as a conference paper at ICLR 2022
Proof. Let a，Qsr(a), We have
The proof is complete.
d
X(E [^2 同-a2)
i=1
d
d - kak22 .
(29a)
(29b)
(29c)
(29d)
□
D.4 Proof of Lemma 4
Lemma 4 Suppose we have an input x ∈ Rd for the QSGD quantizer Q. In the coarse quantization
scenario, the quantization error satisfies E
[llQ(x) -xll2lx] = O(d2) ιιxι∣2.
Proof. Consider a QSGD quantizer (Alistarh et al., 2017) With s = 1. For detailed results of other
quantizers, We refer readers to Basu et al. (2020).
In particular, We have
	Qqsgd (Xi )	= kxk2	• Sgn (Xi) ∙ ξi(x, s),	(30)
where	ξi (x, s)Is=1 =	( 01	WithPrOb. 1 -鼎, WithProb∙网.	(31)
The variance of quantization error is				
			d	
e[iiQ(x)- χH2∣χ] = E X (Xi- Xi)2 ∣X	(32a)
i=1
i=1
d
=X(E [X2∣x] - x2)	(32b)
i=1
=kxk2Pi=IIXiI -kxk2	(32c)
kxk2
=kxk2kxkl -kxk2	(32d)
6 (√d - 1)kxk2,	(32e)
which completes the proof.	□
D.5 Proof of Theorem 1
We first introduce some notations for simplicity. Let ∆(k) denote the difference between two suc-
cessive global latent weights, i.e.,
∆(k) , we (k) - we (k+1) .	(33)
We use ε(mk,t) to denote the stochastic gradient noise, i.e.,
ε(k,t) , gm,t) - gm,t).	(34)
Finally, we let Vf (W) denote the gradient with respect to W. The following five lemmas are Pre-
sented to facilitate the proof.
16
Under review as a conference paper at ICLR 2022
Lemma 5 The global normalized weight we (k) can be reconstructed as the average of local binary
weight, i.e.,
1M
W(k+1) = M X w(k,τ).	(35)
m=1
Proof. See Appendix D.6.	口
Lemma 6 (Lipschitz continuity) Under Assumption 3, ∀ x1 , x2 ∈ R, we have
3(χι)-夕(X2)| 6 C2∣X1 - X2∣.	(36)
Proof. Without loss of generality, suppose x1 < x2 . Based on the mean value theorem, there exists
some c ∈ (x1, x2) such that
以x2)-以x1).	(37)
x2 - x1
For the monotonically increasing function 夕，We have
夕(x2)-2(xi)=夕0(c)(χ2 - xi)	(38a)
①
6 c2 (x2 - x1 ) ,	(38b)
where ① holds due to Assumption 3. The similar result can be obtained by assuming χ2 < xi,
which completes the proof.	口
Lemma 7 (Bounded weight divergence) Under Assumption 4, we have
Ewem(k,τ)-we(k)22	6	(c2η)2τ	τX-i	Eg(mk,t)22	+	σε2	.	(39)
Proof. See Appendix D.7.
□
Lemma 8 Under Assumptions 2 to 5, we have
EDVf(W(k)), ∆(t)E > TEIIVf(W(k))∣∣2
2	M τ -i
+4M (2-(c2L)2η2τ (T-1))X X E∣∣gm,t)∣∣2
(40)
(cic2L)2η3τ (τ - 1)
m=i t=0
σ - T-螳 X RM
m=i
(41)
—
4
where R(mk) , - τP-i P E h(Vf(We(k)))i(Vf(Wem(k,t)))ii and Im(k,t) , ni | gi(k)g(mk,it)
t=0 i∕ιm,t	L	j	l	,
>0.
Proof. See Appendix D.8.	口
Lemma 9 (Bounded global weight difference) Under Assumptions 2 to 5, we have
E∣wk)∣∣2 6 (CMT XX E∣∣gm,t)∣∣2+包Mτσ+M σ2.	⑹
m=i t=0
Proof. See Appendix D.9.
□
17
Under review as a conference paper at ICLR 2022
Theorem 1 For FedVote under Assumptions 1 to 5, if the learning let the learning rate η
O ((C1 )2 lt√√^ ), then after K rounds of communication, we have
K-1
K X c2EWf(w(k))∖∖2 6
k=0
2 f(W⑼)-f(W*)]
L
十 ητKM
ητK
K-1
X σk2 +
k=0
l 2L Γ 1 l c2Lη(τ - 1)
+ c2Lη M + —2—
τMK
K-1 M
X X R(mk).
k=0 m=1
σε2
(43)
where R(mk) , - P
t=0
Ft,E [(Vf(W(k)))i(Vfgt)))i] αan燎) , {5就？ > 0}.
i∈Im
Proof. Consider the difference vector ∆(k) defined in (33), we expand it as
∆(k) = we (k) - we (k+1)	(44a)
M
=W(k)- M X Wm)	(44b)
m=1
MM
=W (k) - M X W m,τ)+M X Zmr,	(44c)
m=1	m=1
where ① follows from (35), and ② holds by substituting the definition of quantization error.
From Assumption 2, we have
f (We(k+1)) - f(W6 YVf(W(k)), ∆(k)E + 2∖∖∆(k)∖∖2.
Let (Ln) T(TT) + LnT 6 A, take the expectation on both sides, and use Lemmas 8-9:
E [f(W(k+1)) - f(W(k))i 6 -c22τEWVf(W(k))∖∖2
⅛Mη (rL2η2τ (T- 1)-等)XX EWgm,t)∖∖2
2	1 m=1 t=0
(c2η)2Lτ
M + c2Lη(τ - 1)) σ2+ η(c2M CI) X Rm) + 2Mσ2
m=1
①
6-
WVf(W(k))∖∖2 + (cη2Lτ (M + c2Lη(τ - 1)) σ2
+TFn X Rm)+2Mσk
m=1
where ① follows from the restrictions on learning rate. We rewrite the restriction as
η6
LT I
-砥+
2L2τ (T — 1)
L2τ(τ - 1)
-1 + 6+^
L(T- 1)c2
C2
L(T- 1)c2 ,
(45a)
(46a)
(46b)
(47a)
(47b)
(47c)
—
+
4
T E
①
6
②
6
where in ① we use T(τ - 1) 6 T2, and ② holds due to the Bernoulli inequality (1 + x) 1 6
1 + 1 x, ∀ X ∈ [-1, ∞). Based on (47c), we set the learning rate η = O ((C1 )2 LT√κ). Summing
18
Under review as a conference paper at ICLR 2022
up over K communication rounds yields
K-1
K X c1EWf(w(肛 12 6
k=0
2 f(W⑼)-f(W*)]
L
十 ητKM
ητK
K-1
X σk2 +
k=0
2	1	c12Lη(τ - 1)
+ c2Lη M + ɪɪ^
τMK
K-1 M
XX R(mk).
k=0 m=1
D.6 Proof of Lemma 5
Proof. From the reconstruction rule (14), we have
we (k+1) = 2p(k+1) - 1.
The ith entry of p(k) is defined in (13) as:
(k+1)
pi
M
M Xι (Wm)=1).
m=1
Substituting (50) into (49) yields
(k+1)
wei
M
1 -1 .
Note that
m=1
21 (Wmk,τ)
+1, Wm(k,τ) = +1,
-1, Wm(k,τ) = -1,
M
w(k+1)=M X w(k),
m=1
we have
which completes the proof.
D.7 Proof of Lemma 7
σε2
(48a)
□
(49)
(50)
(51)
(52)
(53)
□
Proof. With the local initialization and update method described in Algorithm 1, we have
E∣∣wm,τ) - W (k)∣∣2 = E∣k(hm,τ ))-以 hm,町 ∣2
6 c2E∣∣hm,τ)
τ -1
- h(mk,0)22
2
c2E ∑-ηgm，t)
∣ t=0
2
(c2η)2E
(k,t) + ε(k,t))
m εm
t=0
(c2η)2	EτX-1g(mk,t)
t=0
6 (c2η)2τ	X Eg
t=0
2
+E
2
(mk,t)22 +
where ① comes from the LiPschitz condition in Lemma 6.
2
τ -1
X ε(mk,t)
t=0
σε2
2
2
(54a)
(54b)
(54c)
(54d)
(54e)
(54f)
□
19
Under review as a conference paper at ICLR 2022
D.8 Proof of Lemma 8
Proof. We have
EDVf(W(k)), ∆(k)E
MM
=EDVf(W(k)), W⑹-E X Wm,τ) + MM X Zm)E	(55a)
m=1	m=1
=EDVf(W(k)), W(k)- MM X Wm,τ)E	(55b)
m=1
1M
=E(Vf(W(k)), MM X W))- Ψ(hmτ))〉，	(55c)
m=1
where ① follows from Assumption 5. Based on the mean value theorem, for h(k), hm;T) ∈ R, there
exists some c(mk,)i ∈ H(mr,)i such that
H(mr,)i =
o( (k))=以 h(k))-以 hm,T))
ψ (cm,i) =	h(k) - h(k,τ),
where H(mr),i is an open interval with endpoints hi(k) and h(mk,,iT) :
(hi(k), h(mk,,iT)), if hi(k) <h(mk,,iT),
(h(mk,,iT), hi(k)), otherwise.
Let Cmk=diag (d(Cm,)1),…，”(Cm,)d)), We have
T-1
以h(k))-以hmm,τ)) = cm)(h(kk-hm，T)) = ηCm X (g(m,t) + εm,t)),
t=0
Substituting (58) into (55c) yields
M T-1
EDVf(W (k)), ∆(k)E = M X X E DVf (W (k)), Cm gm,t)E.
m=1 t=0
According to the chain rule, g(mk,t) can be written as
g(m,t) = Vhfm(φ(hmt))) = DmZw fm(W mt)),
(56)
(57)
(58)
(59)
(60)
where Dmk,t) = diag ( 忆),..., %t) ). To simplify the notations, let Bmk,t) = Cmk)Dmk,t)
dhm,,1	dhm,,d
Note that Bm(k,t) is still a diagonal matrix, where the ith diagonal element b(mk,,it) is
b(k,t) , (B(k,t∙)).. = ff__d^
m,i (m	)i,i	dcm,T) dm?
(61)
Substituting (60) into (59) we have
M T-1
E〈Vf (W(k)), △(" = M X X E Vff (We(k)), Bmeyfm(Wat))〉.	(62)
m=1 t=0
We first focus on the following inner product:
d
Vf(We(k)),Bm(k,t)Vfm(We(mk,t)) =X(Vf(We(k)))i×b(mk,,it)(Vfm(We(mk,t)))i,	(63)
i=1
20
Under review as a conference paper at ICLR 2022
where (Vf )i denotes the ith entry of the gradient vector. Consider an index set Imktt defined as
Imkit) , {i ∈{1,...,d}∣ (Vf(W(kt))i(Vfm(Wmk,t)))i > 0} .	(64)
Since the signof(Vf(we(k)))i(Vfm (we m(k,t)))i is equal to gi(k)g(mk,,it), the index set Im(k,t)can also be
written as
Im(k,t),ni∈{1,...,d} | gi(k)g(mk,,it) >0}.	(65)
The result in (63) can be bounded as
EDVf(we(k)), Bm(k,t) Vfm (wem(k,t))E	(66a)
> c2 X E h(Vf(W(kt))i(Vfm(Wmk,t)))ii + C X E h(Vf(W(k)))i(Vfm(Wmk,t)))ii
i∈ιmk,t)	i∈ιmk,t)
(66b)
=c12EDVf(We(k)),	Vfm	(We m(k,t))E	+	(c22	- c21)	X	E h(Vf (We (k)))i(Vfm	(Wem(k,t)))ii	, (66c)
i∈ιmk,t)
where ① follows from Assumption 3. To simplify the notation, let Rmk) denote the accumulative
gradient divergence, namely,
τ-1
R(mk) , -X X E (Vf(We (k)))i(Vf(Wem(k,t)))i .
t=0 i∕ιmk，t)
(67)
The expected inner product in (62) can be bounded as
E Vf (We (k)), ∆(k)
2 M τ-1	2	2 M
> cMη X XE DVf(W(k)), Vfm(Wm,t))E - η(c2M c1) X Rm)	(68a)
m=1 t=0	m=1
2 M τ-1
=等 XX (q Vf(W (k))U2 + eIIv∕(w (k,t) )∣∣2
m=1 t=0
-EllVf(Wm,t)) - Vf (W(k)升2) - η(c2M c1) X Rm)	(68b)
m=1
> c12τ∣∣vf (w (k))∣∣2 + 22M XX (EnVf (础,t))∣∣2
m=1 t=0
-L2E∣∣Wm,t) - W(k)∣∣2) - η(c2- c1 X Rm),	(68c)
m=1
where ① follows from 2〈a, b)= ∣∣a∣∣2 + ∣∣b∣∣j — ∣∣a 一 b∣∣2, and ② holds due to Assumption 2.
From Lemma 7, we can show that
E∣∣We (mk,t)	- We (k)∣∣22	6	(c2η)2t	Xt-1	∣∣g(mk,n)∣∣22	+	σε2	,	(69)
n=0
21
Under review as a conference paper at ICLR 2022
where t = 1, . . . , T - 1. Substituting (69) in (68c) yields
E(Vf(W(k)), △⑻)
2	2 M τ-1
> c12ητ EW(W (k))U2 + 箸 X X 叫 Vf(W mk,t))俏
m=1 t=0
—
(c⅛F XX(T(T - 1) - n(n + 1)) EIIg(mk,n) II22
m=1 n=0
—
(c1c2L)2η3τ (τ - 1)
σ - η¾金 X Rm)
m=1
(70a)
4
2	2 M τ-1
> c12ητ 叫 Vf(W "∣2+箸 X X EIlVf(Wmk,t))∣∣2
m=1 t=0
M τ-1
-焉(c1c2L)2η2τ(T- 1) X X EIIg(mk,t)II22
m=1 t=0
—
(c1c2L)2η3τ(τ - 1)
。2-吟尸 X Rm)
m=1
(70b)
4
2	2	M τ-1
› 号F EIIVf(W (k))∣∣2 + 4MM & - ©Ly η2τ(T- 1))X X Eu
m=1 t=0
—
g(mk,t)22
(c1c2L)2η3τ(τ - 1)
σ -吟尸X Rm)
m=1
(70c)
4
where ① follows from T(T - 1) - n(n + 1) 6 T(T - 1), and ② holds due to the chain rule in (60)
and Assumption 3.
□
D.9 Proof of Lemma 9
Proof. We have
2
(71a)
(71b)
(71c)
(71d)
①
E
2
2
2
22
Under review as a conference paper at ICLR 2022
where ① comes from Assumption 5. For the first term in (71d) We have
1M
M Xi
m=1
(72a)
m=1
2M
M2 Xz)-hm，T 嘿
(72b)
m=1
Bn)2 X
M工
m=1
S)2 X
M 二
τ-1
-η X gm,t)
t=0
τ-1
(72c)
(C2n)
M
t=0
τ-1
m=1
2M
τX E
m=1 t=0
(g(mk,t) + ε(mk,t))
2
gmq∣2+」,
(72d)
(72e)
①
6
②
2
E
—
2
2
2
2
2
2
where ① is due to Lemma 6 and ② comes from (9). For the second term in (71d) we have
M
2
E
(73)
m=1
2
Combing the results of (72e) and (73) completes the proof.
□
23