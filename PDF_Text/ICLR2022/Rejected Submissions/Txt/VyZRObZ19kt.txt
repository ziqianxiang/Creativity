Under review as a conference paper at ICLR 2022
LEARNED INDEX WITH DYNAMIC
Anonymous authors
Paper under double-blind review
Ab stract
Index structure is a fundamental component in database and facilitates broad data
retrieval applications. Recent learned index methods show superior performance
by learning hidden yet useful data distribution with the help of machine learning,
and provide a guarantee that the prediction error is no more than a pre-defined
. However, existing learned index methods adopt a fixed for all the learned
segments, neglecting the diverse characteristics of different data localities. In
this paper, we propose a mathematically-grounded learned index framework with
dynamic , which is efficient and pluggable to existing learned index methods. We
theoretically analyze prediction error bounds that link with data characteristics
for an illustrative learned index method. Under the guidance of the derived bounds,
we learn how to vary and improve the index performance with a better space-time
trade-off. Experiments with real-world datasets and several state-of-the-art methods
demonstrate the efficiency, effectiveness and usability of the proposed framework.
1	Introduction
Data indexing (Graefe & Kuno, 2011; Wang et al., 2018; Luo & Carey, 2020; Zhou et al., 2020), which
stores keys and corresponding payloads with designed structures, supports efficient query operations
over data and benefits various data retrieval applications. Recently, Machine Learning (ML) models
have been incorporated into the design of index structure, leading to substantial improvements in
terms of both storage space and querying efficiency (Kipf et al., 2019; Ferragina & Vinciguerra, 2020a;
Mitzenmacher, 2018; Vaidya et al., 2021). The key insight behind this trending topic of “learned
index” is that the data to be indexed contain useful distribution information and such information can
be utilized by trainable ML models that map the keys to their stored positions. State-of-the-art learned
index methods (Galakatos et al., 2019; Kipf et al., 2020; Ferragina & Vinciguerra, 2020b; Ferragina
et al., 2020) adopt piece-wise linear segments to approximate the data distribution and introduce an
important pre-defined parameter . These methods ensure that the maximal prediction error of each
learned segment is no more than and provide a worst-case guarantee of querying efficiency.
By tuning , various space-time preferences from users can be met. For example, a relatively large
can result in a small index size while having large prediction errors, and on the other hand, a relatively
small provides with small prediction errors while having more learned segments and thus a large
index size. However, existing learned index methods implicitly assume that the whole dataset to be
indexed contains the same characteristics for different localities and thus adopt the same for all the
learned segments, leading to sub-optimal index performance. More importantly, the impact of on
index performance is intrinsically linked to data characteristics, which are not fully explored and
utilized by existing learned index methods.
Motivated by these, in this paper, we theoretically analyze the impact of on index performance,
and link the characteristics of data localities with the dynamic adjustments of . Based on the
derived theoretical results, we propose an efficient and pluggable learned index framework that
dynamically adjusts in a principled way. To be specific, under the setting of an illustrative learned
index method MET (Ferragina et al., 2020), we present novel analysis about the prediction error
bounds of each segment that link with the mean and variance of data localities. The segment-wise
prediction error embeds the space-error trade-off as it is the product of the number of covered keys
and mean absolute error, which determine the index size and preciseness respectively. The derived
mathematical relationships enable our framework to fully explore diverse data localities with an
-learner module, which learns to predict the impact of on the index performance and adaptively
choose a suitable to achieve a better space-time trade-off.
1
Under review as a conference paper at ICLR 2022
We apply the proposed framework to several state-of-the-art (SOTA) learned index methods, and
conduct a series of experiments on three widely adopted real-world datasets. Comparing with
the original learned index methods with fixed , our dynamic versions achieve significant index
performance improvements with better space-time trade-offs. We also conduct various experiments
to verify the necessity and effectiveness of the proposed framework, and provide both ablation study
and case study to understand how the proposed framework works.
2	Background
2.1	-BOUNDED LEARNED INDEX
Given a dataset D = {(x, y)|x ∈ X, y ∈ Y}, X is the set of keys over a universe U such as reals or
integers, and Y is the set of positions where the keys and corresponding payloads are stored. The
index such as B+-tree (Abel, 1984) aims to build a compact structure to support efficient query
operations over D. Typically, the keys are assumed to be sorted in ascending order to satisfy the
key-position monotonicity, i.e., for any two keys, xi > xj iff their positions yi > yj, such that the
range query (X ∩ [xlow , xhigh]) can be handled.
Recently, learned index methods (Kraska et al., 2018; Li et al., 2019; Tang et al., 2020; Dai et al., 2020;
Crotty, 2021) leverage ML models to mine useful distribution information from D, and incorporate
such information to boost the index performance. To look up a given key x, the learned index first
predicts position y using the learned models, and subsequently finds the stored true position y based
on y with a binary search or exponential search. Thus the querying time consists of the inference
time of the learned models and the search time in O(log(∣y - y|)). By modeling the data distribution
information, learned indexes achieve faster query speed than traditional B+-tree index, meanwhile
using several orders-of-magnitude smaller storage space (Ding et al., 2020; Galakatos et al., 2019;
Ferragina & Vinciguerra, 2020b; Kipf et al., 2020; Marcus et al., 2020).
Many existing learned index methods adopt piece-wise linear segments to approximate the distribution
of D due to their effectiveness and low computing cost, and introduce the parameter to provides a
worst-case preciseness guarantee and a tunable knob to meet various space-time trade-off preferences.
Here we briefly introduce the SOTA -bounded learned index methods that are most closely to our
work, and refer to the review chapter of (Ferragina & Vinciguerra, 2020a) for details of other methods.
Specifically, Galakatos et al. (2019) greedily learn a set of piece-wise linear segments in a one-pass
manner. Ferragina & Vinciguerra (2020b) adopt another one-pass algorithm that achieves the optimal
number of learned segments. Kipf et al. (2020) introduce a radix structure to organize the learned
segments. Ferragina et al. (2020) adopt a fixed slope setting for all learned segments. Existing
methods constraint all learned segments with the same , i.e., the learning process ensures that the
maximum prediction error is within a pre-defined where ∈ Z>1. In this paper, we will discuss the
impact of in more depth and invistigate how to enhance existing learned index methods from a new
perspective: dynamic adjustment of considering the diversity of different data localities.
2.2	Mean Exit Time (MET) Algorithm
Here we describe an illustrative learned index algorithm MET (Ferragina et al., 2020). Specifically,
for any two consecutive keys of D, suppose their key interval (xi - xi-1) is drawn according to
a random process {Gi}i∈N, where Gi is a positive independent and identically distributed (i.i.d.)
random variable whose mean is μ and variance is σ2. The MET algorithm learns linear segments
S = [S1, ..., Si, ..., SN] in one pass, where Si : y = aix + bi is the learnable linear segment and N is
the total number of learned segments. The learning process is as follows: The current linear segment
fixes the slope a% = 1 /μ and goes through the first available data point, thus b is also determined.
Then the segment covers as many data points as possible until a data point, say (x0, y0) achieves the
prediction error larger than . The violation of triggers a new linear segment, and the data point
(x0 , y0 ) will be the first available data point, and the process repeats until no data point is available.
Although the MET algorithm adopts a simple learning mechanism, it makes the theoretical analysis
convenient by modeling the learning process as a random walk process. Other -bounded learned
index methods such as FITing-Tree (Galakatos et al., 2019), PGM (Ferragina & Vinciguerra, 2020b)
and Radix-Spline (Kipf et al., 2020) learn linear segments in a similar manner while having different
mechanisms to determine the parameters of {Si }. Ferragina et al. (2020) reveal the relationship
2
Under review as a conference paper at ICLR 2022
between and index size performance based on MET. In Section 3.3, we present novel analysis
about the impact of on not only the index size, but also the index preciseness and a comprehensive
trade-off quantity, which facilitates the proposed dynamic adjustment.
3	LEARN TO VARY
3.1	Problem Formulation and Motivation
Before introducing the proposed framework, we first formulate the task of learning index from
data with guarantee, and provide some discussions about why we need to vary . Given a dataset
D to be indexed and an -bounded learned index algorithm A, we aim to learn segments S =
[S1, ..., Si..., SN] as index structure such that the size of S and PiN=1 MAE(Di|Si) are both small,
where Si is the i-th learned linear segment with the parameter i, MAE is the mean absolute prediction
error, and Di ⊂ D is the data whose keys are covered by Si. For the remaining data D \ Sj<i Dj,
the algorithm A repeatedly checks whether the prediction error of new data point violates the given
i, and outputs the learned segment Si that covers Di . When all the is for i ∈ [N] take the same
value, the problem becomes the one that existing learned index methods are dealing with.
Now let’s examine the effect of parameter . To query a specific data point, say (x, y), we first need to
find the specific segment S0 that covers x, and then search its true position y based on the estimated
one y = S0(χ). For the first step, We can find S0 from S in O(log(N)); for the second step, the
search of y based on y can be done in O(log(∣y - y|)). In summary, we can find the true position of
the queried data point in O(log(N) + log(∣y - y |)) 1. From here, we can see that the parameter e
plays an important role to trade off two contradictory performance terms, i.e., the size of the learned
index N, and MAE of the whole data MAE(D|S). If we adopt a small e, the maximal prediction error
constraint is more frequently violated, leading to a large N ; meanwhile, the preciseness of learned
index is improved, leading to a small MAE(D|S). On the other hand, with a large e, we will get a
more compact learned index (i.e., a small N) with larger prediction errors (i.e., a large MAE(D|S)).
Thus these two inversely changed terms jointly impact the querying efficiency.
Actually, the effect of e on index performance is intrinsically linked to the characteristic of the
data to be indexed. For real-world datasets, an important observation is that the linearity degree
varies in different data localities. Recall that we use piece-wise linear segments to fit the data, and
e determines the partition and the fitness of the segments. By varying e, we can adapt to the local
variations of D and adjust the partition such that each learned segment fits the data better. Formally,
let’s consider the quantity SegErri that is defined as the total prediction error within a segment Si ,
i.e., SegErri = P(x,y)∈D |y - Si(x)|, which is also the product of the number of covered keys
Len(Di) and the mean absolute error MAE(Di|Si). Note that a large Len(Di) leads to a small N
since |D| = PiN=1 Len(Di). From this view, the quantity SegErri internally reflects the space-error
trade-off. Later we will show how to leverage this quantity to dynamically adjust e.
3.2	Overall Framework
In practice, it is intractable to directly solve the problem formulated in Section 3.1. With a given ei,
the one-pass algorithm A determines Si and Di until the error bound ei is violated. In other words,
it is unknown what the data partition {Di} will be a priori, which makes it impossible to solve the
problem by searching among all the possible {ei}s and learning index with a set of given {ei}.
In this paper, we investigate how to efficiently find an approximate solution to this problem via the
introduced e-learner module. Instead of heuristically adjusting e, the e-learner learns to predict
the impact of e on the index structure and adaptively adjusts e in a principled way. Meanwhile, the
introducing of e-learner should not sacrifice the efficiency of the original one-pass learned index
algorithms, which is important for real-world practical applications.
These two design considerations establish our dynamic e framework as shown in Figure 1. The
e-learner is based on an estimation function SegErr = f (e, μ, σ) that depicts the mathematical
relationships among e, SegErri and the characteristics μ, σ of the data to be indexed. As a start, users
can provide an expected e that indicates various preferences under space-sensitive or time-sensitive
applications. To meet the user requirements, afterwards, we will internally transform the e into another 1
1In Appendix C, we link the absolute prediction error and specific searching algorithms in further details.
3
Under review as a conference paper at ICLR 2022
Key
Figure 1: Dynamic e framework with the e-learner module.
proxy quantity SegErr, which reflects the expected prediction error for each segment If we set ei = e.
This transformation also links the adjustment of e and data characteristics together, which enables the
data-dependent adjustment of e. Beginning with e, the e-learner chooses a suitable ei according to
current data characteristics, then learn a segment Si using A, and finally enhance the e-learner with
the rewarded ground-truth SegErri of each segment. To make the introduced adjustment efficient,
we propose to only sample a small Look-ahead data D0 to estimate the characteristics (i.e., μ and σ)
of the following data locality. The learning and adjusting processes are repeatedly conducted and
also in an efficient one-pass manner.
Note that the proposed framework provides users the same interface as the ones used by original
learned index methods. That is, we add no any additional cost to the users’ experience, and users
can smoothly and painlessly use our framework with given e just as they use the original methods
with given e. The e is an intuitive, easy-to-set and method-agnostic quantity for users. On the one
hand, we can easily impose restrictions on the worst-case querying cases with e as the data accessing
number in querying process is O(log(∣y 一 y|)). On the other hand, e is easier to estimate than the
other quantities such as index size and querying time, which are dependent on specific algorithms,
data layouts, implementations and experimental platforms. Our pluggable framework retains the
benefits of existing learned index methods, such as the aforementioned usability of e and the ability
to handle dynamic update case (Galakatos et al., 2019; Ferragina & Vinciguerra, 2020b).
We have seen how e determines index performance and how SegErri embeds the space-error trade-
off in Section 3.1. In Section 3.3, we will further theoretically analyze the relationship among e,
SegErri, and data characteristics μ, σ at different localities. Based on the analysis, we elaborate the
details of e-learner and the internal transformation between e and SegErri in Section 3.4.
3.3	Prediction Error Estimation
In this section, we will theoretically study the impact of e on the prediction error SegErri of each
learned segment Si . Specifically, for the MET algorithm, we can prove the following theorem to
bound the expectation of SegErri with e and the key interval distribution of the data to be indexed.
Theorem 1. Given a dataset D to be indexed and an e where e ∈ Z>1, consider the setting of the
MET algorithm (Ferragina et al., 2020), in which key intervals ofD are drawn from a random process
consisting of positive i.i.d. random variables with mean μ and variance σ2, and e》σ/μ. For a
learned segment Si and its covered data Di, denote SegErri = (x,y)∈D |y 一 Si (x)|. Then the
expectation of SegErri satisfies:
μ~< < E^[segErri] < lʌ/-(i) 4 (μ )2e3.
πσ	3 π 3 σ
This theorem reveals that the prediction error SegErri depends on both e and the data characteristics
(μ and σ). Recall that CV = σ/μ is the coefficient of variation, a classical statistical measure of
the relative dispersion of data points. In the context of the linear approximation, the data statistic
1 /CV = μ∕σ in our bounds intrinsically corresponds to the linearity degree of the data. With this, we
can find that when μ∕σ is large, the data is easy-to-fit with linear segments, and thus we can choose a
small e to achieve precise predictions. On the other hand, when μ∕σ is small, it becomes harder to
fit the data using a linear segment, and thus e should be increased to absorb some non-linear data
localities. In this way, we can make the total prediction error SegErri for different learned segments
consistent and achieve a better space-error trade-off. This analysis also confirms the motivation of
4
Under review as a conference paper at ICLR 2022
varying : The local linearity degrees of the indexed data can be diverse, and we should adjust
according to the local characteristic of the data, such that the learned index can fit and leverage the
data distribution better. In the design of the -learner module (Section 3.4), we will take the derived
closed-form relationships among SegErri, E and data statistic μ∕σ into account.
In the rest of this section, we provide a proof sketch of this theorem due to the space limitation. For
detailed proof, please refer to our Appendix. The main idea is to model the learning process of linear
approximation with E guarantee as a random walk process, and consider that the absolute prediction
error of each data point follows folded normal distributions. Specifically, given a learned segment
Si : y = aix + bi , we can calculate the expectation of SegErri for this segment as:
(j*-i)
E[SegErri] = aiE X |Zj |
j=0
∞ n-1
ai X E X |Zj| Pr(j*= n),
n=1	j=0
(1)
where Zj is the j-th position of a transformed random walk {Zj }j∈N, j* = max{j ∈ N| - e/a% ≤
Zj ≤ E∕ai } is the random variable indicating the maximal position when the random walk is within
the strip of boundary ±e/ai, and the last equality is due to the definition of expectation.
Under the MET algorithm setting where ai = 1∕μ and e>σ∕μ, we can show that the increments of
the transformed random walk {Zj} have zero mean and variance σ2, and many steps are necessary to
reach the random walk boundary. With the Central Limit Theorem, we can assume the Zj follows
normal distribution with mean μzj = 0 and variance σ2j = jσ2, and thus |Zj| follows the folded
normal distribution with expectation E(∣Zj|) = ,2∕πσ√j. Thus Eq. (1) can be written as
1 ∞	n-1	ι ∞ n-1	∞^ ∞ n-1
-XE	X	|Zj|	Pr(j*= n)	< — XXE[∣Zj∣]Pr(j*	= n)	= σ√-XXpjPr(j*= n).
μ n=1	j=0	μ n=1 j=0	μ n n=1 j=0
Using E[j*] = μ-e2 and Var[j*] = f μre4 as derived in (Ferragina et al., 2020), we get E[(j*)2]二
σ2	3 σ4
5 μe4. With the inequality Pn-CI √ < 3n√n and E[X4] ≤ (E[X])4, we get the upper bound:
E[_segErri] < -∖∕-σE[(j*)2] ≤ -∖ -σ (E[(j*)2D4 = -∖∕-(5)4(μ)2e3.
3 v π μ	3 π πμ	3 V ∏ 3 σ
For the lower bound, applying the triangle inequality into Eq. (1), we can get E[SegErri] >
1 P∞=ι E [|Z|] Pr(j* = n), where Z = Pn-CI Zj, and Z follows the normal distribution since
Zj 〜N(0, σ2j∙). We can prove that |Z| follows the folded normal distribution whose expectation
E[|Z|] > σ(n - 1)∕√π. Thus the lower bound is:
E[SegErr%] > ^ʌ已 X(n - 1)Pr(j* = n) = -ʌ已E[j* - 1] = ʌ/ɪ(巴 J--).
μ V π z—z	μ V π	V π σ μ
n=1
Since e》μ, we can omit the right term ,1∕π ∙ σ∕μ and finish the proof. Although the derivations
are based on the MET algorithm whose slope is the reciprocal of μ, we found that the mathematical
forms among e, μ∕σ and SegErri are still applicable to other e-bounded methods, and further prove
that the learned segment slopes of other methods are close to the reciprocal of expected key intervals
in Appendix. We will empirically show the links between MET and other SOTA e-bounded methods,
and how effectively the proposed framework works for them on real-world datasets (Section 4.2).
3.4 e-LEARNER
Now given an e, we have obtained the closed-form bounds of the SegErr in Theorem 1, and both
the upper and lower bounds are in the form of wι(μ)w2ew3, where wι,2,3 are some coefficients. As
the concrete values of these coefficients can be different for different datasets and different methods,
we propose to learn the following trainable estimator to make the error prediction preciser:
SegErr = f (e,μ,σ) =wι(μ )w2 ew3,
σ
s.t. ≤ — ≤ wI ≤ -ʌ/-( -) 4 , 1 ≤ w2 ≤ 2, 2 ≤ w3 ≤ 3.
π	3 π3
(2)
5
Under review as a conference paper at ICLR 2022
With this learnable estimator, We feed data characteristic μ∕σ of the look-ahead data and the trans-
1/w3
formed SegErr into it and find a suitable e* as <SegErr∕w∖(μ)w2)	. We will discuss the
look-ahead data and the transformed SegErr in the following paragraphs. Now let’s discuss the rea-
sons for how this adjustment can achieve better index performance. Actually, the e-learner proactively
plans the allocations of the total prediction error indicated by user (i.e., e ∙ |D|) and calculates the
tolerated SegErr for the next segment. By adjusting current e to e*, the following learned segment
can fully utilize the distribution information of the data and achieve better performance in terms of
space-error trade-off. To be specific, when μ∕σ is large, the local data has clear linearity, and thus we
can adjust e to a relatively small value to gain precise predictions; although the number of data points
covered by this segment may decrease and then the number of total segments increases, such cost
paid in terms of space is not larger than the benefit we gain in terms of precise predictions. Similarly,
when μ∕σ is small, e should be adjusted to a relatively large value to lower the learning difficulty and
absorb some non-linear data localities; in this case, we gain in terms of space while paying some
costs in terms of prediction accuracy. The segment-wise adjustment of e improves the overall index
performance by continually and data-dependently balancing the cost of space and preciseness.
Look-ahead Data. To make the training and inference of the e-learner light-weight, we propose to
look ahead a few data D0 to reflect the characteristics of the following data localities. Specifically,
we leverage a small subset D0 ⊂ D \ Ujyi Dj to estimate the value μ∕σ for the following data.
In practice, we set the size of D0 to be 404 when learning the first segment as initialization, and
((⅛) Pj=I Len(Dj)) ∙ P for the other following segments. Here P is a pre-defined parameter
indicating the percentage that is relative to the average number of covered keys for learned segments,
considering that the distribution of μ∕σ can be quite different to various datasets. As for the first
segment, according to the literature (Kelley, 2007), the sample size 404 can provide a 90% confidence
intervals for a coefficient of variance σ∕μ ≤ 0.2.
SegErr and Optimization. As aforementioned, taking the user-expected e as input, we aim to
reflect the impact of e with a transformed proxy quantity SegErr such that the e-learner can choose
suitable e* to meet users, preference while achieving better space-error trade-off. Specifically, we
make the value of SegErr updatable, and update it to be SegErr = wι(μ∕σ)w2ew3 once a new
segment is learned, where μ∕σ is the mean value of all the processed data so far. This strategy enables
us to promptly incorporate both the user preference and the data distribution into the calculation of
SegErr. As for the optimization of the f (e, μ, σ), we adopt the projected gradient descent (Calamai
& More, 1987; den Hertog & Roos, 1991) with the parameter constraints in Eq. (2). In this way,
we only need to track a few statistics and learn the e estimator in an efficient one-pass manner. The
overall adjustment algorithm is summarized in Appendix D.
4	Experiments
4.1	Experimental Settings
Baselines. We apply our framework into several SOTA e-bounded learned index methods that use
different mechanisms to determine the parameters of segments {Si}. Among them, MET (Ferragina
et al., 2020) fixes the segment slope as the reciprocal of the expected key interval. FITing-Tree
(Galakatos et al., 2019) and Radix-Spline (Kipf et al., 2020) adopt a greedy shrinking cone algorithm
and a spline interpolating algorithm respectively. PGM (Ferragina & Vinciguerra, 2020b) adopts
a convex hull based algorithm to achieve the minimum number of learned segments. Further
introduction and implementation details can be found in Appendix.
Datasets. We use several widely adopted datasets with differing data scales and distributions
(Kraska et al., 2018; Galakatos et al., 2019; Ferragina & Vinciguerra, 2020b; Li et al., 2021). Weblogs
and IoT contain about 715M log entries from a university web server and 26M event entries from
different IoT sensors respectively, in which the keys are both log timestamps. Map dataset contains
location coordinates that are collected around the world from the OpenStreetMap contributors (2017),
and the keys are longitude + 90 ∙ latitude of about 1.8M places. Lognormal is a synthetic dataset
whose key intervals follow the lognormal distribution. We generate 20M keys with 40 partitions
6
Under review as a conference paper at ICLR 2022
having different generation parameters to simulate the varied data characteristics among different
localities. More dataset details and visualization are presented in Appendix F.
Evaluation Metrics. We evaluate the index performance in terms of its size, prediction preciseness,
and the total querying time. Specifically, we report the number of learned segments N, the index size
in bytes, the MAE as d P(X y)ED |y - S(x)∣, and the total querying time per query in ns (i.e., we
perform querying operations for all the indexed data, record the total time of getting the payloads
given the keys, and report the time that is averaged over all the queries). For a quantitative comparison
w.r.t. the trade-off improvements, we calculate the area under the space-error curve (AUSEC) where
the x-axis and y-axis indicate N and MAE respectively. For AUSEC metric, the smaller, the better.
4.2	Overall Index Performance
Space-Error Trade-off Improvements. In Table 1, we summarize the AUSEC improvements in
percentage brought by the proposed framework of all the baseline methods on all the datasets. We
also illustrate the space-error trade-off curves for some cases in Figure 2, where the blue curves
indicate the results achieved by fixed e version while the red curves are for dynamic e. Other baselines
and datasets yield similar curves, which we include in Appendix due to the space limitation. From
these results, we can see that the dynamic e versions of all the baseline methods achieve much better
error-space trade-off (-16.48% to -23.57% averaged improvements as smaller AUSEC indicates
better performance), demonstrating the effectiveness and the wide applicability of the proposed
framework. As discussed in previous sections, datasets usually have diverse key distributions at
different data localities, and the proposed framework can data-dependently adjust e to fully utilize
the distribution information of data localities and thus achieve better index performance in terms
of space-error trade-off. Note that the Map dataset has significant non-linearity caused by spatial
characteristics, and it is hard to fit using linear segments (all baseline methods learn linear segments),
thus relatively small improvements are achieved.
Table 1: The AUSEC relative improvements for learned index methods with dynamic e.
I Weblogs		IoT	Map	Lognormal	Average
MET	-25.87%	-7.66%	-10.89%	-21.48%	-16.48%
FITing-Tree	-31.18%	-25.56%	-9.30%	-28.24%	-23.57%
Radix-Spline	-28.37%	-24.59%	-8.77%	-31.32%	-23.26%
PGM	-22.42%	-25.01%	-7.18%	-19.58%	-18.55%
Lognormal Dataset
200
Weblogs Dataset
5 0 5 0
1 1
国VW
IoT Dataset
Ooo
5 0 5
1 1
HVW
,	,-一 ，	01
6 IOOOO 20000	3000。	6	20000	40∞0	60000	0	100	200	300	400
N	N	N
Figure 2:	The space-error trade-off curves for learned index methods.
(图 PUl
QUelying Time(ns)
Querying Time(ns)
Figure 3:	Improvements in terms of querying time for learned index methods with dynamic e.
Querying Time Improvements. Recall that the querying time of each data point is in O(log(N) +
log(∣y — y|) as we mentioned in Section 3.1, where N and |y - y| are inversely impacted by e. To
examine whether the performance improvements w.r.t. space-error trade-off (i.e., Table 1) can lead
to better querying efficiency in real-world systems, we show the averaged total querying time per
7
Under review as a conference paper at ICLR 2022
query and the actual learned index size in bytes for two scenarios in Figure 3. We can observe that
the dynamic versions indeed gain faster querying speed, since we improve both the term N as well
as the term |y - y| via adaptive adjustment of e. The similar conclusion can be drawn from other
baselines and datasets, and we present their results in Appendix. Another thing to note is that, this
experiment also verifies the usability of our framework in which users can flexibly set the expected e
to meet various space-time preferences just as they set e in the original learned index methods.
Index Building Cost. Comparing with the original learned index methods that adopt a fixed e, our
framework introduces extra computation to dynamically adjust e in the index building stage. Does
this affect the efficiency of original learned index methods? Here we report the relative increments of
building times in Table 2. From it, we can observe that the proposed dynamic e framework achieves
comparable building times to all the original learned index methods on all the datasets, showing the
efficiency of our framework since it has the same complexity as the original methods (both in O(|D|)).
Also note that we only need to pay this extra cost once, i.e., building the index once, and then the
index structures can accelerate the frequent data querying operations for real-world applications.
Table 2: Building time increments in percentage for learned index methods with dynamic e.
I Weblogs		IoT	Map	Lognormal	Average
MET	10.54%	5.14%	7.55%	5.26%	7.12%
FITing-Tree	10.7%	1.88%	6.04%	5.23%	5.96%
Radix-Spline	10.19%	1.64%	3.56%	8.96%	6.09%
PGM	16.76%	2.2%	1.07%	21.29%	10.33%
4.3 ABLATION STUDY OF DYNAMIC e
To gain further insights about how the proposed dynamic e framework works, we compare the
proposed one with three dynamic e variants: (1) Random e is a vanilla version that randomly choose
e from [0,2<≡] when learning each new segment; (2) Polynomial Learner differs our framework with
another polynomial function SegErr(e) = θ1eθ2 where θ1 and θ2 are trainable parameters; (3) Least
Square Learner differs our framework with an optimal (but very costly) strategy to learn f (e, μ, σ)
with the least square regression.
Table 3: The AUSEC relative changes of dynamic e variants compared to the proposed framework.
I Weblogs		IoT	Map	Lognormal	Average
Random e	+70.94%	+68.19%	+51.73%	+73.38%	+66.06%
Polynomial Learner	+49.32%	+40.57%	+7.29%	+42.77%	+34.99%
Least Square Learner	+4.44%	+9.32%	+2.20%	-17.63%	-0.42%
We summarize the AUSEC changes in percentage compared to the proposed framework in Table 3.
Here we only report the results for FITing-Tree due to the space limitation and similar results can
be observed for other methods. Recall that for AUSEC, the smaller, the better. From this table, we
have the following observations: (1) The Random e version achieves much worse results than the
proposed dynamic e framework, showing the necessity and effectiveness of learning the impact of
e. (2) The Polynomial Learner achieves better results than the Random e version while still have a
large performance gap compared to our proposed framework. This indicates the usefulness of the
derived theoretical results that link the index performance, the e and the data characteristics together.
(3) For the Least Square Learner, we can see that it achieves similar AUSEC results compared with
the proposed framework. However, it has higher computational complexity and pays the cost of much
larger building times, e.g., 14× and 50× longer building times on IoT and Map respectively. These
results demonstrate the effectiveness and efficiency of the proposed framework that adjusts e based
on the theoretical results, which will be validated next.
4.4 Theoretical Results Validation
We study the impact of e on SegErri for the MET algorithm in Theorem 1, where the derivations
are based on the setting of the slope condition a% = 1∕μ. To confirm that the proposed framework
also works well with other e-bounded learned index methods, we analyze the learned slopes of other
e-bounded methods in Appendix. In summary, we prove that for a segment Si : y = aix + bi whose
8
Under review as a conference paper at ICLR 2022
×io3	Map Dataset
0	12	3	4
1∕μi	×103
Figure 4: Learned slopes.
Figure 5: Illustration of the derived bounds.
covered data is Di and the expected key interval of Di is μ%, then ai concentrates on ∖∕μi within
2/(E[Len(Di)] - 1) relative deviations. Here we plot the learned slopes of baseline learned index
methods in Figure 4. We can see that the learned slopes of other methods indeed center along the line
ai = 1∕μi, showing the close connections among these methods and confirming that the proposed
framework can work well with other -bounded learned index methods.
We further compare the theoretical bounds with the actual SegErri for all the adopted learned
index methods. In Figure 5, we only show the results on Lognormal dataset due to space limitation.
As expected, we can see that the MET method has the actual SegErri within the derived bounds,
verifying the correctness of the Theorem 1. Besides, the other -bounded methods show the same
trends with the MET method, providing the evidence that these methods have the same mathematical
forms as we derived, and thus the -learner also works well with them.
4.5 Case Study
We visualize the partial learned segments for FITing-Tree with
fixed and dynamic on IoT dataset in Figure 6, where the N and
P SegErri indicates the number of learned segments and the
total prediction error for the shown segments respectively. The
μ∕σ indicates the characteristics of covered data {Di}. We can
see that our dynamic framework helps the learned index gain
both smaller space (7 v.s. 4) and smaller total prediction errors
(48017 v.s. 29854). Note that s within -→i are diverse due to the
diverse linearity of different data localities: For the data whose
positions are within about [30000, 30600] and [34700, 35000],
the proposed framework chooses large es as their μ∕σs are small,
and by doing so, it achieves smaller N than the fixed version by
absorbing these non-linear localities; For the data at the middle
part, they have clear linearity with large μ∕σs, and thus the
proposed framework adjusts e as 19 and 10 that are smaller than
32 to achieve better precision. These experimental observations
are consistent with our analysis in the paragraph under Eq. (2),
Fixed： N = 7, £ SegErTi = 48017
35000-
34000
33000
32∞0
31∞0
30000
4000	6000	8000
K⅛y +1.48463X10®
Dynamic: N = 4, £ SegErrt = 29854
35000
34000
S 33000
≡
£ 32000
31000
3∞00
4000	6000	8000
Key ⅛1.48463× 109
Figure 6: Visualization of the
learned index (partial) on IoT for
FITing-Tree with fixed e = 32 and
dynamic version ( e = 32).
and clearly confirm that the proposed framework adaptively adjusts based on data characteristics.
5 Conclusions
Existing learned index methods introduce an important hyper-parameter e to provide a worst-case
preciseness guarantee and meet various space-time user preferences. In this paper, we provide formal
analyses about the relationships among e, data local characteristics and the introduced quantity
SegErri for each learned segment, which is the product of the number of covered keys and MAE,
and thus embeds the space-error trade-off. Based on the derived mathematical relationships, we
present a pluggable dynamic e framework that leverages an e-learner to data-dependently adjust e and
achieve better index performance in terms of space-error trade-off. A series of experiments verify the
effectiveness, efficiency and usability of the proposed framework.
We believe that our work contributes a deeper understanding of how the e impacts the index perfor-
mance, and enlightens the exploration of fine-grained trade-off adjustments by considering data local
characteristics. Our study also opens several interesting future works. For example, we can apply the
proposed framework to other problems in which the piece-wise approximation algorithms with fixed
e are used while still requiring space-error trade-off, such as similarity search and lossy compression
for time series data (Chen et al., 2007; Xie et al., 2014; Buragohain et al., 2007; O’Rourke, 1981).
9
Under review as a conference paper at ICLR 2022
Reproducibility S tatement
For the Theorem 1 presented in Section 3.3, we give a complete proof in Appendix A. We introduce
more implementation details of our method and baselines in Appendix E. More detailed description
of the adopted datasets is included in Appendix F. To facilitate the reproducibitlity, we share
downloadable source codes and IPython notebooks, and attach binary files of the public experimental
datasets in the anonymous link 2.
References
David J Abel. A B+-tree structure for large quadtrees. Computer Vision, Graphics, and Image
Processing, 27(1):19-31,1984.
Timo Bingmann. Stx b+ tree. https://panthema.net/2007/stx-btree/, 2013.
Chiranjeeb Buragohain, Nisheeth Shrivastava, and Subhash Suri. Space efficient streaming algorithms
for the maximum error histogram. In IEEE 23rd International Conference on Data Engineering,
pp. 1026-1035, 2007.
Paul H Calamai and Jorge J More. Projected gradient methods for linearly constrained problems.
Mathematical programming, 39(1):93-116, 1987.
Qiuxia Chen, Lei Chen, Xiang Lian, Yunhao Liu, and Jeffrey Xu Yu. Indexable pla for efficient
similarity search. In Proceedings of the 33rd international conference on Very large data bases, pp.
435-446, 2007.
Andrew Crotty. Hist-tree: Those who ignore it are doomed to learn. In 11th Conference on Innovative
Data Systems Research, 2021.
Yifan Dai, Yien Xu, Aishwarya Ganesan, Ramnatthan Alagappan, Brian Kroth, Andrea Arpaci-
Dusseau, and Remzi Arpaci-Dusseau. From wisckey to bourbon: A learned index for log-structured
merge trees. In 14th USENIX Symposium on Operating Systems Design and Implementation, pp.
155-171, 2020.
Dick den Hertog and Cees Roos. A survey of search directions in interior point methods for linear
programming. Mathematical Programming, 52(1):481-509, 1991.
Jialin Ding, Umar Farooq Minhas, Hantian Zhang, Yinan Li, Chi Wang, Badrish Chandramouli,
Johannes Gehrke, Donald Kossmann, and David B. Lomet. Alex: An updatable adaptive learned
index. In Proceedings of the ACM SIGMOD International Conference on Management of Data,
pp. 969-984, 2020.
Paolo Ferragina and Giorgio Vinciguerra. Learned data structures. In Recent Trends in Learning
From Data,pp.5T1.2020a. doi: 10.1007/978-3-030-43883-8^.
Paolo Ferragina and Giorgio Vinciguerra. The PGM-Index: A fully-dynamic compressed learned
index with provable worst-case bounds. Proceedings of the VLDB Endowment, 13(8):1162-1175,
2020b. ISSN 2150-8097.
Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. Why are learned indexes so effective? In
International Conference on Machine Learning, pp. 3123-3132, 2020.
Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim Kraska. FITing-
Tree: A data-aware index structure. In Proceedings of the International Conference on Management
of Data, pp. 1189-1206, 2019.
Goetz Graefe and Harumi Kuno. Modern b-tree techniques. In 27th International Conference on
Data Engineering, pp. 1370-1373, 2011.
2https://github.com/AnonyMLResearcher/AnonyCodesData/blob/main/Supplemental%20Materials-
ICLR22-Paper997.zip
10
Under review as a conference paper at ICLR 2022
Ken Kelley. Sample size planning for the coefficient of variation from the accuracy in parameter
estimation approach. BehaviorResearch Methods, 39(4):755-766, 2007.
Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter A. Boncz, and Alfons Kemper.
Learned cardinalities: Estimating correlated joins with deep learning. In 9th Biennial Conference
on Innovative Data Systems Research, 2019.
Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim Kraska,
and Thomas Neumann. Radixspline: A single-pass learned index. In Proceedings of the Third
International Workshop on Exploiting Artificial Intelligence Techniques for Data Management,
2020.
Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned index
structures. In Proceedings of the International Conference on Management of Data, pp. 489-504,
2018.
Xin Li, Jingdong Li, and Xiaoling Wang. Aslm: Adaptive single layer model for learned index. In
International Conference on Database Systems for Advanced Applications, pp. 80-95. Springer,
2019.
Yaliang Li, Daoyuan Chen, Bolin Ding, Kai Zeng, and Jingren Zhou. A pluggable learned index
method via sampling and gap insertion. arXiv preprint arXiv:2101.00808, 2021.
Chen Luo and Michael J Carey. Lsm-based storage techniques: a survey. The VLDB Journal, 29(1):
393-418, 2020.
Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra, Alfons Kemper,
Thomas Neumann, and Tim Kraska. Benchmarking learned indexes. Proceedings of the VLDB
Endowment, 14(1):1-13, 2020.
Michael Mitzenmacher. A model for learned bloom filters, and optimizing by sandwiching. In
Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp.
462-471, 2018.
OpenStreetMap contributors. Planet dump retrieved from https://planet.osm.org . https://www.
openstreetmap.org, 2017.
Joseph O’Rourke. An on-line algorithm for fitting straight lines between data ranges. Communications
of the ACM, 24(9):574-578, 1981.
Jun Rao and Kenneth A. Ross. Cache conscious indexing for decision-support in main memory. In
Proceedings of the 25th International Conference on Very Large Data Bases, pp. 78-89, 1999.
Chuzhe Tang, Youyun Wang, Zhiyuan Dong, Gansen Hu, Zhaoguo Wang, Minjie Wang, and Haibo
Chen. Xindex: a scalable learned index for multicore data storage. In Proceedings of the 25th
ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, pp. 308-320,
2020.
Kapil Vaidya, Eric Knorr, Michael Mitzenmacher, and Tim Kraska. Partitioned learned bloom filters.
In International Conference on Learning Representations, 2021.
Jingdong Wang, Ting Zhang, jingkuan song, Nicu Sebe, and Heng Tao Shen. A survey on learning to
hash. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(4):769-790, 2018.
Qing Xie, Chaoyi Pang, Xiaofang Zhou, Xiangliang Zhang, and Ke Deng. Maximum error-bounded
piecewise linear representation for online stream approximation. The VLDB journal, 23(6):
915-937, 2014.
Xuanhe Zhou, Chengliang Chai, Guoliang Li, and Ji Sun. Database meets artificial intelligence: A
survey. IEEE Transactions on Knowledge and Data Engineering, 2020.
11
Under review as a conference paper at ICLR 2022
APPENDICES FOR THE SUBMISSION: LEARNED INDEX WITH DYNAMIC
A Proof of Theorem 1
Given a learned segment Si : y = aix + bi, denote ci as the stored position of the last covered data
for the (i - 1)-th segment (c1 = 0 for the first segment). We can write the expectation of SegErri
for the segment Si as the following form:
(j*-1)
E[SegErri] =E X |aiXj + bi - (j+ci+1)|
j=0
where j* indicates the length of the segment, and Xj indicates the j-th key covered by the segment
Si . As studied in Ferragina et al. (2020), the linear-approximation problem with guarantee can
be modeled as random walk processes. Specifically, Xj = X0 + Pjk=0 Gk (for j ∈ Z>0) where
Gk is the key increment variable whose mean and variance is μ and σ2 respectively. Denote the
Zj = Xj - j/ai + (bi - ci - 1)/ai as the j-th position of the transformed random walk {Zj}j∈N,
and j * = max{j ∈ N| - /ai ≤ Zj ≤ /ai } as the random variable indicating the maximal position
when the random walk is within the strip of boundary ±/ai . The expectation can be rewritten as
(j*-1)
E X |aiXj - j + (bi - ci - 1)|
j=0
(j*-1)
=aiE	X	|Zj|
j=0
∞	n-1
=aiXE	X|Zj|
n=1	j=0
Pr(j* = n).
(3)
The last equality in Eq. (3) is due to the definition of expectation. Following the MET algorithm that
the Si goes through the point (X0, Y0 = ci + 1), we get bi = -aiX0 + ci + 1 and we can rewrite
Zj as the following form:
Z0 = 0,
Zjj=>0Xj-X0-j/ai =XGk-j/ai=X(Gk-1/ai) =X(Wk),
k=1	k=1	k=1
where Wk is the walk increment variable of Zj, E[Wk] = μ 一 1/ai and Var[Wk] = σ2. Under
the MET algorithm setting where a% = 1 /μ and ε》σ∕μ, the transformed random walk {Zj } has
increments with zero mean and variance σ2, and many steps are necessary to reach the random walk
boundary. With the Central Limit Theorem, we can assume that Zj follows the normal distribution
with mean μzj∙ and variance σj and thus |Zj | follows the folded normal distribution:
Zj 〜N(μ - 1∕aij,jσ2),
E(∣ZjI) = μzj[1 一 2Φ( - μzj/%)]+ σzjp2∕∏exp(-μZj∕2σ2j),
where Φ is the normal cumulative distribution function. For the MET algorithm, a% = 1∕μ and thus
the μzj = 0, σzj = σ√j, and E(|Zj ∣) = ,2∕πσ√j. Then the Eq. (3) can be written as
n-1
X|Zj|
j=0
∞
1XE
∞ n-1
Pr(j* = n) < - XX E [|Zj|] Pr(j* = n)
μn=1j=0
∞ ∞	n— 1
=N XXpjPr(j* = n).
μ V π n=1j=0
(4)
For the inner sum term in Eq. (4), we have (Pn-(I √j) < 3n√n since
n-1	n-1	Γ~ n	Q
Xpj<Xpj + 2 <J √xdx=3n√n,
12
Under review as a conference paper at ICLR 2022
then the result in Eq. (4) becomes
2 2σσ x∞
E∖Se-gErτ-j∖ < -J----ɪ2 n√n Pr(j = n)
3γπμn=ι
=3 r∏ μ E[j*)2 ]=2 r μ E h((j *)2可 ≤2 r∏ μ (E[j *)2])4，
2
where the last inequality holds due to the Jensen inequality E[X4] ≤ (E[X])4. Using Ej*] = Fa
σ2
and Varj*] = ∣μ4e4 derived in MET algorithm Ferragina et al. (2020), We get E[(j*)2] = ∣μ4e4,
which yields the following upper bound:
E[SegErTi] < 2 72(5)3 (μ )2e3.
3 π3 σ
For the lower bound, applying the triangle inequality into the Eq. (3), we have
∞
1 XE
n-1
X|Zj|
j=0
∞
Pr(j* = n) > - X E
μ n=ι
n-1
I X ZjI Pr(j*= n)
j=0
∞
-X E [∣Z∣]Pr(j*= n),
μ n=ι
(5)
where Z = Pjn=-01 Zj . Since Zj 〜 N(0, σ2j), the Z follows the normal distribution:
n-1	n-1 n-1
Z ~N (〃Z =0, σZ = X σ2j + X X rjkσzjσzk ,
j=0	j=0 k=0,k6=j
where rjk is the correlation between Zj and Zk. Since μz = 0, the ∣Z∣ follows the folded normal
distribution with E[∣Z∣] = σz vz2∕π. Since the random walk {Zj } is a process with i.i.d. increments,
the correlation rjk ≥ 0. With σzj = σ√j > 0 and rjk ≥ 0, we have
E[∣Z∣] > ∖∕2X σzj> σ√n(n - 1)∕π > σ(n-1),
ππ
j=0
and the result in Eq. (5) becomes:
1∞
E[Se^gErτi] > — ^X E
μ M
n-1
I X Zj I Pr(j*= n)
j=0
1Γ ∞
> -∖ - £(n — 1) Pr(j* = n)
〃vπ n=ι
σ∖∕1 Ej*- 1] = ∖∕1(μ1 σ).
μ V ∏	V ∏ σ μ
Since E》μ, we can omit the right term ∏ ∏ μ and finish the proof.
B LEARNED SLOPES OF OTHER -BOUNDED METHODS
As shown in Theorem 1, we have known how E impacts the SegErri of each segment learned by
the MET algorithm, where the theoretical derivations largely rely on the slope condition a% = 1∕μ.
Here we prove that for other E-bounded methods, the learned slope of each segment (i.e., ai of Si)
concentrates on the reciprocal of the expected key interval as shown in the following Theorem.
13
Under review as a conference paper at ICLR 2022
Theorem 2. Given an ∈ Z>1 and an -bounded learned index algorithm A. For a linear segment
Si : y = ai x + bi learned by A, denote its covered data and the number of covered keys as Di
and Len(Di) respectively. Assuming the expected key interval of Di is μi, the learned slope ai
concentrates on a = ∖∕μ% with bounded relative difference:
(1 — ——-----τarτ≤---)a ≤ E[ai] < (1 + —7--------------[二-------)a.
E	E[Len(Di)] — 1	E[Len(DJ] — J
Proof. For the learned linear segment Si , denote its first predicted position and last predicted position
as y0 and y； respectively, We have its slope a = Xn-O. Notice that yo — e < y0 < yo + e and
yn — < yn0 < yn + due to the guarantee, we have yn — y0 — 2 < yn0 — y00 < yn — y0 + 2 and
the expectation of ai can be Written as
E[ yn-y0 +	2e ]	<	E[αi]	=	yn-y0-	<	E[ yn	-	y0 +	2e ].
xn — x0	xn — x0	xn — x0
Note that for any learned segment Si Whose first covered data is (x0 , y0) and last covered data is
(xn, yn), We have E[xn-x0 ] = μi and thus the inequalities become
yn -y0
1 — E[	2e ]	< E[αi]	< 1+ E[	2e ].
μ	Xn — X0	μ	Xn — X0
Since a = ∖∕μ% and E[x； 一 xo] = (E[Len(Di)] — 1)μi, we finish the proof.
□
The Theorem 2 shows that the relative deviations between learned slope ai and a are within
2e/([Len(Di)] — 1). For the MET and PGM learned index methods, We have the folloWing
corollary that depicts preciser deviations without the expectation term E[Len(Di)].
Corollary 2.1. For the MET method Ferragina et al. (2020) and the optimal e-bounded linear
approximation method that learns the largest segment length used in PGM Ferragina & Vinciguerra
(2020b), the slope relative differences are at O(1/e).
Proof. We note that the segment length of a learned segment is at O(e2) for the MET algorithm,
which is proved in the Theorem 1 of Ferragina et al. (2020). Since PGM achieves the largest learned
segment length that is larger than the one of the MET algorithm, we finish the proof.	□
C Connecting Prediction Error with Searching S trategy
As we mentioned in Section 3.1, we can find the true position of the queried data point in O(log(N) +
log(∣y — y|)) where N is the number of learned segments and |y - y| is the absolute prediction error.
A binary search or exponential search can be used to finds the stored true position y based on y. It is
worth noting out that the searching cost in terms of searching range |y 一 y| of binary search strategy
corresponds to the maximum absolute prediction error e, whereas the one of exponential search
corresponds to the mean absolute prediction error (MAE). In this paper, we decouple the quantity
SegErri as the product of Len(Di) and MAE(Di|Si) in the derivation of Theorem 1. Built upon
the theoretical analysis, we adopt exponential search in experiments to better leverage the predictive
models.
To clarify, let’s consider a learned segment Si with its covered data Di. Denote the absolute prediction
error of k-th data point covered by this segment as |yk 一 yk |, the maximum absolute prediction error
as e. where |yk 一 yk | < e% for all k ∈ [len(Di)].
• The binary search is conducted within the searching range [yk ± e/ for each data point 3,
thus the mean search range is Pken(Di) ien11D∙) 2ei = O(ei), which is independent of the
preciseness of the learned segment and an upper bound ofMAE(Di|Si).
3The lower bound and upper bounds of searching ranges should be constricted to 0 and len(Di) respectively.
For brevity, we omit the corner cases when comparing these two searching strategies as they both need to handle
the out-of-bounds scenario.
14
Under review as a conference paper at ICLR 2022
• The exponential search first finds the searching range where the queried data may present by
centering around the y, repeatedly doubling the range [y ± 2q] where the integer q grows
from 0, and comparing the queried data with the data points at positions y± 2q. After finding
the specific range such that a qk satisfies 2log(qk)-1 ≤ |yk - yk| ≤ 2dlog(qk)e for the k-th
data, an binary search is conducted to find the exact location. In this way, the mean search
range is Pk=n(Di) 他杀,)(2dlog(qk)e+1) = O(MAE(D∕Si)), which can be much smaller
than O(i) especially for strong predictive models and the datasets having clear linearity.
D THE ALGORITHM OF DYNAMIC ADJUSTMENT
Algorithm Dynamic Adjustment with Pluggable Learner
Input: D: Data to be indexed, A: Learned index algorithm, e: Expected e, P: Length percentage
for look-ahead data
Output: S: Learned segments with varied s
1:	initial parameters w1,2,3 of the learnedfunction: f (e, μ, σ) = w1( μ )w2 ew3
2:	initial mean length oflearned segments so far: Len(DS) J 404
3:	S J 0, (μ∕σ) j o
4:	repeat
5:	(μ∕σ) J lookahead(D, Len(DS) ∙ ρ)	/* get data statistic */
1/w3
6:	e* J ∖ S eg Err/w 1( μ )w2)	/* adjust e based on the learner */
7:	[Si, Di] J A(D, e*)	/* learn new segment Si using adjusted e* */
8:	S J S ∪ Si
9:	D J D \ Di, DS J DS ∪ Di
10:	Len(DS) J running-mean Len(DS), Len(Di)	/* online update Len(DS) */
11:	(μ∕σ) J running-mean((μ∕σ), (μ∕σ))
12:	w1,2,3 J optimize(f, Si, SegErri)	/* train the learner with ground-truth */
.....
13:	SegErr J w1(μ∕σ)w2 ew3
14:	until D = 0
In Section 3.4, we provide detailed description about the initialization and adjustment sub-procedures.
The lookahead() and optimize() are in the Look-ahead Data and SegErr and Optimization
paragraph respectively.
E Implementation Details
All the experiments are conducted on a Linux server with an Intel Xeon Platinum 8163 2.50GHz
CPU. We first introduce more details and the implementation of baseline learned index methods.
MET (Ferragina et al., 2020) fixes the segment slope as the reciprocal of the expected key interval,
and goes through the first available data point for each segment. FITing-Tree (Galakatos et al., 2019)
adopts a greedy shrinking cone algorithm and the learned segments are organized with a B+-tree.
Here we use the stx::btree (v0.9) implementation (Bingmann, 2013) and set the filling factors of
inner nodes and leaf nodes as 100%, i.e., we adopt the full-paged filling manner. Radix-Spline (Kipf
et al., 2020) adopts a greedy spline interpolating algorithm to learn spline points, and the learned
spline segments are organized with a flat radix table. We set the number of radix bits as r = 16 for
the Radix-Spline method, which means that the leveraged radix table contains 216 entries. PGM
(Ferragina & Vinciguerra, 2020b) adopts a convex hull based algorithm to achieve the minimum
number of learned segments, and the segments can be organized with the help of binary search,
CSS-Tree (Rao & Ross, 1999) and recursive structure. Here we implement the recursive version
since it beats the other two variants in terms of indexing performance.
We then describe a few additional details of the proposed framework in terms of the e-learner
initialization and the hyper-parameter setting. For the w1,2,3 of the e-learner shown in the Eq. (2), at
the beginning, we learn the first five segments with the e sequence [箱1"弓2?, 4<≡], then track their
rewarded SegErri and update the parameters w1,2,3 using least square regression. We empirically
15
Under review as a conference paper at ICLR 2022
found that this light-weight initialization leads to better index performance compared to the versions
with random parameter initialization, and it benefits the exploration of diverse e*, i.e., leading to
the larger variance of the dynamic sequence [1 , . . . , i, . . . , N]. As for the hyper-parameter ρ
(described in the Section 3.4), we conduct grid search over ρ ∈ [0.1, 0.4, 0.7, 1.0] on Map an IoT
datasets. We found that all the ρs achieve better space-error trade-off (i.e., smaller AUSEC results)
than the fixed e versions. Since the setting ρ = 0.4 achieves averagely best results on the two datasets,
we set ρ to be 0.4 for the other datasets.
F Dataset Details
Our framework is verified on several widely adopted datasets having different data scales and
distributions. Weblogs Kraska et al. (2018); Galakatos et al. (2019); Ferragina & Vinciguerra (2020b)
contains about 715M log entries for the requests to a university web server and the keys are log
timestamps. IoT Galakatos et al. (2019); Ferragina & Vinciguerra (2020b) contains about 26M event
entries from different IoT sensors in a building and the keys are recording timestamps. Map dataset
Kraska et al. (2018); Galakatos et al. (2019); Ding et al. (2020); Ferragina & Vinciguerra (2020b); Li
et al. (2021) contains location coordinates of 1.8M places that are collected around the world from
the Open Street Map OpenStreetMap contributors (2017), and the keys are compound by coordinates
as longitude + 90 ∙ latitude. Lognormal Ferragina & Vinciguerra (2020b) is a synthetic dataset
whose key intervals follow the lognormal distribution: ln(Gi)〜N(μig, σ,). To simulate the varied
data characteristics among different localities. We generate 20M keys with 40 partitions by setting
μlg = 1 and setting σlg with a random number within [0.1, 1] for each partition.
We normalize the positions of stored data into the range [0, 1], and thus the key-position distribution
can be modeled as Cumulative Distribution Function (CDF). We plot the CDFs and zoomed-in CDFs
of experimental datasets in Figure 7 and Figure 8 respectively, which intuitively illustrate the diversity
of the adopted datasets.
Figure 7: CDFs of adopted datasets.
Figure 8: Zoomed-in CDFs of adopted datasets.
Zoomed-in MaP
0.660-
0.655-
0.650-
0.645-
0.640-
3250 3260 3270 3280 3290 3300
Key
G Additional Experimental Results
Overall Index Performance. For the space-error trade-off improvements and the actual querying
efficiency improvements brought by the proposed framework, we illustrate more space-error trade-
off curves in Figure 9 and querying time results in Figure 10. Recall that the N -MAE trade-off
curve adequately reflects the index size and querying time: (1) the segment size in bytes and N are
only different by a constant factor, e.g., the size of a segment can be 128bit if it consists of two
16
Under review as a conference paper at ICLR 2022
double-precision float parameters (slope and intercept); (2) the querying operation can be done in
O(IOg(N) + log(∣y - y |) as We mentioned in Section 3.1, thus a better N-MAE trade-off indicates
a better querying efficiency. From these figures, we can see that the dynamic versions of all the
baseline methods achieve better space-error trade-off and better querying efficiency, verifying the
effectiveness and the Wide applicability of the proposed frameWork.
Weblogs Dataset
8-
M4
IoT Dataset
100
755025
avn
Map Dataset
125
≡755o25o
vn
0	200	400	600	800	1000
N
Lognormal Dataset
Ooooo
0 8 6 4 2
O-,	，	，-一
6	1OO∞ 20∞0	30000
N
IoT Dataset
0	20000	40000	60000
N
Weblogs DataSet
O 200	400	600 800 IOOO
N
Map Dataset
2501-----------ε---------------
200
2000	4000	6000	8000 100∞
N
Map Dataset
Oooo
5 0 5
1 1
VN
150
12.5
e=256
——PGM, Original
....PGM, Dynamic e
U O
U 5
VFJ
Ooo
5 0 5
1 1
3VW
0
0
10000 20000 30000 40000 50000
N
Weblogs Dataset
o.o
0	500	1000	1500
N
o
2000	4000	6000	8000 10000
N
Lognormal Dataset
2000 4000 6000 8000 10000
N
2000	4000	6000	8000
N
Lognormal Dataset
5 O
7 5
vw
0-
0	10000	20000	300∞
N

Figure 9:	The additional space-error trade-off curves for learned index methods.
Ablation Study. To examine the necessity and the effectiveness of the proposed frameWork, in
Section 4.3, We compare the proposed frameWork With three dynamic variants for the FITing-Tree
method. Here We demonstrate the AUSEC relative changes for the Radix-Spline method With the
same three variants in Table 4 and similar conclusions can be draWn.
Table 4: The AUSEC relative changes of dynamic variants compared to the Radix-Spline method
With the proposed frameWork.
I Weblogs		IoT	Map	Lognormal	Average
Random e	+81.23%	+74.78%	+59.20%	+83.16%	+74.59%
Polynomial Learner	+56.20%	+53.28%	+7.01%	+55.01%	+42.88%
Least Square Learner	-9.56%	+9.81%	+0.58%	-11.23%	-2.60%
Theoretical Validation. In Section 4.4, We shoW that all the learned index baseline methods learn
similar segment slopes on the Map dataset. Here We illustrate the learned slope results on the IoT,
Weblogs and Lognormal datasets in Figure 11, Which supports the Theorem 2 that the learned segment
slopes concentrate on the 1∕μ% with a bounded relative difference.
17
Under review as a conference paper at ICLR 2022
Besides, for the comparison between the theoretical bounds and the actual SegErri of all the adopted
learned index methods, we show more results on another two datasets Gamma and Uniform in Figure
12, where the key intervals of the two datasets follow gamma distribution and uniform distribution
respectively. These results show that the MET method gains actual SegErri within the bounds,
verifying the correctness of the Theorem 1 again. Here all the learned index methods also achieve the
same trends, showing that these methods have the same mathematical forms w.r.t. the SegErri,
and μ∕σ, and hence the e-learner can effectively learn the estimator and adaptively choose suitable e.
Oooooooo.
83838383
3 3 2 2 1 1
(as>3s XOPUI
MaP DataSet
小 e=16
爸=16
e=32
三32 X
×MET, Original
▲ MET, Dynamic ε
ε= 64
e=64
X	e=128
盟 128 X 占256 e=256
1250	1300	1350	1400
Querying Time (ns)
WeblogS DataSet
(国。as XOPUI
1,006
1,001
996
991
986
e=2
×
▲
已2
XRadiX-SPline, Original
▲Radix-Spline, Dynamic ε
e=4
A×
e=4	e=8
X X
a8	已 16	f=32 ɪ
e=32
×
500	600	700	800	900	1000	1100
Querying Time (ns)
Map Dataset
(亶 ∞ISXUPOI
so
45
40
35
30
25
× Radix-Spline, Original
ARadix-Spline, Dynamic e
× e=64
6=128
A×	“A
心 128	056
400 410 420 430 440 450 460 470 ‹480 490 500
Qucaying Time (ns)
(图。zsXOPUI
Oooooooooo
Oooooooooo
αM7αl
(图əz-s XOPUI
(图。as 版PUl
×MET, Original
▲MET, Dynamic ε
Lognormal DataSet	.
2<£=16
=16	----------:-------
X MET, Original
▲MET, Dynamic ε
£=32
e=32	£=64	e=128
C= 64 ʌ X 段 128 * X 段 256, ɛ=256
1250	1350	1450	1550	1650	1750
Querying Time (ns)
IoT Dataset
XRadiX-SPline, Original
▲ Radix-Spline, Dynamic ε
▲
於=16
e=32
X
▲	e=64
己 32	X	ɛ=128 =256
¢=256
於=64 f=128 £ 256 X
900
700	900	1100	1300	1500	1700
Querying Time(ns)
Lognormal DataSet
1,540
S, 1,440
飞 1,340
而 1,240
S
W 1,140
1,040
940
X e=16
ε= 164
▲
E=32
XRadiX-SPline, Original
▲Radix-Spline, Dynamic ε
e=32
×
E= 64
£=64	e=128 e=256
xf=128 X E=256 X
700	800	900 1000 1100 1200 1300 1400 1500 1600
Quelying Time(ns)
WeblogS DataSet
IoT DataSet
(禺3-S XOPUI
108 6 4 2 O
XPGM, Original
▲ PGM, DynamiC ε
64
ε= 64 ×ve=128
^= 128 x≡256ΛK
ε=256
850	950	1050
lfe一 m
— — — — — —
L
6 5 4 3 2 1
(as>3s XOPUI
爸=128
e=128
e=256
X	3256	×
XPGM, Original
▲ PGM, Dynamic ε
Querying Time (ns)
i00	1350	1400	1450
Querying Time(ns)
6
&
Lognormal DataSet
(as>3-s XOPUI
10007000
× PGM, Original
▲ PGM, DynamiC ε
(图ə-s XOPUI
XPGM, Original
▲ PGM, DyramiC ε
X	e=128	”，£=256
20E300-	1400 f= 216o0-ʒ
Querying Time (ns)
Figure 10:	Improvements in terms of querying time for learned index methods with dynamic .
18
Under review as a conference paper at ICLR 2022
Figure 11: Learned slopes on the IoT, Weblogs and Lognormal datasets.
40
5-
35
Gamma, k = 1.0, θ = 1.0
0 5 0 5 0
3 2 2 1 1
(J宙ss)oq
100	200	300	400
Gamma, k = 2.0, θ = 3.0
5 0 5 0 5 0 5
3 3 2 2 1 1
(J宙θs)Oq
100	200	300	400
Gamma, k = 3.0, θ = 6.0
5 0 5 0 5 0 5
3 3 2 2 1 1
(J宙θs)Oq
100	200	300	400
Uniform, low
35
e
0.0, high = 1.0
0 5 0 5 0
3 2 2 1 1
(J亩əs)Oq
100	200	300	400
e
35
Uniform, low
40	,
e
0.0, high = 10.0
0 5 0 5 0
3 2 2 1 1
(J亩əs)Oq
100	200	300	400
e
0 5 0 5 0
3 2 2 1 1
(J亩Məs)MOq
35
,m, low
e
10.0, high = 100.0
100	200	300	400
e
Figure 12: Illustrations of the derived bounds on Gamma and Uniform datasets.
19