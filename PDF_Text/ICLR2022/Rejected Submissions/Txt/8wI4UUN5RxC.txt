Under review as a conference paper at ICLR 2022
Variational Inference via Resolution of Singu-
LARITIES
Anonymous authors
Paper under double-blind review
Ab stract
Predicated on the premise that neural networks are best viewed as singular statisti-
cal models, we set out to propose a new variational approximation for Bayesian
neural networks. The approximation relies on a central result from singular learn-
ing theory according to which the posterior distribution over the parameters of
a singular model, following an algebraic-geometrical transformation known as a
desingularization map, is asymptotically a mixture of standard forms. From here
we proceed to demonstrate that a generalized gamma mean-field variational family,
following desingularization, can recover the leading order term of the model evi-
dence. Affine coupling layers are employed to learn the unknown desingularization
map, effectively rendering the proposed methodology a normalizing flow with the
generalized gamma as the source distribution.
1 Introduction
Singular statistical models are ubiquitous in modern machine learning. In contrast to their regular
counterpart, singular models need not be identifiable nor possess a positive-definite Fisher information
matrix. These departures from classic regularity conditions have considerable implications for both
theory and practice. Since neural networks are (strictly) singular models, accounting for such
differences may be critical to some of the most pressing challenges in deep learning theory including
model selection and the generalization puzzle (Murfet et al., 2020).
In this work, singular learning theory (Watanabe, 2009) is brought to bear on the challenge of
performing inference in Bayesian neural networks (MacKay, 1992; Neal, 1996). In particular,
singular learning theory helps us understand the large-sample properties of the posterior distribution
over neural network weights w ∈ Rd . By (Watanabe, 2018, Chapter 6), there exists a so-called
desingularization map (also known as a resolution map), g : Rd → Rd , g(ξ) = w, such that when
n is large, the posterior distribution in a local weight set is proportional to
exp(-nξ2k1 ξ2k2 …ξdkd)∣ξh1 …ξhd ∣b(ξ).	(1)
The k's and h's are natural numbers, and b(∙) is a real-valued C∞ function.
We say the posterior distribution has been put into standard form if coordinates ξ have been found
that allow the posterior to be locally written as in equation 1. Remarkably, it is possible under very
general conditions to write the posterior distribution over the parameters of a singular model as just
such a mixture of standard forms. Based on equation 1, we proceed to demonstrate that a certain
mean-field variational family, following desingularization, can recover the leading order term of the
log (normalized) evidence, up to constant terms that do not depend on sample size n or dimension d.
Let (x, y) denote the input-target pair modeled jointly as p(x, y|w) = p(y|x, w)p(x). Let us assume
the parameter space W is a compact set in Rd andp0(x, y) = p0 (y|x)p(x) is the true data-generating
mechanism. Throughout we suppose there exists w0 ∈ W such that p0(y|x) = p(y|x, w0). In
the parlance of singular learning theory, this condition is known as realizability. Let 夕(W) be a
compactly-supported prior. We shall refer to (p(∙, ∙),po(∙, ∙), O as a model-truth-prior triplet.
Define K(w) to be the Kullback-Leibler divergence between the truth and the model, as a function of
the model parameters w :
K(w) = KL(p0(x, y)||p(x, y|w)) = Ep0 log
po (yIx)
p(y∣χ,w)
1
Under review as a conference paper at ICLR 2022
Following Watanabe (2009), we say a model is regular if it is 1) identifiable i.e., {w : K(w) = 0} is
a singleton, and 2) its Fisher information matrix I(w) is positive definite for arbitrary w ∈ W. We
call a model strictly singular if it is not regular. The term singular will refer to either regular or
strictly singular models.
Henceforth let p(y|x, w) be a neural network model. We wish to approximate the intractable posterior
distribution over neural network weights, p(w∣Dn) = "i=1 叱|：),W)Rw) ,where Dn = {(χi,yi)}n=ι
is a dataset of n input-output pairs. The normalizing constant, Z(n) = J Qn=ιp(yi∣xi, W)夕(W) dw,
is variously known as the (model) evidence and the marginal likelihood.
The asymptotic expansion of ZK(n), a variant of Z(n) defined in equation 5, will prove crucial to
justifying the proposed variational approximation. For strictly singular models, quantities such as
Z(n) and ZK (n) manifest as a singular integral, i.e., an integral of the form JW e-nf (W)夕(W) dw
where W ⊂ Rd is a compact semi-analytic subset, and f and 夕 are real analytic functions. The
behavior of a singular integral critically depends on the zeros of f.
2 Variational inference for singular models
Variational inference is an approximate inference technique in which a family of densities Q, often
called the variational family, is first posited and a member of the variational family, some q* ∈ Q, is
then found via optimization according to some criterion that measures closeness to the desired target
density. To begin, let us write the posterior distribution p(W|Dn) in two alternate forms:
1n
Ln(W) = -— Elog p(yi∣χi,w)
n i=1
p(w∣Dn) H e-nLn(W)夕(W)
Z(n) = / e-nLn(W)P(W) dW
1 n	p0(yi|xi)
n W - n i=i θg p(yi∣χi, w)
p(W|Dn) H e-nKn(W)P(W)
Z(n) = / e-nKn(W)ψ(w).
On the left, the posterior is written in terms of the average negative log likelihood Ln(W) and on the
right in terms of the average log likelihood ratio Kn(W), which is the empirical counterpart to K(W).
Since Z(n) = Z(n)/ Qn=ι Po(yi∣Xi), we refer to Z(n) as the normalized evidence.
Now, consider some general change of variables g : Rd → Rd, g(ξ) = W. In the new coordinate ξ,
the KL divergence between a variational distribution q(ξ) and the desired posterior target,
p(ξ∣Dn) H e-nKn(O(G)以g(ξ))∣g0(ξ)∣,
is given by
KL(q(ξ)“p(ξlDn)) = Eq nKn (g(ξ)) + kL(q(ξ) Hp(g(ξ)) |g0 (ξ)D +log Z(n).
As long as the support of q is contained in the support of the posterior, we have KL(q(ξ) ∣∣p(ξ∣Dn)) ≥
0 and hence the following bound:
ψ(q,g) := -EqnKn(g(ξ)) -KL(q(ξ)l3(g(ξ))lg0(ξ)D ≤ logZ(n).	(2)
Equality in equation 2 is achieved if and only if q(ξ) = p(ξ∣Dn). It is easy to recognize that
maximizing Ψ(q, g) is equivalent to maximizing the so-called evidence lower bound,
n
ELBO(q, g) :=Eq Xlogp(yi∣Xi,g(ξ)) - logq(ξ) + log(p(g(ξ))∣g0(ξ)∣) ,	(3)
i=1
since Ψ(q, g) = ELBO(q, g) + nSn where Sn = -n Pn=ι logP0(yi∣Xi) is the empirical entropy.
Indeed, just as Ψ(q,g) is a lower bound on the log (normalized) evidence log Z(n), so too is
ELBO(q, g) a lower bound on the log (unnormalized) evidence log Z(n).
To facilitate theoretical analysis, we will work with the deterministic counterparts to Ψ(q, g) and
,Z(n), respectively given by
ψκ(q,g) := -EqnK(g(ξ)) - κL(q(ξ)llP(g(ξ))lg0(ξ)1),	(4)
2
Under review as a conference paper at ICLR 2022
and

ZK (n):
(5)
It is plain to see thatjust as Ψ(q, g) ≤ log Z(n), We have ΨK(q, g) ≤ log ZK(n). Our theoretical
results address the possibility that suPq∈Q Ψk(q, g) ≈ log ZK(n) for some variational family Q
and change-of-variables g.
By (Watanabe, 2009, Theorem 6.7), for the leading order term in the asymptotic expansion of ZK (n),
We have
ZK(n) ≈ Cn-λ(logn)m-1.	(6)
The rational number λ ∈ [0, d/2] is an important quantity in singular learning theory knoWn as the
real log canonical threshold (RLCT) and the integer m ≥ 1 is its associated multiplicity. These tWo
quantities, to be defined in equation 11, are uniquely associated to a model-truth-prior triplet.
Equipped With equation 6, (Bhattacharya et al., 2020, Theorem 3.1) established that When g is a
resolution map, the mean-field variational family Q(0,1] of equation 12 can achieve
sup ΨK(q, g) ≥ -λ log n - constant independent of n.	(7)
q∈Q(0,1]
(In Appendix C, We prove this result under more general conditions than assumed in Theorem 3.1 of
Bhattacharya et al. (2020).) Unfortunately, the bound in equation 7 provides little reassurance that
Q(0,1] is a desirable variational family.
Contribution Following Lin (2011), let US call C in equation 6 the leading coefficient of ZK(n).
We go beyond the analysis in Bhattacharya et al. (2020) by taking into account those terms in the
leading coefficient that depend on the dimension d, call it C(d). Our main result, Theorem 5.1, shows
that if g is a resolution map, then the same variational family Q(0,1] of equation 12 can achieve
sup ΨK (q, g) = -λlogn+logC(d).	(8)
q∈Q(0,1]
Next, rather than presuming the resolution map theoretically tractable as in Bhattacharya et al. (2020),
we employ a normalizing flow to learn the unknown resolution map g at the same time as learning
the variational parameters in q. We are aided by the fact that a resolution map can attain the optimal
value of ΨK (q, g) and therefore justifies learning the resolution map via optimization of Ψ(q, g).
Finally let us note that although the result in equation 8 is stronger than that in equation 7, it does
come at the cost of additional assumptions as we will discuss at the end of Section 5.
Remark. When the model is regular, we need not bother with singular learning theory and may obtain
ZK(n) ≈ 夕(wo) Jdet2∏)W°)n-d/2 via the Laplace approximation. The Laplace approximation,
however, is egregiously inappropriate for singular models, in particular neural network models.
Since λ = d/2 and m = 1 in regular models, equation 6 is a true generalization of the Laplace
approximation, holding for both regular and strictly singular models.
3	Singular learning theory
That the posterior distribution in singular models can be written, under quite general conditions, as a
mixture of standard forms is predicated on the monomialization of K(w). The following theorem
from Watanabe (2009), adapted for notational consistency, gives precise conditions for the existence
of the resolution map, an algebraic geometrical transformation such that K(w) can be written as a
monomial. The result is itself based on Hironaka’s resolution of singularities, a celebrated result in
modern algebraic geometry. To prepare, let W = {w ∈ W : K(w) ≤ } for some small positive
constant and W(R) be some real open set such that W ⊂ W(R) . The theorem below will make use
of the multi-index notation: for a given W = (wι,..., Wd) ∈ Rd, define wk := WkI …Wkd where
the multi-index k = (k1, . . . , kd) with each kj a nonnegative integer.
Theorem 3.1 (Theorem 6.5 of Watanabe (2009)). Suppose the model-truth-prior triplet (p,po,夕)
satisfies Fundamental Conditions I and II with s = 2 in Watanabe (2009). We can finda real analytic
manifold M(R) and a proper and real analytic map g : M (R) → W(R) such that
3
Under review as a conference paper at ICLR 2022
1.	M = g-1(W) is covered by a finite set M = ∪αMα where Mα = [0, b]d.
2.	In each Mα,
κ(g(ξ)) = ξ2k = ξ2k1 …ξ2kd,	(9)
where kj ∈ N such that not all kj are zero.
3.	There exists C∞ function b(ξ) such that
以g(ξ))∣g0(ξ)l = ξhb(ξ) = ξh1 …ξhdb(ξ),	(10)
where hj ∈ N, ∣g0(ξ)∣ is the absolute value ofthe determinant ofthe Jacobian and b(ξ) >
c > 0 for ξ ∈ [0, b]d.
If We “plug in" equation 9 and equation 10 into the transformed posterior p(ξ∣Dn), We obtain the first
display of the paper, equation 1. Theorem 6.5 of Watanabe (2009) holds for regular statistical models
as well, e.g., by the transform W = g(ξ) = wo + I(wo)1∕2ξ, we can put a regular model-truth-prior
triplet into the standard form. It is Worth noting that neither the resolution map g nor the multi-indices
k and h are unique for a given triplet (p, po,夕).
A crucial quantity that appears in singular learning theory is the real log canonical threshold (RLCT).
Let {Mα : α} be as in Theorem 3.1 and λj = h2+ ,j = 1,...,d where hj and kj are the entries
of the multi-indices h and k in a local coordinate Mα. (For brevity, the dependence on α has been
suppressed.) When kj = 0, λj is taken to be infinity. Uniquely associated to a triplet (p,po,中)are
its real log canonical threshold (RLCT) and its multiplicity defined, respectively, as
λ = min min λj, m = max #{j : λj = λ}.	(11)
α j∈1,...,d	α
Let {α*} be the set of those local coordinates in which both the min and max in equation 11 are
attained. Watanabe (2000) calls such a set the essential coordinates.
Assuming the prior is proper, the RLCT of a model-truth-prior triplet is at most d/2 (Watanabe, 2009,
Theorem 7.2). When the model is regular, the RLCT is exactly equal to d/2 and the multiplicity
m = 1 (Watanabe, 2009, Remark 1.15). Murfet et al. (2020) argues that (twice) the RLCT might be a
most natural count of parameters in singular models. In Appendix A, we recall a simple toy example
where the resolution map, the RLCT, and the multiplicity can be calculated explicitly.
Remark. In Section 6, we will learn the resolution map using affine coupling layers. However as
indicated by Theorem 3.1, the resolution map g(ξ) as well as the multi-indices k and h in fact depend
on α. Despite this, it is unclear if learning multiple resolution maps gα would have any practical
advantages since the RLCT is determined entirely by the essential local coordinates.
4	Related work
Bayesian learning in neural networks well precede the advent of modern deep learning MacKay
(1992); Neal (1996). The resurgence of interest in Bayesian learning for deep neural networks,
sometimes called Bayesian deep learning Wilson & Izmailov (2020), has been prompted by con-
cerns of overconfidence and miscalibration. Since exact inference for Bayesian neural networks is
intractable, all methods proceed by approximate inference. A major class of approximate inference
techniques is based on scaling classic MCMC to modern settings of large datasets and deep neural
networks. Some scalable variants of MCMC suitable for deep neural networks include Welling &
Teh (2011); Chen et al. (2014); Zhang et al. (2019). Another major approximate inference technique
for Bayesian neural network is represented by variational inference which learns the target posterior
via optimization. The various flavors of variational inference can be commonly characterized by two
ingredients: 1) an approximating family, e.g., a class of distributions over the neural network weights
and 2) a criterion for measuring closeness of two distributions. The most commonly employed
approximating family is undoubtedly the mean-field family of fully factorized Gaussian distributions.
Many variational inference techniques share this approximating family even if they use different
criterion to measure closeness to the target (Graves, 2011; Blundell et al., 2015; Hernandez-Lobato
et al., 2016; Li & Turner, 2016; Khan et al., 2018; Sun et al., 2019). The limitations of the mean-field
Gaussian approximating family are well known however (MacKay, 1992). The desire to move beyond
4
Under review as a conference paper at ICLR 2022
mean-field Gaussian has motivated many recent methods to make use of more realistic covariance
structures (Zhang et al., 2018) or more expressive approximating families, e.g., via normalizing flows
(Louizos & Welling, 2017). Monte Carlo dropout (Gal & Ghahramani, 2016) is another popular
approximate inference technique for Bayesian neural networks which, despite first appearances, can
in fact be viewed as variational inference. Another strain of work is based on the idea of using
stochastic gradient descent as a sampler for the underlying posterior distribution of interest. Works
in this spirit include Mandt et al. (2018), Izmailov et al. (2018) and Maddox et al. (2019). Finally
there are various approximate inference techniques for Bayesian neural networks that are not easily
classifiable according to the distinctions above, e.g., temperature scaling (Guo et al., 2017) and deep
ensembles (Lakshminarayanan et al., 2017).
5	The generalized gamma mean-field approximation
Consider the mean-field variational family proposed in Bhattacharya et al. (2020)
d
Q(0,1] = {qλ,k,β = Y qλj,kj,βj (ξj) ： λ = (λι,...,λd) ∈ R>0, k = (kι,…，kd) ∈ R>0, β = (βι,.
j=1
qj(ξj) := qλj,kj,βj (ξj) Y ξjkjλj-1 exp(-βjξjkj )1(0,i](ξj),	(12)
where each univariate density qj supported on (0, 1] is the density of a truncated generalized gamma
random variable. Let j* ∈ {1,...,d} be the dimension that attains λj* = λ where λ is the RLCT of
the underlying (unknown) model-truth-prior triplet. It was established in Bhattacharya et al. (2020)
that if g is a resolution map, then Q(0,1] satisfies equation 7 in particular by setting λ and k to their
respective true values, and βj* = n and all other βj = 1.
In Theorem 5.1 below we will instead establish equation 8. In the proof we show this can be
accomplished by setting λ and k to their true values as in Bhattacharya et al. (2020) though the
optimal values of β will be different. Finally, although we assume below that m = 1, this is not
necessary; as long as m《d, we can set βj = n1/m for all j such that λj = λ.
Theorem 5.1. Suppose the model-truth-prior triplet is such that Theorem 3.1 holds with [0, b] = [0, 1],
SE
K (g(ξ)) = ξ2k and 夕(g(ξ))∣g0(ξ)∣ = ξh. Let 入 denote the RLCT of the triplet and assume the
multiplicity m = 1. Then supq∈Q ΨK (q, g) = -λ logn + log C(d) where C(d) is the term in
the leading coefficient C that depends on d.
.,βd) ∈ (0,∞)d}
Proof. If ξ ∈ [0,1]d and 夕(g(ξ))∣g0(ξ)∣ H ξh, then necessarily b(ξ) = Q；=11∕(hj + 1). Let
λj = (hj + 1)∕(2kj). Applying Corollary 5.9 in Lin (2011), we obtain
ZK (n)
~ ~
~
~
[0,1]d
exp(-nξ2k)ξh dξ ≈ Cn-λ (log n)m-1 = Cn-λ
(13)
where
~
C =__________________Γ(λ)__________________
.
(m -I) ! Qj = 1(2⅛j) Qj=m+1(2⅛j ∖6j-λ
(14)
If we denote by C (d) the terms in the leading coefficient that depend on d, then we have
d	d	dd
log C(d)	= - X log(2⅛j)	- X log(2%∙) - X log λj- X log(1	- Λ∕Λj).
j=1	j=m+1	j=m+1	j=m+1
Returning to our variational distribution, if the kj’s are well specified and we additionally set βj* = n
where j* is the dimension that attains λj* = λ, we then have EqnK(g(ξ)) = λj* j 6=j* G(λj , βj ),
5
Under review as a conference paper at ICLR 2022
where G(λ, β) is as in B.1. Next, we have
d
KL(q(ξ)lk(g(ξ))∣g0(ξ)l) = KL(q ∣∣ ξhb(ξ)) = XKL(q∕∣ ξj/(hj + 1))
j=1
d
=EEqjlog qj - h j Eqj log ξj + log(hj + 1).
j=1
If in addition the λj ’s are all well-specified, then
d
KL⑷Ing(W)Ig (WI) = E 卜 βj∙G(Xj,β) - log B(kj,h j,β) + log(2⅛j )+log λj],
j=1
where B(k, h, β) is as in B.1. Now let us make use of the fact that log B(k, h, β)	-λlogβ and
G(λ, β) N λ∕β for large β. Since βj∙* = n is large, We get
d
ΨK (q, g) =	-λX	G(λXj, βj)	+	βjG(λXj, βj)	+ log B(kXj, Xhj,	βj)	- log(2kXj)	- log λXj
j 6=j*	j =1
d	d	dd
N -λX log n +	λX(1 -	G(λXj, βj))	+	[βj G(λXj, βj) + log B(kXj, Xhj, βj)]	-	log(2kXj) -	log(λXj).
j=m+1	j=m+1	j=1	j=1
If βj are sufficiently large for j = j*,we get
dd	d	d
ΨK (q, g) N -λX log n - X log(2kXj) - Xlog(λXj) + X λXj(1 - logβj) + λX(1 - Y
j=1	j=1	j=m+1	j=m+1
(15)
Then there exist βj,j = j* so that equation 15 matches -λlog n + log C(d).	□
Theorem 5.1 critically assumes that b(ξ) 8 1. We do not expect this to hold in reality. For example,
even for the simple one-hidden layer tanh network considered in Section 7, it does not appear that
b(ξ) 8 1 (Watanabe, 2000). Currently, we are prevented from stating a more general version of
Theorem 5.1 because there is no off-the-shelf derivation of the leading coefficient when the singular
integral is of the general form [0,b]d exp(-nξ2k)ξhb(ξ) dξ. We expect the generalization to be
technically feasible but as its development requires advanced knowledge of algebraic geometry, it is
beyond the scope of this paper and best left as separate investigation.
In the next section, we proceed to learn the resolution map rather than presume it is known. This is
an improvement over Bhattacharya et al. (2020) which, due to the difficulty of deriving resolution
maps, was limited in its single experiment to the toy neural network fw(x) = b tanh(ax) with weight
w = (a, b) ∈ R2. Again, though Theorem 5.1 is stated in terms of the truncated generalized gamma
mean-field family, we do not believe the assumption b(ξ) b 1 is critical and proceed henceforth to
work with the untruncated generalized gamma mean-field family, which we denote Q.
6	Learning to desingularize
When the resolution map g is known, the preceding results suggest to 1) apply the change-of-variables
g(ξ) = w and 2) maximize ELBO(q, g) over the untruncated generalized gamma mean-field family
Q via e.g., stochastic gradient descent. However, theoretically, the resolution map g is notoriously
difficult to derive. Computationally, the recursive blow-up procedure in algebraic geometry is entirely
not scalable to high dimensions.
We propose to learn the resolution map via a normalizing flow, which is commonly used to model
complex distributions as the push-forward of a simple source distribution through an invertible neural
network G. An interesting direction of future work would be to exploit properties of the resolution
6
Under review as a conference paper at ICLR 2022
map that may aid in the design of the normalizing flow architecture. For now, we simply make use
of a common type of invertible architecture consisting of affine coupling layers. With r denoting a
binary mask, a so-called affine coupling layer acts as follow:
u, v ∈ Rd, u 7→ v = (1 - r)	u + r (u	exp(s(r	u)) + t(r u)).
The binary mask r must alternate from one affine coupling layer to the next for otherwise there would
be little expressive power in the resulting network. Let Gθ be a network consisting of alternating
affine coupling layers, where θ denotes the collective parameters. Since the resolution map is to be
learned, there is no loss in generality to assuming j* = 1. We shall need the gradient with respect to
the variational parameters and the normalizing flow weights as part of employing stochastic gradient
descent, i.e. ▽入,k,β,θELBO(qχ^β, Gθ)∙ Note that here we abuse the notation slightly as we do not
need to update β1 which should be set to the sample size n according to the proof of Theorem 5.1.
Although the source distribution in a normalizing flow can have its own trainable parameters, it is
common practice to adopt a parameter-less source distribution. In particular if the source distribution
is itself reparametrizable, then the learning of the associated parameters can be absorbed into the
invertible transformation. The generalized gamma distribution is not easily reparametrizable for
general values of λ, k, β. However for certain settings of λ, we can in fact avail ourselves to the
reparametrization trick, at least approximately. Let Vj be a gamma random variable with shape
λj and rate βj, then Vj1/(2kj) 〜qj(ξj):= MkjN- exp(-βjMkj)1(o,∞)(ξj)∙ We will mostly be
interested in settings where λj is large, in which case Vj is approximately Gaussian with mean λj /βj
and variance λj∙/βj. Letting T(e) := (F-I(Eι)1∕(2k1),..., F-1(Ed)1∕(2kd)), where F-1(e) ≈
(λj + λjE)e)/βj, the reparametrization trick then leads to the objective function
n
Ee〜N(0,I) ^X logMyi∣xi, Gθ (T(E))) + log P(Gθ(T(E))) + log ∣Gθ (T(E))I - Eq log q∙ (16)
i=1
Note that equation 16 is not the same as ELBO(qλ,k,β , Gθ) because we have made use of the
Gaussian approximation for Vj in the case of large λj .
The entropy component of equation 16, -Eqλ,k,β log qλ,k,β, can be derived analytically, see Ap-
pendix B.2. Next, the specific architecture of Gθ has rendered the log Jacobian term, log ∣Gθ(∙)∣,
computationally tractable. The final piece is to replace Ee〜N(o,ι)with an empirical average over M
samples. In the experiments that follow we will consider either learning the variational parameters
λ, k, β or fixing them at some initial value since other values can be learned through a transformation
that gets absorbed into G.
7	Experiments
In this section, we compare the effect of two source distributions for a normalizing flow given by the
affine coupling network Gθ consisting of 2 pairs of alternating couplings with scaling and translation
networks each consisting of 2 hidden layers with 16 hidden units, see Appendix D for exact details
of the architecture. We denote by nf_gamma_Xo_ko_eo_flag the variational family that results
from pushing forward the untruncated generalized gamma distribution with variational parameters
initialized at λ0 = (1, λ0, . . . , λ0), k0 = (k0, . . . , k0), and β0 = (n, β0, . . . , β0), and a boolean flag
indicating whether the variational parameters are subject to updating. For the other approximation
resulting from pushing forward a Gaussian source distribution N(μo,v0), we write analogously
nf_gaussian_Mo_vo where μo and vo are the fixed mean and variance. For each combination of
λo and βo considered, we set μo = λo/βo and vo = λo∕β2.
We employ the widely adopted variant of (minibatch) stochastic gradient descent known as Adam.
The number of epochs and batch size were set to 2000 and n/10, respectively. Different constant
learning rates were employed according to the parameter type: 1e-3 for affine coupling layer weights
and k, and 1e-1 for λ and β. Expectations in the objective function that are not analytically tractable
are replaced with an average over M = 5 samples. At the end of training, we evaluate Ψ(q, g)
in nf_gamma without recourse to the (approximate) reparametrization and by using the analytic
expression for the entropy component of Ψ and 100 samples from q to approximate other components
in Ψ under expectation.
7
Under review as a conference paper at ICLR 2022
ml. .1	♦	11	11	i~	11.	.1	♦	.	∙	1	.	1	. 1 τ⅛ ɪ CE T	1	1 . ∙	1 ∙
To date, there is a very small collection of model-truth-prior triplets where the RLCT λ and multiplicity
mare known. We shall limit our experiments to two such triplets. This will allow us to compare the
achieved Ψ(q, G) following training to -λ log n + (m - 1) log log n. Note that even in such triplets
where the RLCT and multiplicity are known, the exact value of the leading coefficient C is still
usually unknown. Now, to compare nf_gamma and nf_gaussian to each other, we can simply
see which achieves higher Ψ(q, G) after training.
Looking ahead to downstream tasks, it is natural to ask whether the variational posterior predictive
distribution, pvb(y∣χ, Dn) = hp(y∖χ, G^(ξ))}^(ξ), inherits the desirable properties of the Bayes
posterior predictive distribution, p(y|x, Dn) = hp(y|x, w)ip(w|Dn). The answer turns out to depend
on the relationship between the variational real log canonical threshold λvb and the RLCT of the
model-truth-prior triplet. It may very well be that a variational family which is closer to the true
posterior (in the KL sense) than another variational family may induce a worse approximation of the
true Bayes posterior predictive distribution. We provide an in-depth account of this phenomenon
through the lens of singular learning theory in Appendix E.
Our first example concerns the tanh model-truth-prior triplet. Consider input x ∈ R follow-
ing the uniform distribution on [-1, 1], and response variable y ∈ R modeled as p(y∖x, w) =
√2∏ exp(-2(y - f (x, w))2), where fw(x) = PhH=I bh tanh(ahx) is a tanh network with H hid-
den units and w is the collection of neural network weights {(ah , bh )}hH=1 . If the true distribution
is given by po(y∖x) = p(y∖x, 0) = √2∏ exp(-2y2) and the prior 夕 is a C∞ function of W with
compact support, satisfying 夕(0) > 0, Aoyagi & Watanabe (2006) showed that λ = H+j+i and
m= 2 if i2 = H, andm= 1 if i2 < H where i is the maximum integer satisfying i2 ≤ H. In
contrast, were this a regular statistical model, we would have λ = H. We consider two settings
for p0(y∖x) = p(y∖x, w0) in the experiment: 1) w0 = 0 and 2) w0 = 5. Note for the latter, the
corresponding RLCT and multiplicity are unknown.
Our next example is the reduced rank model-truth-prior triplet. Consider input x ∈ RM and response
variable y ∈ RN modeled as p(y∖x, W) = (2π)-N/2 exp{-ɪ ∖∖y-BAx∖∖2} where {w = (A, B)∖A ∈
RH ×M, B ∈ RN×H }. This model is readily seen to be a special case of a neural network with hidden
units H and identity activation function. We shall set M = H + 3 and N = H . In the realizable
case, i.e., po(y∖x) = p(y∖x, Ao, Bo), if the prior 夕 is a C ∞ function with compact support satisfying
夕(Ao, Bo) > 0, the RLCT was derived in Aoyagi & Watanabe (2005) for various values of N, M, H
and r = rank(BoAo). Below we set Bo = IN×N and Ao = [IH ×H ; JH×3]. The rank r for BoAo
equals H. This then falls under Case (3) in Aoyagi & Watanabe (2005) since N + H < M + r,
leading to λ = (NH - Hr + Mr)/2, m = 1. Note that were this a regular model, we would instead
have λ = (MH+NH)/2.
Table 1 provides a summary of the values ofH considered in each of the triplets and the corresponding
RLCT and dimension. In the experiments, we tested various combinations of values of H, settings
for Wo and priors. Throughout, the priors were designed to be mis-specified. The full results of these
experiments can be found in Tables 2-4. Note that the comparison between different variational
approximations have been made subject to the value of H, the prior, and the relationship λo∕βo = μo.
We should also point out that not all runs reached convergence as can be seen from the count column
in Tables 2-4. This seems largely to be a result of the constant learning rate we used for all training.
The first setting (Table 2) is the realizable tanh network with Wo = 0. In this case, the true RLCT
is known as discussed above. As Table 2 demonstrates, there is no clearly discernible difference
between nf_gamma and nf_gaussian where the source distribution for both starts near zero.
However when the source distribution has λo∕βo = μo = 5, i.e. very far from wo, nf_gamma is
more robust than nf_gaussian. The second setting (Table 3) is analogous to the previous except
the true generating mechanism is given by wo = 5. In this setting, the untruncated generalized
gamma source distribution is seen to provide a better variational approximation than the Gaussian
source distribution. This appears to hold quite independent of the initial values of λ, k, β as well as
the gradient flag. Interestingly, in contrast to the previous setting, there is a clear benefit to learning
λ, k, β. The third setting (Table 4) is the realizable reduced rank regression. In this experiment, we
do not see a discernible difference between the source distributions until we look at λo∕βo = μo = 5,
which is far from wo = (Ao, Bo). As in the first setting, we see nf_gamma is more robust than
nf_gaussian.
8
Under review as a conference paper at ICLR 2022
Finally, though we have cautioned against judging the quality of a variational approximation according
to the approximate posterior predictive distribution induced, it is nonetheless informative to visualize
downstream uncertainty quantification. In Figure 1, we choose one line from the tanh w0 = 0
experiment (Table 2) to further examine. For the two methods illustrated in in Figure 1, their
performance in terms of Ψ is quite close as indicated by Table 2. It is then comforting that the
respective confidence bands are quite similar. Next, in Figure 2, we choose one line from the tanh
w0 = 5 experiment (Table 3) to further examine. This time, nf_gamma achieves significantly better
Ψ than nf_gaussian. We see a corresponding relationship between their respective posterior
predictive distributions. Namely, the confidence band resulting from nf_gaussian are far too
conservative while that from nf_gamma is less so.
Figure 1: The model of interest is the tanh network with hidden units H = 576. The data is generated
according to p0 (y|x, w) = p(y|x, w0) where w0 = 0. The prior is taken to be N (5.0, 100.0Id). The
predictive distributions resulting from different variational approximations trained on a dataset of
size n = 5000 are displayed.
(b) nf_gamma_10_1_100_True
(a) nf_gaussian_5_5e-2
Figure 2: The model of interest is the tanh network with hidden units H = 576. The data is generated
according to p0 (y|x, w) = p(y|x, w0) where w0 = 5. The prior is taken to be N (0.0, 100.0Id). The
predictive distributions resulting from different variational approximations trained on a dataset of
size n = 5000 are displayed.
(b) nf_gamma_500_5_100_True
8	Conclusion
In this work we propose a variational approximation for Bayesian neural networks by leveraging
insights from singular learning theory. Namely, for large n, the posterior distribution over neural
network weights is not Gaussian but rather can be put into a mixture of standard forms. From this,
we demonstrate that the generalized gamma mean-field family, following desingularization, can
in theory achieve the leading order term of the log normalized evidence. Because we choose to
learn the desingularization map using affine coupling layers, the proposed work can be cast as a
normalizing flow with an unconventional source distribution. Interestingly, for large values of the
variational parameter λ, the source distribution in each dimension is approximately N(λ,λ∕β)1/(2k),
which is reparametrizable in terms of the conventional source distribution N(0, 1). Though learning
the variational parameters λ, k, β in the source distribution goes against conventional wisdom in
normalizing flows, our experiments suggest some performance may be gained by learning the optimal
untruncated generalized gamma source distribution at the same time as learning the resolution map.
9
Under review as a conference paper at ICLR 2022
Ethics S tatement
Bayesian learning for neural networks is often touted as a panacea to the challenges of uncertainty
quantification in deep learning. In this work, we propose a variational approximation that performs
well in terms of the ELBO achieved. However, we make no claim that our variational approximation
is superior in downstream uncertainty quantification. We explain extensively in the appendix that a
variational approximation which achieves higher ELBO may induce a worse approximate posterior
predictive distribution than a variational approximation which achieves lower ELBO. According to
singular learning theory, the performance of a variational approximation in terms of the posterior
predictive distribution it induces critically depends on the relationship between the variational RLCT
and the underlying RLCT of the model-truth-prior triplet.
Reproducibility Statement
A zip file of the source code has been submitted as supplementary materials. For theoretical results,
explanations of assumptions and proof of the claims are included in the main text. No datasets are
used; the experiments are solely based on simulated data.
References
Miki Aoyagi and Sumio Watanabe. Stochastic complexities of reduced rank regression in Bayesian
estimation. Neural Networks,18(7):924-933, September 2005.
Miki Aoyagi and Sumio Watanabe. Resolution of Singularities and the Generalization Error with
Bayesian Estimation for Layered Neural Network. IEICE Trans, pp. 2112-2124, 2006.
Anirban Bhattacharya, Debdeep Pati, and Sean Plummer. Evidence bounds in singular models:
Probabilistic and variational perspectives. arXiv:2008.04537 [math, stat], August 2020.
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight Uncertainty in
Neural Network. In International Conference on Machine Learning, pp. 1613-1622. PMLR, June
2015.
Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient hamiltonian monte carlo. In
Eric P. Xing and Tony Jebara (eds.), Proceedings of the 31st International Conference on Machine
Learning, June 2014.
Andrew Y. K. Foong, David R. Burt, Yingzhen Li, and Richard E. Turner. On the expressiveness of ap-
proximate inference in bayesian neural networks. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia
Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural Information Pro-
cessing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS
2020, December 6-12, 2020, virtual, 2020. URL https://proceedings.neurips.cc/
paper/2020/hash/b6dfd41875bc090bd31d0b1740eb5b1b-Abstract.html.
Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian Approximation: Representing Model
Uncertainty in Deep Learning. In Proceedings of The 33rd International Conference on Machine
Learning}, 2016.
Alex Graves. Practical variational inference for neural networks. In J. Shawe-Taylor, R. Zemel,
P. Bartlett, F. Pereira, and K. Q. Weinberger (eds.), Advances in Neural Information Processing
Systems, volume 24, pp. 2348-2356. Curran Associates, Inc., 2011.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural
networks. In Proceedings of the 34th International Conference on Machine Learning - Volume 70,
ICML’17, pp. 1321-1330. JMLR.org, 2017.
Naoki Hayashi. Variational Approximation Error in Bayesian Non-negative Matrix Factorization.
arXiv:1809.02963 [cs, math, stat], February 2020.
Jonathan Heek. Well-Calibrated Bayesian Neural Networks. PhD thesis, University of Cambridge,
2018.
10
Under review as a conference paper at ICLR 2022
Jose Hernandez-Lobato, Yingzhen Li, Mark Rowland, Thang Bui, Daniel Hernandez-Lobato, and
Richard Turner. Black-box alpha divergence minimization. In Maria Florina Balcan and Kilian Q.
Weinberger (eds.), Proceedings of the 33rd International Conference on Machine Learning, vol-
Ume 48 of Proceedings of Machine Learning Research, pp. 1511-1520, New York, New York,
USA, June 2016. PMLR.
T. Hosino, K. Watanabe, and S. Watanabe. Stochastic complexity of variational Bayesian hidden
Markov models. In Proceedings. 2005 IEEE International Joint Conference on Neural Networks,
2005., volUme 2, pp. 1114-1119 vol. 2, 2005.
Pavel Izmailov, Dmitrii Podoprikhin, T. Garipov, Dmitry P. Vetrov, and Andrew Gordon Wilson.
Averaging weights leads to wider optima and better generalization. Uncertainty in Artificial
Intelligence (UAI), 2018.
Mohammad Khan, Didrik Nielsen, Voot Tangkaratt, WU Lin, Yarin Gal, and Akash Srivastava. Fast
and scalable bayesian deep learning by weight-pertUrbation in adam. In International Conference
on Machine Learning, pp. 2611-2620. PMLR, 2018.
Masahiro Kohjima and SUmio Watanabe. Phase Transition StrUctUre of Variational Bayesian Non-
negative Matrix Factorization. In Alessandra Lintas, Stefano Rovetta, PaUl F.M.J. VerschUre, and
Alessandro E.P. Villa (eds.), Artificial Neural Networks and Machine Learning - ICANN 2017,
LectUre Notes in CompUter Science, pp. 146-154, Cham, 2017. Springer International PUblishing.
Ranganath Krishnan and Omesh Tickoo. Improving model calibration with accUracy versUs Uncer-
tainty optimization. arXiv:2012.07923 [cs], December 2020.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles BlUndell. Simple and Scalable Predictive
Uncertainty Estimation Using Deep Ensembles. In I. GUyon, U. V. LUxbUrg, S. Bengio, H. Wallach,
R. FergUs, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 30, 2017.
Yingzhen Li and Richard E. Turner. Renyi divergence variational inference. In Proceedings ofthe 30th
International Conference on Neural Information Processing Systems, NIPS’16, pp. 1081-1089,
Red Hook, NY, USA, 2016. Curran Associates Inc. ISBN 9781510838819.
Shaowei Lin. Algebraic Methods for Evaluating Integrals in Bayesian Statistics. PhD thesis,
University of California Berkeley, 2011.
Christos Louizos and Max Welling. Multiplicative Normalizing Flows for Variational Bayesian
Neural Networks. In International Conference on Machine Learning, 2017.
David J. C. MacKay. A practical Bayesian framework for backpropagation networks. Neural
Computation, 4(3):448-472, May 1992.
Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon Wilson.
A simple baseline for bayesian uncertainty in deep learning. In H. Wallach, H. Larochelle,
A. Beygelzimer, F. dAlche-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information
Processing Systems, 2019.
Stephan Mandt, Matthew D. Hoffman, and David M. Blei. Stochastic Gradient Descent as Approxi-
mate Bayesian Inference. arXiv:1704.04289 [cs, stat], January 2018.
Daniel Murfet, Susan Wei, Mingming Gong, Hui Li, Jesse Gell-Redman, and Thomas Quella. Deep
Learning is Singular, and That’s Good. arXiv:2010.11560 [cs], October 2020.
Shinichi Nakajima and Sumio Watanabe. Variational Bayes Solution of Linear Neural Networks and
Its Generalization Performance. Neural Computation, 19(4):1112-53, 2007.
Radford M. Neal. Bayesian Learning for Neural Networks, volume 118 of Lecture Notes in Statistics.
Springer New York, New York, NY, 1996.
Hippolyt Ritter, Aleksandar Botev, and David Barber. A scalable laplace approximation for neural
networks. In 6th International Conference on Learning Representations, ICLR 2018-Conference
Track Proceedings, 2018.
11
Under review as a conference paper at ICLR 2022
Shengyang Sun, Guodong Zhang, Jiaxin Shi, and Roger Grosse. Functional Variational Bayesian
Neural Networks. In International Conference on Learning Representations, 2019.
Kazuho Watanabe and Sumio Watanabe. Stochastic Complexities of Gaussian Mixtures in Variational
Bayesian Approximation. The Journal of Machine Learning Research, 7:625-644, December
2006.
Sumio Watanabe. Algebraic analysis for non-regular learning machines. In S. Solla, T. Leen,
and K. Muller (eds.), Advances in Neural Information Processing Systems, volume 12.
MIT Press, 2000. URL https://proceedings.neurips.cc/paper/1999/file/
752d25a1f8dbfb2d656bac3094bfb81c-Paper.pdf.
Sumio Watanabe. Algebraic Geometry and Statistical Learning Theory. Cambridge University Press,
USA, 2009.
Sumio Watanabe. Mathematical Theory of Bayesian Statistics. Chapman and Hall/CRC, 1st edition,
2018.
M. Welling and Y. W. Teh. Bayesian learning via stochastic gradient langevin dynamics. In
Proceedings of the 28th International Conference on Machine Learning, 2011.
Andrew Gordon Wilson and Pavel Izmailov. Bayesian Deep Learning and a Probabilistic Perspective
of Generalization. arXiv:2002.08791 [cs, stat], April 2020.
Guodong Zhang, Shengyang Sun, David Duvenaud, and Roger Grosse. Noisy Natural Gradient as
Variational Inference. In International Conference on Machine Learning, pp. 5852-5861. PMLR,
July 2018.
Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, and Andrew Gordon Wilson. Cyclical
Stochastic Gradient MCMC for Bayesian Deep Learning. In arXiv:1902.03932 [Cs, Stat], 2019.
A Toy example of RLCT calculation
We recall Example 27 from Watanabe (2018) to illustrate the concepts of resolution map, RLCT
and multiplicity for a simple model-truth-prior triplet. For univariate input x ∈ [0, 1] and univariate
output y ∈ R, consider the model with parameter w = (a, b) ∈ [0, 1]2 given by
p(x,y∣w) = √2∏ exp(-2(y - atanh(bx))2)	(17)
Suppose the prior is uniform, i.e.,夕(W) = 1 and the truth is given by po(χ,y) = p(χ,y∣0,0). Then
we can easily see that
K (W) = b2α2 gκ0(w),
where
Ko(w) = L 1( tanh(⅛ )2 dx
The following desingularization map puts the triplet in standard form:
ξ1 = rK0P a
ξ2 = b
Furthermore We have 夕(g(ξ)) = ξh where h = (0,0) and b(ξ) = ∣g0(ξ)∣. Since (k1, k2) = (1,1)
and (h1, h2) = (0, 0) we have (λ1, λ2) = (1/2, 1/2). Therefore for this particular model-truth-prior
triplet, the RLCT is 1/2 with multiplicity 2.
12
Under review as a conference paper at ICLR 2022
B Basic calculations for the generalized gamma distribution
B.1	Truncated
We summarize some basic calculations for the [0, 1] truncated generalized gamma distribution from
Bhattacharya et al. (2020). Let qj be the univariate truncated generalized gamma density given in
equation 12.
The normalizing constant of qj is given by B(λj , kj , βj ) where B(λ, k, β)
β-λΓ(λ)γ(λ,β)
2k
and Y(a, x) = r(a)fX tα-1e-t dt is the (regularized) lower incomplete gamma function.
• The quantity Eqjξ2kj = G(λj,βj) where G(λ,β) = λγ(λ⅛F，
B.2	Untruncated
Consider the univariate density
q(ξ)« ξheχp(-βξ2k)
supported on (0, ∞) where h, k, β > 0. Let λ = (h + 1)/(2k). Elementary calculations give
•	E ξ2k = β-⅛ r(a+λ)
Eqξ	=β k Γ(λ)
•	Eq log ξ = 2k(ψ(λ) - log β) where ψ is the digamma function.
•	Eq log q = 2hk(ψ(λ) - log β) - λ - log Z where, Z = β 2：* is the normalizing constant
of q.
C Generalization of (B hattacharya et al., 2020, Theorem 3.1)
Lemma C.1 below states that any variational distribution qλ,k,β in the untruncated generalized gamma
mean field family Q with well-specified k where we additionally set βj* = n is capable of achieving
ΨK (q, g) ≥ -λlogn + A where A is some constant that does not depend on n. Lemma C.1 is a
straightforward extension of Theorem 3.1 of Bhattacharya et al. (2020)from the [0, 1]d truncated
generalized gamma mean field variational family to the untruncated case. We also relax the condition
in Theorem 3.1 of Bhattacharya et al. (2020) that the variational parameters λ and k (and hence h)
are well-specified; here we only require that k be well-specified.
Lemma C.1. Suppose the model-truth-prior triplet is such that Theorem 3.1 holds with K(g(ξ)) =
"
ξ2k and 夕(g(ξ))∣g (ξ)∣ = ξh. Consider the untruncated generalized gamma mean-field family Q,
we have supq∈Q ΨK (q,g) ≥ -λlogn + A, where A is a constant that does not depend on n.
>Λ	∕' T i' I	7 1'	11 -	1	T	1
Proof. If kj = kj for all j = 1, . . . , d, we have
■—
一 ~ K	L∙,	~ K
d	_j Γ(殳	+ λ -)	如*	Γ( kj*	+ λ ∙*)	_j Γ(殳 + λ -)	∖
E κ(n(t∖Y —幻口	R-k (kj	+ j)	—幻1-小(kj*	+ j Y	π R-k (kj + j)	— λ π λj
EqnK(g0 = nU ββ	-jΓ = n j	Γ(λj*)	j=j* βj	-∏λT = λj* j=j* B
13
Under review as a conference paper at ICLR 2022
Next, we have
KL(q(ξ)lk(g(ξ))∣g0(ξ)l)
d
X Eqj [log qj - hj log ξj] - Eq log b(ξ)
j=1
d 「工∙二	1
X 3 j	(ψ(λj )	- log β ) -	λj	+ λj log βj	+	log(2kj )	- logr(λj )	-	Eq log b(ξ)
j=1	2kj
_d_ 「入 A .	A . I 1
X ’2k ’ ψ(λj) - λj + "⅛7- log βj + log(2kj) - logr(λj)
j=1	2kj	2kj
- Eq log b(ξ)
dh h
E ∖r	ψ(λj ) - λj+ ʌj log βj+log(2Aj ) - logr(λj ) - Eq log b(ξ)
2kj
j=1	j
d
λAlogn +	λAj log βj +
j=j*	j=1
A
FMN)-λj+log(2Aj) - logr(λj)
- Eq log b(ξ).
The last line follows from setting βj-* = n where j* ∈ {1,...,d} is such that λj-* =入，breaking ties
arbitrarily. Finally, the desired inequality follows from the fact that Eq log b(ξ) is bounded below by
some constant.	□
D Experiments
Table 1: Summary of models considered.
H RLCT	d	H RLCT	d
576	12.0 1152 1024	16.0 2048	24	324.0 1224 32	560.0 2144
(a) tanh network	(b) Reduced rank
In the experiments, we train an affine coupling network with two pairs of alternating couplings. The
translation t is a feedforward (leaky) ReLU neural network with tanh output activation function.
The scaling t is another feedforward (leaky) ReLU neural network with identity output activation
function. The models implemented are given below.
Translation network
Sequential(
(0): Linear(in_features=dim, out_features=16, bias=True)
(1): LeakyReLU(negative_slope=0.01)
(2): Linear(in_features=16, out_features=16, bias=True)
(3): LeakyReLU(negative_slope=0.01)
(4): Linear(in_features=16, out_features=16, bias=True)
(5): LeakyReLU(negative_slope=0.01)
(6): Linear(in_features=16, out_features=dim, bias=True)
)
Scaling network
Sequential(
(0): Linear(in_features=dim, out_features=16, bias=True)
(1): LeakyReLU(negative_slope=0.01)
(2): Linear(in_features=16, out_features=16, bias=True)
(3): LeakyReLU(negative_slope=0.01)
(4): Linear(in_features=16, out_features=16, bias=True)
(5): LeakyReLU(negative_slope=0.01)
(6): Linear(in_features=16, out_features=dim, bias=True)
(7): Tanh()
)
14
Under review as a conference paper at ICLR 2022
E Approximate posterior predictive distribution
Bayesian prediction proceeds by marginalization, i.e., averaging over all possible values of the model
parameter. This results in the posterior predictive distribution1 ,
I
w
p(y|x, Dn) :
p(y|x, w)p(w|Dn) dw
hp(y|x, w)ip(w|Dn).
(18)
According to singular learning theory, Bayesian prediction via equation 18 is superior to MAP and
MLE, in the sense that the expected generalization error of the posterior predictive distribution is
smaller than that of the MAP or MLE. Specifically, let
Gn(Pn(y∣χ)):= KL(po(y∣χ)p(χ)∣∣Pn(y∣χ)p(χ))
be the generalization error of a predictive distribution pn(y∣χ). According to Theorems 1.2 and 7.2
in Watanabe (2009), we have
EGn(p(y∖x, Dn)) = λ∕n + o(1∕n)
(19)
where the expectation is taken with respect to Dn and λ is the RLCT of the model-truth-prior triplet.
On the other hand, Theorem 6.4 of Watanabe (2009) shows that the expected generalization error of
MLE (and similarly of MAP) is
EGn(p(y∖x,r^mie)) = C/n + o(1∕n)	(20)
where C, the maximum of a Gaussian process, can be much larger than λ. Such a distinction cannot
be made in regular models in which the difference between the three estimators becomes negligible
in the large n regime.
Now, consider the variational approximation to the posterior predictive distribution given by
Pvb(y∖x, Dn) = hp(y∖x,w)'iq*(w),
where q* is the optimal variational distribution in some variational family Q. It may be tempting
to compare different variational approximations according to how well their respective variational
posterior predictive distributions approximate the true Bayes posterior predictive distribution, e.g.,
Blundell et al. (2015); Louizos & Welling (2017). This turns out to be a thorny issue, as documented
in various works on Bayesian neural networks Heek (2018); Krishnan & Tickoo (2020); Foong et al.
(2020). In particular, pvb(y∖x, Dn) does not necessarily inherit the desirable properties of the Bayes
posterior predictive distribution p(y∖x, Dn). Here, we offer insights from singular learning theory to
account for this.
Consider the (normalized) variational free energy
Fvb(n) = Eq nKn(w) +KL(q(w)∖∖ 2(W))
where q is some variational distribution. If the minimum (normalized) variational free energy
FVb(n) = minq Fvb(n) admits an asymptotic expansion2, then it would be of the form
F*b(n) = λvb log n + (mvb — 1)log log n + Rn.
Note that λvb ≥ λ necessarily. Now, if the generalization error of pvb(y∖x, Dn) would admit an
asymptotic expansion3, it would be of the form
EGn (pvb(y∖x, Dn)) = λvb∕n + o(1∕n).
1Though this may seem fundamentally distinct from the maximum likelihood estimator (MLE) or maximum
a posterior (MAP) solution commonly employed in training deep networks, both MLE and MAP may in fact be
regarded as impoverished estimates of equation 18 whereby p(w∣Dn) is approximated with δ(w = W), a point
mass at W.
2We should disclose that general conditions for such an asymptotic expansion of the minimum variational
free energy is still an open problem. The issue has so far been addressed on a case-by-case basis, e.g., reduced
rank regression Nakajima & Watanabe (2007), nonnegative matrix factorization Kohjima & Watanabe (2017);
Hayashi (2020), normal mixture model Watanabe & Watanabe (2006), hidden Markov model Hosino et al.
(2005).
3Similar to the minimum variational free energy, an expansion of EGn (pvb (y|x, Dn)) has not been estab-
lished in full generality at this point.
15
Under review as a conference paper at ICLR 2022
Importantly, λvb 6= λvb in general. Examples can be found where sometimes one is bigger, sometimes
the other Nakajima & Watanabe (2007).
This development is to be contrasted with the Bayes free energy and the Bayes generalization
error. Recall the normalized Bayes free energy, Fn := - log Z(n), admits the following asymptotic
expansion
Fn = λ log n + (m - 1)log log n + Rn	(21)
The very same λ coefficient appears in the asymptotic expansion of the Bayes generalization error in
equation 19. This means that minimizing the Bayes free energy is equivalent to minimizing the Bayes
generalization error. In contrast, minimizing the variational free energy (equivalent to maximizing the
ELBO) does not necessarily lead to a lower generalization error since a variational family with higher
variational free energy (higher λvb) may have lower variational generalization error (lower λvb).
16
Under review as a conference paper at ICLR 2022
Table 2: The model of interest is the realizable tanh-network with H hidden units and true weight
wo = 0. The prior on the model parameters is taken to be 夕(W) = N(μ(夕)，σ2(夕)Id). For various
combinations of values of H and values for (μ(夕)，σ2(夕))，we display the average and standard
deviation of Ψ(q, g) achieved after training on a dataset of size n = 5000 over 10 Monte Carlo
iterations.
H	(μ3,σ2S)	λ0∕β0 ;	=μo method	count	mean	std
		0.00	nf_gaussian_0_1	10.0	-12307.14	1153.17
			nf_gamma_10_1_100_False	10.0	-10894.83	836.64
			nf_gamma_10_1_100_True	10.0	-10768.14	894.35
		0.10	nf_gamma_10_5_100_False	10.0	-12476.67	877.12
			nf_gamma_10_5_100_True	10.0	-11849.96	415.19
			nf_gaussian_0.1_0.001	10.0	-10604.66	528.57
			nf_gamma_T00_1_100_F alse	10.0	-12804.39	1303.57
	(5.0, 1.0)		nf_gamma_100_1_100_True	10.0	-11759.06	610.11
		1.00	nf_gamma_100_5_100_False	10.0	-14328.32	1215.64
			nf_gamma_100_5_100_True	10.0	-13079.31	1022.25
			nf_gaussian_1_1e-2	10.0	-11658.58	713.89
			nf_gamma_500_1_100_F alse	10.0	-16915.87	2048.86
			nf_gamma_500_1_100_True	10.0	-17939.35	6950.49
		5.00	nf_gamma_500_5_100_False	10.0	-15146.53	639.40
			nf_gamma_500_5_100_True	10.0	-15079.50	974.71
576			nf_gaussian_5_5e-2	10.0	-20300.63	2274.93
		0.00	nf_gaussian_0_1	10.0	-4694.71	42.93
			nf_gamma_10_1_100_False	10.0	-4919.57	85.38
			nf_gamma_10_1_100_True	10.0	-4928.69	75.24
		0.10	nf_gamma_10_5_100_False	10.0	-6036.98	511.80
			nf_gamma_10_5_100_True	9.0	-5909.62	116.19
			nf_gaussian_0.1_0.001	10.0	-4722.43	53.72
			nf_gamma_100_1_100_False	10.0	-5460.35	236.25
	(5.0, 100.0)		nf_gamma_100_1_100_True	10.0	-5060.05	186.63
		1.00	nf_gamma_100_5_100_False	10.0	-7590.89	254.81
			nf_gamma_100_5_100_True	10.0	-6098.62	307.36
			nf_gaussian_1_1e-2	10.0	-8010.75	9394.81
			nf_gamma_500_1_100_F alse	10.0	-7144.50	452.06
			nf_gamma_500_1_100_True	10.0	-6842.81	199.32
		5.00	nf_gamma_500_5_100_False	10.0	-8392.05	207.44
			nf_gamma_500_5_100_True	9.0	-8475.71	412.61
			nf_gaussian_5_5e-2	10.0	-10974.67	4667.23
		0.00	nf_gaussian_0_1	10.0	-24543.92	695.44
			nf_gamma_10_1_100_False	10.0	-20607.23	1776.76
			nf_gamma_10_1_100_True	5.0	-19642.01	449.75
		0.10	nf_gamma_10_5_100_False	9.0	-25668.64	1783.73
			nf_gamma_10_5_100_True	9.0	-25693.87	2344.70
			nf_gaussian_0.1_0.001	10.0	-20014.07	505.24
			nf_gamma_100_1_100_False	10.0	-26573.95	1378.88
	(5.0, 1.0)		nf_gamma_100_1_100_True	10.0	-26259.66	2921.10
		1.00	nf_gamma_100_5_100_False	9.0	-28239.06	1348.93
			nf_gamma_100_5_100_True	9.0	-29061.34	2843.18
			nf_gaussian_1_1e-2	10.0	-24311.66	2924.31
			nf_gamma_500_1_100_F alse	10.0	-35135.85	10110.49
			nf_gamma_500_1_100_True	10.0	-34346.62	7563.82
		5.00	nf_gamma_500_5_100_False	10.0	-31770.45	1765.41
			nf_gamma_500_5_100_True	8.0	-31673.14	2167.54
1024			nf_gaussian_5_5e-2	10.0	-243192.15	271227.44
		0.00	nf_gaussian_0_1	10.0	-8396.27	62.13
			nf_gamma_10_1_100_False	10.0	-8705.24	77.06
			nf_gamma_10_1_100_True	10.0	-8847.36	127.36
		0.10	nf_gamma_10_5_100_False	9.0	-11616.24	1014.68
			nf_gamma_10_5_100_True	8.0	-10916.36	377.03
			nf_gaussian_0.1_0.001	10.0	-8425.56	71.42
			nf_gamma_100_1_100_False	10.0	-10916.45	479.14
	(5.0, 100.0)		nf_gamma_100_1_100_True	10.0	-9514.43	397.57
		1.00	nf_gamma_100_5_100_False	9.0	-14374.43	1187.21
			nf_gamma_100_5_100_True	8.0	-12994.13	765.11
			nf_gaussian_1_1e-2	10.0	-9408.79	480.26
			nf_gamma_500_1_100_False	10.0	-21823.85	9739.67
			nf_gamma_500_1_100_True	10.0	-44768.74	94773.50
		5.00	nf_gamma_500_5_100_False	9.0	-15257.90	282.52
			nf_gamma_500_5_100_True	8.0	-16369.58	1287.13
			nf_gaussian_5_5e-2	10.0	-182386.08	155290.52
17
Under review as a conference paper at ICLR 2022
Table 3: The model of interest is the realizable tanh-network with H hidden units and true weight
wo = 5. The prior on the model parameters is taken to be 夕(W) = N(μ(夕)，σ2(夕)Id). For various
combinations of values of H and values for (μ(夕)，σ2(夕))，we display the average and standard
deviation of Ψ(q, g) achieved after training on a dataset of size n = 5000 over 10 Monte Carlo
iterations.
H	(μ3,σ2S)	λ0∕β0 ;	=μo method	count	mean	std
		0.00	nf_gaussian_0_1	7.0	-481210.04	290152.33
			nf_gamma_10_1_100_False	6.0	-564637.97	185632.52
			nf_gamma_10_1_100_True	9.0	-466874.65	229687.03
		0.10	nf_gamma_10_5_100_False	10.0	-189065.73	110357.18
			nf_gamma_10_5_100_True	10.0	-66869.47	18069.35
			nf_gaussian_0.1_0.001	9.0	-308620.24	270119.27
			nf_gamma_T00_1_100_F alse	10.0	-190317.07	74299.40
	(0.0, 1.0)		nf_gamma_100_1_100_True	10.0	-130158.69	76731.88
		1.00	nf_gamma_100_5_100_False	10.0	-48865.52	14299.86
			nf_gamma_100_5_100_True	10.0	-53566.72	18364.18
			nf_gaussian_1_1e-2	10.0	-544930.96	194349.17
			nf_gamma_500_1_100_F alse	10.0	-89427.42	17721.97
			nf_gamma_500_1_100_True	10.0	-81720.39	13133.21
		5.00	nf_gamma_500_5_100_False	10.0	-33854.50	8232.85
			nf_gamma_500_5_100_True	10.0	-32275.02	7026.42
576			nf_gaussian_5_5e-2	10.0	-100876.71	26177.59
		0.00	nf_gaussian_0_1	8.0	-407843.61	96924.16
			nf_gamma_10_1_100_False	5.0	-503729.89	39713.42
			nf_gamma_10_1_100_True	9.0	-407507.24	172978.81
		0.10	nf_gamma_10_5_100_False	10.0	-154222.94	81217.70
			nf_gamma_10_5_100_True	10.0	-64598.97	46518.60
			nf_gaussian_0.1_0.001	9.0	-313547.55	337434.22
			nf_gamma_100_1_100_False	10.0	-170076.39	81803.27
	(0.0, 100.0)		nf_gamma_100_1_100_True	10.0	-112674.00	72282.16
		1.00	nf_gamma_100_5_100_False	10.0	-37469.45	24653.37
			nf_gamma_100_5_100_True	10.0	-47135.05	34424.37
			nf_gaussian_1_1e-2	10.0	-523308.71	212480.52
			nf_gamma_500_1_100_F alse	10.0	-69257.83	21314.18
			nf_gamma_500_1_100_True	10.0	-58690.81	12706.57
		5.00	nf_gamma_500_5_100_False	10.0	-17097.24	6511.72
			nf_gamma_500_5_100_True	10.0	-14548.94	4430.04
			nf_gaussian_5_5e-2	10.0	-87386.90	26349.19
		0.00	nf_gaussian_0_1	3.0	-895765.67	77889.00
			nf_gamma_10_1_100_False	2.0	-924993.41	100733.15
			nf_gamma_10_1_100_True	7.0	-671229.30	160802.33
		0.10	nf_gamma_10_5_100_False	8.0	-558522.30	252813.58
			nf_gamma_10_5_100_True	10.0	-279065.90	225130.01
			nf_gaussian_0.1_0.001	6.0	-452279.64	129732.34
			nf_gamma_100_1_100_False	10.0	-345768.88	61677.23
	(0.0, 1.0)		nf_gamma_100_1_100_True	10.0	-213500.49	64295.75
		1.00	nf_gamma_100_5_100_False	10.0	-183015.46	128751.21
			nf_gamma_100_5_100_True	10.0	-117581.92	42164.41
			nf_gaussian_1_1e-2	6.0	-836952.29	71929.66
			nf_gamma_500_1_100_F alse	10.0	-196193.05	44549.27
			nf_gamma_500_1_100_True	10.0	-179038.64	52969.12
		5.00	nf_gamma_500_5_100_False	10.0	-66127.35	6789.25
			nf_gamma_500_5_100_True	10.0	-67303.85	17901.20
1024			nf_gaussian_5_5e-2	10.0	-216075.28	71401.02
		0.00	nf_gaussian_0_1	3.0	-750263.23	140506.97
			nf_gamma_10_1_100_False	3.0	-780374.21	154817.19
			nf_gamma_10_1_100_True	7.0	-579285.19	156719.96
		0.10	nf_gamma_10_5_100_False	8.0	-484597.15	248508.84
			nf_gamma_10_5_100_True	10.0	-277501.86	268802.25
			nf_gaussian_0.1_0.001	5.0	-421535.06	238781.26
			nf_gamma_100_1_100_False	10.0	-286356.87	64751.89
	(0.0, 100.0)		nf_gamma_100_1_100_True	10.0	-48948.50	35427.55
		1.00	nf_gamma_100_5_100_False	10.0	-163008.27	158054.21
			nf_gamma_100_5_100_True	10.0	-101276.96	77255.56
			nf_gaussian_1_1e-2	8.0	-825735.30	100242.24
			nf_gamma_500_1_100_False	10.0	-161010.10	35334.52
			nf_gamma_500_1_100_True	10.0	-140923.51	58184.19
		5.00	nf_gamma_500_5_100_False	10.0	-45679.41	21039.66
			nf_gamma_500_5_100_True	10.0	-49196.44	56363.79
			nf_gaussian_5_5e-2	10.0	-147644.89	32270.53
18
Under review as a conference paper at ICLR 2022
Table 4: The model of interest is the realizable reduced rank regression model with H hidden units
and true weight w0 = (A0 , B0) where A0 and B0 are as described in Section 7. The prior on the
model parameters is taken to be 夕(W) = N(μ(夕)，σ2(夕)Id). For various combinations of values of
H and values for (μ(夕)，σ2(夕))，we display the average and standard deviation of Ψ(q, g) achieved
after training on a dataset of size n = 5000 over 10 Monte Carlo iterations.
H	33,*M	λθλβ0 ;	=μo	method	count	mean	std
		0.00	nf_gaussian_0_1	10.0	-87415.82	849.17
			nf_gamma_10_1_100_False	10.0	-19679.77	43.94
			nf_gamma_10_1_100_True	10.0	-19633.08	59.80
		0.10	nf_gamma_10_5_100_False	2.0	-20163.30	41.30
			nf_gamma_10_5_100_True	5.0	-20066.54	100.67
			nf_gaussian_0.1_0.001	10.0	-19356.22	148.83
			nf_g amma_100_1_100_F alse	10.0	-19936.36	42.41
	(5.0, 1.0)		nf_gamma_100_1_100_True	10.0	-19908.21	49.62
		1.00	nf_gamma_100_5_100_False	6.0	-20538.23	98.10
			nf_gamma_100_5_100_True	5.0	-20237.83	146.99
			nf_gaussian_1_1e-2	10.0	-19974.33	49.01
			nf_g amma_500_1_100_F alse	10.0	-20362.09	124.35
			nf_gamma_500_1_100_True	10.0	-20367.47	122.89
24		5.00	nf_gamma_500_5_100_False	1.0	-21345.31	NaN
			nf_gamma_500_5_100_True	1.0	-21310.91	NaN
			nf_gaussian_5_5e-2	10.0	-24732.96	1798.18
		0.00	nf_gaussian_0_1	10.0	-75338.44	767.59
			nf_gamma_10_1_100_False	10.0	-8049.29	24.39
		0.10	nf_gamma_10_1_100_True	10.0	-8045.36	17.34
			nf_gaussian_0.1_0.001	10.0	-8012.99	13.94
			nf_gamma_100_1_100_False	10.0	-8179.44	61.48
	(5.0, 100.0)		nf_gamma_100_1_100_True	10.0	-8110.42	44.60
		1.00	nf_gamma_100_5_100_False	1.0	-8675.67	NaN
			nf_gamma_100_5_100_True	1.0	-8367.80	NaN
			nf_gaussian_1_1e-2	10.0	-8164.30	54.74
			nf_g amma_500_1_100_F alse	10.0	-8472.94	107.69
		5.00	nf_gamma_500_1_100_True	10.0	-8510.36	107.44
			nf_gaussian_5_5e-2	10.0	-12594.11	1731.59
		0.00	nf_gaussian_0_1	10.0	-152649.27	934.00
			nf_gamma_10_1_100_False	10.0	-34709.70	86.32
		0.10	nf_gamma_10_1_100_True	10.0	-34642.82	94.35
			nf_gaussian_0.1_0.001	10.0	-33988.99	181.45
	(5.0, 1.0)		nf_gamma_100_1_100_False	10.0	-35191.26	82.93
		1.00	nf_gamma_100_1_100_True	10.0	-35127.52	107.32
			nf_gaussian_1_1e-2	10.0	-35171.68	113.62
			nf_g amma_500_1_100_F alse	10.0	-35978.89	225.51
		5.00	nf_gamma_500_1_100_True	10.0	-36019.50	239.84
32			nf_gaussian_5_5e-2	10.0	-56902.20	13175.17
		0.00	nf_gaussian_0_1	10.0	-131447.49	1093.16
			nf_gamma_10_1_100_False	10.0	-14065.12	52.64
		0.10	nf_gamma_10_1_100_True	10.0	-14041.35	26.66
			nf_gaussian_0.1_0.001	10.0	-13990.93	31.67
	(5.0, 100.0)		nf_gamma_100_1_100_False	10.0	-14293.75	68.46
		1.00	nf_gamma_100_1_100_True	10.0	-14152.35	71.25
			nf_gaussian_1_1e-2	10.0	-14272.72	99.10
			nf_g amma_500_1_100_F alse	10.0	-14874.08	126.36
		5.00	nf_gamma_500_1_100_True	10.0	-14906.96	144.99
			nf_gaussian_5_5e-2	10.0	-33611.96	10019.58
19