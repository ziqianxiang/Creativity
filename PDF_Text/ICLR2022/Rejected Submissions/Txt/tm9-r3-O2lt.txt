Under review as a conference paper at ICLR 2022
Controlling the memorability of real and un-
REAL FACE IMAGES
Anonymous authors
Paper under double-blind review
Ab stract
Everyday, we are bombarded with many photographs of faces, whether on social
media, television, or smartphones. From an evolutionary perspective, faces are
intended to be remembered, mainly due to survival and personal relevance. How-
ever, all these faces do not have the equal opportunity to stick in our minds. It
has been shown that memorability is an intrinsic feature of an image but yet, it is
largely unknown what attributes make an image more memorable. In this work,
we aimed to address this question by proposing a fast approach to modify and
control the memorability of face images. In our proposed method, we first found
a hyperplane in the latent space of StyleGAN to separate high and low memo-
rable images. We then modified the image memorability (while maintaining the
identity and other facial features such as age, emotion, etc.) by moving in the pos-
itive or negative direction of this hyperplane normal vector. We further analyzed
how different layers of the StyleGAN augmented latent space contribute to face
memorability. These analyses showed how each individual face attribute makes
an image more or less memorable. Most importantly, we evaluated our proposed
method for both real and unreal (generated) face images. The proposed method
successfully modifies and controls the memorability of real human faces as well
as unreal (generated) faces. Our proposed method can be employed in photograph
editing applications for social media, learning aids, or advertisement purposes.
1	Introduction
In our everyday life, we are exposed to many pictures of scenes, objects and faces. Research has
shown that all images do not have the same likelihood to be recalled later (Isola et al., 2011; Bain-
bridge et al., 2013; Isola et al., 2014). Although different people have different abilities in memoriz-
ing visual contents (image or video), it has been shown that memorability is an intrinsic feature of an
image and it is consistent across different observers (Isola et al., 2011; Bainbridge et al., 2013; Isola
et al., 2014). In other words, memorability of an image is an attribute of that image which can be
measured, predicted or manipulated (Isola et al., 2011). So far there have been several studies that
have attempted to understand, predict, and even modify image memorability. (Khosla et al., 2013a;
2015; Goetschalckx & Wagemans, 2019; Fajtl et al.; Needell & Bainbridge, 2021; Squalli-Houssaini
et al., 2018; Almog et al.), and a few work attempted to modify image memorability (Khosla et al.,
2013b; Siarohin et al., 2017; Sidorov, 2019; Goetschalckx et al., 2019). However, for practical
applications (e.g., education and advertisement), it is most important to have methods for memora-
bility modifications. Moreover, such approaches will help understanding what constitute as image
memorability, i.e. ”What makes an image memorable?”.
This work proposes a new framework based on Generative Adversarial Networks (GANs) (Good-
fellow et al., 2014) for modifying face memorability as a facial attribute. Older approaches on mod-
ifying face memorability manually used face features (Khosla et al., 2013b), such as SIFT (Lowe,
2004), HOG2x2 (Dalal & Triggs, 2005), and Local Binary Pattern (LBP) (Ojala et al., 2002). Re-
cently, GANs have been used to modify the memorability of images. (Goetschalckx et al., 2019;
Sidorov, 2019). Goetschalckx et al. (2019) leverage latent vector modification to change the memo-
rability of the fake food, scenes, and animal images generated by BigGAN (Brock et al., 2018). This
memorability modification affects several attributes of the image, such as size, color, and shape. In
our work, we aim to modify memorability of face images of real people while keeping their identity,
consequently, their method cannot be used here.
1
Under review as a conference paper at ICLR 2022
The largest dataset of the human faces with their memorability annotations is US 10k Face
database (Bainbridge et al., 2013), which includes 2222 face images with their memorability scores
acquired from human observers in an experiment. StyleGANs are the state-of-the-art models for
generating real-looking faces. Our utilization of StyleGANs is required to create a dataset of
realistic-looking faces. Not only that, for modifying the memorability of real faces, we need Style-
GANs to reconstruct real faces with high accuracy. To date, StyleGANs are the state-of-the-art
models in reconstructing real-face images. StyleGANs provide an extended latent space which we
leverage to derive a more accurate memorability hyperplane. Also, the face attributes of Style-
GANs are especially disentangled in comparison to other GANs, which is required to accurately
modify faces for memorability and study the attributes contributing to this. For this, we employed
pre-trained StyleGAN1 (Karras et al., 2019) and StyleGAN2 (Karras et al., 2020) on the FFHQ
dataset (Karras et al., 2019) to generate 100k fake faces. Next, we adopted computational memo-
rability models which we trained on the US 10k Face Database, to predict the memorability of the
generated face images and organized them into faces with high or low memorability. Inspired by
Shen et al. (2020), we found a hyperplane in latent subspace to separate the highly-memorable and
low-memorable faces. We showed that both latent space and extended latent space can be used for
finding the separating hyperplane. After finding the hyperplane, we moved the latent vector of each
image, in the positive or negative direction of the normal vector of that hyperplane and changed
the distance of the latent vector from the separating hyperplane to manipulate the memorability of
that image. We name the normal vector of this hyperplane, memorability modification vector. With
this proposed approach, we could control the amount of change in memorability by using different
weights for the memorability modification vector. In contrast to the method proposed by Sidorov
(2019), our method does not require training another auxiliary network for modifying face memora-
bility and the amount of change in memorability is controlled by a hyperparameter.
Since different hyperplanes for different facial attributes in StyleGAN latent space (Shen et al.,
2020; Harkonen et al., 2020) can be found, our method can be used to modify the memorability of
the images conditionally. For example, we are able to change the memorability of the face while
maintaining the length of the hair and the existence of eyeglasses. For this, we first find the corre-
sponding hyperplanes for these attributes, and then leverage projection to those subspaces to have the
desired attributes fixed while changing memorability. StyleGAN produces high quality real-looking
images which are near impossible to differentiate from real images. To make sure our memorability-
modified faces still look real, we considered the Frechet Inception Distance (FID) (Heusel et al.,
2017) and Kernel Inception Distance (KID) (BinkoWski et al., 2018) scores of the generated faces
from the StyleGAN as the baseline. Then by calculating the FID score and KID score of our mem-
orability modified images, We shoWed that our modified faces still looked real.
For real faces, We first embedded the face images into GAN latent space using Image2Style (Abdal
et al., 2019) and the method provided by Karras et al. (2020). After finding the image latent vector,
We modified the real face memorability in the same Way previously explained for synthetic faces.
Figure 1 illustrates the general idea of our approach. Finally, We examined hoW different layers of
extended latent space of StyleGAN affect the image of each face and its memorability.
1.1	Related works
Image Memorability. People have different capabilities in memorizing different visual events (Hunt
et al., 1981). In spite of these differences, through a series of experiments, Isola et al. (2011) shoWed
that people consistently remember some images and forget others. They designed an online memory
game experiment and recruited a large number of participants through Amazon Mechanical Turk. In
this experiment, participants observed a series of images presented in a sequence and Were tasked to
detect repetitive images in the sequence. Then Isola et al. (2011) measured a memorability score for
each image, Which corresponded to the rate of people remembering an image after single exposure
to that image in the sequence. Khosla et al. (2015) created the largest annotated image memorability
dataset (LaMem), Which consists of 60,000 images, mostly objects, scenes, and animals. Using this
dataset, they introduced the first deep model for predicting image memorability. This model uses
AlexNet (Krizhevsky et al., 2012) as its backbone architecture. Moreover, Needell & Bainbridge
(2021) introduced neW architectures based on residual netWorks (He et al., 2016) to improve the
performance of memorability prediction. In addition to these models, Fajtl et al. leveraged Attention
Maps to introduce AMNet for predicting memorability.
2
Under review as a conference paper at ICLR 2022
Face
Memorability
Assessor
∙+
w + α. w*
or
w + α.z*
Modifying the latent
vector of the image
Dividing the faces to
high-memorable and
low-memorable
groups
∣0∣1口…10口
W* »
Or	'λHigh-memorable faces
z*	\'	ʌ
low-memorable faces
Finding the separating hyperplane and w^
Modified image
W =
Z =
Figure 1: The proposed method. We first generate synthesized face images from random latent
vectors and predict their memorability scores by a face memorability assessor network. Then, di-
vide them into high-memorable and low-memorable faces. Using either latent vector or extended
latent vector subspace we find a memorability separating hyperplane in that subspace. The second
row shows the proposed framework for modifying the memorability score of face images. Using
a GAN inversion technique we first map faces to StyleGAN’s latent space. Then modify the face
memorability by moving the latent vector (or extended latent vector) towards negative or positive
direction of memorability discriminating hyperplane obtained in previous step. The modified la-
tent vector (or extended latent vector) is fed to the GAN to generate the face image with modified
memorability. It is optional to ovalize the face images before feeding to the assessor.
Generative Adversarial Networks (GANs). With the development of Generative Adversarial Net-
works (Goodfellow et al., 2014), we are now capable of generating real-looking synthetic images
that are indistinguishable from real images. Generally, these networks are composed of two parts;
a generative and a discriminative network. The goal of the generative network is to generate real-
looking images to fool the discriminator and the goal of the discriminator is to learn to distinguish
generated images from real images. These two networks are optimized through a minmax game
where both sides compete to reach their specified goals. In recent years, there have been huge im-
provements in this area and many different GANs have been introduced to produce natural-looking
images such as Progressive GAN (Karras et al., 2017), DCGAN (Radford et al., 2015), and Cycle-
GAN (Zhu et al., 2017). In this work, we used pre-trained StyleGAN1 (Karras et al., 2019) and
StyleGAN2 (Karras et al., 2020) on the FFHQ dataset (Karras et al., 2019) to generate real-looking
faces.
Modifying Image Memorability. While image memorability modification has many potential ap-
plications (e.g. in education or advertisement), it has not been adequately investigated. Khosla et al.
(2013b) proposed a pioneering method for changing face memorability. It leveraged Active Appear-
ance Models (AAMs (Cootes et al., 2001)) to represent faces by their shape and appearance. Then
the loss function was defined based on the cost of modifying identity, modifying facial attributes,
and memorability. As a result, in their method, the identity was fixed. Another approach (Sidorov,
2019) used VAE/GAN (Larsen et al., 2016), StarGAN (Choi et al., 2018), and AttGAN (He et al.,
2019) and trained them with three memorability levels (poorly memorable, moderately memorable,
and highly memorable) of faces and modified the memorability of different faces to these three
levels only. Additionally, Siarohin et al. (2017) utilized style transfer to increase the memorability
of an input image. However, the added style adversely affected the realness of the modified im-
ages, such that it barely could be used in real-world applications. Most recently, Goetschalckx et al.
(2019) trained a transformer network to change the memorability of each generated image by Big-
GAN (Brock et al., 2018) through modifying their latent vectors. Their method works on generated
images of objects and scenes.
2	Method
The overview of our proposed method is depicted schematically in Figure 1. Below we explain the
approach step by step.
3
Under review as a conference paper at ICLR 2022
2.1	Creating the dataset
For the purpose of analyzing the latent vectors of the GANs and their relation to memorability, we
need a large dataset of face images with their memorability scores. The largest dataset available
for face images is the 10k US Adult Faces Database (Bainbridge et al., 2013). This database con-
tains 10,168 natural human face images and 2,222 of these images are annotated with memorability
scores. To create a larger dataset for face images with their corresponding memorability scores, we
leveraged StyleGAN1 and StyleGAN2, which are the state-of-the-art models for creating realistic-
looking face images. These models were pre-trained on the FFHQ dataset (Karras et al., 2019)
which consists of 70,000 high-quality face images with 1024 × 1024 resolution with variations in
age, gender, and glasses. We created two different datasets with StyleGAN1 and StyleGAN2. We
randomly sampled 100k z ∈ R1×512 from a standard normal distribution with truncation to produce
high-quality synthetic face images and saved their mappings in the extended latent space (R18×512)
of both GANs.
2.2	Preprocessing step
The generated images from the StyleGAN have 1024 × 1024 resolution in three channels. For
the purpose of acquiring the memorability of the generated images, we had to preprocess them to
predict their memorability with the computational memorability predicting models (assessor). We
leveraged VGG16 (Simonyan & Zisserman, 2014), ResNet50 (He et al., 2016), and SENet50 (Hu
et al., 2018) that are pre-trained on VGGFace2 (Cao et al., 2018) and fine-tuned them on the US 10k
Face Database to correctly estimate face memorability scores. This dataset consists of oval-shaped
human faces with white backgrounds. 10k US Adult Face images have the same height of 256 with
different widths. Hence, we had to first ovalize the generated faces, then compute their memorability
scores. We used MTCNN (Zhang et al., 2016) for detecting the face in the generated images and
masked an oval on it to make all the images similar to the US 10k Face Database (See Figure 2).
Sample From 10k US Adult Face Sample generated image Generated image after ovalizing SteP
Figure 2: Preprocessing step to make the shape of the synthesized images similar to the dataset that
the assessor is trained on.
2.3	Predicting the memorability scores
As explained in previous section, memorability assessors are trained on 10K US face database which
includes ovalized faces. We first, tested whether the ovalization process is necessary to obtain memo-
rability scores for generated faces. For this, we fine-tuned the pre-trained SENet50 (Hu et al., 2018),
VGG16 (Simonyan & Zisserman, 2014), and ResNet50 (He et al., 2016) for predicting face mem-
orability scores on 10K US face database. We calculated the memorability of both the oval-shaped
and square-shaped faces generated from StyleGAN1 and StyleGAN2. The distributions of the mem-
orability scores using SENet with oval and squared faces are shown in Figure 3. As can be seen,
the memorability distributions are very similar for oval and square faces. We further calculated the
Kendall rank correlation (Schaeffer & Levitt, 1956) and Spearman’s rank correlation for the paired
oval-shaped and square-shaped images. We observed that SeNet50 and VGG16 have a high-rank
score (see Table 1). These results showed that these models can also be used for the square-shaped
face images that contain a background. The benefit of using square-shaped faces is that we can have
more control on the hair of the person. Please note that the performance of memorability predicting
models are measured with rank correlation (Khosla et al., 2015).
4
Under review as a conference paper at ICLR 2022
(a) StyleGan1 (oval)
(b) StyleGan1 (square)
(c) StyleGan2 (oval)
(d) StyleGan2 (square)
Figure 3: Distributions of the memorability scores of the generated images of StyleGan1 and Style-
Gan2 based on using an ovalization step or not.
Table 1: Correlations of memorability scores of square-shaped and oval-shaped faces. High corre-
lation score suggests the assessor performs well on square faces too.
Assessor	Kendall Tau correlation	Spearman’s correlation
ResNet50	0.1606	0.2391
SENet50	0.4419	0.6217
VGG16	0.4720	0.6562
2.4	The proposed method for modifying face memorability
Next we aimed to find a hyperplane to separate the highly-memorable and low-memorable im-
ages. First, we needed to label the faces into highly-memorable and low-memorable faces. For
this, we used the mean of memorability scores as a threshold. We labeled an image as highly or
low memorable if its memorability score was higher or lower than the mean. In our experiments,
we also tried using median of the memorability scores as the threshold for labeling high and low
memorable groups. Next, using logistic regression, we attempted to find a hyperplane to separate
low-memorable and highly-memorable images. For this purpose, we used either z ∈ R1×512 latent
vectors or w ∈ R18×512 extended latent space of StyleGAN1 and StyleGAN2. After finding the
separating hyperplane, we moved the latent vector or the augmented latent vector in the positive or
negative direction of the normal vector of that hyperplane to control the image memorability. This
hyperplane denotes the moderately memorable images, as we chose it to separate the faces into high-
memorable and low-memorable faces based on the mean (or median) of the memorability scores.
Memorability of each image is related to the distance of its latent vector (or extended latent vector
if extended latent vector is used to find the hyperplane) from this hyperplane. Consider image i
with corresponding latent vector zi ∈ R1×512 or wi ∈ R18×512, and its memorability score memi.
We note the normal vector of this hyperplane by z* ∈ R1×512 or w* ∈ R18×512 and We show the
distance from the hyperplane by function d. We will have:
memi α d(z*, Zi) = z*『z	(1)
memi Y d(w*, Wi) = w* w	(2)
Hence, we can change the memorability of each image, by changing the distance of its latent vector
(or extended latent vector) from the separating hyperplane; zedit = z + αz * or similarly wedit =
w + αw * and we will have:
d(z*, zedit) = z*T.zedit = z*T.(z + αz*) = z*T.z + α = d(z*, z) + α	(3)
d(w* , wedit) = w*T .wedit = w*T .(w + αw*) = w*T .w + α = d(w*, w) + α	(4)
The results of this classification task for finding the separating hyperplane are presented in Table 4
when different assessors are used for memorability score predictions. In each case, the accuracy
was about 10 percent higher when we used extended latent space (w), hence we showed the results
for extended latent space in Table 4. According to the results, we decided to use SENet50 as our
assessor and mean memorability as the threshold for our further analysis.
5
Under review as a conference paper at ICLR 2022
Table 2: Accuracy of the separating hyperplane, based on the method for dividing images into
highly-memorable and low-memorable images, the shape of the images, and the assessor.
Assessor	Median		Mean	
	Oval	Square	Oval	Square
ResNet50	0.8131	0.7933	0.8149	0.7928
SENet50	0.8157	0.8291	0.8207	0.8317
VGG16	0.7938	0.8037	0.7952	0.8071
The performance of logistic regression is higher when the extended latent space is used to find the
separating hyperplane. Further, as we show in the next section working with the extended latent
space yields better results in modifying face memorability. (See A.4 for the latent space results.)
One of the benefits of our approach is that we can fix specific attributes while changing memorability.
It has been shown that latent vector play an important role in determining different attributes of a
face and we can find hyperplanes to separate faces based on those attributes, such as glasses, age,
and smile. Consider the norm vectors of these hyperplanes as A = {a1, a2, ..., ak}. We can fix
these attributes by subspace projection as follows: Wnew = w* - Pi=k(w*T.ai)ai (See A.5).
2.5	Latent Vector Recovery for Real faces
The efficiency of our method to modify real human faces depends on how well the latent vector of
the real face can be obtained to reconstruct the original image. After acquiring the latent vector of the
real face image, we can repeat the process for the synthesized images and modify their memorability.
In this work, we used image2style (Abdal et al., 2019) to embed the real faces to latent space of
StyleGAN1, whose loss function consists of a VGG-16 perceptual loss (Johnson et al., 2016) and
a pixel-wise MSE loss term. Furthermore, for projecting real faces to StyleGAN2 latent space, we
employed the same algorithm described by Karras et al. (2020) after using the dlib library (King,
2009) to align 68 face landmarks in the preprocessing step. In this work, we assume that we have the
latent vector of the generated faces, however, if the latent vector ofa generated face is not available,
a similar approach can be employed to retrieve the latent vector.
3	Experiments
3.1	Changing memorability of synthesized faces
As described in Section 2.1, we created two different datasets with StyleGAN1 and StyleGAN2.
We randomly sampled 100k z ∈ R1×512 from a standard normal distribution with truncation to
produce high-quality synthetic face images and saved their mappings in R18×512 augmented latent
space of both GANs. We calculated their memorability scores using SENet50, then labeled them
highly or low-memorable images when compared to the mean memorability score in the dataset,
finally we used the logistic regression to find the separating hyperplane as described in Section 2.4.
After finding the separating hyperplane, we evaluated our method in modifying the memorability
of generated faces with StyleGAN1 and StyleGAN2 using our proposed method. As we discussed
earlier in 2.4, we found separating hyperplanes in either latent space or extended latent space of
StyleGAN1 and StyleGAN2. Figure 4 and Figure 5, demonstrates some samples of memorability
modification with StyleGAN1 and StyleGAN2 respectively (See A.1 for more examples).We ob-
serve that increasing the memorability scores causes some decreases in the facial weight, increases
the presence of makeup and thickness of the lips, and makes the person look younger. Moreover, it
will affect the skin tone by making it brighter. It makes the face more serious. However, decreasing
the memorability score has opposite effects.
In addition to using our method to evaluate face images qualitatively, we also tested the performance
of our method in modifying memorability, quantitatively. For this, we used 10k synthesised faces
and tried different weights of memorability modification on them. Figure 6 depicts the distributions
of memorability scores when shifted by our method as well as the mean of the distributions, which
suggests us we were successful in modifying the memorability scores of the faces.
6
Under review as a conference paper at ICLR 2022
------► Increasing Memorability
------► Decreasing Memorability
Original Image
Increasing Memorability
------► Decreasing Memorability
Figure 4: Modifying memorability of faces generated by StyleGAN1. Exemplar faces and their
counterparts when our memorability modifying approach is applied to them. The second row depicts
images when an extra step of ovalization is applied before feeding to the assessor. The corresponding
memorability score is presented in the top left corner of each image.
, Increasing Memorability
, Decreasing Memorability
Original Image
Figure 5: Modifying memorability of faces generated by StyleGAN2. Exemplar faces and their
counterparts when our memorability modifying approach is applied to them. The second row depicts
images when an extra step of ovalization is applied before feeding to the assessor.
3.2	Realness of the modified faces
In this experiment, we evaluated the realness of the faces when our memorability modification was
applied to them. StyleGAN is a state-of-the-art model in generating real-looking faces. Hence, we
considered the realness of the generated images from StyleGAN (before memorability modification)
as our baseline and compared them to the modified faces. First we generated 10k synthesized faces,
then appllied different weights of memorability modification vector to their latent vectors. We uti-
lized two well-known measures for this purpose; FID and KID. As demonstrated in Figure 7, the
FID and KID scores of the modified images are close to the unmodified faces and therefore, the
realness of faces is not affected by our method.
7
Under review as a conference paper at ICLR 2022
至 SUQa
-4 -2 O 2	4
Memorability coefficient
Square-shape faces
Figure 6: The effectiveness of our method for modifying memorability scores tested on 10k gener-
ated faces. As depicted the distribution and mean memorability score of images changes with the
coefficient used for memorability modification.
0.0 0.2 0.4 0.6 0.8 1.0
Memorability Score
-4 -2 0	2	4
Memorability coefficient
Oval-shape faces
Figure 7:	The realness of the 10k generated images measured by the FID and KID ratios for dif-
ferent memorability modification coefficients. FID and KID score of the unmodified images are the
respective baselines. A close to one ratio indicates similar level of realness with the baseline.
3.3 Changing memorability of real faces
Original Images
Recovered Images
) Increasing memorability
■ Decreasing memorability
Figure 8:	Memorability modification of real faces. The first three rows were encoded to Style-
GAN2 latent space and the fourth row was encoded to StyleGAN1 latent space.
Next we evaluated our method on real human faces. First, we computed their extended latent vector
using the GAN inversion method previously described and then applied our proposed method to
them to change their memorability. For real human faces, we chose to work with the extended
8
Under review as a conference paper at ICLR 2022
latent vectors, because the regenerated images from the extended latent space are more similar to
the original images (See Figure 8).
3.4 Layerwise memorability modification
Decreasing attribute .
Original Images
口 Increasing attribute
Square-shape faces
Oval-shape faces
Figure 9: The effect of changes in the 7th layer of the extended latent space on memorability
score. This layer mostly affects the presence of makeup in female and facial hair in male faces.
We observe that when we move this layer in the positive direction of the corresponding layer of
the memorability vector (w*), the memorability score will drastically increase and the presence of
makeup is highlighted. Additionally, we observed that the lips thickness increases, and the eyebrows
shape and the skin tone of the person changes changes.
Next we tried to identify which layers in extended latent vectors contributed the most to face mem-
orability, i.e., which layers are most responsible for modifying a face memorability score. In each
experiment, we only changed one layer and kept other layers the same. We plotted the faces after
these layerwise changes to examine what kind of changes these layerwise modifications caused in
the faces. We observed that modifications in the first 11 layers were mostly responsible for changes
in a face, and the other 7 layers mostly just affected the color and background of the image. Hence,
we only focused on the first 11 layers. We then repeated the same layerwise changes on 3k syn-
thesized faces and calculated the mean memorability of these images before layerwise and after
layerwise modifications (See Figure 9, for the other layers see A.2).
4 Conclusion
In this work, we proposed a new method for modifying the memorability of face images. Our
approach does not suffer from the limitations of the previous methods and is able to modify the
memorability of faces (synthetic and real) within an arbitrary continuous range. Moreover, we
demonstrated these changes will not affect the realness of the images. However, if a very large
weight for the memorability modification vector is chosen, it will affect the face identity and real-
ness. We showed that our method is effective by applying it to 10k synthesized faces. Further, we
employed our method on real human faces and showed it is effective in changing the memorabil-
ity of real faces as well. Finally, we studied how layerwise modifications will affect the face and
its memorability score and discussed one of the benefits of the proposed method is modifying the
memorability score conditionally by leveraging subspace projection method.
9
Under review as a conference paper at ICLR 2022
References
Rameen Abdal, Yipeng Qin, and Peter Wonka. Image2stylegan: How to embed images into the
stylegan latent space? In Proceedings of the IEEE/CVF International Conference on Computer
Vision,pp. 4432-4441, 2019.
Gal Almog, Saeid Alavi Naeini, Yu Hu, Emma G Duerden, and Yalda Mohsenzadeh. Memoir
dataset: Quantifying image memorability in adolescents.
Wilma A. Bainbridge, Phillip Isola, and A. Oliva. The intrinsic memorability of face photographs.
Journal of experimental psychology. General, 142 4:1323-34, 2013.
Mikolaj BinkoWski, Danica J Sutherland, Michael ArbeL and Arthur Gretton. Demystifying mmd
gans. arXiv preprint arXiv:1801.01401, 2018.
AndreW Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high fidelity natural
image synthesis. arXiv preprint arXiv:1809.11096, 2018.
Qiong Cao, Li Shen, Weidi Xie, Omkar M Parkhi, and AndreW Zisserman. Vggface2: A dataset for
recognising faces across pose and age. In 2018 13th IEEE international conference on automatic
face & gesture recognition (FG 2018), pp. 67-74. IEEE, 2018.
Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo. Star-
gan: Unified generative adversarial netWorks for multi-domain image-to-image translation. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 8789-8797,
2018.
Timothy F. Cootes, Gareth J. EdWards, and Christopher J. Taylor. Active appearance models. IEEE
Transactions on pattern analysis and machine intelligence, 23(6):681-685, 2001.
Navneet Dalal and Bill Triggs. Histograms of oriented gradients for human detection. In 2005 IEEE
computer society conference on computer vision and pattern recognition (CVPR’05), volume 1,
pp. 886-893. Ieee, 2005.
J Fajtl, V Argyriou, D Monekosso, and P Remagnino. Amnet: Memorability estimation With atten-
tion. arxiv 2018. arXiv preprint arXiv:1804.03115.
Lore Goetschalckx and Johan Wagemans. Memcat: A neW category-based image set to study image
memorability. 05 2019. doi: 10.13140/RG.2.2.19105.15202.
Lore Goetschalckx, Alex Andonian, Aude Oliva, and Phillip Isola. Ganalyze: ToWard visual defi-
nitions of cognitive image properties. In Proceedings of the IEEE/CVF International Conference
on Computer Vision, pp. 5744-5753, 2019.
Ian GoodfelloW, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information
processing systems, 27, 2014.
Erik Harkonen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris. Ganspace: Discovering
interpretable gan controls. arXiv preprint arXiv:2004.02546, 2020.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, and Xilin Chen. Attgan: Facial attribute
editing by only changing What you Want. IEEE transactions on image processing, 28(11):5464-
5478, 2019.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a tWo time-scale update rule converge to a local nash equilibrium. Advances in
neural information processing systems, 30, 2017.
Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation netWorks. In Proceedings of the IEEE
conference on computer vision and pattern recognition, pp. 7132-7141, 2018.
10
Under review as a conference paper at ICLR 2022
Earl B Hunt, Janet Davidson, and Marcy Lansman. Individual differences in long-term memory
access. Memory & Cognition, 9(6):599-608,1981.
Phillip Isola, Jianxiong Xiao, Antonio Torralba, and Aude Oliva. What makes an image memorable?
In CVPR 2011, pp. 145-152. IEEE, 2011.
Phillip Isola, Jianxiong Xiao, Devi Parikh, Antonio Torralba, and Aude Oliva. What makes a pho-
tograph memorable? Pattern Analysis and Machine Intelligence, IEEE Transactions on, 36(7):
1469-1482, 2014.
Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and
super-resolution. In European conference on computer vision, pp. 694-711. Springer, 2016.
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for im-
proved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.
Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative
adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pp. 4401-4410, 2019.
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyz-
ing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 8110-8119, 2020.
Aditya Khosla, Wilma Bainbridge, Antonio Torralba, and Aude Oliva. Modifying the memorability
of face photographs. pp. 3200-3207, 12 2013a. doi: 10.1109/ICCV.2013.397.
Aditya Khosla, Wilma A Bainbridge, Antonio Torralba, and Aude Oliva. Modifying the memora-
bility of face photographs. In Proceedings of the IEEE International Conference on Computer
Vision, pp. 3200-3207, 2013b.
Aditya Khosla, Akhil S. Raju, Antonio Torralba, and Aude Oliva. Understanding and predicting
image memorability at a large scale. In 2015 IEEE International Conference on Computer Vision
(ICCV), pp. 2390-2398, 2015. doi: 10.1109/ICCV.2015.275.
Davis E. King. Dlib-ml: A machine learning toolkit. Journal of Machine Learning Research, 10:
1755-1758, 2009.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep con-
volutional neural networks. Advances in neural information processing systems, 25:1097-1105,
2012.
Anders Boesen Lindbo Larsen, S0ren Kaae S0nderby, Hugo Larochelle, and Ole Winther. AUtoen-
coding beyond pixels using a learned similarity metric. In International conference on machine
learning, pp. 1558-1566. PMLR, 2016.
David G Lowe. Distinctive image features from scale-invariant keypoints. International journal of
computer vision, 60(2):91-110, 2004.
Coen D Needell and Wilma A Bainbridge. Embracing new techniques in deep learning for estimat-
ing image memorability. arXiv preprint arXiv:2105.10598, 2021.
Timo Ojala, Matti Pietikainen, and Topi Maenpaa. Multiresolution gray-scale and rotation invari-
ant texture classification with local binary patterns. IEEE Transactions on pattern analysis and
machine intelligence, 24(7):971-987, 2002.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Maurice S Schaeffer and Eugene E Levitt. Concerning kendall’s tau, a nonparametric correlation
coefficient. Psychological Bulletin, 53(4):338, 1956.
Yujun Shen, Ceyuan Yang, Xiaoou Tang, and Bolei Zhou. Interfacegan: Interpreting the disentan-
gled face representation learned by gans. IEEE transactions on pattern analysis and machine
intelligence, 2020.
11
Under review as a conference paper at ICLR 2022
Aliaksandr Siarohin, Gloria Zen, Cveta Majtanovic, Xavier Alameda-Pineda, Elisa Ricci, and Nicu
Sebe. How to make an image more memorable? a deep style transfer approach. In Proceedings
ofthe 2017 ACM on International Conference on Multimedia Retrieval,pp. 322-329, 2017.
Oleksii Sidorov. Changing the image memorability: From basic photo editing to gans. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, pp.
0-0, 2019.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556, 2014.
Hammad Squalli-Houssaini, Ngoc QK Duong, Marquant Gwenaelle, and Claire-Helene Demarty.
Deep learning for predicting image memorability. In 2018 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), pp. 2371-2375. IEEE, 2018.
Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, and Yu Qiao. Joint face detection and alignment using
multitask cascaded convolutional networks. IEEE Signal Processing Letters, 23(10):1499-1503,
2016.
Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation
using cycle-consistent adversarial networks. In Proceedings of the IEEE international conference
on computer vision, pp. 2223-2232, 2017.
12
Under review as a conference paper at ICLR 2022
A Appendix
A.1 Additional examples
Decreasing memorability I
Original Images
► Increasing memorability
Figure 10: Generated images by StyleGAN1 with their corresponding memorability scores.
Modified images when extended latent space of the StyleGAN1 was used to determine the separating
hyperplane. Square-shaped faces were fed to the assessor.
Decreasing memorability [
Original Images
，Increasing memorability
Figure 11: Generated images by StyleGAN1 with their corresponding memorability scores.
Modified images when extended latent space of the StyleGAN1 was used to determine the separating
hyperplane. Oval-shaped faces were fed to the assessor.
13
Under review as a conference paper at ICLR 2022
Decreasing memorability <
，Increasing memorability
Figure 12: Generated images by StyleGAN1 with their corresponding memorability scores.
Modified images when latent space of the StyleGAN1 was used to determine the separating hyper-
plane. Square-shaped faces were fed to the assessor.
Decreasing memorability I
Original Images
Increasing memorability
Figure 13: Generated images by StyleGAN2 with their corresponding memorability scores.
This figure shows the modified images when extended latent space of the StyleGAN2 was used to
determine the separating hyperplane. Square-shaped faces were fed to the assessor.
14
Under review as a conference paper at ICLR 2022
Original Images
0.17
，Increasing memorability
0.44
0.45
.27
0.32
0.47
Figure 14: Generated images by StyleGAN2 with their corresponding memorability scores.
This figure shows the modified images when extended latent space of the StyleGAN2 was used to
determine the separating hyperplane. Oval-shaped faces were fed to the assessor.
Decreasing memorability I
Original Images
Figure 15: Generated images by StyleGAN2 with their corresponding memorability scores.
This figure shows the modified images when latent space of the StyleGAN2 was used to determine
the separating hyperplane. Square-shaped faces were fed to the assessor.
► Increasing memorability
15
Under review as a conference paper at ICLR 2022
A.2 Layerwise modifications
Original Images
I∙
Decreasing attribute 彳
.Increasing attribute
Memorability Score
Square-shape faces
Figure 16: The effect of the changes in the 1st layer of the extended latent space on memora-
bility score. This layer mostly affects shape of the face. Increasing this attribute makes the face
smaller, whereas decreasing this attribute makes the face larger, which usually may cause a decrease
in the memorability score.
Oval-shape faces
Decreasing attribute .
叵	R41¾¾⅝y
Original Images
0.39
q Increasing attribute
Square-shape faces
Oval-shape faces
Figure 17: The effect of the changes in the 2nd layer of the extended latent space on memora-
bility score. This layer mostly affects hair, pose of the face, and the direction of the eyes and shows
how these attributes contribute to the memorability score.
16
Under review as a conference paper at ICLR 2022
Decreasing attribute 彳
Original Images
0.39
.Increasing attribute
Memorability Score	Layer Coelficient level
Square-shape faces
Oval-shape faces
Figure 18: The effect of the changes in the 3rd layer of the extended latent space on memora-
bility score. This layer mostly affects shape and seriousness of the faces. We observed that moving
this layer, in the positive direction of the corresponding layer in the memorability vector (w*), will
highly increase the memorability score.
----- level = -3	----- original ------------ level = +2
Decreasing attribute .
Original Images
^30^^j^^ Ξ3Ξ⅛P^^	∣2043
OO vol
.Increasing attribute
Memorability Score
Square-shape faces
Layer Coelficient level
Oval-shape faces
Figure 19: The effect of the changes in the 4th layer of the extended latent space on memora-
bility score. This layer mostly affects shape of the face (especially the chin). We can observe that
changes in this attribute, largely contribute to the memorability of the face and moving this layer in
the positive direction of the corresponding layer in the memorability vector (w*), will increase the
memorability score.
17
Under review as a conference paper at ICLR 2022
Decreasing attribute 彳
Original Images
.Increasing attribute
B-su<υα
Square-shape faces
Figure 20: The effect of the changes in the 5th layer of the extended latent space on memora-
bility score. This layer mostly affects nose, lips, facial weight, and smile. This is one of the most
important layer that plays a role in determining the memorability score.
Oval-shape faces
Decreasing attribute .	Original Images	t Increasing attribute
g) 0.7
% 0.6
Layer Coelficient level
Square-shape faces
Oval-shape faces
Figure 21: The effect of the changes in the 6th layer of the extended latent space on memorabil-
ity score. This layer mostly affects the smile and form of the lips. We observe that when we move
this layer, in the positive direction of the corresponding layer of the memorability vector (w*), the
memorability score will increase hugely and the person’s lips will become thicker. However, when
you move it in the opposite direction, the person’s lips will become thinner and the memorability
score will decrease.
18
Under review as a conference paper at ICLR 2022
Decreasing attribute 彳
g> 0.7
Original Images
.Increasing attribute
Square-shape faces
Oval-shape faces
Figure 22: The effect of the changes in the 7th layer of the extended latent space on memora-
bility score. This layer mostly affects make-ups and facial hair. We observe that when we move
this layer, in the positive direction of the corresponding layer of the memorability vector (w*), the
memorability score will drastically increase and the makeup starts to appear on the person’s face.
The lips will become thicker and the eyebrows shape and the person’s skin changes.
Memorability Score	Layer Coelficient level
----- level = -3 --------- original ------------ level = +2
Memorability Score
Square-shape faces
Oval-shape faces
Figure 23:	The effect of the changes in the 8th layer of the extended latent space on memora-
bility score. This layer mostly affects the eyes and the hair color.
19
Under review as a conference paper at ICLR 2022
Decreasing attribute L
Original Images
Square-shape faces
F Increasing attribute
Oval-shape faces
Figure 24:	The effect of the changes in the 9th layer of the extended latent space on memorabil-
ity score.This layer mostly affects the facial hair, hair color type and skin color. moving this layer,
in the positive direction of the corresponding layer of the memorability vector (w*), will make the
hair color gold and some shadows and facial hair (if the person is male), will appear on the face.
Decreasing attribute .	Original Images	、Increasing attribute
Square-shape faces
Oval-shape faces
Figure 25:	The effect of the changes in the 10th layer of the extended latent space on mem-
orability score. The changes in this layer or mostly responsible for modifications on skin color
and eyes. We observe, the changes in this layer are not as effective as other layers to modify the
memorability score.
20
Under review as a conference paper at ICLR 2022
Decreasing attribute .
Original Images
.Increasing attribute
Square-shape faces
Oval-shape faces
Figure 26: The effect of the changes in the 11th layer of the extended latent space on memora-
bility score. Changes in this layer control the skin color and face brightness. As it is shown, this
layer does not play an important role in modifying memorability score of the face.
A.3 Face Memorability Assessors
In order to train the models, we split the 10k US Face Database images into train, validation and test
split. We used 80 percent of the data as the training samples and used 10 percent of the data for each
of the test and validation splits. Euclidean distance was used as the loss function and the batch size
was set to 64. Moreover, we leveraged Adam optimizer to train our models. Due to large false alarm
rates in human face images, we trained our models both with raw memorability scores (computed
by hit rate) and corrected memorability scores (considering false alarm rate). We also tried some
simple augmentations on the dataset and found, the score of the models will slightly increase if we
use a simple augmentation like random horizontal flipping(p = 0.5).
Consistent with Khosla et al. Khosla et al. (2013b), we observed when the corrected hit rate scores
are used, all models outperform the case when only hit rate scores are used. That is because false
alarm rate introduces noise to memorability scores, therefore, the models perform better when we
reduce the noise by correcting for false alarms. We have brought the rank correlation scores using
pretrained VGG16, ResNet50 and SENet50 using hit rate and true hit rate values.
Table 3: Memorability scores of the models pre-trained on face recognition (on VGGFaces database)
and fine-tuned on 10K US face database. Note that all these computational models, produce larger
Spearman’s rank correlation score when true hit rate scores are used.
Model	Hit Rate Score	True Hit Rate Score
VGG16	0.445 =	0.579
ResNet50	0.433	0.607
SENet50	0.448	0.601
A.4 Finding hyperplane in the latent space
In this work, we have provided the results of the separating hyperplane accuracy in extended latent
space. We utilized the latent space to find the separating hypeprlane in the latent space of StyleGAN2
and reported the accuracy of the hyperplane.
21
Under review as a conference paper at ICLR 2022
Table 4: Accuracy of the separating hyperplane, based on the method for dividing images into high-
memorable and low memorable images, the shape of the images, and the assessor. In this case latent
space (R512) is used to find the separating hyperplane. We can observe that the accuracy of the
hyperplane is lower than the case when extended latent space is used.
Assessor	Median		Mean	
	OVal	Square	Oval	Square
ResNet50	0.699	0.686	0.706	0.683
SENet50	0.696	0.723	0.700	0.733
VGG16	0.689	0.695	0.697	0.705
A.5 Modifying the faces conditionally
As we described previously, one of the benefits of our work is that it makes it possible to modify the
memorability scores of the faces conditionally. Different hyperplanes for different face attributes
could be used and then with projection, we can try to maintain the corresponding attributes un-
changed. As there is a correlation between different face attributes, choosing large weights and
attempting to change the memorability scores drastically, may affect the attribute. We showed the
attempt to maintain smile and age attributes in Figure 27 as an example. However, this method could
be applied to a variety of face attributes.
Figure 27: Modifying memorability scores of the faces, with the condition to maintaining smile
and age. This figure shows how projection can affect memorability and the special attribute that we
are aiming to maintain unchanged.
A.6 Modifying memorability of generated non-face images by StyleGAN
We extended our experiments and tested our method on other non-face images. We leveraged pre-
trained StyleGAN2 on churches, cats, horses and cars. In here, we used MemNet as our memo-
rability assessor. (See Table 5 for accuracy of the hyperplanes in churches, cats, horses and cars
augmented latent space.)
Table 5: Accuracy of the separating hyperplane, based on the weights of the generator.
Weight	Accuracy
Cats	0.7875
Horses	0.8897
Cars	0.8581
Churches	0.8325
22
Under review as a conference paper at ICLR 2022
Decreasing memorability .
Figure 28: Generated horse images by StyleGAN2 with their corresponding memorability
scores. This figure shows the modified images when extended latent space of the StyleGAN2 was
used to determine the separating hyperplane.
Original Images
Increasing memorability
Decreasing memorability I
Original Images
► Increasing memorability
Figure 29: Generated cat images by StyleGAN2 with their corresponding memorability scores.
This figure shows the modified images when extended latent space of the StyleGAN2 was used to
determine the separating hyperplane.
A.7 Modifying memorability of generated object images by BigGAN
Lastly, we tried to show the effectiveness of our method on generated images by BigGAN. We gen-
erated 200k images by 512 × 512 BigGAN-deep (Brock et al., 2018), predicted their memorability
scores by our assessor, and divided them into low-memorable and highly-memorable images. We
observed that the effect of the modifications. is similar to Goetschalckx et al. (2019). Increasing the
23
Under review as a conference paper at ICLR 2022
Decreasing memorability .
Original Images
，Increasing memorability
Figure 30: Generated car images by StyleGAN2 with their corresponding memorability scores.
This figure shows the modified images when extended latent space of the StyleGAN2 was used to
determine the separating hyperplane.
Decreasing memorability [
，Increasing memorability
Original Images
0.55
0.62
■ 6
4
0.54
0.60
0.66
0.62
0.68
0.71
Figure 31: Generated church images by StyleGAN2 with their corresponding memorability
scores. This figure shows the modified images when extended latent space of the StyleGAN2 was
used to determine the separating hyperplane.
memorability scores, caused the images to become zoomed-in, in some cases the color changed and
also in a few cases (Cheese burger and snake in Figure 35a, made the objects rounder.
24
Under review as a conference paper at ICLR 2022
-3 -2 -1 O 1	2	3
Memorability coefficient
-3 -2 -1 0	1	2	3
Memorability coefficient
(a) Cats
(b) Horses
-3 -2 -1 0	1	2	3
Memorability coefficient
-3 -2 -1 0	1	2	3
Memorability coefficient
(c) Cars
(d) Churches
Figure 32: The effectiveness of our method for modifying memorability scores tested on 5k gener-
ated images for each category. As depicted the distribution and mean memorability score of images
changes with the coefficient used for memorability modification
Decreasing memorability .	Original Images
，Increasing memorability
0.82
0.86
0.89
0.90
0.71
0.79
0.80
0.81
0.82
0.83
0.79
0.84
0.85
0.86
0.77
0.79
0.80
0.83
0.87
0.73
0.76
0.81
0.84
Figure 33: Generated images by 512 × 512 BigGAN-deep with their corresponding memora-
bility scores. This figure shows the modified images when the latent space of the BigGAN (R128)
was used to determine the separating hyperplane.
25
Under review as a conference paper at ICLR 2022
Decreasing memorability I
► Increasing memorability
0.72
0.76
Original Images
0.60
0.75
0.79
0.82
0.68
0.71
0.73
0.79
0.84
I 0.69 I
0.79
0.64
0.75
0.79
0.82
Figure 34: Generated images by 256 × 256 BigGAN with their corresponding memorability
scores. This figure shows the modified images when the latent space of the BigGAN (R140) was
used to determine the separating hyperplane.
(a) 512 × 512 BigGAN-deep (b) 256 × 256 BigGAN
Figure 35: The effectiveness of our method for modifying memorability scores tested on 20k gener-
ated images. As depicted the distribution and mean memorability score of images changes with the
coefficient used for memorability modification
26