Under review as a conference paper at ICLR 2022
Gradient-based meta-solving and its applica-
tions to iterative methods for solving differ-
ENTIAL EQUATIONS
Anonymous authors
Paper under double-blind review
Ab stract
In science and engineering applications, it is often required to solve similar com-
putational problems repeatedly. In such cases, we can utilize the data from pre-
viously solved problem instances to improve efficiency of finding subsequent so-
lutions. This offers a unique opportunity to combine machine learning (in partic-
ular, meta-learning) and scientific computing. To date, a variety of such domain-
specific methods have been proposed in the literature, but a generic approach for
designing these methods remains under-explored. In this paper, we tackle this
issue by formulating a general framework to describe these problems, and pro-
pose a gradient-based algorithm to solve them in a unified way. As an illustration
of this approach, we study the adaptive generation of initial guesses for iterative
solvers to speed up the solution of differential equations. We demonstrate the per-
formance and versatility of our method through theoretical analysis and numerical
experiments.
1	Introduction
It is common and important in science and engineering to solve similar problems repeatedly. For
example, in material science, a tremendous amount of physical and numerical experiments are con-
ducted to discover and characterize new materials (Schmidt et al. (2019)). For another example,
in computational fluid dynamics, many methods involve solving a Poisson equation to compute the
pressure field in every time step of the simulation (Ajuria Illarramendi et al. (2020)). In these situa-
tions, we can utilize the data of the previously solved problems to solve the next similar but unseen
problems more efficiently, and machine learning is a natural and effective approach for this.
Thus, in recent years, many learning-based methods have been proposed for repeated solutions of
computational problems such as partial differential equations (PDEs) (Tang et al. (2017); Ozbay
et al. (2021); Tompson et al. (2017); Hsieh et al. (2018); Huang et al. (2020)). For example, in Tang
et al. (2017), Ajuria Illarramendi et al. (2020), and Ozbay et al. (2021), convolutional neural net-
works are used to predict the solution of Poisson equations, and Ajuria Illarramendi et al. (2020) and
Ozbay et al. (2021) propose to use the predicted solution as an initial guess of traditional numerical
methods. Hsieh et al. (2018) combines a neural network and an iterative solver to accelerate it with
maintaining the convergence guarantee. In addition to the regular supervised learning approaches,
there are several works where meta-learning approaches are taken to solve computational problems
(FeliU-Faba et al. (2020); Chen et al. (2020); Psaros et al. (2021); Guo et al.(2θ2l)). Meta-Iearning,
or learning to learn, leverages previous learning experiences to improve future learning performance
(Hospedales et al. (2021)), which fits the motivation utilizing the data from previously solved equa-
tions for the next one. For example, Chen et al. (2020) use meta-learning to generate a smoother
of the Multi-grid Network for parametrized PDEs. Psaros et al. (2021) propose a meta-learning
technique for offline discovery of physics-informed neural network loss functions.
Although many methods have been proposed in this direction, they are often problem-specific. In
other words, there lacks both a unified framework to explain them and a general design pattern to
adapt them to new problem settings. On the other hand, in the machine learning literature, there ex-
ists a general methodology - gradient-based meta-learning (Finn et al. (2017)) - that covers a variety
of meta-learning problem settings. In this paper, we generalize this approach to yield a framework,
1
Under review as a conference paper at ICLR 2022
which we call gradient-based meta-solving (GBMS), that encompasses both learning and computa-
tional problems. This offers a general means to understand and develop learning-based algorithms
to speed up computation. As an illustration of our approach, we apply GBMS to accelerate the
solution of differential equations with iterative methods through learning. We show the advantage
of the proposed algorithm over the baseline classical and learning-based approaches through theo-
retical analysis and numerical experiments. Finally, we incorporate the algorithm into a practical
application and demonstrate its versatility and performance.
2	Gradient-based meta-solving
In this section, we introduce our core idea of gradient-based meta-solving. First, we formulate
a class of problems, which we call meta-solving, that includes both ordinary meta-learning and
learning-based computational problems. We then propose a general gradient-based algorithm for
solving them. Under our formulation, many methods proposed in related works can be regarded as
special cases of the GBMS algorithm.
2.1	General formulation of meta-solving
Let us now introduce the general formulation of meta-solving. We first fix the required notations.
A task τ is a tuple τ = (Dτ , Uτ , Lτ) consisting of a dataset Dτ, a solution space Uτ, and a loss
function Lτ . A solution space Uτ is a set of parametric candidate solutions, which is usually a
subset of RN for some N ∈ N. A loss function Lτ is a function from Uτ to R≥0 that measures
the quality of solution candidates. To solve a task T means to find an approximate solution U ∈ Ulr
which minimizes Lτ(∙). Meta-SOlving considers the solution of not one, but a distribution of tasks
by a learnable solver. Thus, we consider a task space (T, P) as a probability space that consists
of a set of tasks T and a task distribution P, which is a probability measure defined on a suitable
σ-algebra on T. A solver Φ is a function from T × Θ to U , where U = Sτ∈T Uτ. θ ∈ Θ is
the parameter of Φ, and Θ is its parameter space. Here, θ may or may not be trainable, depending
on the problem. Then, solving a task τ ∈ T by an algorithm Φ with a parameter θ is denoted by
Φ(τ; θ) = U. A meta-solver Ψ is a function from T X Ω to Θ, where ω ∈ Ω is a parameter of
Ψ and Ω is its parameter space. A meta-solver Ψ parametrized by ω ∈ Ω is expected to generate
an appropriate parameter θτ ∈ Θ for solving a task τ ∈ T with a solver Φ, which is denoted by
Ψ(τ; ω) = θτ. Then, by using the notations above, our meta-solving problem is defined as follows:
Definition 1 (Meta-solving problem). For a given task space (T, P), solver Φ, and meta-solver Ψ,
find ω ∈ Ω which minimizes ET〜P [Lτ(Φ(τ]Ψ(τ; ω))].
We present some familiar examples, which can be regarded as special cases of the meta-solving
problem. First, we can see that conventional meta-learning problems fall in this formulation.
Example 1 (Few-shot learning). As an example of the meta-learning problem, we take the few-
shot regression problem with MAML (Finn et al. (2017)). The components of the problem are the
following. The task τ is to learn a regression model from data. The dataset is Dτ = {(xi, yi)iK=1},
which satisfies y = fτ (x) for an unknown function fτ. Dτ is divided into the training set Dτtrain
and validation set Dτval. The solution parameter space Uτ is a weights space of a neural network
(NN) that models fτ . Note that U = Uτ because the architecture of NN is shared across all tasks.
The approximate solution U ∈ U is the trained weights of NN, which is obtained by training on
Dτtrain. The loss function Lτ : U → R≥0 is the mean squared error (MSE) on Dτval. The task
distribution (T, P ) is determined by the distribution of the target function fτ and distribution of
samples (x, y). The solver Φ : T×Θ → U is the single step gradient descent to minimize Ltτrain(U) =
∣D≡∣ P(x,y)∈Dtrain kNN(x; U) - yk2. Its parameter θ ∈ Θ is initial weights U(0) of NN, so Θ = U .
Thus, Φ(τ; θ) = U(O) - αVu(0)LTain(U(O)) = U, where α is a learning rate. The meta-solver
Ψ : T × Ω → Θ is considered as a constant function that returns its parameter ω ∈ Ω for any task
τ ∈ T. The parameter ω ∈ Ω is expected to be an appropriate initial weights for all T ∈ T to be
fine-tuned easily. Thus, Ω = Θ = U, and Ψ(τ; ω) = ω = θ = U(O). Note that the output of the
meta-solver, the initial weights U(O), does not depend on T. Then, the few-shot learning problem is
defined as meta-solving problem, which is
min E [Lτ(Φ(τN(τ; ω))] = min E X	∣∣NN(x; ω - αVωLTain(ω)) - y∣∣2 .	⑴
T ~	T ~ (χ,y)∈DTa
2
Under review as a conference paper at ICLR 2022
In addition to the conventional learning problems, we can regard other computational problems,
such as solving a differential equation, as a task of the meta-solving problem. In constrast with
MAML, the inner-loop learning is now replaced with a family of iterative solvers for differential
equations. This necessitates the distinction of the meta-solver parameter space Ω and the solution
space U . Moreover, the meta-solver has to produce a task-specific parameter for the inner solver.
Example 2 (Solving differential equations). Suppose that we need to repeatedly solve similar in-
stances of a class of differential equations with a given numerical solver. The solver has a number
of hyper-parameters, which sensitively affect accuracy and efficiency depending on the problem in-
stance. Thus, finding a strategy to optimally select solver hyper-parameters given a problem instance
can be viewed as a meta-solving problem. The components of the problem are the following. The
task τ is to solve a differential equation. In this example, suppose that the target equation is the
Poisson equation -∆u = fτ with Dirichlet boundary conditions u = gτ . The dataset Dτ contains
data of the differential equation, Dτ = {fτ, gτ}. The solution parameter space Uτ is RNτ. The loss
function LT : UT → R≥o measures the accuracy of U ∈ UT. In this example, the '2-norm of the
residuals obtained by substituting the approximate solution U into the equation can be used. The task
distribution (T, P) is the joint distribution of fT and gT. The solver Φ : T × Θ → U is a numerical
solver with a parameter θ ∈ Θ for the differential equation. In this example, suppose that Φ is the
Jacobi method (Saad (2003)) and θ is its initial guess. The meta-solver Ψ : TX Ω → Θ is a strategy
characterized by ω ∈ Ω to select a parameter, an initial guess, θτ ∈ Θ for each task T ∈ T. Note that
the output of the meta-solver depends on τ, which is different from the case of Example 1. Then,
finding the strategy to select parameters of the numerical solver becomes meta-solving problem.
The above examples explain why we describe our problem as meta-solving instead of meta-learning.
In Example 1, the task τ is learning from data, and the solver Φ is gradient descent. In Example
2, the task τ is solving a differential equation, and the solver Φ is an iterative differential equation
solver. Regardless of the type of task and algorithm, in both cases, the solver Φ solves the task τ,
and we do not distinguish whether Φ is a learning algorithm or other numerical solver. In other
words, learning algorithms such as gradient descent are also a type of numerical solvers, and we
regard learning as a special case of solving. It is also true for the outer learning algorithm to learn
how to solve the task τ with the solver Φ, so learning to solve is a special case of solving to solve.
In this sense, we call it meta-solving.
2.2	Gradient-based meta-solving
In the previous section, we defined meta-solving problems as a generalization of meta-learning
problems, but how can we solve them effectively? For meta-learning problems such as Example 1,
general methodologies in the form of gradient-based meta-learning (Hospedales et al. (2021)), e.g.
MAML (Finn et al. (2017)), have been proposed. In Example 1, MAML solves the minimization
problem (1)by updating ω using the outer gradient descent algorithm ω J ω - β^ωLT (U). MAML
is an algorithm to find good initial weights of the neural network for conventional meta-learning
problems, but it can be generalized to the meta-solving problems. In meta-solving problems, tasks
may not be learning problems, Φ may not be gradient descent, and its parameter θ may not be initial
weights of a neural network. However, we can still employ the same update rule as MAML, as long
as LT, Φ, and Ψ are differentiable. Thus, for differentiable solvers Φ and Ψ, we propose gradient-
based meta-solving algorithm (Algorithm 1) as a generalization of MAML. This is a form of data-
driven algorithm design, and differs from previous works in this direction (e.g. Hutter et al. (2011),
Mitzenmacher & Vassilvitskii (2021), and Balcan (2021)). These focus on discontinuous problems
such as combinatorial optimization, while our framework focuses on differentiable problems.
2.3	Organizing related works
Owing to the general formulation presented above, we can organize several related works on
learning-based methods for scientific computing and describe them in a unified way. We highlight
the advantages of our method using the examples in this section. The detailed description of how
the task, the solver and the meta-solver are defined in each case are found in Appendix A.
First, let us review FeIiU-Faba et al. (2020). This work proposes a neural network architecture
inspired by the nonstantard wavelet form with meta-learning approach to solve the equations con-
taining partial differential or integral operators. It can be regarded as a special case of GBMS, where
3
Under review as a conference paper at ICLR 2022
Algorithm 1: Gradient-based meta-solving algorithm
Require: (P, T): task space, Φ, Ψ: differentiable solver, S: stopping criterion, α: learning rate
Result: ω
1	initialize ω;
2	while S is not satisfied do
3	Sample task T 〜P;
4	Generate parameter of Φ using meta-solver: θτ(ω) J Ψ(τ; ω);
5	Solve task T using solver: U(ω) J Φ(τ; θτ(ω));
6	Update meta-solver parameter: ω J ω 一 αVωLT(u(ω));
7	end
task T is solving the equation, solver Φ is the forward computation of the trained neural network,
θ ∈ Θ is its weights, and meta-solver Ψ is the constant function that returns the weights θ = ω ∈ Ω.
Note that θ does not depend on the task T . We also note that other works where neural networks
replace a whole or part of numerical methods (Tang et al. (2017); Ozbay et al. (2021); Tompson et al.
(2017); Hsieh et al. (2018)) can be organized in the same way. Thus, the meta-solving formulation
includes many learning-based methods where meta-learning techniques are not explicitly employed.
We take Psaros et al. (2021) as another example. In this work, meta-learning is used to learn a loss
function of the physics-informed neural network, shortly PINN (Raissi et al. (2019)), for solving
PDEs. This also can be considered as a special case of GBMS, where T is training the PINN, the
solver Φ is the gradient descent for training the PINN, θ ∈ Θ is the weights of another neural
network used as the loss function in the training, and the meta-solver Ψ is the constant function that
returns the weights θ = ω ∈ Ω. As in the previous example, θ does not depend on the task T. We
remark that this example and Example 1 are similar in the sense that Φ is gradient descent and Ψ
is the constant function returning neural network’s weights in both examples, though the task T is
different. The unified framework sheds light on a similarity in various methods for various tasks,
which enables us to apply a technique developed for one problem to another easily.
Lastly, let us consider Chen et al. (2020). In this work, meta-learning is used to generate a parameter
of PDE-MgNet, a neural network representing the multigrid method, for solving parametrized PDEs.
This also can be regarded as a special case of GBMS, where T is solving a PDE, the solver Φ is the
PDE-MgNet, whose iterative function is implemented by a neural network φ with weights θ, and the
meta-solver Ψ is another neural network with weights ω to generate θ depending on task T . Note
that the meta-solver Ψ is trained with single step of the solver Φ but tested with multiple steps of Φ.
In other words, this work does not consider the solver Φ itself but instead its iterative function φ in
the training. We will show the importance of this difference in section 3.1.
The above examples show the generality of our meta-solving formulation that organizes a variety of
methods in the systematic way regardless of their type of algorithm. This overall approach allows
us to easily design learning-based methods for new problem settings, and we will demonstrate it in
the next section.
3 GBMS for iterative methods
In this section, we demonstrate how GBMS can be used to yield effective meta-solvers for new prob-
lem settings. In particular, we consider the problem of accelerating iterative methods by adaptively
choosing initial conditions. Iterative methods are powerful tools to solve computational problems.
For example, the Jacobi method and SOR method are used to solve PDEs (Saad (2003)). In iterative
methods, a function φτ , which depends on the task T, is iteratively applied to the current approxi-
mate solution to update it closer to the true solution until it reaches a criterion, such as a certain error
tolerance or number of iterations. These methods require an initial guess as the starting point of the
iterations, and the performance of the method depends on this choice. Thus, adaptively choosing
initial guesses for solvers is an effective way to speed up the computation process.
Here, we apply GBMS to derive a meta-solver that produces effective initial guesses for iterative
solvers. The meta-solving problem here can be viewed as a generalized version of Example 2
beyond Jacobi solvers. The task T is any computational problem which can be solved by iterative
4
Under review as a conference paper at ICLR 2022
methods. For example, τ is solving a PDE as described in Example 2. The task distribution (T, P)
is defined according to each problem. The solver Φ : T × Θ → U is an iterative method with an
initial guess θ = u(0) ∈ Θ, iterative function φτ, and the number of iterations k, so Φ(τ; u(0)) =
φT (u(0)) = u(k) and Θ = U. The meta-solver Ψ: TX Ω → Θ is a function parametrized by
ω ∈ Ω, which takes T ∈ T as an input and generates an initial guess θτ = uT0) ∈ Θ for the solver
Φ. We implement Ψ by a neural network, so ω ∈ Ω is its weights. Then, Ψ is trained to minimize
the expectation of Lτ (u(k)) by the gradient descent. Since both Φ and Ψ are implemented in a deep
learning framework, VωLT (u(k)) can be computed by back-propagation. The entire process of the
algorithm is presented in Algorithm 2.
Hereafter, we consider solving a PDE as a task of the meta-solving problem, but the method is
applicable to other tasks, such as root finding. Note that although Huang et al. (2020), Ajuria Il-
larramendi et al. (2020), and Ozbay et al. (2021) propose to use initial guesses generated by neural
networks, these initial guesses are independent of the solvers. On the other hand, our initial guesses
are optimized for each solver. We will show its advantage in the following sections.
Algorithm 2: Gradient-based meta-solving algorithm for iterative solvers
Require: (P, T): task space, Ψ: differentiable solver, S : stopping criterion, k : number of
iterations of the iterative solver, α: learning rate
Result: ω
1	initialize ω;
2	while S is not satisfied do
3	Sample task T 〜P;
4	Form iterative function φτ depending on τ ;
5	Generate initial guess using meta-solver: uT0)(ω) J Ψ(τ; ω);
6	for i J 1 to k do
7	I Update approximate solution by iterative function: u(τi) (ω) J φτ (u(τi-1) (ω));
8	end
9	Update meta-solver parameter: ω J ω - αVω Lτ (u(τk) (ω));
10	end
3.1 Toy problem: 1D Poisson equations
To study the property of the proposed algorithm, we consider solving 1D Poisson equations as a toy
problem. First, we show a theorem that guarantees the improvement of the proposed meta-solving
approach for the Jacobi method and linear neural networks. Then, we demonstrate that the theorem
numerically holds for another iterative method and practical nonlinear neural network.
3.1.1 Theoretical analysis
Let us recall Example 2 and set the domain of interest D = (0, 1). Then, the target equation becomes
the following 1D Poisson equation with Dirichlet boundary condition:
d* 2
— dX2U(X) = f (X)，X ∈(0,1)
(2)
u(0) = a, u(1) = b.
To solve this equation numerically, it is discretized with finite difference scheme, and we rewrite it as
the matrix equation Au = f, where the domain [0, 1] is discretized into N points, so A ∈ RN×N and
u, f ∈ RN . Suppose that we solve the equation Au = f with the Jacobi method under randomly
sampled fτ. Then, the meta-solving problem for solving 1D Poisson equations is defined by the
following. The task T is to solve Au = fτ . The dataset is Dτ = {fτ, uτ}, where uτ is the solution
of Au = fτ. The solution parameter space is UT = RN. The loss function is LT(U) = IluT 一 U∣∣2.
The task distribution (T, P) is determined by the distribution of fτ, denoted by Pf. It is assumed
to be centered and normalized, i.e. the mean of fT is 0 and the covariance is the identity matrix.
The solver Φk : T × Θ → U is the Jacobi method with k iterations starting at an initial guess
5
Under review as a conference paper at ICLR 2022
U(O) = θ ∈ Θ. Its iterative function is φτ(u) = Mu + 2 fτ, where M = I - 2A. To summarize,
Φk(τ; U(O)) = φk(u(O)) = U. Note that Φo is the identity map. The meta-solver Ψ : TX Ω → Θ
is a linear neural network with weights ω ∈ Ω. It can be represented as matrix multiplication for
some matrix W, so Ψ(τ; ω) = Wfτ = U(O). Here, we assume rank(W) < N to avoid the trivial
solution W = A-1, i.e. the meta-solver does not have the capacity to produce an exact solution for
each task. Then, the meta-solving problem becomes
min E [Lτ (Φ(τ; Ψ(τ; ω))] = min E	Uτ - φτk(Wfτ)2.	(3)
ω∈Ω T〜P	W fτ〜Pf
As for this meta-solving problem, the following theorem holds. The proof is in Appendix B.
Theorem 1 (Guarantee of improvement by meta-solving). For any k ≥ 0, (3) has the unique mini-
mizer Wk. Furthermore, if k1 < k2, then for all k ≥ k2,
E Uτ-φτk(Wk1fτ)2≥ E Uτ-φτk(Wk2fτ)2,	(4)
fτ 〜Pf	fτ 〜Pf
where the equality holds if and only if Wk1 = Wk2.
Theorem 1 guarantees improvement of meta-solving for the considered setting. For example, sup-
pose k1 = 0 (regular supervised learning, i.e. directly predicting the solution without considering
the solver) and k2 = 5. Then, the theorem implies that the meta-solver trained with 5 Jacobi itera-
tions is expected to give an better initial guess than the meta-solver obtained by regular supervised
learning for any number of Jacobi iterations larger than 5. More generally, Theorem 1 shows that
meta-learning with a higher number of Jacobi iterations in the inner solver improves the perfor-
mance, provided one carries out at least a greater number of Jacobi iterations during inference. This
shows the advantage of the meta-solving approach over regular supervised learning.
3.1.2 Numerical examples for more general cases
The key insight from the previous theoretical analysis is that meta-solving leverages the properties
of the solver and adapts the selection of initial conditions to it. Here, we show using numerical
examples that this is the case for more complex scenarios, involving different task distributions,
different iterative solvers, and a practical nonlinear neural network.
The meta-solving problem in this section is defined by the following. The task τ is the same as
the previous section 3.1.1. Let the number of discretization points N be 512. The task distribution
(T, P ) is determined by the distribution of U. We consider two distributions Ps and Ph, where the
solution U consists of sine functions and hyperbolic tangent functions respectively. Their details
are listed in Appendix C.1. For each distribution, we prepare 30,000 tasks for training, 10,000 for
validation, and 10,000 for test. To solve the tasks, we use the Jacobi method and the Red-Black
ordering SOR method (Saad (2003)) with k iterations starting at an initial guess U(O) = θ ∈ Θ,
denoted by ΦJac,k and ΦSOR,k respectively. Note that they are implemented by convolutional layers.
We consider two meta-solvers. One is a heuristic initial guess generator ΨBL that takes τ as an input
and gives the heuristic initial guess, which is the linear interpolation of the boundary condition. ΨBL
does not have a parameter and is used as a baseline. The other is a variant of 1D U-Net (Ronneberger
et al. (2015)) Ψnn With weights ω ∈ Ω, which takes f and the heuristic initial guess Ψbl(t) as
inputs and generates an initial guess θτ ∈ Θ for the solver Φ.
The meta-solver ΨNN is trained with solvers ΦJac,k, ΦSOR,k with k = 0, 4, 16, 64 by using the Algo-
rithm 2. For each setting, ΨNN is trained six times with different random seeds. The details of the
architecture and hyper-parameters of ΨNN are found in Appendix D.1. The trained meta-solver ΨNN
and baseline ΨBL are tested with solvers ΦJac,k, ΦSOR,k with k = 0, 4, 16, 64. The performances of
the meta-solvers are measured by the MSE on the test set and presented in Table 1. Figure 1 shows
the comparison of the initial guesses U(O) obtained by ΨNN with ΦJac,O and ΦJac,64. Figure 2 is the
convergence plot of ΨNN trained with ΦSOR,k on Ps .
The results show that the meta-solver ΨNN is optimized for each corresponding solver Φ. In Table
1, the best performance for a given test solver is achieved at the diagonal where the training and test
solvers match. We can explicitly investigate this adaptive phenomena by visualizing the meta-solver
outputs for a representative problem instance. Figure 1 shows that the meta-solver trained with more
iterations tends to ignore high frequencies and focus more on low frequencies. This is because the
6
Under review as a conference paper at ICLR 2022
Jacobi method converges fast in high frequencies but slow in low frequencies (Saad (2003)), and the
trained meta-solver compensates the weakness of the solver. These results show that the meta-solver
actively adapts to the nature of the inner-loop solver.
Furthermore, we can observe that Theorem 1 holds numerically for the results. Figure 2 illustrates
that a meta-solver trained with more iterations is always better than those trained with fewer itera-
tions, provided the number of iterations during testing is large. In addition, at 10,000 iterations, the
error of ΨNN trained with ΦSOR,64 (MSE of 0.0054 and relative error of 0.013) remains approxi-
mately 8% better than ΨNN trained with ΦSOR,0, which shows that the GBMS keeps its advantage
for a large number of iterations. These results support that Theorem 1 holds for various practical
settings with significant improvement.
Table 1: Average MSE of GBMS for solving Poisson equations. Boldface indicates best perfor-
mance for each column. Standard deviations are presented in Table 3 in Appendix E.
(a) MSE on Ps
Ψ	Trained with	Tested with						
		ΦJac,0	ΦJac,4	Φ Jac, 16	ΦJac,64	ΦSOR,4	ΦSOR,16	ΦSOR,64
ΨNN	Φjac,0 = ΦSOR,0	0.222	0.220	0.219	0.214	0.218	0.212	0.193
	Φjac,4	0.277	0.212	0.210	0.205	0.210	0.203	0.186
	Φ Jac, 16	1.169	0.231	0.209	0.204	0.221	0.203	0.185
	Φ Jac, 64	17.684	3.066	0.279	0.198	0.299	0.198	0.179
	ΦSOR,4	1.140	0.982	0.753	0.496	0.201	0.195	0.179
	ΦSOR,16	25.786	6.145	1.134	0.554	0.392	0.185	0.170
	ΦSOR,64	22.451	8.306	2.459	0.744	2.536	0.224	0.169
ΨBL	-	17.033	12.184	9.482	7.926	9.083	7.611	6.606
				(b) MSE on Ph				
		Tested with						
Ψ	Trained with	ΦJac,0	ΦJac,4	Φ Jac, 16	ΦJac,64	ΦSOR,4	ΦSOR,16	ΦSOR,64
ΨNN	Φjac,0 = ΦSOR,0	1.049	1.041	-~1.030	1.005	1.028	0.994	0.922
	Φjac,4	1.059	1.023	1.006	0.976	1.002	0.964	0.888
	φJac,16	1.202	1.049	1.006	0.971	1.000	0.958	0.885
	Φ Jac, 64	2.017	1.572	1.142	0.940	1.058	0.920	0.839
	ΦSOR,4	1.632	1.479	1.383	1.333	0.984	0.938	0.862
	ΦSOR,16	3.305	2.597	1.764	1.285	1.305	0.928	0.845
	φSOR,64	7.683	6.009	3.580	1.417	3.029	1.116	0.756
ΨBL	-	10.761	10.744	10.695	10.539	10.681	10.463	9.908
3.2 Application: Incompressible flow simulations
In this section, we introduce an application of GBMS for iterative solvers. GBMS is developed for
repeatedly solving task τ sampled from a given task distribution P . One of the typical situations
where GBMS is effective is that similar differential equations are repeatedly solved as a step of
solving a time-dependent problem. For example, in many methods of incompressible flow simula-
7
Under review as a conference paper at ICLR 2022
Figure 2: Convergence plot of Ψ trained with ΦSOR,k on Ps. Vertical dotted lines are k = 4, 16, 64.
tions, Poisson equations are solved to compute the pressure field at every time step, and this process
occupies a large part of the computation time for fluid simulations (Ajuria Illarramendi et al. (2020)).
Problem definition. Let us now describe the incompressible flow simulation setup. We consider
2D channel flow with a fluctuating inflow. The velocity field v and pressure field p follow the
Navier-Stokes equations in the form:
∂v	1
———+ (v ∙ V)v =——Vp + V∆v
∂t	ρ
∆p = -ρV ∙ ((v ∙ V)v)
(5)
(6)
where ρis the density, and ν is the viscosity. The equation (6) is called the pressure Poisson equation.
Let ρ = 1, ν = 0.01. Let the domain of interest D be (0, 1) × (0, 1) and the time t ∈ [0, 1]. Let
y = 0 and y = 1 be the non-slip wall and fluctuating inflow vin defined on x = 0. By using the
finite difference scheme, we discretize the equations into 128 by 128 spacial grids and 1,000 time
steps. Then, v and p are computed alternately by the discretized equations. Details of the numerical
scheme for solving Navier-Stokes equations follow Barba & Forsyth (2018). GBMS for iterative
method is used for solving the pressure Poisson equation (6).
Let us define the meta-solving problem for the above setting. The task τ is to solve a pressure
Poisson equation. The dataset Dτ is {fτ, pτ, fτ-1, pτ-1, fτ-2, pτ-2}, where fτ is the right hand
side and pτ is the solution of the pressure Poisson equation. fτ-i , pτ-i are those at ith previous
time step. Although pτ is determined by fτ theoretically, additional features of previous timesteps
can provide useful information to determine a good guess for pτ . The solution parameter space Uτ
is R128×128. The loss function is the relative '2-error. The task distribution (T, P) is determined
by the distribution of vin and the computation process of the simulation. Let Pin be the distribution
of vin, whose detail is found in Appendix C.2. We prepare 20 inflows for training, 10 for validation,
and 10 for test, which are denoted by Vitnrain , Vivnal and Vitnest respectively. Then, we generate datasets
under each inflow by solving the Navier-Stokes equations with the SOR method without GBMS,
where the relative error tolerance is 10-9 . The solver ΦSOR,k is the SOR method with k iterations
starting at an initial guess θ ∈ Θ. We consider two meta-solvers. One is a baseline ΨBL that takes
τ as an input and gives the heuristic initial guess, which is the solution of the previous step Poisson
equation pτ-1. This choice is based on the domain knowledge of fluid simulations and standard in
the literature (Ferziger & Peric (2002)). The meta-solver ΨNN is a variant of 2D U-Net with weights
ω ∈ Ω, which takes DT \ {pτ} as an input and generates initial guess θτ ∈ Θ for the solver ΦsoR,k.
Note that ΨNN trained with ΦSOR,0 (i.e. solver-independent initial guess) is similar to the method
in Ajuria Illarramendi et al. (2020) and is considered as a data-driven baseline in this paper. We also
note that the choice of ΨNN is arbitrary, and any other problem-specific neural network architectures
can be used as ΨNN.
Training. We train the meta-solver ΨNN with the SOR solver ΦSOR,k with k = 0, 4, 16, 64 by using
the Algorithm 2. The details of the architecture and hyper-parameters of ΨNN are found in Appendix
D.2. In addition, we use data augmentation during training to prevent overfitting to the high-accuracy
training data. During the training, we augment data by proceeding 10 time steps with ΦSOR,k and
ΨNN being trained. Specifically, after computing the loss for pτ , we proceed one time step using
ΦSOR,k and ΨNN, and compute the loss for nextpτ+1 using the computed previous step information.
8
Under review as a conference paper at ICLR 2022
Then, it is repeated 10 times for each mini batch. Without the data augmentation, the inputs of ΨNN
are from the prepared dataset and are always accurate during training. However, during inference,
the inputs of ΨNN are the outputs of the simulation at previous time steps, which can be of a slightly
different distribution than encountered during training (i.e. distribution shift) due to numerical errors
and generalization gaps. This then causes further accuracy problems for the simulation at the next
step, and this issue compounds itself in time. This eventually degrades the performance if the shift
in distribution is not dealt with. The data augmentation is used to prevent it. We remark that this
training process does not require the whole of the simulation to be differentiable. This is practically
important because we can employ GBMS with established solvers by only replacing the Poisson
solver and can utilize the other parts without any modification.
Evaluation. We incorporate the trained meta-solvers into simulations and evaluate them by the
relative `2 -error of the velocity field on test inflows under a fixed number of the SOR iterations.
More specifically, the performance metric is 1VLy P5n∈vtest 盍 P1=10ι kvi-jik, where Vi is the
ground truth of ith step velocity under the inflow vin, which is obtained by using ΨBL and ΦSOR,k
with a large enough k to achieve the relative error tolerance of 10-9, and Vi is the ith step velocity
obtained by using the trained ΨNN and ΦSOR,k with a fixed k. To stabilize the simulation, the first
100 steps are excluded, and the simulation with the trained ΨNN starts with 101 steps.
The results presented in Table 2 demonstrate the advantage of GBMS. Although all ΨNN diverge for
ΦSOR,0 because of error accumulation, for the other solvers, the best performance with significant
improvement is achieved at the diagonal where the training and test solvers match. For example, for
the test solver ΦSOR,4, the accuracy of ΨNN trained with ΦSOR,4 is approximately 50 times better
than regular supervised learning (ΨNN trained with ΦSOR,0 ) and 130 times better than the classical
baseline ΨBL . Furthermore, GBMS keeps its advantage for a larger number of iterations than the
number which it is trained with. For example, for ΦSOR,64, the meta-solver trained with ΦSOR,64
has the best performance, followed by one trained with ΦSOR,16, ΦSOR,4, and ΦSOR,0 in that order.
As for computation time, ΨNN trained with ΦSOR,4 and tested with ΦSOR,4 (GBMS approach) takes
11 sec to simulate the flow for one second, while ΨBL tested with ΦSOR,128 takes 105 sec to achieve
similar accuracy to the GBMS approach. Also, ΨNN trained with ΦSOR,0 and tested with ΦSOR,64
takes 73 sec to achieve the similar accuracy. Since it takes approximately 7 hours to train ΨNN with
a GeForce RTX 3090, our approach is effective if we simulate the flow for more than 268 seconds,
which can be easily satisfied in practical settings. To summarize, GBMS performs best for a fixed
number of iterations and can achieve high accuracy within a smaller number of iterations and shorter
computation time than the classical baseline and regular supervised learning.
Table 2: Relative '2-error of GBMS on incompressible flow simulations.
Ψ	Trained with	Tested with Φsor,o	ΦSoR,4	ΦSoR,16	ΦSoR,64
ΨNN	Φsor,o	NaN	0.054861	0.008543	0.001284
	Φsor,4	NaN	0.001171	0.001625	0.000864
	Φsor,i6	NaN	0.017513	0.000829	0.000723
	ΦsOR,64	NaN	NaN	0.005567	0.000312
ΨBL	-	1.988177	0.152626	0.014112	0.002941
4	Conclusion
In this paper, we proposed a formulation of meta-solving and a general gradient-based algorithm
(GBMS) to solve this class of problems. In the proposed framework, many related works that used
neural networks for solving differential equations were organized in a unified way and regarded
as variants of GBMS. Thus, the GBMS approach offers a general design pattern to develop solu-
tion algorithms that blends machine learning and scientific computing. As a concrete illustration,
we applied GBMS to iterative methods for solving differential equations and showed its advantage
over both classical numerical methods and regular supervised learning. In particular, the proposed
method was tested in the incompressible flow simulation and the accuracy was improved by approx-
imately 50 times compared to regular supervised learning and 130 times compared to a classical
baseline for a fixed number of iterative solver iterations. We will study applications of GBMS to
other types of problems such as nonlinear equations in future work.
9
Under review as a conference paper at ICLR 2022
5	Reproducibility Statement
To ensure the reproducibility, we provide the detailed proof of Theorem 1 in Appendix B. As for the
experiments, we provide the details of dataset generation in Appendix C and the details of network
architecture and training hyper-parameters in Appendix D. In addition, we conducted experiments
with different random seeds to obtain robust results. Finally, we will make our source code public
at a later date. Source code with limited documentation is available upon request.
10
Under review as a conference paper at ICLR 2022
References
Ekhi AjUria Illarramendi, Antonio AlgUaciL Michael Bauerheim, Antony Misdariis, Benedicte
Cuenot, and Emmanuel Benazera. Towards an hybrid computational strategy based on Deep
Learning for incompressible flows. In AIAA AVIATION 2020 FORUM, AIAA AVIATION Fo-
rUm. American InstitUte of AeronaUtics and AstronaUtics, JUne 2020.
Maria-Florina Balcan. Data-Driven Algorithm Design. In Beyond the Worst-Case Analysis of Algo-
rithms, pp. 626-645. Cambridge University Press, January 2021.
Lorena Barba and Gilbert Forsyth. CFD Python: the 12 steps to Navier-Stokes eqUations. Journal
of Open Source Education, 1(9):21, November 2018.
Yuyan Chen, Bin Dong, and Jinchao Xu. Meta-MgNet: Meta Multigrid Networks for Solving
Parameterized Partial Differential Equations. arXiv preprint arXiv:2010.14088, October 2020.
Jordi Feliu-Faba, Yuwei Fan, and Lexing Ying. Meta-Iearning pseudo-differential operators with
deep neural networks. Journal of computational physics, 408:109309, May 2020.
Joel H Ferziger and Milovan Peric. Computational Methodsfor Fluid Dynamics. Springer, Berlin,
Heidelberg, 2002.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. In Proceedings of the 34th International Conference on Machine Learning -
Volume 70, ICML’17, pp. 1126-1135. JMLR.org, August 2017.
Yue Guo, Felix Dietrich, Tom Bertalan, Danimir T Doncevic, Manuel Dahmen, Ioannis G
Kevrekidis, and Qianxiao Li. Personalized Algorithm Generation: A Case Study in Meta-
Learning ODE Integrators. arXiv preprint arXiv:2105.01303, May 2021.
Timothy M Hospedales, Antreas Antoniou, Paul Micaelli, and Amos J Storkey. Meta-Learning in
Neural Networks: A Survey. IEEE transactions on pattern analysis and machine intelligence, PP,
May 2021.
Jun-Ting Hsieh, Shengjia Zhao, Stephan Eismann, Lucia Mirabella, and Stefano Ermon. Learning
Neural PDE Solvers with Convergence Guarantees. In International Conference on Learning
Representations, September 2018.
Jianguo Huang, Haoqin Wang, and Haizhao Yang. Int-Deep: A deep learning initialized iterative
method for nonlinear problems. Journal of computational physics, 419:109675, October 2020.
Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Sequential Model-Based Optimization
for General Algorithm Configuration. In Learning and Intelligent Optimization, pp. 507-523.
Springer Berlin Heidelberg, 2011.
Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with Predictions. In Beyond the Worst-
Case Analysis of Algorithms, pp. 646-662. Cambridge University Press, January 2021.
Ali Girayhan Ozbay, Arash Hamzehloo, Sylvain Laizet, Panagiotis Tzirakis, Georgios Rizos, and
Bjorn Schuller. Poisson CNN: Convolutional neural networks for the solution of the Poisson
equation on a Cartesian mesh. Data-Centric Engineering, 2, 2021.
Apostolos F Psaros, Kenji Kawaguchi, and George Em Karniadakis. Meta-learning PINN loss
functions. arXiv preprint arXiv:2107.05544, July 2021.
M Raissi, P Perdikaris, and G E Karniadakis. Physics-informed neural networks: A deep learn-
ing framework for solving forward and inverse problems involving nonlinear partial differential
equations. Journal of computational physics, 378:686-707, February 2019.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional Networks for Biomed-
ical Image Segmentation. In Medical Image Computing and Computer-Assisted Intervention -
MICCAI 2015, pp. 234-241. Springer International Publishing, 2015.
Yousef Saad. Iterative Methods for Sparse Linear Systems: Second Edition. Other Titles in Applied
Mathematics. SIAM, April 2003.
11
Under review as a conference paper at ICLR 2022
Jonathan Schmidt, Mario R G Marques, Silvana Botti, and MigUel A L Marques. Recent advances
and applications of machine learning in solid-state materials science. npj Computational Materi-
als, 5(1):1-36, AUgUst 2019.
Wei Tang, Tao Shan, Xunwang Dang, Maokun Li, Fan Yang, Shenheng Xu, and Ji Wu. Study on a
Poisson’s equation solver based on deep learning technique. In 2017 IEEE Electrical Design of
Advanced Packaging and Systems Symposium (EDAPS), pp. 1-3, December 2017.
Jonathan Tompson, Kristofer Schlachter, Pablo Sprechmann, and Ken Perlin. Accelerating eulerian
fluid simulation with convolutional networks. In Proceedings of the 34th International Conference
on Machine Learning - Volume 70, ICML’17, pp. 3424-3433. JMLR.org, August 2017.
12
Under review as a conference paper at ICLR 2022
A	Details of examples
Example 3 (FeliU-Faba et al. (2020)). FeliU-Faba et al. (2020) propose the neural network archi-
tecture with meta-learning approach that solves the equations in the form Lηu(x) = f (x) with
appropriate boUndary conditions, where Lη is a partial differential or integral operator parametrized
by a parameter fUnction η(x). This work can be described as follows:
• Task τ: The task τ is to solve a Lηu(x) = f(x) for η = ητ:
-	Dataset D” The dataset DT is DT = {ητ, fτ,uτ}, where ητ,fτ,uτ ∈ RN are the [],
right hand side, and solUtion respectively. The reference solUtion uτ is obtained by [].
-	SolUtion parameter space UT : The solUtion parameter space UT is a sUbset of RN for
N ∈ N.
-	Loss fUnction LT : The loss fUnction LT : U → R≥0 is the mean sqUared error with
the reference solution, i.e. LT(U) = IluT - ^∣2.
•	Task space (T, P): The task distribUtion (T, P) is determined by the distribUtion ofηT and
fT.
•	Solver Φ: The solver Φ : T × Θ → UT is implemented by a neural network imi-
tating the wavelet transform, which is composed by three modules with weights θ =
(Θ1,θ2,θ3).	In detail, the three modules, φι(∙; θι), φ2(∙; θ2), and φ3(∙; θ3), repre-
sent forward wavelet transform, mapping η to coefficients matrix of the wavelet trans-
form, and inverse wavelet transform respectively. Then, Φ is represented by Φ(τ; θ) =
φ3((φ2(ητ； θ2)φ1(fτ； θ1)); θ3) = u.
•	Meta-solver Ψ: The meta-solver Ψ : TX Ω → Θ is the constant function that returns its
parameter ω, so Ψ(τ; ω) = ω = θ and Ω = Θ. Note that θ does not depend on T in this
example.
Then, the weights ω = θ is optimized by a gradient descent algorithm as described in Algorithm 1.
Example 4 (Chen et al. (2020)). The target equation in Chen et al. (2020) is a linear systems of
equations Aηu = f obtained by discretizing parameterized steady-state PDEs, where u, f ∈ RN
and Aη ∈ RN ×N is determined by η, a parameter of the original equation. This work can be
described as follows:
•	Task τ: The task τ is to solve a linear system Aηu = f for η=ηT:
-	Dataset DT: The dataset DT is {ηT, fT}.
-	Solution parameter space UT: The solution parameter space UT is RN.
-	Loss function LT : The loss function LT : U → R≥0 is an unsupervised loss based on
the residual of the equation, LT(U) = IlfT 一 A% uk2/IlfTII2.
•	Task space (T, P): The task distribution (T, P) is determined by the distribution ofηT and
fT.
•	Solver Φ: The solver Φ : T × Θ → U is iterations of a function Φt(∙; θ) : U → U that
represents an update step of the multigrid method. φT is implemented using a convolutional
neural network and its parameter θ is the weights corresponding to the smoother of the
multigrid method. Note that weights of φT other than θ are naturally determined by ηT and
the discretization scheme. In addition, φT takes fT as part of its input at every step, but we
write these dependencies as Φt for simplicity. To summarize, Φ(τ; θ) = φk(u(0); θ) = u,
where k is the number of iterations of the multigrid method and u(0) is initial guess, which
is 0 in the paper.
•	Meta-solver Ψ: The meta-solver Ψ : T × Ω → Θ is implemented by a neural network with
weights ω, which takes Aητ as its input and returns weights θT that is used for the smoother
inspired by the subspace correction method.
Then, ω is optimized by a gradient decent algorithm with the number of multigrid iteration k = 1 as
described in Algorithm 1.
13
Under review as a conference paper at ICLR 2022
Example 5 (Psaros et al. (2021)). In Psaros et al. (2021), meta-learning is used for learning a loss
function of the physics-informed neural network, shortly PINN (Raissi et al. (2019)). The target
equations are the following:
Fλ [u](t, x) = 0, (t, x) ∈ [0, T] × D
Bλ [u](t, x) = 0, (t, x) ∈ [0, T] × ∂D
u(0, x) = u0,λ(x), x ∈ D,
(a)
(b)
(c)
where D ⊂ RM is a bounded domain, u : [0, T] × D → RN is the solution, Fλ is a nonlinear
operator containing differential operators, Bλ is a operator representing the boundary condition,
u0,λ : D → RN represents the initial condition, and λ is a parameter of the equations.
•	Task τ : The task τ is to solve a differential equation by PINN:
-	Dataset DT: The dataset DT is the set of points (t, x) ∈ [0, T] × D and the values
of U at the points if applicable. In detail, DT = Df,T ∪ Db,T ∪ Du0,T ∪ Du,T, where
Df,T, Db,T, and Du0,T are sets of points corresponding to the equation (a), (b), and (c)
respectively. Du,T is the set of points (t, x) and observed values U(t, x) at the points.
In addition, each dataset D” is divided into training set Dtram and validation set Dv,ajJ.
-	Solution parameter space UT: The solution parameter space UT is the weights space
of PINN.
-	Loss function LT : The loss function LT : U → R≥0 is based on the evaluations at the
points in DTval. In detail,
LT(U) = LTaI(U) = LfaT (U) + LvaT (U) + Lual,τ(U),
where
wf
|Df,T |
E ' (Fλ[U](t,χ), 0)
(t,x)∈Df,τ
val
Lb,T
wb
|Db,T|
E	' (Bλ[U](t,χ), 0)
(t,x)∈Db,τ
,T
wu0
|Du0 ,T |
E	' (U(0,x),U0,λ(x)),
(t,x)∈Du0,τ
and` : RN × RN → R≥0 is a function. In the paper, the mean squared error is used
as`.
•	Task space (T, P): The task distribution (T, P) is determined by the distribution of λ.
•	Solver Φ: The solver Φ : T × Θ → UT is the gradient decent for training the PINN.
The parameter θ ∈ Θ controls the objective of the gradient decent, LTam(U; θ) =
L鬻(U; θ) + Ltr,aTn(U; θ) + Luainr(U; θ) + Luain(U; θ), where the difference from Lva is
that parametrized loss `θ is used in LtTrain instead of the MSE in LvTal. Note that the loss
weights wf, wb, wu0 , wu in LtTrain are also considered as part of the parameter θ. In the
paper, two designs of`θ are studied. One is using a neural network, and the other is using a
learned adaptive loss function. In the former design, θ is the weights of the neural network,
and in the latter design, θ is the parameter in the adaptive loss function.
•	Meta-solver Ψ: The meta-solver Ψ : TX Ω → Θ is the constant function that returns its
parameter ω, so Ψ(τ; ω) = ω = θ and Ω = Θ. Note that θ does not depend on T in this
example.
Then, the parameter ω = θ is optimized by a gradient decent algorithm as described in Algorithm 1.
14
Under review as a conference paper at ICLR 2022
B Proof of Theorem 1
Proof of Theorem 1. Equation (3) can be represented as follows:
min E uτ -φτk(Wfτ)2 =min E	Mk(uτ-Wfτ)2	(7)
=min E	Mk(A-1fτ -Wfτ)2.	(8)
W fτ 〜Pf
Since the mean of fτ is 0 and the covariance is the identity matrix, W is the minimizer of (8) if and
only if W is the minimizer of the following:
min Mk(A-1 - W)2F .	(9)
Let λi and Vi (i = 1, 2,...,N) be eigenvalues and eigenvectors of M. Note that λ% = cos Ni+pι and
1 >λι >λ2 > …> λN > -1. Since A = 2I - 2M, eigenvalues and eigenvectors of A are
2 - 2λi and vi . By the eigenvalue decomposition, M and A can be written as
M = VΛVT	(10)
A=V(2I-2Λ)VT,	(11)
where Λ = diag(λi) and V = (v1, v2, . . . , vN ). By the decompositions,
Mk(A-1 - W)2F = VΛkVT(V(2I-2Λ)-1VT - W)2F	(12)
= VΛk(2I-2Λ)-1VT - VΛkVTW)2F	(13)
Thus, the minimizer Wk is
r
Wk = X(2 - 2λi(j,k) )-1vi(j,k)viT(j,k) ,	(14)
j=1
λk
where r = rank(Wk) < N, and i(j,k) is the index i where |2—iy | takes the top jth value in
i ∈ {1, 2, . . . , N}. Then, the following lemma holds.
Lemma 2. If k1 < k2, then for all k ≥ k2
Mk(A-1-Wk1)2F ≥ Mk(A-1-Wk2)2F,	(15)
where the equality holds if and only if Wk1 = Wk2.
Since (8) and (9) are equivalent, if Lemma 2 holds, then Theorem 1 holds.
Proof of Lemma 2. Let
Ik :={1,2,...,N}\{i(j,k) :j = 1,2,...,r}.	(16)
Ik is the set of N - r indices corresponding to the least N - r values of | Ji、. |. We have
2-2λ
Mk(A-1-Wk1)2F - Mk(A-1-Wk2)2F
X (2⅛)2 -X (2⅛Y
∈ i1	∈ i2
X	( λ )2 - X	( λ	)2
乙	∖2 - 2λi	乙	∖2 - 2λi .
i∈Ii1 \Ii2	i∈Ii2 \Ii1
(17)
(18)
(19)
15
Under review as a conference paper at ICLR 2022
If Wk1 = Wk2, then (19) equals 0. Assume Wk1 6= Wk2, so Ik1 6= Ik2. Note that Ik =
{minIk, min Ik + 1, . . . , min Ik + (N - r) - 1 = maxIk}, and for any i ∈ Ik, we have
∣λi| ≤ ∣λmaχik |. In addition, for kι < k2, We have maxI^ ≥ maxk.Let
λik
ikι := arg min | -一— |	(20)
i∈Ik1 \Ik2 2 - 2λi
λik
ik2 ：= arg max | 石一1	(21)
i∈Ik2 \Ik1 2 - 2λi
C:= |Ik1 \Ik2| = |Ik2 \Ik1|.	(22)
Then, We have
>0.
(19) ≥C
k2+(k-k2)	2
λik2
=C
(23)
(24)
(25)
The last inequality (25) is because for any i ∈ Ik2,
and
lλikι | > lλmax Ik2 | ≥ |%|.
This completes the proof of Lemma 2.
(26)
(27)
□
Lemma 2 holds. Thus, Theorem 1 holds.
□
C Details of task distributions
C.1 Distributions of 1D Poisson equation
In Ps, u is represented by	20 u(x) =	ai sin(biπ(x - ci)),	(28) i=1
Where	ai 〜N(0,1)	(29) bi 〜Unif(0,128)	(30) ci 〜 Unif(0, 1).	(31)
In Ph, u is represented by	20 u(x) =	ai tanh(biπ(x - ci)),	(32) i=1
Where	ai 〜 N(0, 10)	(33) bi 〜 Unif(0, 30)	(34) ci 〜 Unif(0, 1).	(35)
16
Under review as a conference paper at ICLR 2022
C.2 Distribution of inflow
In Pin, vin = (v1, v2)T is represented by
		v1(y, t) = w(y, t) cos z(t)	(36)
		v2(y, t) = w(y, t) sinz(t),	(37)
where			
	w(y, t)	0.5 + 0.5 sin(ay - bt)π sin yπ sin tπ	(38)
	z(t)	e sin(ct - d)π	(39)
and			
		a 〜Unif(0,10)	(40)
		b 〜Unif(-5, 5)	(41)
		C 〜Unif(0, 5)	(42)
		d 〜Unif(0, 2)	(43)
		e 〜Unif(0, ∏).	(44)
D Details of network architecture and hyper-parameters
D.1 Details of section 3.1.2
In section 3.1.2, ΨNN is a variant of 1D U-Net with a residual connection to leverage the heuristic
initial guess uh = ΨBL(τ), so ΨNN(τ) = ΨNN(fτ, uh) = uh + 1DUNet(fτ, uh), where 1DUNet
consists of four stages with halved resolutions. Each stage has two convolutional layers with kernel
size 11 and the activation function tanh. In the first stage, the number of channels is 8, and it is
doubled as the resolution is halved. By utilizing the linearity of the Poisson equation, inputs are
normalized by ∣∣fτ k before feeding them into Ψnn, and the final output U is denormalized by IIfτ k.
The model is trained for 2000 epochs by Adam with the learning rate 0.0005 and the batch-size
512. The learning rate is decreased by 1/5 times when the validation loss does not improve for 200
epochs, and the training is terminated when the validation loss does not improve for 250 epochs.
The model with the best validation loss is used for evaluation.
D.2 Details of section 3.2
In section 3.2, ΨNN is a variant of 2D U-Net. The differences from ΨNN in section 3.1.2 are its
dimension, kernel size 5, and the starting number of channels 16. The model is trained for 50 epochs
by Adam with the learning rate 0.0005 and the batch-size 64, and the learning rate is decreased by
1/5 at 30 epoch. Note that the meta-solver is trained for 10 time steps for each mini batch by the
data augmentation. The model with the best validation loss is used for evaluation.
E	Details of experiment results
17
Under review as a conference paper at ICLR 2022
Table 3: Standard deviation of MSE of GBMS for solving Poisson equations.
(a) Standard deviation of MSE on Ps
Ψ	Trained With	Tested With			Φjac,64	ΦSOR,4	ΦSOR,16	ΦSOR,64
		Φjac,0	Φjac,4	Φ Jac, 16				
ΨNN	Φjac,0 = ΦsOR,0	0.0052	0.0052	0.0052	0.0050	0.0051	0.0049	0.0043
	Φjac,4	0.0097	0.0101	0.0098	0.0093	0.0098	0.0091	0.0074
	Φjac,16	0.5548	0.0038	0.0036	0.0033	0.0095	0.0024	0.0020
	Φjac,64	4.8458	0.7034	0.0167	0.0037	0.0381	0.0040	0.0029
	ΦsOR,4	0.1211	0.1005	0.0739	0.0734	0.0085	0.0080	0.0067
	Φsor,16	10.4207	1.9210	0.2923	0.2396	0.0917	0.0072	0.0056
	ΦsOR,64	4.8430	0.9012	0.3301	0.2788	0.1937	0.0095	0.0078
(b) Standard deviation of MSE on Ph
Ψ	Trained with	Tested with			Φjac,64	ΦSOR,4	ΦSOR,16	ΦSOR,64
		Φjac,0	Φjac,4	Φjac,16				
ΨNN	Φjac,0 = ΦsOR,0	0.0194	0.0192	0.0189	0.0184	0.0187	0.0181	0.0186
	Φjac,4	0.0273	0.0261	0.0258	0.0251	0.0257	0.0248	0.0223
	Φjac,16	0.0588	0.0212	0.0195	0.0208	0.0198	0.0213	0.0240
	Φjac,64	0.2278	0.1431	0.0513	0.0279	0.0369	0.0281	0.0288
	ΦsOR,4	0.6228	0.6871	0.7175	0.7154	0.0286	0.0308	0.0324
	Φsor,16	0.3757	0.3590	0.6168	0.7796	0.0309	0.0218	0.0224
	ΦsOR,64	1.2871	0.9696	0.4896	0.0872	0.3847	0.0492	0.0309
18