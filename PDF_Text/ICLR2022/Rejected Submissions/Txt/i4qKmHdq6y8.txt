Under review as a conference paper at ICLR 2022
Learning to Abstain in the Presence of Unin-
formative Data
Anonymous authors
Paper under double-blind review
Ab stract
Learning and decision making in domains with naturally high noise-to-signal ratios
-such as Finance or Public Health - can be challenging and yet extremely impor-
tant. In this paper, we study a problem of learning on datasets in which a significant
proportion of samples does not contain useful information. To analyze this setting,
we introduce a noisy generative process with a clear distinction between uninfor-
mative/not learnable/purely random data and a structured/informative component.
This dichotomy is present both during the training and in the inference phase. We
propose a novel approach to learn under these conditions via a loss inspired by
the selective learning theory. By minimizing the loss, our method is guaranteed
to make a near-optimal decision by simultaneously distinguishing structured data
from the non-learnable and making predictions, even in a highly imbalanced setting.
We build upon the strength of our theoretical guarantees by describing an iterative
algorithm, which jointly optimizes both a predictor and a selector, and evaluate its
empirical performance under a variety of conditions.
1	Introduction
Despite the success of machine learning in computer vision (Deng et al., 2009; Krizhevsky et al.,
2009; He et al., 2016a; Huang et al., 2017) and natural language processing (Vaswani et al., 2017;
Devlin et al., 2018), the power of ML is yet to make significant impact in other areas. One major
challenge is the inherently high noise-to-signal ratio in certain domains. For example, in Finance,
while stock prices generally reflect the information about financial health of their companies, over the
short term, their fluctuations most closely resemble random walks - which are naturally unpredictable
- and are usually modeled as such (Tsay, 2005). In biomedical research, the underlying phenomena
are often highly complex and are affected by unobservable factors. The outcome may appear highly
random to the measurements (gene expression, medical histories), if the true causing factor is not
included or is overwhelmed by others.
We are interested in dealing with datasets that may contain large fraction of noisy/uninformative/not
learnable data in both training and testing stages. Direct application of standard supervised learning
methods to such datasets is both challenging and unwarranted. At the training stage, the uninformative
data can significantly bias the model or even completely overwhelm the true signal (Nettleton et al.,
2010). Therefore, naive forecasts in majority-uninformative datasets are doomed to be unreliable.
Compared to other learning methods, deep neural networks are even more affected by the presence of
noise, due to their strong memorization power (Zhang et al., 2017): they are likely to overfit the noise
and make overly confident predictions where no real structure exists.
In this paper, we propose a novel method for learning on datasets where a significant portion of
content is pure noise. Instead of forcing the classifier to make predictions for every sample, we learn
to decide whether a datapoint is informative or not. If successful, the method abstains from making
decisions where no structure exists, and predominantly learns from the remaining predictable data.
Our idea is inspired by the classic selective prediction problem (Chow, 1957), in which one learns
to select a subset of data and only predict on that subset. However, the goal of selective prediction
is very different from ours. A selective prediction method considers all data relevant. It pursues
a balance between coverage (i.e. proportion of the data selected) and conditional accuracy on the
selected data. In our problem, we assume that uninformative data is an integral part of the data
generative process. No learning method, no matter how powerful, can be successful on such data.
Our goal is to identify these uninformative samples as well as possible, and at the same time, to train
a classifier by minimizing conditional risk on the remaining informative data.
1
Under review as a conference paper at ICLR 2022
Our method learns both a predictor, f , that classifies samples, and a selector, g, that selects learnable
data for the predictor and rejects/abstains from the uninformative data. We are using g to approximate
the ground truth indicator function of StrUctUred/informative data, g*. We assume that g* exists as
a part of the data generation process, but it is never revealed to us, even during training. Instead of
direct supervision, we therefore must rely on the predictor’s mistakes to train the selector. To achieve
this goal, we propose a novel selector loss enforcing that (1) the selected data best fits the predictor,
and (2) the portion of the data where we abstain from forecasting, does not contain many correct
predictions. This loss function is quite different from the loss in classic selective prediction, which
penalizes all unselected data equally.
A major contribution of this paper is the derivation of theoretical guarantees for the empirical
minimizer of our loss. We analyze the proposed selector loss function and provide sample complexity
for learning a nearly optimal selector. We show that optimizing such loss can recover nearly all the
structured/informative data in a PAC fashion (Valiant, 1984; Kearns et al., 1994; Valiant, 2013), i.e.
one can approximate the ground truth selector function g* well with high probability, given sufficient
samples. What may be surprising is that this guarantee holds even in a challenging setting where the
uninformative data represents the majority of the training set.
This theoretical guarantee lets us expand to a more challenging and realistic setting. When the sample
size is limited and the initially learned predictor is not sufficiently close to the ground truth, we extend
our method to an iterative algorithm, in which we progressively optimize both the predictor and the
selector. The selector is improved by optimizing our novel selector loss. Meanwhile, the predictor is
improved by optimizing the empirical risk, reweighted based on the selector’s output; uninformative
or nearly-uninformative samples identified by the selector will be down-weighed. Experiments on
real-world datasets demonstrate superiority of our method to existing baselines. Note that in this
paper, we assume that each sample is either informative or not. Extending our method to a more
general setting with continuous transitions between informative and uninformative is non-trivial and
is left as future work.
1.1	Related Work
Learning with untrusted data aims to recover the ground truth model from a partially corrupted
dataset. Different noise models for untrusted data have been studied, including random label noise
(Bylander, 1994; Natarajan et al., 2013; Han et al., 2018; Yu et al., 2019; Zheng et al., 2020; Zhang
et al., 2020), bounded label noise (Massart & Nedelec, 2006; Awasthi et al., 2015; Diakonikolas
et al., 2019; 2020) and adversarial noise (Kearns & Li, 1993; Kearns et al., 1994; Kalai et al., 2008;
Klivans et al., 2009; Awasthi et al., 2017). In the most pessimistic setting, if the majority data is
corrupted by arbitrary adversarial noise, even mean estimation may be impossible. This is known
as List-Decodable problem (Balcan et al., 2008; Charikar et al., 2017; Diakonikolas et al., 2018),
where the best one can do when the proportion of trusted data α is less than 0.5, is to return 1 many
hypotheses of the mean, knowing one of them is promising. We, on the other hand, aim to produce a
single accurate model even in a setting where the majority of the data is uninformative (the noise, of
course, must be of a certain type, see next section). While above works assume the presence of noisy
data only in the training stage, we study the case where noise is an integral part of the generative
process and thus will appear during inference as well, where it must be detected and discarded once
more.
Selective learning is an active research area. It extends the classic selective prediction problem
and studies how to select a subset of data for different learning tasks. We can summarize existing
methods into 4 categories: Monte Carlo sampling based methods (Gal & Ghahramani, 2016; Kendall
& Gal, 2017; Pearce et al., 2020), margin based methods (Fumera & Roli, 2002; Bartlett & Wegkamp,
2008; Grandvalet et al., 2008; Wegkamp et al., 2011; Zhang et al., 2018), confidence based methods
(Wiener & El-Yaniv, 2011; Geifman & El-Yaniv, 2017; Jiang et al., 2018) and customized selective
loss (Cortes et al., 2016; Geifman & El-Yaniv, 2019; Liu et al., 2019). Notably, several works propose
customized losses, and incorporate them into neural networks. In (Geifman & El-Yaniv, 2019), the
network maintains an extra output neuron to indicate rejection of datapoints. Liu et al. (2019) use
Gambler loss where a cost term is associated with each output neuron and a doubling-rate-like loss
function is used to balance rejections and predictions. Cortes et al. (2016) perform data selection with
an extra model and introduce a selective loss that helps maximize the coverage ratio, thus trading off
a small fraction of data for a better precision.
2
Under review as a conference paper at ICLR 2022
Existing works on selective prediction are all motivated from the coverage perspective - i.e. one wants
to make safe prediction to achieve higher precision while maintain a reasonable recall (El-Yaniv et al.,
2010). Whereas our paper is the first to investigate the case where some (or even majority) of the data
is uninformative, and thus must be discarded at prediction time. Unlike with the selective prediction,
there is a latent ground truth indicator function of whether a datapoint should be selected or not. Our
method is guaranteed to identify those uninformative samples.
2	Problem Formulation
In this section, we describe the inherently-noisy data generation process that we aim to study. The
model has three important features: 1) the uninformative portion of the data has labels generated by
coin flipping; 2) the informative datapoints are labeled with a latent ground truth function; and 3) the
uninformative data has a distinguishable support from the informative data. Formally:
Definition 1 (Noisy Generative Process).
notation X 〜Da where
We define Noisy Generative Process by the following
Dα
ʃ x 〜DU with prob. 1 - α (Uninformative/Noisy Data)
Ix 〜DI with prob. α (Informative/StructuredData).
(1)
Let Ωd ⊆ Rd be the support of Da. Suppose {Ωu, ΩI} is a partition of Ωd, the ground truth
Iabelingfunction f * : X → {+1, —1} is in hypothesis class F and data is sampled according to:
B f Bernoulli(0.5), if X ∈ Ωu
x~Da; y ≡ If *(x),	if X ∈ ΩI.
(2)
Note that the f * is defined on the whole domain, although only the part within ΩI is relevant. α
represents the fraction of informative or structured data in the population. For the rest of the paper,
we abuse the notation and use (x, y)〜Da to refer to samples generated from this process.
Next definition describes a separability condition between informative and uninformative data. It
allows to distinguish noise from structure and enables us to approximate the ground truth selector via
empirical minimization.
Definition 2 (H-Separable). Given compact set Ω and its partition {Ωu, ΩI}, {Ωu, ΩI} satisfies
H-Separable condition if there exists g* ∈ H satisfying g* (X) : X → {+1, -1}:
*(x)≡ ∫-1, if X ∈ ωu
g ( ) ≡ [1, if x ∈ ΩI.
(3)
One can view g*(∙) in definition 2 as the target selector we wish to recover. Having introduced the
data generation process and the separability condition, we now describe our main assumption for the
remainder of the paper.
Assumption 1. Data Sn = {Xi, yi}iN=1 is i.i.d generated according to the Noisy Generative Process
(Definition 1), with f * ∈ F, SuPPOrt Ωgα = Ωu∪ΩI where Ωu, ΩI are H-Separable.
Throughout this paper, we are interested in the following learning task:
Problem 1 (Abstain from Uninformative Data). Under Assumption 1 with enough i.i.d observations
from Da: 1) given hypothesis class F, we aim to learn the underlying ground truth classifier f* (X);
and 2) given the hypothesis class H, we aim to learn the selector g* (X).
Evaluation metrics. We define metrics to evaluate the quality of both the prediction and the selection.
For the prediction, we borrow the selective risk definition from selective learning (El-Yaniv et al.,
2010; Geifman & El-Yaniv, 2019; 2017) using our own notation.
Definition 3 (Selective Risk). Given a predictor f ∈ F and a selector g ∈ H, we define the
selective risk as: CR(f,g~) = E(χ,y)〜Da[1 {f(x) = y}∣g(x) ≥ 0] and its empirical version:
CRS(f,g)
En=I ι{f(χi)=yi}ι{g(χi)≥0}
Pn=ι ι{g(χi)≥0}
Selective risk measures the average risk conditioned on instances that are picked by the selector g(X).
Note here when combined with the ground truth selector g * , the selective risk of the ground truth
3
Under review as a conference paper at ICLR 2022
predictor f * goes to zero. Without a selector, however,
f * has classical classification risk (which will
1
be formally defined in Definition 5 later) of more than 2 (1 一 a).
The metric used to evaluate the quality of a learned selector g is its false positive/negative rate. When
g(x) ≥ 0 and g* (x) < 0, the selector g accepts an uninformative datapoint and thus commits a false
positive error. When g(x) < 0 and g* (x) ≥ 0, g rejects/abstains from an informative datapoint
resulting in a false negative error.
Definition 4 (Evaluation Metric for the Selector). Given distribution Dα as defined in Defnition 1
and g* as target selector, we denote the false positive and false negative of a selector g as
False Positive: P[g(x) ≥ 0|g* (x) < 0]; False Negative: P[g(x) < 0|g*(x) ≥ 0]	(4)
3	Our Method
In this section, we present our approach for learning and abstaining in the presence of uninformative
data (Problem 1). The main challenge is that the latent informative/uninformative status ofa datapoint
is unknown. Our main idea is to introduce a novel selector loss function that trains a selector based
on the performance of the best predictor (Section 3.1). In Section 3.2, we present our main theoretical
result. We show that by jointly finding a predictor minimizing the classification risk and finding a
selector minimizing the proposed selector loss, we can solve Problem 1 with controlled selective
risk and selector error rates. During the analysis, we assume an oracle is given for the empirical
minimizer. Approximating such empirical minimizer is a different topic beyond the scope of this
paper (Bartlett et al., 2006; Yuan & Wegkamp, 2010). Inspired by the theoretical results, in Section
3.3, we propose a heuristic algorithm that iteratively optimizes the predictor and the selector.
Throughout the analysis, we focus on the 0-1 classification loss to optimize the predictor. This follows
the standard for analyzing generalization performance and sample complexity. Formally:
Definition 5 (Classification Risk). We denote the classification risk of a model f as
R(f) ≡ E(x,y)〜Dα[l{f(x) = y}]	(5)
and the empirical classification risk: RSn(f) = 1 En=I l{f (xi) = yi}. We define fSn to be the
empirical minimizer of RSn (f): fS* = arg minf ∈F RSn (f).
3.1	Selector Loss
To learn a selector without direct supervision, we have to leverage the performance of a given
predictor, f. We propose the selector loss, which reweigh the 0-1 loss based on the prediction of f.
This loss penalizes when (1) the predictor makes a correct prediction on a datapoint that the selector
considers uninformative and abstains from, or (2) the predictor makes an incorrect prediction on a
datapoint that the selector considers informative.
Definition 6 (Selector Loss). Given f ∈ F and its selector g ∈ H, we define the following weighted
0 — 1 type risk w.r.t g(∙) as selector risk:
—	—	「0 一 . ......................1	— θ ….....................1
W(g; f,θ) ≡	E(χ,y)〜Da	-l{f (x)	=	y}l{g(χ)	> 0} + τ------l{f (x) = y}l{g(χ)	≤	0}.
α	1 — α
and its empirical version:
一	一 1 ʌ θ 一 ................................1	— θ ........................
WSn(g； f,θ) = — £ —i{f(Xi) = yi}i{g(Xi) > 0} + ；----------i{f(Xi) = yi}i{g(Xi) ≤ 0} (6)
n z—α α	1 — α
i=1
Intuitively speaking, the loss will drive the selector to partition the domain into informative and
uninformative regions. Within the informative region, the predictor is supposed to fit the data well,
and should be more accurate. Meanwhile, within the uninformative region, the label is random and
the predictor is supposed to be more prone to error. Another view of the loss is that we are learning to
fit the selector g(x) to a pseudo-informative label given by the predictor, l{f (x) = y}. Since such
label is f -dependent, the quality of f is crucial for successfully learning g. In the theoretical analysis,
we leverage the fact that predictor f is close enough to the ground truth predictor f*.
4
Under review as a conference paper at ICLR 2022
Note that there are two types of errors penalized in the selector loss: an incorrect prediction on
an informative datapoint, (f (x) 6= y) ∧ (g(x) > 0), and a correct prediction on an uninformative
datapoint, (f(χ) = y) ∧ (g(χ) ≤ 0). We use βι = αθ and βu = 1--θ to weigh these two types of
error in the loss. Both βI and βU are controlled by a parameter θ and the latent informative data
proportion α. We show that for a wide range of θ, the accuracy of the selector is guaranteed, as long
as α is bounded away from 1, i.e., when abstention is necessary. In practice, we can adjust βI and
βU freely without knowing exact value of α, as empirical performance remains stable with regard to
these choices.
Learning a selector with the novel loss. In an ideal setting, to learn a selector, we first estimate
the predictor by minimizing the classification risk, fS 九 =arg min f ∈f RSn (f). Next, we esti-
mate the selector by minimizing the selector loss, conditioned on the estimated predictor, fSn,
gSn = argming∈H WSn (g, fS九,θ). In Figure 1, We show an example of using the empirical mini-
mization strategy with logistic regression and with 0-1 loss replaced by cross-entropy loss. In this
case, the losses are all convex and the empirical minimizers fSn and gS九 can be computed exactly.
Our analysis in Section 3.2 will show that the estimated PrediCtor fS九 and selector gSSn has bounded
selective risk (as in Definition 3), as well as bounded false positive and false negative selector errors
(as in Definition 4).
In practice, however, empirical minimization is not always possible, as optimization for complex
models (e.g., DNNs) and non-convex losses remains open. We therefore propose a heuristic algorithm
in the spirit of our theoretical results - it jointly learns f and g by minimizing the selector loss and a
reweighed classification risk iteratively (see Section 3.3).
(a) Mix of learnable
and not learnable data
(b) Output of fS (x)
(Logistic Regression)
(c) Correct/Incorrect
classification
(d) Output of
selector g∣n (x)
(e) Selective
classification result
Figure 1: Illustration of the learning strategy in an ideal setting, using synthetic (uniformly distributed
noise) data. We replace the 0-1 loss with cross-entropy loss and train logistic regression models
for both f and g. (a) shows that the informative and the uninformative supports are separated. (b)
demonstrates that the model derived with majority-uninformative data has reasonable performance on
the informative portion. (c) shows that the predictor has high accuracy in the informative region, but
low accuracy in the uninformative region. In (d) and (e), the selector trained with fS九 successfully
recovers informative support thus resulting in low selective risk.
3.2	Theoretical Analysis
In this section we report our theoretical results. The main result can be summarized in the following
(informal) statement.
Main Result (Informal) With sufficient data, the estimated predictor fS九=arg min,∈f RSn (f)
and selector gS九=arg ming∈H WSn (g, fS九,θ) are sufficiently close to the targets f * and g* with
high probability.
The proof requires the classic growth function definition (Vapnik & Chervonenkis, 2015).
Definition 7 (Growth Function). Let H be the hypothesis class of function f and Fx1 ,...,xn =
{f (x1), ..., f(xn) : f ∈ F} ⊆ {+1, -1}n. The growth function is defined to be the maximum num-
ber of ways in which n points can be classified by the function class: GF (n) = supx1,...,xn |Fx1,...,xn |.
Roadmap of the proof: Theorem 1 is a standard PAC Learning analysis where we show fS* is
sufficiently close to the ground truth function f*. Note that our analysis does not imply efficient PAC
learning since optimizing binary loss is NP-hard. In Theorem 2, we bound the statistical error of the
selector loss. In Theorem 3, we leverage the fact that informative and uninformative portions of the
data are distinguishable, as well as the fact that fS* has low risk on informative data. This lets us
bound the selector loss of gS* given by W (gS* , fS* , θ). By carefully balancing the weight parameter
5
Under review as a conference paper at ICLR 2022
θ of selector loss, we derive the false positive and false negative guarantees in Theorem 3. Theorem 4
is a formal version of the main result, which applies Sauer’s Lemma (Sauer, 1972) to bound the
growth function of hypothesis classes in Theorem 3. The toolkit we use is driven by the concept of a
VC-dimension in (Vapnik & Chervonenkis, 2015; Blum et al., 2016; Mohri et al., 2018). We also
provide a lower bound construction in the Appendix to show the (near) tightness of our analysis (up
to a logarithmic factor). We present all the results below, detailed proofs are in the Appendix.
We first prove a theorem about sample complexity of the learning hypothesis optimized over a given
dataset, referred to as fS九.We show that it approximates the ground truth function f * well.
Theorem 1.	Under Assumption 1, given hypothesis class F, a set of samples Sn =
{(x1 , y1), ..., (xn, yn)} drawn i.i.d from our Noisy Generative Process and fS*	=
arg min f ∈f RS (f), suppose n ≥ 32[log(4|G[2a2X)+log(Q], 比en With probability at least 1 一 2δ,
R(fSn) ≤ 1 (1 一 α) + 2eα. Furthermore, Px〜Di [f *(x) = fS*n(x)] ≤ 2e.
Next theorem states the sample requirements in order to achieve a small gap between the empirical
selector loss and the true selector loss. The proof takes a union bound over all possible pairs of
hypothesis (g, f) ∈ H × F, which explains the term |GH (2n)||GF (2n)| in the bound for n, the
minimum number of sample points.
Theorem 2.	Given hypothesis class H, F, a set of samples Sn = {(x1, y1), ..., (xn , yn)} drawn i.i.d.
from the Noisy Generative Process and fS* = arg minf ∈F RS(f), gSn* = arg min WSn (g, fS* , θ),
n	g∈H	n
if θ ∈ (α, 1), ɑ ∈ (0,1) and n ≥ '32 [log(4|GH(2；2]：F(2nX)+log(Q], With probability at least 1 一 δ,
|W (gSn ,fSn ,θ) - WSn Un ,fSn/)1 ≤ ^.
Theorem 3 combines the results in Theorems 1 and 2. It shows that, by carefully choosing weight
parameter θ, minimizing the selector loss with sufficiently large amount of data ensures a low false
positive/negative rate of the selector with high probability. In particular, the analysis points to a trade
off between false positive and negative rates faced by the selector in terms of θ. We characterize the
relationship between θ and a using variable C = ɪ in the theorem and prove that for a wide range of
c the false negative rate (FNR) and false positive rate (FPR) are controlled. Intuitively, a larger value
of θ in WSn (g, fS* , θ) implies a higher penalty on the false positive error.
Theorem 3.	Under Assumption 1, given a set of samples Sn = {(x1, y1), ..., (xn , yn)} draWn i.i.d.
from the Noisy Generative Process and fS* = arg minf ∈F RS(f), gSn* = arg min WSn(g, fS* , θ),
n	g∈H	n
if θ ∈ (α, 1), α ∈ (0,1) and n ≥ 32,2[10，(4©丸(2；2!?F(2n)|)+log(5)], f。= 2<4 with 1 < c < 1+α,
We have With probability at least 1 一 δ:
12cα
P[gsn (x) ≥ 0|g (x) ≤ 0] ≤ 2c- 1	[False Positive]
P[gS* (x) < 0|g*(x) ≥ 0] ≤ 20c	[False Negative]
(7)
Next theorem is a formal statement of the main result. It is worth mentioning that the theorem
assumes that α is bounded away from 1, due to the fact that when almost all data is informative, there
is no need for abstention.
Theorem 4.	Under Assumption 1, given set of samples Sn = {(x1, y1), ..., (xn , yn )} draWn i.i.d.
from the Noisy Generative Process, hypothesis class H With VC-dimension dvc(H), F With VC-
dimension dvc(F) and fSn = argminf∈f RS(f ),gSn* = arg min WSn (g,fSn, 732α + ⅛) , f
g∈H
a ∈ (0, 0.9) and n ≥ 1到®Vc(H)+dvc[F)Jog(ε )+log( δ )]. We have with probability at least 1 一 δ:
I)
P[gS* (x) ≥ 0|g*(x) ≤ 0] = O() [False Positive]
P[gS* (x) < 0|g*(x) ≥ 0] ≤ O() [False Negative]
II)
Px〜Dα[f *(x) = fSn (X)IgSn (x) ≥ 3=O(E)
6
Under review as a conference paper at ICLR 2022
Remark 1. We provide a lower bound construction in the appendix to show that our bound in
Theorem 4 is tight up to a logarithmic factor. Note that our lower bound is for empirical minimizers
of R(f) and W(g, f, θ), therefore the tightness result is not an information theoretic bound for this
family of problems. It remains an open question about whether or not strategies other than the
empirical minimization, as in (Hanneke, 2016; Simon, 2015; El-Yaniv et al., 2010), can improve the
sample complexity to a rate of O (*).Note that the informative portion of the data (drawn with
probability a) by itself only requires O( ɪ) samples for an E-excessive statistical error. It turns out
that our analysisfor empirical minimizer is nearly tight, and that the number ofsamples O (α⅛) is
indeed necessary because the presence of noisy data makes our problem harder.
Remark 2. Theorem 4 says that by minimizing the empirical version of the loss from Definitions 5
and 6, one can achieve the goal of simultaneously selecting and learning with noisy data - i.e. the
classification model fS has sufficiently low SeIeCtive risk, and the selector gS can distinguish
informative data from non-informative. The analysis of the selector loss (Theorem 3) relies on the
quality ofthe classifier fS九.But since we know that gSn is able to abstainfrom uninformative data,
we can retrain fS on the informative portion only, therefore guaranteeing its accuracy. Such circular
logic naturally leads to a practical iterative algorithm that we present in the next section.
3.3 A Heuristic Algorithm in Practice
In Section 3.2, we analyzed an empirical minimizer of a conceptual 0-1 loss for the classifier f and
the selector g. Binary loss, however, is impractical from the computational standpoint. In practice,
we use cross-entropy loss instead and require that both f and g have continuous-valued output,
ranging between 0 and 1. We also relax the requirement for empirical minimization oracles, allowing
the practical algorithm to jointly optimize the predictor and the selector in an iterative manner. At
each iteration, we update the predictor using the informative data selected by the selector, and then
update the selector based on the predictor’s output. See Algorithm 1 for the pseudo-code. A pictorial
example of Algorithm 1’s performance can be found in Figure 2 in the Appendix.
During the joint optimization process, the predictor is counting on the selector to show it only the
informative data. However, the initial selector is not trustworthy. To update the predictor f, we
turn to a so-called soft abstention scheme: use a weight vector γ that progressively down-weighs
samples abstained by g, in the spirit of multiplicative weights algorithms (Cesa-Bianchi & Lugosi,
2006; Arora et al., 2012). Specifically, we increase the weight of i-th sample γi if the selector accepts
Xi: Yi = γi(1 + η ∙ l{g(χi) > 0.5}) and then normalize so that Pn=1 Yi = 1. We call this a soft
abstention approach because the algorithm decreases the weight of uninformative data gradually.
In the heuristic algorithm, we use cross-entropy loss to fit the selector to pseudo-informative labels
output by the predictor. We also use a single hyper-parameter β = βι/βu = :(二)to control the
ratio of the two types of errors. As suggested by Theorem 3, small selector FPR and small selector
FNR can be achieved by a β ∈(1,1 + 1). For a scenario when abstention is necessary, i.e. when
the noisy data ratio is in a reasonable range, we can choose our hyper-parameter from a wide interval.
Algorithm 1 Iterative Soft Abstain
Require: Data set Sn = {(χι,yι),..., (χn, yn))}, weight Parameter:/, random initial f0 and g0,
initial sample weights γ0 = ɪ, ∀i ∈ [n], meta learning rate η, number of iterations T
1:	for t — 1,…，T do
2:
3:
4:
5:
6:
Optimize loss to update predictor ft: in=1 Yit {yi log(f(xi)) + (1 - yi) log(1 - f (xi))}
Approximate the ‘pseudo-informative label’ : Zt = l{l{ft(xi) > 0.5} = yi}
Optimize loss to update selector gt: Pin=1 {zit log(g(xi)) + β(1 - zit) log(1 - g(xi))}
Update sample weights using gt : Yit+1
end for
γt(1+ηl {gt(xi)>0.5})
Pn=I γj(i+η1 年区)>o.5}).
7: Output fT , gT
4	Experiments
Datasets. We test the efficacy of our heuristic algorithm (Algorithm 1), via semi-synthetic experi-
ments. We synthesize the noisy data by mixing datasets from two different domains and uniformly
shuffling all labels in one of them. Our first synthetic noisy dataset is composed of MNIST (LeCun
7
Under review as a conference paper at ICLR 2022
et al., 1998) and Fashion-MNIST (Xiao et al., 2017). We uniformly shuffle the labels of MNIST
images and keep original labels of Fashion-MNIST. As a result, images from MNIST are uninforma-
tive while images from Fashion-MNIST are considered informative. The fact that one dataset has
hand-written digits and the other one contains pictures of clothes ensures distinct supports. We mix
these two datasets in different proportions to proxy for our Noisy Generative Process.
We also perform experiments on another synthetic dataset, where noisy and informative portions
come from similar domains. To achieve this, we use SVHN (Netzer et al., 2011). We uniformly at
random flip labels of classes 5-9 into classes 0-4 and mix them with intact data from classes 0-4. In
this case, we consider the data from classes 5-9 uninformative. In this mixed dataset, informative
and uninformative data have similar domains, which makes it more challenging to correctly identify
informative data (and harder to argue separate support).
Baselines. We compare our method to two of the most recently proposed selective learning algorithms.
(1) SelectiveNet (Geifman & El-Yaniv, 2019), which integrates an extra neuron as a data selector in
the output layer and also introduces a loss term to control the coverage ratio; (2) DeepGambler (Liu
et al., 2019), which also maintains an extra neuron for abstention and uses a doubling-rate-like loss
term (i.e., gambler loss) to train the model. (3) We also create a third baseline that selects data using
model prediction confidence, which we refer to as Confidence. The hypothesis is that informative
data should have higher prediction confidence compared to uninformative data.
Evaluation Metrics. We use three criteria to jointly evaluate a selective learning outcome. (1)
Selective risk (SR). Selective risk is the empirical risk measured over the datapoints selected by the
algorithm. This is a metric that is also adopted in (Geifman & El-Yaniv, 2019; Liu et al., 2019). (2)
Precision. Precision is the proportion of true informative datapoints among all the data picked out by
the selector. (3) Recall. Recall is the proportion of true informative samples picked out by the selector
out of all the informative samples in the dataset. SR evaluates the quality of the classifier, Precision
and Recall are the standard ML metrics of the selector. An ideal selective learning algorithm should
have low SR, high precision and high recall.
Experiment setting. We assume that the ratio of informative data, α, is unknown to all methods.
This is necessary in practice; the ratio and strength of noise are not known in most real world
scenarios. For SelectiveNet and DeepGambler, such ratio is a required input. To run these baselines,
we first run the original backbone for 60 epochs, and then estimate α using backbone’s training
accuracy. Assume that the backbone fits all of the informative data perfectly and also makes some
correct guesses on noisy data with probability numfasses，then the frequency estimation of α is
α = num nUm瑞:黑-11 , which is the value we give to baselines. For more details about the
experimental design, please refer to the Appendix (section D).
Results and discussion. Table 1 presents the result where we mix the entire uninformative dataset
(shuffled MNIST) with different proportions of the informative dataset (Fashion-MNIST). Our
algorithm outperforms all the baselines in this setting. If we use partial dataset by decreasing the
number of noisy datapoints and repeating previous experiments with the same uninformative-to-
informative data ratios, our algorithm wins by an even larger margin (Table 2).
We can see that both SelectiveNet and DeepGambler fall apart in the setting where informative data
are sparse. Neither of them achieve a risk below 40% when we mix in only 25% of informative data.
The reason is that both of these two methods are only designed to achieve predetermined coverage
and cannot dynamically adapt to settings with unknown informative-to-uninformative data ratio. Our
algorithm thus gains advantage by learning the underlying uninformative data labeling function in a
data-driven manner.
Our algorithm also outperforms all the baselines on SVHN dataset where noisy data comes from a
similar domain to the informative data. Each experiment is repeated 5 times. Mean and standard
deviation are presented in Table 3 and Table 4.
We provide more experimental results in the Appendix (section D). We test the performance of each
method in the case where α is given and in the case where datasets contain minority noisy data.
8
Under review as a conference paper at ICLR 2022
Table 1: (MNIST - Full Dataset - Unknown α). Results on a synthetic dataset consisting of
uninformative MNIST and informative Fashion-MNIST using the entirety of shuffled MNIST to
proxy for noise.
Uninformative Data Num.	Informative Data Num.	Criterion	Confidence	SelectiveNet	DeepGambler	Ours
60000	15000	SR(%) Precision Recall	59.32±0.83 0.46±0.79 0.94±0.07	45.44±0.68 0.61 ± 0.01 1.00 ± 0.00	45.37±1.29 0.61±0.01 1.00±0.00	10.35±0.31 1.00 ± 0.00 0.85 ± 0.01
60000	30000	SR(%) Precision Recall	39.23±0.47 0.68±0.56 0.98±0.00	28.15±0.63 0.80 ±0.01 1.00 ± 0.00	27.78±0.67 0.80±0.00 1.00±0.00	12.03±1.06 1.00 ± 0.00 0.92 ± 0.04
60000	45000	SR(%) Precision Recall	28.92±0.49 0.79±0.29 0.99±0.00	20.22±0.58 0.88 ±0.86 1.00 ± 0.00	19.09±0.41 0.89±0.00 1.00 ± 0.00	12.58±2.00 1.00 ± 0.00 0.97 ± 0.03
60000	60000	SR(%) Precision Recall	21.88±0.39 0.86±0.46 1.00±0.00	15.38±0.32 0.92±0.22 1.00 ± 0.00	14.20±0.62 0.94±0.00 1.00 ± 0.00	11.61±0.79 1.00 ± 0.00 0.97 ± 0.01
Table 2: (MNIST - Partial Dataset - Unknown α) Results on a synthetic dataset consisting of
uninformative MNIST and informative FashiOn-MNIST data using 25% of shuffled MNIST for noise.
Uninformative Data Num.	Informative Data Num.	Criterion	Confidence	SelectiveNet	DeepGambler	Ours
15000	3750	SR(%) Precision Recall	79.87 ± 0.40 0.22 ± 0.00 0.85 ± 0.00	74.03 ± 1.38 0.29 ± 0.02 1.00 ± 0.00	73.22±0.51 0.30 ± 0.01 1.00 ± 0.00	20.24 ± 9.25 1.00 ± 0.00 0.88 ± 0.07
15000	7500	SR(%) Precision Recall	65.83 ± 0.22 0.38 ± 0.00 0.92 ± 0.01	57.76 ± 1.97 0.48 ± 0.02 1.00 ± 0.01	58.13±0.68 0.48 ± 0.01 1.00 ± 0.00	13.71±0.24 1.00 ± 0.00 0.83 ± 0.01
15000	11250	SR(%) Precision Recall	55.99 ± 0.49 0.49 ± 0.01 0.94 ± 0.01	47.39 ± 1.85 0.60 ± 0.02 1.00 ± 0.00	46.96±0.50 0.60 ± 0.01 1.00 ± 0.00	13.06±1.86 0.99 ± 0.00 0.84 ± 0.02
15000	15000	SR(%) Precision Recall	48.51 ± 0.25 0.57 ± 0.00 0.95 ± 0.00	39.23 ± 0.90 0.68 ± 0.00 1.00 ± 0.00	39.85±0.36 0.68 ± 0.00 1.00 ± 0.00	19.10±4.50 0.99 ± 0.01 0.91 ± 0.04
Table 3: (SVHN - Full Dataset - Unknonw α) Results on a synthetic dataset consisting of uninforma-
tive SVHN and informative SVHN using all of shuffled classes to proxy for noisy data.
Uninformative Data Num.	Informative Data Num.	Criterion	Confidence	SelectiveNet	DeepGambler	Ours
33800	9200	SR(%) Precision Recall	64.91 ± 0.89 0.53 ± 0.01 0.98 ± 0.00	48.61 ± 23.37 0.52 ± 0.22 0.89 ± 0.10	18.24 ± 2.00 0.80 ± 0.02 0.96 ± 0.01	7.03±0.01 0.93 ± 0.01 0.85 ± 0.01
33800	18300	SR(%) Precision Recall	47.64 ± 0.89 0.70 ± 0.01 0.99 ± 0.00	28.15 ± 22.74 0.75 ± 0.18 0.96 ± 0.10	12.03 ± 0.99 0.88 ± 0.02 0.98 ± 0.01	5.41±0.97 0.95 ± 0.01 0.88 ± 0.01
33800	26200	SR(%) Precision Recall	36.53 ± 1.57 0.79 ± 0.01 0.99 ± 0.00	12.96 ± 1.70 0.88 ± 0.01 0.98 ± 0.00	8.65 ± 0.44 0.91 ± 0.01 0.98 ± 0.00	4.05±0.67 0.97 ± 0.01 0.89 ± 0.01
33800	28400	SR(%) Precision Recall	34.48 ± 1.15 0.80 ± 0.01 0.99 ± 0.00	12.10 ± 1.21 0.89 ± 0.01 0.98 ± 0.00	8.31 ± 0.64 0.92 ± 0.01 0.98 ± 0.00	4.43±0.86 0.96 ± 0.01 0.89 ± 0.01
Table 4: (SVHN - Partial Dataset - Unknown α) Results on a synthetic dataset consisting of
uninformative SVHN and Informative SVHN using 25% of shuffled classes to proxy for noisy data.
Uninformative Data Num.	Informative Data Num.	Criterion	Confidence	SelectiveNet	DeepGambler	Ours
9200	2285	SR(%) Precision Recall	74.47 ± 4.15 0.41 ± 0.05 0.94 ± 0.01	64.68 ± 20.32 0.37 ± 0.22 0.85 ± 0.23	34.48 ± 13.46 0.68 ± 0.13 0.83 ± 0.24	14.36 ± 0.08 0.87 ± 0.07 0.80 ± 0.02
9200	4600	SR(%) Precision Recall	61.44 ± 0.64 0.57 ± 0.00 0.95 ± 0.01	48.42 ± 23.42 0.58 ± 0.17 0.97 ± 0.03	26.42 ± 1.68 0.77 ± 0.02 0.96 ± 0.01	7.46 ± 0.87 0.94 ± 0.07 0.85 ± 0.01
9200	6900	SR(%) Precision Recall	52.41 ± 0.71 0.65 ± 0.00 0.96 ± 0.00	25.64 ± 3.01 0.76 ± 0.03 0.96 ± 0.03	20.83 ± 2.06 0.82 ± 0.02 0.97 ± 0.01	7.25±0.77 0.94 ± 0.01 0.87 ± 0.01
9200	9200	SR(%) Precision Recall	49.45 ± 0.45 0.67 ± 0.00 0.96 ± 0.00	24.69 ± 3.08 0.77 ± 0.03 0.98 ± 0.00	18.81 ± 1.47 0.83 ± 0.01 0.98 ± 0.00	7.22±0.54 0.94 ± 0.01 0.88 ± 0.01
5	Conclusion
In this work, we propose a natural noisy generative process to model a problem where a significant
proportion of datapoints are purely random. We solve it by learning both a predictor for classification
and a selector to abstain from the uninformative data. We propose a novel selector loss to learn
selector with theoretical guarantees. Based on the selector loss, we design a heuristic algorithm that
jointly learns the predictor and selector. Our empirical study shows promising results of our method.
9
Under review as a conference paper at ICLR 2022
6	Reproducibility Statement
We describe a synthetic data generation procedure, evaluation metrics and experiment setting in
section 4. For the convenience of the reader to reproduce the experiment, we also summarize the
setting and give implementation details in section D.3. The source code as well as parameters to
reproduce the experimental results will be made available together with the publication of the paper.
7	Ethics Statement
This paper focuses on a theoretical discussion about learning from data that contains different portion
of non-informative samples. Our experiments only use publicly available datasets. Our discussion,
analysis, or data shouldn’t raise any ethics-related issues. The learning method proposed in this paper,
however, can be potentially used in applications with fairness and privacy concerns. It our future
efforts in this area, we aim to address and resolve possible negative impact.
References
Sanjeev Arora, Elad Hazan, and Satyen Kale. The multiplicative weights update method: a meta-
algorithm and applications. Theory ofComputing, 8(1):121-164, 2012.
Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, and Ruth Urner. Efficient learning of linear
separators under bounded noise. In Conference on Learning Theory, pp. 167-190. PMLR, 2015.
Pranjal Awasthi, Maria Florina Balcan, and Philip M Long. The power of localization for efficiently
learning linear separators with noise. Journal of the ACM (JACM), 63(6):1-27, 2017.
Maria-Florina Balcan, Avrim Blum, and Santosh Vempala. A discriminative framework for clustering
via similarity functions. In Proceedings of the fortieth annual ACM symposium on Theory of
computing, pp. 671-680, 2008.
Peter L Bartlett and Marten H Wegkamp. Classification with a reject option using a hinge loss. JMLR,
9(8), 2008.
Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds.
Journal of the American Statistical Association, 101(473):138-156, 2006.
Avrim Blum, John Hopcroft, and Ravindran Kannan. Foundations of data science. Vorabversion
eines Lehrbuchs, 5, 2016.
Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K Warmuth. Learnability and
the vapnik-chervonenkis dimension. Journal of the ACM (JACM), 36(4):929-965, 1989.
Tom Bylander. Learning linear threshold functions in the presence of classification noise. In
Proceedings of the seventh annual conference on Computational learning theory, pp. 340-347,
1994.
Nicolo Cesa-Bianchi and Gdbor Lugosi. Prediction, learning, and games. Cambridge university
press, 2006.
Moses Charikar, Jacob Steinhardt, and Gregory Valiant. Learning from untrusted data. In Proceedings
of the 49th Annual ACM SIGACT Symposium on Theory of Computing, pp. 47-60, 2017.
Chi-Keung Chow. An optimum character recognition system using decision functions. IRE Transac-
tions on Electronic Computers, (4):247-254, 1957.
Corinna Cortes, Giulia DeSalvo, and Mehryar Mohri. Learning with rejection. In ICALT, pp. 67-82,
2016.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale
hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition,
pp. 248-255. Ieee, 2009.
10
Under review as a conference paper at ICLR 2022
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.
Ilias Diakonikolas, Daniel M Kane, and Alistair Stewart. List-decodable robust mean estimation
and learning mixtures of spherical gaussians. In Proceedings of the 50th Annual ACM SIGACT
Symposium on Theory ofComputing, pp.1047-1060, 2018.
Ilias Diakonikolas, Themis Gouleakis, and Christos Tzamos. Distribution-independent pac learning
of halfspaces with massart noise. arXiv preprint arXiv:1906.10075, 2019.
Ilias Diakonikolas, Vasilis Kontonis, Christos Tzamos, and Nikos Zarifis. Learning halfspaces with
massart noise under structured distributions. In Conference on Learning Theory, pp. 1486-1513.
PMLR, 2020.
Andrzej Ehrenfeucht, David Haussler, Michael Kearns, and Leslie Valiant. A general lower bound on
the number of examples needed for learning. Information and Computation, 82(3):247-261, 1989.
Ran El-Yaniv et al. On the foundations of noise-free selective classification. JMLR, 11(5), 2010.
Giorgio Fumera and Fabio Roli. Support vector machines with embedded reject option. In Interna-
tional Workshop on Support Vector Machines, pp. 68-82, 2002.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model
uncertainty in deep learning. In ICML, pp. 1050-1059, 2016.
Yonatan Geifman and Ran El-Yaniv. Selective classification for deep neural networks. In NeurIPS,
2017.
Yonatan Geifman and Ran El-Yaniv. Selectivenet: A deep neural network with an integrated reject
option. In ICML, pp. 2151-2159, 2019.
Yves Grandvalet, Alain Rakotomamonjy, Joseph Keshet, and StePhane Canu. Support vector
machines with a reject option. In NeurIPS, 2008.
Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor W Tsang, and Masashi
Sugiyama. Co-teaching: robust training of deep neural networks with extremely noisy labels. In
NeurIPS, pp. 8536-8546, 2018.
Steve Hanneke. The optimal sample complexity of pac learning. The Journal of Machine Learning
Research, 17(1):1319-1333, 2016.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016a.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In CVPR, pp. 770-778, 2016b.
Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected
convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pp. 4700-4708, 2017.
Heinrich Jiang, Been Kim, Melody Y Guan, and Maya R Gupta. To trust or not to trust a classifier.
In NeurIPS, pp. 5546-5557, 2018.
Adam Tauman Kalai, Adam R Klivans, Yishay Mansour, and Rocco A Servedio. Agnostically
learning halfspaces. SIAM Journal on Computing, 37(6):1777-1805, 2008.
Michael Kearns and Ming Li. Learning in the presence of malicious errors. SIAM Journal on
Computing, 22(4):807-837, 1993.
Michael J Kearns, Robert E Schapire, and Linda M Sellie. Toward efficient agnostic learning.
Machine Learning, 17(2-3):115-141, 1994.
11
Under review as a conference paper at ICLR 2022
Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer
vision? In NeurIPS,pp. 5580-5590, 2017.
Philip Klein and Neal E Young. On the number of iterations for dantzig-WOlfe optimization and
packing-covering approximation algorithms. SIAM Journal on Computing, 44(4):1154-1172,
2015.
Adam R Klivans, Philip M Long, and Rocco A Servedio. Learning halfspaces With malicious noise.
Journal of Machine Learning Research, 10(12), 2009.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
Yann LeCun, L6on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Ziyin Liu, Zhikang Wang, Paul Pu Liang, Russ R Salakhutdinov, Louis-Philippe Morency, and
Masahito Ueda. Deep gamblers: Learning to abstain With portfolio theory. In NeurIPS, 2019.
Pascal Massart and Elodie N6d6lec. Risk bounds for statistical learning. The Annals of Statistics, 34
(5):2326-2366, 2006.
Mehryar Mohri, Afshin Rostamizadeh, and Ameet TalWalkar. Foundations of machine learning. MIT
press, 2018.
Nagarajan Natarajan, Inderjit S Dhillon, Pradeep Ravikumar, and Ambuj TeWari. Learning With noisy
labels. In NIPS, volume 26, pp. 1196-1204, 2013.
David F Nettleton, Albert Orriols-Puig, and Albert Fornells. A study of the effect of different types
of noise on the precision of supervised learning techniques. Artificial intelligence review, 33(4):
275-306, 2010.
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and AndreW Y Ng. Reading
digits in natural images With unsupervised feature learning. 2011.
Tim Pearce, Felix Leibfried, and Alexandra Brintrup. Uncertainty in neural netWorks: Approximately
bayesian ensembling. In AISTATS, pp. 234-244, 2020.
Norbert Sauer. On the density of families of sets. Journal of Combinatorial Theory, Series A, 13(1):
145-147, 1972.
Hans U Simon. An almost optimal pac algorithm. In Conference on Learning Theory, pp. 1552-1563.
PMLR, 2015.
Ruey S Tsay. Analysis of financial time series, volume 543. John Wiley & sons, 2005.
Leslie Valiant. Probably approximately correct: natureos algorithms for learning and prospering in
a complex world. Basic Books (AZ), 2013.
Leslie G Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134-1142, 1984.
Vladimir N Vapnik and A Ya Chervonenkis. On the uniform convergence of relative frequencies of
events to their probabilities. In Measures of complexity, pp. 11-30. Springer, 2015.
Ashish VasWani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz
Kaiser, and Illia Polosukhin. Attention is all you need. arXiv preprint arXiv:1706.03762, 2017.
Marten Wegkamp, Ming Yuan, et al. Support vector machines With a reject option. Bernoulli, 17(4):
1368-1385, 2011.
Yair Wiener and Ran El-Yaniv. Agnostic selective classification. NeurIPS, 24:1665-1673, 2011.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.
Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama. HoW does
disagreement help generalization against label corruption? In ICML, pp. 7164-7173, 2019.
12
Under review as a conference paper at ICLR 2022
Ming Yuan and Marten Wegkamp. Classification methods with reject option based on convex risk
minimization. JMLR, 11(1), 2010.
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. In ICLR, 2017.
Chong Zhang, Wenbo Wang, and Xingye Qiao. On reject and refine options in multicategory
classification. JASA,113(522):730-745, 2018.
Yikai Zhang, Songzhu Zheng, Pengxiang Wu, Mayank Goswami, and Chao Chen. Learning with
feature-dependent label noise: A progressive approach. In International Conference on Learning
Representations, 2020.
Songzhu Zheng, Pengxiang Wu, Aman Goswami, Mayank Goswami, Dimitris Metaxas, and Chao
Chen. Error-bounded correction of noisy labels. In ICML,pp. 11447-11457, 2020.
13
Under review as a conference paper at ICLR 2022
A Illustrative Example for Algorithm 1
(b) Classifier in
1-st iteration
(c) Classifier in
12-th iteration
(d) Algorithm up-weighs
informative data
(a) Ground Truth
value
Figure 2: Illustration of Algorithm 1. By up-weighing the informative datapoints, the algorithm
progressively improves the classifier. d) shows the sum weight of all informative data over weight
sum of all data, i.e "iPf；I Yi ( See Y in Algorithm 1).
B	Theoretical Analysis
In this section, we show auxiliary results culminating with the proof of the main result in Theorem 4.
In this section, we will use the following well-known result repeatedly.
Lemma 1 (Hoeffding’s Inequality). Let Z1, ..., Zn be independent bounded random variables with
Zi ∈ [a, b] for all i, where -∞ < a < b < ∞. Then for all t > 0:
n2
1	2nt
P(nI ∑Zi - E[Zi]∣ ≥ t) ≤ 2e-(b-a)2
i=1
(9)
The next lemma provides an upper bound on the empirical risk RS (f *), if enough samples are
available.
Lemma 2. Consider a set of samples S = {(x1 , y1), ..., (xn, yn)} drawn i.i.d. from the Noisy
Generative Process and f* in the hypothesis class F satisfying f(x) ∈ {-1, +1}. If:
Then we have with probability at least 1 - δ :
RS(f *) ≤ 2(1 - α) + αε	(Io)
Proof: By definition:
R(f )= E(χ,y hDα [1 f(x) = y ]	(11)
and the empirical risk
1n
RS (f ) = -E 叫 f(χi ) = y}	(12)
Note that l{f (x) = y} is bounded in the interval [0,1] and given f * ∈ F, l{f (Xi) = yi}, i ∈ [n]
form a set of n independent random variables. By setting b - a = 1, t = α in Equation 9, the choice
of n ensures that -2^2 ≤ 6 log(δ). Thus
Ps-Dα[∣Rs(f*) - R(f*)I≥ s] ≤ δ.
14
Under review as a conference paper at ICLR 2022
where we have
R(f *) = E(x,y)〜Da11 f (X) = y]
=E(x,y)〜Dα[l{f*(x) = y}|x ∈ Ωu]P[x ∈ Ωu]
X-------------------V--------------------}
1 P[x∈Ωu]: Since y is labeled by coin flipping in Ωu
+ E(x,y)〜Da[1 {f"(X)= y}|x ∈ ωI]P[x ∈ ωI]	(13)
'-------------------V--------------------'
0: Since y is labeled by f * with 0 Bayes Risk in Ωi
=2(ι -α)
This way we have:
PSn 〜Da[|RS(f ) - J(I- a)| ≥ eα] ≤ R
which implies that Equation 10 holds with probability at least 1 一 δ.	□
The proof of Lemma 2 relies on the independence between If (Xi) = y% across different pairs
(Xi , yi ) ∈ Sn . However, there is no guarantee that such independence holds for the empirical
minimizer fS九 =argminf∈f RS(f)..
In order to prove Theorem 1, we use the growth function in Definition 7 for sets of size n and
the following symmetrization lemma. Here we show its proof for completeness; it can be found in
different sources (Mohri et al., 2018; Blum et al., 2016).
Lemma 3. Suppose Sn = {(X1, y1), ..., (Xn, yn)} are i.i.d sampled , L(f, X, y) ∈ [0, b] and LSn =
1 Pn=1 L(f,Xi,yi) .If
nt2 ≥ 2b2
then we have:
Psn~Da[SUF|Lsn(f) - L(f )1 ≥ t] ≤ 2Psn，sn ~Da[s∈FlLSn (f) - LSn(f )1 ≥ 刍.
Proof: Since |LSn(f) - L(f )| ≥ t and ∣Lsn(f) - L(f)| ≤ t implies |LSn - LSn| ≥ t thus
ɪsUP ILSn(f )-L(f )l≥t^ sup |Ls0 (f )-L(f )∣≤t
f ∈F	f ∈f	"	(14)
≤ IsuP |LSn (f )-Ls0 (f )I≥ t
f∈F	n
Taking expectation w.r.t Sn 〜Da and Sn 〜Da We have
PSn 〜Da[SUP |LSn (f) - L(f X ≥ t]PSn 〜Da[SUP 1 L$n (f) - L(f X ≤ X]
n α f∈F n	n α f∈F n	2
≤ PSn,Sn〜Dα[suP lLSn ⑴- LSn (f)| ≥
n f∈F	n	2
(15)
Next we lower bound P[sup ILS，(f) - L(f )∣ ≥ t ]. Since L(f,x,y) ∈ [0,b] and Var(L(f,x,y)) ≤
f∈F
b2, we have:
PSn〜Da[sup ILSn(f) - L(f)∣ ≤ I] ≤ 4Var(LSn) ≤ 1
n f∈F n	2	nt2	2
Given the choice of n ≥ 2b2, we have P[sup |LS；(f) - L(f )∣ ≥ t] ≥ 1 which implies
f∈F
PSn 〜Dα[suP lLSn (f) - L(f )| ≥ t] ≤ 2PSn耳〜Da[SUP l LSn (f) - LSn (f )| ≥ ^∙
f∈F	n	f∈F	n	2
Theorem 1. Under Assumption 1, given a set of samples Sn = {(X1, y1), ..., (Xn, yn)} drawn i.i.d.
from the Noisy Generative Process and
fSn=arg∈min RS(f),
15
Under review as a conference paper at ICLR 2022
suppose
32 [log(4∣GH(2n)∣) + log( 1)]
n ≥--------------？o------------
Then with probability at least 1 - 2δ:
RfSn) ≤ 2(I- α) + 2e°.
Furthermore,
Px〜Dl[f* (X)= fSn (x)] ≤ 2
Proof. : We first bound the probability of the event that R(fSn) ≤ 2 - (1 - 2e)α.
We start with bounding Ps^s，〜Da [|Rsn (f) - R(f) + R(f) - Rs，(f )| ≥ t] for a fixed f. Since
∣Rsn(f) - R(f) + R(f) - RSn(f)| ≥ t implies ∣Rsn(f) - R(f)| ≥ 4 or ∣R(f) - RSn(f)| ≥ 4
we have
Psn,sn〜Dα[∣Rsn(f) - R(f) + R(f) - RSn(f)| ≥ 2]
≤PSn 〜Dα[∣RSn (f)- R(f )| ≥ ^ ]+ PSn 〜。。[^4(f)- R(f )| ≥ ^ ]	(16)
nt2
≤2e-H
Let Fsn,s， = {f (x) : f ∈ F, x ∈ Sn ∪ Sn0 } ⊆ {+1, -1}2n with Lemma 3 and Eq 16 we have:
PSn 〜0. [SUP |RSn (f)- R(f )| ≥ t]
f∈F
≤2Psn,sn〜Dα[sup ∣Rsn(f) - RSn(f)| ≥ t].
n	f∈F	n	2
=2Psn,sn〜Da[ sup	∣Rsn(f) - RSn(f)| ≥ t]
f ∈FSn,Sn	2
≤2	X	P[∣Rsn(f) - Rsn(f)| ≥ I]
n2
f ∈FSn,Sn
=2 X	P[∣Rsn(f) - R(f) + R(f) - Rsn(f)| ≥ t]
n
f ∈FSn,Sn
,,E	I -nt2
≤4FSn ,Sn |e 32
≤4Gf (2n)e-噂
(17)
tλ _ 一一 一，	_ a 、 32(4 log(GF (2n))+log( 1))	_ ɪɪ J__i_TJ	___ɪ -l C
By setting t = αe and n ≥ -~~	/2 ——we have with probability of at least 1 - δ:
α
R(fSn ) - RSn (fSn ) ≤ 工
Next we apply the fact that fSιτ = arg minf ∈f RS(f). Since RSn (f *) ≥ RSn (fSιτ), we have:
α	α
R(fSn ) ≤ 工 + RSn (fSn ) ≤ 工 + RSn (f B
Since RSn(f *) ≤ 2(1 - α) + Ea with failure probability at most δ (Lemma 2), we have with
probability at least 1 - 2δ :
R(fSn) ≤ 2(1 - a) + 2eo.
Next we prove the claim that:
Px"l[f F) = fSn (X)] ≤ 2E.
16
Under review as a conference paper at ICLR 2022
Since R(fSn) ≤ ɪ (1 - α) + 2eα:
R(fSn)=E(χ,y)〜"1 f (X)= y}]
=P(x,y)〜Da[l{fSn (X) = y}]
=P(x,y)〜Dα[l {fSn (X) = V}∖x ∈ ωU ] P(χ,y)〜Da[x ∈ ^U]
S--------------V----------------------V--------'
1 1-α
+ P(x,y)〜D/1 {fSn (X) = y}∖x ∈ ωI ] P(x,y)〜Dα[x ∈ ωI ]
s--------------V--------------'、------V--------'	(18)
P(x,y)〜Da [1 {fSn (X) = f*(χ)}∣χ∈Ql ]	α
=1(I- a) + αpX^Da [1 {fSn (X) = f *(X)}∖x ∈ QI]
≤ ɪ(l — α) + 2eα
=⇒Px-Da [1 {fSn (X) = f * (X)}∖x ∈ CI] ≤ 2
□
Next We analyze the weighted risk in Definition 6 and its empirical version. In particular, we are
interested in the case where θ > α, which implies θ ≥ -ɪ-θ. For a given pair (xi, %), we have:
θ 一 、 ............................1	- θ -.................... 1 θ
a 1{f(Xi) =	y∙i}l{g(Xi)	> 0}	+ ι - Ql{f(Xi)	= y∙i}l{g(Xi)	≤ 0 ≤	≤ -
It is useful to write down explicitly the following decomposition of W(g, f, θ):
—	—	「θ — . ..............1 - θ …...................1
W(g, f, θ) = E(χ,y)〜Da -i{f (x) = y}i{g(X) > 0} + -i{f (X) = y}i{g(X) ≤ 0}
-	1--
θ
=E(χ,y)〜Da -l{f (x) = y}l{g(X) > 0}l{g (x) > 0}
θ
+ E(x,y)〜Da -1{f(x) = y}i{g(X) > 0}i{g (X) ≤ 0}
1-θ
+ E(x,y)〜Da ι--i{f (x) = y}i{g(X) ≤ 0}i{g (x) ≤ 0}
1-θ
+ E(x,y)〜Da ;---l{f (x) = y}l{g(χ) ≤ 0}l{g (χ) > 0}
1--
θ
=-P(x,y)〜Da [f(χ) = y∖g(χ) > 0,g (χ) > 0]Pχ〜Da [g(χ) > 0,g (χ) > 0]
θ
+ -P(x,y)〜Da [f (x) = y∖g(x) > 0,g (x) ≤ 0]Pχ〜Da [g(x) > 0, g (χ) ≤ 0]
1-θ
+ 1--p(χ,y)〜Da[f (x) = y∖g(χ) ≤ 0,g (x) ≤ 0]
1-θ
+1--P(x,y)〜Da[f(x) = y∖g(χ) ≤ 0,g (X) >。]吗〜Da [g(X) ≤ 0,g (X) > 0]
θ
=-P(x,y)〜Da [f(χ) = y∖g(χ) > 0,g (χ) > 0]Pχ〜Da [g(χ) > 0,g (χ) > 0]
θ
+ 5-pχ〜Da[g(X) > 0,g (x) ≤ 0]
2-	a
1-θ
+	----VPx〜Da [g(X) ≤ 0,g (x) ≤ 0]
2(1 - -)	a
1-θ
+ 1--P(x,y)〜Da [f(x) = y∖g(x) ≤ 0,g (χ) > 0]Px〜Da [g(x) ≤ 0, g (χ) > 0]
(19)
17
Under review as a conference paper at ICLR 2022
One can see that if θ > α, then g(x) should reject all X ∈ Ωu since αθ > 11-α. For the informative
partition X ∈ Ωi, the decomposition suggests acceptance of all X such that f (x) = y and rejection of
f (χ) = y. This gives the optimal value 2(；工)Px〜Dα [g*(χ) ≤ 0]. Note that the optimal value of
W(g, f, θ) is not necessarily achieved at (f *, g*). For any fixed f, the optimal value of W(g, f, θ) is
achived for g as long as g accepts all datapoints in Ωi that are correctly classified by f, and rejects
all mistakes made by f in Ωi (as well as all datapoints in Ωu).
Lemma 4. Given a set of samples Sn = {(X1 , y1 ), ..., (Xn, yn)} drawn i.i.d. from the Noisy
Generative Process. Suppose θ ∈ (α, 1), α ∈ (0, 1), ≤ 0.1, and:
n≥
2θ2 log( 1)
e2α4
Then with probability at least 1 - δ we have:
∣Wsn (g*,f*,θ)-W (g*,f *,θ)l≤ αe
Proof. The following holds for a given (Xi, yi):
-l{f(Xi) = yi}l{g(χi) > 0} + 1■-θl{f(Xi) = yi}l{g(χi) ≤ 0}∖ ≤ θ.
α	1-α	α
Since θ < 11, we can apply Hoeffding,s inequality in Lemma 1 with a = 0,b = αθ. For fixed
g, f ∈ F, l{f (Xi)= yi}, i ∈ [n] are set of n independent random variables. By setting b - a = αθ,
t = αe in Equation 9, the choice of n ensures that Wn)2 ≤ 6 log(δ). Therefore:
PSn 〜Da[IWSn (^，f ^) — W (g'/,θ)l ≥ ^] ≤ δ.
□
Recall the empirical minimizer of WSn (g, fS九,θ):
gSn * = arg min WSn (g, fSn , θ) ∙
g∈H	n
Since fS* and gS* are data-dependent, it follows that Wi(gS* , fS* ,-), i ∈ [n] are not independent
draws. Our strategy is to use similar logic as in the proof of the Theorem 1. We begin by finding an
upper bound on the probability of WSn(g, f,-) deviating from its expectation. Then we take a union
bound of all the possible pair of (g, f) ∈ H × F restricted to Sn.
Theorem 2.	Consider a set of samples Sn= {(X1, y1), ..., (Xn, yn)} drawn i.i.d. from the Noisy
Generative Process and
fS*n = argminRS(f),gSn* = arg min WSn (g, fS*n, -),
f∈F	g∈H
If- ∈ (α, 1), α ∈ (0, 1) and
32θ2 (log(4∣GH(2n)∣∣GF(2n)∣)+log( 1))
n ≥	;2O4
then with probability at least 1 - δ:
|W (gSn ,fSn ,θ) — WSn Un f /)1 ≤ ^.
18
Under review as a conference paper at ICLR 2022
Proof. First We apply Lemma 3 with LSn (f, g) = WSn (g, f, θ), b = θ and t= α, and also using
the condition n ≥ 32θ log(2|GH(2nXGF(2n)|)+log( 1) ≥ 22θ^ in the lemma. Then it follows:
2α4	2α4
PSn"a [SUP |WSn (gf , θ) - W (gf , θ) | ≥。七]
g∈H	n	n
α
≤2pSn,sn〜Da[sup IWSn(g,fSn⑼-WSn(g,fSn,θ)1 ≥ 丁]
n g∈H	n	n	n	2
α
≤2PSn,Sn 〜Da[ SUP WSn (g, f 网-WSn (gJ∕)I≥ 可]
n	g∈H,f ∈F	n	2
α
≤2PSn,Sn 〜Da[	SuP	IWSn (g, f, θ) - WSn S,f,θX ≥ 丁]
g∈HSn,Sn0 ,f∈FSn,Sn0	2
≤2	E	PSn,Sn〜Dα[∣WSn (g, f, θ) -	WSn (g,f,θ)I≥ 工]
g∈HSn,Sn0 ,f∈FSn,Sn0
≤2	X	PSn,Sn〜Dα [IWSn (g,f,θ) -	W(g,f,θ) + W(g,f,θ)	- WSn (g,f,θ)I≥	OE]
g∈HSn,Sn0 ,f ∈FSn,Sn0
≤4∣HSn,Sn IlFSn,Sn IPSn 〜Dα[WSn (g, f, θ) - W (g,f,θ)∣ ≥ ɪ]
≤4GH (2n)GF (2n)e
na2e2
32 θ2
32 02

，「…~ …、nα4e2
=4Gχ(2n)GF (2n)e 32θ2
(20)
□
Next We bound the FPR and FNR of gSn leveraging on the fact that WSn (g, fSn) is sufficiently small.
Theorem 3.	Under Assumption 1, given a set of samples Sn = {(x1, y1), ..., (xn, yn)} drawn i.i.d.
from Noisy Generative Process and
fSn = arg min RS(f), gSn * = arg min WSn (g, fSn ,θ),
f∈F	g∈H
ifθ ∈ (α, 1), α ∈ (0, 1) and
32θ2 [log(4∣GH(2n)∣∣GF(2n)∣)+log(5)]
n ≥	E2O4
We have
I)	with probability at least 1 - δ
W(gSn ,fSn ,θ) ≤ 2eΘ + 2oe +(1-^
II)	if θ = 2cα with 1 ‹ c < 1+α, we have With probability at least 1 一 δ
12cOE
P[gSιτ (x) ≥ 0∣g (x) ≤ 0] ≤  --[FFnlee Positive]	(21)
n	2c - 1
P[gS* (x) < 0Ig*(x) ≥ 0] ≤ 20cE[False Negative]	(22)
Proof of I)
19
Under review as a conference paper at ICLR 2022
Proof.
W USn f ,θ)
≤	WSn (磋“ JSn ")+ 旌
X-----------V------------}
with failure probability at most δ Theorem 2)
≤ WSn (Mn W + m
V---------------V-------}
Optimality of 9自九
≤	W (g*,fSn ,θ) + 2αc
、-----------V------------}
With failure probability at most δ (Lemma 4)
「。
= E(x,y)〜Da a 1{fSn (X)= y}1{g (X) > 01
_	「1 - θ …，、	、一、 J
+ E(x,y)〜Da	1-a 1{fSn (X)= y}1{g (X) ≤ 0} +2αe
θ
=E(x,y)〜Da	a 1{fSn (X)= y}∖g (X) > 0 Px 〜DJg (X) ≥ 0]
1-θ
+ E(x,y)〜Da	；---lf^fsn,(X) = y}∖g (X) ≤ 0 Px〜Djg (X) ≤ 0] + 2a
1 — Q
= E(x,y)〜Da [θl {fSn (X) = y}\g * (X) > 0] + E(x,y)〜Da [(1 - θ) 1{fSn (X) = ⅛}\»" (X) ≤ 0]
=θ	Px〜DI [/Sn = f *(X)]
≤2e with failure prob at most δ (Thm 1)
+	(1-θ)Px〜DU [/Sn = y]	+20e
=0.5 since all y’s in Ωu are coin flipping
≤2eθ + 2αe + (I - θ
(23)
□
ProofofII):
Proof.
W (gSn ,/Sn ,θ)
θ
= E(x,y)〜Da Q 1{fSn (x) = y}1{gSn (X) > 0}
1-θ
+ E(x,y)〜Da [1-Q l(fSn (x) = y}1{9Sn (X) ≤ 0}	(24)
θ
=E(x,y)〜Da Q l{fSn (X) = y}1{gSn (X) > 0}Z (X) ≥ 0 Px 〜Da D (x) ≥ 0]
'---------------------------------V-----------------------------'
Term 1
θ
+ E(x,y)〜Da Q 1{fSn (x) = y}1{gSn (X) > 0}Z (X) ≤ 0 Px 〜Da D (x) ≤ 0]
、----------------------------------------V-------------------------------------}
Term 2
1-θ
+ E(x,y)〜Da	；-- l{fSn (X)	= y}1{gSn	(X) ≤	0}|9	(X) > 0	Px〜Da	D	(X) ≥ 0]
1-Q
X----------------------------V------------------------------}
Term 3
1-θ
+ E(x,y)〜Da	1-Q l{fSn (X)= y}1{gSn (X) ≤ 0}|9 (X) ≤ 0 Px〜Da D (X) ≤ 0]
X--------------------------------V----------------------------------'
Term 4
20
Under review as a conference paper at ICLR 2022
Next we lower bound Term 1,2, 3,4 individually and apply upper bound on WIg七), θ) in Eq 23
for the proof of the statement.	"	"
Term 1:
-∩ -
e(≈,!∕)-pc. -i{∕sτι(^) ≠ y}i{5⅛τι∣›) > OHg*(c) ≥ θ 叱〜IUg*(c) ≥ o]
=]E3y)〜兀 [1{琮⑺ ≠ y}l{g*sn{x') > 0}∣∕(x) ≥ θ] 6»	(25)
=θ^x,y)^va [i{∕sτι(χ) ≠ y}∖gsSx") > o,g*(2) ≥ °]叱〜。CJgXI3 > (⅜*3 ≥ o]
≥0
Term 2:
"Q	"
‰,y)^va -l{fsjx) ≠ y}l{g'sjx) > 0}∣∕(x) ≤ 0 Px^va [/(ʃ) ≤ 0]
="[。％(")R [l[fsjx') ≠ y}l{gsjx') > 0}∣∕(x) ≤ θ]
="([ °%(")R [1{fsJx') ≠ y}∖βsn(.χ') > o,g*(c) ≤ o]Pχ~pc, Wsn(ʃ) > o∣g*(c) ≤ o]
^x^τ)u [∕3ιτ≠y] = 0.5 Since all y are coin flipping if g* (æ) ≤ 0
叱〜。JgM(2)> °m*(') ≤ oι
(26)
Term 3:
「1 一 0	"I
⅜r,6% ;------l{fsn(x') = y}l{gsn(x') ≤ ɑll/(ʃ) > 0 F⅛,[g*3 ≥ 0]
1 ■— Q
~^jE(工⑨〜。。[1{∙∕‰f>) = y}i{5⅞l(2) ≤ OHg*3 > θ]	Q7)
=Oj^~等「(”团〜。。[报l3 = y∖9sjχ') ≤ o,g*(c) > 0]叱〜。。[*⑺ ≤ Olg*(/) > 0]
1 — Ct
By Theorem 1 we have with failure probability at most 2δ:
巴〜IU底 ¥/*(叫g*3≥o]≤2e
=叱〜。。[底 ≠ f*3,g2<χ) > Olg*(/) >。]十叱〜。。[报I ≠ ∕*(>), *l3 ≤ *⅜*3 > o] ≤ 2e
=叱〜%[底≠ /*(叫点⑺≤ 0,9*3 >。叱〜。。[姆⑺≤ <⅜*(c) > θ] ≤ 2e
={1 — px^va [fsn = r(x')∖gsjx') < 0,9*3 >。]}叱〜。。[fi⅞τl⑵ ≤ <⅜*3 > 0] ≤ 2e
= iPχ-pc,Ifsn =f*(χ')∖gsn3 ≤。, g*3 >。*〜IUglI⑺ ≤ ɑl/(ʃ) > 0]
≥ 叱〜。。[5⅞l(2) ≤ 0∣ff*(x) > 0] - 2e
(1 - θ∖a
= ɪ _ α ‰^τιa [l{fsn = Γ(.x')}∖9sjx') ≤ 0,9*3 >。%〜。。[娱⑺ ≤ <⅜*(c) > 0]
≥ ɪɪ,— {吗〜IUgiI(C) ≤ θl/(ʃ) > θ] - 2e}
1 — Q
(28)
Term 4:
「1 一。	"I
JE(^)〜。。i----1{fsJχ')=沙}1{感⑺ ≤ OHg*3 ≤ θ 叱〜IUg*3 ≤ 0]
=(1 - 0)E(x,y)^pcι [l[f*Jx') = y}l{g^3 ≤ 0}∣∕(x) ≤ 0]
=(1 —呼(“)〜OJI{母⑺="感3 ≤ 0,∕(x) ≤0]%scj5⅛τι(c) ≤ 0∣∕(x) ≤ 0]
V® s.t.g* (x)≤0,y is coin flip
i — 0
=-ʒ- {1 一叱〜。。底 τιf>) > <⅜*(c) ≤ θ]}
(29)
21
Under review as a conference paper at ICLR 2022
Combining Equations 25, 26, 28, 29 we have:
W (gSn ,fSn ,θ) ≥ {θ⅛ɑ) - l-Γ } Px 〜Da[gSn	' OU3 ≤ ^ +
+ αT-Γ PX~Dα[gSn (X) ≤ W*(X) > 0]-
2(1 - θ)αe
1 - α
(30)
and by part I ) in the theorem, we have with probability at least 1 - 3δ:
W (gSn ,fSn ,θ) ≤ 2eθ + 2αe + (1-6
Combined with the failure probability 2δ in the bound of Term 3 we have the failure probability at
most 5δ:	[θ⅛α2 — 厂} Px〜D.[gSn (x) > Olg*(X) ≤ O] + 厂 2α	2	2 +01--α) Px~Da[gSn (x) ≤ o∣g*(X) > o] - 2(ι1-θααe
(1 - θ)(1 - α)
≤ 2eθ + 2αe + ʌ----------L
θ 1	2	(31)
=⇒ ∣2α - 2 j Px〜Da[gSn (X) > 0|g* (X) ≤ 0]
+ α1-^ Px 〜Da[gSn (X) ≤ 0lg*(x) > 0]
1-α α n
2(1 - θ)α
≤ 2eθ + 2αe + -----L—
1-α
By picking θ = 2cα with 1 ‹ c < 1+α We Can ensure that 1)聂一1 › °； 2) α1-0θ) ≥ α. Finally
we have:
Px〜Dα[gSn(x) > 0∣g*(X) ≤ 0] ≤ 4cɑe + 4ae
12cα
Px 〜Da[gSn (x) > 0lg*(X) ≤ 0] ≤ 3-T
2c - 1
(32)
and
∖1- αθ Px〜Dɑ [gSn (x) ≤ 0|g*(X) > 0] ≤ 4cατ + 2(； -Oa + 2ατ
•Px〜Dα[gSn(x) ≤ 0|g*(X) > 0] ≤ 20cτ
(33)
Given hypothesis class H, one can bound the growth function GH (n) through its VC-dimension.
Next we present the well known Sauer-Shelah Lemma below.
Lemma 5 (Sauer-Shelah Lemma(See (Blum et al., 2016; Mohri et al., 2018; Sauer, 1972))). Let
dvc(H) be the VC-dimension of hypothesis class H, for all n ∈ N,
dvc
GH(n) ≤ X
i=0
en
dvc(H)
dvc (H)
□
Now we are ready to prove the main result.
Theorem 4. Under Assumption 1, given a set of samples Sn = {(X1, y1), ..., (Xn, yn)} drawn
i.i.d. from the Noisy Generative Process, hypothesis class H with VC-dimension dvc (H), F with
VC-dimension dvc(F) and
fS*n=arfg∈mFinRS(f),gSn*=argg∈mHinWSn
g, fS*n
73	α2
72ɑ +72j ,
22
Under review as a conference paper at ICLR 2022
If α ∈ (0, 0.9) and:
n≥
128 [(dvc(H) + dvc(F)) log( 1) + log(竽)]
e2α2
We have with probability at least 1 - δ:
I)
P[gSn(x) ≥ 0∣g*(x) ≤ 0] = O(E)	[False Positive]
P[gsn (x) < 0∣g*(x) ≥ 0] ≤ O(E) [False Negative]
II)
Px〜Dα[f *(x) = fSn (X)IgSn (x) ≥ 3 = O(E)
(34)
(35)
1+ 1+α
Proof. I) above can be proved by observing C = -272- and applying Theorem 3 with Sauer's Lemma
1+1+α	I 1+“、
to bound the growth function in terms of VC-dιmensιon. Also notice that C = —272- ∈ (2, 1+Oa)
given α < 0.9. II) can be proved by observing that I) implies P[gsn(x) = g*(x)] = O(ε) and by
invoking Theorem 1.	□
Remark 3. Let us point out that our proposed selective strategy is different from the consistent
selective strategy in (El-Yaniv et al., 2010). Instead of rejecting by looking for consistent output
from all hypothesis in the version space, our approach deals with one single reasonably accurate
hypothesis (the empirical minimizer). We leverage empirical mistakes made by the predictor in order
to learn a selector, aiming to reject (only) the mistakes in a data driven manner. This avoids dealing
with the issues found in Theorem 14 in (El-Yaniv et al., 2010), where the selector fails to select any
data points.
Remark 4. In (Cortes et al., 2016), a second hypothesis for the selector is introduced and analyzed,
and at the same time, multiple commonly used loss functions are scrutinized and generalization
results are provided. The major difference between this work and (Cortes et al., 2016; Geifman
& El-Yaniv, 2019) is the motivation pertaining to selective learning. While in (Cortes et al., 2016;
Geifman & El-Yaniv, 2019) the selective loss is designed from a coverage ratio perspective, i.e.
one wants to trade coverage ratio for a higher precision (selective loss), our approach is designed
to distinguish data that is naturally unlearnable and unpredictable. This difference leads to an
alternative theoretical result. While the analysis in (Cortes et al., 2016) focuses on selective risk, our
theoretical analysis focuses on the quality of the selector in terms of both the false positive and false
negative errors with the final goal of rejecting uninformative data with high probability.
C	Tightness analysis
In this section, We investigate whether it is necessary to have ΩΩ (dvciH+dvc(F) samples to achieve
Px"ɑ[f* (X)= fSn (X)lg*(x) ≥ 0]= O(E)
and
max {P[gSn(x) = g*(x)∣g*(x) > 0], P[gSn(x) = g*(x)∣g*(x) ≤ 0} = O(ε).
We will show that there exists a distribution Dα among the Noisy Generative Process family and
hypothesis class H, F such that achieving guarantees in Theorem 4 requires Ω(dvc(H)+dvc(F))
samples, thus making our analysis tight within logarithmic factor. Note that our lower bound is
for empirical minimizers of R(f) and W(g, f, θ); it only illustrates the tightness of our analysis,
and thus is not an information theoretic bound for this family of problem - it remains unknown
whether strategies other than the empirical minimization of R(f) and W(g, f, θ) can improve sample
complexity to a rate of 0ε, observing that the informative data is realizable, which usually only
requires O(ɪ) samples for an E statistical error.OUr construction leverages the idea from (Ehrenfeucht
et al., 1989) about the support of the informative data. Over the support of uninformative data, noise
buries the signal of the informative data, thus misleading the empirical minimizer. In our analysis, we
will leverage the anti-concentration results of the Chernoff bound, with the proof idea that comes
from (Klein & Young, 2015):
23
Under review as a conference paper at ICLR 2022
Lemma 6 (tightness of the Chernoff bound). Let X be the average of k independent, 0/1 random
variables (rv.). For any E ∈ (0,1/2] andP ∈ (0,1/2], assuming Epk ≥ 6,pk ≥ 6,ε ≤ 3, we have:
•	If each r.v. is 1 with probability p, then
P[X ≤ (1 - E)p] ≥ e-62pk .
•	If each r.v. is 1 with probability p, then
P[X ≥ (1 + E)p] ≥ e-62pk.
Proof. The proof is similar to Lemma 5.2 in (Klein & Young, 2015) with a different choice of
parameters. With Stirling,s approximation, i! = √2πi(i∕e)ieλ with λ ∈ [1∕(12i + 1), 1∕12i] one
can show:
(36)
Also note: P[X ≤ (1 - e)p] = P(=-ε)p PX =关].
Let ` = b(1 - 2E)pkc. Given the fact that εpk ≥ 6, we have (1 - 2E)pk - 1 ≤ ` ≤ (1 - 2E)pk. It
suffices to lower bound P(=-ε-p2ε)p PX = k] which is at least εpkP[X = `]. From Equation 36
we know that we need to bound A = eepk∕√π' and B =(`)'(告)k-`p`(1 - p)k-`. For term
A, since εpk ≥ 6, l ≤ (1 - 2ε)pk thus We need pk ≥ 9e-2ε to get
ε ≤ 3, it suffices to have pk ≥ 16. To bound B We need to show:
2ε√pk	≥ e-ε2ρk
e√2π(1-2ε)-
Since
⑴'(三)
k-l
pl (1 - p)k-l
≥ e-4ε2pk
SinCe (')'Pe ≥ ((ɪ))l and (I - p)k-l (占)k I= (k(i-p)++2ερk)k we have:
(1 - 2ε)' (1 + 1 + 2εpk )k ' ≤ e- 4ε⅛2k + 2εpk-2εpk+4ε2pk+2 ≤ e5ε2pk
I	k(I- p))—	—
□
We consider the following distribution. Let dvc(F) = d and ej be the standard basis with j-
th coordinate equal to 1 and 0 otherwise. We set ΩU = {+2, -2} ∙ ej, Ωu = ∪d=1ΩU and
ΩjI = {+1, -1} ∙ ej, Ωi = ∪d=1Ωl. Let F = sign(w>x) and H = 2 Qn=1 gj (x) — 1, where
gj(x) ∈ {l{∣e>x∣ ≥ c}∪ {0}, l{∣e>x∣ ≤ c}}. ByLemma 3.2.3 in (BlUmeretal.,1989) we know
dvc(H) ≤ 6dlog(d). We construct Da as follows: in Ωu, each standard basis has 1-a mass with
sign generated via coin flipping (fair). Having generated x, y ∈ {+1, -1} is generated via a coin
flipping. In Ωi, we put a(1 - ε) mass on e1 and d-1 mass on other standard basis ej∙, with sign
generated via a (fair) coin flipping. Having generated x, y ∈ {+1, -1} is generated via Sign(W*>x)
where w* denotes a vector of ones. The above construction allows one to calculate the expected error
by counting the number of basis that are not learned correctly, i.e., each j ∈ [d] s.t. wj < 0 implies
an error 2(O-1)in expectation. Since:
αεn
ESn〜Da[ISn ∩ ΩI ||] = ʃ-,
d- 1
by Markov inequality we have :
6αεn	1
PSn 〜Da[|Sn ∩ ΩI ∣∣≥ d-ɪ] ≤ -.
24
Under review as a conference paper at ICLR 2022
Also note that Ex〜Dα[l{x ∈ Ωl}l{x = -2ej}] = 12-α. In order to derive the probability that
wj < 0 via empirical minimization, we need to bound the following probability:
PxH [	E	yi- E	yi ≥
xi∈Ωj ,e> xi<0	xi∈Ωl,e>xi>0
6αεn
d - 1]
To do so, We consider the following n7- random variables that are conditioned on X ∈ C《：Zi = 1
if ej>xi < 0, yi = 1 or ej>xi ≥ 0, yi = -1 and zi = 0 otherwise. One can see 2 Pi∈n zi - nj =
Σxi∈Ωj,e>xi<0 yi - Σxi∈Ωj,e>xi>0 yi. Thus :
X6αεn
yi -	yi ≥ (d - 1)]
xi∈Ωj ,e>xi<0	xi∈Ωj ,e>xi>0
≥i。[丁 -J
3(1 - α)n
≤ |Sn ∩ Ωl∣≤ 3(1 -/,n]
d
• Pz 〜Sn [ xZi- nj
zi∈Snj
3αεn ∣ (1 — α)n	43(1 — α)n V , V 3(1 — α)n^
≥
≥ 2 Pz 〜Sn [ n X
zi∈Snj
Zi — — ≥
i 2 一
3αεd
(d - 1)(1 - α)
I (1 — α)n	43(1 — α)n V . V 3(1 — α)n^
≥ 1 e-18α2ε2nj ≥ 1 e
-2	- 2
54a2ε,
d
2n
(37)
If n ≤ 432%α2, we have for each j, with probability at least 0.40, Wj < 0 due to the empirical
minimization strategy. Each Wj < 0 contributes 2(O-1)risk in expectation. With probability 0.2, 20%
of coordinates can not be learned correctly, thus resulting in a risk ofat least 0.1εα in expectation.
Next we show that the selector is going to suffer from a poorly learned classifier in terms of its false
negative rate. Now lets focus on the case when E(x,y)〜Da [fsn (x) = y] ≥ 1 (1 - α) + 0.1αε (which
happens with probability at least 0.2), we will show that Ex〜Dα [1 {gsn(x) = g*(x)}|g* (x) > 0] ≥
0.1ε. Let J1 be the set ofj’s s.t. Wj < 0 and J2 for Wj > 0. Suppose θ > α, and consider empirical
minimization:
d
m∈iH WSn (fSn ,g, θ) ≥ X m∈in WSn∩Ωj f , g, θ)
g	j=1 g
(38)

For j0 ∈ Ji, g ∈ arg min WS ∩Ωj' (fS ,g,θ) if gj； (x) = 1{匕，> x| ≥ c}, c > 2 (and for other
g∈H n	n
basis j, gj can be arbitrary). For j0 ∈ J2, g ∈ arg min WS ∩Ωj'(fS ,g, θ) if gj； (x) = 1{®，>x| ≤
g∈H	n	n
c},c ∈ [1, 2). Now consider gSn = 2 Q；=i gj(x) - 1, gj(x) = l{∣e>x∣ ≥ c} with c > 2 if
j ∈ Ji and gj(x) = l{∣e>x∣ ≤ c},c ∈ [1,2) if j ∈ J. One can see that such gS九 is in the
intersection of set of minimizers of WSn∩Ωj (fSn ,g, θ) thus attains the minimum. The total mass
of x s.t. gSn(x) = g*(x) is at least J-『since for all X ∈ Ωj with j ∈ Ji, g之^(x) = g*(x). The
event E : E(x,y)〜Da [fSn (x) = f * (x)] ≥ 2 (1 一 a) + 0.1αε happens with probability at least 0.2
which implies that |Ji | ≥ 0.2d. Thus we have following lower bound on the False Negative:
Px〜Da[gSn (X)= g" (X) U (X) > 0] ≥ 0.1ε.
25
Under review as a conference paper at ICLR 2022
D Supplemental Material for Empirical Study
Extension to Multi-class. Our method extends to multi-class setting naturally. In the case of K-class
classification, we predictors f(x) = f (x)1:K : X → ∆K where ∆K is the K-simplex. In multi-class
scenario, our selector loss remains the same. Meanwhile, we use multi-class cross entropy loss to
train classifier. The pseudo-informative label becomes Zi = l{arg maxk∈[κ] f (xi)k = yi}.
Experiment setting with Unknown α (More Details). For MNIST/Fashion-MNIST experiment,
the backbone model we use for each candidate is TinyCNN, which is a CNN with two consecutive
convolution layers and 3 consecutive fully connected layers. This architecture provides enough model
capacity for an MNIST-type dataset. We use 196 as the batch size. We use Adam as the optimizer
with learning rate 1e-3 and weight decay 1e-4. We train with each algorithm for 162 epochs. We
use the default hyper-parameters for every method (i.e., internal selective learning-specific defaults,
as reported in (Geifman & El-Yaniv, 2019; Liu et al., 2019), and β = ；(1-彳)for our algorithm). It
simulates a practical scenario where hyper-parameter optimization is impossible, since the ground
truth regarding which datapoints are actually learnable is never revealed. For the SVHN experiment,
the backbone model we use is ResNet18 (He et al., 2016b) for every candidate. We use 128 as the
batch size. We use Adam as the optimizer with learning rate 1e-3 and weight decay 1e-4. We train
each algorithm for 162 epochs.
Weight of Informative data. From Figure 3, we can see that our algorithm can pick out almost all
informative data by the end of training for all informative/uninformative ratios even without knowing
the ground-truth α.
(a) MNIST. Weight on Informative Data (b) SVHN. Weight on Informative Data
Figure 3: Weight of informative data as a function of training epoch and the ratio of informative data.
The y axis is the percentage of weight put on the iformative data, i.e EvnY Yi in the notation of
Algorithm 1. Each experiment is repeated 3 times, and 3 standard deviations are presented as the
shaded gray area.
Experiments with Known α. We also test the performance of each method in the idealized case.
In this experiment, we give the groud-truth α to each baseline and perform an exhaustive HPO
(Hyper Parameter Optimization). We use the same backbone, optimizer and the number of training
epochs as before. We run a random hyper-parameter search 500 times (selective loss weight and
parameter λ for SelectiveNet and parameter o in DeepGambler) and record the best performance of
each baseline. In this setting, our method still outperform baselines for most levels of noise ratios. In
this experiment, we use two stage training for our algorithm. We first run 120 epochs to finish 1st
round data selection and then run 42 epochs to train a classifier only with these selected data. The
performance is measured with this refined the classifier.
Experiment with Low Ratio of Uninformative Data. We also conduct experiments with datasets
that contain minority stochastic data. This experiment is conducted under both practical (unknown
α) and idealized scenario (known α). In practical setting (unknown α), our proposed algorithm still
wins by a large margin. In the case when α is known, DeepGambler outperforms other methods in
26
Under review as a conference paper at ICLR 2022
most cases. We hypothesize that when noisy data minority, our method doesn’t get enough samples
to fully learn the pattern of uninformative data.
D.1 EXPERIMENT WITH KNOWN α
Table 5: (MNIST - Full Data Setting - Known α) Results on a synthetic dataset consisting of
uninformative MNIST data and informative Fashion-MNIST data using the entire MNIST.
Uninformative Data Num.	Informative Data Num.	Criterion	Confidence	SelectiveNet	DeepGambler	Ours
60000	15000	SR(%) Precision Recall	10.00 ± 0.32 0.99 ± 0.00 0.99 ± 0.00	10.11 ± 0.42 1.00 ± 0.00 1.00 ± 0.00	9.77 ± 0.51 1.00 ± 0.00 1.00 ± 0.00	9.18 ± 0.49 1.00 ± 0.00 1.00 ± 0.00
60000	30000	SR(%) Precision Recall	9.41 ± 0.20 0.99 ± 0.00 0.99 ± 0.00	9.91 ± 0.48 1.00 ± 0.00 1.00 ± 0.00	9.39 ± 0.26 1.00 ± 0.00 1.00 ± 0.00	9.03 ± 0.73 1.00 ± 0.00 1.00 ± 0.00
60000	45000	SR(%) Precision Recall	8.63 ± 0.23 1.00 ± 0.00 0.99 ± 0.00	9.39 ± 0.35 1.00 ± 0.00 1.00 ± 0.00	9.13 ± 0.51 1.00 ± 0.00 1.00 ± 0.00	8.58 ± 0.26 1.00 ± 0.00 1.00 ± 0.00
60000	60000	SR(%) Precision Recall	8.11 ± 0.08 1.00 ± 0.00 0.99 ± 0.00	8.21 ± 0.12 1.00 ± 0.00 1.00 ± 0.00	8.16 ± 0.05 1.00 ± 0.00 1.00 ± 0.00	8.04 ± 0.49 1.00 ± 0.00 1.00 ± 0.00
Table 6: (MNIST - Partial Data Setting - Known α) Results on a synthetic dataset consisting of
Uninformative MNIST data and informative Fashion-MNIST data Using 25% ofMNIST.____________
Uninformative Data Num.	Informative Data Num.	Criterion	Confidence	SelectiveNet	DeepGambler	Ours
15000	3750	SR(%) Precision Recall	16.71 ± 0.31 0.94 ± 0.02 0.90 ± 0.04	13.50 ± 0.30 1.00 ± 0.00 1.00 ± 0.00	14.11±5.65 1.00 ± 0.00 1.00 ± 0.00	11.38 ± 0.49 1.00 ± 0.00 1.00 ± 0.00
15000	7500	SR(%) Precision Recall	13.93 ± 0.40 0.96 ± 0.01 0.95 ± 0.02	13.34 ± 1.23 0.99 ± 0.01 0.93 ± 0.16	11.20 ± 0.22 1.00 ± 0.00 1.00 ± 0.00	11.29±0.44 1.00 ± 0.00 1.00 ± 0.00
15000	11250	SR(%) Precision Recall	12.29 ± 0.31 0.97 ± 0.01 0.95 ± 0.03	11.45 ± 0.37 1.00 ± 0.00 1.00 ± 0.00	10.61±0.12 1.00 ± 0.00 1.00 ± 0.00	10.42 ± 0.48 0.99 ± 0.00 1.00 ± 0.00
15000	15000	SR(%) Precision Recall	11.76 ± 0.20 0.97 ± 0.01 0.95 ± 0.02	11.24 ± 0.35 1.00 ± 0.00 1.00 ± 0.00	10.12±0.28 1.00 ± 0.00 1.00 ± 0.00	9.97±0.33 0.99 ± 0.01 1.00 ± 0.00
Table 7: (SVHN - Full Data Setting - Known α) Results on a synthetic dataset consisting of
uninformative SVHN and informative SVHN using the entire uninformative data.
Uninformative Data Num.	Informative Data Num.	Criterion	Confidence	SelectiveNet	DeepGambler	Ours
33800	9200	SR(%) Precision Recall	6.45 ± 0.93 0.93 ± 0.01 0.89 ± 0.01	58.06 ± 35.91 0.41 ± 0.36 0.37 ± 0.34	4.58 ± 0.61 0.96 ± 0.00 0.86 ± 0.02	4.48±0.43 0.96 ± 0.00 0.86 ± 0.01
33800	18300	SR(%) Precision Recall	4.30 ± 0.31 0.96 ± 0.00 0.91 ± 0.01	80.42 ± 1.55 0.35 ± 0.00 0.38 ± 0.05	3.08 ± 0.15 0.97 ± 0.00 0.90 ± 0.01	2.91±0.21 0.97 ± 0.00 0.88 ± 0.01
33800	26200	SR(%) Precision Recall	4.49 ± 0.68 0.96 ± 0.68 0.94 ± 0.01	5.22 ± 0.90 0.95 ± 0.01 0.92 ± 0.03	3.86 ± 0.11 0.97 ± 0.00 0.94 ± 0.00	3.65±0.17 0.96 ± 0.00 0.93 ± 0.01
33800	28400	SR(%) Precision Recall	10.87 ± 0.68 0.89 ± 0.00 0.98 ± 0.00	8.27 ± 5.03 0.92 ± 0.05 0.95 ± 0.04	7.65 ± 0.47 0.92 ± 0.01 0.97 ± 0.01	6.39±0.76 0.93 ± 0.01 0.95 ± 0.01
Table 8: (SVHN - Partial Data Setting - Known α) Results on a synthetic dataset consisting of
uninformative SVHN and informative SVHN using 25% uninformative data.
Uninformative Data Num.	Informative Data Num.	Criterion	Confidence	SelectiveNet	DeepGambler	Ours
9200	2285	SR(%)- Precision Recall	30.13 ± 34.94 0.70 ± 0.35 0.67 ± 0.34	55.91 ± 29.49 0.19 ± 0.10 0.16 ± 0.13	7.65±0.48 0.93 ± 0.01 0.78 ± 0.02	11.74 ± 2.32 0.90 ± 0.02 0.80 ± 0.06
9200	4600	SR(%)- Precision Recall	10.41 ± 0.26 0.91 ± 0.00 0.87 ± 0.01	36.46 ± 28.65 0.68 ± 0.24 0.69 ± 0.24	9.70 ± 1.05 0.90 ± 0.03 0.79 ± 0.04	8.12 ± 0.87 0.93 ± 0.01 0.78 ± 0.08
9200	6900	SR(%)- Precision Recall	8.51 ± 0.85 0.92 ± 0.02 0.91 ± 0.02	34.97 ± 30.15 0.73 ± 0.21 0.74 ± 0.22	7.49±0.47 0.94 ± 0.01 0.83 ± 0.04	7.67±0.63 0.92 ± 0.02 0.86 ± 0.01
9200	9200	SR(%)- Precision Recall	9.06 ± 0.82 0.91 ± 0.01 0.94 ± 0.01	13.66 ± 1.39 0.88 ± 0.02 0.92 ± 0.01	7.88 ± 0.29 0.93 ± 0.01 0.88 ± 0.03	7.57±0.51 0.92 ± 0.01 0.91 ± 0.01
27
Under review as a conference paper at ICLR 2022
Table 9: Results on low noise level for both MNIST and SVHN - Unknown α. We evaluate the
methods over different fractions of informative data.
Data Set	Uninformative DataNum.	Informative DataNum.	Criterion	Standard	SelectiveNet	DeepGambler	OUrS
MNIST	30000	60000	SR(%) Precision Recall	21.59 ± 0.33 0.86 ± 0.00 0.98 ± 0.00	14.97 ± 0.00 0.93 ± 0.00 1.00 ± 0.00	14.52 ± 0.76 0.94 ± 0.00 1.00 ± 0.00	12.97 ± 2.84 1.00 ± 0.00 0.98 ± 0.02
MNIST	7500	15000	SR(%) Precision Recall	34.73 ± 0.87 0.72 ± 0.01 0.93 ± 0.01	36.17 ± 0.00 0.72 ± 0.00 1.00 ± 0.00	34.20 ± 0.01 0.74 ± 0.01 1.00 ± 0.00	18.72 ± 6.31 0.98 ± 0.00 0.90 ± 0.07
SVHN	18300	28400	SR(%) Precision Recall	30.59 ± 0.55 0.71 ± 0.01 0.99 ± 0.00	8.94 ± 0.00 0.92 ± 0.01 0.99 ± 0.00	7.32 ± 0.01 0.93 ± 0.01 0.99 ± 0.00	4.69 ± 0.00 0.96 ± 0.00 0.92 ± 0.01
SVHN	2300	9200	SR(%) Precision Recall	36.69 ± 0.85 0.65 ± 0.01 0.97 ± 0.00	16.04 ± 0.01 0.86 ± 0.02 0.98 ± 0.01	17.48 ± 0.02 0.85 ± 0.02 0.98 ± 0.00	6.08 ± 0.01 0.95 ± 0.01 0.90 ± 0.01
Table 10: Results on low noise level for both MNIST and SVHN - Known α. We evaluate the
methods over different fractions of informative data.
Data Set	Uninformative DataNum.	Informative DataNum.	Criterion	Standard	SelectiveNet	DeepGambler	Ours
MNIST	30000	60000	SR(%) Precision Recall	8.19 ± 0.32 1.00 ± 0.00 0.99 ± 0.00	8.17 ± 0.12 1.00 ± 0.00 1.00 ± 0.00	8.09 ± 0.11 1.00 ± 0.00 1.00 ± 0.00	7.97 ± 0.13 1.00 ± 0.00 1.00 ± 0.00
MNIST	7500	15000	SR(%) Precision Recall	11.65 ± 0.38 0.93 ± 0.00 0.87 ± 0.01	11.47 ± 0.21 0.99 ± 0.00 1.00 ± 0.00	9.75 ± 0.63 1.00 ± 0.01 0.86 ± 0.28	10.37 ± 0.13 1.00 ± 0.00 1.00 ± 0.00
SVHN	18300	28400	SR(%) Precision Recall	11.81 ± 0.29 0.89 ± 0.00 0.99 ± 0.00	12.18 ± 0.67 0.89 ± 0.01 0.98 ± 0.00	6.92 ± 0.43 0.93 ± 0.00 0.98 ± 0.00	9.39 ± 0.92 0.89 ± 0.01 0.98 ± 0.01
SVHN	2300	9200	SR(%) Precision Recall	8.49 ± 0.13 0.92 ± 0.01 0.95 ± 0.01	11.96 ± 1.18 0.89 ± 0.01 0.95 ± 0.01	6.81 ± 0.60 0.95 ± 0.01 0.90 ± 0.01	8.43 ± 1.41 0.92 ± 0.02 0.95 ± 0.01
D.2 Experiment with Low Ratio of Uninformative Data
D.3 Implementation Detail
For all our experiments, we are using NVIDIA Tesla V100 GPUs, and we use AWS Sagemaker
service for our HPO processes. We repeat each experiment 5 times with random seed 77, 78, 79, 80,
81.
For MNIST/Fashion-MNIST experiment where α is unknown, the training and testing data set split
is listed in Table 11. The backbone we use is TinyCNN (in section 4). We use 196 as our batch size
and train for 162 epochs for all listed methods. We use Adam as the optimizer with learning rate 1e-3
and weight decay 1e-4. We shrink our learning rate at epoch 45 and 90 by half each time.
For SVHN experiment where α is unknown, the training and testing data set split is listed in Table 11.
The backbone we use is ResNet18. We use 128 as our batch size and train for 162 epochs for all listed
methods. We use Adam as the optimizer with learning rate 1e-3 and weight decay 1e-4. We shrink
our learning rate at epoch 45 and 90 by half each time. For both experiments where α is known
Table 11: Experiment Data Splitting.
Data Set	Uninformative Training Data Num.	Informative Training Data Num.	Uninformative Testing Data Num.	Informative Training Data Num.
	60000	60000	10000	10000
	60000	45000	10000	7500
	60000	30000	10000	5000
	60000	15000	10000	2500
MNIST	30000	60000	5000	10000
	15000	15000	10000	10000
	15000	11250	10000	7500
	15000	7500	10000	5000
	15000	3750	10000	2500
	7500	15000	5000	10000
	33800	28400	11900	9800
	33800	26000	11900	9100
	33800	18300	11900	6500
	33800	9200	11900	3300
SVHN	18300	28400	6500	9800
	9200	9200	11900	9800
	9200	6900	11900	9100
	9200	4600	11900	6500
	9200	2300	11900	3300
		4600			9200			6500			9800	
and HPO is enabled, we maintain the same backbone and optimizer. The hyper-parameter setting is
documented in the code. The code will be open sourced together with the publication of the paper.
28
Under review as a conference paper at ICLR 2022
E Extention of Theorem 4 in the case where only an upper bound
ON α IS GIVEN
Theorem 5. Under Assumption 1, given set of samples Sn = {(x1 , y1), ..., (xn, yn)}
drawn i.i.d. from the Noisy Generative Process with α ∈ (0, 1 - ξ], ξ ≥ 0.2 , hy-
Pothesis class H with VC-dimension dvc(H), F with VC-dimension dvc(F) and fSin =
argminf∈fRS(f),gSn* = argmin WSn (g, fSn, θ) ∙ If θ ∈ (73α,min{1 + 2(1-), 10}α) and
n≥
3200[(dvc(H)+dvc(F)) log(ε) + log( 16)]
^2O2
We have with probability at least 1 - δ:
I)
II)
P[gS* (x) ≥ 0|g* (x) ≤ 0] = O() [False Positive]
P[gS* (x) < 0|g* (x) ≥ 0] ≤ O() [False Negative]
(39)
Px〜Dɑf *(X)= fSn (X)IgSn (X) ≥ 0]= O(E)
III) Further more, to obtain gSn* = arg min WSn g, fS* , θ it suffices to minimize following
g∈H	n
loss with β ∈ (1 + 731-1，馆加口 + 2(1—ξ), 10}):
n
Loss(g; fSn,Sn,β) = X {户IfSn(Xi) = yi}l{g(xi) > 0} + l{fSn(Xi) = yi}l{g(xi) ≤ 0}}
i=1
≤
α ≤1— ξ ^⇒ --
一	1 - ξ
≤1
0 ɪ
1 - ξ
0 -ɪ
2(1 — ξ)
ξ1
0 4(1-ξ) + 2
≤
≤
≤
Proof. I) above can be proved by picking C ∈ (2 + 焉,1 + min{ 2, 4(1-ς)}) in Theorem 3. Note
this range is valid since α ≤ 1 - ξ, we have
1-α
≥1
1-α
α	(40)
1+α
^^2α--
1 + ɑ
4α
By a procedure similar to Theorem 4 (using the Sauer,s Lemma) We have I). Note C ∈ (1 + 击,2 +
min{1, 4(1—ξ)}) ^⇒ θ ∈ (卷,min{1 + 2(1—ξ), 2}α). II) can be proved by observing that I)
implies P[gS* (X) 6= g*(X)] = O(ε) and by invoking Theorem 1. Next We prove III). It is easy
to verify that the minimizer of WSn (g, fS* ) is equivalent to minimizer of Loss(g; fS* , Sn, β) (by
replacing β = O(I-O) )∙ It suffices to analyze that β ∈ (1 + 731-1, min{1+ 2(1—ξ), 10}) implies that
θ ∈ (73θ, min{1 + 2(1—ξ), 10}α). First note that 1—χ is monotone increasing in (0,1), it suffices
to compute image of ；(1—O) and check if β ∈ (1 + 7311-1, min{1 + 2(1-), 10}) stays in such range.
It can be easily verified that α ≤ 1 - ξ implies the lower bound 1 + 731-1 and α > 0 implies the
upper bound 1 + 2(1—1).
□
F Ablation S tudy on Hyperparameters
We provide an ablation study where we vary the hyper-parameter in each baseline. For SelectiveNet,
we first fix λ to be 32 (default setting that is recommended by the author in the original paper)
and then we vary a from 0.1 to 0.7. Then we fix a to be 0.5 (default setting) and then we vary λ
29
Under review as a conference paper at ICLR 2022
from 1 to 66. For DeepGambler, we vary o from 1 to 7. Finally, for our algorithm, we increase the
hyper-parameter β 4 to 10. We can see that the performance of all baselines are quite sensitive to the
choice of hyper-parameter and will experience some large fluctuation. On the contrast, our algorithm
is stable against the choice of hyper-parameter. This empirical observation supports that there exists
a wide range of β so that one can control the FNR and FPR if α is bounded away from 1 as it is
implied in Theorem 5. Furthermore, in all scenario, our algorithm’s performance is better than these
two baselines in two sense. On one hand, our selector has better precision such that we can recover
almost all informative data while the other two cannot. These two baseline tend to to select the whole
data set indistinguishably (low precision and high recall). On the other hand, these baselines show
consistently deteriorated risk performance than ours because of their selector fails to pick informative
data.
Selective Risk (%)
Precision
Figure 4: Ablation Study on Hyper-parameter β - Our Method.
Recall
Selective Risk (%)
Figure 5: Ablation Study on Hyper-parameter o - DeepGambler.
—60000/60000
-∙- 60000/15000
→<- 15000/15000
r- 15000/3750
—eαooo∕5θooo
—∙- 60000/15000
—15000/15000
τ- 15000/3750
Precision
Recall
30
Under review as a conference paper at ICLR 2022
—60000/60000
60000/15000
*	— — f- 15000/15000
→- 15000/3750
0.1	0.3	0.5	0.7
—60000/60000
—∙- 60000/15000
—15000/15000
→- 15000/3750
60000/60000
60000/15000
15000/15000
15000/3750
Selective Risk (%)
Precision
Recall
Figure 6: Ablation Study on Hyper-parameter a and λ - SelectiveNet.
31