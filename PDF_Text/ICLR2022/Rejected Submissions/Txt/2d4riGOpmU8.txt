Under review as a conference paper at ICLR 2022
Sequential Covariate Shift Detection Using
Classifier Two-Sample Tests
Anonymous authors
Paper under double-blind review
Ab stract
A standard assumption in supervised learning is that the training data and test data
are from the same distribution. However, this assumption often fails to hold in
practice, which can cause the learned model to perform poorly. We consider the
problem of detecting covariate shift, where the covariate distribution shifts but the
conditional distribution of labels given covariates remains the same. This problem
can naturally be solved using a two-sample test—i.e., test whether the current test
distribution of covariates equals the training distribution of covariates. Our algo-
rithm builds on classifier tests, which train a discriminator to distinguish train and
test covariates, and then use the accuracy of this discriminator as a test statistic. A
key challenge is that classifier tests assume given a fixed set of test covariates. In
practice, test covariates often arrive sequentially over time—e.g., a self-driving car
observes a stream of images while driving. Furthermore, covariate shift can occur
multiple times—i.e., shift and then shift back later or gradually shift over time. To
address these challenges, our algorithm trains the discriminator online. Further-
more, it evaluates test accuracy using each new covariate before taking a gradient
step; this strategy avoids constructing a held-out test set, which can reduce sam-
ple efficiency. We prove that this optimization preserves the correctness—i.e., our
algorithm achieves a desired bound on the false positive rate. In our experiments,
we show that our algorithm efficiently detects covariate shifts on ImageNet.
1	Introduction
A key challenge facing deep neural networks is their sensitivity to changes in the data distribution. In
particular, supervised learning traditionally assumes that the training and test data are from the same
distribution (Vapnik, 1998), but this assumption often fails in practice. For example, an autonomous
car using perception to identify obstacles needs to be robust to shifts such as changes in the weather
and lighting conditions. We focus on covariate shift (Shimodaira, 2000), where there is a shift in
the covariate distribution p(x), and the conditional label distribution p(y | x) remains unchanged.
Covariate shift can reduce model performance (Sugiyama & Muller, 20θ5), invalidate uncertainty
estimates (Ovadia et al., 2019; Park et al., 2020), and affect model selection (Sugiyama et al., 2007).
One strategy is to devise an algorithm to detect covariate shift; if detected, the algorithm can alert the
user that predictions may be unreliable. Covariate shift detection can be formulated as two-sample
hypothesis test (Gretton et al., 2012a; Rabanser et al., 2018; Liu et al., 2020), where the goal is to
determine whether two sets of examples are from the same distribution. To test for covariate shift,
we choose the first sample to be the data used to train the model and the second sample to be recent
test data given as input to the model. Then, the detector returns “covariate shift” if the hypothesis
test indicates that the two samples are from different distributions and “no shift” otherwise.
We propose a detection algorithm based on classifier tests (Lopez-Paz & Oquab, 2017; Cheng &
Cloninger, 2019; Kim et al., 2021), which use the accuracy of a classifier trained to distinguish the
two samples as the test statistic. In particular, if the two samples are from the same distribution, then
the accuracy should be 1/2; otherwise, it should be > 1/2. Since the test statistic follows a binomial
distribution, we use the Clopper-Pearson interval (Clopper & Pearson, 1934) (an exact confidence
interval for the unknown success probability of the Binomial distribution) to derive the cutoff. In
contrast, prior work relies on asymptotics to derive the cutoff, which results in approximations.
1
Under review as a conference paper at ICLR 2022
Akey challenge is that the test examples are typically obtained over time—e.g., an autonomous robot
continuously perceives its environment, and we want to detect if its distribution of observations shifts
at any time. There are two key challenges to leveraging classifier tests in this setting. First, they rely
on training a classifier to distinguish training and test examples; doing so on every step would be
computationally intractable. Second, they rely on a held-out test set to estimate the test statistic, but
constructing such a set online would reduce sample efficiency.
Rather than train a classifier at each step, our proposed algorithm trains a model online using stochas-
tic gradient descent. Then, rather than construct a held-out test set, our algorithm evaluates the ac-
curacy of the model online using each example before taking a gradient step on that example. We
prove that this strategy results in an unbiased estimate of the model accuracy; as a consequence, the
finite-sample guarantees on the false positive rate provided by the sequential test continue to hold.
In addition, we prove bounds on the false negative rate under mild conditions on the classifier (i.e.,
it achieves nontrivial accuracy distinguishing the two distributions).
We evaluate our approach on both synthetic and natural shifts on the ImageNet (Russakovsky et al.,
2015) dataset. In particular, we demonstrate that our approach achieves better sample efficiency
than baseline algorithms; furthermore, it uniformly satisfies the desired false positive rate. Thus, our
algorithm is an effective strategy for sequential covariate shift detection.
Contributions. We formulate (sequential) covariate shift detection as a two-sample test, and pro-
pose a novel algorithm to solve this problem (Section 3). Then, we prove finite sample bounds
on false positive rate and false negative rate achieved by our algorithm (Section 4). Finally, we
empirically demonstrate that our algorithm effectively detects shifts on ImageNet (Section 5).
Sequential detection vs. sequential tests. While we consider the sequential setting, we deliberately
choose not use a sequential hypothesis test, since the covariate shift may occur after a delay or
gradually over time. A sequential test only applies if all of the test data is shifted. Furthermore, since
we are not using sequential tests, the false positive rate bound only holds per-step, not uniformly
across all steps. This is necessary: we cannot guarantee that we detect a covariate shift occurring
at a later point in time if we constrain the false positive to be bounded uniformly across all steps.
In our experiments, we show that the rate of false alarms remains manageable while enabling our
algorithm to detect covariate shift in a number of interesting scenarios.
2	Related Work
Covariate shift. There has been work on training models in the presence of covariate shift. In
particular, in the unsupervised domain adaptation setting (Ben-David et al., 2007; Bickel et al.,
2007; Ganin et al., 2016), the algorithm has access to labeled examples from the source domain but
only unlabeled examples from the target domain, and the goal is to train a model that achieves good
performance on the target domain. One strategy is to use importance weighting to upweight source
examples that are more similar to target examples (Bickel et al., 2007). Another strategy is to first
learn an invariant representation (Ganin et al., 2016), which is an embedding space where the source
and target examples are similar, and then train a model on this embedding space using the source
examples. If we detect covariate shift, one solution is to retrain the model using these techniques.
Two-sample tests. We focus on classifier two-sample tests (C2ST). In this approach, the idea is
to train a binary classifier to distinguish source and target samples, compute a real-valued score
based on this classifier as the test statistic, and then use a univariate two-sample test to determine the
cutoff for rejecting the null hypothesis (Friedman, 2004). A natural test statistic is the classifier’s
accuracy on a held-out test set (Kim et al., 2021; Lopez-Paz & Oquab, 2017), or the differences
in the classifier’s logits (Cheng & Cloninger, 2019); in this work, we use the former. One way to
compute the cutoff is to use the asymptotic distribution of the test statistic (Lopez-Paz & Oquab,
2017). Nonparametric tests such as permutation tests can also be used (Kim et al., 2021).
Another kind of two-sample test is called a kernel two-sample test. In this approach, the idea is to
use the maximum mean discrepancy (MMD) between the two samples according to a given kernel
embedding as the test statistic (Gretton et al., 2012a; Chwialkowski et al., 2015; Jitkrittum et al.,
2016). The key design decision is the choice of kernel. One strategy is to use a nonparametric kernel
such as Gaussian radial basis functions (Gretton et al., 2012a); alternatively, the kernel can also be
optimized to minimize the false negative rate of the resulting test (Gretton et al., 2012b). In addition,
2
Under review as a conference paper at ICLR 2022
recent work has shown how to first learn a kernel function in the form of a deep neural network, and
then evaluate the MMD distance on a held-out test set (Liu et al., 2020). The test statistic can be
chosen based on finite sample bounds or based on its asymptotic distribution (Gretton et al., 2012a).
Nonparametric permutation tests can also be used (Liu et al., 2020) with this approach.
Concept Drift. In the context of concept drift (Gama et al., 2014), there has been work detecting
shifts in p(χ, y) (Goncalves Jr et al., 2014). However, this work assumes that ground truth labels are
provided for test examples, whereas our approach only requires unlabeled test examples. The former
is substantially easier, since it suffices to check for drift in the distribution of prediction errors, which
is usually very simple (e.g., a Bernoulli distribution for the 0-1 loss), making it easy to test for drift.
In contrast, our approach checks for drift in high-dimensional covariates distribution.
Sequential hypothesis testing. A closely related problem is sequential hypothesis testing, which
adaptively decides whether to reject the null hypothesis as samples become available (Wald, 1945).
These approaches can also applied to two-sample testing (Balsubramani & Ramdas, 2015; Lheritier
& Cazals, 2018; 2019; Manole & Ramdas, 2021). However, as discussed above, they assume that
the each distribution of the two samples does not change over time. In contrast, we are interested
in the setting where the test examples might initially be from the same distribution as the training
examples, but then shift at a later point in time. Sequential tests are not applicable to this setting.
3	Sequential Covariate Shift Detection
3.1	Problem Formulation
Let X be the covariate space, S be the source distribution over X, and Tt1:t2 = (Tt1, Tt1+1, . . . , Tt2)
be a sequence of target distributions over X from time steps t1 to t2 . On time step t, we consider
samples Xt 〜S and Xt 〜Tt; in practice, S can be taken to be the uniform distribution over
the training set. We let Sw,t = (xt-w+1 , xt-w+2 , . . . , xt ) and Tw,t = (xt-w+1 , xt-w+2 , . . . , xt )
denote the recent examples in a time window of a given size w ∈ N.
Our goal is to detect covariate shift at any step t. More precisely, we want to determine whether
S = Tw,t, where TW,t = Pk=t-w+ι Tk/w, i.e., whether the average target distributions over the
previous w steps is shifted compared to S. For a fixed step t, this problem is a two-sample hypothesis
test (Lehmann & Romano, 2006), where the null hypothesis is Ho : S = TW,t, and the alternative
hypothesis is H1 : S 6= Tw,t . That is, a two-sample test f is designed to compute
f(Sw,t,Tw,t) ≈ {0
if S = Tw,t
otherwise.
Our goal is to design a two-sample test f for detecting covariate shift with this data stream. While
we can in principle use any two-sample test, our goal is to design one that is both sample and
computationally efficient while achieving high accuracy for high-dimensional data such as images.
In addition, we want the test f to come with finite sample guarantees on the false positive rate. In
particular, given α ∈ R>o, if S = TW,t, we want to ensure
FSw,t ~sw,Tw,t~Tt-w+Lt
f (Sw,t, Tw,t; α) = 0i ≥ 1 - α∙
Ideally, we also want to provide finite sample bounds on the false negative rate; however, for clas-
sifier tests, we can only do so under additional assumptions about the model family used to try and
distinguish S and TW,t. Intuitively, we assume that (i) the model family has bounded complexity
(e.g., Rademacher complexity), and (ii) some model exists in the family that achieves nontrivial
accuracy at distinguishing S and TW,t. Then, our goal is to ensure that if S = TW,t, we have
IPSw"〜Sw,Tw,t〜Tt-w + i：t [/(Sw,t,Tw,t; α) = 1] ≥ 1 - M(α,w)
for some function M(α, w) that depends on the model family.
3.2	Algorithm Overview
Next, we describe our two-sample test. We build on classifier two-sample test (C2ST) (Lopez-Paz
& Oquab, 2017; Kim et al., 2021). The idea is to train a classifier gt to try and distinguish Sw,t
3
Under review as a conference paper at ICLR 2022
Algorithm 1 Sequential Calibrated Classifier Two-Sample Test
1:	Input: significance level α, window size w
2:	for each time step t do
3:	Draw examples Xt 〜S,x[〜Tt
4:	Predict yt = gt(xt) and y0 = gt(xt)	(.) Source-target prediction
5:	Detect covariate shift if 0.5 ∈ θCP(2wμw,t, 2w; α) (.) Calibrated covariate shift detection
6:	Update gt using (χt, 0) and (x；, 1)	(.) Online source-target classifier update
7:	end for
from Tw,t. Intuitively, if S and 兀,；are different distributions, then gt should achieve nontrivial
accuracy at distinguishing Sw,t from Tw,t (assuming the model family is sufficiently expressive).
Alternatively, if S = z7W,t, then g； necessarily achieves a trivial expected accuracy of 1/2.
In particular, the accuracy of gt can be used as a test statistic for the two-sample test. To choose
the cutoff for rejecting the null hypothesis, we use the Clopper-Pearson (CP) interval (Clopper &
Pearson, 1934) to construct an interval that contains the true accuracy gt with high probability based
on the accuracy of gt on a test set. More precisely, the CP interval is an exact confidence interval
around the empirical estimate of the mean of a Bernoulli random variable. Letting zι,…，zn 〜
BernOUlli(μ*) be i.i.d. samples from a Bernoulli distribution with true mean μ*, the (unnormalized)
estimate of its mean n ∙ μ(z±n) = PZi Zi has distribution Binomial(n, μ*). Then, the CP interval
Θcp(s, n; α) ⊆ [0,1] is an interval around μ containing μ* with probability at least 1 - α, i.e.,
Fs〜BinOmial(n,μ* ) [μ ∈ θCP(s, n; α)] ≥ 1 - α,	(I)
where the probability is taken over s, α is a given confidence level, and ΘCP is a function of the
Binomial random variable S = n ∙ μ(zin). The CP interval is concretely defined by
θcp(s,n; α):= [inf {θ ∣ F(n - s; n, 1 - θ) ≥ 2} , sup {θ ∣ F(s； n, θ) ≥ 2}],
where F(s; n, θ) is the cumulative distribution function (CDF) of Binomial(n, θ). To compute the
CP interval, we can use the following equivalent formula:
ΘCP(s, n;
α) = [Q (2；s, n - S + 1), q (1 -
2； s + 1,n - s)]
where Q(p, a, b) is the pth quantile of a Beta distribution with parameters a, b (Hartley & Fitch,
1951; Brown et al., 2001). Our algorithm uses the CP interval to determine whether the accuracy of
gt is nontrivial, i.e., > 1/2. In particular, the accuracy of gt is the mean of the Bernoulli random
variable l(gt(x) = y), where y is the ground truth indicating whether X is from S or TW,t. Then,
our algorithm rejects if the CP interval does not contain 1/2, since this condition implies that the
accuracy of gt does not equal 1/2 with high probability. We describe this step in detail below.
The key challenge is what data to use as the test dataset to estimate the accuracy of gt. The traditional
strategy is to split the available data into two parts: one to train gt and a second held-out test set to
estimate its accuracy (Lopez-Paz & Oquab, 2017; Kim et al., 2021). However, this approach reduces
sample efficiency, which is problematic in our setting since we often want to w to be small.
To address this challenge, our algorithm exploits the conditional independence structure of classifier
predictions. In particular, as described below, our algorithm uses each example Xt to evaluate the
accuracy of gt before using it to train gt. In the next section, we prove that this strategy maintains
the independence of our estimate of the accuracy of gt (Lemma 1), and that as a consequence, our
algorithm satisfies the desired false positive rate (for a single step t).
3.3	Algorithm Details
Sequential detection algorithm. At each time step t, we observe a source sample Xt 〜S and a
target sample Xt 〜Tt. By using these current samples and previous samples, we detect covariate
shifts by updating the source-target classifier in online learning. In particular, our algorithm consists
of three steps: (1) source-target prediction, (2) covariate shift detection, and (3) online source-target
classifier update. The following and Algorithm 1 include details.
4
Under review as a conference paper at ICLR 2022
Step 1. Source-target prediction. We predict source-target labels on the current samples xt and x0t
using the current source-target classifier gt. In particular, we denote prediction on the source sample
Xt by yt, i.e., yt = gt(xt), and denote prediction on the target sample xt by y0, i.e., y0 = ^t(χt).
These predictions and previous predictions are used in covariate shift detection in the following step.
Step 2. Calibrated covariate shift detection. Let Qw,t be a distribution over X × {0, 1}, where
Qw,t(χ,y)=2 ∙ S(χ) ∙ l(y = 0) + 1 ∙九,t(χ) ∙ l(y = 1).
Then, Z = l(^t(x) = y) is a Bernoulli random variable with distribution Bernoulli(μW,t), where
μw,t = P(χ,y)〜Qw,t [gt(x) = y]
is the accuracy of g at distinguishing whether an example X is from distribution S or 兀,t. The
unbiased empirical estimate of this accuracy is denoted by
1t
μw,t = ʒ- E (1 (yi = yi) + 1 (yi = y0)).
2w
i=t-w+1
In fact, 2w^w,t is a Binomial random variable with Binomial(2w, μW J; thus, the accuracy μW t can
be estimated by the Clopper-Pearson (CP) interval ΘoP(2wμw,t, 2w; α) that includes the unknown
parameter μW,t with high probability, i.e.,
IP [μ* ∈ θCP(2wμw,t, 2w; α)] ≥ 1 — α.
This property can be used for checking the accuracy of ^t might be 1/2. In particular, our algorithm
returns “covariate shift” if 1/2 ∈ θCP(2wμw,t, 2w; α), and “no covariate shift” otherwise, i.e.
f (Sw,t, Tw,t; α) = ɪ (2 ∈ θCP (2w ∙ μw,t, 2w; α)).
Here, the Clopper-Pearson interval calibrates the empirical accuracy μw,t using the property of the
Binomial distribution.
Step 3. Online source-target classifier update. Finally, We update a binary classifier gt using new
training examples based on the source and target samples, i.e., (xt, 0) and (Xt, 1). In general, ^ can
be any model; we consider it to be a neural network, in which case we can update its parameters
using stochastic gradient descent with respect to the cross entropy loss.
4 Theoretical Guarantees
In this section, we describe our finite sample bounds on the false positive and false negative rates of
our covariate shift detector f ; the key to have valid bounds is proving the independence on predic-
tions yι,...,yt (and y1 ,...,y0) to have a valid Clopper-Pearson interval, since they are seemingly
dependent through the online learned classifier gt. First, our key result shows that our estimate
of the accuracy of gt is valid——i.e., the predictions yi,... ,yj are conditionally independent (see
Appendix A.1 for a proof), thus the accuracy is the parameter of the Binomial distribution:
Lemma 1. If Xi,...,Xj are independent for any i,j ∈ N where i < j, yi ,...,yj are conditionally
independent given gi,..., gj-ι.
Our next result says that our algorithm ensures the desired bound α on the false positive rate (i.e., f
says “covariate shift” when there is no covariate shift). To this end, we exploit the following obser-
vation that any source-target classifier makes the expected accuracy of 1/2 if there is no covariate
shift. Intuitively, if S =兀,t, source-target classification is impossible (Lopez-Paz & Oquab, 2017;
Liu et al., 2020); we include this lemma for completeness (see Appendix A.2 for a proof):
Lemma 2. If S =兀,t, we have μW,t = 1/2 for any source-target CIaSSfier gt.
Since the expected accuracy of gt is 1/2 regardless of how we design and learn gt, and how many
samples are used to learn gt, the Clopper-Pearson interval includes the true accuracy with high prob-
ability; thus the false positive rate of the proposed covariate shift detector f is effectively controlled
by the confidence level of the Clopper-Pearson interval, as follows (see Appendix A.3 for a proof):
5
Under review as a conference paper at ICLR 2022
Theorem 3 (Bound on false positive rate). If S =兀,t, thenfor any gt, we have
F(Sw,t,Tw,t)〜Sw ×Tt-w+1：t f((Sw,t, Tw,t; α) = 0 ≥ 1 - α∙
(2)
Our next result provides a bound on the false negative rate; we first observe that the Clopper-Pearson
interval is included in the interval by the Hoeffding’s bound. Intuitively, the Clopper-Pearson interval
represents a lower and upper bound of the expected accuracy given an empirical accuracy tailored
to a Bernoulli random variable; the Hoeffding’s bound can similarly bound the mean but in a more
general setup. Thus, the Clopper-Pearson interval can be smaller (see Appendix A.4 for a proof).
Lemma 4. Let S 〜BinOmial(n,p) and F (s; n,p) is the CDF of Binomial (n, p); we have
S—ʌ/ɪnl ≤ inf nθ IF In -S； n,1-θ) ≥ 2 o and sup nθ ∣F ⑶ n,θ) ≥ 2 o ≤S+ʌ/ɪnl
Leveraging this, we have the following bound on false negative rate (see Appendix A.5 for a proof).
Theorem 5 (Bound on false negative rate). Assume gt achieves nontrivial accuracy, i.e., μW,t ≥
1/2 + e, where e ∈ (0,1/2], is the accuracy at distinguishing S and TW,t. Let α(w, α) := 2w(1∕2 +
,log(2/a)/4w) and b(w, α) := 2w(1∕2 —，log(2/a)/4w). If S = TW,t and W — 1 — [，W log(2∕α)C ≥
0, then we have
IP [/(Sw,t,TW,t; α) = l] ≥ F(2w — [a(w, α) + 11;2w, 1 — e) +F (「b(w,a) — 1];2w, 1). (3)
In the false negative bound, the first term is dominant and increases as w increases, which implies the
sample size needs to be increased to have a powerful shift detector; the condition on w suggests that
the bound is valid when W ≥ 201 given α = 0.01. We note that the assumption L(gt) ：= 1 一 μ* ≤
1/2 — e can be achieved under standard conditions. For instance, assume that the model family G
of source-target classifiers has finite VC dimension (i.e., VC(G) < ∞), and that the optimal model
g* ∈ G has nontrivial inaccuracy L(g*) = 1/2 — ξ for some ξ ∈ R>o; then, with probability at least
1 — δ with respect to Sw,t and Tw,t and letting m = 2w, we have
L(^t) ≤ L(g*)+4 JVC(G)(Iog(2m) + 1)+;⅞≡
mm
≤ 1 — ξ — 4, ∕VC(G )(log(2m) + 1) — ∕l°g(W∖
2	m	m,
'------------------------{z-----------------------}
=:
where the second term (which we have taken to be e) satisfies e > 0 for sufficiently large m.
5	Experiments
We evaluate the effectiveness of our algorithm at detecting both natural and synthetic covariate shifts
of varying forms (e.g., gradual shifts and multiple shifts back and forth), showing that it significantly
outperforms natural baselines.
5.1	Experiment Setup
Baselines. We compare our algorithm to three baselines: two of them differ in the way they use the
samples at each time step, the third uses Wald’s sequential likelihood test (Wald, 1945). For the first
two baselines, while our approach uses all samples to construct the CP interval around the accuracy
of the source-target classifier ^t as well as to train g" the baseline instead constructs a held-out test
set using every Hth sample. Then, only this held-out test set is used to compute the CP interval, and
only the remaining samples are used to train ^t. In our experiments, We used values of H ∈ {2,5},
denoted H2, H5, respectively. For Wald’s test, we consider the Bernoulli random variable with a
probability p indicating whether the prediction of the source-target classifier is correct for the given
6
Under review as a conference paper at ICLR 2022
Table 1: Scenario description for experiments. (a) “M-shift” is Multiple shift, (b) “GI-shift” is
gradually increasing shift, and (c) “GID-shift” is gradually increasing-then-decreasing shift.
(a) M-shift			(b) GI-shift			(c) GID-shift		
Start position	Description	Prob.	Start position	Description	Prob.	Start position	Description	Prob.
0%	No shift	0.0	0%	No shift	0.0	0	No shift	0.0
25%			20%	Shift	0.2	20%	Shift	0.4
	Shift	1.0	40%	Shift	0.4	40%	Shift	0.8
50%	No shift	0.0	60%	Shift	0.6	60%	Shift	0.4
75%	Shift	1.0	80%	Shift	0.8	80%	No shift	0.0
sample. The hypothesis test is H0 : p = 0.5 vs. H1 : p = 0.5+, where = 0.2 in our experiments;
we restart the test each time it makes a decision.
This baseline is essentially the online version of an existing classifier two-sample test (C2ST) (Kim
et al., 2021; Lopez-Paz & Oquab, 2017), which splits the (fixed) training dataset into a training set to
train gt and a held-out test set to estimate the accuracy of gt； thus, H controls the tradeoff between
the number of examples in the training set and held-out test set.
Source-target classifier. We use a fully-connected neural network with a single hidden layer (with
128 hidden units) and with the ReLU activation functions as the source-target classifier gt. We use
a binary cross-entropy loss for training in conjunction with an SGD optimizer with a learning rate
of 0.01 (for natural shift experiments) and 0.001 (for synthetic shift experiments). Finally, since the
inputs are ImageNet images (Russakovsky et al., 2015), we use a 2048-dimensional feature vector
generated by first running a pretrained ResNet152 model (He et al., 2016) on the images, and then
using these features vectors for the covariates of Sw,t and Tw,t.
Scenarios. We run each algorithm to test whether the target distribution in the given window is
shifted with three different scenarios: multiple shift (“M-shift”), gradually increasing shift (“GI-
shift”), and gradually increasing-then-decreasing shift (“GID-shift”). Table 1 describes each sce-
nario. For example, the multiple shift scenario proceeds as follows: (i) it starts with no covariate
shift at the beginning; (ii) after observing 25% target samples (i.e., 250th samples for natural shift
experiments and 2500th samples for synthetic shift experiments), covariate shift is applied to all tar-
get samples (with probability 1) by adding random perturbations for synthetic shift and by drawing
samples from a target distribution for natural shift; (iii) after 50% of target samples, it reverts to
no covariate shift; and (iv) finally after observing 75% target samples, the covariate shift is applied
to the all target samples. Gradually increasing shift and gradually increasing-then-decreasing shift
scenarios start with no covariate shift for the first 20% of target samples; then, covariate shift is
applied with some probability 0 < p < 1 by gradually changing p over time.
Stream data generation. For each shift (i.e., natural shift and synthetic shift), we have a source
dataset S and target datasets Tt, from which we randomly draw source and target samples for each
time step t. In particular, we consider a batch of samples for computational efficiency, where we
denote the batch size by B; we use B = 10 for our experiments. That is, we wait for B samples to be
collected from the target distribution before checking for covariate shift and the updating the source-
target classifier; then, we begin collecting the next batch. Finally, we evaluate each approach using
multiple random repetitions, which we denote by R (the value of R depends on each experiment).
5.2	Natural shift
Dataset. First, we consider a natural shift on ImageNet. To construct such a shift, we consider the
subset of dog classes; in particular, 120 of the 1000 of the ImageNet classes are of dogs (Khosla
et al., 2011). Then, we randomly select half (i.e., 60) of these classes to be the source dataset, and
the other half to be the target dataset; thus, the number of source and target images is 2997 each
(after removing duplicated images). As a consequence, the source and target datasets correspond to
different dog breeds, which is a kind of natural distribution shift.
Results. Figure 1 and Table 2 show results for the natural shift experiment with w = 10 and
α = 1%. Figure 1 illustrates detection rates of the four algorithms with R = 100 repetitions (i.e.,
the fraction of repetitions that reported “covariate shift” at each step). Table 2a shows the number
7
Under review as a conference paper at ICLR 2022
(％) UOWladaJ.IQAO φlec≤UO-tjələɑ
(a) M-shift	(b) GI-shift	(c) GID-shift
Figure 1: Detection rate for natural shift with R = 100, w = 10, α = 1%. The black dashed line
indicates shifted sample ratio, i.e., the degree (or probability) of covariate shift.
Table 2: Natural shift results with (a) w = 10, α = 1%, and R = 100, and (b) R = 20000 . In (a),
we bold the best algorithm. In (b), we bold values that exceed the desired α = 1%.
(a) Number of samples for detection (≥ 80%)			(b) FPR (%) at selected time		
Scenario Algorithm Natural shift			Scenario Algorithm		50 100 150 200
	Ours	190		Ours	0.27 0.53 0.73 0.77
M-shift	H2	720	M-shift	H2	0.29 0.28 0.26 0.33
	H5	-		H5	0.34 0.52 0.51 0.56
	Wald	640		Wald	0.60 0.47 0.27 0.27
	Ours	620		Ours	0.21 0.60 0.76 0.83
GI-shift	H2	-	GI-shift	H2	0.21 0.25 0.29 0.36
	H5	-		H5	0.32 0.43 0.50 0.85
	Wald	-		Wald	0.78 0.57 0.29 0.22
	Ours	310		Ours	0.30 0.53 0.70 0.95
GID-shift	H2	-	GID-shift	H2	0.18 0.21 0.28 0.41
	H5	-		H5	0.36 0.56 0.53 0.81
	Wald	-		Wald	0.77 0.58 0.34 0.23
of shifted samples required to reach at least 80% of covariate shift detection rate under the shift.
Table 2b shows false positive rate (FPR) after 50, 100, 150, and 200 samples with R = 20000
repetitions.
Discussion. Figure 1 shows the detection rate of each algorithm as each scenario progresses. In
multiple shift (Figure 1a) and gradually increasing-then-decreasing shift (Figure 1c), covariate shift
disappears after a certain point, and all algorithms correctly detect this change. However, as shown
in Table 2a, our approach always requires fewer samples to detect the shift. While H5 does not
achieve 80% detection and H2 and Wald reach 80% only for multiple shift change scenario, our
approach always detects covariate shift at a rate higher than 80%. Furthermore, for multiple shift,
our algorithm requires fewer than half the number of samples compared to H2. In summary, our al-
gorithm is significantly more sample efficient at detecting covariate shift compared to the baselines,
most likely since it utilizes all samples for both training the source-target classifier and constructing
the CP interval. For FPR, all algorithms always satisfy the FPR bound (i.e., FPR ≤ α).
5.3	S ynthetic S hift
Dataset. Next, we consider a synthetic shift on ImageNet. In particular, we split the original Im-
ageNet validation set into equal sized source and target datasets. To construct the target dataset,
we add synthetic perturbations on original images. We (separately) consider five perturbation types
from (Hendrycks & Dietterich, 2019)—in particular, Contrast, Defocus Blur, Elastic Transform,
Gaussian Blur, and Gaussian Noise, with five different severity levels.
Results. The experiment results are shown in Figure 2 and Table 3 for the experiments with the
perturbation severity of 2, window size w = 10, and significance level α = 1%. Table 3a shows the
number of target samples required by each algorithm to detect the first covariate shift in the detection
rate of at least 80%. Table 3b shows the false positive rate (FPR) after 500, 1000, 1500 and 2000
samples for each of the three scenarios. Figure 2 shows the detection rates over multiple repetitions
8
Under review as a conference paper at ICLR 2022
(％) UOWladaJ.IQAO φlec≤UO-tjələɑ
Number of samples
(a) M-shift
Figure 2: Detection rate for synthetic shifts with Gaussian noise perturbation, Severity = 2, R =
100, w = 10, α = 1%. The black dashed line indicates shifted sample ratio, i.e., the degree (or
probability) of covariate shift. The red dotted line shows the accuracy of ResNet152 on the source
and target samples in the given window.
Table 3: Synthetic shift results with (a) Severity = 2, w = 10, α = 1%, and R = 100, and (b)
R = 20000. In (a), we bold the best algorithm. In (b), we bold values that exceed the desired
α = 1%.
(a) Number of samples for detection
			Defocus	Elastic	Gaussian	Gaussian
Scenario	Alg.	Contrast	Blur	Transform	Blur	Noise
	Ours	230	200	220	210	180
aæ CITift∙ M-shift	H2	470	450	450	490	350
	H5	410	410	410	460	310
	Wald	-	-	-	-	-
	Ours	2100	2060	2090	2070	2080
CT C hi ft	H2	4050	3690	4050	4010	3670
GI-shift	H5	4360	4110	6010	4110	4110
	Wald	-	-	-	-	-
	Ours	880	560	900	720	610
GID-shift	H2	2030	2010	2050	2010	2010
	H5	2060	2060	2060	2060	2060
	Wald	-	-	-	-	-
(b) FPR (%) at selected time
Scenario	Alg.	500	1000	1500	2000
	Ours	0.73	1.00	0.90	1.00
M-shift	H2	0.40	0.46	0.46	0.50
	H5	0.80	0.73	0.84	0.69
	Wald	0.07	0.11	0.04	0.01
	Ours	0.86	0.89	0.92	0.85
GI-shift	H2	0.62	0.54	0.60	0.50
	H5	0.74	0.71	0.77	0.73
	Wald	0.10	0.13	0.07	0.03
	Ours	0.87	0.95	0.92	0.89
GID-shift	H2	0.51	0.57	0.51	0.53
	H5	0.73	0.75	0.85	0.89
	Wald	0.09	0.08	0.04	0.02
for each of the three scenarios using the Gaussian noise perturbation. Results for other perturbation
types and severities are shown in Appendix D.
Discussion. As can be seen, our approach outperforms the baselines in terms of sample efficiency
for the covariate shift detection as was the case of the natural shift. Our algorithm requires about
half as many samples before detecting covariate shift compared to the baselines. In terms of FPR,
our approach always satisfies the FPR bound. Finally, Figure 2 shows the accuracy drop with the
shifted samples. In particular, the red dotted line shows the accuracy of ResNet152 on the examples
in the source and target samples of the given window; as can be seen, the accuracy decreases as the
degree of the shift increases. Covariate shift detection can be successfully used to notify a user that
an accuracy drop may have occurred.
6	Conclusion
We have proposed a novel covariate shift detection algorithm, which uses a classifier two-sample test
to check whether the current test examples differ in distribution compared to the training examples.
Our approach ensures sample efficiency by avoiding the need to split the dataset into a training set
and a held-out test set, and instead using all the data to both train the source-target discriminator
and to evaluate its accuracy. We prove that even with this optimization, our approach provides finite
sample guarantees on the false positive rate at a desired level; we also prove bounds on the false
negative rate under a mild conditions on the trained classifier. Finally, we empirically demonstrate
that our proposed algorithm is significantly more sample efficient compared to a natural baseline
that uses a held-out test set in terms of detecting both natural and synthetic shifts on ImageNet.
9
Under review as a conference paper at ICLR 2022
Reproducibility Statement. For our empirical results, we stated our algorithm in Algorithm 1,
hyperparameters in Section 5.1, and dataset setups in Section 5.2 and 5.3. We have included the
source code in the supplement for reproducing the experimental results. For our theory, we have
included all proofs in Appendix A.
References
Akshay Balsubramani and Aaditya Ramdas. Sequential nonparametric testing with the law of the
iterated logarithm. arXiv preprint arXiv:1506.03486, 2015.
Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations
for domain adaptation. In Advances in neural information processing systems, pp. 137-144, 2007.
Steffen Bickel, Michael Bruckner, and Tobias Scheffer. Discriminative learning for differing training
and test distributions. In Proceedings of the 24th international conference on Machine learning,
pp. 81-88. ACM, 2007.
Christopher M Bishop. Pattern recognition and machine learning. Springer, 2006.
Lawrence D Brown, T Tony Cai, and Anirban DasGupta. Interval estimation for a binomial propor-
tion. Statistical science, pp. 101-117, 2001.
Xiuyuan Cheng and Alexander Cloninger. Classification logit two-sample testing by neural net-
works. arXiv preprint arXiv:1909.11298, 2019.
Kacper Chwialkowski, Aaditya Ramdas, Dino Sejdinovic, and Arthur Gretton. Fast two-sample
testing with analytic representations of probability measures. arXiv preprint arXiv:1506.04725,
2015.
Charles J Clopper and Egon S Pearson. The use of confidence or fiducial limits illustrated in the
case of the binomial. Biometrika, 26(4):404-413, 1934.
Jerome Friedman. On multivariate goodness-of-fit and two-sample testing. Technical report, Cite-
seer, 2004.
Joao Gama, Indre Zliobaite, Albert Bifet, Mykola Pechenizkiy, and Abdelhamid BoUChachia. A
survey on concept drift adaptation. ACM computing surveys (CSUR), 46(4):1-37, 2014.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Francois
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural net-
works. Journal of Machine Learning Research, 17(59):1-35, 2016. URL http://jmlr.org/
papers/v17/15-239.html.
Paulo M Goncalves Jr, Silas GT de Carvalho Santos, Roberto SM Barros, and Davi CL Vieira. A
comparative study on concept drift detectors. Expert Systems with Applications, 41(18):8144-
8156, 2014.
Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Scholkopf, and Alexander Smola.
A kernel two-sample test. The Journal of Machine Learning Research, 13(1):723-773, 2012a.
Arthur Gretton, Dino Sejdinovic, Heiko Strathmann, Sivaraman Balakrishnan, Massimiliano Pontil,
Kenji Fukumizu, and Bharath K Sriperumbudur. Optimal kernel choice for large-scale two-sample
tests. In Advances in neural information processing systems, pp. 1205-1213. Citeseer, 2012b.
HO Hartley and ER Fitch. A chart for the incomplete beta-function and the cumulative binomial
distribution. Biometrika, 38(3/4):423-426, 1951.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common cor-
ruptions and perturbations. Proceedings of the International Conference on Learning Represen-
tations, 2019.
10
Under review as a conference paper at ICLR 2022
WittaWat Jitkrittum, Zoltan Szabo, Kacper Chwialkowski, and Arthur Gretton. Interpretable distri-
bution features with maximum testing power. arXiv preprint arXiv:1605.06796, 2016.
Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Li Fei-Fei. Novel dataset for fine-
grained image categorization. In First Workshop on Fine-Grained Visual Categorization, IEEE
Conference on Computer Vision and Pattern Recognition, Colorado Springs, CO, June 2011.
Ilmun Kim, Aaditya Ramdas, Aarti Singh, and Larry Wasserman. Classification accuracy as a proxy
for two-sample testing. The Annals ofStatistics, 49(1):411-434, 2021.
Erich L Lehmann and Joseph P Romano. Testing statistical hypotheses. Springer Science & Business
Media, 2006.
Alix Lheritier and Frederic Cazals. A sequential non-parametric multivariate two-sample test. IEEE
Transactions on Information Theory, 64(5):3361-3370, 2018.
Alix Lheritier and Frederic Cazals. Low-complexity nonparametric bayesian online prediction with
universal guarantees. Advances in Neural Information Processing Systems, 32:14581-14590,
2019.
Feng Liu, Wenkai Xu, Jie Lu, Guangquan Zhang, Arthur Gretton, and Dougal J Sutherland. Learn-
ing deep kernels for non-parametric two-sample tests. In International Conference on Machine
Learning, pp. 6316-6326. PMLR, 2020.
David Lopez-Paz and Maxime Oquab. Revisiting classifier two-sample tests. In International Con-
ference on Learning Representations, 2017.
Tudor Manole and Aaditya Ramdas. Sequential estimation of convex divergences using reverse
submartingales and exchangeable filtrations. arXiv preprint arXiv:2103.09267, 2021.
Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua V
Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model’s uncertainty?
evaluating predictive uncertainty under dataset shift. arXiv preprint arXiv:1906.02530, 2019.
Sangdon Park, Osbert Bastani, James Weimer, and Insup Lee. Calibrated prediction with covariate
shift via unsupervised domain adaptation. In International Conference on Artificial Intelligence
and Statistics, pp. 3219-3229. PMLR, 2020.
Stephan Rabanser, Stephan Gunnemann, and Zachary C Lipton. Failing loudly: An empirical study
of methods for detecting dataset shift. arXiv preprint arXiv:1810.11953, 2018.
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng
Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual
recognition challenge. International journal of computer vision, 115(3):211-252, 2015.
Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-
likelihood function. Journal of statistical planning and inference, 90(2):227-244, 2000.
Masashi Sugiyama and Klaus-Robert Muller. Input-dependent estimation of generalization error
under covariate shift. 2005.
Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert Muller. Covariate shift adaptation by
importance weighted cross validation. Journal of Machine Learning Research, 8(5), 2007.
Vladimir Vapnik. Statistical learning theory. Wiley, 1998. ISBN 978-0-471-03003-4.
Abraham Wald. Sequential tests of statistical hypotheses. The annals of mathematical statistics, 16
(2):117-186, 1945.
11
Under review as a conference paper at ICLR 2022
A Proofs
A.1 Proof of Lemma 1
Figure 3: The dependency structure of random variables.
Figure 3 represents the graphical model over random variables, where observed random variables
are colored in gray. We prove the conditional independence using the d-separation (also called the
Bayes ball algorithm) (Bishop, 2006), which is a set of rules that can determine the conditional
dependency between two random variables based on the graphical model and observed random
variables. In particular, y%+2 is conditionally independent to yk for all k ≤ i + 1 since the path to yk
is blocked by gi+ι (i.e., gi+ι is observed). Similarly, yi+2 is conditionally independent to yk for all
k ≥ i + 3. This proves the claim. 口
A.2 Proof of Lemma 2
For any source-target classifier gt, if S = Tw,t, the following holds:
μW,t = F(X,y)~Qw,t [gt(X) = y]
=	ER (gt(χ) = y) Qw,t(χ, y)dχ
y∈{0,1}
=∣ X 1 (gt(X) = y) (1 ∙S(X) ∙ i(y = 0) + 1 •兀,t(X) ∙ i(y = 1)) dχ
y∈{0,1}	2	2
=1 / X 1 (Jt(X) = y)S(X)I(y = 0)+ X 1 (gt(X) = y) TW,t(x)i(y = 1)dx
y∈{0,1}	y∈{0,1}
2/
2 Z
2 Z
2 Z
1
2,
1 (gt(x)= 0) S(x) + 1 (^t(x) = 1)兀,t(x)dx
1 (gt(x) = 0) S(x) + 1 (^t(x) = 1) S(x)dx
(1 (gt(x) = 0) + 1 (^t(χ) = 1)) S (χ)dχ
S (x)dx
where the sixth equality holds since S = Tw,t; the claim follows. 口
12
Under review as a conference paper at ICLR 2022
A.3 Proof of Theorem 3
Denote the event that F(x,y)〜Qw t [gt(x) = y] = 1/2 by E, and let Sw,t = 2w^w,t. Then, We have
IPSw,t,Tw,t 0(Sw,t,Tw,t; α)=0
2 ∈ θcp(sw,t, 2w; α)) ∧ flPχ,y [^t(x) = y] = 2
FSw,t,τw,t [E] FSw,t,τw,t 2 ∈ θcp(Sw,t, 2w;α) E
FSw,t,τw,t 2 ∈ θcp(Sw,t, 2w;α) E
≥ 1 - α,
where the first equality holds since S = Tw,t and by Lemma 2, the third equality holds by Lemma
2, and the last inequality holds by the property of the Clopper-Pearson interval and Lemma 1.	□
A.4 Proof of Lemma 4
We use the tail bound of the binomial distribution using the Hoeffding’s inequality—i.e.
F(s; n,p) ≤ exp { — 2n (P — S)
For the upper bound of the upper Clopper-Pearson interval, we have
sup{θ I F(s; n,θ) ≥ 2 O ≤ sup
sup
n+vln2
(4)
For the lower bound of the lower Clopper-Pearson interval, we have
inf nθ II F(n — S; n, 1 — θ)
(5)
Finally, (4) and (5) imply the claim. □
A.5 Proof of Theorem 5
Let the lower and upper bound of the Clopper-Pearson interval Θcp be Θcp and Θcp, respectively.
Recall that we denote the CDF of a binomial distribution binomial(n, p) by F(S; n, p). Then, we
13
Under review as a conference paper at ICLR 2022
have
Psw",TwJ∕(Sw,t,Tw,t; α) = 1]
FSwMTw,t 2 ∈ θCP(2wμW,t, 2w; a)
S^S-yj ^wTuj^t
FSw,t ,Tw,t
FSw,t ,Tw,t
μW,t < 2 + e V μW,t ≥ 2 + e)八
*
μw,t
*
μw,t
2 ∈ θCP(2wμW,t, 2w;a)
≥ I + e)八 £ ∈ θCP(2wμW,t, 2w； a)
Sw ,t ,Tw ,t
1 ∈ θCP(2wμW,t, 2w; a)
2 ∈ θCP(2wμW,t, 2w;a) μ
'W ≥ 2 + e
θCP(2wμW,t, 2w;句 > 1 V θCP(2wμW,t, 2w; a) <
θCP(2wμW,t, 2w;α) > 2 I μW,t ≥ J + e
+ FSw,t,τw,t θCP(2wμW,t, 2w;α) < 2
(6)
*
μw,t
*
μw,t
*1
μW,t ≥ 2 + e
where ⑹ and ⑺ hold due to FSw,t,τw,t [μW,t < 1∕2 + e]=。and FSw,t,τw,t [μW,t ≥ 1∕2 + e] = 1
from the assumption on gt and S = T, respectively.
By Lemma 4, the first term is lower bounded as follows:
FSw,t,τw,t θCP(2wμW,t, 2w; a) > 2	μW,t ≥
*1
μW,t ≥ 2 + e
FSw,t,τw,t 2wμW,t > a(w, α) μW,t ≥ 2 + e
FSw,t,τw,t 2w^W,t ≥ [a(w,α) + 1J	μW,t ≥ 2 + e
≥F ( 2w — [α(w, α) + 1_|; 2w, ɪ — e
(8)
where the last inequality holds since the binomial parameter 1 — e makes the CDF F smallest.
Similarly, the second term is lower bounded as follows:
pSw,t,τw,t θCP(2wμW,t, 2w;α) < 1	4
，W,t ≥
≥ FSw,t,τw,t
*
MW,t
FSw,t,Tw,t
FSw,t,Tw,t
2w^W,t < b(w,α)
*
MW,t
2w^W,t ≤ db(w, α) — 1] μ
C,t ≥ 2 + e
≥ ∣ + e F
≥
1
——+ e
2
^S-uτwT-,jjit
S^S-yj ^wTuj^t
1
1
2
1
≥ 2 + e
⑺
1
2 + e
1
——+ e
2
∕ln2	1
"w"+d 常 < 2
1
≥ 2 + e
1
≥ 2 + e
≥F (db(w,α) — 1];2w, 1),
(9)
where the last inequality holds since the binomial parameter μWt = 1 makes the CDF F smallest.
The claim follows by combining (8) and (9).	□
14
Under review as a conference paper at ICLR 2022
(％) UOWladaJ.IQAO φlec≤UO-tjələɑ
(a) M-shift
(c) GID-shift
(b) GI-shift
Figure 4: Detection rate for natural shift with R = 100, w = 10, α = 1%. Deep Kernel result is
included. The black dashed line indicates shifted sample ratio, i.e., the degree (or probability) of
covariate shift.
Table 4: Natural shift results with (a) w = 10, α = 1%, and R = 100, and (b) R = 20000 . In (a),
we bold the best algorithm. In (b), we bold values that exceed the desired α = 1%.
(a) Number of samples for detection (≥ 80%)			(b) FPR (%) at selected time		
Scenario Algorithm Natural shift			Scenario Algorithm		50 100 150 200
	Ours	190		Ours	0.27 0.53 0.73 0.77
	H2	720		H2	0.29 0.28 0.26 0.33
M-shift	H5	-	M-shift	H5	0.34 0.52 0.51 0.56
	Wald	640		Wald	0.60 0.47 0.27 0.27
	DK	180		DK	1.69 2.31 2.16 2.54
	Ours	620		Ours	0.21 0.60 0.76 0.83
	H2	-		H2	0.21 0.25 0.29 0.36
GI-shift	H5	-	GI-shift	H5	0.32 0.43 0.50 0.85
	Wald	-		Wald	0.78 0.57 0.29 0.22
	DK	770		DK	2.11 2.67 2.22 3.29
	Ours	310		Ours	0.30 0.53 0.70 0.95
	H2	-		H2	0.18 0.21 0.28 0.41
GID-shift	H5	-	GID-shift	H5	0.36 0.56 0.53 0.81
	Wald	-		Wald	0.77 0.58 0.34 0.23
	DK	-		DK	1.91 2.67 2.37 3.42
B Additional Baseline
We include one additional baseline, adapted version of Deep Kernel MMD (Liu et al., 2020). This
Deep Kernel (DK) requires training of the kernel parameters and the network for extracting features.
We use half of samples for this training process and conduct a test using the rest of samples as H2.
We run this algorithm for Natural shift as in Section 5.2.
Results. The experimental results with DK are shown in Figure 4, and Table 4. As described in
Section 5.2, Figure 4 shows the detection rates of each algorithms, and Table 4 presents FPR at
selected points. Our approach outperforms this adapted version of Deep kernel MMD approach.
First, in terms of the false positive rate (FPR), DK violates the desired FPR bound, while ours
satisfies the bound (Table 4b). Furthermore, Table 4a shows that our approach generally requires
a smaller number of samples for detection. In the M-shift case, ours needs ten more samples. In
the other two shifts, however, ours shows superior performance compared to DK. In the GI-shift,
our approach requires 150 fewer samples, and in GID-shift, our approach uses 310 samples for the
detection, while DK cannot achieve 80 % detection.
C Additional Discussion
C.1 Multiple Epochs in Training
As shown in Algorithm 1, each example is used only once in updating the source-target classifier,
baselines also follow this setting in all experiments. We consider this single epoch update anticipat-
ing that our algorithms being used in the online setting, where it is infeasible to take multiple passes
15
Under review as a conference paper at ICLR 2022
over the training data. However, without consideration of the online setting, each example can be
used multiple times during training with the restriction that the example can be used only once in
the CP interval, which can improve the performance. As this strategy is orthogonal to our approach,
it can be applied to both ours and other baselines expecting the performance improvement.
D	Additional Experimental Results
D. 1 Detection Rate
This section shows the additional detection rate plots for the different perturbations, severities, and
window sizes (w) including figures in the main paper.
D.1.1 M-shift
Figure 5 - Figure 19 display the detection rate plot for M-shift scenario with different settings. These
all different settings show the similar pattern with the figures in the main paper.
16
Under review as a conference paper at ICLR 2022
Uooooo
U 8 6 4 2
1
(％) uo⅛3θdφ-l」① >。① HEa UO-EIPCJ
(求)AUE-JnyV 7 04E」cυ-dlues P ①：UΞS
(注 >ws⊃y< / 0^2 ①-QLUfσs P 菖 IlS
Oooooo
108 6 4 2
(％) Uo≡⅛dcυ.J」3>0 ①屋 UO-IE ① Q
(兴)>urt3.lrDU</。=ɑ)-duæs PΦ⅛HUS
OOOoo
1 8 6 4 2 0
(a) Severity = 1
(b) Severity = 2
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
4000	6000	8000	10000	0
Number of samples
(c) Severity = 3
2000
Ooowoo
108 6 4 2
(％) UO≡sd ①」」ω>0 3⅛H UOQU①一① Q
(％) Aue-lny∖/ / Ow ①-dlues pφ(tΞs
OOOoo
1 8 6 4 2 0
2000	4000	6000	8000
Number of samples
(d) Severity = 4
(％) uoq-⅛d ①」」əao əjfoee:Uo--dələɑ
(％) >U23UU< 一 04E」①QLues pad=!Ξs
Ooooo
18 6 4 2 0
ιoooo
(e) Severity = 5
Figure 5: Contrast with R = 100, w
10, α = 1%.
17
Under review as a conference paper at ICLR 2022
(a) Severity = 1
4000	6000	8000	10000
Number of samples
(b) Severity = 2
Ooowoo
108 6 4 2
(％) Uo≡sd ①」」ω>0 3⅛H UOQU①一① Q
(％) Aue-lny∖/ / Ow e-dujes pφ(tΞs
OOOoo
1 8 6 4 2 0
(％) >ws⊃y< / O 口 B」①-QUJcσs P ①ctzs
O
OoOoo
1 8 6 4 2 0
0	2000	4000	6000	8000
Number of samples
(c) Severity = 3
0	2000	4000	6000	8000	10000
Number of samples
(d)	Severity = 4
Oooooo
0 8 6 4 2
(％) Uoq-⅛daj」① >0 ①居 Uo-tsələo
(％) >U23UU< 一 O4E」UdLUeS pad=!Ξs
Ooooo
18 6 4 2 0
Number of samples
(e)	Severity = 5
Figure 6: Defocus blur with R = 100, w = 10, α = 1%.
18
Under review as a conference paper at ICLR 2022
Uooooo
U 8 6 4 2
1
(％) uo⅛3θdφ-l」① >。① HEa UO-EIPCJ
Oooooo
108 6 4 2
(％) Uo≡⅛dcυ,J -l0)>o ①色 UO-IE ① Q
(兴)>urt3.lrDU</。=a)-duæs PΦ⅛HUS
OOOoo
1 8 6 4 2 0
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
4000	6000	8000	10000
Number Of samples
(a) Severity = 1
Ooowoo
108 6 4 2
(％) Uo≡sd ①」」ω>0 3⅛H UOQU①一① Q
(％) Aue-lny∖/ / Ow e-dujes pφ(tΞs
OOOoo
1 8 6 4 2 0
O 2000	4000	6000	8000 IOOOO
Number of samples
(c) Severity = 3
(求)AUE-JnyV 7 04E」cυ-dlues P ①：UΞS
(注 >ws⊃y< / 0^2 ①-QLUfσs P 菖 IlS
0	2000	4000	6000	8000
Number of samples
(b) Severity = 2
0	2000	4000	6000	8000
Number of samples
(d) Severity = 4
(％) Uoq-⅛daj .Jα)Λ0 ①居 Uo-tsələo
(％) >U23UU< 一 O4E」①QLues pad=!Ξs
(e) Severity = 5
Figure 7: Elastic transform with R = 100, w = 10, α = 1%.
19
Under review as a conference paper at ICLR 2022
Uooooo
U 8 6 4 2
1
(％) uo⅛3θdφ-l」① >。① HEa UO-EIPCJ
Oooooo
108 6 4 2
(％) Uo≡⅛dcυ.J」3>0 ①屋 UO-IE ① Q
(兴)>urt3.lrDU</。=ɑ)-duæs PΦ⅛HUS
OOOoo
1 8 6 4 2 0
(求)AUE-JnyV 7 04E」cυ-dlues P ①：UΞS
(注 >ws⊃y< / 0^2 ①-QLUfσs P 菖 IlS
(a) Severity = 1
(b) Severity = 2
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
O 2000	4000	6000	8000 IOOOO
Number of samples
Ooowoo
108 6 4 2
(％) UO≡sd ①」」ω>0 3⅛H UOQU①一① Q
(％) Aue-lny∖/ / Ow ①-dlues pφ(tΞs
OOOoo
1 8 6 4 2 0
0	2000	4000	6000	8000
Number of samples
(c) Severity = 3
(d) Severity = 4
(％) Uoq-⅛daj .Jα)ΛO ①居 Uo-tsələo
(％) >U23UU< 一 O4E」①QLues pad=!Ξs
(e) Severity = 5
Figure 8: Gaussian blur with R = 100, w = 10, α = 1%.
20
Under review as a conference paper at ICLR 2022
Uooooo
1U8 6 4 2
(％) Uo≡wdφ-l」3>0 ①色 Uo-IE ① Q
4000	6000	8000	10000
Number of samples
(b) Severity = 2
(％) >ws⊃y< / O 口 B」①-QUJcσs P ①ctzs
O
OoOoo
18 1s 4 2 O
Ooowoo
108 6 4 2
(％) Uo≡sd ①」」ω>0 3⅛H UOQU①一① Q
(％) Aue-lny∖/ / Ow e-dujes pφ(tΞs
OOOoo
1 8 6 4 2 0
urs25-∙-∙
OHH
--
Uooooo
U 8 6 4 2
1
(％) uo⅛3θdφ-l」① >。① HEa UO-EIPCJ
(a) Severity = 1
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
O 2000	4000	6000	8000 IOOOO
Number of samples
(c)	Severity = 3
0	2000	4000	6000	8000	10000
Number of samples
(d)	Severity = 4
(％) Uoq-⅛daj .Jα)Λ0 ①居 Uo-tsələo
(％) >U23UU< 一 O4E」①QLues pad=!Ξs
(e)	Severity = 5
Figure 9: Gaussian noise with R = 100, w = 10, α = 1%.
21
Under review as a conference paper at ICLR 2022
0	2000	4000	6000	8000
Number Of samples
(a) Severity = 1
(兴)AUB-JrDW=B.Jɑ)-duæs pφt!Ξs
OOOoo
1 8 6 4 2 0
0	2000	4000	6000	8000	10000
Number of samples
(b) Severity = 2
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
Ooowoo
108 6 4 2
(％) UO≡sd ①」」ω>0 3⅛H UoQU①一① Q
(％) Aue-In yq / Ow ①-dlues pφ(tΞs
OOOoo
1 8 6 4 2 0
	Ours H2			
aɪɔ忖5 ”不			
			
				,		
			
τ* √⅛⅜A∙W			
(％)
O
10
60
40
20
10000
< / 0≈2ωɑErσs P gzs
(c) Severity = 3
(d) Severity = 4
(％) Uoq-⅛daj .Jα)Λ0 ①居 Uo-tsələo
(％) >U23UU< 一 O4E」①QLues pad=!Ξs
(e) Severity = 5
Figure 10: Contrast with R = 100, w = 20, α = 1%.
22
Under review as a conference paper at ICLR 2022
IOO
80
60
40
20
2000	4000	6000	8000	10000
Number Of samples
(a) Severity = 1
ιoo
εo
60
40
20
2000	4000	6000	8000	10000
Number of samples
(c) Severity = 3
	Ours H2			
ai∙∙∙.片 $..不			
			
			
			
(b) Severity = 2
6000	8000
Number of samples
Ooowoo
108 6 4 2
(％) Uo≡sd ①」」ω>0 3⅛H UOQU①一① Q
(%,) >ue-lny4 一。4①-dines pφ(tΞs
Uooooo
108 6 4 2
(％) Uo⅛⅛dcυ,J .lα)>o ① H UO-IE ① Q
羡)Aue-Jnuuq/.2/」φ-dEBS pφt!Ξs

(求)AUE-JnyV 7 04E」cυ-dlues P ①：UΞS
(注 >ws⊃y< / 0^2 ①-QLUfσs P 菖 IlS
(d) Severity = 4
(％) Uoq-⅛dsj .Ja)Λ0 ①居 Uo-tsələo
1008060
4020
0	2000	4000	6000	8000	10000
Number of samples
(e) Severity = 5
Figure 11: Defocus blur with R = 100, w = 20,
%
1
荣)A5q/三」diE)一示 =
o a
23
Under review as a conference paper at ICLR 2022
OoooOo
108 6 4 2
(％) Uo≡⅛dcυ.J」3>0 ①屋 UO-IE ① Q
(兴)>urt3.lrDU</O =e」ɑ)-duæs PΦ⅛HUS
(％) >up」nuJ</.2le」(υ-dE<σs P ①：uzs
O
Ooooo
18 6 4 2 0
Uooooo
U 8 6 4 2
1
(％) uo⅛3θdφ-l」① >。① n(υα UO-EIPCJ
OOOoo
1 8 6 4 2
(％) Uo≡sd ①」」3>。3⅛H UOQU①一① Q
(％) /Oe-Inyq /。口B」e-dujes pφ(tΞs
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
O 2000	4000	6000	8000 IOOOO
Number of samples
(e) Severity = 5
Figure 12: Elastic transform with R = 100, w
%
1
24
Under review as a conference paper at ICLR 2022
(兴)AUB-JrDW=B.Jɑ)-duæs pφt!Ξs
OOOoo
1 8 6 4 2 0
0	2000	4000	6000	8000
Number Of samples
(a) Severity = 1
0	2000	4000	6000	8000	10000
Number of samples
(b) Severity = 2
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ

Ooowoo
108 6 4 2
(％) UO≡sd ①」」ω>0 3⅛H UoQU①一① Q
(％) Aue-In yq / Ow ①-dlues pφ(tΞs
OOOoo
1 8 6 4 2 0
60
40
20
10000
0	2000	4000	6000	8000
Number of samples
(％)
O
10
< / 0≈2ωɑErσs P gzs
0	2000	4000	6000	8000	10000
Number of samples
(c) Severity = 3
(d) Severity = 4
(％) Uoq-⅛daj .Jα)Λ0 ①居 Uo-tsələo
Ooooo
0 8 6 4 2
--Ours
-H2
atF5
Ooooo
18 6 4 2

(上) Auenuu4 一O1E」①QEES pə:uzs
(e) Severity = 5
Figure 13: Gaussian blur with R = 100, w = 20, α = 1%.
25
Under review as a conference paper at ICLR 2022
(％) AUE-JrmV/.20<υ-dE<σs P ①4=;ΞS
O
Ooooo
18 6 4 2 0
Oooooo
108 6 4 2
(％) Uo⅛⅛dcυ,J .lα)>o ①色 UO-IE ① Q
(兴)AUe-JnUU</。= φ-dujes pφ⅛Hqs
OOOoo
1 8 6 4 2 0
0	2000	4000	6000	8000	10000
Number of samples
(b) Severity = 2
(a) Severity = 1
< / 0≈2ωɑErσs P gzs
	Ours H2			
aɪɔ忖夕"			
			
						
			
			
60
40
20
10000
(％)
O
10
Ooowoo
108 6 4 2
(％) UO≡sd ①」」ω>0 3⅛H UoQU①一① Q
(％) Aue-lny∖/ / Ow ①-dlues pφ(tΞs
OOOoo
1 8 6 4 2 0
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
(d) Severity = 4
(c) Severity = 3
(上) Auenuu4 一O1E」①QEES pə:uzs
Oooooo
0 8 6 4 2
(％) Uoq-⅛daj .Jα)>o ①屋 Uo-tsələo
	Ours H2			
			
			
			
		I Γ⅜	
Ooooo
18 6 4 2
(e) Severity = 5
Figure 14: Gaussian noise with R = 100, w = 20, α = 1%.
26
Under review as a conference paper at ICLR 2022
2000	4000	6000	8000
Number Of samples
(a) Severity = 1
OoooOo
108 6 4 2
(％) Uo≡⅛dcυ,J -l0)>o ①色 UO-IE ① Q
(兴)>urt3.lrDU</。=e-a)-duæs PΦ⅛HUS
OOOoo
1 8 6 4 2 0
(b) Severity = 2
(求)>UΠ3.Jnu∑>v 7 O4E」cυ-dlues P ①：UΞS
(注 >ws⊃y< / 0^2 ①-QLUfσs P 菖 IlS
	Ours I H2 I				
=iiii∙∙甘 5”…；-				
				
				
				
≡j⅛⅛uβ⅛J≡Li				X⅝⅛⅛⅛⅛l,	
4000	6000	8000	10000
Number of samples
Oo
200
(c) Severity = 3
2000	4000	6000	8000
Number of samples
(d) Severity = 4
4000	6000	8000	10000
Number of samples
(e) Severity = 5
Figure 15: Contrast with R = 100, w = 50, α = 1%.
27
Under review as a conference paper at ICLR 2022
(求)AUE-JnyV 7 04E」cυ-dlues P ①：UΞS
(注 >ws⊃y< / 0^2 ①-QLUfσs P 菖 IlS
OoooOo
108 6 4 2
(％) Uo≡⅛dcυ,J -l0)>o ①色 UO-IE ① Q
(兴)>urt3.lrDU</。=e-a)-duæs PΦ⅛HUS
OOOoo
1 8 6 4 2 0
(b) Severity = 2
3806040200
(％) Uo≡sd ①」」ω>0 3⅛H UOQU①一① Q
2000	4000	6000
Number of samples
(％) uo⅛4->θdφ-l」① >。ə:jBa UO-EZPQ
(a) Severity = 1
4000	6000	8000	10000
Number of samples
(％) /Oe-Inyq / Ow e-dujes pφ(tΞs
OOOoo
1 8 6 4 2 0
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti8方Q
(c) Severity = 3
(d)	Severity = 4
4000	6000	8000	10000
Number of samples
(e)	Severity = 5
Figure 16: Defocus blur with R = 100, w = 50, α = 1%.
28
Under review as a conference paper at ICLR 2022
OoooOo
108 6 4 2
(％) Uo≡⅛dcυ,J -l0)>o ①色 UO-IE ① Q
(兴)>urt3.lrDU</。=a)-duæs PΦ⅛HUS
OOOoo
18 6 4 2 0
0	2000	4000	6000	8000
Number Of samples
(a) Severity = 1
0	2000	4000	6000	8000	10000
Number of samples
(b) Severity = 2
2000
(％) Aue-lny∖/ / Ow ①-dines pφ(tΞs
OOOoo
1 8 6 4 2 0
100806040200
(％) UO≡sd ①」」ω>0 3⅛H UoQU①一① Q
4000	6000	8000	10000
Number of samples
(c) Severity = 3
2000	4000	6000
Number of samples
(d) Severity = 4
(％) >ws⊃y< / 0 4 B」①-QUJcσs P ①ctzs
O
OoOoo
18 1s 4 2 O
(％) uoq-⅛d ①」」əao əjfoee:Uo--dələɑ
(％) >U23UU< 一 04E」①QLues pad=!Ξs
Ooooo
18 6 4 2 0
IOOOO
(e) Severity = 5
Figure 17: Elastic transform with R = 100,
w = 50, α = 1%.
29
Under review as a conference paper at ICLR 2022
(％) AUP」rm</.20(υ-dE<σs P ①4=!zs
O
Ooooo
18 6 4 2 0
UoooOo
lυ8 6 4 2
(％) Uo≡wdφ-l .lα)>o ① JBa Uo-IE ① Q
(％) /Oe-Inyq / Ow e-dujes pφ(tΞs
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
%.
1
30
Under review as a conference paper at ICLR 2022
(求)AUE-JnyV 7 04E」cυ-dlues P ①：UΞS
(注 >ws⊃y< / 0^2 ①-QLUfσs P 菖 IlS
OoooOo
108 6 4 2
(％) Uo≡⅛dcυ,J -l0)>o ①色 Uo-IE ① Q
Number of samples
(b) Severity = 2
2000	4000	6000	8000
Number of samples
(兴)AUB-JrDW=B.Jɑ)-duæs pφt!Ξs
OOOoo
1 8 6 4 2 0
Uooooo
U 8 6 4 2
1
(％) uo⅛3θdφ-l」① >。① n(υa UO-EIPCJ
4000	6000	8000	10000
Number of samples
(a) Severity = 1
Oo
2u∪
4000	6000	8000	10000
Number of samples
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
(c) Severity = 3
(d)	Severity = 4
4000	6000	8000	10000
Number of samples
(e)	Severity = 5
(％) >U23UU< 一 04E」UdLUeS pad=!Ξs
Figure 19: Gaussian noise with R = 100, w = 50, α = 1%.
31
Under review as a conference paper at ICLR 2022
D.1.2 GI-shift
This section includes the plots for GI-shift scenario with different perturbation, window
and fixed severity.
sizes (w),
(％) A9en∑>u4 / 04E」①QEcσs P 岂zs
IOO
80
(<⅛) AUE-JrmV / O 一看」φαlucσs P gZS
---60
---40
——20
10000
*-<-	100
-----80
----60
----40
----20
10000
Number of samples
(b) Defocus blur
(d) Gaussian blur
(c) Elastic transform
(e) Gaussian noise
Figure 20: GI-shift with R = 100, w = 10, α = 1%.
32
Under review as a conference paper at ICLR 2022
(％) Uo≡wdφ-l .lα)>o ① JBa Uo-IE ① Q
(％) Uoq-⅛daj .Ja)ΛO ①居 Uo-tsələo
(％) >U23UU<^ O皂 UdLUeS p9d=!Ξs
%.
1
33
Under review as a conference paper at ICLR 2022
(兴)AUB-JrDW=B.Jɑ)-duæs pφt!Ξs
OOOoo
1 8 6 4 2 0
Uooooo
U 8 6 4 2
1
(％) uo⅛3θdφ-l」① >。① HEa UO-EIPCJ
< / 0≈2ωɑErσs P gzs
2000	4000	6000	8000
Number of samples
(d) Gaussian blur
60
40
20
10000
(％)
O
10
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
Ooowoo
108 6 4 2
(％) UO≡sd ①」」ω>0 3⅛H UoQU①一① Q
(％) Aue-In yq / Ow ①-dlues pφ(tΞs
OOOoo
1 8 6 4 2 0
(c) Elastic transform
IOOOO
(％) >U23UU< 一 04E」①QLues pad=!Ξs
Ooooo
18 6 4 2 0
(％) uoq-⅛d ①」」əao əjfoee:Uo--dələɑ
ιoo
80
60
40
20
0	2000	4000	6000	8000
Number of samples
(e) Gaussian noise
Figure 22: GI-shift with R = 100, w =
50, α = 1%.
34
Under review as a conference paper at ICLR 2022
D.1.3 GID-shift
Similar to the previous two sections, this section includes figures for the GID-shift scenario with
different perturbation with severity 2, and different window sizes (w).
0	2000	4000	6000	8000	10000
Number of samples
(b) Defocus blur
2000	4000	6000	8000	10000
Number of samples
(a) Contrast
2000	4000	6000	8000	10000
Number of samples
(c) Elastic transform
(d) Gaussian blur
0	2000	4000	6000 SOOO 10000
Number of samples
(e) Gaussian noise
: GID-shift with R = 100, w = 10, α = 1%.
Oooooo
0 8 6 4 2
(％) uol口① daι」a>0 £2H uɔ:P ①一① Cl
Figure 23
35
Under review as a conference paper at ICLR 2022
0	2000	4000	6000	8000	10000
Number Of samples
(a)	Contrast
0	2000	4000	6000	8000	10000
Number of samples
(b)	Defocus blur
O 2000	4000	6000	8000 IOOOO
Number of samples
(d) Gaussian blur
Ooowoo
108 6 4 2
(％) Uo≡sd ①」」ω>0 3⅛H UOQU①一① Q
(％) Aue-lny∖/ / Ow e-dujes pφ(tΞs
OOOoo
1 8 6 4 2 0
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
(c) Elastic transform
0	2000	4000	6000	8000	10000
Number of samples
(e) Gaussian noise
Oooooo
0 8 6 4 2
(％) Uoq-⅛daj」① >0 ①居 Uo-tsələo
Figure 24
: GID-shift with R = 100, w = 20, α = 1%.
36
Under review as a conference paper at ICLR 2022
(d) Gaussian blur
Uooooo
U 8 6 4 2
1
(％) uo⅛3θdφ-l」① >。① n(υα co≡wω⅞Q
Uooooo
U 8 6 4 2
ɪ
(％) UO口口 ① daι -lθ>o ω4.JEccu°ti①：lθQ
(c) Elastic transform
Number of samples
(a) Contrast
(e) Gaussian noise
Figure 25: GID-shift with R = 100, w = 50, α = 1%.
37
Under review as a conference paper at ICLR 2022
D.2 Number of Samples for Detection
This section presents the required number of samples for detecting covariate shift over repetitions
(Rate ≥ 80%) with different perturbations, severities, and window sizes (w).
D.2.1 M-shift
Table 5: Number of samples for detection with R = 100, w = 10
Severity	Algorithms	Contrast	Defocus Blur	Elastic Transform	Gaussian Blur	Gaussian Noise
	Ours	280	240	510	400	220
1	H2	610	550	1310	950	450
	H5	610	460	1610	960	410
	Ours	230	^^200^^	220	210	180
2	H2	470	450	450	490	350
	H5	410	410	410	460	310
	Ours	190	170	190	140	140
3	H2	350	370	410	270	270
	H5	310	360	360	260	260
	Ours	150	140	160	120	120
4	H2	250	290	290	210	210
	H5	210	260	260	210	160
	Ours	130	-^120^^	140	100	110
5	H2	210	230	210	170	150
	H5	160	210	210	160	160
Table 6: Number of samples for detection with R = 100, w = 20
Severity	Algorithms	Contrast	Defocus Blur	Elastic Transform	Gaussian Blur	Gaussian Noise
	Ours	300	-^250^^	430	360	250
1	H2	530	430	970	770	410
	H5	460	410	1010	710	360
	Ours	250	-^220^^	240	230	210
2	H2	430	390	390	410	350
	H5	360	360	360	360	310
	Ours	220	^^200^^	230	170	170
3	H2	330	330	370	290	270
	H5	310	310	360	260	260
	Ours	170	170	200	140	140
4	H2	270	290	310	230	230
	H5	260	260	260	210	210
	Ours	160	-^150^^	170	110	120
5	H2	250	250	230	190	190
	H5	210	210	210	160	160
38
Under review as a conference paper at ICLR 2022
Table 7: Number of samples for detection with R = 100, w = 50
Severity	Algorithms	Contrast	Defocus Blur	Elastic Transform	Gaussian Blur	Gaussian Noise
	Ours	360	^^300^^	490	430	290
1	H2	570	510	870	710	470
	H5	560	460	810	660	410
	Ours	310	270	280	280	250
2	H2	510	450	470	470	390
	H5	460	410	460	460	360
	Ours	260	^^240^^	270	220	210
3	H2	410	410	450	330	330
	H5	360	360	410	310	310
	Ours	210	^^210^^	230	170	160
4	H2	310	370	370	270	270
	H5	310	360	360	260	260
	Ours	170	^^170^^	190	130	130
5	H2	290	310	290	210	210
	H5	260	260	260	210	210
39
Under review as a conference paper at ICLR 2022
D.2.2 GI-shift
Table 8: Number of samples for detection with R = 100, w = 20
Algorithms	Contrast	Defocus Blur	Elastic Transform	Gaussian Blur	Gaussian Noise
Ours	2100	2040	2100	2040	2050
H2	2890	2150	2610	2170	2190
H5	4110	4010	4110	4010	4010
Table 9: Number of samples for detection with R = 100, w = 50
Algorithms	Contrast	Defocus Blur	Elastic Transform	Gaussian Blur	Gaussian Noise
Ours	1580	980	1340	1170	970
H2	2310	2130	2190	2170	2130
H5	2460	2310	2510	2310	2310
D.2.3 GID-shift
Table 10: Number of samples for detection with R = 100, w = 20
Algorithms	Contrast	Defocus Blur	Elastic Transform	Gaussian Blur	Gaussian Noise
Ours	620	430	530	470	450
H2	1890	990	1670	1170	1030
H5	2010	2010	2060	2010	2010
Table 11: Number of samples for detection with R = 100, w = 50
Algorithms	Contrast	Defocus Blur	Elastic Transform	Gaussian Blur	Gaussian Noise
Ours	590	480	550	520	490
H2	1110	870	1010	970	910
H5	1510	910	1310	1010	960
40