Under review as a conference paper at ICLR 2022
Rethinking Client Reweighting for
Selfish Federated Learning
Anonymous authors
Paper under double-blind review
Ab stract
Most federated learning (FL) algorithms aim to learn a model which achieves
optimal overall performance across all clients. However, for some clients, the
model obtained by conventional federated training may perform even worse than
that obtained by local training. Therefore, for a stakeholder who only cares about
the performance of a few internal clients, the outcome of conventional federated
learning may be unsatisfactory. To this end, we study a new selfish variant of fed-
erated learning, in which the ultimate objective is to learn a model with optimal
performance on internal clients alone instead of all clients. We further propose
Variance Reduction Selfish Learning (VaRSeL), a novel algorithm that reweights
the external clients based on variance reduction for learning a model desired in this
setting. Within each round of federated training, it guides the model to update to-
wards the direction favored by the internal clients. We give a convergence analysis
for both strongly-convex and non-convex cases, highlighting its fine-tune effect.
Finally, we perform extensive experiments on both synthesized and real-world
datasets, covering image classification, language modeling, and medical image
segmentation. Experimental results empirically justify our theoretical results and
show the advantage of VaRSeL over related FL algorithms.
1 Introduction
Federated learning (FL) proposes a privacy-preserving scheme, which enables different clients to
cooperatively learn a global model by integrating knowledge from multiple clients. Suppose there
are Q clients {Dn}nQ=1 in total. A general objective of FL is given by
Q
minX LDn (f),	(1)
f n=1
where f is the model, and LDn is the generalization loss on client Dn .
However, since the general objective (1) fairly optimizes the mean generalization loss across all
clients, a model learned by (1) may not perform well on some individual clients. We implemented
several state-of-the-art FL algorithms on FeTS 2021 (Pati et al., 2021), a real-world FL dataset for
medical image segmentation, and discovered that the federally learned model is not guaranteed to
generalize on local client(s) at least as well as the locally learned model. (see Figure 1)
In cross-silo FL (Kairouz et al., 2019), this issue becomes particularly serious since clients typically
have sufficient data for training a decent local model. In this case, the clients may become reluctant
to participate in federated training. This issue raises an important challenge for FL society as well
as practitioners: For a stakeholder who is only interested in the model’s performance on a small
portion of clients, is it possible to guarantee its benefits from federated learning?
This is a common challenge in many practical cases. For instance, in a bank network, due to the lim-
ited size of internal datasets, a banking group wants to leverage more data and learn a better model
through federated learning, while the banking group expects the final model to maximize the perfor-
mance on its own internal banks, rather than overfitting to other external banks. As another example,
to build an AI-assisted diagnostic system, a medical association hopes to integrate knowledge from
the datasets of external partner hospitals through federated learning. As the system ultimately serves
1
Under review as a conference paper at ICLR 2022
its internal hospitals/patient populations, its performance should not be disturbed by external partner
hospitals (Rieke et al., 2020). In these cases, to enhance the model perf the stakeholder would like
to purchase gradient updates from external collaborators.
Selfish federated learning In this work, we re-
solve the aforementioned challenge by investigat-
ing a novel learning setting called selfish federated
learning (Selfish-FL), where the stakeholder who
only cares about the performance on a few internal
clients can reap the benefits of cooperative learning
with external clients. To formalize, the Q clients are
partitioned into M internal clients and N external
clients (M + N = Q, M N). Though it is possi-
ble to incorporate the knowledge in all Q clients for
model training, the stakeholder only focuses on the
model’s performance on the M internal clients.
Comparisons with related setups Table 1 lists
several FL settings. While centralized and decen-
tralized FL differ in communication network, both
of them are looking for a global consensus among
all the clients (Wang et al., 2021; Koloskova et al.,
2020). Personalized-FL allows each client to main-
tain a personalized model, but the losses of all clients
are still considered in the overall objectives (Fallah
Figure 1: The Dice score of FL methods and
local training on 1st site in FeTS 2021 for
brain tumor segmentation. FedAvg (McMa-
han et al., 2017), FedProx (Li et al., 2020b),
and Per-FL (Fallah et al., 2020) are different
FL variants.
et al., 2020; Tan et al., 2021). In Selfish-FL, only internal clients are the concern of the stakeholder,
while the role of external clients is to provide additional information to further improve the model’s
performance on internal clients.
Table 1: Comparisons among related federated learning settings.
Learning Setting	Objective	Comments
Centralized-FL	M+N n=1 LDn (f)	Server has access to clients’ updates {gn}nM=+1N.
Decentralized-FL	M+N n=1 LDn (f)	Client n has access Sn and {fk}k∈N(n); fn’s finally converge to a global consensus.
Personalized-FL	M+N n=1 LDn (fn)	fn’s may not converge to a global consensus.
Selfish-FL	PiM=1 LDi (f)	Internal clients 1, ∙ ,M have access to datasets Si,…,SM and updates {gj}M+M+「
Our contributions The main contributions in this paper can be summarized as four aspects: First,
we study a novel setting in federated learning, namely “Selfish-FL”, which is the first work (to the
best of our knowledge) considering biased objectives and internal/external partitions in FL setting.
Second, we propose a novel algorithm, called VaRSeL, for solving Selfish-FL problem. It leverages
knowledge from external clients to improve the model via gradients variance reduction. This is a dif-
ferent perspective compared with previous loss-based clients reweighting strategy (Cho et al., 2020;
Chen et al., 2020). Within each round of federated training, it guides the model to update towards the
direction favored by the internal clients. Moreover, our strategy is free of hyperparameter-tuning.
Third, we present a convergence analysis of our reweighting strategy for this new setting, both in
strongly-convex cases and non-convex cases. Based on the convergence result, we also observe its
fine-tune effect.
Finally, we perform extensive experiments on both synthesized and real-world natural language and
medical image analysis datasets. The experimental results demonstrate that our proposed VaRSeL
2
Under review as a conference paper at ICLR 2022
outperforms the classical FedAvg, related client selection methods, as well as the state-of-the-art for
non-iid data (FedProx) and personalized FL algorithm (Per-FL) in terms of model accuracy.
2	Related works
2.1	Federated learning and challenges
Federated learning (FL) (Yang et al., 2019; Kairouz et al., 2019; Wang et al., 2021) provides a
promising way of cooperative learning with privacy protection. In this subsection, we will briefly
summarize a few important lines of FL (Some works may lie at intersection):
Relieving clients’ non-iid Proximal terms (Li et al., 2020c), cluster-based methods (Briggs et al.,
2020; Ghosh et al., 2020), client-drift regulations (Karimireddy et al., 2020; Acar et al., 2021) are
some leading methods to address the heterogeneity of clients’ data distributions. At a high level, all
these methods can be summarized as pursuing a compromise solution that can work fairly well on
all the clients. Therefore, even though these methods are very effective in classical FL frameworks,
none of them fits well into our selfish-FL framework, because the internal clients are in nature
reluctant to compromise with any external clients.
Personalized FL Many approaches have been proposed for achieving personalization in FL set-
ting (Kairouz et al., 2019), e.g., mixing the global model and user’s local model, dividing the net-
work into base and personalized layers. Recently, Per-FL (Fallah et al., 2020) linked personalized FL
with meta-learning by building a good initial meta-model that can be updated effectively. Dinh et al.
(2020) used Moreau envelopes as clients’ regularization loss to achieve personalized FL and Zhang
et al. (2020) proposed a flexible FL framework that allows clients to personalize to specific target
data distributions. Readers can refer to comprehensive surveys in Li et al. (2020a); Tan et al. (2021).
However in personalized FL, the losses of all clients are still considered in the overall objectives.
Alleviating communication cost Lin et al. (2017); Richtarik et al. (2021) provided several model
compression schemes to reduce communication cost and proved the convergence of their compres-
sion methods. Liang et al. (2020); Li et al. (2021) proposed to learn a combination of local and
global models, while only the global parts are synchronized. It’s worth mentioning that our method
is orthogonal to these communication-efficient methods and can be combined with theirs directly.
2.2	Sample reweighting.
Our work is also related to sample reweighting, i.e., assigning different weights to samples in model
training to tackle dataset biases. There are two completely opposite strategies on how to set the
weights w for external datasets. One line of works Freund et al. (1996); Malisiewicz et al. (2011);
Cho et al. (2020) argues that the samples with higher losses should be given more weights, since
these difficult samples can help sharpen the decision boundaries and increase the adversarial robust-
ness. The other line of works Ghadikolaei et al. (2019); Song et al. (2021) suggests lowering their
weights, since their high losses are attributed to training set biases or mislabels (e.g., nosiy samples).
In fact, this contradiction directly points to a fundamental, difficult problem in machine learning:
Dilemma. How to distinguish the difficult samples from the noisy ones?
To the best of our knowledge, the controversy continues, and people are still far from getting a clear
resolution. To bypass the aforementioned dilemma, some researchers (Ren et al., 2018; Shu et al.,
2019) used meta-learning approach to learn how to assign weights w adaptively. However, their
method suffers from computationally expensive second derivatives estimation, and can hardly gen-
eralize to federated learning framework since it requires full-client participation throughout training.
Client reweighting in FL In FL framework, since one only has access to limited training exam-
ples, clients instead of samples are reweighted to tackle their heterogeneity. Existing FL algorithms
reweight clients using the sizes of their datasets (Li et al., 2020c), the numbers of their local steps
(Wang et al., 2020), their local losses (Cho et al., 2020; Chen et al., 2020), etc.
3
Under review as a conference paper at ICLR 2022
As an inevitable issue in FL, communication costs usually restrict the number of clients one can
access within each communication round (McMahan et al., 2017). Suppose client j is sampled with
probability wj ∈ [0, 1], M+1 ≤ j ≤ M+N. Since the communication costs mainly depend on the
number of sampled clients, existing algorithms (Lian et al., 2018; Wang et al., 2019) impose hard
constraints on wj as 1Tw = PjM=+MN+1 wj ≤ CbN = K, where Cb > 0 is called the communication
budget, to alleviate the communication bottleneck.
3	Problem formulation
In this section, we give a formal definition of the setting selfish federated learning (Selfish-FL).
Internal and external clients Let X denote the input space (e.g., feature space) and Y the space
of outputs (e.g., label space). Each client characterizes a joint distribution D = P(X, Y ) over
X × Y. Suppose there are M + N clients {Dn }nM=+1N , among which the first M clients are called
the internal clients and the remaining N clients are called the external clients (M	N). We
assume that internal clients are consistent and the difference between internal and external clients
are expected to be larger than that between internal clients. To formalize, we have
Di =…=DM，Di；
Dj 6= DI , M + 1 ≤ j ≤ M + N.
In practice, the distributions of clients are not observed directly, but given in the form of sample sets
Sn 〜Dn, for 1 ≤ n ≤ M + N. The stakeholder has direct access to the raw data in Si,..., SM,
but can only query external clients in a privacy-preserving way as in typical FL scenario.
Ultimate objective While conventional federated learning setting usually aims to minimize the
generalization loss across all clients, the objective in Selfish-FL is to minimize the generalization
loss on internal clients Di, ∙ ∙ ∙ , DM alone:
1M
min l(θ) := M EE(X,y)〜DiLfθ (x),y),	⑵
i=i
where fθ denotes a model f parameterized by θ, and L denotes an appropriate loss function. Al-
though the stakeholder can simply learn θ by local training on datasets of internal clients, we will
show both in theory and in experiments that it is probable to improve the estimation of θ by lever-
aging additional knowledge from external clients without sharing raw data.
4	VaRSeL: variance reduction selfish learning
4.1	Reweighting via variance reduction
In Selfish-FL, we incorporate the knowledge of external clients to further improve the performance
of model fθ on internal clients. Since external clients are of uneven qualities, it’s natural to assign
them different weights and formulate a surrogate objective as
l(θ; w)
M + 1Tw
(3)
where W ∈ [0,1]N, 1TW ≤ K, and ln(θ) = ∣s^ P(X y)∈Sn L(fθ(x),y) is the empirical loss on
client n. As a result, how to set the weights w is a key issue in designing Selfish-FL algorithms. In
this paper, to bypass the dilemma in section 2.2, we consider the client reweighting strategy from a
different perspective compared with previous works:
Strategy. We’re setting W neither to reduce losses nor to increase losses, but to
make our surrogate objective (Eq. (3)) simulate the ultimate objective (Eq. (2)).
Since the majority of optimizers applied in deep learning are first-order methods (e.g., SGD, Adam)
(Wang et al., 2021), we consider making the estimated gradient as precise as possible. Specifically,
4
Under review as a conference paper at ICLR 2022
the goal is to reduce the variance (denoted as Φ(w; θ)) between the estimated, surrogate gradient
Vl(θ; W) and the unseen, ultimate gradient Vl(θ)1:
Φ(w;θ) = E∣∣Vl(θ; w) -Vl(θ)k2
1	M+N	2
=(M +1Tw)2 ∙司 M (VlI (θ)-vl(θ))+ X Wj (Vlj (θ)-vl(θ))卜
j=M+1
where II(θ)=吉 PM=I li(θ). Since the internal gradients are unbiased estimators of the ultimate
gradients, we have
E[Vli (θ)] = E[VlI(θ)] = Vl(θ), 1 ≤ i ≤ M.
Thus, the variance Φ(w; θ) can be simplified as follows:
M	M+N	2
X EkVli(θ) -Vl(θ)k2 + E∣∣ X Wj (Vlj (θ) - Vl(θ))∣∣ .	(4)
i=1	j=M+1
φ(w; θ) = (M + ITw)2
The optimal weights w* are thus chosen to minimizes the variance in Equation (4):
w* = arg min Φ(w; θ).
w
In this way, we can head towards the optimal direction for the ultimate objective.
4.2	Convergence analysis
In this section, we give a convergence analysis for our reweighting strategy. Our proofs mainly
follow Li et al. (2020c), and we refer readers to Appendix A and B for the details of the proofs.
As in Schmidt & Roux (2013); Li et al. (2020b); Vaswani et al. (2019), we assume bounded dis-
similarity on internal datasets. For external datasets, we take a weaker assumption by allowing
non-vanishing noises (νj ) near the optimal point. In general, our assumptions are weaker than the
constantly-bounded noise assumptions since the noises are allowed to grow with the gradient norms.
ASSUMPTION 1 For internal datasets, we assume: for some constant σ > 0,
EkVlI(θ)-Vl(θ)k2 ≤ σkVl(θ)k2;
For external datasets, we take weaker assumptions: for each M + 1 ≤ j ≤ M + N, for some
constants κj , νj > 0,
EkVlj(θ)-Vl(θ)k2≤κjkVl(θ)k2+νj.
Lemma 1. Under Assumption 1, there exist constants A, B > 0, such that
Φ(w*; θ) ≤ AkVl(θ)k2 + B.
To ensure convergence, we further assume that the objective functions are well-conditioned.
ASSUMPTION 2a The ultimate objective function is L-smooth (L > 0):
kVl(θ1) -Vl(θ2)k ≤ Lkθ1 - θ2k.
ASSUMPTION 2b The empirical loss functions are L-smooth (L > 0):
kVln(θ1) -Vln(θ2)k ≤ Lkθ1 - θ2k,	1 ≤n ≤ M+N.
Assumption 3 The ultimate objective is μ-strongly convex (μ > 0):
__________________________kVl(θ1) -Vl(θ2)k ≥ μkθι - θ2∣∣.
1The “variance reduction” here is essentially different from that in conventional FL. In conventional FL,
it reduces the variance between all clients to speedup the global convergence; in selfish-FL, it can be seen as
reducing the variance between internal and external clients, thus alleviating the disturbance of external noises.
5
Under review as a conference paper at ICLR 2022
ASSUMPTION 4 The estimated gradient norms are uniformly bounded:
EkVln(θ)k2 ≤ G2,	1 ≤ n ≤ M + N.
To gain some insights, we start our analysis from a well-conditioned case and assume local steps
τ = 1. Using the bound of Lemma 1, we can derive Theorem 2 on convergence rate. The first term
on the right hand side of Eq. (5) is called optimization term, and the second is called noise term. The
convergence rate is bounded by the sum of the two terms.
Theorem 2 (Basic Convergence). Let θt+1 = θt 一 ηVl(θt; Wtt), 0 ≤ t ≤ T 一 L Under Assump-
1 - A
tion 1, Assumption 2a and Assumption 3, for η < 2√μ , we have
Ekθ* - θtk2 ≤(1 一 ηΞ1)tEkθ* - θ0k2 + ξ2b ,
(5)
|
{^^^^^^™
optimization term
}	l{z}
noise term
where Ξ1 and Ξ2 are constants,
The basic convergence result (Eq. (5)) provides useful insights for model training. At the beginning
of training, due to random initialization, the optimization term can be arbitrarily large. But as
T increases, the optimization term decays in linear rate. Consequently, the dominant term will be
gradually shifted to noise term, which is mainly determined by the noises in external datasets. Based
on this observation, when training progresses to later stage, in order to get more precise gradients, it
will gradually switch back to internal datasets and fine-tune the trained model at the end of learning.
Taking multiple steps between communication rounds is an entrenched convention in communica-
tion efficient federated learning (McMahan et al., 2017; Kairouz et al., 2019). Hence we give a more
general convergence analysis, in which local steps τ ≥ 1. We formalize it as follows:
θnt = θt ,
θt+ k+1 = θnτ+1 一 ηVln(θn+ τ+1),	1 ≤ n ≤ M + N, for 0 ≤ k ≤ T 一 1,
θt+1 = θt+ τ+1 w,
where θw = PM θi MPM^ "j .
Theorem 3 (Main Convergence). For T ≥ 1, under Assumption 1, Assumption 2a, Assumption 2b
and Assumption 4, for η < L(A+√A), we have
T	T-1 T-1	____ 2
TTXXEBvl(θt+τ+1 w”∣∣ ≤
W - l(θ*) + Γ1Γ2
ηΓ3TT	Γ3T
where Γ1, Γ2 and Γ3 are constants.
Algorithm 1 Variance Reduction Selfish Learning (VaRSeL)
Input: learning rate η , communication rounds T .			Output: final model θfinal.
1	: Initialize model θ0.	10:	Sample a subset of clients St according to
2	for t = 0,1 …，T - 1 do		W.
3	Compute internal gradients Vlι(θt),…，	11:	for j ∈ St in parallel do
	VlM (θt), and then VlI (θt).	12:	Send back Vlj (θt).
4	: Broadcast (θt, VlI(θt)) to clients [M +	13:	end for
	1,M+N].	14:	Solve Wt according to Equation (4).
5	: for j ∈ [M + 1, M + N] in parallel do	15 15:	∆t	M VlI (θt)+wξ[Vlj (θt)]j∈St
6	:	Compute gradient update Vlj (θt).		△ =	M+1tw*
7	Sendback IlVlj(θt) -VlI(θt)∣∣.	16:	θt+1 := θt 一 η∆t
8	: end for	17:	end for
9	Solve W according to Equation (8).	18:	return θfinal := θt
6
Under review as a conference paper at ICLR 2022
4.3	Variance reduction selfish learning
Based on our above reweighting strategy, we design an algorithm, called Variance Reduction Selfish
Learning (VaRSeL). It is free of hyperparameter-tuning, and moreover, as shown in experiments, it
will automatically fine-tune the model when learning progresses to later stage. VaRSeL is not exactly
the reweighting strategy in section 4.1, but an approximation algorithm to the reweighting strategy,
The main idea of VaRSeL is to select the external collaborators wisely within each communication
round. Within iteration t, suppose the central server has collected the gradient updates on internal
datasets. Then we can estimate the ultimate gradient unbiasedly:
E[Vlι (θt )] = l(θt).	(6)
Communication bottleneck is a major obstacle that prevents us from accurately solving the optimal
weights w* in Equation (4). To this end, We propose a heuristic:
M	M+N	2
X EkVli(θ) -Vl(θ)k2 + E∣∣ X Wj (Vlj (θ) -Vl(θ))∣∣
i=1	j=M+1
1	M	M+N	2	(7)
≤ (M + 1Tw)2 X EkVli(θ) -Vl(θ)k2 + ITw X Wj E∣∣Vlj (θ) -Vl(θ)∣∣	，Φ(w; θ).
I + i L i=1	j=M +1	、----------------}-
communicated term
Before the external clients send back their updates, we first estimate an approximate weight:
W = arg min Φ(w; θ).	(8)
w
This approximate weight tightens the upper bound in (7) and can be computed very efficiently, since
only a few bytes of communication are required. Then, we sample clients according to W, and after
receiving their updates, we can solve a more accurate w* according to Equation (4).
The pseudo-code of VaRSeL is given in Algorithm 1. This is a simple implementation when local
steps τ equals 1. In fact, τ is allowed to be greater than 1, and we almost don’t modify any other
parts of the algorithm, except to replace the gradient update with the accumulated model update.
φ(w; θ) = (M + 1Tw)2
5 Experiments
In this section, we present experimental results on both synthesized benchmark datasets and real-
world datasets. For synthesized benchmark experiments, we mainly use them to support the claims
made in our paper. For real-world dataset experiments, we show the real-world performance of our
method and its higher accuracy over the other competitors.
We compared VaRSeL with seven existing methods mentioned in section 2:
•	Baseline methods, including Local Training (i.e., training the model with internal datasets)
and the original FedAvg (McMahan et al., 2017);
•	Non-iid relief methods, FedProx (Li et al., 2020b);
•	Reweighting methods, including Skew (Cho et al., 2020), SL (Song et al., 2021), and OCS
(Chen et al., 2020);
•	Personalized FL methods, the MAML-based Per-FL (Fallah et al., 2020).
5.1	Experiments on synthesized benchmark datasets
Dataset and settings We conducted experiments on three benchmark datasets, Fashion-MNIST,
EMNIST, and CIFAR-10 (Xiao et al., 2017; Cohen et al., 2017; Krizhevsky, 2009) to demonstrate
the robustness and fine-tune effect of our methods. The datasets were preprocessed in similar ways
as McMahan et al. (2017). We used a logistic model for Fashion-MNIST, a 2NN model for EMNIST,
anda CNN model for CIFAR-10. For model training, we used cross entropy loss and SGD optimizer,
setting batch size b = 32. Every result is taken from the average of3 independent runs. More details
about data preprocessing and model architecture can be found in Appendix C.
7
Under review as a conference paper at ICLR 2022
Table 2: Test accuracy on synthesized datasets with different learning rate lr and local step τ .										
Methods 	I	I	Fashion-MNIST	∣			I	EMNist	∣			CIFAR-10			
	I 0.1, 3	0.3, 3	0.3, 5	0.3, 3	0.1, 5	0.3,5 I	.03, 3	0.1, 3	.01, 5	.03, 5
Local Training	92.94	92.66	92.80	76.57	77.50	78.89	73.5	74.0	74.0	75.0
FedAvg (McMahan et al., 2017)	78.53	84.35	88.09	76.49	73.53	79.51	67.0	70.5	66.5	69.5
FedProx (Li et al., 2020b)	I 88.37	89.34	90.86	76.49	73.53	79.32 I	66.5	71.5	66.5	69.5
Skew (Cho et al., 2020)	83.38	85.04	88.92	72.90	72.83	77.81	76.5	78.8	75.0	76.2
SL (Song et al., 2021)	85.32	89.20	90.17	78.94	76.54	81.02	77.2	74.0	78.0	73.8
OCS (Chen et al., 2020)	81.30	86.43	85.04	70.72	69.15	77.18	72.0	52.0	75.0	68.8
Per-FL (Fallah et al., 2020)	I 77.56	82.13	87.40	74.72	72.39	78.85 I	67.0	71.0	64.5	69.5
VaRSeL (Ours)	I 95.01	96.88	94.88	80.65	80.18	82.61 I	81.5	78.8	80.0	80.5
Robustness We’ve tested the robustness of VaRSeL under different learning rates and local steps.
Learning rates range from 0, 3, 0.1, 0.03, 0.01, and local steps range from 1, 3, 5. As shown in Table
2, our method outperforms the best accuracy of other competitors by at least 3.94% in Fashion-
MNIST, 1.59% in EMNIST, and 2.7% in CIFAR-10.
The fine-tune effect As indicated in our basic convergence analysis, the external weights w should
decay gradually. And in VaRSeL, the weights w* is computed adaptively within each iteration, so
the fine-tuning will take effect automatically without any human intervention or additional hyper-
parameters. In Figure 2, we plot the sum of external weights (1Tw) in our synthesized experiments,
as an indicator of the fine-tune effect. It can be observed that the external weights gradually decrease
during the training process, which is consistent with our theoretical analysis.
Figure 2: The automatic fine-tune effect of VaRSeL on Fashion-MNIST, EMNIST and CIFAR-10.
5.2	Experiments on Shakespeare dataset
Dataset and settings We used an FL dataset derived from The Complete Works of William Shake-
speare (Shakespeare, 2007). There are altogether 715 clients, each of whom corresponds to a role in
one of the Shakespeare’s six classic plays—‘All’s Well That Ends Well’, ‘Much Ado About Nothing’,
‘Pericles, Prince of Tyre’, ‘The First Part of King Henry the Fourth’, ‘The Taming of the Shrew’, and
‘The Tragedy of King Lear’. The clients’ datasets are comprised of their lines in the play. Finally,
we designate the roles in one of the six plays as internal clients, and those in the remaining five plays
as external clients.
Details of implementation and results Following McMahan et al. (2017), we used a 2-layer
LSTM for the prediction of next character. For model training, we employed cross entropy loss,
learning rate η ∈ [0.5, 5.0], local steps τ ∈ {1, 2, 3}, and batch size b = 4. We took the average
results of three independent runs of 200 communication rounds. As shown in Table 3, the average
score of VaRSeL outperforms other competitors by at least 0.89%.
5.3	Experiments On medical image dataset
Dataset and settings Tumor segmentation is one of challenging tasks (Hesamian et al., 2019) due
to the limitation annotations, the imbalance of data distribution, and the heavy noises in different
image scans. In this subsection, we show the real-world performance of our method and other com-
petitors on FeTS 2021 (Pati et al., 2021), a real-world brain tumor segmentation dataset composed
of clinically acquired, magnetic resonance imaging (MRI) scans from 17 different medical sites.
8
Under review as a conference paper at ICLR 2022
Table 3: Prediction accuracy on the plays of Shakespeare.
Methods	AWTEW	MAAN	PPT	TFPKHF	TTS	TTKL	Accmean
Local Training	45.39	45.23	47.41	45.81	43.43	43.53	45.13
FedAvg (McMahan et al., 2017)	45.52	44.59	45.21	43.61	43.99	44.61	44.59
FedProx (Li et al., 2020b)	45.40	44.49	46.13	44.27	42.99	44.51	44.63
Skew (Cho et al., 2020)	45.33	46.76	47.13	45.86	43.89	38.10	44.51
SL (Song et al., 2021)	44.88	42.56	46.25	38.61	42.05	43.27	42.94
OCS (Chen et al., 2020)	45.28	44.23	47.22	45.63	43.84	40.65	44.47
Per-FL (Fallah et al., 2020)	42.20	41.44	42.82	40.48	41.42	42.60	41.83
VaRSeL (Ours)	45.83	46.52	47.96	46.27	44.48	45.03	46.02
Table 4: Dice scores of different methods (95% C.I.) for whole brain tumor segmentation on FeTS
2021 by taking different site data as internal sites.
Methods	Score on 1st Site	Score on 6th Site	Score on 16th Site	SCoremean
Local Training	70.76 ± 0.14	58.12 ± 0.10	53.83 ± 0.34	60.90
FedAvg (McMahan et al., 2017)	68.32 ± 0.83	58.01 ± 0.57	56.95 ± 0.47	61.90
FedProx (Li et al., 2020b)	-67.87 ± 0.62-	-58.48 ± 0.57-	-56.43 ± 0.31	-60.92-
Skew (Cho et al., 2020)	-68.20 ± 0.08-	-53.84 ± 0.29-	-56.32 ± 0.88	-59.45-
SL (Song et al., 2021)	71.67 ± 0.04	57.42 ± 0.01	58.86 ± 0.23	62.65
OCS (Chen et al., 2020)	69.12 ± 0.09	59.95 ± 0.83	57.33 ± 0.66	62.13
Per-FL (Fallah et al., 2020)	-66.48 ± 0.02-	-55.96 ± 0.10-	-56.64 ± 0.25	-59.69-
VaRSeL (Ours)	72.06 ± 0.04	61.06 ± 0.02-	-61.60 ± 0.83-	-64.91-
To form the internal and external clients, we took one of the three largest sites (1st, 6th, or 16th) as
the internal site, and the rest as the external ones. Furthermore, for each setting, the chosen internal
site was partitioned equally into 3 parts, which are distributed to 3 internal clients respectively to
simulate more internal clients. The MRI scans include various modalities (Bakas et al., 2018),
say a) native (T1), b) post-contrast T1-weighted (T1Gd), c) T2-weighted (T2), and d) T2 Fluid
Attenuated Inversion Recovery (T2-FLAIR). For whole brain tumor segmentation, T2-FLAIR is
reported to better identify the malignant features (Zeineldin et al., 2020), To highlight the nature of
internal/external partition, the internal datasets are all organized in T2-FLAIR, while every external
dataset randomly picks up from one modality to enlarge the distribution shift of different datasets.
Details of implementation and results We used the 2D U-Net (Ronneberger et al., 2015) with
instance normalization (Ulyanov et al., 2016). We took the following measures to ensure fair
competitions between all the methods: (i) Try gradient descent with three different learning rates
η = 0.3, 0.1, 0.03; (ii) Try three different local steps τ = 1, 3, 5; (iii) For the best learning rate and
local steps, we take the average results of three independent runs of 60 communication rounds. The
experimental results are summarized in Table 4. It is observed that our VaRSeL outperforms local
training on all three sites, show the effectiveness of incorporating external sites to boost the perfor-
mance of internal sites. Also, the average score of VaRSeL largely outperforms other competitors
by over 2.26%, showing the effectiveness of our proposed framework.
6 Conclusions and remarks
This work proposes a novel setting called “selfish federated learning” that cooperatively optimizes
a biased objective towards internal distributions in a communication-efficient and heterogeneous
privacy-preserving way. The central idea is to reweight the external datasets via a variance-reduction
approach, based on which we develop “VaRSeL” (Algorithm 1). We provide convergence analysis
for our reweighting strategy, and highlight its fine-tune effect. In synthesized and realistic experi-
ments, we support the theoretical results made in our paper, and demonstrate its better performance
compared to alternative methods. Our code is publicly available and we believe that VaRSeL can
find a wide range of applications, such as healthcare (Rieke et al., 2020).
9
Under review as a conference paper at ICLR 2022
References
Durmus Alp Emre Acar, Yue Zhao, Ramon Matas, Matthew Mattina, Paul Whatmough, and
Venkatesh Saligrama. Federated learning based on dynamic regularization. In International Con-
ference on Learning Representations, 2021.
S Bakas, M Reyes, A Jakab, S Bauer, M Rempfler, A Crimi, RT Shinohara, C Berger, SM Ha,
M Rozycki, et al. Identifying the best machine learning algorithms for brain tumor seg-
mentation, progression assessment, and overall survival prediction in the brats challenge. corr
abs/1811.02629 (2018), 2018.
Christopher Briggs, Zhong Fan, and Peter Andras. Federated learning with hierarchical clustering
of local updates to improve training on non-iid data. In 2020 International Joint Conference on
NeuralNetworks (IJCNN),pp.1-9.IEEE, 2020.
Wenlin Chen, Samuel Horvath, and Peter Richtarik. Optimal client sampling for federated learning.
arXiv preprint arXiv:2010.13723, 2020.
Yae Jee Cho, Jianyu Wang, and Gauri Joshi. Client selection in federated learning: Convergence
analysis and power-of-choice selection strategies. arXiv preprint arXiv:2010.01243, 2020.
Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van Schaik. Emnist: Extending mnist
to handwritten letters. In 2017 International Joint Conference on Neural Networks (IJCNN), pp.
2921-2926. IEEE, 2017.
Canh Dinh, Nguyen Tran, and Tuan Dung Nguyen. Personalized federated learning with moreau
envelopes. Advances in Neural Information Processing Systems, 33, 2020.
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning with theo-
retical guarantees: A model-agnostic meta-learning approach. In Advances in Neural Information
Processing Systems, 2020.
Yoav Freund, Robert E Schapire, et al. Experiments with a new boosting algorithm. In icml,
volume 96, pp. 148-156. Citeseer, 1996.
Hossein Shokri Ghadikolaei, Hadi Ghauch, Carlo Fischione, and Mikael Skoglund. Learning and
data selection in big datasets. In International Conference on Machine Learning, pp. 2191-2200.
PMLR, 2019.
Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran. An efficient framework for
clustered federated learning. arXiv preprint arXiv:2006.04088, 2020.
Mohammad Hesam Hesamian, Wenjing Jia, Xiangjian He, and Paul Kennedy. Deep learning tech-
niques for medical image segmentation: Achievements and challenges. Journal of digital imag-
ing, 32(4):582-596, 2019.
Peter Kairouz, H Brendan McMahan, Brendan Avent, AUrelien BelleL Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Ad-
vances and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
International Conference on Machine Learning, pp. 5132-5143. PMLR, 2020.
Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A unified
theory of decentralized sgd with changing topology and local updates. In International Confer-
ence on Machine Learning, pp. 5381-5393. PMLR, 2020.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, 2009.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges,
methods, and future directions. IEEE Signal Processing Magazine, 37(3):50-60, 2020a.
10
Under review as a conference paper at ICLR 2022
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. In Conference on Machine Learning and
Systems, 2020b.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of
fedavg on non-iid data. In International Conference on Learning Representations, 2020c.
Xiaoxiao Li, Meirui JIANG, Xiaofei Zhang, Michael Kamp, and Qi Dou. FedBN: Federated learn-
ing on non-IID features via local batch normalization. In International Conference on Learning
Representations, 2021.
Xiangru Lian, Wei Zhang, Ce Zhang, and Ji Liu. Asynchronous decentralized parallel stochastic
gradient descent. In International Conference on Machine Learning, pp. 3043-3052. PMLR,
2018.
Paul Pu Liang, Terrance Liu, Liu Ziyin, Nicholas B Allen, Randy P Auerbach, David Brent, Ruslan
Salakhutdinov, and Louis-Philippe Morency. Think locally, act globally: Federated learning with
local and global representations. arXiv preprint arXiv:2001.01523, 2020.
Yujun Lin, Song Han, Huizi Mao, Yu Wang, and William J Dally. Deep gradient compression: Re-
ducing the communication bandwidth for distributed training. arXiv preprint arXiv:1712.01887,
2017.
Tomasz Malisiewicz, Abhinav Gupta, and Alexei A Efros. Ensemble of exemplar-svms for object
detection and beyond. In 2011 International conference on computer vision, pp. 89-96. IEEE,
2011.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial intelli-
gence and statistics, pp. 1273-1282. PMLR, 2017.
Sarthak Pati, Ujjwal Baid, Maximilian Zenk, Brandon Edwards, Micah Sheller, G. Anthony Reina,
Patrick Foley, Alexey Gruzdev, Jason Martin, Shadi Albarqouni, et al. The federated tumor seg-
mentation (fets) challenge, 2021.
Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. In International Conference on Machine Learning, pp. 4334-4343. PMLR,
2018.
Peter Richtarik, Igor Sokolov, and Ilyas Fatkhullin. Ef21: A new, simpler, theoretically better, and
practically faster error feedback. arXiv preprint arXiv:2106.05203, 2021.
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R Roth, Shadi Albarqouni, Spyri-
don Bakas, Mathieu N Galtier, Bennett A Landman, Klaus Maier-Hein, et al. The future of digital
health with federated learning. NPJ digital medicine, 3(1):1-7, 2020.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedi-
cal image segmentation. In International Conference on Medical image computing and computer-
assisted intervention, pp. 234-241. Springer, 2015.
Mark Schmidt and Nicolas Le Roux. Fast convergence of stochastic gradient descent under a strong
growth condition. arXiv preprint arXiv:1308.6370, 2013.
William Shakespeare. The complete works of William Shakespeare. Wordsworth Editions, 2007.
Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng. Meta-weight-
net: learning an explicit mapping for sample weighting. In Proceedings of the 33rd International
Conference on Neural Information Processing Systems, pp. 1919-1930, 2019.
Youyi Song, Lequan Yu, Baiying Lei, Kup-Sze Choi, and Jing Qin. Selective learning from external
data for ct image segmentation. In International Conference on Medical Image Computing and
Computer-Assisted Intervention, pp. 420-430. Springer, 2021.
11
Under review as a conference paper at ICLR 2022
Alysa Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang. Towards personalized federated learning.
arXiv preprint arXiv:2103.00710, 2021.
Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Instance normalization: The missing in-
gredient for fast stylization. arXiv preprint arXiv:1607.08022, 2016.
Sharan Vaswani, Francis Bach, and Mark Schmidt. Fast and faster convergence of sgd for over-
parameterized models and an accelerated perceptron. In The 22nd International Conference on
XrtficiaI Intelligence and Statistics, pp.1195-1204. PMLR, 2019.
Jianyu Wang, Anit Kumar Sahu, Zhouyi Yang, Gauri Joshi, and Soummya Kar. Matcha: Speed-
ing up decentralized sgd via matching decomposition sampling. In 2019 Sixth Indian Control
Conference (ICC), pp. 299-300. IEEE, 2019.
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. Tackling the objective
inconsistency problem in heterogeneous federated optimization. Advances in Neural Information
Processing Systems, 33, 2020.
Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H Brendan McMahan, Maruan Al-Shedivat,
Galen Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data, et al. A field guide to feder-
ated optimization. arXiv preprint arXiv:2107.06917, 2021.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmark-
ing machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept
and applications. ACM Transactions on Intelligent Systems and Technology (TIST), 10(2):1-19,
2019.
Ramy A Zeineldin, Mohamed E Karar, Jan Coburger, Christian R Wirtz, and Oliver Burgert.
Deepseg: deep neural network framework for automatic brain tumor segmentation using mag-
netic resonance flair images. International journal of computer assisted radiology and surgery,
15(6):909-920, 2020.
Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose M Alvarez. Personalized fed-
erated learning with first order model optimization. In International Conference on Learning
Representations, 2020.
12
Under review as a conference paper at ICLR 2022
Appendix
Roadmap of Appendix The Appendix is organized as follows. We provide the theoretical proof of
basic convergence results in Section A and main convergence results in Section B. The details of
experimental setting (e.g., model architectures and dataset preprocessing) are in Section C.
A Proof of Basic Convergence Results
A.1 Preliminaries
Proposition 4. For Y > 0, 2(u, Vi ≤ Y∣∣uk2 + Y∣∣vk2.
Proof. According to Cauchy-Schwarz inequality, we have
2hu, Vi = 2h√γ u, √1γVi ≤ 2k√γuk ∙ k√γVk ≤ Ykuk2 + Y kvk2.
□
Proposition 5. Let PiN=1 pi = 1, pi > 0 for 1 ≤ i ≤ N. Then
NN
EkXpixik2 ≤ XpiEkxik2.
i=1	i=1
Proof. This follows from Jensen’s inequality and the convexity of Ekxk2 .
Lemma 6. For θ ∈ ΘH, we have
□
l(θ*) - l(θ) ≤-ɪkVl(θ)k2.
2L
Proof. Let θ0 = θ 一 LVl(θ). Then
l(θ0) ≤ l(θ) + hVl(θ),θ0 - θi + 2kθ0-θk2
≤ l(θ) + hVl(θ),-1 Vl(θ)i + Lk1 Vl(θ)k2
L	2L
=l(θ)- ɪkVl(θ)k2.
2L
Hence
l(θ*) - l(θ) ≤ l(θ0) - l(θ) ≤-ɪkVl(θ)k2.
□
Lemma 7. Let {an} be the sequence of non-negative real numbers. If0 < α < 1, β > 0, and
an+1 ≤ (1- α)an + β,
then
an ≤ (1 - α)nao + —.
α
Proof. Since
an - - ≤ (1 - α)(an -号,
αα
we can simply prove by induction that
an - - ≤ (1 - α)n[a0 -白,
αα
13
Under review as a conference paper at ICLR 2022
and then
an ≤ (1 — α)nao + [1 — (1 — α)n]—
α
≤ (1 - a)nao + β.
α
□
1
(M + 1tw)2
A.2 Proof of Lemma 1
Proof. We have:
Φ(w; θ)
M	M+N	2
X EkVli(θ) - Vl(θ)k2 + E∣∣ X Wj (Vlj (θ) -Vl(θ))∣∣
i=1	j=M +1
1	M+N	2
≤ (M + 1τw)2 M 2σkvl(θ)k2 + e∣∣ X Wj (VIj (θ)-vl(θ))∣∣
( + w)	j=M+1
=(M +11τw)2 (M2σkvl(θ)k2 + e[(ςTW)T(*Tw)])
=(M +11TW)2 (M2σkvl(θ)k2 + E[wT(ςςT)W]),
(9)
where
VlM+ι(θ) -Vl(θ)'
.	∈ RN×d
.
VlM+N(θ) - Vl(θ)
Since the right hand side of Equation (9) is an upper bound of Φ(w; θ), and we want to make this
upper bound tight by taking its minimum (w.r.t. W):
W = argmin (M +；Tw)2 (M2σkVl(θ)k2 + EiWT(ΣΣτ)w]}
Clearly, whatever W you take, RHS&) will always be no less than Φ(w*; θ).
Let λι ≤ λ2 ≤ ∙∙∙ ≤ λN denote all the N eigenvalues of ΣΣτ. Then
M+N	M+N
Nλι ≤ X λj =trace(∑ΣT) = X EkVlj(θ) -Vl(θ)∣∣2.	(10)
j=M+1	j=M+1
Let e be the corresponding unit eigenvector (i.e.eTe = 1) of λ1. Then, in order to minimize the
RHS(9), W and e must be collinear vectors. Therefore, we can assume that
W = ωe.
Substituting this into RHS(9), we have
(M +11TW)2 (M%kVl@k2 +eIwT(ςςt)wD
=(M + ωiTe)2 (M^wl(θ)k2 + s2E[eT(££T)e])
=(M + I1Te)2 (〃％河(町『+ λιω2) , h(ω)
Take derivative with respect to ω:
dh 2λ1ω(M + ω1τe)2 — (M2σkVl(θ)k2 + λ1ω2) ∙ 21τe(M + ω1τe)
∂ω =	(M + ω1τe)4	= 0.
14
Under review as a conference paper at ICLR 2022
Thus,
ω = λ-1 ∙ 1TeMb||Vl(e)『,
and then
=	σkVl(θ)∣∣2
―1 + X-1(1Te)2b||Vl(e)k2
缪	σ∣∣Vl(θ)∣∣2
-I + N (1Te)2 σ∣∣Vl(θ)∣∣2
+ PMM+ιEkVj(θ)-Vl(θ)k2
1
1 I	N(ITe)2	一
σ∣E(θ)∣∣2 + pMM+i Ek^ij (θ)-vi(θ)k2
According to Assumption 1, we further have
h(ω) -	1 I	N(ITe)2
bgl(θ)k2 + PMM+ι Eku(θκθ)k2
/	1
-	1	+	N(ITe)2	.
σ∣E(θ)∣∣2 + (PM*1叼 )∣E(θ)k2+PM*1Vj
Further, due to AM-HM inequality, we have
h(ω) - M I	N(ITe)2
Mσk▽'⑺k2 + (PMM+ip "Wk2+PMM+ι"j
<	Mσ∣∣Vl(θ)∣∣2 + (1Te)-2 [(£%卷1 K)∣∣Vl(θ)∣∣2 + PM+N+ι Vji
-	(M + N )2
Therefore, Φ(w*; θ) can be finally bounded as follows:
Φ(w*; θ) — h(ω)—
Mσ∣∣Vl(θ)∣∣2 + (ITe)-2 [(£曙霜1 K)∣∣Vl(θ)∣∣2 +
∑M=+M+1 T
(M + N )2
Mσ + (1Te)-2 PM+M+1 κ	(1Te)-2 ∑MMζ1 V
-------(M + N )2----------kVl(e)k +—(M + N )2—
S------------V------------'	S--------V----------'
A	B
(11)
A∣∣Vl(θ)∣∣2 + B.
□
Comments. From Formula (11), we can observe that B is mainly determined by PMM+1 Vj, i.e.
the noises in the external datasets.
A.3 Proof of Theorem 2
Proof. Due to the μ-strongly convexity, we have
l(θ*) ≥ l(θt) + (Vl(θt),θ* - θti + μ∣∣θ* -叫2
=l(θt) + hVl(θt; w),θ* - θti - hVl(θt; w) - Vl(θt),θ* - θti + μ∣∣θ* - θtk2
≥ l(θt) + hVl(θt; w),θ* - θti + 2∣θ* - θtk2
-	1 卜 1∣Vl(θt; w) - Vl(θt)k2 + ɪ ∣∣θ* - θtk2
2 L	71」
=l(θt) + hVl(θt; w),θ* - θti + (2 -*)∣θ* - θtk2 - γ1 ∣Vl(θt; w) - Vl(θt)k2,
(12)
15
Under review as a conference paper at ICLR 2022
where γι > 0.
Since θt+1 = θt — η^l(θt; w), it yields
(yi(θt; w),θ* — θti = —1 hθt+1 — θt,θ* — θti
η
=—ɪ [∣∣θt+1 — θtk2 + ∣∣θ* — θtk2 — ∣∣θ* — θt+1k2]
1	(13)
=—Tr [η2∣Vl(θt; w)k2 + ∣θ* — θtk2 — ∣θ* — θt+1k2]
—η ∣Vl(θt; W)k2 —白 ∣θ* — θtk2 + 21 ∣∣θ* — θt+1k2.
η	2η	2 η
Based on Lemma 1, we have
E∣Vl(θt; w*) — Vl(θt)∣2 ≤ AEkVl(θt)∣2 + B,
and then
E∣Vl(θt; w*)∣2 = E∣Vl(θt) + Vl(θt; w*) — Vl(θt)∣2
≤	γ2E∣∣Vl(θt)k2 + ɪE∣Vl(θt; w*) — Vl(θt)∣2
Y2
≤	γ2E∣∣Vl(θt)k2 + ɪ (AEkVl(θt)∣2 + B)
Y2
= (γ2 + A)EkVl(θt)∣2 + B,
Y2	Y2
where γ > 0.
Substituting it into Equation (13), we have
E{Vl(θt; w*),θ* — θti
≥ — η	[(72	+ A)EkVl(θt)k2 +	b-1	— ɪE∣∣θ* — θtk2 +	ɪE∣∣θ*	— θt+1k2.
2	L 72	72」2η	2η
(14)
(15)
Then, substituting Formula (14), (15) into Inequality (12), we have
E[l(θ*)]	≥ E[l(θt)]	— η [(72	+ A)EkVl(θt)k2	+ b-1	— ɪEkθ*	— θtk2 + ɪE∣∣θ*	— θt+1∣∣2
2	72	72	2η	2η
+ (μ — 4)Ekθ* — θtk2 —我(AEkVl(θt)k2 + B).
2	2γi	2
Rewrite the above formula as:
E∣∣θ* — θt+1k2 ≤ (1 — (ημ — — ))E∣∣θ* — θt∣∣2 + 2ηE [l(θ*) — l(θt)]
+ (Aη71 + M + η272)EkVl(θt)k2 + (η2 + η71)B,
72	72
and then, it follows from Lemma 6 that
E∣∣θ* — θt+1k2 ≤ (1 — (ημ — ɪ)E∣∣θ* — θt∣∣2 — — E∣∣Vl(θt)k2
71	L
+ (Aη71 + Aη2 + η272)EkVl(θt)k2 + (η2 + η71 )B
72	72
2
≤ (1 — (ημ-------))Ekθ* — θtk2 + (—+ η71)B,
71	72
where L ≥ A71 + A + η72 and μ >	.2
1 A
2Ifs easy to verify that γι and γ exist when η < L-μ .
16
Under review as a conference paper at ICLR 2022
Finally, according to Lemma 7, we have
E∣∣θ* - θtk2 ≤ (1 - (ημ - ɪ))tE∣∣θ* - θ0k2 +
"+ γι
Y2	/ 1
μ----
γ	Yi
B.
□
B Proof of Main Convergence Results
B.1 PRELIMINARIES
To simplify, we introduce the following notations:
1 M
θI = M X θi,
θ . p3 %+PMM∖ Wθ = mθi+PMM+ι 叼%
W =	M + 1Tw	= M + 1Tw	.
Thus,
θt+1 = θt+ τ+ι W.
Lemma 8. For 0 ≤ k ≤ T - 1,
E∣∣θt+ τ+1 -θt+ τ+ι w∣∣2 ≤ 4η2k2G2.	(16)
Proof. Prove by induction. Inequality 16 holds for k = 0. Assume that it also holds for k - 1,
0 < k < τ. Then,
E ∣ ∣ θt+壬-θt+τ+1w∣∣
=E ∣ ∣ θt+ τ+1 - θt+ k+1 + θt+ k+1 - θt+ τ+τ W + θt+ ⅛1 W - θt+ τ⅛1 w∣∣
≤ E ∣ ∣ θt+τ+i - θt+M ∣∣ + e∣ ∣θt+靠-θt+⅛1 w∣∣ + E∣∣θt+τ⅜τ w - θt+k+1 w∣∣
≤ ηG + 2η(k - 1)G + ηG
=2ηkG.
Hence, E∣ ∣ θt+ τ+τ - θt+ 壬w∣∣2 ≤ 4η2k2G2.
□
17
Under review as a conference paper at ICLR 2022
B.2 Proof OF Theorem 3
Proof. According to Assumption 2a, we have
E
M	M	M+N	,	-∣
M+⅛w(Xv∕i(θt+中)+ X WjVj(θj+中川
i=1	j=M +1	」
≤ E[l(θt+ 壬W)]
_____ M	卜	M+N	卜
-M+⅛w E(Vl(θt+ 壬 w), X vli(θt+ E )+ X Wj Vj (θj+E )〉
ɪ	i=1	j=M +1
、----------------------------V------------------------------}
Ti
(17)
τ 2	IM	K	M +N	K	0
+ -TEMTiTW(XVlM+E)+ X WjVlj(θj+E川
i=1	j=M +1
、-------------V-------------}
T2
，E[l(θt+ 壬w)] + T1 + T.
Then we are to bound the T and T in Equation 17 respectively.
For T1 , we have
「M	______ 工	M+N	______ 工
TI = - M JITWE X (v∕(θt+ τ⅛τw), V∕i(θt+ E))+ X Wj(v∕(θt+ τ⅛τW), RIj(θt+ E)
十	Li=1 ∖	j=M+1
M+N
=-M +71twE (M + X Wj)DV(铲+4Tw),VW+τ+τw))
j=M+1
M	k
-X <Vl(θt+ τ+τw), Vl(θt+ τ+τw) - Vli(θi τ+1 ))
i=1
M+N	_____ _____________ 卜 -∣
- X Wj(Vl(θt+ τ+τ w), Vl(θt+ τ+τW) -Vlj(θt+ τ+τ)M
j=M+1
=FEllVl(K w)『+m⅛w XVI(K w),
M	____ 卜	M+N	_______ 卜 、
X (Vl^t+τ+τw) - Vli(θt+τ+τ))+ X Wj (Vl(θt+4TW) -Vlj(θt+τ+τ)))，
i=1	j=M+1	/
and further, since (U1, v。≤ γ1∣∣u1∣∣2 + a ∣∣v1∣∣2, it yields
T1 ≤ (-η + γιη)E∣∣Vl(θt+4Tw)∣ l 2
η	PMa (Vl(θt+4T W) - Vli(θt+ 壬))+ PM；MVHI Wj(Vl(θt+4T W) - Vlj (θj+ τ+τ)) 2
4 4γ1 ®	M + 1tw
=(-η + γιη)E∣ ∣ Vl(θt+4T w)∣ ∣ 2
+ ɪ E VI(Kw) - PNI 环婷4T)+ PM⅞1 Wj VIj (θj+4τ) 2
4γι	v	M	M + 1tw
、---------------------------V-------------------------}
T3
，(-η + Yιη)E∣ ∣ VlW+ 占w)∣ ∣ 2 + 言T3,
(18)
18
Under review as a conference paper at ICLR 2022
where 0<γι < 1.
For T2, we have
2	2	-ɪ	M	K	M+N	K	C
T2 = ~τEllMTlTw(Xvli(θt+E)+ X Wjv/j(θt+E))||
i=1	j=M+1
=萼 E Vl(θt+ τ+1 W)
∑M=1 (vιi(θt+壬)-Vl(θt+τ⅛τw)) + PM+N+1 Wj(VIj(θj+壬)-Vl(θt+τ⅛τW)) 2
+	M + 1TW
and further, since ∣∣u2 + v2∣∣2 = ∣∣u2∣∣2 + ∣∣v21∣2 +2〈山,r2≤ (1 + γ2)∣∣u2∣∣2 + (1 + 击)∣∣v2∣∣2,
it yields
+(1 + 壶)L叽 v.(K)PM1 vli(θt+τ+τ) + PM+N+1 WjVIj (θt+τ+τ) 2
+ -2- E Vl (θ τ+1 W)---------------M + 1Tw-------------
S----------------------V----------------------}
丁：十 τ+τ)
，(1 + ”2 E Vl(θt+^w) 2 +(1 + FLn2 球+ τ+τ),
where 72 > 0.
(19)
Therefore, putting Equation 17, 18, 19 together, we have
E l{θt+ 串W) = E[l(θt+ τ+τW)] + Ti + T2
≤ E[l(θt+τ+τW)] - ((1- 71)η - (1+272%2) ∙ E∣∣Vl(θt+⅛w)∣∣2 (20)
+ (看 + ∖22 )「).
Let Γo = (1 - 71) - (1+γ2)Lη, and Γι = ± + (1+ 弓)".Summing over k from 0 to T - 1 in
Equation 20, we have
T — 1	______
X E∣∣Vl(θt+τ+τ W)
k=0
E[l(θtw)] - E[l(θt+ τ+τw)]
ηro
+ΓιX Tff)
U k=0
E[l(θt)] - E[l(θt+1)]
ηΓo
+Γ X T3"f)
0 k=0
≤
(21)
19
Under review as a conference paper at ICLR 2022
Then, we are to bound Pk-0 T3(t+ τ+1)
，(叶丰)—E v,fθt+⅛)PM=1 ▽，欣+τ+τ)+PMXI WjEj 婷*) 2
3	-E EW W)	M + 1Tw
≤ (1 + Y3)E
▽ " 3+⅛)	PM=1 Ew 壬 W ) + PM+N+1 Wj Ej (θt+ τ⅛ W )
EW τ+1 W)	M + ITw
2
1	pg (ew+4 W)- Eia 告T)
+ (1 + F)E	M + ITw
PM+N+1 Wj (Ej (θt+τ+1 w) - Ej (θj+ τ+τ)) 2
+	M + ITW
≤ (1 + Y3)E
)	p3 Ei(θt+壬 w)+pM+N+ι Wj Ej (θt+τ+τ w)
EW τ+1 W)	M + ITw
2
+ (1 + ɪ) ∙ 4L2η2k2G2
Y3
=(1+ Y3)Φ(w; θt+ τ+FT W) + (4 + 2)L2η2k2G2
Y3
≤ (1+ γ3)A∣∣E(θt+ τ++τW) I I 2 + (1+ γ3)B + (4+ W)L2η2k2G2,
and then
T — 1	卜 T — 1	_______
XT(t+E) ≤ X(1 + 73)A∣∣vi(θt+τ+τW)∣∣2
k=0	k=0
+ (1 + Y3)τB + (| + ---)L2η2G2(2τ3 一 3丁2 + T).
3	373
X-----------------------V------------------------}
「2
(22)
Substituting Formula (22) into Inequality (21), we have
τ —1	_____ 2
η、(「0-(1+ 73)AΓ1),XE∣∣Vl(θt+τ+τW)∣∣ ≤ E[l(θt)] - E[l(θt+1)] + ηΓ1Γ2,
'------V---------' k=0
「3
or
τ —1	_____ 2
X e∣ ∣vl(θt+* w"∣ ∣
k=0
E[l(θt)] - E[l(θt+1)]
ηΓ3
Γ1Γ2
+ ^7T
Summing over t from 0 to T — 1 and dividing by τT, we have:3
1 T —1 T —1	______ 2
TTXXe ∣ ∣ vl(θt+4τw" ∣ ∣ ≤
ι(θ0) - I(θ*) + Γ1Γ2
ηΓ3TT	Γ3T
□
C Experimental Details
C.1 Model Architectures
In synthesized experiments, we mainly follow the model architectures used in McMahan et al.
(2017). The logistic model is a 784 × 10 fully connected layer. The 2NN model consists of a
3Ifs easy to verify that the constants in the derivation exist when η < ；:；^A).
20
Under review as a conference paper at ICLR 2022
784 × 200 hidden layer, another 200 × 200 hidden layer, and a final 200 × 47 output layer. The CNN
model consists of a convolution layer with 5 × 5 kernel and 32 channels, another convolution layer
with same kernel size and 64 channels, a fully connected layer with 512 units with ReLU activation,
and a final 512 × 10 output layer. For all three model outputs, we use cross entropy loss.
In Shakespeare experiment, we use a 8-dimension embedding, a 2-layer character LSTM with 256
hidden units, and a final 256 × 90 output layer. We use cross entropy loss that ignores empty words
in the truncated sentence.
In FeTS2021 experiment, we follow the U-Net structure in Ronneberger et al. (2015). There are
three slight modifications: (1) The input image is resized to 120 × 120; (2) We halves the channel
sizes to (32, 64, 128, 256, 512, 256, 128, 64, 32); (3) We replace the batch normalization layer with
instance normalization layer.
C.2 Dataset Preprocessing
In synthesized experiments, we mainly follow the preprocessing methods suggested in McMahan
et al. (2017). The Fashion-MNIST dataset is split into 120 shards, each of which has 500 samples of
one single digit. Assign each of the 60 clients two shards. Two of the clients are chosen as internal
clients. The EMNIST-Balanced dataset is split into 600 shards, each of which has 180 samples
of one single category. Assign each client 24 shards with continuous category indices. Two of
the clients are chosen as internal clients. The CIFAR-10 dataset is partitioned in the same way as
Fashion-MNIST. For all three synthesized experiments, the communication threshold K is set to 10.
In Shakespeare experiments, there are altogether 715 clients, each of whom corresponds to one role
in one of the six classic plays of Shakespeare. Then all the clients are naturally classified into 6
groups, according to which of the six plays they belong to. The clients’ datasets are formed by their
lines in the play. To simplify the training, we truncate each line into segments of 80 characters. Each
time we designate the clients in one group as internal clients, and the remaining clients as external
clients. The communication threshold K is set to 50.
In FeTS2021 experiments, as shown in Figure 3, there are altogether 17 medical sites. There are
only 341 different volumes, so we only choose the three largest sites (numbered 1, 6 and 16) as
internal sites in our experiments. We did not choose the remaining sites as internal sites since they
are too small to separate a test set of appropriate size. Further, we divide the chosen internal site
into three balanced parts to form the group of internal clients. Moreover, to simplify the training,
all client samples are resized to 120 × 120 and all the 3 different lesion labels are merged for whole
brain tumor segmentation. Finally, we set the communication threshold K to 4.
21
Under review as a conference paper at ICLR 2022
Natural split
S ① seuJo」9qlurlN
Figure 3: The natural partition of 17 medical sites in FeTS2021. The figure is downloaded from
https://fets-ai.github.io/Challenge/data/.
22