title,year,conference
 Muppet: Massive multi-task representations with pre-finetuning,2021, arXiv preprintarXiv:2101
 Learning to recombine and resample datafor compositional generalization,2020, ArXiv
 Good-enough compositional data augmentation,2020, In ACL
 Learning phrase representations using RNN encoder-decoder forstatistical machine translation,2014, In Proceedings of the 2014 Conference on Empirical Methods inNatural Language Processing (EMNLP)
 Meta-learning to compositionally gener-alize,2021, In Proceedings of the 59th Annual Meeting of the Association for Computational Linguisticsand the 11th International Joint Conference on Natural Language Processing (Volume 1: LongPapers)
 Improving text-to-SQL evaluation methodology,2018, In Proceedingsof the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: LongPapers)
 Compositional generalizationin semantic parsing: Pre-training vs,2020, specialized architectures
 Permutation equivariantmodels for compositional generalization in language,2020, In International Conference on LearningRepresentations
 A joint many-taskmodel: Growing a neural network for multiple NLP tasks,2016, In NIPS 2016 Continual Learning andDeep Networks Workshop
 Measuring compositional generalization: A comprehensivemethod on realistic data,2020, In ICLR
 COGS: A compositional generalization challenge based on semanticinterpretation,2020, In Proceedings of the 2020 Conference on Empirical Methods in Natural LanguageProcessing (EMNLP)
 Compositional generalization through meta sequence-to-sequence learning,2019, InH
 Generalization without systematicity: On the compositionalskills of sequence-to-sequence recurrent networks,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Compositional generalization by learning analytical expressions,2020, Advancesin Neural Information Processing Systems
 Learningcompositional rules via neural program synthesis,2020, arXiv preprint arXiv:2003
 Sentence encoders on stilts: Supplementarytraining on intermediate labeled-data tasks,2018, arXiv preprint arXiv:1811
 An overview of multi-task learning in deep neural networks,2017, arXiv preprintarXiv:1706
 Compositional generalization in adeep seq2seq model by separating syntax and semantics,2019, arXiv preprint arXiv:1904
 Syntactic scaffolds for semantic structures,2018, In Proceedings of the 2018 Conference onEmpirical Methods in Natural Language Processing
 Well-read students learn better:The impact of student initialization on knowledge distillation,2019, CoRR
 Attention is all you need,2017, In I
 Compositional generalization for neural semantic parsing viaspan-level supervised attention,2021, In Proceedings of the 2021 Conference of the North AmericanChapter of the Association for Computational Linguistics: Human Language Technologies
 Using Inductive Logic Programming to Automate the Construction of NaturalLanguage Parsers,1995, PhD thesis
 Compositional generalization via semantic tagging,2020, arXiv preprintarXiv:2010
