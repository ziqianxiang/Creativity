title,year,conference
 Hyperparameter opti-mization of deep neUral networks: Combining hyperband with bayesian model selection,2017, InConference sur IApprentissage Automatique
 Learning to learn withoUt gradient descent by gradientdescent,2017, In Proceedings of the 34th International Conference on Machine Learning
 Statistical comparisons of classifiers over mUltiple data sets,2006, J
 BERT: pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Nas-bench-201: Extending the scope of reproducible neural architec-ture search,2020, In 8th International Conference on Learning RePresentations
 BOHB: robust and efficient hyperparameter opti-mization at scale,2018, In Proceedings of the 35th International Conference on Machine Learning
 Forward and reversegradient-based hyperparameter optimization,2017, In Proceedings of the 34th International Conferenceon Machine Learning
 Non-stochastic best arm identification and hyperparameteroptimization,2016, In Proceedings of the 19th International Conference on Artificial Intelligence andStatistics
 Efficient global optimization of ex-pensive black-box functions,1998, J
 Hyper-band: A novel bandit-based approach to hyperparameter optimization,2017, J
 Multi-fidelity bayesian optimizationvia deep neural networks,2020, In Advances in Neural Information Processing Systems 33: AnnualConference on Neural Information Processing Systems 2020
 Gradient-based hyperparameter opti-mization through reversible learning,2015, In Proceedings of the 32nd International Conference onMachine Learning
 Using a thousand optimization tasks to learn hyperparameter search strategies,2020, CoRR
 Scalable hyper-parameter transfer learning,2018, In Advances in Neural Information Processing Systems 31: AnnualConference on Neural Information Processing Systems 2018
 Practical bayesian optimization ofmachine learning algorithms,2012, In Advances in Neural Information Processing Systems25: 26th Annual Conference on Neural Information Processing Systems 2012
 Freeze-thaw bayesian optimization,2014, CoRR
 Combination of hyperband and bayesian optimizationfor hyperparameter optimization in deep learning,2018, CoRR
 Deep kernellearning,2016, In Proceedings of the 19th International Conference on Artificial Intelligence andStatistics
 Auto-pytorch: Multi-fidelity metalearning forefficient and robust autodl,2021, IEEE Trans
