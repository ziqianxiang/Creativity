title,year,conference
 Square attack: a query-efficient black-box adversarial attack via random search,2020, ArXiv
 Obfuscated gradients give a false sense of security:Circumventing defenses to adversarial examples,2018, ArXiv
 The theory and practice of item response theory,2008, 2008
 Instance adaptive adversarial training: Improved accuracytradeoffs in neural nets,2019, ArXiv
 Curriculum learning,2009, In ICML ’09
 Curriculum adversarial training,2018, ArXiv
 Towards evaluating the robustness of neural networks,2017, 2017 IEEESymposium on Security and Privacy (SP)
 Unlabeled dataimproves adversarial robustness,2019, ArXiv
 Active bias: Training more accurateneural networks by emphasizing high variance samples,2017, In NIPS
 Ead: Elastic-net attacks to deep neuralnetworks via adversarial examples,2018, ArXiv
 Robustoverfitting may be mitigated by properly learned smoothening,2021, In ICLR
 Cat: Customized adversarial trainingfor improved robustness,2020, ArXiv
 Reliable evaluation of adversarial robustness with an ensemble of diverseparameter-free attacks,2020, In ICML
 Learnable boundary guided adversarial training,2020, ArXiv
 On the sensitivity ofadversarial robustness to input data distributions,2019, ArXiv
 Limitations of adversarial robustness: strong no free lunch theorem,2018, ArXiv
 Item response theory for psychologists,2000, 2000
 Evaluating and understanding the robustness ofadversarial logit pairing,2018, ArXiv
 A decision-theoretic generalization of on-line learning and an applicationto boosting,1995, In EuroCOLT
 Explaining and harnessing adversarialexamples,2015, CoRR
 Uncovering the limitsof adversarial training against norm-bounded adversarial examples,2020, ArXiv
 Improving robustness using generated data,2021, ArXiv
 Let’s agree to agree: Neural networks shareclassification order on real datasets,2019, arXiv: Learning
 Using pre-training can improve model robustnessand uncertainty,2019, In ICML
 Self-adaptive training: beyond empirical riskminimization,2020, ArXiv
 Precise tradeoffs in adversarial training for linearregression,2020, In COLT
 Adversarial logit pairing,2018, ArXiv
 Reluplex: An efficient smtsolver for verifying deep neural networks,2017, ArXiv
 Learning multiple layers of features from tiny images,2009, 2009
 Self-paced learning for latent variable models,2010, In NIPS
 Adversarial machine learning at scale,2017, ArXiv
 Tiny imagenet visual recognition challenge,2015, 2015
 Gradient-based learning applied to documentrecognition,1998, 1998
 Gradient descent with early stopping is provablyrobust to label noise for overparameterized neural networks,2020, ArXiv
 Towards deep learningmodels resistant to adversarial attacks,2018, ArXiv
 Virtual adversarial training: A regulariza-tion method for supervised and semi-supervised learning,2019, IEEE Transactions on Pattern Analysisand Machine Intelligence
 Confidence-aware learning fordeep neural networks,2020, In ICML
 Deepfool: A simple andaccurate method to fool deep neural networks,2016, 2016 IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 Logit pairingmethods can fool gradient-based attacks,2018, ArXiv
 Robustness to adversarial perturbationsin learning from incomplete data,2019, ArXiv
 Adversarial robustness may be at odds with simplicity,2019, ArXiv
 Adversarial robustness toolbox v1,2018,2
 Pervasive label errors in test sets destabilizemachine learning benchmarks,2021, ArXiv
 Towards the science ofsecurity and privacy in machine learning,2016, ArXiv
 Practicalblack-box attacks against machine learning,2017, Proceedings of the 2017 ACM on Asia Conference onComputer and Communications Security
 Adversarial perturbations prevail inthe y-channel of the ycbcr color space,2020, ArXiv
 Defense-friendly images in adversarial attacks:Dataset and metrics for perturbation difficulty,2020, ArXiv
 Analysis of instance hardness in machinelearning using item response theory,2015, 2015
 Adversarial robustness through local linearization,2019, InNeurIPS
 Overfitting in adversarially robust deep learning,2020, ArXiv
 Adversarial training is a form of data-dependentoperator norm regularization,2020, arXiv: Learning
 Are accuracy and robustness correlated,2016, 201615th IEEEInternational Conference on Machine Learning and Applications (ICMLA)
 Adversarially robustgeneralization requires more data,2018, In NeurIPS
 Training region-based object detectorswith online hard example mining,2016, 2016 IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Very deep convolutional networks for large-scale imagerecognition,2015, CoRR
 Low curvature activations reduce overfittingin adversarial training,2021, ArXiv
 Improving classification accuracy by identifying and removing instancesthat should be misclassified,2011, The 2011 International Joint Conference on Neural Networks
 An instance level analysis of data complexity,2013, MachineLearning
 Guided adversarialattack for evaluating and enhancing adversarial defenses,2020, ArXiv
 Relating adversarially robust generalization to flatminima,2021, ArXiv
 Is robustness the cost ofaccuracy? - a comprehensive study on the robustness of 18 deep image classification models,2018, InECCV
 An empirical study of example forgetting during deep neural network learning,2019, ArXiv
 Ensemble adversarialtraining: Attacks and defenses,2018, ArXiv
 On adaptive attacks to adversarial exampledefenses,2020, ArXiv
 Robustness may be at oddswith accuracy,2019, arXiv: Machine Learning
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improving adversarialrobustness requires revisiting misclassified examples,2020, In ICLR
 Towards understanding the regularization of adversarial robustnesson neural networks,2020, ArXiv
 Evalu-ating the robustness of neural networks: An extreme value theory approach,2018, ArXiv
 Robustness for non-parametricclassification: A generic attack and defense,2020, In AISTATS
 A closer look ataccuracy vs,2020, robustness
 Wide residual networks,2016, ArXiv
 Attacks which do not kill training make adversarial learning stronger,2020, ArXiv
 Curriculum learning by dynamic instance hardness,2020, In NeurIPS
