title,year,conference
 Blind backdoors in deep learning models,2020, arXivpreprint arXiv:2005
 Sentinet: Detecting localized universalattacks against deep learning systems,2020, In 2020 IEEE Security and Privacy Workshops (SPW)
 Hardware trojan attacks on neural networks,2018, arXiv preprintarXiv:1806
 Exploiting correcting codes:On the effectiveness of ecc memory against rowhammer attacks,2019, In 2019 IEEE Symposium onSecurity and Privacy (SP)
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Another flip in the wall of rowhammer defenses,2018, In 2018IEEE Symposium on Security and Privacy (SP)
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint arXiv:1708
 Trojaning attack on neUral networks,2017, 2017b
 8-bit inference with TensorRT,2017, NVIDIA GPU Technology Conference
 Deep neUral networks are easily fooled: High confi-dence predictions for Unrecognizable images,2015, In Proceedings of the IEEE conference on comPutervision and Pattern recognition
 A tale of evil twins: Adversarial inpUts versUs poisoned models,2020, In Proceedingsof the 2020 ACM SIGSAC Conference on ComPuter and Communications Security
 Combinatorial oPtimization: algorithms and com-Plexity,1998, CoUrier Corporation
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In Proceedings of the IEEE international conference on computer vision
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Defeating software mitigationsagainst rowhammer: a surgical precision hammer,2018, In International Symposium on Research inAttacks
