title,year,conference
 Finite-time analysis of the multiarmed banditproblem,2002, Machine learning
 Dynamic programming,1966, Science
 Finite memory multiple hypothesistesting: Close-to-optimal schemes for bernoulli problems,1978, IEEE Transactions on InformationTheory
 The two-armed-bandit problem with time-invariant finitememory,1970, IEEE Transactions on Information Theory
 The neural basis of decision making,2007, Annual review ofneuroscience
 Memory augmented control networks,2017, arXiv preprint arXiv:1709
 Recurrentreinforcement learning: a hybrid approach,2015, arXiv preprint arXiv:1509
 Solv-ing pomdps by searching the space of finite policies,1999, In Kathryn B
 Learning finite-statecontrollers for partially observable environments,2013, arXiv preprint arXiv:1301
 Automatic differentiation inpytorch,2017, 2017
 Monte-carlo planning in large pomdps,2010, Neural Information ProcessingSystems
 The optimal control of partially observable markovprocesses over a finite horizon,1973, Operations research
 Despot: Online pomdp planning withregularization,2013, In NIPS
 Reinforcement learning: An introduction,2018, MIT press
 Representing hierarchicalpomdps as dbns for multi-scale robot localization,2004, In IEEE International Conference on Roboticsand Automation
 The act of remembering: A study in partially observablereinforcement learning,2020, arXiv:2010
 Hierarchical pomdp controller optimizationby likelihood maximization,2008, In UAI
 Bounded Memory and Biases in Information Processing,1468, Econometrica
 Multiple hypothesis testing by finite memory algorithms,1974, The Annals ofStatistics
 Learning deepneural network policies with continuous memory states,2016, In 2016 IEEE International Conferenceon Robotics and Automation (ICRA)
