title,year,conference
 Bayesian Posterior Sampling via StochasticGradient Fisher Scoring,2012, In Proc
 A Statistical Theory of Cold Posteriors in Deep Neural Networks,2021, In Proc
 Towards Optimal Scaling OfMetropolis-coupled Markov Chain Monte Carlo,2011, Statistics and Computing
 Tight Nonparametric Convergence Rates forStochastic Gradient Descent under the Noiseless Linear Model,2020, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Entropy-SGD: Biasing Gradient Descentinto Wide Valleys,2017, In Proc
 Stochastic Gradient Hamiltonian Monte Carlo,2014, InProc
 Statistical Inference for Model Parametersin Stochastic Gradient Descent,2020, Annals of Statistics
 Accelerating Nonconvex Learningvia Replica Exchange Langevin Diffusion,2019, In Proc
 Information Theory: Coding Theorems for Discrete MemorylessSystems,2011, Cambridge University Press
 Non-Convex Learning via ReplicaExchange Stochastic Gradient MCMC,2020, In Proc
 Accelerating Conver-gence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction,2021, In Proc
 Replica Exchange for Non-Convex Optimization,2021, arXiv:2001
 On the Infinite Swapping Limit for ParallelTempering,2012, SIAM J
 Sampling from a Strongly Log-concave Distribution with theUnadjusted Langevin Algorithm,2016, arXiv:1605
 Weak Convergence and Optimal Scaling of RandomWalk Metropolis Algorithms,1997, Annals of Applied Probability
 Deep Residual Learning for ImageRecognition,2016, In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 In Proc,2018, of the Conferenceon Uncertainty in Artificial Intelligence (UAI)
 Austerity in MCMC Land: Cutting the Metropolis-Hastings Budget,2014, In Proc
 Simple and Scalable PredictiveUncertainty Estimation using Deep Ensemble,2017, In Advances in Neural Information ProcessingSystems (NeurIPS)
 Preconditioned StochasticGradient Langevin Dynamics for Deep Neural Networks,2016, In Proc
 Efficiency of ExchangeSchemes in Replica Exchange,2009, Chemical Physics Letters
 ASimple Baseline for Bayesian Uncertainty in Deep Learning,2019, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Convex Optimization with Unbounded Nonconvex Oraclesusing Simulated Annealing,2018, In Proc
 Ergodicity for SDEs and Approximations: LocallyLipschitz Vector Fields and Degenerate Noise,2002, Stochastic Processes and their Applications
 Generalized Ensemble and Tempering Simulations: AUnified View,2007, Phys
 Dynamics and Optimal Number of Replicas in ParallelTempering Simulations,2007, Phys
 Replica Exchange MonteCarlo Method for the Isobaric-isothermal Ensemble,2001, Chemical Physics Letters
 The Incomplete Beta Function Lawfor Parallel Pempering Sampling of Classical Canonical Systems,2004, Chemical Physics Letters
 Non-convex Learning via StochasticGradient Langevin Dynamics: a Nonasymptotic Analysis,2017, In Proc
 Approximation Analysis of Stochastic Gradient Langevin Dynamicsby Using Fokker-Planck Equation and Ito Process,2014, In Proc
 An Efficient Minibatch Acceptance Test forMetropolis-Hastings,2017, In Proc
 Non-Reversible Parallel Tempering: a Scalable Highly Parallel MCMC scheme,2021, arXiv:1905
 Bayesian Learning via Stochastic Gradient Langevin Dynamics,2011, InProc
 How Good is the BayesPosterior in Deep Neural Networks Really? In Proc,2020, of the International Conference on MachineLearning (ICML)
 Global Convergence of Langevin DynamicsBased Algorithms for Nonconvex Optimization,2018, In Advances in Neural Information ProcessingSystems (NeurIPS)
 Hybrid Switching Diffusions: Properties and Applications,2010, Springer
 CyclicalStochastic Gradient MCMC for Bayesian Deep Learning,2020, In Proc
 The Anisotropic Noise in StochasticGradient Descent: Its Behavior of Escaping from Sharp Minima and Regularization Effects,2019, InProc
 BenignOverfitting of Constant-Stepsize SGD for Linear Regression,2021, In Proc
 According to Eq,2022,(32)
