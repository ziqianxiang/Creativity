title,year,conference
 Guidelines for human-aiinteraction,2019, In Proceedings of the 2019 chi conference on human factors in computing systems
 Explainable machine learning in de-ployment,2020, In Proceedings of the 2020 Conference on Fairness
 Eye-tracking metrics in perception and vi-sual attention research,2017, EJMT
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Visualizing higher-layerfeatures of a deep network,2009, University of Montreal
 Interpretable explanations of black boxes by meaningful perturba-tion,2017, In Proceedings of the IEEE International Conference on Computer Vision
 Datasheets for datasets,2018, arXiv preprint arXiv:1803
 Interpretation of neural networks is fragile,2019, InProceedings of the AAAI Conference on Artificial Intelligence
 Chexpert: A large chestradiograph dataset with uncertainty labels and expert comparison,2019, In Proceedings of the AAAIconference on artificial intelligence
 Adv-watermark: A novel wa-termark perturbation for adversarial examples,2020, In Proceedings of the 28th ACM InternationalConference on Multimedia
 The work that visualisationconventions do,2016, Information
 An algebraic process for visualization design,2014, IEEEtransactions on visualization and computer graphics
 A unified approach to interpreting model predictions,2017, arXiv preprintarXiv:1705
 Model cards for model reporting,2019, InProceedings of the conference on fairness
 Interpretable Machine Learning,2019, 2019
 Methods for interpreting and un-derstanding deep neural networks,2018, Digital Signal Processing
 The building blocks of interpretability,2018, Distill
 Rise: Randomized input sampling for explanation ofblack-box models,2018, arXiv preprint arXiv:1806
 “Why Should I Trust You?”: Explain-ing the predictions of any classifier,2016, In Proceedings of the 22nd ACM SIGKDD internationalconference on knowledge discovery and data mining
 Evaluating the visualization of what a deep neural network has learned,2016, IEEE transactionson neural networks and learning systems
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In Proceedings of the IEEE international conference on computer vision
 Learning important features throughpropagating activation differences,2017, In International Conference on Machine Learning
 Deep inside convolutional networks: Vi-sualising image classification models and saliency maps,2013, arXiv preprint arXiv:1312
 Smoothgrad:removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Striving forsimplicity: The all convolutional net,2014, arXiv preprint arXiv:1412
 Axiomatic attribution for deep networks,2017, InInternational Conference on Machine Learning
 Exploring principledvisualizations for deep network attributions,2019, In IUI Workshops
 Sanitychecks for saliency metrics,2020, In Proceedings of the AAAI conference on artificial intelligence
 What clinicianswant: contextualizing explainable machine learning for clinical end use,2019, In Machine learning forhealthcare conference
 Eye movements and vision,2013, Springer
