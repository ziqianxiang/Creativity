title,year,conference
 Deep learning with differential privacy,2016, In Proceedings of the 2016 ACM SIGSACConference on Computer and Communications Security
 Privacy amplification by subsampling: Tightanalyses via couplings and divergences,2018, In Proceedings of the 32nd International Conference onNeural Information Processing Systems
 A little is enough: Circumventing defensesfor distributed learning,2019, In Advances in Neural Information Processing Systems 32: AnnualConference on Neural Information Processing Systems 2019
 Private empirical risk minimization: Efficientalgorithms and tight error bounds,2014, In 2014 IEEE 55th Annual Symposium on Foundations ofComputer Science
 Large-scale machine learning with stochastic gradient descent,2010, In Yves Lechevallierand Gilbert Saporta (eds
 Optimization methods for large-scale machinelearning,2018, Siam Review
 Differentially private stochastic coordinate descent,2021, Proceedings of the AAAIConference on Artificial Intelligence
 Largescale distributed deep networks,2012, In F
 The algorithmic foundations of differential privacy,2014, Foundationsand Trends in Theoretical Computer Science
 The hidden vulnerability ofdistributed learning in Byzantium,2018, In Jennifer Dy and Andreas Krause (eds
 Distributed momentum forbyzantine-resilient stochastic gradient descent,2021, In 9th International Conference on LearningRepresentations
 Privacy-preserving distributed learning via obfuscated stochasticgradients,2018, In 2018 IEEE Conference on Decision and Control (CDC)
 The composition theorem for differentialprivacy,2015, In Francis Bach and David Blei (eds
 Certifiedrobustness to adversarial examples With differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy
 ToWard robustness and privacy in federated learning:Experimenting With local and central differential privacy,2020, ArXiv
 Opacus PyTorch library,2021, Available from opacus
 A unified vieW on differentialprivacy and robustness to adversarial examples,2019, arXiv preprint arXiv:1906
 Privacy-preserving deep learning,2015, In 2015 53rd Annual AllertonConference on Communication
 Membership inference attacks against adversariallyrobust deep learning models,2019, In 2019 IEEE Security and Privacy Workshops
 Stochastic gradient descent with differentially privateupdates,2013, In 2013 IEEE Global Conference on Signal and Information Processing
 Training very deepnetworks,2015, In C
 Privacy-preserving distributed deep learning viahomomorphic re-encryption,2019, Electronics
 Subsampled renyi differentialprivacy and analytical moments accountant,1226, In Kamalika Chaudhuri and Masashi Sugiyama (eds
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
 Byzantine-robust distributedlearning: Towards optimal statistical rates,2018, In Jennifer Dy and Andreas Krause (eds
 Deep leakage from gradients,2019, In H
