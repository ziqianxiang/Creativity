title,year,conference
 Optimality and approximationwith policy gradient methods in Markov decision processes,2020, In Conference on Learning Theory
 Fast global convergence ofnatural policy gradient methods with entropy regularization,2020, arXiv preprint arXiv:2007
 A characterization of superlinear convergence and its applicationto quasi-Newton methods,1974, Mathematics of computation
 A theory of regularized Markov decisionprocesses,2019, In International Conference on Machine Learning
 A natural policy gradient,2001, Advances in neural information processing systems
 Actor-critic algorithms,2000, In Advances in neural informationprocessing systems
 Asynchronous methods for deep reinforcementlearning,2016, In International conference on machine learning
 Primal-dual subgradient methods for convex problems,2009, Mathematical programming
 A unified view of entropy-regularized Markovdecision processes,2017, arXiv preprint arXiv:1705
 Rates of superlinear convergence for classical quasi-Newtonmethods,2021, Mathematical Programming
 Iterative methods for sparse linear systems,2003, SIAM
 Trust regionpolicy optimization,2015, In International conference on machine learning
 High-dimensional continuous control using generalized advantage estimation,2015, arXiv preprintarXiv:1506
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Adaptive trust region policy optimization: Globalconvergence and faster rates for regularized mdps,2020, In Proceedings of the AAAI Conference onArtificial Intelligence
 Reinforcement learning: An introduction,2018, MIT press
 Policy gradientmethods for reinforcement learning with function approximation,1999, In NIPs
 Mirror descent policyoptimization,2020, arXiv preprint arXiv:2005
 Hessian informed mirror descent,2021, arXiv preprint arXiv:2106
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Policymirror descent for regularized reinforcement learning: A generalized framework with linear con-vergence,2021, arXiv preprint arXiv:2105
