title,year,conference
 Learning from noisy examples,2017, Machine Learning
 Confidence scoresmake instance-dependent label-noise learning possible,2019, In Proceedings of the 38th InternationalConference on Machine Learning
 ClassificationWith rejection based on cost-sensitive classification,2021, In International Conference on MachineLearning
 Learning With instance-dependent label noise: A sample sieve approach,2018, In International Conference on LearningRepresentations
 BERT: Pre-training of deepbidirectional transformers for language understanding,2010, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Learning object categories fromGoogle’s image search,2005, In Tenth IEEE International Conference on Computer Vision
 Training deep neural-netWorks using a noise adaptationlayer,2017, In International Conference on Learning Representations
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InAdvances in Neural Information Processing Systems
 Deep residual learning for imagerecognition,2018, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Adam: A method for stochastic optimization,2015, In 3rd InternationalConference on Learning Representations
 DiVideMix: Learning with noisy labels as semi-superVised learning,2020, In International Conference on Learning Representations
 Isolation forest,2008, In 2008 eighth IEEE internationalconference on data mining
 Early-learning reg-ularization preVents memorization of noisy labels,2015, In Advances in Neural Information ProcessingSystems
 Peer loss functions: Learning from noisy labels without knowing noiserates,2020, In Proceedings of the 37th International Conference on Machine Learning
 Random classification noise defeats all conVex potentialboosters,2010, Machine learning
 Normal-ized loss functions for deep learning with noisy labels,2020, In Proceedings of the 37th InternationalConference on Machine Learning
 Decoupling “when to update” from “how to update”,2017, InAdvances in Neural Information Processing Systems
 Learning from binary labelswith instance-dependent noise,2020, Machine Learning
 Efficient estimation of word representa-tions in vector space,2020, In International Conference on Learning Representations
 Consistent estimators for learning to defer to an expert,2020, InInternational Conference on Machine Learning
 Deepdouble descent: Where bigger models and more data hurt,2013, In International Conference on LearningRepresentations
 SELF: Learning to filter noisy labels with self-ensembling,2020, InInternational Conference on Learning Representations
 Confident learning: Estimating uncertainty indataset labels,2019, arXiv preprint arXiv:1911
 Training deep neural networks on noisy labels with bootstrapping,2015, In InternationalConference on Learning Representations
 On the importance of initializationand momentum in deep learning,2015, In International conference on machine learning
 Symmetric crossentropy for robust learning with noisy labels,2019, In Proceedings of the IEEE International Conferenceon Computer Vision
 Unsupervised feature learning via non-parametric instance discrimination,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Learning from massive noisylabeled data for image classification,2019, In Proceedings of the IEEE conference on computer visionand pattern recognition
 Understand-ing deep learning requires rethinking generalization,2017, In International Conference on LearningRepresentations
 mixup: Beyond empiricalrisk minimization,2021, In International Conference on Learning Representations
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2021, In Advances in neural information processing systems
