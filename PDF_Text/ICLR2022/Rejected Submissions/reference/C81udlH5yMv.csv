title,year,conference
 Generalizing to unseendomains via distribution matching,2019, arXiv preprint arXiv:1911
 Invariant risk minimization,2019, arXiv preprintarXiv:1907
 From detection of individual metastases to classification of lymph nodestatus at the patient level: the camelyon17 challenge,2018, IEEE Transactions on Medical Imaging
 Recognition in terra incognita,2018, ECCV
 Flexiblyfair representation learning by disentanglement,2019, In International conference on machine learning
 Deepjdot: Deep jointdistribution optimal transport for unsupervised domain adaptation,2018, In Proceedings of the EuropeanConference on Computer Vision (ECCV)
 Representation viarepresentations: Domain generalization via adversarially learned invariant representations,2020, arXivpreprint arXiv:2006
 Censoring representations with an adversary,2015, arXiv preprintarXiv:1511
 Domain generalization for objectrecognition with multi-task autoencoders,2015, ICCV
 Domain adaptation withconditional transferable components,2016, In International conference on machine learning
 A kernel method for the two-sample-problem,2006, Advances in neural information processing systems
 In search of lost domain generalization,2020, arXiv preprintarXiv:2007
 Wasserstein fair classification,2020, InUncertainty in Artificial Intelligence
 Adam: A method for stochastic optimization,2015, ICLR
 WILDS: A benchmark ofin-the-wild distribution shifts,2021, In International Conference on Machine Learning (ICML)
 Deep domain generalizationvia conditional invariant adversarial networks,2018, In Proceedings of the European Conference onComputer Vision (ECCV)
 Deep domain generalizationvia conditional invariant adversarial networks,2018, In Proceedings of the European Conference onComputer Vision (ECCV)
 On the fairness ofdisentangled representations,2019, arXiv preprint arXiv:1905
 Adversarial autoencoders,2015, arXivpreprint arXiv:1511
 Causality from a distributional robustness point of view,2018, In 2018 IEEE Data ScienceWorkshop (DSW)
 Domain generalization via invariant feature representa-tion,2013, In International Conference on Machine Learning
 Elements of causal inference: foundations and learningalgorithms,2017, The MIT Press
 Computational optimal transport,2019, Foundations and Trends in MachineLearning
 Theoretical analysis of domain adaptation with optimaltransport,2017, In Joint European Conference on Machine Learning and Knowledge Discovery inDatabases
 Mitigating information leakage in image representations: A maximumentropy approach,2019, 2019
 Distributionally robust neural networks forgroup shifts: On the importance of regularization for worst-case generalization,2019, arXiv preprintarXiv:1911
 Towardcausal representation learning,2021, Proceedings of the IEEE
 Wasserstein distance guided representation learning for domainadaptation,2018, In Proceedings of the AAAI Conference on Artificial Intelligence
 Deep coral: Correlation alignment for deep domain adaptation,2016, In Europeanconference on computer vision
 Robustly disentangled causal mechanisms:Validating deep representations for interventional robustness,2019, In International Conference onMachine Learning
 Rxrx1: An image set for cellularmorphological variation across many experimental batches,2019, In International Conference onLearning Representations (ICLR)
 Statistical learning theory wiley,1998, New York
 Deep hashing network forunsupervised domain adaptation,2017, CVPR
 A survey of unsupervised deep domain adaptation,2020, ACM Transactions onIntelligent Systems and Technology (TIST)
 Controllable invariance through adversarial featurelearning,2017, arXiv preprint arXiv:1705
 Improve unsupervised domain adaptation with mixuptraining,2020, arXiv preprint arXiv:2001
 Learning fair representations,2013, In S
 Adaptive risk minimization:A meta-learning approach for tackling group shift,2020, 2020
 Domain generalization with optimal transportand metric learning,2020, arXiv preprint arXiv:2007
2 Maximum Mean DiscrepancyMMD Gretton et al,2022, (2006) is a distance based on empirical samples from two distributions
