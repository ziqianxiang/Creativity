title,year,conference
 Thevulnerability of learning to adversarial perturbation increases with intrinsic dimensionality,2017, In2017 IEEE Workshop on Information Forensics and Security (WIFS)
 Decision-Based Adversarial Attacks: ReliableAttacks Against Black-Box Machine Learning Models,1712, arXiv:1712
 Towards Evaluating the Robustness of Neural Networks,2016, InSecurity and Privacy (SP)
 HopSkipJumpAttack: A Query-EfficientDecision-Based Attack,2019, arXiv:1904
 Query-EfficientHard-label Black-box Attack:An Optimization-based Approach,1807, arXiv:1807
 Query-efficient hard-label black-box attack: An optimization-based approach,2019, International Conferenceon Learning Representations
 SIGN-OPT: A QUERY-EFFICIENT HARD-LABEL ADVERSARIAL ATTACK,2020, The InternationalConference on Learning Representations (ICLR)
 Certified Adversarial Robustness via Ran-domized Smoothing,1902, arXiv:1902
 Query-Efficient Physical Hard-Label Attacks on Deep Learning Visual Classifica-tion,2020, arXiv:2002
 Explaining and Harnessing AdversarialExamples,1412, 2014
 Black-box Adversarial Attackswith Limited Queries and Information,1804, arXiv:1804
 The Robust ManifoldDefense: Adversarial Training using Generative Models,2019, arXiv:1712
 Sensible Adversarial Learning,2020, 2020
 Learning Multiple Layers of Features from Tiny Images,2009, pp
 Perceptual Adversarial Robustness: Defense AgainstUnseen Threat Models,2006, arXiv:2006
 DeepFool: a simpleand accurate method to fool deep neural networks,1511, 2015
 Defense-gan: Protecting classifiersagainst adversarial attacks using generative models,2018, In International Conference on LearningRepresentations
 Adver-sarially Robust Generalization Requires More Data,1804, arXiv:1804
 Disentangling Adversarial Robustness and General-ization,2019, In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Intriguing ProPerties of neural networks,1312, PP
 Rethinkingthe incePtion architecture for comPuter vision,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 A Boundary Tilting PersePective on the Phenomenon of AdversarialExamPles,2016, arXiv:1608
 On AdaPtive Attacksto Adversarial ExamPle Defenses,2002, arXiv:2002
 Stealing Machine Learning Models via Prediction APIs,2016, 2016
 Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training,2019, In H
 Adversarial Interpolation Training: A simple approach for improvingmodel robustness,2020, 2020
 Understanding the Intrinsic Robustnessof Image Distributions using Conditional Generative Models,2003, arXiv:2003
