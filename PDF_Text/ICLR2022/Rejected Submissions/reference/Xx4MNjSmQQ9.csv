title,year,conference
 Improved algorithms for linear stochasticbandits,2011, In NIPS
 Thompson sampling for contextual bandits with linear payoffs,2013, InInternational Conference on Machine Learning
 The implicit regularization of stochastic gradientflow for least squares,2020, In International Conference on Machine Learning
 Neural module networks,2016, InProceedings of the IEEE conference on computer vision and pattern recognition
 Convex sparse matrix factorizations,2008, arXiv preprintarXiv:0812
 Predicting with proxies: Transfer learning in high dimension,2020, Management Science
 Analysis of representations fordomain adaptation,2007, In Advances in neural information processing systems
 Learningbounds for domain adaptation,2008, In Advances in neural information processing systems
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Gradient descent finds globalminima of deep neural networks,1675, In International Conference on Machine Learning
 Learning models with uniform performance via distributionallyrobust optimization,2018, arXiv preprint arXiv:1810
 Beyond ucb: Optimal and efficient contextual bandits withregression oracles,2020, In International Conference on Machine Learning
 Convergenceof adversarial training in overparametrized neural networks,2019, Advances in Neural InformationProcessing Systems
 No spurious local minima in nonconvex low rank problems: Aunified geometric analysis,1233, In International Conference on Machine Learning
 Learning one-hidden-layer neural networks with landscapedesign,2017, arXiv preprint arXiv:1711
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, arXiv preprint arXiv:1903
 Neural tangent kernel: Convergence andgeneralization in neural networks,2018, arXiv preprint arXiv:1806
 An introduction to computationallearning theory,1994, MIT press
 Wilds: Abenchmark of in-the-wild distribution shifts,2020, arXiv preprint arXiv:2012
 Algorithmic regularization in over-parameterizedmatrix sensing and neural networks with quadratic activations,2018, In Conference On Learning Theory
 Exploring general-ization in deep learning,2017, arXiv preprint arXiv:1706
 Certified defenses against adversarialexamples,2018, arXiv preprint arXiv:1801
 Beyond accuracy:Behavioral testing of nlp models with checklist,2020, arXiv preprint arXiv:2005
 Abenchmark for systematic generalization in grounded language understanding,2020, arXiv preprintarXiv:2003
 Linearly parameterized bandits,2010, Mathematics ofOperations Research
 Theoretical insights into the optimizationlandscape of over-parameterized shallow neural networks,2018, IEEE Transactions on InformationTheory
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Measuring robustness to natural distribution shifts in image classification,2020, arXivpreprint arXiv:2007
 High-dimensional statistics: A non-asymptotic viewpoint,2016, Book Draft(Working Publication)
 Robust learning under uncertain test distributions:Relating covariate shift to model misspecification,2014, In International Conference on MachineLearning
 Group-sparse matrix factorization fortransfer learning of word embeddings,2021, In International Conference on Machine Learning
 A useful variant of the davis-kahan theorem forstatisticians,2015, Biometrika
