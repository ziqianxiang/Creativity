title,year,conference
 Pseudo-labelingand confirmation bias in deep semi-supervised learning,2020, International Joint Conference on NeuralNetworks (IJCNN)
 To-wards shape biased unsupervised representation learning for domain generalization,2019, In arXivpreprint arXiv:1909
 Out-distribution aware self-training in an open worldsetting,2020, In arXiv preprint arXiv:2012
 Co-training and expansion: Towards bridgingtheory and practice,2005, In Advances in neural information processing systems
 A computational approach to edge detection,1986, 1986
 A simple framework forcontrastive learning of visual representations,2020, In International conference on machine learning
 Self-training avoids using spuriousfeatures under domain shift,2020, In Advances in Neural Information Processing Systems
 Multi-column deep neural networks for imageclassification,2012, In Computer Vision and Pattern Recognition (CVPR)
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning (ICML)
 Histograms of oriented gradients for human detection,2005, In IEEEcomputer society conference on computer vision and pattern recognition (CVPR)
 On the canny edge detector,2001, In Pattern Recognition
 Adversarial robustness as a prior for learned representations,2019, In ArXiv preprintarXiv:1906
 Adversarial examples are a naturalconsequence of test error in noise,2019, In arXiv preprint arXiv:1901
 Neocognitron: A self-organizing neural network model for a mechanism ofpattern recognition unaffected by shift in position,1980, Biological cybernetics
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations (ICLR)
 Annotation artifacts in natUral langUage inference data,2018, In North AmericanChapter of the Association for Computational Linguistics (NAACL)
 Conditional variance penalties and domain shiftrobUstness,2017, arXiv preprint arXiv:1710
 The origins and prevalence of textUre bias inconvolUtional neUral networks,2020, In Advances in Neural Information Processing Systems
 Self-adaptive training: Bridging the sUpervisedand self-sUpervised learning,2021, In arXiv preprint arXiv:2101
 Batch normalization: Accelerating deep network training byredUcing internal covariate shift,2015, In International Conference on Machine Learning (ICML)
 Label propagation for deep semi-sUpervised learning,2019, In Computer Vision and Pattern Recognition (CVPR)
 On the effectiveness of adversar-ial training against common corrUptions,2021, In arXiv preprint arXiv:2103
 Learning multiple layers of features from tiny images,2009, In Technical report
 Imagenet classification with deep con-volutional neural networks,2012, In Advances in Neural Information Processing Systems (NeurIPS)
 Understanding self-training for gradual domainadaptation,2020, In International Conference on Machine Learning (ICML)
 Temporal ensembling for semi-supervised learning,2017, InternationalConference on Learning Representations (ICLR)
 Backpropagation applied to handwritten zip code recognition,1989, InNeural computation
 Certified ro-bustness to adversarial examples with differential privacy,2019, In Symposium on Security and Privacy(SP)
 Pseudo-label: The simple and efficient semi-supervised learning method fordeep neural networks,2013, In Workshop on challenges in representation learning
 A simple unified framework for detectingout-of-distribution samples and adversarial attacks,2018, In Neural Information Processing Systems(NeurIPS)
 Shape-texture debiased neural network training,2021, In International Conference on LearningRepresentations (ICLR)
 Object recognition from local scale-invariant features,1999, In Proceedings of the seventhIEEE international conference on computer vision
 Causality from a distributional robustness point of view,2018, In Data ScienceWorkshop (DSW)
 Virtual adversarial training: aregularization method for supervised and semi-supervised learning,2018, 2018
 Self-distillation amplifies regularizationin hilbert space,2020, In arXiv preprint arXiv:2002
 Analyzing the effectiveness and applicability of co-training,2000, InProceedings of the ninth international conference on Information and knowledge management
 Deep co-training for semi-supervised image recognition,2018, In Proceedings of the european conference on computer vision(EECV)
 Distributionally robustneural networks for group shifts: On the importance of regularization for worst-case generaliza-tion,2020, In International Conference on Learning Representations
 Informativedropout for robust representation learning: A shape-bias perspective,2020, In International Conferenceon Machine Learning
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations (ICLR)
 A 3x3 isotropic gradient operator for image processing,1968, 1968
 Fixmatch: Simplifying semi-supervisedlearning with consistency and confidence,2020, In Advances in Neural Information Processing Systems
 Frustratingly simple domain generalization viaimage stylization,2020, In arXiv preprint arXiv:2006
 Unbiased look at dataset bias,2011, In CVPR 2011
 The bigchaos solution to the netflix grandprize,2009, Netflix prize documentation
 Deep image prior,2017, In ArXiv preprintarXiv:1711
 Theoretical analysis of self-trainingwith deep networks on unlabeled data,2021, In International Conference on Learning Representations(ICLR)
 Noise or signal: The role ofimage backgrounds in object recognition,2020, arXiv preprint arXiv:2006
 Mico: Mixup co-training for semi-supervised domain adaptation,2020, In arXivpreprint arXiv:2007
 Cotrade: Confident co-training with data editing,2011, In IEEETransactions on Systems
 Confidence regularizedself-training,2019, In Proceedings of the IEEE International Conference on Computer Vision
