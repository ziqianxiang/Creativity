title,year,conference
 Adversarial examples are a naturalconsequence of test error in noise,2019, arXiv preprint arXiv:1901
 Unsupervised domain adaptation by backpropagation,2015, InInternational conference on machine learning
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, International Conference on Learning Representations (ICLR)
 Cycada: Cycle-consistent adversarial domain adaptation,2018, In Internationalconference on machine learning
 Rethinking distributional matching based domain adaPtation,2020, arXivpreprint arXiv:2006
 Revisiting batch normalizationfor Practical domain adaPtation,2016, arXiv preprint arXiv:1603
 Improvingrobustness without sacrificing accuracy with patch gaussian augmentation,2019, arXiv preprintarXiv:1906
 Autodial:Automatic domain alignment layers,2017, In Proceedings of the IEEE International Conference onComputer Vision
 Visda:The visual domain adaptation challenge,2017, arXiv preprint arXiv:1710
 DatasetShift in Machine Learning,2009, MIT Press
 Increasing the robustness of dnns against image corruptions byplaying the game of noise,2020, arXiv preprint arXiv:2001
 A simple way to make neural networks robust against diverse imagecorruptions,2020, In Andrea Vedaldi
 Improving robustness against common corruptions by covariate shift adaptation,2020, Advancesin Neural Information Processing Systems
 Correlation alignment for unsupervised domainadaptation,2017, In Domain Adaptation in Computer Vision Applications
 Unsupervised domain adaptation throughself-supervision,2019, arXiv preprint arXiv:1909
 Test-time trainingwith self-supervision for generalization under distribution shifts,2020, In International Conference onMachine Learning
 Learning to resize images for computer vision tasks,2021, arXivpreprint arXiv:2103
 Fully test-timeadaptation by entropy minimization,2020, arXiv preprint arXiv:2006
 Image quality assessment: From errorvisibility to structural similarity,1057, Trans
 Entropy minimizationvs,2020, diversity maximization for domain adaptation
 Negative log likelihood ratio loss for deepneural network classification,2020, In Kohei Arai
9 and initial learning rate0,2020,01
