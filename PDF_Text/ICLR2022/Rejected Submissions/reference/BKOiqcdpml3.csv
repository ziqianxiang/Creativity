title,year,conference
 Eyeriss: An Energy-Efficient Re-configurable Accelerator for Deep Convolutional Neural Networks,0018, IEEE J
 Learned Step Size Quantization,2020, 8th Int
 TETRIS: Scalableand efficient neural network acceleration with 3D memory,2017, ACM SIGPLAN Not
 Model selection based on minimum description length,0022, J
 EIE: Efficient Inference Engine on Compressed Deep Neural Network,2016, feb 2016
 Binarizedneural networks,2016, In Adv
 Learning to quantize deep networks by optimizing quantizationintervals with task loss,2019, In Proc
 A learnableparallel processing architecture towards unity of memory and computing,2015, Sci
 Deep Compression: Compressing Deep Neural,2016, Iclr 2016
 Automated Log-Scale Quantization forLow-Cost Deep Neural Networks,2021, Proc
 Analytical guarantees on numerical precisionof deep neural networks,2017, 34th Int
 Pattern Recognit,1063,
 Efficient Processing of Deep Neural Net-works: A Tutorial and Survey,2017, mar 2017
 Efficient Processing of DeepNeural Networks,1935, Synth
 DeePÎº-means: Re-training and parameter sharing with harder cluster assignments for compressingdeep convolutions,2018, 35th Int Conf
 On compressing deep models by lowrank and sparse decomposition,2017, Proc
 Kernel Quantization for Efficient NetworkCompression,2020, 2020
 DoReFa-Net:Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients,2016, jun 2016
