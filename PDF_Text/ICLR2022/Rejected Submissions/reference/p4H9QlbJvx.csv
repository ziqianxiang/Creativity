title,year,conference
 A closer look at structuredpruning for neural network compression,2018, arXiv preprint arXiv:1810
 Imagenet: A large-scalehierarchical image database,2009, In CVPR
 Model compression and hardwareacceleration for neural networks: A comprehensive survey,2020, Proceedings of the IEEE
 Auto-balanced filter pruning forefficient convolutional neural networks,2018, In AAAI
 Linear mode con-nectivity and the lottery ticket hypothesis,2020, In ICML
 The state of sparsity in deep neural networks,2019, arXivpreprint arXiv:1902
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In AISTATS
 Deep residual learning for image recognition,2016, In CVPR
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In CVPR
 Channel pruning for accelerating very deep neural net-works,2017, In ICCV
 Data-driven sparse structure selection for deep neural networks,2018, InECCV
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In ICML
 Data-dependent initializationsof convolutional neural networks,2015, arXiv preprint arXiv:1511
 Learning multiPle layers of features from tiny images,2009, Technical rePort
 OPtimal brain damage,1990, In NeurIPS
 Gradient-based learning appliedto document recognition,1998, Proceedings of the IEEE
 Snip: Single-shot network pruning basedon connection sensitivity,2019, In ICLR
 A signal propagationperspective for pruning neural networks at initialization,2020, In ICLR
 Pruning filters forefficient convnets,2017, In ICLR
 Learn-ing efficient convolutional networks through network slimming,2017, In ICCV
 Rethinking the value ofnetwork pruning,2019, In ICLR
 Thinet: A filter level pruning method for deep neuralnetwork compression,2017, In ICCV
 Exploringthe granularity of sparsity in convolutional neural networks,2017, In CVPR Workshop
 All you need is a good init,2016, In ICLR
 Skeletonization: A technique for trimming the fat from anetwork via relevance assessment,1989, In NeurIPS
 Pruning algorithms - a survey,2020, IEEE Transactions on Neural Networks
 Exact solutions to the nonlinear dynam-ics of learning in deep linear neural networks,2014, In ICLR
 Very deep convolutional networks for large-scale imagerecognition,2015, In ICLR
 Woodfisher: Efficient second-order approximations for modelcompression,2020, In NeurIPS
 On the importance of initializa-tion and momentum in deep learning,2013, In ICML
 Efficient processing of deep neuralnetworks: A tutorial and survey,2017, Proceedings of the IEEE
 Faster gaze prediction withdense networks and fisher pruning,2018, arXiv preprint arXiv:1801
 Eigendamage: Structured pruningin the kronecker-factored eigenbasis,2019, In ICML
 Picking winning tickets before training bypreserving gradient flow,2020, In ICLR
 Structured pruning for efficientconvnets via incremental regularization,2019, In IJCNN
 Neural pruning via growing regularization,2021, InICLR
 Learning structured sparsity indeep neural networks,2016, In NeurIPS
 Neural architecture search with reinforcement learning,2017, In ICLR
