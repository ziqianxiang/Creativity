title,year,conference
 Qsgd: Communication-efficientsgd via gradient quantization and encoding,2017, Advances in Neural Information Processing Systems (NeurIPS)
 Advancing the cancer genome atlas glioma mricollections with expert segmentation labels and radiomic features,2017, Scientific data
 signsgd: Com-pressed optimisation for non-convex problems,2018, In Proceedings of the International Conference on MachineLearning (ICML)
 CapC learning: Confidential and private Collaborative learning,2020, In Proceedings ofthe International Conference on Learning Representations (ICLR)
 Emnist: Extending mnist to hand-written letters,2017, In 2017 International Joint Conference on Neural Networks (IJCNN)
 Pipetransformer: Automated elasticpipelining for distributed training of transformers,2021, arXiv preprint arXiv:2102
 Deep residual learning for image recognition,2016, InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Distilling the knowledge in a neural network,2015, arXiv preprintarXiv:1503
 The non-iid data quagmire of decentralizedmachine learning,2020, In Proceedings of the International Conference on Machine Learning (ICML)
 Learning multiple layers of features from tiny images,2009, 2009
 Optimal brain damage,1990, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Fedmd: Heterogenous federated learning via model distillation,2019, arXiv preprintarXiv:1910
 Progressive learning anddisentanglement of hierarchical representations,2019, In Proceedings of the International Conference on LearningRepresentations (ICLR)
 Dynamic model pruning withfeedback,2019, In Proceedings of the International Conference on Learning Representations (ICLR)
 Ensemble distillation for robust model fusion infederated learning,2020, In Advances in Neural Information Processing Systems (NeurIPS)
 Deep gradient compression: Reducing the com-munication bandwidth for distributed training,2018, In Proceedings of the International Conference on LearningRepresentations (ICLR)
 A double residual compression algorithm for efficientdistributed learning,2020, In Proceedings of the International Conference on Artificial Intelligence and Statistics(AISTATS)
 Learning efficientconvolutional networks through network slimming,2017, In Proceedings of the IEEE International Conferenceon Computer Vision (ICCV)
 Sgdr: Stochastic gradient descent with warm restarts,2017, In Proceedings of theInternational Conference on Learning Representations (ICLR)
 Simultaneous training of partially maskedneural networks,2021, arXiv preprint arXiv:2106
 Skeletonization: A technique for trimming the fat from a networkvia relevance assessment,1989, In Advances in Neural Information Processing Systems (NeurIPS)
 Bidirectional compression in heterogeneous settings fordistributed or federated learning with partial participation: tight convergence guarantees,2020, arXiv preprintarXiv:2006
 Model compression via distillation and quantization,2018, InProceedings of the International Conference on Learning Representations (ICLR)
 Adaptive federated optimization,2021, In Proceedings of the International Conferenceon Learning Representations (ICLR)
 Federated learning in medicine:facilitating multi-institutional collaborations without sharing patient data,2020, Scientific reports
 On communication compression for distributed optimization on heterogeneous data,2020, arXivpreprint arXiv:2009
 Sparsified SGD with memory,2018, Advances inNeural Information Processing Systems (NeurIPS)
 Doublesqueeze: Parallel stochastic gradientdescent with double-pass error-compensated compression,2019, In Proceedings of the International Conferenceon Machine Learning (ICML)
 A fully progressive approach to single-image super-resolution,2018, In Proceedings of theIEEE conference on computer vision and pattern recognition workshops
 Terngrad: ternary gra-dients to reduce communication in distributed deep learning,2017, In Advances in Neural Information ProcessingSystems (NeurIPS)
 Cascade ef-gan: Progressive facial expression edit-ing with local focuses,2020, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Double quantization for communication-efficient distributed opti-mization,2019, In Advances in Neural Information Processing Systems (NeurIPS)
54 Â± 0,2022,44	49
