title,year,conference
 On the convergence of the proximal algorithm for nonsmoothfunctions involving analytic features,2009, Mathematical Programming B
 Stability and stabilization of discontinuous systems andnonsmooth lyapunov functions,1999, ESAIM: Control
 The geometry of sign gradient descent,2020, arXivpreprint arXiv:2002
 First-order methods in optimization,2017, SIAM
 signsgd:Compressed optimisation for non-convex problems,2018, In International Conference on MachineLearning
 signsgd withmajority vote is communication efficient and fault tolerant,2018, arXiv preprint arXiv:1810
 On biased compressionfor distributed learning,2020, arXiv preprint arXiv:2002
 The Eojasiewicz inequality for nonsmooth suban-alytic functions with applications to subgradient dynamical systems,2007, Society for Industrial andApplied Mathematics
 Optimization methods for large-scale machinelearning,2018, Siam Review
 Generalized gradients of lipschitz functionals,1981, Advances in Mathematics
 First-order methods of smooth convexoptimization with inexact oracle,2014, Mathematical Programming
 Spider: near-optimal non-convexoptimization via stochastic path integrated differential estimator,2018, In Proceedings of the 32ndInternational Conference on Neural Information Processing Systems
 A variational approach to dual methods forconstrained convex optimization,2017, In 2017 American Control Conference (ACC)
 A variational approach to dual methods forconstrained convex optimization,2017, In 2017 American Control Conference (ACC)
 Analysis of optimiza-tion algorithms via integral quadratic constraints: Nonstrongly convex problems,2018, SIAM J
 Admm and accelerated admm as continuousdynamical systems,2018, In International Conference on Machine Learning
 A dynamical systems perspective on nonsmooth constrainedoptimization,2019, arXiv preprint 1808
 Mini-batch stochastic approximation methodsfor nonconvex stochastic composite optimization,2016, Mathematical Programming
 Linear convergence of gradient and proximal-gradient methods under the Polyak-Iojasiewicz condition,2016, In Joint European Conference onMachine Learning and Knowledge Discovery in Databases
 Error feedbackfixes signsgd and other gradient compression schemes,2019, In International Conference on MachineLearning
 Fine-grained analysis of stability and generalization for stochasticgradient descent,2020, In International Conference on Machine Learning
 Stochastic gradient descent for nonconvex learningwithout bounded gradient assumptions,2019, IEEE transactions on neural networks and learningsystems
 Analysis and design of optimization algorithms via integralquadratic constraints,2016, SIAM J
 On faster convergence of scaled signgradient descent,2021, arXiv preprint arXiv:2109
 Ensembles Semi-analytiques,1965, Centre de Physique Theorique de 1'Ecole Polytechnique
 On the gradient inequality,1999, Bulletin of the PolishAcademy of Sciences
 Shadowing properties of optimization algorithms,2019, In Neural InformationProcessing Systems
 A calculus for computing filippovâ€™s differential inclusion withapplication to the variable structure control of robot manipulators,1987, IEEE Transactions on Circuitsand Systems
 A stochastic approximation method,1951, The annals of mathematicalstatistics
 Convergence of the expectation-maximization algorithmthrough discrete-time lyapunov stability theory,2019, Proceedings of the American Control Conference(ACC)
 Stochastic sign descent methods: New algorithms and bettertheory,2021, In International Conference on Machine Learning
 Dynamical properties of hybrid systems simulators,2010, Automatica
 Using dynamical systems methods to solve minimization problems,1995, AppliedNumerical Mathematics
 Understanding the acceleration phenomenon viahigh-resolution differential equations,2018, arXiv preprint 1810
 A new and dynamic method for unconstrained minimization,1982, Applied MathematicalModelling
 Dynamical systems and numerical analysis,1998, CambridgeUniversity Press
 A control perspective for centralized and distributed convex optimization,2011, InIEEE Conference on Decision and Control and European Control Conference
 A variational perspective on acceleratedmethods in optimization,2016, Proceedings of the National Academy of Sciences
 Lyapunov Arguments in Optimization,2018, PhD thesis
 Accelerating rescaled gradient descent: Fastoptimization of smooth functions,2019, arXiv preprint arXiv:1902
 The use of differential equations in optimization,1981, PhD thesis
 Direct runge-kutta discretization achievesacceleration,2018, In Neural Information Processing Systems
