title,year,conference
 Wasserstein GAN,2017, ArXiv
 The Cramer Distance as a Solution to Biased Wasserstein Gradients,2017, ArXiv
 Demystifying MMDGANs,2018, ArXiv
 Behavioral Priors and DynamicsModels: Improving Performance and Domain Transfer in Offline RL,2021, ArXiv
 Decision Transformer: Reinforcement Learning via SequenceModeling,2021, ArXiv
 Off-Policy Actor-Critic,2012, ArXiv
 Tree-Based Batch Mode Reinforcement Learn-ing,2005, J
 Diagnosing Bottlenecks in Deep Q-learning Algorithms,2019, In ICML
 Addressing Function Approximation Errorin Actor-Critic Methods,2018, In Jennifer Dy and Andreas Krause (eds
 Off-Policy Deep Reinforcement Learning withoutExploration,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Generative Adversarial Nets,2014, In Z
 EvaluatingReinforcement Learning Algorithms in Observational Health Settings,2018, ArXiv
 Im-proved Training of Wasserstein GANs,2017, In NIPS
 Reinforcement Learning with DeepEnergy-Based Policies,2017, In ICML
 Soft Actor-Critic: Off-PolicyMaximum Entropy Deep Reinforcement Learning with a Stochastic Actor,1861, In Jennifer Dy andAndreas Krause (eds
 Soft Actor-Critic Algorithmsand Applications,2018, ArXiv
 Double Q-learning,2010, In NIPS
 Generative Adversarial Imitation Learning,2016, In D
 Way Off-Policy Batch Deep Reinforcement Learning ofImplicit Human Preferences in Dialog,2019, ArXiv
 Offline Reinforcement Learning with ImplicitQ-Learning,2021, ArXiv
 Stabilizing Off-PolicyQ-Learning via Bootstrapping Error Reduction,2019, In Advances in Neural Information ProcessingSystems
 Conservative Q-Learning for Of-fline Reinforcement Learning,2020, In H
 Controlling Overes-timation Bias with Truncated Mixture of Continuous Distributional Quantile Critics,2020, ArXiv
 Deeper inside PageRank,1542, Internet Mathematics
 Safe Policy Improvement with Baseline Bootstrapping,2019, In ICML
 OptiDICE: OfflinePolicy Optimization via Stationary Distribution Correction Estimation,2021, ArXiv
 SUNRISE: A Simple Unified Framework forEnsemble Learning in Deep Reinforcement Learning,2021, In ICML
 MMD GAN: TowardsDeeper Understanding of Moment Matching Network,2017, In NIPS
 Continuous Control with Deep Reinforcement Learning,2016, CoRR
 Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation,2018, In NeurIPS
 Matrix Analysis and Applied Linear Algebra,0898, Society for Industrial and AppliedMathematics
 Conditional Generative Adversarial Nets,2014, ArXiv
 Spectral Normalizationfor Generative Adversarial Networks,2018, ArXiv
 Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning,2020, ArXiv
 Integral Probability Metrics and Their Generating Classes of Functions,1997, Advances inApplied Probability
 AlgaeDICE:Policy Gradient from Arbitrary Experience,2019, ArXiv
 The PageRank Citation Ranking: Bringing orderto the Web,1998, In Proceedings of the 7th International World Wide Web Conference
 UnsUpervised Representation Learning with DeepConvolUtional Generative Adversarial Networks,2016, CoRR
 Im-proved TechniqUes for Training GANs,2016, In NIPS
 Sur la theorie relativiste de l'electron et l'interpretation de la mecanique quan-tique,1932, Annales de l'institut Henri Poincare
 Trust Region PolicyOptimization,2015, ArXiv
 DeterministicPolicy Gradient Algorithms,2014, In ICML
 Learning Structured Output Representation usingDeep Conditional Generative Models,2015, In NIPS
 Reinforcement Learning: An Introduction,0262, A BradfordBook
 Off-policy Evaluation for Slate Recommendation,2017, In NIPS
 Deep ReinforcementLearning for Automated Radiation Adaptation in Lung Cancer,2017, Medical Physics
 Risk-Averse Offline Reinforcement Learning,2021, ArXiv
 All of Nonparametric Statistics,2006, Springer
 Sampling Generative Networks,2016, arXiv: Neural and Evolutionary Computing
 Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning,2021, In ICML
 Implicit Distributional Reinforcement Learn-ing,2020, In Hugo Larochelle
 A Survey of AutonomousDriving: Common Practices and Emerging Technologies,2020, IEEE Access
 GenDICE: Generalized Offline Estimation ofStationary Values,2020, ArXiv
4 Â± 21,2022,4	48
