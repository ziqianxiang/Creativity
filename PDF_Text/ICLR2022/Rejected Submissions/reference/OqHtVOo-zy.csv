title,year,conference
 Learning from noisy examples,1988, Machine Learning
 Confidence scoresmake instance-dependent label-noise learning possible,2020, arXiv preprint arXiv:2001
 SUpport vector machines Under adversarial labelnoise,2011, In ACML
 Learning withbounded instance-and label-dependent label noise,2020, In ICML
 Training deep neural-networks using a noise adaptationlayer,2017, In ICLR
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InNeurIPS
 Deep residual learning for image recog-nition,2016, In CVPR
 Using trusted data to traindeep networks on labels corrupted by severe noise,2018, In NeurIPS
 MentorNet: Learning data-driven curriculum for very deep neural networks on corrupted labels,2018, In ICML
 Robust active label correction,2018, In AISTATS
 Dividemix: Learning with noisy labels as semi-supervised learning,2020, In ICLR
 Gradient descent with early stopping isprovably robust to label noise for overparameterized neural networks,2020, In AISTATS
 Provably end-to-end label-noise learning without anchor points,2021, arXiv preprint arXiv:2102
 Learning fromnoisy labels with distillation,2017, In ICCV
 Early-learningregularization prevents memorization of noisy labels,2020, In NeurIPS
 Peer loss functions: Learning from noisy labels without knowing noiserates,2020, In ICML
 Curriculum loss: Robust learning and generalization against labelcorruption,2020, In ICLR
 Dimensionality-driven learning with noisy labels,2018, In ICML
 Decoupling” when to update” from” how to update”,2017, InNeurIPS
 Noise tolerance under risk minimization,2013, IEEE Transactions onCybernetics
 Learning withnoisy labels,2013, In NeurIPS
 Self: Learning to filter noisy labels with self-ensembling,2020, In ICLR
 Learning with confident examples: Rankpruning for robust classification with noisy labels,2017, In UAI
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In CVPR
 Training deep neural networks on noisy labels with bootstrapping,2015, In ICLR
 Meta transition adaptation for robust deeplearning with noisy labels,2020, arXiv preprint arXiv:2006
 Joint optimization frame-work for learning with noisy labels,2018, In CVPR
 Robustness of conditionalgans to noisy labels,2018, In NeurIPS
 Learningfrom noisy large-scale datasets with minimal supervision,2017, In CVPR
 Co-mining: Deep face recognitionwith noisy labels,2019, In ICCV
 Class2simi: A new perspective on learning with label noise,2020, arXiv preprintarXiv:2006
 Part-dependent label noise: Towards instance-dependentlabel noise,2020, In NeurIPS
 Parts-dependent label noise: Towards instance-dependentlabel noise,2020, In NeurIPS
 Learning from massive noisylabeled data for image classification,2015, In CVPR
 L_dmi: A novel information-theoretic lossfunction for training deep nets robust to label noise,2019, In NeurIPS
 Learning frommultiple annotators with varying expertise,2014, Machine learning
 Free lunch for few-shot learning: Distribution calibration,2021, InICLR
 Searching to exploit memo-rization effect in learning with noisy labels,2020, In ICML
 Dual t: Reducing estimation error for transition matrix in label-noise learning,2020, InNeurIPS
 Learning with biased complementarylabels,2018, In ECCV
 Understandingdeep learning requires rethinking generalization,2017, In ICLR
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
 Learning withfeature-dependent label noise: A progressive approach,2021, In ICLR
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In NeurIPS
 Error-bounded correction of noisy labels,2020, In ICML
 A second-order approach to learning with instance-dependent label noise,2020, arXiv preprint arXiv:2012
 Clusterability as an alternative to anchor points whenlearning with noisy labels,2021, arXiv preprint arXiv:2102
9 and a learningrate of 0,2020,01
