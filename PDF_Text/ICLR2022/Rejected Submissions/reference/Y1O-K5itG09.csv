title,year,conference
 On exactcomputation with an infinitely wide neural net,2019, Advances in Neural Information Processing Systems
 Spectrally-normalized margin bounds for neuralnetworks,2017, Advances in Neural Information Processing Systems
 Weight uncertainty in neuralnetwork,2015, In International Conference on Machine Learning
 Stochastic gradient hamiltonian monte carlo,2014, In Internationalconference on machine learning
 Repulsive deep ensembles are bayesian,2021, arXiv preprintarXiv:2106
 Efficient and scalable bayesian neural nets with rank-1 factors,2020, In Internationalconference on machine learning
 Deep ensembles: A loss landscape perspective,2019, arXivpreprint arXiv:1912
 Dropout as a Bayesian approximation: Representing model uncertainty indeep learning,2016, In International Conference on Machine Learning
 Deep convolutional networks asshallow gaussian processes,2018, In International Conference on Learning Representations
 Practical variational inference for neural networks,2011, In Advances in Neural Information ProcessingSystems
 On calibration of modern neural networks,2017, InInternational Conference on Machine Learning
 Bayesian deep ensembles via the neural tangentkernel,2020, In Advances in Neural Information Processing Systems
 Delving deep into rectifiers: Surpassing human-levelperformance on imagenet classification,2015, In Proceedings of the IEEE international conference on computervision 
 Deep residual learning for image recognition,2016, InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Benchmarking neural network robustness to common corruptions andperturbations,2018, In International Conference on Learning Representations
 Probabilistic backpropagation for scalable learning ofBayesian neural networks,2015, In International Conference on Machine Learning
 Batch normalization: Accelerating deep network training by reducinginternal covariate shift,2015, In International conference on machine learning
 Subspace inference for bayesian deep learning,2020, In Uncertainty in Artificial Intelligence
 Fantastic generalizationmeasures and where to find them,2019, In International Conference on Learning Representations
 Approximate inferenceturns deep networks into gaussian processes,2019, Advances in Neural Information Processing Systems
 Adam: A method for stochastic optimization,2015, In ICLR (Poster)
 Learning multiple layers of features from tiny images,2009, 2009
 Simple and scalable predictive uncertaintyestimation using deep ensembles,2017, In Advances in Neural Information Processing Systems
 Structured and efficient variational deep learning with matrix gaussianposteriors,2016, In International Conference on Machine Learning
 Ensemble sampling,2017, In NIPS
 A practical Bayesian framework for backpropagation networks,1992, Neural Computation
 Bayesian methods for adaptive models,1992, PhD thesis
 A simplebaseline for bayesian uncertainty in deep learning,2019, In Advances in Neural Information Processing Systems
 Sample-then-optimizeposterior sampling for bayesian linear models,2017, In NeurIPS Workshop on Advances in Approximate BayesianInference
 Bayesian Learning for Neural Networks,1995, PhD thesis
 Priors for infinite networks,1996, In Bayesian Learningfor Neural Networks
 Norm-based capacity control in neural networks,2015, InConference on Learning Theory
 Exploring generalization in deeplearning,2017, Advances in Neural Information Processing Systems
 Bayesian deep convolutional networks with many channels aregaussian processes,2018, In International Conference on Learning Representations
 Neural tangents: Fast and easy infinite neural networks in python,2019, In International Conferenceon Learning Representations
 Deep exploration via bootstrappeddqn,2016, Advances in neural information processing systems
 Uncertainty in neural networks: Approximately bayesianensembling,2020, In International conference on artificial intelligence and statistics
 Deep bayesian bandits showdown: An empirical comparisonof bayesian deep networks for thompson sampling,2018, In International Conference on Learning Representations
 Rethinking function-space variational inference in bayesianneural networks,2021, In Third Symposium on Advances in Approximate Bayesian Inference
 Kernel implicit variational inference,2018, In International Conference onLearning Representations
 Scalable training of inference networks for gaussian-processmodels,2019, In International Conference on Machine Learning
 Function space particle optimization for Bayesian neuralnetworks,2019, In International Conference on Learning Representations
 Deep kernel learning,2016, In Artificialintelligence and statistics
 Inverting modified matrices,1950, Statistical Research Group
 Fashion-mnist: a novel image dataset for benchmarking machinelearning algorithms,2017, arXiv preprint arXiv:1708
 Noisy natural gradient as variationalinference,2018, In International Conference on Machine Learning
 Cyclical stochasticgradient mcmc for bayesian deep learning,2019, In International Conference on Learning Representations
 The batch size for trainingdata is 64,1000, The batch size for extra measurement points is 0
