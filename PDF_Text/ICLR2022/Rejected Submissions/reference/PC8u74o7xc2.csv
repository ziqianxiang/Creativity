title,year,conference
 Analogies explained: Towards understanding word embed-dings,2019, In International Conference on Machine Learning
 What the vec? towards probabilisticallygrounded embeddings,2019, Advances in Neural Information Processing Systems
 Canonical labelling of graphs in linear average time,1979, In 20thAnnual Symposium on Foundations of Computer Science (sfcs 1979)
 Towardtransformer-based object detection,2020, ArXiv
 Enriching word vectors withsubword information,2017, Transactions of the Association for Computational Linguistics
 A non-local algorithm for image denoising,2005, In 2005IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)
 Variational methods for the solution of problems of equilibrium and vibra-tions,1994, Lecture notes in pure and applied mathematics
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Animage is worth 16x16 words: Transformers for image recognition at scale,2020, arXiv preprintarXiv:2010
 Inductive representation learning on largegraphs,2017, In Proceedings of the 31st International Conference on Neural Information ProcessingSystems
 Distributional structure,1954, Word
 Word embeddings as metricrecovery in semantic spaces,2016, Transactions of the Association for Computational Linguistics
 Stochastic estimation of the maximum of a regression function,0003, TheAnnals of Mathematical Statistics
 Adam: A method for stochastic optimization,2015, In YoshuaBengio and Yann LeCun (eds
 Neural word embedding as implicit matrix factoriza-tion,2014, In Z
 Topical word embeddings,2015, In AAAI
 Efficient estimation of word represen-tations in vector space,2013, In Yoshua Bengio and Yann LeCun (eds
 Hierarchical probabilistic neural network language model,2005, InInternational workshop on artificial intelligence and statistics
 Word sense disambiguation using cosine similarity collaborateswith word2vec and wordnet,2019, Future Internet
 Glove: Global vectors for wordrepresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 Glove: Global vectors for wordrepresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 Pte: Predictive text embedding through large-scale hetero-geneous text networks,2015, In Proceedings of the 21th ACM SIGKDD international conference onknowledge discovery and data mining
 The reduction of a graph to canonical form and the algebrawhich appears therein,1968, NTI
 BERT post-training for review reading compre-hension and aspect-based sentiment analysis,2019, In Proceedings of the 2019 Conference of theNorth American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Integrating and evaluating neuralword embeddings in information retrieval,2015, In Proceedings of the 20th Australasian documentcomputing symposium
 It uses sentence as a sample to guess word’s neighborhood which inducesa lot of noise,2014, Our framework would suggest to use the entire computation of fagg instead ofsampling if possible for a given fagg and graph
