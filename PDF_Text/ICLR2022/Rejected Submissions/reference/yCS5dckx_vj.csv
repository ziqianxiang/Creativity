title,year,conference
 On the optimization of deep networks: Implicitacceleration by overparameterization,2018, In ICML
 A convergence analysis of gradientdescent for deep linear neural networks,2019, In ICLR
 Learning representations by maximizingmutual information across views,2019, arXiv preprint arXiv:1906
 Vicreg: Variance-invariance-covariance regularizationfor self-supervised learning,2021, arXiv preprint arXiv:2105
 Signature Verifi-cation using a“ siamese” time delay neural network,1994, NeurIPS
 Emerging ProPerties in self-suPervised vision transformers,2021, arXiv preprintarXiv:2104
 A simPle framework forcontrastive learning of visual rePresentations,2020, arXiv preprint arXiv:2002
 ExPloring simPle siamese rePresentation learning,2020, arXiv preprintarXiv:2011
 ImProved baselines with momentumcontrastive learning,2020, arXiv preprint arXiv:2003
 An analysis of single-layer networks in unsuPervisedfeature learning,2011, In International conference on artificial intelligence and statistics
 ImageNet: A Large-Scale HierarchicalImage Database,2009, In CVPR
 Width Provably matters in oPtimization for deeP linear neural networks,2019, InICML
 Whitening for self-supervised representation learning,2021, In International Conference on Machine Learning
 Deep residual learning for image recog-nition,2016, In CVPR
 Momentum contrast forunsupervised visual representation learning,2020, In CVPR
 On featuredecorrelation in self-supervised learning,2021, ICCV
 Deep learning without poor local minima,2016, NeurIPS
 An analytic theory of generalization dynamics and transferlearning in deep linear networks,2018, In ICLR
 Deep linear networks with arbitrary loss: All local minima areglobal,2018, In ICML
 Predicting what you already know helps:Provable self-supervised learning,2020, arXiv preprint arXiv:2008
 Representation learning with contrastive predic-tive coding,2018, arXiv preprint arXiv:1807
 Byol workseven without batch statistics,2020, arXiv
 Exact solutions to the nonlinear dynam-ics of learning in deep linear neural networks,2013, arXiv preprint arXiv:1312
 A mathematical theory of semanticdevelopment in deep neural networks,2019, Proc
 Contrastive multiview coding,2019, arXiv preprintarXiv:1906
 Understanding self-supervised learning dynamicswithout contrastive pairs,2021, arXiv preprint arXiv:2102
 Introduction to the non-asymptotic analysis of random matrices,2010, arXiv preprintarXiv:1011
 Toward understanding the feature learning process of self-supervisedcontrastive learning,2021, arXiv preprint arXiv:2105
 Barlow twins: Self-supervisedlearning via redundancy reduction,2021, ICML
