title,year,conference
 Optimization and abstraction:A synergistic approach for analyzing neural network robustness,2019, In Proceedings of the 40th ACMSIGPLAN Conference on Programming Language Design and Implementation (PLDI)
 Square at-tack: a query-efficient black-box adversarial attack via random search,2020, In European Conferenceon Computer Vision
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Primal heuristics for mixed integer programs,2006, 2006
 Evasion attacks against machine learning at test time,2013, In JointEuropean conference on machine learning and knowledge discovery in databases
 Effi-cient verification of relu-based neural networks via dependency analysis,2020, In AAAI Conference onArtificial Intelligence (AAAI)
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In ICLR
 Lagrangian decomposition for neural network verifica-tion,2020, Conference on Uncertainty in Artificial Intelligence (UAI)
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Zoo: Zeroth order opti-mization based black-box attacks to deep neural networks without training substitute models,2017, InProceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Query-efficient hard-label black-box attack: An optimization-based approach,2018, arXiv preprintarXiv:1807
 Minimally distorted adversarial examples with a fast adaptiveboundary attack,2020, In International Conference on Machine Learning
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In International conference on machine learning
 Improved branch and bound for neural network verificationvia lagrangian decomposition,2021, arXiv preprint arXiv:2104
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE conference on computervision and pattern recognition
 Output range analysisfor deep feedforward neural networks,2018, In NASA Formal Methods Symposium
 Adual approach to scalable verification of deep networks,2018, Conference on Uncertainty in ArtificialIntelligence (UAI)
 Explaining and harnessing adversarialexamples,2015, In ICLR
 On the effectiveness of interval bound propagation fortraining verifiably robust models,2019, Proceedings of the IEEE International Conference on ComputerVision (ICCV)
 Safety verification of deep neuralnetworks,2017, In International Conference on Computer Aided Verification (CAV)
 Black-box adversarial attacks withlimited queries and information,2018, In International Conference on Machine Learning (ICML)
 Prior convictions: Black-box adversarialattacks with bandits and priors,2018, arXiv preprint arXiv:1807
 Reluplex: Anefficient smt solver for verifying deep neural networks,2017, In International Conference on ComputerAided Verification (CAV)
 Neural network robust-ness verification on gpus,2020, arXiv preprint arXiv:2007
 Pre-cise multi-neuron abstractions for neural network certification,2021, arXiv preprint arXiv:2103
 Solvingmixed integer programs using neural networks,2020, arXiv preprint arXiv:2012
 Towards the science ofsecurity and privacy in machine learning,2016, arXiv preprint arXiv:1611
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Certified defenses against adversarial exam-ples,2018, International Conference on Learning Representations (ICLR)
 Semidefinite relaxations for certify-ing robustness to adversarial examples,2018, In Advances in Neural Information Processing Systems(NeurIPS)
 Fast neural net-work verification via shadow prices,2019, arXiv preprint arXiv:1902
 A convex relaxationbarrier to tight robustness verification of neural networks,2019, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Fastand effective robustness certification,2018, In Advances in Neural Information Processing Systems(NeurIPS)
 Boosting robustness certifica-tion of neural networks,2018, In International Conference on Learning Representations
 Intriguing properties of neural networks,2013, In ICLR
 Diversity can be transferred: Output diversificationfor white-and black-box attacks,2020, Advances in Neural Information Processing Systems (NeurIPS)
 Evaluating robustness of neural networks with mixedinteger programming,2019, International Conference on Learning Representations (ICLR)
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Integer optimization by local search: A domain-independent approach,2003, Springer
 Efficient formal safetyanalysis of neural networks,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Formal security analysisof neural networks using symbolic intervals,2018, In USENIX Security Symposium
 Enhancing gradient-based attackswith symbolic intervals,2019, arXiv preprint arXiv:1906
 Beta-crown: Efficient bound propagation with per-neuron split constraints for complete and incompleteneural network verification,2021, arXiv preprint arXiv:2103
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning (ICML)
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Training for fasteradversarial robustness verification via inducing relu stability,2019, In ICLR
 Automatic perturbation analysis for scalable certifiedrobustness and beyond,2020, Advances in Neural Information Processing Systems (NeurIPS)
 Fastand complete: Enabling complete neural network verification with rapid and massively parallelincomplete verifiers,2021, International Conference on Learning Representations (ICLR)
 Efficient neural net-work robustness certification with general activation functions,2018, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Distributionally adversarial attack,2019, In Proceedingsof the AAAI Conference on Artificial Intelligence (AAAI)
 Beam-stack search: Integrating backtracking with beam search,2005, InICAPS
