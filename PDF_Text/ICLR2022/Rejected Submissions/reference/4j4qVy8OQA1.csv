title,year,conference
 Forecasting sequentialdata using consistent Koopman autoencoders,2020, In International Conference on Machine Learning
 Neural machine translation by jointlylearning to align and translate,2015, In International Conference on Learning Representations
 The problem of learning long-term dependenciesin recurrent networks,1993, In IEEE international conference on neural networks
 Modern KooPman theory fordynamical systems,2021, arXiv preprint arXiv:2102
 Learning phrase representations using RNN encoder-decoder forstatistical machine translation,2014, In EMNLP
 Optimizing neural networks via Koopman operatortheory,2020, In Advances in Neural Information Processing Systems
 Bifurcations of recurrent neural networks in gradient descent learning,1993, IEEE Transactionson neural networks
 Universality of fully connected recurrent neural networks,1993, Dept
 Finding structure in time,1990, Cognitive science
 Physics-informed autoen-coders for lyapunov-stable fluid flow prediction,2019, arXiv preprint arXiv:1905
 Deep residual learning for imagerecognition,2016, In CVPR
 Long short-term memory,1997, Neural computation
 Hamiltonian systems and transformation in Hilbert space,1931, Proceedings of thenational academy of sciences of the united states of america
 Learning compositional Koopmanoperators for model-based control,2020, In International Conference on Learning Representations
 How recurrent networks implement contextual processingin sentiment analysis,2020, arXiv preprint arXiv:2004
 Reverseengineering recurrent networks for sentiment classification reveals line attractor dynamics,2019, InAdvances in Neural Information Processing Systems
 Applications of Koopman mode analysis to neural networks,2020, arXivpreprint arXiv:2006
 VAMPnets for deep learning of molecularkinetics,2018, Nature communications
 Deep dynamicalmodeling and control of unsteady fluid flows,2018, In Advances in Neural Information ProcessingSystems
 On the difficulty of training recurrent neuralnetworks,2013, In International Conference on Machine Learning
 Composition operators on function spaces,1993, Elsevier
 Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks,2013, Neural computation
 Attention is all you need,2017, In Advances in neural informationprocessing Systems
