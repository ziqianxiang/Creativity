title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Magnet and” efficient defenses against adversarial attacks” arenot robust to adversarial examples,2017, arXiv preprint arXiv:1711
 Towards evaluating the robustness of neural networks,2017, In 2017Ieee Symposium on Security and Privacy (Sp)
 Unlabeleddata improves adversarial robustness,2019, In Hanna M
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In Proceedings of the 37th International Conference on MachineLearning
 On thesensitivity of adversarial robustness to input data distributions,2019, In ICLR (Poster)
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Countering adversarialimages using input transformations,2018, In 6th International Conference on Learning Representations
 Deep residual learning for imagerecognition,2016, In Conference on Computer Vision and Pattern Recognition
 APE-GAN: adversarialperturbation elimination with GAN,2019, In International Conference on Acoustics
 Learning multiple layers of features from tiny images,2009, 2009
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Conference on ComputerVision and Pattern Recognition
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, In International Conference on Learning Representations
 Understandingadversarial attacks on deep learning based medical image analysis systems,2021, Pattern Recognition
 Decoupling direction and norm for efficient gradient-based L2 adversarial attacks anddefenses,2019, In Conference on Computer Vision and Pattern Recognition
 Very deep convolutional networks for large-scale imagerecognition,2015, In Yoshua Bengio and Yann LeCun (eds
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Improvingadversarial robustness requires revisiting misclassified examples,2019, In International Conference onLearning Representations
 Tiny imagenet challenge,2017, Technical Report
 Stronger and faster wasserstein adversarialattacks,2020, In Proceedings of the 37th International Conference on Machine Learning
 Class2simi: A noise reduction perspective on learning with noisy labels,2021, InInternational Conference on Machine Learning
 Part-dependent label noise: Towards instance-dependentlabel noise,2020, Advances in Neural Information Processing Systems
 Spatially transformedadversarial examples,2018, In 6th International Conference on Learning Representations
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Estimatinginstance-dependent label-noise transition matrix using dnns,2021, arXiv preprint arXiv:2105
 Towardsdefending against adversarial examples via attack-invariant features,2021, In Proceedings of the 38thInternational Conference on Machine Learning
