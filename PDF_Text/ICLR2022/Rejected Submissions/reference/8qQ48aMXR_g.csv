title,year,conference
 Stochastic training of graph convolutional networks withvariance reduction,2017, arXiv preprint arXiv:1710
 Stochastic training of graph convolutional networks withvariance reduction,2017, arXiv preprint arXiv:1710
 Fastgcn: fast learning with graph convolutional networks viaimportance sampling,2018, arXiv preprint arXiv:1801
 Convolutional networks on graphs forlearning molecular fingerprints,2015, arXiv preprint arXiv:1509
 Addressing the cold start problem in active learn-ing approach used for semi-automated sleep stages classification,2018, In 2018 IEEE InternationalConference on Bioinformatics and Biomedicine (BIBM)
 On large-batch training for deep learning: Generalization gap and sharp minima,2016, arXivpreprint arXiv:1609
 Diffusion convolutional recurrent neural net-work: Data-driven traffic forecasting,2017, arXiv preprint arXiv:1707
 Subgroup generalization and fairness of graph neuralnetworks,2021, arXiv preprint arXiv:2106
 On the universality of invariantnetworks,2019, In International conference on machine learning
 Birds of a feather: Homophily in socialnetworks,2001, Annual review of sociology
 Active learning literature survey,2009, Computer Sciences Technical Report 1648
 Graph attention networks,2017, arXiv preprint arXiv:1710
 Beyondhomophily in graph neural networks: Current limitations and effective designs,2020, arXiv preprintarXiv:2006
 Let D be a given training set,2022, M and f are the GNN model and prediction functionwhich have parameter Î¸ and satisfy the property in Assumption 2
