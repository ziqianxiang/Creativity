title,year,conference
 Learning to recombine and resampledata for compositional generalization,2021, In International Conference on Learning Representations
 Good-enoUgh compositional data aUgmentation,2020, In Proceedings of the 58th AnnualMeeting of the Association for Computational Linguistics
 Incorporating discrete translation lexiconsinto neural machine translation,2016, In Proceedings of the 2016 Conference on Empirical Methods inNatural Language Processing
 The psychology of meaningful verbal learning,1963, 1963
 Neural machine translation by jointlylearning to align and translate,2015, In Yoshua Bengio and Yann LeCun (eds
 Com-positional generalization via neural-symbolic stack machines,2020, In Hugo Larochelle
 Syntactic structures,1957, 1957
 The devil is in the detail: Simple tricksimprove systematic generalization of transformers,2021, arXiv preprint arXiv:2108
 The compositionality papers,2002, Oxford University Press
 Connectionism and cognitive architecture: A critical analy-sis,1988, Cognition
 Convolutionalsequence to sequence learning,2017, In International Conference on Machine Learning
 Distributional structure,1954, Word
 Long short-term memory,1997, Neural computation
 Measuring comPo-sitional generalization: A comPrehensive method on realistic data,2019, In International Conferenceon Learning Representations
 Cogs: A comPositional generalization challenge based on semanticinterPretation,2020, arXiv preprint arXiv:2010
 Adam: A method for stochastic oPtimization,2015, In YoshuaBengio and Yann LeCun (eds
 The social motivation of a sound change,1963, Word
 ComPositional generalization through meta sequence-to-sequence learn-ing,2019, In H
 Generalization without systematicity: On the comPositionalskills of sequence-to-sequence recurrent networks,2017, the 35th International Conference on MachineLearning (ICML 2018)
 Effective aPProaches to attention-basedneural machine translation,2015, In Proceedings of the 2015 Conference on Empirical Methods inNatural Language Processing
 Linguistic semantics: An introduction,1995, Cambridge University Press
 Rethinking eliminative connectionism,1998, Cognitive psychology
 The algebraic mind: Integrating connectionism and cognitive science,2018, MIT Press
 Rote versus meaningful learning,2002, Theory into practice
 Efficient estimation of word represen-tations in vector sPace,2013, In Yoshua Bengio and Yann LeCun (eds
 ExPloiting similarities among languages for ma-chine translation,2013, arXiv preprint arXiv:1309
 Universal grammar,1970, 1974
 Cognitive preference and learning mode asdeterminants of meaningful learning through concept mapping,1988, Science Education
 Bleu: a method for automaticevaluation of machine translation,2002, In Proceedings of the 40th annual meeting of the Associationfor Computational Linguistics
 Contextual correlates of synonymy,0001, Commun
 Bidirectional recurrent neural networks,1997, IEEE transactionson Signal Processing
 Attention is all you need,2017, In I
 Matching networks for oneshot learning,2016, Advances in neural information processing Systems
 Birre: learning bidirectional residual relation embeddings forsupervised hypernymy detection,2020, In Proceedings of the 58th Annual Meeting of the Associationfor Computational Linguistics
 A learning algorithm for continually running fully recurrentneural networks,1989, Neural computation
 Unsupervised dataaugmentation for consistency training,2019, arXiv preprint arXiv:1904
 Synet: Synonymexpansion using transitivity,2020, In Proceedings of the 2020 Conference on Empirical Methods inNatural Language Processing: Findings
 A basic assumption isthat all languages change over time due to non-linguistic factors,2015, Since the rise of sociolinguistics inthe 1960s
 The embedding size is 512 for both encoder and decoder,1989, Thereare a total of 5
 is adapted from the seq2seq convolutional network proposed by Wu et al,1024, (2019)
