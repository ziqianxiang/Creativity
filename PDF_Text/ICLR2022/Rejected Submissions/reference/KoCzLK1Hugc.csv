title,year,conference
 Square at-tack: a query-efficient black-box adversarial attack via random search,2020, In ECCV
 Understanding deep neuralnetworks with rectified linear unit,2018, In ICLR
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Adversarial robustness on in- andout-distribution improves explainability,2020, In ECCV
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In ICLR
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy
 Unlabeleddata improves adversarial robustness,2019, In NeurIPS 
 Ead: Elastic-net attacksto deep neural networks via adversarial examples,2018, In AAAI
 Adversarialrobustness: From self-supervised pre-training to fine-tuning,2020, In CVPR
 Query-efficient hard-label black-box attack: An optimization-based approach,2019, In ICLR
 Minimally distorted adversarial examples with a fast adaptiveboundary attack,2020, In ICML
 Provable robustness against all adversarial lp-perturbations forp â‰¥ 1,2020, In ICLR
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In ICML
 Mind the box: l1-apgd for sparse adversarial attacks on imageclassifiers,2021, In ICML
 Robustbench: a standardized adversarial robustness bench-mark,2020, arXiv preprint arXiv:2010
 Adversarial classifi-cation,2004, In KDD
 Mma training: Directinput space margin maximization through adversarial training,2020, In ICLR
 Deep Learning,2016, MIT Press
 Explaining and harnessing adversarialexamples,2015, In ICLR
 On the effectiveness of intervalbound propagation for training verifiably robust models,2018, preprint
 Uncoveringthe limits of adversarial training against norm-bounded adversarial examples,2020, arXiv preprintarXiv:2010
 Identity mappings in deep residualnetworks,2016, In ECCV
 Benchmarking neural network robustness to common cor-ruptions and perturbations,2019, In ICLR
 Using pre-training can improve model robustnessand uncertainty,2019, In ICML
 A simple fine-tuning is all youneed: Towards robust deep learning via adversarial fine-tuning,2020, arXiv preprint
 Testing robustness againstunforeseen adversaries,2019, arXiv preprint arXiv:1908
 Adversarial examples in the physical world,2017, InICLR Workshop
 Perceptual adversarial robustness: Defense againstunseen threat models,2021, In ICLR
 signSGD via zeroth-order oracle,2019, InICLR
 Adversarial learning,2005, In KDD
 Learning to generate noise for multi-attackrobustness,2021, In ICML
 Adversarial robustness against the union of multipleperturbation models,2020, In ICML
 Yet another but more efficient black-box adver-sarial attack: tiling and evolution strategies,2019, arXiv preprint
 Sparsefool: a few pixelsmake a big difference,2019, In CVPR
 Adversarial training against location-optimized adver-sarial patches,2020, In ECCV Workshop on the Dark and Bright Sides of Computer Vision: Challengesand Oppurtinities for Privacy and Security
 Augmented Lagrangian adver-sarial attacks,2021, In ICCV
 Disentangling adversarial robustness and general-ization,2019, CVPR
 Confidence-calibrated adversarial training: Gener-alizing to unseen attacks,2020, In ICML
 Intriguing properties of neural networks,2014, In ICLR
 Adversarial training and robustness for multiple perturbations,2019, InNeurIPS
 On adaptive attacks toadversarial example defenses,2020, In NeurIPS
 Learning perturbation sets for robust machine learning,2021, In ICLR
 Scaling provable adversarialdefenses,2018, In NeurIPS
 Adversarial momentum-contrastive pre-training,2020, arXiv preprint
 Wide residual networks,2016, In BMVC
 Adversarial framing forimage and video classification,2019, In AAAI
 On thedesign of black-box adversarial examples by leveraging gradient-free optimization and operatorsplitting method,2019, In ICCV
