title,year,conference
 Neural machine translation by jointlylearning to align and translate,2014, arXiv preprint arXiv:1409
 End-to-end object detection with transformers,2020, In European Conferenceon Computer Vision
 An attentive survey ofattention models,2019, arXiv preprint arXiv:1904
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Animage is worth 16x16 words: Transformers for image recognition at scale,2020, arXiv preprintarXiv:2010
 Sparse subspace clustering,2009, In IEEE Conference on ComputerVision and Pattern Recognition
 Attention in natural language processing,2020, IEEETransactions on Neural Networks and Learning Systems
 Neural turing machines,2014, arXiv preprintarXiv:1410
 Transfg: A transformer architecture for fine-grained recognition,2021, arXiv preprintarXiv:2103
 Transformers in vision: A survey,2021, arXiv preprint arXiv:2101
 Robust subspace segmentation by low-rank repre-Sentation,2010, In International Conference on Machine Learning
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Robustand efficient subspace segmentation via least squares regression,2012, In European Conference onComputer Vision
 From softmax to sparsemax: A sparse model of attentionand multi-label classification,1614, In International conference on machine learning
 Languagemodels are unsupervised multitask learners,2019, OpenAI blog
 Exploring the limits of transfer learning with a unified text-to-texttransformer,2019, arXiv preprint arXiv:1910
 Nonlinear dimensionality reduction by locally linear embedding,2000, Science
 Vl-bert: Pre-trainingof generic visual-linguistic representations,2019, arXiv preprint arXiv:1908
 Lxmert: Learning cross-modality encoder representations from trans-formers,2019, arXiv preprint arXiv:1908
 Attention is all you need,2017, In Neural Information ProcessingSystems
 Generalized Principal Component Analysis,2016, SpringerVerlag
 Noisy sparse subspace clustering,2013, In International Conference onMachine Learning
 Provable subspace clustering: When LRR meetsSSC,2013, In Neural Information Processing Systems
 Dive into deep learning,2021, arXivpreprint arXiv:2106
 Deformable detr:Deformable transformers for end-to-end object detection,2020, arXiv preprint arXiv:2010
