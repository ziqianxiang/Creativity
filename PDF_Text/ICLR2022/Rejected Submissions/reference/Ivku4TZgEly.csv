title,year,conference
 Sanitychecks for saliency maps,2018, In S
 Explainable machine learning indeployment,2020, In Proceedings of the 2020 Conference on Fairness
 Visualizing higher-layerfeatures of a deep network,2009, Technical report
 Interpretable explanations of black boxes by meaningful per-turbation,2017, 2017 IEEE International Conference on Computer Vision (ICCV)
 European union regulations on algorithmic decision-makinganda “right to explanation”,0738, AI Magazine
 A benchmark for interpretabilitymethods in deep neural networks,2019, In H
 Gradient-based learning applied to documentrecognition,1998, Proceedings ofthe IEEE
 A unified approach to interpreting model predictions,2017, In I
 A Value for N-Person Games,1952, RAND Corporation
 Deep inside convolutional networks: visualising imageclassification models and saliency maps,2014, pp
 Visualizing the impact of feature attributionbaselines,2020, Distill
 Axiomatic attribution for deep networks,2017, CoRR
 Understanding neuralnetworks through deep visualization,2015, In Deep Learning Workshop
