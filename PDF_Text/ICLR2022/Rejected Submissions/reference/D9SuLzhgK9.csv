title,year,conference
 Disentangling adaptivegradient methods from learning rates,2020, arXiv preprint arXiv:2002
 Forward super-resolution: How can gans learn hierarchicalgenerative models for real-world distributions,2021, arXiv preprint arXiv:2106
 An adaptive mirror-prox method for variational inequalities with singular operators,2019, Advances in Neural InformationProcessing Systems
 Adaptive extra-gradient methods for min-max optimization and games,2020, arXiv preprint arXiv:2010
 Do gans learn the distribution? some theory andempirics,2018, In International Conference on Learning Representations
 A universal algorithm for variational inequalities adaptive to smooth-ness and noise,2019, In Conference on Learning Theory
 Approximability of discriminators implies diversity ingans,2018, arXiv preprint arXiv:1806
 Understanding overparameterization in generative ad-versarial networks,2021, arXiv preprint arXiv:2104
 Began: Boundary equilibrium generative ad-versarial networks,2017, arXiv preprint arXiv:1703
 Large scale gan training for high fidelity naturalimage synthesis,2018, arXiv preprint arXiv:1809
 On empirical comparisons of optimizers for deep learning,2019, arXiv preprintarXiv:1910
 Training gans withoptimism,2017, arXiv preprint arXiv:1711
 Adversarially learned inference,2016, arXiv preprint arXiv:1606
 Understanding gans: the lqg setting,2017, arXivpreprint arXiv:1710
 Gradient descent-ascent provably converges to strict local minmaxequilibria with a finite timescale separation,2020, arXiv preprint arXiv:2009
 An adaptive proximal method forvariational inequalities,2019, Computational Mathematics and Mathematical Physics
 Generative adversarial nets,2014, Advances in neural informationprocessing systems
 Im-proved training of wasserstein gans,2017, arXiv preprint arXiv:1704
 Beyond convexity: Stochastic quasi-convexoptimization,2015, arXiv preprint arXiv:1507
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Sgd learns one-layer networks inwgans,2020, In International Conference on Machine Learning
 Making method of moments great again?-how can gans learn distribu-tions,2020, arXiv preprint arXiv:2003
 Towards better understanding of adaptive gradient algorithms in generative adversarialnets,2019, arXiv preprint arXiv:1912
 Learning by turning: Neural archi-tecture aware optimisation,2021, arXiv preprint arXiv:2102
 Spectral normalizationfor generative adversarial networks,2018, arXiv preprint arXiv:1802
 Revisiting normalized gradient descent: Fastevasion of saddle points,2019, IEEE Transactions on Automatic Control
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2015, arXiv preprint arXiv:1511
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Large batch training of convolutional networks,2017, arXivpreprint arXiv:1708
 Large batch optimization for deeplearning: Training bert in 76 minutes,2019, arXiv preprint arXiv:1904
 fastmri: An open dataset andbenchmarks for accelerated mri,2018, arXiv preprint arXiv:1811
 Self-attention generativeadversarial networks,2019, In International conference on machine learning
 On the discrimination-generalization tradeoff in gans,2017, arXiv preprint arXiv:1711
 Onthe convergence of adaptive gradient methods for nonconvex optimization,2018, arXiv preprintarXiv:1808
