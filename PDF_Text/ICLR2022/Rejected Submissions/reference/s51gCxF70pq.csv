title,year,conference
 Contrastivebehavioral similarity embeddings for generalization in reinforcement learning,2021, In InternationalConference on Learning Representations
 Gradient based sample selectionfor online continual learning,2019, In 33rd Conference on Neural Information Processing Systems(NeurIPS)
 Unsupervised state representation learning in atari,2019, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Layer normalization,2016, arXiv preprintarXiv:1607
 Representation learning: A review and newperspectives,2013, IEEE Transactions on Pattern Analysis and Machine Intelligence
 A simple framework forcontrastive learning of visual representations,2020, In Proceedings of the 37th International Conferenceon Machine Learning (ICML)
 Big self-supervised models are strong semi-supervised learners,2020, In 34th Conference on Neural InformationProcessing Systems (NeurIPS)
 Improved baselines with momentumcontrastive learning,2020, arXiv preprint arXiv:2003
 DeepMDP:Learning continuous latent space models for representation learning,2019, In Proceedings of the 36thInternational Conference on Machine Learning (ICML)
 Bootstrap latent-predictive representations for multitask reinforce-ment learning,2020, In International Conference on Machine Learning (ICML)
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In Proceedings of the 35thInternational Conference on Machine Learning (ICML)
 Soft actor-critic algo-rithms and applications,2018, arXiv preprint arXiv:1812
 Dream to control: Learn-ing behaviors by latent imagination,2020, In International Conference on Learning Representations(ICLR)
 Mastering atari withdiscrete world models,2021, In Internation Conference on Learning Representations (ICLR)
 Data-efficient image recognition with contrastive predictive coding,2020, InProceedings of the 37th International Conference on Machine Learning (ICML)
 Reproducibility of bench-marked deep reinforcement learning tasks for continuous control,2017, In Proceedings of the ICML2017 workshop on Reproducibility in Machine Learning (RML)
 Adaptive scheduling for multi-task learning,2018, InContinual Learning Workshop at the 32nd Conference on Neural Information Processing Systems(NeurIPS)
 QT-Opt:Scalable deep reinforcement learning for vision-based robotic manipulation,2018, In 2nd Conferenceon Robot Learning (CoRL)
 CURL: Contrastive unsupervised representa-tions for reinforcement learning,2020, In Proceedings of the 37th International Conference on MachineLearning (ICML)
 Rein-forcement learning with augmented data,2020, In 34th Conference on Neural Information ProcessingSystems (NeurIPS)
 Stochastic latent actor-critic:Deep reinforcement learning with a latent variable model,2020, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Predictive information accelerates learning in rl,2020, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Human-level control through deep reinforcement learning,2015, Nature
 Data-efficient reinforcement learning with self-predictive representations,2021, In InternationalConference on Learning Representations (ICLR)
 Multi-task learning as multi-objective optimization,2018, In 32ndConference on Neural Information Processing Systems (NeurIPS)
 Loss is its own reward: Self-supervision for reinforcement learning,2017, In International Conference on Learning Representations(ICLR)
 Decoupling representation learningfrom reinforcement learning,2021, In Proceedings of the 38th International Conference on MachineLearning (ICML)
 DeepMind control suite,2018, arXiv preprint arXiv:1801
 dm_control: Software and tasks forcontinuous control,2020, arXiv preprint arXiv:2006
 Representation learning with contrastive predic-tive coding,2018, arXiv preprint arXiv:1807
 Au-toloss: Learning discrete schedules for alternate optimization,2019, In International Conference onLeanring Representations (ICLR)
 Im-proving sample efficiency in model-free reinforcement learning from images,2020, arXiv preprintarXiv:1910
 Reinforcement learning with proto-typical representations,2021, In Proceedings of the 38th International Conference on Machine Learning(ICML)
 Paying more attention to attention: Improving the per-formance of convolutional neural networks via attention transfer,2017, In International Conference onLearning Representations (ICLR)
 Learn-ing invariant representations for reinforcement learning without reconstruction,2021, In InternationalConference on Learning Representations (ICLR)
