title,year,conference
 Do deep nets really need to be deep? In Z,2014, Ghahramani
 Signatureverification using a “Siamese” time delay neural network,1993, In Proceedings of the 6th InternationalConference on Neural Information Processing Systems
 Pre-trainingtasks for embedding-based large-scale retrieval,2020, In 8th International Conference on LearningRepresentations
 Deeper text understanding for IR with contextual neural languagemodeling,2019, In Benjamin Piwowarski
 Intra-Document Cascading: Learning to Select Passages for Neural Document Ranking,2021, In Proc
 Billion-scale similarity search with gPus,2021, IEEETransactions on Big Data
 Focal loss for denseobject detection,2017, In IEEE International Conference on Computer Vision
 A replication study of dense passageretrieVer,2021, CoRR
 Cedr: Contextualizedembeddings for document ranking,2019, In SIGIR
 High accuracyretrieVal with multiple nested ranker,1595, In Proceedings of the 29th Annual International ACM SIGIRConference on Research and Development in Information Retrieval
 Thinkingfast and slow: Efficient text-to-Visual retrieVal with transformers,2021, In IEEE Conference on ComputerVision and Pattern Recognition
 An introduction to neural information retrieVal,1554, Foundations andTrends® in Information Retrieval
 Passage re-ranking with BERT,2019, CoRR
 RankDistil: Knowledge distillation for ranking,2021, InArindam Banerjee and Kenji Fukumizu (eds
 Sentence-bert: Sentence embeddings using Siamese BERT-networks,2019, In Proceedings of the 2019 Conference on Empirical Methods in Natural LanguageProcessing
 Trends Inf,1554, Retr
 Patient knowledge distillation for BERT modelcompression,2019, In Kentaro Inui
 Rethink-ing the inception architecture for computer vision,2016, In 2016 IEEE Conference on Computer Visionand Pattern Recognition
 Well-read students learn better:The impact of student initialization on knowledge distillation,2019, CoRR
 Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers,2020, In H
 Approximate nearest neighbor negative contrastive learning for dense textretrieval,2021, In International Conference on Learning Representations
 BERT-of-theseus: CompressingBERT by progressive module replacing,2020, In Proceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing (EMNLP)
 Optimizingdense retrieval model training with hard negatives,2021, CoRR
 Jointly optimizingquery encoder and product quantization to improve retrieval performance,2021, In CIKM
 He has been play,1938, 
