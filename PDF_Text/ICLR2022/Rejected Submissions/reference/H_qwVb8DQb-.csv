title,year,conference
 Iterative solution of games by fictitious play,1951, Activity analysis of production andallocation
 Gradnorm: Gradientnormalization for adaptive loss balancing in deep multitask networks,2018, In International Conferenceon Machine Learning
 Multi-task learning with deep neural networks: A survey,2020, arXiv preprintarXiv:2009
 Model-agnostic meta-learning for fast adaptation ofdeep networks,2017, In Proceedings of the 34th International Conference on Machine Learning (ICML)
 Distributionally robust stochastic optimization with wassersteindistance,2016, arXiv preprint arXiv:1604
 Dynamic task prioriti-zation for multitask learning,2018, In Proceedings of the European Conference on Computer Vision(ECCV)
 Kullback-leibler divergence constrained distributionally robust opti-mization,2013, Available at Optimization Online
 Information theory and statistical mechanics,1957, Physical review
 Adaptive scheduling for multi-task learning,2019, arXivpreprint arXiv:1909
 Adam: A method for stochastic optimization,2014, In Proceedings ofthe International Conference on Learning Representations (ICLR)
 Scheduled multi-task learning: From syntax totranslation,2018, Transactions ofthe Associationfor Computational Linguistics
 Exponentiated gradient versus gradient descent for linearpredictors,1997, information and computation
 Learning multiple layers of features from tiny images,2009, Technical report
 Subword regularization: Improving neural network translation models with mul-tiple subword candidates,2018, In Proceedings of the 56th Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Papers)
 Bimatrix equilibrium points and mathematical programming,1965, Management science
 Large-scale methods for distributionallyrobust optimization,2020, Proceedings of the 34th Annual Conference on Neural Information ProcessingSystems (NeurIPS)
 Darts: Differentiable architecture search,2018, InProceedings of the International Conference on Learning Representations (ICLR)
 Effcient Continuous Pareto Exploration in Multi-TaskLearning,2020, In Proceedings of ICML 2020
 Distributionally robustlanguage modeling,2019, In Proceedings of the 2019 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP)
 Distributionally Robust Optimization: A ReView,2019, arXivpreprint arXiv:1908
 Routing networks: AdaptiVe selection ofnon-linear functions for multi-task learning,2018, In Proceedings of the International Conference onLearning Representations (ICLR)
 An OVerView of Multi-Task Learning in Deep Neural Networks,2017, In arXiv preprintarXiv:1706
 Neural transfer learning for natural language processing,2019, PhD thesis
 A hierarchical multi-task approach for learningembeddings from semantic tasks,2019, In Proceedings of the 33rd Meeting of the Association forAdvancement of Artificial Intelligence (AAAI)
 Attention is all you need,2017, In Proceedings of the 31st AnnualConference on Neural Information Processing Systems (NIPS)
 Gradient Vaccine: Investigating andImproving Multi-task Optimization in Massively Multilingual Models,2021, In Proceedings of ICLR2021
 Examining and combating spuriousfeatures under distribution shift,2021, In Proceedings of the 38th International Conference on MachineLearning (ICML)
