title,year,conference
 Towards robust interpretability with self-explainingneural networks,2018, In Neural Information Processing Systems (NeurIPS)
 Entropy-based logic explanations of neural networks,2021, CoRR
 Representation learning: A review and newperspectives,2013, IEEE transactions on pattern analysis and machine intelligence
 Explainable machine learning in de-ployment,2020, In Proceedings of the 2020 Conference on Fairness
 Logic explained networks,2021, CoRR
 Step-wise sensitivity analysis: Identifying partially distributedrepresentations for interpretable deep learning,2018, 2018
 Towards automatic concept-basedexplanations,2019, In Neural Information Processing Systems (NeurIPS)
 beta-vae: Learning basic visual concepts with aconstrained variational framework,2017, In International Conference on Learning Representations(ICLR)
 Disentangling by factorising,2018, In Jennifer G
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2014, In Yoshua Bengio andYann LeCun (eds
 Concept bottleneck models,2020, In International Conference on Machine Learning(ICML)
 Challenging common assumptions in the unsupervised learn-ing of disentangled representations,2019, In International Conference on Machine Learning (ICML)
 Disentangling factors of variations using few labels,2020, In International Conferenceon Learning Representations (ICLR)
 A unified approach to interpreting model predictions,2017, In AnnualConference on Neural Information Processing Systems (NeurIPS)
 Gcexplainer: Human-in-the-loop concept-based explanations for graph neural networks,2021, CoRR
 Promises andpitfalls of black-box concept learning models,2021, CoRR
 ”why should I trust you?”： Explaining thepredictions of any classifier,2016, In International Conference on data science and advanced analytics(DSAA)
 Learning deep disentangled embeddings with the f-statisticloss,2018, In Advances in Neural Information Processing Systems (NeurIPS)
