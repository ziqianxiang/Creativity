title,year,conference
 Online learning for linearly parametrized control problems,2012, PhD thesis
 Improved algorithms for linear stochasticbandits,2011, In Advances in Neural Information Processing Systems
 Finite time analysis of the multiarmed banditproblem,2002, Machine Learning
 Unifying count-based exploration and intrinsic motivation,2016, In Advances in Neural Information Processing Systems
 An empirical evaluation of Thompson sampling,2011, In Advances inNeural Information Processing Systems
 Human-level control through deep reinforcementlearning,2015, Nature
 The uncertainty Bellman equation and explo-ration,2018, In Proceedings of the 35rd International Conference on Machine Learning
 Deep exploration via bootstrapped dqn,2016, InAdvances in neural information processing systems
 The multi-armed bandit problem with covariates,2013, The Annals of Statistics
 Deep Bayesian bandits showdown: An empiricalcomparison of Bayesian deep networks for Thompson sampling,2018, In Proceedings of the 6thInternational Conference on Learning Representations
 Learning to optimize via information-directed sampling,2014, In Advances inNeural Information Processing Systems
 A bayesian framework for reinforcement learning,2000, In Proceedings of the 17th internationalconference on Machine learning
 Reinforcement Learning: An Introduction,2018, The MIT Press
 On the likelihood that one unknown probability exceeds another in view ofthe evidence of two samples,1933, Biometrika
 Deep reinforcement learning with double Q-learning,2016, InProceedings of the 30th AAAI Conference on Artificial Intelligence
 Learning from Delayed Rewards,1989, PhD thesis
 Efficient exploration and value function generalization in deterministicsystems,2013, In Advances in neural information processing systems
 Self-correcting q-learning,2020, arXiv preprint arXiv:2012
