title,year,conference
 A publicdomain dataset for human activity recognition using smartphones,2013, 21th European Symposiumon Artificial Neural Networks
 Language models are few-shot learners,2020, Advances in NeuralInformation Processing Systems
 Deep reinforcement learning for motion plan-ning of quadrotors using raw depth images,2020, In 2020 international joint conference on neuralnetworks (IJCNN)
 Sparse networks from scratch: Faster training withoUt losingperformance,2019, CoRR
 Rigging the lottery:Making all tickets winners,2020, In Hal Daume In and Aarti Singh (eds
 The state of sparsity in deep neural networks,2019, arXivpreprint arXiv:1902
 One ticket to win them all: generalizinglottery ticket initializations across datasets and optimizers,2019, ReScience C
 Learningto prune deep neural networks via reinforcement learning,2020, International Conference on MachineLearning (ICML) AutoML Workshop
 Second order derivatives for network pruning: Optimal brainsurgeon,1993, In S
 Second order derivatives for network pruning: Optimal brainsurgeon,1993, In S
 Deep residual learning for image recog-nition,2015, CoRR
 Amc: Automl for modelcompression and acceleration on mobile devices,2018, In European Conference on Computer Vision(ECCV)
 Sparsity indeep learning: Pruning and growth for efficient inference and training in neural networks,2021, arXivpreprint arXiv:2102
 Optimal brain damage,1990, In D
 Optimal brain damage,1990, In D
 Layer-adaptive sparsity forthe magnitude-based pruning,2021, In International Conference on Learning Representations
 Snip: Single-shot network pruningbased on connection sensitivity,2018, arXiv preprint arXiv:1810
 Dynamic model pruningwith feedback,2020, In International Conference on Learning Representations
 Parameter efficient training of deep convolutional neural networksby dynamic sparse reparameterization,2019, In Proceedings of the 36th International Conference onMachine Learning
 Lookahead: a far-sighted alternative ofmagnitude-based pruning,2020, International Conference on Learning Representations
 Efficient neural architecturesearch via parameters sharing,2018, In Jennifer Dy and Andreas Krause (eds
 Xnor-net: Imagenetclassification using binary convolutional neural networks,1611, Lecture Notes in Computer Science
 Compression of neural machinetranslation models via pruning,2016, arXiv preprint arXiv:1606
 Energy and policy considerations fordeep learning in nlp,2019, 57th Annual Meeting of the Association for Computational Linguistics(ACL)
 Picking winning tickets before training bypreserving gradient flow,2020, In International Conference on Learning Representations
 Neural pruning via growing regularization,2021, InInternational Conference on Learning Representations
