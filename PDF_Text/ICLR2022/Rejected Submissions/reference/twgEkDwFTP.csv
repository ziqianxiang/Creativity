title,year,conference
 A convergence theory for deep learning via over-parameterization,2019, In International Conference on Machine Learning
 Demographic dialectal variation in socialmedia: A case study of African-American English,1120, In Proceedings of the 2016 Conference onEmpirical Methods in Natural Language Processing
 Gradient descent finds globalminima of deep neUral networks,2019, In International Conference on Machine Learning
 Learning models with Uniform performance via distribUtion-ally robUst optimization,2018, arXiv preprint arXiv:1810
 EqUality of opportUnity in sUpervised learning,2016, In D
 Fairness with-oUt demographics in repeated loss minimization,2018, In Jennifer Dy and Andreas KraUse (eds
 Counterfactual fairness,2017, In Advancesin neural information processing systems
 Wide neural networks of any depth evolve as linear modelsunder gradient descent,2019, Advances in neural information processing systems
 Just train twice: Improving group robustness without traininggroup information,2021, In International Conference on Machine Learning
 Justice as fairness: A restatement,2001, Harvard University Press
 Distributionally robustneural networks for group shifts: On the importance of regularization for worst-case generaliza-tion,2020, In International Conference on Learning Representations
 An investigation of why over-Parameterization exacerbates spurious correlations,2020, In Hal DaUme In and Aarti Singh (eds
 Introduction to the non-asymptotic analysis of random matrices,2010, arXiv preprintarXiv:1011
 Doro: Distributional and outlier ro-bust optimization,2021, In Marina Meila and Tong Zhang (eds
