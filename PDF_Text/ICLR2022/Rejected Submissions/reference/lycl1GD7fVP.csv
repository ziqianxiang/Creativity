title,year,conference
 Fine-grained analysis of op-timization and generalization for overparameterized tWo-layer neural netWorks,2019, In InternationalConference on Machine Learning
 Overfitting or perfect fitting? risk bounds for classi-fication and regression rules that interpolate,2018, arXiv preprint arXiv:1806
 Reconciling modern machine-learning practice and the classical bias-variance trade-off,2019, Proceedings of the National Academyof Sciences
 On the inductive bias of neural tangent kernels,2019, arXiv preprintarXiv:1905
 Spectrum dependent learning curves inkernel regression and wide neural networks,2020, In International Conference on Machine Learning
 Towards understanding thespectral bias of deep learning,2019, arXiv preprint arXiv:1912
 Spherical harmonics in p dimensions,2012, arXiv preprintarXiv:1205
 Infinite attention: NNGP andNTK for deep attention networks,2020, In International Conference on Machine Learning (ICML)
 Neural tangent kernel: Convergence and gener-alization in neural networks,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Deep neural networks as gaussian processes,2018, In International Conference onLearning Representations (ICLR)
 Finite versus infinite neural networks: an empirical study,2020, In Advancesin Neural Information Processing Systems (NeurIPS)
 The largelearning rate phase of deep learning: the catapult mechanism,2020, CoRR
 Just interpolate: Kernel “ridgeless” regression can gener-alize,2020, The Annals of Statistics
 On the infinite widthlimit of neural networks with a standard parameterization,2020, arXiv preprint arXiv:2001
 Learning curves for gaussian processes,1999, Advances in neural information processingsystems
 On learning over-parameterized neural networks: A functional approxi-mation perspective,2019, arXiv preprint arXiv:1905
 Deep learning generalizes because theparameter-function map is biased towards simple functions,2018, arXiv preprint arXiv:1805
 Tensor programs I: wide feedforward or recurrent neural networks of any architectureare gaussian processes,2019, CoRR
 A fine-grained spectral perspective on neural networks,2019, arXiv preprintarXiv:1907
