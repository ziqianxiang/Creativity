title,year,conference
 The importance of pessimism in fixed-datasetpolicy optimization,2020, arXiv preprint arXiv:2009
 Information-theoretic considerations in batch reinforcement learning,2019, InInternational Conference on Machine Learning
 Two-timescale networks for nonlinearvalue function approximation,2018, In International conference on learning representations
 Benchmarking batchdeep reinforcement learning algorithms,2019, arXiv preprint arXiv:1910
 Off-policy deep reinforcement learning withoutexploration,2019, In International Conference on Machine Learning
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In International Conferenceon Machine Learning
 Way off-policy batch deep reinforcement learning ofimplicit human preferences in dialog,2019, arXiv preprint arXiv:1907
 Meta-learning representations for continual learning,2019, arXivpreprint arXiv:1905
 Approximately optimal approximate reinforcement learning,2002, In InProc
 Stabilizing off-policy q-learning viabootstrapping error reduction,2019, arXiv preprint arXiv:1906
 Asymptotically efficient adaptive allocation rules,1985, Advances inapplied mathematics
 Provably good batch reinforce-ment learning without great exploration,2020, arXiv preprint arXiv:2007
 Human-level controlthrough deep reinforcement learning,2015, nature
 Algorithms for inverse reinforcement learning,2000, In Icml
 Randomized prior functions for deep reinforcementlearning,2018, arXiv preprint arXiv:1806
 Pretraining representations for data-efficientreinforcement learning,2021, arXiv preprint arXiv:2106
 Reinforcement learning: An introduction,2018, MIT press
 High confidence policyimprovement,2015, In International Conference on Machine Learning
 Policy finetuning: Bridgingsample-efficient offline and online reinforcement learning,2021, arXiv preprint arXiv:2106
 Meta-gradient reinforcement learning,2018, arXivpreprint arXiv:1805
 Mopo: Model-based offline policy optimization,2020, arXiv preprint arXiv:2005
 Autoregressive dynamics models for offline policy evaluation andoptimization,2021, In International Conference on Learning Representations
 Gradientdice: Rethinking generalized offlineestimation of stationary values,2020, In International Conference on Machine Learning
