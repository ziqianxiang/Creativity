title,year,conference
 Infinite mixture proto-types for few-shot learning,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 End-to-end object detection with transformers,2020, In Andrea Vedaldi
 Pre-trained image processing transformer,2021, In IEEE Conferenceon Computer Vision and Pattern Recognition
 An image is worth 16x16 words: Transformers for image recognition atscale,2021, In 9th International Conference on Learning Representations
 MELR: meta-learning via modelingepisode-level relationships for few-shot learning,2021, In 9th International Conference on LearningRepresentations
 Dynamic few-shot visual learning without forgetting,2018, In2018 IEEE Conference on Computer Vision and Pattern Recognition
 Siamese neural networks for one-shotimage recognition,2015, In ICML deep learning workshop
 Lgm-net: Learning to generate matching networks for few-shot learning,2019, In Kamalika Chaudhuriand Ruslan Salakhutdinov (eds
 A universal repre-sentation transformer layer for few-shot image classification,2021, In 9th International Conference onLearning Representations
 Parameter-efficient multi-task fine-tuning for transformers via shared hypernetworks,2021, In Chengqing Zong
 TADAM: task dependent adaptivemetric for improved few-shot learning,2018, In Samy Bengio
 Meta-learning with latent embedding optimization,2019, In 7th InternationalConference on Learning Representations
 Attention is all you need,2017, In Isabelle Guyon
 Match-ing networks for one shot learning,2016, In Daniel D
 Deformable DETR:deformable transformers for end-to-end object detection,2021, In 9th International Conference onLearning Representations
