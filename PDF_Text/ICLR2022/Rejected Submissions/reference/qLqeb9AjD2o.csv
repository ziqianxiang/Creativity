title,year,conference
 Con-crete problems in AI safety,2016, arXiv preprint arXiv:1606
 Unrestricted adversarialexamples via semantic manipulation,2020, In International Conference on Learning Representations
 Language models are few-shotlearners,2020, In H
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy
 On evaluating adversarial robustness,2019, arXivpreprint arXiv:1902
 Intel-ligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission,2015, InProceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery andData Mining
 A simple framework forcontrastive learning of visual representations,2020, In Hal DaUme In and Aarti Singh (eds
 Certified adversarial robustness via randomizedsmoothing,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 The many faces of robustness: A criticalanalysis of out-of-distribution generalization,2020, arXiv preprint arXiv:2006
 Consistency regularization for certified robustness of smoothedclassifiers,2020, In H
 Learning multiple layers of features from tiny images,2009, Technical report
 Gradient-based learning applied to documentrecognition,1558, Proceedings of the IEEE
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Training confidence-calibrated classifiers fordetecting out-of-distribution samples,2018, In International Conference on Learning Representations
 Certified adversarial robustness withadditive noise,2019, In Advances in Neural Information Processing Systems 32
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems 32
 Mastering the game of gowithout human knowledge,2017, nature
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations
 On adaptive attacks toadversarial example defenses,2020, In Advances in Neural Information Processing Systems
 Attention is all you need,2017, In I
 Grandmasterlevel in starcraft ii using multi-agent reinforcement learning,2019, Nature
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In Jennifer Dy and Andreas Krause (eds
 A survey of autonomousdriving: Common practices and emerging technologies,2020, IEEE Access
 MACER: Attack-free and scalable robust training via maximizing certi-fied radius,2020, In International Conference on Learning Representations
 mixUp: Beyond em-pirical risk minimization,2018, In International Conference on Learning Representations
 Towards stable and efficient training of verifiably robUst neUral networks,2020, InInternational Conference on Learning Representations
 Attacks which do not kill training make adversarial learning stronger,1127, In Hal Daume Inand Aarti Singh (eds
