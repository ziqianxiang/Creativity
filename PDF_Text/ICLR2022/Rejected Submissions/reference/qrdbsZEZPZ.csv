title,year,conference
 DeeP learning with differential Privacy,2016, In Proceedings of the 2016 ACM SIGSACconference on computer and communications security
 cPsgd:commUnication-efficient and differentially-Private distribUted sgd,2018, In Proceedings of the 32ndInternational Conference on Neural Information Processing Systems
 Baffle:Backdoor detection via feedback-based federated learning,2020, arXiv preprint arXiv:2011
 Differentially Private federated learning: An information-theoreticPersPective,2020, In ICML Workshop on Federated Learning for User Privacy and Data Confidentiality
 How tobackdoor federated learning,2020, In International Conference on Artificial Intelligence and Statistics
 A little is enough: Circumventing defenses fordistributed learning,2019, In H
 Private emPirical risk minimization: Efficientalgorithms and tight error bounds,2014, In 2014 IEEE 55th Annual Symposium on Foundations ofComputer Science
 Protec-tion against reconstruction and its aPPlications in Private federated learning,2018, arXiv preprintarXiv:1812
 Machine learningwith adversaries: Byzantine tolerant gradient descent,2017, In Proceedings of the 31st InternationalConference on Neural Information Processing Systems
 Practical secure aggregation for privacy-preserving machine learning,2017, In proceedings of the 2017 ACM SIGSAC Conference on Computerand Communications Security
 Machine learning classificationover encrypted data,2015, In NDSS
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Distributed statistical machine learning in adversarial settings:Byzantine gradient descent,2017, Proceedings of the ACM on Measurement and Analysis of ComputingSystems
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 The algorithmic foundations of differential privacy,2014, Foundationsand Trends in Theoretical Computer Science
 The hiddenvulnerability of distributed learning in byzantium,2018, In International Conference on MachineLearning
 The limitations of federated learning insybil settings,2020, In 23rd International Symposium on Research in Attacks
 Differentially private federated learning: A clientlevel perspective,2017, arXiv preprint arXiv:1712
 Badnets: Evaluating backdooringattacks on deep neural networks,2019, IEEE Access
 Federated learning for mobile keyboard prediction,2018, arXivpreprint arXiv:1811
 Probability inequalities for sums of bounded random variables,1994, In The CollectedWorks OfWassily Hoeffding
 Ad-versarial machine learning,2011, In Proceedings of the 4th ACM workshop on Security and artificialintelligence
 Learning multiple layers of features from tiny images,2009, Technical report
 MNIST handwritten digit database,2010, 2010
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Learning to detect malicious clientsfor robust federated learning,2020, arXiv preprint arXiv:2002
 Exploring private federatedlearning with laplacian smoothing,2020, arXiv preprint arXiv:2005
 Data poisoning against differentially-private learners:Attacks and defenses,2019, In International Joint Conference on Artificial Intelligence
 Dopamine: Differentially private federated learning on medical data,2021, arXivpreprint arXiv:2101
 Learning differentially privaterecurrent language models,2018, In International Conference on Learning Representations
 Exploiting unintendedfeature leakage in collaborative learning,2019, In 2019 IEEE Symposium on Security and Privacy (SP)
 Renyi differential privacy,2017, In 2017 IEEE 30th Computer Security FoundationsSymposium (CSF)
 Glove: Global vectors for wordrepresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 DeepSecure: Scalable provably-secure deep learning,2018, In Proceedings of the 55th Annual Design Automation Conference
 Rab: Provable robustness againstbackdoor attacks,2020, arXiv preprint arXiv:2003
 Mitigating backdoor attacks in federatedlearning,2020, arXiv preprint arXiv:2011
 Dba: Distributed backdoor attacks against federatedlearning,2019, In International Conference on Learning Representations
 Federated machine learning: Concept andapplications,2019, ACM Transactions on Intelligent Systems and Technology (TIST)
 Applied federated learning: Improving google keyboard querysuggestions,2018, arXiv preprint arXiv:1812
 Deep leakage from gradients,2019, InH
