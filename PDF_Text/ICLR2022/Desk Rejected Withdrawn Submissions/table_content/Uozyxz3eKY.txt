Table 1: BLEU scores on 8 IWSLT machine translation tasks.
Table 3: BLEU scores for one-to-many multilingual translation on related languages.
Table 2: BLEU scores on WMT16 Ro→Enble 2. The results show that our method surpasses sev- machine translation tasks.
Table 4: Fine-tuned model performances on GLUE language understanding benchmark.
Table 5: Classification accuracy on CIFAR-100.
Table 6: Comparison among different consistencyregularization objectives.
Table 7: Comparison among different augmentation strate-gies on CIFAR-100 and IWSLT14 De→En.
Table 8: Data statistics for multilingual translation experiments.
