Table 1: The mean Average Precision (mAP) for the different number of bits on CIFAR-10 andNUS-WIDE. The best mAP scores are in bold. GPQ with asterisk (*) is the result obtained by ourreproduction from the TensorFlow implementation provided by the original authors.
Table 2: mAP scores on CIFAR-100 and CUB-200 datasets with different number of bits.
Table 3: mAP scores on CIFAR-10 and CIFAR-100 datasets when we use the one half of classes asseen and the other half as novel. Our results on all datasets are averaged over 4 different class splits.
Table 4: Performance of different pairwise pseudo-labeling methods on CIFAR-10 and NUS-WIDE.
Table 5: Accuracy of the proposed approach with different combination of the loss terms.
Table 6: mAP scores on CIFAR-10 with fewer labeled examples. We use 7 classes as seen classes.
Table 7: Comparison with novel class discovery methods on CIFAR-10, CIFAR-100, and Tiny-ImageNet in terms of three evaluation metrics including ACC, NMI, and ARI.
