Table 1: Effect of enforcing a LiPschitz constant of 1 on the accuracy on the source domain andtarget domain. Constrained 4-layer classifiers are comParable or better than unconstrained.
Table 2: Computing adversarial representations z0 and inputs x00 on SVHN/MNIST (source) andMNIST/KMNIST (target). Models: unconstrained (None), with Lipschitz constant 1 (WN). Metrics:model accuracy (Acc.), percentage of found adversarial representations (pz) or adversarial inputs(px), mean L∞ distance between adversarial representations (z∆) and adversarial inputs (x∆).
Table 3: Smoothing on SVHN (source) → MNIST (target) using classifiers without (None) and withLipschitz constant 1 (WN). Columns: data (source/target), constraint (None/WN), accuracy of thebase classifier (AB), median prediction accuracy (AM), verifiable accuracy (AV ) and radius (Rad.)1-layer classifier		Base	Label smooth.		Representation smooth.		Logit smooth.	Data, Con.	Training	AB [%]	Av [%]	Rad.	AM[%]	Av [%]	Am [%]	Av [%]	normal	944~~	261 ^^	0.049^^			69.4	^^26.1	noise	93.2	79.8	0.153			93.5	79.8Source	adv	95.7	46.4	0.073			76.9	46.4None	adv-d	95.8	75.4	0.111			84.7	75.4	adv-s	94.2	82.1	0.166			94.6	82.1	normal	96.5	19.6	0.055	67.3	56.9	67.3	19.6	noise	92.9	66.0	0.152	93.3	91.0	93.3	66.0Source	adv	96.7	28.5	0.079	75.7	67.5	75.7	28.5WN	adv-d	96.7	57.9	0.096	83.0	80.4	83.0	57.9	adv-s	92.2	72.5	0.165	92.2	90.6	92.2	72.5	normal	96.2	21.5	0.13			83.9	21.5	noise	96.2	53.7	0.175			93.4	53.7Target	adv	97.3	38.8	0.155			92.6	38.8None	adv-d	96.4	82.0	0.173			91.7	82.0	adv-s	96.1	69.6	0.192			95.4	69.6
Table 4: Smoothing on MNIST/FMNIST (source) → KMNIST (target) using 4-layer classifierswithout (None) and with Lipschitz constant 1 (WN). Columns: data (source/target), constraint(None/WN), accuracy of the base classifier (AB), median prediction accuracy (AM), verifiable ac-curacy (AV ) and radius (Rad.).
