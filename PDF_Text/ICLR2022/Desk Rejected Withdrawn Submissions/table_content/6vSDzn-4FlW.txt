Table 1: Results of the experiment on accuracy. The table shows the observed mean accuracy inpercent and standard deviations for 3-fold cross-validation runs for a given combination of parametersfor the datasets MNIST (M10), CIFAR-10 and CIFAR-100 (C10 and C100). The highest accuracyfor a dataset and architecture combination is highlighted in bold. The numbers I, II and III denotethe methods of fuzzy learning rates, weight rejuvenation, and weight splitting, respectively.
Table 2: Results of the experiment on learning speed. The table shows the observed mean epochwhen the maximum accuracy occurred, and its standard deviations for 3-fold cross-validation runsfor a given combination of parameters for the datasets MNIST (M10), CIFAR-10, and CIFAR-100(C10 and C100). The lowest numbers of trained epochs for dataset and architecture combinations arehighlighted in bold. The numbers I, II and III denote the methods of fuzzy learning rates, weightrejuvenation, and weight splitting, respectively.
Table 3: Results of the experiment on gradient inversion. The table shows the observed reconstructionerror (mean square error) for different combinations of methods for untrained models and modelstrained 100 epochs on CIFAR-100. Highest reconstruction errors for the dataset and architecturecombinations are highlighted in bold. The numbers I, II and III denote the methods of fuzzy learningrates, weight rejuvenation and weight splitting respectively.
