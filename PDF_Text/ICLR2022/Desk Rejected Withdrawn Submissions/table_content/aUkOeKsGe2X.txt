Table 1: We report the L1, SSIM and LIPIPS (Zhang et al., 2018) norm between the reconstructionsof the real images (unknown) and the corresponding synthetic (Synth.) training images (realistic ortoy) or input images (Real). We report the mean of the norms across the dataset: for SSIM larger ↑and for the others smaller J is better. E-AE performs best.
Table 2: For each experiment, the best accuracy on real TICaM images across all epochs is takenand the mean, standard deviation and maximum of those values across all 10 runs is reported. Themodel weights achieving maximum performance per run on TiCAM are evaluated on SVIRO. Ourapproach outperforms the corresponding classification models significantly.
Table 3: For each of the 10 experimental runs per method after 250 epochs (i.e. not the best modelweights per training were selected) and using the VGG-11 extractor we trained different classifiersin the latent space: k-nearest neighbour (KNN), random forest (RForest) and support vector machinewith a linear kernel (SVM). The results show that most of the contribution to the synthetic to realgeneralization is due to the novel II variation of the PIRL cost function.
Table 4: Model architecture for AE, VAE and β-VAE on MPI3DEncoder	DecoderInput: 3 x 64 x 64	Input: 10Conv, 4x4, 32, padding 1, stride 2 ReLU	FC, 256, bias True ReLUConv, 4x4, 32, padding 1, stride 2 ReLU	FC, 1024, bias True ReLUConv, 4x4, 64, padding 1, stride 2 ReLU	ConvTranspose, 4x4, 64, padding 1, stride 2 ReLUConv, 4x4, 64, padding 1, stride 2 ReLU	ConvTranspose, 4x4, 32, padding 1, stride 2 ReLUFC, 256, bias True ReLU	ConvTranspose, 4x4, 32, padding 1, stride 2 ReLUFC, 10, bias True (twice in case of VAE)	ConvTranspose, 4x4, 3, padding 1, stride 2 Sigmoid16Under review as a conference paper at ICLR 2022Table 5: Model architecture for FactorVAE on MPI3D. The model is exactly the same as the VAEmodel and uses the following discriminator.
Table 5: Model architecture for FactorVAE on MPI3D. The model is exactly the same as the VAEmodel and uses the following discriminator.
Table 6: Model architecture for E-AE on MPI3D. The extractor is fixed during training.
Table 7: Model architecture for E-AE on SVIRO, SVIRO-Illumination and TICaM. C is the channeldimension which is 1 for all datasets. The extractor is fixed during training.
Table 8: We report the L1, SSIM and LIPIPS (Zhang et al., 2018) norm between the reconstructionsof the real images (unknown) and the corresponding synthetic training images (realistic or toy). Wereport the mean of the norms across the entire reduced dataset: for SSIM larger ↑ and for the otherssmaller ] is better. E-AE performs best. Some models used SSIM, others BCE during training.
Table 9: For each experiment, the best performance (in percentage) on real vehicle interior images(TICaM) across all epochs is taken and then the mean and maximum of those values across all10 runs is reported. For the same backbone model extractor, our approach outperforms the vanillaclassification models significantly. The model weights achieving the maximum performance per runare also evaluated on SVIRO where they perform better as well.
Table 10: Different model architecture variations trained on MNIST. Then different classifiers weretrained on the latent space representation of the training data and evaluated on real images of digits.
