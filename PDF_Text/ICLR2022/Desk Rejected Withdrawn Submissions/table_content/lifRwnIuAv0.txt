Table 1: For the sake of clarity, we refer to PGD-2 AT without random initialization as PGD-2-NRSAT and PGD-2 AT with random initialization as PGD-2-RS AT. For PGD-2-RS AT, the random noiseused for initializing the perturbation is sampled from uniform distribution U (-, ). Different from(Andriushchenko & Flammarion, 2020), which evaluates the models’ adversarial (robust) accuracyagainst PGD-50-10 on 1000 random points, we evaluate models’ robust accuracy on the whole testset. The experimental settings are detailed in Section 5.1 and Section C.
Table 2: PGD-2-RS AT and Qusai-PGD-2-RS AT (with α = 1.25/2) for large perturbations.
Table 3: Performance of different efficient AT methods on CIFAR10 and SVHN. All the results arereported with the average and the standard deviation averaged over 5 random seeds.
Table 5: Performance of different efficient AT methods against AutoAttack. All the results arereported with the average and the standard deviation averaged over 5 random seeds.
Table 6: Performance of PGD-2-RS AT and Qusai-PGD-2-RS AT on ImageNet. The final-epochtraining top-1 accuracy against PGD-2-RS or Qusai-PGD-2-RS is around 23%, and the gap betweentraining accuracy and the testing robust accuracy is only around 5%. Thus, we can say PGD-2-RSAT and Qusai-PGD-2-RS AT do not suffer from catastrophic overfitting at = 8/255 on ImageNet.
Table 7: Performance of PGD-k-RS AT on CIFAR10 and SVHN. All the results are reported withthe average and the standard deviation averaged over 5 random seeds.
Table 8: Performance of different adversarial training methods on CIFAR10 under piecewise learn-ing schedules. All the results are reported with the average and the standard deviation averaged over5 random seeds. The best results are marked in bold. We set the weight decay as 2e-3 instead of5e-4 and stop training after the first epoch with the learning rate 0.001 or 0.002.
