Table 1: Ablation experiment results of CAMMETHOD	APs	APm	APl	ARs	ARm	ARlbaseline	34.8%	60.5%	83.6%	57.9%	78.7%	82.8%Weighted Fusion	35.6%	63.0%	84.1%	60.5%	81.8%	93.2%Adaptive Fusion	36.0%	63.1%	84.9%	58.9%	81.0%	93.6%Concatenation Fusion	36.6%	61.0%	84.2%	59.8%	79.5%	93.1%concatenation and Softmax. Three channels correspond to the three inputs one-to-one, and the con-text information can be aggregated to the output by calculating the weighted sum. We verify theeffectiveness of each fusion method through ablation experiments and the results are shown in thefollowing Table 1. APs , APm , and APl are defined as the precision of tiny, medium, and largetargets. And ARs, ARm, and ARl are denoted as the recall of tiny, medium, and large targets.
Table 2: Ablation study results of data augmentationPAST TIME	APs	APm	APl	ARs	ARm	ARlbaseline	34.8%	60.5%	83.6%	57.9%	78.7%	82.8%Paste×1	37.3%	62.7%	83.4%	59.8%	80.9%	93.0%Paste×2	36.8%	62.6%	82.2%	58.0%	81.0%	92.1%Paste×3	33.2%	59.7%	81.5%	58.0%	79.8%	93.1%3.2	Copy-Reduce-Paste data enhancementIn the current mainstream public data set, the number of positive samples generated by tiny objectsand the contribution to loss of tiny objects is much smaller than those of larger targets, making thedirection of convergence lean toward to larger targets. In order to alleviate this problem, we copy,reduce, and paste the target in images during training. By increasing the number of tiny objects inimages and the number of images containing tiny objects, the contribution to the loss of the tinyobject is increased and makes training more balanced. Figure 6 b, c is the results of pasting onceper target at different positions. By this way, the number and context information of tiny objects isgreatly enriched.
Table 3: Overall ablation study resultsAUGMENTATION	CAM	FRM	APs	APm	APl	ARs	ARm	ARl			34.8%	60.5%	83.6%	57.9%	78.7%	92.8%X			37.3%	62.7%	83.4%	59.8%	80.9%	93.0%	X		36.6%	61.0%	84.2%	59.8%	79.5%	93.1%		X	37.6%	62.1%	83.9%	59.0%	79.1%	92.6%X	X	X	40.2%	64.1%	84.6%	64.8%	81.0%	93.9%In general, the module proposed in this paper can significantly improve the target detection perfor-mance, especially for the tiny objects and medium objects, which is also in line with our originalintention. As shown in the table, APs is increased by 5.4%. APm is increased by 3.6% , while APl isincreased by 1.0%. At the same time, the recall of targets of different scales has also been improvedto varying degrees. Specifically, ARs is increased by 6.9%, ARm is increased by 2.3%, and ARlis increased by 1.1%. Copy-reduce-paste: The data enhancement method increases APs by 2.5%, increases APm by 2.2%, but decreases APl slightly. CAM: The CAM module can improve APs, APm, and APl, especially for APs . Its precision and recall rate are increased by 1.8% and 1.9%respectively. FRM: APs is increased by 2.8%, APm is increased by 1.6%, and APl is basically thesame.
Table 4: Comparison results on the VOC data set (IOU=0.5), “++” Represents multi-scale testingALGORITHM	BACKBONE	INPUT SIZE	MAPTwo-stage Network			Faster RCNN(Ren et al., 2016)	ResNet101	1000×600	76.4OHEM(Shrivastava et al., 2016)	VGG16	1000×600	74.6CoupleNet(Zhu et al., 2017)	ResNet101	1000×600	82.7FPN-Reconfig(Kong et al., 2018)	ResNet101	1000×600	82.4IPG RCNN(Liu et al., 2020)	IPGNet101	1000×600	84.8One-stage Network			SSD512(Liu et al., 2016)	VGG16	512×512	79.8YOLOv2(Redmon & Farhadi, 2017)	Darknet19	544×544	78.6RefineDet(Zhang et al., 2018)	VGG16	512×512	81.8CenterNet(Duan et al., 2019)	DLA	512×512	80.7PFPNet-R512(Kim et al., 2018)	VGG16	512×512	82.3Proposed	Darknet53	448×448	83.6Proposed++	Darknet53	448×448	85.1It can be seen from Table 5 that the algorithm proposed in this paper has absolute advantages in APand AR on tiny objects. The algorithm in this paper is 3.9% higher than YOLOV4(Bochkovskiyet al., 2020) (16.9%vs.13%), which has the highest APs among comparison algorithms. Comparedwith the RefineDet(Zhang et al., 2018), our proposed algorithm are 9.2% (29.4% vs. 20.2%) higher
Table 5: Detection results of tiny objectALGORITHM	APs	APm	ARs	ARmRefineDet	11.6%	34.9%	20.2%	39.9%CenterNet	9.2%	31.3%	17.4%	43%YOLOV4	13%	34.5%	18.1%	42.8%Proposed	16.9%	33.4%	29.4%	45.8%5	SummaryWe propose a composite structure of FPN, which contains a context augmentation module and afeature refinement module. The context augmentation module leverages the dilated convolution toextract the context information of different receptive fields and then integrates it into FPN to im-prove the context information of the tiny objects. The feature refinement module combines spatialadaptive fusion and channel adaptive fusion to suppress conflicting features from the dimensionsof channel and space to highlight useful features. In addition, a copy-reduce-paste data enhance-ment method of tiny objects is proposed to prevent imbalance in training. Through experimentalresults, we can see that the tiny object detection network proposed in this paper performs well onthe VOC data set. More results and Code are available at https://github.com/xiaojs18/Object-Detection/tree/main/smallObjDetection.
