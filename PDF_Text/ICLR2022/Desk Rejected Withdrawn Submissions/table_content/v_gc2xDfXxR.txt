Table 1: Object detection and instance segmentation results on the COCO benchmark (Lin et al.,2014). APbb and APmk denote bounding box and mask average precision (AP), respectively. We usepublicly available pre-trained models for baselines. * denotes results performed in our codebase.
Table 2: (a) Semantic segmentation on ADE20K (Zhou et al., 2017), and (b) video object segmen-tation on DAVIS 2017 (Pont-Tuset et al., 2017). We use publicly available pre-trained models forbaselines. All results are performed in our codebase.
Table 3: Ablation studies on (a) each contribution of three components in our method: the neigh-boring patches (“Neighbors”), positive matching (“Matching”) and aggregation module (“Aggrega-tion”); and (b) varying the number of positive patches used in positive matching. All models arepre-trained on the COCO benchmark (Lin et al., 2014). We evaluate the pre-trained models usingthe semantic segmentation benchmark, ADE20K (Zhou et al., 2017).
