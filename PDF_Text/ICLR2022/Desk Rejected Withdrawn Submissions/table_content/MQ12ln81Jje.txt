Table 1: Datasets global informationsCora		Citeseer	PubmedNumber of nodes	2 707	3 327	197l7Number of edges	5 429	4 732	44 338edges by node (mean)	2.01	1.42	2.25Max node degree	168	99	171Min node degree	1	1	1Oriented	Yes	Yes	YesMax score PageRank	4, 92 * 10-02	4,01 * 10-02	6,10 * 10-03The extraction of graph data, the score computation until edge selection and dropping were donebefore the GCN training on Intel Xeon Processor E5-2690 with 8 cores. The result was used tobuild Gdrop. The trainings with Gdrop were done on Nvidia Tesla V100 PCIe 16GB GPUs. Theoriginal GCN, the state of the art DropEdge and our RankedDrop were compared in this section tovalidate our solution.
Table 2: Accuracy comparaison for full-supervised learning methods for GCN architecureDataset	Method	2 Layers	4 Layers	8 LayersB J O O	Original	-8∏0^^	78.5	-^3∏0-	DroPEdge	82.80	78.8	53.1	RankedDroP	82.90	82.00	63.90Citeseer	Original	-70.80^^	61.2	^^30:20-	DroPEdge	72.30	68.8	33.20	RankedDrop	73.20	71.30	45.50Pubmed	Original	-7900^^	78.30	-^6120-	DropEdge	79.60	77.7	54.50	RankedDrop	79.90	79.40	77.17Under review as a conference paper at ICLR 2022We first compare the accuracy between original GCN, GCN with DropEdge and GCN with Ranked-Drop in the semi-supervised learning, with 2, 4 and 8 layers (Table 2). The hyper-parameters for2 layers are from the paper of DropEdge, and the one for 4 and 8 layers are the best one that wefound. The parameters used for the selection of the nodes with RankedDrop are available in the ap-pendix A. The accuracies obtained with RankedDrop are all higher than with DropEdge. Moreover,the deeper the GCN is, the better accuracy improvement RankedDrop offers comparing to DropE-dge. The accuracy obtained with RankedDrop for the 8-layer GCN is 20% better than the one with
Table 3: Accuracy comparaison for full-supervised learning methodsDataset	Type	Original method	DropEdge	RankedDropE J O U	4GCN	85:50	85.70	87:60	8 IncepGCN	86.70	87.70	87.90	16JKNet	86.20	87.30	88.40Citeseer	-4GCN-	7670	79.20	79:90	8 IncepGCN	79.20	80.5	80.30	8JKNet	79.60	80.20	79.8Pubmed	-4GCN-	8870	90.5	9070	4 IncepGCN	89.90	91.10	91.80	16JKNet	90.40	91.40	88.30The accuracies of full-supervised learning are presented in the table 3. For each of the datasets,we evaluated with three different backbones: GCN, IncepGCN and JKNet. The number of layersfor each backbone was chosen from the best accuracy declared by DropEdge. We used the samehyper-parameters given by Rong et al. (2019), only the edge dropping percentage is modified forRankedDrop. The accuracies are globally equivalent between RankedDrop and DropEdge; andRankedDrop achieved better accuracies than DropEdge for Cora the smallest dataset. It again showthat RankedDrop reduce better the over-fitting phenomenon. Moreover, the hyper-parameters usedhere are not specifically adapted to RankedDrop, but RankedDrop can still achieve good accuracies.
Table 4: Hyper-parameters used to obtain the accuracy presented in this paper with the RankedDrop method.
