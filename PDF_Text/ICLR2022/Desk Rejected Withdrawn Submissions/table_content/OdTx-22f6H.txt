Table 1: AR-UNET 3D - Modules and blocksModules	Blocks	Action	Out channelsEncoder	Initial input block + skip	Input block with skip connection	64Bridge	Residual block 1 and 2 Bridge residual block	1st and 2nd block in the Encoder Connects Encoder to Decoder using residual block	128,256 512Decoder x 3	Upsample Attention blocks Residual blocks	Upsamples the image Weighs inputs Converts concatenated channels to required size	512, 256, 128 512, 256, 128 256, 128, 64Final	Final output block	Produces a segmented mask	43Under review as a conference paper at ICLR 20223.2	LinkNet 3D:The proposed architecture, as can be seen in Figure 4 and described in Table 2 is a 3D modificationupon the LinkNet architecture (Chaurasia & Culurciello, 2017) for semantic segmentation in 2Dspace. The ‘conv’ here refers to a convolution operation in 3D space. Batch Normalization (Ioffe &Szegedy, 2015) is used between each convolutional layer, followed by ReLU (Nair & Hinton, 2010)activation to introduce non-linearity as has been mentioned in (Chaurasia & Culurciello, 2017). TheLinkNet 3D network comprises of an Encoder network which is effectively a 3D variation of the 18layer Residual Network or ResNet18 (He et al., 2016), and a Decoder network which is a modified3D variation of the decoder architecture mentioned in (Chaurasia & Culurciello, 2017).
Table 2: LinkNet 3D - Modules and blocksModules	Blocks	Action	Out channels	Initial Input block	Convolution and max-pooling	64Encoder	Residual blocks	4 blocks following the initial input block for ‘Feature extraction’	64, 128, 256, 512Decoder	Decoder Blocks	Converts concatenated channels (512, 256, 128, 64) to required channel size	256, 128, 64, 64	Final Block	Produces the final segmentation mask	43.3	Pyramid Scene Parsing Network (PSPNet) 3D:The proposed architecture as can be seen in Table 3, namely PSPNet-3D is a three-dimensionaladaptation of the original PSPNet paper (Zhao et al., 2017) which was used for 2D segmentation.
Table 3: PSPNet 3D - Modules and blocksModules	Blocks	Action	Out channels	Initial Input block	3 convolutions and a max-pooling block.	128Encoder	3D Dilated	4 residual blocks for feature extraction	256, 512,	Residual blocks	following the initial input block	1024, 2048Decoder	3D Pyramid Pooling Module	4 pooling blocks of 4 different reolutions generating the final concatenated feature map.	1024	Final Block	Produces the final segmentation mask	44	Experiments4.1	DatasetThe (Brain Tumor Segmentation) BraTS 2020 dataset (Menze et al., 2015) (Bakas et al., 2017)(Bakas et al., 2018) with a total of 250 brain MRI 3D images belonging to flair modality, in which6Under review as a conference paper at ICLR 2022eight percent of the training data has been substituted with 3D augmentations (Nalepa et al., 2019)based on time tested augmentation techniques like affine transforms and flips for each of the respec-tive models.
Table 4: Training detailsModels	Parameters	Learning Rate	Mean Dice Loss	Best Dice ScoreAR-UNET 3D	35838349	0.0001	0.3270	0.8500LinkNet 3D	32925860	0.00001	0.3431	0.8041PSPNet 3D	74352202	0.0001	0.3334	0.8087Test results for all 3 models are given below.
