Table 1: Structures of different modules^^^^^Module Name Dataset Name~Jä¸€		Feature Extractor	Classifier	DiscriminatorDouble Inter-TWin Moons	Linear(2,15) Sigmoid layer	Linear(15,2) Softmax layer	Linear(15,2) Softmax layerTriple Inter-Twin Moons	Linear(2,15) Sigmoid layer	Linear(15,2) Softmax layer	Linear(15,3) Softmax layerDigits	Conv2d(3, 32, kerneLsiZe=5) BatchNorm2d(32) nn.MaxPool2d(2) ReLU Conv2d(32, 48, kerneLsiZe=5) BatchNorm2d(48) Dropout2d() MaxPool2d(2) ReLU	Linear(48 * 4 * 4, 100) BatchNorm1d(100) ReLU Dropout Linear(100, 100) BatchNorm1d(100) ReLU Linear(100, 10) Softmax Layer	Linear(48 * 4 * 4, 100) BatchNorm1d(100) ReLU Linear(100, 2) Softmax LayerAmazon	Linear(30000,50) Sigmoid layer	Linear(50,2) Softmax layer	Linear(50,4) Softmax layerOffice-31	Linear(4096,50) Sigmoid layer	Linear(50,3i) Softmax layer	Linear(50,3) Softmax layerImageCLEF-DA	Linear(1024,50) Sigmoid layer	Linear(50,12) Softmax layer	Linear(50,3) Softmax layer15Under review as a conference paper at ICLR 2022D Hyper-ParametersThe hyper-parameters for training the neural networks are recorded in Table 2.
Table 2: Hyper-parameters for the network trainingDataset Name	Learning Rate	Trade-Off in Models	Batch Size	Epochs	Patience for Early StoppingInter-twin Moons (Double)	0.003-	01	-3^	300	50Inter-twin Moons (Triple)	0.003	0.1	32	300	50Digit	0.0001	0.1	1024	300	50Amazon	0.0001	0.05	256	300	10Office-31	0.0001	0.1	128	300	50ImageCLEF-DA	0.0001	0.1	32	300	50The hyper-parameters for the AL process are recorded in Table 3. At the beginning, a part ofinstances are randomly selected to train the initial model (recorded as initial labeled size), whichis referred to as a warm start process. Then, a fixed number of instances are iteratively selected(recorded as AL batch size). When the total budget has been consumed, the AL process terminates.
Table 3: Hyper-parameters for AL processDataset Name	Total Budget	Initial Labeled Size	AL Batch Size	Repeat TimesInter-twin Moons (Double)	-500-	-100	40	-50-Inter-twin Moons (Triple)	500	100	40	50Digit	20000	2000	2000	5Amazon	4000	800	400	10Office-31	2400	400	200	20ImageCLEF-DA	1080	180	90	3016Under review as a conference paper at ICLR 2022E Results of ComparisonsE.1 Results of Comparisons over ModelsTo present the results of comparison over models more clearly, the performances are also recordedin Table 4. For each dataset, the performance at the first selection iteration and the last selectioniteration are recorded. These two stages reflect the performances of models when the number oflabeled instances is small and large.
Table 4: The classification accuracy (%) of models on each dataset at the first and last AL iterationsDatasets ModeP^^^^^^	Double Moons	Triple Moons	Digit	Amazon	Office-31	ImageCLEFLabeled Number	100	100	2000	-800-	400	180DANN	95:20	9490	94.22	84.45	-64.48-	3483MAN	97.54	95.95	94.03	83.94	66.01	37.44MDNet	95.54	94.08	93.09	83.13	54.62	30.28SDL-joint	95.04	96.02	94.08	84.37	64.42	34.59SDL-separate	90.73	88.93	93.23	82.44	56.64	33.02Labeled Number	1000	1000	2000	-4000-	-2400-	1080DANN	98:54	9832	97.47	-86.33-	-82.28-	4791MAN	99.93	99.87	97.12	86.67	84.01	52.28MDNet	98.62	98.26	97.00	86.69	79.45	49.50SDL-joint	98.86	98.66	97.39	86.17	82.21	48.02SDL-separate	98.11	98.57	97.18	86.11	79.35	50.3317Under review as a conference paper at ICLR 2022E.2 Results of Comparisons over DomainsThe performances of different models on each domain of double and triple inter-twin moons areshown in Fig. 8. The domain performances of the best model-strategy pairs on amazon, office-31and imageCLEF-DA dataset are shown in Fig. 9 and Fig. 10.
