Table 1: Normalized average returns on Drone Con-trol tasks over 10 runs. Values in bold denote highestreturns. Values in green indicate best returns betweenoffline RL policies.
Table 2: Summary of comparisons.
Table 3: Comparison of the gap Qk - Q between value estimates Qk and actual Monte-Carlo returnsQ. Note that negative values denote conservatism and positive values overestimations.
Table 4: Average returns on all 13 D4RL datasets (results averaged over 4 random seeds). Values in bold denote highest returns. We additionally compare withstate-of-the-art baselines BEAR (Kumar et al., 2019), BRAC (Wu et al., 2019), AWR (Peng et al., 2019), AlgaeDICE (aDICE) (Nachum et al…î 2019), BCQ(Fujimoto et al., 2019), REM (Agarwal et al., 2020), TD3+BC (1 ujimoto & Gu, 2021), UWAC (WU et al., 2021) and IQL (Kostrikov et al., 2021).
Table 5: Additional approximation methods considered with their practical limitations.
