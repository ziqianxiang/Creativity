Table 1: Benchmark results. Comparing between different methods for molecular properties pre-diction. All results are taken from the original papers except CMPNN. Results in bold are the best-performing results for their respective datasets. (↑ means that higher result is better and ] means thatlower result is better.)Metric		AUROC					RMSE		Dataset		Tox21 (↑)	ClinTox (↑)	SIDER (↑)	BBBP (↑)	BACE (↑)	ESOL (J)	FreeSolv (J)	Lipophilicity (J)PAIR	• MPNN (atom only)	-0845	0.896	0.644	0.908	0.864	-0719	1.243	0.625	? MPNN	0.844	0.881	0.641	0.910	0.850	0.702	1.242	0.645	× DMPNN	0.845	0.894	0.646	0.913	0.878	0.665	1.167	0.596	▲ CMPNN	0.854	0.908	0.656	0.958	0.887	0.567	0.901	0.582SUB	• AGCN	-0.802-	0.868	0.592	-	-	-0.306	1.33	0.736	? GAAN	0.839	0.888	0.658	-	-	0.294	1.057	0.605	× ML-MPNN	0.852	0.892	0.689	-	-	0.571	1.052	0.560•MolHMPN		-0.837-	0.924	0.620	-0.928-	0.894	-0.392-	0.815	0.511where NK(vi) is the K-hop neighborhood set of vi. This extension allows the membership adjust-ment to consider a much higher-order interactions while restricting the scope of the edge (or mem-bership) learning to the extented Hk so that the learned memberships are guided by the chemically-valid prior knowledge.
Table 2: Increasing K for hyperedge learning. Comparison between the different K used. Resultsin bold are the best-performing results for their respective datasets. (↑ means that higher result isbetter and ] means that lower result is better.)Metric	AUROC					RMSE		Dataset	Tox21(↑)	ClinTox (↑)	SIDER (↑)	BBBP(↑)	BACE (↑)	ESOL (；)	FreeSOIV (J)	Lipophilicity (J)MolHMPN-0	-0838	0.918	0.605	0.927	0.873	-0.450	0.815	0.519	(± 0.0146)	(± 0.0426)	(± 0.0227)	(± 0.0299)	(± 0.0232)	(± 0.0339)	(± 0.3606)	(± 0.0391)MolHMPN-1	0.837	0.924	0.614	0.928	0.888	0.436	0.980	0.511	(± 0.0042)	(± 0.0452)	(± 0.0105)	(± 0.0388)	(± 0.0106)	(± 0.1324)	(± 0.4127)	(± 0.0672)MolHMPN-2	0.837	0.912	0.620	0.903	0.894	0.392	1.012	0.533	(± 0.0072)	(± 0.0485)	(± 0.0160)	(± 0.0416)	(± 0.0173)	(± 0.0917)	(± 0.5553)	(± 0.0744)MolHMPN-3	0.833	0.909	0.608	0.921	0.885	0.406	1.100	0.556	(± 0.0717)	(± 0.0465)	(± 0.0144)	(± 0.0202)	(± 0.0258)	(± 0.0872)	(± 0.4243)	(± 0.0928)Instead, increasing the interactions between the atoms and bonds in CMPNN gives better results, es-pecially for BBBP, ESOL and FreeSolv. Comparing MolHMPN with the PAIR models, we can see thatthe inclusion of higher-order connectivities is indeed beneficial for the tasks as MolHMPN has out-performed the models for five out of eight datasets. From the SUB results, we can see that MolHMPNoutperforms the other baselines for three out of six datasets. Also, although ML-MPNN has inte-grated information from the nodes, edges, subgraphs and graphs, MolHMPN has outperformed it forfour out of six datasets. This shows the efficacy of employing chemically-useful representations
Table 3: Subgraph Comparison. Comparison between different types of subgraphs. Results inbold are the best-performing results for their respective datasets. (↑ means that higher result is betterand ] means that lower result is better.)Metric	AUROC					RMSE		Dataset	Tox21 (↑)	ClinTox (↑)	SIDER (↑)	BBBP (↑)	BACE (↑)	ESOL⑷	FreeSolVa)	Lipophilicity (J)Ring & C. Bond	-0.834	0.904	0.577	-0.919-	0.884	0.509	1.468	0.513	(± 0.0142)	(± 0.0401)	(± 0.0339)	(± 0.0124)	(± 0.0106)	(± 0.0547)	(± 0.5970)	(± 0.0475)2-hop ngh.	0.836	0.902	0.582	0.926	0.894	0.431	0.995	0.526	(± 0.0135)	(± 0.0448)	(± 0.0271)	(± 0.0314)	(± 0.0240)	(± 0.0709)	(± 0.3844)	(± 0.0475)3-hop ngh.	0.830	0.881	0.597	0.918	0.871	0.508	0.984	0.524	(± 0.0147)	(± 0.0363)	(± 0.0307)	(± 0.0278)	(± 0.0136)	(± 0.1032)	(± 0.3094)	(± 0.0889)MolHMPN-0	-0838	0.918	0.605	0927-	0.873	-0.450	0.815	0.519	(± 0.0146)	(± 0.0426)	(± 0.0227)	(± 0.0299)	(± 0.0232)	(± 0.0339)	(± 0.3606)	(± 0.0391)5.2	Subgraph comparisonsWe evaluate the performance of MolHMPN with other methods that employs other kinds of substruc-tures. We do this by assessing the effectiveness of employment of the functional group informationas compared to the baseline methods, which are known to effective in solving molecule generationand graph meta-learning tasks. Since we are making comparison based on the substructure typesonly, we analyze the results using MolHMPN-0. The baseline methods are (1) “Ring & ChemicalBond” which utilizes the ring structure and chemical bonds as the subgraph3 (Jin et al., 2020) and
Table A.1: Functional groups with nitrogen as the central atom. The red circles represent thecentral atoms, and the blue and green circles represent the 1-hop and 2-hop neighbors from thecentral atom respectively.
Table A.2: Functional groups with carbon as the central atom. The red circles represent thecentral atoms, and the blue and green circles represent the 1-hop and 2-hop neighbors from thecentral atom respectively.
Table A.3: Functional groups with oxygen as the central atom. The red circles represent thecentral atoms, and the blue and green circles represent the 1-hop and 2-hop neighbors from thecentral atom respectively.
Table A.4: Functional groups with phosphorus as the central atom. The red circles representthe central atoms, and the blue and green circles represent the 1-hop and 2-hop neighbors from thecentral atom respectively.
Table A.5: Functional groups with sulfur as the central atom. The red circles represent the centralatoms, and the blue and green circles represent the 1-hop and 2-hop neighbors from the central atomrespectively.
Table A.6: Datasets types, number of tasks, performance metric and split typeDataset	Task	Number of tasks	Metric	SplitTox21	Classification	12	AUROC	RandomClinTox	Classification	2	AUROC	RandomSIDER	Classification	27	AUROC	RandomBBBP	Classification	1	AUROC	RandomBACE	Classification	1	AUROC	RandomESOL	Regression	1	RMSE	RandomFreeSolv	Regression	1	RMSE	RandomLipophilicity	Regression	1	RMSE	RandomTable A.7: Atom features used to featurize the node featuresAtom Features	Number of Featuresatom type one hot	43atomic number	1atom mass	1atom degree one hot	11atom explicit valence one hot	6atom implicit valence one hot	7atom total num H one hot	5atom formal charge one hot	5
Table A.7: Atom features used to featurize the node featuresAtom Features	Number of Featuresatom type one hot	43atomic number	1atom mass	1atom degree one hot	11atom explicit valence one hot	6atom implicit valence one hot	7atom total num H one hot	5atom formal charge one hot	5atom hybridisation one hot	5atom num radical electrons one hot	5atom is aromiatic one hot	2atom is in ring one hot	2atom chiral tag one hot	4atom chirality type one hot	2atom is chiral center	1Table A.8: Bond features used to featurize the edge featuresBond Features	Number of Featuresbond type one hot	4
Table A.8: Bond features used to featurize the edge featuresBond Features	Number of Featuresbond type one hot	4bond is in ring	1bond is conjugated one hot	217Under review as a conference paper at ICLR 2022Training details. For our tasks, we randomly split the datasets into 80:10:10 ratio as the training,validation and test sets and take the average of the results from different 5 random seeds (0 to 4). Weuse the AdamP optimizer (Heo et al., 2021) whose learning rate is scheduled by the CosineAnnealingscheduler(Loshchilov & Hutter, 2016). The loss functions for the classification and regression tasksare the binary cross-entropy (BCE) loss and mean squared error (MSE) respectively. We give extraweights to the minority class in the loss functions for the classification datasets based on the ratioof the minority to majority class of each task to handle the class imbalance problems. The attentivesum and max function are used as the readout function of Gθ(∙). We use a batch size of512, run themodels for 500 epochs and initialized the learning rate as 0.001. For F⅛(∙) and Gθ(∙), We use onlyone HyperMP layer each. The training details can be found in Table A.9 and A.10.
Table A.9: Hyperparameters for MolHMPN-0Dataset	xk	Cycles	GNN dropout	Regressor dropout	MLP neurons	Latent dimensionsTox21	ZERO	FALSE	0.2	0.2	[64]	128ClinTox	ZERO	FALSE	0.3	03	[64, 32]	128SIDER	MEAN	FALSE	0.0	01	[64]	128BBBP	MEAN	FALSE	0.0	00	[128]	256BACE	MEAN	TRUE	0.2	00	[64, 32]	128ESOL	MEAN	TRUE	0.0	0.0	[128]	256FreeSolv	MEAN	FALSE	0.4	0A	-	128Lipophilicity	MEAN	FALSE	0.2	0.2	-	128Table A.10: Hyperparameters for MolHMPN-1,2,3Dataset	xk	Cycles	GNN dropout	Theta dropout	Regressor dropout	MLP neurons	Latent dimensionsTox21	ZERO	FALSE	0.2	0.2	0.2	[64]	128ClinTox	ZERO	FALSE	0.3	03	0.3	[128]	256SIDER	MEAN	FALSE	0.0	00	0.1	[64]	128BBBP	MEAN	FALSE	0.0	00	0.0	[128, 64]	256BACE	MEAN	TRUE	0.0	00	0.0	[128]	256ESOL	MEAN	TRUE	0.0	0.0	0.0	[128]	256FreeSolv	MEAN	FALSE	0.4	01	0.4	-	128Lipophilicity	MEAN	FALSE	0.2	0.2	0.2	-	128
