Table 1: Mean and standard deviation of the classification accuracy of 5 runs. The first two columnsrepresent the number of observed nodes used in the evaluation and training of each experiment (See§4.2 for more detail). If the number of observed nodes is constant, the setting corresponding to eachdataset is indicated with daggers (f」). Results of the unpaired t-test with the best baseline (exceptfor the oracle ) are denoted by asterisks ( **P-value < .001 , *P-value < .05 ).
Table 2: Performance byedge types on FNTN.
Table 3: Meanings of the notationsNotation	MeaningG = (Vglob, Aglob , Xglob) obs	obs S = {S1, ..., SM}, S = {S1 , ..., S S = (Vsub,Asub), Sobs = (Vobs,Aobs) Vglob , Vsub , Vobs Aglob , Asub , Aobs Xglob ∈ R∣Vglob∣×Fin g F in , F y ∈ {1, ..., C}	A global graph Mobs }	Sets of M subgraphs and partially observed subgraphs A subgraph and a partially observed subgraph Sets of nodes in G, S, Sobs Sets of edges in G, S, Sobs An input feature matrix of global nodes Vglob A vector of subgraph-level features Dimensions of X glob and the learned representation A label (class) corresponding to the subgraph SG[Vsub] = (Vsub,A[Vsub]) Vsubk , Vglobk V+,V-	An induced subgraph of G formed from a set of nodes in the subgraph Vsub The k-hop neighbors of observed nodes u ∈ Vobs that are actually included in the subgraph Vsub, and that are not. Positive and negative sets of nodes for Inter-SGIEin : RN×Fin ×A→RN×F EQ, EK, EV, EI : RN×F → RN×F Hobs,Hsubk,Hglobk andH+,H- H *, H ± HQ,obs, HK，*, HV，*, HI，± sobs , ssub ∈ RF Robs , Dobs and Rsub , Dsub	A graph neural encoder for input features X glob , Aglob Encoders for Intra-SGI (Q, K, V ) and Inter-SGI (I) Encoded node representations of Vobs , Vsubk , Vglobk (Intra-SGI) andV+,V- (Inter-SGI) Concatenation of Hobs,Hsubk,Hglobk (Intra-SGI) and H+ , H- (Inter-SGI) The output of EQ, EK, EV, EI onHobs, H*, H*, H± The subgraph summary vectors of node representations HQ，obs , HV，* in subgraphs Sobs , S Readout functions and discriminators for Intra-SGI (Hobs, sobs) and Inter-SGI(H*, SSUb)	B Proof of Proposition 1Proposition 1 (The conditional GAN-like divergence MI bound). For d-dimensional randomvariables X and Y with a joint distribution p(x, y) and marginal distributions p(x) and p(y), fixany function f : (X, Y) → R and realization X of X. Let Cx = Ey 〜p(y)[ef(x,y)], Bcx ⊂ R bestrictly lower bounded by cx, and Ycx = {y |ef(x,y) ∈ Bcx} with an assumption of p(Ycx ) > 0. ForYr in the Borel σ-algebra over Rd, let q(Y ∈ Yr|X = x) = p(Yr |Ycx), then I CGAN ≤ IGAN whereIcGAN = Ex,y〜p(x,y) [log σ(f (x, y川 + Ex〜p(x)Ey〜q(y∣x) [log (I- σ"(x, y)))] ,	(14)Igan = Ex,y〜p(x,y) [log σ(f (x, y))]+ Ex〜p(x)Ey〜p(y) [log (1 - σ(f (x, y)))] .	(15)Proof. It suffices to show that Ey〜p(y) [log (1 + ef (x,y))] ≤ Ey〜q®x) [log (1 + ef(x,y))] forall Xto prove ICGAN ≤ IGAN, since,Ey〜P(y) [log (1 + ef(x,y))] ≤ Ey〜q(y∣x) ^og (1 + ef(x,y))][log (1 + ef(x,y)) ] ≤ Ex 〜p(x),y 〜q(y∣x) bog (1 + ef (x,y))]⇒ Ex〜p(x),y〜q(y∣x) [log (I- σf (X, y)))] ≤ Ex〜p(x),y〜p(y) [log (I- σf (X, y)))]⇒ I CGAN ≤ IGAN(16)
Table 4: Statistics of real-world datasets.
Table 5: Summary of accuracy (5 runs) of Intra/Inter-SGI with and without using Transformer in theencoder EQ (Equation 10). The result of GraphSAGE in the best setting is also presented.
Table 6: Comparison of k-hop subgraphs and full subgraphs for different graph characteristics:degree assortativity, average clustering, and density.
Table 7: Summary of accuracy (5 runs) of GraphSAGE model on three datasets with regard to theratio of observed nodes at the test and training (i.e., x%/x% setting).
Table 8: Mean wall-clock time (seconds) per batch of the training process on real-world datasets.
Table 9: The number of parameters of GraphSAGE and Intra/Inter-SGI.
