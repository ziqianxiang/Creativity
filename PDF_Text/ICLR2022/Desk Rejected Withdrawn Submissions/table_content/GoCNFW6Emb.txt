Table 1: Average test results at 16x acceleration for in- and out-of-distribution data with SNRand motion perturbations. The heavy difficulty configuration (R(σ) = [0.2, 0.5) for noise andR(α) = [0.2, 0.5) for motion) was used for all physics-driven augmentations during consistencytraining with 1:1 balanced sampling and augmentation curricula with highest validation cPSNR.
Table 2: Average test results for in-distribution data and out-of-distribution data with heavy motionand heavy noise perturbations. Physics augmentations are compositions of noise and motion in theirheavy training difficulty configurations.
Table 3: Ablation for consistency at pixel-level vs. latent space. LM: light motion; HM: heavymotionModel	cPSNR (dB)	SSIM	CPSNR (dB)(LM)	SSIM (LM)	cPSNR (dB) (HM)	SSIM (HM)Supervised	35.8	0.798	33.6	0.809	27.1	0.706Pixel-Level	36.4	0.873	35.9	0.866	33.2	0.828R4	36.4	0.877	34.7	0.865	29.8	0.778R3,R4	36.4	0.873	34.0	0.852	30.1	0.781R2,R3,R4	36.3	0.873	34.4	0.854	29.5	0.769R1,R2,R3,R4	36.3	0.875	34.7	0.864	30.3	0.7755.3	VORTEX VS. BASELINESWe compare VORTEX performance for in- and out-of-distribution data at 16x acceleration tosupervised methods using both physics-driven and the state-of-the-art image-based MRAugmentaugmentations, and to the state-of-the-art self-supervised via data undersampling (SSDU) recon-struction method (Yaman et al., 2020). We describe SSDU method and our implementation in detailin the Appendix D.2. OOD simulations of SNR change and motion corruption follow the setupdescribed in Section 5.2 where heavy motion (HM) corresponds to α = 0.4 phase error amplitudeand heavy noise (HN) corresponds to σ = 0.4 additive k-space zero-mean complex-valued Gaussiannoise. Physics augmentations listed in Table 2 correspond to the composition of noise and motionaugmentations in their heavy difficulty configurations during training (R(σ) = [0.2, 0.5) for noiseand R(α) = [0.2, 0.5) for motion). Consistency-weighting λ, augmentation probability p, balanced
Table 4: Summary of notation used in this work.
Table 5: Data augmentation configuration for mridata 3D FSE knee dataset experiments. p is theeffective probability of applying an augmentation. In MRAugment, this is equivalent to the baseprobability multiplied by the weighting factor. Acquisition-based augmentations were configured inseparate experiments at both light and heavy settings.
Table 6: Comparison of different scheduling methods and warmup periods on the mridata knee multi-coil dataset with heavy motion augmentations. All scheduling methods outperform non-scheduledtraining (base). There is no advantage of a specific scheduling protocol, suggesting that somecurriculum is better than none.
Table 7: Impact of training duration on cPSNR of supervised methods without augmentations(Supervised), supervised methods with motion augmentations (Aug (Motion)), MRAugment, andVORTEX with motion consistency (VORTEX (Motion)). Training duration are percentages of thefull training duration (200 epochs). * indicates the default training configuration. Both supervisedaugmentation methods and MRAugment are more sensitive to training time than Supervised orVORTEX methods. Supervised underperforms Aug, MRAugment, and VORTEX. VORTEX achieveshighest performance and is insensitive to training duration relative to the other methods.
Table 8: Ablation for acceleration — 12x vs 16x. Like in the 16x regime, VORTEX (Motion)outperformed supervised methods, and MRAugment at 12x acceleration. This may suggest thatVORTEX is broadly applicable to different acceleration levels.
Table 9: Slice metrics (mean [standard deviation]) on the mridata knee dataset. Asterisk (*) indicatessignificant performance of VORTEX over all baselines (p <0.05).
Table 10: Test performance (mean [standard deviation]) on the fastMRI multi-coil brain dataset at 8xacceleration. Results are shown on both in-distribution data and different motion levels of α = 0.6,α = 0.8, α = 1.0 for Supervised, SSDU, MRAugment, augmentation baselines, and VORTEX.
