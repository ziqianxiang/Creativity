Table 1: CIFAR- 10: Certified accuracy at various `2 radii and ACR scores. We train different models byvarying the hyper-parameters for SmoothAdv, Adv2 and Adv∞ (as in (Salman et al., 2019a)) and by choosingσ = {0.25, 0.5, 0.75} for test-time adaptation to obtain the maximum certified radii for each test example. SeeTable 5 and 6 (Appendix) for detailed results on both ImageNet and CIFAR- 1 0 respectively. We also presentthe best reported results for MARCER and Consistancy at σ = 0.5, obtained from their respective papers.
Table 2: Top-1 accuracy of different classifiers under different levels of Gaussian noises augmented to the testimages. We randomly shuffle test images and sample the noises and report (mean ± 2 × sd) of five runs.
Table 3: Top-1 accuracy using fixed test batch-size = 512 for AT models under Gaussian augmented noisewith σ = 0.5 for different choices of momentum, ρ during inference. We randomly shuffle the test images toreport (mean + 2 × sd) of 5 different runs.
Table 4: Top-1 accuracy using fixed ρ = 1 for AT models under Gaussian augmented noise with σ = 0.5 fordifferent size of test batches during inference. We randomly shuffle the test images to report (mean + 2 × s.d.)of 5 different runs.
Table 5: ImageNet: Certified top-1 accuracy at various '2 radii as we vary σ for BN adaptationand certification along with average certified radii (ACR). We use ResNet50 for ImageNet. Eachgray block is corresponding to one classification model while the rows are corresponding to itscertification performances as we choose different noise levels for adaptations and certifications. TheBest Radii are obtained by selecting the highest radius for each test example as we adapt the modelswith different noise levels, σ .
Table 6: CIFAR- 10: Certified top-1 accuracy at various `2 radii as we vary σ for test-time BN adaptationalong with average certified radii (ACR) for individual SettingS. Each gray block iS correSponding to oneclaSSification model while the rowS are correSponding to itS certification performanceS aS we chooSe differentnoiSe levelS for adaptationS and certificationS. The Best Radii are obtained by training different modelS withvarying hyper-parameterS and adapting them with different noiSe levelS during inference. We alSo preSent thebeSt reported reSultS for MARCER (Zhai et al., 2020) and ConSiStancy Jeong & Shin (2020) at σ = 0.5,obtained from the reSpective paperS.
