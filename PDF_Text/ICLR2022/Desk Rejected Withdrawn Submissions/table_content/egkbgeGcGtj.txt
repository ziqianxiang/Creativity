Table 1: Overall results evaluated on four different datasets: Pascal VOC, ADE20K, COCO-Stuffand Cityscapes, using different number of datasets for pretraining.
Table 2: Ablation studies on hyper-parameters.
Table 3: Comparisons with more baselines.
Table 4: Comparisons of different cross-dataset mixing strategies.
Table 5: The effects of consistent learning.
Table 6: ResUlts over Pascal VOC With fixed backbone.
Table 7: Results of pixel-to region loss and our pixel-to prototype loss on head classes and taildasses of ADE20k.___________________________________________________________________________Method	Wall	Head classes (top 5%)					road	mIoU		bUilding	sky	floor	tree	ceiling		pixel-to-region	73.21	79.48	^^93.29	76.77	70.96	79.83	80.16	39.22pixel-to-prototype	73.12	79.93	93.62	77.11	71.58	80.75	79.74	39.60Method			Tail classes (last 5%)					mIoU	monitor	bUlletin board	shoWer	radiator	glass	clock	flag	pixel-to-region	37.69	30.64	0.0^^	29.19	1.34	15.23	1.9	39.22pixel-to-prototype	45.25	35.31	0.0	38.45	1.06	21.35	12.01	39.60A. 1 Evaluation with fixed backboneWe fix the backbone and fine-tUne only the segmentation head to verify the discriminability of thefeatUres obtained by MDP. The resUlts are shoWn in Table 6. MDP achieves 6.43% performance gaincomparing With the pixel-to-pixel baseline (57.31% to 63.74%), and also oUtperforms sUpervisedor self-sUpervised ImageNet pretraining (61.97% and 63.51%). The performance can be fUrtherimproved by a large margin by adding the COCO-StUff dataset and prolong the pre-training epochs.
Table 8: Results of 2-stage pretraining based on ImageNet pretrained weights. * means conductingMDP on the basis of ImageNet pretraining.
Table 9: Transferability of MDP using segmentation dataset for pretraining, and testing over COCOdetection and instance segmentation.
