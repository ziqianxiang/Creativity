Table 1: The generation results for Ring and Grid synthetic data.
Table 3: Results on CIFAR-10 and CIFAR-100.				Models	CIFAR-10		CIFAR-100		IS↑	FIDJ	IS↑	FIDJGAN	4.84	^^4	4.79	85.6Unrolled GAN	4.65	76.2	4.96	83.1VEEGAN	3.56	161.1	4.34	88.6GDPP	4.43	80.4	4.87	82.8DP-GAN	4.72	78.7	4.79	83.3IID-GAN(1-D)	4.89	-65.4	5.05	84.5IID-GAN(M -D)	5.00	76.9	5.27	82.1The Gaussian inverse samples. As discussed above, some methods (Kingma & Welling, 2014;Srivastava et al., 2017) designs an inverse mapping or an encoder to learn the representations betweenz and x. However, as shown in Left 4 columns of Fig. 4, VAE-based methods (Kingma & Welling,2014) can cause the overlap of the inverse samples z, which may lead to bad generations(whitepoints). And BiGAN and VEEGAN learn the relations between z and x rather than the relationamong the samples {G-1(x)}, which fails to get the 2D inverse Gaussian samples as shown in thefirst column of Fig. 4. For IID-GAN, as shown in the fifth column for IID-GAN(M-D), the inversesamples is very similar to the Gaussian samples, which show the effect of the regularization.
Table 2: Static evaluation for IID test on Ring.			Model	SW Static ↑	KS S Dimension 1	tatic J Dimension 2BiGAN	-0.8537-	0.3900	0.1637VEEGAN	0.9567	0.3141	0.2350IID-GAN(1-D)	-0.9548-	0.0882	0.0866IID-GAN(M-D)	0.9824	0.1185	0.0579are used for IID test. Compared to other methods, the blue points of IID-GAN are closer to the reddiagonal, which means that the inverse samples of each dimension are close to the Gaussian.
Table 4: Generation Results on Stacked MNIST andthe architecture is in	line with Radford et al. (2016).			Table 5: Generation Results on STL-10.			Models	StackedMNIST Mode↑	KLl	FIDL			Models	IS↑	STL-10 FIDj	MS↑GAN	392.0	8.012	97.788	GAN	2.28	245.21	2.29VEEGAN	761.8	2.173	86.689	BiGAN	1.22	251.21	1.22PACGAN	992.0	0.277	117.128	Unrolled GAN	4.78	142.16	4.62IID-GAN(1-D)	^^996.4	0.152	86.911	VEEGAN	1.45	298.95	1.46IID-GAN(M -D)	999.7	0.101	69.675	IID-GAN(M -D)	5.16	139.10	5.12Table 6: Evaluation with the frameworkResults on conditional generation. We present the re-sults in Fig. 8. Given different categories for generation,the conditional IID-GANs (including its 1-D version) arethe most stable and robust on CIFAR-10, and do not suf-fer from mode collapse. More results about conditionalgeneration are presented in Appendix G.2.
Table 6: Evaluation with the frameworkResults on conditional generation. We present the re-sults in Fig. 8. Given different categories for generation,the conditional IID-GANs (including its 1-D version) arethe most stable and robust on CIFAR-10, and do not suf-fer from mode collapse. More results about conditionalgeneration are presented in Appendix G.2.
Table 7: Network Architecture of Inverse F forSynthetic Ring-Grid Data.
Table 8: Network Architecture of DiscriminatorD for Synthetic Ring-Grid Data.
Table 9: Network Architecture OfDiscriminator D for Synthetic Ring-Grid Data.
Table 10: Network Architecture of Inverse F for CIFAR-10 and CIFAR-100.
Table 11: Network Architecture of Generator G for CIFAR-10 and CIFAR-100.
Table 12: Network Architecture of Discriminator D for CIFAR-10 and CIFAR-100.
Table 13: Network Architectures of Generator Gfor STL-10.				Layer	Output size			KernelLinear	8192			ResnetBlock	4	×	4	3 × 3, 256 3 × 3, 256 1 × 1, 256Upsample	8	×	8	scale factor = 2.0ResnetBlock	8	×	8	3 × 3, 128 3 × 3, 128 1 × 1, 128Upsample	16	×	16	scale factor = 2.0ResnetBlock	16	×	16	3 × 3, 64 3 × 3, 64 1 × 1, 64Upsample	32	×	32	scale factor = 2.0ResnetBlock	32	×	32	3 × 3, 64 3 × 3, 64Conv2d	32	×	32-	G.2 Results for Real DataTable 14: Network Architecture of Inverse F forSTL-10.		Layer	Output size	KernelConv2d	32 × 32	3 × 3, 64ResnetBlock	32 × 32	3 × 3, 64		3 × 3, 64AvgPool2d	16 × 16	3 × 3, stride 2
Table 14: Network Architecture of Inverse F forSTL-10.		Layer	Output size	KernelConv2d	32 × 32	3 × 3, 64ResnetBlock	32 × 32	3 × 3, 64		3 × 3, 64AvgPool2d	16 × 16	3 × 3, stride 2		3 × 3, 64ResnetBlock	16 × 16	3 × 3, 128		1 × 1, 128AvgPool2d	8 × 8	3 × 3, stride 2		3 × 3, 128ResnetBlock	8×8	3 × 3, 256		1 × 1, 256AvgPool2d	4 × 4	3 × 3, stride 2		3 × 3, 256ResnetBlock	4×4	3 × 3, 512		1 × 1, 512Linear	20	Results on disentanglement. We perform unsupervised disentanglement learning with M-D IID-
Table 15: NetWork ArChiteCture of DiSCriminator D for STL-10.
