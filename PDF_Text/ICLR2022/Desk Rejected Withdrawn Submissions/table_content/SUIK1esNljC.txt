Table 1: Test errors of AutoDrop and baselines reported inthe literature. For CIFAR-10 and CIFAR-100 we ran eachexperiment four times with different random seeds. We reportthe mean and standard deviation of the final test error (at the200th epoch). For ImageNet, we ran each experiment onceand report the final test error (at the 105th epoch). * followsthe the setup of (Zhang et al., 2019b). ^ follows the the setupof (Zagoruyko & Komodakis, 2016). * follows the the setup			of (He et al., 2016).			Model	一	MethOd			Test Error [%]ResNet-18 CIFAR-10	BaSeIinei (P = AutoDrop (ρ 二 AutoDrop (ρ 二 AutoDrop (ρ 二	0.2) 0.1) 0.2) 0.5)	4.87 ± 0.085 5.07 ± 0.465 4.61 ± 0.173 4.71 ± 0.111WRN-28x10 CIFAR-10	BaSeline* (P = AutoDrop (ρ 二 AutoDrop (ρ 二 AutoDrop (ρ 二	0.2) 0.1) 0.2) 0.5)	3.77 ± 0.05 3.73 ± 0.26 3.73 ± 0.10 4.29 ± 1.13ResNet-34 CIFAR-100	BaSeIinei (P = AutoDrop (ρ 二 AutoDrop (P 二 AutoDrop (ρ 二	0.2) 0.1) 0.2) 0.5)	21.91 ± 0.20 23.27 ± 0.48 21.82 ± 0.50 21.43 ± 0.29WRN-40x10 CIFAR-100	Baseline* (ρ = AutoDrop (ρ 二 AutoDrop (ρ 二 AutoDrop (ρ 二	0.2) 0.1) 0.2) 0.5)	19.16 ± 0.11 18.25 ± 0.33 18.17 ± 0.25 23.15 ± 3.43ReSNet-18- ImageNet	BaSeline* (P = AutoDrop (p 二	0.1) 0.1)	29.93 29.80	the baselines), was always among the winning AutoDrop strategies. For ImageNet the baseline8Under review as a conference paper at ICLR 2022recommended using ρ =0.1 and again for this setting AutoDrop performed favorably. Furthermore,in Figure 6 we report an exemplary plot capturing the behavior of the learning rate, train loss, and
Table 2: Test error [%] of AutoDrop andthe baseline for different initial learning rates.
