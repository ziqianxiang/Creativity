Table 1: Robust accuracy: stand-alone and add-on performances of adversarial purifiers are shownfor the worst white-box attack. SVHN dataset is evaluated below, and the results for other datasetscan be found in Appendix B.
Table 2: Computational load: Purification time (i.e., inference time) and training time of the ad-versarial purifiers. Purification time was measured with batch size one. The reported values weremeasured with a single RTX2080ti, except for the training time of PixelDefend’s TinyImageNet thatWas measured With four RTX2080ti's due to the memory requirement.______________________	SVHN		CIFAR-10		CIFAR-100		TinyImageNet		Purification time (sec/img)	Training time (min)	Purification time (sec/img)	Training time (min)	Purification time (sec/img)	Training time (min)	Purification time (sec/img)	Training time (min)Defense-GAN	0.14	205	0.13	197	0.14	198	0.31	1385PixelDefend	41.97	1185	40.54	1056	40.96	1056	166.31	5131AID-Purifier (Ours)	0.29	23	0.29	15	0.29	16	0.30	147Both of PixelDefend and AID-Purifier show positive improvements as a stand-along defense, but theperformance is far from being impressive. When both are utilized together, hoWever, they achieve42.67% of robust accuracy that is better than Madry or Zhang as a stand-alone. As an add-on,each of PixelDefend and AID-Purifier creates large improvements over all three adversarial trainingmodels. In fact, the best performance is achieved When both are utilized together. This synergy is dueto the diversity betWeen PixelDefend and AID-Purifier, and the diversity Will be discussed further inSection 6. In Table 1, PixelDefend tends to perform better than AID-Purifier as an individual model.
Table 3: Robust accuracy: Exhaustive experiment results for PixelDefend and AID-Purifier areshown for SVHN, CIFAR-10, CIFAR-100, and TinyImageNet datasets. As an add-on, each of Pix-elDefend and AID-Purifier provides a positive improvement for almost any individual combinationof dataset and attack method. Worst in the last column denotes the worst robustness among Clean,PGD, C&W, DF, and MIM. By inspecting the worst performance column of each dataset, it can beobserved that PixelDefend+AID-Purifier achieves the best performance for three datasets and AID-Purifier achieves the best performance for TinyImageNet, which is the most complex dataset in ourexperiments.
Table 4: Robust accuracy under a score-based attack (Square attack) and transfer-based black-boxattacks. (S=T) denotes the source model (Wideresnet-34) is the same as the target model and (S6=T)denotes the source model (VGG-19) is different from the target model. PGD, C&W, DF, and MIMattacks are used to evaluate the transfer-based attacks, and the results for the worst attacks are shownin the table. The results are ShoWn for SVHN._______________________________________________	Score-based	Tranfer-based (S = T)	Transfer-based (S6=T)Natural training	0.213	11.955	38.55Natural training+AID-Purifier	51.625	43.178	43.32Madry et al. (2017)	16.745	40.731	87.31Madry et al. (2017)+AID-Purifier	84.668	55.025	86.42In addition to the ablation studies, we have investigated the sensitivity to the defense epsilon and thenumber of iterations N at the time of purification defense. The results are shoWn in Appendix G.1Where AID-purifier’s robustness is confirmed.
Table 5: DiScriminator architectureOperation	Size	Activation	Outputhlow → Linear	1024	ReLU	Linear	1024	ReLU	Output 1hhigh → Linear	1024	ReLU	Linear	1024	ReLU	Output 2Concat (Output 1, Output 2)	2048		Linear	1024	ReLU	Linear	512	ReLU	Linear	1		Sigmoid	1		A.3 AID-Purifier : discriminator hyperparametersTraining hyperparameters: We train the network uSing SGD with learning rate 0.01, weightdecay 2e-4, and momentum 0.9 for 1 epoch. We uSe γ = 2 for SVHN and γ = 1.5 for CIFAR-10,CIFAR-100, and TinyImageNet.
Table 6: HyperparameterS in Algorithm 2DataSet	N	ε	αSVHN	10	12/255	3/255CIFAR-10	10	8/255	2/255CIFAR-100	10	16/255	2/255TinyImageNet	10	8/255	2/25513Under review as a conference paper at ICLR 2022A.4 Attack hyperparametersAll attacks are evaluated under the l2 metric for C&W and the l∞ metric for the others. For SVHN,we use the perturbation size 12/255 and the step size 2/255. For CIFAR-10, CIFAR-100, and Tiny-ImageNet, we use the perturbation size 8/255 and the step size 1/255. We use Foolbox (Rauberet al., 2017), a third-party toolbox for evaluating adversarial robustness. All other parameters are setby Foolbox to be its default values.
Table 7: Robust accuracy: stand-alone and add-on performances of adversarial purifiers are shownfor the worst white-box attack. CIFAR-10 dataset is evaluated below.
Table 8: Robust accuracy: stand-alone and add-on performances of adversarial purifiers are shownfor the worst white-box attack. CIFAR-100 dataset is evaluated below.
Table 9: Robust accuracy: stand-alone and add-on performances of adversarial purifiers are shownfor the worst white-box attack. TinyImageNet dataset is evaluated below.
Table 10: Robust accuracy: exhaustive experiment results for NRP and AID-Purifier are shownfor SVHN, CIFAR-10, CIFAR-100, and TinyImageNet datasets. As an add-on, each of NRP andAID-Purifier provides a positive improvement for almost any individual combination of dataset andattack method. By inspecting the worst performance column of each dataset, it can be observed thatNRP+AID-Purifier achieves the best performance for two datasets, CIFAR-10 and CIFAR-100, andAID-Purifier achieves the best performance for two datasets, SVHN and TinyImageNet. Results ofstand-alone and add-on using AID-Purifier only are duplicated from Table 3.
Table 11: Robust accuracy: (SVHN under PGD attack; Madry is used to train the main classificationnetwork) (a) Performance of Madry and Madry+AID-Purifier for varying the attack epsilon of PGDare shown for SVHN. (b) Performance of Madry and Madry+AID-Purifier for varying the attackiteration of PGD are ShoWn for SVHN.______ _______________________________________Attack eps	Madry	Madry+AID-Purifier	Attack iteration	Madry	Madry+AID-Purifier1/255	57.29	88.20	40 (our Work)	38.17	49.852/255	49.49	86.92	100	35.64	48.604/255	42.18	83.82	200	34.86	48.348/255	34.94	73.14			12/255 (our Work)	38.17	49.85			16/255	22.28	28.62			32/255	1.27	1.59			(a)	(b)D.3 Common corruptionThe CIFAR10-C benchmark (Hendrycks & Dietterich, 2019) consists of 15 diverse corruption typesapplied to test images of CIFAR10. The corruptions are draWn from four main categories; noise,blur, Weather, and digital. We investigate the robustness for CIFAR10-C, and the results are shoWnin Table 12. Compared to Madry, Madry+AID-Purifier shoWed a similar performance. The resultsshoW that AID-Purifier is not sensitive to common corruptions.
Table 12: Robust accuracy results for different corruptions. Results are shoWn for Madry andMadry+AID-Purifier on CIFAR1OC.___________________________________________________________	Noise				Blur						Gaussian	Shot	Speckle	Impulse	Defocus	Gaussian	Motion	Zoom		Madry	8311	84.45	84.14	76.77	82.93	80Λ8	78.82	81.79		Madry+AID-Purifier	83.38	84.56	84.30	76.44	82.52	80.22	78.47	81.16				Weather					Digital				Snow	Fog	Brightness	Frost	Contrast	Elastic	Pixelate	JPEG	Spatter	SaturateMadry	82.87	61.94	85.64	79.87	44.84	81.92	86.38	85.96	83.86	85.46Madry+AID-Purifier	82.22	63.45	85.05	79.24	45.87	81.48	86.10	85.78	83.48	84.73D.4 AutoAttackWe evaluated AID-Purifier under a recent strong ensemble White-box attack, AutoAttack (Croce &Hein, 2020), and AID-Purifier significantly improves robust accuracy as shoWn in Table 13.
Table 13: Robust accuracy under AUtoAttack. The results are shown for SVHN.
Table 14: Ablation test results over the key features of AID-Purifier: The evaluations are over Madry,SVHN, and PGD. The baseline performance of Madry without any add-on is 38.17%. (a) Numberof intermediate layers connected from C(x) to the discriminator. (b) Training targets. (c) Dataaugmentation method for training.					Augmentation	Accuracy (%)Number of h(x) Accuracy (%)	Targets	Accuracy (%)	None AV	46.02 47.731	48.93	Contrastive	44.87	Mixup	48.492	49.85	Clean vs. adv.	49.85	AVmixup	49.85(a) Number of h(x)	(b) Training targets		(c) Data augmentation	E.2 INTERMEDIATE LAYERS CONNECTED FROM C(x) TO THE DISCRIMINATOR DTable 15: Ablation test of the intermediate layers connected from C(x) to the discriminator: Theevaluations are over Madry, SVHN, and PGD. 1st Conv denotes the output of the first convolutionlayer and n-th Block denotes the output of the n-th residual block, where downsampling is per-formed. Check symbols indicate the connected layers. The best performing combination is {10thblock, 15th block}, but we have used {1st Conv, 15th block} in our main experiments becausethe combination performs almost equally well and because it is more consistent with our designprinciple.
Table 15: Ablation test of the intermediate layers connected from C(x) to the discriminator: Theevaluations are over Madry, SVHN, and PGD. 1st Conv denotes the output of the first convolutionlayer and n-th Block denotes the output of the n-th residual block, where downsampling is per-formed. Check symbols indicate the connected layers. The best performing combination is {10thblock, 15th block}, but we have used {1st Conv, 15th block} in our main experiments becausethe combination performs almost equally well and because it is more consistent with our designprinciple.
Table 16: Robust accuracy results over Madry, SVHN, and PGD.
Table 17: Robust accuracy for Madry+AID-Purifier with respect to the variations in thenumber of defense iterations (SVHN underPGD attack; Madry is used to train the mainclassification network).
Table 18: Attack method used at the time of training and the resulting robust accuracy (SVHN underPGD attack; Madry is used to train the main classification network).
Table 19: Estimation results of mutual information between the two layers (hlow(x) and hhigh (x)).
