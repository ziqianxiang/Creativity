Table 1: Deploying the Dirichlet mechanism to protect deep reinforcement learning agentsConfiguration	Attack Accuracy (± Std)	Total Reward (± std)No Protection	99.19(±0.35)%	^^0.9095 (±0.0429)-k = 100	98.74 (±0.58) %	0.9047 (±0.0425)k = 10	55.87 (±2.58) %	0.8960 (±0.0475)k = 1	50.59 (±1.09) %	0.8936 (±0.0498)k = 0.1	50.00 (±0.00) %	0.8843 (±0.0487)k = 0.01	50.00 (±0.00)%	0.8783 (±0.0516)Table 2: Deploying the Dirichlet mechanism to protect sequence-to-sequence modelsConfiguration	Attack Accuracy (± std)	BLEU Score (± std)No Protection	81.02 (±1.64) %	-^46.74 (±0.16) %-k = 100	67.53 (±1.59) %	46.53 (±0.17) %k = 10	55.98 (±3.10) %	46.02 (±0.20) %k = 1	53.42 (±3.67) %	44.57 (±0.19) %k = 0.1	50.42 (±1.19) %	43.961 (±0.21)%k = 0.01	50.34 (±0.43)%	43.74 (±0.22) %In order to deploy the Dirichlet mechanism, we must choose the parameter k in equation 4. Irrespec-tive of k, the Dirichlet mechanism has a bounded local differential privacy budget and the expectedvalue of its output coincides with its input. However, the value of k affects the concentration of theoutputs around the input and affects the privacy parameters. As a result, the value of k balances the
Table 2: Deploying the Dirichlet mechanism to protect sequence-to-sequence modelsConfiguration	Attack Accuracy (± std)	BLEU Score (± std)No Protection	81.02 (±1.64) %	-^46.74 (±0.16) %-k = 100	67.53 (±1.59) %	46.53 (±0.17) %k = 10	55.98 (±3.10) %	46.02 (±0.20) %k = 1	53.42 (±3.67) %	44.57 (±0.19) %k = 0.1	50.42 (±1.19) %	43.961 (±0.21)%k = 0.01	50.34 (±0.43)%	43.74 (±0.22) %In order to deploy the Dirichlet mechanism, we must choose the parameter k in equation 4. Irrespec-tive of k, the Dirichlet mechanism has a bounded local differential privacy budget and the expectedvalue of its output coincides with its input. However, the value of k affects the concentration of theoutputs around the input and affects the privacy parameters. As a result, the value of k balances thetrade-off between the Dirichlet mechanism’s differential privacy and utility.
