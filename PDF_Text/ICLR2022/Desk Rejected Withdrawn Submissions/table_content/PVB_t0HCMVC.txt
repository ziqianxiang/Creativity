Table 1: Model accuracies on different datasets (%). We also provide the Standard Deviation for Allattacks of each method on each dataset.
Table 2: White-box attacks on MNIST and CIFAR-10 by manually selecting BN branches to gen-erate adversarial examples (BN0, BN1, BN2, and BN3 denotes the BN branch for clean, '1, '2, and'∞ adversarial examples in GBN, respectively). Results are shown in model accuracy (%).
Table 3: Classification accuracy (%) of ResNet-20 on CIFAR-10, where models need to generalizeto attack types not included for training (the higher the better).
Table 4: Model robustness of VGG-16 on CIFAR-10 (the higher the better).
Table 5: Model robustness of LeNet on MNIST over each individual attack (the higher the better).
Table 6: Model robustness of ResNet-20 on CIFAR-10 over each individual attack (the higher thebetter).
Table 7: Model robustness of ResNet-34 on Tiny-ImageNet over each individual attack (the higherthe better).
Table 8: Model robustness of VGG-16 on CIFAR-10 over each individual attack (the higher thebetter).
Table 9: Model robustness of WideResNet-28-10 on CIFAR-10 over each individual attack (thehigher the better).
Table 10: Robustness evaluation by AutoAttack (the higher the better). We report the clean accuracy,the robust accuracy of the individual attacks as well as the combined one of AutoAttack (denotedAA) using LeNet, ResNet-20, and ResNet-34.
Table 11: Model performance (classification accuracy %) of ResNet-20 on CIFAR-10 on differentPGD-k attacks (k denotes the iteration steps).
Table 12: Runtime analysis of different methods on CIFAR-10 (the lower the better).
Table 13: Model robustness of ResNet-20 on CIFAR-10 using different prediction approaches of thegated sub-network (the higher the better). The hyper-parameters for PGD-'ι, PGD-'2, and PGD-'∞attacks are shown in Section D.1 in the supplementary material.
