Table 1: Across all batch sizes we see that our approach provides better estimates of Wasserstein-2distance on the Classic Images from the DOTMark dataset. As mini-batch approaches are an upper-bound to Wasserstein distance, our 20-30% reduction and estimate represents a tighter approximation.
Table 2: Pyramid Mini-Batching dramatically increases the number of validly classified couplings.
Table 3: Across datasets with different numbers of modalities and various batch sizes, PMB ap-proaches improve learned alignments between (2x-5x) when compared to a random mini-batchbaseline. By aligning distributions according based on gradient flows at t = 50, we can get abetter sense of the limitations an approach will be able to fully align discrete distributions. We seethat the number of modes present in a dataset has an impact on how well Wasserstein-2 distancecan be minimized and that PMB approaches significant increase the ability to minimize this OTdistances. PMB batches of size 10 perform on par with random batches of size 1000 across all ofthese experiments on synthetic datasets.
