Table 1: Top-1 accuracy and training time in per epoch (accuracy/time) of ViTs trained from scratchon ImageNet-1k. We use warmup scheme coupled with a cosine scaling rule for 300 epochs. Fol-lowing the original setting of ViT, we set batch size as 4096.
Table 2: Large-batch training accuracy of ViT-B-16 on ImageNet-1k. We use warmup scheme cou-pled with linear rule to scale the learning rate for 300 epochs. Look-LayerSAM achieves consistenthigher accuracy than SAM from 4k to 32k.
Table 3: Accuracy of ViT-B-16 on ImageNet-1k when using RandAug and MixupAlgorithm	RandAug	Mixup	Optimizer	32k	64kVanilla ViT			LAMB	72.4	68.1Look-LayerSAM			LAMB	77.1	72.0Look-LayerSAM	X		LAMB	79.2	74.9Look-LayerSAM	X	X	LAMB	79.7	75.6To further evaluate the performance of LookSAM about accelerating the training of SAM, we an-alyze their training time when scaling batch size from 4096 to 32768. Note that we use TPU v3128 chips, TPU v3 256 chips, TPU v3 512 chips and TPU v3 1024 chips to report the speed ofViT-B-16 on batch size 4096, 8192, 16384 and 32768. Besides, we use warmup schedule coupledwith linear learning rate decay for 300 epochs. The experimental results are shown in Table 4, whichillustrates that LayerSAM will cause about 1.7× training time compared with vanilla ViT. However,Look-LayerSAM can significantly reduce the training time and achieve 1.5× speed compared withLayerSAM when k = 5. In particular, training time of ViT-B-16 on ImageNet-1k can be reduced to0.7 hour.
Table 4: Training Time of ViT-B-16 on ImageNet-1kAlgorithm	4k	8k	16k	32kLAMB	4.8h	2.4h	1.2h	/LAMB + LayerSAM	8.4h	4.3h	2.2h	1.1hLAMB + Look-LayerSAM	5.6h	2.8h	1.4h	0.7h4.4	Accuracy and Efficiency TradeoffThe reuse frequency k controls the trade-off between the accuracy and speed. In this section, we tryto conduct an analysis on the performance of LookSAM with different values ofk. The experimentalresults in Figure 4 indicates that LookSAM can achieve the similar accuracy as vanilla SAM whenk ≤ 5. With reuse frequency k getting larger, the accuracy begin to drop while the training speedis accelerated. When k is larger than 15, we notice that the speed is converged (almost identical toplain AdamW training). Therefore, in practice we can determine the k value based on the desiredtrade-off, and we recommend k = 5 for general applications since it will significantly improve theefficiency while still achieve almost identical test accuracy as SAM.
Table 5: Sensitivity Analysis of αModel	Method	Optimizer	Batch Size	α = 0.5	α = 0.7	α = 1.0ViT-B-16	Look-LayerSAM	LAMB	~~16384^^	77.7	78.4	78.2ViT-B-16	Look-LayerSAM	LAMB	32768	76.5	77.1	75.94.5.2	SENSITIVITY ANALYSIS OF ρFinally, we also have a sensitivity analysis for different value of ρ, the intensity of perturbation onLook-LayerSAM algorithm. We evaluate the accuracy of ViT-B-16 on batch size 16384 and 32768.
Table 6: Sensitivity Analysis of ρModel	Method	Optimizer	Batch Size	ρ = 0.5	ρ=0.8	ρ= 1.0	ρ = 1.2ViT-B-16	Look-LayerSAM	LAMB	^^16384^^	77.0	77.8	78.4	77.9ViT-B-16	Look-LayerSAM	LAMB	32768	75.2	76.4	77.1	76.75	ConclusionWe propose a novel algorithm LookSAM to reduce the additional computation from SAM and speedup the training process. To further evaluate the performance in large-batch training, we proposeLook-LayerSAM, which use a layer-wise schedule to scale the weight perturbation of LookSAM.
Table 7: Accuracy of different Models on CIFAR10Model	AdamW	SAM-5	SAM-10	SAM-20	LookSAM-5	LookSAM-10	LookSAM-20	SAMWRN-28-10	96.5	97.2	97.0	968	97.3	97.1	97.0	97.3ResNet-18	95.6	96.2	96.0	96.0	96.2	96.1	96.1	96.4ResNet-50	95.7	96.6	96.5	96.2	96.8	96.6	96.4	96.9Table 8: Accuracy of Different Models on CIFAR100Model	AdamW SAM-5 SAM-10 SAM-20	LookSAM-5	LookSAM-10	LookSAM-20	SAMwrn-28-10	81.7	83.8	833	829	844	843	836 ResNet-18	78.9	80.4	80.0	79.7	80.7	80.4	80.0 ResNet-50	81.4	82.5	82.3	82.1	83.3	82.8	82.4	84.4 80.7 83.3A.4 Parameter SettingsIn this section, we will introduce the architectures of ViTs in this paper (Table 9). Next, we providethe hyperparameters in Table 10 for ViT training, including learning rate, warmup, optimizer, gradi-ent clipping, epoch, etc. In addition, Table 11 gives us the parameter settings of ViT for large-batchtraining in this paper.
Table 8: Accuracy of Different Models on CIFAR100Model	AdamW SAM-5 SAM-10 SAM-20	LookSAM-5	LookSAM-10	LookSAM-20	SAMwrn-28-10	81.7	83.8	833	829	844	843	836 ResNet-18	78.9	80.4	80.0	79.7	80.7	80.4	80.0 ResNet-50	81.4	82.5	82.3	82.1	83.3	82.8	82.4	84.4 80.7 83.3A.4 Parameter SettingsIn this section, we will introduce the architectures of ViTs in this paper (Table 9). Next, we providethe hyperparameters in Table 10 for ViT training, including learning rate, warmup, optimizer, gradi-ent clipping, epoch, etc. In addition, Table 11 gives us the parameter settings of ViT for large-batchtraining in this paper.
Table 9: Architectures of ViTsModel	Params	Patch Resolution	Sequence Length	Hidden Size	Heads	LayersViT-B-16	87M	16×16	196	768	12	12ViT-B-32	88M	32 × 32	49	768	12	12ViT-S-16	22M	16×16	196	384	6	12ViT-S-32	23M	32 × 32	49	384	6	1215Under review as a conference paper at ICLR 2022Table 10: Parameter Settings of ViT for Vanilla TrainingModel	Input Resolution	Batch Size	Epoch	Warmup Steps	Peak LR	LR Decay	Optimizer	ρ	Weight Decay	Gradient ClippingViT-B-16	224	4096	200	10000	3e-3	cosine	AdamW	/	0.3	1.0ViT-B-32	224	4096	200	10000	3e-3	cosine	AdamW	/	0.3	1.0ViT-S-16	224	4096	200	10000	3e-3	cosine	AdamW	/	0.3	1.0ViT-S-32	224	4096	200	10000	3e-3	cosine	AdamW	/	0.3	1.0ViT-B-16 + SAM	224	4096	200	10000	3e-3	cosine	AdamW	0.18	0.3	1.0ViT-B-32 + SAM	224	4096	200	10000	3e-3	cosine	AdamW	0.15	0.3	1.0ViT-S-16 + SAM	224	4096	200	10000	3e-3	cosine	AdamW	0.1	0.3	1.0ViT-S-32 + SAM	224	4096	200	10000	3e-3	cosine	AdamW	0.05	0.3	1.0ViT-B-16 + LookSAM	224	4096	200	10000	3e-3	cosine	AdamW	0.18	0.3	1.0ViT-B-32 + LookSAM	224	4096	200	10000	3e-3	cosine	AdamW	0.15	0.3	1.0
Table 10: Parameter Settings of ViT for Vanilla TrainingModel	Input Resolution	Batch Size	Epoch	Warmup Steps	Peak LR	LR Decay	Optimizer	ρ	Weight Decay	Gradient ClippingViT-B-16	224	4096	200	10000	3e-3	cosine	AdamW	/	0.3	1.0ViT-B-32	224	4096	200	10000	3e-3	cosine	AdamW	/	0.3	1.0ViT-S-16	224	4096	200	10000	3e-3	cosine	AdamW	/	0.3	1.0ViT-S-32	224	4096	200	10000	3e-3	cosine	AdamW	/	0.3	1.0ViT-B-16 + SAM	224	4096	200	10000	3e-3	cosine	AdamW	0.18	0.3	1.0ViT-B-32 + SAM	224	4096	200	10000	3e-3	cosine	AdamW	0.15	0.3	1.0ViT-S-16 + SAM	224	4096	200	10000	3e-3	cosine	AdamW	0.1	0.3	1.0ViT-S-32 + SAM	224	4096	200	10000	3e-3	cosine	AdamW	0.05	0.3	1.0ViT-B-16 + LookSAM	224	4096	200	10000	3e-3	cosine	AdamW	0.18	0.3	1.0ViT-B-32 + LookSAM	224	4096	200	10000	3e-3	cosine	AdamW	0.15	0.3	1.0ViT-S-16 + LookSAM	224	4096	200	10000	3e-3	cosine	AdamW	0.1	0.3	1.0ViT-S-32 + LookSAM	224	4096	200	10000	3e-3	cosine	AdamW	0.05	0.3	1.0Table 11: Parameter Settings of ViT for Large-Batch TrainingModel	Batch Size	Epoch	Warmup Steps	Peak LR	LR Decay	Optimizer	ρ	α	Weight Decay	Gradient ClippingViT-B-16 + SAM	4096	200	10000	1e-2	linear	LAMB	0.18	/	0.1	1.0ViT-B-16 + SAM	8192	200	10000	1.7e-2	linear	LAMB	0.18	/	0.1	1.0ViT-B-16 + SAM	16834	200	7000	1.8e-2	linear	LAMB	0.18	/	0.1	1.0ViT-B-16 + SAM	32768	200	6000	1.8e-2	linear	LAMB	0.18	/	0.1	1.0
Table 11: Parameter Settings of ViT for Large-Batch TrainingModel	Batch Size	Epoch	Warmup Steps	Peak LR	LR Decay	Optimizer	ρ	α	Weight Decay	Gradient ClippingViT-B-16 + SAM	4096	200	10000	1e-2	linear	LAMB	0.18	/	0.1	1.0ViT-B-16 + SAM	8192	200	10000	1.7e-2	linear	LAMB	0.18	/	0.1	1.0ViT-B-16 + SAM	16834	200	7000	1.8e-2	linear	LAMB	0.18	/	0.1	1.0ViT-B-16 + SAM	32768	200	6000	1.8e-2	linear	LAMB	0.18	/	0.1	1.0ViT-B-16 + LayerSAM	4096	200	10000	1e-2	linear	LAMB	1.0	/	0.1	1.0ViT-B-16 + LayerSAM	8192	200	10000	1.7e-2	linear	LAMB	1.0	/	0.1	1.0ViT-B-16 + LayerSAM	16384	200	7000	1.8e-2	linear	LAMB	1.0	/	0.1	1.0ViT-B-16 + LayerSAM	32768	200	6000	1.8e-2	linear	LAMB	1.0	/	0.1	1.0ViT-B-16 + LayerSAM	65536	200	3500	2e-2	linear	LAMB	1.0	/	0.2	1.0ViT-B-16 + Look-LayerSAM	4096	200	10000	1e-2	linear	LAMB	1.0	0.7	0.1	1.0ViT-B-16 + Look-LayerSAM	8192	200	10000	1.7e-2	linear	LAMB	1.0	0.7	0.1	1.0ViT-B-16 + Look-LayerSAM	16384	200	7000	1.8e-2	linear	LAMB	1.0	0.7	0.1	1.0ViT-B-16 + Look-LayerSAM	32768	200	6000	1.8e-2	linear	LAMB	1.0	0.7	0.1	1.0ViT-B-16 + Look-LayerSAM	65536	200	3500	2e-2	linear	LAMB	1.0	0.7	0.2	1.0A.5 Generalization boundWe firstly introduce Theorem 1 regarding generalization bound based on sharpness of LookSAMand then give a proof for it. Note that a similar bound was also established in the original SAMpaper Foret et al. (2020).
