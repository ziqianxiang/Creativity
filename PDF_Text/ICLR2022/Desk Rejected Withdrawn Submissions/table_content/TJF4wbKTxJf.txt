Table 1: Illustration of our CSR-Conv-4 architec-ture in Table 2 for VGG-16 with T = 5, wherethe parameters in the 6th-13th convolutional layersare converted to the parameters U, V in CSR-Convwith the same spatial sizes.
Table 2: Summary of our results on (2nd block) CIFAR-10 and (3rd block) ImageNet, where “#C-C” denotesthe number of CSR-Conv modules used in the networksfor learning compact networks, and “pm” denotes themodel size compression rate.
Table 3: Lightweight network comparison on ImageNet interms of the number of parameters and top-1 error. Numbersare cited from https://paperswithcode.com/sota/image- classification-on-imagenet. All the net-works with model sizes smaller than 5M are included.
Table 5: Comparison on CIFAR-10.
Table 6: Pruning results on CIFAR-10based on our learned CSR-Conv net-works. Here, VGG-16 and ResNet-56are two backbone networks.
