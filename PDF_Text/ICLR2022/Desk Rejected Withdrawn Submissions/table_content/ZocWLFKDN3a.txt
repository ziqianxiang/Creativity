Table 1: Evaluations of our model on VQA v2 and VQA-CP v2. In the table, UpDn (Andersonet al., 2018) does not deal with the language priors problem, so does our model without introduceregularization (mark f in the table). AdvReg (Ramakrishnan et al., 2018) introduce adversariallearning to alleviate the language priors.
Table 2: Evaluate on VisDial v1.0. This paper compare the models which constructed based on softattention mechanism in different manners. RvA (Niu et al., 2019) recursively calculate vision atten-tion based on dialog context. MCA-I-H (Agarwal et al., 2020) stacked the self attention and crossattention in image representations and text representations. MVAN (Park et al., 2021) considers themulti view such as word level attention and sentence level attention.
Table 3: Robustness test with the noise contextI x£ : there is a male baseball player that has swung■ ■ Torthrballx； : is there a man? yesI : is he a baseball player? yes.. ^isheinauniformyesQ4: is he a professional?Prediction: yesGT: yes■ ■看芯■ ■石苕:a person with an open umbrella near a car:what color is van? blue:is it day time out? yes:whal color is bicycle? blueQ4: is it raining?Prediction: yesGT: yes
