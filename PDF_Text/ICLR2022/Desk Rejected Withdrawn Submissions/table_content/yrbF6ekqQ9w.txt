Table 1: ID and OOD performance of various methods. E2E: end-to-end; LC: linear classifier. Thehighest overall accuracy for each dataset is in bold, while the highest accuracy among models derivedfrom CLIP is underlined. Avg OOD displays the mean performance among the five OOD datasets,while Avg ID,OOD shows the average of ImageNet (ID) and Avg OOD.
Table 2: Compared to the fine-tuned model, WiSE-FT improves OOD accuracy without reducing IDaccuracy. Compared to the zero-shot model, WiSE-FT improves ID accuracy without reducing OODaccuracy. All numbers are percentage point improvements. Top and bottom respectively capturevertical movement above the fine-tuned model (i.e., improved effective robustness) and horizontalmovement to the right of the zero-shot model in the associated scatter plots.
Table 3: In addition to robustness, WiSE-FT with optimal Î± is able to improve in-distributionperformance on a number of datasets compared to standard fine-tuning.
Table 4: OOD accuracy gain (percentage points) without any loss in ID accuracy relative to thefine-tuned linear classifier for the methods described in Section B.3.
Table 5: Accuracy of various independently trained models ensembled with CLIP on ImageNetand derived distribution shifts. OSE denotes output-space ensembling. Avg OOD displays the meanperformance among the five out-of-distribution datasets, while Avg ID,OOD shows the average ofImageNet (ID) and Avg OOD.
