Table 1: Shuffle test results and accuracy (%) comparison of the models trained by AT and thenaive BiaMAT using auxiliary datasets on CIFAR-10. More results on the effectiveness of the naiveBiaMAT can be found in Appendix G. Red numbers denote worse robustness than the vanilla AT.
Table 2: Performance improvements (accuracy %) on CIFAR-10 and CIFAR-100 following applica-tion of the proposed method using various datasets. The best results within each baseline method (ATand TRADES) are indicated in bold. The results on ImgNet100 can be found in Appendix E.
Table 3: Comparison (accuracy %) of the effectiveness of BiaMAT with the semi-supervised (Carmonet al., 2019) and pre-training (Hendrycks et al., 2019a) methods on CIFAR-10.
Table 4: Performance improvements (accuracy %) on CIFAR-10 following application of the proposedmethod using various datasets. The best result is indicated in bold.
Table 5: Comparison (accuracy %) of the effectiveness of data augmentation (cifar-B and cifar-C) oncifar-A.
Table 6: Performance improvements (accuracy %) on ImgNet100 following application of theproposed method using Places365 and ImgNet900. The best results are indicated in bold.
Table 7: Comparison (accuracy %) of the effectiveness of BiaMAT with the semi-supervised (Carmon				et al., 2019) and pre-training (Hendrycks et al., 2019a) methods on the CIFAR datasets.				Primary dataset	Method	Auxiliary dataset	Clean	AA	Hendrycks et al. (2019a)	CIFAR-100 ImageNet	80.21 87.11	42.36 55.30		CIFAR-100	82.61	50.81		Places365	83.95	52.81CIFAR-10	Carmon et al. (2019)	ImageNet ImageNet-500k	85.42 86.02	53.79 55.63		ImageNet-250k	86.51	56.27		ImageNet-100k	86.87	56.56	TRADES+BiaMAT (ours)	CIFAR-100	87.02	55.48		Places365	87.18	55.24		ImageNet	88.03	56.64	Hendrycks et al.(2019a)	ImageNet	59.23	28.79		Places365	56.74	26.22		ImageNet	63.45	27.71CIFAR-100	Carmon et al. (2019)	ImageNet-500k	64.90	28.64		ImageNet-250k	66.18	29.49		ImageNet-100k	65.40	30.61	TRADES+BiaMAT	Places365	64.58	29.24	(ours)	ImageNet	65.82	31.87
Table 8: Comparison (accuracy %) of the effectiveness of pre-training-based method using pre-trainedImageNet model on CIFAR-10 according to fine-tuning method.
Table 9: Accuracy (%) comparison of the models trained by AT and the naive version of BiaMATusing various datasets.
Table 10: FID to CIFAR-10.
Table 11: The training times of the models in our experiments.
Table 12: The hyperparameter α for each model in Table 9Primary dataset	Method	Auxiliary dataset	α		SVHN	0.5		CIFAR-100	0.5CIFAR-10	AT+BiaMAT	SVHN, CIFAR-100	0.5	(naive)	Places365	0.5		ImageNet	1.0		Places365, ImageNet	1.0CIFAR100	AT+BiaMAT	Places365	0.5	(naive)	ImageNet	1.0tiny images dataset (Torralba et al., 2008), and the 80 million tiny images dataset contains imagesdownloaded from seven independent image search engines: Altavista, Ask, Flickr, Cydral, Google,Picsearch, and Webshots. The Places365 images are queried from several online image search engines(Google Images, Bing Images, and Flickr) using a set of WordNet synonyms. The ImageNet imagesare collected from online image search engines and organized by the semantic hierarchy of WordNet.
Table 13: The hyperparameter α and π for each model in Table 2Primary dataset	Method	Auxiliary dataset	α	π		SVHN			AT+BiaMAT	CIFAR-100 Places365	1.0	0.55CIFAR-10		ImageNet				CIFAR-100			TRADES+BiaMAT	Places365 ImageNet	0.5	0.5CIFAR100	AT+BiaMAT	Places365 ImageNet	1.0	0.5	TRADES+BiaMAT	Places365 ImageNet	1.0	0.3ImgNet100	AT+BiaMAT	Places365 ImgNet900	1.0	0.5characteristics of the primary task, such as the scale of training loss and its learning difficulty. Forexample, the primary task on CIFAR-10 achieves a lower training loss than that on CIFAR-100, andthus, a smaller α value is required when the primary dataset is CIFAR-10 than that required whenthe primary dataset is CIFAR-100. In addition, when the proposed method is applied to improvethe sample complexity of a high-difficulty task, the confidence-based selection strategy becomessensitive to the hyperparameter π, because the threshold used by the strategy is determined basedon the confidences of the sampled primary data. Therefore, as a future research direction, we aim todevelop an algorithm that can stably detect the data samples causing negative transfer.
Table 14: The results of ablation study on π. Primary dataset: CIFAR-10; Auxiliary dataset: ImageNet.
Table 15: Accuracy (%) comparison of the models (WRN34-10) trained on each robust datasetgenerated from the AT and AT+BiaMAT models.
Table 16: Average higher-than-threshold ratio of the ImageNet training images by the AT+BiaMAT-trained CIFAR-10 classifier. The fine-grained ImageNet classes are mapped to CIFAR-10 superclassesby the WordNet hierarchy. “All” denotes the entire training ImageNet images. “Deer” and “Horse”classes has zero error because there is only one ImageNet class matched to each of them (Table 17).
Table 17: The mapping between CIFAR-10 superclasses and ImageNet classes for Table 16.
