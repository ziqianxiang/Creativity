Table 1: Median rank of compared methods across the datasets of the UCI machine learning repository.
Table 2: Results of all compared methods on the subset of medium-sized tabular datasets (Shwartz-Ziv& Armon, 2021). Reported values are the logloss on the respective test sets, averaged over threereplicates, as well as the corresponding standard error of the mean.
Table 3: Results of all compared methods on the subset of medium-sized tabular datasets (Shwartz-Ziv& Armon, 2021). Reported values are the misclassification error on the respective test sets, averagedover three replicates, as well as the corresponding standard error of the mean.
Table 4: Runtime estimates of Hopular and XGBoost based on the dataset gesture-phase, specified inseconds per step. One step refers to one complete pass through of the training set for Training, andone complete pass through of the test set for Inference. Although it takes more time to train Hopular,this difference is negligible during inference, as the absolute runtime is still in the seconds.
Table A1: Complete listing of all evaluated hyperparameter settings for Hopular. Settings with ascaling factor of 1 were additionally performed for NPT.
