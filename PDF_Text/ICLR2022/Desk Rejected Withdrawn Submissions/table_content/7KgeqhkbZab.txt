Table 2: ResUlts on CodeXGLUE datasetfor vUlnerability detectionModel	Acc (%)Transformer	62.0RoBERTa (code)	61.0CodeBERT	62.1PLBART	63.2CBERT	63.6*Boost	MLM+CLR+	64.4MLM+CLR±	63.6MLM+CLR± +NT-MLM	63.8*We take this resUlt from BUratti et al. (2020). Theydid not Use CodeXGLUE splits, so the test data canbe different with other baselines.
Table 3: Clone detection results on POJ104 and Big-CloneBenchModel	POJ104	BigCloneBench		MAP@R	Prec.(%)	Rec.(%)Transformer	62.11	-	-MIsIM-GNN	82.45	-	-RoBERTa (code)	76.67	-	-CodeBERT	82.67	94.7	93.4*GraphCodeBERT	-	94.8	95.2*B oost			MLM+CLR+	82.44	93.9	93.7MLM+CLR±	82.73	95.1	93.3MLM+CLR±+NT-MLM	82.77	94.2	94.6*The authors of both works fixed bugs in their evaluation tool and updated theresults in their Github repositories. We take their latest results and use their latestevaluation tool for fair comparisons.
Table 5: Results for the best baseline, smallBoost and medium Boost for each downstreamtask. POJ-104 is for code clone task; VD-CXG isfor CodeXGLUE vulnerability detection; VD-RVis for REVEAL vulnearbility detectionModel	POJ-104 (MAP@R)	VD-CXG (Acc)	VD-RV (F1)BOOSTsmall	82Γ^	63.8	46.4B oostmedium	83.5	64.6	50.2Baselinelarge	82.7	63.6	45.8formance of downstream tasks. Note that our medium dataset isof the baseline models (13G vs. 20G).
Table 6: Common Weakness Enumeration (CWE) types covered by our bug injection heuristicOperation	Potential CWE typesMisuse of Data Type	CWE-190: Integer overflow CWE-191: Integer Underflow CWE-680: Integer Overflow to Buffer Overflow CWE-686: Function Call With Incorrect Argument Type CWE-704: Incorrect Type Conversion or Cast CWE-843: Access of Resource Using Incompatible TypeMisuse of Pointer	CWE-476: NULL Pointer Dereference CWE-824: Access of Uninitialized Pointer CWE-825: Expired Pointer DereferenceChange of Conditional Statements	CWE-120: Buffer Overflow CWE-121: Stack-based Buffer overflow CWE-122: Heap-based Buffer overflow CWE-124: Buffer Underflow CWE-125: Out-of-bounds Read CWE-126: Buffer Over-read CWE-129: Improper Validation of Array Index CWE-787: Out-of-bounds Write CWE-788: Access of Memory Location After End of Buffer CWE-823: Use of Out-of-range Pointer OffsetMisuse of Values	CWE-369: DiVide ByZerO CWE-456: Missing Initialization of a Variable CWE-457: Use of Uninitialized Variable CWE-908: Use of Uninitialized ResourceChange of Function Calls	CWE-683: Function Call With Incorrect Order of Arguments CWE-685: Function Call With Incorrect Number of Arguments CWE-686: Function Call With Incorrect Argument Type CWE-687: Function Call With Incorrectly Specified Argument Value CWE-688: Function Call With Incorrect Variable or ReferenceA.2 Node Type DetailsWe parse the source code into ASTs and extract the node type and parent node type for each token.
Table 7: Examples for tokens and their AST node typestoken	node type	parent node type	token	node type	parent node typemt	type	func_definition	1	punctuation	Parenthesized_exprfoo	identifier	func_deClarator	return	keyword	return_Stmt(	punctuation	param」ist	(	punctuation	Parenthesized_exprint	type	parameter-declaration	1	number」iteral	Parenthesized_exprbar	identifier	parameter-declaration	)	punctuation	Parenthesized_expr)	punctuation	Parameter」ist	;	punctuation	return_stmt{	punctuation	compoundStmt	else	keyword	if_stmtif	keyword	if_stmt	return	keyword	return_stmt(	punctuation	Parenthesized_expr	(	punctuation	Parenthesized_exprbar	identifier	binary _expr	0	number」iteral	Parenthesized_expr<	operator	binary _expr	)	number」iteral	Parenthesized_expr5	number」iteral	binary _expr	;	punctuation	return_stmt			J		punctuation	compount_stmtA.3 DatasetPre-training We collect our dataset from C and Java Github repositories. Our main dataset is thecombination of Java small and C small. From Table 8, we can see that our dataset is significantlysmaller than the existing pre-trained models. For an ablation study (§ 6) with enlarged dataset, wecollect a medium dataset of C language. We have seen the improvement using such larger dataset,
Table 8: Comparison of pre-training dataset size between ours and other related workDataset	Instance Count	Total SizeBoost		Java SMALL	187K	992 MBC SMALL	64K	865 MBC MEDIUM	860 K	12 GBCOdeBERT	8.5M	-20GB-GraphCodeBERT	2.3M	20 GBCuBERT	7.4M	-DOBF	-	45 GBPLBART		-	576 GBDatasets for downstream tasks We provide dataset details of our downstream tasks in Table 9.
Table 9: Details of downstream tasks datasets.
