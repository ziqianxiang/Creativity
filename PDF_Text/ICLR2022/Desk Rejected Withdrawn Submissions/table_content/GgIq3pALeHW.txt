Table 1: MNIST Case 1 accuracy and F1 scoresModels	Private attr.		Utility attr.		accuracy	F1 score	accuracy	F1 scorewithout distortion (raw)	0198	0.98	0.98	0.98UAE-PUPET	0.29	0.26	0.9604	0.9676Under review as a conference paper at ICLR 2022(b) UPT curve (Accuracy Scores)Figure 4: MNIST Case 1: (4a) Odd and even adjacent columns show original and privatized ver-sions respectively (generated by joint training). Private feature refers to digit identity and utilityattribute refers to whether a number contains a circle or not. It is interesting to see that some pri-vatized data looks like a combination of more than one digits masked together, making it harder toinfer the digit identity. (4b) shows the robustness of joint training against multiple adversaries and aperformance comparison of the two settings.
Table 2: MNIST Case 2 accuracy resultsModel	Private attr. (acc)	Utility attr. (acc)without distortion (raw)	098	098emb-g-filter (Chen et al., 2019)	0.651	0.855UAE-PUPET		0.609	0.97Our proposed mechanism outperforms the existing method by achieving 4.2% smaller accuracy onthe private attribute and 11.5% higher accuracy on the utility attribute. Similarly, Figure 5c showsthat joint training performs much better than individual training. Also notice that considering onlythe Model 1 adversary, the private feature accuracy is 50%, whereas utility accuracy is maintained at96%. However, when we test the same private data against multiple adversaries we find adversarieswhich can perform much better, hence collapsing the privacy guarantee made by (Chen et al., 2019)under this model.
Table 3: UCI Adult accuracy and AUROC result comparison with existing techniquesModels	Private attr.		Utility attr.		accuracy	AUROC	accuracy	AUROCLFAE (LouiZoS et al., 2017)	0802	0.703	0.851	0.761LMFIR (Song et al., 2018)	0.728	0.659	0.829	0.741emb-g-filter (Chen et al., 2019)	0.717	0.632	0.822	0.731	UAE-PUPET		0.681	0.52	0.8274	0.731Fashion MNIST: We now consider a setup where the private feature is the identity of the fashionarticle (T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot) and theutility feature is encoded on two labels: Upper (meaning T-shirt/top, Pullover, Dress, Coat, Shirt)and Miscellaneous. Figure 7a shows the privatized images, along with their original versions. WeTable 4: Fashion MNIST accuracy and F1 scoresModels	Private attr.		Utility attr.		accuracy	F1 score	accuracy	F1 scorewithout distortion (raw)	0.98	0.98	099	0.99UAE-PUPET	0.24	0.20	0.95	0.958Under review as a conference paper at ICLR 2022see that the privatized images appear to have been changed to different articles of clothing. We alsonotice blurriness of privatized images, in such a way that they appear sometimes to be comprised of
Table 4: Fashion MNIST accuracy and F1 scoresModels	Private attr.		Utility attr.		accuracy	F1 score	accuracy	F1 scorewithout distortion (raw)	0.98	0.98	099	0.99UAE-PUPET	0.24	0.20	0.95	0.958Under review as a conference paper at ICLR 2022see that the privatized images appear to have been changed to different articles of clothing. We alsonotice blurriness of privatized images, in such a way that they appear sometimes to be comprised oftwo different images juxtaposed on one. Figure 7b shows the performance comparison of joint andindividual training, while Table 4 shows a drop of inference accuracy on private feature from 98%to 24% whereas the inference accuracy on utility feature decrease slightly from 99% to 95%.
Table 5: US Census Demographic Data Accuracy resultsModels	Private attr.		Utility attr.		accuracy	AUROC	accuracy	AUROCwithout distortion (raw)	0.887	0.885	0.92	0.925UAE-PUPET	0.52	0.52	0.90	0.8994 ConclusionIn this paper, we introduced a novel UAE-based privacy mechanism (UAE-PUPET), and showedthat it can attain better privacy-utility tradeoffs than the existing works. This implies that forcing aGaussian distribution on the latent variable of autoencoders (such as in VAE-based privacy mecha-nisms) appears to hinder, rather than help, the privacy mechanism. We emphasized the importanceof testing the privacy mechanism against multiple adversaries to provide better privacy guarantees.
Table 6: This neural network architecture reflect the architecture of both adversary and utility modelsfor MNIST case 1 and case 2 for discriminator mentioned in Model 1, Model 3, Model 4, Model 5and Model 6(in case of joint setting)Name	Configuration	RepetitionInput Layer	Input shape = (28 * 28)	1Reshape	ReshaPe(28,28,1)	1Convolution	conv2D (filter = 32 kernel size = 4), activation = relu	1MaxPooling	MaxPooling2D(pooLsize=(2, 2))	1Convolution	conv2D (filter = 16 kernel size = 4), activation = relu	1MaxPooling	MaxPooling2D(pooLsize=(2, 2))	1Flatten	Flatten()	1Output	Fully Connected FC (output shape), activation = softmax	1Table 7: This neural network architecture reflect the architecture of both adversary and utility modelsfor MNIST case 1 and case 2 for discriminator mentioned in Model 2Name	Configuration	RepetitionInput Layer	Input shape = (28 * 28)	1Reshape	ReShaPe(28,28,1)	1Convolution	conv2D (filter = 64, kernel size = 4), activation = relu	1MaxPooling	MaxPooling2D(pooLsize=(2, 2))	1Convolution	conv2D (filter = 16 kernel size = 4), activation = relu	1
Table 7: This neural network architecture reflect the architecture of both adversary and utility modelsfor MNIST case 1 and case 2 for discriminator mentioned in Model 2Name	Configuration	RepetitionInput Layer	Input shape = (28 * 28)	1Reshape	ReShaPe(28,28,1)	1Convolution	conv2D (filter = 64, kernel size = 4), activation = relu	1MaxPooling	MaxPooling2D(pooLsize=(2, 2))	1Convolution	conv2D (filter = 16 kernel size = 4), activation = relu	1MaxPooling	MaxPooling2D(pooLsize=(2, 2))	1Flatten	Flatten()	1Output	Fully Connected FC (output shape), activation = softmax	1A.2 Fashion MNIST experimentsOptimizer: Stochastic Gradient Descent (SGD)Learning rate: 0.01Loss: Categorical Cross-entropyBatch Size: 3213Under review as a conference paper at ICLR 2022Epochs: 30For FashionMNIST experiment where discriminators are trained either on distorted data or trained
Table 8: This neural network architecture reflect the architecture of both adversary and utility modelsfor all discriminators of FashionMNIST experimentsName	Configuration	RepetitionInput Layer	Input shape = (28 * 28)	1Reshape	ReshaPe(28,28,1)	1Convolution	conv2D (filter = 32, kernel size = 3), activation = relu, kernel initializer = he_uniform, padding = same, BatchNormalization()	2MaxPool	MaxPooling2D(pool Size = (2,2)), DroPoUt(0.3)	1Convolution	conv2D (filter = 64, kernel size = 3), activation = relu, kernel initializer = he_uniform, padding = same, BatchNormalization()	2MaxPool	Maxpooling2D(pool size = (2,2)), Dropout(0.4)	1Convolution	conv2D (filter = 128, kernel size = 3), activation = relu, kernel initializer = he_uniform, padding = same, BatchNormalization()	2MaxPool	Maxpooling2D(pool size = (2,2)), Dropout(0.5)	1Flatten	Flatten()	1Dense	FC(128), activation = relu, kernel initializer = he-uniform	1BatchNorm	BatchNormalization()	1Dropout	Dropout(0.6)	1Output	FC(Output shape), activation = softmax	1A.3 UCI Adult ExperimentsOptimizer: AdamLoss: Categorical Cross-entropyBatch Size: 512
Table 9: This neural network architecture reflect the architecture of both adversary and utility modelsfor all discriminators of UCI adult experimentsName	Configuration	RepetitionInput Layer	Input shape = (input shape = 102)	1Dense	FC(256), activation = relu	1Dropout	DroPoUt(0.2)	1Dense	FC(256), activation = relu	1Dropout	Dropout(0.3)	1Dense	FC(128), activation = relu	1Dropout	DroPoUt(0.4)	1Output	FC(output shape), activation = softmax	114Under review as a conference paper at ICLR 2022A.4 US Demography Census Data experimentsOptimizer: AdamLoss: Categorical Cross-entropyBatch Size: 512Epochs: 50For US Demography Census Data experiment where discriminators are trained either on distorteddata or trained together with the joint training:
Table 10: This neural network architecture reflect the architecture of both adversary and utilitymodels for all discriminators of US Census Demographic Data experimentsName	Configuration	RepetitionInput Layer	Input shape = (input shape = 14)	1Dense	FC(64), activation = relu	3Output	FC(output shape), activation = Softmax	1For more details on the architecture of the encoder and decoder, different system parameters based onwhich the experiments were conducted please refer to this url: https://anonymous.4open.
