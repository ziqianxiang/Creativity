Table 1: Comparison of various classification heads with a fixed pretrained feature extractor. Wereport average accuracy with 95% confidence interval on the test split of each dataset. Classifiersthat require optimization on novel support set are indicted with Xin the second column. ∣ NearestNeighbor classifier and ProtoNet classifiers with euclidean and cosine distances are equivalent.
Table 2: Accuracy with 95% confidenceinterval on support (S) and query (Q) setsof novel 5-shot tasks from MiniImageNet.
Table 3: (Left) Comparison of initialization methods for W1 and W2 . (Middle) Comparison of{W, b} and {W, b} from Eq. 2 and 3. (Right) Use of outlier exposure (OE) in meta-training of H.
Table 4: State-of-the-Art comparison on test split of MiniImageNet and TieredImageNet. We divide previous approaches into those that require task-dependent optimization (indicated With a Xin the second column) and those that do not. Our method belongs to the latter. We highlight state-of-the- art methods in each group separately. We report our accuracy With a 95% confidence interval on 10K tasks, setting aneW state-of-the-art in three out of four cases When compared to each of the tWo groups. Results on MiniImageNet and TieredImageNet datasets are reported from original paper and Xing et al. (2019) respectively. ^Results are reported from Ye et al. (2O20).						MiniImageNet			TieredImageNet	Method		1-shot 5-Way	5-shot 5-Way	1-shot 5-Way	5-shot 5-WayMTL (Sun et al., 2019)	X	61.20±1.80	75.50±0.80	-	-MetaOptNet-SVM (Lee et al., 2019)	X	62.64±0.61	78.63±0.46	65.99±0.72	81.56±0.53MCRNet-SVM (Zhong et al., 2021)	X	62.53±0.64	80.34±0.47	-	-Neg-Cosine (Liu et al., 2020)	X	63.85±0.81	81.57±0.56	-	-RFS (Tian et al., 2020)	X	64.82±0.60	82.14±0.43	71.52±0.69	86.03±0.49MABAS (Kim et al., 2020)	X	65.08±0.86	82.70±0.54	-	-SNAIL (Mishra et al., 2018)		55.71±0.99	68.88±0.92	-	-TADAM (Oreshkin et al., 2018)		58.50±0.30	76.70±0.30	62.13±0.31	81.92±0.30Shot-Free (Ravichandran et al., 2019)		59.04±0.43	77.64±0.39	66.87±0.43	82.64±0.43TapNet (Yoon et al., 2019)		61.65±0.15	76.36±0.10	63.08±0.15	80.26±0.12DSN (Simon et al., 2020)		62.64±0.66	78.83±0.45	66.22±0.75	82.79±0.48ProtoNet (Snell et al., 2017) t		62.39±0.21	80.53±0.14	68.23±0.23	84.03±0.16RelationNet2 (DCN) (Zhang et al., 2020)		63.92±0.98	77.15±0.59	68.58±0.63	80.65±0.91FEAT (Ye et al., 2020)		66.78±0.20	82.05±0.14	70.80±0.23	84.79±0.16Ours		66.33±0.20	82.19±0.14	72.06±0.22	86.50±0.15Table 5: State-of-the-art comparison on the test split of CIFAR-FS. Previous approaches are dividedinto two groups: (i) methods that require task-dependent optimization (indicated with Xin the sec-
Table 5: State-of-the-art comparison on the test split of CIFAR-FS. Previous approaches are dividedinto two groups: (i) methods that require task-dependent optimization (indicated with Xin the sec-ond column), and (ii) methods that do not. We highlight state-of-the-art methods in each groupseparately. Our method falls in the second group, where we set a new state-of-the-art. We alsooutperform the state-of-the-art method in the first group in the 5-shot case. Accuracy reported with95% confidence interval on 10K tasks. ^Results are reported from (Tian et al., 2020).
Table 6: Accuracy of our model with 95% confidence interval on test split of TieredImageNet datasetwhen meta-trained and meta-tested with different number of ways.
Table 7: Accuracy of our model with 95% confidence interval using ResNet-12 and ResNet-18backbones on test split of MiniImageNet dataset.
Table 8: Analyzing properties of context-aggregation and permutation invariance on 5-shot 5-wayMiniImageNet. We report accuracy with 95% confidence interval. Transformer aggregates contextin permutation invariant manner and achieves the highest accuracy.
Table 9: Accuracy of FEAT(Ye et al., 2020) with 95% confidence interval when the backbone ispretrained using supervised (Sup.) vs supervised and self-supervised (Sup.+Self-Sup.) objectives.
