Table 1: RbK,C (w(U, V)) = kUk2 + kVk2 of the predictor learned by gradient descent on linear convolutional networks withdifferent number of output channels C and kernel sizes K on the MNIST task. We show the mean over 10 trials as well as thestandard deviations are also shown.
Table 2: Rb K,C (fGD) = kUk2 + kVk2 of the predictor learned by gradient descent on ReLU convolutional networks without biasparameters, with different number of output channels C and kernel sizes K, on the MNIST task. The values shown are the medianstaken over 5 trials.
Table 3: Rb K,C (fGD) = kUk2 + kVk2 of the predictor learned by gradient descent on ReLU convolutional networks with bias onboth layers, with different number of output channels C and kernel sizes K, on the MNIST task. The values shown are the medianstaken over 5 trials.
Table 4: Rb K,C,3 (w(U, V)) = kUk2 + kVk2 of the predictor learned by gradient descent on linear convolutional networks withdifferent number of output channels C and kernel sizes K on the CIFAR-10 task.
Table 5: RbK,C,3(w(U, V)) = kUk2 + kVk2 of the predictor learned by gradient descent on linear convolutional networks withzero padding with different number of output channels C and kernel sizes K on the CIFAR-10 task.
