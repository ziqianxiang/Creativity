Table 1: AutoAttack robust ac-curacy of WRN-28-10 modelstrained using PGD adversarialtraining on CIFAR-10+DDPM-6M. Nonparametric activationfunctions are labeled by “Non”.
Table 2: Natural and robust accuracy of PGD adversarially trained models of various activationfunctions with respect to '∞ attacks with radius 0.031. The AA column gives the robust accuracyof attacks generated through AutoAttack on the test set. We highlight robust accuracies larger thanReLU in purple.
Table 3: Minimum and maximum values for clean accuracy of standard trained models across allactivations and parameter values tested.
Table 4: Natural and robust accuracy of adversarially trained VGG-16 models of various activationfunctions with respect to '∞ attacks with radius 0.031 generated through AUtoAttack. We highlightrobust accuracies higher than ReLU in purple.
Table 5: Natural and robust accuracy of adversarially trained WRN-28-10 models on CIFAR-10 withrespect to `2 attacks with radius 0.5 generated through AutoAttack. We highlight robust accuracieshigher than ReLU in purple.
Table 6: Natural and robust accuracy of TRADES adversarially trained ResNet-18 models of variousactivation functions with respect to '∞ attacks with radius 0.031 generated through AutoAttack. Wehighlight robust accuracies higher than ReLU in purple.
Table 7: Natural and robust accuracy of adversarially trained models of various activation functionswith respect to '∞ attacks with radius 0.031 generated through AutoAttack on ImageNette andCIFAR-100. We highlight robust accuracies higher than ReLU in purple.
Table 8: Natural and robust accuracy of PSSiLU model with β fixed at 0.3 with respect to L-infinityattacks with radius 0.031 generated by AutoAttack.
