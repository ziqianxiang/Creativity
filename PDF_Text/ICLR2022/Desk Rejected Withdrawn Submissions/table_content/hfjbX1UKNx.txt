Table 1: Precision and recall scores from PRD curves on MNIST, Fashion-MNIST and CelebAdatasets with the DCGAN architecture.
Table 2: FID scores on CIFAR-10 with the DCGAN architecture.
Table 3: FID, precision and recall scores on CIFAR-10 and CelebA datasets with the StyleGAN2architecture, where 10 and 5 discriminators are adopted, respectively, while k = 1. The asterisk (*)means that results are copied from (Yu et al., 2020) except for our method.
Table 4: Quantitative results on Yosemitee (SummerWinter) and CatDog dataset. The bestresults are obtained when MCL component is added in most cases. The asterisk (*) means that resultsare copied from (Mao et al., 2019).
Table 5: Quantitative results on CUB-200-2011. We obtained improved results consistently by addingthe proposed MCL component. The asterisk (*) means that results are copied from (Mao et al., 2019).
Table 6: Quantitative results on Yosemitee (SummerWinter) and CatDog dataset. The bestresults are obtained when MCL component is added in most cases. The asterisk (*) means that resultsare copied from (Mao et al., 2019).
Table 7: Recall and precision scores given by different clustering methods: MCL vs. ground-truthlabel. The model ‘Label’ assigns an expert discriminator of each real sample by the ground-truthlabel under our multi-discriminator framework.
Table 8: Effect of non-expert loss weight (α) when m = 10 and k = 1 on MNIST.
Table 9: Effect of balance loss weights (βd and βg) when m = 10 and k = 1 on MNIST.
Table 10: Comparisons by number of discriminators (m).
Table 11: Comparisons by number of experts per sample (k).
Table 12:	Stability of model performances and the number of active discriminators when m10,20,40andγ = 0.0002 on MNIST.
Table 13:	Comparisons of computational overheads on CelebA.
