Table 1: Clean and robust accuracy (%), and total training time (mins) of different adversarial train-ing methods. For each method, all the hyper-parameters were kept the same as full training. Forour proposed approach, the difference with full training is shown in parentheses. Note that the ro-bust accuracy for each objective was computed accordingly, the detail of which can be found in theAppendix.
Table 2: Clean and robust accuracy (%), and total training time (mins) of Perceptual AdversarialTraining for CIFAR-10 and ImageNet-12 datasets. The training objective uses Fast LagrangianPerceptual Attack (LPA) (Laidlaw et al., 2021) to train the network. At test time the networksare evaluated against attacks that were not seen during training, as well as different versions ofPerceptual Adversarial Attack (PPGD and LPA). In each dataset, the unseen attacks were selectedsimilar to Laidlaw et al. (2021). For more information about the settings, please see the Appendix.
Table 3: Training details for experimental results of Section 4.
Table 4: Hyper-parameters of attacks used for the evaluation of PAT models in Section 4.
