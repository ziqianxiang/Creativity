Table 1: Joint inference results with T5 architecture on GLUE and SuperGLUE development sets, and WMT’sEnglish-to-Romanian translation. The FLOPs for Super and Swift are respectively 87×1011 and 4.25×1011.
Table 2: Ablation study on different T5-based scenarios. Each cell shows FLOPs/Accuracy.
Table 4: Joint inference results with BERT architecture on GLUE development set compared with SOTA.
Table 5: Orthogonality of E-LANG (ours) with Dyn-aBERT in terms of FLOPs/Accuracy.
