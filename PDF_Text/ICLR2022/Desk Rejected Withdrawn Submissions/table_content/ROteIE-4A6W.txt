Table 1: Setting of Early Specialization, Table 2: Setting of Efficient Parallel Branch. Fusion LayerN*N means 2D kernel size of convs. means fusing with which modality-shared layer.
Table 3: Experimental results of sharing different components in Transformer layer. LN1 denotesthe LN before Attn. LN2 denotes the LN before FFN.
Table 4: Results of sharing different layers in Transformer.
Table 5: Layer-wise NMI scores of models.													Layer	0	1	2	3	4	5	6	7	8	9	10	11 I Avg.	CLIP (ViT-B/32, T768)	0.586	0.387	0.265	0.252	0.255	0.241	0.239	0.243	0.235	0.23	0.227	0.185	0.278MS-CLIP (B/32)	0.589	0.332	0.235	0.211	0.2	0.21	0.2	0.202	0.214	0.197	0.192	0.173	0.246w/ Early Specialization	0.471	0.348	0.215	0.21	0.218	0.221	0.22	0.213	0.19	0.183	0.179	0.161	0.235MS-CLIP-S (B/32)	0.519	0.536	0.243	0.216	0.199	0.221	0.19	0.247	0.216	0.215	0.224	0.217	0.270Table 6: Experimental results of zero-shot recognition on ImageNet validation.
Table 6: Experimental results of zero-shot recognition on ImageNet validation.
Table 7: Results of zero-shot image-text retrieval.
Table 8: Linear probing results on 24 datasetsDatasets	CLIP (ViT-B32)	MS-CLIP-S (B32)	âˆ†Food-101	71.3	76.0	+ 4.7SUN397	68.1	71.7	+ 3.6Stanford Cars	21.8	27.5	+ 5.7FGVC Aircraft	31.8	32.9	+ 1.1Pascal Voc 2007	84.4	86.1	+ 1.7Describable Texture (dtd)	64.1	69.4	+ 5.3Oxford-IIIT Pets	61.1	62.1	+ 1.0Caltech-101	82.8	81.6	- 1.2Oxford Flowers 102	90.7	93.8	+ 3.1MNIST	96.5	97.2	+ 0.7Facial Emotion Recognition	54.9	53.6	- 1.3STL-10	95.4	95.1	- 0.3GTSRB	67.1	69.9	+ 2.8PatchCamelyon	78.3	81.3	+ 3.0UCF101	72.8	74.6	+ 1.8CIFAR-10	91.0	87.2	- 3.8CIFAR-100	71.9	66.7	- 5.2Hateful Memes	50.6	52.4	+ 1.8
Table 9: Common Semantic Structure distanceLayer	0	1	2	3	4	5	6	7	8	9	10	11	Avg.
