Table 1: Accuracy (%) on Office-31 dataset for UDA and source-free UDA methods (ResNet-50).
Table 2: Accuracy (%) on Office-Home for UDA and source-free UDA methods (ResNet-50).
Table 3: Accuracy (%) on VisDA-2017 for UDA and source-free UDA methods (ResNet-101).
Table 4: Accuracy (%) on Office-Home for ODA and PDA (ResNet-50).
Table 5: Ablation results (%) of Office-31 datasetfrom the same source modelAblation study	AvgSource pre-trained model (not train)	78.6Source pre-trained model + GMM PL (not train)	83.4Naive PL + Standard training + CE	80.6Naive PL + Maxprob weighting + CE	83.6GMM PL + PPL weighting + CE	87.7GMM PL + LPG weighting + CE	89.5GMM PL + JMDS weighting + CE	90.1GMM PL + JMDS + CE + Weight Mixup	90.0GMM PL + JMDS + CE + Aug	89.7GMM PL + JMDS + CE + Weight Mixup + Aug	90.5GMM PL + JMDS + SCE + Weight Mixup + Aug (CoWA) 90.9part of Table 5, we obtained the best performance when the SCE loss, weight mixup, and dataaugmentation are all applied. This clearly shows that each component is essential for CoWA training.
Table 6: The license of datasets from https://paperswithcode.com/datasets.
Table 7: The times spent on each task.
Table 8: The mean accuracy (%) and standard deviation of it on Office-31 dataset.
Table 9: The experimental results (%) about weight mixup on Office-31 dataset.
Table 10: Evaluations of the JMDS score based on AURC.
Table 11: Additional ablation results (%) for the other datasets.
