Table 1: CIFAR-10: Standard AdversarialTraining using Large-ε perturbations results inpoor clean accuracy. Performance (%) of variousexisting Adversarial Defenses trained using ε =8/255 or 16/255 against attacks bound withinε = 8/255 and 16/255. Defenses reported areTRADES (Zhang et al., 2019), AWP (Wu et al.,2020), PGD-AT (Madry et al., 2018) and FAT(Zhang et al., 2020).
Table 2: Adversarial Training on Contrast-Enhanced (CE) datasets: Performance (%) of theAWP-TRADES defense (Wu et al., 2020) by performing the training and evaluation on contrast-enhanced (CE) datasets when compared to standard datasets. Evaluation is done against AutoAttack(Croce & Hein, 2020b) at different perturbation bounds. The contrast of a dataset plays a significantrole in the Robustness-Accuracy trade-off achieved.
Table 3: Comparison with existing methods: Performance (%) of the proposed defense OA-ATwhen compared to baselines against the attacks, GAMA-PGD100 (Sriramanan et al., 2020), Au-toAttack (AA) (Croce & Hein, 2020b) and an ensemble of Square (Andriushchenko et al., 2020)and Ray-S (Chen & Gu, 2020) attacks (SQ+RS), with different ε bounds. Sorted by AutoAttack(AA) accuracy at ε = 8/255 for CIFAR-10 and CIFAR-100, andε = 4/255 for SVHN.
Table 4: CIFAR-10, CIFAR-100: Ablation experiments on ResNet-18 architecture to highlight theimportance of various aspects in the proposed defense OA-AT. Performance (%) against attacks withdifferent ε bounds is reported.
Table 5: CIFAR-10: Performance (%) of the proposed defense OA-AT against attacks with differentε bounds, when compared to the following baselines: AWP (Wu et al., 2020), ExAT (Shaeiri et al.,2020), TRADES (Zhang et al., 2019), ATES (Sitawarin et al., 2020), PGD-AT (Madry et al., 2018)and FAT (Zhang et al., 2020). AWP (Wu et al., 2020) is the strongest baseline. The first partitionshows defenses trained on ε = 16/255. Training on large perturbation bounds results in very poorClean Accuracy. The second partition consists of baselines tuned to achieve clean accuracy close to80%. These are sorted by AutoAttack accuracy (Croce & Hein, 2020b) (AA 8/255). The proposeddefense achieves significant gains in accuracy across all attacks.
Table 6: CIFAR-100: Performance (%) of the proposed defense OA-AT against attacks with dif-ferent ε bounds, when compared to the following baselines: AWP (Wu et al., 2020), ExAT (Shaeiriet al., 2020), TRADES (Zhang et al., 2019), ATES (Sitawarin et al., 2020), PGD-AT (Madry et al.,2018) and FAT (Zhang et al., 2020). AWP (Wu et al., 2020) is the strongest baseline. The base-lines are sorted by AutoAttack accuracy (Croce & Hein, 2020b) (AA 8/255). The proposed defenseachieves significant gains in accuracy against the strongest attacks across all ε bounds. Since theproposed defense uses AutoAugment (Cubuk et al., 2018) as the augmentation strategy, we presentresults on the strongest baseline AWP (Wu et al., 2020) with AutoAugment as well.
Table 7: Evaluation against various attacks with a perturbation bound ofε = 8/255 on CIFAR-10: Performance (%) of the proposed defense OA-AT against various attacks (sorted by RobustAccuracy) to ensure the absence of gradient masking. ^Includes 5000-queries of Square attack.
Table 8: Effect of Ancillary Methods applied to AWP baseline: Performance (%) of modelstrained by applying AutoAugment (Cubuk et al., 2018), Label Smoothing + Warmup and WeightAveraging (Izmailov et al., 2018) to the AWP baseline (Wu et al., 2020), against GAMA-PGD100(Sriramanan et al., 2020) and Square (Andriushchenko et al., 2020) attacks. Results on the CIFAR-10, CIFAR-100 and SVHN datasets are reported using different ε bounds.
