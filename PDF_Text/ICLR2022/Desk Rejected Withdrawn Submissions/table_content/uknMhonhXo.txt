Table 1: Time series augmentations.
Table 2: Domain attributes. Each row of domains is regularized in fixed regularization selection.					(a) Bearings	(b) HHAR				Loc. Loading torque	User			Phone model	^^0~1 ~2~3-		Nexus	S3	S3 mini	S+Drive_A_B^^C^^D-	User 1	A	B	C	DFan E F G H	User 2	E	F	G	H		User 3	I	J	K	L4.1	Fault DetectionThe Bearings dataset1 from Case Western Reserve University is widely used for predictive mainte-nance. It contains vibration signals at 12kHz sampling rate to detect rolling element bearings faultsin rotating machines (Smith & Randall, 2015). We extract samples of length 4096 by a sliding win-dow with stride 290 (Zhang et al., 2017). There are 1 healthy class and 9 fault classes: inner-racefault (IF), outer-race fault (OF), and ball fault (BF) with each further divided into dimensions 0.007,0.014 and 0.021 inches. We apply a combination of mean shift, scaling and masking data augmen-tations by setting μ = x, μnew = 0, σ = sd(x) and σnew = 1 in Table 1. Samples are augmentedwith probability 0.5, and additional augmentations beyond the first one are applied with probability0.5 to allow a mixture of perturbations. There are 8 domains: drive end and fan end location witheach operated at 0, 1, 2, and 3 loading torques as in Table 2. For fixed regularization selection, con-sistency regularization is applied on domains with the same location. From domain generalizationperformance in Table 3, the proposed method improves over the baseline ERM in almost all cases.
Table 3: Bearings: Classification accuracy on target domain using leave-one-domain-out testing andtraining on remaining domains.
Table 4: HHAR: Classification accuracy on target domain using leave-one-domain-out testing andtraining on remaining domains.
Table 5: Effect of regularization and time series augmentation strategies.
Table 6: Bearings: Average classification ac-curacy of proposed method with fixed consis-tency regularization using different regulariza-tion functions (squared L2 distance, cosine dis-tance, KL-divergence) between samples or do-mains and cluster centroids, without time seriesaugmentations.
Table 7: Bearings: Target domain classification accuracy of the proposed method given differentcluster assignments for fixed regularization selection, without time series augmentations. Placingeach domain in a separate cluster is equivalent to ERM.
Table 8	: Setup for hyperparameter tuning.	A.2 Datasets and network architecturesWe provide details on the sample size of the datasets. Backbone network architectures used for eachdataset is given in Table 9.
Table 9: Backbone network architectures for each dataset. Convolution operation is abbreviated as‘Conv’ and fully connected operation is abbreviated as ‘FC’.
Table 10: HHAR: Sample size distribution per domain.
Table 11: Bearings drive-end domains: Classification accuracy on target domain using leave-one-domain-out testing and training on remaining domains. Standard error is taken over 3 seeds.
Table 12: HHAR user 1: Classification accuracy on target domain using leave-one-domain-outtesting and training on remaining domains. Standard error is taken over 3 seeds. Train/test samplesplits in all domains are also varied by seed.
Table 13: Bearings: Regularization strategies of the proposed method for learned selective regular-ization, without time series augmentation.
