Table 1: Linear evaluation (top-1) and semi-supervised fine-tuning (1% labels or 10% labels) onImageNet after pretraining. BSSL outperforms all other SSL methods by large margins across forboth the linear evaluation and semi-supervised fine-tuning.
Table 2: Object detection (mAP, AP50 and AP75)on Pascal VOC after pretraining. BSSL outper-forms all the compared methods including super-vised pretraining.
Table 3: SVM classification (mAP) for the few-shot and full-shot settings on VOC07 after pretrain-ing. BSSL outperforms all other SSL methods by large margins and performs on par with supervisedpretraining on both settings. The number of shots (k) is varied from 1 to 96. We report the averagedperformance over 5 runs with the standard deviation.
Table 4: Transfer learning (top-1) on either object-centric or scene-centric datasets after pretraining.
Table 5: Ablation studies on the various proposed components of BSSL.① refers to using a ran-domly initialized classifier as targets. ② ‘Feat. Sim., refers to feature similarity loss (Eq. 2). ③’Dyn. Bal., refers to using the dynamic balancing. ④ refers to using the tuned multi-stage train-ing. Each step of improving BSSL contribute to a non-trivial performance gain as the evaluationis done with the ImageNet dataset. Also, using only ① already outperforms 'Tuned MoCov2', thestate-of-the-art SSL baseline for linear evaluation (Shen et al., 2021).
Table 6: L1, L2, and the cosine distancesare compared. The cosine distance is by farthe best choice amongst the three, as is sup-ported by our intuition that a bounded lossterm would be better as the augmented lossterm.
Table 7: Comparison of dynamic balancingfunctions. The Eq. 3 (smooth annealing)is the best amongst the three choices. Theλ(t) = 0.7 does not capture the dynamic na-ture of the balancing factor and the inverseshifted Heaviside step function disrupts thetraining midway.
Table 8: Linear evaluation (top-1) and image classification using SVM (mAP) on the ImageNet100and VOC07 datasets after pretraining on ImageNet100 are shown. BSSL performs the best comparedto SSL baselines and even outperforms the supervised pretraining. The best result among SSLmethods for each task is shown in bold.
Table 9: Semi-supervised fine-tuning with either 1% labels or 10% labels on the ImageNet100dataset after pretraining on ImageNet100 are shown. BSSL is the best performer in all metricscompared to SSL baseline and performs close to the supervised pretraining. The best result amongSSL methods for each setup is shown in bold.
Table 10: Few-shot image classification using SVM (mAP) on the VOC07 dataset after pretrain-ing on ImageNet100 are shown. The number of shots (k) is varied from 1 to 96 and the averageover 5 runs with the standard deviation are reported. BSSL outperforms all methods including thesupervised pretaining. The best result among SSL methods for each shot is shown in bold.
Table 11: SVM classification (mAP) and object detection (mAP, AP50, AP75) for supervised pre-training on ImagetNet100 and SSL pretraining on ImageNet are shown. BSSL outperforms all othermethods by large margins for both tasks. The best result for each metric is shown in bold.
Table 12: Few-shot image classification using SVM (mAP) on the VOC07 dataset for supervisedpretraining on ImagetNet100 and SSL pretraining on ImageNet are shown. The number of shots (k)is varied from 1 to 96 and the average over 5 runs with the standard deviation are reported. BSSLoutperforms all methods including the supervised pretaining. The best result among SSL methodsfor each shot is shown in bold.
