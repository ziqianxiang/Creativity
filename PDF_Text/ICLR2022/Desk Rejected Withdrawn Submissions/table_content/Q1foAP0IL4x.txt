Table 1: Results on Cifar-10 for supervised trained models with standard cross-entropy trainingLCE, adversarial PGD training (AT), and our proposed Noisy Adversarial Training (N-AT). For theexperiments marked with +, 1 million additional synthetic data points based on Cifar-10 were usedfor training. During training, the initial adversarial instances were created governed by '∞ with astrength of 8/255. All experiments were run 5 times and the mean value is reported.
Table 2: Loss functions and optimization problems defined for the used self-supervised adversarialtraining methods. In all formulations x is a given clean sample, f indicates the observed model, andδ is the adversarial perturbation. Also t1 and t2 define two different random transformation, whileτ is some temperature hyperparameter. The contrastive loss is used within the RoCL framework,based on SimCLR, where xpos and xneg give the positive and negative samples, respectively. Thesimilarity sim between two output vectors is calculated as the cosine similarity. For the MoCo Loss,q and k represent the query and key encoder, respectively, and M is the used memory bank. Whilestandard MoCo only defines one memory bank, within the AMOC framework the authors use twomemory banks Mclean and Madv to store the clean and adversarial historical samples. AMOC ACCis one specific loss function within the overall AMOC framework, for which the authors report goodresults, and which is therefore used in this study.
Table 3: Full list of parameters for training AMOC, as well as the supervised models/classificationheads with clean, i.e., LCE, and adversarial, i.e., AT, samples. FC is implemented to decaying thelearning rate by a factor of 10 at epochs 10 and 15, while TOTAL reduces the learning rate by afactor of 10 at epochs 30 and 35. A default transformation is implemented as padding by 4, randomresized cropping to 32, random horizontal flipping. SimCLR as transformation is composed of:random cropping of size 32, applying color jitter with a strength of 0.4 to the brightness, contrast,and saturation, while the hue is perturbed with strength 0.1, all with a probability of 0.8, randomgrayscale with a probability of 0.2, applying gaussian blur with a probability of 0.5, and randomhorizontal flipping. All inputs are converted to tensors, i.e., to the range [0, 1].
Table 4: Full list of parameters for training RoCL, as well as the supervised classification headswith clean, i.e., LCE, and adversarial, i.e., AT, samples. To train RoCL Kim et al. (2020) use theLARS You et al. (2017) optimizer based on SGD with the given parameters. The initial learningrate is increased during the first 10 epochs by an overall factor of 15. Afterwards the learning rate isdecayed by a cosine scheduler. Their input transformation is composed of: applying color jitter witha strength of 0.4 to the brightness, contrast, and saturation, while the hue is perturbed with strength0.1, all with a probability of 0.8, random grayscale with a probability of 0.2, random horizontalflipping, and random resized cropping of size 32. All inputs are converted to tensors, i.e., to therange [0, 1].
Table 5: Time demand for different operations during N-AT given in ms. For each method we listthe overall mean time and standard deviation for one epoch, as well as the time required to calculatethe initial adversarial input. The overall scatter operation is split into calculating δx0,x, which is onlyperformed once, and the creation of one pseudo adversarial input. In particular, we also list the timerequired to evaluate the loss function for the created pseudo adversarial instance.
Table 6: Results on Cifar-10 for supervised trained models with standard cross entropy trainingLCE, adversarial PGD training (AT), and our proposed Noisy Adversarial Training (N-AT). For theexperiments marked with +, 1 million additional synthetic data points based on Cifar-10 were usedfor training. During training, the initial adversarial instances were created governed by '∞ with astrength of 8/255. All experiments were run 5 times and the mean value is reported.
Table 7: Results on Cifar-10 for self-supervised trained models. In the first part, the classificationhead was trained without adapting the pretrained features. In the second part, the parameters ofthe pretrained model were also adapted during training the classification head. LCE, AT, and N-ATdefine, whether the classification head, and in case of finetuning the pretrained models, were trainedon clean, adversarial, or with addition of pseudo adversarial inputs, respectively. An N- before thegiven self-supervised method indicates, that our proposed extension was applied. During training,the initial adversarial instances were created governed by '∞ with a strength of 8/255.
