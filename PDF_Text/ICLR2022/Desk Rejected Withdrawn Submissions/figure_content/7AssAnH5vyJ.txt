Figure 1: Pipeline of solving combinatorial optimization problems in meta-level: At PSRO loop t,we first use meta-solver to compute the meta-strategy σt given the meta-table UΠt and then trainingbest response (St+1, PtI+1) based on current policy set and meta-strategy (Πt, σt). Finally we get anew meta-table UΠt+1 according to the new obtained policy and algorithm process transfers to thenext loop.
Figure 2: Exploitability and performance of our model as the PSRO training goes on5 4 3 2 1c⅝) ʤ⅛O-6O1Figure 3: Optimality gap of mixing-solver with different com- Figure 4: Ablations on differentbined numbers and weights	Initialization methodFig. 3 shows the comparison between different cases. We can see ’Original’ setting achieves the bestresults among different scales of TSP which shows the theoretic stability of nash weights describedin Section. 4.4. But for ’Uniform’ setting, its performance degenerates on different scales becauseit assigns equal importance on all solvers even though some of them are quite weak. As for the’Original-Partial’ setting, it only use 2 solvers which violates the original game structure, leading tothe poor ability to deal with unseen problems. However, considering the resource consumption, wehave to use partial solvers and lose a bit performance at the moment. And pursuing more efficientcombining implementation and more reasonable mixing weights are left for future works.
Figure 3: Optimality gap of mixing-solver with different com- Figure 4: Ablations on differentbined numbers and weights	Initialization methodFig. 3 shows the comparison between different cases. We can see ’Original’ setting achieves the bestresults among different scales of TSP which shows the theoretic stability of nash weights describedin Section. 4.4. But for ’Uniform’ setting, its performance degenerates on different scales becauseit assigns equal importance on all solvers even though some of them are quite weak. As for the’Original-Partial’ setting, it only use 2 solvers which violates the original game structure, leading tothe poor ability to deal with unseen problems. However, considering the resource consumption, wehave to use partial solvers and lose a bit performance at the moment. And pursuing more efficientcombining implementation and more reasonable mixing weights are left for future works.
Figure 5: Meta strategy of the model population.
Figure 6: Training figure of attack generator for LIH (Wu et al., 2021).
Figure 7: Training figure of attack generator for AM (Kool et al., 2018)A.6 Demonstration of Attack DistributionWe visualize the attack distribution obtained by each PSRO loop in Fig. 8. Specifically, Fig. 8(a), 8(c)and 8(e) are points which comprises 1000 instances. Fig. 8(b), 8(d) and 8(f) are corresponding kerneldensity estimations.
Figure 8: Attack distribution generated by PSRO16Under review as a conference paper at ICLR 202225	50	75	100	125Method→- Farthest Insertion→- Random Insertion* Nearest Insertion→- AM(n=20,gr)→- AM(n=50,gr)→- AM(n=100,gr)♦ AM(n=20,sample)→- AM(n=50,sample)→- AM(n=100,sample)Problem Scale(a) Generalization results on some classical heuristic methods and AM (Koolet al., 2018).
Figure 9: Generalization results of some models (or methods) on different problem scales.
