Figure 1: A neural network (left) with n(i) hidden units per layer is traditionally represented byexplicitly specifying the weights of the connections, usually as a matrix or tensor W(i) of dimensionn(i-1) Ã— n(i)(middle). We propose instead to view the network as sets of neurons (right), with(i)a neuron j in layer i represented as a vector zj . Weights are generated implicitly by calculatingalignment coefficients between neurons. This representation is parameter efficient and there is noexplicit ordering within each layer, rendering it permutation invariant.
Figure 2: Representation of a convolutional neuron. The standard representation explicitly specifiesall the weights in the kernel. Depthwise separable convolutions provide an approximate replace-ment by splitting the kernel into a pointwise kernel, which mixes information across channels, anda depthwise convolution which applies one spatial kernel per channel. We replace the pointwiseconvolution with an implicit representation using neuron embeddings but keep the depthwise con-volution, rendering the network permutation invariant to the ordering of filters but preserving spatialstructure. Each neuron embedding and depthwise convolution pair represents a single output filter.
Figure 3: Model accuracy under linear interpolation. Weights/embeddings are directly interpolated.
Figure 4: Accuracy under neuron transplanting. Crossover coefficient indicates the proportion ofneurons in the layer replaced by neurons from another model. At 100% crossover, an entire layerfrom the source network is directly transplanted to the recipient network without any further training.
