Figure 1: Causal graph illustrating assump-tions about content-specific feature zc andstyle-specific feature zs of the data point xand their relationship with category label yand domain label d. Observed variables areshaded.
Figure 2: An overview of the proposed model. For a source sample (x, y) (red box), its content-specific feature zc is extracted through the mapping F . By randomly picking a domain index d, anddrawing a Gaussian vector, a random domain feature Zs is generated by T. A new (semanticallypreserved) sample X is then generated by feeding Zc and Zs into G. The classifier f is trained by twolosses (all T, F, and G are pretrained and fixed during training f): 1) The standard cross-entropy lossLcls that encourages f to predict the correct class label for x, 2) The domain-invariant regularizationloss Lreg that encourages f to make similar prediction for X and x.
Figure 3: Exemplary images from different datasets. a) PACS datatset (first row: Art-painting, secondrow: Cartoon, Third row: Photo, last row: Sketch), b) OfficeHome dataset (first column: Art, secondcolumn: ClipArt, Third column: Product, last column: Photo). c) Mini-DomainNet dataset (firstcolumn: ClipArt, second column: Painting, Third column: Real, last column: Sketch).
Figure 4: Sensitivity analysis of DIR to the hyper-parameter Î» on OfficeHome dataset.
Figure 5: Image generation results on PACS. First row: Original Images. Second row: TransformedImages using C-StarGAN. Last row: Transformed Images using StarGAN.
