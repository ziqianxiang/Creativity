Figure 1: Motivations for discrepancy-optimal meta-learning. In the feature space Rd , T denotes therange of target domains and S1, S2 denote the ranges of two source domains. (+) and (-) denotepositive examples and negative examples, respectively. A real-world case is shown in Appendix Fis shown as the α-arrows and β-arrows in Figure 1 (c), respectively. A theoretical analysis from ageometric perspective shows that the collaborative effectiveness of the inner-loop and outer-loopoptimization is to minimize Y -discrepancy between target domain and the convex hull of sourcedomains. Empirically, we conduct experiments on DomainBed (Gulrajani & Lopez-Paz, 2020) andevaluate on two DG benchmarks. Results show that our method is highly effective and achievesstate-of-the-art performances. The code will be released at https://anonymous.com.
Figure 2: Geometric understanding. PX denotesthe space of domains (distributions) on input spaceand (M(PA(D)(S)(X)), discγ(∙, ∙)) denotes apseudo-metric space of domains (distributions) on featurespace.
Figure 4: t-SNE visualization of feature representions on PACS when the target domain is photo.
Figure 5: Number of meta-training domains on DomainNet.
