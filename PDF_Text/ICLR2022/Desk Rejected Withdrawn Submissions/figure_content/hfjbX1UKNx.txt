Figure 1: The main idea of MCL-GAN.
Figure 2: Snapshots of 256 random samples drawn from the generators of the baseline and MCL-GAN.
Figure 3: Qualitative comparison between MCL-GAN and GMAN on MNIST (top) and Fashion-MNIST (bottom). MCL-GAN generates more semantically faithful and diverse images than GMAN.
Figure 4: Effect of L1 loss weight (γ). Each random sample is colored by its expert discriminator.
Figure 5: Qualitative comparison between MCL-GAN and GMAN on Fashion-MNIST (top), CIFAR-10 (middle) and CelebA (bottom). MCL-GAN generates more realistic images with less failure casesthan GMAN.
Figure 6: Selected samples generated by MCL-GAN with DCGAN architecture.
Figure 7: Random samples generated by MCL-GAN with StyleGAN2 architecture. For generation,truncation ψ = 0.8 is applied.
Figure 8:	Cluster by discrimantors. Each row represents the subcluster of each discriminator. Closesimilarities are discovered among the images if they are in the same row.
Figure 9:	Effect of L1 loss weight (γ). The update statistics of individual discriminators when 40discriminators are used for training on MNIST and Fashion-MNIST datasets.
Figure 10:	Specialization results for k ∈ {1, 3, 5} with 10 discriminators on MNIST and Fashion-MNIST. The images in each row correspond to the same discriminators.
Figure 11: Diversity comparison of image-to-image translation on Yosemitee (SummerWinter) andCatDog dataset.
Figure 13: More image-to-image translation results by MCL-GAN on CatDog.
Figure 14: More text-to-image synthesis results by MCL-GAN on CUB-200-2011.
