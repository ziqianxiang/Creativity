Figure 1: An evaluation example on GigaWord for text summarization. IMAGINE visualizes ma-chine imagination with DALL-E's pre-trained dVAE and extracts textual and visual representationswith CLIP. While traditional evaluation metrics for natural language generation rely on n-gramsmatching or textual embeddings comparison, IMAGINE introduces imagination into the evaluationprocess and understands the text snippet as a whole with the help of multi-modal information.
Figure 2: IMAGINE similarity score computation process. Given the reference text Xref and thegenerated hypothesis Xhyp, We visualize the machine imagination Iref and Ihyp with the pre-traineddVAE. We extract features for the pair of text and corresponding pair of imagination with CLIP.
Figure 3: The effectiveness of augmenting BLEU-n (n=1,2,3,4) and BERTScore with IMAGINEsimilarities and BERTtext similarity on two machine translation datasets. The y-axis shows thePearson correlation with human judgments.
Figure 4: Case studies for machine translation. Src: the German text to be translated. Ref: thereference translation. Hyp: the generated translation candidate. We report the metric scores and thehuman score for the reported pair of (Ref, Hyp).
Figure 5: The effectiveness of augmenting BLEU, BERTScore and ROUGE-related metrics withIMAGINE similarities and BERTtext similarity on two abstractive text summarization datasets. They-axis shows the Pearson correlation with human judgments.
Figure 6: Case studies for abstractive text summarization. Src: the text to be summarized. Ref: thereference summary. Hyp: the generated summary candidate. We report the metric scores and thehuman score for the reported pair of (Ref, Hyp).
Figure 7: The effectiveness of augmenting BLEU, METEOR, ROUGE-L, CIDEr, and BERTScorewith IMAGINE similarities and BERTtext similarity on three data-to-text generation datasets. They-axis shows the Pearson correlation with human judgments.
Figure 8: Case studies for data-to-text generation. Ref: the reference text. Hyp: the generated textcandidate. We report the metric scores and the human score for the reported pair of (Ref, Hyp).
Figure 9: (a) The intra-group pairwise visual similarity distributions for images generated by dVAE,BigGAN, and VQGAN. The plot shows the three quartile values and the extreme values. (b) Thescore distributions histplot of IMAGINE, BERTtext and BERTScore used in our experiments. Allfour metrics range between [-1, 1].
Figure 10: Groups of images generated by ImaginE with different image genrative backbones withrandom initializations. The image generative backbones are dVAE, BigGAN and VQGAN.
Figure 11:	More examples for the machine translation task on WMT'19. Src: the German text to betranslated. Ref: the reference translation. Hyp: the generated translation candidate.
Figure 12:	More examples for the machine translation task on IWSLTâ€™14. Src: the German text tobe translated. Ref: the reference translation. Hyp: the generated translation candidate.
Figure 13:	More examples for the abstractive text summarization task on DUC2004. Src: the textto be summarized. Ref: the reference summary. Hyp: the generated summary candidate.
Figure 14:	More examples for the abstractive text summarization task on GigaWord. Src: the textto be summarized. Ref: the reference summary. Hyp: the generated summary candidate.
Figure 15:	More examples for the data-to-text task on WebNLG. Ref: the reference text. Hyp: thegenerated text candidate.
Figure 16:	More examples for the data-to-text task on E2ENLG. Ref: the reference text. Hyp: thegenerated text candidate.
Figure 17:	More examples for the data-to-text task on WikiBioNLG. Ref: the reference text. Hyp:the generated text candidate.
