Figure 1: The framework of TransTCN. The input of TransTCN is a series of timing signals fromthe input embedding layer or features from the prior block. The downstream task can be the nexttime value of the prediction time series, such as prediction of word level or character level, or thenoting prediction of a music.
Figure 2:	The models and setups of the three ablation experiments. (a) The vanilla TCN withoutthe two branches proposed in this paper. (b) The right branch in the dark area is the causal-dilatedresidual connection branch. (c) The left branch in the dark area is the global attention branch.
Figure 3:	The convergence process of training TransTCN and TCN on different datasets.
Figure 4:	The convergence process of training TransTCN and TransTCN without two respectivebranches on different datasets.
Figure 5:	The convergence process of training TransTCN and TransTCN with a global attentionbranch of convolution after attention.
Figure 6:	The convergence process of training TransTCN and TransTCN with a global attentionbranch of one convolution layer.
