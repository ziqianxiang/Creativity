Figure 1: Illustration of the ASR representa-tion. Q1 selects the translational componentof an action, Q2 selects the rotational com-ponent.
Figure 2: Equivariance relationsexpressed by Equation 7 and Equa-tion 8.
Figure 3: (a), (b) Baselines that do not use image augmentation. (c) (d) Image augmentation base-lines. (a) and (c) show learning curves as a running average over the last 150 training grasps. (b) and(d) show average near-greedy performance of 1000 validation grasps performed every 150 trainingsteps.
Figure 4: The Pybullet simulationenvironment.
Figure 5: Ablation studyof our method. The figureshows validation results. Wezoomed in the plot after the750th grasp.
Figure 7: (a) Learning curves from 500-grasp experiment. (b) Learning curves from 1000-graspexperiment. All curves are averaged over 3 runs.
Figure 6: Robot setup.
Figure 8: The train/test object sets. Objects need to be graspable of the gripper at any configuration(smaller than the gripper open width and has enough height), and need be able been captured by thedepth camera (no transparent nor has thing wall).
Figure 9: The neural network architecture of q1 and q2 . R means regular representation, T meantrivial representation, Q means quotient representation. q1 network is in D4 group . q2 network in500-grasp training is in C16/C2 group, in 1000-grasp training is in C32/C2 group.
