Figure 1: Example of two typical scenarios using pre-training. Regarding the true label, the fine-tunedmodel obtains higher confidence on original input yet lower confidence on adversarial input than thestandard model.
Figure 2: Example images of Pets, NICO, Flowers, Cars, Food, CIFAR10 and Alphabet, respectively.
Figure 3: The CCA similarities between different models, which is normalized to [0, 100].
Figure 4: Visualization of UAP for fine-tuned and standard models on Alphabet: UAPs with differentattacking letter classes.
Figure 5: UAP attack results: (a) Using UAP of fine-tuned model and standard model to attackthemselves at different training batches (on Alphabet). (b) Using UAP of pre-trained model to attackthe fine-tuned model and standard model (on other datasets).
Figure 6: The MMD distance between source dataset and target dataset v.s. DR of fine-tuned model.
Figure 7: The performance of fine-tuned model on CIFAR10 dataset using ADAM optimizer.
Figure 8: The performance of fine-tuned model on CIFAR10 dataset using SGD optimizer.
Figure 9:	The performance of fine-tuned model on Pets dataset using ADAM optimizer.
Figure 10:	The performance of fine-tuned model on Pets dataset using SGD optimizer.
Figure 11: Illustration of the ResNet-18. The output of Layer1 is the corresponding bottom-layerfeature, the output of Layer4 is the corresponding all-layer feature.
Figure 12:	The CCA similarities between different models, which is normalized to [0, 100].
Figure 13:	The analytical results on model capacity and task difficulty. The top three figures are theanalytical results about model capacity, and the bottom three figures are the analytical results abouttask complexity.
