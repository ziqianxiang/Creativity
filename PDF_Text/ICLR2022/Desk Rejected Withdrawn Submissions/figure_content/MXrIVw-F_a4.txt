Figure 1: Normalized memory vs. test accuracy of FLOAT with existing state-of-the-art OAT for(a) ResNet34, (b) WRN16-8, and (c) WRN40-2, respectively. CA and RA represent clean-imageclassification accuracy and robust accuracy (accuracy on adversarial images), respectively. For eachdataset we normalized the memory requirement with the maximum model memory needed for that.
Figure 2: Comparison of a conditional layer between (a) existing FiLM based approach in OAT and(b) proposed approach in FLOAT.
Figure 3:malizationNote that the standard deviation (σl) of the noise matchesthat of its weight tensor. For λ = 0 and 1, we obtain theoriginal weight tensor or a noisy variant, respectively.
Figure 4: Post-training modelperformance on both clean andgradient-based attack-generated ad-versarial images, with differentnoise re-scaling factor λn .
Figure 5: Modified conditional layer ofFLOAT to support dynamic complexityswitch in FLOATS.
Figure 6: Performance of FLOAT on (a) CIFAR-10, (b) CIFAR-100, (c) Tiny-ImageNet, (d) SVHN,and (e) STL10 with various λn values sampled from Sλn for two different λth for BNC to BNAswitching. The numbers in the bracket corresponds to (CA, RA) for the boundary conditions ofλ = 0 and λ = 1. λn varies from largest to smallest value from top-left to bottom-right point.
Figure 7: Performance comparison of FLOAT with OAT and PGD-AT generated models on (a)CIFAR10, (b) SVHN, and (c) STL10. λ varies from largest to smallest value in Sλ for the pointsfrom top-left to bottom-right.
Figure 8: Comparison of FLOAT with OAT and PGD-AT in terms of (a) normalized training timeper epoch and (b) model parameter storage (neglecting the storage cost for the BN and α). Notehere, PGD-AT:1T yields 1 model for a specific λ choice.
Figure 9: Performance comparison of FLOATS with OATS on slimming-factor of (a) 1.0 and (b)0.5. We used ResNet34 on CIFAR-10 to evaluate the performance. λ varies from largest to smallestvalue in Sλ for the points from top-left to bottom-right.
Figure 10: Performance comparison of FLOAT with OAT on (a) PGD20 and (b) FGSM attackgenerated images. We used WRN16-8 on SVHN to evaluate the performance. λ varies from largestto smallest value in Sλ for the points from top-left to bottom-right.
Figure 11: Performance compari-son on autoattack with ResNet34 onCIFAR-10.
Figure 12: Trained noise scaling factor value (layer-wise) for (a) ResNet34 on CIFAR-10, (b)ResNet34 on CIFAR-100, and (c) WRN40-2 on STL10.
Figure 13: Comparison of trade-off between accuracy and robustness of FLOAT, OAT, and PGD-AT.
Figure 14: Performance comparison on CW attack with ResNet34 on CIFAR-10.
Figure 15: Comparison of per epoch normalized training time between FLOAT and OAT for differ-ent number of OAT training λs, on (a) CIFAR-10, (b) SVHN, and (c) STL10.
