Figure 1: Causal graph explanationfor decoupling spurious feature andtarget feature with randomization. Sis the spurious feature and T is thetarget feature. L is the original labeland Y is the correctness of the pre-dicted label.
Figure 2: Sensitivity of four NLP models to eight spurious features, as a function of injection prob-ability.
Figure 3: Linear regression plots of sensitivity vs. robustness vs. post data augmentation ∆ againstspurious features. Each point in the plots represents a model-feature pair. We define “avg sensitivity”as log AUC of the corresponding curve in Figure 2 (Equation 8), “robustness” as the performancedrop on perturbed test set (Equation 9) and “post aug △” as the performance boost on perturbed testset (Equation 10). P is Spearman correlation. * indicates high significance (p-value < 0.001).
Figure 4: An example sentence injected with different spurious features.
