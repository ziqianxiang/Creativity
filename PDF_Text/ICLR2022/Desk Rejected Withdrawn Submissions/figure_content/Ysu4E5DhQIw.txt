Figure 1: Illustration of the fast encoder (left) and slow classifier (right) based semantic code searchapproaches (at inference stage). With the encoder based approach, we independently computerepresentations of the NL query and candidate code sequences. The code snippet with representationnearest to the query vector is then returned as the search result. With the classifier based approach,we jointly process the query with each code sequence to predict the probability of the code matchingthe query description. The code sequence corresponding to the highest classifier confidence score isthen returned as the search result.
Figure 2: Overview of the speed versus performancetrade-off of current code search approaches. Areasof the circles here are proportional to model sizes.
Figure 3: CasCode: Our proposed cascadedscheme for semantic code search. At thetop, the transformer encoder independentlyprocesses the query Xi and the code snippetsin the fast retrieval stage. The top Kcandidates (based on the nearest neighborlookup) from this stage are passed on to thesecond stage, where a transformer classifierjointly processes the query sequence witheach of the filtered candidates to predict theprobability of their semantics matching. Thesecond stage classifiers are thus acceleratedfor the code retrieval task by the first stage ofencoders.
Figure 4: Mean reciprocal ranking (MRR) atdifferent values of K over the validation set ofCodeSearchNet Husain et al. (2019) when using afinetuned CodeBERT (slow) binary classifier (matchor not) for text-code retrieval.
Figure 5: Recall at different values of K over thevalidation set of CodeSearchNet Husain et al. (2019)when using a finetuned CodeBERT encoder (fast) fortext-code retrieval.
Figure 6: Recall @ K = {1, 2, 5, 8, 10} with the fast encoder and CasCode (shared and separate)methods on the test set queries of CodeSearchNet dataset.
