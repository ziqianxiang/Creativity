Figure 1: Distinctive properties of the proposedmethod. The performance of deep neural net-works (DNNs) tends to improve exponentially asthe amount of data increases. However, when theamount of data is small, DNNs fail to achievegeneralized performance during the test phase be-cause they are typically overfitted to the trainingdataset. In contrast, shallow neural networks con-verge quickly and are robust to overfitting. How-ever, their performance reaches a non-optimal sat-uration point early, no matter how much more datathe algorithms use. The performance of the pro-posed method follows the shaded line without sig-nificant performance degradation.
Figure 2: The proposed anytime neural processes (ATNP) framework includes neural (CNPs) and Gaussian(GPs) processes with gate networks. Inputs are shared among the components and each CNPs and GPs esti-mates factorized predictive distributions. The gate networks controls the importance Gk for each estimate andgenerates aggregated predictive distributions.
Figure 3: Quantitative ATNPs framework results withrespect to training iterations. (a) Target NLL given ob-servations. (b) Mixing weights for each expert esti-mated by the gate network.
Figure 4: Comparison of the ATNPs with the baselinemodels. (a) Target NLL and (b) L2 for the mean esti-mates.
Figure 5: Quantitative results with respect to iter-ation for the proposed gate network with variouskernel functions and Gumbel-softmax estimator.
Figure 6: Qualitative results on both MNIST andCelebA datasets. For each image, first and lastcolumns refer to context inputs and ground truthsrespectively. Each row shows how the predictionon full target pixels evolves against training itera-tions.
