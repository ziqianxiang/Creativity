Figure 1: Temporal Augmentations. Each row demonstrate the effect of an augmentation on the rawwaveform, mel-spectrogram, and video frames, respectively. The first row, represent the originalvideo with its respective audio without any transformation applied.
Figure 2: Illustration of self-supervised pre-training pipeline. Given a video x, we sample 2 clipsusing monotonically decreasing probability distribution, followed by augmenting each stream withdomain specific augmentations and temporal augmentations.
Figure 3: Top-1 accuracy of linear classifiers on representations pre-trained with contrastive loss onAVE dataset using one or pair of spatio-temporal augmentations for 500 epochs. The bottom-rightelement is a model trained with no spatio-temporal augmentation. The last row/column representsthe average of each row/column, respectively. Diagonal of the matrix demonstrates the result whenonly one corresponding spatio-temporal augmentation applied during pre-training.
