Figure 1: Illustration of Palette’s performance on four image-to-image translation tasks.
Figure 2: Illustration of colorization methods on ImageNet validation images. Baselines: '(Guadarrama et al.,2017), ^(Kumar et al., 2021), and our own strong regression baseline. Figure C.2 shows more samples.
Figure 3: Comparison of inpainting methods on object removal. Baselines: ^Photoshop's Content-aware Fillbuilt on PatchMatch (Barnes etal.,2009), *(Yu etal.,2019), and 计(Yi etal.,2020). Figure C.4 has more samples.
Figure 4: Image uncropping results on Places2 validation images. Baselines: BoUndlesst (TeterWak et al., 2019)and InfinityGANtt (Lin et al., 2021) trained on a scenery subset of Places2. Figure C.7 shows more samples.
Figure 5: Visual comparison for JPEG decompression on ImageNet validation images.
Figure 6:	Diversity of Palette outputs on colorization (top), inpainting (middle) and uncropping (bottom). FiguresC.3, C.5, C.8 and C.9 have more samples.
Figure 7:	Distribution of pairwise multi-scale SSIM for Colorization (left) and Inpainting (right). FigureTable 6 indicates that multi-task Palette outperforms the task-specific model on JPEG decompression,it lags behind task-specific Palette models on inpainting and colorization. Due to compute limitations,we currently train multi-task Palette for the same number of training steps as task-specific models.
