Figure 1: Example images from benchmark object recognition data set ImageNet (a), benchmarkscene recognition data set Places365 (b), and fine-grained data set Caltech-UCSD Birds-200-2011(c and d).
Figure 2: Results on scenery image using low and high pass filter.
Figure 3: Illustration of low and high pass filters. In figure (b) and (c), the mask (black region) de-notes information removed by corresponding filters; the length of red line denotes the correspondingfilter size.
Figure 4: Top-1 accuracy (%) on Place365 and ImageNet data sets using low pass filters (a) and highpass filters (b). The x-axis denotes the size of the corresponding filters.
Figure 5: The schema of down-sample component in ResNet and Lossless Pooling module fromthe view of spatial dimension. (a) Down-sample component in ResNet from the view of spatialdimension. During the down-sampling process, 3/4 of the spatial information are discarded and thenumber of channels is doubled. (b) Lossless Pooling module from the view of spatial dimension.
