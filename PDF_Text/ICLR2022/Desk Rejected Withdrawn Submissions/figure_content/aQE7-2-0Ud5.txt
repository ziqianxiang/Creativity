Figure 1: The top row shows a sample image (left column), one of intermediate features (middlecolumn) and the final prediction (right column), while the middle and bottom rows provide resultswith detail enhancement and structure (or semantic) enhancement, respectively.
Figure 2: The architectures of FEM-D (left) andFEM-S (right) are dePicted, resPectively. The oP-erations including batch normalization and ReLUactivation are omitted for simPlification.
Figure 3: Our architecture contains a backbone network (e.g. ResNet (He et al., 2016)), a pyramidpooling module (PPM) (Zhao et al., 2017), and two information flows, i.e. detail flow and semanticflow. Both of the two flows are composed of FEMs with different enhancement purposes.
Figure 4: Left: comparison of segmentation results between baseline^ and w/ DF on the Cityscapesvalidation set. Right: comparison of segmentation results between baseline↑ and w/ SF on theCityscapes validation set. Best view in color and zoom in.
Figure 5: Comparison of segmentation results be-tween baseline↑ and FENet on the Cityscapes val-idation set. Best view in color and zoom in.
Figure 6: Visualization of features maps. From left to right: input images, original features, featuresafter executing DF, and features after executing SF, respectively.
Figure 7: Visual comparison with state-of-the-art methods.
