Figure 1: A simplified goal-predefined combinatorial problem in training and inference. Whenrandom moves are probabilistically biased toward optimal moves, a model learns this distributionand uses it for inference. Lef t: During training, random moves {a, b, c} can occur at every nodeby the equal probability of 1/3. If an unknown path consisting of these duplicable moves connectsnodes G (goal) and S (scramble), the optimal (shortest) path (b, b) is most likely of all the pathspossible, followed by the second optimal three-move paths and then four-move paths. At all nodes,adding up the probabilities of all the possible paths, a move in more optimal paths turns out tohave a higher probability of being in the unknown path. Thus, the model can learn the probabilitydistributions merely by observing a sufficient number of random moves derived from G. Right:Using the learned probability distributions, the model can infer reverse paths from node S to theunknown goal G consisting of the inverse moves {a0, b0 , c0}. Since the moves in the shortest pathare learned most frequent of all paths, in this instance, the move b0 is predicted to be more optimalthan a0 and c0 at node S and its subsequent node.
Figure 2: An illustrated scheme of the proposed self-supervised learning on Rubik’s Cube. Applyinga sequence of random moves [F’ U R R D’ B F L] to Rubik’s Cube, the DNN receives theone-hot representation of the scrambled state as input and predicts the last move in the scramble.
Figure 3: Solution length versus number of nodes by three methods: Optimal solver, DeepCubeA,and ours. Each dot represents the number of moves in a solution and the number of nodes expandedduring a search. For a clear comparison, we scatter plot the result of solutions by 1.0M modelwith the beam width of 215 only. Frequency plots are separately shown for both dimensions, andThe pink dashed line shows the trajectory of mean coordinates (cross markers) scaling up along thebeam widths for each model. Some crosses are annotated by their corresponding beam widths.
Figure 4: Calculation time versus solution length by three methods. The scatterplot on the left showsthe actual time taken, and the right one shows the time normalized by per-node computation time.
Figure 5: Associations between the number of nodes and calculation time for three different meth-ods. Lef t: Strong correlations between the two metrics in log scales. Right: Distributions ofcomputation time per node for the optimal solver, DeepCubeA, and ours (1.0M model).
Figure 6: Solution length versus number of nodes generated during solution search.
