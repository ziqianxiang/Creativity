Figure 1: Supervised KL div. method (Martinez et al., 2020; LiU et al., 2020), proposed BSSL (usesno supervision), and linear evaluation accuracy of ablated models on ImageNet. Shen et al. (2021)tuned MoCov2 for binary networks and We show it (‘Tuned MoCov2, in (c)) as a reference. Ourbaseline (①)already outperforms it by a noticeable margin and gain by the full model (+5.5%) issignificant, given that the downstream task is on a large scale dataset, ImageNet.
Figure 2: Gradient magnitude for the binary classifier (a) and the binary feature extractor (b) duringearly training with and without LFS. With only KL, the gradients of the classifier is extremelylarge and this carries over to the feature extractor. Additionally, we observe intermediate spikes forboth the classifier and the feature extractor. The addition of LFS significantly lowers the gradientmagnitudes of the classifier as well as the feature extractor at early iterations. Additionally, thesurges in gradient magnitudes are also subdued.
Figure 3: Gradient magnitude of (a) binary classifier and (b) the binary feature extractor duringearly training for various choices of LFS such as the cosine, L1, and L2 distances. Both L1 and L2distances show very high gradients at the beginning in the classifier, especially L2 . Moreover, L1and L2 distances exhibit potential gradient explosions in the feature extractor. The proposed cosinedistance shows none of these trends that harm training efficacy.
Figure 4: Plots for the various λ(t) compared in Table 7 are shown.
