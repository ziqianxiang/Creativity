Figure 1: (a) Example of a challenging bag; (b) MI-AL performance on instance-level predictions;(c)-(e) Prediction scores of instances in the bag in different MI-AL steps.
Figure 2: MI-AL performance comparison50.047.5⅛ 45.0Ξ42.540.0・91SISI76.5-76.0-H 5.
Figure 3: EffectiveneSS of P-F active SamPlingEvaluation metric and model training. To aSSeSS the model Performance, We rePort the inStance-level mean average PreciSion (mAP) Score, Which SummarizeS a PreciSion-recall curve aS a Weightedmean of PreciSion achieved at each threShold, With the increaSe in recall from the PreviouS threSholdaS the Weight. mAP exPlicitly PlaceS much Stronger emPhaSiS on the correctneSS of the feW toPranked inStanceS than other metricS (e.g., AUC) (Su et al., 2015). ThiS makeS it Particularly Suitablefor inStance Prediction evaluation aS a Small SubSet of inStanceS With the higheSt Prediction ScoreSWill eventually be identified aS PoSitive for further inSPection (by human exPertS) With the reSt beingignored. For Cifar10, Cifar100, and PaScal VOC dataSetS, We extract the viSual featureS from theSecond-to-the laSt layer of a VGG16 netWork Pre-trained uSing the imagenet dataSet, yielding a4,096 dimenSional feature vector for each inStance. For 20NeWSGrouP, We uSe the available 200-dimenSional feature vector. In termS of netWork architecture, We uSe a 3-layer FC neural netWork.
Figure 4: Impact of key model parameters: (a-b) Pascal VOC; (c-d) Cifar100(a) Sample bag B2(b) Sample bag B3Bag	P-F	F-EntropyBBΓ	~L0O~	0.04-BF	0.53	0.07-BF	~0.64~	0.55	一~BT^	Shadow of a bird	~B2-	Side view of a bird	~B3-	Part of a bird	(c) mAP scores(d) Percentage of TP bagsFigure 5: (a-b) Poorly explored bags in Pascal VOC; (b) Description of these bags and their mAPscores; (d) Additional true positive bags successfully explored by P-F samplingAblation Study. Figure 4 demonstrates the impact of λ and β . In particular, λ can be set according tothe imbalanced instance distribution within bags, where a larger λ corresponds to a higher imbalanceddistribution. We vary λ in [10-10, 1] and since most bags in the MIL setting are highly imbalanced,λ ∈ [10-06, 10-02] gives very good performance in general. Figures 4 (b) and (d) show that λ = 0.01clearly outperforms too large (or small) λ values. As for β, placing less emphasis on an instancelevel loss (small β), we may not fully leverage labels of queried instances. Meanwhile, with too
Figure 5: (a-b) Poorly explored bags in Pascal VOC; (b) Description of these bags and their mAPscores; (d) Additional true positive bags successfully explored by P-F samplingAblation Study. Figure 4 demonstrates the impact of λ and β . In particular, λ can be set according tothe imbalanced instance distribution within bags, where a larger λ corresponds to a higher imbalanceddistribution. We vary λ in [10-10, 1] and since most bags in the MIL setting are highly imbalanced,λ ∈ [10-06, 10-02] gives very good performance in general. Figures 4 (b) and (d) show that λ = 0.01clearly outperforms too large (or small) λ values. As for β, placing less emphasis on an instancelevel loss (small β), we may not fully leverage labels of queried instances. Meanwhile, with toomuch emphasis on the instance level loss (large β), the model overly focuses on the limited queriedinstances with less attention to the bag labels. Therefore, a good balance (with β = 1) results in anoptimal performance, shown in (a) and (c). More ablation study results are provided in Appendix E.
Figure 6: Example of challenging bags from different topics in 20NewsGrouptheoretical equivalence to KL-divergence and present the result in Theorem 2. We then provide thedetailed proofs for both theorems.
Figure 7: Impact of key model parameters: (a-b) Cifar10; (c-d) 20NewsGroupE Additional Experimental ResultsIn this section, we first give a detailed description of the datasets. We then present additional ablationstudy results that complement the ones presented in the main paper. Finally, we demonstrate somequalitative examples where our approach is able to sample the true positive instance from the bagcontaining outlier but Maximum-Entropy can not.
Figure 9: ImPact of hyPerParameter kFigure 8: MI-AL Performance With standard deviation(c) Cifar100(or Poorly) leveraging annotated instances. Therefore, a good balance betWeen the bag-level andinstance-level losses achieves the best result, as shoWn in Figures 7 (a) and (c).
Figure 8: MI-AL Performance With standard deviation(c) Cifar100(or Poorly) leveraging annotated instances. Therefore, a good balance betWeen the bag-level andinstance-level losses achieves the best result, as shoWn in Figures 7 (a) and (c).
