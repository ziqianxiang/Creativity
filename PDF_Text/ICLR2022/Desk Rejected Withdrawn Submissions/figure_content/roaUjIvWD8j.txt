Figure 1: An overview of our experimental setup. 1,000 low-resolution images are fed through eachof 124 SISR models to produce a dataset of 124,000 super-resolved images. We then train our modelparsing and attribution classifiers on this dataset.
Figure 2: T-SNE visualizations of of super-resolved image feature embeddings. Figure 2a shows thefeatures of images upscaled by the 108 custom-trained models, grouped by scale and loss. Figure2b shows feature embeddings for the pretrained SISR model images as encoded by the pretrainedmodel attribution classifier (left) and the custom model attribution classifier (right). Classificationaccuracies associated with the models in each plot are in the lower-left corner.
Figure 3: Distinguishing between models which differ only by seed.
Figure 4: Parser predictions for the pre-trained models. For example, out of the 100test images for SPSR, 66 were predicted tocome from a model with 2x scale, 34 from4x. Actual model hyperparameter values arein green boxes. Some models use losses andarchitectures which aren’t in the parsers’ setof class labels, so none of their columns areinscribed in green.
