Figure 1: The deep delta encoding pipeline for lidar range image compression. Given a lidarrange image, We first quantize the attribute values and then run inference of the predictive modelon the quantized range image to derive residuals. Finally We use entropy encoders to compress theresiduals to a bitstream.
Figure 2: The deep intra-frame prediction model. Given a range image patch with quantizedattribute values, We associate pixel values With their relative laser shot angles (elevation and azimuth)to the to-be-predicted pixel (on the bottom right). The pixels with relative angles and depth valuescan be considered a 3D point cloud in the (azimuth, elevation, depth) space. Our predictor then takesthis mini point cloud and predict the attribute (depth in this example) of the bottom right pixel.
Figure 3: Evaluation of the compression methods with geometric metrics. Left: symmetircChamfer distance v.s. bit per point (bbp) on the WOD data; Middle: PSNR v.s. bpp on the WODdata; Right: max Chamfer distnace v.s. bpp on the KITTI dataset. We compare our deep deltaencoding compressor with three strong non-learning baselines: G-PCC, Draco and PNG (on WOD)and two prior art deep models: OctSqueeze and MUSCLE (on KITTI). At a certain bitrate, a lowerthe Chamfer distance or the higher the PSNR means better reconstruction quality.
Figure 4: Impact of lidar data compression to 3D object detection quality. Using a pre-trainedPointPillars detector on the Waymo Open Dataset train set on the raw point cloud (with no compres-sion), we evaluate the detector with compressed point clouds on the validation set.
Figure 5: Visualization of reconstructed point clouds, colored by per point Chamfer distance.
Figure 6: Distribution of residuals at different quantization precisions. Proposed deep predictionmodel is able to accurately model the joint distributions of range image pixel attributes, resulting ina concentrated distribution of residuals with low entropy.
