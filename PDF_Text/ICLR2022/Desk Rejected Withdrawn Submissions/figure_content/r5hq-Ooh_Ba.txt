Figure 1: Graphical explanations of the “Ex-clusion Method” for classification task. Foran image, the proposed method excludes somewrong classes via different images of the sameclass, so as to eliminate the wrong answers.
Figure 2: Diagram of the proposed MutexMatch. Given a batch of unlabeled samples, TPC P usestheir weakly-augmented variants to generate pseudo-labels. Then we adopt the classes with thelowest confidence as the complementary labels to train TNC N separately. Meanwhile, TPC andTNC are used for mutex-based consistency regularization in the high and low-confidence portion ofTPC’s predictions respectively. f denotes output features and p, r denote predictions of TPC andTNC. Superscripts w and s represent corresponding outputs for the weakly-augmented variant andstrongly-augmented variant, respectively.
Figure 3: Training of TNCTPC, it is much easier to obtain correct labels for TNC. Thus we exploit TNC to provide moreguidance information on unlabeled data. We then propose a mutex-based prediction consistency onTPC and TNC to make full use of unlabeled data, which is described in Section 3.3. The high-leveltraining process of TNC is shown in Figure 3. Unlike the standard complementary label genera-tions (Ishida et al., 2017; Yu et al., 2018), we use the class with the lowest confidence in TPC’spredictions as the complementary label to train TNC. The training loss Lsep can be calculated asLsep1 μB-B∑H (argmin(P (θ(xW )),N(θ(xW))),μ n=1(3)where θ represents that θ is considered constant for the generation of this loss, i.e., stop back-propagating gradients. Since our downstream task is to accurately classify images, we adopt suchgradient-blocking operation to ensure that the feature extractor will not be affected by the trainingof TNC. We extensively investigate the effectiveness of TNC in Section 4.3.
Figure 4: The rate (%) of each class (column in heat map) in the pseudo-label and complementarypseudo-label outputted by TPC and TNC respectively corresponding to each class (row in heat map)in CIFAR-10. The darker, the higher. Results are reported in a run on CIFAR-10 with 40 labels.
Figure 5: Accuracy of pseudo-label and com-plementary label on CIFAR-10 with differentamount of labeled data.
Figure 6: The learning curve of ablation study on SVHN. The x-axis represents the training epochand y-axis represents the test accuracy in (a) and the pseudo-label accuracy in (b).
Figure 7: The learning curve of ablation study on CIFAR-10 with 40 labels. The x-axis representsthe training epoch and the y-axis represents the test accuracy in (a), the pseudo-label accuracy in (b),and the complementary pseudo-label accuracy in (c).
Figure 8: Test accuracy on CIFAR-10 in single run with various amount of labels using TNC to par-ticipate test phase. The x-axis represents confidence threshold T and y-axis represents test accuracy.
Figure 9:	Accuracy on CIFAR-10 with 40 la-bels and various λsep, λn .
Figure 10: The correct component in prediction vector is class 1.
Figure 11: (a) Average probability of each component in prediction vector of automobile images.
Figure 12: The learning curve of ablation study on SVHN. The x-axis represents the training epochand y-axis represents the test accuracy in (a), (c) and the pseudo-label accuracy in (b), (d).
