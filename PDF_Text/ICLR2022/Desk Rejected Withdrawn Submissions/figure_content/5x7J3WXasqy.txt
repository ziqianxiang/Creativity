Figure 1: Model architecture for our method in autonomous driving(IVRs). The detailed features are described in Subsection A.5 in Appendix. All types of informa-tion include two-dimensional global positions such that the relative information of all feature typesis expected to be effectively encoded in our model. Our model consists of four distinctive mod-ules: inter-vehicle relation encoder, multi-modal information encoder, policy networks, and valuenetworks. The overall structure of the modules is described in Figure 1. Actor and critic are im-plemented with fully-connected layers, and other modules are explained in Subsections below. Wepractically employed double-critics for stable value learning, which is proposed for deep Q networks(van Hasselt et al., 2016).
Figure 2: Training evolution of our methods and a baseline on three types of roadsWe compare various structures of our algorithm to a baseline HRL method with domain knowledgeabout sub-goals. Figure 2 shows the performance of agents on the roads of four straight lanes (left),two curved lanes (center), and two lanes merging into one (right). During the joint training of all7Under review as a conference paper at ICLR 2022vehicle agents using each method, we plotted moving average of the sum of returns for each episodewith initiation to 0 and alpha = 0.1.
Figure 3: Trajectories of vehicles on two curved lanesWe qualitatively examined the traveling trajectory of vehicle agents on curved two lanes in ourmethod against that of the baseline HRL method. General human tactics for the agent is to takethe shortest possible path, which could be a straight line in the optimal environment. The agentshould consider collision avoidance, travel time reduction, and compliance with speed limits. In ourexperiment, two vehicle agents start to drive from the left end of each lane almost simultaneouslywith slight randomness. When an inter-vehicle region on the shortest possible path is available, thenthe agent will move on to occupy the region. Figure 3 shows agents using our method. The agent ontwo curved lane tried to take the inner lane at first, and then the outer lane in the end. The red agenton merging lane wait until the green agents pass the lane in the middle, and follow the green agent.
Figure 4: Three types of roads for our highway driving environmentFigure 5: A position in a quadrilateral represented in normalized quadrilateral coordinate frameratio u, which are the interpolation of (xfl , yfl) and (xrl , yrl ) with ratio v and the interpolation of(xfr , yfr) and (xrr , yrr) with ratio v, respectively. Figure 5 shows the positions on an arbitraryquadrilateral represented in both global coordinate frame and normalized quadrilateral coordinateframe. The transformation from normalized position (u, v) to global position (x, y) is easily doneby the two steps of interpolation, while transformation from (x, y) to (u, v) is performed by solvingthe following equations. For x axis,xvl = xrl + v (xfl - xrl)= xrl + vdl ,(9)xvrxrr + v(xfr - xrr)= xrr + vdr ,(10)12Under review as a conference paper at ICLR 2022u(X - Xvl)(xvr - xvl )
Figure 5: A position in a quadrilateral represented in normalized quadrilateral coordinate frameratio u, which are the interpolation of (xfl , yfl) and (xrl , yrl ) with ratio v and the interpolation of(xfr , yfr) and (xrr , yrr) with ratio v, respectively. Figure 5 shows the positions on an arbitraryquadrilateral represented in both global coordinate frame and normalized quadrilateral coordinateframe. The transformation from normalized position (u, v) to global position (x, y) is easily doneby the two steps of interpolation, while transformation from (x, y) to (u, v) is performed by solvingthe following equations. For x axis,xvl = xrl + v (xfl - xrl)= xrl + vdl ,(9)xvrxrr + v(xfr - xrr)= xrr + vdr ,(10)12Under review as a conference paper at ICLR 2022u(X - Xvl)(xvr - xvl )X - (Xrl + Vdl)
Figure 6: An exampling for understanding the hashing algorithm of the quadrilaterals of lanesLanes are static features with respect to a global reference point. Thus, if all lanes can be approxi-mated before driving, or parts of lanes ahead of ego vehicle can be approximated before they comein the view range, the approximated parts can be used repeatedly during driving. In addition, ifthe quadrilaterals that approximate the lanes can be hashed, the time to search for the quadrilateralinside which the center or a corner position of a vehicle exists can be reduced from O(n) to O(1)where n is the number of quadrilaterals to be searched for. Thus, we devise a hashing algorithm that13Under review as a conference paper at ICLR 2022Table 1: Candidate behaviors with their available IVRs to pay mind to and the outline IVRBehavioral mode	Set of available IVRs to pay mind to	Outline IVRstay in current IVR	{current IVR}, or {front IVR} or {rear IVR} if a vehicle invades the lane of ego	current IVRmaneuver to the other in lane (optionally selectable)	{front IVR} if ego is in rear IVR {rear IVR} if ego is in front IVR	IVR in mindpay mind to the left	{IVRs on left lane in mind} if the lane exists, otherwise 0	current IVRmaneuver to the left	{IVRs on left lane ahead in mind} if the lane exists, otherwise 0	IVR in mindpay mind to the right	{IVRs on right lane in mind} if the lane exists, otherwise 0	current IVRmaneuver to the right	{IVRs on right lane ahead in mind} if the lane exists, otherwise 0	IVR in mindcan quickly search for quadrilaterals to which a given position can belong. Figure 6 is an examplefor understanding the hashing algorithm. Our hash function can hash a position in two-dimensionto a bin, which can be represented as a blue rectangle of the smallest possible unit size. To store
Figure 7: An example of inter-vehicle regions for the purple-colored vehicleAn inter-vehicle region (IVR) in a lane is defined as the region between the rear end NQC,nr = (qr, vr), and the front end NQC, nf = (qf, vf), bordered by surrounding vehi-cles or any end of the view range. Figure 7 shows an example of IVRs for the purple-colored vehicle. Given normalized positions of both ends, the featuring global positions,(po,ι,P0,r), (pι,ι,pι,r), ∙, (pn-i,i,Pn-i,r), (pn,i,PN,r), are acquired by sampling N times withuniform distance interval on the left and right sides along the progressing direction, where (p0,l, p0,r)and (pN,l, pN,r) are defined by nr and nf, respectively. By using the distance function A.2, the dis-tance between the rear and front Dtotal = D(l, nr, nf) is acquired, and from the rear, we can get thenext sample at the distance of Ds = Dtotal/(N - 1) in turn. Table 1 specifies candidate high-levelcommands of behaviors, the corresponding set of available IVRs to pay mind to, and the outlineIVR.
Figure 8: Range sensing of vehiclesapplicable as the long-term goal. For experiments, we simply define a long-term goal region as therectangular box (l, r, t, b) to deal with two types of goal regions, the region reached after the rightend of a random lane and all lanes. Including the goal reaching reward, four types of rewards andtheir definitions are as in Table 2.
