Figure 1: (a) Illustration of six image shifting variants out of the total T, as defined in Sec. 3.1. Agrid is shown over each image shift variant. In each variant, the grid represents a different divi-sion of the image to patches. Patches shown in light blue and red indicate two different patch-shifting variants. The color of the grid is indicative of the variant index. (b) The same six variantsare shown for the light blue (top) and red (bottom) patches in (a). The figure illustrates the sub-optimality of the fixed partition used in previous work. For example, the dogâ€™s left eye is fullycaptured only in the "orange partition" and the nose only in the "yellow partition". A fixed parti-tion would only capture one of those concepts.
Figure 2: Illustration of our local attention layer. Patch i is represented in blue; Variants of iare shown in different colors. All patches are first encoded using a convolutional layer, which,together with the positional encoding, results in a D dimensional embedding Ois for each patch iand variant s. Given Ois, a query embedding is generated as in Eq. 1. For each patch variant, a keyembedding is generated as in Eq. 2. Both the query and key embeddings are used to create Wiusing Eq. 3, a softmax probability vector indicating the importance of each patch variant. Finally,Wi is multiplied by the value embeddings (generated using Eq. 2 for all patch variants) as in Eq. 4,to generate the final output Ai.
