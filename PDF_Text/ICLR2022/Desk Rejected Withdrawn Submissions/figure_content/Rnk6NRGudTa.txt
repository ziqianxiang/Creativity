Figure 1: Shape of PSSiLU at various values of a and β. Left:β is fixed to 0.3 while α is varied. Right: α is fixed to 1 whileβ is varied. ReLU is given by the dotted black line. We cansee that α controls the curvature of the function near 0 while βcontrols the behavior on negative inputs.
Figure 2: Visualization of parametric activation functions at various values of parameter α.
Figure 3: Square robust accuracy and average minimum PGD radius for ResNet-18 models trainedon CIFAR-10 with various parameter α. Results are computed over 3 trials. Red points indicate themeasured PGD radius while blue points indicate the Square robust accuracy across models.
Figure 4: Square robust accuracy and averageminimum PGD radius for SSiLU at varied β forResNet-18 models trained on CIFAR-10. Resultsare computed over 3 trials.
Figure 5: Highest PGD train and test accuracy for ResNet-18 models. Train accuracy is measuredonly on CIFAR-10.
Figure 6: Learned shapes of PAFs across 11 models of various architectures (WRN-28-10, ResNet-18, VGG) trained using PGD adversarial training on various datasets (CIFAR-10, CIFAR-100, Ima-geNette). Each grey line represents the shape learned by a single model. The red line represents theaverage of the learned αs across all models. The dotted black line represents ReLU.
Figure 7: Learned shapes of activationfunctions across 11 models of variousarchitectures (WRN-28-10, ResNet-18,VGG) trained using PGD adversarialtraining on various datasets (CIFAR-10,CIFAR-100, ImageNette). Each greyline represents the shape learned by asingle model. The red line representsthe average of the learned αs and βsacross all models. The dotted black linerepresents ReLU.
Figure 8:	Square robust accuracy and average minimum PGD radius for WRN-28-10 models trainedon CIFAR-10 with various parameter α.
Figure 9:	Square robust accuracy and average minimum PGD radius for VGG-16 models trained onCIFAR-10 with various parameter α.
Figure 10:	Square robust accuracy and average minimum PGD radius for ResNet-18 models trainedon CIFAR-100 with various parameter α.
Figure 11: Square robust accuracy and average minimum PGD radius for ResNet-18 models trainedon ImageNette with various parameter α.
Figure 12: Square robust accuracy and average minimum PGD radius for ResNet-18 models trainedon CIFAR-10 with various parameter α for PReLU+ and PBLU activations. Errors bars are com-puted over 3 trials.
Figure 13: Square robust accuracy and average minimum PGD radius for VGG-16 models trainedCIFAR-10 with various parameter α for PReLU+ and PBLU activations.
Figure 14: Empirical Lipschitz constant of PReLU and PELU ResNet-18 models trained on CIFAR-10 at varied value of parameter α. Lower empirical Lipschitz constant suggests that the modeloutputs are more stable in the presence of perturbations. The trend in Empirical Lipschitz constantmatches the trends observed in PGD radius and Square robust accuracy.
Figure 15:	Square robust accuracy and average minimum PGD radius for PSSiLU across parameterβ for standard trained WRN-28-10 and VGG-16 architectures.
Figure 16:	Square robust accuracy and average minimum PGD radius for PSSiLU across parameterβ for standard trained ResNet-18 models on CIFAR-100.
Figure 17: Impact of regularization strength λ on β parameter on AutoAttack robust accuracy ofPGD adversarially trained ResNet-18 model.
Figure 18: Learned shapes of PReLU+ and ReBLU activation functions across all 11 models trainedusing PGD adversarial training. Each gray line represents the shape learned by a single model. Thered line represents the average of the learned αs across all models.
