Figure 1: In each step of the proposed algorithm, we regularize our model by forcing closeness of task targetlayer distribution (representing current information) and CW generator output distribution (representing pastinformation). This applies to both solving individual tasks as well as training the CW generator. Note that ourconstruction does not require extra memory to remember previous tasksâ€™ datasets. (The figure was producedusing diagrams.net software.)Figure 2: The figures demonstrate how CW-TaLaR works in the real world CL scenario. Blue dots representoutput produced on a target layer for samples from the first task wile orange dots represent output for samplesfrom the second task. In the first column, we present how output data look like after training the first task.
Figure 2: The figures demonstrate how CW-TaLaR works in the real world CL scenario. Blue dots representoutput produced on a target layer for samples from the first task wile orange dots represent output for samplesfrom the second task. In the first column, we present how output data look like after training the first task.
Figure 3: Comparison of average accuracy over currently completed tasks achieved by each method applied forSplit MNIST in three CL scenarios, calculated on validation dataset during the training process. (All resultswere additionally averaged over 10 runs.) Note that CW-TaLaR is superior to overcome forgetting in single-head scenarios.
Figure 4: Comparison of average accuracy over currently completed tasks achieved by each method applied forSplit CIFAR-10 in three CL scenarios, calculated on validation dataset during the training process. (All resultswere additionally averaged over 10 runs.) Note that scores for CW-TaLaR are comparable with those for SI andMAS.
Figure 5: Comparison of average accuracy over currently completed tasks achieved by each method appliedfor Permuted MNIST in IDL scenario, calculated on validation dataset during the training process. (All resultswere additionally averaged over 10 runs.) Note that CW-TaLaR is superior in learning new tasks or for relativelyshort term scenarios.
