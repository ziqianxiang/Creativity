Figure 1: Sparse rewards in the case of the Rubik’s cube. The state space is extremely large, butonly the final solved state has a non-zero reward, making the reward distribution extremely sparse.
Figure 2: Some applications of transformers in different fields of machine learning. For NLP, amachine translation pipeline is show, while for CV, the vision transformer (Dosovitskiy et al., 2020)pipeline is shown. The decision transformer (Chen et al., 2021) is shown for RL.
Figure 3: Representation of the rubik’s cube states. Examples of 3×3 and 4×4 are shown.
Figure 4: The training pipeline and principal blocks used in CubeTR. Starting from the solved state,the decision blocks are cascaded in reverse to get the ground truth for actions. In addition to Lact ,there are two more losses, Lrew and Lmov, that have not been shown in the diagram for clarity.
Figure 5: The inference pipeline used in CubeTR. Starting from an arbitrary unsolved state, newactions are predicted, and performed, leading to the solved state. Validate Action is a simple logicalmodule that validates if the pseudo reward is increasing and if it is not, replaces the predicted actionwith a random action.
