Figure 1: Given an image with nuisance factors, (a): invariant representation learning splits pre-dictive factors from all nuisance factors; (b): disentangled representation learning splits the knownnuisance factors but mixing predictive and unknown nuisance factors; (c): Our method splits allpredictive, known nuisance and unknown nuisance factors simultaneously.
Figure 2: Architecture of the model. Red box is the generation part and the blue box is the predictionpartdistinguish between the joint distribution of latent factors q(z) and multiplication of marginal distri-bution of every latent factor q(zi). By using the discriminator, FactorVAE finds a better trade-offbetween reconstruction quality and disentangled representation. Comparing to β-VAE, DIP-VAE(Kumar et al., 2018) adds another regularization D(qφ(z)∣∣p(z)) between the marginal distributionof latent factors qφ(z) = J qφ(z∣x)p(x)dx and the prior p(z) to further encourage disentangledrepresentation learning. D here can be any proper distance function. Chen et al. (2019) proposedβ-TCVAE which decomposed the DKL used in β-VAE into: total correlation, index-coded mutualinformation and dimension-wise KL divergence. During training, the quality of reconstruction anddisentanglement are controlled by three different hyper-parameters applied on those three regular-ization. To overcome the challenge proposed by Locatello et al. (2019), AdaVAE (Locatello et al.,2020a) purposely choose pairs of inputs as supervision signal to learn representation disentangle-ment. Besides, Locatello et al. (2020a) proved theoretically that under some assumptions, the idealrepresentation disentanglement can be achieved without compromise.
Figure 3: Disentanglement representation learning for known nuisance factors ZnkSelecting image pairs for training and latent factors assumptions: As mentioned by Higginset al. (2017), the true world simulator using generative factors to generate X can be modeled as:p(X|v, w) = Sim(v, w), where v is the generative factors and w is other confounding factors. In-spired by this, we choose pairs of image by randomly selecting some generative factors to be thesame and keeping the value of other generative factors to be random. As the image pair exam-ple in Figure 4b indicates, each image X has corresponding generative factors v, and the training4Under review as a conference paper at ICLR 2022(a) In early training stages, small number of latent fac-tors are swapped. the number of latent factors to beswapped increases gradually.
Figure 4: Two training strategies for learning known nuisance factors znk[3,1,3,1,0,7]	[3,1,3,1,5,7]Only one distinct generative factor[lt2t2t0f3t12]	[2,2,1,5,1,10]Multiple distinct generative factor(b) In early training stages, input pair with small num-ber of generative factors are chosen. The number ofgenerative factors increases gradually.
Figure 5: t-SNE visualization of zp and znu embeddings of Color-Rotation-MNIST images col-ored by rotation angle. As desired, the zp embedding does not encode rotation information, whichmigrates to znu .
Figure 6: Heat map visualization for Colored-MNIST dataset(a) latent factors change by chang-ing the color(b) latent factors change by chang-ing the angle(c) latent factors change by chang-ing the angleFigure 7: Heat map visualization for Rotation-Colored-MNIST dataset14Under review as a conference paper at ICLR 2022Figure 8: Reconstruction results of Colored-MNIST dataFurther, we visualize the heatmap of latent space change by giving the model with different inputs.
Figure 7: Heat map visualization for Rotation-Colored-MNIST dataset14Under review as a conference paper at ICLR 2022Figure 8: Reconstruction results of Colored-MNIST dataFurther, we visualize the heatmap of latent space change by giving the model with different inputs.
Figure 8: Reconstruction results of Colored-MNIST dataFurther, we visualize the heatmap of latent space change by giving the model with different inputs.
