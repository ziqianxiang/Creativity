Figure 1: Pruning filters of ResNet-50 on CIFAR-10. (Left) Pruning filters of ResNet-50 basedon different pruning heuristics, including `1 norm, `2 norm and FPGM (He et al., 2019). (Center)Experiments on fine-tuning epochs with different pruning ratios. (Right) Comparison of fine-tuning,rewinding and retraining from scratch with an uniform pruning ratio of 0.75.
Figure 2:	STD pruning spaces under cflops = {0.25, 0.1, 0.05, 0.02}. In the figure, we study threeSTD pruning spaces, including STD-0.1, STD-0.05 and STD-0.01 spaces. (Row 1) Accuracydrop EDFs on STD spaces. (Row 2) Standard deviation of r distribution. (Row 3) RemainingFLOPs distribution. (Row 4) Remaining parameters distribution. (Row 5) Mean computation budgetdistribution. (Row 6) The winning pruning recipe on each STD pruning space. Note that the scalesof accuracy drop under different cflops varies.
Figure 3:	We present winning subnetworks on all STD spaces with cflops and cparams respectively.
Figure 4: STD pruning spaces under cparams = {0.25, 0.1, 0.05, 0.02}. In the figure, we study threeSTD pruning spaces, including STD-0.1, STD-0.05 and STD-0.01 spaces with a constraint onparameter bucket. (Row 1) Accuracy drop EDFs on STD spaces. (Row 2) Remaining FLOPs distri-bution. (Row 3) Remaining parameters distribution. (Row 4) Mean computation budget distribution.
Figure 5: (Left) Sort winning subnetworks under different constraints (cflops and cparams) by theiraccuracy drops. Each one is the best on all STD spaces under a constraint. (Right) We present thebest 40 subnetworks on all STD spaces under each constraint.
