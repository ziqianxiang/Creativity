Figure 1: BBOB with precision 1e - 5 and budget 10D. X-axis: budget/dimension in log-scale.
Figure 2: As Fig. 1 but with a 100d budget. Turbo,s speed makes its for this higher budget. Resultsare shown for dimensions 2, 3, 5, and 10.
Figure 3: Multi-deterministic Open AI Gym with tiny neural net: a random seed is randomly drawnfor each optimization run, so that overfitting is more difficult. See Fig. 4 for an aggregated view.
Figure 4: Same problem as Fig. 3, but aggregated comparison as provided by Nevergrad, bestmethods first: row A col B shows the frequency at which method A outperformed method B for thegiven budget. 13 distinct problems per budget. We include only problems for which dimension isD < 50. Methods are ranked per average winning rate. Note that winning rates are all very closeto each other: only PSO is significantly better. Fig. 5 presents similar experiments but with biggerneural nets. Fig. 6 extends the present results to budgets 1600 and 3200.
Figure 5: Same as Fig. 4, but with bigger nets (neural factor 3 in Nevergrad). 18 distinct problemsper budget. We truncated at dimension â‰¤ 264. Dimension ranges from 24 to 264 instead of 8 to 40in Fig. 4. We note that PSO still dominates by far. Due to the computational cost, it was not possibleto finish the runs for SMAC. Fig. 6 extends the present results to budgets 1600 and 3200.
Figure 6: Extension of Fig. 4 and 5, for budget 1600 (top row) and 3200 (bottom row) for algorithmsthat were sufficiently fast (faster than 3 days wall-clock time).
