Figure 1: (a) A standard neural network with 3 input and 12 weight parameters. (b) An new neuralnetwork produced by applying standard adversarial Training on the left, which attacks all inputs. (c)An new neural network produced by applying DropAttack to the network on the left. Assume thateach input vector and weight parameter have a 2/3 and 1/3 probability of being attacked, respectively.
Figure 2: Training and validation accuracy of different models (TextRNN, TextCNN and TextR-CNN) with and without DropAttack on IMDB dataset.
Figure 3: 2D and 3D visualization of the minima of the empirical risk generated by standard training(left) and DropAttack (right) on IMDB dataset.
Figure 4: The impact of attack probability and perturbation coefficient on model performance.
Figure 5: 2D visualization of the minima of the risk selected by standard training and DropAttackon IMDB, PHEME, AGnews, MNIST, CIFAR-10 datasets, respectively.
Figure 6: 3D visualization of the minima of the risk selected by standard training and DropAttackon IMDB, PHEME, AGnews, MNIST, CIFAR-10 datasets, respectively. * With DropAttack.
