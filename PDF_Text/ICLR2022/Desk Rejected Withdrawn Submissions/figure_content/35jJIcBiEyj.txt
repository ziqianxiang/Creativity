Figure 1: Problem description. (a) Biased dataset occurs when there is an imbalance regime re-garding pairs (class, domain), where each class is observed mostly under one distribution, leavingother options under-represented. This results in trained models which do not generalize well. In thecase of supervised debiasing case, one has additional annotations regarding the domain distribution.
Figure 2: Starting from the current parameter configuration θ, gradients on L(Dbias , fθ) andL(DunbiaS, fθ) are evaluated to produce the new configuration θ . The regularization step usingmixed data aims at producing a contribution that decreases the loss function on DbiaS, DunbiaS, andDmix, simultaneously, the latter estimated over the configuration θ*. (Best viewed in color)on. Second, we can have a precise control of the amount of samples assigned to the two splits, e.g.
Figure 3: Examples of biased training data and unbiased data (with red boundary) from Waterbirds and BAR.
Figure 4: Results on Waterbirds and BAR. (a) Performance on the whole (Avg.) and unbiased (Unbias) onlytest set: comparisons with baseline, unsupervised and supervised methods (see text for discussion). Ablationon γ. (b) We set γ = 0.8, 0.85, 0.9, 0.95 and reported the related final accuracy. We compare with ERMbaseline, Nam et al. (2020) and our method using the ground-truth bias knowledge as an oracle, i.e., imposing^	^Dbias = Dbias and Dunbias = Dunbias .
Figure 5: Test accuracy for unbiased samples (Green) and generic samples (Red) for different values of ζ . Xaxis is in logarithmic scale. For ζ = 0.0 we have the weighted ERM of Eq. 5.
