Figure 1: Left: RND scores (↑) for BigGAN images generated from latent distributions with varioustruncations. Right top: four images from the least diverse (most severely truncated) distribution(0.02). Right middle: four images from the second least diverse distribution (0.5). Right bottom:four images from the most diverse distribution (1.0). All images randomly selected from generateddata from the ImageNet class “Academic Gown" (index 400).
Figure 2: Left: RND scores (↑) for different ImageNet 128 × 128 GANs. Right top: four imagesfrom BigGAN. Right middle: four images from ACGAN. Right bottom: four images from SAGAN.
Figure 3: Left: RND scores (↑) for ten different ImageNet classes. We observe a range of diversitymeasurements and display images from the most and least diverse classes. Right top: four imagestaken from the least diverse ImageNet class measured (“Tibetan terrier” - index 200). Right bottom:four images taken from the most diverse class measured (“Hook/Claw” - index 600).
Figure 4: Left: RND scores (↑) comparing single-image GANs. Right top: four randomly selectedimages generated from a single ImageNet training image by SinGAN. Right bottom: four randomlyselected images generated from a single ImageNet training image by ConSinGAN. Images are fromthe class “Tiger Beetle" (index 300).
Figure 5: Left: RND scores (↑) for different CelebA 128 × 128 generative models. Right top: fourimages randomly taken from the most diverse data generated by RealnessGAN. Right middle: fourrandom images generated by PGAN. Right bottom: four random images generated by ALAE.
Figure 6: Left: Generalization gap for different vocabulary sizes. RND captures the correct rankingof diversity with larger vocabulary sizes achieving higher scores than less diverse, smaller vocabularytext. Right: Generalization gap for natural and synthetic text. RND scores the more diverse naturaltext higher than the synthetic text, with the stronger GPT-2 scoring higher than GPT-1.
Figure 8: Ablation on epochs used to train the predictor net. Truncation experiments repeated as in 1.
Figure 7: Left: RND scores (↑) for random noise, and natural images taken from a randomly selectedImageNet class. Right top: four images taken from the ImageNet class measured ("Slot" - index800). Right bottom: four images of random noise used to calculate RND score for random noise.
Figure 9: Ablation on epochs used to average in calculating RND score. Truncation experimentsrepeated as in 1. Left: RND calculated with final 15 epochs. Right: RND calculated with final 20epochs. The relative ordering is preserved across different networks.
Figure 10: Ablation on runs used to calculate RND score. Truncation experiments repeated as in 1.
Figure 11: Ablation on training split. Truncation experiments repeated for selected indices as in 1.
Figure 12: Ablation on network used to calculate RND score. Truncation experiments repeated forselected indices as in 1. Left: Alexnet results (Krizhevsky et al., 2012). Right: ResNet34 Results.
Figure 13: Visualizing generalization gap during training. Left: Index 0. Right: Index 100Figure 14: Visualizing generalization gap during training. Left: Index 200. Right: Index 300Figure 15: Visualizing generalization gap during training. Left: Index 400. Right: Index 50018Under review as a conference paper at ICLR 2022:I 0 020-O⅛ 0.015 -5∙≈ 0.010-⅜g 0.005 -Oo.ooo-0	10	20	30	40	50Epoch0	10	20	30	40	50EpochFigure 16: Visualizing generalization gap during training. Left: Index 600. Right: Index 700(PaZ-"Uuou) &fflo co-⅞N--ffluυcυo
Figure 14: Visualizing generalization gap during training. Left: Index 200. Right: Index 300Figure 15: Visualizing generalization gap during training. Left: Index 400. Right: Index 50018Under review as a conference paper at ICLR 2022:I 0 020-O⅛ 0.015 -5∙≈ 0.010-⅜g 0.005 -Oo.ooo-0	10	20	30	40	50Epoch0	10	20	30	40	50EpochFigure 16: Visualizing generalization gap during training. Left: Index 600. Right: Index 700(PaZ-"Uuou) &fflo co-⅞N--ffluυcυo(PaZ-"Uuou) de。Co-⅞N--Eυcυ0
Figure 15: Visualizing generalization gap during training. Left: Index 400. Right: Index 50018Under review as a conference paper at ICLR 2022:I 0 020-O⅛ 0.015 -5∙≈ 0.010-⅜g 0.005 -Oo.ooo-0	10	20	30	40	50Epoch0	10	20	30	40	50EpochFigure 16: Visualizing generalization gap during training. Left: Index 600. Right: Index 700(PaZ-"Uuou) &fflo co-⅞N--ffluυcυo(PaZ-"Uuou) de。Co-⅞N--Eυcυ00	10	20	30	40	50
Figure 16: Visualizing generalization gap during training. Left: Index 600. Right: Index 700(PaZ-"Uuou) &fflo co-⅞N--ffluυcυo(PaZ-"Uuou) de。Co-⅞N--Eυcυ00	10	20	30	40	50Epoch0.0250.0200.0150.0100.0050.000-0.0050	10	20	30	40	50EpochFigure 17: Visualizing generalization gap during training. Left: Index 800. Right: Index 900(PaZ=euuou) deζ,Co-⅞N--EυcυφFigure 18: Generalization gap during training on 10 ImageNet classes.
Figure 17: Visualizing generalization gap during training. Left: Index 800. Right: Index 900(PaZ=euuou) deζ,Co-⅞N--EυcυφFigure 18: Generalization gap during training on 10 ImageNet classes.
Figure 18: Generalization gap during training on 10 ImageNet classes.
