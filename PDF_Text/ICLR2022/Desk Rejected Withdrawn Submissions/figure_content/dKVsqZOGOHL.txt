Figure 1: Clean accuracy (%) and robust accuracy (%) of the student models (MobileNetV2) against20-step PGD attack (Madry et al., 2017) with different radii on CIFAR-10. The two students aredistilled from the same adversarially trained WideResNet with TRADES (Zhang et al., 2019). “KD”stands for the standard knowledge distillation and “KDIGA” stands for our proposed knowledgedistillation with input gradient alignment.
