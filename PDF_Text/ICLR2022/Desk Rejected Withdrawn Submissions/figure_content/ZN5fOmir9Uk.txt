Figure 1: Example images, labels, and ground truth relation for TexRel dataset Relations task (bestviewed in color)1Under review as a conference paper at ICLR 2022nor of more recent compositional metrics such as tre (Andreas, 2019). Whilst this could show thatincreasing the meaning space does not increase underlying latent ground truth compositionality, weargue that our counter-intuitive result might instead be because existing compositionality metrics donot correlate perfectly with underlying latent ground-truth compositionality. Thus our results showthat there could be an opportunity to develop new compositionality metrics, or to refine existing ones.
Figure 2: Emergent communications referential taskwith unlabeled receiver images, Xtst = {xtst,1 , . . . , xtst,n}, and predicts the correct labels,Ytst = {ytst,1 , . . . , ytst,n}. We hope that the Sender agent will learn to represent the underly-ing concept h in the generated linguistic utterance u. Often, Xtrn consists of a single example, andeach ytst,i is always implicitly true. In our own work, we wish to represent relations, so we extend tothe more general case of multiple labeled sender examples.
Figure 3: Detailed architecture for sender and receiver modelsthe CLEVR code to create a dataset for emergent communication, but found that the ray-tracinggeneration process is relatively slow; and the resulting images are large, and slow to train on.
Figure 4: Experiments on varying size of meaning space M, using TEXREL Texture datasets. Shadedareas are 95% confidence intervals, over 5 seeds.
Figure 5: Experiments on TRE based on Andreas (2019) section 7, using TEXREL. errgen meansgeneralization error. Each run is for 5k training steps. Each point represents the result of a single run.
