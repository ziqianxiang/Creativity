Figure 1: A block diagram of the SynCLR framework. SynCLR learns multiple embedding spacesto construct view-sensitive information. Take text-invariant embedding z1 as an example: The text-modified synthetic sample is considered to be positive while the rest of the samples in the batch areconsidered negative samples, and thus z1 represents the text-invariant information generalizable totext-sensitive out-of-domain distribution.
Figure 2: The pipeline of multi-view data synthesis.ãŠ‰ denotes the element-wise addition operation,and LR denotes the length regulator.
Figure 3: Comparison of synthesized images over out-of-domain CUB dataset.
Figure 4: Comparison of synthesized images over in-domain CUB dataset.
