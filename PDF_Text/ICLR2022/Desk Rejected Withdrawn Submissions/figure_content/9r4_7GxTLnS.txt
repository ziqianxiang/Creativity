Figure 1: Overview of PolyViT. Our model is capable of performing multiple tasks spanning dif-ferent modalities, and processes a single task at a time. The architecture consists of a transformerencoder shared among all tasks, modality-specific input tokenizers and task-specific output heads.
Figure 2: Task sampling schedules considered inthis paper. Each element within a task corre-sponds to the number of training steps performedfor that task by the baseline model.
