Figure 1: Typical settings for semantic segmentation. a) The standard pipeline, which performssupervised or self-supervised pretraining on ImageNet, and trains segmentation models over specificdatasets. b) A simple multi-dataset training method that manually unifies label spaces of differentdatasets. c) Our proposed MDP, which automatically integrates multiple datasets for pretraining.
Figure 2: The pipeline of MDP. Given a labeled image xt randomly sampled from the collectionof multiple datasets D, We first obtain three different views Xt, Xt and Xt (not shown in the figure)through data augmentation as well as a mixed view Xt through cross-dataset mixing. Then weconduct pixel-to-prototype contrastive learning and consistency regularization to model intra-classcompactness and inter-class separability, as well as considering inter-class similarity. The right partillustrates two components of MDP, i.e., cross-dataset mixing and online class prototype update.
Figure 3: Comparisons of MDP, MoCo-V2, and supervised ImageNet pretraining on a) Pascal VOC,b) ADE20K and c) Cityscapes at different fine-tuning iterations.
Figure 4: t-sne visualization of the pixel level feature embeddings of the last layer. The model ispretrained by a) supervised ImageNet pretraining, b) single-head cross-entropy loss, c) pixel-to-pixelloss and d) our pixel-to-prototype loss, respectively.
