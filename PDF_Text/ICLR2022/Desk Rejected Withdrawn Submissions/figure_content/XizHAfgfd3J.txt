Figure 1: Feature contrastive learning ms. Proba-bility contrastive learning. (a) The distribution ofinitial features are relatively scattered. (b) AfterFCL, the features of same semantic are clustered,but the learned class weights are deviated from theclass center. (c) After PCL, the features with sim-ilar semantics can be not only clustered but alsodistributed around the class weights.
Figure 2: Framework of FCL and PCL. Differ-ent from FCL, PCL uses the output of softmax toperform contrastive learning and removes the `2-norm normalization.
Figure 3: The t-SNE visualization of learned features. We focus on the relationship between featuresand class weights on the Câ†’S task of DomainNet dataset with Resnet34 under the setting of 3-shot.
