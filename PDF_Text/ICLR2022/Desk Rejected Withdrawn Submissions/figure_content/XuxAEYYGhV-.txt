Figure 1: The framework of the proposed method. We are provided with K source domains. Thetarget is to train a classifier that can generalize to the unseen domain. The conditional generatornetworks are learned in a pretraining and fine-tune manner, which effectively and efficiently modelsthe multiple source domains. We apply linear interpolation on the multiple correlated networks in theparameter space to generate diversified OoD data. A style-mixing mechanism is further introducedto get semantic augmented samples.
Figure 2: Typical examples of the OoD datasets.
Figure 3:	Visualization results of synthetic images on various datasetsvolume of synthesized data. The superior performance confirms the possibility of improving OoDgeneralization ability via increasing the data diversity.
Figure 4:	Comparison of the generated images from different data augmentation mechanisms. Thesamples generated by deep generative models are more realistic and preserves the class labels.
Figure 5: Illustration of the Full Colored MNIST dataset. The 10 digits were colored with 10 colorsbased on different correlations with the labels to construct different environments, i.e., 80% and 90%for training environments and 10% for the test environments.
Figure 7: More visualization results of synthetic images on the Full Colored MNIST.
