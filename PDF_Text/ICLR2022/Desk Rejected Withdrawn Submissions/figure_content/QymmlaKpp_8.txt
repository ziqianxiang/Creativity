Figure 1: ABCDâ€™s Architecture. We train a single encoder for all domains. The objective functionencourages the representation of every image to be as far as possible from those of other images fromthe same domain - this encourages domain disentanglement. Additionally, the objective encouragesthe representation of different augmentations of the same image to be the same. This encouragesrepresentation alignment. The choice of augmentations determines the inductive bias of the method.
Figure 2: Image Translation results of LORD & ABCD. Both methods perform very well on Cars3D.
Figure 3: Image Translation results of LORD & ABCD. The leftmost images are the targets, therightmost three and the top-3 retrievals. We can see that results on Cars3d are good for both methods.
