Figure 1: Meta-inference stage using various classifiers composed with a fixed task-agnostic featureextractor. We propose a task-agnostic hypernetwork (d) to generate a task-specific linear classi-fier. Note, LR and linear SVM (c) require training during meta-inference, whereas the remainingclassifiers (a,b,d) are training-free during meta-inference.
Figure 2: T-SNE projection (Van der Maaten & Hinton, 2008) of support (star) and query (circles)features, color-coded by classes in a novel 1-shot 5-way task from MiniImageNet. Our context-aware approach achieves higher accuracy than context-unaware ProtoNet.
Figure 3: (a) Effect of batch size M on model performance. Ablation study on architecture of thetransformer T: (b) hidden dimensions t (c) number of heads (d) number of encoder layers. Wereport accuracy with 95% confidence interval on TieredImageNet test split.
