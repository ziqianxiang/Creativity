Figure 1: The red points represent the benign ex-amples in focus on the latent space, while the blackpoints represent their adversarial counterparts. Byminimizing the OT-based adversarial regulariza-tion term Wd (Qh, Qh), the global information ofall benign examples can be used to push an adver-sarial example to an appropriate cluster of the be-nign examples with the same label, and encouragethe classifier h to reduce the mismatch in its predic-tions.
Figure 3: Robustness comparison on the CIFAR-10dataset against PGD attack at η = 0.003, while varying∈ [0.02, 0.1], k=20 (left), k ∈ [10, 100], = 8/255(right).
Figure 2: Robustness comparison on the MNISTdataset against PGD attack with η = 0.01, while vary-ing ∈ [0.1, 0.7] k=40 (left), k ∈ [10, 100]	= 0.3(right).
Figure 4: Robustness accuracy for SVHN (left) andCIFAR-100 (right) against PGD attack with varying∈ [0.02, 0.1], k=20 in model ResNet-18.
Figure 5: Robustness accuracy for CIFAR-10 (left)and CIFAR-100 (right) against PGD attack with vary-ing ∈ [0.02, 0.1], k=20 in model WRN-34-10.
Figure 6: Label distribution from penultimate layers for CIFAR-10 against PGD-20, based on baseline model TRADES (left),and proposed model GOT-TRADES-LM (right).
Figure 7: Robustness comparison on theMNIST dataset regarding changing OT losstrade off.
