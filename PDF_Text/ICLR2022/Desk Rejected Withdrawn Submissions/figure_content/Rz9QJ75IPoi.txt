Figure 1: (a) For the COCO dataset, all the images are resized such that the short edge has 800 pixels whilethe long edge has less than 1333 pixels. For the ImageNet dataset, all the images are resized to 224 × 224 tocalculate the statistics. (b) We predict pseudo-label on the rest of COCO training data with a converged Faster-RCNN detector (with FPN and ResNet50 backbone), trained with 10% COCO data. The low average recalland precision show that hard pseudo-label incur more noise with False Negative samples. (c) All the scoresare predicted by the RetinaNet detector with FPN and ResNet 50 backbone, which is trained with randomlysampled 10% COCO data. The score distance is the absolute difference between the predictions of the imagein different sizes. The Y-axis is the average number of anchors per image.
Figure 2: The Image (w/o Aug) means that the input is only weakly augmented (random resize and flip). TheImage in (c) is strongly augmented, such as color jittering, gaussian blur. (a) In STAC (Sohn et al., 2020b), amodel is trained with labeled data to predict hard pseudo-label for self-training during the first stage. (b) Unbi-ased Teacher (Liu et al., 2021) generates hard pseudo-label by the slowly progressing teacher, which is shownto yield more accurate targets (Tarvainen & Valpola, 2017). (c) Our model improves the scale invariance, whichis critical for object detectors, by regularizing the consistency between different-sized images. Furthermore,the inherent False Negative sample noise is alleviated by predicting soft pseudo-label. A re-weighting strategyis adopted to solve the severe class imbalance problem.
Figure 3: Overview of our method. For simplicity, the supervised branch is ignored, which shares the StudentModel with the unsupervised branch. The dashed line means the prediction of the Teacher Model is not op-timized by the gradient. For Scale consistency Regularization, the loss constrains predictions from differentlevels, linked by arrows of the same color (best viewed in color).
Figure 4: The average sample is the average anchor number in a single image. The baseline method is simplytreating all samples equally. The samples with large gradients don’t contribute significantly because the samplenumber is relatively small. Our re-weighting strategy focuses on the samples with large score discrepanciesand linearizes the relationship between gradient contribution and score distance.
Figure 5: The CDF of instance size dis-tribution on the whole MS-COCO traindataset.
