Figure 1: The paradigm of localizing crucial re-gions in region-aware knowledge distillation onHorse→Zebra with CycleGANs.
Figure 2: The overview of Region-aware Knowledge Distillation (best viewed in color). (a) Step-1:Find the crucial regions in the to be translated image by applying the attention module to teacherfeatures. Note that the attention module is composed of an absolute value operation and a meanoperation on the channel dimension. Then, K regions with the largest attention values are selectedas the crucial regions (here K=3). (b) Step-2: Based on the crucial regions found in Step-1, selectstudent and teacher features on these crucial regions and discard the features in unimportant regions.
Figure 3: The overview of perceptual distillation.
Figure 4: Qualitative results on Horse→Zebra and Zebra →Horse. A 15.81× compressed Cycle-GAN is utilized as the student. Results on Edges2Shoes are shown in Appendix B.
Figure 5: The visualization of the learned similarity between student features in one region andteacher features in all regions. For each line, we plot the similarity when six different regionsof students are selected. Three of these regions come from horses and the others come from thebackground. A Lighter region indicates a higher similarity.
Figure 6: The FID curve of CycleGAN studentstrained with and without knowledge distillation onHorse→Zebra and Zebra→Horse.
Figure 8: Sensivity studies on the three hyper-parameters with CycleGAN on Horse→Zebra.
