Figure 1: TAN consists of (left) the encoder and the decoder, and (right) two setting masks:The areas highlighted in red are the newly introduced elements. In the training phase, TANaccepts the same input sequence as the source text, and the target text, learns WZ and WV ,and makes topics share with the encoder and the decoder via topic alignment, attentionmask for training, TDM and TEM. In the generation phase, TAN uses only the decoder(pre-trained NLM) using the attention mask for text generation, WZ , and WV .
