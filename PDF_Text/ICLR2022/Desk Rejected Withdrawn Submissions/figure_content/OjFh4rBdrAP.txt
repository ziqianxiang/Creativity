Figure 1: We show the easy and hard cases in our dataset. (a) shows an easy case in which eachchapter has clear temporal structures. (b) shows a hard case. There are no clear visual or narrationfeatures to determine where the chapter beginning is without watching most parts of the video.
Figure 2: The framework of our approach. (a) Chapter localization stage. A two-stream networkwith a sliding window mechanism is developed for extracting visual and text features. (b) Chaptertitle generation stage. The Transformer encoder-decoder is used for generating chapter title.
Figure 3: The skip sliding window mechanism. The video timeline is denoted by blue arrow withG.T. chapter beginning time marked by green stars. The red and yellow segments represent twoconsecutive sliding windows. If a small time offset o around G.T. is acceptable, the sliding windowstep u = 2o can achieve best efficiency without missing any G.T. chapter beginning time.
Figure 4: The chapter generation results and saliency maps. Our framework can precisely localizethe chapter start time and generate semantically reasonable chapter titles.
