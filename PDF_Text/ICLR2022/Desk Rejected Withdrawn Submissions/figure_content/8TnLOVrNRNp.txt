Figure 1: Overview of Visual Transformatcher. The feature maps extracted from an image pair areused to compute a multi-channel correlation map to be processed by our match-to-match attentionmodule for refinement. We construct a dense flow field from the resulting correlation map, whichcan be used to transfer keypoints for training with keypoint pair annotation.
Figure 2: Match-to-match attention module. The multi-channel correlation map is projected toquery, key and value matrices, which are multiplied with rotary positional embeddings. The match-to-match attention module exploits additive addition mechanisms to aggregate query/key matricesto global vectors, which is used for element-wise product to induce global context awareness. Thefinal output is projected to a single-width channel to be reshaped to a refined 4D correlation map.
