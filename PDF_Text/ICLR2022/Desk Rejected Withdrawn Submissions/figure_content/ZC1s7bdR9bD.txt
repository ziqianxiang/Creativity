Figure 1: Example contributions to predictive uncertainty for a classification task in dogs versus catsdata. The image is compared to a fiducial black screen with entropy of 0.49 (aleatoric 0.39, epis-temic 0.1). Importances are smoothed with a Gaussian filter (Î£ = 3I). Red importances representcontributions towards increasing uncertainty, while purple importances contribute towards decreas-ing uncertainty.
Figure 2: Procedural sketch to generate a pathof integration. Here, fiducial z0 and recon-struction z points are optimized in latent spaceby gradient descent, starting initially from theencoding of x (dashed lines). A connectingstraight path (in blue) is projected to the data-manifold and augmented with an interpolatingcomponent (in red).
Figure 3: An example of in-distribution curvesconnecting fiducial (left-most) and real (right-most) data points, on MNIST digits data. Digitson the left bear no model uncertainty in classifi-cation.
Figure 4: Comparison of uncertainty attributions for individual pixels on a CelebA image. Wecompare predictive uncertainties for three Bayesian classifiers, which measure the presence (or lack)of smiles (left), arched eyebrows (centre), and bags under eyes (right). Red pixels contribute byincreasing uncertainties, in green we find contributions towards decreasing uncertainties.
Figure 5: (a) Uncertainty attributions With decomposition across aleatoric/epistemic componentsand (b) comparison against popular methods, on MNIST digits.
Figure 6: Comparison of uncertainty attribution meth-ods on fashion-MNIST images.
Figure 7: Uncertainty attributions on CelebA images. (a) Pictures with the smile attribute labelled aspositive (top two pictures) or negative (bottom two pictures). (b) Pictures with the arched eyebrowsattribute labelled as negative (top two pictures) or positive (bottom two pictures)8Under review as a conference paper at ICLR 2022Similarly to digits and fashion items in previous examples, our importances isolate the pixels forfacial features that seemingly contradict the predicted class by the Bayesian classifier. In compar-ison, attributions through vanilla integrated gradients identify multiple artefacts, present a mix ofpositive and negative importances, and are hard to interpret. KernelSHAP offers inconsistent resultsthat commonly highlight wide areas around the region of interest. Finally, CLUE importances visi-bly struggle with higher resolution images, the reason for this being reliance on direct comparisonsbetween an image and its counterfactual reference. We also note that redrawing a high-fidelity facereconstruction with an autoencoder is considerably more difficult than drawing digits or clothes.
Figure 8: Vanilla uncertainty attributions using a straight path. Classes predicted with 0 posteriorpredictive entropy. Importances reflect a reduction in entropy from a black background fiducial.
Figure 9: Attributions of uncertainty on MNIST digits.
Figure 10: Comparison of uncertainty attributions methods on MNIST digits.
Figure 11: Comparison of uncertainty attributions methods on MNIST-fashion images.
Figure 12: Comparison of uncertainty attributions methods on CelebA images, class label smile.
Figure 13: Comparison of uncertainty attributions methods on CelebA images, class label bagsunder eyes.
Figure 14: Comparison of uncertainty attributions methods on CelebA images, class label archedeyebrows.
