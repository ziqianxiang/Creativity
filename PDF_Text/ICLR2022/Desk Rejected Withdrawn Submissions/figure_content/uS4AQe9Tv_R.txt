Figure 1: An example of gender bias in 60 most biased profession words in BERT-base model. Foreach profession, we measure the difference between the probability of filling the masked pronounin each template sentence with ”he” and ”she” tokens. Some words such as nurse (-0.73) and recep-tionist (-0.57) are supposed to be gender neutral by definition but BERT-base model consider themas female professions. On the other hand, lawyer (0.74) and prosecutor (0.81) are considered as jobsfor male.
Figure 2: Difference between SPPA and GEEP methods. Blue boxes represent the parameters ofthe pre-trained model before any further training and yellow boxes show updated parameters dur-ing second-phase pre-training (SPPA). SPPA requires updating all the pre-trained model,s parame-ters. GEEP method only requires initializing the profession words embeddings Wpo、, Wpo2 .…，Wpomrandomly and updating them during second-phase pre-training while freezing all the pre-trainedmodel,s parameters.
Figure 3: Difference between the probabilities of filling a masked pronoun with ”he” and ”she”tokens in the template sentences containing 60 most biased professions. GEEP method outperformsthe two other methods. For example, the bias score for ”nurse” token decreases from -0.7 in BERT-base to -0.5 in BERT-SPPA and 0.1 in GEEP model.
