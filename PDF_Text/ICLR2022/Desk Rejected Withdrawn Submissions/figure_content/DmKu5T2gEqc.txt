Figure 1: Pipeline of our framework: (a) Stack ConvLSTM (Xingjian et al., 2015). (b) Our CD-Net. The CDNet consists of four modeling components: Encoder-Decoder module, motion LSTMfor motion dynamics prediction, global information integration for preserving global appearanceinformation, and refine LSTM for appearance refinement.
Figure 2: (Left) The design for the refine LSTM cell. The refine LSTM cell iteratively refinesthe predicted feature referring to the global foreground and background information. (Right) Thehidden state update strategy. The hidden state H refers to the mask B to update the information, i.e.
Figure 3: Given 4 frames on the human 3.6m dataset, We specifically show the prediction results ofeach frame predicted by the model in the future 4 frames. All the referenced models are trained bytheir open-source code.
Figure 4: Qualitative results on Human 3.6M dataset.
Figure 5: Intermediate representation on human3.6M dataset. (left) MSE, MAE and PSNR results in1 motion prediction layer and 5 refinement layers at t+1 frame prediction and t+2 frame prediction.
Figure 6: Qualitative results on UCF101 dataset.
Figure 7: Details of the global information integration and updater U in refine LSTM.
Figure 8: Prediction of 8 future frames based on the model trained by 4â†’4 setting.
Figure 9: Larger visualization of intermediate representation on human 3.6M dataset, correspondingto Fig. 5 in the main paper.
Figure 10:	Qualitative comparisons on Human 3.6M. We display predictions of PhyDNet (GUen &Thome, 2020), CrevNet (YU et al., 2020) and our CDNet starting from the 5th frame to 8th frame.
Figure 11:	Qualitative comparisons on Human 3.6M. We display predictions of PhyDNet (GUen &Thome, 2020), CrevNet (YU et al., 2020) and our CDNet starting from the 5th frame to 8th frame.
Figure 12:	Qualitative comparisons on UCF101. We display predictions of PhyDNet (GUen &Thome, 2020), CrevNet (Yu et al., 2020) and our CDNet starting from the 5th frame to 14th frame,with 3 frames interval. They are trained by past 4 high resolution frames.
