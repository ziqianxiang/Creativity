Figure 1: GroupVAE’s architecture visualization and graphical model. We visualize the com-plete model, including model weights in (a) as well as show the (b) generative and (c) inference partsas graphical models. The model visualization shows two paired inputs, one pair sharing “style” andthe other sharing “content”. The KL minimization depends on the group g that is shared. For in-stance, for input (x(1) , x0(1) , g(1) = “style”), GroupVAE objective only minimizes the KL betweenthe style latent variables. Shaded nodes denote observed quantities in (b) and (c), and unshadednodes represent unobserved (latent) variables. Dotted arrows represent minimizing the KL diver-gence between variables during inference.
Figure 2: Example of failed content-style disentanglement with high MIG.
Figure 3: Interpolations of 3D Shapes. We show samples from our model GroupVAE and thebaseline models (MLVAE and GVAE) with median group-MIG over five hyperparameter sweeps.
Figure 4: Qualitative samples of ShapeNetV2. We show reconstructions of FoldingNet and ourapproach in (a) and show interpolations of our approach in (b).
Figure 5: Collapse and sensitivity of existing weakly supervised group disentanglement models.
