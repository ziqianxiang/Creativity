Figure 1: An overview of the MARL attackframework against federated learning.
Figure 2: A comparison of average classification error rates for FL with four different aggregation rules(coordinate-wise median, FLTrust, Safeguard, and Centered Clipping) on three different datasets (Fashion-MNIST, CIFAR-10 and ImageNet) for both i.i.d. data and non-i.i.d. data. Key parameters: number of workers =1, 000, number of attackers = 50, subsampling rate = 20%. All other parameters are set as default. Error barsindicate the standard deviations. The results for Krum follow similar trends and are omitted to save space.
Figure 3: A comparison of average classification error rates and Wasserstein distance by varying configurationsof RL-based methods for FL with FLTrust defense rule on Fashion-MNIST with i.i.d. data. Error bars indicatethe standard deviations. In (a) and (c), DL: default distribution learning; NDL: no distribution learning; DLR:distribution learning with random dummy data. In (d), FC: coordination in all the stages; NC: no coordination;CDL: coordinated distribution learning and uncoordinated policy learning.
Figure 1: A comparison of classification errors on Fashion-MNIST with i.i.d. data with FLTrust defense ruleby varying the level of subsampling (left) and the number of attackers (right). Key parameters: number ofworkers = 1, 000, number of attackers = 50 (left), subsampling rate = 20% (right). All other parameters are setas default.
Figure 2: A comparison of Wasserstein distance between the true mixture distribution (P) and thelearned distribution (P) on Fashion-MNIST when the server applies non Â´ i.i.d. data for FL withFLTrust defense rule. Key parameters: number of workers = 1, 000, number of attackers = 50,subsampling rate = 20%. All other parameters are set as default.
