Figure 1: Overview of the proposed federated contrastive learning (FCL) framework. Four steps areperformed in each learning round, including model and feature uploading from clients to the server,model aggregation on the server, model and feature downloading from the server to clients, and locallearning. Local learning is performed by the proposed feature fusion in Sect. 4 and neighborhoodmatching in Sect. 5.
Figure 2: Local contrastive learning with feature fusion reduces false negative ratio and improvesdata diversity, and improves the learned representations on each client.
Figure 3: Neighborhood matching aligns each clientâ€™s local features to the remote features such thatwell-clustered features among clients are learned.
Figure 4: Linear evaluation accuracy on CIFAR-10 and CIFAR-100 in IID setting. The classifieris trained by 100% labels on a fixed encoder learned by different approaches. Error bar denotesstandard derivation over three independent runs.
Figure 5: Ablations on CIFAR-10 dataset under non-IID FL (a), (b) and IID FL (c), (d). CL iscontrastive learning. FF is feature fusion and NM is neighborhood matching. Top-1 accuracy oflinear classifier and semi-supervised learning (1% labels) are reported.
