Figure 1: A stroke patient performing a functional activity (drinking) from the StrokeRehab activitiesbattery. Using the functional motion taxonomy, the activity can be decomposed into its constituentfunctional primitives as follows: reach, upper extremity (UE) motion to bring it into contact witha target object (e.g. water bottle); stabilize minimal UE motion to keep a target object still (e.g.
Figure 2: Popular action recognition datasets arealigned to a hierarchy of the labeled actions theycontain. Our dataset StrokeRehab mainly con-tains short-duration basic functional primitives.
Figure 3: Distribution of action duration of ac-tions for the various benchmark datasets. Thisillustrates the extreme fine-grained nature of ac-tions (functional primitives) in the StrokeRehabdataset in comparison to existing ones.
Figure 4: Comparison of sequence-to-sequence (seq2seq) and segmentation models. The segmen-tation model outputs frame-wise action predictions, which can then be converted to a sequenceestimate by removing the duplicates. The seq2seq model produces a sequence estimate directly.
Figure 5: Boundary accuracy achieved by thesegmentation models vs duration of the actionsfor several datasets. Boundary-detection accu-racy is inversely proportional to action duration.
Figure 6: Comparison of ground-truth and pre-dicted mean counts for the different activities inthe StrokeRehab dataset. The relative error isvery small for structured activities like movingobjects on/off a shelf (Shelf), and larger for un-structured activities like brushing.
Figure 7: Confusion Matrix for the best perform-ing model on the StrokeRehab video Dataset.
Figure 8: Confusion Matrix for the best perform-ing model on the StrokeRehab sensor Dataset.
