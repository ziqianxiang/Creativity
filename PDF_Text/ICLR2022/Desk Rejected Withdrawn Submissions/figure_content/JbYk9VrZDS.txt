Figure 1: The variational Bayesian autoencoderusing plate notations, where φ and θ are globalvariables representing the encoder’s parameters andthe decoder’s parameters respectively.
Figure 2:	Convergence of different algorithms. (a) ResNet18 on CIFAR10, (b) DenseNet121 on CIFAR10, (c)MobileNetV2 on CIFAR10, (d) BiLSTM on Sent140.
Figure 3:	Training efficiency of different algorithms. (a) ResNet18 on CIFAR-10, (b) DenseNet121 on CIFAR-10, (c) MobileNetV2 on CIFAR-10, (d) BiLSTM on Sent140.
Figure 4: Visualization of data distribution (only a subset of the original data is illustrated). (a) the originaldistribution of MNIST, (b) the inferred distribution of MNIST with FedDAF, (c) the original distribution ofCIFAR-10, (d) the inferred distribution of CIFAR-10 with FedDAF.
Figure 5: Comparison of parameter bias. (a)ResNet18 on CIFAR-10, (b) BiLSTM on Sent140.
Figure 6: Test accu-racy with different hetero-geneity η (ResNet18 onCIFAR-10).
Figure 7: Test accu-racy with different num-ber of clients (ResNet18on CIFAR-10).
