Figure 1: Illustration of nonstationary causal structures in physical systems. Casual structures canbe represented as a graph, where edges indicate interaction between objects. Take the example ofthe supporting force in the block falling sequence, the graph changes over time, posing a challengeto video causal discovery methods.
Figure 2:	Comparison of existing causal structure representations for causal discovery. For sta-tionary causal models, (a) Li et al. (2020) propose the double-edged causal summary graph and(b) Zheng et al. (2018) model both the instantaneous interactions (i.e., among objects at the sametime step) and time-leg interactions (i.e., among objects at different time steps). For nonstationarycausal models, (c) Gerhardus & Runge (2020) learns both the causal graph structure and the in-tervention set (i.e., nodes in orange color). (d) We propose the intervention-based recurrent causalmodel (IRCM) to use interventions to model nonstationary time-leg interactions. (e) We visualizethe matrix representation of the intervention set and causal graph for the given example.
Figure 3:	Model designs of the proposed IRCM. The model has two modules: recurrent network(RN) and intervention-based causal model (ICM). Given the input video frame feature xt-1, RNupdates the hidden states ht and predicts probability values (αt , βt) to sample DAG structure Mtand intervention set It, respectively. With observation x1:t-1 and causal structure representation(Mt, It), ICM predicts the mean and covariance of multivariate Gaussian distribution for bothobservation and intervention sets, (μt, Σt) and (μt, Σt), resulting the probability density function f.
Figure 4: Learning and inference of the proposed IRCM. During learning, We first make the forwardpass to predict the Bernoulli distribution parameters (αt , βt) and sample causal structure represen-tation (Mt , It) to predict the probability density function f. Then, we backpropagate the loss toupdate the parameters in neural network models, θRN and θICM. During inference, we recursivelyfeed the predicted xt into the model to estimate the next time step state via the Monte Carlo method.
