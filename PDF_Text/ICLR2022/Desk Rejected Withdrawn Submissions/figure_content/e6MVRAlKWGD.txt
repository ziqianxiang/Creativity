Figure 1: CARP learns to align representations of passages and corresponding representa-tions of critiques.
Figure 2: Box plots of story lengths for the Writing Prompts (WP) and Story-Critique (SC)datasets, broken down by sentiment. All four groups exclude outliers from in the plot.
Figure 3: Validation Loss and Accuracy for CARP during training.
Figure 4: We compare CARP-L, CARP-B, CARP-T, to our three baseline models: multi-ple choice classification prompt engineering, seq2seq classification prompt engineering, andseq2seq finetuning on our dataset. In the top plot we measure the cosine similarity (higheris better) of the predicted distribution against the human baseline. In the bottom plot,we compute f (x) = KL(softmax(Human scores), x) per story and similarly plot a box plot(lower is better).
