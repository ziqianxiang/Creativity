Figure 1: Trajectories of different optimization methods.
Figure 2: Training loss of each optimization methodESGDâ€”oursAnalysis on generalization. Here, we compare our method with second-order optimization toevaluate the generalization performance. The third and fourth columns of Table 2 list the trainingand test accuracy achieved by the best models of each optimizer. The best model was selectedaccording to the highest validation accuracy. The values of selected learning rates are available inthe supplementary material. Our method shows a remarkable generalization performance and canachieve the highest test accuracy on all the tasks. Especially on IMDb, Kernel SGD improves thetest accuracy by around 28%. Moreover, Kernel SGD can mitigate overfitting and achieves a stableaccuracy, which is demonstrated by the relatively small gaps between the test accuracy and trainingaccuracy and the small variances. Note that we did not adopt pre-processing techniques such asrandom flipping on the tested data for fair comparison and thus the accuracy in Table 2 may beslightly different from those shown in other studies.
Figure 3: Overall performance.
Figure 4: Impact of batch size on Kernel SGD.
