Figure 1: An illustration of our proposed approach. E and G are the pretrained and fixed StyleGAN2encoder (Richardson et al., 2021) and generator (Karras et al., 2020) respectively. Only the mappingT and the entropy model are trained using the joint rate (R) and distortion (D) loss. On the left weshow SGANC for image compression; On the encoding side, the images are projected in the latentspace (W+) then mapped to Wc? where the quantization/compression is done. On the decoding side,the obtained bit-stream is decompressed, then mapped to W+ before generating the reconstructedimage. On the right we show SGANC for video compression using inter coding (SGANC IC);we quantize the consecutive latent code difference and reconstruct the current latent code from thisdifference and the last reconstructed latent code.
Figure 2: An illustration of our proposed approach for Video compression using Inter Coding withresidual during test (Section 3.3). Q corresponds to quantization, compression encoding and decod-ing. Here g = 1.
Figure 3: Rate distortion curves on MEAD intra dataset: for medium and large BPP, our method(SGANC in blue) is better in terms of LPIPS and MS-SSIM than VTM (Red), AV1 (Purple),MeanHP (Orange) and HP (Green). For high BPP, our method is better in terms of PSNR. Theperceptual metrics LPIPS and PIM clearly show that our method outperforms existing methods per-ceptually.
Figure 4:	Qualitative results for image compression with comparable BPP for all methods (imagesare better seen zoomed). Other methods introduce blocking artifacts and blurring. Our method(SGANC) leads to high quality reconstruction and perceptually lower distortion. In particular, theperceptual metrics LPIPS and PIM show a significant impact of our method.
Figure 5:	Qualitative results for video compression (images are better seen zoomed). Other methodsintroduce blocking artifacts and blurring. Our method (SGANC IC) leads to high quality recon-struction and a significantly lower perceptually distortion, as measured by the metrics LPIPS andPIM.
Figure 6: Rate distortion curves on MEAD inter dataset. Our approach SGAN-IC leads to a signifi-cantly lower perceptual distortion as measured by the perceptual metrics LPIPS and PIM.
Figure 7: Ablation study for the choice of the distortion loss on MEAD intra dataset. we comparethe MSE loss in the image space (SGANC Img, Orange), the MSE loss in the latent space W +(SGANC Lat, Blue), the combination of both (SGANC Lat + Img, Green), the LPIPS loss in theimage space (SGANC LPIPS, Purple) and the combination of the MSE and the LPIPS losses asdone in other works (SGANC LPIPS + Img, Red). The loss in the latent space (SGANC Lat, ours)outperforms the MSE and LPIPS losses in the image space. Using the MSE loss with our loss doesnot seem to improve the results (SGANC Lat + Img).
Figure 8: Ablation study for the choice of the distortion loss. We compare the effect of taking theMSE loss in; the latent space (Lat. D, ours), in the image space (Img. D), both in the latent andimage space (Lat.-Img. D) and in the image space with the LPIPS perceptual distortion (LPIPS.-Img. D). The loss in the image space favors some artifacts such as white patches and the images areblurred. In addition, the LPIPS loss produce blurred images ((LPIPS.-Img. D and LPIPS. D). Ourloss produce artifacts free images. There is no benefit of using additionally the image space loss.
Figure 9: Qualitative results for image compression: Using an AE (AEC) instead of NF leads tohigh distortion and a change in the facial attributes and the identity of the person. Our method(SGANC) leads to high quality reconstruction and perceptually lower distortion. Images are betterseen zoomed.
Figure 10: Ablation study for video compression using inter coding with residuals on MEAD interdataset. res: do residual coding each g frames, intra: do intra coding each g frames, SS: stagespecific entropy model and transformation T, L1: add L1 regularization during training (sectionA.3.3), EM: entropy model0.006 0.008 0.010BPP20Under review as a conference paper at ICLR 2022A.4 More resultsIn this section we show more quantitative and qualitative results for image and video compression.
Figure 11: Qualitative results for image Compression: Other methods introduCe bloCking artifaCtsand blurring. Our method (SGANC) leads to high quality reConstruCtion and perCeptually lowerdistortion. Images are better seen zoomed.
Figure 12: Qualitative results for image compression: Other methods introduce blocking artifactsand blurring. Our method (SGANC) leads to high quality reconstruction and perceptually lowerdistortion. Cheng et al. (2020) is better than HP, but still the results are blurred. Images are betterseen zoomed.
Figure 13: Qualitative results for image compression: Other methods introduce blocking artifactsand blurring. Our method (SGANC) leads to high quality reconstruction and perceptually lowerdistortion. Images are better seen zoomed.
Figure 14: Qualitative results for image compression: Other methods introduce blocking artifactsand blurring. Our method (SGANC) leads to high quality reconstruction and perceptually lowerdistortion. Images are better seen zoomed.
Figure 15: Qualitative results: Other methods introduce blocking artifacts and blurring. Our method(SGANC) leads to high quality reconstruction and perceptually lower distortion. Images are betterseen zoomed22Under review as a conference paper at ICLR 2022BPPLPIPS0.02160.24980.01490.0610.00890.17180.02890.0080.00680.317Figure 16: Qualitative results: Other methods introduce blocking artifacts and blurring. Our method(SGANC) leads to high quality reconstruction and perceptually lower distortion. Images are betterseen zoomed
Figure 16: Qualitative results: Other methods introduce blocking artifacts and blurring. Our method(SGANC) leads to high quality reconstruction and perceptually lower distortion. Images are betterseen zoomedFigure 17: Rate distortion curves on FILMPAC dataset: for medium and large BPP, Our method(Blue) is better in terms of LPIPS and MS-SSIM than VTM (Green), MeanHP (Orange). For highBPP, our method is better in terms of PSNR.
Figure 17: Rate distortion curves on FILMPAC dataset: for medium and large BPP, Our method(Blue) is better in terms of LPIPS and MS-SSIM than VTM (Green), MeanHP (Orange). For highBPP, our method is better in terms of PSNR.
Figure 18: Qualitative results for video compression: Other methods introduce blocking artifactsand blurring. Our method (SGANC IC) leads to high quality reconstruction and perceptually lowerdistortion. Images are better seen zoomedLPIPS (Zhang et al., 2018)Figure 19: Rate distortion curves for video compression on Filmpac dataset. The perceptual metricLPIPS clearly shows a perceptual improvement of our method.
Figure 19: Rate distortion curves for video compression on Filmpac dataset. The perceptual metricLPIPS clearly shows a perceptual improvement of our method.
Figure 20:	Qualitative results on MEAD inter dataset for extreme BPP, computed for three videoframes. H.265 shows blocking artifacts and blurring, VTM shows blurring especially at the edgesof the face and the hair while our method (SGANC) is almost artifacts free and with high qualityimages.
Figure 21:	Qualitative results on MEAD inter dataset for extreme BPP, computed for three videoframes (columns). H.265 shows blocking artifacts and blurring, VTM shows blurring especially atthe edges of the face and the hair while our method (SGANC) is almost artifacts free and with highquality images.
Figure 22:	Qualitative results on MEAD inter dataset for extreme BPP, computed for three videoframes. H.265 shows blocking artifacts and blurring, VTM shows blurring especially at the edgesof the face and the hair while our method (SGANC) is almost artifacts free and with high qualityimages.
Figure 23: Qualitative results on MEAD inter dataset for extreme BPP: H.265 shows blockingartifacts and blurring, VTM shows blurring especially at the edges of the face and the hair whileour method (SGANC) is almost artifacts free and with high quality images.
Figure 24: Qualitative results on MEAD inter dataset: H.265 shows blocking artifacts and blurring,VTM shows blurring especially at the edges of the face and the hair while our method (SGANC) isalmost artifacts free and with high quality images.
Figure 26: Qualitative results on MEAD inter dataset: H.265 shows blocking artifacts and blurring,VTM shows blurring especially at the edges of the face and the hair while our method (SGANC) isalmost artifacts free and with high quality images.
Figure 27: Qualitative results on MEAD inter dataset: H.265 shows blocking artifacts and blurring,VTM shows blurring especially at the edges of the face and the hair while our method (SGANC) isalmost artifacts free and with high quality images.
