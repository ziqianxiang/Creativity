title,year,conference
 Pattern recognition and machine learning,2012, Elsevier
 Unsupervised label noisemodeling and loss correction,2019, In International Conference on Machine Learning
 A closer look at memorizationin deep netWorks,2017, In ICML
 Understanding and improving early stopping for learning With noisy labels,2021, arXiv preprintarXiv:2106
 Learning object categories from internetimage searches,2010, Proceedings of the IEEE
 Training deep neural-netWorks using a noise adaptation layer,2017, InICLR
 MentorNet: Learning data-drivencurriculum for very deep neural netWorks on corrupted labels,2018, In ICML
 Robust active label correction,2018, In AISTATS
 Learning multiple layers of features from tiny images,2009, 2009
 Dividemix: Learning With noisy labels as semi-supervisedlearning,2019, In ICLR
 Provably end-to-end label-noiselearning Without anchor points,2021, arXiv preprint arXiv:2102
 Classification With noisy labels by importance reWeighting,2016, IEEE Trans-actions on pattern analysis and machine intelligence
 Peer loss functions: Learning from noisy labels Without knoWing noise rates,2020, InICML
 Dimensionality-driven learning With noisy labels,2018, In ICML
 Exploring the limits of weakly supervised pretraining,2018, InProceedings of the European Conference on Computer Vision (ECCV) 
" Decoupling"" when to update"" from"" how to update""",2017, In NeurIPS
 Foundations of machine learning,2018, MIT press
 Learning with noisylabels,2013, In NeurIPS
 Self: Learning to filter noisy labels with self-ensembling,2019, In ICLR
 Making deepneural networks robust to label noise: A loss correction approach,2017, In CVPR
 Training deep neural networks on noisy labels with bootstrapping,2015, In ICLR
 Learning to reweight examples for robustdeep learning,2018, In International Conference on Machine Learning
 Trainingconvolutional networks with noisy labels,2015, In ICLR
 Joint optimization framework forlearning with noisy labels,2018, In CVPR
 Learning from massive noisy labeleddata for image classification,2015, In CVPR
 L_dmi: A novel information-theoretic loss functionfor training deep nets robust to label noise,2019, In NeurIPS
 Dualt: Reducing estimation error for transition matrix in label-noise learning,2020, In NeurIPS
 Understanding deeplearning requires rethinking generalization,2017, In ICLR
 mixup: Beyond empirical riskminimization,2018, In ICLR
 Learning noise transition matrix from only noisy labelsvia total variation regularization,2021, arXiv preprint arXiv:2102
 Generalized cross entropy loss for training deep neural networks with noisylabels,2018, In NeurIPS
