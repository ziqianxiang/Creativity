title,year,conference
 Large scale gan training for high fidelity naturalimage synthesis,2018, arXiv preprint arXiv:1809
 Wassersteincontrastive representation distillation,2020, arXiv preprint arXiv:2012
 Generative adversarial nets,2014, Advances in neural informationprocessing systems
 Distilling the knowledge in a neural network,2014, InNeurIPS
 Image-to-image translation withconditional adversarial networks,2017, In Proceedings of the IEEE conference on computer vision andpattern recognition
 Teachers do more than teach: Compressing image-to-image models,2021, In Proceedings ofthe IEEE/CVF Conference on Computer Vision and Pattern Recognition
 Perceptual losses for real-time style transfer andsuper-resolution,2016, In European conference on computer vision
 Learning to discovercross-domain relations with generative adversarial networks,2017, In International Conference on Ma-chine Learning
 Deblur-gan: Blind motion deblurring using conditional adversarial networks,2018, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Photo-realistic sin-gle image super-resolution using a generative adversarial network,2017, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Gan compression: Effi-cient architectures for interactive conditional gans,2020, In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition
 Semantic relation preserving knowledge distillation forimage-to-image translation,2020, In European Conference on Computer Vision
 Structured knowledge distillationfor dense prediction,2020, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Content-awaregan compression,2021, In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition
 Conditional generative adversarial nets,2014, arXiv preprintarXiv:1411
 Representation learning with contrastive predic-tive coding,2018, arXiv preprint arXiv:1807
 Contrastive learning for unpairedimage-to-image translation,2020, In European Conference on Computer Vision
 Relational knowledge distillation,2019, In Pro-ceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Fitnets: Hints for thin deep nets,2015, In ICLR
 Singan: Learning a generative model froma single natural image,2019, In Proceedings of the IEEE/CVF International Conference on ComputerVision
 Contrastive representation distillation,2019, arXivpreprint arXiv:1910
 Similarity-preserving knowledge distillation,2019, In Proceedings of theIEEE International Conference on Computer Vision
 Gan slimming: All-in-one gan compression by a unified optimization framework,2020, In European Conference on ComputerVision
 Video-to-video synthesis,2018, arXiv preprint arXiv:1808
 High-resolution image synthesis and semantic manipulation with conditional gans,2018, In Proceedings ofthe IEEE conference on computer vision and pattern recognition
 Esrgan: Enhanced super-resolution generative adversarial networks,2018, In Proceedingsof the European conference on computer vision (ECCV) workshops
 Dualgan: Unsupervised dual learning for image-to-image translation,2017, In Proceedings of the IEEE international conference on computer vision
 Paying more attention to attention: Improving the perfor-mance of convolutional neural networks via attention transfer,2017, In ICLR
 Improve object detection with feature-based knowledge distilla-tion: Towards accurate and efficient detectors,2021, In ICLR
 Deep mutual learning,2018, In CVPR
 Learning deepfeatures for discriminative localization,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Unpaired image-to-image translationusing cycle-consistent adversarial networks,2017, In Proceedings of the IEEE international conferenceon computer vision
