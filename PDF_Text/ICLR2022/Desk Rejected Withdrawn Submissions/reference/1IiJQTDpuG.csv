title,year,conference
 Large scale gan training for high fidelity naturalimage synthesis,2019, ArXiv
 Language models are few-shot learners,2020, ArXiv
 KgPt: Knowledge-grounded Pre-training for data-to-textgeneration,2020, In EMNLP
 Sentence moverâ€™s similarity: Automaticevaluation for multi-sentence texts,2019, In ACL
 Bert: Pre-training of deeP bidi-rectional transformers for language understanding,2019, In NAACL-HLT
 An image is worth 16x16 words: Transformers for image recognition at scale,2020, ArXiv
 Semantic noise matters for neural naturallanguage generation,2019, In INLG
 Evaluating the state-of-the-art of end-to-endnatural language generation: The e2e nlg challenge,2020, ComPut Speech Lang
 Taming transformers for high-resolution imagesynthesis,2021, In CVPR
 Mental imagery and the comprehension-monitoring perfor-mance of fourth-and fifth-grade poor readers,1986, Reading Research Quarterly
 Creating train-ing corpora for nlg micro-planners,2017, In ACL
 Clipscore: A reference-free evaluation metric for image captioning,2021, ArXiv
 Tiger: Text-to-image grounding for image caption evaluation,2019, In EMNLP
 Imagery in sentence comprehension:an fmri study,2004, NeuroImage
 A new measure of rank correlation,1938, Biometrika
 Meant 2,2017,0: Accurate semantic mt evaluation for any output language
 Yisi - a unified semantic mt quality evaluation and estimation metric for languages withdifferent levels of available resources,2019, In WMT
 From word embeddings todocument distances,2015, In ICML
 From word embeddings todocument distances,2015, In ICML
 Neural text generation from structured data withapplication to the biography domain,2016, In EMNLP
 Vil-bertscore: Evaluating image caption using vision-and-language bert,2020, In EVAL4NLP
 Stacked cross attention for image-textmatching,2018, ArXiv
 Deep recurrent generative decoder for abstractive textsummarization,2017, ArXiv
 ROUGE: A package for automatic evaluation of summaries,1013, In Text SummarizationBranches Out
 Vilbert: Pretraining task-agnostic visiolin-guistic representations for vision-and-language tasks,2019, In NeurIPS
 Mental imagery and idiom comprehension,2003, 2003
 Iter: Improving translation edit rate through optimizable edit costs,2018, In WMT
 Bleu: a method for automaticevaluation of machine translation,2002, In Proceedings of the 40th annual meeting on association forcomputational linguistics
 The heterogeneity of mental representation: Ending theimagery debate,2015, Proceedings of the National Academy of Sciences
 Languagemodels are unsupervised multitask learners,2019, 2019
 Learningtransferable visual models from natural language supervision,2021, ArXiv
 Zero-shot text-to-image generation,2021, ArXiv
 Discrete variational autoencoders,2017, ArXiv
 A dual coding view of imagery and verbal processes in reading com-prehension,1994, 1994
 Bleurt: Learning robust metrics for textgeneration,2020, In ACL
 Neural machine translation of rare words withsubword units,2016, ArXiv
 A study of translation editrate with targeted human annotation,2006, In AMTA
 Improved deep metric learning with multi-class n-pair loss objective,2016, In NIPS
 Revisiting unreasonable effectiveness ofdata in deep learning era,2017, 2017 IEEE International Conference on Computer Vision (ICCV)
 Yfcc100m: the new data in multimedia research,2016, Commun
 Accelerated dp based search for statisticaltranslation,1997, In EUROSPEECH
 Reading imaginatively: the imagination in cognitive science and cognitiveliterary studies,2013, Journal of Literary Semantics
 Representation learning with contrastive predictivecoding,2018, ArXiv
 Attention is all you need,2017, ArXiv
 Cider: Consensus-based imagedescription evaluation,2015, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Character: Translation edit rate on characterlevel,2016, In WMT
 Prophetnet: Predicting future n-gram for sequence-to-sequence pre-training,2020, ArXiv
 Bertscore: Evaluatingtext generation with bert,2020, ArXiv
