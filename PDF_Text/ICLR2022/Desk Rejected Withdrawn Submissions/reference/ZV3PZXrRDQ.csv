title,year,conference
 Explaining individual predictions when features aredependent: More accurate approximations to shapley values,2019, arXiv preprint arXiv:1903
 Explaining deep neural networks with apolynomial time algorithm for shapley value approximation,2019, In International Conference onMachine Learning
 Values of non-atomic games,2015, Princeton University Press
 Polynomial calculation of the shapley value based onsampling,2009, Computers & Operations Research
 Feature removal is a unifying principle for modelexplanation methods,2020, arXiv preprint arXiv:2011
 Understanding global feature contributions throughadditive importance measures,2020, arXiv preprint arXiv:2004
 Learning global pairwise interactions with bayesianneural networks,2019, arXiv preprint arXiv:1901
 Real time image saliency for black box classifiers,2017, arXiv preprintarXiv:1705
 Understanding deep networks via extremalperturbations and smooth masks,2019, In Proceedings of the IEEE/CVF International Conference onComputer Vision
 Interpretable explanations of black boxes by meaningful perturba-tion,2017, In Proceedings of the IEEE International Conference on Computer Vision
 Shapley explainability on the data manifold,2021, In International Conference on LearningRepresentations
 An axiomatic approach to the concept of interaction amongplayers in cooperative games,1999, International Journal of game theory
 Estimators of relative importance in linear regression based on variance decompo-sition,2007, The American Statistician
 Local rule-based explanations of black box decision systems,2018, arXiv preprintarXiv:1805
 A simplified bargaining model for the n-person cooperative game,1963, InternationalEconomic Review
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Explaining explanations: Axiomatic featureinteractions for deep networks,2020, arXiv preprint arXiv:2002
 Towards hierarchical importanceattribution: Explaining compositional semantics for neural sequence models,2019, In InternationalConference on Learning Representations
 Fair attribution offunctional contribution in artificial and biological networks,2004, Neural computation
 Learning multiple layers of features from tiny images,2009,2009
 Imagenet classification with deep con-volutional neural networks,2012, Advances in neural information processing systems
 Problemswith shapley-value-based explanations as feature importance measures,2020, In International Conferenceon Machine Learning
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Introduction to bivariate and multivariate analysis,1980, Technical report
 A unified approach to interpreting model predictions,2017, InI
 Consistent individualized feature attribution fortree ensembles,2018, arXiv preprint arXiv:1802
 The explanation game: Explaining machine learning models usingshapley values,2020, In International Cross-Domain Conference for Machine Learning and KnowledgeExtraction
 Beyond word importance: Contextual decomposition toextract interactions from lstms,2018, In International Conference on Learning Representations
 Game-theoretic understanding of adversarially learned features,2021, arXivpreprint arXiv:2103
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In Proceedings of the IEEE international conference on computer vision
 A value for n-person games,1953, Contributions to the Theory of Games
 Deep inside convolutional networks:Visualising image classification models and saliency maps,2013, arXiv preprint arXiv:1312
 Hierarchical interpretations for neural networkpredictions,2018, In International Conference on Learning Representations
 Detecting statistical interactionswith additive groves of trees,2008, In Proceedings of the 25th international conference on Machinelearning
 Explaining prediction models and individual predictions withfeature contributions,2014, Knowledge and information systems
 Explaining instance classifications withinteractions of subsets of feature values,2009, Data & Knowledge Engineering
 Visualizing the impact of feature attributionbaselines,2020, Distill
 The many shapley values for model explanation,2020, InInternational Conference on Machine Learning
 Axiomatic attribution for deep networks,2017, InProceedings of the 34th International Conference on Machine Learning-Volume 70
 Detecting statistical interactions from neural networkweights,2018, In International Conference on Learning Representations
 Understanding neuralnetworks through deep visualization,2015, In International Conference on Machine Learning
 Interpreting multivariateshapley interactions in dnns,2021, In Proceedings of the AAAI Conference on Artificial Intelligence
 Object detectorsemerge in deep scene cnns,2015, In International Conference on Learning Representations
 Learning deepfeatures for discriminative localization,2016, In Proceedings of the IEEE conference on computer visionand pattern recognition
