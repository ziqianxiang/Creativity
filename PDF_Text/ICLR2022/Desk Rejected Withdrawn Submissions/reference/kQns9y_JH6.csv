title,year,conference
 Better fine-tuning by reducing representational collapse,2020, In International Conference onLearning Representations
 A convergence theory for deep learning via over-parameterization,2019, In International Conference on Machine Learning
 Stability and generalization of learning algorithmsthat converge to global optima,2018, In International Conference on Machine Learning
 De-scribing textures in the wild,2014, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Large scale fine-grainedcategorization and domain-specific transfer learning,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Decaf: A deep convolutional activation feature for generic visual recognition,2014, In Inter-national conference on machine learning
 Learning generative visual models from few trainingexamples: An incremental bayesian approach tested on 101 object categories,2004, In 2004 conferenceon computer vision and pattern recognition workshop
 Stochastic first-and zeroth-order methods for nonconvex stochas-tic programming,2013, SIAM Journal on Optimization
 Distance-based regularisation of deep networks for fine-tuning,2020, In International Conference on Learning Representations
 Rethinking imagenet pre-training,2019, In Proceedings ofthe IEEE/CVF International Conference on Computer Vision
 Momentum contrast forunsupervised visual representation learning,2020, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Linear convergence of gradient and proximal-gradient methods under the Polyak-IojasieWicz condition,2016, In Joint European Conference on Ma-chine Learning and Knowledge Discovery in Databases
 Novel dataset for fine-grained image categorization: Stanford dogs,2011, In Proc
 3d object representations for fine-grainedcategorization,2013, In Proceedings of the IEEE international conference on computer vision work-shops
 Exponential step sizes for non-convex opti-mization,2020, arXiv preprint arXiv:2002
 A simple proximal stochastic gradient method for nonsmooth nonconvexoptimization,2018, In Advances in Neural Information Processing Systems
 Fully convolutional netWorks for semanticsegmentation,2015, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Fine-grainedvisual classification of aircraft,2013, arXiv preprint arXiv:1306
 A survey on transfer learning,2009, IEEE Transactions on knowledgeand data engineering
 Cats and dogs,2012, In 2012IEEE conference on computer vision and pattern recognition
 Sinkhorn autoencoders,2020, In Uncertainty in Artifi-cial Intelligence
 Computational optimal transport: With applications to datascience,2019, Foundations and Trends® in Machine Learning
 Gradient methods for minimizing functionals,1963, Zhurnal Vychislitel’noiMatematiki i Matematicheskoi Fiziki
 Hierarchically robust representation learning,2020, In Proceedings ofthe IEEE Conference on Computer Vision and Pattern Recognition
 Faster r-cnn: ToWards real-time objectdetection With region proposal netWorks,2015, Advances in neural information processing systems
 A stochastic approximation method,1951, The annals of mathemati-cal statistics
 The nature of statistical learning theory,2013, Springer science & business media
 A generalized loss function for crowd counting and lo-calization,2021, In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog-nition
 Sun database:Large-scale scene recognition from abbey to zoo,2010, In 2010 IEEE computer society conference oncomputer vision and pattern recognition
 Stagewise training accelerates convergenceof testing error over sgd,2019, In Advances in Neural Information Processing Systems
