title,year,conference
 Katyusha: The First Direct Acceleration of Stochastic Gradient Methods,2017, InSTOC
 Katyusha X: Practical Momentum Method for Stochastic Sum-of-Nonconvex Op-timization,2018, In Proceedings of the 35th International Conference on Machine Learning
 How To Make the Gradients Small Stochastically,2018, In Proceedings of the 32ndConference on Neural Information Processing Systems
 Hotel booking demand datasets,2019, Data in brief
 Incremental proximal methods for large scale convex optimization,2011, Mathematicalprogramming
 Ergodic convergence of a stochastic proximal point algorithm,2016, SIAM Journal onOptimization
 Stochastic model-based minimization of weakly convexfunctions,2019, SIAM Journal on Optimization
 A simple practical accelerated method for finite sums,2016, Advances in neural informationprocessing systems
 Saga: A fast incremental gradient methodwith support for non-strongly convex composite objectives,2014, In Advances in Neural InformationProcessing Systems
 Adam: A method for stochastic optimization,2014, In Proceedings of the3rd International Conference on Learning Representations
 Adaptive subgradient methods for online learning andstochastic optimization,2011, Journal of Machine Learning Research
 Stochastic methods for composite and weakly convex optimizationproblems,2018, SIAM Journal on Optimization
 Event labeling combining ensemble detectors and backgroundknowledge,2192, Progress in Artificial Intelligence
 Adaptive Filtering Theory,2002, Prentice Hall
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Faster stochastic alternating direction methodof multipliers for nonconvex optimization,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov(eds
 Accelerating stochastic gradient descent using predictive variancereduction,2013, In Advances in Neural Information Processing Systems
 Reversibility and stochastic networks,2011, Cambridge University Press
 Mnist handwritten digit database,2010,2010
 Non-convex finite-sum optimization viaScsg methods,2017, In Advances in Neural Information Processing Systems
 Learning word vectors for sentiment analysis,2011, In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics: Human Language Technologies
 Numerical optimization,2006, Springer Science & Business Media
 New nonasymptotic convergence rates of stochastic proximal point algorithm forstochastic convex optimization,2020, Optimization
 A user¡¯s guide to measure theoretic probability,2002, Number 8
 Monotone operators and the proximal point algorithm,1976, SIAM journal oncontrol and optimization
 Stochastic proximal iteration: a non-asymptotic improvement uponstochastic gradient descent,2014, Preprint
 On the importance of initializationand momentum in deep learning,2013, In International conference on machine learning
 The proximal Robbins-Monro method,2021, Journalof the Royal Statistical Society: Series B (Statistical Methodology)
 Online alternating direction method,2012, In Proceedings of the29th International Coference on International Conference on Machine Learning
 Incremental constraint projection-proximal methods fornonsmooth convex optimization,2013, SIAM J
 Fast stochastic alternating direction method of multipliers,2014, InEric P
 Adabelief optimizer: Adapting stepsizes by the belief inobserved gradients,2020, arXiv preprint arXiv:2010
