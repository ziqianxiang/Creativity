title,year,conference
 Asymmetric loss for multi-label classification,2020, arXiv preprint arXiv:2009
 Curriculum learning,2009, InProceedings ofthe 26th International Conference on Machine Learning
 Yolov4: Optimal speed andaccuracy of object detection,2020, arXiv preprint arXiv:2004
 Learning imbalanceddatasets with label-distribution-aware margin loss,2019, In Proceedings of the 33rd International Con-ference on Neural Information Processing Systems
 Superloss: A generic loss for robustcurriculum learning,2020, In 34th Conference on Neural Information Processing Systems
 Measuring and relieving theover-smoothing problem for graph neural networks from the topological view,2020, In 34th AAAIConference on Artificial Intelligence
 Fastgcn: Fast learning with graph convolu-tional networks viaimportance sampling,2018, In 6th International Conference on Learning Representations
 Local toglobal learning: Gradually adding classes for training deep neural networks,2019, In 32nd IEEE/CVFConference on Computer Vision and Pattern Recognition
 On the lambertwfunction,1996, Advances in Computational Mathematics
 Large scale fine-grainedcategorization and domain-specific transfer learning,2018, In 2018 IEEE/CVF Conference on ComputerVision and Pattern Recognition
 Class-balanced loss basedon effective number of samples,2019, In 2019 IEEE Conference on Computer Vision and PatternRecognition
 A unified bias-variance decomposition for zero-one and squared loss,2000, In Proceed-ings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference onInnovative Applications of Artificial Intelligence
 Learning to teach,2018, In 6th Interna-tional Conference on Learning Representations
 Experiments with a new boosting algorithm,1996, In MachineLearning: Proceedings of the Thirteenth International Conference
 Training deep neural-networks using a noise adaptationlayer,2017, In 5th International Conference on Learning Representations
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, In32nd Conference on Neural Information Processing Systems
 Deep residual learning for image recog-nition,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Densely connectedconvolutional networks,2017, In 2017 IEEE Conference on Computer Vision and Pattern Recognition
 Adaptive sampling towards fastgraph representation learning,2018, In 32nd Conference on Neural Information Processing Systems
 Easy samples first: Self-paced reranking for zero-example multimedia search,2014, In 2014 ACM Conference on Multimedia
 Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels,2018, In Proceedings of the 35thInternational Conference on Machine Learning
 Dcnns on a diet: Sampling strategies forreducing the training set size,2016, arXiv preprint arXiv:1606
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Learning from long-tailed data withnoisy labels,2021, arXiv preprint arXiv:2108
 Not all samples are created equal: Deep learning withimportance sampling,2018, In Proceedings of the 35th International Conference on Machine Learning
 Adam: A method for stochastic optimization,2015, In 3rdInternational Conference on Learning Representations
 Learning multiple layers of features from tiny images,2009, MIT Press
 Gradient harmonized single-stage detector,2019, In 33rd AAAIConference on Artificial Intelligence
 Metasaug:Meta semantic augmentation for long-tailed visual recognition,2021, arXiv preprint arXiv:2103
 Focal loss for dense objectdetection,2017, In 2017 IEEE International Conference on Computer Vision
 Just train twice: Improving group robustness withouttraining group information,2021, arXiv preprint arXiv:2107
 Online batch selection for faster training of neural net- works,2016, InProceedings of the 33th International Conference on Machine Learning
 Dimensionality-driven learning with noisy labels,2018, In Proceedingsof the 35th International Conference on Machine Learning
 The pascal visual object classes challenge: A retrospective,2015, InternationalJournal of Computer Vision
 Training deep neural networks on noisy labels with bootstrapping,2015, In 3rd Interna-tional Conference on Learning Representations
 Learning to reweight examples forrobust deep learning,2018, In 6th International Conference on Learning Representations
 Learning to reweight examples forrobust deep learning,2018, In Proceedings of the 35th International Conference on Machine Learning
 Dropedge: Towards deepgraph convolutional networks on node classification,2020, In 8th International Conference on LearningRepresentations
 Low: Training deep neural networks by learning optimal sample weights,2021, PatternRecognition
 Hypergeometric functions and their applications,1991, Springer-Verlag
 Pit-falls of graph neural network evaluation,2018, In 32nd Conference on Neural Information ProcessingSystems
 Meta-weight-net: Learning an explicit mapping for sample weighting,2019, In 33rd Annual Conference on NeuralInformation Processing Systems
 Going deeper with convolutions,2015, In2015 IEEE Conference on Computer Vision and Pattern Recognition
 Equalization loss for long-tailed object recognition,2020, In 2020 IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Visualizing data using t-sne,2008, Journal of MachineLearning Research
 Denoising implicit feed-back for recommendation,2021, In Proceedings of the Fourteenth ACM International Conference onWeb Search and Data Mining
 A survey on curriculum learning,2021, IEEE Transactionson Pattern Analysis and Machine Intelligence
 Self-paced balance learning for clinical skin disease recognition,2020, IEEE Transactions onPattern Analysis and Machine Intelligence
 Revisiting semi-supervised learningwith graph embeddings,2016, In Proceedings of the 33th International Conference on Machine Learn-ing
 Rethinking bias-variance trade-off for generalization of neural networks,2020, In Proceedings of the 37the International Conferenceon Machine Learning
 Wide residual networks,2016, In Proceedings of the BritishMachine Vision Conference
 Understandingdeep learning requires rethinking generalization,2017, In 5th International Conference on LearningRepresentations
 mixup: Beyond empir-ical risk minimization,2018, In 6th International Conference on Learning Representations
 Distribution alignment: Aunified framework for long-tail visual recognition,2021, arXiv preprint arXiv:2103
 Learning fast sample re-weighting without reward data,2021, arXivpreprint arXiv:2109
 Stochastic optimization with importance sampling,2015, In Proceedings ofthe 32th International Conference on Machine Learning
 Self-paced learning for imbalanced data,2016, InAsian Conference on Intelligent Information and Database Systems
