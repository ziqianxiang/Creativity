title,year,conference
 Research on chinese naming recognition model based on bert embedding,2019, In 2019 IEEE10th International Conference on Software Engineering and Service Science (ICSESS)
 Named entity recognition with long short-term memory,2003, In Proceedings of theseventh conference on Natural language learning at HLT-NAACL 2003
 F-score driven max margin neural network for named entity recognitionin chinese social media,2017, In Proceedings of the 15th Conference of the European Chapter of theAssociation for Computational Linguistics: Volume 2
 Bidirectional lstm-crf models for sequence tagging,2015, arXive-prints
 Bert: Pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of NAACL-HLT
 The third international chinese language processing bakeoff: Word segmenta-tion and named entity recognition,2006, In Proceedings of the Fifth SIGHAN Workshop on ChineseLanguage Processing
 Efficient estimation of word represen-tations in vector space,2013, Computer Science
 Named entity recognition for chinese social media with jointlytrained embeddings,2015, In Proceedings of the 2015 Conference on Empirical Methods in NaturalLanguage Processing
 Learning chinese word representations from glyphs of characters,2017, InProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Incorporating lexicon and characterglyph and morphological features into bilstm-crf for chinese medical ner,2021, In 2021 IEEE Inter-national Conference on Consumer Electronics and Computer Engineering (ICCECE)
 Smedbert: A knowledge-enhanced pre-trainedlanguage model with structured semantics for medical text mining,2021, In Proceedings of the 59thAnnual Meeting of the Association for Computational Linguistics and the 11th International JointConference on Natural Language Processing (Volume 1: Long Papers)
 Chinese ner using lattice lstm,2018, In Proceedings of the 56th Annual Meetingof the Association for Computational Linguistics (Volume 1: Long Papers)
