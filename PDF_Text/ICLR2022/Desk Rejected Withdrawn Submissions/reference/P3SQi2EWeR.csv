title,year,conference
 Designing neural network architec-tures using reinforcement learning,2017, In 5th International Conference on Learning Representations
 Under-standing and simplifying one-shot architecture search,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 SMASH: one-shot modelarchitecture search through hypernetworks,2018, In 6th International Conference on Learning Repre-sentations
 Proxylessnas: Direct neural architecture search on target taskand hardware,2019, In 7th International Conference on Learning Representations
 Once-for-all: Train onenetwork and specialize it for efficient deployment,2020, In 8th International Conference on LearningRepresentations
 Progressive differentiable architecture search: Bridgingthe depth gap between search and evaluation,2019, In IEEE International Conference on ComputerVision
 XcePtion: Deep learning with depthwise separable convolutions,2017, In IEEE Confer-ence on Computer Vision and Pattern Recognition
 Fairnas: Rethinking evaluation fairness ofweight sharing neural architecture search,2019, arXiv preprint arXiv:1907
 Evolvingsearch space for neural architecture search,2020, arXiv preprint arXiv:2011
 Deformableconvolutional networks,2017, In IEEE International Conference on Computer Vision
 Imagenet: A large-scalehierarchical image database,2009, In IEEE Computer Society Conference on Computer Vision andPattern Recognition
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 Acnet: Strengthening the kernelskeletons for powerful CNN via asymmetric convolution blocks,2019, In IEEE International Conferenceon Computer Vision
 Efficient multi-objective neural architecturesearch via lamarckian evolution,2019, In 7th International Conference on Learning Representations
 Deformable kernels: Adapting effective recep-tive fields for object deformation,2020, In 8th International Conference on Learning Representations
 Singlepath one-shot neural architecture search with uniform sampling,2019, arXiv preprint arXiv:1904
 Learning both weights and connections forefficient neural networks,2015, arXiv preprint arXiv:1506
 Deep residual learning for imagerecognition,2016, In IEEE Conference on Computer Vision and Pattern Recognition
 Identity mappings in deep residualnetworks,2016, In Proceedings of the European Conference on Computer Vision
 MobileNets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Densely connectedconvolutional networks,2017, In IEEE Conference on Computer Vision and Pattern Recognition
 Adam: A method for stochastic optimization,2015, In 3rd InternationalConference on Learning Representations
 Learning multiple layers of features from tiny images,2009, Tech Report
 Imagenet classification with deep convolu-tional neural networks,2012, In 26th Annual Conference on Neural Information Processing Systems
 Fractalnet: Ultra-deep neural networkswithout residuals,2017, In 5th International Conference on Learning Representations
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Deeply-supervised nets,2015, In Proceedings of the Eighteenth International Conference on Artificial Intelli-gence and Statistics
 Selective kernel networks,2019, In IEEE Conferenceon Computer Vision and Pattern Recognition
 Progressive neural architecture search,2018, In Proceedingsof the European Conference on Computer Vision
 Hi-erarchical representations for efficient architecture search,2018, In 6th International Conference onLearning Representations
 DARTS: differentiable architecture search,2019, In 7thInternational Conference on Learning Representations
 Understanding the effective recep-tive field in deep convolutional neural networks,2016, In Annual Conference on Neural InformationProcessing Systems
 ShuffleNet V2: Practical guidelines forefficient cnn architecture design,2018, In Proceedings of the European Conference on Computer Vision
 Simplifying convnets for fast learning,2012, In InternationalConference on Artificial Neural Networks
 Object class recognition and localization using sparse features withlimited receptive fields,2008, International Journal of Computer Vision
 XNAS:neural architecture search with expert advice,2019, In Annual Conference on Neural InformationProcessing Systems
 Large kernel matters - improvesemantic segmentation by global convolutional network,2017, In IEEE Conference on Computer Visionand Pattern Recognition
 Large-scale evolution of image classifiers,2017, In Proceedings of the 34thInternational Conference on Machine Learning
 Regularized evolution for imageclassifier architecture search,2019, In The Thirty-Third AAAI Conference on Artificial Intelligence
 Natural image statistics and neural representation,2001, Annualreview of neuroscience
 Very deep convolutional networks for large-scale imagerecognition,2015, In 3rd International Conference on Learning Representations
 Going deeper with convolutions,2015, InIEEE Conference on Computer Vision and Pattern Recognition
 Genetic CNN,2017, In IEEE International Conference on Computer Vision
 PC-DARTS: partial channel connections for memory-efficient architecture search,2020, In 8th InternationalConference on Learning Representations
 Greedynas:Towards fast one-shot NAS with greedy supernet,2020, In IEEE Conference on Computer Vision andPattern Recognition
 Multi-scale context aggregation by dilated convolutions,2016, In 4thInternational Conference on Learning Representations
 Bignas: Scaling up neural architec-ture search with big single-stage models,2020, In Proceedings of the European Conference on ComputerVision
 Wide residual networks,2016, In Proceedings of the BritishMachine Vision Conference 2016
 Shufflenet: An extremely efficientconvolutional neural network for mobile devices,2018, In IEEE Conference on Computer Vision andPattern Recognition
 Bayesnas: A bayesian approach for neuralarchitecture search,2019, In Proceedings of the 36th International Conference on Machine Learning
 Neural architecture search with reinforcement learning,2017, In 5thInternational Conference on Learning Representations
 Learning transferable architecturesfor scalable image recognition,2018, In IEEE Conference on Computer Vision and Pattern Recognition
 We apply the SGD optimizer with an initial learning rate of 0,2017,025(annealed down to zero following a cosine schedule without restart)
