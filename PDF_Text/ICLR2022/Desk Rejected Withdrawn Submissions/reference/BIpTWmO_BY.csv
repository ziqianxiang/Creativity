title,year,conference
 Deep learning with differential privacy,2016, In Proceedings of the 2016 ACM SIGSACconference on computer and communications security
 How tobackdoor federated learning,2020, In International Conference on Artificial Intelligence and Statistics
 Poisoning attacks against support vector ma-chines,2012, arXiv preprint arXiv:1206
 Dp-instahide: Provably defusing poisoning andbackdoor attacks with differentially private data augmentations,2021, arXiv preprint arXiv:2103
 Detecting backdoor attacks on deep neural networks byactivation clustering,2018, arXiv preprint arXiv:1811
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Learning to confuse: generating training time adversarialdata with auto-encoder,2019, arXiv preprint arXiv:1905
 Preventing unauthorized use of proprietary data: Poisoning for secure datasetrelease,2021, arXiv preprint arXiv:2103
 Witchesâ€™ brew: Industrial scale data poisoning via gradient matching,2020, arXivpreprint arXiv:2009
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint arXiv:1708
 Unlearnableexamples: Making personal data unexploitable,2021, arXiv preprint arXiv:2101
 Metapoison: Prac-tical general-purpose clean-label data poisoning,2020, arXiv preprint arXiv:2004
 Invisiblebackdoor attacks against deep neural networks,2019, arXiv preprint arXiv:1909
 Invisible backdoorattacks on deep neural networks via steganography and regularization,2020, IEEE Transactions onDependable and Secure Computing
 Towards Poisoning of Deep Learning Algorithms with Back-gradient Optimization,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Imagenet large scale visualrecognition challenge,2015, International journal of computer vision
 Hidden trigger backdoor at-tacks,2019, arXiv preprint arXiv:1910
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Justhow toxic is data poisoning? a unified benchmark for backdoor and data poisoning attacks,2020, arXivpreprint arXiv:2006
 Tensorclog: An imperceptible poisoning attack on deepneural network applications,2019, IEEE Access
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Certified Defenses for Data PoisoningAttacks,2017, In Advances in Neural Information Processing Systems 30
 Spectral signatures in backdoor attacks,2018, arXivpreprint arXiv:1811
 Neural cleanse: Identifying and mitigating backdoor attacks in neural networks,2019, In 2019IEEE Symposium on Security and Privacy (SP)
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
