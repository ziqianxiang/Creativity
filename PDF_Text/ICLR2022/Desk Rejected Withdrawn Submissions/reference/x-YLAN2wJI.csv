title,year,conference
 Random fourier features for kernel ridge regression: Approximation bounds and statisticalguarantees,2017, In ICML
 Variance-invariance-covariance regularization forself-supervised learning,2021, arXiv preprint arXiv:2105
 Mutual information neural estimation,2018, In International Conferenceon Machine Learning
 A simple frameworkfor contrastive learning of visual representations,2020, In ICML
 Exploring simple siamese representation learning,2020, arXiv preprintarXiv:2011
 Rethinking attentionwith performers,2020, In ICLR
 Debi-ased contrastive learning,2020, In NeurIPS
 BERT: pre-training of deepbidirectional transformers for language understanding,2019, In NACAL
 Learning robustrepresentations via multi-view information bottleneck,2020, In ICLR
 Simcse: Simple contrastive learning of sentenceembeddings,2021, arXiv preprint arXiv:2104
 Bootstrap your own latent - Anew approach to self-supervised learning,2020, In NeurIPS
 Deep residual learning for imagerecognition,2016, In CVPR
 Momentum contrast forunsupervised visual representation learning,2020, In CVPR
 Learning deep representations by mutual information estimationand maximization,2019, In ICLR
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Fastfood-approximating kernel expansions in loglineartime,2013, In ICML
 Self-supervised learning withkernel dependence maximization,2021, arXiv preprint arXiv:2106
 Unsupervised learning of visual representations by solving jigsawpuzzles,2016, In ECCV
 On variationalbounds of mutual information,2019, In ICML
 Byol works even withoutbatch statistics,2020, arXiv preprint arXiv:2010
 Contrastive learning withhard negative samples,2021, In ICLR
 The deterministic information bottleneck,2016, In UAI
 Understanding self-supervised learning dynamicswithout contrastive pairs,2021, In ICML
 Deep learning and the information bottleneck principle,2015, In ITW
 Self-supervisedlearning from a multi-view perspective,2021, In ICLR
 On mutualinformation maximization for representation learning,2019, In ICLR
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 Understanding contrastive representation learning through align-ment and uniformity on the hypersphere,2020, In ICML
 Graphcontrastive learning with augmentations,2020, In NeurIPS
 Orthogonal random features,2016, In NIPS
 BarloW twins: Self-supervisedlearning via redundancy reduction,2021, In ICML
 From canonical correlationanalysis to self-supervised graph neural networks,2021, arXiv preprint arXiv:2106
 Large-scale kernel methods forindependence testing,2018, Statistics and Computing
 Deep graph contrastiverepresentation learning,2020, arXiv preprint arXiv:2006
