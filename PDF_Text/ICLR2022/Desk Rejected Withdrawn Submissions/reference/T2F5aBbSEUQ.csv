title,year,conference
 Gradient based sample selectionfor online continual learning,2019, In Advances in Neural Information Processing Systems
 Scail: Classifier weights scaling for class incremental learn-ing,2020, In The IEEE Winter Conference on Applications of Computer Vision
 Random search for hyper-parameter optimization,2012, Journal ofmachine learning research
 Flexible dataset distillation: Learn labelsinstead of images,2020, Neural Information Processing Systems Workshop
 Coresets via bilevel optimization for continuallearning and streaming,2020, NeurIPS
 Super-samples from kernel herding,2010, The Twenty-SixthConference Annual Conference on Uncertainty in Artificial Intelligence
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, ArXiv
 Imagenet classification with deep convo-Iutional neural networks,2012, In Advances in neural information processing Systems
 Tiny imagenet visual recognition challenge,2015, CS 231N
 Optimal brain damage,1990, In Advances in neuralinformation processing systems
 Rectified linear units improve restricted boltzmann machines,2010, InProceedings of the 27th international conference on machine learning (ICML-10)
 Dataset meta-learning from kernel-ridgeregression,2021, In International Conference on Learning Representations
 icarl:Incremental classifier and representation learning,2017, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 On random weights and unsupervised feature learning,2011, In Icml
 Active learning for convolutional neural networks: A core-setapproach,2018, ICLR
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Genera-tive teaching networks: Accelerating neural architecture search by learning to generate synthetictraining data,2020, International Conference on Machine Learning (ICML)
 An empirical study of example forgetting during deep neural networklearning,2019, ICLR
 Instance normalization: The missing in-gredient for fast stylization,2016, arXiv preprint arXiv:1607
 Visualizing data using t-sne,2008, Journal of machinelearning research
 Dataset distillation,2018, arXivpreprint arXiv:1811
 Querying discriminative and representative samples for batch modeactive learning,2015, ACM Transactions on Knowledge Discovery from Data (TKDD)
 Herding dynamical weights to learn,2009, In Proceedings of the 26th Annual InternationalConference on Machine Learning
 Nas-bench-101: Towards reproducible neural architecture search,2019, In International Conference onMachine Learning
 Dataset condensation with differentiable siamese augmentation,2021, InInternational Conference on Machine Learning
 Dataset condensation with gradient matching,2021, InInternational Conference on Learning Representations
