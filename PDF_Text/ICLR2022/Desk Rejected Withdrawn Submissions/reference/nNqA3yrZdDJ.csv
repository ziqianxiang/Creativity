title,year,conference
 A convergence theory for deep learning via over-parameterization,2019, In International Conference on Machine Learning
 Onexact computation with an infinitely wide neural net,2019, arXiv preprint arXiv:1904
 Fit without fear: remarkable mathematical phenomena of deep learning through theprism of interpolation,2021, arXiv preprint arXiv:2105
 Neuro-dynamic programming: an overview,1995, In Pro-ceedings of 1995 34th IEEE Conference on Decision and Control
 Generalization bounds of stochastic gradient descent for wide anddeep neural networks,2019, Advances in Neural Information Processing Systems
 Gradient descent findsglobal minima of deep neural networks,2019, In ICML
 Gradient descent provably optimizesover-parameterized neural networks,2019, In ICLR (Poster)
 Minimax-optimal off-policy evaluation with linear function approx-imation,2020, CoRR
 Risk bounds and rademacher complexity in batch reinforcementlearning,2021, arXiv preprint arXiv:2103
 Doubly robust policy evaluation and learning,2011, arXivpreprint arXiv:1103
 More robust doubly robustoff-policy evaluation,2018, arXiv preprint arXiv:1802
 Deep neural networks for estimation andinference: Application to causal effects and other semiparametric estimands,2018, arXiv preprintarXiv:1809
 Mod-elling transition dynamics in mdps with RKHS embeddings,2012, In ICML
 A Distribution-Free Theory ofNonparametric Regression,2002, Springer series in statistics
 Finite depth and width corrections to the neural tangent kernel,2019, arXivpreprint arXiv:1909
 Provably efficient reinforcementlearning with linear function approximation,2137, In Conference on Learning Theory
 Gaus-sian processes and kernel methods: A review on connections and equivalences,2018, arXiv preprintarXiv:1807
 Density estimation in besov spaces,1992, Statistics &amp;probability letters
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Conservative q-learning for offlinereinforcement learning,2020, arXiv preprint arXiv:2006
 Least-squares policy iteration,2003, J
 Batch reinforcement learning,2012, In Reinforce-ment learning
 Batch policy learning under constraints,2019, InICML
 Local rademacher complexity bounds based on coveringnumbers,2016, Neurocomputing
 Breaking the curse of horizon: Infinite-horizon off-policy estimation,2018, In NeurIPS
 Human-levelcontrol through deep reinforcement learning,2015, nature
 Error bounds for approximate policy iteration,2003, In ICML
 Algaedice:Policy gradient from arbitrary experience,2019, ArXiv
 On the proof of global convergence of gradient descent for deep relu networks withlinear widths,2021, arXiv preprint arXiv:2101
 Bracketing metric entropy rates and empirical central limit theoremsfor function classes of besov- and sobolev-type,2007, Journal of Theoretical Probability
 Eligibility traces for off-policy policyevaluation,2000, In Proceedings of the Seventeenth International Conference on Machine Learning
 Bridging offline rein-forcement learning and imitation learning: A tale of pessimism,2021, arXiv preprint arXiv:2103
 Cog:Connecting new skills to past experience with offline reinforcement learning,2020, arXiv preprintarXiv:2010
 Adaptivity of deep relu network for learning in besov and mixed smooth besov spaces:optimal rate and curse of dimensionality,2018, arXiv preprint arXiv:1810
 Data-efficient off-policy policy evaluation for reinforcementlearning,2016, In International Conference on Machine Learning
 Combiningonline learning and offline learning for contextual bandits with deficient support,2021, arXiv preprintarXiv:2107
 Theory of function spaces,1983, 1983
 Empirical study of off-policy policyevaluation for reinforcement learning,2019, arXiv preprint arXiv:1911
 Provably efficient reinforcement learningwith general value function approximation,2020, CoRR
 Optimism in reinforce-ment learning with generalized linear function approximation,2019, CoRR
 A theoretical analysis of deep q-learning,2019, CoRR
 Error bounds for approximations with deep relu networks,2017, Neural Networks
 Near-optimal provable uniform convergence in offlinepolicy evaluation for reinforcement learning,2021, In Arindam Banerjee and Kenji Fukumizu (eds
 Gendice: Generalized offline estimation ofstationary values,2020, ArXiv
 Gradientdice: Rethinking generalized offlineestimation of stationary values,2020, ArXiv
