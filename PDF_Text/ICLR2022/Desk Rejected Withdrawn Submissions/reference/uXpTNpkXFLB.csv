title,year,conference
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PloS one
 Explicability? legibility? predictability? transparency? privacy? security? the emerginglandscape of interpretable agent behavior,2019, In Proceedings of the international conference on au-tomated planning and ScheduIing
 Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks,2018, In 2018IEEE winter conference on applications of computer vision (WACV)
 Cameras:Enhanced resolution and sanity preserving class activation mapping for image saliency,2021, In Pro-ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
 Guided integrated gradients: An adaptive path method for removing noise,2021, In Proceed-ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
 Interpreting interpretability: Understanding data scientistsâ€™ use of interpretabilitytools for machine learning,2020, In Proceedings of the 2020 CHI Conference on Human Factors inComputing Systems
 Learning how to explain neural networks: Patternnet and patternat-tribution,2017, arXiv preprint arXiv:1705
 Sub-gaussian estimators of the mean of a random vector,2019, Theannals of statistics
 Salient deconvolutional networks,2016, In European Confer-ence on Computer Vision
 Explaining nonlinear classification decisions with deep taylor decomposition,2017, PatternRecognition
 There and back again: Revisitingbackpropagation saliency methods,2020, In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition
 Evaluating the visualization of what a deep neural network has learned,2016, IEEE transactionson neural networks and learning systems
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In Proceedings of the IEEE international conference on computer vision
 Learning important features throughpropagating activation differences,2017, In International Conference on Machine Learning
 Deep inside convolutional networks: Vi-sualising image classification models and saliency maps,2013, arXiv preprint arXiv:1312
 When explanations lie: Why many modified bpattributions fail,2020, In International Conference on Machine Learning
 Smoothgrad:removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Striving forsimplicity: The all convolutional net,2014, arXiv preprint arXiv:1412
 Fooling network interpretation inimage classification,2019, In Proceedings of the IEEE/CVF International Conference on ComputerVision
 Axiomatic attribution for deep networks,2017, InInternational Conference on Machine Learning
 Con-trastive relevance propagation for interpreting predictions by a single-shot object detector,2019, In 2019International Joint Conference on Neural Networks (IJCNN)
 Score-cam: Score-weighted visual explanations for convolutional neural networks,2020, InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Work-shops
 Bias also matters: Bias attribution for deep neuralnetwork explanation,2019, In International Conference on Machine Learning
 On predictability of time series,2019, Physica A:Statistical Mechanics and its Applications
 Visualizing and understanding convolutional networks,2014, InEuropean conference on computer vision
 Learning deepfeatures for discriminative localization,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
