title,year,conference
 Bert: Pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 Text processing like humans do:Visually attacking and shielding NLP systems,1634, In Proceedings of the 2019 Conference of theNorth American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Competency problems: On finding and removing artifacts in language data,2021, arXivpreprint arXiv:2104
 Robustness gym: Unifying the nlp evaluation landscape,2021, In Proceedings Ofthe 2021 Confer-ence of the North American Chapter of the Association for Computational Linguistics: HumanLanguage Technologies: Demonstrations
 Tradeoffs in dataaugmentation: An empirical study,2020, In International Conference on Learning Representations
 Annotation artifacts in natural language inference data,2018, In Proceedings of the2018 Conference of the North American Chapter of the Association for Computational Linguis-tics: Human Language Technologies
 Using pre-training can improve model robustnessand uncertainty,2019, In International Conference onMachine Learning
 Quantifying the evaluation of heuristic methods for textual dataaugmentation,2020, In Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT2020)
 Learning the difference that makes a differ-ence with counterfactually-augmented data,2019, In International Conference on Learning Represen-tations
 Contextual augmentation: Data augmentation by words with paradigmatic rela-tions,2018, In Proceedings of the 2018 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 Improving neural machine translation robustness via data augmen-tation: Beyond back-translation,2019, In Proceedings of the 5th Workshop on Noisy User-generatedText (W-NUT 2019)
 NeuralClassifier: An open-source neural hierarchical multi-label text classificationtoolkit,2019, In Proceedings of the 57th Annual Meeting of the Association for Computational Lin-guistics: System Demonstrations
 Recurrent neural network for text classificationwith multi-task learning,2016, In Proceedings of the Twenty-Fifth International Joint Conference onArtificial Intelligence
 Everything has a cause: Lever-aging causal inference in legal text analysis,2021, In Proceedings of the 2021 Conference of the NorthAmerican Chapter of the Association for Computational Linguistics: Human Language Technolo-gies
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Predicting inductive biases of pre-trained models,2020, In International Conference on Learning Representations
 Right for the wrong reasons: Diagnosing syntacticheuristics in natural language inference,2019, In Proceedings of the 57th Annual Meeting of the Asso-ciation for Computational Linguistics
 Syntactic dataaugmentation increases robustness to inference heuristics,2020, In Proceedings of the 58th AnnualMeeting of the Association for Computational Linguistics
 Introduction to causal inference from a machine learning perspective,2020, Course Lec-ture Notes (draft)
 Seeing stars: exploiting class relationships for sentiment categorizationwith respect to rating scales,2005, In Proceedings of the 43rd Annual Meeting on Association forComputational Linguistics
 Leveraging random label memorization for unsupervised pre-training,2018, arXiv preprintarXiv:1811
 Beyond accuracy: Be-havioral testing of nlp models with checklist,2020, In Proceedings of the 58th Annual Meeting of theAssociation for Computational Linguistics
 Apac: Augmented pattern classification withneural networks,2015, arXiv preprint arXiv:1505
 Code-mixing on sesame street: Dawn of the adversarial poly-glots,3596, In Proceedings of the 2021 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 An empirical study on robustness to spuriouscorrelations using pre-trained language models,2020, Transactions of the Association for Computa-tional Linguistics
 Counterfactual invari-ance to spurious correlations: Why and how to pass stress tests,2021, arXiv preprint arXiv:2106
 Textflint: Unified multilingual robustness eval-uation toolkit for natural language processing,2021, In Proceedings of the 59th Annual Meeting ofthe Association for Computational Linguistics and the 11th International Joint Conference onNatural Language Processing: System Demonstrations
 Identifying spurious correlations for robust text classification,2020, InProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:Findings
 Eda: Easy data augmentation techniques for boosting performance on textclassification tasks,2019, In Proceedings of the 2019 Conference on Empirical Methods in NaturalLanguage Processing and the 9th International Joint Conference on Natural Language Process-ing (EMNLP-IJCNLP)
 A broad-coverage challenge corpus for sen-tence understanding through inference,2018, In Proceedings of the 2018 Conference of the North Amer-ican Chapter of the Association for Computational Linguistics: Human Language Technologies
 Transformers: State-of-the-art naturallanguage processing,2020, In Proceedings of the 2020 Conference on Empirical Methods in Natu-ral Language Processing: System Demonstrations
