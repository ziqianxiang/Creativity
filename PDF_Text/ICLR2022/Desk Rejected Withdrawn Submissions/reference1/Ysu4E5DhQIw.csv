title,year,conference
 Unified pre-trainingfor program understanding and generation,2021, In Proceedings of the 2021 Conference of theNorth American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Program synthesis with large languagemodels,2021, arXiv preprint arXiv:2108
 Frozen in time: A joint video andimage encoder for end-to-end retrieval,2021, In IEEE International Conference on Computer Vision
 When deep learningmet code search,2019, In Proceedings of the 2019 27th ACM Joint Meeting on European SoftwareEngineering Conference and Symposium on the Foundations of Software Engineering
 Evaluating large language modelstrained on code,2021, arXiv preprint arXiv:2107
 A simple framework forcontrastive learning of visual representations,2020, In International conference on machine learning
 BERT: Pre-training of deepbidirectional transformers for language understanding,4171, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 CodeBERT: A pre-trained model for programmingand natural languages,2020, In Findings of the Association for Computational Linguistics: EMNLP2020
 Codebert: A pre-trained model for programming and naturallanguages,2020, arXiv preprint arXiv:2002
 Deep code search,2018, In 2018 IEEE/ACM 40thInternational Conference on Software Engineering (ICSE)
 Graphcodebert: Pre-training code representations withdata flow,2021, ICLR 2021
 Noise-contrastive estimation: A new estimation principlefor unnormalized statistical models,2010, In Proceedings of the thirteenth international conference onartificial intelligence and statistics
 Align before fuse: Vision and language representation learning with momentumdistillation,2021, In NeurIPS
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Codexglue: A machine learning benchmarkdataset for code understanding and generation,2021, arXiv preprint arXiv:2102
 Thinkingfast and slow: Efficient text-to-visual retrieval with transformers,2021, In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition
 Intellicode compose:Code generation using transformer,2020, In Proceedings of the 28th ACM Joint Meeting on EuropeanSoftware Engineering Conference and Symposium on the Foundations of Software Engineering
 Attention is all you need,2017, In Isabelle Guyon
 Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation,2021, 2021b
 In-ide code generation from natural language:Promise and challenges,2021, arXiv preprint arXiv:2101
 From word embeddings to documentsimilarities for improved information retrieval in software engineering,2016, In Proceedings of the 38thinternational conference on software engineering
