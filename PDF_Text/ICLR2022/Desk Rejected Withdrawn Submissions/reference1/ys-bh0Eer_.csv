title,year,conference
 Policy and valuetransfer in lifelong reinforcement learning,2018, In Jennifer Dy and Andreas Krause (eds
 Combining physical simUlators and object-based networks for control,2019, In 2019International Conference on Robotics and Automation (ICRA)
 Online continUal learning with maximally interfered retrieval,2019, arXiv preprintarXiv:1908
 ModUlar mUltitask reinforcement learning with policysketches,2017, In International Conference on Machine Learning
 Lipschitz continUity in model-based re-inforcement learning,2018, In Jennifer Dy and Andreas KraUse (eds
 Robust locally-linear controllable embed-ding,2018, In International Conference on Artificial Intelligence and Statistics
 Successor features for transfer in reinforcement learning,2016, arXiv preprintarXiv:1606
 Dynamic Programming,1957, Princeton University Press
 Multitask learning,1997, Machine learning
 On tiny episodic memories in continuallearning,2019, arXiv preprint arXiv:1902
 Hardware conditioned policies for multi-robot transfer learning,2018, arXiv preprint arXiv:1811
 Learning modularneural network policies for multi-task and multi-robot transfer,2017, In 2017 IEEE internationalconference on robotics and automation (ICRA)
 Stochastic processes,53, John Wiley & Sons
 Hidden Parameter Markov Decision Processes: A Semi-parametric Regression Approach for Discovering Latent Task Parametrizations,1308, arXiv:1308
 Multiple model-basedreinforcement learning,2002, Neural computation
 Visualforesight: Model-based deep reinforcement learning for vision-based robotic control,2018, arXivpreprint arXiv:1812
 Metrics for finite markov decision processes,2004, InProceedings of the 20th Conference on Uncertainty in Artificial Intelligence
 Bisimulation metrics for continuous markovdecision processes,97, SIAM J
 Model-agnostic meta-learning for fast adaptation ofdeep networks,2017, In Proceedings of the 34th International Conference on Machine Learning-Volume70
 Learning visual predictivemodels of physics for playing billiards,2015, arXiv preprint arXiv:1511
 A survey on concept drift adaptation,2014, ACM Comput
 Embracing change: Continuallearning in deep neural networks,2020, Trends in Cognitive Sciences
 Learning latent dynamics for planning from pixels,2019, In International Conference onMachine Learning
 Variational recurrent models for solving partially observablecontrol tasks,2019, arXiv preprint arXiv:1912
 Meta reinforcement learning as task inference,2019, arXiv preprint arXiv:1905
 Deep variationalreinforcement learning for PomdPs,2018, In International Conference on Machine Learning
 Meta-learning representations for continual learning,2019, arXivpreprint arXiv:1905
 Abstraction selection in model-based reinforcementlearning,2015, In International Conference on Machine Learning
 Planning and acting in partiallyobservable stochastic domains,1998, Artificial intelligence
 Learning adaptive exploration strategies in dynamic environments throughinformed policy regularization,2020, arXiv preprint arXiv:2005
 Continual reinforcement learning withcomplex synapses,2018, In International Conference on Machine Learning
 The marabou framework forverification and analysis of deep neural networks,2019, In International Conference on Computer AidedVerification
 Towards continual reinforcementlearning: A review and perspectives,2020, arXiv preprint arXiv:2012
 Context-aware dynamicsmodel for generalization in model-based reinforcement learning,2020, In Hal DaUme III and AartiSingh (eds
 Perspectives on system identification,1367, Annual Reviews in Control
 Modular universal reparameterization: Deep multi-tasklearning across diverse domains,2019, arXiv preprint arXiv:1906
 Markov Chains and Stochastic Stability,1993, Springer-Verlag
 A simple neural attentive meta-learner,2017, arXiv preprint arXiv:1707
 No-regret exploration in contextual reinforcement learning,2020, InConference on Uncertainty in Artificial Intelligence
 Markov decision processes withcontinuous side information,2018, In Algorithmic Learning Theory
 Deep online learning via meta-learning: Con-tinual adaptation for model-based RL,2019, In International Conference on Learning Representations
 Learning complex motions by sequencingsimpler motion templates,2009, In Proceedings of the 26th Annual International Conference on MachineLearning
 Automatic differentiation inpytorch,2017,2017
 Curiosity-driven explorationby self-supervised prediction,2778, In International Conference on Machine Learning
 Terrain-adaptive locomotion skills usingdeep reinforcement learning,2016, ACM Transactions on Graphics (TOG)
 Generalized Hidden ParameterMDPs:Transferable Model-Based RL in a Handful of Trials,2020, Proceedings of the AAAI Conferenceon Artificial Intelligence
 Markov decision processes: Discrete stochastic dynamic programming,1995, Journalof the Operational Research Society
 Languagemodels are unsupervised multitask learners,2019, OpenAI Blog
 Epopt: Learningrobust neural network policies using model ensembles,2016, arXiv preprint arXiv:1610
 Efficient off-policymeta-reinforcement learning via probabilistic context variables,2019, In Kamalika Chaudhuri and RuslanSalakhutdinov (eds
 Continual learning in reinforcement environments,1994, PhD thesis
 Progressive neural networks,2016, arXiv preprintarXiv:1606
 Applied Nonlinear Control,1991, Prentice Hall
 Toward Training Recurrent Neural Networksfor Lifelong Learning,899, Neural Computation
 MTEnv- environment interface for multi-task reinforcement learning,2021, Github
 Multi-task reinforcement learning with context-based representations,2021, In International Conference on Machine Learning (ICML)
 Optimalrobot excitation and identification,1997, IEEE transactions on robotics and automation
 Distral: Robust multitask reinforcement learning,2017, In Advances inNeural Information Processing Systems
 Lifelong learning algorithms,1998, In Learning to learn
 Subspace identification for linear systems: The-ory¡ªImplementation¡ªApplications,2012, Springer Science & Business Media
 Embed tocontrol: A locally linear latent dynamics model for control from raw images,2015, arXiv preprintarXiv:1506
 Robustness and generalization,885, Mach
 Densephysnet:Learning dense physical object representations via mUlti-step dynamic interactions,2019, arXiv preprintarXiv:1906
 Improvingsample efficiency in model-free reinforcement learning from images,2019,2019
 Knowledge transfer for deep reinforcement learning with hierarchicalexperience replay,2017, In Proceedings of the AAAI Conference on Artificial Intelligence
 Preparing for the Unknown: Learning a Universalpolicy with online system identification,2017, In Robotics: Science and Systems
 On the identification problem,1956, IRE Transactions on Circuit Theory
 Learning caUsal state representations of partiallyobservable environments,2019, The Multi-disciplinary Conference on Reinforcement Learning andDecision Making
 Invari-ant representations for reinforcement learning withoUt reconstrUction,2021, In International Confer-ence on Learning Representations
 Facial landmark detection by deepmUlti-task learning,2014, In European conference on computer vision
 Latent statemodels for meta-reinforcement learning from images,2020, In 4th Annual Conference on Robot Learning
 Environment probing interaction policies,2019, InInternational Conference on Learning Representations
 Fast model identificationvia physics engines for data-efficient policy search,2017, arXiv preprint arXiv:1710
 Fast contextadaptation via meta-learning,7693, In International Conference on Machine Learning
 Numerical identification of linear dynamic systems fromnormal operating records,1965, In Proc
