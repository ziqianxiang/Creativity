Under review as a conference paper at ICLR 2022
Input Convex Graph Neural Networks: an
APPLICATION TO OPTIMAL CONTROL AND DESIGN
OPTIMIZATION
Anonymous authors
Paper under double-blind review
Ab stract
Despite the success of modeling networked systems via graph neural networks
(GNN), applying GNN for the model-based control is pessimistic since the
non-convexity of GNN models hinders solving model-based control problems.
In this regard, we propose the input convex graph neural networks (ICGNN)
whose inputs and outputs are related via convex functions. When ICGNN
is used to model the target objective function, the decision-making problem
becomes a convex optimization problem due to the convexity of ICGNN and the
corresponding solution can be obtained efficiently. We assess the prediction and
control performance of ICGNN on several benchmarks and physical heat diffusion
problems, respectively. On the physical heat diffusion, we further apply ICGNN
to solve a design optimization problem, which seeks to find the optimal heater
allocations while considering the optimal operation of the heaters, by using a
gradient-based method. We cast the design optimization problem as a bi-level
optimization problem. In there, the input convexity of ICGNN allows us to
compute the gradient of the lower level problem (i.e., control problem with a given
heater allocation) without bias. We confirm that ICGNN significantly outperforms
non-input convex GNN to solve the design optimization problem.
1	Introduction
Decision-making problems are often written in a form of mathematical optimization, where each
part of the optimization problem is required to be modeled to well represent the nature of problem
while encouraging the solvability of the problem. This is also true when applying machine learning
(ML) models as a component (or whole) of those decision-making problems. If one focuses only
on accurately modeling a target system, finding the (optimal) solution of the problem becomes
challenging. On the other hand, if one focuses only on effective solution finding by restricting
the representability of the model, the found solution may not be appropriate as the model cannot
well represent the nature of the problem. Thus, it is crucial to balance an expressive representation
for the problem and the mathematical tractability to solve the formulated problem.
The inductive biases for representability Incorporating the knowledge about the target systems
into ML models often leads the models to have higher generalization performances (Battaglia et al.,
2018). One famous approach is using graph representation to represent the state of graph-structured
target systems and employing graph neural networks (GNN) to learn the relationships among entities
composing the target system. (Battaglia et al., 2016; Sanchez-Gonzalez et al., 2018; Park & Park,
2019). These GNN approaches learn the interactions among the graph entities (e.g., nodes, edges)
and apply the learned interactions to perform predictions. Notably, the approaches often show
outstanding generalization capabilities compared to the different types of network models. Such
property of GNN models becomes more important when the model is used to formulate the decision-
making problem that needs to produce the optimal decision given the conditions that have not been
considered during training the model.
The inductive biases for solvability Imposing structural assumptions to the optimization can
make the problem to be solved effectively. In various ML pipe-lined optimization problems,
1
Under review as a conference paper at ICLR 2022
valid structural assumptions enhance the performance while decreasing computational burdens
(Rashid et al., 2018; Sunehag et al., 2017; Chen et al., 2018b). The exemplary approach is
imposing convexity to the ML models so that entire decision-making can be done by solving convex
optimization problems. The input convex neural network (ICNN) (Amos et al., 2017) is a general
method for reformulating NN models as they become convex function w.r.t the inputs. The convexity
of ICNN helps to solve optimal control problems by employing recurrent extensions of ICNN (Chen
et al., 2018b; 2020; Yang & Bequette, 2021).
Balancing between representability and solvability In order to solve the decision-making
problem with ML models, both of higher representability (generalizability) of model and solvability
of problem are essential. In this perspective, the marriage of the exceptional generalization capability
of GNN and solvability of ICNN enable us to construct a decision-making problem to represent the
target system well and be solved effectively. In this paper, we propose input convex GNNs (ICGNN),
a class of GNN whose inputs and outputs are related via convex functions so that it can be used to
solve the various decision-making, i.e., optimal control, and bi-level design optimization problems.
We provide a general-yet-simple recipe that transforms well-known GNN architectures (e.g., GCN
(KiPf & Welling, 2016), GAT VelickoVic et al. (2017), GIN XU et al. (2018), GN blocks Battaglia
et al. (2018)) into ICGNN. We also propose recurrent extensions of ICGNN so that it can be used to
Predict the mUlti-steP ahead resPonses of network systems.
Training ICGNN We achieVe the conVexity of ICGNN by restricting some Parameters to be non-
negatiVe and Utilizing a conVex and non-decreasing actiVation fUnctions (e.g. ReLU, LeakyReLU).
ThUs training ICGNN is condUcted by solVing a constrained oPtimization. This constrained training
Problem is often iteratiVely solVed by solVing Unconstrained training Problem and then Projecting
the Parameters into the feasible region (Amos et al., 2017; Chen et al., 2018b) at each steP. We
foUnd that sUch training scheme can deteriorate the PredictiVe Performance of the trained model. To
circUmVent that issUe, we emPloy a reParameterization scheme which reformUlates the constrained
training Problem into an Unconstrained training Problem. We foUnd that sUch oPtimization scheme
is more effectiVe than constrained oPtimization with Projections.
Validation To Validate the efficacy of the ProPosed ICGNN by solVing the following two tyPes of
decision-making Problems.
•	Optimal control problem We emPloy ICGNN to model the state transition of PDE systems
(Physical heat diffUsion) and Use this dynamic model to control the PDE systems Using the
model PredictiVe control (MPC) scheme. From oUr nUmerical exPeriments, we confirm the
ProPosed ICGNN excels its non-inPUt conVex coUnterPart in Predicting the target system’s fUtUre
trajectories and controlling the system.
•	Bi-level design optimization We also aPPly the ProPosed ICGNN to solVe a design oPtimization
Problem, seeking to find the oPtimal controller allocations that can maximize control
Performance. We comPUte the gradient of the control objectiVe with resPect to the design
Parameters Using imPlicit differentiation and Use the gradient to oPtimize the oPtimal controller
layoUt Via a gradient-based method. This resUlt oPens an oPPortUnity to Utilize data-driVen
models in solVing a long-standing engineering Problem efficiently.
2	Related Works
2.1	Relational inductive biases: Graph neural networks
GNN is a tyPe of neUral network that oPerates on graPh-strUctUred data. Majority of GNN methods
aims to learn the Pairwise interaction Patterns of the edges from VarioUs graPh domains ranging
from social network, combinatorial oPtimizations and Physics domains (KiPf & Welling, 2016; Park
et al., 2021a; Sanchez-Gonzalez et al., 2018; Park & Park, 2019). SUch learned Pairwise interactions
allows GNN to Predict the resUlts from the graPhs that are distinct from the training graPhs. This
ProPerty is esPecially effectiVe for modeling Physics systems sUch as Particle simUlators and FEM
methods (Alet et al., 2019; Sanchez-Gonzalez et al., 2020). We Utilize the ProPosed ICGNN to
model one of the Physical systems; diffUsion of heat. The trained ICGNN shows better PredictiVe
resUlts than GNN. FUrthremore, we confirmed that the inPUt conVexity of ICGNN imProVes the
control Performance of the simUlated heat system comPared to the Plain GNN.
2
Under review as a conference paper at ICLR 2022
2.2	Functional inductive biases: input convex neural networks
Imposing some mathematical properties (e.g. homogeneity, positivity, monotonicity, and convexity)
on neural networks has been investigated from various contexts (Sill, 1998; Tang et al., 2020; Park
et al., 2021b; Amos et al., 2017). Such mathematical properties helps the generalization capabilities
of the networks when the mathematical properties are well aligned with target problems (Tang et al.,
2020). Among the approaches, input convexity posits an attractive property when the network serves
as a component of optimization problems as the optimization problem becomes convex. input
convex neural network (ICNN) (Amos et al., 2017) proposes a general recipe, which limits the
weight parameters of MLP to be positive and non-linearities are monotone, to construct a neural
network whose inputs and outputs are related via convex functions. Based on the ICNN formula
and input convexity, optimal control methods (Chen et al., 2018b), optimal transportation methods
(Makkuva et al., 2020), and norm-learning methods (Pitis et al., 2019) are has been proposed.
ICGNN is a graph-extension of ICNN so that ICNN framework still valid in graph GNN. We
investigate input convex reformulations of famous GNNs, and also simple optimizations tricks which
makes entire training results of ICNNs much better.
2.3	Behavioural inductive biases: Implicit NNs
Implicit neural networks (also referred as infinite depth models) impose “behavioural” inductive
biases, that are represented as a form of a mathematical (optimization) problems, to the neural
networks and the gradient of the problem can be computed in a computationally efficient manner.
The graident is then used to optimize the parameters of neural networks. For instance, Neural ODE
(NODE) Chen et al. (2018a) applies the adjoint method to estimate the gradient of ODE problems.
The other well-known members of implicit neural networks contains neural fixed point methods
(Bai et al., 2019; Park et al., 2021b) and differentiable optimization layers (Amos & Kolter, 2017;
Agrawal et al., 2019). We found the efficacy of the proposed ICGNN when it is used as a part
of differentiable convex optimization layers. Since the optimization problem becomes convex, we
can find optimal solutions in theory. Additionally, we show ICGNN can provide the exact gradient
of differentiable optimization layer without introducing bias due to its convexity. Based on this
property, we cast the design optimization problem as a bi-level optimization whose inner loop is for
optimizing the control inputs of the heat simulation, which convexity improves the optimization
performance, and the outer loop is for optimizing the position of controllers given the optimal
control, which graph representation of input and GNN provides high-fidelity predictions.
3	Preliminaries
Before we discuss ICGNN, we provide a brief introduction for the building blocks of ICGNN. We
first present a Lemma about the composition of convex functions:
Lemma 1. If f (∙) is convex and g(∙) is non-decreasing and convex, then h(∙) = (g◦ f )(∙) = g(f (∙))
is convex.
The proof of the Lemma 1 is given in Boyd et al. (2004, Ch.3.2). All propositions that will appear
in this paper can be proved by the Lemma 1.
The input convex neural network (ICNN) fθ(∙) is a neural network whose input and output are
related with convex functions. The general expression of k-layers fully input convex neural network
(FICNN) is as follows: For i = 0, ..., k - 1,
z0 = x, zi+1 =σi(Wi(z)zi + Wi(x)x + bi), fθ(x) =zk	(1)
where Zi is the hidden unit of i-th layer, σ,∙) is an activation function of i-th layer and θ
W0(:zk)-1, W0(:xk)-1, b0:k-1 are parameters. Then the following proposition holds:
Proposition 1. FICNN fθ(∙) is convex if W(z∣)-1 are non-negative and σo^-ι(∙) are convex and
non-decreasing functions.
The proof of Proposition 1 is straight-forward due to Lemma 1. Depending on the applications,
some part of x may not require to be convex to zk . In such cases, the use of partially input convex
3
Under review as a conference paper at ICLR 2022
(a) ICGNN
(b) PICGNN
Figure 1: An overview of ICGNN architectures
(c) ICGRNN
neural network (PICNN) can be considered. For clear explanation, we overload x so that it is
corresponding to the convex features and y denotes the features that is not required to be convex.
PICNN is defined as follows: For i = 0, ..., k - 1,
u0 = y, z0 = x	(2)
ui+1 = ξi(Vi(u)ui + Vi(y)y + ci)	(3)
zi+1 = σi(Wi(z)zi + Wi(u)ui + Wi(x)x + Wi(y)y + bi)	(4)
fθ(x, y) = zk	(5)
where zi and ui are the hidden units for convex and non convex features respectively. Those are
called namely “convex path” and “non-convex path”, respectively. Then the following proposition
holds:
Proposition 2. PICNN fθ(∙) is convex in X if W(zk)- 1 are non-negative and σ0lk-1 (∙) are convex
and non-decreasing functions.
A recurrent extension of ICNN, the input convex recurrent neural network (ICRNN), is investigated
(Chen et al., 2018b). ICRNN takes x0:T -1 and an initial hidden state h0 as inputs and predicts a
sequence of outputs y1:T as follows: For t = 0, ..., T - 1,
ht+1 = fθ(ht,xt)	(6)
yt+1 = gθ(ht+1)	(7)
where ht is the hidden state at t, fθ(∙) is a hidden update function and gθ(∙) is a decoder function.
Then the following proposition holds.
Proposition 3. ICRNN is convex and non-decreasing function if fθ (∙) and gθ (∙) are non-decreasing
ICNN.
For further details of ICNN, PICNN, and ICRNN, please refer to the following papers (Amos et al.,
2017; Chen et al., 2018b).
4	Input convex graph neural networks
In this section, we discuss the input convex formulation of the general GNN and its recurrent
extension. We first introduce the notations and a general formulation of GNN layer. Then we
provide a general recipe for transforming the GNN to input convex models and their partial and
recurrent extensions.
In this paper, we consider a directed graph G = (V, E), where V = {vi}, E = {eij} ⊂ V × V, vi
is ith node, and eij is the edge from vi to vj , as inputs of GNN models. A generalized GNN layer
utilizes G as inputs and produces the updated graph G0 = (V0, E0) via the following steps:
e0ij = φθ (vi , vj , eij )	∀eij ∈ E	(8)
Vj = ψθ (Vj ,P({eij }i∈Nj))	∀vj ∈ V	⑼
where φθ(∙) is an edge update function, ρ(∙) is a permutation-invariant aggregation function (e.g.
sum, mean, max), ψθ(∙) is a node update function and Nj is the neighborhood set of Vj. Notice that
4
Under review as a conference paper at ICLR 2022
this formulation is a generalization of famous GNN layers including GCN (Kipf & Welling, 2016),
GIN (Xu et al., 2018), GN (Battaglia et al., 2018). Based on the generalized GNN layer, we propose
the input convex graph neural network (ICGNN).
Proposition 4. ICGNN is convex if φθ(∙) is convex and ψθ(∙) and ρ(∙) are convex and non-
decreasing functions.
The conditions of ICGNN are attained by employing FICNN for φθ(∙) and ψθ(∙), and commonly-
used aggregation functions (e.g. sum, mean, max) as ρ(∙). Furthermore, as similar to PICNN,
we can extend ICGNN to the partially convex variants called the partially ICGNN (PICGNN). A
generalized PICGNN utilizes G = (Gc, Gnc) where Gc = (Vc, Ec) and Gnc = (Vnc, Enc) as inputs
and produces the updated graph G0 = (V0, E0) via the following steps:
0ij =φθnc(νi,νj,ij)	∀ij ∈Enc	(10)
e0ij =	φcθ(vi, vj, eij, νi, νj, ij)	∀eij ∈ Ec	(11)
Vj =	ψc(vj ,ρc({eij }i∈Nj), Vj ,Pnc({e'ij}i∈Nj))	∀vj ∈ VC	(12)
where Gc and G nc are inputs for convex path and non-convex path. Then the following proposition
holds:
Proposition 5. PICGNN is convex in G if φθ(∙) is convex and ΨC(∙) and ρc(∙) are convex and non-
decreasing through convex path.
We can satisfy the condition of Proposition 5 by applying PICNN for φC(∙), non-decreasing
PICNN for ψC(∙) and non-decreasing convex aggregation function for ρc(∙). We provide the GNN
architectures that can be modified into ICGNN and PICGNN in the Appendix A.1.
We also introduce a recurrent extension of ICGNN, called the input convex graph recurrent neural
network (ICGRNN). ICGRNN takes a sequence of input graphs G0:T -1 and an initial hidden
embedding graph H0 to produce a sequence of graphs G10:T as follows: For t = 0, ..., T - 1,
Ht+1 = fC(Ht, Gt)	(13)
Gt0+1 = gC(Ht+1)	(14)
where Ht is the hidden embedding graph at t, fc(∙) is a hidden graph update function and gc(∙) is a
graph decoder function. Then the following proposition holds.
Proposition 6. ICGRNN is a convex and non-decreasing function if fc(∙) and gc(∙) are non-
decreasing ICGNN.
Figure 1(a), 1(b) and 1(c) show the architectures of ICGNN, PICGNN and ICGRNN. We omit the
architecture of the partially ICGRNN which is the partially convex variant of ICGRNN.
5	Training ICGNN
Training ICGNN requires to solve a constraint optimization problem where the constraints are
imposing the non-negativity on W of ICNN. Solving a constrained optimization problem is more
challenging than an unconstrained optimization especially when the number of variables (e.g., the
number of training parameters) becomes larger. Therefore, a simple heuristic, which projecting the
parameter values to the non-negative region after the gradient update, is often used (Amos et al.,
2017; Chen et al., 2018a). We observe that such heuristic deteriorates the predictive performance of
ICNN. To circumvent such issue, we propose to use a variable reparameterization as follows:
Wij = σ(ωij)	(15)
where Wij is the (i,j)-th component of W, σ(∙) is a non-negative function (e.g. ReLU, absolute
value function), and ωij is the reparameterized variable.
6	Experiments
We investigate the proposed ICGNN in three different domains: (1) benchmark graph problems,
(2) dynamic control problems on the physical heat diffusion environment with model predictive
control (MPC), and (3) design optimization problems where the input convexity and graph property
of ICGNN show distinct advantages.
5
Under review as a conference paper at ICLR 2022
Il Cora ∣ Citeseer ∣ Pubmed ∣	∣ MUTAG ∣∣ COLLAB IIMDB-B.∣ IMDB-M.
GCN	0.81	0.70	0.79	GIN	0.85	0.67	0.65	0.43
ICGCN	0.81	-0:73-	-0:79-	ICGIN	-0:89-	-060	-052-	-039-
Table 1: GNN benchmark results (accuracy)
6.1	ICGNN on the public benchmarks
We investigate the predictive performance of input convex reformulation of the famous GNN on the
public benchmark domains. As the IC reformulations restrict the parameter space, it may harms the
predictive performances of the GNN. However, from our experimental results, the performance drop
may not be severe and, surprisingly, for some cases, the IC reformulation shows better predictive
performance than original GNNs.
We evaluate GCN, GIN and thier convex reformulation on cora, citeseer, pubmed, and MUTAG,
COLLAB, IMDBBINARY, IMDBMULTI, respectively. For implementing the GNN models, we
uses the hyperparmeters of the open-source implementations1. Table 1 shows the classification
accuracy of the GNN models and their input convex counterparts. As shown in Table 1, the IC
reformulations do not severely decrease the classification performances. For some cases (e.g.,
Citeseer, MUTAG), they show improved classification performances.
6.2	ICGNN on the control problems
One of prominent applications of convex predictive model is optimal control. We evaluate the
predictive and control performance of ICGNN on a partially observable heat diffusion environment.
On the domain of the heat diffusion environment, a number of sensors Vx which observe the heat
value and controllers Vu which generate the heat are spatially distributed. Note that the number and
location of sensors and controllers are chosen at random. The heat is evolved from the controllers,
diffused through the entire domain and observed at the sensors. The observation and control input
of the heat diffusion environment at time-step t are denoted as xt and ut respectively. Please refer
Appendix B.1 for the details of the partially observable heat diffusion environment.
We represent the environment at time-step t as a directed graph Gt = (V, E), where V = Vu ∪ Vx
and E = (V × V) \ (Vu × Vu) (i.e., complete but controller to controller edges). The ith sensor
has the feature vix which contains the location and the heat observation of the ith sensor. The jth
controller has vju which contains the location and heat input of the jth controller. The edge between
two nodes has the Euclidean distance between two nodes as the edge feature eij .
We model the dynamics of the environment by using the partially ICGRNN. The partially ICGRNN
utilizes the location and distance features as the inputs of non-convex path and heat observations of
sensors and heat inputs of controllers as the inputs of convex path. ICGRNN predicts a sequence
of heat observation Xi：T from an initial hidden embedding graph Ho and a sequence of heat inputs
u0:T -1 by recursively updating the hidden embedding graph Ht. The model utilizes four past and
current observations to generate an initial hidden embedding graph H0. We use three-layer partially
ICGNN for fθ(∙) of equation 13 and four-layer FICNN for gθ(∙) of equation 14. We utilize the
same architecture of ICGRNN for GRNN model as a baseline. To obtain training and test data,
we randomly initialize 30 environments which has different sensor and heater allocations and gather
state-control trajectories by applying random heat inputs. Both models are trained by minimizing the
mean squared error (MSE) between the rollout predicted heat values of 10 future steps and ground
truth observations. Please refer Appendix B.2 for the details of the predictive models and training.
Evaluating predictive performance We evaluate the rollout prediction performance of ICGRNN
in the heat diffusion environment. Figure 2(a) illustrates the rollout predictions of ICGRNN and
GRNN model. As shown in Figure 2(a), both of the ICGRNN and GRNN models show accurate
predictions when the rollout step is short. However, when the rollout step becomes longer, ICGRNN
model shows more reliable predictions than GRNN model. To further understand the generalization
performances of the models, we build a test dataset consist of the 10 sensor/heater layouts and the
1https://github.com/dmlc/dgl
6
Under review as a conference paper at ICLR 2022
(a) 4 rollout results
Figure 2: Heat diffusion prediction results
(b) Average rollout prediction errors
action trajectories length of 100 whose actions are sampled fromU(0.0, 50.0). Figure 2(b) visualizes
the averages prediction errors of the ICGRNN and GRNN models on the test dataset. As shown in
Figure 2(a), both of the ICGRNN and GRNN can well predict the 10 future states as they are trained
to predict until 10 future steps. However, after the 10 steps, the prediction errors of GRNN starts to
diverge while ICGRNN shows relatively stable prediction errors.
Evaluating control performance Now we study the control performance of ICGRNN in the heat
diffusion environment. In our experiments, we use model predictive control (MPC) framework to
control the environment. In the MPC framework, at each time-step t, we solve an optimization
problem to find the optimal control input u↑.t+K-1 of the future K steps, which minimizes the
control objective while satisfying the feasible condition and the predictive model. After solving the
optimization problem, we execute the first optimized controls to the target environment and repeat
the process. The optimization problem is given as follows:
K-1
arg min EJ(Xt+k+1, Xt+k+1, ut+k)	(16)
ut:t+K-1	k=0
s. t. xt+1:t+K = Fθ (Ht, ut:t+K-I)	(17)
U ≤ ut:t+K-ι ≤ U	(18)
where J(∙) is the control objective, Fθ(∙) is the predictive model, Xt+k is predicted heat value at
time-step t + k, X0:T-1 is a reference heat trajectory (i.e., target to track), Ht is an initial hidden
embedding graph at time-step t and u and U are the lower and upper bound of u.
In the following experiments, we investigate the control performance of ICGRNN model for two
widely-used J(∙): (1) reference tracking problem (i.e., deriving the heats X to the reference x)
and (2) input minimization problem (i.e., minimizing the control inputs with heat-level constraints).
To evaluate the control performances, we run MPC on five randomly initialized environments and
report the average of the control objectives. We consider the ground truth controller and GRNN as
baselines. The detail of the control problem is given in Appendix B.3.
Figure 3[top] illustrates the results of the MPC experiments whose objectives are the reference
tracking. The red line shows X and the blue line shows the observed state values when applying
Ut from each controller. The green lines shows the optimized action sequences of each controller.
From Figure 3[top], we can confirm that the MPC controller which utilizes ICGRNN as Fθ(∙)
produces the control results that are closed to the controller with ground truth model. On the
other hand, the control which utilizes GRNN tends to underperform than the control with ICGRNN.
Table 2 summarizes the average control performances on the test data set. The numerical results
highlights that ICGRNN model shows better control performance (i.e. providing higher solvability)
than GRNN model.
7
Under review as a conference paper at ICLR 2022
Figure 3: Sample optimal control and MPC result of ICGRNN and GRNN and their control objective values
(×10-5) on reference tracking problem.
Table 2: Average control objective value. (×10-5)
Il Reference Tracking ∣ Input Minimization		
Optimal	0.026	1.62
GRNN	731	204
ICGRNN	2.46	1.72
6.3 ICGNN on the design optimization problem
From the previous section, we confirm that ICGNN model provides better solvability than GRNN
models. we now apply ICGNN to solve more practically demanding decision-making problem.
Design optimization, which aims to find the (optimal) design parameter p that optimizes the system’s
performance metric J (p), has numerous real-world applications. A few of ML researches tackle
such problems by employing the differentiable learned model fθ (p) = J (p) and gradient-based
optimizations. However, when the performance metric is related with not only p but also the
operations u(p) that do not have explicit expressions, it is less straightforward to solve the design
optimization problem as did in previous researches. For instance, we aim to find the optimal
controller allocations that minimize the control objective functions of Section 6.2.
We cast the design optimization as a bi-level optimization problem whose lower-level optimization
is seeking for optimal controls u* (P) with the given P and upper-level optimization is for finding
the optimal heater allocations p*. The bi-level optimization is written as follows:
T-1
arg min EJ(Xt+1, Xt+ι, Ut)
p	t=0
T-1
arg min	J(xt+1, Xt+ι, Vt)
s. t. u0:T -1 = v0:T -1 t=0
s. t. equation (17), (18)
X1:T = Fθ (HO, u0：T —1； P)
P ≤ P ≤ P
(19)
(20)
(21)
(22)
where J(∙) is the control objective function, Fθ(∙;P) is the predictive model when the controller
position P is given, and p, P is the upper and lower bound of p.
To solve the proposed bi-level optimization via a gradient-based method, it is required to compute
the gradient of U with respect to p; ∂∂u. In general, computing 喘 is challenging as it has no
explicit expression. However, the convexity of ICGRNN makes the lower-level problem as convex
8
Under review as a conference paper at ICLR 2022
(a) ICGRNN with control objective values (×10-5)
(b) GRNN with control objective values (×10-5)
Figure 4: Sample design optimization result on the input minimization problem.
(a) Reference Tracking Problem
(b) Input Minimization Problem
Figure 5: Design optimization performance for two control problems.
optimization. As a result, solving the lower-level optimization and finding a root of its Karush-Kuhn-
Tucker (KKT) conditions are equivalent. Based on this, we apply the implicit function theorem to
the KKT conditions to efficiently compute the gradient ∂u without introducing biases. OnCe We
attain ∂∂p, We Can solve the design optimization problem Via a gradient-based method as follows:
Pt+ι J Pt + α X "J(Pt)	(23)
∂pt
Please refer Appendix B.4 for full derivation of the gradient Ip.
From the initial layout Po, we employ the ICGRNN and GRNN model as Fθ(∙) to solve the design
optimization problem. As shown in Figure 4(a), the ICGRNN model can be used for successful
design optimization. On contrary, the design optimization results with GRNN convereges to the
solution worse than the ICGRNN solutions (see Figure 4(b). To verify this observation is generally
established, we repeat the similar experiments with the different initial layouts and different control
problems. From the Figure 5, we can observe that ICGRNN consistently provides better optimized
design than GRNN.
7 Conclusion
In this work, we proposed ICGNN that balances the representability (generalizability) of GNN
models and solvability of ICNNs in ML pipe-lined decision-making problems. We verify the
representability and solvability of ICGNN on the public benchmark domains and dynamic control on
the physical heat diffusion environment. We also employ ICGNN to solve the design optimization
problem via a gradient-based method. Experimental results support the representability and
solvability of ICGNN on various predicting and decision-making problems.
9
Under review as a conference paper at ICLR 2022
References
Akshay Agrawal, Brandon Amos, Shane Barratt, Stephen Boyd, Steven Diamond, and Zico Kolter.
Differentiable convex optimization layers. arXiv preprint arXiv:1910.12430, 2019.
Ferran Alet, Adarsh Keshav Jeewajee, Maria Bauza Villalonga, Alberto Rodriguez, Tomas Lozano-
Perez, and Leslie Kaelbling. Graph element networks: adaptive, structured computation and
memory. In International Conference on Machine Learning, pp. 212-222. PMLR, 2019.
Brandon Amos and J Zico Kolter. Optnet: Differentiable optimization as a layer in neural networks.
In International Conference on Machine Learning, pp. 136-145. PMLR, 2017.
Brandon Amos, Lei Xu, and J Zico Kolter. Input convex neural networks. In International
Conference on Machine Learning, pp. 146-155. PMLR, 2017.
Brandon Amos, Ivan Dario Jimenez Rodriguez, Jacob Sacks, Byron Boots, and J Zico Kolter.
Differentiable mpc for end-to-end planning and control. arXiv preprint arXiv:1810.13400, 2018.
Shaojie Bai, J Zico Kolter, and Vladlen Koltun. Deep equilibrium models. arXiv preprint
arXiv:1909.01377, 2019.
Peter W Battaglia, Razvan Pascanu, Matthew Lai, Danilo Rezende, and Koray Kavukcuoglu.
Interaction networks for learning about objects, relations and physics. arXiv preprint
arXiv:1612.00222, 2016.
Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi,
Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al.
Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261,
2018.
Stephen Boyd, Stephen P Boyd, and Lieven Vandenberghe. Convex optimization. Cambridge
university press, 2004.
Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary
differential equations. In NeurIPS, 2018a.
Yize Chen, Yuanyuan Shi, and Baosen Zhang. Optimal control via neural networks: A convex
approach. In International Conference on Learning Representations, 2018b.
Yize Chen, Yuanyuan Shi, and Baosen Zhang. Input convex neural networks for optimal voltage
regulation. arXiv preprint arXiv:2002.08684, 2020.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional
networks. arXiv preprint arXiv:1609.02907, 2016.
Ashok Makkuva, Amirhossein Taghvaei, Sewoong Oh, and Jason Lee. Optimal transport mapping
via input convex neural networks. In International Conference on Machine Learning, pp. 6672-
6681. PMLR, 2020.
Junyoung Park and Jinkyoo Park. Physics-induced graph neural network: An application to wind-
farm power estimation. Energy, 187:115883, 2019.
Junyoung Park, Sanjar Bakhtiyar, and Jinkyoo Park. Schedulenet: Learn to solve multi-agent
scheduling problems with reinforcement learning. arXiv preprint arXiv:2106.03051, 2021a.
Junyoung Park, Jinhyun Choo, and Jinkyoo Park. Convergent graph solvers. arXiv preprint
arXiv:2106.01680, 2021b.
10
Under review as a conference paper at ICLR 2022
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-
performance deep learning library. In Advances in Neural Information Processing Systems 32, pp.
8024-8035. Curran Associates, Inc., 2019. URL http://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.
pdf.
Silviu Pitis, Harris Chan, Kiarash Jamali, and Jimmy Ba. An inductive bias for distances: Neural
nets that respect the triangle inequality. In International Conference on Learning Representations,
2019.
Tabish Rashid, Mikayel Samvelyan, Christian Schroeder, Gregory Farquhar, Jakob Foerster,
and Shimon Whiteson. Qmix: Monotonic value function factorisation for deep multi-agent
reinforcement learning. In International Conference on Machine Learning, pp. 4295-4304.
PMLR, 2018.
Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller,
Raia Hadsell, and Peter Battaglia. Graph networks as learnable physics engines for inference and
control. In International Conference on Machine Learning, pp. 4470-4479. PMLR, 2018.
Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, and Peter
Battaglia. Learning to simulate complex physics with graph networks. In International
Conference on Machine Learning, pp. 8459-8468. PMLR, 2020.
Joseph Sill. Monotonic networks. 1998.
Peter Sunehag, Guy Lever, Audrunas Gruslys, Wojciech Marian Czarnecki, Vinicius Zambaldi, Max
Jaderberg, Marc Lanctot, Nicolas Sonnerat, Joel Z Leibo, Karl Tuyls, et al. Value-decomposition
networks for cooperative multi-agent learning. arXiv preprint arXiv:1706.05296, 2017.
Hao Tang, Zhiao Huang, Jiayuan Gu, Bao-Liang Lu, and Hao Su. Towards scale-invariant
graph-related problem solving by iterative homogeneous gnns. Advances in Neural Information
Processing Systems, 33, 2020.
Petar VeliCkovic, Guillem CUcUrulL Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua
Bengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017.
Minjie Wang, Da Zheng, Zihao Ye, Quan Gan, Mufei Li, Xiang Song, Jinjing Zhou, Chao Ma,
Lingfan Yu, Yu Gai, Tianjun Xiao, Tong He, George Karypis, Jinyang Li, and Zheng Zhang.
Deep graph library: A graph-centric, highly-performant package for graph neural networks. arXiv
preprint arXiv:1909.01315, 2019.
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural
networks? arXiv preprint arXiv:1810.00826, 2018.
Shu Yang and B Wayne Bequette. Optimization-based control using input convex neural networks.
Computers & Chemical Engineering, 144:107143, 2021.
11
Under review as a conference paper at ICLR 2022
A Detail Information of ICGNN
A. 1 ICGNN Formulation for Famous GNN Architectures
Here, we provide a list of famous GNN architectures that can be transformed into input-convex
GNN.
A.1.1 Input Convex GNN
The input-convex formulations for GCN, GIN and GN block are straight-forward so we omit the
detail formulations.
A.1.2 Partially Input Convex GNN
Graph Attention Network (GAT) Since the operator Softmax(∙) is not a convex function, it
should be formulated as the partially input convex GAT. The partially input convex GAT layer takes
two node features {hi} and {vi } as inputs for convex path and non-convex path and produces an
updated node feature {h0i } by the following steps:
eij = ξ(W(v)vi, W(v)vj),	∀(i,j) ∈E	(24)
αij = softmaxi (eij), / ∖	∀j ∈ V	(25)
h0j = σ X αij W(h) hi	,	∀j ∈ V	(26)
i∈Nj
where ξ(∙, ∙) is a shared attention function, αj is the attention score between node i and node j, σ(∙)
is an activation function and W (v) and W (h) are parameters. Then the output h0j is convex in {hi }
if W(h) is non-negative and σ(∙) is a non-decreasing convex function.
B	Experimental Details
B.1	Details of Heat Diffusion Environment
B.1.1	Heat Equation
The heat equation or heat diffusion equation on domain D ∈ R2 is given as:
∂u	∂2u	∂2u
∂ = kδIU + f =	κ(∂χ2	+ ∂χ2)	+ f,	∀(X, y)	∈	D,t ≥ 0	(27)
u(x, y, 0) = u0 (x, y),	∀(x, y)	∈	D	(28)
u(x,y, t) = v(x, y, t),	∀t ≥ 0	(29)
where u(∙) is the heat value, f (∙) is a heat source function, u0(∙) is an initial condition, v(∙) is a
boundary condition and κ is the thermal diffusivity. Here, we observe the values of u at sensors
as observation and change the value of f at controllers as control input. For simplicity, we choose
u0(x,y ) = 0, v(x, y, t) = 0 and κ = 1 in our experiment.
B.1.2	Heat Diffusion Environment
To simulate the heat equation, we use finite element method to discretize the time and the domain D
into time-space grid mesh and perform the difference version of dynamic of heat equation. Let ∆t
and ∆x be the interval of time mesh and space mesh. The one-step computation to advance from
the time-step t to the time-step t + 1 is the following:
uit,+j1 = s(uit+1,j+1 + uit+1,j-1 + uti-1,j+1 + uit-1,j-1) + (1 - 4s)uit,j + (∆t)fit,j	(30)
where S =(£产 and Uij and 篇 imply the heat value and heat source on the domain (i∆x, j∆x)
at time t∆t, respectively. In the heat diffusion environment, once the heat source f comes to the
environment, we perform the equation ?? T times.
12
Under review as a conference paper at ICLR 2022
Figure 6: Dynamic of the partially observable heat diffusion simulator.
B.1.3	Partially Observable Heat Diffusion Environment
In our experiment, we use the partially observable heat diffusion environment. The reason why we
called ”partially” is because we are only able to observe uit,j at some specific values of (i, j), not
the whole area. Figure 6 describes how the action affects to the partially observable heat diffusion
environment, how the dynamic undergoes and how the observation is made.
B.1.4	Hyperparameters
In our experiment, we choose the domain D = [-0.5, 0.5]2, ∆x = 0.1, ∆t = 0.000025, T = 400.
B.2	Training Predictive Models
B.2.1	Model Architecture
The role of predictive model is to predict the future heat observation of the heat diffusion
environment given past observation-action trajectory and current and future heat input. We construct
the partially ICGRNN model with three different parts: 1) An initial hidden embedding function, 2)
a hidden graph update function and 3) a graph decoder function. The partially ICGRNN model is
convex with the current and future heat input trajectory and not convex with the other features such
as the past observation-action trajectory, position of controllers and sensors.
Initial hidden embedding function Inputs of initial hidden embedding function are past heat
observation trajectory {x(T) }0:t and past heat input trajectory {u(T) }0:t-1 from time-step 0 to t. To
deal with two different temporal data efficiently, we use two different GNN architectures. To obtain
an initial hidden embedding node feature Ht = {h(t)}, for each time τ = 0, ..., t - 1,
yj(T) = GAT(x(T+1),h(T),h(jT),px,pjx))	∀j ∈ Vx	(31)
z(jT) = GCN(u(T),h(jT),pu,pjx),	∀j ∈ Vx	(32)
h(jT+1) =NN(h(jT),yj(T),z(jT),pjx),	∀j ∈ Vx	(33)
where h(j0) = NN(x(j0)), ∀j ∈ Vx, yj(T) and z(jT) are aggregated sensor and controller messages at
node j ∈ Vx. For GAT(∙) and GCN(∙), we additionally use the controller positions Pu and sensor
positions px as additional features.
Hidden graph update function To update the hidden graph, the update function aggregates the
message from controller nodes and other sensor nodes. Similar to initial hidden embedding function,
we construct two different GNN architectures as follows: Given the initial hidden graph Ht and the
13
Under review as a conference paper at ICLR 2022
heat input u(t),
yj(t) =PICGAT(h(t),hj(t),px,pjx),	∀j	∈Vx	(34)
z(jt) =	PICGCN(u(t),hj(t),pu,pjx),	∀j	∈	Vx	(35)
h(jt+1) =PICNN(h(jt),yj(t),z(jt),pjx)	∀j	∈Vx	(36)
Here, all architectures are convex in all but the sensor positions p(x) and controller positions p(u) .
Graph decoder function We use 4-layer FICNN to obtain predicted heat observations {xj"}
from the embedding graph Ht :
Xjt) = FICNN(hjt)), ∀j ∈ Vx	(37)
We use absolute value function for reparameterization trick of the parameters that should be non-
negative. We use a parametric ReLU, called PReLU, for activation function, which is defined as:
P ReLU (x; a) = x if x ≥ 0	(38)
ax else
with a parameter a.
To make a fair comparison, we build the exact same GRNN architecture without any constraint about
input convexity and use it as a baseline model.
B.2.2	Data Generation and Training Hyperparameters
We randomly initialize 120 target environments from the number of sensors and controllers from
U (20, 81). For each episode, we choose the control input from U(0, 50) and collect the state-action
trajectory with trajectory length 100. We divide 100, 10, 10 state-action trajectories for training,
validation and test data. We implement on the Python by using PyTorch (Paszke et al., 2019) and
DGL (Wang et al., 2019) library. We us the Adam (Kingma & Ba, 2014) optimizer with decaying
learning rate from 0.001 to 0.0001 with decaying rate 0.5 for every 500 epochs.
B.3	MPC on Heat Diffusion Environment
B.3	. 1	Optimization Problem Setup
At time-step t, MPC solves the following optimization problem:
K-1
min V' J(Xt+k+ι, Xt+k+ι, ut+k)	(39)
ut:t+K-1
k=0
s. t. Xt+1:t+K = Fθ (Ht,ut∙t+κ-ι)	(40)
U ≤ Ut：t+K-1 ≤ U	(41)
where J(∙) is the control objective function, Fθ(∙) is the predictive model, Xt+k is predicted heat
value at time-step t + k, Xo：T-ι is a reference heat trajectory, Ht is an initial hidden embedding
graph at time-step t and u = 0 and U = 50 are the lower and upper bound of u. For both control
problems, We choose K = 10 and the values of u and U are 0 and 50, respectively.
For reference tracking problem, we use J (Xt+ι, Xt+ι, Ut) = ∣∣Xt+ι - Xt+ιk2 and run the projected
gradient-descent algorithm 3000 times with the Adam optimizer. We reduce the learning rate
from 0.005 to 0.0001 with decaying factor 0.5 when the validation score does not decrease for 5
consecutive steps.
For input minimization problem, we use J(Xt+ι, Xt+ι, Ut) = (Xt+ι — Xt+ι)+ + α∣∣utk2 with
α = 0.001 and run the projected gradient-descent algorithm 1000 times with the Adam optimizer.
We choose the same learning rate scheduler of reference tracking problem, start the learning rate
from 0.001.
14
Under review as a conference paper at ICLR 2022
B.4 Design Optimization on Heat Diffusion Environment
B.4.1	Full derivation of Implicit Gradients
Problem definition We build the design optimization problem as a bi-level optimization. The
lower-level optimization problem is formulated as:
T-1
Uq-t-i = u*(p) = arg min EJ(Xt+1, Xt+1, Ut)	(42)
u0:T-1	t=0
s. t. Xi：T = Fθ (Ht, uq-t-i； p)	(43)
U ≤ uq-t-i ≤ U	(44)
where J(∙) is the control objective function, Fθ(∙;p) is the predictive model When the controller
position P is given. By putting 17 into Xi：T on the control objective function, we can simply write
the lower-level problem as Uq：t-ι = U (p) = arg min。{L(u, p) : u ≤ U ≤ u}.
Now, the upper-level optimization problem is formulated as:
T-i
min TJ(Xt+1, ^ct+ι, Ut)	(45)
p
t=q
S.t. Uq：t-i = U*(p)	(46)
Xi：T = Fθ (Hq , uq：t-i； p)	(47)
P ≤ P ≤ P	(48)
where P = -0.5, P = 0.5 is the lower and upper bound of p. We can simplify the upper-level
problem as:
min L*(p) = L(u*(p), p)	(49)
p
s.t. p ≤ p ≤ P	(50)
From the fact that the gradient of L (p) w.r.t. P is given as
▽pL*(P) = NpL(U(P), P) = (VuL(U*(p), P))(Vpu*(p)) + VpL(u*(p), p),	(51)
we can compute the gradient of control objective function when the gradient Vpu* (p) is computed.
KKT conditions In convex optimization problem, solving the optimization problem is equivalent
to finding a root of KKT conditions. We state the KKT conditions of the lower-level problem:
VuLp(U) + λi Vu(u — u) + λ2 Vu(u — U) = VuLp(u) — λi + λ? = 0	(52)
λi(u — u) = 0	(53)
λ2(u — U) = O	(54)
U ≤ U ≤ U	(55)
λi,λ2 ≥ 0	(56)
where λi and λ2 are Lagrange multipliers of inequality constraints (u ≤ u) and (u ≤ u),
respectively. However, the implicit function theorem can only handle the equations, not inequalities.
Thus, we select only active inequalities of the lower-level optimization problem at the optimal value
u* (p) and change the active inequality constraints as equality constraints, denoted as GU — h = 0
(Amos et al., 2018). With a new Lagrange multiplier ν for the equation (GU — h = 0), we state a
transformed KKT conditions:
VuLp(U)+GTν=0	(57)
GU — h = 0	(58)
which simply denoted as F(w, p) = 0 where w = [U, ν].
15
Under review as a conference paper at ICLR 2022
Applying the implicit function theorem We employ the implicit function theorem on the KKT
conditions described on the equation 57. Then We can derive Vpu* (P) by:
Vpw*(P) = VVppνu**((PP)) = -(VwF (w*(P), P))-1(VpF (w*(P), P))	(59)
VwF(w*(P),P)= HuLGp(u)	G0T	(60)
VpF (w*(P), P) = Vp(Vu0Lp(u))	(61)
B.4.2 Hyperparameters
We use the projected gradient-descent algorithm 100 times With the Adam optimizer for upper-level
optimization problem on the both control problems. We reduce the upper-level learning rate from
0.05 to 0.001 With decaying factor 0.5 When the validation score does not decrease for 5 consecutive
steps. For loWer level problem, We use the same optimizer and learning rate scheduler described in
Section B.3.
16