Under review as a conference paper at ICLR 2022
Unsupervised Visual Program Induction
with Function Modularization
Anonymous authors
Paper under double-blind review
Ab stract
Program induction serves as one way to analog the ability of human thinking.
However, existing methods could only tackle the task under simple scenarios
(Fig 1(a),(b)). When it comes to complex scenes, e.g., the visual scenes, cur-
rent program induction methods fail due to the huge program action space. In this
paper, to the best of our knowledge, we are the first to tackle this problem. We
propose a novel task named unsupervised visual program induction in complex vi-
sual scenes that require complex primitive functions. Solving this task faces two
challenges: i) modeling complex primitive functions for complex visual scenes
is very difficult, and ii) employing complex functions in the unsupervised pro-
gram induction suffers from a huge and heterogeneous program action space. To
tackle these challenges, we propose the Self-Exploratory-Modularized-Function
(SEMF) model, which can jointly model individual function selection and its pa-
rameters through a unified modular block. Moreover, a Monto-Carlo-Tree-Search
(MCTS) based Self-Exploratory algorithm is proposed to explore program space
with modularized function as prior. The exploratory results, in turn, guide the
training of these modularized functions. Our experiments demonstrate that the
proposed SEFM model outperforms all the existing baselines in model perfor-
mance, training efficiency, and model generalization.
1	Introduction
Program induction is regarded as an efficient way to analog human’s thinking process (Fodor, 1975;
Piantadosi, 2011), which could be described as: given a set of core primitive functions, the algorithm
is required to organize these functions into a program to explain the rule hidden in the observed
scenes (Koza & Koza, 1992; Piantadosi, 2011) without teacher guidance. However, when it comes
to visual scenes, due to the complexity of the scene and the required complex primitive function,
traditional program induction methods fail due to the exponential search complexity.
In this paper, we tackle the task of visual program induction with complex functions unsupervisedly
for the first time. We propose a novel task named unsupervised visual program induction with
complex functions. Fig. 1(c) provides an example of visual program induction: a complex visual
scene would require complex functions with multiple parameters, thus resulting in a much larger
action space. Solving this problem poses two challenges that lead to the failure of existing non-
visual program induction approaches: i) modeling complex primitive functions for complex visual
scenes is very difficult, and ii) employing complex functions in the unsupervised program induction
suffers from a huge and heterogeneous program action space.
To solve these challenges, we propose the Self-Exploratory-Modularized-Function (SEMF) model
which is capable of jointly modeling function selection together with its parameters through a uni-
fied modular block. Particularly, the whole action space is re-organized modularized functions, i.e.,
each function together with its parameters will be organized as a unified modular block. A mod-
ularized function can act automatically given different observations of visual patterns. Moreover,
to train the modularized functions unsupervisedly, we design a function planning mechanism that
focuses on the function-level program generation and propose a special two-stage Monto-Carlo-
Tree-Search (MCTS) based search algorithm to efficiently conduct visual program induction. The
Self-Exploratory algorithm is able to search the program space with those modularized functions as
prior, and the explored search results will in turn guide the training of these modularized functions.
1
Under review as a conference paper at ICLR 2022
Input	Traget
Primitive Functions
MOVE()
TURN_LEFT()
PICK_BEEPER()
PUT_BEEPER()
Target Program
MOVE();
PICK_ BEEPER();
MOVE();
Input：	2, [3 5 4 7 5]
Target: [7]
Primitive Functions
DOT[X,Y,COL]
VLINE[TX,BX,Y,COL]
HLINE[LY,RY,X,COL]
BLOCK[TX, LY, BX, RY, COL]
BORDER[TX, LY, BX, RY, COL]
Target Program
BORDER[0, 0, 2, 3, RED]
BORDER[2, 0, 4, 3, BLUE]
Primitive Functions HEAD	ZIPWITH LAST	SCALE TAKE	SORT DROP	SUM ACCESS	MAP MINIMUM FILTER MAXIMUM COUNT REVERSE		Target Program k G int; b G [int]; C G SORT b; d G TAKE k c; e G SUM d;
(a) move one step; ； (b) assign inputs to k and b; sort b, store ； (C) draw a rectangle border from Pos (0,0) to Pos
pick the blue beeper; ； the result in c; take the k-th element : (2,3) with color crimson; draw a rectangle border
and move one step. ; from c into d; assign the sum of d to e. : fromPos (2,0) toPos (4,3) with color blue.
Figure 1: Program induction task examples. (a) The famous Karel task (Pattis et al., 1981), which
includes four primitive functions with no parameter, i.e., the total action space is 4; (b) The “Se-
quence Manipulation” task (Balog et al., 2017), which includes 15 primitive functions with limited
parameters, and the total action space is 34. (c) The Visual Program Induction task in this paper,
where there are five primitive functions with rich parameters, and the total action space is 2,349.
(See Appendix A to see how these numbers are calculated.)
We conduct extensive experiments to test the proposed algorithm with respect to model perfor-
mances, training efficiency, and generalization ability compared to several state-of-the-art baselines.
The results demonstrate the superiority of our proposed SEMF model over existing methods for
solving the task of unsupervised visual program induction with complex functions.
To summarize, we make the following contributions in this paper.
•	To the best of our knowledge, we are the first to tackle visual program induction with
complex functions in an unsupervised manner, and formally propose the novel problem of
unsupervised visual program induction with complex functions.
•	We propose the Self-Exploratory-Modularized-Functions (SEMF) model which is able to
jointly optimize individual function selection and its parameters by decoupling the learning
process into modularized functions learning and Monto-Carlo-Tree-Search (MCTS) based
function planning. The decoupling procedure makes exploring the huge and heterogeneous
action space possible and efficient.
•	We conduct extensive experiments to compare our proposed SEMF model with several
state-of-the-art baselines on a novel and specialized-designed dataset. Our proposed SEMF
model could gain magnitude improvement compared with the baselines in terms of model
performance, training efficiency, and model generalization ability.
2	Program Induction with Complex Functions
In this section, we formally define the task of program induction with complex functions, and com-
pare it with simple functions studied in the literature.
2.1	Definition
The task of program induction aims to generate programs to explain the input-output pairs from a
set of given primitive functions (Koza & Koza, 1992; Piantadosi, 2011). In particular, we focus on
complex primitive functions that may have arbitrary and heterogeneous parameters for the first time.
First, we provide some intuitions for modeling complex primitive functions. From the perspective
of human cognition, human skills and actions are mostly modularized and complex such that we
could act adaptively depending on different environments (Chollet, 2019; Johnson et al., 2021). As
the goal of program induction is to analogize and approach human’s thinking system (Fodor, 1975;
2
Under review as a conference paper at ICLR 2022
Piantadosi, 2011), the ability to model complex functions is indispensable. From the perspective
of programming language, a parameterized function could represent expediently a group of actions
that share the same basic functionality but with different properties to adapt to diverse conditions.
However, the modeling of complex functions has long been overlooked in the literature. Therefore,
we aim to explicitly model complex functions to meet the demand of LOT and general program
induction.
In this paper, a complex function is defined as FΘ = (F, ΘF), where F ∈ F is the function
class, F denotes all possible function classes, and ΘF = [θF,1, θF,2, ..., θF,nF] are nF the function
parameters forF. The parameters range is denoted as ΞF = ΞF,1 ×ΞF,2...×ΞF,nF, i.e., θF,i ∈ ΞF,i.
Notice that the parameters and their ranges depend on F. We use FΘ(Ot) → Ot+1 to represent the
mapping of FΘ from Ot to Ot+1. We adopt subscripts to denote multiple functions in a sequence,
e.g., Fiθi, and Use F = {Fθ∣F ∈ F, Θf ∈ ΞF } to denote the possible action space for the
complex fUnction.
Formally, given an inpUt Oin and oUtpUt OoUt, the action space F, the task of program indUction with
complex fUnction is to find a seqUence of fUnctions P = {FtΘt ∈ F}tT=1 sUch that:
FΘT ◦ FT--1 …。FΘ1 (Oin) → Oout.
(1)
Notice that T depends on the underlying ground-truth program in generating the input-output pair
and is not observed in the data. Moreover, since we do not want P to have an infinity length, we
transform the task into a constrained optimization problem by minimizing the cost of P as follows:
min C(P)
P
s.t.	Fθτ。FθT-1 …。FΘ1 (Oin) → Oout,
(2)
where C(∙) is a metric that measures the cost of a sequence of functions. In the following, for
notation convenience, we also write Oin as O0 and Oout as OT .
2.2	Comparison with simple functions
The general goal of our paper is aligned with previous program induction tasks, but we consider
complex functions with a huge and heterogeneous action space, which cannot be solved by tradi-
tional program induction models.
As shown in Fig 1(a), the Karel task (Pattis et al., 1981) is a typical example of program induction
and includes only four parameter-free primitive functions, i.e., the robot Karel can only choose from
these four actions. In Fig. 1(b), Balog et al. (2017) consider the sequence manipulation problem
which includes 15 primitive functions. It is also worth mentioning that these primitive functions
contain none or a very limited number of parameters. For convince, Balog et al. (2017) directly
flatten all the primitive functions and associated parameters, obtaining a action space of 34.
In contrast, as shown in Fig 1(c), we consider visual program induction problems where all the
primitive functions contain at least one position parameter and an extra color parameter. Therefore,
a task with five primitive functions already results in the whole action space being 2,349, which is
two orders of magnitude larger than previous works (Appendix A explains how these numbers are
calculated in details).
2.3	Problem Analysis and Literature Solutions
The core of solving program induction tasks relies on the fact that all functions are executable. Then,
our goal turns into finding the following transition dynamics:
Fθt 〜P(Fθ∣Ot-ι, Ot； F),Ot = Fθt(Ot-1).
(3)
The transition dynamic is executed iteratively until we reach the target state OT or reach a preset
max iteration step Tmax . Then, functions along the success trace are treated as a valid program.
Next, we review the literature for solving the transition dynamics.
Solving via Exhaustive Search. Search-based methods are common solutions when the action
space is not large as we can simply “try” all the possible programs until finding OT . Naively, by
3
Under review as a conference paper at ICLR 2022
uniformly exploring the action space, i.e., P(Fθ∣Ot-ι, OT; F) = 1/|F|, ∀Fθ ∈ F, we can define
an order to enumerate all the possible programs of length Tmax . Though search-based methods
can guarantee a valid solution when we try every possible program, when the action space becomes
huge, naively trying out all feasible candidate programs is not feasible in practice.
Solving via Learning. In the modern AI era, we can also learn the transition dynamics using neural
networks, i.e., P(Fθ∣Ot-ι,OT; F) = 1 q(Fθ, Ot-ι,OT; F), where q(∙) is a neural network to
predict the probability distribution of FΘ to be the next function and Z is the normalization term.
Though achieving some successes, however, those learning-based solutions require ground-truth
riθ3τ
programs {Ft t }tT=1 as supervision signals during train (Lezama, 2008; Tian et al., 2019), which
is expensive or even infeasible to obtain for most program induction tasks.
Solving via Searching and Learning. More recently, Balog et al. (2017) investigate the possibil-
ity of combing exhaustive search and learning-based methods where a neural network q(∙) is also
utilized to learn P(Fθ∣Ot-ι,OT; F). But instead of using ground-truth programs as supervision,
the neural network q(∙) is directly trained from final search results. This idea is shown successful
in (Balog et al., 2017). However, when it comes to the complex functions considered in this paper,
this basic search-and-learn framework suffers from the problem of the huge and heterogenous action
space, and the learning of q(∙) becomes fragile and easy to collapse into trivial local minima.
3	SEMF: Self-Exploratory-Function-Modularization
As explained in Section 2.3, the existing methods cannot model complex functions and suffer from
the huge and heterogeneous action space. In this section, we solve this problem by reformulating the
program induction task with complex functions as learning function planning and function parameter
prediction, where the former decides which function class should we use and the latter decides what
parameters should be learned. The intuition is that functions and learnable parameters should be
considered separately to better explore the action space.
This section is organized as follows: in Section 3.1, we reformulate the problem into two stages of
“function planing” and “parameter prediction”; in Section 3.2, we introduce Modularized Functions
proposed in this paper; in Section 3.3, we introduce the Self-Exploratory Learning Framework to
efficiently explore this two-stage action space.
3.1	Task Reformulation
To handle complex functions considered in this paper, we first split Eq. (3) into two parts: function
planing and parameter prediction, where the former focus on predicting the function class Ft while
the latter focus on predicting parameters Θt :
Ft 〜PF(F∣Οt-ι,Ot； F), Θt 〜P® (Θ∣O1,OT; F, Ξf),Ot = F?"Ot-i).	(4)
The decoupling of function class prediction and parameter prediction facilitates exploring the huge
action space: we first determine the function and then find the best parameters, rather than directly
selecting from the whole action space. From another perspective, the function class prediction can
be regarded as modeling function’s long-term planing dynamic since the function class usually deter-
mines the main functionality, while the parameter prediction models function’s short-term transition
dynamic by selecting the best parameters.
3.2	Modularized Functions
Instead of implementing Eq. (4) with two separated models as in (Tian et al., 2019), in this paper,
we propose the idea of modularized functions, where a modularized function for FΘ is defined as
MF = (eF, QF) where eF is a special designed embedding used in function planning and QF is a
set of neural networks used to predict function parameters.
Shared Visual Encoder. Due to the complexity of visual scenarios, we firstly introduce a shared
encoder E to encode the raw input space O into an embedding space, i.e., si = E(Oi) ∈ Rh, where
h is the dimensionality of the embedding space.
4
Under review as a conference paper at ICLR 2022
Figure 2: Model illustration. (a) The process of computing function class Ft and parameters Θt
from Ot-1 to Ot. (b) An illustration from Ot-1 to Ot in the embedding space, where si = E (Oi)
is the state embedding vector and eF is the function class embedding. Ft determines main direction
while Θt further revises the direction of the function towards Oout .
Function Planning. Each function F ∈ F is assigned with a vector eF ∈ Rh which is used for the
long-term function planning. The probability for function Ft is defined as:
Ft 〜PF(F∣Ot-ι, Ot； F)
1
ZF
σ (∆s>eF) , ∀F ∈ F,
(5)
where ∆st = E(OT) - E(Ot-1), ZF is the normalization term, and σ is an activation function. In a
nutshell, we calculate the difference ∆st between our desired output OT and the current state Ot-1
and select functions with large inner product similarities in the embedding space.
Parameter Prediction. After predicting Ft using PF (F |Ot-1, OT; F), we use QFt to calculate
the probability of function parameters Θt based on (Ot-1, OT). For function F with parameters
ΘF = [θF,1, θF,2, .., θF,nF], we use nF neural networks QF = {qF,θi}in=F1 to model the marginal
distribution of ΘF as:
θF,i 〜PF,θi (°|Ot-1, OT； ξF,J
=Z^σ (qF,θi (E(OT), E(Ot-I), eF))θF i .
Based on Ft and QFt, the probability distribution for Θt is:
Θt 〜Pθ(Θ∣Ot-ι, Ot; Ft, ΞFt) = YnFtPFt岛(θ∣Ot-ι, Ot; Ξi).
i=1
(6)
(7)
Using the above definition of modularized function MF, we further illustrate the computing process
of our proposed method in Fig. 2. As shown in Fig. 2(a), given OT as the target, the inner product
between eF and ∆st = E(OT) - E (Ot-1) is computed to select a function class Ft. After that,
{θFt ,i }in=F1t is computed and gathered into Θt. Notice that, during function planning, we do not
consider how to learn the parameters. Similarly, during parameter prediction, QF tries to find the
best parameters assuming the function class F is already selected. In Fig. 2(b), a brief illustration of
the transition dynamic is given. In the embedding space, the function class Ft is used to determine
the main direction using eFt, while Θt is selected from the parameter space to further revise this
direction conditioned on eFt to find the best FtΘt .
3.3	The Self-Exploratory Learning Framework
Next, we introduce our Self-Exploratory Learning Framework, which includes a search phase and a
training phase.
Our search method is based on the modularized function and the Monto-Carlo-Tree-Search (MCTS,
see (Browne et al., 2012) for more details) algorithm. Due to the huge action space and the non-
zero-sum-game nature of this task, vanilla MCTS would still meet extra challenges:
5
Under review as a conference paper at ICLR 2022
1.	The parameter space is still huge even with our proposed modularization, limiting the
search efficiency.
2.	The successful traces are extremely sparse, i.e., most of the searched programs from Oin
cannot lead to Oout , and thus could not provide very informative supervision.
To tackle these two challenges, we introduce the following two improvements into MCTS:
1.	Increase the parameter search width, i.e., select multiple candidates when searching for
parameters rather than search one trace in the standard MCTS;
2.	Utilize failed traces as an extra supervison.
Building the Search Tree. One key of MCTS is to build a search tree that enumerates program
traces with high probabilities, which includes Select Child, Expand Node, and Backup:
Select Child. Starting from the root node indicating
O0(1) = Oin, we select a function FtΘt with high-
est scores to attach to the search tree. Specifically,
since there are two types of distributions for func-
tion planning and parameter prediction, we make
some modification compared to standard MCTS.
When choosing a function node Ft , we directly se-
lect the function with highest score and append it to
the search tree. For the parameter prediction, rather
than selecting a single set of parameters, we select
the top-k sets of parameters with highest scores to
better explore the huge parameter space.
Expand Node. In the “expansion” process, given
one function class Ft and multiple sets of parame-
ters {Θt,i}, all the possible output are computed as
{FtΘt,i (Ot-1)}. Then we randomly select one of
them to expand for the next round of Select Child.
Backup. After the expansion process reaches the
maximum depth Tmax , we compare OT(i)	and all
Tmax
(i)
other intermediate Ot with Oout , and backup the
statistics, which is the visit count in our scenario.
After statistics backup, We continue next round Se-
lect Child from the root, i.e., O0(i+1) = Oin.
The score function for selecting a child node u ∈
Ω(v), where Ω(∙) denotes all possible children of
the current node v , is defined as:
,⑶
I)
half-way stop
success
backup
backu
⑵
Θi
Oout
一(3)
Figure 3: An illustrating example of the mod-
ified MCTS algorithm to build a search tree
in this paper. We assume three parameters are
selected for each function and show the first
three traces (best view in colors).

。*

score(u)
1
pl + β ∙ α(u)
•P(U),
(8)
where α(u) is the visit count of the child node u, β is a scaling hyper-parameter, and P(•) is the
learnable distribution defined as Eq. (5) (for function planing) or Eq. (7) (for parameter prediction).
In essence, the learnable distribution encourages searching most potential candidates, while penal-
izing frequently visiting the same nodes within a tree and thus helps exploration. More details could
be found in Appendix C.
Transform into Training Data. After building the search tree, as shown in Fig 3, there are three
type of possible traces: (1) successful traces that reach the target (represented as green dash line),
i.e., Ot(i) = Oout ; (2) traces that reach the maximum depth but still do not reach the target (repre-
sented as red dash line), i.e., OT(i) 6= Oout; (3) other half-way stopped traces that no dot reach the
target (represented as blue dash line), i.e., Ot(0i) 6= Oout , t0 6= Tmax . We denote these traces as Ts,
Tf, To, respectively, where each search step in these traces is in the form of (Ot-1, Ot, Oout, Ft, Θt)
where FtΘt (Ot-1) → Ot.
6
Under review as a conference paper at ICLR 2022
Training the Model. Given the traces above as training data, the function planing model is opti-
mized using the following loss function:
LF =	X	PF(FtNog Pf (Ft)+	X	(1-PF (Ft)) ∙b虱I-PF(Ft)),
(Ot-1 ,Ot ,Oout ,Ft)∈Ts	(Ot-1 ,Ot ,Oout ,Ft)∈Tf
(9)
where PF (Ft) is defined in Eq. (5).
For parameter prediction, since we do not have supervision and the action space is large, we
propose a method to optimize the per-step improvement, i.e., only considering the relative im-
Provement compared to the last step. Formally, We design a function D(∙) to measure the qual-
ity of a searched state Ot compared to our goal Oout. We realize D(∙) as the edit distance
in this paper, Which can be easily generalized. Then, the per-step improvement is measured as
∆D(Ot, Ot-1) = D(Ot, Oout) - D(Ot-1, Oout). The parameter prediction is trained With the
folloWing cross-entropy loss:
LΘ =	X	Q(Θt) log PΘ(Θt) + (1 - Q(Θt)) log(1 - PΘ(Θt)), (10)
(Ot-1 ,Ot ,Oout ,Ft ,Θt)∈Ts ∪Tf ∪Tp
Where PΘ(Θt) is defined in Eq. (7) and Q(Θt) = ρ ∆D FtΘt (Ot-1), Ot-1	is the normalized
relative improvement When choosing parameter Θt at the current step.
4	Experiments
In this section, We conduct experiments for the visual program induction task. We first introduce
the data generation process and experimental setup in Sec. 4.1. In Sec. 4.2, We report the results of
our proposed model and state-of-the-art search-based and learning-based baselines. In Sec. 4.3, We
analyze the training efficiency and generalization ability. Besides, We give some results illustration
in Appendix. D.
4.1	Data Generation and Experimental Setup
Data Generation. We specifically design a visual program induction dataset inspired by the visual
patterns from Abstraction and Reasoning Corpus (Chollet, 2019) and focus on pixel modification
primitive functions on 5 × 5 grids With ten colors (see Fig. 1(c) for an example). The training set
and testing set are generated by randomly selecting primitive functions to form a program, and then
applying the program to a random input observation Oin to obtain Oout . In this paper, We generate
10, 000 instances for training and 1, 000 instances for testing. We fix the maximum length of the
program as T = 3 unless stated otherWise. Ground-truth program is used to measure the model
performance. More details and examples about the dataset could be found in Appendix A.
Model Instantiation. The instantiation of our proposed method is as folloWs. The encoder E is
a convolutional neural netWork (CNN) With four convolutional layers and one MLP layer. The
neural netWorks for parameter prediction qF,θi has 4 MLP layers, Which are shared across different
parameters, and one parameter-specific MLP layer with the output dimensionality the same as | Ξp,i |.
The model is optimized With Adam (Kingma & Ba, 2014) optimizer and the learning rate is 0.001.
The training are conducted with 1 GTX 3090 GPU and 60 CPU cores for two days.
Comparing Methods. We compare the following methods. (1) Basic search-based algorithms,
including Depth-First-Search (DFS), Beam Search, and A specifically-designed MCTS algorithm
for this task. These baselines do not have a training process. (2) Our proposed SEMF model.
Since SEMF is a general learning framework, we equip it with different search methods mentioned
above, i.e., DFS, Beam Search, and MCTS, in the testing phase. (3) Supervised baseline, which is
inspired by program synthesis (Sun et al., 2018; Tian et al., 2019) and uses ground-truth programs
as supervision. Notice that the supervised baseline should be considered as an upper bound since it
utilizes ground-truth programs. More details about these methods could be found in Appendix. B.
Metrics. We consider two metrics in this paper: Hit@N, i.e., whether a successful trace is found
within N trials, which measures the inference accuracy, and AvgTime, i.e., the average inference
time to solve a problem, which measures the model efficiency.
7
Under review as a conference paper at ICLR 2022
Table 1: The overall performance Comparison. For training and testing, “AvgTime” measures the
average search time for a maximum of 50 trails. For search-based baselines, since they do not have
a training stage, we directly apply them to the training data and testing data, respectively. For SEMF
and Supervised methods, different search methods only affect the testing phase.
Model	Search Method	Training		Testing			
		Hit@50f	AvgTimeJ	Hit@10f	Hit@50f	Hit@200f	AvgTimeJ
	Beam	1.7%	>1000s	0.2%	1.8%	3.5%	>1000s
Search	DFS	1.1%	>1000s	0.3%	1.1%	2.6%	>1000s
	MCTS	2.4%	>1000s	0.5%	2.3%	2.7%	>1000s
	+Beam	85.5%	200s	61.0%	74.4%	86.1%	358ms
SEMF	+DFS	85.5%	200s	66.3%	67.3%	87.8%	191ms
	+MCTS	85.5%	200s	72.5%	82.1%	90.7%	108ms
Supervised	+MCTS	93.8%	23ms	85.1%	92.1%	94.4%	79ms
4.2	Results
We report the results of all the comparing methods in Table 1 and make the following observations.
First, search-based methods fail miserably to solve most of the tasks within an acceptable time,
indicating that these classical methods cannot solve the visual program induction tasks with complex
functions. The search space of exhaustive search grows exponentially with respect to the length of
the program. By setting Tmax = 3, which is the ground-truth length of the dataset, the search space
would have a size of 20493 > 8 × 109, which is infeasible in practice. The results also motivate
combining search-based methods with learning-based solutions.
Our proposed SEMF model significantly outperforms search-based methods. For example,
SEMF+MCTS achieves more than 70%, 80%, and 90% accuracy for Hit@10, Hit@50, and
Hit@200, respectively. Besides, the average inference time for SEMF+MCTS is around 100 mil-
liseconds, which is more than 1000x faster than search-based methods.
Comparing different search methods, our proposed MCTS significantly outperforms DFS and Beam
search. For example, MCTS improves the accuracy by about 8% for Hit@50 while reducing the
average inference time by more than 43%. We attribute the strong performance of MCTS to our
tailed design for the visual program induction task.
Our proposed method achieves comparable performance compared to the supervised baseline. No-
tice that the supervised baseline needs ground-truth programs of the training data, which is expensive
or infeasible to collect for most real visual program induction tasks.
4.3	Training Efficiency and Generalization Ability
In this section, we analyze the training efficiency model robustness and generalization Ability of our
proposed method.
Training efficiency First, we compare a variant of our proposed method without function modular-
ization, i.e., directly choosing from the 2,349 functions in the action space. The results are shown
in Fig. 4(a). Clearly, without function modularization, the training accuracy is much lower and the
convergence rate is much slower. Next, we compare our proposed method with DFS when the pro-
gram length varies. The results are shown in Fig. 4(b). DFS can barely handle when the program
length if larger than 1. In contrast, the average inference time of our proposed method only grows
marginally as the program length increases, demonstrating the superior efficiency.
Generalization ability. Here we test the generalization ability of our proposed method with re-
spesct to the program length T . Specifically, the model is trained with Tmax = 3, but tested with
varying program lengths of T = 1, ..., 10. The results are shown in Fig. 4(c). DFS could not handle
programs when T > 1 with a time budget of 1,000 seconds. On the other hand, our model and the
supervised baseline can fairly generalize to data with a larger program length. Interestingly, when
8
Under review as a conference paper at ICLR 2022
(a)
123456789 10
Program Length (T)
(b)
(c)
Figure 4: Training efficiency and generalization ability analysis results.
the program length exceeds 7, our proposed method even slightly outperforms the supervised base-
line. The results clearly show that our proposed method has a good generalization ability without
using ground-truth programs as supervisions.
5	Related Work
Program Induction. Program induction analogs the ability of human thinking, which has regained
research interests recently (Lake et al., 2015; Chollet, 2019; Qi et al., 2021). Classical program
induction methods adopt search-based or other enumeration-based methods like Depth-First-Search
(DFS) and SMT-based Solvers (Lezama, 2008; Feser et al., 2015). Recently, the combination of deep
learning and program induction is also a trending direction (Balog et al., 2017; Irving et al., 2016).
Besides technical advancements, there are also new datasets like ARC (Chollet, 2019), PQA (Qi
et al., 2021), etc. In this paper, we focus on visual program induction tasks that require complex
primitive functions, which is mostly inspired by ARC that aims to solve complex visual abstract
reasoning tasks. Compared with the tasks considered by (Balog et al., 2017; Irving et al., 2016), our
task is much more complicated especially considering the complex functions and visual domains.
Program Synthesis. Program Synthesis could be seen as the supervised version of program induc-
tion where the annotated programs are provided as supervision, also known “using machine learning
to write programs”. Parisotto et al. (2017); Bunel et al. (2018); Devlin et al. (2017) have applied
program synthesis on the Karel environment or string transformation tasks. Ling et al. (2017) solve
the task of algebraic word problems, Sun et al. (2018) use similar techniques to learn programs for
2D visual games, and Tian et al. (2019) consider synthesizing 3D programs for 3D shapes. All these
methods rely on the supervised setting and require expensive program annotation costs.
Program Induction with latent Programs. As neural networks are good at handling high-
dimensional vector data, the modeling of program states rather than explicit programs is also ap-
pealing. Famous examples include Neural Turing Machines and its follow-up works (Graves et al.,
2014). Neural Logic Machines (Dong et al., 2019) and Neural GPU (Li et al., 2016; Devlin et al.,
2017) are also related in the latent program space. In comparison, we focus on explicit program
induction which is more explainable and the obtained programs are understandable to humans.
6	Conclusion
In this paper, we are the first to tackle the task of program induction with complex functions for the
visual abstract reasoning tasks. We model a function and its corresponding parameters as a unified
modules. Moreover, we propose a two-stage MCTS algorithm to efficiently search the action space
to provide training supervision. Our method could outperform several strong baselines, especially
has a higher efficiency. We believe this method would help us to explore a wider program induction
scenarios towards modeling much more complex functions and to achieve machines’ intelligence
and mental thinking system.
9
Under review as a conference paper at ICLR 2022
References
Matej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow.
Deepcoder: Learning to write programs. 2017.
Cameron B Browne, Edward Powley, Daniel Whitehouse, Simon M Lucas, Peter I Cowling, Philipp
Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon Samothrakis, and Simon Colton. A survey
of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in
games, 4(1):1-43,2012.
Rudy Bunel, Matthew Hausknecht, Jacob Devlin, Rishabh Singh, and Pushmeet Kohli. Leverag-
ing grammar and reinforcement learning for neural program synthesis. Proceedings of the 4th
International Conference on Learning Representations(ICLR), 2018.
Hyeong Soo Chang, Michael C Fu, Jiaqiao Hu, and Steven I Marcus. An adaptive sampling algo-
rithm for solving markov decision processes. Operations Research, 53(1):126-139, 2005.
Francois Chollet. On the measure of intelligence. arXivpreprint arXiv:191L01547, 2019.
Jacob Devlin, Rudy Bunel, Rishabh Singh, Matthew Hausknecht, and Pushmeet Kohli. Neural
program meta-induction. Neural Information Processing Systems (NIPS), 2017.
Honghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, and Denny Zhou. Neural logic
machines. Proceedings of the 4th International Conference on Learning Representations(ICLR),
2019.
John K Feser, Swarat Chaudhuri, and Isil Dillig. Synthesizing data structure transformations from
input-output examples. ACM SIGPLAN Notices, 50(6):229-239, 2015.
Jerry A Fodor. The language of thought, volume 5. Harvard university press, 1975.
Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. arXiv preprint
arXiv:1410.5401, 2014.
Sumit Gulwani, Susmit Jha, Ashish Tiwari, and Ramarathnam Venkatesan. Synthesis of loop-free
programs. ACM SIGPLAN Notices, 46(6):62-73, 2011.
Geoffrey Irving, Christian Szegedy, Alexander A Alemi, Niklas Een, Francois Chollet, and Josef
Urban. Deepmath-deep sequence models for premise selection. Advances in Neural Information
Processing Systems, 29:2235-2243, 2016.
Aysja Johnson, Wai Keen Vong, Brenden M Lake, and Todd M Gureckis. Fast and flexible: Human
program induction in abstract reasoning tasks. arXiv preprint arXiv:2103.05823, 2021.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. 2014.
John R Koza and John R Koza. Genetic programming: on the programming of computers by means
of natural selection, volume 1. MIT press, 1992.
Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level concept learning
through probabilistic program induction. Science, 350(6266):1332-1338, 2015.
A Solar Lezama. Program synthesis by sketching. PhD thesis, PhD thesis, EECS Department,
University of California, Berkeley, 2008.
Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural
networks. Proceedings of the 4th International Conference on Learning Representations(ICLR),
2016.
Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale gener-
ation: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146,
2017.
Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, and Push-
meet Kohli. Neuro-symbolic program synthesis. Proceedings of the 4th International Conference
on Learning Representations(ICLR), 2017.
10
Under review as a conference paper at ICLR 2022
Richard Pattis, J Roberts, and M Stehlik. Karel the robot. A gentele introduction to the Art of
Programming, 1981.
Steven Thomas Piantadosi. Learning and the language of thought. PhD thesis, Massachusetts
Institute of Technology, 2011.
Yonggang Qi, Kai Zhang, Aneeshan Sain, and Yi-Zhe Song. Pqa: Perceptual question answering.
In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.
12056-12064, 2021.
David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche,
Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering
the game of go with deep neural networks and tree search. nature, 529(7587):484-489, 2016.
Shao-Hua Sun, Hyeonwoo Noh, Sriram Somasundaram, and Joseph Lim. Neural program synthesis
from diverse demonstration videos. In International Conference on Machine Learning, pp. 4790-
4799. PMLR, 2018.
Yonglong Tian, Andrew Luo, Xingyuan Sun, Kevin Ellis, William T Freeman, Joshua B Tenenbaum,
and Jiajun Wu. Learning to infer and execute 3d shape programs. International Conference on
Learning RepresentationsarXiv preprint arXiv:1901.02875, 2019.
11
Under review as a conference paper at ICLR 2022
A Data Generation and Result Illustration
A.1 The primitive Functions
We listed the considered primitive functions in Table. 2.
Table 2: Primitive Functions.
Primitive Functions	Descriptions
DOT[X,Y,COL] VLINE[TX,BX,Y,COL] HLINE[LY,RY,X,COL] BLOCK[TX, LY, BX, RY, COL] BORDER[TX, LY, BX, RY, COL]	draw a dot at position (X, Y) with color COL draw a vertical line from (TX, Y) to (BX, Y) with color COL draw a horizontal line from (X, LY) to (X, RY) with color COL draw a block from (TX, LY) to (BX, RY) with color COL draw a rectangle border from (TX,LY) to (BX, RY) with color COL
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
In this table, each primitive function is implemented as a small python function. the function and
its parameters are then organized by a pytorch.nn.Module. An examples of the DOT primitive
function and its modularized form Dot are shown as follows:
import numpy as np
import torch
def DOT(In, X, Y, COL):
Out = copy.deepcopy(In)
Out[X, Y] = COL
return Out
class Dot(torch.nn.Module):
def __init__(self, H):
super ().-init—()
self.fn = DOT
self.embedding = torch.rand(size=(H,))
# ParamNet is another mlp to predict parameters.
self.params[‘X'] = ParamNet("X", H, range=MAXSIZE[0])
self.ParamS[‘Y'] = ParamNet("Y", H, range=MAXSIZE[0])
self.ParamS[’C’] = ParamNet("C", H, range=NUM_OF_COLOR)
def inference(In, Target):
S = encoder(Target) - encoder(In)
Param_x = self.ParamS['X’](S)
Param_y = self.ParamS['Y'](S)
param_c = self.params['C’](S)
return self.fn(In, param_x, param_y, param_c)
Listing 1: The primitive function DOT and its Modularized Functions
A.2 Generate the dataset
In the main experiment, we test the task under a canvas of shape (5, 5) with ten colors. This setting
results in awhole action space as 2349 (See Table. 3), which is much more larger than other tasks
ever before (Pattis et al., 1981; Balog et al., 2017).
To generate a dataset, we randomly sample a list of functions and parameters to form a program
[f(θi ),F(θ2), ∙∙∙喈 T)]
P
with T < Tmax, and generate a random Input O0, and apply
the program to O0 to obtain OT . Then (O0, OT ) is used as an input-output pairs. Moreover, due
to that some function would overwrite previous one (e.g., Fj=DOT(X,Y,1) will always overwrite
Fi =DOT(X,Y,2) if j > i),we carefully compare the generating trace [Oo, Oι,…,OT] to delete
those functions that have been overwritten.
12
Under review as a conference paper at ICLR 2022
Table 3: Function Action Size.
Primitive Functions	Overall Action Space
DOT[X,Y,COL]	C(5,1)×C(5,1)×9 = 5×5×9 = 225
VLINE[TX,BX,Y,COL]	C(5,1)×C(5,2)×9 = 5×10×9 = 450
HLINE[LY,RY,X,COL]	C(5,2)×C(5,1)×9 = 10×5×9 = 450
BLOCK[TX, LY, BX, RY, COL]	C(5,2)×C(5,2)×9 = 10×10×9 = 900
BORDER[TX, LY, BX, RY, COL]	(C(5,2) - 4)2×9 = 6×6×9 = 324
The training set in this paper consists of 20% programs with length 1, 20% programs with length
2, and 60% programs with length 3. The alpha testing set (Table. 1) has the same distribution as
training set. While the beta test set (Figure 4) consists only those datas with a program of exactly
length Tmax. In this paper, the training set contains of 10,000 input-output pairs, all the testing set
contains 1000 input-output pairs.
B	Implementation and Baselines
B.1	More details on MCTS
The model in this paper is implemented with pytorch. Basically, the encoder is a 2-layer CNN
neural network while the ParamNet (a.k.a, gθF in Eq. 6) is a three layer MLP. The hidden size in
this paper is set as 400. At each round of selection, we select 200 parameters, and using GPU to
parallelly computing all the output observations. And the whole model is optimized with an Adam
optimizer with learning rate 1e-3.
Moreover, to accelerate the training speed, we follow the setting of MuZero (Silver et al., 2016) to
implement a muti-processing system based on Ray1. The system consists of 60 explorers to contin-
uously explore the function space via the Self-Exploratory algorithm (Alg.1), and explored traces
are used to train the model via an online trainer. The trained model weight are used in the follow-
ing exploration (Fig. 5). The whole framework is launched on a GPU server with two Intel(R)
Xeon(R) Gold 6240 CPU @ 2.60GHz CPU processors and two GTX 3090 GPU proces-
sors. The whole learning process takes about two days.
Message and Log
Shared Model Weight
Explorer i
OnIineTester
Figure 5: The multi-processing learning framework of this paper.
. We also provide more details about the Self-Exploratory Algorithm in Appendix C.
B.2	Baselines
In this paper, we consider a supervised baseline, and several of the search-based baseline DFS,
BeamSearch, and MCTS. More details about them are as follows:
1https://www.ray.io/
13
Under review as a conference paper at ICLR 2022
1.	Supervised. This baseline is inspired by Lezama (2008); Tian et al. (2019). Basically,
based on st, two neural networks are used to predict Ft and Θt. This model is supervised by
the program P as described in Sec. A. We make sure that this model has similar parameters
with our SEMF. Similar implementation could also be found in Sun et al. (2018).
2.	DFS. Depth-First-Search(DFS) is one of the most famous search-based method, which
has been widely used. Despite those specialized-designed search-method (Lezama, 2008;
Gulwani et al., 2011), DFS would still be competitive the general scenarios (Balog et al.,
2017). As DFS explore the candidates according to a give order, it would help if we could
rerank the candidates and provide a better order for the algorithm.
3.	BeamSearch. BeamSearch is widely used in nature-language-processing community to
avoid local minima by tracing the top K candidates simultaneously. Rather than DFS,
BeamSearch would be seen as a constrained version of Breadth-First-Search (BFS) by
constraining the breadth to K .
4.	MCTS. MCTS is widely used to make decisions. While in this paper, we found that it
could also be used to do searching. We call this algorithm as MCTS, which iteratively
search from the root node until reach the target or reach maximum depth as described in
Alg. 1. MCTS would be more efficient in this paper for its consistency with the training
process.
C Overall Algorithm
The overall algorithm in this paper includes the Exploring phase and the Training phase, which
could be found in Alg. 2.
Algorithm 1: MCTS-based Exploration
Input: (Oin, Oout), Action Space S, Maximum Depth Tmax, Number of Traces N
Output: Training Traces Ts , Tf , To
Function Backup(node):
while node 6= root do
I node.Visit = node.visit + 1
L node = node.Parent
Function SelectChild(v):
[return arg maXu∈Ω(v) score(u)
Function Select-k-Children(v):
u=[]
while len(u) < k do
Ui = argmaxu∈Ω(v),u∈u score(U)
U u.append(ui)
_ return U
count = 0 while count < N do
node = Oin
while node.depth < Tmax and node 6= Oout do
F = SelectChild (node)
Θ1...Θk = Select-k-Children(F)
Add F, Θ1, ..., Θk to the tree
Compute Ot,i = FΘi (node)}, i = 1, ...k
node = Ot,i, i 〜Uniform(1, k)
Backup (node)
c count J count + 1
Transform traces into Ts , Tf , To and return
C.1 Detailed MCTS algorithm in this paper
A search tree in this task aims to find the programs that enables the transition from Oin to Oout . To
achieve this, we would start from Oin , iteratively select next function and parameter, and repeat this
14
Under review as a conference paper at ICLR 2022
Algorithm 2: The Self-Explore-Learnable-Functions Algorithm
Input: D = {(Oin, Oout)}, F;	// Datas and Function Primitives
Output： PF(F∣Ot-i, Oout, F); Pp,θi(Θ∣Ot-i, OT, Ξi);	// Eq. 5, and Eq. 7
TrainingQueue = Queue()
DataQueue = Queue()
Function Explorer(Pθ, {PF,θi}):
repeat
(Oin, Oout) - DataQueue.get()
TS, Tf, To J SelfExplore((O0, OT));	// ALg. 1
TrainingQueue.put(Ts, Tf, To)
until Model Converged;
Function Trainer(TrainingQueue):
repeat
Ts , Tf , To = TrainingQueue.get()
LJLF + Lθ ；
Parameter Update with Adam ;
until Model Converged;
// Update the
// Eq.
model weights
9, Eq. 10
with Adam
repeat
trainer = NewRayProcess(Trainer);
for rank in range(N) do
new .explorer = NewRayProcess(Explorer)
new_explorer.run()
trainer.run()
for (Oin, Oout) ∈ D) do
L DataQueue.put((Oin, Oout))
until Model Converged;
process until we reach Oout . This process is very similar with a DFS search, except that the search
order will dynamically change along the tree building process. Following MCTS, we introduce this
process as:
•	Child Selection. Given current observation Ot , the goal of child selection is to select a
proper function Ft+1 and Θt+1 for next step. Unlike those scenarios there are a unified
action space, in this paper, we have two sequentially action space. Note that the parameter
action space is much bigger, we use the following strategy:
Ft+1 = SelectCchild(P( ∙ ∣Ot-ι,OT; F))
{Θ(+)ι} = Select-k-Children(P( ∙ ∣Ot-ι,OT; F))
(11)
where the SelectChild function is to compute the next next node according to their score
as:
score(u)
1
pl + β ∙ α(υ)
・ P(U),
(12)
where α(u) is the visit count of the child node u, β is a scaling hyper-parameter, and P(∙) is
the learnable distribution defined as Eq. (5) (for function planing) or Eq. (7) (for parameter
prediction). Eq. 12 is a simplified version of the UCB Chang et al. (2005) score that only
remains the most important characteristic: the score is proportional to the negative square
root of visit number.
•	Node Expansion. With the select Fi and {Θi}. The search tree is expanded to a set of
new node O(+)ι, O(j[,•- O(+1, where k is the superscripts corresponding to Θ(k). In the
original MCTS algorithm, at each step, only one action is selected. But for our scenarios,
we select multiple parameters.
•	Statistics Backup. After the search reach max search step or reach target OT, the next task
is to backup the statics. In our setting, for those success node, all of its parents receives 1.
and the visit count is added 1. For those failed traces, we do not need to backup any statics.
15
Under review as a conference paper at ICLR 2022
Compared with the vanilla MCTS method. Our algorithm has two major difference:
1.	The search process includes two types of distribution. Firstly, the function planning distri-
bution on F defined in Eq. 5. Secondly, a group of distribution for parameter prediction,
each of which corresponds to one of the primitive function, defined in Eq. 7 on ΞF . This
two types of distribution guides the sampling process. Compared with a unified action dis-
tribution on F , this two-stage sampling introduces extra sampling complexity, but gains
more explainability and robustness for training.
2.	Within the two-stage sampling, the function planning is a discrete distribution with |F |
dimensions while the parameter prediction is a discrete distribution with ∣Ξf| dimension.
The latter dimension is much more bigger than the first one. In this paper, we tackle this
problem by selecting more than one child when it comes to the parameter selection parts.
An extra
D Result Illustrations
Fig. 6 illustrates some of the input output observations and successful model predictions. Also In
Fig. 7, we show an case that the prediction is not the same with the ground-truth. This is usually the
case: The ground-truth program always is not the unique answer. This would provide more inspi-
ration that the supervised training model could be further improved if considering the uniqueness of
the program.
16
Under review as a conference paper at ICLR 2022
Predicted programs and Traces
(1)BORDER[0,0,4,4,9]; BORDER[1,1,3,3,5];
DOT[2,2,4];DOT[0,4,5]
Target Program
BORDER[1,2,3,4,4];
BORDER[1,0,4,2,4];
BORDER[0,0,4,4,9];
DOT[0,4,5];
BORDER[1,1,3,3,5]
Input Target
Target Program
BLOCK[0,0,1,1,7];
BLOCK[0,3,1,4,3];
BLOCK[3,3,4,4,6];
BORDER[1,1,3,3,1]
Predicted programs and Traces
(1)BLOCK[0,0,1,1,7];BLOCK[0,3,1,4,3];
BLOCK[3,3,4,4,6];BORDER[1,1,3,3,1]
Target Pro gram
VLINE[2,3,3,8];
D0T[3,3,9];
D0T[3,1,4];
D0T[3,2,3];
HLINE[3,4,2,6]
Predicted programs and Traces
(1) VLINE[2,3,3,8];D0T[3,1,4];D0T[3,3,9];
HLINE[3,4,2,6];DOT[3,2,3]
Figure 6:	Results Illustrations.
17
Under review as a conference paper at ICLR 2022
Target Program
BORDER[0,1,2,4,7];
BORDER[2,1,4,4,4];
HLINE[3,4,1,1];
Predicted programs and Traces
Figure 7:	Results Illustrations.
18