Under review as a conference paper at ICLR 2022
On the Effect of Input Perturbations for
Graph Neural Networks
Anonymous authors
Paper under double-blind review
Ab stract
The expressive power of a message passing graph neural network (MPGNN)
depends on its architecture and the input node attributes. In this work, we study
how this interplay is affected by input perturbations. First, perturbations of node
attributes may act as noise and hinder predictive power. But, perturbations can also
aid expressiveness, by making nodes more identifiable. Recent works show that
unique node IDs are necessary to represent certain functions with MPGNNs. Our
results relate properties of the noise, smoothness of the model and the geometry
of the input graphs and task. In particular, we take the perspective of lower
bounding smoothness for achieving discrimination: how much output variation
is needed for exploiting random node IDs, or for retaining discriminability? Our
theoretical results imply constraints on the model for exploiting random node IDs,
and, conversely, insights into the tolerance of a given model class for retaining
discrimination with perturbations of node attributes.
1	Introduction
Graph Neural Networks (GNNs) (Scarselli et al., 2008) are the state-of-the-art representation learning
algorithms on graphs. Important variants of GNNs include Graph Attention Networks (GATs)
Velickovic et al. (2018) and Graph Convolutional Networks (GCNs) KiPf & Welling (2017). They
have shown to be quite successful in practice, e.g., in physics Shlomi et al. (2020); Battaglia et al.
(2016), predicting drug interations Lim et al. (2019), protein design Strokach et al. (2020); Ingraham
et al. (2021), studying molecules Jin et al. (2018); Duvenaud et al. (2015), quantum chemistry Gilmer
et al. (2017), and drug discovery Sun et al. (2020) (see Wu et al. (2020) for a survey on GNNs, and
Zhou et al. (2020) for a review on applications).
Despite having numerous successful empirical results, it is observed that GNNs are sensitive to
perturbation in both graph structure and node attributes (see e.g., Zugner & Gunnemann (2019)), and
they are vulnerable to over-smoothing: having deep networks results in poor representations (see
e.g., Kipf & Welling (2017); Oono & Suzuki (2019)). Intuitively, deeper networks allow to fit more
smooth functions to the given data, along with having hidden representations depending on large
neighborhoods. These issues have been addressed in several papers, and subsequently, people also
tried to provide a consistent theory for these observation.
The discrimination power or the expressive power of GNNs is also another well-studied topic, and
many works notice that having similar initial node attributes at different nodes may affect the power
of network to distinguish distinct graphs, as well as counting subgraphs, while node identifiers
(IDs), which are typically randomly chosen, can resolve the issues. But how much smoothness/non-
smoothness of the model can affect the benefits of those (random) node IDs? Here by the smoothness
of the model we means (lower/upper) bounds involving (perhaps higher-order) derivatives of the
representation with respect to hidden representations, where here these derivatives assumed to exist.
The goal of this paper is to unify these observations/questions in one theory and relate the expressive
power of GNN to the smoothness of the model and the sensitivity of it to the random perturbation of
initial node attributes (or having (random) node IDs1). Our approach is restrict the class of functions
1Also, initial node attributes can be considered random in cases that are task independent (while quite being
informative). For example, a GNN running on a social network can be initialized with individuals gender (as
initial attributes) while the learning task is independent from the information.
1
Under review as a conference paper at ICLR 2022
that GNNs can approximate (i.e., the expressive power of GNNs), if the model is robust against
random perturbations of initial attributes, and satisfy upper/lower bounds on its (perhaps higher-order)
derivatives with respect to hidden representations.
Our main finding is a quantitative lower bound relating the following important notions about GNNs
to each other: expressive power, geometry of the noiseless, smoothness of the model, and sensitivity
to node attributes. In particular, we observe that non-smoothness representations are essential to
express many graph classifiers with GNNs while still remaining robust against random perturbation of
attributes. This scenario can also happen when node attributes are still informative, but independent
of the learning task2 . In addition, since the class of graph classifiers achieved with smooth and
non-sensitive GNNs is completely restricted, we conclude that we should either be non-robust against
random perturbations, or we should accept non-smooth representation to break the bound.
In short, in this paper, we make the following contributions:
•	We present a theory explaining why restriction the model to smooth GNNs and still demand-
ing robustness against random perturbations of node attributes can dramatically decrease
the expressive power of the model. The result is a quantitative lower bounds which allows
to observe the effects of the discussed notions on the representation in one mathematical
equation, which we refer to it as an uncertainty principle for GNNs too.
•	We introduce the notion of discrepancy of graph classifiers for studying GNNs, study its
properties, and relate it to the smoothness, sensitivity, and the expressive power of GNNs.
•	Our bound also applies to the expressive power of GNN with random (or task independent)
node attributes, which can be of independent interest. In particular, we study how smoothness
can affect the expressive power of GNN with random node attributes and the results suggest
that while node IDs can improve the expressive power in general, with more smooth GNNs
can approximate a restricted class of graph classifiers.
2	Related works
Theory of GNNs. The expressive power of GNNs is limited to the so-called Weisfeiler-Lehman
(WL) graph isomorphism test (Xu et al., 2019), and under specific conditions, they are universal
approximator (Scarselli et al., 2009) (see (Azizian & marc lelarge, 2021; Sato, 2020) for more on
expressive power). Note that function approximation and graph isomorphism testing with GNNs are
equivalent (Chen et al., 2019). Beyond graph isomorphism testing, GNNs are known to be unable
to count substructures (see for instance (Chen et al., 2020b; You et al., 2019)). To improve the
expressive power of GNNs, it is proposed to use random attributes (Sato et al., 2021) or coloring
nodes (Dasoulas et al., 2020). We notice that just being able to represent a functions does not mean
that the representation is achievable with smooth functions. For example, in the context of learning on
sets, it is shown that imposing regularity conditions on the underlying functions results in limitations
on representing functions (Wagstaff et al., 2019). In addition, GNNs suffer from the problem of
over-smoothing (Oono & Suzuki, 2019). For example, with dropping edges is an instance of defeating
against over-smoothing problem (Rong et al., 2020). Recently, generalization and stability bounds
for GNNs have been also derived, e.g., see (Garg et al., 2020; Verma & Zhang, 2019).
We note that although GNNs with infinite width and node identifiers are Turing-complete (Loukas,
2020a), depth/width lower bounds show that GNNs should scale to several graph learning problems
(Loukas, 2020b;a). These papers however does not relate the expressive power of GNNs to the
smoothness and they also work only for discrete spaces. For the two-layer neural networks, the
expressive power and smoothness are conjectured to satisfy a quantitative law of robustness (Bubeck
et al., 2021).
Other related works. Adversarial attacks on graph representations have been well studied, see for
instance (Bojchevski & Gunnemann, 2019a) which is about edge attack on random walk methods. In
general, GNNs are known to be sensitive to adversarial perturbations (Zugner & Gunnemann, 2019),
and heuristic solutions based on task and application exist, e.g., (Zhu et al., 2019; Jin et al., 2020b).
For more information about adversarial attacks/defenses on graphs, see reviews (Jin et al., 2020a;
2For example, in social networks, node attributes while carry information about nodes, may be independent
of a specific learning task and can be considered as noisy inputs.
2
Under review as a conference paper at ICLR 2022
Sun et al., 2018; Xu et al., 2020), and for solutions see (ZUgner & Gunnemann, 2020; Liu et al., 2020;
Tang et al., 2020; Zugner & Gunnemann, 2019; Dai et al., 2018; BOjchevski & Gunnemann, 2019b;
Geisler et al., 2020; Chen et al., 2020a).
3	Background, Motivation, and Problem Formulation
3.1	Graph Neural Networks (GNNs)
Let Gn denote the set of all simple graphs on n vertices, and let Gn ⊆ Gn be an arbitrary subset.
Assume that for each element of Gn , the maximum degree is upper/lower bounded by ∆max , ∆min ∈
N. Attached to a simple graph G = ([n], EG), there are initial attributes xv ∈ X, v ∈ [n], for
nodes, and non-zero e(u,v) ∈ X, (u, v) ∈ EG, for edges (by setting zero elsewhere it can also
be extended to all pairs), where X ⊆ Rd is a compact convex set. Thus, a graph with initial
attributes is just a tensor which lies in Rn×n×d. The initial attributes profile is denoted by init(G) =
({xv}v∈[n] , {e(u,v)}(u,v)∈E). A graph representation is a function h(.; θ) : Rn×n×d → R, that is
further invariant under permutations of nodes, where θ denotes the set of all (learnable) parameters,
and θ ∈ Θ for some compact set Θ. A Message Passing Graph Neural Network (MPGNN) is a
particular way to represent graphs with specific iterative learnable functions, and it is a special case
of Graph Neural Networks (GNNs) (Gilmer et al., 2017). In this paper, we consider MPNNs as graph
representation and we use the two terms GNN and MPGNN interchangeably.
We consider the most expressive GNN, i.e., Graph Isomorphism Network (GIN) in our formulation
(Xu et al., 2019). However, our analysis and results are not restricted to this model and are applicable
to other first order GNNs with minor changes. Let us consider the following general formulation. In
a GNN with k iterations, at iteration ` ∈ [k], we compute
hV'=Φ'(hV'T) + X Ψ'(hU'T), e(u,v))),	(1)
u∈N (v)
for each node V ∈ [n], where N(V) denotes the set of neighbors of node v, and Ψ', Φ', ' ∈ [k], are
learnable functions with appropriate dimensions, e.g, they can be modeled by Multi-Layer Perceptron
(MLP), thanks to the universal approximation property (Hornik et al., 1989; Hornik, 1991). In
particular, to update, it first aggregates on the neighbors of a node V ∈ [n], and then combine the
result with the current representation of V to achieve the updated representation. Throughout this
paper, We assume that Ψ', Φ',' ∈ [k], have continuous derivatives. For example, if the activation
function of MLPs is twice differentiable, then the assumption is satisfied.
To initialize, let h(v0) = xv , for V ∈ [n]. Finally, a function is applied, called READOUT function, to
achieve the final representation of the graph G,
h(G) = Φ X h(vk),	(2)
v∈[n]
where Φ : Rdk → R is a continuously differentiable real-valued function. To emphasize, we
can also denote the final representation of a graph G with h(G, init(G); θ), where θ denotes all
parameters involving the representation. Note that some GNNs use the concatenation function as
READOUT, but here we focus on a permutation-invariant function of graphs which allow to analyze
the graph classification problem. It is known that this special READOUT function can model any
permutation-invariant function as well (Zaheer et al., 2017).
3.2	Random Node Attributes Perturbation
In the most simple case, the initial node attributes may be extractable from G itself (e.g, degree, or
from data attached to the graph). They can also be informative for the underlying learning task. The
perturbed representation3, which is now a random variable (since the perturbation is random), is
2
denoted by hpert(G) for any graph with attributes G ∈ Rn×n×d, and is achieved by Xv 〜N(μv,谭Id)
3In order to facilitate the analysis we consider the Gaussian perturbation in the paper but the assumption can
be easily replaced to the other other perturbations (e.g., integer perturbation).
3
Under review as a conference paper at ICLR 2022
2
2
and e(u,v)〜N(p(u,v), -e-Id) where。£, σ2 denote the variance of perturbations, and μv, V ∈ [n],
are graph/node dependent noiseless node attributes. Still, h(G) denotes the representation without
randomness, achieved by noiseless initial attributes. We also consider the following bounds for the
noiseless initial attributes: kμv ∣∣2 ≤ Bμ for all V ∈ [n], and 1 ≤ ∣∣ρu,v ∣∣2 ≤ BP for all (u, V) ∈ Eg,
and ρu,v = 0 for other pairs4.
3.3	Graph Classifiers and Discrepancy
In this paper, a function f : Rn×n×d → R is called a graph function if and only if for any
G1, G2 ∈ Rn×n×d, we have f(G1) = f(G2) whenever G1 ' G2 where ' means the graph isomorphism
(with respect to the attached initial attributes). A graph classifier is a graph function whose codomain
is {±1}. Let P denote an arbitrary but fixed probability measure on Rn×n×d which is supported on
the class of graphs with initial attributes5. The given dataset of graphs can be considered as i.i.d.
samples from P. For a graph classifier f, let ηf+, (and also ηf-) denote the conditional probability
measures given f(G) = 1 (or f(G) = -1), and we refer to them as the measures associated with f.
For any G, G0 ∈ Rn×n×d with initial attributes define their λ-distance as
dist(G, G0; λ) := min X X kμv - μ∏(v)k2 + λ X kρ(u,v) - ρ(π(u),π(v))k2 },	⑶
π∈Sn
v∈[n]
u,v∈[n]
u<v
where Sn denotes the set of permutations of [n].
For each λ > 0 this defines a metric on the space of graphs with initial attributes. In particular,
for simple graphs without different initial attributes this reduces to the edit distance on graphs:
the minimum number of edges to be added/removed to construct one graph from the other (with
respect to the graph isomorphism). Note that dist(G1, G2; λ) = 0 if and only if G1 ' G2 and always
dist(G1, G2; λ) ≤ 2Bμn + λBρ∆maχn if∣μV∣2 ≤ Bμ and kρ(u,v)∣∣2 ≤ BP for all nodes and i = 1,2.
Discrepancy of a graph classifier is an important quantity in our analysis. Roughly speaking, in
the case of simple graphs without initial attributes, it is the average number of edges required to
be removed/added to change the output of the classifier, and it is similar to the notion of margin in
classical classification problems. First note that we have already defined a metric on the set of graphs
with initial attributes, hence we can define the Wasserstein distance for probability measures on this
space.
Definition 1. For a graph classifier f, the discrepancy of f is defined as disc(f) := W1(ηf+, ηf-),
where W1 denotes the Wasserstein distance, and ηf+, ηf- are two measures associated with f. In
words, the discrepancy of a graph classifier is the optimal transportation cost of changing the binary
label, for two measures induced by random choice of the graphs.
For more technical information about optimal transport in this space, see Appendix A. Also, we
compute the discrepancy of well-known graph classifiers in Section 5.
An important problem in deep learning and graph representations learning is to determine the
approximation power of a model: the classifiers that can be approximated by some parameters.
Typically, we say that a graph classifier can be approximated by a class of graph representations if and
only if we can successfully classify the data with a threshold function applied on the representation.
Accordingly, under the perturbation of input, the associated probability of error must be small. In
what follows, we state this definition rigorously.
Definition 2. A graph classifier f is called to be approximated under perturbations (with the error
probability of at most δ) by a class of parameterized GNNs h(.; θ), θ ∈ Θ, if and only if
inf inf P f(G) 6= 1{hpert(G) ≥ γ} ≤ δ,
θ∈Θ γ∈R
(4)
where γ ∈ R is a threshold which possibly depends on θ, and 1{.} is the sign function.
4Clearly, those bounds must hold uniformly on all observable graphs.
5We assume that given each graph, the resulting measure in absolutely continuous with respect to the
Lebesgue measure, and we assume that each graph classifier is measurable in this space.
4
Under review as a conference paper at ICLR 2022
4	Main Result
Let Gn denote the set of observable graphs with initial attributes. Also, let Us denote the gradient of
the graph representation for G ∈ Gn with respect to initial attributes by ∂vh(G), d(u,v)h(G) for all
v ∈ [n], (u, v) ∈ EG (similarly defined for hpert(G)). The main result of this paper is summarized in
the following theorem.
Theorem 1. Consider a parametrized class of GNNs h(.; θ) which obey the following properties.
•	[polynomial approximation] For any graph with initial attributes G ∈ Gn, there exists a
polynomial of initial attributes6, of degree at most kpoly, such that
|hpoly(G) - h(G)| ≤ Cpoly
var(hpert(G)).
(5)
This polynomial may depend of G, and the RHS, which can be interpreted as the normalized
approximation error by polynomials is bounded. The variance of representation is just used
to normalize the error in RHS.
•	[lower bound on average gradients7] For any G ∈ Gn, ∣∣E[∂vhpert(G)]k2 ≥ Lmin,
kE[∂(u,v)hpert(G)]k2 ≥ Lmin for all v ∈ [n], (u, v) ∈ EG.
•	[upper bound on norm of representations] For any G ∈ Gn, v0 ∈ [n], and ' ∈ [k],
khV' 1)k2 ≤ n X LhIlXv ∣∣2 + |E-| X Lhke(u,v) l∣2 + Bh.	⑹
v∈[n]	G (u,v)∈EG
This means that when ∣∣xv k2, ∣∣e(u,v)∣∣2 = O ⑴,then ∣∣hv'0-1)k2 = O(2Lh + Bh).
•	[upper bound on gradients] For any G ∈ Gn, ∣∂vh(G)∣∣2 ≤ LmaX, ∣∂(u,v)h(G)∣2 ≤ LmaX
for all v ∈ [n], (u, v) ∈ EG.
•	[smoothnessfor aggregation] For any G ∈ Gn,
kψ'(hUIT), e(u,v))k2 ≤ LΨ llhu-1)k2 + LΨke(u,v)k2.	⑺
Then, a graph ClaSSifier f : Gn 一 {±1} can be approximated by the class (with the error probability
of at most δ), only if
(disc(f )+8.68 (1 + 2nδCp0ly (1 + 3 2 k poly ))4(2Bμ + λBρ∆maX))	(8)
X LmaX(I + ɪ (1 + 2kLψ(Lh(Bμ + σn + BP + σ e) + Bh) + 2kLΨ(1 + σE))) (9)
≥
0.17Lmin σn√n J(I + 2σe2 ʌ`min)
(1 + 2Cpoly (1 + 31 kpoly ))2
(10)
Let us interpret the result and conditions. Theorem 1 is a quantitative bound restricting the expressive
power of GNNs with the smoothness of the model, variance of perturbations, and the discrepancy of
graph classifiers. A more general form of this theorem is also available in appendices, which does
not involve lower bounds on the average gradients. We note that a class of GNNs can satisfy the
conditions of Theorem 1, if we have lower/upper bounds on the gradient of graph representation, and
also we can locally approximate the normalized versions of it with polynomials, which we interpret
them as smoothness conditions. Note that the approximation by polynomials essentially follows from
having bounds on higher-order derivatives. However, the converse is not true. Also, the lower bound
on the average gradients, for small perturbations, is essentially the gradient without perturbations.
6For vectors, consider polynomials of entires.
7This condition can be relaxed to average of these quantities too, we just considered the most simple case
here and the more general form of the theorem is available in appendices.
5
Under review as a conference paper at ICLR 2022
Remark 1. A graph representation is called smooth (on observable graphs) if and only if 8 the
bounds Bμ,Bρ,Bh,Lh,kLψ,Cpoiy, kPoly = O(1) ,and = O ⑴ are satisfied. And consider σ =
σn = σe = Θ(1) (bounded variance perturbation), and λ = Θ(1). In this case, the condition in the
theorem can be written as
(disc(f) + O(nδ∆maχ)) & -Lminσ√n.	(11)
Lmax
We interpret Lmin/Lmax as a notion of inverse condition number for smooth GNNs. The above
Condition means that if a smooth GNN further satisfies the Condition Lmin/LmaX = Ω(1) (i.e.,
having small condition number), and has small probability of error δ (n∆max)-1, and we can
approximate the graph classifier f with it (under perturbations), then the discrepancy of classifier
must be lower bounded by O(√n). However, we will see in next section that this is quite restricting,
and the class of those classifiers is not so large. Note that discrepancy is an intrinsic value assigned
to the classifier, and it independent for the representation.
Let us also notice an important fact about the results: the conditions are obtained via a statistical
formulation of the problem, hence the computational tractability is not considered here. Indeed, the
bounds even hold for arbitrary large networks as long as the smoothness conditions are satisfied.
For better interpretation of the result, we introduce a new notion in the following subsection.
4.1 Separability of (Noiseless) Node Attributes
As one can expect, the effect of random perturbation to node attributes depends on how noiseless
attributes are separated. In other words, if noiseless attributes are well-separated from each other,
probably having random perturbation could not change the final representation much, and the model
is more expressive (see Definition 2). In order to measure this separation, we define separability of
the noiseless node attributes as the maximum change when we add an edge to a graph.
Definition 3. The separability ofnoiseless node attributes (μv)v∈[n] is defined as
sep(μ):
max
G,G0∈Gn
dist(G,G.λ) = 1
Σ
v∈[n]
kμv - μVk2.
(12)
In words, the separability of node attributes means how much adding an edge can change the initial
node attributes. It is worth mentioning that the higher separability can make the learning task easier.
Example 1. In the absence ofnoiseless node attributes sep(μ) = 0. This may happen when the node
attributes are completely random.
Example 2.	If the initial node attributes are the degrees of nodes (either one-hot encoded or uncoded)
then sep(μ) = 2.
Example 3.	If the initial node attributes are one-hot encoded, and adding an edge can only change
the noiseless attributes of at most T nodes, then sep(μ) ≤ 2T. If T《n then sep(μ)《n.
In many reasonable scenarios, We can expect sep(μ) = O(1) or at least sep(μ) = o(n).
4.2	Uncertainty and GNNs
Let us assume there is no edge attribute. Note that from the definition of distance function betWeen
graphs, We can conclude (if λ = 1) for a given set of observable graphs and a graph classifier f,
_ , ..	<— , ., , , _ ,,,
disc(f) ≤ disc(f) × (sep(μ) + O(1))	(13)
Where disc(f) is the discrepancy of f With respect to the edit-distance.
8We bound kLΨ because the linear approximations of the netWork accumulate, and if the output is bounded,
it makes sense to have this bound too. Indeed, k in our model can be arbitrary large. Also, one can rescale Ψ'
functions and change the mode a little bit to come up With other cases, and the assumption leads to no loss of
generality, other than boundedness of output along With other conditions.
6
Under review as a conference paper at ICLR 2022
In this case, the result in Theorem 1 can be written as
(disc(f) + O(1))卜ep(μ) + O(1)) & Lminσ√n.	(14)
Lmax
This can be considered as an uncertainty principle for smooth GNNs: the product of the discrepancy
of the target graph classifier (which measures how simple is that graph classifier to be approximated
by a GnN), and the separability of the noiseless node attributes (which measures how noiseless
node attributes are capable to help the classification) is lower bounded by √n. Additionally, if also
sep(μ) = O(1), as we argued before, we have a strong lower bound: disc(f) & √n. As we will see
later in Section 5, this lower bound completely restricts the class of functions GNN is capable to
approximate and consequently if also gives lower bounds on the estimation error of estimating graph
parameters. Note that here the new bound is with respect to the edit-distance.
Remark 2. The above bound also shows that if we want to approximate a "complex" graph classifier
(disc(f) = O(1)) then one of the following cases must happen:
•	sep(μ) & √n. In this case, the noiseless node attributes can be quite informative.
•	The model is non-smooth: one of the smoothness conditions are violated.
•	The model has large probability of error (at least O(n-1)).
•	The model is not robust against random perturbation of node attributes: the resulting
representation is sensitive.
4.3	Multi-class Classification
In this part, we extend Theorem 1 to the multi-class graph classifiers. A function f : Gn → [P] is
called a multi-class graph classifier, where p ∈ N. The case p = 2 reduces to the aforementioned
class of (binary) graph classifiers.
First we define approximation of multi-class graph classifiers with GNNs.
Definition 4. A multi-class graph classifier f : Gn → [p] can be approximated (with error probability
of at most δ) by a class of parameterized GNNs h(.; θ), θ ∈ Θ, if and only if
inf inf sup Pf(G) 6= ζ(hpert(G)) ≤δ,	(15)
θ∈θ ζ∈Z P∈{Pp0∙0Mp0∈[p]} V	/
where Z is the set of piecewise constant functions ζ : R → [p] with at most p - 1 discontinuity points.
Also, Pp0 is the conditional probability measure on f-1(p0), for each p0 ∈ [p], andN denotes the
Gaussian probability measure corresponded to the perturbations (see 3.2 for more explanations).
Remark 3. The motivation of this definition is that if f(G) ≈ hpert(G) then there is confidence
intervals allowing to infer f(G) from hpert(G) with high probability.
Let us define the discrepancy of multi-class graph classifiers as follows.
Definition 5. For a multi-class graph classifier f : Gn → [p], the discrepancy of f is defined as
disc(f) := min disc(fp1,p2 ),	(16)
p1 ,p2 ∈[p]
p1 6=p2
where fp1,p2 (G) : f-1(p1) ∪ f-1(p2) → {±1} is defined as
f	(G) := +1 iff f(G) = p1	(17)
fp1,p2(G) := -1	iff f(G) =p2	(17)
To define the discrepancy of multi-class graph classifiers, we consider all pairs of differently labeled
graphs according top1,p2, and take the minimum discrepancy of the corresponded graph classifier.
Note that the set of observable graphs here is f-1(p1) ∪ f-1(p2) for fixed p1 6= p2.
The main result of this part is the following proposition which directly follows from Theorem 1.
Proposition 1. Theorem 1 holds for multi-class graph classifiers f : Gn → [p].
Note that to satisfy the smoothness conditions for multi-class graph classifiers, we can normalize the
resulting representations fp1,p2, since Theorem 1 holds for eachp1,p2.
7
Under review as a conference paper at ICLR 2022
Table 1: Approximation bounds for graph parameters
f Gn → [0,t )
Parameter	disc( fp)	Discrepancy & additive error		κ
Number of edges	n∆max + O(1)	disc(fP)	Eadditive + O(1)	1
Number of triangles	P + O(1)	disc(fP)	3Eadditive + O(1)	3
Number of subgraphs H	常+。⑴	disc(fP)	mH Eadditive + O (1)	mH
Diameter	n-1 +O(1)	disc(fP)	Eadditive + O(1)	1
Max-cut	n∆max + O(1)	disc(fP)	Eadditive + O(1)	1
Min-cut	n∆max + O(1)	disc(fP)	Eadditive + O(1)	1
Clique number	2 -Pax + O(1)	disc(fP)	∆max Eadditive + O (1)	∆max
Independence number	^pax + O(1)	disc(fP)	∆max Eadditive + O (1)	∆max
Number of connected components	P + O(1)	disc(fP)	Eadditive + O(1)	1
5 Applications of the Derived B ound
In this part, we give some applications of the proved bound by computing the discrepancy of a
number of well-known graph functions. First consider a graph property as f : Gn → [0, T), e.g., the
number of edges, diameter, etc. To approximate it with a GNN, let’s consider the discrepancy of its
quantization to a p-level function:
fp(G) ：= P0 iff T (p0 - 1) ≤ f (G) <Tp0,	(18)
pp
for any p0 ∈ [p]. If f as a multi-class graph classifier can be approximated by GNNs, then fp can be
approximated by GNNs, and the estimation error for f is at most Eadditive = T. More precisely, this
quantity is the expectation of the absolute value of the error f - fGNN.
Hence, to achieve a lower bound for representing a graph parameter (function) from the main result,
we need to compute the discrepancy of fp. We expect that disc(fp) is decreasing with p, meaning that
having more resolution applies more complexity for representation. We will make this observation
more clear in the following proposition and achieve bounds on the estimation error Eadditive .
Proposition 2. For any graph parameter in Table 1, there is an appropriate set of graphs and T ∈ R
such that we have the provided bounds on the table on the discrepancy of their quantization. Also,
the additive error of approximation is related to the discrepancy in the third column.
Note that the number of subgraphs can be interpreted as induced or not necessarily induced, and the
bounds are achieved for both cases. Also, nH and mH denote the number of nodes and the number
of edges of a small graph H, and typically for counting tasks we have nH, mH = O(1).
Now using the above table and the result on the approximation of the multi-class graph classifiers, we
can derive the following bound on the estimation error of the above graph parameters.
Remark 4. The proposition gives a quantitative bound based on the variance of perturbation,
smoothness of the model, separability of noiseless attributes, and the additive estimation error of
representation. In particular, under the assumptions in Section 4.2, we have the following necessary
condition:
(K X Eadditive + O(1))"p(μ) + O(1)) & √n.	(19)
We can immediately conclude the following proposition.
Proposition 3. Consider the case that sep(μ) = O(1). Then, for counting subgraph H (either
induced or not necessarily induced) with GNNs, we have
Eadditive & √n.	(20)
This means that roughly speaking smooth GNNs with node attributes perturbation are unable to count
subgraphs with the additive estimation error o(√n).
8
Under review as a conference paper at ICLR 2022
The lower bounds in previous propositions suggest that smooth GNNs with node attributes perturba-
tions are subject to high approximation error for the graph parameters in Table 1, and that is why we
can argue that those graph representations are highly restricted to large error.
6 Conclusion
In this paper, we theoretically analyze GNNs with smooth representations, along with perturbed node
attributes. It is observed that having smoothness highly restricts the model, and imposes several lower
bounds on the approximation error for graph parameters. Our bound also allows to achieve compute a
trade-off relating the expressive power of GNNs to the smoothness, separability of noiseless attributes,
and the variance of perturbation.
References
Waiss Azizian and marc lelarge. Expressive power of invariant and equivariant graph neural networks.
In International Conference on Learning Representations, 2021.
Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, et al. Interaction networks
for learning about objects, relations and physics. In Advances in neural information processing
systems,pp. 4502-4510, 2016.
Aleksandar Bojchevski and StePhan Gunnemann. Adversarial attacks on node embeddings via graph
poisoning. In International Conference on Machine Learning, pp. 695-704. PMLR, 2019a.
Aleksandar Bojchevski and Stephan Gunnemann. Certifiable robustness to graph perturbations. arXiv
preprint arXiv:1910.14356, 2019b.
Stephane Boucheron, Gabor Lugosi, and Pascal Massart. Concentration inequalities: A nonasymptotic
theory of independence. Oxford university press, 2013.
Sebastien Bubeck, Yuanzhi Li, and Dheeraj M Nagaraj. A law of robustness for two-layers neural
networks. In Conference on Learning Theory, pp. 804-820. PMLR, 2021.
Xu Chen, Ya Zhang, Ivor Tsang, and Yuangang Pan. Learning robust node representation on graphs.
arXiv preprint arXiv:2008.11416, 2020a.
Zhengdao Chen, Soledad Villar, Lei Chen, and Joan Bruna. On the equivalence between graph
isomorphism testing and function approximation with gnns. In Advances in Neural Information
Processing Systems, pp. 15894-15902, 2019.
Zhengdao Chen, Lei Chen, Soledad Villar, and Joan Bruna. Can graph neural networks count
substructures? arXiv preprint arXiv:2002.04025, 2020b.
Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. Adversarial attack on
graph structured data. In International conference on machine learning, pp. 1115-1124. PMLR,
2018.
George Dasoulas, Ludovic Dos Santos, Kevin Scaman, and Aladin Virmaux. Coloring graph neural
networks for node disambiguation. In Christian Bessiere (ed.), Proceedings of the Twenty-Ninth
International Joint Conference on Artificial Intelligence, IJCAI-20, pp. 2126-2132. International
Joint Conferences on Artificial Intelligence Organization, 7 2020.
David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alan
Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular
fingerprints. In Advances in neural information processing systems, pp. 2224-2232, 2015.
Vikas Garg, Stefanie Jegelka, and Tommi Jaakkola. Generalization and representational limits of
graph neural networks. In Int. Conference on Machine Learning (ICML), pp. 5204-5215. 2020.
Simon Geisler, Daniel Zugner, and Stephan Gunnemann. Reliable graph neural networks via robust
aggregation. Advances in Neural Information Processing Systems, 33, 2020.
9
Under review as a conference paper at ICLR 2022
Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural
message passing for quantum chemistry. In Proceedings of the 34th International Conference on
Machine Learning-Volume 70, pp.1263-1272, 2017.
Kurt Hornik. Approximation capabilities of multilayer feedforward networks. Neural networks,
1991.
Kurt Hornik, Maxwell Stinchcombe, Halbert White, et al. Multilayer feedforward networks are
universal approximators. Neural networks, 1989.
John Ingraham, Vikas Kamur Garg, Regina Barzilay, and Tommi S Jaakkola. Generative models for
graph-based protein design. 2021.
Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, and Jiliang Tang. Adversarial attacks and defenses on graphs:
A review and empirical study. arXiv preprint arXiv:2003.00653, 2020a.
Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. Graph structure
learning for robust graph neural networks. In Proceedings of the 26th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining, pp. 66-74, 2020b.
Wengong Jin, Kevin Yang, Regina Barzilay, and Tommi Jaakkola. Learning multimodal graph-to-
graph translation for molecular optimization. arXiv preprint arXiv:1812.01070, 2018.
Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks.
In International Conference on Learning Representations, 2017.
FD Lesley and VI Rotar. Some remarks on lower bounds of chebyshev’s type for half-lines. JIPAM,
4(5):96, 2003.
Jaechang Lim, Seongok Ryu, Kyubyong Park, Yo Joong Choe, Jiyeon Ham, and Woo Youn Kim.
Predicting drug-target interaction using a novel graph neural network with 3d structure-embedded
graph representation. Journal of chemical information and modeling, 59(9):3981-3988, 2019.
Yang Liu, Xianzhuo Xia, Liang Chen, Xiangnan He, Carl Yang, and Zibin Zheng. Certifiable
robustness to discrete adversarial perturbations for factorization machines. In Proceedings of the
43rd International ACM SIGIR Conference on Research and Development in Information Retrieval,
pp. 419-428, 2020.
Andreas Loukas. What graph neural networks cannot learn: depth vs width. In International
Conference on Learning Representations, 2020a.
Andreas Loukas. How hard is to distinguish graphs with graph neural networks? In Advances in
Neural Information Processing Systems, 2020b.
Ryan O’Donnell. Analysis of boolean functions. Cambridge University Press, 2014.
Kenta Oono and Taiji Suzuki. Graph neural networks exponentially lose expressive power for node
classification. arXiv preprint arXiv:1905.10947, 2019.
Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. Dropedge: Towards deep graph convo-
lutional networks on node classification. In International Conference on Learning Representations,
2020.
Ryoma Sato. A survey on the expressive power of graph neural networks. arXiv preprint
arXiv:2003.04078, 2020.
Ryoma Sato, Makoto Yamada, and Hisashi Kashima. Random features strengthen graph neural
networks. In Proceedings of the 2021 SIAM International Conference on Data Mining (SDM), pp.
333-341. SIAM, 2021.
F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini. Computational capabilities
of graph neural networks. IEEE Transactions on Neural Networks, 20(1):81-102, 2009.
Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The
graph neural network model. IEEE Transactions on Neural Networks, 20(1):61-80, 2008.
10
Under review as a conference paper at ICLR 2022
Jonathan Shlomi, Peter Battaglia, and Jean-Roch Vlimant. Graph neural networks in particle physics.
Machine Learning: Science and Technology, 2(2):021001, 2020.
Alexey Strokach, David Becerra, Carles Corbi-Verge, Albert Perez-Riba, and Philip M Kim. Fast and
flexible protein design using deep graph neural networks. Cell Systems, 11(4):402-411, 2020.
Lichao Sun, Yingtong Dou, Carl Yang, Ji Wang, Philip S Yu, Lifang He, and Bo Li. Adversarial
attack and defense on graph data: A survey. arXiv preprint arXiv:1812.10528, 2018.
Mengying Sun, Sendong Zhao, Coryandar Gilvary, Olivier Elemento, Jiayu Zhou, and Fei Wang.
Graph convolutional networks for computational drug development and discovery. Briefings in
bioinformatics, 21(3):919-935, 2020.
Xianfeng Tang, Yandong Li, Yiwei Sun, Huaxiu Yao, Prasenjit Mitra, and Suhang Wang. Transfer-
ring robustness for graph neural network against poisoning attacks. In Proceedings of the 13th
International Conference on Web Search and Data Mining, pp. 600-608, 2020.
Petar VeliCkovic, GUillem CUcUrUlL Arantxa Casanova, Adriana Romero, Pietro Lid, and Yoshua
Bengio. Graph attention networks. In International Conference on Learning Representations,
2018.
SaUrabh Verma and Zhi-Li Zhang. Stability and generalization of graph convolUtional neUral networks.
In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &
Data Mining, pp. 1539-1548, 2019.
CedriC Villani. Topics in optimal transportation. Number 58. American Mathematical Soc., 2003.
Edward Wagstaff, Fabian FUchs, Martin Engelcke, Ingmar Posner, and Michael A Osborne. On the
limitations of representing fUnctions on sets. In International Conference on Machine Learning,
pp. 6487-6494, 2019.
Zonghan WU, ShirUi Pan, Fengwen Chen, GUodong Long, Chengqi Zhang, and S YU Philip. A
comprehensive sUrvey on graph neUral networks. IEEE transactions on neural networks and
learning systems, 2020.
Han XU, Yao Ma, Hao-Chen LiU, Debayan Deb, HUi LiU, Ji-Liang Tang, and Anil K Jain. Adversarial
attacks and defenses in images, graphs and text: A review. International Journal of Automation
and Computing, 17(2):151-178, 2020.
KeyUlU XU, WeihUa HU, JUre Leskovec, and Stefanie Jegelka. How powerfUl are graph neUral
networks? In International Conference on Learning Representations, 2019.
JiaxUan YoU, Rex Ying, and JUre Leskovec. Position-aware graph neUral networks. In International
Conference on Machine Learning, pp. 7134-7143. PMLR, 2019.
Manzil Zaheer, Satwik KottUr, Siamak Ravanbakhsh, Barnabas Poczos, RUss R SalakhUtdinov,
and Alexander J Smola. Deep sets. In Advances in neural information processing systems, pp.
3391-3401, 2017.
Jie ZhoU, GanqU CUi, Shengding HU, Zhengyan Zhang, Cheng Yang, ZhiyUan LiU, Lifeng Wang,
Changcheng Li, and Maosong SUn. Graph neUral networks: A review of methods and applications.
AI Open, 1:57-81, 2020.
DingyUan ZhU, Ziwei Zhang, Peng CUi, and WenwU ZhU. RobUst graph convolUtional networks
against adversarial attacks. In Proceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, pp. 1399-1407, 2019.
Daniel Zugner and Stephan Gunnemann. Certifiable robustness and robust training for graph
convolUtional networks. In Proceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, pp. 246-256, 2019.
Daniel Zugner and Stephan Gunnemann. Certifiable robustness of graph convolutional networks
under structure perturbations. In Proceedings of the 26th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining, pp. 1656-1665, 2020.
Daniel Zugner and Stephan Gunnemann. Adversarial attacks on graph neural networks via meta
learning. In International Conference on Learning Representations, 2019.
11
Under review as a conference paper at ICLR 2022
A Optimal Transportation Duality
Let Gn ⊆ Rn×n×d denote the set of all graphs with initial attributes which is equipped with the
λ-distance. Let P(Gn) denote the set of all probability measures on the set of graphs with initial
attributes that are absolutely continuous with respect to the Lebesgue measure. The Wasserstein
distance between two probability measures Pi, P2 ∈ P(Gn) is defined as
W1(P1,P2):=	inf	E(G1,G2)〜p[dist(Gi, G2; λ)],	(21)
P∈M(P1,P2)
where M(Pi, P2) denotes the set of all couplings of Pi, P2. Note that (P(Gn), Wi) is a metric space.
From the duality principle, we have the following alternative definition for the Wasserstein distance,
Wi(Pi,P2)
涔J""©]-EG~p2[f(G)]},
(22)
where
F •— n fl ∙ G* →R ∙ S UD If(G)- f (G0)| < 10
FI L U1 : Gn → R : Sup dist(G, G0; λ) ≤ 1;.
(23)
For more on optimal transport, see (Villani, 2003).
B	Proof of Theorem 1
Since the proof of the theorem is long, let us decompose it into a few subsections.
B.1 A More General Result
Let us restate the main theorem (in a more general case) here.
Theorem 2. Under the conditions of Theorem 1, except the lower bound on average gradients, a
graph classifier f : Gn 一 {±1} can be approximated by the class (With the error probability ofat
most δ), only if
(disc(f )+8.68 (1 + 2nδCpoly (1 + 3 2 k poly ))4(2Bμ + λBρ∆maX))	(24)
X LmaX(I + ɪ (I +	2kLψ Lh(Bμ	+	σn	+	BP	+ σe) +	2kLψ(1 +	σe)))	(25)
≥  ----------017----------ɪ max n inf ∖∕var(hPert©),	(26)
(1 + 2Cpoly (1 + 3 2 kpoly))	lG∈Gn
E[Jvar(hpe"©)] - 8.68δ(1 + 2C⅛y(1 + 32kpoly)) SUp JVar(hPert(G))},
n	(27)
Remark 5. This result is more general that that of Theorem 1. In particular, the RHS involves the
average variance, if δ is small enough, and this means that we are outperforming Theorem 1, which
can be concluded from the worst-case infimum variance (details are below).
We conclude the main result with the following proposition.
Proposition 4. We have that
inf
G∈Gn
《var( hPert(G)) ≥ Lminσn√n(1 + 2 ∖ Δmin ).
(28)
Proof. For any fixed G ∈ G/, hpert(G) is a deterministic function of a number of Gaussian random
variables: Xv = μv + nv and e(u,v)= p(u,v)+ n(u,v)such that nv 〜N(0, σnId) and n(u,v)〜
12
Under review as a conference paper at ICLR 2022
N(0, σf Id) for V ∈ [n] and (u, V) ∈ Eg. From the theory of Hermit polynomials and Gaussian
Hilbert spaces (O’Donnell, 2014), we know that
var(hpert(G)) ≥ σn X ∣∣E[∂vhwt(G)]k2 + σ∣ X 1旧伙”,。人骑©]||2.	(29)
v∈[n]	(u,v)∈EG
The RHS can be interpreted as the square norm of the average gradient around perturbations. In-
tuitively, if perturbation is small, this is essentially the gradient without perturbations. From the
assumption, we simply get
var(hpert(d)) ≥ nσnLmin + |&足Lmin ≥ n%皿(蝙 + ^θmin).	(30)
We are done.	口
B.2 Approximating the Graph Classifier
In this part, we approximate the given graph classifier f with an auxiliary classifier f which aggress
with f with high probability, we then exploit properties of the new classifier to proceed the proof.
Note that if the probability of error in Equation 4 is bounded for any graph in G/, instead of random
graphs, then we can skip this part since the approximation is not required and all graphs satisfy the
conditions below.
Consider is a graph classifier f which can be approximated by GNNs, meaning that there exist θ, γ
such that
Pf(G) 6= 1{hpert(G) ≥γ} ≤δ.	(31)
Now consider the following set:
A= nɑ ∈ Gn : P(f(G) = 1{hpert(G) ≥ γ}∣G = G) ≤ W},	(32)
where C1 is an arbitrary fixed constant to be determined later. For simplicity, let us define
PG(f(G) = 1{hpert(G) ≥ γ}) ：= P(f(G) = 1{hpert(G) ≥ γ}∣G = G).	(33)
Note that we have
Pf(G) = 1{hpert(G) ≥ γ}) =	Pf(G)	= 1{hpert(G) ≥ y}a)p(A)	(34)
+	P(f(G)	= 1{hpert(G) ≥ γ}∣Ac)P(Ac)	(35)
≥	Pf(G)	= 1{hpert(G) ≥ γ}∣Ac)(1 -	P(A))	(36)
≥	Jnf PG	(f (G) = 1{hpert(G) ≥ Y}) (1	— P(A))	(37)
G∈Ac
≥ ɪ(l - P(A)).	(38)
C1
Thus, P(A) ≥ 1 - C1δ.
Now, consider the function f : A ⊆ Gn →{±1} which is the restriction of f to the set A. We write
disc(∕) = Wι(η+ ,ηf)	(39)
(a)
≤ Wι(η+ ,η+) + Wι(η+,η-) + Wι(ηf,ηf)	(40)
=disc(f) + Wι(η+ ,η+) + Wi (η-,η-),	(41)
where (a) holds by the triangle inequality. Recall that Gn is the set of graphs with initial attributes.
To bound the other terms, consider the following coupling between the measures ηf, ηf for K ∈ {±}.
Let ηκ denote the following probability measure on Gn X Gn: first we choose an element Gi with
respect to the probability measure ηfκ , and then if it belongs to A then the second element G2 is
13
Under review as a conference paper at ICLR 2022
the same as G1. Otherwise, we draw a random element of A for G2, with respect to the probability
measure ηκ^. This is clearly a coupling between η},ηf, and so We conclude
Wι(ηf,ηf) ≤ EnK[dist(Gι, G2;λ)]	(42)
≤ (2Bμn + λBρ∆maχn)(1 - P(A))	(43)
≤ C1δn(2Bμ + λBρ∆maX),	(44)
since the trivial bound dist(Gι, G2; λ) ≤ 2B*n + λBρ∆maχn holds for all graphs.
Combining the above result with (41) shows that
disc(f) ≤ disc(f) + 2Cιδn(2Bμ + λBρ∆maχ).	(45)
B.3 Duality Principle and Approximating GNNs
In this part, we use the optimal transportation duality, and then we approximate the GNN representa-
tion with a polynomial, along with we using mean-value theorem to bound the approximation error.
This approximation allows us to compute useful bounds for the given graph representation.
■‰ τ 1	∙ 1	∙ . 1	/` /-	1	. .1 . ττn Γ 7	/ X ∖ 1 彳r ±	EI ♦	/`	. ∙
Now let US consider associated measures of f and note that E[hpert(G)] : Gn → R is a function on
the space (Gn, dist(.,.; λ)), thus
where
disc(f) = Wι(η+,η-)
=sup {Eg〜n+ [fι(G)] - EG〜n-[fι(G)]}
f1∈F1 If	fJ
≥ ^hy (Eg~〃+ [E[hpert(G)]] - E°~n- [E[hpert(G)]]),
L (h) := sup
G,G0∈Gn
G6'G0
∣E[hpert(G)] - E[hpert(G0)]]
dist(G, G0; λ)
Note that the function f is supported on A, and thus we have
PG(f (G) = 1{hpert(G) ≥ γ}) ≤ ɪ,
(46)
(47)
(48)
(49)
(50)
for all G ∈ A (see (33) for the definition). Fix G ∈ A, and let us approximate the above probability
from below. First let us consider the case that f(G) = -1. Using the definition, we have
PG(hpert(d) ≥ Y) ≤ K.
(51)
1 ʌ . 7	/ X ∖ ∙	1	∙ ∙ . ∙ ∕'	. ∙	∕'	∙ ∙ . -I y -1	♦	1	∙ Λ -I	T	. ∙ -I
But hpert(G) is a deterministic function of some jointly Gaussian random variables. In particular,
let us recall that hpert(G) is the graph representation for G, when we have perturbed initial attributes
Xv 〜N(μv, σnId) and e(u,v)〜N(p(u,v), σeId) where V ∈ [n] and (u, V) ∈ Eg. Now we need the
following lemma for the rest of analysis.
Lemma 1 (Lesley & Rotar (2003)). Let X be a random variable with zero mean, unit variance, and
E[X4] = ζ ≥ 1. Then, we have
0.46	1.4	0.02
P(X ≥t) ≥ - -√ζt + 尹 t,
(52)
for any t ≥ 0.
The above lemma can be proved by carefully finding an upper bound for the indicator function
1{. ≤ t} in terms of a degree four polynomial, and do some calculation to optimize the bound.
Consequently, under the conditions of the lemma,
0 46	1 4
∀t ≥ 0： P(X ≥ t) ≥ -Z- -√ζ
t =⇒ P(X ≥
(53)
14
Under review as a conference paper at ICLR 2022
Let XG := hpert(G)-E [hpert(G)]. Clearly, XG is a random variable with zero mean and unit variance, and
ʌ/ var(hpe1(G))
that randomness comes merely from perturbations, since G is fixed. Thus, by the above lemma, we
conclude that
一 ，一 ，〜、 . PG(hpert(G) ≥ Y)二	= PG(XG ≥ γ-E[hpert(G)] )≤ ɪ.	(54) Var(hpert(GG))	C1
Now using (53), we conclude that C〉E[X4] C1 ≥ -oɪ 二	Y - E[hpert(G)]	0.17 ⇒	I	 ≥	1		 (55) JVar(hpert(G))	yE[X4]
Now we need to upper bound the fourth moment of Xg . To do that, we use the following result on
Gaussian hypercontactivity.
Lemma 2 (Boucheron et al. (2013)). Let f : Rn → R be a multivariate polynomial of degree at
most k, and (X1,X2,..., Xn)〜N(0, I) be a Sequence of i.i.d. Gaussian random variables. Then,
we have
(E[|f(X1,X2,...,Xn)∣q])1/q ≤ (q- 1)k/2(E[|f(Xi,X2,...,Xn)∣2])1/2.	(56)
Note that by assumption there is a polynomial hpoly(G) of degree at most kpoly such that
|hpoly© - h(G) | ≤ Cpoly := Cpoly ʌ/Var(hpert(G)),	(57)
holds for any initial attributes, even if we consider the perturbed case hpɛrt(ɑ). The polynomial,
however, may depend on G. Thus, we obtain that
In particular, we can apply the above lemma to XG since it is a real-valued random variable, which is
a deterministic function of Gaussian random variables (i.e., perturbations). Thus, setting q = 4 in the
lemma results in
(e[x4])1/4
hpert(d) - E[hpert(d)]
JVar(hpert(G))
1/4
1
Var(hpert(GG))
(E[(hpert (G) — E%ert(G)])4])1/4
ɪ	/ _=/，-	，〜、	-	，〜、、	，-	，〜、	__--	，〜、r、
-/	〜	(E[((hpert(G) - hpoly(G)) + (hpoly(G) - E[hpoly(G)D
Var(hpert(GG))
4	1/4
+ (E[hpoly(GG)] - E[hpert(GG)])) ]
(a)
≤
1
JVar(hpert(G))
(2CPoy + (E[(hp0ly(G) - E[hpoly(G)])4])1/4)
<	/	1	〜(2。嬴 + 31 kpoly (E[(hpoly(G)- E[hpoly(G)])2])1Q
Var(hpert(GG))
1
JVar(hpert(G))
(2Cp°ly + 32kpoly(E[((hpoly(G)- hpert(G))
+ (hpert(GG) - E[hpert(GG)])) + (E[hpert(GG)] - E[hpoly(GG)])2)])1/2
(58)
(59)
(60)
(61)
(62)
(63)
(64)
(65)
(c)	1	1
≤	/	〜(2Cp°ly + 31 kpoly(2Cp°ly + (E[(hpert(G) - E[hpert(G)])
Var(hpert(GG))
2 1/2
(66)
15
Under review as a conference paper at ICLR 2022
2C0
=1 +	poly =(1 + 31 kpoly)	(67)
Jvar(hpert(G)) '
=1 + 2Cpoly(1 + 31 kpoly),	(68)
where (a) and (c) hold by Minkowski inequality, and (b) hold by Lemma 2. To proceed, we combine
the above lemma with (55) and obtain the optimal constant C1, thus if
Ci = 4.34(1 + 2Cpoly(1 + 31 kpoly ))4,	(69)
then
Y ≥ E[hpert(G)] + 0.17-_qvar(Mert(G))	,	(70)
(1 + 2Cpoly(1 + 3 2 kpoly))
holds for any G ∈ A such that f(G) = -1. Thus, taking the expectation from both sides with respect
to G 〜η- results in
En- [JvaKhpert (G))]
Y ≥ Egm- [E[hpert(G)]] + 0.17--f----------------------E,	(71)
f	(1 + 2Cpoiy(1 + 31 kpoly))
while again we emphasize that hpert(G) is a random variable which depends on on perturbations, given
any graph G ∈ A.
In a similar way, for any G ∈ A such that f(G) = 1 it can be shown that
En- [qvar(hpert(G))]
Y ≤ E°~n+ [E[⅛ert(G)]] - 0.177~~----------------------72 ,	(72)
f	(1 + 2Cpoly(1 + 3 1 kpoly))
with the same C1 defined in (69). Combining (71) and (72) shows that
En+ [qvar(hpert(G))] + En- [qvar(hpert(G))]
EG〜n+ [E[hpert(G)]] - Eg5-阳也^©]] ≥ 0」7	f /---------------------fʌ-2---------------∙
f	f	(1 + 2Cpoly(1 + 3 1 kpoly))
(73)
Now using the duality principle (see 48) we conclude that
八	En+ [qvar(hpert(G))] + En- [qvar(hpert(G))]
disc(f)L(h) ≥ 0.17 —f---------------------------f------G----------.	(74)
(1 + 2CPoly(1 + 3 2 kpoly))
Note that
En+ [Jvar(hpert(d))] = En+ [ Jvar(hpert(G)) A]P(A) + En+ [ Jvar(hpert(d))∣Ac]P(Ac)	(75)
≤ En+ [Jvar(hpert(G)) A] + 旧η彳[ʌ/var(hpert(ɑ))|Ac]P(Ac)	(76)
≤ En+ [Jvar(hpert(G))]	(77)
+ 4.34δ(1 + 2CPoly(I + 32kpoly )) En+ [qvar(hpert(G)) |Ac]	(78)
≤ En+ [√var(hpert(G))]	(79)
16
Under review as a conference paper at ICLR 2022
+ 4∙34δ(1 + 2cpoiy(1 + 3 2 kpoly )ɔ	SUP /var(hPert(G))
'	G G∈Gn Y
Similarly, one can obtain
En- [jvar(hpert(d))] ≤ En- [jvar(hpert(d))]
+4.34δ(l + 2Cpoiy(1 + 32kpoly)) SuP q/var(hpert(G))
'	G G∈Gn V
(80)
(81)
(82)
(83)
(84)
Hence9,
E[Jvar(hpert(G))] ≤ 旧η彳[ʌ/var(hpert(ɑ))] + Eg
ηf-
[Jvar(hpert(G))]
≤ En+ [Jvar(hpert(d))] + En- [Jvar(hpert(d))]
+ 8.68δ(1 + 2Cpoiy(1 + 32kpoly)) SuP /∕var(hpert(G))
'	G G∈Gn V
Now combining with 74 results in
disc(∕)L(h) ≥  ------------017-----------F max { inf ʌ/var(hpert(ɑ)),
(l + 2Cpoly(1 + 3 2 kpoly))	G∈Gn
(85)
(86)
(87)
(88)
4
E[ʌ/ var(hpert(G))] — 8.68δ(l + 2Cpoiy (1 + 3 2 kpoly
) sup JVar(hpert(G))}.
G G∈Gn v	J
n
(89)
B.4 Analysis of the Lipschitz Constant
Now let us analyze L (h). By the definition
L(h) = SuP
G,G0∈Gn
G6'G0
∣E[hpert(G)] - E[hpert(G0)]]
dist(G, G0; λ)
(≤)	SU	En [∣hpert(G)- hpert(G0)∣]
≤ g,Gu⅛	dist(G, G0; λ)
G6'G0
(90)
(91)
where in (a) we couple the two perturbations into one according to the transportation map π ∈ Sn
that achieves dist(G, G0; λ). (see 3). Fix G, G0 ∈ Gn and the coupled perturbations, and without
loss of generality, assume that π = id. Note that the initial attributes considered for hpert(G) are
Xv = μv + nv and e(u,v)= p(u,v)+ n(u,v)for V ∈ [n] and (u,v) ∈ Eg, and similarly for
hpert(G0) they are xv = μv + nv and e(u,v)= ρ(u,v) + n(u,v)for V ∈ [n] and (u,v) ∈ Eg，. Let
us define a few auxiliary graphs as follows. Define G1 the same as G, except with new initial node
attributes Xv = μv + nv for V ∈ [n]. Also, define G2 the same as Gι, except with new edge
attributes e2,(u,v) = ρ(u,v) + n(u,v) for all (u, V) ∈ EG ∩ EG0, and e2,(u,v) = ρ0(u,v) + n(u,v) for all
(u, V) ∈ EG0 \ EG , and zero elsewhere.
One can write
|hpert(G) - hpert (G0)| ≤ |hpert(G) - h(G1)| + |h(G1) - h(G2)| + |h(G2) - hpert(G0)|.	(92)
For the first term by the mean-value theorem,
IhPert(G)- h(G1) | = J X hdv hpert(G)(ξv), (μv + nv ) - (μv + nv )i |	(93)
v∈[n]
9This expectation is with respect to the probability measure P which is the law of graph generation.
17
Under review as a conference paper at ICLR 2022
(b)
≤ E k∂vhpert(G)(ξv)k2kμv-μVk2
v∈[n]
(94)
≤ LmaX	kμv - μVk2	(95)
v∈[n]
≤ LmaX dist(G, G0; λ),	(96)
where (a) holds for some ξ ∈ [μv + nv ,μV + nv], meaning that it belongs to the line segment between
two endpoints, and also (b) holds by the CaUchy-SchWarz inequality.
For the second term, consider G1, and for instance, assume that G2 differs from G1 by only adding
one edge. Observe that adding an edge such as (u, v) to G1, without changing node attributes, is
equivalent to adding Ψ'(hUe-1), e(u,v)) to node U in 'th iteration (i.e., to hUe-1)) and the same for v.
Note that each hUe-1) in above is computed for Gι, so the perturbations are also considered there.
Thus, using the mean-value theorem,
∣h(Gι)- h(G2)∣ =) J X hΨ'(hV'T), e(u,v)),d(u,'—i)h(Gi)(gu,')i	(97)
'∈[k]
+ X hψ'(hU'-1), e(u,v)),d(v,'-1)h(G1)(ξv,')i∣	(98)
'∈[k]
≤) X kΨ'(hF-1),e(u,v))k2k∂(u,'-i)h(G1)(ξu,')k2	(99)
'∈[k]
+ X llψ'(hV'-1), e(u,v))k2kd(v,'-1)h(GI)(品,'州2	(IOO)
'∈[k]
≤ LmaX X IMS 厂), e(u,v))k2 + LmaX X llψ'(hV'-1), e(u,v))k2	(IOI)
'∈[k]	'∈[k]
≤ LmaxLΨ ɪ2(khf 1)k2 + khv' I) k2)+ 2kLmaxLΨ ke(u,v) k2
'∈[k]
≤ 2kLmaxLψ( n X LhkXvk2 + jE^"j^ X Lhke(u,v) k2 + Bh)
+ 2kLmaXLΨ le(u,v) l2
≤ 2kLmaχLψ(— ^X (Lhkμv k2 + Lhknv k2 + nBh)
n
v∈[n]
+ ∣e-T	X Lh(IlP(U,v)k2 + ∣∣n(u,v)k2 ))
G (u,v)∈EG
+ 2kLmaXLΨ(kρ(u,v) k2 + kn(u,v)k2),
(1O2)
(1O3)
(1O4)
(1O5)
(1O6)
(1O7)
where (a) holds for some ξv,', ξu,' for ' ∈ [k], and (b) follows from the Cauchy-Schwarz inequality.
Thus, if we take expectation from both sides with respect to the perturbation, we have the bound
En Ih(GI ) - h(G2)| ≤ 2kLmaχLψ(- X (Lhkμv k2 + Lhσn)	(108)
n
'∈[k]
+ jE^∣	X (LhkP(U,v)k2 + Lhσe) + nBh)	(109)
+ 2kLmaXLΨ (kρ(u,v) k2 + σe)	(11O)
≤ 2kLmaXLψ(LhBμ + LhBP + Lhσn + Lhσe + Bh)	(111)
+ 2kLmaχLψ(dist(Gι, G2; λ)∕λ + σe).	(112)
Note that in this case, dist(G1, G2; λ) ≥ λkP(u,v) k2 ≥ λ. Similarly, if we consider more than one
edge difference between G1, G2, the same result holds as
Eπ ∣h(G1) - h(G2)∣
(113)
18
Under review as a conference paper at ICLR 2022
≤ (2kLmaxLΨ (LhBμ + Lhσn + LhBP + Lhσe + Bh) + 2kLmaxLΨ (I + σe)^ -^^^ɔ,^^~~
(114)
Finally and similar to the previous arguments, we write
|h(G2) - hpert(G0)| ≤	k∂e(u,v)h(G)(ξv)k2k(ρ(u,v) + n(u,v)) - (ρ0(u,v) + n(u,v))k2
(u,v)∈EG2
≤ Lmax	kρ(u,v) - ρ(u,v) k2
(u,v)∈EG2
dist(G, G0; λ)
≤ LmaX	ʌ .
(115)
(116)
(117)
Combining (96), (114) and (117) shows that
L(h) ≤
sup
G,G0∈Gn
G6'G0
En [|hpert(G)- hpert(GO) |]
dist(G, G0; λ)
(118)
≤ LmaX(I + γ(1 + 2kLψ (Lh Bμ + Lhσn + LhBP + Lhσ e + Bh) + 2kLΨ (1 + σE))) ∙
λ	(119)
B.5 Final Step of the Proof
Finally, we combine the above result and use (89) to achieve
1
disc(f) ×LmaX(I + λ(I + 2kLψ(LhBμ + Lhσn + LhBP + Lhσe + Bh) + 2kLψ(1 + σe)))
≥ ------------017----------F max n inf ∖∕var(hpert(G)),
(1 + 2Cpoiy(1 + 3 2 kpoiy))	IG∈Gnv
(120)
(121)
E[Jvar(hpert(G))] - 8.68δ(1 + 2Cp°iy(1 + 32kpoly)) SUp JVar(hpert(G))}.
n	(122)
Now according to (45) we obtain
(disc(f )+8.68(1 + 2Cpoiy(1 + 3 2 kpoly ))4δn(2Bμ + λBρ∆maχ))	(123)
× LmaX(I + λ (1 + 2kLψ (LhB μ + Lhσn + LhBP + Lhσ e + Bh) + 2kLψ(1 + σe)))
(124)
≥ -------------017---------F max n inf ʌ/var( hpert (G)),
(1 + 2Cpoiy(1 + 3 2 kpoiy))	1G∈Gnv
(125)
E[Jvar(hpert(G))] - 8.68δ(1 + 2Cp°y(1 + 32kpoly)) sup JVar(hwt(G))},
which completes the proof.
C Proof of Proposition 2
To prove Proposition 2, we introduce a natural class of simple graphs Gn that simply allows to couple
graphs with different labels.
19
Under review as a conference paper at ICLR 2022
•	Number of edges. In this case, simply consider the set of graphs Gn = {G0, G1, . . . , Gm}
where m = n∆max constructed as follows. First let Go be the empty graph and for each Gi,
add an arbitrary edge to Gi-1 to construct it. For the number of edges function, denoted by
f : Gn → [0, n∆max ], each interval in the definition of fp has length n∆max. To couple two
intervals, wejust shift the index: i → i + n3max ± 1 (since its an integer). This means that
2p
the discrepancy can be upper bounded by n∆max + O(1). The next part also follows from
Eadditive = n⅜max which is the length of interval.
2p
•	Number of triangles, number of subgraphs H. Let us just prove the desired result for
the latter. For any graph H, construct the set Gn = {Go, Gι,..., Gm} where m = nn∙
constructed as follows. Start with empty graph G0, and add independent copies of H (i.e.,
without overlapping nodes) sequentially to find Gi, i ∈ [m]. Now, for the subgraph count
function f : Gn → [0, ɪ], we have the length of interval Eadditive = ~n~. Similar to the
nH	pnH
previous part, to achieve a coupling, use index shift, and to increase the function by Pn^ we
need to add nmH ± 1 edges, which completes the proof.
•	Diameter. Consider path graphs Pi for i ∈ {0, 1, . . . , n - 1} as Gn, and similar to the
number of edges, construct the coupling. The proof is the same.
•	Max-cut, min-cut. The two case are dual of each other if we compute the completion of
the graphs (discrepancy bounds are invariant with respect to this operation). Thus, we only
prove the max-cut case, and construct bipartite graph on n ± 1 nodes (since the number is
integer), and add edges to greedily construct Go, Gι,..., Gm for m = ^maX ± 1. Then,
since adding edges will directly change the function value, we conclude the result similar to
the number of edges case.
•	Clique number, independence number. By duality we only prove the result for the clique
number. Start from Go as empty set, and greedily enlarge a clique to achieve Gm which has
a clique of size ∆maχ. Then, Eadditive = ^max, and to add this number we need to add at
most ∆maχ X ∆mpax new edges. The proof is thus complete.
•	Number of connected components. This case essentially the same as the analysis for the
diameter of graphs.
20