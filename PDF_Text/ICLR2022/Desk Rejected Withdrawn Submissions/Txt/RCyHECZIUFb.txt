Under review as a conference paper at ICLR 2022
Explaining Knowledge Graph Embedding via
Latent Rule Learning
Anonymous authors
Paper under double-blind review
Ab stract
Knowledge Graph Embeddings (KGEs) embed entities and relations into con-
tinuous vector space following certain assumptions, and are powerful tools for
representation learning of knowledge graphs. However, following vector space
assumptions makes KGE a one step reasoner that directly predicts final results
without reasonable multi-hop reasoning steps. Thus KGEs are black-box mod-
els and explaining predictions made by KGEs remains unsolved. In this paper,
we propose KGExplainer, the first general approach of providing explanations for
predictions from KGE models. KGExplainer is a multi-hop reasoner learning la-
tent rules for link prediction and is encouraged to behave similarly to KGEs during
prediction through knowledge distillation. For explanation, KGExplainer outputs
a ranked list of rules for each relation. Experiments on benchmark datasets with
two target KGEs show that our approach is faithfulness to replicate KGEs be-
haviors for link prediction and is good at outputting quality rules for effective
explanations.
1	Introduction
Knowledge Graphs (KGs) are natural models for background knowledge in many real-world appli-
cations, including recommender system(Wong et al., 2021), question answering(Huang et al., 2019),
and natural language processing(Annervaz et al., 2018). Thus many large scale KGs have been built,
while they are still challenging to work with because of incompleteness. To address this problem,
Knowledge Graph Embeddings (KGEs) have emerged as state-of-the-art for link prediction and rep-
resentation learning on knowledge graphs. With the capability of encoding semantics of entities and
relations into continuous vector space as embeddings, KGEs transfer link prediction into simple but
efficient calculations over embeddings in vector space.
Despite their strengths, KGEs have been argued for lack of transparency for a long time as no
human-intelligible explanations could be easily provided for their one-step predictions which limits
trustworthiness from human-being, the maintainer as well as the final consumers of KGs (Nand-
wani et al., 2020). Thus many more transparent and explainable methods have been applied and
preferred including reinforcement learning (Xiong et al., 2017; Das et al., 2018; Wan et al., 2020)
and differentiable rule learning (Yang et al., 2017; Sadeghian et al., 2019; Wang et al., 2020). Their
explainability is enabled in the explicit multi-hop reasoning steps of the models. Since there is
no method for explaining KGEs, this inspires us to explain KGEs via transforming KGEs into a
multi-hop reasoning model.
In this paper, we propose KGExplainer, an approach for explaining predictions made by KGEs.
We follow the idea to approximate models with a surrogate model which is probed for explana-
tions (Lakkaraju et al., 2017; Schmitz et al., 1999). KGExplainer is set to a multi-hop reason-
ing model learning latent rules and trained via making the multi-hop reasoning results approach to
KGEs’ results. Thus during training, we regard the scores from target KGEs as soft labels for KG-
Explainer and labels from data as hard labels following the setting of knowledge distillation(Gou
et al., 2021). In KGExplainer, we represent latent rules for each relation as a rule embedding, based
on which a rule decoder is learnt to sequentially decode compositive body relation embeddings from
rule embeddings. The body relation embeddings will be orderly used for multi-step reasoning fol-
lowing translation function defined in target KGEs. Explanations are provided by a set of ranked
symbolic rules decoded from body relation embeddings based on general vector space similarity as-
1
Under review as a conference paper at ICLR 2022
Figure 1: KGExplainer explains the target KGE via learning a multi-step surrogate model with
latent rules and providing paths from head entity to tail entity as explanations.
sumption. Given a query, KGExplainer provides explanations as paths from query entity to answer
entity, chosen from the existing paths according to the ranked rules list from KGExplainer, as shown
in Figure 1. This approach is suitable for KGEs following a two-functional paradigm with a trans-
lation function f to translate head entity embedding to tail entity embedding according to relation
embedding, and a scoring function g to calculate the similarity between two entity embeddings.
On two commonly used benchmark datasets for link prediction, we firstly evaluate the faithfulness
of KGExplainer to approximate target KGEs and then present the evaluation over explanations to
show it’s capability of providing explanations. Experiments show that KGExplainer successfully
replicate KGEs with almost zero score difference averaged on samples, and generate higher quality
rules than two statistical baseline and a differentiable rule learning method, and provide consistent
and concise explanations to help people understand the predictions and judge their correctness.
2	Related Work
Knowledge Graph Embeddings embed entities and relations into low-dimensional vector space,
called embedding, enabling complex predictions through calculation with entity and relation em-
beddings. Various vector spaces are applied to KGEs, including Real space (Bordes et al., 2013),
ComplEx space (Trouillon et al., 2016), Hyperbolic space (Chami et al., 2020), Hypercomplex space
(Cao et al., 2021), etc.
The score function of triples Φ in KGEs we are interested in this paper is composed of two functions
represented as f(h, r, t) = g(f(h, r), t)(Bordes et al., 2013; Sun et al., 2019; Yang et al., 2015;
Trouillon et al., 2016). Lets represent entity and relation embeding space as E and P, and real num-
ber space as R. Given an head embedding h ∈ E and a relation embedding r ∈ R, transformation
function f : E × P 7→ E transforms h to predicted tail entity embedding t ∈ E that the entity and
relation correspond to h, r, t are possibly to composed a positive triple. Given two entity embed-
dings, g : E × E 7→ R scores them with a real number to indicate their similarity. The design of
f and g in KGEs usually follows specific vector space assumptions. For example, TransE(Bordes
et al., 2013) assumes that for a positive triple (h, r, t), the head entity could be linearly translated to
tail entity with the relation that h + r = t, thus ftranse (h, r) = h + r and the similarity between
entity embedding are evaluated by Euclidean distance that g(t0, t) = kt0 - tk.
Some KGEs do not strictly follow this two-functional paradigm, they either shrink two functions into
one score function that is unable to split(Dettmers et al., 2018) or first combine head and tail entity
embedding and then calculate the similarity in relation space(Abboud et al., 2020) or calculate the
similarity with entity embeddings after transformed by relation(Wang et al., 2014; Lin et al., 2015b).
In this paper, we focus on explaining KGEs following the general two-functional paradigm described
above. Although there are methods providing explanations for completion results, some of them
made explanations towards Why the prediction is reasonable (NandWani et al., 2020; GUsmao et al.,
2018), or made a trade-offbetween performance and explainability(Stadelmaier & Pado, 2019), thus
faithfUl explainer toWards hoW KGE predicts is necessary.
Differentiable Rule learning is firstly proposed by Yang et al. (2017) to learn the confidence score
of a rule and its structure at the same in a differentiable framework. Since rules are human-friendly to
provide explanations for link prediction, and rule mining methods in a differentiable manner is more
easy to be integrated into other deep learning methods, differentiable rule learning methods(Yang
et al., 2017; Sadeghian et al., 2019; Wang et al., 2020) are widely been interested. They are build
based on operations defined in TensorLog(Cohen et al., 2020) and the key idea is to generate the
weights of relation for each reasoning step given a query, and rules could be decoded based on
2
Under review as a conference paper at ICLR 2022
accumulation of the weights in each step, which greatly motivate us for rule learning and decoding
in KGExplainer.
Explaining Black Box Models. Although explaining prediction of KGEs is not well-studied, build-
ing robust and practical methods to explain black-box model’s, especially neural works’, has de-
veloped into an own research area(Guidotti et al., 2019; Samek et al., 2021). To generate post hoc
explanations, there are four families of techniques. The first category of methods aims to learn a self-
explanatory surrogate model to replace the target model(Ribeiro et al., 2016; Guidotti et al., 2018;
Ribeiro et al., 2018). The second category of methods are build based on perturbation analysis where
the input is repeatedly updated to test the effect on the neural networks’ output, including occasion
analysis(Zintgraf et al., 2017), shapley value analysis(Lundberg & Lee, 2017) and other meaning-
ful perturbation(Fong & Vedaldi, 2017). The third category of methods explain by integrating the
gradient along some trajectory in input space connecting some root point to data point(Sundararajan
et al., 2017; Smilkov et al., 2017). The fourth category is Layerwise Relevance Propagation method
that makes explicit use of the layered structure of the neural networks and operates in an iterative
manner to produce the explanation(Montavon et al., 2019).
While existing explanation methods based on meaningful input features implicitly assume that those
input features are inseparable to the receiver such as human, they are hard to directly implied to rep-
resentation learning methods such as knowledge graph embedding, since the input of representation
learning methods, embeddings, is unexplainable regarding to each dimension of the representation.
In KGEs, the embedding of entities and relations are interpretable only when regarding them as a
whole and calculating the similarity to other entities and relations in the embedding space. Thus
in this paper, we take an alternative way to explain KGEs by expanding KGEs into an explainable
multi-hop reasoning method and explaining each step via interpretable similarities in vector space.
3	Preliminary
Knowledge Graph. Let K = {E, R, T} denotes a knowledge graph, where E, R and T are
set of entities, relations and triples. Triples are of the form (h, r, t) where h ∈ E and t ∈ E
are head entity and tail entity and r ∈ R is the relationship between h and t, an example is
(I phone, brandIs, Apple). Knowledge graphs are incomplete and without loss of generality, we
consider the problem of explaining a link prediction task in this paper.
Explanation for Link Prediction. A common explanation for link prediction query q = (h, r, ?)
with answer as a = t is a multi-hop path starting from h to t. For example, suppose the answer for
motherIs	hasH usband
(Bob, f atherI s, ?) is David, one of the explanation might be Bob -→ M arry ---------→
David which could be formally written as
(Bob, fatherIs, David) — (Bob, motherIs, Marry) ∧ (Marry, hasHusband, David) (1)
Such explanation could be regarded as a grounding of certain rules. For example, explanation (1) is
a grounding of following rule
(X, fatherIs, Y) — (X, motherIs, Z) ∧ (Z, hasHusband, Y)	(2)
Since rules are of the human-intelligible form, given a target KGE to be explained, this motivates
us to learn a set of rules as the underlying logic for prediction as long as based on which the link
prediction results are similar to the target KGE. Thus we frame the task of explaining KGE as
learning a model with triple scoring function Ψ including a set of latent rules performs the same as
target KGEs with triple score function Φ that
Ψ(q, a) ≈ Φ(q, a), where Ψ(q,a) =	p(a|G, q, z)p(z|q)	(3)
z∈Z
where Z is a set of latent rules, and p(z|q) is a prior over the set of rules conditioned on the query
q, and p(a|G, q, z) is the likelihood of the answer a conditioned on rule z, q and G.
Rules. As shown in Equation (2), rules are of the form head J body where head and body are
composed of atoms containing variables and relations. Our interests in this paper is the type of rule
closely related to paths from one entity to another entity proven to be useful for link predictionGuu
et al. (2015); Zhang et al. (2019); Yang et al. (2015); Niu et al. (2020), called chain-liked rules.
3
Under review as a conference paper at ICLR 2022
Step 1 Step 2	Step T
Figure 2: Overview of KGExplainer. f and g are the translation and similarity function from the tar-
get KGE. zr is the rule emebdding for relation r and r(zir) is the ithe compositive relation embedding
from rule decoder D.
In chain-liked rules, each variable appears twice, example refers to Equation (2). Rules from a
learning system usually are associated with a confidence score α given by the system to indicate how
confident this rule is. Thus chain-liked rules could be abbreviated as α : r(O) J [r⑴,r⑵,…,r(T)]
where T is the length of the rule. Given a set of rules Z, there are usually two steps to answer a
target query q = (h, r, ?), firstly to select rules zr with relation in head as r, called head relation,
meaning that zr could be used to infer new triples containing relation r, and secondly to walk along
the relation sequence in rule body starting from h and the finally reached entities are answers given
by z and they are scored proportionally according to confidence of z .
4 KGExplainer
In this section, we introduce KGExplainer applied to TransE(Bordes et al., 2013) and RotatE(Sun
et al., 2019), two typical KGEs.
Learning KGExplainer. Given a well-trained target KGE with score function for a triple as
Φω (h, r, t) = g(f (h, r), t) where f : E × P 7→ E and g : E × E 7→ R, in order to make KG-
Explainer with score function Ψθ replicate the link prediction performance of that target KGE, we
adopt the idea of knowledge distillation(Gou et al., 2021) and make the score from target KGE for
triples as soft labels of KGExplainer, and labels from data as hard labels. Thus the objective for
KGExplainer’s optimization is
mine X l∣Φω(a|q, G)- Ψθ(a|q, G)kι + L(q, a)	(4)
(q,a)∈G
where q = (h, r, ?), a = t, the first term is the soft label loss ofL1 norm of score difference between
KGExplainer and the target KGE, and the second term is the hard label loss, which is defined with
negative sampling in the following form for both TransE and RotatE:
k
L(q, a) = -logσ(γ - Ψ(h, r, t)) - X p(h0i, ri, t0i)logσ(Ψ(h0i, ri, t0i) - γ)	(5)
i=1
where (h0, r, t0 ) are the negative triples sampled following the self-adversarial strategy proposed in
(Sun et al., 2019). In Equation (4), score of KGExplainer is designed based on a set of latent rules
Z similar to Qu et al. (2021) that
ψθ(aIaq) = EpTS∣G,q,Z)PY (Zlq)	⑹
z∈Z
where pγ(Zlq) is the prior probability of applying rule Z for q andpτ(alG, q, Z) is the likelihood of
a for query q given G and latent rules Z . Recalling the reasoning process with rule Z as introduced
in Section 3, pγ (Zlq) is easy to get by checking the head relation and obtain the confidence score of
it. Thus we rewrite the Equation (6) as
ψθ(aIaq) = τz1r X azr × pτ(alG,q, zr)
lZrl zr∈Zr
(7)
4
Under review as a conference paper at ICLR 2022
in which Zr is a set of latent rules in KGExplainer for relation r and αzr is the confidence score
of zr . To normalize the length of rules to T , while enable the variance of length for rules within T
steps, a special self-loop relation transforming each entity to itself is added to relation set. Thus with
direction of relations considered (inverse relations are considered), there are |Zr| = (2 × |R| + 1)T
possible rules for r. Our target is to formulate the problem in the context of KGE, thus with a
well-trained KGE, Equation (7) could be approached to with
Ψθ(a∣G,q)〜X αzr × g(RNNf(h,Zr),t)	(8)
zr ∈Zr
where h and t are the embedding of h ∈ q and answer t. Function RNNf is a recurrent network
defined based on f from KGE that si , the hidden state at ith step, is
si =f(si-1,r(zir)),i∈ [1,T],s0 =h	(9)
where r(zir) is the emebdding of the ith body relation in rule z . For example, suppose KGE is
TransE(Bordes et al., 2013) and there is a rule zr = [rz(1r) , rz(2r) , rz(3r)], for a query q = (h, r, ?),
the predicted tail entity embedding given by zr with TransE(Bordes et al., 2013) and RotatE(Sun
et al., 2019) is
RNNftranse (h, Zr) = (( (h + 吗)+ ^) + ^)	(IO)
RNNfrotate(h, Zr) = (( (h 乳 ^))乳 ^)乳 ^)	(II)
where 0 indicates the rotation operation in complex vector space. Thus the target of KGExPlainer
is to learn the confidence score αzr and the structures of rules Zr = [r(1), r(2), ..., r(T)], while
this is difficult because of the confidence score is associated with particular rule, and enumerating
rules is an inherently discrete task(Yang et al., 2017). Thus similarly, we make the undiferentiable
rule-dependent summation in Equation (8) into a differentiable step-dependent summation that
|R|
Ψθ(a|G, q)〜g (RNNf (h,zr.), t), where rZi0) = X αj X r7-	(12)
r	j=1
where Zr0 = [r(z10), r(z20), ..., r(zT0 )] that r(zi0) is the embedding of expected relation embedding at the
r zr zr	zr	zr
ith step, and αirj is the confidence score of the jth relation rj as the ith body relation in Zr . Thus
currently, the goal of KGExplainer is to learn the confidence scores similarly to what did in Neu-
ralLP(Yang et al., 2017), while instead of keeping the summation operation which is expensive for
large knowledge graphs with huge amount of relations, we take a more efficient way to directly
decode the compositive relation embedding r(zi0), the results of summation operation. With r(zi0), αirj
could be calculated in a post hoc manner based on the basic similarity assumption in vector space.
Latent Rule Decoder D. In KGExplainer, for each relation, we learn a rule embedding to represent
the latent rule for it, denoted as z0r, which is assumed to encode the semantic of Zrs. The sequence
of compositive body relation is decoded by a latent rule decoder D, and such sequential output can
be effectively modeled by recurrent neural networks
r(i0) = b(i0) = LSTM (z0 ㊉ r(i0-1), b(i0-1)), b0, = 0	(13)
zr	zr	r zr	zr	zr
where the ㊉ means concatenation of two vectors. Finally, the output is a sequence of compositive
(1) (2)	(T)
relation embeddings [rz0 , rz0 , ..., rz0 ] for body of Zr0 to be applied to Equation (12). The algorithm
zr	zr	zr
of learning KGExplainer is shown in Algorithm 1.
Symbolic Rule Decoding and Explanation. Decoding in a post hoc manner, getting the confidence
score αirj in Equation (12) is the key target. KGEs, as representation learning methods for KGs,
could discover entity and relation similarities automatically, thus the decoding is based on similarity
between relation embeddings. Suppose the similarity is calculated between r(zi0) and relation em-
zr
bedding matrix R from the KGE, to make αirj consistent to the semantic of compositive relation
(i)
embeddings rz0 , there is a basic assumption that
zr
|R|	|R|
Xαirjf(h,Rj)=f(h,XαirjRj))	(14)
j=1	j=1
5
Under review as a conference paper at ICLR 2022
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
Algorithm 1: Learning KGExplainer.
Input: Training set S = {(h, r, t)}, a well trained KGE with relation embeddings R, entity
embeddings E, translation and similarity function f and g, max step M, rule length T
// Learning KGExplainer;
Randomly initialize rule embeddings Z and parameters in LSTM;
m J 0 ;
for m < M do
Sbatch J sample(S, b) // sample a minibatch of size b;
Z J D(Z) //decode body relation embeddings according to Equation (13);
for (h, r, t) ∈ Sbatch do
b = h // initialize the answer as head entity embedding;
t=0;
while t < T do
I b J f(b, Zrt)) // the tth step reasoning;
end
skgexplainer(h, r, t) J g(b, t) // get the score of KGExplainer;
skge (h, r, t) J g(f (h, r), t) // get the score from target KGE;
end
Update parameters w.r.t. P(h,r,t)∈Sbatch ||skge(h, r,t) - skgexplainer(h, r, t)|| + L(h, r,t)
end
which means given a head entity embedding h, the weighted sum of |R| predictions following all
relation embeddings in R should be equal to the the prediction calculated with h and the weighted
sum of all relations in R. This assumption ensures that r Zr)〜PjRI αirj Rj which is important for
regarding r(zir) as a compositive relation embedding. While this assumption is challenging to satisfy
because the smoothness assumption is not always hold for translation function f that r ≈ r0 do not
generally imply f(h, r) ≈ f(h, r0). Thus we propose to separate f into two functions, that
|R|	|R|
f(h, r) = f1(h,f2(r)), where Xαijf1(h,f2(Rj)) = f1(h, Xαijf2(Rj)))	(15)
j=1	j=1
where f1 is the function that satisfy the assumption in Equation (14), and f2 is a function to transform
relation emebddings. The separation of f1 and f2 for different KGEs depend on their assumptions.
For TransE, it is simple that f1 (h, r0) = h + r0 and f2 (r) = r, and for RotatE, f1 (h, r0) = h ◦ r0
f2 (r) = cos(r) + sin(r)i where ◦ denotes the Hadamard (element-wise) product. We provide the
proof in Appendix.
As introduced before, there (|R| × 2 + 1)T possible rules with different rule body for inferring
relation r, thus inverse relation emebddings r-1 and self-loop relation embedings r。should be
added into relation embedding matrix for KGEs based on their assumptions. For both TransE and
RotatE, r-1 = -r, and r。= 0. We provide the proof in Appendix.
Given latent rule embedding z0r for relation r and its decoded body sequence [r(z10), r(z20), ..., r(zT0 )], the
zr	zr	zr
confidence score is calculated via dot product ar = f2(rZ") ∙ f2(Rj) And finally, for a rule Zr =
[rz(1r), rz(2r), ..., rz(Tr )], the confidence score given by KGExplainer is αzr = α1(1) × α2(2) × ... × αT(T).
According to the confidence scores, a ranked list of rules Zr in descending order for each relation
could be generated. For a prediction task q = (h, r, ?), suppose the answer from KGExplainer is
a = t, we present the one top path from h to t grounded according to Zr as explanation.
5 Experiment
During the experiment, we apply KGExplainer to TrasnE(Bordes et al., 2013) and RotatE(Sun et al.,
2019) and evaluate it from two perspectives, one is faithfulness evaluation showing to what extend
that KGExplainer duplicate the behavior of target KGEs, the other one is explanation evaluation
to show the quality of explanations KGExplainer provides. All evaluations are conducted on two
6
Under review as a conference paper at ICLR 2022
Table 2: Link prediction results on WN18RR and FB15K-237.
WN18RR
FB15K-237
Method	MRR	Hit			MRR	Hit		
		@1	@3	@10		@1	@3	@10
NeuralLP	.435	.371	.434	.566	.2402	.1769	.2618	.3623
DRUM	.486	.425	.513	.586	.343	.255	.378	.516
MINERVA	.448	. 413	.456	.513	.293	.217	.329	.456
TransE	.2224	.0128	.3993	.5298	.3294	.2300	.3686	.5272
KGExplainer-TransE	.2225±.0001	.0128±.0001	.3992±.0001	.5297±.0000	.3294±.0001	.2302±.0002	.3683±.0002	.5269±.0002
RotatE	.4767	.4296	.4952	.5737	.3361	.2397	.3731	.5301
KGExplainer-RotatE	.4768±.0001	.4297±.0002	.4951±.0003	.5737±.0002	.3362±.0001	.2397±.0001	.3733±.0002	.5301±.0003
Avg. dif.	.0001±.0001	.0001±.0002	.0001±.0003	.0001±.0002	.0001±.0001	.0001±.0002	.0003±.0002	.0002±.0003
benchmark datasets for link prediction that widely used in KGE works, WN18RR and FB15k-237.
Their statsitics are shown in Table 1.
5.1	Faithfulness evaluation
One of the desiderata of an explaining method is to reliably and
comprehensively represent the local decision structure of the target
model, which means, in the context of KGEs, KGExplainer should
replicate the behavior of KGEs as much as possible. Thus we first
compare the link prediction results of KGExplainer and the target
KGEs and then show how distillation loss changes during training.
Setup and implementation details. KGEs are trained with code
Table 1: Datasets statistics.
	WN18RR	FB15k-237
# Train	86,835	272,155
# Valid	3,034	17,535
# Test	3,134	20,466
# Relation	11	237
# Entity	40,943	14,541
provided by Sun et al. (2019)1 following the best config recommendation on two datasets. For
KGExplainer, we set the length of rules T = 2, and the rule embedding dimension as 2 times
over relation embedding dimension. Other KGE related hyperparameters are set consistent to the
target KGEs. Link prediction results are measured by the common matrices Mean Reciprocal Rank
(MRR), and Hit Ratio (Hit@x(x = 1/3/10)), over head entity prediction and tail entity prediction.
In order to enable head entity prediction, we inverse the order of rule body relation embeddings from
rule decoder and replace each of them with it’s inverse relation embedding, specifically, for query
(?, r, t), [(r(zTr ))-1, ..., (r(z2r))-1, (r(z1r))-1] are applied as z0 in Equation (8). For KGExplainer , we
repeat the experiment for 3 times, and report the average results.
Result Analysis. The link prediction results of KGExplainer and target KGEs in Table 2 shows
that KGExplainer successfully achieves nearly the same performance on link prediction task as the
target KGE, with average performance differences among three matrices vary from 0.0001 to 0.0003
on WN18RR and FB15k-237. While considering that different KGEs models might achieve similar
results as shown in Sun et al. (2019), to take a deep look at the differences between KGExplainer and
KGEs, in Figure 3, we show the changes of distillation loss during training of KGExplainer for each
dataset with two target KGEs. The distillation loss decreases quickly from a high value close to 1 to
almost 0, showing that for each training sample, both positive and negative ones, KGExplainer gives
nearly the same scores as the target KGE, supporting that KGExplainer is faithful to target KGEs
and is a reliable and successful replicator of target KGEs.
(b) TransE-FB	(C) RotatE-WN
Figure 3: Distillation loss during training, where “WN” and “FB” are abbreviations for WN18RR
and FB15k-237, respectively.
1https://github.com/DeepGraphLearning/KnowledgeGraphEmbedding
7
Under review as a conference paper at ICLR 2022
5.2	Explanation Evaluation
It is important to reach an objective assessment of how good an explanation is for KGExplainer.
Unfortunately, similar to other areas, evaluating explanations is made difficult by the impossibility of
collecting “ground-truth” explanations, which is possibly to be built only with experts understanding
how the model decides(Miller, 2019). Thus instead of end-to-end evaluation schemes, we take an
alternative way to first evaluate the quality of latent rules from KGExplainer and then show case
study of explanations.
Evaluation metrics. With a decreasingly ranked list of rules for each relation according to the
confidence score given by KGExplainer, we calculate the average statistical confidence score of
each rule to show the quality of them. Statistical confidence are
#(x,y) : ∃e1,..., em : B∧r(x,y)
conf (r(x, y) J B) =-------------------------------------- (16)
#(x,y) : ∃e1,..., em : B
where denominator is the number of head and tail entity pairs satisfying the rule body B, and the
numerator is the number of head and tail entity pairs satisfying both the rule body B and rule
head r(x, y). Statistical confidence reflects how common that the entity pairs satisfy rule body and
also satisfy rule head, and is a measurement of rule quality from statistical point of view. Given a
ranked list of rules, generally, a higher average statistical confidence score means rules contained
in the list with better quality. Since the higher quality rules are expected to be ranked at the top
of the list, we report the average statistical confidence of Topk(k = 1, 3, 5, 10) rules, denoted as
AvgConfk = ∣Ri×k Pzr∈zr[:k] Conf (Zr) in which ZJ k] is the ToP k rules list for relation r
provided by a model.
Baseline Approaches. We ProPoses two statistical baselines for AvgConfk comParison to KGEx-
Plainer, Traverse-Avg and RAR (Resource Allocation over Relations). APart from statistical base-
lines, we also comPare to scoring the traverse Paths via TransE and RotatE, and also differentiable
rule learning methods NeuralLP and DRUM .
Traverse. Given a relation r, we traverse all relations at each steP resulting in (|R| × 2 + 1)T rules of
all Possible combinations with relation direction considered. And their average statistical confidence
are rePorted as results. Thus ToPk are the same with different k in Traverse-Avg. This baseline shows
overall average confidence of all combinations. Other methods should achieve better results than
Traverse-Avg as long as they are effective at learning rules. Based on traversed Paths, we also rePort
Trverse-TransE and Trverse-RotatE as baseline (with inverse and selflooP relation added and their
embeddings are got in the same way as KGExPlainer) in which we score them via similarity between
comPositional rePresentation of Paths rePresentation and target relation embedding following (Yang
et al., 2015; Guu et al., 2015; Zhang et al., 2019).
RAR (Resource Allocation over Relation). Following the idea of resource allocation over net-
works(Lu & Zhou, 2011) and PCRA algorithm(Lin et al., 2015a), We propose a method for resource
allocation over relations with the frequency of connection between two relations within considera-
tion. Specifically, more resources (higher probability) should be assigned to more frequently linked
relations. Given two relation r1 and r2, the probability of choosing r2 as the next step of r1 in the
rule body that -r→1 ◦ -r→2 is defined as
P(r1∣r2，G) = PPePC⅛× ChC	(17)
r∈G	e∈G C(r1,e) × C(r,e)
where C(tr,e) is the times of entity e as the tail entity of r in G, counted over train dataset, and C(hr,e)
is the the times of e as the head entity of r. Finally, RAR will rank the most frequent path at the top.
This baseline is a naive but powerful solution for rule mining similar to the idea of biased random
walk(Liu & LU, 2010).
NeuralLP is the first differential rule learning method which could generate a probability for each
relation as the relation in each step of the rule body, and finally the confidence score of each rules,
of the same semantic as the α in our method, could be calculated. For one relation r, the ranked list
of rules for it is decoded following the rule decoding algorithm proposed in NeuralLP(Yang et al.,
2017) and DRUM(Sadeghian et al., 2019), with threshold set as 0.0001 to ensure enough number of
rules for each relation.
8
Under review as a conference paper at ICLR 2022
Table 3: AvgConfk results on WN18RR and FB15K-237.
Method		WN18RR				FB15K-237	
	Topl	Top5	Top10	Top1	Top5	Top10
Traverse-Avg	.1123	.1123	.1123	.0032	.0032	.0032
RAR	.2939	.2673	.2371	.0649	.0689	.0649
NeuralLP	.6931	.5228	.4376	.0510	.0477	.0457
DRUM	.6163	.5694	.5193	.0703	.0531	.0471
Traverse-TransE	.0909	.1089	.0872	.0129	.0026	.0013
Traverse-Rotate	.0599	.0236	.0527	.0000	.1582	.1306
KGExplainer-TransE	.6569±.0008	.5077±.0007	.4289±.0008	.1715±.0098	.0960±.0034	.0794±.0031
KGExplainer-RotatE	.7897±.2166	.4786±.0711	.4293±.0578	.6660±.0849	.2968±.0436	.2173±.0347
Result Analysis. As shown in Table 3, for WN18RR, NeuralLP, KGExplainer-TransE and KGEx-
plainer RotatE achieves comparable quality of rules, in which DRUM performs best on Top5 and
Top10 and KGExplainer-RotatE is the best on Top1. And for FB15k-237, KGExplainer-RotatE
shows a significantly better quality of rules than other methods. If we have a look at the link predic-
tion results in Table 2, we could find that generally the rule quality provided by these models are con-
sistent to their link prediction results, for example, on FB15k-237, RotatE and KGExplainer-RotatE
performs the best, then is TransE and KGExplainer-TransE, and finally is DRUM and NeuralLP,
which is the same in Table 3. This illustrates the effectiveness of KGExplainer as an explainer for
KGEs. Results of Traverse-TransE and Traverse-RotatE is significantly worse than KGExplainer,
showing that getting a good rank of rules that reflect how KGE makes predictions is nontrivial. The
score variance of Top1 to Top10 is gradually decreasing, showing that the average quality of Top10
rules are stable while the Top1 rule might be diverse.
I I I
əouəpɪjuo0ə00EJəʌv
top1 top5 top10 hit10	top1
(a) TransE-WN
20161208040°
9u9pyuoəEJəʌv
0iυH
# Steps
top5 top10 hit10
0.4
0.2
5000	10000 15000
əouəpɪjuo0ə00EJəʌv
(c) RotatE-WN
əouəpɪjuo0ə00EJəʌv
----toρ5 ----top10 -----hit10
0.6
-topi
0.80
0.60
0.40
0.20
0.00
0
0
5000 10000 15000
# StepS
(d) RotatE-FB
O=!H
(b) TranSE-FB
Figure 4: AvgConf k and the link prediction results on valid dataset at different steps during training.
Figure 4 shows the changes of link prediction results H it10 and AvgConfk of rules during training.
It is interesting that for FB15k-237, the link prediction result of Hit10 gets stable after a few steps,
while the quality of rules keeps increasing, showing that even if the link prediction results keeps
the same, the latent rule quality could be improved further. And for WN18RR, this phenomenon is
less obvious which might be because of the small combination space over 11 relations for path-like
rules.
Case Study. Figure 5 shows a case study for prediction q =
(00621734, NeriVationally_relatedRrm) and a = 05685030,
where KGExplainer-TransE and KGExplainer-RotatE rank the
answer at the 3rd and 1st one over 40943 candidate enti-
ties respectively. The two explanations are both composed by
_derivatiOnauy_relatedform and _hypernym, while with different
directions for relations. The statistical confidence of rules from
KGExplainer-RotatE which the explanations are grounded accord-
ing to is higher than KGExplainer-TransE, this ensures a better pre-
diction. The bar chart shows the average confidence for tail entities
ranked in different intervals, in which the average confidence of
05683582 Statistical confidence
ʃɪ TransE: 0.57
Jierivationallyj"elαtecΓJ9fl^	_砌&吧1
^∙^^^erivationallyj∙elatedjbrm
Ct"-------------------------------*L)
0062173^^^^	5685030
00622384
I 0.9
8 0.8
5 0.7
S 0.6
δ0∙5
用0.4
2 0.3
∣0∙2
RotatE:0.97
I	I TransE
I	I RotatE
[1, 5] [6, 10] [11, 15] [16, 20] [21, Inf.)
Rank
Figure 5: Analysis from WN18RR.
predictions ranked in top5 has a significantly higher average confidence than those out of the top 5,
which means that the average confidence of correct predictions is higher than incorrect ones.
E
6	Conclusion and Future work
In this paper, we propose to explain KGE via latent rule learning and propose a framework KG-
Explainer which works well on explaining TransE and RotatE. In KGExplainer, we learn a latent
rule embedding for each relation and train a rule decoder with rule embedding as input to output the
compositive body relation embedding for link prediction, based on which KGExplainer achieves
almost the same link prediction results as the target KGE. Finally, after training, we decode a ranked
list of symbolic rules from compositive body relation embedding based on similarity in vector space
for providing explanations. The rule quality from KGExplainer is proved consistent to the capabil-
ity of target KGEs As a possible future work we would like to adapt KGExplainer for more KGEs
with variance rule length, to make it a more general and flexible framework.
9
Under review as a conference paper at ICLR 2022
References
Ralph Abboud, Ismail Ilkan Ceylan, Thomas Lukasiewicz, and Tommaso Salvatori. Boxe: A box
embedding model for knowledge base completion. In NeurIPS, 2020.
K. M. Annervaz, Somnath Basu Roy Chowdhury, and Ambedkar Dukkipati. Learning beyond
datasets: Knowledge graph augmented neural networks for natural language processing. In
NAACL-HLT,, pp. 313-322. Association for Computational Linguistics, 2018.
Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko.
Translating embeddings for modeling multi-relational data. In Advances in neural information
processing systems, pp. 2787-2795, 2013.
Zongsheng Cao, Qianqian Xu, Zhiyong Yang, Xiaochun Cao, and Qingming Huang. Dual quater-
nion knowledge graph embeddings. In AAAI, pp. 6894-6902. AAAI Press, 2021.
Ines Chami, Adva Wolf, Da-Cheng Juan, Frederic Sala, SUjith Ravi, and Christopher Re. LoW-
dimensional hyperbolic knowledge graph embeddings. In ACL, pp. 6901-6914. Association for
Computational Linguistics, 2020.
William W. Cohen, Fan Yang, and Kathryn Mazaitis. Tensorlog: A probabilistic database imple-
mented using deep-learning infrastructure. J. Artif. Intell. Res., 67:285-325, 2020.
Rajarshi Das, Shehzaad DhuliaWala, Manzil Zaheer, Luke Vilnis, Ishan Durugkar, Akshay Krishna-
murthy, Alex Smola, and AndreW McCallum. Go for a Walk and arrive at the ansWer: Reasoning
over paths in knoWledge bases using reinforcement learning. In ICLR (Poster). OpenRevieW.net,
2018.
Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. Convolutional 2d
knoWledge graph embeddings. In AAAI, pp. 1811-1818. AAAI Press, 2018.
Ruth C. Fong and Andrea Vedaldi. Interpretable explanations of black boxes by meaningful pertur-
bation. In ICCV, pp. 3449-3457. IEEE Computer Society, 2017.
Jianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. KnoWledge distillation: A
survey. International Journal of Computer Vision, 129(6):1789-1819, 2021.
Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, and Fosca
Giannotti. Local rule-based explanations of black box decision systems. CoRR, abs/1805.10820,
2018.
Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, and Dino
Pedreschi. A survey of methods for explaining black box models. ACM Comput. Surv., 51(5):
93:1-93:42, 2019.
Arthur Colombini Gusmao, Alvaro HenriqUe Chaim Correia, Glauber De Bona, and Fabio Gagliardi
Cozman. Interpreting embedding models of knoWledge bases: A pedagogical approach. CoRR,
abs/1806.09504, 2018.
Kelvin Guu, John Miller, and Percy Liang. Traversing knoWledge graphs in vector space. In EMNLP,
pp. 318-327. The Association for Computational Linguistics, 2015.
Xiao Huang, Jingyuan Zhang, Dingcheng Li, and Ping Li. KnoWledge graph embedding based
question ansWering. In WSDM, pp. 105-113. ACM, 2019.
Himabindu Lakkaraju, Ece Kamar, Rich Caruana, and Jure Leskovec. Interpretable & explorable
approximations of black box models. CoRR, abs/1707.01154, 2017.
Yankai Lin, Zhiyuan Liu, Huan-Bo Luan, Maosong Sun, SiWei Rao, and Song Liu. Modeling
relation paths for representation learning of knoWledge bases. In EMNLP, pp. 705-714. The
Association for Computational Linguistics, 2015a.
Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. Learning entity and relation
embeddings for knoWledge graph completion. In Twenty-Ninth AAAI Conference on Artificial
Intelligence, 2015b.
10
Under review as a conference paper at ICLR 2022
WeiPing LiU and LinyUan Lu. Link prediction based on local random walk. EPL (EuroPhysics
Letters), 89(5):58007, 2010.
Linyuan LU and Tao Zhou. Link prediction in complex networks: A survey. Physica A: statistical
mechanics and its applications, 390(6):1150-1170, 2011.
Scott M. Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In NIPS,
pp. 4765-4774, 2017.
Tim Miller. Explanation in artificial intelligence: Insights from the social sciences. Artif. Intell.,
267:1-38, 2019.
Gregoire Montavon, Alexander Binder, Sebastian Lapuschkin, Wojciech Samek, and Klaus-Robert
Muller. Layer-wise relevance propagation: An overview. In Explainable AI, volume 11700 of
Lecture Notes in Computer Science, pp. 193-209. Springer, 2019.
Yatin Nandwani, Ankesh Gupta, Aman Agrawal, Mayank Singh Chauhan, Parag Singla, and
Mausam. Oxkbc: Outcome explanation for factorization based knowledge base completion. In
AKBC, 2020.
Guanglin Niu, Yongfei Zhang, Bo Li, Peng Cui, Si Liu, Jingyang Li, and Xiaowei Zhang. Rule-
guided compositional representation learning on knowledge graphs. In AAAI, pp. 2950-2958.
AAAI Press, 2020.
Meng Qu, Junkun Chen, Louis-Pascal A. C. Xhonneux, Yoshua Bengio, and Jian Tang. Rnnlogic:
Learning logic rules for reasoning on knowledge graphs. In ICLR. OpenReview.net, 2021.
Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. "why should I trust you?”： Explaining
the predictions of any classifier. In KDD, pp. 1135-1144. ACM, 2016.
Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Anchors: High-precision model-agnostic
explanations. In AAAI, pp. 1527-1535. AAAI Press, 2018.
Ali Sadeghian, Mohammadreza Armandpour, Patrick Ding, and Daisy Zhe Wang. DRUM: end-to-
end differentiable rule mining on knowledge graphs. In NeurIPS, pp. 15321-15331, 2019.
Wojciech Samek, GregOire Montavon, Sebastian Lapuschkin, Christopher J. Anders, and Klaus-
Robert Muller. Explaining deep neural networks and beyond: A review of methods and applica-
tions. Proc. IEEE, 109(3):247-278, 2021.
Gregor P. J. Schmitz, Chris Aldrich, and F. S. Gouws. ANN-DT: an algorithm for extraction of
decision trees from artificial neural networks. IEEE Trans. Neural Networks, 10(6):1392-1401,
1999.
Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda B. Viegas, and Martin Wattenberg. Smooth-
grad: removing noise by adding noise. CoRR, abs/1706.03825, 2017.
Josua Stadelmaier and Sebastian Pado. Modeling paths for explainable knowledge base completion.
In BlackboxNLP@ACL, pp. 147-157. Association for Computational Linguistics, 2019.
Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. Rotate: Knowledge graph embedding
by relational rotation in complex space. In ICLR (Poster). OpenReview.net, 2019.
Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In
ICML, volume 70 of Proceedings of Machine Learning Research, pp. 3319-3328. PMLR, 2017.
Theo Trouillon, Johannes Welbl, Sebastian Riedel, EnC Gaussier, and Guillaume Bouchard. Com-
plex embeddings for simple link prediction. In ICML, volume 48 of JMLR Workshop and Con-
ference Proceedings, pp. 2071-2080. JMLR.org, 2016.
Guojia Wan, Shirui Pan, Chen Gong, Chuan Zhou, and Gholamreza Haffari. Reasoning like human:
Hierarchical reinforcement learning for knowledge graph reasoning. In IJCAI, pp. 1926-1932.
ijcai.org, 2020.
11
Under review as a conference paper at ICLR 2022
Po-Wei Wang, Daria Stepanova, Csaba Domokos, and J. Zico Kolter. Differentiable learning of
numerical rules in knowledge graphs. In ICLR. OpenReview.net, 2020.
Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph embedding by trans-
lating on hyperplanes. In Twenty-Eighth AAAI Conference on Artificial Intelligence, 2014.
Chi-Man Wong, Fan Feng, Wen Zhang, Chi-Man Vong, Hui Chen, Yichi Zhang, Peng He, Huan
Chen, Kun Zhao, and Huajun Chen. Improving conversational recommender system by pretrain-
ing billion-scale knowledge graph. In ICDE,pp. 2607-2612. IEEE, 2021.
Wenhan Xiong, Thien Hoang, and William Yang Wang. Deeppath: A reinforcement learning method
for knowledge graph reasoning. In EMNLP, pp. 564-573. Association for Computational Linguis-
tics, 2017.
Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and
relations for learning and inference in knowledge bases. In ICLR (Poster), 2015.
Fan Yang, Zhilin Yang, and William W. Cohen. Differentiable learning of logical rules for knowl-
edge base reasoning. In NIPS, pp. 2319-2328, 2017.
Wen Zhang, Bibek Paudel, Liang Wang, Jiaoyan Chen, Hai Zhu, Wei Zhang, Abraham Bernstein,
and Huajun Chen. Iteratively learning embeddings and rules for knowledge graph reasoning. In
WWW, pp. 2366-2377. ACM, 2019.
Luisa M. Zintgraf, Taco S. Cohen, Tameem Adel, and Max Welling. Visualizing deep neural network
decisions: Prediction difference analysis. In ICLR (Poster). OpenReview.net, 2017.
A Appendix
This section presents the proofs of 1) self-loop relation embedding, 2) inverse relation embedding
and 3) f1 and f2 function separation of translation function f for TransE and RotatE. Before starting,
we first briefly introduce the TransE and RotatE.
Given a knowledge graph, TransE embed entities and relations as vectors in low-dimensional vector
space. Thue for a triple (h, r, t), elements’ embedding are represented as h ∈ Rd, r ∈ Rd and
t ∈ Rd respectively. For a positive triple (h, r, t), TransE assums that the head entity embedding h
could be translated to t according to r that h + r = t. Thus
Φtranse = gtranse (ftranse(h, r), t)
ftranse (h, r) = t = h + r
gtranse(t, t0) = kt - t0k
(18)
(19)
(20)
For a triple (h, r, t), in RotatEm entities are embeded in complex vector space that h ∈ C and
relation as rotation in complex space which is calculated from r ∈ Rd . Thus
Φrotate = grotate (frotate(h, r), t)
frotate(h, r) = t0 = h ◦ (cos(r) + sin(r)i))
grotate(t, t0) = kt - t0k
(21)
(22)
(23)
A.1 Self-loop relation embedding.
Embedding for self-loop relation r° could be inferred by the vector space assumption of KGEs.
Since self-loop relation means an entity is linked to itself through this relation that (e, r°, e), thus
•	In TransE, e + r° = e. Thus r° = 0 in TransE.
•	In RotatE, e ◦ (cos(r°) + Sin(r°)i) = e. Suppose e = e『+ eyi, r； = cos(r°) and
Y? = sin(r°), thus
e ◦ (cos(r°) + sin(r°)i) = (e； ◦ r； - ei ◦ r°) + © ◦ r； + e； ◦ r°)i	(24)
12
Under review as a conference paper at ICLR 2022
thus
er o 琮-ei o r° = er, and ei o 琮 + er o r° = ei	(25)
thus
琮=1 = cos(ro), ri = 0sin(ro)	(26)
Finally, we could infer that ro = 0 in RotatE.
A.2 INVERSE RELATION EMBEDDING.
The inverse relation r-1 of relation r means that when (h,r,t) holds, then (t,r-1, h) also holds.
Thus
•	In TransE, we could get h + r = t and t + r-1 = t, thus r-1 = -r in TransE.
•	In RotatE, we could get that ho(cos(r)+sin(r)i) = t and to(cos(r)-1+sin(r-1)i) = h,
and suppose that h = hr + r%i, t = tr + t%i, rr = cos(r), r = sin(r), r-1 = cos(r-1),
r-1 = sin(r-1) thus
hr o rr — hi o r = tr	(27)
hr o ri + hi o rr = ti	(28)
tr o r-1 - ti o r-1 = hr	(29)
tr o r-1 + ti o r-1 = hi	(30)
thus
(tr o r-1 - ti o r-1)	o rr - (tr o r-1 + ti o r-1) o ri = tr	(31)
(tr o r-1 - ti o r-1)	o ri + (tr o r-1 + ti o r-1) o r = t	(32)
thus
tr o (r-1 o rr - r-1	o r) - ti(r-1 o ∏ + r-1 o rɔ = tr	(33)
tr o (r-1 o ri + r-1	o rr) + ti(r-1 o rr - r-1 o rr) = t	(34)
thus
rr-1 o rr - ri-1 o rr = 1	(35)
rr-1 o ri + ri-1 o rr = 0	(36)
.∙. cos(r-1)cos(r) — sin(r-1) o sin(r) = 1	(37)
cos(r-1) o sin(r) + sin(r-1) o cos(r) = 0	(38)
thus
cos(r-1) = cos(r), sin(r-1) = -sin(r)	(39)
Finally, we could get that r-1 = -r in RotatE.
A.3 f1 AND /2 SEPARATION.
In this section, we prove that the separation of /1 and /2 for KGEs satisfy Equation (15).
13
Under review as a conference paper at ICLR 2022
•	In TransE, we set f2(r) = r and f1 (h, r0) = h + r0, suppose αi is the weight for ith
relation
|R|	|R|
Xαif1(h,f2(r)) = Xαi(h+r)	(40)
i=1	i=1
|R|	|R|
= X αih + X αir	(41)
i=1	i=1
|R|	|R|
= h + X αir, if X αi = 1	(42)
i=1	i=1
|R|
= f1(h,Xαif2(r))	(43)
i=1
Thus such separation of f1 and f2 in TransE satisfy Equation (15).
•	In Rotate, we set f2(r) = cos(r) + sin(r) and fι(h, r0) = h ◦ r0 ,suppose a is the weight
for ith relation
|R|	|R|
X αif1(h,f2(r)) = X αi(h ◦ (cos(r) + sin(r)))	(44)
i=1	i=1
|R|
= h ◦	αi(cos(r) + sin(r))	(45)
|R|
= f1(h, X αif2 (r))	(46)
i=1
Thus such separation of f1 and f2 in RotatE satisfy Equation (15).
14