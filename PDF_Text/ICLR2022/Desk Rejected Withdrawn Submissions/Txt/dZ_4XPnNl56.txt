Under review as a conference paper at ICLR 2022
BioLeaF: A Bio-plausible Learning Frame-
work for Training Spiking Neural Networks
Anonymous authors
Paper under double-blind review
Ab stract
Our brain consists of biological neurons encoding information through accurate
spike timing, yet both the architecture and learning rules of our brain remain
largely unknown. Comparing to the recent development of backpropagation-based
(BP-based) methods that are able to train spiking neural networks (SNNs) with
high accuracy, biologically plausible methods are still in their infancy. In this
work, we wish to answer the question of whether it is possible to attain compara-
ble accuracy of SNNs trained by BP-based rules with bio-plausible mechanisms.
We propose a new bio-plausible learning framework, consisting of two compo-
nents: a new architecture, and its supporting learning rules. With two types of
cells and four types of synaptic connections, the proposed local microcircuit ar-
chitecture can compute and propagate error signals through local feedback con-
nections and support training of multi-layers SNNs with a globally defined spik-
ing error function. Under our microcircuit architecture, we employ the Spike-
Timing-Dependent-Plasticity (STDP) rule operating in local compartments to up-
date synaptic weights and achieve supervised learning in a biologically plausi-
ble manner. Finally, We interpret the proposed framework from an optimization
point of view and show the equivalence between it and the BP-based rules un-
der a special circumstance. Our experiments show that the proposed framework
demonstrates learning accuracy comparable to BP-based rules and may provide
new insights on how learning is orchestrated in biological systems.
1	Introduction
Thanks to greater computing power, deep learning has gained remarkable achievements in re-
cent years (Hinton et al., 2006; Bengio & LeCun, 2007; Schmidhuber, 2015; Goodfellow et al.,
2016). However, learning by backpropagation (BP) (Rumelhart et al., 1986) is still the most popular
method, which is generally believed impossible to be implemented in our brains (Illing et al., 2019).
As compared to deep neural networks (DNNs), our brain, the only known true intelligence system,
is more energy efficient (Von Neumann, 2012), robust (Deneve et al., 2017; Qiao et al., 20l9), and
capable of achieving life-long learning (Parisi et al., 2019), online learning (Lobo et al., 2020), logic
reasoning (Monti & Osherson, 2012), and has many other advantages (Raichle et al., 2001). The
development of artificial intelligence (AI) may benefit from investing in how our brain works.
Our brain is a complex system consisting of neurons that communicate with each other through
spikes. Therefore, people tried to use simplified spiking neurons to form a network that mimic the
function of our brain. Such spiking neural networks (SNNs) can naturally exploit spatio-temporal
data with each neuron’s internal temporal dynamics (Yang et al., 2021), and save orders of magnitude
of less energy when running on neuromorphic hardwares (Davies et al., 2018; Kim et al., 2020b;
Davies et al., 2021). However, the training of SNNs is difficult.
Recent developments of the direct training methods of SNNs mainly diverge into two streams: BP-
based rules and bio-plausible rules (Hao et al., 2020).
BP-based learning rules include: the activation-based surrogate gradient methods (Zenke & Ganguli,
2018; Shrestha & Orchard, 2018; Wu et al., 2018), the timing-based methods (Zhang & Li, 2020),
the combination of both (Kim et al., 2020a), and the recently proposed neighborhood aggregation
method - NA (Yang et al., 2021). These BP-based methods gained great performance improvement
1
Under review as a conference paper at ICLR 2022
and helped SNNs to be implemented on real-world problems, yet their biological plausibility re-
mains unresolved: the co-existence of both forward and backward signals requires a neuron to fire
two sets of uncorrelated signals from the same neuron body, which is not bio-plausible.
While the other branch, the bio-plausible learning rules, represented by the STDP (Taylor et al.,
1973; Levy & Steward, 1983) and the Widrow-Hoff (WH) (Widrow & Hoff, 1960) rules, adjusts
parameters using local plasticity only.
The STDP learning rule is built upon the Hebbian learning rule, which can be informally described
as: ”Cells that fire together, wire together” (Hebb, 1949). Following this rule, STDP adjusts synaptic
weights by evaluating the timing correlation: If a presynaptic neuron fires a few milliseconds before
a postsynaptic neuron, meaning this presynaptic spike contributes to the firing of the postsynaptic
neuron, their connection is strengthened (causal), or called long-term potentiation. Whereas the
opposite temporal order results in long-term depression (acausal). Although STDP demonstrates its
potential usefulness in both supervised and unsupervised manners, it is unlikely that STDP works
alone: Strengthened connection makes the firing activity of a pair of neurons more synchronized,
and vice versa. Due to the existence of the positive feedback loop, one needs to introduce additional
tricks to stabilize the learning process - such as winner-takes-all (WTA) (Nessler et al., 2013; Diehl
& Cook, 2015; KheradPisheh et al., 2018; SaUnders et al., 2018), weights normalization (Ferre et al.,
2018), weights clamping (Diehl & Cook, 2015; Kheradpisheh et al., 2018; Lee et al., 2018; Saunders
et al., 2018), layer-by-layer training (KheradPisheh et al., 2018), and others (Panda & Roy, 2016).
In comparison, the WH-based learning algorithms, represented by ReSUMe(PonUIak & Kasinski,
2010) and SPAN (Mohemmed et al., 2012), are able to train a sPiking neUron to generate sPikes with
accUrate timing, and do not need additional tricks as STDP does. The WH learning rUle (Widrow &
Hoff, 1960) is a special case of the gradient descent rUle where the least mean sqUare loss is applied.
Ponulak & Kasinski (2010) presented a spiking analogy to the classical WH rule for spiking neuron
models, and their rUle can be interpreted as an STDP-like process between a presynaptic spike train
and a postsynaptic error signal. However, previous WH-based methods are constrained to train a
single layer SNN since it has difficulty in propagating the teaching signal to previous layers. Sporea
& GrUning (2013) extend the single layer WH-based learning rule - ReSuMe (Ponulak & Kasinski,
2010) onto multi-layers networks through BP-liked error propagation, which is practical but deviates
from the original intention of exploring bio-plausible mechanisms.
In this work, we propose a bio-plausible learning framework - BioLeaF, underpinned by two key
components: 1) a microcircuit architecture consisting of two types of spiking neurons and four types
of synapses as shown in Figure 1, and 2) the STDP-based learning rules built upon our architecture.
The architecture is inspired from the predict-coding-based algorithms (Rao & Ballard, 1999; Ste-
fanics et al., 2014). Previous works proposed several predictive-coding-inspired microcircuit ar-
chitectures to realize BP-liked learning on rate-based neurons (Bastos et al., 2012; Whittington &
Bogacz, 2017; Sacramento et al., 2018), where all neurons communicate with each others through
continuous currents, and no explicit temporal point processes or spiking behaviors are included.
This simplified setting limits the discussion of the widely used bio-plausible learning rules defined
by the spike-timing correlation like STDP rule and WH rule. Our architecture differs from them in
both the neuron and the synapse models. We include the more bio-plausible spiking leaky integrate-
and-fire (LIF) neuron (Gerstner & Kistler, 2002) and synapses models that transmit discontinuous
spikes into our architecture.
The architecture consists of two types of spiking cells - pyramidal cells and somatostatin-expressing
(SOM) cells (Petreanu et al., 2009; Larkum, 2013). Each pyramidal cell i has a paired SOM cell ip
to predict its firing activity one-on-one through the same current inputs aj, j = 1 …N, where N is
the total number of presynaptic neurons. The prediction mismatch, also interpreted as a surprise or
free energy (Friston, 2010), is transmitted through top-down connections to all presynaptic neurons’
apical dendrites, and acts as their error signals. A pyramidal cell,s top-down output a is modulated
by its error signals, whereas a SOM cell’s top-down output ap is not. Therefore, without knowing
the signal in i’s apical dendrite, SOM cell ip’s prediction can only cancel out part of i’s output,
which leaves the error-related signal on j’s apical dendrites. The summation of all top-down signals
will cancel out each others pair by pair, and leaves the total error-related signals onto j , from where
the layer-by-layer error backpropagation is realized.
2
Under review as a conference paper at ICLR 2022

Pyramidal cell i
Pyramidal cell j
f
Apical dendrites
Basal
dendrites
Forward Forward Predict
>--lʃ; F^//^ +
u；
斤
a；
So Soma
------------------^p；
Top-down Top-down Predict
reset

Figure 1: Our proposed Microcircuit architecture.
The learning rule built upon our microcircuit architecture is the standard STDP rule as defined in
Levy & Steward (1983) with specialized choices of pre/postsynaptic signals. As comparing to typi-
cal SNNs’ architectures (Shrestha & Orchard, 2018; Wu et al., 2018; Yang et al., 2021), which only
have forward connected weights, we introduce three additional types of weights: forward predict,
top-down, and top-down predict as in Figure 1 to support the bio-plausible learning. Therefore, to
update different types of synaptic weights, our STDP updating rules need to be defined between
pairs of presynaptic and postsynaptic signals locates in different components of our microcircuit ar-
chitecture. A presynaptic signal is an output spike train located in the presynaptic neuron like sj for
both weights wij and wipj, or sip for wjipe following Levy & Steward (1983), and a postsynaptic
signal is an error signal located in the postsynaptic neuron like ei for weights wij and ej for wjipe.
More generally, we analytically show that the the proposed framework is equivalent to the BP-
based learning rules under certain settings. To derive a BP-based learning rules which propagates
continuous-valued loss signal through discontinuous all-or-none firing activity, some approximation
methods are applied following previous works (Shrestha & Orchard, 2018; Wu et al., 2018; Yang
et al., 2021). Yet such approximation surprisingly aligned with the standard STDP rules under our
microcircuit architecture with only minor differences. We empirically build a 2-layers toy example
to evaluate the learning ability of BioLeaF. Deeper than a single layer breaks the limit of the previous
WH-based learning rules. Then, by benchmarking on the datasets including MNIST (LeCun, 1998)
and CIFAR10 (Krizhevsky et al., 2009), the proposed BioLeaF also exhibits comparable accuracy
with other BP-based methods when extended to multi-layers deep SNNs.
2	Microcircuit Architecture
2.1	Spiking Neuron Model
Both pyramidal cells and SOM cells are modeled by the leaky integrate-and-fire (LIF) neuron model,
which is one of the most prevalent choices for describing dynamics of spiking neurons.
2.1.1	LIF Neuron Model
The dynamics of the neuronal membrane potential u of neuron i in layer l is described by:
du(I)⑴
Tm ~1Γ~
(1)
where Ii(l) is the total input of synaptic currents, and ηi(l) (t) denotes the reset function. A spiking
neuron reset its membrane potential from threshold H to the resting potential Vrest (We set Vrest = 0)
each time when it fires a spike. We model ηi(l) (t) as the time convolution (*) between a reset kernel
V and the neuron,s output spike train Sil): η(l)(t) = (V * Sy))(t). The reset kernel V(t) = -Hδ(t).
3
Under review as a conference paper at ICLR 2022
The amount of resetting is equal to the threshold Id (We set Id = 1), and δ(t) is the Dirac delta
function. The neuron’s output spike train is also modeled by a serious of delta functions as:si(l) =
Pf δ(t - ti((l)f)). Here, ti((l)f) represent the firing time of the fth spike of neuron i in layer (l). An
output spike is generated once the membrane potential reaches the threshold H. Following Shrestha
& Orchard (2018), We define the spike function as:
fs(u) : u → s, s(t) := s(t) + δ(t - t(f+1)), t(f+1) = min t : u(t) = H,t > t(f) .	(2)
2.2	Synaptic Currents
We model the general total input current on neuron i as: Ii(t) = Pj wij Pf αij (t - tj(f)). The
modeled total input is the Weighted sum over all current pulses:
αij (t - tj(f)) = gij (t - tj(f)) ∙ [Esyn - Ui ⑴] ,	⑶
Where Esyn is the reversal potential for the synaptic current. We set Esyn	H in all types of
synapses (Destexhe et al., 1998), so the membrane potential dependency can be neglected, and the
term [Esyn - ui(t)] can be treated as a constant and absorbed into Weights. gij (t - tj(f)) is the
synaptic conductance change. We modeled it folloWing Eyal et al. (2018), but simplified the double
exponential function to a single exponential decaying function and have:
gij (t - tj(f)) = Bi ⑴∙(I∕τS) ∙ exp [- (t - tj(f)) ∕τs] ,	(4)
Where Bi(t) is a membrane potential dependent gating function. The synapses in different location
have different properties, Where the tWo types of synapse We apply are named as the forward-related-
type (F-type) and the error-related-type (E-type). We introduce them one by one as folloWing:
F-Type Synapses:
The connections from the outputs of pyramidal cells in one layer to the basal dendrites of pyramidal
cells in their next layer carrying important feature information build up the main architecture in a
spiking neural netWorks. When training is finished, only these forWard connections are needed to
realize inference. We implement these forWard connections wi(jl) together With their paired forWard
predict connections wi(l)j With the F-type synapses.
Bi(t) is set to 1 (voltage independent conductance) as a general setting for AMPA-based conduc-
tance (Eyal et al., 2018). We folloW this setting and the input current is then simplified to a Widely-
used alpha function With time constant τs :
αj (t — tj(f)) = (1∕τs) ∙ exp [— (t - tj(f)) ∕τs] .	(5)
Under Which, the synaptic current is independent from neuron i, and all postsynaptic current (PSC)
generated from neuron j can be uniformly expressed by one variable aj as:
aj(t) = X αij(t - tj(f)) = (Sj * e)(t),	e(t) = (1∕τs) ∙ exp(-t∕τs)H(t),	(6)
f
where (*) represents the time convolution. e(∙) is the impulse response. H(∙) represents the Heavi-
side step function: H(t) = 1, t ≥ 0 and H(t) = 0, t < 0.
A fully connected layer can be described through the current flows as:
N (l-1)	N (l-1)
Ii(l)(t) = X wi(jl)Xαij(t-t(jl(-f)1))= X wi(jl)a(jl-1)(t).	(7)
j=1	f	j=1
Other layers like convolution layers can be easily converted to fully connected layers. Similarly, the
total current of SOM cell Ii(l) is modeled as: Ii(l) (t) = PjN=(l1-1) wi(l)ja(jl-1), where the footnote p
represent the predict-related, or the SOM-related variables.
E-Type Synapses:
All other connections are modeled by E-type synapses, which differs from the F-type synapses by
their postsynaptic voltage dependent property. We model the voltage dependent gating function
4
Under review as a conference paper at ICLR 2022
Bi(t) like how prior works model the NMDA-based synapses (Eyal et al., 2018). Bi(t) has a
shape that peaks when the PostsynaPtic cell,s membrane potential ui(t) reaches the threshold H,
and decrease as ui(t) moves away from H. Such a shape acts as surrogate derivative function when
compared to BP-based methods, which will be fully discussed in the following section.
We define Bi(t) of our synapses on the apical dendrites as following:
Bi(t)
gmax
1 + exp [—k (ui(t) — uo)] ∙ [Mg2+] ∙ n
(8)
where the extracellular magnesium concentration [Mg2+] was 1 mM in the model. We shift the
voltage dependency of Bi(t) by u0 = H, and tune the parameters gmax, k and n to fits the function
B into our simplified setting where vrest = 0, and H = 1.
The error backpropagation is achieved by the corporation between pairs of pyramidal cells and SOM
cells. Higher level pyramidal cells’ top-down output currents are coupled by the error signals located
in their apical dendrites. We model this coupling effect by the current sum of both a neuron’s PSC
and its error signal as: eai(l)(t) = ai(l) (t)+ei(l) (t). A pyramidal cell’s top-down connection contributes
positively with weights wj(li) onto previous layers’ pyramidal cells’ apical dendrites, and its paired
SOM cell contribute negatively with weights wj(li) , where the footnotes p stands for SOM-related,
and the footnotes e stands for error-related. We express the total error signals on the pyramidal cell
j’s apical dendrites as:
N(l)
e(jl-1)(t) = Bj(l-1)(t) X wj(li)eaei(l)(t)—wj(li)peai(pl)(t)	,	(9)
i=1
For the output layer, the apical dendrites receives the one-on-one error signal from higher brain areas
to realize supervised learning.
ei(lN)(t) =Bi(lN)(t) haitarget(t) —ai(lN)(t)i	(10)
In our framework, SOM cells mimic the behavior of the same layer’s pyramidal cells one-on-one.
Therefore, a one-to-one nudging signal from a pyramidal cell to its corresponding SOM cell (as
the dashed purple connections in Figure 1) are needed. Together with the negative feedback output
currents that SOM cells generated themselves, we get the local error signals ei(l) ofan SOM cell i in
layer (l):
ei(pl)(t) = αi(pl)j(t) — αi(pl)ip(t) = Bi(pl)(t) hai(l)(t) —ai(pl)(t)i .	(11)
Although this simplified one-to-one setting impose special constrains on the neural network’s con-
nectivity, the recent monosynaptic experiments confirm that the SOM cells do receive top-down
connections which may encode such teaching information (Leinweber et al., 2017).
The SOM cells differs from the pyramidal cells by the sign of their output currents, but it does not
mean that we fix the type of a cell to be excitatory or inhibitory. Instead, we allow the synapses’
connection weights to move across zero freely and change the sign of its current, which is a general
setting in previous works (PonUlak & Kasinski, 2010; Sacramento et al., 2018). When currents from
both SOM cells and pyramidal cells summed together into the SOM cells or the apical dendrites as
in (11) and (9), a minus sign is added for SOM cell’s outputs.
3 Bio-plausible Learning Rules
3.1 Spike-Timing-Dependent-Plasticity (STDP)
We first introduce a popular version of the STDP rules: ∆wij = m n κSTDP (tim — tjn), where
κSTDP is the STDP kernel function, which is modeled by the two-sides exponential decaying func-
tion defined as:
κSTDP(∆t)
A+ ∙ exp(—∆t∕τ+), ∆t > 0
—A- ∙ exp(∆t∕τ-), ∆t < 0
(12)
5
Under review as a conference paper at ICLR 2022
Meantime, We define a reversed STDP kernel function Kstdp (t) = κsτDp(-t). Recalling that
all spike trains are a serious of delta function s = Pf δ(t - t(f) ), and considering the delta func-
tion’s sampling property [f (t)δ(t - T)] dt = f(T), We reWrite the STDP updating rule into tWo
equivalent forms:
∆wij
* KSTDP)(t) ∙ Si(t)
dt = ηij J Sj (t) ∙ (si
* 用STDp)(t) dt,
(13)
Where ηij is the learning rate. Although ηij can be absorbed into A+ and A-, We explicitly define
it for clarity.
Since the WH rule can be interpreted as an STDP-like process betWeen the presynaptic spike trains
sj and an error signal ei := siteach - si. In this Work, We represent both the STDP rule and the
WH rule uniformly as STDP(∙, ∙), where the STDP rule is: STDP(spre, spost), and the WH rule
is: STDP(spre, epost). In addition, WH rule’s kernel function KWH is usually equal to KSTDP as in
(12). Defining the reverse kernel function kwh(∕) = kwh(-%), we have the weight updating rule
of the WH rule as:
∆wij
ηj /(sj * κwH)(t) ∙ ei(t) dt = ηj / sj(t) ∙ (ei * 方wH)(t) dt.
(14)
It is noteworthy that the WH-based rules provides a fixed point in the weight space, ∆wij = 0 when
ei = 0, which means siteach = si . It is a global positive attractor under certain conditions (Ponulak
& Kasinski, 2010).
3.2 Our bio-plausible learning rules
We first conclude our synaptic learning rules as following:
∆wi(jl)	= STDP(s(jl-1),ei(l))	= ηij	s(jl-1) (t) * KSTDP (	t) ∙ e(l(t)dt	(15)
∆wi(l)j = ipj	STDP(s(jl-1),ei(pl))=	ηipj	sj(l-1) (t) * KSTDP	It) ∙ e(p) (t)dt	(16)
∆wj(li)	= j pe	STDP(si(pl), e(jl-1)) =	ηjipe	si(pl) (t) * KSTDP (t	)∙ ejlτ) (t)dt	(17)
where ηij , ηipj , and ηjipe are three different learning rates for these three types of synaptic con-
nections. In the above three equations, all the adjusting rules of a synapse can be described as a
STDP process between a presynaptic current and a postsynaptic error signal, which exploits great
biological plausibility. The top-down synaptic weights wj(li) are set to be equal to the bottom-up for-
ward weights wi(jl) for simplicity. One can also try to fixed the top-down weights wj(li) as randomly
initialized values following the idea of the feedback alignment (Sacramento et al., 2018).
We interpret each type of synapses’ learning rule as following:
In (15), wi(jl) represents the forward weights. It’s fixed point ei(l) (t) = Bi(lN) (t)[aitarget(t) -
ai(lN)(t)] = 0 forms a positive attractor to minimize the error signal. When training is converged,
we expect ai(lN) ≈ aitarget for all pyramidal cells (i = 1, . . . , N(l)), (l = 1, . . . , lN).
In (16), wi(l)j stands for the predictive connections. Its fixed point in our learning rule is ei(l) (t) =
Bi(l) (t)[ai(l) (t) - ai(l) (t)] = 0, which means ai(l) = ai(l), and si(l) = si(l). As compared to (15),
the learning rule of (16) does not have a fixed target signal, but needs to follow the continuously
changing behavior of each SOM cell’s corresponding pyramidal cell during training.
The learning rule (17) minimizes the norm of ej(l-1) (t) in (9) through adjusting wj(li) , which is
equivalent to solving a linear equation: PiN=(1l) wj(li) ai(l) (t) = PiN=(1l) wj(li) (ai(l) (t) + ei(l) (t)).
Considering the Current-Time as a continuous f (X) - X function space, where all SOM cells'
PSCs ai(l), (i = 1, . . . Nl) form a basis of the space. Then the goal here is to restore the summed
6
Under review as a conference paper at ICLR 2022
currents of all pyramidal cells in layer (l) through these basis functions. When a predictive weight
wi(l)j is well adjusted, ai(l) approximately equals to ai(l), then an obvious solution to the equation
above will be letting wj(li) equal to wj(li) , if we consider the error currents ei(l) (t) as the orthogonal
uncorrelated signal to the basis.
4 Relationship to the BP Algorithm
4.1	Backpropagation Flow
Since the SOM cells are auxiliary in our architecture, we only introduce how backpropagation works
in a general SNN without SOM cells.
Consider a general loss function L = t E(t)dt, which is defined on the output layers’ PSC
ai(lN) (t), i = 1, . . . , N(l) , where lN is the total number of layers. The differentiable property of
a loss function requires that ∂L∕∂a(lN)(t) exist. We name the partial derivative on the layer (l)'s
PSCas:d(l)(t) := dadLt-.
ai (t)
Taking the l2 distance between two PSCs, or the van Rossum distance (van Rossum, 2001) between
two spike trains, as an example:
L= 1 /[(at”.- a"3t)]2 dt =1 / [((Starget * e)-(铲) * €»矶2 dt (18)
When computing the gradient of loss with respect to the synaptic weight of the last layer wi(jlN):
∂L∕∂wjN) = R d(N)(t) (e * ∂s(N)/∂wjN)) (t)dt, one may find the derivative ∂s(lN)∕∂wjN) is
ill-defined due to spiking neurons’ discontinuous all-or-none firing activities. Following (Zenke &
Ganguli, 2018), We substitute this term by: (σ0(u(lN)) ∙ ∂u(lN)∕∂wjN)), and further approximate
the term (∂uilN )∕∂wjN)) ≈ ajN-1) by omitting the temporal dependency of membrane potentials.
We have the Weights updating rule as:
∆wi(jlN)
ij
η/-d(N)(t) (e * (σ0(u(lN)) ∙ a尸—1))) (t)dt
∂L
-η∂W(N
η
post
e * (SjN - 1) * e))) (t) = η / e(lN)(t) ∙
s(jlN-1) *κBP (t),
pre
(19)


|
z
Where η is the learning rate, ei(lN) := -di(lN)σ0(ui(lN)), and the kernel function of BP algorithm
KBP(t) := (e * e)(t) = [(t∕τs2) ∙ exp(-t∕τs) ∙ H(t)]. In the second line, we approximately switch
the order of time convolution and product to separate variables of presynaptic neurons and postsy-
naptic neurons. Then to further propagate the gradient to previous layers, we calculate the partial
derivative of loss with respect to hidden layer’s PSCs as:
N(l)	N(l)	N(l)
djl-1)(t) = X (dil) * e) (t) ∙ σ0 (uil)(t)) wj) ≈ X Wj) (d(l) ∙ σ0(u(l))) (t) = - X wj)e(l),
i=1	i=1	i=1
(20)
Here we omit the temporal dependency (*e) for simplicity. Since BP is not our contribution, we
discuss different omitting methods of all previous works and the detailed derivatives including the
full dependency in the appendix. With d(jl-1)(t) calculated, an hidden layer follows the same rule to
propagate from d(jl-1) to (∂L∕∂wj(lm-1)) as the output layer.
4.2	Comparing BP with our framework
We analyses our bio-plausible learning rule from the optimization point of view.
7
Under review as a conference paper at ICLR 2022
-2.0-1.5-1.0-0.5 0.0 0.5 1.0
(a) Comparison of σ,(u) & B(u)
0.012
0.010
0.008
0.006
0.004
0.002
0.000
Time/ms
0 100 200 300 400 500 600
(b) Comparison of KBP & the positive side of KSTDP
Figure 2: (a) σ0 (u) = 1/(1 + |u - 1|)2) is defined following Zenke & Ganguli (2018), and the
parameters of B(U) used here are: uo = Id = 1, gmax = 109.45, k = 1.18 and n = 124.33. (b)
KBP = e * e, with Ts = 30 ms. The positive side of KSTDP = A+exp(-t∕τ+)H(t) has parameters:
A+ = 0.0124, and τ+ = 89.73 ms.
In the output layer, the error signal in (10) corresponds to -di(lN)σ0(ui(lN)) , which is the postsy-
naptic part in (19). The term -di(lN) corresponds to [aitarget(t) - ai(lN) (t)] in (10), which implies
that the equivalent loss function we apply for the bio-plausible rule is also the van Rossum distance.
For other loss functions, one can safely substitute [aitarget(t) - ai(lN) (t)] with their own (-di(lN)).
The auxiliary σ0(ui(lN)) function corresponds to the voltage dependent gating function Bi(lN). One
may find that with proper parametrization they can almost overlap as shown in Figure 2 (a). Both of
them reshapes the error signal depending on the neuron’s membrane potential, where the gradients
farther from the threshold are weakened.
With error signals clearly defined, we find both the BP-based learning rule (19) and the previously
described bio-plausible STDP-based learning rule (15) follow a surprisingly similar form:
δWij H J(SPre * K) ∙ epost∙	QI)
As shown in Figure 2 (b), the shape of BP’s kernel function KBP is highly similar to the positive side
of the STDP kernel KSTDP, where the value peaks near zero, and decays gradually. Such equivalence
gives theoretical analysis of what should the kernel looks like from the optimization point of view
and provides possibly explanations of why the negative side of STDP learning rule usually dampen
the performance, and usually been omitted in previous works to boost the performance (Ponulak &
Kasinski, 2010). In the experiment part, We also ignored the negative side of STDP kernel.
When further propagating the gradient to previous layers, the more complex predictive-coding-
inspired architectures are involved. As in Sacramento et al. (2018), we also name the ideal state
where wi(jl) = wi(l)j = wj(li) = wj(li) as self-predicting (self-predicting is needed theoretically, but
not experimentally as shown in the next section). Under which, the summed error signal on the
apical dendrites of a pyramidal cell in (9) are simplified to:
N(l)	N(l)
e(jl-1)(t)=Bj(l-1)(t)Xwi(jl)(ai(l)(t)+ei(l)(t))-wi(jl)ai(l)(t) =Bj(l-1)(t)Xwi(jl)ei(l)(t).
i=1	i=1
(22)
Comparing to (20), which propagates the negative weighted sum of ei(l) to dj(l-1), and further cal-
culate e(jl-1) = -d(jl-1)σ0(u(jl) ), our rule yields more symmetry, where the error signals e flow
through layers without any intermediate variables. These two rules are equivalent when pairing
B(u) to σ0 (u) as in Figure 2 (a).
We conclude their similarity and difference as following: 1) Both of the learning rules share a same
form: ∆wij H R(SPre * K) ∙ epost. 2) The surrogate derivatives σ0(u(I)) in BP is correspondingly
achieved by Bi(l) of the E-type synapses in our framework. 3) The shape of BP’s kernel function
KBP is similar to the positive side of KSTDP. 4) For both rules, the error backpropagation between
two layers are equivalent when our network in its self-predicting state. And the one difference these
two methods have is: The kernel function KBP only has the positive side (t > 0), but KSTDP has
double sides.
8
Under review as a conference paper at ICLR 2022
(a) 2-layers fully-connected (FC) net:
a universal spike train approximator
(b) Before training
(C) After training
Figure 3: Universal spike train approximator experiment
5	Experimental Results
5.1	Universal Spike Train Approximator
To test the learning ability of our proposed bio-plausible learning rules, we build up a 2-layers SNN
to fit a random target spike train (PSC) from randomly generated inputs as shown in Figure 3 (a).
One SOM cell paired with the output pyramidal cell helps it propagate error backwards and update
the input weights. More detail settings can be found in the appendix. In Figure 3 (b) and (c), the
upper two sub-figures exploit that both the output ai and the predict output aip are able to fit our
randomly assigned sinusoidal target PSC aitarget . The lower two sub-figures shows the difference
between paired weights, where the two backward weights w(li) ≈ w(li) after training, yet the other
pe	e
pair remains different. Such difference would not hinder the training because the success of error
backpropagation only requires ai ≈ aip .
5.2	The Results on the MNIST Dataset and the CIFAR-10 Dataset
The proposed framework is compared with other BP-based rules on two widely used real-world
datasets: MNIST (LeCun, 1998) and CIFAR-10 (Krizhevsky et al., 2009). Previous works usually
use the fixed-step first-order forward Euler method to discretize continuous membrane voltage up-
dates over a set of discrete time steps, we also following this setting and take several measures to
guarantee a fair comparison: 1) Mirroring B (U) with “ to get B (u)'s value when u > 优 2) Setting
κSTDP [t] = 1 when t = 0, and κSTDP [t] = 0 when t 6= 0. 3) All the comparisons are made under
a SNN’s self-predicting state. The results are concluded in table 1. Our method gains comparable
performance as compared to BP-based works.
Table 1: Performances comparison of different methods on the MNIST and CIFAR10 datasets
	MNIST		CIFAR10	
Method	#StePS	BestAcc	#Steps	BestAcc
SLAYER (Shrestha & Orchard, 2018)	300	99.41%	null	nun
TSSL-BP (Zhang & Li, 2020)	5	99.53%	5	89.22%
NA (Yang et al., 2021)	5	99.69%	5	91.76%
This work	5	99.46%	5	86.88%
MNIST SNN structure: 15C5-P2-40C5-P2-300
CIFAR10 SNN structure: 96C3-256C3-P2-384C3-P2-384C3-256C3-1024-1024
6	Conclusion
We proposed a new bio-plausible learning framework, BioLeaF, consisting of two key components:
an architecture, and its paired learning rules. BioLeaF leverages previous bio-plausible works’ lim-
itation, and bridges the gap between the bio-plausible approach and the BP-based approach both
analytically and experimentally. The equivalence of these two approaches are demonstrated under a
special setting, and the comparable experimental performance of them are benchmarked on MNIST
and CIFAR10 datasets. This work may provide new insights on both approaches.
9
Under review as a conference paper at ICLR 2022
References
Andre M Bastos, W Martin Usrey, Rick A Adams, George R Mangun, Pascal Fries, and Karl J
Friston. Canonical microcircuits for predictive coding. Neuron, 76(4):695-711, 2012.
Yoshua Bengio and Yann LeCun. Scaling learning algorithms towards AI. In Large Scale Kernel
Machines. MIT Press, 2007.
Mike Davies, Narayan Srinivasa, Tsung-Han Lin, Gautham Chinya, Yongqiang Cao, Sri Harsha
Choday, Georgios Dimou, Prasad Joshi, Nabil Imam, Shweta Jain, et al. Loihi: A neuromorphic
manycore processor with on-chip learning. Ieee Micro, 38(1):82-99, 2018.
Mike Davies, Andreas Wild, Garrick Orchard, Yulia Sandamirskaya, Gabriel A Fonseca Guerra,
Prasad Joshi, Philipp Plank, and Sumedh R Risbud. Advancing neuromorphic computing with
loihi: A survey of results and outlook. Proceedings ofthe IEEE,109(5):911-934, 2021.
Sophie Deneve, Alireza Alemi, and Ralph Bourdoukan. The brain as an efficient and robust adaptive
learner. Neuron, 94(5):969-977, 2017.
Alain Destexhe, Zachary F Mainen, Terrence J Sejnowski, et al. Kinetic models of synaptic trans-
mission. Methods in neuronal modeling, 2:1-25, 1998.
Peter U Diehl and Matthew Cook. Unsupervised learning of digit recognition using spike-timing-
dependent plasticity. Frontiers in computational neuroscience, 9:99, 2015.
Guy Eyal, Matthijs B Verhoog, Guilherme Testa-Silva, Yair Deitcher, Ruth Benavides-Piccione,
Javier DeFelipe, Christiaan PJ De Kock, Huibert D Mansvelder, and Idan Segev. Human cortical
pyramidal neurons: from spines to spikes via models. Frontiers in cellular neuroscience, 12:181,
2018.
Paul Ferre, Franck Mamalet, and Simon J Thorpe. Unsupervised feature learning with winner-takes-
all based stdp. Frontiers in computational neuroscience, 12:24, 2018.
Karl Friston. The free-energy principle: a unified brain theory? Nature reviews neuroscience, 11
(2):127-138,2010.
Wulfram Gerstner and Werner M Kistler. Spiking neuron models: Single neurons, populations,
plasticity. Cambridge university press, 2002.
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning, volume 1.
MIT Press, 2016.
Yunzhe Hao, Xuhui Huang, Meng Dong, and Bo Xu. A biologically plausible supervised learning
method for spiking neural networks using the symmetric stdp rule. Neural Networks, 121:387-
395, 2020.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing
human-level performance on imagenet classification. In Proceedings of the IEEE international
conference on computer vision, pp. 1026-1034, 2015.
Donald Olding Hebb. The organization of behavior: A neuropsychological theory. Psychology
Press, 1949.
Geoffrey E. Hinton, Simon Osindero, and Yee Whye Teh. A fast learning algorithm for deep belief
nets. Neural Computation, 18:1527-1554, 2006.
Bernd Illing, Wulfram Gerstner, and Johanni Brea. Biologically plausible deep learning—but how
far can We go with shallow networks? Neural Networks, 118:90-101, 2019.
Saeed Reza Kheradpisheh, Mohammad Ganjtabesh, Simon J Thorpe, and TimOthee Masquelier.
Stdp-based spiking deep convolutional neural networks for object recognition. Neural Networks,
99:56-67, 2018.
Jinseok Kim, Kyungsu Kim, and Jae-Joon Kim. Unifying activation-and timing-based learning rules
for spiking neural networks. Advances in Neural Information Processing Systems, 2020a.
10
Under review as a conference paper at ICLR 2022
Seijoon Kim, Seongsik Park, Byunggook Na, and Sungroh Yoon. Spiking-yolo: Spiking neural
network for energy-efficient object detection. In Proceedings of the AAAI Conference on Artificial
Intelligence, volume 34, pp. 11270-11277, 2020b.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009.
Matthew Larkum. A cellular mechanism for cortical associations: an organizing principle for the
cerebral cortex. Trends in neurosciences, 36(3):141-151, 2013.
Yann LeCun. The mnist database of handwritten digits. http://yann. lecun. com/exdb/mnist/, 1998.
Chankyu Lee, Priyadarshini Panda, Gopalakrishnan Srinivasan, and Kaushik Roy. Training deep
spiking convolutional neural networks with stdp-based unsupervised pre-training followed by su-
pervised fine-tuning. Frontiers in neuroscience, 12:435, 2018.
Marcus Leinweber, Daniel R Ward, Jan M Sobczak, Alexander Attinger, and Georg B Keller. A
sensorimotor circuit in mouse cortex for visual flow predictions. Neuron, 95(6):1420-1432, 2017.
WB Levy and O Steward. Temporal contiguity requirements for long-term associative potentia-
tion/depression in the hippocampus. Neuroscience, 8(4):791-797, 1983.
Jesus L Lobo, Javier Del Ser, Albert Bifet, and Nikola Kasabov. Spiking neural networks and online
learning: An overview and perspectives. Neural Networks, 121:88-100, 2020.
Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint
arXiv:1711.05101, 2017.
Ammar Mohemmed, Stefan Schliebs, Satoshi Matsuda, and Nikola Kasabov. Span: Spike pattern
association neuron for learning spatio-temporal spike patterns. International journal of neural
systems, 22(04):1250012, 2012.
Martin M Monti and Daniel N Osherson. Logic, language and the brain. Brain research, 1428:
33-42, 2012.
Bernhard Nessler, Michael Pfeiffer, Lars Buesing, and Wolfgang Maass. Bayesian computation
emerges in generic cortical microcircuits through spike-timing-dependent plasticity. PLoS com-
putational biology, 9(4):e1003037, 2013.
Priyadarshini Panda and Kaushik Roy. Unsupervised regenerative learning of hierarchical features
in spiking deep networks for object recognition. In 2016 International Joint Conference on Neural
Networks (IJCNN), pp. 299-306. IEEE, 2016.
German I Parisi, Ronald Kemker, Jose L Part, Christopher Kanan, and Stefan Wermter. Continual
lifelong learning with neural networks: A review. Neural Networks, 113:54-71, 2019.
Leopoldo Petreanu, Tianyi Mao, Scott M Sternson, and Karel Svoboda. The subcellular organization
of neocortical excitatory connections. Nature, 457(7233):1142-1145, 2009.
FiliP Ponulak and Andrzej Kasinski. Supervised learning in spiking neural networks with resume:
sequence learning, classification, and spike shifting. Neural computation, 22(2):467-510, 2010.
Ximing Qiao, Yukun Yang, and Hai Li. Defending neural backdoors via generative distribution
modeling. Advances in Neural Information Processing Systems, 2019.
Marcus E Raichle, Ann Mary MacLeod, Abraham Z Snyder, William J Powers, Debra A Gusnard,
and Gordon L Shulman. A default mode of brain function. Proceedings of the National Academy
of Sciences, 98(2):676-682, 2001.
Rajesh PN Rao and Dana H Ballard. Predictive coding in the visual cortex: a functional interpreta-
tion of some extra-classical receptive-field effects. Nature neuroscience, 2(1):79-87, 1999.
David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-
propagating errors. nature, 323(6088):533-536, 1986.
11
Under review as a conference paper at ICLR 2022
Joao Sacramento, RUi Ponte Costa, YoshUa Bengio, and Walter Senn. Dendritic cortical microcir-
cuits approximate the backpropagation algorithm. Advances in Neural Information Processing
Systems, 2018.
Daniel J SaUnders, Hava T Siegelmann, Robert Kozma, et al. Stdp learning of image patches with
convolUtional spiking neUral networks. In 2018 international joint conference on neural networks
(IJCNN), pp. 1-7. IEEE, 2018.
JUrgen Schmidhuber. Deep learning in neural networks: An overview. Neural networks, 61:85-117,
2015.
Connor Shorten and Taghi M Khoshgoftaar. A sUrvey on image data aUgmentation for deep learning.
Journal of Big Data, 6(1):1-48, 2019.
SUmit Bam Shrestha and Garrick Orchard. SLAYER: spike layer error reassignment in time. In
Advances in Neural Information Processing Systems, pp. 1419-1428, 2018.
Ioana Sporea and Andre Gruning. Supervised learning in multilayer spiking neural networks. Neural
computation, 25(2):473-509, 2013.
Gabor Stefanics, Jan KremIaCek, and IStvan Czigler. Visual mismatch negativity: a predictive coding
view. Frontiers in human neuroscience, 8:666, 2014.
MM Taylor et al. The problem of stimulus structure in the behavioural theory of perception. South
African Journal of Psychology, 3:23-45, 1973.
Mark CW van Rossum. A novel spike distance. Neural computation, 13(4):751-763, 2001.
John Von Neumann. The computer and the brain. Yale University Press, 2012.
James CR Whittington and Rafal Bogacz. An approximation of the error backpropagation algorithm
in a predictive coding network with local hebbian synaptic plasticity. Neural computation, 29(5):
1229-1262, 2017.
Bernard Widrow and Marcian E Hoff. Adaptive switching circuits. Technical report, Stanford Univ
Ca Stanford Electronics Labs, 1960.
Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, and Luping Shi. Spatio-temporal backpropagation for
training high-performance spiking neural networks. Frontiers in neuroscience, 12:331, 2018.
Yukun Yang, Wenrui Zhang, and Peng Li. Backpropagated neighborhood aggregation for accu-
rate training of spiking neural networks. In International Conference on Machine Learning, pp.
11852-11862. PMLR, 2021.
Friedemann Zenke and Surya Ganguli. Superspike: Supervised learning in multilayer spiking neural
networks. Neural computation, 30(6):1514-1541, 2018.
Wenrui Zhang and Peng Li. Temporal spike sequence learning via backpropagation for deep spiking
neural networks. Advances in Neural Information Processing Systems, 33, 2020.
12