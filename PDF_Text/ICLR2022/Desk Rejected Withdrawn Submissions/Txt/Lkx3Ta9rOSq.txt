Under review as a conference paper at ICLR 2022
A Unified Framework for Multi-distribution
Density Ratio Estimation
Anonymous authors
Paper under double-blind review
Ab stract
Binary density ratio estimation (DRE), the problem of estimating the ratio p1/p2
given their empirical samples, provides the foundation for many state-of-the-art
machine learning algorithms such as contrastive representation learning and co-
variate shift adaptation. In this work, we consider a generalized setting where
given samples from multiple distributions p1, . . . ,pk (for k > 2), we aim to effi-
ciently estimate the density ratios between all pairs of distributions. Such a gen-
eralization leads to important new applications such as estimating statistical dis-
crepancy among multiple random variables like multi-distribution f -divergence
and bias correction via multiple importance sampling. We then develop a general
framework from the perspective of Bregman divergence minimization, where each
strictly convex multivariate function induces a proper loss for multi-distribution
DRE. Moreover, we formally relate multi-distribution density ratio estimation and
class probability estimation, theoretically justifying the use of any strictly proper
scoring rule composite with a link function for multi-distribution DRE. We show
that our framework leads to methods that strictly generalize their counterparts in
binary DRE, as well as new methods that show comparable or superior perfor-
mance on various downstream tasks.
1	Introduction
Estimating the density ratio between two distributions based on their empirical samples is a central
problem in machine learning, which continuously drives progress in this field and finds its appli-
cations in many machine learning tasks such as anomaly detection (Hido et al., 2008; Smola et al.,
2009; Hido et al., 2011), importance weighting in covariate shift adaptation (Huang et al., 2006;
Sugiyama et al., 2007), generative modeling (Uehara et al., 2016; Nowozin et al., 2016; Grover
et al., 2019), two-sample test (Sugiyama et al., 2011; Gretton et al., 2012), mutual information es-
timation and representation learning (Oord et al., 2018; Hjelm et al., 2018). It is such a powerful
paradigm because computing density ratio focuses on extracting and preserving contrastive infor-
mation between two distributions, which is crucial in many tasks.
Despite the tremendous success of binary DRE, in practice, many application scenarios involve more
than two probability distributions and developing density ratio estimation methods among multiple
distributions has the potential of advancing various applications such as estimating multi-distribution
statistical discrepancy measures (Garcia-Garcia & Williamson, 2012), multi-domain transfer learn-
ing, bias correction and variance reduction with multiple importance sampling (Elvira et al., 2019),
multi-marginal generative modeling (Cao et al., 2019) and multilingual machine translation (Dong
et al., 2015; Aharoni et al., 2019).
Although recent years have witnessed significant progress and a continuously increasing trend in
developing more sophisticated and advanced methods for binary DRE (Sugiyama et al., 2012; Liu
et al., 2017; Rhodes et al., 2020; Kato & Teshima, 2021; Choi et al., 2021), methods for estimat-
ing density ratios among multiple distributions remain largely unexplored, besides an empirical
exploration of multi-class logistic regression for multi-task learning (Bickel et al., 2008), where the
density ratios serve as the resampling weights between the distribution of a pool of examples of
multiple tasks and the target distribution for a given task at hand and lead to significant accuracy
improvement on HIV therapy screening experiments.
1
Under review as a conference paper at ICLR 2022
In this work, we propose a unified framework based on expected Bregman divergence minimization,
where any strictly convex multivariate function induces a proper loss for multi-distribution DRE,
thus generalizing the framework in (Sugiyama et al., 2012) to multi-distribution case. Moreover,
based on a new multivariate Bregman identity, we formally relate losses for multi-distribution den-
sity ratio estimation and class probability estimation, theoretically justifying the use of any strictly
proper scoring rule (e.g., the logarithm score (Good, 1952), the Brier score (Brier et al., 1950) and
the pseudo-spherical score (Good, 1971)) composite with a link function for multi-distribution DRE.
By choosing a variety of specific convex functions or proper scoring rules, we show that our unified
framework leads to methods that strictly generalize their counterparts for binary DRE, as well as
new objectives specific to multi-distribution DRE. We demonstrate the effectiveness of our frame-
work, and study and compare the empirical performance of its different instantiations on various
downstream tasks that rely on accurate multi-distribution density ratio estimation.
2	Preliminaries
2.1	Multi-class Experiments
In multi-class experiments, we have a pair of random variables (X, Y ) ∈ X × Y with joint distri-
bution D(X, Y ), where X is the sample space and Y = [k] := {1, . . . , k} is the finite label space.
Define the probability simplex as ∆k := {p ∈ R≥0∣1>p = 1}. According to chain rule of Proba-
bility, any joint distribution D(X, Y ) can be decomposed into class priors πi := P(Y = i) and class
conditionals Pi(x) := P(X = x|Y = i) for i ∈ [k], or into sample marginal M(x) := P(X = x)
and class probability function η : X → ∆k (i.e., ηi(x) = P(Y = i|X = x)). We write η(x) as a
vector η and omit x when it is clear from context. Thus we can also represent the joint distribution
as D = (π, P1, . . . , Pk) (where π ∈ ∆k) or (M, η). For any i ∈ [k], we assume Pi has density pi
with respect to the Lebesgue measure.
Remark on notations. To avoid confusion, we would like to emphasize that the class probability
is denoted as ηi(x) = P(Y = i|X = x) and the class conditional is denoted as Pi(x) = P(X =
x|Y = i) with density pi (x). The former further satisfies the normalization constraint: ∀x ∈
X, Pik=1 ηi(x) = 1, while i in the latter one only serves as the index for k different distributions.
In multi-class classification, given independent and identically distributed (i.i.d.) samples from the
joint distribution D(X, Y), We want to learn a probabilistic classifier r^ : X → ∆k to approximate
the true class probability function η by minimizing the following `-risk:
LcpeO^;D) = Ep(x,y)['(y, η(x))] = Ex 〜M [Ey 〜n(x)['(y, η(x))]] = Ex 〜M [L(η(x), η(x))] (1)
where ' : [k] X ∆k → R is the loss function for using the class predictor τ^(χ) when the true class
is y, and L : ∆k × ∆k → R is the expected loss of τ^(χ) under the true class probability η(χ).
Definition 1 (proper loss). A loss function ` is proper if the corresponding expected loss satisfies:
∀P, Q ∈ ∆k, L(P, Q) ≥ L(P, P). It is strictly proper if the equality holds only when P = Q.
In statistical decision theory (Gneiting & Raftery, 2007), the negative proper loss is also called
proper scoring rule (i.e., S(y, τ^(x)) = -'(y, τ^(x))), which assesses the utility of the prediction.
properness of a loss is desirable in multi-class classification because it encourages the class proba-
bility estimator r^ to match the true class probability function η. An important property of proper
loss is summarized in the following theorem:
Definition 2 (Bregman divergence). Given a differentiable convex function φ : S → R defined on a
convex set S ⊂ Rd and two points x, y ∈ S, the Bregman divergence from x to y is defined as:
Bφ(χ, y) := Φ(χ) - φ(y) - hχ — y, Vφ(y)i	(2)
Theorem 1 ((Gneiting & Raftery, 2007); proposition 7 in (Vernet et al., 2011)). Given a proper
loss ` and the corresponding expected loss L, for any P, Q ∈ ∆k, the generalized entropy function
L(P) := infQ∈∆k L(P)Q) = L(P,P) is concave; when L is differentiable, the regret or excess
risk of a predictor Q over the Bayes-optimal P is the Bregman divergence induced by the convex
function f = -L:
reg(P, Q； '):= L(P, Q)- L(P, P) = Bf (P, Q)	(3)
2
Under review as a conference paper at ICLR 2022
Given the Bregman divergence representation of the point-wise regret in Theorem 1 and the `-risk
in Equation (1), the excess risk of a class probability estimator r^ over the Bayes optimal η is:
reg(η; M, η,') ：=LCPE(n； D)-LCPE(η; D) = EM(χ)[L(η(x), η(x)) - L(η(x), η(x))]
=EM(χ)[Bf (η(x), η(x))]	()
2.2	MULTI-DISTRIBUTION f-DIVERGENCE
Csiszar,s f -divergence is a popular way to measure the discrepancy between two probability distri-
butions. Specifically, given two distributions P, Q and a convex function f : R+ → R ∪ {±∞}
satisfying f(1) = 0, the f-divergence between P and Q is defined as Df (P ||Q) = EQ[f(dP/dQ)].
In the following, we will introduce the multi-distribution extension of f -divergence (Garcia-Garcia
& Williamson, 2012).
Definition 3 (Multi-distribution f -divergence). For k probability distributions P1, . . . , Pk on a com-
mon probability space (X, σ(X)) with densities p1, . . . ,pk, given multi-variate closed convex func-
tion f : Rk+-1 → R ∪ {±∞} satisfying f(1) = 0, the multi-distribution f -divergence between
P1, . . . , Pk-1 and Pk is defined as:
Df(P1,...,Pk-1||Pk) =Epk(x)
f PPI(X)	Pk-I(X)
P (Pk(x),..∙, Pk(x)
(5)
2.3	Connecting Density Ratios and Class Probabilities via Link Function
Inspired by the definition in Eq. (5), we consider the following canonical density ratio vector
(more discussion about this choice can be found in Section 3.2): r(X) = (r1(X), . . . , rk (X))
where ri(X) := Pi(X)/Pk(X) and rk (X) = 1. Then we can connect a density ratio vector
r(X) ∈ Rk+-1 × {1} and a class probability vector η(X) ∈ ∆k via an invertible link function.
According to Bayes’ theorem, we have:
P(X = X, Y = i)	πi Pi (X)	M(X)ηi (X)
P(X = X, Y = k)	πkPk(X)	M(X)ηk (X)
Pi (X)	πk	ηi (X)
⇔ ri(X) =而=∏- ∙诉.⑹
Thus we define the following multi-distribution link function Ψdr : ∆k → Rk+-1 × {1} as a natural
generalization of the binary DRE link function (Menon & Ong, 2016; Vernet et al., 2011):
[ψdr(η)]i :=」∙ — = ri, for all i ∈ [k].	⑺
πi ηk
Given Eq. (7) and the normalization constraint Pi∈[k] ηi = 1, we obtain the inverse link function:
[Ψ-r1 (r)]i := L πiri——=ηi, for all i ∈ [k].	(8)
dr	j∈[k] πjrj
Thus given knowledge of the prior distribution π (which can also be easily estimated from empirical
samples), one can transform a class probability estimator into a density ratio estimator via r =
Ψdr(η) and vice versa via η = Ψ-1(r).
3	A Unified Framework for Multi-distribution DRE
3.1	Multi-distribution Density Ratio Estimation Problem Setup
Following the basic formulation of multi-class experiments in Section 2.1, we now introduce the
problem setup of multi-distribution density ratio estimation (DRE). Recall that X is the common data
domain and P1, . . . , Pk are k different distributions defined on X with densities P1, . . . ,Pk. Suppose
we are given ni i.i.d. samples {X(ji)}jn=i 1 from each distribution Pi. The goal of multi-distribution
DRE is to estimate the density ratios between all pairs of distributions {rij := Pi/Pj }i,j∈[k] from
the i.i.d. datasets {{Xj(i)}jn=i 1}ik=1. In this paper, we assume that the density ratios are always well-
defined on domain X (e.g., when the distributions have strictly positive densities), which is also a
common assumption in binary DRE problem (Kanamori et al., 2009; Kato & Teshima, 2021).
3
Under review as a conference paper at ICLR 2022
A naive approach towards this problem is to separately estimate each density pi from {x(ji) }jn=i 1
and then plug in pi and pj to get rij . However, as previous theoretical works (Kpotufe, 2017;
Nguyen et al., 2007; Kanamori et al., 2012; Que & Belkin, 2013) suggest, directly estimating density
ratios has many advantages in practical settings. Specifically, we know that (1) optimal convergence
rates depend only on the smoothness of the density ratio and not on the densities; (2) optimal rates
depend only on the intrinsic dimension of data, thus escaping the curse of dimension in density
estimation. Inspired by these observations in binary DRE, this paper aims to develop a general
framework for directly estimating multi-distribution density ratios. Moreover, we also theoretically
prove that various interesting facts (Menon & Ong, 2016; Sugiyama et al., 2012), which hold in the
binary case, extend to our multi-distribution case in Section 4.
While most previous works focus on DRE in binary cases, multi-distribution DRE has many impor-
tant downstream applications. For example, given any integrable function φ : X → R, suppose we
want to use importance sampling to estimate the expectation of φ with respect to a target distribution
Q with density q w.r.t. the base measure:
q(x)
Eq(x)[φ(x)] = J q(x)φ(x)dx = J P(X)p(χ)φ(x)dx = Ep(X) [r(x) ∙ φ(x)]
(9)
where we use the density ratio r = p/q to correct the bias caused by using samples from the proposal
distribution p rather than the target distribution q. However, in practice, finding a good proposal is
critical yet challenging (Owen & Zhou, 2000). An alternative and more robust strategy is to use a
population of different proposals (sampling schemes) and use a set of density ratios to correct the
bias, which is also known as multiple importance sampling (MIS) (CaPPe et al., 2004; Elvira et al.,
2015). Given k different proposals p1, . . . ,pk, the MIS estimation of the expectation is given by:
k
Eq(x) [φ(x)] =	ωiEpi(x)
i=1
黑 φ(χ)
(10)
where ωi is the weight for each proposal pi and satisfies i ωi = 1. Thus a more efficient and
accurate multi-distribution DRE method will lead to better MIS. In the context of multi-source off-
policy policy evaluation (Kallus et al., 2021), the proposals correspond to a set of demonstration
policies and the target distribution is the query policy whose performance we want to evaluate from
the offline multi-souce demonstrations; in the context of multi-domain transfer learning setting (co-
variate shift adaptation) (Bickel et al., 2008; Dinh et al., 2013), the proposals correspond to a set
of data generating distributions (e.g. multiple source domains or various data augmentation strate-
gies) and the target is the test distribution we care about. Estimating multi-distribution density ratios
also allows us to compute important information quantities among multiple random variables such
as the multi-distribution f -divergence in Equation (5), which can be used to analyze various kinds
of discrepancy and correlations between multiple random variables and further has the potential of
inspiring new generative models for multiple marginal matching problem (Cao et al., 2019).
3.2	Multi-distribution DRE via Bregman Divergence Minimization
Inspired by the success of Bregman divergence minimization for unifying various DRE methods in
the binary case (Sugiyama et al., 2012), in this section, we propose a general framework for solving
the multi-distribution density ratio estimation problem. First, we discuss our modeling choices.
Although our goal is to estimate k2 density ratios (between all possible pairs), the solution set
{∣ij := Pi/pj}i,j∈[k] actually has k - 1 degrees of freedom (e.g., ∣ik = rj ∙ rjk). Thus without
loss of generality, we parametrize the following k - 1 density ratio models rrθ = (rrθ1,. . . , rrθk-1) to
approximate the true canonical density ratios r = (r1, . . . , rk-1), where ri := Pi/Pk for i ∈ [k - 1].
For the simplicity of notation, we will omit the dependence on the parameters θ and write our
density ratio models as rr = (rr1, . . . , rrk-1). An advantage of such modeling choice is that any
density ratio can be recovered within one step of computation P = ρ7pk
ri, thus avoiding
rj
large compounding error while naturally ensuring consistency within the solution set (i.e., if we
parametrize *j, rjk and *k respectively, We have to make sure they satisfy *k = Irij ∙ j).
Since our goal is to optimize r to approximate the true density ratios r, we consider to use Bregman
divergence (Def. 2) to measure the discrepancy between r and rr. Specifically, for any strictly convex
4
Under review as a conference paper at ICLR 2022
function f : Rk+-1 → R and ∀x ∈ X, we have the following point-wise optimization problem:
min	Bf(r(x),	r(x)) =	f(r(x))	—	f (r(x))	— hVf (r(x)),	r(x)	—	r(x)i	(11)
r(χ)∈R+-1
which corresponds to the difference between the value of f at r, and the value of the first-order
Taylor expansion of f around point r evaluated at point r. Although the current formulation can be
understood as a regression problem from r(x) to the true density ratios r(x), we actually only have
i.i.d. samples X 〜pι,...,Pk instead of the true targets r(χ). In this case, We consider to use the
following expected Bregman divergence to measure the overall discrepancy from the true density
ratios r to the density ratio models r:
Ldre(r； D) =/ Pk(x)(f(r(x)) — f(r(x)) — {Vf(r(x)), r(x) — r(x)))dx
=Epk(X) [hVf (r(x)), r(x)i — f (r(x))] — X Epi(X) [&f (r(x))] + C
i∈[k-1]
(12)
(13)
where C := JXPk(x)f (r(x))dx = Df(P1,..., Pk-IkPk) is a constant with respect to r and the
equality comes from the fact that Pk ∙ (ri,..., rk-ι) = (pi,... ,Pk-ι) according to the definition
of r. The rationale behind the above choice is that it allows us to get an unbiased estimation of the
discrepancy between r and r only using i.i.d. samples from pi,... ,Pk. Specifically, since C is a
constant, we have the following optimization problem over r to approximate the true density ratios
(where each expectation Epi can be empirically estimated using samples from Pi):
min	Epk(X) [hVf (r(x)), r(x)i — f (r(x))] — X Epi(X) [∂iJ(r(x))]	(14)
*x→r+	i∈[k-1]
Interestingly, the above multi-distribution DRE formulation, which is based on Bregman divergence
minimization, can be alternatively derived from the perspective of variational estimation of multi-
distribution f -divergence. In the following, We briefly discuss such an interpretation of Eq. (14).
Based on Fenchel duality, we can represent any strictly convex function f : Rk+-i → R ∪ {+∞}
through its conjugate function f *(s) := maXr∈Rk-ι(s, r) — f (r) as:
f(r(x)) =	max (r(x), s(x)) — f *(s(x)), for any X ∈ X.	(15)
s:X →Rk-1
In order to estimate the multi-distribution f -divergence defined in Eq. (5) only using samples from
Pi , . . . , Pk (instead of their density information), we consider the following variational representa-
tion of multi-distribution f -divergence by substituting Eq. (15) into Eq. (5):
Df(Pι,...,Pk-i∣∣Pk) = — min ι — V Epi(X)[s(x)]i + Epk(X)f*(s(x))	(16)
s:X →Rk-1
i∈[k-i]
We then have the following lemma revealing the equivalence between the optimization problem in
Eq. (14) and Eq. (16).
Proposition 1 (DRE via variational estimation of multi-distribution f -divergence). Given a strictly
convex function f : Rk+-i → R ∪ {+∞}, the optimization problem in Eq. (14) (induced by
minimizing expected Bregman divergence Bf (r, r)) is equivalent to the one in Eq. (16) (for
variational estimation of multi-distribution f -divergence) under change of variables satisfying:
Vf (r(x)) = s(x), ∀x ∈ X.
4 Connecting Losses for Multi-class Classification and DRE
Inspired by the link and inverse link function connecting density ratio estimators and class proba-
bility estimators introduced in Section 2.3, there has been existing theoretical works that established
the connections between the losses of binary classification and binary DRE (Menon & Ong, 2016).
However, despite the empirical exploration in (Bickel et al., 2008), the relationship between losses
of multi-class classification and multi-distribution DRE has not been theoretically understood.
5
Under review as a conference paper at ICLR 2022
In Section 2.1, we have shown that the exact minimization of the excess risk for any strictly proper
loss ` results in the true class probability function η, and consequently gives us the true density ratio
r through the link function Ψdr (η). In the following, we take a further step to show that essen-
tially the procedure of minimizing any strictly proper loss is equivalent to minimizing an expected
Bregman divergence between the true density ratios r and the approximate density ratios r, thus
generalizing the theoretical results in binary case (Menon & Ong, 2016) to the multi-distribution
case and justifying the validity of using any strictly proper scoring rule (e.g. Brier score (Brier et al.,
1950) and pseudo-spherical score (Good, 1971)) for multi-distribution DRE. All proofs for this sec-
tion can be found in Appendix A.3. We start by introducing a new multivariate Bregman identity
that may be of independent interest.
Lemma 1 (Multivariate Bregman Identity). Given a convex function f : Rk-1 → R, we can define
an associatedfunction f ~(uι,..., uk-ι) = (1 + Pi∈[k-i] ui)f ("P ；~~— ∙ u^. We can show
that (i) f~ is convex and (ii) for any u, v ∈ Rk-1, their associated Bregman divergences satisfy:
1	1	1	1 _	1
f V + Pi∈[k-1] Ui ∙	, 1 + Pi∈[k-i]Vi ∙ ) = 1 + Pi∈[k-1] Ui
(17)
Bf~ (u, v).
One can then apply Lemma 1 with Ui = ∏∏i r and Vi = ∏∏i ^ for each i ∈ [k -1] and use the fact that
Bf~ (r, r) = Bf~ (u, V) for f~(r) = f ~(∏^∏ ◦ r) to establish the following connection between
the optimality gap of density ratio estimators and class probability estimators, where we use a ◦ b to
denote the element-wise product between vectors a and b, and ∏[±k-i] ∈ Rk-I as the vector when
restricting π onto its first k - 1 coordinates.
Proposition 2. For any convex function f : Rk+-1 → R, and two density ratio vectors r(x) and
r(x), one can construct corresponding class probability vectors η(x) = Ψ-1(r(x)) and τj(x)=
Ψ-r1(r(x)) through the inverse link function in Eq. (8), and obtain:
Bf(T(X), η(X))
	——πk--------- B ~ (r(x), r(x)) for all X ∈ X
πk+------------------i∈[k-1]πiri(X)	fπ
(18)
where we define the convex function fπ~ induced by some prior distribution π ∈ ∆k as
f~(rι,...,rk-ι) := I 1 + E πir√πk I ∙ f
i∈[k-1]
n[i:k-i] ◦ r
πk + Pi∈[k-1] πiri
(19)
Combining Proposition 2 with the Bregman divergence representation of the point-wise regret for
a proper risk ` for multi-class classification in Eq. (4), we provide the following main theorem
that interprets the minimization of multi-class classification regret as multi-distribution DRE under
expected Bregman divergence minimization.
Theorem 2. Given any strictly proper loss `, for any joint data distribution D(X, Y ) with class
prior π ∈ ∆k, the multi-class classification regret defined in Eq. (4) satisfies that:
reg(T; M, η,') = ∏kEpk(χ)Bf∏~ (r(x), r(x)),	(20)
for f~ as defined in Eq. (19), and r = Ψ-r(η) and r = Ψ-r(T) as defined in Eq.⑺.
Theorem 2 generalizes a known equivalence between density ratio estimation and class probability
estimation in the binary case (see Section 5 in (Menon & Ong, 2016)), and serves as a theoretical
justification for a new equivalence in the more complicated multi-class experiments. Besides, in
comparison to the binary case result, we also provide a simpler proof, loosen the assumptions on
the twice-differentiability of convex function f induced by the proper loss ' (i.e., f = -L, see
Theorem 1 for more details), and generalize the argument to an arbitrary prior distribution π ∈ ∆k
instead of the uniform prior case π1 = π2 = 1/2 considered in (Menon & Ong, 2016).
Moreover, we notice that multi-distribution f -divergence among class conditionals P1, . . . , Pk also
corresponds to the statistical information measure in multi-class experiments (DeGroot, 1962) (de-
fined as the gap between the prior and posterior generalized entropy). Since we have established the
equivalence between multi-class DRE (Eq. (14)) and variational estimation of multi-distribution f-
divergence (Eq. (16)), we can show by choosing particular convex functions (associated with the loss
` for multi-class classification), multi-distribution DRE can be viewed as estimating the statistical
information measure in multi-class experiments. See detailed discussions in Appendix A.3.1.
6
Under review as a conference paper at ICLR 2022
5 Examples of Multi-distribution DRE
In the binary density ratio matching under Bregman divergence framework (Sugiyama et al., 2012),
we can choose various convex functions to recover popular binary DRE methods such as KLIEP
(Sugiyama et al., 2008), LSIF (Kanamori et al., 2009) and Logistic Regression (Franklin, 2005). In
this section, we provide some instantiations of our multi-distribution DRE framework. Specifically,
Section 3.2 suggests that any strictly convex multivariate function f : Rk+-1 → R induces a proper
loss for multi-distribution DRE, and Section 4 justifies that any strictly proper scoring rule composite
with Ψdr can also be used for multi-distribution DRE. We briefly discuss some choices of the convex
function or proper scoring rule, and we provide detailed derivations in Appendix A.4.
5.1	Methods Induced by Convex Functions
Multi-class Logistic Regression. From Section 2.3, we know that there is a one-to-one corre-
SPondence between a class probability estimator and a density ratio estimator: r = Ψdr ◦ r^
and η^ = Ψ-r1 ◦ r. For the clarity of presentation, here We assume the class prior distribu-
tion π is uniform such that %(x) = ηi(x)∕ηk(x) and η(x) = Iri(x)/ P：=i rj(x). To re-
cover the loss of multi-class logistic regression, we choose the following convex function to be
f (ri,..., rk-ι) = k Pk=ι ri log (*/ Pk=I ∣j). In this case, the loss in Eq.(14) reduces to:
kEpk(X) log (Xrj(χ)j]-kXEpi(X) log (PJ〔lx)!# = - (kXEpi(X)[logηi(x)]
j=	=	j=	=	(21)
We provide discussions for the general case (non-uniform prior π) in Appendix A.4.1. Interestingly,
we noticed that the above convex function also gives rise to the multi-distribution Jensen-Shannon
divergence (Garcia-Garcia & Williamson, 2012) (also known as the information radius (Sibson,
1969), Df(Pι,...,Pk) = k Pk=IDKL(PiIl 1 Pj=I Pj)) UP to a constant of log k.
Multi-LSIF. When the convex function associated with the Bregman divergence is chosen to be
f (rι,...,rk-ι) = 2 Pk-：(* - 1)2 = 2 Ilr — 1∣2,the loss in Eq. (14) reduces to:
1 k-1	k-1	1 k-1
2 X Epk(X) [r2(x) - 1] - X Epi(X) [ri(x) - 1]= 2 XEpk(X) [C^i(x) - ri(x))2] - C (22)
i=1	i=1	i=1
where C = Epk(X) [∣∣r(x) — 1∣∣2] is a constant w.r.t. r and the minimizer to the above loss func-
tion matches the true density ratios, which strictly generalizes the Least-Squares Importance Fitting
(LSIF) (Kanamori et al., 2009) method to the multi-distribution case.
Besides, we also consider the following simple convex functions that either strictly generalize their
binary DRE counterparts as above, or lead to completely new methods for multi-distribution DRE:
• Multi-KLIEP. f (ri,.. .√^k-ι) = PMII⑴ log*_*)= hr, log(r)i-∣rkι. This strictly
generalizes the Kullback-Leibler Importance Estimation Procedure (KLIEP) (Sugiyama
et al., 2008) to the multi-distribution case. See Appendix A.4.3 for more details.
• Power. f(ri,... ,rk-ι) = Pk-ILra = ∣∣rkS, for α > 1. This strictly generalizes the
robust DRE method in (Sugiyama et al., 2012), which recovers Multi-KLIEP when α → 1
and Multi-LSIF when α = 2. See Appendix A.4.4 for more details.
• Quadratic. f (ri,..., rj-ι) = r>Hr+ q>r, for any positive definite matrix H * 0.
When H is the identity matrix and q = (-2, . . . , -2), this is equivalent to Multi-LSIF.
• LogSumExp. f (rι,...,rk-i) = α log (Pk=IL exp(*∕α)) for α > 0.
In principle, we can use any desired strictly convex function f : Rk+-i → R within the optimization
problem in Eq. (14), implying the great potential of our unified framework for discovering novel
objectives for multi-distribution DRE. In terms of modeling flexibility, the curvature of different
convex functions encode different inductive biases that may favor various downstream applications
and we leave the design of more suitable convex functions for DRE as exciting future avenues.
7
Under review as a conference paper at ICLR 2022
5.2	METHODS INDUCED BY PROPER SCORING RULES COMPOSITE WITH Ψdr
From Section 4, we know that any strictly proper loss ` : [k] × ∆k → R (or strictly proper scoring
rule S(i, τ^) = -'(i, τ^)) in conjunction with the link function Ψdr also induces valid losses for
multi-distribution DRE:
min	Ep(χ,y)['(y, η(x))] = Ex〜M,y〜η(x)['(y, Ψ-1(r(x)))]	(23)
QX→r+-1
In this work, we consider using the following classic proper scoring rules (Gneiting & Raftery,
2007), where r^ is parametrized as Ψ-1(r) (i.e. ^i = ∏i*/ Pj=ι ∏jrj):
•	Logarithm score. (Good, 1952) The loss is specified as '(i, τ^) = - log(ηi), which also
recovers the loss of multi-class logistic regression in Section 5.1.
•	Brier score. (Brier et al., 1950) The loss is specified as '(i, τ^) = —2n + Pj=、n + 1.
• Logarithm pseudo-spherical score. (Good, 1971; Fujisawa & Eguchi, 2008) The loss is
specified as '(i, r^) = — log
ηα-1
(Pk=ι na)(a-i)/a
for α > 1.
6 Experiments
In this section, we verify the validity of our framework, as well as study and compare the various
instantiations introduced in Section 5, on a variety of tasks that all rely on accurate multi-distribution
density ratio estimation. In particular, the tasks we consider include density ratio estimation among
multiple multivariate Gaussian distributions, anomaly detection on CIFAR-10 (Krizhevsky et al.,
2009), multi-target MNIST Generation (LeCun et al., 1998) and multi-distribution off-policy policy
evaluation. We discuss the basic problem setups, evaluation metrics and experimental results in the
following and we provide more experimental details for each task in Appendix A.5.
Synthetic Data Experiments. We first apply our methods to estimate density ratios among k = 5
multivariate Gaussian distributions with different mean vectors and identity covariance matrix. We
conducted experiments for various data dimensions ranging from 2 to 50. Since Gaussian distribu-
tions have tractable densities, we know the ground-truth density ratio functions and we calculate the
mean absolute error (MAE) between all k2 true density ratios and the learned ones:
2
MAEd r; M(X)) = W-IEM(x)
E	Irij(X)- rij(X)I
1≤i<j ≤k
where density ratio between Pi and Pj is recovered by *∕r7∙ as discussed in Section 3.2. We sum-
marize the results in Table 1, from which we can see that multi-class logistic regression and Brier
score composite with Ψdr show superior performance in this task.
OOD Detection on CIFAR-10. Suppose we have k different distributions P1, . . . ,Pk, where Pk =
Pi∈[k-1] αiPi, (Pi∈[k-1] αi = 1 and ∀i, αi > 0). For each distribution Pi (i ≤ k-1), samples from
the mixture distribution Pk contain both inlier samples and outlier samples. The goal of this task is
to identify the inlier samples from the pool of mixture samples. In particular, we use the learned
density ratio * as the score function to retrieve the inlier samples of pi, since the true density ratio
function ri = Pi/ Pj∈[k-1] αjPj tend tobe larger for samples from Pi and smaller for samples from
other distributions. In this case, we calculate the average AUROC for each scoring function.
Multi-target MNIST Generation. DRE can be used in the sampling-importance-resampling (SIR)
paradigm (Liu & Chen, 1998; Doucet et al., 2000). Suppose we want to obtain samples from
P1, . . . , Pk-1 while we have a large set of samples from Pk. For each i ∈ [k - 1], we can use
the density ratio function Iri in conjunction with SIR to approximately sample from the target dis-
tribution Pi (Algorithm 1 in (Grover et al., 2019)). For this task, we evaluate if the SIR samples
for target distribution Pi contains the correct proportion of classes/properties (10 digit numbers in
MNIST) and we use j-ɪ Pk-IL P；=i Ihij 一 hj I as the evaluation metric, where hj and hj denote
the desired proportion and sampled proportion for property j in each target-generation task i.
8
Under review as a conference paper at ICLR 2022
Table 1: Mean absolute error for multi-distribution density ratio estimation among five multivariate
Gaussian distributions. Results are averaged across three random seeds.
Method	Dim = 2	Dim = 5	Dim = 10	Dim = 20	Dim = 30	Dim = 40	Dim = 50
Random Init	1.724 ± 0.03	1.723 ± 0.008	1.728 ± 0.02	1.765 ± 0.017	1.749 ± 0.009	1.753 ± 0.002	1.768 ± 0.008
Multi-LR	0.044 ± 0.003	0.048 ± 0.005	0.061 ± 0.002	0.07 ± 0.001	0.081 ± 0.002	0.089 ± 0.001	0.098 ± 0.002
Multi-KLIEP	0.051 ± 0.002	0.066 ± 0.002	0.074 ± 0.0	0.089 ± 0.002	0.105 ± 0.005	0.112 ± 0.004	0.123 ± 0.003
Multi-LSIF	0.073 ± 0.006	0.097 ± 0.001	0.109 ± 0.005	0.124 ± 0.003	0.144 ± 0.004	0.141 ± 0.005	0.158 ± 0.004
Power	0.054 ± 0.003	0.073 ± 0.001	0.081 ± 0.004	0.104 ± 0.003	0.117 ± 0.003	0.123 ± 0.005	0.135 ± 0.004
Brier	0.042 ± 0.002	0.056 ± 0.003	0.066 ± 0.003	0.081 ± 0.002	0.086 ± 0.002	0.094 ± 0.002	0.105 ± 0.001
Spherical	0.103 ± 0.007	0.106 ± 0.006	0.115 ± 0.004	0.121 ± 0.005	0.125 ± 0.006	0.132 ± 0.003	0.138 ± 0.011
LogSumExp	0.231 ± 0.067	0.198 ± 0.034	0.184 ± 0.013	0.179 ± 0.014	0.184 ± 0.009	0.192 ± 0.01	0.193 ± 0.003
Quadratic	0.148 ± 0.033	0.186 ± 0.028	0.218 ± 0.011	0.219 ± 0.018	0.226 ± 0.018	0.236 ± 0.023	0.254 ± 0.014
Table 2: Results for CIFAR-10 OOD detection, MNIST multi-target generation and multi-
distribution off-policy policy evaluation error based on learned density ratios. ↑ means higher is
better and J means lower is better. Results of top 3 methods for each task are bold. Results are
averaged across three random seeds.
Method	CIFAR-10 OOD (↑)	MNIST Generation Q)	Off-policy Evaluation (J)
Random Init	0.499 ± 0.017	1.598 ± 0.063	1377.68 ± 379.76
Multi-LR	0.854 ± 0.009	0.156 ± 0.014	62.43 ± 12.87
Multi-KLIEP	0.828 ± 0.005	0.281 ± 0.050	110.89 ± 35.33
Multi-LSIF	0.801 ± 0.008	0.274 ± 0.027	71.09 ± 1.12
Power (α = 1.5)	0.816 ± 0.007	0.224 ± 0.036	53.43 ± 20.73
Brier	0.849 ± 0.010	0.107 ± 0.022	71.21 ± 17.34
Spherical (α = 1.8)	0.853 ± 0.010	0.145 ± 0.041	/
LogSumExp (α = 5)	0.782 ± 0.012	/	52.02 ± 9.16
Quadratic	0.804 ± 0.009	/	55.10 ± 11.92
Multi-distribution Off-policy Policy Evaluation. Suppose we have k different reinforcement
learning policies pi(a|s), each inducing an occupancy measure (Syed et al., 2008) (i.e, state-action
distribution) ρi(s, a). Density ratios allow us to conduct off-policy policy evaluation, which esti-
mates the expected return (sum of reward) of target policies p1, . . . , pk-1 given trajectories sampled
from a source policy pk . In this case, we evaluate the following metric to assess the quality of the
learned density ratios (τ = {(st, at)}tT=1 denotes a sequence of state-action pairs):
1 k-1
k-ι X Epk(T)
i=1
T
>Fi(st,at)r(st,at)
t=1
-Epi (τ)
T
r(st, at)
t=1
We summarized the results for CIFAR-10 OOD detection, multi-target MNIST generation and multi-
distribution off-policy policy evaluation in Table 2 (omitted results indicates the corresponding
method performs worse than listed methods by a large margin on the specific task). We can see
that methods induced by proper scoring rules such as multi-class logistic regression, Brier score
and pseudo-spherical score tend to have the best performance on the first two tasks. And surpris-
ingly, methods induced by some simple multivariate convex functions such as the LogSumExp and
the quadratic function show excellent performance on the third task. These results demonstrate
the advantage of our framework in the sense that it offers us extreme flexibility for designing new
objectives for multi-distribution DRE that are more suitable for various downstream applications.
7 Conclusion
In this paper, we focus on the generalized problem of efficiently estimating density ratios among
multiple distributions. We propose a general framework based on expected Bregmand divergence
minimization, where each strictly convex function induces a proper loss for multi-distribution DRE.
Furthermore, we theoretically prove an equivalence between the problem of class probability esti-
mation and density ratio estimation in the context of multi-class experiments, generalizing previous
results in binary case and justifying the use of any strictly proper scoring rules for multi-distribution
DRE. Finally, we demonstrated the value of our framework on various downstream tasks.
9
Under review as a conference paper at ICLR 2022
References
Roee Aharoni, Melvin Johnson, and Orhan Firat. Massively multilingual neural machine translation.
arXiv preprint arXiv:1903.00089, 2019.
Steffen Bickel, Jasmina Bogojeska, Thomas Lengauer, and Tobias Scheffer. Multi-task learning for
hiv therapy screening. In Proceedings of the 25th international conference on Machine learning,
pp. 56-63, 2008.
Glenn W Brier et al. Verification of forecasts expressed in terms of probability. Monthly weather
review, 78(1):1-3, 1950.
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and
Wojciech Zaremba. Openai gym. arXiv preprint arXiv:1606.01540, 2016.
Jiezhang Cao, Langyuan Mo, Yifan Zhang, Kui Jia, Chunhua Shen, and Mingkui Tan. Multi-
marginal wasserstein gan. Advances in Neural Information Processing Systems, 32:1776-1786,
2019.
Olivier Cappe, Arnaud Guillin, Jean-Michel Marin, and Christian P Robert. Population monte carlo.
Journal of Computational and Graphical Statistics, 13(4):907-929, 2004.
Kristy Choi, Madeline Liao, and Stefano Ermon. Featurized density ratio estimation. arXiv preprint
arXiv:2107.02212, 2021.
Morris H DeGroot. Uncertainty, information, and sequential experiments. The Annals of Mathemat-
ical Statistics, 33(2):404-419, 1962.
Cuong V Dinh, Robert PW Duin, Ignacio Piqueras-Salazar, and Marco Loog. Fidos: A generalized
fisher based feature extraction method for domain shift. Pattern Recognition, 46(9):2510-2518,
2013.
Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and Haifeng Wang. Multi-task learning for multiple
language translation. In Proceedings of the 53rd Annual Meeting of the Association for Compu-
tational Linguistics and the 7th International Joint Conference on Natural Language Processing
(Volume 1: Long Papers), pp. 1723-1732, 2015.
Arnaud Doucet, Simon Godsill, and Christophe Andrieu. On sequential monte carlo sampling meth-
ods for bayesian filtering. Statistics and computing, 10(3):197-208, 2000.
John Duchi, Khashayar Khosravi, and Feng Ruan. Multiclass classification, information, divergence
and surrogate risk. The Annals of Statistics, 46(6B):3246-3275, 2018.
Victor Elvira, Luca Martino, David Luengo, and Monica F Bugallo. Efficient multiple importance
sampling estimators. IEEE Signal Processing Letters, 22(10):1757-1761, 2015.
Victor Elvira, Luca Martino, David Luengo, and Monica F Bugallo. Generalized multiple impor-
tance sampling. Statistical Science, 34(1):129-155, 2019.
James Franklin. The elements of statistical learning: data mining, inference and prediction. The
Mathematical Intelligencer, 27(2):83-85, 2005.
Hironori Fujisawa and Shinto Eguchi. Robust parameter estimation with a small bias against heavy
contamination. Journal of Multivariate Analysis, 99(9):2053-2081, 2008.
Dario Garcia-Garcia and Robert C Williamson. Divergences and risks for multiclass experiments. In
Conference on Learning Theory, pp. 28-1. JMLR Workshop and Conference Proceedings, 2012.
Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation.
Journal of the American statistical Association, 102(477):359-378, 2007.
IJ Good. Rational decisions. Journal of the Royal Statistical Society, pp. 107-114, 1952.
IJ Good. Comment on “measuring information and uncertainty” by robert j. buehler. Foundations
of Statistical Inference, pp. 337-339, 1971.
10
Under review as a conference paper at ICLR 2022
Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Scholkopf, and Alexander Smola.
A kernel two-sample test. The Journal ofMachine Learning Research,13(1):723-773, 2012.
Aditya Grover, Jiaming Song, Alekh Agarwal, Kenneth Tran, Ashish Kapoor, Eric Horvitz, and
Stefano Ermon. Bias correction of learned generative models using likelihood-free importance
weighting. arXiv preprint arXiv:1906.09531, 2019.
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft actor-critic: Off-policy
maximum entropy deep reinforcement learning with a stochastic actor. In International confer-
ence on machine learning, pp. 1861-1870. PMLR, 2018.
Shohei Hido, Yuta Tsuboi, Hisashi Kashima, Masashi Sugiyama, and Takafumi Kanamori. Inlier-
based outlier detection via direct density ratio estimation. In 2008 Eighth IEEE international
conference on data mining, pp. 223-232. IEEE, 2008.
Shohei Hido, Yuta Tsuboi, Hisashi Kashima, Masashi Sugiyama, and Takafumi Kanamori. Statis-
tical outlier detection using direct density ratio estimation. Knowledge and information systems,
26(2):309-336, 2011.
R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam
Trischler, and Yoshua Bengio. Learning deep representations by mutual information estimation
and maximization. arXiv preprint arXiv:1808.06670, 2018.
Jiayuan Huang, Arthur Gretton, Karsten Borgwardt, Bernhard Scholkopf, and Alex Smola. Correct-
ing sample selection bias by unlabeled data. Advances in neural information processing systems,
19:601-608, 2006.
Nathan Kallus, Yuta Saito, and Masatoshi Uehara. Optimal off-policy evaluation from multiple
logging policies. In International Conference on Machine Learning, pp. 5247-5256. PMLR,
2021.
Takafumi Kanamori, Shohei Hido, and Masashi Sugiyama. A least-squares approach to direct im-
portance estimation. The Journal of Machine Learning Research, 10:1391-1445, 2009.
Takafumi Kanamori, Taiji Suzuki, and Masashi Sugiyama. Statistical analysis of kernel-based least-
squares density-ratio estimation. Machine Learning, 86(3):335-367, 2012.
Masahiro Kato and Takeshi Teshima. Non-negative bregman divergence minimization for deep
direct density ratio estimation. In International Conference on Machine Learning, pp. 5320-
5333. PMLR, 2021.
Samory Kpotufe. Lipschitz density-ratios, structured data, and data-driven tuning. In Artificial
Intelligence and Statistics, pp. 1320-1328. PMLR, 2017.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009.
Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Jun S Liu and Rong Chen. Sequential monte carlo methods for dynamic systems. Journal of the
American statistical association, 93(443):1032-1044, 1998.
Song Liu, Akiko Takeda, Taiji Suzuki, and Kenji Fukumizu. Trimmed density ratio estimation.
arXiv preprint arXiv:1703.03216, 2017.
Aditya Menon and Cheng Soon Ong. Linking losses for density ratio and class-probability estima-
tion. In International Conference on Machine Learning, pp. 304-313. PMLR, 2016.
XuanLong Nguyen, Martin J Wainwright, and Michael I Jordan. Estimating divergence functionals
and the likelihood ratio by penalized convex risk minimization. In NIPS, pp. 1089-1096, 2007.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. In Proceedings of the 30th International Conference
on Neural Information Processing Systems, pp. 271-279, 2016.
11
Under review as a conference paper at ICLR 2022
Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predic-
tive coding. arXiv preprint arXiv:1807.03748, 2018.
Art Owen and Yi Zhou. Safe and effective importance sampling. Journal of the American Statistical
Association, 95(449):135-143, 2000.
Qichao Que and Mikhail Belkin. Inverse density as an inverse problem: The fredholm equation
approach. arXiv preprint arXiv:1304.5575, 2013.
Benjamin Rhodes, Kai Xu, and Michael U Gutmann. Telescoping density-ratio estimation. arXiv
preprint arXiv:2006.12204, 2020.
Robin Sibson. Information radius. Zeitschriftfur Wahrscheinlichkeitstheorie Und Verwandte Gebi-
ete, 14(2):149-160, 1969.
Alex Smola, Le Song, and Choon Hui Teo. Relative novelty detection. In Artificial Intelligence and
Statistics, pp. 536-543. PMLR, 2009.
Masashi Sugiyama, Shinichi Nakajima, Hisashi Kashima, Paul Von Buenau, and Motoaki Kawan-
abe. Direct importance estimation with model selection and its application to covariate shift
adaptation. In NIPS, volume 7, pp. 1433-1440. Citeseer, 2007.
Masashi Sugiyama, Taiji Suzuki, Shinichi Nakajima, Hisashi Kashima, Paul von BUnau, and Mo-
toaki Kawanabe. Direct importance estimation for covariate shift adaptation. Annals of the Insti-
tute of Statistical Mathematics, 60(4):699-746, 2008.
Masashi Sugiyama, Taiji Suzuki, Yuta Itoh, Takafumi Kanamori, and Manabu Kimura. Least-
squares two-sample test. Neural networks, 24(7):735-751, 2011.
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density-ratio matching under the breg-
man divergence: a unified framework of density-ratio estimation. Annals of the Institute of Sta-
tistical Mathematics, 64(5):1009-1044, 2012.
Umar Syed, Michael Bowling, and Robert E Schapire. Apprenticeship learning using linear pro-
gramming. In Proceedings of the 25th international conference on Machine learning, pp. 1032-
1039, 2008.
Masatoshi Uehara, Issei Sato, Masahiro Suzuki, Kotaro Nakayama, and Yutaka Matsuo. Generative
adversarial nets from a density ratio estimation perspective. arXiv preprint arXiv:1610.02920,
2016.
Elodie Vernet, Robert Williamson, Mark Reid, et al. Composite multiclass losses. 2011.
12
Under review as a conference paper at ICLR 2022
A Proofs
A.1 Proofs for Section 2
Theorem 1 ((Gneiting & Raftery, 2007); Proposition 7 in (Vernet et al., 2011)). Given a proper
loss ` and the corresponding expected loss L, for any P, Q ∈ ∆k, the generalized entropy function
L(P) := infQ∈∆k L(P)Q) = L(P,P) is concave; when L is differentiable, the regret or excess
risk of a predictor Q over the Bayes-optimal P is the Bregman divergence induced by the convex
function f = -L:
reg(P, Q； ') ：= L(P, Q)- L(P, P) = Bf (P, Q)	(3)
Proof. For completeness, We provide the proof here. First, We can check that L(P) : ∆k → R is a
concave function. Define L(P) to be the vector (`(1, P), . . . , `(k, P)). Then the entropy function
can be represented as L(P) = L(P,P) = Ey〜p['(y,P)] = P>L(P) and similarly L(P,Q)=
P>L(Q). For λ ∈ [0,1] and P, Q ∈ ∆k, we have:
L(λP + (1 - λ)Q) = (λP + (1 - λ)Q)>L(λP + (1 - λ)Q)
=λP>L(λP+(1-λ)Q)+(1-λ)Q>L(λP+(1-λ)Q)
≥ λP>L(P) + (1 - λ)Q>L(Q) = λL(P) + (1 - λ)L(Q)
where the inequality is because ' is proper. Thus L is a concave function. Next we show that the
excess risk is a Bregman divergence with convex function -L. First, observe that
L(P, Q) = P>L(Q) = Q>L(Q) + (P - Q)>L(Q)
Because ` is proper, we have:
0 ≤ L(P, Q) -L(P,P) = Q>L(Q) + (P - Q)>L(Q) - P>L(P)
=-L(P) - (-L(Q))-(P - Q)>(-L(Q))
Rearrange the term we get -L(P) ≥ (-L(Q)) + (-L(Q))>(P - Q) and therefore -L(Q) is
a subderivative of -L. When -L is differentiable, its subdifferential contains exactly one sub-
derivative and -L(Q) = V(-L(Q)). Therefore, we have reg(P, Q) = L(P, Q) - L(P,P)=
f (P) - f (Q) - hVf (Q), P - Qi= Bf (P, Q) with f = -L.	□
A.2 Proofs for Section 3.2
Proposition 1 (DRE via variational estimation of multi-distribution f -divergence). Given a strictly
convex function f : Rk+-1 → R ∪ {+∞}, the optimization problem in Eq. (14) (induced by
minimizing expected Bregman divergence Bf (r, r)) is equivalent to the one in Eq. (16) (for
variational estimation of multi-distribution f -divergence) under change of variables satisfying:
Vf (r(x)) = s(x), ∀x ∈ X.
Proof of Proposition 1. We first recall that the optimization problem for multi-distribution DRE is
of the form
ʌ mink_1 Epk(X) KVf(r(x)), r(x)i - f(r(X))] - X Epi(X) [dif (r(X))]	(24)
rX→R+-1	,F
and one can use the Fenchel-dual convex conjugate to represent the f -divergence as
Df (Pi,…，Pk-ι∣∣Pk ) = - min, - X Epi(X)[s(x)]i + Epk(X)f *(s(x))	(25)
s:X →Rk-1
i∈[k-1]
By first-order optimality condition of convex functions, for any X ∈ X the optimal solution S(X) for
Eq. (25) satisfies that
∀i ∈ [k - 1],x ∈ X, Pi(X)- ∂if*(s(x))pk(x) = 0 ^⇒ Pi(X) = ∂,f*(s(x))
pk(X)
13
Under review as a conference paper at ICLR 2022
Therefore r(x) = Vf *(s(χ)) recovers the true density ratios.
Now We show that under change of variable s(x) = Vf (r(χ)), one can write the problem in
Eq. (25) equivalently as the one in Eq. (24). First due to the property of the convex conjugate
function (f ** = f), we have:
f *(S(X))=	min	hs(x), h(X)i - f (h(χ))
h(x)∈Rk-1
Substituting S(X) with Vf (r(x)), we have:
f*(S(X)) =	min 1 hVf(r(x)), h(x)i - f (h(x))	(26)
h(x)∈Rk-1
Taking derivative w.r.t. h and due to the strict convexity of f (Vf (a) = Vf (b) ⇔ a = b), we
know that the minimum ofEq. (26) achieves at h(x) = r(x). Thus we have:
f *(s(x)) = hVf (r(x)), r(x)i - f (r(x))	(27)
Plugging Eq. (27) and s(x) = Vf (r(x)) back to the optimization problem in Eq. (25), we can get
the following equivalent problem by flipping a sign of the objective function without changing the
optimal solution:
ʌ min	Epk(X) KVf (r(x)), r(x)i - f (r(x))] — X Epi(X)dif(r(X)),
r i X-Rk-1	—
i∈[k-1]
which is the same as the one in (24).	口
A.3 Proofs for Section 4
Lemma 1 (Multivariate Bregman Identity). Given a convex function f : Rk-1
an associated function f~(u1, . . . , uk-1) = (1 + Pi∈[k-1] ui)f 1+P
→ R, we can define
• u . We can show
1
i∈[k-1] ui
that (i) f~ is convex and (ii) for any u, v ∈ Rk-1, their associated Bregman divergences satisfy:
Bf (…L 1----------u,…L 1---------V)=…L 1----------Bf ~ (u, v).	(17)
1 +	i∈[k-1] ui	1 + i∈[k-1] vi	1 +	i∈[k-1] ui
Proof of Lemma 1. For simplicity of notations we let uk = vk = 1 for arbitrary u, v ∈ Rk-1. We
first prove the convexity of f~ by definition. Given any two points u, v ∈ Rk-1 and θ ∈ [0, 1], one
has
f~(θu+(1-θ)v)
XM + (1 - θ)vi)) ∙ f (ii + (1-θ)Vi) ∙ (θu + (1 - θ)v)
θ	ui+(1-θ)	vi	•f θP
i∈[k]	i∈[k]
1
• (θu +(1 — θ)v)
i∈[k] ui + (1 - θ)	i∈[k] vi
≤) θ (X Uj f (P1 u U)+(1 - θ) (X VJ f (P1 v V)
i∈[k]	i∈[k] ui	i∈[k]	i∈[k] vi
=θf~(u) + (1 - θ)f~(V).
Here for inequality (?) we use the fact that for any convex function g : Rn → R, the perspective
function h(t, X) : R × Rn → R defined as h(t, X) := tg(X/t) is a function jointly convex in (t, X).
Now to see the identity holds, note we can write
LHS =f (	——U) — f (	——V)
i∈[k] ui	i∈[k] vi
-(Vf ( P^--------v ) , P^------U - P1-------V )
i∈[k] vi	i∈[k] ui	i∈[k] vi
14
Under review as a conference paper at ICLR 2022
and that
RHS =f ——U)-
i∈[k] Ui
i∈[k] vi
当 J ∙ u -
i∈[k] Ui
∑i
P
i∈[k] ui
i∈[k] vi
i∈[k] ui
• f [p^—
i∈[k] vi
•f P
∖乙
i∈[k] vi
•V -
1
i∈[k] ui
Vf~(v),u-v
1
i∈[k]
P------. V) 1 + ( I - P
i∈[k] vi
i∈[k]
—1v> ) Vf I ------------V[ , U - V)
vi	i∈[k] vi
(ii)	1
=f (Pi∈^ • u)-
1
+ Ρ∈R
=f P
∖乙
i∈[k] ui
Ei∈[k]vi + Ei∈[k] (Ui - Vi)
i∈[k] vi	i∈[k] ui
卜f (∑⅛ •V
1
i∈[k] vi
• U) - f (	------V
i∈[k] vi
•f P
∖乙
i∈[k]
v1>	(u - v
•v
vi
)+
+ (Vf P^——• V) , P 1	∙ U - P^—
i∈[k] vi	i∈[k] ui	i∈[k] ui
• V______Ei∈∣kI(Ui- Vi)
Pi∈[k] ui	Pi∈[k] vi
•v
=f P
∖乙
i∈[k] ui
• U)- f l∑⅛ ∙V
+ (Vf (P 1	∙ V) , P 1	∙ u - P^—
i∈[k] vi	i∈[k] ui	i∈[k] vi
•v ,
where We use (i) the gradient formula that Vf~(v) =(I -
1
Ρi∈ [k] Vi
definition of f~, and (ii) rearranging terms and that hAv, ui = hu, A>vi.
Thus, we have shown that LHS = RHS and concludes the proof.
IVDVf (p⅛ ∙ V) by
Proposition 2. For any convex function f : Rk+-1 → R, and two density ratio vectors r(x) and
r(x), one can ConStruct CorreSponding class probability vectors η(x) = Ψ-1(r(x)) and τ^(x)=
Ψ-r1(r(x)) through the inverse link function in Eq. (8), and obtain:
Bf (η(x),η(X))
------——πk----------- Bf~ (r(x), r(x)) for all X ∈ X,
πk +--i∈[k-1]πiri (x) fπ
(18)
where we define the convex function fπ~ induced by some prior distribution π ∈ ∆k as
f~(rι,...,rk-i)= I 1 + E ∏i%∕∏k I ∙ f
i∈[k-1]
n[i:k-i] ◦ r
πk + Pi∈[k-1]πiri
(19)
Proof of Proposition 2. Given any X ∈ X, the equality follows by applying Lemma 1 with U =
看∏[Lk-i] ◦ r(x) and V = 看∏[Lk-i] ◦ r(x). To see why this is true, note that we have by
definition of ηi(χ) and ηi (x) that (here ◦ implies element-wise multiplication)
η(X)
π ◦ r(X)
πk + Pj∈[k-1]πj rj(X)
1
1 + Ρi∈[k-1] Ui
•u, and similarly τ^(x)=-——-------------------v.
1 +	i∈[k-1] Vi
—
1
1
1
• V
1
1
□
Consequently applying Lemma 1 implies that
Bf (η(χ),n(x))
1
1 + Pi∈[k-1] ui
Bf~ (U, V)
(28)
15
Under review as a conference paper at ICLR 2022
Note that given any convex function f~, we consider its composition with linear map function as
f~(r) = f~ (π1 n[i:k-i] ◦ r) = f~(u).
We note that linear composition preserves convexity and Bregman divergence equality, i.e. we have
Bf~ (u, V) = f~(u) - f~(v) -hVf~(v), U - Vi
=f ~ 1-1 ni:k-i	◦ r)	- f ~ 1-1 ni:k-i ◦	r)	- (Vf ~	1-1 ni:k-i	◦ r) , -1 ni:k-i	◦ (r - r)
πk	πk	πk	πk
=)f~(r) - f~(r) - hVf~(r), r - r = Bf~ (r, r),
(29)
where for equality (?) we use chain rule for taking derivatives of the linear composite mapping.
Combining Equations (28) and (29) and replacing U =看∏[±k-i] ◦ r gives the desired result. 口
Theorem 2. Given any strictly proper loss `, for any joint data distribution D(X, Y ) with class
prior π ∈ ∆k, the multi-class classification regret defined in Eq. (4) satisfies that:
reg(η; M, η,') = ∏kEpk(x)Bf~ (r(x), r(x)),	(20)
for f~ as defined in Eq. (19), and r = Ψdr(η) and r = Ψdr(η) as defined in Eq.⑺.
Proof of Theorem 2. Given the multi-class classification regret under some proper loss ` in Eq. (4)
and Proposition 2 we have:
reg(η; M, η,') := LCPE(n；D)- Lcpe(η; D) = EM(x)[Bf (η(x), η(x))]
-X πiEpi(X)Bf (η(χ), η(x)) = Epk(X)( X πiPi(X)Bf (η(χ),η(XX
i∈[k]	i∈[k]	pk (x)
(== Epk(X)	πk + X πiri(x)	∙ Bf(η(x), η(χ))
i∈[k-1]
(iii)
=∏kEpk(x)Bf~ (r(x), r(x)),
where we use (i) the definition of marginal distribution M(X) = Pi∈[k] πipi (X), (ii) the defini-
tion of density ratio that ri (X) = pi (X)/pk (X) ∀X ∈ X , i ∈ [k], and (iii) Proposition 2 with the
consistent definitions of f~ and r, r as stated in the theorem.	口
A.3.1 Information Measure in Multi-class Experiments
In this section, we show that multi-distribution density ratio estimation can be viewed as estimating
the statistical information measure (DeGroot, 1962) in multi-class experiments, under appropriate
choices for the convex function f .
We first introduce the following definitions in multi-class experiments. Forp ∈ ∆k, any proper loss
function ` : [k] × ∆k → R induces a generalized entropy:
H'(ρ) := inf, X Pi '(i, q),
q∈∆k
i∈[k]
which measures the uncertainty of the task. Given a multi-class experiment D = (π, P1, . . . , Pk) =
(M, η) and the generalized entropy h` : ∆k → R (which is closed concave), the information mea-
sure in a multi-class experiment (DeGroot, 1962; Duchi et al., 2018) is defined as the gap between
the prior and posterior generalized entropy:
Ih'(D) = H'(∏) - EM(x)[H'(η(x))].
We next introduce the following connections between multi-distribution f -divergence, generalized
entropy and information measure in multi-class experiments. Specifically, Duchi et al. (2018) proved
an equivalence between the gap of prior and posterior Bayes risks and the multi-distribution f-
divergence induced by a convex function f depending on ` and the prior π, demonstrating the utility
of multi-distribution f -divergence for experimental design of multi-class classification.
16
Under review as a conference paper at ICLR 2022
Theorem 3 ((DUchi et al., 2018)). Given a proper loss ', its associated generalized entropy h` and
a multi-class distribution D = (π, P1, . . . , Pk) = (M, η), we can define a closed convex function
f`,n : r+-1 → R ∪ {士∞} as
f',∏ (t) := SUp	H'(∏) - E ∏i'(i, ν)ti - ∏k'(k, V)
ν∈∆k	i∈[k-1]
(30)
We can then express the information measure of multi-class experiments as the multi-distribution
f -divergence induced by Eq. (30):
Ih'(D) = H (∏) — EM (χ)[H'(η(x))] = inf. E ∏i'(i, V) - inf L(r); D)
V∈δ" i⅛	η
=Df',∏ (P1,...,Pk-1kPk).
Given Theorem 3 and Proposition 1, we know that mUlti-distribUtion density ratio estimation by
minimizing expected Bregman divergence (Eq. (14)), induced by the convex function f',∏ defined
in Eq. (30), corresponds to estimating the statistical information measUre in mUlti-class classification
experiments.
A.4 Examples of Multi-distribution DRE
A.4. 1 Multi-class Logistic Regression
From Section 2.3, we know that there is a one-to-one correspondence between a class probability
estimator and a density ratio estimator through the link and the inverse link function: r = Ψdr ◦ r^
and η = Ψ-r1 ◦ r. When the class prior distribution π is uniform, We have:
*(x) = 7，) and τ^i(x) = -J(X)---------, for all i ∈ [k],x ∈ X.	(31)
ηk(X)	∑k=ι ^j (χ)
To recover the loss of multi-class logistic regression used in (Bickel et al., 2008), We choose the
following convex function (where we use ^ = 1):
f(rι,...,rk-ι) = k X ri log(	.ri ʌ)	(3幻
k i=ι	∖∑j-=ι Tj)
∂if (rι,...,rk-ι)= 1log (Pkri 落)for i ∈ [k - 1]	(33)
Thus the loss in Eq. (14) reduces to:
k Epk(X)
k-1
X ri(x)log	J(X)
七 )	Pk=I rj(X)
—
k-1	k	k
X ri(X) log ri(X) + (X ri(X) ) log (X ri(X))-
i=1	i=1	i=1
k-1
kχ E
i=1
WXJog (P=‰)1
=kEpk(X) rk(x)log
(X ri(X)
k-1
Epi(X) log
i=1
ri(X)
Pk=Irj (x)刀
= - (k XEpi(X)[log(ηi(χ))]
where (i) is because rk (x) = 1, ∀x ∈ X and Eq. (31).
When the class prior π is not uniform, from Section 2.3, we know that the link and inverse link
connecting density ratio estimators and class probability estimators are:
ri =	πk	∙	η-	and	^^i	= L	πiri——,	for all i ∈	[k],X ∈ X.	(34)
∏ ηk	工 j∈[k]πj rj
17
Under review as a conference paper at ICLR 2022
In this case, We choose the following convex function (where We use ^ = 1):
k
f(r1,...,rk-1) = X∏i^ log ∏i^ -
i=1
∂ifWι,...,^k-i) =∏i log I	jiri- ) for i ∈ [k - 1]
∖∑j = 1 πirj)
Note that when π is uniform distribution, Eq. (35) reduces to Eq. (32).
(35)
(36)
The loss in Eq. (14) reduces to:
Epk(X)卜krk(χ)log (X∏iri(χ)) - ∏krk(χ)log(∏krk(χ))
k-1
-	Epi(x)
i=1
π	πiri(X)	ʌ
πilog Pk
.	∖∑2j=ι πj rj IX)) _
=-(X niEpi(x)[log(ni(X))])
which corresponds to the multi-class logistic regression loss for the class probability estimators τ^.
Remark. Interestingly, we noticed that the multi-distribution f -divergence associated with the
convex function in Eq. (32) is the multi-distribution Jensen-Shannon divergence (Garcia-Garcia &
Williamson, 2012) (also known as information radius (Sibson, 1969)) up to a constant of log k:
Df(P1,...,Pk) =Epk(x)
f(≡
pk-1(X)
,…，Pk (x)
k Epk(X)
X PMlOM ( Pi(X) Y
⅜1 Pk(X) g IPk=IPk(X)Ji
1k
kX E
i=1
pi(x) log
1	pi(x)	M - logk
1 Pk=I Pj (X)Ji
1k	1k
k X DKL (Pik k X PJ - log k
i=1
j=1
A.4.2 Least-squares Importance Fitting
When the convex function associated with the Bregman divergence is chosen to be:
1 k-1	1
f (r1,...,rk-1 ) = 5∑S(ri-1)2 = 2 kr - 1k2
2 i=1	2
∂if(rι,..., rk-1) = ri - 1 for i ∈ [k - 1]
The loss in Eq. (14) reduces to:
k-1	k-1	k-1
Epk (X) ∣X(r2(X)- ri(X))- 2 X(r2(X)- 2ri(X) + 1) - XEpi(X) [ri(x) - 1]
i=1	i=1	i=1
(37)
(38)
1	k-1
=2Epk(X) ∑^(r2(X)- I)
k-1
-X Epi(χ) [ri(X) - 1]
i=1
1 k-1
2 EEpk(X)
i=1
r2(X)-1 - 2 PM(ri(X)-1)
k-1
=2 X Epk(X) [(ri(X)- ri(X))2] - C
i=1
where C = Epk(X) [∣∣t(x) - 1∣∣2] is a constant w.r.t. r and the minimizer to the above loss func-
tion matches the true density ratios, which strictly generalizes the Least-Squares Importance Fitting
(LSIF) (Kanamori et al., 2009) method to the multi-distribution case.
18
Under review as a conference paper at ICLR 2022
A.4.3 KL Importance Estimation Procedure
When the convex function associated with the Bregman divergence is chosen to be:
k-1
f(^, ...,rk-i) = X(^i log 3-ri) = hr, log(r)i — krkι	(39)
i=1
∂if(rι,...,rk-i) = log ^ for i ∈ [k - 1]	(40)
The loss in Eq. (14) reduces to:
k-1	k-1
Epk (x) X ^(x) log*(x) - X(*(χ)log*(x) - *(χ))
i=1	i=1
k-1
=Epk (x)	Eri(X)
i=1
k-1
-X Epi(X) [log ri(x)]
i=1
(41)
k-1
-X Epi(X) [log ri(x)]
i=1
This is equivalent to the following constrained optimization problem:
I (	Pi(X)
og Iri(X) ∙Pk(x)
k-1	k-1
argmin EDKL(Pi(X)IIri(X) ∙Pk(X)) = EEpi(X)
AX→Rk-1 i=1	i=l
k-1
=arg min -£ Epi(X) [log ^i(x)]
rιX→Rk-1	i=ι
s.t. Epk(χ)[^i(x)] = 1 and ^i(x) ≥ 0, for all i ∈ [k — 1].
which strictly generalizes the KUllback-Leibler Importance Estimation Procedure (KLIEP)
(Sugiyama et al., 2008) to the multi-distribution case.
A.4.4 Basu’ s Power Divergence for Robust DRE
For some α > 1, we choose the following convex function (the α-norm ofa vector):
k-1
f Crι,...√^k-ι) = X rα = k^∣α	(42)
i=1
∂if (rι,...,rk-i) = αrα-1	(43)
The loss in Eq. (14) reduces to:
k-1	k-1	k-1
Epk (X) X αrα(X)- X rα(X)I - XEpi(X) [αrα-1(X)]
i=1	i=1	i=1
k-1	k-1
=XEpk(X) [(α- 1)rα(X)] - X Epi(X) [αrα-1(X)]	(44)
i=1	i=1
To understand the robustness of this formulation, for each i ∈ [k - 1], we take the derivative of
Eq. (44) w.r.t. the parameters in the density ratio model Iri and equate it to zero, and We get the
following parameter estimation equation:
Epk(X)[rα-1(X)Vri(x)] - Epi(X)[rα-2(X)Vri(x)] = 0	(45)
Now we apply the same analysis to the multi-distribution KLIEP method in Eq. (41) and we get the
following equation (for each i ∈ [k - 1]):
Epk(X)[Vri(X)] - Epi(X)[r-1(X)Vri(x)] = 0	(46)
Comparing Eq. (45) with Eq. (46), we can see that the power divergence DRE method in Eq. (44)
is a weighted version of the multi-distribution KLIEP method, where the weight rα-1(X) controls
19
Under review as a conference paper at ICLR 2022
the importance of the samples. In some scenario where the outlier samples tend to have density
ratios less than one, they will have less influence on the parameter estimation, which generalizes the
binary Basu’s power divergence robust DRE method (Sugiyama et al., 2012) to the multi-distribution
case. Another interesting observation is that when α → 1, Eq. (45) recovers the KLIEP gradient in
Eq. (46); when α = 2, the power divergence DRE in Eq. (44) recovers the multi-distribution LSIF
method in Section A.4.2.
A.4.5 More Examples
When the convex function is chosen to be the Log-Sum-Exp type function (for α > 0):
k-1
f(rι,...,rk-i) = α log I EeXp(*∕α)
∂if(r1,...,r∙k-1)
exp(*∕α)
Pk-II exp(%∕α)
(47)
(48)
The loss in Eq. (14) can be written as:
Epk (x)
k-1
X
i=1
ri(x)exp(^i(x)∕a)
Pk-I exp(rj(X)/a)
k-1	k-1
—αlog (2exp(ri(x)∕α)) — ɪjEpi(X)
exp(^i(x)∕α)
Pk-I exp(rj(X)/a)
We can similarly derive loss functions induced by other convex functions such as the quadratic
function f (*,..., rk-ι) = r>Hr + q>r, for some positive definite matrix H * 0.
A.5 More Experimental Details
We provide more details about the problem setup of each task used in our empirical study.
For the synthetic data experiments, we use k = 5 multivariate Gaussian distributions with identity
covariance matrix and different mean vectors:
μι = (1,0,0,...)d
μ2 = ( —1, 0, 0, . . .)d
μ3 = (0,1,0,...)d
μ4 = (0,-1,0,...)d
μ5 = (1, 0,0,.. .)d
We use such design so that the density ratios are almost surely well-defined and the numerical
optimization with respect to the canonical density ratio vector r = (ri,..., rk-ι) is more stable. We
use a two-layer Multi-Layer Perceptron (MLP) (Linear(d, 32) → Linear(32, 32) → Linear(32, k -
1)) with ReLU activation function to realize the density ratio model.
For CIFAR-10 OOD detection experiments, we set k = 4 and we construct each distribution as:
p1 - samples labeled {airplane, automobile, bird}; p2 - samples labeled {cat, deer, dog, frog}; p3
- samples labeled {horse, ship, truck} and p4 - a uniform mixture of these distributions. We use a
standard convolution neural network in the PyTorch tutorial1 with k- 1 outputs to realize the density
ratio model.
For MNIST multi-target generation experiments, we use k = 6 and we construct each distribution
as: p1 - samples labeled {0,1}; p2 - samples labeled {2,3}; p3 - samples labeled {4,5}; p4 - samples
labeled {6,7}; p5 - samples labeled {8,9}; p6 - a mixture of these distributions. We use a two-
layer convolutional neural network (Conv(1,32, 3, 1) → Conv(32, 64, 3, 1) → Linear(9216, 128) →
Linear(128, k - 1)) with ReLU activation function to realize the density ratio model.
For multi-distribution off-policy policy evaluation experiments, we conducted experiments on the
Half-Cheetah environment in OpenAI Gym (Brockman et al., 2016). We use soft actor-critic al-
gorithm (Haarnoja et al., 2018) to obtain five different policies with average expected return of
1https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html
20
Under review as a conference paper at ICLR 2022
{3811, 5277, 6444, 7397, 5728} respectively and we learn density ratios between their induced
occupancy measures (state-action distributions). We use a three-layer MLP (Linear(17, 256) →
Linear(256, 256) → Linear(256, 256) → Linear(256, k - 1)) with ReLU activation function to
realize the density ratio model.
21