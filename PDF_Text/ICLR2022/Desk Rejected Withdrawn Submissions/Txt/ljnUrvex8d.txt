Under review as a conference paper at ICLR 2022
Representation Topology Divergence:	A
Method for Comparing Neural Network Rep-
resentations.
Anonymous authors
Paper under double-blind review
Ab stract
Comparison of data representations is a complex multi-aspect problem that has not
enjoyed a complete solution yet. We propose a method for comparing two data
representations. We introduce the Representation Topology Divergence (RTD)
measuring the dissimilarity in multi-scale topology between two point clouds
of equal size with a one-to-one correspondence between points. The data point
clouds are allowed to lie in different ambient spaces. The RTD is one of the few
TDA-based practical methods applicable to real machine learning datasets. Ex-
periments show the proposed RTD agrees with the intuitive assessment of data
representation similarity and is sensitive to its topological structure. We apply
RTD to gain insights on neural networks representations in computer vision and
NLP domains for various problems: training dynamics analysis, data distribution
shift, transfer learning, ensemble learning, disentanglement assessment.
1	Introduction
Representations of objects are the essential component learnt by deep neural networks. In opposite
to the distance in the original space, similarity of representations are proved to be semantically
meaningful. Despite of the significant practical success of deep neural networks many aspect of
their behaviour are poorly understood. Only few methods study learned representations without
relying on their quality on a specific downstream task. In this work, we focus on the comparison of
representations from neural networks.
Comparison of representations is an ill-posed problem without a “ground truth” answer. Early stud-
ies were based on variants of Canonical Correlation Analysis (CCA): SVCCA, (Raghu et al., 2017),
PWCCA (Morcos et al., 2018). Hovewer, CCA-like measures define similarity too loosely since
they are invariant to any invertible linear transformation. The Centered Kernel Alignment (CKA),
(Kornblith et al., 2019) is the statistical test to measure the independence of two sets of variables.
(Kornblith et al., 2019) proved it to be more consistent with the intuitive similarity of representa-
tions. Particularly, neural networks learn similar representation from different seeds as evaluated by
CKA. Another line of work studies alignment between groups of neurons (Li et al., 2015), (Wang
et al., 2018). The similarity of representation is also a topic of a study in neuroscience (Edelman,
1998; Kriegeskorte et al., 2008; Connolly et al., 2012).
Representations’ comparison metrics like CKA and CCA were used to gain insights on represen-
tations obtained in meta-learning (Raghu et al., 2020), to compare representations from different
layers of language models (Voita et al., 2019), study the effect of fine-tuning (Wu et al., 2020). Fi-
nally, (Nguyen et al., 2021) used CKA to study the phenomenon of a “block structure” emerging in
wide and deep networks in computer vision and compare their representations.
In this paper, we take a topological perspective on representations’ comparison. We propose the
Representation Topology Divergence (RTD) score which measures a dissimilarity between two point
clouds of equal size with one-to-one correspondence between points. Point clouds are allowed
to lie in different ambient spaces. Existing geometrical and topological methods are dedicated to
other problems: they are either too general and doesn’t incorporate the requirement of one-to-one
correspondence (Khrulkov & Oseledets, 2018), (Tsitsulin et al., 2020), or they restrict point clouds
to lie in the same ambient space (Kynkaanniemi et al., 2019), (Barannikov et al., 2021). Such
1
Under review as a conference paper at ICLR 2022
20	40 ∈p0ch 60	80	100
Figure 1: Comparison of representations after the i-th epoch and the final one done by RTD,
1-CKA, and disagreement of predictions. All the measures are normalized by division to their
maximal values. Strikingly, RTD highly correlates with the disagreement of models’ predictions.
methods (except for (Tsitsulin et al., 2020)) are mostly applied to the evaluation of GANs, where
point clouds of real and generated objects are matched. Recently, (Moor et al., 2020) proposed
a loss term to compare a topology of data in original and latent spaces (with natural one-to-one
correspondence) and applied it as a part of the Topological Autoencoder.
In this work, we make the following contributions:
1.	We propose a topologically-inspired approach for comparison of neural network represen-
tations;
2.	We introduce the R-Cross-Barcode(P, P ), a tool based on Topological Data Analysis
(TDA) which measures differences in multi-scale topology of two point clouds P, P with
one-to-one correspondence between points;
3.	Based on the R-Cross-Barcode(P, P ), we define the Representation Topology Divergence
(RTD), the scalar measuring the multi-scale topological dissimilarity between two repre-
sentations;
4.	By doing computational experiments, we show that RTD agrees with an intuitive notion
of neural network representations similarity. In contrast with most existing approaches,
RTD score is sensitive to cluster and other topological structures of the representations and
enjoys very good correlation with disagreement of models predictions. We apply RTD
to compare representations in computer vision and NLP domains and various problems:
training dynamics analysis, data distribution shift, transfer learning, ensemble learning,
disentanglement. We have also compared RTD with CKA, IMD and SVCCA.
2	Comparing Neural Network Representations
Our starting point is the geometric perspective on representation learning through the lens of the
manifold hypothesis (Goodfellow et al., 2016), according to which real-world data presented in a
high dimensional space are expected to concentrate in vicinity of a manifold of much lower dimen-
sion. The low-dimensional manifold MP underlying the given data representation P can be accessed
generally only through discrete sets of samples. The standard approach to recover the manifold MP
is to take a sample P and to approximate MP by a set of simplices with vertices from P. A common
approach to select the simplices approximating MP is to fix a threshold α > 0 and consider the
simplices with edge lengths not exceeding α (Niyogi et al., 2008; Belkin & Niyogi, 2001). It is
difficult in general to guess the correct value of the threshold, hence a reasonable viewpoint is to
study all thresholds at once, see e.g. (Chazal & Michel, 2017). This can be accomplished by means
of the mathematical tool, called barcode, that quantifies the evolution of manifold topology features
over multiple scales.
Given two representations, we consider two corresponding graphs with distance-like weights and
compare the difference in the two graphs’ multiscale topology.
2
Under review as a conference paper at ICLR 2022
2.1	R-Cross-Barcode
Let P(V), P (V) be two representations giving two embeddings of the same data. The two em-
beddings P , P belong in general to different ambient spaces and we have the natural one-to-one
correspondence between points in P and P. Given a sample of data V ⊆ V, the representation
P = P(V) defines the weighted graph Gw with the vertex set V. The weight wAB of an edge AB
is given by the distance between points P (A) and P (B). Similarly the representation P = P(V)
defines the weighted graph GW on the same vertex set.
The simplicial approximation to the manifold MP at threshold α consists of simplices whose edges
in Gw have weights not exceeding α. Let Gw≤α denote the graph with the vertex set V and the edges
with weights not exceeding a. To compare the SimPliciaI approximations to manifolds MP and MP
described by the graphs Gw≤α and Gw≤α We embed both graphs into the graph Gmin(W,W)≤α. The
graph Gmin(W,W)≤α contains an edge between vertices A and B exactly when the distance between
the points A and B is smaller than α in at least one of the representations P, P.
Recall that Vietoris-Rips complex of a graph G equipped with edge weights’ matrix m is the collec-
tion of k-simplices, k ≥ 0, which are (k + 1)-elements subsets of the set of vertices of G, with
the filtration threshold of a simplex defined by its edges’ maximal weight:
Ra(Gm) = {{Ao,...,Ak},Ai ∈ Vert(G)∣ImAjAl ≤ α}
Our simplicial approximations to the manifolds MP, MP at threshold α are the unions of all sim-
plices from the simplicial complexes Ra(GW), Ra(GW).
The dissimilarity between the filtered simplicial complexes Ra(GW) and Ra(GW) can be quantified
using the homological methods. The relevant tools here are the homology, the Whitehead theorem
and the homology exact sequence. Because of the space limitations we sketch how this leads to our
construction, described below, in the Appendix, Section B.
Concretely, to compare the multi-scale topology of the two weighted graphs Gw and GW we introduce
the weighted graph G(w,w) With doubled set of vertices and with the edge weights defined as
follows. For each vertex A ∈ Vert(G) we add the extra vertex A0 together with A to G and define
the distance-like edge weights in G(w, W) as:
dAB = min(wAB,Wab), "ab0 = "a0b = wab, "aa0 = 0, dA0B0 = 0	(1)
where B ∈ Vert(G), A 6= B.
In practice G, G are full graphs and the edge weights on the graph G(w, W) are given by 2N X 2N,
N = |V|, symmetric matrix
0W
m=
∖ w min(w,w)
where W and W are the distance-like edge weights matrices of Gw and GW.
Next, we construct the VietOnS-RiPS filtered simplicial complex from the graph G(w, w). Intuitively,
the i-th barcode of Ra(G(w, W)) records the i-dimensional topological features that are born in
Ra(GW) but are not yet born at the same place in Ra (GW) and the (i + 1) -dimensional topological
features that are dead in Ra(GW) but are not yet dead at this place in Ra (GW), see Theorem 1 below.
Definition. The R-Cross-Barcodei (P, P) is the set of intervals recording the “births” and “deaths”
of i-dimensional topological features in the filtered simplicial complex Ra(G(w, w)).
The R-Cross-Barcode*(P, P) (for Representations Cross-Barcode) records the differences in mul-
tiscale topology of the two embeddings. The topological features with longer lifespans indicate in
general the essential features.
Theorem 1. Basic properties OfR-CroSS-Barcode*(P, P):
•	if P (A) = P (A) for any object A ∈ V, thenR-Cross-Barcode *(P,P) = 0;
•	if all distances within P(V) are zero i.e. all objects are represented by the same point in P, then
R-Cross-Barcode*(P, P) = Barcode*(P) the standard barcode ofthe point cloud P;
(2)
3
Under review as a conference paper at ICLR 2022
Algorithm 1 R-Cross-Barcodei (P, P)
Input: w, W : matrices of pairwise distances
within point clouds P , P
Require: vr(m): function computing filtered
complex from pairwise distances matrix m
Require: B(C, i): function computing persis-
tence intervals of filtered complex C in dimen-
sion i
0w
m J Iw min(w,W)J
R-Cross-Barcodei J B(vr(m), i)
._ _ _ _ _ ~.	_ . _ 一
Algorithm 2 RTD(P, P), see section 2.3 for de-
tails, suggested default values: b = 500, n = 10
Input: P ∈ RlVl×D, P ∈ RlVl×D : datarepre-
sentations
for j = 1 to n do
Vj J random choice (V , b)
Return: intervals’ list R-Cross-Barcodei (P, P )
representing ”births” and ”deaths” of topolog-
ical discrepancies between P and P.
~ ~∙,
Pj ,PjJP (Vj ),P(V∙)	~
Bj J R-Cross-Barcode1 (Pj , Pj) intervals’
list calculated by Algorithm 1
rtdj J sum of lengths of all intervals in Bj
end for
RTD(P, P) J mean(rtd)
Return: number RTD(P, P) representing dis-
CrePanCy between the representations P, P
~
~
~
•	for any value of threshold α, the following sequence of natural linear maps of homology groups
...→ Hi(Ra(GW)) → Hi(Ra(Gmin(W，w))) → Hi(Ra(G(w,W))) →
→ Hi-1 (Ra(GW)) → Hi-I(Ra(Gmm(W，w))) → ...⑶
is exact; recall that it means that the kernel of any map is the image of the previous map
The proof of the first two properties is immediate and the third property follows from the exactness
of the corresponding sequence of simplicial complexes, see Appendix for more details.
2.2	Representation Topology Divergence.
The R-Cross-Barcode*(P, P) is by itself, to our opinion, a precise and intuitive tool for understand-
ing discrepancies between two representations. There are several numerical characteristics measur-
ing the non-emptyness of R-Cross-Barcode. Based on experiments and on its relation with Earth
Moving Distance, see (Barannikov et al., 2021), we have defined the sum of lengths of the bars in
R-Cross-Barcodei (P, P), denoted RT Di(P, P) as the scalar characterizing the degree of topologi-
cal discrepancy between the representations P, P. We use most oftenly the average of RT D1(P, P)
i	τ-tm 7^Λ /六 7~»\ i	. i nmr∖	♦	.	. ∙	1 ι
and RTD1(P, P), denoted RTD score, in our computations below.
Proposition 1. If RTDi (P, P) = RTDi(P, P) = 0 forall i ≥ 0 then the barcodesofthe weighted
graphs GW and GW are the same in any degree. Moreover in this case the topological features are
located in the same places: the inclusions Ra(GW) ⊆ Ra(Gmin(W,W)), Ra(GW) ⊆ Ra(Gmm(W'W))
induce for any threshold α the isomorphisms in homology.
2.3	Algorithm
First we compute the R-Cross-Barcode1 (P, P) on two representations P, P ofa sample V . For this
We calculate the matrices of pairwise distances w, W within the point clouds P, P. We assume that
the metrics in the ambient spaces of representations are normalized so that the two point clouds are
of comparable size, namely their 0.9 quantile of pairwise distances coincide. This ensures that our
score has scaling invariance, the reasonable property ofa good representation similarity measure, as
argued in e.g. (Kornblith et al., 2019). Next the algorithm builds the Vietoris Rips complex from the
matrix m defined in Equation (2). Then the 1-dimensional barcode, see (Chazal & Michel, 2017),
of the built filtered simplicial complex is calculated. The last two steps can be done using scripts that
are optimized for GPU acceleration. Then We sum the lengths of bars in R-Cross-Barcode ι(P, P).
To get the symmetric measure we usually take the half-sum with similar sum of bars in R-Cross-
Barcode1 (P, P). The computation is repeated sufficient number of times to obtain the mean of the
chosen characteristics. We have observed experimentally that about 10 times is normally sufficient
for common datasets. The main steps of the computation are summarized in the Algorithms 1, 2.
4
Under review as a conference paper at ICLR 2022
Complexity. Algorithm 1 starts with the computation of the two matrices of pairwise distances w,
W for a pair of representations of a sample V: P ∈ Rb×D, P ∈ Rb×D involving O(|V|2 (D + D))
operations. Next, persistent intervals of the filtered complex must be computed. Given the distance
matrix m, the complexity of their computation doesn’t depend on the dimensions D, D of the data
representations. Generally, the barcode computation is at worst cubic in the number of simplices
involved. In practice, the calculation is quite fast since the boundary matrix is typically sparse for
real datasets. For R-Cross-Barcodes’ calculation we used the GPU-optimized software. Thus, the
computation of R-Cross-Barcode takes similar time as in the previous step even on datasets of big
dimensionality. Since only the dissimilarities in representation topology are calculated, the results
are quite robust and a rather low number of iterations is needed to obtain accurate results.
3 Experiments
In the experimental section, we study the ability the proposed R-Cross-Barcodes and RTD to detect
changes of topological structures using synthetic point clouds; we demonstrate the superiority of
RTD over CKA, SVCCA, IMD (Section 3.1). By comparing representations from various archi-
tectures (Section 3.3), layers, epochs, ensembles and after data distribution shift (Section 3.4) we
show that RTD is in line with natural notion of neural representations’ similarity. High correlation
of RTD and disagreement of networks’ predictions is an interesting empirical finding. Additionally,
empirical evidence suggests that RTD is useful for evaluating disentanglement of representations
(Section 3.2).
3.1	Experiments with synthetic point clouds
Figure 2: Point clouds used in “clusters” (top) and “rings” (bottom) experiments.
(a) “clusters” experiment: 1 cluster vs. 2, 6, 12 clusters
(b) “rings” experiment: 5 rings vs. 4, 3, 1 rings
Figure 3: Examples of R-Cross-Barcodes for experiments with synthetic point clouds.
Figure 4: Representations’ comparison measures for the “clusters” point clouds. Ideally, the evalu-
ation measure should monotonically change with the increase of topological complexity.
5
Under review as a conference paper at ICLR 2022
Figure 5: Representations’ comparison measures for the “rings” point clouds. Ideally, the evaluation
measure should monotonically change with the increase of topological complexity.
We start with small-scale experiments with synthetic point clouds: “clusters” and “rings”. For
the “clusters” experiment (Figure 2, top), the initial point cloud consists of 300 points randomly
sampled from 2-dimensional normal distribution having mean (0, 0). Next, we split it into 2,3. . . 12
parts (clusters) and move them to the circle with radius 10. Then, we compare the initial point cloud
(having one cluster) with the split ones.
In the “rings” experiment, we compare synthetic point clouds consisting of a variable number of
rings, see Figure 2, bottom. Initially, there are 500 points uniformly distributed over the unit circle.
Then, the points are moved onto circles with varying radius, from 0.5 to 1.5. Finally, we compare
the leftmost point cloud having 5 rings with other ones.
In both of the experimental settings there is a one-to-one correspondence between points in the point
clouds. We compared these point clouds by calculating: RTD (proposed), CKA (Kornblith et al.,
2019), IMD (Tsitsulin et al., 2020) and SVCCA (Raghu et al., 2017). We calculated linear CKA
since (Kornblith et al., 2019) concluded that it provides the same performance as with RBF kernel
but doesn't require to select a kernel width. For SVCCA, We calculated average correlation P for
the truncation threshold 0.99, as recommended by the authors (Raghu et al., 2017). The IMD score
(Tsitsulin et al., 2020) was very noisy and we averaged it over 100 runs.
Figures 4, 5 present the results. RTD measure almost ideally reflects the change of the topological
complexity while the alternative measures mostly fail. The Kendall-tau rank correlations of the
measures with a number of clusters are: RTD: 1.0, CKA: 0.23, IMD: 0.43, SVCCA: 0.14; for the
number of rings: RTD: 0.9, CKA: -0.2, IMD: 0.9, SVCCA: -0.2. We also note than RTD score
doesn’t have any tunable parameters as SVCCA and doesn’t require averaging over as many runs
as IMD. Figure 3 shows some of the H1 R-Cross-Barcodes calculated while comparing clusters and
rings. In accordance with the definition, H0 barcodes are absent. The sum of lengths of segments
increases as differences of topology increases. All of the R-Cross-Barcodes are in Appendix D.
3.2	Experiments with disentanglement
Learning disentangled representations is a fundamental problem for
improving generalization, robustness, and interpretability of gener-
ative models. Zhou et al. (2020) proposed to evaluate the disen-
tanglement of generative models by comparing topology of data
manifold slices. Let Z be a latent space, X - a space of objects,
g : Z → X - a generator. Zhou et al. (2020) compares slices
Xv = g(Z |zi=v) for different values of v. If the direction zi cor-
responds to an interpretable factor, then Xv must be topologically
similar for different v.
We use the following experimental design. Zv,n = {z ∈ Z |
(z, n) = v} - a slice in a latent space orthogonal to a unit vector
n. We take a finite random sample Z1 ⊂ Zv,n and a shifted sample
Z2 = {zi + δn}i=11 for small δ. By definition, Z1 and Z2 have natural point-wise mapping and we
can estimate homological similarity ofg(Z1) and g(Z2) by RTD.
In this experiment, we use dSprites1 for the evaluation of disentanglement. dSprites is a
dataset of procedurally generated 2D shapes from 5 ground truth independent latent factors: shape,
scale, rotation, x-position and y-position ofa sprite. Thus, the latent space is disentangled and fully
factorized. Particularly, we compare the slices orthogonal to axes-aligned vectors and orthogonal to
1https://github.com/deepmind/dsprites-dataset
Table 1: Evaluation of the dis-
entanglement for various di-
rections in the latent space of
dSprites.
axis RTD
axis 1	148.1
axis 2	71.3
axis 3	53.4
axis 4	41.2
axis 5	40.5
random	162.8 ± 18.6
6
Under review as a conference paper at ICLR 2022
Figure 6: dSprites generated across directions in the latent space, top: random direction, bottom:
axis-aligned direction, corresponds to an interpretable factor of variation.
random vectors, see Table 1. Except for the first axis, the topological dissimilarity estimated by RTD
is significantly less then for a random direction. The first axis corresponds to a categorical factor -
shape for which the aforementioned approach is arguably not applicable. The dSprites dataset
is quite simple and RTD was calculated for point clouds in the pixel space. However, the same
technique can be straightforwardly applied to evaluate disentanglement of image representations for
more complex datasets.
3.3	Experiments with NAS -Bench-NLP
Recently, neural architecture search attracted a lot of attention in
the machine learning community (Liu et al., 2019; Dong & Yang,
2019; Chen et al., 2021). Klyuchnikov et al. (2020) developed a
benchmark for neural architecture search which is a collection of
14’322 recurrent architectures; all of them were trained on the PTB
dataset. We took 90 random architectures and compared word em-
beddings: each architecture contains 400-dimensional embeddings
of 10’000 words. Then, we evaluated all the pairwise similarities
between embeddings2 from the architectures and visualized them
via multi-dimensional scaling, see fig. 7, where color depicts a log.
perplexity. Accordingly to a common sense, architectures having
similar embeddings have similar log. perplexity.
3.4	Experiments with convolutional neural
NETWORKS
Figure 7: Multi-dimensional
scaling of 90 random ar-
chitectures from NAS-Bench-
NLP. Color depicts log. per-
plexity.
To demonstrate the abilities of RTD to work with image representations, we train ResNet-20 (He
et al., 2016) and VGG-11 (Simonyan & Zisserman, 2014) networks on CIFAR (Krizhevsky et al.,
2009) datasets. In the experiments, we compare RTD with CKA and disagreement of predictions.
For more intuitive comparison we consider 1-CKA instead of CKA. As a measure of the difference
in predictions, we use Disagreement (Kuncheva & Whitaker, 2003; Wen et al., 2020), the fraction
of mismatched predictions calculated as N PN=I [fe1 (Xn) = fe2(xn)] , where fθ(x) denotes the
class label predicted by the network for input x. As discussed in (Fort et al., 2019), the lower the
accuracy of predictions, the higher its potential mismatch due to the possibility of the wrong answers
being random, and then we normalize the Disagreement by (1 - a), where a is the mean accuracy
of the predictions. To calculate the final metrics, we averaged values for five random batches of 500
representations from the test dataset.
3.4.1	Training dynamics
As the first experiment, we analyze the training dynamics of
neural networks. On each epoch, we collect the outputs of the
convolutional part that extract the representations. To compare
dynamics properly, we scaled the metrics by their maximum
value. Fig. 1 shows the dynamics of differences with the final
representations.
Table 2: The correlation of metrics
with Disagreement in the training
dynamics experiment
RTD 1-CKA
VGGTI 099^^0.83
ResNet-20 0.98	0.93
2to speedup the computation, we averaged metrics for 10 random batches of 100 word embedding.
7
Under review as a conference paper at ICLR 2022
Figure 9: Analysis of ResNet-20 representations under different data distribution shifts. The dy-
namics of scaled metrics with the monotonic transformations of images.
RTD 1-CKA
Noise	0.968^^0.928
Gaussian blur	0.982	0.915
Grayscale	0.998	0.937
Hue	0.982	0.916
Table 3: Analysis of ResNet-20 representations under different data distribution shifts. The correla-
tion of metrics with Disagreement.
The results coincide with the intuition: the representations on each epoch become more similar to
the final one. Moreover, RTD demonstrates the same behavior as disagreement of predictions. RTD
better correlates with the Disagreement, see table 2.
3.4.2	Layers
As the next experiment, we compare the outputs of layer
blocks within the trained network. For VGG-11, the block has
the form Conv→BN→Activation→(Pooling), and for ResNet-
20, we take the output of the first Conv→BN→Activation
block and then the outputs of each residual block. In fig. 8,
we see that both RTD and 1-CKA show similar results, in-
cluding the slight difference between adjacent layers. Also,
we can see that both metrics reveal the significant changes in
the outputs of the ResNet-20 last block.
Figure 8: The representation dif-
ferences between the layer blocks
within trained networks. The
columns correspond to the archi-
tecture, and the rows correspond to
the metric.
3.4.3	Data Distribution Shift
Here, we apply the data distribution shift to test the RTD. As
a shift, we consider different image transformations: noising,
blurring, grayscaling, and hue changing. For each transforma-
tion, we analyze the metric dynamics as a strength of trans-
formation increases. Fig. 9 confirms our sanity check about
the monotony of RTD and other metrics with respect to data
distribution shift. Moreover, Table 3 shows that RTD has a higher correlation with disagreement of
predictions.
3.4.4	Ensembles
It is known that an ensemble of neural networks performs better than a single network and can
estimate the uncertainty of the predictions. It is showed in (Lee et al., 2015; Opitz et al., 1996)
that the diverse ensembles work better. Thus, measuring ensembles’ diversity is important. The
disagreement is a good example of such a measure. To show that RTD can measure the diversity
as well as disagreement, we learn two types of ensembles: the classical one, when we learn the
networks from different random initializations, and the Fast Geometric Ensemble (FGE) (Garipov
et al., 2018), which is known to have the lower diversity. We learn four models for each type of
ensemble and average the metrics among all pairs. The results in Table 4 confirm that RTD can
measure the diversity on the same scale as the disagreement of predictions.
8
Under review as a conference paper at ICLR 2022
Classical Ensemble FGE	Difference, %
RTD	15.27 ± 0.12	10.45 ± 0.32	31.6
1-CKA	0.094 ± 0.02	0.033 ± 0.003	64.9
Disagreement	0.915 ± 0.05	0.607 ± 0.03	33.6
Table 4: The averaged metric among all pairs of ensemble members with a ResNet-20 architecture,
and the relative difference between the types of ensemble.
Cifarioo	cifario
Figure 10: Scaled metrics demonstrating the difference between representations of CIFAR-100 and
CIFAR-10 datasets during fine-tune process.
3.4.5	Transfer learning
Another possible application is the measure of changes in representations after transferring the pre-
trained model to a new task. In this experiment, we conduct the transfer learning from CIFAR-100
to CIFAR-10 dataset. We make full fine-tuning with the small learning rate for the convolutional
part. In fig. 10, we demonstrate the dynamics for both dataset representations. The results again
coincide with the intuition about the difference during the learning steps, and here RTD has also high
correletion with Disagreement, see Table 5. Also, we note that RTD can be applied to the continual
learning task, where catastrophic forgetting appears, and thus it is crucial to track the changes of
network representations.
4 Conclusions
In this paper, we have proposed a topologically-inspired ap-
proach to compare neural network representations. The most
widely used methods for this problem are statistical: Canonical
Correlation Analysis (CCA) and Centered Kernel Alignment
(CKA). But the problem itself is a geometrical one: compar-
ison of two neural representations of the same objects is de-
facto comparison of two points clouds from different spaces
having one-to-one correspondence. The natural way is to com-
Table 5: The correlation of metrics
with Disagreement in the transfer
learning experiment
RTD	1-CKA
CIFAR-100^^0.99^^093
CIFAR-10 0.92	0.89
pare their geometrical and topological features, taking into account their localization, that is exactly
done by the R-Cross-Barcode and RTD. We demonstrated that RTD coincides with the natural as-
sessment of representations similarity. We used the RTD to gain insights on neural networks repre-
sentations in computer vision and NLP domains for various problems: training dynamics analysis,
data distribution shift, transfer learning, ensemble learning, disentanglement assessment.
RTD strikingly well correlates with the disagreement of models’ predictions; this is an intriguing
topic for the further research. Finally, R-Cross-Barcode and RTD are general tools and which are
not limited only to representations comparison. They could by applied to other problems involv-
ing comparison of two point clouds with one-to-one correspondence, for example in 3D computer
vision.
9
Under review as a conference paper at ICLR 2022
References
SergUei Barannikov. Framed Morse complexes and its invariants. Adv. Soviet Math., 22:93-115,
1994.
SergUei Barannikov, Ilya Trofimov, Grigorii Sotnikov, Ekaterina Trimbach, Alexander Korotin,
Alexander Filippov, and Evgeny BUrnaev. Manifold Topology Divergence: a framework for
comparing data manifolds. In Proceedings of the 33rd International Conference on Neural Infor-
mation Processing Systems, NeurIPS’21, arXiv:2106.04024, 2021.
Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps and spectral techniqUes for embedding and
clUstering. In Proceedings of the 14th International Conference on Neural Information Processing
Systems: Natural and Synthetic, pp. 585-591, 2001.
Frederic Chazal and Bertrand Michel. An introduction to topological data analysis: fundamental
and practical aspects for data scientists. arXiv:1710.04019, 2017.
Wuyang Chen, Xinyu Gong, and Zhangyang Wang. Neural architecture search on imagenet in four
gpu hours: A theoretically inspired perspective. International Conference on Learning Represen-
tations, 2021.
Andrew C Connolly, J Swaroop Guntupalli, Jason Gors, Michael Hanke, Yaroslav O Halchenko,
Yu-Chien Wu, Herve Abdi, and James V Haxby. The representation of biological classes in the
human brain. Journal OfNeurOscience, 32(8):2608-2618, 2012.
Xuanyi Dong and Yi Yang. Searching for a robust neural architecture in four gpu hours. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1761-1770,
2019.
Shimon Edelman. Representation is representation of similarities. Behavioral and brain sciences,
21(4):449*7,1998.
Stanislav Fort, Huiyi Hu, and Balaji Lakshminarayanan. Deep ensembles: A loss landscape per-
spective. arXiv preprint arXiv:1912.02757, 2019.
Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry Vetrov, and Andrew Gordon Wilson.
Loss surfaces, mode connectivity, and fast ensembling of dnns. In Proceedings of the 32nd Inter-
national Conference on Neural Information Processing Systems,pp. 8803-8812, 2018.
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning, volume 1.
MIT press Cambridge, 2016.
Arthur Gretton, Olivier Bousquet, Alex Smola, and Bernhard Scholkopf. Measuring statistical de-
pendence with hilbert-schmidt norms. In International conference on algorithmic learning theory,
pp. 63-77. Springer, 2005.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Valentin Khrulkov and Ivan Oseledets. Geometry score: A method for comparing generative ad-
versarial networks. In International Conference on Machine Learning, pp. 2621-2629. PMLR,
2018.
Nikita Klyuchnikov, Ilya Trofimov, Ekaterina Artemova, Mikhail Salnikov, Maxim Fedorov, and
Evgeny Burnaev. Nas-bench-nlp: neural architecture search benchmark for natural language
processing. arXiv preprint arXiv:2006.07116, 2020.
Simon Kornblith, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton. Similarity of neural
network representations revisited. In International Conference on Machine Learning, pp. 3519-
3529. PMLR, 2019.
Nikolaus Kriegeskorte, Marieke Mur, and Peter A Bandettini. Representational similarity analysis-
connecting the branches of systems neuroscience. Frontiers in systems neuroscience, 2:4, 2008.
10
Under review as a conference paper at ICLR 2022
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009.
Ludmila I Kuncheva and Christopher J Whitaker. Measures of diversity in classifier ensembles and
their relationship with the ensemble accuracy. Machine learning, 51(2):181-207, 2003.
TUomas Kynkaanniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Improved
precision and recall metric for assessing generative models. In 33rd Conference on Neural Infor-
mation Processing Systems (NeurIPS 2019), 2019.
Stefan Lee, Senthil Purushwalkam, Michael Cogswell, David Crandall, and Dhruv Batra. Why
m heads are better than one: Training a diverse ensemble of deep networks. arXiv preprint
arXiv:1511.06314, 2015.
Yixuan Li, Jason Yosinski, Jeff Clune, Hod Lipson, John E Hopcroft, et al. Convergent learning:
Do different neural networks learn the same representations? In FE@ NIPS, pp. 196-212, 2015.
Hanxiao Liu, Karen Simonyan, and Yiming Yang. Darts: Differentiable architecture search. Inter-
national Conference on Learning Representations, 2019.
Michael Moor, Max Horn, Bastian Rieck, and Karsten Borgwardt. Topological autoencoders. In
International Conference on Machine Learning, pp. 7045-7054. PMLR, 2020.
Ari S Morcos, Maithra Raghu, and Samy Bengio. Insights on representational similarity in neural
networks with canonical correlation. arXiv preprint arXiv:1806.05759, 2018.
Thao Nguyen, Maithra Raghu, and Simon Kornblith. Do wide and deep networks learn the same
things? uncovering how neural network representations vary with width and depth. International
Conference on Learning Representations, 2021.
Partha Niyogi, Stephen Smale, and Shmuel Weinberger. Finding the homology of submanifolds with
high confidence from random samples. Discrete & Computational Geometry, 39(1-3):419441,
2008.
David W Opitz, Jude W Shavlik, et al. Generating accurate and diverse members of a neural-network
ensemble. Advances in neural information processing Systems, pp. 535-541, 1996.
Aniruddh Raghu, Maithra Raghu, Samy Bengio, and Oriol Vinyals. Rapid learning or feature reuse?
towards understanding the effectiveness of maml. International Conference on Learning Repre-
sentations, 2020.
Maithra Raghu, Justin Gilmer, Jason Yosinski, and Jascha Sohl-Dickstein. Svcca: Singular vector
canonical correlation analysis for deep learning dynamics and interpretability. arXiv preprint
arXiv:1706.05806, 2017.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556, 2014.
Anton Tsitsulin, Marina Munkhoeva, Davide Mottin, Panagiotis Karras, Alex Bronstein, Ivan Os-
eledets, and Emmanuel Mueller. The shape of data: Intrinsic distance for data distributions. In
International Conference on Learning Representations, 2020.
Elena Voita, Rico Sennrich, and Ivan Titov. The bottom-up evolution of representations in the
transformer: A study with machine translation and language modeling objectives. EMNLP, 2019.
Liwei Wang, Lunjia Hu, Jiayuan Gu, Yue Wu, Zhiqiang Hu, Kun He, and John Hopcroft. Towards
understanding learning representations: To what extent do different neural networks learn the
same representation. 32nd Conference on Neural Information Processing Systems (NeurIPS),
2018.
Yeming Wen, Dustin Tran, and Jimmy Ba. Batchensemble: An alternative approach to efficient
ensemble and lifelong learning. ArXiv, abs/2002.06715, 2020.
George W Whitehead. Elements of homotopy theory, volume 61. Springer Science & Business
Media, 1968.
11
Under review as a conference paper at ICLR 2022
John M Wu, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, and James Glass. Sim-
ilarity analysis of contextual word representation models. Proceedings of ACL, 2020.
Sharon Zhou, Eric Zelikman, Fred Lu, Andrew Y. Ng, Gunnar Carlsson, and Stefano Ermon.
Evaluating the disentanglement of deep generative models through manifold topology. preprint
arXiv:2006.03680, 2020.
A	Background on Simplicial Complexes. Barcodes
The simplicial complex is a combinatorial object that can be thought of as a higher-dimensional
generalization of a graph.
A simplex is defined via the set of its vertices. Given a finite set V , a k-simplex is a finite (k +
1)-element subset in V . Simplicial complex S is a collection of k-simplices, k ≥ 0, which satisfies
the natural condition that for each σ ∈ S, σ0 ⊂ σ implies σ0 ∈ S . A simplicial complex consisting
only of 0- and 1-simplices is a graph.
Denote via Ck(S) the vector space over the field Z/2Z whose basis elements are k-simplices from
S. The boundary linear operator ∂k : Ck(S) → Ck-1(S) is defined on σ = {A0, . . . , Ak} as
k
∂kσ =	{A0, . . . , Aj-1, Aj+1, . . . , Ak}.
j=0
The k-th homology group Hk(S) is the factor vector space ker ∂k/ im ∂k+1. The elements
c ∈ ker ∂k are called cycles. The elements of Hk (S) represent various k-dimensional topolog-
ical features in S. A basis in Hk (S) corresponds to a set of basic topological features.
In applications the simplicial complexes are often built via consequential adding of simplices one
after another in increasing order of some numerical characteristics. Mathematically this corresponds
to the filtration on the simplicial complex. It is defined as a family of simplicial complexes Sα,
indexed by a finite set of real numbers, with nested collections of simplices: for α1 < α2 all
simplices of Sα1 are also in Sα2 .
The inclusions Sα ⊆ Sβ induce the maps on homology Hk (Sα ) → Hk (Sβ). The evolution of
cycles across the nested family of simplicial complexes Sαi is described by the principal persistent
homology theorem (Chazal & Michel, 2017; Barannikov, 1994), according to which for each dimen-
sion there exists a choice of a set of basic topological features across all nested simplicial complexes
Sα so that each basic feature c appears in Hk(Sα) at specific time α = bc and disappears at specific
time α = dc . The barcode of the filtered complex is the record of the appearence, or “birth” time,
and disappearence, or “death” time, of all these basic topological features.
A.1 Construction of R-Cross-Barcode
Here We gather some intuition behind the construction of the graph G(w,w) and the R-Cross-
Barcode. An inclusion of simple simplicial complexes S ⊂ R is an equivalence in homotopy
category, if and only if the induced map on homology is an isomorphism (Whitehead, 1968).
Therefore the maps on homology induced by the inclusions of filtered simplicial complexes
Ra(Gw ) ⊆ Ra(Gmin(W,w)), Ra(GW ) ⊆ Ra(Gmin(w，W))	(4)
should be as close as possible to isomorphisms, in order that the appoximations to manifolds MP
and MP have similar geometrical and topological features located at the same place.
It follows from the exact sequence from Theorem 1 that the R-CrOSS-BarCode* (P, P) is exactly the
list of topological features describing the failure of the maps, induced on homology by inclusions
(4), to be isomorphisms.
Cf	C 八	ɪʌ	T	/ C 二、
B Properties of R-Cross-BarCode*(P, P).
The proof of the exact homology sequence from Theorem 1 follows from the following proposition.
12
Under review as a conference paper at ICLR 2022
Figure 11: R-Cross-Barcodes for the “clusters” experiments. Top: R-Cross-Barcode(P, P), Bottom:
CC	ɪʌ	1 / 7~⅛ 7-»\ 7-» ∙ , 1	∙ , 1 Fl ∙	1	Sacxlx-YCTAI,
R-Cross-Barcode(P, P). P - is the point cloud having one cluster, P - 2, 3, 4, 5, 6, 10, 12 clusters.
Proposition 2. The embedding Ofweightedgraphs Gmm(W,W) → G(w,W)) gives the exact sequence
of chain complexes
0 → Ra(Gmm(W,W)) → Rα(Go(w, W)) → Ra(GW) → 0.	(5)
where Ra(Go(w, W)) has the same homology as Ra(G(w, W)) and Ra(GW) has the same homology
as Ra(GW) shifted by +1.
The proof follows from the straightforward construction of a homotopy to identity map.
Comparison with Cross-Barcode and Geometry score. The Cross-Barcode from (Barannikov et al.,
2021) compares two data manifolds lying in the same ambient space and can not use the information
provided by one-to-one correspondence between points. It uses instead the proximity information
inferred from the pairwise distances between points from different clouds lying in the same ambient
space. Geometry score is based on comparison of standard barcodes for each cloud and for example
does not detect any difference when similar topological features are located geometrically in very
distant places of the two clouds.
C Discussion of CKA
Given two series of equal size xi ∈ Rnx, yi ∈ Rny, i = 1 . . . n the CKA (Kornblith et al., 2019) is
defined as
CKA(K, L)
HSIC(K,L)
PHSIC(K, K)HSIC(L,L)
where HSIC(K, L) is a Hilbert-Schmidt Independence Criterion (Gretton et al., 2005), Ki,j =
k(xi,xj), Lij = l(yi,yj), L = E - n-1 where k(∙, ∙), l(∙, ∙) are kernels. HSIC itself an em-
pirical estimate of the Hilbert-Schmidt norm of the cross-covariance operator. HSIC is equivalent to
maximum mean discrepancy between the joint distribution P(X, Y ) and the product of the marginal
distributions P (X)P (Y ); HSIC = 0 implies independence of X and Y if the associated kernel is
universal.
However, CKA is sometimes applied to measure similarity between representations from different
layers of neural network. In this case Y = f(X). X and Y are tightly dependent and the joint
distribution can always be factorized as P(X, Y ) = P(Y |X)P (X). Thus, the application of CKA
to comparison of representation from different layers is questionable.
D Details on experiments with point clouds
13
Under review as a conference paper at ICLR 2022
Figure 12: R-Cross-Barcodes for the “rings” experiments. Top: R-Cross-Barcode(P, P ), Bottom:
R-Cross-Barcode(P, P). P - is the point cloud having 5 rings, P - 4, 3, 2, 1 rings.
Metrics to correlate Noise Gaussian Blur Grayscale Hue
Disagreement RTD	0.968^^0.982	0998	0982^
1-CKA	0.928	0.915	0.937	0.916
Error rate	RTD	0.984^^0.974	0.875	0.975
1-CKA	0.967	0.999	0.978	0.987
Table 6:	Analysis of ResNet-20 representations under different data distribution shifts. The correla-
tion of RTD and 1-CKA with Disagreement and Error rate.
Figure 13: Analysis of ResNet-20 representations under different data distribution shifts. The dy-
namics of scaled metrics with monotonic application of various types of image transformations.
Metrics to correlate Zoom Brightness Contrast Rotation
Disagreement^^RTD	0.956^^0.978	0.939	0.962
1-CKA	0.891	0.857	0.853	0.861
Error rate RTD	0.945^^0.922	0.938	0.945
1-CKA	0.995	0.998	0.998	0.984
Table 7:	Analysis of ResNet-20 representations under different data distribution shifts. The correla-
tion of RTD and 1-CKA with Disagreement and Error rate.
RTD 1-CKA
Disagreement 0.99	0.93
Error rate	0.91	0.99
(a)	CIFAR-100
RTD 1-CKA
Disagreement 0.92	0.89
Error rate	0.60	0.73
(b)	CIFAR-10
Table 8:	The correlation of metric dynamics when transferring the ResNet-20 network from CIFAR-
100 to CIFAR-10 dataset.
14
Under review as a conference paper at ICLR 2022
VGG-11 ResNet-20
Number of epochs	100	
Optimizer	SGD, momentum=0.9
Learning rate (initial)	01
Scheduler	<50%: 0.1 50-90%: 0.1-0.001 (linear) >90%: 0.001
Batch size	128
Table 9: Details on learning the neural networks from random initialization on CIFAR datasets.
Encoder part	Classifier part
Number of epochs		50	
Optimizer		SGD, momentum=0.9
Learning rate (initial)	0.001	0T
Scheduler	None	<50%: 0.1 50-90%: 0.1-0.001 (linear) >90%: 0.001
Batch size	128
Table 10: Details on fine-tuning the ResNet-20 from CIFAR-100 to CIFAR-10 dataset.
15