Under review as a conference paper at ICLR 2022
Disentangled Representations using Trained
Models
Anonymous authors
Paper under double-blind review
Ab stract
We propose a novel method to learn disentangled representations. The ability to
compute a disentangled representation is useful for many tasks because it contains
information about samples from a dataset in an interpretable and compact structure.
Thus development of a method that learns disentangled representations is an active
area of research. In contrast to previously proposed methods, we neither require
access to the values of the interpretable factors, nor to information about groups of
data samples which share the values of some interpretable factors. Our proposed
algorithm uses only a set of models which already have been trained on the data.
With the help of the implicit function theorem we show how, using a diverse
set of models that have already been trained on the data, to select a pair of data
points that have a common value of interpretable factors. We prove that such an
auxiliary sampler is sufficient to obtain a disentangled representation. Based on
this theoretical result, we propose a loss function that the method should optimize
to compute the disentangled representation. Our approach is easy to implement
and shows promising results in simulations.
1	Introduction
The main goal of this paper is to determine a computational method that disentangles interpretable
factors of data without access to labels. In our approach, interpretable factors are functionally
independent factors that contain all the information necessary for downstream tasks of interest. For
example, for a dataset containing photographs of animals, the set of interpretable factors can be
the type of the nose of the animal, eyes color, and so on. We note that the set of data-generating
factors may be larger than the set of interpretable factors. The background in the photos is not an
interpretable factor if all the tasks of interest are related to the classification and identification of
animals. While there is no standardized definition of disentangled representations, the key intuition is
that a disentangled representation should capture and separate the interpretable factors of the data
(Bengio, 2012; Higgins et al., 2018; Liu et al., 2021). In this paper, we assume that in a disentangled
representation, each latent dimension is a diffeomorphic function of one of the interpretable factors.
The ability to compute a disentangled representation is useful for many tasks because it contains
information about samples from a dataset in an interpretable and compact structure (Bengio et al.,
2013; Higgins et al., 2018). Interpretability of the representation helps in tasks where users interact
with a system, as they understand how it works and can provide informative feedback. Moreover,
learning a disentangled representation helps for tasks where state-of-the-art machine learning-based
approaches still struggle but where humans excel (Bengio, 2012). Such scenarios include learning
with knowledge transfer (Tommasi et al., 2010; Huang & Wang, 2013; Pan et al., 2010), zero-shot
inference (Lampert et al., 2009; Romera-Paredes & Torr, 2015) and supervised learning (Szegedy
et al., 2014; Nguyen et al., 2015). A possible reason why people successfully solve these tasks is
that they have a mental model that captures interpretable factors about the world. Algorithms that
can capture the same explanatory factors about the world as humans will have the same ability to
generalize.
The development of an algorithm that learns disentangled representations has recently become an
active area of research (Detlefsen & Hauberg, 2019; Dezfouli et al., 2019; Lorenz et al., 2019; Liu et al.,
2021). Since learning disentangled representations is possible only with inductive biases (Locatello
et al., 2019; Hyvarinen & Pajunen, 1999), methods that learn disentangled representations use some
1
Under review as a conference paper at ICLR 2022
form of supervision (Bouchacourt et al., 2018; Fumero et al., 2021; Locatello et al., 2020a). The
type of supervision ranges from full supervision (Locatello et al., 2020a; Shu et al., 2020), semi-
supervision (Locatello et al., 2020b) to weak supervision (Kazemi et al., 2019; Dubrovina et al.,
2019). These methods require either to have access to subsets of data that share the values of a group
of interpretable factors (Bouchacourt et al., 2018; Fumero et al., 2021; Locatello et al., 2020a) or to
have access to data samples with labels. (Locatello et al., 2020b).
In contrast to previous work, we neither require access to the values of the interpretable factors, nor
to groups of data samples that share common values of the interpretable factors. We obtain the groups
of data space that share common values of the interpretable factors using a set of models. More
precisely, giving a data sample x1, we use the implicit function theorem to compute the intersection
of preimages of the trained models. From the obtained intersection we select another data sample
x2 that shares the values of the interpretable factors with x1 . We prove that an auxiliary sampler
selecting such pairs of points is sufficient to compute a disentangled representation. Based on our
theory, we propose a loss function, minimizing which we can compute a data representation in which
each dimension in the learned representation is diffiomorphic to one of the interpretable factors. Our
approach is easy to implement and shows good results in simulation.
This paper is organized as follows. In Section 2, we give a definition of disentangled representations
and compare it with the commonly accepted characteristics of disentangled representations. Then we
summarize the properties of the trained models that our algorithm receives as input in the Section 3.
In Section 4, we formally define auxiliary samplers and illustrate the theory with an example. We
describe how to compute the samplers in the Section 5. Finally, we finish the paper with a summary
and discussion.
2	Disentangled representation
2.1	Definition of interpretable factors and disentangled representation
At the basis of our work is the assumption that high dimensional data D ⊂ Rn has m < n functionally
independent factors that describe all important characteristics of it. Intuitively, this assumption means
that all downstream tasks of our interest can be described as functions of m unobservable variables.
There may be other data-generating factors, but they are not informative for downstream tasks.
For example, in a dataset containing photographs of people, the background in the photographs is
irrelevant for all face identification tasks, but the background is still a data-generating factor. In the
following sentence, we formally introduce the concept of interpretable factors.
Definition 1 (interpretable factors of data). Unobserved factors z are interpretable factors of data, if
they satisfy 3 conditions:
1.	There is a map Z, such that Z := (zι(x),…，Zm(X)) ：= Z(xι, ∙∙∙ , Xn);
2.	z are functionally independent of each other i.e., the rank of the Jacobian matrix ∂dχi is
equal to m in each point of the data space;
3.	all models of interest on the data can be expressed as functions of z.
We note, that interpretable factors are often considered statistically independent. Although the
concepts of statistical and functional independence are related, they are not identical. A summary is
provided in Appendix B.
We aim to construct a disentangled representation of data, which we define as follows:
Definition 2 (disentangled representation). A disentangled representation of data with respect to
interpretable factors z is a map G : Rn → Rm such that
G(x) = (gι(x),…，gm(x)),	⑴
where gi : Rn → R equals to zi up to diffeomorphic functions ηi (i.e. ηi are smooth and invertible):
gi(x) = ηi(zi(x)), ηi : R → R.	(2)
Note that according to this definition, disentangled representations are aligned with the interpretable
factors, i.e., by permuting factors from the disentangled representation, we obtain an entangled
2
Under review as a conference paper at ICLR 2022
representation. This property of disentangled representations can be useful to create a machine
learning model that is fair or non-discriminatory (Binns, 2018). For example, we can create an
algorithm that excludes gender discrimination by having a dataset containing "gender" as the first
interpretable factor. The first latent factor in a disentangled representation for such a dataset reflects
gender. Thus, an algorithm that is invariant to changes in the first latent factor excludes discrimination
based on gender. However an algorithm that is invariant to changes in the second latent factor does
not necessarily excludes discrimination based on gender. Therefore, for this example, the alignment
between latent factors and the interpretable factors is important. To achieve this alignment, we
provide to the proposed algorithm a set of models for which it is known on which interpretable factors
they functionally depend (see Section 3).
2.2	Proposed definition of disentanglement and commonly accepted
CHARACTERISTICS OF DISENTANGLED REPRESENTATIONS
Commonly it is accepted that disentangled representations should satisfy 2 characteristics:
Characteristic 1. (Higgins et al., 2017; Bengio, 2012; Kim & Mnih, 2018) In a disentangled
representation single latent dimensions are sensitive to changes in single interpretable factors, while
being relatively invariant to changes in other factors (see Figure 1a).
Characteristic 2. (Kumar et al., 2018) In a disentangled representation a change in a single
interpetable factor causes a highly sparse change in the representation. (see Figure 1b).This property
of representations is also called completeness (Eastwood & Williams, 2018).
(a) First characteristic of disentanglement.	(b) Second characteristic of disentanglement.
Figure 1: Different characteristics of disentanglement.
Representations satisfying Definition 2 satisfy Characteristics 1. To see this, let us look at 2 data
samples x1, x2, which differ by the value of one of the factors in the disentangled representation, i.e.:
G(x1) = (s, g2,…,gm) and G(x2) = (s0, g2,…，gm), where S = s0. As each gi is an invertible
function of zi by definition of diffeomorphic functions, it follows that zi(x1) = zi(x2), ∀i 6= 1 and
z1 (x1 ) 6= z1 (x2 ). That shows that a change in a single factor in the disentangled representation
corresponds to a change in a single interpretale factor, which is Characteristic 1.
Representations satisfying Definition 2 also satisfy Characteristics 2. To see this, let us look at 2
data samples x1, x2, which differ by the value of one of the interpretable factors, i.e.: Z(x1) =
(s, z2,…,zm) and Z(x2) = (s0, z2,…，zmɔ, where S = s0. As each of gi is an invertible function
of zi by definition of diffeomorphic functions, it follows that gi(x1) = gi(x2), ∀i 6= 1 and g1(x1) 6=
g1(x2). That shows that a change in a single interpretable factor leads to a change in a single factor
in the disentangled representation, which corresponds to Characteristic 2.
3
Under review as a conference paper at ICLR 2022
2.3 Can we construct disentangled representation?
Without any additional information, our goal of constructing disentangled representation is not
reachable: there are several sets of interpretable factors for which the observable factors are the
same. Therefore, no algorithm can distinguish between different sets of interpretable factors based on
observations only and, as a consequence, create a disentangled representation corresponding only to
the chosen interpretable factors. Thus, to construct disentangled representations we make additional
assumptions, which are described in Section 3.
We give an example of different sets of interpretable factors for which the observable factors are the
same. Let z are interpretable factors, Φ is a diffeomorphic deformation of z: Φ : Rm → Rm , and
another map to interpretable factors is Z0 := Z ◦ Φ-1. Two maps Z and Z0 have the same observable
data, but different disentangled representations.
3 Assumptions
In order to be able to build a disentangled representation additional information and assumptions
are required (see Section 2.3), which we introduce in this section. Without loss of generality,
we describe assumptions for the reconstruction of g1 only. The described assumptions can be
extended in a similar way to construct other gi. In addition to the data set, the proposed method
requires access to trained models, which We denote as F := {fι,…，fk}. As any model of our
interest can be expressed as a function of interpretable factors, we can define fi : fi(Z(x)) :=
fi(x),∀fi ∈ F. We denote as F the following map: F : Rm → Rk, F(Z) = (fι(z),…，fk(z)).
As we show in Section 4.1 the preimage of F can provide information about z. However, to be able
to distinguish different points in z, we require the map F to be locally injective, i.e., we assume that
for every point z there exists a neighborhood O(z) of it in which F is injective.
The assumptions described so far are not sufficient to distinguish z1 from other generative factors.
To overcome this, for each of the models fi, our method requires information about whether f
is functionally dependent on z1 . This means that the trained models are divided into two subsets:
F =	Fd	∪	Fi,	where Fi	:=	{fι,…，力} and	Fd	:=	{力+ι,…，fk}.	Functions from	Fi	are
functionally independent of zι, i.e,, ∀fr ∈ Fi ∀z : fr(Z) = 0. Functions from Fd are functionally
dependent on zι, i.e., Yfr ∈ Fd ∃z : f(Z) = 0. We also assume, that the map Fi : RmT →
Rl, Fi(z2, ∙∙∙ ,Zm) := (f1(z2,…，Zm),…，f1(z2,…，Zm)) is locally injective. That is, for every
point zι = (z2, ∙∙∙ ,Zm) ∈ Rm-I there exists a neighborhood O(Zi) ⊂ Rm-I in which Fi is
injective. As we show in Section 4.2.2, this assumption helps to select two data samples with the
same values of zi, but different values of Zi.
Figure 2: Summary of information we provide to algorithm and assumptions we make.
4
Under review as a conference paper at ICLR 2022
The described assumptions are summarized in Figure 2. In Appendix A, we provide a formal proof
that, given the described assumptions, we can compute a disentangled representation. Having the
descriptions of the assumptions, we are now ready to provide a theory of how to compute disentangled
representation.
4 Theoretical justification of the loss function required for
COMPUTING DISENTANGLED REPRESENTATIONS
In this section, we first give an example of input data and show what the proposed method should
compute. Then we define the loss function and give its theoretical justification.
4.1	Example of the problem: input data and the outcome of the method
observable factors
trained models
Figure 3: Example of dataset containing rectangle
As an example of input data we use a dataset containing rectangles of various shapes and brightness.
Each sample from the data is described by 3 observable factors: 1.the area of the rectangle, 2.the
length + 2*width, and 3.the brightness (see Figure 3). The interpretable factors are factors predefined
by people. In this example, we consider the length and width of the rectangle as the interpretable
factors. These are interpretable factors according to definition 1, if the tasks we are interested in do
not depend on the brightness of rectangles. Examples of such problems are calculating the area of
a given rectangle or calculating the length of its diagonal. In addition to a data set, we are given 2
models: fι and f2. fι calculates the area of the rectangle, and is dependent on both interpretable
factors; f2 calculates the width of the rectangle, and is independent of the length of the rectangle (see
Figure 3).
The problem that we address in this paper is to construct a disentangled representation. A disentangled
latent representation of this dataset with respect to the length and width contains two latent factors.
One of these factors is an invertible function of the length of the rectangles. The second factor is an
invertible function of the width of the rectangles.
4.2	Theory
4.2.	1 Spurious latent factors.
The proofs below use coordinates, which we call latent factors. Specifically, the first latent factors
correspond to the interpretable factors z, while other latent factors, which we denote as y :=
(yι,…，yn-m), are any factors that are functionally independent of Z (see Appendix definition 5).
The latent factors y are not informative to downstream tasks of our interest, so we call them spurious
latent factors. We do not require access to the latent factors, but we use the fact that for each point x1
there is the neighbourhood O(x1), in which a diffeomorphism Φx→(z,y) : O(x1) → Rn is defined:
Φχ→(z,y)(x) := (Z(x),Y(x)) := (zι(x),…，Zm(x),yι(x),…，yn-m(x)).	(3)
5
Under review as a conference paper at ICLR 2022
This fact is formally proven in Appendix A.1.
To illustrate the concept of spurious latent factors we refer to the example, given in Section 4.1. For
that example, the first 2 latent factors are: 1.length and 2.width of the rectangle. The spurious
latent factor could be brightness of rectangle, but it also could be brightness of rectangle +
area of rectangle, since these factors functionally depend on the brightness of the rectangles.
4.2.2 The main idea how to construct disentangled representations
In this section, we give a theoretical justification of the loss function required to compute a
function sensitive only to changes in z1. The described theory can be used in a similar way to
compute functions sensitive to changes in other interpretable factors. To formulate the theory
properly, We give notations. We denote as Zι the following interpretable factors:
zi :=(Z2,…，Zm).	(4)
We denote the correspondent map as Z i：
Z1	:	Rn	→ Rm-1,	Zι(x)	:=(Z2(x),…，Zm(x)).	(5)
Having the notation, we are ready to formulate criteria that a function is sensitive only to changes in
zi. A function is sensitive only to changes in zi, if and only if it is invariant to changes in Zi and to
changes in spurious latent factors y.
Below we propose two loss functions reflecting the described invariances: 1. a loss function reflecting
invariance to changes in spurious latent factors; and 2. a loss function reflecting invariance to changes
in Zi.
Invariance to changes in spurious latent factors To achieve invariance to y, we show how
to sample two points, witch latent factors differ only in the values of y. To sample such pairs
of points, we use level sets of the map F ; and compute the closest point to x2 in the level set
CF(xi) := {x ∈ Rn : F ◦ Z(x) = F ◦ Z(xi)}. We denote as Mi(xi, x2) the following map:
Mi(xi,x2) := arg min Φx→(z,y) (x2) - Φx→(z,y) (x)	.	(6)
x∈CF(x1)	2
Having defined the map Mi, we give the sketch of the proof that Z(Mi(xi, x2)) = Z(xi), while
Y (Mi (xi , x2 )) = Y (x2 ) (the formal proof is given in Appendix in lemma 6).
Lemma 1. Let O(xi) is neighborhood of xi, the map F is injective in Z(O(xi)), andMi(xi, x2) ∈
O(xi), then Z(Mi(xi, x2)) = Z(xi), while Y (Mi(xi, x2)) = Y (x2).
Proof. Z(xi) ∈ Z(CF (xi)) by definition, and F is injective in Z(O(xi)). This means that
Z(CF (xi) ∩ O(xi)) = {Z(xi)}. Consequently, any point x ∈ CF (xi) ∩ O(xi) satisfies
Z(x) =Z(xi)
We proceed the proof by estimating the right side of the equation 6 and providing the point where it
achieves minimum.
:Z(m)=inZ( 1)Φx→(z,y) (x2) - Φx→(z,y) (x)2 ≥
x:Z (x)=Z (x )	2
xm∈iRnnY(x)-Y(x2)2+Z(x2)-Z(xi)2 ≥
Z(x2)-Z(xi)2
This means that the minimum is achieved only in the points with the latent factors equal to
Z(xi),Y(x2).
6
□
Under review as a conference paper at ICLR 2022
Having such pairs of data points, we define the loss function L1, which penalizes a function for
sensitivity to changes in the spurious latent variables:
L1 (g) :=	X	(g(x1) -g(M1(x1,x2)))2,	(7)
x2∈O(x1),x1∈D
where D is a data set, and O(x1) ⊂ Rn is a neighborhood of x1. The function g : Rn → R is
invariant to changes of spurious latent factors if and only if L1(g) = 0 (see formal proof in Appendix
theorem 1).
To illustrate M1 and the loss function L1 we use the example, given in the Section 4.1. We denote as
l(rec1), w(rec1), b(rec1) the length, width, and brightness of the rectangle rec1. Given two data
points rec1 and rec2, we compute M1 (rec1, rec2) using the level set CF (rec1) = {rec : l(rec) =
l(rec1), w(rec) = w(rec1)}. The closest rectangle rec ∈ CF (rec1) to rec2 is equal to
arg min (|l(rec) - l(rec2)|2 + |w(rec) - w(rec2)|2 + |b(rec) - b(rec2)|2) =
rec∈CF (rec1 )
arg min (|l(rec1) - l(rec2)|2 + |w(rec1) - w(rec2|2 + |b(rec) - b(rec2)|2) =
rec∈CF (rec1 )
arg min (|b(rec) - b(rec2)|2).
rec∈CF (rec1 )
Thus the closest rectangle rec ∈ CF (rec1) to rec2 has the following latent factors
(l(rec1), w(rec1), b(rec2)). Consequently, L1 penalises g when its values differ on a rectangle with
(l(rec1), w(rec1), b(rec2)) and on a rectangle with (l(rec1), w(rec1), b(rec1)).
Invariance to changes in interpretable latent factors Zι We achieve invariance to changes in
Zι in a similar way as We achieve invariance to changes in spurious latent factors. The only
difference is that we sample two points, which latent factors differ only in the values of Zι. To
sample such pairs of data points, we compute M2(x1, x2) - the closest point to x1 in the level set
CFi (x2) := {x ∈ Rn : Fi ◦ Z(x) = Fi ◦ Z(x1)}. The latent factors of the map M2 satisfy that
z1(M2(x1, x2)) = z1(x1), Y (M2 (x1, x2)) = Y (x1), Z1(M2(x1, x2)) = Z1(x2). The proof of this
fact is analogous of the proof of Lemma 1 and is formally given in Appendix in lemma 7.
Having such pairs of data points, we define the loss function L2,which penalizes a function for
sensitivity to changes in Zi：
L2(g) :=	X	(g(x1) - g(M2(x1,x2)))2,	(8)
x2∈O(x1),x1∈D
where D is a data set, and O(x1) ⊂ Rn is a neighborhood of x1. The function g : Rn → R is
invariant to changes of the interpratable factors Zi if and only if L2 (g) = 0 (the formal proof is given
in Appendix theorem 1).
Having the description of the two loss functions L1 and L2 , we are now ready to provide a method
for computing g1 .
5 Computation of the loss function
In this section, we describe the loss function required to compute a function diffeomorphic to z1(x).
This loss function consists of 3 components：
L := L1 + L2 + L3.
(9)
A function g can be expressed as a function of z1 if and only if it minimizes L1 + L2 (see Section 4.2).
L3 addresses the problem that any constant function minimizes L1 + L2 (L3 is defined below in the
equation 12).
The proposed method, which we denote as Aux2samp, uses 2 auxiliary samplers. The auxiliary
sampler M1(x1, x2) is equal to the closest point to x2 in the level set CF (x1) (see Section 4.2.2).
We compute M1 (x1 , x2 ) by minimizing the following expression：
Mi (x1, x2) = arg min ((1- μ) JF(X)- F(XI)I+ 仙 J|x - x2()，	(⑼
7
Under review as a conference paper at ICLR 2022
where μ ∈ (0,1) is the hyper parameter of the algorithm. The first part of the optimization functional
expresses that x is in the level set CF(x1). The second part expresses that x is close to x2. The hyper
parameter μ reflects the relative importance of these conditions. Since it is important for invariance to
spurious latent factors that z1(M1(x1, x2)) = z1(x1) and y(M1(x1, x2)) 6= y(x1), we recommend
choosing μ to be less than 0.5.
The second auxiliary sampler M2(x1, x2) is equal to the closest point to x1 in the level set CFi (x2)
(see Section 4.2.2). We compute M2(x1, x2) by minimizing the following expression:
M2 (x1, x2) = argmin ((1 - λ) IFi (X)- Fi(X2)∣∣2 + λ ∙∣∣x - x1 ID ,	(11)
where λ ∈ (0, 1) is the hyper parameter of the algorithm. The first part of the optimization functional
expresses that x is in the level set CFi (x2). The second part expresses that x is close to x1. The hyper
parameter λ reflects the relative importance of these conditions. Since it is important for invariance
to latent factors Zι that z1(M2(x1, x2)) = z1(x1) and Z1(M2(x1, x2)) = Z1(χ1), We recommend
choosing λ to be more than 0.5 (See Appendix A.3.3 for details on the connection between the
theory in Section 4.2 and the proposed optimization problems.)
The last component of the loss function, given the data set D, is defined by the following expression:
L3(g) := (Fvar(D,g) - 1)2,	(12)
where Fvar (D, g) := J1 PPχi∈ D (g (Xi ) - Fmean (D, g)) , Fmean(D, g) := k PPχi∈ D g(x' ).
The loss function L3(g) reflects that the output of the function g is normalized, i.e. the expec-
tation of the g(x) is 0, while the variance of g(x) is equal to 1. Computation of the loss function L is
summarized in Algorithm 1.
Algorithm 1 Computation of the loss function L
Require: Number of samples N, data set D, models F and Fi , function g : Rn → R
1:	Randomly sample 4 ∙ N data points D J {(x1,i,…，x4,i), i = 1,…，N}
2:	for i ≤ N do
3:	mj	J argmij	((1	- μ)	∙ ∣∣F(X) - F(X1,i)∣∣ + μ ∙ ∣∣x - x2,i∣∣j)
4:	m2	J argmij	((1	— λ)	∙ ∣∣Fi(X) — Fi (x3,i)∣∣ + λ ∙ ∣∣x — x4,i∣∣2)
5:	end for
6:	LJ ΣN=i∣∣m1 - g(x1,i)∣∣2 + ΣN=i∣∣m2 - g(x3,i)∣∣2 + (fvar Mg)- 1^
6 Experiment
6.1	Data preprocessing
To minimize the loss functions L1 and L2, we must minimize the distance between the points
∣x - x1 ∣2. If one of observable features has much higher variance than others, its value will
dominate the optimization process. To avoid this, we standardize the observable features to have
mean 0 and variance 1:
xi
xi - Fm
ean(D, xi)
Fvar(D, xi)
where X = (xι,…，Xn).
(13)
Moreover, to minimize the loss functions L1 and L2, we must also minimize the distance
∣∣ F(X) — F(x1) ∣∣ . If one of the models has much higher variance than others, its value will dominate
the optimization process. Thus, we also normalize output of the functions from F to have mean 0
and variance 1:
〜
~
¥	(n ʃʌ
f - Fmean(D, f)
f s-----------工---,∀f ∈ F.
Fvar(D,f)
(14)
8
Under review as a conference paper at ICLR 2022
6.2	Experiment
2
§
CM
hidden layer	hidden layer	hidden layer	hidden layer
dimension 30	dimension 15	dimension 30	dimension 150
Figure 4: Result of recovering latent variable using proposed approach.
To test the performance of the proposed approach, we applied it to artificial data. In the experiments
we model z as a result of 2 layer neural network with relu (Agarap, 2018) nonlinearity acting on the
input observable variables:
Z(X) = Az,2 ∙ relu(Az,ι ∙ x),	(15)
where Az,1 and Az,2 are randomly initialized matrices. In our experiment, the functions from Fd are
2 layer neural networks with relu (Agarap, 2018) nonlinearity:
-τ,	.	,.	一 ..
f(x) = Afd,2 ∙ relu(Afd,ι ∙ Z(x)),	(16)
where Afd,1 and Afd,2 are randomly initialized matrices. The functions from Fi are 2 layer neural
networks with relu (Agarap, 2018) nonlinearity:
f(x) = Afi,2 ∙ relu(Afi,ι ∙ ZI(X)),	(17)
where Afi,1 and Afi,2 are randomly initialized matrices. We model g as a fully connected neural
network with 2 layers and relu noninearity and find parameters of it by minimizing the loss function
described in Equation 9. To measure Aux2samp performance, we use linear regressor. This linear
regression is trained to predict z1 by taking as input g, g2, ..., g5. We use the R2 score of a trained
linear model as a measure of the performance of Aux2samp.
We conduct experiments using several experimental conditions. In our experiments, we vary the
dimension of the feature space, the dimension of the hidden space and the number of neurons in
the hidden layer of the neural network. We repeat all experiments 10 times to obtain statistically
significant results.
The proposed algorithm shows good results independently of the dimension of the feature space, the
dimension of the hidden space and the number of neurons in the hidden layer of the neural network
(see Figure 4). Specifically, the linear regression used to predict z1 has R2 score equal to 0.7 - 0.8.
Whereas linear regression, which predicts zi, i = 1, using g,g2,…，g5 as a feature vector, has R2
score less than 0.001.
7 Conclusion
In this paper we propose a method Aux2samp to disentangle interpretable factors. Aux2samp requires
a set of trained models at the input. The implicit function theorem allows us to compute preimages
of the trained models and to select a pair of data points that have a common value of interpretable
factors. We propose a loss function that uses these pairs of data points, and prove that by minimizing
it, we obtain a disentangled representation. Based on our theory, we propose a simple recipe to
compute disentangled representations in practice. In contrast with previous work the proposed
method neither require labels nor information about groups of data samples which share the values of
some interpretable factors. Our method is easy to implement and shows good results in simulation,
independently of the dimension of features space and the number of interpretable factors.
9
Under review as a conference paper at ICLR 2022
References
Abien Fred Agarap. Deep learning using rectified linear units (relu). CoRR, abs/1803.08375, 2018.
Yoshua Bengio. Deep learning of representations for unsupervised and transfer learning. In Proceed-
ings ofICML workshop on unsupervised and transfer learning, pp. 17-36. JMLR Workshop and
Conference Proceedings, 2012.
Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new
perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8):1798-1828,
2013.
Reuben Binns. Fairness in machine learning: Lessons from political philosophy. In Conference on
Fairness, Accountability and Transparency, pp. 149-159. PMLR, 2018.
Diane Bouchacourt, Ryota Tomioka, and Sebastian Nowozin. Multi-level variational autoencoder:
Learning disentangled representations from grouped observations. In Proceedings of the AAAI
Conference on Artificial Intelligence, volume 32, 2018.
Nicki Skafte Detlefsen and S0ren Hauberg. Explicit disentanglement of appearance and perspective
in generative models. In Advances in neural information processing systems, pp. 1016-1026, 2019.
Amir Dezfouli, Hassan Ashtiani, Omar Ghattas, Richard Nock, Peter Dayan, and Cheng Soon Ong.
Disentangled behavioral representations. bioRxiv, pp. 658252, 2019.
Anastasia Dubrovina, Fei Xia, Panos Achlioptas, Mira Shalah, Raphael Groscot, and Leonidas J
Guibas. Composite shape modeling via latent space factorization. In Proceedings of the IEEE/CVF
International Conference on Computer Vision, pp. 8140-8149, 2019.
Cian Eastwood and Christopher KI Williams. A framework for the quantitative evaluation of
disentangled representations. In ICLR, 2018.
Marco Fumero, Luca Cosmo, Simone Melzi, and Emanuele Rodola. Learning disentangled represen-
tations via product manifold projection. In Proceedings of the 38th International Conference on
Machine Learning, volume 139, pp. 3530-3540. PMLR, 2021.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a
constrained variational framework. In ICLR, 2017.
Irina Higgins, David Amos, David Pfau, Sebastien Racaniere, Loic Matthey, Danilo Rezende,
and Alexander Lerchner. Towards a definition of disentangled representations. arXiv preprint
arXiv:1812.02230, 2018.
De-An Huang and Yu-Chiang Frank Wang. Coupled dictionary and feature space learning with
applications to cross-domain image synthesis and recognition. In Proceedings of the IEEE
international conference on computer vision, pp. 2496-2503, 2013.
Aapo Hyvarinen and Petteri Pajunen. Nonlinear independent component analysis: Existence and
uniqueness results. Neural networks, 12(3):429-439, 1999.
Hadi Kazemi, Seyed Mehdi Iranmanesh, and Nasser Nasrabadi. Style and content disentanglement in
generative adversarial networks. In 2019 IEEE Winter Conference on Applications of Computer
Vision (WACV), pp. 848-856. IEEE, 2019.
Hyunjik Kim and Andriy Mnih. Disentangling by factorising. In Proceedings of the 35th International
Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp.
2654-2663. PMLR, 2018.
Steven G Krantz and Harold R Parks. The implicit function theorem: history, theory, and applications.
Springer Science & Business Media, 2012.
Abhishek Kumar, Prasanna Sattigeri, and Avinash Balakrishnan. Variational inference of disentan-
gled latent concepts from unlabeled observations. In 6th International Conference on Learning
Representations, 2018.
10
Under review as a conference paper at ICLR 2022
Christoph H Lampert, Hannes Nickisch, and Stefan Harmeling. Learning to detect unseen object
classes by between-class attribute transfer. In Proceedings of the IEEE Computer Vision and
Pattern Recognition Conference,pp. 951-958, 2009.
Xiao Liu, Pedro Sanchez, Spyridon Thermos, Alison Q O’Neil, and Sotirios A Tsaftaris. A tutorial
on learning disentangled representations in the imaging domain. arXiv preprint arXiv:2108.12043,
2021.
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Scholkopf,
and Olivier Bachem. Challenging common assumptions in the unsupervised learning of disentan-
gled representations. In Proceedings of the 36th International Conference on Machine Learning,
pp. 4114-4124. PMLR, 2019.
Francesco Locatello, Ben Poole, Gunnar Ratsch, Bernhard Scholkopf, Olivier Bachem, and Michael
Tschannen. Weakly-supervised disentanglement without compromises. In International Conference
on Machine Learning, pp. 6348-6359. PMLR, 2020a.
Francesco Locatello, Michael Tschannen, Stefan Bauer, Gunnar Ratsch, Bernhard Scholkopf, and
Olivier Bachem. Disentangling factors of variation using few labels. In 8th International Confer-
ence on Learning Representations, 2020b.
Dominik Lorenz, Leonard Bereska, Timo Milbich, and Bjorn Ommer. Unsupervised part-based
disentangling of object shape and appearance. In IEEE Conference on Computer Vision and Pattern
Recognition, pp. 10955-10964. Computer Vision Foundation / IEEE, 2019.
Anh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High confidence
predictions for unrecognizable images. In Proceedings of the IEEE conference on computer vision
and pattern recognition, pp. 427-436, 2015.
Sinno Jialin Pan, Qiang Yang, et al. A survey on transfer learning. IEEE Transactions on Knowledge
and Data Engineering, 22(10):1345-1359, 2010.
Bernardino Romera-Paredes and Philip Torr. An embarrassingly simple approach to zero-shot
learning. In International Conference on Machine Learning, pp. 2152-2161, 2015.
Rui Shu, Yining Chen, Abhishek Kumar, Stefano Ermon, and Ben Poole. Weakly supervised
disentanglement with guarantees. In 8th International Conference on Learning Representations,
2020.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. In 2nd International Conference on
Learning Representations, 2014.
Tatiana Tommasi, Francesco Orabona, and Barbara Caputo. Safety in numbers: Learning categories
from few examples with multi model knowledge transfer. In Proceedings of the IEEE Computer
Vision and Pattern Recognition Conference, pp. 3081-3088, 2010.
11
Under review as a conference paper at ICLR 2022
A Theory
A. 1 Choosing local coordinates
Before giving the theory we make some preparation steps. First, we choose convenient local
coordinates on data D. Then we choose local coordinate maps existing in L∞-balls.
Definition 3 (L∞-ball). L∞ -ball with radius c and the center a is the following set {x ∈ Rn :
|x - aL∞ < c, a ∈ Rn, C ∈ R}∙
L∞-balls possesses the property that if 2 points p1, p2 are in one L∞-ball, then the point p3 for
which each coordinate is equal to the corresponding coordinate of p1 or p2 is in the same L∞-ball.
We need this property of L∞-balls in lemma 3.
Formally, we choose the coordinates in Rn such that the first m coordinates on D correspond to
interpretable factors z. Specifically, we choose Y : Rn → Rn-m to be a map such that the map
Φx→(z,y) : Rn → Rn, Φx→(z,y) (x) := (Z(x),Y (x))	(18)
has rank of Jacobian dφx→(Z'y) is equal to n. Such map always exists see Lemma 4.4.7 from (Krantz
& Parks, 2012).	j
In the following lemma we construct the local coordinate maps existing in L∞-balls.
Lemma 2. Lets D ⊂ Rn is a compact subset. Then we can choose a finite open cover ∪ir=1Oi of
D ⊂ Rn, such that
1.	Φx→(z,y) is diffeomorphism in each of Oi
2.	Φx→(z,y) (Oi) ⊂ Rn is an open L∞-ball.
Proof. We denote as O(x1) epsilon neighbourhood of x ∈ Rn:
O(x1) := x ∈ Rn :x1 - x <	.	(19)
As the rank of Jacobian of Φx→(z,y) is equal to n, for each point x ∈ Rn ∃ > 0 such that Φx→(z,y)
is diffiomorphism in O (x). Thus, by the definition of diffiomorphism, it is defined the inverse
function of Φx→(z,y) on Φx→(z,y) (O(x)), which depends on x:
Φ(xz,y)→x:= Φx-→1 (z,y)|O(x),	(20)
We can choose L∞-ball V(x) ⊂ Φx→(z,y) (O(x)), such that Φx→(z,y) (x) ∈ V(x). The preimage
of V (x) is open subset in Rn, which we denote as
O(x) := Φx-→1 (z,y)(V(x)) ∩ O(x).
But ∪x∈DO(x) is an open cover of the compact set D. Thus we can choose a finite cover of D
consisting of some sets O(x).	口
Thus we construct
1.	a coordinate map Φx→(z,y)
2.	its inverse Φ(xz,y)→x, which depends on x
3.	the open cover ∪ir=1Oi as in the lemma 2
In what follow next we assume that these maps and the open cover are fixed.
12
Under review as a conference paper at ICLR 2022
A.2 Main theorem
Before moving further We need one more notation. We denote as Z1 the projection to (z2,…，zm,),
i.e.:
Z1: Rn → Rm-1 , Zl(x) :=(Z2,…，Zm)	(21)
In the folloWing lemma We implicitly define 2 family of transformations M1 and M2 . M1 alloWs
us to create pairs of points With the same values of z coordinates, but With different values of y
coordinates. Having infinitely many such pairs of points We can design a function to be invariant to
changes in y, Which is shoWn in the theorem 1.
M2 alloWs us to create pairs of points With the same values of z1 and y coordinates, but With different
values of (z2,…，zm) coordinates. Having infinitely many such pairs of points we can design a
function to be invariant to changes in (z2,…，zm), which is shown in the theorem 1.
Lemma 3. There are 2 families of transformations M1 = {M1,i : Oi × Oi → Oi} and M2 =
{M2,i : Oi × Oi → Oi } which are implicitly defined by the following properties:
Φχ→(z,y) ◦ M1,i(x1, x2) = (z1 (x1), Z1(x1), Y(x2)), ∀x1, x2 ∈ Oi.	(22)
and
Φχ→(z,y) ◦ M2,i(x1, x2) = (z1(x2), Z 1(x1 ),Y(x2)), ∀x1, x2 ∈ Oi,	(23)
Proof. As we choose Oi such that Φx→(z,y) (Oi) is L∞-ball we can always choose points in Oi that
satisfy conditions for M1,i and M2,i. The image of M1,i, M2,i contains no more than one point from
any level set of Φχ→(z,y), because Φχ→(z,y) is diffiomorphism on Oi.	□
We denote as M1 the map equals to M1,i(x1, x2), where x1, x2 ∈ Oi. We denote as M2 the map
equals to M2,i(x1, x2), where x1, x2 ∈ Oi.
Before giving our main theorem, we remind the definition of directional derivative
Definition 4 (Directional derivative). g is a function defined in a neighborhood of x ∈ Rn and
differentiable at x. If t : [-, ] → Rn is a differentiable curve such that t(0) = x, then the
directional derivative of g along t can be defined as follows:
∂g
∂t
d
dTg ◦ t(T )τ =0
(24)
In our main theorem we give the necessary and sufficient conditions the function g : Rn → R to be
locally invariant towards the changes of zi , yj for i 6= 1, 1 ≤ j ≤ m - n. Specifically, we define 2
loss functions
L1(g, x1, x2) := (g(x1) - g(M1(x1, x2)))2	(25)
and
L2(g, x3, x4) := (g(x3) - g(M2(x4, x3)))2	(26)
We prove that the necessary and sufficient condition for the invariance of the function to changes in y
is the minimization of L1 , which is defined by following equations
L1(g) :=	X	L1(g, x1, x2)	(27)
x1∈D,x2∈O(x1)
We also prove that the necessary and sufficient condition for the invariance of the function to changes
in (z2, ∙∙∙ ,zm) is the minimization of L2
L2(g) :=	X	L2 (g, x3, x4)	(28)
x3∈D,x4∈O(x3)
Formally,
13
Under review as a conference paper at ICLR 2022
Theorem 1. We denote
txi (C)= φXz,y)→x (X + 〜Zi)	(29)
tXi (c) = φXz,y)→x(X + 〜yi)	(3O)
Let g is a function invariant to changes in variables caused by M1 or M2, i.e. we assume:
1.	For every point X1 ∈ D exists small number C > 0 such that L1 (g, X1, X2) = 0 for any
point X2 ∈ O(X1)
2.	For every point X3 ∈ D exists small number C > 0 such that L2 (g, X3, X4) = 0 for any
point X4 ∈ O(X3)
Then ∂dtgX- =0, ∀x ∈ D, 1 < i ≤ m.
zi
and ∂dg- = 0, ∀x ∈ D, 0 < i ≤ n 一 m,
∂tyi
The proof of the theorem contains of 2 lemmas. The notations in lemmas are the same as in the
theorem 1.
Lemma 4. If for every point x1 ∈ D exists small number C > 0 such that
g(x2) = g(M1 (x2, x1)) ∀x2 ∈ O(x1)
then ∂tg- = 0, ∀x ∈ D, 0 < i ≤ n 一 m,
yi
Proof. Our proof is by contradiction. Lets assume that exists x1 ∈ D such that Sdtx ) = 0. Then
∂tyi
∃C > 0 : g(x1) 6= g(tyx (C)). We choose C to be small enough, such that x2 := tyx (C) is in Op (x1)
from the condition of the lemma.
Φx→(z,y)(M1,i(x2, x1)) = (Z(x2), Y (x1)) = Φx→(z,y) (x1).
M1,i(x2, x1)) = x1, as Φx→(z,y) diffiomorphism on Oi and M1,i(x2, x1) ∈ Oi.
From assumptions of the lemma g(x2) = g(M1,i(x2, x1)) = g(x1). We achieve contradiction. □
Lemma 5. Iffor every point x3 ∈ D exists small number C > 0 such that
g(x4) = g(M2(x3, x4)), ∀x4 ∈ O(x3).
Then ∂tg- = 0, ∀x ∈ D, 1 < i ≤ m.
Proof. Our proof is by contradiction. Lets assume that exists x3 ∈ D such that d*tx ) = 0. Then
zi
∃C > 0 : g(p3x) 6= g(tzxi (C)). We choose C to be small enough such that x4 := tzxi (C) is in O(x3)
from the second condition of the lemma.
Φχ→(z,y)(M2,i(x3, x4)) = (z3(x4),P z3 (x3),Y (x4 )) = Φχ→(z,y)(x3).
M2,i(x3, x4) = x3 as Φx→(z,y) diffiomorphism on Oi and M2,i(x4, x3) ∈ Oi. From assumptions
of the lemma g(x4) = g(M2,i(x4, x3)) = g(x3). We achieve contradiction.
□
Theorem 1 reduces the problem of constructing a function invariant to changes of (z2,…，Zm) and
y to an optimization problem of minimizing 2 loss functions L1 (g) and L2 (g). The last step is to
build M1 and M2 explicitly.
14
Under review as a conference paper at ICLR 2022
A.3 Constructing auxiliary maps
A.3.1 EXPLICIT CONSTRUCTION OF M1
Lemma 6 reduces the problem of constructing M1 to a simple optimisation problem. More specifically,
if CF (x1) ⊂ Rn is a level set:
CF(x1) = {x ∈ Rn : F(X) = F(X1)}
then	M1,i(x1, x2)	can be calculated by finding a point x that minimises
∣∣Φχ→(z,y)(x2) — Φχ→(z,y)(x)( on the level set CF(x1) ∩ Oi.
Lemma 6. Lets F : Rm → Rl is injective map in Z(Oi). We denote as CF(x1) ⊂ Rn the level set:
CF(x1) = {x ∈ Rn : F ◦ Z(x) = F ◦ Z(x1)}.	(31)
M1,i defined in lemma 3 is equal to
M1,i(x1, x2) = arg min ∣∣Φx→(z,y)(x2) - Φx→(z,y) (x)∣∣ .	(32)
Proof. Z(x1) ∈ Z(CF(x1)) by definition, and F is injective in Z(Oi). This means that Z(CF(x1)∩
Oi) = {Z(x1)}. Consequently, any point x ∈ CF(x1) ∩ Oi satisfies
Z(x) =Z(x1)
We proceed the proof by estimating the right side of the equation 32 and providing the point where it
achieves minimum.
:Z(m)inZ( 1)∣∣Φx→(z,y)(x2) - Φx→(z,y)(x)∣∣2 ≥
x:Z (x)=Z (x )	2
xm∈iRnn∣∣∣Y(x)-Y(x2)∣∣∣2+∣∣∣Z(x2)-Z(x1)∣∣∣2 ≥
∣∣∣Z(x2)-Z(x1)∣∣∣2
This means that the minimum is achieved only in the points with the coordinates
Z(x1),Y(x2).
We note that Φx→(z,y) (Oi) is a L∞-ball and Φx→(z,y) is diffiomorphism on Oi. This involves that
∃!x3 ∈ Oi such that Φχ→(z,y)(x3) = (Z(x1),Y(x2)).	□
A.3.2 EXPLICIT CONSTRUCTION OF M2
Lemma 7 reduces the problem of constructing M2 to a simple optimisation problem. More specifically,
if CFi(XI) is a level set:
CFi(x1) = {x ∈ Rn ： Fi(X) = Fi(XI)},
then	M2,i(x1, x2)	can be calculated by finding a point x that minimises
∣∣Φχ→(z,y)(x2) - Φχ→(z,y)(x)∣L Onthelevelset CFi(x1) ∩ Oi.
Lemma 7. Lets Fi : RmT → RkTis injective map in Zι(Oi). We denote as CFi (x1) ⊂ Rn the
level set:
CFi(x1) := {x ∈ Rn : Fi ◦ Z(x) = Fi ◦Z(x1)}.	(33)
M2,i defined in lemma 3 is equal to
M2,i(x1,x2) = arg min ∣∣Φx→(z,y)(x2) - Φx→(z,y) (x)∣∣ .	(34)
x∈CFi (x1)∩Oi	2
15
Under review as a conference paper at ICLR 2022
Proof. Z 1(x1) ∈ Zi(Cfi(x1)) by definition and Fi is injective in Zι(Oi). This means that
Zi(Cfi(x1) ∩ Oi) = {Z 1(x1)}. Consequently, the projection on (z2,…，Zm) of any point X ∈
CFi(x1) ∩ Oi coincides with the corresponding projection of x1:
Z1 (x) = Z 1(x1)
Our prove consists of estimating the right side of the equation 34 and providing the point where it
achieves minimum.
亍，min , J∣φχ→(z,y)(X2)- φχ→(z,y)(X)IL ≥
x:Z1(x)=Z1(x1)	2
χ∈∈Rn ((zι(χ)- zι (x2))2 +∣∣Y(X)- Y (χ2)∣∣2+∣∣Z ι(χ2)- Z1 (XI)II2) ≥
I佟 1(X2)- Z1 (X1)∣∣2
This means that the minimum is achieved only in the points with the coordinates
(zι(x2),Zi(x1),Υ(x2)).
Φx→(z,y) (Oi) is a L∞-ball and Φx→(z,y) is diffiomorphism on Oi. This involves that ∃!X3 ∈ Oi
such that Φχ→(z,y)(x3) = (zι(x2),Z 1(x1),Y(x2)).	□
A.3.3 Practical implementation of auxiliary maps
M1 (Eq. 32) and M2 (Eq. 34) are defined using the map Φx→(z,y). We do not have access to
Φx→(z,y), so in our implementation we use a reasonable replacement of it. More specifically, we
assume that Φx→(z,y) is Lipschitz in D (which is a natural assumption as any function with bounded
first derivative on compact set is Lipschitz). Lets the Lipschitz constant is equal to c, then
∣∣φx→(z,y)(x2) - φχ→(z,y)(X)∣∣2 ≤ C ∙∣∣x2 - x∣∣2 .	(35)
Thus, instead of minimising ∣∣Φx→(z,y) (x2) - Φx→(z,y) (x)∣∣ we minimise ∣∣x2 - x∣∣2.
B Comparison between statistically independent and
functionally independent variables.
Definition 5 (functional independence). We say that z1, ..., zm are functionally dependent if there is
an open subset U ∈ Rm such that p((zι, •…,Zn) ∈ U) > 0 and a differentialfunction Φ : Rm → R
such that Φ(z1, ..., zm) = 0 ∀z ∈ U. Moreover, gradient of Φ(z) is not equal to 0∀z ∈ U. Otherwise
Z1 , ..., Zm are functionally independent.
Functional independence and statistical independence are different concepts. Indeed, variables can
be statistically dependent, but functionally independent.
B.0.1 Example of statistically dependent variables which are functionally
INDEPENDENT
For this example we introduce some notations:
•	Let a, b ∈ R and a < b. Then we denote as ξ 〜U [a, b] a random variable ξ that has uniform
distribution in the segment [a, b].
•	We denote as Iξ∈[a,b] a random variable that is equal to 1 if and only if ξ ∈ [a, b]. Otherwise
it equals to 0.
16
Under review as a conference paper at ICLR 2022
We give an example of 2 random variables that are statistically dependent, but functionally indepen-
dent. Let xi 〜 U[0,1] is a random variables that is uniformly distributed in [0,1], and let
_ ʃ ~ U[0,0.5] if xi ∈ [0,0.5]
x2 := ɪ ~ U[0.5,1] if x1 ∈ [0.5,1]
First, we assert that xi and x2 are statistically dependent variables. Indeed,
p(xi < 0.5, x2 > 0.5) = 0 = p(xi < 0.5) ∙ p(x2 > 0.5) = 0.25.	(36)
Now we prove that xi and x2 are functionally independent. Indeed, if they would be functionally
dependent on the subset U with measure more than 0, then they will be dependent on some subset Ui
with measure more than 0 which lies in either xi < 0.5, x2 < 0.5 or in xi > 0.5, x2 > 0.5. Without
loss of generality we can assume that Ui lies in xi < 0.5, x2 < 0.5. Than by implicit function
theorem Krantz & Parks (2012) there is some function φ such that zi = φ(z2) on some open space in
xi < 0.5, x2 < 0.5. But this contradict our assumption on distribution ofxi and x2.
B.0.2 Example of statistically independent variables which are functionally
DEPENDENT
In this subsection we give an example of 2 random variables that are statistically independent, but
functionally dependent. Assume that there are 2 independent identically distributed discrete random
variables xi , x2
p(xi = 0) = p(x2 = 0) = 0.5,
p(xi = 1) = p(x2 = 1) = 0.5,
p(xi = a) = p(x2 = b) = 0 ∀a, b ∈/ {0, 1}
These variables are statistically independent. But xi , x2 are functionally dependent. Indeed, the
function
Φ := xi + x2	(37)
is equal to 0 in the interval U := (-0.5, 0.5), and
p(xi, x2 ∈ U) = p(xi = 0, x2 = 0) = 0.25 > 0	(38)
However, if the distribution of random variables is continuous, we cannot give such an example:
when statistically independent variables have continuous distributions, then these variables are also
functionally independent.
B.0.3 Connection between statistically independent random variables with
CONTINUOUS DISTRIBUTION AND FUNCTIONAL INDEPENDENCE
In this section we formally prove that statistically independent variables with continuous distributions
are also functionally independent.
Fact 1. Let zi, ∙…Zm are random variables with the distributions Fi. Lets Fi is equal to 0 outside of
some interval Ui and is continuous on Ui. Moreover,
p(zi ∈ U ) > 0 ∀open set U ⊂ Ui	(39)
Thenfromfunctional dependence of zi, ∙…Zm follows their statistical dependence.
Proof. Let zi, ..., zm are functionally dependent. Then we can choose some open subset U ⊂ Rm
such thatp(Zi, ..., Zm ∈ U) > 0, and differentiable function F such that F(Zi, ..., Zm) = 0 in U.
Let z0 is interior point in Ue and z0 ∈ Ui. Without loss of generality We can assume that 芸 |z。= 0.
Then by inverse function theorem Krantz & Parks (2012) there is an open set U1 containing z0, and
a continuous function f such that
Zi = f(Z2, ...,Zm)	(40)
Lets zi ∈ Ue1 such that Zii 6= Zi0, and let Ue2 (Zii) ⊂ Ui — is open subset Which contains Zii but
does not contain Zi0 . As f is a continuous functions there is an open subset Ve ⊂ Rm-i such that
Ue2(zl) ∩ f (Ve) = 0. Then
p(Zi ∈ Ue2 (Zi ), (Z2 , ..., Zm ) ∈ Ve ) = 0
17
Under review as a conference paper at ICLR 2022
But
p(zi ∈ U62 (z1)) ∙ P((Z2,…，Zm) ∈ ve) > 0.
Which ends the proof that z1, ..., zm are statistically dependent.
□
18