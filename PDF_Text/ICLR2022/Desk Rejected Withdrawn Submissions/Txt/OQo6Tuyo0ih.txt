Under review as a conference paper at ICLR 2021
Interpretable multi-hop reasoning for Fore-
casting on Temporal Knowledge Graphs
Anonymous authors
Paper under double-blind review
Ab stract
Temporal knowledge graphs (KGs) have recently attracted growing attention. The
temporal KG forecasting task, which plays a crucial role in applications such as
event prediction, is predicting future links based on historical facts. The inter-
pretability of the current temporal KG forecasting models is manifested in provid-
ing the reasoning paths. However, the comparison of reasoning paths is operated
under the black box. Inspired by the observation that reasoning based on multi-
hop paths is equivalent to answering questions step by step, this paper designs
an Interpretable Multi-hop Reasoning (IMR) model for temporal KG forecasting.
IMR transforms reasoning based on path searching into step-by-step question an-
swering. Moreover, IMR designs three indicators according to the characteristics
of temporal KGs and reasoning paths: question matching degree, answer com-
pleting level and path confidence. Unlike other models that can only utilize paths
with a specified hop, IMR can effectively integrate paths of different hops; IMR
can provide the reasoning paths like other interpretable models and further explain
the basis for path comparison. While being more explainable, IMR has achieved
state-of-the-art on four baseline datasets.
1	Introduction
Knowledge Graphs (KGs) are collections of triples, such as Freebase (Bordes et al., 2013), YAGO
(Suchanek et al., 2008). Temporal KGs introduce a new dimension into static knowledge graphs (Li
et al., 2021), i.e., a timestamp for every triple to form a quadruple. Although there are billions of
triples in KGs, they are still incomplete. These incomplete knowledge bases will bring limitations to
practical applications. Since temporal KGs involve the time dimension, the completion of temporal
KGs can be divided into interpolation and forecasting. The former utilizes the facts of all times-
tamps to predict the triples at a particular moment; the latter employs historical facts to predict the
future triples. Due to the importance of temporal KG forecasting in event prediction, it has recently
attracted growing attention. This paper mainly focuses on temporal KG forecasting.
Most of the current researches on the temporal KG completion focus on interpolation (Jin et al.,
2019; Garcla-Duran et al., 2018; XU et al., 2020a; JUng et al., 2021; Han et al., 2021; WU et al.,
2020). There have been recent attempts to investigate temporal KG forecasting (Jin et al., 2019;
Han et al., 2021; Li et al., 2021; ZhU et al., 2020). According to the interpretability, researches
on temporal KG forecasting can be divided into two categories. One type is the black-box model,
which jUst design a Unexplainable scoring fUnction for evalUating the rationality of qUadrUples. The
other type is interpretable approaches. CyGNet (ZhU et al., 2020) Utilizes 1-hop repetitive facts to
realize prediction. The performance of CyGNet is limited by lacking direct repetitive knowledge
in historical moments. xERTR (Han et al., 2021), ClUSTeR (Li et al., 2021) and TITer (SUn et al.,
2021) are both path-based temporal KG forecasting models. xERTR (Han et al., 2021) adopts the
inference sUbgraphs to aggregate local information aroUnd the qUery. ClUSTeR (Li et al., 2021)
and TITer (SUn et al., 2021) manipUlate reinforcement learning for path search and improves the
performance throUgh temporal reasoning.
However, these models cannot effectively combine paths with different hops for reasoning. xERTR
(Han et al., 2021) can only Utilize the path with the specified hop. The experiments of ClUSTeR (Li
et al., 2021) illUstrate that the performance with the maximUm hop set to 2 is not as good as that
with the maximUm hop set to 1, which is not in line with common sense. AlthoUgh these models
1
Under review as a conference paper at ICLR 2021
can present the reasoning paths, they lack an explanation of the preference for various paths, i.e., the
models cannot provide the basis for path comparison.
In practice, forecasting based on path searching is to find the appropriate multi-hop paths, the com-
bination of whose relations is equivalent to the query’s relation. As we observe, reasoning based
on multi-hop paths is similar to answering questions step-by-step. Inspired by step-by-step question
answering, this paper designs a new Interpretable Multi-hop Reasoning model - IMR, which can
perform interpretable operations on reasoning and integrate paths of different hops simultaneously.
The primary route of IMR can be described as follows. IMR first transforms reasoning based on
path searching into step-by-step question answering based on TransE (Bordes et al., 2013) and IRN
(Zhou et al., 2018). When searching for multi-hop paths step by step, we calculate the rest part of
the query for each path. Besides, IMR designs three indicators based on the remaining parts of the
query and the reasoning tails: query matching degree, answer completing level and path confidence.
Query matching degree, that is, the matching degree between the reasoning tails and the query,
measures the rationality of the new quadruples. Answer completing level, that is, the matching
degree between the relations of paths and that of the queries, measures the completeness of the
answer. Path confidence, that is, the difference between the same entities with different timestamps,
measures the reliability of the reasoning paths. IMR achieves the unified scoring of multi-hop paths
and better explainable reasoning simultaneously with these indicators’ combined effect.
The major contributions of this work are as follows. (1) This paper proposes a new interpretable
multi-hop reasoning model (IMR) which can perform interpretable operations on the question. Fur-
thermore, IMR designs three indicators: query matching degree, answer completing level and path
confidence. (2) Unlike other models that can only process paths with a specified hop, IMR can mea-
sure paths of different hops equivalently and utilize paths with different hops for reasoning. (3) IMR
can provide the reasoning path like other interpretable models and further explain the basis for path
comparison. (4) Experiments show that IMR achieves state-of-the-art on four benchmark datasets.
2	Related Work
Static KG reasoning. Knowledge graph reasoning based on representation learning has been widely
concerned by scholars. These approaches for reasoning can be categorized into geometric models
(Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015; Ji et al., 2015; Sun et al., 2019), tensor
decomposition models (Yang et al., 2015; Nickel et al., 2011; Trouillon et al., 2016; Balazevic et al.,
2019) and deep learning models (Dettmers et al., 2018; Nguyen et al., 2018; 2019). In recent years,
some scholars have attempted to introduce GCN into knowledge graph reasoning (Vashishth et al.,
2020), which can improve the performance of basic models. Some other scholars focus on multi-
hop reasoning with symbolic inference rules learned from relation paths (Li & Cheng, 2019; Wang
et al., 2019). The above methods are all designed for static KGs, challenging to deal with temporal
knowledge graphs reasoning.
Temporal KG reasoning. Temporal KGs import the time dimension to static KGs, which makes
the facts of a specific timestamp extremely sparse. The temporal KG reasoning task can be divided
into two categories: reasoning about historical facts (Jin et al., 2019; Garcia-Duran et al., 2018; XU
et al., 2020a; Jung et al., 2021; Han et al., 2021; Wu et al., 2020), i.e., interpolation on temporal KGs,
and reasoning about future facts (Jin et al., 2019; Han et al., 2021; Li et al., 2021; Zhu et al., 2020),
i.e., forecasting on temporal KGs. The former predicts the missing facts of a specific historical
moment based on the facts of all moments, and the latter predicts future events based only on the
past facts. There are many studies on the task of temporal KG interpolation. However, these studies
are all black-box models, which cannot explain predictions. For temporal KG forecasting, most of
the proposed models are also black box models. Recently, xERTR (Han et al., 2021), CluSTer (Li
et al., 2021) and TITer (Sun et al., 2021) can explain predictions to some extent. These models can
provides the reasoning paths for the predictions. However, both models can not integrate multi-hop
paths. xERTR can only perform reasoning with a specified hop. Experiments show that CluSTeR
performs worse on paths with multiple hops than on paths with only one hop.
In general, most of the current temporal KG forecasting models are black-box models. Only some
models can provide reasoning paths for prediction. Moreover, none of them can explain how path
comparisons work and none of them can combine reasoning paths with different hops effectively.
2
Under review as a conference paper at ICLR 2021
3	Preliminaries
The task of temporal KG forecasting. Suppose that E , R, and T represent the entity set, predicate
set and timestamp set, respectively. The temporal KG is a collection of quadruples, which can be ex-
pressed as:K = {(es, rq, eo, tq) , es, eo ∈ E, rq ∈ R, tq ∈ T}. (es, rq, eo, tq) denotes a quadruple,
es and eo represent the subject and object respectively, rq represents the predicate, i.e. the relation,
and tq represents the time when the quadruple occurs. Suppose that the set of facts that happened
before the time tq can be expressed as Gtq = {(ei, ri, ej, ti) ∈ K|ti < tq}. Temporal KG forecast-
ing is to predict future links based on past facts, that is, the process of predicting eo given a query
(es, rq, ?, tq) and the previous facts Gtq. Similar to static KG reasoning, temporal KG forecasting
ranks all entities of the specific moment and obtains the preference for prediction.
Temporal KG forecasting Based on Paths. Knowledge graph embedding associates the entities
e ∈ E and relations r ∈ R with vectors e, r. Different from static KGs, the entities in temporal
KGs contain time information. The entity may contain different attributes at different moments. In
order to better characterize the entity in temporal KGs, we associate each entity e with a time label
tq ∈ T, so the entity e can be depicted as etq and its embedding can be denoted as etq . The set
of quadruples directly associated with etsq, which means the 1-hop paths associated with etsq, can be
expressed as: P& ,tq) = {(es,rq ,ei,ti) | (es,rq, ei, ti) ∈ Gtq , es , ei ∈ E ,rq ∈ R, ti < tq ∈ T}.
The set of entities directly associated with etsq in the path P(es,tq), i.e., the 1-hop neighbors of estq,
can be denoted as N(es ,tq ) = ei | (es , rk , ei , th ) ∈ P(es ,tq ) , es , ei ∈ E, rk ∈ R, th < tq ∈ T}.
Given the query (es , rq, ?, tq), the forecasting task can be depicted as requesting the entity
eo based on path searching. For example, we search the path with es as the starting point:
(es , rp1 , e1 , t1 ) , (e1 , rp2 , e2 , t2 ) , (e2 , rp3 , e3 , t3 ) , . . . , (ei-1 , rpi , ei , ti ). So answers to the query
may be e1, e2, e3, . . . , ei, and the corresponding inference hop is 1, 2, 3, . . . , i respectively.
Fact matching based on TransE. This paper is the first to design interpretable evaluation indicators
from the perspective of actual semantics. In order to better illustrate the design route, we choose the
basic embedding model-TransE as the basis of IMR. In TransE,relations are represented as transla-
tions in the embedding space: if the triple (es, r, eo) holds in static KGs, TransE (Bordes et al., 2013)
assumes that |es + r - eo| = 0. For each quadruples (es, rq, eo, tq) in temporal KGs, the relation
rq can also be taken as the translations from the subject es to the object eo, i.e. estq + rq = etoq . We
suppose that when the distance d of quadruples is smaller, the quadruple will be better matched. The
distance of the quadruple (es, rq, eo, tq) can be expressed as:
d= etsq +rq-etoq	(1)
The relations indicate the translations between entities, whose specific design determines the com-
plexity of indicators designed by IMR. The design route of IMR starts from the perspective of
reasoning from actual semantics, which is not limited to specific basic models. All the specific
formulas of IMR in this paper are based on TransE, which will not be explained below.
4	Our model
We introduce Interpretable Multi-hop Reasoning (IMR) in this section. We first provide an overview
of IMR in Section 4.1. IMR comprises three modules: path searching module, query updating
module, and path scoring module. The path searching module searches related paths hop by hop
from the subjects of questions, involving path sampling and entity clipping, which will be introduced
in Section 4.2. The query update module calculates the remaining questions hop-by-hop for each
path, involving the update of the subject and relations, which will be introduced in Section 4.3. The
scoring module designs three indicators: question matching degree, answer completing level, and
path confidence. This module combines three indicators to score each path, which will be introduced
in Section 4.4. We will introduce training strategies and the regularizations on state continuity in
Section 4.5.
1We reverse all the quadruple. Add ej , rq-1 , ei, tk for each (ei, rq, ej , tk). In this way, P(es ,tq) can
represent all associated quadruples.
3
Under review as a conference paper at ICLR 2021
Time-aware exponentially weighted Calculate the rest of questions for	Prune based on the scores of PathS
sampling	each path.
Figure 1: Model Architecture. We take the 2-hop path searching as an example. The black arrow
means time-aware exponentially weighted sampling. The blue arrows denote calculating the rest of
questions for each path. The red arrow represents pruning based on the scores of paths. We take
(Sub, Rel, ?, Time) as the original question ,which can be denoted as (es, rq, ?, tq). The searched
two paths are [(Sub,R1,Obj1,Time1)] and [(Sub,R1,Obj1,Time1),(Obj1,R5,Obj5,Time5)], which
can be denoted as [(es, rp1, e1, t1)] and [(es, rp1, e1, t1) , (e1, rp2, e2, t2)] respectively. (Sub’, Rel’,
?, Time) and (Sub”, Rel”, ?, Time) denote the remaining question after 1-hop and 2-hop path,
wihch can be taken as es-1, rq-1, ?, tq , es-2, rq-2, ?, tq respectively.
4.1	Model Overview
We observe that predicting unknown facts based on paths is similar to question answering, i.e., the
question can be answered directly via finding triples with the equivalence relation or gradually by
utilizing a multi-hop equivalence path. Inspired by this observation, we view the task of link predic-
tion as to question answering. IMR primarily consists of searching for paths hop by hop, updating
the remaining questions for each path, and filtering the best answers based on three indicators: ques-
tion matching degree, answer completing level, and path confidence.
We show a toy example in Figure 1. Given a question (es, rq, ?, tq) and the previous facts Gtq,
the task of forecasting is predicting the missing object eo . The steps of IMR are as follows. Step
1: Starting from the subject es, find out the associated quadruples P(es,tq), namely 1-hop paths.
We temporally bias the neighborhood sampling using an exponential distribution for the neighbors.
The distribution negatively correlates with the time difference between node es and its neighbor
N(es,tq). Then, calculate the remaining questions (the remaining subject es-1 and the remaining
relation rq- 1 ) for each sampled path. Finally, IMR scores 1-hop paths based on three indicators,
which will be discussed in Section 4.4. Step 2: To prevent the path searching from exploding, the
model samples the tails of 1-hop paths for the 2-hop path searching. As shown by the pink arrow
in Figure 1, tails of 1-hop paths are clipped according to scores of 1-hop paths. For the 2-hop paths
searched from the clipped tails, IMR samples the paths negatively correlated with time distances.
Then, IMR calculates the remaining questions for each 2-hop path (the remaining subject es-2 and
the remaining relation rq-2) and scores the 2-hop paths based on three indicators. Step 3: Rank the
scores of all paths to obtain the preference answer.
4.2	Path Searching Module
Path sampling. For the path searching from the starting subject es, the number of triples in Gtq
may be very large. To prevent the path searching from exploding, we sample a subset of the paths.
In fact, the attributes of entities in temporal KGs may change over time. Consider the observation
that when t1 is closer to tq, the attributes of ets1 should be more similar to those of etsq . Therefore,
we are more prone to sample nodes whose time is closer to tq. In this paper, we employ time-aware
4
Under review as a conference paper at ICLR 2021
exponentially weighted sampling in xERTR (Han et al., 2021). xERTR (Han et al., 2021) temporally
biases the neighborhood sampling using an exponential distribution of time distance.
Entity pruning. The search for next-hop paths is based on the tails of previous hop paths. Be-
sides, the number of paths is increased by O(kn). In order to avoid the explosion of next-hop path
searching, only a few tails are selected for further path searching. We directly sort the scores of the
previous hop and select the top-K entities for the next-hop search.
4.3	Query Updating Module
Given a question (es, rq, ?, tq), there may be few direct equivalent relations with rq in the temporal
KGs for the task of link prediction. More questions need to go through multi-hop paths to reason
about the result. In question answering, a complex question can be decomposed into multiple sub-
questions, and one sub-question is answered at each step. So the reasoning based on the multi-hop
path is equivalent to answering complex questions step by step. For the part that has already been
answered, we need to remove the part resolved so that we can focus on the remaining questions.
Therefore, we need to update the question according to the last hop of the path, focusing on finding
the unsolved parts. The embedding of entities is first introduced in this subsection, followed by the
query updating module.
Entity representation. The attributes contained in the entity may change over time. This paper
divides the entity embeddings of each timestamp into static representation and dynamic representa-
tion.
e = act (MLP ([ estatic || edynamic ]))	(2)
Here, the vector estatic ∈ Rd denotes the static embedding, which captures time-invariant features
and global dependencies over the temporal KGs. The vector edynamic ∈ R2d represents the dy-
namic embedding for each entity that changes over time. MLP(∙) denotes the multilayer perceptron
(MLP). act(∙) means the activation function and We take LeakyReLU as the activation function in
this paper. We will provide more details about the each component A.1.
Question updating. Each path has a different set of relations. After each hop, the question needs to
discard the processed semantic, i.e., to obtain the remaining subject and relation of the question. As
shoWn in Figure 1, the subject and relation of the question after the i-th hop path are updated based
on Eq.1 as folloWs.
eq-i = eq- i-1 + rpi	(3)
rq- i = rq- i-1 - rpi	(4)
Where the embedding eq- i and rq- i represents the remaining subject and relation of the question
after the i-hop path respectively. Besides, rpi denotes the relation of i-th hop path and i is the
number of hops for each path. eq- 0 = eq, rq- 0 = rq .
4.4	Path Scoring Module
We evaluate the path searching from three perspectives. First, the searched tails should match the
original question, Which means that the correct tails searched by paths and the question should satisfy
TransE. Secondly, the ideal path should be the search of equivalent semantics for relations, not just
the search for the correct tails. It is necessary to ensure the correctness of semantic equivalence,
i.e., the path is semantically equivalent to the relation of the question. Finally, considering the
particularity of the temporal KGs, the attributes of the same entity may change over time. The
current sampling strategy for path searching is to sample adjacent timestamp triples of the same
entity. When the attribute value of the entity changes significantly over time, it is inappropriate
to perform this sampling strategy for the next hop. We need to ensure that the same entity With
different timestamps has similar properties in the same path. In this Way, three indicators have been
developed by IMR to measure the rationality of the reasoning path respectively: question matching
degree, ansWer completing level, and path confidence.
5
Under review as a conference paper at ICLR 2021
Figure 2: A brief illustration Of the Path SCOring module. For the query (Sub, Rel, Tq,?), We search
the 2-hop path (Sub, Rl, Tl, Objl),(Objl, R2, T2, Obj2). The pink box indicates that the original
question and the tailof the path are formed a quadruple to measure the rationality Of the inference tail
as the answer, that in, QUestion MatChing Degree rfqmd∙ The purple box represents the comparison
between the question's ed(jlemtion and the Path relations to measure the semantics equivalence between
the question and the Paths that is, AnSWer ComPleting Level fac. These green boxes compare the
attributes Of the Salme entities With different timestamps to measure the reliability Of the search path,
that is, Path Confidence fp=.
semantcs o te queston. toug tese pats can ner te ta, tese pats are not va or eng
ruenlreevlaantecde tboettwteeeqnuettsteiopnatitn asnedmtatneticq.ueTsttieorne.foAren,sIwMerRcdoemsipglnetsinagn lienvdeelxfto minedaiscuatreesttwetseettmearntttice
rceommabiinniantgiorneloaftiopnatstorfetlatteioqnusesctainonreaflsetcttettaensrweleartioconmopfltettiengquleesvteilo,nwinticsetmisanctailcc.ulIaMteRd tbaakseesdtotne
tgtiveer.eTltaetiocnalcouflaatiqouneroyf rfeamc faoinrsi,tttt-teomppopraettcoismpa1ps,lfeotpel2l,oa.wn..ssw. er tte combinatiqo.n of gpatt rel,ations will
faic= krq-rp1-rp2-rp3-...-rpikp
=	rq-1 - rp2 - rp3 -...- rpip	(6)
=	rqq--ip p	p p
oPfattthecpornefivdioeunscet.opP.atWt tseeanrcsetainrcgtiisntgtfeoprraocpeastst,otftseecarucrtreinngt sfaomr tptlienngesxttr-attoegpypiastttso bsaasmepdleonadttjaecteanilt
ttiimmeessttaammppstriinplteesmopfotrtaelsKamGes.enTtittye.pTretmeriesearoefdtetviisatsiaomnsplbientgwesternattetgeysiasmtetaetntoitnileys wwittetndiefnfetirteienst
attributes ctange significantly over time, performing an effective next patt searct is inappropriate.
Tte reasoning patt is more reliable wten tte deviations between entities are smaller. IMR designs
Patt Confidence fpc, i.e., tte error between tte subject of tte updated question eq-i and tte tails of
ttepattetii.Ttecalculationoffpcforitt-toppa6ttisasfollows.
where the p-norm of a complex vector V is defined as ∖∖V∖∖p = ^∕∖Vi∖p. We use Ll-norm for all
indicators in the following.
Answer completing level. Among the paths to the right tails, some paths are not related to the
semantics of the question. Although these paths can infer the tail, these paths are not valid for being
unrelated to the question in semantic. Therefore, IMR designs an index to measure the semantic
relevance between the path and the question. Answer completing level fac indicates whether the
combination of path relations can reflect the relation of the question in semantic. IMR takes the
remaining relations of the question as the answer completing level, which is calculated based on
the distance between the relations of paths rpι, rp2, ∙∙∙ and the relation rq. In general, the fewer
the relation of a query remains, the more complete answer the combination of path relations will
give.The calculation of fac for 汕-hop path is as follows.
fac = llrq - rpl - rp2 — ⅛3 —…—rpi∣∣p
=∣∣⅝-1 - rp2 - Tp3 —…一rpi∣∣
Il	H Q	⑹
= ∣∣rq-2-rp3-...-rpi∣∣p
=llrq-i∣lp
Path confidence. Path searching is the process of searching for the next-hop paths based on the tail
of the previous hop. When searching for a path, the current sampling strategy is to sample adjacent
timestamp triples of the same entity. There are deviations between the same entities with different
timestamps in temporal KGs. The premise of this sampling strategy is that only when entities
have similar attributes under different timestamps, the path searching is valid. When the entity,s
attributes change significantly over time, performing an effective next path search is inappropriate.
The reasoning path is more reliable when the deviations between entities are smaller. IMR designs
Path Confidence fpc, i.e., the error between the subject of the updated question eq_i and the tails of
the path et>. The calculation of fpc for 汕-hop path is as follows.
6
Under review as a conference paper at ICLR 2021
fpic = eq-i - eiti p	(7)
Where eq- i represents the remaining subject of the question updated by paths of the length i, and
eiti represents the tail reasoned by the i-hop paths.
Combination of scores. IMR merges the scores of paths with multilayer perceptron (MLP) to obtain
the final score f of each path .
f=MLP([fpc || fac || fqmd])
(8)
The temporal KG forecasting is to sort all entities with the same timestamp, that is, IMR needs
to combine scores of entities with different timestamps. Entities with the same timestamp may be
inferred from different paths. Considering only one path matches the query the most, IMR employs
max aggregation for the score of paths inferring same entities with the same timestamp. In this
case, the entity has only one unique score per timestamp. Besides, certain paths may infer the same
entity with a different timestamp. In order to make better use of the path information of different
timestamps, IMR performs average aggregation for the scores of entities with different timestamps.
Finally, IMR obtains the score of each entity at the query timestamp.
4.5	Learning
We utilize the binary cross-entropy as the loss function, which is defined as:
_-L X__________
1Q1 q∈Q ∣εpath∣
1
L
X ( yei,q log ( P	fei,q f ) + (1 - yei,q) log(1 - P	fei,q f ))
path	ei∈εqpath fei,q	ei∈εqpath fei,q
ei ∈εq	q	q
(9)
where εqpath represents the set of entities reasoned by selected paths. yei,q represents the binary label
that indicate whether ei is the answer for q and Q represents the training set. fei,q denotes the score
obtained by Eq.8 for each path. We jointly learn the embeddings and other model parameters by
end-to-end training.
Regularization. For the same entity with different timestamps, the closer the entity’s time distance
is, the closer its dynamic embedding is. IMR implements the regularization on continuity for the
dynamic vectors of entities.
reg= eitj - eitj-1 p + eitj -eitj+1p
(10)
where, eitj denotes the dynamic embedding of the i-th entity at the j-th timestamp. eitj-1 , eitj+1
denotes the dynamic embedding of the previous and later timestamp against etj respectively. ∣∣∙kp
denotes the p norm of the vectors and we take p as 1 in this paper.
5	Experiments
5.1	Datasets and baselines
In order to evaluate the proposed module, we consider two standard temporal KG datasets Integrated
Crisis Early Warning System (ICEWS) (Boschee et al., 2015), WIKI (Leblay & Chekol, 2018b) and
YAGO (Mahdisoltani et al., 2015). The ICEWS dataset contains information about political events
with time annotations. We select three subsets of the ICEWS dataset, i.e., ICEWS14 and ICEWS18,
containing event facts in 2014 and 2018, respectively. WIKI and YAGO is a temporal KG that fuses
information from Wikipedia with WordNet (Miller, 1995). Following the experimental settings of
HyTE (Dasgupta et al., 2018), we deal with year-level granularity by dropping the month and date
information. We compare IMR and baseline methods by performing the temporal KGs forecasting
task on the ICEWS14, ICEWS18, WIKI, and YAGO. Details of these datasets are listed in Table 1.
We adopt the same dataset split strategy as in (Jin et al., 2020).
7
Under review as a conference paper at ICLR 2021
Dataset	entity	relation	timestamp	training	validation	test
ICEWS14	7128	230	365	63685	13823	13222
ICEWS18	23033	256	304	373018	45995	49545
WIKI	12554	24	232	539286	67538	63110
YAGO	10623	10	189	161540	19523	20026
Table 1: The number of entities, relations, timestamps and observed triples for four benchmark
datasets.
ICEWS14	ICEWS18	WIKI	YAGO
	MRR	Hit@1	Hit@3	Hit@10	MRR	Hit@1	Hit@3	Hit@10	MRR	Hit@1	Hit@3	Hit@10	MRR	Hit@1	Hit@3	Hit@10
TTransE	13.43	3.11	17.32	34.55	8.31	1.92	8.56	-21.89-	29.27	21.67	34.43	42.39	31.19	18.12	40.91	51.21
TA-DistMult	26.47	17.09	30.22	45.41	16.75	8.61	18.41	33.59	44.53	39.92	48.73	51.71	54.92	48.15	59.61	66.71
DE-SimPlE	32.67	24.43	35.69	49.11	19.30	11.53	21.86	34.80	45.43	42.6	47.71	49.55	54.91	51.64	57.30	60.17
TNTComPlEx	32.12	23.35	36.03	49.13	27.54	19.52	30.80	42.86	45.03	40.04	49.31	52.03	57.98	52.92	61.33	66.69
CyGNet	32.73	23.69	36.31	50.67	24.93	15.90	28.28	42.61-	33.89	29.06	36.10	41.86	52.07	45.36	56.12	63.77
RE-NET	38.28	28.68	41.34	54.52	28.81	19.05	32.44	47.51	49.66	46.88	51.19	53.48	58.02	53.06	61.08	66.29
xERTE	40.79	32.70	45.67	57.30	29.31	21.03	33.51	46.48	71.14	68.05	76.11	79.01	84.19	80.09	88.02	89.78
TANGO-Tucker	—	—	—	—	28.68	19.35	32.17	47.04	50.43	48.52	51.47	53.58	57.83	53.05	60.78	65.85
TANGO-DistMult	-	-	-	-	26.75	17.92	30.08	44.09	51.15	49.66	52.16	53.35	62.70	59.18	60.31	67.90
TITer	41.73	32.74	46.46	58.44	29.98	22.05	33.46	44.83	75.50	72.96	77.49	79.02	87.47	84.89	89.96	90.27
IMR	44.76	35.64	49.49	62.30	32.45	22.97	36.05	49.36	80.41	76.04	84.91	85.95	90.24	87.91	92.65	92.77
Table 2: Results comparison on four datasets. Compared metrics are time-aware filtered MRR(%)
and Hits@1/3/10 (%), which are multiplied by 100. The best results among all models are in bold.
We compare the performance of IMR against the temporal KG reasoning models, including TTransE
(LeHay & ChekoL 2018a), TA-DistMUlt/TA-TransE (Garcla-Duran et al., 2018), DE-SimPlE (Goel
et al., 2020), TNTComplEx (Lacroix et al., 2020), CyGNet (Zhu et al., 2020), RE-Net (Jin et al.,
2020), TANGO (Ding et al., 2021), TITer (Sun et al., 2021) and xERTR (Han et al., 2021).
In the exPeriments, the widely used Mean ReciProcal Rank (MRR) and Hits@1,3,10 are emPloyed
as the metrics. The filtered setting for static KGs is not suitable for the reasoning task under the
exPloration setting, as mentioned in xERTR (Han et al., 2021). The time-aware filtering scheme
only filters out triPles that are genuine at the query time.
5.2	Experimental results and ablation study
Result Comparison. Table 2 shows the comParison between IMR and other baseline models on
the ICEWS, WIKI, and YAGO datasets 2. Overall, IMR outPerforms all baseline models in all
metrics while being more interPretable, which convincingly verifies its effectiveness. ComPared
to the strongest baseline TITer (Sun et al., 2021), IMR obtains a relative imProvement of 3.3%
and 2.5% in MRR and Hits@1, which are averaged on ICEWS, WIKI, and YAGO. To assess the
imPortance of each comPonent, we further conduct several ablation studies.
Comparison of multi-hop paths. Figure 3 shows the Performance of IMR on ICEWS, WIKI, and
YAGO as the maximum hoP of Paths increases. The Performance basically continues to rise with
the increase of the maximum hoP of Paths. But when the maximum hoP of Paths increases, the
Performance of IMR on ICEWS18 hardly imProves. The further analysis of ICEWS18 in (Li et al.,
2021) exPlains that there are no strong dePendencies between the relations of the question and the
multi-hoP Paths. Thus, in this situation, longer Paths Provide little gain for inference 3. Besides,
as the max-hoP of Paths increases, the number of inference Paths increases exPonentially, most
of which are invalid Paths and will suPPress the Performance of IMR. In order to ensure that the
Performance of the model does not decrease, we strictly control the samPling number of next-hoP
Paths to limit the number of multi-steP Paths and suPPress the imPact of noise samPles. Here, we
set the number of next-hoP samPling to 5 in the exPeriments of this PaPer. In summary, exPeriments
show that unified indicators designed by IMR measure the Paths of different hoPs in the same sPace,
allowing better reasoning based on Paths with different hoPs, which is consistent with the claim in
Section 4.4.
2Codes and datasets will be available at httPs://github.com/lfxx123/TKBC
3We leave it for future work to construct a more comPlex dataset for verifying the effectiveness of multi-hoP
Paths.
8
Under review as a conference paper at ICLR 2021
Dataset
Figure 3: Comparison of the performance of paths with different maximun hop on four datasets. We
average the output of four experiments with different random seeds and fixed hyperparameters.
YAGO
ICEWS14
WIKI
ICEWS18
Indicator
fac, fpc, fqmd
Distance to the best
fqmd
fac
fpc
fac, fqmd
fpc, fqmd
fac, fpc
Hit@1	Hit@3	Hit@10	MRR	Hit@1	Hit@3	Hit@10	MRR	Hit@1	Hit@3	Hit@10	MRR
87.32	92.53	-9276-	89.87	22.61	39.20	55.32	33.48	70.75	83.39	-85.87	77.12
87.79	92.67	92.78	90.18	31.67	46.02	59.21	41.05				
87.74	92.67	92.77	90.15	25.65	43.03	58.25	36.63	70.72	83.35	85.31	77.00
87.95	92.67	92.77	90.26	34.91	49.26	-61.12	43.82	76.12	84.90	85.94	80.46
87.74	92.67	92.75	90.15	25.64	43.16	58.30	36.63	73.85	84.12	85.65	78.99
87.91	92.65	92.77	90.24	34.81	49.02	61.15	43.74	76.04	84.91	85.95	80.41
88.31	92.66	92.77	90.48	34.96	49.27	-61.09	43.89	76.09	84.92	85.96	80.44
0	0.01	0	0	0	0	0.06	0	0.03	0	0	0.02
Hit@1
12.76
20.41
14.92
23.05
13.10
23.04
23.15
0
Hit@3	Hit@10	MRR
26.47	43.75	22.66
33.50	47.48	29.45
29.00	45.58	24.82
36.20	49.47	31.84
26.38	43.27	22.75
36.10	49.46	31.83
36.12	49.52	31.89
0.08	0	0
Table 3: The comparison of three indicators in different combinations. We average the output of
ten experiments with different random seeds and fixed hyperparameters. All metrics are multiplied
by 100.
Combination of indicators. The three indicators measure different aspects of the path: the match-
ing degree between answers and the question, the completeness of relational equivalence, and the
reliability of reasoning paths. We verify the performance of each metric through ablation experi-
ments. As shown in Table 3, the first block displays the performance with only one indicator, the
second block presents the performance with a combination of two parameters, and the last is a com-
bination of three indicators. The bottom line shows the error between the combination of the three
parameters and the best result. Since the distribution varies across two datasets, there are certain dif-
ferences in performance when employing a single indicator to rank paths. The model,s performance
has been significantly improved after incorporating the three indicators in pairs, but few differences
still remain. IMR can obtain the best inference performance in most datasets by combining three
indicators. In summary, the experiment illustrates that the combination of three indicators designed
by IMR can effectively measure the reasoning paths.
6	CONCLUSION
We proposed an Interpretable Multi-hop Reasoning approach (IMR) for forecasting future links
on temporal KGs. IMR transforms reasoning based on path searching into step-by-step question
answering. Moreover, IMR designs three indicators to measure the answer and reasoning paths.
Extensive experiments on four benchmark datasets demonstrate the effectiveness of our method. In
the future, we plan to enhance the prediction by integrating different paths reaching the same tail,
which will be more effective and interpretable.
References
Ivana Balazevic, Carl Allen, and Timothy M. Hospedales. Tucker: Tensor factorization for knowl-
edge graph completion. ArXiv, abs/1901.09590, 2019.
9
Under review as a conference paper at ICLR 2021
Antoine Bordes, Nicolas Usunier, Alberto Garcla-Duran, J. Weston, and Oksana Yakhnenko. Trans-
lating embeddings for modeling multi-relational data. In NIPS, 2013.
Elizabeth Boschee, Jennifer Lautenschlager, Sean O’Brien, Steve Shellman, James Starz, and
Michael Ward. Icews coded event data., volume 12. Harvard Dataverse, 2015.
Shib Sankar Dasgupta, Swayambhu Nath Ray, and Partha P. Talukdar. Hyte: Hyperplane-based tem-
porally aware knowledge graph embedding. In EMNLP, pp. 2001-2011. Association for ComPu-
tational Linguistics, 2018.
Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and S. Riedel. Convolutional 2d knowledge
graph embeddings. In AAAI, 2018.
Zifeng Ding, Zhen Han, Yunpu Ma, and Volker Tresp. Temporal knowledge graph forecasting with
neural ode. ArXiv, abs/2101.05151, 2021.
Alberto Garcia-Duran, Sebastijan Dumancic, and Mathias Niepert. Learning sequence encoders for
temporal knowledge graph completion. In EMNLP, pp. 4816-4821. Association for Computa-
tional Linguistics, 2018.
Alberto Garcia-Duran, Sebastijan Dumancic, and Mathias Niepert. Learning sequence encoders for
temporal knowledge graph completion. In EMNLP, 2018.
Rishab Goel, Seyed Mehran Kazemi, Marcus A. Brubaker, and P. Poupart. Diachronic embedding
for temporal knowledge graph completion. ArXiv, abs/1907.03143, 2020.
Zhen Han, Peng Chen, Yunpu Ma, and Volker Tresp. Explainable subgraph reasoning for forecasting
on temporal knowledge graphs. In ICLR. OpenReview.net, 2021.
Guoliang Ji, Shizhu He, L. Xu, Kang Liu, and Jun Zhao. Knowledge graph embedding via dynamic
mapping matrix. In ACL, 2015.
Woojeong Jin, Changlin Zhang, Pedro A. Szekely, and Xiang Ren. Recurrent event network for
reasoning over temporal knowledge graphs. CoRR, abs/1904.05530, 2019.
Woojeong Jin, Meng Qu, Xisen Jin, and Xiang Ren. Recurrent event network: Autoregressive
structure inference over temporal knowledge graphs. In EMNLP, 2020.
Jaehun Jung, Jinhong Jung, and U. Kang. Learning to walk across time for interpretable temporal
knowledge graph completion. In KDD, pp. 786-795. ACM, 2021.
Timotheie Lacroix, G. Obozinski, and Nicolas Usunier. Tensor decompositions for temporal knowl-
edge base completion. ArXiv, abs/2004.04926, 2020.
J. Leblay and M. Chekol. Deriving validity time in knowledge graph. Companion Proceedings of
the The Web Conference 2018, 2018a.
Julien Leblay and Melisachew Wudage Chekol. Deriving validity time in knowledge graph. Com-
panion Proceedings of the The Web Conference 2018, 2018b.
Ruiping Li and Xiang Cheng. DIVINE: A generative adversarial imitation learning framework for
knowledge graph reasoning. In EMNLP/IJCNLP (1), pp. 2642-2651. Association for Computa-
tional Linguistics, 2019.
Zixuan Li, Xiaolong Jin, Saiping Guan, Wei Li, Jiafeng Guo, Yuanzhuo Wang, and Xueqi Cheng.
Search from history and reason for future: Two-stage reasoning on temporal knowledge graphs.
In ACL/IJCNLP (1), pp. 4732-4743. Association for Computational Linguistics, 2021.
Yankai Lin, Zhiyuan Liu, M. Sun, Yang Liu, and Xuan Zhu. Learning entity and relation embeddings
for knowledge graph completion. In AAAI, 2015.
F. Mahdisoltani, J. Biega, and Fabian M. Suchanek. Yago3: A knowledge base from multilingual
wikipedias. In CIDR, 2015.
George A. Miller. Wordnet: A lexical database for english. Commun. ACM, 38(11):39-41, 1995.
10
Under review as a conference paper at ICLR 2021
Dai Quoc Nguyen, T. Nguyen, Dat Quoc Nguyen, and Dinh Q. Phung. A novel embedding model
for knowledge base completion based on convolutional neural network. ArXiv, abs/1712.02121,
2018.
Dai Quoc Nguyen, Thanh Vu, T. Nguyen, Dat Quoc Nguyen, and Dinh Q. Phung. A capsule
network-based embedding model for knowledge graph completion and search personalization.
ArXiv, abs/1808.04122, 2019.
Maximilian Nickel, Volker Tresp, and H. Kriegel. A three-way model for collective learning on
multi-relational data. In ICML, 2011.
Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. Yago: A large ontology from wikipedia
and Wordnet. Journal ofWeb Semantics, 6(3):203-217, 2008.
Haohai Sun, Jialun Zhong, Yunpu Ma, Zhen Han, and Kun He. Timetraveler: Reinforcement learn-
ing for temporal knoWledge graph forecasting. In EMNLP, 2021.
Zhiqing Sun, Zhihong Deng, Jian-Yun Nie, and Jian Tang. Rotate: KnoWledge graph embedding by
relational rotation in complex space. ArXiv, abs/1902.10197, 2019.
Theo Trouillon, Johannes WelbL S. Riedel, Eric GaUssier, and GUillaUme Bouchard. Complex
embeddings for simple link prediction. In ICML, 2016.
Shikhar Vashishth, SoUmya Sanyal, V. Nitin, and P. TalUkdar. Composition-based mUlti-relational
graph convolUtional netWorks. ArXiv, abs/1911.03082, 2020.
Heng Wang, ShUangyin Li, Rong Pan, and Mingzhi Mao. Incorporating graph attention mechanism
into knoWledge graph reasoning based on deep reinforcement learning. In EMNLP/IJCNLP (1),
pp. 2623-2631. Association for CompUtational LingUistics, 2019.
Zhen Wang, J. Zhang, Jianlin Feng, and Z. Chen. KnoWledge graph embedding by translating on
hyperplanes. In AAAI, 2014.
Jiapeng WU, Meng Cao, Jackie Chi Kit CheUng, and William L. Hamilton. Temp: Temporal message
passing for temporal knoWledge graph completion. In EMNLP (1), pp. 5730-5746. Association
for CompUtational LingUistics, 2020.
Chenjin XU, Mojtaba Nayyeri, FoUad AlkhoUry, Hamed Shariat Yazdi, and Jens Lehmann. Temporal
knoWledge graph completion based on time series gaUssian embedding. In ISWC (1), volUme
12506 of Lecture Notes in Computer Science, pp. 654-671. Springer, 2020a.
Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, and Kannan Achan. Inductive repre-
sentation learning on temporal graphs. ArXiv, abs/2002.07962, 2020b.
B. Yang, Wen tau Yih, X. He, Jianfeng Gao, and L. Deng. Embedding entities and relations for
learning and inference in knowledge bases. CoRR, abs/1412.6575, 2015.
Mantong Zhou, Minlie Huang, and Xiaoyan Zhu. An interpretable reasoning network for multi-
relation question answering. In COLING, pp. 2010-2022. Association for Computational Lin-
guistics, 2018.
Cunchao Zhu, Muhao Chen, Changjun Fan, Guangquan Cheng, and Yan Zhan. Learning from
history: Modeling temporal knowledge graphs with sequential copy-generation networks. CoRR,
abs/2012.08492, 2020.
A	Appendix
A.1 The Embedding for Entities
This paper divides the entity embeddings of each timestamp into static representation and dynamic
representation. The static embedding captures time-invariant attributes of the entity. We denote the
static embedding of the entity ei with ei-static ∈ Rd, which is a d-dimensional vector independent
11
Under review as a conference paper at ICLR 2021
of time. (Xu et al., 2020b) proposes a generic time encoding to generate the time-variant part of
entity representations, which can be denoted as Φ (t). Employing this time-encoding, quadruples
with the same subject, predicate, and object can have different attention scores. Specifically, quadru-
ples that occurred recently tend to have higher attention scores. This makes the embedding more
interpretable and effective.
Φ(t)= V d [cos(ωιt + φι),..., cos(ωdt + φd)], Φ(t) ∈ Rd	(II)
We observe that the semantic attributes of entities determine the reasoning, and the attribute devia-
tion caused by the time deviation is the only assumption obtained after statistics. In order to avoid
being only affected by time factors, we propose a new time-specific entity representation eit ∈ Rd ,
that is, each entity has a different representation at different timestamps. If each entity applies
different representations at every moment, it will consume enormous resources. As most of the
entities are only observed at limited timestamps, this paper characterizes the entities whose times-
tamps only appear in the training dataset. IMR utilizes the embedding of the separate entity when
it last occurred in the training dataset to represent the embedding at the timestamps missing from
the training dataset. Besides, to avoid over-fitting caused by too many parameters, we apply regu-
larizations on time continuity. This regularization believes that the temporally continuous entities
should have closer embeddings, as described in 4.5. Finally we combine Φ (t) and eit to construct
et
ei-dynamic
∈ R2d .
eit-dynamic = Φ(t) ||eit	(12)
where || denotes the operation of concatenation. In summary, the embedding for each entity ei can
be represented as :
ei = act (MLP([ ei-static || ei-dynamic D)	(13)
where MLP(∙) denotes the multilayer perceptron (MLP). act(∙) means the activation function and
we take LeakyReLU as the activation function in this paper.
A.2 Case Studies and Interpretability
For the query (John Kerry,Make a visit,?,2014-11-11), we extract part of the paths for the case study
in Table 4. The lower the scores or indicators in Table 4, the better the performance of the path. We
compare the paths based on the total score, analyze various aspects of the paths based on detailed
indicators, and verify the interpretation of the model with actual semantics.
The first block of Table 4 selects reasoning paths with the same objects to analyze the answer com-
pleting level. First, we compare path 1-1 and path 1-2. The score of path 1-1 is lower than that of
path 1-2. As we analyze the three indicators further, we find that the answer completing level of
path 1-1 is smaller than that of path 1-2. The comparison of answer completing level indicates that
the relation of path 1-1 should be closer to the relations of the query. Practically, path 1-1 has the
same relation as the query, which is closer to the relation of query than path1-2. Actual semantics
verifies the interpretation of the model. Comparing path 1-4 and path 1-5, we find that the total score
of path 1-4 is lower than that of path 1-5, and the answer completing level of path 1-5 is higher than
that of path 1-4. IMR shows that the combination of reasoning relations of path 1-4 is better than
that of path 1-5. In fact, these two paths for inference do not seem to be particularly appropriate to
the query. Nevertheless, the combination of relations [Meet at a ’third’ location + Make a visit] is
actually closer to the relation of the query [Make a visit] than the combination of relations [Consult
+ Consult]. To summarize, the first set of experiments shows that the answer completing level can
effectively indicate how well the combination of path relations equals to the relation of the query,
verifying the statement in section 4.4.
The second block of Table 4 selects the paths of the same reasoning relations to verify the path
confidence and the question matching degree. Comparing path 2-1, 2-2, 2-3 and 2-4, we observe
that the scores of the paths are increasing. Additionally, the path confidence of these three paths is
also increasing. In fact, the time distance between the paths and the query is gradually increasing,
12
Under review as a conference paper at ICLR 2021
Query: John Kerry	Make a visit	Oman	2014-11-11
Path-ID
path 1-1
path 1-2
path 1-3
path 1-4
path 1-5
path 2-1
path 2-2
path 2-3
path 2-4
path 2-5
path 2-6
path 2-7
path 2-8
path 2-9
John Kerry	Make a visit
John Kerry Express intent to meet or negotiate
John Kerry	(Reversed) Host a visit
John Kerry Meet at a ’third’ location
John Kerry	Consult
John Kerry Express intent to meet or negotiate
John Kerry Express intent to meet or negotiate
John Kerry Express intent to meet or negotiate
John Kerry Express intent to meet or negotiate
John Kerry Reversed Meet at a ’third’ location
John Kerry Reversed Meet at a ’third’ location
John Kerry	Make	a visit
John Kerry	Make	a visit
John Kerry	Make	a visit
Reasoning Path
e2	t2	e2	r3
Oman	2014-11-09
Oman	2014-11-09
Oman	2014-11-09
Catherine Ashton
Mohammad Javad Zarif
Oman
Oman
Oman
Oman
Catherine Ashton
Catherine Ashton
China
North Atlantic Treaty Organization
Canada
2014-11-10 Catherine Ashton
2014-11-10 Mohammad Javad Zarif
2014-11-10
2014-11-09
2014-11-05
2014-11-02
2014-11-10
2014-11-10
2014-11-05
2014-06-25
2014-10-27
path 3-1
path 3-2
path
path
3-3
3-4
path 3-5
path 3-6
John Kerry Reversed Meet at a ’third’ location
John Kerry Express intent to	meet or negotiate
John Kerry	Make	a visit
John Kerry	Make	a visit
John Kerry	Make	a visit
John Kerry (Reversed) Make a visit
Catherine Ashton
Oman
Afghanistan
Afghanistan
2014-11-10
2014-11-09
Angola
Catherine Ashton
Score
fa fm fp	Combined Score
0	74	74	137
26	74	69	169
27	74	76	178
38	74	90	206
73	74	107	254
26	47	41	119
26	74	69	170
26	89	83	196
26	90	82	197
49	91	101	246
49	89	100	242
0	88	88	162
0	87	87	160
0	85	85	157
53	46	40	155
26	74	69	169
O	88	88	162
Reversed Make statement Barack Obama 2014-07-18	34	94	104	241
(Reversed) Make statement Anthony Foxx 2014-08-04	35	93	105	241
MakeaviSit	Oman 2014-11-09	33	74	85	197
e3	t3
Make a visit
Consult
Oman	2014-11-09
Oman	2014-11-09
Catherine Ashton Express intent to meet or negotiate
Catherine Ashton Express intent to meet or negotiate
2014-07-21	-
2014-07-21	Afghanistan
2014-08-05	Angola
2014-11-10 Catherine Ashton
Oman	2014-11-03
Oman	2014-11-05
Table 4: Reasoning paths searched for the query (John Kerry, Make a visit , ?, 2014-11-11) and
their scores respectively.
Query:	Citizen (Nigeria)	Use unconventional violence	Secretariat (Nigeria)	8016 I				
Path-ID		Reasoning Path					Score	
	es	r2	e2	t2	fac	fqmd	fpc Combined Score	
path 4-1	Citizen (Nigeria)	Use unconventional violence	Militant (Nigeria)	7968	^^0-	162	162	215
path 4-1	Citizen (Nigeria)	Use unconventional violence	Militant (Nigeria)	7728	0	185	185	245
path 5-2	Citizen (Nigeria)	Reversed Use unconventional violence	Terrorist (Boko Haram)	7824	^72^	204	199	359
path 5-3	Citizen (Nigeria)	Reversed Use unconventional violence	Terrorist (Boko Haram)	7776	72	174	168	319
path 5-4	Citizen (Nigeria)	Reversed Use unconventional violence	Militant (Boko Haram)	7872	72	206	202	363
path 5-5	Citizen (Nigeria)	Reversed Use unconventional violence	Militant (Boko Haram)	7776	72	173	166	317
path 5-6	Citizen (Nigeria)	Reversed Use unconventional violence	Militant (Boko Haram)	7752	72	175	167	319
Path 6-1	Citizen (Nigeria)	Reversed fight with small arms and light weapons	Boko Haram	7992	^73^^	95	95	220
path 6-2	Citizen (Nigeria)	Reversed fight with small arms and light weapons	Boko Haram	7872	73	174	168	321
path 6-3	Citizen (Nigeria)	Reversed fight with small arms and light weapons	Boko Haram	7848	73	177	171	324
path 6-4	Citizen (Nigeria)	Reversed fight with small arms and light weapons	Boko Haram	7824	73	178	171	325
path 6-5	Citizen (Nigeria)	Reversed fight with small arms and light weapons	Boko Haram	7680	73	180	173	328
path 7-1	Citizen (Nigeria)	Reversed fight with small arms and light weapons	Boko Haram	7848	^73^^	177	171	324
path 7-2	Citizen (Nigeria)	Make an appeal or request	Government (Nigeria)	7848	78	167	158	315
path 7-3	Citizen (Nigeria)	Reversed fight with small arms and light weapons	Boko Haram	7848	73	177	171	324
path 7-4	Citizen (Nigeria)	Reversed Make an appeal or request	Tony Momoh	7848	80	207	205	377
path 7-5	Citizen (Nigeria)	Reversed Express intent to meet or negotiate	South Africa	7848	85	169	165	330
path 7-6	Citizen (Nigeria)	Reversed Bring lawsuit against	Fessehaye Yohannes	7848	80	210	206	379
Table 5: Reasoning paths searched for the query (Citizen (Nigeria), Use unconventional violence
, ?, 8016) and their scores respectively.
which means that the reliability of the paths gradually decreases. The reliability indicated by path
confidence is consistent with the actual reliability. Similarly, we find that the path confidence of path
2-5 is higher than that of path 2-6, indicating that path 2-5 is less reliable. The actual situation is
that the timestamp of path 2-5 (2014-11-03<2014-11-05) is farther from the timestamp of the query,
which is consistent with the explanation. Comparing path 2-9 with path 2-7 and 2-8, respectively,
the model further infers that the path confidence and question matching degree of path 2-9 are better
than the other two paths. The actual situation is that the timestamp error with the query satisfies: path
2-7>path 2-9>path 2-8. This is because the question matching degree covers the path confidence.
Considering the fact that the path confidence contains the error of the triple in the training dataset,
the triple error covers the error caused by different timestamps, which makes path 2-9 more reliable
than path 2-7. In general, the second set of experiments illustrates that the path confidence can
effectively indicate the validity of each path.
In the third block of Table 4, we randomly select the paths, explain the paths based on these in-
dicators, and verify them with the actual situation. We first sort three paths according to answer
completing level : path 3-1 <path 3-2 <path 3-3. Therefore, the semantic similarity of relations
between the three paths and the query should satisfy : path 3-3 >path 3-2 >path 3-1. The ac-
tual semantic similarity between the relations of paths and that of the query satisfies: Make a visit
>Express intent to meet or negotiate >Meet at a’third’ location, which is consistent with the
interpretation of IMR. Sort three paths by path confidence: path 3-1 <path 3-2 <path 3-3. The re-
liability of the three inference paths should satisfy: path 3-1 <path 3-2 <path 3-3. We observe that
the time distance between the three paths and the query is gradually increasing, which verifies the
explanation by path confidence. The analysis of path 3-4 to 3-6 is similar to the analysis of former
paths. Case studies show that IMR can both provide reasoning paths as well as offer an valid basis
for path comparison.
13
Under review as a conference paper at ICLR 2021
(a) YAGO	(b) WIKI
Figure 4: The relation between Path Confidence and time diatance.The questions and paths corre-
sponding to each polyline is shown in Table 6 and Table 7.
Question
Paths
Matt_Mills ,playsFor, SwindonTownF.C.,186
BoIton_Wandelers_F.C., Reversed playsFor , AriZa_MakUkuIa , 183
Marln Raykov , IsAffiliatedTo , Bulgarian Communist Party , 186
StUart_Lewis , playsFor , EngIand_national_Under , 17_football_team , 187
IPSwich_Town_F.C. , Reversed playsFor , Giovani dos Santos , 186
Sean Thornton , playsFor , Blackpool F.C. , 185
Bangkok Dock Company , Reversed owns , Ministry of Finance (Thailand) , 187
AlanHoward , isMarriedTo , Sally_BeaUman , 184
Denise Kandel, isMarriedTo , Eric Kandel, 187
NfmesOympique , Reversed playsFor , DjibriI_Ciss§ , 183
WebMD , owns , MedicineNet ,184 ,
WLBJ , LP , Reversed owns , Knights of Columbus , 185
Kevin Corrigan , isMarriedTo , EIiZabeth_Berridge_(actress), 185
ScottishOpera , owns , Theatre_RoyaI ,一GIaSgow , 185
Ronald Stuart Burt, worksAt, University of Chicago , 187
Lela Rochon , Reversed isMarriedTo , Shabba Doo , 183
England national under , 18 football team , Reversed playsFor , Terry Dunfield , 186
ChaIn , pyo , isMarriedTo , ShinAe , ra , 187
Michael Shanks , isMarriedTo , LexaDoig , 186
Amara (singer), isMarriedTo , Frans Mohede , 186
HeIder_Barbosa , playsFor , PortUgaLnationaLUnder , 16_footbaILteam , 184
Walter Richardson (politician) , isAffiliatedTo , Australian Labor Party , 183
University of Basel, Reversed worksAt, Alfred Rittmann , 186
Winiam_Webster_(AUstraIian_PoIitician) , isAffiliatedTo , Nationalist Party of Australia , 185
Matt-Mills , playsFor , Swindon_Town_Fc
BoIton_Wanderers_F.C. , Reversed playsFor , Ulish Booker
Marin Raykov , isAffiliatedTo , Bulgarian Communist Party
StUartLewis , playsFor , EngIand_nationaLUnder , 17_football_team
Ipswich Town F.C. , Reversed playsFor , Mark Burchill
Sean Thornton , playsFor , Republic of Ireland national under , 17 football team
Bangkok Dock Company , Reversed owns , Ministry of Finance (Thailand)
AIan_Howard , Reversed isMarriedTo , Sany_BeaUman
Denise Kandel, Reversed isMarriedTo , Eric Kandel
N^mes Olympique , Reversed playsFor , Milko Djurovski
WebMD , owns , RxList
WLBJ , LP , Reversed owns , Knights of Columbus
Kevin Corrigan , Reversed isMarriedTo , EIiZabeth_Berridge_(actress)
Scottish_Opera , owns , Theatre_Royal ,一GIaSgow
Ronald Stuart Burt, worksAt, University of Chicago
LelaRochon , isMarriedTo , Shabba Doo
England national under , 18 football team , Reversed playsFor , Terry Dunfield
Chain , pyo , Reversed isMarriedTo , Shin_Ae , ra
Michael Shanks , Reversed isMarriedTo , Lexa Doig
Amara(singer), Reversed isMarriedTo , Frans Mohede
HeIder_Barbosa , playsFor , PortUgaLnationaLUnder , 16_footbaILteam
WaIter_Richardson_(PoIitician), isAffiliatedTo , Australian Labor Party
University of Basel , Reversed worksAt, Alfred Rittmann
Winiam_Webster_(AUstraIian_PoIitician) , isAffiliatedTo , Australian Labor Party
Table 6:	20 questions and the corresponding paths selected in YAGO.
A.3 Correlation between Path confidence and Time Distance
The current sampling strategy believes that the greater the time distance of the same entity, the
greater the deviation of its semantic properties. Therefore, IMR adopts a time negative sampling
strategy to search for more effective paths. Path reliability is affected by semantic similarity, and
negative time-aware correlation is a general situation or statistical result. IMR proposes path relia-
bility to better measure the reliability of the searched path. Here we utiliZe Path Confidence of the
same path with different timestamps to analyZe the changes in semantic similarity over time. For the
same problem, we find the same path with various timestamps. We randomly select 20 questions for
path search, and each question selects the same path containing ten different timestamps to calculate
Path Confidence. The randomly selected questions and the corresponding search paths are shown in
Table 6 and Table 7. Figure 4 shows how the Path Confidence of each path changes with time and
distance.
Figure 4 shows that as the time distance between the paths and questions increases, the score of Path
Confidence gradually increases, indicating that its confidence is gradually decreasing. Experiments
show that the semantic deviation of the same entity increases as the time distance increases, which
verifies the rationality of time-aware negative exponentially sampling.
A.4 The Property of Offset in The Question Updating
In order to infer the correct tails, the Query Update Module should satisfy that the question still
matches the same tail entity even after the updating. As shown in Eq.14, the Query Updating Module
satisfies the property.
14
Under review as a conference paper at ICLR 2021
Question
Paths
Q1647 ,Reversed P190,Q2948 ,231
Q780378 ,P39 ,Q13653224 ,225
Q45178 ,P1435 ,Q20747146 ,229
Q450442 ,Reversed P26 ,Q1054316 ,230
Q358052 ,P1435 ,Q624232 ,222
Q840499,P31 ,Q484170,228
Q774064,P131 ,Q12626,227
Q80985 ,P190 ,Q31487 ,228
Q649 ,Reversed P551 ,Q440996 ,226
Q17397691 ,Reversed P579 ,Q184196,228
Q1170125 ,P31 ,Q484170 ,226
Q61306,P190,Q1489,229
Q911052,P1435 ,Q7934314,229
Q693208 ,P31 ,Q667509 ,226
Q622321 ,P463 ,Q253414,230
Q3120,P131 ,Q16394,223
Q838714 ,P131 ,Q1726339 ,224
Q21300,P131 ,Q12717,223
Q4974 ,P131 ,Q16227 ,230
Q337531 ,Reversed P463 ,Q432786 ,231
Q1647 ,Reversed P190,Q52981
Q780378 ,P166,Q987080
Q45178 ,P1435 ,Q20747146
Q450442 ,Reversed P26 ,Q1054316
Q358052,P1435 ,Q624232
Q840499 ,P31 ,Q484170
Q774064 ,P131 ,Q12626
Q80985,P190,Q2044
Q649 ,P31 ,Q515
Q17397691 ,Reversed P579 ,Q220373
Q1170125 ,P31 ,Q484170
Q61306,P190,Q5836
Q911052 ,P1435 ,Q7934314
Q693208 ,P131 ,Q854043
Q622321 ,P463 ,Q83276
Q3120,P131 ,Q16394
Q838714,P131 ,Q1726339
Q21300 ,P131 ,Q12717
Q4974 ,P131 ,Q16227
Q337531 ,Reversed P463 ,Q401557
Table 7:	20 questions and the corresponding paths selected in WIKI.
Datasets	MRR	H@1	H@3	H@10
ICEWS14	44.76±0.17	35.64±0.10	49.49±0.05	62.30±0.04
ICEWS18	32.45±0.13	22.97±0.07	36.05±0.05	49.36±0.03
WIKI	80.41±0.15	76.04±0.09	84.91±0.06	85.95±0.05
YAGO	90.24±0.18	87.91±0.12	92.65±0.09	92.77±0.08
Table 8: Mean and standard deviation of IMR across ten runs on four datasets.
eq- i + rq-i = eq-i-1 + rpi + rq-i-1 - rpi
= eq-i-1 + rq-i-1
= eq-0 + rq-0	(14)
= eq + rq
= eo
This cancellation of relation guarantees that the answer to questions will not change along with the
paths. In addition, the offset will not appear in the calculation of the indicator. Only the subject of
the question is applied in the calculation of Path Confidence, and only the relation in the question is
used in the calculation of Answer Completing Level.
A.5 The Robustness of IMR
We experiment on all datasets ten times by using ten different random seeds with fixed hyperparam-
eters. Table 8 shows the mean and standard deviation of IMR on these datasets. It shows that IMR
demonstrates a small standard deviation, which indicates its robustness.
15