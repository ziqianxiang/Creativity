Under review as a conference paper at ICLR 2022
Modeling and Eliminating Adversarial Exam-
ples using Function Theory of Several Com-
plex Variables
Anonymous authors
Paper under double-blind review
Ab stract
Reliability of a learning model is key to the successful deployment of machine
learning in various industries. Creating a robust model, particularly one that is
unaffected by adversarial attacks require a comprehensive understanding of the
adversarial examples phenomenon. In this paper, we present a model and a solu-
tion for the existence and transfer of adversarial examples in analytic hypotheses.
Grounding in function theory of several complex variables, we propose the class
of complex-valued holomorphic hypotheses as a natural way for representing the
submanifolds of decision boundary and samples simultaneously and specialize the
definitions of the optimal Bayes and the maximum margin classifiers to this class
of hypotheses. The approach is validated initially on both synthetic and real-world
classification problems using polynomials. Backed by theoretical and experimen-
tal results, we believe the analysis to be applicable to other classes of analytic
hypotheses such as neural networks.
1	Introduction
The state-of-the-art neural models are shown to suffer from the phenomenon of adversarial exam-
ples, where an artificial neural network (ANN) is fooled to return an undesirable output on particular
inputs that an adversary carefully crafts. The phenomenon is peculiar because it seems to affect neu-
ral networks in every application globally and that the adversarial examples are invariant to changes
in network architecture, transferring from one network to another. From the perspective of learning
theory, the existence of these samples is paradoxical since the nonrobust networks show acceptable,
even super-human, performance on the natural samples. In the literature, many attempts at resolving
this paradox have been made, each revealing a different facet of the phenomenon.
Szegedy et al. (2013) explained the adversarial examples as small pockets in the domain of the
hypothesis, where the hypothesis fails to be correct due to its highly nonlinear nature. In contrast,
Goodfellow et al. (2014) proposed that the phenomenon is a side-effect of a linear hypothesis in
high dimensions. Conversly, Ilyas et al. (2019) blamed useful nonrobust features that are effective in
dealing with natural samples; but are a hindrance when the model is tested on adversarial examples.
Barati et al. (2021) unified these different and opposing perspectives under the banner of pointwise
convergence of the hypothesis to the optimal hypothesis. However, they came short of describing
the transfer of the adversarial examples.
On a separate thread, Tanay & Griffin (2016) came up with a geometrical description of the phe-
nomenon in which adversarial examples are a byproduct of tilting the decision boundary towards
the natural samples. Shamir et al. (2019) observed that adversarial examples could be a natural con-
sequence of the geometry of Rn with a Hamming metric. Following that, Shamir et al. (2021) put
forward the dimpled manifold model, in which the decision boundary weaves through the submani-
fold of the samples, sitting very close to the natural samples.
In this paper, we attempt to unify all these proposals under what we call the diverging derivative
model by analyzing the phenomenon through the lens of functions of several complex variables.
The use of complex variables and functions enables us to consider the algebraic and the geometric
properties of the phenomenon simultaneously, leading to a rigorous framework to study the phe-
nomenon and a possible remedy for its effects. For this reason, we introduce a novel approach in
1
Under review as a conference paper at ICLR 2022
describing the submanifolds of samples and decision boundary using a complex-valued hypothesis
and continue by showing that the holomorphicity of this hypothesis is necessary for its robustness.
We then introduce the space of holomorphic hypotheses and show that, in the limit of infinite sam-
ples, all holomorphic hypotheses are forced to converge to the orthogonal projection of the optimal
Bayes classifier into the space of holomorphic hypotheses, explaining the transfer of adversarial
examples between analytic hypotheses. Finally, by generalizing the linear maximum margin classi-
fication rule to the case of holomorphic hypotheses, we pave the way for mitigating the effects of
the adversarial examples phenomenon.
2	The space of holomorphic hypotheses
We review holomorphic functions and discuss their various properties in appendix A. Here, we first
motivate complex-valued classifiers as the primary model for analyzing the adversarial examples
phenomenon in binary classification problems and continue by introducing the space of holomorphic
hypotheses in learning theory terms.
Given the observations made about the phenomenon in the literature, we can see that there are two
submanifolds that we need to consider in our analysis. The submanifold of natural samples S and
the submanifold of the decision boundary C. We assume that geometrical position of C and S are
represented using the equations u(x) = 0 and v(x) = 0 in which u : X → R and v : X → R
are smooth functions from the domain of samples to real numbers. Thus, h(x) = u(x) + iv(x) is
a smooth function from the domain of samples to the complex plane that encodes the information
about the two submanifolds simultaneously. Having h, we can determine the label of a sample by
looking at the sign of the real part of h(x). Similarly, we can determine if a sample is natural by
considering the imaginary part of h(x). These definitions are consistent with the standard notions
of the submanifolds of decision boundary and samples. For example, in the case of a 1D real-valued
classifier, the submanifold of the samples is the real line, which is a curve in the complex plane,
and the decision boundary is represented by the zeros of the hypothesis in which the real part is
zero naturally. Hence, we can simultaneously learn the submanifolds of samples and the decision
boundary by solving a regression and a classification problem.
Tanay & Griffin (2016) have shown that S and C are perpendicular in a robust linear classifier. As
a result, if u and v were linear functions of x, their contours had to be perpendicular everywhere
in Ω in order for h to be robust. From complex analysis, We know that this condition is known
as conformality and that conformality and holomorphicity are equivalent. First, we generalize the
result of Tanay & Griffin (2016) to the case of smooth complex-valued hypotheses.
Theorem 2.1	Suppose that C and S are represented by contours of real and imaginary parts of a
smooth function h : X → C,
C(h) = {x ∈ X | <[h(x)] =0}, S(h) = {x ∈ X | =[h(x)] =0}.	(1)
Suppose that c ∈ C is a point on the decision boundary and that <[h(x)] is a robust classifier. Then,
h is holomorphic in a neighborhood of c.
We see that a robust complex-valued hypothesis has to be holomorphic in a vicinity of the decision
boundary. As a consequence of the Cauchy-Riemann condition, constant functions are the only
holomorphic functions that could be defined on a set X ⊂ R. Thus, for h to be robust, we have
to assume that either the domain of h is complex, or that it is constant. While the transition from
domains in R to domains in C is a necessity from the standpoint of theorem 2.1, it has the added
benefit of enabling geometrical interpretations in scenarios where the previous proposals could not
be applied.
Barati et al. (2021) showed that the phenomenon could be observed in 1D problems. Since it is
impossible to extend the decision boundary outside the submanifold of samples in such cases, this
observation immediately conflicts with the dimpled manifold and the boundary tilting models. In
other words, since the decision boundary has a lower dimension than the domain of the hypothesis,
it is forced to be 0D in a 1D classification problem. How would a set of points wrap the training
samples? Or, from the boundary tilting perspective, How would one describe the angle between a
set of points and a line? To use the geometrical models of the phenomenon in 1D problems, we need
to assume some space for extending the decision boundary. Extending the domain of the hypothesis
2
Under review as a conference paper at ICLR 2022
from R to C would provide this necessary space. Consequently, we replace x ∈ Rd with z ∈ Cd,
and replace X ⊂ Rd with Ω ⊂ Cd to symbolize the transition from real variables to complex ones.
Theorem 2.1 shows that holomorphicity is enforced on a robust hypothesis in a limited sense. Pre-
cisely, the theorem asserts that h is analytic in a neighborhood of a point on the decision boundary.
We emphasize that theorem 2.1 does not specify anything about the characteristics of h outside of
a vicinity of the decision boundary. It is possible to construct smooth non-analytic functions that
satisfy the conditions of theorem 2.1, e.g. a meromorphic function. Nevertheless, we only consider
holomorphic functions in this paper since analysis of analytic functions is a well-known subject and
it is the first step in analysis of other less well-behaved hypotheses. Moreover, when we assume
that h is holomorphic, We can interpret h as a complex chart from Ω to C by definition. As a result,
C and S would be submanifolds of this complex analytic manifold in the same sense that R is a
submanifold of C, namely, they are smooth and locally Euclidean. Compact Riemann surfaces are a
prime example of the complex manifolds that we are considering in this paper.
In order to analyze a holomorphic function as a hypothesis in a learning algorithm, we first have
to define the space of holomorphic functions as a space of learnable hypotheses. It is customary
in analysis to represent the space of holomorphic functions on a domain Ω with O(Ω). Then, the
Bergman space A2(Ω) is defined as follows,
A2(Ω) = {f ∈O(Ω) |
L
Jω
If(z)∣2dV(z)1 ≡ kfkA2(Ω) < ∞},
(2)
in which dV(Z) is the volume differential of Ω. Since holomorphic functions has a unique power
series representation, we can deduce that the VC-dimension of A2(Ω) is upper bounded by the
VC-dimension of the space of polynomial hypotheses on Ω.
Theorem 2.2	A2(Ω) is nonuniform learnable.
We emphasize that theorem 2.2 cannot be used to define a learnable space on all possible domains
Ω. For example, if Ω = C, then the Bergman space does not exist. To give a complete account of the
subject of domains of holomorphic functions, one needs to analyze it through the lens of domains
of holomorphy. Nevertheless, as long as we choose Ω tobea convex and compact subset of Cd, it is
safe to ignore these subtleties. For example, there is no compact subset of C that cover R and thus
theorem 2.2 could not be used to define a learnable hypotheses space that covers R. On the other
hand, R ∪ {∞} could be mapped to the unit circle using a MObiUS transformation. Then, we can
assume Ω to be a disk, which is compact and convex.
A2(Ω) is a reproducing kernel Hilbert space with inner product hf, g)= Ω f (z)g(z)dV(z). The
Bergman kernel Kω (z, Z) is the unique function with the reproducing property
f(z) =
Jω
f (z)Kω(z,Z )dV (Z),
∀f ∈ A2(Ω).
(3)
Since A2(Ω) is a subspace of L2(Ω), an orthonormal basis {夕j}∞=ι for A2(Ω) exists. Due to
holomorphicity, the hypotheses that we consider in this paper are the hypotheses that has a power
series representation on their domain Ω,
h(z) = E Wa夕α(z),
∣a∣≥0
(4)
in which,
γα
I ∣z∣2a dV(z),
Jω
夕 a(z)
(5)
3
Under review as a conference paper at ICLR 2022
In equation 4 and equation 5, we have used the multi-index notation,
α 二(α1,α2,…，αd) αj ∈ No,
d
|a| =E αj,
j=1
d
zα =Yzjαj.	(6)
j=1
The next theorem is a well-known result in the function theory of several complex variables that
provides a way for computing the Bergman kernel of Ω.
Theorem 2.3	Let D be a compact subset of Ω. Then the series
∞
X ψj (z)ψj(Z)	(7)
j=1
sums uniformly on D X D to the Bergman kernel Kω(z, Z).
A remarkable fact about theorem 2.3 is that it is true no matter what the choice of complete or-
thonormal basis {夕j}∞=ι for A2(Ω) is. In other words, if the features 夕 were represented using a
Fourier series or some neural network instead of polynomials, equation 7 would still converge to the
Bergman kernel of Ω as long as We keep the set of features complete and orthonormal on Ω.
The reproducing property of the Bergman kernel of Ω in conjunction with the fact that no hypothesis
can get a better score than the optimal Bayes classifier provides the means to define the infinite
sample limit of any learning rule on A2 (Ω) independently from the details of the implementation or
training process.
Definition 2.1 (holomorphic optimal Bayes classifier) The holomorphic optimal Bayes classifier
is the orthogonal projection Ofthe optimal Bayes classifier into A2(Ω),
oD (Z)= f fD (Z)KΩ (z, Z) dV(Z),
Jω
(8)
in which Kω(z, Z) is the Bergman kernel of Ω and fD is the optimal Bayes classifier
As a consequence of definition 2.1, the adversarial examples of any two holomorphic hypotheses
would be similar since they are converging to the same hypothesis as we introduce more samples to
the training set.
Theorem 2.4 Suppose that h1,h2 ∈ A2 (Ω) are two complex-valued hypotheses that are trained on
two training sets Si, S2 〜D. Further, suppose that the size ofthe training samples are sufficiently
large. Then, the adversarial examples of h1 transfer to h2 and vice versa.
Theorem 2.4 provides a compelling explanation for the transfer of adversarial examples between
different analytic hypotheses, such as neural networks or polynomials. Our proposal is an extension
of the proposal of Goodfellow et al. (2014), in which the transfer of adversarial examples is at-
tributed to convergence to the optimal linear classifier. Theorem 2.4 formally describes the transfer
of adversarial examples in holomorphic hypotheses, including linear hypotheses.
3 Maximum margin classification in holomorphic hypotheses
In Tanay & Griffin (2016), it is argued that the adversarial examples phenomenon is a byproduct ofa
tilted decision boundary. It was also shown that linear maximum margin classifiers could be robust
if regularized correctly. Here, we follow up this proposal by introducing the holomorphic maxi-
mum margin classifier, which generalizes the linear maximum margin classifiers to holomorphic
hypotheses.
4
Under review as a conference paper at ICLR 2022
h(Ω)
Figure 1: A depiction of the shortest path from a sample z0 to C(h) and Z (h). the point h-1 (c)
represents the closest point on C to z0 .
From the perspective of a tilted boundary, the phenomenon occurs because the decision boundary
somehow tilts towards the submanifold of samples. Since the hypotheses in A2(Ω) are holomor-
phic, we can be assured that wherever C and S intersect, they form a right angle. Nevertheless,
holomorphicity of h would not assert that the learning rule has maximized the margin of the deci-
sion boundary, which could result in the occurrence of adversarial regions. The connection between
robustness and maximum margin classification has been studied before in the literature (Elsayed
et al., 2018; Ding et al., 2020). A maximum margin classifier is a classifier that maximizes the dis-
tance between the training samples and the decision boundary. In general, the distance between two
points on a manifold is defined as the length of the shortest curve that connects the two points with-
out leaving the manifold. According to h, the shortest curve from a sample to C is the preimage of
the straight path that connects the image of the sample z0 to C. Figure 1 illustrates the shortest path
from z0 to C in both the domain and the range of an arbitrary holomorphic hypothesis. The figure
shows that the shortest path from a sample to the decision boundary is a curve and not a straight line
in general.
Let Z(h) = {z ∈ Ω | h(z) = 0} be the zero set of h. We can see that Z(h) = C(h) ∩ S(h). Hence,
the shortest path on the submanifold of the samples from s ∈ S(h) to C(h) is equal with the shortest
path on the submanifold of samples from s to Z(h).
Theorem 3.1 Consider a Sample zo ∈ Ω ⊂ Cd and a hypothesis h ∈ A2(Ω). Suppose that Y :
[0,1] → Ω is the shortestPathfrom zo to Z(h). Then,
dj⑴=∂jhdh(t)) j = 口,…,%	⑼
Theorem 3.2 Consider a hypothesis h ∈ A2 (Ω) and a sample zo ∈ Ω. Suppose that Yz and Yc
are the shortest paths from zo to Z(h) and C (h), respectively. Furthermore, assume that γs is the
shortest path that connects the ends ofYc and Yz without leaving C(h). Then,
kYzk -kYsk ≤ kYck,	(10)
With equality being true iff =[h(zo)] = 0.
As a consequence of theorem 3.2, maximizing the margin of h ∈ A2(Ω) is equivalent with min-
imizing kYs k and maximizing kYz k for every training sample. According to theorem 3.1, we can
maximize ∣∣γz∣∣ for all training samples by maximizing | ∂hh(z) 12 everywhere in Ω. Moreover, by
minimizing |=[h(zo)]| for all training samples, we can make the bound given by theorem 3.2 as
tight as possible. In maximizing | ∂hh(z) 12 everywhere in Ω, We cannot utilize ∣h(z)∣2 since We do
not have access to oD(z) and using h(z) as a surrogate for oD(z) would reinforce any wrong predic-
tion of h(z) as well. On the other hand, from definition 2.1 we know that ∂doD(z) is as close to the
zero function as possible since it is the orthogonal projection of a step function into A2 (Ω). Thus,
5
Under review as a conference paper at ICLR 2022
minimizing ∣∂dh(z)∣2 in Ω is a true heuristic for finding od(z). It is easy to see that minimizing
∣∂dh(z)∣2 in Ω is equivalent with minimizing the L2 norm of d&h(z) for every dimension d. This
result is in accordance with the success of regularizing the Jacobian of a hypothesis in training robust
classifiers reported in literature (Ross & Doshi-Velez, 2018; Paknezhad et al., 2021).
Definition 3.1 (holomorphic maximum margin classifier) Let h be a holomorphic hypothesis
and let S = {(zm,tm) ∈ Ω X { —1,1}} be a set of training samples of size M. The holomor-
phic maximum margin classifier is the solution to the following program,
arg min h, ξ, ν	λ	kVh(Z)k2 dV (Z) + Jω	-1 X M乙 m=	ξm 1	+ νm
subject to	1 — ξm ≤ tm <[h(Zm )]	m=	1, 一	∙ ,M,
	—Vm ≤ =[h(Zm)] ≤ νm	m=	1, 一	∙ ,M,
	0 ≤ξm	m=	1, 一	∙ ,M,
	0 ≤ νm	m=	1, 一	∙ ,M
(11)
We can show that the linear maximum margin classifier is a special case of Definition 3.1. Assume
that h = wHz + b is a linear classifier, then,
∣∣Vh(z)k = kwk.	(12)
Since kwk is independent of z, we can take it out of the integral. Thus, the remaining integral
will be computing the volume of Ω which is a positive constant that does not depend on any of the
optimization variables. Consequently, we can merge the integral with λ and we are left with a linear
maximum margin classification program.
From the form of problem ??, it is evident that the standard and holomorphic maximum margin
classification are very similar and that we can make use of the kernel trick in the case of holomorphic
maximum margin classification. Moreover, the notion of support vectors is the same in the standard
maximum margin formulation and the holomorphic formulation, differing only in the addition of
support vectors for the regression part of the holomorphic formulation.
4	S ynchronization
According to Ilyas et al. (2019), the existence of adversarial examples is rooted in the existence of
useful but nonrobust features. However, the perspective does not consider scenarios where nonrobust
features are not only useful, but also essential to classify samples correctly. Furthermore, making use
of nonrobust features does not automatically result in a nonrobust hypothesis. For example, consider
the Fourier expansion ofan optimal Bayes classifier, e.g. sign(x). The high-frequency Fourier bases
are categorized as useful nonrobust features as stated by the definition of useful nonrobust features
in such a scenario. However, we know that the Fourier expansion of the optimal Bayes classifier is
robust and is equal with the optimal classifier and that the higher-frequency bases are essential for
an accurate approximation of the classifier.
In this section we utilize definition 3.1 and introduce the concept of synchronized features as an
improvement to the core idea of robust features of Ilyas et al. (2019).
Theorem 4.1 Suppose that h is a holomorphic hypotheses with the following representation,
n
h(Z) = b + X Wj ψj(Z),	(13)
j=1
6
Under review as a conference paper at ICLR 2022
where {夕j }n=ι is a Set of holomorphic features. Then, the dual problem of the holomorphic maxi-
mum hard margin program is as follows,
arg max λ, θ	M	1MM X : <[αm] - 2ΣΣtntm αn am ^^ ς ,2 m, m=1	m=1 n=1 M
sub ject to	X tmαm = 0,	(14) m=1 0 ≤ λm m = 1,…，M, 0 ≤ θm m = 1,…，M
where ɑm, = λm + iθm and	Σ =	JW(Z)JW(Z)H dV (Z),	(15) Jω
where JW(Z) is the Jacobian matrix of 夕=[夕j].
Σ is a positive definite square matrix that We call the synchronization matrix of {夕j∙}. We can inter-
pret Σ as a metric on the space of hypotheses spanned by 夕 and infer that the holomorphic maximum
margin learning rule prioritizes hypotheses With smaller kwkΣ. Computing the synchronization ma-
trix paves the Way to make use of nonrobust features robustly. Consequently, We see that dividing
the useful features into robust and nonrobust categories is not helpful, and it is better to categorize
feature sets instead of individual features. With robustness in mind, it is possible to isolate a par-
ticular category of feature sets identified With the property that their synchronization matrix is the
identity matrix.
Definition 4.1 (synchronized feature Set) Let {夕j } be a set of features in which
Za(Wj(Z))H(V^k(z)) dV(z) = {0 if j = k ,	(16)
then {夕j } is a set of synchronized features and Ω is its synchronization domain.
For a set of synchronized features kwkΣ = kwk. In other Words, the objective of the holomorphic
maximum margin learning rule coincides With minimizing the `2 norm of the Weights. It should be
clear from Definition 4.1 that the feature set of a linear hypothesis is synchronized up to a normal-
ization constant. This fact explains the observation made in Tanay & Griffin (2016) about the ef-
fectiveness of`2 regularization of the Weights in suppressing the adversarial examples phenomenon
in linear classifiers. There is no reason to assume that the features of an artificial neural netWork
are synchronized Which explains the ineffectiveness of `2 regularization in training robust neural
classifiers.
We can synchronize any set of features φ given the synchronization matrix Σ. Seeing that Σ is
positive definite, its matrix square root exists, is unique, and it is a positive definite matrix. Thus,
we can synchronize 夕 as follows,
φ*(z) = ς- 1 φ(z).	(17)
Then, the synchronization matrix of 夕* would be the identity matrix,
Σ*
/
Jω
Jw*(z)J(w*(z)h dV (z),
∑-1 J JW(Z)JW(Z)H dV(z)∑-JH,
Jω
Σ-1ΣΣ-H = I.
(18)
5	The diverging derivative model
In this section, we put the proposed framework into practice and use it to analyze the phenomenon.
Figure 2 visualizes the trained hypotheses by applying the maximum margin learning rule to a set
7
Under review as a conference paper at ICLR 2022
Orthonormal
Synchronized
ι.o
0.5
⅛ 00
-0.5
-1.0
-1.0 -0.5 0.0	0.5	1.0
-1.0 -0.5 0.0	0.5 ι.o
JR[z]
JR[z]
Figure 2: 1D orthogonal and synchronized hypotheses on the complex plane. The black and white
contours represent the contours of imaginary and real parts of the hypotheses, respectively. The
training samples are depicted using black dots. Hue and saturation of the colors represent the argu-
ment and the magnitude of h(z), respectively.
of orthonormal and synchronized polynomial features on the unit disk D. We omit the details of
the implementation to make room for more content. The interested reader can find these details and
more in appendix C. We can see in the figure that the submanifold of the decision boundary of the
orthonormal hypothesis curves back and gets close to the submanifold of the samples, resulting in
adversarial regions near the boundary of the disk. In contrast, the synchronized hypothesis does not
show any adversarial regions in the unit disk.
Figure 2 shows that the region of the convergence of the power series corresponding to the orthonor-
mal hypothesis does not cover the entirety of the unit disk. On the other hand, the convergence region
of the synchronized hypothesis is a little bigger than the unit disk. This observation is the essence
of our proposal; the diverging derivative model for the adversarial examples phenomenon. To be
more precise, according to theorem A.1 in appendix A, a holomorphic hypothesis converges to the
optimal hypothesis in both value and all of its derivatives. When we do not use a set of synchronized
features, `2 regularization of the weights does not guide the learning rule to the hypothesis with the
smallest derivative, the maximum margin hypothesis, but rather to the hypothesis with the smallest
value. As a result, the derivative of the hypothesis is free to get as large as possible to fulfill both
the training loss and the regularization objectives. In turn, this unbounded increase in the magnitude
of the derivative shrinks the convergence region of the hypothesis, resulting in adversarial regions
around the submanifold of the samples.
Compared to other proposals in the literature, the diverging derivative model has some unique advan-
tages. First, it bridges the geometrical and functional approaches to describing the phenomenon. On
top of that, the model connects these two approaches through the analyticity of the hypotheses space
and enables the use of a host of powerful algebraic tools. Moreover, by representing the hypothesis
by a power series, the diverging derivative model simplifies the analysis of different hypothesis by
making the analysis of the hypothesis independent from the details of implementation of h, such as
architecture. We provide more simulations and experiments in appendix C.
6	Conclusion and future research
This paper proposed a model to explain the existence and transfer of adversarial examples in holo-
morphic hypotheses. According to our proposal, the adversarial examples occur due to the diver-
gence of the derivative of the trained hypothesis. These examples transfer to other analytic hy-
8
Under review as a conference paper at ICLR 2022
potheses because the projection of the optimal model into the space of holomorphic functions on a
domain is uniquely decided by the Bergman kernel of the domain, and itis independent of the details
of implementation or training. Moreover, we generalized the linear maximum margin classifier to
holomorphic functions and introduced synchronized features as a solution to the phenomenon. We
ground the model on rigorous analysis of the phenomenon and provide empirical evidence support-
ing the proposal.
Given the nature of the proposal, one may imagine that a similar approach could be applied to
real analytic functions as well, and that there is no need to consider holomorphic functions and
complex variables. Opposite to complex analytic functions, real analytic functions are not closed
under uniform convergence. In other words, there is no guarantee that the limit of a sequence of
analytic functions that converge uniformly is analytic. This is a major hurdle in considering real
analytic functions as a learnable hypotheses space and complex variables and functions are unique
in this regard.
The Achilles heel of our proposal is that computing the objective of problem 11 in high dimensions
is NP-hard in the general case. In particular, implementing the holomorphic maximum margin clas-
sification for ANNs would require stochastic optimization techniques to the best of our knowledge
(see appendix D). Nonetheless, we can see that it would be implementable for polynomials if we can
come up with an efficient way to select useful polynomial features. Another promising approach to
this problem is to use the dual formulation of problem 11, in which we would need the synchronized
kernel of the domain or an approximation of it. On top of these, since the submanifold of samples is
explicitly determined in a complex-valued hypothesis, our proposal could find use in implementing
the solutions mentioned in Shamir et al. (2021) by providing a way to project the test sample into
the submanifold of natural samples.
Another shortcoming of our approach is that it is based on the analysis of a binary classification
problem. Even though our experiments suggest that the analysis generalizes to the multiclass clas-
sification problem, extending the proposal’s reach in its current form to other machine learning
applications does not seem feasible. We believe that the most helpful analysis would be when a
sufficient robustness condition is derived from the training loss function. Our approach in defining
the shortest path from a sample to the decision boundary can be generalized in this regard.
References
Ramin Barati, Reza Safabakhsh, and Mohammad Rahmati. Towards explaining adversarial exam-
ples phenomenon in artificial neural networks. In 2020 25th International Conference on Pattern
Recognition (ICPR),pp. 7036-7042, 2021. doi:10.1109/ICPR48806.2021.9412367.
AUgUstin Chevallier, Sylvain Pion, and Frederic Cazals. Improved polytope volume calculations
based on hamiltonian monte carlo with boundary reflections and sweet arithmetics. 2020.
Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, and Ruitong Huang. Mma training:
Direct input space margin maximization through adversarial training. In International Confer-
ence on Learning Representations, 2020. URL https://openreview.net/forum?id=
HkeryxBtPB.
Dheeru Dua and Casey Graff. UCI machine learning repository, 2017. URL http://archive.
ics.uci.edu/ml.
Gamaleldin Fathy Elsayed, Dilip Krishnan, Hossein Mobahi, Kevin Regan, and Samy Bengio. Large
margin deep networks for classification. 2018. URL https://arxiv.org/pdf/1803.
05598.pdf.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014.
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander
Madry. Adversarial examples are not bugs, they are features. arXiv preprint arXiv:1905.02175,
2019.
Steven George Krantz. Function theory of several complex variables, volume 340. American Math-
ematical Soc., 2001.
9
Under review as a conference paper at ICLR 2022
T. Needham. Visual Complex Analysis. Comparative Pathobiology - Studies in the Postmodern
Theory of Education. Clarendon Press, 1998. ISBN 9780198534464. URL https://books.
google.com/books?id=ogz5FjmiqlQC.
Mahsa Paknezhad, Cuong Phuc Ngo, Amadeus Aristo Winarto, Alistair Cheong, Beh Chuen Yang,
Wu Jiayang, and Lee Hwee Kuan. Explaining adversarial vulnerability with a data sparsity hy-
pothesis, 2021.
Andrew Slavin Ross and Finale Doshi-Velez. Improving the adversarial robustness and interpretabil-
ity of deep neural networks by regularizing their input gradients. In Thirty-second AAAI confer-
ence on artificial intelligence, 2018.
Adi Shamir, Itay Safran, Eyal Ronen, and Orr Dunkelman. A simple explanation for the existence of
adversarial examples with small hamming distance. CoRR, abs/1901.10861, 2019. URL http:
//arxiv.org/abs/1901.10861.
Adi Shamir, Odelia Melamed, and Oriel BenShmuel. The dimpled manifold model of adversarial
examples in machine learning, 2021.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.
Thomas Tanay and Lewis Griffin. A boundary tilting persepective on the phenomenon of adversarial
examples. arXiv preprint arXiv:1608.07690, 2016.
A Functions of several complex variables
In this section, we give a brief introduction to the theory of functions of several complex variables.
For a review of the subject see Needham (1998) and Krantz (2001). In order to establish notation,
We first review the case of one complex variable. Let Ω ⊂ C 〜R2 be a domain in complex plane
and let f (x, y) = u(x, y) + iv(x, y) represent a complex-valued function on Ω. We write,
Z = X + iy,	Z = X — iy,	(19)
dz = dx + idy,	dz = dx — idy.	(20)
Then the differential of f at a point a is given by
df (a) = ^-(a)dx + ^J-(a)dy
xy
+ ιιf )(a)dz + 1( IX - i∂f )(a)dz.	QI)
the following notation is introduced:
∂f	10	1 ∂f	∂f	1 ∂f	1 ∂f
=1=
∂z	2' ∂x	i ∂y	∂Z	2' ∂x	i ∂y
to simplify equation 21 to
∂f	∂f
df (a) = ~^~(a)dz + ~(a)dz.
(23)
For a differentiable map, one has complex differentiability at a when the Cauchy-Riemann condition
(C-R condition) holds at a:
f (a) = 0.
∂z
(24)
If a function f is complex differentiable on every point of Ω, then it is called holomorphic.
Holomorphic functions are the main object of interest in our discussion. The interest in these func-
tions comes from the fact that conformal maps and analytic functions are holomorphic. A conformal
map is a complex-valued function in which the contours of the real and imaginary parts of that func-
tion are perpendicular. An analytic function is a function that is equal with its Taylor series. The
10
Under review as a conference paper at ICLR 2022
equivalence of complex differentiability, conformality and analyticity is a profound, nontrivial re-
sult in complex analysis. In other words, complex differentiability, analyticity and conformality of
a complex-valued function are one and the same with holomorphicity of that function.
In case of Ω ⊂ Cn, a function f : Ω → C is complex differentiable if it is holomorphic in every
dimension separately and we write
∂j f
∂f
dzj
1( ∂f
2( ∂xj
j = 1,…，n
(25)
or ∂f = 0 for short and refer to this system of equations as the ∂ equation.
We say that a sequence {fj}∞=ι converges compactly on Ω if {fj} converges uniformly on each
compact subset of Ω. In our discussion, a significant fact about O(Ω) is that it is closed under
compact convergence.
TheoremA.1 Suppose {fj}∞=ι ⊂ O(Ω) converges compactly in Ω to the function f : Ω → C.
Then f ∈ O(Ω) andfor each α ∈ Nn,
lim ∂αfj = ∂αf
j→∞
compactly in Ω.
In theorem A.1 We have used the multi-index notation ∂α = d：1 ∂?2 …∂nn.
B Proofs of the theorems
B.1 Theorem 2.1
First assume that samples are 1D. Without loss of generality We can assume that h(c) = 0. Since h
is smooth, the real and imaginary part of h(x) = u(x) + iv(x) could be approximated using a linear
complex function g in a neighborhood of c,
g(x) = (x - c) u0(c) + iv0 (c) .
(26)
Since it is assumed that u is a linear robust classifier, We knoW from (Tanay & Griffin, 2016) that
C(h) and S(h) are perpendicular on c. Thus, v0(c) is a 90 degree rotation ofu0(c). Since multiplica-
tion by i could be interpreted as another 90 degree rotation, We can conclude that u0(c) + iv0 (c) = 0.
Hence, if u and v are functions of a real variable, they are forced to be constant around c,
du dv	du dv
dx(C) + F = 0 ⇒ dx (C) =五(C) = 0.
(27)
In the case that x is a complex variable, u0(c) + iv0(c) = 0 Would result in the Cauchy-Riemann
condition,
∂u
∂x
∂u
∂y
∂v
∂y,
∂v
∂x .
(28)
(29)
—
As a result, We can conclude that h is holomorphic in a neighborhood of a point C ∈ C(h).
In the case Where samples are d dimensional, similar argument folloWs. First approximate h using
linear functions around C. Then, fix all the coordinates of C except one, e.g. xj. Similar to above, We
reach the conclusion that h needs to satisfy Cauchy-Riemann condition in xj . Since the choice of
xj Was arbitrary, We conclude that h needs to satisfy the C-R condition in every dimension. Hence
h is holomorphic in a vicinity of C ∈ C(h).
B.2 Theorem 2.2
Since h ∈ A2 (Ω) is holomorphic, it could be represented using a power series,
h(z) = E Wa夕:(z),	(30)
0≤∣a∣
11
Under review as a conference paper at ICLR 2022
in which {夕} is a set of complete and orthonormal polynomials on Ω. Consequently, We define the
truncated hypotheses space HΩ,
Hn = {h(z) | X wɑψα(z)}.	(31)
0≤∣ɑ∣≤n
Thus, the VC-dimension of the real (or imaginary) part of h ∈ 酒 cannot get larger than the VC-
dimension of the space of polynomial hypotheses of degree n. Hence, it is finite. Furthermore,
∞
A2(Ω) = U HΩ.	(32)
n=0
Thus, A2 (Ω) is nonuniform learnable.
B.3 Theorem 2.4
Since h1,h2 ∈ A2 (Ω), they could be represented in a power series form,
hj (Z)= E Wj,α^α(z).	(33)
0≤∣α∣
Since hj is trained on Sj, we can conclude that loss ofhj would be less than some j with probability
1 - δj and that (ej, δj) are determined by the sample complexity of A2(Ω) and the size of Sj.
We know that od has the lowest possible loss e* and that od can be represented in a similar form to
hj . Thus,
hj(z) = OD(z) + E aj,α夕α(z)∙	(34)
0≤∣α∣
Hence,
sup | E aj,α夕α(z)∣ ≤ Ej + e*,	(35)
z∈ω ^≤μ∣
with probability 1 - δj . Consequently,
hl(z) - h2(z) = E ai,α夕α(z) - E。20Pα(z)	(36)
0≤∣α∣	0≤∣α∣
Thus,
sup ∣hι(z) - h2(z)∣ ≤ 2e* + Ei + Ej,	(37)
z∈Ω
with probability (1 - δ1)(1 - δ2).
We conclude that as we increase the size of the training samples, supz |h1 (z) - h2 (z)| gets smaller.
As a result, for large enough training sets, h1(z) and h2(z) would be close in value.
B.4 Theorem 3.1
Since h ∈ A2(Ω) is holomorphic, it is equal with its Taylor series expansion around a point Z = γ(t),
h(z + η) = X d h(z) ηα.	(38)
α!
0≤∣α∣
in which η is an arbitrary direction. Without loss of generality we can assume that all elements ofη
except ηj- are zeros and that η = dj(t). Then,
h(Z + η) = h(Z) + ηj ∂j h(Z).	(39)
Consequently,
dγj (t)=V	(40)
dt	∂j h(γ (t))
12
Under review as a conference paper at ICLR 2022
B.5 Theorem 3.2
The length of a C1 curve Y : [0,1] → Ω in A2(Ω) is calculated as follows,
l∣γk = Z (Xgi,j(Y(U)Yi⑴Yj⑴)2dt,	(41)
0 j,k
in which {gi,j } is a Hermitian metric called the Bergman metric.
As depicted in the figure 1, we only need to use the fact that h(z) is a holomorphic chart of a complex
analytic manifold. Then, the theorem would simply result from the triangle inequality.
lYzl ≤ lYcl +lYsl ⇒lYzl -lYsl ≤ lYcl.	(42)
B.6 Theorem 4.1
The analogue hard margin problem of the holomorphic maximum margin classification rule is as
follows,
arg min
w, b
1WH Σw
subject to 1 ≤ tm<[h(zm)]
m = 1,…，M,
(43)
=[h(zm)] =0 m =1,…，M
in which Σ is the synchronization matrix. Thus, the Lagrangian is defined as follows,
1M
L = 2W ςw + ɪ2 λm(I - tm<[h(Zm)D + θm = [h(Zm)]∙
m=1
We know,
<[z]=2(Z+z) =[z]=£(Z—Z).
First, we solve for b,
∂L-X+ (λ /、
∂b = 2^tm(λm + Iltmj
m=1
M
=	tmαm.
m=1
Thus,
M
tmαm = 0.
m=1
Next, we solve for W,
∂L	1 M ∂	∂
∂W = 2ςw - ΣL tmλm ∂W<[h(Zm)I + θm ∂W = [h(Zm)],
in which We have used matrix calculus notation. In other words, ∂∂L is a vector.
Thus,
M
W =):力团。团夕	ψ.
m=1
(44)
(45)
(46)
(47)
(48)
(49)
(50)
We get the dual function by replacing W and b in the Lagrangian,
M	1MM
g(λ, θ) = E <[αm] - 2ΣΣtntm αn am ψn ς 2m ∙	(51)
m=1	m=1 n=1
13
Under review as a conference paper at ICLR 2022
Consequently, the dual problem of the holomorphic hard maximum margin is as follows,
arg max λ, θ	M	1MM E <[αm] - 2 ΣS Σ tntmαnam夕n ς ψm, m=1	m=1 n=1 M
sub ject to	X tmαm = 0,	(52) m=1 0 ≤ λm m = 1,…，M, 0 ≤ θm m = 1,…，M
Since the primal problem is convex and Slater’s condition is trivial for the equality constraints,
strong duality holds.
C Detailed experiments
C.1 Synchronized polynomials
We will be needing the kernels of the orthonormal and synchronized polynomial features of the unit
disk D. Finding the kernel of the orthonormal features is straightforward. It is known that,
γj
|z|2j dV (z),
D
π
=j+1,
zj
ψj(Z) = -μ≡ j ∈ {0,…，∞},
√γj
(53)
is an orthonormal basis for A2(D). Thus, the kernel of the orthonormal features is calculated as
follows,
∞j
κ(z,ζ) = X j+~ (ZZy,
j=1 π
_	1	1
π(1 — zZ)2	∏
(54)
In other words, the kernel of the orthonormal polynomials on Ω is the Bergman kernel of Ω minus
the term that is contributed by the zero degree polynomial. Similarly,
Yj= j 12|z|2(jT)
D
dV (Z),
j ∈ {1,…,∞},
(55)
are the synchronized polynomials on D. Thus, the kernel of the synchronized features is as follows,
K j(z,Z ) = X ①,
j=1 jπ
1	, F
=—Li1(ZZ),
π
1., F
=-----In(I - ZZ),
π
in which Li1 is the polylogarithm function of order 1.
(56)
14
Under review as a conference paper at ICLR 2022
We show that training a polynomial that is represented by a synchronized basis is robust. As our
first experiment, we choose a training set Sn which is generated by the following rule,
Xnj = 2~ - 1,
n
znj = xnj + 0.25i sin πxnj ,
Sn+1 = {(znj, Sign(Xnj) | j =0,…，n}.	(57)
Next, we train two classifiers that make use of either an orthonormal set of polynomial features or a
set of synchronized polynomials. We choose the following hypotheses spaces to apply our learning
rule to,
d
Hd = {h(z) | h(z) = W0 + X WjΨj(z) Wk ∈ C},	(58)
j=1
d
Hd = {h(z) | h(z) = wo + X Wj工(Z) Wk ∈ C},	(59)
j=1
where 夕j and φd are defined by equation 53 and equation 55.
Figure 2 visualizes the result of applying a learning rule similar to problem 11 to H20 and H2d0 with
the sole difference that the integral in the objective is replaced by kW k. In the case of H20, the
learning rule is similar to the standard maximum margin learning rule, and for H2d0 it is equivalent
with the holomorphic maximum margin learning rule. We have also colored the figure using a
domain coloring technique to help with the identification of S(h), C(h) and Z (h). The hue of the
colors represent arg h(z) with cyan equaling ∏ or -∏, red 0, green-yellow ∏2 and purple-blue - ∏2
and the saturation of the colors represent |h(z)|. The zeros are identified with the property that all
the possible hues surround them. Figure 2 shows that the decision boundary of the hypothesis with
orthonormal features has curved back and became parallel with the submanifold of the samples near
the boundary of the unit disk.
On the other hand, the holomorphic maximum margin learning rule resulted in a hypothesis that
did not show a similar trait, and the decision boundary continued in a path perpendicular to the
submanifold of the samples. We argue that Figure 2 describes the nonlinear version of the boundary
tilting perspective that is conjectured by Tanay & Griffin (2016). The pattern of the colors also
marks the domain of convergence of the hypothesis, and we can see that the synchronized features
have resulted in a larger domain of convergence.
In the last experiment, the hypotheses were complex analytic. Next, we examine the scenario where
the hypotheses are real analytic functions, in which the pointwise limit of a sequence of analytic
functions is not guaranteed to be an analytic function. Similar to Barati et al. (2021), we choose the
training samples to be,
Sn+1 = {(x, Sign(X)) | x = 2j - 1 j = 0,…，n}.	(60)
n
Then, we train two maximum margin classifiers that use the orthonormal and the synchronized
Chebyshev basis, respectively. It is known that,
dTn (X)
—-----=nUn-i(x),
dX
(61)
where Tn and Un-1 are Chebyshev basis of the first and second kind, respectively. {Tn} form a
sequence of orthonormal polynomials on [-1,1] with respect to the weight function W(X) = √ι-χ2,
if n 6= m,
Tn (X) Tm (X)W(X) dX = π
JT	12
if n = m = 0,
if n = m 6= 0.
1	(2ndmin(n,m)e	if n,m odd,
U Un(x) Um(X)W(X) dx = < n + 2π[mm(『m)C	if n, m even,
T	I 0	otherwise.
(62)
(63)
15
Under review as a conference paper at ICLR 2022
orthogonal	synchronized
Figure 3: 1D orthonormal and synchronized Chebyshev hypotheses on the real line. We have used
the basis functions up to degree 30 and S6 in both cases.
orthogonal
synchronized
-0.5
-1.0
1.0-
0.5-
⅛ 00 -
-1.0 -0.5 0.0	0.5	1.0
-1.0 -0.5 0.0	0.5	1.0
∑R[z]
∑R[z]
Figure 4: 1D orthonormal and synchronized hypotheses on the complex plane. The domain of
convergence of the hypotheses does not cover the whole unit disk contrary to expectation. In case of
orthonormal features, the domain of convergence does not even cover the whole of [-1, 1] interval.
16
Under review as a conference paper at ICLR 2022
Similar to orthonormalization, the effect of weight functions on synchronization is to determine the
importance of each point in the domain. We calculate the synchronization matrix of {Tn} using
equation 61 and equation 63.
We can see the results for training a Chebyshev polynomial of degree 30 on S6 in Figures 3 and 4.
Figure 3 shows the classifiers on the real line, and it demonstrates that the synchronized hypothesis
is robust. Figure 4 shows the hypothesis on the complex plane. In this figure, we can see that S(h)
and C(h) are perpendicular, irrespective of the robustness of the hypotheses. The phenomenon is
enabled by parts of S (h) that have branched out from the real line into the complex plane. It is
deducible from the figures that the synchronized hypothesis has maximized the distance between
the training set and Z(h) and has a bigger domain of convergence.
Figure 4 suggest that adversarial regions are not always a result of a tilted boundary, but they are a
result of copies of the decision boundary that are present in the complex plane and cross S(h) multi-
ple times. These copies of the decision boundary are also available in the synchronized hypothesis,
but they do not cross S(h) in a neighborhood of the synchronization domain.
Since powers of z are holomorphic and form an orthogonal basis on the unit disk, we expect that the
trained hypothesis be holomorphic on the unit disk D. However, it is evident from Figure 4 that the
domain of convergence does not cover the whole disk in either hypotheses. A similar effect is ob-
servable in function approximation when we approximate analytic functions with singularities using
polynomials. This observation suggests that the holomorphic optimal Bayes classifier is singular
somewhere on the complex plane. The holomorphic optimal Bayes classifier oD (z) is calculated as
follows,
oD(z) =
D
fD(ζ)K(z, ζ) dV (ζ)
sign(r cos θ)
π(1 — zre-iθ )2
rdrdθ
i
—(ln(—z — i) — ln(—z + i)) + ….
π
where
is the optimal Bayes classifier and
fD(z) = sign(<z),
K(z, ζ)
1
∏(1 - zZ)2
(64)
(65)
(66)
is the Bergman kernel of D.
The existence of adversarial regions could be analyzed from two different perspectives; the holo-
morphic maximum margin classifier’s primal and the dual formulations. Nevertheless, the duality
of the two formulations suggests that both of these interpretations are the same and that it would be
incorrect to prefer one over the other.
The primal formulation suggests that the phenomenon occurs because the derivative of the trained
hypotheses is diverging. From equation 64 itis evident that oD(z) has two logarithmic branch points
on i and —i and that it is a transcendental function. Thus, it cannot be expressed in terms of a finite
sequence of algebraic operations. Consequently, the space of polynomial hypotheses of finite degree
is agnostic to oD(z). As a result, the learning rule has to compensate for this shortcoming somehow.
The singularities in the complex plane force the learning rule to prefer higher degree polynomials
to lower degree ones, even when the decision boundary could be easily represented using a linear
hypothesis. Since a nonrobust learning rule only seeks the uniform convergence of h, it is fooled
into choosing a hypothesis that does not uniformly converge in its derivative, producing adversarial
regions near the training points.
The dual of the holomorphic maximum margin optimization problem suggests another perspective
on the phenomenon. An orthonormal set of polynomial features would result in a kernel that has a
pole for its singularity as demonstrated by equation 54 whereas the singularities of equation 64 are
logarithmic branch points. The discrepancy between the singularities results in the wrong hypothesis
to be learned by the maximum margin learning rule. In contrast, the kernel of a synchronized set of
17
Under review as a conference paper at ICLR 2022
Figure 5: 2D orthonormal and synchronized hypotheses. We have used basis functions up to degree
30 in both dimensions and 100 equispaced samples to train the classifiers.
polynomials exhibits the correct type of singularity as demonstrated by equation 56, which would
then be able to represent the optimal hypothesis correctly.
We conducted an experiment on a 2D synthetic problem using orthonormal and synchronized 2D
Chebyshev polynomials as well and reported the result in Figure 5. The optimal Bayes classifier is
fD(x) = sign(kxk∞ - 0.5)	(67)
in this experiment and the synchorization matrix is computed using equation 61, equation 62, equa-
tion 63. The results agree with the dimpled manifold model in the sense that the decision boundary
appear to be weaving through the submanifold of the samples. Nonetheless, adversarial regions are
positioned between the training points. This observation is not predicted by the dimpled manifold
model.
C.2 Synchronization in real-world problems
For our next experiment, we train a few maximum margin classifiers on the UCI ML handwritten
digits dataset (Dua & Graff, 2017) that use orthonormal and synchronized Chebyshev polynomials
as features. The samples are 8-by-8 black and white pictures of handwritten digits. The reason for
choosing this dataset over MNIST is that it is relatively low dimensional compared to the MNIST
family while being complicated enough to be a good representation of a real-world dataset. Nev-
ertheless, the combinatorial explosion of possible polynomial features is still severe. To keep the
training procedure computationally feasible, we limit the degree of the polynomials in a manner in-
spired by Markov random fields. More precisely, we first create an 8-by-8 lattice graph and connect
each node to itself. Then, we enumerate all unique walks on this graph up to a certain length. The
nodes decide the uniqueness of a walk. For example,
(3,2)→(3,2)→(3,3)
and
(3,2)→(3,3)→(3,2)
are considered the same. Finally, we assign each dimension to its corresponding node in the graph
and choose the degree by counting the occurrence of each node in a walk. For example,
(3,2)→(3,2)→(3,3),
18
Under review as a conference paper at ICLR 2022
P-Ouwld ∙6>ro
Figure 6: The weighted average f1-score of the models in natural and adversarial settings on the
digits dataset.
corresponds to T2(x32)T1 (x33). We calculate the synchronization matrix with respect to the nor-
malized weight function w(χ) = ∏√-χ2, so that Σjk does not become so large that elements of
Σ-2 approach zero.
After splitting the dataset into train and test sets using 50% of samples for each, we train maximum
margin classifiers with polynomial kernel up to degree 4 on the train set and attack these classifiers
using a l2 normalized, one-step attack on the test set. Next, we train new classifiers for Chebyshev
polynomials with the same degree and compute the weighted average of f1-score of the classifiers
on the natural test samples and the adversarial test samples of the polynomial kernel classifier. We
have reported the results of the experiment in Figure 6.
Figure 6 reports the accuracy of maximum margin classifiers that were trained on the UCI ML hand-
written digits dataset (Dua & Graff, 2017) and used different polynomials as features on natural and
adversarial test samples. One of the models uses the polynomial kernel, and the other two use the
orthonormal and synchronized Chebyshev polynomials as features. We have used the classifier with
the polynomial kernel as the baseline since it employs all the polynomial features up to a certain
degree. In contrast, due to the combinatorial explosion of possible polynomial features in high
dimensions, the Chebyshev polynomial features were selected based on a scheme founded on the
position of the pixels in the image. The adversarial examples are generated by attacking the baseline
using a one-step, `2 normalized, gradient-based attack.
We can see that as we increase the degree of the polynomial, the model’s performance improves on
the natural samples as expected. In the adversarial setting, the performance of the models increases
as we move from a linear hypothesis to a polynomial of degree 2. This observation follows the
linearity hypothesis of Goodfellow et al. (2014), and we conclude that a linear hypothesis is not
strong enough to represent the robust optimal hypothesis. However, as we increase the degree of
the polynomial, the performance of non-synchronized hypotheses is dominated by the effect of the
diverging derivative and worsens, a trait that is not shared with the synchronized hypothesis. We
present these results as evidence for useful nonrobust features that are essential in constructing a
robust hypothesis if regularized correctly.
19
Under review as a conference paper at ICLR 2022
Table 1: The accuracy of the neural and the Bergman hypothesis on the adversarial examples in
the direct and transferred scenarios. The results suggest that the two hypothesis represent the same
decision boundary.
source
1
(υ
S
MLP BKM
MLP	0.07	0.30
BKM	0.09	0.27
C.3 Transfer of adversarial examples
This section is dedicated to examining the transfer of adversarial examples between holomorphic
hypothesis. In an experiment we compare the adversarial examples of a kernel machine with the
Bergman kernel and an artificial neural network on the MNIST dataset. For the neural network
hypothesis, we use a standard multi-layer perceptron (MLP) with tanh activation function and the
space of kernel machine hypotheses (BKM) is as follows,
M
HM = {h(z) | h(z) = w0 +	wmK(z, ζm)},
m=1
in which K is the Bergman kernel of the d-dimensional poly-disk Dd,
1d 1
K(Z, ζ) =  ∏ ~Tλ-----7v^.
πd j=1 ∏(1 - zZj)2
(68)
(69)
We scale the pixel values of samples of MNIST to [-1, 1] range so that the samples fall into the poly-
disk. We train both hypotheses using gradient descent and cross-entropy loss with `2 regularization
of the parameters of the hypotheses. The size of the MLP was 784 × 512 × 512 × 10, and the
kernel machine had 100 kernels. Both hypotheses use softmax as the final activation function. The
parameters of the MLP are real numbers, whereas the parameters of the kernel machine are complex.
In our experiments, the parameters of the Bergman kernels ζj had to be pure imaginary; otherwise,
the learning rule would fail. As of this writing, we have not been able to find the reason behind this
requirement, but we guess it has something to do with the singularities of the Bergman kernels.
After training for ten epochs, the accuracy of the neural and Bergman hypotheses on the test set
is 0.88 and 0.91, respectively. Then, we attack each hypothesis with a white-box, one-step, l∞-
normalized gradient-based attack. The results of the experiment are reported in Table 1. The result
shows that the adversarial examples of the two hypotheses transfer, and the performance of the
hypotheses are almost identical.
To better demonstrate the extent of similarity between the two hypotheses, we graphed each hy-
pothesis in the neighborhood of the adversarial path in the complex plane in Figure 7. To be more
precise, if sn and sa represent the natural and adversarial samples, let
η = sn - sa	(70)
to represent the adversarial direction for sample sn and k and l to represent the label that the hypoth-
esis assign to the natural and adversarial examples, respectively. Figure 7 visualizes the following
function for each hypothesis h,
g(z) = hk(sn + zη) - hl(sn + zη) z ∈ C.	(71)
We emphasize that the hypothesis h is not activated with softmax in g(z). Since we compare the real
parts of hk and hl to decide the label of the sample, C(g) is the decision boundary between classes
k and l. Considering that our analysis does not cover the case of multiclass classification, we will
leave the interpretation of S(g) to future works.
From the figure, we can see that the position of the submanifold of the decision boundary is similar
in both hypotheses. The only difference is that the multi-layer perceptron is a periodic function in
the complex plane due to its activation function. Nevertheless, this seems to be a technical issue, and
both hypotheses are identical with regard to the geometrical position of their decision boundaries
as far as we are concerned. This observation supports our proposal that all analytic hypotheses
converge to the holomorphic optimal Bayes classifier regardless of their implementations.
20
Under review as a conference paper at ICLR 2022
MLP
BKM
-1.0 -0.5	0.0	0.5	1.0
3l[s]
K[s]
Figure 7: Visualization of the slice of a Bergman kernel machine (BKM) and a multi-layer per-
ceptron (MLP) in the adversarial direction in the complex plane for an arbitrary test sample. The
triangle and the circle represent the position of the natural and adversarial samples respectively.
D Hardness of robust learning
We start the discussion from the perspective of the primal problem of holomorphic maximum margin
classification. The exact computation of the objective of the primal problem is NP-hard in general.
For example, consider a neural network with a single hidden layer and ReLU activation and suppose
that the samples are points in X = [0, 1]d. To compute the synchronization matrix of the neurons,
we have to compute
Σjk
((Vσj(X))T
X
(Vσk(x)) dV(x),
T
wi wj
Hj (x)Hk (x) dV (x),
(72)
X
X
in which Hj (x) is the Heaviside step function indicating the half-space where neuron j is activated.
Hence, we can see that computing Σjk is equivalent to computing the volume of a somewhat arbi-
trary polytope. It is known that this problem is P#-complete, and thus it is NP-hard (Chevallier
et al., 2020). Consequently, training a maximum margin neural classifier is a stochastic optimization
problem and is outside the scope of this paper.
Next, we will inspect the solution from the perspective of the dual of holomorphic maximum margin
classification problem. In Section 3, we showed that it would be possible to train robust classifiers
if we have the kernel corresponding to the synchronized features on a domain. We also calculated
the kernel for the unit disk D. Here, we will try to do the same for the poly-disk Dd. First, we need
a basis for A2(Dd). It is known that {zα} is an orthogonal basis for A2(Dd) in which we have used
the multi-index notation,
α =(αι, α2,…,ad) αj ∈ No,
d
zα =Yzjαj.
j=1
(73)
21
Under review as a conference paper at ICLR 2022
Similar to equation 55, the synchronized polynomial features are calculated as follows,
dα
Ya=L X1 为ι dV (z),
=πd Pj=I αj (αj + 1)
Qk=Igk + 1)
zα
工(Z) = √≡.
Thus, the kernel of the synchronized polynomial features of Dd is computed by,
K*(z,ζ) = X d Pj=1(。：+\ (zζ)a.
α π j=1 αj (αj + 1)
(74)
(75)
There is no simple expression for K * (z, Z) to the best of our knowledge, and We have to leave this
solution to future works as well.
It seems that there is no easy way to solve the holomorphic maximum margin optimization problem
in high dimensions. Nevertheless, it is still possible to simplify the hypotheses space so that robust
training becomes computationally feasible. We can achieve efficiency by limiting α, i.e., assuming
independence between dimensions and only using certain degrees of polynomials as features.
22