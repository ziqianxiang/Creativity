Under review as a conference paper at ICLR 2022
Accelerating Stochastic Simulation with
Interactive Neural Processes
Anonymous authors
Paper under double-blind review
Ab stract
Stochastic simulations such as large-scale, spatiotemporal, age-structured epidemic
models are computationally expensive at fine-grained resolution. We propose Inter-
active Neural Process (INP), a Bayesian active learning framework to proactively
learn a deep learning surrogate model and accelerate simulation. Our framework is
based on the novel integration of neural process, deep sequence model and active
learning. In particular, we develop a novel spatiotemporal neural process model to
mimic the simulator dynamics. Our model automatically infers the latent process
which describes the intrinsic uncertainty of the simulator. This also gives rise to a
new acquisition function based on the latent information gain. We design Bayesian
active learning algorithms to iteratively query the simulator, gather more data, and
continuously improve the model. We perform theoretical analysis and demonstrate
that our approach reduces sample complexity compared with random sampling in
high dimension. Empirically, we demonstrate our framework can faithfully imitate
the behavior of a complex infectious disease simulator with a small number of
examples, enabling rapid simulation and scenario exploration.
1	Introduction
Computational modeling is now more than ever at the forefront of infectious disease research due to
the COVID-19 pandemic. Stochastic simulations play a critical role in understanding and forecasting
infectious disease dynamics, creating what-if scenarios, and informing public health policy making
(Cramer et al., 2021). More broadly, stochastic simulation (Ripley, 2009; Asmussen & Glynn, 2007)
produces forecasts about complex interactions among people, environment, space, and time given a
set of parameters. They provide the numerical tools to simulate probabilistic models and stochastic
processes in finance (Lamberton & Lapeyre, 2007), chemistry (Gillespie, 2007) and many scientific
disciplines.
Unfortunately, stochastic simulations at fine-grained spatial and temporal resolution are extremely
computationally expensive. For example, epidemic models whose aim is to simulate realistic
diffusion dynamics via in-silico experiments require the exploration of a large parameter space
(e.g. characteristics of a virus, policy interventions, people’s behavior). Therefore, hundreds of
thousands of simulations are required to explore and calibrate the epidemic model with observed
epidemic surveillance data. This process significantly hinders the adaptive capability of existing
stochastic simulators, especially in “war time” emergencies, due to the lead time needed to execute
new simulations and produce actionable insights that could help guide decision makers.
Learning deep surrogate models to speed up complex simulation has been explored in climate
modeling and fluid dynamics for deterministic dynamics (Sanchez-Gonzalez et al., 2020; Wang
et al., 2020; Holl et al., 2019; Rasp et al., 2018), but not for stochastic simulations. Furthermore,
these surrogate models can only approximate specific system dynamics and fail to generalize under
different parametrization. Especially for pandemic scenario planning, we desire models that can
predict futuristic scenarios under different conditions. Furthermore, the majority of the surrogate
models are trained passively using a simulation data set. This requires a large number of simulations
to cover different parameter regimes of the simulator and ensure generalization.
We propose Interactive Neural Process (INP), a Bayesian active learning framework to speed up
the stochastic simulation. Given parameters such as disease reproduction number, incubation and
infectious periods, mobility dynamics, and initial state, current mechanistic simulators generate
1
Under review as a conference paper at ICLR 2022
future outbreak states with time-consuming numerical integration. Our framework accelerates the
simulation by learning the input-output map between parameters and future states, hence bypassing
numerical integration. We develop a novel neural process (NP) (Garnelo et al., 2018) model to mimic
the mechanistic simulator with uncertainty. We extend NP to spatiotemporal setting: we introduce
a time-evolving latent process for temporal dynamics and integrate graph convolution for spatial
modeling.
Instead of learning passively, we design active learning algorithms to interact with the simulator and
update our model in “real-time”. We derive a new acquisition function, Latent Information Gain
(LIG), based on our unique model design. Our algorithm selects the parameters with the highest
LIG, queries the simulator to generate new simulation data, and continuously updates our model.
Compared with Gaussian processes (GP), INP is more expressive, more accurate, and scales easily
to high-dimensional sequence data. We provide theoretical guarantees for the sample efficiency of
this procedure over random sampling. We also demonstrate the efficacy of our method on large-scale
spatiotemporal epidemic models. In summary, our contributions include:
•	Interactive Neural Process: a deep Bayesian active learning framework for accelerating
large-scale stochastic simulation
•	A novel spatiotemporal neural process model (STNP) for high-dimensional time series data
with temporal latent process and spatial graph convolution.
•	New acquisition function, Latent Information Gain (LIG), based on the inferred temporal
latent process to quantify uncertainty with theoretical guarantees
•	Real-world application to speed up stochastic, spatiotemporal epidemic models.
2	Related Work
Bayesian Active Learning and Experimental Design. Bayesian active learning, or experimental
design is well-studied in statistics and machine learning (Chaloner & Verdinelli, 1995; Cohn et al.,
1996). Gaussian Processes (GPs) are popular for posterior estimation e.g. Houlsby et al. (2011) and
(Zimmer et al., 2018), but often struggle in high dimension. Deep neural networks provide scalable
solutions for active learning. Deep active learning has been applied to discrete problems such as
image classification (Gal et al., 2017) and sequence labeling (Siddhant & Lipton, 2018) whereas our
task is continuous time series. Our problem can also be viewed as sequential experimental design
where we design simulation parameters to obtain the desired outcome (imitating the simulator). Foster
et al. (2021) propose deep design networks for Bayesian experiment design but they require a explicit
likelihood model and conditional independence in experiments. Kleinegesse & Gutmann (2020)
consider implicit models where the likelihood function is intractable, but computing the Jacobian
through sampling path can be expensive and their experiments are mostly limited to low (<=10)
dimensional design. In contrast, our design space is of much higher-dimension and we do not have
access to an explicit likelihood model for the simulator.
Neural Processes. Neural processes (NP) (Garnelo et al., 2018) model distributions over functions
and imbue neural networks with the ability of GPs to estimate uncertainty. NP has many extensions
such as attentive NP (Kim et al., 2019) and functional NP (Louizos et al., 2019). However, NP
implicitly assumes permutation invariance in the latent variables and can be limiting in modeling
temporal dynamics. Singh et al. (2019) proposes sequential NP by incorporating a temporal transition
model into NP. Still, sequential NP assumes the latent variables are independent conditioned on
the hidden states. We propose spatiotemporal NP with temporal latent process and spatial graph
convolution, which is well-suited for modeling the spatiotemporal dynamics of infectious disease. We
apply our model to real-world large-scale Bayesian active learning. Note that even though Garnelo
et al. (2018) has demonstrated NP for Bayesian optimization, it is only for toy 1-D functions.
Stochastic Simulation and Dynamics Modeling. Stochastic simulations are fundamental to many
scientific fields (Ripley, 2009), especially epidemic modeling. Data-driven models of infectious
diseases are increasingly used to forecast the evolution of an ongoing outbreak (Arik et al., 2020;
Cramer et al., 2021; Lourenco et al., 2020). However, very few models can mimic the internal
mechanism of a stochastic simulator and answer “what-if questions”. GPs are commonly used as
surrogate models for expensive simulators (Meeds & Welling, 2014; Gutmann et al., 2016; Qian et al.,
2020), but GPs do not scale well to high-dimensional data. Likelihood-free inference Lueckmann
2
Under review as a conference paper at ICLR 2022
Figure 1: Illustration of the interactive neural process (INP). Given simulation parameters and data,
INP trains a Neural Process model to infer the latent process. The inferred latent process allows
prediction and uncertainty quantification. The uncertainty is used to select the next set of parameters
to query the simulator, and simulate more data.
augmented
parameters
Acquisition
Function
et al. (2019); Papamakarios et al. (2019); Munk et al. (2019); Wood et al. (2020) aim to learn the
posterior of the parameters given observed data. They use neural density estimators to learn an
emulator, but require a lot of simulations. We propose a novel neural process model to learn the
likelihood. For active learning, instead of relying on Monte Carlo sampling, we directly compute
the information gain in the latent process. For epidemic modeling, Qian et al. (2020) only consider
the simple SEIR model. In contrast, we demonstrate the use of deep sequence model as a prior
distribution in Bayesian active learning for real-world, large-scale, spatiotemporal dynamics. Our
framework is also compatible with other deep sequence models for time series, e.g. Deep State Space
(Rangapuram et al., 2018), Neural ODE (Chen et al., 2018) and etc.
3	Methodology
Consider a stochastic process {X1,…，XT}, governed by time-varying parameters θt ∈ RK, and
the initial state x0 ∈ RD. In epidemic modeling, θt can represent the effective reproduction number
of the virus at a given time, the effective contact rates between individuals belonging to different age
groups, the people’s degree of short- or long-range mobility, or the effects of time varying policy
interventions (e.g. non-pharmaceutical interventions). The state xt ∈ RD includes both the daily
prevalence and daily incidence for each compartment of the epidemic model (e.g. number of people
that are infectious and number of new infected individuals at time t).
Stochastic simulation uses a mechanistic model F (θ; ξ) to simulate the process where the random
variable ξ represents the randomness in the simulator. Let θ := (x0, θ1,…，θτ) represent the initial
state and all the parameters over time. For each θ, we obtain a different set of simulation data
{(x1, ∙ ∙ ∙ , XT)m}M=1. However, realistic large-scale stochastic simulations require the exploration
of a large parameter space and are extremely computationally intensive. In the following section,
we describe a pipeline called Interactive Neural Process (INP) to proactively query the stochastic
simulator, generate simulation data, in order to learn a fast surrogate model for rapid simulation.
3.1	Interactive Neural Process
Our high-level goal is to train a deep surrogate model to mimic the stochastic simulator. As show in
Figure 1, given parameters θ, we query the simulator, i.e., the mechanistic model to obtain a set of
simulations {(x1, ∙ ∙ ∙ , XT)m}M=1. We train a neural process (NP) model to learn the probabilistic
map from parameters to future states. Our NP model is spatiotemporal and it captures the unique
disease dynamics of the epidemic simulator. During inference, the model needs to generate predictions
(X1, ∙ ∙ ∙ , XT) at the target parameters θ corresponding to different scenarios.
Instead of simulating at a wide range of parameter regimes, we take a Bayesian active learning
approach to proactively query the simulator and update the model incrementally. Using NP, we can
infer the latent temporal process (z1, ∙ ∙ ∙ , zT) that encodes the uncertainty of the current surrogate
3
Under review as a conference paper at ICLR 2022
Figure 2: Graphical model comparison: Neural Process, Sequential Neural Process and our Spa-
tiotemporal Neural Process. The key difference lies in the inference of the latent variable zt . The
distributions of zt for NP, SNP and STNP are q(zt |xt-1, xt, θt, A), q(zt|xt-1, xt, θt, z1:t-1, A), and
q(zt |xo：t, θi:t, A) respectively. A is the adjacency matrix for the spatial graph, which is omitted in
the figure for simplicity. ht is the encoder hidden state and Ht is the decoder hidden state.
model. Then we propose a new reward/acquisition function, latent information gain (LIG), to select
the θ? with the highest reward. We use θ? to query the simulator, and in turn generate new simulation
to further improve the model. Next, we describe each of the components in detail.
3.2	Spatiotemporal Neural Process
Neural process (NP) (Garnelo et al., 2018) is a type of deep generative model that represents
distributions over functions. It approximates a stochastic process by combining Gaussian process
with deep learning. NP introduces a global latent variable z to capture the stochasticity and learns the
conditional distribution p(xi：T∣θ) by optimizing the evidence lower bound (ELBO):
logp(xi:T∣θ) ≥ Eq(z|xi：T,θ) [logp(xi:T|z, θ)] - KL(q(z∣xi:T, θ)∣∣p(z))	(1)
Herep(z) is the prior distribution for the latent variable. We use xi：T as a shorthand for (xi,…，XT).
The prior distribution p(z) is conditioned on a set of context points θc, xc1:T as p(z|xc1:T, θc). The set
of context points is randomly sampled from the training data. Its complement is the target set.
However, the global latent variable z in NP can be limiting for non-stationary, spatiotemporal
dynamics in the epidemics. We propose spatiotemporal neural process (STNP) with two extensions.
First, we introduce a temporal latent process (zi,…，zt) to represent the unknown dynamics. The
latent process provides an expressive description of the internal mechanism of the stochastic simulator.
Each latent variable zt is sampled conditioning on the past history. Second, we explicitly model the
spatial dependency in xt ∈ RD. Rather than treating the dimensions in xt as independent features,
we capture their correlations with a graph. For instance, the travel graph between locations can be
represented as an adjacency matrix A ∈ RD×D .
Given parameters {θ}, simulation data {x1:T}, and the spatial graph A as inputs, STNP models the
conditional distributionp(xi：T∣θ, A) by optimizing the following ELBO objective:
logp(xi:T∣θ,A) ≥ Eq(ZLT|xi：T,θ,A) logp(xi:T|zi：T,θ,A) - KL(q(zi:T|xi：T,θ,A)kp(zi:T)) (2)
where the distributions q(z1:T|x1:T, θ, A) and p(x1:T |z1:T, θ, A) are parameterized with neu-
ral networks. The prior distribution p(z1:T) is conditioned on a set of contextual sequences
p(z1:T |xc1:T, θc, A). Figure 2 visualizes the graphical models of our STNP, the vanilla NP (Gar-
nelo et al., 2018), and Sequential NP (Singh et al., 2019).
We implement STNP following an encoder-decoder architecture. The encoder parametrizes the mean
and standard deviation of the variational posterior q(z1:T |x1:T, θ, A) and the decoder approximates
the predictive distribution p(x1:T |z1:T, θ, A). To incorporate the spatial graph information, we use
a Diffusion Convolutional Gated Recurrent Unit (DCGRU) layer (Li et al., 2017) which integrates
graph convolution in a GRU cell. We use multi-layer GRUs to obtain hidden states from the inputs.
Using re-parametrization (Kingma & Welling, 2013), we sample zt from the encoder and then decode
xt conditioned on zt in an auto-regressive fashion. To ensure fair comparisons, we adapt NP and
SNP to graph-based settings and use the same architecture as STNP to generate the hidden states
shown in Figure 6. See Appendix B.3 for architecture details.
3.3	Bayesian Active Learning
Algorithm 1 details a Bayesian active learning algorithm, based on Bayesian optimization (Shahriari
et al., 2015; Frazier, 2018). We train a NP model to interact with the simulator and improve
4
Under review as a conference paper at ICLR 2022
Algorithm 1: Interactive Neural Process
Input: Initial simulation dataset Si
1	Train the model NP(1) (S1) ;
2	for i = 1,2,…do
3	Learn (z1,z2,…，zτ) ~ q(i)(zi：T|xi：T, θ Si)；
4	Predict (X1,X2,…，Xτ)〜p(i)(xi：T|zi：T,θ, Si)；
5	Select a batch {θ(i+1)} — argmax& Ep(XLTIzLT,θ) [r(Xi：T|zi：T,θ)];
6	Simulate {xii+ 1)} J Query the simulator F(θ(i+i); ξ);
7	Augment training set Si+i J Si ∪ {θ(i+1),x1i+1)};
8	Update the model NP(i+i) (Si+i) ；
9	end
learning. Let the superscript (i) denote the i-th interaction. We start with an initial data set Si =
{θ(i), x(ii:T) } and use it to train our NP model and learn the latent process. During inference, given the
augmented parameters θ that are candidate scenarios, we use the trained NP model to predict the states
(X1,…,XT). We evaluate the models' predictions with an acquisition function r(X1：T, z1：T, θ) and
select the set of parameters {θ(i+i)} with the highest reward. We query the simulator with {θ(i+i)}
to augment the training data set Si+i and update the NP model for the next iteration.
The choice of the reward (acquisition) function r depends on the goal of the active learning task.
For example, to find the model that best fits the data, the reward function can be the log-likelihood
r = logp(X1：T∣θ, A). To collect data and reduce model uncertainty in Bayesian experimental design,
the reward function can be the mutual information. In what follows, we discuss different strategies
to design the reward/acquisition function. We also propose a novel acquisition function based on
information gain in the latent space tailored to our STNP model.
3.4	Reward/Acquisition functions
For regression tasks, standard acquisition functions for active learning include Maximum Mean
Standard Deviation (Mean STD), Maximum Entropy, Bayesian Active Learning by Disagreement
(BALD), and random sampling (Gal et al., 2017). With the distributions represented by NP, we
explore various acquisition functions and their approximations. The temporal latent process in STNP
encodes the internal mechanism of the stochastic simulator. We introduce a new acquisition function
based on our unique NP design called Latent Information Gain (LIG).
Maximum Mean STD. Mean STD (Gal & Ghahramani, 2016) is a heuristic used to estimate the
model uncertainty. For each augmented parameter θ, we sample multiple zi:T and generate a set of
predictions {X1：T}∙ For a length T sequence with dimension D, we compute the standard deviation
σt,d for time step t and feature d. Mean STD computes σ = TD PT=I PD=I P σt,d for each
parameter θ. We select the θ with the maximum σ. Empirically, we found that Mean STD often
becomes over-conservative and tends to explore less.
Maximum Entropy. Maximum entropy computes the maximum predictive entropy as H(X)=
-E[logp(X1：T)]. In general, entropy is intractable for continuous output. Our NP model implicitly
assumes the predictions follow a multivariate Gaussian, which allows us to compute the differential
entropy (Jaynes, 1957). We follow the same procedure as Mean STD to estimate the empirical
covariance Σ ∈ Rtd×tdand compute the differential entropy for each parameter as H = 11 ln ∣Σ∣ +
TD (1 + ln 2∏). We select the parameter θ with the maximum entropy.
BALD and EIG. BALD (Houlsby et al., 2011) quantifies the mutual information between the
prediction and model posterior H(X1：T∣θ) 一 H(X1：T|z1：T, θ), which is equivelant to the expected
information gain (EIG). Computing the EIG/BALD is challenging since p(X1：T|z1：T, θ) cannot be
found in closed form in general. The integrand is intractable and conventional MC methods are not
applicable (Foster et al., 2019). One way to get around this is to employ a nested MC estimator with
quadratic computational cost for sampling (Myung et al., 2013； Vincent & Rainforth, 2017). We
prove the equivalence between the expected information gain for selecting the parameter θ and the
5
Under review as a conference paper at ICLR 2022
expected KL divergence in the latent processes, as illustrated by the following proposition. In this
way, conventional MC method becomes applicable, which helps reduce the quadratic computational
cost to linear.
Proposition 1. The expected information gain (EIG) for neural process is equivalent to the KL
divergence between the likelihood and posterior in the latent process, that is
EIG(XlT,θ) := E[H(Xi：T) - H(XLT|z[T, θ)] = Ep(χEθ) [KL(p(zi:T|Xi：T, θ)kp(zi:T))]⑶
See proof in the appendix A.1. Inspired by this fact, we propose a novel acquisition function based
on the information gain in the latent process.
Latent Information Gain. The trained NP model produces a variational posterior given the current
dataset S as p(z1:T |S). For every parameters θ remained in the search space, we can predict
Xi：T with the decoder. We use Xi：T and θ as input to the encoder to re-evaluate the posterior
p(zi：T|Xi：T, θ, S). LIG computes the distributional difference with respect to the latent process
zi：T as Ep(XLT ∣θ) [KL(p(zi:T |Xi：T ,θ, S )kp(zi：T |S))] where KL(∙∣∣∙) denotes the KL-divergence
between two distributions. We select a batch of θ with the highest latent information gain.
3.5	Theoretical Analysis
We shed light onto the intuition behind choosing adaptive sample selection over random sampling via
analyzing a simplifying situation. Assume that at a certain stage we have learned a feature map Ψ
which maps the input θ of the neural network to the last layer. Then the output X can be modeled as
X = (Ψ(θ), z*i + e, where z* is the true hidden variable, e is the random noise.
Our goal is to generate an estimate z, and use it to make predictions (Ψ(θ), ^). A good estimate shall
achieve small error in terms of ∣∣Zt - z* |卜 with high probability. In the following theorem, we prove
that greedily maximizing the variance of the prediction to choose θ will lead to an error of order O(d)
less than that of random exploration in the space of θ, which is significant in high dimension.
Theorem 1. For random feature map Ψ(∙), greedily optimizing the KL divergence,
KL(P(Z|X, θ)∣p(z)) , or equivalently the variance of the posterior predictive distribution
E [(hΨ(θ),zi- E hΨ(θ),zi)2]
with high probability.
in search of θ will lead to an error ∣∣zt — z* |卜 of order O (σd∕√t)
On the other hand, random sampling of θ will lead to an error of order O (σd2∕√t) with high
probability.
See proofs in the Appendix A.2.
4	Experiments
We start with a simple susceptible-exposed-infectious-removed (SEIR) compartmental model. We
compare our method with Gaussian process for validation. We then apply our INP framework to
mimic the dynamics of a real-world large-scale Local Epidemic and Mobility model (LEAM-US)
simulator and report the performance using different acquisition functions. We implement GP using
gpytorch (Gardner et al., 2018) with Matern kernel. All NP models are implemented using pytorch
(Paszke et al., 2019).
4.1	SEIR Compartmental Model
SEIR Simulation. To show that INP indeed provides a more flexible and faster alternative to GP, we
begin with a simple stochastic, discrete, chain-binomial SEIR compartmental model as our stochastic
simulator. In this model, susceptible individuals (S) become exposed (E) through interactions with
infectious individuals (I) and are eventually removed (R), see Appendix B.1 for details.
We set the total population N = S+E+I+R as 100, 000, the initial number of exposed individuals
as E0 = 2, 000, and the initial number of infectious individuals as I0 = 2, 000. The latent period
varies between approximately 1.5 to 4 days, i.e. latent individuals move to the infectious stage at a
rate ε ∈ [0.25, 0.65] (step 0.05) that is inversely proportional to the latent period, the infectious period
6
Under review as a conference paper at ICLR 2022
10,000
8,000
I 6,000
4 4,000
-2,000
10
20	30	40
Day
50
600
500
2400
300
200
100
0.74% 1.11%	1.48% 1.85% 2.22% 2.59% 2.96% 3.33% 3.7% 4.07%
Percentage of Data
Figure 3: Neural Processes vs. Gaussian Processes for Bayesian active learning in SEIR compart-
mental model. Left: uncertainty quantification comparison with the truth. Right: MAE loss versus
the percentage of data for both NP and GP using different acquisition functions.
μ-1 is set to be equal to 1 day, and We let the basic reproduction number R0 (which in this case
coincides with the transmissibility rate β) vary between 1.1 and 4.0 (step 0.1). Here, each (β, ε) pair
corresponds to a specific scenario, which determines the 2-dimensional parameters θ . We simulate
the first 100 days of the epidemic for the infectious population (output dimension 100) with a total of
300 scenarios. We generate 30 samples for each scenario.
Model Implementation. We compare INP with GP for Bayesian active learning. In this toy
experiment, we only predict the number of individuals in the infectious compartment. The input is
(β, ε) pair and the output is the 100 days’ infection prediction. As the simulator is simple, we use the
vanilla NP model with the global latent variable z. For each epoch, we randomly select 10% of the
samples as context. Implementation details are deferred to Appendix B.5.
MeanSTD
MaxEntropy
LIG
Random
1200
0.6
0.5
0.4
0.3
0.6
0.5
0.4
0.3
■ 0.6-
「05
04
0.3
4.0
1.5	2.0	2.5	3.0	3.5
「0；
1.5	2.0	2.5	3.0	3.5	4.0
ε ,doireP tnetaL eht fo esrevnI
LJJVW UOqB-ndod SnO-IOaJU-
drawer noitcnuf noitisiuqcA

Transmission rate, β
Figure 4: NP Acquisition functions behavior visualization in 2D. For each iteration, top row represents
the current MAE mesh in infectious population for all (β, ε) candidates. Bottom row is the score
evaluated by the acquisition function. Yellow dots are existing parameters. Red stars are the newly
selected parameters.
Uncertainty Quantification. Figure 3 compares the NP and GP performance on one scenario in the
held-out test set. It shows the ground truth and the predicted number of infectious population for the
first 50 days. We also include the confidence intervals (CI) with 5 standard deviations for ground
truth and NP predictions and 1 standard deviation for GP predictions. We observe that NP fits the
simulation dynamics better than GP for mean prediction. Moreover, NP has closer CIs to the truth,
reflecting the simulator’s intrinsic uncertainty. GP shows larger CIs which represent the model’s own
uncertainty. Note that NP is much more flexible than GP and can scale easily to high-dimensional
data.
Acquisition Functions. We compare different acquisition functions in Bayesian active learning. We
select 2 scenarios as the initial training dataset. Then we continue augmenting the training set using
7
Under review as a conference paper at ICLR 2022
Figure 5: Left: INP predictions for the number of individuals in Infectious and Removed compart-
ments in LEAM-US model. Right: acquisition function comparisons on the LEAM-US simulator.
MAE loss versus the percentage of samples for INP during Bayesian active learning.
the remaining scenarios until the validation loss converges. GP is not a latent variable model, hence
LIG does not apply. We report the average test mean absolute error (MAE) over three random runs.
The candidate set for training includes 270 scenarios. We set aside 15 scenarios each for validation
and test. The scenarios are evenly distributed in the search space.
Figure 3 shows the testing MAE versus the percentage of data used for training for NP and GP with
different acquisition functions. None of the GP methods converge after selecting 4.07% of the data
for training while NP methods converge much faster. Our proposed acquisition function LIG is
more sample efficient in NP. It takes only 4.07% of the data to converge and reach the NP offline
performance, which uses the entire training set for training.
Exploration Exploitation Trade-off. To understand the large performance gap for LIG vs. baselines
on NP, we visualize the values of test MAE and the reward from acquisition functions for each
Bayesian active learning iteration, shown in Figure 4. For Mean STD and Maximum Entropy, both
tend to exploit the region with large transmission rate for the first 2 iterations. Including these
scenarios makes the training set unbalanced. The MAE in the region with small transmission rate
become worse after 2 iterations. Meanwhile, Random is doing pure exploration. The improvement of
MAE performance is not apparent after 2 iterations. Our proposed LIG is able to reach a balance by
exploiting the uncertainty in the latent process and encouraging exploration. Hence, with a small
number of iterations (I = 2), it has already selected “informative scenarios” in the search space.
4.2	Local Epidemic and Mobility model (LEAM-US)
As a real-world experiment, we use a large-scale, spatiotemporal, age-structured epidemic model,
LEAM-US, as our stochastic simulator. Our goal is to use INP to mimic the internal mechanism of
this simulator to accelerate disease modeling and scenario creation.
LEAM-US Simulator. The Local Epidemic and Mobility model (LEAM-US) is a stochastic, spatial,
age-structured epidemic model based on a metapopulation approach which divides the US in more
than 3,100 subpopulations, each one corresponding to a each US county or statistically equivalent
entity. Population size and county-specific age distributions reflect Census’ annual resident population
estimates for year 2019. We consider individuals divided into 10 age groups. Contact mixing patterns
are age-dependent and state specific and modeled considering contact matrices that describe the
interaction of individuals in different social settings (Mistry et al., 2021). LEAM-US integrates
a human mobility layer, represented as a network, using both short-range (i.e., commuting) and
long-range (i.e., flights) mobility data, see more details in Appendix B.2.
Dataset. We separate data in California monthly to predict the 28 days’ sequence from the 2nd to the
29th day of each month from March to December. Each θ includes the county-level parameters of
LEAM-US and state level incidence and prevalence compartments. The total number of dimensions
in θ is 16, 264, see details in Appendix B.2. Overall, there are 315 scenarios in the search space,
corresponding to 315 different θ with total 16, 254 samples. We split 78% of the data as the candidate
train set, and 11% for validation and test. We use 8.6% data for initial training. We first perform
offline learning to show that the STNP model can accurately learn the LEAM-US dynamics. For
Bayesian active learning, we use the candidate train set as the search space.
Model Implementation. We instantiate a STNP model to mimic an epidemic simulator that has θ
at both county and state level and xt at the state level. We use county-level parameter θ together
8
Under review as a conference paper at ICLR 2022
with a county-to-county mobility graph A in California as input. We use the DCGRU layer (Li et al.,
2017) to encode the mobility graph in a GRU. We use a linear layer to map the county-level output to
hidden features at the state level. For both the state-level encoder and decoder, we use multi-layer
GRUs. For each epoch, we randomly select 20% samples as context sequence.
STNP Predictions. Figure 5 left visualize the STNP predictions in four key compartments of a
typical scenario with R0 = 3.1 from March 2nd to March 29th. The confidence interval is plotted with
2 standard deviations. We can see that both the mean and confidence interval of STNP predictions
match the truth well. These results demonstrate the promise that the generative STNP model can
serve as a deep surrogate model for the LEAM-US simulator.
Acquisition Functions. We compare different acquisition functions with STNP. All methods start
with the same initial train set. Then we continue adding 8 scenarios to the training set until the
validation loss converges. We measure the average performance over three random runs and report
the test MAE. Figure 5 right shows the log scale MAE versus the percentage of samples included for
training, which scales linearly in computation. It shows our proposed LIG always has the best MAE
performance until the convergence. Moreover, after using 31.4% of data from the candidate train set,
LIG already outperforms the offline model.
Ablation Study on NP Models. We perform
ablation study on our proposed NP model, STNP.
Compared with vanilla NP (Garnelo et al., 2018)
and SNP (Singh et al., 2019), the key innovation
of model is temporal latent process, modeled
by state level encoder and decoder as in Fig-
ure 6. To ensure fair comparison, we modified
NP by adding the convolutional layers with dif-
fusion convolution (Li et al., 2018) to embed
the graphs. Similarly, we modified SNP by re-
placing the convolutional layers with diffusion
convolution. Figure 2 shows the corresponding
Table 1: NP model comparison in LEAM simula-
tor, population divided by 1000.
Model	I MAE
NP (Garnelo et al., 2018) 24.231 ± 5.884
SNP (Singh et al., 2019)	21.781 ± 0.825
STNP (Ours) I 6.291± 0.848
graphical models. Table 1 shows the testing MAE of different NP models trained in an offline fashion.
Our STNP significantly improves the performance and can accurately learn the simulator dynamics.
Batch Active Learning with LIG. In the case where we add more than one scenario of data per
iteration, LIG allows us to calculate the corresponding reward for a batch of scenarios due to the
mean aggregation layer in the NP encoder. In our LEAM-US experiment, we add 8 scenarios per
iteration (batch size 8). As an ablation study, we compared 4 different batch sizes, see Appendix
Figure 8. We observe that larger batch leads to better performance. This strategy combines LIG
and random search, where it first randomly selects a set of groups and then uses LIG to measure the
reward for the data within each group. Random search encourages exploration whereas LIG exploits
the highest reward.
5	Conclusion & Limitation
We present a new way to seamlessly interact with existing stochastic simulators and accelerate
simulation. Our Neural Interactive Process (INP) includes a novel spatiotemporal neural process
model to approximate the underlying simulation dynamics. It infers the latent process which
describes the intrinsic uncertainty of the simulator. We exploit this uncertainty and propose LIG as an
acquisition function in Bayesian active learning. We perform theoretical analysis and demonstrate
that our approach reduces sample complexity compared with random sampling in high dimension.
Using a complex epidemic simulator, we demonstrate our method provides a faster and more flexible
alternative to Gaussian process for policy optimization and scenario creation.
One limitation of our current work is the optimization step. Currently, we use a brute force search
mechanism to select the parameters according to the value of an acquisition function. However, this
search will become expensive in high dimension. We plan to leverage Monte Carlo sampling and
Bayesian optimization techniques to parameterize the reward function. Then we would also be able
to directly optimize for the target parameters with auto-differentiation.
9
Under review as a conference paper at ICLR 2022
Reproducibility S tatement
The implementation code is included in the supplementary material. The readme file includes the
corresponding instructions. The full proof of the Theorem 1 can be found in Appendix A.2.
10
Under review as a conference paper at ICLR 2022
References
Sercan Arik, Chun-Liang Li, Jinsung Yoon, Rajarishi Sinha, Arkady Epshteyn, Long Le, Vikas
Menon, Shashank Singh, Leyou Zhang, Martin Nikoltchev, et al. Interpretable sequence learning
for covid-19 forecasting. Advances in Neural Information Processing Systems, 33, 2020.
S0ren AsmUssen and Peter W Glynn. Stochastic simulation: algorithms and analysis, volume 57.
Springer Science & Business Media, 2007.
Duygu Balcan, Vittoria Colizza, Bruno Gongalves, Hao Hu, Jos6 J Ramasco, and Alessandro Vespig-
nani. Multiscale mobility networks and the spatial spreading of infectious diseases. Proceedings
ofthe National Academy ofSciences, 106(51):21484-21489, 2009.
Duygu Balcan, Bruno Gongalves, Hao Hu, Jos6 J Ramasco, Vittoria Colizza, and Alessandro
Vespignani. Modeling the spatial spread of infectious diseases: The global epidemic and mobility
computational model. Journal of computational science, 1(3):132-145, 2010.
Kathryn Chaloner and Isabella Verdinelli. Bayesian experimental design: A review. Statistical
Science, pp. 273-304, 1995.
Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural ordinary differential
equations. In Proceedings of the 32nd International Conference on Neural Information Processing
Systems, pp. 6572-6583, 2018.
Zizhong Chen and Jack J. Dongarra. Condition numbers of gaussian random matrices. SIAM Journal
on Matrix Analysis and Applications, 27(3):603-620, 2005.
Matteo Chinazzi, Jessica T Davis, Marco Ajelli, Corrado Gioannini, Maria Litvinova, Stefano Merler,
Ana Pastore y Piontti, Kunpeng Mu, Luca Rossi, Kaiyuan Sun, et al. The effect of travel restrictions
on the spread of the 2019 novel coronavirus (covid-19) outbreak. Science, 2020.
David A Cohn, Zoubin Ghahramani, and Michael I Jordan. Active learning with statistical models.
Journal of artificial intelligence research, 4:129-145, 1996.
Estee Y Cramer, Velma K Lopez, Jarad Niemi, Glover E George, Jeffrey C Cegan, Ian D Dettwiller,
William P England, Matthew W Farthing, Robert H Hunter, Brandon Lafferty, et al. Evaluation of
individual and ensemble probabilistic forecasts of covid-19 mortality in the us. medRxiv, 2021.
Jessica T Davis, Matteo Chinazzi, Nicola Perra, Kunpeng Mu, Ana Pastore y Piontti, Marco Ajelli,
Natalie E Dean, Corrado Gioannini, Maria Litvinova, Stefano Merler, Luca Rossi, Kaiyuan Sun,
Xinyue Xiong, M. Elizabeth Halloran, Ira M Longini, CeCiIe Viboud, and Alessandro Vespignani.
Estimating the establishment of local transmission and the cryptic phase of the covid-19 pandemic
in the usa. medRxiv, 2020.
Simon Du, Jason Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai. Gradient descent finds global
minima of deep neural networks. In Proceedings of the 36th International Conference on Machine
Learning (ICML), pp. 1675-1685, 2019.
Conor Durkan, Iain Murray, and George Papamakarios. On contrastive learning for likelihood-free
inference. In International Conference on Machine Learning, pp. 2771-2781. PMLR, 2020.
A Foster, M Jankowiak, E Bingham, P Horsfall, YW Tee, T Rainforth, and N Goodman. Variational
bayesian optimal experimental design. Conference on Neural Information Processing Systems,
2019.
Adam Foster, Desi R Ivanova, Ilyas Malik, and Tom Rainforth. Deep adaptive design: Amortizing
sequential bayesian experimental design. Proceedings of the 38th International Conference on
Machine Learning (ICML), 2021.
Peter I Frazier. A tutorial on bayesian optimization. arXiv preprint arXiv:1807.02811, 2018.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model
uncertainty in deep learning. In international conference on machine learning, pp. 1050-1059.
PMLR, 2016.
11
Under review as a conference paper at ICLR 2022
Yarin Gal, Riashat Islam, and Zoubin Ghahramani. Deep bayesian active learning with image data.
In International Conference on Machine Learning, pp. 1183-1192. PMLR, 2017.
Jacob R Gardner, Geoff Pleiss, David Bindel, Kilian Q Weinberger, and Andrew Gordon Wilson.
Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration. arXiv
preprint arXiv:1809.11165, 2018.
Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J Rezende, SM Eslami, and
Yee Whye Teh. Neural processes. arXiv preprint arXiv:1807.01622, 2018.
Daniel T Gillespie. Stochastic simulation of chemical kinetics. Annu. Rev. Phys. Chem., 58:35-55,
2007.
Michael U Gutmann, Jukka Corander, et al. Bayesian optimization for likelihood-free inference of
simulator-based statistical models. Journal of Machine Learning Research, 2016.
Friedrich Gotze and Alexander Tikhomirov. Rate of convergence in probability to the Marchenko-
Pastur law. Bernoulli, 10(3):503 - 548, 2004.
Philipp Holl, Nils Thuerey, and Vladlen Koltun. Learning to control pdes with differentiable physics.
In International Conference on Learning Representations, 2019.
Neil Houlsby, Ferenc Huszðr, Zoubin Ghahramani, and Mgte Lengyel. Bayesian active learning for
classification and preference learning. arXiv preprint arXiv:1112.5745, 2011.
IATA, International Air Transport Association, 2021. URL https://www.iata.org/. https:
//www.iata.org/.
Edwin T Jaynes. Information theory and statistical mechanics. Physical review, 106(4):620, 1957.
Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan Rosenbaum, Oriol
Vinyals, and Yee Whye Teh. Attentive neural processes. International Conference on Learning
Representation, 2019.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Steven Kleinegesse and Michael U Gutmann. Bayesian experimental design for implicit models
by mutual information neural estimation. In International Conference on Machine Learning, pp.
5316-5326. PMLR, 2020.
Damien Lamberton and Bernard Lapeyre. Introduction to stochastic calculus applied to finance.
CRC press, 2007.
Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion convolutional recurrent neural network:
Data-driven traffic forecasting. arXiv preprint arXiv:1707.01926, 2017.
Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion convolutional recurrent neural network:
Data-driven traffic forecasting. In International Conference on Learning Representations (ICLR),
2018.
Christos Louizos, Xiahan Shi, Klamer Schutte, and Max Welling. The functional neural process.
Advances in Neural Information Processing Systems, 2019.
Jose Lourenco, Robert Paton, Mahan Ghafari, Moritz Kraemer, Craig Thompson, Peter Simmonds,
Paul Klenerman, and Sunetra Gupta. Fundamental principles of epidemic spread highlight the
immediate need for large-scale serological surveys to assess the stage of the sars-cov-2 epidemic.
MedRxiv, 2020.
Jan-Matthis Lueckmann, Giacomo Bassetto, Theofanis Karaletsos, and Jakob H Macke. Likelihood-
free inference with emulator networks. In Symposium on Advances in Approximate Bayesian
Inference, pp. 32-53. PMLR, 2019.
12
Under review as a conference paper at ICLR 2022
Edward Meeds and Max Welling. Gps-abc: Gaussian process surrogate approximate bayesian
computation. In Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence,
pp. 593-602, 2014.
Song Mei and Andrea Montanari. The generalization error of random features regression: Precise
asymptotics and double descent curve. arXiv: 1908.05355, 2019.
Dina Mistry, Maria Litvinova, Ana Pastore y Piontti, Matteo Chinazzi, Laura Fumanelli, Marcelo FC
Gomes, Syed A Haque, Quan-Hui Liu, Kunpeng Mu, Xinyue Xiong, et al. Inferring high-resolution
human mixing patterns for disease modeling. Nature communications, 12(1):1-12, 2021.
Andreas Munk, Adam Scibior, AtIhm GUneS Baydin, Andrew Stewart, Goran Fernlund, AnoUsh
Poursartip, and Frank Wood. Deep probabilistic surrogate networks for universal simulator
approximation. arXiv preprint arXiv:1910.11950, 2019.
Jay I Myung, Daniel R Cavagnaro, and Mark A Pitt. A tutorial on adaptive design optimization.
Journal of mathematical psychology, 57(3-4):53-67, 2013.
OAG, Aviation Worlwide Limited, 2021. URL http://www.oag.com/. http://www.oag.
com/.
George Papamakarios, David Sterratt, and Iain Murray. Sequential neural likelihood: Fast likelihood-
free inference with autoregressive flows. In The 22nd International Conference on Artificial
Intelligence and Statistics, pp. 837-848. PMLR, 2019.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style,
high-performance deep learning library. In Advances in neural information processing systems, pp.
8026-8037, 2019.
Zhaozhi Qian, Ahmed M Alaa, and Mihaela van der Schaar. When and how to lift the lockdown?
global covid-19 scenario analysis and policy assessment using compartmental gaussian processes.
Advances in Neural Information Processing Systems, 33, 2020.
Syama Sundar Rangapuram, Matthias W Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang Wang, and
Tim Januschowski. Deep state space models for time series forecasting. Advances in neural
information processing systems, 31:7785-7794, 2018.
Stephan Rasp, Michael S Pritchard, and Pierre Gentine. Deep learning to represent subgrid processes
in climate models. Proceedings of the National Academy of Sciences, 115(39):9684-9689, 2018.
Brian D Ripley. Stochastic simulation, volume 316. John Wiley & Sons, 2009.
Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, and Peter
Battaglia. Learning to simulate complex physics with graph networks. In International Conference
on Machine Learning, pp. 8459-8468. PMLR, 2020.
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. Taking the
human out of the loop: A review of bayesian optimization. Proceedings of the IEEE, 104(1):
148-175, 2015.
Aditya Siddhant and Zachary C Lipton. Deep bayesian active learning for natural language processing:
Results of a large-scale empirical study. arXiv preprint arXiv:1808.05697, 2018.
Gautam Singh, Jaesik Yoon, Youngsung Son, and Sungjin Ahn. Sequential neural processes. Advances
in Neural Information Processing Systems, 32:10254-10264, 2019.
Michele Tizzoni, Paolo Bajardi, Chiara Poletto, Jose J Ramasco, Duygu Balcan, Bruno Gongalves,
Nicola Perra, Vittoria Colizza, and Alessandro Vespignani. Real-time numerical forecast of global
epidemic spreading: case study of 2009 a/h1n1pdm. BMC medicine, 10(1):165, 2012.
Benjamin T Vincent and Tom Rainforth. The darc toolbox: automated, flexible, and efficient delayed
and risky choice experiments using bayesian adaptive design. PsyArXiv. October, 20, 2017.
13
Under review as a conference paper at ICLR 2022
Rui Wang, Karthik Kashinath, Mustafa Mustafa, Adrian Albert, and Rose Yu. Towards physics-
informed deep learning for turbulent flow prediction. In Proceedings of the 26th ACM SIGKDD
international conference on Knowledge discovery and data mining. ACM, 2020, 2020.
Frank Wood, Andrew Warrington, Saeid Naderiparizi, Christian Weilbach, Vaden Masrani, William
Harvey, Adam Scibior, Boyan Beronov, John Grefenstette, Duncan Campbell, et al. Planning as
inference in epidemiological models. arXiv preprint arXiv:2003.13221, 2020.
Qian Zhang, Kaiyuan Sun, Matteo Chinazzi, Ana Pastore y Piontti, Natalie E Dean, Diana Patricia
Rojas, Stefano Merler, Dina Mistry, Piero Poletti, Luca Rossi, et al. Spread of Zika virus in the
Americas. Proceedings ofthe National Academy ofSciences, 114(22):E4334-E4343, 2017.
Christoph Zimmer, Mona Meister, and Duy Nguyen-Tuong. Safe active learning for time-series
modeling with gaussian processes. In Proceedings of the 32nd International Conference on Neural
Information Processing Systems, pp. 2735-2744, 2018.
14
Under review as a conference paper at ICLR 2022
A	Theoretical Analysis
A. 1 Latent Information Gain
Proposition 1. The expected information gain (EIG) for neural process is equivalent to the KL
divergence between the prior and posterior in the latent process, that is
EIG(x,θ) := E[H(X) - H(X∣z, θ)] = Ep(χ∣θ) [KL(p(z∣X, θ)∣∣p(z))]	(4)
Proof of Proposition 1. The information gained in the latent process z, by selecting the parameter θ
and generate X is the reduction in entropy from the prior to the posterior lG(θ) = H(X) - H(X|z, θ).
Take the expectation of IG(X, θ) under the marginal distribution, we obtain from the conditional
independence of z and θ that
log
p(z∣X,θ)
P(z)
Ep(X,zιθ) log pp(Zm J
Ep(x,z∣θ) [logp(z, X,θ) - logp(X, θ) - logp(z,θ) + logp(θ)]
Ep(χ,z∣θ)[logp(X∣z, θ) - logp(X∣θ)]
Ep(Z) Ep(x∣z,θ) [logp(X∣z,θ)] - Ep(χ∣θ)[logp(X∣θ)]
Ep(Z) [H(X∣θ) - H(X∣z, θ)]
EIG(X, θ).
□
A.2 Sample Efficiency of Active Learning
From the main text we know that in each round, the output random variable
X = hΨ(θ),z*i + C.	(5)
We further assume that the random noise is mean zero and σ-subGaussian.
Using this information, we treat z as an unknown parameter and define a likelihood function so that
p(X |z; θ) has good coverage over the observations:
P(XkIz; θk) H eχρ (-2σ2 (Xk- hψ(θk ), Zi)2).
Let the prior distribution over z bep(z∣θk) = p(z) h exp (-寿 IlzlI2). Here We use k instead of
(i) in the Algorithm 1 to represent the number of iterations. We can form a posterior over z in the
k-th round:
p(z∣xi, θ1, ... , Xk, θk ) h exp (-2σ2 kzk2 - 2σ2 ^X (Xs- hMθS), Zi)2).
Focusing on the random variable z 〜p(∙∣Xι, θι,..., Xk, θk), the estimate of the hidden variable,
we can express it at k-th round as:
zk = zk + σVk ηk,
(6)
where zk = V-1 Pk=ι XsΨ(θs), Vk = ml + Pk=ι Ψ(θs)Ψ(θs)t, and 仇 is a standard normal
random variable.
15
Under review as a conference paper at ICLR 2022
We can either choose action θ randomly or greedily. A random choice of θ corresponds to taking
θk ~N (0,I),	(7)
A greedy procedure is to choose action θk in the k-th round to optimize KL (p(z∣X, θ)∣∣p(z))=
Ep(z∣^,θ) (log P(PIxF), where We denote the estimated output variable X given θ and Z as X =
hΨ(θ), zi. This optimization procedure is equivalent to maximizing the variance of the prediction:
θk = arg max Ez~p(∙∣Xι,θι,…,Xk-1,θk-1) [(hψ⑻,zi - Ez~p(∙∣Xι ,θι,…,Xk-ι ,θk-ι)hΨ(θ), zi2 .
(8)
For both approaches, we assume that the features Ψ(θ) are normalized.
We compare the statistical risk of this approach with the random sampling approach.
Assume that the features are normalized, so that for all θ ∈ Rd, Ψ(θ) ∈ Sd-1. Define a matrix
Ak ∈ Rd×k containing all the column vectors {Ψ(θ1), . . . , Ψ(θk)}. We can then express the
estimation error in the following lemma.
Lemma 1. The estimation error ∣∣Zk 一 z* |卜 can be bounded asfollow.
∣∣Zk - z*k2 ≤ m (m + σmin (AkAT)) 1 ∙ ∣∣z*∣2
+ min < 1/ (2√m) , 1/ ∣{Qmg (AkAT) +——	m = ∣ > ∙ σ√d.
[	V	Jσmin (Ak AT) ；
We now analyze random sampling of θ versus greedy search for θ.
If the feature map Ψ(∙) = id, then from random matrix theory, we know that for θ randomly
sampled from a normal distribution and normalized to ∣∣θ∣ = 1, Qm® (ɪAk AT) will converge to
(p\/k 一 pi/d) for large k, which is of order Ω(1 /d). This will lead to an appealing risk bound
for k Zk 一 z* k 2 on the order of O (d/√k).
However, in high dimension, this feature map is often far from identity. In the proof of Theorem 1
below, we demonstrate that even when Ψ(∙) is simply a linear random feature map, with i.i.d. normal
entries, random exploration in θ can lead to deteriorated error bound. This setting is motivated by the
analyses in wide neural networks, where the features learned from gradient descent are close to those
generated from random initialization Du et al. (2019); Mei & Montanari (2019).
Theorem 1 (Formal statement). Assume that the noise in equation 5 is Q -subGaussian.
For a normalized linear random feature map Ψ(∙), greedily optimizing the KL divergence,
KL (p(z∣X, θ)∣p(z)) (or equivalently the variance of the posterior predictive distribution defined
in equation equation 8) in search of θ will lead to an error ∣∣Zk — z*∣b = O Qdd√fk^ with high
probability.
On the other hand, random sampling of θ following equation 7 will lead to ∣∣Zk — z*∣b =
O(Qd2/") with high probability.
Proof of Theorem 1. For a linear random feature map, we can express Ψ(θ) = Ψθ, where entries in
Ψ ∈ Rd×d are i.i.d. normal. The entries of Ψθ are then normalized.
• For random exploration of θ, the matrix containing the feature vectors becomes Ak =
ΨΘk, where matrix Θk ∈ Rd×k collects all the k column vectors of {θ1, . . . , θk}. Then
AkAkT = ΨΘkΘkTΨT. From random matrix theory, we know that the condition number of
Ψ is equal to d with high probability Chen & Dongarra (2005). Hence for normalized Ψ
and θ, Qmin (ΨΘkΘTΨT) ≥ σ2min (Ψ) Qmin (θkΘT)=今Qmin (θkΘT). The inequality
holds because the smallest singular value is the inverse of the norm of the inverse matrix.
16
Under review as a conference paper at ICLR 2022
We then use the fact from random matrix theory that for normalized random θ, the asymptotic
distribution of the eigenvalues of 1 ΘkΘf follow the (scaled) Marchenko-Pastur distribution,
which is supported on λ ∈
, where the 1/d
—
scaling comes from the fact that θ is normalized Gotze & Tikhomirov (2004). Hence for
large k, σmin (θkθg) ≥(1 - PkTd) with high probability. This combined with the
previous paragraph yields that for the random feature model,
σmin (AkAT) = Ω
with high probability. Plugging this result into Lemma 1, We obtain that the error ∣∣Zk - z* k2
for random exploration in the space of θ is of order O (d2∕√k).
• We then analyze the error associated with greedy maximization of the posterior predic-
tive variance. We first note that the variance of the posterior predictive distribution in
equation equation 8 can be expressed as follows using equation equation 6:
E [(hΨ(θ), Zi- E hΨ(θ), zi)[ = σ2E [(<Ψ(θ), Vk-IInk〉)[ = σ2Ψ(θ)TVk-2]Ψ(θ),
(9)
where the expectations are with respect to Z 〜p(∙∣Xι, θι,..., Xk-1, θk-1).
We perform a singular value decomposition Ak = UkΛkWk.	Then
Pk=ι Ψ(θs)Ψ(θS)T = AkAT = UkΛkΛTUT, and that Vk-2l = (ml + Ak-IAT-J 2 =
Uk-1 (mI + Λk-ιΛT-ι) 2 UT-1. Via this formulation, we see that maximizing
Ψ(θ)TVk--21Ψ(θ) in equation equation 9 to choose θk is equivalent to choosing
Ψ(θk) = (Uk-I)T,i), where l = argmi□i∈{i,…,d}仆一八乙兀㈤.In words, when we
use greedy method and maximize the variance of the prediction, it corresponds to taking
Ψ(θk) in the direction of the smallest eigenvector of Vk-1.
Since every Ψ(θ) is normalized and we initialize uniformly: V0 = mI, the process is
equivalent to scanning the orthogonal spaces of normalized vectors in Rd for bkTdc times.
For large k, entries in ΛkΛkT are approximately uniform and are all larger than or equal to
[k/蜀. Then σmin (Ak AT) = Ω(k∕d). Plugging into the bound of Lemma 1, we obtain
that
∣∣Zk-z*k2 = O (%.
□
ProofofLemma 1. We first express the estimate Zk as follows.
kk	k
Zk = HT XXsΨ(θs) = HT X Ψ(Θs)Ψ(Θs)tz* + HT X %Ψ(θs).
Then
k
Vk-1 X Ψ(θs)Ψ(θs)T - I
s=1
k
≤	Vk-1 X Ψ(θs)Ψ(θs)T - I
।---------------------------
l∣Zk - z*
k
Z* + Vk-1 XsΨ(θs)
s=1
k
Z*
Vk-1	sΨ(θs)	.
{z
T1
s=1
^^^^z
T2
+
2
J I
2
2
}
Define a matrix Ak ∈ Rd×k containing all the column vectors {Ψ(θ1), . . . , Ψ(θk)} and perform a
singular value decomposition Ak = UkΛkWk. Then Psk=1 Ψ(θs)Ψ(θs)T = AkAkT = UkΛkΛkTUkT,
17
Under review as a conference paper at ICLR 2022
and Vk = mI + AkAkT, We further define vector ek ∈ Rs where (ek)s = s. We use this definition
to simplify the two terms further.
For term T1 ,
KVkT X ψ(θs)ψ(θS)T - I) z*	= m Μ-1z* ∣∣2
≤ m 恒-1∣∣2 ∙kz*k2
=m (m + σmin (Ak Ak))	∙ ∣∣ z ∣∣ 2 .
For term T2, We define a diagonal matrix Ak ∈ Rk×k which satisfies (ΛGi . = 1 if i ≤ d and
(Λ k).. = 0 if i > d, when k > d. The following bound on T2 can be achieved.
k
Vk-1X	sΨ(θs )
s=1
= ∣Vk-1Akek∣2
2
=IIUk (AkAT + ml)-1 UTUkAkAkWkek∣∣2
≤ ∣∣Uk (AkAT + ml)-1 Ak∣∣2 ∙ ∣∣AkWkek∣∣2
=∣∣(AkAT + ml) 1 Ak∣∣2 ∙ ∣∣AkWkek∣∣2
≤ min < 1/ (2√m), 1/ I Jbmm (AkAT) +
m
σ σmin (AkAT)
Assuming that noise Es is σ-subGaussian, then so is Wkek since Wk is a unitary matrix. Multiplied
by the diagonal matrix A k which has zero, IlAkWkek∣∣2 ≤ σ√d. Therefore,
k
Vk-1X	sΨ(θs )
s=1
≤ min < 1/ (2√m), 1/ I JσmE (AkAT) +
yσmin (AkAT)
m
□
B Experiment Details
B.1	SEIR Simulator
Our SEIR simulator is a simple stochastic, discrete, chain-binomial compartmental model. In
this model, susceptible individuals (S) become exposed (E) through interactions with infectious
individuals (I). Exposed individuals which are infected but not yet infectious transition to infectious
compartment at a rate ε that is inversely proportional to the latent period of the disease. Lastly,
infectious individuals transition to the removed compartment at a rate μ which is inversely proportional
to the infectious period. Removed individuals (R) are assumed to be no longer infectious and they
are to be considered either recovered or dead. All transitions are simulated by randomly drawn from
a binomial distribution.
B.2	LEAM-US MODEL
LEAM-US integrates a human mobility layer, represented as a network, using both short-range
(i.e., commuting) and long-range (i.e., flights) mobility data. Commuting flows between counties
are obtained from the 2011-2015 5-Year ACS Commuting Flows survey and properly adjusted to
account for differences in population totals since the creation of the dataset. Instead, long-range air
traveling flows are quantified using origin-destination daily passenger flows between airport pairs
as reported by the Official Aviation Guide (OAG) and IATA databases (updated in 2021) (OAG,
18
Under review as a conference paper at ICLR 2022
Aviation Worlwide Limited, 2021; IATA, International Air Transport Association, 2021). In addition,
flight probabilities are age and country specific.
The model is initialized using a multi-scale modeling approach that utilizes GLEAM, the Global and
Epidemic Mobility model (Balcan et al., 2009; 2010; Tizzoni et al., 2012; Zhang et al., 2017; Chinazzi
et al., 2020; Davis et al., 2020), to simulate a set of 500 different initial conditions for LEAM-US
starting on February 16th, 2020. The disease dynamics are modeled using a classic SEIR-like model
and initial conditions are determined using the Global and Epidemic Mobility model (Balcan et al.,
2009; 2010; Tizzoni et al., 2012; Zhang et al., 2017) calibrated to realistically represent the evolution
of the COVID-19 pandemic (Chinazzi et al., 2020; Davis et al., 2020). Lastly, travel restrictions,
mobility reductions, and government interventions are explicitly modeled to mimic the real timeline
of interventions of the events that occurred during the COVID-19 pandemic.
B.3	Spatiotemporal NP Model
Mobility '。	0 ‘。。‘。。。。
Network • • *,	• ・ *,	• ・ *,	, ・ *,
Counmteel 口仇 口％ 口…忸
Mobility
Network
County Level
Parameter
Figure 6: Visualization of the STNP model architecture. For both the encoder and the decoder, we
use a diffusion convolutional GRU (DCGRU) Li et al. (2018) to capture spatiotemporal dependency.
As shown in Figure 6, our model has θ at both county and state level and xt at the state level. The total
number of dimensions of θ is 16,264 (12 compartments × 2 (incidence + prevalence) + 28 days × 58
counties × 10 metadata parameters). The output dimension is 672 (12 compartments × 2 (incidence
+ prevalence) × 28 days) We use county-level parameter θ together with a county-to-county mobility
graph A as input. We use the DCGRU layer (Li et al., 2017) to encode the graph in a GRU. We
use a linear layer to map the county-level output to hidden features at the state level. For both the
state-level encoder and decoder, we use multi-layer GRUs.
The input θi:t is the county-level parameters for LEAM-US with a dimension of 10. The county
level embedding uses 1 layer DCGRU with a width of 16. The internal state is at state level with
a dimension of 16. The state level encoder and decoder use 3 layer GRUs with width of 128. The
dimension of the latent process z1:t is 32. The dimension of output x1:t is 24, including the incidence
and prevalence for 12 compartments. We trained STNP model for 500 steps with learning rate fixed
at 10-3 using Adam optimizer. We perform early stopping with 50 patience for both offline learning
and Bayesian active learning.
B.4	Sequential Neural Likelihood (SNL) Model Implementation for SEIR
S imulator.
The input and output of SNL are the same as INP and GP. We use the likelihood-free inference code
(Durkan et al., 2020) to implement SNL model. For each iteration, we perform Monte Carlo sampling
from the trained likelihood model to report MAE. SNL takes 1 hour to complete training.
19
Under review as a conference paper at ICLR 2022
Table 2: Performance comparison of different acquisition functions in INP for SEIR simulator
Percentage of samples	I	LIG	Random	MeanSTD	MaxEntropy
1.11%	I 365.87 ± 142.87	480.68 ± 5.24	480.22 ± 12.63	427.73 ± 61.36
1.85%	I 236.9 ± 50.6	398.33 ± 131.05	314.75 ± 111.42	302.24 ± 119.84
2.96%	I 119.26 ± 14.22	244.27 ± 148.89	158.94 ± 36.6	186.88 ± 57.48
4.07%	I 96.73 ± 17.07	116.8 ± 9.1	127.36 ± 27.97	146.72 ± 26.06
Table 3: Performance comparison of different acquisition functions in GP for SEIR simulator
Percentage of samples	I Random	MeanSTD	MaxEntropy
1.11%	I 663.76 ± 46.36	606.81 ± 6.89	586.25 ± 58.44
1.85%	I 637.12 ± 13.45	619.15 ± 36.42	628.54 ± 71.34
2.96%	I 597.3 ± 19.59	589.72 ± 24.9	568.84 ± 19.05
4.07%	I 519.98 ± 17.86	530.07 ± 32.95	578.34 ± 68.7
Table 4: Performance comparison of different acquisition functions in INP for LEAM-US simulator,
popu山tion divided by 1000.__________________________________________________________
Percentage of samples ∣ Random		MeanSTD	MaxEntropy	LIG
11.1%	I 20.961 ± 5.548	35.356 ± 28.706	65.498 ± 13.324	14.447 ± 1.087
13.7%	I 13.418 ± 0.815	16.092 ± 3.11	30.496 ± 24.333	11.704 ± 0.216
21.3%	I 9.332 ± 0.601	11.191 ± 0.184	10.028 ± 2.065	7.593 ± 0.822
28.9%	I 8.077 ± 0.657	7.908 ± 0.536	8.417 ± 0.616	6.539 ± 0.618
36.5%	I 6.719 ± 0.383	7.533 ± 0.861	7.431 ± 0.776	6.008 ± 1.079
Table 5: Performance comparison between LIG in INP and SNL for SEIR simulator.				
	Percentage of samples	I	LIG	SNL	
	1.11%	I 365.87 ± 142.87	707.61 ± 44.42	
	1.85%	I 236.9 ± 50.6	669.03 ± 73.19	
	2.96%	I 119.26 ± 14.22	668.67 ± 72.42	
	4.07%	I 96.73 ± 17.07	685.28 ± 53.00	
B.5	Implementation Details
For both GP and INP mimicking SEIR simulation, we ran experiments using CPU. No GPU
accelerator is needed for this simple model. It takes 1.5 hours to complete training. For INP
mimicking LEAM-US simulation, we ran experiments with GEFORCE RTX 2080. It takes 5 hours
to complete training. For all experiments, we run with three different random seeds.
B.6	Broader Impact
The proposed approach has applications in the field of computational epidemiology as it provides a
way to efficiently explore the parameter space of complex epidemiological model (such as LEAM-US)
allowing to reduce the time-to-insights needed to provide actionable insights to policy makers. As
an example, a single realization of the LEAM-US model requires about 1 hour to be completed (on
a single thread of a AMD Ryzen Threadripper 3970x CPU, 3.7Ghz base clock) while in this work
we show that using INP framework can achieve a performance comparable to the one of epidemic
simulator while requiring less than one-third of the runs (as shown in Figure 5). In other words,
this means that we can produce COVID-19 forecasts and projections three times faster than we
would without the integration with the proposed framework. In addition, INP provides a general
surrogate model that is not tailored to solve only for a specific target outcome (e.g. prediction of future
deaths) but rather it retains the ability to describe the underlying state of the system as the original
20
Under review as a conference paper at ICLR 2022
mechanistic epidemic model. This feature preserves the ability of using the learned surrogate model
as a situational awareness and outbreak analytics tool as it can also provide insights on unobservables
(such as the fraction of immune population in a certain location/age group) which can be used by
public health officials to assess the (potential) impact of past/future policies on the evolution of an
epidemic.
C Additional Results
C.1 INP VERSUS GP AND SNL
Table 2 shows the average results together with the standard deviation of INP for SEIR simulator
after running experiments three times. Table 3 shows the average results together with the standard
deviation of GP for SEIR simulator. Figure 7 shows the average test MAE over three random runs
versus the percentage of training data for SNL, NP and GP with different acquisition functions. Table
5 shows the comparison of average MAE together with the standard deviation for the SEIR simulator.
We observe that LIG is always better than SNL until convergence. Table 4 shows the average MAE
together with the standard deviation of INP for the LEAM-US simulator.
Figure 7: MAE loss versus the percentage of data for SNL, NP and GP using different acquisition
functions.
C.2 Batch Active Learning with LIG.
Figure 8 compares 4 different setups: 8 batches (size 1), 4 batches (size 2), 2 batches (size 4), and 1
batch (size 8).
Figure 8: Batch size comparisons for LIG on the LEAM-US simulator. MAE loss versus the
percentage of samples for INP during Bayesian active learning.
21