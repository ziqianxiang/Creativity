{
    "Decision": {
        "decision": "Accept (Spotlight)",
        "comment": "The reviewers are unanimous in their opinion that this paper offers a novel approach to learning naÃ¯ve physics.  I concur.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper studies counterfactual event prediction in physical simulation. The authors proposed a model that leverages object-centric scene representations and graph networks for modeling object interactions. The model also uses a recurrent network to encode and extract the confounder information for counterfactual prediction. In the experiments, the authors compared the proposed method, baselines, and human performance on pose estimation and counterfactual prediction.\n\nI reviewed an earlier version of the paper at another venue. Compared with that, the current manuscript has improved a lot. It's studying an important problem. The model builds upon SOTA techniques such as GCN. Experiments are conducted on multiple physical events with multiple confounders. There are also rich ablation studies. The writing is clear and easy to follow. My recommendation is weak accept.\n\nI think the paper can be improved by adding experiments on real data. The model involves 'de-rendering' which seems not easily generalizable to complex real scenes. Also, while the block tower scenario has been well studied, the discussion on ball and collision scenarios is quite limited. I encourage the authors to include more results on those datasets. The authors should also conduct human studies there, too.\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Summary of what the paper claims and contributes\n---\nThis paper presents a new object forecasting task in the setting of \"intuitive physics\" that requires counterfactual reasoning and also presents method to perform this task. The task is to predict the alternative future trajectory of objects in 3D simulation given a video (A_frame,B_frames) of how the objects move in one situation and an alternative single frame (C_frame) that corresponds to modifying object position(s) at the first timestep of the input video. Due to unobserved confounding factors such as mass and friction that are not directly observable in either the video or the intervened frame, successful forecasting requires either implicitly or explicitly estimating these confounders. The motivation for this task is the hypothesis that counterfactual reasoning is a necessary component to forecast in general, unobserved situations. Prior work on explicit causal reasoning mainly concerns lower-dimensional problems, and prior work on high-dimensional \"intuitive physics\" has not evaluated the capability of models to perform counterfactual reasoning.\n\nThe paper proposes a neural network that learns to implicitly predict sufficient statistics of confounders of the situation. Training occurs in two stages. First, it is trained to estimate 3d positions of objects from images given pairs of (image, ground truth 3d positions). Then, it is trained to forecast future unobserved object positions with a graph convolutional network. Inference is performed by estimating the current object positions in all of the frames of the input (A_frame, B_frames), and then using the final representation of the input situation as the representation of confounders that is fed into the alternative-future prediction.\n\nThe experiments find:\n1) Humans are not very good at these specific tasks, as evidenced by a simple position-copying baseline that outperforms humans. Given that the simple copying baseline is so performant, the claim in the abstract of \"super human performance\"  is also true for the copying baseline, and therefore that claim isn't very meaningful and should be removed.\n2) The proposed approach outperforms position-copying and two non-counterfactual approaches that do not reason (explicitly or implicitly) about confounders,.\n3) The approach attempts to show that confounder representations are learned as the main evidence that the model can perform counterfactual reasoning. However, several aspects of this experiment are unclear, making the claim difficult to evaluate.\n\nFinally, although the abstract and the main text say that the task is to perform counterfactual forecasting in high-dimensional scenarios in a unsupervised way, the paper ends up using direct supervision of the object positions. With this knowledge, the problem is not that different than counterfactual forecasting in low-dimensional settings, as the positions of the objects at all frames corresponding to \\mathbf{A}, \\mathbf{B}, and \\mathbf{C} could simply be extracted with this detector. Thus, through this supervision the approach seems to circumvent most of the challenges imposed by high-dimensional forecasting.\n\nEvaluation\n---\n\n>Originality:\nAre the tasks or methods new?\nThe task of counterfactual forecasting from high-dimensional observations is new. The proposed method extends prior work to the new task.\n\nIs the work a novel combination of well-known techniques?\nYes.\n\nIs it clear how this work differs from previous contributions?\nYes.\n\nIs related work adequately cited?\nTo my knowledge, yes.\n\n>Quality:\nIs the submission technically sound?\nYes.\n\nAre claims well supported by theoretical analysis or experimental results?\nSome of the claims are supported, but the evidence for the counterfactual representation recovery claim is currently unclear. Additionally, the high-level motivation of counterfactual forecasting in high-dimensional settings is significantly undermined by the use of low-level supervision information that could feasibly be predicted at test time.\n\nIs this a complete piece of work or work in progress?\nIt seems relatively complete.\n\nAre the authors careful and honest about evaluating both the strengths and weaknesses of their work?\nWeaknesses are not explicitly explored. It would be good to include discussion that illuminates or hypothesizes when and why the method fails, and how it could be made to perform better.\n\n>Clarity:\nIs the submission clearly written?\nThe submission is mostly clear, however there are some significant ambiguities in the experiments.\n\nIs it well organized?\nYes.\n\nDoes it adequately inform the reader?\nMostly -- see ambiguities.\n\n>Significance:\nAre the results important?\nIt's currently unclear whether the results are significant, but it's clear the task is important (only when not supervised by object positions). However, justification with respect to other recent intuitive physics simulators is needed.\n\nAre others (researchers or practitioners) likely to use the ideas or build on them?\nOther researchers are likely to build on the task and data released.\n\nDoes the submission address a difficult task in a better way than previous work?\nN/A (new task)\n\nDoes it advance the state of the art in a demonstrable way?\nThere is no SOTA on this new task.\n\nDoes it provide unique data, unique conclusions about existing data, or a unique theoretical or experimental approach?\nYes, one of the main strengths of the paper is the task and dataset that will be released. This experimental approach could be very useful for future research.\n\nAdditional feedback\n---\nThe experiments to validate the cofounder estimation is unclear. Ambiguities:\n0) In the text, the classification of mass and friction is presented as follows: \"The obtained results are shown in Table 6 (middle)\", yet the results are in Table 5. The impact of confounder supervision is described as follows \"we do, however, explore what effect supervision could have on performance, as shown in Table 5\", yet the results are in Table 6. These typos, when combined with the layout of Tables 5 and 6, makes it very difficult to interpret these results.\n1) What is feedforward method? I can't find any description. Is this the IN or the NPE baseline, or something different? Why aren't both used? Without more details, its unclear that the proposed method actually learns confounder representations better than other methods.\n2) What is the \"random baseline level\"? Is this just chance results from a uniform distribution as a baseline classifier?\n3) What are the details of the classifier that predicts the mass and friction coefficients?\n\nIt is a bit odd to include comparisons to humans on a task on which the humans are outperformed by a very simple baseline. Either downplay the role of these comparisons, or remove these comparisons, or change the task such that humans cannot be outperformed by a simple baseline.\n\nMore details about the NPE and IN baselines are missing. Specifically, do they also leverage access to the ground-truth positions at training time? If so, how do they do this? This discussion is important for the paper to be self-contained. \n\nPage 9 \"The CophyNet model also consistently outperforms the augmented variants...\" the outperformance isn't present in all cases (i.e. not in 4->2 or 4->3); change to \"usually\".\n\nIt's not clear if there is any stochasticity in the dynamics of the created data (which would be relevant to modeling and evaluation).\n\nIt wasn't clear until page 7 that the training leveraged GT positions in 3d space. The training objective (equation after Eq (5)) has an undefined o^*, which the reader must infer corresponds to GT, or read appendix A.1, to understand. The description of the method was introduced in terms of A, B, C, and D which are images or videos. To me, the fact that GT 3D positions are used seems like it was \"buried\" later in the paper, rather than described up-front alongside the introduction of A, B, C, and D.\n\nThe meaning of the colors, if any, in Fig 2 is unclear. If they are meant to illustrate observed information, perhaps grayscale shading could be used instead, as is standard in PGMs.\n\nThe latent representation in Fig 4 appear to emerge just from the red object's RNN, rather than all of the objects RNNs.\n\nTables 1 and 2 appear very far from their description in the text.\n\nMore discussion is needed that relates the tasks in to the tasks in Riochet2018 and Bakhtin2019. It's not clear why a new benchmark is needed without this discussion. Specifically, could the proposed method and evaluation be applied to these benchmark simulators? If not, why not? The answers to these questions seem to be the main motivation for the proposed tasks.\n\nThe simplest baseline would be to simply stack (A,B,C) as contextual input to a learned regressor of the future positions in D. Another simple baseline is to use the learned position estimator to predict all of the positions in (A,B,C) and use these positions as input to a learned regressor.\n\nUse two backtick characters instead of the double-quote character for starting forward quotations.\n\nRecommendation\n---\nTaken together, the novelty of the task and dataset, the discrepancy between problem motivation (high-dimensional counterfactual reasoning vs. uses low-dimensional ground-truth), and the partial clarity of the experimental results, leads me to conclude that although the proposed task and data are quite interesting and promising, the paper needs significant work to clarify its motivation and justification of its claims. I would rate the paper borderline, however it appears I'm forced to discretize to WA or WR. I choose WA because I am optimistic that the authors could address my doubts.\n"
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "N/A",
            "title": "Official Blind Review #3",
            "review": "Update: after revision, I have decided to keep the score unchanged.\n\nOriginal comments:\n\nIn this paper, the authors proposed a new method to learn physical dynamics based on counterfactual reasoning. \n\n1. As also summarized by the paper, over recent years, there has been increasing interest in the research community for the study of visual reasoning, intuitive physics and perceptual causality. This work provides an interesting framework that combines all the three domains together to solve the problem of learning physical dynamics. The experimental result also shows promise. \n\n2. This paper also provides a nice work that bridges the gap between the counterfactual reasoning and deep learning community.\n\nWith all of this said, I think overall the paper is an interesting addition to the causal inference and deep learning literature.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        }
    ]
}