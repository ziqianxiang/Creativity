{
    "Decision": {
        "decision": "Accept (Spotlight)",
        "comment": "All the reviewers found the paper to contain an interesting idea with insightful experiments. The rebuttal further improved confidence of the reviewers. The paper is accepted.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This work inspects the bias existing in the neural network classifiers through two techniques from computational neuroscience, the classification image techniques and spike-triggered covariance (STA) analysis. The classification image is generated as the difference map between all the averaged images with predicted classes under noise perturbation. STA is used to generate the eigenvector as the input and response, as a visualization. Both of the tools are the standard psychophysics tools. \n\nThe authors use the two tools to visualize the bias learned by various classifiers, CNN, MLP, and logistic regression, trained on three datasets MNIST, Fashion-MNIST and CIFAR 10. There are interesting patterns that emerged from the classifiers trained on MNIST and Fashion-MNIST by the classification image technique, but the result from the CIFAR 10 is not explainable. The classification image is further used to analyze the adversarial attack and defense while STA is used to visualize the internal units. \n\nStrengths:\nThe paper is well-written and easy to follow. With detailed and complete psychophysics experiments, several interesting properties of the filters and the biases of the neural network classifiers are revealed. It is great to see that more tools from psychophysics can be applied to understand neural network classifiers.\n\nWeakness:\n1. One concern I have is that the result on CIFAR-10 is not interpretable. See figure 3. On the other hand, the visualization of filters in higher layers (conv4 and conv6) from the net trained on CIFAR-10 in Figure 8 still looks like edge detectors. There are not so many discussions and explanations on what possibly happened here. \n\n2. The inferior result on CIFAR-10 might indicate that the techniques cannot be generalized to interpret large-scale networks such as AlexNet or resnet, trained on ImageNet or Places. It is 2019 now, I expect to see more experiments on at least AlexNet or VGG, rather than tiny sets MNIST or CIFAR. I will suggest the authors run experiments on AlexNet trained on ImageNet/Places, then we can compare the visualization with the other filter visualization to see the difference.\n\n3. There is no comparison for other bias visualization methods. Following the idea of mean images, I think you can also show the mean images conditional on the predicted labels (average all the testing images with certain predicted labels). How the result from the psychophysics is different from that? How well the proposed methods are able to identify the bias? What other bias cannot be identified? Some discussions on the failure cases would be appreciated\n"
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "Summary:\nThis paper introduces two tools from spike analysis to understand the bias neural networks have. The first tool is classification images and the second, spike-triggered analysis.\n\nThe broad goal of the paper is to add more tooling to add interpretability and robustness to a neural network.\n\nClassification images can be summarized as: Produce a stimulus from the sum of a signal image and a noise image. Then average the response over many trials to determine what template the network used.\n\nSpike-triggered analysis can be understood as measuring a neuron's response to time-varying stimuli (ie: neuron responding to a line) which scopes out the receptive field.\n\nThe paper is well written. Experimentation section is thorough. The related work is well discussed.\nThe overall techniques are interesting and can help the community think about interpretability by using tools from related disciplines.\n\nDecision:\nAccept\n\nReasoning:\nInterpretability is a very important problem and the authors present ways of thinking about it from the lens of computational neuroscience. This paper has the potential to inspire future research in this direction.\n\n\n\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This is an interesting paper that uses two techniques from neuroscience (eletrophysiology) to interpret CNNs. The \"classification images\" technique allows the authors to build an input specific bias map for CNNs, from different images that are randomly generated using different methods. STA is also used to visualize filters. The authors find interesting similarities between CNNs and animal/human brain such as the shift of the psychometric curve. The paper is well written and the experiments are thorough.\n\nThis paper has comprehensive use of neuroscience method, nicely bringing the two fields together. Even though the authors mention other approaches, perhaps one weakness is the limited discussion of other visualization tools: what is the difference between other more frequent approaches such as activation maximization and the approach the authors present. What could we understand with these tools that cannot be understood through activation maximization (i.e. using backprop to find optimal stimuli)? One problem with classification images is that the pattern is limited to low level patterns unless the random images have structure in them. The authors solve this problem using more complex random sample (e.g. with Gabor features). But a more in depth discussion is necessarily about the additional understanding that is procured from such an approach in comparison to activation maximization. It's an important discussion because even neuroscientists are now interested (and finally able) to properly perform activation maximization to test their hypotheses more strongly (see Bashivan et al 2019 science for a great example). \n\nEven though I think the lack of this discussion is currently a limitation, I think this paper is a good opportunity to have this discussion and bring together the specifics of these two different approaches.\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper uses classification images and spike triggered averages to\nreveal hidden structure in deep neural networks.  As the authors\nclearly state, the techniques used are not novel (they have been used\nin neuroscience) but the results are interesting.\n\nOne interesting aspect is that the classification image technique is\nquite good (better than the average gradient of the classification\nloss with respect to the image) at revealing trojan (adversarial\npatch) networks - networks trained with trojan patches that change the\nclassified class of the image - (and the area of the trojan attack).\nHow long does it take (and with what hardware) to create the\nclassification images for the trojan networks?\n\nThe authors also show how the method can be used for black-box adversarial\nattacks without need for gradients or logits and model microstimulation\nexperiments.\n\nI don't feel there is quite enough insights here for ICLR publication.\n"
        }
    ]
}