{
    "Decision": {
        "decision": "Accept (Talk)",
        "comment": "This paper proposes a novel stochastic gradient Markov chain Monte Carlo method incorporating a cyclical step size schedule (cyclical SG-MCMC).  The authors argue that this step size schedule allows the sampler to cross modes (when the step size is large) and locally explore modes (when the step size is smaller).  SG-MCMC is a very promising method for Bayesian deep learning as it is both scalable and easily to incorporate into existing models.  However, the stochastic setting often leads to the sampler getting stuck in a local mode due to a requirement of a small step size (which itself is often due to leaving out the Metropolis-Hastings accept / reject step).   The cyclic learning rate intuitively helps the sampler escape local modes.  This property is demonstrated on synthetic problems in comparison to existing SG-MCMC baselines.  The authors demonstrate improved negative log likelihood on larger scale deep learning benchmarks, which is appreciated as the related literature often restricts experiments to small scale problems.  The reviewers all found the paper compelling and argued for acceptance and thus the recommendation is to accept.  Some questions remain for future work.  E.g. all experiments were performed using a very low temperature, which implies that the methods are not sampling from the true Bayesian posterior.  Why is such a low temperature needed for reasonable performance?  In any case a very nice paper.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This article presents cyclical stochastic gradient MCMC for Bayesian deep learning for inference in posterior distributions of network weights of Bayesian NNs. The posteriors of Bayesian NN weights are highly multi-modal and present difficulty for standard stochastic gradient MCMC methods. The proposed cyclical version periodically warm start the SG-MCMC process such that it can explore the multimodal space more efficiently.\n\nThe proposed method as well as the empirical results intuitively make sense. The standard SG-MCMC basically has one longer stepsize schedule and is exploring the weight space more patiently, but only converges to one local mode. The cyclical SG-MCMC uses multiple shorter stepsize schedules, so each one is similar to a (stochastic) greedy search. Consequently, the cSG-MCMC can collect more diverse samples across the weight space, while the samples of SG-MCMC are more concentrated, but likely with better quality (as shown in Figure 3). \n\nPersonally I would like to see how Bayesian deep learning can be applied to real large-scale applications. Probabilistic inference is expensive; Bayesian model averaging is even more expensive. That's probably why recent literature focuses on variational inference or expectation propagation-based approaches. "
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "8: Accept",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "title": "Official Blind Review #3",
            "review": "The paper propose a new MCMC scheme which is demonstrated to perform well for estimating Bayesian neural networks. The key idea is to not keep lowering the step sizes, but -- at pre-specified times -- go back to large step sizes.\n\nThe paper is timely, the proposed algorithm is novel, and the theoretical analysis also seem quite novel.\n\nMy key concern is that with MCMC sampling it is often quite difficult to tune parameters, and by introducing more parameters to tune when step sizes should increase, I fear that we end up in a \"tuning nightmare\". How sensitive is the algorithm to choice of parameters?\n\nI would expect that the proposed algorithm is quite similar to just running several MCMCs in parallel. The authors does a comparison to this and show that their approach is significantly faster due to \"warm restarts\". Here I wonder how sensitive this conclusion is to choice of parameters (see nightmare above) ? I would guess that opposite conclusions could be reached by tuning the algorithms differently -- is that a reasonable suspicion ?\n\nIt is argued that the cyclic nature of the algorithms gives a form of \"warm start\" that is beneficial for MCMC. My intuition dictate that this is only true of the modes of the posterior are reasonable close to each other; otherwise I do not see how this warm starting is helpful. I would appreciate learning more about why this intuition is apparently incorrect.\n\nMinor comments:\n* on page 4 it is stated that the proposed algorithm \"automatically\" provide the warm restarts -- but is it really automatic? Isn't this a priori determined by choice of parameters for the algorithm?\n\n* It would be good to use \\citet instead of \\cite at places, e.g. \"discussed in (Smith & Topin, 2017)\" should be \"discussed by Smith & Topin (2017)\". This would improve readability (which is generally very good).\n\n* For the empirical studies I think it would be good to report state-of-the-art results as well. I expect that the Bayesian nets still are subpar to non-Bayesian methods, and I think the paper should report this.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper develops a cyclical stepsize schedule for choosing stepsize for Langevin dynamics. \nThe authors prove the non-asymptotic convergence theory of the proposed algorithm. Many experimental results, including ImageNet, are given to demonstrate the effectiveness of the proposed method. \n\nHere I suggest that authors also need to point out that the continuous-time MCMC is the Wasserstein gradient flow of KL divergence. The bound derived in this paper focus on the step size choice of gradient flows. This could be a good direction for combining gradient flows studies in optimal transport and MCMC convergence bound for the choice of step size. \n\nOverall, I think that the paper is well written with clear derivations. I strongly suggest the publication of this paper. "
        }
    ]
}