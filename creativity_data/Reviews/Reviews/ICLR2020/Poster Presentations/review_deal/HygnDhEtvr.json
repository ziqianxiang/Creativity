{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "The reviewers found this paper on improving NLG using a graph-to-sequence architecture interesting and the results impressive. While I would personally have preferred to see further evaluation of this model on another NLG task, I think it would be overstepping in my role as AC to go against the reviewer consensus. The paper is clearly acceptable.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #1",
            "review": "The paper proposes two modules to improve the performance of the Natural Question Generation task: (1) deep alignment network and (2) passage graph embeddings. The idea of generating passage graph is novel. The authors experiment with SQuAD and the numbers look good.\n\nI have a few questions regarding the model and experiments.\nFirst, a reasonable baseline could be using Transformer-based sequence to sequence model. Could you fine tune the embedding of CLS token and use that as a summary of the document? It seems that the construction of the passage graph is basically sparsifying a multi-head attention in the BERT model. I think you should justify why graph-structure is important in your experiment.\n\nSecond, if the Graph2Seq is particularly important for Natural Question Generation, the author should clarify it more. If the Graph2Seq model is generally applicable to replace the Seq2Seq model, the author should experiment with more tasks. The paper seems not well motivated.\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #2",
            "review": "This paper focuses on improving the performance on the task of natural language generation. To this end, they propose a  graph-to-sequence (Graph2Seq) model for the task of question generation which exploits the rich structure information in the text as well as use reinforcement learning based policy gradient approach to address the exposure bias and inconsistency between test/train distributions in cross-entropy optimization setup. \n\nThe Graph2Seq model has a bidirectional gated graph neural network on the encoder side, which is an extension of traditional gated graph neural network. To exploit the rich hidden structure information in the input text, they explore two different methods: (1) syntax-based static graph; (2) semantics-aware dynamics graph. \n\nThe proposed model achieves state-of-the-art results on question generation, which are further validated with human evaluations. \n\nOverall, The paper should be rejected because the paper have minor extensions to each of their modules but lacking any major important contribution. \nSome major concerns: \n1) The bidirectional gated GNN doesn’t seem novel enough in comparison to previous work\n2) I believe RL to Graph2Seq is a minor extension from Seq2Seq, since RL mostly deals with the decoder part which is common in across both Graph2Seq and Seq2Seq\n\n\nArguments:\n\n1) Adding the structure information to the encoder via the GNNs is an interesting angle for question generation. Compared to previous work, this paper proposes an additional deep alignment network on the encoder side to align paragraph and answer. However, the importance of this module is not well studied in the experiments section. I see that there is an ablation with/without this module but its not fairly compared with other aligning or simple techniques like in Zhao et al. (2018). \n\n2) The addition of RL component to Graph2Seq is a minor extension from the Seq2Seq model, because both of these models have similar decoder and RL mainly deals with it. Also the importance of each reward component or the effect of each phrase-matching automatic metrics is missing. \n\n3) Open part I am unclear about the dataset is which dataset version did you use sentence-level or paragraph level? I see that the baselines correspond to sentence-level, but the Figure-1 alignment module has input paragraph. Also I couldn’t find the SeqCopyNet (Zhou et al., 2018) split-2 BLEU4 score=13.02 in the original paper! \n\n4) Some of the latest papers which use BERT based models are not discussed in the paper which achieve state-of-the-art-results: “Addressing Semantic Drift in Question Generation for Semi-Supervised Question Answering”\n\n5) For Table-2 results are the differences in the scores for the two models statistically significant?\n\n6) Table-3: First of all, evaluating only one metric is no sufficient. Please see latest papers that have also introduced new metrics that are good for QG evaluation, e.g., Q-BLEU. The gap between G2Ssta+BERT vs. G2Ssta+BERT+RL seems negligible, and missing statistical significance. \n\n7) Minor comments: BLUE -> BLEU; please cite KNN-style graph sparsification; the color choices in Figure-3 are creating confusion in understanding the model. \n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        },
        {
            "rating": "8: Accept",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "The authors propose a Graph-to-Sequence Reinforcement Learning Model for Natural Question Generation, evaluated on SQuAD benchmark in for Question Generation. An interesting aspect of the work is related to the Graph2Seq model, and the use of the Reinforcement Learning to fine-tune the model. The latter stage seems to improve the structure of the answers considerably. An interesting use of RL algorithm and apparently a good choice of reward functions.\n\nQuestions: in the combined loss used in the RL run:\n1. Have you managed to have a successful run with gamma = 1?\n2. I understand that the L_rl factor is computed based on the sampling, and the L_lm is computed based on the top variant from the nbest list?\n\n"
        }
    ]
}