{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "This paper studies the role of topology in designing adversarial defenses. Specifically , the authors study defense strategies that rely on the assumption that data lies on a low-dimensional manifold, and show theoretical and empirical evidence that such defenses need to build a topological understanding of the data.\n\nReviewers were initially positive, but had some concerns pertaining to clarity and limited experimental setup. After a productive rebuttal phase, now reviewers are mostly in favor of acceptance, thanks to the improved readibility and clarity. Despite the small-scale experimental validation, ultimately both reviewers and AC conclude this paper is worthy of publication.  ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper tries to answer the following question:\nIn adversarial defense training do manifold based defenses need to know the structure of the underlying data manifold?\nThe question is quite rhetoric (the answer is most probably yes), nevertheless, the paper provides a theoretical and empirical answer.\n\nThe paper reads well and it is interesting to read. Nevertheless, I have a very basic question regarding the usefulness of the methods that the paper studies and the topic of adversarial defenses. I have worked on the topic for some years and in the beginning, I found it quite interesting, until I realized that, at least for images, audio, 3d meshes, all adversarial attacks can be very easily addressed with simple denoising mechanisms (for images even a non-local means filter or even a Gaussian filter eliminated all the adversarial attacks I have tried). There are some recent papers that demonstrate this [A] or recently feature denoising [B]. Why denoising is not enough to pull the data back to the data manifold (e.g., general low-rank data denoising or general denoising suitable for the data under investigation)?  \n\nI really want a discussion about that before I make a final decision.\n\n[A] Defensive denoising methods against adversarial attack\n[B] Feature Denoising for Improving Adversarial Robustness"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #2",
            "review": "This paper argues that defenses against adversarial attacks need to be stronger than they currently are. Defenses that use generative models assume that there exists a manifold of data that is modeled by a trained generative model that can be used to project any out-of-manifold data unto the manifold. However, this work argues that if the generative model does not model the topology of the manifold, it can still be fooled by an adversarial example. They argue that a generative model needs to be at least aware of the number of connected components of the data-generating manifold. If the number of connected components does not match, based on theorem 2, Corollary 1 argues that a generative model can generate an adversarial example that does not exist in the data-generating manifold.\n\nPros:\n- To the extent I checked, proofs are correct.\n- The experimental results support this result on 2D toy manifolds. They show how a prior defense based on generative-models (INC) fails on the toy problems and show how a modification to INC can improve it.\n\nCons:\n- In their experiments, they use the number of classes as an approximation to the number of connected components (Appendix E) and train class-conditional generative models. Some of these details are better to be put in the main text.\n- There are no experiments beyond toy examples on high-dimensional problems and datasets. It should not be too difficult to have some preliminary results using the proposed extension of INC on MNIST or CIFAR10.\n\nAfter rebuttal:\nI have raised my score after authors improved to quality of the text. Even though this work does not have empirical results on high-dimensional datasets such as MNIST or CIFAR10, it has a nice theoretical contribution useful for finding stronger defenses against adversarial examples.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #1",
            "review": "I. Summary of the Paper\n\nThis paper studies robustness to adversarial examples from the\nperspective of having 'topology-aware' generative models. Next\nto some experiments on data sets with a manifold structure, the\nmain contribution of the paper is a tandem of theorems that state\nthe conditions under which models can recover the topology---or\nthe number of connected components---of a data set correctly,\nthereby making them more robust to adversarial examples.\n\nII. Summary of the Review\n\nThis paper provides a novel perspective on adversarial examples through\nthe lens of Riemannian Geometry and topology. I appreciate novel\nresearch that employs topology-based methods, but at present, I cannot\nfully endorse accepting the paper. Specifically, I see the following\nissues:\n\n- Missing clarity: while the appendix is very comprehensive, which\n  I appreciate, the main text could be improved; some statements appear\n  redundant, while others need to be re-formulated to build intuition\n\n- This paper appears to span both theory and applications. I appreciate\n  this attempt, knowing full well that this is no easy feat to\n  accomplish. However, the main theoretical result on the number of\n  connected components only applies to mixtures of Gaussian\n  distributions, but the purported scope of the paper is the analysis of\n  manifold-based defences in general. I would expect a more in-depth\n  discussion of the limitations of the theorem. Can we expect this to\n  generalise? Moreover, 'topology' is reduced to 'connected components'\n  in this paper. While this is perfectly adequate in the sense of\n  connected components being a particular concept from topology, I would\n  expect this to be clarified much earlier in the paper. In addition,\n  connected components are a very basic and coarse concept, so I am\n  wondering to what extent it is sufficient to describe models purely\n  based on that information.\n\n- As a sort of corollary to the previous point, the experiments could be\n  improved. I like the idea of employing known data sets with a simple\n  manifold structure, but the setup is somewhat preliminary; I would\n  prefer to see an analysis of border cases or limit cases in which the\n  theorem _almost_ applies (or not); plus, a more in-depth analysis of\n  stochastic effects during training: do _all_ models end up being\n  robust if their number of connected components is sufficiently large?\n  Is there a dependency between the number of connected components and\n  vulnerabilities---are models with a very small number of connected\n  components more vulnerable than models with a very larger number of\n  connected components? The present experimental section is lacking this\n  depth.\n\n- The same statements apply to the INC example. I found this super\n  instructive, but it is only _one_ case on _one_ manifold---I would\n  like to see more details here; maybe some of the experiments in the\n  appendix could be moved to the front? I have some suggestions for\n  shortening the paper (see below).\n\nDespite these issues, I think this paper can be a strong contribution if\nproperly revised; since I am positive that at least some of these\nsuggestions could be performed within a revision cycle, I want to be\nupfront and state that I will definitely consider raising my score,\nprovided that my concerns are addressed appropriately!\n\nI have to state that I am _not_ an expert in adversarial examples, but\nan expert in topology-based methods; I consider this paper to belong to\nthe latter field given its theoretical contributions about 'recovering'\nthe correct density distribution.\n\nIII. Clarity\n\nThe paper provides an extensive background to Riemannian geometry, which\nI appreciated as a reference. Nevertheless, there are improvements to\nthe main text that I would suggest:\n\n- Please consider changing the title to 'On the need...'\n\n- The manifold assumption is that data lie _on_ a manifold or _close to_\n  a manifold whose intrinsic dimension is much lower than that of the\n  ambient space. This is not stated in sufficient precision in the\n  paper; please correct the usage on p. 1 and p. 2\n\n- In terms of notation, why use $p_M$ to denote the density on the whole\n  of $\\mathds{R}^n$? I would expect $p_M$ to refer to the density on $M$\n  rather than the density of the whole space.\n\n- If $M$ is a disjoint union of manifolds, please consider using\n  a '\\cupdot' operator to make this more clear.\n\n- If the pairwise manifolds are disjoint, how can the resulting data\n  distribution still contain any ambiguities? I find this hard to\n  harmonise with the statement in Section 3.4 about the existence of\n  a classifier that separates the manifolds. Please clarify the meaning\n  behind the term 'ambiguities' here.\n\n- The '(R0)' requirement definition and the discussion in Section 3.2\n  strike me as needlessly complex. Would it be possible to shorten this\n  or move some content to the appendix? I think it would be sufficient\n  to have Eq. 1 and mention how it could be solved.\n\n- Section 3.3 could be shortened as well, if I am not mistaken; while it\n  is good to know how such models look, the 'change of variable formula'\n  is not used directly any more in the paper; I think it might be easier\n  to write down a generic form of the density for each model.\n\n- The salient points of Section 3.4 seem to be the projection point;\n  maybe this could also be shortened somewhat in the interest of having\n  more space for experiments. The relevant information of this section\n  was to learn how projections work for different models, but it would\n  be sufficient to keep Eq. 3 and discuss Eq. 4 in the appendix\n\n- The 'topological differences' mentioned in Section 4 could be\n  clarified: the paper talks about differences in connected components.\n\n- The $\\lambda$-density set appears to be a superlevel set, if I am not\n  mistaken: the level set would be defined for a single threshold only,\n  while this paper introduces the pre-image of an interval.\n\n- I would expect the pre-image to be defined as $p^{-1}$, not $p_{-1}$;\n  the latter strikes me as somewhat non-standard usage\n\n- The statements preceding Definition 1 require some more intuition;\n  what is the purpose of these assumptions?\n\n- The notation for the Euclidean balls should be briefly introduced\n  before Definition 1. I recognise this as a standard notation, but\n  since this is the first appearance of the symbol, it should be\n  mentioned at least briefly.\n\n- Definition 1 could also be phrased more intuitively; additional\n  sentence behind each definition would be useful, such as:\n  $\\delta_\\lambda$ is the largest $\\delta$ such that the full\n  superlevel set is contained in a ball of radius $\\delta_\\lambda$.\n\n  Figure 1 is already helpful in that regard; it should ideally precede\n  the definition and/or be made larger to be more illustrative\n\n- Maybe the results of Theorem 2 could already be stated earlier; it\n  could probably be explained reasonably well when describing the number\n  of connected components as a sort of 'baseline' topological complexity\n  that a model has to satisfy.\n\n  On a more abstract level, could it also be summarised as 'the\n  inclusion of prior knowledge is a necessary condition for robustness'?\n\n- I would not state that the main goals of the experiments are to\n  'check the correctness of Theorem 2'---the proofs should be\n  responsible for this! I would rather say that the main goals are to\n  provide empirical evidence for the *relevance* or *applicability* of\n  the Theorem.\n\n- The paragraph on 'Latent vector distributions' contains the most\n  relevant information, viz. the knowledge of what the paper considers\n  to be a 'topology-aware' and 'topology-ignorant' model; this should be\n  highlighted more; maybe the figures could be extended to contain\n  information about $n_X$?\n\nOverall, I like the idea of having one overarching question in a paper\nthat is subsequently answered or discussed under different aspects. I\nvery much commend the authors of the paper for choosing this sort of\nwriting style!\n\nIV. Experimental setup\n\nAs mentioned above, the experiments require more depth. I would propose\nadding more repetitions of the training process for different data sets\nand analysing the impact of the 'parameters' used in the theorems.\n\nIn particular, the 'INC' experiments show great promise for multiple\nrepetitions. Why not choose more data sets and more staring positions\nand visualise the trajectories of _multiple_ draws, as shown for\na single draw in Figure 4 a,b,c?\n\nAlso, please consider moving the additional experiments from the\nappendix to the main paper.\n\nMore compelling examples would also be helpful. Why not generate data\nsets consisting of more than two manifolds? At present, the largest\nissue I see in this section is that the conceptual 'leap of faith'\nbetween the theory and the applications is simply too large. Would it\nnot be possible to perform the same experiments on a simple digits data\nset, say MNIST?\n\nV. Minor issues\n\nThe paper is well-written overall. There are only a few typos and minor\nstyle issues that I would recommend fixing:\n\n- please check the usage of quotes; it should be ``pulled back'', not ''pulled back'' in LaTeX\n\n- please check the usage of citations; if '\\citet' is used, citations\n  can be used as nouns directly (for example: 'in Pennec (1999)' instead\n  of 'in (Pennec, 1999)'.\n\n- etc.. --> etc.\n- it approximates posterior distribution --> it approximates a posterior distribution\n- for compound distribution --> for a compound distribution\n- a relatively simpler distribution --> a simpler distribution\n- near manifold --> near a/the manifold\n- we simply the minimum --> we denote (?) the minimum\n- satisfies the followings --> satisfies the following properties\n- number of connected component --> number of connected components\n- Experimental result --> Experimental results\n\nVI. Update after the rebuttal\n\nThe authors managed to address the majority of my comments. Overall, I still would like to see a more detailed/in-depth experimental setup, but I realise that this not directly possible within the timeframe allotted during the rebuttal period. I am thus raising my score.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        }
    ]
}