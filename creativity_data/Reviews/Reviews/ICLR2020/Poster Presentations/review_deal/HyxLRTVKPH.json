{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "This paper formalizes the problem of training deep networks in the presence of a budget, expressed here as a maximum total number of optimization iterations, and evaluates various budget-aware learning schedules, finding simple linear decay to work well. \n\nPost-discussion, the reviewers all felt that this was a good paper. There were some concerns about the lack of theoretical justification for linear decay, but these were overruled by the practical use of these papers to the community. Therefore I am recommending it be accepted.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #2",
            "review": "Pros:\nThe paper is clearly written. It provides an interesting perspective for training neural networks under resource constraints. The problem setting is novel. The proposed solution is simply decaying learning rate linearly from the initial value to zero during training, which is parameter free. \n\nCons:\n\n- As the authors are advocating using linear scaling schedule, I would like to see whether it has some clear advantages over other schedules, but it is not quite clear. For example, we can still see step based schedule has better performance in 2 of the 4 tasks in Table 2. Poly and Cosine schedule is also better in some of the budgets in Figure 2. \n\n- The comparison in Figure 2 and Table 2 is not very convincing without considering the variance of different trails. It is not clear whether the advantage is caused by learning rate schedule or randomness. It is better to report the mean and variance for multiple trials. Ideally, it would be better to performance significance test.\n\n- I would like to see other lr schedules in Table 2. As shown in Figure 2, step based schedule is not the top3 schedules for CIFAR-10.\n\n- As shown in Table 3, the proposed method has to wait until the end of training to get the best performing model, while step based schedule can find the best model around 90% training. The author argues that the proposed method does not need to perform validation test for each checkpoint and reduce the computation cost,  however, on the other side, this means early stopping is not able to use for linear scaling based schedule, which could be very useful when the training budget is large enough and evaluation is cheap.\n\n- My major concern for this work is a lack of deeper understanding about the reason why linear LR schedule works better, if any. It would be stronger with such understandings. The authors try to provide an explanation from the relationship between learning rate and gradient magnitudes, but no clear conclusion is given. As noted in [1,2,3], when weight decay is used in training and BN layers are used, the weight magnitude is also decreasing, so is the gradient norms. But the weight norms or gradient norms does not mean too much due to scale invariance. I would like to see when no weight decay is used and whether there is any correlation between the learning rate and gradient norms. \n\n- What is the lr decay unit for linear schedule? Is it decaying per epoch or per mini-batch? If epoch based lr decay is used, it is essentially step-based lr decay with many steps. Then when the number of epochs is three, the step decay method (lr decays at epoch 1 and 2) and the linear decay method are actually almost equivalent. \n\n- I would expect the convergence to be related with number of iterations. When the number of iterations is not long enough, neither linear lr decay or step based decay will work. It would be better if the author can investigate when linear schedule starts to outperforms step based decay in terms of epochs or iterations. Since different batch size results in different number of iterations, I would expect the difference between two schedules for small batch size at the early stage of training would be less in comparison with large batch training, especially when the number of iterations is enough.\n\n- Different initial learning rate may also results in different behaviour. We often see some learning curves with larger initial learning rate converges faster at the beginning but yields similar generalization error at the end of training. On the other hand, the author only compared different schedules with single initial learning rate. Image when the initial learning rate is small, there would not be too much difference for different schedules. Actually the linear decay schedule changes may simply find a good learning rate during training as long as the initial learning rate is larger than the optimal one.\n\n\n[1] Dinh et al, Sharp minima can generalize for deep nets, ICML 2017\n[2] Li et al, Visualizing the Loss Landscape of Neural Nets, NIPS 2018\n[3] van Laarhoven, L2 regularization versus batch and weight normalization, NIPS 2017\n\n\n----- update after rebuttal ------\nThe authors' rebuttal addressed some of my concerns.  I think early stopping is still an important feature to save compute, especially for HPO, which could limit the usage of the proposed method (cannot stop earlier). If the authors believe practitioners are used to train model in full budget without early stopping to guarantee the best performance, then why would people try budged training with worse performance? I hope the authors could make the limitation clear. My major concern about the reason for why linear scaling schedule is better is still not clear, which makes the contribution kind of weak. Nevertheless,  the problem setting and the observations could be beneficial to the community for further discussion, So I raised my score to weak accept.\n\nminor: I see exactly the same variance values for step and linear methods int the top rows of Table 12, is this a mistake?\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper analyzed which learning rate schedule (LRS) should be used when the budget (number of iteration) is limited. First, the authors have introduced the concept of BAS (Budget-Aware Schedule). Various LRSs are classified, and it is experimentally shown that the LRSs based on BAS performed better. Among them, the performance of the linear decay method was shown to be simple and robust.\n\nPros\n\n1. Formally define important and well-motivated issues to improve performance on a limited budget.\n2. Various experimental results show that the simple linear decay method works well, and it might become a baseline method for future budgeted training solutions (assuming there is no similar work with the same purpose).\n3. It seems to be easy to apply to the NAS,  and the experiments in Appendix A look a big plus. This section can be put into the main paper.\n\nCons\n\n1. No sound theory as to why linear decay or other smooth decay methods work well.\n2. As Mishkin et al. [1] have already experimented with linear decay, the novelty of the methodology proposed by the authors might be limited.\n\nWhile there is some concern regarding the significance of novelty,  the paper seems meaningful enough to be accepted.\n\n[1] Dmytro Mishkin, Nikolay Sergievskiy, and Jiri Matas. Systematic evaluation of convolution neural network advances on the imagenet. Computer Vision and Image Understanding, 161: 11–19, 2017."
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This work presents a simple technique for tuning the learning rate for Neural Network training when under a \"budget\" -- the budget here is specified as a fixed number of epochs that is expected to be a small fraction of the total number of epochs required to achieve maximum accuracy. The main contribution of this paper is in showing that a simpler linear decay schedule that goes to zero at the end of the proposed budget achieves good performance. The paper proposes a framework called budget-aware schedule which represents any learning rate schedule where the ratio of learning rate at time `'t' base learning rate is only a function of the ratio of 't' to total budget 'T'. In this family of schedules, the paper shows that a simple linear decay works best for all budgets. In the appendix, the authors compare their proposed schedule with adaptive techniques and show that under a given budget, it outperforms latets adaptive techniques like adabound, amsgrad, etc.\n\nPros:\n1. This paper presents a simple technique for a problem that is impactful namely performing training under a small budget presumably as an approximation during neural architecture search or hyperparameter tuning. The technique is empirically shown to be effective for many computer vision benchmarks.\n2. The paper presents extensive experimental results comparing linear decay with other budget-aware schedules. The accuracy comparisons are performed under different budgets as well as for neural architecture ranking while selecting architecture with budgeted training.\n3. Overall, I think this paper can be generally useful for many practitioners.\n\nCons:\n1. The paper makes claims around the phenomena of gradient magnitude vanishing as well as its effectiveness. E.g. in section 5, authors state \"We call this “vanishing gradient” phenomenon budgeted convergence. This correlation suggests that decaying schedules to near-zero rates (and using BAC) may be more effective than early stopping.\". This is not clear from the paper as the paper merely shows gradient magnitude decreasing with learning rate. This claim appear like an overreach to me.\n2. The key motivating use cases for budget-aware training is providing approximations for problems like neural architecture search and hyper parameter tuning. However, for these use cases, the paper does not perform extensive comparisons for commonly used algorithms like Adam. Why?\n\nnits:\n1. In section 2, various -> varies\n2. Right above equation 1, budge -> budget\n"
        }
    ]
}