{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "The paper proposes a black box algorithm for MRF training, utilizing a novel approach based on variational approximations of both the positive and negative phase terms of the log likelihood gradient (as R2 puts it, \"a fairly creative combination of existing approaches\"). \n\nSeveral technical and rhetorical points were raised by the reviewers, most of which seem to have been satisfactorily addressed, but all reviewers agreed that this was a good direction. The main weakness of the work is that the empirical work is very small scale, mainly due to the bottleneck imposed by an inner loop optimization of the variational distribution q(v, h). I believe it's important to note that most truly large scale results in the literature revolve around purely feedforward models that don't require expensive to compute approximations; that said, MNIST experiments would have been nice. \n\nNevertheless, this work seems like a promising step on a difficult problem, and it seems that the ideas herein are worth disseminating, hopefully stimulating future work on rendering this procedure less expensive and more scalable.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper presents a black-box style learning algorithm for Markov Random Fields (MRF). The approach doubles down on the variational approach with variational approximations for both the positive phase and negative phase of the log likelihood objective function. For the negative phase, the authors use two separate variational approximations, one of which involves the modeling of the latent variable prior under the approximating distribution,\n\nThe approach is novel, as far as I know, though not particularly so, and I view this as one of the weak point of the paper. That said, it does seems like a fairly creative combination of existing approaches. As others have found in the past, a variational approximation to the partition function contribution to the loss function (i.e. the negative phase) results in the loss of the variational lower bound on log likelihood and the connection between the resulting approximation and the log likelihood becomes unclear. To deal with this issue, the authors argue (in Lemma 1) that the gradient of their approximate objective is at least in the same direction as the ELBO (lower bound) objective. The result is fairly obvious, but the conditions for validity have interesting consequences for the training algorithm, as it relates the approximation error to the norm of the gradient of the ELBO loss.\n\nI have a minor issue with the discussion (in the last paragraph of sec. 3.2) stating that the theoretical statement of the proposed objective relies on a much weaker assumption than the nonparametric assumption made in the theoretical justification of GANs. While I agree with the statement as such, the GAN development makes a stronger statement about the nature of the learning trajectory. Specifically, it states that the generator is minimizing a Jenson-Shannon divergence which has a fixed point at the true data density. In the current development, Theorem 1 only states that the optimization process will converge to the stationary points of the approximate ELBO objective (L1 in the paper's notation).\n\nClarity: I found the paper to be very well written with a clear exposition of the material and sound development of the technical details. \n\nRelevance and Significance: This paper is highly relevant to the ICLR community and -- to the extent that one believes that training and inference in MRFs is important -- also significant. One this last point, it seems ironic to me that the proposed strategy for training the MRF is through the use of three separate directed graphical models (an encoder q(h | x),  a decoder and a VAE to model the approximate prior over the latents h). In most modeling situations, one would simply impose the directed graphical model directly and skip the formalization in terms of an MRF. I would appreciate a more forceful motivation of the relevance of MRFs rather than just stating it as a important model with applications. What is unique\nabout the MRF formalism that -- for practical applications -- could not be effectively captured in a directed graphical model?\nI note that I am aware of the theoretical representation differences between directed and undirected models, I am wondering how these differences actually matter in practical applications at scale.\n\nExperiments: The authors show the empirical advantages offered by the proposed method over the existing literature. I was surprised not to see how this model performs on the binarized MNIST dataset, and would like to see that result as well as CIFAR likelihood.  MNIST, in particular, is a well studied dataset that many readers will be able to easily interpret. Its absence seems like a serious omission.\n\nWhat is meant by \"RBM loss\" in Fig. 2(d), I do not see this defined? \n\nI am somewhat alarmed at the use of 100 updates of the joint model q(v,h) (K1 = 100) for every update of the other parameters. For larger scale domains, I fear this could become an important obstacle to effective model training. The comparison to PCD-1 in Fig. 3 seems a bit unfair in that the learning curve ends at 8000 iterations, while PCD-1 continues to\nimprove NLL. I would like to see this curve extended until we start to see signs of overfitting. Perhaps PCD-1 results in performance that is far better than AdVIL. I would also like to see a comparison to CD-k, which often outperforms PCD-k. While I understand the stance taken by the authors that these methods leverage the tractability of the conditional\ndistributions, these strategies are sufficiently general to be considered widely applicable and a true competitor for AdVIL. \n\nWith respect to Deep Boltzmann Machine (DBM), I would prefer to see quantitative comparisons against published results. Here again, MNIST would be a useful dataset.  It seems as though, in the application of AdVIL to the DBM, the authors are exploiting the structure of the model in how they define their sampling procedure. Is that the case? More detail for this application of AdVIL would be nice. Also, I would like to see the test estimated NLL (via AIS) learning curves for VCD and AdVIL. Given the comparison to PCD in the RBM setting, I am somewhat surprised that AdVIL is so competitive with VCD in\nthe case of the DBM.\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The work proposes using variational distributions to model the model the inference of latent variables and model the partition function building on NVIL, thereby providing an algorithm that would work on general MRFs for both inference and learning. Since the two terms in the NLL are opposite in sign, it is a minimax operation and GAN like adversial training can be used. The paper shows providing tighter results to estimate the log partition function and comparisons on the digits dataset and Anneal importance sampling.\n\nThe paper builds on NVIL by using two variational distributions for the NLL and how to solve the parameter estimation problem. I think this strategy can be tested more extensively on more types of general MRFs and more rigourous experimentation and that the community will benefit from reading from these ideas. The paper contains some theory behind the work and experimental analysis of Advil including the sensitivity to parameters. Advil shows promise compared to the competing methods in some of the problems.\n\nQuestions and suggestions for improving the paper\n1. Is this applicable to multivalued nodes or just binary problems? Or are any modifications needed?\n2. Inference can be done in general using approximate methods like variational message passing, QBPO among others that don't depend on graph structures either, how does this work compared when those algorithms are used with simple gradient descent while training the parameters?\n3. The paper states that the algorithm is convergent if the variational encoder approximates the model well. How would you define good approximation?\n4. It would be good to add more details of how the GAN framework/adversial training is used.\n5. Would it be possible to compare Advil to ALI in some of the experiments?\n6. Fig. 2 d was not clear to me as why to expect the plot we see. The NLL flattens out with no progress.\n7. It would be helpful to the reader to understand the comparison using persistent contrastive divergence. Why is it not used in other experiments. The paper says the main comparison point is NVIL but different experiments either mention ALI, VCD or PCD which is confusing.\n8. It would be nice to see the time comparison between this learning parameters and other methods.\n\n\n\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This manuscript proposes a new approach to fitting Markov Random Fields (MRFs).  The general structure of the algorithm is amenable to many MRF structures and can be fairly straightforwardly applied to learning on a wide variety of problems.  The theoretical analysis supports that the algorithm is reasonable.  Experimental results show strong results on several different MRF models, albeit on relatively small problems.\n\nI am giving this manuscript a weak accept.  The approach, to me, seems novel in fitting MRFs.  However, the theoretical claims and their limitations need to be more realistically discussed, and the empirical results need to be shown on larger and more complex datasets.\n\nFirst, on the empirical results, there is a large literature on fitting RBM models, including many on scaling to much larger models.  Given that AdVIL actually diverges on the logZ estimation as the number of iterations goes up makes me worry about the efficacy of this approach on larger RBMs (Figure 2 uses v=64 and h=15 while a common RBM on MNIST is v=784 and h=500, a huge difference in scale).  As a large literature shows that estimating partition functions or normalizing constants gets much harder as the dimensionality goes up, I worry about this strategy and I think the manuscript would be greatly enhanced by looking at more common model sizes from the ML literature.\n\nAlso, to me, the classic MCMC+SGD is as much a black box as the proposed technique.  I realize that many of the top performing MCMC adapt specifically to the problem, but much of this is transferable between systems and can be put in simple sampling schemes.  Table 1 should be updated to include these typical techniques, because it is not clear that the proposed system actually outperforms the typical PCD-1 scheme (especially given in Figure 3).  Or succinctly, it should be made clear why I should use this over an MCMC approach.\n\nTo address these concerns, I would like the authors to answer how their proposed algorithm works in larger MRFs and do a more complete analysis compared to more traditional strategies.\n\nSecond, the theoretical claims are nice, but the manuscript should be revised to address the limitations of the theory.  In particular, Lemma 1 is extremely strong, and I disagree with the assessment that it is \"much weaker\" than the typical nonparametric assumption.  It seems that as the optimization gets close to the solution, this is essentially the exact same condition.  The authors need to clarify how exactly this is different, and dive into the practical implementations.  This also seems like it would get increasingly difficult as the number of hidden and visible units increases, so they should address how this Lemma holds as the theory scales.\n\n"
        }
    ]
}