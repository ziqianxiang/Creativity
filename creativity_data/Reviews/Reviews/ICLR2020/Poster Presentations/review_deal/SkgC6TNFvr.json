{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "Authors propose a novel scheme to perform active learning on image segmentation. This structured task is highly time consuming for humans to perform and challenging to model theoretically as to potentially apply existing active learning methods. Reviewers have remaining concerns over computation and that the empirical evaluation is not overwhelming (e.g., more comparisons). Nevertheless, the paper appears to bring new ideas to the table for this important problem.    ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "This work presents a method to use active learning to control the labeling process to gather training data in the context of a semantic segmentation application. In particular, authors define actions, states and rewards, and slightly modify DQN, to learn a policy to select informative image regions to obtain pixel labels. The proposed strategy contains several novelties related to the model and the application domain. Furthermore, the paper is clear and well written. \n\nOne weak part of the proposed method is the predefined split of each image into 24 regions that are used to define the population of sampling candidates. I believe that, for the case of semantic segmentation, the arbitrary definition of the boundary of each region might degrade performance. This because for this application the real object boundary is highly informative. Actually, this could be a major reason to explain that the proposed method only presents a modest boost in performance with respect to baselines, which is clear only for the under-represented categories. \n\nA point that it is not clear to me is the initial training of the segmentation network. Also, it is not clear how is the process to train the segmentation network after the inclusion of each new batch of labeled data (do the segmentation network is trained incrementally with just the new data?). Finally, I believe it will be good to include information about the computational complexity of resulting model.\n\nIn summary, the idea of using AL and RL to control the labeling process in a semantic segmentation application is interesting and particularly relevant for this application. While the proposed method has some weaknesses, it is novel and it will be of interest to people interested in semantic segmentation. I rate the paper as weak accept."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #2",
            "review": "# Summary #\nThe paper works on active learning for semantic segmentation, aiming to annotate as few \"blocks/patches\" as possible while training a strong model. The authors proposed to learn a query policy via Q learning, and design states and actions specifically for segmentation. The experimental results show that the learned policy can attend to informative patches and rare classes to learn a model faster and efficiently.\n\n# Strength #\nS1. The paper is well-motivated; the references are quite sufficient.\nS2. The paper clearly states the challenges when applying RL algorithms like Q-learning to image segmentation, which should serve as good guidance for other future work.\n\n#Weakness/comments#\nW1. The writing of the technical part can be strengthened.  The authors deferred the state and action design entirely to the supplementary, while they are the main contributions to the paper.\n\nW2. The proposed algorithms seem to be highly time-consuming. The actions require pairwise comparison, and at every step, the models need to evaluate all the validation images to get the reward.\n\nW3. If I understand correctly, the authors use part of the training data D_T, D_S (of an existing dataset) together with the validation data D_R to learn the policy, and then use the learned policy to select patches from the remaining training data D_V to train the segmentation model. I have two questions.\n1) The labeled data involved in policy training is indeed quite large (validation plus part of the training, D_S + D_T + D_R). Does it mean that to learn a good active learning policy we indeed need a large number of labeled data?\n2) Since (D_S, D_T, and D_R) are used to learn the policy, they should be treated as available training data for segmentation that all the compared algorithms can use without spending the budget. In other words, all the compared algorithms (U, H, B) should use those data to fine-tune a pre-train segmentation network before they start to acquire data from D_V. It would be great if the authors can clarify this.\n\nW4. In applying the policy for selecting patches from D_V, do the authors update the model once on the selected patches, or do the authors train with them for multiple iterations together with other previous selected patches? Since deep neural nets are known to forget what has been learned (i.e., catastrophic forgetting), it's better if the author could clarify this.\n\nW5. The authors include an upper bound in Fig. 4; however, I didn't find the explanation. Why the proposed methods can outperform the upper bound with all the training data, even with only 24% of data?\n\n#Rebuttal#\n\nPlease discuss W1-W5.\n\n- Annotating an entire image is definitely easier to annotators than annotating patches. Could the authors discuss how to design an active learning algorithm by selecting informative images to annotate, and maybe compare to such a method?\n\n- Can the authors discuss Figure 3 more? As H is based on maximum entropy, why is it outperformed by the proposed method? \n\n- There is no explicit mechanism to prevent that the k actions select similar patches. Can the authors provide more discussion?\n\n# Post rebuttal\nThe authors responded to most of my concerns. I'd like the authors to incorporate all their responses into the manuscript or the appendix so that future readers can better understand the concepts and details.  I would like to raise the score to borderline (4 or 5). I modified my scores to weak accept (6) since there is no option in between.\n\nOne concern I still have is W3. 2). Given only 360 images are available, it might be inappropriate to use D_T + D_S (roughly 160 images?) to pre-train baseline models and then use D_R with \"200\" images for validation (early stopping). It will be more appropriate to use, for example, 70% of 360 images for training. This is supported by that many modern datasets use a much larger training set than the validation set. Therefore, I would highly suggest the authors redoing the baseline methods; otherwise, future work that re-splits the data (this is totally valid!) from the 360 images might easily achieve higher accuracy.\n\nThe authors must also reorganize the paper, taking W1 into account. ",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        }
    ]
}