{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "The paper proposes a new variational-inference-based continual learning algorithm with strong performance.\n\nThere was some disagreement in the reviews, with perhaps the one shared concern being the complexity of the proposed method. One reviewer brought up other potentially related work, but this was convincingly rebutted by the authors. Finally, one reviewer had an issue with the simplicity with the networks in the experiments, but the authors rightly pointed out that the architectures were simply designed to match those from the baselines.\n\nContinual learning has been an active area for quite some time and convincingly achieving SOTA in a new way is a strong contribution, and will be of interest to the community. Progress in a field is sometimes made by iteratively simplifying an initially complex solution, and this work lays in a brick in that direction. For these reasons, I recommend acceptance.\n\n\n\n",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The authors propose a new continual learning method. The model is based on the probabilistic model and variational inference. To show the effectiveness of the proposed model, the authors do experiments on several benchmarks.\n\nThe model lacks enough technical novelty. The motivation of this paper is a task-specific weight adaptation mechanism, which seems a simple version of [1]. In addition, the design of b^T as s/(1+e^{-a^T})-1 is not well-motivated. It is better to explain more.\n\nIn addition, if the authors compare the performance on both negative transfer (forgetting) and forward transfer (performance on the new task). I suggest the authors compare with [2], which also focuses on the performance of new tasks.\n\nMinor:\n1. The font of figures and its legends are small.\n\n[1] Li, Xilai, et al. \"Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting.\" ICML’19.\n\n[2] C Finn et al. “Online Meta-learning” ICML’19\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "This paper introduces CLAW, a complex but effective approach to continual learning with strong performance in the sequential task learning setting, as demonstrated on a number of standard benchmarks.\n\nI recommend acceptance because:\n- While conceptually similar to VCL, CLAW is convincingly shown to have superior performance across standard benchmarks and measures. The evaluation is thorough across the board, as far as I can tell.\n- Forward transfer is shown to be substantially better compared to other methods. Experiments with long sequences of tasks (Omniglot, CIFAR-100) are particularly telling.\n- Overall, the balance between not forgetting and still learning new tasks seems particularly favourable for the proposed method. This has been an elusive goal of continual learning research, hence the importance of accepting this work.\n\n\nHere are some good reasons why an adversarial reviewer would reject this paper:\n- The sequential task setting for continual learning has very little to add in practice, and to other branches of machine learning: it has little to say for domains where continual learning problems occur naturally, such as reinforcement learning, GAN training, multi-agent learning; all of these domains need continual learning solutions; while progress on standard benchmarks is important, we may be overfitting to these benchmarks.\n- The paper is well written but the method is rather complex and presumably non-trivial to tune. This is actually characteristic of several top competing methods on these benchmarks; getting the last bit of performance seems to require this complexity, but it also makes it that much harder to generalize such methods beyond these benchmarks. For example, exploiting well partitioned datasets into different tasks and known task labels is a good starting point, but once such information is not available all bets are off. Acceptance means encouraging work on these benchmarks; is this really what we should do?\n- It's perfectly tractable to store some small amount of old data for these problems in an 'episodic memory', so one could claim that an entire class of relevant baselines is missing, e.g. A-GEM, iCaRL, etc.\n\n\nLuckily, I am not an adversarial reviewer, but I want to see progress across a more diverse and widely relevant set of continual learning challenges."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposed a novel probabilistic continual learning approach which automatically learn an optimal adaptation for arriving tasks while maintaining the performance of the past tasks. CLAW learns element-wise weight masking per task task with respect to the several learnable parameters. \nCLAW fundamentally based on Variational Continual Learning, but it outperforms benchmarks on diverse dataset even without additional coreset. However, the ablation study and analysis on the model is weak and authors only show experimental observations. Also, the experiments are performed on old architectures. Then, it needs to show the model consistently outperform on recent deep network architectures, such as ResNet.\n\n\nI have several questions,\n\n- How about the training time / convergence rate of the CLAW compared to other methods? \n\n- If the model need to divide the sample into two halves, isn't the model vulnerable when there are only a few number of samples with high variance? This situation is quite natural on realistic problem, like Imagenet.\n\n- Why are the VCL variants with CNN not compared?\n\n- There might be used a wrong plots in Figure 1 (e). It doesn't make sense that all methods show equal accuracy on task 46.\n\n"
        }
    ]
}