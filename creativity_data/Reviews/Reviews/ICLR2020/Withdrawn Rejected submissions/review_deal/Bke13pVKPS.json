{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper proposes a GA-based method for optimizing the loss function a model is trained on to produce better models (in terms of final performance). The general consensus from the reviewers is that the paper, while interesting, dedicates too much of its content to analyzing one such discovered loss (the Baikal loss), and that the experimental setting (MNIST and Cifar10) is too basic to be conclusive. It seems this paper can be so significantly improved with some further and larger scale experiments that it would be wrong to prematurely recommend acceptance. My recommendation is that the authors consider the reviewer feedback, run the suggested further experiments, and are hopefully in the position to submit a significantly stronger version of this paper to a future conference.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "*Summary*\nThe authors propose using evolutionary computation (EC) to perform meta learning over the set of symbolic expressions for loss functions. It's a compelling idea that is well-motivated. They find that applying their EC method to mnist yields an interesting loss function that they name the 'Baikal loss.' Much of the paper is devoted to analyzing the properties and performance of the Baikal loss. \n\n*Overall Assessment*\nThe paper's idea is very interesting. However, there are some important drawbacks of this work. These should be fixed and the paper should be resubmitted to a different conference soon.\n1) The experiments focus almost entirely on the Baikal loss (a particular loss function found once when running EC on mnist), and do not analyze the overall behavior of EC for loss functions. Does EC consistently converge to the same loss, or do different ones emerge different times you run it? What happens if you optimize convergence speed vs. generalization accuracy with EC? How do these loss functions differ?\n2) The experiments are largely on mnist, with a small study showing that the Baikal loss can be applied to cifar-10. It would be good to show that loss functions meta-learned on mnist generalize to larger-scale problems than cifar. \n\n*Comments*\nI was surprised when you optimized in fig 3 for convergence speed, rather than final accuracy of something that runs for a while. Why should our goal be to find loss functions that lead to fast optimization, instead of loss functions that lead to models that generalize best? If these are two different goals, then you should have two sets of experiments analyzing how GLO can find interesting (and perhaps different) loss functions for each.\n\nMnist is possible to get basically 100% accuracy. This means that the loss will only be evaluated in certain regimes of its inputs. What happens when you transfer this to problems where the best achievable accuracy is something like 60% for binary classification?\n\nYou should cite the Focal loss as another alternative to the cross entropy loss. Is the focal loss achievable in your particular grammar over loss functions? You should also cite label smoothing as an additional way to achieve a very similar implicit regularization effect as the Baikal loss.\n\nYou only analyze one loss function that came from your EC. What if you run it multiple times? Do you find different formulas? How do these perform? The beginning of the paper is very focused on EC, but then you transition suddenly to only discussing the Baikal loss. Can you present experiments demonstrating, for example, how the EC performance varies with the number of steps, with different ways to define the search space, etc?\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper proposes a very interesting idea of loss function optimization. At first sight, loss function is the goal of optimization and can not be optimized directly. However, the true goal of optimization is the final accuracy (for classification). So lots of loss functions can be designed and combined to form a large search space. In this paper, the authors adopt genetic programming to design loss functions hierarchically.  And experiments show that GLO (Genetic Loss-function Optimization) based loss function can achieve better results than cross entropy. \n\nThe paper is well written and easy to understand. I like the idea. Baikal loss is a form searched by GLO. Interestingly and counter intuitively , it is not a monotonically decreasing function. The authors explain it as a regularizer which can prevent the model to be too confident. \n\nExperiments on MNIST and Cifar10 are conducted to show the effectiveness of the proposed method. This part is very weak since MNIST and Cifar10 are very small datasets and the provided results are far from state-of-the-art results. Experiments on larger datasets such as ImageNet and more analysis about the optimization details are suggested to make this work more promising. Since the optimization is rather complex, it's better to show if it is stable enough to generalize to various datasets and models."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The authors present a framework to perform meta-learning on the loss used for\ntraining. They introduce the Baikal loss, obtained using the MNIST dataset, and\nBaikalCMA where the coefficients have been tuned. The evaluation of these loss\nfunctions is performed on the MNIST and CIFAR-10, and according to the results\nthey converge faster, towards lower test error and need fewer samples to obtain\nresults similar to the cross-entropy loss.\n\nThe claims are clearly stated and the framework is detailed, the experiments\ncover all the potential benefits of the Baikal loss. However it seems that some\npotentially critical points have been omitted. The cross-entropy loss is well\nknown to be beneficial in dataset with severe class imbalance. The two datasets\nused for evaluation are perfectly balanced, it might beneficial to see how it\nperforms in the unbalanced case.\n\nI have a couple of concerns about the method. First about step \"(1) loss\nfunction discovery\": The initial population starts with trees of depth at most\n2, and the final solution(Baikal) has either 2 or 3 (depending on which\ndefinition of depth is chosen). It is unclear that the genetic optimization is\nsuperior to simply choosing random loss functions. I think it would be relevant\nto add a figure that shows how the fitness of the leader of each generation\nevolves over time.\n\nThe second step \"(2) coefficient optimization\", while objectively generating a\nloss function that was superior on the metrics evaluated, raised some\nquestions. In equation (2) the factor \"1.5352\" seems to be equivalent to adding\na constant to the loss, which should not impact optimization. Also the factor\n\"2.7279\" seems to be equivalent to a change in learning rate. This may be an\nindication that the learning rate search was not done thoroughly. It would be\nbeneficial to clarify when it is happening: a) For each individual of the\npopulation during step (1), b) before performing CMA, c) after CMA. Also: Was\nlearning rate search was performed on the network trained with Cross-Entropy? It\nwas not entirely clear from the experiment details in Appendix A.2.1.\n\nAbout the Baikal loss itself, I fear that it could produce models that have very\npoor calibration, it might be nice to evaluate that (even if it is only in\nthe appendix).\n\n\nWhile the paper does a great job at presenting the problem and its applications\nand propose a framework that generated a loss that can transfer to other\ndatasets without any tuning required. I think it lacks a more thorough\nevaluation and description of the dynamics observed during the genetic\nevolution, and the performance of the Baikal loss on other datasets (my quick\nexperients with it on ImageNet diverged I did not have the time necessary to\ntune the hyper-parameters).\n\nMinor remarks:\n\nThere might be a slight omission in section 3.1: according to Figure 1, exp(x)\nis one of the potential unary operators explored by the GLO framework. However\nit is not present it the list of operators. Could you clarify this?\n\nTo the best of my knowledge, in the machine learning literature, it seems that\nthe letter x is used to denote the prediction and y for the ground truth. The\nfact that this paper used the opposite convention confused me the first time I\nread it.\n"
        }
    ]
}