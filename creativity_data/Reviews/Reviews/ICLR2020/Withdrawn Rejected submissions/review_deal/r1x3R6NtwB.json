{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper introduces a regularization scheme for gradient-based meta-learning. The scheme proposed is DropGrad, where they randomly scale the values of the gradient by a Bernoulli or Gaussian distribution effectively preventing overfitting and enhancing generalization. The authors evaluate the proposed approach extensively in domains ranging from supervised learning to reinforcement learning, and with different variations of their method.\n\nThe overall paper is well written and motivated. The experiment section is extensive and they show in different domains how their method performs better than without regularization. However, I feel that the overall contribution is not enough. First, their approach is not novel enough. Even dropout has not been applied to meta-learning, it has been applied to different  methods and fields successfully. Second, there is no insight why this approach works or should be used. The authors just reference to the success of dropout on other works. However, applying the dropout to a gradient is inherently different than doing it to the activations. For instance, it can result in a direction that is not of descent. Finally, while the experimentation is exhaustive, the results do not show the proposed approach works substantially better than without regularization. In section 4.1 and 4.2, almost all the results are within a standard deviation of each other. Moreover, in section 4.1, you are applying gradient dropout to \\theta and \\theta’, I wonder why that choice since it seems that the proper way of doing it would be to just apply the dropout to \\theta’. In this section, the authors should also compare against other kinds of regularization, for instance gradient penalty, L2, etc… In section 4.3, the results shown are just one random seed, which given the noisiness of reinforcement experiments renders them not very meaningful. Furthermore, the main motivation of the paper is to avoid overfitting, but here, there are just two tasks. Therefore, regularization should not help unless the improvement is coming from somewhere else. The authors claim that the “improvement could be attributed by the uncertainty on gradients that provide a better exploration of the policy”, but they do not have evidence for corroborating that claim. The inner update on MAML-RL comes for vanilla policy gradient, which already has high variance. It would be interesting (not only in this experiment but in supervised learning as well) to see the variance of your gradient estimator and w/o the regularization. \n\nAt this stage, this paper does not have enough delta on novelty, insights why the proposed method works (or should be used), nor results."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper proposes to apply dropout to the inner-step gradients of MAML as a regularization to prevent robustness against meta-level overfitting. The authors perform experiments on few-shot classification benchmark datasets, reinforcement learning task and online object tracking, on which the proposed regularizer improves the performance of the base gradient-based meta learners. \nThe paper tackles an important and less spotlighted problem of meta-level overfitting. However, it is well known that the meta-level overfitting can be alleviated by applying existing regularizers such as data augmentation, weight decay, label smoothing, and dropout [1], and the proposed DropGrad is simply a generalization of dropout applied to the same problem. \nThus the proposed meta-level regularizer seems very trivial or incremental at best. Without further experimental validations against other types of regularizers applied to the meta-learning framework, the contribution of the proposed work is unclear. Thus I recommend rejecting the paper unless those points are clearly addressed in the rebuttal.\n\nFurther Comments\n- The authors briefly discuss and compare against existing dropout methods. However, there is no information about the range of hyperparameters considered for the baselines, and the experiment considers only 5-shot classification case on the miniImageNet dataset. Could you provide more information and experimental results on this experiment?\n- Dropout could be applied when computing the outer loss as well as the inner loss, and this should be another baseline that DropGrad should be compared against.\n- Why should DropGrad perform better than the existing dropout techniques? What makes the difference between applying dropout technique before / after computing gradients?\n- It would be interesting to see how DropGrad would compare with DropBlock [2] in a meta-learning framework. \n- For MAML, ResNet-18 is one of the lowest-performing backbone networks, according to Chen et al. Could you provide the results on other architectures (ResNet-12) as well?\n \nReferences\n[1] Lee et al., Meta-Learning with Differentiable Convex Optimization, CVPR, 2019\n[2] Ghiasi et al., DropBlock: A regularization method for convolutional networks, NeurIPS, 2018"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper proposes to use a form of dropout (or masking) on the gradients for meta-learning purposes. Authors discuss two forms of masking, Bernoulli and Gaussian masking. \n\n\nThe proposed method is straightforward and reasonable. My only concern here and hence my weak reject score is due to the novelty of the work. Both masking options are well-known and as a matter of fact, been used before. In particular, the MT-Net uses masking on the gradient.\n\nAside from this, can you comment on the sensitivity of the solution wrt to the parameters? For example, in the case of the Bernoulli, can you elaborate on the performances while varying p? (I might have missed this) "
        }
    ]
}