{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper makes a claim that the iid assumption for NN parameters does not hold. The paper then expresses the joint distribution as a Gibbs distribution and PoE. Finally, there are some results on SGD as VI. Reviewers have mixed opinion about the paper and it is clear that the starting point of the paper (regarding iid assumption) is unclear. I myself read through the paper and discussed this with the reviewer, and it is clear that there are many issues with this paper.\n\nHere are my concerns:\n- The parameters of DNN are not iid *after* training. They are not supposed to be. So the empirical results where the correlation matrix is shown does not make the point that the paper is trying to make.\n- I agree with R2 that the prior is subjective and can be anything, and it is true that the \"trained\" NN may not correspond to a GP. This is actually well known which is why it is difficult to match the performance of a trained GP and trained NN.\n- The whole contribution about connection to Gibbs distribution and PoE is not insightful. These things are already known, so I don't know why this is a contribution.\n- Regarding connection between SGD and VI, they do *not* really prove anything. The derivation is *wrong*. In eq 85 in Appendix J2, the VI problem is written as KL(P||Q), but it should be KL(Q||P). Then this is argued to be the same as Eq. 88 obtained with SGD. This is not correct.\n\nGiven these issues and based on reviewers' reaction to the content, I recommend to reject this paper. ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The authors show that parameters of a DNN do not satisfy the i.i.d. prior assumption and that neural layer activations considered as i.i.d. are not valid assumptions for all hidden layers of the network. One can therefore not rightfully use GPs to describe the networkâ€™s hidden layers. The authors suggest formulating the neurons per layer as energy functions thereby rendering a hidden layer as a Gibbs distribution and the connection between adjacent hidden layers as a PoE model. \n\nThe paper is well written and well postulated. \n\n> Fig 4: What is the information presented by each neuron? How would this have looked with the i.i.d. prior in place.\n\n> There are places in the paper where one must refer to the supplementary, for example sections H and J with the simulations. Do consider moving these crucial sections to the main paper.\n\n> One recurring thought I had when the authors bring up Bayesian Hierarchical model, is that most of the BHMs rely on i.i.d assumptions both in the prior space and with the observations. How would you stand by your claim of explaining a DNN's layers to be modelled as a BHM? \n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #27",
            "review": "\nMain contribution of the paper\n- The paper argues that the base assumption, the i.i.d. of the activated elements (activations) in the hidden layers, the existing methods (lee.et.al 2018) hold is not convincible.\n- Instead, the author proposes a new way to probabilistically model the hidden layers, activations, and layer/layer connections.\n- Based on the probabilistic model, the paper proposes a new regularizer.\n\nMethods\n- The author argues that the activation is not iid by empirically showing that the trained MLP (in most cases) does not un-correlated.\n- The author proposes a new probabilistic model for MLP, and CNN assuming the Gibbs distribution to each activation and also assuming the product of expert (poE) model to explain the layer/layer relationship.\n- And according to their model, CNN will be explained by the MRF model.\n- The author proposes a regularization term regarding layer/layer connection.\n- They argue that the SGD training can be seen as a first-order approximation of the inference of the hidden activations in MLP.\n\nQuestions\n- See the Concerns\n\nStrongpoints\n- The probabilistic explanation of the MLP and the CNN seems novel and was interesting to the reviewer\n- The proposed explanation assumes a weaker condition compared to the existing methods.\n\nConcerns\n- The main concern is that the reviewer cannot fully convince that i.i.d. assumption is wrong. \nEven though the trained MLP does not support the i.i.d. condition, one can suppose that the reason would be the typical training method (SGD), just finding the local minima in a deterministic way.\nMaybe the proof in Appendix.G. supports the argument of the author, but the reviewer failed to clearly agree with the argument.\nA clear explanation regarding the issue would be required.\n- As far as the author understands, the paper proposes a probabilistic (Bayesian) model for explaining MLP, but it seems that they just used SGD for training the model. \nIn that case, the reviewer is little suspicious of the role of the proposed regularization in that the regularization comes from Bayesian formulation, but the model was trained in a deterministic way.\nThe reviewer wants to ask the author that \n(1) is it possible to infer the model in a Bayesian manner such as sampling?\n(2) Is there any justification for using SGD when conducting the experiments regarding the regularization? If it is related to Appendix.G, clearer explanation would be appreciated.\n- As far as the reviewer understands, the regularization deals with the practical part of the paper. It would be better to see the effect of the regularization of widely used networks such as small-layered ResNet or others.\nIf the proposed formulation has other practical strongpoints, it would be nice to clarify them.\n- The explanation using Gibbs distribution and PoE looks similar to RBM. The reviewer strongly wants a clear explanation of the difference and the strongpoints compared to RBM.\n\nConclusion\n- The author proposed a new probabilistic explanation of the neural network, which seems novel and worth reporting.\n- However, the reviewer failed to fully agree on some steps in the process of the paper.\nTherefore, the reviewer temporary rates the paper as weak-reject, but this can be adjusted after seeing the answers of the author.\n \nInquiries\n- See the concerns parts.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "title": "Official Blind Review #1",
            "review": "Summary of the Paper:\n  \nThe authors claim the that i.i.d hypothesis that is often used in the prior when looking for the equivalence between neural networks and GP is not valid. Then, they propose a new interpretation of neural networks as Gibbs distributions (in the case of fully connected layers) and a MRF in the case of convolutional layers. Some simulations are done to verify this.\n\n\nDetailed comments:\n\nOverall I believe that the writing of the paper is very sloppy and difficult to read and follow. It is not clear that the GP interpretation cannot be valid simply because the activations and weights are not i.i.d. I.I.D is a sufficient condition but not required in the central limit theorem. For example, the sum of correlated Gaussian variables also tends to a Gaussian distribution. The same for non-Gaussian variables. Therefore, I do not think that the GP interpretation of the NN is wrong simply for that. This simply shows that the i.i.d. prior may be suboptimal.\n\nSumming up, I think that this paper needs more work. Currently, I do not think I can extract anything useful from it.\n\nThe prior is subjective and can be chosen by the user. So if an i.i.d. prior is actually chosen, the corresponding Bayesian  neural network will converge to a GP.\n\nAn i.i.d. prior may be sub-optimal. However, it can be used to interpret neural networks as GP. There is no problem with that.\n\nIt is well known that the sum of random variables can also converge to a Gaussian distribution even though they are not independent. This questions the claims of the paper.\n\nThe witting of the paper needs to be improved. There are several expressions that do not sound well. E.g., \", GP with i.i.d.\"\n\nZ'y in Eq. (9) should depend on l.\n\nIt is not clear what is the distribution of a hidden layer (activations weights etc..).\n\n\"...and f Y is an estimation of the true distribution P (Y |X)\" what do you mean by that?\n\nEq. (8) seems to be a prob. distribution for the random variable Fy. However, the authors give an expression for f_yl, which does not make sense.\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."
        }
    ]
}