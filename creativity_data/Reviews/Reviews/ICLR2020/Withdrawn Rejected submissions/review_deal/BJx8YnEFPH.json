{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper suggests an RL-based approach to design a data valuation estimator. The reviewers agree that the proposed method is new and promising, but they also raised concerns about the empirical evaluations, including not comparing with other approaches of data valuation and limited ablation study.\nThe authors provided a rebuttal to address these concerns. It improves the evaluation of one of the reviewers, but it is difficult to recommend acceptance given that we did not have a champion for this paper and the overall score is not high enough.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This article present an approach to assign an importance value to an\nobservation, that quantifies its usefulness for a specific objective task. \nThis is useful in many contexts, such as domain adaptation, corrupted sample\ndiscovery or robust learning.\nThe importance values may also be used to improve the performance of a model for the task.\n\nThe importance values are learned jointly with that model. \nA small neural network called by the authors a Data Value Estimator (DVE) is\nlearnt by the authors to estimate sample selection probabilities, which will\ndictate which instances will be used for the main model that tackles the\nobjective task. \nWhile the main model is trained through usual mini-batch gradient descent, the DVE can\nnot be, since the sampling process is not differentiable. \nIt follows that the DVE is trained with a RL signal, that follows\nthe variation of the loss throughout the learning process.\n\nThe method proposed by the authors is new and show very significant results\nover existing methods. It is scalable, while many of the presented approaches are not.\nIt is said to have a much lower computational burden than some existing methods,\ne.g. LOO or Data Shapley.\nThe paper is very well written, and the method is illustrated on several datasets,\nfrom different domains.\n\nHowever, it seems that many approaches that did not suffer from the same complexity\ndrawbacks of LOO and Data Shapley were not compared to this work. While some\nof the presented approaches are recent, e.g. ChoiceNet (2018), others are more established,\ne.g. domain adversarial networks (DANs, Ganin et al 2016) and are not compared for\ndomain adaptation tasks. Given that the contributions of the authors are solely empirical,\nit is necessary to compare their approach to other scalable domain adaptation approaches.\nThe approach proposed by the authors also features many hyperparameters, with\nfixed chosen values, and the architecture of the DVE is not precised, which may impair the\nreproducibility of the paper. \n\nThe authors should provide code if not already provided.  \nThere is a mistake on the legends of Figure 2 and Figure 3, since accuracy\nshould increase when removing the least important samples."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #2",
            "review": "This paper proposes a method for assigning values to each datum.  For example, data with incorrect labels, data of low quality, or data from off-the-target distributions should be assigned low values. The main method involves training a neural network to predict the value for each training datum. The reward is based on performance on a small validation set. To make  gradient flow through data sampling, REINFORCE is used. The method is evaluated on multiple datasets. The results show that the proposed method outperforms a number of existing approaches.\n\nI think the proposed method is reasonable, and the results look promising. However, I'm concerned that there's limited ablation study provided to show how each design choice impacts the performance. (After all, the proposed has many differences from existing methods.) Without proper ablation study, it's hard for the community to learn conclusively from the proposed techniques. In addition, as pointed out by the comments by Abubakar Abid, there is a model that is trained on the clean validation data used during training. But this is not discussed in paper. How does it impact performance? Also, all the image datasets studied in this paper are small, and this paper only considers fine-tuning the final layer from an ImageNet-pre-trained model. It'll be more convincing to show results on more relevant datasets or tasks in the community. \n\nOverall I think this paper is slightly below the bar for publication in its current form, and will benefit from additional experiments. \n\n\n-------after rebuttal--------\nThanks for providing additional results and explanations. I found the new ablations in C.6 helpful for understanding the impact of each of the design choices. The rebuttal also addresses my concerns regarding datasets, and my concerns regarding implementation details of ‘y_train_hat’, as now it's included in sec 4. Overall, after rebuttal, I'd like to recommend \"weak accept\" for this paper. ",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper proposes a meta learning approach based on data valuation for reinforcement learning tasks. The core idea is to train a second network (the data value estimator) in conjunction to a regular predictor network. The predictor is then trained with samples chosen via the data value estimation. The authors motivate this construction with the goal to filter out unreliable and corrupted data. \n\nIt's well established that RL poses a difficult learning problem, and as such the goal to improve the RL process is definitely a good one. To the best of my knowledge the approach proposed here is new. The exposition of the paper is also quite clear, and all parts of the approach are explained nicely. In addition, the submission contains a thorough evaluation of the method. \n\nA central point for the method seems to be the validation data set which is used to train the data value estimator. The text emphasizes that this data set can be \"small\" several times, and the discussion and results of section 4.5 try to shed light here. However, Figure 5 indicates that a fairly large fraction of samples is needed to identify, e.g., more than 50% of the corrupted samples.\n\nAnother cricital aspect for meta-learning approaches such as this one is also the training time. RL is already expensive, so if the meta learning introduces a large factor, the training could quickly become infeasible. Here, the text gives a factor of about 3, which is noticeable, but not overly big. This still seems practical. Potentially, the estimator could also be reused (at least partially) for repeated training runs.\n\nThe tests in figure 2 are somewhat unituitive at first - I was expecting results of models trained on datasets with different samples being removed beforehand, rather than removing samples based on a trained estimator. However, this test makes sense on second sight, and e.g., the significant drop in performance after removing the most important samples indicates that the estimator was able to correctly identify a certain portion of data that is actually important for successful predictions. In addition to the noisy label and domain adaptation tests, this paints a positive picture. The method seems to yield useful (be it somewhat small) improvements in terms of learning performance.\n\nOne aspect that could be justified better in my opinion is the choise for a discrete representation for the data value estimator. Shouldn't the method likewise work with a continuous representation here? The paper explain how the discrete model is trained with quite some detail, but the choice itself could be motivated more clearly.\n\nHowever, overall I think the method is interesting and yields nice performance improvements. It is described and evaluated in detail, so I think the paper could me included in the ICLR program."
        }
    ]
}