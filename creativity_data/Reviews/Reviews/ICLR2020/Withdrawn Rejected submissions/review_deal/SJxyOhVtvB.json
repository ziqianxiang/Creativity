{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "Summary:\nThe paper proposed a IEG method to handle the noisy label learning problem. IEG consists of 3 parts: 1)  isolate the noise\nlabels via meta optimization; 2) escalate the supervision mislabeled data via pseudo meta re-labeling; 3) use small trusted data to guide training. IEG gains improvements over SOTA. \n\nStrength:\n1. The motivation of IEG is very clear. \n2. Ablation experiments are useful for understanding. \n\nWeakness:\n1. The organization of Section 2 is somewhat confusing. Readers may need to jump from one section to another section to follow how the method work. IEG should consist of 3 components, while there are only 2 subsections in section 2. Could the authors clarify which part corresponds to which component? \n2. I am wondering where are the tiny trusted data used? I am not following that from ALG 1. Do I miss something?\n3. For experimental comparisons, I think the authors may miss some important baselines. \n    1) Symmetric cross entropy for robust learning with noisy labels, ICCV2019\n    2) Joint Optimization Framework for Learning with Noisy Labels, CVPR2018\n    3) Dimensionality-driven learning with noisy labels, ICML2018\n4. For the ablation study, the authors miss some important experiments. 1) testing the influence of the number of trusted data; 2) showing the rate of isolated misclassified data in the learning process. 3) showing the influence of weight w. \n5. Open-set case is important for understanding IEG. I am confusing why IEG still works so well in the open-set case where most labels of data cannot be predicted correctly because of the open-set setting. The weight w before examples very small? or anything else? The author should provide more evidence on open-set case for better understanding. "
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper combines several methods for dealing with label noise. Specifically, combining the idea of learning to reweight (Ren et al. 2018), pseudo labeling (Berthelot et al. 2019), MixUp regularization (Zhang et al. 2018 ICLR), etc. Excellent empirical results have been achieved. Sufficient details have been given to repeat the experiments. Overall, the paper is well-organized and presented. \n\nI appreciate that the performances have been greatly boosted for many datasets for dealing with label noise. \n\nHowever, as for an academic paper, I think only good empirical performance maybe not enough given that it is achieved by combining several existing methods. "
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper proposed a method named IEG (the first letters of isolation, escalation and guidance) for robust neural network training with severe label noises. Specifically, the letters of IEG mean isolation of noisy labels, escalation of useful supervision from mislabeled data, and guidance from small trusted data. Therefore, the method is a combination of 3 components.\n\nIn fact, \"I\" is just the sample selection direction in learning with noisy labels, and \"E\" is just the label correction direction in learning with noisy labels. They are 2 out of 3 famous directions when there are only training data with noisy labels. The direction of \"G\" is also quite famous when there are also a small set of clean validation data. These directions are conceptually orthogonal, and this is known for long time in this area. A combination of them cannot make the novelty above the threshold of a very competitive ML conference like ICLR! Note that this is an academic/scientific paper, not an industrial product, so you don't need to combine all things that might work.\n\nBTW, in \"E\", no useful *supervision* from mislabeled data is used; instead, some useful *information* from mislabeled data is used. The term supervision refers to the y part rather than the x part of the data in ML or at least in weakly-supervised learning."
        }
    ]
}