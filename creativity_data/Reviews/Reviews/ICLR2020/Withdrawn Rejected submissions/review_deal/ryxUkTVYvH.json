{
    "Decision": {
        "decision": "Reject",
        "comment": "This work performs fast controllable and interpretable face completion, by proposing a progressive GAN with frequency-oriented attention modules (FOAM).  The proposed FOAM encourages GANs to highlight more to finer details in the progressive training process. This paper is well written and is easy to understand. While reviewer #1 is overall positive about this work, the reviewer #2 and #141 rated weak reject with various concerns, including unconvincing experiments, very common framework, limited novelty, and the lack of ablation study. The authors provided response to the questions, but did not change the rating of the reviewers. Given the various concerns raised, the ACs agree that this paper can not be accepted at its current state.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #141",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper aims at the problem of face synthesis. The authors propose a progressive GAN with frequency-oriented attention modules for high resolution and fast controllable and interpretable face completion, which learns face structures from coarse to fine guided by the FOAM. Experiments are conducted to verify the effectiveness of the proposed method. This paper is well written and is easy to understand. \n\n1. The most interesting idea is the frequency-oriented attention modules ,while the idea of structure-aware seems very common in the area.\n\n2. The experiments are unconvincing. There are so many works about face synthesis in recent years. Why do the authors only compare with GL and CTX? Also, the authors do not study how each component affects the final performance, which is very important for the reader to understand why it works.\n\n3. In general, the framework of the proposed method is very common. This paper only follow previous work and lacks new insights about the problem. "
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. It combines the masks, landmarks, corrupted images as inputs to generate completed images in high-resolution. The proposed frequency-oriented attentive module (FOAM) encourages GANs to highlight much more to finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures.\n\nIntegrating the Progressive growing GAN (PGGAN) for high-resolution face completion is an interesting step-up work after the success of PGGAN on high-resolution image generation.\n\nBasically the FOAM is proposed to merge the images from different resolution levels instead of a weighted summation. The novelty, however, is not strong as the simple summation provides reasonable performance as convinced in the progressive growing GAN paper. And there lacks quantitative analysis on ablation study as showed in Figure 4. Therefore, the contributions of each component are not convincing.\n\nUsing Progressive Growing GAN for high-resolution face completion is also studied in [1]. Figure 17, Figure 18, indicates the author used the same structure as used by [1]. However,  [1] is not cited and there is no comparison between these two models in the paper.\n\n[1] Zeyuan Liu, et al  \"High Resolution Face Completion with Multiple Controllable Attributes via Fully End-to-End Progressive Generative Adversarial Networks \""
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes a face completion network that synthesizes the missing part in the face images with GANs. Using facial landmarks and facial attributes, face completion became controllable as both are used as conditional information (input) for the generation (synthesis). Moreover, the proposed Frequency-Oriented Attention Module (FOAM) enables an interpretable coarse-to-fine progressive generative process. The proposed methods show significant improvement in the completion quality.\n\nOverall,  the method shows how the face completion can be controlled and how the face completion is done by improving details. The attentive framework makes possible to do kinds of band-pass filtering. The results are impressive but have some concerns as the following:\n\n- Have you tried to train models without using facial landmarks? Are facial landmarks only for controlling facial expressions?\n- As I carefully looked at the generated faces, many of them have asymmetric (unbalanced) eyes. Is it due to the predicted facial landmarks?\n- Is there any randomness (random input) involved during completion (generation)? Is this model possible to generate different faces from the same conditional input?\n- What happens if the attributes are interpolated rather than zero or one?\n- The order of Fig 4 and 5 seems weird."
        }
    ]
}