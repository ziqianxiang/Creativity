{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper extends Gauge invariant CNNs to Gauge invariant spherical CNNs.  The authors significantly improved both theory and experiments during the rebuttal and the paper is well presented. However, the topic is somewhat niche, and the bar for ICLR this year was very high, so unfortunately this paper did not make it. We encourage the authors to resubmit the work including the new results obtained during the rebuttal period.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Cohen et al. recently proposed the \"Gauge equivariant CNN\" framework for generalizing convolutions to arbitrary differentiable manifolds. The present paper instantiates this framework for the case of the sphere.\n\nThe sphere is the simplest natural non-trivial manifold to try out gauge invariant networks on, and spherical CNNs have several applications. However, other than the details of the interpolation etc., there is really very little in this paper that is new relative to the original paper by Cohen et al., it reads a bit more like an extended \"experiments\" section. \n\nUnfortunately the experimental results are not all that remarkable either, probably because the tasks are relatively easy, so other SO(3) equivariant architectures do quite well too. Given that there is essentially no new theory in the paper, I would have welcomed a much more thorough experimental section, comparing different architectures, different discretization strategies of the sphere and different interpolations/basis functions."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "1. (p1) ``in almost in all cases\" to \"in almost all cases\" \n2.  (1.1) The authors could explain more about why we would want to consider tensor features. \n3. They conducted experiments on different datasets, including the MNIST dataset. They achieved good results comparing to baseline spherical CNNs. However, the advantage of this method over S2CNN can be further elaborated, as S2CNN already achieved high accuracy; it seems like the one improvement is the complexity (improved from S2CNN's $O(N \\log N)$ to their model's $O(N)$), but the reduction of complexity is not significantly reflected in the training time per epoch (from 380s to 284 s). \n4. Overall, the paper provides clear theoretical backgrounds on gauge CNNs that justifies their definition of convolution operator only uses the intrinsic structure of the manifold (does not reply on higher dimensional embedding)."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes SO(3) equivariant layer, derived from the recently introduced Gauge equivariant CNN framework. The novel contributions are in taking the Gauge equivariance CNN and finding efficient ways to perform logarithmic mapping, parallel transport, and convolution by the equivariant kernel when applied to the sphere. An interpolation scheme for an improved approximation to global SO(3) symmetry is also discussed. Experimental results on spherical MNIST, climate pattern segmentation, and omnidirectional semantic segmentation demonstrate the usefulness of the proposed method for prediction on a sphere.\n\nFor the most part, the paper is very clearly written despite the challenging and technical nature of the topic. In particular, the first four pages provide a nice overview of related work and a clear explanation of the Gauge equivariance framework of Cohen et al’19. Two sections that can benefit from further clarification are the proposed \"regular non-linearities\" (where it would be nice to show in equation why we have equivariance), and equation (4), the logarithmic map (where I had a hard time mapping the discussion in words to the equation). \n\nHowever, the experiments, while satisfactory, are not impressive: one issue is that the results are mostly compared to the results of two relevant papers by Cohen and colleagues. In recent years, there have been other proposals for deep learning on the sphere, and I wonder why experiments do not try to compare with these works?  (see Kondor et al’18, Coors et al’18, and others cited in the paper.) Moreover, although in theory, the proposed framework improves the Icosahedral CNN of Cohen et al’19 (by directly operating on the sphere rather than an Icosahedral approximation), the practical improvements over the Icosahedral CNN seem to be often marginal (with one exception in spherical MNIST). Do you have any explanation for this? Is there any setup where you expect the proposed approach would give a substantial improvement?\n"
        }
    ]
}