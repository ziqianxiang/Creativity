{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper attempts to introduce a neural network which structure which is inspired by use of episodic memory in the brain. Unfortunately, it is very difficult to discern what the precise contribution is, either from the methods sections or the experiments, and a few competing goals of the paper seem to be at odds.\n\nStarting high-level, I still am not clear what the paper's fundamental goal is. In the abstract, there is the stated goal that a challenge to understanding the results of cognitive experiments on animals is \"incomplete access to relevant circuits in the brain\", and that ANNs can \"model neural circuits\". This is a fine goal — using a computational model of the brain as a means to better understand its latent processes when analyzing experimental data — but it is worth bearing in mind that actual models of the brain do not have much in common with typical deep learning architectures, even recurrent networks. However, the following sentences seem to completely contradict this goal! Instead of building a low-level model of the brain, the goal is to build an ANN which mimics the high-level cognitive behaviour. This is also a fine goal — mimicking humans or animals in behaviour at particular tasks makes sense, and may even help us learn about high-level cognitive function — but it is not at all clear what this has to do with recording \"the electrical activity of the animals neurons\". To me these seem like fundamentally different goals, with different types of models required: a biophysical model for the former, probably, and a deep learning model for the latter.\n\n\nUnfortunately, I do not understand what model is being introduced. Section 2.1 introduces a variant of a GRU, but does so without defining any relevant notation, and without defining the standard GRU in their notation by which we could compare differences. Instead, we are given a description of a simple RNN (in a continuous-time formulation), and then the modified GRU (in a discrete-time formulation). Why is the standard GRU not presented, if that forms the basis for modification? What are these modifications? It seems like the primary change is injecting gaussian noise in Equation (4), but the text claims the primary change is the use of a \"threshold-linear\" (I assume this is the same as rectified linear) activation on the output. Also, what is the function f() in equation (4)? The text says \"The function f(x) = x is a linear function\" — which is, in fact, the identity function. Why is the identity function here?\n\nWhich part of this modified GRU corresponds to episodic memory?\n\nIf this is not the episodic memory, where is it? There are no further equations anywhere in the paper. The entire high-level description in section 3.2 of a \"replay buffer\" is far too vague to constitute an explanation. How is this buffer used? An algorithm block, at the very least, would be necessary. From the text, I have no idea how to implement this method.\n\nExperiments: the correlation to the animal behaviour in Figure 3 is quite good. However, this is a very small setting — is this all the data available from Roitman & Shadlen, or similar studies?\n\nAlso, multiple times the paper points out the goal is not to maximize performance, but rather to mimic the animal data. I think instead it would be good to re-define \"performance\" as correlation, or some other measure, relative to the animal behaviour: \"good performance\" means the left and right columns of figure 3 nearly match. This can be quantified!\n\nHow well do other algorithms, without the episodic memory or the modified GRU, perform at the task in figure 3? What is a meaningful baseline here — do other machine learning methods perform meaningfully differently from the proposed method?\n\nFinally, I am confused by the experiments on the final two pages. It is stated it takes 18,000 trials for the agent to achieve the baseline accuracy rate. How many trials does it take the monkeys in the original study? Is it possible to also include the monkey performance in figures 4 and 5, is matching the monkey performance is the goal?\n "
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "The authors trained recurrent neural networks (RNNs) augmented with episodic memory on a random dots motion discrimination (RDMD) task. They observe that agents with the episodic memory system learn to perform the task in fewer trials than those without. Further, they observe that varying the types of memories stored strongly influences the agents' performance.\n\nMy major concern about this paper is that it doesn't seem to provide new insight into the neuroscience of perceptual decision making or episodic memory. Do we believe that episodic memory/the hippocampus are actually involved in perceptual decision making tasks like RDMD? Is there evidence/discussion in the neuroscience literature suggesting that the hippocampus is invoked in RDMD in primates or humans? If the answer to either of these questions is yes, then it's necessary to make that case in the introduction/motivation section of this paper. If the answer to both is no, then I'm not sure what the purpose of modeling RDMD with episodic memory is.\n\nBasic Clarifications\nHow do you sample memories to retrieve? How are those retrieved memories then used? Are they provided as input to the RNN? Are they reinstated?\n\nHow are you training the parameters? You're using policy gradients, should we assume you're also using backprop/backprop through time?\n\nOther comments\nThis sentence doesn't sit well \"existing theory fails to describe how the brain selects experiences, from many possible options, to govern the decisions that are made.\", given\nMattar, M. G., & Daw, N. D. (2018). Prioritized memory access explains planning and hippocampal replay. Nature neuroscience, 21(11), 1609.\n\n\"This means that the additional viewing time for difficult trials was devoted to integrating sensory information.\" This claim doesn't seem justified.\n\nTypos\nrecognitive function -> cognitive function\nto predicting -> to predict\nat the beginning of the trial -> at the beginning of training\nOur result suggesting -> Our result suggests\n"
        }
    ]
}