{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper presents a synthetic oversampling method for sequence-to-sequence classification problems based on autoencoders and generative adversarial networks. \n\nAll reviews reject the paper for two main reasons:\n1 The novelty of the paper is not enough for ICLR as the idea of utilizing GAN for data sampling is common now.\n2 The experimental is not convincing as authors did not compare with other leading oversampling methods.\n\nThe rebuttal did not well answer these two questions; thus I choose to reject the paper.\n",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #5",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "1. For imbalanced learning problem, Precision cannot play a good role. Therefore, I recommend using the performance metrics F-value and G-mean to provide comprehensive assessments. \n2. In table 2 of the 5%  data imbalance, the proposed method is not as good as the baseline. Could you provide more results with different percentage of data imbalance, such as 2%, 3%, and 4%. \n2. The authors created their own baseline, and compared against it. There is plenty of baseline methods in literature to compare against such as:\n[1] Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. SMOTE: synthetic minority over-sampling technique. Journal of Artificial Intelligence Research, 16:321–357, 2002. \n[2] Haibo He, Yang Bai, Edwardo A Garcia, and Shutao Li. ADASYN: Adaptive synthetic sampling approach for imbalanced learning. In 2008 IEEE International Joint Conference on Neural Networks, pp. 1322–1328. IEEE, 2008. \n[3] Han H, Wang W Y, Mao B H. Borderline-SMOTE: a new over-sampling method in imbalanced data sets learning[C]//International conference on intelligent computing. Springer, Berlin, Heidelberg, 2005: 878-887.\n3. Figure 2 is hard to understand.\n4. What if projecting both original data and synthetic data into 2D space for visualization, as shown in “Model-Based Oversampling for Imbalanced Sequence Classification”. \n5. How robust is the proposed algorithm when facing different levels of noise?\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper is well-written. The idea is good, but it seems like GANs have been suggested for Imbalanced data sequences before. A quick search on google, I found this paper:\n\"Multi-Task Generative Adversarial Network for Handling Imbalanced Clinical Data\" by Mina Rezaei et al., arXiv:1811.10419v1\n\nMoreover, the paper doesn't seem to be comparing their results with other state of the art imbalanced sequence classification methods. The comparisons are all between different proposed GAN methods. \n\nFor these two reasons, I do not recommend this paper for publication at this point. "
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper consider important and interesting problem: how to generate a sequence from minority class if we want to do oversampling with synthetic data in a way similar to SMOTE. \n\nNow from the paper, the exact used approach is not clear, as the details are too scarce (see some examples below). Experiments are not convincing, as the authors don't compare to the state of the art approaches. As the exact problem statement is hard to grasp, it is hard to identify the exact contribution of authors.\nNote, that the proposed approaches, in my opinion, are not that different from approaches from modern data generation for imbalanced classification [1, 2], as we propose some kind of GAN to generate new data and so have only two variables: how we select loss for this GAN and how we select the architecture.\n\nI assume, that to be accepted at a major venue a deeper investigation is required at the moment.\n\nSee also the following comments:\n1. Figure 4: title is not required, as we have a caption with the same information. Better to use confidence bars too.\n2. The figures will benefit from usage of vector format.\n3. Figure 3: tSNE can vary from one run to another. It is better to provide at least 3 random figures or even better train e.g. a simple classification model for t-SNE embedded model and present ROC AUC scores for identification synthetic/non-synthetic.\n4. Table 1&2 formatting is different from that usually used in Academy (see e.g. https://dl.sciencesocieties.org/files/publications/style/chapter-05.pdf)\n5. F1 score is often not the best metric for imbalanced problems. The paper will benefit from providing also PR AUC (average precision) scores.\n6. Figure 2: avoid confusion matrices presented in this form, as they take much space providing almost no information. Classic tables are better.\n7. From the problem statement at the very beginning of section 2 it is not clear what kind of labels do we expect (I suppose that for each sequence we have a specific label i.e. all y_i are 0 but one, that is 1)\n8. Sometimes bigger weights for minority objects or dropping significant part of majority sequences are enough, so results for these approaches also should be included\n9. How the hyperparameters mu and lambda were selected?\n\n[1.] Guo, Ting, et al. \"Discriminative Sample Generation for Deep Imbalanced Learning.\" Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 2019. IJCAI 2019, https://www.ijcai.org/proceedings/2019/0334.pdf\n[2.] Douzas, Georgios, and Fernando Bacao. \"Effective data generation for imbalanced learning using conditional generative adversarial networks.\" Expert Systems with applications 91 (2018): 464-471."
        }
    ]
}