{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "The paper aims to understand and interpret feature representation in DNNS by proposing two entropy-based at pixel-level metrics called Strict information discard (SID) and reconstruction uncertainty (RU). The new metrics are used to diagnosis the generality and coherency of DNN models. \nOverall, quantifying and interpret feature representation learning in DNNS are important and interesting topics. Two proposed metrics have clear intuitions. However, the paper needs to be improved to be published at the top-notch venues. \nSection 3 contains the main contributions, however, there are many aspects which is not rigorously defined. Hence, it is difficult to justify the soundness of the metrics. Some unclear details are as follows\n1/ What is X_c, is it the empirical distribution of data or data distribution in general or what else? \n2/ In Eq(6), to compute the concentration, do we need the ground truth?\n3/ The proposed metrics are mentioned to be related to the information-bottleneck principle but the paper does not describe it in detail. How are they similar and different? Can newly proposed metrics replace the information-bottleneck principle? \n4/The paper mentioned that the perturbation-based methods are heuristic-based, why are the entropy-based methods not heuristic? Is there any theoretical guarantee that they reflect the idea of SID and RU?\nMoreover, the experiments only demonstrate how SID and RU works in several datasets and settings. There is no comparison with other works in the literature, e.g. the information-bottleneck principle."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes two measures of information discarding during forward propagation of a neural network. The paper presents how to calculate the two measures, compare them with alternatives, and demonstrate their values in different networks and different tasks. \n\nThe paper is in general well written. However, first, the proposed measures do not seem to be well motivated--what is the essential purpose of having the measures? Second, although the intuition is clear, the proposed methods do not seem be well justified. As the authors pointed out, the proposed measures are related to the mutual information I(F;X), where F is the considered inner representation. Why are the proposed measures superior to alternatives? Why are they better than the information bottleneck one (in the extreme case, to make it task-independent, one may drop the term involving Y)? Furthermore, on the technical side, the raw input as well as the reconstructed input is highly non-iid (independent and identically distributed), so is it sensible to calculate the total entropy H(X_c) as the sum of the individual ones for the pixels (in equation 2, for example) at all? Third, the authors tried to justify that the proposed measures are consistent and faithful in Section 4, but I failed to see if from the panels in Figure 1. What is the exact definition of coherency here? "
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "Summary: this paper introduces 2 new entropy-based metrics that can be used to explain what happens in hidden layers of image neural nets. These metrics are information discarding (how much original info from the features is flowing through a particular layer) and reconstruction uncertainty (how much can be  recovered to the original input)\nOverall, it is an interesting idea and it looks less ad-hoc than other methods (gradient based, inversion based etc).  The  initial ideas and approximations are well explained, but applying it all to neural nets is not that clear- I did find it hard understanding how it all works together, and an algorithm for computing all the metrics would in a table would be much easier to follow.  I also find it hard to draw any conclusions from observing the values of the metrics (please see below) on different architectures (see comment #4).\n\nDetailed questions/comments\n1) How is delta_f computed? Is it a variance of activations values over the batch? Or something else\n2) How is concept defined? It seems that the paper goes under the assumption that there is a magic subset f  (in a hidden layer), but where is it coming from. For a trained nn, how do you define what this f is?\n3) How does the proposed method apply to non image settings, for example a simple binary classification with dense features. What are the concept features, where is the ground truth segment etc\n4) Figure 3: what conclusions do we draw from it? Which modification of res net was giving better performance? Should we look for networks with higher SID, harmonic mean of SID and reconstruction or something else How do you practically use the metrics you propose to chose the best architecture. The only thing you say is that deep DNN has higher SID and RU. Struggling to understand what use this is. \nFrom the appendix, Section A is actually more interesting and illustrative than what you put into experiments in the main paper. \n5) Experiments didn't really compare your proposed method with any of alternative methods. A couple of illustrative pictures with what your method shows and gradient based shows for example would go a long way\n6) How do you train a reconstruction network to ensure minimum required efficiency. What is the architecture you chose for it?\n7) If these proposed metrics are correlated with generalization (which is not clear yet), do you  think it can be introduces as a new regularization during training.\n\nMinor: \n- I really would suggest to have separate captions for each figure, instead of one long caption and top left, top right etc. It is really hard to parse\n- In appendix instead of such a large dump of pics, chose a couple that really illustrate that you are trying to show, and add the explanations from alternative methods (gradient based for example) to demonstrate the benefits of your method \n\n"
        }
    ]
}