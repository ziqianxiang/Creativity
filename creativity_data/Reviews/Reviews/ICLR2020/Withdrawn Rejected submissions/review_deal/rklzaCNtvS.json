{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This submission claims to adapt and improve on neural semantic encoders for the task of abstractive summarization. The submission:\n- briefly describes the neural semantic encoder (NSE) model (Munkhdalai and Yu, 2017)\n- claims that the dot-product attention mechanism in NSE is too simplistic for the task of summarization because dot-product attention does not capture word-sentence and sentence-sentence correlations, the latter two being important to summarize a document, and suggests utilizing the additive attention mechanism along with the pointer-generator mechanism instead\n- Introduces the “hierarchical NSE” model and a self-critical sequence training scheme to optimize for ROUGE\n- Provides empirical results for these models and for other relevant baseline models on the CNN/Daily Mail dataset\n\nAt a high-level, this submission is unpolished, imprecise, lacks technical (both experimental and theoretical) rigor in its description and explanation of its methods, and generally does not have a significant contribution, which is why I believe it should be rejected.\n\nThe primary motivation underlying this submission is strong: modeling long-range dependencies in a document is very critical for abstractive summarization. However, the submission does not make a convincing case for its proposed methods/models, in the context of this motivation and otherwise. The whole premise behind the NSE (according to Munkhdalai and Yu’s paper) is that its variable-sized encoding memory allows it to access the entire input sequence during reading, thus providing for long-range dependencies and helping with tasks like summarization. So the exceptionally low ROUGE scores for plain NSE in Table 2 seemed at odds with the motivation and premise. The authors attribute this very briefly to the dot-product attention mechanism and show empirically that changing it to an additive attention mechanism leads to a significant increase in ROUGE.\n\nAt an intuitive level, the notion of “highlighting” seems to be congruous to “attending”. The submission (with the title Read, Highlight and Summarize) seems to be suggesting that they are incongruous and that there is novelty in this notion itself, however there is no clear mathematical description or rigorous explanation of this notion.\n\nThe suggested improvements beyond the standard NSE architecture (augmented with the well-known additive attention and the pointer-generator mechanism) are limited to extending NSE in a “hierarchical” fashion and optimizing for ROUGE, both of which have not been described in sufficient detail or clarity for the task at hand. Munkhdalai and Yu evaluated the NSE approach for document sentiment analysis (among other tasks) and for that task, they used two NSEs: one for obtaining sentence representations and another for document representations using sentence representations. This submission’s “hierarchical NSE” seems to overlap with Munkhdalai and Yu’s approach for document sentiment analysis, except that the document memory seems to be constructed in a different fashion that is not clearly described.\n\nIn Table 1, Hier-NSE seems to be performing worse than the pointer-generator with coverage loss and only slightly better without coverage loss. Since Hier-NSE contains the pointer-generator mechanism, it seems the Hier-NSE isn’t really adding any non-trivial value. What would be interesting to try out as an exercise is to see if the factoring of lemma and PoS tags described helps significantly improve the pointer-generator with coverage loss.\n\nSome typos:\n- Equation 5 should have m_{r,t}, not m_{t,t}\n- Page 5 right above equation 22 has a Stack Overflow link that has nothing to do with the submission\n\nSuggestions on improving the submission that are here to help, not necessarily part of my decision assessment:\n- Provide dimensions for every non-scalar parameter in the Proposed Models section: while I see dimensions for some parameters, I do not see dimensions for others\n- Use accessible notation that makes it easy to distinguish between a non-scalar parameter and a scalar parameter (boldface non-scalars, use capitalized letters for only matrices/tensors, not scalars or vectors, etc.)\n- Use \\mathbb{R} for depicting the set of real numbers in LaTeX\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "# overview\n\nThe paper proposes a hierarchical memory network for abstractive summarization. The claimed innovation is to add a memory component to the regular sequence-to-sequence model. With all the additional pieces, such as having the ability to use words in the document as in pointer networks and training with ROUGE score as rewards, the paper achieves strong performance on CNN/Daily Mail data set.\n\nI am giving the paper a score 3. I appreciate the engineering effort and the strong performance reported in the paper. However, I am afraid that the presentation of the paper is not clear enough that others can reproduce the results without trouble. In addition, the design decisions are based on hypotheses that are either not proven or false, and I believe the paper should make it clear that those hypotheses are speculations, and we are responsible to stop misinformation from spreading.\n\nThe feedforward process in section 3 has many errors, which makes it impossible to reproduce the model. (A detailed list of the errors is given below.) The representation of the input and output and the loss for training the network are missing. Besides, there is no mentioning of the network's size and number of layers. The largest gain (by looking at table 1) comes from using the lemmas and pos tags. However, the details have been omitted in the paper.\n\nThe motivation/hypotheses for many of the design decisions, as stated throughout the paper, are too strong. The fact that the model works well might have nothing to do with those motivations. (A detailed list is given below.) An even more severe problem is that the biggest gain in the paper actually comes from using lemmas and pos tags, which has nothing to do with all the motivations and other design decisions. It is likely that other models can get similar performance gain by incorporating lemmas and pos tags.\n\n\n# a list of unproven speculations\n\n... either hierarchical attention mechanism are too sparse using hard attention or noisy using soft attentions.\n--> evidence?\n\nLSTMs ... often fail to capture long-term dependencies while modeling sequences.\n--> evidence? this is not a proven fact.\n\nTo address these issues, we have adapted Neural Semantic Encoders (NES) ...\n--> how so? i don't see how adapting NES fixes the problem.\n\nEncoder-decoder models have proved effective for short sequence tasks such as machine translation where the length of a sequence is less than 120 tokens. However, in text summarization, the length of the sequences vary from 400 to 800 tokens, and modeling long-term dependencies becomes increasingly difficult.\n--> evidence that LSTMs can remember 120 tokens but not 800 tokens?\n\nThe use of two LSTMs separately for words and sentences improves the ability of the model to retain its memory for longer sequences.\n--> evidence? we should not correlate how much LSTMs remember with task performance.\n\n..., just a dot-product attention mechanism is too simplistic for text summarization.\n--> how so? what does it mean to be too simplistic?\n\nHumans first form an abstractive representation of what they want to say and then try to put it into words while communicating.\n--> cite?\n\nWhen humans read a document, we organize it in terms of word semantics followed by sentence semantics and then document semantics.\n--> cite?\n\nReplacing Multi-Layered Perceptron (MLP) in the NSE with an LSTM further improved the performance because it remembers what was previously composed and facilitates the composition of novel words.\n--> evidence that the LSTM remembers and facilitates composition?\n\n\n# problems in the equations\n\nequation (4)\n--> r does not appear on the right hand side\n\nequation (7)\n--> k does not appear on the left hand side\n\nequation (11)\n--> might be useful to say that w now belongs to a larger set that is the union of the vocabulary set and the words appeared in the documents\n\nequation (15), (16)\n--> r does not appear on the right hand side\n\nequation (17)\n--> r does not appear on the left hand side\n\n\n# minor errors\n\nFigure 1\n--> the figure is not being referred anymore in subsequent sections. besides, we don't even know if the figure is what is actually happening inside the model.\n\nExtractive approaches select sentences ... and groups them ...\n--> group\n\n3.1 neural semantic encoder:\n--> remove colon at the end of the subsection\n\n..., which is a weighted combination ... forms a highlight\n--> ungrammatical sentence\n\nhttps://stackoverflow.com/questions ...\n--> misplaced link?\n\n... dropout, and L_2 penalty ... with a drastically increased training time.\n--> slow in terms of convergence rate? dropout and L_2 are not computationally expensive. if it is indeed a convergence issue, then more tuning is required?\n"
        }
    ]
}