{
    "Decision": {
        "decision": "Reject",
        "comment": "All reviewers rated this submission as a weak reject and there was no author response.\nThe AC recommends rejection.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #4",
            "review": "The paper bases its methodology on well known developments in image analysis/synthesis about similarity of pixel values in adjacent locations. Many techniques have been used for modelling this similarity, including predictive models, cliques and graphs. The paper uses a simple autoregressive model for generating pixel values based on the values of previously processed pixels, estimating the differences between these neighboring pixel values. \n\nThe method is implemented through copying the pixel values and adjusting the differences.  Three types of prediction, based on absolute, or relative values are examined, for image generation, colorization, super-resolution. The problems are significant, but the approach rather superficial. A small experimental study is presented, based on CIFAR-10 and downsampled ImageNet datsaets. Much more experiments, including quantitative and qualitative results are reuired, to validate the prospects of the method in different types of (complex) problems and contexts. Marginal improvements are observed in the presented results. Since image generation and image to image translation are targeted, comparison and/or combined use with Sota methods, i.e., GANs should be examined. \n\nMoreover, the paper presentation needs improvement; for example, symbols are undefined when used for the first time in the text (see eq. 3), etc.  \n\n   ",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "In this paper the authors present a new way to use autoregressive modeling to generate images pixel by pixel where each pixel is generated by modeling the difference between the current pixel value and  the preexistent ones. In order to achieve that, the authors propose a copy and adjustment mechanism that select an existing pixel, and then adjust its sub-pixel (channel values) to generate the new pixel. The proposed model is demonstrated with a suite of experiments in classic image generation benchmark. The authors also demonstrate the use of their technique in Image to Image translation.\nOverall, although the paper explain clearly the intuition and the motivation of the proposed technique, I think that the paper in its present state have low novelty, weak related work analysis review and insufficient experiments to support a publication at ICLR. \n\n\n\n**Novelty, contribution and related work**\nThe authors should highlight better their main contribution novelty of the proposed method compared to their baseline.\n\n\n**Result and conducted experiments**\nthe correctness of the proposed approach is not proved by the conducted experiment  in fact:\nThe experiments do not provide the details of the used architecture compared to your baseline. \nIn Table 1 you report the results using your technique on several computer vision tasks (generation, colorization and super-resolution) but you're not comparing with the SoA of each of these tasks.\nThe  results reported in Tables 1 and 2 are not convincing  when compared to existing approaches (using only CIFAR10 in Table2). \nThere are so many missing details specially to validate Image-To-image translation \nFigure 3 is confusing and  not clear  \n\n**Minor comments**\nIn  references section : (Kingma & Dhariwal, 2018) is not in a proper format (nips 2018)\nBad quality of illustrations and images \nBe coherent with the position of captions (figure 3)"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes an approach for image generation that relies on an autoregressive model for the image pixels. These models are popularly used in image coding and compression settings, and have been used in generative models like PixelCNN. In contrast to this prior work, the proposed model is based on the selection of a previously available pixel and the modeling of the differences between the old pixel and the new one. The copy and adjustment models, i.e., eqs (3) and (5-6), are straightforward. Applications to image-to-image translation are also presented.\n\nI am rating the paper \"weak reject\" mostly due to the limited set of comparisons in experimental results. There is no qualitative comparison to other algorithms for two of the problems considered (colorization, super-resolution) and the comparison with other algorithms for unconditional image generation is limited to CIFAR-10; thus, the impact of this contribution is not clear. Furthermore there is no discussion of these comparison results - i.e., what the proposed algorithm contributes given that it's outperformed by the sparse transformer.\n\nIt is not clear at first what the authors mean by \"sub-pixel\", which appears to be one of the color/spectrum channels of a pixel of the image? Also not clear what \"outcome masking\" refers to. The explanation of the hidden states (g,h) used for each mechanism are not always clear or explicit. For example, can you write an equation for h_{i,c-1} which is more explicit than \"composing the history of generated sub-pixels\"? Can you define Ui when it is first used in (6)? What is the difference between the pixel state h_{r,C} and its values x_r?\n\nMinor comments\nThe second equation in Section 2.3 is missing =\nIn Section 5.1, it is not clear what is meant by \"discrediting\" the image.\nThe table in Fig. 3 could use full names for the problems instead of initials."
        }
    ]
}