{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "\n=== Summary ===\nThe authors study the importance of spatial information in (later layers of) CNNs for Image Classification. Specifically, they propose to remove spatial information by either 1) shuffling the input to a convolution, 2) average pooling and replacing convolutions by fully connected layers or 3) replacing spatial convolution by pointwise (1x1) convolutions.\nThey find that removing spatial information in the last layers of CNNs at training time doesn't impact image classification performance while removing parameters (and potentially FLOPs) for VGG16, ResNet50.\n\n=== Recommendation ===\nThe presented study contains a few experimental flaws. The choice of method for removing spatial information is rather arbitrary and it seems the authors confuse spatial information (being aware of the relative spatial position between pixels) and spatial processing (processing nearby spatial positions). Specifically:\n- For shuffling, it makes more sense to keep spatial consistency by applying the same shuffling operation to all feature maps. Shuffling independently for each feature map does more than destroy spatial information, it also destroys spatial consistency which probably hinders training more than it needs to.\n- The authors should have tried 3x3 convolutions where the weights are the same for each relative position (ie C^2 parameters instead of 9C^2 parameters, but the same amount of FLOPS). This allows to still increase the receptive field size in the last layer but without using spatial information.\n\nExperimental improvements of accuracy with respect to the number of parameters are shown on very suboptimal architectures such as VGG16 and ResNet50. The improvements on better architectures (from a parameter efficiency perspective) are negligible. In particular, the rule of thumb provided by the authors is already applied in today's most efficient models such as MnasNet and EfficientNet.\n\nThe small importance of spatial information for image classification, especially in later layers, is relatively well known and has already been mentioned by other work such as Approximating CNNs with bag-of-local-features models works surprisingly well on imagenet. This also relates to the \"Picasso problem\" and the motivation for capsule networks.\nAdditionally, work on applying self-attention for vision is also concerned with adding spatial information to the self-attention operation (As such, it could have been interesting to replace the 3x3 convolutions with local self-attention layers without spatial information).\nThe additional questions raised by this work are rather non-conclusive (e.g: relationship with receptive field size, removing spatial information as regularization)\n\nIn summary, the presented study, while interesting, contains a few flaws, is of limited scientific novelty and experimental results are rather underwhelming.  The current draft doesn't warrant for ICLR acceptance."
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper wants to show that removing the spatial information from the last layers of a deep neural network does not affect the network performance (in some case it obtains even better results). Results seem consistent across different datasets and models.\n\nI lean to reject this paper because the proposed analysis is quite shallow and many considerations about geometrical information are not taken into account. In my opinion, there are few interesting experiments in the paper, but the global plot that spatial information is not useful does not work. In particular 1x1 convolutions do not destroy the spatial information of a network. In the following, I explain it more in detail.\n\nIn this paper is missing a clear definition of spatial information and how it is represented throughout the network's layers. It considers three different ways to “destroy” spatial information. However, in my opinion only shuffle conv and global average pooling (GAP) really destroy the spatial information in a network:\n- Shuffle Convolution: In this case, after this layer, the spatial information is fully destroyed because the location of the feature maps is shuffled. If enough shuffling iterations are performed during training, the following fully connected layer of the network will learn to discard possible spatial correlations. In Table 2 left is quite interesting to see that a network trained with this shuffle conv layers at the end can almost recover the full performance when shuffling the last 3 layers, while it does not provide any results when applying shuffle net at run time only. However, shuffle net is abandoned for the following experiments presumably because it does not perform well on more difficult conditions.\n- Global Average Pooling: In this case, the spatial information is lost in the sense the all the spatial features are merged in a single 1x1 spatial dimension. It makes sense (in Fig.2) that shuff conv and GAP perform similarly because in both cases the only remaining information is at the feature level. It should be clear that, if the network has enough layers, and therefore enough receptive field, removing the spatial information at the last layers does not affect the performance, because the spatial information learned before it is more than sufficient. This is why many recent network architectures (e.g. ResNet) substitute the final fully connected layer with a simpler GAP layer.\n1x1Conv: When using a 1x1 convolution a layer considers the input features locally, in the sense that it does not look at how those features interact with the neighbors' features (or pixels). However, their spatial information is preserved for the following layers. For instance, if the network ends with a fully connected layer, this layer can collect and exploit the spatial information contained in the different locations of a feature map computed with 1x1 convs. The fact that a 1x1 convolution does not destroys spatial information can be seen also in Fig.3 right. There, even with only 1x1 convolution, the receptive field is still higher than 1 and the classification performance, even if reduced, is still good.\n\nOverall, I think that the paper needs a global rethinking with a better definition and understanding of spatial information and in which sense it is destroyed.\n"
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper examines the role of spatial information in image classification. The representation produced by the network is perturbed in a variety of ways including the use of a shuffled convolution where the spatial position of activations is randomly shuffle as information proceeds from early layers to later layers. This is done independently across training and test runs. Experiments reveal that there is a degree of robustness of performance subject to permutations or other operations and that performance is preserved to a surprising degree when fewer layers are perturbed.\nOverall, I find this paper tackles an interesting problem and does so in a direct and natural manner. One question that could receive more attention is the role of spatial pooling in this process. i.e. to what degree is information naturally abstracted spatially by these networks? In the extreme case, one could imagine all values being pooled and a shuffle having zero effect. This is clearly not the reality, but the interaction of shuffling and pooling seems important to the achieved performance.\nAnother consideration that is worth addressing in more detail is why the performance drops so precipitously when all or almost all the layers are perturbed. It seems that having a few stable layers may be enough but this is a necessary condition for performance to be preserved. Any insight as to why this is so necessary would be a nice touch for readers of this paper."
        }
    ]
}