{
    "Decision": "",
    "Reviews": [
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper proposes new optimization method called NAMSG by combining AMSGRAD and NAS and introducing more parameters. There are two regret bounds in convex and strongly-convex settings and some experimental validation on MNIST and CIFAR compared to various previous methods.\n\nThe purpose of the paper is unclear, and should be rejected. \n\nIf the NAMSG is the next best optimization method for neural nets, then any regret bounds on convex functions is irrelevant, and the authors should focus on rigorous experimental comparisons. Currently it is not clear at all how parameters for each optimization method is set, and that the previous optimization methods were given a fair chance. There is not enough information about the experimental design to convince people that the authors were careful to rule out alternative explanations. For example, it definitely should say how the various hyperparameters are picked in various methods.\n\nOn the other hand, if any of the analysis is novel, it would be good if the author can emphasize it and say what is the innovation in analysis and its significance. Right now it seems that the new parameters are plugged into a standard recipe to derive a very complicated formula, which is not helpful. I am not familiar enough with the area to tell if there is any interesting novelties in the analysis.\n"
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "The authors propose a new training method for learning parameters of NNs, describing a method that combines gradients at different observation points. They also provide theoretical analysis of the convergence of the algorithm.\n\nThe paper is not very readable, and the authors do not help the reader understand and appreciate their work. This is clear from the beginning, where not even the algorithm acronym is explained. This continues throughout the paper, where there is very little sensible explanations. Detailed comments are given below:\n- Please introduce the methods and notation better. There are a number of works that are just thrown out there without proper explanation (e.g., acronyms HB, ASGD, and others are not even explained).\n- Notation could be improved as well, as matrices, scalars, and vectors are all denoted the same now.\n- Algorithm 1 is quite different from the actual text. E.g., where did line 5 appear from, it was never mentioned in the text. This adds to a lot of confusion. Similarly with several other aspects of the method (such as line 8).\n- \"if the vector operations are run by pipelines\", not sure what this refers to.\n- Typos: mu instead of \\mu, stand -> standard, ...\n- The intuition behind the theorems and what they actually tell us should be discussed. Currently they are just given.\n- \"roughly 1 times faster\", so not faster at all?\n- The experiments are also not very convincing. In fact, the proposed method doesn't really outperform the competing method in nearly any experiments. Discussion on what are the added benefits would be welcome.\nPlease note that I am not an expert on the topic (as I indicated below in my self-assessment). However, the paper is nevertheless poorly written, and the empirical evaluation is weak. I am quite interested in seeing other reviews by more qualified researchers."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper tries to present an adaptive first order algorithm called NAMSG. The algorithm is based on the principle of computing stochastic gradients at configurable observation points. Their main novelty as opposed to CNAG is that instead of approximating NAG for exact gradients, it adjusts the learning rates for eigen directions with different curvatures, thus accelerating convergence in the stochastic setting. The authors analyze the algorithm's convergence rate first via a data dependent regret bound for convex functions and provide a O(log(T)) regret bound for strongly convex objectives. They run experiments demonstrating their algorithm is competitive against other adaptive methods such as ADAM. \n\nThe writeup is hard to read. It would benefit from a more concise and intuitive explanation of the proposed algorithm. The approach seems well motivated. It is a noble task to obtain adaptive algorithms with convergence rates. The experiments are on standard MNIST and CIFAR datasets and are conducted vs a variety of other algorithms showing their algorithm performs well in comparison. \n\nMy main concerns are twofold. One, the paper seems to have been written in a hasty way which makes the presentation very hard to follow. It would greatly benefit from a major rewrite, focused on fleshing out the novel / challenging / related work aspects of the work. It isn't clear what is the problem this paper is set to solve that other algorithms don't do well at. The algorithm does perform well in practice. It does seem it has promise. The theory seems correct, and the techniques are standard."
        }
    ]
}