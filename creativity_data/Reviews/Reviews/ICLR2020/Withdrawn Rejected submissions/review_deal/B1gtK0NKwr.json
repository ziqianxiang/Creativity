{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Summary:\nThe assumption behind this paper is that we have access to:\n- A state space, which is essentially a semantic description of the state of the world\n- An observation process, which converts the state space into a visual representation (this is eventually a noisy process)\nWith this, the papers deals with performing verification over specification that gives ground truths corresponding to subsets of the state space.\n\nThe strategy followed is to decompose the input state into tiles, compute bounds on the values that can be taken by the visual representations and then verify using an existing solver that those bounds on the model input lead to the correct prediction.\n\nThe authors propose two toy examples, one imitating a camera taking image of a road and one imitating LIDAR measurements of a sign with one of three predefined shapes\n\nOpinion:\nI think that the contribution of this paper is very limited. \nExisting verification works essentially propagate constraints over the input to obtain bounds on the output of the model. The contribution of this paper is to say that if your specification is over a state space, you should propagate your constraints through the generative model to obtain constraints over the input, and then use existing methods, which is trivial. The problematic lies in being able to do it for complex meaningful generative models. This paper simply circumvents it by having simple enough generative models and handcrafted generation of the bounding box corresponding to subsets of the input space.\n\nI don't think that this paper should be accepted."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The paper starts with a quite promising phrase, namely that the authors present the first method for verification that a neural network produces a correct output for _every_ input of interest. This is quite a strong claim and in its boldness almost comparable to claiming solving NP-hard problems exactly. Reading the paper it turns out that the solution to this problem is similar to solving NP-hard problems (an admittedly slightly provocative comparison I drew here): the instance of the problem needs to be simple enough.\n\nThis is really the main concern I have with this paper: its applicability is so restricted, that I am at loss at finding any suitable problems where it can be applied. Basically, the paper proposes to verify the correctness of neural networks but only trained on problems for which we normally would not use neural works to solve them in the first place.\n\nLack of applicability alone is of course not a ground for rejection, if we get theoretical insights into the problem from a paper. But I am not sure what we can learn from this algorithm scientifically, and I’d like the authors to elaborate on this. What kind of knowledge is gained from the proposed solution to the question of correctness verification? Is there even a roadmap to solving the problem on which this paper made a first step to?\n\nIn a nutshell, the algorithm supposes the existence of a state space underlying the problem, from which the observations are sampled. This is not a rare assumption, as many highly dimensional data are embedded in a much lower dimensional manifold, albeit an unknown one. However, this work requires to (i) provide a known state space which is of sufficiently low dimensions such that a tiling can be performed and all tiles can be processed through an exhaustive algorithm, and (ii), an observation process can be specified which produces observations from the state space. Short, the work requires the specification of a generative model. More importantly, the observation process requires bounded error in order to fulfill the constraint of being able to guarantee that the error for each input simple be lower than a certain threshold. It is easy to see, that even a naïve Bayesian classifier on 1D real input with Gaussian class conditionals does not fulfill these needs, as the Bayes error can never be zero due to the tails of the Gaussian law. The paper proposes verification in probability in this case, but (i) this waters down the message of the paper, which is precisely the claim of correctness verification, and (ii) verification in probabilities for generative models are pretty useless in my opinion, as the underlying estimates for the distributions are, more often than not, quite bad.\n\nThe algorithm itself is very easy and directly follows from the tiling process. As mentioned above, the state space is tiled and bounds are calculated for each tile.\n\nThe evaluation mirrors the remarks on the applicability of the algorithm: it is applied to very simple solutions, where the state can be described by 2 or 3 scalar values (e.g. angles of a camera on a road) and where the observation can be generated by simple laws from the state (e.g. a read consisting of 2 lines without any texture). \n\nThe question is, how this algorithm could be applied to more complex scenes – this is completely left unclear. \n\nLastly, in terms of presentation, I think that section 4 should be rephrased. At the beginning it is unclear what the inputs of the scientific process (described by the paper) are. What are the conditions? Are they assumptions? Are they something to be proved? It becomes clear to the reader later that these are assumptions, but we should not need to guess this.\n\nThere are two theorems, but not proof. Luckily their correctness is pretty evident from the assumptions, but why do we need them then? If a theorem is too simple to proof it, skip it. If it is not simple, provide a proof.\n"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This work presents a method for upper bounding prediction errors of neural networks for perception tasks. The method assumes that the input (and the corresponding output) to the neural network is generated conditioned on one of the many world states. The method proposes to compute ground-truth output intervals for each of the states. Next the method proposes to compute bounding boxes for input regions of the states. Given the input regions and a trained model, the method proposes to estimate output ranges of the network for the states. The method then combines ground-truth output intervals with network output ranges to compute the error bounds. The authors consider two toy problems for empirical analysis.\n\nThe paper is clearly written and easy to follow; however I find the it hard to see how the method can be applied in a realistic scenario. For instance the method assumes the states of the world to be a priori known. Moreover, input and output generation processes g(.) and lambda(.) respectively are taken to be accessible. Since in general we can't expect to have access to data generation processes, I am not sure how the ground-truth output intervals or even input range bounding boxes can be computed. Also, with or without having access to g()/input bounding boxes, how reliably can we estimate the output range of a model (neural network) given that it may be unbounded? I am also not sure why just the output limits are sufficient to compute error bounds. Shouldn't it be based on prediction error? \n\n\nIt would be nice if the authors could also clarify why there method is only specific to neural networks. They should also demonstrate applications of their proposed approach to real benchmarks. "
        }
    ]
}