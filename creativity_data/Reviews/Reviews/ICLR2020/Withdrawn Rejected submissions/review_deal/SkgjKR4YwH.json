{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper builds a connection between MixUp and adversarial training. It introduces untied MixUp (UMixUp), which generalizes the methods of MixUp. Then, it also shows that DAT and UMixUp use the same method of MixUp for generating samples but use different label mixing ratios. Though it has some valuable theoretical contributions, I agree with the reviewers that it’s important to include results on adversarial robustness, where both adversarial training and MixUp are playing an important role.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper introduces directional adversarial training (DAT) and UMixUP, which are extension methods of MixUp. DAT and UMixUp use the same method of MixUp for generating samples but use different label mixing ratios where DAT retains the sample's original label. In contrast, UMixUp uses a function of the input mixing ratio. This paper shows that UMixUp and DAT are equivalent when the number of samples tends to infinity. In the experiments, UMixUp provides an improvement over MixUp.\n\nThis paper should be rejected because the originality of the proposed method over MixUp is marginal, and the improvement of classification accuracy is not surprising, although the explanation of the relationship among DAT, UMixUp, and the original MixUp is nice. The modification of label mixing ratios is not enough contribution. A more precise description of why DAT and UMixUp work better over the original MixUp is required.\n\nThe same idea of MixUp was proposed at the same conference (ICLR2018). It should be cited.\nTokozume et al., Learning from Between-class Examples for Deep Sound Recognition. ICLR, 2018.\nTokozume et al. explain why the mixture of examples works well from the different perspectives of adversarial examples. Also, BC learning uses a KL loss, not a cross-entropy loss. Therefore, the reviewer doubts the following statement: \"MixUp is only applicable to baseline models that use cross entropy loss\" on page 2.\n\nMinor comments\n1) In page 8, \"negative-cosine (CE)\" might be \"negative-cosine　(NC)\"."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes a novel data augmentation method, untied MixUp (UMixUp), which is a general case of both MixUp and Directional Adversarial Traning (DAT). DAT is referred to in this paper as a scheme that only input feature vectors are mixed, while MixUp also incorporates their corresponding labels. The authors provide a theoretical discussion that both DAT and UMixUp converges to be equivalent to each other when the number of training samples becomes infinity. Experimental results on Cifar 10, Cifar 100, MNIST, and Fashion MNIST show quantitative comparisons among the baseline, MixUp, and UMixUp.\n\nAccording to the author guideline,\n> There will be a strict upper limit of 10 pages for the main text. Reviewers will be instructed to apply a higher standard to papers in excess of 8 pages.\nThe authors use nine pages. Therefore, the review should be more careful about its quality.\n\nCurrently, I have three major concerns that keep me from judging this paper acceptable in ICLR 2020.\n\nFirst, the authors failed to cite two closely related papers below:\n- Tokozume et al., LEARNING FROM BETWEEN-CLASS EXAMPLES FOR DEEP SOUND RECOGNITION. ICLR, 2018.\n- Tokozume et al., Between-class Learning for Image Classification. CVPR, 2018.\nThe first one is published in the previous ICLR and mixing two samples belonging to different classes. The second one is an application to image classification using ImageNet dataset, which is larger than the dataset used in this paper.  What's more important is that both papers propose that the mixing ratio of two samples is not linearly but depending on the strength of their signals. Since UMixUp is also focusing on the mixing ratio between two training samples, Between-Class Learning should have been compared to the proposed method.\n\nSecondly, the theoretical discussion is not so fascinating. Actually, both MixUp and UMixUp are shown to converge to DAT when the number of training samples tends to infinity. Data augmentation is, however, performed to remedy the lack of training samples in general. The discussion that the number of training samples is assumed to be large is the opposite situation. \n\nThirdly, the experimental results show that the performance gain by UMixUp is relatively small in comparison to that of the original MixUp. There are no ablation studies using different values for alpha and beta, which are parameters for the policy of UMixUp. The authors reported that these values are defined using a heuristic search. Thus, we cannot see if the performance is sensitive to the parameter selection.\n\nI lean to reject this paper because of these concerns. I'm looking forward to seeing the revised version in another conference."
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "First of all, the concept of 'Directional Adversarial Training (DAT)' is not appropriate. Actually similar method has been proposed in Hiroshi Inoue (2018) as a data augmentation method.\n\nWhat surprised me the most is that after trying to connect UMixUp with adversarial training in the whole paper, there is no evaluation of adversarial robustness in the experiments? The main character of adversarial training is an improvement in robustness and degeneration on clean accuracy, which is different from the performance of UMixup or Mixup.  \n\nThe authors should do a major modification on their motivation and experiments before the paper is able to be published.\n\nReference:\n[1] Hiroshi Inoue. Data Augmentation by Pairing Samples for Images Classification. arXiv 1801.02929\n"
        }
    ]
}