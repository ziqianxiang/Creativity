{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper has been reviewed by three reviewers and received scores such as 3/3/6. The reviewers took into account the rebuttal in their final verdict. The major criticism concerned the somewhat ad-hoc notion of interpretability, the analysis of vanishing/exploding gradients in  TPRU is experimental lacking theory. Finally,  all reviewers noted the paper is difficult to read and contains grammar issues etc. which does not help. On balance, we regret that this paper cannot be accepted to ICLR2020.\n\n",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes a novel model of recurrent unit for RNNs which is inspired from tensor product representation (TPR) introduced by Smolensky et al. in 1990. The authors claim that this allows one to better incorporate structural information into learning and easier interpretability for the learned representations. The proposed approach is motivated by a theoretical analysis showing that using TPR in this context acts as a sort of pre-conditioner and stabilizes learning. Experiments on entailment tasks (given two statement, decide whether the first implies the second) are provided to validate the approach. \n\nI find the paper not easy to follow, with a non-negligible amount of typos in the notations and results. The advantage in terms of accuracy of the proposed approach seems marginal in the experiment, and the analysis of the interpretability of the learned representations could be improved: loosely speaking, particular examples of interpretability are given but sometimes without contexts or baselines to compare to (see the two last comments below). I know \"interpretability\" is a difficult property to assess but I think there may be more principled ways to showcase the approach.\n\nI think this paper is not yet ready for publication: the proposed model is interesting and relevant but its validity could be better assessed and the paper needs some thorough proof-reading. \n\n\n* Questions / Comments *\n\n- page 1: the authors write U^TR = I, but I believe this is only possible if the TPR dimension d is bigger than the number of roles N. Is this always the case? This should be clarified.\n- related to the previous point:  if U^TR = I then shouldn't U^Tb_{t-1} simply be f_{t-1} in Eq. 1?\n- before Eq.1, f should be from R^d\\times R^d' to R^d, not from R^d \\times R^d\n- In Eq. 1, b_{t-1} and x_t are not of the same dimension, so the cannot be multiplied by the same matrix U (this is why the matrices V_x and V_b are introduced later on).\n- there seems to be a problem with Eq. (7): db_t/d_{b_{t-1}} appears on both sides of the equality...\n- Modification 1: what is \\tilde{vb_t}? I don't remember seeing this notation introduced before.\n- Table 1: constants should not be included in big O notation! To compare constants, one should give the exact number of operations needed for inference.\n- POS tagging: Aren't there many other reasons that could lead to this correlation (beside the informal argument that \"TPR captures structured information\")? Maybe the authors should compare with something else, for example the PMI between values of hidden neurons in a learned RNN and POS tags. Out of context, the numbers in Table 5 are not informative.\n- Polysemy: Only a very specific cherry picked example is given here. A more principled or in depth analysis of this phenomenon is needed to make a stronger case.\n\n* Typos *\n\n- \" The number of parameter matrices *is* the same as that of...\"\n- page 4 \"stables\" -> \"stabilizes\" (but rephrasing the sentence altogether would be better).\n- page 5: BiDAF misses the capital letters (\"bidaf\").\n- \"dev set\" -> \"validation set\" or \"development set\".\n- page 8: \"provides research*ers with* an intuitive...\"?\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "N/A",
            "review": "In this paper, a new unit based on the outer product called TPRU is proposed for recurrent neural networks. The performance of TPRU is validated with several NLP tasks such as POS tagging. \n\nWhile my knowledge about RNNs is limited, I feel the paper has room for improvement and I vote for rejection this time. The main reasons are: 1. the paper is not well written, and 2. the way of analysis is not enough.\n\n1. From the viewpoint of an RNN non-expert (i.e., me), the paper somehow fails to introduce the background. For example, tensor product representation (TPR) is introduced in the second paragraph of Introduction. While TPR is an elemental idea of this study, it is introduced with neither motivation (why and when TPR is useful, etc) nor appropriate references, which makes non-experts difficult to catch up with the main body of this study. So the paper is not self-contained enough. \n\n2-1. The paper tries to explain why TPRU is better in terms of gradient vanishing/explosion in Section 4. However, the analysis is mainly performed in a qualitative way, and there is no quantitative analysis of it. For example, I expect something like the evaluation of the magnitude of the gradient, e.g., how much degree the gradient scale is reduced from normal gate to the TPRU gate. Or, at least there should be the numerical experiments for the comparison. Otherwise, it is hard to judge whether the gradient is actually stabilized.\n\n2-2. The paper says one of the advantages of using TPRU is in its interpretability. However, the term \"interpretability\" is very vague and it is not properly defined in this paper. The paper should discuss what is the metric of interpretability here. More specifically, the paper claims TPRU's interpretability by Table 5. It looks, however, improper because there is no baseline and we cannot conclude that TPRU has better interpretability than others."
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "This paper proposes a new recurrent unit with a simplified dynamics during training leading to more stable training algorithms and better performance. The paper is difficult to read because it assumes the reader is an expert on Tensor Product Representations. Many important terms are not clearly defined, which makes difficult to follow. For example, the terms “roles” and “filler” are not defined. I think a quick introduction to the field with a clarifying figure would be greatly appreciated by general readers. However, I think the contribution of the paper is important and presented experimental results, comparing the method against classical LSTM and GRU architectures, seem to be relevant for the field.\n\n\n\n\n\n"
        }
    ]
}