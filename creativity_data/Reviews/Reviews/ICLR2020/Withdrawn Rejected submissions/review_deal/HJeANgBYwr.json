{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper proposes a graph neural network based approach for scaling up imitation learning (e.g., of swarm behaviors). Reviewers noted key limitations in the discussion of related work, size of the proposed contribution in terms of model novelty, and evaluation / comparison to strong baselines. Reviewers appreciated the author replies which resolved some concerns but agree that the paper is overall not ready for publication.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The authors have proposed a GNN implementation that predicts and imitates the motion behaviors from observed swarm trajectory data. I have the following major comments on the paper:\n1. I think the authors should discuss more on the related works. They should clearly mention their contributions and difference compared to the prior works.\n2. What do the authors mean by 'functions universal across all nodes and edges'? Are these same functions for all nodes and edges?\n3. I feel that the section 2.3 explaining 1D convolutions is slightly separated from the previous and following sections.\n4. Why does the proposed GNN model performs better than Kipf's GNN for predicting and imitating the motion behaviors? What is the component that makes the difference?\n5. How does the model depend on the history window length T_w? Also I am curious how does the model depend on the number of GNN layers used?\n6. I am not quite satisfied with provided experimental evaluation of the paper. It is not clear to me why Kipf's GNN does not perform better than the proposed model (which simply aggregates the edge states). Also it would be interesting to try some other GNN models, such as ClusterGCN, GCI etc.\n7. Also I want to see a fair comparison in the paper. If the main contribution is a GNN model, then the model should be compared with the recent GNN models, and if the main contribution is predicting the motion behavior from observed swarm trajectory data, it should be compared with MAS based approaches. While reading the paper, it appeared to me that the authors proposed a graph-based method for solving MAS task and they compared with an old GNN method, which is not justified.\nI also have some minor comments as follows:\n1. In page 1, \"re-finement\" should be \"refinement\"\n2. In page 3, \"... my be found in Battaglia ...\" my should be may.\n3. In page 4, \"... sample rate is affects ...\" should be \"... sample rate affects ...\"\n4. In page 6, \"... a agent ...\" should be \"... an agent ...\"\n5. In page 7, \"... swarms of with larger ...\" either of or with\n6. In page 8, Table 3 ending parenthesis is missing. "
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This work considers sequence prediction problems in a multi-agent system (MAS), which I think is different from imitation learning problems where agents try to mimic experts’ behavior given histories or states. In that sense, I think the title of this work should be changed so that readers are not confused. \n\nThe main idea of this work is to use (1) graph neural networks (GNNs) to learn the abstract information among multiple agents, (2) use 1D convolution to extract historical features of each agent, (3) and minimize the MSE loss function between true and predicted states to make expected successor states of multiple agents more accurate. The experiments show training in a small number of agents can be generalized and transferred to the setting in which there is a large number of agents. \n\nAlthough the proposed algorithm is practically useful, I believe the submission is premature to be accepted at a conference due to (1) the lack of comparison with existing works on multi-agent (reinforcement and imitation) learning and (2) the lack of novelty (It seems that the proposed method simply combines existing neural networks and applies it to multi-agent behavior prediction.). There’s a huge recent development on multi-agent RL and IL regarding the scalability of MARL (MF-MARL, https://arxiv.org/pdf/1802.05438.pdf), coordinated multi-agent imitation learning (https://arxiv.org/abs/1703.03121), multi-agent GAIL (https://arxiv.org/abs/1807.09936), etc, which should be considered as related literature. In addition to them, there’s a paper on arXiv that uses GNN for MARL (https://arxiv.org/abs/1810.09202), which may be deeply related to this work as well. \n\nI’ll definitely increase my score if I underestimate the quality of this work. "
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "N/A",
            "review": "Review for \"Towards Scalable Imitation Learning For Multi-Agent Systems with Graph Neural Networks\".\n\nThe paper proposes a new time series model for learning a sequence of graphs. \n\nI vote to reject the paper for three reasons.\n\n1. Lack of significance. Algorithm 1 is essentially supervised learning of an autoregressive model with a GNN. The GNN definition is expanded out in the pseudocode, but seems to be completely standard. Moreover, Section 2.5 is also completely standard - you are using a sum of standard MSE losses. It should be much more concise. Also, there is typically no point scaling the loss by D if you use Adam (because the scaling they will eventually cancel out).\n\n2. Poor awareness of prior work. What you call \"scalability issue caused by poor extrapolation\" is normally called poor generalization. Improving generalization is an established problem in ML. You should cite some of that work. See [1] and follow the references.\n\n3. Poor experimental evaluation. Your experiments show that the competing GNN method (what you call Kipf's GNN) didn't converge in certain settings. Robust GNN implementations exist that converge for a wide range of reasonable graphs. You should have used one of them.\n\nAs things stand, because the criticisms concern the core of the submission, I have doubts the quality of the paper can be improved enough within the ICLR revision time to obtain an \"accept\" score. However, I wanted to encourage you not to give up. The building blocks that you have in the paper are very relevant and can be a basis for impactful work. You also write well (despite some minor issues). I hope these skills will help you make great submissions in the future!\n\nMinor points:\n1. I would not call what the paper is doing \"imitation learning\". Imitation learning normally means you have a controllable system and want to learn a policy from expert demonstrations. What this paper does is commonly referred to as learning an autoregressive time series model. \n2. Avoid colorful language. For example, the sentence: \"the apparent resemblance of the corrected distributions in the final output may inspire an inductive bias as part of training objective\" is unclear. \n\n[1] https://papers.nips.cc/paper/7176-exploring-generalization-in-deep-learning.pdf"
        }
    ]
}