{
    "Decision": {
        "decision": "Reject",
        "comment": "Evolutionary strategies are a popular class of method for black-box gradient-free optimization and involve iteratively fitting a distribution from which to sample promising input candidates to evaluate.  CMA-ES involves fitting a Gaussian distribution and has achieved state-of-the-art performance on a variety of black-box optimization benchmarks when the underlying function is cheap to evaluate.  In this work the authors replace this distribution instead with a much more flexible deep generative model (i.e. NICE). They demonstrate empirically that this method is effective on a number of synthetic global optimization benchmarks (e.g. Rosenbrock) and three direct policy search reinforcement learning problems.  The reviewers all believe the paper is above borderline for acceptance.  However, two of the reviewers said they were on the low end of their respective scores (i.e. one wanted to give a 5 instead of a 6 and another a 7 instead of 8.)  A major issue among the reviewers was the experiments, which they noted were simple and not very convincing (with one reviewer disagreeing).  The synthetic global optimization problems do seem somewhat simple.  In the RL problems, it's not obvious that the proposed method is statistically significantly better, i.e. the error bars are overlapping considerably.   Thus the recommendation is to reject.  Hopefully stronger experiments and incorporating the reviewer comments in the manuscript will make this a stronger paper for a future conference.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "Summary:\n\nAs the title of the paper states, this paper tries to improve evolution strategies (ES) using a generative neural network. In the standard ES candidate solution is generated from a multivariate normal distribution, where the parameters of the distribution are adapted during the optimization process. The authors claim that the gaussian distribution, i.e., the ellipsoidal shape of the sampling distribution, is not adequate for the objective functions such as multimodal functions or functions with curved ridge levelsets such as the well-known Rosenbrock functions. The motivation is clearly stated. The technique is interesting and non-trivial. However, the experimental results are not very convincing to conclude that the proposed approach achieves the stated goal. Moreover, this paper may fit more to optimization conferences such as GECCO. \n\nBecause of the empirical results, I would rate this paper as the border line (around 5), but due to the slightly annoying rating system the rate appears as 6. \n\nComments:\n\nP2: \"Efficient Natural Evolutionary Strategies (xNES) (Sun et al., 2009) has been shown to reach state- of-the-art performances on a large ES benchmark.\" \n\nThis algorithm is \"eNES\" and  this algorithm is not competitive with the state-of-the-art ES such as CMA-ES. The authors might want to refer to exponential NES, which is xNES, proposed by Glasmachers et al 2010.\n\nP5: \"Indeed, other bijective GNN models like the Real-NVP (Dinh et al., 2016) introduce non-volume preserving transformations, which can easily overfit and lead to premature concentration and convergence.\" Has it been reported in a reference? If so provide the reference. If not, the authors should state that it has been observed the authors preliminary study. In any case, I think it depends how the model is used or trained, and this statement itself is not universally true.\n\nP7: \"By using fη instead of gη as the push-forward map of the NICE model, we ensure that the flexibility brought by the GNN only impacts the tails of the search distribution. As detailed in an ablation study presented in Appendix F, this additional tool turns out to be essential in order to use GNNs for ES.\"\n\nI barely understood this point. Please make is clearer.\n\nP8: Experimental results are not very convincing. The experiments are limited to dimension 2, 5, 10 and only a few functions are selected from the BBOB test function suite. How about on 20D? What happens if the target is 1e-8, which is the default setting in BBOB? \n\nFigure 3 looks interesting, and this is what the authors are trying to achieve. Therefore, it looks like the authors reached the stated objective. However, this is only 2D. No results are provided to convince that the proposed strategy achieved the stated objective. \n\nFigure 4  simply looks that the proposed algorithm failed to reach the \"flexibility\" stated in Section 2: \"Another limitation of classical search distribution is their inability to follow multiple hypothesis, that is to explore at the same time different local minima. Even if mixture models can show such flexibility, hyper-parameters like the number of mixtures have optimal values that are impossible to guess a priori.\"\n\nFrom these results, I am not convinced that the proposed strategy really achieved more flexible distribution than the classical methods, and whether the flexibility contributes to improve the performance. \n\nAnother critical point to be discussed is its usefulness. Since this algorithm is proposed to \"improve evolution strategy\" as a black-box optimizer (not for specific tasks), I expect to improve the state-of-the-art performance. Are the reported results outperform the CMA-ES? Based on Glasmachers et al (2010), xNES tends to require more objective function evaluations than CMA-ES, especially for higher dimensional cases. I am curious to know if the proposed approach outperforms the CMA-ES on Rosenbrock functions. \n\n"
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "Summary: In ES the goal is to find a distribution pi_theta(x) such that the expected value of f(x) under this distribution is high. This can be optimized with REINFORCE or with more sophisticated methods based on the natural gradient. The functional form of pi_theta is almost always a Gaussian, but this isn't sufficiently flexible (e.g. multi-modal) to provide a good optimization algorithm. In response, the authors advocate for using a flexible family of generative neural networks for pi_theta. Using NICE as a generative model is desirable because it maintains volumes. This means that we can adjust volumes in latent space and this directly corresponds to volumes in x space. Doing so is useful to be able to tune how concentrated the search distribution is and to explicitly reason about the mode of the search distribution.\n\nOverall, I found that there were a number of technical details that were well motivated, such as how to leverage the 'mode preservation' of NICE, how to use importance sampling to be able to use samples from multiple rounds of optimization when updating theta and the fact that any existing ES algorithm can be used to do the optimization in the latent space. \n\n\n\n\"We found that the PGES algorithm (naive stochastic gradient descent of (8) with the score-function estimator) applied to the NICE distribution suffers from the same limitations as when applied to the Gaussian; it is inable to precisely locate any local minimum.\" \n   I don't understand this. Can't the Gaussian become very concentrated?\n \nYou write: \"ES implicitly balance the need for exploration and exploitation of the optimization landscape. The exploitation phase consists in updating the search distribution, and exploration happens when samples are drawn from the search distribution’s tails.\"\nThis is a weak form of exploration, since there is no explicit mechanism that encourages f(x) to be evaluated at regions that it has never been evaluated on before. The search distribution's tails will have low probability mass, so exploration unlikely. Your proposed method uses a pi(x) that is flexible enough to represent multi-modal distributions. However, how can you ensure that your search procedure actually uses this flexibility? In other words, how is your proposed method any better at exploration that the baseline ES method?\n\nIt would be great to have a slightly more detailed alg. box in the main text for your proposed method, instead of having it in the appendix. Some details I found confusing, such as whether you perform one step of alternating optimization per call to f(x) or if you perform many steps of alternating optimization.\n\nYour \"Mode preserving properties\" trick is cool. However, I don't fully understand how it is used. Surely you need to be able to be able to change the mode of the distribution some time? Do you only use the mode preservation trick at certain optimization steps? Again, incorporating this in the alg box would be helpful.\n\nIn the results, I was disappointed that you required restart strategies. I thought that one of the key advantages of using NICE was that you could capture a multi-modal search distribution. Can you explain?\n\n What do you mean by the 'global volume of the distribution?' What is the volume of a distribution? I understand what concept you're trying to convey, but can you be more precise?\n"
        },
        {
            "rating": "8: Accept",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "Review of “Improving Evolutionary Strategies with Generative Neural Networks”\n\nTypically in ES, the distribution of solution candidates come from a hand-engineered distribution (i.e. multivariate Gaussian, or other parametrized distributions). In place of hand-engineered distribution choices, they introduce the use of GANs as a tool for Evolution Strategies. I liked the novelty of combining the use of GANs in new directions (namely ES/GA).\n\nThe core idea is to model the density function using Generative Neural Networks (GNN, MacKay 1995), and find the parameters of this GNN using tools from the normalizing flows literature for their NICE invertible properties (okay pun intended :) along with GAN-style training using historical data from the ES process.\n\nThey demonstrate their method on traditional blackbox optimization toy tasks (such as Rosenbrok and Rastrigin functions), and also on a few continuous control RL benchmark tasks, to demonstrate improved performance over a strong representative ES algorithm (XNES).\n\nOverall, I liked the work as it provides a fresh way of using GANs with another subfield (ES/GA). If they want to improve the work, I would suggest demonstrating that their approach can solve certain difficult tasks that traditional ES methods (or RL methods) cannot solve. Although the experiments chosen are not difficult ones, I believe they were chosen for clarity to showcase the method, so I think that is fine (in case there are complaints that they experiments are too simple).\n\n(For the record, I was looking to give a score of 7, but the ICLR system made me choose between 6 and 8, and I chose 8.)"
        }
    ]
}