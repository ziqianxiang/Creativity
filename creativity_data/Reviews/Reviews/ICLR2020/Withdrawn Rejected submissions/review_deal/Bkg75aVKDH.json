{
    "Decision": {
        "decision": "Reject",
        "comment": "The authors develop a new technique for training neural networks to be provably robust to adversarial attacks. The technique relies on constructing a polyhedral envelope on the feasible set of activations and using this to derive a lower bound on the maximum certified radius. By training with this as a regularizer, the authors are able to train neural networks that achieve strong provable robustness to adversarial attacks.\n\nThe paper makes a number of interesting contributions that the reviewers appreciated. However, two of the reviewers had some concerns with the significance of the contributions made:\n1) The contributions of the paper are not clearly defined relative to prior work on bound propagation (Fast-Lin/KW/CROWN). In particular, the authors simply use the linear approximation derived in these prior works to obtain a bound on the radius to be certified. The authors claim faster convergence based on this, but this does not seem like a very significant contribution.\n\n2) The improvements on the state of the art are marginal.\n\nThese were discussed in detail during the rebuttal phase and the two reviewers with concerns about the paper decided to maintain their score after reading the rebuttals, as the fundamental issues above were not \n\nGiven these concerns, I believe this paper is borderline - it has some interesting contributions, but the overall novelty on the technical side and strength of empirical results is not very high.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #4",
            "review": "The paper proposes an approach for computing more refined estimates of robustness in comparison w/ existing linear approximation approaches that only give a yes or no answer with regard to robustness guarantees for a given lp-norm ball with radius epsilon. The nice thing is that as the linear-approximations get better, the contributions in this paper would continue to help. \n\nThe paper makes two key algorithmic/theoretical contributions:\n1. An approach to obtain a better estimate of the radius of the l-p ball where the NN is provably robust. This result is fairly straightforward, and relies on computing the distance of a point to the boundary of adversarial polytope.\n\n2. An approach to exploit the fact that the pixel values are restricted to specific bounds, which might allow us trim away some regions from the l-p norm balls around a given input image w.r.t which we want to be robust, while computing the robustness. This I think is a more interesting contribution. \n\n\nI am leaning towards a reject, however I am open to changing my score. I have several key concerns:\n\n1. Verified Training: Why is there no comparison with IBP and IBP+Crown (Zhang 2019) -- it seems like an appropriate comparison to make. Particularly, when the current paper refers and discusses both of the above works. \n\n2. I am not sure that comparison with CRO entirely suffices in my opinion. Would it be possible to compare with the tighter SDP based approaches (Raghunathan et al., NeurIPS'19 and Dvijotham et al., UAI'19)? Is there a specific reason to not compare (other than that the SDP based approach is not a linear approximation, and probably is much slower)? \n\nMy main concern here is the utility of pushing boundaries with the linear approximation, while there are potentially tighter relaxations?\n\n3. You claim no overhead compared to CROWN. Don't the greedy-optimization steps add some overhead, or am I missing something? How expensive are they? (It's possible I might have missed some discussion in this regard. If so, please point me in the right direction and that should suffice)\n\n4. Can you plot the distributions of the certified epsilon? Are there a few samples for which you can certify a much larger epsilon (than just saying not robust) or are there a lot of samples where you can only show a tiny bit of robustness (compared to CROWN saying not robust)? \n\nThe gains in the average robustness are somewhat small, and these gains alone are not convincing without being able to see how these gains were obtained. \n\nMinor Comment:\nMissing reference to MixTrain for B' < B helps. \n\nUpdate:\nThanks for the detailed response!\n\n1. This makes sense, the first bit seems obvious --> if you don't train with IBP, you won't get much out of IBP and this is reasonably well known. \n\nTable 5: When trained with IBP and verifying with IBP, it seems to do better or quite comparable to train/verify with PER --- in this sense, the gains seem quite marginal.\n\n2. Since a part of the contribution claimed in this paper is improved robustness guarantees for pre-trained networks, I do feel that comparisons with the UAI'19 paper or the NeurIPS'18 paper would be nice -- however, I do agree that the computational tractability of KW/FastLin/IBP are much more favorable.\n\n3. Thanks -- it is much more clear now.\n\n4. The distributions for MMR/PER seem quite similar and most of the gain seems to come at the lower end (small eps). \nThis still remains my biggest concern -- I was hoping that the distributions would diverge a bit more at larger eps, but this is difficult to confirm with the current set of plots.\n\nThese plots, as of the current version, are not very useful -- a CDF plot as opposed to a histogram would be much more illustrative in terms of comparing the different approaches. Overlaying them with different opacity might also be useful. \n\nI am still leaning towards a weak reject. I am not sure how the scoring system works, the scores are distributed unevenly -- I would judge this a 5 on the 1-10 scale. However, going by the wording, I will stay with a 3.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper proposes a certifiable NN training method, \"polyhedral envelope\nregularization\" (PER) for defending against adversarial examples.  The defense\nis based on the same linear relaxation based outer bounds of neural networks\n(KW/CROWN) used in many previous works.  The paper makes a few new (but small)\ntechnical contributions:\n\n1. this paper uses a different loss function (7), which is essentially Hinge\nloss on the lower bounds of distance to decision boundary. Previous works like\nKW used cross-entropy loss on the lower bound of prediction margin instead,\nwhich was based on minimax robust optimization theory. But I am not fully\nconvinced if the new loss function is better or not.\n\n2. in (5), the authors solve the bounded input case more carefully than\nprevious works.  (5) is trivial to solve in the L infinity case and has been\nused in previous works like (Wong & Kolter 2018, Gowal et al., 2018 and Zhang\net al., 2019); but solving it for other norms requires some efforts, and this\npaper proposes a good solution for it (Algorithm 2);\n\n3. In previous works like KW/CROWN, to find the largest certifiable radius, a\nbinary search is needed. The authors proposes a very small improvement to the\nbinary search process by setting the lower bound of search to the largest\nepsilon that is certifiable using the current linear relaxations obtained from\na larger epsilon.\n\nThe authors does not improve any bounds proposed in KW/CROWN, and they reuse\nthe same bounds. I see the main contribution as the new hinge-like loss\nfunction for training, and a more careful procedure to find the largest\ncertifiable radius in bounded input case.\n\nEmpirically, the improvement of the proposed algorithm is limited - based on\nTable 1 it is hard to say if PER is better than KW or not. PER+at outperforms\nKW sometimes, however it is not a completely fair comparison, as we can add a\nPGD based adversarial training loss to KW as well, as done in DiffAI (Mirman et\nal., https://github.com/eth-sri/diffai).\n\nQuestions:\n\n1. In my personal experience I usually found Hinge loss not as effective as\ncross-entropy loss in deep learning based tasks probably due to its\nnon-smoothness. The claim that (7) is better than cross-entropy loss is that it\ndoes not overregularize the network. The authors should provide more evidence\nto show if this argument holds, e.g., plotting the norm of weight matrices\nduring the training for the two losses to show that it can reduce\noverregularization.\n\n2. I think the metric ACB KW and ACB CRO (average certified radius of KW/CROWN)\nin Table 1 and 2 are confusing and not fair. In KW and CROWN's evaluation,\ngiving an epsilon, if an example cannot be certified due to epsilon to large\n(i.e., ||A|| \\epsilon + b > 0), certifiable radius will be count as 0 (flat\nline in Figure 1(a)). In this paper, the authors instead in this case use -b /\n||A|| as the certifiable radius. This is merely a different way of evaluation,\nand I don't see this as a contribution, as the \"improvement\" does not come from\na tighter bound.  In the same sense, I don't think Figure 1(a) and the\ndiscussions on page 3 are appropriate characterization of KW/CROWN. PEC uses\nexactly the same linear bounds as in KW/CROWN, and has the same certification\npower.\n\n3. For L2 based perturbations, in Table 1, the epsilon used for MNIST is too\nsmall. It is better to use an epsilon that is aligned with previous works. For\nexample in Wong et al., 2018 (https://arxiv.org/pdf/1805.12514.pdf), page 22,\nyou will find the epsilon used for MNIST and CIFAR.\n\n4. As discussed above, it is probably not fair to compare PER+at with KW. A new\nbaseline like KW+at should also be considered.\n\n5. For norms other than L infinity norms, solving (5) for getting $d$ can be\ntime consuming (Algorithm 2). How much additional time does it comparing\nto KW?\n\nOverall, I cannot recommend accepting this paper due to its limited theoretical\ncontribution as well as unconvincing empirical results comparing to previous\nmethods. I suggest rephrasing some parts of the paper and providing more\nexperimental results as discussed above.\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "Summary:\nThere exists several method (KW, Crown, zonotope transformers) which essentially propagate linear lower and upper bound through the network (bounds is a linear function of the input variables). So far, to check for robustness, these methods propagated the bounds until the last layer (+ margin computation) and then concretized them and compared the result to zero to see if the studied radius was safe or not. This paper highlights the fact that in the case where the studied radius is not safe, it is possible to extract a safe radius from the linear bound.\n\nThe authors then show that:\n-> this can be used to make binary search to find the larger verifiable epsilon faster (by providing a lower bound on epsilon even when failing to verify, rather than simply when succeeding verification)\n-> this can be employed during the training process to improve regularization, similarly to another previously proposed method (Croce et al.). While the methods are similar, the bounds are much less conservative than Croce's one and should therefore be more helpful\n\nThe presentation of the content is quite clear, and Figure 1.a is extremely useful in conveying the benefits of the method.\n\nExperimental validation is thorough:\n-> Comparing the ACB KW and ACB PEC columns in Table 1 and 2, for all type of activation functions, shows that this is as expected a strict improvement in the generated bound.\n-> Comparing the various rows in Table 1 shows the improvement with regards to other methods, both in terms of clean accuracy (this produces less over-regularization), while maintaining similar or better robust accuracy.\n-> Table 6 shows the benefit in the application to binary search.\n\nOpinion:\nThis paper is clearly written and I think that it's an interesting insight and that the authors do a good job at conveying its usefulness. I'm happy for this paper to be accepted.\n\n"
        }
    ]
}