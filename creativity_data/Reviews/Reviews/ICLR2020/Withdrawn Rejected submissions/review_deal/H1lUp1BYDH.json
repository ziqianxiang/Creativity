{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Summary: This paper aims to ease network congestion and enable more efficient flow in systems like traffic, supply chains and electrical grids. They apply Multi-Agent Reinforcement Learning (MARL) to such problems by considering each vertex in the network as an agent. Instead of assuming the agents are independent like most MARL-based models, the authors propose a framework that induces cooperation and coordination amongst agents, connected via an underlying network. The network is learned via emergent communication in a MARL-based setup. Experimentally, they demonstrate the utility of communication in networks of traffic systems.\n\nStrengths:\n- This work is nicely written. I like how communication and RL can be used in this interesting setup.\n- The experimental results seem plausible and show some improvement over existing methods that do not explicitly model communication.\n\nWeaknesses:\n- In Figure 4, why does a DQN start off so much higher in rewards as compared to your method?\n- In Figure 5, why does having 1 blind agent make almost no difference and still achieve as strong performance as the full model?\n- Why does 'communication' have to be used in this setting, instead of other graph-based methods that take information from a node's neighbors and make a holistic prediction on the whole graph? It was not completely clear if there was imperfect information between agents, which makes communication crucial. If there was complete information about each agent then communication would not be needed.\n- Could the authors comment on how the complexity would increase with more agents? Would it still be feasible? "
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The paper proposes a framework for communication in networks by formulating the problem as MARL-based setup. Agents in the network can communicate with their neighbors to share their local observations which leads to overall better performance in partially observable scenarios. The paper then shows results on SUMO traffic simulator which suggest that networks with communication outperform the ones without it. The paper further shows that in these networks individual groups emerge which coordinate with each other to achieve a common goal.\n\nThe paper hasn’t been situated properly with respect to prior work. Similar concepts have been tested in Graph Attention Networks [1], Interaction Networks [6] and VAIN [2] papers. In [1], the value of each network is attended sum of neighbors’ hidden state. The networks based on continuous communication can be easily converted to discrete ones through Gumbel Softmax. So, due to concerns around novelty and limited experiments only on traffic junction with some critical details missing, I would give initial rating of reject. I post my other concerns and feedback below:\n\nPaper claims Sukhbaatar et. al. 2017 [3] as concurrent work which was published in 2017. [1] has further two derivative works Singh et. al. 2018 [4] and Das et. al. 2017 [5] which need to be compared against as well. On the difference from [3] as mentioned in the paper, in [3, 4, 5], (i) agents can be easily converted to be traffic lights instead of cars. (ii) continuous communication can be converted into discrete using Gumbel Softmax (iii) every agent can communicate to every other agent. The paper essentially contributes results on what happens when the agents are in network topology instead of open communication so (iii) point needs to be framed better. It would be interesting and informative to see how the paper’s model compare against [3, 4, 5] in open communication setting (it may be an upper bound). As mentioned above, proper differences from [1] and [2] also need to be mentioned.\n\nPaper is also missing experiments on scalability of this approach. Does the approach scale well as agents in the network increase? It would be helpful to know (i) the generalization of this approach by testing on different configuration at test time (ii) if the approach works well on task other than traffic control like network packet routing (iii) How well the approach scales as the number of agents increase.\n\nWhat is the value of beta used for reward function? And paper doesn’t comment on how does the performance get affected by value beta as it goes from 0 (individual rewards) [4] to 1 (global rewards) [3]. Also, what is the composition of the factors mentioned in reward structure at page 5. Having the exact equation in paper would be helpful.\n\n\nIf the paper can provide the following details, it would help on its readability and my understanding. \n(i) For easily comparing different baseline, a table should be added with the final rewards.\n(ii) What are the architectural details of the CNN used in image encoder and the RNN used in accumulator. What are the values of other hyperparameters?\n(iii) How exactly the model has been trained? \n(iv) Why does 1 blind agent network converges faster and higher initially even though there is a missing observation?\n(v) The paper claims at many points that global rewards help but have they tried with individual rewards? As [4] suggest, individual rewards converge faster and higher than global rewards it might be worth exploring this.\n\n[1] Veličković, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. \"Graph attention networks.\" arXiv preprint arXiv:1710.10903 (2017).\n[2] Hoshen, Yedid. \"Vain: Attentional multi-agent predictive modeling.\" In Advances in Neural Information Processing Systems, pp. 2701-2711. 2017.\n[3] Sukhbaatar, Sainbayar, and Rob Fergus. \"Learning multiagent communication with backpropagation.\" In Advances in Neural Information Processing Systems, pp. 2244-2252. 2016.\n[4] Singh, Amanpreet, Tushar Jain, and Sainbayar Sukhbaatar. \"Learning when to communicate at scale in multiagent cooperative and competitive tasks.\" arXiv preprint arXiv:1812.09755 (2018).\n[5] Das, Abhishek, Théophile Gervet, Joshua Romoff, Dhruv Batra, Devi Parikh, Michael Rabbat, and Joelle Pineau. \"Tarmac: Targeted multi-agent communication.\" arXiv preprint arXiv:1810.11187 (2018).\n[6] Battaglia, Peter, Razvan Pascanu, Matthew Lai, and Danilo Jimenez Rezende. \"Interaction networks for learning about objects, relations and physics.\" In Advances in neural information processing systems, pp. 4502-4510. 2016.\n"
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This work explores a multi-agent communication setting, building on a recent framework (MARL) to assess the feasibility of an approach that uses discretized messages and a soft-attention based communication medium. The domain is traffic flow management, using the SUMO traffic simulator.\n\nThe multi-agent setup is constructed by treating each traffic junction as a node in a graph. Thus, each node is restricted in who it can send a message to, and who it can receive a message from, which is dissimilar from previous approaches that employed all-to-all connectivity. The results show a nice improvement over baselines, which include fixed-time controllers, DQN, and other heuristic-based solutions. \n\nA quite interesting result is the performance of the DQN model, which uses no communication at all. This result has me wondering how another version of this model would do, particularly one that receives not only visual input for its junction, but the inputs from its neighbors. One can imagine this as each agent communicating its full state information to its neighbors. I understand the authors are exploring emergent communication protocols, but this model might be another strong baseline against which to measure.\n\nIf the authors could address the following questions and comments, it would be appreciated:\n\nHow is this method expected to scale? I suppose like other multi-agent work, if each agent has its own unique parameters then training can quickly become infeasible as the number of nodes grows. On the other hand, if nodes share parameters, then one can imagine subsampling smaller graphs and training in batch on these.\n“Emergent communication”, as the title suggests, isn’t exactly what’s happening here since communication is built into the structure of the algorithm. An emergent communication *protocol* is more accurate.\nIs there some notion of directionality of message? You can imagine, for example, a situation requiring the flow of traffic to increase in the North direction for multiple nodes because of traffic backup, but *not* wanting adjacent Southern nodes to send even more traffic North because of the congestion. This would require sending one message to Northern nodes to increase northwards flow, and another message to Southern nodes to decrease northward flow. If there is no directionality of message, do you see this as a problem? If so, how would you propose to fix it?\n\nAltogether this work is nicely presented, and the inclusion of a number of baselines is commended. I’m assigning a “weak reject” rating because I am not sure it surpasses the bar of acceptance, in particular in regards to significant deviation over prior approaches and importance of results. But I look forward to the subsequent discussions, and will note that this rating is flexible.\n"
        }
    ]
}