{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper proposes learning a latent embedding for image manipulation for PixelCNN by using Fisher scores projected to a low-dimensional space.\nThe reviewers have several concerns about this paper:\n* Novelty\n* Random projection doesn’t learn useful representation\n* Weak evaluations\nSince two expert reviewers are negative about this paper, I cannot recommend acceptance at this stage.\n",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This work proposes to learn a latent space for the PixelCNN by first computing the Fisher score of the PixelCNN model and then projecting it onto a lower-dimensional space using a sparse random matrix.\n\nMy first concern about this work is its novelty. Defining a feature space using the Fisher kernel of a generative model is a very well-known idea, and there is a large body of work around that. As the paper points out, the problem with the Fisher score for the recent deep generative model architectures is that Fisher score operates in the parameter space and the deep models have a very large number of parameters. The paper proposes to get around this problem by projecting the Fisher score onto a lower-dimensional space using random matrices. But I am not convinced that this random projection can learn useful representations, which brings me to my second concern about the evaluation metric. The paper uses the activation of the last layers of the PixelCNN as a baseline, which I consider to be a very weak baseline. Each activation at spatial position (i,j) only depends on the previous pixels and I believe they are not in general good high-level representations. For the evaluation, the paper only considers the FID score on the interpolated images and reconstructions. There are much better ways to compare the quality of unsupervised representations such as their performance on classifying images with a linear classifier as done in [1]. The paper would improve by comparing the quality of its latent representations with the recent unsupervised/self-supervised learning methods such as [1,2].\n\n[1] Data-Efficient Image Recognition with Contrastive Predictive Coding\n[2] Learning deep representations by mutual information estimation and maximization"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #1",
            "review": "Motivated by the observation that powerful deep autoregressive models such as PixelCNNs lack the ability to produce semantically meaningful latent embeddings and generate visually appealing interpolated images by latent representation manipulations, this paper proposes using Fisher scores projected to a reasonably low-dimensional space as latent embeddings for image manipulations. A decoder based on a CNN, a Conditional RealNVP, or a Conditional Pyramid PixelCNN is used to decode high-dimensional images from these projected Fisher score.  Experiments with different autoregressive and decoder architectures are conducted on MNIST and CelebA datasets are conducted. \n\nPros:\n\nThis paper is well-written overall and the method is clearly presented.\n\n\nCons:\n\n1) It is well-known that the latent activations of deep autoregressive models don’t contain much semantically meaningful information. It is very obvious that either a CNN decoder, a conditional RealNVP decoder, or a conditional Pyramid PixelCNN decoder conditioned on projected Fisher scores will produce better images because the Fisher scores simply contain much more information about the images than the latent activations. When the $\\alpha$ is small, the learned decoder will function similarly to the original pixelCNN, therefore, latent activations produce smaller FID scores than projected Fisher scores for small $\\alpha$’s. These results are not surprising. Detailed explanations should be added here.\n\n2) The comparisons to baselines are unfair. As mentioned in 1), it’s obvious that Fisher scores contain more information than latent activations for deep autoregressive models and are better suited for manipulations. Fair comparisons should be performed against other latent variable models such as flow models and VAEs with more interesting tasks, which will make the paper much stronger.\n\n3) In Figure 3, how is the reconstruction error calculated? It’s squared error per pixel per image?\n\n4) On pp. 8, for semantic manipulations, some quantitative evaluations will strengthen this part.\n\nIn summary, this paper proposes a novel method based on projected Fisher scores for performing semantically meaningful image manipulations under the framework of deep autoregressive models. However, the experiments are not well-designed and the results are unconvincing. I like the idea proposed in the paper and strongly encourage the authors to seriously address the raised questions regarding experiments and comparisons.\n\n------------------\nAfter Rebuttal:\n\nI took back what I said. It's not that obvious that the \"latent activations of deep autoregressive models don’t contain much semantically meaningful information\". But the latent activations are indeed a weak baseline considering that PixelCNN is so powerful a generator. If the autoregressive generator is powerful enough, the latent activations can theoretically encode nothing.  I have spent a lot of time reviewing this paper and related papers, the technical explanation about the hidden activation calculation of PixelCNN  used in this paper is unclear and lacking (please use equations not just words). \n\nRelated paper:  The PixelVAE paper ( https://openreview.net/pdf?id=BJKYvt5lg ) explains that PixelCNN doesn't learn a good hidden representation for downstream tasks\n\nAnother paper combining VAE and PixelCNN also mentions this point:\n\nECML 2018: http://www.ecmlpkdd2018.org/wp-content/uploads/2018/09/455.pdf\n\nPlease also check the related arguments about PixcelCNN (and the \"Unconditional Decoder\" results) in Variational Lossy Autoencoder (https://arxiv.org/pdf/1611.02731.pdf )\n\nAs I mentioned in the response to the authors' rebuttal, training a separate powerful conditional generative model from some useful condition information (Fisher scores) is feasible to capture the global information in the condition, which is obvious to me. This separate powerful decoder has nothing to do with PixelCNN, which is the major reason that I vote reject.\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper focuses on the problem of interpolating between data points using neural autoregressive models. The core idea is that it is possible to use (a smaller-dimensional projection of) the Fisher score of the density function defined by the autoregressive model to represent data points in embedding space, and a neural decoder for mapping them back to input space. Experiments on both MNIST and Celeb suggest that this is a sensible method, and leads to smoother interpolations rather than just relying on the embeddings resulting from the network activations.\n\nMinor: the FID acronym on pg. 2 was not introduced beforehand.\n"
        }
    ]
}