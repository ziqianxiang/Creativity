{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper deals with the problem of missing data imputation in multivariate time series and subsequent classification of the imputed time series. It combines a time-step-wise imputation step using a VAE with a full-time-series imputation using an RNN. The RNN uses special GRU cells that take the missigness pattern and the output variance of the VAE into account.\n\nGenerally, I believe the idea has conceptual merit, but the empirical evaluation is not sufficient to finally judge its practical value. Evaluations of the actual imputations, experiments on simple benchmark tasks, and more thorough ablation studies of different parts of the model would greatly strengthen this work.\n\n\nMAJOR COMMENTS\n--------------\n\n- It seems plausible that the prediction loss (L_pred) and the imputation losses (L_reg, L_vae) do not always favor the same solution. It could for instance happen that a \"wrong\" imputation of the time series (compared to the ground truth) would be easier to classify than the correct imputation. Can we be sure that this is not happening here? It would be useful to actually evaluate the quality of the imputations themselves on held-out data with and without L_pred in the loss function.\n- In Figure 3, it looks like the lowest value for alpha almost consistently outperforms the other values. Does this suggest that the VAE might actually not be useful in this architecture? Section 4.3.1 says that the performance degrades with an increasing beta parameter and that the VAE loss is thus still important. I don't think this conclusion is fully supported by the data, since it does not take the prediction loss (L_pred) into account. Increasing beta may well degrade the prediction performance because it weakens the influence of L_pred on the total loss, without any knowledge about the influence of L_vae.\n- Looking at the error bars in Table 2, I don't think the conclusion that the full V-RIN model poses a \"significant enhancement\" over the other one is statistically supported. The confidence intervals seem to be well overlapping. Looking more closely, they actually also seem to overlap with some of the RITS and BRITS models on some measures. Those values should probably also be printed in bold face and the claim in the text should be respectively weakened.\n\n\nMINOR COMMENTS\n--------------\n\n- The grammar and orthography should be checked here and there.\n- The reconstruction loss in the VAE-ELBO (Eq. 9) seems to encourage \\hat{x} to be close to \\tilde{x}. But \\tilde{x} contains zeros in place of all the missing features. Would this not encourage the VAE to just also put zeros there and therefore lead to \\bar{x} being roughly equal to \\tilde{x}? Maybe the \\hat{x} could actually be shown in the experiments to give an intuition for whether or not this is happening.\n- While I agree that medical time series are a challenging task to tackle and appreciate the usage of real data in the experiments, I think some aspects of the model could be more easily studied on some simpler benchmark task, where for instance the imputations could be visualized and ground-truth data for the missing values could be used for evaluation."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper proposed a model for imputing missing values and predicting clinical events in time series data. Its contribution lies in incorporating uncertainty,  feature correlations and temporal correlations into GRU when imputing the missing values.\n\nComments:\n\n1. The representation in section 3.2 is rather confusing. Do you learn different inference networks for \\mu_z, \\sigma_z and different generative networks for \\mu_x, \\sigma_x at different time points? If so, please add t as the subscript for all  \\mu_z, \\sigma_z, \\mu_x, \\sigma_x above the uncertainty matrix paragraph. Otherwise, it is confusing when ‘t’ first appears as the subscript of \\sigma_x in the formula of \\hat{\\Sigma}_x, . According to the context of section 3.2, \\sigma_{x,t} is a vector with D elements, since diag(\\sigma_{x,t}) represents a D*D diagonal matrix, the dimension of the matrix [diag(\\sigma_{x,1}), …, diag(\\sigma_{x,T}) ] is D*DT, hence \\hat{\\Sigma}_x cannot \\in R^{T*D} as the author claimed. \n\n2. The introduction section and the related work section is a bit redundant with repeated descriptions of the same reference papers at both sections.\n\n3. For evaluation purposes, the paper performed experiments to compare the proposed model with various baseline models, which is thorough enough in terms of different baselines. However, it only employed one data set. It would be more convincing if it had performed more experiments on other data sets, such as MIMIC-III.\n\n4. There are many places missing articles in front of the singular nouns. E.g. “However, since it is intractable due to involvement of ...” should be “However, since it is intractable due to the involvement of ...”; “As time delay ∆t is essential element to...” should be ”As time delay ∆t is an essential element to...” ; “...our learnable parameters in recurrent imputation network.” should be “...our learnable parameters in a recurrent imputation network.”; “As part of the ablation studies,...” should be “As a part of the ablation studies,...”\n\n5. “...Eq. (1) using negative exponentional rectifier...” should be “exponential”.\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper presented a method that combines VAE and uncertainty aware GRU for sequential missing data imputation and outcome prediction.  \n\nPros:\n>modeling heterogeneous sequential data with missing value is an important task, especially in the healthcare domain.  \n>The presentation of the method is easy to follow. \n>The experiments compared with many baselines \n\nCons:\n>Figure 2 should compare the D-GRU (che 2018) cell which is the baseline as well. Comparing to D-GRU, I am not sure what is the contribution as the GRU-D has considered both the delay \\Delta and the delay \\gamma. Please clarify.\n> Also many works have studied  VAE + sequential model. Combining with the previous point. I don't see sufficient novelty in this work apart from using the standard VAE + sequential formula with D-GRU. \n>How does alpha and gamma from equation (11) been chosen? I guess that the performance is sensitive to these parameters. \n>The experiments are weak as it is only evaluated on one dataset (PhysioNet).\n>Improvement shows in Table 2 are not significant considering std comparing with other methods. \n>There are many VAE based methods for missing value such as [1][2], and the uncertainty is used for downstream tasks [2]. \n>It would be great to have analysis comparing with non-sequential VAE based imputation method etc and discuss which part of the design contributed most to the performance gain. \n\n[1] Mattei, Pierre-Alexandre, and Jes Frellsen. \"MIWAE: Deep Generative Modelling and Imputation of Incomplete Data Sets.\"\n[2] Ma, Chao, et al. \"Eddi: Efficient dynamic discovery of high-value information with partial VAE.\" arXiv preprint arXiv:1809.11142 (2018).\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Paper summary\n\nThe authors introduce a missing data imputation network to incorporate correlation, temporal relationships, and data uncertainty, specifically for the problem of data sparsity in EHRs. Their model involves two main portions: an imputation network that feeds into a classification network. They tested the effectiveness of their method by predicting in-hospital mortality rate on the PhysioNet Challenge data from 2012. Their model yields higher AUC on the mortality rate classification task than several other methods. The compared methods are well described, with good explanations of how they differ from the authors' model. In addition to strong experimental results, the introduced model also has some theoretical justification for the additions that they have made to the traditional GRU.\n\nDecision\n\nThe algorithm has been both theoretically and empirically justified, and has valuable contributions for an important application. The performance of the method is encouraging, and the method has novel components. Still, analysis of the experiments would greatly benefit from statistical significance tests when comparing to other methods. This paper still needs some work before it can be accepted.\n\nAdditional feedback\n\nThere are a few things that need to be addressed before the paper should be published. In section 3.2, besides citing the reparameterization trick, the authors are not clear on how much of the VAE is based on existing work. On the other hand, their graphical comparison between the vanilla GRU and their version is very informative. Throughout the paper, the authors need not write out the equations of well-established functions (e.g., cross-entropy loss function).\n\nFigure 3 should have a dotted line for V-RIN and a solid line for V-RIN-full, as the current format is difficult to read in black and white. Lastly, some proofreading and restructuring should be done throughout the paper, as some portions are difficult to read. For example, in both the first sentences of the abstract and the introduction, the word \"comprise\" should not be followed by \"of\" (EHRs store longitudinal data comprising patient's clinical observations in the ICU).\n\nLastly, there would be a stronger argument for the paper if the imputation network were tested on a dataset with naturally missing data, rather than randomly sampling from an existing dataset. This is because there might be certain variables that are more likely to be missing than others, but could offer a strong signal if successfully imputed."
        }
    ]
}