{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper presents a network architecture to attain temporally coherent video super-resolution using temporal connections across the residual block layers between the previous and current frames. It reuses the feature maps computed in the previous frame after passing it through a warping layer based on screen-space (that is, 2D image space) motion vectors ('velocities' in the paper). In other words, the second convolutional layer of the residual block gets not only the feature map of the first convolutional layer feature map but a concatenated feature map that is composed of the first convolutional layer feature map and the warped feature map of the first convolutional layer computed in the previous frame. This allows propagating feature maps in time. This is called as 'depth-recurrent residuals.' Other variants are also evaluated. \n\nThe network is trained with sequences of HR-LR image pairs that are rendered using Unity’s HDRP. However, neither the original TecoGAN nor any of the other baselines have been trained with such rendered data. It is not clear whether the training of the entire network and testing with the Unity generated rendered data provides an unfair advantage to this method in comparison to the other methods that do not use such data in their training. The paper mentions that TecoGAN re-trained, yet no quantitative results are provided for that version in the paper. Also, it is not clear, why motion-compensated features in residual blocks are better than the existing architectures that use multiple motion-compensated frames, perhaps the paper could have provided a deeper discussion.\n\nTo make a case for a video SR method that is applicable not only to CGI rendered videos but also to a more general class of natural videos (e.g. camera acquired) additional results on the NTIRE 2019 video SR challenge dataset should have been provided. The paper fails to compare with any of the top methods in the video SR challenge in NTIRE 2019.  "
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "The paper presents a super-resolution technique for video that modifies the inter-frame connections of a residual block network. The paper is presented in a fairly clear way and I have no general negative comments about the idea itself, but I am also not able to assess the claims for state-of-art performance. With that said, I am still leaning towards reject.\n\nOnly a few algorithms are compared with in a small scale problem, and the results are not very conclusive when viewing the three measures as a whole.\n\nThe purpose seems to be to improve video game streaming, but the speed of the algorithm does not make it practically useful yet, as the authors acknowledge. If existing techniques are practically useful, then that’s a drawback. One can wish for faster computers, but these other techniques were working within realistic constraints. I assume they will improve too with better computation speed."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "In this submission a new type pf connections for ResNet architectures is proposed to improve the spatial-temporal anti-aliasing in video super-resolution. The work presents promising results in comparison with related supervised approaches and GAN-based approaches.\n \nHowever, in the submission the algorithm is tested only on a private dataset without any statistics description. Comparison on commonly used datasets (e.g. BAPPS, Vid4, etc.) and standard metrics PSNR is not presented in evaluation. Therefore, the performance of the proposed algorithm cannot be well justified.\n \nOther comments are:\n1. Improvement of proposed connection is not clearly demonstrated. Is there any comparison between the skip connection in ResNet and the proposed connection?\n\n2. The running speed of the proposed DRR architecture. Is it faster than other related works? Please present the comparison of the running time.\n"
        }
    ]
}