{
    "Decision": "",
    "Reviews": [
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper addresses an interesting case of text generation, interpolating between the requirements of content fidelity and style transfer. This is carried out using a hybrid \"attention-copy\" mechanism, which is intended to attend to style in a reference sentence and copy content over from a structured data representation. This along with data augmentation and a combined unsupervised objective comprise the learning framework. An ablation study and human evaluation are carried out, confirming that the model presented has advantages over foregoing style transfer and generation models. \n\nI think this paper should be accepted as it addresses an interesting and widely applicable scenario, and the combined unsupervised objective is a creative and well-motivated solution. It consitutes a contribution both to neural generation and style transfer methods. It is not a strong accept as I think that when introducing a new task, more in-depth evaluation and error analysis is appropriate.\n\nOne challenge with this task is evaluation -- some of the scores are close enough to 50% that it would be useful to have significance of some kind calculated, more information about the annotators and inter annotator agreement, and some amount of error analysis to help give context for Table 3. Particularly, since this is a new task, the foregoing models compared would be expected to perform worse than the new model. To learn more about ways in which the new model is well adapted to the task, it could be useful to look closer into the tradeoff between fidelity and style transfer, e.g. comapring the BLEU score between y and y_hat in addition to y' and y_hat for all models.\n\nRecommendations:\n1. If possible, please use clearer notation to explain the data augmentation step. It is really interesting and creative, but very hard to follow x, x', y, y' -- please consider using subscripts like y_side or something.\n2. In section 6.2, a binary transformer classifier is mentioned. Please clarify how 'manipulating the content successfully' is measured, and describe the classification task in further detail."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "The authors propose a method for a specific type of structured text generation, where an array of structured text fields is provided, along with a sentence, and a new sentence is generated which incorporates the information from the structured text fields while preserving the linguistic style of the original sentence. The authors assess the validity of their method by comparing it to alternative rule-based, seq2seq, and style transfer methods, on metrics including content fidelity, style preservation, and linguistic fluency.\n\nAlthough the problems of style transfer and structured text generation are both interesting and important research questions in their own right, the authors' focus on a highly specific, and frankly contrived, problem wherein we wish to rewrite a sentence by imputing the information currently in it with replacement information, is instead much more amenable to non-learning rule-based methods, as their own findings show. Even with the most trivial rule-based baseline of identifying matching data type fields and replacing them with new structured data values, the rule-based method compares favorably (Table 2, Table 3). The most obvious flaws with the rule-based methods are that it sometimes leaves in no-longer-relevant information, or fails to add in all of the new structured field information. Both of these flaws can be largely remedied with the introduction of additional operations which cleave off parts of the original sentence which contain information not present in the structured text, and append additional structured field information via appending e.g. \"and [player_name]\". The paper itself also contains copious typos, grammatical errors, and awkwardly phrased text to the extent that it impedes understanding. This reviewer is therefore of the opinion that this paper should be rejected.\n\nTypos and awkward phrasings:\n* pg1 : \"under investigated\" --> \"under-investigated\"\n* pg1 : \"controll In\" --> \"control. In\"\n* pg1 : \"controlled generation text generation\" --> \"controlled text generation\"\n* pg1 : \"and many others\" --> adds nothing, remove\n* pg1 : \"and so forth\" --> adds nothing, remove\n* pg1 : \"of reference sentence\" --> \"of the reference sentence\"\n* pg2 : \"on the contrary\" --> adds nothing, remove\n* pg2 : \"in comparison\" --> adds nothing, remove\n* pg2 : \"encourages to precisely\" --> \"encourages it to precisely\"\n* pg3 : \"generating more accurate description\" --> \"generating more accurate descriptions\"\n* pg3 : \"exiting\" --> \"existing\"\n* pg3 : \"Without loss of generality\" --> adds nothing, remove\n* pg3 : \"not exact the same\" --> \"not exactly the same\"\n* fig2 : \"Jure_Holiday\" --> \"Jrue_Holiday\"\n* pg4 : \"extract representation\" --> \"extract a representation\"\n* pg4 : \"The decoder is to generate\" --> \"The decoder is used to generate\"\n* pg5 : \"in reference sentence\" --> \"in the reference sentence\"\n* pg5 : \"written by human\" --> \"written by humans\"\n* pg5 : \"y|x\" --> incorrect symbol being used for the vertical bar, possibly subscripted\n* pg5 : equation 1\" --> \"equation 1\"\n* pg6 : \"e.g.,\" --> \"e.g.\"\n* pg6 : \"riginal\" --> ???\n* pg6 : \"e.g.(eatType\" --> \"e.g. (eatType\"\n* ... and so on ...\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper presents a new task: given some structured content and a reference sentence, the goal is to generate a new sentence describing the input structured content while at the same time have a similar style to the reference sentence. They provide new datasets, and propose an objective which balances content fidelity and style preservation. The proposed model is evaluated against simple structured content to sentence generation system as well as recent style transfer methods. I believe the task is important, but I am not sure if the datasets used are right for this task. For both the datasets, the structured content is usually some facts which cannot be described in a lot of different styles. I suggest using data where users can use more emotions, resulting in a wider range of styles for the same content. Examples can be data from dialogue agents and reviews. Given the current data, I am not convinced about the style transfer claims. "
        }
    ]
}