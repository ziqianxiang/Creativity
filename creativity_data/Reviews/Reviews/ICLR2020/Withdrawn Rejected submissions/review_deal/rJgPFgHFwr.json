{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper proposes and studies a task where the goal is to classify an image that has been intentionally degraded to reduce information content. \nAll the reviewers found the comparison of human and machine performance interesting and valuable. However the reviewers expressed concerns and noted the following weaknesses: the presented results are not convincing to support our understanding of the differences between human and machine perception (R1), using entropy to quantify the distortion is not well motivated and has been addressed before (R1), lack of empirical evidence (R2). \nAC suggests, in its current state the manuscript is not ready for a publication. We hope the detailed reviews are useful for improving and revising the paper. ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "The paper proposes and studies a task where the goal is to classify an image that has been intentionally degraded to reduce information content - hence the name \"laconic\" image classification. The motivation for this task is to compare human and machine performance in a task that deviates from the standard ImageNet setup. To make different content reductions comparable, the authors measure the (approximate) entropy of an image via its PNG-compressed file size. As image transformations, the authors utilize quantization, downsampling, cropping, and a combination of the above. The authors find that convnets with higher accuracy are also more robust to these perturbations, and that humans perform well on the minimum-entropy examples of the networks (but not vice-versa).\n\nOverall I find the comparison of human and machine performance interesting and hence recommend accepting the paper. However, there are multiple directions that could possibly strengthen the core experiment. Hence I only give a weak accept at this point. Concretely, these directions are:\n\n- Do the results in the paper change if a different entropy measure is used (e.g., JPEG compression)?\n\n- As suggested by the authors, training networks to be robust to the \"laconic\" image perturbations could be an interesting direction. For instance, standard data augmentation with the proposed perturbations would be a relevant baseline.\n\n- To aid replicability and to compare the performance of different human test subjects, it would be interesting to conduct the experiment also on a crowdsourcing platform such as Mechanical Turk (as a complement to, not a replacement for, the university population in the paper).\n\n- Also to add replicability and to make it easier to compare different human accuracy evaluations, it would be good to measure how well the annotators perform on the unperturbed images and on a simple noise transformation (e.g., Gaussian noise).\n\n- It would be good to know how approximate the entropy measures in the paper are, e.g., to understand why humans perform worse in the \"combined\" perturbation setting.\n\n- How did the results from the control group and the open / online evaluation differ?\n\n\nIn addition, I have the following suggestions for improving the paper:\n\n- For the related work section, the authors may find the following papers on robustness of convnets to distortions interesting:\n\n* Manitest: Are classifiers really invariant?\nhttps://arxiv.org/abs/1507.06535\n\n* Exploring the Landscape of Spatial Robustness\nhttps://arxiv.org/abs/1712.02779\n\n* Spatially Transformed Adversarial Examples\nhttps://arxiv.org/abs/1801.02612\n\n* Semantic Adversarial Examples\nhttps://arxiv.org/abs/1804.00499\n\n- It could be helpful for the reader to see some example images of the different transformations in the main text.\n\n- Section 6: \"[...] a bias in texture for images trained on the ILSVRC dataset [...]\" - should this be \"classifiers\" instead of \"images\"?\n\n- Section 6: \"[...] would be interesting to explore in future\" - insert \"the\" before \"future\"?"
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper proposes a method to understand and compare the performance of DNNs classifier, which is different from the precise prediction in the notion of correct/wrong. With approximate minimal-entropy of input images, the classifiers can recognize this image so that different classifiers including human and DNNs will need different reduction methods (cropping, downsampling, color reduction )for the same image to give correct prediction and also will give us different performance in a same test dataset. By comparing the results with human’s and DNNs’, the author claims that it will have more challenges for DNNs in this laconic image classification task than human will have.  \nFor the motivation in this paper, the author tries to propose a new perspective to evaluate the robustness of image classifiers. Especially compared with humans’ understanding, this paper would like to rethink the influence of reduction for this task. However, it is not clear that why three reduction methods the author used can help with understanding the difference between humans and DNNs because when training a DNN for image classification, we usually use these methods to augment our training set, but for humans, it is a totally different story that how to recognize an image.\nFor the theoretical demonstration, in this paper, the author uses approximating minimal-entropy to quantify the minimal content of an image DNNs or humans need to give correct category. The intuition of this method is suitable. But in section 3, the author didn’t give a clear demonstration of how to compute the entropy reduction in 3.1. I think if it is better to introduce how to measure 3.2 in detail, then 3.1 may be more clear. And it also makes me confused about the atomic reduction step in the last paragraph in 3.1. For the 3.5, I think the authors should focus on how to demonstrate MEPIs for humans more mathematically so that it will be more reliable.\nFor the experiments, the author tries to answer two questions: 1. How does the entropy required by DNN and human classifiers compare? 2. How do the classifiers perform in terms of precision for each others’ MEPIs? However, the experiments do not provide convincing evidence to existing approaches. First of all, for a single DNN, how different entropy reduction methods influence the classification? Secondly, how different reduction scales in the same model influence the results? At last, the comparison between different models should give a more visualized figure to illuminate the difference. It will be better to provide more ablation study experiments for this paper.\n"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "Summary:\nIn this empirical study, the authors attempt to identify a minimal entropy version of an image such that the image may be correctly classified by a human or computer. The authors then compare the efficacy of a human and computer to maintain accuracy in the presence of a reduced entropy representation of an image. The authors find that machines are more sensitive to reductions in entropy due to image resolution than humans (as opposed to color or cropping). In addition, the authors find that humans are generally better at identifying minimal entropy images than machines.\n\n1. Corruption results not surprising. \n\nAlthough the authors offer some intriguing methods, I found the results to not be compelling nor improve our understanding of the relative differences between human and machine perception. While identifying that humans are less sensitive to a reduction in resolution, this result is not terribly surprising given that networks are known to suffer from aliasing artifacts, e.g.\n\n  Geodesics Of Learned Representations\n  Olivier J. Henaff & Eero P. Simoncelli\n  https://www.cns.nyu.edu/pub/lcv/henaff16b-reprint.pdf\n\n2. Unclear what we learn from the method.\n\nI am not too clear about what specific insights the methods provide in this paper. Estimating the entropy associated with each image corruption -- while interesting -- does not lead to any substantive analysis nor conclusions as far as I can tell. Given the lack of benefit to analyzing the entropy, I am left to really just consider these methods to be image corruptions that downsample the resolution or desaturate the images. These corruptions are not terribly novel with respect to previous work, e.g.\n\n  Generalisation in humans and deep neural networks\n  https://arxiv.org/pdf/1808.08750.pdf\n\n  Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\n  https://arxiv.org/abs/1903.12261\n\nTo summarize, my feedback is the following:\n\n1. Please justify the use of entropy to quantify the distortion. What does entropy provide above and beyond just parameterizing the distortion (e.g. image resolution, color saturation)?\n\n2. Are there other results above-and-beyond sensitivity to image resolution that distinguishes human and machine in these experiments? These results seem to be largely known by just considering corruptions such as low pass filters, etc. presented in the above papers.\n\n\nMinor Comments:\n\n- The authors should provide a figure with example images in the main text showcasing how each method corrupts an image."
        }
    ]
}