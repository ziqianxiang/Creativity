{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #4",
            "review": "The authors consider energy-based learning for discriminating real vs machine generated text. They explore the approach of using a generative text model to generate machine generated training examples. They then consider generalization when the generative model in test time is different from the generative model used for training, as well as if the training data changes to a different corpus. They observe that their model is reasonably able to generalize when the generative model or training data is changed.\n\nThe experiments in this work seem fine. My main issue is with the theory, specifically if their approach to using an energy function is truly different from supervised learning. \n\nIt is not really clear why an energy model is useful for the tasks they consider in the paper, as it essentially seems to be a binary classification problem. Additionally, is it fair to say that the BCE loss used is essentially the classic supervised loss function, modulo using the most offending negative? If we model the probability the text is real as exp(-E(x)) / (exp(-E(x)) + 1), then we get the classic supervised loss function (again modulo using the most offending negative).\n\nTo me, an energy based approach would be to model P(x) = exp(-E(x)) / Z, where Z is a normalization constant. I would calculate the log likelihood as -E(x) - log(Z), which agrees with LeCun, 2006 and Du and Mordatch, 2019.\n\nThe authors need to do a better job explaining why they consider this an energy based approach and relate it to more typical energy based approaches. Additionally, a bit of text describing why using the most offending negative would be helpful.\n\nAn additional experiment that would be interesting is to train the model using many different generative text models and test on an unused generative text model.\n\nI would also like to see a more formal definition of \"residual\". \n\n\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #1",
            "review": "The paper proposes an energy based model for text. Since energy-based model requires two kinds of examples (positive and negative) with negative examples as being harder to mine, the paper proposes to use existing language models as a source of negative examples. \n\nI like the empirical analysis for generalization in the paper. This is novel, rigorous, and interesting. But I have two main concerns:\n\n1. The general idea of the paper is however not new. There have been at least 4 works for post-hoc training of classifiers to correct for mistakes of generative models using resampling based methods. These have been applied to image models, but the methods presented in these works are general purpose. Unfortunately, none of these works have been cited.\n- [1] proposes a boosting procedure based on classifier training over an existing generative model (Section 3.2)\n- [2, 3, 4] propose different resampling methods (rejection sampling, MCMC, importance weighting) for improving the base generative model via post-hoc training of a binary classifier.\n\n2. Casting this as an energy-based model is not very interesting if we only care about classification accuracy. A generative model permits many more inference tasks; likelihood evaluation or sampling. These are intractable for the current EBM I believe and I wish there was a more rigorous discussion around this. [4] for example formalizes the induced EBM and presents a particle based approximation for sampling from such an EBM (Section 4). Similarly, EBMs can be used for tasks requiring any task requiring relative likelihoods e.g., inpainting, denoising etc. Would have been great if some experiment along those lines was included to truly stress on the generative modeling capabilities of current EBM.\n\n- I am also curious of the training metrics for the classifier. What happens if you use a non-probabilistic classification loss (e.g., hinge loss)? \n- Also, what happens when the base language model doesn't have full support? Would the distribution of negatives of the EBM be biased?\n\nAuthors are recommended to clarify the above questions, clearly discuss relationship with existing work and analyze the EBM formulation in greater detail during the rebuttal period. \n\nReferences:\n1. Boosted Generative Models.  AAAI 2018.\n2. Discriminator rejection sampling. ICLR 2019.\n3. Metropolis-hastings generative adversarial networks. ICML 2019.\n4. Bias Correction of Learned Generative Models using Likelihood-Free Importance Weighting. NeurIPS 2019.\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes to generating negative samples for EBMs using pre-trained auto-regressive language models, and the trained EBMs (called the residual EBMs) are used for real/fake text discrimination.\nThe generalization ability of residual EBMs is thoroughly evaluated.\n\nIn generally, the paper is well motivated and well written. But I have some concerns.\n\n1. Important relevant references are missed.\n\nEBMs (a.k.a. un-normalized models, random fields) have been successfully applied to model text sequences in recent years. Connecting and comparing to these previous works are needed.\n\n[1] R. Rosenfeld, S. F. Chen, and X. Zhu, “Whole-sentence exponential language models: a vehicle for linguistic-statistical integration,” Computer Speech & Language,  2001.\n[2] B. Wang, Z. Ou, and Z. Tan, “Trans-dimensional random fields for language modeling,” ACL, 2015.\n[3] B. Wang, Z. Ou, and Z. Tan, “Learning transdimensional random fields with applications to language modeling,” IEEE transactions on pattern analysis and machine intelligence, 2018.\n[4] B. Wang and Z. Ou, “Language modeling with neural trans-dimensional random fields,” IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), 2017.\n[5] B. Wang and Z. Ou, “Learning neural trans-dimensional random field language models with noise-contrastive estimation,” IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018.\n[6] B. Wang and Z. Ou, “Improved training of neural trans-dimensional random field language models with dynamic noise-contrastive estimation,” IEEE Spoken Language Technology Workshop (SLT), 2018.\n\n\n2. Some unclear issues:\n\nIt is not very clear how the trained EBMs are used to do real/fake text discrimination specifically.\n\nThe energies used in Eq.(1) are in the form of conditional energies. It is not very clear how the conditional input is fed into the EBM architectures in Section 4.3.\n\n3. I am a little bit concerned that the theoretical contribution seems weak, though the application of applying EBMs in real/fake text discrimination is novel.\n\nI'm happy to adjust the score if the paper can be better placed in the literature and the authors take efforts to improve the paper."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "The paper discusses training an energy-based discriminator to discriminates the generated examples from a language model from human-written sentences.  To do this, it assigns lower energy value to the real text and higher energy values to the generated text, by optimizing binary cross-entropy.\n\nThe motivation of the paper claims that the authors solve (or at least move toward solving) the problem of sampling from energy-based models for high-dimensional sequence problems; however, I do not see any contribution towards that. \n\nThe importance of having a well-trained energy-based model is its modeling capability, which also enables us to sample from it (that is done using gradient descent and Langevin dynamic for modeling images). But here, the energy-based model has no effect on the quality of samples from the auto-regressive model, so it does not give us a better model for text. It would be similar to EBGAN (Zhao et al., 2017), but only training the energy discriminator and keeping the generator as is (here a pretrained LM).\n\nThis work would become an interesting and influential work if you can update the generator parameters from the feedback of the energy-based model, so the generator works as a sampling process for the energy-based model (which was what I expected while I was reading the first part of the paper). "
        }
    ]
}