{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper considers an important problem in medical applications of deep learning, such as variability/stability of  model's predictions in face of various perturbations in the model (e.g., random seed), and evaluates different approaches to capturing model uncertainty. However, it appears to be little innovation in terms of machine-learning methodology, so ICLR might not be the best venue for this work, while perhaps other venues focused more on medical applications might be a better fit. \n ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "I am not an expert in the field of model uncertainty\n\nSummary / contributions:\nThis paper discusses the important problem of model uncertainty in the output of ML models developed for clinical applications. The authors illustrate the underlying concepts using RNNs which are popular in the medical ML literature by applying these to two datasets. They argue that Bayesian RNNs with Bayesian embeddings should be the models of choice in such settings as they explicitly allow the expression of uncertainty whereby obtaining confidence intervals etc is easy. The other advantage is the fewer number of parameters that need to be stored to get such statistics.\n\nNovelty:\n-- Some of the ideas presented are standard or well-known properties to most ML practitioners. For instance, the relationship between mean and variance in Fig 2 or the uncertainty in predictions / optimal decisions in Fig 3. Is the point of the paper to make it more obvious?\n-- It is certainly the case that medicine practioners are not as aware of these issues, but to reach that audience this paper would do better in a venue that caters to that community. However, the paper needs to address the concerns first so as to not confuse that community\n-- The Bayesian RNN models being discussed are not novel either and their properties have been discussed in the corresponding papers (probably not in such detail and with examples).\n-- What is the value of the Bernoulli distribution? Isn't the single output from a well calibrated model is enough to give the same information.\n\nWriting:\nThe paper is very well written and has good figures and examples to explain the ideas. The one area that can be improved is the contributions section.\n\n\nResults:\n-- The authors do not discuss the related issue of model calibration in much detail. It is unclear what additional information we are gaining from the author's perspective of model uncertainty. A well calibrated model as well as other ways of obtaining confidence intervals (via hypothesis tests) would serve just as well.\n-- Are the conclusions derived on the specific datasets general?\n-- The results showing group-level biases are not very helpful and come across as anecdotal. These can be derived from most other models too."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Thank you for an interesting read.\n\nThis paper is an experimental paper which argues the importance of epistemic/model uncertainty in applications for electronic health records (EHR). The main arguments are the following:\n1. current metrics on dataset level cannot reveal uncertainty in prediction on personal level;\n2. when evaluated on personal level, deterministic NNs with different random initialisations can produce very different predictions (thus require consideration of model uncertainty)\n\nI am not exactly sure if ICLR is the best venue for this submission, as there is quite little innovation in modelling methodology, and the empirical analysis is domain specific. I feel this paper is more suitable to e.g. MLHC or MICCAI which focus on data analysis/machine learning methods applied to healthcare science.\n\nStill I think the set of experiments in the paper is overall supportive to the main argument that the authors is trying to make. Possible improvements:\n1. The histograms in Figure 3 & 4 clearly show that, deterministic NNs trained with different initialisations produces diverse predictions on individual patients. I commend the authors for presenting these visualisations, and I think it would be more useful to quantify this phenomenon on dataset level, e.g. compute the mean and variance of this variation of individual predictions.\n2. I would expect to see an improvement of ECE for the Bayesian/deep ensemble models. The Table A.3 so marginal improvements, and I wonder how would this result support the author's claim? Also how do the ECE/ACE metrics look like when computed on sub-groups?\n\nApart from section 3.3, in general I think the paper writing is clear to me. The loss sensitive optimal decision method is interesting, but a lot of details are missing:\n1. The presentation in section 3.3 is unclear, e.g. minimising eq. (4) w.r.t. what? What's the definition of decision region? Also what exactly is the mathematical form of the associated cost used in the experiments?\n2. If I understand it correctly, in experiments the optimal thresholding method has only been applied to individual networks in the ensemble. If so what is the intention of discussing eq. (5) in the first place? Also it is unclear to me how this method performs in the deep ensemble/Bayesian RNN case. See e.g. https://arxiv.org/pdf/1805.03901.pdf for a relevant approach."
        }
    ]
}