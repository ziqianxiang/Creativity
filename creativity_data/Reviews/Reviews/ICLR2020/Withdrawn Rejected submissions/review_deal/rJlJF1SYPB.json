{
    "Decision": "",
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "N/A",
            "title": "Official Blind Review #5",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper theoretically shows that data manifolds can be approximated by neural-network-based generative models including GANs. In particular, they prove that under mild assumptions neural networks can map a given latent space $M_z$ onto a set $M_theta$ which is close to the given data manifold $M$ within a small Hausdorff distance. There results hold for the case of both single data manifold (i.e. data generated from a single class) and multiple data manifolds (i.e. data generated from multiple classes). In the latter, they need to allow insignificant parts of the latent space to be mapped onto thin “tunnels” connecting the manifolds. The construction of the mapping from the latent space onto the data manifold provided in their proofs is only for shallow networks. Section 6 of the paper - Invariance Property of Deep Expanding Networks - characterizes the property of the manifold $M_theta$ computed by deep neural networks that expanding the dimensionality of the input. In particular, they show that $M_theta$ is a smooth embedded manifold and it is diffeomorphic to the latent manifold $M_z$, which shows that neural networks cannot significantly transform the latent space. The paper also extends the results for the geometric universality of generative models to cycle generative models including the CycleGANs or Pix2Pix architectures. In particular, they show that under mild conditions, there exists a pair of neural networks that can approximately map back and forth between two given data manifolds.\n\nPotentially, this paper could be an interesting contribution. However, some points in the theory need to be verified, and at least toy experiments should be provided to validate their theoretical claims. Furthermore, Section 6 - Invariance Property of Deep Expanding Networks - does not seem related to the main story of the paper and should be a separate paper itself. I weakly reject this paper, but given these clarifications in an author response, I would be willing to increase the score. \n\nMain arguments and questions:\n\n1. Theorem 5.1 and 5.2 - Geometric Universality of Generative Models for signal class and multiclass case - seem to be straight-forward applications of Lemma 5.1 and Theorem 4.2. Lemma 5.1 is a special case of the Brown’s mapping theorem and Theorem 4.2 is the well-known theorem on the universal approximation power of neural networks. I, therefore, question the significance of  Theorem 5.1 and 5.2.\n\n2. Since this is clearly a theory paper, lack of experiments can be tolerated. However, the paper does not provide even a single toy simulation result to at least shed light on their theoretical claims. For example, the results from Theorem 6.1 which show that neural networks cannot significantly transform the latent space can be empirically justified.\n\n3. Will the results in Section 5 and 7 hold for Convolutional Neural Networks, or only for Fully Connected Networks? \n\n4. Theorem 6.1 shows that the manifold $M_theta$ computed by a neural network is diffeomorphic to the latent manifold $M_z$. However, the mappings by deep generative models like GANs, in most cases, are not invertible. It would be great if the authors can elaborate this point more. Otherwise, the results in Theorem 6.1 are questionable. \n\n5. The paper admits that according to theorem 6.1, “it is impossible to approximate an arbitrary data manifold with latent space being R^{d}”, but in practice, deep generative models like GANs can generate good-looking images. As mentioned in the paper, a precise theorem for this case is not provided. The authors, however, say they “hypothesize that it may be possible to approximate an arbitrary compact data manifold using expanding networks up to a subset of arbitrary small measure, and thus limitations imposed by Theorem 6.1 are negligible in practice.”. However, I didn’t see how this hypothesis is related to the results and discussion in Section 7. It would be great if the authors can provide more explanation for this hypothesis and its connection to the results in Section 7.\n\n6. Geometric universality does not guarantee that a good approximation to data manifolds can be found after training the generative model. The optimization, especially the objective losses used to train the model, plays an important role in understanding the manifold $M_theta$ represented by the trained model. As a result, I am not quite sure about the significance of this paper and would appreciate if the authors can discuss the relevance of their results.\n\nThings to improve the paper that did not impact the score:\n\n1. The paper should define what fully connected neural networks are.\n\n2. Some notations in the paper need to be defined such as the ≃ in Theorem 6.1.\n\n3. More discussion on exponential map and the intuitions behind it should be provided.\n\nMinor comments:\n\nThere are some typos in the paper such as “continuos” in page 4, “an embedding is the following” in Definition 6.1, “may possible” in page 7, and “is two train two neural networks” in page 7."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "N/A",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "Summary: The paper provides certain basic guarantees on when manifolds can be written (exactly or approximately) as the image of a map approximated by a neural net. This is couched as answering the question of when GANs can approximate certain distributions, though in fairness, distributions aren't really ever considered -- only the images of the maps approximated by the neural net of the GAN.  \n\nTechnical contributions: The paper mostly stitches together known theorems from (differential) geometry of manifolds, as well as standard universal approximation results. For instance, the result about differentiable connected manifolds proceeds by essentially using known results about the exponential map of such manifolds (Lemmas 5.1 and 5.2), and subsequently approximating this map in a black box way via known universal approximation results. \n\nVerdict: The paper unfortunately doesn't pass my ICLR bar -- the techniques are essentially known, so there is very little new mathematically; additionally, the question is in some sense the \"wrong\" one: one needs to approximate *distributions* with support over a low-dimensional manifold, rather than only worry about the range of the map from the latent space to the domain of the GAN. Additionally, much in the way Neural Net approximator has been studied, and one tries to determine which factors require larger nets (e.g. Fourier domain sparsity in Barron's theorem, etc.) the interesting thing here would be to determine what geometric properties of the manifold determine the size of the GAN needed  (e.g. curvature, complexity of the exponential map) and potentially how these properties interact with the distribution over the manifold considered. \n\n\n\n\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "N/A",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The paper theoretically investigates whether  generative models can universally approximate any compact smooth manifold.\n\nAlthough I think this paper has some interesting observations, I think it has very little significance for generative models as it ignores the distribution over the image completely.  \n\nI must note that I am not familiar enough with the related work to judge the novelty of this work.\n\nDetailed remarks:\n- The paper claims to talk about generative models, but it actually only talks about GANs. The paper needs to make this clear as this is misleading.\n- One severe limitation of this work is that it only looks at the output set and says nothing about the distribution induced on it by the mapping (or the original). \n- The paper doesn't connect (nor do I think it is possible to connect) the metric used here, Hausdorff distance, to any metric between distributions. Therefore it is not clear what value this results have for *generative* models instead of general neural networks.\n- The question \"In particular, what does it even mean for a GAN to model a distribution?\" is trivial. Any mapping on a distribution induces a distribution on its image. While this distribution might be hard/impossible to compute and evaluate in practice, it is clear what it means for a GAN to model a distribution.\n- I think the analysis is interesting and should be published but under some revision. If the focus is generative models or GANs, then some thought should be made to the distribution, connecting to metrics between distributions and/or saying something even on a uniform distribution over the manifold embedded in R^n. Otherwise, these results might be worth considering in the more general framework of DNN and maybe see GANs as a single instance. \n\n\nMinor details:\n- You assume oriantability, but unless I missed something you do not use this assumption anywhere\n- While the claim that a compact and connected manifold is geodesically complete is a well known, a reference might be nice as this is a different community. \n- Typo in sec. 7 \" is two train two neural networks\" -> \"is to train two neural networks\"."
        }
    ]
}