{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper examines the utility of a sinusoidal representation of timestamps for predicting patient outcomes from EHR data. It uses a representation inspired by the Transformer's Positional Embedding, in this case applied to time and called the Time Embedding. The same idea was recently used in a pre-print called \"TAPER: Time-Aware Patient EHR Representation” on the same task (and even the same dataset). It’s possible that this paper is a followup by those authors or maybe it’s convergent thinking in the field of ML4Health. \n\nIn any case, the idea is relatively simple and intuitively could be useful for certain kinds of temporal events. This paper does a cursory evaluation of its utility on the MIMIC-III EHR dataset and shows that the addition of time embeddings is typically slightly worse than using binary masking of missing time steps. It’s totally fine to arrive at a negative result! However, we should learn more from this evaluation than simply “we tried an idea and it lost to an alternative”. To make this paper successful the authors should evaluate on multiple datasets, evaluate different granularities of time (hours vs. days vs. months), and imitate Lipton 2016 in examining baselines such as forward filling imputation of missing data. As it stands the paper doesn’t add enough to our understanding of when a sinusoidal embedding of time would or wouldn’t help. \n\nUnclear phrasing and/or grammatical nits:\n* \"This makes it harder to learn time dependencies found in time series problems.” — do you mean e.g. time of day of an event or the degree of delay between two events, or some other kind of “time dependencies”? \n* \"The tests were made with two tasks” — maybe better to say that you evaluate on two tasks?\n* \"The problem in focus of this work is how can a machine learning method learn representations from irregularly sampled data.” Repeats introduction, or “The problem in focus of this work” isn’t quite right grammatically. \n* \"even with the sparsity of binary masks.” — is this talking about the low frequency of observed events? \n* \"Despite the improvement an issue about these methods is missing the potential of how the observation time can be informative” — the improvement of what over what? Should this sentence be part of the previous paragraph? \n* \"also proposed a method to improve discretization” — discretization of what?\n* \"Another approach is to make complex models capable of dealing with irregularities” — does this mean models that are somehow more complicated or those that somehow represent sparse time with complex numbers?\n* \"To make the dataset even more irregular we removed randomly part of observed test data” — missing “the”? \n* \"In the length of stay task TEs achieved better results, especially with bigger gaps at the reduced data test” — this should come after some description of figures 3 & 4, since thus far the reduced data results weren’t described.\n\nTypos:\n* “asses” -> “assess” \n* \"were binary masking had a better performance.” -> “where binary masking…\"\n* \"Specially to very irregular time series and high dimensional data” -> “Especially\"\n* \"were TEs can be applied by addition without increasing the input dimensionality” -> “where\"\n\n\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "--- Overall ---\n\nI thought the authors presented a simple, but interesting idea for encoding temporal information as input to a discrete time model; however, I think the paper could use more intuition for why this approach should work and the experimentation does not appear to support use of the method. \n\n--- Major comments ---\n\n1. My understanding of the argument for this approach is that it supports easier learning for the functions we think may be present in our data, however, this is not clearly demonstrated in the paper. In particular, I never fully understood why time embeddings were preferable to simply including absolute time and time deltas. I imagine an argument of the form: \"A common function we might want to learn in health care is f, however, computing f from time deltas requires the network to learn XYZ complex function, whereas when using time embeddings it can be calculated more simply as ABC.\" I recommend using specific examples. There is a lot of extra room in this paper, so you can tutorialize a bit to make your point really clear.\n\n2. The experiments appear to show that using missingness indicators works better in most cases than using time embeddings. If this is the case, then why should I use time embeddings? In general, I try to promote publishing negative results, but since there is no error analysis, I don't feel like I understand why one approach is better than the other. Further, time deltas would seem to be the most comparable approach to time embeddings (certainly they are the most frequently mentioned alternative method in section 3) and should probably be included in the experiments."
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The work is motivated by a real challenge of time series analysis: how to properly embed irregular time series data.\n\nThe contribution seems to transfer positional embeddings to time-series data embeddings. The authors apply the proposed embedding method on two tasks: in-hospital mortality and length of stay prediction.\n\nClarity\nThe background, experiment settings and some frequently used words are not explained well. E.g., what is and how to apply binary masks(BM). Simply saying that “a regular LSTM” and “a self-attentive LSTM” are used as baselines is not acceptable.\n\n\nSignificance \nThe approach described in this paper barely improves the prediction results. The experiments are not solid enough to support the claim in the paper, as well.\n\n\nMinor comments\n- lots of grammar mistakes: e.g. ”As a CNN do not consider... ”(Sec. 3.1, p.2); also sentences above and below eq(1) and eq(2) (p.2).\n- The main manuscript only has 6 pages.\n"
        }
    ]
}