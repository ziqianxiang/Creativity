{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper is rejected based on unanimous reviews.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper presents an algorithm to train neural networks combining sparsity and adversarial training. \nOn the sparsity inducing regularization, the paper proposes using proximal methods. \n\nOn the positive side:\n- The goal is of interest when it comes to real-world applications.  \n- There is an interesting analysis of the weights and how pruning / AT affects them. \n\n\nOn the negative side:\n\n- In my opinion, the introduction messes unstructured and structured. Weight sparsification is associated with structured while I do believe is unstructured. \n\n\n- Related work does not seem very comprehensive. The paper claims novelty on using RGSM to improve performance. How is this different from the formulation used in \"Learning the Number of Neurons in Deep Networks, Alvarez and Salzmann NIPS 2016\".\n\n\n\nExperimental settings:\n- One thing that got my attention is the threshold for pruning weights (1e-15). I think that is not a fair value. There are related works suggesting no loss in accuracy if the threshold is ~1e-5 (y. Sparse convolutional neural networks CVPR2015). I do believe the numbers would change drastically. \n\n- The comparison between ADMM and the proximal is unfair if using that threshold. The proximal has an implicit thresholding Eq. 6. \n\n- What is the goal for the ensembles of the small networks? where are the numbers?\n\n\nMinor stuff:\n- In sparsity and robustness, there are some works missing (as a typo). \n- On the method, there are two parts where I am confused. What is the aim for including all-around Eq. 4? The same with the theoretical guarantees. "
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Summary: This paper presents an observation that Feynman-Kac formalism principled ResNet ensemble [1] yields sparser network weights compared to those of standard Resnet.  Based on this observation, the authors combine the ensemble model with Lagrangian based sparsification methods to obtain sparse and robust models. \n\nPros:\n- Obtaining sparse and robust networks is an important and challenging problem that could be of interest to a large audience.\n- The paper provides an interesting observation that EnResNet [1] yields sparser network weights compared to standard ResNet, and further leverage it to obtain sparse and robust models. \n\nCons:\n- The paper has limited novelty. It has already been shown in the original EnResNet paper [1] that EnResNet is more robust to adversarial attacks. Thus the only additional contribution of this paper is the observation that EnResnet is more sparse than standard ResNet, and combination of EnResnet with sparsification methods.  \n- The paper is not well justified on why one should use sparsifying techniques such as RVSM, RGSM with the Feynman-Kac formula principled EnResnet. The authors state that this enables sparsity to meet robustness; however, in all experimental results, the robustness actually decreases with the increase in sparsity which is opposite to the claims made in the paper. \n- The authors only report robustness on white-box gradient-based attacks. Thus it is not clear whether the method will generalize to black-box/gradient-free attack approaches such as NAttack [2].\n\nMinor comments:\n\n- Why didn’t you report the accuracy on the clean examples? This is important in showing that the method generalizes well to clean examples while maintaining robustness.\n- Why use only 20 iterations to evaluate the attack? Will the model maintain its robustness with the increase in the iteration and epsilon? \n- Figures are not referenced anywhere in the text.\n- It would be better to put the results on CIFAR100 in the main paper rather than in the appendix.\n- Page 2, “lower cases”  -> “lower case”.\n- Page 2, “Related Works” -> “Related work”, it’s better to have it as a separate section.\n\nOverall, while the paper provides an interesting observation, it has limited contributions due to lack of novelty. Further, inadequate experimental validation makes it difficult to see if the claims made in the paper are actually true. Thus I believe that this paper requires substantial improvements in order to be accepted to top-tier publication venues such as ICLR.\n\nReferences:\n[1] Bao et al. 2018, https://arxiv.org/abs/1811.10745 \n[2] Yadong et al. 2019, https://arxiv.org/abs/1905.00441"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "Summary:\nThis paper focuses on the study of sparse neural architectures and efficient DNN compression algorithms for the robust and accurate deep learning. The authors apply relaxed augmented Lagrangian based sparsification algorithms to perform both unstructured and channel pruning for the AT DNNs. By combing with the sparsity merit of EnResNet, their sparsification algorithms further boost the sparsity limit of the AT DNNs, leading to much better robustness and accuracy. Their approach demonstrates superior natural and robust accuracies under several benchmark attacks.\n\nStrengths:\n1 The authors practically apply the RVSM/RGSM algorithms to the AT using robust PGD training, resulting in significantly enhanced sparsity of DNNs, and achieving promising robust accuracies against various adversarial attacks.   \n2 The authors provide the theoretical analysis showing the convergence of the RVSM algorithm.\n\nWeaknesses:\n1 The main contribution of paper is to adapt the RVSM/RGSM algorithms to the AT of DNNs to sparsify the deep model. However, both RVSM and RGSM have already been used as sparsification algorithms for DNNs, and the Feynman-Kac formalism principled DNNs has also been investigated for the purpose of sparsification, thus the contribution is largely reduced and the novelty appear to be limited.\n\n2 For the experiments, the effectiveness of RVSM/RGSM are verified on the variants of ResNet and EnResNet, and there are insufficient comparisons with other cutting-edge compression/sparsification methods to show the advantage of the proposed method.\n\nQuestion:\n1 The author claim that ADMM produce a lot of small weights that cannot be regarded as zero since the norm is large than 1e-15. Is the ‘1e-15’ threshold too small to regard a value as zero?"
        }
    ]
}