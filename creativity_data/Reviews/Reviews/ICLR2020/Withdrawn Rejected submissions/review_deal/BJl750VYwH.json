{
    "Decision": "",
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper proposes an augmented matrix factorization model, which leverages user’ interacted items and item’s interacted users to regularize the modeling of a given interaction. In particular, the proposed AGMF model augments conventional GMF model with 1) multi-hot encodings of historical items and users, and 2) an attention-based pooling layer to dynamically integrate the information of those items and users. Experiments on four datasets show that AGMF can outperform several baselines w.r.t. HR and NDCG.   \n\nOverall, the paper is well-organized and easy to follow. However, I have several concerns as follows:\n\nD1: It seems that the proposed method is inspired by SVD++, which leverages the interacted items of users. Thus, I suppose that the contributions of this paper are to bring this idea for both users and items, and to use attention for a better integration. From this perspective, it seems that the technical contribution is a bit weak, and it lacks critical technical challenges to be addressed. Please elaborate the technical contributions of this paper more clearly.\n\nD2: The explanations about why AGMF would be better than the other MF methods are not clearly stated. In the introduction, some claims can be found, but they are not very intuitive and may confuse the readers, such as\n-\t“the connection between user embedding and item embedding is only weakly enforced by fitting the given individual rating value”. What is the meaning of “weakly enforced” and why?\n-\t“the latent features of a user could be potentially enriched by taking into account the latent features of the user’s interacted items”. How do we know that the user’s interacted items can provide extra information for the user? In conventional MF model, a user embedding itself might be containing the information of the user’s interacted items, as those are fed into the model as training data. As such, what is the benefit of integrating the historical item embeddings, as their information might be already contained in the user embedding. \n-\t“user embedding and item embedding may be interpreted as some high-level descriptions or properties of user and item, which are supposed to have some explicit connections.” If possible, please use examples to further elaborate what are the “high-level descriptions” and “explicit connections”.\nOverall, the authors are suggested to find a more intuitive explanation and draw more insights for the propose model, and better with some experiments to support them. That would be more meaningful than just proposing a model that can beat baselines.\n\nRemark on D2: A possible explanation is that a user’s preference might be complex or having some uncertainties, which can hardly be encoded in a single embedding vector. When having additional historical item embeddings for a user, they can collaboratively reflect more complex user preference. This is similar to using a distribution to represent a latent concept instead of using a point estimate (e.g., an embedding vector). From this perspective, AGMF is better than GMF because it increases the model flexibility. Please feel free to comment or argue this.\n\nD3: The proposed method is not compared with some recent studies:\n-\tEbesu, Travis, Bin Shen, and Yi Fang. \"Collaborative memory network for recommendation systems.\" The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. ACM, 2018.\n-\tTran, Thanh, et al. \"Signed Distance-based Deep Memory Recommender.\" The World Wide Web Conference. ACM, 2019.\n-\tWang, Xiang, et al. \"Neural Graph Collaborative Filtering.\" The 42nd International ACM SIGIR Conference on Research & Development in Information Retrieval. ACM, 2019.\nThese papers also leverage attention to integrate the information from other users or items as well. Please also discuss how the proposed method is different from them and try to include them in the experiments.\n\nD4: Why do we need to filter out both users & items (with interactions<10) for Yelp, but only users for the Amazon datasets?\n\nD5: It is not suggested to use the leave-one-out evaluation method, as it is not aligned with the real recommendation scenarios. It would be better to use all the items as the candidate set, rather than 99 randomly-sampled negative items + 1 positive item.\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The work presents a matrix factorization (MF) framework for enforcing the effect of historical data when learning user preferences in collaborative filtering settings. The key idea is to augment vector representations of users and items with additional terms related to other interactions from the observation history. The standard inner product between entities is then replaced with its generalized non-linear counterpart. The authors use a non-linear AGMF model that incorporates both user and item profiles in a symmetric way and utilizes smart parametrization to learn the corresponding weights of all involved observations.\n\nEven though I generally like the presented approach, I believe the work misses some key points and should be rejected. Most importantly, the conceptual model design has a limited novelty and is basically reinvented. Likewise, the experiments part lacks comparison with appropriate baselines, which raises concerns on actual performance of the proposed approach.\n\nMain argument:\n\nThe authors claim that most of the existing approaches do not take into account additional interactions data and that the only model that provides such functionality is SVD++. This is not true.\nFirst of all, the SVD++ model itself was not the first one to propose such a design. Similar augmentation was implemented in NSVD model by [Paterek 2007] (a user vector was replaced by a combination of all items in user profile). Even though it was simpler than SVD++ it served as an inspiration for later models.  You could simply write the NSVD model in the form SQQ^T, where Q encodes item embeddings and SQ represents user embeddings (no separate user space was learned). Matrix S serves as the design matrix which is essentially the one-hot encoding (can be “multi-hot” using the authors’ term). The SVD++ model can be written in similar way as XPQ^T, where X is a new design matrix, which encodes all user interactions and allows to augment standard scalar product with additional terms. The model can be extended further to XP(YQ)^T with the addition of item-side design matrix Y, which now resembles the AGMF approach proposed in the paper at review.\n\nSuch a formulation is used in a number of models, e.g., SVDFeature by [Chen et al. 2011] or LightFM by [Kula 2015]. Even though they are typically used for hybrid systems (to incorporate side information about users and items), they are perfectly suitable for the considered here task as well. Probably, one of the earliest published work that utilizes such a symmetric design is MatchBox by Microsoft [Stern, Herbrich, Graepel 2009] (they use the notion of user and item traits). Finally, the most general framework for the task is presented by the Factorization Machines (FM) proposed by [Rendle 2010], which is widely used in industry as well as in various recsys challenges. This model has many implementations and should be considered as the default baseline for this kind of work. Excluding models like FM or at least LightFM from comparison makes the work incomplete, especially considering that the authors emphasize the importance of taking interactions history into account by comparing AGMF with a simpler GMF model.\n\nRegarding the source code, it’s nice that it has more or less complete state in a sense that’s it’s runnable with almost no modification. I was able to run it on my GTX 1060; however the training was pretty slow. Note, that even simple and fast SVD-based model can be tuned to provide a decent quality of recommendations, see EigenRec model (for example, compared to other popular models in the RecWalk paper by [Nikolakopoulos and Karypis 2019]). I used the scaling trick from EigenRec (see, e.g., https://www.eigentheories.com/blog/to-svd-or-not-to-svd/ for more details on how to do scaling). I was able to get HR=0.713 and NDCG=0.446 on the Movielens dataset with this modified SVD model. Computing of the optimal result (with rank 128) takes only 1.2 seconds on my 4-years old laptop. The comparable level of HR and NDCG was achieved by AGMF only after approximately 3.5 hours of training (each epoch was taking 6-7 minutes and it required around 30 epochs). In fact, the entire hyper-parameter search time for the SVD-based model took less than 4 minutes, which was dominated by the evaluation time not the model computation time (for any set of hyper parameters you need to compute SVD only once for the highest rank value, as the model with lower rank values can be obtained by a simple rank truncation procedure). This raises the concern in an overall practicality of the AGMF approach. The best score is only 2.5% higher than that of SVD and takes more than 8 hours to get (on GTX 1060) vs. 1.2 seconds for SVD (computed on 4-core CPU). Recommender systems is a very applied field. Hence, the complexity analysis as well as computation time comparison should also be part of the work. Potential scalability issues should be explicitly explained and not left for the readers to discover. \n\nThings to improve the paper that did not impact the score:\n\n1) Have you tried to work with the version of NeuCF that is modified the same way as AGMF?\nNeuCF provides the general framework that also allows to incorporate interactions history into inner product computations via “feature vectors”. According to the authors, NeCF > GMF, which means that potentially NeuCF with extended user and item description, similarly to AGMF, could also perform competitively. I believe, it would make the work better from the perspective of fair comparison.\nIt’s important to note, however, that there’s a certain evidence that recent neural network-based approaches do not actually outperform simpler linear models, see work by [Dacrema, Cremonesi, Jannach 2019] on “A Worrying Analysis of Recent Neural Recommendation Approaches”. For example, NeuCF was not better than SLIM and in some cases even worse than KNN-based models. It would be better to add at least some of this baselines into the comparison.\n2) Accordingly, I’d like to see the source code for entire experiments showing how experiment is conducted, how baseline models are tuned, etc. The source code attached for the review only contains basic training for one dataset and only for AGMF model.\n3) Recommender systems data is noisy. It’s hard to make a reliable comparison of models without an analysis of statistical significance of different results. I would suggest to employ a different evaluation strategy with user-based k-fold cross validation (each fold consisting of 1/k fraction of users). This would allow to report confidence intervals for your results and demonstrate reliability of your conclusions.\n4) I believe the term “multi-hot” encoding is misleading. FM also uses the same representation; however it’s still called “one-hot”.\n\nReferences:\nPaterek, Arkadiusz. \"Improving regularized singular value decomposition for collaborative filtering.\" In Proceedings of KDD cup and workshop, vol. 2007, pp. 5-8. 2007.\nChen, Tianqi, Weinan Zhang, Qiuxia Lu, Kailong Chen, Zhao Zheng, and Yong Yu. \"SVDFeature: a toolkit for feature-based collaborative filtering.\" Journal of Machine Learning Research 13, no. Dec (2012): 3619-3622.\nKula, Maciej. \"Metadata embeddings for user and item cold-start recommendations.\" arXiv preprint arXiv:1507.08439 (2015).\nStern, David H., Ralf Herbrich, and Thore Graepel. \"Matchbox: large scale online bayesian recommendations.\" In Proceedings of the 18th international conference on World wide web, pp. 111-120. ACM, 2009.\nRendle, Steffen. \"Factorization machines.\" In 2010 IEEE International Conference on Data Mining, pp. 995-1000. IEEE, 2010.\nNikolakopoulos, Athanasios N., and George Karypis. \"Recwalk: Nearly uncoupled random walks for top-n recommendation.\" In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, pp. 150-158. ACM, 2019.\nDacrema, Maurizio Ferrari, Paolo Cremonesi, and Dietmar Jannach. \"Are we really making much progress? A worrying analysis of recent neural recommendation approaches.\" In Proceedings of the 13th ACM Conference on Recommender Systems, pp. 101-109. ACM, 2019."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "In this paper, the authors study a recommendation with users' implicit feedback towards items, which is formally defined in Section 2.1. In particular, the authors extend generalized matrix factorization (GMF) and design a dual version of GMF, which is shown in Figure 1. The proposed model is called augmented GMF (AGMF).\n\nEmpirical studies on four public datasets show the effectiveness of the proposed model, i.e., AGMF. Overall, the paper is well presented and easy to follow.\n\nSome comments/suggestions:\n\n1 The novelty of the proposed model is a bit limited from the perspective of combining two GMFs together in a dual manner.\n\n2 For the empirical studies, some details about the parameter configurations are not sufficient enough for reproducibility, e.g., for BPR-MF and SVD++. Moreover, some strong baseline methods are not included such as CDAE [WSDM 2016] and Mult-VAE [WWW 2018]. Hence, the results may not be very convincing in the context of the state-of-the-art recommendation methods with users' implicit feedback.\n\n3 The dual form of GMF may cause efficiency problem especially for the right part in Figure 1, because there may be many users who have interacted with a certain item. The authors are thus suggested to include some analysis or empirical studies on time complexity or time cost.\n\n"
        }
    ]
}