{
    "Decision": {
        "decision": "Reject",
        "comment": "Perturbation-based methods often produce artefacts that make the perturbed samples less realistic. This paper proposes to corrects this through use of an inpainter.  Authors claim that this results in more plausible perturbed samples and produces methods more robust to hyperparameter settings. \nReviewers found the work intuitive and well-motivated, well-written, and the experiments comprehensive.\nHowever they also had concerns about minimal novelty and unfair experimental comparisons, as well as inconclusive results. Authors response have not sufficiently addressed these concerns.\nTherefore, we recommend rejection.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper proposes to improve perturbation-based explanation techniques by complementing the perturbation step with an inpainting step that removes artefacts caused by it.\n\nThe approach is sound and intuitive.\n\nThe authors show the flexibility of their approach by applying it to a variety of perturbation-based attribution techniques.\n\nIt is unclear what is the computational cost of the inpainter. Perturbation-based explanations are generally quite slow due to having to evaluate the function many times, and therefore a further slowdown could harm practical use. I'm curious whether the inpaiting approach could be in some way also extended to faster explanation techniques (e.g. gradient-based, or propagation-based).\n\nEvaluation experiments are not fully conclusive. Bounding box experiments are rather indirect and the deletion/insertion metrics do not systematically show the performance improvement of using inpainting. Perhaps the deletion metric should have been equiped with inpainting as well in order to avoid deletion artefacts. (See e.g. Samek'17 MoRF / LeRF experiments where various perturbation schemes are tested for deletion).\n\nThe evaluation benchmark is restricted to perturbation-based approaches. It could have been useful to broaden the comparison to non-perturbation approaches.\n\nAn experiment I found particularly interesting is the robustness to perturbation hyperparameters. Given the difficulty of designing evaluation metrics that can support hyperparameter selection, hyperparameter insensitivity is indeed strongly desirable.\n\nI'm wondering whether it is really necessary to use a strong deep neural network inpainter since the goal is just to remove artefacts. Some inpainters provided as part of standard computer vision libraries work quite well, and do not need to be trained and adapted to a certain shape of missing data.\n\nOverall, the paper presents an interesting and sound approach to improve perturbation-based explanations. Experiments are extensive, although some of them remain so far not fully conclusive."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper is focused on perturbation-based local explanation methods; methods that only need black-box(ish) access to the model and generally seek to find a region, pixel, etc's importance score through by removing that region, pixel, etc.. The intuition is that an important region if removed, will result in a large drop in the predicted class confidence. One main issue with such methods is that the removal itself can throw the image out of the data distribution and therefore result in a drop in confidence, not because of the region's importance, but because of the network's unpredictable behavior in such unseen parts of the input space. The work is focused on giving a solution to this problem: instead of removal through blurring, graying, etc, use inpainting; i.e. replace the removed region with using given the rest of the image. The idea has already been discussed out in the literature and the novelty of the work seems to be twofold: They introduce the same method in a way that is not curated for a specific perturbation-based method and could be concatenated with \"ANY\" given (or future) perturbation-based local explanation method (which authors notate by calling it ${existing_method}-G, they study robustness to hyper-parameter choice. \n\nThe paper is quite well written and the experiments are comprehensive. I have two major comments/issues with the work:\n\n1- The contribution of this work given existing work (more specifically the famous Chang et al work seems not to be enough for a venue like ICLR. If I want to list the contributions, it would be as follows (I would appreciate if the authors could correct me as the score is subject to change given more clarification on the matter):\n    - This work utilizes an inpainting step in combination with several methods while previous work is focused on meaningful perturbations method. This, although useful, does not introduce a novel technical contribution. The main technical contribution has been the use of inpainting (to be more exact, using generative models to approximate P(c|x_r)) which has been done before on a few previous works.\n    - The work argues that the use of inpainting in Chang et al (focused on keeping the salient object and removing background) was invalid as the inpainter model is not trained to do such a task. It could be argued that one could train another inpainting model that \"is\" capable of such a thing and therefore the general argument would not hold. One drawback of this approach, however, would be that training such an inpainting model might be difficult.\n    - Hyperparameter robustness. Studying this question is valuable. However, given that the assumption of this work and previous works is that generative approaches are generally better (even not considering the hyperparameter robustness), I am not sure how this knowledge could be used.\n\n2- Both this work and the previous works run on the assumption mentioned at the beginning of this review which basically says that non-generative perturbation-based methods throw the image out of data distribution and this is bad for such and such reasons. Although intuitively clear, I could not find any evidence in this work suggesting any meaningful difference using objective measures. One would assume that such phenomena would manifest itself clearly using insertion-deletion explanation metrics while as the authors report there was no significant difference. (Section 4.1 results clearly show a difference but this is not related to how the downstream explanation task is affected) For all it is know, generative methods have the drawback of being computationally more expensive than a simple blurring or replacing with random noise. (And a major elephant in the room is whether using an inpainter is actually taking the data back to the true data distribution which seems to be on an unproven assumption that these generative models are capable of learning the data manifold)\n\nMinor comments:\n    -Section 4.2 is really interesting. Thanks!\n    - Fig 3 results: MP is more robust than MP-G and I couldn't find any explanation of why this method behaves specifically different than the other two in the experiments section. It might be better to move the explanation in the discussions to the experiments.\n    - The task of most generative perturbation-based methods is to find a way to approximate P(c|x_\\r) which is the conditional probability given the non-removed part of the image. Usually, they do the approximation by sampling several images from the conditional P(x_r|x_\\r) (conditional inpainting)  using the generative model and averaging the prediction probability. This work seems not to be concerned with these specifics and directly feeds one of such samples. Could you explain this choice\n    - For studying the robustness of LIME, apart from the random seed, couldn't one change the hyperparameters of the superpixel method? Tha one seems more of a practical problem."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes a deep visualization technique for black-box image classifiers that feeds modified versions of the original input by means of an off-the-shelf (black box too) image inpainting approach (DeepFill-v1), in order to capture changes in the classification performance. In particular, the substitution of the input image follows three published paradigms: Sliding Patch (SP), Local Interpretable Model-Agnostic Explanations (LIME), Meaningful Perturbation (MP). Whereas the states of the art use gray images (SP, LIME)/blurred versions (MP) as substitution on different spatial supports (regular patch SP, random-shaped superpixel regions LIME, learned continuous region MP), the proposed approach inserts there the output of the inpainting.   \nThere are problems in the paper, major and minor.\nMajor: \n1)\tThe technical contribute is minimal, the author combine two already existent techniques.\n2)\tThe results are not convincing: a) the comparison are not fair, since on two out of three techniques the authors consistently change the competitors, letting them work with zero-value occluders or random noise. Only the third competitor has been employed in is original form (blurring the images). b) results are better (higher classification drop, plus other metrics) with the proposed approach wrt the first two competitors, which looks strange. Can the authors try to apply the comparative approaches in their original versions?\n3)\tThe fact that we are using an inpainting tool which may work in some cases (in providing well-distributed patches) but in other may fail, corrupting consequently the overall following analysis is a price I don’t want to pay, so I prefer some synthetical but controlled artifact. Actually, in the case of inpainting failure will generate structured noise, hard to be managed.   \nMinor/improvements\n--In the introduction the authors should spend a little more two or three words in explaining on which basis Adebayo et al. 2018 questions the correctness of the heatmap, since this is something on which the authors are building their hypothesis.\n--The title is misleading, the authors are talking about generic feature removal but in reality we are considering the image domain only.(check)\n--Figure 1’s caption should report the references for the three SP LIME and MP\n"
        }
    ]
}