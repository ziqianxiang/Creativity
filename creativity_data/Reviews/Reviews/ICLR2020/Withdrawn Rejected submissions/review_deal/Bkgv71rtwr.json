{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper introduces a new method of open-set domain adaptation, which exploits Self-Ensembling with the category-agnostic clusters in the target domain. Firstly, the proposed pipeline performs clustering to decompose all target samples into a set of category-agnostic clusters. Secondly, an additional clustering branch is integrated into the student model to estimate cluster assignment distribution. By aligning the cluster assignment distribution to the inherent cluster distribution via minimizing their KL-divergence, the feature representation is enforced to preserve the data structure of the target domain. Finally, the mutual information among the feature map, classification, and clustering assignment distribution is maximized to enhance the feature representation. \n\nAlthough the classification performance is better than the baseline methods, this paper should be rejected because (1) this paper is not well organized and a bit hard to read, (2) the proposed pipeline is ad -hod and complicated, and there are a lot of hyperparameters to tune. \n\nMany important terms and concepts are used without explanation in the first half of the paper, such as \"student model,\" \"assignment distribution.\" They can be understood if readers read all pages, but it would be better to write it reader-friendly. At least, a short introduction of Self-Ensenbleing is required in Sec.1. Also, motivation to use Self-Ensembling as a base model is not written. The authors should mention the reason why the authors integrate the cluster alignment into Self-Ensembling.\n\nThe proposed pipeline seems ad-hoc. The algorithm is not justified by theory. The authors should state the reason why the alignment of clusters works well for open-set problems more clearly. Mutual information maximization seems a sideshow of the main claim of this paper, and it makes the reviewer feel the proposed pipeline more ad-hoc.\n\nThis paper should cite some articles about prototypical networks and discuss the novelty of this paper referring to them.\nYingwei Pan, Ting Yao, Yehao Li, Yu Wang, Chong-Wah Ngo, Tao Mei. Transferrable Prototypical Networks for Unsupervised Domain Adaptation. CVPR, 2019."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Comments:\nThe authors proposed a method based on self-ensembling and clustering for open-set domain adaptation. The proposed method steers category-agnostic clusters to learn the underlying structure of test samples, which is used as a constraint to learn better representation. Experiments are compared with different baseline methods and comprehensive analysis is carried out.    \n\nPros:\n1. The proposed method incorporates the clustering method into model training to get better representation to keep the original data structure in the target domain.\n\n2. Sufficient experiments are compared with different baseline methods on different datasets. The performance of the proposed method is good in most settings. Especially, on the close-set domain adaptation task, the method is also good compared with baseline methods. Besides, the authors also analyze the influence of different factors on the experimental results. For example, different distance metrics in the clustering branch and different branches in the MIM part.\n\nCons:\n1. The whole framework is complicated and seems a combined method with different existing components. The necessity and importance of different components are not clearly claimed. How to determine the choice of hyperparameters in the unsupervised domain adaptation setting? The performance would be very sensitive and unreliable. There is no sensitivity analysis for performance.\n\n2. For the concept of agnostic clustering, the author may have an incorrect understanding.  In the Probably Approximately Correct (or PAC) learning model, the assumption is that the data distribution over labeled examples is correctly classified by some fixed but unknown concept in some concept classes, e.g., by a linear separator. In the agnostic setting, however, the assumption is weakened to the hope that most of the data is correctly classified by some fixed but unknown concept in some concept space, and the goal is to compete with the best concept in the class by an efficient algorithm.  I suggest two papers involved with agnostic clustering for the authors:\n\nBalcan, M. F., RÃ¶glin, H., & Teng, S. H. (2009, October). Agnostic clustering. In International Conference on Algorithmic Learning Theory (pp. 384-398). Springer, Berlin, Heidelberg.\n\nKothari, P.K. and Steinhardt, J., 2017. Better agnostic clustering via relaxed tensor norms. arXiv preprint arXiv:1711.07465.\n\n3. Technically, I got lost on Eq. (3), which also is a very important step in the proposed SE-CC framework. How do the authors perform clustering? Why do the authors use such an update policy for centres? If it follows the k-means model, the centre update policy needs to be reproduced after you use a different metric function.  However, I found the authors still used the average value update policy. It is very strange and unclear.\n\n4. For the main technique equation (5), it is very sudden that the authors use KL to do minimization. If the number of $x_t$ is small, the L_KL may lead to a small value. There must be enough samples for the following optimization. However, the sample numbers of x_T^S and x_t is unclear.\n\n5. The writing may be improved and some parts are not clearly explained. For example, \n1) in the 'Summary' part of section 2, \"The structure preservation enables effective alignment of sample distributions within known and unknown classes\"; \n2) It would be better, if the A -> D, A -> W and others are explained in the caption of Table 1.\n\nQuestions:\n1. In the introduction part, the authors claimed the binary classifier cannot get good performance because of ambiguous semantic labels between known and unknown classes. Why is the clustering method able to tackle the samples with ambiguous semantic labels? Do the authors have any proof?\n\n2. In figure 2, 1) Is the MI maximization discriminator is necessary? The authors claimed that this constraint can enhance the learned feature representation. What does 'enhance' mean? 2) How can we understand the results (real or fake) of Mutual Information Maximization after the discriminator? 3) How can you choose the input image \\hat_{x}_t^S?  Why do you need the MI constraint between only one image and the input image, not between all the other images(excluding the input image only) and the input image? \n\n3. In MI optimization, a global and local strategy is applied. It is unclear why the authors use these steps and what are their convergence conditions and results?\n\n4. The authors claimed that \"Hence, the learned feature representations are enforced to be domain-invariant for known classes and meanwhile more discriminative for unknown and known classes in target domain\". How can you guarantee this? I can not see why the representations are more discriminative for unknown and known classes in the target domain.\n\n5. In table 2, 1) why is the performance of different classes so diverse? Some are around 90%, some are around 10%. 2) SE is better than the proposed method in many classes. Could you explain more?\n\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The paper introduces a new approach to open set domain adaptation, where the source domain categories are contained in the target domain categories. The overall goal is to filter out outlier categories in the target domain and enable adaptation within the shared classes.\n\nThe paper employs the self-ensembling student-teacher model for the closed-set domain adaptation part. However, the paper does not explain how this part contributes to the open set domain adaptation part. It just copies the previous method without sufficient motivation. This should not be considered as a contribution of the paper.\n\nWhat distance measure is used in the K-means algorithm is not introduced. The similarity measure between data points and centroids is cosine distance. It should be consistent with the distance measure in the K-means algorithm.\n\nThe paper uses features from the pre-trained model on ImageNet for clustering. However, when the target domain deviated from the ImageNet much and there is no model pre-trained on large-scale data related to the target domain, the features are not reliable and may induce large clustering errors. Training the clustering branch on such wrong clustering assignments is sub-optimal. Could the authors provide a solution to such a situation?\n\nThe mutual information maximization part is the major contribution of the paper. It employs both global and local mutual information and uses adversarial learning to enforce each feature to match the class probability and cluster assignment. This part is novel to the open set domain adaptation problem.\n\nThe classification results on several datasets show that the proposed method outperforms previous methods. However, the method uses the self-ensembling technique, which is not used by previous papers and not the contribution of the proposed method. It should be better to compare with previous methods by modifying their closed-set part with the ensembling model.\n\nThe ablation study part is not that convincing. It cannot reveal the relationship between different parts of the method. From the results, we do not know how the CE, KL and MIM parts influence each other. For example, the MIM may rely on KL and CE since we need good P_{clu} and P_{cls}. It should be better to show when removing one part from the method, what is performance.\n"
        }
    ]
}