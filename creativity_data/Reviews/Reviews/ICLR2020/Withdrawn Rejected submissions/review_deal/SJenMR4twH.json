{
    "Decision": "",
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This work is about Deep Neural Network Models with interpretable components. The authors replace network input with outputs of predefined (manually selected) filters, e.g. sharpening, embossing, color and edge filters. Experiments done on MNIST and ImageNet verify that the proposed architecture has comparable/slightly better performance than original network structure. \nStrength:\n1. Handcrafted features + CNN concept is not new. Many believe this typical structure can hardly lead to good result. This paper explains deteriorated result is mainly due to badly selected filters. If the filters are selected well, comparable performance can be achieved. \n2. The paper also design method to obtain filter score which can indicate the contribution of a typical filter to the final classification result. It provides a direct way for people to understand the relationship between image attributes and the classification result.  \n\n\nWeakness:\n1. It is necessary to verify whether the network is applicable to various tasks, e.g. detection/segmentation. However, limited experiments are done in this work. \n2.  As the pre-defined filters can only extract low-level features, the framework can only learn the impact of the superficial features, e.g. color, edge to the final classification result. It is doubtful that this architecture can be used interpret the contribution of high-level abstract features. \n3.  Authors have shown that number of filters can directly affect the final classification performance. However, they did not analyse the contribution of different types of filters to the results. \n4. Image outputs of sharpening and blurring filters preserve most visual information of the original image. If remove the two filters, will the final classification results differ very much? If replace this two with the original image, what will be the result? \n5. Normalized random filter provides the best result, but little analysis and discussion are done to explain why it is the best. How many random filters are used? What's the similarity/difference between random filter + CNN and CNN with first layer fixed with initial weights?  \n\nThis paper does not verify the effectiveness of the architecture on various types of computer vision tasks, e.g. detection/segmentation. It also misses important analysis of contribution of different filters to the performance.  The proposed network can only help us to interpret the impact of superficial features, e.g. color, edge and shape to the classification result. This may not work for tasks when low-level feature dose not perform well, e.g. large-scale face recognition task.  \n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "=== A. Summary ===\n\nThe paper proposes to hand-design (as opposed to learning) the 3x3 kernels in the very first layer of an image classifier CNN to be the well-known kernels that perform sharpening, embossing, blurring, and edge detecting, etc.\nAfter that, the network is trained to perform image classification (i.e. these kernels are kept frozen and only other layers' parameters are updated during training) on MNIST or ImageNet.\nThe authors argue that the hand-designed kernels are well-understood and showed qualitative examples of how they can be used to interpret what filters are often used to classify which class of images.\nAdditionally, the paper shows that the integration of the hand-designed filters almost kept the network accuracy unchanged.\n\n\n=== B. Decision ===\n\nReject.\n\nI vote for Reject because the work here, i.e. replacing the 1st layer 3x3 filters with the hand-designed ones, does not provide any new or surprising insights into what we have already known about the first layer kernels of CNNs or CNNs in general.\nIt has been since 2012 that Krizhevsky et al. showed the 1st layer filters learned during the training already learned Gabor-like filters and kernels that detector colors.\nThat is, they are already quite interpretable from human perspectives.\nCan't one reproduce this paper with the learned filters and draw similar insights?\nThe choices of the hand-designed kernels in the paper are arbitrary i.e. not supported by any reason.\n\n\n=== C. Suggestions for improvement ===\n\nInterpreting CNNs is an important quest and designing interpretability into CNNs is a viable approach!\nHowever, I suggest the authors seriously think about the motivation of the work i.e. focus on identifying what questions are not well-understood in CNNs and how your methods answer those questions."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper proposed a method to introduce interpretable components (basically pre-defined image filters) into a deep neural network by essentially replacing the first layer trainable filters by well-known pre-defined kernels in image processing (e.g., edge detection, blurring, etc.) The authors also defined a \"filter score\", which measures the importance of those pre-determined filters for a given image, aiming to increase the interpretability of the DNN.\n\nOverall, I want to say the paper is poorly written, and the contribution claimed by the authors is insignificant. My reasonings are as follows.\n\n1) The caption of Figure 1 does that match the figure and the text, which causes confusion right from the start.\n2) The definition of filter score in 2.1.3 is extremely confusing: what is the difference between filter scores and \"each kernel's important score\"? Also, what does it mean that \"K is a group of indices belong to the 37th kernel? Should there be only one 37th kernel? If I understand it correctly, the input image (of size 1x28x28) is first convolved with, say, 40 pre-defined filters, which produces a first-layer feature map of dimension 40x28x28. Than is the 37th filter score a scalar or a number? Is it the sum (over every pixel) of the salient map of the 37-th output-channel of the first-layer feature map?\n3) The authors claimed that replacing the first-layer of a DNN with enough pre-determined filters does not decrease the accuracy of the network. This is not a surprise, and also, in my opinion, does not contribute significantly to this field.\n\nBased on the above reason, I do not recommend accepting the paper for publication."
        }
    ]
}