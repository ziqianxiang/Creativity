{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Summary\nThe paper follows up on some recent dispute, which centrally uses diagrams of the information plane to support claims with empirical evidence. These diagrams are essentially showing estimates of the mutual information between a neural network’s input and a specific layer’s activations (typically on the x-axis) and mutual information estimates between the true label and layer-activations (y-axis). Since these two terms are traded-off in the information bottleneck objective, one could easily draw visual conclusions about neural network training approximately following some information-bottleneck objective. This would be an interesting finding, since typically unregularized neural network training via “plain” stochastic gradient descent (SGD) is investigated, and it is not at all trivial how this would naturally induce an information-bottleneck objective. Unfortunately, as has been reported before, mutual information estimation methods typically employed strongly depend on the binning chosen (to estimate discrete probability mass functions). Additionally there is some conceptual criticism, essentially the issue that discrete, deterministic neural networks are invertible (especially with softmax, tanh or other sigmoid activations) - as such the quantities shown in the information plane should be constant, regardless of the layer.\nThis paper aims at shedding some more light on these issues, by performing a series of experiments where e.g. the bin-size, or the activation-composition across layers is varied. Additionally the paper investigates whether salient “kinks” in the information-plane trajectories can be related to early stopping, or “perfect” stopping. Finally, the paper performs some very exploratory experiment on pruning neural network layers, based on the information plane diagrams.\n\nContributions\ni) Information-plane diagrams for different bin-sizes and both tanh and ReLU activations, and combinations of the latter two, using datasets used in previous publication to allow for easy comparison (and reproduction of some results).\n\nii) Experiments to see whether points in training selected by early stopping (validation accuracy starts decreasing again?) or “perfect” stopping (validation loss starts increasing again) correspond to characteristic kinks in the information plane diagrams (which indicate the onset of the compression phase).\n\nQuality, Clarity, Novelty, Impact\nThe reasons why neural networks are able to learn representations that generalize well are currently not understood, but the question is receiving increasing attention in the recent literature. Several authors have proposed that SGD (in combination with neural networks) might have interesting, automatic regularization properties that favor weight-configurations that not only minimize training loss, but also generalize well. Showing that SGD dynamics “naturally” optimize an information-bottleneck (IB) type objective would be a breakthrough result in understanding neural network training. As such, the topic is highly timely and of large potential impact. This paper aims at adding another piece to this puzzle by clarifying some of the issues with empirically verifying a connection between SGD dynamics and the IB objective. Unfortunately, I think that the current paper is not ready for publication. My main issue is that the large parts of the paper are very hard to follow, many parts are quite hand-wavy and sometimes plain wrong. Instead of clarifying and summarizing the recent dispute, the current paper causes more confusion and often simply re-iterates arguments that have been made earlier. There are some promising bits, but the paper currently looks fairly rushed and unfinished and I am convinced that it would benefit from some thorough polishing. If this were done properly, the paper could serve as a nice summary, and entry-point, to understand the scientific debate that spans several other publications. There is much that could be discussed/added to the arguments brought fore in previous publications and how to move forward with some of the findings / or how to try and alleviate issues with mutual information estimation, but this seems beyond the scope of the current paper.\n\n\nImprovements\na) The paper needs at least one or two more passes to de-clutter and clarify. Also sometimes the context (reported in previous papers on the issue) is completely missing - I think the introduction could be substantially improved. Other parts, for instance Section A in the appendix, are quite imprecise at best, sometimes borderline wrong (unless the reader familiar with the subject adds a lot of interpretation in favor of the paper).  See my comments below for some more specific sections and parts that need improvements.\n\nb) The paper would strongly benefit from a clear goal. Is it either to summarize the previously reported debate and reproduce all results in one publication? Or is the idea to propose better ways of estimating discrete mutual information from samples? Is the paper arguing in favor of using information plane diagrams as proposed by Schwartz-Ziv & Tishby and relating them to early stopping and/or some network compression algorithms, or is the paper arguing in favor of dismissing the trajectories in the information plane as (not very meaningful) artifacts of estimating discrete mutual information while it should actually be constant? Depending on the answer to each of these questions, the paper would need different kinds of (major) revision.\n\n\nComments\n\ni) P3, First paragraph, last sentence. I cannot follow the sentence, please clarify/rewrite.\n\nii) There are several occasions where the paper claims that smaller bins make mutual information estimation more reliable. I agree with this in the case of having infinitely many samples from a distribution (or the parametric form of a continuous PDF, as shown in the illustrations in the appendix). Under what conditions does this statement hold true when estimating discrete PMFs from a (small) number of samples?\n\niii) Page 4, first paragraph. What are the “2 compression phases”? Is there not only a single compression phase (after the “kink” when the mutual info with X decreases rapidly)?\n\niv) Page 4, first paragraph. When describing results shown in the figure please mention which particular trajectory is being referred. Otherwise the description is quite hard to follow.\n\nv) Section 2.3. The whole discussion in the section (and the experiments) should be fairly obvious to anyone vaguely familiar with (discrete) information theory - one important part is the criticism that tanh neural networks are essentially invertible, leading to constant MI. The other important part is that activations tend to cluster more and more strongly during training (Fig. 5), which explains the difficulty of choosing a good binning scheme. I personally think that the whole section can be significantly shortened (to about half a page, max. 1 page).\n\nvi) How was Figure 4 produced? What does it mean that the bins were “tracked”? Please explain this (to a degree where it can easily be reproduced). Also, what does it mean that “it is from a different notebook”?\n\nvii) Describe precisely what “early stopping” and “perfect stopping” mean.\n\nviii) Figure 7 could be shown in a single panel (b, bottom right) where the time-points for early, and perfect stopping are marked with different vertical bars.\n\nix) The whole section A in the appendix needs improvement. E.g. entropy is not a measure of disorder, KL divergence is not really a distance measure (in the strict sense), the case where the info bottleneck produces a minimal sufficient statistic is for infinite beta (no capacity constraint), most of the framework is concerned with constraints that imply insufficient capacity (same is true for rate-distortion which is the basis for IB and THE framework for lossy compression, i.e. non-invertible channels).\n\nx) Figure 9, Appendix B. What is the difference between the two panels (and what’s the difference to Fig 2a)?\n\nxi) Appendix G. The text description is currently hard to follow, but might be really important for readers who want to understand the dispute."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper present a study on the \"mutual information plane\" during training of neural networks. They concentrate on the effect of a binning procedure, the different actications (relu vs tanh), the effect of noise, early stoping, etc... \n\nIn my opnion, this paper should be rejected because (1) the bining approach make it such that only very small system can be studied, therefore limiting drastically the conclusion that can be done. (2) the paper simply repeat, with more care, some simulation from Tishby and al, and Saxe et al, without much new results.  (3) the paper is ignoring some key results for Mutual Information (see below).\n\nHere are some more precise comments:\n\n* All the  works in the \"bottleneck story\" focused either on small network models with discrete (continuous, eventually binned) activations, or on linear networks. It is hard to see how any of the conclusion can be generalised to anything sensible, and the present paper is working in the same regime. Even if we know what is going on in this simulation, and could understand the effect of binning,  how this can be relevant to deep learning and estimating mutual information in high dimensional problem is unclear. The simulations presented here, in particular, seemed very incremental w.r.t. Saxe and Tishby's\n\n* The work of Gabrie et al seems to be unknown to the authors. In  \"Entropy and mutual information in models of deep neural networks\", in NeurIPS 2018, rigorous results were given for the mutual information and entropy in deep neural networks, as well, as computations of the flow of the Mutual Information. These results showed, for instance, that a wide possibilities of behaviour could be observed, not all of them consistent with the Bottleneck story. Additionally, this paper also showed that compression WAS definitely possible with sigmoid network.  Note that this work computed the MI without any binning thanks to (rigorously proven) replica formula. \n\nWhen computing the effect of binning, etc... it would be natural to compare, again, to some of the rigorous predictions. Since this work was published, I am a little bit skeptical of any claims of computing \"the MI\" right when it is not confronted with the  exact results.\n\n* The most interesting fact seems to be that information plane tracks the clustering of activations. But this is, as the authors pointed themselves, a message sent by the previous paper by Goldfeld et al.\n\n\n\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Summary\n===========\nThis paper reevaluates the claims made in the debate around Information flow in deep neural networks. Schwartz-Ziv & Tishby (2017) introduced the Information Bound(IB) theory of deep learning with three claims: training of deep learning models occurs in two phases: empirical error minimization (ERM) and representation compression, the generalization performance of deep neural networks can be attributed to the representation compression, and the compression phase occurs due to random diffusion by SGD. However, these claims were refuted by Saxe et al. (2018). Later, Goldfeld et al. (2018) showed using elegant formulation that IB methods were measuring information about clustering of the internal layer representations and not compression. Evaluating the claims made by the papers mentioned above among others, the paper makes the following conclusions: Information plane (IP)is tracking clustering in layers, which in turn is affected by bin size. Mutual Information for discrete values is indeed constant on the two datasets evaluated. However, the information plane does not show constant MI due to loss of precision during the process of discretization into bins. Consequently, smaller bin sizes make the layers drift towards a fixed point in the Information plane, showing many differences between the layers in the IP can be attributed to the bin size selection. The aforementioned effect is influenced by the activation function, with a network showing different patterns based on whether the starting layers had ReLU activation or tanh activation. Different performance by ReLU and tanh is possible due to binning at zero done by ReLU. The authors did not find a universal connection between early stopping and perfect stopping in terms of plots along the IP, but find that at least in the scenarios they tested the behaviour along the IP plane of different layers could be used to prune unnecessary layers and simplify the model. \n\n\nPros:\n(1)\nThis paper addresses a topic of high interest to the DL community which was the subject of much debate. It reaffirms the findings made by Saxe et al. (2018) and Goldfeld et al. (2018) about the IB theory for deep learning, and points to where it could be used. \n(2)\nIt includes comprehensive empirical analysis with many supplementary figures, asking follow up questions arising from the conclusions drawn. For example, the authors claim that the differences between activation functions can be attributed to the binning in ReLU at 0 and Clustering tracked by the Mutual Information can be used for network pruning.\n\nCons: \n(1)\nThe paper is not well written, is full of grammatical errors and hard to follow. Terms like “hard IB constraint” are used without definition. Figures are referenced as both fig and Figure and sometimes out of order. The abstract is not summarizing the paper properly and is riddled with errors. The authors need to restructure the text substantially to improve readability.\n(2) \nWhile the reviewers understand the value of independent evaluation of previous claims, especially in the case of a hotly debated topic of great interest, the paper offers limited novelty in findings. Network pruning using IP is the only application offered and it has not been sufficiently explored. For example, it could have been used to investigate redundancy present in well established deep learning models. \n\nMinor comments:\n----------------------------\nAbstract: Information Plain instead of plane\nAbstract: “However, this finding is controversial, which has\nbeen supported by e.g. Achille et al. (2017); Achille & Soatto (2017); Noshad et al. (2018) and denied.” This sentence is grammatically incorrect.\n Introduction: “ Section 2.3 explains why the IP looks the way it does.” This sentence is vague.\nSection 2.1: should be “784-number of classes” instead of “784-Amount of classes”\n Section 2.1: should be “number of bins” instead of “amount of bins”.\n Section 2.1: should be “we chose to use bin size instead ...” instead of “it is chosen to change to use bin size ...”.\nSection 2.2.2: should be “Here we find that TanH-layers make a significant impact on deeper ReLU layers” instead of “ Here there is a significant impact of the TanH-layers on the ReLU-layers findable”.\nSection 2.3: repetition of word mutual.\nFigure 4 Caption: Vague statement: “because it is from a different notebook that did not gather all data at the same time”.\nSection 2.3: “ its filled bins down to two bins - 0 and 1”. Needs a : instead of the -.\nSection 2.3: “multiple zeros and a one” instead of “multiple zeros and one 1.”\nSection 2.4.1: Weird phrasing in sentence: “Therefore, there seems to be a not general connection between compression and the first minimum but no connection to the global minimum.”\nSection 2.5: “We believe” should be replaced by “We postulate”?\nAppendix D: “ The biggest difference is that there is no distinct behaviour for Early Stopping on this dataset.” instead of “The biggest difference is, that there is no distinct behaviour for Early Stopping on this dataset findable” \n"
        }
    ]
}