{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper presents a large-scale automatically extracted knowledge base in Chinese which contains information about entities and their relations present in academic papers. The authors have collected several papers that come from around 38 different domains. As such this is a dataset creation paper where the authors have used existing methodologies to perform relation extraction in Chinese.\n\nAfter having read the reviews and followup replies by authors, the main criticisms of the paper still hold. In addition to the lack of technical contribution, I feel that the writing of the paper can be improved a lot, for example, I would like to see a table with some example entities and relations extracted. That said, with further improvements this paper could potentially be a good contribution to LREC which is focused on dataset creation.\n\nIn its current form, I recommend the paper to be rejected.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper talks about creating a Tech Knowledge Graph of 260 million tripes, with 52 million entities coming from 38 research domains. The authors claim this is the first of it's technology specific Chinese KG, so they claim scale, specificity and list out various aspects that makes this distinct to existing KG's. \n\nA few things that the paper is missing or not written well:\n1. Related work is pretty much just listing existing KG's but no limitations and how those limitations are addressed by this work other than the fact that tech KG is technology specific. By being technology specific how does it help, where is KG being used and what metrics are current KG's fall short etc.\n2. There is no novelty in the way KG is built, so there is no technical contribution to this paper making it a very weak submission for ICLR standards.\n3. There is a huge appendix section with some results and lot of information. It would have been great to distill how KG's are being used in existing benchmarks and either show the value of a tech KG in the metrics/benchmarks or introduce a new metric or benchmark to measure the value of a specific domain KG like the tech KG.\n\nIf the authors can address these issues, the value of the work can increase significantly."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "title": "Official Blind Review #1",
            "review": "I have read the author response, thank you for responding.\n\nOriginal review:\nThis paper presents the extraction of a bibliographic database of Chinese technical papers.  This database could potentially be a valuable resource for the community.  However, the paper is mis-targeted to the ICLR conference, as it does not discuss learning representations or using deep learning (the 36-page appendix does include some material on knowledge graph embedding, but this is not covered in the main body of the paper).  Also, for important tasks like name deduplication, the paper does not discuss or compare against techniques from previous work, and instead proposes a small set of heuristics, which is a sensible approach for building a resource but will not be of interest to the ICLR audience.\n\nThe paper refers to their resource as a knowledge graph, but I would say it is more accurate to call it a bibliographic database (it consists primarily of paper titles, authors, and keywords).  This is very different from the broader KBs and KGs discussed in the related work.  YAGO, Freebase, Cyc, and so on capture a much wider variety of semantic relationships and entity types.  I think re-positioning this submission as being aimed at building a bibliographic database, rather than a Knowledge Graph, would help ensure it reaches the right audience.  Also, targeting a different venue like a digital libraries conference and making a strong case that this set of bibliographic data offers advantages in coverage or accuracy over other comparable resources, if any, would help.\n\nFinally, one of the most valuable features of a bibliographic database is the citation graph, it would be exciting if TechKG could be extended to include citation information.\n\nMinor:\nSection 2, most of these citations should not be shortcites but should be regular full cites.  For example in the first paragraph, Miller (1995) should be (Miller, 1995).\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "\nThis paper introduces a large-scale knowledge graph database called TechKG, which is constructed from a massive repository of academic papers in Chinese. The authors have described in details the process and heuristics in use for constructing such knowledge base, and also reported important statistics and characteristics of the database, including duplicate name, imbalance issue etc. The main contribution is to provide a KG in Chinese, which wasn’t widely available compared to popular languages such as English.\n\nThe paper does not clearly demonstrate experiment showing how this new knowledge graph can be complementary to or benefit existing realm of machine learning tasks. How much does it help improve KG-dependent task in Chinese language, or in multi-lingual setting? Without these experiments, it’s hard to estimate precisely the contribution of the KG database to the machine learning community. \n\nIn Section 3.1, the authors should specify more clearly the source of the journals collected & the representativeness of the repository.\n\nIn Section 3.3, how is the threshold defined to determine the hierarchical relation from k1 to k2?\n \nThe writing can be polished further. Things to improve the paper that did not impact the score:\n\nPage 1: Great progress have been -> great progress has been\nPage 1: most of existing -> many existing\nSection 2, paragraph 4: lack space between `WordNet` and `Miller`, also need adding space between `YAGO` and `suchanek`\n\n"
        }
    ]
}