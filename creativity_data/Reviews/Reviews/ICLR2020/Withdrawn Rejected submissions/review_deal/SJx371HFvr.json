{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper studies the distribution of the activations of the last layer before softmax in classification networks. They argue that cross-entropy minimization is performing posterior inference over the distribution of class labels given the activations. They use this intuition to propose a new loss to train a student network in knowledge distillation and class conditional image generation.\n\nCons:\n- Dropping the norm of w and a is not well-justified and the form of the vMF distribution is based on this.\n- The proposed L_CKD loss doesn't seem particularly interesting. Basically, instead of training the student network with the distribution p(pred label | input), they train it to match the distribution p(pred label | gt label). This is a simpler distribution that provides less training signal to the student. There is no reason why this loss should work better than the knowledge distillation loss.\n- Results for knowledge distillation in Table 2 and 3 are misleading. Usually, the knowledge distillation loss combines the classification loss with KD loss with a regularization term and the regularization term is tuned. So with properly tuned hyperparameters, KD should not perform worse than classification loss alone.\n- Figure 3 suggests that there is no difference between training a student network with a weak teacher network like ResNet-18 vs a stronger one like ResNet-101. This is expected based on the explanation above and not in favor of the proposed loss.\n- The gap between label accuracy in table 2 and the accuracies with wrn models from Anh et al 2019 is big. That suggests a problem in training.\n- Section 2.3: One needs to consider normalizing during training for the intuition about posterior inference to hold.\n- Eq 6 is ignoring the normalization by qj, why?\n- Eq 6: the expectation on the right-hand-side should only over i. What is the expectation inside D_KL? Based on the next paragraph it should be over a."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper studies the distribution of the second-to-last layers of neural networks. The paper argues that, under certain assumptions, minimizing the standard cross-entropy loss of a classification task corresponds to minimizing the KL divergence between the distribution of the penultimate activations and a von Mises-Fisher (vMF) distribution. They assess their assumptions through experiments, and use this interpretation of the penultimate activations as vMF distributions on two tasks: knowledge distillation and class-conditional image generation. They argue that this interpretation outperforms other knowledge distillation methods under domain shift, and report a similar success for class conditional image generation.\n\nThis is an important problem, especially since these penultimate activations have become more frequently used as object representations in downstream tasks. Their result could also help us understand better interpretations of neural networks. The writing is clear throughout, and it's straightforward to read. \n\nThe results are based on assumptions that I will try to list below:\n  * normalizing the penultimate activations does not affect classification performance\n  * the class-specific vectors in the final weight matrix have constant normalizations\n  * minimizing cross-entropy loss is equivalent to minimizing the KL divergence between the penultimate activation distribution and a vMF distribution (i.e. the entropy term in equation 6 is negligible)\n\nIn light of these assumptions, theoretical claims like \"learning the networks with the cross-entropy loss makes their (normalized) penultimate activations follow a von Mises-Fisher distribution for each class\" in the abstract are false; even if the normalization assumptions are true, this is an approximate result, due to 1) no guarantee that the KL-divergence will be zero and 2) the entropy term in Equation 6. Additionally, Equation 6 is only applied to the numerator of the objective in Equation 4, so the objectives aren't equivalent. \n\nThese results are thus necessarily based on approximations and some heuristics. This is not inherently a problem, but I would argue that it necessitates that experiments prove these assumptions to be useful. I find Table 1 to be convincing of the assumption that the weight and activation normalizations are negligible. Figure 1 is also a nice visualization for arguing that penultimate activations are approximately vMF.\n\nThe MNIST experiment in Table 4 is a red flag, since the presented results do not match the results in the HVAE paper. The paper claims the experimental setup is identical to the HVAE paper, so it is concerning that the results do not match, especially since the results in the HVAE paper appear to outperform the proposed method. It is possible that the results in the original paper are not reproducible or that the experiments differ, but this should be stated in the paper, since the natural assumption would be that the baseline was not adequately reproduced. \n\nSmall comment: In Table 2 it is not clear from the figure or the caption that CKD is the method the paper is proposing. It would also make sense to bold the best performing method since you do that for the other tables in the paper.\n\nI like the paper and think the results are interesting, but because they are based on heuristics and assumptions, the paper currently promises too much. This puts the burden on presenting experiments that are convincing of improvement, which is not currently the case with the HVAE experiment. I would be open to changing my score if these reviews are addressed. "
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The authors observe that training with the softmax loss is (approximately) maximum log-likelihood for a model in which each class-conditional distribution on the last hidden layer is a von Mises-Fisher (vMF) distribution.  They claim that this shows that the class-conditional distribution is a vMF distribution.  I do not see this -- very roughly, they have shown that training with soft-max behaves as if this is the case, not that it is the case.  They then propose a distillation method based on this model, and also use the model to motivate a distribution of the seeds for a generative model (specifically a VAE model).\n\nThe experiments whose results are plotted Figure 1 are not described in\nenough accuracy to be reproduced.  I don't see strong evidence from\nthese plots that the class-conditional distributions are vMF distributions.\n\nIt is folklore that the soft-max loss performs multinomial\nlogistic regression with respect to the last hidden layer,\nand back-propagates the gradients to earlier layers.\nSee https://chrisyeh96.github.io/2018/06/11/logistic-regression.html.\nTheir model is like this, except they abstract away the lengths of the\nvectors.\n\nIn Section 4, the propose to distill a model by using a vMF\nmodel based on the last layer to probabilistic model of\nthe distribution of class predictions for a randomly\nchosen member of the class of an example sampled during\nthe student phases.  In constant, the original\ndistillation algorithm uses the teacher model to\nestimate the probability of different classes, for\nthe particular member of the class of a training example.\nThey make a case that using their method improves robustness\nto domain shift.  These results are believable, but\nunderwhelming.\n\nFinally, the use the vMF model based on the last hidden\nlayer as a prior for a VAE that chooses uses a prior of\nthe hidden variables that generates unit-length vectors.\nThis VAE trains on data that includes class designations.\nTaking account of the structure of the classes in this way\nsounds like a good idea to me, and they get slightly better\nresults in this way.\n\nThe paper is written in a clear and engaging way.\n"
        }
    ]
}