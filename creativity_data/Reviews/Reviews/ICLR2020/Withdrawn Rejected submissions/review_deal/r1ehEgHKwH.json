{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "The paper conducts a series of empirical evaluations that compares the performance first-order vs second-order decoders (in a graph NN) for the NLP task of dependency parsing, as a function of dependency length, encoder complexity, and data size.\n\nAlthough I greatly appreciate this type of principled empirical evaluation, which I also think is lacking currently in our field (especially in deep learning), for this particular contribution, I have the following concerns for it to be published at ICLR:\n\n1). The main conclusion drawn by the authors in the introductory paragraphs, i.e., that complicated decoders is needed for big data (especially when dependency length increases) is weakly supported by their experiment results; for example, according to the authors explanation, the reason that the gap between LSTM-2+FO and LSTM-2+SO becomes large as dependency length increases can be attributed to the inferiority of the first-order decoder in finding very long-term dependencies (they imply that the FO decoder cannot fully extract information provided by a powerful encoder like LSTM-2). However, the same trend can be said of the non-neural parser, so to me their explanation is insufficient.\n\n2). Most of the differences between the combinations of encoder-decoder is not significant according to their experiments (for Table 2 and 3).\n\n3). The summary of results at the end of the paper do not add much insight to the current literature; for example, the finding that a LSTM encoder is better than non-neural encoder on large data and vice versa on small data is to be expected."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper empirically analyzes various encoders, decoders and their dependencies for graph-based dependency parsing. Their findings are summarized evidenced by experimental results.\n\nThis paper addresses an important problem and the topic should be of interest to many researchers.  The paper is easy to follow.\n\nThere are some concerns on the paper:\n\n1) The experimental results are valuable, but more analyses and discussions are needed to draw more convincing conclusions.\n\nTable 2 shows that SO is better than FO for LSTM-2 while there is no clear gain for LSTM-1 on the largest treebanks. A similar trend can be observed on the medium sized training data in Table 3. These results are contrary to the assumption that more powerful encoders diminish the necessity of high-order decoding. Given that this was the motivation of the work, the conclusion of the paper, that the data-efficiency of FO and SO may depend on the encoder, is a bit disappointing.\n\n2) SO is better than FO for LSTM-2 but not for LSTM1-1. However, LSTM-3 (or greater) is not even considered.\n\nThe assumption implies that the effectiveness of SO decreases as an encoder becomes more powerful. Up to LSTM-2, the result is contrary to the assumption. I was not sure why LSTM-3 (and greater) was not even considered even if adding more layers had little effect in a previous study. It is very natural to conduct experiments to add more layers until it is observed that the necessity actually diminishes. If it does not diminish, it should provide a new insight."
        }
    ]
}