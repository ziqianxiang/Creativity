{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper presents a method based on Convolutional LSTM that achieves compression of very small resolution images (e.g., 32x32). In this setting it achieves what may be seen as SoTA performance for its class (i.e., recurrent, progressive). The authors also look into applying this method in the setting of distributed source coding.\n\nI think we may want to accept this paper because I have not seen any such work before (though, I have to say I have never encountered distributed source coding problems before; but I have extensively studied neural image approaches).\n\nThe paper uses a framework very similar to that of Toderici et al., and it applies the modified architecture to CIFAR and MNIST (the original method was never tested on those datasets by the authors). In this paper that method is outperformed by the proposed architecture, and results are presented in the case in which multiple signals need to be encoded together. Since I am not familiar with the field of DSC, I cannot comment how important this is for that community.\n\nWith respect to the evaluation on CIFAR and MNIST, I have soem concerns. In particular, most containers (JPEG, JPEG 2K, BPG) have a considderably sized header. When dealing with such small images, this header may take a significant part of the size of the file. I don't see the authors discussing this, and describing how they adjusted the bitrates for those codecs. Moreover, for datasets like CIFAR, JPEG and BPG are not able to operate properly unless they're set to run in 4:4:4 mode (it's by default using 4:2:0, which puts them at a huge disadvantage). Therefore, I don't know whether I can trust parts of the evaluation, since the authors didn't call out any of these issues.\n\nMoreover, it's not clear what PSNR refers to. I can guess that it may be PSNR in the RGB color space, but this is not called out.\n\nThe figures are also poorly labeled. For example, in Figure 4, it's not explicitly said which datasets are used (e.g., I am *guessing* it's CIFAR and MNIST, but it's not clear). The caption for Figure 5 should also be updated, and honestly, I don't think anyone can read the various labels in the charts presented in that figure if printed on a piece of paper, unless they have a looking glass...\n\nI also find it disturbing to be reading an image compression paper with NO COMPRESSED IMAGES SHOWN! I have no idea qualitatively whether this method is any good. In the final version I expect to see images compressed both in the multiple channel setup, and in the single channel setup. I expect to see images compressed with the codecs to be compared against at comparable bitrates, while taking into account to remove the headers and make sure that 4:4:4 mode is enabled, and that a hyperparameter sweep is attempted.\n\nIf this paper is to be accepted, the evaluation section needs to be absolutely clear and all points I mentioned need to be addressed.\n\nOn the novelty side of things, since it's a tweak on an existing method, I am not very excited, and since I know nothing on DSC, I can't comment on the novelty in that area. I'll defer that judgement to the other reviwers, who hopefully have more insight into this than I do.\n\nOverall, I think it's an interesting twist on an existing type of method, and may be worth publishing ASSUMING that the authors address the problems I mentioned earlier."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "The authors propose a method to train image compression models on multiple sources, with a separate encoder on each source, and a shared decoder. The model is based on a recurrent image compression network. The main difference from a standard image compression network is that it has multiple copies of encoders and at training time, it optimizes on all sources jointly. The experiments are conducted on the CIFAR10, MNIST, and Kodak dataset. It shows that the method works slightly worse than jointly training all sources, and clearly outperforms training separate models.\n\nThe paper is clearly written and easy to follow. The proposed method is simple. \n\nMy main concerns are regarding the experiment results: \n1. The experiments are conducted on a not very realistic setting of splitting CIFAR10 and MNIST by class labels. First of all these datasets are small, simple, and low-resolution. Second, by splitting by the labels, the sources are still highly correlated as they are collected from the same distribution. Jointly training multiple larger datasets that show more diverse properties would make the results more convincing. \n2. I don't find the motivations of training multiple encoders clear. Given the fact that jointly training on a larger dataset typically gives a better performance, it's still not clear when we would want to train separate encoders. An extended discussion would help.\n3. I found the results not very surprising. The observations that a jointly trained model sees more examples, so performs \nbetter seems expected  (particularly when the dataset is small). \n4. The technical contributions are light-weight. Using multiple copies of parameters for different data distributions is used e.g., in multi-task learning and domain adaptation literatures. \n\nOverall I think this paper would benefit from improving the experiments and providing better supporting evidence for demonstrating practical value of the system."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposed a distributed recurrent auto-encoder for image compression that uses a ConvLSTM to learn binary codes that are constructed progressively from residuals of previously encoded information. Experiments show that the proposed model achieved better PSNR than other compression auto-encoders and algorithms. The paper claims distributed representation has advantage for image compression.\n\nThe idea in the paper is a good one, except for the part about \"distributed\". 2 main concerns here:\n\n1. The paper uses the word \"distributed\" to mean multi-source or clustered data inputs. This is different from what the deep learning community normally means, and the paper has the risk of misleading readers without clarification or using a different terminology. Why not multi-source / multi-modal?\n\n2. By analyzing figure 4 and figure 5 together, it seems that the PSNR results are similar between multi-source / clustered data and normal auto-encoder. The paper mentioned that the multi-source model may have advantage over information corruption and balance between encoder/decoder model sizes, but no experiments are shown to demonstrate that. This rendered the motivation of the whole \"distributed\" part unclear.\n\nSince the \"distributed\" seems to occupy a significant portion of the paper, I vote for rejection based on the current manuscript."
        }
    ]
}