{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Attention models has been extensively used to achieve state-of-the-art performance in computer vision and natural language processing. This paper identifies a problem that the attention weights in the standard models tend to concentrate on single or very few locations which fails to reflect relations between entities. The main contribution of the paper is to introduce a relation module in the neural network's architecture and a relation loss to enhance learning relations between different entities. Experiments are conducted on several benchmark tasks including object detection, scene categorization and document categorization to show the effectiveness of the method. \n\nOne major concern I have is about the novelty of the method. In particular, the center-mass cross entropy loss, which is one of the central component in the paper, is indeed the same as the focal loss in [1]. The only difference is to apply it on a matrix to measure relations. This makes the contribution limited. Moreover, I also have some concerns about the experiments, which will be detailed in the following. Overall, I find the paper has interesting observations and results, but the paper is not easy to follow and the contribution is limited. I am willing to increase my score if my concerns are clarified. \n\na. About the training of the relation matrix  \nOne of the key component of the algorithm is to train a relation matrix between entities. I have a few concerns about this step. \n\nFirst, are the entities given by a pre-trained model or is it learned during the training? If these entities are learned, then how do we train the relation matrix? For example let's say they are region of interests (ROI), the region proposal will be very poor at the beginning and the correct regions may not be included so how to handle the relation matrix between these poor regions? Moreover, how do we use the ground truth regions since maybe some of them are not correctly identified even in the well-trained model. \n\nSecond, do we need extra annotations to learn the relation matrix? In particular, the information of relations is needed in order to train the relation matrix, this does not seem to be free from since we need to distinguish whether they are the same instances. This would make the comparison to other models unfair since more information are available here. \n\nb. About the comparison to the benchmarks\nI am not an expert of the tasks considered in the paper so I may not notice the sensitivity of the improvement.  \n\nIn the object detection task, I would expect a better state-of-the-art performance since F-RCNN seems to be a weak baseline. The second column of the object detection table is using FAN + L_{det}, but it cites the Relation Network [2], is this a better baseline comparing to the Relation Network? What are the differences?\n\n[1] Focal loss for dense object detection, Lin et al, 2017\n[2] Relation networks for object detection, Hu et al 2018"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "Summary:\nThe following work proposes some effective and simple pseudo-labels for graph attention on both vision and language tasks. The supervision provided by these heuristic-based allows the final model to outperform the unsupervised attention baseline. Results are demonstrated on the relationship proposal task, object detection (attention is applied to context encoding for each object), and scene categorization, and document categorization. The largest gains appear to be on the relationship proposal task, with small improvements over SOTA on all other tasks.\n\n\nStrengths:\n- The paper was fairly easy to follow\n- The proposed automatic attention labeling schemes appear to be simple and effective\n- Results demonstrated improvements on a variety of tasks.\n\n\nWeaknesses and questions:\n-For visual recognition datasets, the attention targets are defined such that we want to maximize the weights between two overlapping objects of differing classes. This seems very dataset/task specific, and clearly would not apply to other datasets such as human-human interaction datasets.\n-I'm not sure that the center-mass CE loss is strictly a cross entropy loss? Maybe it would be if one takes the log of \\tilde{\\mathcal{W}} in (2) .\n-Should center-mass be center-of-mass instead?\n-The proposed center of mass seems to be a straightforward weighted reduced sum. I'm not sure where the \"notion of center-mass\" comes into play, nor how this is a novel contribution\n-The pairing scheme for language tasks as shown in Figure 2 seems fairly arbitrary. Has this been properly ablated? How much does each particular pairing matter? How much better is it than some pairing scheme that includes the negative set of edges (verb-adjectiv, noun-adverb)?\n-Any form of failure mode analysis is missing from this work. Figure 1 shows qualitative examples of when the proposed focused attention network performs qualitatively better than the Relation Network from Hu et al, but it's hard to believe that this is always the case.\n\n\nOverall, I don't see the proposed loss, nor the conclusion that supervised attention (even with heuristic-based labels) can outperform unsupervised attention to be sufficient contributions. I do think that the discovery of a simple and effective pseudo-labeling scheme (creating edges for overlapping objects of differing classes) to yield some insight. That said, this is certainly much task specific, and such a similarly simple attention labeling strategy may not exist for other vision tasks."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper proposes to learn attention among pairs of input units (they call these entities) as a matrix of attention values. These when aggregated along a row gives a summary of related entities for each input entity, and when aggregated overall gives the 'soft' entity-pairs in an input.  They apply it on four image-related tasks: object detection, categorization, relation , and scene detection and one document classification task.  Direct supervision for learning the entity-pair attention is only available from the relation proposal task.  They also induce indirect supervision from the object detection task using co-occurrence of objects in an image.  For text they hypothesize attention pair supervision based on POS tags.  Their experiments show that only for the relation proposition task their method provides significant gains over existing methods, that too in the fully supervised mode.    For scene categorization their method is good only with supervision on attention relation. For object detection their gains are insignificant and for text classification they show gains only with the labeled data is small.\n\nI have the following concerns about this work:\n1.  Computing pairwise attention is computationally expensive, and the gains they obtain seem too small to justify.  The only significant gains are for the relation proposal task where such pairwise attention is expected to be the norm.\n\n2.  Their experiments do not perform a fair comparison over the number of parameters and running time.   The FAN module inserts lot more parameters and quadratically blows up the attention vector length.  If we normalize on the number of  parameters and running time, it is unclear if the gains of FAN over  baseline will continue to hold.  For example, in the document classification task, they concatenate the FAN descriptor with usual  word to sentence attention.  What if a multi-headed attention is  used on the word to sentence layer? It is unclear if FAN will score over multi-headed attention.\n\n3. Their coverage of related work and empirical comparison with existing work is sketchy.\nAuthors have not done justice to the multiple prior work that seek to\nsupervise attention or model the relationship between attention of\nmultiple entities.  Several papers on supervising attention but in the section \n\"Attention Networks â€“ Limitations\" the authors do not mention these.  I list some of these:\n\nSyntax-Directed Attention for Neural Machine Translation\nKehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Tiejun Zhao\nAAAI 2018.\n\nSiddhesh Khandelwal, Leonid Sigal: AttentionRNN: A Structured Spatial\nAttention Mechanism. CoRR abs/1905.09400 (2019)\n\nAttentive Relational Networks for Mapping Images to Scene Graphs\nMengshi Qi, Weijian Li, Zhengyuan Yang, Yunhong Wang, Jiebo Luo; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 3957-3966\n\nSupervised Attentions for Neural Machine Translation\nHaitao Mi Zhiguo Wang Abe Ittycheriah\nhttps://www.aclweb.org/anthology/D16-1249.pdf\n\n\nQuestion for authors:\n---------------------------------\nPlease clarify the exact way in which the FAN module that provides word-pair\nattention is converted into a sentence descriptor. From Figure~3 it appears that you do row-wise\nmax-pooling but please  specify clearly in section 4.5,  preferably with a formula.\n\nThe form of Equation 3 needs more justification. Why this specific form?\n\nPresentation:\n------------------\nThe first section is hard to read and requires significant improvement in writing.  I give some suggestions:\n\nTypo in sentence:\n\"for the task of learning relationship attention weights between entities\"\n\n\"relation weights\" is an awkward construct.\n\nA citation is required on \"Relation Networks\" in their first mention in this sentence:\n\" Typical qualitative examples comparing Relation Networks with our\nFocused Attention Network are shown in Figure 1, with a quantitative\ncomparison reported in Section 5.\"\n\nThe sentences in the paper are often hard to parse.  Here is are some\nexamples:\n\n\"The scaled dot product attention module of Vaswani et al. (2017), for\nexample, uses learned pairwise attention weights between region\nproposal network (RPN) generated bounding boxes in images of natural\nscenes (Hu et al., 2018) to boost object detection.\"\n\n\"In fact, for a given reference object (region), relation networks (Hu\net al., 2018) tend to predict high attention weights with scaled or\nshifted bounding boxes surrounding the same object instance. This is\nlikely because including surrounding context, or simply restoring\nmissing parts of the reference object, boosts object detection\"\n\nThe illustration of attention in Figure 2 is not at all clear."
        }
    ]
}