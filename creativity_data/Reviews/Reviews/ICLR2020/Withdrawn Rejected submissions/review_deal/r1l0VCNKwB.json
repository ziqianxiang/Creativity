{
    "Decision": {
        "decision": "Reject",
        "comment": "Main summary:  Sngle image super-resolution network that can generate high-resolution images from the corresponding C-JPG images\n\nDiscussions\nreviewer 3: reviewer has a few issues including, claim the method is lossless, want more information about JPG revovering step\nreviewer 1: (not knowledgable): paper is well written and reviewer gives very few cons\nreviewer 2: main concerns are wrt novelty and technically sound\nRecommendation: the 2 more knowledgable reviwers mark this as Reject, I agree.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "In this article, the authors propose a single image super-resolution network that can generate high-resolution images from the corresponding C-JPG images. The method contains two main parts, namely a JPG recovering step, which recovers the information from low-quality JPG images, and an SR generation step, which generates SR images from the images achieved by the recovering step. Moreover, the authors leverage a cycle loss to generate better results.\nThe main contribution of this work is only the integration of existing models. The authors claimed that the proposed method is lossless, while there is no evidence to demonstrate it. The authors should show more evidence about the JPG recovering step, like how much information it can recover. Moreover, the SR generation step only incorporates s-LWSR without any improvement. It makes SR in this manuscript more like an application for the JPG recovering method rather than a contribution to the SISR field. \nIn the experimental section, Figure 5 makes readers confused. Does the image entitled “s-LWSR(Training)” mean the “STRAIGHT TRAINING” described in section 4.2.1? If yes, is there any perceptual difference between the result of s-LWSR and the result of ours? It is suggested that the authors should reorganize the results and provide more instructions. In Table 1, the results derived from s-LWSR32(C-JPG) and the proposed are very similar. The authors should more convincingly show the advantages of the proposed method. From the results, I observe that the SR images of the proposed model are blurry and lack much information about textures. At the same time, there are some other SISR studies, especially GAN based models like ESR-GAN, which show visual quality with more realistic and natural textures. I hope the authors can conduct more comparisons with these methods.\nThere are still some issues as follows:\n1.\tThe authors should carefully check the format of the references in the whole article. For instance, in section 4.1, almost all references are in the wrong format. The same mistake happens in the caption of Figure 6. Please check the full article before submission.\n2.\t(Page 1, line 2 from bottom) Please add a reference to “bicubic”.\n3.\t(Section 3, line 1) Please add a full stop after “Challenge Formulation”.\n4.\t(Figure 2) Please enlarge the arrow of the red lines. They are hard to read right now.\n5.\t(Figure 4) The figure seems to miss the skip connect of the former five layers, which should be a part of the input added to the latter four layers (Li et al., 2019). In addition, please enlarge the arrow of the blue lines.\n6.\t(Section 4.2.1, line 4) “Both of the PSNR …” Does figure 5 can reflect this? Please add data instruction.\n"
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper focuses on the super-resolution (SR) task: to get better super-resolution images from compressed JPG inputs. They propose a two-stage pipeline to first recover the details that were lost during the compression of low-quality JPG images (called as JPG recovering), second to generate SR with satisfactory visual quality (called as SR generating). Finally, they added a hybrid loss function to support an integrated model and the results of their experiments showed good SR generation. \n\nMy decision is weak accept, considering the below aspects. \nPositive points: (1) Recovering model methodology is quite novel compared to traditional noise- elimination-based approaches. (2) Experimental results showed better results compared to state-of-the-art methods. Cycle loss seems to be working well. Also, visualizations in the appendix showed better SR generation. (3) The paper is well organized.\n\nFor the experiments, the following should be addressed:\n1.\tCould you explain what does it mean, “Our model is trained over 1 × 10^3 times until reaching its convergence in training settings.”\n2.\t“In order to remove ring, checkerboard effects, as well as other noise, the former half sub-model is trained with pre-processed C-JPG LR images as inputs.” May I know preprocessing is employed here?\n3.\tCan you provide further explanations to statements in 4.2.1, 4.2.2? - “The huge difference in supervised information leads to large variance among middle layers, which represent ideal details serving the final SR model.”, “Denoising only makes these C-JPG inputs clearer, while recovering brings accurate information to C-JPG images.” are there any empirical results to support these statements”\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper addresses the task of single image super resolution (SISR) on compressed JPG images. Different from the standard SISR problem, the input images of this task are compressed according to the JPEG standard, which have lower quality than what standard SISR deals with. The authors proposed a two-stage network which recovers the lossed information of compressed JPG (C-JPG) on the first stage and handles standard SR on the second stage. The whole model is trained with three L1 losses that ensure compressed information recovering, super resolution and LR-SR cycle consistency, respectively. Experiments on standard benchmarks demonstrate the effectiveness of this work.\n\nHowever, my main concerns on this work are: 1. this works is not technically sound w.r.t. its novelty; 2. the efficacy of each loss function is not well supported by ablation studies and 3. the comparison experiments with other methods are not clearly stated.\n\n**Main arguments:**\n\n1. This works lacks novelty since the main idea is just a simple concatenation of a JPEG-artifact-removal model and a super resolution model. Both of the components are based on former work (s-LWSR 32). There’re no new insights on model design or inter-task relationship analysis provided. Besides, there’re already mature solutions on JPEG-artifact-removal and super resolution, like [R1-4]. Given the fact that cascading these solutions could also solve the C-JPG super resolution problem, the practical usage of this work is limited.\n2. The efficacy of each loss function is not well supported. For example, what if we remove the $\\mathcal{L}^1_{L1}$ loss defined in equation (2)? The performance could still be better than the other counterparts since the two-stage model have two times more parameters than a single super resolution net. Likewise, the effectiveness of the cycle consistency loss $\\mathcal{L}^3_{L1}$ is also unclear. \n3. In section 4.3, the input of other leading methods during training and testing is not described clearly. For fair comparison, it should be the same as `ours`. Otherwise, the whole comparison is invalid.\n\n[R1] RESIDUAL NON-LOCAL ATTENTION NETWORKS FOR IMAGE RESTORATION, ICLR 2019.\n[R2] Residual Dense Network for Image Restoration, arXiv 2018.\n[R3] MemNet: A Persistent Memory Network for Image Restoration, ICCV 2017.\n[R4] Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising, TIP 2018."
        }
    ]
}