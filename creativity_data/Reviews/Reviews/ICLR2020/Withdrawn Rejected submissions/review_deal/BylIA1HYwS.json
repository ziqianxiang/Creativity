{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper introduces a model for generating text, conditionally on a context content and on a style information. Given a context sentence or paragraph, the task consists in generating plausible text with a content corresponding to this initial context and a style corresponding to another piece of text. The model is based on a transformer architecture inspired from GPT2. It is trained using a combination of loss functions: log likelihood, distillation w.r.t a pre-trained GPT2, style and adversarial loss. The model is evaluated on aggregations of multiple text corpora building a multi-style corpus.\n The proposed model combines several interesting features like making use of large pre-trained language models to guide the generation or the use of a latent GAN formulation for text decoding in order to avoid non differentiability. The authors propose different variants of the model for incorporating the style component into the transformer architecture. The role of the different loss components should however be better motivated. The _DIST and _GAN components are not directly linked to the objective and their importance for the model should be better stressed. The global model is probably quite heavy and a discussion on its complexity and on the training strategy would be useful in order to complete the description.\nThe evaluation is performed on two corpora assembled by the authors and representing a variety of styles. This contribution could be helpful to the community. The authors introduce a series of evaluation criteria:  perplexity of the generated text, style classifier, diversity and novelty. They also provide human evaluation. According to the quantitative criteria, one of the variants seems to perform reasonably well compared to the baselines. However, the evaluation is not convincing. It requires to be pushed further and the results and the system behavior should be better analyzed. The different examples of generated text are not consistent, and rather look like a random sampling over the vocabulary. This is in contradiction with the scores appearing in the tables and on the figures. One of the Baselines (SC) generates much more coherent texts – at least in the examples provided by the authors – while its perplexity score is similar to the authors’ model. The ablation study does not show the importance of the different loss components. For example, the models without the GAN or the DIST loss terms behave as well as the complete model does. Concerning the human evaluation, I do not understand the numbers in table 3-right: it seems that the model performs better at generating among 21 styles (-category) than it does with 3 styles?\nOverall, the paper represents a large amount of experimental work, but deserves a more in depth discussion of the usefulness of the different components. The experimental evaluation is still preliminary.\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper presents a (to the best of my knowledge) new task and models to generate plausible completions of a given paragraph condition on a reference text that has a different “style” from the input. The proposed model is comprised of a transformer language model trained with multiple objectives including an LM completion objective where the reference text has the same style distribution as the input, a cross stream where the reference text has a different style and the generated LM completion is forced to have the style of the reference text as determined by a pre-trained classifier. Two additional objectives - a distillation objective to match the output distributions of the transformer LM and a pre-trained GPT model and a GAN objective to their feature distributions is used as well (since the pre-trained classifier operates in the space of pre-trained GPT hidden representations). I think the paper tackles the interesting problem of example guided text style transfer that hasn’t been studied much and presents a complicated solution to the problem. However, I don’t think the paper is ready for publication in its current state because 1) The writing needs to be significantly improved to include high level textual descriptions and intuitions for each training objective - this is particularly benefit readers new to this class of problems 2) The paper needs much simpler baselines especially since the tasks and datasets presented are new. Each presented model has several moving parts - a GAN, pre-trained GPT and the different style token conditioning strategies. 3) Samples from the model (presented in the Appendix) appear quite poor and I’m not convinced that the model really works right now.\n\nI have a few comments and questions\n\n1) Distillation loss - you say this loss is trained by “minimizing the mutual information between F and H” don’t you want to maximize the MI? Also the formulation written in L_{dist} is equivalent to minimizing cross-entropy between H and F.\n\n2) The paper would really benefit from a baseline where instead of an example from a target serves as reference, just it’s style category is used. This would be turning the problem into the more common formulation of text style transfer. \n\n3) Did you consider having a back-translation objective instead of a complicated style-classifier and GAN loss? This has shown to be much easier to optimize and learn see Prabhumoye et al [1] and Subramanian et al [2].\n\n4) You report pre-trained accuracies of C when trained on H_{f}, what about during training? Does it correlate to progress in GAN training?\n\n5) If the goal of using a GAN objective is just to match the distributions of H_{f} and F_{f}, then why train it only on cross samples? Why not also on reconstruction samples?\n\n6) How does the style decoder F_{s} deal with variable lengths of p_{k}? Is the length of p_{k} truncated to a fixed length?\n\n7) Do human evaluators also know the target style type that the model is supposed to emulate?\n\nMinor\n\nAbstract - “texts decoder” -> “text decoder”\nIntroduction - “main mean” -> “main means”\n\nReferences\n\n[1] Style transfer through back-translation - https://arxiv.org/abs/1804.09000\n[2] Multiple-attribute text style transfer - https://arxiv.org/abs/1811.00552"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper proposes a stylized text generation approach grounded on specific text domain, such as review or news article. They leverages the large-scale pretrained transformer (GPT-2) and employed a linear combination of 4 losses to train the model. While I do think that this task is important, challenging and interesting, several aspects of this paper failed to convince me that the proposed method is indeed effective:\n\n1. The paper does not define the goal of the proposed task clearly, e.g., what should the well-generated results look like? From my perspective, style example-guided text generation should first sustain related content as the input context (coherent semantic information). However, the paper neither demonstrates this nor provided a related metric to evaluate this. On the contrary, the paper proposes to use fluency score, style score, style diversity, content novelty to evaluate the generated results. Is a fluent paragraph with the correct style but totally off-topic content desirable? It's also not clear how to define the style of the reference. Since the reference is also a paragraph rather than a style label or a single sentence, the generated paragraph probably inherits characteristics more than just style information from the reference. How to tell whether the borrowed information is style or content?\n\n2. Although the paper provides a new text style generation task based on examples, the novelty of the proposed framework is relatively limited.  The proposed framework is based on the transformer generation with conditions on style example. Additional adversarial feature alignment is used to sustain correct style generations. However, these components are already widely used in previous text generation tasks. In other words, I didn't see that the proposed framework is specifically designed for example-guided text style generation. \n\n3. What are F_d and H_d in Figure 1? These are not defined in the paper. \n\n4. It seems that the generation ability is borrowed from GPT-2, rather than trained on the dataset. Without distillation from GPT-2, what would the performance become? \n\n5. Where is the F_f output layer illustrate in Figure 2? My concern is if style information z is incorporated into P_i in a very shallow way, then the input fake feature may have a very different distribution with the input real feature. Then the discriminator can easily be trained very strong and the generator couldn't get efficient updates. \n\n6. The experiment is not thorough. Many ablation studies are missing."
        }
    ]
}