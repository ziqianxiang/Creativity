{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The paper is a very incremental addition to Tu and Gimple, 2018, which originally talks about using an inference network to find the optimum of a structured prediction energy network. Here they have separated the test time inference network and loss-augmented inference network (that is used for training) and added an extra term for optimizing the test-time inference network.\n\nHow this work is better than \"Learning Discriminators as Energy Networks in Adversarial Learning by Pan et al.\". It seems that they have a very similar approach, but extending the idea behind deep value networks rather than structural SVM. \n\nThe comparison here is very narrow, why you haven't tried comparing your approach with other approaches such as deep value networks ( DVNs) (Gygli et al. ,2017)? \nCould you try your approach on any task reported in DVNs' paper to have some sense of comparison?"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This submission is a follow-up on the SPEN model originally proposed in Tu & Gimpel (2018), which trains an energy-based model for structural prediction. I am voting to reject this work for the lack of contributions and significance. While the overall writing is clear and well-motivated, basically the main contributions boil down to a set of minor modifications to model architecture (separating the inference network) and hacking the original objectives (Sec 4&5). On the significance side, the improvements seem incremental. Since this paper focuses on empirical efforts, stronger results are needed to make the case. \n\nMinors: It's not clear what is the motivation behind the design of the global energy term in Eqn (6). And the author(s) should try to avoid citing papers in the abstract. "
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "*Summary*\nSPENs are an interesting structured prediction technique. They used a trained deep energy function (like the discriminator in a GAN) to reward high-quality structured outputs. Prior work (Tu and Gimpel 2018) contributed an 'amorized inference' method for training SPENs that appears to be considerably more practical than the training methods originally proposed for SPENs. This paper provides additional improvements to the amortized inference training method that make it simpler and perform better. Directly address a weakness of Tu and Gimpel: the amortized predictor was trained for a different objective (loss augmented inference) than it will be used for at test time. They explore a variety of ways to tie two separate amortized predictors together. The most interesting one is where the train-time predictor has access to the ground truth label.\n\n*High-level assessment*\nOverall, the authors do a good job of providing careful ablation analysis of their contributions. This level of analysis is absent from many submitted papers. The paper's contributions also seem like an important step in making SPENs practical. \n\nI can imagine that other reviewers may be critical of the size of the paper's contributions: it mainly presents a collection of tricks of the trade to make SPEN training work in practice. Much of the ICLR community is very interested in structured prediction, but It appears that SPENs have not had much traction. I think that this paper is important because it may teach practitioners that they should consider SPENs.\n\n\n\n*Additional Comments*\n\nSec 4.2: your paper should be self contained. What is this loss?\n\nPaper would be improved if it helped explain why people should care about SPENs. I'd include more of a sales pitch for the benefits of them.\n\nAlso, your approach is substantially more complex than training a straightforward model with some deep representations. Is it worth the complexity?\n\nHow do you justify removing the hinge term in your max-margin objective when updating the inference network? Is there some principle that would suggest that this is OK?\n\nThe idea of having the inference network condition on the ground truth label is cool. This is similar in RL to how people will use 'asymmetric critics', where the critic has access to more information than the actor. For example, the critic may have access to a scene's actual 3-D geometry, while the actor just has a 2D camera view of it. It might be worth drawing this connection."
        }
    ]
}