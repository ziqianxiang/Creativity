{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper explores generating articles from summaries--- the inverse problem of document summarization. Since directly generating a long article from summary results in degenerations such as repetitions (appendix), here the authors proposed to generate a \"sketch\" of an intermediate length (the geometric mean of summary length and article length), then generate the article based on both the sketch and the summary. The sketch supervision comes from extracting sentences in the article close to the summary in the embedding space (using BERT), and both generation problems (summary -> sketch, summary+sketch -> article) can be trained with MLE. Then the whole pipeline is finetuned using policy gradients, where the reward signal for the sketch generator is the log likelihood of the article generator. In terms of modeling, the authors use a gating mechanism to combine summary and sketch states in the article decoder.\n\nExperiments are conducted on two summarization datasets in the reverse direction (CNN/DM and BigPatent). To evaluate the generations' faithfulness, the authors proposed ROUGE-rec, which is based on another summarization system that summarizes the generated article, and use ROUGE-L as the score. To evaluate the generations' fluency, the authors used perplexity under GPT-2. The proposed method exhibits superior performance compared to normal seq2seq baselines, and human evaluations agree with ROUGE-rec and GPT-2 ppl.\n\nPros:\n1. Most long document generation problems are open-ended such as pure language modeling. A closed-ended task like summary-to-article opens an interesting research venue.\n2. The proposed model gets much better generations than the baselines, especially from the showed examples in the appendix.\n\nCons:\n1. The proposed model has much more parameters than the baseline. It is not a fair comparison unless the baseline seq2seq gets the same number of parameters.\n2. The proposed model relies on external models such as BERT for obtaining the sketches, which might give it an unfair advantage.\n3. It seems that the baseline seq2seq models produce many repetitions even with nucleus sampling (appendix). I suspect they are not well trained.\n4. With word/sentence perturbations, pretraining, and RL, there seem to be too many floating parts of the proposed approach.\n\nQuestions:\n1. why does ROUGE correlate so poorly with pairing accuracy? (table 5)\n2. what's the baseline reward R_t in Eq 2? Does that come from a neural network as well?\n3. after pretraining, is Eq 2 the only objective for the sketch generator? Or do you need to mix it with MLE?\n\nMinorï¼š\n1. table 6, human evaluation, column pairing accuracy, should make 68.3 bold instead of 65.0.\n2. figure 2 is too small, hard to read\n\nOverall, this work considers a very interesting problem, and by using a two-phase generation approach, this work gets decent performance in terms of summary-to-document generation. However, I think the approach is not very novel and I am inclined to reject this paper."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper presents a new task on generating articles from their corresponding summaries. They propose a two-step generation process, where a sketch is first generated from the summary, and then the articles is generated from the sketch. Reinforcement learning is used for model training. \n\nI think the task is interesting. My major concern lies in the evaluation. Since the task is about article-level generation, i.e. long text generation, it would be necessary to evaluate the structure or discours flow of the text in addition to relevance. It is not extremely hard for neural models to generate content that is relevant to the prompt (e.g. summaries), from my opinion, the difficulty comes from how to maintain a coherent and connective discourse flow rather than drifting away to various topics or producing repetitive or generic content. However, none of these aspects is evaluated in the submission. I would suggest the authors consider these generation quality aspects. \n\n\nOther comments:\n- The lengths of the generated articles should be reported, since different lengths of articles would significantly affect the perception of their relevance and quality.\n\n- The author should commment on ethical concerns of the task. Since the summary only contains a subset of the information from the article, the model tends to generate fabricated content by filling in the rest of the narrative. This issue should be addressed in the discussion section. \n\n- Fig 8&9 captions are incorrect."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper explores the task of summary-to-article generation, the task of generating long articles given a short summary. Generating long text as output is challenging, since the seq2seq model often fall into degeneration of language models. To address this issue and have a better control on the long-form text generation, this paper proposes a hierarchical generation approach which first generates an intermediate sketch of the article and then generated the full article. This intermediate sketch can be noisy during inference because of the discrepancy between the training and inference strategies. To this end, this paper proposes a multi-agent reinforcement learning as well. \n\nFor the evaluation of such long-form text outputs (article), this paper also proposes to use a summarization model to summarize the generated article and measure the ROUGE score between the generated summary and ground-truth. The premise here is that if we can generate a good article, then the output summary generated based on this article as input will also be good. \n\nThey empirically evaluated the proposed hierarchical model with reinforcement learning, showing significant improvements over conventional seq2seq models. \n\nOverall, this paper is interesting with some new ideas, with caveat for some clarifications and missing some important experiments. \n\nArguments:\n\n\n1) It would be interesting to see how does a fine-tuned GPT-2 model on these summarization datasets perform on this article generation task. \n\n2) ROUGE-rec metric is weird in the sense that if the summary-to-article model just copies the summary with some junk non-related information which is fluent, the summarization model based on this article can still generate a good summary. However, this might not be the case as the human evaluation correlation is good with this metric. Anyway, I would suggest to further analyse this metric.\n\n3) By seeing the outputs generated by the conventional seq2seq model, I was wondering if the repetition can be fixed by simply blocking the n-gram repeats. Further, I would be interesting  to see if transformers are better baselines in such long-form text generation tasks. \n"
        }
    ]
}