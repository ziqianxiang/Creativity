{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper aims to model fake news by drawing tools from multi-agent reinforcement learning. After the discussion period, there is a consensus among the reviewers that the paper lacks novel technical contributions. The reviewers also acknowledge that paper also doesn't quite deliver a practical solution as claimed by the authors.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "In this work, the authors aim to solve the problem of fake news detection in social media. The proposed method is built upon a multi-agent reinforcement learning method. Although the problem of fake news detection in social media has been extensively studied and many method including deep learning have been investigated to help solve the problem, it is relatively novel to use multi-agent reinforcement learning in this field. The proposed method is based on traditional multi-agent deep reinforcement learning approach and the authors extend the conventional framework by introducing the role of attacking agents - agents that can spread biased information or even take over the stance of regular users. The paper has been well written and necessary details for reproducing the experimental results have been provided with a link to the code repository. However, a major concern of mine is the contribution of novelty of the manuscript.\n\nThe main contribution of novelty of the work, as claimed by the authors, is that they come up with a practical solution for fake news detection with deep reinforcement learning. Most research efforts have been focusing on detecting fake and deep-fake content while very few pay attention to utilizing machine learning in learning a best action/practice. This is because the root cause of the widespread of fake news is quite complicated. Besides those who intentionally create and spread fake news and biased content, the innocent users' major problem is how to quickly identify fake news from massive amount of information flows. The idea that building a practical fake news prevention solution by using multi-agent reinforcement learning seems to have underestimated the complexity of the misinformation challenge. For example, three high-level suggestions/solutions proposed in the manuscript include social network users should be more aware of the presence of fake news, keeping private information private on social networks, and encouraging well balanced social network structures. My question is that how we can apply these solutions in the real world? Therefore, I think this piece of work is more theoretical rather than practical.\n\nIn terms of the technical part, the authors propose to introduce agents for fake news and biased information. The technical solution is solely based on multi-agent reinforcement learning and the extension is straightforward. The assumption that there is only one kind of role for fake news dissemination in social networks again underestimates the complexity of the problem in the real world. E.g., there are users who intentionally create fake news in social networks, and also users who are not aware of a piece of information being fake and yet still deeply believe what they spread is true. I would suggest the authors to find more related work in the field of information diffusion, where researchers have long been focusing on competitive information propagation in social networks with multiple parties (such as political campaign and word-of-mouth social marketing). \n\nIn conclusion, I think the work is well-written and quite interesting - solving an emerging and important problem from a new perspective. However, both the hypothesis and the technical solution are lacking enough contributions of novelty. I would like to suggest the authors either make the solution actually practical or focus more on the theoretical part of competitive information diffusion in social networks."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper proposes a model under which to study social networks under attacks attempting to propagate misinformation. It proposes a theoretical model based on assumptions on what kinds of graphs are common in social media and what kinds of attacks take place. While this could be interesting, the work presented falls short of what it promises, i.e. to develop a practical model of fake news on social networks,  because many of the assumptions made about the phenomena under study are unrealistic. In more detail\n\n- There is a lot of research looking at social network graphs and analyzing them. As an example, here is a paper by Kate Starbird: https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17836/17028 \nI believe that there is little reason to generate data if one can collect them\n- Even if generating the data can be justified, the graphs on which the methods are studies are 10-12 nodes. I can't see why such a low number was chosen given that the data is simulated, but it doesn't allow to assess whether the methods proposed would be practical in a real social network\n- There is work suggesting that misinformation spreads faster than information: https://science.sciencemag.org/content/359/6380/1146\nThus it would make sense to take this into account in designing the graph theoretical model. Given this though, it is unlikely that the assumption that the social network will converge to the truth.\n- Assuming that the social network graph remains fixed over time is also unrealistic. One can study how Twitter networks evolve over time\n- The modelling of the users as merely voting on the truth or false value of a claim is not what happens in most social networks in which users fave/like, share, etc. Furthermore, it doesn't make that users want to prevent other from copying them. Being retweeted is a sign of influence, and users want to be influential.\n- The attacks described do not seem to be grounded in any evidence/research on how misinformation propagates and what attackers actually do, so I can't accept the results of the analyses that use them."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #1",
            "review": "Update: I thank the authors for their response and for improving the paper. However, I maintain my position that the paper lacks a significant technical contribution to learning algorithms and that the applicability of the proposed approach is remains questionable in the current state.  \n\nSummary:\nThe paper proposes the  use of deep multi agent reinforcement learning (DMARL) for modelling fake news propagation and detection in social networks. The agents observe an informative yet noisy private signal and the actions of their neighbors (in the social network graph) and have to guess whether a claim (related to the received signal) is true or false. The fake news is modelled as an adversarial attack to the graph that either provides a hand-coded biased private signal to one of the agents or replaces one of  the agents with an RL policy trained to minimize the total reward of the agents in the graph (i.e. social network).\n\nMain Comments:\nI lean towards rejecting this paper because I do not find the methodological contribution to be significant enough to be published at ICLR, given that the main contribution is applying current techniques to a novel toy domain. While this paper attempts to apply DMARL to a new domain with real-world relevance, the authors only consider a toy example and make strong assumptions that are likely to break in the real world. Hence, it is not at all clear whether or how the conclusions of this paper would translate to more realistic scenarios of fake news in social networks. While strong assumptions and toy examples are reasonable for showing algorithmic improvements, this paper does not propose any improvement to core DMARL algorithms, but merely applies current methods to a new toy domain. \n\nI am also concerned about the lack of comparison with other approaches to information aggregation in social networks. While I admit I am not familiar with that literature, I would still find it useful to provide some comparisons with non-DMARL (e.g. heuristic or game theoretic) approaches or at least some motivation for not comparing against those methods. The authors qualitatively describe those methods and their shortcomings, but the experimental section does not support those claims due to the lack of comparison. Despite all these concerns, the paper does indeed open-up numerous research directions and I can imagine follow-up papers being written that relax some of the current assumptions. \n\nOther Questions / Comments:\n\n1. Can you provide  some motivation for choosing to model the social network as a Barabsi Albert graph and why this is a reasonable modelling choice?\n\n2. What happens if instead of a clustered or balanced graph, you have some combination of the two? It seems to me like that would be a more realistic scenario (i.e. a large graph containing subgraphs with different structures). Can the framework generalize to that? How would the conclusions change?\n\n3. Is there any evidence that the conclusions supported by the experiments in this paper hold in real-world social networks and model some realistic aspects of social network dynamics?  Without such evidence, it is difficult to assess the relevance of this work for the  real-world application. Since the behavior of the agents in the graph is not guaranteed to be optimal / a best-response or even stable, is it at least a good approximation to human behavior in social networks? It would also be useful to show more comparisons against best-response or heuristic agents.\n\n4. What is  the motivation behind considering a fixed budget of bias? Why not instead have a fixed number of agents that you will be biased? I think it would be informative to compare against applying beta = 3 to two citizens,  along with the focused and spread scenarios.\nThe legend in Figure 2 A & B is slightly confusing. I’d suggest using different styles for “private signal optimal” and “all signals optimal”. \n\n5. Can you include error bars in Figure 2 D?\n\n6. Can you provide results with a heuristic attacker that always lies about the claim? I read your intuition of why  you believe this wouldn’t be stronger than an attacker that is trained with RL together with the other agents, but is it actually true in practice, do the agents really learn to easily detect the “lying” attacker and distrust it? Based on your results, doesn’t it mean that one can find a heuristic attacker that has an equivalent behavior to the learned one ? Can one build even stronger hand-tuner attackers  based on heuristics?\n\n\n\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        }
    ]
}