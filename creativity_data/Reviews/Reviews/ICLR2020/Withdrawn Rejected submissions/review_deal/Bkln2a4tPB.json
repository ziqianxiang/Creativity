{
    "Decision": {
        "decision": "Reject",
        "comment": "This work proposes a dynamical systems model to allow the user to better control sequence generation via the latent z. Reviewers all agreed the that the proposed method is quite interesting. However, reviewers also felt that current evaluations were weak and were ultimately unconvinced by the author rebuttal. I recommend the authors resubmit with a stronger set of experiments as suggested by Reviewers 2 and 3.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "\nThis paper proposes to add a latent variable to a dynamical, thereby encoding the notion of \"task\", eg, in Mocap, the latent variable could encode the walking style in an unsupervised manner.\nFurthermore, it is then possible to generate new series conditioning of chosen latent variables.\n\nThe paper is clear and well written, the idea is interesting and the experiments seem well designed and convincing.\n\nI do have just a couple of clarifications:\n- in sec 2.1.1, you say that the diagonal*orthongal parametrization is valid without any loss of generality. If I understood well, to get to this for, you would still need to multiply the input x_t by U^{-1}. Therefore, any MTDLS can be written in this simplified form, correct, for a given input x_{1:T}, the formulation using the diagonal is more restrictive I believe. U^{-1} x could be of this form, but not necessarily x.\n- in 2.3, the estimation of the posterior using your method of AIS with MoG seem quite involved, even though you mention it converges fast. What happened for simpler methods of estimating the posterior, did you see a drop in performance, run-tine only?\n\nOverall I think this is an interesting paper, however I am not familiar with all the related work."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #2",
            "review": "This paper proposes a multi-task dynamical system for sequence generation. The model learns a number of parameters that represents the latent code z. The learned model can generate the customized individual data sequence and provide the smooth interpolation in the sequence space. The experiments on the synthetic data and the ocap dataset show the customization is beneficial for prediction tasks and enables for style transfer and morphing within generated sequences. \n\nThe mathematical definition and the proof in this paper are well justified. However, I had a hard time understanding the contribution of this paper. \n\n- The main motivation of this paper is to treat each sequence as a task in the training set (customization of the individual data sequence). What are the advantages of this setting for sequence generation?\n\n- Separate parameterization of the latent variable z for different tasks seems to be a key idea in this paper. What is the main benefit of parameterizing each latent variable? Does it improve diversity?\n\n- If not, what is the key idea that the proposed model can generate diverse sequences compare to other generative models (e.g., GAN or VAE-based models). \n\n- The authors claim that the proposed approach provides grater data efficiency. How is it compare to other generative models?\n\n- Overall, it is not clear the benefit of the proposed model over existing algorithms. This paper needs to provide comparisons with any other existing models, especially on Mocap data, \n\n- What are the differences between pooled models and single-task models?\n\n---- \nI increase the rating after rebuttal, since the idea is interesting and the paper has been improved. However, I still think the experiments and the comparisons are unconvincing. ",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #796",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "<Strengths> \n+ This paper proposes a new dynamic model named hierarchical multi-task dynamical systems (MTDSs) as a latent sequence model that enables users to directly  control the output of data sequence via a latent code z. \n+ The proposed model adopts the multi-task learning idea to represent each sequence in the training set. Another strength of the model is flexibility as different base models and latent models can be chosen. In experiments, it can achieve reasonable performance using hierarchical RNN as a base model and VAE for latent modeling. \n+ The new formulation is well-explained in the thorough appendix.\n\n\n<Weakness>\nIn my opinion, the major weakness of this paper is weak experiments, although many results of different types of tests are reported. \n\n1. The experiments are carried out with a simple toy dataset DHO and MOCAP data. As done in previous related papers, some challenging video datasets can be used for more convincing evaluation.\n\n2. The compared baseline models are too weak, given that no state-of-the-art model is compared. \n- Throughout the papers, only single-task version and pooped version of the model are compared. It may not be surprising that the multi-task version is better than these two weak baselines. \n -In section 3, several latent sequential models are introduced, including Miladinovic et al. (2019),  Hsu et al. (2017), Yingzhen & Mandt (2018), Bird et al. (2019). I strongly recommend a couple of them may need to be implemented and investigated in some sets of experiments.\n\n<Conclusion>\nMy initial rate is borderline with slightly leaning toward accept. I am willing to adjust my rate more favorably if more experiments are conducted as mentioned above. \n"
        }
    ]
}