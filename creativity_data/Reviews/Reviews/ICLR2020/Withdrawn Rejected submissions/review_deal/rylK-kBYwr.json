{
    "Decision": "",
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "[Contribution summary]\nAuthors propose a new E2E model for the DST task that (1) implements a response generator that leverages DB query results as well as other dialog contexts with a late fusion approach for joining domain and slot pair representations, and (2) obtains the competitive results (50.91% for the joint task of DST & context-to-text generation, and 49.55% joint accuracy for the DST task, both on MultiWoZ 2.1).\n\n[Comments]\nThe proposed model is reasonably structured. Empirical results show improvement over other baselines, with the main gain (among ablations) coming from incorporating the dialog states from previous turns, and the joint domain-slot module, etc. The empirical analysis section could improve and the novelty of the system over the previous literature be clarified -- some of the components used in this work are not entirely novel and previously utilized in other work, hence it is hard to discern where the main gain is really coming from, compared to the previous work (especially for the DST task). Empirical comparison of the joint DST & generation, which is one of the main results, is limited to Lei et al.\n\nThere have been recent work on DST with new SOTA results (e.g. “Towards Scalable Multi-domain Conversational Agents: The Schema-Guided Dialogue Dataset” by Rastogi et al.) -- please consider comparing the approaches.\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The authors consider the problem of learning an end-to-end multi-domain task-oriented dialogue system. Methodologically, the innovation is to learn a slot belief tracker and a domain state tracker independently and combine them to produce a join domain-slot state tracker with ‘late fusion’ — which is then used as input to a response generator. At a conceptual level, this is largely a combination of [Wen, et al., EACL17] (for the policy network to response decoder component), [Wu, et al. ACL19] (for the intuition of the state generator modified to be a transformer network), and [Lei, et al., ACL18] (mostly on the generation side). That isn’t to say that this is a ‘smash-up’ paper as putting these ideas together with a transformer network and getting it to work is a non-trivial endeavor, just that this is probably the closest contrasting work. Experiments are conducted on the MultiWoZ dataset, achieving state-of-the-art results with respect to recent competitive work on the end-to-end and state-tracking task. \n\nThe positives of this paper are readily apparent — this work combines the previously mentioned papers in an ostensibly sensible way to produce a state-of-the-art model for end-to-end (including generation) and state-tracking problems in multi-domain settings. The model is intuitively appealing and this is likely the baseline system for end-to-end multi-domain goal-oriented conversational agents going forward. From a purely technical perspective, while I believe other researchers *could* have put this together based on referenced work (i.e., it isn’t a conceptual breakthrough), they did get it to work and get good results.\n\nThe weakest aspect of this paper is the presentation and writing; overall it seems rushed, took several readings (and some assumptions) to understand despite being familiar with relevant work, doesn’t contrast crisply with related work, overloads some notation, and doesn’t focus on possibly the most interesting aspect of the paper (in terms of seeing which subcomponents can be attributed for performance) — the ablation study. Below are more detailed/specific comments in this regard:\n— In general, when situating within relevant work, the introduction and related work sections are more of a ‘laundry list’ than direct contrast. I would even say that this should extend to the general text where works are referenced conceptually (as in the first paragraph on this review) and a clear contrast is made. \n— In the same vein, ideally, the paper should be as self-contained as possible — however, I would recommend contrasting with relevant works in the body such that readers will at least know where to reference to get a better understanding wrt concepts used in other papers and described in more detail there. Also, the introduction lacks examples to explain clearly to readers who aren’t familiar with these concepts (e.g., inform vs. request slots)\n— Not just a writing criticism, but in my opinion, while the stated architecture ostensibly performs well, it really isn’t clear if it is because the conceptual explanation or just a lot of machinery minimizing the loss well and many other architectures would work. Obviously, there isn’t room to describe any failures, but the ablation study could capture this to some degree with additional discussion.\n— Small point; the notation ’S’ is used both for ‘slot’ and ’system response’. It is generally obvious which is which, but still a good idea to change.\n— In the ‘Domain-Slot Joint State Tracking’, when I see element-wise, I am thinking Hadamard. However, this looks like somewhere that a tensor-network would be appropriate to capture interactions (i.e., Kronecker product), which is also reflected in the stated dimensionality and the text. Please clarify.\n— In ‘End-to-End’ section on page 7, you “adapt the method [TSCP] to the multi-domain dialogue setting”. I can think of at least two ways of doing this; please clarify.\n— As this is likely the baseline for future work in this direction, Table 3 is probably the most interesting part of the paper in terms of looking where to push on this model. However, the discussion is minimal. I would prefer this over the ‘qualitative results’ and some of the repetition in the intro to related work sections.\n\nFinally, as this is very specific to dialogue agents, I do question if ICLR is the ideal venue. Nothing in the model has broader methodological implications and all of the conceptual underpinnings are somewhat specific to this domain. Based on these concerns, I am currently leaning toward ‘weak reject’ as I think the technical contribution is solid, but the presentation is weak to the point where I still have some remaining questions and don’t think I will really understand what is happening in some sections until I look at the code. As the model is somewhat complicated, I understand that this is difficult to solve — but I think possible. However, I am ambivalent and would rate as borderline if available and thus am looking forward to further discussion."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper presents an end-to-end multi-domain task-oriented dialog system by a novel end-to-end neural architecture to separate out slot and domain modules to achieve the state-of-the-art results on MultiWOZ 2.1. The paper also proposed a response generation module without system action annotation. \n\nWhile the approach is well-motivated and well placed in the literature for multi-domain task-oriented dialogue system, the idea of separating out slot and domains are not very new. The neural architecture is novel however it is an assembly of transformers and attention which is not also very innovative considering the previous literatures. What's more, I found some of the details are very hard to follow in the paper and the delivery of the paper could be better.  Here are a few of my questions:\n\n1. How does the request/inform slot being determined is not well-mentioned in the paper. As far as my personal knowledge, there is no information about request/inform slot information for dialog state at each turn in MultiWoz 2.1, it would be great if the paper could describe how to get these labels. \n\n2. What is the meaning of “keeping slot token sequence fixed in all dialogue examples” ? Does that mean for a particular dialogue, the slot token sequence is unchanged across different turns?\n\n3. What is the difference between slot token sequence and belief state? I can see the only major difference is that belief state contains values and slot token sequence does not have values.\n\n4. In the experimental session, you mention there are N_s = 35 inform slots in total, but in the previous section, the paper mentioned N_s = N_s(inform) + N_s(request). So is N_s representing the number of inform slots or the number of inform+request slots?\n\n5. Table 3 is reporting the ablation studies on the test set,  it would be nice to see the numbers on the development set as well. \n\n6. What is the impact of the domain module? if removing the domain module and consider all slots are in one domain, what is the accuracy ? \n\nWithout clear delivery of the paper and rigorously proof of the effectiveness of the approach on other dataset, although it claims to achieve the-state-of-the-art results on MultiWOZ 2.1, it can be only considered as an application paper and can hardly meet the standards in a conference like ICLR. \n\n\n\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper presents a deep neural architecture for dialogue systems. It relies on a novel belief state tracking approach based on a transformer architecture. The method is tested on multiWOZ dataset. \n\nThe paper is very descriptive of the architecture and doesn't motivate very well the choices that were made. I feel the authors were very much influenced by the dataset they will test their method on which led to very specific design choices. The dialog state is supposed to be representable by a set of key-value pairs which is a strong assumption. It comes from a long tradition of slot-filling applications in the field of spoken dialogue systems but I feel this choice makes the work very ad hoc. Especially, the response generator is strongly dependent on that structure. \n\nI also feel that belief tracking makes more sense in the case of a spoken dialogue system that can introduce additional ambiguity because of speech recognition errors. Here, the input text is supposed to represent quite accurately the intent of the user. It comes again from the chosen test data set. \n\nAll in all, I feel the proposed architecture would not serve the general purpose of developing end-to-end dialogue systems for multi-domain applications. It only solves the targeted task (multiWOZ). Thus, I'm not sure what is the scientific/technical contribution of the paper. I'd like the authors to comment on that. \n\n"
        }
    ]
}