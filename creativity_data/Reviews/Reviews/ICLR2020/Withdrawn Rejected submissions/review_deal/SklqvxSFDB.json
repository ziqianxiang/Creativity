{
    "Decision": "",
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The proposed method addresses the problem of predicting per-time-step corrections for the motion estimates produced by a visual odometry (VO) system. A training dataset is aggregated, collecting errors of the considered VO system (libviso2) as observations and the images for the respective time steps as conditional inputs. A convolutional neural network is then trained to amortize a predictive multivariate Normal distribution that should fit the observed errors. The inputs to the network are the images at the current time step. The network parameters are optimized with stochastic gradient descent, maximizing the log-likelihood of the observed error w.r.t. the predicted Gaussian model. The authors also propose modifications to an existing convolutional neural network architecture. The method is evaluated on the KITTI and EuroC data sets.\n\nThe reviewer recommends rejecting the paper. In its current state it is not possible to judge the contributions due to a lack of clarity in the experiments section and because a highly relevant metric is omitted (long-term translation and rotation error). The results on uncertainty quantification are hard to judge.\n\nMajor Comments:\n\n1) The method described in the paper is justified.\n\n2) Section 3 fails to point out the exact differences to the cited prior work. For example, the assumed LDL decomposition appears the same as in the work  by Lie et al. 2018. It should be stated more clearly what the delta is to the work of Peretroukhin & Kelly 2018 that lets the CNN predict the Normal mean, and to the work of Lie et al. 2018 that has the CNN predict the Normal covariance matrix. After looking at the respective papers, it appears the two methods have been combined in a single consistent Gaussian model without further modification.\n\n3) The summarized statistics in Table 2 are not clear. Are those the predicted statistics from the amortized conditional distribution? Or are they the empirical diagonal Gaussian statistics computed over the VO transformations which have been corrected by the mean predicted by the network? The latter is my current best guess given the highlighting. However it is not clear what this metric would show us in terms of model performance.\n\n4) Quantifying the quality of the residual uncertainty estimates via the ratio of observed residuals that fall into the +/- 3 sigma band of a diagonal Gaussian seems like an arbitrary choice. The neural network is supposed to predict a full multivariate Gaussian distribution - why not utilize the full covariance matrix? For example, one could compute log-likelihood scores w.r.t. the predictive model. The authors of DICE evaluate their uncertainty estimates by illustrating a correlation between uncertainty and error magnitude. A similar experiment would be helpful here to judge the quality of the uncertainties.\n\n5) The last sentence right before the conclusion is unclear. What is meant under \"the results from considering an unbiased error\"â€”was a second model that assumes a zero-mean Gaussian fit to the data, similar to DICE?\n\n6) The paper is missing evaluations that demonstrate the overall and piece-wise reduction of drift in the visual odometry system when the predicted corrections are applied. The last two figures showing a single example from KITTI are not sufficient to judge the effectiveness of the method. For instance DPC-net, which the authors compare against, reports three metrics of long-term pose error (See: C. Evaluation Metrics of https://arxiv.org/pdf/1709.03128.pdf). It is not possible to evaluate the contribution of the method without looking at long-term trajectory estimates and how they change after applying the proposed model.\n\nSuggested improvements:\n\n1) The paper needs an experiment detailing long-term pose error with and without the proposed method.\n2) It is hard to interpret section 4.2.3. The paper would benefit from an experiment showcasing the usefulness of uncertainty."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The field of visual odometry is very extensively researched. Coming up with a substantial improvement in the results is non-trivial.\nThe proposed loss function introduced in this paper seems like a variation of the \"Deep inference for Covariance Estimation:  Learning Gaussian Noise Models for State Estimation.\" (Liu et al., 2018), with a lot of the similar computational tricks being imposed to ensure a reasonable loss function. So, the main contribution to the paper seems like a marginal improvement over previously proposed methods.\nThe results don't altogether seem better for the proposed loss function. The pitch error especially in KITTI is significant, as this is one of the variables most in flux. The improvement in uncertainty estimation also is not apparent. It is better for some variables, worse for others, relative to VO, which is not infact based on deep learning.\nThere is also the appropriateness of choosing this conference, which should be questioned. This maybe belongs in a robotics conference.\n"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper introduces a residual learning approach to visual odometry, learning an error correction term to complement traditional visual odometry pipelines. In contrast to existing work, which tends to use a correction network following a zero mean Gaussian error model, this work proposes a Gaussian error correction term using a full covariance matrix, and non-zero mean error model, introducing a modified loss to do so. This makes this work somewhat incremental. However, well calibrated visual odometry systems with a measure of uncertainty are crucial to downstream processes in robotics, so this is an important topic.\n\nMinor:\nThere are some language choices and typos that make the paper somewhat difficult to follow. For example, the paper repeatedly uses the phrasing \"... deep learning can be sided to classifical visual odometry\" to indicate learned error correction. I think the paper would be clearer if the contribution was described in the context of residual learning, and the paper proof read to correct other typos.\n\nThe paper uses a 3 sigma outlier test to assess the quality of the learned error model. While I appreciate the fact that the paper does evaluate the uncertainty model, this is a weak test, and a better test for normality would be more useful.\n\nMajor:\nTraining process, tests were conducted on held out sequences from the Kitti dataset. Were the sequences captured in areas previously seen during training, or on similar routes?\n\nI am concerned about the scope of the work and it's potential interest to an ICLR audience. Visual odometry is a very specific application, and a more general paper on uncertainty estimation for residual learning would be better aligned to ICLR, with the addition of experiments in other settings, than this paper which is very specifically focused on VO. As it stands, the paper seems better suited to a robotics conference like ICRA or IROS.\n\nThe paper does a good job of providing detail on experimental architectures and parameter settings. However, in the experimental results, the paper states that the proposed NLL loss and the prior work lie algebra formulation are similar, but the 2 degree yaw error is quite a bit larger than the prior work. By my reading, the table seems to indicate that the lie formulation is actually better at correction, or that the greater expressiveness of the error model reduces the residual corrections ability to correct the odometry.\n\nUnfortunately, given the incremental nature of this work and the lack of particularly strong results, I lean towards rejecting this paper."
        }
    ]
}