{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper presents a single image super-resolution method that uses a rendered face and the corresponding parameters as priors into its residual block network layers. Given an LR image, it computes a vector of 3DMM coefficients that represents identity, facial expression, texture, illumination and pose using a face rendering network based on ResNet50 after upsampling the LR image. Using these coefficients, it reconstructs 3D shape and texture images. The coefficient vector is transformed into feature maps by reshaping, resizing and zero-padding, and concatenates them with the reconstructed face and fed into the SR network. These priors are spatially affine transformed (details are missing in the paper and the notation is confusing) and applied into a chain of spatial attention blocks, which are followed by a residual channel attention block. The feature maps deconvolved and upsampled to HR size to obtain the final SR image. The loss is computed using MSE.  \n\nExcept using a reconstructed image and heuristically rearranged coefficients as a prior, the novelty is very weak. \n\nPresentation requires a revision, many important technical details are not clearly explained. Is only MSE is used for the loss? How two branches are trained (in an alternating fashion, separately, end-to-end, etc.)? Why the face reconstruction network is not fine-tuned?\n\nThe ablation study is substandard at best since it fails to provide a detailed understanding of how hyper-parameters affect the final results. It is not clear how accurate the reconstructed prior would be for 16x16 inputs (samples for 32x32 are shown). How are the 3D shape/texture reconstruction errors handled for 16x16 inputs? 3D prior does not provide any hair texture info,  yet the estimated SR images have refined hairs than the bicubic inputs, does this indicate the prior is useless? No analysis of alternative choices for the coefficient arrangement is provided.  \n\nThe generated results look like bilateral filtered as they are over-smoothed without any texture. \n\nThe experimental evaluations are missing the method [1] which reported comparably competitive results for 8x SR than the prior work evaluated in this paper. \n\n[1] X. Yu et al., Face Super-resolution Guided by Facial Component Heatmaps, ECCV 2018. "
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "In this paper, the authors introduce a super-resolution method especially tailored for facial images. The main contribution of this work lies in: (a) utilizing a 3D face reconstruction branch which is used to extract 3D face priors, and (b) using the Spatial Attention Mechanism to adaptively integrate the 3D face prior in the network. \n\nI am inclined to reject this paper as I deem that:\n\n- there is a lack in novelty: (a) Spatial Attention Mechanism is based on already existing works in the literature, i.e., Spatial Feature Transform (Wang et al, 2018) and Attention Mechanism (Hu et al., 2017). In particular, for the super-resolution task, Residual Channel Attention Blocks are employed in the recent work of Zhang et al., 2018b (RCAN), (b) the introduction of the priors from the 3D face rendering process is incremental. I understand that this addition makes the difference from the compared methods as this method is tailored for faces and incorporating relevant information such as identity will definitely help. However, the idea per se is not novel enough.\n\n- the baseline is weak. This paper is focused on face super-resolution (also known as face hallucination).  The authors should have compared with SOTA methods in face hallucination such as Super-Identity Convolutional Neural Network for Face Hallucination (Zhang et al., ECCV 2018), which is especially tailored for recovering the face identity during the generation process. \n\nAdditional comments:\n\nFaces are a significant area of Machine learning research, but can your method generalize in other domains and if so, how? \nIn Fig. 2, how many times do you apply the Residual Channel Attention Blocks? Have you seen any increase in the performance depending on the number of times you apply them?\nPlease cite RCAN (Zhang et al., 2018b) in Section 4.2, where you write about the Residual Channel Attention Blocks.\nBe consistent in the notation. For example, in Section 3, you use bold letters for the matrices/vectors in Eq (1) but you do not do so in Eq (3) (e.g., image I is a matrix, etc.).  Also, put the vectors in bold in Eq (4), etc."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper presents a new face super-resolution method that explicitly incorporates 3D facial priors which grasp the sharp facial structures. Experimental results on CelebA and Menpo verified the efficacy of the proposed method.\n\nThe writing and presentation are good. The problem solved in this paper aligns with real applications.\n\nMy concerns regarding this paper are as below.\n1) What are the training computational complexity and testing time cost of the proposed method compared with other SOTAs, since speed is very important for real applications.\n2) The datasets compared in this paper are quite old, more experiments on more recent challenging benchmarks are needed to verify the superiority of the proposed method, e.g., IJB-/C.\n3) How did the authors create the low-quality images? How did the authors ensure that such created low-quality images can represent real scenarios?\n4) Some related works should be discussed, e.g., Cross-Resolution Face Recognition via Prior-Aided Face Hallucination and Residual Knowledge Distillation [Kong et al., 2019], 3D-Aided Dual-Agent GANs for Unconstrained Face Recognition [Zhao et al., T-PAMI 2018].\n5) Format of references should be consistent."
        }
    ]
}