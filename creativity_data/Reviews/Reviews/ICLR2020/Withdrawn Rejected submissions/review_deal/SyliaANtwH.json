{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "In this paper, the authors propose a new model to generate adversarial poisoning examples. The generation model is based on MAML and the experiments partially show the effectiveness of the proposed method.\n\nThe problem is interesting and using MAML to generate adversarial poisoning examples is timely. However, my concerns are:\n\n1. The paper is not well-organized. For example, (1) the first section should be named as \"Introduction\"; (2) In figure 6, the location of three figures is not in a line.\n2. The technical contribution is limited. The authors simply apply MAML to generate adversarial poisoning examples. The motivation is clear but the design is quite straightforward. No new attack/defense models are proposed. I think the contribution is lower than the acceptance bar of ICLR.\n3. No baselines are compared. The authors should compare the proposed model with other adversarial sample generation methods in the experiments."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper introduces a novel class of clean-label attacks of deep model training procedures (from scratch) using a meta-learning inspired approach. \n\nPros:\n1) Transferability across different training strategies is a particularly important novelty of this work, I think.\n2) I find it particularly impressive that a clean-label attack is shown to work when training from scratch, which reduces the amount of knowledge about the model needed by the attacker.\n3) The meta-learning formulation presented here may prove to be the starting point of many future investigations.\n4) Multi-targeted attacks and third-party attacks appear to be novel contributions of this paper, but there is too little context given to judge that from the text alone.\n\nCons:\n1) The figures are not too informative. Could you please provide more examples in an appendix?\n2) The writing could be much improved, especially for making the paper more accessible to a wider audience.\n3) Details of the meta-learning procedure and related works are almost non-existent. While the authors provide a discussion of what's possible and challenging for current adversarial attack methods, many details and citations are missing. This makes the many comments and explanations in the text obscure, although they may be correct and insightful. Could you please work on the writing and assume that I know nothing of the SOTA in adversarial attacks? I am willing to read the paper again.\n4) There is far too little detail about experimental procedures. Please provide a detailed discussion with references to established procedure or previous works!\n- What are the meta-training/meta-validation and meta-testing sets? \n- What is a reasonable baseline you could compare against? If nothing else, please argue for that in the paper and perhaps provide an ablation of your method as a baseline.\n\nAs far as I can tell, the paper may be introducing an approach with potential, but many clarifications are required. The paper is not self-contained enough to even attempt to guess how important or novel the presented results are. Hence, all I can do is judge the little I have managed to understand from the paper. While this may be enough for a workshop, I cannot at this point recommend acceptance, primarily because of the writing. "
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "\nSummary\nThe authors propose solving data poison bi-level optimization using the meta learning formulation. \n\nDecision\nOverall, I think the proposed meta-learning formulation seems legit, but I found the formulation of metalearning is hard to parse and the experimental comparison is not persuasive. Hence I recommend for weak reject.\n\nSupporting argument:\n1. The written can be improved in describing the meta learning formulation. Usually there is a clear definition of meta-learning training/testing tasks and training/test examples in each task. \n2. 16/255 is quite large for CIFAR10. What happen in other radius? Can the approach work in other constraints? \n3. In figure 4, the variance of the success rate, target loss are quite large. I wonder whether this means the approach is not stable.\n4. Since it is the first clean-label poisoning attack on networks trained from scratch, it might be worth comparing the approach to other setup where there are some baselines.\n5. The arrangement of figures are far away from text.\n6. In Algorithm 1 Line 5, I don't get the part why there are M models instead of M-th model. In Lines 9, 10, the formulation is not clear. What's the reason for Line 11?\n7. It is not clearly to me why there needs to be M models to consider. What's the performance with different M?\n\n\nAdditional feedback:\n1. Footnote should go after period. \n"
        }
    ]
}