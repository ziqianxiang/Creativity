{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper proposed an unsupervised few-shot object recognition method by integrating GAN, Self-supervised learning, and deep metric learning of latent parts. The contributions of this paper are.\n1)\tImprovement of GAN by using the uniformly sampled codes and reconstruction loss. \n2)\tUse of an image masking procedure for triplet loss sampling. \nThe proposed ideas are interesting, and experimental results show very high performances compared with previous unsupervised few-shot learning methods. \n\nOn the other hand, there are several weak points, which are summarized below. \n\n1. The authors claimed the discrete latent codes correspond to parts of an object in images. However, if the discrete codes really correspond to parts is not verified.\n\n2. In the abstract, the authors wrote that the reconstruction loss enforces the discriminator to capture the most relevant characteristic of “fake” images. However, it is not clear why capturing the characteristics of “fake” images leads to improve the performance of few-shot recognition. \n\n3. The ablation study is incomplete. On p.2, the authors wrote that the discrete encoding gives better performance than the continuous counterpart. However, Table1 reports only the performance of BCE, which includes both discrete encoding and reconstruction loss. Thus, it is not clear if both discrete encoding and reconstruction losses are effective. Also, the performances of GAN+ROT, GAN+METRIC, and other combinations of each method are missing. \n\n4. Lacking some closely related works.\n\nB.Zhang, T.Che, Z.Ghahramni, Y.Bengio, Y.Song, MetaGAN: An Adversarial Approach to Few-Shot Learning, In Proc. NeurIPS 2018. \nS.Gidaris, A.Bursuc, N.Komodakis, P. Perez, and N. Cord, Boosting Few-Shot Visual Learning with Self-Supervision, arXiv:1906.07079. \n\n5. Random erasing data augmentation also uses erased rectangle regions for data augmentation. It is not clear if the triplet-based training is better than using masked images for data augmentation. \n\nZ.Zhong, L.Zheng, G.Kang, S.Li and Y.Yang, Random Erasing Data Augmentation, arXiv:1708.04896. \n\n"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "= Summary\nThis paper tackles a new image recognition task called unsupervised few-shot object recognition, which is the few-shot classification with unlabeled training images of unseen classes. The proposed model is learned to discover and predict object parts shared among different object classes so that it can utilize the part information to represent target object classes in the support set during testing. The model is trained by multiple loss functions that have been proposed for GAN and self-supervised learning so far. With the model, the proposed method achieves impressive performance on the task, even outperforming the prototypical network relying on stronger supervision. \n\n\n= Decision\nIn spite of its notable performance, my current decision is reject mainly due to the following reasons.\n\n1. The target task (i.e., \"unsupervised few-shot object recognition\") seems neither realistic nor practically useful. The task assumes that there is no labeled training images at all, but in these days image-level class labels are very cheap and readily available in a large-scale well-established datasets like ImageNet; there is no reason to avoid them during training. \n\n2. The technical contribution is limited. The proposed approach is a combination of many existing losses and tasks. Furthermore, there is no clear justification for the components and their combination (e.g., what's the effect of the rotation prediction?), except the empirical verification in Table 1. Besides, the two-stage training strategy is not justified too. The method thus seems like a naive multi-task learning approach in which well-known tasks relevant to the target task are all adopted for training. \n\n3. The metric learning part is something new and its basic idea sounds quite interesting. However, its implementation is not convincing enough due to its main assumption: corner patches of an image will not be relevant to object parts while center patches will include distinctive object parts. This assumption does not hold always, but it depends on the image content.\n\n\n= Other comments\n1. In the manuscript, D is often called \"discriminator\", but it is not true as D has three branches and only one of them, specifically, D_r/f plays the role of discriminator. This could make future readers getting confused. \n\n2. The metric learning objective used in this paper also relies on a kind of self-supervision, so it seems natural to introduce this objective together with the rotation-prediction in the self-supervised learning section.\n\n3. Not justified: \n- Sampling from the uniform distribution \n- Predicting binary values (one of -1 and 1) instead of continuous numbers within [-1, 1]"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This submission aims to improve unsupervised representation learning by combining several known methods into a single framework. The representation is tested on a few-shot learning task, by taking the nearest neighbor in the learned space. The combination of techniques results in impressive results.\n\nMy decision is reject, because of mainly two reasons: 1. The paper does not relate its method well to the literature. This leads to inadvertent claims of novelty. These missing key citations also means there is little discussion and analysis around what makes this work different from previous works. 2. The experimental evidence is sparse, with only a single table comparing against four previous papers. There is also little ablation studies and analysis.\n\nRelevant work:\n\nThe idea to add a “reconstruction loss” to the vanilla GAN is similar to works like Adversarial AE [1] and BiGAN [2]. The latter is the only one cited in this paper, but only in the results table and there is no mention in related work. The formulation is not exactly the same though, but quite similar. For instance, if we call the x -> z network E, then this paper adds a reconstruction loss to L(z, E(G(z))) while [1] adds it to L(x, G(E(x)). This difference should be pointed out and discussed. Is there a benefit of one over the other? What about the BiGAN formulation? If this particular formulation does not offer any improvement, then this is not a novelty.\n\nRotation for the purpose of self-supervision from Gidaris et al. is not cited. The paper mentions that rotation has “state-of-the-art performance reported in the literature”, acknowledging that this is not a novelty; however, a citation is missing.\n\nUsing object center bias (which is used in the masking strategy) has plenty of prior work, but there is no discussion around this. I’m not sure what the key citations in this area should be, but searching the web for “object center bias” yields several starting points. I believe this formulation with a triplet loss is novel, but it should be more clear how novel this is compared to prior object center-bias literature.\n\nExperimental evidence:\n\nThe core method itself does representation learning on any unlabeled dataset. This is tested using unsupervised N-way K-shot classification with nearest neighbor. A direct comparison with the related task of semi-supervised N-way K-shot is unfortunately not possible, so the number of comparisons to prior work is small. However, I don’t see why this work couldn’t be used in an unsupervised pretraining/classification fine-tuning setting that the self-supervised literature has embraced. Having a second results table that compares to this body of literature would make this work much more compelling, especially if the numbers are competitive.\n\nI think the paper could also use more ablation studies and analysis. It would be interesting to see ROT alone (it always good to compare with the original implementation), METRIC alone, and ROT+METRIC. It would be interesting to see numbers comparing Adversarial AE, BiGAN, and this method. There are many hyper parameters too, so an insight into how sensitive it is to get these right would be interesting.\n\nMinor:\n\nThe notation for D is a bit confusing. Sometimes D without subscript refers to the real/fake classifier, and sometimes to the reconstruction.\n\n[0] Unsupervised Representation Learning by Predicting Image Rotations - Gidaris et al. ICLR 2018\n[1] Adversarial Autoencoders, Makhzani et al.\n[2] Adversarial Feature Learning, Donahue et al. ICLR 2017"
        }
    ]
}