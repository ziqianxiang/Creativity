{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes to compare the recognition performance of hyperbolic representations (learned with hyperbolic network layers) with other types of representations in Euclidean or spherical geometry. The comparison is performed in several computer vision contexts: image classification, one/few-shot learning and person re-identification.\nThe paper experimentally shows that hyperbolic representations can (sometimes) obtain better performance than Euclidean or spherical embeddings.\n\nThe paper is well-written, the context and background are very clear.\n\nAlthough the reported results show that there exist contexts where hyperbolic representations perform better than Euclidean representations, I vote for reject for the following reasons:\n\n- There is a lack of novelty in terms of machine learning methodology: the paper only applies existing ML approaches on different computer vision tasks. Therefore, since it is an experimental paper, I would expect more insight on the results. In the current version, the only insight provided that the paper is that representations pretrained with VGG have good hyperbolicity scores (see end of Section 4). \nIf I understand correctly, VGG16 representations were pretrained with a standard classification framework without exploiting hyperbolic geometry. Since the datasets have hyperbolicity score close to 0, this means that hyperbolic representations are appropriate. This is an interesting result. However, that part could still be improved by studying the hierarchies that can be extracted from the different datasets (CUB/miniImageNet/omniglot). Maybe there could be some insight about the hierarchies intrinsically learned by the VGG model.\n \n- In Section 5.1, it is mentioned that images difficult to classify are close to the origin whereas easy images are more far away. This seems natural since hyperbolic distances tend to grow exponentially as points get further from the origin. Therefore, difficult images (i.e. close to the origin) are close to the decision boundaries of the different categories. On the other hand, easy images are very close to only one decision boundary (w.r.t. some hyperbolic distance) by having a larger Euclidean norm. \n\n- The results in Section 5.2 are not really significant: the advantage of hyperbolic representations seems significant only in the 1-shot 5-way scenario. However, Euclidean representations seem better in the 5-shot 20-way, this kind of scenario is less prone to randomness since there are more examples to represent each category (i.e. the test accuracy is less dependent on how the support set is sampled since there is less randomness to represent a category at test time). This experiment should include standard deviation to have a better understanding of the statistical significance.\n\n- The results in Table 4 (which correspond to Section 5.3 and 5.4) are fishy. The hyperparameter c is related to the curvature of the space. It was for instance already observed in ref [A] that the curvature of the space has an impact on recognition performance. \nWhy do you report results only for c in {0.05,0.0007} on MiniImageNet and in {0.05,0.0005} for CUB (respectively best scores for 1-shot and 5-show)? Why do you not report results for other values of c (e.g. c=1)? How was c cross-validated? That value of c=0.0007 on miniImageNet does not seem conventional. The paper should provide more insight on the choice of c since it seems like an important hyperparameter. \n\n\n\n\nI also have a question: \nThe method proposes to replace the average vector of ProtoNets (Snell et al., 2017) by the gyrocentroid [B] (Eq. (2) of the submission, also called Einstein (gyro)midpoint). However, the choice of the average vector in (Snell et al., 2017) is motivated by the formulation of ProtoNet which is a special case of ref [C], the average vector is then the minimizer of some expected distortion (see Section 3.1 of [C]) called Bregman information. \nAs explained in [B], the gyrocentroid preserves left gyrotranslation. Is the Einstein gyromidpoint is not a minimizer of some expected distortion for more than 2 points?\n\n\n\nIn conclusion, the paper shows that hyperbolic representation can outperform Euclidean or spherical representations in some computer vision contexts. However, the paper lacks some insight, and some choices (e.g. the value of the hyperparameter c and the choice of midpoint) need clarification.\n\n\n\nReferences:\n[A] Law et al., Lorentzian distance learning for Hyperbolic representations, ICML 2019\n[B] Ungar, Analytic Hyperbolic Geometry in n dimensions: an introduction, 2014\n[C] Banerjee et al., Clustering with Bregman divergences, JMLR 2005"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "The authors show that changing the Euclidean geometry to the hyperbolic one in the final layers of neural networks *sometimes* benefits the computer vision tasks.\n\nStrengths:\n1. The paper is well-written.\n2. This is a reasonable attempt to transfer the success of hyperbolic language embeddings to vision tasks.\n\nWeaknesses:\n1. The second part of the motivation (Fig. 2, right) about blurred images being more generic than those with higher resolution sounds far-fetched. If this is a by-product of training, then maybe it's better to present it as such.\n2. There're experiments on a variety of datasets, but there is no proper analysis of the obtained results - why it works in some cases but does not work in the other. The authors defer this to future work, but I believe that for the paper to be complete this should be done here so that future work concentrates on weaknesses of the approach.\n\nQuestions:\n1. The last paragraph of Sec. 2 (p. 3) says that \"The hybrid nature of our setups makes the origin a special point ... This leads to the useful tendency of the learned embeddings to place more generic/ambiguous objects closer to the origin while moving more specific objects towards the boundary\". But wasn't this the case for purely hyperbolic embeddings as in the work of Nickel and Kiela (2017)?\n2. Since we already know that embedding graphs and words into a product of hyperbolic spaces is more beneficial than embedding them into a single hyperbolic space (Gu et al., 2019), why not trying the same for vision?\n\nReferences\n- Gu, A., Sala, F., Gunel, B. and Ré, C., 2019. Learning Mixed-Curvature Representations in Product Spaces. In Proceedings of ICLR\n- Nickel, M. and Kiela, D., 2017. Poincaré embeddings for learning hierarchical representations. In Proceedings of NeurIPS."
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The authors argue that existing image classification/retrieval models fail to explore the hierarchical distribution of the image data. For this reason, they propose an image embedding framework by transferring the computation from Euclidean space to the hyperbolic space. The work is closely related to hyperbolic neural networks. Experimental results on several benchmarks show the performance of the proposed model. \n\nMy main concern is regarding the motivation and the technical contribution of this paper. \n(1) the example of MINIST in Fig. 1 can not well support the argument of this paper. Why MNIST (digits) exhibit a hierarchical data distribution? Why using Poincare embedding is beneficial for image classification in MINIST? In contrast, I like the examples shown in Fig. 2.\n(2) the technical contribution of this paper is not clear. The authors simply generalize some distance or averaging functions from Euclidean space to the hyperbolic space for learning the Poincare embedding, let along [Ganea et al., 2018] is already published in the literature. \n(3) In the experiments, the authors may want to provide more discussion about why hyperbolic embedding is necessary for the studied datasets. "
        }
    ]
}