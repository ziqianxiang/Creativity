{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper constitutes interesting progress on an important topic; the reviewers identify certain improvements and directions for future work, and I urge the authors to continue to develop refinements and extensions.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper introduces Skip-gram style embedding algorithms that consider attribute distributions over local neighborhoods. Algorithm 1 and 2 shows that in fact they propagate randomly selected node features to neighbors. The reviewer doesn’t think this random-walk way for selecting node feature is appropriate.  Node features describe node content. The features of neighboring nodes may complement each other. However, there is no benefit to select random features and then propagate, given that there already many approaches smartly combining node content in neighborhood. \n\nThe proof part follows Qiu et al (2018). But it is unclear, why c^{−1}A is the stationary joint distribution over consecutive nodes p(wj , wj+1).  and c^{−1}DF describes the stationary joint distribution p(f,wj) over nodes and features. There needs more explanation. \n\nThe Remark 1 and 2 discuss the case AE with F=I_|V|,  which is in fact the case when there is no node attributes. In this case, the AE process naturally goes back to plain network embedding, where DeepWalk and WalkLets are proposed for. Therefore, these remarks are done by Qiu et al (2018) already, not make no much new contribution here. \n\nFigure 2 shows that the presented two approaches just slightly better or equivalent, or sometimes worse than baseline methods. As mentioned earlier, it is not beneficial to randomly select features to propagate. \n\nThe experiments presented in Section 5.2 evaluate whether the learned embedding can be used for label inference in a different graph. But it is unknown how success the transferring is. There is no F1-score of a solution that does embedding of the target network itself independently, and then classify the target network nodes. \n"
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This manuscript introduces embedding algorithms that consider attribute distribution. To address the multi-scale attribute information, the multi-scale version of AE is derived (MUSAE). Then the proposed algorithms are proven theoretically to implicitly factorize the PMI matrix, which enhance their interpretability. The experiments are conducted on various scenarios including node classification, transfer learning, regression and link prediction. showing the quality of learned embeddings. The results show the benefits of multi-scaling and several conclusions are drawn.\nFollowing are some review’s questions:\n1. In MUSAE, what is the intention that the tuples are added to different sub-corpus for source and target nodes? Besides, the D_r should be a corpus rather sub-corpus.\n2. In 5.2, I’m not quite understand what do you mean by ‘vanilla MUSAE and AE are inductive and can easily map nodes to the embedding space if the attributes across the source and target graph are shared’."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "This paper proposed an attributed network embedding method by leveraging a node’s local distribution over attributes. The neighborhood attribute distribution of a node is considered in both a pooled and a multi-scale way. The multi-scale embedding approach considers the neighborhood nodes with different distance to the interested node distinctly, providing more flexibilities to the model. Then, the paper proved theoretically that the proposed embedding methods, both the pooled and multi-scale versions, can be equivalently written the factorization of a node-feature pointwise mutual information matrix.\n\nThe proposed embedding methods are standard. The key contribution of this paper comes from the theoretical part, which establishes the equivalence between the proposed embedding methods and matrix factorization. It looks interesting, although there are several similar works before, as mentioned in the paper. I don’t know how different your work is from the Qiu’s paper.\n\nThe experimental results are not convincing. The node classification is a very standard task in the performance evaluation of network embedding, but you put the results into the appendix. I examine the results anyway, and I found the performance gain is very limited, and on some datasets, the proposed methods even perform inferiorly.\n"
        }
    ]
}