{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper proposes  an interesting idea to leave a very simple form for piecewise-linear RNN, but separate units in to two types, one of which acts as memory. The \"memory\" units are penalized towards the linear attractor parameters, i.e. making elements of $A$ close to 1 and off-diagonal of $W$ close to $1$. \nThe benchmarks are presented that confirm the efficiency of the model.\nThe reviewer opinion were mixed; one \"1\", one \"3\" and one \"6\"; the Reviewer1 is far too negative and some of his claims are not very constructive, the \"positive\" reviewer is very short. Finally, the last reviewer raised a question about the actual quality on the results. This is not addressed. Although there is a motivation for such partial regularization, the main practical question is how many \"memory neurons\" are needed. I looked through the paper - this addressed only in the supplementary, where the value of $M_{reg}$ is mentioned (=0.5 M). For $M_{reg} = M$ it is the L2 penalty; what happens if the fraction is 0.1, 0.2, ... and more? A very crucial hyperparameter (and of course, smart selection of it can not be worse than L2RNN). This study is lacking. In my opinion, one can also introduce weights and sparsity constraints on them (in order to detect the number of \"memory\" neurons more-or less automatically). Although I feel this paper has a potential, it is not still ready for publication and could be significantly improved.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "Overview\nThis paper proposes a type of regularization for recurrent networks, with the goal of encouraging particular dynamical structures (in this case, line attractors) in the dynamics of the networks. The proposed regularization penalty is only applied to a subset of the recurrent units; the motivation for this is to allow neurons not contained in the subset to learn different structures. The paper applies this regularization method on three example machine learning sequence tasks: an addition task, a multiplication task, and sequential MNIST classification, as well as on learning a 2-D dynamical system model of a bursting neuron with two different timescales.\n\nMajor comments\nI have a number of serious concerns about the paper's motivation, logic, and experiments:\n\n- First, the paper motivates the proposed regularization as a way to encourage the network to have line attractor dynamics. In particular, the paper dismisses gated architectures as not being interpretable, stating that LSTMs and GRUs \"are complicated and tedious to analyze from a DS perspective.\" (pg 2). However, there is recent work both theoretical (https://arxiv.org/abs/1906.01005) and empirical (https://arxiv.org/abs/1907.08549) that analyzes these gated architectures from a DS perspective. In particular, these papers demonstrate that LSTMs and GRUs are perfectly capable of learning line attractors. Given that it is possible to analyze gated architectures as dynamical systems, the overall motivation of the paper is much weaker.\n\n- The paper proposes a squared penalty on subsets of the weights in the recurrent network as a way to encourage line attractor dynamics. However, it is not clear to me that this is sufficient. In particular, unless the subset of the network that implements the line/plane attractor is completely disconnected from the rest of the network, then the overall dynamics may not contain a line attractor (the units will interact with the unregularized units). Also, the proposed regularization penalty only penalizes the diagonal elements of the A matrix to be close to 1--but shouldn't the off diagonal elements also be penalized to be close to zero?\n\n- Moreover, the paper makes no mention of the Jacobian of these recurrent networks. The eigenvalues of the Jacobian of the recurrent networks determine the behavior of the linearized system around fixed points--specifically, eigenvalues with real part close to 1 will exhibit slow dynamics (approximate line attractors along those dimensions). It seems to me that a much more natural way of encouraging line attractor dynamics is to place a regularization penalty on the Jacobian itself (which is analytically tricky, but numerically more plausible with modern autodifferentiation software). Regardless, the authors should compare the eigenvalues of the recurrent networks' Jacobian when using their regularization method vs without it. Does the proposed regularization encourage the Jacobian of the resulting networks to have eigenvalues close to 1?\n\n- The paper compares the proposed method with a number of vanilla RNNs with different initializations, and an LSTM. However, a critical missing baseline is simply an RNN with l2 regularization on the weights (standard regularization in the literature). This baseline is important to determine if the proposed regularization simply helps because it is an l2 penalty on the weights (note that none of the other baselines have regularization).\n\n- The paper motivates the method as trying to study line attractor dynamics, but then does not apply them to tasks where line attractors are required. For example, the addition and multiplication tasks require discrete memories, not line attractors. The bursting neuron approximation (2D dynamical system) also does not involve a line attractor. However, there definitely exist tasks both in neuroscience (e.g. sensory integration in decision making, path integration in navigation, etc.) and in machine learning (c.f. https://arxiv.org/abs/1906.10720) that use or require line attractors. The motivation of the paper would be much better tested on these tasks.\n\nMinor comments\n- The authors comment at the beginning of page 4 that by setting A=I, W=0, and h=0, the network contains a line attractor, but the more precise language would be to state that the network contains an N-dimensional plane attractor, where N is the number of units. Typically, 'line attractor' refers to a 1-dimensional manifold of fixed points along which the system can integrate inputs, but perturbations off of the line attractor are not remembered (decay back to the line attractor)."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The paper proposes a regularization scheme to improve the ability of RNNs in capturing long-range dependency in the latent space. The proposed model then uses EM for inference and achieves superior performance in sequence modeling tasks over LSTMs and iRNNs. \n\n+ The motivation of the line attractor is novel and effective. The special RNN model studied in the paper has strong connections with neuro-dynamics models. \n+ The paper is well motivated and clearly written. The illustration about the line attractor is particularly interesting. \n+ Good experimental performance on multiple sequence modeling tasks including addition, multiplication and sequence MNIST.\n\n- The paper is building a generative model for sequences. It’s not clear to me why VAE or variational RNN type of approaches cannot be used in this setting. One might think of replacing the Gaussian prior with more complex distributions. The inference procedure can also be significantly simplified with variational inference.\n- The step-wise annealing together with EM inference is not scalable, which prohibits the model from applying to large-scale sequence modeling tasks. \n\nMinor comments\n- \" All code used in this work is freely available on the github site ... . \" Remove this sentence\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper presents a regulariser that encourages the formation of line attractors in RNNs. This regulariser works on a neuroscience-motivated formulation of RNN, bringing the Jacobian of the dynamic system close to identity. This paper is well-written, with a good coverage of background material from machine learning to computational neuroscience.  While the alleviating the exploding and vanishing gradient problem for simple RNNs is an interesting direction, I think the empirical results are not sufficient to support claims in the paper.\n\nThe paper starts by criticising initialisation and reparametrisation-based techniques. However, I am not convinced why such methods limit the expressive power of RNNs. In fact, one may argue that initialisation is a milder constraint compared with an explicit regulariser, since regularisation affects the entire learning process. It seems that such initialisation requires less tuning (i.e., just identity) compared with the regulariser weights (a rather wide range of choices). Either a theoretical justification or strong empirical results are required to support this claim. However, both are missing in the current paper. \n\nExperiments:\n\nFirst, the baseline results for even toy problems (e.g., addition) are unclear. Despite the results in the paper show the advantage of the proposed method, direct comparison with results from other papers are missing. For example,  when the T > 150 the results from Le et al, 2015 (A Simple Way to Initialize Recurrent Networks of\nRectified Linear Units) were much better compared with baseline results in the paper. This could be due to the smaller size of the models (40 vs 100 hidden units in Le et al.). For clear and direct comparison in this case, models with comparable size should be used in these experiments. Despite this, I wonder why the performance of addition and multiplication seem even worse than the much smaller model reported in Hochreiter and Schmidhuber 1997? (see table 7 and 8)? \n\nActually, it would be helpful to test the proposed method on more practical tasks such as language (at least synthetic ones) and speech modelling, which would bring more impact on the wider community.\n\nA few technical questions:\n\n- Is the form of eq. 1 necessary, or can the method be adapted for the more standard formulation of RNN used in machine learning? It seems that A can be interpreted as a skip connection\n\n- Eq.3 can simply be referred to as “softmax”\n\n- Please comment on the algorithm in section 3.4 in comparison with more standard variational approaches, such as stochastic variational inference with reparametrisation as in variational RNNs (e.g., Chung, et al., 2015, A Recurrent Latent Variable Model for Sequential Data). Is “stepwise annealling” always necessary?\n\n- Eq. 7 as a measurement of the match between trajectories still depends on z. Is there an additional expectation over p(z)? Is “freely simulated trajectories” the prior over trajectories? If so, what’s the form of this prior?"
        }
    ]
}