{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "The authors propose creating new classes for augmented data instead of the traditional approach of adding them to the original source class. The hope is that a more diverse set of tasks will be created, thus better approximating some unseen task in few-shot learning. They test this idea by rotating images to augment the data and then compare the two approaches. Their experiments were conducted using several data sets and a few different base learners. In nearly all the results, they show that their approach performs better. \n\nI find Figure 3 difficult to read because of the separation of the 1-shot and 5-shot classes. (The figure feels a bit clumsy to read.) I'm also unclear what that section contributes to the paper since it is so short. \n\nWhy only use rotations to augment?\n\nI weakly accept this paper because the simple idea seems elegant and appears to improve performance. Since I know little about the field, I will defer to other, more qualified reviewers. I would like to see more experimentation though since this is purely an experimental paper (theory would be wonderful). "
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Summary & Pros\n- This paper proposes a task-level data augmentation technique that augments labels while data augmentation. This process makes novel classes, so generalization might be improved, especially on few-shot tasks.\n- The authors also use an ensemble technique and the validation set to improve the performance.\n- The proposed method improves performance consistently across methods and datasets.\n\nConcerns #1: Why the proposed method is working?\n- Throughout this paper, the verification of the proposed method is unclear. For example, in Section 3.2, the authors said \"Despite the two problems, the fundamental features of the novel images can provide useful information\", however, they do not explain why and how such novel images, especially rotated images, can improve few-shot learning. A more detailed explanation and (theoretical or experimental) verification should be presented in the paper.\n\nConcerns #2: +ens and +val\n- First, using the components +ens and +val is not standard protocol for few-shot learning. In the protocol, the validation set is typically used for only finding a best model while training. Then, the best model is solely used to evaluate few-shot learning classification accuracy on the test set. Many few-shot learning papers report their scores using the standard protocol, for example, the reported ProtoNet in Table 1 does not use ensemble/validation [1]. Thus the comparison in Table 1 is unfair.\n- The components, +ens and +val, are orthogonal to the proposed method, and they are not a contribution of this paper. However, in Table 1, the authors emphasize the two components. Thus, I highly recommend removing such orthogonal components.\n- Table 2-4 show the ablation studies on TaskAug, +ens, and +val. The tables use different datasets but provide the same message. Thus I think the tables might be over-presented (roughly 1 page) compared to the message (TaskAug, +ens, +val can improve the performance).\n\nConclusion:\nThis paper proposes a somewhat novel task augmentation technique for few-shot learning, but I think its contribution is limited. Moreover, +ens and +val techniques seem to be over-claimed, and explanation and verification are not enough.\n\n[1] Kwonjoon Lee et al., Meta-Learning with Differentiable Convex Optimization, CVPR 2019\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper introduces a new data augmentation method for meta-learning, named as \"Task Level Data Augmentation (Task Aug).\" The general data augmentation methods add various translations to the original data to amplify the original data. However, in the meta-learning problems, especially few-shot learning, which is experimented in the paper, the smallest unit is rather a task than data. Therefore, the number of data instances per class is not as critical as other learning problems. Therefore, TaskAug increases the number of classes instead of the number of instances per class by generating images that are clearly recognized as different classes from the original data. With an increased number of classes, the number of task instances that can be sampled also increases. TaskAug rotates the natural images by 90, 180, 270 degrees making three new classes. Furthermore, TaskAug put smaller weights on the new classes letting the model prioritize the original classes. The smaller weights are implemented using two arguments, p_max and T. To build a task instance, classes of augmented classes are selected with the probability p and classes of original data are selected with the probability  1-p. The probability p increases from 0 to p_max linearly for T task instances.\n\nOverall, this paper proposes a novel task augmentation method for meta-learning problems and shows that it improves the learning performance from the experiments. However, the class generating method is limited to rotating, which is questionable in terms of novelty and efficacy, and the writing is unclear and unpolished.\n\nAs it is already mentioned in the paper, rotating images do not generate images that are clearly separated from the original class, which the algorithm intended. For example, balls of the natural image dataset, or the alphabet 'O' and the number '0' of character dataset can not be clearly separated by rotating and rotating '6' by 180 degrees generated '9' whose class already exists. The authors only claim that the features from the new classes can provide useful information and do not propose any remedy. Moreover, rotating images is one of the most popular data augmentation methods which are used to amplify the images per class. It is hard to argue that the same translation method does different work.\nAlso, Table 1 and Table 4 show only the contributions of '+ens+val' which is not the main contribution of the paper. The ensemble method is from the Huang et al. 's work, and '+val' additionally uses validation data.\n\nTo improve this paper, the authors can contemplate other method(s) to increase the number of classes which can be clearly separated from the existing classes as the algorithm intended in the first place.\n\nMinor comments:\n\nThere are some unclear parts in the paper.\n1) In Algorithm 1, p<-p_max*min{1,t/T}  means that p increases from 0 to p_max for the first T tasks, but the paper says that p increase from 0 to o_max after T tasks in Section 3.2.\n2) The writing in 4.1.3 is unclear and hard to get what '+ens','+val', and '+ens+val' means. It seems like '+ens' takes ensemble of 60 models acquired during 60 training epochs using training classes, '+val' adds validation classes for the last epoch and chooses the last model, and '+ens+val' adds validation classes for the last epoch and takes ensemble of 60 models. But I'm not sure if I understood correctly.\n3) Why were the validation classes used for the training?\n4) It is hard to understand Figure 3. How about using the same color or same mark for TaskAug 1-shot & 5-shot, Baseline 1shot-5shot, and so on? Because 1-shot and 5-shot are clearly separated in the graph.\nSome typos/errors: Section 4, line 4, probably -> probability"
        }
    ]
}