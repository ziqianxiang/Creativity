{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "An interesting paper, generally well-written. Though it would be nice to see that the methods and observations generalize to other datasets, it is probably too much to ask as datasets with required properties do not seem to exist.  There is a clear consensus to accept the paper.\n\n+ an interesting extension of previous work on emergent communications (e.g., referential games)\n+ well written paper\n ",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Review",
            "rating": "7: Good paper, accept",
            "review": "--------------\nSummary and Evaluation:\n--------------\n\nThe paper presents a nice set of experiments on language emergence in a mutli-modal, multi-step setting. The multi-modal reference game provides an interesting setting for communication, with agents learning to map descriptions to images. The receiving agent's direct control over dialog length is also novel and allows for the interesting analysis presented in later sections. \n\nOverall I think this is an interesting and well-designed work; however, some details are missing that I think would make for a stronger submission (see weaknesses).\n\n\n--------------\nStrengths:\n--------------\n- Generally well-written with the Results and Analysis section appearing especially thought-out and nicely presented.\n\n- The proposed reference game provides a number of novel contributions -- giving the agents control over dialog length, providing both agents with the same vocabulary without constraints on how each uses it (implicit through pretraining or explicit in the structure/loss), and introducing an asymmetric multi-modal context for the dialog.\n\n- The analysis is extensive and well-grounded in the three key hypothesis presented at the beginning of Section 6.\n\n--------------\nWeaknesses:\n--------------\n\n- There is room to improve the clarity of Sections 3 and 4 and I encourage the authors to revisit these sections. Some specific suggestions that might help:\n\t\t- numbering all display style equations\n\t\t- when describing the recurrent receiver, explain the case where it terminates (s^t=1) first such that P(o_r=1) is defined prior to being used in the message generation equation. \n\n- I did not see an argument in support of the accuracy@K metric. Why is putting the ground truth in the top 10% the appropriate metric in this setting? Is it to enable comparison between the in-domain, out-domain, and transfer settings?\n\n- Unless I missed something, the transfer test set results only comes up once in the context of attention methods and are not mentioned elsewhere. Why is this? It seems appropriate to include in Figure 5 if no where else in the analysis.\n\n- Do the authors have a sense for how sensitive these results are to different runs of the training process?\n\n- I did not understand this line from Section 5.1: \"and discarding any image with a category beyond the 398-th most frequent one, as classified by a pretrained ImageNet classifier'\"\n\n- It is not specified (or I missed it) whether the F1 scores from the separate classifier are from training or test set evaluations.\n\n- I would have liked to see analysis on the training process such as a plot of reward (or baseline adjusted reward) over training iterations. \n\n- I encourage authors to see the EMNLP 2017 paper \"Natural Language Does Not Emerge ‘Naturally’ in Multi-Agent Dialog\" which also perform multi-round dialogs between two agents. Like this work, the authors also proposed removing memory from one of the agents as a means to avoid learning degenerate 'non-dialog' protocols.\n\n- Very minor point: the use of fixed-length, non-sequence style utterances is somewhat disappointing given the other steps made in the paper to make the reference game more 'human like' such as early termination, shared vocabularies, and unconstrained utterance types. I understand however that this is left as future work.\n\n\n--------------\nCuriosities:\n--------------\n- I think the analysis is Figure 3 b,c is interesting and wonder if something similar can be computed over all examples. One option would be to plot accuracy@k for different utterance indexes -- essentially forcing the model to make a prediction after each round of dialog (or simply repeating its prediction if the model has chosen to stop). \n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting take on representation learning",
            "rating": "7: Good paper, accept",
            "review": "The setup in the paper for learning representations is different to many other approaches in the area, using to agents that communicate over descriptions of objects using different modalities. The experimental setup is interesting in that it allows comparing approaches in learning an effective representation. The paper does mention the agents will be available, but leaves open wether the dataset will be also available. For reproducibility and comparisons, this availability would be essential. \n\nI like that the paper gives a bit of context, but presentation of results could be clearer, and I am missing some more explicit information on training and results (eg how long / how many training examples, how many testing, classification rates, etc).\nThe paper says is the training procedure is described in Appendix A, but as far as I see that contains the table of notations. \n\n\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting paper that extends basic referential game",
            "rating": "7: Good paper, accept",
            "review": "The paper proposes a new multi-modal, multi-step reference game, where the sender has access to visual data and the receiver has access to textual messages, and also the conversation can be terminated by the receiver when proper. \n\nLater, the paper describes their idea and extension in details and reports comprehensive experiment results of a number of hypotheses. The research questions seems straightforward, but it is good to see those experiments review some interesting points.  One thing I am bit concerned is that the results are based on a single dataset. Do we have other datasets that can be used?\n\nThe authors also lay out further several research directions. Overall, I think this paper is easy to read and good. \n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}