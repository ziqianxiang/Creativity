{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The idea of universal perturbation is definitely interesting and well carried out in that paper.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "The main issue I am having is what are the applicable insight from the analysis",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper discusses universal perturbations - perturbations that can mislead a trained classifier if added to most of input data points. The main results are two fold: if the decision boundary are flat (such as linear classifiers), then the classifiers tend to be vulnerable to universal perturbations when the decision boundaries are correlated. If the decision boundary are curved, then vulnerability to universal perturbations is directly resulted from existence of shared direction along with the decision boundary positively curved. The authors also conducted experiments to show that deep nets produces decision boundary that satisfies the curved model.\n\nThe main issue I am having is what are the applicable insight from the analysis:\n\n1. Why is universal perturbation an important topic (as opposed to adversarial perturbation).\n2. Does the result implies that we should make the decision boundary more flat, or curved but on different directions? And how to achieve that? It might be my mis-understanding but from my reading a prescriptive procedure for universal perturbation seems not attained from the results presented.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Universal perturbations as a consequence of positive curvature",
            "rating": "7: Good paper, accept",
            "review": "The paper develops models which attempt to explain the existence of universal perturbations which fool neural networks — i.e., the existence of a single perturbation which causes a network to misclassify most inputs. The paper develops two models for the decision boundary:\n\n(a) A locally flat model in which the decision boundary is modeled with a hyperplane and the normals two the hyperplanes are assumed to lie near a low-dimensional linear subspace.\n\n(b) A locally positively curved model, in which there is a positively curved outer bound for the collection of points which are assigned a given label. \n\nThe paper works out a probabilistic analysis arguing that when either of these conditions obtains, there exists a fooling perturbation which affects most of the data. \n\nThe theoretical analysis in the paper is straightforward, in some sense following from the definition. The contribution of the paper is to posit these two conditions which can predict the existence of universal fooling perturbations, argue experimentally that they occur in (some) neural networks of practical interest. \n\nOne challenge in assessing the experimental claims is that practical neural networks are nonsmooth; the quadratic model developed from the hessian is only valid very locally. This can be seen in some of the illustrative examples in Figure 5: there *is* a coarse-scale positive curvature, but this would not necessarily come through in a quadratic model fit using the hessian. The best experimental evidence for the authors’ perspective seems to be the fact that random perturbations from S_c misclassify more points than random perturbations constructed with the previous method. \n\nI find the topic of universal perturbations interesting, because it potentially tells us something structural (class-independent) about the decision boundaries constructed by artificial neural networks. To my knowledge, the explanation of universal perturbations in terms of positive curvature is novel. The paper would be much stronger if it provided an explanation of *why* there exists this common subspace of universal fooling perturbations, or even what it means geometrically that positive curvature obtains at every data point. \n\nVisually, these perturbations seem to have strong, oriented local high-frequency content — perhaps they cause very large responses in specific filters in the lower layers of a network, and conventional architectures are not robust to this? \n\nIt would also be nice to see some visual representations of images perturbed with the new perturbations, to confirm that they remain visually similar to the original images. \n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The paper provides an interesting analysis linking the geometry of classifier decision boundaries to  small universal adversarial perturbations.",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The paper is written well and clear.   The core contribution of the paper is the illustration that: under the assumption of flat, or curved decision boundaries with positive curvature small universal adversarial perturbations exist.  \n\nPros: the intuition and geometry is rather clearly presented.  \n\nCons: \nReferences to \"CaffeNet\"  and \"LeNet\" (even though the latter is well-known) are missing.  In the experimental section used to validate the main hypothesis that the deep networks have positive curvature decision boundaries, there is no description of how these networks were trained. \n\nIt is not clear why the authors have decided to use out-dated 5-layer \"LeNet\"  and NiN (Network in network) architectures instead of more recent and much better performing architectures (and less complex than NiN architectures). It would be nice to see how the behavior and boundaries look in these cases.  \n\nThe conclusion is speculative:\n\"Our analysis hence shows that to construct classifiers that are robust to universal perturbations, it\nis key to suppress this subspace of shared positive directions, which can possibly be done through\nregularization of the objective function. This will be the subject of future works.\" \n\nIt is clear that regularization should play a significant role in shaping the decision boundaries. Unfortunately, the paper does not provide details at the basic level, which algorithms,  architectures, hyper-parameters or regularization terms are used. All these factors should play a very significant role in the experimental validation of their hypothesis.\n\nNotes: I did not check the proofs of the theorems in detail. \n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}