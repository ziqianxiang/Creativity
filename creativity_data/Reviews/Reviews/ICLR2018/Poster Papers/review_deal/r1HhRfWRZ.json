{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "Since this seems interesting, I suggest to accept this paper at the conference. However, there are still some serious issues with the paper, including missing references. ",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Learning a world representation through state prediction, implemented and evaluated in an unclear manner.",
            "rating": "4: Ok but not good enough - rejection",
            "review": "Summary:\nThe paper describes a system which creates an internal representation of the scene given observations, being this internal representation advantageous over raw sensory input for object classification and control. The internal representation comes from a recurrent network (more specifically, a sequence2sequence net) trained to maximize the likelihood of the observations from training\n\nPositive aspects:\nThe authors suggest an interesting hypothesis: an internal representation of the world which is useful for control could be obtained just by forcing the agent to be able to predict the outcome of its actions in the world. This hypothesis would enable robots to train it in a self-supervised manner, which would be extremely valuable.\n\nNegative aspects:\nAlthough the premise of the paper is interesting, its execution is not ideal. The formulation of the problem is unclear and difficult to follow, with a number of important terms left undefined. Moreover, the experiment task is too simplistic; from the results, it's not clear whether the representation is anything more than trivial accumulation of sensory input\n\n- Lack of clarity:\n-- what exactly is the \"generic cost\" C in section 7.1?\n-- why are both f and z parameters of C? f is directly a function of z. Given that the form of C is not explained, seems like f could be directly computing as part of C.\n-- what is the relation between actions a in section 7.1 and u in section 4?\n-- How is the minimization problem of u_{1:T} solved?\n-- Are the authors sure that they perform gathering information through \"maximizing uncertainty\" (section 7.1)? This sounds profoundly counterintuitive. Maximizing the uncertainty in the world state should result in minimum information about the worlds state. I would assume this is a serious typo, but cannot confirm given that the relation between the minimize cost C and the Renyi entropy H is not explicitely stated. \n-- When the authors state that \"The learner trains the model by maximum likelihood\" in section 7.1, do they refer to the prediction model or the control model? It would seem that it is the control model, but the objective being \"the same as in section 6\" points in the opposite direction\n-- What is the method for classifying and/or regressing given the features and internal representation? This is important because, if the method was a recurrent net with memory, the differences between the two representations would probably be minimal.\n\n- Simplistic experimental task:\nMy main intake from the experiments is that having a recurrent network processing the sensory input provides some \"memory\" to the system which reduces uncertainty when sensory data is ambiguous. This is visible from the fact that the performance from both systems is comparable at the beginning, but degrades for sensory input when the hand is open. This could be achievable in many simple ways, like modeling the classification/regression problem directly with an LSTM for example. Simpler modalities of providing a memory to the system should be used as a baseline.\n\n\nConclusion:\nAlthough the idea of learning an internal representation of the world by being able to predict its state from observations is interesting, the presented paper is a) too simplistic in its experimental evaluation and b) too unclear about its implementation. Consequently, I believe the authors should improve these aspects before the article is valuable to the community\n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Great Paper (update: with weaknesses)",
            "rating": "7: Good paper, accept",
            "review": "The paper proposes an architecture for internal model learning of a robotic system and applies it to a simulated and a real robotic hand.  The model allows making relatively long-term predictions with uncertainties. The models are used to perform model predictive control to achieve informative actions. It is shown that the hidden state of the learned models contains relevant information about the objects the hand was interacting with. \n\nThe paper reads well. The method is sufficiently well explained and the results are presented in an illustrative and informative way. \nupdate: See critique in my comment below.\nI have a few minor points:\n\n- Sec 2: you may consider to cite the work on maximising predictive information as intrinsic motivation:\nG. Martius, R. Der, and N. Ay. Information driven self-organization of complex robotic behaviors. PLoS ONE, 8(5):e63400, 2013.\n- Fig 2: bottom: add labels to axis, and maybe mention that same color code as above\n- Sec 4 par 3: .... intentionally not autoregressive: w.r.t. to what? to the observations? \n- Sec 7.1: how is the optimization for the MPC performed? Which algorithm did you use and long does the optimization take? \n in first Eq: should f not be sampled from GMMpdf, so replace = with \\sim\n\nTypos:\n- Sec1 par2: This pattern has has ...\n- Sec 2 par2: statistics ofthe\n- Sec 4 line2: prefix of an episode , where  (space before ,)\n \n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Some really good ideas, but probably not ready for publication",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The authors explore how sequence models that look at proprioceptive signals from a simulated or real-world robotic hand can be used to decode properties of objects (which are not directly observed), or produce entropy maximizing or minimizing motions.\n\nThe overall idea presented in the paper is quite nice: proprioception-based models that inject actions and encoder/pressure observations can be used to measure physical properties of objects that are not directly observed, and can also be used to create information gathering (or avoiding) behaviors. There is some related work that the authors do not cite that is highly relevant here. A few in particular come to mind:\n\nYu, Tan, Liu, Turk. Preparing for the Unknown: uses a sequence model to estimate physical properties of a robot (rather than unobserved objects)\n\nFu, Levine, Abbeel. One-Shot Learning of Manipulation Skills: trains a similar proprioception-only model and uses it for object manipulation, similar idea that object properties can be induced from proprioception\n\nBut in general the citations to relevant robotic manipulation work are pretty sparse.\n\nThe biggest issue with the paper though is with the results. There are no comparisons or reasonable baselines of any kind, and the reported results are a bit hard to judge. As far as I can understand, there are no quantitative results in simulation at all, and the real-world results are not good, indicating something like 15 degrees of error in predicting the pose of a single object. That doesn't seem especially good, though it's also very hard to tell without a baseline.\n\nOverall, this seems like a good workshop paper, but probably substantial additional experimental work is needed in order to evaluate the practical usefulness of this method. I would however strongly encourage the authors to pursue this research further: it seems very promising, and I think that, with more rigorous evaluation and comparisons, it could be quite a nice paper!\n\nOne point about style: I found the somewhat lofty claims in the introduction a bit off-putting. It's great to discuss the greater \"vision\" behind the work, but this paper suffers from a bit too much high-level vision and not enough effort put into explaining what the method actually does.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}