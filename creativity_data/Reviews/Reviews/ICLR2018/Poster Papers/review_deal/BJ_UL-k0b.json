{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "Pros:\n+ The paper introduces a non-trivial interpretation of MAML as hierarchical Bayesian learning and uses this perspective to develop a new variation of MAML that accounts for curvature information.\n\nCons:\n- Relatively small gains over MAML on mini-Imagenet.\n- No direct comparison against the state-of-the-art on mini-Imagenet.\n\nThe reviewers agree that the interpretation of MAML as a form of hierarchical Bayesian learning is novel, non-trivial, and opens up an interesting direction for future research.  The only concerns are that the empirical results on mini-Imagenet do not show a particularly large improvement over MAML, and there is no direct comparison to the state-of-the-art results on the task.  However, the value of the new perspective on meta-learning outweighs these concerns.\n",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Review",
            "rating": "6: Marginally above acceptance threshold",
            "review": "Summary\nThe paper presents an interesting view on the recently proposed MAML formulation of meta-learning (Finn et al). The main contribution is a) insight into the connection between the MAML procedure and MAP estimation in an equivalent linear hierarchical Bayes model with explicit priors, b) insight into the connection between MAML and MAP estimation in non-linear HB models with implicit priors, c) based on these insights, the paper proposes a variant of MALM using a Laplace approximation (with additional approximations for the covariance matrix. The paper finally provides an evaluation on the mini ImageNet problem without significantly improving on the MAML results on the same task.\n\nPro:\n-            The topic is timely and of relevance to the ICLR community continuing a current trend in building meta-learning system for few-shot learning.\n-            Provides valuable insight into the MAML objective and its relation to probabilistic models\n\nCon:\n-            The paper is generally well-written but I find (as a non-meta-learner expert) that certain fundamental aspects could have been explained better or in more detail (see below for details).\n-            The toy example is quite difficult to interpret the first time around and does not provide any empirical insight into the converge of the proposed method (compared to e.g. MAML)\n-            I do not think the empirical results provide enough evidence that it is a useful/robust method. Especially it does not provide insight into which types of problems (small/large, linear/ non-linear) the method is applicable to. \n\n\nDetailed comments/questions:\n-            The use of Laplace approximation is (in the paper) motivated from a probabilistic/Bayes and uncertainty point-of-view. It would, however, seem that the truncated iterations do not result in the approximation being very accurate during optimization as the truncation does not result in the approximation being created at a mode. Could the authors perhaps comment on:\na) whether it is even meaningful to talk about the approximations as probabilistic distribution during the optimization (given the psd approximation to the Hessian), or does it only make sense after convergence? \nb) the consequence of the approximation errors on the general convergence of the proposed method (consistency and rate)\n\n-            Sec 4.1, p5: Last equation: Perhaps useful to explain the term $log(\\phi_j^* | \\theta)$ and why it is not in subroutine 4 . Should $\\phi^*$  be $\\hat \\phi$ ?\n-            Sec 4.2: “A straightforward…”: I think it would improve readability to refer back to the to the previous equation (i.e. H) such that it is clear what is meant by “straightforward”.\n-            Sec 4.2: Several ideas are being discussed in Sec 4.2 and it is not entirely clear to me what has actually been adopted here; perhaps consider formalizing the actual computations in Subroutine 4 – and provide a clearer argument (preferably proof) that this leads to consistent and robust estimator of \\theta.\n-            It is not clear from the text or experiment how the learning parameters are set.\n-            Sec 5.1: It took some effort to understand exactly what was going on in the example and particular figure 5.1; e.g., in the model definition in the body text there is no mention of the NN mentioned/used in figure 5, the blue points are not defined in the caption, the terminology e.g.  “pre-update density” is new at this point. I think it would benefit the readability to provide the reader with a bit more guidance.\n-            Sec 5.1: While the qualitative example is useful (with a bit more text), I believe it would have been more convincing with a quantitative example to demonstrate e.g. the convergence of the proposal compared to std MAML and possibly compare to a std Bayesian inference method from the HB formulation of the problem (in the linear case)\n-            Sec 5.2: The abstract clams increased performance over MAML but the empirical results do not seem to be significantly better than MAML ? I find it quite difficult to support the specific claim in the abstract from the results without adding a comment about the significance.\n-            Sec 5.2: The authors have left out “Mishral et al” from the comparison due to the model being significantly larger than others. Could the authors provide insight into why they did not use the ResNet structure from the  tcml paper in their L-MLMA scheme ?\n-            Sec 6+7: The paper clearly states that it is not the aim to (generally) formulate the MAML as a HB. Given the advancement in gradient based inference for HB the last couple of years (e.g. variational, nested laplace , expectation propagation etc) for explicit models, could the authors perhaps indicate why they believe their approach of looking directly to the MAML objective is more scalable/useful than trying to formulate the same or similar objective in an explicit HB model and using established inference methods from that area ?\n\nMinor:\n-            Sec 4.1 “…each integral in the sum in (2)…” eq 2 is a product\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Novel view on MAML, well presented.",
            "rating": "7: Good paper, accept",
            "review": "The paper reformulates the model-agnostic meta-learning algorithm (MAML) in terms of inference for parameters of a prior distribution in a hierarchical Bayesian model. This provides an interesting and, as far as I can tell, novel view on MAML. The paper uses this view to improve the MAML algorithm. The writing of the paper is excellent. Experimental evalution is well done against a number of recently developed alternative methods in favor of the presented method, except for TCML which has been exluded using a not so convincing argument. The overview of the literature is also very well done. ",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Non-trivial hierarchical Bayes interpretation of MAML",
            "rating": "7: Good paper, accept",
            "review": "MAML (Finn+ 2017) is recast as a hierarchical Bayesian learning procedure. In particular the inner (task) training is initially cast as point-wise max likelihood estimation, and then (sec4) improved upon by making use of the Laplace approximation. Experimental evidence of the relevance of the method is provided on a toy task involving a NIW prior of Gaussians, and the (benchmark) MiniImageNet task.\n\nCasting MAML as HB seems a good idea. The paper does a good job of explaining the connection, but I think the presentation could be clarified. The role of the task prior and how it emerges from early stopping (ie a finite number of gradient descent steps) (sec 3.2) is original and technically non-trivial, and is a contribution of this paper. \nThe synthetic data experiment sec5.1 and fig5 is clearly explained and serves to additionally clarify the proposed method. \nRegarding the MiniImageNet experiments, I read the exchange on TCML and agree with the authors of the paper under review. However, I recommend including the references to Mukhdalai 2017 and Sung 2017 in the footnote on TCML to strengthen the point more generically, and show that not just TCML but other non-shallow architectures are not considered for comparison here. In addition, the point made by the TCML authors is fair (\"nothing prevented you from...\") and I would also recommend mentioning the reviewed paper's authors' decision (not to test deeper architectures) in the footnote. This decision is in order but needs to be stated in order for the reader to form a balanced view of methods at her disposal.\nThe experimental performance reported Table 1 remains small and largely within one standard deviation of competitor methods.\n\nI am assessing this paper as \"7\" because despite the merit of the paper, the relevance of the reformulation of MAML, and the technical steps involved in the reformulation, the paper does not eg address other forms (than L-MAML) of the task-specific subroutine ML-..., and the benchmark improvements are quite small. I think the approach is good and fruitful. \n\n\n# Suggestions on readability\n\n* I have the feeling the paper inverts $\\alpha, \\beta$ from their use in Finn 2017 (step size for meta- vs task-training). This is unfortunate and will certainly confuse readers; I advise carefully changing this throughout the entire paper (eg Algo 2,3,4, eq 1, last eq in sec3.1, eq in text below eq3, etc)\n\n* I advise avoiding the use of the symbol f, which appears in only two places in Algo 2 and the end of sec 3.1. This is in part because f is given another meaning in Finn 2017, but also out of general parsimony in symbol use. (could leave the output of ML-... implicit by writing ML-...(\\theta, T)_j in the $sum_j$; if absolutely needed, use another symbol than f)\n\n* Maybe sec3 can be clarified in its structure by re-ordering points on the quadratic error function and early stopping (eg avoiding to split them between end of 3.1 and 3.2).\n\n* sec6 \"Machine learning and deep learning\": I would definitely avoid this formulation, seems to tail in with all the media nonsense on \"what's the difference between ML and DL ?\". In addition the formulation seems to contrast ML with hierarchical Bayesian modeling, which does not make sense/ is wrong and confusing.\n\n# Typos\n\n* sec1 second parag: did you really mean \"in the architecture or loss function\"? unclear.\n* sec2: over a family\n* \"common structure, so that\" (not such that)\n* orthgonal\n* sec2.1 suggestion: clarify that \\theta and \\phi are in the same space\n* sec2.2 suggestion: task-specific parameter $\\phi_j$ is distinct from ... parameters $\\phi_{j'}, j' \\neq j}\n* \"unless an approximate ... is provided\" (the use of the subjunctive here is definitely dated :-) )\n* sec3.1 task-specific parameters $\\phi_j$ (I would avoid writing just \\phi altogether to distinguish in usage from \\theta)\n* Gaussian-noised\n* approximation of the it objective\n* before eq9: \"that solves\": well, it doesn't really \"solve\" the minimisation, in that it is not a minimum; reformulate this?\n* sec4.1 innaccurate\n* well approximated\n* sec4.2 an curvature\n* (Amari 1989)\n* For the the Laplace\n* O(n^3) : what is n ?\n* sec5.2 (Ravi and L 2017)\n* for the the \n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}