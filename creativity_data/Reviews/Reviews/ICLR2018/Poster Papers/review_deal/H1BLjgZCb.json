{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The paper proposes a method to generate adversaries close to the (training) data manifold using GANs rather than arbitrary adversaries. They show the effectiveness of their method in terms of human evaluation and success in fooling a deep network. The reviewers feel that this paper is for the most part well-written and the contribution just about makes the mark.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "An interesting paper which is marginally above acceptance threshold",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The authors of the paper propose a framework to generate natural adversarial examples by searching adversaries in a latent space of dense and continuous data representation (instead of in the original input data space). The details of their proposed method are covered in Algorithm 1 on Page 12, where an additional GAN (generative adversarial network) I_{\\gamma}, which can be regarded as the inverse function of the original GAN G_{\\theta}, is trained to learn a map from the original input data space to the latent z-space. The authors empirically evaluate their method in both image and text domains and claim that the corresponding generated adversaries are natural (legible, grammatical, and semantically similar to the input).\n\nGenerally, I think that the paper is written well (except some issues listed at the end). The intuition of the proposed approach is clearly explained and it seems very reasonable to me.  \nMy main concern, however, is in the current sampling-based search algorithm in the latent z-space, which the authors have already admitted in the paper. The efficiency of such a search method decreases very fast when the dimensions of the z-space increases. Furthermore, such an approximation solution based on the sampling may be not close to the original optimal solution z* in Equation (3). This makes me feel that there is large room to further advance the paper. Another concern is that the authors have not provided sufficient number of examples to show the advantages of their proposed method over the other method (such as FGSM) in generating the adversaries. The example in Table 1 is very good; but more examples (especially involving the quantitative comparison) are needed to demonstrate the claimed advantages. For example, could the authors add such a comparison in Human Evaluation in Section 4 to support the claim that the adversaries generated by their method are more natural? \n\nOther issues are listed as follows:\n(1). Could you explicitly specify the dimension of the latent z-space in each example in image and text domain in Section 3?\n(2). In Tables 7 and 8, the human beings agree with the LeNet in >= 58% of cases. Could you still say that your generated “adversaries” leading to the wrong decision from LeNet? Are these really “adversaries”?\n(3). How do you choose the parameter \\lambda in Equation (2)?\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The authors present an interesting research problem of generating adversarial examples to show differences in predictions in black-box classifiers. However, I feel the novelty of the perturbation idea in semantic space is questionable and author needs to highlight the significance in a more explicit way. ",
            "rating": "6: Marginally above acceptance threshold",
            "review": "Quality: Although the research problem is an interesting direction the quality of the work is not of a high standard. My main conservation is that the idea of perturbation in semantic latent space has not been described in an explicit way. How different it will be compared to a perturbation in an input space? \n\nClarity: The use of the term \"adversarial\" is not quite clear in the context as in many of those example classification problems the perturbation completely changes the class label (e.g. from \"church\" to \"tower\" or vice-versa)\n\nOriginality: The generation of adversarial examples in black-box classifiers has been looked in GAN literature as well and gradient based perturbations are studied too. What is the main benefit of the proposed mechanism compared to the existing ones?\n\nSignificance: The research problem is indeed a significant one as it is very important to understand the robustness of the modern machine learning methods by exposing them to adversarial scenarios where they might fail.\n\npros:\n(a) An interesting problem to evaluate the robustness of black-box classifier systems\n(b) generating adversarial examples for image classification as well as text analysis.\n(c) exploiting the recent developments in GAN literature to build the framework forge generating adversarial examples.\n\ncons:\n(a) The proposed search algorithm in the semantic latent space could be computationally intensive. any remedy for this problem?\n(b) Searching in the latent space z could be strongly dependent on the matching inverter $I_\\gamma(.)$. any comment on this?\n(c) The application of the search algorithm in case of imbalanced classes could be something that require further investigation.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A novel idea for generating more useful adversary examples. ",
            "rating": "7: Good paper, accept",
            "review": "\nSummary:\n A method for creation of semantical adversary examples in suggested. The ‘semantic’ property is measured by building a latent space with mapping from this space to the observable (generator) and back (inverter). The generator is trained with a WGAN optimization. Semantic adversarials examples are them searched for by inverting an example to its sematic encoding and running local search around it in that space. The method is tested for generation of images on MNist and part of LSUM data and for creation of text examples which are adversarial in some sense to inference and translation sentences. It is shown that the distance between adversarial example and the original example in the latent space is proportional to the accuracy of the classifier inspected.\nPage 3: It seems that the search algorithm has a additional parameter: r_0, the size of the area in which search is initiated. This should be explicitly said and the parameter value should be stated.\nPage 4: \n-\tthe implementation details of the generator, critic and invertor networks are not given in enough details, and instead the reader is referred to other papers. This makes this paper non-clear as a stand alone document, and is a problem for a paper which is mostly based on experiments and their results: the main networks used are not described.\n-\tthe visual examples are interesting, but it seems that they are able to find good natural adversary examples only for a weak classifier. In the MNist case, the examples for thr random forest are nautral and surprising, but those for the LE-Net are often not: they often look as if they indeed belong to the other class (the one pointed by the classifier). In the churce-vs. tower case, a  relatively weak MLP classifier was used. It would be more instructive to see the results for a better, convolutional classifier.\nPage 5:\n-\tthe description of the various networks used for text generation is insufficient for understanding:\no\tThe AREA is described in two sentences. It is not clear how this module is built, was loss was it used to optimize in the first place, and what elements of it are re0used for the current task\no\t ‘inverter’ here is used in a sense which is different than in previous sections of the paper: earlier it denoted the mapping from output (images) to the underlying latent space. Here it denote  a mapping between two latent spaces.\no\t It is not clear what the ‘four-layers strided CNN’ is: its structure, its role in the system. How is it optimized?\no\tIn general: a block diagram showing the relation between all the system’s components may be useful, plus the details about the structure and optimization of the various modules. It seems that the system here contains 5 modules instead of the three used before (critic, generator and inverter), but this is not clear enough. Also which modules are pre-trained, which are optimized together,a nd which are optimized separately is not clear.\no\tSNLI data should be described: content, size, the task it is used for\n\n\nPro:\n-\tA novel idea of producing natural adversary examples with a GAN\n-\tThe generated examples are in some cases useful for interpretation and network understanding \n-\tThe method enables creation of adversarial examples for block box classifiers\nCons\n-\tThe idea implementation is basic. Specifically search algorithm presented is quite simplistic, and no variations other than plain local search were developed and tested\n-\tThe generated adversarial examples created for successful complex classifiers are often not impressive and useful (they are either not semantical, or semantical but correctly classified by the classifier). Hence It is not clear if the latent space used by the method enables finding of interesting adversarial examples for accurate classifiers. \n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}