{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "Well motivated and well written, with extensive results. The paper also received positive comments from all reviewers. The AC recommends that the paper be accepted.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "A sound approach to mix two complementary strategies for domain adaptation",
            "rating": "7: Good paper, accept",
            "review": "As there are many kinds of domain adaptation problems, the need to mix several learning strategies to improve the existing approaches is obvious. However, this task is not necessarily easy to succeed. The authors proposed a sound approach to learn a proper representation (in an adversarial way) and comply the cluster assumption.\n\nThe experiments show that this Virtual Adversarial Domain Adaptation network (VADA) achieves great results when compared to existing learning algorithms. Moreover, we also see the learned model is consistently improved using the proposed \"Decision-boundary Iterative Refinement Training with a Teacher\" (DIRT-T) approach.\n\nThe proposed methodology relies on multiple choices that could sometimes be better studied and/or explained. Namely, I would like to empirically see which role of the locally-Lipschitz regularization term (Equation 7). Also, I wonder why this term is tuned by an hyperparameter (lamda_s) for the source, while a single hyperparamer (lambda_t) is used for the sum of the two target quantity.\n \nOn the theoretical side, the discussion could be improved. Namely, Section 3 about \"limitation of domain adversarial training\" correctly explained that \"domain adversarial training may not be sufficient for domain adaptation if the feature extraction function has high-capacity\". It would be interesting to explain whether this observation is consistent with Theorem 1 of the paper (due to Ben-David et al., 2010), on which several domain adversarial approaches are based. The need to consider supplementary assumptions (such as ) to achieve good adaptation can also be studied through the lens of more recent Ben-David's work, e.g. Ben-David and Urner (2014). In the latter, the notion of \"Probabilistic Lipschitzness\", which is a relaxation of the \"cluster assumption\" seems very related to the actual work.\n\nReference:\nBen-David and Urner. Domain adaptation-can quantity compensate for quality?, Ann. Math. Artif. Intell., 2014\n\nPros:\n- Propose a sound approach to mix two complementary strategies for domain adaptation.\n- Great empirical results.\n\nCons:\n- Some choices leading to the optimization problem are not sufficiently explained.\n- The theoretical discussion could be improved.\n\nTypos:\n- Equation 14: In the first term (target loss), theta should have an index t (I think).\n- Bottom of page 6: \"... and that as our validation set\" (missing word).\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "This paper presents two complementary models for unsupervised domain adaptation (classification task): 1) the Virtual Adversarial Domain Adaptation (VADA) and 2) the Decision-boundary Iterative Refinement Training with a Teacher (DIRT-T). The authors make use of the so-called cluster assumption, i.e., decision boundaries should not cross high-density data regions. VADA extends the standard Domain-Adversarial training by introducing an additional objective L_t that measures the target-side cluster assumption violation, namely, the conditional entropy w.r.t. the target distribution. Since the empirical estimate of the conditional entropy breaks down for non-locally-Lipschitz classifiers, the authors also propose to incorporate virtual adversarial training in order to make the classifier well-behaved. The paper also argues that the performance on the target domain can be further improved by a post-hoc minimization of L_t using natural gradient descent (DIRT-T) which ensures that the decision boundary changes incrementally and slowly.    \n\nPros:\n+ The paper is written clearly and easy to read\n+ The idea to keep the decision boundary in the low-density region of the target domain makes sense\n+ The both proposed methods seem to be quite easy to implement and incorporate into existing DATNN-based frameworks\n+ The combination of VADA and DIRT-T performs better than existing DA algorithms on a range of visual DA benchmarks\n\nCons:\n- Table 1 can be a bit misleading as the performance improvements may be partially attributed to the fact that different methods employ different base NN architectures and different optimizers\n- The paper deals exclusively with visual domains; applying the proposed methods to other modalities would make this submission stronger\n\nOverall, I think it is a good paper and deserves to be accepted to the conference. Iâ€™m especially appealed by the fact that the ideas presented in this work, despite being simple, demonstrate excellent performance.\n\nPost-rebuttal revision:\nAfter reading the authors' response to my review, I decided to leave the score as is.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good contribution to unsupervised domain adaptation",
            "rating": "7: Good paper, accept",
            "review": "The paper was a good contribution to domain adaptation. It provided a new way of looking at the problem by using the cluster assumption. The experimental evaluation was very thorough and shows that VADA and DIRT-T performs really well. \n\nI found the math to be a bit problematic. For example, L_d in (4) involves a max operator. Although I understand what the authors mean, I don't think this is the correct way to write this. (5) should discuss the min-max objective. This will probably involve an explanation of the gradient reversal etc. Speaking of GRL, it's mentioned on p.6 that they replaced GRL with the traditional GAN objective. This is actually pretty important to discuss in detail: did that change the symmetric nature of domain-adversarial training to the asymmetric nature of traditional GAN training? Why was that important to the authors?\n\nThe literature review could also include Shrivastava et al. and Bousmalis et al. from CVPR 2017. The latter also had MNIST/MNIST-M experiments.",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}