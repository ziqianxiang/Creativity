{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The paper proposes a novel predictive model (e.g., from videos), called error encoding networks, by first learning a deterministic prediction model and then learning to minimize the residual error using latent variables. The latent variables given the sample are estimated by sampling from the prior then updating via gradient descent. The proposed method shows improved performance over the baselines. However, the qualitative results are not fully convincing, possibly because of (1) the limitation of the architecture, (2) suboptimal implementation/tuning of baselines (such as GAN and cVAE). "
    },
    "Reviews": [
        {
            "title": "interesting model, baselines are weak, not enough signal on it's generalization ability",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The paper proposes a model for prediction under uncertainty where the separate out deterministic component prediction and uncertain component prediction.\nThey propose to have a predictor for deterministic information generation using a standard transformer trained via MSE.\nFor the non-deterministic information, they have a residual predictor that uses a low-dimensional latent space. This low-dim latent space is first predicted from the residual of the (deterministic prediction - groundtruth), and then the low-dim encoding goes into a network that predicts a corrected image.\nThe subtleness of this work over most other video prediction work is that it isn't conditioned on a labeled latent space (like text to video prediction, for example). Hence inferring a structured latent space is a challenge.\nThe training procedure follows an alternative minimization in EM style.\n\nThe biggest weakness of the paper (and the reason for my final decision) is that the paper completely goes easy on baseline models. It's only baseline is a GAN model that isn't even very convincing (GANs are finicky to train, so is this a badly tuned GAN model? or did you spend a lot of time tuning it?).\n\nBecause of the plethora of VAE models used in video prediction [1] (albeit, used with pre-structured latent spaces), there has to be atleast one VAE baseline. Just because such a baseline wasn't previously proposed in literature (in the narrow scope of this problem) doesn't mean it's not an obvious baseline to try. In fact, a VAE would be nicely suited when proposing to work with low-dimensional latent spaces.\n\nThe main signal I lack from reading the paper is whether the proposed model actually does better than a reasonable baseline.\nIf the baselines are stronger and this point is more convincing, I am happy to raise my rating of the paper.\n\n[1] http://openaccess.thecvf.com/content_ICCV_2017/papers/Marwah_Attentive_Semantic_Video_ICCV_2017_paper.pdf",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Nicely written, lack of comparison to other methods, poor results",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This paper introduce a times-series prediction model that works in two phases. First learns a deterministic mapping from x to y. And then train another net to predict future frames given the input and residual error from the first network. And does sampling for novel inputs by sampling the residual error collected from the training set. \n\nPros:\nThe paper is well written and easy to follow.\nGood cover of relevant work in sec 3.\n\nCons\nThe paper emphasis on the fact the their modeling multi-modal time series distributions, which is almost the case for most of the video sequence data. But unfortunately doesnâ€™t show any results even qualitative like generated samples for other  work on next frame video prediction. The shown samples from model looks extremely, low quality and really hard to see the authors interpretations of it.\n\nThere are many baselines missing. One simple one would be what if they only used the f and draw z samples for N(0,1)? VAE is very power latent variable model which also not being compared against. It is not clear what implantation of GAN they are using?.Vanilla GAN is know to be hard to train and there has been many variants recently that overcome some of those difficulties and its mode collapse problem. \n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting direction, but alternatives not fully explored and not sure what I learn from experiments.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "Summary: \n\nI like the general idea of learning \"output stochastic\" noise models in the paper, but the idea is not fully explored (in terms of reasonable variations and their comparative performance).  I don't fully understand the rationale for the experiments: I cannot speak to the reasons for the GAN's failure (GANs are not easy to train and this seems to be reflected in the results); the newly proposed model seems to improve with samples simply because the evaluation seems to reward the best sample.  I.e., with enough throws, I can always hit the bullseye with a dart even when blindfolded.\n\nComments:\n\nThe model proposes to learn a conditional stochastic deep model by training an output noise model on the input x_i and the residual y_i - g(x_i).  The trained residual function can be used to predict a residual z_i for x_i.  Then for out-of-sample prediction for x*, the paper appears to propose sampling a z uniformly from the training data {z_i}_i (it is not clear from the description on page 3 that this uniformly sampled z* = z_i depends on the actual x* -- as far as I can tell it does not).  The paper does suggest learning a p(z|x) but does not provide implementation details nor experiment with this approach.\n\nI like the idea of learning an \"output stochastic\" model -- it is much simpler to train than an \"input stochastic\" model that is more standard in the literature (VAE, GAN) and there are many cases where I think it could be quite reasonable.  However, I don't think the authors explore the idea well enough -- they simply appear to propose a non-parametric way of learning the stochastic model (sampling from the training data z_i's) and do not compare to reasonable alternative approaches.  To start, why not plot the empirical histogram of p(z|x) (for some fixed x's) to get a sense of how well-behaved it is as a distribution.  Second, why not simply propose learning exponential family models where the parameters of these models are (deep nets) conditioned on the input?  One could even start with a simple Gaussian and linear parameterization of the mean and variance in terms of x.  If the contribution of the paper is the \"output stochastic\" noise model, I think it is worth experimenting with the design options one has with such a model.\n\nThe experiments range over 4 video datasets.  PSNR is evaluated on predicted frames -- PSNR does not appear to be explicitly defined but I am taking it to be the metric defined in the 2nd paragraph from the bottom on page 7.  The new model \"EEN\" is compared to a deterministic model and conditional GAN.  The GAN never seems to perform well -- the authors claim mode collapse, but I wonder if the GAN was simply hard to train in the first place and this is the key reason?  Unsurprisingly (since the EEN noise does not seem to be conditioned on the input), the baseline deterministic model performs quite well.  If I understand what is being evaluated correctly (i.e., best random guess) then I am not surprised the EEN can perform better with enough random samples.  Have we learned anything?\n",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}