{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The pros and cons of the paper are summarized below:\n\nPros:\n* The proposed tweaks to the dynamic evaluation of Mikolov et al. 2010 are somewhat effective, and when added on top of already-strong baseline models improve them substantially\n\nCons:\n* Novelty is limited. This is essentially a slightly better training scheme than the method proposed by Mikolov et al. 2010.\n* The fair comparison against Mikolov et al. 2010 is only shown in Table 1, where a perplexity of 78.6 turns to a perplexity of 73.5. This is a decent gain, but the great majority of this is achieved by switching the optimizer from SGD to an adaptive method, which as of 2018 is a somewhat limited contribution. The remainder of the tables in the paper do not compare with the method of Mikolov et al.\n* The paper title, abstract, and introduction do not mention previous work, and may give the false impression that this is the first paper to propose dynamic evaluation for neural sequence models, significantly overclaiming the paper's contribution and potentially misleading readers.\n\nAs a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al.) in the majority of the experiments, I think this papers till falls short of the quality bar of ICLR.\n\nAlso, independent of this decision, a final note about perplexity as an evaluation measure to elaborate on the comments of reviewer 1. In general, perplexity is an evaluation measure that is useful for comparing language models of the same model class, but tends to not correlate well with model performance (e.g. ASR accuracy) across very different types of models. For example, see \"Evaluation Metrics for Language Models\" by Chen et al. 1998. The method of dynamic evaluation is similar to the cache-based language models that existed in 1998 in that it reinforces the model to choose similar vocabulary to that it's seen before. As you can see from this paper that the quality of perplexity of an evaluation measure falls when cache-based models are thrown into the mix, and one reason for this is that cache models, while helping perplexity greatly, tend to reinforce previous errors when errors do occur."
    },
    "Reviews": [
        {
            "title": "Review of \"dynamic evaluation of neural sequence models\"",
            "rating": "3: Clear rejection",
            "review": "This paper proposes a dynamic evaluation of recurrent neural network language models by updating model parameters with certain segment lengths.\n\nPros.\n- Simple adaptation scheme seems to work, and the paper also shows (marginal) improvement from a conventional method (neural cache RNNLM) \nCons.\n- The paper is not well written due to undefined variables/indexes, confused explanations, not clear explanations of the proposed method in abstract and introduction (see the comments below)\n- Although the perplexity is an important measure, it’s better to show the effectiveness of the proposed method with more practical tasks including machine translation and speech recognition. \n\nComments:\n- Abstract: it is difficult to guess the characteristics of the proposed method only with a term “dynamic evaluation”. It’s better to explain it in more detail in the abstract.\n- Abstract: It’s better to provide relative performance (comparison) of the numbers (perplexity and bits/char) from conventional methods.\n- Section 2: Some variables are not explicitly introduced when they are appeared including i, n, g, and l\n- Section 3: same comment with the above for M. Also n is already used in Section 2 as a number of sequences.\n- Section 5. Why does the paper only provide examples for SGD and RMSprop? Can we apply it to other optimization methods including Adam and Adadelta?\n- Section 6, equation (9): is this new matrix introduced for every layer? Need some explanations.\n- Section 7.1: It’s better to provide the citation of Chainer.\n- Section 7.1 “AWD-LSTM”: The paper should provide the full name of AWD-LSTM when it is first appeared.\n\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Dynamic Evaluation or is it Fast Weights at test time?",
            "rating": "7: Good paper, accept",
            "review": "This paper takes AWD-LSTM, a recent, state of the art language model that was equipped with a Neural Cache, swaps the cache out for Dynamic Evaluation and improves the perplexities.\n\nDynamic Evaluation was the baseline that was most obviously missing from the original Neural Cache paper (Grave, 2016) and from the AWD-LSTM paper. In this sense, this work fills in a gap.\n\nLooking at the proposed update rule for Dynamic Evaluation though, the Global Prior seems to be an implementation of the Fast Weights idea. It would be great to explore that connection, or at least learn about how much the Global Prior helps.\n\nThe sparse update idea feels very much an afterthought and so do the experiments with Spanish.\n\nAll in all, this paper could be improved a lot but it is hard to argue with the strong results ...\n\nUpdate:  I'm happy with how the authors have addressed these and other comments in revision 2 of the paper and I've bumped the rating from 6 to 7.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The proposed improvement to the dynamic evaluation method yields some performance gains on the considered benchmarks, but the authors are missing an evaluation on a larger data set.",
            "rating": "7: Good paper, accept",
            "review": "The authors provide an improved implementation of the idea of dynamic evaluation, where the update of the parameters used in the last time step proposed in (Mikolov et al. 2010) is replaced with a back-propagation through the last few time steps, and uses  RMSprop rather than vanilla SGD. The method is applied to word level and character level language modeling where it yields some gains in perplexity. The algorithm also appears able to perform domain adaptation, in a setting where a character-level language model trained mostly on English manages to quickly adapt to a Spanish test set. \n\nWhile the general idea is not novel, the implementation choices matter, and the authors provide one which appears to work well with recently proposed models. The character level experiments on the multiplicative LSTM make the most convincing point, providing a significant improvement over already good results on medium size data sets. Figure 2 also makes a strong case for the method's suitability for applications where domain adaptation is important.\n\nThe paper's weakest part is the word level language modeling section. Given the small size of the data sets considered, the results provided are of limited use, especially since the development set is used to fit the RMSprop hyper-parameters. How sensitive are the final results to this choice? Comparing dynamic evaluation to neural cache models is a good idea, given how both depend en medium-term history: (Grave et al. 2017) provide results on the larger text8 and wiki103, it would be useful to see results for dynamic evaluation at least on the former.\n\nAn indication of the actual additional evaluation time for word-level, char-level and sparse char-level dynamic evaluation would also be welcome.\n\nPros:\n- Good new implementation of an existing idea\n- Significant perplexity gains on character level language modeling\n- Good at domain adaptation\n\nCons:\n- Memory requirements of the method\n- Word-level language modeling experiments need to be run on larger data sets\n\n(Edit: the authors did respond satisfactorily to the original concern about the size of the word-level data set)",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}