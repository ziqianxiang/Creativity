{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "Both R1 and R2 suggested that Conceptors (Jaeger, 2014) had previously explored learning transformations in the context of reservoir computing. The authors acknowledged this in their response and added a reference. The main concern raised by the reviewers was lack of novelty and weak experiments (both the MNIST and depth maps were small and artificial). The authors acknowledged that it was mainly a proof of concept type of work. R1 and R2 also rejected the claim of biological plausibility (and this was also acknowledged by the authors). Though the authors have taken great care to respond in detail to each of the reviewers, I agree with the consensus that the paper does not meet the acceptance bar."
    },
    "Reviews": [
        {
            "title": "OK but nothing really new",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The technical part of the paper is a nice study for classification with Echo State Networks. The main novelty here is the task itself, classifying different distortions of MNIST data. The actual technique presented is not original, but an application of the standard ESN approach. The task is interesting but by itself I don't find it convincing enough. Moreover, the biological plausibility that is used as an argument at several places seems to be false advertising in my view. The mere presence of recurrent connections doesn't make the approach more biological plausible, in particular given that ridge regression is used for training of the output weights. If biological plausibility was the goal, a different approach should have been used altogether (e.g., what about local training of connections, unsupervised training, ...). Also there is no argument why biological plausibility is supposed to be an advantage. A small number of training examples would have been a more specific and better motivation, given that the number of \"training\" examples for humans is only discussed qualitatively and without a reference. \n\nThe analysis using the PCs is nice; the works by Jaeger on Conceptors (2014) make also use of the principal components of the reservoir states during presentation of patterns (introduction in https://arxiv.org/abs/1406.2671), so seem like relevant references to me. \n\nIn my view the paper would benefit a lot from more ambitious task (with good results), though even then I would probably miss some originality in the approach.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "limited novelty, questionable experiments",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The claimed results of  \"combining transformations\" in the context of RC was done in the works of Herbert Jaeger on conceptors [1], which also should be cited here.\n\nThe argument of biological plausibility is not justified. The authors  use an echo-state neural network with standard tanh activations, which is as far away from real neuronal signal processing than  ordinary RNNs used in the field, with the difference that the recurrent weights are not trained.  If the authors want to make the case of biological plausibility, they should use spiking neural networks.\n\nThe experiment on MNIST seems artificial, in particular transforming the image into a time-series and thereby imposing an artificial temporal structure. The assumption that column_i is obtained  by information  of column_{i-k},..,column_{i-1} is not true for images. To make a point, the authors should use a datasets with related sets of time-series data, e.g EEG or NLP data.\n\nIn total this paper does not have enough novelty for acceptance and the experiments are not well chosen for this kind of work. Also the authors overstate the claim of biological plausibility (just because we don't train the recurrent weights does not make a method biologically plausible).\n\n[1] H. Jaeger (2014): Controlling Recurrent Neural Networks by Conceptors. Jacobs University technical report Nr 31 (195 pages) \n\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The paper has some potentially interesting ideas, but they are not well-enough explored to support the strong claims it makes about generalization.",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The paper uses an echo state network to learn to classify image transformations (between pairs of images) into one of fives classes.  The image data is artificially represented as a time series, and the goal is generalization of classification ability to unseen image pairs.  The network dynamics are studied and are claimed to have explanatory power.\n\nThe paper is well-written and easy to follow, but I have concerns about the claims it makes relative to how convincing the results are.  The focus is on one simple, and frankly now-overused data set (MNIST).  Further, treating MNIST data as a time series is artificial and clunky.  Why does the series go from left to right rather than right to left or top to bottom or inside out or something else?  How do the results change if the data is \"temporalized\" in some other way?\n\nFor training in Section 2.4, is M the number of columns for a pair of images?  It's not clear how pairs are input in parallel--- one after the other? Concatenated? Interleaved columns?  Something else? What are k, i, j in computing $\\delta X_k$?  Later, in Section 3.2, it says, \"As in section 2.2, $xl(mn)$ is the differential reservoir state value of the $m$th reservoir node at time $n$ for input image $l$\", but nothing like this is discussed in Section 2.2; I'm confused.\n\nThe generalization results on this one simple data set seem pretty good.  But, how does this kind of approach do on other kinds of or more complex data?  I'm not sure that RC has historically had very good success scaling up to \"real-world\" problems to date.\n\nTable 1 doesn't really say anything.  Of course, the diagonals are higher than the off diagonals because these are dot products.  True, they are dot products of averages over different inputs (which is why they are less than 1), but still.  Also, what Table 1 really seems to say is that the off-diagonals really aren't all that different than the diagonals, and that especially the differences between same and different digits is not very different, suggesting that what is learned is pretty fragile and likely won't generalize to harder problems.  I like the idea of using dynamical systems theory to attempt to explain what is going on, but I wonder if it is not being used a bit simplistically or naively.\n\nWhy were the five transform classes chosen?  It seems like the \"transforms\" a (same) and e (different) are qualitatively different than transforms b-d (rotated, scaled, blurred).  This seems like it should talked about.\n\n\"Thus, we infer, that the reservoir is in fact, simply training these attractors as opposed to training the entire reservoir space.\"  What does this mean?  The reservoir isn't trained at all in ESNs (which is also stated explicitly for the model presented here)…\n\nFor 3.3, why did were those three classes chosen? Was this experiment tried with other subsets of three classes?  Why are results reported on only the one combination of rotated/blurred vs. rotated?  Were others tried?  If so, what were the results?  If not, why?  How does the network know when to take more than the highest output (so it can say that two transforms have been applied)?  In the case of combination, counting either transform as the correct output kind of seems like cheating a bit—it over states how well the model is doing.  Also, does the order in which the transforms are applied affect their relative representative strength in the reservoir?\n\nThe comparison with SNNs is kind of interesting, but I'm not sure that I'm (yet) convinced, as there is little detail on how the experiment was performed and what was done (or not) to try to get the SNN to generalize.  My suspicion is that with the proper approach, an SNN or similar non-dynamical system could generalize well on these tasks.  The need for a dynamical system could be argued to make sense for the camera task, perhaps, as video frames naturally form a time series; however, as already mentioned, for the MNIST data, this is not the case, and the fact that the SNN does not generalize here seems likely due to their under utilization rather than due to an inherent lack of capability.\n\nI don't believe that there is sufficient support for this statement in the conclusion, \"[ML/deep networks] do not work as well for generalization of learning. In generalized learning, RCNs outperform them, due to their ability to function as a dynamical system with ‘memory’.\"  First of all, ML is all about generalization, and there are lots and lots and lots of results showing that many ML systems generalize very well on a wide variety of problems, well beyond just classification, in fact.  And, I don't think the the paper has convincingly shown that a dynamical system 'memory' is doing something especially useful, given that the main task studied, that of character recognition (or classification of transformation or even transformation itself), does not require such a temporal ability.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}