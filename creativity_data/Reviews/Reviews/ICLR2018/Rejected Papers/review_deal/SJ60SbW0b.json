{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The proposed LAN provides a visualization of the selectivity of networks to its inputs. It takes a trained network as golden target and estimates an LAN to predict masks that can be applied on inputs to generate the same outputs.\nBut the significance of the proposed method is unclear, \"what is the potential usage of the model?\". Empirical justification of that would make it stronger.  "
    },
    "Reviews": [
        {
            "title": "Attention masks for diagnosing neural nets",
            "rating": "7: Good paper, accept",
            "review": "The paper presents the formulation of Latent Attention Masks, which is a framework for understanding the importance of input structure in neural networks. The framework takes a pre-trained network F as target of the analysis, and trains another network A that generates masks for inputs. The goal of these masks is to remove parts of the input without changing the response of F. Generated masks are helpful to interpret the preferred patterns of neural networks as well as diagnose modes of error.\n\nThe paper is very well motivated and the formulation and experiments are well presented too. The experiments are conducted in small benchmarks and using simple fully connected networks. It would be interesting to report and discuss convergence properties of the proposed framework. Also, insights of what are the foreseeable challenges on scaling up the framework to real world scenarios.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper presented a general method for visualizing an arbitrary neural network's inner mechanisms.",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The main contribution of the paper is to propose to learn a Latent Attention Network (LAN) that can help to visualize the inner structure of a deep neural network. To this end, the paper propose a novel training objective that can learn to tell the importance of each dimension of input. It is very interesting. However, one question is what is the potential usage of the model? Since the model need to train an another network to visualize the structure of a trained neural network, it is expensive, and I don't think the model can help use to design a better structure (at least the experiments did not show this point). And maybe different structures of LAN will produce different understanding of the trained model. Hence people are still not sure what kind of structure is the most helpful.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The authors of this paper proposed a data-driven black-box visualization scheme. The paper primarily focuses on neural network models in the experiment section. The proposed method iteratively optimize learnable masks for each training example to find the most relevant content in the input that was \"attended\" by the neural network.  The authors empirically demonstrated their method on image and text classification tasks. \n\nStrength:\n           - The paper is well-written and easy to follow. \n           - The qualitative analysis of the experimental results nicely illustrated how the learnt latent attention masks match with our intuition about how neural networks make its classification predictions.\n\n        Weakness:\n           - Most of the experiments in the paper are performed on small neural networks and simple datesets. I found the method will be more compiling if the authors can show visualization results on ImageNet models. Besides simple object recognition tasks, other more interesting tasks to test out the proposed visualization method are object detection models like end-to-end fast R-CNN, video classification models, and image-captioning models. Overall, the current set of experiments are limited to showcase the effectiveness of the proposed method.\n           - It is unclear how the hyperparameter is chosen for the proposed method. How does the \\beta affect the visualization quality? It would be great to show a range of samples from high to low beta values. Does it require tuning for different visualization samples? Does it vary over different datasets?\n  ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}