{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "Reviewers are unanimous that this is a reject.\nA \"class project\" level presentation.\nErrors in methodology and presentation.\nNo author rebuttal or revision"
    },
    "Reviews": [
        {
            "title": "This paper is an application paper on detecting when a face is disguised, however it is poorly written and do not contribute much in terms of novelty of the approach.",
            "rating": "3: Clear rejection",
            "review": "This paper is an application paper on detecting when a face is disguised, however it is poorly written and do not contribute much in terms of novelty of the approach. The application domain is interesting, however it is simply a classification problem\n\nThe paper is written clearly (with mistakes in an equation), however, it does not contribute much in terms of novelty or new ideas.\n\nTo make the paper better, more empirical results are needed. In addition, it would be useful to investigate how this particular problem is different than a binary classification problem using CNNs.\n\nNotes:\nEquation 2 has a typo, '*'",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "clear application paper / class project",
            "rating": "1: Trivial or wrong",
            "review": "The paper is relatively clear to follow, and implement. \n\nThe main concern is that this looks like a class project rather than a scientific paper. For a class project this could get an A in a ML class!\n\nIn particular, the authors take an already existing dataset, design a trivial convolutional neural network, and report results on it. There is absolutely nothing of interest to ICLR except for the fact that now we know that a trivial network is capable of obtaining 90% accuracy on this dataset.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Limited significance and no originality; weak experiments, flaws in the evaluation",
            "rating": "2: Strong rejection",
            "review": "\nAs one can see by the title, the originality (application of DCNN) and significance (limited to ATM domain) is very limited. If this is still enough for ICLR, the paper could be okay. However, even so one can clearly see that the architecture, the depth, the regularization techniques, and the evaluation are clearly behind the state of the art. Especially for this problem domain, drop-out and data augmentation should be investigated.\n\nOnly one dataset is used for the evaluation and it seems to be very limited and small. Moreover, it seems that the same subjects (even if it is other pictures) may appear in the training set and test set as they were randomly selected. Looking into the referece (to get the details of the dataset -  from a workshop of the IEEE International Conference on Computer Vision Workshops (ICCVW) 2017) reveals, that it has only 25 subjects and 10 disguises. This makes it even likely that the same subject with the same disguise appears in the training and test set.\n\nA very bad manner, which unfortunately is often performed by deep learning researchers with limited pattern recognition background, is that the accuracy on the test set is measured for every timestamp and finally the highest accuracy is reported. As such you perform an optimization of the paramerter #iterations on the test set, making it a validation set and not an independent test set. \n\nMinor issues:\nmake sure that the capitalization in the references is correct (ATM should be capital, e.g., by putting {ATM} - and many more things).",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}