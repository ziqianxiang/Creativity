{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The main idea of the paper is to transform graph classification into image representation (via adjacency matrices). Two reviewers are positive, while one is negative. The concerns are novelty (as mentioned by R2), while the last reviewer thinks the method is too simple and unprincipled (here the AC agrees with authors that simple is not necessarily bad). Overall, none of the reviewers champions this paper. Due to many excellent submissions, unfortunately this paper cannot be accepted in present form."
    },
    "Reviews": [
        {
            "title": "Surprising that the method works, but the method is too unprincipled for me to really see the value of it.",
            "rating": "3: Clear rejection",
            "review": "The paper proposes to use 2-d image representation techniques as a means of learning representations of graphs via their adjacency matrices. The adjacency matrix (or a subgraph of it) is first re-ordered to produce some canonical ordering which can then be fed into an image representation method. This can then be fed into a classifier.\n\nThis is a little too unprincipled for my taste. In particular the paper uses a Caffe reference model on top of the adjacency matrix, rather than learning a method specifically for graphs. Perhaps this is due to a lack of available graph training data, but it doesn't seem to make a lot of sense.\n\nMaybe I missed or overlooked some detail, but I didn't spot exactly what the classification task was. I think the goal is to identify which of the graphs a subgraph belongs to? I'm not sure how relevant this graph classification task is. \n\nThe method does prove that the Caffe reference model maintains some information that can be used for classification, but this doesn't really suggest a generalizable method that we could confidently use for a variety of tasks. It's surprising that it works at all, but ultimately doesn't reveal a big scientific finding that could be re-used.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "interesting idea",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper views graph classification as image classification, and shows that the CNN model adapted from image net can be effectively adapted to the graph classification. The idea is interesting and the result looks promising, but I do not understand the intuition behind the success of analogizing graph with images.\n\nFundamentally, a convolutional filter stands for a operation within a small neighborhood on the image. However, it is unclear how it means for the graph representation. Is the neighborhood predefined? Are the graph nodes pre-ordered? \n\nI am also curious with the effect of pre-trained model from ImageNet. Since the graph presentation does not use color channels,  pre-trained model is used different from what it was designed to. I would imagine the benefit of using ImageNet is just to bring a random, high-dimensional embedding.  In addition, I wonder whether it will help to fine-tune the model on the graph classification data. Could this submission show some fine-tune experiments?",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good paper",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The paper proposed a subgraph image representation and validate it in image classification and transfer learning problems. The image presentation is a minor extension based on a method of producing permutation-invariant adjacency matrix. The experimental results supports the claim.\n\nIt is very positive that the figures are very helpful for delivering the information.\n\nThe work seems to be a little bit incremental. The proposed image representation is mainly based on a previous work of permutation-invariant adjacency matrix. A novelty of this work seems to be transforming a graph into an image. By the proposed representation, the authors are able to apply image classification methods (supervised or unsupervised) to subgraph classification. \n\nIt will be better if the authors could provide more details in the methodology or framework section.\n\nThe experiments on 9 networks support the claims that the image embedding approaches with their image representation of the subgraph outperform the graph kernel and classical features based methods. It seem to be promising when using transfer learning.\n\nThe last two process figures in 1.1 can be improved. No caption or figure number is provided.\n\nIt will be better to make the notations easy to understand and avoid any notation in a sentence without explanation nearby.\nFor example:\n\"the test example is correctly classified if and only if its ground truth matches C.\"(P5)\n\"We carry out this exercise 4 times and set n to 8, 16, 32 and 64 respectively.\"(P6)\n\nSome minor issues:\n\"Zhu et al.(2011) discuss heterogeneous transfer learning where in they use...\"(P3)\n\"Each label vector (a tuple of label, label-probability pairs).\" (incomplete sentence?P5)",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}