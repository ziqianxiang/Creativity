{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "Authors apply dense nets and LSTM to model dependencies among labels and demonstrate new state-of-art performance on an X-Ray dataset.\n\nPros:\n- Well written.\n- New improvement to state-of-art\n\nCons:\n- Novelties are not strong. One combination of existing approaches are used to achieve state-of-art on what is still a relatively new dataset. (All Reviewers)\n\n- Using LSTM to model dependencies would be affected by the selected order of the disease states. In this sense, LSTM seems like the wrong architecture to use to model dependencies among labels. This may be a drawback in comparison to other methods of modeling dependencies, but this is not thoroughly discussed or evaluated. (Reviewer 1 & 3)\n\n- There is a large body of work on multi-task learning with shared information, which have not been evaluated for comparison. Because of this, the contribution of the LSTM to model dependencies between labels in comparison to other available approaches cannot be verified. (Reviewer 1 & 3)\n\n- Top AUC performance on this dataset does not carry much significance on its own, as the dataset is new (CVPR 2017), and few approaches have been tested against it.\n\n- Medical literature not cited to justify with evidence the discovered dependencies among disease states. (Reviewer 1)\n\n"
    },
    "Reviews": [
        {
            "title": "Interesting but flawed in terms of applicability",
            "rating": "6: Marginally above acceptance threshold",
            "review": "Well written and appropriately structured. Well within the remit of the conference.\nNot much technical novelty to be found, but the original contributions are adequately identified and they are interesting on their own.\n\nMy main concern (and complaint) is not technical, but application-based. This study is (unfortunately) typical in that it focuses on and provides detail of the technical modeling issues, but ignores the medical applicability of the model and results. This is exemplified by the fact that the data set is hardly described at all and the 14 abnormalities/pathologies, the rationale behind their choice and the possible interrelations and dependencies are never described from a medical viewpoint. If I were a medical expert, I would not have a clue about how these results and models could be applied in practice, or about what medical insight I could achieve.\n\nThe bottom line seems to be: \"my model and approach works better than the other guys' model and approach\", but one is left with the impression that these experiments could have been made with other data, other problems, other fields of application and they would not have not changed much ",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting application of DenseNet/LSTM to the medical field",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The paper proposes to combine the recently proposed DenseNet architecture with LSTMs to tackle the problem of predicting different pathologic patterns from chest x-rays. In particular, the use of LSTMs helps take into account interdependencies between pattern labels. \n\nStrengths:\n- The paper is very well written. Contextualization with respect to previous work is adequate. Explanations are clear. Novelties are clearly identified by the authors.\n- Quantitative improvement with respect to the state the art. \n\nWeaknesses:\n- The paper does not introduce strong technical novelties -- mostly, it seems to apply previous techniques to the medical domain. It could have been interesting to know if there are more insights / lessons learned in this process. This could be of interest for a broader audience. For instance, what are the implications of using higher-resolution images as input to DenseNet / decreasing the number of layers? How do the features learned at different layers compare to the ones of the original network trained for image classification? How do features of networks pre-trained on ImageNet, and then fine-tuned for the medical domain, compare to features learned from medical images from scratch? \n- The impact of the proposed approach on medical diagnostics is unclear. The authors could better discuss how the approach could be adopted in practice. Also, it could be interesting also to discuss how the results in Table 2 and 3 compare to human classification capabilities, and if that performance would be already enough for building a computer-aided diagnosis system.\n\nFinally -- is it expected that the ordering of the factorization in Eq. 3 does not count much (results in Table 3)? As a non-expert in the field, I'd expect that ordering between pathologic patterns matters more.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Learning to diagnose from scratch by exploiting dependencies among labels",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper presents an impressive set of results on predicting lung pathologies from chest x-ray images. \nAuthors present two architectures: one based on denseNet, and one based on denseNet + LSTM on output dimensions (i.e. similar to NADE model), and compare it to state of the art on the chest x-ray classification. Experiments are clearly described and results are significantly better compared to state of the art.\n\nThe only issue with this paper is, that their proposed method, in practice is not tractable for inference on estimating probability of a single output, a task which would be critical in medical domain. Considering that their paper is titled as a work to use \"dependencies\" among labels, not being able to evaluate their network's, and lack of interpretable evaluation results on this model in the experiment section is a major limitation. \n\nOn the other hand, there are many alternative models where one could simply use multi-task learning and shared parameter, to predict multiple outcomes extremely efficiently. To be able to claim that this paper improved the prediction by better modeling of 'dependencies' among labels, I would need to see how the (much simpler) multi-task setting works as well. \n\nThat said, the paper has several positive aspects in all areas:\n\nOriginality - the paper presents first combination of DenseNets with LSTM-based output factorization,\nWriting clarity - the paper is very well written and clear.\nQuality - (apart from the missing multi-task baseline), the results are significantly better than state of the art, and experiments are well done,\nSignificance - Apart from the issue of intractable inference which is arguably a large limitation of this work, the application in medical field is significant. \n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}