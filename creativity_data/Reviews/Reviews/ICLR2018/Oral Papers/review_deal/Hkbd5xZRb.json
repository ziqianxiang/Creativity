{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "This work introduces a trainable signal representation for spherical signals (functions defined in the sphere) which are rotationally equivariant by design, by extending CNNs to the corresponding group SO(3). The method is implemented efficiently using fast Fourier transforms on the sphere and illustrated with compelling tasks such as 3d shape recognition and molecular energy prediction.\n\nReviewers agreed this is a solid, well-written paper, which demonstrates the usefulness of group invariance/equivariance beyond the standard Euclidean translation group in real-world scenarios. It will be a great addition to the conference. ",
        "decision": "Accept (Oral)"
    },
    "Reviews": [
        {
            "title": "Non-Abelian Harmonic Analysis to Get Spherical Invariance in CNNs",
            "rating": "7: Good paper, accept",
            "review": "The focus of the paper is how to extend convolutional neural networks to have built-in spherical invariance.  Such a requirement naturally emerges when working with omnidirectional vision (autonomous cars, drones, ...).\n\nTo get invariance on the sphere (S^2), the idea is to consider the group of rotations on S^2 [SO(3)] and spherical convolution [Eq. (4)]. To be able to compute this convolution efficiently, a generalized Fourier theorem is useful. In order to achieve this goal, the authors adapt tools from non-Abelian [SO(3)] harmonic analysis.  The validity of the idea is illustrated on 3D shape recognition and atomization energy prediction. \n\nThe paper is nicely organized and clearly written; it fits to the focus of ICLR and can be applicable on many other domains as well.\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Added Late Reviewer",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "review": "First off, this paper was a delight to read.  The authors develop an (actually) novel scheme for representing spherical data from the ground up, and test it on three wildly different empirical tasks: Spherical MNIST, 3D-object recognition, and atomization energies from molecular geometries.  They achieve near state-of-the-art performance against other special-purpose networks that aren't nearly as general as their new framework.  The paper was also exceptionally clear and well written.\n\nThe only con (which is more a suggestion than anything)--it would be nice if the authors compared the training time/# of parameters of their model versus the closest competitors for the latter two empirical examples.  This can sometimes be an apples-to-oranges comparison, but it's nice to fully contextualize the comparative advantage of this new scheme over others.  That is, does it perform as well and train just as fast?  Does it need fewer parameters?  etc.\n\nI strongly endorse acceptance.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Spherical CNNs",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "Summary:\n\nThe paper proposes a framework for constructing spherical convolutional networks (ConvNets) based on a novel synthesis of several existing concepts.  The goal is to detect patterns in spherical signals irrespective of how they are rotated on the sphere.  The key is to make the convolutional architecture rotation equivariant.\n\nPros:\n\n+ novel/original proposal justified both theoretically and empirically\n+ well written, easy to follow\n+ limited evaluation on a classification and regression task is suggestive of the proposed approach's potential\n+ efficient implementation\n\nCons:\n\n- related work, in particular the first paragraph, should compare and contrast with the closest extant work rather than merely list them\n- evaluation is limited; granted this is the nature of the target domain\n\nPresentation:\n\nWhile the paper is generally written well, the paper appears to conflate the definition of the convolutional and correlation operators?  This point should be clarified in a revised manuscript.  \n\nIn Section 5 (Experiments), there are several references to S^2CNN.  This naming of the proposed approach should be made clear earlier in the manuscript.  As an aside, this appears a little confusing since convolution is performed first on S^2 and then SO(3). \n\nEvaluation:\n\nWhat are the timings of the forward/backward pass and space considerations for the Spherical ConvNets presented in the evaluation section?  Please provide specific numbers for the various tasks presented.\n\nHow many layers (parameters) are used in the baselines in Table 2?  If indeed there are much less parameters used in the proposed approach, this would strengthen the argument for the approach.  On the other hand, was there an attempt to add additional layers to the proposed approach for the shape recognition experiment in Sec. 5.3 to improve performance?\n\nMinor Points:\n\n- some references are missing their source, e.g., Maslen 1998 and Kostolec, Rockmore, 2007, and Ravanbakhsh, et al. 2016.\n\n- some sources for the references are presented inconsistency, e.g., Cohen and Welling, 2017 and Dieleman, et al. 2017\n\n- some references include the first name of the authors, others use the initial \n\n- in references to et al. or not, appears inconsistent\n\n- Eqns 4, 5, 6, and 8 require punctuation\n\n- Section 4 line 2, period missing before \"Since the FFT\"\n\n- \"coulomb matrix\" --> \"Coulomb matrix\"\n\n- Figure 5, caption: \"The red dot correcpond to\" --> \"The red dot corresponds to\"\n\nFinal remarks:\n\nBased on the novelty of the approach, and the sufficient evaluation, I recommend the paper be accepted.\n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}