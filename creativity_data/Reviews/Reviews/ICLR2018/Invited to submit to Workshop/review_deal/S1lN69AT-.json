{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The authors present a thorough exploration of large-sparse models that are pruned down to a target size and show that these models can perform better than small dense models. Results are shown on a variety of datasets with as conv models and seq2seq. The authors even go so far as to release the code. I think the authors are to be thanked for their experimental contributions.\nHowever, in terms of accepting the paper for a premier machine learning conference the method holds little surprise or non-obviousness. I think the paper is a good experimental contribution, and would make a good workshop paper instead but it offers little contribution by way of machine learning methods.\n",
        "decision": "Invite to Workshop Track"
    },
    "Reviews": [
        {
            "title": "Informative experiments, unsurprising results.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "Summary:\nThis paper presents a thorough examination of the effects of pruning on model performance.  Importantly, they compare the performance of \"large-sparse\" models (large models that underwent pruning in order to reduce memory footprint of model) and \"small-dense\" models, showing that \"large-sparse\" models typically perform better than the \"small-dense\" models of comparable size (in terms of number of non-zero parameters, and/or memory footprint).  They present results across a number of domains (computer vision, language modelling, and neural machine translation) and model types (CNNs, LSTMs).  They also propose a way of performing pruning with a pre-defined sparsity schedule, simplifying the pruning process in a way which works across domains.  They are able to show convincingly that pruning is an effective way of trading off accuracy for model size (more effective than simply reducing the size of model architecture), although there does come a point where too much sparsity degrades the model performance considerably; this suggests that pruning a medium size model to 80%-90% sparsity is likely better than pruning a larger model to >= 95% sparsity.\n\nReview:\nQuality: The quality of the work is high --- the experiments are extensive and thorough.  I would have liked to see \"small-dense\" vs. \"large-sparse\" comparisons on Inception (only large-sparse results are reported).\n\nClarity: The paper is clearly written, though there is room for improvement. For example, many of the results are presented in a redundant manner (in both tables and figures, where the table and figure are often not next to each other in the document).  Also, it is not clear in several cases exactly which training/heldout/test sets are used, and on which partition of the data the accuracies/BLEU scores/perplexities presented correspond to. A small section (before \"Methods\") describing the datasets/features in detail would be helpful.  Also, it would have probably been nice to explain all of the tasks and datasets early on, and then present all the results at once (NIT: include the plots in paper, and move the tables to an appendix).\n\nOriginality: Although the experiments are informative, the work as a whole is not very original.  The method proposed of using a sparsity schedule to perform pruning is simple and effective, but is a rather incremental contribution. The primary contribution of this paper is its experiments, which for the most part compare known methods.\n\nSignificance: The paper makes a nice contribution, though it is not particularly significant or surprising.  The primary observations are:\n(1) large-sparse is typically better than small-dense, for a fixed number of non-zero parameters and/or memory footprint.\n(2) There is a point at which increasing the sparsity percentage severely degrades the performance of the model, which suggests that there is a \"sweet-spot\" when it comes to choosing the model architecture and sparsity percentage which give the best performance (for a fixed memory footprint).\n\nResult #1 is not very surprising, given that Han et al (2016) were able to show significant compression without loss in accuracy; thus, because one would expect a smaller dense model to perform worse than the large dense model, it would also perform worse than the large sparse model.\nResult #2 had already been seen in Han et al (2016) (for example, in Figure 6).\n\nPros:\n- Very thorough experiments across a number of domains\n\nCons:\n- Methodological contributions are minor.\n- Results are not surprising, and are in line with previous papers.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper analyzes the effectiveness of model pruning for deployment in resource constrained environments. The contribution is marginal but interesting as a summary",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper analyzes the effectiveness of model pruning for deployment in resource constrained environments. The contribution is marginal but interesting as a summary\n\n\nThis paper analyzes the effectiveness of model pruning for deployment in resource constrained environments. Contrary to other approaches, this paper assumes there is a computational budget to be meet and the pruning approach should result in a model that fits within that budget.\n\nAccording to the paper there is a contribution of a pruning scheme. To the best of my understanding, the proposal / contribution is minimal or not clearly detailed. My understanding is the approach is equivalent to a L1 pruning where the threshold for pruning is updated over time / training process rather than pushing weights down towards zero (as it is usually done). \nThen, there is a schedule for minimizing the impact of modifying the weights although this has been discussed in related works (see Alvarez and Salzmann 2016). \n\n\nGiven this setup, the paper present a number of comparisons and experimental validations. \n\nThere are several steps that are not clear to me. \n\n1) how does this compare to the low-rank or group sparsity approaches referred in the related work section?\n2) The key here is modifying the thresholds as the training progresses up to a certain point which seems to me quite equivalent to L1 pruning where the regularization term is also affected by the learning rate (therefore having less influence as the training progresses). In this paper though there are heuristics to stop pruning when certain constraints are met. Which is interesting (as pruning will affect the quality and capacity of the network) but also applicable to other methods. Also, as suggested in related works, the pruning becomes negligible after certain number of epochs (therefore there is no real need to stop the process). Any discussion here would be interesting.\n\n3) For me, it is interesting the fact that pruning in an initial stage is too aggressive. However, it also limits the capacity of the network by pruning too much at the begining. I think there are contrary messages in the paper that would be nice to clarify: pruning rapidly at the beginning where redundant connections are abundant and then, there is the need to have a large learning rate to recover from the pruning.\n\n4) I missed a discussion on the Inception model in the experimental settings. \n\n5) If this is based on masks for pruning and performing sparse operations I wonder how does this benefit at inference time since many operations will be faster in a dense matrix multiplication manner. That is why I think would be interesting to do at group level as proposed in some related methods.\n\n6) Tables showing comparisons are not complete. I do not understand why measuring the non-zero parameters if, in the baseline, there is no analysis on how many of these parameters can be actually set to 0 by pruning as a postprocessing step. Please, add explanations on why / how non-zeros are measured in the baseline.\n\n7) More importantly, I think the comparison sparsity vs width is not fair. This is comparing the training process of a model with limited capacity vs a model where the capacity is progressively limited (the pruned). Training regimes should be detailed and properly analyzed for this to be fair. Nevertheless, results are consistent with other approaches listed in the state of the art (pruning while training is a good thing).\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "pruning efficacy in deep learning",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper presents a comparison of model sizes and accuracy variation for pruned version of over-parameterized deep networks and smaller but dense models of the same size. It also presents an algorithm for gradual pruning of small magnitude weight to achieve a pre-determined level of sparsity. The paper demonstrates that pruning of large over-parameterized models leads to better classification compared to smaller dense models of relatively same size. This pruning technique is demonstrated as a modification to TensorFlow on MobileNet, LSTM for PTB dataset and NMT for seq2seq modeling.\n\nThe paper seems mainly a comparison of impact of pruning a large model for various tasks. The novelty in the work seems quite limited mainly in terms of tensorflow implementation of the network pruning using a binary mask. The weights which are masked in the forward pass don't get updated in the backward pass. The fact that most deep networks are inherently over-parametrized seems to be known for quite sometime.\n\nThe experiments are missing comparison with the threshold based pruning proposed by Han etal. to ascertain if the gradual method is indeed better. A computational complexity comparison is also important if the proposed pruning method is indeed effective. In Section 1, the paper claims to arrive at \"the most accurate model\". However, the validation of the claim is mostly empirical and shows that there lies a range of values for increase in sparsity and decrease in prediction accuracy is better compared to other values.\n\nOverall, the paper seems to perform experimental validation of some of the known beliefs in deep learning. The novelty in terms of ideas and insights seems quite limited.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}