{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "This paper introduces a GAN-based framework for inferring human category representations. The reviewers agree that the idea is interesting and well-motivated, and the results are promising. The technical contribution is not significant, but nevertheless the paper combines existing ideas in an interesting way. The reviewers would also like to see some more work towards the direction of investigation of the results and extraction of insights, without which the paper feels somehow incomplete.",
        "decision": "Invite to Workshop Track"
    },
    "Reviews": [
        {
            "title": "Using GANs for visualizing human representations of visual categories.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper presents a method based on GANs for visualizing how humans represent visual categories. Authors perform experiments on two datasets: Asian Faces Dataset and ImageNet Large Scale Recognition Challenge dataset.\n\nPositive aspects:\n+ The idea of using GANs for this goal is smart and interesting\n+ The results seem interesting too\n\nWeaknesses:\n- Some aspects of the paper are not clear and presentation needs improvement.\n- I miss a clearer results comparison with previous methods, like Vondrick et al. 2015.\n\nSpecific comments and questions:\n\n-  Figure 1 is not clear. Authors should clarify how they use the inference network and what the two arrows from this inference network represent.\n- Figure 2 is also not clear. Just the FLD projections of the MCMCP chains are difficult to interpret. The legend of the figure is too tiny. The right part of the figure should be better described in the text or in the caption, I don't understand well what this illustrates.\n- Regarding to the human experiments with AMT: how do the authors deal with noise on the workers performance? Is any qualification task used? What are the instructions given to the workers?\n- In section 4.2. the authors state \"We also simultaneously learn a corresponding inference network, .... granular human biases captured\". This seems interesting but I didn't find any result on that in the paper. Can you give more details or refer to where in the paper it is discussed/tested?\n- Figure 4 shows \"most interpretable mixture components\".  How this \"most interpretable\" were selected?\n- In second paragraph Section 4.3, it should be Table 1 instead of Figure 1. \n- It would be interesting to see a discussion on why MCMCP Density is better for group 1 and MCMCP Mean is better for group 2. To see the confusion matrixes could be useful.\n\nI like this paper. The addressed problem is challenging and the proposed idea seems interesting.  However, the aspects mentioned make me think the paper needs some improvements to be published.\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "deep extension of MCMCP",
            "rating": "6: Marginally above acceptance threshold",
            "review": "Quality\n\nThis paper demonstrates that human category representations can be inferred by sampling deep feature spaces. The idea is an extension of the earlier developed MCMC with people approach where samples are drawn in the latent space of a DCGAN and a BiGAN. The approach is thoroughly validated using two online behavioural experiments.\n\nClarity\n\nThe rationale is clear and the results are straightforward to interpret. In Section 4.2.1 statements on resemblance and closeness to mean faces could be tested. Last sentences on page 7 are hard to parse. The final sentence probably relates back to the CI approach. A few typos.\n\nOriginality\n\nThe approach is a straightforward extension of the MCMCP approach using generative models.\n\nSignificance \n\nThe approach improves on previous category estimation approaches by embracing the expressiveness of recent generative models. Extensive experiments demonstrate the usefulness of the approach.\n\nPros\n\nUseful extension of an important technique backed up by behavioural experiments.\n\nCons\n\nDoes not provide new theory but combines existing ideas in a new manner.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper proposes a method for using MCMCP to characterize a distribution of GAN-constrained image statistics corresponding to a human concept category. The paper describes a well-motivated method for investigating an interesting problem, but feels incomplete in exploring natural questions presented by the problem.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The idea of using MCMCP with GANs is well-motivated and well-presented\nin the paper, and the approach is new as far as I know.  Figures 3 and 5 are\nconvincing evidence that MCMCP compares favorably to direct sampling of\nthe GAN feature space using the classification images approach.\n\nHowever, as discussed in the introduction, the reason an efficient\nsampling method might be interesting would be to provide insight\non the components of perception.  On these insights, the paper felt\nincomplete.\n\nFor example, it was not investigated whether the method identifies\nclassification features that generalize.  The faces experiment is\nsimilar to previous work done by Martin (2011) and Kontsevich\n(2004) but unlike that previous work does not investgiate whether\nclassification features have been identified that can be added to an\narbitrary image to change the attribute \"happy vs sad\" or \"male vs female\".\n\nSimilarly, the second experiment in Table 1 compares classification\naccuracy between different sampling methods, but it does not provide\nany comparison as done in Vondrick (2015) to a classifier trained\nin a conventional way (such as an SVM), so it is difficult to discern\nwhether the learned distributions are informative.\n\nFinally, the effect of choosing GAN features vs a more \"naive\" feature\nspace is not explored in detail.  For example, the GAN is trained\non an image data set with many birds and cars but not many\nfire hydrants.  Is the method giving us a picture of this data set?",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}