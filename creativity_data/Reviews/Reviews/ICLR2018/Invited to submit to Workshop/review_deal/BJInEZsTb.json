{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "This paper compares autoencoder and GAN-based methods for 3D point cloud representation and generation, as well as new (and welcome) metrics for quantitatively evaluating generative models.  The experiments form a good but still a bit too incomplete exploration of this topic.  More analysis is needed to calibrate the new metrics.  Qualitative analysis would be very helpful here to complement and calibrate the quantitative ones.  The writing also needs improvement for clarity and verbosity.  The author replies and revisions are very helpful, but there is still some way to go on the issues above. Overall, the committee is intersting and recommends this paper for the workshop track.",
        "decision": "Invite to Workshop Track"
    },
    "Reviews": [
        {
            "title": "Well written paper with new  important results",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "3D data processing is very important topic nowadays, since it has a lot of applications: robotics, AR/VR, etc.\n\nCurrent approaches to 2D image processing based on Deep Neural Networks provide very accurate results and a wide variety of different architectures for image modelling, generation, classification, retrieval.\n\nThe lack of DL architectures for 3D data is due to complexity of representation of 3D data, especially when using 3D point clouds.\n\nConsidered paper is one of the first approaches to learn GAN-type generative models.\nUsing PointNet architecture and latent-space GAN, the authors obtained rather accurate generative model.\n\nThe paper is well written, results of experiments are convincing, the authors provided the code on the github, realizing their architectures. \n\nThus I think that the paper should be published.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Above average results, but needs more experiments/comparisons",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper introduces a generative approach for 3D point clouds. More specifically, two Generative Adversarial approaches are introduced: Raw point cloud GAN, and Latent-space GAN (r-GAN and l-GAN as referred to in the paper). In addition, a GMM sampling + GAN decoder approach to generation is also among the experimented variations. \n\nThe results look convincing for the generation experiments in the paper, both from class-specific (Figure 1) and multi-class generators (Figure 6). The quantitative results also support the visuals. \n\nOne question that arises is whether the point cloud approaches to generation is any more valuable compared to voxel-grid based approaches. Especially Octree based approaches [1-below] show very convincing and high-resolution shape generation results, whereas the details seem to be washed out for the point cloud results presented in this paper. \n\nI would like to see comparison experiments with voxel based approaches in the next update for the paper. \n\n[1]\n@article{tatarchenko2017octree,\n  title={Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs},\n  author={Tatarchenko, Maxim and Dosovitskiy, Alexey and Brox, Thomas},\n  journal={arXiv preprint arXiv:1703.09438},\n  year={2017}\n}\n\nIn light of the authors' octree updates score is updated. I expect these updates to be reflected in the final version of the paper itself as well. ",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "interesting approach, but concerns about method",
            "rating": "5: Marginally below acceptance threshold",
            "review": "Summary:\n\nThis paper proposes generative models for point clouds. First, they train an auto-encoder for 3D point clouds,  somewhat similar to PointNet (by Qi et al.). Then, they train generative models over the auto-encoder's latent space, both using a \"latent-space GAN\" (l-GAN) that outputs latent codes, and a Gaussian Mixture Model. To generate point clouds, they sample a latent code and pass it to the decoder. They also introduce a \"raw point cloud GAN\" (r-GAN) that, instead of generating a latent code, directly produces a point cloud.\n\nThey evaluate the methods on several metrics. First, they show that the autoencoder's latent space is a good representation for classification problems, using the ModelNet dataset. Second, they evaluate the generative model on several metrics (such as Jensen-Shannon Divergence) and study the benefits and drawbacks of these metrics, and suggest that one-to-one mapping metrics such as earth mover's distance are desirable over Chamfer distance. Methods such as the r-GAN score well on the latter by over-representing parts of an object that are likely to be filled.\n\nPros:\n\n- It is interesting that the latent space models are most successful, including the relatively simple GMM-based model. Is there a reason that these models have not been as successful in other domains?\n\n- The comparison of the evaluation metrics could be useful for future work on evaluating point cloud GANs. Due to the simplicity of the method, this paper could be a useful baseline for future work.\n\n- The part-editing and shape analogies results are interesting, and it would be nice to see these expanded in the main paper.\n\nCons:\n\n- How does a model that simply memorizes (and randomly samples) the training set compare to the auto-encoder-based models on the proposed metrics? How does the diversity of these two models differ?\n\n- The paper simultaneously proposes methods for generating point clouds, and for evaluating them. The paper could therefore be improved by expanding the section comparing to prior, voxel-based 3D methods, particularly in terms of the diversity of the outputs. Although the performance on automated metrics is encouraging, it is hard to conclude much about under what circumstances one representation or model is better than another.\n\n- The technical approach is not particularly novel. The auto-encoder performs fairly well, but it is just a series of MLP layers that output a Nx3 matrix representing the point cloud, trained to optimize EMD or Chamfer distance. The most successful generative models are based on sampling values in the auto-encoder's latent space using simple models (a two-layer MLP or a GMM).\n\n- While it is interesting that the latent space models seem to outperform the r-GAN, this may be due to the relatively poor performance of r-GAN than to good performance of the latent space models, and directly training a GAN on point clouds remains an important problem.\n\n- The paper could possibly be clearer by integrating more of the \"background\" section into later sections. Some of the GAN figures could also benefit from having captions.\n\nOverall, I think that this paper could serve as a useful baseline for generating point clouds, but I am not sure that the contribution is significant enough for acceptance.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}