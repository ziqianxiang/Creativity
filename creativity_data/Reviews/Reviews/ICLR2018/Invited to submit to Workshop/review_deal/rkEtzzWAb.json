{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "Pros:\n - The paper proposes interesting new ideas on evaluating generative models.\n - Paper provides hints at interesting links between structural prediction and adversarial learning.\n - Authors propose a new dataset called Thin-8 to demonstrate the new ideas and argue that it is useful in general to study generative models.\n - The paper is well written and the authors have made a good attempt to update the paper after reviewer comments.\n\nCons:\n- The proposed ideas are high level and the paper lack deeper analysis.\n- Apart from demonstrating that the parametric divergences perform better than non-parametric divergences are interesting, but the reviewers think that practical importance of the results are weak in comparison to previous works.\nWith this analysis, the committee recommends this paper for workshop.",
        "decision": "Invite to Workshop Track"
    },
    "Reviews": [
        {
            "title": "Interesting way to think about GANs",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper is in some sense a \"position paper,\" giving a framework for thinking about the loss functions implicitly used by the generator of GAN-type models. It advocates thinking about the loss in a way similar to how it is considered in structured prediction. It also proposes that approximating the dual formulation of various divergences with functions from a parametric class, as is typically done in GAN-type setups, is not only more tractable (computationally and in sample complexity) than the full nonparametric estimation, but also gives a better actual loss.\n\nOverall, I like the argument here, and think that it is a useful framework for thinking about these things. My main concern is that the practical contribution on top of Liu et al. (2017) might be somewhat limited.\n\nA few small points:\n\n- f-divergences can actually be nonparametrically estimated purely from samples, e.g. with the k-nearest neighbor estimator of https://arxiv.org/abs/1411.2045, or (for certain f-divergences) the kernel density based estimator of https://arxiv.org/abs/1402.2966. These are unlikely to lead to a practical learning algorithm, but could be mentioned in Table 1.\n\n- The discussion of MMD in the end of section 3.1 is a little off. MMD is fundamentally defined by the kernel choice; Dziugaite et al. (2015) only demonstrated that the Gaussian RBF kernel is a poor choice for MNIST modeling, while the samples of Li et al. (2015) simply by using a mixture of Gaussian kernels were much better. No reasonable fixed kernel is likely to yield good results on a harder image modeling problem, but that is a slightly different message than the one this paragraph conveys.\n\n- It would be interesting to replicate the analysis of Danihelka et al. (2017) on the Thin-8 dataset. This might help clarify which of the undesirable effects observed in the VAE model here are due to likelihood, and which due to other aspects of VAEs (like the use of the lower bound).",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A very general formulation without real theoretical or empirical support",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This paper introduces a family of \"parametric adversarial divergences\" and argue that they have advantages over other divergences in generative modelling, specially for structured outputs. \n\nThere's clear value in having good inductive biases (e.g. expressed in the form of the discriminator architecture) when defining divergences for practical applications. However, I think that the paper would be much more valuable if its focus shifted from presenting a new notion of divergence to deep-diving into the effect of inductive biases and presenting more specific results (theoretical and / or empirical) in structured prediction or other problems.  In its current form the paper doesn't seem particularly strong for either the divergence or GAN literatures. Some reasons below:\n\n* There are no specific results on properties of the divergences, or axioms that justify them. I think that presenting a very all-encompassing formulation without a strong foundation does not add value. \n* There's abundant literature on f-divergences which show that there's a 1-1 relationship between divergences and optimal (Bayes) risks of classification problems (e.g. Reid at al. Information, Divergence and Risk for Binary Experiments in JMLR and Garcia-Garcia et al. Divergences and Risks for Multiclass Experiments in COLT).  This disproves the point that the authors make that it's not possible to encode information about the final task in the divergence. If the loss for the task is proper, then it's well known how to construct a divergence which coincides with the optimal risk.\n* The divergences presented in this work are different from the above since the risk is minimised over a parametric class instead of over the whole set of integrable functions. However, practical estimators of f-divergences also reduce the optimization space (e.g. unit ball in a RKHS as in Nguyen et al.  Estimating Divergence Functionals and the\nLikelihood Ratio by Convex Risk Minimization or Ruderman et al. Tighter Variational Representations of f-Divergences via Restriction to Probability Measures). So, given the lack of strong foundation for the formulation, \"parametric adversarial divergences\" feel more like estimators of other divergences than a relevant new family.\n* There are many estimators for f-divergences (like the ones cited above and many others based e.g. on nearest-neighbors) that are sample-based and thus correspond to the \"implicit\" case that the authors discuss. They don't necessarily need to use the dual form. So table 1 and the first part of Section 3.1 are not accurate.\n* The experiments are few and too specific, specially given that the paper presents a very general framework. The first experiment just shows that Wasserstein GANs don't perform well in an specific dataset and use that to validate a point about those GANs not being good for high dimensions due to their sample complexity. That feels like confirmation bias and also does not really say anything about the parametric adversarial GANs, which are the focus of the paper.\n\nIn summary, I like the authors idea to explore the restriction of the function class of dual representations to produce useful-in-practice divergences, but the paper feels a bit middle of the road. The theory is not strong and the experiments don't necessary support the intuitive claims made in the paper.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Limited novelty for GAN and adversarial divergences literature",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This paper takes some steps in the direction of understanding  adversarial learning/GAN and relating GANs and structured prediction under statistical decision theory framework. \n\nOne of the main contribution of the paper is to  study/analyze parametric adversarial divergences and link it with structured losses. Although, I see a value in the idea considered in the paper, it is not clear to me how much novelty does this work bring on top of the following two papers:\n\n1) S. Liu. Approximation and convergence properties of generative adversarial learning. In NIPS, 2017.\n2) S. Arora. Generalization and equilibrium in generative adversarial nets (GANs). In ICML, 2017.\n\nMost of their theoretical results  seems to be already existing in literature (Liu, Arora,  Arjovsky) in some form of other and it is claimed that this paper put these result in perspective in an attempt to provide a more principled view of the nature and usefulness of adversarial divergences, in comparison to traditional divergences.\n\nHowever, it seems to me that the paper is limited both in theoretical novelty and practical usefulness of these results. Especially, I could not see any novel contribution for GAN literature or adversarial divergences. \n\nI would suggests authors to clearly specify novelties and contrast their work with\n1) GAN literature: ([2] Arora's results) \n2)  Adversarial divergences literature: ([1] Liu)\n\nAlso, provide more experiments to support several claims (without any rigorous theoretical justifications) made in the paper.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}