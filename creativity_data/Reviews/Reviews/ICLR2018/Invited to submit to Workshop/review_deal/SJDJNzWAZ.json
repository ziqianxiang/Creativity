{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "I've summarized the pros and cons of the reviews below:\n\nPros:\n* The method for time representation in event sequences is novel and well founded\n* It shows improvements on several but not all datasets that may have real-world applications\n\nCons:\n* Gains are somewhat small\n* The task is also not of huge interest to ICLR in particular, and thus the paper might be of limited interest\n\nAs a result, because the paper is well done, but drew little excitement from any of the reviewers, I suggest that this not be accepted to the main conference, but encouraged to present at the workshop track.",
        "decision": "Invite to Workshop Track"
    },
    "Reviews": [
        {
            "title": "Approach is good",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The paper proposes a set of methods for using temporal information in event sequence prediction. Two methods for time-dependent event representation are proposed. Also two methods for using next event duration are introduced.\n\nThe motivation of the paper is interesting and I like the approach. The proposed methods seem valid. Only concern is that the proposed methods do not outperform others much with some level of significance. More advance models may be needed.\n\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Minor technical contribution, not significant gains with state of the art, misrepresents previous work",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The authors present a model base on an RNN to predict marks and duration of events in a temporal point process. The main innovation of the paper is a new representation of a point process with duration (which could also be understood as marks), which allows them to use a \"time mask\", following the idea of word mask introduced by Choi et al, 2016. In Addition to the mask, the authors also propose a discretization of the duration using one hot encoding and using the event duration as a regularizer. They compare their method to several variations of their own method, two trivial baselines, and one state of the art method (RMTPP) using several real-world datasets and report small gains with respect to that state of the art method.\n\nOverall, the technical contribution of the paper is minor, the gains in performance with respect to a single state of the art are minimal, and the authors oversell their contribution specially in comparison with the related literature. More specifically, my concerns, which prevent me from recommending acceptance, are as follows:\n\n- The authors assume the point process contains duration and intervals, however, point processes generally do not have duration per event but they are discrete events localized in particular time points. Moreover, the duration in their representation (Figure 1) is sometimes an interevent time and sometimes a duration, which makes the whole construction inconsistent. Moreover, what happens then to the representation depicted in Figure 1 when duration is nonexistent or zero?\n\n- The use of \"time mask\" is not properly justified and the authors are just extending the idea of word mask to their setting -- it is unclear why the duration of an event is going to provide context and in any case this seems like a minor technical contribution. \n\n- The use of a time mask does not appear \"more principled\" than previous work (Due et al., Mei & Esiner, Xiao et al.). Previous work use the framework of temporal point processes in a principled way, the current work does not. I would encourage to authors to tone down their language.\n\n- The regularization proposed by the authors uses a Gaussian on the \"prediction error\" of the duration or just cross entropy on a discretization of the duration. Given the inconsistency in the definition of the duration (sometimes it is duration, sometimes is interevent time), the resulting regularization may lead to unexpected/undesirable results. Moreover, it is unclear why the authors do not model the duration time with an appropriate distribution (e.g., Weibull) and add the log-likelihood of the durations under that distribution as regularization. \n\n- The difference in performance  with respect to a single nontrivial baseline (the remaining baselines are trivial or versions of their own model) is minimal. Moreover, the authors fail to compare with other methods, e.g., the method by Mei & Eisner, which beats RMTPP. This is specially surprising since the authors mention such work in the related work and there is available source code at https://github.com/HMEIatJHU/neurawkes.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "An interesting attempt for time-event information fusion, but can be much improved.",
            "rating": "4: Ok but not good enough - rejection",
            "review": "Quality above threshold.\nClarity above threshold.\nOriginality slightly below threshold.\nSignificance slightly below threshold.\n\nPros:\nThis paper proposed a RNN for event sequence prediction. It provides two constructed choices for combining time(duration) information to event. Experiments on various datasets were conducted and most details are provided.\n\nCons (concerns):\n\n1. Event sequence prediction is a hard problem as there’s no clear way to fuse the features about event and the information about the time. It is a nice attempt that in this work, duration is used for event representation. However, the choices are not “principled” as claimed in the paper. E.g., the duration is simply a scaler, but \"time mask\" approache converts that to a multi-dimensional vector while there’s not much information to regularize it.\n\n2. Event-time joint embedding sounds sensible as it essentially remaps from the original value to some segments. E.g., 10 minutes and 11 minutes might have same effect on next event in one dataset while 3 days and a week might have similar effect on next event prediction. But the way how the experiments are designed and analyzed do not provide such insights.\n\n3. The experimental results are not persuasive as no other baselines besides RNN-based methods are provided. Parametric and nonparametric methods both exist for this event prediction problem in previous work. In the results provided, no significant difference between the listed model choices is found, partly because only using event type and duration is not enough. Other info such as time of day, day of week matters a lot. ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}