{
    "Decision": {
        "metareview": "This paper presents a differentiable simulator for protein structure prediction that can be trained end-to-end. It makes several contributions to this research area. Particularly training a differentiable sampling simulator could be of interest to a wider community.\n\nThe main criticism comes from the clarity for the machine learning community and empirical comparison with the state-of-the-art methods. The authors' feedback addressed a few  confusions in the description, and I recommend the authors to further polish the text for better readability. R4 argues that a good comparison with the state-of-the-art method in this field would be difficult and the comparison with an RNN baseline is rigorously carried out.\n\nAfter discussion, all reviewers agree that this paper deserves a publication at ICLR.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Oral)",
        "title": "Novel end-to-end-differentiable model for protein structure prediction"
    },
    "Reviews": [
        {
            "title": "Interesting paper - not clear and mature enough ",
            "review": "The paper proposes a new end-to-end training framework for computational prediction of protein structure from sequence. \nThis is a very important problem and any progress due to new data and/or methods for utilizing may have high impact. \n\nThe paper presents several technical contributions in the modelling and training procedure - for example, automatic transformation between Cartesian and angular coordinates, using Langevin dynamics, and imputation method to get fine atomic coordinates. \n\nThe overall breadth and depth of the methods presented in the paper are impressive. The paper describes a quite complicated systems with multiple modules interacting between them. The paper doesn't describe the system built in enough details, although many of the details are given in the appendix.  \nFigure. 6 presents a scheme of the entire system, but it lacks details about the different modules, and it is not clear how they interact and how their training together is performed. \nThe pseudo-code boxes describing Algorithms 1-4, and Table 2 describing the representation are informative and helpful, and more descriptions of this type would help. \nFor example:    - In Algorithm 3, what do 'CartesianStep' and 'ClippedInternalStep' mean? where are they described? (should have their own boxes/description).  \n\t\t- I didn't see an Algorithm describing the atomic imputation part. \n\t\t- It would be good to add a high-level pseudo-code for the entire end-to-end training algorithm. In it there could be calls to Algorithms 1-4 when needed.  \n\nThere is also no single place where all the parameters used by the authors to achieve their empirical results are presented \n(e.g. learning rates, Gaussian kernel widths, how are random time steps for enforcing Lipschitz condition chosen etc.). \nIn addition, the empirical loss defined in eq. (8) is a sum of 6 different losses. It is not clear how are these very different losses scaled to the same 'units', which ones are more important, \nif and how are constants multiplying them chosen to give lower/higher weights to some of the losses etc. - I guess these choices will have a large effect on the training. \n\nThe authors present generalization results of their trained model in predicting 3D structures from CATH at different generalization level\n(i.e. different similarity levels to the training set proteins). It is not clear to me how good are these results, except that they are shown \nto be better than a baseline simple model. How well does the author's model compare to other recently suggested end-to-end models? \n(the authors mention AlQuraishi, Anand&Huang, papers). How do they compare to state-of-the art structure prediction programs? (e.g. CASP winners)? \nI realize giving an automatic end-to-end solution is interesting even if performance is below that of best programs, but still it would be good to know gaps.\nIf such comparisons are less meaningful/not practical to perform this should be argued convincingly. \nIt would also be useful to add some metrics of running time - it is not clear how computationally heavy and scalable is the author's model and training, compared to other methods. \n\n\nThere are many typos and inconsistent notations which makes it harder for the reader to understand the paper. \nFor example, 'Figure ??' in multiple locations, wrong Figure referenced, using s vs. S for sequence - S is defined as an L*20 matrix but in the appendix there are\n3 indices: s_{i,l,j} and it looks like different sequences in alignment should be denoted s_i. \nEquation for M_{l,j} isn't clear: j is used both as fixed index and index in summation. \nThe indexing in 'orientation vectors' v-hat_ij definition seems off (the formula of base vectors gives 0/0)\n\n\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "review": "Overall this is an important piece of work that deserves publication at ICLR. I recommend to the authors revise their manuscript to make it more accessible to the machine learning community and that they provide better context to allow them to assess the relative quality of the work compared to state of the art results.\n\n# Quality\n\nThe hypothesis that the authors set out to resolve is whether there is an advantage in using an energy function sampled by Langevin dynamics versus simply using a neural network to regress shape from sequence. They construct a flexible deep energy model where the sequence and structure dependent parts are separated in such a way that fast rollouts are possible. They also adapt the learning algorithm to  ensure that long rollouts can be carried out and present a clever trick for integrating internal coordinates efficiently on a GPU. \n\nThe only criticism in terms of quality of work is that it somewhat lacks putting in context with results from the larger community, for example how well does the model compare in terms of speed and accuracy with co-evolutionary approaches? I realise it will not be possible to give a completely fair like to like comparison, but it will help readers put the results in context if they understood, for example, what the average TM score for CASP12 results was, as summarized in this paper for example: https://onlinelibrary.wiley.com/doi/full/10.1002/prot.25423. Similarly, it would be useful to compare the baseline - at least qualitatively - with the results from AlQuraishi et. al. whose model seems very similar in spirit.\n\n# Clarity\n\nI think in terms of clarity, the paper could be improved a little to take into account the audience of ICLR. In particular:\n\n* It may be useful to add a sentence of how profiles have been found to improve secondary structure prediction greatly. Currently the text makes it sound as though they constitute a sort of 'data augmentation', whereas in my opinion they add information compared to the sequence alone. In fact a brief explanation of the importance of homology might help the reader understand the relevance of the hierarchical approach taken to splitting the training set.\n\n* Fig. 2 caption. Could add some information to explain what panel B is showing. I think this would go a long way to explain why both cartesian and internal coordinates are important.\n\n* Fig. 4 second panel. The x axis should be labeled fraction or be numbered 0-100.\n\n* Fig 4. caption. The figure does not have a caption explaining what the graphs are showing. This would be a good place to explain that the colors refer to test sets that overlap with the training set in the full CATH code (black), overlap only in the CAT code (orange) etc. I admit I had found the explanation of the test/train/validation split rather confusing. It is not clear what the validation set is used for, i.e. which hyper-parameters have been tuned on it etc.\n\n* The nature of the loss. The appendix does a good job in describing each term in the loss function, but does not explain how the empirical loss function and the log-likelihood terms are mixed together. \n\n# Originality\n\nThe work is original and is references the relevant literature.\n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting idea with some weaknesses in the evaluation",
            "review": "This paper presents an end-to-end differentiable model (NEMO) for protein structure prediction. I found this paper very interesting and the idea of training the network through the sampling procedure promising. The authors present the challenges and techniques (damping, Lyapunov regularization etc) in detail.\n\nThe paper is clearly written, however the description of the method can be confusing. This stems in part from the many components of the network as well as the fact that the protein is represented using various coordinate systems and features, so that it is not easy to follow which applies at each stage. Fig. 6 in the appendix helps, however it would be better to have a (perhaps more concise) overview in the main text.\n\nIn the evaluation, the NEMO method is compared to a baseline approach using RNNs. While NEMO trained on profile features performs best, the baseline is trained on sequences only. However, it outperforms the NEMO model trained on sequence-only in every category. Therefore, it would be interesting to see whether NEMO outperforms a baseline trained on profile features. Otherwise, I am not certain whether I can follow the conclusion that \"NEMO generalizes more effectively\". Beyond that, it would be interesting to see some generated atomic substructures from the imputation network, in particular an analysis of how diverse the generated atom positions are and whether they depend on the local environment.\n\nOverall, I appreciate the general idea and find the proposed approach very interesting. The contribution could have been stronger with a more detailed evaluation and better presentation.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "review",
            "review": "Post-rebuttal revision: The authors have adressed my concerns sufficiently. The paper still has issues with presentation, and weak comparisons to earlier methods. However, the field is currently rapidly developing, and comparing to earlier works is often difficult. I believe the Langevin-based prediction is a significant and clever contribution. I'm raising my score to 6.\n\n------\n\nThe paper proposes an end-to-end neural architecture for learning protein structures from sequences. The problem is highly important. The method proposes to use a Langevin simulator to fold the protein ‘in silico’ from some initial state, proposes numerous tricks for the optimisation, and proposes neural networks to extract information from both the sequence and the fold state (energy function). The system works on internal coordinates, which are conditioned and integrated on the fly. The method seems to perform very well, improving upon their baseline model considerably.\n\nIn spite of the paper being an outstanding work, I have two criticisms about the accessibility and impact of the paper on the broader ICLR audience. In its current form and complexity, the paper feels accessible mostly to a narrow audience.\n\nFirst, the framework proposed in the paper is massive, containing a large amount of components, neural networks, simulators, integrators, optimisation tricks, alignments, profiles, stabilizations, etc. The amount of work done in the manuscript is staggering, but the method is also difficult to understand from reading the main manuscript alone. The 10+ page appendix is critical for understanding (for instance, the appendix reveals that MSA is used to generate more data), and even with it the method is difficult to grasp as a whole. This paper should be presented in a journal form with a presentation not hindered by page limits, while currently one needs to jump between the main text and appendix to get the whole picture. I also wonder if some parts of the system have already been published, and perhaps the presentation could be condensed that way. \n\nSecond, the introduction lists numerous competing methods both on the protein modelling side and on the MCMC vs optimisation side. The paper does not compare to any of these, which is strange, and makes it difficult to assess how much this paper improves upon state-of-the-art. Right now its unclear what is state-of-the-art in general. No bigger context of protein folding is given either, for instance, how well the method fares against purely alignment based approaches, or against purely physics-based simulators. Finally, the experimental section poorly describes how all the pieces of the system affect the final predictions. The discussion on the exploding gradients and dampening is excellent however. The only baseline is one with the simulator replaced by an RNN. There does not seem to be any running time analyses. As such, it is hard to interpret the current system, and it feels like a black box.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}