{
    "Decision": {
        "metareview": "The paper proposes a set of tricks leading to a new SOTA for sampling high resolution images. It is clearly written and the presented contribution will be of high interest for practitioners.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Oral)",
        "title": "New SOTA for image sampling"
    },
    "Reviews": [
        {
            "title": "Good paper",
            "review": "Summary:\nThis paper proposes a suite of tricks for training large-scale GANs, and obtaining state-of-the-art results for high-resolution images. The paper starts from a self-attention GAN baseline (Zhang 2018), and proposes:\n-\tIncreasing batch size (8x) and model size (2x)\n-\tSplitting noise z in multiple chunks, and injecting it in multiple layers of the generator\n-\tSampling from truncated normal distribution, where samples with norms that exceed a specific threshold are resampled. This seems to be used only at test-time and is used to control variety-fidelity tradeoff. The generator is encouraged to be smooth using an orthogonal regularization term.\nIn addition, the paper proposes practical recipes for characterizing collapse in GANs. In the generator, the exploding of the top 3 singular values of each weight matrix seem to indicate collapse. In the discriminator, the sudden increase of the ratio of first/second singular value of weight matrices indicate collapse in GANs. Interestingly, the paper suggests that various regularization methods which can improve stability in GAN training, do not necessarily correspond to improvement in performance.\n\nStrengths:\n-\tProposed techniques are intuitive and very well motivated\n-\tOne of the big pluses of this work is that authors try to \"quantify\" each proposed technique with training speed and/or performance improvement. This is really a good practice.\n-\tDetailed analysis for detecting collapse and improving stability in large-scale GAN\n-\tProbably no need to mention that, but results are quite impressive\n\nWeaknesses:\n-\tComputational budget required is massive. The paper mentions model use from 128-256 TPUs, which severely limits reproducibility of results.\n\nComments/Questions:\n-\tCan you elaborate more on why BatchNorm statistics are computed across all devices as opposed to per-device? Was this crucial for best performance? \n-\tIt is not clear if provided analysis for large-scale GANs apply for small-medium sized GANs. Providing such analysis would be also helpful for the community.\n-\tHow do you see the impact of the suggested techniques on tackling harder data-modalities for GANs, e.g. text or sequential data in general?\n\nOverall recommendation:\nThe paper is well written, ideas are well motivated/justified and results are very compelling. This is a good paper and I higly recommend acceptance.\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good investigation, great results, could be improved.",
            "review": "Summary:\nThe authors present a empirical investigation of methods for scaling GANs to complex datasets, such as ImageNet, for class-conditioned image generation. They first build and describe a strong baseline based on recently proposed techniques for GANs and push the performance on large datasets with several modifications presented sequentially, to obtain strong state-of-the-art IS/FID scores, as well as impressive visual results. The authors propose a simple truncation trick to control the fidelity/variance which is interesting on its own but cannot always scale with the architecture. The authors further propose a orthogonalization-based regularization to mitigate this problem. An investigation of training collapse at large scale is also performed; the authors investigate some regularization schemes based on gathered empirical evidence. As a result, they explore and discard Spectral Normalization of the generator as a way to prevent collapse and show that a severe tradeoff between stability and quality can be controlled when using zero-centered gradient penalties in the Discriminator. In the end, no solution that can ensure quality and stability is found, except having prohibitively large amounts of data (~300M images). Models are evaluated on the ImageNet and on this internal, bigger dataset.\n\nPros:\n- This investigation gives a significant amount of insights on GAN stability and performance at large scales, which should be useful for anyone working with GANs on complex datasets (and that have access to great computational resources).\n\n- Even though commonly used evaluations metrics for GANs are still not fully adequate, the authors obtain quantitative performance significantly beyond previous work, which seems indeed correlated with remarkable visual results.\n\n- The baseline and added modifications are well presented and clearly explained. The Appendices also have great value in that regard.\n\n\nCons:\n- Discussions sometimes lack depth or are absent.\nFor example, it is unclear to me why some larger models are not amenable to truncation. Besides visible artifacts, what does it mean? Why does a smoother G reduces those artifacts? Were samples from those networks better without using truncation? Why would this be?\n\nAuthors report how wider networks perform best, and how deeper networks degrade performance. Again, discussions are lacking, and it doesn’t seem the authors tried to understand why such behaviors were shown.\n\nEven though this is mostly an empirical investigation, I think some more efforts should be put in understanding and explaining why some of those behaviors are shown, as I think it can bootstrap future work more easily.\n\n- In Section 3.1 : “Across runs in Table 1, we observe that without Orthogonal Regularization, only 16% of models are amenable to truncation compared to 60% with Orthogonal Regularization.” For me, this is not particularly clear. Is this something the reader should understand from Table 1? \n\n- I question the choice of sections chosen to be in the main paper/appendices. I greatly appreciated the negative results reported in the main text as well as in the appendices and this has significant value. However, as this is to me mostly a detailed empirical investigation and presentation of high-performance GANs on large scales, I would be likely to share this with colleagues who want to tackle similar problems. In this case, if future readers limit themselves to the main text, I think it can have more value to present some content form Appendix B and C than to have more than a full page on stability investigations and attempted tricks that turned out not to be used to reach maximal performance. However I do not want to discourage publishing of negative results, and I definitely wish to see this investigation in the paper, but I merely question the positioning of such information. With regard to my first negative point above about the lack of discussions, it seems the analysis of Section 4 is disproportionate compared to other places.\n\n\nSuggestions/Comments:\n\n- Regarding the diversity/fidelity tradeoff using different truncation thresholds, I think constraining the norm of the sampled noise vectors to the exact threshold value (by projecting the samples on the 0-centered hyper-sphere of radius = threshold) could yield even more interesting or more informative Figures, as obtained scores or samples on the edge of that hyper-sphere might provide information on the ‘guaranteed’ (not proven) quality/fidelity of samples mapped from inside that hyper-sphere. \n\n- In Appendix D, the Figures could be slightly clarified by using a colored heatmap to color the curve, with colors corresponding to the threshold values. Similar curves could also be produced with the hyper-sphere projection proposed above to have a slightly clearer idea of the behavior on the limit of that hyper-sphere.\n\n- In Section 4.2, in the second paragraph, you refer to Appendix F and describe “sharp upward jump at collapse” in D’s loss. However, it seems the only Figure showing D’s loss when unconstrained is Figure 26, in which it is hard to notice any significant jump in the loss.\n\n- In Appendix F, Figure 20 d), the title seems wrong. It seems to report sigma^2 values, but the title says “losses”.\n\n\nThis investigation of GAN scalability is successful results-wise even though the inability to stabilize training without sacrificing great performance on ImageNet is disappointing. The improvement over previous SOTA is definitely significant. This work thus shows a modern GAN architecture for complex datasets that could be a strong basis for future work. However, I think the paper could and should be improved with some more detailed analysis and discussions of exhibited behaviors in order to further guide and encourage future work. It could also be clarified on some aspects, and potentially re-structured a bit to be better align with its probable impact directions.  I would also be curious to see the proposed techniques applied on simpler datasets. Can this be useful for someone having less compute power and working on something similar to CelebA? \n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Great progress achievement in the field of image generation",
            "review": "This paper present extensions of the Self-Attention Generative Adversarial Network approach SAGAN, leading to impressive images generations conditioned on imagenet classes. \nThe key components of the approach are :\n- increasing the batch size by a factor 8\n- augmenting the width of the networks by 50% \nThese first two elements result in an Inception score (IS) boost from 52 to 93.  \n- the use of shared embeddings for the class conditioned batch norm layers, orthonormal regularization and hierarchical latent space bring an additional boost of IS 99.\nThe core novel element of the paper is the truncation trick: At train time, the input z is sampled from a normal distribution but at test time, a truncated normal distribution is used: when the magnitude of elements of z are above a certain threshold, they are re-sampled.\nVariations of this threshold lead to variations in FD and IS, as shown in insightful experiments. The comments that more data helps (internal dataset experiments) is also informative. \nVery nice to have included negative results and detailed parameter sweeps.\n\nThis is a very nice work with impressive results, a great progress achievement in the field of image generation. \nVery well written.\n\nSuggestions/questions: \n- it would be nice to also propose unconditioned experiments. \nIt would be good to give an idea in the text of TPU-GPU equivalence in terms of feasibility of a standard GPU implementation - computation time it would involve. \n- I understand that no data augmentation was used during training?    \n- clarification of the truncation trick: if the elements of z are re-sampled and are still above the threshold, are they re-sampled again and again until they are all below the given threshold?\n- A sentence could be added to explain the truncation trick in the abstract directly since it is simple to understand and is key to the quality of the results.\n- A reference to Appendix C could be given at the beginning of the Experiments section to help the reader find these details more easily.\n- It would be nice to display more Nearest neighbors for the dog image.\n- It would be nice to add a figure of random generations.\n- make the bib uniform: remove unnecessary doi - url - cvpr page numbers\n",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}