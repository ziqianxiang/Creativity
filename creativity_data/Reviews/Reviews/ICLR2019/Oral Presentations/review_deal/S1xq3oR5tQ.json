{
    "Decision": {
        "metareview": "The paper advocates neuroscience-based V1 models to adapt CNNs.  The results of the simulations are convincing from a neuroscience-perspective.  The reviewers equivocally recommend publication.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Oral)",
        "title": "a good step in bringing computational neuroscience and CNNs together"
    },
    "Reviews": [
        {
            "title": "Review of The effects of neural resource constraints on early visual representations",
            "review": "EDIT: On the basis of revisions made to the paper, which significantly augment the results, the authors note: \"the call for papers explicitly mentions applications in neuroscience as within the scope of the conference\" which clarifies my other concern. For both of these reasons, I have changed my prior rating.\n\nThis paper is focused on a model of early visual representation in recognition tasks drawing motivation from neuroscience. Overall the paper is an interesting read and reasonably well written (albeit with some typos). The following addresses the positives and negatives I see associated with this work:\n\nPositives:\n- There are relatively few efforts that focus heavily on more shallow models with an emphasis on representation learning, and for this reason this paper fills an important space\n- The connections to neuroscience are interesting albeit it's unclear the extent to which this is the mandate of the conference\n- The most interesting bit of the paper to me is the following: \"A bottleneck at the output of the retina yielded center-surround retinal RFs\" - it is somewhat a foregone conclusion that most networks immediately converge on orientation selective and color opponent representations. That this model produces isotropic filters is a very interesting point.\n\nNegatives:\n- The work feels a little bit shallow. It would have been nice to see a bit more density in terms of results and ablation studies. This also relates to my second point.\n- Given the focus on early visual processing, there seems to be a missed opportunity in examining the role of normalization mechanisms or the distinction between simple and complex cells. If the focus resides in the realm of neuroscience and early visual representation, there is an important role to these mechanisms. e.g. consider the degree of connectivity running from V1 to LGN vs. LGN to V1.\n\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "A great paper and a solid contribution to computational neuroscience",
            "review": "I enjoyed reading this paper which is a great example of solid computational neuroscience work.\n\nThe authors trained CNNs under various biologically-motivated constraints (e.g., varying the number of units in the layers corresponding to the retina output to account for the bottleneck happening at the level of the optic nerve or varying the number of \"cortical\" layers to account for differences across organisms). The paper is clear, the hypotheses clearly formulated and the results are sound. The implications of the study are quite interesting suggesting that the lack of orientation selectivity in the retina would arise because of the bottleneck at the level of the optic nerve. The continuum in terms of degree of linearity/non-linearity observed across organisms at the level of the retina would arise as a byproduct of the complexity/depth of subsequent processing stages. While these results are somewhat expected this is to my knowledge the first time that it is shown empirically in an integrated computational model.\n\nMinor point: The authors should consider citing the work by Eberhardt et al (2016) which has shown that the exists an optimal depth for CNNs to predicting human category decisions during rapid visual categorization.\n\nS. Eberhardt, J. Cader & T. Serre. How deep is the feature analysis underlying rapid visual categorization? Neural Information Processing Systems, 2016.\n\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting application of deep neural nets to neuroscience.",
            "review": "This paper addresses questions about the representation of visual information in the retina. The authors create a deep neural network model of the visual system in which a single parameter (bandwidth between the “retina” and “visual cortex” parts) is sufficient to qualitatively reproduce retinal receptive fields observed across animals with different brain sizes, which have been hard to reconcile in the past. \n\nThis work is an innovative application of deep neural networks to a long-standing question in visual neuroscience. While I have some questions about the analyses and conclusions, I think that the paper is interesting and of high quality.\n\nMy main concern is that the authors only show single examples, without quantification, for some main results (RF structure). For example, for Fig. 2A and 2B, an orientation selectivity index should be shown for all neurons. A similar population analysis should be devised for Fig 2C, e.g. like Fig 3 in [1]\n\nMinor comments:\n1. Page 4: “These results suggest that the key constraint ... might be the dimensionality bottleneck..”: The analyses only show that the bottleneck is *sufficient* to explain the differences, but “the key constraint” also implies *necessity*. Either soften the claim or provide control experiments showing that alternative hypotheses (constraint on firing rate etc.) cannot explain this result in your model.\n\n2. I don’t understand most of the arguments about “cell types” (e.g. Fig. 2F and elsewhere). In neuroscience, “cell types” usually refers to cells with completely different connectivity constraints, e.g. excitatory vs. inhibitory cells or somatostatin vs. parvalbumin cells. But you refer to different CNN channels as different “types”. This seems very different than the neuroscience definition. CNN channels just represent different feature maps, i.e. different receptive field shapes, but not fundamentally different connectivity patterns. Therefore, I also don’t quite understand what you are trying to show with the weight-untying experiments (Fig. 2E/F).\n\n3. It is not clear to me what Fig. 3B and the associated paragraph are trying to show. What are the implications of the nonlinearity being due to the first or second stage? \n\n4. Comment on Fig 3F: The center-surround RFs probably implement a whitening transform (which is linear). Whitened inputs can probably be represented more efficiently in a network trained with L2-regularization and/or SGD. This might explain why the “quasi-linear” retina improves separability later-on.\n\n[1] Cossell, Lee, Maria Florencia Iacaruso, Dylan R. Muir, Rachael Houlton, Elie N. Sader, Ho Ko, Sonja B. Hofer, and Thomas D. Mrsic-Flogel. “Functional Organization of Excitatory Synaptic Strength in Primary Visual Cortex.” Nature 518, no. 7539 (February 19, 2015): 399–403. https://doi.org/10.1038/nature14182.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}