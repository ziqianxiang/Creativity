{
    "Decision": {
        "metareview": "\npros:\n- The paper is well-written and includes a lot of interesting connections to cog sci (though see specific clarity concerns)\n- The tasks considered (visual and symbolic) provide a nice opportunity to study analogy making in different settings.\n\ncons:\n- There was some concerns about baselines and novelty that I think the authors have largely addressed in revision\n\nThis is an intriguing paper and an exciting direction and I think it merits acceptance.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "Interesting and relevant work, improved in revision"
    },
    "Reviews": [
        {
            "title": "Interesting direction and nice discussions, but evaluation and analysis are not strong enough ",
            "review": "This work investigates the ability of a neural network to learn analogy. They showed that a simple neural network is able to solve analogy problems with image or abstract input, given that the training data is selected to contrast abstract relational structures. \n\nThe paper is relatively well-written with rich discussions. Some details about the experiments are missing like how many examples are used for training and testing. It is also important to show how much variations are in the dataset, and there should be some external baselines like those proposed in (Barrett et al, 2018). \n\nAlthough the performance is relatively high, some error analysis will provide more insights into what the neural network is missing and if it makes mistakes similar to human. \n\nSection 4 claims that “For a model trained via LABC, we found that these activities clustered according to relation type (e.g. progression ) more-so than domain”. However, it is unclear whether Figure 4 can support this. Some quantitive measure should help, for example, the average distance within the clusters between clustering based on relation type and domain. \n\nThe novelty of the proposed approach is limited. The difference between the proposed method and baseline in performance seems to be a result of whether there is a difference between train and test setting. For example, if trained in “contrasting” will have better test performance on “contrasting” but worse on “normal” and vice versa. \n\nThe problem is very interesting and the discussion is extensive. However, the proposed approach isn’t very novel and the evaluation and analysis should be improved to provide a stronger support. \n\nBarrett, David GT, et al. \"Measuring abstract reasoning in neural networks.\" arXiv preprint arXiv:1807.04225 (2018).\n\n------\n\nScore updated after reading authors' response. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The paper describes an approach to train neural networks for analogical reasoning tasks by selecting training instances that force the network to learn relational structure",
            "review": "The paper describes an approach to train neural networks for analogical reasoning tasks.\n\nGeneral analogical reasoning is quite a significant milestone in Machine learning. Therefore, the paper tackles an extremely challenging problem.  The paper does a good job of constructing various tasks to show that analogies can be learned in different scenarios which are complex analogy tasks. Specifically, visual analogy and symbolic analogies are considered. The main idea is to choose training examples such that the model is forced to learn the relational structure rather than simply learn superficial features. One weakness is that we need to hand code the training examples to force it to have contrasting relational structure for different tasks. Is this realistic in different problems? That is maybe a limiting factor of this work. An automated method for generating such examples is given, but there is not too much detail on this (5.3). Maybe this needs to be expanded.\n\nAlso, is the idea of LABC different from SMT. The novelty may be a bit weak in this aspect. If LABC  can be described in a more general manner, it would help a reader not familiar with the other related work.  Since the baseline comparison is with a very weak method (randomly chosen examples), it is hard to judge the impact of the proposed approach. In summary, I think the paper has nice ideas, particularly, if we can automatically generate examples using LABC. but maybe there is a need to work on better organizing the ideas, more general formulation of LABC and a more convincing experimental evaluation that includes a state-of-the-art method if available",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Intuitive idea for improved training demonstrated powerful in the analogy domain",
            "review": "Cons\n\n1.\tIt’s unclear why LABC produces lower scores than ‘normal’ training on ‘normal’ testing.\n2.\tThe text says nothing I can find to explain why in Fig 5 the ‘entity’ vectors have all 0s except in one dimension, which seems to make the problem considerably easier.\n3.\tIn a sense, there is no cross-domain adaptation required in the symbolic task: min is min, whether it operates on dimension k of the source vectors or dimension j of the target vectors. On the other hand, dimensions are processed independently in the model, as far as I can tell, so there’s no free transfer of learning min on dimension k to knowing min on dimension j. It would be good to comment on this issue.\n4.\tThere seem to be obvious analogies (so to speak) to GANs, and it is very curious that this is not mentioned anywhere that I can see. This is particularly glaring in Sec. 5.3.\n5.\tThe quantitative results are scattered throughout the prose; it would be challenging, but worthwhile, to gather them into an actual table.\n\nPros\n\n6.\tThe basic idea (“We should aspire to select as negative examples those examples that are plausible considering the most abstract principles that describe the data”, p. 14) is very intuitive, common-sensical, bordering on obvious. But it is not at all obvious that the idea has as much power as is demonstrated in the experiments. The transfer to novel domain combinations, novel domains, and novel values of dimensions is impressive and surprising.\n7.\tThe result that the proposed training, designed to promote generalization on analogy tasks, also seems to promote improved sensory processing is interesting. Whether it really instantiates the parallel connection argued for by the High-Level Perception view from psychology/philosophy is debatable, but that is itself an interesting connection that the authors should be praised for identifying.\n8.\tIn general, the connection to the cognitive literature is creative and tantalizing and provides good scientific grounding for the work.\n9.\tThe linking to the flexibility of word meanings in the final paragraph pushes the limit of the plausibility of connection to broader cognitive issues, but I’m inclined to indulge the authors for at least bringing up this important and relevant issue.  \n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}