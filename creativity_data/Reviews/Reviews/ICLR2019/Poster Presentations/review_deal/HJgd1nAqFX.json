{
    "Decision": {
        "metareview": "This paper considers the task of web navigation, i.e. given a goal expressed in natural language, the task is to navigate webs by filling up fields and clicking links. The proposed model uses reinforcement learning, introducing a novel extension where the graph embedding of the pages is incorporated into the Q-function. The results are sound, and the paper is overall well-written.\n\nThe reviewers and AC note the following potential weaknesses. The primary concern that was raised was the novelty. Since the task could potentially be framed as semantic parsing, reviewer 4 mentioned there may be readily available approaches for baselines that the authors did not consider. The comparison to semantic parsing required a more detailed discussion, pointing not only the differences but also the similarities, that would encourage the two communities to explore novel approaches to their tasks. Further, reviewer 2 was concerned about the limited novelty, given the extensive work that combines GNN and RL, such as NerveNet.\n\nThe authors provided comments and a revision to address these issues. They described why it is not trivial to formulate their setup as a semantic parsing problem, partly due to the fact that the environment is partially observable.\nSimilarly, the authors described the differences between the proposed approach and methods like NerveNet, such as the use of a dynamic graph and off-policy RL, making the latter not a viable baseline for the task. These changes addressed most of the concerns raised by the reviewers.\n\nThe reviewers agreed that this paper should be accepted.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "Novel application of RL, sound results"
    },
    "Reviews": [
        {
            "title": "Moderately interesting result, but not aware at all of a huge related literature",
            "review": "Caveat: I am an emergency reviewer filling in for someone that fell through on their commitment to review for ICLR.  The framing of this paper is quite outside my typical area, so I am not super familiar with the related work here, nor do I have time to get familiar with it for this last-minute review.                                                                                                                                                                             \n                                                                                                     \nThis paper presents a new model for deep reinforcement learning on web pages, where the system is given a goal (stated in text) and is supposed to interact with the web page (through clicking and entering text) in order to achieve that goal.  The supervision is a positive reward when the sequence of actions taken matches the goal.  The novel model presented in this paper is a modular Q function that incorporates graph embeddings of the web page's DOM, as well as similarity scores between elements in the DOM with words in the goal.\n                                                                                                     \nJust judging the presentation of the paper, it looks sound.  The methods seem reasonable (very similar to methods that are known to work well on related problems; more on that below), and the experiments look to be well done.  The paper is reasonably well written.  I don't know the RL community well enough to know how impactful this particular piece of work would be there - it's a new model architecture, basically, that gives improved performance.  I'd probably give a similar paper in my area a 3.5-4 out of 5 for an ACL conference.  The one major drawback I see in this paper is that it is _so_ similar to work on semantic parsing, but doesn't realize it.\n                                                                                                     \nI am not a \"reinforcement learning\" researcher, though I am a \"semantic parsing\" researcher.  The problem statement in this paper reads to me exactly like a semantic parsing problem: map a piece of text to a statement in some formal language.  In this case, the \"statement\" is a sequence of actions on the DOM of a web page.  The web page is possibly unseen at test time (the particulars of the data setup weren't totally clear to me), so the model has to be able to handle linking words in the sentence to pieces of the DOM in a way that doesn't rely on having seen those DOM elements during training.  This setup seems almost identical to the WikiTableQuestions dataset (Pasupat and Liang 2015), which has seen several RL-inspired works recently (e.g., https://arxiv.org/abs/1807.02322).  The way that the authors propose to use attention scores in the \"global module\" is _very_ similar to the linking mechanism proposed by Krishnamurthy, Dasigi and Gardner (EMNLP 2017) for WikiTableQuestions, and the way that the \"word-token selection\" only allows words in the goal sentence is very reminiscent of Chen Liang's language for parsing questions in WikiTableQuestions, which has similar restrictions for similar reasons.\n                                                                                                     \nI think the main difference between what we call \"weakly-supervised semantic parsing\" and what you call \"deep reinforcement learning\" is that semantic parsing leverages the fact that we know the language we're parsing into, so we don't need to use model-free RL methods like Q-learning.  We know the model, so we can be much smarter about learning.  Again, I'm not super familiar with the tasks you're looking at here, but I'm pretty sure there are much better _supervised_ learning techniques that you could apply to these problems.\n                                                                                                     \nAll of this is to say that the methods proposed here look _very_ similar to methods that have been studied for quite a while in the semantic parsing literature (I gave only recent references above, but the basic problems go back decades; e.g., http://aclweb.org/anthology/P09-1010, or http://www.cs.utexas.edu/~ml/papers/senior-aaai-2008.pdf).  Yet this paper only cites recent deep RL papers.  I think the authors would benefit greatly from familiarizing themselves with this literature.  I think the semantic parsing community would also benefit from this, as there are surely ideas in the deep RL community that we could benefit from, too.  But the two communities don't really talk to each other much, it seems, even though in some cases we are working on _very_ similar problems.\n                                                                                                     \nSo, to summarize: the paper seems reasonable enough.  I'm guessing that the RL community would find it at least moderately interesting, and it appears well written and well executed.  My one concern is that it's totally oblivious to the fact that it's sitting right next to a well-established literature that could probably teach it a thing or two about mapping language to actions.\n\n\n--------------\n\nAfter seeing the authors engage at least a little with the related semantic parsing literature, I've increased my score to a 7.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting paper",
            "review": "The authors propose a novel architecture for RL-based web navigation to address both of these problems, DOM-Q-NET, which utilizes a graph neural network to represent tree-structured HTML along with a shared state space across multiple tasks. It is believed more flexible to be probed on WorldOfBits environments. Significant improvements are shown by experiment.",
            "rating": "7: Good paper, accept",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "Review",
            "review": "DOM-Q-NET: GROUNDED RL ON STRUCTURED LANGUAGE \n\nThis paper presents a somewhat novel graph-based Q-learning method for web navigation benchmark tasks. The authors show that multi-task learning helps in this case and their method is able to learn without BC as previous works have needed. While this work is interesting and to my knowledge somewhat novel. I concerns with one aspect of the evaluation. In some part it was stated that they show the highest success rate for testing on 100 episodes, if this is indeed the maximum success rate, it is unclear if these results are misleading or not. It is possible that there was a lucky seed in those 100 episodes leading to a higher max that is not representative of the algorithm performance. Also, please have the submission proof-read for English style and grammar issues. There are many minor mistakes, some of which are pointed out below. I am rating marginally below due mainly to the potentially misleading results from the comment on using the highest success rate to report results and to a minor extent due to the novelty aspect (though this is an interesting application).\n\n\nComments:\n\n- “Evaluation metric: we plot the moving average of the reward for last 100 episodes, and report the highest success rate for testing on 100 episodes.” —> This is unclear, do you mean you only displayed the maximum success rate out of all 100 episodes? So if the success rates are [0, 100, 0, 0, 0], Figure 2 shows 100% success? If so, this is somewhat misleading and a better metric may have been the average success rate with confidence intervals. Otherwise you may have just gotten a lucky random seed potentially.\n- I would’ve liked to see if this is the only method which benefits from multitask learning or do DOMNETs also benefit. This however, is just a nice to have.\n- I appreciate the inclusion of hyper parameters and commitment to releasing the code in an effort to promote reproducibility! Great job there. \n- I really like the idea of using graph networks with RL, though I’m not sure if it’s novel to this work. Interesting line of work!\n- While this is an interesting application, I’m not sure about the novelty. I suggest spending a bit more time discussing how this work contrasts with methods like Wang et al., or others cited here.\n\nTypos:\n\n“MiniWoB(Shi et al., 2017) benchmark tasks. “ —> missing space between citation\n“Q network architecture with graph neural network” —> with a graph neural network\n\"MiniWoB(Shi et al., 2017)” —> MiniWoB (Shi et al., 2017) (missing space)\n“achieved the state” —> achieved state of the art \n“2016; Wang et al., 2018)as main” —> missing space\n“series of attentions between DOM elements and goal” —> series of attention (modules?) between the DOM elements and the goal (?)\n“constrained action set” —> constrained action sets\n“In appendix, we define our criteria for difficulties of different tasks.” —> In the appendix",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}