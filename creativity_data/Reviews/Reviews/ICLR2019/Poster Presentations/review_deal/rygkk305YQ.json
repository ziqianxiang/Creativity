{
    "Decision": {
        "metareview": "This is an ambitious paper tackling the important and timely problem of controlling non-annotated attributes in generated speech. \n\nThe reviewers had mixed opinions about the results. R1 asks for more convincing exposition of results but, nevertheless, acknowledging that it is difficult to evaluate TTS systems systematically. Besides, R2 and R3 find the results good. \n\nJudging from the reviews and previous work, this paper does not seem to be very novel, although it certainly has intriguing new elements. Furthermore, it constitutes a mature piece of work.  \n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "Paper attacks significant problem"
    },
    "Reviews": [
        {
            "title": " A structure to the z-space to create predictabilily in the features of the generated speech is implemented  with good results",
            "review": "The authors describe the conditioned GAN model to generate speaker conditioned Mel spectra. They augment the z-space corresponding to the identification with latent variables that allow a richer set of produced audio. In a way this is like a partially conditioned model that has \"extra\" degrees of freedom. It looks that the \"latent\" variables are just concaneted to the \"original\" set of z-values (altough with particular conditions to maximize independence). The conditioning of the z-space has originality in it and may provide interesting to the audience. Ultimately one coud think about z-space direction being totally mapped to specific features of the produced signal.\n\nAlso, I am curious to know how the Mel spectra are used to produce the actual sound wave - as the phase information is not present if utilizing only the spectral amplitude. Very often this leads to suboptimal generation, and the remedy is to use the time domain like in ( https://arxiv.org/ftp/arxiv/papers/1810/1810.05319.pdf).  However, in this case the audio samples show a pretty nice generation of sound.  However, it is not really end to end.\n\nThe manuscript has some curious decisios in its concepts - I do not see the architecture really hiearchial, nor end to end. I would prefer modifications on the paper that concentrate on the truly novel features. \n\nThe paper is clear, well written and done with high ambition, from data set utilization  to novel architetures to human quality panels. Results are good and interesting.\n\nNEW:\nThe authors have addressed the concerns I had with the manuscript.\n\n\n\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A good work",
            "review": "This paper proposes a two layer latent variable model to obtain disentangled latent representation, thus facilitates fine-grained control over various attributes including noise level, speaker rate etc.\n\nDetailed comments:\n\ni) This work is closely related to Akuzawa et al. (2018). The difference is not properly discussed. \n\nii) In the abstract, “end-to-end text-to-speech” is an unfortunate claim, because the proposed system has two separately trained component: 1) a text to mel-spectrogram model based on Tacotron and, 2) a WaveRNN for waveform synthesis.  In ASR, it’s absolutely fine to claim a spectrogram to text model as a end-to-end system, because the wave to spectrogram step is trivial.  In TTS, waveform synthesis is a very crucial step and largely determines the final naturalness results. \n\niii) In experiment, one need include the MOS score of ground truth for comparison or debiasing.\n\niv) Did you try different values of D other than 16? When you check the meaning of different dimensions, how many dimensions are meaningful? How many are meaningless, or even just dummy?\n\nIn summary,  \npros:\n- A good work with impressive results.\ncons:\n- Related work need to be properly discussed. \n- Doesn’t include the MOS of ground truth.\n- Moderate novelty. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Hierarchical Generative Modeling for Controllable Speech Synthesis",
            "review": "Quality: This submission claims to present a model that can control non-annotated attributes such as speaking style, accent, background noise, etc. Though empirical evidence in the form of numerical measurements is presented for some controllable attributes more evidence other than individual samples and authors claims is needed. For example a reliable numerical evidence is needed on page 4 following \"We also found...\", page 5 following \"We discovered....\", page 5 following \"It clearly presents...\", page 5 following \"Drawing samples...\" evidence is given only for 1 dimension, page 6 following \"Figure 7(b)...\". \n\nClarity: The model is simple though the exact form and nature of observed and latent class variables could be made more explicit. Including how they are computed/initialised/set. What are different modes using the proposed model? Why both negative results are in the appendix? \n\nOriginality: moderately\n\nSignificance: moderately\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}