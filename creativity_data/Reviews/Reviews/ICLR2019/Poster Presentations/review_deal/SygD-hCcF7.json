{
    "Decision": {
        "metareview": "This paper introduces an approach for reducing the dimensionality of training data examples in a way that preserves information about soft target probabilistic representations provided by a teacher model, with applications such as zero-shot learning and distillation. The authors provide an extensive theoretical and empirical analysis, showing performance improvements in zero shot learning and finite sample error upper bounds. The reviewers generally agree this is a good paper that should be published.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Good paper"
    },
    "Reviews": [
        {
            "title": "What do we really minimize?",
            "review": "The paper deals with a problem formulation adjacent to that of the sufficient dimension reduction: given training set of pairs (x_i,y_i), how to reduce the dimension of the first element, i.e. map x_i --> f(x_i), so that f(x_i)'s still have all the information to recover y_i's.\n\nIn the paper, the output y_i is a probability distribution over k labels that softly describes inclusion of example i into k classes.\n\nThey consider a nonlinear case, i.e. the mapping f is taken from a prespecified set of mappings, parameterized by Theta (e.g. neural network). Then by \"recovering y_i\" they mean that EM algorithm for {f(x_i)} will result in a clustering of the data into k soft clusters similar to given {y_i}.\n\nThe algorithm that is presented is quite natural, though no guarantees that it will converge to something relevant were given. Theoretical analysis deals with a question --- how far the empirical discrepancy could be from the true expected one. Especially, easiness of substitution of \\bar{Y}_{ic} with Y_{ic} in the algorithm is unclear (roughly speaking, the latter means that E-step is omitted in EM). If matrix Y in algorithm is fixed, why we need to compute \\pi in the loop? Isn't it going to be the same? Does this algorithm really minimizes the discrepancy?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "strong inductive bias of the model may not be appropriate for visualization",
            "review": "Authors propose a method of embedding training data examples into low-dimensional spaces such that mixture probabilities from a mixture model on these points are close to probability predictions from the original model in terms of KL divergence. Authors suggest two use-cases of such an approach: 1) data visualization, and 2) zero-shot learning. For the visualization use-case, authors compare against other dimensionality reduction methods with qualitative analysis on a synthetic problem, as well as evaluation metrics such as Neighborhood-Preservation Ratio and Clustering Distance Preservation Ratio. For zero-shot use-case, they take pre-trained models on two zero-shot tasks, and improve the accuracy by using probability outputs from pre-trained models as target.\n\nRegarding the benefit of using the proposed method for visualization, the DRPR is making a strong assumption that representations of data points that belong to the same class form a uni-modal, Gaussian distribution (since authors don't experiment with distance functions other than L2). This inductive bias comes with a strong benefit when the assumption is true - as demonstrated in the toy dataset experiment - but when it is not true, the visualization would strongly distort the underlying structure of the model. And I don't believe this is a realistic assumption, because there has to be a reason that most deep-learning based classification models in the literature don't always use a model like (3) or Prototypical Networks instead of typical fully-connected + softmax layer, unless the data size is small and we need stronger inductive bias to improve the performance of the model.  That is, we usually don't think unimodality is the right assumption, even with learned representations. I suspect that the while DRPR might be good at visualizing relationships between class labels - especially which class can be easily confused with another - but would be worse at faithfully representing each data point, especially the ambiguity of class labels on individual ones. I would argue, however, that faithful representation of each data point is more important for scatter plots than relationship between classes, because the latter can be more effectively analyzed with other methods such as confusion matrices. As it is typical in most dimensionality reduction papers, I would encourage authors to consider more types of synthetic datasets which nonlinearity and multimodality are critical to be learned. I don't believe quantitative evaluation in Table 1 and 2 are very meaningful, because DRPR's objective function is much better aligned with these metrics than others. \n\nZero-shot experiments show a promising lift over the baseline pre-trained models. The kind of bias we should be careful about, however, is that when we distillate one model into another, the performance generally improves even when the same exact model is both the teacher and the student: (Furlanello et al, ICML 2018 https://arxiv.org/abs/1805.04770 ). Therefore, it would be interesting to compare against distillation with baseline models themselves.\n\nPros:\n* Extensive theoretical and empirical analysis\n* Simple idea that generalizes to multiple use-cases, which implies robustness of the approach as a methodology\n\nCons:\n* Unimodal assumption is likely not realistic, which would result in misleading visualization of data\n* Visualization analysis focuses on how class-relationships are preserved rather than faithful representation of each data point, which is a wrong target\n* Synthetic experiment is conducted on a single, too simplistic one; more examples are needed to understand the capabilities of the model in more detail\n* The bias of knowledge distillation is not controlled",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Excellent paper with strong motivation, interesting proposed method, and comprehensive empirical results",
            "review": "Summary:\n\nThis paper introduces a new supervised dimensionality reduction model. Supervision is provided in the form of class probabilities and the learning algorithm learns low-dimensional representations such that posterior cluster assignment probabilities given the representations match the observed class probabilities. The representations can be learned directly or the parameters of a neural network can be learned which maps inputs to the lower-dimensional space. The authors provide an extensive theoretical analysis of the proposed method and evaluate it on dimensionality reduction, visualization, and zero-shot learning tasks.\n\nReview:\n\nOverall, I thought this was an excellent paper. The idea is well-motivated, the presentation is clear, and the evaluations are both comprehensive and provide insight into the behavior of the proposed methods (I will not comment on the theoretical analysis, as it is entirely contained in the supplemental materials). I was honestly impressed by the shear volume of content in this paper, particularly since I found none of it to be superfluous. Frankly, this paper might be better served as two papers or a longer journal paper, but that is hardly a reason not to accept it. I strongly recommend acceptance and have only a couple of comments on presentation.\n\nComments:\n\n- When trying to understand the proposed method, I found it useful to expand out the full objective function and derive the gradients w.r.t. to f_i. If my maths were correct, the gradient of the objective w.r.t. f_i can be written as the difference between the expected gradient of the divergence w.r.t Y and the expected gradient of the divergence w.r.t. the posterior cluster assignment probabilities. Though not surprising in and of itself, the authors might consider including this equation as it really helped me understand what the learning algorithm was doing. \n\n- The authors might consider adding a more complete description of the zero-shot learning task. My understanding of the task was that there are text descriptions of each category and at test time new text descriptions are added that were not in the training set. The goal is to map an unseen image to a class based on the text descriptions of the classes. A couple of sentences explaining this in the first paragraph of section 4.2 would help those who are not familiar with this zero-shot learning setup.",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}