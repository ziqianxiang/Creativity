{
    "Decision": {
        "metareview": "The paper presents a graph neural network that represents the movements of electrons during chemical reactions, trained from a dataset to predict reactions outcomes.\n\nThe paper is clearly written, the comparisons are sensical. There are some concerns by reviewer 3 about the experimental results: in particular the lack of a simpler baseline, and the experimental variance. I think the some of the important concerns from reviewer 3 were addressed in the rebuttal, and I hope the authors will update the manuscript accordingly.\n\nOverall, this is fitting for publication at ICLR 2019.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "Interesting application of graph neural networks"
    },
    "Reviews": [
        {
            "title": "A quite interesting contribution that also brings more clearer interpretations on what is learned",
            "review": "Summary:\nThe paper presents a novel method for predicting organic chemical reactions, in particular, for learning (Robinson-Ingold's) ''arrow pushing\" mechanisms in an end-to-end manner. Organic molecules consist of covalent bonds (that's why we can model them as molecular graphs), and organic reactions are recombinations of these bonds. As seen in organic chemistry textbooks, traditional chemists would qualitatively understand organic reactions as an alternating series of electron movements by bond breaking (bond cleavage) and bond forming (bond formation). Though now quantum chemistry calculations can give accurate quantitative predictions, these qualitative understanding of organic reactions still also gives strong foundations to consider and develop organic reactions. The proposed method tries to learn these series of bond changes directly through differentiable architectures consisting of three graph neural networks: 1) the one for determining the initial atom where electron movements start, 2) the one for representing state transitions from  the previous bond change to the next, and 3) the one for determining when the electron movements end. Experimental evaluations illustrate the quantitative improvement in final product prediction against existing methods, as well as give chemical intuitions that the proposed method can detect a class of LEFs (linear electron flows).\n\nComment:\n- This study is a quite interesting contribution because many existing efforts focus on improving differentiable architecture design for graph transformation and test it using chemical reaction data without considering what is learned after all. In contrast, this paper gives the clear meaning to predict \"arrow pushing\" mechanism from chemical reaction data and also makes sure the limitation to LEFs that are heterolytic. Traditional graph rewrite systems or some recent methods directly borrowing ideas from NLP do not always give such clear interpretations even though it can somehow predict some outputs.\n\n- The presentation of the paper is clear and in very details, and also provides intuitive illustrative examples, and appendix details on data, implementations, and related knowledge. \n\n- The architecture is based on graph neural networks, and seem natural enough. Basically, I liked overall ideas and quite enjoyed them but several points also remained unclear though I'm not sure at all about chemical points of view.\n\n1) the state transition by eq (2)-(4) seems to assume 1-st order Markovian, but the electron flow can have longer dependence intuitively. Any hidden states are not considered and shared between these networks, but is this OK with the original chemical motivations to somehow model electron movements? The proposed masking heuristics to prevent stalling would be enough practically...? (LEF limitations might come from this or not...?)\n\n2) One thing that confuses me is the difference from approaches a couple of work described at the beginning of section 'Mechanism prediction (p.3)', i.e. Fooshee et al 2018; Kayala and Baldi, 2011, 2012; Kayala et al, 2011. I don't know much about these studies, but the paper describes as \"they require expert-curated training sets, for which organic chemists have to hand-code every electron pushing step\". But for \"Training\" (p.6) of the proposed method, it also describes \"this is evaluated by using a known electron path and intermediate products extracted from training data\". Does this also mean that the proposed method also needs a correct arrow pushing annotations for supervised learning?? Sounds a bit contradicting statements?\n\n3) Is it just for computational efficiency why we need to separate reactants and reagents? The reagent info M_e is only used for the network for \"starting location\", but it can affect any intermediate step of elementary transitions intuitively (to break through the highest energy barrier at some point of elementary transitions?). Don't we need to also pass M_e to other networks, in particular, the one for \"electron movement\"?\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Potentially interesting and novel ideas but impossible to tell if they are significant due to low-quality results section",
            "review": "Review of \"A Generative Model for Electron Paths\"\n\nPaper summary:\n\nThe paper proposes a new model for predicting arrow-pushing chemical\nreaction diagrams from raw reaction data.\n\nSection 1 summarizes the motivation: whereas other models only predict\nchemical reaction products from reactants, the proposed model attempts\nto also predict the reaction mechanism.\n\nSection 2 provides a background on related work. Previous models for\nmechanism prediction are limited to work which require expert-curated\ntraining sets. The proposed model is designed for a subset of\nreactions called \"linear electron flow\" (LEF) which is\nexplained. Contributions of this paper are an end-to-end model, a\ntechnique for identifying LEF reactions/mechanisms from\nreaction/product data, and an empirical study of how the model learns\nchemical knowledge.\n\nSection 3 explains the proposed generative model, which represents a molecule\nusing a graph (nodes are atoms and edges are bonds). It is proposed to\nlearn a series of electron actions that transform the reactants into\nthe products. The total probability is factorized into three parts:\nstarting location, electron movement, and reaction\ncontinuation. Figure 2 and Algorithm 1 are helpful.\n\nSection 4 explains the proposed method for creating mechanism data\nfrom chemical reactant/product databases. Figure 3 is helpful.\n\nSection 5 discusses results of predicting mechanisms and products on\nthe USPTO data set.\n\nComments:\n\nStrong points of the paper: (1) it is very well written and easy to\nunderstand, (2) the chemical figures are very well done and helpful,\nand (3) the method for predicting mechanisms seems to be new.\n\nThe major weak point of the paper is the results section, which needs\nto be improved before publication.\n\nIn particular Tables 2-3 (comparison of prediction accuracy) need to\nshow some measure of variance (standard deviation or confidence\ninterval) so the reader can judge if there is any significant\ndifference between models. Please use K-fold cross-validation, and\nreport mean/sd of test accuracy over the K test folds.\n\nThe term \"end-to-end\" should be defined. In section 2.2 it is written\n\"End-to-End: There are many complex chemical constraints that limit\nthe space of all possible reactions. How can we differentiate through\na model subject to these constraints?\" which should be clarified using\nan explicit definition of \"end-to-end.\"\n\nAlso there needs to be some comparison with baseline methods for\npredicting mechanisms.  It is claimed that no comparison can be made\nagainst the previous methods for mechanism prediction (Section 2.2),\nbecause \"they require expert-curated training sets, for which organic\nchemists have to hand-code every electron pushing step.\" However the\ncurrent paper proposes a method for generating such steps/data for LEF\nreactions. So why not use those data to train those baseline models,\nand compare with them? That would make for a much stronger paper. Please\nadd at least one of the methods discussed in section 2.2 to your\naccuracy comparison in Table 2.\n\nIt would additionally be helpful to know what the \"uninformed\nbaseline\" / \"ignore the inputs\" / \"random guessing\" accuracy rates are\non your data set. For example in classification the uninformed\nbaseline always predicts the class which is most frequent in the\ntraining data, and in regression it predicts the mean of the\nlabels/outputs in the training data. What would the analogy be for\nyour two problems? (product and mechanism prediction)\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "good paper, nice contribution",
            "review": "The paper presents a novel end-to-end mechanistic generative model of electron flow in a particular type of chemical reaction (“Linear Electron Flow” reactions) . Interestingly, modeling the flow of electrons aids in the prediction of the final product of a chemical reaction over and above problems which attack this “product prediction problem” directly. The method is also shown to generalize well to held-out reactions (e.g. from a chemistry textbook).\n\nGeneral Impressions\n\n+ For me the biggest selling point is that it improves performance in predicting the ultimate reaction outcome. It should do because it provides strictly more supervision, but it’s great that it actually does. \n+ Because it models the reaction mechanism the model is interpretable, and it’s possible to enforce constraints, e.g. that dynamics are physically possible.\n+ Generalises outside of the dataset to textbook problems :-)\n+ Well-founded modeling choices and neural network architectures.\n- Only applies to a very particular type of reaction (heterolytic LEF). \n- Requires supervision on the level of electron paths. This seems to inhibit applying the model to more datasets or extending it to other types of reactions.\n- Furthermore the supervision extraction does not seem take advantage of symmetries noted in the section(s) about difficulty evaluating inference. \n- It would be nice to margin out the electron flow model and just maximize the marginal likelihood for the product prediction problem.\n\nNovelty\nI’m not an expert on the literature of applying machine learning to the problems of reaction {product, mechanism} prediction but the paper appears to conduct a thorough review of the relevant methods and occupy new territory in terms of the modeling strategy while improving over SOTA performance.\n\nClarity\nThe writing/exposition is in general extremely clear. Nicely done. There are some suggestions/questions which I think if addressed would improve clarity.\n\nWays to improve the paper\n1. Better motivate the use of machine learning on this problem. What are the limitations of the arrow-pushing models? \n\n2. Explain more about the Linear Electron Flow reactions, especially:\n- Why does the work only consider “heterolytic” LEF reactions, what other types of LEF reactions are omitted?\n- Is the main blocker to extending the model on the modeling front or the difficulties of extracting ground-truth targets? It appears to be the latter but this could be made more clear. Also that seems to be a pretty severe limitation to making the algorithm more general. Could you comment on this?\n\nQuestions\n1. Is splitting up the electron movement model into bond “removal” and “addition” steps just a matter of parameterization or is that physically how the movements work? \n\n2. It appears that Jin et al reports Top 6/8/10 whereas this work reports Top 1/3/5 accuracy on the USPTO dataset. It would be nice if there was overlap :-). Do your Top 6/8/10 results with the WLDN model agree with the Jin et al paper?\n\n\nNits\nSection 2.3, first paragraph “...(LEF) topology is by far the most important”: Could you briefly say why? It’s already noted that they’re the most common in the database. Why?\n\nSection 3.ElectionMovement, first paragraph. “Observer that since LEF reactions are a single path of electrons…”. Actually, it’s not super clear what this means from the brief description of LEF. Can you explain these reactions in slightly more detail?\n\nSection 3.ElectionMovement, second paragraph. “Differently, the above distribution can be split…”. Awkward phrasing. How about “In contrast, the above distribution can be split…”. \n\nSection 3.Training, last sentence “...minibatches of size one reaction”. Slightly awkward phrasing. Maybe “...minibatches consisting of a single reaction”?\n\nSection 5.2, second sentence. “However, underestimates the model’s actual predictive accuracy…”. It looks like a word accidentally got deleted here or something.\n\nSection 5.2, paragraph 4. “To evaluate if our model predicts the same major project”... Did you mean “the same major product”?\n\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}