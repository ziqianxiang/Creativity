{
    "Decision": {
        "metareview": "Important problem (visually grounded dialog); incremental (but not in a negative sense of the word) extension of prior work to an important new setting (GuessWhich); well-executed. Paper was reviewed by three experts. Initially there were some concerns but after the author response and reviewer discussion, all three unanimously recommend acceptance. \n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "meta-review"
    },
    "Reviews": [
        {
            "title": "Contributions seem incremental and concerns regarding the formulated approach",
            "review": "The paper proposes an improvement over the AQM approach for an information-theoretic framework for task-oriented dialog systems. Specifically, the paper tries to circumvent the problem of explicitly calculating the information gain while asking a question in the AQM setting. While the original AQM approach sweeps over all possible guesses and answers while estimating information gain, this is rendered impractical in scenarios where this space cannot be tractably enumerated. As a solution, AQM+ proposes sweeping over only some top-k relevant instantiations of answers and guesses in this space by normalizing the probabilities of the subset of the space in consideration. In addition, unlike AQM, AQM+ can ask questions which are relevant to the dialog context so far. Consequentially, this is generalizable and applicable for dialog systems with non ‘yes/no’ answers. Empirical observations demonstrate improvements over the existing approaches for such task-oriented dialog systems. The paper is not very well-written and at times is hard to understand. The contributions seem incremental as well in addition to the concerns mentioned below.\n\nComments:\n- The paper is overloaded with notations and the writing is not very smooth. The terse nature of the content makes it hard to follow in general. If someone apriori was not familiar with task-oriented dialog or the visual dialog setting in Das et al. (2017b), it would be quite hard to follow.\n- While mentioning SL/RL approaches while comparing or introducing the setup, the authors do not make any distinction between discriminative and generative dialog models. Specifically, SL approaches could either be trained discriminatively to rank options among the provided ones given dialog context or in a generative manner via token-level teacher forcing. The authors should clearly make this distinction in the introduction and in other places where it’s needed.\n- The authors should stress more upon the approximations involved while calculating mutual information. As far as I understand, even in the AQM approach the numerator and the denominator within the logarithm are estimated from a different set of parameters and as such they need not be consistent with each other under marginalization. The term resembles MI and ensuring consistency in such a framework would require either of the numerator or the denominator to be close to something like a variational approximation of the true distribution. In addition, AQM+ adopts the same framework as AQM but computes MI over some top-k of the random variables being considered. Could the authors comment more on why restricting the space of r.v.’s to some top-k samples is a good idea? Would that not lead to somewhat of a biased estimator?\n- Unless I am missing something, training aprxAgen from the training data (indA) seems odd. Assuming, this to be Qbot’s mental model of Abot -- there is no prior reason why this should be initialized or trained in such a manner. Similarly, the training paradigm of the depA setting is confusing. If they are trained in a manner similar to a regular Abot -- either SL or RL -- then they’re not approximate mental models but are rather just another Abot agent in play which is being queried by Qbot.\n- Under Comparative Models, in paragraph 2 of section 4.1, the authors state that “there are some reports….looks like human’s dialog”. Can the authors elaborate on what they mean by this statement? It’s not clear what the message to be conveyed here is.\n- Comparisons in GuessWhich highly rely on the PyTorch implementation in the mentioned github repository. However, the benchmarking performed in that repository for RL over SL is not accurate because of inherent bugs in the implementation of REINFORCE (see https://github.com/batra-mlp-lab/visdial-rl/issues/13 and https://github.com/batra-mlp-lab/visdial-rl/pull/12 ). I would suggest the authors to take this into account.\n- Can the authors also show performances for the GuessWhich models (under the AQM+ framework) on the original retrieval metrics for Visual Dialog mentioned in Das et al. (2017a)? This would be useful to judge the robustness of the proposed approach over the methods being compared with. \n\n\nUpdated Thoughts\n- The authors adressed the issues raised/comments made in the review. In light of my comments below to the author responses -- I am inclined towards increasing my rating.\n- In addition, I have mentioned some updates in the comments which might make the paper stronger -- centered around clarifications regarding the computation of the top-k info-gain term.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper addresses the important limitation of the prior work and improves the generalization of the model.",
            "review": "The goal of this paper is to build a task-oriented dialogue generation system that can continuously generate questions and make a guess about the selected object.\n\nThis paper builds on the top of the previously proposed AQM algorithm and focuses on addressing the limitation of the AQM algorithm, which chooses the question that maximizes mutual information of the class and the current answer, but uses fixed sets of candidate questions/answers/classes.\nThe proposed AQM+, the extension of AQM, is to deal with 1) the natural language questions / answers using RNN as the generator instead of selecting from the candidate pool (RNN as generator) and 2) a large set of candidate classes (from 10 to 9628). \nThe novelty is relatively limited, considering that the model is revised from AQM.\nAlthough this work is incremental, this paper addresses the important issue about the generalization.\n\nThe experiments show that the model achieves good performance in the experiments.\nHowever, some questions should be clarified.\n\n1) In the ablation study, what is the performance of removing Qpost and remaining Qinfo (asking questions using AQM+, and guessing with an SL-trained model)?\n\n2) In the experiments, the baselines do not contain AQM. \nAlthough AQM has more constraints, it is necessary to see the performance difference between AQM and AQM+, . \nIf the difference is not significant, it means that this dataset cannot test the generalization capability of the model, so experiments on other datasets may be considered.\nIf the difference is significant, then the effectiveness of the model is well justified.\nThe authors should include the comparison in the experiments; otherwise, it is difficult to justify whether the proposed model is useful.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Review",
            "review": "\n=================\nUpdated Thoughts\n=================\n\nI was primarily concerned about a lack of analysis regarding the technical contributions moving from AQM to AQM+. The revisions and author comments here have addressed the specific experiments I've asked for and more generally clarified the contributions made as part of AQM+. I've increased my rating to reflect my increased confidence in this paper. Overall, I think this is a good paper and will be interesting to the community.\n\nI also thank the authors for their substantial efforts to revise the paper and address these concerns.\n\n\n===========\nStrengths:\n===========\n\nThe approach is a sensible application of AQM to the GuessWhich setting and results in significant improvements over existing approaches both in terms of quantitative results and qualitative examples. \n\n===========\nConcerns:\n===========\n\n[A] Technical Novelty is Limited Compared to AQM \nThe major departures from the AQM approach claimed in the paper (Section 3.3) are:\n\t[1] the generation of candidate questions through beam search rather than predefined set \n\t[2.1] The approximate answerer being an RNN generating free-form language instead of a binary classifier. \n\t[2.2] Dropping the assumption that \\tilde p(a_t | c, q_t) = \\tilde p (a_t | c, q_t, h_{t-1}). \n\t[3] Estimate approximate information gain using subsets of the class and answer space corresponding to the beam-search generated question set and their corresponding answers.\n\nI have some concerns about these:\n\nFor [1], the original AQM paper explores this exact setting for GuessWhat in Section 5.2 -- generating the top-100 questions from a pretrained RNN question generator via beam search and ranking them based on information gain. From my understand, this aspect of the approach is not novel.\n\nFor [2.1] I disagree that this is a departure from the AQM approach, instead simply an artifact of the experimental setting. The original AQM paper was based in the GuessWhat game in which the answerer could only reply with yes/no/na; however, the method itself is agnostic of this choice. In fact, the detailed algorithm explanation in Appendix A of the AQM paper explicitly discusses the possibility of the answer generator being an RNN model. \n\nGenerally, the modifications to AQM largely seem like necessary, straight-forward adjustments to the problem setting of GuessWhich and not algorithmic advances. That said, the changes make sense and do adapt the method to this more complex setting where it performs quite well!\n\n\n[B] Design decisions are not well justified experimentally\nGiven that the proposed changes seem rather minor, it would be good to see strong analysis of their effect. Looking back at the claimed difference from AQM, there appear to be a few ablations missing:\n- How useful is generating questions? I would have liked to see a comparison to a Q_fix set samples from training. (This corresponds to difference [1] above.)\n- How important is dialog history to the aprxAns model? (This corresponds to difference [2.2] above).\n- How important is the choice to restrict to |C| classes? Figure 4b begins to study this question but conflates the experiment by simultaneously increasing |Q| and |A|. (This correspond to difference [3] above.)\n\n[C] No evaluation of Visual Dialog metrics\nIt would be useful to the community to see if this marked improvement in GuessWhich performance also results in improved ability to predict human response to novel dialogs. I (and I imagine many others) would like to see evaluation on the standard Visual Dialog test metrics. If this introspective inference process improves these metrics, it would significantly strengthen the paper!\n\n[D] No discussion of inference time\nIt would be useful to include discussion of relative inference time. The AQM framework requires substantially more computation than an non-introspective model. Could authors report this relative increase in inference efficiency (say at K=20)? \n\n\n[E] Lack of Comparison to Base AQM\nI would expect explicit comparison to AQM for a model named AQM+ or a discussion on why this is not possible.\n\n\n===========\nMinor Things:\n===========\n\n- I don't understand the 2nd claimed contribution from the introduction \"At every turn, AQM+ generates a question considering the context of the previous dialog, which is desirable in practice.\" Is this claim because the aprxAns module uses history? \n\n- Review versions of papers often lack polished writing. I encourage the authors to review their manuscript for future versions with an eye for clarity of terminology, even if it means a departure from established notation in prior work. \n\n- The RL-QA qualitative results, are these from non-delta or delta? Is there a difference between the two in terms of interpretability? \n\n===========\nOverview:\n===========\n\nThe modifications made to adapt AQM to the GuessWhich setting presented here as AQM+ seem to be somewhat minor technical contributions. Further, where these difference could be explored in greater detail, there is a lack of analysis. That said, the proposed approach does make significant qualitative and quantitative improvements in the target problem. I'm fairly on the fence for this paper and look forward to seeing additional analysis and the opinions of other reviewers.\n\n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}