{
    "Decision": {
        "metareview": "This paper characterizes a particular kind of fragility in the image classification ability of deep networks: minimal image regions which are classified correctly, but for which neighboring regions shifted by one row or column of pixels are classified incorrectly. Comparisons are made to human vision. All three reviewers recommend acceptance. AnonReviewer1 places the paper marginally above threshold, due to limited originality over Ullman et al. 2016, and concerns about overall significance.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "metareview"
    },
    "Reviews": [
        {
            "title": "Interesting paper but requires additional experiments ",
            "review": "Ullman et al. showed that slight changes in location or size of visible regions in minimal recognizable images can significantly impair human ability to recognize objects. This paper is a  follow-up of Ullman et al. paper, with focus on sensitivity of DNNs to certain regions in images. In other words, slight change of such regionsâ€™ size or location in the image can significantly affect DNN ability in recognizing them, even-though these changes are not noticeable for humans. \n\n\nComments and questions:\n\nThis paper provides in-depth study of fragile recognition in DNNs. \n\n- Visualizing activations of different layers of DNN for Loose shift/shrink FRIs can potentially provide more details on why the final output of DNN is significantly different for two visually similar images.   \n\n- Naively augmenting training data with crops of small FRI sizes can potentially harm and confuse DNN in classifying training samples as many small patches in training images are background and they don't contain target object. It is interesting to see the sensitivity of DNNs that are trained for the task of object detection to FRIs, like sensitivity of R-CNN to FRIs. In this case augmenting training data with crops of small FRI sizes can be properly done since ground-truth bounding boxes can determine which region is foreground and which region is background. ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting progress in measuring the fragility of deep neural network based recognition.",
            "review": "This paper is a more thorough follow-up to e a previous work by Ullman et al that was comparing minimally recognizable patches by humans compared to deep neural network. This paper exhibits that a wide range of architectures features the same fragility and that these effects can combated by better training methodology and different pooling architectures. Still even with those changes deep CNNs still posses more fragile behavior than human vision. One of my criticism is that human vision is kind of different: it makes multiple passes over the same images at multiple scales, so this might contribute significantly to these differences. Still this paper makes a lot of interesting observations and analyses and represents a first methodological study of this phenomenon.\n\nA novelty of this work is that it is the first paper that methodologically analyses FRIs for DNNs a reasearch area which might shed new light on the understanding of how vision systems work and the source of misrecognitions and the limitations of recognition systems.\n\nIn light of the changes of the paper and the clarification on the novelty aspect of this research, I suggest this paper to be accepted as it constitutes novel research in understanding how DNNs recognize image content and its similarities and differences to human vision.\n\n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "ok paper; an important question on upscaling image crops",
            "review": "Thanks the authors for an interesting work!\nThe paper studies the differences between human and DNN vision via means of minimal images (i.e. smallest image crops that can be correctly classified).\n\nThere are a few notable take-away messages:\n1. DNNs are not invariant to even tiny (1-2 px) translations of small image crops.\n    - It would be more insightful if authors added comparison between DNN sensitivity to tiny translations of small image crops vs. full-size images (i.e. translation-based adversarial examples https://openreview.net/forum?id=BJfvknCqFQ ).\n2. The smaller the image crops, the more sensitive DNNs become (here, more FRIs)\n3. DNNs and human vision misclassify the image crops differently: (1) DNNs have almost twice more FRI(s) and (2) FRIs of human and DNNs differ in location.\n\nQuestions:\n\n- \"After extracting the region from the image, the region is resized to be of the size required by the network.\"\nWould upscaling say a small 28x28 crop into 224x224 image here naturally negatively impact the DNN predictive performance?\nThat is, because typically image classifiers are trained on one (or a few) fixed resolution(s) of images.\n\nOne hypothesis here is that fragile recognition may be because the test image resolution does not match the training image resolution.\nHuman on the other hands, have been trained on images of variable resolutions.\n\nAn alternative to upscaling here is to zero-pad the crop region. Can you help us understand your choice of upscaling here?\n\n+ Originality\nThe originality is limited as it is a close extenstion work of Ullman et al. 2016\n\n+ Clarity\nThe paper is well written and presented.\n\n+ Significance\nThis work extends our understanding of the differences between DNNs and human vision.\nHowever, given what we learned from the adversarial example research area, the contribution of this work is low because results might not be too surprising.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}