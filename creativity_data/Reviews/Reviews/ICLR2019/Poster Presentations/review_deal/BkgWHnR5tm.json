{
    "Decision": {
        "metareview": "Lean in favor\n\nStrengths:  The paper tackles the difficult problem of automatic robot design. The approach uses graph neural\nnetworks to parameterize the control policies, which allows for weight sharing / transfer to new policies even\nas the topology changes.  Understanding how to efficiently explore through non-differentiable changes to the body\nis an important problem (AC). The authors will release the code and environments, which will be useful in an area where there are \ncurrently no good baselines (AC). \n\nWeaknesses: There are concerns (particularly R2, R1) over the lack of a strong baseline, and with the results \nbeing demonstrated on a limited number of environments (R1)  (fish, 2D walker). In response, the authors clarified the nomenclature and\ndescription of a number of the baselines, and added others. AC: there is no submitted video (searches for \"video\" on the PDF text\nproduces no hits); this is seen by the AC as being a real limitation from the perspective of evaluation. \nAC agrees with some of the reviewer remarks that some of the original stated claims are too strong.\n  AC: the simplified fluid model of Mujoco (http://mujoco.org/book/computation.html#gePassive) is\nunable to model the fluid state, in particular the induced fluid vortices that are responsible for a\ngood portion of fish locomotion, i.e., \"Passive and active flow control by swimming fishes and\nmammals\" and other papers. Acknowledging this kind of limitation will make the paper stronger, not weaker;\nthe ML community can learn from much existing work at the interface of biology and fluid mechancis.\n\nThere remain points of contention, i.e., the sufficiency of the baselines. However, the reviewers R2 and R3 have\nnot responded to the detailed replies from the authors, including additional baselines (totaling 5 at present) \nand pointing out that baselines such as CMA-ES (R2) in a continuous space and therefore do not translate in any obvious way\nto the given problem at hand.  \n\nOn balance, with the additional baselines and related clarifications, the AC feels that this paper makes a \nuseful and valid contribution to the field, and will help establish a benchmark in an important area.\nThe authors are strongly encouraged to further state caveats and limitations, and to emphasize why some\ncandidate baseline methods are not readily applicable.\n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "borderline, but lean in favor"
    },
    "Reviews": [
        {
            "title": "Interesting approach, inconclusive experiments",
            "review": "This paper proposes an approach for automatic robot design based on Neural graph evolution.\nThe overall approach has a flavor of genetical algorithms, as it also performs evolutionary operations on the graph, but it also allows for a better mechanism for policy sharing across the different topologies, which is nice.\n\nMy main concern about the paper is that, currently, the experiments do not include any strong baseline (the ES currently is not a strong baseline, see comments below). \nThe experiments currently demonstrate that optimizing both controller and hardware is better than optimizing just the controller, which is not surprising and is a phenomenon which has been previously studied in the literature.\nWhat instead is missing is an answer to the question: Is it worth using a neural graph? what are the advantages and disadvantages compared to previous approaches?\nI would like to see additional experiments to answer this questions.\n\nIn particular, I believe that any algorithms you compare against, you should optimize both G and theta, since optimizing purely the hardware is unfair.\nYou should use an existing ES implementation (e.g., from some well-known package) instead of a naive implementation, and as additional baseline also CMA-ES. \nIf you can also compare against one or two algorithms of your choice from the recent literature it would also give more value to the comparison.\n\nDetailed comments:\n- in the abstract you say that \"NGE is the first algorithm that can automatically discover complex robotic graph structures\". This statement is ambiguous and potentially unsupported by evidence. how do you define complex? that can or that did discover?\n- in the introduction you mention that automatic robot design had limited success. This is rather subject, and I would tend to disagree.  Moreover, the same limitations that apply to other algorithms to make them successful, in my opinion, apply to your proposed algorithm (e.g., difficulty to move from simulated to real-world).\n- The digression at the bottom of the first page about neural architecture search seem out of context and interrupts the flow of the introduction. What is the point that you are trying to make? Also, note that some of the algorithms that you are citing there have indeed applied beyond architecture search, eg. Bayesian optimization is used for gait optimization in robotics, and Genetic algorithms have been used for automatic robot design.\n- The stated contributions number 3 and 5 are not truly contributions. #3 is so generic that a large part of the previous literature on the topic fall under this category -- not new. #5 is weak, and tell us more about the limitations of random search and naive ES than necessarily a merit of your approach. \n- Sec 2.2: \"(GNNs) are very effective\" effective at what? what is the metric that you consider?\n- Sec 3 \"(PS), where weights are reused\" can you already go into more details or refer to later sections?\n- First line page 4 you mention AF, without introducing the acronym ever before.\n- Sec 3.1: the statements about MB and MF algorithms are inaccurate. Model-based RL algorithms can work in real-time (e.g. http://proceedings.mlr.press/v78/drews17a/drews17a.pdf) and have been shown to have same asymptotic performance of MB controllers for simple robot control (e.g. https://arxiv.org/abs/1805.12114) \n- \"to speed up and trade off between evaluating fitness and evolving new species\" Unclear sentence. speed up what? why is this a trade-off?\n- Sec 3.4 can you recap all the parameters after eq.11? going through Sec 3.2 and 2.2 to find them is quite annoying.\n- Sec 4.1:  would argue that computational cost is rarely a concern among evolutionary algorithms. The cost of evaluating the function is typically more pressing, and as a result it is important to have algorithms that can converge within a small number of iterations/generations.\n- Providing the same computational budget seem rather arbitrary at the moment, and it heavily depends from implementation. How many evaluations do you perform for each method? why not having the same budget of experiments?  ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting paper on co-optimizing robot structure and control",
            "review": "This paper discusses the optimization of robot structures, combined with their controllers. The authors propose a scheme\nbased on a graph representation of the robot structure, and a graph-neural-network as controllers. The experiments show\nthat the proposed scheme is able to produce walking and swimming robots in simulation. The results in this paper are impressive, and the paper seems free of technical errors. \n\nThe main criticism I have is that I found the paper harder to read. In particular, the exact difference between the proposed method and the ES baseline is not as clear as it could be. This makes the contribution of this paper in terms of the method\nhard to judge. Please include further description of the ES cost function and algorithm in the main body of the paper.\n\nThe second point is that the proposed approach seems to modify a few things from the ES baseline. The efficacy of the separate modifications should be tested. Therefore I would like to see experiments with the ES cost function, but with\ninclusion of the pruning step, and experiments with the AF-function but without the pruning step.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Direct application of ES with NerveNet for fitness evaluation",
            "review": "[Summary]:\nThis paper tackles the problem of automatic robot design. The most popular approach to doing this has been evolutionary methods which work by evolving morphology of agents in a feed-forward manner using a propagation and mutation rules. This is a non-differentiable process and relies on maintaining a large pool of candidates out of which best ones are chosen with the highest fitness. In robot design for a given task using rewards, training each robot design using RL with rewards is an expensive process and not scalable. This paper uses graph network to train each morphology using RL. Thereby, allowing the controller to share parameters and reuse information across generations. This expedites the score function evaluation improving the time complexity of the evolutionary process.\n\n[Strengths]:\nThis paper shows some promise when graph network-based controllers augmented with evolutionary algorithms. Paper is quite easy to follow.\n\n[Weaknesses and Clarifications]:\n=> Robot design area has been explored extensively in classical work of Sims (1994) etc. using ES. Given that, the novelty of the paper is fairly incremental as it uses NerveNet to evaluate fitness and ES for the main design search.\n=> Environment: The experimental section of the paper can be further improved. The approach is evaluated only in three cases: fish, walker, cheetah. Can it be applied to more complex morphologies? Humanoid etc. maybe?\n=> Baselines: The comparison provided in the paper is weak. At first, it compares to random graph search and ES. But there are better baselines possible. One such example would be to have a network for each body part and share parameters across each body part. This network takes some identifying information (ID, shape etc.) about body part as input. As more body parts are added, more such network modules can be added. How would the given graph network compare to this? This baseline can be thought of a shared parameter graph with no message passing.\n=> The results shown in Figure-4 (Section-4.2) seems unclear to me. As far as I understand, the model starts with hand-engineered design and then finetuned using evolutionary process. However, the original performance of the hand-engineered design is surprisingly bad (see first data point in any plot in Figure-4). Does the controller also start from scratch? If so, why? Also, it is not clear what is the meaning of generations if the graph is fixed, can't it be learned altogether at once?\n\n[Recommendation]:\nI request the authors to address the comments raised above. Overall, this is a reasonable paper but experimental section needs much more attention.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}