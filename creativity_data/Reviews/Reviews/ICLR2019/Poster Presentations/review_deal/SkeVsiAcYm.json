{
    "Decision": {
        "metareview": "This paper proposes to estimate the predecessor state dynamics for more sample-efficient imitation learning. While backward models have been used in the past in reinforcement learning, the application to imitation learning has not been previously studied. The paper is well-written and the results are good, showing clear improvements over GAIL in the presented experiments. The primary weakness of the paper is the lack of comparisons to the baselines suggested by reviewer 1 (a jumpy forward model and a single step predecessor model) to fully evaluate the contribution, and to SAIL and AIRL. Despite these weaknesses, the paper slightly exceeds the bar for acceptance at ICLR.\nThe authors are strongly encouraged to include these comparisons in the final version.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "meta review"
    },
    "Reviews": [
        {
            "title": "interesting idea, but some issues need to be clarified.",
            "review": "This paper studies the problem of matching the state-action distributions of agent and expert demonstrations. In order to address this problem, the authors consider a likelihood treatment comprising a conditional probability (which is estimated from demonstrations) and a state distribution (which is estimated from sampling approximations). \n\nThe authors provide a descent result (i.e., equ. (7)) to estimate the gradient of the logarithmic state distribution. One problem is that it is unclear how the discount factor $\\gamma$ influence this result?\n\nIn addition, in (12), two scaling factors are used, so how to balance these weights?\n\nSpecifically, in (11), it seems the authors are considering the stationary joint state-action distribution, which is different from the state-action distribution generated by the agent on-line, it is suggested to clarify this issue.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good Results But Relevant Literature is missing.",
            "review": "The paper proposes to use predecessor models for imitation learning to overcome the issue of only observing expert samples during imitation from expert trajectories.\n\nThe paper is very well written. But the proposed method is really not novel. The idea of using predecessor models have already been explored in multiple places [1], [2] (but not in imitation learning scenario!). Hence, the novelty comes from using the predecessor models for imitation learning. The introduction of the paper should mention this  to reflect the contribution. \n\n[1] Recall Traces: Efficient Backtracking models for efficient RL https://arxiv.org/abs/1804.00379\n[2] Organizing Experience: A Deeper Look at Replay Mechanisms for Sample-based Planning in Continuous State Domains\nhttps://arxiv.org/abs/1806.04624\n\nBoth of these papers should be cited and discussed.\n\nResults: The proposed method outperforms GAIL and behaviour cloning in terms of sample efficiency   on simulation-based manipulation tasks.\n\nRegarding experiments, I would like to see certain baselines.\n\n- What happens when you predict sequentially using predecessor models ? I understand that the sequential generation is prone to accumulating errors, but as [1] points out, using predecessor models you can sample from many states on the expert trajectory. And Hence possible to get good learning signal even while sampling shorter trajectories using predecessor models.\n\n- Comparison with Dyna based methods. For this baseline, authors would learn a forward model. And then sample from the forward model, and use the samples from the forward model for imitation learning.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Compelling, sample efficient approach to imitation learning using learned dynamics models. Experiments could be extended.",
            "review": "The submission builds up on recent advances in neural density estimation to develop a new algorithm for imitation learning based on a probabilistic model for predecessor state dynamics. In particular, the method trains masked autoregressive flows as a probabilistic model for state action pairs conditioned on future states. This model is used to estimate the gradient of the stationary distribution of a policies visited states. Finally, the proposed objective uses this estimate and the gradient of the log likelihood of expert actions under the policy to maximise the similarity of the expert’s and agent’s stationary state-action distributions. \n\nThe proposed method outperforms existing imitation learning approach (GAIL & BC) on 2 simulation-based manipulation tasks. It performs particularly well in terms of sample efficiency. \nThe magnitude of difference between the sample efficiencies of GAIL and the proposed approach seems quite surprising and it would be beneficial if the authors could explicitly state if the measured number of samples include the ones used for training of the probabilistic model as well as the policy (apologies if I have missed a section fulfilling this purpose).\n\nWhile the improvements on the presented experiments are clear, the experimental section represents a small shortcoming of the submitted paper. The 2 experiments (clip and peg insertion) are quite similar in type and to not take into account other common domains e.g. locomotion tasks from the original GAIL paper. Furthermore, an additional comparison to SAIL would be recommended since the approaches are closely related as the authors acknowledge. The provided comparison with different types of available expert data is quite interesting and could possibly be extended to test other state-of-the-art methods (action-free versions of GAIL, AIRL,etc.).\n\nNonetheless, the paper overall presents a strong submission based on novelty & relevance of the proposed method and is recommended for publication. \n\nMinor issues:\n- Related work: improve transitions between the section about trajectory tracking and BC.\n- Ablation studies with less flexible probabilistic models would strengthen the experiment section further. \n- Add derivation from Eq. 3 to 4 and 5 to appendix to render the paper more self-contained and easier to access.\n- A release of the code base would further strengthen the contributions of the submission.\n\nGeneral recommendation:\n- The authors are encouraged to further investigate off-policy corrections for improved convergence.\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}