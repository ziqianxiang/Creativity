{
    "Decision": {
        "metareview": "This paper proposes to use meta-learning to design MCMC sampling distributions based on Hamiltonian dynamics, aiming to mix faster on set of problems that are related to the training problems. The reviewers agree that the paper is well-written and the ideas are interesting and novel. The main weaknesses of the paper are that (1) there is not a clear case for using this method over SG-HMC, and (2) there are many design choices that are not validated. The authors revised the paper to address some aspects of the latter concern, but are encouraged to add additional revisions to clarify the points brought up by the reviewers.\nDespite the weaknesses, the reviewers all agree that the paper exceeds the bar for acceptance. I also recommend accept.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "meta review"
    },
    "Reviews": [
        {
            "title": "Well written paper that presents an interesting proof-of-concept for meta-learning MCMC samplers",
            "review": "In the paper \"Meta-Learning for Stochastic Gradient MCMC\", the authors present a meta-learning approach to automatically design MCMC sampler based on Hamiltonian dynamics to mix faster on problems similar to the training problems. The approach is evaluated on simple multidimensional Gaussians, and Bayesian neural networks (including fully connected, convolutional, and recurrent networks).\n\nMCMC samplers in general, and Hamiltonian Monte Carlo sampler in particular, are very powerful tools to perform Bayesian inference in high-dimensional spaces. Combined with stochastic gradients, methods like Stochastic Gradient MCMC (SGMCMC), or Stochastic Gradient Langevin Dynamics (SGLD) have been successfully used to apply these methods in the large data regime, where only noisy estimates of the gradients are feasible. Even though, many different samplers exists, and they are provably correct (meaning they converge to the correct distribution), fast mixing and low auto-correlation within the chain can heavily depend on the problem at hand and the hyperparameters of the sampler used.  The work presented here, uses the general framework for SG-MCMC samplers of Ma et al., parametrizes it with a neural network and learns its weights on representative training problems.\n\nThe paper is well written, although occasional minor mistakes and typos can be found.\nIt seems however, that the method is still quite laborious and some care needs to be taken to train the meta-sampler.\nThe overall narrative is easy to follow, but could benefit from more detail in certain parts. In general, I argue for acceptance of the paper, but have the following questions/comments:\n\n- Below Eq. (7), an interpretation of the parametrizations Q_f and D_f is given. I greatly appreciate this, but the phrase 'Q_f is\nresponsible for the acceleration of \\theta' is not really instructive. By definition, the change in \\theta is mostly driven by the momentum p. Therefor, Q_f looks like an inverse mass (at least in the second line of (7)), but maybe that is not a very helpful analogy either.\n- at the beginning of section 3.2, the term 'particles' is used. While I am fully aware of what that is supposed to mean, a reader less familiar with the topic could be confused, because there is no explanation of it.\n- It is unclear to me how the stochastic estimate \\tilde{U}(\\theta) in equation (10) is computed exactly. Is it estimated using the current mini-batch at time t, or is it estimated using a 'holdout-test set'?\n- I was wondering how the correlation between the chains due to thinning for the In-chain loss affects the results. The text, does not address this at all.\n- The experiments are very thorough and I appreciate the comparison to the tuned baselines, but I am missing some details in the paper:\n     (a) Did you tune the SGHMC method in Figure 2, as well? It is not mentioned in the text, and the sample path looks very volatile, which could indicate a poor combination of step length and noise.\n     (b) How was the tuning of the base line methods performed?\n     (c) Are the results in Figure 3 based on single runs, or do you show the mean over 10 independent runs (as in table 1).\n- The insets in Figure 6 are helpful, but I think you could shrink the 'outer y axis' and have the inset in the top right corner instead. That way, the zoomed-out plot would show more details on its own.\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Very interesting paper but many design choices not validated",
            "review": "TITLE\nMeta-learning for stochastic gradient mcmc\n\nREVIEW SUMMARY\nA wonderful paper with many great ideas and insights. Main weakness is the complexity of the algorithms and many design choices wich are well argued for but not theoretically or empirically well founded.  \n\nPAPER SUMMARY\nThe main idea (based on the result of Ma et al.'s \"complete recipe for stochastic gradient mcmc\") is to parameterize the diffusion and curl matrices by neural networks and (meta-)learn/optimize an sg-mcmc algorithm. \n\nQUALITY\nThe technical quality of the paper appears to be good. Due to the complexity of the algorithm and lack of access to authors code at review time, it is not feasible for me to validate empirical results.\n\nMy main critisism of this work is that the proposed procedure is quite complicated, and there are a lot of steps and design choices that are made in the paper which are not backed up by theory or experiment. For example, the structure and parametrization of D and Q. I would like to have seen e.g. empirical results on full matrices compared to the particular \"diagonal\" struture used, to give an idea of how much we loose by that design choise. Similarly, the choice of meta learning objective is not (to me at least) obvious, and this could be examined further. Also, the use of the Stein gradient estimator is known sometimes to be problematic (maybe particularly with an rbf kernel) but this is not explored.\n\nAll in all, the paper leaves me wanting more, but of course there is only so much space in a conference paper. My conclusion here is that I recommend that the paper is published as it is, and I hope the authors will continue their work in future research (as also outlined in the paper). \n\nCLARITY\nThe paper is clear and well written, notation is consistent, and everything is fairly easy to follow.\n\nORIGINALITY\nThe idea of meta learning sg-mcmc is not something I have seen before, so to my knowledge the idea is original. \n\nSIGNIFICANCE\nI think the whole line of research in which this paper falls has a very high potential, and i strongly welcome any new results. This paper develops new interesting ideas of broad interest.\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Very well written paper, interesting idea, unconvincing experimental results",
            "review": "This paper proposes a novel method to perform meta-learning for stochastic gradient MCMC. They utilize a general family of SDEs that guarantees preservation of the target density with somewhat loose constraint on the drift and diffusion functions (from Ma et al. (2015)). Then, they propose learning these functions on a set of training tasks and evaluating on unseen, different tasks, in a meta-learning fashion.\n\nThis paper is well written and easy to follow. They do a very good job presenting the motivation for their work as well as seminal work in SG-MCMC. The idea is fairly natural, especially in light of recent success of meta-learning and learning optimizers. They do a thorough survey of related work and also do a good job presenting their method in context of very modern work on MCMC and SG-MCMC.\n\nI am not completely convinced by the meta-training objective; both losses seem natural but quite intractable to compute in practice. The use of Stein indicates that the kernel must probably be *very* carefully crafted and given that the whole method relies on this objective, it seems like this could be a breaking point. I am also curious to know how you diagnostic/evaluate the choice of these kernels.\n\nIn terms of evaluation, the experimental results are not the most convincing given that across the board, they are (except in one case) in 4 case within 0.2% of SGHMC and in the two others, within 0.5% and 0.8% respectively. This seems a bit weak, especially considering the compute invested both at training time and for each SG-MCMC step (i.e. getting the outputs from the neural networks vs simply doing HMC). Is there really a case for using the method over SG-HMC? I would have also very much liked to see a run-time evaluation.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}