{
    "Decision": {
        "metareview": "After discussion, all reviewers agree to accept this paper. Congratulations!!",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Meta-Review for DyRep paper"
    },
    "Reviews": [
        {
            "title": "An interesting idea which could use clearer theoretical justification and larger scale experimental validation.",
            "review": "Overall the paper suffers from a lack of clarity in the presentation, especially in algorithm 1, and does not communicate well why the assumption of different dynamical processes should be important in practice. Experiments show some improvement compared to (Trivedi et al. 2017) but are limited to two datasets and it is unclear to what extend end the proposed method would help for a larger variety of datasets. \n\nNot allowing for deletion of node, and especially edges, is a potential draw-back of the proposed method, but more importantly, in many graph datasets the type of nodes and edges is very important (e.g. a knowledge base graph without edges loses most relevant information) so not considering different types is a big limitation. \n\nComments on the method (sections 2-4).\n\nAbout equation (1):\n \\bar{t} is not defined and its meaning is not obvious. The rate of event occurrence does not seem to depend on l (links status) whereas is seems to be dependent of l in algorithm 1. \n\nI don’t see how the timings of association and communication processes are related, both \\lambda_k seem defined independently. Should we expect some temporal dependence between different types of events here? The authors mention that both point processes are “related through the mediation process and in the embedding space”, a more rigorous definition would be helpful here. \n\nThe authors claim to learn functions to compute node representations, however the representations z^u seem to be direct embeddings of the nodes. If the representations are computed as functions it should be clear what is the input and which functional form is assumed.\n\nI find algorithm 1 unclear and do not understand how it is formally derived, its justification seems rather fuzzy. It is also unclear how algorithm 1 relates to the loss optimisation presented in section 4. \n\nWhat is the mechanism for addition of new nodes to the graph? I don’t see in algorithm 1 a step where nodes can be added but this might be handled in a different part of the training. \n\nComments on the experiments section.\n\nSince the proposed method is a variation on (Trivedi et al. 2017), a strong baseline would include experiments performed on the same datasets (or at least one dataset) from that paper. \n\nIt is not clear which events are actually observed. I can see how a structural change in the network can be observed but what exactly constitutes a communication event for the datasets presented?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Marked Point Process extension of (Trivedi et al., 2017)",
            "review": "Overall, the contribution of the paper is somewhat limited [but a little more than my initial assessment, thanks to the rebuttal]. It is essentially an extension of (Trivedi et al. 2017), adding attention to provide self-exciting rates, applied to two types of edges (communication edges and “friendship” edges). Conditioned on past edges, future edges are assumed independent, which makes the math trivial. The work would be better described as modeling a Marked Point Process with marks k \\in {0,1}.\nOther comments:\n1.\t[addressed] DyRep-No-SP is as good as the proposed approach, maybe because the graph is assumed undirected and the embedding of u can be described by its neighbors (author rebuttal describes as Localized Propagation), as the neighbors themselves use the embedding of u for their own embedding (which means that self-propagation is never \"really off\"). Highly active nodes have a disproportional effect in the embedding, resulting in the better separated embeddings of Figure 4. [after rebuttal: what is the effect of node activity on the embeddings?]\n2.\t[unresolved, comment still misundertood] The Exogenous Drive W_t(t_p – t_{p−1}) should be more personalized. Some nodes are intrinsically more active than others. [after rebuttal: answer \"$W_t(t_p - t_{p-1})$ is personalized as $t_p$ is node specific\", I meant personalized as in Exogenous Drive of people like Alice or Bob]\n3.\t[unresolved] Fig 4 embeddings should be compared against (Trivedi et al. 2017) [after rebuttal: author revision does not make qualitative comparison against Trivedi et al. (2017)]\n\nBesides the limited innovation, the writing needs work. \n4.\t[resolved] Equation 1 defines $g_k(\\bar{t})$ but does not define \\bar{t}. Knowing (Trivedi et al. 2017), I immediately knew what it was, but this is not standard notation and should be defined. \n5.\t[resolved] $g_k$ must be a function of u and v\n6.\t[resolved] “$k$ represent the dynamic process” = >  “$k$ represent the type of edge” . The way it is written $k$ would need to be a stochastic process (it is just a mark, k \\in {0,1})\n7.\t[resolved] Algorithm 1 is impossibly confusing. I read it 8 times and I still cannot tell what it is supposed to do. It contains recursive definitions like $z_i = b + \\lambda_k^{ji}(t)$, where $\\lambda_k^{ji}(t)$ itself is a function of $z_i(t)$. Maybe the z_i(t) and z_i are different variables with the same name?\n8.\t[resolved] The only hint that the graph under consideration is undirected comes from Algorithm 1, A_{uv}(t) = A_{vu}(t) = 1. It is *very* important information for the reader.\nRelated work (to be added to literature):\nDynamic graph embedding: (Yuan et al., 2017) (Ghassen et al., 2017)\nDynamic sub-graph embedding: (Meng et al., 2018)\n\nMinor:\nstate-of-arts => state-of-the-art methods\nlist enumeration “1.)” , “2.)” is strange. Decide either 1) , 2) or 1. , 2. . I have never seen both.\nMAE => mean absolute error (MAE)\n\nYuan, Y., Liang, X., Wang, X., Yeung, D. Y., & Gupta, A., Temporal Dynamic Graph LSTM for Action-Driven Video Object Detection. ICCV, 2017.\nJerfel,  , Mehmet E. Basbug, and Barbara E. Engelhardt. \"Dynamic Collaborative Filtering with Compound Poisson Factorization.\" AISTATS 2017. \nMeng, C., Mouli, S.C., Ribeiro, B. and Neville, J., Subgraph Pattern Neural Networks for High-Order Graph Evolution Prediction. AAAI 2018.\n\n--- --- After rebuttal \n\nAuthors addressed most of my concerns. The paper has merit and would be of interest to the community. I am increasing my score.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "This paper presents a dynamic graph embedding method, which considers two types of dynamics in evolving networks: association events with node and edge grows, and communication events with node-node interactions.     ",
            "review": "The paper is very well written. The proposed approach is appropriate on modeling the node representations when the two types of events happen in the dynamic networks. Authors also clearly discussed the relevance and difference to related work. Experimental results show that the presented method outperforms the other baselines.\nOverall, it is a high-quality paper. \nThere are only some minor comments for improving the paper:\nν\tPage 6, there is a typo. “for node v by employing …”  should be “for node u”\nν\tPage 6, “Both GAT and GaAN has”   should be  “Both GAT and GaAN have”\nν\tIn section 5.1, it will be great if authors can explain more what are the “association events” and “communication events” with more details in these two evaluation datasets.\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}