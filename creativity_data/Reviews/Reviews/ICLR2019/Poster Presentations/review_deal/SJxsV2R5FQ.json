{
    "Decision": {
        "metareview": "pros:\n- the paper is well-written and precise\n- the proposed method is novel\n- valuable for real-world problems\n\ncons:\n- Reviewer 2 expresses some concern about the organization of the paper and over-generality in the exposition\n- There could be more discussion of scalability",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "Good paper and valuable direction"
    },
    "Reviews": [
        {
            "title": "Learning sparse relational transition models",
            "review": "In the manuscript \"Learning sparse relational transition models\", the authors combine neural nets with relational models, using ideas from linguistics. They apply this to learning the representations of the space in which a simulated robot operates in a reinforcement learning ML paradigm. This work is of interest to the AI community and ICLR is a good venue for this work.\n\nThe authors apply their model in particular to a problem in which the simulated robot must rearrange objects in space, and they achieve reasonable accuracy.\n\nMajor points:\n\n- Organisationally, I thought that the authors could have gotten to the loss function sooner, as much of the development of the theory is lacking in motivation until specific tasks are defined.\n\n- The application domain seemed to lose some of the power of the linguistic analysis they were doing to develop the representation through \"properties\" and \"action templates\". These definitions were quite general, but it was unclear if more than a few (with few parameters) were used in the actual application, and so it's unclear that so much generality was required by the application.\n\n- The authors could have compared with more modern deep learning techniques for reinforcement learning such as DeepMimic (Peng et al 2018).\n\nMinor points:\n- Typesetting periods \"Pasula et al. and\" -> \"Pasula et al.\\ and\"\n\n- Page 2: \"value of a note\" -> \"value of a node\"\n\n- 3.1 was hard to follow.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An approach to learn lifted transition rules using neural networks that take advantage of relational structure",
            "review": "An approach is proposed that learns transition rules in terms of local contexts. Specifically, transition rules make predictions as a distribution over the set of possible states based on local context of objects. A learning algorithm is described that learns the transition rules by maximizing the conditional likelihood. To learn the rules jointly with selecting the right samples for the transition rule, and EM algorithm is proposed. \n\nThe paper is well-written. The contribution seems significant considering that relational structure is integrated with neural networks in a systematic manner. Though written from the perspective of learning transition rules for tasks such as robotic manipulation, I think similar ideas can be for general tasks that can benefit from both relational structure and neural network representation.  Learning lifted rules has also been studied in  domains such as ILP and Statistical Relational Learning (Getoor and Taskar 07)(lifted rules with uncertainty). I think including their perspective and commenting on their relationship with the proposed work will be useful.\n\nExperiments are performed on a robotic manipulation task involving pushing a stack of blocks in a cluttered environment. A method that does not take object relations into account and simply predicts the state transition is used as baseline for comparison. The proposed approach shows the benefits of exploiting the structure between objects. There is not too much discussion on scalability. Does the propose method scale up for learning transition rules in real tasks? Are there any tradeoffs involved, etc. would be good to know.\nIn summary, this seems to be a well-written and novel contribution.",
            "rating": "7: Good paper, accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "L EARNING SPARSE RELATIONAL TRANSITION MODELS",
            "review": "\nSUMMARY:\nThis work is about learning state-transition models in complex domains represented as sets of objects, their properties, ``\"deictic\" reference functions between sets of objects, and possible actions (or action templates). A parametric model for the actions is assumed, and these parameters act on a neural net that learns the transition model (probabilistic rule) from the current state to the next one.  It is basically this nonlinear transition model implemented by a network which makes this work different from previous models described in the literature. The relational transition model proposed is sparse, based on the assumption that actions have only ``local effects on related objects. The prediction model itself is basically a Gaussian distribution whose mean and variances are represented by neural nets. For jointly learning multiple rules, a clustering strategy is presented which assigns experience samples to transition rules. The method is applied to simulated data in the context of predicting pushing stacks of blocks on a cluttered table top.\n\nEVALUATION: \nThe type of problems addressed in this paper is challenging and highly relevant for solving problems in the ``real'' world. Although the method proposed is in some sense a direct generalization of the work in [Pasula et al.], it still contains many novel and interesting aspects.Any single part of the model (like the use of Gaussians parametrized by functions implemented via neural nets) is somehow ``standard in deep latent variable models, but in complex real-world rule-learning problems the whole system presented  defines  certainly a big improvement over the state-of-the-art, which in my opinion has the potential to indeed advance this field of research.     \n ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}