{
    "Decision": {
        "metareview": "The reviewers viewed the work favorably, with only one reviewer providing a score slightly below acceptance. The authors thoroughly addressed the reviewer's original concerns, and they adjusted their score upwards afterwards. The low-rating reviewer remains skeptical of the significance of the work, but the other two reviewers make firm cases for the appeal of the work to the ICLR audience. In follow-up discussion after the author's responses were submitted and discussed, the low-rating reviewer did not make a clear case for rejecting the paper, and further, the higher-rating reviewers' arguments for the impact of the paper were convincing. Therefore, I recommend accepting this paper.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Reviewer consensus is accept"
    },
    "Reviews": [
        {
            "title": "Interesting well done paper",
            "review": "Following the suggested rubric:\n1. Briefly establish your personal expertise in the field of the paper.\n2. Concisely summarize the contributions of the paper.\n3. Evaluate the quality and composition of the work.\n4. Place the work in context of prior work, and evaluate this work's novelty.\n5. Provide critique of each theorem or experiment that is relevant to your judgment of the paper's novelty and quality.\n6. Provide a summary judgment if the work is significant and of interest to the community.\n\n1.  I work at the intersection of machine learning and biological vision\nand have worked on modeling word representations.\n\n2. This paper develops a new representation system for object\nrepresentations from training on data collected from odd-one-out human\njudgements of images.  The vector representation for objects is\ndesigned to be sparse and low dimensional (and ends up being about\n49D).  Similarity is measured by dot products in the space and\nprobabilities of which pair of items will be paired are modeled as the\nexponential of the similarity.\n\n\n3,5  The resulting embedding\tdoes a good job\tof predicting human similarity\njudgements and seems to cover similar features to those named by\nhumans.  They also explain typicality judgements and cluster semantic\ncategories well.   The creation of the upper limit based on noise between \nand within subjects was a nice addition.\n\n\n4. Some relevant related work is discussed and this seems like a novel\nand interesting contribution.  The authors might also want to compare\nto similar work that looked at similarities among triplets (Similarity\nComparisons for Interactive Fine-Grained Categorization\nhttp://ttic.uchicago.edu/~smaji/papers/similarity-cvpr14.pdf;\nConditional Similarity Networks https://arxiv.org/abs/1603.07810 ).\n\n\n6. While this paper is not especially surprising or ground breaking, the\nnumber and quality of the comparisons make it a worthwhile\ncontribution and the resulting embeddings are worth further exploration\nand could be very useful for future research.\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting paper",
            "review": "This is an interesting paper with a new approach to learn a sparse, positive (and hence interpretable) semantic space that maximizes human similarity judgements, by training to specifically maximize the prediction of human similarity judgements. The authors have collected the dataset themselves and have rating of sets of 3 objects from 1854 unique objects. They end up with a space (SPoSE) with relatively low dimensionality with respect to usual word embeddings (49 dimension) but perhaps not surprising when considering the small size of the words to embed. The authors run a set of experiment to show the usefulness of SPoSE. The most interesting one is the prediction of its dimensions by the CSLB features, which reveals a nice clustering in the different SPoSE dimensions. Perhaps the results would be a little more convincing if additional common word embeddings were also tested.\n\nDue to the different objects used in the different datasets, some of the experiments have a smaller set of words. A good extension of this work would be to combine a text-derived embedding  or the synsets to interpolate the SPoSE dimensions for missing words in the original set. Or perhaps the object similarity ratings could be used in a semi-supervised setting to inform the learning of a co-occurence word embedding. This will allow the model to better describe a larger set of words. Another possible extension is to test this larger set of words on a non-behavioral NLP task to show possible improvements that the behavioral data and the interpretable space give.\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Behavioral experiment on human representations - Manuscript has improved -revison",
            "review": "This is a paper that communicates a large scale experiment on human object/semantic representations and a model of such representations.   The experiment could have been more carefully controlled (and described in the paper) and the modeling work is inconclusive.\n\nQuality, \nThe experiment design is conventional, based on rating pair-wise similarity among triplets. Compared to earlier experiments, this data has more objects and more triplets.  Additional control experiments on smaller subsets have been carried out to further address hypotheses.  The description of the experiment could have been more careful: What are the precise instructions, how are the object/images presented (it is well known that relative positions, asymmetry, etc can play an important role), are there any temporal/learning effects (how clear is the task to the workers?).\nThe modeling work is basic and contains a number of steps that have unknown influence on the final outcome. For example model dimension: Is you claim that \"D=49\" is a law of human nature?  Model predictive performance seems excellent, that is interesting! But we do not know how robust this is to the many heuristics\n\nClarity, \nThe presentation of the inference process is clear. Not so clear what the uncertainties are\n\nOriginality \nLimited. Mainly related to scale. But the data quality is unclear. The modeling approach involves a number of untested heuristics (non-negative, exponentiation etc). \n\nSignificance \nMostly related to the data.  I did not understand if it is planned to release the data.\n\nPros and cons \n\n+Large scale experiment\n+simple model, seem to have good accuracy\n\n-experiment needs more careful description\n-too many heuristics in model and inference, unclear how general the conclusions are\n\nOther comments:\nReferences have many issues\n\nThe authors have done a good job in the revision and have clarified points that were unclear in the first version. \nI have remaining reservations on significance, but move rating up a notch to reflect the extensive improvements and  the authors' confirmation that they will release the data.\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}