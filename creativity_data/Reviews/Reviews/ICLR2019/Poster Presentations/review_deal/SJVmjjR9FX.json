{
    "Decision": {
        "metareview": "The reviewers lean to accept, and the authors clearly put a significant amount of time into their response. I will also lean to accept. However, the comments of reviewer 2 should be taken seriously, and addressed if possible, including an attempt to cut the paper length down.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "Meta-Review for Phylogenetic Inference paper"
    },
    "Reviews": [
        {
            "title": "New approximate inference approaches for phylogenetic trees",
            "review": "This paper explores an approximate inference solution to the challenging problem of Bayesian inference of phylogenetic trees. Its leverages recently proposed subsplit Bayesian networks (SBNs) as a variational approximation over tree space and combines this with modern gradient estimators for VI. It is thorough in its evaluation of both methodological considerations and different datasets.\n\nThe main advantage would seem to be a large speedup over MCMC-based methods (Figure 4), which could be of significant value to the phylogenetics community. This point would benefit from more discussion. How do the number of iterations (reported in Figures 3&4, which was done carefully) correspond to wallclock time? Can this new method scale to numbers of sites and sequences that were previously unfeasible?\n\nThe main technical contribution is the use of SBNs as variational approximations over tree-space, but it is difficult to follow their implementation and parameter sharing without the explanation of the original paper. Additionally, the issue of estimating the support of the subsplit CPTs needs more discussion. As the authors acknowledge, complete parameterizations of these models scale in a combinatorial way with “all possible parent-child subsplit pairs”, and they deal with this by shrinking the support up front with various heuristics. It seems that these support estimation approaches would be feasible when the data are strong but would become challenging to scale when the data are weak. Since VB is often concerned with the limited-data regime, more discussion of when support estimation is feasible and when it is difficult would clarify how widely applicable the method is.\n\nOverall, this work is an interesting extension of variational Bayes to a tree-structured inference problem and is thorough in its evaluation. While it is a bit focused on classical inference for ICLR, it could be interesting both for the VI community and as a significant application advancement.\n\nOther notes:\nIn table 1, is the point that all methods are basically the same with different variance? This is not clear from the text. What about the variational bounds?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A nice approach to inferring phylogenetic trees",
            "review": "This paper proposes a variational approach to Bayesian posterior inference in phylogenetic trees. The novel part of the approach (using subsplit Bayesian networks as a variational distribution) is intelligently combined with recent ideas from the approximate-inference literature (reweighted wake-sleep, VIMCO, reparameterization gradients, and multiple-sample ELBO estimators) to yield what seems to be an effective approach to a very hard inference problem.\n\nMy score would be higher were it not for two issues:\n* The paper is 10 pages long, and I'm not convinced it needs to be. The reviewer guidelines (https://iclr.cc/Conferences/2019/Reviewer_Guidelines) say that \"the overall time to read a paper should be comparable to that of a typical 8-page conference paper. Reviewers may apply a higher reviewing standard to papers that substantially exceed this length.\" So I recommend trying to cut it down a bit during the revision phase.\n* The empirical comparisons are all likelihood/ELBO-based. These metrics are important, but it would be nice to see some kind of qualitative summary of the inferences made by different methods—two methods can produce similar log-likelihoods or KL divergences but suggest different scientific conclusions.\n\nOne final comment: it's not clear to me that ICLR is the most relevant venue for this work, which is purely about Bayesian inference rather than deep learning. This isn't a huge deal—certainly there's plenty of variational inference at ICLR these days—but I suspect many ICLR attendees may tune out when they realize there aren't any neural nets in the paper.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A novel well executed paper",
            "review": "This paper is well written, appears to be well executed, and the results look good. I am not particularly well informed about the area, but the work appears to be novel. MCMC for phylogenetic inference is hugely expensive, and anything we can do to reduce that cost would be beneficial (the computational expense is not given, or I've missed it, for the variational approach - presumably it is relatively small compared to MCMC?).\n\nMy main criticism is that I found the details of subsplit Bayesian networks difficult to follow. Googling them suggests they are a relatively new model, which has not been well studied or used (there are no citations of the paper that introduces them for example!). The paper would be stronger if it discussed these in more detail - how close can they come to approximating the models usually used in phylogenetic analyses? Often the inferred phylogeny is itself of interest - how similar are the trees inferred here to those found from MrBayes?",
            "rating": "7: Good paper, accept",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        }
    ]
}