{
    "Decision": {
        "metareview": "This work presents a method to model embeddings as distributions, instead of points, to better quantify uncertainty. Evaluations are carried out on a new dataset created from mixtures of MNIST digits, including noise (certain probability of occlusions), that introduce ambiguity, using a small \"toy\" neural network that is incapable of perfectly fitting the data, because authors mention that performance difference lessens when the network is complex enough to almost perfectly fit the data. \n\nReviewer assessment is unanimously accept, with the following points:\n\nPros:\n+ \"The topic of injecting uncertainty in neural networks should be of broad interest to the ICLR community.\"\n+ \"The paper is generally clear.\"\n+ \"The qualitative evaluation provides intuitive results.\"\n\nCons:\n- Requirement of drawing samples may add complexity. Authors reply that alternatives should be studied in future work.\n- No comparison to other uncertainty methods, such as dropout. Authors reply that dropout represents model uncertainty and not data uncertainty, but do not carry out an experiment to compare (i.e. sample from model leaving dropout activated during evaluation).\n- No evaluation in larger scale/dimensionality datasets. Authors mention method scales linearly, but how practical or effective this method is to use on, say, face recognition datasets, is unclear.  \n\nAs the general reviewer consensus is accept, Area Chair is recommending Accept; However, Area Chair has strong reservations because the method is evaluated on a very limited dataset, with a toy model designed to exaggerate differences between techniques. Essentially, the toy evaluation was designed to get the results the authors were looking for. A more thorough investigation would use more realistic sized network models on true datasets.  ",
        "confidence": "2: The area chair is not sure",
        "recommendation": "Accept (Poster)",
        "title": "Point embeddings changed to distribution embeddings to model uncertainty. "
    },
    "Reviews": [
        {
            "title": "Modelling Uncertainty with Hedged Instance Embeddings",
            "review": "# Summary\nPaper proposes an alternative to current point embedding and a technique to train them. Point embedding are conventional embedding where an input x is deterministically mapped to a vector in embedding space.\n\ni.e         f(x) = z where f may be a parametric function or trained Neural network.\n\nNote that this point embedding means that every x is assigned a unique z, this might be an issue in cases where x is confusing for example if x is an image in computer vision pipeline then x may be occluded etc. In such cases paper argues that assigning a single point as embedding is not a great option.\n\nPaper says that instead of assigning a single point it's better to assign smear of points (collection of points coming from some distributions like Gaussian and mixture of Gaussian etc) \n\nThey provide a technique based on variational inference to train the network to produce such embeddings. They also propose a new dataset made out of MNIST to test this concept.\n\n# Concerns\n\nAlthough they have results to back up their claim on their proposed dataset and problem. They have not compared with many existing uncertainty methods like dropout. (But I’m not sure if such a comparison is relevant here)\nUnlike Kendall method or dropout method, hyperparameters here are a pain point for me, i.e how many Gaussians should I consider in my mixture of Gaussian to create the embeddings (results will depend upon that)\nI.e consider the following scenario\nThe first digit is occluded and can be anything 1,2,3,4,5,6,7,8,9,0 should I use only one Gaussian to create my embeddings like they have shown in the paper for this example, or should I choose 10 gaussian each centered about one of the digits, which might help in boosting the performance?\n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Great paper! Could use more uncertainty-measuring application / experiments",
            "review": "pros: The  paper is well-written and well-motivated. It seems like uncertain-embeddings will be a valuable tool as we continue to extend deep learning to Bayesian applications, and the model proposed here seems to work well, qualitatively. Additionally the paper is well-written, in that every step used to construct the loss function and training seem well motivated and generally intuitive, and the simplistic CNN and evaluations give confidence that this is not a random result. \n\ncons: I think the quantitative results are not as impressive as I would have expected, and I think it is because the wrong thing is being evaluated. It would make the results more  impressive to try to use these embeddings in some active learning framework, to see if proper understanding of uncertainty helps in a task where a good uncertainty measure actually affects the downstream task in a known manner. Additionally, I don't think Fig 5 makes sense, since you are using the embeddings for the KNN task, then measuring correlation between the embedding uncertainty and KNN, which might be a high correlation without the embedding being good. \n\nMinor comments: \n - Typo above (5) on page 3.\n - Appendix line under (12), I think dz1 and dz2 should be after the KL terms.\n\nReviewer uncertainty: I am not familiar enough with the recent literature on this topic to judge novelty. ",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review of \"Modeling Uncertainty with Hedged Instance Embeddings\"",
            "review": "While most works consider embedding as the problem of mapping an input into a point in an embedding space, paper 1341 considers the problem of mapping an input into a distribution in an embedding space. Computing the matching score of two inputs (e.g. two images) involves the following steps: (i) assuming a Gaussian distribution in the embedding space, computing the mean and standard deviation for each input, (ii) drawing a set of samples from each distribution, (3) computing the normalized distances between the samples and (iv) averaging to obtain a global score.\n\nThe proposed approach is validated on a new benchmark built on MNIST.\n\nOn the positive side:\n-\tThe topic of injecting uncertainty in neural networks should be of broad interest to the ICLR community.\n-\tThe paper is generally clear.\n-\tThe qualitative evaluation provides intuitive results.\n\nOn the negative side:\n-\tThe whole idea of drawing samples to compute the distance between two Gaussian distributions seems unnecessarily complicated. Why not computing directly a distance between distributions? There exist kernels between distributions, such as the Probability Product Kernel (PPK). See Jebara, Kondor, Howard “Probability product kernels”, JMLR’04. The PPK between two distributions p(x) and q(x) writes as: \\int_x p^a(x) q^a(x) dx, where a is a parameter. When a=1, it is known as the Expected Likelihood Kernel (ELK). When a=1/2, this is known as the Hellinger or Bhattacharyya kernel (BK). In p and q are Gaussian distributions, then the PPK can be computed in closed form. If p and q are mixtures of Gaussians, then the ELK can be computed in closed form. \n-\tThe Mixture of Gaussians embedding extension is lacking in details. How does the network generate C Gaussian distributions? By having 2C output branches generating C means and C standard deviation vectors? \n-\tIt might be useful to provide more details about why the self-similarity measure makes sense as an uncertainty measure. In its current state, the paper does not provide much intuition and it took me some time to understand (I actually understood when I made the connection with the ELK). Also, why not using a simpler measure of uncertainty such as the trace of the covariance matrix?\n-\tThe experiments are lacking in some respects:\no\tIt would be useful to report results without the VIB regularization.\no\tThe focus on the cases D=2 and D=3 (embedding in a 2D or 3D space) shades some doubt on the practical usefulness of this framework in a higher-dimensional case.\n\nMiscellaneous:\n-\tIt seems there is a typo between equations (4) and (5). It should write z_1^{(k_1)} \\sim p(z_1|x_1)\n\n--- \n\nIn their rebuttal, the authors satisfyingly addressed my concerns. Hence, I am upgrading my overall rating.\n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}