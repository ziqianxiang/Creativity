{
    "Decision": {
        "metareview": "This paper argues that each layer of a network may have some channels useful for and some not useful for transfer learning. The main contribution is an approach which identifies the useful channels through an attention based mechanism. The reviewers agree that this work offers a valuable new approach that offers modest improvements over prior work. \n\nThe authors should take care to refine their definition of behavior regularization, including/expanding on the discussion from the rebuttal phase. The authors are also encouraged to experiment with other architecture backbones and report both overall performance as well as run time for learning with the larger models. \n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "An interesting approach to transfer learning by focusing on relevant channels"
    },
    "Reviews": [
        {
            "title": "main contributions: bringing in the concept from teacher-student, same task to different task in transfer learning by modifying the weights of outer layers",
            "review": "Summary\nThe paper describes using the technique of modifying the weights for the outer layers, used in teacher-student network for same task, to transfer learning for different tasks by modifying the loss function and pre-training using target network labels to emphasize the neurons that are considered important for prediction. The technique seems to be no more/slightly better than the Lsquare SP, but exceeds when used with attention.\n\nImprovements\n- the amount of training time needed to pre-train using the L-square FE and target labels should be mentioned as it seems that for large network, and large data, this can be a factor\n- The choice of Resnet, at least one of the more recent networks for object detection (Inception, YOLO etc.)  would be a good add",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting approach but not yet clearly demonstrating a significant boost in performance",
            "review": "Authors present a new regularisation approach named DELTA (Deep Learning Transfer using feature map with attention). What it does is preserving the outer layer outputs of the target network (in a transfer learning scenario) instead of constraining the weights of the neural network. I am not sure how this approach helps preserve the semantics. Authors state that the distance between source/target networks is characterised by DELTA using their outer layer outputs. This distance is then used in the loss function and through back-propagation incorporates knowledge from the source network. The results demonstrate some marginal improvement in the datasets used when compared with L^2 and L^2-SP.\nMore importantly I think the paper needs some attention in its format as the concepts are not very clear. It has some elements of novelty but not yet there.\n\nAuthors have addressed most of my issues and hence I have revised my decision.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper proposes a normalization procedure improving transfer learning by considering together the output layers of the source and target deep nets. The contribution is rather limited, the experiments are reasonable but not always complete, the use of language satisfactory but can be improved. ",
            "review": "This is a reasonable paper based on a simple intuition. The authors have noticed that some of the state of the art methods (they use Li et al - ICML18 as the main reference) are using only some simple normalization for improving the transfer learning and as such they propose preserving the outer layer output of the target network and aligning it with the one of the source network. On top of that they also propose modeling the difference of feature maps considering an attention mechanism obtain through supervised learning. \n\nThe idea in itself is interesting and valuable. However, I have had some difficulty in understanding precisely how the \"behavior\" is really regularized. While I understand what is depicted in Figure 1 I'm not completely sure this really means that the network behavior is regularized rather than simply correlating the two outputs. In the evaluation, the authors present in Figure 4 some qualitative examples but I would have expected to see some quantitative evaluation of this. I would have liked to see experiments on some larger datasets that are commonly used in computer vision (e.g., Caltech 256 is rather old even if it has been used in Li et al.). The quantitative results in Table 1 and 2 indicate some slight improvement but I'm not completely convinced that this is really significant in the end. The results in Figure 4 tend to show that with the attention mechanism there is a central bias and most of the results tend to be concentrated on the center of the image (in this case the result might also be correct but the examples presented are not too eloquent). \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}