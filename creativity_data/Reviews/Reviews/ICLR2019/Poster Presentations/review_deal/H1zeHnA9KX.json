{
    "Decision": {
        "metareview": "This paper presents experiments showing that a linear mapping existing between the hidden states of RNNs trained to recognise (rather than model) formal languages, in the hope of at least partially elucidating the sort of representations this class of network architectures learns. This is important and timely work, fitting into a research programme begun by CL Giles in 92.\n\nDespite its relatively low overall score, I am concurring with the assessment made by reviewer 1, whose expertise in the topic I am aware of and respect. But more importantly, I feel the review process has failed the authors here: reviewers 2 and 3 had as chief concern that there were issues with the clarity of some aspects of the paper. The authors made a substantial and bona fide attempt in their response to address the points of concern raised by these reviewers. This is precisely what the discussion period of ICLR is for, and one would expect that clarity issues can be successfully remedied during this period. I am disappointed to have seen little timely engagement from these reviewers, or willingness to explain why they are stick by their assessment if not revisiting it. As far as I am concerned, the authors have done an appropriate job of addressing these concerns, and given reviewer 1's support for the paper, I am happy to add mine as well.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Acceptable"
    },
    "Reviews": [
        {
            "title": "Interesting exploratory research, some more examples are desired",
            "review": "This paper investigates internal working of RNN, by mapping its hidden states\nto the nodes of minimal DFAs that generated the training inputs and its \nabstractions. Authors found that in fact such a mapping exists, and a linear\ndecoder suffices for the purpose. \nInspecting some of the minimal DFAs that correspond to regular expressions, \ninduced state abstractions are intuitive and interpretable from a viewpoint of\ntraining RNNs by training sequences.\n\nThis paper is interesting, and the central idea of using formal languages to\ngenerate feeding inputs is good (in fact, I am also doing a different research\nthat also leverages a formal grammar with RNN).\n\nMost of the paper is clear, so I have only a few minor comments:\n\n- In Figures 4 and 5, the most complex MDFA of 14 nodes does not have the\n  lowest testing accuracies. In other words, testing accuracies is not\n  generally proportional to the complexity of MDFA. Why does this happen?\n\n- As noted in the footnote in page 5, state abstraction is driven by the idea\n  of hierarchical grammars. Then, as briefly noted in the conclusion, why not\n  using a simple CFG or PCFG to generate training sequences? \n  In this case, state abstractions are clear by definition, and it is curious\n  to see if RNN actually learns abstract states (such as NP and VP in natural\n  language) through mapping from hidden states to abstracted states.\n\n- Because this paper is exploratory, I would like to see more examples\n  beyond only the two in Figure 6. Is it possible to generate a regular \n  expression itself randomly to feed into RNN?\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting idea, serious clarity problems",
            "review": "This paper aims to show that an RNN trained to recognize regular languages effectively focuses on a more abstract representation of the FSA of the corresponding language. \n\nUnderstanding the type of information encoded in the hidden states of RNNs is an important research question. Recent results have shown connections between existing RNN architectures and both weighted (e.g., Chen et al., NAACL 2018, Peng et al., EMNLP 2018) and unweighted (Weiss et al., ACL 2018) FSAs. This paper asks a simple question: when trained to recognize regular languages, do RNNs converge on the same states as the corresponding FSA? While exploring solutions to this question is potentially interesting, there are significant clarity issues in this paper which make it hard to understand it. Also, the main claim of the paper — that the RNN is focusing on a low level abstraction of thew FSA — is not backed-up by the results.\n\nComments:\n\n— The authors claim that the RNN states map to FSA states with *low* coarseness, but Figure 3b (which is never referred to in text…) shows that in most cases the ratio of coarseness is at least 1/3, and in some cases > 1/2. \n\n— Clarity:\nWhile the introduction is relatively clear starting from the middle of section 3 there are multiple clarity issues in this paper. In the current state of affairs it is hard for me to evaluate the full contribution of the paper.\n\n- The definitions in section 3 were somewhat confusing. What is the conceptual difference between the two accuracy definitions? \n\n- When combining two states, does the new FSA accept most of the strings in the original FSAs? some of them? can you quantify that? Also, figure 6 (which kind of addresses this question) would be much more helpful if it used simple expressions, and demonstrated how the new FSA looks like after the merge.\n\n- section 4 leaves many important questions unanswered:\n1. Which RNN was used? which model? which parameters? which training regime? etc.\n2. How were the expressions sampled? the authors mention that they were randomly sampled, so how come they talk about DATE and EMAIL expressions?\n3. What is the basic accuracy of the RNN classifier (before decoding)? is it able to learn to recognize the language? to what accuracy? \n\n- Many of the tables and figures are never referred to in text (Figure 3b, Figure 5)\n\n- In Figure 6, there is a mismatch between the regular expression (e.g., [0-9]{3}….) and the transitions on the FSA (a-d, @).\n\n- How come Figure 3a goes up to 1.1? isn’t it bounded by 1? (100%?)\n\n- The negative sampling procedure should be described in the main text, not the appendix. Also, it is not clear how come shuffling the characters is considered an independent distribution.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Well written paper -- One major concern",
            "review": "Paper Summary -\nThe authors trained RNNs to recognize formal languages defined by random regular expressions, then measured the accuracy of decoders that predict states of the minimal deterministic finite automata (MDFA) from the RNN hidden states. They then perform a greedy search over partitions of the set of MDFA states to find the groups of states which, when merged into a single decoder target, maximize prediction accuracy. For both the MDFA and the merged classes prediction problems, linear decoders perform as well as non-linear decoders.\nClarity - The paper is very clear, both in its prose and maths.\nOriginality - I don't know of any prior work that approaches the relationship between RNNs and automata in quite this way.\nQuality/Significance - I have one major concern about the interpretation of the experiments in this paper.\n\nThe paper seems to express the following logic:\n1 - linear (and non-linear) decoders aren't so good at predicting MDFA states from RNN hidden states\n2 - if we make an \"abstract\" finite automata (FA) by merging states of the MDFA to optimize decoder performance, the linear (and non-linear) decoders are much better at predicting this new, smaller FA's states.\n3 - thus, trained RNNs implement something like an abstract FA to recognize formal languages.\n\nHowever, a more appropriate interpretation of these experiments seems to be:\n1 - (same)\n2 - if we find the output classes the decoder is most often confused between, then merge them into one class, the decoder's performance increases -- trivially. in other words, you just removed the hardest parts of the classification problem, so performance increased. note: performance also increases because there are fewer classes in the merged-state FA prediction problem (e.g., chance accuracy is higher).\n3 - thus, from these experiments it's hard to say much about the relationship between trained RNNs and finite automata.\n\nI see that the \"accuracy\" measurement for the merged-state FA prediction problem, \\rho, is somewhat more complicated than I would have expected; e.g., it takes into account \\delta and f(h_t) as well as f(h_{t+1}). Ultimately, this formulation still asks whether any state in the merged state-set that contains f(h) transitions under the MDFA to the any state in the merged state-set that contains f(h_{t+1}). As a result, as far as I can tell the basic logic of the interpretation I laid out still applies.\n\nPerhaps I've missed something -- I'll look forward to the author response which may alleviate my concern.\n\nPros - very clearly written, understanding trained RNNs is an important topic\nCons - the basic logic of the conclusion may be flawed (will await author response)\n\nMinor -\nThe regular expression in Figure 6 (Top) is for phone numbers instead of emails.\n\"Average linear decoding accuracy as a function of M in the MDFA\" -- I don't think \"M\" was ever defined. From contexts it looks like it's the number of nodes in the MDFA.\n\"Average ratio of coarseness\" -- It would be nice to be explicit about what the \"ratio of coarseness\" is. I'm guessing it's (number of nodes in MDFA)/(number of nodes in abstracted DFA).\nWhat are the integers and percentages inside the circles in Figure 6?\nFigures 4 and 5 are difficult to interpret because the same (or at least very similar) colors are used multiple times.\nI don't see \"a\" (as in a_t in the equations on page 3) defined anywhere. I think it's meant to indicate a symbol in the alphabet \\Sigma. Maybe I missed it.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}