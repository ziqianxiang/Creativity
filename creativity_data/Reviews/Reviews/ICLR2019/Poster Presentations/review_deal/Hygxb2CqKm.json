{
    "Decision": {
        "metareview": "The paper presents both theoretical analysis (based upon lambda-stability) and experimental evidence on stability of recurrent neural networks. The results are convincing but is concerns with a restricted definition of stability. Even with this restriction acceptance is recommended. ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Important topic, favorable reviews but are the stated implications general?"
    },
    "Reviews": [
        {
            "title": "Interesting theoretical angle on RNNs that provides insights but also feel incomplete",
            "review": "This is an interesting paper that I expect will generate some interest within the ICLR community and from deep learning researchers in general. The definition of stability is both intuitive and sound and the connection to exploding gradients is perhaps the most interesting and useful part of the paper. The sufficient conditions yield practical techniques for increasing the stability of, e.g., an LSTM, by constraining the weight matrices. They also show that stable recurrent models can be approximated by models with finite historical windows, e.g., truncated RNNs. Experiments in Sec 4 suggest that stable models produced by constraining standard RNN architectures can compete with their unconstrained unstable counterparts, and often without necessitating significant changes to architecture or hyperparameters. The perhaps most interesting observations are in Sec 4.3, in which the authors claim that even fundamentally unstable models, e.g., unconstrained RNNs, often operate in a stable regime, at least when being applied to in-sample data. I lean toward acceptance at the moment, but I am eager to discuss with the authors and other reviewers as I am not 100% confident that I fully understood the theory.\n\nSUMMARY\n\nThis paper proposes a simple, generic definition of “stability” for recurrent, non-linear dynamical systems such as RNNs: that given two hidden states h, h’, the difference between their updated states given input x is bounded by the product between the difference between the states themselves and a small multiplier. The paper then immediately draws a connection between stability, asserting that unstable models are prone to gradient explosions during gradient descent-based training. In Sec 2.2, the paper presents sufficient conditions for basic RNNs and LSTMs to be stable. Secs 3.2 and 3.3 argue that stable recurrent models can be approximated by feedforward models during both inference and training with a finite history horizon, such as a RNN with a truncated history. Experiments in language and music modeling substantiate this claim: constrained, stable models are competitive with standard unconstrained models. Sec 4.3 sheds some light on this phenomenon, arguing that there is a weaker form of data-dependent stability and that even unstable models may operate in a stable regime for some problems, thus explaining the parity between stable and unstable models.\n\nSTRENGTHS\n\n* This paper is surprisingly engaging and easy to read.\n* The theorems are clearly stated and the proofs appear sound to me, though I will admit that I am not confident that I would catch a significant bug.\n* This paper provides a new (to me, anyway) and thought-provoking analysis of RNNs. In particular, I was especially interested in the observation that stable models can be approximated by truncated models and that there is a connection between stability and long-term dependencies. This seems consistent with the fact that for many problems, non-recurrent models (ConvNets, Transformers, etc.) are often competitive with more complex architectures.\n\nWEAKNESSES\n\n* In practice it seems as though stability may depend on not only choice of  model architecture but also the data themselves. There is probably no good way to know a priori what the stability characteristics of a given data set are, making it tough to apply the ideas of this paper in practice\n* The literature review seems a bit limited and appears to ignore the growing body of work on constraining RNN weight matrices to address both exploding and vanishing gradients. For example, I am pretty confident that the singular thresholding trick for renormalizing neural net weights has been  described in the literature previously.\n* Although stable and unstable models appear to be competitive in experiments, the theoretical analysis provides no insights into stability and how it relates to accuracy.",
            "rating": "7: Good paper, accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Interesting theoretical and practical results but false claims on RNNs",
            "review": "+ An interesting problem to study on the stability of RNNs\n+ Investigation of spectral normalization to sequential predictions is worthwhile, especially Figure 2\n+ Some theoretical justification of SGD for learning dynamic systems following Hardt et al. (2016b).\n\n- The take-home message of the paper is not clear. First, it defines a  notion of stability based on Lipchitz-continuity and proves SGD can learn it. Then the experiments show such a definition is actually not correct, but rather a data-dependent one. \n- The theory only looks at the instantaneous dynamics from time t to t+1, without unrolling the RNNs over time. Then it is not much different from analyzing feed-forward networks. The theorem on SGD is remotely related to the contribution of the paper. \n- The spectral normalization technique that is actually used in experiments is not new",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "In this paper, the authors study the stability property of recurrent neural networks. Adopting the definition of stability from the dynamical system literature, the authors present a generic definition of stable recurrent models and provide sufficient conditions of stable linear RNNs and LSTMs. The authors also study the \"feed-forward\" approximation of recurrent networks and theoretically show that the approximation works for both inference and training. Experimental studies compare the performance of stable and unstable models on various tasks.\n\nThe paper is well-written and very pleasant to read. The notations are clear and the claims are relatively easy to follow. The theoretical analysis in Section 3 is novel, interesting and solid. However, the reviewer has concerns about the motivation of the presented analysis and insufficient empirical results.\n\nThe stability property only eliminates the exploding gradient problem, but not the vanishing gradient problem. The reviewer suspects that a stable recurrent model always suffers from vanishing gradient. Therefore, stability might not necessarily be a desirable property. There has been a line of work that constrain the weight matrix in RNNs to be orthogonal or unitary so that the gradient won't explode, e.g. [1], [2], [3]. It seems that the orthogonal or unitary conditions are stronger than the stability condition, and are probably less prone to the vanishing gradient problem. \n\nThe vanishing gradient problem is also related to the analysis in Section 3. If a recurrent network is very stable and has vanishing gradient, then a small perturbation of the initial hidden state has little effect on later time steps. This intuitively explains why it can be well approximated by using only the last k time steps. However, the recurrent model itself might not be a desirable model.  In other words, although Theorem 1 shows that $y_T$ and $y_T^k$ can be arbitrarily close, $y_T$ might not be a good prediction.\n\nThe experimental study seems weak. Again, in the RNN case, constraining the singular values of the weight matrix is not a new idea. Furthermore, the results in Table 1 seem to suggest that the stable models perform worse than unstable ones. What is the benefit in using stable models? Proposition 2 is only a sufficient condition of a stable LSTM and it seems very restrictive, as the authors point out. This might explain the worse performance of the stable LSTMs in Table 1. The reviewer was expecting more experimental results to support the claims in Section 3. For example, an empirically study of the difference between a recurrent model and a \"feed-forward\" or truncation approximation.\n\nMinor comments:\n* Lemma 1: $\\lambda$-contractive => $\\lambda$-contractive in $h$?\n* Theorem 1: $k=O(...)$ => $k=\\Omega(...)$? Intuitively, a bigger k leads to a better feed-forward approximation.\n\n[1] Martin Arjovsky, Amar Shah, and Yoshua Bengio. Unitary evolution recurrent neural networks. ICML, 2016.\n[2] Scott Wisdom, Thomas Powers, John Hershey, Jonathan Le Roux, and Les Atlas. Full-capacity unitary recurrent neural networks. NIPS, 2016.\n[3] Eugene Vorontsov, Chiheb Trabelsi, Samuel Kadoury, and Chris Pal. On orthogonality and learning recurrent networks with long term dependencies. ICML, 2017.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}