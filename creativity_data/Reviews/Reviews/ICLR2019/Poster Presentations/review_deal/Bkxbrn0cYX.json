{
    "Decision": {
        "metareview": "Two of the reviewers raised their scores during the discussion phase noting that the revised version was clearer and addressed some of their concerns.  As a result, all the reviewers ultimately recommended acceptance.  They particularly enjoyed the insights that the authors shared from their experiments and appreciated that the experiments were quite thorough.  All the reviewers mentioned that the work seemed somewhat incremental, but given the results, insights and empirical evaluation decided that it would still be a valuable contribution to the conference.  One reviewer added feedback about how to improve the writing and clarity of the paper for the camera ready version.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "incremental but interesting contribution to life long learning for neural networks."
    },
    "Reviews": [
        {
            "title": "Interesting work addressing an interesting class of problems, novel regularizer and good experiments, but writing and paper organization need work",
            "review": "REVISION AFTER REBUTTAL\nWhile the revision does not address all of my concerns about clarity, it is much better. I still think that the introduction is overly long and the subsequent sections repeat information; if this were shortened there could be room for some of the figures that are currently in appendix. I appreciate the new figures; I think that it would be great if especially figure 10 were included in the main paper. \nI agree with the other two reviewers that the work is somewhat incremental, but the differences are well explained, the experimental results are interesting (particularly the differences of parameter vs representation-based sparsity, and the plots in appendix showing neuron importance over tasks), and the progression from SNI to SLNID is well-presented.  I think overall that this paper is a good contribution and I recommend acceptance. I have updated my review to a 7. \n===============\n\"Activations\" \"Representation\" and \"Outputs\" are used somewhat interchangably throughout the work; for anyone not familiar it might be worth mentioning something about this in the intro.\n \nProblem setting is similar to open set learning (classification); could be worth mentioning algorithms for this in the related work which attempt to set aside capacity for later tasks.\n\nResults are presented and discussed in the introduction, and overall the intro is a bit long, resulting in parts later being repetitive.\n\nWorth discussing sparsity vs. distributed representations in the intro, and how/where we want sparsity while still having a distributed representation.\n\nShould be made clear that this is inspired by one kind of inhibition, and there are many others (i.e. inhibition in the brain is not always about penalizing neurons which are active at the same time, as far as I know)\n\nChanges in verb tense throughout the paper make it hard to follow sometimes. Be consistent about explaining equations before or after presenting them, and make sure all terms in the equation are defined (e.g. SNI with a hat is used before definition). Improper or useless \"However\" or \"On the other hand\" to start a lot of sentences.\n\nFigure captions could use a lot more experimental insight and explanation - e.g. what am I supposed to take away from Figure 10 (in appendix B4), other than that the importance seems pretty sparse? It looks to me like there is a lot of overlap in which neurons are important or which tasks, which seems like the opposite of what the regularizer was trying to achieve. This is a somewhat important point to me; I think this interesting and I'm glad you show it, but it seems to contradict the aim of the regularizer.\n\nHow does multi-task joint training differ from \"normal\" classification? The accuracies especially for CIFAR seem very low.\n\nQuality: 7/10 interesting and thoughtful proposed regularizer and experiments; I would be happy to increase this rating if the insights from experiments, especially in the appendix, are a bit better explained\nClarity:  6/10 things are mostly clearly explained although frequently repetitive, making them seem more confusing than they are. If the paper is reorganized and the writing cleaned up I would be happy to increase my rating because I think the work is good. \nOriginality: 8/10 to my knowledge the proposed regularizer is novel, and I think think identifying the approach of \"selfless\" sequential learning is valuable (although I don't like the name)\nSignificance: 7/10 I am biased because I'm interested in LLL, but I think these problems should receive more attention.\n\nPros:\n - proposed regularizer is well-explained and seems to work well, ablation study is helpful\n\nCons:\n - the intro section is almost completely repetitive of section 3 and could be significantly shortened, and make more room for some of the experimental results to be moved from the appendix to main text\n - some wording choices and wordiness make some sentences unclear, and overall the organization and writing could use some work\n\nSpecific comments / nits: (in reading order)\n1. I think the name \"selfless sequential learning\" is a bit misleading and sounds like something to do with multiagent cooperative RL; I think \"forethinking\" or something like that that is an actual word would be better, but I can't think of a good word... maybe frugal? \n2.  Mention continual/lifelong learning in the abstract\n3. \"penalize changes\" maybe \"reduce changes\" would be better?\n4. \"in analogy to parameter importance\" cite and explain parameter importance\n5. \"advocate to focus on selfless SL\" focus what? For everyone doing continual learning to focus on methods which achieve that through leaving capacity for later tasks? This seems like one potentially good approach, but I can imagine other good ones (e.g. having a task model)\n6. LLL for lifelong learning is defined near the end of the intro, should be at the beginning when first mentioned\n7. \"lies at the heart of lifelong learning\" I would say it is an \"approach to lifelong learning\"\n8. \"fixed model capacity\" worth being specific that you mean (I assume) fixed architecture and number of parameters\n9. \"those parameters by new tasks\" cite this at the end of the sentence, otherwise it is unclear what explanation goes with which citation\n10.  \"hard attention masks, and stored in an embedding\" unclear what is stored in the embedding. It would be more helpful to explain how this method relates to yours rather than just describing what they do.\n11. I find the hat notation unclear; I think it would be better just to have acronyms for each setting and write out the acronyms in the caption\n12.\"richer representation is needed and few active neurons can be tolerated\" should this be \"more active neurons\"?\n13. Comparison with state of the art section is repetitive of the results sections",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review for Selfless Sequential Learning",
            "review": "This paper deals with the problem of catastrophic forgetting in lifelong learning, which has recently attracted much attention from researchers. In particular, authors propose the regularized learning strategies where we are given a fixed network structure (without requiring additional memory increases in the event of new task arriving) in the sequential learning framework, without the access to datasets of previous tasks.  Performance comparisons were performed experimentally against diverse regularization methods including ones based on representation, based on parameter itself, and the superiority of representation-based regularization techniques was verified experimentally. Based on this, authors propose a regularization scheme utilizing the correlation between hidden nodes called SNI and its local version based on Gaussian weighting. Both regularizers are even extended to consider the importance of hidden nodes. Through MNIST, CIFAR, and tiny Imagenet datasets, it has been experimentally demonstrated that the proposed regularization technique outperforms state-of-the-art in sequential learning.\n\nIt is easy to follow (and I enjoyed the way of showing their final method, starting from SNI to SLNI and importance weighting). Also it is interesting that authors obtained meaningful results on several datasets beating state-of-the-arts based on very simple ideas.\n\nHowever, given Cogswell et al. (2015) or Xiong et al. (2016), it seems novelty is somehow incremental (I could recognize that this work is different in the sense that it considers  local/importance based weighting as well as penalizing correlation based on L1 norm). Moreover, there is a lack of reasoning about why representation based regularization is more effective for life-long learning setting. Figure 1 is not that intuitive and it does not seem clearly describe the reasons.   \n\nMy biggest concern with the proposed regularization technique is the importance of neurons in equation (6). It is doubtful whether the importance of activation of neurons based on \"current data\" is sufficiently verified in sequential learning (in the experimental section, avg performance for importance weight sometimes appears to come with performance improvements but not always). It would be great if authors can show some actual overlaps of activations across tasks (not just simple histogram as in Figure 5). And isn't g_i(x_m) a scalar? Explain why we need the norm when you get alpha.\n\nIt would be nice to clarify what the task sequence looks like in Figure 2. It is hard to understand that task 5, which is the most recent learning task, has the lowest performance in all tasks.\n\n-----------------------------------------------------------------------------------------------------\n- On figure 4: I knew histograms are given in figure 4 (I said figure 5 mistakenly, but I meant figure 4). But showing overlap patterns across tasks (at different layers for instance) might be more informative. \n- On figure 2: It looks weird to me because last task has the lowest accuracy even for ReLU (sequential learning w/o regularization); tuning for task 5 will lead catastrophic forgetting for previous tasks, meaning acc for task 1 be the lowest?\n\n-----------------------------------------------------------------------------------------------------\n-  My concerns about figures are solved; I want to thank authors for their efforts.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Thorough continual learning work but limited to task-based case",
            "review": "[REVISION]\nThe work is thorough and some of my minor concerns have been addressed, so I am increasing my score to 6. I cannot go beyond because of the incremental nature of the work, and the very limited applicability of the used continual learning setup from this paper.\n\n[OLD REVIEW]\nThe paper proposes a novel, regularization based, approach to the sequential learning problem using a fixed size model. The main idea is to add extra terms to the loss encouraging representation sparsity and combating catastrophic forgetting. The approach fairs well compared to other regularization based approaches on MNIST and CIFAR-100 sequential learning variants.\n\nPros:\nThorough experiments, competitive baselines and informative ablation study.\nGood performance on par or superior to baselines.\nClear paper, well written.\n\nCons:\nThe approach, while competitive in performance, does not seem to fix any significant issues with baseline methods. For example, task boundaries are still used, which limits applicability; in many scenarios which do have a continual learning problem there are no clear task boundaries, such as data distribution drift in both supervised and reinforcement learning.\nSince models used in the work are very different from SOTA models on those particular tasks, it is hard to determine from the paper how the proposed method influences these models. In particular, it is not clear whether these changes to the loss would still allow top performance on regular classification tasks, e.g. CIFAR-10 or MNIST even without sequential learning, or in multitask learning settings. \n\nSummary:\nAlthough the work is substantial and experiments are thorough, I have reservations about extrapolating from the results to settings which do have a continual learning problem. Although I am convinced results are slightly superior to baselines, and I appreciate the lengthy amount of work which went into proving that, the paper does not go sufficiently beyond previous work.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}