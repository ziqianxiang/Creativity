{
    "Decision": {
        "metareview": "There's precious little work asking existential questions about adversarial examples, and so this work is most welcome. The work connects with deep results in probability to make simple and transparent claims about the inevitability of adversarial examples under some assumptions. The authors have addressed the key criticisms of the authors around clarity.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Interesting contribution to our understanding of adversarial examples"
    },
    "Reviews": [
        {
            "title": "good insight on understanding adversarial examples",
            "review": "This paper uses several lemmas in geometry to prove that adversarial examples\nare hard to avoid under the assumption that there is no \"don't know\" class and\nthe distribution of each class is not too concentrated. The paper first starts\nwith a simple case where the data points are distributed on a sphere, and then\nextends the results to the realistic case where data points are inside a cube\n[0,1]^n. \n\nThe paper uses epsilon expansion of a set as a mathematical tool, and borrows\nsome important lemmas from geometry to the case of adversarial learning.  In\nthe sphere case, the results come from a fact that high dimensional\nhalf-spheres can almost cover all points in the sphere after an epsilon\nexpansion, and the results depend on dimension n. For the unit cube case, the\nauthors borrow a result from Talagrand, to show that the epsilon expansion of a\nset can cover a large portion of the cube as long as the set distribution is\nnot very concentrated.  In this case, the results (for l_2 norm) do not depend\non dimension n.\n\nExperimentally, the authors show that inputs with higher dimension can actually\nget better robustness, aligning with the provided analysis.  The primary reason\nthat current adversarial defense does not work well on CIFAR is due to the fact\nthat dataset is more spread out in high dimensional space. This is a good\ninsight for understanding adversarial examples.\n\nThe paper is overall well written and easy to follow. The interpretation of\neach lemma and proposition is clear. Although the paper mostly depend on\nwell-known results in geometry and the ideas used are simple, it does provide\ngood insight on explaining the prevalence of adversarial examples. I recommend\nto accept this paper.\n\nQuestion:\nIs there any good method to estimate U_c for a dataset? Although it is intuitive\nthat CIFAR may have a smaller U_c than MNIST, is it possible to numerically\nestimate this quantity? This is necessary to fully support the conclusions made\nin experiments.\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "interesting maths; implications less clear",
            "review": "The paper considers the problem of adversarial examples in (mostly high-dimensional) multi-class classification problems. Although the results are not specific necessarily to very high dimensional data or two images, the paper mostly uses images as a running example, and so will I in the review. \n\nAssume that the data all lies in the unit box in R^n ([0, 1]^n). A multiclass classifier with K classes partitions the unit cube into K parts, each part corresponding to a given class. There are distributions \\rho_c associated with each class and there is a bound on their density given by U_c and the fraction of examples of class c is f_c. And (eps, p) adversarial point y for some point x is such that |x - y|_p <= \\eps and the classifier classifies x & y differently. \n\nThe paper shows that under this modeling assumption adversarial examples are inevitable. The results mostly use standard (but deep) results from probability theory. The technical proofs themselves are not particular difficult (provided one has the right background). I think the overall implications are interesting, and I will recommend the paper be accepted. \n\nHowever, I also feel that this is a missed opportunity. To some extent the authors do try to have some high-level discussion about adversarial examples, but I think this could be expanded on more. For instance, why should it be assumed that an example that is \\eps far should automatically have the same class label? Surely, being \"eps\"-far away is an equivalence relation, thus this would mean that all the hypercube would have to be labeled by the same class. This is clearly not the case. One plausible explanation is that if you take two points that are in two different classes, then any sequence of points that take one to the other with the property that each adjacent pair is at most \\eps far away, must have the property that some intermediate mass have negligible chance of being a \"natural\" image. \n\nOn the other hand, doesn't the fact that humans are not susceptible to most adversarial examples, imply that adversarial-example resistant classifiers exist? My own feeling is the assumption that U_c is bounded is the strongest assumption that may not hold true with real data. In any case, the paper has enough technical content to merit acceptance and I hope the open review forum will lead to a fruitful discussion about some of these questions.\n\n--\n\nMinor comments:\nPage 6 (just after Thm 2). Isn't the bound in Eqn. (5) true for all \\ell_p norms for p \\geq 2? (not just \\ell_2 as the sentence says)\nParas on Page 6 (just below Thm 2). It would be more pleasant if equation x could be replaced by Eq. (x) or Equation (x). \nPara in Sec 7 on Unbounded density: Clarify what norm you mean when you talk about \\eps/2 perturbations.\nThm 5: Seems odd to have a theorem about MNIST. Surely the result is a lot more general!!!",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "a good angle, limited technical contributions, inconclusive statements",
            "review": "This paper explores the inevitability of adversarial examples with concentration inequalities. It is motivated by the difficulties of achieving adversarial robustness in literature. It derives isoperimetric inequalities on a cube, and then discuss the adversarial robustness of data distributed inside the cube, with the assumption that the data has bounded density. These inequalities are established on different norms. The authors then discuss limitation of the proposed bounds when analyzing practical data distribution and discussed the influence of dimensionality on adversarial robustness.\n\n\nNovelty of the idea:\nThe idea of using concentration inequalities to explain vulnerability is novel in the field of adversarial examples and is a relevant/meaningful angle on understanding this phenomenon. (Although there are concurrent works also relating concentration inequalities to adversarial robustness, they don't diminish the novelty of this work.)\n\n\n\nOn technical contributions:\nIn summary, this paper applies / adapts previous results in concentration inequalities to develop bounds related to adversarial examples. The bounds in Lemma 3 are on any p>0, this seems to be new to my knowledge, but the technical contribution in the proof is limited.\n\nHere are some detailed comments.\n\nThe authors claim that\n\"This question is complicated by the fact that simple, geometric isoperimetric inequalities fail to exist for the cube, and the shapes that achieve minimal \\eps-expansion (if they exist) depend on the volume they enclose and the choice of \\eps.\"\nThis statement is at least misleading, if not wrong. It is well known that geometric isoperimetric inequality does exist for cube for the L2 case (see Ledoux, M., 2001. Proposition 2.8.), and the proof procedure the author used is also very similar to the proofs in Ledoux, M., 2001.\n\nTheorem 5's proof is confusing, if not wrong. \nThis is my brief recap on the first part of Thm 5, \nIf there exists eps and p such that, for all classifiers on MNIST, a random image has eps-adv with probability at least p, then for all classifiers on b-MNIST, a random image has b*eps-adv with probability at least p.\nThe proof in Appendix E says b-MNIST images can be classified by first downsampling. These downsampled classifiers do not cover \"all classifiers on b-MNIST\", so I don't see how the proof stands.\nLikewise, the proof of the second part has the similar problem.\nTherefore, I'm not yet convinced that Thm 5 is correct.\nAlso I suggest the authors use more rigorous language to present Theorem 5, in a similar fashion to previous theorems.\n\nRe: Lemma 4, my understanding is that it is from previous literature. The authors should point out exactly where is it from (with section# and theorem#), so that readers and reviewers can more easily check the correctness of it.\n\nThe authors mention that \"Intuitively, the concentration limit Uc can be interpreted as a measure of image complexity.\"\nI think this statement is problematic. It is, at best, oversimplifying the the problem. If we assume the data lies in low-dimensional space, the volume of the support will be 0, no matter how complex the shape of the manifold is. This lead to unbounded density in the ambient dimension.\nEven when considering \"expanded dataset\" like the authors discussed in Section 7, it is not obvious that Uc can be interpreted as image complexity. To make such a claim, more assumptions need to made and more analyses need to be done.\nSimilar comments applies to the \"correlations between pixels\" and concentration.\n\n\n\nOn the significance:\nAs the author themselves have already mentioned, the bounds described in the paper all depends on the bounded density of the data distribution. In practice, the density of data distribution is difficult to understand, if not impossible. Therefore it is still inconclusive whether the \"inevitability\" exists. But to be fair, I believe this is mostly due to the difficulty of the problem being studied.\n\n\n\nClarity and writing:\nThe skeleton of the paper is well written and easy to follow. I've pointed out some problems in my previous comments.\nI also appreciate that the authors made efforts to not overclaim.\n\nhere are a few more comments:\n- I personally feel Section 3 as an \"warm-up\" section is redundant, and the authors can consider move them to the appendix.\n- In Section 6 and 7, the authors talk about when is the bound \"meaningful\" and \"active\". This part is confusing/misleading. eps=sqrt(n) is actually the maximum possible perturbation and not falls into the common \"adversarial perturbation\" where the perturbation does not change the semantic meaning of the image. There should be a least an additional numerical examples on small eps, so the readers have better ideas on the tightness/looseness of the bound.\n\n\n\nReferences:\nLedoux, M., 2001. The concentration of measure phenomenon (No. 89). American Mathematical Soc..\n\n==========================\nI change my rating on this paper to be 6, after the authors' response. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}