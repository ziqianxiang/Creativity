{
    "Decision": {
        "metareview": "This paper proposes an approach for imitation learning from unsegmented demonstrations. The paper addresses an important problem and is well-motivated. Many of the concerns about the experiments have been addressed with follow-up comments. We strongly encourage the authors to integrate the new results and additional literature to the final version. With these changes, the reviewers agree that the paper exceeds the bar for acceptance. Thus, I recommend acceptance.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "meta review"
    },
    "Reviews": [
        {
            "title": "The InfoGail method extended to online latent code estimation at test time",
            "review": "The paper presents a learning-based method for learning the latent context codes from demonstrations along with a GAIL model. \nThis amounts to learning the option segments and the policies simultaneously. \nThe main contribution is the model the problem as a time-dependent context and then use a directed information flow loss instead of the mutual information loss.\n\n1. What is the effect of models of the underlying distribution of latent codes. \nCan it be categorical only, or can it be continuous? \nCould we also model it as multidimensional?\nThe current results only provide single dimensional categorial distribution as latent codes. \n\n2. The paper missed an important line of work which solves nearly the same problem -- option discovery and policy learning. \nKrishnan -- Discovery of Deep Option(1703.08294). This work was used by authors in continuous options and then again for program generation (https://openreview.net/pdf?id=rJl63fZRb). \n\nThey explicitly infer the option parameters, along with termination conditions with the Expectation Propagation method. \nThe results are in very similar domains hence comments, if not a comparison, would be useful. \n\n\n3. The authors state that the main problem with an InfoGail style method is dependence on the full trajectory as in eq 1. Hence the directed info flow is required to solve the problem. However in the actual model, the authors make a sequence of variational approximations -- (a) reduction of eq2 to eq1 with a variation lower bound on posterior p(c|c,\\tau) and then replace the prior p(c) with q(c|c,\\tau) in eq 5. But looking at the model diagram in fig 2. the VAE actually makes the Markovian assumption -- i.e. c only depends on c_{t-1} and s_{t}. If that is true then how would this be very different from InfoGAIL mutual information loss. \nIt appears that to capture the authors' mathematical intuition the VAE should have a recurrent generator which should have a hidden state factor passing in to capture dependence on history until the current time. \n\n3a. In fact the first term in eq 6 looks closer to the actually used model. If that is not true then the authors should clarify. \n\n4. Experiments do capture the notion discovery of options. But the simplicity of data leaves much to be desired. \nOne of the main difference of this work in comparison to unsupervised segmentation models GMM or BP-AR-HMM is the fact that the options learned are composable. But the authors only show this composability on the circle domain -- which is arguably a toy-domain. \nA reasonable confirmation that the model indeed learns composition is to generate a trajectory for a sequence of latent code not seen in data. -- like walking -- normal -- left-right-left can be converted to limping gait -- left-left-right-right. This is only a suggestive example. \n\n5. In appendix eq 8 how is the reduction from line 3 to line 4 of the equation made -- what is the implicit assumption. \njoint distribution p(c, \\tau) is written out as p (\\tau|c) p(c) without an integral.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review of Directed-Info GAIL",
            "review": "Summary:\n\nThis paper proposes an extension over the popular GAIL method for imitation learning  for the multi-modal data or tasks that have hierarchical structure in them. To achieve that the paper introduces an unsupervised variational objective by maximizing the directed mutual information between the latents c’s and the trajectories. The advantage of using directed information instead of regular MI based criterion is two-folds: 1) Being able to express the causal and temporal dependencies among the c’s changing across time. 2) Being able to learn a macro-policy without needing to condition on the future trajectories. Authors present results both on continuous and discrete environments.\n\n\nQuestions: \n1) Can you give more detailed information about the hyperparameters of your model? For example how many seeds have you used?\n2) Have you tried pre-training c_t’s as continuous latent variables?\n3) Have you tried pre-training your model as Variational RNN instead of VAE?\n4) Have you tried training your model on the pixels on the continuous control tasks?\n\nPros:\n* Although the approach bears some similarity to Info-GAIL approach. The idea of using directed information for GAIL is novel and very interesting. This approach can be in particular useful for the tasks that have \n* The paper is very well-written the goal and motivation of the paper is quite clear.\n\nCons:\n* Experiments are quite weak. Both the discrete and the continuous environment experiments are conducted on very simplistic and toyish tasks. There are much more complicated and modern continuous control environments such as control suite [1] or manipulation suite [2].  In particular tasks where there is a more clear hierarchy would be interesting to investigate.\n* Experimental results are underwhelming. For example Table 1, the results of the proposed approach is only barely better than the baseline.\n\n[1] https://github.com/deepmind/dm_control\n[2] Learning by Playing-Solving Sparse Reward Tasks from Scratch, M Riedmiller, R Hafner, T Lampe, M Neunert et al - arXiv preprint arXiv:1802.10567, 2018\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A well written paper with a relevant contribution for imitation learning",
            "review": "The paper describes a new learning framework, based on generative\nadversarial imitation learning (GAIL), that is able to learn sub-tasks\npolicies from unsegmented demonstrations. In particular, it follows\nthe ideas presented in InfoGAIL, that depends on a latent variable,\nand extend them to include a sequence of latent variables representing\nthe sequence of different subtasks. The proposed approach uses a\npre-training step, based on a variational auto-encoder (VAE), to\nestimate latent variable sequences. The paper is well written and\nrelates the approach with the Options framework. It also shows,\nexperimentally, its performance against current state-of-the-art\nalgorithms.  \n\nAlthough the authors claim in the appendix that the approach is\nrelatively independent on the dimensionality of the context variable,\nthis statement needs further evidence. The approach is similar to HMMs\nwhere the number f hidden states or latent variables can make a\ndifference in the performance of the system.\n\nAlso, it seems that the learned contexts do not necessarily correspond\nto meaningful sub-tasks, as shown in the circle-world. In this sense,\nit is not only relevant to determine the \"right\" size of the context\nvariable, but also how to ensure a meaningful sub-task segmentation. \n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}