{
    "Decision": {
        "metareview": "A hierarchical method is presented for developing humanoid motion control,\nusing low-level control fragments, egocentric visual input, recurrent high-level control.\nIt is likely the first demonstration of 3D humanoids learning to do memory-enabled tasks using only\nproprioceptive and head-based ego-centric vision. The use of control fragments as opposed\nto mocapclip-based skills allows for finer-grained repurposing of pieces of motion, while\nstill allowing for mocap-based learning\n\nWeaknesses: It is largely a mashup up of previously known results (R2).  Caveat: this can be said for all research\nat some sufficient level of abstraction. The motions are jerky when transitions happen between control fragments (R2,R3).\nThere are some concerns as to whether the method compares against other methods; the authors note\nthat they are either not directly comparable, i.e., solving a different problem, or are implicitly\ncontained in some of the comparisons that are performed in the paper.\n\nOverall, the reviewers and AC are in broad agreement regarding the strengths and weaknesses of the paper.\n\nThe AC believes that the work will be of broad interest. Demonstrating memory-enabled, vision-driven,\nmocap-imitating skills is a broad step forward. The paper also provides a further datapoint as \nto which combinations of method work well, and some of the specific features required to make them work.\n\nThe paper could acknowledge motion quality artifacts, as noted by the reviewers and \nin the online discussion.  Suggest to include  [Peng et al 2017] as some of the most relevant related HRL humanoid control work, as per the reviews & discussion.\n\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "accept;  vision-enabled/memory-enabled/mocap-mimicing humanoid"
    },
    "Reviews": [
        {
            "title": "Review",
            "review": "1) Summary\nThe authors propose an interesting hierarchical reinforcement learning method that makes use of visual inputs as well as proprioception for locomotion of humanoid agents. The low-level controllers make use of “motion capture” data and are expected to form a set of movement primitives that can be used by a higher-level controller that has vision and memory. Their method is tested on a variety of tasks and different choices of low-level controller are explored.\n\n2) Pros\n+ Combining vision, memory, and motor control\n+ Allows the high-level controller to operate at a coarser time scale\n+ The set of low-level movement primitives can be extended by using more mocap data\n\n3) Cons\n- No comparison to earlier work\n- Highly unnatural motions even though it makes use of mocap data\n- Sample inefficient: more than 1 billion time-steps to train the high-level controller\n\n4) Comments\nShowing that the agent can provide suitable solutions for these tasks using raw vision input is indeed interesting, however it is not clear what the main contribution of the paper is as the authors fail to compare their results with earlier work. It would be useful if the authors could cover the related work in more depth in order to motivate their method and contrast it with the existing solutions. As an example, DeepLoco (Peng et al. 2017) solves a similar problem in which they use an egocentric heightmap instead of direct visual input, hence a formal consideration of the trade-offs would be informative.\n\nIn addition, the appeal of using hierarchical reinforcement learning is to divide up the task into easier chunks that can be solved easier, however it is not obvious how well this method succeeds at this task, keeping in mind that the high-level controller takes in the order of 1 billion time-steps to learn most tasks (5 billion in the case of “Heterogeneous Forage”).\n\nIn the end, an ablation study could be useful since the authors make plenty of novel design decision, yet their effect on the final performance is not clear.\n\n\n6) Questions\n- Is is possible to entirely remove proprioception from the input to the high-level controller or at least use just a small portion of it? How do the results compare in this case?\n\n- How robust is “cold-switching” between control fragments? Is it possible to transition between most fragments without losing balance or does the high-level controller have to be extremely careful as to which combination it should use? The former case would suggest that this method is indeed useful as a hierarchical method. However the latter case might imply that the hierarchical method is failing and the higher level controller’s task has not been made much easier than the original problem itself.\n\n- Table 2 describes the mocap clips used to train the low-level controllers in each task. What is the effect of choosing different sets of motions? Specifically how well does the steerable controller work if walking motions were used for the “Go To Target” and “Walls” tasks rather than running motions? Presumably, this can result in a more flexible controller which allows sharper turns without loosing balance.\n\n- The network in Figure A.1 gets the last action as an input. Why is this required? Especially since the LSTM unit can learn to remember any information related to the previous actions.\n\n- How does the supervised pre-training described in section 2.1 effect the training of low-level controllers? Is it used as a speed-up mechanism or a way of escaping local minima?\n\n- In section 2.1 the authors mention that the episodes are “terminated when the pose deviates too far from the trajectory”. I believe this termination criteria was not present in the earlier works (Peng et al. 2018), then what is the effect of adding such a criterion? Can this make the learned agent less robust as it will not learn to recover from larger perturbations?\n\n\n7) Conclusion\nThe method and the results are interesting but further comparison with existing work is required.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good paper with great results in interesting environments ",
            "review": "The paper proposes a control architecture for learning task oriented whole body behaviors  in simulated humanoid robots bootstrapped with motion capture data.\n\nThe authors use a hierarchical approach, where the low-level controllers are trained to follow motion captured data whereas the high-level control combines them. \nThe topic of the paper is interesting and the language is understandable. \n\nThe paper discusses and compares different ways to achieve such a higher level control.\nIt probably won’t be useful for real robots, but will be possibly useful for computer graphics.\nI suspect that code will not be published anytime soon, and I am afraid it will be hard to reproduce without. There is a solid software engineering involved and the system has many parameters.  \n\nThe related work section (or lack thereof) can be improved. What is the advantage of this work over the multi-skill integration in Peng et al 2018? Please explain explicitly in the paper.\n\nThe end-to-end approach seems a bit too weak to me. The video shows more artifacts than other similar papers, (cf. Heess et al. 2017). What’s the detail of the training for the end-to-end baseline?\n\nAre the environments randomized in each rollout? If not then this would need an ablation study which ablates memory/vision to prove its claim of integrating vision and memory. \nHow much is the memory used in the tasks where nothing needs to be memorized?\nIs there any noise in the simulations?\n\nOne weakness is that the low-level controllers are not adapted any further. That is probably why the fragments outperformed the transition policies etc., because the higher level policy has more flexibility.\n\nOverall, from the perspective of deep learning, I think the paper is novel and provides some insights into different approaches to the problem.\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "1) Summary\nThis paper proposes a hierarchical reinforcement learning (HRL) method for visual motor control of humanoid agents. The method is decomposed into a high-level controller that takes in visual input and proprioceptive information, and a low-level controller (they compare may ways of doing this) that takes care of the agent’s motor control. In experiments, the proposed method is tested on a variety of RL tasks where the many low-level controllers presented in the paper are compared against each other.\n\n2) Pros:\n+ Novel high-level controller that takes in front-view visual information\n+ Novel multi-policy low level controller\n+ Interesting experimental section\n\n3) Cons:\nNumerical comparison to previous methods:\n- The only issue I found with this paper is that there is no comparison with other methods. Even if the other methods do not take in front-view visual input, it would be nice to compare with them. Maybe visual inputs results in better high-level controller? Or even show that performance is similar would be an interesting result.\n\n4) Comments:\nJerky transitions in switching controller:\n- Due to the fact that one policy takes over after each other based on the high-level controller choice, there is a jerk artifact that shows when the policies are being changed/executed. Did you guys try to add a connection in feature space between policies rather than only passing the state of the agent? This may be able to help with that artifact that sampling noise adds to the actions. Can the authors comment on this?\n\nSteerable controller limited rotation:\n- From observing the steerable controller policy in action, it seems the policy learned a steering that is somewhat independent of what the limbs are doing. Maybe adding a mechanism where the leg motion intensity depends more on the direction of movement could be a way to fix the issue where this policy moves to fast for the turning it tries to do. Maybe an energy based objective to minimize the torques or something in that line.\n\n4) Conclusion:\nTo the best of my knowledge, this paper proposes a novel interesting method for modeling humanoid motor skills with front-view visual input. However, as mentioned above, the paper lacks of numerical comparisons with other methods, and only compares against its own variations which is more of an ablation study. I am willing to increase my review score if the authors successfully address the concerns mentioned above",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}