{
    "Decision": {
        "metareview": "The paper makes progress on a problem that is still largely unexplored, presents promising results, and builds bridges with \nprior work on optimal control.  It designs input convex recurrent neural networks to capture temporal behavior of \ndynamical systems; this then allows optimal controllers to be computed by solving a convex model predictive control problem.\n\nThere were initial critiques regarding some of the claims. These have now been clarified.\nAlso, there is in the end a compromise between the (necessary) approximations of the input-convex model and the true dynamics, and being able to compute an optimal result. \n\nOverall, all reviewers and the AC are in agreement to see this paper accepted.\nThere was extensive and productive interaction between the reviewers and authors.\nIt makes contributions that will be of interest to many, and builds interesting bridges with known control methods.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "strong paper; nomination for oral presentation; nomination for best reviewer"
    },
    "Reviews": [
        {
            "title": "Well-motived but may have serious issues. EDIT: Serious issues have been fixed.",
            "review": "This is a well-motived paper that considers bridging the gap\nin discrete-time continuous-state/action optimal control\nby approximating the system dynamics with a convex model class.\nThe convex model class has more representational power than\nlinear model classes while likely being more tractable and\nstable than non-convex model classes.\nThey show empirical results in Mujoco continuous-control\nenvironments and in an HVAC example.\n\nI think this setup is a promising direction but I have\nsignificant concerns with some of the details and claims\nin this work:\n\n1. Proposition 2 is wrong and the proposed input-convex recurrent\n   neural network architecture not input-convex.\n   To fix this, the D1 parameters should also be non-negative.\n   To show why the proposition is wrong, consider the convexity of y2\n   with respect to x1, using g to denote the activation function:\n\n       z1 = g(U x1 + ...)\n       y2 = g(D1 z1 + ...)\n\n   Thus making\n\n       y2 = g(D1 g(U x1 + ...) + ...)\n\n   y2 is *not* necessarily convex with respect to x1 because D1 takes\n   an unrestricted weighted sum of the convex functions g(U x1 + ...)\n\n   With the ICRNN architecture as described in the paper not being\n   input-convex, I do not know how to interpret the empirical findings\n   in Section 4.2 that use this architecture.\n\n2. I think a stronger and more formal argument should be used to show\n   that Equation (5) is a convex optimization problem as claimed.\n   It has arbitrary convex functions on the equality constraints that\n   are composed with each other and then used in the objective.\n   Even with parts of the objective being convex and non-decreasing\n   as the text mentions, it's not clear that this is sufficient when\n   combined with the composed functions in the constraints.\n\n3. I have similar concerns with the convexity of Equation (6).\n   Consider the convexity of x3 with respect to u1, where g is\n   now an input-convex neural network (that is not recurrent):\n\n       x3 = g(g(x1, u1), u2)\n   \n   This composes two convex functions that do *not* have non-decreasing\n   properties and therefore introduces an equality constraint that\n   is not necessarily even convex, almost certainly making the domain\n   of this problem non-convex. I think a similar argument can be\n   used to show why Equation (5) is not convex.\n\nIn addition to these significant concerns, I have a few other\nminor comments.\n\n1. Figure 1 hides too much information. It would be useful to know,\n   for example, that the ICNN portion at the bottom right\n   is solving a control optimization problem with an ICNN as\n   part of the constraints.\n\n2. The theoretical results in Section 3 seem slightly out-of-place within\n   the broader context of this paper but are perhaps of standalone interest.\n   Due to my concerns above I did not go into the details in this portion.\n\n3. I think more information should be added to the last paragraph of\n   Section 1 as it's claimed that the representational power of\n   ICNNs and \"a nice mathematical property\" help improve the\n   computational time of the method, but it's not clear why\n   this is and this connection is not made anywhere else in the paper.\n\n4. What method are you using to solve the control problems in\n   Eq (5) and (6)?\n\n5. The empirical setup and tasks seems identical to [Nagabandi et al.].\n   Figure 3 directly compares to the K=100 case of their method.\n   Why does Fig 6 of [Nagabandi et al.] have significantly higher rewards\n   for their method, even in the K=5 case?\n\n6. In Figure 5, f_NN seems surprisingly bad in the red region of the\n   data on the left side. Is this because the model is not using\n   many parameters? What are the sizes of the networks used?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A good paper that bridges the gap between neural networks and MPC.",
            "review": "This paper proposes to use input convex neural networks (ICNN) to capture a complex relationship between control inputs and system dynamics, and then use trained ICNN to form a model predictive control (MPC) problem for control tasks.\nThe paper is well-written and bridges the gap between neural networks and MPC.\nThe main contribution of this paper is to use ICNN for learning system dynamics. ICNN is a neural network that only contains non-negative weights. Thanks to this constraint, ICNN is convex with respect to an input, therefore MPC problem with an ICNN model and additional convex constraints on control inputs is a convex optimization problem.\nWhile it is not easy to solve such a convex problem, it has a global optimum, and a gradient descent algorithm will eventually reach such a point. It should also be noted that a convex problem has a robustness with respect to an initial starting point and an ICNN model itself as well. The latter is pretty important, since training ICNN (or NN) is a non-convex optimization, so the parameters in trained ICNN (or NN) model can vary depending on the initial random weights and learning rates, etc. Since a convex MPC has some robustness (or margin) over an error or deviation in system dynamics, while non-convex MPC does not, using ICNN can also stabilize the control inputs in MPC.\nOverall, I believe that using ICNN to from convex MPC is a sample-efficient, non-intrusive way of constructing a controller with unknown dynamics. Below are some minor suggestions to improve this paper.\n\n-- Page 18, there is Fig.??. Please fix this.\n-- In experiments, could you compare the result with a conventional end-to-end RL approach? I know this is not a main point of this paper, but it can be more compelling.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A great work in quality, originality, significance, some questions to authors",
            "review": "The paper proposes neural networks which are convex on inputs data to control problems. These types of networks, constructed based on either MLP or RNN, are shown to have similar representation power as their non-convex versions, thus are potentially able to better capture the dynamics behind complex systems compared with linear models. On the other hand, convexity on inputs brings much convenience to the later optimization part, because there are no worries on global/local minimum or escaping saddle points. In other words, convex but nonlinear provides not only enough search space, but also fast and tractable optimization. The compromise here is the size of memory, since 1) more weights and biases are needed to connect inputs and hidden layers in such nets and 2) we need to store also the negative parts on a portion of weights. \n\nEven though the idea of convex networks were not new, this work is novel in extending input convex RNN and applying it into dynamic control problems. As the main theoretical contribution, Theorem 2 shows that to have same representation power, input convex nets use polynomial number of activation functions, compared with exponential from using a set of affine functions. Experiments also show such effectiveness. The paper is clearly and nicely written. These are reasons I suggest accept.\n\n\nQuestions and suggestions:\n\n1) For Lemma 1 and Theorem 1, I wonder whether similar results can be established for non-convex functions. Intuitively, it seems that as long as assuming Lipschiz continuous, we can always approximate a function by a maximum of many affine functions, no matter it is convex or not. Is this right or something is missing?\n\n2) In the main paper, all experiments were aimed to address ICNN and ICRNN have good accuracy, but not they are easier to optimize due to convexity. In the abstract, it is mentioned \"... using 5X less time\", but I can only see this through appendix. A suggestion is at least describing some results on the comparison with training time in the main paper.\n\n3) In Appendix A, it seems the NN is not trained very well as shown in the left figure. Is this because the number of parameters of NN is restricted to be the same as in ICNN? Do training on both spend the same resource, ie, number of epoch? Such descriptions are necessary here.\n\n4) In Table 2 in appendix, why the running time of ICNN increases by a magnitude for large H in Ant case?\n\n\nTypos:\n\tPage 1 \"simple control algorithms HAS ...\"\n\tPage 7 paragraph \"Baselines\": \"Such (a) method\".\n\tIn the last line of Table 2, 979.73 should be bold instead of 5577.\n\tThere is a ?? in appendix D.4.\n\t\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}