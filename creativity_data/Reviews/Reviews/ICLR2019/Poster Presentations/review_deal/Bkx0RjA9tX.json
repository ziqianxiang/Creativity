{
    "Decision": {
        "metareview": "All reviewers recommend accept. \nDiscussion can be consulted below.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Clear accept ratings from reviewers."
    },
    "Reviews": [
        {
            "title": "Good ideas, more clarification about results/relevant work is necessary",
            "review": "This paper proposes a generative approach to textual QA on SQUAD and visual QA on CLEVR dataset, where, a joint distribution over the question and answer space, given the context (image or Wikipedia paragraphs) is learned (p(q,a|c)). During inference the answer is selected by argmax p(q,a|c) that is equal to p(a|c,q) if the question is given. Authors propose an architecture shown in Fig. 3 of the paper, where generation of each question word is condition on the corresponding answer, context and all the previous words generated in the question so far. The results compared to discriminative models are worse on SQUAD and CLEVR. Nevertheless, authors show that given the nature of the model that captures more complex relationships, the proposed model performs better than other models on a subset of SQUAD that they have created based on answer type (number/date/people), and also on adversarial SQUAD. \n\nComments / questions:\n\nThe paper is well written, except for a few parts mentioned below, all the equations / components are explained clearly. The motivation of the paper is clearly stated as using generative modelling in (V)QA to overcome biases in these systems, e.g., answering questions by just using word matching and ignoring the context (context=image or Wikipedia paragraph). I have the following questions / comments about the paper which addressing them by authors will help to better understand/evaluate the paper:\n1.\tIn page 3 on the top of section 2.3, can authors provide a more clear explanation of the additional 32-dimensional embedding added to each word representation? Also in Table 2, please add an ablation how much gain are you getting from this?\n2.\tIn the same page (page 3), section 2.4, paragraph 2, put the equation in a separate line and number it + clearly explain how you have calculated s^{endpoints} and s{length}.\n3.\tIn page 4 section 2.5.2 paragraph 2, the way the bias term is calculated and the incentive behind it is not clear. Can authors elaborate on this?\n4.\tIn page 6 section 3.2 the first paragraph authors claim that their model is performing multihop reasoning on CLEVR, while there is no explicit component in their model to perform multiple rounds of reasoning. Can authors clarify their statement? \n5.\tIn section 3.3 the third paragraph, where authors explain the question agnostic baselines, can they clarify what they mean by “the first answer of the correct type”? \n6.\tIn Table 5 and section 3.4 the second paragraph, authors are stating that “… The improvement may be due to the model’s attempt to explain all question words, some of which may be unlikely under the distractor”. It is very important that the authors do a complete ablation study similar to that of Table 2 to clarify how much gain is achieved using each component of generative model. \n7.\tIn page 8 under related works: \na.\tIn paragraph 2 where authors state “Duan et al. (2017) and Tang et al. (2017) train answering and generation models with separate parameters, but add a regularisation term that encourages the models to be consistent. They focus on answer sentence selection, so performance cannot easily be compared with our work.”. I do not agree that the performance can not be compared, it is easily comparable by labeling a sentence containing the answer interval as the answer sentence. Can authors provide comparison of their work with that of Duan et al. (2017) and Tang et al. (2017)?\nb.\tIn the same paragraph as 7.a, the authors have briefly mentioned “Echihabi & Marcu (2003) describe an earlier method for answering questions in terms of the distribution of questions given answers.” Can they provide a more clear explanation of this work and its relation to / difference with their work? \n\n////////////\nI would like to thank authors for providing detailed answers to my questions. After reading their feedback, I am now willing to change my score to accept. ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting ideas but weak experiment results",
            "review": "In this paper, authors proposed a generative QA model, which optimizes jointly the distribution of questions and answering given a document/context. More specifically, it is decomposed into two components: the distributions of answers given a document, which is modeled by a single layer neural network; and the distribution of questions given an answer and document, which is modeled by a seq2seq model with a copy mechanism. During inference, it firstly extracts the most likely answer candidates, then evaluates the questions conditioned on the answer candidates and document and finally returns the answer with the max joint score from two aforementioned components.\n\n\nPros: \nThe paper is well written and easy to follow. \n\nThe ideas are also very interesting. \n\nIt gives a good ablation study and shows importance of each component in the proposed model.\n\n\nCons:\nThe empirical results are not good. For example, on the SQuAD dataset, since the proposed model also used ELMo (the large pre-trained contextualized embedding), cross attentions and self-attentions, it should be close or better than the baseline BiDAF + Self Attention + ELMo. However, the proposed model is significantly worse than the baseline (83.7 vs 85.6 in terms of F1 score). From my experience of the baseline BiDAF + Self Attention + ELMo, it obtains 1 more point gain if you fine tune the models.  On CLEVER dataset, I agree that incorporating with MAC cells will help the performance.\n\nIn Table 1, it should be clear if the authors could category those models into with/without ELMo for easy compassion. Furthermore, it is unclear how the authors select those baselines since there are many results on the SQuAD leaderboard. For example, there are many published systems outperformed e.g., RaSOR. \n\nQuestions:\nDuring inference, generating answer candidates should be important. How the number of candidate affects the results and the inference time? \n\nIn SQuAD dataset, its answers often contain one or two tokens/words. What is the performance if removed length of answer feature?\n\nDuring the fine turning step, have you tried other number of candidates?   ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Great idea, well executed, well written",
            "review": "This paper introduces a generative model for question answering.  Instead of modeling p(a|q,c), the authors propose to model p(q,a|c), factorized as p(a|c) * p(q|a,c).  This is a great idea, it was executed very well, and the paper is very well written.  I'm glad to see this idea implemented and working.                                                       \n                                                                                                     \nReactions:                                                                                           \n- Section 2.1: Is there a bias problem here, where you're only ever training with the correct answer?  Oh, I see you covered that in section 2.6.  Great.\n- Section 2.4: what happens when there are multiple QA pairs per paragraph or image?  Are you just getting conflicting gradients at different batches, so you'll end up somewhere in the middle of the two answers?  Could you do better here?\n- Section 2.6: The equation you're optimizing there reduces to -log p(a|q,c), which is exactly the loss function used by typical models.  You should note that here.  It's a little surprising (and interesting) that training on this loss function does so poorly compared to the generative training.  This is because of how you've factorized the distributions, so the model isn't as strong a discriminator as it could be, yes?\n- Section 3.1 (and section 2.6): Can you back up your claim of \"modeling more complex dependencies\" in the generative case?  Is that really what's going on?  How can we know?  What does \"modeling more complex dependencies\" even mean?  I don't think these statements really add anything currently, as they are largely vacuous without some more description and analysis.\n- Section 3.3: Your goal here seems similar to the goal of Clark and Gardner (2018), trying to correctly calibrate confidence scores in the face of SQuAD-like data, and similar to the goals of adding unanswerable questions in SQuAD 2.0.  I know that what you're doing isn't directly comparable to either of those, but some discussion of the options here for addressing this bias, and whether your approach is better, could be interesting.\n                                                                                                     \nClarity issues:                                                                                      \n- Bottom of page 2, \"sum with a vector of size d\" - it's not clear to me what this means.            \n- Top of page 3, \"Answer Encoder\", something is off with the sentence \"For each word representation\" \n- Section 2.5, \"we first embed words independently of the question\" - did you mean \"of the _context_\"?\n- Section 2.5.2 - it's not clear to me how that particular bias mechanism \"allows the model to easily filter out parts of the context which are irrelevant to the question\".  The bias mechanism is independent of the question.\n- Section 2.7 - when you said \"beam search\", I was expecting a beam over the question words, or something.  I suppose a two-step beam search is still a beam search, it just conjured the wrong image for me, and I wonder if there's another way you can describe it that better evokes what you're actually doing.\n- Section 3.1 - \"and are results...\" - missing \"competitive with\"?                                   \n- Last sentence: \"we believe their is\" -> \"we believe there is\" ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}