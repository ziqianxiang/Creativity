{
    "Decision": {
        "metareview": "The paper proposes an adversarial framework that learns a generative model along with a mask generator to model missing data and by this enables a GAN to learn from incomplete data.\nThe method builds on AmbientGAN but it is a novel and clever adjustment to the specific problem setting of learning from incomplete data, that is of high practical interest.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "Intersting idea with practical impact "
    },
    "Reviews": [
        {
            "title": "Good paper but need to rectify few things",
            "review": "This is a good paper, as we have good experimental evidence that the proposed method seems to have some advantage over baseline methods.\n\nThe authors measure the success of their algorithm by computing FID scores for the randomly inputed images. That is the authors use a metric which measures a distance between the distribution of the generated images and images in a dataset. This is fine and interesting to know, but people also care about the distance of the completed pixels from the ground truth (missing) values. (E.g. https://www.cs.rochester.edu/u/jliu/paper/Ji-ICCV09.pdf)\n\nThis is important, because in a real life application, one would pick the mode of the distribution of the missing samples, and not sample from that distribution as the authors seems to be doing in this paper. \n\nI would therefore suggest adding experiments where authors pick the mode of the distribution and estimate an error metric such as root mean square error (RMSE or PSNR https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio ) \n\nI also found the 'marketing'/presentation of the algorithm little misleading, especially in the introduction, given that there exists another GAN based imputation algorithm. I think the authors should clearly state in the introduction that the other algorithm, abbreviated GAIN, exists as a GAN based missing data completion method. Then they should point out the differences of this algorithm from GAIN. Namely they should elaborate verbally on why learning the missing data distribution helps. Overall, what I am trying to say is, the key idea of this paper - that is learning the mask distribution - is not well motivated in this paper. \n\nDespite my concerns above, I recommend an accept. The algorithm seems novel, and there is some experimental results to back it up.  \n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Resolving a major challenge in AmbientGAN, by focusing on a very specific application. ",
            "review": "Building upon the success of AmbientGAN by Bora, Price, and Dimakis, this paper studies one of the major issues that is not resolved in AmbientGAN: the distribution of the data corruption is typically unknown. In general this is an ill-defined problem to solve, as the data corruption distribution is not identifiable from the corrupted data. The major insight of this paper is to identify a plausible setting where such identifiability issues are not present. Namely, the corruption itself is identifiable from the corrupted data. The brilliance of this paper is in identifying this niche application of data imputation/missing data/incomplete data. \n\nOnce the goal is set to train a GAN on incomplete data, the solution somewhat follows in a straightforward manner from AmbientGAN. Pass the generated output through a masking operator, which is also trained. Train the masking operator on the masking pattern of the real (corrupted) data. Imputation generator and discriminator also follows in a straightforward manner. \n\nA major shortcoming of this paper is that the performance of the proposed approach is not fully supported by extensive experiments. For example, a major application of such imputation solution will be predicting missing data in real world applications, such as recommendation systems, or biological experimental data. A experimental setting in \"GAIN: Missing Data Imputation using Generative Adversarial Nets\" provides an excellent benchmark dataset, and imputation approaches should be compared against GAIN in those scenarios. \n\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Nice extension of AmbientGAN with detail experiment analysis",
            "review": "This paper proposed a new network structure to learn GAN with incomplete data, and it is a nice extension of AmbientGAN. Two theorems are provided for better understanding the potential effect of the missing values. Improved results compared with state-of-the-art methods on MNIST, CIFAR-10 and CelebA are presented. Overall, the paper is well organized, and the experiment results are sufficient to demonstrate the advantages of the proposed method. I particular like figure5 where AmbientGAN failed in this case.\n\n Several suggestions about improving the paper. I notice the images used in the experiments are small size. It would be interesting to test the performance on a larger image. Another direction would be testing the robustness of the model, for example, what will happen if the observation is also noisy? Some discussion about the potential extensions will also be helpful. For example, can the proposed network be used to solve the compressive sensing problem with a real value mask instead of binary valued. \n\nI did not dive into the detail of the prove of theorems. And it seems valid by reading through each step.  Although these two theorems are not directly related to the properties of the proposed network structure. But it does provide some nice intuition.\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}