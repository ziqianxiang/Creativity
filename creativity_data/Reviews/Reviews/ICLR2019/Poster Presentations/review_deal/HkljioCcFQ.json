{
    "Decision": {
        "metareview": "The paper proposes a new attentional pooling mechanism that potentially addresses the issues of simple attention-based weighted averaging (where discriminative parts/frames might get disportionately high attentions). A nice contribution of the paper is to propose an alternative mechanism with theoretical proofs, and it also presents a method for fast recurrent computation. The experimental results show that the proposed attention mechanism improves over prior methods (e.g., STPN) on THUMOS14 and ActivityNet1.3 datasets. In terms of weaknesses: (1) the computational cost may be quite significant. (2) the proposed method should be evaluated over several tasks beyond activity recognition, but it’s unclear how it would work. \n\nThe authors provided positive proof-of-concept results on weakly supervised object localization task, improving over CAM-based methods. However, CAM baseline is a reasonable but not the strongest method and the weakly-supervised object recognition/segmentation domains are much more competitive domains, so it's unclear if the proposed method would achieve the state-of-the-art by simply replacing the weighted-averaging-attentional-pooling with the proposed attention mechanism. In addition, the description on how to perform attentional pooling over images is not clearly described (it’s not clear how the 1D sequence-based recurrent attention method can be extended to 2-D cases). However, this would not be a reason to reject the paper. \n\nFinally, the paper’s presentation would need improvement. I would suggest that the authors give more intuitive explanations and rationale before going into technical details. The paper starts with Figure 1 which is not really well motivated/explained, so it could be moved to a later part. Overall, there are interesting technical contributions with positive results, but there are issues to be addressed.\n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "metareview"
    },
    "Reviews": [
        {
            "title": "Could this paper be used for other tasks beyond video action understanding?",
            "review": "This paper considers the problem of weakly-supervised temporal action localization. It proposes a marginalized average attention network (MAAN) to suppress the effect of overestimating salient regions.  Theoretically, this paper proves that the learned latent discriminative probabilities reduce the difference of responses between the most salient regions and the others. In addition, it develops a fast algorithm to reduce the complexity of constructing MAA to O(T^2). Experiments are conducted on THUMOST14 and ActivityNet 1.3.\n\nI like the theoretical part of this paper but have concerns about the experiments. More specifically, my doubts are\n\n- The I3D network models are not trained from scratch. The parameters are borrowed from (Carreira and Zisserman 2017), which in fact make the attention averaging very easy. I don’t know whether the success is because the proposed MAAN is working or because the feature representation is very powerful.\n\n- If possible, I wish to see the success of the proposed method for other tasks, such as image caption generation, and machine translation.  If the paper can show success in any of such task, I would like to adjust my rating to above acceptance.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Well executed paper on a reasonable idea",
            "review": "Summary\nThis paper proposed a stochastic pooling method over the temporal dimension for weakly-supervised video localization problem. The main motivation is to resolve a problem of discriminative attention that tends to focus on a few discriminative parts of an input data, which is not desirable for the purpose of dense labeling (i.e. localization). The proposed stochastic pooling method addressed this problem by aggregating all possible subsets of snippets, where each subset is constructed by sampling snppets from learnable sampling distribution. The proposed method showed that such approach learns more smooth attention both theoretically and empirically.\n\nClarity:\nThe paper is well written and easy to follow. The ideas and methods are clearly presented.\n\nOriginality and significance:\nThe proposed stochastic pooling is novel and demonstrated that empirically useful. Given that the proposed method can be generally applicable to other tasks, I think the significance of the work is also reasonable. One suggestion is applying the idea to semantic segmentation, which also shares a similar problem setting but easier to evaluate its impact than videos. Similar to (Zhou et al. 2016), you can plug the proposed pooling method on top of CNN feature map instead of global average pooling, which might be doable with the more affordable computational cost since the number of hidden units for pooling is much smaller than the length of videos (N < T). \n\nOne downside of the proposed method is its computational complexity (O(T^2)). This is much higher than the one for other feedforward methods (O(T)), which can be easily parallelized (O(1)). This can be a big problem when we have to handle very long sequences too (increasing the length of snippets could be one alternative, but it is not desirable for localization at the end). Considering this disadvantage, the performance gain by the proposed method may not be considered attractive enough. \n\nExperiment:\nOverall, the experiment looks convincing to me. \n\nMinor comments:\nCitation error: Wrong citation: Nguyen et al. CVPR 2017 -> CVPR 2018\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Overly-complicated explanation of method, qualitative and quantitative results do not clearly reflect the proposed contribution.",
            "review": "In this paper the authors focus on the problem of weakly-supervised action localization. The authors state that a problem with weakly-supervised attention based methods is that they tend to focus on only the most salient regions and propose a solution to this which reduces the difference between the responses for the most salient regions and other regions. They do this by employing marginalized average aggregation to averaging a sample a subset of features in relation to their latent discriminative probability then calculating the expectation over all possible subsets to produce a final aggregation.\n\nThe problem is interesting, especially noting that current attention methods suffer from paying attention to the most salient regions therefore missing many action segments in action localization. The authors build upon an existing weakly-supervised action localization framework, having identified a weakness of it and propose a solution. The work also pays attention to the algorithm's speed which is practically useful. The experiments also compare to several other potential feature aggregators.\n\nHowever, there are several weakness of the current version of the paper:\n\n- In parts the paper feels overly complicated, particularly in the method (section 2). It would be good to see more intuitive explanations of the concepts introduce here. For instance, the author's state that c_i captures the contextual information from other video snippets, it would be good to see a figure with an example video and the behaviour of p_i and c_i as opposed to lamba_i. I found it difficult to map p_i, c_i to z and lambda used elsewhere.\n\n- The experimental evidence does not show where the improvement comes from. The authors manage to acheieve a 4-5% improvement over STPN through their re-implemenation of the algorithm, however only have a ~2% improve with their marginalized average attention on THUMOS. I would like to know the cause in the increase over the original STPN results: is it a case of not being able to replicate the results of STPN or do the different parameter choices, such as use of leakly RELU, 20 snippets instead of 400 and only rejecting classes whose video-level probabilities are below 0.01 instead of 0.1, cause this big of an increase in results? There is also little evidence that the actual proposal (contextual information) is the reason for the reported improvement.\n\n- There seems to be several gaps in the review of current literature. Firstly, the authors refer to Wei et al. 2017 and Zhang et al. 2018b as works which erase the most salient regions to be able to explore regions other than the most salient. The authors state that the problem with these methods is that they are not end-to-end trainable, however Li et al. 2018 'Tell Me Where to Look': Guided Attention Inference Network' proposes a method which erases regions which is trainable end-to-end. Secondly, the authors do not mention the recent work W-TALC which performs weakly-supervised action localization and outperforms STPN. It would be good to have a baseline against this method.\n\n- The qualitative results in this paper are confusing and not convincing. It is true that the MAAN's activation sequence shows peaks which correspond to groundtruth and are not present in other methods. However, the MAAN activation sequence also shows several extra peaks not present in other methods and also not present in the groundtruth, therefore it looks like it is keener to predict the presence of the action causing more true positives, but also more false positives. It would be good to see some discussion of these failure cases and/or more qualitative results. The current figure could be easily compressed by only showing one instance of the ground-truth instead of one next to each method.\n\nI like the idea of the paper however I am currently unconvinced by the results that this is the correct method to solve the problem.\n",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}