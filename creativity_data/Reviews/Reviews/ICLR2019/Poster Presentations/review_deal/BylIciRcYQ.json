{
    "Decision": {
        "metareview": "The proposed notion of star convexity is interesting and the empirical work done to provide evidence that it is indeed present in real-world neural network training is appreciated.  The reviewers raise a number of concerns. The authors were able to convince some of the reviewers with new experiments under MSE loss and experiments showing how robust the method was to the reference point. The most serious concerns relate to novelty and the assumptions that individual functions share a global minima with respect to which the path of iterates generated by SGD satisfies the star convexity property. I'm inclined to accept the authors rebuttal, although it would have been nicer had the reviewer re-engaged. Overall, the paper is on the borderline.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "New notion of nonconvexity"
    },
    "Reviews": [
        {
            "title": "The paper provides interesting idea but the empirical results may be biased due to ill-posed problem ",
            "review": "The paper proposes a new approach to explain the effective behavior of SGD in training deep neural networks by introducing the notion of star-convexity. A function h is star-convex if its global minimum lies on or above any plane tangent to the function, namely h* >= h(x) + < h'(x), x*-x> for any x. Under such condition, the paper shows that the empirical loss goes to zero and the iterates generated by SGD converges to a global minimum. Extensive experiments has been conducted to empirically validate the assumption. \n\nThe paper is very well organized and is easy to follow. The star-convexity assumption is very interesting which provides new insights about the landscape of the loss function and the trajectory of SGD. It is in general difficult to theoretically check this condition so several empirical verifications has been proposed. My main concern is about these empirical verifications.\n\n1) The minimum of the cross entropy loss lies at infinity \nThe experiments are performed respect to the cross entropy loss. However, cross entropy loss violates Fact 1 since for any finite weight, cross entropy loss is always strictly positive. Thus the zero is never attained and the global minimum always lies at infinity. As a result, the star-convexity inequality h* >= h(x) + < h'(x), x*-x> hardly makes sense since x* is at infinity and neither does the theorem followed. \nIn this case, a plot of the norm of xk is highly suggested since it is a sanity check to see whether the iterates goes to infinity. \n\n2) The phenomenon may depend on the reference point, i.e last iterate\nSince the minimum is never attained, the empirical check of the star-convexity maybe biased. More precisely, it might be possible that the behavior of the observed phenomenon depends on the reference point, i.e. the last iterate. Therefore, it will be interesting to see if the observed phenomenon still holds when varying the stopping time, for instance plot the star convexity check using the iterates at 60, 80, 100, 120 epochs as reference point. \n\nIn fact, the experiments shown in Figure 4 implicitly supports that the behavior may change dramatically respect to different reference point. The reason is that the loss in these experiments are far away from 0, meaning that we are far from the minimum, thus checking the star-convexity does not make sense because the star-convexity is only defined respect to the minimum. \n\nOverall, the paper provides interesting idea but the empirical results may be biased due to ill-posed problem ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting paper, but maybe less significant than it appears to be",
            "review": "This paper attempts to account for the success of SGD on training deep neural networks. Starting from two empirical observations: (1) deep neural networks can almost achieve zero training loss; (2) the path of iterates generated by SGD on these models follow approximately the “star convex path”, under the assumptions that individual functions share a global minima with respect to which the path of iterates generated by SGD satisfies the star convexity properties, the papers shows that the iterates converges to the global minima. \n\nIn terms of clarity, I think the paper can definitely benefit if the observations/assumptions/definitions/theorems are stated in a more formal and mathematically rigorous manner. For example:\n- On page 3, “fact 1”: I don’t think “fact” is the right word here. “Fact” refers to what has been rigorously proved or verified, which is not the case for what is in the paper here. I believe “observation” is more appropriate. Also the assumption that l_i is non-negative should be formally added.\n- On page 3, section 3.1: the x^* here is the last iteration produced by SGD. Then how can it be called the “global minima”? The caption of Figure 1 on page 4 is simply misleading.\n- On page 4, the statement in definition 1 is more like a theorem than a definition. It is giving readers the impression that any path generated by SGD satisfies the star-convex condition, which is not the case here. A definition should look like “we call a path generated by SGD a star-convex path if it satisfies …”. Definition 2 on page 6 has the similar issue.\n\nIn terms of quality, while I believe the paper is technically correct,  I have one minor question here:\nPage 3, Fact 1: How can you conclude that the set of common global minimizers are bounded? In fact I don’t believe this is true at all in general. If you have a ReLu network, you can scale the parameters as described in [1], then the model is invariant. Therefore, the set of common minimizer is definitely NOT bounded. \n\nIn terms of significance, I think this paper is very interesting as it attempts to draw the connection between the aforementioned observations and the convergence properties of SGD. Unfortunately I think that this paper is less significant than it has appeared to be, although the analysis appears to be correct. \n\nFirst of all, all the analysis of this paper is based on one very important and very strong assumption, namely, all individual functions $l_i$ share at least one common global minimizer. The authors have attempted to justify this assumption by empirical evidences (figure 1). However, achieving near-zero loss is completely different from achieving exact zero because only when the model achieves exact zero can you argue that a common global minimizer exists. \n\nSecondly, the claim that the iterate converges to the global minima is based on the assumption that the path follows an “epoch-wise star-convex” property. From this property, it only takes simple convex analysis to reach the conclusion of theorem 1 and 2. Meanwhile, the assumption that the path does follow the “epoch-wise start-convex” properties is not at all informative. It is not clear why or when the path would follow such a path. Therefore theorem 1 and 2 are not more informative than simply assuming the sequence converges to a global minimizer. \n\nIn fact, it is well-known that SGD with constant stepsize converges to the unique minimizer if one assumes the loss function F is strongly convex and the variance of the stochastic gradient g_k is bounded by a multiple of the norm-square of the true gradient:\nVar(g_k) <= M ||∇F(x_k)||^2\nWhich is naturally satisfied if all individual functions share a common minimizer. Therefore, I don’t think the results shown in the paper is that surprising or novel. \n\nWith respect to the empirical evidence, the loss function l_i is assumed to be continuously differentiable with Lipschitz continuous gradients, which is not true for networks using ReLU-like activations. Then how can the paper use models like Alexnet to justify the theory? Also, if what the authors claim is true, then the stochastic gradient would have vanishing variance as it approaches x^*. Can the authors show this empirically?\n\nIn summary, I think this paper is definitely interesting, but the significance is not as much as it would appear.\n\nRef: \n[1] Dinh, L., Pascanu, R., Bengio, S., & Bengio, Y. (2017). Sharp minima can generalize for deep nets. arXiv preprint arXiv:1703.04933.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Good theoretical paper",
            "review": "This paper analyzed the global convergence property of SGD in deep learning based on the star-convexity assumption. The claims seem correct and validated empirically with some observations in deep learning. The writing is good and easy to follow.\n\nMy understanding of the analysis is that all the claims seem to be valid when the solution is in a wide valley of the loss surface where the star-convexity holds, in general. This has been observed empirically in previous work, and the experiments on cifar10 in Fig. 2 support my hypothesis. My questions are:\n\n1. How to guarantee the star-convexity will be valid in deep learning?\n2. What network or data properties can lead to such assumption?\n\nAlso, this is a missing related work from the algorithmic perspective to explore the global optimization in deep learning: \n\nZhang et. al. CVPR'18. \"BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning\".\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}