{
    "Decision": {
        "metareview": "This paper introduces a new graph neural network architecture designed to learn to solve Circuit SAT problems, a fundamental problem in computer science. The key innovation is the ability to to use the DAG structure as an input, as opposed to typical undirected (factor graph style) representations of SAT problems. The reviewers appreciated the novelty of the approach as well as the empirical results provided that demonstrate the effectiveness of the approach.  Writing is clear. While the comparison with NeuroSAT is interesting and useful, there is no comparison with existing SAT solvers which are not based on learning methods. So it is not clear how big the gap with state-of-the-art is. Overall, I recommend acceptance, as the results are promising and this could inspire other researchers working on neural-symbolic approaches to search and optimization problems.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Good paper, comparison with traditional SAT solvers would be helpful"
    },
    "Reviews": [
        {
            "title": "Possibly interesting ideas, but needs more experiments",
            "review": "The paper proposes a graph neural network architecture that is designed to use the DAG structure in the input to learn to solve Circuit SAT problems. Unlike graph neural nets for undirected graphs, the proposed network propagates information according to the edge directions, using a deep sets representation to aggregate over predecessors of each vertex and GRUs to implement recurrent steps. The network is trained by using a \"satisfiability function\" which takes soft variable assignments computed by the network and applying a relaxed version of the circuit to be solved (replacing AND with softmax, OR with softmin, and NOT with 1 - variable value) to compute a continuous score that measures how satisfying the assignment is. Training is done by maximizing this score on a dataset of problem instances that are satisfiable. Results are shown on random k-SAT and graph coloring problems.\n\nThe paper is reasonably well-written and easy to follow. The idea of using the relaxed version of the circuit for training is nice. Combining ideas from DAG-RNNs and Deep Sets is interesting, although incremental.\n\nCriticisms:\n- How much does tailoring the network architecture to the DAG structure of the circuit actually help? A comparison to a regular undirected graph neural network on the circuit input without edge directions would be useful. In particular, since both edge directions are used in the current architecture but represented as two different DAGs, it naturally raises the question of whether a regular undirected graph neural net would also work well.\n- How does the proposed approach compare to the current state-of-the-art non-learning approaches to SAT (CDCL, local search, etc.)? There is a huge literature on SAT, and ignoring all that work and comparing to only NeuroSAT seems unjustified. Without such comparisons, it is hard to say what is the benefit learning approaches in general, and the specific approach in this paper, provide in this domain. Even basic sanity-check baselines, e.g., random search, can be valuable given that the domain is somewhat new to learning approaches.\n- One way to interpret the proposed approach is that it is learning to propose soft assignments that can be easily rounded. It would be good to compare to a Linear Programming relaxation-based approach that represents the SAT instance as an integer program with binary variables, relaxes the variables to be in [0,1], solves the resulting linear program, and rounds the solution. Do these approaches share the same failure modes, how does their performance differ, etc.\n- The proposed approach has an obvious advantage over NeuroSAT in that it has access to the circuit structure, in addition to the flat representation of the SAT instance. According to the paper, not providing the circuit structure to the proposed approach hurts its performance. It would be useful to devise an experiment where a modified version of NeuroSAT is given the circuit structure as an additional input to see whether that closes the gap between the approaches.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "strong paper ",
            "review": "The Authors of this paper investigate Neuro-Symbolic methods in the context of learning a SAT solver generalized to the Circuit-SAT problem. Using a reinforcement learning â€“ inspired approach to demonstrate a framework that is capable of (unsupervised) learning, by means of an end-to-end differentiable training procedure. Their formulation incorporates the solving of a given SAT problem into the architecture, meaning the algorithm is trained to produce a solution if a given problem is satisfiable. This is in contrast to previous similar work by (Selsam et al. 2018), where the framework was trained as a SAT classifier. Their results outline the performance increase over the previous work (Selsam et al. 2018) on finding a given solution for a SAT problem, on in-sample and out-sample results.\n\nNeg: \nFigure descriptions are not very clear\nWhen it comes to comparing the results, they do use a prepossessing step for their algorithm which they do not incorporate into the results\n\nPros:\nClear outline of the data sets used for benchmarks.\nGood Literature review, expressing in-depth knowledge of the current state of the art formulation for same/similar tasks \nExtensive background section, that explains the theoretical concepts and their architecture used well.\nClear outline of the Solver, where the individual parts/networks are explained and justified in detail\nVery well outlined argumentation for approaching this particular problem by the proposed method/\nThe experimental results as well are easy to follow and show promising results for the proposed framework\nThe proposed method as well is novel and outperforms similar algorithms in the experimental evaluation.\n\n\nThe paper is very well written, proposes a novel Neuro-Symbolic  approach to the classical SAT problem, and demonstrates promising results.\n ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review for Circuit-SAT",
            "review": "The paper makes a nice contribution to solving Circuit-SAT problem from a Neuro-Symbolic approach, particularly, 1) a novel DAG embedding with a forward layer and a reverse layer that captures the structural information of a circuit-sat input. 2) Compared with Selsam et al.'s work of Neuro-SAT, the proposed model in this paper, DG-DAGRNN, directly produces an assignment of variables, and the method is unsupervised and end-to-end differentiable. 3) Empirical experiments on random k-SAT and random graph k-coloring instances that support the authors' claim on better generalization ability.\n\nThe paper is lucid and well written, I would support its acceptance at ICLR. Though I have a few comments and questions for the authors to consider.\n\n- In figure 1 (a), what are x11, x12, etc?\n\n- When comparing the two approaches of Neuro-Symbolic methods, besides the angles of optimality and training cost, it is worth to mention that the first one that based on classical algorithms always has a correctness guarantee, while the second one (learning the entire solution from scratch) usually does not.\n\n- Section 4.1, as a pure decision problem, solving SAT means that giving a yes/no answer (i.e., a classification); while for practical purposes, solving SAT means that producing a model (i.e., a witness) of the formula if it is SAT. This can be misleading for some readers when the authors mentioning \"solving SAT\", and it would be clear if the authors could make a distinction when using such terms.\n\n- Section 4.1, \"without requiring to see the actual SAT solutions during training\", again, what is the meaning of \"solutions\" is not very clear at this point. Readers may realize the experiments in the paper only train with satisfiable formulae from the afterward description, so the \"solutions\" indicates the assignments of variables. But it would be better to make it clear.\n\n- Section 4.1/The Evaluator Network, \"one can show also show that min() < S_min() <= S_max() < max()\", what is the ordering relation (i.e., < and <=) here? It is a bit confusing if a forall quantifier for inputs (a_1, ... a_n) is required here.\n\n- Section 4.1/The Evaluator Network, how does the temperature affect the results of R_G? It would be helpful to show their dynamics.\n\n- Section 4.1/Optimization, \"if the input circuit is UNSAT, one can show that the maximum achievable values for S_\\theta is 0.5\", it would be better to provide a brief description of how it is guaranteed. Also, this seems to be suggesting the DG-SAGRNN solver has no false positives, i.e., it will never produce a satisfiable result for unsatisfiable formulae? This would be interesting toward some semi-correctness if the answer is yes.\n\n- Section 5.1, are the testing data all satisfiable formulae? If yes, then the figure 2 shows there is a number of satisfiable formulae but both the models cannot produce correct results -- is that a correct understanding of figure 2? If not, then what is the ground truth?\n\n- I would love to see more experiments on SAT instances with a moderate number of variables but from real-world applications. It would be interesting to see how the model utilizes the rich structural information of instances from real applications (instead of randomly generated formulae).\n\n- The training time and testing time(per instance) are not reported in the experiments.\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}