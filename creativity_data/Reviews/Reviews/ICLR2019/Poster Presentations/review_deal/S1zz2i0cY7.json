{
    "Decision": {
        "metareview": "This paper addresses the issue of numerical rounding-off errors that can arise when using latent variable models for data compression,  e.g., because of differences in floating point arithmetic across different platforms (sender and receiver). The authors propose using neural networks that perform integer arithmetic (integer networks) to mitigate this issue. The problem statement is well described, and the presentation is generally OK, although it could be improved in certain aspects as pointed out by the reviewers. The experiments are properly carried out, and the experimental results are good.\nThank you for addressing the questions raised by the reviewers. After taking into account the author's responds, there is consensus that the paper is worthy of publication. I therefore recommend acceptance. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Interesting solution to a practical problem"
    },
    "Reviews": [
        {
            "title": "Interesting read; would be helpful to better explain difficulties in training",
            "review": "This well-written paper addresses the restrictions imposed by binary communication channels on the deployment of latent variable models in practice. In order to range code the (floating point) latent representations into bit-strings for practical data compression, both the sender and receiver of the binary channel must have identical instances of the prior despite non-deterministic floating point arithmetic across different platforms. The authors propose using neural networks that perform integer arithmetic (integer networks) to mitigate this issue.\n\nPros:\n- The problem statement is clear, as well as the approach taken to addressing the issue.\n- Section 5 did a nice job tying together the relevant literature on using latent variable models for compression with the proposed integer network framework.\n- The experimental results are good; particularly, Table 1 provides a convincing case for how using integer networks remedies the issue of decompression failure across heterogeneous platforms.\n\nCons:\n- In Section 3, it wasn’t clear to me as to why the authors were using their chosen gradient approximations with respect to H’, b’ and c’. Did they try other approximations but empirically find that these worked best? Where did the special rescaling function s come from? Some justifications for their design choices would be appreciated. \n- The authors state in Section 2 that the input scaling is best determined empirically -- is this just a scan over possible values during training? This feels like an added layer of complexity when trying to train these networks. It would be nice if the authors could provide some insight into exactly how much easier/difficult it is to train integer networks as opposed to the standard floating point architectures.\n- In Section 6, the authors state that the compromised representational capacity of integer networks can be remedied by increasing the number of filters. This goes back to my previous point, but how does this “larger” integer network compare to standard floating point networks in terms of training time?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Application paper: how to modify latent variable models s.t. they survive range coding transmission.",
            "review": "This paper explains that range coding as a mechanism for transmitting latent-variable codes from source to target for decoding is severely sensitive to floating point errors.\n\nThe authors propose what amounts to an integer version of Balle 2018, and demonstrate that it allows for transmission between platforms without catastrophic errors due to numerical round-off differences.\n\nThe paper (and problem) is of low significance, but the authors present a neat solution.\n\nPros:\n- Well defined problem and solution.\n- Practical question relating to use of ANNs for data en/de-coding.\n\nCons:\n- Presentation needs brushing up: e.g. why give two examples for H, b, v bit widths?\n- Some approximations are not well motivated or justified.  E.g. why is it valid to replace gradient of a function that has 0 gradients with the identity?\n- Paper needs some rewriting for clarity.  E.g. where is the kernel K defined?\n- Lack of experimentation to justify the fact that the construction of (16) leads to instabilities, and is therefore less suitable than the method outlined here.  \n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An interesting approach for a very important problem",
            "review": "The paper presents a very important problem of utilizing a model on different platforms with own numerical round-offs. As a result, a model run on a different hardware or software than the one on which it was trained could completely fail due to numerical rounding-off issues. This problem has been considered in various papers, however, the classification task was mainly discussed. In this paper, on the other hand, the authors present how the numerical rounding-off issue could be solved in Latent-Variable Models (LVM).\n\nIn order to cope with the numerical rouding-off issue, the authors propose to use integer networks. They consider either quantized ReLU (QReLU) or quantized Tanh (Qtanh). Further, in order to properly train the integer NN, they utilize a bunch of techniques proposed in the past, mainly (Balle, 2018) and (Balle et al., 2018). However, as pointed out in the paper, some methods prevent training instabilities (e.g., Eqs. 18 and 19). All together, the paper tackles very important problem and proposes very interesting solution by bringing different techniques proposed for quantized NNs together .\n\nPros:\n+ The paper is well-written.\n+ The considered problem is of great importance and it is rather neglected in the literature.\n+ The experiments are properly carried out.\n+ The obtained results are impressive.\n\nCons:\n- A natural question is whether the problem could be prevented by post-factum quantization of a neural network. As pointed out in the Discussion section, such procedure failed. However, it would be beneficiary to see an empirical evidence for that.\n- It would be also interesting to see how a training process of an integer NN looks like. Since the NN is quantized, instabilities during training might occur. Additionally, its training process may take longer (more epochs) than a training of a standard (float) NN. An exemplary plot presenting a comparison between an integer NN training process and a standard NN training process would be highly appreciated.\n- (Minor remark). The paper is well-written, however, it would be helpful to set the final learning algorithm. This would drastically help in reproducibility of the paper.\n\n--REVISION--\nAfter reading the authors response and looking at the new version of the paper I decided to increase my score. The paper tackles very important problem and I strongly believe it should be presented during the conference.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}