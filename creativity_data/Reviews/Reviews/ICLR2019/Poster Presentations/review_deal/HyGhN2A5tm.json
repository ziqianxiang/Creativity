{
    "Decision": {
        "metareview": "A paper that studies two tasks: machine translation and image translation. The authors propose a new multi-agent dual learning technique that takes advantage of the symmetry of the problem. The empirical gains over a competitive baseline are quite solid. The reviewers consistently liked the paper but have in some cases fairly low confidence in their assessment.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Accept"
    },
    "Reviews": [
        {
            "title": "Straightforward Idea, pretty good results, some things should be clarified (potential issue with the maths).",
            "review": "Summary\n\nThe paper proposes to modify the \"Dual Learning\" approach to supervised (and unsupervised) translation problems by making use of additional pretrained mappings for both directions (i.e. primal and dual). These pre-trained mappings (\"agents\") generate targets from the primal to the dual domain, which need to be mapped back to the original input. It is shown that having >=1 additional agents improves training of the BLEU score in standard MT and unsupervised MT tasks. The method is also applied to unsupervised image-to-image \"translation\" tasks.\n\nPositives and Negatives\n+1 Simple and straightforward method with pretty good results on language translation.\n+2 Does not require additional computation during inference, unlike ensembling.\n-1 The mathematics in section 3.1 is unclear and potentially flawed (more below).\n-2 Diversity of additional \"agents\" not analyzed (more below).\n-3 For image-to-image translation experiments, no quantitative analysis whatsoever is offered so the reader can't really conclude anything about the effect of the proposed method in this domain.\n-4 Talking about \"agents\" and \"Multi-Agent\" is a somewhat confusing given the slightly different use of the same term in the reinforcement literature. Why not just \"mapping\" or \"network\"?\n\n-1: Potential Issues with the Maths.\n\nThe maths is not clear, in particular the gradient derivation in equation (8). Let's just consider the distortion objective on x (of course it also applies to y without loss of generality). At the very least we need another \"partial\" sign in front of the \"\\delta\" function in the numerator. But again, it's not super clear how the paper estimates this derivative.  Intuitively the objective wants f_0 to generate samples which, when mapped back to the X domain, have high log-probability under G, but its samples cannot be differentiated in the case of discrete data. So is the REINFORCE estimator used or something? Not that the importance sampling matter is orthogonal. In the case of continuous data x, is the reparameterization trick used? This should at the very least be explained more clearly.\n\nNote that the importance sampling does not affect this issue.\n\n-2: Diversity of Agents.\n\nAs with ensembles, clearly it only helps to have multiple agents (N>2) if the additional agents are distinct from f_1 (again without loss of generality this applies to g as well). The paper proposes to use different random seeds and iterate over the dataset in a different order for distinct pretrained f_i. The paper should quantify that this leads to diverse \"agents\". I suppose the proof is in the pudding; as we have argued, multiple agents can only improve performance if they are distinct, and Figure 1 shows some improvement as the number of agents are increase (no error bars though). The biggest jump seems to come from N=1 -> N=2 (although N=4 -> N=5 does see a jump as well). Presumably if you get a more diverse pool of agents, that should improve things. Have you considered training different agents on different subsets of the data, or trying different learning algorithms/architectures to learn them? More experiments on the diversity would help make the paper more convincing.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Applying ensembles to machine translation appears to result in good performance on language and image translation",
            "review": "The author's present a dual learning framework that, instead of using a single mapping for each mapping task between two respective domains, the authors learn multiple diverse mappings. These diverse mappings are learned before the two main mappings are trained and are kept constant during the training of the two main mappings. Though I am not familiar with BLEU scores and though I didn't grasp some of the details in 3.1, the algorithm yielded consistent improvement over the given baselines. The author's included many different experiments to show this.\n\nThe idea that multiple mappings will produce better results than a single mapping is reasonable given previous results on ensemble methods. \n\nFor the language translation results, were there any other state-of-the-art methods that the authors could compare against? It seems they are only comparing against their own implementations.\n\nObjectively saying that the author's method is better than CycleGAN is difficult. How does their ensemble method compare to just their single-agent dual method? Is there a noticeable difference there?\n\nMinor Comments:\n\nDual-1 and Dual-5 are introduced without explanation.\n\nPerhaps I missed it, but I believe Dan Ciresan's paper \"Multi-Column Deep Neural Networks for Image Classification\" should be cited.\n\n### After reading author feedback\nThank you for the feedback. After reading the updated paper I still believe that 6 is the right score for this paper. The method produces better results using ensemble learning. While the results seem impressive, the method to obtain them is not very novel; nonetheless, I would not have a problem with it being accepted, but I don't think it would be a loss if it were not accepted.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Extensive experiments and results, but not enough contribution",
            "review": "Summary:\nThe authors propose an extension of dual learning (DL). In DL, one leverages the duality of a dataset, by predicting both forward and backward, e.g. English to German, and German back to English. It’s been shown that training models using this duality is beneficial. This paper extends DL by introducing multiple models for the forward and backward, and using their output to regularise the training of the two main agents.\n\nThe authors show that this setup improves on the SotA, at only a training computation expense (inference/test time remains the same).\n\nReview:\nThe paper shows extensive experimentation and improves the previous result in all cases. The proposed method is a straightforward extension and can be readily implemented and used.\n\nI have difficulty understanding equation 8 and the paragraph below. It seems like the authors use an equal weighting for the additional agents, however they mention using Monte Carlo to “tackle the intractability resulting form the summation over the exponentially large space y”. According to the paper the size of y is the dataset, is it exponentially large? Do the authors describe stochastic gradient descent? Also what do the authors mean by offline sampling? Do they compute the targets for f_0 and g_0 beforehand using f_1…n and g_1…n?\n\nThe results mention computational cost a few times, I was wondering if the authors could comment on the increase in computational cost? e.g. how long does “pre-training” take versus training the dual? Can the training of the pre-trained agents be parallelised? Would it be possible to use dropout to more computationally efficient obtain the result of an ensemble?\n\nIn general I think the authors did an excellent job validating their method on various different datasets. I also think the above confusions can be cleared up with some editing. However the general contribution of the paper is not enough, the increase in performance is minimal and the increased computational cost/complexity substantial. I do think this is a promising direction and encourage the authors to explore further directions of multi-agent dual learning.\n\nTextual Notes:\n- Pg2, middle of paragraph 1: “which are pre-trained with parameters fixed along the whole process”. This is unclear, do you mean trained before optimising f_0 and g_0 and subsequently held constant?\n- Pg2, middle last paragraph: “typical way of training ML models”. While the cross entropy loss is a popular loss, it is not “typical”.\n- Pg 3, equation 4, what does “briefly” mean above the equal sign?\n- Perhaps a title referring to ensemble dual learning would be more appropriate, given the possible confusion with multi agent reinforcement learning. \n\n\n################\nRevision:\n\nI would like to thank the authors for the extensive revision, additional explanations/experiments, and pointing out extensive relevant literature on BLUE scores. The revision and comments are much appreciated. I have increased my score from 4 to 6.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}