{
    "Decision": {
        "metareview": "as r1 and r2 have pointed out, this work presents an interesting and potentially more generalizable extension of the earlier work on introducing noise as regularization in autoregressive language modelling. although it would have been better with more extensive evaluation that goes beyond unsupervised language modelling and toward conditional language modelling, but i believe this is all fine for this further work to be left as follow-up.\n\nr3's concern is definitely valid, but i believe the existing evaluation set as well as exposition merit presentation and discussion at the conference, which was shared by the other reviewers as well as a programme chair.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "accept"
    },
    "Reviews": [
        {
            "title": "Interesting paper.",
            "review": "The paper presents a Bayesian/ variational interpretation of data noising in recurrent networks (Xie et al. 2017). Overall I found the paper interesting and well presented.\n\nThe authors first review the work of Xie et al. 2017, that proposes data noisy for regularizing recurrent networks. This is done by randomly replacing certain words in the context according to some distribution. Xie et al. 2017 showed that this is highly related to smoothing in n-gram models.\n\nThe authors take a Bayesian approach where there is a prior over the parameters p(W) . Computing the posterior for RNNs is generally intractable so they suggest using a variational distribution q(W) instead. They show how certain choices of the variational distribution give a similar effect to different types of smoothing (e.g. linear interpolation and Kneser Ney), as well as show how for instance, combining smoothing with dropout fits into their theory. \n\nExperimenetal results show that their approach outperforms vanilla LSTMs and the approach of Xie et al. 2017 on PTB and Wikitext-2 which are two common (although small) benchmarks for language modeling.\n\nThe paper could be improved by running a comparison on larger dataset (e.g. billion word benchmark Chelba et al. 2013)\n\n \n\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A data noising technique motivated by Bayes RNN and smoothing",
            "review": "This submission closely builds upon an earlier work (Xie et al., 2017, Gal and Ghahramani, 2016) and proposes a new data noising technique motivated by Bayesian RNNs. Specifically, the key contribution is to extend Gal and Ghahramani (2016) to word embedding noising, while drawing inspiration from trational data smoothing techniques. Some variants are discussed, including those motivated by linear interpolation and Kneser-Ney smoothing, just as in Xie et al., 2017. Empirical evaluation is performed with language modeling experiments, and the proposed methods outperforms comparable baselines. One can imagine such a technique could be useful in many other sequence tasks. \n\nThe paper is well-motivated and clearly written, and the experiments seem reasonable to me. Therefore I would vote for acceptance. My concern, which is not major, is that the proposed method might be a bit incremental based on Xie et al. (2017) and Gal and Ghahramani (2016).\n\nPros:\n- Theoratical justification seems reasonably sound to me.\n- Strong empirical performance.\n\nCons: \n- It would be interesting to see how the proposed technique works when applied to state-of-the-art models.\n\nDetails:\n\n- I'm not entirely familiar with Gal and Ghahramani (2016), but I'm assuming the discussion in Section 3 and how it extends to word embeddings are from this earlier work. Please correct me if I'm wrong, so that I can adjust my recommendation accordingly.\n\n- I can't find anything describing how \\sigma is determined.\n\n- Page 4, the paragraph of `Training.` I can't parse `we go though sequence t multiple times`.\n\n- \\ell_2 Regularization for `VS` models. I'm confused here, isn't the coefficient for VS determined by Eq. 3? Why is it still tuned in Section 5.1?\n\n- Elementwise smoothing: I'm confused why one needs to sample \\alpha for each dimension. Can't it be done by sampling a mask, just as in dropout?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Missing consideration of and comparison to existing work, far from state-of-the-art results",
            "review": "In this submission, the authors present a variational smoothing interpretation of the data noising approach presented in (Xie et al., 2017). Although the theoretical coverage of the problem gives interesting insights. However, a comparison to related work w.r.t. alternative regularization approaches is missing. Similarly, the perplexity values reported in the experimental results on Penn Treebank are far away from state-of-the-art results published by many competitors on this task, e.g. see the current state-of-the-art results on Penn Treebank by (Yang et al., 2017, https://arxiv.org/pdf/1703.02573.pdf and references therein). It is bad practice to ignore existing work completely like this. The interesting question here would be, inhowfar the presented smoothing/regularization methods are complementary to existing approaches, and if the presented methods do provide improvements on top of these.\n\nFinally, the mode of language modeling evaluation presented here, without considering an actual language or speech processing task, provides limited insight w.r.t. its utility in actual applications. Moreover, the very limited size of the language modeling tasks chosen here is highly advantageous for smoothing/regularization approaches. It remains totally unclear, how the presented approaches would perform on more realistically sized tasks and within actual applications.\n",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}