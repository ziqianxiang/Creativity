{
    "Decision": {
        "metareview": "Strengths:\nWell written paper on a new kind of spherical convolution for use in spherical CNNs.\nEvaluated on rigid and non-rigid 3D shape recognition and retrieval problems.\nPaper provides solid strategy for efficient GPU implementation.\n\nWeaknesses: There was some misunderstanding about the properties of the alt-az convolution detected by one of the reviewers along with some points needing clarifications. However, discussion of these issues appears to have led to a resolution of the issues.\n\nContention: The weaknesses above were discussed in some detail, but the procedure was not particularly contentious and the discussion unfolded well.\n\nAll reviewers rate the paper as accept, the paper clearly provides value to the community and therefore should be accepted.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Solid technical contributions and valuable insights for spherical convolutions"
    },
    "Reviews": [
        {
            "title": "Potential impact, but comparison could better highlight improvements in practical applications",
            "review": "Deep Learning 3D Shapes using Alt-Az Anisotropic 2-Sphere Convolution\n\nThis paper presents a polar anisotropic convolution scheme on a unit sphere. The known non-shift-invariance problems of current manifold neural nets are avoided by replacing filter translation with filter rotation on a sphere. Spherical convolution are thus enabled and are rotation invariant compared to manifold convolutions. This shift also enables a proposed angular max-pooling scheme. Results are presented on mesh projections, shape classification and shape retrieval. \n\nThe paper generally reads well. Tackling the learning problem on a unit sphere has high potential, however, the proposed paper seems to be highly constrained by heuristics on a 2-sphere, such as constraining filters on a reduced rotation group to 2 rotations. This could be fine for many 3D application, but results may lack an exhaustive comparison with other spherical and manifold-based methods on the proposed experiments. Currently, several variants of data augmentations are used, and discussion may lack an explicit comparison with the state-of-the-art of spherical and spectral methods. This may impair understanding in which context the proposed method would work best.\n\n\nOther comments, possible clarification and improvements:\n\n[Method]\n- Can this be extended to unit 2-balls?\n- Isn't the \"alt-az rotation group\" the same as SO(3)?  If orientation is removed, what quotient group would this be?\n- What is the benefit of containing a filter on this quotient group rather than using convolution filters within the full rotation group?  Could a simple experiment convince the reader that the proposed approach is better than using convolutions in SO(3)?\n- Is there a dependence created by the spherical parameterization strategy?\n- How robust is the convolution scheme to topological defects, such as holes, noise?\n- Spherical images may induce parameterization distorsion if using a lat-lon grid, which would require complex variable filters on the spherical image. Are these variable filters burdening the computational complexity?\n- How to handle the distortion induced by the spherization process?\n- How to handle discontinuities around the sphere poles?\n- Computing geodesic may be costly - how does impact performance?\n- Does this rely on data augmentation to cover rotation invariance of filters?\n- Now icosahedrons are used - could the convolution work on an arbitrary mesh discretization, ranging from an ideal isoparametric sphere to a highly irregularly-triangulated mesh?\n- The remeshing strategy to a sphere also looses information from the original mesh connectivity - For instance, links between mesh nodes on the original surface may convey important information (e.g., brain connectivity in neuroscience), remising to a sphere would loose such connectivity information.\n\n[Results]\n- The experiments shows the proposed method with several augmented approaches - How exactly are data augmented?\n- Comparison with other spherical methods (Cohen et al 2018), or manifold-based methods (Monti et al 2018)?  Illustrating the pros and cons with these respective state-of-the-art?\n- Improvements could be better emphasized in Fig 6, Table 3 - how is the method better than others?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution",
            "review": "# Weaknesses\nApplications are a bit unclear.\nIt would be nice to see a better case made for spherical convolutions within the experimental section.  The experiments on SHREC17 show all three spherical methods under-performing other approaches.  It leaves it unclear to the reader when someone should choose to utilize a spherical method or when the proposed method would then be preferred compared to other spherical methods.  Is there a task that this representation significantly outperforms other spherical methods and non-spherical methods?  Or a specific useful application where spherical methods in general outperform other approaches?  \n\n# Strengths:\nThe method is well developed and explained.  \nAbility to implement in a straight-forward manner on GPU.\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution ",
            "review": "# Summary\nThis paper proposes a new kind of spherical convolution for use in spherical CNNs, and evaluates it on rigid and non-rigid 3D shape recognition and retrieval problems. Previous work has either used general anisotropic convolution or azimuthally isotropic convolution. The former produces feature maps on SO(3), which is deemed undesirable because processing 3-dimensional feature maps is costly. The latter produces feature maps on the sphere, but requires that filters be circularly symmetric / azimuthally isotropic, which limits modeling capacity. This paper proposes an anisotropic spherical convolution that produces 2D spherical feature maps. The paper also introduces an efficient way of processing geodesic / icosahedral spherical grids, avoiding complicated spectral algorithms.\n\n\n# Strengths\nThe paper has several strong points. It is well written, clearly structured, and the mathematics is clear and precise while avoiding unnecessary complexity. Much of the relevant related work is discussed, and this is done in a balanced way. Although it is not directly measured, it does seem highly likely that the alt-az convolution is more computationally efficient than SO(3) convolution, and more expressive than isotropic S2 convolution. The most important contribution in my opinion is the efficient data structure presented in section 4, which allows the spherical convolution to be computed efficiently on GPUs for a grid that is much more homogeneous than the lat/lon grids used in previous works (which have very high resolution near the poles, and low resolution at the equator). The idea of carving up the icosahedral grid in just the right way, so that the spherical convolution can be computed as a planar convolution with funny boundary conditions, is very clever, elegant, and practical.\n\n\n# Weaknesses\nThere is however a misunderstanding about the properties of the alt-az convolution that must be cleared up before this paper can be published. To start with, the set of rotations R(phi, nu, 0) called the alt-az group in this paper is not a group in the mathematical sense. This easy to see, because a composition of rotations of the form Rz(phi) Ry(nu) is not generally of that form. For instance we can multiply Rz(phi) Ry(nu) by the element Rz(omega)Ry(0) = Rz(omega), which gives the element Rz(phi) Ry(nu) Rz(omega). As noted in the paper, this is a general element of SO(3) (and hence not in the set of alt-az rotations). So the closure axiom of a group is violated.\n\nThis matters, because the notion of equivariance really only makes sense for a group. If a layer l satisfies l R = R l  (for R a alt-az rotation), then it automatically satisfies l RR' = RR' l, which means l is equivariant to the whole group generated by the set of alt-az rotations. As we saw before, this is the whole rotation group. This would mean that the layer is actually SO(3)-equivariant, but it has been proven [1], that any rotation equivariant layer between scalar spherical feature maps can be expressed as an azimuthally isotropic convolution. Since the alt-az convolution is not isotropic and maps between scalars on S2, it cannot be equivariant. This also becomes apparent in the experiments section, where rotational data augmentation is found to be necessary. The paper does not contain an attempted proof of equivariance, and if one tries to give one, the impossibility of doing so will become apparent.\n\nI note that the alt-az convolution *is* equivariant to rotations in the subgroup SO(2) of rotations around the Z-axis.\n\nAnother somewhat jarring fact about the alt-az convolution is that it is not well defined on the south pole. The south pole can be represented by any pair of coordinates of the form phi in [0, 2pi], nu = +/- pi. But it is easy to see that eq. 10 will give different results for each of these coordinates, because they correspond to different rotations of the filter about the Z-axis. This is ultimately due to the fact that the set of alt-az rotations is not the same as the set of points on the sphere, topologically speaking. The set of points on the sphere can only be viewed as the quotient SO(3)/S(2).\n\nThe paragraph motivating the alt-az convolution on page 4 is not very clear, and some claims are questionable. I agree that local SO(2) invariance is too limiting. But it is not true that rotating filters is not effective in planar/volumetric CNNs, as shown by many recent papers on equivariant networks. I would suggest rewriting this paragraph to make it clearer and less speculative, and acknowledge that although rotating filters might increase computational complexity, it has often been shown very effective.\n\n\n# Other comments\n\nThe experiments show that the method is quite effective. For instance, the SHREC17 results are on par with Cohen et al. and Esteves et al., presumably at a significantly reduced computational cost. That they do not substantially outperform these and other methods is likely due to the input representation, which is lossy, leading to a maximal performance shared by all three methods. An application to omnidirectional vision might more clearly show the strength of the method, but this would be a lot of work so I do not expect the authors to do that for this paper.\n\nIt would be nice to see a more direct comparison between the three definitions of spherical convolution (general SO3, isotropic S2, and anisotropic S2). Right now, the numbers reported in Cohen et al. and Esteves et al. are copied over, but there are probably many differences between the precise setup and architectures used in these papers. It would be interesting to see what happens if one uses the same architecture on a number of problems, changing only the convolution in each case.\n\nInitially, I was a bit puzzled about why SO(3) augmentation seems to reduce accuracy in table 1. I think this is because SO(3) augmentation actually makes the classification problem harder if the input is initially aligned. Some more explanation / discussion would be good. \n\nIt would be nice to explain the spherical parameterization in more detail. Is this operation itself rotation equivariant? \n\n\nTypos & minor issues\n\n- Abstract: \"to extract non-trivial features\". The word non-trivial really doesn't add anything here. Similarly \"offers multi-level feature extraction capabilities\" is almost meaningless since all DL methods can be said to do so.\n- Below eq. 5, D_R^{-1} should equal D_R(-omega, -nu, -phi). The order is reversed when inverting.\n- \"Different notations of convolutions\" -> notions\n- \"For spherical functions there is no consistent and well defined convolution operators.\" As discussed above, the issue is quite a bit more subtle. There are exactly two well-defined convolution operators, but they have some characteristics deemed undesirable by the authors.\n- \"rationally symmetric\" -> rotationally\n- \"exact hierarchical spherical patterns\" -> extract\n- It seems quite likely that the unpacking of the icosahedral/hexagonal grid as done in this paper has been studied before in other fields. References would be in order. Similarly, hexagonal convolution has a history in DL and outside.\n- Bottom of page 7, capitalize \"for\".\n- \"principle curvatures\" -> principal.\n- \"deferent augmentation modes\" -> different\n- \"inspite\" -> in spite\n- \"reprort\" -> report\n- \"utlize\" -> utilize\n- \"computer the convolution\" -> compute\n\n\n# Conclusion\n\nAlthough the alt-az convolution lacks the mathematical elegance of the general anisotropic and azimuthally isotropic spherical convolutions, it still seems like a practically useful operation for some kinds of data, particularly when implemented using the homogeneous icosahedral/hexagonal grid and fast algorithm presented in this paper. Hence, I would wholeheartedly recommend acceptance of this paper if the authors correct the factual errors (e.g. the claim of SO(3)-equivariance) and provide a clear discussion of the issues. For now I will give an intermediate rating to the paper.\n\n\n[1] Kondor, Trivedi, \"On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups\"",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}