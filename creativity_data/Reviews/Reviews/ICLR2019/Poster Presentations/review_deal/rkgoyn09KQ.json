{
    "Decision": {
        "metareview": "This paper presents an extension of an existing topic model, DocNADE. Compared to DocNADE and other existing bag-of-word topic models, the primary contribution of this work is to integrate neural language models into the topic model in order to address two limitations of the bag-of-word topic models: expressiveness and interpretability. In addtion, the paper presents an approach to integrate external knowledge into the neural topic models to address the empirical challenges of the application scenarios where there might be only a small training corpus or limited context available. \n\nPros: \nThe paper presents strong and extensive empirical results. The authors went above and beyond to strengthen their paper during the rebuttal and address all the reviewers' questions and suggestions (e.g., the submitted version had 7 baselines, and the revised version has 6 additional baselines per reviewers' requests).\n\nCons:\nThe paper builds on an earlier paper that introduced the DocNADE model. Thus, the modeling contribution is relatively marginal. On the other hand, the extended model, albeit based on a relatively simple idea, is still new and demonstrates strong empirical results.\n\nVerdict:\nProbably accept. While not groundbreaking, the proposed model is new and the empirical results are strong. ",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "While not groundbreaking, the proposed model is new and the empirical results are strong. "
    },
    "Reviews": [
        {
            "title": "Method is not novel but results seem to be solid",
            "review": "\nCons: \nThe proposed method is not novel. For example, Lauly et al., 2017 have proposed a similar way of combining LM and DocNADE. This paper does not provide some motivations or theories behind such artificial combination (i.e., just linearly combine their hidden state) to explain why it works better than other alternatives (e.g., what about adding some linear layers before combining h_i^{DN} and h_i^{LM}).\n\nPros: \nHowever, the results seem to be solid and significantly better than the previous state-of-the-art methods. I think some recent neural topic models such as [1,2,3] are still missing even though there are already many tables in the paper (I am not an expert on neural topic modeling or embedding for IR tasks, so there might be others missing state of the arts which I am not aware of). In addition, why does Table 5 only compares perplexity between 3 methods and Table 6 only compares coherence between 4 or 5 methods, while there are 9 or 12 methods are compared in IR task (Table 3 and 4). What's the difficulty of comparing the coherence and perplexity of all different topic models (including [1,2,3])?\nI will vote for acceptance if the mentioned baselines are also compared or there are good reasons why they cannot be compared.\n\n\nWriting and presentation:\nThe quality of writing should be improved. Here are several examples.\n1. In the abstract, the following sentence needs to be rewritten and the rule of capitalization should be consistent. \"(2) Limited Context and/or Smaller training corpus of documents: In settings with a small number of word occurrences (i.e., lack of context) in short text or data sparsity in a corpus of few documents, the application of TMs is challenging.\"\n2. I do not understand what's the purpose of the right figure in Figure 1. I think the paper does not do any matching like that.\n3. In the 3rd paragraph of the introduction, \"topmost\" -> top most \n4. The paper should have a related work section. In addition to the related work discussion scattered in the introduction, authors should discuss the difference between this work and Lauly et al., 2017. Authors should also include some related work such as [1,2,3].\n5. Just below (1), \"where,\" -> , where\n6. In the last sentence of the paragraph after (1), you mentioned \"v_{<i} are orderless\", so what's the ordering used in experiments? Random ordering?\n7. I guess \"a\" in algorithm 1 means sum_{k<i}(W_{:,v_k}), but I cannot find the explicit explanation about the purpose of \"a\".\n8. For ctx-DocNADEe, is W+E the embedding of words at input layer in LM?\n9. In the 3rd paragraph of section 2.2, you said: \"each row vector W_{j,:} is a distribution over vocabulary of size K\". Could W has negative values during optimization?  If yes, why a distribution representing a topic could have negative value. If no, you should explicitly mention this non-negativity constraint.\n10. Why are some values in Table 12 and 13 missing?\n\n[1] Cao, Z., Li, S., Liu, Y., Li, W., & Ji, H. (2015, January). A Novel Neural Topic Model and Its Supervised Extension. In AAAI (pp. 2210-2216).\n[2] Srivastava, A., & Sutton, C. (2017). Autoencoding variational inference for topic models. ICLR\n[3] Card, D., Tan, C., & Smith, N. A. (2017). A Neural Framework for Generalized Topic Models. arXiv preprint arXiv:1705.09296.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "related work not great, but experiements extensive otherwise",
            "review": "DocNADE has great performance so this is a welcome bit of\nresearch extending it.\n\nThere has been a huge amount of activity in combining topic models with\n(1) embeddings and (2) neural networks such as LSTMs and RNNs.\nI will say I have great sympathy for the poor author trying to do\nfair comparisons against start-of-the-art because the standards are\nmoving quickly.\n\nIn this case, some neural network papers I have seen are TopicRNNs by\nDieng, Wang Gao and Paisley, and LLA by Zaheer, Ahmed and Smola.  The\nlatter is still a bag-of-words model and but places the LSTM over the\nsequence of topic proportions.  The Gauss-LDA and glove-DMM work is\nfairly dated (in our fast-paced ML world) and their performance is\nknown to be poor, as some papers in 2017 show.  Now I know historically LDA has been fairly poor\nwith IR tasks, but I would expect the recent supervised LDA methods,\nsome also have word embeddings, to do better as well.\nSo the discussion of related work and comparative experiments\nare poor.\n\nIf you want to illustrated good improvememts gained using embeddings,\nit helps to try different proportions, say 20/40/60/80% of a data\nset and plot.  Usually, you should see embeddings aid performance\ndramatically for smaller fractions of data sets.  Hence, your results\nseem strange.\n\nNote the data sets are all fairly small, which makes me wonder about\nthe computation time.  Could you give some computational performance\nstats for a data set?\n\nIn section 2.2 top of page 5, why is it \"pseudo\" log likelihood?\nIsn't that formula exact?\n\nThe paper has a relatively small part devoted to the model, and\nvirtually nothing on the algorithm, although this is probably covered\nin earlier DocNADE papers.   I'm assuming the model is\ntrained by SGD on the log likelihood with all the parameters\nshoved in there in one go.  Is that right?  Would be nice to mention\nwhatever it is.\n\nThe use of four different kinds of evaluations (classification, IR,\nperplexity, etc.) is good.  Note that the improvement over the earlier\nDocNADE is quite small but clearly significant, and improvement of adding\nembeddings seems even smaller, though seems better for short texts.\nI wonder if the method for including embeddings is much good!\nNot fully convinced.\n\nAFTER RESPONSE:   Wow guys, what a great revision.  Thanks so much.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Extends existing DocNADE model by replacing the feedforward network with an LSTM",
            "review": "The paper extends an existing topic model - DocNADE - by replacing the feedforward part of the network which combines the textual context with an LSTM sequence model. Hence this paper fits in a long tradition of work which aims to extend the bad-of-words model from the original LDA paper with some sequence information.\n\nThe authors do a commendable job in thoroughly evaluating the proposed extension, using a number of evaluations based on perplexity, topic coherence, and text retrieval and categorization.\n\nMy main problem with the paper as it stands is that it a) arguably oversells the contribution, and b) is unclear when explaining certain crucial aspects of the model.\n\nIt would also help to have a clearer statement of whether the contribution here is on the document modeling side, or the language modeling side. Motivation is provided from both angles, but the evaluation focuses largely on the topic modeling (which is fine, just need to say it).\n\nMore specific comments:\n--\nThe abstract should mention that the DocNADE model already exists, and that the contribution of the current work is to extend that existing model in a particular way. For those readers unfamiliar with DocNADE, this will help situate the work with regard to the existing literature.\n\nUsing existing word embeddings as a 'prior' for the LSTM word embeddings is a completely standard alternative now to learning those embeddings from scratch. I'm not sure that can count as a second, major contribution of the paper. (I'm also not sure that either extension to DocNADE warrants a new name, but I'll leave that to the authors' judgement.)\n\nI'm confused by one aspect of the DocNADE model: \"the topic assigned ...equally depends all the other words appearing in the same document\". But the model is generative, no? And eqn 1 suggests that each word is generated conditioned on the *previous* words in the document, or did I miss something? \n\nRelated to this point, DocNADE transforms its BoWs into a sequence. But what's the order? Is it just the order of the words in the document? In which case it's very similar to the LSTM extension, except the LSTM keeps the order in the history, whereas the bag-of-words model doesn't.\n\nRelation to generative models: LDA is a generative model with a generative story. It's not completely obvious to me what the generative story is in the new model. Talking about \"distributed compositional priors\" doesn't help, since I'm assuming these aren't priors in a Bayesian modeling sense? (It's also not clear in what sense these \"priors\" are compositional, but that's a separate question.)\n\nEquation 2: what's the motivation for mixing the LSTM history with the bag-of-words (esp. if the history is from the same bag of words in each case). Why not just use the LSTM?\n\nIt would be useful to state in the main body of the text what the value of lambda ends up being. In 3.1 there's a suggestion this might be 0.01, but that effectively ignores the LSTM?\n\nSimilar question: how can the DocNADE model provide a *global* context if the model is generative?\n\nPerplexity is a reasonable thing to measure, but presumably the auto-regressive nature of the LSTM means that it's more-or-less guaranteed to do better than a bag-of-words model? I wonder if it's worth acknowledging this fact?\n\nI don't understand why lambda has to be zero \"to compute the exact log-likelihood\".\n\nThe first line of the conclusion doesn't say much: it's pretty obvious that the ordering of the words is going to help better estimate the probability of a word in a given context; 50 years of language modeling research has already taught us that.\n\nMinor presentational comments:\n--\nSome of the hyphenation looks odd, eg in the title. Are you using the standard LaTeX hyphenation settings?\n\nStrictly speaking, I'm not sure that 'bear' in the example is a proper noun.\n\n\"orderless sets of words\": bags, not sets, since the counts matter, no?\n\nThe tables are too small, with a lot of numbers in them. One option is to move some of the details to the Appendix. Either way there needs to be more summary in the main body explaining what the numbers tell us.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}