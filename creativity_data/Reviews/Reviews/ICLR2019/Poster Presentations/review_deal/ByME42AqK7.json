{
    "Decision": {
        "metareview": "The paper proposes an evolutionary architecture search method which uses weight inheritance through network morphism to avoid training candidate models from scratch.  The method can optimise multiple objectives (e.g. accuracy and inference time), which is relevant for practical applications, and the results are promising and competitive with the state of the art. All reviewers are generally positive about the paper. Reviewers’ feedback on improving presentation and adding experiments with a larger number of objectives has been addressed in the new revision. \n\nI strongly encourage the authors to add experiments on the full ImageNet dataset (not just 64x64) and/or language modelling -- the two benchmarks widely used in neural architecture search field.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "interesting method, promising results"
    },
    "Reviews": [
        {
            "title": "An interesting method with a troubled presentation",
            "review": "This paper proposes LEMONADE, a random search procedure for neural network architectures (specifically neural networks, not general hyperparameter optimization) that handles multiple objectives.  Notably, this method is significantly more efficient more efficient than previous works on neural architecture search.\n\nThe emphasis in this paper is very strange.  It devotes a lot of space to things that are not important, while glossing over the details of its own core contribution.  For example, Section 3 spends nearly a full page building up to a definition of an epsilon-approximate network morphism, but this definition is never used.  I don't feel like my understanding of the paper would have suffered if all Section 3 had been replaced by its final paragraph.  Meanwhile the actual method used in the paper is hidden in Appendices A.1.1-A.2.   Some of the experiments (eg. comparisons involving ShakeShake and ScheduledDropPath, Section 5.2) could also be moved to the appendix in order to make room for a description of LEMONADE in the main paper.\n\nThat said, those complaints are just about presentation and not about the method, which seems quite good once you take the time to dig it out of the appendix.\n\nI am a bit unclear about how comparisons are made to other methods that do not optimize for small numbers of parameters? Do you compare against the lowest error network found by LEMONADE? The closest match in # of parameters?\n\nWhy is the second objective log(#params) instead of just #params when the introduction mentions explicitly that tuning the scales between different objectives is not needed in LEMONADE?\n\nIt seems like LEMONADE would scale poorly to more than 2 objectives, since it effectively requires approximating an #objectves-1 dimensional surface with the population of parents.  How could scaling be handled?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Official Review",
            "review": "Summary:\nThe paper proposes LEMONADE, an evolutionary-based algorithm the searches for neural network architectures under multiple constraints. I will say it first that experiments in the paper only actually address to constraints, namely: log(#params) and (accuracy on CIFAR-10), and the method as currently presented does not show possible generalization beyond these two objectives, which is a weakness of the paper.\n\nAnyhow, for the sake of summary, let’s say the method can actually address multiple, i.e. more than 2, objectives. The method works as follows.\n\n1. Start with an architecture.\n\n2. Apply network morphisms, i.e. operators that change a network’s architecture but also select some weights that do not strongly alter the function that the network represents. Which operations to apply are sampled according to log(#params). Details are in the paper.\n\n3. From those sampled networks, the good ones are kept, and the evolutionary process is repeated.\n\nThe authors propose to use operations such as “Net2WiderNet” and “Net2DeeperNet” from Chen et al (2015), which enlarge the network but also choose a set of appropriate weights that do not alter the function represented by the network. The authors also propose operations that reduce the network’s size, whilst only slightly change the function that the network represented.\n\nExperiments in the paper show that LEMONADE finds architecture that are Pareto-optimal compared to existing model. While this seems like a big claim, in the context of this paper, this claim means that the networks found by LEMONADE are not both slower and more wrong than existing networks, hand-crafted or automatically designed.\n\nStrengths:\n1. The method solves a real and important problem: efficiently search for neural networks that satisfy multiple properties.\n\n2. Pareto optimality is a good indicator of whether a proposed algorithm works on this domain, and the experiments in the paper demonstrate that this is the case.\n\nWeaknesses:\n1. How would LEMONADE handle situations when there are more than one $f_{cheap}$, especially when different $f_{cheap}$ may have different value ranges? Eqn (8) and Eqn (9) does not seem to handle these cases.\n\n2. Same question with $f_{exp}$. In the paper the only $f_{exp}$ refers to the networks’ accuracy on CIFAR-10. What happens if there are multiple objectives, such as (accuracy on CIFAR-10, accuracy on ImageNet) or (accuracy on CIFAR-10, accuracy on Flowers, image segmentation on VOC), etc.\n\nI thus think the “Multi-Objective” is a bit overclaimed, and I strongly recommend that the authors adjust their claim to be more specific to what their method is doing.\n\n3. What value of $\\epsilon$ in Eqn (1) is used? Frankly, I think that if the authors train their newly generated children networks using some gradient descent methods (SGD, Momentum, Adam, etc.), then how can they guarantee the \\epsilon-ANM condition? Can you clarify and/or change the presentation regarding to this part?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The proposed method is interesting, but the proposed method does not seem to provide a large contribution",
            "review": "\n- Summary\nThis paper proposes a multi-objective evolutionary algorithm for the neural architecture search. Specifically, this paper employs a Lamarckian inheritance mechanism based on network morphism operations for speeding up the architecture search. The proposed method is evaluated on CIFAR-10 and ImageNet (64*64) datasets and compared with recent neural architecture search methods. In this paper, the proposed method aims at solving the multi-objective problem: validation error rate as a first objective and the number of parameters in a network as a second objective.\n\n- Pros\n  - The proposed method does not require to be initialized with well-performing architectures.\n  - This paper proposes the approximate network morphisms to reduce the capacity of a network (e.g., removing a layer), which is reasonable property to control the size of a network for multi-objective problems.\n\n- Cons\n  - Judging from Table 1, the proposed method does not seem to provide a large contribution. For example, while the proposed method introduced the regularization about the number of parameters to the optimization, NASNet V2 and ENAS outperform the proposed method in terms of the accuracy and the number of parameters.\n  - It would be better to provide the details of the procedure of the proposed method (e.g., Algorithm 1 and each processing of Algorithm 1) in the paper, not in the Appendix.\n  - In the case of the search space II, how many GPU days does the proposed method require? \n  - About line 10 in Algorithm 1, how does the proposed method update the population P? Please elaborate on this procedure.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}