{
    "Decision": "",
    "Reviews": [
        {
            "title": "The model seems to be really intriguing but the formulation ...",
            "review": "The paper presents a model to separately learn two parts of sentence representation in vectors: meaning and form. Why this is needed is easy to underatand and well explained. On the contrary, the forumulation of the model is indeed unnecessarely complex. It seems the authors want to convince that the model is extremely complicated. Yet, the formulation does not help in explaining the complexity of the model. \n\nThe formulation (Section 3) is a really difficult part to understand. It does not follow an easy path. First of all, what is the diffence beween \\textbf{X} and \\mathcal{X}. More importantly, where \\textbf{X} used in the formulation? What is p(.) in the main equation of the formulation? Is it a probabilistic distribution over vectors \\vec{f}^a \\vec{f}^b. Then, if p(.) is a probabilistic distribution and \\alphas are scalars, \\vec{f}_i is a scalar? \np(.) shuold be better described. \n\nIf the aim of furmulation is to help readers to go into the paper, it does not seem to be reached. On the contrary, it makes reading more complex.\n\nThe main innovation of the paper seems the introduction of two layers in a standard GAN. These two layers are: (1) the Motivator; (2) the Discriminator. These two models should address two different perspectives for sentence modeling. To better explain the model, the athors could use Fig. 1 by adding the outputs and the inputs of the layers. If the input and the output of the generator are intuitive, the output of the Motivator and the Discriminator is not that clear. An example could be very useful to clarify the model. What is exactly the output of the Discriminator? And the one of the Motivator? These two layers force the separation of the meaning and the form, respectively. But how? What is the target output for the first and the target output for the second?\n\nMinor issues\n====\nThere are some abbreviations that are not explained or are explained after their first use, e.g., Natural Language Processing (NLP), CV?, Generative Adversial Network (GAN), Long-Short Term Memory (LSTM), ...\n ",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Neat little contribution.",
            "review": "The paper presents a method for style transfer using latent vectors that are trained to separately capture meaning and form (style). \n\nThe main claims are that (i) the form aspect is modeled in a continuous fashion as opposed to prior work, and (ii) the use of a motivator (in addition to a discriminator) to encourage packing information about the form. \n\nThe paper presents experiments that compare how controllable the generation is under this model. \n\nHere are my concerns with the paper:\n\n1. Why is decomposing information from a packed sentence embedding better than say separately tracking meaning and form related information using two separate LSTMs? It is not obvious why one is better than the other. -- One can argue that there are more parameters with two LSTMs. But then how does this compare with the parameters of the 2-layer MLP? \n\n2. One of the main distinctions being claimed is that this model treats form as truly continuous. But the discriminator seems to be trained to predict the form of the sentence -- where form is one of the two classes (middle vs. modern)? \n-- If this is indeed the case then how is this treatment different from prior work (e.g. Hu et al. (2017) which treat the latent variable as a binary feature but with continuous values). The mechanism is different but the treatment seems to be the same. Is it?\n-- If this is not the case then how does the discriminator know what the continuous form vector should be for each sentence?\n\n3. As far as I can tell the evaluations don’t seem to test the benefit of the form being truly continuous in the sense of controllable generation. \nIs there a way to say generate this sentence in a high degree of middle english? I cannot imagine why/how this would be useful as a task.\n\n4. There is one evaluation in Figure 2, which suggests that the ADNet model generated sentences have higher transfer strength but this evaluation is not conclusive in the sense that you have too much drop in content. It would be compelling to have a manual evaluation to supplement this evidence. \n\n5. Table 1 examples look good but Table 2 results seem to indicate that the model doesn’t do as well for headlines to scientific article titles. Why is this the case?\n\n6. Table 3 results are encouraging. It would be useful to also include a result where you use both the form and meaning vectors (say concatenated) as a control test to see if it is indeed the meaning vectors that are useful or if it is this kind of separation that is somehow useful. \n\n7. The intro has a sentence that says the method decomposes the sentence embedding into several vectors -- this has only been tested for form and meaning. There is nothing in the model that says it can't have more than two vectors but just that the empirical evidence is only for form and meaning. \n\nSome typos:\nbetter decomposition → better decompose\ndissociation meaning and form → dissociating meaning from form\ncomplimentary → complementary\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting method, but some important questions are not answered, and experiments didn't clearly justify the contributions",
            "review": "This paper proposed a method to decompose text representation into two vectors for meaning and form respectively. The method used an adversarial discriminator to eliminate form information in meaning vectors and used a motivator on form vectors. The authors evaluated the model on a form transfer task and a downstream task of paraphrase detection.\n\nPros of the paper:\n1. The paper proposed to use a motivator to encourage the model to keep more form information in form vectors.\n\n2. Learned meaning embedding gives a better performance than other unsupervised method on a downstream paraphrasing detection task.\n\nCons of the paper, and questions:\n\n1. One big concern about the method is why f (form vector) would contain only form information, while m (meaning vector) would contain all semantic information. I might miss something, but it seems totally possible to me that some semantic information will shift to f rather than to m, because f has access to the whole input, and that's why previous work used a categorial vector. The authors didn't explain how they addressed this issue.\n\n2. In the form transfer experiments, the proposed model had lower content preservation scores. This probably means semantic meaning will shift after switching f, so the issue mentioned above does exist, right? The authors should show more results and analysis on how well meaning is preserved.\n\n3. The procedure of constructing the opposite form vector in Section 5.1.1 is a bit ad-hoc, and it doesn't really motivate the use of continuous form representation. It would be nice if the authors could show other use cases where continuous form representation is clearly a better choice.\n\n4. Why not report experiments on sentiment data? I think the model is generic enough and should be able to handle sentiment decomposition and transfer. I would be curious to see the results on sentiment data.\n\n5. The perplexity change from 6.89 to 9.74 seems huge to me. Even though the absolute change seems small, the relative change is huge (~30%) according to 1-billion-words-benchmark of language model. It would be useful to show more evidence that this change doesn't impact the fluency.\n\nOverall the originality of the method is marginal. Some questions about the method need to be answered. Evaluations are a bit weak and they don't clearly justify the contributions of the paper.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}