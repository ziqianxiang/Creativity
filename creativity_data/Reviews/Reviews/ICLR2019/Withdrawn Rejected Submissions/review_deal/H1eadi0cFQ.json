{
    "Decision": {
        "metareview": "The paper proposes a method to escape saddle points by adding and removing units during training. The method does so by preserving the function when the unit is added while increasing the gradient norm to move away from the critical point. The experimental evaluation shows that the proposed method does escape when positioned at a saddle point - as found by the Newton method. The reviewers find the theoretical ideas interesting and novel, but they raised concerns about the method's applicability for typical initializations, the experimental setup, as well as the terminology used in the paper. The title and terminology were improved with the revision, but the other issues were not sufficiently addressed.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Meta-review"
    },
    "Reviews": [
        {
            "title": "Interesting work, though not sure how symmetry breaking happens",
            "review": "This is an interesting submission and I appreciate especially connecting to a body of literature which is not normally well known in our community (e.g. Fukumizu&Amari). I think the perspective is definitely new and probably quite relevant not only for practical approaches to escape saddles but also to understand learning in deep learning.  I have a few notes and suggestions:\n\n1) Name of the paper: \nI think is not descriptive of the approach and actually the words “magic” makes it sound strange. I think this will reduce the amount of people reading the work. Please consider something more descriptive like: “Escaping saddle points by increasing capacity”. Or something else more inspired, but that also hints what the work is about. \n\n2) Notation: \nThe notation used is not ML friendly (or generically) to the average reader. I strongly suggest to use b_v for bias, W_uv for weights, and not theta_v and theta_uv which is not typical notation. ‘u’ and ‘v’ are somewhat non-typical choices either, though I understand that they come from the graph notation. Transfer functions are usual sigma. In the text you explain the process by starting with a u’ and then add the clone which is u. Normally you should have started with u and add the clone that is u’. x_u for the value of unit u (assuming this is in the middle of a deep net) is also quite a strange notation. I can guess the authors might be from a slightly different community, but I’m worried about people from the target audience (ICLR) being turned away from the work or even worse confused because of notations.\n\n3) Related work\nThere is the Net2Net work that is related to what is going on here that is not cited (https://arxiv.org/pdf/1511.05641.pdf). I think there was some follow-up work after this.\n\n4) Symmetry breaking\nI do not understand how symmetry is broken. If I clone a unit, and have a new variant of it u’ that now has the same outbound connections but multiplied by alpha (while the original unit by 1-alpha) then while the norm of the gradients differ, their direction does not. Wouldn’t this mean that the units will track each other and hence no tunnel is open? In Net2Net dropout was used to break symmetry (i.e. a source of noise that would pick one path over the other). There is no source of noise here to break symmetry. \n\n5) Diagrams and analysis\nConnected to this, I feel like this could have been represented clearly with a diagram showing the net before and after. There could be some analysis, a more extended discussion of where the symmetry breaking comes from, empirical evidence that it does. I’m not necessarily worried that experiments are not scaled up, I’m more concerned that the hypothesis and solution is only tested by means of change in performance. What is this tunnel doing? How does it change the Hessian at the saddle? Any visualization to reinforce the intuition of what the approach is doing? \n\n\n6) Closing tunnels & re-organizing\nI don’t understand the mechanism for reorganizing weights and closing tunnels. It seems first of all to confirm my intuition that there is no symmetry breaking since we can “close” the tunnel by simple algebraic manipulation. So if those two units always stay in sync how do you actually change the error surface? How do you take advantage of this extra capacity to solve anything. Regardless, when it comes to re-organizing, it seems you pick two of these units that are in sync (previous tunnel I guess) and collapse them to open a new tunnel, right? How does this change anything? Which unit needs to be cloned? Any? So then why is the previous tunnel not efficient anymore? \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting ideas for expanding/contracting a network's size to escape saddles, but would benefit from further experiments",
            "review": "Summary:\n\nThis paper presents a new strategy for escaping saddle points by adding and removing hidden units during training. The method essentially finds conditions where adding a hidden unit does not change the overall input-output map, and uses these as constraints to add a hidden unit that maximally increases the gradient norm (thus potentially getting learning unstuck). Experiments show that the method can improve training speed relative to the same network with randomly added new units.\n\nMajor comments:\n\nThis paper presents interesting theoretical ideas and clearly separates the opportunities for adding/removing hidden units without changing the input-output map from the impact on the gradient due to the change in parametrization. \n\nThe experiments show that the proposed method can speed up learning when a network is genuinely stuck at a saddle point. Importantly however, the experimental evaluation intentionally seeks saddle points using Newton’s method, such that learning is genuinely stuck, before adding the additional units. It is therefore less clear whether this method can offer speedups to network training in practice. Do NNs come close enough to saddle points to benefit from the method when beginning from typical initializations? Experiments on ImageNet begin from a specifically chosen random seed that happens to enter a very flat region. How many random seeds were tried before finding this one? This would speak to the importance of these findings in general. The paper would benefit greatly from applying the proposed method to networks trained under standard protocols, to identify the speed up (if any) it can confer for the average case. It would also be important to account for wall clock time, as the proposed method involves potentially expensive steps (at least in its straightforward form).\n\nThe paper notes several other strategies for expelling from saddle points. The experimental evaluation could be improved greatly by including comparisons to these alternatives. Does the proposed method escape more quickly, or have other merits relative to these alternatives?\n\nThe clarity of the paper is good overall but the title could be improved to be more informative of the content of the method.\n\nOverall the significance of the paper is not clearly established because the evaluations mostly consist of internal comparisons, in somewhat unnatural settings (where networks are initialized right next to saddle points). The theoretical observations, however, seem promising.\n\nMinor comments:\n\nI could not understand the motivation for closing the tunnel—it seems as though optimization proceeds more quickly if it remains open. \n\nThe paper discusses a range of relevant work but would benefit from citing other incremental learning work in neural networks, in particular:\n\nY. Bengio et al., Convex Neural Networks, NIPS 2006\n\nF. Bach. Breaking the curse of dimensionality with convex neural networks. JMLR 2017\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review",
            "review": "The paper addresses the problem of increasing and decreasing the number of hidden nodes (aka, dimensionality) in the network such that the optimization will not enter the plateaus of saddle points. The opening or closing of tunnels (filters) guarantee the existence of “new escape directions” and faster convergence. \n\nStrengths:\n+ provide a new perspective of designing the shape/dimensionality of a network in a dynamic manner. \n+ provide theoretic proof of CNNs and FCs on the contribution to the gradient after cloning. \n\nWeakness:\n- Experiments are very weak to verify the theory.\n\nDetailed comments:\n\n- Eqn. (6) seems to provide a unified evaluation on the contribution of two units to the gradients. How does it relate to the experiments? It gives me a sense that the manuscript is isolated between theory (Section 2 and 3) and verification (experiments).\n- Why does the blue curve get stuck in a flat area? A better staring learning rate could alleviate the plateau bottleneck. \n- The experiment settings are a little bit simple, even for the most complicated one in Section 4.4, where there are five conv layers and the tunnel opening only involves one single filter. Do authors conduct more filters opening in more layers? How about the closing case? There is no result/analysis in the experiments. \n- Why authors claim the blue curve in the left figure 2, a “flat area”? It seems working as the orange one (loss decreases normally). \n- Another big concern is that the proposed method is supposed to prevent network from saddle points and faster convergence, which is verified. And yet, the ultimate goal is to improve the performance. I am surprised that there is no such result at all in the manuscript (for example, error rate goes down on cifar/mnist/etc). \n\nIn summary, I do recognize the theoretical effort the paper has provided; however, the experiments seem not to verify the proposed method in a professional manner. \n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}