{
    "Decision": {
        "metareview": "The paper presents LEAPS, a hybrid model-based and model-free algorithm that uses a Bayesian approach to reason/plan over semantic features, while low level behavior is learned in a model-free manner. The approach is designed for human-made environments with semantic similarity, such as indoor navigation, and is empirically validated in a virtual indoor navigation task, House3D. Reviewers and AC note the interesting approach to this challenging problem. The presented approach can provide an elegant way to incorporate  domain knowledge into RL approaches. \n\nThe reviewers and AC note several potential weaknesses. The reviewers are concerned about the very low success rate, and critiqued the use of success rate as a key metric itself, given that random search with a sufficiently high cut-off could solve the task. The authors added additional results in a metric that incorporates path length, and provided clarifying details. However, key concerns remained given the low success rates. The AC notes that e.g., results in the top and middle row of figure 4 show very similar results for LEAPS and the reported baselines. Further, \"figure 5\" shows no confidence / error bars, and it is not possible to assess whether any differences are statistically significant. Overall, the questions of whether something substantial has been learned, should be addressed with a detailed error analysis of the proposed approach and the baselines, to provide insight into whether and how the approaches solve the task. At the moment, the paper presents a potentially valuable approach, but does not provide convincing evidence and conceptual insights into the approach's effectiveness.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "novel approach to combine model-based and model-free RL - needs more in-depth analysis of results"
    },
    "Reviews": [
        {
            "title": "Learning and Planning with a Semantic Model ",
            "review": "This work proposes a hybrid model for robot visual navigation in synthetic indoor environments, specifically a combination of a  high-level planning scheme (model-based) with a low-level behavior based approach (model-free) . The main contribution is on the high-level based planning that is based on semantic cues from the environment, specifically the construction of a semantic prior about rooms connectivity. By using this prior the system is able to generalize to new environments simplifying an initial robot exploration phase. \n\nThe semantic prior is implemented by the construction of a graph representation that encodes room connectivity. Links between rooms (nodes) are given by Bernoulli variables which are inferred by previous experiences and an exploration phase in the current environment.  \n\nResults are one of the weaker parts of the paper, success rates are very low, even for short planning horizons (figures 3,4,5).  Furthermore, it is not clear the real relevance of the semantic prior because relative performance with respect to baselines is not significant. In general, while a room connectivity prior can be of help, I believe is not so critical for indoor robot navigation. There are prior works on Robotics that has shown more impact using structural priors, such as, presence of corridors, doors, etc, or \"object-room\" spatial relations. The low success rate is even more critical if one considers that the validation is based on synthetic environments.\n\nIn general the paper is easy to follow, although, there are some details missing, specially in terms of model description. My main concern is that the paper is limited in technical novelty and it suffers from a lack of practical significance.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper proposes a hybrid model-based and model-free approach called LEAPS, consisting of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. ",
            "review": "The contributions of this paper are in the area of semantic modelling, where the authors propose an approach called LEAPS consisting of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. The fundamental premise of the proposed approach is that when placed in an unseen environment the agent plans with the semantic model based on new observations. Particularly, the authors propose to learn a Bayesian model over the semantic level and infer the posterior structure via the Bayes rule. The proposed approach is validated with experiments in visual navigation tasks using a 3D environment that contains diverse human-designed indoor scenes with real world objects. Finally, the authors show the key role of using semantic context compared to the baselines that do not consider semantic context.\n\nThe parer is interesting, well structured and and clearly written. Also, the addressed topic of incorporating semantic model in the context of learning and planning is very interesting.\n\nThe related work is extensively presented with pertinent and up-to-date literature. Furthermore, the background section presents well the DRL notations.\n\nIn section 5, how the values for e.g between dinning room and garage 0.05, dinning room and kitchen 0.7 are learned, and how generalisable is this approach to other applications - because the way those priors are determined do not seem very explicit?\n\nFurthermore in the experiments it does not seem explicit how the semantic model is updated in light of new information, I think this deserves further explanation or to be clearly pinpointed?\n\nAlso, what are the key requirements that make  the semantic model interpretable. Because, the way the validation is conducted in this paper, it seems that ithe nterpretability is quite specific to House3D - is it generalisable to other applications and under which conditions?\n\nOtherwise, I believe that the questions asked in the experiments section are well answered with the experimental results\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "non-effective method (works well only with groundtruth information), convoluted writing, improper evaluation metric",
            "review": "The paper proposes a hybrid model-free and model-based RL agent for the task of navigation. Reaching the target is decomposed into a set of sub-goals, and the plan is updated as the agent explores the environment. The method has been tested in the House3D environment for the task of RoomNav, where the goal is to navigate towards a certain room. \n\nThe idea of integrating RL agents with semantic knowledge is interesting. However, the paper has several major issues that should be addressed in the rebuttal:\n\n(1) The experiment results in Figure 3 and Figure 4 are based on groundtruth room information. The only experiment that is fully automatic is the one in Figure 5. However, there is no difference between the proposed method and the baselines in that case. So the proposed method is not effective without groundtruth information.\n\n(2) The only evaluation metric that is used is \"Success Rate\". That metric is not sufficient for evaluation of navigation agents since it does not include episode length information. All of the results should be based on the protocol mentioned in \"On Evaluation of Embodied Navigation Agents\", arXiv 2018. \n\n(3) There is no termination action according to Appendix B. So the agent does not know if it is at the target or not. It seems the agent will stop if it issues \"stay still\" three times. That is different from termination action. Also, it is confusing what 450 pixels means for a scene classifier that works on the image.\n\n(4) The paper is written in a convoluted way:\n   (a) It is not clear if the semantic model is trained along with the RL model end-to-end or not.\n   (b) Regarding multi-target sub-policies, is there a separate policy for each pair of intermediate targets? \n   (c) Regarding inference and planning on M, what is \\tau exactly? How is the length of the plan determined? \n   (d) Why is the model updated only after a fixed number of steps? That increases the episode length. \n\n(5) The number of T_i's is manually set to 8. That causes serious generalization issues. How do we know how many T_i's exist in a new environment?\n\n\nMinor comments:\n- The paper mentions \"An example of such environments is House3D which contains 45k real-world 3D scenes\". House3D includes only synthetic scenes. They should not be called real-world scenes.\n- How is the reward shaping done?\n\n****\nFinal comments after reading the response and the reviews:\n\nRegarding the fairness of the review, success rate is not sufficient to evaluate navigation agents. A random agent can achieve 100% success if it is given enough time. So it is totally fair to ask for a metric (such as SPL) that is a function of both success rate and episode length. \n\nI am going to increase the rating to 5 since some of my concerns have been addressed. There are still a number of issues:\n\n- The authors did not run the experiments with the termination action. I disagree that this is orthogonal to the focus of the paper. This is not just an additional action. It indicates whether the agent has learned anything or it is just a combination of better obstacle avoidance and luck. The SPL numbers are so low (maximum SPL is 6.19%) so adding the termination action will probably make the method similar to random.\n\n- There is a huge gap between success rate and SPL numbers. For instance, success rate is 66.4, while SPL is 5.84 (note that for some reason the SPL numbers are multiplied by 10 in the table). I doubt that the agent has learned anything meaningful in comparison to the baseline. I understand that the task is hard, but this gap is so huge.\n\n- A separate policy is trained for each sub-target. This doesn't scale. There should be one policy for all targets. \n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}