{
    "Decision": {
        "metareview": "Reviewers mostly recommended to reject after engaging with the authors, however since not all author answers have been acknowledged by reviewers, I am not sure if there are any remaining issues with the submission. I thus lean to recommend to reject and resubmit. Please take reviewers' comments into consideration to improve your submission should you decide to resubmit.\n",
        "confidence": "2: The area chair is not sure",
        "recommendation": "Reject",
        "title": "Paper decision"
    },
    "Reviews": [
        {
            "title": "The paper may contain interesting ideas, but lacks clarity, and might have issues with experimental evaluation.",
            "review": "Summary:\nThis paper introduces a generative model for 3D point clouds. Authors aim at theoretically showing the difficulties of using existing generative models to learn distributions of point clouds, and propose a variant that supposedly solves the issues.\n\nPros:\n+ The problem of designing generative models for 3D data is important.\n\nCons: \n- Paper is often hard to follow, and contains a significant number of typos. \n- Authors claim to identify a fundamental problem with the existing generative models for point clouds, yet Section 2 tries to show that a _specific version_ that uses DeepSet does not satisfy theoretical guarantees. What if we use e.g. a recurrent network instead? As is, the counter example proof itself is quite confusing: it would really help if the proof was more formal.\n- Jointly learning an inference network (Q) has certainly been done before, and I am not sure authors provide an elaborate enough explanation of what is the difference with adversarially learned inference /  adversarial feature learning.\n- It is not clear why authors did not follow the evaluation protocol of [Achlioptas’17] or [Wu’16] more closely. In particular, evaluation for the classification task should be compatible with the proposed model, which would give a much better picture of the learned representations.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Generative model for point clouds, based on local-global latent variables.",
            "review": "Summary:\nThis paper proposes a generative point cloud model based on adversarial learning and definitti’s representation theorem of exchangeable variables.\nThe main focus in experiments and the exposition is on 3D point clouds representing object shapes (seems the surface, but could also be the interior of objects, please clarify). \nThe main idea is to represent a point cloud using a global latent variable that captures the overall shape, and a collection of local latent variables that code for the position of a point on the shape.\nThe model consists of thee components:\n(i) an “encoder” that takes a point cloud as input and maps it to a (point estimate of) the global latent variable of the shape represented by the input cloud, a point-net architecture is used here\n(ii) a “decoder” that takes the estimated global latent variable, and a local latent variable, and maps it to an “output” point in the cloud to be produced by the model. \n(iii) a “discriminator” network that aims to distinguish points from a *given* shape, and the points produced by pipe-lining the encoder and decoder. Critically different from conventional GANs, the discriminator is optimized *per shape*, ie each point cloud is considered as a *distribution* over R^3 specific to that shape. \n(iv) a “shape prior” that, once the encoder-decoder model from above is trained, is used to model the distribution over the global latent variables. This model is trained, presumably, in a conventional GAN style using the global latent variable representations inferred across the different training point clouds.\n\nAs compared to prior work by Achiloptas et al (2017), the proposed approach has the advantage to allow for sampling an arbitrary number of points from the target shape, rather than a fixed pre-defined number. \n\nIn addition, the authors propose to minimize a weighted average of a lower bound and upper bound on the Wasserstein distance between the distributions of points corresponding to given shapes. \nThis approach translates to improved quantitative evaluation measures, \n\nExperiments are conducted on a simple toy data set, as  a proof of concept, and on data from ModelNet10 and ModelNet40. \nTwo performance metrics are introduced to assess the auto-encoding ability of the model: to what extent does the encoder-decoder pipeline result in point clouds similar to the shape from which the input point-cloud is generated. \n\nOverall I find the idea of the paper interesting and worth publishing, but the exposition of the paper is less than ideal and needs further work. \nThe experimental validation of the proposed approach can also be further improved, see more specific comments below. \n\nSpecific comments:\n\n- The counter example at the bottom of page 2 is limited, in the sense that the oracle assumption seems highly non-realistic, casting doubt on the relevance of the argument.\n\n- The notation in section 3 (before 3.1) is rather sloppy. \nFor example, \n- please define P and G, the elements of the divergence D(P||G) that appears in the first paragraph of section 3.\n- it is not defined in which space theta lives, it is not clear what the authors intend with the notation G_theta(u) \\sim p(theta). \n- what prior distributions p(z) and p(u) are used? What is the choice based on?\n\n- abbreviation IPM is referred several times in the paper, but remains undefined in the paper until end of page 4, please define earlier. \n\n- The model G_theta does not appear in the training objective function (4), how is this module trained precisely?\n\n- Lack of clarity in the following passage: “In our setting, each point xi in the point cloud can be considered to correspond to single images when we train GANs over images”\n\n- The notion of divergence D(P|G) is not made concrete in section 3 and 3.1, which makes the notation of rather little use.\n\n- The following paper merits a discussion in the related work section: \n“TOWARDS A NEURAL STATISTICIAN”, ICLR’17, https://openreview.net/pdf?id=HJDBUF5le\n\n- The manuscript contains many typos. For example\n “vedio” op page 4, “circile” on page 5, “condct” on page 8, etc.\nPlease proof read your paper and fix these.\nThe refenence to  Bengio 2018 is incomplete: what do you refer to precisely?\n\n- There seems to be no mention of the dimension of the “local” latent variables z_i. \nPlease comment on the choice, and its impact on the behavior of the model.\n\n- The quantitative evaluation in table 1 is interesting and useful. \nIt is limited, however, in the sense that it (only) measures auto-encoding capabilities: to what extent can the shape be reproduced given a sample point cloud from the given shape. \nQuantitative evaluation of generative modeling performance is unfortunately missing from this paper, as it is in much of the GAN literature. \nCould you please comment on how this can/will be fixed?\n\n- The toy data set experiments could be dropped  to make room for experiments suggested below.\n\n- An experimental study of the effect of the mixing parameter “s” would be useful to include. \nFor example, by taking s on a grid from 0 to 1, one could plot the coverage and distance-to-face measures.\n\n- Experimental evaluation of auto-encoding using a variable number of input points is interesting to add: ie how do the two evaluation measures evolve as a function of the number of points in the input point cloud?\n\n- Similar, it is interesting to evaluate how auto encoding performs when non-uniform decimation of the input cloud is performed, eg what happens if we “chop off” part of the input point cloud (eg the legs of the chair), does the model recover and add the removed parts? This is potentially useful to practitioners which have to deal with incomplete point clouds acquired by range scanners. \n\n- Analysis of shapes with different genus and dimensions would be interesting. \nDoes the model manage to capture that some shapes have holes, or consists of a closed 2D surface (ball) vs an open surface (disk),  despite a simple prior on the local latent variables z?\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A variant of WGAN, suppressing bias but leading to worse stability when estimating Wasserstein distance",
            "review": "Authors provide a variant of WGAN, called PC-GAN, to generate 3D point clouds. The drawback of a vanilla GAN with a DeepSet classifier is analyzed. The rationality that decoupling the point generator with the object generator is also discussed. \nA sandwiching objective function is proposed to achieve a better estimation of Wasserstein distance. \nCompared with AAE and the simplified variants of the proposed PC-GAN, the proposed PC-GAN achieves incremental results on point cloud generation.\n\nComments:\n1. Authors calculate W_U in a primal form via solving an assignment programming problem. Have authors ever tried Sinkhorn iteration? To my knowledge, sinkhorn iteration is a very popular method to solve OT problem effectively. It would be nice if authors can provide some reasons and comparisons for their choice on the optimizer of W_U. \n\n2. Authors proved that the sandwiching object W_s is closer to the real Wasserstein distance, but it increases the variance of the loss function. Specifically, the dynamics of W_U, and W_L, according to lemma1, is (epsilon2-epsilon1)*w(P, G) while the dynamics of W_s is 2*epsilon1 * w(P, G), and 2epsilon1 > epsilon2 - epsilon1 (according to the assumption in lemma 1). Does it mean that the W_s is not as stable as W_L or W_U during training?  Additionally, authors combined W_U with W_L with a mixture 20:1, i.e., the s in Eqs(6, 13, 14) is smaller than 0.05. In such a situation, both the value and the dynamics of W_s will be very close to that of W_U. Does it mean that W_L is not so important as W_U? Authors should analyze the stability of their method in details.\n\nEssentially, the proposed method is a variant of WGAN, which estimates Wasserstein distance with lower bias but may suffer from worse stability. In the experiments, both the setting and the experimental results show that the proposed W_s will be very close to W_U. As a result, the improvement caused by the proposed method is incremental compared with its variants. \n\nTypos:\n- The end of the 2nd line of lemma 1: P, G should be \\mathbb{P}, \\mathbb{G}\n- The 3rd line of lemma 1: epsilon1 -> epsilon_1\n- Page 14, Eq(14), \\lambda should be s\n- Page 14, Eqs(13, 14), w(\\mathbb{P}, \\mathbb{G}) should appear on the right.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}