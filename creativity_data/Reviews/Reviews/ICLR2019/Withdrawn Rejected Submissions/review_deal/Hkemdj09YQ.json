{
    "Decision": {
        "metareview": "The main goal of the submission is to figure out a way to produce less \"noisy\" saliency maps. The RectGrad method uses some thresholding during backprop, like Guided Backprop. The visuals of the proposed method are good, but the reviewers rightfully point out that evaluating whether the proposed method is any good is not obvious. The ROAR/KAR results are perhaps not telling the whole story (and the authors claim that RectGrad is not expected to get a high ROAR score, but I would like to see this developed more in a further version of this work).\n\nGenerally, I feel like there was a healthy back and forth between authors and R3 on the main concerns of this work. I agree that the mathematical justification for RectGrad seems not fully developed. Given all of these concerns, at this point I cannot support acceptance of this work at ICLR.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "metareview"
    },
    "Reviews": [
        {
            "title": "Interesting work, but I believe a few questions need to be answered to make the paper strong enough for acceptance. ",
            "review": "Summary of the paper:\nThis paper proposed RectGrad, a gradient-based attribution method that tries to avoid the problem of noise in the attribution map. Further, authors hypothesize that noise is caused by the network carrying irrelevant features, as opposed to saturation, discontinuities, etc as hypothesized by related papers. \n\nThe paper is well written and easy to read through. \n\nStrengths:\n- Formally addresses a hitherto unanswered question of why saliency maps are noisy. This is an important contribution.\n- RectGrad is easy to implement.\n\nQuestions for authors:\n- Since the authors are saying that the validity of their hypothesis is “trivial”, it would be nice to have this statement supported by more quantitative, dataset-wide analyses on the feature map and training dataset occlusion tests. For e.g., what percentage of the test dataset shows attributions on the 10x10 occluded patch? \n- How does RectGrad compare with simply applying a final threshold on other attribution maps? How do the results on training data and feature occlusion change after such a threshold is applied? How do results on adversarial attacks change?\n- Could this method generalize to non-ReLU networks?  \n- Premise that auxiliary objects in the image are part of the background is not necessarily true. For instance, the hand in “lighter” is clearly important to know that the flame is from a lighter and not from a candle or some other form of fire. Similarly, the leaves in the “frog” example. \n- (Optional) As shown in (https://openreview.net/forum?id=B1xeyhCctQ) gradients on ReLU networks overlook the bias term. In the light of this, what is the authors’ take on whether a high bias-attribution is the cause for the noisy gradient-attribution? \n- (Optional) In some sense, RectGrad works because layers closer to the input may capture more focussed features than layers close to input which may activate features spread out all over the image. It would be interesting to see if RectGrad works for really small networks such as MobileNet (https://arxiv.org/abs/1801.04381) where such an explicit hierarchy of features may not be there. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "This paper proposes a new method for producing saliency maps and my main concerned is the objective evaluation. ",
            "review": "This paper studies how to better visually interpret a deep neural network. It proposes a new method to produce less noisy saliency maps, named RectGrad. RectGrad thresholds gradient during backprop in a layer-wise fashion in a similar manner to a previous work called Guided Backprop. The difference is that Guided Backprop employs a constant threshold, i.e. 0, while RectGrad uses an adaptive threshold based on a percentile hyper-parameter. The paper is well-written, including a comprehensive review of previous related works, an meaningful meta-level discussion for motivation, and a clear explanation of the proposed method. \n\nOne of my biggest concern is regarding the experiment and evaluation section. Conclusions are drawn based on the visualization of a few saliency maps. I am not sure how much I can trust these conclusions as the conclusions are drawn in a handy-wavy manner the examples are prone to cherry-picking and . For example, this is the conclusion in the Adversarial Attack paragraph: “we can conclude that Rectified Gradient is  equally or more class sensitive than baseline attribution methods”. As pointed out by the paper, the conclusion can be drawn from Figure 8 in the main paper and Figure 10 in Appendix A.1. However, the proposed method tends to produce a saliency map with higher sparsity, therefore the difference may appear more apparent. It is stretching to conclude that it is more class sensitive without further quantitative validation. \n\nEvaluation appears to be a common concern to the work on saliency maps.  The existing quantitative evaluation in the paper seems disconnected to the visual nature of saliency maps. Concretely, when can we say one saliency map looks better than another? Since this paper claims to produce less noisy saliency maps, what does it mean quantitatively? Is it true that it produces less pixels on the background? If so, can we evaluate it with foreground-background segmentation annotation to prove that point? Though how to evaluate saliency maps remains an open question, I feel some discussion on this paper would make the paper more insightful. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Insightful observations, but results are less convincing.",
            "review": "In the paper, the authors proposed a new saliency map method, based on some empirical observations about the cause of noisy gradients.\nSpecifically, through experiments, the authors clarified that the noisy gradients are due to irrelevant information propagated in the forward pass in DNN. Because the backpropagation follows the same pass, irrelevant feature are conveyed back to the input, which results in noisy gradients.\nTo avoid noisy gradients, the authors proposed a new backpropagation named Rectified Gradient (RectGrad). In RectGrad, the backward pass is filtered out if the product of the forward signal and the backward signal are smaller than a threshold. The authors claim that, with this modification in backpropagation, the gradients get less noisy.\nIn some experiments, the authors presented that RectGrad can produce clear saliency maps.\n\nI liked the first half of the paper: the observations that irrelevant forward passes are causing noisy gradients seem to be convincing. The experiments are designed well to support the claim.\nHere, I would like to point out, that noisy gradients in occluded images may be because of the convolutional structures. Each filter in convolution layer is trained to respond to certain patterns. Because the same filter is used for each of subimages, some filters can be activated occasionally on occluded parts. I think this does not happen if the network is densely connected without convolutional structures. The trained dense connection will be optimized to remove the effects of occluded parts. Hence, for such networks, the gradient will be zeros for occluded parts.\n\nThe second half of the paper (Sec.4 and 5) are not very much convincing to me.\nBelow, I raise several concerns.\n\n1. There is no justification on the definition of RectGrad: Why Rl = I(al * Rl > t) R(l+1)?\nThe authors presented Rl = I(al * Rl > t) R(l+1) as RectGrad, that can filter out irrelevant passes. However, there is no clear derivation of this formula: the definition suddenly appears. If the irrelevant forward passes are causes of noisy gradients, the modification Rl = I(al > t) R(l+1) seems to be more natural to me. It is also a natural extension to the ReLU backward pass Rl = I(al > 0) R(l+1). Why we need to filter out negative signals in backward pass?\n\n2. The experimental results are less convincing: Is RectGrad truly good?\nIn Sec.5.2, the authors presented saliency maps only on a few images, and claimed that they look nicely. However, it is not clear that those \"nicely looking\" saliency map are truly good ones. I expect the authors to put much efforts on quantitative comparisons rather than qualitative comparisons, so that we can understand that those \"nicely looking\" saliency maps are truly good ones.\nSec.5.3 presents some quantitative comparisons, however, the reported Sensitivity and ROAR/KAR on RectGrad are not significant. The authors mentioned that this may be because of the sparsity of RectGrad. However, if the sparsity is the harm, the underlying observations of RectGrad may have some errors. I think the current manuscript has an inconsistency between the fundamental idea (based on empirical observations) and the performance of RectGrad.\n\n[Minor Concern]\nIn Sec.5, the authors frequently refer to the figures in appendix. I think the main body of the paper should be self-contatined. I therefore think that some of the figures related to main results should appear in the main part.\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}