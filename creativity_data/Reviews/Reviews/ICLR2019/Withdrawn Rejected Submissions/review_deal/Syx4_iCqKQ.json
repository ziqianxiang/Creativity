{
    "Decision": {
        "metareview": "This work proposes a class of neural networks that can jointly perform classification and regression in the output space.\nThe authors explore the concept of polar prototypes which are points on the hypersphere in the output space. For classification, each class is described by a single polar prototype and training is equivalent to minimizing angular distances between examples and their class prototypes. For regression, training can be performed as a polar interpolation between two prototypes.\nAs rightly acknowledged by R3, “it is nice to see an alternative to the dominant cross-entropy loss and l2 loss for deep classification and regression respectively, also the ability to tackle both” at the same time.\n\nHowever, all reviewers and AC agreed that the current manuscript lacks convincing empirical evaluations that clearly show the benefits of the proposed approach. To strengthen the evaluation, (1) see R1’s concern regarding the state-of-the-art performance on CIFAR-10;  (2) see R3’s suggestion to use more challenging datasets (e.g. ImageNet), stronger backbone networks (e.g. densenet), and also other applications (e.g. object recognition and pose estimation; face recognition and age estimation as classification and regression problems); (3) see R2’s suggestions for more baselines to be compared to.\nTwo other requests to further strengthen the manuscript are: (1) finding alternative ways to MC or evolutionary algorithms (R2); (2) exploring class correlation in the prototype space (R2). \n\nIn the response, the authors acknowledged that their initial results were not aimed for state-of-the-art comparison, but to show that the proposed objective is comparable to minimizing softmax cross-entropy loss. The authors provide additional experiments using DenseNet as the base network and the results are still slightly inferior to state-of-the-art performance. \nThe experiments using ImageNet dataset have been promised by the authors (in response to R3), but are not included in the current revision. \n\nAC suggests in its current state the manuscript is not ready for a publication. We hope the reviews are useful for improving and revising the paper. \n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Meta-Review"
    },
    "Reviews": [
        {
            "title": "Interesting idea but need more convincing experiments",
            "review": "This paper proposes a unified framework for both classification and regression and a combination of both using pre-designed prototypes distributed on a hypersphere with max separation. It is nice to see an alternative to the dominant cross-entropy loss and l2 loss for deep classification and regression respectively, also the ability to tackle both in a shared output space is a plus. However, the experiments are limited and not convincing that the proposed framework offers a genuine alternatives to existing formulations. \n\nPros:\n\n•\tThe over idea appears to novel, despite its connections to various previous attempts to angular separation (Hasnat et al., 2017; Liu et al., 2017a; Wang et al., 2018; Zheng et al., 2018).\n•\tIt is nice to see a framework that can perform classification/regression multi-task learning. Many computer vision problems have this nature, e.g. object recognition and pose estimation; face recognition and age estimation. So addressing both problems jointly can potentially bring in mutual benefits.  \n\nCons:\n\n•\tThe experiments on CIFAR 10/100 seems to be at par with a conventional cross-entropy loss. It would be more convincing if more experiments on other more challenging datasets (e.g. ImageNet) using more powerfully backbone networks (e.g. densenet) can be provided.\n•\tIn the CIFAR experiments the hypersphere space dimension is set to the same as the number of classes. In this case, why not just use a one-hot vector to represent each class, and do L2 normalization to the output of the feature extraction network and then do softmax cross-entropy? As pointed out in Section 4, several works project network outputs to the hypersphere for classification through L2 normalization, which forces softmax cross-entropy to optimize for angular separation (Hasnat et al., 2017; Liu et al., 2017a; Wang et al., 2018; Zheng et al., 2018). These works should be compared here to convince the readers why it is necessary to use evolutionary algorithm or Monto-Carlo sampling to set the prototypes rather than just using one-hot vectors. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "review",
            "review": "Proposal to use polar regression for prediction problems. To do so, one maps the target variable into \"maximally separating prototypes\" laid in the D-hypersphere. For classification, the learning problem reduces to minimizing the angle between D-dimensional feature vectors and the associated D-dimensional polar prototype. A similar strategy applies to regression, where the continuous target variable is squeezed to the range of the hypersphere.\n\nThe authors claim that their method unifies, as opposed to much prior art, classification and regression approaches. I disagree with this claim, since we usually approach classification as a (normalized!) regression problem. In some cases the normalization is on the entire output space (single-label classification as in ImageNET), and in some other cases this normalization happens separately in each component of the output space (multi-label classification as in COCO). It is even possible to train an ImageNET classifier using mean squared error given unit-norm feature vectors (Tygert et al, 2017). As such, the \"unification\" proposed by the paper seems a bit blurry to me.\n\nI am unconvinced about the impact shown by the experiments. Table 1 shows accuracies far from the state-of-the-art (91% for all methods in CIFAR-10 versus 97% SOTA, 65% for the proposed method versus 75% SOTA) and throw some separation statistics without a clear correlation to accuracy. The experiment on semantic priors is inconclusive, as all non-baseline results are within error bars. The impact of Section 3.3. is also unclear, since obtaining semantic (digit rotation) interpolations in MNIST is a common feat achieved by unsupervised learning algorithms with decent feature learning.\n\nThe results from section 3.2 are interesting, although I would be interested in seeing a reduction-to-classification baseline, where the years are clustered to set up a classification problem, and the prediction is fine-tuned by a local regression.\n\nNote: Regressing to (random) polar prototypes was proposed in https://arxiv.org/abs/1704.05310",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting paper, but still need to improve",
            "review": "This paper unifies both classification and regression task based on the polar prototype network. For classification, the prototypes for all classes are chosen in advance based on a max-margin principle, while the embedding of all instances is then optimized to have small cosine distance to assigned prototypes. For the regression, the output value is interpolated between the two prototypes. Experiments on classification, regression, and combined tasks show the method can achieve good results.\n\nThe idea of using the prototype and the polar system is interesting, and the whole paper is well-written. However, there are still some problems and questions about this paper.\n1. There are two problems with using the max-margin prototypes. First, to maximize the smallest distance between two prototypes, the authors use MC or evolutionary algorithms to do the optimization, which may be time-consuming, and it may be extremely difficult when the prototype space is high dimension. Second, the previous approach indeed obtains discriminative prototypes, but we lose the **class correlation**. In the extreme case, it is equal distance between all prototypes, but some similar classes will have a smaller prototype distance than others. For example, the prototype distance between \"cat\" and \"dog\" should not be the same as that between \"car1\" and \"car2\". The semantic consideration in the paper can solve this problem to some extent, but there needs more evidence.\n\nUsing the pre-defined prototype is also considered in the paper \"M. Perrot et al. Regressive Virtual Metric Learning. NIPS15\". \n\n2. For the unified output space\nOne main contribution is that based on the polar system, the method unifies both classification and regression tasks in the same space. We can also do this in basic embedding algorithms. In the embedding space, a method can do both classification and regression with the nearest neighbor rule (based on majority voting and average respectively). The authors should compare with such kinds of methods in the experiments.\n\n3. Experiments\nFrom the experiments, using semantic cannot improve a lot for the classification task. The authors can try more datasets to validate is this the common scenario. The reviewer strongly suggests the authors should compare with more methods. For example, in some papers the prototypes are learned simultaneously (Snell et al. Prototypical networks for few-shot learning. NIPS17; Wen et al. A discriminative feature learning approach\nfor deep face recognition. ECCV16); while in other cases, there are no prototypes as we optimize the triplet/contrastive loss directly. First, the authors can compare classification performance with these approaches; besides, some visualization results can also show the used prototypes or embeddings. \nThe main advantage of the method is not stressed clearly in the experiments part. The authors can clarify it in later versions.\n\nThe final rating depends on the authors' response.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}