{
    "Decision": {
        "metareview": "All three reviewers found that the motivation for the proposed method was lacking and recommend rejection. The AC thus recommends the authors to take these comments in consideration when revising their manuscript.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Reject"
    },
    "Reviews": [
        {
            "title": "minor generalization of AdaGrad style methods",
            "review": "The paper presents a generalization of the Adagrad type methods using a min-max formulation and then presents two alternate algorithms to solve this formulation. \n\nIt is unclear to me that much extra generalization has been achieved over the original AdaGrad paper. That paper simply presents the choice of hyperparameters as an optimal solution to a proximal primal dual formulation. The formulation presented here appears to be another form of the proximal mapping formulation, and so it is unclear what the advance here is. The AdaGrad paper used a particular Bregman divergence, and different divergences yield slightly different methods, as is observed here by the authors when they use different divergence measures.\n\nThe Bregman divergences do make sense from a primal pual proximal formulation point of view, but why do you use a discrepancy function in your min-max formulation that comes from the \\phi - divergence family? Why not consider an L_p normalization of the discrepancy? \n\nThe difference between formulations (5) and (6) is not clearly specified. Did you mean to drop the constraints that \\beta \\in \\cal{B}_t ? Otherwise, why is (6) , which looks to be a re-write of (5), unconstrained and hence separable?\n\nThe authors claim that the method is free of parameter choices, but the initial \\beta_0 seems to be a crucial parameter here since it forms both a target and a lower bound for subsequent \\beta_t's. How is this parameter chosen and what effect does it have on convergence? From the results (Figs in Sec 5), this choice does significantly impact the final test loss obtained. \n    \nI could not find a proof for Thm 6 in the appendix. Did I over look it or is there a typo?",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Novel idea but theoretical guarantees and empirical results are not convincing.",
            "review": "This paper presents a method for adaptively tuning the learning rate in gradient descent methods. The authors consider the formulation of each gradient descent update as a quadratic minimization problem and they propose adding a phi-divergence between the learning rate that would be used and an auxiliary vector. The authors also propose adding a maximization over all learning rates in the update.  \n\nThe authors study an important problem and propose a novel method. The algorithms suggested by the author are also relatively clear, and it is great that the paper presents both theoretical results as well as numerical experiments.\n\nOn the other hand, I didn't find the main idea of hyper-regularization to be well-justified. It is not clear why adding an additional regularization term for the learning rate makes sense , and it is even less clear why this should be presented as a maxmin problem. This can make the update step much more complicated and is probably why the authors also propose a simpler alternating optimization algorithm as an alternative. Unfortunately, the authors do not discuss how this alternating optimization problem relates to the original one, and the theoretical guarantees are only presented for the original algorithm. The authors also do not justify the choice of phi-divergence as the regularizer for the learning rate. The theoretical guarantees in the paper also do not suggest that the algorithm presented in the paper is better than existing state-of-the-art methods, even in specific situations (i.e. the regret bounds don't appear better than the AdaGrad regret bounds). Moreover, without tests for statistical significance, I also didn't find the experimental results sufficiently compelling.\n\nSpecific comments and questions:\n1) Page 3: Equation (4): The paper would be stronger if the authors motivated why the regularization should be posed as an outer maximization.\n2) Page 3: \"we use the \\phi-divergence as our hyper-regularization\". Why is this a good choice of reuglarizer?\n3) Page 3: \"only a few extra calculations are required for each step\". This is a misleading comment, because the maximization can be hard when phi is complicated, even if the problem splits across dimensions.\n4) Page 4: \"The solution of problem (5) is the same as (7) in unconstrained case\". You should provide a reference for this statement as well as discuss the specific assumptions on the objective that allow you to arrive at this claim.\n5) Page 4: \"while the solution of (7) is more difficult to get. Thus, we choose (5) as our basic problem\". This seems like a very bad motivation for choosing the maxmin formulation. For instance, the problem would be even simpler if  you didn't include this extra phi-divergence at all.\n6) Page 4: \"Although setting \\eta-t=\\beta_t is our main focus...\". Why is smoothness in the learning rate a good property? \n7) Page 5: Equation (11). How do these iterates relate to the ones in equation (5) (e.g. when do they coincide, if ever)?\n8) Page 5: \"influence the efficient of our algorithms.\" Grammatical error.\n9) Page 6. \"our algorithms are robust to the choice of initial learning rates and do not rely on the Lipschitz constant or smoothness constant\". I'm not sure why this is a valuable property, since AdaGrad doesn't rely on these parameters either.\n10) Page 6: Theorems 6 and 7. How do these results depend on alpha and \\beta_t? This paper would be much stronger if the bounds depend on \\phi more clearly and if the authors were able to show that there exist choices of phi that make this algorithm better than existing methods.\n11) Page 6: Theorem 7: The dependence on G in the regret bound actually makes this worse than the AdaGrad regret bound.\n12) Page 7: \"KL_devergence\". Typo.\n13) Page 7: \"different update rules were compared in advance to select the specific one for any phi divergence in the following experiments.\" What does this mean exactly? How much of a difference does the choice of update rule make?\n14) Page 7: \"growth clipping is applied to all algorithms in our framework\". Why is this necessary, and how does it affect the theoretical results?\n14) Page 7-8: Figures 1, 2, and 3. It's hard to interpret the significance of these results without error bars.\n\n\n\n\n\n\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Unclear formulation, and Benefit of approach is not Demonstrated",
            "review": " Summary: \n%%%%%%%%%%%%%%%\nThe paper explores ways to adapt the learning rate rule through a new minimax formulation.\nThe authors provide regret bounds for their method in the online convex optimization setting.\n\nComments:\n%%%%%%%%%%%%%%%\n-I found the motivation of the approach to be very lacking.\nConcretely, it is not clear at all why the minimax formulation even makes sense, and the authors do not explain this issue.\n\n-While the authors provide regret guarantees for their method, the theoretical analysis does not reflect when is their approach  beneficial compared to standard adaptive methods. Concretely, their bounds compare with the well known bounds of AdaGrad. \nIt is nice that their approach enables to extract AdaGrad as a private case. But again, it is not clear what is the benefit of their extension.\n\n-Finally, the experiments do not illustrate almost any benefit of the new approach compared to standard adaptive methods.\n\n\nSummary\n%%%%%%%%%%%%%%%\nThe paper suggests a different approach to adapt the learning rate.\nUnfortunately, the reasoning behind the new approach is not very clear.\nAlso, nor theory neither experiments illustrate the benefit of this new approach over standard methods.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}