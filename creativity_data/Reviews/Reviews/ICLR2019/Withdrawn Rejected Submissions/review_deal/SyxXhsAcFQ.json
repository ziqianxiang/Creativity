{
    "Decision": {
        "metareview": "This paper studies group equivariant neural network representations by building on the work by [Cohen and Welling, '14], which introduced learning of group irreducible representations, and [Kondor'18], who introduced tensor product non-linearities operating directly in the group Fourier domain. \n\nReviewers highlighted the significance of the approach, but were also unanimously concerned by the lack of clarity of the current manuscript, making its widespread impact within ICLR difficult, and the lack of a large-scale experiment that corroborates the usefulness of the approach. They were also very positive about the improvements of the paper during the author response phase. The AC completely agrees with this assessment of the paper. Therefore, the paper cannot be accepted at this time, but the AC strongly encourages the authors to resubmit their work in the next conference cycle by addressing the above remarks (improve clarity of presentation and include a large-scale experiment). ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting ideas, but currently not sufficiently well presented"
    },
    "Reviews": [
        {
            "title": "Difficult to read, insufficient evaluation",
            "review": "This paper proposes autoencoder architectures based on Cohen-Welling bases for learning rotation-equivariant image representations. The models are evaluated by reconstruction error and classification in the space of the resulting basis on rotated-MNIST, showing performance improvements with small numbers of parameters and samples.\n\nI found most of this submission difficult to read and digest. I did not understand much of the exposition. I’ll freely admit I haven’t followed this line of work closely, and have little background in group theory, but I doubt I’m much of an outlier among the ICLR audience in that regard. The “Preliminaries” section is very dense and provides little hand-holding for the reader in the form of context, intuition, or motivation for each definition and remark it enumerates. I can't tell how much of the section is connected to the proposed models. (For comparison, I skimmed the prior work that this submission primarily builds upon (Cohen & Welling, 2014) and found it relatively unintimidating. It gently introduces each concept in terms that most readers familiar with common machine learning conventions would be comfortable with. It's possible to follow the overall argument and get the \"gist\" of the paper without understanding every detail.)\n\nAll that being said, I don’t doubt this paper makes some interesting and important contributions -- I just don’t understand what they are.\n\nHere are some specific comments and questions, mostly on the proposed approaches and experiments:\n\n* What actually is the “tensor (product) nonlinearity”? Given that this is in the title and is repeatedly emphasized in the text, I expected that it would be presented much more prominently. But after reading the entire paper I’m still not 100% sure what “tensor nonlinearity” refers to.\n\n* Experiments: all models are described in long-form prose. It’s very difficult to read and follow. This could be made much clearer with an algorithm box or similar.\n\n* The motivation for the “Coupled Autoencoder” model isn’t clear. What, intuitively, is to be gained from reconstructing a high-resolution image from a low-resolution basis and vice versa? The empirical gains are marginal.\n\n* Experiments: the structure of the section is hard to follow. (1) and (2) are descriptions of two different models to do the same thing (autoencoding); then (3) (bootstrapping) is another step done on top of (1), and finally (4) is a classifier, trained on top of (1) or (2). This could benefit from restructuring.\n\n* There are long lists of integer multiplicities a_i and b_i: these seem to come out of nowhere, with no explanation of how or why they were chosen -- just that they result in “learn[ing] a really sharp W_28”. Why not learn them?\n\n* How are the models optimized? (Which optimizer, hyperparameters, etc.?)\n\n* The baseline methods should also be run on the smaller numbers of examples (500 or 12K) that the proposed approach is run on.\n\n* A planar CNN baseline should be considered for the autoencoder experiments.\n\n* Validating on MNIST alone (rotated, spherical, or otherwise) isn’t good enough in 2018. The conclusions section mentions testing the models with deeper nets on CIFAR, but the results are not reported -- only hinting that it doesn’t work well. This doesn’t inspire much confidence.\n\n* Why are Spherical CNNs (Cohen et al., 2018) a good baseline for this dataset? The MNIST-rot data is not spherical.\n\n* Table 1: The method labels (Ours, 28/14 Tensor, and 28/14 Scale) are not very clear (though they are described in the text)\n\n* Table 1: Why not include the classification results for the standard AE? (They are in the Fig. 6 plot, but not the table.)\n\n* Conclusions: “We believe our classifiers built from bases learnt in a CAE architecture should be robust to noise” -- Why? No reasons are given for this belief.\n\n* There are many typos and grammatical errors and odd/inconsistent formatting (e.g., underlined subsection headers) throughout the paper that should be revised.",
            "rating": "3: Clear rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "A bit rough around the edges, but there are some interesting lessons to be learned here if one reads between the lines.",
            "review": "Recently there has been a spate of work on generalized CNNs that are equivariant to various symmetry groups, such a 2D and 3D rotations, the corresponding Euclidean groups (comprising not just rotations but also translations) and so on. The approach taken in most of the recent papers is to explicitly build in these equivariances by using the appropriate generalization of convolution. In the case of nontrivial groups this effectively means working in Fourier space, i.e., transforming to a basis that is adapted to the group action. This requires some considerations from represntation theory. \n\nEarlier, however, there was some less recognized work by Cohen and Welling on actually learning the correct basis itself from data. The present paper takes this second approach, and shows for a simple task like rotated MNIST, the basis can be learned from a remarkably small amount of data, and actually performs even better than some of the fixed basis methods. There is one major caveat: the nonlinearity itself has to be rotation-covariant, and for this purpose they use the recently introduced tensor product nonlinearities. \n\nThe paper is a little rough around the edges. In the first 4 pages it launches into an exposition of ideas from representation theory which is too general for the purpose: SO(2) is a really simple commutative group, so the way that \"tensor product\" representations reduce to irreducibles could be summed up in the formula  $e^{-2\\pi i k_1 x}e^{-2\\pi i k_2 x}=e^{-2\\pi i (k_1+k_2) x}$. I am not sure why the authors choose to use real representations (maybe because complex numbers are not supported in PyTorch, but this could easily be hacked) and I find that the real representations make things unnecessarily complicated. I suspect that at the end of the day the algorithm does something very simple (please clarify if working with \nreal representations is somehow crucial). \n\nBut this is exactly the beauty of the approach. The whole algorithm is very rough, there are only two layers (!), no effort to carefully implement nice exact group convolutions, and still the network is as good as the competition. Another significant point is that this network is only equivariant to rotations and not translations. \n\nNaturally, the question arises why one would want to learn the group adapted basis, when one could just compute it explicitly. There are two interesting lessons here that the authors could emphasize more:\n\n1. Having a covariant nonlinearity is strong enough of a condition to force the network to learn a group adapted (Cohen-Welling) basis. This is interesting because Fourier space (\"tensor\") nonlinearities are a relatively new idea in the literature. This finding suggests that the nonlinearity might actually be more important than the basis.\n\n2. The images that the authors work on are not functions on R^2, but just on a 28x28 grid. Rotating a rasterized image with eg. scikit-rotate introduces various artifacts. Similarly, going back and forth between a rasterized and polar coordinate based representation (which is effectively what would be required for \"Harmonic Networks\" and other Fourier methods) introduces messy interpolation issues. Not to mention downsampling, which is actually addressed in the paper. If a network can figure out how to best handle these issues from data, that makes things easier.\n\nThe experiments are admittedly very small scale, although some of the other publications in this field also only have small experiments. At the very least it would be nice to have standard deviations on the results and some measure of statistical significance. It would be even nicer to have some visualization of the learned bases/filters, and a bare bones matrix-level very simple description of the algorith. Again, what is impressive here is that such a small network can learn to do this task reasonably well.\n\nSuggestions: \n\n1. Also cite the Tensor Field Networks of Thomas et al in the context of tensor product nonlinearities.\n\n2. Clean up the formatting. \"This leads us to the following\" in a line by itself looks strange. Similarly \"Classification ising the learned CW-basis\". I think something went wrong with \\itemize in Section 3.1. \n\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An Important Problem, but insufficient experiments and unsure about some details of method",
            "review": "Review: This paper deals with the issue of learning rotation invariant autoencoders and classifiers.  While this problem is well motivated, I found that this paper was fairly weak experimentally, and I also found it difficult to determine what the exact algorithm was.  For example, how the optimization was done is not discussed at all.  At the same time, I'm not an expert in group theory, so it's possible that the paper has technical novelty or significance which I did not appreciate.  \n\nStrengths: \n\n -The challenge of learning rotation equivariant representations is well motivated and the idea of learning representations which transfer between different scales also seems useful.  \n\nWeaknesses: \n  \n-I had a difficult time understanding how the preliminaries (section 2) were related to the experiments (section 3).  \n\n-The reference (Kondor 2018) is used a lot but could refer to three different papers that are in the references.  \n\n  -Only reported results are on rotated mnist, but the improvements seem reasonable, but unless I'm missing something are worse than the 1.62% error reported by harmonic nets (mentioned in the introduction of the paper).  In addition to rot-mnist, harmonic nets evaluated boundary detection on the berkeley segmentation dataset.  \n\n  -It's interesting that the model learns to be somewhat invariant across scales, but I think that the baselines for this could be better.  For example, using a convolution network with mean pooling at the end, one could estimate how well the normal classifier handles evaluation at a different scale from that used during training (I imagine the invariance would be somewhat bad but it's important to confirm).  \n\n\nQuestions: \n\n-Section 3.1 makes reference to \"learning parameters\".  I assume that this is done in the usual way with backpropagation and then SGD/Adam or something?  \n\n-How is it guaranteed that W is orthogonal in the learning procedure?  \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}