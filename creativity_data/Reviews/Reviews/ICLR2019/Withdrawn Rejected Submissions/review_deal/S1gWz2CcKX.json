{
    "Decision": {
        "metareview": "The reviewers raise a number of concerns including limited methodological novelty, limited experimental evaluation (comparisons), and poor readability. Although the authors did address some of the concerns, the paper as is needs a lot of polishing and rewriting. Hence, I cannot recommend this work for presentation at ICLR.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "metareview"
    },
    "Reviews": [
        {
            "title": "Interesting ideas and results but lacking clarity and focus. ",
            "review": "This paper proposes a multi agent life simulators as an environment for RL. The environment is procedurally generated, with possibly many different game dynamics including foraging, and combat. They train deep RL agents in this environment and show various emergent behaviors such as exploration, and niche development. Additionally, they propose a tournament competition scheme to evaluate different populations of agents against each other.\n\nThis paper has a number of interesting findings, but overall lacks polish and coherence. The writing is verbose and informal in many places. There are many details not included -- for example specifics on combat targeting, how RL agents are trained, and information how to parse figures (what do colors mean?).\n\nPro\n+ Interesting idea, and demonstration of a system. From the intro, I believe an environment such as this is will be fruitful to study.\n+ Results seem preliminary but are interesting. In particular, the finding that agents generalize and thus perform better on tournament selection when trained in larger population is intriguing as well as the exploration results with population count!\n+ Reproducibility: authors claim they will release environment simulator code.\n\nCon\n- Paper can be considerably tightened. It is currently quite long (9.5 pages vs the suggested 8 page). There are also a lot of details included that don't seem core to the message. For example -- the multiple types of API / IPC communication, much of the RPGs section.\n- Some areas of writing could be improved, either too casual, or sloppy. For example -- various names are not capitalized in bibliography.\n- Examples of imprecise / casual writing: \"good performance without discounting, but training was less stable.\" What does \"less stable\" actually mean? \"postprocess trajectories using a discount factor\" this is part of the REINFORCE algorithm -- postprocessing, to me, implies modifying the observations. The term \"numerical collapse\" is not a term I am aware of.\n- It is unclear what is shown in many of the figures. What are the colors in figures 8,9,10 for example? \n- Lots of details and ongoing work put in which distracts from a clear message. For example, why was \"entity targeting\" included? It doesn't appear to be described and the results shown in figure 10 are confusing. I would consider stepping back, and figuring out what one thing you want to show the reader, then drop all detail not around that point.\n- Lacking a conclusion of somesort. Ideally there would be something to pull the whole paper together.\n- use of terminology -- unclear why neural mmo is name of this environment. This is not a MMO, nor does the environment have anything \"neural\" related -- one can train reinforcement learning agents without neural network function approximators on it for example. I would consider renaming.\n\nIn its current form, I do not recommend accepting this paper but I do encourage the authors to continue working on it to both tighten the writing and presentation as well as continue to show interesting results via RL experiments.\n\n\n\nEDIT: See bellow, raised score from 4 --> 6.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official Review: a multiplayer environment. Lacks comparison with related settings, many arbitrary choices, needs rewriting.",
            "review": "The paper presents a new evaluation platform based on massive multiplayer games, allowing for a huge number of neural agents in persistent environments.\nThe justification evolves from MMO as a source of complex behaviours arguing that these settings have some characteristics of life on earth, being a “competitive game of life”. However, there are many combinations with completely different insights and implications. The key characteristics for the setting in this paper seem to be:\n1.\tCognitive evolution with learning, rather than physical or just genetic evolution (all bodies and architectures are equal)\n2.\tChanging environments (tasks), between parameter updates\n3.\tSurvival-oriented rewards\nAnd for some experiments some agents share policy parameters to simulate “species”.\nFrom the introduction and the rest of the paper, it’s not clear whether the same platform can be used with agents that are not neural, or even agents that are hardcoded (for the sake of diversity or to analyse specific behaviours). This is an important issue, as other platforms allow for the definition of some baseline agents, including random agents, agents with simple policies, etc.\nThe background and related work section covers MMO and artificial life, but has some important omissions, especially those ideas in the recent literature that are closest to this proposal.\nFirst, why can’t Yang et al., 2018 be extended with further tasks? \nSecond, conceptually, the whole setting is very similar to the Darwin-Wallace setting proposed in Orello et al. 2011:\n@inproceedings{hernandez2011more,\n  title={On more realistic environment distributions for defining, evaluating and developing intelligence},\n  author={Hern{\\'a}ndez-Orallo, Jos{\\'e} and Dowe, David L and Espa{\\~n}a-Cubillo, Sergio and Hern{\\'a}ndez-Lloreda, M Victoria and Insa-Cabrera, Javier},\n  booktitle={International Conference on Artificial General Intelligence},\n  pages={82--91},\n  year={2011},\n  organization={Springer}\n}\n\nThe three characteristics mentioned before are the key elements of this evaluation setting, which changes environments between generations. Also, the setting is presented in the context of evaluation and experimentation, as this manuscript.\n\nThird, regarding multi-agent evaluation setting, Marlo over Minecraft (Malmo) is covering this niche as well. \n\nhttps://marlo-ai.github.io/\n\nAlthough it is episodic and the number of agents is limited, this should be compared too.\n\nNevertheless, the authors should make a more convincing argument about why we need *massively* multiplayer settings. Why is it the case that some behaviours and skills appear with thousands of agents but cannot appear with dozens of examples? In evolutionary game theory, for instance, some complex situations emerge from very few agents.\n\nFinally, the use of agents that have to survive with “health, food and water” and its use as experimental setting can be found in Strannegård et al. 2018.   \nhttps://www.degruyter.com/downloadpdf/j/jagi.2018.9.issue-1/jagi-2018-0002/jagi-2018-0002.pdf\nFigures are not very helpful. Especially the captions do not really explain what we see in the figures. For instance, Figure 2 doesn’t show much. Figure 3 left and middle show some weird dots and patterns, but they are not explained. Also, the one on the right tries to show “ghosting”, but colours and their meaning are not explained. Similarly, it is not clear what the agents see and process. I assume it is a local grid as the one seen in figure 4. But this is quite an aerial view, and other grid options might do the job as well.\nSimilarly, some actions are mentioned (it seems that N, S, E, W and “Pass”? plus some attack options, but they are not described). In the end, I understand many choices have to be made for any evaluating setting, but many choices are very arbitrary (end of section 3 and especially experiments) and there is a lot of tuning, so it’s unclear whether some of the observations happen just in a particular combination of choices, but are more general. The authors end up with many inconclusive observations and doubts (“perhaps”) about small changes, at the end of section 5.\nOther things such as the “spawn cap” and the “server merge” are poorly explained, with clear definitions and proper justification of their role. Similarly, I’m not sure about how reproduction takes place or not, and if so, whether weights are inherited or reinitialised. Something related is said about species.\nI found the statement about multiagent competition being a curriculum magnifier, not a curriculum itself, very interesting, but is this really shown in the paper or elsewhere?\nIn general, I miss many details and justifications for the whole architecture and mechanism of this neural MMO.\nPros:\n-\tDesigned to be scalable\n-\tGoes in the right direction of benchmarks that can capture generally variable (social) behaviour.\nCons:\n-\tPoor comparison with existing platforms and similar ideas.\n-\tToo many arbitrary decisions for the setting and the experiments to make it work or show complex behaviours\n-\tThe paper needs extensive rewriting, clarifying many details, with the figures really helping for the understanding.\nTypos and minor things: \n-\t“Susan Zhang 2018” is named a couple of times, but the reference is missing. Also, it is quite unusual to use the given name for this researcher while this is not done for any other of the references.\n-\t“as show in Figure 2” -> shown\n-\t“impassible” -> “impassable”\n\n****************************\nI've read the new comments from the authors and the new version of the paper. I think that the paper has improved significantly in terms of presentations, coverage of related work. I still see that the contribution is somewhat limited, but I'm updating the score to better account with this new version of the paper.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Revised Review (Score revised up to 7, from 5)",
            "review": "Revised Review:\n\nThe authors of this work has taken my concerns, and concerns of other reviewers, and revised their paper during the rebuttal period. They have increased the quality of the writing / clarity, restructured the presentation (i.e. put many details in the Appendix section), and committed to open-sourcing the platform post publication. For these reasons I believe this work is now at a state that should be published at ICLR, and I revised my score from 5 to 7. I hope other reviewers can reread the work and post their updated comments.\n\nI'm excited about the work, because it incorporates good ideas from A-Life / evolution / open-endedness communities, to introduce new paradigms and new ways of thinking to the RL community. I look forward to using this environment in my own research going forward, regardless of whether this work gets accepted or not. Good luck!\n\nMinor comment: On page 4, the section 5 Experiments, I think \"Technical details\" should be in bold font before the sentence \"We run each experiment using 100 worlds.\" so it is distinguished from being part of that sentence.\n\nOriginal Review:\n\nThe authors present a new game environment inspired by MMORPGs. The environment supports a \"massive\" number of agents, each have different neural net brains (*) and have some foraging and combat skills. They use distributed RL to train the policies (using REINFORCE) and over time can observe the dynamics of the population of these artificial life agents interact with each other, where the only reward is survival. There are many interesting insights, such as looking at how multi-agent cooperative (and deceptive) strategies emerge, and how some agents with different niche skills co-evolve with agents with other niche skills. They also plan to open source the platform and I have high hopes that this will be a fantastic research environment. While I'm very optimistic about this work and direction, there are issues with this particular paper, and I feel it is not ready for publication in its current form. While I have no doubt that the software project will be great, as a reviewer I'm evaluating this particular paper, and I want to highlight flaws about the paper and what can be done to fix it during the rebuttal/review period.\n\nMy recommendations to improve the article:\n\n(1) Writing - I really enjoyed this work, but frankly, the writing is horrible. It took me days of effort to decipher every paragraph and understand all the terms and what is going on. The article reads like it is written by the person who programmed the game, and played MMORPGs almost every day of his childhood and adult life, so someone who is not reading the article thru the lens of the author might have an incredibly tough time digesting the content. For instance, there are sentences like \"It adds melee, ranged, and magic-based combat\"... \"Melee, ranged, and magic combat have maximum Manhattan distance of effect of 1, 2, and 3 cells respectively. They do 10, 2, and 1 damage respectively\"... \"This prevents uninteresting 'spawn killing' and is a common technique in human games\". These are only a small selection of samples. There are also terminology like \"#ent and #pop\" which I feel should be replaced by $N_{ent}$ and $N_{pop}$ for a paper. In contrast, older works related to population-based RL training like [2], or RL in games like [3] are examples of clear and understandable writing. I highly recommend you give the draft to someone outside of your team, who is sufficiently isolated from this project (or perhaps to a professional writer if your lab has one), to go over each paragraph, and make the writing more clear. This would benefit the work in the long term as people refer back to the paper when they run your code.\n\n(2) Diagrams - While the diagrams look interesting, IMO they are poorly made. When I look at Figure 1, 4, and 9, it is really difficult to understand what is going on. I recommend redoing the diagrams, perhaps get some inspiration from distill.pub or OpenAI blog posts. There are things that are not clear, like what the inputs are into each agent, and how the training works. I recommend having some pseudocode snippets (like the Gym framework) to explain parts of the overall picture in more detail as figures.\n\nGiven a work of this magnitude, I'm personally okay that they went over 8 pages, as long as it is properly used for clarity.\n\nDiscussion:\n\nConcepts from Artificial Life and Evolution has been introduced in this work. There is some confusion between what is \"learning\" and what has been \"evolved\" in your setup. Some readers coming from the evolution, or biology fields (who I bet will find your paper interesting to read and experiment with) might interpret \"learning\" to be weight changes during a life time, while \"evolution\" would be changes to the weight parameters from one generation to the next, but I think in policy-gradient RL, \"learning\" means weight changes after an agent dies and is reborn. Should consider clarifying in the introduction, the definition of learning, and whether it is inter-life or intra-life.\n\nYou cited some of Stanley's talks on open-endedness, but I wonder if you considered their work [1] where they proposed that having a minimum criteria condition might encourage diversity of solutions. For instance, perhaps in your environment, an agent doesn't have to be the very best, but only manage to survive, to move on to the next generation, which might cause very interesting multi-agent population dynamics. A parallel to modern life is that people (at least those in wealthy nations) live with such a good social safety net that people don't really have to be the best \"agent\" to reproduce and survive, and this might explain the large diverse cultures and ideas we end up with as human species, compared to other animals (where the current game is probably a suitable model of). An experiment to explore an experiment where only the very weakest agents die, but leaving agents with mediocre foraging and combat skills still live on (and pursue their own interests, whatever they may be) will be super interesting, and I encourage you to explore these ideas of open-endedness.\n\nBugs: In the appendix, the citation for OpenAI Five needs fixing.\n\nCurrently it pains me that I can only assign a score of 5 of this work (NOTE: this has been since revised upwards to 7 upon reading revision after rebuttal period), since I don't think the current writing is up to standards. In my opinion, it deserves a score of 7-8. If you work on points (1) and (2) and submit a revised draft with much better writing, visualization, figures to explain the work, I'll happily revise my score and improve it by 1-3 points depending on how much improvement is made.\n\n[1] Brand and Stanley. \"Minimal Criterion Coevolution: A New Approach to Open-Ended Search\" (GECCO 2017) http://eplex.cs.ucf.edu/papers/brant_gecco17.pdf\n[2] https://arxiv.org/abs/1703.03864\n[3] https://arxiv.org/abs/1804.03720\n\n(*) well, sort of, due to compute limits they are clustered to some extent to their species, so agents within a species have identical brains, unlike the real world.\n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}