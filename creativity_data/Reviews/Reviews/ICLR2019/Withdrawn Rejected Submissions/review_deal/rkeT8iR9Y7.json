{
    "Decision": {
        "metareview": "The paper presents a careful analysis of SGD by characterizing the stochastic gradient via von Mises-Fisher distributions. While the paper has good quality and clarity, and the authors' detailed response has further clarified several raised issues, some important concerns remain: Reviewer 1 would like to see careful discussions on related observations by other work in the literature, such as low rank Hessians in the over-parameterized regime, Reviewer 2 is concerned about the significance of the presented analysis and observations, and Reviewers 2 and 4 both would like to see how the presented theoretical analysis could be used to design improved algorithms. In the AC's opinion, while solid theoretical analysis of SGD is definitely valuable, it is highly desirable to demonstrate its practical value (considering that it does not provide clearly new insights about the learning dynamics of SGD).",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Good quality and clarity but limited novelty and significance "
    },
    "Reviews": [
        {
            "title": "The theory looks good but how can it be used?",
            "review": "\nGradient stochasticity is used to analyse the learning dynamics of SGD. It consists of two aspects: norm stochasticity and directional stochasticity. Although the norm stochasticity is easy to compute, it vanishes when the batch size increases. Therefore, it can be hard to measure the learning dynamics of SGD. The paper is motivated by measuring the learning dynamics by the directional stochasticity. Directly measuring the directional stochasticity with the ange distribution is hard, so the paper uses vMF distribution to approximate the uniformity measurement. The paper theoretically studies the proposed directional uniformity measurement. In addition, the experiments empirically show the directional uniformity measurement is more coherent with the gradient stochasticity.\n\n1. As I’m not a theory person, I’m not very familiar with the related work on this line. But the analysis on the directional uniformity is interesting and original. So is the vMF approximation.\n2. The theoretical analysis looks comprehensive and intuitive. And the authors did a reasonably good job on the experiments.\n3. This paper provides some insights that warn people to pay attention to the directions of SGD. But the paper didn’t provide an answer on how this study can inform people to improve SGD. It’s true that the directional uniformity increases over training and it is correlated to the gradient. But what could this bring us remains unstudied.\n4. Can the authors provide any theoretical or empirical analysis on why the directional uniformity didn’t increase in deep models like CNN and why it increases when BN and Res are applied?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting idea but implications, significance, theoretical analysis and experiments need improvements.",
            "review": "\nQuality and clarity: good.\n\nOriginality and significance: This paper studies the stochasticity\nof the norms and directions of the mini-batch gradients, to\nunderstand SGD dynamics. The contributions of this paper can be\nsummarized as: a) This paper defines gradient norm stochasticity as\nthe ratio of the variance of the stochastic norm to the expectation\nof the stochastic norm. It theoretically and empirically shows that\nthis value is reduced as the batch size increases b) This paper\nempirically finds that the distribution of angles between\nmini-batch gradient and a given uniformly sampled unit vector\nconverges to an asymptotic distribution with mean 90 degrees, which\nimplies a uniform distribution of the mini-batch gradients. c)\t\nThis paper uses von Mises-Fisher Distribution to approximate the\ndistribution of the mini-batch gradients. By theoretically and\nempirically observing that the estimated parameter \\hat \\kappa\ndecreases during training, they claim that the directional\nuniformity of mini-batch gradients increases over SGD training.\n\nThe idea of measuring the uniformity of mini-batch gradients\nthrough VMF distribution seems interesting. But it is unclear how\nthe study of this stochasticity dynamics of SGD can be related to\nthe convergence behavior of SGD for non-convex problems and/or the\ngeneralization performance of SGD.\n\nThere are additional concerns/questions regarding both theoretical\npart and empirical part:\n\n[1] Section3.3: Assumption that p_i(w_0^0) =p_i(w_1^0) = p_i is not\nreasonable when theoretically comparing \\hat \\kappa(w_1^0) and \\hat\n\\kappa(w_0^0). The concentration parameter \\hat \\kappa(w) should be\nestimated by the sum of the normalized mini-batch gradients \"\\hat\ng_i(w)/||\\hat g_i(w)||\" . Instead of using mini-batch gradient,\nthis paper uses the sum of \"p_i-w\" by assuming that \"p_i(w_0^0) -w\"\nis parallel to \"\\hat g_i(w)\", which is ok. However, when comparing\n\\hat \\kappa(w_0^0) and \\hat \\kappa(w_1^0), we say \\hat\n\\kappa(w_0^0) = h(\\sum p_i(w_0^0) - w_0^0) ) and \\hat \\kappa(w_1^0)\n= h(\\sum p_i(w_1^0) - w_1^0) ). It is not reasonable to use the\nsame p_i for p_i(w_0^0) and p_i(w_1^0) because p_i(w_0^0) -w_1^0 is\ndefinitely not parallel to \\hat g_i(w_1^0).\n\n[2] Section 3.3: Assumption \\hat g_i(w_t^{i-1}) \\hat g_i(w_t^0) is\nnot convincing. With this assumption, the paper writes w_1^0 =\nw_0^0 - \\eta\\sum_i \\hat g_i(w_0^{i-1}) = w_0^0 - \\eta\\sum_i \\hat\ng_i(w_0^0) = w_0^0 - \\eta \\sum_i p_i-w_0^0. These equalities are\nnot persuasive. Because, \\sum_i \\hat g_i(w_0^0) is the full\ngradient g(w_0^0) at w_0^0. In other words, these equalities imply\nthat from w_0^0 to w_1^0 (one epoch), SGD is doing a full gradient\ndescent: w_1^0 = w_0^0 -\\eta g(w_0^0), which is not the case in\nreality.\n\n[3] Experiment: Batch size should be consistent with the given\nassumption in the theoretical part. In theoretical part, \\hat\n\\kappa(w_1^0) < \\hat \\kappa(w_0^0) is based on the assumption that\n|\\hat g_i(wt^{i-1}| \\tat for all i, with *large mini-batch size*.\nBut in the experiment, they prove \\hat \\kappa(w_1^0) < \\hat\n\\kappa(w_0^0) by using small-batch size which is 64. The authors\nshould either provide experiments with large batch size or try to\navoid the assumption of large batch size in theoretical part.\n\n[4] The CNN experiment; It is better to add a discussion why the\n\\kappa increases in the early phase of training.\n\n[5] The experiment results show, by the end of training, all models\nFNN, DENN and CNN have very large value of \\kappa which is around\n10^4. This value implies that the mini-batch gradients distribution\nis pretty concentrated, and it is contradictory to the statement in\nthe introduction which is \"SGD converges or terminates when either\nthe norm of the minibatch gradient vanishes to zeros, or when the\nangles of the mini-batch gradients are uniformly distributed and\ntheir non-zero norms are close to each other''. It is also\ncontradictory to the experiment in 3.2 which implies the mini-batch\ngradient are uniformly distributed after training.\n\n[6] The notations in this paper can be improved, some notations are\nusing \"i\" for batch index, some notations are using \"i\" for one\ndata sample. Some notations in Section 3.3 and 3.1 can be moved to\nSection 2 Preliminaries. It will be clearer to define all the\nnotations in one place.\n\nTypos: -Section 3.1: first paragraph, E\\hat g(w) -> E[\\hat g(w)]; -\nParagraph before Lemma2: \\hat \\kappa increases -> \\hat \\kappa\ndecreases; - Paragraph after Theorem2: double the directions in \"If\nSGD iterations indeed drive the directions the directions of\nminibatch gradients to be uniform\".",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Contribution not entirely clear",
            "review": "Summary: This work provides an analysis of the directional distribution of of stochastic gradients in SGD. The basic claim is that the distribution, when modeled as a von Mises-Fisher distribution, becomes more uniform as training progresses. There is experimental verification of this claim, and some results suggesting that the SNR is more correlated with their measure of uniformity than with the norm of the gradients.\n\nQuality: The proofs appear correct to me. \n\nClarity: The paper is generally easy to read.\n\nOriginality & Significance: I don't know of this specific analysis existing in the literature, so in that sense it may be original. Nonetheless, I think there are serious issues with the significance. The idea that there are two phases of optimization is not particularly new (see for example Bertsekas 2015) and the paper's claim that uniformity of direction increases as SGD convergence is easy to see in a simple example. Consider f_i(x) = |x-b_i|^2  quadratics with different centers. Clearly the minimum will be the centroid. Outside of a ball of certain radius from the centroid all of the gradients grad f_i point in the same direction, closer to the minimum they will point towards their respective centers. It is pretty clear, then that uniformity goes up as convergence proceeds, depending on the arrangement of the centers.\n\nThe analysis in the paper is clearly more general and meaningful than the toy example, but I am not seeing what the take-home is other than the insight generated by the toy example. The paper would be improved by clarifying how this analysis provides additional insight, providing more analysis on the norm SNR vs uniformity experiment at the end. \n\nPros:\n- SGD is a central algorithm and further analysis laying out its properties is important\n- Thorough experiments.\n\nCons:\n- It is not entirely clear what the contribution is.\n\nSpecific comments:\n- The comment at the top of page 4 about the convergence of the minibatch gradients is a bit strange. This could also be seen as the reason that analysis of the convergence of SGD rely on annealed step sizes. Without annealing step-sizes, it's fairly clear that SGD will converge to a kind of stochastic process.\n\n- The paper would be stronger if the authors try to turn this insight into something actionable, either by providing a theoretical result that gives guidance or some practical algorithmic suggestions that exploit it.\n\nDimitri P. Bertsekas. Incremental Gradient, Subgradient, and Proximal Methods for Convex Optimization: A Survey. ArXiv 2015.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}