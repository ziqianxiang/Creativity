{
    "Decision": {
        "metareview": "This paper proposes a neural network based method for computing committor functions, which are used to understand transitions between stable states in complex systems.\nThe authors improve over the techniques of Khoo et al. with a method to approximately satisfy boundary conditions and an importance sampling method to deal with rare events.\nThis is a good application paper, introducing a new application to the ML audience, but the technical novelty is a bit limited. The reviewers see value in the paper, however scaling w.r.t. dimensionality appears to be an issue with this approach.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Borderline paper"
    },
    "Reviews": [
        {
            "title": "Interesting application paper, somewhat incremental improvement over prior work",
            "review": "This paper looks at the problem of computing committor functions, which is defined as the probability a state first visits a local minimum of the energy landscape in Langevin dynamics. The authors motivates the problem well by explaining why this is difficult to compute. Khoo et al, 2018 uses a deep network to variationally approximate this function. The major contribution of this paper is several improvements to the techniques of Khoo et al. I will comment on each of the improvements in turn. \n\nIn section 3.1 the authors proposes that instead of using optimization to satisfy boundary condition, it might be better to parameterize the function to satisfy the boundary condition. This contribution seems incremental. Eq.(9) guarantees satisfaction of the boundary conditions when lambda is large enough, so I imagine that lambda is not very difficult to pick. Therefore, the practical reason to use the more sophisticated parameterization is unclear. The new proposal removes a hyper-parameter lambda, but introduces new hyper-parameters epsilon and the exact smoothing for the two functions X_A, X_B.\n\nThe contribution in 3.2 seems interesting. The authors replace the original sampling function, which has high variance, with importance sampling. It seems that importance sampling is very well suited for this problem, and the authors found a very natural and reasonable proposal distribution. This method is generally interesting for estimating the expectation of any random variable with respect to a Boltzmann distribution.\n\nIn section 3.3 the authors proposes to work on a feature space. This is interesting to audience interested in the specific applications. But for machine learning this is a standard procedure, so has limited methodology novelty. \n\nOne issue of this paper is limited audience in ICLR. It seems much more appropriate to submit to statistical physics, material science or other relevant communities. I am not capable to judge the significance of this paper to those communities. As an application paper, the proposed methods are somewhat incremental; I only find section 3.2 interesting to a broader audience. \n\nWriting:\nI like the writing. Everything symbol is defined before use, and the notation is clean and unambiguous. I can easily follow the author’s arguments down to the minor details. \n\nA minor improvement to section 2 is to first explain the shortcoming of Eq.(5), then introduce Eq.(6)(7). \n\nEq.(11) can be better explained. The definition doesn’t look like a smooth function, and it takes some time to figure out what the authors mean here. \n\nMinor comments:\nA, B \\in \\Omega should be A, B \\subset \\Omega in Section 2\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Experiments need to be improved",
            "review": "In response to the authors' rebuttal, I have increased my ratings accordingly. I strongly encourage the authors to include those ablative study results in the work. I also strongly recommend an ablative study on importance sampling so as to provide more quantitative results, in addition to Fig. 4. Finally, I hope the authors can consider more advanced importance sampling techniques and explore whether it helps you get better results in even higher dimensions.\n\n=================================\nThis paper proposes several enhancements to a neural network method for computing committor functions so that it can perform better on rare events in high-dimensional space. The basic idea is using a variational formulation with Dirichlet-like boundary conditions to learn a neural committor function. The authors claim to improve a previous neural network based method by i) using a clever parameterization of the neural committor function so that it approximately satisfy the boundary condition; ii) bypassing the difficulty of rare events using importance sampling; and iii) using collective variables as feature engineering.\n\nGenerally I feel this paper is well written and easy to understand, without requiring too much background in physics and chemistry. The application is new to most people in the machine learning community. However, \nthe main contributions of this paper are empirical, and I found the experiments not very convincing. Here are my main concerns:\n\n1. There is almost no ablation study. The parameterization of committor function satisfies the Dirichlet boundary condition, which is aesthetically pleasing. However, it's unclear how much this improves the regularization used in the previous method. Similarly, without importance sampling, will the results actually become worse? What changes if the collective variables are removed? There is even no comparison with the previous neural network based method on computing committor functions, though the authors cited it.\n\n2. In the experiment on extended Mueller potentials, authors use the FEM results as the ground truth. However, it is not clear how accurate those FEM solutions are. Without this being clarified, it is unclear to me that the RMSE and MAE results in Table 1 are meaningful. Maybe try some simpler problem where the committor functions can be computed exactly?\n\n3. In experiments the authors often argue that results will improve when networks become deeper. However, all network architectures used in the paper are narrow and shallow when viewed from the perspective of modern deep learning. If the authors want to stress this point, I would expect to see more experimental results on neural network architectures, where you vary the depth of the network and report the change of results.\n\n4. \"Then we use the result as the initial network to compute the committor function at T = 300K\" => Did you first train a neural committor on samples of T = 800K and use its weights as initialization to the neural committor for T = 300K? Please clarify this more.\n\n5. Finally, I think the importance sampling technique proposed in this paper can be improved by other methods, such as annealed importance sampling. The largest dimension tested in this paper is only 66, which is still fairly small in machine learning, and I don't expect the vanilla importance sampling can work in higher dimensions.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "summary",
            "review": "The paper proposes to apply neural network to compute the committor function arose from physics, which looks an interesting application problem by employing machine learning algorithms. Typically, I know very well that the BG distribution usually has multi-modes which makes the sampling difficult extremely. The authors then employ the importance sampling for possibly explore the whole variable space. It seems to me the only possible contribution is parameterize the committor function by using a neural network.\nThe committor function is parametrized by using a neural network. My first concern is the training data. How would you collect the training data? It is well-known that a neural network works best when there are plenty of training data. Presumably when you are collecting the data, you are basically calculate the committor function and so that you may be able to directly solve the variational problem. \nImportance sampling: I would not consider the importance sampling as a big deal concerning the contribution of the paper. You could employ a series of importance distributions which could result in many more samples. Have you also looked at the Uniform distribution?\nThe paper targets high-dimensional problem. However, in the experiments, the problems do not look really like high-dimensional problems.\nSome notations need to be clarified, for example, the Nabla, the Delta, and as well as the dot operator.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review",
            "review": "This paper presents a method to train NNs as black box estimators of the commitor function for a physical, statistical mechanical, distribution. This training is performed using samples from the distribution. As the committor function is used to understand transitions between modes of the distribution, it is important that the training samples include points between modes, which are often extremely low probability. To address this concern, this paper draws MCMC samples at a high temperature, and then uses importance weights when training the committor function using these samples. Overall -- this seemed like a good application paper. It applies largely off-the-shelf machine learning techniques to a problem in physics. I don't have enough background to judge the quality of the experimental results.\n\nI had one major concern: the approach in this paper is motivated as a solution to estimating commitor functions in high-d. The variance of importance sampling estimates typically increases exponentially in the dimensionality of the problem, so I suspect this technique as presented would fall apart quickly if pushed to higher dimensions. All experiments are on problems with either 9 or 10 (effective) degrees of freedom, which from the ML perspective at least is quite low dimensional, and which is consistent with this exponentially poor scaling. There are likely fixes to this problem -- e.g. the authors might want to look into annealed importance sampling*.\n\nmore specific comments:\n\n\"and dislocation dynamics\" -> \"dislocation dynamics\"\n\n\"One can easily check\" -> \"One can check\" :P\n\neq 5 -- this is very sudden deep water! Especially for an ML audience. You should either give more context for the Kolmogorov backward equation, or just drop it. (The Kolmogorov formulation of the problem is not used later, and for an ML audience describing the task in terms of it will confuse rather than clarify.)\nwhat is \\Delta q? Does that indicate the Laplacian? Not standard ML notation -- define.\n\nsimilarly, define what is intended by \\partial A and \\partial B (boundary of the respective regions?)\n\neq. 9 -- nit -- recommend using a symbol other than rho for regularization coefficient. visually resembles p, and is rarely used this way. lambda is very common.\n\neqs 10/11 -- include some text motivation for why the definition of chi explicitly excludes the regions inside A and B.\n\neq 14: cleverly formulated!\n\neq 14 / eq 20:\nfactor of 1000 is very fast! corresponds to an epsilon of O(1e-3). You need to make sure that training samples are generated in the epsilon width border around A and B, otherwise the effect of chi will be invisible when training q_theta. So it seems like epsilon should be chosen significantly larger than this. Might want to include some discussion of how to choose epsilon.\n\n* Totally incidental to the current context, but fascinatingly, annealed importance sampling turns out to be equivalent to the Jarzynski equality in nonequilibrium physics.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}