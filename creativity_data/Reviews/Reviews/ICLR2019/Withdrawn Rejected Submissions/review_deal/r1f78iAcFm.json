{
    "Decision": {
        "metareview": "The reviewers and authors participated in modest discussion, with the authors providing direct responses to reviewer comments. However, this did not appreciably change the overall ratings of the paper (one reviewer raised their rating, while another grew more concerned), and in aggregate the reviewers do not recommend that the paper meets the bar for acceptance.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "After modest discussion, no clear signal for acceptance"
    },
    "Reviews": [
        {
            "title": "Somewhat incremental results and an important point why we can apply RL in this setup remains unclear",
            "review": "Summary:\nThis paper develops a novel method for predicting organic chemical reactions, in particular, final product prediction from given reactants. Organic molecules consist of covalent bonds, and hence organic reactions can be regarded as an alternating multistep series of bond breaking and bond forming (i.e. qualitative understanding as \"reaction mechanisms\" against quantum chemical calculations). The developed method aims to predict this series of bond changes through a form of reinforcement learning guided with neural networks. In this sense, the setup and formulation seem largely inherited from cited previous papers by Bradshaw et al, 2018 or Kayala & Baldi, 2011 (though they are not used any RL formulation). Organic compounds at each elementary step are represented as molecular graphs, and reactions are thus a series of graph transformations. Each bond change can be considered as \"action\" at that state to form the next states to head for the final product. The method itself seems quite natural: States transitions are shared by an RNN and the hidden states and observations (molecular graphs at each step, and bond changes as actions) are used to learn \"policy\" and \"state transition\" for RL via graph neural networks. Atom pairs to lead the bond change are detected from such graph embeddings and state observations through self-attentive architectures. In addition, masking by additional indicator variables is introduced to avoid redundant training as well as determine the termination of the reaction. Experimental evaluations on a standard large benchmark dataset of USPTO show improved prediction performance compared to previous methods of Jin et al, 2017 and Schwaller et al, 2018.\n\nComment:\n- Given that a chemical reaction can be regarded as a multi-step chain of bond breaking and forming, thus the method part seems a quite natural extension of the past effort but also sounds rather incremental even though the performance gain exists.\n\n- The method part is written clearly but the problem setup seems rather unclear. The most unclear point is how the environment for RL can give any reward to each bond change. How we can know each prediction of a bond change is correct or not? Can it be supervised? Does this mean that the training set of reactions has the correct perfect information of these multi-step bond changes?? How did you construct such curated dataset for USPTO? If this is the case, the motivation to go for RL would be more understandable but this part is not explained at all. (Because it is inherited from previous work of Bradshaw et al 2018 or something?? )\n\n- Why this proposed method has no limitation whereas the previous method by Bradshaw et al, 2018 are limited to \"linear chain topology\" (?). If this method is the direct competitor, what points are important to remove this limitation of the previous method should be clarified more clearly. This method is referred multiple times in the paper, but no direct explanations exist. \n\nPros:\n\t- Nice and solid design of proposed \"graph transformation policy network\"\n\t- Better prediction performance against previous methods\n\nCons:\n\t- Why this extension could break the previous limit (of ELECTRO?) remains unclear\n\t- The descriptions on the problem setup and the data are unclear. Perfectly curated as chemically correct multi-steps of bond changes are given as training set? How we can know each prediction of a bond change is correct or not?\n\t- the proposed architecture is nice but somewhat seems incremental. (heuristic combinations of existing techniques of RL and graph neural nets)\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Nice application. Some edits are needed.",
            "review": "Update:\n\nScore increased.\n\n___________________________________\n\nOriginal review:\n\nThe paper presents an approach to predict the products of chemical reactions, given the reactants and reagents. It works by stepwise predicting the atom pairs that change their bonds in course of reaction, and then adjusting the bonds between them. This can be interpreted as a stepwise graph transformation.\n\nI think this is an interesting applied ML paper with fair results. The presentation is clear and understandable. The experimental setup is reasonable. However, the paper is not ready yet to be accepted in my opinion.\n\nI think a higher score is justified if the authors address the following points:\n\n- Relation to previous work, originality\n\nIn contrast to what the authors claim, what is predicted here is not exactly the reaction mechanism, but an implementation of the principle of minimal chemical distance, which was already described by Ugi and coworkers in 1980 [see Jochum, Gasteiger, Ugi, The Principle of Minimum Chemical Distance Angew. Chem. Int. Ed. Engl. 1980, 19, p 495-505]. \nThe “insight” the authors have about treating reagents and reactants jointly is Organic Chemistry 101, and that reactions are stepwise graph transformations was also reported by Ugi et al, however, already in 1979! [Ugi, et al. \"New applications of computers in chemistry.\" Angewandte Chemie International Edition in English 18.2 (1979): 111-123. ] I assume the authors were not aware of these papers, but now they are, so this needs to be modified accordingly, and these papers need to be referred to in the introduction. \n\n\n\n- Questions:\n\nThe authors suggest that graph neural networks are more generic that so-called heuristic features (fingerprints) – which, as Duvenaud et al have elaborated, can be interpreted just as graph neural networks themselves – with fixed weights. Also, there are results by the Hochreiter group which show that graph neural networks perform worse that classical chemical features under rigorous testing { DOI: 10.1039/C8SC00148K } Do the authors think their models could also improve if they used the classical fingerprints?\n\n\nIs the GRU really needed to encode the past bond changes? What happens if you remove it?\n\nThe statement that the method has the advantage of not relying on handcrafted reaction templates is somewhat overselling, because instead it uses a handcrafted complex neural network architecture. How complicated is it to train the network? If you remove some of the “tricks” of shaping the loss function, does it still train well?\n\n\nTo what degree is the ranking of the different models just a matter of hyperparameter tuning or different architectures? If you used a different graph neural net instead of an MPNN on top of your GTPN method, what would you expect? Are the differences between the models significant?\n\n\nDuring prediction, you apply a flag to the starting molecules if they are a reagent or reactant. How do you know upfront what a reagent or reactant is during inference? \n\nOn page 5 and 7, you speak of the correct sequence of reaction triples (which implies an ordering), even though earlier you claim the algorithm is order-invariant? Where do you get the ground truth labels from? I assume these are already annotated in the data.\n\n\nIn the appendix, please replace the pie chart with a bar chart.\n\n- Language:\nI would suggest the authors to adapt the language of their paper towards a more academic tone. Science is not a sports competition of getting slightly higher numbers in benchmarks, but rather about providing insights and explanations. Words like “beating” or “record” are locker room talk, and to be avoided.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "review": "The paper provides a new system that combines a number of neural networks to predict chemical reactions. The paper brings together a number of interesting methods to create a system that outperforms the state of the art.\n\nGood about this paper: \n - reported performance: the authors report a small but very consistent performance improvement.\n - the authors propose an approach that puts together many pieces to become an effective approach to chemical reaction prediction. \n -\n\nProblematic with this paper\n - this paper is impossible to understand if you only refer to the ten pages of content. There are at least 5 pointers in the paper where the authors refer to the appendix for details. Details in many of these cases are necessary to even understand what is really being done:  p3: rewards p4: message passing functions, p5: updating states, p9: training details. Further, The paper has some details that are unnecessary - e.g. the discussion of global vs. local network on p4 - this could go into the appendix (or be dropped entirely)\n\n - the model uses a step-wise reward in the training procedure (p3) -> positive reward for each correct subaction. It is not clear from the paper whether the model requires this at test time too (which should not be available). It's not clear what the authors do in testing. I feel that a clean RL protocol would only use rewards during training that are also available in testing (and a final reward)\n\n - eq 7: given there is an expontential in the probability - how often will the sampling not pick the top candidate? feels like it will mostly pick the top candidate. \n\n - eq 9: it's unclear what this would do if the same pair of atoms is chosen twice (or more often)\n\n - the results presented in table 3: it appears that GTPN alone (and with beam search) is worse than the previous state of the art. only the various post processing steps make it better than the previous methods. It's not clear whether the state of the art methods in the table use similar postprocessing steps or whether they would also improve their results if the same postprocessing steps were applied. \n \n\nminor stuff: \np2: Therefore, one can view GTPN as RL -> I don't think there is a causality. Just drop \"Therefore\"\np2: standard RL loss -> what is that? \neq. 2: interestin gchoice to add the vectors - wouldn't it be easier to just concatenate?\np4: what does \"NULL\" mean? how is this encoded?\np4 bottom: this is quite uncommon notation for me. Not a blocker but took me a while to parse and decrypt.\np5: how are the coefficients tuned?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}