{
    "Decision": {
        "metareview": "The paper addresses the problem of out-of-distribution detection for helping the segmentation process.\n\nThe reviewers and AC note the critical limitation of novelty of this paper to meet the high standard of ICLR. AC also thinks the authors should avoid using explicit OOD datasets (e.g., ILVRC) due to the nature of this problem. Otherwise, this is a toy binary classification problem.\n\nAC thinks the proposed method has potential and is interesting, but decided that the authors need more works to publish.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Limited novelty"
    },
    "Reviews": [
        {
            "title": "Discriminative out-of-distribution detection for semantic segmentation",
            "review": "Summary:\nThis paper addresses the problem of out-of-distribution detection for helping the segmentation process. Therefore, the detection is performed on a pixel basis. The application of the approach is to datasets used for autonomous driving, where semantic segmentation of the view of the road is a typical application. Since in a road view there will be pixels that are projections of objects that are likely not in the set of classes known by the semantic segmentation algorithm, it makes sense to flag them as being out of distribution (OOD), or not known, or to assign to them a low confidence level. The proposed approach is trivial: train a binary classifier that distinguishes image patches from a known set of classes from image patches coming from an unknown (background class). The classifier output applied at every pixel will give the confidence value. While there are different dataset options to represent the known classes, the background class is represented by images from ILSVRC. The results show that for the segmentation application the approach works better than using an adaptation of more elaborate out-of-distribution methods.\n\nQuality and clarity:\nThe paper is well organized and is described very clearly and provides an ok set of results, despite the simplicity of the approach.\n\nOriginality and significance:\nUnfortunately, I do not see any relevant technical novelty, and this is a major issue. Perhaps the only significant conclusion about this paper is that before designing a new OOD detector, if representing the set of “unknown” classes with ILVRC is reasonable, then it makes sense to simply train a binary classifier and see how it works.\n\nBesides the novelty, I disagree with the way the paper has been positioned and motivated. It brings into play epistemic and aleatoric uncertainty concepts to justify (the simplicity of) the approach, and it overlooks a large body of machine learning (novelty detection, one-class classification, …). This is also a major issue.\n\n\nAdditional comments:\n\nOne of the biggest motivations for this work is that other approaches do not distinguish between epistemic and aleatoric uncertainty and this is why they do not work. This is regarded as a distinctive advantage of the proposed approach. It is claimed that the proposed formulation is insensitive to any aleatoric uncertainty. On the other hand, the paper is written in a way that ignores a large body of literature that goes under the name of “novelty detection”, “anomaly detection”, “one-class classification”, and related names. So, I am wondering how the approaches just mentioned compare with the proposed method, when epistemic and aleatoric uncertainty become part of the discussion. Isn’t every novelty detector insensitive to aleatoric uncertainty as well? Could the Authors clarify what they claim with that statement, while considering a broader view? \n\nThe paper should relate to the literature mentioned above. In particular, I would point the Authors to a couple of recent works that seem to precisely contradict the premises of the proposed approach, which are given at the beginning of section 3:\n\n- Adversarially Learned One-Class Classifier for Novelty Detection, CVPR 2018\n- Generative Probabilistic Novelty Detection with Adversarial Autoencoders, arXiv, July 2018.\n\n\nAgain, related to novelty detection, it looks like the proposed approach still requires tuning one or more thresholds. Therefore, it would not be that different from tuning the threshold of a novelty detector, or a one-class classifier. It would have strengthened the paper if the approach was compared also to a novelty detector.\n\nIt is not clear if the fully convolutional OOD detector is working on a patch or on the entire image. If it is a patch, of what size?\n\nPage 4, define the “ID” acronym. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting results, good direction to follow ",
            "review": "This paper aims to detect out-of-distribution pixels for semantic segmentation, which is a good direction for researchers in this field to explore. As the authors point out, recent semantic segmentation systems surpass 80% mIoU on Pascal VOC 2012  and  Cityscapes, which is a good achievement. Unfortunately, most existing semantic segmentation datasets assume closed-world evaluation which means that they require predictions over a predetermined set of visual classes. This work utilize data from other domain to detect undetermined classes, thus can model uncertainty better in an explicit way. I just have minor comments. \n\n1. When you perform training, do you train from scratch or from a pre-trained model? If using pre-trained model, then ILSVRC is not actually pure OOD pixels. \n\n2. How to interpret the results in Table 5? \n\n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Difficult to understand",
            "review": "ML models are trained on a predefined dataset formed by a set of classes. Those classes use to be the same ones for training and testing. However, what happen when during testing time images with classes unseen during training are shown to the model? This article focus in this problem which is not currently taking much attention by the mainstream research community and is of great importance for the real world applications.\n\nThis article tries to detect areas of the image where those out-of-distribution situations appear in semantic segmentation applications. The approach used is by training a classifier that detects which pixels are out of distribution. For training two datasets are used: the dataset of interest and another different one. The classifier learns to detect if a pixel is from the dataset of interest or from another distribution.\n\nThe main problem I found with this article is that I couldn't fully understand it. Maybe because the text needs a bit more of review and improvement or maybe because Im not very familiar with the topic. Moreover the article is 10 pages while it is encouraged to be 8. I find that the method of the paper is quite simple and can be explained more straight forward and in less pages. The related work section overlaps a lot with the intro, I suggest to combine both. First two paragraphs of the method seam that should be in the intro. Model details from the experiments I consider that should be explained in the method. I miss a figure explaining the architecture of the model. Why using the semantic segmentation model proposed and no something standard? For instance Tiramisu (That is also based on dense layers). Note that the method used for semantic segmentation is 10 points lower than the SOTA in Cityscapes. Figure 1 is impossible to read as the captions are too small. The representations of figures 2-5 are difficult to interpret. There is no comparison to SOTA\n\n",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}