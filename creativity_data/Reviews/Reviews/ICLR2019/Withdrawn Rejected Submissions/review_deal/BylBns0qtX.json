{
    "Decision": {
        "metareview": "This paper shows experiments in favor of learning and using heteroscedastic noise models for differentiable Bayes filter. Reviewers agree that this is interesting and also very useful for the community. However, they have also found plenty of issues with the presentation, execution and evaluations shown in the paper. Post rebuttal, one of the reviewer increased their score, but the other has reduced the score. Overall, the reviewers are in agreement that more work is required before this work can be accepted.\n\nSome of existing work on variational inference has not been included which, I agree, is problematic. Simple methods have been compared but then why these methods were chosen and not the other ones, is not completely clear. The paper definitely can improve on this aspect, clearly discussing relationships to many existing methods and then picking important methods to clearly bring some useful insights about learning heteroscedastic noise. Such insights are currently missing in the paper.\n\nReviewers have given many useful feedback in their review, and I believe this can be helpful for the authors to improve their work. In its current form, the paper is not ready to be accepted and I recommend rejection. I encourage the authors to resubmit this work.\n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting but not good enough."
    },
    "Reviews": [
        {
            "title": "Nice study which (sadly) ignores large parts of the related work",
            "review": "# Review for \"On Learning Heteroscedastic Noise Models within Differentiable Bayes Filters\"\n\nThe method revisits Bayes filters. It evaluates the benefit of training the observation and process noise models, while keeping all other models fixed. Experimentally, a clear performance boost is verified if heteroscedastic noise is used.\n\nFirst, I want to applaud the effort done to do the study. I think it is very beneficial for the community to revisit classic algorithms and evaluate them in a broader and more recent context. I certainly will revisit this article and point colleagues to it. \n\nThe paper is well-written and the experiments seems to be well done. The review of the relevant models is adequate, although space filling, since the methodology  is not at the core of ICLR. I however consider it highly relevant for the future of the field.\n\nHowever, there is a major flaw: the variational state-space model literature is completely ignored. I consider this blank spot unacceptable. Especially, the models proposed have already explored heteroskedastic noise models in contexts where state-space models and posterior approximations were fully trained. It is just that an ablation study was never done.\n\nI am very torn, as I like the paper in general but think that the recognition of the variational SSM literature needs to be added, and not having it in here would foster a separation of two \"micro communities\".\n\nHere is an incomplete list of articles, which can serve as starting points for a more thorough literature review.\n\n- Archer, E., Park, I. M., Buesing, L., Cunningham, J., & Paninski, L.\n(2015). Black box variational inference for state space models. arXiv preprint arXiv:1511.07367.\n- Fraccaro, M., SÃ¸nderby, S. K., Paquet, U., & Winther, O. (2016). Sequential neural models with stochastic layers. In Advances in neural information processing systems (pp. 2199-2207).\n- Karl, M., Soelch, M., Bayer, J., & van der Smagt, P. (2016). Deep  variational bayes filters: Unsupervised learning of state space models from rawdata. ICLR 2017.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Small novelty with insufficient novelty",
            "review": "This paper presents a method to learn and use state and observation dependent noise in traditional Bayesian filtering algorithms.  For observation noise, the approach consists of constructing a neural network model which takes as input the raw observation data and produces a compact representation and an associated (diagonal) covariance.  Similarly for state process noise, a network predicts the (diagonal) covariance of the temporal process given the current state.\n\nThe paper notes that these noise models can be trained end-to-end by instantiating an (approximate) Bayesian filter.  In particular, they explore the use of a Kalman Filteer, Extended Kalman Filter, (Monte Carlo and regular) Unscented Kalman Filter and a Particle Filter.\n\nThe technique is applied to two different tasks, visual odometry on the KITTI dataset and a \"planar pushing\" task.  The results show that the addition of a learned noise model made no significant difference on the KITTI dataset, with the EKF without learning performing as well as any of the other variations.  The planar pushing task has a higher dimensional state space and more challenging noise dynamics.  In that case some gains are seen with learning.\n\nOverall the contribution of this paper seems small and the experimenal results insufficient.  The observation that gradient based training can be done through a Bayesian filter, as the paper pointed out, was developed elsewhere.  Extending that to a more complex noise model seems like a rather small contribution.  Indeed, the observational noise component was not found to have a significant or consistent impact and hence only the process noise is particularly notable.  Further, at least one obvious and important baseline was missing.  Specifically, process noise models could be trained independently by simply maximizing the likelihood of the next predicted state.  It's not clear that there's a significant benefit to training the model end-to-end in this case.  There may well be, but that is something that should be demonstrated.\n\nA number of other, smaller issues:\n - Eq (4) should be written as a matrix inverse, not a fraction.\n - In the UKF the Julier paper of 1997 also notes a heuristic solution for ensuring positive definiteness of the estimated covarance matrix is lambda is negative.  Was this tried?\n - How was the number of particles selected for the PF at test time?  In particular, how did the computation time between the methods compare?\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good exploration of optimizing Bayesian filter noise variance through back propagation, but with incomplete results",
            "review": "This is a well written paper which proposes to learn heteroscedastic noise models from data by optimizing the prediction likelihood end-to-end through differentiable Bayesian Filters. In addition to existing Bayesian filters, the paper also proposes two different versions of the [differentiable] Unscented Kalman Filter. Performance of the different filters and noise models is evaluated on two real-world robotic problems: Visual Odometry and visual tracking of an object pushed by the robot.\nWhile the general idea of learning the noise variances through backpropagation are straightforward extensions of existing work on differential Bayesian filters, the questions that the paper explores are important to make end-to-end learning of Bayesian filter more common. The results will help future research select the correct differential filter for their use case, and insight in potential benefits (or lack thereof) by learning heteroscedastic or homoscedastic process noise, and/or observation noise.\nA downside is that the paper does not further explore how to weigh different loss terms which are apparently important to successfully train such models. Also unfortunate is the footnote which states that the current results are incomplete and will be updated, hence as a reviewer I am not sure which results and conclusions are valid right now.\n\n\nPros:\n+ clearly written\n+ useful experiments for those seeking to select a differential Bayesian filter, and learning (heteroscedastic) noise from data.\n+ experiments on real-world use cases rather than toy problems\n\nCons:\n- Incomplete experiments according to footnote, thus results and conclusions might change after this review.\n- Unclear what the effect of the selected process / observation model is on the learned noise\n\n\nBelow are more detailed comments and questions:\n* p6. Footnote: \"due to time constraints, ..., results will be updated\" Is this acceptable? I have never seen such a notice when reviewing. So, are the current results on a single fold? Will the numbers in the tables, or the conclusions change after this review?\n* If I understand correctly, the paper 'only' focuses on learning the heteroscedastic noise variance, but assumes that the deterministic non-linear parts of the process and observation models are fixed. I did not find this very clearly stated in the paper, though at least the Appendix explicitly states the used functions for the process models.\n* I would have liked to see in the paper more explanation on how the process and observations models were selected and validated  in the experiments, since I expect that the validity of these functions affects the learned noise variances. Since the noise needs to account for the inaccuracies in the deterministic models, would the choice for these functions not impact your conclusions? And, would it or would it not be possible to learn both these deterministic models and the noise jointly from the training data?\n* Is it possible to add priors on Q and R parameters for Bayesian treatment of learning model parameters? I can imagine that priors can guide the optimization to either adjust more of the Q or more of the R variance to improve the likelihood.\n\n* Section 1:\n\t* \"Our experiments show that ... \" This may be a matter of taste, but I did not expect to see the main conclusions already in the introduction. They should appear in the abstract to help out the quick reader. In the introduction, it appears as if you are talking about some separate preliminary experiments, and which you base some conclusions that will be used in the remainder of this paper.\n\n* Section 3:\n\t* So, mostly empirical study, since heteroscedastic noise models were already used?\n\t* \"Previous work evaluated ... \" please add citations\n\n* Section 4.1:\n\t* \"train a discriminative neural network o with parameters wo to preprocess the raw sensory data D and thus create a more compact representation of the observations z = o(D;wo).\" At this point in the paper, I don't understand this. How is z learned, via supervised learning (what is the target value for z)? Or is z some latent representation that is jointly optimized with the filters? This only became somewhat clearer in Sec. 5.2 on p.8 where it states that \"We ... train a neural network to extract the position of the object, the contact point and normal as well as ...\". So if I understand correctly, the function o for z = o(D) is thus learned offline w.r.t. some designed observation variables for which GT is available (from manual annotations?).\n\n* Section 4.2:\n\t* \"we predict a separate Qi for every sigma point and then compute Q as the weighted mean\" â So, separate parameters w_g for each sigma point i, or is a single learned non-linear function applied to all points?\n\n* Section 4.3:\n\t* Equation 14: inconsistent use of boldface script: should use bold sigma_t, and bold l_t ?\n\t* \"In practice, we found that during learning ... by only increasing the predicted variance\" â  This is an interesting observation, which I would have liked to see explored more. I understand that term (ii) is needed to guide the learning processes, but in the end wouldn't we want to optimize the actual likelihood? So, could you (after the loss with (ii) converged) reduce \\lambda_2 to zero to properly optimize only the log likelihood without guidance from a good initial state? Or is it not possible to reliably optimize the likelihood via back-propagation at all from some reason?\n\n* Section 5.1.1\n\t* \"... of varying length (from 270 to over 4500 steps) ...\" it would be good to mention the fps, to get understand to what real-world time horizons 50 / 100 frames correspond.\n\n* Section 5.1.2:\n\t* Table 1: How are the parameters of the filters in the \"no learning\" column obtained? Are these tuned in some other way, or taken form existing implementations? Also, can you clarify if the 'no learning' parameters served as the initial condition for the learning approaches?\n\t* Table 1, first row column Q+R: \"0.2\" â Is there a missing zero here, i.e. \"0.20\"? Otherwise, the precision of reported results in this table is not consistent. Hard to say: is the mean of R+Q 0.2, and slightly lower than R+Qh, or could it be as high as 0.24 ?\n\t* \"learning a heteroscedastic process noise model leads to big improvements and makes the filters competitive with the EKF\". Results for EKF still appear significantly better than the novel UKF, and even the PF (especially rotational error).\n\n* Section 6: \n\t* \"Large outliers in the prediction of the preprocessing networks were not associated with higher observation noise.\" I don't see on what presented results these conclusions were drawn, as this is the first time the word \"outlier\" is mentioned in the paper. Outliers seem indeed important, as they contradict the typical assumptions e.g. of Gaussian noise, so it would be useful to clarify how the proposed techniques handle such outliers.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}