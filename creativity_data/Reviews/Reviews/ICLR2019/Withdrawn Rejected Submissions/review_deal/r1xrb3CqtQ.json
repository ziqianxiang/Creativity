{
    "Decision": {
        "metareview": "This paper studies the problem of heterogeneous domain transfer, for example across different data modalities.\n\nThe comments of the reviewers are overlapping to a great extent. On the  one hand, the reviewers and AC agree that the problem considered is very interesting and deserves more attention.\n\nOn the other hand, the reviewers have raised concerns about the amount of novelty contained in this manuscript, as well as convincingness of results. The AC understands the authors’ argument that a simple method can be a feature and not a flaw, however this work still does not feel complete. Even within a relatively simple framework, it would be desirable to examine the problem from multiple angles and \"disentangle\" the effects of the different hypotheses – for example the reviewers have drawn attention to end-to-end training and comparison with other baselines. The points raised above, together with improving the manuscript (as commented by reviewers) would make this work more complete.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting problem, but work does not feel complete"
    },
    "Reviews": [
        {
            "title": "The technical part is weak",
            "review": "The authors demonstrate that it is possible to transfer across modalities (e.g., image-to-audio) by first abstracting the data with latent generative models and then learning transformations between latent spaces. We find that a simple variational autoencoder is able to learn a shared latent space to bridge between two generative models in an unsupervised fashion, and even between different types of models (e.g., variational autoencoder and a generative adversarial network). Some detailed comments are listed as follows, \n1. The technical parts are weak since the authors use the existing method with to some extent evolution. \n\n2 The proposed method can transfer the positive knowledge. However, for the transfer learning, one concerned and important issue is that some negative knowledge information can be also transferred. So how to avoid the negative transferring? Some necessary discussions about this should be given in the manuscript.\n\n2 There are many grammar errors in the current manuscript. The authors are suggested to improve the English writing.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A two-step solution for heterogeneous domain transfer (e.g., image-to-audio)",
            "review": "In this paper, the authors study an interesting problem, i.e., heterogeneous domain transfer such as knowledge transfer between an image domain and a speech/audio domain. In particular, the proposed solution contains two major steps: (i) pre-train each domain via VAE or GAN, and (ii) train a conditional VAE in semi-supervised manner in order to bridge two domains (see Section 2.2). Experiments on three public datasets (including three cross-domain settings) show the effectiveness of the proposed two-step solution.\n\nSome Comments/suggestions:\n(i) The technical novelty (considering the two-step solution) is limited though the studied problem is very interesting.\n\n(ii) The authors are suggested to put the proposed solution in the context of transfer learning, which may better show the significance of this work. Currently, such a discussion and comparison is missing.\n\n(iii) There are many grammar errors throughout the whole paper. The authors are suggested to significantly improve the linguistic quality.\n\n(iv) A section of Conclusions is missing.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "poor organization, trivial techical implementation",
            "review": "In this paper, the authors have proposed a cross domain transferring methods, supervised by three category of losses. The experiments somewhat demonstrate the effective of this method. However, this paper still suffers from some drawbacks as below:\nThe paper is not well-organized, the structure of the paper need improving. For example, the related work is put almost at the end of the paper and the tables and figures are hard to follow sometimes.\nThe technical implementation of the proposition is somewhat trivial. Why the generative model should be pre-trained. Why not try in the end-to-end way. \nThe experiments are not convincing. The authors argue that CycleGAN suffers from some drawback. Why do not the authors compare with CycleGAN in this paper? By the way, the authors also need to compare with more state-of-the-art methods, such as StarGAN.\nSome implementation details are not clearly stated. For example, the authors say “Our goal can thus be stated as learning transformations that preserve locality and semantic alignment, while requiring as few labels from a user as possible.” So, how many labeled samples are used in Table 2?",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}