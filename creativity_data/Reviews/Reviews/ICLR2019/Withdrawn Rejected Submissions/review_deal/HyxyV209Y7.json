{
    "Decision": "",
    "Reviews": [
        {
            "title": "Addressed an interesting and important topic; but the significance of the work can be improved.",
            "review": "To really understand how robust the node embedding methods are to poisoning attacks, the authors should conduct experiments on various random graph models. Examples of random graph models include Erdos-Renyi, Stochastic Kronecker Graph, Configuration Model with power-law degree distribution, Barabasi-Albert, Watts-Strogatz, Hyperbolic Graphs, Block Two-level Erdos-Renyi, etc. That way we can learn what types of networks are more susceptible to attacks on node embeddings and perhaps look into why some are more vulnerable than others.  For instance, an Erdos-Renyi graph should be very robust to attacks because the connections are random.  ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Applying some existing attack models to node embedding with limited novelty; paper presentation is also an issue",
            "review": "This paper aims to propose effective data poisoning attack against node embedding methods. As explained in the paper, node embedding methods like DeepWalk and LINE can be cast under a matrix factorisation framework as explained in [Qiu 2017] and restated in the paper. Also, data poisoning attacks on matrix factorisation have been studied in [Li 2016]. It then becomes straightforward to do data poisoning attacks on node embedding methods. And in fact the two types of attacks being analysed are the same as those mentioned in [Li 2016]. Projected gradient descent is used in both [Li 2016] and this paper. So, it seems to me that the key contribution of this paper is more like applying the attacks proposed in [Li 2016] to node embedding problem without much novelty.\n\n+ve: \n1. The problem is an interesting and trendy one.\n\n-ve:\n1. The originality of this work is limited as presented above.\n2. The quality of the paper presentation is not satisfactory. \n\nSpecific comments: \n- Section 5.1 is hard to follow while Section 5.2 is too short to gain more insight\n- There are quite many typo mistakes and the paper is not well organised and presented.\nSection 2 line 5:    ... graph neural networks (),\nSection 2 last para, third last line:    ... unsupervised methods for gra*g*h\nSection 5.1 line 3: ... the adjacency matrix is continous  -> continuous\n... (many more)\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper studies poisoning attack to node embedding methods. The studied problem needs to be further clarified. ",
            "review": "This paper studies poisoning attack to node embedding methods. It is assumed that the attacker can manipulate the poisoned graph G by adding or deleting edges. \nThe proposed method is evaluated on two adversarial goals:\n1)\tIn the integrity attack, the target is to change the probability of the edge connected with a pair of nodes. Why bothered to change the probability of the existence of edges?  Since in the assumption, attackers are powerful enough to directly add or delete any edges.\n2)\tIn availability attack, the goal is to reduce the performance over a test set. What is the “performance” here? What is measured by average precision score?\n\nThe experimental evaluation doesn’t show a strong support to the purpose of study. The baselines are “random selection” and “PageRank”.   Why not comparing to an attack strategy based on the “node degree” for adding or deleting edges?",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}