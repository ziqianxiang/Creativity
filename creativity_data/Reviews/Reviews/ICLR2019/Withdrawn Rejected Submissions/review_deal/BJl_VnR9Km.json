{
    "Decision": {
        "metareview": "There was major disagreement between reviewers on this paper. Two reviewers recommend acceptance, and one firm rejection. The initial version of the manuscript was of poor quality in terms of exposition, as noted by all reviewers. However, the authors responded carefully and thoroughly to reviewer comments, and major clarity and technical issues were resolved by all authors. \n\nI ask PCs to note that the paper, as originally submitted, was not fit for acceptance, and reviewers noted major changes during the review process. I do believe this behavior should be discouraged, since it effectively requires reviewers to examine the paper twice. Regardless, the final overall score of the paper does not meet the bar for acceptance into ICLR.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Significant revisions in review"
    },
    "Reviews": [
        {
            "title": "SOTA results in video prediction and interesting analysis but the presentation is severely lacking clarity",
            "review": "Summary:\nThe paper presents a novel architecture for video prediction consisting of a feed-forward path with sparse convolutions and an LSTM generating predictions of chunks of video based on the sequence of input chunks. A feedback path links the LSTMs of the different sparse prediction modules. Experiments in video prediction are performed on moving-MNIST and the KTH action recognition dataset and the model achieves state-of-the-art performance on both. Interestingly, the model is exhibits prediction suppressions effects as have been observed during neurophysiological experiments in the inferotemporal cortex of macaque monkeys. The proposed method exhibits prediction suppression effects also in the lower layers, motivating a neurophysiological experiment in the earlier V1/V2 regions, which yielded an observation similar to the model’s prediction.\n\nStrengths:\nThe performance improvements over competing methods on Moving-MNIST and KTH presented in the experimental section are significant. The analysis seems fairly thorough.\n\nWeaknesses and requests for clarification:\n- The description of the sparse predictive module is difficult to follow, and I am not sure I understood it completely. I find it a bit unintuitive to start the description with the errors, instead of explaining what is computed from beginning to end. The section reads more like a loose description of isolated parts instead of an integrated whole. Maybe walking the reader step-by-step through one complete iteration of the computation helps to clarify this. Also, not every character in equations 1-5 and the algorithm has been defined. For example, what is L? \n- The text makes it sound like the idea of using 3d convolutions in a convLSTM is novel. 3D convLSTMs have been previously used in 3d vision, see \nChoy, C. B., Xu, D., Gwak, J., Chen, K., & Savarese, S. (2016, October). 3d-r2n2: A unified approach for single and multi-view 3d object reconstruction. In European conference on computer vision (pp. 628-644). Springer, Cham.\nThe application of 3d convLSTMs to video might be new, but the mentioned paper by Choy et al. (2016) should be cited.\n- You mention that padding is used for rows and columns. Are you using padding on the temporal axis as well?\n- The paper seems to be written in a rush, as it contains way too many typos and grammar mistakes, e.g. “a hierarchical of” (should be “a hierarchy of“ or just “hierarchical”), “feedforwad”, “Expriment” (section 4 heading), “achievedbetter”, “trained monkeys to image pairs”, “pervious”, “perserves”, “processure”, “sequnence” “viusal”. Many typos could have been caught by a spellcheck! This would improve readability a lot!\n- The citations are not properly formatted: (1) If the author names are used as part of the sentence, use e.g. Lotter et al. (2016), else (2) If the author names are not part of the sentence, use (Lotter et al., 2016). These two styles are mixed randomly in the current draft. This makes the manuscript, which already contains a lot of language mistakes, difficult to read.\n- Abbreviations that are used but not introduced: CNN, IT, PSTH, DCNN, LSTM.\n- The related work section could benefit from referring to some of the related work in neuroscience.\n- Adding a sentence explaining the intuition behind using SatLU in equation (1) might be helpful\n\nTo summarize my feedback: I think experimental results and analysis are strong, but the presentation is strongly lacking! The description of the approach definitely needs to be improved to make replication of the results easier. It might help to have someone who doesn’t know the model already read the description and explain it back to you while revising the draft. I hope I could provide some helpful suggestions. I would recommend the manuscript for acceptance, if the presentation is significantly improved!",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting bio-inspired sequence prediction network explaining familiarity effects in early and late visual system.",
            "review": "The authors propose a biologically inspired ANN to predict a video sequence, that performs better than previous biologically inspired video sequence predictors (>PredNet and >PredRNN+).  Their model also accounts for familiarity effects (i.e. decrease in neural activations when repeatedly presenting the same visual sequence) found in primate early visual system V1/V2 (data recorded for this article) and late visual system IT.\n\nThis work is interesting because it proposes a sequence prediction technique that accounts well for familiarity effects found in different regions of the visual system.\n\nHowever one of the claims does not seem supported by data:\n\n1. The authors claim repeatedly that using the prediction error framework is computationally more efficient than alternatives but they do not show this.\n\nFurthermore, the article would benefit from the following clarifications:\n\n2. It is unclear how their network performance compares to state-of-the-art NON neurally plausible models of sequence prediction.\n\n3. It is unclear from the introduction how they modified the network proposed by (Pan et al) to obtain their network. \n\n4. \"The SSIM index over time shows that the C-C method is more effective than C-F method, for C-F method performs better than C-C method in the short term perdiction when ground truth images are provided, but setting sliding window is too time-consuming, much more than the performance increase\"\nPlease clarify this statement.\n\n5. Macaque experiments: Some experiments on macaques were performed for this article, but there is no mention of ethical guidelines and whether they were respected.\n\n6. Many typos are present in the text!\n\nI believe this work at the intersection of deep learning and neuroscience is an interesting contribution for both fields. However, the paper would benefit from these clarifications and a thorough proof-reading for the many typos present in the text. \n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Clarity and quantification need improvement",
            "review": "This paper proposes a network architecture inspired by the primate visual cortex. The architecture includes feedforward, feedback, and local recurrent connections, which together implement a predictive coding scheme. Some versions of the network are shown to outperform the similar PredNet and PredRNN architectures on two video prediction tasks: moving MNIST and KTH human actions. Finally, the authors provide neural data from monkeys and argue that their network shows similarities to the biological data.\n\nThe paper contains intriguing ideas about the benefits of sparse and predictive coding, and the direct comparison to biological data potentially broadens the impact of the work. However, major claims are unsubstantiated, and accuracy and clarity need to be improved to make the manuscript acceptable.\n\nMajor concerns:\n1. The authors claim that their architecture is more efficient because it uses sparse coding of residuals. Implementation details and some quantitative arguments, ideally benchmarks, need to be provided to show that their architecture is actually more efficient than PredRNN++ and PredNet.\n\n2. It is unclear whether the PredRNN++ should be compared to the C-C or C-F version of the network. Does the PredRNN++ have access to as many current and future frames as the C-C net? Is this a fair comparison? Please provide a clearer description of the different versions of your network and how they relate to the baseline models. That section in particular has many confusing typos (frame-by-chunk, chunk-by-frame abbreviations mixed up).\n\n3. In Figure 6, the authors claim that more layers lead to “better” representations. What does “better” mean? It is implied that the networks with more layers actually make the different motions more discriminable. Please quantify this. For example, a linear classifier could be trained on the neural activations. Also, how is this related to the rest of the paper? Do the authors claim that this result is unique to the proposed architecture? In that case, please provide a quantitative comparison to the PredNet or PredRNN++.\n\n4. In Figure 9, the presentation is highly confusing. Plots (c) to (h) are clearly made to look like the monkey data in (b) (nonlinear x-axes?), but show totally different timescales (training epochs vs. milliseconds). Please explain why it makes sense to compare these timescales. Also, what does it mean for a training epoch to have a negative value? \n\nMinor comments:\n1. I don’t understand the “tension” between hierarchical feature representations and residual representations brought up in Section 2. Do the PredNet and PredRNN++ not contain a hierarchy of representations?\n\n2. Figure 1 is not fully annotated and could be clearer. What does the asterisk mean? Why are there multiple arrows between the P’s? What do the small arrows next to the big arrows mean? Please expand the legend. Consider using colors to differentiate between components.\n\n3. I don’t understand Figure 4c. According to the text, this plot shows “effectiveness as a function of time”, but the x-axis is labeled “Layer Number”. What does “effectiveness over time” mean? What does the y-label mean (SSIM per day?)? What is “trunk prediction” (not mentioned anywhere in the text)?\n\n4. For Figure 9, it is pointed out that activity is expected to be lower for E neurons, but is also lower for R and P. This is interesting and also applies to Figure 8, so it would be good to see Figure 8 split up by E/R/P, too. \n\n5. The word “Figure” is missing before figure references.\n\n6. Please proof-read for typography, punctuation and grammar.",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}