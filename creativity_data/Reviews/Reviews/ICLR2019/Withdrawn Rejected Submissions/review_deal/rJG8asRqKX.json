{
    "Decision": {
        "metareview": "While there was disagreement on this paper, reviewers remained unconvinced about the scalability and novelty of the presented work. While it was universally agreed that many positive points exist in this paper, it is not yet ready for publication. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "metareview for dynamic survival analysis paper"
    },
    "Reviews": [
        {
            "title": "Seems like a solid survival analysis work, but not a good fit for ICLR",
            "review": "Summary:\nThe authors propose Dynamic-DeepHit, a survival analysis framework for modeling longitudinal data with multiple competing risks. As opposed to previous works, Dynamic-DeepHit can model survival events (e.g. death, cancer relapse) which can be driven by multiple, potentially competing, underlying risks. The proposed model uses an RNN shared across multiple risks for processing past-to-recent measurements, and multiple feedforward nets that accept the most recent measurements and the hidden layer of shared RNN. Joint predictions (across time and competing risks) are made using a softmax layer. The model is tested on two datasets where Dynamic-DeepHit outperforms other baselines.\n\nPros:\n- Detailed explanation of survival analysis formulation.\n- Experiments across multiple aspects: prediction performance, explaining the variable importance, visualizing the RNN hidden states\n\nIssues:\n- As the selling point of this model is its ability to capture competing risks, it is not very convincing that the experiments were conducted with only two competing risks. Can Dynamic-DeepHit truly capture multiple competing risks?\n- The prediction performance was measured by \"cause-specific time-dependent concordance index\", which is described by Eq.5. But Eq.5 alone does not intuitively explain what it is trying to measure.\n- Mayo Clinic data also has two competing risks, but Table 2 only shows the prediction performance for one risk, with the justification \"liver transplant prediction is not in our interest\". For the thoroughness of the experiments, why not put the complete result?\n- All other issues aside: I can see that the authors put considerable effort into this work. But the effort is mainly focused on survival analysis, rather than learning representations. The novelty of this work regarding learning representations seems limited to me, as opposed to the contribution on improving survival analysis & medical prediction. This work would be much better received if submitted to a more relevant venue.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Novel modelling framework for well-motivated research problem",
            "review": "The authors present a novel deep learning representation for jointly modelling longitudinal measurements and dynamic time-to-event analysis where there are competing risks for a given event. The authors incorporate patient-level historical data using an RNN which allows updating of individual-level (i.e. personalized) risk predictions as additional data points are collected. This method (Dynamic-DeepHit) makes no assumptions about the underlying stochastic processes. The authors further evaluate the clinical utility of these methods in terms of interpretability of variable importance and dynamic risk predictions.\nThe work is clearly structured and clearly articulate a well-motivated research problem. It is also extremely well-placed within the historical context of previous work done in survival modelling. The authors have carried out an extensive review of the literature showing the evolution as well as the strengths and weaknesses of these methods.\nMy main concern with this manuscript is the handling of missing data. In the context of this study, the evaluation of missing data was inadequately investigated. This is an important problem within the context of what the authors are trying to achieve. Although it may be outside the scope of the current manuscript, different assumptions regarding missing data should be investigated. For example, if missing data was correlated with a particular outcome or a particular covariate, then replacing missing values with interpolation or with the mean and mode would lead to biased estimates. \n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good Empirical Performance, Questionable Scalability",
            "review": "The paper proposes a deep architecture that conducts survival analysis from longitudinal data where multiple competing risks are present. Experimental results demonstrate the effectiveness of the proposed method.  Specific comments follow:\n\n1. A primary concern in the reviewer's opinion is the scalability of the architecture. While the reviewer appreciates the discussion of the scalability issue in terms of the output layer in the paper, the architecture might also not scalable if the number of competing risks is large because of the increase of the cause-specific subnetworks in the architecture.  Overall, the reviewer finds the lack of a principled approach to deal with competing risks and long time horizon presented in the paper.  Since dealing with competing risks in survival analysis is the goal of the paper, the reviewer finds the method presented insufficient for acceptance. As a remedy, for example, for the output layer, can the author consider the use of a neural net to model o_k at a particular time using time and f_{c_k}() as input?\n\nOther issues:\n2. it will be nice to explain (1) and (2) a little after presenting the formula.\n3. page 5, $\\mathbf{y}_j$ should also be explained because the next place where $\\mathbf{y}_j$ is present is (4), which is one page later.\n4. the term \"dynamic survival analysis\" is also obscure. What exactly does \"dynamic\" mean? To the reviewer's understanding, compared to standard survival analysis, the architecture models directly from raw longitudinal data of repeated measurements, and hence is called \"dynamic\".\n5. even the \"dynamic\" part of the dynamic survival analysis is not very novel, see, for example, \nRecurrent Marked Temporal Point Processes: Embedding Event History to Vector\nand the follow-up works in the use of deep learning for point process modeling.\n\n===============After Reading Authors' Response ================\nThe reviewer would like to thank the authors for their detailed response and careful revision of the paper to address the reviewer's concern. However, the reviewer is not persuaded by the authors' response. Specifically,\n\n1. the reviewer is not satisfied with the explanation and modification to address the scalability issue stemming from both the cause-specific subnetworks and the output layer. Simplifying the structure and parameterization of cause-specific subnetworks when many are present seems like a comprise rather than a principled approach to address the issue. The same is true for the exponentially distributed parameterization of the output layer.\n\n2. It is the reviewer's impression that for point process neural networks, it is possible to use the covariate information for prediction, as opposed to the claim given by the author.\n\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}