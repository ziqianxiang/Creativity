{
    "Decision": {
        "metareview": "AR1 is is concerned that the only contribution of this work is  combining second-order pooling with with a codebook style assignments. After discussions, AR1 still maintains that that the proposed factorization is a marginal contribution. AR2 feels that the proposed paper is highly related to numerous current works (e.g. mostly a mixture of existing contributions) and that evaluations have not been improved. AR3 also points that this paper lacks important comparisons for fairly evaluating the effectiveness of the proposed formulation and it lacks detailed description and discussion for the methods.\n\nAC has also pointed several works to the authors which are highly related (but by no means this is not an exhaustive list and authors need to explore google scholar to retrieve more relevant papers than the listed ones):\n\n[1] MoNet: Moments Embedding Network by Gou et al. (e.g. Stanford Cars via Tensor Sketching: 90.8 vs. 90.4 in this submission, Airplane: 88.1 vs. 87.3% in this submission, 85.7 vs. 84.3% in this submission)\n[2] Second-order Democratic Aggregation by Lin et al. (e.g. Stanford Cars: 90.8 vs. 90.4 in this submission)\n[3] Statistically-motivated Second-order Pooling by Yu et al (CUB: 85%)\n[4] DeepKSPD: Learning Kernel-matrix-based SPD Representation for Fine-grained Image Recognition by Engin et al.\n[5] Global Gated Mixture of Second-order Pooling for Improving Deep Convolutional Neural Networks by Q. Wang et al. (512D representations)\n[6] Low-rank Bilinear Pooling for Fine-Grained Classification' by S. Kong et al. (CVPR I believe). They get some reduction of size of 10x less than tensor sketch, higher results than here by some >2% (CUB), and all this obtained in somewhat more sophisticated way.\n\nThe authors brushed under the carpet some comparisons. Some methods above are simply better performing even if cited, e.g. MoNet [1] uses sketching and seems a better performer on several datasets, see [2] that uses sketching (Section 4.4), see [5] which also generates compact representation (8K). [4] may be not compact but the whole point is to compare compact methods with non-compact second-order ones too (e.g. small performance loss for compact methods is OK but big loss warrants a question whether they are still useful). Approach [6] seems to also obtain better results on some sets (common testbed comparisons are essentially encouraged). \n\nAt this point, AC will also point authors to sparse coding methods on matrices (bilinear) and tensors (higher-order) from years 2013-2018 (TPAMI, CVPR, ECCV, ICCV, etc.). These all methods can produce compact representations (512 to 10K or so) of bilinear or higher-order descriptors for classification. This manuscript fails to mention this family of methods.\n\nFor a paper to be improved for the future, the authors should consider the following:\n- make a thorough comparison with existing second-order/bilinear methods in the common testbed (most of the codes are out there on-line)\n- the authors should vary the size of representation (from 512 to 8K or more) and plot this against accuracy\n- the authors should provide theoretical discussion and guarantees on the quality of their low-rank approximations (e.g. sketching has clear bounds on its approximation quality, rates, computational cost). The authors should provide some bounds on the loss of information in the proposed method.\n- authors should discuss the theoretical complexity of proposed method (and other methods in the literature)\n\nAdditionally, the authors should improve their references and the story line. Citing  (Lin et al. (2015)) in Eq. 1 and 2 as if they are the father of bilinear pooling is misleading. Citing (Gao et al. (2016)) in the context of polynomial kernel approximation in Eq. 3 to obtain bilinear pooling should be preceded with earlier works that expand polynomial kernel to obtain bilieanr pooling. AC can think of at least two papers from 2012/2013 which do derive bilinear pooling and could be cited here instead. AC encourages the authors to revise their references and story behind bilinear pooling to give unsuspected readers a full/honest story of bilinear representations and compact methods (whether they are branded as compact or just use sketching etc., whether they use dictionaries or low-rank representations).\n\nIn conclusion, it feels this manuscript is not ready for publication with ICLR and requires a major revision. However, there is some merit in the proposed direction and authors are encouraged to explore further.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Incomplete work."
    },
    "Reviews": [
        {
            "title": "Method needs some clarification. ",
            "review": "Summary: This paper presents a way to combine existing factorized second order representations with a codebook style hard assignment. The number of parameters required to produce this encoded representation is shown to be very low. Like other factorized representations, the number of computations as well as the size of any intermediate representations is low. The overall embedding is trained for retrieval using a triplet loss. Results are shown on Stanford online, CUB and Cars-196 datasets.\n\nComments:\n\nReview of relevant works seems adequate. The results seem reproducible. \n\nThe only contribution of this paper is combining the factorized second order representations  of (Kim et. al. 2017) with a codebook style assignment (sec. 3.2). Seems marginal.\n\nThe scheme described in Sec. 3.2 needs clarification. The assignment is applied to x as h(x) \\kron x in (7). Then the entire N^2 D^2 dimensional second order descriptor h(x) \\kron x \\kron h(x) \\kron x is projected on a N^2 D^2 dim w_i. The latter is factorized into p_i, q_i \\in \\mathbb{R}^{Nd}, which are further factorized into codebook specific projections u_{i,j}, v_{i,j} \\in \\mathbb{R}^{d}. Is this different from classical assignment, where x is hard assigned to one of the N codewords as h(x), then projected using \\mathbb{R}^d dimensional p_i, q_i specific to that codeword ?\n\nIn section 4.1 and Table 2, is the HPBP with codebook the same as the proposed CHPBP ? The wording in \"Then we re-implement ... naively to a codebook strategy\"  seems confusing.\n\nThe method denoted \"Margin\" in Table 4 seems to be better than the proposed approach on CUB. How does it compare in terms of efficiency, memory/computation ?\n\nIs it possible to see any classification results? Most of the relevant second order embeddings have been evaluated in that setting.\n\n\n===============After rebuttal ===============================\n\nAfter reading all reviews, considering author rebuttal and AC inputs, I believe my initial rating is a bit generous. I would like to downgrade it to 4. It has been pointed out that many recent works that are of a similar flavor, published in CVPR 2018 and ECCV 2018, have slightly better results on the same dataset. Further, the only novelty of this work is the proposed factorization and not the encoding scheme. This alone is not sufficient to merit acceptance. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting idea of bilinear pooling with codebooks. But, needs more experiments for validating the idea.",
            "review": "Summary:\nThis paper proposes a novel bilinear representation based on a codebook model.\nThe proposed method is build upon the form of Hadamard Product for efficient representation of a bilinear model.\nThrough introducing the framework of codebook, it is naturally extended into a multiple-rank representation while the efficient pooling scheme is also derived from the (sparse) codeword assignment.\nIn addition, the authors also present an efficient formulation in which the codebook-based projections are factorized via a shared projection to further reduce the parameter size.\nThe experimental results on image retrieval tasks show that the proposed method produces better classification accuracy with a limited amount of parameters.\n\nComments:\nPros:\n+ It is interesting that one-rank bilinear pooling is naturally extended to multiple-rank one via introducing codebooks.\n+ Good performance in the image retrieval tasks.\n\nCons:\n- This paper lacks important comparison for fairly evaluating the effectiveness of the proposed formulation.\n- It also lacks detailed description and discussion for the methods.\n\nDue to the above-mentioned weak points, the reviewer cannot fully understand whether the performance improvement really comes from the proposed formulation or not. Thus, this manuscript is currently judged as border. The detailed comments are shown in the followings.\n\n- Comparison\nEventually, the proposed method is closely related to the multiple-rank representation of a bilinear model;\n\nz_i = x^T W_i x (Eq.5) ~ x^T u_i v_i^T x (one-rank, Eq.6) ~ x^T U_i V_i^T x (multiple-rank), ... Eq.(A)\n\nwhich is a straightforward extension from the one-rank model. From this viewpoint, the proposed form in Eq.10 is regarded as an extension of (A) by introducing non-linearity as\n\nz_i = x^T U_i {h(x)h(x)^T} V_i^T x.  ... Eq.(10)\n\nThus, the main technical contribution is found in the weighting by {h(x)h(x)^T}, but its impact on the performance is not evaluated in the experiments. Furthermore, it is also possible to simply introduce such a non-linearity into the model (A) according to [Kim et al.,2017];\n\nz_i = \\sigma(x^T U_i) \\sigma(V_i^T x) = 1^T {\\sigma(U_i^T x) .* \\sigma(V_i^T x)}, ... Eq.(B)\n\nwhere \".*\" indicates Hadamard Product, and we can more directly apply the method of [Kim et al., 2017] to the multiple-rank model by\n\nz_i = p^T {\\sigma(U_i^T x) .* \\sigma(V_i^T x)}, ... Eq.(C)\n\nwhere p is a R-dimensional vector. On the other hand, it is also necessary to compare the proposed method with [Kim et al.,2017] which is formulated by\n\nz = P^T {\\sigma(U^T x) .* \\sigma(V^T x)}, ... Eq.(D)\n\nwhere U and V are matrices of d x K and P is K x D. The parameter K (shared rank) should be determined so that the total parameter size of (2dK + KD) is compatible to that of the proposed method, 2NdD.\n\nIn summary, for demonstrating the effectiveness of the proposed method in Eq.(10), it is inevitable to compare it with the models (A, B, D) and hopefully (C).\n\n- Presentation\nIn Section 4.2, the performance results of the factorization model in Eq.(13) are merely shown without deep discussion nor analysis on them. In particular, it is unclear why the JCF of N=32 and R=32 outperforms the CHPBP of N=32. Those two methods are different only in the form of U and V:\n(CHPBP) U_i -> U'_i A (JCF),\nwhere U_i and U'_i have the same dimensionality of d x 32, and thus we can say that JCF overly parameterizes the projection by redundantly introducing A of 32 x 32. Thus, the projection capacity of JCF is completely the same as that of CHPBP. Therefore, it needs detailed discussion for the performance improvement shown in Figure 1.\n\nMinor comments are:\n* There are lots of notations, and thus it would be better to show a summary of the notations.\n* In Section 4.1, there is no clear description about the methods of BP and HPBP. Actually, the method of HPBP is different from the one presented in [Kim et al., 2017].\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The proposed representation method is tested on only one task and considers only one evaluation metric",
            "review": "The paper proposes a second order method to represent images. More exactly, multiple (low-dimensional) projections of Kronecker products of low-dimensional representations are used to represent a limited set of dimensions of second-order representations. It is an extension of HPBP (Kim et al., ICLR 2017) but with codebook assigment. \n\nThe main advantage of the method is that, if the number of projection dimensions is small enough, the number of learned parameters is small and the learning process is fast. The method can be easily used as last layers of a neural network. Although the derivations of the method are straightforward, I think the paper is of interest for the computer vision community. \n\nNonetheless, I think that the experimental evaluation is weak. Indeed, the article only considers the specific problem of transfer learning and considers only one evaluation metric (recall@k). However, recent papers that evaluate their method for that task also use the Normalized Mutual Information (NMI) (e.g. [A,B]) or the F1-score [B] as evaluation metrics. \nThe paper does not compare the same task and datasets as (Kim et al., ICLR 2017) either.\nIt is then difficult to evaluate whether the proposed representation is useful only for the considered task. Other tasks and evaluation metrics should be considered.\nMoreover, only the case where D=32 and R=8 are evaluated. It would be useful to observe the behavior of the approaches for different values of R. \nIn Section 3.2, it is mentioned that feature maps become rapidly intractable if the dimension of z is above 10. Other Factorizations are then proposed. How do these factorizations affect the second order nature of the representation of z? Is the proposed projection in Eq. (10) still a good approximation of the second order information induced by the features x?\n\n\nThe paper says that the method is efficient but does not mention training times. How does the method compare in terms of clockwork times compared to other approaches (on machines with similar architecture)?\n\nIn conclusion, the experimental evaluation of the method is currently too weak.\n\n\n[A] Hyun Oh Song, Stefanie Jegelka, Vivek Rathod, Kevin Murphy: Deep Metric Learning via Facility Location. CVPR 2017\n[B] Wang et al., Deep Metric Learning with Angular Loss, ICCV 2017\n\nafter rebuttal:\nThe authors still did not address my concern about testing on only one task with only one evaluation metric.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}