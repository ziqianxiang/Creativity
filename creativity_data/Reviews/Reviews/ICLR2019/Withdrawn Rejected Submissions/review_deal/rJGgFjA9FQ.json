{
    "Decision": "",
    "Reviews": [
        {
            "title": "Still needs a lot of work",
            "review": "This submission develops a method for evaluating the degree to which certain input features contextualize the effects of other input features in deep learning models. The authors achieve this through two steps. First, they approximate the behaviour of the target network with a mixture of student networks, that each only process a subset of the input. This provides a coarse-grained measure of the relevant context for features' effects. Second, they obtain a fine-grained measure of how input units interact with each other, via a backwards propagation algorithm. In turn, the authors demonstrate an application of these methods to the value network of an AlphaGo instantiation. Here, the objective is to measure how the effect of a newly-placed stone is modulated by the other stones on the board. The authors then validate these measures against human Go experts, providing some examples and summary statistics.\n\nI don't think this submission is ready for publication. \n\n- I found it a very confusing read, and much of the text requires a substantial rewrite to make it clearer to understand. For instance, I struggled to follow the process in Section 3.2, and the results in Section 4.2. Target units (3.2.2) and inference patterns are not explained, nor is o^{bfr}.\n\n- While the authors explain two different steps (the coarse-grained and the fine-grained ones), it's not clear how these are related. Are they used together on the AlphaGo value net? Why not just do the fine-grained study directly on the original teacher net? \n\n- Critically, the evaluation with human experts lacks the necessary rigor. There are no baselines considered for the correlations or the subjective ratings. What structure is actually being captured by this? Is it advanced Go knowledge, elementary Go knowledge, or spatial proximity? \n\n- Despite promising to \"explain the gaming strategy of the alphaGo Zero model\", I'm not convinced this delivers in the end.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "the motivation of this paper is not properly justified by these evaluations.",
            "review": "\nSummary: \nThis paper proposes a method to reveal the effect of contextual (local) features to CNN network output. Specifically, the authors focus on the task of explaining the value network in AlphaGo. Value network provides a prediction of the winning probability over the current board. The proposed idea first uses a mixture of small local models to estimate the target global model of Value network.  It then uses the mid-level patterns from the smaller networks to extract the collaboration between different features. The evaluation section shows that the method proposed has extracted information that correlates with human annotations.\n\nReview:\nThis paper targets an interesting problem and proposes a novel approach. The local visualization idea is interesting.  A few comments: \n\n0. The evaluation section needs to be improved. The explanation in Figure 3 is clear, but it doesn’t justify the method.\n\n1.  Please add results showing the performance of using student networks. The absence of this result makes the main logic of the paper questionable. \n\n2.  Please add more evaluation of the collaboration extraction from the local models. It should be compared to baselines, like saliency maps.\n\n3.  The reported Jaccard Similarity is only 0.36. It is about the whole board. This hardly justifies that the result achieves good correlation with human annotations.\n\n4.  Why the last three boards in figure 5 are “perfect” while the predicted contextual features are very different from the human annotation? Besides, I suggest the authors add a baseline using distance to compare with the result from the proposed method.\n\nIn summary, I feel the motivation of this paper is not properly justified by these evaluations.\n\nMinor issues/suggestions:\n1.    No summary of the proposed method. An algorithm box is recommended.\n2.    Experiment results shown in the Appendix are problematic. In the “more result” Section board 3,4 “merged map” and “manual annotation” have different stones. Also, more descriptions should be provided to explain the results in the appendix.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Need more work",
            "review": "The paper uses a mixture of student models to learn from the pre-trained AlphaGoZero model (ELF OpenGo). Each student model only covers a faction of the board (13x13 or 10x10). With the student model, given one referenced stone u, its relationship with its surrounding stones is studied (i.e., contextual collaboration), by checking the difference between activation with/without the reference stone u. The relationship is in terms of values. High-value means the connection favors black and/or damaging white. Based on the proposed approach, the paper gives case studies of multiple situations in the Go game, as well as human player evaluation. \n\nThe paper is somehow confusing, leaving a lot of issues to be addressed. In the first part of the paper, student models are trained to mimic the teacher's output, after that student models are used to compute the contextual collaboration using some metric (e.g. how strong the role is played by one activation). I didn't see why not just use the original 19x19 model directly to understand contextual collaboration (which should be much more accurate since ELF OpenGo is quite strong), and what would be the difference compared to using a model with smaller receptive field. Also how good is the local model in predicting the value function? The value function of Go is a global quantity and a few changes in the local stone patterns will completely change the value from black 100% win to white 100% win. Such information cannot be carried by a single value output by the local students (Eqn. 2 and 3). \n\nThe experiments are unconvincing. There are a few visualizations, a few human evaluations, but the conclusion is a bit vague. What to get from the paper? Did we have a better understanding of the model? From Fig. 3 it looks like the model indeed captures some common basic patterns in the game, but this is also the case for methods without convolutional network (e.g., \"Bayesian Pattern Ranking for Move Prediction in the Game of Go\"). \n\nThe sentence in (footnote 2, page 6: \"The value net uses the current state, as well as seven most recent states, to output eight values for the eight states. To simplify the algorithm, we take the value corresponding to the current state as the target value\n\") is not right. AlphaGoZero model (and ELF OpenGo) takes the current state and the last 7 most recent states as input, and only output a single value for the current state. \n\nOverall I feel that the paper made an interesting initial attempt but there are still a lot of work to do. \n\nDetailed questions: \n\n1. Experiments:\n - How many board situations are annotated? \n - It seems the heatmaps are very different yet the players gives perfect score. Is this metric too subjective?\n - For 13x13 splitting, the four sub-boards are rotated so that all corners are aligned with top-left. How about the nine 10x10 boards? The sub-board in the middle of the 19x19 board should not behave the same as the sub-board at the corners. \n\n2. The paper shows stones that have strong correlations with the probe stone. Are there other stones in similar situations but are not picked up by this method? \n\n3. What is the error/loss to estimate the whole board values using local region values? If the error is high then using student model for analysis might raise issues. \n\n4. Can you show weights and values learned by other subregions to show how discriminative they are?\n\n5. All examples are in the middle of some unfinished sequences, so just based on last move it will be a very strong baseline (e.g. this will be easily learned by convnets even if not specifically provided.) Can you provide some more game states such that the target move is far away from the last move region? (Applicable to both experiments)\n\nMinor issues:\nin 4.2 the white and the white -> the black and the white",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}