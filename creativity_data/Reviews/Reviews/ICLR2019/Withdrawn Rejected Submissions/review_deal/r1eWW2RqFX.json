{
    "Decision": "",
    "Reviews": [
        {
            "title": "Comparison with the state-of-the-art is incomplete",
            "review": "The paper presents an approach for generating 3D shapes as point clouds. The approach consider a lexicographic ordering of points according to the (x, y, z) coordinates and train a model to predict points in order given the previous predictions. The conditional distribution is modeling using a self-attention mechanisms that consider multiplicative interactions between representations.  \n\nThe model is evaluated in two ways. First  for point-cloud generation which is evaluated both qualitatively and for unsupervised learning of point-cloud representations. Second as a decoder for image to shape completion tasks. \n\nComments:\n\n1. Lexicographic overlong of points seems like a poor choice for shape representation. It is sensitive to object rotation, missing parts, etc. \n2. The method is not compared with other approaches for point-cloud generation that have improved over the 3D R2N2 approach the paper compares against. In particular \n    1. AtlastNet and FoldingNet (CVPR 2018) consider parameterization of point clouds as a function of (x,y) coordinates to encoded the 2 manifold nature of the shape.\n\n    2. Multiresolution Tree Networks (ECCV 2018) -- that consider 1D ordering of points obtained from a KD tree ordering of points. This approach is directly comparable to the proposed approach and reports 86.4% accuracy for unsupervised representation learning on ModelNet40 classification. The improvements over the approach that uses fully-connected layers such as PointSetGen (Fan et al, 2017) is marginal (.640 -> 0.656 improvement in IOU). MRTNet and AtlasNet report improvements by a larger margin over PointSetGen. \n\n    3. Other baselines for image to shape generation that generate shapes using hierarchical voxel-based representation (OctTree networks Riegler et al.), view-based models (Lin et al., AAAI 2018), etc. are missing.\n\nIn summary the representation is not well motivated and the evaluation is incomplete. In particular comparison to several recent works on 3D shape generation is missing.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "OK paper, but does not seem particularly novel, and experiments seem inconclusive",
            "review": "Summary:\nThe paper introduces a generative model for point clouds. The main idea is to use an auto-regressive model, essentially a version of pixel-RNN, which generates points one-by-one. In addition, authors use an attention model to handle longer-range interactions.\n\nPros:\n+ The paper is relatively easy to follow.\n+ Developing new generative models for 3D objects and in particular point clouds is clearly a very important problem.\n+ The overall approach of using pixel RNN-like models for this task makes a lot of sense.\n+ Using attention to extract global features also seems reasonable in this context.\n+ Experiments show that the proposed models performance is on par or better than the existing methods (although see cons).\n+ Shape completion is a nice bonus of the model.\n\nCons:\n- Although the approach seems reasonable, it is not entirely clear what is the message of the paper: is it that we should use autoregressive models to generate point clouds, or use the attention / global context?\n- Whether the work is very novel is not clear: both of the main contributions (shape of the generative distribution and using the context / attention) have already been done before (albeit maybe not in exactly the same context).\n- As for the experimental evaluation, since there are no ablation studies, it is hard to see which part of the model is actually important for the performance.\n- One of the major issues with pixelRNN is its scalability. It is inherently sequential and thus does not scale really well to large outputs. Thus it is a bit strange that scalability is not really discussed in the paper.\n- (minor) Figures 2 and 4 are not very helpful.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting paper! Please address the concerns listed below.",
            "review": "Paper summary:\nThis paper studies the problem of point cloud generation using deep autoregressive models. More specifically, it proposed a novel architecture called PointGrow network that is able to iteratively generate 3D point cloud unconditionally or conditioned on semantic context (e.g., 2D image, class label, or partial 3D point cloud). Key design is a context-aware operation that aggregates all the previously generated points dynamically by fetching and averaging. For experimental evaluations, this paper used a subset of ShapeNet (objects from 7 categories), ModelNet40 and PASCAL 3D+ dataset. \n\n==\nNovelty & Significance:\nThis is a very interesting paper that applies the pixelCNN (Oord et al. 2016) framework to 3D point cloud generation. Despite the high-quality generation results shown in the paper, reviewer feels the novelty of this paper is quite limited: (1) The iterative generation has been explored to some extent in image domain; (2) Similar self-attention operators have been proposed before on point cloud recognition and generation (e.g., Qi et al 2017, Wang et al 2018).\n\n==\nQuality & Presentation:\nOverall, this paper provides solid comparisons with previous work in terms of generation quality and representation power. However, reviewers have a few concerns in terms of experimental design.\n\nQ1: For the unconditional version, please comment on the performance when training the proposed PointGrow network on all categories. Does it work or not?\n\nQ2: In Figure 3, the visualization of self-attention field looks a bit noisy. For example, most of the activated context points are not very relevant to the point on the table (on 3rd row, 7th column of Figure 3). Please clarify this in the rebuttal.\n\nQ3: In Table 1 and Table 2, it makes more sense to provide information  such as model complexity as well. \n\nQ4: For unsupervised feature learning, the results will be much more convincing if the proposed model is also trained on 55 categories. It is an important ablation study.\n\nQ5: The shape completion experiment is a bit artificial. As the points are generated by some pre-defined order, the PointGrow framework may not be able to perform shape completion task in general (e.g., to complete the shape given two wings of an airplane).\n\nQ6: For image condition interpolation (see Figure 9), reviewer would like to know the performance with other categories. Please comment on the performance in the rebuttal.\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}