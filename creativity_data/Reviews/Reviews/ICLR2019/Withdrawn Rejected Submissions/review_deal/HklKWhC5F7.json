{
    "Decision": {
        "metareview": "The reviewers conclude the paper does not bring an important contribution compared to existing work. The experimental study can also be improved. ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "reject"
    },
    "Reviews": [
        {
            "title": "An empirical study of the influence of training data size on model robustness ",
            "review": "This paper conducts an empirical analysis of the effect of training data size on the model robustness to adversarial examples. The authors compared four different NN architectures using four different datasets for the task of image classification. Overall, the paper is easy to follow and clearly written. \n\nHowever, since Su et al., 2018, already presented similar findings, I do not see any major contribution in this paper. Additionally, I would expect the authors to conduct some more analysis of their results besides acc. and distortion levels. For examples, investigate the type of mistakes the models have made, compare models with the same test acc. but different amount of training data used to get there, some analysis/experiments to explain these findings (monitor models parameters/grads during training, etc.) \n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Clear structure and presentation of the empirical evaluation but the significance of the results is not clear.",
            "review": "This paper empirically evaluates the effect of the training dataset size on accuracy and robustness against adversarial attacks. The methodology of the paper is generally easy to assess and the overall idea well communicated.\n\nFor the motivation example I assume the following assessment holds true. Several linear functions are sampled and compose S_1, S_2, and T. A single linear regression model is used to fit all the data, either S_1 or (S_1 and S_2). If that is the case the experiment is not clear to me since the single linear model can only fit the data mean, mean slope (a) and constant (mu). Since the joint dataset better captures the mean of T the error for the joint training should be lower indeed. However, to actually compare both values the same threshold theta should be used for both and not a percentage of their performance. I would argue that this very simple model does not provide any valuable insight into the problem due to its construction.\n\nThe experimental setup presented in Section 4 only considers examples which are classified correctly by all data subsets. However, it is crucial to also consider the mistakes of these subsequent sets. For example, the learned model for the most restrictive dataset is most likely not exposed to a complex decision boundary, therefore it will exhibit a much smoother prediction at the cost that it will simply classify many more examples as the target class. In this case using data perturbations is not even the problem since completely different examples might be classified wrongly. Although not entirely clear, it would be very useful to consider the nearest negative neighbor in the dataset in the embedding space of the classifier to capture this problem at least partially. In general if the test accuracy is lower the learned classifier exhibits less performance, thus, adversary examples, distorted examples are not the main issue since it simply makes mistakes on visually different examples. Therefore, the overall analysis should be much more focused on models which achieve the same test performance but use require less data to achieve this performance.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Empirical study of variation of accuracy and robustness of networks versus training data size",
            "review": "The paper presents an empirical study of how accuracy and robustness vary with increasing training data for four different data sets and CNN architectures. The main conclusion of the study is that while training accuracy generally increases with increasing training data, provided sufficient training data is available for training the network in the first place, the robustness on the other hand does not necessarily increase, and may even decrease.\n\nSimilar findings were presented previously in Su et al., 2018. Hence, the current paper contains incremental and marginal new findings versus the existing literature. The paper would also have been a lot stronger and significantly advanced our scientific understanding of the problem if the authors had made some attempt at trying to explain their findings theoretically. In its current form the paper does not contain sufficient contributions for acceptance.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}