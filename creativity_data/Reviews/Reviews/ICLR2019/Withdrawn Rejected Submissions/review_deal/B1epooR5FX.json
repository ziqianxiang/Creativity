{
    "Decision": {
        "metareview": "The paper proposes a framework at the intersection of programming and machine learning, where some variables in a program are replaced by PVars - variables whose values are learned using machine learning from data. The paper presents an API that is designed to support this scenario, as well as three case studies: binary search, quick sort, and caching - all implemented with PVars.\n\nThe reviewers and the AC agree that the paper presents and potentially valuable new idea, and shows concrete applications in the presented case studies. They provide example code in the paper, and present a detailed analysis of the obtained results.\n\nThe reviewers and AC also not several potential weaknesses - the AC will focus on a subset for the present discussion. The paper is unusual in that it presents a programming API rather than e.g., a thorough empirical comparison, a novel approach, or new theoretical insights. Paper at the intersection of systems and machine learning can make valuable contributions to the ICLR community, but need to provide a clear contributions which are supported in the paper by empirical or theoretical results. The research contributions of the present paper are vague, even after the revision phase. The main contribution claimed is the introduction of the API, and that such an API / system is feasible. This is an extremely weak claim. A stronger claim would be if e.g., the present approach would advance the state of the art beyond an existing such framework, e.g., probabilistic programming, either conceptually or empirically. I want to particularly highlight probabilistic programming here, as it is mentioned by the authors - this is a well developed research area, with existing approaches and widely used tools. The authors dismiss this approach in their related work section, saying that probabilistic programming is \"specialized on working with distributions\". Many would see the latter as a benefit, so the authors should clearly motivate how their approach improves over these existing methods, and how it would enable novel uses or otherwise provide benefits. At the current stage, the paper is not ready for publication.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "innovative idea, contributions insufficient"
    },
    "Reviews": [
        {
            "title": "Potentially interesting idea, not well explained and justified",
            "review": "This paper proposes using predicted variables(PVars) - variables that learn\ntheir values through reinforcement learning (using observed values and\nrewards provided explicitly by the programmer). PVars are meant to replace\nvariables that are computed using heuristics.\n\nPros:\n* Interesting/intriguing idea\n* Applicability discussed through 3 different examples\n\nCons:\n* Gaps in explanation\n* Exaggerated claims\n* Problems inherent to the proposed technique are not properly addressed, brushed off as if unimportant\n\nThe idea of PVars is potentially interesting and worth exploring; that\nbeing said, the paper in its current form is not ready for\npublication.\n\nSome criticism/suggestions for improvement:\n\nWhile the idea may be appealing and worth studying, the paper does not address several problems inherent to the technique, such as:\n\n- overheads (computational cost for inference, not only in\n  prediction/inference time but also all resources necessary to run\n  the RL algorithm; what is the memory footprint of running the RL?)\n\n- reproducibility\n\n- programming overhead: I personally do not buy that this technique -\n  at least as presented in this paper - is as easy as \"if statements\"\n  (as stated in the paper) or will help ML become mainstream in\n  programming. I think the programmer needs to understand the\n  underpinnings of the PVars to be able to meaningfully provide\n  observations and rewards, in addition to the domain specific\n  knowledge. In fact, as the paper describes, there is a strong\n  interplay between the problem setting/domain and how the rewards should be\n  designed.\n\n- applicability: when and where such a technique makes sense\n\nThe interface for PVars is not entirely clear, in particular the\nmeaning of \"observations\" and \"rewards\" do not come natural to\nprogrammers unless they are exposed to a RL setting. Section 2 could\nprovide more details such that it would read as a tutorial on\nPVars. If regular programmers read that section, not sure they\nunderstand right away how to use PVars. The intent behind PVars\nbecomes clearer throughout the examples that follow.\n\nIt was not always clear when PVars use the \"initialization function\"\nas a backup solution. In fact, not sure \"initialization\" is the right\nterm, it behaves almost like an \"alternative\" prediction/safety net.\n\nThe examples would benefit from showing the initialization of the PVars.\n\nThe paper would improve if the claims would be toned down, the\nlimitations properly addressed and discussed and the implications of\nthe technique honestly described. I also think discussing the\napplicability of the technique beyond the 3 examples presented needs\nto be conveyed, specially given the \"performance\" of the technique\n(several episodes are needed to achieve good performance).\n\nWhile not equivalent, I think papers from approximate computing (and\nperhaps even probabilistic programming) could be cited in the related\nwork. In fact, for an example of how \"non-mainstream\" ideas can be\nproposed for programming languages (and explained in a scientific\npublication), see the work of Adrian Sampson on approximate computing\nhttps://www.cs.cornell.edu/~asampson/research.html\nIn particular, the EnerJ paper (PLDI 2011) and Probabilistic Assertions (PLDI 2014).\n\nUpdate: I maintain my scores after the rebuttal discussion.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting proposal without clear contributions",
            "review": "This paper proposes the use of RL as a set of commands to be included as programming instructions in  common programming languages.  In this aspect, the authors propose to add simple instructions to employ the power of machine learning in general, and reinforcement learning in particular in common programming tasks.\n\nIn this aspect, the authors show with three different examples how the use of RL can speed up the performance of common tasks: binary search, sorting and caches.\n\nThe paper is easy to read and follow. \n\nIn my opinion, the main problem of the paper is that the contributions are not clear. The authors claim that the introduce a new hybrid approach of programming between common programming and ML, however, I do not see many differences between calling APIs and the current proposal. The paper seems to be a wrapper of API calls. Here, the authors should comment existing approaches based on ML and APIs.\n\nThe authors  introduce the examples to show the advantages of using predictive variables. Many of the advantages are based on increasing the performance of the algorithms using these predictive variables, however, the results do not include the computational costs of learning the models. \n\nTherefore, in my opinion the paper should be more focused on detailing the commands of use of predictive variables and emphasising the advantages with respect to existing methods. Currently, the paper gives too relevance to the performance of the experiments, where the novel contributions are not there.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting idea but replaces constants with other constants ",
            "review": "The paper proposes to include within regular programs, learned parameters that are then tuned in an online manner whenever the program is invoked. Thus learning is continuous, integration with the ML backend seamless. The idea is very interesting however, it seems to me that while we can replace native variables with learned parameters, the hyperparameters involved in the learning become new native variables (e.g. the value of feedback). Perhaps with some effort we can replace the  hyperparameters with predicted variables too. Other concerns of mine stem from the programmer in me. I think of a program as something deterministic and predictable. With continuous, online, self-tuning, these properties are gone. How do the authors propose to assuage folks with my kind of mindset? Is debugging programs with predicted variables an issue? Consider a situation where the program showed some behavior with a certain setting of q which has since been tuned to another value and thus the same behavior doesn't show up. I find these to be very interesting questions but don't see much of a discussion in the current draft. Also, how does this work relate to probabilistic programming?",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}