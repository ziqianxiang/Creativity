{
    "Decision": {
        "metareview": "This paper presents a taxonomic study of neural network architectures, focussing on those which seek to map onto different part of the hierarchy of models of computation (DFAs, PDAs, etc). The paper splits between defining the taxonomy and comparing its elements on synthetic and \"NLP\" tasks (in fact, babi, which is also synthetic). I'm a fairly biased assessor of this sort of paper, as I generally like this topical area and think there is a need for more work of this nature in our field. I welcome, and believe the CFP calls for, papers like this (\"learning representations of outputs or [structured] states\", \"theoretical issues in deep learning\")). However, despite my personal enthusiasm, the reviews tell a different story.\n\nThe scores for this paper are all over the place, and that's after some attempt at harmonisation! I am satisfied that the authors have had a fair shot at defending their paper and that the reviewers have engaged with the discussion process. I'm afraid the emerging consensus still seems to be in favour of rejection. Despite my own views, I'm not comfortable bumping it up into acceptance territory on the basis of this assessment. Reviewer 1 is the only enthusiastic proponent of the paper, but their statement of support for the paper has done little to sway the others. The arguments by reviewer 3 specifically are quite salient: it is important to seek informative and useful taxonomies of the sort presented in this work, but they must have practical utility. From reading the paper, I share some of this reviewer's concerns: while it is clear to me what use there is the production of studies of the sort presented in this paper, it is not immediately clear what the utility of *this* study is. Would I, practically speaking, be able to make an informed choice as to what model class to attempt for a problem that wouldn't be indistinguishable from common approaches (e.g. \"start simple, add complexity\"). I am afraid I agree with this reviewer that I would not.\n\nMy conclusion is that there is not a strong consensus for accepting the paper. While I wouldn't mind seeing this work presented at the conference, but due to the competitive nature of the paper selection process, I'm afraid the line must be drawn somewhere. I do look forward to re-reading this paper after the authors have had a chance to improve and expand upon it.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Borderline"
    },
    "Reviews": [
        {
            "title": "Very interesting consolidation paper on the analysis of dynamic neural networks",
            "review": "I really liked this paper and believe it could be useful to many practitioners of NLP, conversational ML and sequential learning who may find themselves somewhat lost in the ever-expanding field of dynamic neural networks.\n\nAlthough the format of the paper is seemingly unusual (it may feel like reading a survey at first), the authors propose a concise and pedagogical presentation of Jordan Networks, LSTM, Neural Stacks and Neural RAMs while drawing connections between these different model families.\n\nThe cornerstone of the analysis of the paper resides in the taxonomy presented in Figure 5 which, I believe, should be presented on the front page of the paper. The taxonomy is justified by a thorough theoretical analysis which may be found in appendix.\n\nThe authors put the taxonomy to use on synthetic and real data sets. Although the data set taxonomy is less novel it is indeed insightful to go back to a classification of grammatical complexity and structure so as to enable a clearer thinking about sequential learning tasks. \n\nAn analysis of sentiment analysis and question answering task is conducted which relates the properties of sequences in those datasets to the neural network taxonomy the authors devised. In each experiment, the choice of NN recommended by the taxonomy gives the best performance among the other elements presented in the taxonomy.\n\nStrength:\no) The paper is thorough and the appendix presents all experiments in detail. \no) The taxonomy is clearly a novel valuable contribution. \no) The survey aspect of the paper is also a strength as it consolidates the reader's understanding of the families of dynamic NNs under consideration.\n\nWeaknesses:\no) The taxonomy presented in the paper relies on an analysis of what the architectures can do, not what they can learn. I believe the authors should acknowledge that the presence of Long Range Dependence in sequences is still hard to capture by dynamic neural networks (in particular RNNs) and that alternate analysis have been proposed to understand the impact of the presence of such Long Range Dependence in the data on sequential learning. I believe that mentioning this issue along with older (http://ai.dinfo.unifi.it/paolo/ps/tnn-94-gradient.pdf) and more recent (e.g. http://proceedings.mlr.press/v84/belletti18a/belletti18a.pdf and https://arxiv.org/pdf/1803.00144.pdf) papers on the topic is necessary for the paper to present a holistic view of the matter at hand.\no) The arguments given in 5.2 are not most convincing and could benefit from a more thorough exposition, in particular for the sentiment analysis task. It is not clear enough in my view that it is true that \"since the goal is to classify the emotional tone as either 1 or 0, the specific contents of the text are not very important here\". One could argue that a single word in a sentence can change its meaning and sentiment.\no) The written could be more polished.\n\nAs a practitioner using RNNs daily I find this paper exciting as an attempt to conceptualize both data set properties and dynamic neural network families. I believe that the authors should address the shortcomings I think hinder the paper's arguments and exposition of pre-existing work on the analysis of dynamic neural networks.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Useful taxomony of memory-based neural network",
            "review": "Summary\n=========\nThe paper analyses the taxonomy over memory-based neural networks, in the decreasing order of capacity: Neural RAM to Neural Stack, Neural Stack to LSTM and LSTM to vanilla RNN. The experiments with synthetic and NLP datasets demonstrate the benefits of using models that fit with task types.  \n\nComment\n========\nOverall, the paper is well written and presents interesting analysis of different memory architectures. However, the contribution is rather limited. The proposed taxonomy is not new. It is a little bit obvious and mentioned before in [1] (Unfortunately, this was not cited in the manuscript). The theorems on inclusion relationship are also obvious and the main contribution of the paper is to formally show that in mathematical forms.  The experiments on synthetic tasks give some insights into the models’ operations, yet similar analyses can be found in [2, 3]. To verify the models really learn the task, the authors should include tests on unseen sequence lengths.  There remains questions unexplained in NLP tasks such as why multi-slot memory did not show more advantages in Movie Review and why Neural Stack performed worse than LSTM in bAbI data.  \n\nMinor potential errors: \n\nIn Eq. (6), r_{t-1} should be r_t   \n\nThe LSTM presented in Section 3.2 is not the common one. Normally, there should be x_t term in Eq. (3) and h_t=g_{o,t}*\\tanh(r_t) in Eq. (6). The author should follow the common LSTM formulas (which may lead to different proofs) or include reference to their LSTM version.  \n\n[1] Yogatama et al. Memory Architectures in Recurrent Neural Network Language Models. ICLR’18 \n\n[2] Joulin et al. Inferring algorithmic patterns with stack-augmented recurrent nets. NIPS’15 \n\n[3] Graves et al. Neural Turing Machines. arXiv preprint arXiv:1410.5401 (2014). ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Taxonomy is not illuminating",
            "review": "The authors propose a review-style overview of memory systems within neural networks, from simple RNNs to stack-based memory architectures and NTM / MemNet-style architectures. They propose some reductions to imply how one model can be used (or modify) to simulate another. They then make predictions about which type of models should be best on different types of tasks.\n\nUnfortunately I did not find the paper particularly well written and the taxonomy was not illuminating for me. I actually felt, in the endeavor of creating a simple taxonomy the authors have created confusing simplifications, e.g.\n\n\"LSTM: state memory and memory of a single external event\"\n\nto me is mis-leading as we know an LSTM can compress many external events into its hidden units. Furthermore the taxonomy did not provide me with any new insights or display a prediction that was actually clairvoyant. I.e. it was clear from the outset that a memory network (say) will be much better at bAbI than a stack-augmented neural network. It would be more interesting to me, for example, if the paper could thus formalize why NTMs & DNCs (say) do not outperform LSTMs at language modeling, for example. I found the reductions somewhat shady, e.g. the RAM simulation of a stack is possible, however the model could only learn the proposed reduction if the number of write heads was equal to the number of memory slots --- or unless it had O(N) thinking steps per time step, where N is the number of memory slots, so it's not a very realistic reduction. You would never see a memory network, for example, simulating a stack due to the fixed write-one-slot-per-timestep interface. \n\nNit: I'm not sure the authors should be saying they 'developed' four synthetic tasks, when many of these tasks have previously been proposed and published (counting, copy, reverse copy). ",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}