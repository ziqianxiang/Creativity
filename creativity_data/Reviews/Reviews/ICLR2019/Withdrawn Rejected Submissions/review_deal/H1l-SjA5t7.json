{
    "Decision": {
        "metareview": "While the paper has good quality and clarity and the proposed idea seems interesting, all three reviewers agree that the paper needs more challenging experiments to justify the proposed idea. The authors are not able to include additional experiments (such as these based on different transformations) into their revision to better convince the reviewers. In addition, the AC feels that the technical novelty of the paper is rather minor (some incremental change to VAE). In particular, related to some concerns of Reviewer 3, the AC feels the proposed idea is not too much different than introducing certain kind of side-information for supervision; the main novelty seems to be distorting the data itself somehow to provide these side information (which does not seems to be that novel).\n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting idea, but the novelty is not high and the experimental analysis is weak"
    },
    "Reviews": [
        {
            "title": "An interesting model without enough experimental justifications",
            "review": "This paper proposed a new training framework to disentangle global structures from local structures \nbased on Variational Autoencoders (VAEs). They first generate a transformed image by shuffl\u000fing the \npatches of the original image to destroy the global structures. The training task forces the model to\nreconstruct the original image and shuffled images from different latent variables, thus separating \nglobal long-range structural correlations and local patch-wise correlations .\n\nInstead of adjusting the objective function or model structure, the paper proposed a new and simple\ntraining framework to disentangle the global and local structures, which is novel. \n\nThe experiment results are good on SVHN. Some visual inspection experiments on CIFAR10 are performed. \nThe plot (Figure2 (d)) is very blurry and people cannot really tell local structure from it. The rest experiments \nare all based on SVHN, which is too simple. \n\nMore experiments based on other types of data sets with clear global structures such as faces or stop signs will \nbe more convincing.\n\nIn the digit dataset, the local and global structures are relatively easy to separate. However, in Table 1, the \nperformance of VAE+Auxiliary is not better than two of the other methods.\n\nThe idea in this paper is novel but experiments do not seem to be enough. More experiments on datasets \nwith clear global and local structure separations with careful analyses are required to make the paper stronger.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good paper; a broader analysis beyond global-local disentanglement is desirable.",
            "review": "The paper proposes a method to disentangle latent variables for certain factors of interest in an image by considering the original input image and a transformation of the image where information about the factors of interest is removed. The generative process is then modeled by having two latent variables --  the first responsible for generating the transformed image whereas both latent variables are responsible for generating the original input image. This inductive bias naturally enforces that the second latent variable will not model the information which the first needs to reconstruct the transformed image, due to the VAE objective penalizing redundancy in information present in the latents. The paper demonstrates this in one setting where the transformation is random shuffling of image patches, which should remove the global information of the original input image.\n\nThe methodology of the paper was concise and easy to follow. The simple inductive bias presented in the paper for disentangling local and global information is very interesting. It is not obvious that shuffling image patches at a particular scale would lead to complete loss of global information, but the paper does show results on SVHN and CIFAR10 for which global information is sufficiently disentangled. The results for digit identity clustering were great for showing the correlation between their learnt global information and label information.\n\nThe paper introduced their model as a general purpose strategy for placing desired information in latent variables using auxiliary tasks, but focus was directed to the global vs local line of analysis. While giving examples for what kind of information can be removed, the authors mentioned that color to gray-scale might be one possibility.  It would have been interesting to see this and other possibilities explored in the paper. I feel that the idea deserves a broader analysis beyond just a single choice of disentanglement.\n\nIt is mentioned in the paper that having a single inference network for the posterior as opposed to the factorized one is conceivable. I would be curious to see an analysis of how that works out as compared to the separate encoders case.\n\nOverall, the paper has a novel idea which is well motivated and executed in terms of experiments.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Approach seems limited and the source of improvement is not clear",
            "review": "This work proposes an approach for explicitly placing information in a subset of the latent variables. The approach is to construct an auxiliary generative model that takes as input the set of latent variables subtracted from the target subset, which is used to model modified data samples that do not contain the desired information. \n\nExperiments focus on learning global information. The auxiliary model is then given data that have their global information destroyed via random shuffling of image patches.\n\n# Approach seems limited.\n - This approach seems very limited, as there must exist a known transformation that removes the desired information. Apart from global vs. local, can the authors provide more examples of what sort of information this approach can disentangle? (Even for global vs. local, is there a transformation that can remove local information as opposed to global information?)\n - Can this approach learn multiple factors as opposed to just two? \n - What if the desired factors are not clearly disjoint and collectively exhaustive? (e.g. mustache vs. gender on human faces.)\n\n# More ablations or experiments with comparable settings would be desirable.\n - What is the choice of beta in the beta-VAE training objective? Apart from 1.2, this isn't mentioned. My concern here is that beta might be affecting the result more than the proposed training algorithm. Can the proposed approach perform just as well without a modified objective? Ablation studies that show the proposed algorithm can improve upon the baseline in all settings would make this a stronger paper. (e.g. this approach with normal VAE objective, and normal VAE objective without auxiliary task for the clustering experiment.)\n - Why were 30 discrete categories used in the clustering experiment? Is this still comparable to the approaches that use 10, which would correspond to the number of classes?\n\n# Related work.\nThere are some well-cited works that the authors may have missed. These are ultimately different approaches, but perhaps the authors can obtain some inspiration from these:\n- Tranforming autoencoders [1] also apply a transformation to the image, but the goal is to learn the factor corresponding to the transformation, rather than the complement as in this work.\n- An opposing approach for explicit information placement with a modified training procedure (where the target information is directly placed in the target subset and can handle multiple factors) is DC-IGN [2]. I believe the DC-IGN approach is more general and can handle a superset of the tasks of this approach, without requiring an auxiliary decoder. Comparing to this approach, I wonder if it would be better to provide samples that exhibit a particular factor, or samples that conceal the factor?\n\n[1] Hinton, Geoffrey E., Alex Krizhevsky, and Sida D. Wang. \"Transforming auto-encoders.\" International Conference on Artificial Neural Networks. Springer, Berlin, Heidelberg, 2011.\n[2] Kulkarni, Tejas D., et al. \"Deep convolutional inverse graphics network.\" Advances in neural information processing systems. 2015.\n\n---- Update since rebuttal ----\n\nI thank the authors for clarifying how this work fits in with related works and clarifying the hyperparameters. I maintain my concerns that the experiments are limited and do not showcase the individual benefit of using explicit information placement. More experiments based on different transformations that the authors have mentioned would make this a stronger contribution. The use of beta>1 is fine if it helps alongside the use of this approach, but it would have been better to see the effects of this approach and beta>1 (and other hyperparameters such as k in Table 1) in isolation. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}