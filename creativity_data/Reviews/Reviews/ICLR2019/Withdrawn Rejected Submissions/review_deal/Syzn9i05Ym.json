{
    "Decision": {
        "metareview": "This paper proposes a method for learning neural RFs with the inclusive-divergence minimization problem.\n\nReviewers generally agree that the experiments are sufficient and convincing, and that the method is evaluated well. Results are comparable with SOTA methods for image generation. The paper is reasonably well-written.\n\nThe paper is also somewhat lacking in background; most people at ICLR will not be very familiar with this learning problem. More information on the inclusive-divergence minimization problem would be helpful. A major concern of reviewers is whether novelty of the method is sufficient for publication.\n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Meta-Review"
    },
    "Reviews": [
        {
            "title": "Interesting but incremental",
            "review": "This paper addresses an important problem of learning the random field using neural networks by using a inclusive auxiliary generator. Comparing to existing state-of-the-art methods for learning neural random fields, this paper used a the inclusive-divergence (KL divergence of the density approximate and the auxiliary generator) which avoids the intractable entropy term. SGLD/SGHMC are used to revise samples drawn from the auxiliary generator and these two sampling methods are examined theoretically.  \n\nIn generally, the paper is well motivated and well written. Experiments are sufficient and convincing, especially the synthetic data experiments with GMM distributions. \n\nHowever, I am a little bit concerned that the theoretical contribution seems weak. As discussed in the related work, the idea of using neural network to learn the random field is not new. Using inclusive-divergence is also not new, e.g. Xie et al (2016) and Wang & Ou (2017) already proposed to use the inclusive-divergence. If I understand it correctly, the only contribution here is to apply the SGLD/SGHMC to revise the samples and authors provided some theoretical analysis of SGLD/SGHMC.\n\nThe overall technical quality of the paper is sound but I am not 100% sure about the equations, e.g. the second line in Eq. 4. \n\nIn summary, this paper is well written and authors have done a good job. But I will appreciate if authors can elaborate\nmore on the novelty and innovation of the paper. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "appears effective, though unfamiliar with this type of model",
            "review": "This paper describes a method of training NRFs with auxiliary generator networks, using an error that minimizes KL(NRF || generator).  This formulation enables the use of iterative gradient-based stochastic sampling of image samples from the model distribution using SGLD/SGHMC.  Applications to both unsupervised sample generation and semi-supervised classification are evaluated.\n\nI'm not very familiar with these types of NRFs or random sampling techniques, but the approach appears sound and is evaluated rather well.  I would have liked some more background and explicit description and contrast compared to the explicit NRF.  While this is described already, I think the contrasts could potentially be spelled out even more explicitly, particularly in the descriptions of the sampling algorithms.\n\nThe toy example with mixture of gaussians is convincing showing the contrast in results between the exclusive NRF, inclusive, and sampling gradient revision steps.\n\nExperimental evaluations on MNIST, SVHN and CIFAR show that the system obtains performance similar to SOA generative systems, in both semi-supervised classification and sample generation.\n\n\nQuestions and comments:\n\n- While the paper claims the results show classification and generation performance are complementary, Table 3 appears to validate the opposite claim, that these are to a large degree a trade-off.  The fact that this system performs well at both is good, but to me it looks like it may be on the \"shoulder\" of a frontier curve if one were to plot the classification vs generation performance of the different current systems.\n\n- Table 4 and sec 4.4:  I think these could be clearer.  The first observation states that revision improves IS.  But using more iterations (increasing L) does not appear to increase IS.  There does appear to be a consistent increase from the first column (generation) to second (revision), though -- is this what this observation refers to?  In addition, I'm not entirely clear what the \"Generation IS\" vs \"Revision IS\" column refers to --- I believe \"generation\" is the initial sampling of x=g(h) (i.e. h followed by q(x | h)), and \"revision\" is the application of gradient revision.  But then how does the generation IS results change from row to row (which only modify the revision step)?\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Incremental Contribution",
            "review": "The paper proposes the inclusive neural random field model. Compared the existing work, the model is different because of the use of the inclusive-divergence minimization for the generative model and the use of stochastic gradient Langevin dynamics (SGLD) and stochastic gradient Hamiltonian Monte Carlo  (SGHMC) for sampling. Experimental results are reported for unsupervised, semi-supervised, and supervised learning problems on both synthetic and real-world datasets. Specific comments follow:\n\n1. A major concern of the reviewer is that, given the related work mentioned in Section 3, whether the proposed method exerts substantial enough contribution to be published at ICLR. The proposed method seems like an incremental extension of existing works.\n\n2. A major claim by the authors is that the proposed techniques can help explore various modes in the distribution. However, this claim can only seem easily substantiated by experiments on synthetic data. It is unclear whether this claim is true in principle or in reality.\n\nOther points:\n3. the experimental results of the proposed method seems marginally better or comparable to existing methods, which call in question the necessity of the proposed method.\n\n4. more introduction to the formulation of the inclusive-divergence minimization problem could be helpful. The presentation should be self-contained.\n\n5. what makes some of the statistics in the tables unobtainable or unreported?\n\n\n============= After Reading Response from Authors ====================\n\nThe reviewer would like to thank the authors for their response. However, the reviewer is not convinced by the authors’ argument. \n\n“The target NRF model, the generator and the sampler are all different.”\nIt is understandable that modeling continuous data can be substantially different from modeling discrete data. Therefore, it is non-surprising that the problem formulations are different.\n\nAs for SGLD/SGHMC and the corresponding asymptotic theoretical guarantees, this reviewer agrees with reviewer 2’s perspective that it is a contribution made by this paper. But this reviewer is not sure whether such a contribution is substantial enough to motivate acceptance.\n\nThe explanation for better mode exploration of the proposed method given by the authors are the sentences from the original paper. The reviewer is aware of this part of the paper but unconvinced.\n\nIn terms of experiments, sample generation quality seems to be marginally better. Performances in multiple learning settings are comparable to existing methods.\n\nA general advice on future revision of this paper is to be more focus, concrete, and elaborative about the major contribution of the paper. The current paper aims at claiming many contributions under many settings. But the reviewer did not find any of them substantial enough.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}