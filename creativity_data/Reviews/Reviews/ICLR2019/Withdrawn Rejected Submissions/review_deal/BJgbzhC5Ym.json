{
    "Decision": {
        "metareview": "This paper proposes a principled solution to the problem of joint source-channel coding. The reviewers find the perspectives put forward in the paper refreshing and that the paper is well written. The background and motivation is explained really well.\n\nHowever, reviewers found the paper limited in terms of modeling choices and evaluation methodology. One major flaw is that the experiments are limited to unrealistic datasets, and does not evaluate the method on a realistic benchmarks. It is also questioned whether the error-correcting aspect is practically relevant.\n\n\n ",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Meta-Review"
    },
    "Reviews": [
        {
            "title": "Interesting, yet limited paper",
            "review": "The authors set out to tackle an old problem (joint source-channel coding) with a principled approach and a fresh perspective. However, I find the paper quite limited both in terms of modeling choices as well as evaluation methodology. Specifically:\n\n- The mutual information maximization approach is appropriate, but hardly novel. Besides being highly related to ELBO maximization, there have been several recent papers on rate-distortion optimization, as well as on deriving variational bounds for MI (see, for instance, Alemi et al.).\n\n- The experimental setup is somewhat niche: in the context of image compression, both the fixed-rate constraint as well as the use of a binary symmetric channel are unusual. The vast majority of image compression methods are variable-rate, and for good reason: generic images tend to carry vastly different amounts of self-information, such that a fixed-rate code is almost guaranteed to achieve suboptimal *average* performance in terms of rate-distortion. Additionally, the vast majority of images today are sent over channels that already perform error correction, such as packet-switched networks (e.g., the Internet) or digital storage media, so that it's unclear why this particular case of joint source-channel coding would be practically relevant.\n\n- I find the claim that the model is \"competitive against industry standard compression\" hardly justified based on the presented data. First, JPEG is now almost 40 years old. Since its inception, newer industry standards have exceeded it multiple times over in terms of rate-distortion performance. Second, JPEG was designed as a compression method for generic images. Comparing its performance on Omniglot and CelebA datasets is unfair, because the presented model can be trained to exploit special probabilistic structure in these datasets, while JPEG cannot. A widely used and accessible dataset better suited to compare against exisiting image compression methods would be the Kodak set, for example. And third, as explained above, JPEG is a variable-rate compression algorithm. How exactly were the number of bits required for JPEG to achieve the same distortion as NECST computed? To produce the plot in Figure 1, did the authors first compute an average rate for each average distortion, or was the computation done for each individual image, and then averaged to produce Figure 1 in a second step? This distinction could make a big difference.\n\n- Regarding Sections 5.3 and 5.4: Could the authors please justify why they just double the length of the VAE representation? Wouldn't it be fairer towards LDPC to compare NECST to a VAE+LDPC code with various amounts of redundancy? Similarly, could the authors please justify comparing runtime only against a fixed 50 iterations of LDPC, rather than comparing against a range of possible values to make sure they are giving LDPC the benefit of the doubt?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "review": "Summary of paper: For the finite-bit case of the noisy communication channel model, it is suboptimal to optimize source coding (compression of input) and error correction (fault tolerance for inherent noise in the channel) separately. The authors propose a neural network model (NECST) that is very similar to the standard VAE, except using binary latents with corruption (e.g.,  random bit flipping in the style of a binary symmetric channel). They use VIMCO to optimize through the discrete units. In their experiments, they show that they can outperform a JPEG+ideal channel code model, but perform similarly to a VAE+LDPC (LDPC is a classic error correcting code) setup.\n\nFirst of all, the paper is quite well written and easily readable. Great work on explaining the motivation and the model -- the writing is clear and explains background knowledge extremely well.\n\nThe main contribution in the model is the use of discrete binary latents, instead of the standard continuous latents in a VAE. However, I am uncertain about the novelty of this contribution. There have been numerous works examining discrete latent variables in autoencoders (a random sampling: [1, 2, 3, 4]) and beyond. Furthermore, the method of training through discrete latents is also standard (VIMCO, though one can also imagine using more recent advances like REBAR or RELAX). The only difference would be the addition of noise to the discrete. I would be curious to see how that compares to recent works that have also added noise to discrete latents [5].\n\nThus, it strikes me that the main contribution of this work would be in comparing against the current best techniques for coding. However, the experiments section is weak, and does not provide significant evidence that the NECST model is better than the alternatives. NECST outperforms JPEG+ideal channel coding, but doesn't do much better than a VAE+LDPC baseline. This suggests that most of the gains comes from the encoder (source coding) model q(\\hat{y} | x), instead of the joint training of source coding and error correcting code. It is not surprising that using a neural network to generate codes would provide significant gains. It's not clear that error correcting code aspect (noise in the latents) is particularly important.\n\nFurthermore, in the classification results, the MLP model trained on the discrete codes gets 93% accuracy on noiseless MNIST inputs. You can easily get this accuracy by training logistic regression directly on the pixels. Despite what the authors write, this result suggests that the codes are not very useful for downstream learning. Furthermore, it is unclear why adding random noise to the inputs would significantly improve some of the weaker classifiers. The only reason I can think of is data augmentation, but this has nothing to do with the NECST model.\n\nIn conclusion, this is a well written paper, but the novelty is not apparent and the experimental results are weak, and so I am not convinced this is suitable for ICLR.\n\nAdditional Questions:\n* How is the runtime computed? Specifically, for NECST, do you batch the data and then divide the forward pass time by the batch size? If this is how runtime is computed, it's not surprising that NECST does better, given that batching is cheap with modern hardware. If the actual forward pass time for a single example is cheaper than that of LDPC's belief propagation, then that would be quite promising.\n* The authors state that VAEs optimize a lower bound on the marginal log-likelihood p(X), whereas NECST optimizes a lower bound on the mutual information I(X, Y), where Y is the noised code. The authors however do not discuss why one should optimize for mutual information compared to marginal log-likelihood. What are the advantages and disadvantages between the two?\n\n[1] Semi-Supervised Learning with Deep Generative Models (https://arxiv.org/abs/1406.5298)\n[2] Discrete Variational Autoencoders (https://arxiv.org/abs/1609.02200) \n[3] Neural Discrete Representation Learning (https://arxiv.org/abs/1711.00937)\n[4] Discrete Autoencoders for Sequence Models  (https://arxiv.org/abs/1801.09797)\n[5] Theory and Experiments on Vector Quantized Autoencoders (https://arxiv.org/pdf/1805.11063.pdf)",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good paper, well written and well motivated, good results, no-source code!",
            "review": "This interesting paper tackles the problem of joint source-channel coding, by means of learning.\n\nFrom 100kft heights, especially given the choice of VIMCO gradient estimates, this is effectively a \"let's embed a source-channel-decoder simulator and differentiate through it\", and find a solution that is better than source|channel factorized classic methods, or hand-tuned approaches.\n\nThe method and results are good. The authors also show some interesting results about the representations learned, about how decoded samples (images) change smoothly when the (discrete) embedding (the-codes) changes over deltas of hamming_d()=1bit. This is very good results IHMO. One limitation of this method is the fixed-code-length.\n\nJumping straight to my main main issue with this paper: no code was made available, at least not at this time.\n\nWhile the authors do provide an extensive appendix with hyper-parameter specs, usually in my experience when dealing with discrete / monte-carlo methods, it's usually rather hard to reproduce results. I really strongly advise the authors to provide fully reproducible code for this paper, to help further research on this topic.\n\nBesides that I have three technical comments / request regarding this paper:\n\n1// the choice of BSC channel - while this is the easiest most natural choice, and we should certainly have results on BSC, I am left wondering why the authors didn't try other more complex / more realistic channels? The authors only mention this as potential area of future research in the last sentence of the conclusions. \n\nThere are several reasons for this comment: first of all, it is well known that even classic joint source-channel coding methods do shine on complex channels, such fading/erasure channels and/or in general channels with correlated error sequences. Such channels are indeed key in modern wireless communications, and are easy to simulate. Given that more-complex channels could be introduced in the channel model p(y_hat|y) -  it would not change the rest of the method - it would be particularly interesting to see what results this method achieve in these more complex environments.\n\n2// I would like to hear more about the choice of VIMCO. Understood the authors statement to \"preserve the hard discreteness\" ~ that said methods like Gumbel-SM and several others also referenced in the paper ~ have been used  successfully to solve for propagating gradients through discrete units. This is where, in my opinion, experiments comparing VIMCO approximation results to at least one other method could allow to decide / validate the best architecture. \n\nThis is also because, in my previous experience, this type of networks with discrete units may be hard to train. I would like to hear from the authors about how stable the training was under different hyper-parameters, and perhaps see some convergence curves for the loss function(s).\n\n3// it's not 100% clear to me where the limitation of fixed code-length come into play from the architecture. Could the authors please point this out clearly?\n\nThank you!\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}