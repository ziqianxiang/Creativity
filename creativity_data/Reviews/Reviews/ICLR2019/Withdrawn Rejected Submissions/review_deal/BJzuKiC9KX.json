{
    "Decision": {
        "metareview": "The paper presents a well conducted empirical study of the Reweighted Wake Sleep (RWS) algorithm (Bornschein and Bengio, 2015). It shows that it performs consistently better than alternatives such as Importance Weighted Autoencoder (IWAE) for the hard problem of learning deep generative models with discrete latent variables acting as a stochastic control flow. \nThe work is well-written and extracts valuable insights supported by empirical observations: in particular the fact that increasing the number of particles improves learning in RWS but hurts in IWAE, and the fact that RWS can also be successfully applied to continuous variables.\nThe reviewers and AC note the following weaknesses of the work as it currently stands:  a) it is almost exclusively empirical and while reasonable explanations are argued, it does not provide a formal theoretical analysis justifying the observed behaviour b) experiments are limited to MNIST and synthetic data, confirmation of the findings on larger-scale real-world data and model would provide a more complete and convincing evidence. \nThe paper should be made stronger on at least one (and ideally both) of these accounts.\n\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting empirical observations of the advantage of RWS, but lacking formal theoretical analysis, and larger scale experiments"
    },
    "Reviews": [
        {
            "title": "Nice experimental discoveries",
            "review": "This paper conducts an extensive set of experiments on RWS and compares it against a set of benchmarks such as GMM and IWAE. The main contribution of the paper is the fact revealed by these experiments, that RWS learns better models and inference networks with increasing numbers of particles, and that its benefits extend to continuous latent variable models as well. The performance of RWS will increase significantly if we increase the number of particles. \n\nThe experimental part is written in an inspiring way, and I enjoyed reading it. However, there should be stronger baselines incorporated. for example, https://arxiv.org/abs/1805.07445. Also, I think the authors could try to emphasize more on the shortcomings of RWS discovered by the GMM experiments, and how defensive importance sampling fixes it. There are several other parts in the paper that indicates interesting facts, diving deeper into it could possibly lead to more interesting findings.\n\nIn all, I would consider these comparison results important to be somewhere in the literature, but because its lack of rigorous analysis and explanation for the observations, I personally think these observations alone are not novel enough to be an ICLR paper. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Revisiting Reweighted Wake-Sleep",
            "review": "This manuscript investigates the performance of Reweighted Wake-Sleep (RWS) framework for learning deep generative models with discrete latent variables. It gives a clear introduction to variational autoencoder based models for scenarios with discrete latent variables, including IWAE and also models based on continuous relaxations of discrete variables. The paper performs several experiments, which suggest that RWS is more appropriate for discrete latent variables than other methods such as IWAE. Especially, increasing the number of particles, unlike IWAE, always enhances the performance of RWS.\n\nWhile this paper investigates an important problem, and also offers interesting observations, it lacks a rigorous analysis of why the RWS performance is consistently better than IWAE. More precisely, the propositions should be stated in more formal language and they should be accompanied with a minimal rigorous justification.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An interesting experimental paper but more insights are expected",
            "review": "Main idea:\nThis paper studies a problem of the importance weighted autoencoder (IWAE) pointed out by  Rainforth 18, that is, tighter lower bounds arising from increasing the number of particles improve the learning of the generative model, but worsen the learning of the inference network. The authors show that the reweighted wake-sleep algorithm (RWS) doesn't suffer from this issue. Moreover, as an alternative to control variate scheme and reparameterization trick, RWS doesn't suffer from high variance gradients, thus it is particularly useful for discrete latent variable models.   \nTo support the claim, they conduct three experiments: 1) on ATTEND, INFER, REPEAT, a generative model with both discrete and continuous latent variables; 2) on MNIST with a continuous latent variable model; 3) on a synthetic GMM.\n\nClarity issues:\n1. \"branching\" has been used many times, but AFAIK, this seems not a standard terminology. What do \"branching on the samples\", \"conditional branching\", \"branching paths\" mean?\n2. zero-forcing failure mode and delta-WW: I find this part difficult to follow. For example, the following sentence \n\"the inference network q(z|x) becomes the posterior for this model which, in this model, also has support at most {0, . . . , 9} for all x\". \nHowever, this failure mode seems an interesting finding, and since delta-WW outperforms other methods, it deserves a better introduction. \n\nQuestions:\n1. In Fig 1 (right), how do you estimate KL(q(z|x) || p(z|x))?\n2. In Sec 4.2, why do you say IWAE learns a better model only up to a point (K = 128) and suffers from diminishing returns afterwards?  \n3. In Fig 4, why WS doesn't achieve a better performance when K increasing?\n\nExperiments:\n1. Since the motivating story is about discrete latent variable models, better baselines should be compared, e.g. RBM, DVAE, DVAE++, VQ-VAE etc. \n2. All experiments were on either on MNIST or synthetic data, at least one large scale experiment on discrete data should be made to verify the performance of RWS. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}