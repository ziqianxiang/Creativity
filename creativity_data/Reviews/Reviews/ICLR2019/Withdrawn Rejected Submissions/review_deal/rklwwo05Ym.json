{
    "Decision": {
        "metareview": "The paper tried to introduce a new interpretation of dropout and come with improved algorithms. However, the reviewers were not convinced that the presented arguments were correct/novel, and they found the paper difficult to follow. The authors are encouraged to carefully revise their paper to address these concerns. ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "New perspectives on dropout but unconvincing arguments"
    },
    "Reviews": [
        {
            "title": "A special interpretation of Dropout. Unfortunately, not convincing.",
            "review": "Different from an existing variational dropout method which used variational inference to explain Dropout, this paper proposes to interpret Dropout from the MAP perspective. More specifically, the authors utilize the Jensen inequality to develop a lower bound for log-posterior, which is used as training objective for dropout. They then exploit the power mean to develop the conditional power mean model family, which provide additional flexibility for evaluation during validation.\nEven though the way how the proposed method is analyzed/generalized is interesting, the proposed method is not convincing, but I am not absolutely sure. Besides the paper is hard to follow, some other concerns are listed below.\n(1) “…the original/usual dropout objective” and “the dropout rate” are not defined in the paper, even though they appear many times in the paper.\n(2) In the last paragraph of Sec. 2, the authors argue that utilizing their MAP objective “sidestep any questions about whether variational inference makes sense.” However, the presented MAP lower bound has its own problem, since it is derived using the Jensen inequality.  For example, as shown in Appendix C, the equality becomes true only when p(w|\\Theta) is a delta function.\n(3) How to tune the hyperparameters (alpha, lambda) of the extended dropout family in practice?\n(4) The current experiments might be weak. Additional experiments on popular image datasets are recommended.\n\nMinors:\n(1) In Eq. (3), is p(w_r|\\Theta) of the second formula identical to p(w|\\Theta) of the third formula?\n(2) In the second row below Eq. (6), E_w p(w|\\Theta) p(y|x,w) is a typo.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting paper but still lack of novelty",
            "review": "The paper point that the dropout in training is equivalent to MAP estimate of hierarchical models when the prior distribution of weights, \\Theta, is a zero mean Gaussian. Based on that observation the authors propose several different evaluation methods for dropout. The experimental results show that the proposed evaluation methods improved the performance of language models.\n\nAre there any experimental results of the proposed evaluation methods for another type of data beyond language modeling?\n\nDo the term \"deterministic dropout\" in the last sentence of the first paragraph on page 1 and the one in Sec 3 (the first bullet) refer to the same thing? \n\nMinor: gaussian -> Gaussian",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Try to provide new perspectives on the problem. But they are not sound. No convincing approach. ",
            "review": "This paper studies the problem of making predictions with a model trained using dropout. Authors try to provide a theoretical foundation for using dropout when making predictions. For this purpose, they show that when using dropout training we are maximizing a common lower bound on the objectives of a family of models, including most of the previously used methods for prediction with dropout. \n\nI find that the paper addresses a relevant problem and try to apply a novel approach. But, in general, I find the paper is not easy to follow and to grasp the main ideas. \n\nHere I detail my main concerns:\n\n\n1. This is one of my main concerns. The contraposition between the geometric and the average model. I don't like this contraposition. The average model is just the standard marginalization operation over the weights, $p(y|x) = \\int p(y|x,w)p(w|\\Theta)dw$. This is the natural solution for the prediction problem to the problem if we accept the generative model given in Eq (3). \n\nIn the case of the variational dropout, we depart from the same generative model, but we employ an approximation. It is the variational approximation the one that induces the geometric mean provided in eq (6). I.e. if we want to compute the posterior over the label y* for a sample x*, after training, we should compute the associated lower bound\n$\\ln p(y*|x*) >= E_q[\\ln p(y*|x*,w)] - KL(q|p)$\nIn this case, q(w) = p(w|\\Theta), as stated Eq (3) and in the corresponding equation provided in page 2 (the q(w) is not learnt because it only depends on the dropout rate, while the $\\Theta$ are learnt by maximum log-likelihood and do not have a $q$ associated).  This gives rise to the geometric mean approximation provided in Eq (6).  I.e. the geometric mean prediction is simply the result of using a variational approximation at prediction time.   \n\nMy problem here is that authors employ convoluted arguments to introduce this geometric mean prediction and the average prediction, without making the connection discussed above. \n\n3. Section 3.3 and 3.4 introduces new arguments for modifying the dropout rate (and the alpha) parameter at test time. But, again, I find the arguments convoluted. We consider the dropout rate a hyper-parameter of the model, the standard learning theory tells us to fix the parameters with the training data and evaluate them later when making predictions. Why should we use different dropout rates at training and testing? Authors arguments about the tightness of the bound of Eq (8) and Eq(9). are not convincing to me. \n\nSo, I don't find authors provide convincing answers to the raised questions at the beginning of the paper about the use of dropout when making predictions. \n\nMinor comments:\n\n1. The generative model for Variational dropout is the same than the generative model for the \"conditional model\", eq. (3). \n\n2. In Eq. (7) authors are defining the weighted power mean. I think it would be clearer to directly introduce the weighted power mean instead of the standard power mean in Section 3.2.\n\n3. Section 3.3. I find some parts are difficult to understand. \"suppose we pick a base model from the power mean family and have a continuum of subvariants with gradually reduced variance in their predictions but the same expectation.\" Later, I can understand authors are referring to the possibility of reducing the dropout rate. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}