{
    "Decision": {
        "metareview": "All reviewers recommended rejecting this submission so I will as well. However, I do not believe it is fundamentally misguided or anything of that nature.\n\nUnfortunately, reviewers did not participate as much in discussions with the authors as I believe they should. However, this paper concerns a relatively niche problem of modest interest to the ICLR community. I believe a stronger version of this work would be a more application-focused paper that delved into practical details about a specific case study where this work provides a clear benefit.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Clear reviewer consensus to reject"
    },
    "Reviews": [
        {
            "title": "Important topic but significance can be improved",
            "review": "The study of detecting malicious edges in graphs is interesting and important.  However, the significance of the paper can be improved.  To properly test the detection performance, I recommend that the authors run experiments on various random graph models. Examples of random graph models include Erdos-Renyi, Stochastic Kronecker Graph, Configuration Model with power-law degree distribution, Barabasi-Albert, Watts-Strogatz, Hyperbolic Graphs, Block Two-level Erdos-Renyi, Multiplicative Attribute Graph Model, etc. That way we can learn on what types of networks the detection performance is better.  Also, in terms of detection models, I recommend that the authors try approaches that look for goodness of fit and model selection (e.g., see https://arxiv.org/pdf/1806.11220.pdf).",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "This manuscript tackles the interesting problem, but more improvement seems necessary in various aspects.",
            "review": "The authors address the interesting problem about the attack on the graph convolutional network model. The proposed method is developed under the assumptions about the attacking models sound simple but reasonable with proper references.  \n\nHowever, the proposed approaches mostly include the ideas about the detecting mechanisms instead of being formulated in some novel form. Given that the proposed algorithms do not leverage the underlying model structure very much, why the proposed algorithms are special to the graphical neural network is not very clear.\n\nAlso, the evaluations need to be further improved. It seems that victim nodes are carefully selected and fixed throughout all the experiments, but it limits the generalization about the performance of the proposed algorithms. Particularly, since the different detection algorithms perform differently on different datasets, more extensive evaluations are required along with the guideline of what detection algorithm we have to choose for the unsupervised setting.\n\n*Details\n- It will be great if the authors clearly describe what the proposed methods aim to defend. Basically, the values by protecting some victim nodes, regardless of what attacking models are assumed, will help the audience with better understanding. Some of content in Section 2.2 can be brought up in the introduction.\n- In Section 3.1 and some other subsections, it seems to assume that the links in a given network are very clean but in reality there are a lot of noisy connections. How can we distinguish some random connections from malicious connections? Evaluation along with this question will be also useful.\n- In Section 3.2, eventually, the ratio of malicious edges remains the same if the authors use random sampling. In that case, how SubGraphLinkPred helps is not very convincing.\n- The detection algorithm seems to exist to detect malicious edges without supervision. In that case, how can we determine which method we should use given that detection performance differs in different dataset?\n- It would be useful to compare with some existing malicious node/graph pattern mining algorithms such as Graph-Based Fraud Detection in the Face of Camouflage, Hooi et. al. even if the baseline method does not aim to directly solve the addressed problem. And also that literature needs to be cited.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "First step on an important problem but hard to tell if its generally useful.",
            "review": "In this paper the authors present 4 methods for detecting outlier edges and nodes in graphs so as to prevent adversarial attacks on graph convolutional networks.  They demonstrate that their methods are accurate (through high AUC) in detecting edges added by two previous adversarial detection methods.\n\nI think focusing on not just attacking GCNs but actually preventing them is awesome, and work of this sort should be highly lauded as I believe prevention is more difficult than attacks.  That said, it is hard to tell how general this work is.  The methods discussed follow fairly standard anomaly detection procedures (albeit with NN based models).  However, this leaves a few key open questions: \n\n(1) To what degree do these methods address the particulars of GCN attacks?  This could possibly be addressed by better recapping the GCN attacks and explaining how these methods directly relate to those attacks.\n\n(2) How robust are these methods?  While the intuition behind the methods at a high level seems reasonable, it is unclear if they provide any real robustness to an adversary.  Could the previous attacks be adapted if these detection mechanisms were known?  For example, I expect that adding edges that are high likelihood and maximally change the victim label would be an effective deception technique.  I believe a more thorough theoretical understanding of the robustness of the protection would make me more confident that these are broadly useful.  As of now, it seems very much data dependent.\n\n\nDetails:\n\nGraphGen is worded weirdly -- you're not generating graphs, you're building a generative model for which you evaluate the probability that you would have generated an observed subgraph.\n\nRobust MF has been studied and should be cited as well:\n\nBenjamin Van Roy and Xiang Yan. Manipulation-resistant collaborative filtering systems. In Proceedings of the Third ACM Conference on Recommender Systems, RecSys ’09, pages 165–172, New York, NY, USA, 2009. ACM.\n\nBhaskar Mehta and Wolfgang Nejdl. Unsupervised strategies for shilling detection and robust collaborative filtering. User Model. User-Adapt. Interact., 19(1-2):65–97, 2009.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}