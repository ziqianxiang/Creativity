{
    "Decision": "",
    "Reviews": [
        {
            "title": "[Review] Linearizing Visual Processes with Deep Generative Models",
            "review": "[Paper Summary]\n- The proposed work proposes a new method that model non-linear visual process with a deep version of a linear process (Markov process). The latent space is described by the linear process and the nonlinear mapping function from the latent space to image distribution.\n\n[Pros]\n- The model gives a well defined deep approximation to the Markov process (with Gaussian Form). The reviewer didn't follow every detailed step, but the overall direction seems fair.\n\n[Cons]\n- First of all, the practical strongpoints of the proposed work (applying linear process) compared to the existing deep sequential approaches (using the recurrent network) are not well investigated. The reviewer was difficult to find the benefit of using the proposed algorithm than RNN+VAE such as DRAW [1]. The proposed method can also use GAN for latent-to-image mapping, but using GAN to sequential model itself is not a novel techniques [2]. Maybe the existence of variance would be the difference, then the author should clarify it into the experiment section (more than the current version).\n\n[1] Gregor, Karol, et al. \"Draw: A recurrent neural network for image generation.\" arXiv preprint arXiv:1502.04623 (2015).\n[2] Walker, Jacob, et al. \"The pose knows: Video forecasting by generating pose futures.\" Computer Vision (ICCV), 2017 IEEE International Conference on. IEEE, 2017.\n\n- Related work seems to omit some of the similar existing studies. The author should clarify the novelty of the proposed work from the mentioned papers.\n\n[1] Karl, Maximilian, et al. \"Deep variational bayes filters: Unsupervised learning of state space models from raw data.\" arXiv preprint arXiv:1605.06432 (2016).\n[2] Gao, Yuanjun, et al. \"Linear dynamical neural population models through nonlinear embeddings.\" Advances in neural information processing systems. 2016.\n[3] Yoo, Y., Yun, S., Chang, H. J., Demiris, Y., & Choi, J. Y. (2017, July). Variational autoencoded regression: high dimensional regression of visual data on complex manifold. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 3674-3683).\n\n- The video generation sequence in figure 5 seems little trivial because most parts of the image are static. Is it possible to try the model with more complicated video such as UCF 101 (like [1])?\n\n[1] Walker, Jacob, et al. \"An uncertain future: Forecasting from static images using variational autoencoders.\" European Conference on Computer Vision. Springer, Cham, 2016.\n\n[Summary]\nThe proposed paper provides well described linear model approximated by the deep network.  However, the reviewer is still skeptical for the novelty of the paper, and the strong point of the work compared to the existing deep sequence generation algorithms. The profound explanation of the problems would be required.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "promising direction, but some important math mistakes and no baselines",
            "review": "This paper proposes a new deep generative model for sequences, particularly image sequences and video. By utilizing a linear structure in part of the model, this work aims to offer more efficient sampling, while also aiming for a simpler training procedure.\n\n\nUnfortunately there are some important mistakes in the mathematical justification of the method provided in Section 3. One is the claim that \"Eq. (1) is a special case of Eq. (2) ...\" and later \"The model Eq. (2) describes a much broader class of visual processes than Eq. (1).\" A counterexample is to take n=2, d=1, and\n\nA = [[ cos(\\pi/4) -sin(\\pi/4) ]\n     [ sin(\\pi/4)  cos(\\pi/4) ]]\nC = [[ 1 0 ]]\n\\bar{y} = 0\n\nSince C^+ is [[ 1 ] [ 0 ]], the provided formula does not recover the periodic dynamics of Eq. (1) and is instead just a mean-reverting random walk. To make the counterexample more extreme, we can take n=1000 and d=1 with an A matrix that exhibits 500 distinct frequencies (with eigenvalues in complex conjugate pairs) and with C = [[ 1 1 ... 1 ]], then clearly in Eq. (1) the dynamical behavior is a sum of 500 oscillators, which can't be recovered by Eq. (2) (in which y_{t+1} depends only on y_{t}). More precisely, with d=1 Eq. (1) can represent a stationary process with any rational power spectral density (up to the right degree, depending on n) but Eq. (2), being first-order Markov on the observation sequence (stated as Assumption 1) can't. (It's incorrectly implied near the bottom of p. 2 that processes following the dynamics of Eq. (1) are first-order Markov on the y sequence, but they're not; that's the purpose of having a latent state.)\n\nThere are some other issues in Section 3 that are not mistakes but are unclear. It's inaccurate to describe C as a diffeomorphism (just before Sec 3.2) and \\Gamma : R^d \\to R^n as a diffeomorphism, since diffeomorphisms must be invertible and here n < d, though it's clear from context that you mean their appropriate restrictions are diffeomorphisms. Remark 1 states the process noise must have covariance I - AA' without stating that, in addition to choosing a basis for the latent space in which states have a marginal standard Gaussian distribution, it must be chosen so that I - AA' is positive definite. The initial state distribution is not taken to be the stationary distribution of the latent state dynamics, yet a basis can only be chosen to satisfy Assumption 2 in stationarity. Some of the mathematics in Section 3.2 is unnecessary; \\Gamma essentially serves as a coordinate chart, and notions of fixed points on manifolds (as in Proposition 1) is textbook stuff.\n\nIn the description of the learning procedure, no overall objective is specified, and the treatment of the constraint in Eq. (15) is weak (a squared Frobenius penalty is simply added into the objective).\n\nOne consequence of these correctness and clarity issues is that it's hard to understand how to relate this work to other ideas. In addition to having a general related works section, this paper should contrast the proposed model and fitting procedure with others. For example, how does this compare to fitting a nonlinear AR(1) model? Or an autoregressive model for p(y_{t+1} | y_t, ..., y_1) parameterized by an RNN? Or any of the various latent variable generative models for videos based on VAE architectures?\n\n\nThe other main issue with the current paper is a lack of baselines. As far as I can tell, there are no baselines of comparison in the experiments section. One clear baseline would be a nonlinear AR(1) model parameterizing p(h_{t+1} | h_t) directly, perhaps as a Gaussian with mean and variance that depend on h_t through a neural network. But there are lots of video models at this point, of both the autoregressive and latent variable flavor, and this paper must include some comparisons. Moreover, the modeling tasks considered here seem nonstandard.\n\nTo make up for the clarity and correctness issues with the mathematical justification of the approach in the paper as currently written, the results would have to be especially impressive compared to strong baselines, but the experiments section does not give enough information to make that evaluation.\n\n\nOverall, there are some interesting ideas here but the paper needs more work to polish the mathematics and to produce convincing experiments.\n\n\nSome minor suggestions:\n * It's confusing to write \"linear, Gaussian models of observed sequences\" in the abstract, since the models are not (completely) linear and the resulting distribution on observations is not Gaussian.\n * Since the model in Eq. (3) is one of those considered in the SVAE paper (namely in Sec 2.2 of the SVAE paper), and probably also in earlier works, it's worth citing some related work around Eq. (3).\n * It might be interesting to draw a comparison to subspace identification methods like 4SID, as described in \"Subspace Identification for Linear Systems\" by van Overschee and de Moor, or spectral methods for HMMs, as in \"A Spectral Algorithm for learning Hidden Markov Models\" by Hsu, Kakade, and Zhang.\n * It might be helpful to rename \"MAR\" to \"VAR\" for \"vector autoregressive\", since \"MA\" often stands for \"moving average\" in the context of VARMA models.\n * Writing \"due to the curse of dimensionality\" in Sec 3.2 is vague; what do you mean there?",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A nice idea and model with really lacking experimental validation",
            "review": "Quick summary:\n\nThe author investigate if we can learn a linearized state space model using deep generative models to guide and transform non-linear dynamic observations into linear state space processes. A quick analysis of the feasibilty of the model and its relation to existing models is provided. Experimental results include a GAN and a VAE as the generative model on a few datasets.\n\nPros:\n\n  - The model is interesting and the motivation is quite clear\n  - analysis is quite nice\n  - writing is quite clear and decent\n\nCons:\n\n - Extremely lacking experimental validation - there are literally no baseline models, no numbers or any kind of quantitative analysis. The figures show samples from the model with very little explanation or discussion and it's entirely unclear what we learn from this model. Scientifically speaking, this is not up to par.\n\nBottom line - I think this is a good start for a paper about an interesting model, but I don't feel that this teaches us anything about what the model learns and how it relates in practice to other models.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}