{
    "Decision": "",
    "Reviews": [
        {
            "title": "An interesting, in-depth study but lacks summary and clarity",
            "review": "The empirical evaluation of models is an important part of scientific research, and I am glad to see work in this vein. The authors clearly put a significant amount of effort into the ablation study of these common sequence architectures, and there is a lot to look at and think about here. What are the key takeaways from this ablation study? Are there any concrete recommendations the authors can make, or possible directions of further exploration?\n\nThe current paper is dense, and on reading all the details it is still difficult to find a key takeaway, or set of recommendations that might be useful in other work. Adding this kind of high level overview or synopsis would strengthen the paper. A more in-depth discussion of some of these architecture changes, and why they might be theoretically unsound (sigmoid RNN issues, for example) would be also useful alongside the ablation study. Some of ablations performed seem like methods that *shouldn't* work well, and a description of why they don't make sense would help (alongside the bad performance numbers). For discussing if HMMs really are just RNNs, a clear mathematical description of the type of HMM, its factorization, and relationship the RNN factorization would be needed. This discussion seems to be present in the paper to some extent, but stating it clearly and directly in a concrete section would be beneficial - as it stands now it is spread over several sections and derivations.\n\nThe concluding sentence \"We also find that HMM outperforms other RNNs variants in a next POS tag prediction task, which demonstrates the advantages of models with discrete bottlenecks in increased interpretability\" seems unclear to me - how does performance in prediction show anything directly about interpretability? Exploring the interpretability aspect would be interesting, but as it stands I don't see the connection between the POS performance and interpretability. In addition, POS tagging is an extremely common task, and seeing more references to recently related work in NLP would be useful, alongside past papers using HMMs for this. Given the discussion of Viterbi decoding, it may also be relevant to have discussion or pointers to beam search in RNNs, and the importance of this technique. A recent paper describing beam search (A Stable and Effective Learning Strategy for Trainable Greedy Decoding), with a number of \"backward references\" to related work is linked below.\n\nOn LSTM performance on language modeling in particular, I think it is important that it be stated or shown that LSTM can do much better on this task. See for example the papers linked below. While the paper focuses on ablation and understanding, which is nice, it is also important to show the peak performance that can be achieved, especially when there are several papers showing that a \"base\" LSTM can outperform more intricate models.\n\nRNNss have also been analyzed from the interpretability angle, and maybe some of these can inspire further looks at HMM interpretability in direct comparison to RNNs. There have also been extensive studies on HMM interpretability in the past, and some in relation to RNN as well, a few links are provided below. If the interpretability angle is to be highlighted, it should probably reference other work on this topic and have a stronger focus in the paper. If it isn't a focus, then it probably shouldn't be discussed in the conclusion.\n\nThe question posed by the abstract \"Do these observations suggest that, despite their many apparent differences, HMMs are a special case of RNNs?\" isn't directly answered anywhere in the text. This was discussed above, but worth highlighting in particular here since a question/hypothesis posed in the abstract should probably have a direct answer in the text, and likely re-summarized in the conclusion. In addition, the title of the paper and the direct \"hypothesis question\" seem at different with each other - is the primary contribution in answering this question, or in deriving the \"bridge\" in a clear way? Doing the latter seems to answer the former to some extent, but a more direct unification and direct answer to these would clarify the paper.\n\nThis is interesting work overall, with a lot to digest. My primary concerns are a larger relation to past related work for unfamiliar readers, comparison to modern work (or any work outside this paper itself) in the results tables, and a focus on clarifying the take home message of the paper. Is it interpretability? Is it the bridging of HMMs and RNNs through the derivation (this is something I have not seen directly until now)? Are HMMs really just RNNs? What are the reasons to choose one over the other? What is the driving motivation for the work, and what things were learned by this empirical exploration?\n\nOn the State of the Art of Evaluation in Neural Language Models https://arxiv.org/abs/1707.05589\nRegularizing and Optimizing LSTM Language Models https://arxiv.org/abs/1708.02182\nAn Analysis of Neural Language Modeling at Multiple Scales https://arxiv.org/abs/1803.08240\nA Stable and Effective Learning Strategy for Trainable Greedy Decoding https://arxiv.org/abs/1804.07915\nLSTMVis http://lstm.seas.harvard.edu/\nVisualizing and Understanding Recurrent Neural Networks https://arxiv.org/abs/1506.02078\nIncreasing the Interpretability of Recurrent Neural Networks Using Hidden Markov Models https://arxiv.org/abs/1611.05934\nBeyond Sparsity: Tree Regularization of Deep Models for Interpretability https://arxiv.org/abs/1711.06178\nA Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition https://www.robots.ox.ac.uk/~vgg/rg/papers/hmm.pdf",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "questionable necessity/importance of establishing explicit connections between HMMs and RNNs ",
            "review": "The paper studies explicit connections between HMMs and RNNs by architecturally transforming an HMM to an RNN and vice versa. This gives a spectrum of architectures between HMMs and RNNs (Figure 1). The paper also proposes to build on the tutorial paper of Eisner (2016) by establishing connections between forward probabilities under HMMs with quantities in the RNN cell.\n\nThe main problem with the work is unfortunately its direction. It's not clear why these architectural connections between two particular models are significant. The aspects of these connections (e.g., independence) are not unknown and do not seem to add significant insights (other than what components of RNNs are responsible for how much performance gain). \n\nIt's possible that this architectural analysis for its own sake is of interest to others, so I'll not put confidence on my review. ",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "review of the paper",
            "review": "This paper discusses the connections between HMMs and RNNs and investigates a number of architectural transformations between the two for the expressivity and interpretability.  Overall, the paper is well-written and the logic is clear.  However, I have following concerns.\n\n1.  The HMMs discussed in the paper, in my opinion, are only a subset of the HMM family.  First of all, it only covers the HMMs with a discrete emission state distribution which is commonly used in NLP, but not popular in speech recognition.  Speech recognition, which is dominantly based on HMMs, uses continuous emission state distributions such as Gaussian distributions or Gaussian mixture distributions, which is not addressed in the framework investigated in this paper.  Actually starting from the fundamentals, the authors phrase the framework as \"word prediction\",\"word distribution\" and \"word probability\", which all hints that the HMM-RNN discussion is implicitly carried out in the NLP domain.   Therefore, I would suggest the authors make it clear in the title to point it out that this discussion is about HMMs with discrete emission state distributions. \n\n2. A follow-up comment on HMMs.  I think some of the architecturally transformed HMMs, which are considered to be some special form of RNNs, are actually still within the HMM family.  The difference is that they are not homogeneous HMMs any more. Their state transitions are not fixed and state emission distributions can also be time variant. These heterogeneous HMMs are still HMMs, although they possess some characteristics of RNNs.  Again,  the assumption on HMMs in this paper is too limited to begin with as HMMs consist of a broad family of models. \n\n3. I also have concerns with the experiments.  The PTB baseline seems a bit high to me.  I will feel more comfortable if a single-layer LSTM LM can have a perplexity around 70. Note that this is not even state of the art.   Overall, I find the experimental justification is not overwhelmingly strong. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}