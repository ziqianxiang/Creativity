{
    "Decision": "",
    "Reviews": [
        {
            "title": "Interesting \"fix\" to Godard et al 2017",
            "review": "Summary: This work is closely based on Godard et al 2017. The latter work does not handle occlusions well, as they give rise to artefacts and duplicates due to the use of backwards bilinear sampling (which is key to the method however, since it is locally sub-differentiable). Such artefacts, in turn, result in blurred disparity maps once trained on. The present work fixes this, and correspondingly obtains good experimental results, by defining an occlusion mask (section 3.2), and a way to get rid of the blurriness (section 3.3).\nThe experimental validation of the fix is carried out similarly to Godard et al 2017, with identical losses, on the same KITTI dataset, using the same splits, but also on the virtual KITTI dataset.\n\nThe paper is structured alright. The presentation is rather sloppy overall, with agrammatical sentences (noun-gerund-infinitive confusions, mainly) which repeatedly get in the way of understanding, sloppy character spacing and punctuation, references from the main text to the supplementary material. Individual paragraphs are exempt of errors and read smoothly.\nThe experimental evaluation seems adequate. \nThe related work section is uncomfortably similar to Godard et al 2017, from which it borrows the presentation structure, and mostly the order of introduction of individual references.\n\nIt almost seems like this is an obligatory fix to Godard et al 2017, and might in the future be considered a standard correction to it. Overall, the scientific contribution appears to be slim.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Relatively incremental novelty while better visualization results.",
            "review": "Summary & Pros: \nThis paper proposes monocular depth estimation with awareness of occlusion regions and edge blurriness during training. For occlusion region, it uses predicted disparity for estimating a mask map. For buryness, it modifies the network output and loss comparison strategy. The two strategies combined together yield sharper edge predictions. Though results are rather incremental for KITTI, the numbers are more significant with virtual KITTI having dense ground truth due to more pixels are evaluated around edge areas.\n\nCons: \n1: The work misses several relative works in unsupervised field for handling occlusion and boundary: \n\nComputing occlusion in unsupervised learning with videos has already been explored by optical flow prediction. \n[1] Meister et.al AAAI 2018: UnFlow: Unsupervised Learning of Optical Flow with a Bidirectional Census Loss.  \n[2] Wang et.al CVPR 2018: Occlusion Aware Unsupervised Learning of Optical Flow\nIn this paper, computing occlusion mask for stereo pair could be a special case of optical flow. I would say the author may directly apply the same strategy to obtain same mask using disparity. \n\nHandling edge and boundary for blurriness using monocular videos  was also mentioned in \n[1] Yang et.al CVPR 2018: LEGO: Learning Edge with Geometry all at Once by Watching Videos\nThe author may also apply an non-local constraint for improve the edge quality as well. Maybe should compare a strategy such as dense crf, bilateral or learning edge affinity for clear boundary learning as well. \n\n2: Other than computing mask, the major novelty of the paper is an engineered modification of  network input and output for computing loss, which I think is not sufficient for ICLR. I would suggest this to be a workshop paper.  It needs more significant contributions not only handle boundaries, maybe consider improvements of absolute estimation results. Experiments over KITTI dataset also shows a rather incremental improvement over Godard's method.\n\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Difficult to read; method unclear",
            "review": "This paper proposes a method for learning to perform monocular depth estimation, using calibrated pairs of stereo images - without supervision from ground truth depth maps. It is heavily based on Godard et al., CVPR 2017, and focuses on sharp ('clear') reconstruction of occluding boundaries.\n\nMy first problem with this paper is the poor quality of English, which makes it difficult to understand. I do not think this submission can be accepted for publication at ICLR, if only because of this.\n\nTechnically speaking, if I understand correctly, the key idea is:  At each optimization step, consider the predicted depth map. The points that are predicted to be visible in only one of the two images according to this depth map are 'disabled' during gradient back propagation, so that they do not influence the network optimization. The motivation is that the loss function assumes that each pixel in the first image is also visible in the corresponding second image of the stereo pairs - which is not true along the occluding boundaries. There is another technique, which (I think) consists in flipping the images and their roles, but I do not understand why it should improve learning - besides providing more training data.\n\nThe proposed method sounds weird to me:  If I understand correctly, there is no guarantee that learning will converge to anything meaningful.  For example, the optimization could introduce more occlusions than there really is, to disable the influence of more pixels without being penalize?\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}