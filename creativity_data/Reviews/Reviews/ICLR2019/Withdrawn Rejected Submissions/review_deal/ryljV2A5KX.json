{
    "Decision": {
        "metareview": "Strengths:  This paper introduces a clever construction to build a more principled disentanglement objective for GANs than the InfoGAN.  The paper is relatively clearly written.  This method provides the possibility of combining the merits of GANs with the useful information-theoretic quantities that can be used to regularize VAEs.\n\nWeaknesses:  The quantitative experiments are based entirely around the toy dSprites dataset, on which they perform comparably to other methods.  Additionally, the qualitative results look pretty bad (in my subjective opinion).  They may still be better than a naive VAE, but the authors could have demonstrated the ability of their model by comparing their models against other models both qualitatively and quantitatively on problems hard enough to make the VAEs fail.\n\nPoints of contention:  The quantitative baselines are taken from another paper which did zero hyperparameter search.  However the authors provided an updated results table based on numbers from other papers in a comment.\n\nConsensus:  Everyone agreed that the idea was good and the experiments were lacking.  Some of the comments about experiments were addressed in the updated version but not all.",
        "confidence": "2: The area chair is not sure",
        "recommendation": "Reject",
        "title": "Nice idea, experiments lacking"
    },
    "Reviews": [
        {
            "title": "A paper with several interesting ideas; Experimental evaluation could do with extra work",
            "review": "(Apologies for this belated review)\n\nSummary \n\nThe authors propose a GAN-based approach to learning disentangled representations that combines elements InfoGAN with recent Information-Bottleneck (IB) perspectives on variational auto-encoders. In addition to minimizing the normal GAN loss, the authors propose to maximize a lower bound on the mutual information under the generative model, whilst minimizing an upper bound\n\n\tIg[X,Z] = E_p(X,Z)[log p(X,Z) - log p(X) - log p(Z)]\n\nIn order to optimize this objective whilst retaining the likelihood-free property of GANs, the authors propose to define a generative model with an intermediate representation r, which allows them to define a likelihood-free generator x = G(r) whilst defining a parametric distribution p(r,z) = eψ(r|z) p(z). This enables the authors to define model architectures that jointly train an encoder qφ(z | x) and a GAN-style generator using an objective that incorporates inductive biases for learning disentangled representations\n\nQuantitative evaluation is performed on d-Sprites (where metrics for disentanglement are evaluated), and qualitative results are shown for Celeb-A and the Chairs dataset. \n\n\nComments\n\nI think this is a paper that presents several interesting ideas. Integrating IB-based ideas into the InfoGAN framework is a useful contribution. Moreover, I think that the way they authors integrate a likelihood-free generative model with an inference model is something of a contribution in its own right. I particularly like the idea of the intermediate representation. \n\nHaving done some work in this space, I would say that the results on d-Sprites are quite good. Aside from the numerical scores in the table aside, the latent traversals in Figure 2 show a good degree of disentanglement. There is a reason that many of the recent papers don’t show these traversals; it turns out to quite difficult to disentangle shape from the other variables, and even rotation tends to correlate with some of the other latents in many cases.\n\nThat said, I would say that the experiments could do with some additional work. I would like to see some discussion of how tight/loose the upper and lower bounds are (some convergence plots would be helpful in this regard). I would also like to see some experiments that evaluate different choices for λ and β (along with some discussion of how these values were chosen – see below). Finally, could the authors find one or two additional datasets? I generally find it difficult to evaluate results on Celeb-A (other than the qualitative evaluation “the images look sharper than those produced by VAEs”). Even something like MNIST/FMNIST would be OK for purposes of evaluating inclusion of Discrete/Concrete variables and/or extrapolation to unseen combinations of factors (as in the Esmaeli et al. paper). \n\nOverall, I would say that this is a potentially strong paper, but that experimental evaluation does need work. I’d be willing to look at an updated version of the paper and adjust my score accordingly if the authors can provide one. \n\nQuestions \n\n- Could the authors comment on why they need to set λ=150, β=1? On a quick read, it is not immediately obvious to me why λ > β implies that we will maximize Ig[X,Z] is this simply because maximizing the lower bound will win out over minimizing the upper bound? When we set λ=β, since this would yield a zero loss when the bounds are tight, is that correct? In this case we presumably not necessarily expect to maximize Ig[X,Z] w.r.t. θ?\n\n- What is perhaps missing from this paper is a discussion of *why* maximizing Ig[X,Z] induces a disentangled representation. One hypothesis could be that be that, for a given number of uncorrelated latent variables, a disentangled generator is simply more efficient in terms of the number of distinct samples X it can construct. In this context, it would be interesting if the the authors could report their Ig[X,Z] bounds. In particular, could they compute\n\n\texp[Ig[X,Z]] / N\n \nIntuitively, this number indicates how many examples the generator can produce relative to the number of training examples N. Is it the case that a more disentangled generator is also capable of producing more distinct samples? \n\n\nMinor \n\n- This is a bit of a pet peeve of mine: Is it really true that GANs lean a representation? A representation is generally a mapping from data to features. A GAN is a mapping from features to data. The authors in this paper do train an encoder to invert the generative model, which learns representation, and certainly a disentangled GAN arguably is useful for more controllable forms of generation in its own right, it just seems that we should not conflate the two. \n\n- Fix: General consent -> General consensus\n- Fix: good representation -> good representations\n- Fix: such disentangled representation -> disentangled representations\n- Fix: (?Higgins et al., 2017b; 2018)\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Elegant approach, well presented, more experimental validation of the core intuition would have been nice",
            "review": "This work addresses the problem of unsupervised disentangled representation learning, and leverages insights and intuitions about utilizing an information bottleneck (IB) approach to encourage disentangling. In particular, building upon insights of how beta-VAE can be understood (and improved upon) by understanding it in terms of IB, the authors propose to modify GANs to include an IB, so as to leverage similar disentangling benefits. The promise is that this approach could utilise the strengths of the GAN framework over VAEs, such as the often sharper reconstructions and the ease of including discrete latents in addition to continuous ones. \n\nTo implement their proposal in practice, the authors introduce a neat trick to control an upper bound for the additional mutual information term that the new approach -- termed IB-GAN -- requires. This adds just one layer of complexity to the GAN setup via adding a stochastic representation model between the latent representation and the generator, and has elegant limiting cases that recover both the standard GAN and the InfoGAN approach.\n\nThe paper is clearly presented and the intuitive arguments can be readily followed, even though the resulting loss formulation is a bit tricky to justify without expanding upon the underlying motivation. \n\nThe approach is tested on three standard datasets and two different metrics that have previously been used for benchmarking unsupervised disentangling, and the results look convincing enough to demonstrate the improvement over existing GAN approaches. \n\nStill, the experimental section is arguably the weakest part of the paper, as there are now stronger beta-VAE variants as baselines available, so I am taking the numbers for VAE-based methods in the quantitative assessment with a grain of salt. More importantly, though, as the motivation of the work is that introducing an information bottleneck is what creates the success in disentangling, it would have been nice to see this effect more clearly broken out in experiments directly demonstrating the effect of beta and gamma on the degree of disentanglement. \n\nOverall, though, this is an interesting contribution to the rapidly developing subfield of unsupervised disentangling, and I would expect the introduction of IB ideas into GAN setups to drive further advances in representation learning techniques. \n\n===\nUpdate: \nI am happy with the clarifications and the changes to the manuscript, and have increased my rating accordingly from 6 to 7. ",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Nice idea.  Experiments lacking.",
            "review": "Please have your submission proof-read for English style and grammar issues. \n\nThis paper introduces the IB-GAN and information bottleneck inspired GAN variant.  The ordinary GAN objective is modified to include a variational lower and upper bound on the generative mutual information.  This should allow one to control the amount of information in the representation of the GAN, in contrast to the InfoGAN which simply maximizes the mutual information.  While lower bounding the generative mutual information is straight forward and only requires a variational inverting network (some q(z|x)) upper bounding the generative mutual information is trickier.  Here the paper offers a very nice solution.  Formally they realize a modified Markov chain   Z -> R -> X where R is made explicitly stochastic.  By Data Processing Inequality I(Z;X) <= I(Z;R) and with a tractable e(r|z), only a variational marginal m(r) is needed to obtain a variational upper bound on the mutual information in the GAN.  This then gives a GAN objective that looks like the information bottleneck interpretation of the VAE.\n\nWhile the idea for obtaining a variational upper bound on the generative mutual information is novel and clever, the experiments in the paper are lacking.\n\nIt should be noted that the variational lower bound on the generative mutual information has already been introduced as the GILBO (generative information lower bound) (arxiv:1802.04874) \n\nI take issue with the discussion in the \"Reconstruction of input noise z\" section.  It is claimed that beta-VAE \"applies the MSE loss to x and uses beta > 1\".  VAEs do not have to utilize gaussian observation models and can use powerful autoregressive decoders (e.g. arxiv:1611.02731).  \n\nLater down the page it is claimed that when m(r) and p(z) have the same distributional form and dimensionality the R will become independent of Z.  I do not believe this.  What prevents e(r|z) from being a near identity in this situation, for which there could be a large generative mutual information?\n\nThe experiments used batch normalization, itself a stochastic procedure that would make their tractable densities incorrect.  There is no discussion of the effect batch norm would have on their bounds.\n\nMy principal complaint is the general lack of experimental evidence.  The paper suggests what appears to be a nice framework and simple procedure for controlling the information flow in a GAN.  To do so they introduce two Lagrange multipliers, beta and lambda in their notation (Equation 11) but there are no experiments showing the effect of these two hyperparameters.  They have what should be both an upper and lower bound on the same quantity, the generative mutual information, but these are not shown separately for any of their experiments.  There is no discussion of how tight the bounds are and if they approach each other.  There is no discussion of how the beta and lambda might influence them either individually or jointly.  There is no evidence to demonstrate the effect of constraining the mutual information between X and Z.\n\nIn short, the paper offers what appears to be a very clever idea, but does very little to experimentally explore its effects.\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}