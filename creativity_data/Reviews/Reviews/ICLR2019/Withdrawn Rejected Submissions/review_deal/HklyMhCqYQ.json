{
    "Decision": {
        "metareview": "The main novelty of the paper lies in using multiple noise vectors to reconstruct the high resolution image in multiple ways. Then, the reconstruction with minimal loss is selected and updated to improve the fit against the target image. The most important control experiment in my opinion should compare this approach against the same architecture with only with m=1 noise vector (i.e., using a constant noise vector all the time). Unfortunately, the paper does not include such a comparison, which means the main hypothesis of the paper is not tested. Please include this experiment in the revised version of the paper.\n\nPS: There is another high level concern regarding the use of PSNR or SSIM for evaluation of super-resolution methods. As shown by \"Pixel recursive super resolution (Dahl et al.)\" and others, PSNR and SSIM metrics are only relevant in the low magnification regime, in which techniques based on MSE (mean squared error) are very competitive. Maybe you need to consider large magnification regime in which GAN and normalized flow-based models are more relevant.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "The paper needs to be improved"
    },
    "Reviews": [
        {
            "title": "Interesting approach, but experiments are not appropriate",
            "review": "- Summary\nThis paper proposes a method based on implicit maximum likelihood estimation for single-image super-resolution. The proposed method aims at avoiding common artifacts such as high-frequency noise and shape distortion. The proposed method shows better performance than SRGAN in terms of PSNR, SSIM, and human evaluation of realism on the ImageNet dataset.\n\n- Pros\n  - The proposed method shows better performance than SRGAN in terms of PSNR, SSIM, and human evaluation.\n  - The selection of the evaluation methods is appropriate. In the field of image super-resolution tasks, both signal accuracy (e.g., PSNR) and perceptual quality (e.g., human evaluation) are important.\n\n- Cons\n  - The experiments are conducted thoroughly in the ImageNet, but the selection of the dataset is not appropriate. It would be better to apply the proposed method to other datasets which are used recent papers.\n  - Also, the selection of the methods to be compared is not appropriate. It would be better to provide recent state-of-the-art methods and compare the proposed method with them.\n\nThe proposed approach is interesting and promising, but the selection of the methods and datasets to be compared is not appropriate.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Paper is written well and except for some sections, it provides enough details. The work is original enough but might need some improvement or more explanation in experiments/result section.",
            "review": "This paper proposes a technique to find a maximum-likelihood estimate of the super-resolved images under latent variables without computing it. Paper is mostly clearly written and except for some sections, it provides enough details. The work is original enough but might need some improvement or more explanation in experiments/result section.\n\nPros:\n-The idea seems to be original enough, simple and easy to implement.\n-A nice follow-up of the recent work in NN search and Implicit maximum likelihood estimation. \n-Many details that could be helpful for further research in the area are given.\n\nCons:\n-Regarding methodology, an unclear point in the paper is how different networks trained according to algorithm 1. Is each sub-network trained separately? Is the visual perception based feature space pre-trained and fixed, or is it jointly retrained with the super-resolution network? \n\n-Another critical point is post-training, particularly the way learned parameters are used could be explained better: Given a super-resolution model f, how the super-resolution of a single image is performed? What is the sampling variation? How likely such a network can be productionized in real-time systems (e.g., digital displays or embedded systems)? How does the proposed approach compared to GAN based methods with regards to that? Is multi-modality a problem in this case? Any way to choose one specific mode in a conscious way?\n\n-My main concern about the paper is the results section: Authors perform both large-scale offline comparison (imagenet) and a small subset human evaluation. The results in human evaluation need some explanation. This comparison is identical to several previous 1-1 comparisons performed in literature and almost every single such comparison it has been found that state of the art techniques (e.g., 10+ years of super-resolution algorithms) significantly outperform bicubic interpolation. However, Table 2 in the paper suggests that both SRGAN and SRIM barely beats bicubic interpolation. For example, authors in https://arxiv.org/pdf/1209.5019.pdf showed that a relatively older supervised technique beat bicubic 90% of the time. There seems to be some explanation needed here: Is it the sample size? Are the samples from both SRIM and SRGAN very variable?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "A super-resolution method with with fewer visual artifacts than the SRGAN method.",
            "review": "Quality: The overall quality of this paper is good. It adopts a simple but novel idea on SISR and shows clear improvement against existing method (e.g., SRGAN). \n\nClarify: This paper is well written and easy to follow. It shows a clear motivation for adopting the implicit probabilistic model.\n\nOriginality: To the best of my knowledge, this paper is the first work to learn multi-modal probabilistic model for SISR.\n\nSignificance: While the results can be further improved (still look a bit blurred), this paper shows an interesting and important direction to learn better mappings for SISR.\n\nPros:\n+ The writing is clear.\n+ The proposed method is well motivated and easy to understand.\n+ The experimental results include both objective and subjective evaluations.\n\nCons:\n- The two-stage architecture is similar to the following generative models and SR methods. It’s suggested to discuss them as well.\n[a] Denton, E. L., Chintala, S., & Fergus, R. “Deep generative image models using a￼ laplacian pyramid of adversarial networks”. NIPS, 2015.\n[b] Karras, T., Aila, T., Laine, S., & Lehtinen, J. “Progressive growing of gans for improved quality, stability, and variation”. ICLR 2018.\n[c] Lai, W. S., Huang, J. B., Ahuja, N., & Yang, M. H. “Deep laplacian pyramid networks for fast and accurate super-resolution.” CVPR 2017.\n[d] Wang, Y., Perazzi, F., McWilliams, B., Sorkine-Hornung, A., Sorkine-Hornung, O., & Schroers, C. “A Fully Progressive Approach to Single-Image Super-Resolution.”. CVPR Workshops 2018.\n\n- In the hierarchical sampling (section 2.4), it’s not clear how to generate the upper noise vector “conditioned on the lower noise vector”. \n\n- The hierarchical sampling seems to improve the efficiency of training. I wonder does it affect the results of testing?\n\n- In the implementation details (section 2.5), I don’t understand why you need to transfer the the feature activations from GPU to CPU? I think all the computation can be done on GPU for most common toolboxes. Projecting the activations to a lower dimension with a “random Gaussian matrix” sounds harmful to the results.\n\n- How do you generate the low-resolution images? Are you using bicubic downsampling or other approaches? This detail should be clarified.\n\n- While the evaluation with PSNR and SSIM is a reference to show the quality, many literatures already show that PSNR and SSIM are not correlated well with human perception. It is suggested to also evaluate with some perceptual metrics, e.g., LPIPS [e].\n[e] Zhang, R., Isola, P., Efros, A. A., Shechtman, E., & Wang, O. “The unreasonable effectiveness of deep features as a perceptual metric.” CVPR 2018.\n\n- In Figure 7, how do you generate different results from the same input image for SRGAN? From my understanding, SRGAN doesn’t take any noise vector as input and cannot generate multi-modal results.\n\n- I feel that the comparison with only SRGAN is not enough. There are some GAN-based SR methods [f][g]. It’s also suggested to compare with MSE-based state-of-the-art SR algorithms [h][i].\n\n[f] Sajjadi, M. S., Schölkopf, B., & Hirsch, M. “Enhancenet: Single image super-resolution through automated texture synthesis.“ ICCV 2017.\n[g] Wang, X., Yu, K., Dong, C., & Loy, C. C. “Recovering realistic texture in image super-resolution by deep spatial feature transform.” CVPR 2018.\n[h] Lim, B., Son, S., Kim, H., Nah, S., & Lee, K. M. “Enhanced deep residual networks for single image super-resolution.” CVPR Workshops 2017.\n[i] Zhang, Y., Tian, Y., Kong, Y., Zhong, B., & Fu, Y. “Residual dense network for image super-resolution.” CVPR 2018.\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}