{
    "Decision": {
        "metareview": "The work presents a method of imposing harmonic structural regularizations to layers of a neural network. While the idea is interesting, the reviewers point out multiple issues.\n\nPros:\n+ Interesting method\n+ Hidden layer coherence tends to improve\n\nCons:\n- Deficient comparisons to baselines or context with other works.\n- Insufficient assessment of impact to model performance.\n- Lack of strategy to select regularizers\n- Lack of evaluation on more realistic datasets",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Structural regularizations imposed on layers. "
    },
    "Reviews": [
        {
            "title": "Interesting technique, Lack of Related work",
            "review": "Authors present a novel regularizer to impose graph structure upon hidden layers of a neural Network. The intuition is that Neural Networks has typically  symmetric computation among different channels in one layer. Due to the lack of order, visually inspecting the hidden representation is not feasible. By adding edges one can impose a structure upon nodes in one layer and add for example a Laplacian regularizer rather than simple L2 norm regularizer to force the activations to follow the imposed structure. \n\nPros: \n\nInteresting idea for bringing some benefits of graphical models into Neural Networks using a regularizer.\n\nExperiments verify that one can successfully improve the intrepretability of hidden representations. Also, they provide examples of use cases for such technique like aligning the capsule dimmensions. \n\nCons:\n\nThe major flaw is the lack of comparison with ``any'' of the related work on interpretability or the prior work on imposing structure upon hidden representations. Also, the manuscripts lacks a clear discussion of where does this work stands in the literature like structured VAEs, graphical models, sum product nets + factor graphs. \n\nAlso, in none of the experiments authors mention how the added regularizer affects the model performance. Whether imposing the grid structure on CNN (last experiment) drops the CNN accuracy or has no effect? Same for the CapsNet.\n\nFurthermore, the feasibility of calculating the Laplacian for larger scale hidden layers or approximating it is not addressed.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Latent structure through spectral regularization.",
            "review": "The paper introduces a spectral regularization with the aim of obtaining representations\nthat are easier to interpret.\n\nSome sentences are often confusing and, in general, clarity needs to be improved.\n\nThe motivation of the work is not very strong in my opinion, in particular by adding such\na prior the space of possible solutions greatly shrinks and I am afraid\nthat interesting solutions will be lost. I think one should focus on properties\nrather than visual inspection.\nAlso, isn't it that if we can clearly see the pattern, perhaps that pattern is\nlinear and of easy discovery also by simpler models?\n\nMore importantly, it seems that all experiments are performed on tasks where the\nunderlying structure is known, however this is almost never the case in practice.\nAssuming one uses the proposed spectral regularization, how would one interpret\nit in such cases?\n\nIn section 2 please clarify the paragraph on bounded Lp norm.\n\nI am sorry but why isn't there a relation, for convolutional nets,\nbetween neurons in different channels? Each element in the feature map represents\nthe input surrounding that location in a k dimensional space.\n\nThe authors state that the usual bottleneck for autoencoders is composed of 2/3\nneurons, this is simply not true. There has been extensive work on\novercomplete representations that shows that is better to have many more dimensions\nbut only few degrees of freedom.\n\nThe spectral bottleneck should cite VQVAE as the approach is very similar and the \nauthors should compare to it.\n\nFor the topological inference experiment it is assumed that one knows the structure,\nbut how to address the more general problem?\nMore practically, the regularization enforces smoothing (if few eigenfunctions\nare used, which is never explained in the paper) between connected nodes, did\nthe authors try to have a simple L2 penalty instead? E.g. minimize the difference\nbetween activations in the group.\n\nRegarding the capsule network example, when you write that without regularization\neach digit responds differently to perturbation of the same dimension, isn't it\npossibly true only up to a, unknown, permutation of the neurons?\n\nTo summarize, while the idea sounds interesting, I miss to find the easy interpretability\nof results and also the overall motivation sounds a bit weak. \nMore importantly the selection of W, crucial for defining structure, is not discussed at all in the paper.\nExperiments are performed on toy examples only whereas here, given that we can\npossibly interpret the results I would have liked something more involved to\nbetter show that this kind of interpretability is needed.\n\nMissing cites:\n[1] van den Oord et al, Neural Discrete Representation Learning.\n[2] Koutnik et al, Evolving neural networks in compressed weight space.\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "The usefulness of graph spectral regularizer is shown, but the key points in practice are not considered.",
            "review": "Authors highlight the contribution of graph spectral regularizer to the interpretability of neural networks. Specifically, authors consider the Laplacian smoothing regularizer to enhance the local consistency/smoothness between a neuron and its neighbors. Furthermore, by extending the graph Fourier transformation to overcomplete dictionary representation, authors further propose a spectral bottleneck regularizer. Experimental results show that when suitable structural information and corresponding regularizers are imposed, the interpretability of the intermediate layers is improved.\n\nMy main concern is that the power of Graph-based regularizer has been well-known in the ML community for a long time. It is not surprising that adding such regularizers to the training process of neural networks can help to get more structural activations. The key points are \n\n1) How to define the Laplacian graph for the neurons? For the simple case shown in Figures 1 and 2, the topology of the neurons has been predefined and the functionality of them is predefined implicitly. For more challenging cases, how to build the Laplacian graph reasonably? \n\n2) How to add the regularizers with good scalability? The complexity of the proposed regularizers is O(N^2) where N is the number of neurons. When the layers contains thousands of neurons or more, how to add the regularizers efficiently?\n\n3) Which regularizer should be selected? Authors propose a class of graph spectral regularizers and their performance is different in different tasks. Is there any strategy helping us to select suitable regularizers for specific tasks?\n\nUnfortunately, authors provide little analysis on these key points.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}