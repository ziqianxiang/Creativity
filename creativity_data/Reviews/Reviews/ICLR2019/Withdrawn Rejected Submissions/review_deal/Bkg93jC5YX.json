{
    "Decision": {
        "metareview": "This paper is very close to the decision boundary and the reviewers were split about whether it should be accepted or not. The authors updated the paper with additional experiments as request by the reviewers.\nThe area chair acknowledges that there is some novelty that leads to (moderate) empirical gains but does not see these as sufficient to push the paper over the very competitive acceptance threshold. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Reject"
    },
    "Reviews": [
        {
            "title": "a semi-supervised algorithm for bilingual lexicon induction problem",
            "review": "Summary: \n\nThe paper propose a semi-supervised algorithm for bilingual lexicon induction (BLI) problem. Prior works on BLI problem usually impose orthogonality constraint on the linear transformation in order to obtain a \"reversible\" mapping and to preserve the monolingual performance. However, from both modeling and generalization perspective, recent works do not impose this constraint while learning the mapping (Doval et al 2018, Jawanpuria et al 2018, Joulin et al 2018, Sogaard et al 2018, among others). The present work argues for the removal of the orthogonality constraint when language spaces are non-isometric, and proposes to employ the Gromov Hausdroff (GH) distance to validate this condition. Overall, the paper employs  an objective function which is the sum of the (unsupervised) adversarial distribution matching objective (Lample et al 2018b), (supervised) the BLI loss function (typically the square loss), and a consistency loss (Hoshen and Wolf 2018). Empirically, the proposed method shows better results than unsupervised method of Lample et al (2018b) and the Procrustes solution.\n\nThe pros:\n\n- Existing works have shown that some BLI techniques perform better than the other in *some* pair of languages. Hence, it seems that there may not be \"one size fit all\" BLI technique. The proposed usage of GH distance is in the direction to quantitatively categorize pairs of languages. Based on a carefully crafted metric, the practical systems may chose to use one BLI algorithm over another for a given pair of languages.\n\nThe cons:\n\n- From modeling perspective, the utility of weak orthogonality constraint in the objective function is unclear. Does it improve generalization performance? Is it for preserving monolingual performance? The cited works (in the above summary) show that removing the strong/weak orthogonality constraint improves the BLI accuracy while preserving the monolingual performance.\n- The baselines chosen for experiments are not state-of-the-art. In addition, Artetxe et al. (2017, 2018) results are with NN/ISF retrieval procedure. These baselines should be rerun with CSLS retrieval procedure (codes are available in the author's website), which is now a standard for BLI task. Refer to Artetxe et al (2018b), Joulin et al (2018), Jawanpuria et al (2018), Gravel et al (2018) for state-of-the-art (semi-supervised/ unsupervised) results on MUSE and Vecmap datasets.\n- Experiments with varying data (Table 6) does not provide a clear picture without discussing unsupervised/semi-supervised baselines.\n- The logic behind experiments on GH distance (Table 2) is unclear. Why should a high correlation with *a baseline* suggest that GH distance correlates well with the degree of isometry of the two languages? Does GH distance has high correlation with *any* baseline for BLI?\n\n\nArtetxe et al (2018b): A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings.\nJoulin et al (2018): Loss in translation: Learning bilingual word mapping with a retrieval criterion.\nJawanpuria et al (2018): Learning multilingual word embeddings in latent metric space: a geometric approach.\nHoshen and Wolf (2018): Non-adversarial unsupervised word translation.\nDoval et al (2018): Improving cross-lingual word embeddings by meeting in the middle.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Solid work with some obscure parts that should be clarified",
            "review": "This paper presents a new semi-supervised method to learn cross-lingual word embeddings mappings combining unsupervised distribution matching, alignment over a training dictionary, and a weak orthogonality constraint. The paper also shows that the underlying isometry assumption in orthogonal mappings weakens as the languages involved are more distant, proposes a new method to quantify the strength of the said assumption, and argues that the proposed semi-supervised mapping method is particularly suited for these more challenging cases.\n\nI think that this is a solid work that explores an interesting research direction within cross-lingual embedding mappings. While the basic ingredients of the proposed method are not new, their combination is certainly original. In that regard, I think that the paper is rather incremental, but still has enough substance to make an interesting contribution. However, I think that some parts of the paper are too obscure, and I am not fully convinced by the experiments. I would appreciate if the authors could address my concerns below, and I would be happy to modify my score accordingly:\n\n1) My understanding is that the proposed method (the one named BLISS in the experiments) only makes use of the proposed semi-supervised framework (Section 3.2) and is not followed by the iterative procrustes refinement (Section 3.3), but this is not clear at all from the paper. Could you clarify this?\n\n2) It is well known that the retrieval method can have a big impact in bilingual dictionary induction due to the hubness problem. However, the paper does not detail which retrieval method is used in the experiments. I assume that MUSE uses CSLS and Vecmap uses nearest neighbor over cosine. Is this correct? What retrieval method does BLISS use?\n\n3) I assume that when you talk about the \"CSLS metric\" in page 7 and 13 you refer to the unsupervised validation criterion of Lample et al. (Section 3.5 in their paper), and not to CSLS itself (Section 2.3 in their paper). In either case, this needs some clarification.\n\n4) Unlike the \"train\" dictionaries, the \"full\" dictionaries from MUSE as provided at github also include the test set. Do you preprocess them to exclude the test set? If so, this should be clearly stated in the paper. If not, this would invalidate all these experiments.\n\n5) The authors use different language pairs in their different result tables, which I find very confusing. For instance, none of the language pairs in table 5 (except for en-ru), are included in the main results (table 3), so we do not know how the different baselines and variants perform in them. Is there any reason for that?\n\n6) Could you include all MUSE variants in Table 4?\n\n7) While you compare your method to different versions of Vecmap (Artetxe et al., ACL 2017 & AAAI 2018), the last one (Artetxe et al., ACL 2018) (http://aclweb.org/anthology/P18-1073) is missing. That paper reports 48.1% and 48.2% accuracy for en-it and en-de in the unsupervised case, which is substantially better than your results for en-it (45.9%) and at par for en-de (48.3%). This goes against the main motivation of the paper (i.e. unsupervised distribution information and supervision from dictionaries can be combined for best results), as a completely unsupervised method seems to perform better than (or at least at par with) the proposed semi-supervised method. I think that the paper should include some discussion on this. In particular, I would like to know whether you have any argument to believe that both works are complementary.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "review": "This paper presents a new semi-supervised method for bilingual dictionary induction and proposes a new metric to measure isometry between embedding spaces.\n\nPros:\n- The paper proposes to use a new metric, the Gromov-Hausdorff distance to measure how isometric two word embedding spaces are.\n- The toy example is useful for motivating the use case of the method.\n- The approach achieves convincing results on the dataset.\n\nCons:\n- Beyond the isometry metric, the main innovation as far as I can see seems to be the hubness filtering, which is incremental and not ablated, so it is not clear how much improvement it yields. The weak orthogonality constraint has already been used in [2].\n- It is not clear to me what the proposed metric adds beyond the eigenvector similarity metric proposed in [1]. The authors should compare to this metric at least.\n- The authors might want to add the results of [3] for an up-to-date comparison.\n\n[1] Søgaard, A., Ruder, S., & Vulić, I. (2018). On the Limitations of Unsupervised Bilingual Dictionary Induction. In Proceedings of ACL 2018.\n[2] Zhang, M., Liu, Y., Luan, H., & Sun, M. (2017). Adversarial Training for Unsupervised Bilingual Lexicon Induction. In Proceedings of ACL.\n[3] Artetxe, M., Labaka, G., & Agirre, E. (2018). A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings. In Proceedings of ACL 2018.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}