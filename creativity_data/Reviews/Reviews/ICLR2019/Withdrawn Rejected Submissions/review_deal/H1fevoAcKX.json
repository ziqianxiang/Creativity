{
    "Decision": {
        "metareview": "This paper proposes new heuristics to prune and compress neural networks. The paper is well organized. However, reviewers are concerned that the novelty is relatively limited. The advantage of the proposed method is marginal on ImageNet. What is effective is not very clear. Therefore, recommend for rejection. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "not convincing"
    },
    "Reviews": [
        {
            "title": "using cumulative saliency as guidance for model pruning",
            "review": "In this paper, the authors propose to use cumulative saliency as guidance for model pruning. In particular, when designing saliency, they introduce a balanced formula by taking the filter size and gradient value into account.  The paper is well organized, and extensive experiments are investigated.  However, the novelty is relatively limited. The advantage of the proposed method is marginal on ImageNet, when comparing with the relevant approaches. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Method for pruning networks with global network saliency computed for the entire dataset",
            "review": "This paper proposes a method for pruning CNNs, which considers all filters globally. It normalizes the weights of a filter within a layer and globally across all layers. To incorporate the effect of the data set, the authors additionally compute the normalized gradients and multiply the weight term with it. The third concept that the authors introduce is the idea of accumulating this measure of the importance of a filter for one entire epoch, before pruning.\n\nThe paper is missing an important citation: \"Pruning Convolutional Neural Networks for Resource Efficient Inference\", Molchanov, et al., 2017, which previously introduced many of the concepts proposed in this submission. For example, Molchanov, et al., propose the magnitude of the product of the activation and its gradient as the criteria for pruning. They derive mathematically as to how their criterion relates to the expected change in the overall loss via the Taylor series expansion. They additionally emphasize the importance of normalizing the criterion across network layers and the importance of greater number of updates to the network before pruning for better results. It is important that authors of this submission clearly compare and differentiate their work from the previous very closely related work of Molchanov et al.\n\nAdditionally, in order to understand the contribution of each of the concepts that the authors introduce, i.e., accumulation of saliency, multiplication with gradients, normalization within a layer, normalization across layers, the authors should present ablation studies to show the affect of each of these concepts independently to the overall accuracy of their approach.\n\n\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Weak reject: Incremental work and insufficient experiments.  ",
            "review": "This paper proposes new heuristics to prune and compactify neural networks. The heuristics try to consider 1) filter weight and gradient normalization by their size, 2) saliency normalization across layers, 3) saliency accumulation across batch. The author claims that these can address problems previous studies had and experimental results show that the proposed method achieve higher compression ration with less loss of accuracy.\n\nThis paper discusses how to determine the importance of filters. As cited in the paper, there have been various attempts to tackle the same problem and the paper contributes to the series of efforts. The paper introduces a new way to compute such importance values based on their observations. The method is tested on a few dataset and a various models and compared with some previous studies. I like the simple but yet effective method, however, I think it is not good enough for ICLR. \n\n1. What is effective is not very clear.\n\nThe paper pointed out issues of previous studies and proposed the new method based on the observations. However, only the final method is compared with other work and it did not examine which part of the method was essential. The paper needs more detailed analyses on the proposed method. For example, the readers would want to know if the normalization in Eq. (2) is really important or not. The readers would be also interested in a visualization like Fig. 2 without saliency normalization. \n\n2. The numbers of previous studies come only from their papers.\n\nIt is very difficult to know if the proposed method is actually better than the previous methods if the numbers just come from their papers. We want to compare the ideas, but not numbers. The essential ideas of other papers need to be abstracted and tested in the paper by itself. It relates to the first item above. \"Baseline\" should be a baseline method but not models without pruning.\n\nNumbers from other papers are still useful to show that the numbers in the paper are good in an absolute manner.\n\n3. Weak theoretical reasoning\n\nEq. (1) in the paper is not actually used for optimization while some previous methods do. If the proposed method is better than other methods which directly optimizes the loss, should we think that the formulation itself is bad? \n\nThe paper discusses imbalanced pruned pruning results. It needs to show that it is actually bad.\n\n* minor things\n\n** Table 1: Should the first row of \"Wen et al. (2016)\" have \"5-19\" and \"1-5\" or \"4-19\" and \"1-4\" for \"Filters\" and \"Channels\", respectively?\n\n** I'd recommend another proofreading.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}