{
    "Decision": {
        "metareview": "The paper presents a modification of the convolution layer, where the convolution weights are generated by another convolution operation. While this is an interesting idea, all reviewers felt that the evaluation and results are not particularly convincing, and the paper is not ready for acceptance.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "evaluation and results not convincing"
    },
    "Reviews": [
        {
            "title": "Review of \"Adaptive Convolutional Neural Networks\"",
            "review": "This paper presents a pretty cool idea for enabling \"adaptive\" kernels for CNNs which allow dramatic reduction in the size of models with moderate to large performance drops.  In at least one case, the training time is also significantly reduced (2x).\n\nThe best part about this paper is that the size of the models are much smaller; but the paper does offer any explanation of the value of this.  For example, even a 1% drop in accuracy can be unacceptable; but in some applications (like cell phones and IOT devices) model size is critical.  The authors' should add some wording to explain this value.\n\nThe \"adaptive\"kernels the the authors talk about are really a new class of nonlinear kernels.  It would be very interesting to see a discussion of the class of functions these nonlinear kernels represent.  This kind of discussion would give the reader  motivation for the choice of function, ideas for how to improve in this class of functions, and insight into why it works.\n\nThe method presented is interesting; but it is not clear that it is present with enough detail for it's results to be replicated.  It would be nice if the authors pointed to a git repository with their code an experiments.  More importantly, the results presented are quite meager.  If this is a method for image recognition, it would be better to present results for a more substantial image recognition problem than MNIST and CIFAR-10.  And the analysis of the \"dynamic range\" of the algorithim is missing.  How do performance and model size trade off?  How were the number of layers and kernels chosen?  Was the 5x10x20x10 topology used for MNIST the only topology tried?  That would be very surprising.  What is the performance on all of the other topologies tried for the proposed algorithm?  Was crossvalidation used to select the topology?  If so, what was the methodology. \n\nAdditionally, some readers may find this paper a little difficult to read due to (1) lack of clarity in the writing, e.g., the first three paragraphs in Section 3; (2) omitted details, e.g., how much overlap exists between kernels (Figs. 1, 2, and 4 suggests there is no overlap - this should be made clear); and (3) poor grammar and nonstandard terminology, e.g., the authors' use of the word \"energy\" and the phrase \"degradation problem\".  All of these issues should be addressed in a future version of the paper.\n\nNot sure why Eqns. 2 and 9 need any parentheses.  They should be removed.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Is this really a type of convolutional network?",
            "review": "The paper develops a new 'convolution' operation. \nI think it is misleading to call it a convolution, as (a) it is not a convolution mathematically, and (b) fast convolution techniques (Fourier, Winograd) cannot be applied, so claims to greater efficiency may be misleading.\n\np2-3, Section 3.1 - I found the equations impossible to read. What are the subscripts over?\nIn (2) is (N+1)x(N+1) the kernel size (sums are over 0,1,...,N?)??\nIs the output of the first convolution a single HxW feature planes, or a HxWx(N+1)x(N+1) tensor?\n\nEquation (4). What is d_{k,l}? A pixel-wise target label? Where does it come from?\n\nExperimental section: Like depthwise convolutions, you seem to achieve reasonable accuracy at fairly low computational cost. It would therefore be much more interesting to compare your networks with ShuffleNet style networks designed for computational efficiency, rather than networks designed mainly to push the benchmark numbers down whatever the cost.\n\nIt would be helpful to have the computational cost of the network in FLOPs, and running time compared a regular ConvNet using Winograd/Fourier convolutions.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review of Adaptive Convolutional Neural Networks.",
            "review": "The paper introduces adaptive kernels (that adapts its weights as a function of image content) to the framework of CNN. The benefit of adaptive kernels is the reduction of memory usage (at training and at the inference time) as well as training speedups (up to 2x). The kernels are evaluated on two datasets MNIST and CIFAR10\n\nI like the idea of building models that are memory efficient at training and at evaluation time. However, the evaluation of the proposed adaptive kernels is rather limited. In order to improve the paper, the authors could take into consideration the following points:\n\n1. Why there is still a need to combine adaptive convolutions with regular convolutions? What would the model performance be for a model with only adaptive kernels?\n2. I might have missed it, but I couldn't find any motivation on why tanh is used as nonlinearity. Would the method work with relu?\n3. Traditional convolutional kernels together with max pooling operations ensures some degree of translation invariance. How big is the generalization gap for the tested models when adaptive kernel is used?\n4. How sensitive are the results to the number of adaptive kernels in the layers.\n5. Adaptive kernels have only been tested in the first convolutional layer, would the adaptive kernels work well also in different layers?\n6. On CIFAR10 the results seem to be worse that other methods. However, it is important to note that the Adaptive Kernels CNN has way less parameters. It would be interesting to see how the performance of adaptive kernels based CNNs scales with the number of parameters.\n7. The evaluation on two datasets seems to be rather limited, additional comparisons should be included.\n8. The authors acknowledge the similarities (and some differences) with Brabandere et al (2016). It might be beneficial to include comparison to this approach in the experimental section. Moreover, given the similarities, it might be good to discuss the differences in the approaches in the introduction section.\n9. The ideas presented in the paper seems related to general concept of hypernetworks, where one network learns (or helps to learn) paramenters of the other network. It would be nice to position the ideas from the paper w.r.t. this line of research too.\n10. Another related paper seems to be Spatial Transformer Networks (Jaderberg et al.).\n\nI like the drawings, however, the font on the drawings is too small - making it hard to read.\n\nSome typos:\n1. the difficult to train the network\n2. table 2: Dynamic -> Adaptive?\n\nOverall, the paper presents interesting ideas with some degree of originality. I'd encourage the authors to extend the intro and position the ideas w.r.t. existing works and extend the evaluation.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}