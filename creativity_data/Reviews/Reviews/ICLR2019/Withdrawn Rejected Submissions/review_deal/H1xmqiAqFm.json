{
    "Decision": {
        "metareview": "The paper analyzes the performance of CNN models when data is mislabelled in different manners.\n\nThe reviewers and AC note the critical limitation of novelty of this paper to meet the high standard of ICLR.\n\nAC thinks the proposed method has potential and is interesting, but decided that the authors need more works to publish.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Limited novelty"
    },
    "Reviews": [
        {
            "title": "Interesting analysis, but not surprising results",
            "review": "The authors challenge the CNNs robustness to label noise, but when the label noise is class dependent, more realistic scenario than class independent noise. \nTo analyse the CNNs behavior in such a scenario, they consider the ImageNet 1k dataset, and change some labels to labels that are close according to the ImageNet 1k tree of WordNet. \nThe authors conduct multiple experiment to compare the effect of class dependent and class independent noise on:\n* the model accuracy\n* the robustness to adversarial perturbation \n* the learned representation\n\nThe paper is generally well written and well structured. The analysis is sound and addresses interesting points, giving insightful results. Nevertheless, the overall conclusion is not very surprising. This work  confirms the commonly admitted fact that CNNs learn features that are visually meaningful.   Moreover, there is no significant novelty in the paper. The paper only analyses the CNNs behavior, without suggesting any new algorithm based on the observations. One specific point that seems under-investigated in my sense is the observation about the robustness to adversarial perturbations. The model with the class dependent noisy labels is in average less sensitive to the perturbations, even if this is not significant for the tested noise level. Did the authors test with different noise levels? This calls for a further analysis. It has the potential to give more insights, and probably inspire new methods to improve training robustness.    ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A good start, but lack of sufficient support",
            "review": "This paper attempted to analyse the performance of CNN models when data is mislabelled in different manners, i.e. class dependent labels and class independent labels. It carried out several good experiments as a good start, but several points are not comprehensively studied and analysed. \n1. Try to provide more direct and solid proofs on the relationship between conceptual and visual distances between class dependent labels. \n2. In table 1, model trained with noise on class dependent label has lower fooling rate than model trained with clean data. Is it worth exploiting in a deeper manner?\n3. In figure 5, why the curve appears so different after block 4 only? Would visualising feature maps from different layers help understand this observation?\n4. In figure 6, it seems that the difference between those experiments is marginal, which contribute little to the argument of this paper.\n5. About the discussion on 'cluster', it would be better if sufficient experiments and analysis can be provided.\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "CCN model and IDN model should be the focus in learning with noisy labels.",
            "review": "This paper demonstrates that CNNs are more robust to class-relevant label noise. They argue that real-world noise should be class-relevant.\n\nPros:\n\n1. The authors find a new angle to exploit robust learning with noisy labels.\n\n2. The authors perform numerical experiments to demonstrate the effectiveness of their proposal. And their experimental result support their previous claims.\n\nCons:\n\nWe have two questions in the following.\n\n1. Basic definition: in learning with noisy labels, there are two basic models. First, most research focuses on class-conditional noise (CCN) model [1]. Second, recent research explore a bit on instance-dependent noise (IDN) model [2, 3]. As far as I know, there is no class-irrelevant label noise and class-relevevant label noise. In CCN mode, people would like to use symmetric noise and asymmetric noise as a basic benchmark to conduct experiments.\n\n2. Motivation: The authors want to claim CNNs are more robust to such realistic label noise than class-irrelevant label noise. However, they make one mistake. They do not have a clear definition about realistic label noise. In my mind, I believe Clothing1M [4] should be realistic label noise dataset.\n\nBy the way, in learning with noisy labels, there are two kinds of research. First, people propose new robust methods for CCN model. Second, people propose new robust methods for IDN models. Proposing new setting should be encouraged. However, the setting and conclusion should be reasonable.\n\nReferences:\n\n[1] D. Angluin and P. Laird. Learning from noisy examples. Machine Learning, 1988.\n\n[2] A. Menon, B. Rooyen, and N. Natarajan. Learning from binary labels with instance-dependent corruption. Machine Learning, 2018.\n\n[3] J. Cheng, T. Liu, K. Ramamohanarao, D. Tao. Learning with bounded instance-and label-dependent label noise. arxiv 1709.03768, 2017.\n\n[4] T. Xiao, T. Xia, Y. Yang, C. Huang, and X. Wang. Learning from massive noisy labeled data for image classification. In CVPR, 2015.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}