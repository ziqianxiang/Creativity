{
    "Decision": "",
    "Reviews": [
        {
            "title": "Well engineered solution, good results, somewhat limited novelty, could compare to prior art better",
            "review": "Summary: \nIn this paper the authors engineer a method for fully automatic de-identification, which can also be applied to videos by applying it separately frame-by-frame. The process utilizes an encoder-decoder architectures, which is trained using a combination of adversarial, reconstruction, and perceptual losses. The model also leverages features from a pre-trained face recognition model. Visually, the results look promising, but do occasionally contain some small artifacts or blurriness (albeit only noticeable when zoomed in). The de-identification process appears to work well, and with minimal change in the appearance of the face. Head pose and the majority of facial expression is also well preserved. Resulting images are evaluated using human evaluation and pretrained identity recognition models, which demonstrate quantitatively that de-identification is successful. Pixel-wise difference from the original image is also shown to be less compared to previous methods. Video samples look good and successive frames flow well with no visible flickering.\n\nPros:\n-face images appear to be successfully de-identified, while face pose and expression is preserved\n-produces smooth videos without flickering, even though applied per-frame\n-paper is well written\n-very good at including details needed for reproduction, such as hyperparameter settings\n-contains ablation study\n\nCons:\n-some faint blurriness still can be found in the resulting images \n-large number of hyperparamters that must be tuned\n-only compares with a single alternative de-identification method from 4 years ago (no comparison against modern GAN based methods)\n-ablation study has no quantitative metrics, so it is difficult to tell how much impact any individual component of the system had on the overall performance\n\nComments:\nWhile the proposed system achieves its goal of de-identified videos, its novelty is somewhat limited. Performance is achieved mainly through clever application of many existing methods, rather than any singular new idea or technique. That being said, I think that this work does present some significant improvement over previous de-identification methods, but it needs to prove it better. In the related work the authors mention several alternative de-identification methods, but they only compare with a single method from 2014. I think the paper could be made much stronger if the authors could compare against more recent techniques, especially those that also utilize an adversarial component. \n\nThe ablation study does a good job of demonstrating the impact of each component of the system visually. However, I think it could be improved if some quantitative metrics were included to measure how much improvement each component contributes to the overall performance of the system. \n\nQuestions:\nHow sensitive are the results to the hyperparameter settings? Does it require a lot of tuning in order to get good results, or is it fairly robust to the settings?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": " This work presents an adversarial encoder-decoder network architecture that is conditioned on the high-level representation of a person’s facial image for face de-identification that enables fully automatic video modification. The effectiveness of the proposed method is verified qualitatively and quantitatively. Although the novelty of the method is not impressive, the proposed method seems to be useful for face-related applications and the experimental results are convincing to me.",
            "review": " This work presents an encoder-decoder network architecture that is conditioned on the high-level representation of a person’s facial image for face de-identification that enables fully automatic video modification. The effectiveness of the proposed method is verified qualitatively and quantitatively. Although the novelty of the method is not impressive, the proposed method seems to be useful for face-related applications and the experimental results are convincing to me.\n\nPros:\n- This method is simple, apparently effective and is a nice use of adversarial encoder-decoder for a practical task. The paper is written clearly and the English is fine.\n\nCons:\n- My main concern with this paper is regarding the novelty. The authors seem to claim a novel GAN architecture by using an auto-encoder-based network architecture with a pre-trained face recognition network and multi-image perceptual loss. However, it is not clear to me what aspect of their GAN is particularly new.\n\n- Missing experimental comparisons with state-of-the-arts. The most recent work that compared in the Experiment section is the work of Samarzija & Ribaric (2014). Detailed experimental comparisons with more recent state-of-the-arts are needed to justify the superiority of the proposed method.\n\n- Missing ablation study and more in-the-wild comparisons in the Experiment section. The proposed framework contains several modules, an ablation study is needed to verify the separate contribution of each component. Moreover, more in-the-wild qualitative and quantitative experiments on recent benchmarks with large facial variations (e.g., expression, occlusion, blur, etc.) are needed to verify the efficacy of the proposed method.\n\nAdditional comments:\n- How did authors update each component and ensure stable yet fast convergence while optimising the whole GAN-based framework? \n\n- How did authors choose the value of \\alpha in Eq. (2-4)?",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Non-trivial results on an interesting problem",
            "review": "The submission proposes a method for face de-identification. \nA network is trained to transform an input face image to simultaneously stay close to the low- and mid-level representations  while maximising the distance of the high-level representation of the input image in a face recognition network. Additionally an adversarial loss and reconstruction losses both in terms of the input image as well as its horizontal and vertical gradients are employed.\nThe network learns to transform faces to be maximally different in identity from a given reference image while preserving low-level features. Thus, at inference the network can de-identify face images from arbitrary new people given a single reference image of each person.\n\nThe method is evaluated in three different ways. \na) It is shown that humans have difficulties discriminating between transformed and non-transformed videos.\nb) In a fine-discrimination experiment human subjects are asked to re-identify faces from a given reference image among five dark-haired caucasian males. The subjects could re-identify the images without face de-identification but had substantial problems after the transformation was applied.\nc) In a quantitative study it is shown that a state-of-the-art face recognition network cannot recognise faces of celebrities after the de-identification is applied while it recognise it fairly well before the transformation\n\nI have some questions and remarks:\n\n1.) How long are the videos used for evaluation a), what is the exact study protocol ?\n\n2.) Are the evaluation networks trained on the same dataset as the loss network? If yes it is not surprising that the generated images can fool the networks as they represent the same data as the loss network and I would like to see the evaluation for networks not trained on the same dataset as the loss network. \n\n3.) The method is optimised to maximise confusion of the identity while preserving low and mid level features. This leads to good de-identification if the set of identities from which to retrieve is densely sampled in the space of low-level features. I.e. if in the set of identities from which to identify a person there exist many people with similar low-level features. However, there are many conceivable scenarios in which the number of possible identities from which to retrieve is far smaller. To de-identify in such scenarios, it is necessary to apply much stronger transformations to the face to obscure the identity of a person. It would be great if this dependency between the strength of the transformation that needs to be applied and the reference set of identities from which to retrieve the identity of a given person could be explicitly discussed in the submission.\n\n4.) The emphasis on performance for video de-identification is somewhat misleading as the method does not seem to include any particular effort to explicitly improve video performance. It is great that the method also seems to work for video, but I cannot see strong evidence that it strongly outperforms pre-existing methods on video performance (they might also just work well out-of-the-box).\n\nNevertheless, I believe the submission addresses an interesting topic and shows non-trivial results. While I have some questions about the evaluation and minor concerns about the presentation I would overall recommend acceptance of the submission.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}