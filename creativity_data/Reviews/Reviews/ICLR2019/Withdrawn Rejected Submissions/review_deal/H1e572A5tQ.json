{
    "Decision": {
        "metareview": "The reviewers raised a number of concerns including the lack of clarity of various parts of the paper, lack of explanation, incremental novelty, and insufficiently demonstrated significance of the proposed. The authors’ rebuttal addressed some of the reviewers’ concerns but not fully. Overall, I believe that the paper presents some interesting extensions for multi-agent communication but in its current form the paper lacks explanations, comparisons and discussions. Hence, I cannot recommend this paper for presentation at ICLR.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Metareview"
    },
    "Reviews": [
        {
            "title": "Interesting extensions for multi-agent communication, it misses some baselines to illustrate the benefits of the contribution.",
            "review": "The authors present a multi-agent communication architecture where, agents can use targeted communication and can perform multiple communication steps. The paper is well written and easy to follow.\n\nComments:\n\n1) The idea of multi-stage communication is great, but the paper doesn't have a strong point to support this contribution. Could the authors illustrate the benefit of multi-stage e.g. vs. the communication channel width?\n\n2) In DIAL, the authors introduce a \"null\" action, what is the difference of that and multi-stage?\n\n3) It is not clear to the reader what is the contribution of targeted communication vs. non-targeted as it looks a solution to the mean-pooling. Could the authors include at least one more experiment with on an architecture that doesn't use mean pooling. From an architecture perspective there is a scalability benefit of using pooling, but if that's the only one it has to be made more clear.\n\n4) Following (3) based on Reddit there was a recent code release in python https://github.com/minqi/learning-to-communicate-pytorch. An alternative would be to evaluate TarMAC to one of the test beds, but the paper misses baselines.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "An interesting extension of the 'learning to communicate' work using targeted messages and multiple rounds of communication. ",
            "review": "The authors propose a new architecture for learning communication protocols. In this architecture each message consists of a key and a value. When receiving the message the listener produces an attention key that is used to selectively attend to some messages more than other using soft attention. This differs from the typical 'broadcasting' protocols learned in literature. \n\nQuestions / Comments: \n- Eqn (4) looks like a vanilla RNN. Did you experience any issues around exploding or vanishing gradients when doing multiple rounds of communication? Why not use a gated architecture here? \n- \"Centralized Critic\" section: This equation is from the COMA paper, ie. a centralised critic with policy gradients rather than DDPG. What did you use for the variance reduction baseline to estimate the advantage? Also, did you try conditioning the critic on the central state rather than the concat of observations? Formally this is required for the algorithm to be convergent. \n- How many independent seeds are the results averaged over? \n- The attention mechanism seems to provide very little value across all experiments: \n-- 84.9% vs 82.7% \n-- 89.5% vs 89.6% \n-- 64.3% vs 68.9% \nDid you check if any of these numbers are significant? This is my single biggest concern with the paper. Currently it's unclear whether attention is required at all in the settings presented. It would be good to see eg. the TarMAC 2-stage on the traffic junction (97.1%) ablated without attention.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Paper review",
            "review": "The authors present a study on multi-agent communication.\nSpecifically, they adapt communication to be targeted and multi-staged.\nExperiments on  2 synthetic datasets and 1 3D visual dataset confirm that both additions are beneficial\n\nOverall, this paper was somewhat clear and more importantly includes experiments on House3D, a more realistic dataset.\n\nMy main concern is the following: the method is not about targeting, but about selectively hearing.\nIf agents are sharing the reward then why should targeted communication be beneficial at all? Isn't the optimal strategy to just communicate everything to everyone? I understand that they should be selective at the listening side to properly integrate only the relevant information (so, attend over all received messages), but why should we expect the speaker to apriori know who this message should go to? Moreover, I don't really understand how targeted communication can even work (in the way the authors explain it) since the agents have partial information (e.g., in shapes they only see 5x5 around them), so they don't really know who is where --  but I could potentially see this working should the agents put information about their own identity and location.  So, given the positive results that the authors get, my understanding is that the signature doesn't have information about who should the recipient of the information be but more about what where the properties of the sender of this information.  So, based on my understanding, I don't feel that the flow of the story quite matches what is really happening and this might be very confusing for prospective readers. Can the authors elaborate on this, aim i getting things wrong?\n\nThere is literally no information about model size (or at least I wasn't able to find any). Is there any weight-sharing across agents? Do you obtain CommNets by using the implementations of the authors or by ablating the signature-part of your model? Moreover, why do agents have a limited view window on the SHAPES -- is (targeted) communication redundant when agents have full observability? The part about how multi-staged communication is implemented is quite cryptic at the moment -- is multi-staged the fact that the message is out-putted by processing with a recurrent unit? The messages is factorized into two parts k and u leading to a vector of size D -- what happens should we have one message of size D (rather than factorizing into 2), something like this would control for any improvements obtained from increases the parameters of the model.\n\nFinally,  if the premises of the paper is to define more effective communication protocols, evident in the use of continuous communication, (rather than studying what form can multi-agent communication etc etc), a necessary baseline  (especially in cases where agents share reward), is to communicate the full observation (rather than a function of it).  This baseline is not presented here and it's absolutely necessary.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}