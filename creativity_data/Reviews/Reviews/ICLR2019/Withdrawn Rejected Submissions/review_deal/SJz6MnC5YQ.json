{
    "Decision": {
        "metareview": "Although one reviewer recommended accepting this paper, they were not willing to champion it during the discussion phase and did not seem to truly believe it is currently ready for publication. Thus I am recommending rejecting this submission.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "No reviewer was willing to champion this work"
    },
    "Reviews": [
        {
            "title": "Novel idea but requesting clarifications. ",
            "review": "The paper presents a novel idea of generating discrete data such as graphs that is conditional on input data to control the graph structure that is being generated.\n\nGiven an input graph, the proposed method infers a target graph by learning their underlying translation mapping by using new graph convolution and deconvolution\nlayers to learn the global and local translation mapping.\n\nThe idea of learning generic shared common and latent implicit patterns across different graph structure is brilliant.\n\nTheir method learns a distribution over graphs conditioned on the input graph whilst allowing the network to learn latent and implicit properties. \n\nThe authors claim that their method is applicable for large graphs. However, it seems the experiments do not seem to support this. \n\nIt is not clear how the noise is introduced in the graphs. I would have expected to see some analysis and results on the translation quality over systematic noise applied to the input graph. \n\nIt is also not clear what are the assumptions made on the connectivity of the input graph and the target graph.\nDo we know how does the connectedness of the  input graph affect the translation quality in the case of strongly connected directed graphs? Or what happens if the target graph has a strong connectivity? Towards this, how does the computational complexity scale wrt to the connectedness?\n\nA lot of clarity is required on the choice of evaluation metric; for example choice of distance measure ?  What is the L1 norm applied on? \n\nI did not completely follow the arguments towards directed graph deconvolution operators. There is lack of clarity and the explanation seems lacking in parts in this particular section; especially since this is the key contribution of this work\n\nTypo:. The “Inf” in Tabel 1 \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Good problem setting, interesting results, needs more clarifications.",
            "review": "This paper addresses the important / open problem of graph generation, and specifically in a conditional/transductive setting.\n\nGraph generations is a new topic, it is difficult, and has many important applications, for instance generating new molecules for drug development.\n\nAs stated by the authors, this is a relatively open field: there are not many papers in this area, with most approaches today resorting to domain specific encodinings, or \"flattening\" of graphs into sequences to then allow for the use recurrence (like in MT); this which per se is an rather coarse approximation to graph topology representations, thus fully motivating the need for new solutions that take graph-structure into account.\n\nThe setting / application of this method to graph synthesis of suspicious behaviours of network users, to detect intrusion, effectively a Zero-shot problem, is super interesting.\n\nThe main architectural contribution of this paper are graph-deconvolutions, practically a graph-equivalent of CNN's depth-to-space - achieved by means of transposed structural matrix multiplication of the hidden GNN (graph-NN) activation - simple, reasonable and effective.\n\nWhile better than most of the baseline methods, the N^2 memory/computational complexity is not bad, but still too high to scale to very large graphs.\n\nResults are provided on relatively new tasks so it's hard to compare fully to previous methods, but the authors do make an attempt to provide comparisons on synthetic graphs and intrusion detection data. The authors do published their code on GitHub with a link to the datasets as well.\n\nAs previously mentioned in public comments on this forum, some points in the paper are not very clear; specifically regarding the loss function, the definition of \"edge-to-edge\" convolutions and generally the architectural choice related to the conditional GAN discriminator. Clarifications of these points, and more in general the philosophy behind the architectural choices made, would make this paper a much clearer accept.\n\nThank you!\n\nps // next my previous public comments, in detail, repeated ...\n\n--\n\n- the general architecture, and specifically the logic behind the edge-to-edge convolution, and generally the different blocks in fig.1 \"graph translator\".\n\n- how exactly do you do a L1 loss on graphs? I'd have to assume the topology of the graph is unchanged between Gy and T(Gx) ~ and then maybe take L1 of weight matrix? But then is this general enough ~ given your stated goal of modeling different topologies? Either ways, more explanation / and perhaps equations to clarify this loss would be very helpful. \n\n- why do you need a conditional GAN discriminator, if you already model similarity by L1? Typically one would use a GAN-D() to model \"proximity\" to the source-distribution, and then a similarity loss (L1 in your case) to model \"proximity\" to the actual input sample, in the case of trasductional domains. Instead here you seem to suggest to use L1 and GAN to do basically the same thing, or with significant overlap anyways. This is confusing to me. Please explain the logic for this architectural choice.\n\n-  could you please explain the setting for the “gold standard” experiment. I'd have to assume, for instance, you train a GNN in a supervised way by using both source (non-suspicious) and target (suspicious) behaviour, and label accordingly? That said I am not 100% sure of this problem setting.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting work with some odd issues on implementation and results",
            "review": "The paper presents an approach for translating graphs in one domain to graphs in the same domain using a GAN approach. A graph Translator approach is defined and a number of synthetic data sets and one real-world data set are used to evaluate the approach. Most of the paper is written well, though there are some odd sentence structure issues in places. The paper could do with a thorough check for grammatical and spelling mistakes. For example you miss-spell NVIDIA.\n\nThe main concerns with the work:\n1) Equation 2 is used to minimise the distance between graphs from X and graphs in Y. Yet, the main metric which is used to evaluate the paper is this distance. This would seem to give an unfair advantage to your approach. I would also be concerned about the fact that later you use this for stating if a graph represents good or hacker activity. If you have drawn translated graphs towards real graphs, how do you know that you haven’t pulled a good graph closer to a hacker graph? This is more concerning considering work which came out of NIPS which suggested that GAN’s tend to favour producing similar output rather than spreading it evenly over the domain.\n\n2) It isn’t entirely clear what your results are trying to show. Presumably P, R, AUC and F1 are generated from the results produced from your Discriminator? Were each of the other approaches optimised against your discriminator or not? Also, it is unclear as to what the Gold Standard method is - we’re only told that its a classifier, but what type and how constructed?\n\n3) Your approach seems to be ‘fixed’ in the set of nodes which are in both in the input and output graphs - needing to be the same. This would seem significantly limiting as graphs are rarely of the same node set.\n\n4) Although you comment on other graphs approaches being limited to very small graphs, you do not test your approach on graphs with over 150 nodes. These would also seem to be very small graphs in comparison to real-world graphs. Further evaluation on larger graphs would seem to be essential - how long would it take on graphs with 10^6 nodes?\n\n5) The real-world dataset seems rather odd and not fully explored. Given that you have this data it is surprising that you didn’t complete the loop by showing that you could take data from before a hack attempt and show that you could predict that in the future you had a hack attempt. Perhaps this is due to the fact that you didn’t have the ground-truth data in here to show a graph going from good to bad? But if not it would have been good to have shown, either through this data or some other, how your approach does match in with real-world results.\n\nGiven the points above, I would be very concerned on an approach which used the above to identify a future hacking attempt.\n\nSome more specific comments on the paper:\n- \"The tremendous success of deep generative models on generating continuous data like image and audio” - it is not clear what this continuous data is.\n\n- Hard to parse : “which barely can be available for the accounts worth being monitored.”\n\n- “This requires us to learn the generic distribution of theft behaviors from historical attacks and synthesize the possible malicious authentication graphs for the other accounts conditioning on their current computer networks” - given that these historical attacks are (hopefully) rare, is there enough data here to construct a model?\n\n- Please define GCNN\n\n- “Our GT-GAN is highly extensible where underlying building blocks, GCNN and distance measure in discriminator, can be replaced by other techniques such as (Kipf & Welling, 2017; Arjovsky et al., 2017) or their extensions.” - this sounds more like a feature of what you have contributed rather than a contribution in its own right.\n\n- In the context of synthetic data, what is ground-truth?\n\n- Hard to parse “Modern deep learning techniques operating on graphs is a new trending topic in recent years.”\n\n- Hard to parse “However, these methods are highly tailored to only address the graph generation in a specific type of applications such as molecules generation” \n\n- Hard to parse “Existing works are basically all proposed in the most recent year,”\n\n- “Typically we focus on learning the translation from one topological patterns to the other one” -> “Typically we focus on learning the translation from one topological pattern to the other”\n\n- It’s not clear in equation 1 how you represent G_X. Only much later is it mentioned about adjacency matrix.\n\n- Hard to parse “Different and more difficult than graph generation designed only for learning the distribution of graph representations, for graph translation one needs to learn not only the latent graph presentation but also the generic translation mapping from input graph to the target graph simultaneously.“\n\n- Hard to parse “graph translation requires to learn”\n\n- Hard to parse “in most of them the input signal is given over node with a static set of edge and their weights fixed for all samples”\n\n- “we propose an graph” -> “we propose a graph”\n\n- Hard to parse “The two components of the formula refers to direction filters as talked above”\n\n- Hard to parse “Next, graph translator requires to”\n\n- “as shown in Equations equation 7 and Equations equation 6,” -> “as shown in Equation 6 and Equation 7”\n\n- Hard to parse “The challenge is that we need not only to learn the”\n\n- Figure 2 would seem to need more explanation. \n\n- The end of section 3.3 is a bit vague and lacks enough detail to reproduce.\n\n- “our GT-GAN is able to provide a scalable (i.e., O(N2)) algorithm that can generate general graphs.” - what sizes have you tested this up to?\n\n- Hard to parse “we randomly add another kjEj edges on it to form the target graph”\n\n- “The goal is to forecast and synthesize the future potential malicious authentication graphs of the users without any historical malicious behaviors, by the graph translator from normal to malicious graph trained based on the users with historical malicious-behavior records.” - This isn’t entirely clear. Are you trying to create new malicious graphs or show that a current graph will eventually go malicious?\n\n- “All the comparison methods are directly trained by the malicious graphs without the conditions of input graphs as they can only do graph generation instead of translation.” - not clear. For the synthetic data sets how did you choose which ones were malicious?\n\n- “GraphRNN is tested with graph size within 150. GraphGMG, GraphVAE is tested within size 10 and RandomVAE is tested on graphs within size 150.” -> “GraphRNN and RandomVAE are tested with graph up to size 150. GraphGMG, GraphVAE is tested with graphs up to  size 10.”\n\n- “Here, beyond label imbalance, we are interested in “label missing” which is more challenging.” - “missing labels”?\n\n- “In addition, we have also trained a “gold standard” classifier based on input graphs and real target\ngraphs.” - need to say more about this.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}