{
    "Decision": {
        "metareview": "Dear authors,\n\nThe reviewers all appreciated the question you are asking and the study of the impact of each layer is definitely an interesting one.\n\nThey were however uncertain about the actual metrics you used to emphasize your points. Further, as you noted, there were quite a few presentation issues that led to skepticism of the reviewers, despite them spending quite a bit of time reading the paper and engaging in discussion.\n\nHence, I regret to inform you that your work is not yet ready for publication. A more focused analysis would be a great addition to the questions you raise.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "An interesting question but there are issues with the presentation and analysis"
    },
    "Reviews": [
        {
            "title": "Nice empirical study with a layerwise perspective on training/generalization",
            "review": "Pros:\nOverall, this is a nice empirical paper with a reasonably extensive set of experiments. It is interesting that, among networks that train to ~100% with Layca, the best generalizing ones tend to have balanced training between layers (Fig. 2), and that tuned SGD does not generalize as well as Layca (Fig. 4). I think this paper’s focus on discrepancies in training & generalization originating from layers of a deep network is an interesting and important topic of study that warrants further empirical and theoretical investigation from the community. I think the work already has some interesting results and will encourage further investigation.\n\nCons:\n--Would appreciate greater discussion of the originality of the results; in particular, a more upfront discussion (which is currently concisely presented in the supplementary) regarding algorithms that are similar to Layca when less crucial steps are dropped, e.g. Yu et al 2017 and Ginsburg et al 2018.\n--After reading the paper, I don’t feel especially convinced that rotation (of the flattened weight matrix) is the best quantity to analyze training dynamics of a single layer. Could there be greater discussion & motivation for this, and in particular, relationship to work where weights are parameterized using orthogonal matrices, or even orthogonal initialization?\n\nSome minor comments:\n--Would have appreciated a discussion of the learning rate schedule (as well as other experimental details, e.g. loss function used and what role this plays) and whether networks with lower learning rates would need to be trained longer.\n--Greater discussion of why the first and last layer(s) do not experience the same rotation rate as other layers and if there would be better generalization if they did.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "There are some interesting ideas but I am not yet convinced that the measured quantity is really the one we should care about",
            "review": "Paper summary: The authors propose layer rotation speed as a measure of layer-wise training speed and introduce the Layca optimizer as a means of enforcing uniform layer rotation speed throughout the network. They show empirically that layer rotation speed is linked to the generalization performance of deep neural networks and that weight decay induces uniform layer rotation speeds.\n\n\nDetailed comments:\n\nOverall, I felt that the paper introduced some interesting ideas but I was not left convinced that layer rotation speed is the correct measure of layer training speed. I hope that the authors can clarify this based on my questions and comments below.\n\n1) In the introduction you refer to input and feedback signals to a layer, I assume this refers to the forward and backward pass. As I understand it, this intuition and the findings of Figure 1 do not immediately relate to the notion of layer rotation speed during training. Could you clarify what you mean by \"the input and feedback signals that a layer receives could also influence the generalization ability induced by the layer's training\", to me this statement seems obvious as input+feedback signals contains training entirely.\n\n2) In Figure 1 you show that when training one chosen layer and keeping the others fixed, if the chosen layer is deeper into the network the test accuracy is worse. I wonder to what extent this might be remedied by initialization. For example, one might expect that when sampling random square matrices there are some very small eigenvalues which \"kill\" information in the forward pass. If we train a layer deep in the network it may have access to less information from the data than one earlier on. Whereas training an earlier layer could allow this layer to shift mass into the parts of the eigenspace which are well represented (so-to-speak) in the future layers. Have you thought about this at all? One simple way to evaluate this would be to initialize the weights to be random orthogonal matrices, ensuring that the eigenvalues are equal. With that said, I thought that this was an interesting experiment with a fairly surprising outcome!\n\n3) In related work you discuss the vanishing and exploding gradients problems in terms of layer-level training speed. I think that another relevant research direction may be dynamical isometry [1] which solves this problem by restricting all singular values of the Jacobian matrix to be close to 1. These ideas may also be relevant when discussing Layca and layer-rotation.\n\n4) I found section 3.1. a little unconvincing. It is not obvious to me that layer rotation speed is necessarily a good measure of training speed. In fact, there are many updates which have large cosine distance (as you define it) but do not change the network function (for example, permuting the weight matrices in fully-connected networks). Why is the rotation defined through a vectorization of the weight matrix as opposed to e.g. the polar decomposition? Is this a computational issue? Similarly, in section 3.2 you liken Layca to optimization on a manifold but I am not convinced that this makes sense for matrices which inherently have some structure (e.g, perhaps the Stiefel manifold would be more meaningful).\n\n6) Figure 2 shows that uniform rotation leads to improved test accuracy. But could it be the case that controlling the effective learning rate is sufficient (and layer rotation is one way to achieve this)? For example, we might take the sign of the update and use this to ensure that each weight matrix has the same effective learning rate (something like [2]). Do you expect this would have a similar effect? If not, what is unique about layer rotation that provides good test accuracy?\n\n7) You claim that SGD and adaptive methods with weight decay works without taking extra care to control the layer-rotation rate, as weight decay provides a similar effect. Firstly, you use weight decay and L2 regularization interchangeable, could you be explicit about exactly which you mean (see e.g. [3]). Assuming you mean weight decay (and not L2 regularization), then this could also be due to the effective learning rate ([4,5,6]) which may have some interaction with layer rotation rate (i.e. Figure 4). In summary, I would have liked to see an explanation for why weight decay leads to uniform rotation speeds.\n\n8) If I understand correctly, Figure 5 shows 5 tasks and reportedly 5 optimization schemes - each on a different task? It seems more reasonable to compare these on the same task.\n\nOverall I felt that the paper had some interesting contributions and a fairly comprehensive empirical study. However, I do not feel that the paper gives adequate attention to the notion of effective learning rate induced by weight decay and I was not totally convinced that the way layer rotation speed is defined is the correct way.\n\nMinor comments:\n\n- A lot of white space and a large caption for Figure 1.\n- Section 4 opens with \"monitor and control\", but I think the latter is really presented in section 4 and not section 3.\n- I think a diagram of the projection step of the Layca algorithm would be informative (for 2D weight vector).\n- Why does `5` appear in equation 1? Is this an arbitrary choice?\n- Some of the lighter colors in e.g. Figure 2(b) made some lines hard to read when printed. I do not believe that this affected the image significantly.\n\nClarity: The paper is well written and is easy to understand. Some of the figures in the experiments are a little cluttered and the lighter colors can be hard to see (e.g. Fig 2(b)), but this is minor.\n\nSignificance: The paper presents an interesting view point but I am not convinced that it offers as strong an explanation for these phenomena as other approaches. I believe with some more clarification the results could become more significant. My review score hinges mostly on the interaction between layer rotation speed and the effective layer-wise learning rate.\n\nOriginality: To my knowledge, the ideas are presented in the paper are original. In particular, this is a novel way to characterize layer-wise training speed.\n\n\nReferences:\n\n[1] Pennington et al. \"Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice\" https://arxiv.org/abs/1711.04735\n[2] Bernstein et al. \"signSGD: Compressed Optimisation for Non-Convex Problems\" https://arxiv.org/abs/1802.04434\n[3] Loshchilov et al. \"Fixing Weight Decay Regularization in Adam\", https://arxiv.org/pdf/1711.05101.pdf\n[4] Laarhoven, \"L2 Regularization versus Batch and Weight Normalization\" https://arxiv.org/abs/1706.05350\n[5] Hoffer et al. \"Norm matters: efficient and accurate normalization schemes in deep networks\" https://arxiv.org/abs/1803.01814\n[6] Anonymous, \"Three Mechanisms of Weight Decay Regularization\" https://openreview.net/forum?id=B1lz-3Rct7   (Another ICLR 2019 submission)",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Impressive theme and motivation, but limited contribution",
            "review": "This paper insists layer-level training speed is crucial for generalization ability. The layer-level training speed is measured by  angle between weights at different time stamps in this paper. To control the amount of weight rotation, which means the degree of angle movement, this paper proposes a new algorithm, Layca. This algorithm projects the gradient vector of SGD (or update vector of other variants) onto the space orthogonal to the current weight vector, and adjust the length of the update vector to achieve the desirable angle movement. This paper conducted several experiments to verify the helpfulness of Layca.\n\nThis paper have an impressive theme, the layer-level training speed is important to have a strong generalization power for CNNs. To verify this hypothesis, this paper proposes a simply SGD-variant to control the amount of weight rotation for showing its impact on generalization. This experimental study shows many insights about how the amount of weight rotation affect the generalization power of CNN family. However, the contribution of this paper is limited. I thought this paper lacks the discussion of how much the layer-level training speed is important. This paper shows the Figure 1 as one clue, but this figure shows the importance of each layer for generalization, not the importance of the layer-level training speed. It is better to show how and how much it is important to consider the layer-level training speed carefully, especially compared with the current state-of-the-art CNN optimization methods or plain SGD (like performance difference).\n\nIn addition, figures shown in this paper are quite hard to read. Too many figures, too many lines, no legends, and these lines are heavily overlapped. If this paper is accepted and will be published, I strongly recommend authors choose some important figures and lines to make these visible, and move others to supplementary material.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}