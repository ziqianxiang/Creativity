{
    "Decision": {
        "metareview": "This paper presents an interesting approach to image compression, as recognized by all reviewers. However, important concerns about evaluating the contribution remains: as noted by reviewers, evaluating the contribution requires disentangling what part of the improvement is due to the proposed approach and what part is due to the loss chosen and evaluation methods. While authors have done a valuable effort adding experiments to incorporate reviewers suggestions with ablation studies, it does not convincingly show that the proposed approach truly improves over existing ones like Balle et al. Authors are encouraged to strengthen their work for future submission by putting particular emphasis on those questions.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting work but important evaluation concerns remain"
    },
    "Reviews": [
        {
            "title": "interesting approach; good MS-SSIM results; lacking insights / MSE evaluation",
            "review": "Adaptive Sample-space & Adaptive Probability (ASAP) lossy compressor is proposed. ASAP is based on neural networks.\nASAP jointly learns the quantization width and a corresponding adaptive quantization scheme. Some steps are similar to Nakanishi et al. 2018.\nASAP with the bpp x (1-MS-SSIM) x MSE loss improves in terms of MS-SSIM over Rippel & Bourdev 2017 and Nakanishi et al. 2018 on Kodak and RAISE-1k datasets.\n\nThe idea of jointly learning the quantization width and the adaptive quantization is interesting and the MS-SSIM results are good.\n\nThere is an inconsistency between section 2.2.2 and Fig. 7. I would expect in Fig. 7 also the result for the objective function from eq (6). In Fig. 7 could be added also a reference approach (such as BPG or a learned method).\n\nBy comparing Fig.7 and Fig.2  and Nakanishi et al., I suspect that the improvement of ASAP over Nakanishi et al., comes mainly from the change in the objective function and not from the proposed ASAP core? \n\nThe paper should include/discuss also the paper of \nBalle et al., \"Variational image compression with a scale hyperprior\", ICLR 2018\n\nThe authors target only MS-SSIM, however it is unclear to me why.\nAccording to Balle et al, ICLR 2018 and also to the recent CLIC challenge at CVPR18, learning for MS-SSIM or for PSNR / MSE leads to results that are not necessarily strongly correlated with the perceptual quality. MS-SSIM does not strongly correlate to the perceptual quality, while PSNR / MSE is a measure of fidelity / accuracy towards a ground truth. \n\nI would like to see a comparison in PSNR / MSE terms with BPG and/or Balle et al., ICLR 2018.\n\nI would like to see a discussion on the complexity, design, runtime, and memory requirements for the proposed approach in comparison with the other learned methods.\n\nAlso, it would be good to see more visual results, also for higher bpp.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Overall score 7",
            "review": "1. An ASPA coding method was proposed in this paper for lossy compression, which achieves the state-of-the-art performance on Kodak dataset and RAISE-1k dataset.\n\n2. What is the difference on the architecture used in the proposed method and other compared methods? Since various numbers of layers or neurons lead to very big differences on the resulting performance.\n\n3. Besides, it seems that the proposed method for compressing images includes more complex calculations. Is it faster or slower than others?\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Is it the loss or the quantization that matters?",
            "review": "The paper proposes Adaptive Sample-space & Adaptive Probability (ASAP) coding for image compression based on neural networks. In contrast to most prior methods, which adhere to a fixed quantization scheme (i.e. with fixed number of quantization levels, and fixing the level themselves), the proposed method jointly learns a probability model of the quantized representation (the bottleneck of an autoencoder model) for coding and a corresponding adaptive quantization scheme. The distribution of each entry in the bottleneck before quantization is modeled as a Gaussian, whose mean and variance are predicted by a neural network conditionally on bottleneck entries on a grid at different scales (similar as in Nakanishi et al. 2018). The same network also predicts quantization intervals to adaptively quantize the respective entry of the bottleneck. Together, the predicted means, variances, and quantization intervals are used to obtain an estimate of the code length. The proposed compression networks are trained with a novel multiplicative loss, showing clear improvements over prior methods Rippel & Bourdev 2017, Nakanishi et al. 2018 on the Kodak and Raise1k data sets in terms of MS-SSIM.\n\nPros:\n\nThe results presented in this paper seem to be state-of-the-art, and innovation on quantization, which has not attracted a lot of attention in the context of neural network-based image compression is a welcome contribution. The method also seems to outperform the recent method [1], which should be included for comparison.\n\nQuestions:\n\nA major issue is, however, that it is unclear from the results whether the gains are due to the novel quantization system, or due to the novel loss. From Fig. 7 it looks like the loss BPP + \\lambda (1-MS-SSIM) (assuming the formula in (6)) is correct, and the legend in Fig. 7 incorrect) that is used in most other works performs essentially on par with  Rippel & Bourdev 2017, Nakanishi et al. 2018. For example at 1 bpp, this loss yields an MS-SSIM of 0.992 which is essentially the same as Rippel & Bourdev 2017, Nakanishi et al. 2018 obtain, cf. Fig. 2. To show that the improvement is due to the learned quantization and not just because of the loss (8) an ablation experiment should be done. One could e.g. train the proposed method with the same predictor, but without the employing the learned quantization scheme, and compare to the results obtained for the proposed method.\n\nFurthermore, a better understanding of the loss (8) would be desirable. How is the MSE factor justified?\n\nAlso, it would be good to present visual examples at rates 0.1-1.0 bpp. All visual examples are at rates below 0.08 bpp, and the proposed method is shown to also outperform other methods at much higher rates.\n\n\n[1] Ball√©, J., Minnen, D., Singh, S., Hwang, S.J. and Johnston, N. Variational image compression with a scale hyperprior. ICLR 2018.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}