{
    "Decision": {
        "metareview": "The paper presents a multi-scale extension of the hourglass network. As the reviewers point out, the paper is below ICLR publication standard due to low novelty (i.e., multi-scale extension is not a new idea) and significance (i.e., not a significant performance gain against the state-of-the-art method or other baselines).",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "decision"
    },
    "Reviews": [
        {
            "title": "Minor novelty",
            "review": "In this paper a method for pose estimation is proposed, which is based on the well known neural model “stacked hourglass networks”. The novelty in the proposed paper is a multi-scale formulation, which creates multiple scales from the input image and feeds them into different hourglass modules. The different scales are weighted differently, where the weights for a given scale depend on the error obtained on previous scales.\n\nImportant issues:\n\nThe novelty seems to be not sufficient to me, as multi-scale solutions are not new in computer vision and have been applied a lot in pose estimation as well, be it deep neural models or older techniques. In particular in deep models, multi-scale techniques have been proposed extensively for resolution preserving image to image mappings (which is done here), beginning with quite “old” techniques (in deep learning time scales) going back to 2012 (Farabet, C., Couprie, C., Najman, L., LeCun, Y., 2012. Scene parsing with multiscale feature learning, purity trees, and optimal covers. In: ICML.), or formulations which integrate scales and layers, starting with hyper-columns in 2015 (Hypercolumns for object segmentation and fine-grained localization, CVPR 2015) and many more recent variants.\n\nIn 2018, multi-scale formulations are now standard techniques in computer vision with deep networks. I am not sure how the proposed method makes a difference. Also, I am wondering whether there shouldn’t be some parameter sharing between the models of the different scales, as is often done in the literature now to reduce model capacity.\n\nThe way the multi-scale Since different resolutions are created is particular. Why not just simply subsample the input images to different resolutions? Why are these trained layers needed as a preprocessing?\n\nWeighting different scales is not fundamentally new. We also don’t know whether it improves performance, it is not part of the ablation study.\n\nThe method has been compared to several methods, but which are not state of the art anymore. Most papers are from 2016, the field advanced quickly. The performance gains of the multi-scale formulation are pretty low, and overally, the method is not state of the art on the targeted benchmark. Obviously I do not want to say that a paper needs to be state of the art on a benchmark to get published, even at a top-level conference, far from it. However, if the methodological and theoretical contribution of the paper is rather minor, than the performance and evaluation should be flawless.\n\nMinor remarks:\n\nThe writing of this paper is somewhat fuzzy, using non-standard technical language, which I could not decipher and which seems to me somewhat misleading. Examples are:\n\n- “the stacked hourglass network theoretically increases the stacked depth”: how does theory tell us anything about depth in this context?\n\n- “difficult to form differentiated and determined collaboration mechanisms for each stacked hourglass”: I don’t understand what this means, simply. This phrase is also repeated several times in the paper in different places\n\n- “information loss caused by the functional consistency of hourglass networks”: I don’t understand what functional consistency means here, and why it leads to information loss.\n\nThe description of Algorithm 1 does not seem to be necessary to me. It basically follows from the equations 4-6, which are executed in order and per layer. \n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Ok but incremental",
            "review": "Summary: \n\nThis paper proposes a modification to the original hourglass network for single pose estimation using (1) a preprocessing network to generate multiscale feature maps (2) a upgrade of hourglass network backbone (3) using a adaptive loss weighting strategy. It yields some improvements over the original baseline. \n\nCons: \nThe method is somewhat incremental with respect to original work and only compares algorithm 2 years ago without comparing to current SOTA methods. \n\nBy checking the online benchmarks of MPII, the Tang et al., ECCV'18 results has already reach 92.8 while the proposed one is 91.2, which is significant lower than other SOTA strategies. \n\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Authors extends stacked hourglass network with inception-resnet-A mudules and a multi-scale approach for human pose estimation in still RGB images. Given a RGB image, a pre-processing module generates feature maps in different scales which are fed into a set of serial stack hourglass modules each responsible for a different scale. Authors propose an incremental adaptive weighting formulation for each stack-scale-joint. They evaluate proposed architecture on LSP and MPII datasets.",
            "review": "Authors extends stacked hourglass network with inception-resnet-A mudules and a multi-scale approach for human pose estimation in still RGB images. Given a RGB image, a pre-processing module generates feature maps in different scales which are fed into a set of serial stack hourglass modules each responsible for a different scale. Authors propose an incremental adaptive weighting formulation for each stack-scale-joint. They evaluate proposed architecture on LSP and MPII datasets.\n\npositive:\n- Having an adaptive weight strategy is a necessary procedure in multi-loss functions where cross-validation or manual tuning of fixed weights are expensive. While the weights are functions of the loss, it is not analyzed and evaluated thoroughly, e.g. evolution of weights for each joint-stack-scale. Even it is not given in the section 5.2.1. So it is hard to judge effectiveness of the proposed loss. \n\nnegative:\n- In general experiments section is the most weakness of the paper. I comment some points in the following:\na) Multi-scale image processing is not a novel idea in computer vision and specifically in human pose estimation. The authors have not compared their methods with most recent papers in the literature and I believe the results are not state-of-the-art (see [1] for instance which is a multi-scale approach).\nb) What is the effect of each scale in the results and for each joint? This must be analyzed and shown visually or numerically.\n\n- The number citations is not enough.\n\n- The writing must be improved.\n\noverall:\nRegarding mentioned comments, I believe the paper needs a huge extra effort (both analytically and numerically) to be adequate for publication. Therefore, I recommend rejection.\n\n\n[1] Yang, W., Li, S., Ouyang, W., Li, H., Wang, X.: Learning feature pyramids for human pose estimation. In: ICCV. (2017)",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}