{
    "Decision": {
        "metareview": "Though the overall direction is interesting,  the reviewers are in consensus that the work is not ready for publication (better / larger scale evaluation is needed, comparison with other non-autoregressive architectures should be provided, esp Transformer as there is a close relation between the methods). ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "interesting direction but not ready for publication"
    },
    "Reviews": [
        {
            "title": "A well-motivated work, but relations to prior works need to be addressed",
            "review": "This paper draws inspiration from recent works on graph convolutional networks and proposes GTCN, a convolutional architecture for language modeling. The key intuition is to treat sentences as (potentially densely-connected) graphs over tokens, instead of sequences as in many RNN-based language models. The model then, when predicting a token, summarizes previous tokens using attention mechanism as context. Empirical evaluation on word-level language modeling on Penn Treebank shows competitive performance.\n\nThe idea of this work appears reasonable and well-motivated to me. But the connections to previous works, especially those based on self-attention, should be clearly addressed. Further, writing can be improved, and I would encourage a thorough revision since there are typos making the paper a bit hard to follow.\nLast but not least, I find several of the claims not very-well supported. Please see details below.\n\nPros:\n- Well-motivated intuition treating language as structured.\n\nCons:\n- Writing can be improved.\n- Missing discussion of existing works. \n\nDetails:\n\n- Based on my understanding of Eqs. 6--11, the proposed GTCN seems to be a gated version (also equipped with window-2 convolutions) of the self-attention mechanism. Could the authors comment on how GTCN relates to Vaswani et al. (2017), Salton et al. (2017), among others? Also, empirical comparisons to self-attention based language models might be necessary.\n\n- I was confused by Eqs. 13--14 and the text around it. Doesn't one need some kind of classifier (e.g., an MLP) to predict x_{t+1}? Why are these two equations predicting word embedding?\n\n- The start of Section 4.1. There seems to be a typo here. I'm assuming the two vectors are `$\\mathbf{v}$ and $\\mathbf{q}$` here, as in Eqs. 6 and 7.\n\n- More clarification on Eq. 9 might be necessary. Is \\mathbf{W}^p part of the parameters? I'm guessing \\mathbf{W}_{i-j}^p selects a row from the matrix, since there is a dot product outside.\n\n- Can the authors clarify Eq. 5? I'm not sure how to interpret it, and it seems not used anywhere else.\n\n- Eq. 2 is a bit misleading: it might give the impression that f_{t+1} does not depend on f_t (and so forth), which is not the case for LSTM.\n\n- It would be interesting to be how GTCN compare to other models in efficiency, since the paper mentions parallel computation many times.\n\n- Contribution.2: GTCN is not really the state-of-the-art model on LM.\n\n- Comparison to RNNG: RNNG treats each sentence as a separate sequence, in contrast to most cited works in Table 1, where the whole training (eval) set is treated as a single sequence, and truncate the length when applying BPTT. And according to the second paragraph of Section 5.1, this work follows the latter. To the best of my knowledge, such a difference does have an effect on the perplexity metric. In this sense, RNNG is not comparable to the rest in Table 1. It is perhaps fine to still put it in the table, but please clarify it in the text.\n\nMinors:\n\n- Why is the margins above equations seem larger. Can the authors make sure the template is right?\n\n- Around Eq.5: why is \\mathbf{X} is capitalized in the eq, but not in the text? Are they the same thing?\n\n- Section 4.3: the dependence of attention weights $a$ is not reflected in the notation.\n\n- Section 5.1: I think what it means here is a `10K` vocabulary, instead of a 10K word tiny corpora.\n\n\nReferences\n\nVaswani et al.. 2017. Attention is All You Need. In Proc. of NIPS.\n\nSalton et al.. 2017. Attentive Language Models.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting but requires more experiments",
            "review": "This work proposes a CNN based language model based on graph neural networks. Basic idea is to compute adjacency matrix for an entire sentence in parallel for faster computation. Empirical results show probably the best performance among CNN approaches but still lags behind the best RNNs.\n\nPros:\n\n- A new network based on graph neural networks.\n\nCons:\n\n- The proposed model needs to recompute attention probabilities for each step and it might incur latencies. I'd like to know how slow it is when compared with other CNN approaches and how fast it is when compared with other RNNs.\n\n- Lacking experiments. This paper shows only a single table comparing other approaches, and does not present any ablation studies. Note that section 4.4 mentions some details, but does not show any numbers to justify the claim, e.g., why choosing the window size of 10, 20, 30, 40.\n\n- This paper claims that the learned model captures the ground truth parse tree in section 4.3. However, this work simply picks a single example in section 5.3 to justify the claim. I'd recommend the author to run a parser to see if the proposed attention mechanism actually capture the ground truth parse trees or not.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "official review",
            "review": "The paper applies graph convolutional networks to Penn Treebank language modeling and provides analysis on the attention weight patterns it uses.\n\nClarity: the paper is very clearly written!\n\nThe introduction states that existing CNN language models are \"not easily interpretable in that they do not explicitly learn the structures of sentences\". Why is this? The model in this paper computes attention values which is interpreted by the authors as corresponding to the structure of the sentence but there are equivalent means to trace back feature computation in other network topologies as well.\n\nMy biggest criticism is that the evaluation is done on a very small language modeling benchmark which is clearly out of date. Penn Treebank is the CIFAR10 of language modeling and any claims on this dataset about language modeling are highly doubtful. Models today have tens and hundreds of millions of parameters and training them on 1M words is simply a regularization exercise that does not enable a meaningful comparison of architectures.\n\nThe claims in the paper could be significantly strengthened by reporting results on at least a mid-size dataset such as WikiText-103, or better even, the One Billion Word benchmark.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}