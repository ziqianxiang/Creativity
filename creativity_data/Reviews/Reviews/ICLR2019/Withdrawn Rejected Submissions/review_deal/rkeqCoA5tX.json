{
    "Decision": {
        "metareview": "The paper proposes two simple generator architecture variants enabling the use of GAN training for the tasks of denoising (from known noise types) and demixing (of two added sources). While the denoising approach is very similar to AmbientGAN and could thus be considered somewhat incremental, all reviewers and the AC agree that the developed use of GANs for demixing is an interesting novel direction. The paper is well written, and the approach is supported by encouraging experimental results on MNIST and Fashion-MNIST.\nReviewers and AC noted the following weaknesses of the paper: a) no theoretical support or analysis is provided for the approach, this makes it primarily an empirical study of a nice idea. \nb) For an empirical study, the experimental evaluation is very limited, both in terms of dataset/problems it is tested on; and in terms of algorithms for demixing/source-separation that it is compared against. \nFollowing these reviews, the authors added the experiments on Fashion-MNIST and comparison with ICA which are steps in the right direction. This improvement moved one reviewer to positively update his score, but not the others.\nTaking everything into account, the AC judges that it is a very promising direction, but that more extensive experiments on additional benchmark tasks for demixing and comparison with other demixing algorithms are needed to make this work a more complete contribution.\n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Interesting and promising novel approach for demixing, but with no theoretical grounding and limited experimental evaluation"
    },
    "Reviews": [
        {
            "title": "Review",
            "review": "In this, paper a GANs-based framework for additive (image) denoising and demixing is proposed. The proposed methodology for denoising largely relies on the Ambient GAN model and hence the technical contribution of the paper in this task appears to be limited. Regarding demixing, as explained in the comments below, the proposed model appears to be superficial in the sense that neither theoretical analysis nor thorough empirical evaluation is provided. The proposed method is evaluated on both tasks (i.e., denoising and demixing) by conducting toy experiments on handwritten digits (MNIST).\n\nMore specifically, the authors employ the Ambient GAN to train a generator that generates clean samples when the type of corruption is known (i.e., when corruption is modelled by a known function which interacts with the clean data in an additive way). For denoising, the authors propose to learn the latent variable that generates the clean test image by solving a ridge regularized non-convex inverse problem (Eq. 3). The problem is solved via gradient descent and theoretical analysis on the converge of the algorithm is not provided.  Clearly, this approach has limited practical applications since the corruption function needs to be known which rarely happens in practice.\n\nNext, considering additive demixing, the authors assume that the corruption/structured signal is unknown but it can be modelled using a convolutional network (using the architecture of DCGAN). They employ the same network architecture for modelling the clean data generation process and learn the parameters of both generators using adversarial training. Demixing is performed by solving a similar by solving a similar ridge regularized non-convex inverse problem as in the case of denoising (i.e., Eq. 4). As authors mention in the paper, it is indeed surprising that the proposed GANs-based model with two generators is able to produce samples from the distribution of each signal component by observing only additive mixtures of these signals. Without any assumptions, the proposed model is not identifiable. This is my main concern regarding this paper and a theoretical investigation is definitely needed. My main questions revolve around under what conditions the column spaces of the two generators are mutually independent and what is the type of components structure that the proposed model can recover. \n\nAs mentioned above, the experimental evaluation is limited to the NMIST dataset while comparisons with existing related models such as RPCA and ICA that work efficiently and with guarantees in the additive setting studied in this paper are considered essential in order to prove empirically the merits of the proposed framework. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Extension of AmbientGAN on denoising and demixing problemsï¼Œ but experiments are not sufficient",
            "review": "This paper proposed two new GAN structures for learning a generative modeling using the superposition of two structured components. These two structures can be viewed as an extension of AmbientGAN. Experiments results on MNIST dataset are presented. Overall, the demixing-GAN structure is relatively novel. However, the potential application seems limited and the experiment result is not sufficient enough to support the idea. Detail comments are as following,\n\n\n1.\tIt seems there are no independent assumption imposed on the addition of two generators. It is possible that the possible model only will works on simple toy example, where the distributions of two structured components are drastic different. Or the performance will be affected by the initialization.  It would be nice if the author test this on more realistic examples, such as the source separation problem in acoustic or the unmixing problem in hyper-spectral images. More detail information about the experiments setting, such as the methods used to initialize the two generators are need. \n2.\tIn the experiment part, it would be nice to have Quantitive results presented, for example PSNR for denoising. Simple comparison with several traditional methods could also help understanding the advantage of the model.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "contribution, but experiments lacking",
            "review": "Quality is good, just a handful of typos.\nClaritys above average in explaining the problem setting.\nOriginality: scan refs...\nSignificance: medium\nPros: the authors develop a novel GAN-based approach to denoising, demixing, and in the process train generators for the various components (not just inference). Further, for inference, the authors propose an explicit procedure. It seems like a noveel approach to demixing which is exciting.\nCons: The experiments do not push the limits of their method. It's difficult to judge the demixing 'power' of the method because it's difficult to tell how hard the problem is. Their method seems to easily solve it (super low MSE). The classification measure is clearly improved by denoising, which is totally unsurprising-- There should definitely be comparison with other denoising methods.\n\nIn general, they don't compare to any other methods. Actually in the appendix, comparisons are provided for a basic compressive sensing problem, but their only comparator is \"LASSO\" with a \"fixed regularization parameter\", and vanilla GAN. Since the authors \"main contribution\" (their words) is demixing, I'm surprised that they did not compare with other demixing approaches, or try on a harder problem. Could you  give some more details about the LASSO approach? How did you choose the L1 parameter?\n\nI have another problem with the demixing experimental setting. On one hand, both the sinusoids and MNIST have \"similar characteristics\" in the sense that they are both pretty sparse, basically simple combinations of primary curves. This actually makes the problem harder for a dictionary learning approach like MCA (referenced in your paper). On the other hand, both signals are very simple to reconstruct. For example, what if you superimposed the grid of digits onto a natural image? Would you be able to train the higher resolution GAN to handle a more difficult setting? The other demixing setting of adding 1's and 2's has a similar problem.\n\nThe authors need to provide (R)MSE  results that show how well the method can reconstruct mixture components on average over the dataset. The only comparison is visual, and no comparators are provided.\n\nConclusions:\nI'm actually torn on this paper. On one hand this paper seems novel and clearly contributes to the field. On the other hand, HOW MUCH contribution is not addressed experimentally, i.e. the method is not properly compared with other denoising or demixing methods, and definitely not pushed to its limits. It's hard to assess the difficulty of the denoising problem because their method does so well, and it's hard to assess the difficulty of demixing because of the lack of comparators.\n\nCaveats:\nI am knowledgeable about iterative optimization approaches to denoising and demixing, especially MCA (morphological component analysis), but *not knowledgeable about GAN-based approaches*, though I have familiarity with GANs.\n\n*********************\nUpdate after author response:\nI think the Fashion-MNIST experiments and comparisons with ICA are many times more compelling than the original experiments. I think this is an exciting contribution to dually learning component manifolds for demixing.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}