{
    "Decision": {
        "metareview": "The paper trains a classifier to decide if a program is a malware and when to halt its execution. The malware classifier is mostly composed of an RNN acting on featurized API calls (events). The presentation could be improved. The results are encouraging, but the experiments lack solid baselines, comparisons, and grounding of the task usefulness, as this is not done on an established benchmark.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting application of DRL, but too confuse presentation and too little experimental for the task and results"
    },
    "Reviews": [
        {
            "title": "Possibly useful malware detector but unclear paper and uncharacterized black box labels in dataset",
            "review": "This paper attempts to train a predictor of whether software is malware. Previous studies have emulated potential malware for a fixed number of executed instructions, which risks both false negatives (haven’t yet reached the dangerous payload) and false positives (malware signal may be lost amidst too many other operations). This paper proposes using deep reinforcement learning over a limited action space: continue executing a program or halt, combined with an “event classifier” which predicts whether individual parts of the program consist of malware. The inputs at each time step are one of 114 high level “events” which correspond to related API invocations (e.g. multiple functions for creating a file). One limitation seems to be that their dataset is limited only to events considered by a \"production malware engine\", so their evaluation is limited only to the benefit of early stopping (rather than continuing longer than the baseline malware engine). They evaluate a variety of recurrent neural networks for classifying malware and show that all significantly underperform the “production antimalware engine”. Integrating the event classifier within an adaptive execution control, trained by DQN, improves significantly over the RNN methods. \n\nIt might be my lack of familiarity with the domain but I found this paper very confusing. The labeling procedure (the \"production malware engine”) was left entirely unspecified, making it hard to understand whether it’s an appropriate ground-truth and also whether the DRL model’s performance is usable for real-world malware detection. \n\nAlso, the baseline models used an already fairly complicated architecture (Figure 3) and it would have been useful to see the performance of simple heuristics and simpler models. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "DRL for malware control",
            "review": "The paper proposes an approach to use deep reinforcement learning to halt execution in detecting malware attacks. The approach seems interesting, there are some problems.\n\n1. There is no good justification of using DRL to the problem. Action space is only continue and halt. Besides there should be no effect to the result by the previous action. So I don't think DRL is a good selection.\n2. Experiments are weak. There is no detailed comparison to other existing works. Only one dataset is used.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "using REINFORCEMENT LEARNING for NEURAL MALWARE CONTROL",
            "review": "This paper uses deep reinforcement learning (DRL) for malware detection. It can get better performance than LSTM or GRU based models.\n\nDeep reinforcement learning (DRL) has already used for classification or detection. I am not sure about the main contribution of this work. The new application of DRL can not convince me.\n\nAs the dataset is not a public dataset, it is difficult to evaluate the performance. As for the comparing models, i think some CNN based methods should be included. If the task is a detection, i think some attention methods should also be investigated and compared. LSTM combined with attention should already be well investigated in other classification/detection tasks.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}