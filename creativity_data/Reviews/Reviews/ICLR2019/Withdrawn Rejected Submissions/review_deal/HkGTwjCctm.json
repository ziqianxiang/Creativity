{
    "Decision": {
        "metareview": "This paper studies change-point detection in time series using a multiscale neural network architecture which contains recurrent connections across different time scales. \n\nReviewers were mixed in this submission. They found the paper generally clear and well-written, and the idea of adding a multiscale component to the model interesting. However, they also pointed out weaknesses in the related work section and found the experimental setup somewhat limited. In particular, the paper provides little to no analysis of the learnt features. Taking these assessments into consideration, the AC concludes this submission cannot be accepted at this time. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting ideas, but insufficient insight and novelty"
    },
    "Reviews": [
        {
            "title": "Could be interesting but biased in many aspects ",
            "review": "The paper presents an interesting approach to change point detection. I agree we need more general model to capture the change. However, unfortunately, they did not place the contribution correctly with respect to existing literature. The comments for prior work seem to be highly biased. For instance,  in Section 2, \"these methods either have unrealistic assumptions, such as defining changes as a large difference in covariance matrix\". I would like to comment that, covariance change can capture a large number of changes in real applications and these are not unrealistic assumptions. \n\nThe \"pyramid\" recurrent neural network seems to be a extension of RNN using the idea of multi-scale structure. Could be interesting.\n\nThe paper gives too much emphasis on the \"merit\" of the neural networks on capturing the change patterns. However, there is a very important aspect been ignored or hiding: in order to train neural networks to capture anomaly patterns, since neural networks are highly over-parameterized model, usually there won't be a large number of samples for anomalies. Therefore, in many situations, it is simply unpractical to train neural networks to capture post-change samples. \n\nThere is a large body of literature on change point detection in statistics etc. (the author mentioned one, Chen and Zhang 2015, more over, the comment that \"they can only detect abrupt change\" is wrong, the method is quite general).\n\nThe paper fails to have any comparison with existing methods. For instance, how does the proposed method compare with hoteling T-square statistic, or CUSUM statistic, or generalize likelihood ratio statistic, or MMD statistic (non-parametric approach)? Without any comparison, it does not make sense to claim proposed method is superior. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Nice model with somewhat lacking experimental validation.",
            "review": "This paper proposes a pyramid based neural net which both decomposes a signal into several scales (learning the basis functions to do that) and processes the resulting bands in a scale invariant manner. The method is applied to 1D signals with underlying processes occurring at different time scales where the task is change point detection.\n\nPros:\n* Nice model and model formulation - learning the basis functions both for the low and high frequency is a nice idea. I also liked the way weights are shared across scales. In particular that the information flow between consecutive scales is shared, as well as through time.\n\n* Writing is very clear and method is well motivated\n\nCons:\n* I found the experimental validation a bit limited - the presented results are nice and for the problem quite comprehensive but I would have wanted something a bit more complicated than change point detection. Specifically, since the natural world is full of scale free phenomena it would have been much more interesting with other tasks (generative models? natural images? many options). I feel this would have made the case for the paper much stronger.\n* There's also very little analysis of what is learned from the data - how do the kernels look like and how do they correspond to known wavelets? to the data? would be nice to understand what's going on here.\n\n\nBottom line:\nI like the proposed model and for what it is it's quite good but it would have been a much more convincing paper with more experiments demonstrating the power of the method and analyzing it.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting deep architecture for multi-variate time series modeling, lacks proper comparison with existing literature",
            "review": "1. This papers leverages the concept of wavelet transform within a deep architecture to solve the classic problem (especially for wavelet analysis) of change point detection. The authors do a reasonably comprehensive job of demonstrating the efficacy of the proposed framework using various synthetic and real data sets with both gradual and abrupt changes\n\n2. The concept of pyramid network idea is not really new, in the context of CNN it has been established quite well. The paper should highlight this fact by citing papers such as \"Lin, Tsung-Yi, et al. \"Feature Pyramid Networks for Object Detection.\" CVPR. Vol. 1. No. 2. 2017.\" \n\n3. Involving wavelet transforms in deep nets have been done before. This paper attempts to learn wavelet transform parameters by involving them as trainable layers. But even this kind of idea is also emerging in the community. Papers such as \"Fujieda, Shin, Kohei Takayama, and Toshiya Hachisuka. \"Wavelet Convolutional Neural Networks.\" arXiv preprint arXiv:1805.08620 (2018)\" need to be discussed in this context. \n\n4. The biggest issue in my mind is that I feel \"Chung et al 2016\" is still a very similar framework as the proposed one. While authors argue that it uses more like CNN architecture and the proposed method may pick up the multi-scale features better, comparison with this seems to be most appropriate. This will also clearly identify the benefits of the wavelet structure to the filters and multi-resolution analysis approaches.\n\n5. RCNN term has been used for CNN+RNN architecture. This may not be a good terminology to use since RCNN is a very popular term referring to Region based CNN for detection and localization purposes.\n\n6. AUC metric, I believe is the - area under ROC curve, this needs to be spelled out, how it is computed? at least in the Appendix\n\nxxxxxxxxxxxxxxxxxxx\n\nAppreciate the authors' rebuttal, updated my score.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}