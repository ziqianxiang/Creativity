{
    "Decision": {
        "metareview": "The paper addresses an important problem of supervised learning for predicting graph connectivity using both node features and the overall graph structure. The paper is clearly written, and the presented approach produces promising results on synthetic data. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. We hope the authors will use the suggestions of the reviewers to further improve the paper. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "A heuristic approach for graph learning, evaluated on synthetic data  only "
    },
    "Reviews": [
        {
            "title": "A heuristically designed method for learning graph networks",
            "review": "This papers presents a supervised method to learn from network data. The method alternates two steps: a node embedding step (using convolutions) and an adjacency matrix update (using local convolutions or fully connected layers). These steps are stacked forming a NN that is used to represent the learning steps. The objective function is composed of a linear combination of typical losses such as cross-entropy, intersection over union and other regularization terms. The linear coefficients are treated as hyper-parameters. The methods are evaluated on graph generation and edge prediction tasks, showing results comparable to the state-of-the-art.\n\nOverall, the paper is clearly written and addresses an important problem. However, I found the proposed method rather heuristic and not very well theoretically principled. Why should one use the proposed architecture (stacking learning steps)? What is the latent structure that this method is trying to learn, a particular sequence of graphs? Which one? Where do the supposed benefits come from? In general, both the architecture and loss (or combination of losses) need to be better justified.\n\nRegarding experiments, on the positive side, the authors consider a representative set of methods. However, the tasks are too simple. I miss some sensitivity analysis, e.g., on the different loss functions or the number of layers. It is not clear how the method scales on the size of the networks and the depth of the layers.\n\nminor:\n\n- specify better how the ground truth is used in the objective\n- How was the noise added? uncorrelated noise over the features?\n- the loss function is referenced before being presented\n- \"set of node embedding\" -> \"set of node embedings\"",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "review": "This paper proposes a supervised learning method for predicting the connectivity of a graph based on both the features of nodes in the graph as well as the overall graph structure, rather than just the structure of the graph or just the node features. The approach is evaluated on two synthetic datasets, a “community” dataset and a “geometric figures” dataset.\n\nUnfortunately, I do not think this paper as it stands currently is ready for publication at ICLR for the following reasons: (1) the comparison and discussion with prior literature is lacking; (2) the experiments are rather weak; and (3) the significance and novelty of the method itself seems limited.\n\n1. I am very surprised there was no discussion of [1] (or even better, a comparison to), which is another method which uses information about the full graph (via message-passing) to infer the connectivity of the graph in an unsupervised way. The discussion of the literature on graph neural networks in general is a bit weak, missing important references such as [2-4]. Such approaches, especially message-passing style approaches like [4], do exactly what the current paper suggests has not been done: they make predictions based on information in the nodes while considering the structure of the graph as a whole (via message-passing). Although [4] does not explicitly make edge predictions the approach is straightforward to generalize to making edge predictions, see [5].\n\n2. The experiments in the paper only test the proposed method on very toy domains, and thus feel weak. The results in Table 2, for example, suggest that the proposed method has reached ceiling-level performance and thus to really tell the difference between GLN_f, GLN_c, and any other methods, more difficult problems are called for. The geometric figures dataset, in particular, does not seem to me like it would test the claim that the paper would like to make: that it is important to take into account the fully structure of the graph when predicting edges. Indeed, there is a very simple rule that can be applied in the geometric figures case which does not use global graph information (if the two nodes have the same color, connect them, if they are different colors, do not connect them). It is therefore unsurprising that GLN_c actually does slightly better than GLN_f (according to Table 2) on geometric figures.\n\nAdditionally, the experiments do not provide much insight into the architecture itself. For example, the present architecture is meant to repeat the embedding and link-prediction steps some number of times, and in the experiments it seems that these steps are repeated four times. But how important is the repetition in practice? It would be nice to see the effect of repetitions on final performance, to demonstrate whether this is in fact an important component of the model or not. Similarly, there are several different loss functions but it is not obvious to what extent these losses contribute to the final performance of the model. It would be nice if there could be some ablation studies that train the model with different combinations of losses to see which are actually important.\n\n3. Finally, I have some concerns about the model itself. If I understand correctly, both f_l and c_l depend on a number of learned parameters which is a function of the number of nodes in the graph. This is unfortunate, as one of the strengths of the graph neural network approach is that GNNs usually have a number of parameters that is independent of the size of the graph, thus allowing GNNs to scale to graphs of arbitrary size. However, that is not the case in this model. Moreover, the architecture of f_l and c_l do not seem particularly novel. f_l just involves passing the node embeddings through a MLP to produce the link predictions. c_l involves something closer to message-passing, though where weighted combinations are learned on a per-node basis (rather than sharing the same function across all nodes). This could be interesting, even though it sacrifices the scale-free nature of GNNs, if it could be shown to actually outperform existing GNN approaches on more realistic datasets. However, given the lack of experiments demonstrating this, it is hard to say how significant the approach is.\n\n[1] Kipf, Fetaya, Wang, Welling & Zemel (2018). Neural Relational Inference for Interacting Systems. ICML 2018.\n[2] Gori, M., Monfardini, G., and Scarselli, F. (2005). A new model for learning in graph domains. IJCNN 2005.\n[3] Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., and Monfardini, G. (2009). The graph\nneural network model. IEEE Transactions on Neural Networks, 20(1):61–80.\n[4] Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and Dahl, G. E. (2017). Neural message passing for quantum chemistry. arXiv preprint arXiv:1704.01212.\n[5] Battaglia, P. W., Hamrick, J. B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi, V., ... Pascanu, R. (2018). Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Heuristic method without real data application.",
            "review": "Authors propose a supervised method for predicting adjacency matrix for a set of points. Loss function consists of 4 terms: intersection over union loss with respect to target adjacency, cross entropy loss, symmetry penalty and L2 regularization of parameters. Learning process consists of alternating node feature updates parametrized by GCN-like layers and updates of the adjacency matrix (different across layers).\n\nMy main concern is the heuristic nature of the method without any successful real data application. I do not see this work as impactful or of interest to ICLR community.\n\nDirectly regarding the content I have following comments and questions:\n\nWord \"structure\" seems to be used in several meanings. For example \"We consider the problem of predicting the structure of a given set of points (which we assume are the nodes of a graph) and an initial structure (connections of the points).\" It only becomes somewhat clear later what is actually the learning problem studied in this paper.\n\n\"The learned convolutions\" - convolution is a particular mathematical operation. I believe authors should refer to the weights of their architecture instead.\n\nSymmetry penalty of equation 14 seems unnecessary. When optimizing for symmetric matrix it should be recognized that corresponding symmetric entries are identical variables. Hence it is sufficient, and mathematically appropriate, to correct the gradient computed without symmetric consideration. Correction is simply sum of the gradient with itself transposed (without diagonal entries).\n\n\"We compare against traditional generative models for graphs: mixed-membership stochastic block models (MMSB) \" - could you please elaborate on how you use MMSB for graph generation. The use-case I am familiar with is community detection.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}