{
    "Decision": {
        "metareview": "Reviewers mostly recommended to reject. Please take reviewers' comments into consideration to improve your submission should you decide to resubmit.\n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Paper decision"
    },
    "Reviews": [
        {
            "title": "Bayesian view on deep network binarization - interesting idea but lacks in clarity and experiments",
            "review": "The paper treats network binarization as learning a bernoulli probability that each weight is 0 or 1. It uses a hierarchical approach to factor the probability in to parameters shared between weights/kernels/layers. The result is a network that can be used to sample a binary network. The main novelty is that full-precision weights are not needed during training. \n\n- There is a variance issue underlying this idea. The goal is to find a binary network that has high performance, but the probabilistic formulation could have a high variance in terms of the performance of the resulting binary networks. In the experiments, the variance is not shown, rather the authors sample 100 networks and pick the best one based on validation set accuracy? (they just say \"pick the best one\"). Should this be accounted for in the objective function? The prior has very high variance (p=0.5). The authors claim that this \"demonstrates the versatility\" -- how?\n- Related to the above, there is a high variance associated with he REINFORCE estimator. In the appendix, the authors use a baseline value to alleviate this, but no discussion is provided in the main text or the experiments.  \n- For the stochastic version of binary connect, the authors report the best out of 100 trials. I would rather like to see the mean and confidence intervals, for this as well as the proposed method.\n\n- Please provide a comparison of the number of hyper parameters used vs the number of binary network parameters. Is it feasible to store the \"master network\" in memory for small devices? It seems you need more parameters than the original network as you have weight specific parameters + kernel/filter/layers specific parameters? Is there any generalization between these hyperparameters that can be shown in experiments e.g. using a compact hierarchy?\n- More generally, how do you see this method being used in practice? Do you sample each binary network on the device? \n- How is this better than other methods of training binary nets, which have better accuracy than your approach (according to Table 2)?\n- In the experiments, the hierarchical structure used for hyperparameters is not clearly described. \n\n- I found the exposition in Section 3.2 to be very confusing using f(*)  whereas it is very simply described in words. The policy network is hierarchical upon layers/filters/kernels/weights. What is \"s\" in equations (1) etc.?\n- In Section 3.3, I found the connection to MDPs tenuous, whereas it is easy to understand that you are using REINFORCE to estimate the gradient of the expectation. \n- The pseudo-reward is completely ad-hoc. Since this is a \"1-step MDP\" (bandit problem?), the reward is maximized when the probability of w=1 is related to the sign of the gradient. In the end, we seem to have arrived at something that is basically similar to BinaryConnect (i.e. using the sign of the gradient). \n- Only experiments with an uniform prior are shown. Can the prior be used in some ways?\n\n- In the experiments, the activation functions used are not described. \n- Some numbers are missing in Table 3.\n- One advantage of TernaryConnect is that it allows sparsity by allowing zero weights, whereas binary nets only allow +/- 1 weights. That is, Ternary Connect should not be dismissed simply and the performance of Ternary Connect should be shown on all the datasets.\n- The error for VGG on CIFAR-10 is very high compared to SOTA (close to 94% accuracy). \n- The legend on Figure 3 is not readable, the font size can be increased. \n- Page 1 \"regardless of the availability ...\" - citation needed. \n- Page 2, experiments are not a separate contribution.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Need clarification on the experimental setting",
            "review": "This paper proposes to binarize all parameters of a CNN where the binary parameters are generated from another policy neural network (let's call it parameter generator). The parameter generator network has a special nested structure to regularize parameters within layers and filters. All parameters in CNN and parameter generator network are jointly trained. Since the gradient is hard to back propagated through binary variables, the paper adopts reinforcement learning approach to back-propagate rewards to the parameter generator. \n\nThe experiments look solid. The results show that the proposed approach is slightly worse than BinaryConnect (baseline) on MINST, CIFAR10 and CIFAR100, but outperforms BinaryConnect on ImageNet by a large margin. The ablation study also verified the need for the proposed nested parameter structure.\n\nThe paper is well written. The proposed method (1) is able to provide the posterior distribution of parameters so that we can use that in other applications such as confidence estimation and model selection (2) is memory and power efficient due to binarization. \n\nHaving said that, the experimental setting falls short. For the proposed method, the paper samples 100 binary networks from the parameter generator and pick the best one, which seems not correct. The results of the proposed method should be based on the average of these 100 binary networks, rather than picking the best one, because we won't be able to know which binary network is the best. Using the best one seems label leakage to me. For now, I'll give the benefit of doubt. Please clarify this during the feedback phase.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "learning binary weight neural networks using a structured variational approximation, gradients estimated using modified reinforce",
            "review": "Summary: The paper considers a variational inference strategy for learning neural networks with binary weights. In particular, the paper proposes using a structured recognition model to parameterise the variational distribution, which couples the weights in different layers/filters in a non-trivial way. The gradient of the expected likelihood term in the variational lower bound is estimated using the REINFORCE estimator. This paper adjusts this estimator to use the gradient of the log-likelihood wrt the samples. Experiments on several image classification tasks are provided.\n\nevaluation:\n\npros:\n- the idea of the proposed approach is interesting: using variational inference for binary weight neural networks. While recent work on VI for discrete variables only focused on discrete latent variable models, this work shows how VI can be used for binary neural networks.\n \ncons:\n- the writing, in my opinion, needs to be improved [see my comments below]. The VI presentation is cluttered and the justification of using the pseudo-reward for reinforce is not clear.\n- the experimental results are mixed and it's not clear to me how to interpret them/compare to the baselines -- what is the goal here: computational efficiency, compression or accuracy?\n\nSome specific questions/comments:\n\n+ What is the input of the policy/recognition network? It's not clear from the paper whether this includes the inputs of the current batch or outputs or both? If so, how are variable batch sizes handled? What is the input to this network at test time? In contrast to generative models/VAEs, the weights here are global parameters and it's not clear to me these should be varied for different data batches.\n\n+ related to the question above: how is prediction handled at test time? Say the parameters of the variational distribution over weights are generated using the recognition network, then 100 weights are sampled given these parameters which then give 100 predictions -- should these be then averaged out to get the final prediction? I'm not quite sure I understand why the paper chose to *pick the best one* out of 100 predictions and the justification/criterion for this procedure.  \n\n+ The writing is not very clear at places, and it does not help that the references being merged with the text. I'm also not sure about some of the technical jargons/terms used in the papers:\n- reinforcement learning: is this really a reinforcement learning problem? If you tackle this problem from a pure variational perspective, reinforce is used to obtain the gradient of the expected log-likelihood wrt the variational parameters. But instead of using the log likelihood, a learning signal that depends on the gradient of the log-likelihood is used.\n- concrete weights -- what are these? I assume they are just binary weights sampled from the variational approximation.\n- middle of page 3: p(w|X, Y) = p_\\theta(w): this is not precise as p_\\theta(w) is only an approximation to the exact posterior, which then allows us to lower bound the log marginal likelihood. \"common practice in modern variational approximation\": This is the standard way of deriving the lower bound and has been used for many years.\n\n+ the reinforce estimator tends to have high variances since it does not make use of the gradient of the function in the expectation. This paper adjusts the vanilla estimator with a learning signal that involves the gradient. Could you comment on the bias/variance trade-off of the resulting estimator? Much of recent literature on learning discrete variables, as far as I understand, propose ways to not to have to use the vanilla reinforce, for example Concrete, Relax or rebar, albeit the focus on latent variable models.\n\n+ model selection and uncertainty measure: the paper mentions these potential advantages of the proposed approach over deterministic binarisation schemes, but does not fully explore and test these.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}