{
    "Decision": {
        "metareview": "This paper shows convergence of stochastic gradient descent  for the problem of learning weight matrices for a linear dynamical system  with non-linear activation.  Reviewers agree that the problem considered is both interesting and challenging. However the paper makes many simplifying assumptions - 1) both input and hidden state are observed, a very non standard assumption, 2) analysis requires increasing activation functions, cannot handle ReLU functions. I agree with R2 and think these assumptions make the results significantly weaker. R1 and R3 are more optimistic, but authors response does not give an insight into how one might extend this analysis to the setting where hidden state is not observed. Relaxing these assumptions will make the paper more interesting. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "ICLR 2019 decision"
    },
    "Reviews": [
        {
            "title": "Interesting result on learning a non-linear dynamical system",
            "review": "This work considers the problem of learning a non-linear dynamical system in which the output equals the state.  Under several assumptions (input is Gaussian, non-linear activation is strictly increasing, stable system) it is shown that SGD converges linearly to the ground truth system with near-optimal sample complexity. The proof idea is to reduce this problem to the problem of learning a single non-linear neuron in the case that the covariance matrix of the data is well-conditioned. The main challenge is to show the covariance is well-conditioned under the reduction. In a nutshell, this is done by splitting the trajectory to sub-trajectories with independent states and using results from random matrix theory on matrices with independent rows.\n \nThis work tackles a very challenging problem and the results are interesting. The guarantees are strong – linear convergence to the ground truth parameters and near-optimal sample size. Given that not much is known on deep non-linear networks, I think that the result is significant. The main weakness of the paper is the assumption that the state equals the output. Another minor weakness is the clarity and presentation of results:\n1.       The proof outline of the main result is hard to follow. There is no proof outline of Theorem 4.2 in the main text. The proof is highly technical and there are many technical ideas that were moved to the appendix. For instance, the proofs in sections C and D are not mentioned in the main text. I suggest to write a summary of the steps required to prove the main result and how all of the technical ideas are combined together.\n2.       There is no reference and comparison to the paper of Mei et al. [1] that study single neuron models.\n3.       It is claimed that by increasing beta the convergence is faster. However, I am not sure why this is meaningful. By changing beta the ground truth changes as well. For beta = 0 the ground truth dynamical system is linear and for beta = 1 the ground truth is a non-linear dynamical system with ReLU. Since a ReLU network is more expressive, generally in the case of beta = 1 the ground truth is more difficult to learn than beta = 0. Therefore, we should expect convergence to be slower than beta=0 or not occur at all. Am I missing something?\n4.       The Gaussian assumption is not stated clearly in the text. It can be deduced only from the statements of the theorems and the conclusion section.\n5. In Theorem F.1, it is claimed that all rows of E are equal. However, in the statement of the theorem it is not mentioned that the rows of A are identically distributed. Should this assumption be included in the statement?\n\n[1] Mei, Song, Yu Bai, and Andrea Montanari. \"The landscape of empirical risk for non-convex losses.\" arXiv preprint arXiv:1607.06534 (2016).‏ \n\n\n-----------Revision------------------------\n\nI am not changing the score. I disagree with AnonReviewer2 regarding the significance of the results.  The assumption that the states are observed is indeed a weakness of the paper. However, understanding non-linear dynamical systems is extremely challenging and this paper provides strong convergence guarantees. Furthermore, there are several insights in the analysis that may be useful in future work.\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting and challenging problem, but assumptions weaken the results",
            "review": "This paper studies the ability of SGD to learn dynamics of a linear system + non-linear activation. That is, in the standard LTI setting, the dynamics of a system evolve according to\n\nh_{t+1} = Ah_t + Bu_t,\n\non input u_t.\n\nIn addition, this paper considers the setting where the evolution is:\n\nh_{t+1} = \\phi(Ah_t + Bu_t)\n\nfor \\phi a non-linear activation function. \n\nThis is a difficult problem. Though system identification was for many decades a large and active area in the control community, the understanding of system identification from a modern statistical perspective (understanding sample complexity and computational complexity simultaneously) is surprisingly lacking. This is evidenced by the fact that the first results along these lines for the simplest possible (SISO, LTI) system, came only recently (Hardt, Ma, Recht ’16). \n\nThis paper attacks a more general setting, due to the presence of the nonlinearity.\n\nHowever, the present setting is significantly limited in another sense: the authors assume that the state is observed directly. This is in contrast to the typical situation where we observe only a projection of the state, or possibly even a noisy such projection. Indeed, this is one of the critical complications in the work of Hardt, Ma and Recht. Without it, i.e., under the assumption that the entire state trajectory can be directly observed, much more is possible, and indeed much more has been done. For example, work by Bento, Ibrahimi and Montanari ’10, solves a more difficult problem in that they estimate sparse dynamics (in appropriate sample complexity). Jalali and Sanghavi ’11 generalized the work of Bento et al., to the setting where some of the components of the state are not all observed, but rather some are latent.\n\nThe motivating application for this work is estimating RNNs. In this case, the state variable represents the critical information that is carried from one time to the next in the RNN. Presumably the setting here is to show that if indeed data are generated by an RNN, then we can compute this using SGD and backprop. Towards this, the assumption of having access to the internal state is a difficult one. On the one hand, this is a hard and important problem. On the other, we really won’t have access to such an internal state. There are of course other problematic aspects, such as robustness, the inability to use ReLU (Defn 3.1). But the observation model seems important. Again, I believe this is especially so, because the considerable complications present in Hardt, Ma, Rect ’16 specifically seemed to be a consequence of the observation model being partial.\n\nThe inability to use ReLU at first look does not seem like a great limitation. But then one problematic aspect here seems that the proof concept and direction critically rely on this, as they basically reduce to the setting of linear activations — something which, presumably, is impossible for something like ReLU. So it is not only the results, but also the developed machinery, that seem to be inherently limited.\n\nThis is, overall, an interesting paper, attacking an important and also very challenging area. As with all papers in this vein, we are left with having to make a judgement call on whether this simplified scenario is indeed a good first step towards solving the problems we are hoping to solve. Is it developing the right insight, right tools, etc. While I find there is a lot of interesting and good work in this paper, I am not completely convinced about this last point.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Good convergence result for non-convex dynamic problem under stable system condition",
            "review": "The paper studies discrete time dynamical systems with a non-linear state equation.  They assume the non-linear function is assumed to be \\beta-increasing like leaky ReLU. Under this setting, the authors prove that for the given state equation for stable systems with random gaussian input at each time step, running SGD on a fixed length trajectory gives logarithmic convergence.\n\nThe paper is well-written and proves strong convergence properties. The deterministic result does not seem very novel and uses the idea of one-point strong convexity which has been studied in various prior works. However the bounding of the condition number of the data matrix is interesting and guarantees are near-optimal. The faster convergence for odd activations is a good observation. Overall, I think the paper is good. I do list some concerns:\nQuestions/concerns:\n- The deterministic theorem (Theorem 4.1) seems similar to Theorem 3 in [1] with SGD instead of GD. Also under the distribution being symmetric, it can be derived from [2] with $k=1$. \n- Can the ideas be extended to other commonly used activations such as ReLUs/Sigmoids? Sigmoids have exponentially small slope near origin.\n- The proof seems to rely on the fact that due to the gaussian input added each time step and stable system assumption after a sufficient number of time steps, the input-output pairs will not be highly correlated. So the data is sufficiently uncorrelated taking enough data. What happens if this data at each step is not gaussian?\n- In the unstable setting, the solution proposed just samples from different trajectories which by default are independent hence correlation is not an issue, this seems a bit like cheating. \n- In RNNs, the motivation of the work, the hidden vectors are not observed, thus this setting seems a bit restrictive.\n- If SGD was performed on only one truncated series, do the results still hold?\n\nOther comments:\n- There has been previous work on generalized linear models which work in more general settings like GLMtron [3]. The authors should update prior work on generalized linear models as well as neural networks.\n- Typo on Page 2 y_t = h_{t+1} not y_t = h_t.\n\n[1] Dylan J. Foster, Ayush Sekhari, and Karthik Sridharan. Uniform Convergence of Gradients for Non-Convex Learning and Optimization. NIPS 2018.\n[2] Surbhi Goel, Adam Klivans, and Raghu Meka. Learning One Convolutional Layer with Overlapping Patches. ICML 2018.\n[3] Sham M. Kakade et al. Efficient learning of generalized linear and single index models with isotonic regression. NIPS 2011.\n\n\n--------------\nI would be maintaining the same score. I agree that the paper has nice convergence results that could possibly be building steps towards the harder problem of unobserved hidden states however, there is more work that could be done for unstable systems and possible extension to ReLU and other activations to take it a notch higher. ",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}