{
    "Decision": {
        "metareview": "The paper describes  a method for the link prediction problem in both directed and undirected hypergraphs.  While the problem discussed in the paper is clearly importnant and interesting, all reviewers agree that the novelty of the proposed approach is somewhat limited given the prior art.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting and important problem, somewhat limited novelty of the approach"
    },
    "Reviews": [
        {
            "title": "Interesting problem, but incremental contribution",
            "review": "[Relevance] Is this paper relevant to the ICLR audience? yes\n\n[Significance] Are the results significant? somewhat\n\n[Novelty] Are the problems or approaches novel? rather incremental\n\n[Soundness] Is the paper technically sound? yes\n\n[Evaluation] Are claims well-supported by theoretical analysis or experimental results? marginal\n\n[Clarity] Is the paper well-organized and clearly written? okay\n\nConfidence: 2/5\n\nSeen submission posted elsewhere: No\n\nDetailed comments:\n\nIn this work, the authors propose an approach to the (hyper-) link prediction problem in both directed and undirected hypergraphs. The approach first applies an existing dual transformation to the hypergraph such that the link prediction problem (in the primal) becomes a node classification problem in the dual. They then use GCNs to classify the (dual) nodes. Experimentally, the proposed approach marginally outperforms existing approaches.\n\n=== Major comments\n\nI found the novelty of the proposed approach rather limited. The proposed approach essentially just concatenates three existing strategies (dual reformulation from Scheinerman and Ullman, GCNs from Kipf and Welling, and negative sampling which is common in many communities, e.g., Han and Chen, but many others, as well). I believe the contribution for link prediction in directed hypergraphs is a more novel contribution, however, I had difficulty following that discussion.\n\nIt is difficult to interpret the experimental results. Tables 3 and 6 do not include a measure of variance. Thus, it is not clear if any of the results are statistically significant. It is also not clear whether the “10 trials” mentioned in the figure captions correspond to a 10-fold cross-validation scheme or something else. It is unclear to me what the random feature matrix for the metabolic network is supposed to me or do. It is also unclear to me why “fake papers” are needed for the citation networks; it is clear that “fake author lists” are needed for negative sampling, but it seems they could be attached to existing papers. Similarly, it is unclear how the set of candidate edges (\\mathcal{E}) was chosen.\n\nI appreciate that the authors made the code available. I did not run it, but I did have a look, and I believe it could be adapted by others without an unreasonable amount of work.\n\n=== Minor comments\n\nThis work is very similar to the arXiv submission 1809.09401. To the best of my knowledge, though, that work has not yet been published in a peer-reviewed venue, so I do not consider it a problem that it is not cited here.\n\nAccording to Tables 1 and 2, iAF692 and iHN637 datasets are smaller than the other datasets except DBLP; those two are also less dense than DBLP. According to Table 3, NHP-U seems noticeably better than SHC and CMM on the, while does not appear very significant in the other cases. Is there some relationship between NHP’s performance and the size/density of the graph? or is there some other explanation for this behavior?\n\nRelated to the above point, Table 3 shows that the performance on the undirected versions for those two datasets is better than on the other two metabolic networks, while Table 6 shows the opposite for the directed versions. Is there some explanation for this? For example, are there qualitative differences in the size of the hypernodes?\n\nThe described strategy for negative sampling seems as though it selects “easy” negative samples, in the sense that they are far away from observed positives; thus, they are also likely far away from any sort of decision boundary. How does the performance change if more “difficult” (or just uniformly random) negative samples are chosen?\n\nI believe Recall@100 (or Precision@100, or @$\\Delta E$, etc.) is a more meaningful value to report in Tables 4 and 7, rather than the raw number of edges. That is, it would be more helpful to report something so that numbers across datasets are at least somewhat comparable.\n\n=== Typos, etc.\n\nIn Equation (4), the “k” index in d_{ijk} is in {1,2}, but in the text, it is in {0,1}.\n\n“table 2” -> “Table 2”, and many other similar examples throughout the paper.\n\n“higher-order etc.” -> “higher-order, etc.”\n“GCN based” -> “GCN-based”, and similar in several places in the paper\n“a incomplete” -> “an incomplete”\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Interesting and important problem; technical contribution is limited given existing work.",
            "review": "This paper proposed Neural Hyperlink Predictor (NHP) to perform link prediction based on graph convolutional network (GCN). Following prior work, the hyperlink prediction is perform in the dual hypergraph, where each node represents a hyperlink in the primal hypergraph. The original problem is then equivalent to a simple node classification problem. To deal with directed hyperlink, a separate term is added to distinguish heads from tails.\n\nThe problem of link prediction in hypergraph is important and interesting, especially in the chemistry domain. However from the technical point of view, this work is somewhat incremental since prior work has done link prediction using GCN (Zhang and Chen, 2018). The idea of performing hyperlink prediction in the dual hypergraph is not new, either (Lugo-Martinez and Radivojac, 2017). As for the directed hypergraph setting, it seems to be a straightforward extension once one knows how to do in the undirected setting (adding an extra term to classify head/tail).\n\nIn terms of experiments, given the similarity between Lugo-Martinez and Radivojac, 2017 and NHP (both operates in the dual hypergraph), it would be better if the former could also be used as a baseline, as least in the undirected setting.\n\nIt is reasonable to have a subset of links as candidate reactions in the metoboli network datasets. For CORA and DBLP, it is not clear where the ‘actual papers’ and ‘candidate papers’ come from. For example in CORA there are 1072 authors; yet there are only 5416 candidate papers.\n\nIt seems the joint learning of NHP-D does not improve the accuracy in the directed setting as claimed in Sec. 5.2. Besides, there is no baseline in the directed setting. It is difficult to appreciate the performance in Sec. 6. One thing one can do is to use previous methods in the undirected setting, e.g., CMM, with the extra term L_d in Eq. (4).\n\nMinor comments:\nTypo: \nP5: atleast -> at least\nP5: What is GCN 2?\nSec. 5: ‘p = 32 in 1’ and ‘shown in 2’\n\nMissing references on link prediction and/or deep learning:\nDiscriminative relational topic models. PAMI 2014.\nRelational deep learning: A deep latent variable model for link prediction. AAAI 2017\nNeural relational topic models for scientific article analysis. CIKM 2018.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Novelty of the proposed method is very marginal",
            "review": "This paper proposed to use graph convolutional neural networks for link prediction. The authors proposed to use the dual graph to simultaneously learn node and edge embeddings. The label of the edges (positive or negative) are used as supervised signal for training the GCNs. Experiments on a few small data set prove the effectiveness of the proposed approaches.\n\nStrength:\n- important problem\n\nWeakness:\n- the novelty of the proposed method is very marginal\n- the experiments are quite weak\n\nDetails:\n- the novelty of the proposed method seems to be very marginal, which simply applies the GCN for link prediction. The existing GCN based method for recommendation shares similar ideas (e.g., Yin et al. 2018, PinSage), though dual hypergraph is not used. But the essential idea is very similar. \n- the data sets used in the experiments are too small\n- the node embedding based methods should be compared for link prediction, e.g., DeepWalk, LINE, and node2vec.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}