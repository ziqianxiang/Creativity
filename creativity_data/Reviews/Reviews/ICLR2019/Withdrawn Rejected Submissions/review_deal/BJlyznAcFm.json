{
    "Decision": {
        "metareview": "The paper presents a novel architecture, reminescent of mixtures-of-experts,\ncomposed of a set of advocates networks providing an attention map to a\nseparate \"judge\" network. Reviewers have several concerns, including lack\nof theoretical justification, potential scaling limitations, and weak\nexperimental results. Authors answered to several of the concerns, which did\nnot convinced reviewers. The reviewer with the highest score was also the least\nconfident, so overall I will recommend to reject the paper.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "meta-review"
    },
    "Reviews": [
        {
            "title": "Interesting idea but not convincing",
            "review": "This paper presents a novel concept of supervised learning, advocacy learning. In this framework, supervised learning procedure is given by two subnetworks, advocates and judge. Advocates generate evidence in the form of attention for individual classes and judge decide the final class labels.\n\nThe main idea looks interesting, and the paper is clear enough to deliver the idea. However, this paper has the following major issues.\n\n1. There is no formal justification of the idea. Although the idea looks interesting, there is no theoretical background and no clear intuition.\n\n2. Experiment is weak and even inconsistent. Evaluation is performed on very small datasets only, where all baseline methods already show very high accuracy and accuracy gain given by the proposed method is very marginal. In particular, Table 1 and 2  have inconsistent results; advocacy network is better in Table 1 while worse in Table 2 compared to honest advocacy network. To make the idea more convincing, it is required to test it on much larger datasets, at least ImageNet scale, and more desirable to show results in other tasks such as object detection and image segmentation.\n\n3. I am not sure if advocacy network has any separate supervision to enforce it to be learned in a class-conditional manner. Also, in honest advocacy network, each subnetwork can look at only a part of dataset (data corresponding to the class), and I wonder if there is any problem given by data deficiency issue.\n\nOverall, the paper does not look ready for publication because the idea is clearly justified neither theoretically nor empirically.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "The paper proposes a novel network architecture for classification problems that is based on decomposing the network into two parts classed the advocates and the judge. The advocates learn by competing with each other to provide a judge-convincing \"evidence\" -- an attention map over the input that supposedly highlight the most class-relevant parts of the input.\nI find the very general idea interesting because it could potentially help to improve interpretability of neural networks by explicitly putting in the network a corresponding bottleneck.\nHowever, in its current form the approach has a number of drawbacks:\n\n1) The input to the judge network scales linearly with the number of classes which potentially prevents from learning on large-scale datasets such as ImageNet.\n2) The attention / saliency map might be very difficult to compute for complex data if relies an autoencoding-like computation. \n3) There is no guarantee or an intuition on why would the advocates learn to provide evidences that are interpretable to humans. \n\nThe provided experiments are conducted on rather simple datasets and to argue on wide applicability of the method I suggest using more visually-diverse datasets like Cifar. \nI also find the gains on classification accuracy quite marginal and perhaps less important than the interpretability of the evidences which has not been convincingly demonstrated.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Adversarial Lawyers an interesting idea for a deep learning architecture ",
            "review": "This  seems like a very interesting concept, creating adversarial agents for each class that essentially compete with each other.  It seems like this might be a very promising method for arguing for even more abstract classes like \"circus\" vs \"zoo\" \n\nI wise more had been said about why the Honest Advocate outperformed the standard Advocate on the MIMIC dataset.  \n\nThe authors state:\n\n\"Advocates can effectively compete to generate higher quality evidence, though this effect was\nlargely localized to a few class-pairs (e.g. shirts v.s. pullovers). \"\n\nDoes it do this on things that are essentially very similar?  \n\nOverall, I think this is a great idea. I have been looking for some similar work and consider this work to be similar in the multi-generative aspect: \"MEGAN: Mixture of Experts of Generative Adversarial Networks for Multi-modal Image Generation\" - Park, Yoo, Bahng, Choo and Park, IJCAI 2018, but I cannot find similar work using the generative experts as collective adversaries for discrimination.\n\nThe paper is clear and well written.  Improvements for the paper would be going into more detail about why the method works.  It would have been great to have seen a data set on which the method performs poorly - that would give additional insight into its strengths and weaknesses.\n\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}