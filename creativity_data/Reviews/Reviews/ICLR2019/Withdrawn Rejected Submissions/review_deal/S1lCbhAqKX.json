{
    "Decision": "",
    "Reviews": [
        {
            "title": "An approach for content preservation in style transfer",
            "review": "The paper proposes a method to address the issue of content-preservation, which is usually not explicitly handled in approaches for unsupervised style transfer. The presented technique consists of extracting nouns from the input sentence (where the nouns are selected using POS tags), and encouraging the model to include the same nouns in the generated sentence, using two different losses: 1) one that comes from a language model conditioned on the nouns in the input sentence 2) one that combines the cosine distance between the input and the generated nouns embeddings. The model is evaluated on two different datasets: sentiment transfer and political slant transfer.\n\nThe use of a language model on the generated sentences was already done in \"Unsupervised Text Style Transfer using Language Models as Discriminators\" from Yang et al. (2018). The difference is that now the language model is conditioned on the input nouns, but the impact of this conditioning is not studied in the paper. It is also not totally obvious to me that a language model conditioned on the average of nouns embeddings will be able to exploit this information (unless there are only a couple of words?). Did you try to generate random tuples of 4 or 5 nouns and see what the language model samples when it is conditioned on the average of these nouns embeddings?\n\nAlthough relatively simple, the model combines a lot of different elements (there are 4 different losses), and the impact of each of them is not really clear. It would have been nice to have a more detailed ablation study to see the impact of each loss. In particular, if the language model is conditioned on the content, why is lambda_POS still needed? Similarly, since you also condition the language model on the style, why is the classifier still needed? L_class and L_pos seem redundant with L_lm.\n\nI was initially confused by the title \"Structured content preservation\" and the section title \"POS preservation constraints\". As far as I understand, the POS tags are only used to select the nouns in input and generated sentences, and are otherwise ignored. Similarly, the label \"POS distance\" in Table 1 seems inaccurate, instead I would rather call this \"nouns distance\". Also, I have a concern about this approach for content preservation. The way the loss works is only a \"soft\" way to ensure that the generated nouns are the same, in the sense that if 2 words have a very similar embedding, their cosine distances with any other word will also be very similar. As a result, if \"orange\" and \"apple\" are very close in the embedding space, and \"orange\" is the word in the input sentence, the model penalty for generating \"apple\" as opposed to \"orange\" will be very small. This is typically what happens for people's names that usually have very similar embeddings, this is why I don't find the explanation in 4.2.2 very satisfying.\n\nFew questions:\n1. The equation 8 is very unclear, I cannot understand what d_i is.\n2. You set η to 0.5, α to 0.2, and β to 0.1. How did you find these hyper-parameters? Did you try other configurations? Although these losses have a different nature, it gives the feeling that the L_pos loss (which is the main novelty of the paper) with the coefficient β = 0.1 is the least important one.\n3. Could you show some examples of Political Slant Transfer in Appendix?\n4. In Table 2 you selected 100 random sentences from the test set. The original test set of 500 sentences is already quite small. Could you perform the evaluation on the full 500 sentences? The fact of selecting 100 random sentences will make it difficult for other research groups to reproduce and compare similar experiments.\n\nOverall, I find the overall approach quite incremental. Given the previous studies of Hu et al and Yang et al, the novelty boils down to adding a coefficient L_pos, which I don't find particularly convincing, especially given the absence of ablation study.\n\nTypos:\n\"Yep review\" -> \"Yelp reviews\" (3.3)\n\"BLUE score\" -> \"BLEU score\" (4.1.2 and 4.2.2)\n\"infomration\" -> \"information\" (4.1.2)",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A simple but effective improvement for style transfer",
            "review": "Structured Content Preservation in Style Transfer\n\nThis paper presents a method for style transfer that using an autoencoder. The autoencoder trained to generate a meaning representation of the sentence. A decoder does the style transfer from this meaning representation. The decoder is trained to minimize style transfer loss and content loss. \n\nThe new contribution here is a content loss (referred to as POS loss in the paper), which serves to penalize models that do not retain nouns in the output. \n\nStrengths:\n\n1. The paper addresses an important problem in style transfer, one of balancing content loss versus changing style. \n2. The experiments include a manual evaluation in addition to automatic evaluation. \n3. The evaluations show that the proposed method is effective compared to style transfer methods that don't include this noun-based content loss.\n\nIssues:\n\n1. The manual evaluation seems to have conflated two dimensions of evaluation into a single rating. Specifically, the evaluation question is:  “Which sentence has an opposite sentiment of the original sentence and at the same time preserves the content of it?” What happens in cases where A preserves the content but does not style transfer and B transfers style but does not preserve content. Which one would the annotators choose? It would be useful to obtain two ratings and combine them instead of using a single one.\n\n2. The idea of enforcing a content loss is well motivated but the approach considered seems rather heuristic. Selecting nouns is a useful start but as the authors point out that not all content words are nouns, and not all nouns are content words always. It would have been useful to consider other categories and quantify their impact in style transfer. \n\n3. It would have been useful to include an ablation where only the noun lm is used but not the training loss. \n\n4. The main gains come from using nouns as the set of content to preserve.  I wonder if there is a simpler baseline that uses the noun-based restriction also. A simple baseline for this idea could be to rescore beams using the same loss function (at test time only). \n\n5. Is there some information on inter-annotator agreement on this task. I suspect the task is straightforward enough that this might not be an issue but it would be useful to know. \n\n6. The difference in BLEU (Human) between the systems is not that large. However, the difference in terms of the manual evaluation is strikingly large. \nThis kind of variance is observed often in language generation tasks. The authors should consider explaining why this difference is so large with a bit more analysis.\n\n7. Why is the paper titled \"structured\"? It was not obvious to me what kind of structure is being inferred or used in this problem. Also, calling the POS distance is confusing as it seems to indicate that there is some POS tag sequence comparison being done here, which is not the case.\n\nOverall this is a focused contribution that presents a simple yet effective empirical advance on style transfer for two types of tasks. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "I am skeptical about the need of using POS tags for the text style transfer task.",
            "review": "The paper presents a neural network architecture for unsupervised text style transfer. The key differential of the proposed architecture is the use of part-of-speech tagging (POS) information to enforce  content preservation. The authors limit the use of POS tags to identify nouns, and employ them in the computation of two loss functions: POS loss and language model loss.\nThe authors present experimental results for two different datasets and show competitive results when compared with other recently proposed neural net architectures.\n\nThe paper have some major issues, as listed below, which makes me inclined to vote for rejection:\n-\tThe novelty is very limited. The use of nouns to enforce content preservation was already explored by Melnyk et al. (2017) and the idea of using language models was already proposed by Yang et al (2018). Although the way that the losses are computed in each of these papers are somewhat different from the submitted paper, the key ingredients are the same. Additionally, the authors do not present any comparison with these methods.\n-\tThe proposed strategy goes in a different direction of the current trend in Deep Learning-based NLP approaches. Researchers are trying to move away from classical pipelines that use NLP tools such as POS taggers. Moreover, it is not clear if the POS-based loss is essential for the architecture because there is no ablation experiments showing the importance of each one of the component: attention, POS loss, lm loss. The ablation experiment presented is quite weak and only shows the contribution of the lm loss. Additionally, another recent paper (dos Santos et al.  2018) has shown that just using back-translation or attention is enough to have good content preservation. In summary, I am skeptical about the need of using POS tags for the text style transfer task.\n\nSome minor questions/comments:\n(1)\tWhy do you name your method “structured”? Because of the use of nouns? As far as I understand, a set of nouns do not save the structure of the original sentence where they are employed.\n(2)\tModel description is not clear. Passages like “After switching the style representation, we can get the generated sentence ~yi” should be improved to include more detail and clarity.\n(3)\tWhat exactly is d_i in eq. (8)? Is it the normalized distance between the noun “i” in the input and all nouns in the output ?\n(4)\tThe authors have used the following question for the human evaluators: “Which sentence has an opposite sentiment of the original sentence and at the same time preserves the content of it?”. I am not sure if this is the right question to be asked since it is quite geared towards the type of transfer that their model does. I was expecting a more neutral question.\n(5)\tThe authors do not inform what POS extends for. Please note that ICLR has a diverse audience, NLP researchers are not the majority in this conference.\n\n\nReferences:\nYang et al. Unsupervised Text Style Transfer using Language Models as Discriminators. Arxiv 2018\nDos Santos et al.  Fighting Offensive Language on Social Media with Unsupervised Text Style Transfer. ACL 2018.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}