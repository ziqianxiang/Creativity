{
    "Decision": {
        "metareview": "This is a proposed method that studies learning of disentangled representations in a relatively specific setting, defined as follows: given two datasets, one unlabeled and another that has a particular factor of variation fixed, the method will disentangle the factor of variation from the others. The reviewers found the method promising, with interesting results (qual & quant).\n\nThe weaknesses of the method as discussed in the reviews and after:\n\n- the quantitative results with weak supervision are not a big improvement over beta-vae-like methods or mathieu et al.\n- a red flag of sorts to me is that it is not very clear where the gains are coming from: the authors claim to have done a fair comparison with the various baselines, but they introduce an entirely new encoder/decoder architecture that was likely (involuntarily, but still) tuned more to their method than others.\n- the setup as presented is somewhat artificial and less general than it could be (however, this was not a major factor in my decision). It is easy to get confused by the kind of disentagled representations that this work is aiming to get.\n\nI think this has the potential to be a solid paper, but at this stage it's missing a number of ablation studies to truly understand what sets it apart from the previous work. At the very least, there is a number of architectural and training choices in Appendix D -- like the 0.25 dropout -- that require more explanation / empirical understanding and how they generalize to other datasets.\n\nGiven all of this, at this point it is hard for me to recommend acceptance of this work. I encourage the authors to take all this feedback into account, extend their work to more domains (the artistic-style disentangling that they mention seems like a good idea) and provide more empirical evidence about their architectural choices and their effect on the results.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "metareview"
    },
    "Reviews": [
        {
            "title": "Interesting approach, somewhat artificial setup, limited interpretation of \"disentangling representation learning\"",
            "review": "The authors address the problem of representation learning in which data-generative factors of variation are separated, or disentangled, from each other. Pointing out that unsupervised disentangling is hard despite recent breakthroughs, and that supervised disentangling needs a large number of carefully labeled data, they propose a “weakly supervised” approach that does not require explicit factor labels, but instead divides the training data in to two subsets. One set, the “reference set” is known to the learning algorithm to leave a set of generative “target factors” fixed at one specific value per factor, while the other set is known to the learning algorithm to vary across all generative factors. The problem setup posed by the authors is to separate the corresponding two sets of factors into two non-overlapping sets of latents. \n\nPros:\n\nTo address this problem, the authors propose an architecture that includes a reverse KL-term in the loss, and they show convincingly that this approach is indeed successful in separating the two sets of generative factors from each other. This is demonstrated in two different ways. First, quantitatively on an a modified MNIST dataset, showing that the information about the target factors is indeed (mostly) in the set of latents that are meant to capture them. Second, qualitatively on the modified MNIST and on a further dataset, AffectNet, which has been carefully curated by the authors to improve the quality of the reference set. The qualitative results are impressive and show that this approach can be used to transfer the target factors from one image, onto another image.\n\nTechnically, this work combines and extends a set of interesting techniques into a novel framework, applied to a new way of disentangling two sets of factors of variation with a VAE approach. \n\nCons:\n\nThe problem that this work solves seems somewhat artificial, and the training data, while less burdensome than having explicit labels, is still difficult to obtain in practice. More importantly, though, both the title and the start of the both the abstract and the introduction are somewhat misleading. That’s because this work does not actually address disentangling in the sense of “Learning disentangled representations from visual data, where high-level generative factors correspond to independent dimensions of feature vectors…” What it really addresses is separating two sets of factors into different parts of the representation, within each of which the factors can be, are very likely are, entangled with each other.\n\nRelated to the point that this work is not really about disentangling, the quantitative comparisons with completely unsupervised baselines are not really that meaningful, at least not in terms of what this work sets out to do. All it shows is whether information about the target factors is easily (linearly) decodable from the latents, which, while related to disentangling, says little about the quality of it. On the positive side, this kind of quantitative comparison (where the authors approach has to show that the information exists in the correct part of the space) is not pitted unfairly against the unsupervised baselines.\n\n===\nUpdate: \nThe authors have made a good effort to address the concerns raised, and I believe the paper should be accepted in its current form. I have increased my rating from 6 to 7, accordingly. ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "The paper proposes reference based VAEs, which considers learning semantically meaningful feature with weak supervision. The latent variable contains two parts, one related to the reference set and the other irrelevant. To prevent degenerate solutions, the paper proposed to use reverse KL resulting in a ALICE-style objective. The paper demonstrates interesting empirical results on feature prediction, conditional image generation and image synthesis.\n\nI don’t really see how Equation (5) in symmetric KL prevents learning redundant z (i.e. z contains all information of e). It seems one could have both KL terms near zero but also have p(x|z, e) = p(x|z)? One scenario would be the case where z contains all the information about e (which learns the reference latent features), so we have redundant information in z. In this case, the learned features e are informative but the decoder does not use e anyways. To ensure that z does not contain information about e, one could add an adversarial predictor that tries to predict e from z. Note that this cannot be detected by the feature learning metric because it ignores z for RbVAE during training.\n\nThe experiments on conditional image generation look interesting, but I wonder if the ground truth transformation for MNIST can be simply described as in some linear transformation on the original image. I wonder if the proposed method works on SVHN, where you can use label information as reference supervision. Moreover, I wonder if it is possible to use multiple types of reference images, but fewer images in each type, to reach comparable or even better performance.\n\nMinor points:\n- Why assume that the reference distribution is delta distribution whose support has measure zero, instead of a regular Gaussian?\n- (6), (8), (10) seems over complicated due to the semi-supervised nature of the objective. I wonder if having an additional figure would make things clearer. \n- Maybe it is helpful to cite the ALICE paper (Li et al) for Equation (10).\n- Table 1, maybe add the word “respectively” so it is clearer which metric you use for which dataset.\n- I wonder if it is fair enough to compare feature prediction with VAE and other models since they do not use any “weak supervision”; a fairer baseline could consider learning with the weak supervision labels (containing the information that some images have the same label). The improvement on AffectNet compared to regular VAE does not look amazing given the additional weak supervision.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Results are promising, but missing comparison to an established method. And the loss seems more complicated than it need be.",
            "review": "Summary: Given two sets of data, where one is unlabelled and the other is a reference data set with a particular factor of variation that is fixed, the approach disentangles this factor of variation from the others. The approach uses a VAE whose latents are split into e that represents the factor of variation and z that represents the remaining factors. A symmetric KL loss that is approximated using the density-ratio trick is optimised for the learning, and the method is applied to MNIST digit style disentangling and AffectNet facial expression disentangling.\n\nPros:\n- Clearly written\n- Results look promising, both quantitative and qualitative.\n\nCons:\n- Mathieu et al disentangle a specific factor from others without explicit labels but by drawing two images with the same value of the specified factor (i.e. drawing from the reference set) and also drawing a third image with a any value of the specified factor (i.e. drawing from the unlabelled set). Hence their approach is directly applicable to the problem at hand in the paper. Although Mathieu et al use digit/face identity as the shared factor, their method is directly applicable to the case where the shared factor is digit style/facial expression. Hence it appears to me that it should be compared against.\n- missing reference - Bouchacourt - explicit labels aren’t given and data is grouped where each group shares a factor of var. But here the data is assumed to be partitioned into groups, so there is no equivalent to the unlablled set, hence difficult to compare against for the outlined tasks.\n- Regarding comparison against unsupervised disentangling methods, there have been more recent approaches since betaVAE and DIP-VAE (e.g. FactorVAE (Kim et al) TCVAE (Chen et al)). It would be nice to compare against these methods, not only via predictive accuracy of target factors but also using disentangling metrics specified in these papers.\n\nOther Qs/comments\n- the KL terms in (5) are intractable due to the densities p^u(x) and p^r(x), hence two separate discriminators need to be used to approximate two separate density ratios, making the model rather large and complicated with many moving parts. What would happen if these KL terms in (5) are dropped and one simply uses SGVB to optimise the resulting loss without the need for discriminators? Usually discriminators tend to heavily underestimate density ratios (See e.g. Rosca et al), especially densities defined on high dimensions, so it might be best to avoid them whenever possible. The requirement of adding reconstruction terms to the loss in (10) is perhaps evidence of this, because these reconstruction terms are already present in the loss (3) & (5) that the discriminator should be approximating. So the necessity of extra regularisation of these reconstruction terms suggests that the discriminator is giving poor estimates of them. The reconstruction terms for z,e in (5) appear sufficient to force the model to use e (which is the motivation given in the paper for using the symmetric KL), akin to how InfoGAN forces the model to use the latents, so the necessity of the KL terms in (5) is questionable and appears to need further justification and/or ablation studies.\n- (minor) why not learn the likelihood variance lambda?\n\n************* Revision *************\nI am convinced by the rebuttal of the authors, hence have modified my score accordingly.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}