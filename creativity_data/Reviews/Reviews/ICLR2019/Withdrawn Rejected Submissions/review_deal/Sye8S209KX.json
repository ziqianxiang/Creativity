{
    "Decision": "",
    "Reviews": [
        {
            "title": "Slight gains from concatenating token-based and sentence-based representations",
            "review": "This paper proposes a sentence encoder that is the concatenation of three separately trained component representations:\n1.  An encoder adversarially trained in a multi-task setting (Section 3.1., trained with AllNLI and Quora)\n2.  GenSen from Subramanian et al, ICLR 2018 (encoder trained with multi-task learning with 5 tasks/datasets, one of which is AllNLI)\n3.  ELMo (average pooling of the word representations to get a sentence representation)\n\nThis combined representation is the best in the transfer learning setting for 5 out of the 15 tasks investigated (Tables 1 and 2).  \n\nThe portion of the representation learned in this paper (Sent2vec) appears to be mostly dominated by the existing GenSen.  In Table 1, GenSen is more accurate than Sent2vec for 7 out of the 8 investigated tasks.  Adding Sent2vec to the combination of GenSen+ELMo (comparing lines 4.2 and 4.3) changes the results by less than 1% absolute in 7 out of the 8 tasks.\n\nPage 7 mentions that \"we observe a significant improvement on 4 out of 8 tasks...\" -- how was significance determined here?\n\nIn Table 2, the line for GenSen+ELMo (the equivalent of line 4.2 in Table 1) is missing.  This would be good to include for completeness.  \n\nThe idea of multitask learning for sentence representations is not new to this paper (see for example GenSen, which also uses multitask learning, with more tasks and includes two out of the three source datasets used here already).  ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Unclear Contribution and Novelty, Lack Ablation Study",
            "review": "The paper studies several variants of BiLSTM-max for feature transfer learned from text classification tasks, shared or not shared. It also includes experiments with an adversary that attempts to improve the transferrability of the features.\n\nThe main issue of the paper is that the contribution and novelty cannot be clearly identified. All of the proposed models have appeared before, and these respective papers offer enough experiments to showcase their effectiveness. Furthermore, there is not a clear winner for any of the models studied in this paper. This makes it impossible to assess the novelty of the particular combination of methods.\n\nSecondly, since the methods are different combinations of previously proposed approaches, better ablation study should be included that compare each component individually. The study offered in the paper only assesses the weights between transfer tasks, but not on the individual component.\n\nBased on these comments, I recommend rejection of the paper",
            "rating": "3: Clear rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Limited Novelty with questionable \"improvements\" over simpler setups from prior work",
            "review": "The paper introduces an approach to train sentence representations from multiple text classification tasks. Two variants of shared private multi-task learning are employed to train BiLSTM based sentence encoders. Experiments were conducted with care and nicely compared to existing results from the literature. However, these show only incremental improvements over recent baselines. \n\nThe idea of using shared and private encoders in the multitask setup is interesting, however, results do not indicate much improvements over simple MTL settings like the one from Conneau et al. Overall, the paper seems to be a straight-forward combination of 2 existing ideas: the model and datasets (except for QQP) from Conneau et al. and the SP setup from Liu et al. The additional QQP dataset actually doesn't seem to offer all that much looking at the appendix. Furthermore, the authors simply concatenate all embeddings that exist to build their universal representations which is fairly obvious that this helps. They also concatenate all private embeddings with the shared one, which is not all that fair in comparison to other results, because the larger dimensionality typically helps in these tasks, even with random projections [1]. Nevertheless there is no real gain over previous approaches.\n\n\nSo overall I believe that the incremental contributions in this paper as well as the lack of favorable results that would support the additions made over Conneau et al. make this paper rather an interesting workshop addition than a conference full-paper.\n\n\nComment:\nOn a sidenote, as a line of research I would also like to raise awareness on how little trained sentence representations actually offer over simple BoW representations. See for instance the following parallel submission [1] that uses BoW representations with random projections. This paper also points out a problem in InferSent that prevents proper evaluation when using max-pooling. In case the InferSent library was used to obtain results for this paper, this would make it hard to trust the results.\n\n[1] https://openreview.net/forum?id=BkgPajAcY7",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}