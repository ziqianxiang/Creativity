{
    "Decision": {
        "metareview": "All reviewers agree to reject. While there were many positive points to this work, reviewers believed that it was not yet ready for acceptance.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Meta-Review for Group Profiling paper"
    },
    "Reviews": [
        {
            "title": "poorly written paper, not ready for publication",
            "review": "Pros:\n-- Clustering sequence vectors is a practical and useful problem. Some of the business use-cases described in the paper are indeed useful and relevant for analytics in healthcare and retail.\n\nCons:\n-- The paper is poorly written. There are numerous typos and grammatical errors throughout the paper. \n-- The ideas are not presented coherently. The writing needs to improve quite a bit to get accepted at a conference like ICLR.\n-- Description of related literature is done very poorly.  \n-- The generative model described clearly lacks justification. The model is not described concretely either. There is no clear description of the inference techniques used.\n-- Empirical results are weak. ",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Zero novelty",
            "review": "The problem formulation at the bottom of page 3 correspond to what a bag of words preprocessing of a document would provide and in this the clustering would be a much simpler solution that just doing LDA.\n\nThe paper has zero interest.",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Both the writing and experiments should be improved",
            "review": "This paper propose a hierarchical Bayesian model to cluster sparse sequences data. The observations are modeled as Poisson distributions, whose rate parameter \\lambda_i is written as the summation of \\lambda_{ik}, a Gamma distribution with rate equal to the mixture proportion \\alpha_{ik}. The model is implemented in Pystan. Experimental results on a real-world user visit dataset were presented.\n\nThe format of this paper, including the listing in the introduction section, the long url in section 2.3, and the model specification in section 3.2, can be improved. In particular, the presentation of the model would be more clear if the graphical model can be specified. \n\nThe motivation of choosing the observation model and priors is not clear. In section 3, the author described the details of model specification without explaining why those design choices were appropriate for modeling sparse sequence data.\n\nExperimental results on a real-world dataset is presented. However, to demonstrate how the model works, it would be best to add synthetic experiments as sanity check. Results using common baseline approaches should also be presented. The results should also be properly quantified in order to compare the relative advantage of different approaches.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The authors discuss a hierarchical Bayesian framework for clustering sparse sequences. They use data from a restaurant loyalty program to identify users (rows) and weeks of visits (columns) under the assumption that user visits to a restaurant will be sparse across weeks. ",
            "review": "The paper is very poorly written. It is hard to understand what the real contribution is in this paper. \nThe connection of the model with HMM is not clear. The literature review has to be rewritten.\n\nTo the reader, it sounds that the authors are confused with the fundamentals itself: mixture model, Bayesian models, inference. \n\n> Mixture models can be based on any of the exponential family distributions - Gaussian just happens to be the most commonly used.\n> Again if this is a Bayesian model, why are #clusters not inferred? The authors further mention that in their Pystan implementation K clusters were spun too quick. What was the K used here? Was it set to a very large value or just 3? Did the authors eventually use the truncated infinite mixture model in Pystan?\n> The authors mention their model is conceptually similar to EM but then end up using NUTS. \n> Why is a url given in Section 2.3 instead of being given in the references? \n> Provide a plate model describing Section 3.2.",
            "rating": "1: Trivial or wrong",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "HIERARCHICAL BAYESIAN MODELING FOR CLUSTERING SPARSE SEQUENCES IN THE CONTEXT OF GROUP PROFILING",
            "review": "The paper discusses clustering sparse sequences using some mixture model. It discusses results about clustering data obtained from a restaurant loyalty program.\n\nIt is not clear to me what the research contribution of the paper is. What I see is that some known techniques were used to cluster the loyalty program data and some properties of the experiments conducted noted down. No comparisons are made. I am not sure what to evaluate in this paper. ",
            "rating": "2: Strong rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}