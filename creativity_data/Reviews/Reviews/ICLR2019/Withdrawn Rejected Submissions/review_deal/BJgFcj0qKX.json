{
    "Decision": "",
    "Reviews": [
        {
            "title": "Builds heavily on recent literature. Improves segmentation results, but limited novelty.",
            "review": "The paper proposes a network architecture for semantic image segmentation. The architecture is based on composing a stack of basic U-Net architectures. After an initial discriminative training of the first portion of the network, the training can be completed end-to-end for the entire network. The second portion of the network entails a dilation. The evaluation of the approach seems to be pretty extensive. The motivation is to build a network that does not heavily rely on pre-trained discriminative networks such as VGG or ResNet, but to build one that is fully targeting the segmentation problem. This approach has led to an architecture that reduces the number of parameters quite significantly while improving results.\n\nThe paper is well organized and sufficiently clear. The results section is pretty rich. \n\nThe technical novelty however is limited. The paper leverages many ideas that have been lingering around, including the most important idea, which is to stack U-Nets. The results do show an improvement (for segmentation) with a clear size decrease of the architecture, but this might not be enough.\n\nI would have appreciated a table showing the training times of the proposed approach in comparison with the previous works.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "An Submission Substantially Below Acceptance Bar",
            "review": "This paper proposed stacked U-Net for image segmentation. The main contribution as claimed by the authors is stacking multiple U-Net to repeat the high-low-high feature representation. \n\nGenerally speaking, the proposed idea is completely out-of-date as a submission for ICLR 2019. There are a large number of research works have been done to improve the first encoder-decoder design since 2016. Stacked multiple U-Nets to repeat the information concentration and recovering process is widely used as a standard design such as Hourglass network. I can hardly believe that this idea can be considered as significant for an ICLR submission in 2019.\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting architecture design, but the experiments are not convincing",
            "review": "This paper proposed an architecture similar to stacked hourglass network, while replacing each block with module similar to UNet. It is claimed to achieve competitive results while using much less parameters. Many techniques are adopted to improve its performance, e.g. skip connection, residual connection, 1 stride convolution, multi-grid dilation, ect. \n\nQuestions for experiment comparison:\n 1. As mentioned by authors the main task of this model is semantic segmentation instead of classification, so when comparing with the performance of ResNet101, especially borrowing the results from Chen et al. 2017's work, it would be better also comparing with the 'block5-7' results, instead of 'block4' solely. \n2. On MS-COCO dataset the experiment setting is slightly different (30k image more for training comapring with Chen et al. 2017). Thus the boost of accuracy is not very convincing.\n3. It has not outperform the state-of-the-art models on VOC2012 or Cityscapes.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}