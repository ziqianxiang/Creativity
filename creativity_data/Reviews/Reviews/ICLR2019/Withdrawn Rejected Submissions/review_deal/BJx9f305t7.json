{
    "Decision": {
        "metareview": "The paper introduces a W2GAN method for training GAN by minimizing 2-Wasserstein distance using \nby computing an optimal transport (OT) map between distributions. However, the difference of previous works  is not significant or clearly clarified as pointed out some of the reviewers. The advantage of W2GAN over standard WGAN is also superficially explained, and did not supported by strong empirical evidence. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "no clear practice advantage "
    },
    "Reviews": [
        {
            "title": "Interesting approach to OT GAN for Wasserstein distances with regularised Kantorovitch duals",
            "review": "\npros\n\n- formal approach to the problem and a clear understanding of what is missing (Section 6.6); I appreciated Section 3 at large in particular.\n\n- I like Theorem 1 and Corollary 1. Is it is possible to reason about an imperfect generator class and undertrained discriminator, and get sufficient conditions for convergence (not necessarily exponential) ?\n\n\ncons\n\n- In Proposition 1, I suspect that p > 2 (see below), which makes the p=2 choice a limit case of the proposition.\n\n- The paper should have cited the paper https://arxiv.org/pdf/1710.05488.pdf which goes along similar lines in its Section 3 and make proper comparisons.\n\n - experimental results do not do a great favour to the technique proposed: in Table 1, W2-OT is not better than Barycentric-OT (see spiral); in Table 2, W2GAN is not better than WGAN-LP; Figure 1-a is maybe the only Figure with a clearcut advantage. However, the CIFAR examples in Figure 1b look quite bad after zooming. Do the authors have more experiments and comparisons on images ?\n\nDetail:\n\n* In proposition 1, (6), use the Holder conjugate of p: ||\\nabla||^{1(p-1)-1} =1/||\\nabla||^{2-q}. Also better to understand as $q\\leq 2$. \n\n* looking at the proof of proposition 1, I do not know how you derive the inverse gradient, but I suspect you need in fact $p>2$, which also implies $q<2$ above.\n\n* Sentence after (10) grammatically incorrect\n\n* In the interpretation of the equation after (16), isn’t is possible to interpret the Jacobian terms as a geometric tweak for the update of G ?\n\n* Lots of mistakes in references: Mistake in the first ref in references, many @JOURNAL/CONF titles do not appear.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Original contribution unclear",
            "review": "The paper W2GAN describes a method for training GAN and computing an optimal transport (OT) map\nbetween distributions. As far as I can tell, it is difficult to identify the original contributions\nof the paper. Most results are known from the OT community. The differences with the work of Seguy, 2018\nis also not obvious. I encourage the authors to establish more clearly the differences of their work\nwith this last reference. Most of the theoretical considerations of Section 3 is either based on \nunrealistic assumptions (case 1) or make vague assumptions 'if we ignore the possibly significant effect ...'\nthat seem unjustified so far. Experimental results do not show evidences of superiority wrt. existing works.  \nAll in all I would recommend the authors to better focus on the original contribution of their works wrt.  \nstate-of-the-art and explain why the theoretical analysis on convergence following a geodesic path in a \nWasserstein space is valuable from a practical view. Finally, I did not understand the final claim of the \nAbstract : 'Perhaps surprisingly, we also provide empirical evidence that other GANs also approximately following\nthe Optimal Transport.'. What are those empirical evidences ? It seems that this claim is not supported somewhere \nelse in the paper.\n\nMinor remarks:\n - regarding the penalization in eq. (5), the expectation is not for all x and y \\in R^2, but for x drawn from \\mu and y from \\nu.\n   Same for L_2 regularization\n - Proposition 1 is mainly due to Brenier\nBrenier, Y. (1991). Polar factorization and monotone rearrangement of vector‐valued functions. Communications on pure and applied mathematics, 44(4), 375-417.\n - from Eq (7), you should give precisely over what the expectations are taken.\n - Eq (10) : how do you inverse sup and inf ? \n - when comparing to Seguy 2018, are you using an entropic or a L_2 regularization ? How do you set the regularization strength ?\n - where is Figure 2.a described in section 4.2 ? \n\nRelated works :\n - what is reference (Alexandre, 2018) ?  \n - regarding applications of OT to domain adaptation, there are several references on the subject. \n   See for instance \nCourty, N., Flamary, R., Tuia, D., & Rakotomamonjy, A. (2017). Optimal transport for domain adaptation. IEEE transactions on pattern analysis and machine intelligence, 39(9), 1853-1865.\nor \nDamodaran, B. B., Kellenberger, B., Flamary, R., Tuia, D., & Courty, N. (2018). DeepJDOT: Deep Joint distribution optimal transport for unsupervised domain adaptation. ECCV \nfor a deep variant.\n - Reference Seguy 2017 and 2018 are the same and should be fused. The corresponding paper\n   was published at ICLR 2018\n   Regarding this last reference, the claim 'As far as we know, it is the first demonstration of a GAN achieving reasonable generative modeling results and an approximation of the optimal transport map between two continuous distributions.' should maybe be lowered ? ",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "GANs for OT and OT for GANs",
            "review": "The paper proposes W2GAN, a GAN where the objective function relies on a W2 distance. Authors state that the discriminator approximate the W2 distance, and that the generator follows an OT map. \nWhile I did not see any flaws in the development, the paper is quite bushy and hard to follow. Some questions are still open, for instance in the end of the experiments, authors state that the model has \"a strong theoretical advantages\": can you provide more details about those advantages?\nThe experiments do not show any clear advantages of the method regarding competitors. Regarding Table 1, why are there some points with no arrows? W2-OT seems not to perform better: are there some other advantages (computational?) to use the method? In Figure 1, it is quite difficult to evaluate the results on a single image with no comparisons. Again, providing a strong evaluation of the method would help to strengthen the paper. \n\nThere are some weird statements and typos mistakes that should be corrected. For example in the first 2 pages: (abstract) \"other GANs also approximately following the Optimal Transport\", (Introduction) \"An optimal map has many important implications such as computing barycenters\", \"high-dimenisonal\", \"generator designed\", \"consideral\", \"although the theoretical arguments do not scale immediately\".\nThe layout of the bibliography should be deeply reviewed.\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}