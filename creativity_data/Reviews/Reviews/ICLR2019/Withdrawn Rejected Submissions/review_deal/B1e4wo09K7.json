{
    "Decision": {
        "metareview": "The paper presents a new approach to learn separate class-invariant and class-equivariant latent representations, by training on labeled (and optional additional unlabelled) multi class data. Empirical results on MNIST and SVHN show that the method works well.\nReviewers initially highlighted the following weaknesses of the paper: insufficient references and contrasting with related work (given that this problem space has been much explored before), \nlimited novelty of the approach, limited experiments (MNIST only). One reviewer also mentioned a sometimes vague, overly hyperbolic, and meandering writeup.\n\nAuthors did a commendable effort to improve the paper based on the reviews, adding new references, removing and rewriting parts of the paper to make it more focused, and providing experimental results on an additional dataset (SVHN). The paper did improve as a result. But while attenuated, the initial criticisms remain valid: the literature review and discussion remains short and too superficial. The peculiarities of the approach which grant it (modest) originality are insufficiently (theoretically and empirically) justified and not clearly enough put in context of the whole body of prior work. Consequently the proposed approach feels very ad-hoc. Finally the additional experiments are a step in the right direction, but experiments on only MNIST and SVHN are hardly enough in 2018 to convince the reader that a method has a universal potential and is more generally useful. Given the limited novelty, and in the absence of theoretical justification, experiments should be much more extensive, both in diversity of data/problems, and in the range of alternative approaches compared to, to build a convincing case.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "A new ad-hoc approach for learning class-equivariant representations, with limited justification, literature context, and experiments."
    },
    "Reviews": [
        {
            "title": "Nice, clean generative model, wonder how it would perform on a more challenging dataset.",
            "review": "The paper proposes a genarative model for images which explicitly separates the within class variation \n(the covariant part) from the across class variation (invariant part). Functionally, this achieves a similar \nresult as various recent works on incorporating invariances in neural nets, but the fact that it is able \nto explicitly construct models for both parts of the distribution is nice. Results on MNIST are good, \nbut of course this is a very simple dataset. It would be very interesting to see how the model \nperforms on a more realistic problem. \n\nAdmittedly, I am not an expert in generative models. This is a clean paper with a clear goal, it is hard \nfor me to judge how original the idea is.\n\n\"Covariant\" might not be the best word to use here because it has a very specific meaning in the context \nof some other neural networks related to how quantities transform according to representations of a symmetry \ngroup. This is a potential source of confusion. ",
            "rating": "7: Good paper, accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Technically Sound, Well Written, but The Key Idea is Not Very New",
            "review": "This paper is well written, and the quality of the figures is good. In this paper, the authors propose an invariant-covariant idea, which should be dated back at least to the bilinear models. The general direction is important and should be pursued further. \n\nHowever, the literature is not well addressed. Eslami et al. 2018 have been cited, but some very important and related earlier works like: \n[1] Kulkarni et al. 2015, Deep Convolutional Inverse Graphics Network\n[2] Cheung et al. 2015, Discovering Hidden Factors of Variation in Deep Networks\nwere not discussed at all. The authors should certainly make an effort to discuss the connections and new developments beyond these works. At the end of section 1, the authors argue that the covariant vector could be more general, but in fact, these earlier works can achieve further equivalence, which is much stronger than the proposed covariance.\n\nThere is also an effort to compare this work to Sabour et al. 2017 and the general capsule idea. I would like to point out, the capsule concept is a much more fine-grained what & where separation rather than a coarse-grained class & pose separation in one shot. In a hierarchical representation, what & where can appear at any level as one class can consist of several parts each with a geometrical configuration space. So the comparison of this work to the generic capsule network is only superficial if the authors can not make the proposed architecture into a hierarchical separation. Besides different capsule network papers, I found another potentially useful reference on a fine-grained separation:\n[3]Goroshin et al., Learning to Linearize Under Uncertainty\n\nIn the paper, it is argued several times that the latent vector r_y contains a rich set of global properties of class y, rather than just its label and the aim is that it can learn what the elements of the class manifold have in common. But this point is not supported well since we can always make a label and this latent vector r_y equivalent by a template. I think this point could be meaningful if we look at r_y's for different y, where each of the dimension may have some semantic meaning. Additional interpretation is certainly needed.\n\nUnder equation (3), \"Note that v is inferred from r_y\" should be \"inferred from both r_y and x\", which is pretty clear from the fig 5. Related to this, I could imagine some encoder can extract the 'style' directly from x, but here both r_y and x are used. I couldn't find any guarantee that v only contains the 'style' information based on the architecture with even this additional complication, could the authors comment on this?\n\nEquation (5) is not really a marginalization and further equation (6) may not be a lower bound anymore. This is probably a relatively minor thing and a little extra care is probably enough.\n\nThe numbers in table 2 seems a little outdated.\n\nTo conclude, I like the general direction of separating the identity and configurations. The natural signals have hierarchical structures and the class manifold concept is not general enough to describe the regularities and provide a transparent representation. Rather, it's a good starting point. If the authors could carefully address the related prior works and help us understand the unique and original contributions of this work, this paper could be considered for publication.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "CoVAE",
            "review": "The paper presents a VAE that uses labels to separate the learned representation into an invariant and a covariant part. The method is validated using experiments on the MNIST dataset.\n\nThe writing in this paper is somewhat problematic. Although it is hard to put the finger on a particularly severe instance, the paper is filled with vague and hyperbolic statements. Words like \"efficiently\", \"meaningful\", \"natural\", etc. are sprinkled throughout to confer a positive connotation, often without having a specific meaning in their context or adding any information. Where the meaning is somewhat clear, the claims are often not supported by evidence. Sometimes the claims are so broad that it is not clear what kind of evidence could support such a claim.\n\nA relatively large amount of space is used to explain the general concept of invariant/covariant learning, which, as a general concept, is widely understood and not novel. There are other instances of overclaiming, such as \"The goal of CoVAE is to provide an approach to probabilistic modelling that enables meaningful representations [...]\". In fact, CoVAE is a rather specific model(class), rather than an approach to probabilistic modelling.\n\nThe paper is at times meandering. For instance, the benefits of and motivation for the proposed approach are not simply stated in the introduction and then demonstrated in the rest of the paper, but instead the paper states some benefits and motivations, explains some technical content, mentions some more benefits, repeats some motivations stated before, etc.\n\nMany researchers working on representation learning hope to discover the underlying learning principles that lead to representations that seem natural to a human being. In this paper, labels are used to guide the representation into the \"right\" representation. It is in my opinion not very surprising that one can use labels to induce certain qualities deemed desirable in the representation.\n\nTo conclude, because of the writing, limited novelty, and limited experiments, I think this paper currently does not pass the bar for ICLR.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}