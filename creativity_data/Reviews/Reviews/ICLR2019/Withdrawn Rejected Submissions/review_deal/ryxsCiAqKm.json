{
    "Decision": "",
    "Reviews": [
        {
            "title": "This paper presents several enhancements to spectral GCNs. I don't believe it is novel enough for ICLR, nor are its experimental results strong enough.",
            "review": "## Summary ##\n\nThe authors describe several improvements on existing spectral convolutional networks for graphs:\n\n1. Learning 'abstract' edges that aren't included in the graph.\n2. Incorporating multiple edge types by several different methods.\n3. Building hierarchical graphs for image tasks.\n\nThey apply these modified architectures to classification of chemical compounds, social networks and images.\n\n## Assessment ##\n\nThe topic of spectral graph convolutions is interesting, and the enhancements suggested seem promising. However, each of 1-3 above is a straightforward application of an idea that appears elsewhere to spectral graph convolutions, making the work seem incremental. What is more, the experimental results were mixed; it was hard to discern significant improvement from 1-3. I don't think this paper warrants acceptance in ICLR at this time.\n\n## Questions and Concerns ##\n\n* I think section 2.1 (describing approximate spectral graph convolutions) could be made much clearer. The section in the supplementary material was much clearer and didn't take any more space than 2.1. Obviously, the authors can't be expected to cover ChebNet in detail, but it would be nice if they could get the gist of it from section 2.1 without having to read the original paper.\n* In many of the experiments, the hierarchical/multigraph ChebNet either underperformed another architecture, or outperformed by a very narrow margin. If there aren'y big improvements on benchmarks, it would be nice to see some other way that these new features are improving the model (e.g. can we show that it implicitly learns some interesting feature of the graphs?).\n* I found the comparison of edge fusion methods (summarized in Fig 5) difficult to understand. It was difficult to distinguish which improvements come from a better architecture and which simply come from a larger receptive field.\n* In 'Graph formation for images,' the authors say they included features from the last layer of pretrained VGG-16 in the hierarchical ChebNet for PASCAL. Moreover, these features were pretrained on a separate dataset (Imagenet). It wasn't clear whether these features were available to any other architectures, but they seem like they would provide a large advantage.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Highly-problematic experimental setup",
            "review": "# Summary of the paper\n\nThis paper presents a method for graph classification based on spectral convolutional neural networks. At its heart, the paper applies a standard decomposition in terms of the graph Laplacian and uses Chebyshev polynomials to obtain an approximation of node feature convolution. This is now extended to graphs with multiple edge relation types by performing the same calculations for every Laplacian that is induced by a certain relation $r$, and either extended the Chebyshev polynomials to multiple variables, or multiplying/adding the resulting feature vectors.\n\n# Review\n\nThe main idea of this paper, i.e. improving graph classification results by exploiting different types of edges, is very interesting. In particular for data sets with additional hierarchical information, this could well increase performance significantly.\n\nHowever, in its present form, the paper suffers from several issues. The following is a brief listing; each point will be expanded on below:\n\n1. Issues with originality: at times, it is unclear in what ways previous work is extended\n2. Issues with clarity: while most of the parts of the method can be 'reconstructed' through literature knowledge, the paper is not self-contained and often uses terms without explaining them.\n3. Issues with experiments: the reported results are *not* state-of-the-art for several data sets and I doubt the correctness of the setup.\n\nIn particular the experimental issues I consider to be highly problematic at the moment.\n\n## Originality:\n\nThe paper needs to be more clear about its contributions. Some parts read like an introduction to GCNs, but it is often not clear what is novel here:\n\n- The main contribution, as far as I understand it, should be an extension of `ChebNet` to multigraphs.  However, different relations in a graph appear to be modelled by calculating multiple graph Laplacians, which in turn can be stacked; this strikes me as a rather straightforward extension. Furthermore, the operation in Eq. 5 also appears a straightforward extension that uses learned node embeddings for each relation type.\n\n- The learning of edges for each relation, described in Section 3.1, is also a straightforward formulation/re-use of previous work (the papers cites Velickovic et al. (2018) as an example), and I do not exactly what is novel here: Velickovic et al. use the same equation to predict coefficients, as claimed in the paper, but how is this different from learning a weight for all edges as in Eq. 7? In Velickovic et al., this coefficient is only calculated for some of the edges. Is the novelty then that this is calculated for _all_ edges here?\n\n## Clarity:\n\n- The explanation of the Chebyshev expansion could be improved: Kipf & Welling (2016), for example, explain this in term of signal convolution (Eq. 3--5 in their paper), while for this paper, the introduction of node features in Eq. 2 is not clear.\n\n- What is $f_0, \\dots, f_{R-1}$ in Eq. 5? Is this an input signal at the nodes of a graph or an additional function defined on it, such as in the `ChebNet` paper by Monti et al.?  \n\n- What is $f_{\\text{edge}}$ in Eq. 7?\n\n- What is $\\bar{X}^{(0)}$ in EQ. 5? The preceding section only introduces a notation for $X$ with multiple indices, but suddenly, $X$ is now indexed over the number of relations.  \n\n- p. 4: The paper seems to be contradicting itself at places: the multi-variable polynomials from Eq. 3 and Eq. 4 are said to have a great computational cost and an exponential number of parameters for many relations. But the edge feature concatenation introduced at the bottom of p. 3 is dismissed by saying that it grows _linearly_ with $R$. What am I missing here?\n\n- The paper claims that most data set, except for the image, only have a single relation type ($R = 1$); later on, 'learned edges' are added for training. While I understand this and the benefits of adding them, I think that this should be clarified more: the advantage of the current approach seems to be that it can leverage more information by treating learned edges as a separate entity. This should be highlighted better.\n\n- In general, the paper would benefit from a section that describes the full method, preferably with a few equations, so that the readers can see at one glance which parts are involved. At present, I am doubtful about the reproducibility of the method.\n\n## Experimental setup\n\nThis is the major issue for me: the paper claims to follow a 'standard approach to evaluation' (p. 6) that consists of a 10-fold cross-validation. However, only average classification accuracies are reported, even though the sources I checked (Shervashidze et al., Yanardag & Vishwanathan, Niepert et al.) provide also the *standard deviation* along with the mean accuracy. This is important to know, since often (in particular for smaller data sets), there is a lot of overlap in terms of accuracy +- sdev.\n\nMoreover, the reported accuracies are just not state of the art: the 2016 paper *On Valid Optimal Assignment Kernels and Applications to Graph Classification* by Kriege et al. describes a novel variant of the Weisfeiler-Lehman graph kernel, referred to as WL-OA. The reported accuracies +- sdev are as follows:\n\n- NCI1: 86.1±0.2 (better than in the current paper)\n- NCI109 86.3±0.2 (better than in the current paper)\n- MUTAG: 86.0±1.7 (worse than in the current paper; WL instead of WL-OA)\n- ENYZMES: 59.9±1.1 (worse than in the current paper)\n- PROTEINS: 76.4±0.4 (better/equal to the current paper)\n- COLLAB: 80.7±0.1 (better than in the current paper)\n\nEven accounting for standard deviations, WL-OA appears to have a good 'safety margin' in terms of accuracy here. The claim that the new method 'wins by a large margin' here is thus flatly false.\n\nFurthermore, I find the way results are reported somewhat misleading: since Table 1 shows the second-best result in bold, the Multigraph Chebnet results appear to be more important. At the very least,  the standard deviations have to reported, and the experimental setup should be described in more detail, because the graph kernel publications also clarify that they learn their parameters on an inner validation such that only training data is used for hyperparameter tuning. It is unclear whether the paper is following the same approach here.\n\n# Minor issues\n\n- p. 2: use a consistent notation for the real space, i.e. $\\mathds{R}$ or $\\mathbb{R}$\n- p. 2: the justification of Eq. 1 could be phrased more succinctly: since $U$ is an orthogonal matrix, the convolution equation simplifies the way it is described; I find the description of '...property of eigendecomposition to eliminate computationally inconvenient eigenvectors' somewhat confusing\n- I don't see the significance of Figure 1; it only expresses that matrix powers make eigenvalues smaller if $\\lambda < 1$ (this property of the Laplacian is not mentioned, by the way)\n- p. 3: the notation for the number of relations is not optimal: $\\Theta\\in X_{in} K^R X_{out}$ should be rather rephrased as '$\\Theta$ is a matrix of the following dimensions'\n- The bibliography needs to be updated: there are some inconsistencies with respect to capitalization (such as in journal titles); also, at least the citation of Kipf & Welling should be adjusted as it is *not* a pre-print any more but was published in ICLR 2017\n- p. 3: Figure 2 needs a better explanation to be fully useful: its purpose appears to show that a 2D Chebyshev polynomial captures a different sort of information than a 2-hop filter because it does use information about different edge relations. Is this not clear from the onset since multi-hop filters operate only on a _single_ view of the graph?\n- p. 3: Eq. 5 seems to be a Hadamard product, so another operator should be used (essentially a circle with a dot); at present, the operator is implying that one _composes_ features by first applying one filter, then another, and so on.\n\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "An instance of spectral GCNs on multigraphs",
            "review": "This paper extends spectral GCN to multigraphs, in which graph size and structure may vary. It builds on Chebnets and extends it to graphs with several relations (more than one edge by pair of nodes).\nWhile the paper is clearly written and is interesting, the contributions are rather incremental and the experimental section does not show a clear improvement wrt the state-of-the-art, neither a clear conclusion on the impact of learning the edges.\n\nMinor comments regarding the experiments:\nThe experimental section may be improved in order to better demonstrate the value of the proposed method.\nAuthors use a standard setting for the experiments: 10 reps. of 10 nested CV on several benchmarked datasets. As pointed out by the authors, some of them contain few samples (mutag). Mean accuracies are reported, but standard deviations are also of interested (difficult to see if a method is better than an other one by comparing avg only). In addition, in table 1, some figures are missing (I believe this is because the methods have not been implemented by the authors). \nRegarding social graphs datasets, this is an issue as the results do not build on the same datasets (for multigraph chebnet, some features are added -- this is not the case for some competitors). \nSome experiments on a image classification context are also provided, but some competitive methods are not evaluated (e.g. PSCN). The bold/underlined+bold should be carefully checked as some wrong figures are highlighted.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}