{
    "Decision": {
        "metareview": "\npros:\n- The paper is clear and easy to read\n- Both Reviewer 1 and Reviewer 2 found the empirical evaluation to be good\n\ncons:\n- Some of the reviewers felt that the proposed approach lacked novelty (e.g. with respect to Nogueira and Cho)\n- Some of the architecture choices seem complicated and it was not fully clear to the reviewers (even after the rebuttal) how and why things were working better in this approach than in other similar ones.\n\nI think this is a good paper but it doesn't quite meet the bar for acceptance at this time. \n\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Clear paper but the reviewers have questions about novelty and needs more analysis"
    },
    "Reviews": [
        {
            "title": "Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation",
            "review": "The authors proposed a variant of ensemble method in reinforcement learning for query reformulation. They train multiple specialized sub-agents on disjoint partitions of the training data, and use a meta-agent, which can see all the training data, to decide the final answer. This can speed up the training thanks to parallelization. They observed that this can improve the diversity of learnt reformulations and the overall performance in some cases. \n\n\nStrengths\n1. The paper is clear and easy to follow.\n2. Multiple evaluation metrics and baseline models are considered\n\nWeaknesses\n1. The proposed method is simple and lacks novelty.\n2. The performance improvement is marginal and some empirical results are not carefully analyzed. \n\n\nSignificance\nExploring a diverse set of strategies is beneficial in reinforcement learning. This paper focuses on two aspects of this problem. One is how to learn diverse agents and the other one is how to efficiently learn these agents efficiently, which are important concerns in practice. \n\n\nOriginality\nThe model learning approach they proposed is merely a simple variant of ensemble learning. The main difference is they train sub-agents on disjoint partitions of the training data, which seems a trivial modification although this shows to improve the overall model performance.\n\n\nTechnical Quality\nOverall, the experiments are well-thought, but the following questions need to be explained:\n1.\tIn the Introduction, the authors claim three contributions they made in this paper. My question is, if the third one is really an important contribution, why didn’t the authors demonstrate it in detail in the main text? Attaching it to the appendix could make the reader confused about its significance.\n2.\tIn Table-1, the authors claim that their proposed architectures can outperform the baseline RL-10-Ensemble with only 1/10 time. The sub-agents are trained on a partition of the training set. My question is, are these sub-agents trained in parallel on different machine? If so, why cannot the RL-10-Ensemble be trained in parallel through some multithread or distributed computation? The implementation of the proposed model and the baseline seems not that fair.\n3.\tThe main architecture is described in section 3.3 and 3.4, including the Sub-agents and the Aggregator. However, in Appendix C.1, the authors claim that the gains the proposed method comes mostly from the pool of diverse reformulators, and not from the simple use of a re-ranking function (Aggregator). This is confusing because if it is true, the proposed method is really reduced to an ensemble of the baseline model.\n4.\tIn Table-2, some of the results are worse than the baseline methods like Re-Ranker. Although the authors claim the re-ranking is a post-processing, Re-Ranker performs significantly better than the proposed model. If the authors want to better demonstrate the advantages of the proposed model, a comparison between the proposed model with re-ranking and the Re-Ranker is required.\n5.\tIn Table 10, why the proposed method fails to produce the right answer whereas the other methods perform well?\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Strong empirical results. Would like to see more analysis",
            "review": "Summary:\nThe authors propose to train multiple distinct agents, each over a different subset of the training set. A meta-agent, known as the aggregator, groups and scores answers from the sub-agents for any given input. \n\nEach agent produces a unique reformulation that is applied to the environment, producing an answer for the reformulated query. The aggregator receives the original query and the answers provided by the environment and produces a relevance score for each answer with respect to the original query that is a function of both components.\n\nThe final answer is select using this relevance score, as well as an aggregate ranking score for over the space of reformulations for each answer.\n\nThe aggregator is trained to minimize the cross-entropy of the relevance score. Each reformulation agent is trained using Recall@40 as a reward for retrieving the correct answer from the environment given their reformulation. \n\nThe authors argue that learning multiple specialized sub-agents is easier than learning a generalist agent responsible for being able to model the entire training data. Authors shows that this strategy is even more generalizable than training an ensemble for the same number of agents over the entire training set. Authors apply the approach to query reformulation for document retrieval and QA.\n\nReview:\n\nPros:\n-The paper provides convincing empirical evidence that training multiple distinct agents on different partitions of a dataset to learn to reformulate queries for environment feedback is a more efficient and accurate approach than training single or ensemble model on the whole dataset. Empirical result show that both the addition of the aggregator and the exclusivity of the agents contributes to this effect. Baselines are considerable and in-depth (though it seems like the Hui et al., 2017 model that is SOTA on TREC-CAR could be shown in Table 1 as well)\n-The paper is well written and easy to understand in the approach.\n\nCons:\n-The authors could do a better job explaining a couple of unclear points. First, how did the authors come up with equation 2 for computing the relevance score? While the empirical investigation in Table 8 indicates it does better than other simpler formulations, it’s not clear why the authors were motivated to try this one.\n-I don’t come away with an idea of WHY the author’s proposed approach works better. While the empirical investigation is a contribution in it of itself, the results seem slightly counterintuitive. It’s not clear why a random partition should be better than a semantically-motivated partition. It’s also not clear why training the reformulating agents individually on these partitions would do better than an ensemble. I find the paper interesting, but the analysis of these results is missing.\n\nQuestions:\nWhy does the function for z_j in equation 2 need to be so complicated? Why are the CNN features of the query concatenated twice in the first part. What does the dot operator in the second part of the equation correspond to?",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Novelty limited and experiments not convincing enough ",
            "review": "In this paper, authors proposed an ensemble approach for query reformulation (QR).  The basic idea is that 1) train a bunch of models/sub-agents on subsets, e.g., randomly partitioned, of the training data; 2) and then train an additional meta model/meta-agent to aggregate the results from the step 1).  They conduct experiments on document retrieval and question answering tasks to show the effectiveness of the proposed model.\n\nThis paper is well written and easy to follow.  \nHowever there are several my concerns. \n\n1. It is counter intuitive, e.g., why sub-agents trained on full training dataset obtain worse results than on its subset. Regarding diversity, one may use different random seeds or different dropout rates instead of sample a subset of training data. \n\n2. The baseline is much lower than the current SOTA systems. Such as the best result on SearchQA in this paper is 50.5 in terms of F1 score. However R3 and Re-Ranker obtains 55.3 and 60.6 respectively. Could the proposed approach be adapted on those models? Note that those SOTA systems are released.\n\n3. The proposed system is quite similar to Nogueira& Cho 2017 and Buck et al. 2018. I'm not very sure the contribution of this work and its novelty.  \n\nQuestions:\n1. Why the authors didn't use beam search during the sub-agent training? \n2. It seems that the proposed framework is a pipeline model: firstly it trains a bunch of sub-agents; and then trains meta-agent. Is it possible to fine-tune the model jointly?\n3. What is Extra Budget in Table 1?    ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}