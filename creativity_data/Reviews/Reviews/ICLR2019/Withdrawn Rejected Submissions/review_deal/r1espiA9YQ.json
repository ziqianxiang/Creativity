{
    "Decision": {
        "metareview": "This paper proposes a combination of SVGD and SLGD and analyzes its non-asymptotic properties based on gradient flow. This is an interesting direction to explore. Unfortunately, two major concerns have been raised regarding this paper:  1) the reviewers identified multiple technical flaws. Authors provided rebuttal and addressed some of the problems. But the reviewers think it requires significantly more improvement and clarification to fully address the issues. 2) the motivation of the combination of SVGD and SLGD, despite of being very interesting, is not very clearly motivated; by combining SVGD and SLGD, one get convergence rate for free from the SLGD part, but not much insight is shed on the SVGD part (meaning if the contribution of SLGD is zero, then the bound because vacuum). This could be misleading given that one of the claimed contribution is non-asymptotic theory of ''SVGD-style algorithms\" (rather than SLGD style..). We encourage the authors to addresses the technical questions and clarify the contribution and motivation of the paper in revision for future submissions.  \n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting paper but Improvement and Clarification are needed"
    },
    "Reviews": [
        {
            "title": "a hybrid SGLD - SVGD",
            "review": "Two promising methods for scalable sample-based Bayesian inference are:\n1) SGLD: simply discretize a standard Langevin dynamics to construct a Markov chain that approximate the correct invariant distribution. This reads: \n\nx_{t+1} = x_t + \\nabla \\log \\pi(x_t) \\delta + \\sqrt(2 \\delta) \\xi\n\n2) SVGD: the method can be expressed as a type of gradient descent of an appropriate functional on the space of probability distributions. A cloud of particles {x_i}_{I=1}^M evolves according to:\n\nx^i_{t+1} = x^i_t + (some functional of all the particles) \\, \\delta\n\nThe method proposed in the article is not very different from alternating the two above mentioned update, which is indeed quite a natural idea, and can work pretty well I think. The method reads:\n\nx^i_{t+1} = x^i_t + [ \\nabla \\log \\pi(x_t) \\delta + (some functional of all the particles) \\, \\delta ] + \\sqrt(2 \\delta) \\xi.\n\nPROS:\n- yes, I think that the method can work quite OK since it may be borrowing the strengths of both SGLD and SVGD.\n- It seems that the meat of the paper consists in proving some (non-asymptotic) convergence result. Unfortunately, this went above my head and I cannot claim that I have read the details of the proofs. \n\nCONS:\n- it is (very) difficult to fairly evaluate this type of methods in high-dimensional settings. I thus appreciate that the numerical section starts with a toy very simple Gaussian model. I would have been much more interested  in fair and extensive simulations in this type of settings where it is relatively easy to compare the proposed method with SGLD and SGVD. In other words, after reading the paper, I must say that I am not at all convinced that the method does bring something over SGLD or SVGD (although it is very possible that it does).  For example, comprehensive and fair comparisons with SGLD and SVGD  in Gaussian settings (not necessarily one-dimensional) could have been presented. The delicate tuning of the different methods, the speed of convergence wrt algorithmic time, the speed of comparison wrt the number of particles, etc.. could have been investigated numerically: this would have been, I think, much more convincing.\n\nMINOR comments:\n- I did check the proof of Theorem 2, which seems hand-wavy and overly complicated.  What is the function G? It seems that the proof of Theorem 2 simply consists in establishing that if each particle x_i follows the dynamics dx = F(x)*dt then the associated densities satisfy \\partial_t \\mu_t = -\\partial_x(F(x) * \\mu_t(x))  , which is obvious. But the situation in the paper is indeed more delicate since the particles are interacting, etc... Reading this proof got me very worried and did not motivate me to read the rest of the paper.\n\nSUMMARY:\n- the method is not terribly original -- this is a simple hybrid SVGD / SGLD -- but may work very well.\n- unfortunately, the numerical experiments are not convincing.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "This paper proposes a particle-based inference algorithm, the optimal update for each particle is the summation of the standard SGLD direction and SVGD velocity.  The work further analyzes non-asymptotic properties of SPOS. The results appear theoretically interesting and of potential practical value in designing inference algorithms. I did not go through the proofs in the supplementary. \n\n[Experimental results are not convincing] \n\n[BNN] I noticed the test RMSE and test LL of SVGD are directly copied from the original SVGD paper. However, the performance critically depends on:\n1.    Running time, or training epochs\n2.    Data partitions\nTo be a fair comparison, the authors should keep at least the training epochs and random partitions the same. Especially for the dataset Year, for which only one random partition is conducted. It’s highly likely that the performance gain is due to favored data partition rather than the superiority of the algorithm.\n\n[RL] Average rewards are significantly lower than the scores reported in the original SVPG paper?\n1.    From figure 3, SPOS only outperforms SVPG on envs Cartpole Swing Up and Double Pendulum. The best reward for env Cartpole Swing Up reported in this paper is around 200. However, the score is ~400 in the original SVPG paper. For the env Double Pendulum, there’s also very large performance gap. I am aware the code for SVPG is now publicly available, the authors may consider conducting the experiments with the same settings (e.g. same seed?). Otherwise, it’s hard to tell whether the performance gain is significant while the baseline is much worse than it should be.\n2.    Only 3 envs are reported, the authors may also consider reporting all the envs are used in the SVPG paper\n\n[Figure 1] The authors may consider reporting the exact settings of this case, otherwise, it’s hard to believe that SVGD would collapse on a simple 1D case.\n\nIf the authors can fully address the concerns above, I will consider changing the scores.  \n\nOther comments:\n\n-    Related papers:\n     Stein Variational Message Passing for Continuous Graphical Models,  Wang et al., ICML18 (https://arxiv.org/abs/1711.07168)\n     Stein Variational Gradient Descent as Moment Matching, Liu et al., NIPS18 (https://arxiv.org/abs/1810.11693)\n\n-    Page 30 crashes my browser all the time\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "I have multiple concerns regarding proof of Theorem 3",
            "review": "This paper considers the problem of Bayesian inference using particle optimization sampler. Similarly to SGLD, authors propose Stochastic Particle Optimization Sampler (SPOS), augmenting Stein Variational Gradient Descent (SVGD) with diminishing Gaussian noise, replacing the hard-to-compute term of the Chen et al. (2018) formulation. Various theoretical results are given.\n\nThis paper was a pleasant read until I decided to check the proof of Theorem 3. I was not able to understand transitions in some of the steps and certain statements in the proof seem wrong.\n\nTheorem 3:\n\"Note that $\\theta^i_t$ and $\\hat \\theta^i_t$ are initialized with the same initial distribution µ0 = ν0 and we can also set $\\theta^i_0$ to be independent of $\\hat \\theta^i_0$, we can have $\\gamma(0) = 0$. $\\gamma(0) = E \\|\\theta^i_0 - \\hat \\theta^i_0 \\|^2$.\" - this doesn't seem right to me. Expectation of squared difference of two independent and identically distributed random variables is not 0, assuming expectation is with respect to their joint density.\n\n\"Then according to the Gronwall Lemma, we have\" - I don't see how the resulting inequality was obtained. When I tried applying Gronwall Lemma, it seems that authors forgot to multiply by $t$ and  $\\lambda_1$. Could you please elaborate how exactly Gronwall Lemma was used in this case.\n\n\"... some positive constants c1 and c2 independent of (M, d)$ - in the proof authors introduce additional assumption \"We can tune the bandwidth of the RBF kernel to make ∇K ≤ H_∇K, which is omitted in the Assumption due to the space limit.\" First, there is a missing norm, since ∇K is a vector and H_∇K is I believe a scalar constant. Second, c1 = H_∇K + H_F, which both bound norm of d-dimensional vector and hence depend on d. I also suggest that all assumptions are included in the theorem statements, especially since authors have another assumption requiring large bandwidth. Additionally, feasibility of these both assumptions being satisfied should be explored (it seems to me that they can hold together, but it doesn't mean that part of assumptions can be moved to the supplement).\n\nI find using Wasserstein-1 metric misleading in the theorem statement . This is not what authors really bound - from the proof it can be seen that they bound W_1 with W_2 and then with just an expectation of l2 norm. Moreover I don't understand the meaning of this bound. Theorem is concerned with W_1 distance between two atomic measures. What is the expectation over? Note that atom locations are supposed to be fixed for the W_1 to make sense in this context (and the expectation is over the coupling of discrete measures defined by weights of the atoms, not atom locations).\n\n\"Note the first bullet indicates U to be a convex function and W to be ... \" I think it should be K, not W.\n\nTheorems 3-6 could be lemmas, while there should be a unifying theorem for the bound.\n\nFinally, I think notation should be changed - same letter is used for Wasserstein distance and Wiener process.\n\nOther comments:\n\nExample in Figure 1 is somewhat contrived - clearly gradient based particle sampler will never escape the mode since all modes are disconnected by regions with 0 density. Proposed method on the other hand will eventually jump out due to noise, but it doesn't necessarily mean it produces better posterior estimate. Something more realistic like a mixture of Gaussians, with density bounded away from zero across domain space, will be more informative.\n\nIt is not sufficient to report RMSE and test log likelihood for BNNs. One of the key motivating points is posterior uncertainty estimation. Hence important metric, when comparing to other posterior inference techniques, is to show high uncertainty for out of distribution samples and low for training/test data.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}