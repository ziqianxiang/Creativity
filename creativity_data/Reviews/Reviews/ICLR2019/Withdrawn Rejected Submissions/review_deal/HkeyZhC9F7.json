{
    "Decision": {
        "metareview": "The paper proposes the use of reinforcement learning to learn heuristics in backtracking search algorithm for quantified boolean formulas, using a neural network to learn a suitable representation of literals and clauses to predict actions. The writing and the description of the method and results are generally clear. The main novelty lies in finding a good architecture/representation of the input, and demonstrating the use of RL in a new domain. While there is no theoretical justification for why this heuristic should work better than existing ones, the experimental results look convincing, although they are somewhat limited and the improvements are dataset dependent. In practice, the overhead of the proposed method could be an issue. There was some disagreement among the reviewers as to whether the improvements and the results are significant enough for publication.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Borderline paper"
    },
    "Reviews": [
        {
            "title": "Interesting application of reinforcement learning and GNN over a specific decision problem",
            "review": "The paper is proposing to use reinforcement learning as a method for implementing heuristics of a backtracking search algorithm or Boolean Logic. While I'm not familiar with this specific topic, Section 2 is didactic and clear. The challenges of the tackle problem are clearly explained in this section.\n\nThe Graph neural network architecture proposed in Section 4 to compute literals of the formula is an original idea. The experimental results look convincing and suggest this approach should be more deeply investigated.\n\nMy main concern is that the novelty from a machine learning and reinforcement learning point of view remains limited while the application seems original and promising. So I will not be strongly opposed to the publication if this work in ICLR venue while I remain unsure it is the best one.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "needs some improvement ",
            "review": "The aim of this paper is to learn a heuristic for a backtracking search algorithm utilizing Reinforcement learning. The proposed model makes use of Graphical Neural Networks to produce literal and clauses embeddings, and use them to predict the quality of each literal, through a NN, which in turn decides the probability of each action.\n\nPositives\nA new approach on how to employ Machine learning techniques to Automated reasoning problems. Works with any 2QBF solver.\nThe learned heuristic seems to perform better than the state of the art in the presented experiments.\n\nNegatives\nNo theoretical justification about why this heuristic should work better than the existing ones.\nDoesn't solve QBF formulas in general, but only 2QBF.\nIt is not clear whether the range of formulas that can be solved using this approach is greater than that of existing solvers.\nHaving a substantial amount of formulas that produce incomplete episodes, as it might be the case in real world scenarios, hinders learning, so the dataset has to be manually adjusted.\n\nConclusion\nThe proposed framework is an interesting addition to existing techniques in the field and the idea is suitable for further exploration and refinement. The experimental results are promising, so the direction of the work is worth pursuing. However, some of the foundations and overall nature of the work needs some improvement and maturity. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting application of deep learning with interesting results.",
            "review": "The paper proposes an approach to automatically learning variable selection\nheuristics for QBF using deep learning. The evaluation presented by the authors\nshows the promise of the method and demonstrates significant performance\nimprovements over a variable selection heuristic that does not use machine\nlearning.\n\nIn practice, the overhead of the proposed method is likely to be a major\nobstacle in its adoption. The authors note the difficulty of finding suitable\nbenchmarks and restrict the set of instances they use for evaluation to formulae\nwhere the proposed method is likely to achieve improvements. This skews the\nevaluation in favor of the proposed method; in particular, the 90% improvement\nfigure mentioned in the abstract is not representative of the general case.\nIndeed, on another set of instances the proposed method falls significantly\nshort of the performance of a state-of-the-art heuristic that does not employ\nlearning.\n\nA drawback of the paper is that there is no comparison to related work. I\nrealize that this is difficult to achieve because other approaches are in\nrelated, but different areas and may be difficult to adapt for this case, but a\ngeneral comparison to the improvements other approaches achieve would be\nhelpful.\n\nNevertheless, the work is interesting and presents a new angle on using machine\nlearning to speed up combinatorial problem solving. While several issues hinder\npractical adoption, this is likely to lead to interesting follow-up work that\nwill improve problem solving in practice.\n\nThe description of the method (Section 4.1) is short and not detailed enough to\nreproduce the approach the authors are proposing. However, the code is\navailable.\n\nIn summary, I feel that the paper can be accepted.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}