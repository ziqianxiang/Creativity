{
    "Decision": {
        "metareview": "The paper presents a GAN for learning a target distribution that is defined as the difference between two other distributions.\n\nThe reviewers and AC note the critical limitation of novelty and appealing results of this paper to meet the high standard of ICLR. \n\nAC thinks the proposed method has potential and is interesting, but decided that the authors need more works to publish.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Lack of novelty "
    },
    "Reviews": [
        {
            "title": "Interesting but straightforward idea that needs more development.",
            "review": "The paper presents DS-GAN, which aims to learn the difference between any two distributions whose samples are difficult or impossible to collect. To this end they simply model the target distribution such that adding it to one of the distribution results in another, and propose a min-max objective based on it. To show the effectiveness of the proposed DS-GAN, the authors validate it on semi-supervised learning and adversarial training tasks, on which it performs reasonably well in generating the difference between the two distributions. \n\nPros\n- The idea of learning the difference between two distributions is novel to my knowledge. Similar ideas have been explored in prior work such as [Li et al. 17] but are not doing exactly what the authors try to do. \n- The proposed method works reasonably well on semi-supervised learning and adversarial learning tasks, and thus it seems practically useful. \n\nCons\n- The proposed model is quite straightforward in its formulation, and since the paper is not addressing the importance of, or any challenges with the problem they are trying to solve, the contribution of this work appears minor. \n- The authors list theoretical results as contributions, but they are rather straightforward replacement of the p_d and p_g terms in the original theorems on optimality in [Goodfellow et al. 14] with the target distributions in this paper, that has nothing to do with what the authors claim in this paper.  Thus they add nothing to the value of the paper.\n- The motivation is very unclear when reading the introduction section, and Figure 1 does not do a good job of providing it.  \n- The experimental validation is lacking in many aspects. I think the main results should show that the difference-seeking GAN can learn distributional differences but the authors jump straight to the applications. Also, the current experimental section simply reports performances on the two tasks, without much analysis showing why it works well and how it works differently from other models. \n\nIn sum, the idea seems nice and interesting but the model is straightforward and the current results are very weak in analysis in order to make a good paper. I would recommend the authors to perform further analysis of the model either theoretically or experimentally.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting problem formulation, but the method doesn't seem innovative and the empirical results not very convincing",
            "review": "- Summary:\nThis paper considers the problem of learning a GAN to capture a target distribution p_t with only very few training samples from p_t available.\n\n- Good\nAn interesting problem formulation. \nThe proposed approach is not new, but seems to be a sensible and simple solution to the problem formulated in this paper. I would see the contributions of the paper: (1) an interesting problem formulation on how to learn p_t (with a few assumptions) (2) a sensible adaptation of GANs on this problem (with minor modifications to GANs which have been observed/adopted in many GAN literatures in the last two years)\nThe training appaoches/tricks are rather straightforward and not new as well.\n\n- Suggestions\nThe main problem of this paper is that it does not provide sufficient results on any real applications that can support its problem&model formulations. \nFor example, in which scenarios would the users of the model need to train a GAN to mimic a target distribution p_t which is a difference of another two distributions (with examples available there but unavailable in p_t)? It would be good to show significant results on real applications to show the problem and the method useful.\n\nTwo applications on semi-supervised classification and adversarial training are discussed. While both seem to be very artificial IMO if considering the used dataset and designed experiments. The results are also not convincing even for the shown two experiments compared to baselines.\n\nNo related works on addressing the similar problems have been discussed nor compared in experiments.\n\n- Theoretical results:\nWhile the authors claim new theoretical results, in fact, I didn't see any contributions here as the theories developed in section 3 are mostly rather straightforward. There have been some similar theories being developed in previous papers where a component in GAN exhibits mixture-modeled forms, such as in TripleGan (Li et al. NIPS'17). So I would not recommend the authors to claim contributions here.\n\n- Writing:\nThe paper does not seem to be polished. It may not be necessary to exceed 8 pages as many spaces in this paper could be easily squeezed (apparently). The organization could be better; Some parts are vague and difficult to understand;  the writing could be improved to be more clearly demonstrate the contributions of this paper. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Potentially Interesting Method but the Paper Needs Polishing",
            "review": "The paper presents a new Generative Adversarial Network (GAN) for learning a  \ntarget distribution that is defined as the difference between two other \ndistributions. Applications in semi-supervised learning and adversarial training \nare considered in the experimental evaluation and results are presented in \ncomputer vision tasks. \n\nThe paper is not very well written and can be hard to follow. One very important \nissue for me was motivation for defining the target distribution as a difference \nbetween two other distributions. I am not familiar with this area, but reading \nthrough the introduction it was never clear to me why this is a useful scenario, \nin practice. Furthermore, some statements in the introduction felt quite \narbitrary. For example, the authors state that PixelCNN \"does not have a latent \nrepresentation\" in a manner that makes it sound as if that is a bad thing. If \nindeed it is, then why so? It would be very helpful to motivate the setting more \nand to provide a couple of examples of where this method would be useful, in the \nintroduction. Also, regarding the MNIST example in the end of page 1, what is \nthe \"universal set\"? This paragraph also felt a bit arbitrary and unclear.\n\nSome comments about the rest of the paper:\n  - The theoretical results of section 3 are just stated/listed, but are not \n    connected to algorithm 1. Please connect them to the different parts of the \n    algorithm and state in a couple sentences what they imply for the algorithm.\n  - Right after theorem 1, which assumption are you referring to when you say \n    \"the assumption in Theorem 1\"?\n  - The reformulation of section 3.1 is never justified. What led you to use \n    this reformulation and why do you think it is more stable in practice?\n  - You should mention in the caption of table 4, what quantity you are \n    computing.\n\nNote that my evaluation for this paper is based mainly on the way it is written \nas, in its current state, it is hard for me to judge what is novel and what is \nuseful, and what readers are supposed to take in by reading this paper. The main \nquestion that the paper definitely needs to answer, but does not do so currently \n(in my opinion) is:\n\n  When is this method useful to readers? For solving which problems and under \n  what conditions? And also, when is this method bad and should not be used?\n\n== Experiments ==\n\nSection 5.1 is hard to follow and I don't quite get how it connects to the rest.\n\nAlso, in section 5.1.2 you mention that in comparison to Dai et al. (2017) your \nmethod does not need to rely on an additional density estimation network. Even \nif that is true, I cannot see how it is a useful remark given that the method of \nDai et al. seems to always beat your method.\n\n== Style ==\n\nIn figure 1, no labels or legends are provided making it hard to figure out \nwhat's going on at a glance. It would be very helpful to include labels and a \nlegend.\n\nEquation 2 is not written correctly. The equals sign only refers to \"V(G, D)\" \nand not the min-max of that, right? Please make that explicit by first defining \n\"V(G, D)\" alone.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}