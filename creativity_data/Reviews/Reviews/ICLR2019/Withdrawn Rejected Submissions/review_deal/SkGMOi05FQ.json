{
    "Decision": "",
    "Reviews": [
        {
            "title": "Lack of baselines and insufficient analysis",
            "review": "This paper presents an approach of using GANs for text generation by training a Skip-thought sentence embedding model and applying GANs to distinguish embeddings from the training corpus encoded with a skip thought encoder and sentence embeddings generated by a CNN.\n\nWhile the paper gives some initial experimental results in table 1, there are major gaps in the experiments. For example, there are no comparisons with maximum-likelihood trained models or comparisons with other existing GAN architectures. Without these comparisons, it's hard to see the benefit of having the skip-thought architecture compared to the existing text GAN literature such as SeqGAN and MaskGAN.\n\nThe improvements gained with Wasserstein and gradient penalties are interesting but results on more datasets and longer samples are needed, especially section 4.2 would benefit from quantitative and human evaluation.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Paper badly written and very little contribution",
            "review": "This paper precomputes skip-thought vectors and then feeds it into several types of GANs to use the skip-though decoder on generated samples of skip-thought vectors.\n\nThe contribution of this paper is almost trivial which is worsen by truly bad writing and questionable experiments. Paper does not provide any comparison to previous work.\n\nThe paper seems to be written in rush:\n- no conclusion nor summary\n- the introduction does not properly introduce nor motivate this work\n- experiment description is very scarce and not sufficient for understanding (what is the metric? how to compute it? why is it reasonable? only a couple of questions paper should have answered)\n\nAnd minor points:\n- many citations are missing the year (I suggest to add \"circa ...\" if it is unknown)\n- strange question marks on p3\n- references to Tables 2a-d seem to be broken",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "No novelty and very poor/limited experiments.",
            "review": "The paper describes the application of generative adversarial networks for modeling textual data with the help of skip-thought vectors. The authors experiment with different flavors of GANs and show experimental results for two different datasets.\n\nThe paper suffers from different weaknesses as listed below:\n-\tThe paper lacks novelty. The presented architecture is just a specialization of adversarial autoencoders where, in this specialized version, the noise vector is processed by some conv. layers before given as input to the discriminator. It is also very similar to “Adversarially Regularized Autoencoders” (Zhao et al., 2018)\n-\tThe paper is poorly written. For instance, the method is not properly described. Sec. 3.3 is quite short and confusing. Fig. 1 is not even referred to inside the text.\n-\tThe experimental setup used is quite weak and do not give real evidence of the advantages of the proposed method.\n-\tThere is no comparison with previous text generation methods. The authors only present results for different versions of their own approach.\n\nDue to the many issues listed above, my recommendation is for rejection.\n\nMinor question: What do the authors mean by: “Unknown tokens are not included in the vocabulary.”? By definition, “unknown” tokens aren’t exactly the ones that do not appear in the vocabulary?",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}