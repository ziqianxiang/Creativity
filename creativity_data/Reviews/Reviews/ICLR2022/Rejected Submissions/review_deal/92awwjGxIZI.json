{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "Based on the contrastive learning loss wildly used in the NLP and computer vision domains, this paper presents Self-GenomeNet, a contrastive learning method for representation learning of genomic sequences.\nAs shown in the experiment section, the improvement compared to baselines CPC, Language model, and even supervised learning method is considerable, on three benchmark datasets in both self-supervised and semi-supervised evaluation.\n\nEven after the discussion phase, there exists disagreement among the reviewers.\nAC considered all reviews, author responses, and the discussions, as well as read the paper.\nWhile the paper has some merit such as an effective Self-GenomeNet model for the particular problem setup, reviewers still have several reservations to directly accepting it:\n+ Questionable impact. The proposed framework is overall a simple combination of existing methods and beyond genome datasets, the impact of this proposed method is questionable.\n+ Limited inspiration. The proposed method is mainly constructed on the previously-proposed contrastive learning loss wildly-used in the NLP and computer vision domains, the benefits of the proposed method may be limited on the genome data (especially the domain-specific data augmentation e.g., reverse complement). How can the insights foster future research?\n+ Lack of justification. The innovations introduced by the paper seem ad-hoc, and the reasons for the large observed improvement are not entirely intuitive.\nMeanwhile, even with the provided response from the authors, the connection between motivation and the proposed method is still not crystal clear.\n\nGiven the above reservations, AC could not accept the paper for now but encourage the authors to fully revise the paper and strengthen their work."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a self-supervised learning approach using contrastive loss for representation learning of genomic sequences. The contrastive loss has been used for self-supervised learning in the NLP and computer vision domains and the paper presents its application for genomics. Self-supervised contrastive learning tries to maximize the agreement between augmented views of a sample. Therefore, Self-GenomeNet splits a sequence into two subsequences, and the learned representation of subsequence 1 is compared to subsequence 2 and its revers compliment (positive samples) as well as other sequences (negative samples). The described method has two considerations specific to the genomics tasks - (1) it handles variable sequences (2) it incorporates reverse complement information of the sequences. The method is applied on two prediction tasks and one transfer learning task using sequences from viral, bacterial, and human genomes. Its performance is compared to the supervised model, generative language model, and self-supervised learning models - CPC and Contrastive-sc. The results show improved classification performance over the baseline for both supervised retraining and semi-supervised training settings. ",
            "main_review": "Strengths:\n\n+ The idea to use self-supervised contrastive learning for genomic sequences is interesting and well-motivated\n+ Proposed changes to the existing model are domain-specific and relevant for the application of the method for genomic tasks\n+ The improvement in classification performance over supervised models is promising, especially for 0.1% and 1% labels cases, is promising. \n+ The results indicate that learning robust representations via contrastive loss-based self-learning of the sequences can lead to better performances for supervised and semi-supervised learning in genomics.\n\nWeaknesses:\n\n- The paper's central claim is that self-learning-based methods can help with genomics tasks with limited data. However, the datasets used in the paper do not reflect those tasks and have an ample amount of labeled information. While the label scarcity is simulated in some results, it would be helpful to demonstrate the applicability of Self-GenomeNet for classification for genomic tasks with limited labels. \n- The rationale for the choice of the datasets, models, and baselines is not entirely clear. For example, there are more recent methods (like Basenji) that perform genome sequence classification. So why was DanQ chosen as the model of choice? \n- Similarly, how was the model architecture for classifying viral genomes selected? Are there existing deep learning models performing this task? \n- Data imbalance is an issue for both Virus and DeepSEA datasets. Why were different evaluation metrics chosen for the classification tasks on the two datasets?\n- It is unclear how the training for the baseline models like CPC was performed? Was sufficient hyperparameter tuning performed for all the models?\n- I am not entirely sure how the model can perform transfer learning from bacteria to virus datasets. Was the model trained using bacteria sequence (or a part of it) re-trained on viral genomes? \n- The ablation analysis needs to be more comprehensive. It is also unclear if the variable sequence length was explored thoroughly. It seems that only 2 settings were tried - 150 and 72/78. \n\nMinor points:\n- The result section could be arranged better for making it easier to follow\n- Typo in Table 6 caption: \"din\"\n- Table 5 results are repeated in Table 8\n- Are the ablation study differences for forward and reverse-compliment strands significant?\n- The related work section for genomic sequence predictions could include more recent works than DeepSEA and DanQ\n- The input length of 150 bp might be limiting the model's performance as studies have shown that longer DNA sequences can better capture the neighboring context of the signal being predicted. \n",
            "summary_of_the_review": "Overall the ideas presented in the paper are interesting and potentially useful. However, limited experiments and results fail to support the main claims of the paper. The results could include tasks with label scarcity and some of the choices for experimental settings are unclear. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This submission introduces self-genomenet, a self-supervised training\nmethod for learning from DNA sequences. The self-supervision is done\nby predicting the end of a sequence from its start (both broken into\nsmaller subsequences), through a contrastive loss against other random\nsequences. The predicted part is also reverse-complemented (RC),\nmaking the network learn the expected reverse-complement invariance of\nthe prediction function. The method is extensively tested on several\nlearning tasks, where it shows good performances.",
            "main_review": "The question of self-supervision for networks predicting from DNA is\ntimely, given the success encountered by this paradigm in other\napplications of learning. The proposed contribution is novel, and does\nseem to improve the prediction performance on a variety of tasks. The\nevaluation is thorough, including large datasets from different\ndomains of the tree of life, relevant baselines and assessments on\nfine-tuning, semi-supervised and transfer learning settings. It also\nincludes an ablation study confirming in particular the contribution\nof (i) training on variable sequence sizes and (ii)\nreverse-complementing the piece of the sequence to be predicted.\n\nMy main concern is on the clarity of the manuscript, in particular:\n\n- The terms \"encoder\" and \"context\" networks are used without being\n  clearly defined. It could help to say earlier to which architectures\n  (respectively, a CNN and an RNN) they refer specifically.\n\n- I found the use of macro-averaged recall confusing: my understanding\n  is that in this context (binary classification) it is equivalent to\n  balanced accuracy, but it first seems like only recall is considered\n  (as opposed to eg precision or anything else quantifying false\n  positives).\n\n- The claims on RC-invariance should be clarified. For example in 3.2\nit is claimed that \"The architecture enforces the symmetry implied by\nthe RC\". Is it really the case? It seems like the network could learn\nto be RC-invariant, but that the invariance is not built in.\n\n- It was not immediately clear to me why the self-supervision task\nmade sense (predicting the end of a sequence from its start,\ncontrastively to other sequences). It made more sense when I saw the\ntask of predicting a class of sequence (prophage vs non-prophage\nviruses. Maybe this could be justified earlier. Maybe more\nimportantly, is the relevance of this self-sueprvision universal, or could it be\nless efficient on some other tasks?\n\nThe writting could also be improved, eg:\n\n- \"One likely explanation is that, because we maximized the mutual\ninformation between the learned embeddings and varying-length target\nsequences with both short and long inputs.\"\n\n- \"One loss term is introduced for each index i, denoting\n  the number of patches represented by z i\"\n\n- \"We investigated the effect of the change in length of target subsequen-\nces by comparing our method against the single-length or longer target subsequences.\"\n\n- \"Self-GenomeNet uses the embedding representation of a context\nnetwork for downstream tasks which learns from reverse complement as a\ntarget for its predictions.\"\n\n- In Section 3 (motivation) I also found the formulation unclear: the\ntext suggests that CPC doesn't deal with multiple sizes, and then says\nthe opposite.\n",
            "summary_of_the_review": "The contribution is novel, timely and useful to the community. Its assessment is thorough. The clarity of the manuscript could be improved.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Recently several works have proposed semi-supervised learning methods to leverage unlabeled biological sequences for learning their general-purpose representations. In this work, the authors proposed the Self-GenomeNet, a novel contrastive learning method for nucleotides based on the reverse-complement (RC) context prediction. First, given a sequence, they divide it into two subsequences and transform one into its RC. Then, the model is trained to distinguish their representations from those of other random nucleotide sequences. The authors claimed that the proposed method considerably outperforms previous self-supervised baseline models on three benchmark datasets in both self-supervised and semi-supervised evaluation ",
            "main_review": "-\tWhile the paper has its own merits, my biggest concern is that the connection between motivation and the proposed method is not crystal clear. I agree that pursuing the representation equivariance of two reverse-complementary sequences is an important research direction. However, the proposed method deals with representations of two subsequences. Even if they are originally from a single sequence, RC of one subsequence does not make it reverse-complementary to the other subsequence. I’m not sure why the prediction of S^bar_(N:t’) is more helpful than the prediction of S_(N:t’) or S^bar_(1:N).\n-\tOn page2-line3, the authors stated that “our method divides a sequence into two complementary subsequences..” I don’t think the authors meant that they are composed of complementary nucleotides (A^bar = T), but it might be misleading for some readers. \n-\tOn page3-line10, the authors stated that “positive pairs include the input sequence and a reverse-complement of the sequence.” However, this is not entirely correct. The proposed method used one subsequence and the RC of the other subsequence as the positive pairs. \n-\tOn the page3-last sentence of the background, the authors stated that “exploit this genome-specific feature to tighten the lower bound between mutual information between learned representations.” However, I could not find theoretical or empirical grounds to claim that the proposed method tightens the mutual information lower bound. Please clarify the point.\n-\tIn Sec3.2-line4, the authors stated that the proposed architecture makes training more efficient. Can you explain why it is more efficient? \n-\tPlease provide some missing experiment setups. (1) which value was used for “m” in the proposed loss term. (2) length statistics of the three datasets. (3) Training time and learning curve for the proposed method.\n-\tAccording to the network architecture section, it seems using the DanQ model architecture for the DeepSEA dataset causes some issues that only 3.6% of parameters are trained in the self-supervised stage. Then, why didn’t you use the model architecture used for the Virus dataset? \n-\tTo be self-contained, please provide more algorithmic details for the compared baselines. In addition, can you clarify whether the baselines use the N-gram or single nucleotide for the pre-training? If it is the latter, can you also provide the results for using the N-gram?\n-\tDo you have any specific reasons for using the recall as the evaluation metric? Can you also compare them in terms of the F1 score?\n-\tIn Table7, the authors compared the autoregressive models reading the target subsequences in forward, reverse, and RC directions. What is the difference between the forward model and the CPC model? In my view, the relatively small performance difference between the forward and RC models might indicate that the effectiveness of the proposed method based on the RC-equivariance is not significant.\n-\tWhile the proposed method is largely motivated by the RC equivariance, the paper does not seem to provide sufficient theoretical or empirical analyses concerning the point. (1) Since the RC-equivariance is not guaranteed within the model, can you show how well the learned representations satisfy the RC equivariance? (2) Can you compare its performance with those of previous RC-equivariance techniques on some NGS datasets?\n",
            "summary_of_the_review": "While the paper has its own merits, it has several issues to be addressed regarding (1) the connection between motivation and the proposed method, (2) theoretical or empirical analyses concerning the RC-equivariance, and (3) some questionable experiment setups. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors proposed a self-supervised learning method for nucleotide-level genomic data utilizing reverse-complement of genomic sequences. The proposed method achieved a considerable performance improvement. In addition, the authors proposed an architecture called Self-GenomeNet that handles varying-length genome sequences.",
            "main_review": "**Strengths**\n* The proposed method is simple yet effective. The domain-specific data augmentation (e.g., reverse complement) improves the representation power considerably. \n* Unlike CPC or skip-gram methods that use a fixed-length short subsequence, the proposed method trains models based on varying length sequences. \n* The improvement compared to baselines CPC, Language model, and even supervised learning method is considerable.\n\n\n**Weaknesses**\n* The proposed method is constructed by existing methods and beyond the genome data, the benefits of the proposed method are limited.\n* If the authors provide more explanation about the difference between the proposed method and baseline algorithms such as contrastive-sc, it would be better to evaluate the main contributions of this manuscript.",
            "summary_of_the_review": "The proposed method is a simple and effective contrastive learning method and shows great representation power. The proposed method showed the best performance in many different settings such as linear evaluation and semi-supervised learning. The reverse-complement based data augmentation seems simple and effective. However, the proposed framework is overall a simple combination of existing methods and beyond genome datasets, the impact of this proposed method is questionable.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}