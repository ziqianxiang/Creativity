{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The authors consider an interesting approach for modeling analogical relations through Abelian group networks. While the conceptual contributions in the work, the explicit introduction of Abelian relations in particular, were generally appreciated, the reviewers found the numerical results provided in the paper lacking. In addition, several issues regarding the scope of the problems to which the proposed approach applies have been raised. Thus, given this, and the exchanges between the reviewers and the authors, in its present form, the paper cannot be recommended for acceptance. The authors are encouraged to incorporate the valuable feedback provided by the knowledgeable reviewers."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a method of learning word analogies by training a network to explicitly model analogical relationships using an architecture based on invertible projections, which they show induces an abelian group on the input space. With a supervised setup using a training set of word analogies, the paper shows improvements over baselines that do not model this structure.",
            "main_review": "Strengths:\n\n1. The approach is motivated well, the proposed abelian network is very interesting and could have applications for other tasks. \n2. The paper is written well and is very easy to follow\n\nWeaknesses:\n\nThe experimental setup seems quite weak:\n1. The authors only consider only word embedding setup (word2vec) which is several years old and many other better-performing embeddings (on word analogy task) have since been proposed such as fasttext or glove.\n2. Even with word2vec, the proposed approach only outperforms baselines in a specific case (where we exclude query words from the candidate set). \n3. Why is this problem interesting in itself? A side effect of learning unsupervised word embeddings was they perform well on word analogies, however, it is not clear why training of this specific task is important. Does that improve the embeddings for any downstream tasks where they can be used?\n\n---- \n\nUpdated the score from 5 to 6 after rebuttal\n",
            "summary_of_the_review": "While the presented premise and the theory of abelian neural networks is quite interesting and may have interesting applications, the experimental section seems weak and needs additional results/motivation.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Does not have any ethical concerns in my view.",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors introduce Abelian group networks (AGN) that explicitly model the operational relation between elements in an Abelian group. The authors prove that the design has the ability to model such relations and present feasible neural network realizations. The authors also prove the ability of AGN to learn representations of multisets. The authors design experiments to test AGN's ability to model word analogy by viewing the \"a:b = c:d\" relation as $c - a + b$. The results seem to suggest that AGN outperforms MLP baselines always and word vectors in some cases. However, closer examinations reveal concerns about their strength and validity to support the efficacy of AGN.",
            "main_review": "### Pros\n- Novel interesting idea of explicitly incorporating Abelian relation prior into neural networks.\n- Theoretical proofs for the claimed properties regarding the AGN's ability to model Abelian relations and multisets.\n\n### Cons\n- Insufficient empirical evidence that AGN will help certain kinds of learning tasks in a realistic setting. The current evaluation is restricted to the word analogy task and does not show a definitive gain under practical settings. The strengths of the MLP baselines are questionable. Important details missing. See questions below and localized points below (Table 2-6).\n\nI think the authors could improve the strength of the work by any of the following.\n1) Looking for better tasks that can showcase the benefit of modeling Abelian relation explicitly. The arithmetic relation between word pairs is thought to be an emergent property of the popular word vector learning objectives. In other words, it may already be well-modeled by word vectors and thus AGN does not give a further advantage. At least a discussion about possible applications to a wide range of tasks would show the proposal has a greater impact.\n2) Showing that AGN indeed gives a notable boost to word analogy in a practical setting. For example, not when WV is weakened when a, b, c are present (Table 2,4,6). Those words can easily be excluded in practice. I think Table 3 gives positive results but there are numbers in that table that seem off to me, which leads to the next point.\n3) Making sure the experimental settings are described well and all the interesting/unusual observations from the results are addressed. For example, why would accuracy drop when excluding a, b, c, in Table 3? Why are MLPs so bad in Table 6? Those unusual observations may be related to problematic settings/processes, or unrealized behaviors/findings. In either case, it will be worth examining.\n4) Comparing to competitive baselines. WV is an attested and competitive baseline. However, MLPs used in the paper seem to be particularly poor. Especially, why would they be poorer than WV (Table 3, 4, 5, 6) when they are built on top of WV? I think this suggests there is something wrong with the design and/or training. Thus, we don't really know if AGN has an advantage over MLP.\n5) Showing AGN is advantageous in other aspects, e.g. interpretability, rather than focusing only on accuracy.\n\n### Questions to the Authors\n1) What is exactly the neural network architecture used in the experiments?\n2) What are the authors' thoughts or plans in applying/experimenting AGN for other tasks / in other settings?\n3) Localized points below for Table 2-6.\n\n### Localized Points\n1) Eq (5). Are w^{(k, j)}, b^{(k, j)} for 1 <= k <= K, 1 <= j <= J_k all trainable parameters?\n2) End of P7. Worth explaining what is \"the Glow architecture\" used here.\n3) Table 2. The competitive results for MLP_C suggest a simple linear underlying relation between embedding vectors. All the extra theory and design may be overkill.\n4) Table 3. Compared to Table 2, for example, the last two numbers of MLP_C, I don't understand why there can be a drop? I think removing words a, b, c would only help? Are they cases where the correct answer is one of the words a, b, c, such as \"split: split\"? If that is the case, we should probably remove impossible queries or at least make a remark on the existence and frequency of such cases. \n5) Table 4 and 5. The numbers make it seems like the benefit of AGN is to reduce confusion from a, b, c. However, we can easily exclude them in downstream applications.\n6) After Table 5. \"This is probably because the word2vec model was highly tuned for the Google analogy test set for this evaluation method.\" Do we have a better dataset, or even a better task, to showcase the benefit of the proposed approach?\n7) Table 6, \"we enumerated the answers of each model for some toy example relations\". How are the examples chosen? Random? Or by some criteria? \n8) Table 6, the first half. This may be a nice verification for the theoretical property, but it is hardly helpful in practice: one can write some simple logic to give the right answer for \"a:a = b:?\" queries.\n9) Table 6, the second half. WV does just as perfect as AGN, so it does not particularly show an advantage. MLP and MLP_C failed completely. The comparison does not seem to support AGN is better, but rather there is something really bad happening with MLP and MLP_C and makes one doubt the legitimacy of them as competitive baselines. \n10) After Table 6. \"On the other hand, the MLP-based models failed in most cases, which indicates that they are not good at the type of examples different from the training dataset.\" I feel it impresses more as if we should put a better effort into designing and tuning baseline MLPs. Why are they giving nonsensical predictions while still making reasonable numbers in previous tables?",
            "summary_of_the_review": "Novel and interesting idea of adding explicit Abelian constraints into neural networks with proofs that AGN is able to model Abelian relations. However, the scope is limited to word analogy and experimental results do not provide good support that AGN is advantageous than word vectors and MLPs.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces a new kind of neural network for multisets of vector inputs. Whereas DeepSets uses a function h(x, y) = g(f(x) + f(y)), the proposed model uses h(x, y) = f^{-1}(f(x) + f(y)), where f is an invertible neural network. It applies this network to the problem of learning word analogies.",
            "main_review": "While the paper is generally reasonably clear, I feel that it takes a long time to get to the main idea, which is on page 5-6 of 9. The preliminaries (some of which are not actually used until the Appendix, I believe), related work, and elementary proofs on page 5, take up quite a lot of space.\n\nSo it's surprising to me that in the methods section, \\phi, a critical component of the model, is left undefined. Its definition does not come until the bottom of page 7, in the experiments section, and even then, the definition is not an equation, but just the name of the network (Glow) and a citation.\n\nCould you explain why commutativity is needed to model word analogies? Even if \\circ is noncommutative, wouldn't you still have the property that a = b -> f(a,b,c) = c and a = c -> f(a,b,c) = b?\n\nYou write: “We mitigate this issue [of eliminating a, b, and c from the candidate set] by learning richer functions than addition and subtraction.\" But this seems to be not borne out by the experiments, where WV+AGN benefit greatly from eliminating a, b, and c from the candidate set, while WV+MLP and WV+MLP_C do not.\n\nOn the Google analogy test set, the proposed model does not outperform WV. You write: “This is probably because the word2vec model was highly tuned for the Google analogy test set for this evaluation method.\" While this is possible, do you have a citation or evidence for this claim?\n\n",
            "summary_of_the_review": "This paper describes a simple and interesting method for modeling unordered data that has some nice theoretical properties, like generalization from smaller to larger sets. However, it is applied to only one problem, the word analogy problem, where the sets are always of size 3 and the importance of commutativity could be made more clear. Experimental results are mixed, with the proposed model performing the best on BATS but not on the Google analogies dataset.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}