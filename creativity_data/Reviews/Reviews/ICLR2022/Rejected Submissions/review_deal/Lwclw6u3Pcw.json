{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "*Summary:* Compare neural networks and tasks using TDA, particularly persistence diagrams. \n\n*Strengths:* \n- Some reviewers found this a fresh perspective. \n- Distance calculation using TDA can offer advantages and a theoretical basis. \n\n*Weaknesses:* \n- Insufficient motivation and experimental evidence for utility of the proposed approach. \n- Computational cost and hyperparameter choices in PD computation. \n- Difficulty of interpreting proposed distance matrices. \n\n*Discussion:* \n\nZGgm found the paper interesting and that it offered a fresh perspective, but that the purpose of the comparison was not sufficiently well motivated. The authors provide some explanations, particularly about the method allowing to compare networks of different sizes, but ZGgm found their comments were not adequately addressed. rtBj found that even though the authors made efforts to address their comments, the paper still requires substantial improvements. HwgX appreciated the authors’ responses but considers that the paper needs to be improved with additional validation. They expressed doubts about the adequacy of the approach and found that although it improves upon certain methods, it is insufficiently verified. \n\n\n*Conclusion:* \n\nAll reviewers agree that this work has some strengths but also significant weaknesses and does not reach the acceptance bar for this conference. Main weaknesses are insufficient motivation and experimental evidence. The reviewers made several suggestions on how the paper could be improved. I agree with the reviewers and hence I must reject this article."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper converts a given NN to a weighted directed graph and consider the flag complex on the top of it and use that object to compute the PD of the input NN. Two neural networks are then considered to be similar iff the PDs are close enough with respect to WD. ",
            "main_review": "I think the paper is interesting and novel. The idea of converting the NN that way to PD is something I have not seen before. However, I have many concerns about the paper.\n\nNeural networks are functions, and it it is not clear if two neural networks that have different architectures should be not similar. This method suffers from this in my opinion. You might have two neural networks that are totally different, one of them is giant and one of them is small and yet they are similar in the function they do--this will not be captured by the the method presented--at least this is not justified.\n\n- also, more importantly, why do you want to measure similarity between two NNs? I think it is interesting mathematical purpose but it is not clear from a practical perspective why you want or need to do that?  ",
            "summary_of_the_review": "While the paper is interesting and offers fresh point of view, I feel the paper lacks justification of important parts : such as why do we need a similarity between two NNs.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "In this work, the authors propose to characterize neural networks with Topological Data Analysis, more precisely with its main descriptor, the so-called persistence diagram, in order to be able to compare neural networks with different numbers of layers, different numbers of neurons, or trained on different data sets. More specifically, they show that the computational graphs corresponding to the neural networks can be filtered using the edge weights that are learnt during training, in order to produce filtered flag complexes, from which persistent homology can be computed. Then, the authors interpreted the distances between the persistence diagrams obtained from networks with varying parameters (number of layers, neurons, labels), and showed that, often, the distances have intuitive correlation with the complexity of the networks.\n",
            "main_review": "The article is well written and proposes an interesting approach, but I have some trouble figuring out how powerful and meaningful the method actually is, due to the lack of theoretical back-ups and the vague, hand-waving interpretations of the set of experiments. \n\nI have the following comments:\n\na. I understand that thresholding persistence diagrams is important for keeping the running time reasonable, but, on the other hand, setting the lifespan threshold to 0.01 seems pretty arbitrary. It would be nice to comment about how this threshold was chosen in the text.\n\nb. It is quite difficult to interpret the proposed distance matrices and values. Increasing and decreasing values of distances can be caused by many factors, and not only the ones suggested by the authors. For instance, simply increasing the size of the graphs sometimes results in larger distances just because the persistence diagrams have more points, invalidating some of the authors interpretation. In order to be fully convincing, I think some null statistical model should be provided and compared to, with some corresponding p-values. See for instance https://openreview.net/pdf?id=rHaiOtGdRS. Otherwise, it is impossible to go beyond vague comments and explanations of the results.\n\nc. I am not sure about how useful are these distances. Even though they seem to detect a few properties of the network, they do not seem to always be very discriminative: some architectures with very different hyper parameters coming from different experiment groups can end up quite close in the proposed distance. Indeed, values that are outside of the blocks corresponding to the various experiments can still be very small in the distance matrices. Hence, I am not sure if there are settings in which using this distance actually make sense, practically speaking. Would it be possible, for instance, to do model selection based on it?\n\nd. Topological uncertainty (https://www.ijcai.org/proceedings/2021/367), is a good reference to add in the related work section, since it also aims at characterizing the shape of neural nets with persistence (for another application though).\n\n[Post rebuttal comment] Even though I appreciate the author's responses and suggestions, I still think that the paper requires substantial improvements before publication, so I did not change my grade.\n   ",
            "summary_of_the_review": "While the approach is novel and interesting, I think the experiments are not convincing enough and too hand-waving to definitely validate the procedure. Since the approach is purely experimental, I think the work is too preliminary for publication.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors give a method to evaluate the closeness of a task considered by a neural network. They represent a trained NN as a weighted graph and extract features of the NN by calculating persistent homology from the graph.\nThe distance between NNs is calculated by calculating the distance between persistent homologies, and it is experimentally shown that the corresponding tasks of each NN can be determined whether they are similar or different.",
            "main_review": "Strength\n- This paper shows that the distance between graphs calculation using TDA is more suitable for comparing tasks than the general method of calculating the distance between graphs.\n- Constructed a framework for comparing trained NNs and demonstrated its effectiveness for simple methods.\n\nWeakness\n- As mentioned in the Related work section of this paper, Rieck et.al.(2019b) have shown a method for representing NNs as graphs and analyzing them with TDA. On the other hand, when the intrinsic graph structures of NNs are similar, they correspond to almost the same task, and when the tasks are completely different, the NN structures are often very different.（It is possible that the structure of NNs will be similar for different tasks, but I don’t think we need to worry about it practically.）The proposed method is based on the fact that NNs for similar tasks have similar graph structures, and TDA is good at analyzing graph structures. Therefore, the idea of the proposed method is not particularly new.\n- The structure of a trained NN depends on the training data, loss function, and optimization algorithm. Even if the NN is for the same task, the structure of the NN is often different if they are different. In this study, verification under different conditions is lacking, and we cannot say that the proposed method measures whether the NNs are for the same task or not. However, it is worthwhile as a comparison under the same conditions, so it will be a sufficient contribution if specific applications are shown.\nMinor comment\nTable captions are usually written above the table.\n",
            "summary_of_the_review": "The contribution to the proposal and validation of a more effective framework for comparing trained NNs is acknowledged. On the other hand, the novelty of the idea is low and its applicability is questionable.\n\n[Post rebuttal comment] I appreciate the author's responses. The author's perception was clear to me, but I think it still needs to be improved with additional validation, so I did not change my grade.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In order to characterize and measure the similarity of two neural networks, this paper uses abstract simplicial complex to represent neural networks. The Persistent Homology of the constructed graph associated to a neural network is computed to obtain the corresponding Persistence Diagram. To calculate and quantify the similarity, the authors use supported vectorized persistence summaries: Persistence landscape, Weighted silhouette, and Heat vectorizations respectively and compare their ability to measure the similarities between neural networks. Detailed and complete experiments are conducted on different kinds of datasets. Each experiment only contains one modification on hyperparameter.  Results show that the PH-based representation did characterize and capture latent information from the networks.",
            "main_review": "## Strength\n1.\tThis paper presents a new approach to represent neural networks which includes abstract simplicial complex representation and PH method. It is novel and insightful to combine neural networks similarity measure and topological methods. Especially, using PD discretization to measure the similarity is intuitive and reasonable.\n2.\tThis paper is well-supported theoretically. Both the topological characterizations associated to neural networks and PH methods for measuring similarity are technically sound and significant for the problem studied.\n3.\tThis paper is well written and easy to understand. Although I think the display of experimental results could be arranged more reasonably (see weaknesses 1)\n\n## Weakness\n1.\tAs mentioned in the introduction, a correct characterization should be able to distinguish whether two neural networks are trained for the same task, regardless of subtle differences in architecture, input order, etc. However, discussion about how PD discretization recognizes the different types of tasks better than 1-norm and Frobenius norm (similar to figure3), not only in the control experiments, is not clear and sufficient.\n2.\tVery few details are given about the calculation of PD discretization, i.e., Persistence landscape, Weighted silhouette and Heat vectorizations. Their calculation and topological meaning may explain partly why Heat and Silhouette separate the experimental group better than Landscape, which is worth exploring as well.\n\n",
            "summary_of_the_review": "The motivation and the problem studied in this paper is interesting. The authors present a novel and effective approach to represent neural networks in a topological way and propose a similarity measure using PD discretization, which is supported by the experimental results. However, the discussion part could be more focused on the discretization’s ability to separate the experiment groups, rather than sensitivity to parameter changes. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}