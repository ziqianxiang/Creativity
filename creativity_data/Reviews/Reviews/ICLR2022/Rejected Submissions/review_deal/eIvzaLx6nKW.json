{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper introduces a multi-domain self-supervised representation learning method. Its objective consists of three terms: the first two terms are identical to SimCLR and the last one is to minimize the similarity of pairs across different datasets which is similar to the second term of SimCLR. In the experiment, it tests the methods across multiple common datasets. The method is simple but results are pretty good at the multi-domain setting. It seems to demonstrate the importance of domain clustering and moving the domains apart. However, there are several important questions the paper may need more clarification on: \n1. What is the definition of the domain? How to determine the pair of data is from different domains? What is the motivation/theory that you used to choose those datasets as different domains in your experiment? \n2. Is there any of the public datasets that would cover multiple domains? \nWithout solving these questions, I think it would constrain the future research/adoption of the method."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a method for multi-domain self-supervised representation learning (MDSSL).  The contrastive MDSSL training objective consists of three  terms: (1) a loss  term  that  maximizes the similarity between two transformed views of a sample in the latent space (identical to SimCLR), (2) a loss term that maximizes the similarity between every pair of samples within a dataset,  and  (3)  a loss term  that minimizes the similarity between pairs of samples  across different datasets. Loss terms (2) and (3) are weighted using hyperparameters. Authors perform experiments using common datasets including CIFAR-10, CIFAR-100,  STL-10, TinyImageNet and  SVHN. Experiments show that MDSSL outperforms (1) representations learnt by naively combining all datasets and (2) representations learnt on individual domains,  on average classification accuracy on training domains as well as held-out domains. Authors also perform  ablation studies to explore the effect of loss term hyperparameters on  downstream performance. The paper further extends the basic MDSSL method by adding an assumption that dataset labels are not available, and determine dataset labels using k-means clustering during the training process, and also explore a robust k-means clustering method. Experiments using 2 training domains show that the downstream classification performance of this unsupervised MDSSL method is comparable to original labeled MDSSL. ",
            "main_review": "Strengths:\n1. The paper is clearly written and well-organized: The motivation, method, experiments, and results are clearly explained. The loss formulation for MDSSL is sensible.  \n2. All experiments show substantial improvement in performance on downstream tasks over single-domain SSL and naive combination of domains. \n3. Ablation studies on hyperparameters and t-SNE plots are helpful in understanding the effect of  design choices on performance. \n\nWeaknesses (Not weaknesses per se, but some questions/suggestions):\n1. No external baselines: As the authors mention in the paper, the Feng et al. approach based on mutual information is a theoretically well-motivated approach for combining multiple domains for learning SSL representations. Comparing MDSSL with this baseline will strengthen the paper. \n2. Additional analysis along domain diversity: While the authors use fairly diverse datasets in terms of size and label types, they have only used natural, object-focused image datasets. Additional experiments with other data domains---medical images, satellite images etc.---will strengthen the paper. \n3. The paper is missing an experiment with full ImageNet pretraining (which is common in SSL papers), which could clarify if MDSSL has advantage over learning representations using a single, but large and diverse dataset. \n",
            "summary_of_the_review": "The paper proposes a simple and sensible method for  multi-domain self-supervised learning that obtains good performance on for both in-domain and out-of-domain problems. Comparison with baselines and experiments with full ImageNet datasets is missing. Overall, I think the paper is marginally above the acceptance threshold. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "\nThe paper presents a contrastive learning approach to self-supervised learning (SSL) that works for multiple domains. \n\nThey show that their approach generalizes better across domains than the baseline algorithm (SimCLR). Their method is basically an extension to SimCLR, which is nice because then SimCLR acts as the perfect baseline model.\n\nThey also provide an approach to using multiple domains when the domain labels are not available (using clustering).\n",
            "main_review": "\nStrengths:\n\nThe method is clear and clean, and the paper is well organized and laid out. The results also show some nice improvements when working with multiple datasets. Overall, it is a nicely written paper with a clear contribution. \n\nWeaknesses:\n\nThere are some shortcomings in the paper, and some spots where the language should be revised.\n\nFirst, there is a confound of dataset size that the authors should address. The authors focus on very small datasets (SVHN, CIFAR10, and similar), then show that SimCLR does poorly to generalize when you mix them all together. What about if working with very large diverse image datasets, like the full size ImageNet? This should at least be mentioned, since these SSL techniques are typically intended for ImageNet and larger training.\n\nSecond, there is not a good theoretical justification for expression (3). The heart of the method is the contrastive learning objective of the expressions (2-4).  (2) and (3) give you the standard SimCLR objective, which puts same-images close together in the latent space, and different-images farther apart in the latent space. \n\nBut there is a small tweak done here. The authors essentially take expression (2), and break it into 2 cases, the case of 2 different images within the database (they now make the representations CLOSER instead of farther like simCLR), and the case of 2 different databases (expression 4), where they make the representations farther apart (that makes sense). I do not have a theoretical appreciation for the tweak of expression (3), to make different images within a database have similar representations, and why that is what is making the representations generalize better. Is it doing some kind of regularization? Can the authors provide some more justification for this change, and perhaps give a bit more of the SimCLR context as I have described here?\n\n\nminor:\n\n\n- related work, 2nd paragraph, first sentence does a bad job of explaining the goal of SSL. Rephrase to say something like “SSL learns representations that are blah blah. It achieves this by … (then the thing you said). Right now, it doesn’t do SSL justice.\n",
            "summary_of_the_review": "\nThe paper is clean and shows some improvements, but there is not a clear theoretical argument. Furthermore, the paper is limited by using tiny datasets which limit how well we would expect these results to generalize in practice. \n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper extends self-supervised contrastive learning from one single domain to multiple domains and achieve better generation for multi-domain performance. \n\nIntuitively, the paper finds SimCLR, an existing self-supervised contrastive learning algorithm performs pool when takes the union of a multi-domain data (e.g., union of CIFAR10, STL-10, SVHN etc) , and is also weak when training on one specific domain and evaluates on the unobserved domain. To bridge the gap, the paper brings in an additional loss into SimCLR to mitigate the gap across different domains - maximizing the discrepancy between data from different domains. \n\nThis change achieves great improvement when training and evaluating via a unified model and better generation – train on one domain data and evaluate on the other domains.\n",
            "main_review": "Ups \n\n1.\tSimple solution. The learning objective includes 3 terms, the first 2 terms (minimize the discrepancy between data with different views and maximizing the data pair from the same domain) are derived from SimCLR and the 3rd term is designed to maximizing the discrepancy between pair of data from different domains. \n2.\tGood results. 25% increase in top-1 accuracy when comparing to SimCLR trained on the union of multi-domain data. \n3.\tGreat presentation and through experimental study. The table presented in the paper are well organized and informative to present every details. Clear and concise. \n\nDowns:\n1.\tIt is not very clear for the motivation in Eq (3). Since \\lambda_1 is always negative, does it mean the approach is trying to maximize the discrepancy of a pair of data from the same domain and maximize those between a pair of data from different domain even further? The choice of \\lambda_1 and \\lambda_2 seems very sensitive, could the author provide the corresponding set-up for each experiment and list them in each table? \n2.\tIt is unclear how one domain data is benefits from others. SimCLR performs pool on unobserved domains. This seems that multi-domain data are crossed in the latent space. MDSSL is superior because it introduces a large margin between each domain data. It hints that performance of a particular domain is upper bounded by SimCLR on the single domain. Is it as expected? How will other domains data help?  \n3.\tWithin domain clusters seems important and may need further research. Since MDSSL performs better than SimCLR on the union of multi-domain data, does MDSSL perform superior on single domain with each cluster as a new domain? \n",
            "summary_of_the_review": "Pros: Simple approach and good results for building a unified model for multi-domain data.\n\nCons: The formulation and motivation may need further clarification. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}