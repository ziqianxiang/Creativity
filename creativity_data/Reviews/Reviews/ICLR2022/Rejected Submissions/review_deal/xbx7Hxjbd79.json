{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The main contribution of this paper is that it points out incorrect claims in the literature of multi-agent RL and provides new insight on the failure modes of current methods. Specifically, this paper investigates the inconsistency problem in LOLA (meaning it assumes the other agent as a naive learner, thus not converging to SFPs in some games). It then shows problems with two fixes in the literature: 1) HOLA addresses the inconsistency problem only when it converges; otherwise, HOLA does not resolve the issue. 2) GCD does not resolve the issue although it claims to do so. This paper then proposes a method COLA that fixes the inconsistency issue, which outperforms HOLA when it diverges. Reviewers generally agree that the insight from this work is interesting and important for the field. However, there were some concern on both the theory and the experiments. While the updated version addresses some of the concerns, it also made significant changes to both the theoretical and the empirical sections, and would benefit from another round of close review. Thus, I think the current version of this work is borderline."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper investigates the inconsistency problem in LOLA: each LOLA agent assumes the other agent as a naive learner, resulting in LOLA agents not converging to SFPs in some games. This paper aims to address this problem by the infinite-order LOLA, which can have a consistent view of each other and empirically observes that HOLA may not resolve LOLA's convergence issues. Instead of HOLA, this paper proposes COLA that employs neural networks to explicitly minimize the consistency loss. COLA empirically shows that COLA finds the consistent solution when HOLA converges and finds more stable solutions when HOLA diverges. ",
            "main_review": "**Strengths:** \n1. This paper studies closely related literature (i.e., LOLA, HOLA, CGD) and make interesting empirical observations to the community.\n2. COLA only requires up to second-order derivatives compared to iLOLA, which requires many higher-order derivatives.\n\n**Weaknesses/Concerns:**\n1. My main concern is COLA's benefit against SOS (Letcher et al., 2019). SOS not only has a theoretical convergence guarantee to SFPs while retaining the LOLA's opponent-shaping to achieve higher performance, if needed. However, COLA does not have a convergence guarantee and, COLA may perform worse than SOS when it does not converge to SFPs (e.g., COLA:0.1 in the Tandem game). Hence, it is unclear when COLA should be used instead of SOS. \n2. Could you clarify further on the consistency (Definition 1) regarding how it avoids the infinite regress problem? Specifically, Equation 5 is dependent on Equation 6 as Equation 5 includes $h_2$. Similarly, Equation 6 is dependent on Equation 5 as Equation 6 includes $h_1$. As a result, the infinite regress problem can arise when we replace $h_2$ in Equation 5 with Equation 6: to compute $h_1$ on the left-hand side of Equation 5, it requires $h_2$ in Equation 6, which then requires computation of $h_1$ in Equation 5 (and this recursion continues). \n3. While it is an interesting idea to learn the update functions $h_1$ and $h_2$ via neural networks (parameterized by $\\phi_1$ and $\\phi_2$), I am concerned about the scalability of this approach. When the dimension of $\\theta_1$ and $\\theta_2$ are small, then learning the update functions that output the dimension of $\\theta_1$ and $\\theta_2$ is possible. However, when $\\theta_1$ and $\\theta_2$ are policies represented by neural networks, then the dimension of $\\theta_1$ and $\\theta_2$ are large, which results in the difficulty of learning $h_1$ and $h_2$.\n4. In Figure 1, CGD is only compared in the Tandem domain. Why is CGD not compared in other domains, including matching pennies (competitive game)?\n5. This is minor, but it is difficult to understand the experimental results because Tables 1-2 and Figure 1 are not positioned near Section 6.",
            "summary_of_the_review": "I initially vote for a score of 3. While this paper finds interesting empirical observations to related works, I am unsure how it improves over the state-of-the-art approach in the literature, such as SOS. After reading the authors' responses to my questions, I am open to raising my score.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors tackle the consistency problem of the original LOLA formulation. The paper investigates HOLA convergence, demonstrates that CGD does not correspond to high-order LOLA in general, and proposes COLA to directly address the consistency problem. The proposed method COLA seems more robust to different look-ahead values where HOLA diverges. The authors also find that COLA is still sometime susceptible to the ‘arrogant’ LOLA behavior, opening questions for future work. ",
            "main_review": "### Strengths\n- Paper is well written and provides a well motivated investigation into LOLA’s failure to preserve SFPs and corresponding ‘arrogant’ behavior.\n- Explanation of cases where CGD is not equivalent to iLOLA in general-sum games seems important and significant.\n- The motivation behind the proposed COLA method is well explained and justified, and the empirical results are thorough and support the authors’ claims. \n\n### Weaknesses\n- More thorough proof for CGD argument would strengthen the paper, as well as including it as a baseline in more of the empirical evaluations. ",
            "summary_of_the_review": "This work attempts to overcome and investigate weaknesses of LOLA to tackle the consistency problem. Even with explicit consistency loss the authors still find that we still find that the arrogant behavior remains, so the insights from this investigation seem relevant for future work and open questions in this area.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper deals with the problem of learning in differentiable games. Mainly the paper tackles the problem of learning in games while taking into account the learning of the opponent as well. The main contribution of the paper is to point out a flaw in the existing claims regarding correspondence between competitive gradient descent and iLOLA. The paper further gives a definition of consistent update rules for differentiable games and based on this definition show that iLOLA is update rule is consistent. The paper proposes a new algorithm COLA and shows that it find more consistent solutions empirically.\n",
            "main_review": "Overall, I like the paper. However the main issue for me was that I could not clearly see the relation between CGD and LOLA. This seems to be an important correction to existing claims. However, the paper says that this is not a rigorous proof of the correction. The problem is that if an existing claims is incorrect than it is useful to correct it as soon as possible. However, the proof of correction should be quite clear. I did not find that to be the case. Ideally, it would be nice to first say that the existing claim says that series expansion will look like this and while doing so they forgot about this particular term that seems to appear in LOLA’s loss and thus the correction to the existing claim. \nOverall, I think even just this correction could be a sufficient contribution for publication. \n\nThe paper claims that COLA follows a consistent update rule. However, empirically COLA does not converge to a a Tit-for-Tat strategy as desired (or as LOLA does). Then what is the motivation behind using COLA over LOLA?\n\nI am not sure of what is the original claim form the CGD paper and if it is correctly interpreted in this paper. It seems that the original claims from the CGD paper is series expansion of CGD recovers HOLA (high order LOLA). The paper says that this implies CGD is equal to iLOLA. I am not sure how this is true. \n\nWhile I have other minor points, but I think the claim regarding the original claim from CGD paper and its correction should be first made clear.",
            "summary_of_the_review": "I think my decision mainly depends on whether the claim that the paper makes a correction to the existing literature is true or not. And if the paper can it more clear. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper is on learning in a differential game setting by accounting for the ability of the opponent to learn. It displays several issues in previously existing methods, proposes a new methods, and demonstrates some of the features that appear to be superior to the existing methods. ",
            "main_review": "The paper focuses on an interesting challenge in learning in the presence of opponents. \n\nOn the other hand, the contributions the paper makes do not meet the claims made throughout the paper. For example, take section 4.1: \"This is not a rigorous proof, but it should be intuitively clear...\" First of all, \"should\" has no meaning? What if it is not? Second, this is one of the main claims that the paper is built on. If you are not going to give a rigorous proof for this, what will you give a proof for? Too much is left to future work. \n\nThe paper is also filled with similar vague language. In addition to the wishy-washy language, central concepts like \"consistency\" and \"stability\" are used throughout the paper and for the most part without a clear definition (at least for a long time). And, even comparative form, e.g., \"more stable\" are used even though nothing had been made quantitative. \n\nWhile this shortcoming may be inherited from the literature, the assumptions (e.g., knowledge of the opponent's payoff functions, parameters, and gradients) made in the paper are just way too strict. Coupled with the lack of rigorous results, the insights established in the paper are at best limited.  \n\nThere is a proposition that gives the means to check whether a pair of update functions are consistent. On the other hand, it is not clear how one actually checks the condition for consistency given in the proposition.\n\nSome of the questions posed at the beginning of the results section are odd. It is not clear whether an empirical analysis can even ever answer such questions. As stated, only rigorous proofs would answer the questions (and the paper lacks those). Similarly, the discussion of the observations from the empirical results overgeneralizes. \n\n",
            "summary_of_the_review": "The paper is on an interesting issue yet it is at best a starting point and far from prime time. \n\n----------------\n\nAfter the author response:\n\nThanks to the authors for the response. It unfortunately does not change my assessment. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}