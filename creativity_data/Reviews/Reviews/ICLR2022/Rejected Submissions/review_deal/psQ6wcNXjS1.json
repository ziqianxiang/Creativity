{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper proposed a strategy to train EBMs according to the length of MCMC trajectories required. The paper covers three settings with the different length of MCMC: image synthesis, adversarial defense, and density estimation. The reviewers generally find that there are interesting ideas and promising results in the paper, but the paper is not ready to publish at its current stage. The argument regarding density estimation and FID evaluation is not convincing. The proposed method is also more complicated than the baseline methods (CoopNets and PCD), and we would need a stronger argument for the added complexity."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper describes techniques to train EBMs according to the length of MCMC trajectories required. The paper explores three applications of EBMs: image synthesis, adversarial defense, and density estimation. Each of these applications uses a different regime of MCMC sampling length. An approach is described for modifying the initialization of MCMC both during training and at test-time to improve the performance in each of these applications.\n\nFor image synthesis, the paper proposes using a combination of persistent chains and cooperative learning. Persistent chains with rejuvenation can cause instability since negative samples can vary between freshly rejuvenated samples and longer run samples. However, no rejuvenation often leads to lack of sample diversity. Persistent banks don’t scale well to large datasets since they cannot capture all the variability of the larger dataset. Instead, chains can be rejuvenated from a fast generator model, which is trained jointly with the EBM, known as cooperative learning. The authors identify and fix a key issue with cooperative learning. The issue is that generators early in training are unable to generate a diverse set of samples that the EBM can refine. One fix is to use batch normalization in the generator. Instead, the authors propose using a persistent bank over the joint distribution of latent noise and generated images (where the latent noise is input to the generator), which the sampling process is rejuvenated from with the usual process.",
            "main_review": "Image synthesis section comments:\n- It should be more clearly explained why batch-normalization in the generator isn’t enough to fix the issue.\n- Section 2.2 is confusing. Isn’t the persistent bank just over the distribution (x, z) factorized as p(x|z)p(z), where z is the latent vector and x is the generated image?\n\nAdversarial defense\n- “Annealing” in the final paragraph of 3.1 refers to “annealing the learning rate”, right?\n- Section 3.2 it’s unclear how the hyperparameters are specified. As I understand it, two of K, K_def, and p_rejuv must be specified. Which of the two are specified, and to what values?\n- Are the experiments justifying the reasoning given in the last paragraph of 3.1? How similar are the trajectories of length K late in training to actual trajectories of length K_def, when the learning rate is annealed?\n- In Figure 6, why does robustness decrease for large K? Shouldn’t larger K used during training lead to better performance when using K_def at test-time?\n- How do the results compare when using data samples instead of a pre-trained generator?\n\nDensity Estimation\n- First paragraph, Section 4.1\n   - “However, persistent learning without rejuvenation has shortcomings mentioned in Section 3” -> Section 2?\n- “Persistent samples that are newly rejuvenated (up to about 50K Langevin steps since rejuvenation, and possibly many more) cannot be approximate steady-state samples for any current known rejuvenation sources, including data, generators, and noise.”\n- I think this sentence needs more elaboration / definition of terms. My understanding is as follows: Samples in a bank that have undergone less than 50k langevin updates cannot be steady-state samples\n- What is 50k defined relative to? Is it supposed to be half of 100k, which is the number of steps being used to estimate the density?\n- What is the definition of “lifetime” Langevin updates? Does this refer to the number of Langevin updates applied to a sample between different training iterations (e.g. by being sampled from the persistent bank and its updated version back into the persistent bank)\n- “Samples in the newly rejuvenated bank that have been updated sufficiently many times will eventually replace samples from the bank used to update the EBM, at which point newly rejuvenated states will be added to the first bank.”\n  - “the first bank” refers to the bank for newly rejuvenated samples, correct?\n- How do the results compare when using data samples instead of a pre-trained generator?\n- Are there experiments measuring the quality of the EBM density?\n  - My understanding is that these experiments show that EBMs can be trained so that long-run MCMC samples (which are closer to samples from the true EBM density) are high-quality. Are there experiments measuring how good the density is directly? For example, experiments on out-of-distribution detection? A small tractable model on MNIST where the normalizing constant can be estimated, and compare the log-likelihood to exact density models, as well as exact samples to long-run MCMC samples?\n- The prior EBM used in eqn. 2 seems like a little bit of a hack. To me it sounds like it could just be “slowing-down” how fast MCMC converges before oversaturation. Are there any plots showing that MCMC achieves a wide-region of stability where the sample quality and diversity stays relatively constant?\n\nTypos:\n- Section 1 (Introduction)\n  - “an misaligned” (3rd paragraph)\n- Section 2.2 (Hybrid Persistent Cooperative Initialization)\n  - “uses paired latent and image states that a drawn from” (Figure 2 caption)\n- Section 4 (Longrun Sampling for Density Estimation)\n  - “these outcomes not equivalent” (2nd paragraph)\n  - “the lack scalable methods” (2nd paragraph)\n  - “by introducing an MCMC initialization can incorporate” (2nd paragraph)\n- Section 4.1 (Incorporating Rejuvenation in Density Estimation)\n  - “initializatin” (Figure 4 caption)\n  - “remain the the” (Figure 4 caption)\n  - “burnin bank” (Figure 4 caption) \n  - “until they have approach” (Figure 4 caption)\n  - text under eq. (2) does not explain U_0 term",
            "summary_of_the_review": "Overall the paper is well-structured and clear, and presents unique and interesting ideas for training unconditional EBMs for different applications. There are some places where clarity could be improved, and some additional experiments which I think might improve some of the points in the paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper discusses learning strategies for energy-based models, short sampling for image generation, midrun sampling for adversarial defense, and longrun sampling for density estimation. The paper claims these methods achieve significant performance gain across the three applications and achieved state-of-the-art performances.",
            "main_review": "**Strengths**\nThe paper investigates training heuristics for energy-based models.\n\n**Weaknesses**\n\nI am not convinced by the argument that the performances are \"state-of-the-art\". \n- In Table 1, the proposed EBM method clearly does not outperform GANs and recently proposed diffusion / score-based generative models. \n- In Table 2, the number of *ours* has a typo of 0.0.566 in CIFAR10 and has worse natural accuracy than the EBM method in Hill et al., and ImageNet results are clearly not outperforming baselines (although the state-of-the-art claim avoids this). \n- There are no density estimates on the test set, only FID, since the method does not discuss how to estimate the partition function.\n- We have yet to discuss the amount of compute and time needed to perform training and inference with EBMs, which are quite slow as well.\n\nThe paper does not have many technical novelties. Most of the discussion is about the usage (or not) of persistent initialization and pretrained generator for \"rejuvenation\". The \"rejuvenation model\" is so important in all three cases, that a reasonable alternative is to use a good \"rejuvenation model\" and avoid EBM entirely. The heuristics themselves might be helpful in EBM learning, but it is questionable why we would adopt an EBM in the first place if it does not perform well on image generation/density estimation compared to other models (GANs, flow models, diffusion models). \n- For example, a pretrained SNGAN is used to rejuvenate EBMs (section 4), yet the model itself outperforms EBMs in terms of FID (see Table 1).\n\nIf the method claims \"density estimation\", then we should expect to see results other than FID (since that is image generation), even if partition function is not possible to compute, it can still help to see if density estimation have other uses, such as out-of-distribution detection.\n\n## Post rebuttal response\nI appreciate the authors taking the time to discuss and address my concerns. Unfortunately, I will keep my scores as is.\n\n- Similar to reviewer pepN, I am not entirely convinced about using FID in the \"density modeling\" section. Sure, density modeling does not require partition functions, and both FID and likelihood are flawed as measurements of image quality, but the argument used in this paper can also be used in GANs (it is also modeling some kind of density, and you can evaluate FID with it)? EBMs are more expressive than GANs in the sense that they also give un-normalized densities, but the paper never used these densities for any meaningful tasks (like out-of-distribution detection). The rebuttal also mentions that \"(ours) represent a significant departure from mainstream approaches for learning and evaluating density models\"; I don't see how evaluating FID is a significant departure, most EBM-based work after 2019 already report FIDs? \n- Existing work has shown that diffusion models can beat GANs on ImageNet (even with higher resolutions): https://github.com/openai/guided-diffusion; this includes unconditional and conditional models.\n- The \"technically novel\" bit in this paper seems to be using pretrained generators for rejuvenation, and if there are models that already beats EBM in image generation, why would we train and use another EBM instead? The rebuttal mentions that \"Alternatives such as variational approximation yield much worse distributional approximations than MCMC\", which might be true in principle, but can be quite far from what happens in practice (since MCMC can have slow mixing speed). Again, diffusion models are inspired by variational inference and seem to have quite good FIDs.\n\nAll in all, I find that the paper and rebuttal make some claims in favor of EBMs (and the paper itself) that I cannot fully agree with.\n",
            "summary_of_the_review": "The paper spans various different problems, but makes relatively little contribution to each of them. The claims over empirical performances are inflated. The EBM-based methods do not have an advantage over score-based / diffusion generative models in terms of generation and likelihood evaluation (which also avoids estimating partition functions).",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper discusses 3 applications for EBMs: image generation, adversarial robustness, and density modeling. The authors discuss how the standard methods for training EBMs do not adequately address the latter two of these applications. For this reason, they propose a new method which combines ideas from 2 popular EBM training methods; CoopNets, and PCD, to alleviate some issues with both methods. The authors present results on the 3 tasks mentioned and their method appears favorable compared to other EBM variants.",
            "main_review": "Strengths:\n\nThis paper addresses a large issue in the EBM space. Current methods for training these models are difficult to tune, unstable, and slow compared to other generative modeling approaches. The proposed fix combining ideas from CoopNets and PCD may provide a best-of-both-worlds approach to training EBMs while adding no overhead on top of either of these training methods. \n\nFurther, this paper correctly brings attention to many real issues in the EBM space such as the sample quality / density model quality trade-off. As well, the paper addresses adversarial robustness which appears to be a powerful and promising of EBMs. While I am not an expert in adversarial robustness (and cannot make super-strong claims about the correctness of these experiments), it appears to me that the robustness results give a solid improvement over [6] and many other techniques purely meant for this task.\n\n\nWeaknesses:\n\nWhile the authors provide some high-level intuition for their proposed modifications to CoopNets/PCD, they do not provide any theoretical justification for their proposed approach. Have you considered other ways to improve the diversity of the CoopNet samples? Could this be due to the approximations that are made with the standard CoopNet learning algorithm (which the authors mention)? You could regularize entropy as in [5, 4]. I feel the paper would be made much stronger if more care was placed on the details and more theoretical justification was given.\n\nThe experimental details in the paper are quite scant. The authors do not mention anything about the optimizers used, the learning rates, the batch sizes, or training training time. As such, the results in this paper are not reproducible. I am aware the authors have included code, but these details should be accessible from the paper (at least in the appendix). Further, from an investigation of the code, there appear to be a number of additional experimental hyper-parameters (such as gradient clipping and energy tempering) which are not once mentioned in the paper. These modifications to the training objective can be very responsible for the success/failure of EBMs when training in this way and there has been a good deal of work discussing it.\n\nThis work is attempting to improve stability and success of EBM training. Many of these tricks (or hacks depending on your point of view) are there to accommodate for many of the issues that this paper proposes to address (such as high variance of negative sample gradients from training on newly resampled examples) so it should be made clear which, if any, of these tricks are no longer needed. \n\nI have some issues with the evaluation used in the long-run sampling for density estimation section. The authors claim early in the paper that sample quality can be a misleading indicator of model quality (where quality is evaluated by maximum likelihood), which I completely agree with. I was then disappointed to find the only quantitative result in this action was FID which is a qualitative measure of sample quality. If the authors want to argue that their training procedure learns a better density model then there are many alternative evaluations which could be used -- and have been used in recent EBM work. You could use AIS/RAISE to estimate upper/lower-bounds on likelihood as in [1, 2]. Or, you could use your training procedure to train a tractable likelihood model and then evaluate using the model’s known likelihood as in [3, 4].\n\n\nMinor: Typo in Table 2. \n\n[1] Du, Yilun, and Igor Mordatch. \"Implicit generation and generalization in energy-based models.\" arXiv preprint arXiv:1903.08689 (2019).\n[2] Gao, Ruiqi, et al. \"Learning energy-based models by diffusion recovery likelihood.\" arXiv preprint arXiv:2012.08125 (2020).\n[3] Song, Yang, et al. \"Sliced score matching: A scalable approach to density and score estimation.\" Uncertainty in Artificial Intelligence. PMLR, 2020.\n[4] Grathwohl, Will, et al. \"No MCMC for me: Amortized sampling for fast and stable training of energy-based models.\" arXiv preprint arXiv:2010.04230 (2020).\n[5] Dieng, Adji B., et al. \"Prescribed generative adversarial networks.\" arXiv preprint arXiv:1910.04302 (2019).\n[6] Hill, Mitch, Jonathan Mitchell, and Song-Chun Zhu. \"Stochastic security: Adversarial defense using long-run dynamics of energy-based models.\" arXiv preprint arXiv:2005.13525 (2020).\n\n----------Post author response------------\n\nI appreciate the authors responding to my feedback and thank them for the changes they have made to the paper. Unfortunately, I do not find their arguments convincing regarding density estimation and the use of FID to evaluate the method. As well, if the authors were able to demonstrate that their method simplifies EBM training while offering similar quality results, this would be compelling, but I do not feel this was done in the work. The proposed method is more complicated than CoopNets and PCD and provides additional hyper-parameters to tune. If the authors were able to make a compelling argument that their method allows us to learn a better density model, then I would support acceptance of this work, but I do not believe this was done. For this reason, I will keep my score the same. There are some interesting ideas presented in this work, but I do not feel the results presented demonstrate that they are a sufficient contribution to the field for acceptance. \n",
            "summary_of_the_review": "This paper presents a new method for training EBMs which combines features of two popular training approaches: CoopNets and PCD. While the proposed method makes sense, and appears to work, there are considerable issues with the method’s evaluation, experimental details, and theoretical justification. Thus, in its current form, I do not advocate for its acceptance. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work presents different MCMC initialization techniques for training EBM with differerent lengths, for the purposes of image generation, adversarial defense, and density estimation respectively. More specifically, for shortrun image generation, the author proposed a hybrid persistent cooperative initialization that mitigate the lack of diversity issue of EBM learning with generator initialization. For midrun adversarial defense, the author proposed a pretrained generator rejuvenation to scale up EBM defense. For longrun density estimation, the author proposed rejuvenation methods and regularization trick to correct oversaturation.",
            "main_review": "The paper is well written and easy to follow. The empirical performance looks good compared to the baseline models (although the fairness requires further investigation).\nThe weakness of the paper is that the contribution seems to be incremental, as most of the techniques used in this paper have been proposed somewhere else. Below are some of my concerns.\n\n1. For image generation, why not use a pretrained generator? And if the generator already provide high quality samples (e.g., SNGAN), what is the purpose of using EBM after it? Did the baseline EBMs use generator initialization? Also, I did not see a comparison to Xie et al. (2018).\n\n2. How does the pretained generator initialization compared with data samples? How important if annealing? Is annealing applied to other baseline methods? Lack Ablation studies here.\n\n3. Where is the density estimation result for longrun EBM? ",
            "summary_of_the_review": "Overall, the paper provide some interesting empirical findings for EBMs with different MCMC lengths. However, current experiment results and lack of novelty make it a bit under the bar of ICLR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}