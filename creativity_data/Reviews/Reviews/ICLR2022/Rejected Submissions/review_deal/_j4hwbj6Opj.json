{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper applies a metalearning strategy to point cloud registration, which refines 3D registration networks to improve performance on specific datasets/settings.  Reviews for this paper recognized its potential interest but uniformly highlighted that the work is lacking in polish---both from an expository perspective and in terms of experiments.  Questions included whether the experiments truly support the claim of generalization, and whether the work would be better considered as a method for scene flow.  Authors did not rebut these points, so I am recommending rejection."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper addresses point cloud registration from a meta-learning perspective to quickly adapt with limited training data. The main idea is using a meta-learner is to initialise a 3D registration learner. The meta-learner predicts a prior registration that can rapidly adapt to new registration problems. Experimental results on several datasets (ModelNet, FlyingThings3D, and KITTI) showed superior performance over FlowNet3D.\n",
            "main_review": "Presentation is in general deficient; often the text seems vague. I will give some examples next. I believe that concise explanations and providing examples could help in communicating ideas in this paper. \n\nI feel the abstract could be improved to be more precise. For example, when saying \"we define each task\", results unclear what are those tasks or why is it not a single task. \n\nThe following affirmation seems vague to me \"In comparison to iterative registration methods, learning-based methods have advantages in dealing with a large number of datasets since learning-based methods can transfer the registration pattern from one dataset to another one.\" I feel we can also transfer patterns (parameters?) from different datasets when using traditional methods. \n\nI am not sure about the meaning of optimal in the following sentence: \"The meta-learner is responsible for providing the optimal initialization of a 3D registration learner\". My intuition tells me that an optimal initialisation does not require any adjustment; hence no need for a 3D registration learner. \n\nI am not sure what the text is trying to comunicate in the following sentence: \"... our meta-learning-based approach gains competitive advantages over existing generalization methods that our method can uniquely parameterize the 3D registration function for each pair of shapes to provide 3D point cloud registration.\"\n\n\n\nOn experimentation over the KITTI dataset:\n----------------------------------------------------------\nI think the text should explain the point cloud pair generation (source, target) from the stereo vision information. How many pairs were considered?\n\nI recommend report also quantitative results for the KITTI dataset.\n\n\nOther comments\n-----------------------\nI suggest rewriting section 2.2 (META-LEARNING METHODS) to contrast the proposed approach against existent ones. My impression of the review here is a list of related approaches but without comparing them with the propositions here. Beyond the particular problem here (3D registration), what do other methods have in common with the proposed one? What is new?\n\nWhat is the notation \"~\" in Eq. (1)?\n\nWhy theta_m is not in Eq. (2)?\n\nWhat is the difference between theta_m and sigma?\n\nWhat is the self-supervised variant in Table 4?\n",
            "summary_of_the_review": "I found the presentation deficient and my impression is that despite the results seeming promising, this paper requires substantial improvements to be ready for another review process. \n\nThis paper seems correct in methodology however I did not check everything, in part of difficulties related to the presentation. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "A scene flow estimation network is proposed with a meta-learning hypernetwork type design: the top level estimates the parameters of the bottom level network, which combines with meta-learned parameters to enable better generalization properties.",
            "main_review": "The design of this proposed network is fairly interesting, but I am not convinced that all claims are properly substantiated. Additionally, the paper itself isn't very polished and leaves me with several concerns regarding its effectiveness for the proposed applications.\n\nFirst, 3d point cloud registration typically refers to finding a single rigid transformation in SE(3) that best aligns two point sets. The title mentions point cloud registration, but the method itself and the methods it is compared against are scene flow methods. Scene flow differs from 3d point cloud registration in that each point is assigned a different transformation in SE(3), typically in a 1-to-1 manner as a 3D analogue of optical flow. Given the non-standard use of technical terms, I question how this method is to be used. If the main comparative work is FlowNet3D and FlowNet3D++, it would seem that this paper should be more aligned with other scene flow works than registration (e.g. you also compare against ICP, which *is* a 3d point cloud registration algorithm). \n\nThe qualitative results are not all that convincing to me, and I don't know whether or not the result was cherry-picked or demonstrates the typical performance difference. Much of the details I would need to reimplement this method (including explanations of metric and experimental procedure) just refer to FlowNet3D. I think to make the paper more self-contained, it would be nice to include a little more detail instead of requiring reading FlowNet3D to understand your evaluation.\n\nTraining on FlyThings3D and testing on KITTI, showing good results, is encouraging to me that your method is actually achieving some superior generalizability performance with its meta-learning design. However, I am not quite sure if your ablations prove your claims since one could attribute the superior performance to just having a higher capacity network when the meta-learner is enabled? Also, why do you elementwise add the estimated meta parameters to the learned parameters? It would nice to see an ablation where you either fully predict the parameters (a traditional hypernetwork approach), or concatenate instead of adding, or use the predicted parameters just for layer normalization (which is more commonly seen in approaches like conditional batchnorm, or FiLM, or even in things like AdaIn or StyleGAN). \n\nThe text itself needs some work-- the citations seem to have a latex problem and break up the text, disrupting the flow and making everything hard to parse. Some of the math exposition is a little imprecise. For example, in Equation 1, shouldn't it be argmax if \\mathcal{L} is a similarity measure? Also, S_i and G_i are *not* subsets of R^3. A subset of R^3 is a single 3D point. S_i and G_i, since they are 3d point clouds, are a set of points in R^3. Typically, I would expect to see something like S_i \\in R^{N \\times 3}. \n\nOther small things: uniformly sampling rotation angles on each three rotation axes independently results in a biased sampling of SO(3). Axis-angle representation is better suited for unbiases SO(3) sampling of rotation angles under 45 degrees. In Table-1, you should have understandable shorthand instead of A,B,C,D-- I find this really hard to cross-reference. ",
            "summary_of_the_review": "Overall, I think this paper just has too many problems for me to recommend acceptance. I'm not fully convinced by the approach to meta-learn in function space-- I did not see a convincing argument explain how exactly this is necessary (e.g. a toy experiment to demonstrate its necessity would be nice)-- and the ablation results seem to be explainable by just having a higher capacity and therefore higher performing network. Lastly, I am a little confused whether this is a scene flow or a point cloud registration paper-- it would appear to be the former though the title and intro seem to indicate the former.",
            "correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a learning method to estimate the transformation matrix directly using neural networks. This paper tried to leverage the meta-learning strategy to improve the generalization ability. ",
            "main_review": "The objective of the work: This paper proposes a learning method to improve the generalization ability for the point cloud registration tasks.\n\nStrong points: This overall idea is a hot topic in the point cloud area. The concept of this meta-learning is interesting.\n\nWeak points: (1). The paper claimed to improve the generalization ability, while the experiments are extremely lacked to support this claim. All the other recent point cloud registration methods (e.g, FMR[1], DeepGMR[2], RGM[3], PntLK++[4]) achieve very well in this generalization setting. (2) The paper claimed to solve the point cloud registration problem. However, the experiments have not been compared with the recent state-of-the-art point cloud registration methods, such as FMR, DeepGMR, RGM, PntLK++. The current experimental results in Table 2 seems worse than the state-of-the-art registration methods. \n\n[1]. Huang, Xiaoshui, Guofeng Mei, and Jian Zhang. \"Feature-metric registration: A fast semi-supervised approach for robust point cloud registration without correspondences.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n[2]. Yuan, Wentao, et al. \"Deepgmr: Learning latent gaussian mixture models for registration.\" European Conference on Computer Vision. Springer, Cham, 2020.\n[3]. Fu, Kexue, et al. \"Robust Point Cloud Registration Framework Based on Deep Graph Matching.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n[4]. Li, Xueqian, Jhony Kaesemodel Pontes, and Simon Lucey. \"PointNetLK Revisited.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n",
            "summary_of_the_review": "The overall idea is interesting. However, the experiments are much lacking behind to support the claims, and the current experiments have not compared with the state-of-the-art registration methods. I think this work is ongoing work and need to do more investigation.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents a new architecture for point cloud registration. Different from existing methods, the proposed architecture consists of two stages. The first one is called meta learner, which is used to predict a task distribution and sample the key parameters for the second stage - 3D registration learner.\nBy separating the network into two different parts, the learned model may be better at generalization.\n \nExperiments were conducted on ModelNet40, FlyingThings3D, and KITTI datasets. The results show the proposed method outperforms some existing methods, including FlowNet3D, FlowNet3D++, and HPLFlowNet.",
            "main_review": "Strengths:\nThe idea looks new to me. The results are promising but are still not solid to support the claim (well addressing the generalization problem).\n \nWeakness:\nThough this work is about 3D point cloud registration, many important works about 3D point cloud registration are missing. For example, feature-based methods like FCGF, D3Feat, and end-to-end methods such as Global Point Registration, PREDATOR, PR-Net, RPM-netï¼ŒDeep closet point, etc.\n \nThe proposed method does not show its superior performance on generalization in the experiments. The only experiment for evaluation of generalization capability is the KITTI test, where the model was trained on flyingthings3d and tested on KITTI.  I think more tests should be conducted on more datasets and compared with some state-of-the-art methods such as PREDATOR and RPM-Net.",
            "summary_of_the_review": "1. The proposed idea is new.\n2. Many related works are missing.\n3. Experiments are not solid to support the idea.",
            "correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}