{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "Though some concepts discussed in the submission are interesting, there are many major concerns: there is a lack of literature review, comparison experiments with the state-of-the-art methods are missing, the technical novelty of the proposed method is very limited. \nIn the rebuttal, the authors agreed with reviewers' comments and did not provide responses to address reviewers' concerns.\n\nTherefore, based on its current form, this submission does not meet the standard of publication at ICLR."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents Multi-Distribution Learning, exploring the effectiveness of Data Augmentation to prepare for Distribution Shift.",
            "main_review": "Pros:\n\nThe expression of this paper is okay.\n\n\nCons:\n\nThe novelty and contribution of this work are marginal.",
            "summary_of_the_review": "The novelty and contribution of this work are marginal.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this work, the authors present a data augmentation method to address the data distribution shift problem in a multi-task learning framework. ",
            "main_review": "The paper is more like an undergraduate course project report instead of an academic paper. In this paper, they mainly described how they do, but many important comparisons and studies are totally missing. For example, there is no literature study, no evidence to show the limitation of the literature, and no comparison with state-of-the-art. No motivation is described. Using data augmentation and multi-task learning are widely used techniques in many papers, so they can not be considered a novelty. ",
            "summary_of_the_review": "Many important comparisons and studies are missing. No technical novelty. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors investigate distribution shift between the data seen during training and the data seen during testing by proposing a framework to analyze distribution shift as well as empirical analysis. In particular, they define a training regime for learning from many distributions within one model as well as a lookahead method to determine which distributions should be chosen for a 0-shot distribution shift benchmark.   ",
            "main_review": "**Overall thoughts:**\n\nPreparing for or adapting to distribution shift is a an interesting, yet in my opinion understudied, challenge for machine learning models. Real world applications would likely benefit the most from research in this domain, and a work which develops models robust to distribution shift, or able to adapt quickly to such a shift, is likely to be highly celebrated and well received by industry. This paper collapses distributional learning and data augmentations into one perspective and investigates how training models on many \"distributions of augmentations\" may lead to models which are robust to significant distribution shifts during inference. \n\n**Method**\n\nThe goal of this work is to improve a model's robustness to test-time distribution shift by training one model on many different dataset distributions (i.e. data augmentations). After training, this model should perform well on all dataset distribution on which it was trained. The authors judge this is a good indication of robustness to distribution shift and cite Martin Arjovsky to support their framing of the problem (i.e. the requirement to inject prior knowledge about the types of distribution shifts into the training dataset). Later, the authors analyze which distributions should be trained together in one model to increase model generalizability. \n\nIt is unsurprising to me that one model can learn multiple dataset augmentations (i.e. \"distribution shifts\") throughout training and perform well on each of them during test time. This also creates a disconnect from real-world applications of this method in that the distribution shift for a live model is typically unknown (both in terms of what the shift will be and when it will occur). Moreover, simply scaling a model's size may to enable it to learn a robust feature extractor which can handle many different distributions of data. \n\n**Weaknesses and Suggestions for improvement**\n\nOverall, it feels as if this paper was a bit rushed and incomplete. I do not recommend it for acceptance to ICLR, but encourage the authors to invest additional time into crafting the story and improving the empirical analysis for later resubmission. As it is presented, this work feels a bit all over the place, and while the ideas are interesting and promising, they are not developed into a strong or cohesive story. \n\n1. In my opinion, much of the value of distributional shift learning is invested in creating a model which can quickly adapt to changes in the test distribution or is robust to these changes. Table 4 begins to analyze this dimension, but significantly more analysis would be needed to support the authors' method in finding dataset augmentations which would train a model that is especially robust to distribution shift. \n2. Similar to point 1, the authors quote Martin Arjovsky to support their framing of the problem (i.e. the requirement to inject prior knowledge about the types of distribution shifts into the training dataset), but this requirement is often unavailable in many real world applications. It  severely limits the scope of this work to the scenarios where a future distribution shift can be anticipated in the present.\n3. I would recommend the authors consider refocusing the story of this paper to decide which dataset augmentations to apply to a model to make it robust to corrupted data and test-time distribution shifts. In other words, given ImageNet1k, which dataset augmentations would likely maximize the performance on Stylized ImageNet or ImageNet-Corrupted? \n\n**Strengths**\n\n1. I think the concept of choosing dataset augmentations from a predefined set to create a model which is robust to distributional shifts is very interesting and promising. Given the number of augmentations available to image data, and the pervasiveness of distributional shift for real-world applications, this work addresses an important challenge in computer vision. \n2. The introduction and related work contextualize the authors’ method with the most recent work in this domain. It is apparent the authors are familiar with the distributional shift landscape and knowledgeable in this domain. \n3. The proposal to develop a \"generalization score\" disparate from test-time metrics like test loss and test accuracy is also very relevant.\n\n**Nitpicks**\n\nTypos:\n 1. Achilles heel => Achilles' heel (should be plural)\n\nA lot of nouns are also capitalized that should not be capitalized. For instance\n1. for targeted Generalization => for targeted generalization\n2. Data Augmentation => data augmentation\n3. Deep Learning => deep learning\n4. Distributional Shift => distributional shift\n5. Average Distributional Accuracy => average distributional accuracy\n6. Distributional Generalization Metrics => distributional generalization metrics\n\nFinally, there are several latex/formatting issues:\n1. **?** utilized style randomization to understand intrinsic properties of Convolutional Neural Networks, finding a texture bias => missing reference in latex.\n2. Figures and tables have width which exceeds the margins.",
            "summary_of_the_review": "I think the authors investigate a very interesting/relevant challenge that could be applicable to a wide range of machine learning applications, but the work as it is presented now -- the story, writing, and empirical analysis -- needs significant revision to present a compelling case for the utility, correctness, and applicability of their method. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}