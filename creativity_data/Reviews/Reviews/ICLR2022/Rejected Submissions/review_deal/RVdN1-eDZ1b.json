{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper presents a new method for solving the problem of inverting image classifier models. The authors introduce three new augmentation-based techniques to do this. The techniques are validated using Vision Transformer and MLP models and compared against previous methods. The reviewers appreciate the problem that the paper aims to solve. However, the reviewers are not satisfied with the presentation and evaluation of the proposed approach. The main contribution of the paper is not presented clearly enough, according to the reviewers, and it remains unclear to them what aspect of model inversion the authors most want to improve on, and whether their proposed technique indeed achieves such an improvement. In their response, the authors do provide Inception scores that show that their inversion method improves the perceptual quality of generated images compared to previous approaches. The reviewers acknowledge the author response, but indicate that it does not fully resolve their concerns. I recommend that the authors update their paper to more clearly present their main contributions and conclusions, and to provide a more thorough comparison against previous methods, before submitting to another conference."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper attempts to solve the problem of image inversion by introducing three augmentation-based techniques. It specifically tries to solve the problem of class inversion, which generates an interpretable image from a neural network by sending the pre-initialized image to the network. Then optimization is wrt the input image instead of the weights of the network. It introduced new sets of augmentation-based techniques like centering, zooming, color shift augmentation, ensembling that have not been tried before, and finally, they combined them with VIT and MLP based vision models. They validated all the augmentations using Vision transformer and MLP based vision models and compared them against the exiting method Deep Inversion(Yin et al., 2020). The paper is well written but lack quantitative evaluation which is a very significant shortcoming. ",
            "main_review": "# Highlights: \nThe problem addressed in the paper is well written and well described in the Introduction and Background section.\n\n# Related work: \nThere should be a separate Related work section citing the work that has been done in this area previously with a thorough literature review. \n\n\n# Methods: \n1.\tThe paper mentioned several drawbacks in the Introduction section of the existing methods - the authors should put any of such examples like the generated images being highly sensitive to the weights assigned to the regularized terms, etc, and compare that with the images generated by PII to show how PII is working better.\n2.\tThe authors should have provided some theoretical justifications of their work -  why are the new sets of augmentation working better than its predecessor?\n\n# Experiments:\n\t\n1.\tOne of the main issues in this paper is the applicability of the solution of the problem is not discussed in the paper. For example, there are three major applications where Deep Inversion(Yin et al., 2020) can be used - (a) pruning, (b) knowledge transfer, and (c) continual (class incremental) learning. If the authors set Deep Inversion as the baseline, they should have formulated the experiments for these three applications and compared PII with all architectures like VIT and MLP and others against Deep Inversion. Also if there are any other applications of the solution, that should have been clearly mentioned in the paper. \n\n2.\tThe authors experimented only using the Imagenet dataset. They should have done against other datasets like CIFAR 10 - the way Deep Inversion was doing.\n\n3.\tTo prove such a simple method is working better than the previous models, the authors should have either used or introduced some metric that gives a quantitative comparison between all the inversion techniques. In this paper, the authors compared PII with different settings and against Deep Inversion qualitatively. For example, in Deep Inversion, the authors did a wide range of quantitative comparisons among various metrics like inception score, knowledge transfer results, continual learning results (table 1-7 Deep Inversion (Yin et al., 2020))\n\n# Minor:\n1.\tSection 2.3, 2nd paragraph where Vision transformers are discussed - in line #2, there is a mistake \\cite{Vaswani}\n2.\tSame for the last line in the same paragraph \\cite{CoaT and CaiT}\n",
            "summary_of_the_review": "* Since the baseline for this paper is Deep Inversion lack and there are many quantitative experiments in that paper, the lack of quantitative results in this paper is not justifiable.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a method to perform class inversion on image data, called Plug-In Inversion. This method consists of a sequence of augmentations on image data and is designed to be applicable to a variety of architectures. This method is evaluated on ImageNet trained models and is compared with other techniques used for the same goal.",
            "main_review": "This paper proposes a technique called Plug-In Inversion, which is to be used as-is, irrespective of the underlying model which is to be inverted. This method works by applying a particular sequence of augmentations to the image, and then performing inversion by minimizing the loss of this image with respect to a single class.\n\nStrengths:\n- The motivation behind the paper is clearly presented - the goal is to reduce the need for extensive hyperparameter optimization of an inversion system. This is an interesting motivation, given that extensive tuning of regularizers is often difficult to perform.\n- The paper is in general clear and easy to follow. The main ideas are presented in a concise manner and formulate a solid story for the paper.\n- The authors demonstrate the effects of each different augmentation used in their inversion system, both in the main paper and the appendix. This is particularly useful both for understanding how Plug-In Inversion works and how each part of the procedure affects the resulting image (namely, how the zoom + centering procedure operates, as well as the effect of the ColorShift augmentation).\n- The proposed method is evaluated on a great variety of models, and produces intelligible images for the classes presented (in the sense that they conform to the high-level notion related to the class).\n\nWeaknesses:\n- The proposed Plug-In inversion method is introduced very late in the paper (at the end of Section 3.4) even though it consists only of combining the augmentation and search space restriction techniques provided in the previous sections (3.1 - 3.3). It would have been much clearer for the reader if this fact was fully described earlier in Section 3 (for example, by moving Section 3.4 earlier in the paper), instead of delaying the presentation of the full method.\n- My greatest concern is the fact that I am not sure whether the claim of the authors that the method can be applied to multiple networks without tuning is fully supported by the experimental results. More specifically, in Figures 7 and 8 the method is applied in a variety of networks, resulting in images which, while intelligible, are of varying quality. As such, to fully support the argument of the lack of need of extensive hyperparameter tuning, one would also need to show that using the same regularizer (for example, TV, which can be applied to any model) with the same hyperparameter leads to more extensive degradation, when applied to different models. I believe that a small example to demonstrate this motivation would greatly improve the paper.\n- The above point is made even more unclear by the fact that one of the models considered by the authors does use a TV regularizer (which leads to drastic improvement in image quality).\n- The ColorShift augmentation proposed by the authors is, unless I am mistaken, a variant of color jittering (in the sense that the adjustment is made directly to the pixels of the image, rather than on hue, saturation, contrast etc.). Given that applying some form of adjustment to the color of the image is a form of data augmentation which has been used in prior work  (Krizhevsky et al., 2012, section 4.1), I am not sure if this data augmentation is as novel as the authors claim (although I do appreciate the qualitative analysis of its effects in the context of inversion).\n\nQuestions:\n-\tThe hyperparameters for ColorShift are fixed to $a=b=1$, and if I understand correctly this comes from a qualitative analysis of the results in a few simple experiments. Is this correct?\n\nMinor comments/typos:\n-\tAs a minor comment related to the above, I believe the authors should indicate in the captions of the figures which model the respective images come from.\n-\tThere is a space missing in the second-to-last line of page 6.\n-\tThe caption in Figure 10 in the appendix is incomplete.\n\nReferences:\nKrizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems, 25, 1097-1105.\n",
            "summary_of_the_review": "Overall, this work has an interesting motivation (alleviating the need for extensive tuning of regularizers for class inversion), but I am not certain if the benefits of Plug-In Inversion, as described by the authors, are fully supported by the experimental evidence provided. As such, given also the fact that the individual components of the method do not seem novel by themselves, I marginally lean towards rejecting this paper, pending extra discussion during the rebuttal process.\n\n**Update after rebuttal**: See response to the authors' comments below.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors introduce a novel method for the class inversion problem: given a trained classifier and a specific class/label, generate an example image of that class.  This method is called Plug-In Inversion (PII) and it works as follows: a gradient descent is performed to find the image x such that the output of the classifier is close to the target label under a suitable loss function.  In PII, each successive gradient update is computed using a data-augmented version of the current iterate of the image x.  The authors introduce new data augmentations and combinations thereof.  The benefits of this inversion method is that it works for any classification architecture (which is treated only as a black box), and the same hyper parameter values (e.g. amount of color shift) work across a range of significantly different classifier architectures.  The authors present the output of PII across 12 different networks (including Convolutional, Transformer, and MLP nets), and they demonstrate several examples where their method is more interpretable than DeepInversion, a state-of-the-art method for class inversion.  \n",
            "main_review": "Strengths of the paper:\n- The proposed method works for class inversion for any architecture, including Vision Transformers and MLPs.\n- The proposed method is robust across architectures with little-to-no hyperparameter tuning\n\nWeak points of the paper:\n- The specific method proposed is not clearly presented at a mathematical level (it is described only in words)\n- The only baseline comparison I saw was relative to one method (DeepInversion).  \n\nRequested response from authors that will affect my recommendation:\n\nThe authors should justify why they believe their baseline comparisons are sufficient (or comment on what additional baselines they would present in a camera ready). \n\nThe paper does not comment on methods for adversarial examples, such as adversarial patches, either as related work or as baselines.  In the rebuttal, please justify why these comparisons are not present, or comment about them.\n\nThe authors should clarify what exactly the PII algorithm is at a mathematical level (write out the GD iteration) so that I am clear I am not misunderstanding the model.\n\nAdditional feedback with the aim to improve the paper:\n\nIf my reading is correct, the method treats the classifier as a black box, which is why it works for any architecture.  If this is true, then the paper would be much improved by clearly stating it treats the classifier as a black box.  In its current form, it comes across as being restricted to neural networks, which I do not think is the case.\n\nTypos:\nThe minimization problem on page 2 should say argmin_x L(f(x), y).  It has an incorrect parenthesis.\n\nThere are several places where the document says \"cite XYZ\".  Replace these with the citations.\n\nFigure 2 caption: \"An image a different stages\" has a grammatical issue.\n",
            "summary_of_the_review": "Clearly state your recommendation with 1-2 reasons\n\nI rate this paper as a weak accept for the following reasons.\n\nThe reason to accept is: They provide a class inversion method that produces interpretable visualizations for recent architectures (Vision Transformers + MLPs) that existing methods do not work for.  This could accelerate the development of better classifiers by helping researchers interpret and fix their behavior.\n\nThe reason this isn't rated higher is: The baseline comparison was inadequate.  The authors should compare their visualization method on Transformers/MLPs to the best existing approach that exists before this work.  Perhaps that approach is a plain inversion method.  Perhaps there are methods that can be borrowed from the methods of targeted adversarial examples.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes Plug-In Inversion (PII), which can invert a trained image classifier so that it generates a class-conditional image.\nIn addition to CNNs that previous work has considered, PII can handle Vision Transformers and Vision MLPs as well.\nPII starts generating from the center of a random initialization with lower resolution. Then, the method gradually broadens the generating area (centering) and increases the resolution (zooming). During generation, colors are randomly shifted (ColorShift) and the averaged cross-entropy to $e$ color-shifted images are used.\n\n",
            "main_review": "# Strengths\n\n* The authors aim for a model-agnostic and hyperparameter-robust method. This is an important direction.\n* To verify the model-agnostic features, the authors tested the proposed method on various CNNs (MobileNet, ResNet, etc.), Vision Transformers (ViT, DeiT, etc.), and MLPs.\n\n# Weaknesses\n\n* According to Section 7, the purpose of this paper is to understand vision models. I agree with one of the goals of model inversion is so, but the paper lacks a discussion of how PII helps us to understand vision models, even though the authors conducted experiments on various image recognition models.\n* The analysis is limited to qualitative ones. I would include quantitative results to compare PII with other methods. For example, DeepInversion [Yin+20] reported classification accuracy and the Inception score (IS). Santurkar+19 also shows IS.\n* The authors claimed that DeepInversion needs statistics $\\hat{\\mu}_k, \\hat{\\sigma}^2_k$ ported from batch normalization (BN) and thus is not applicable to models sans BN, such as ViT. However, I think that $\\hat{\\mu}_k, \\hat{\\sigma}^2_k$ are statistics of training data and can be obtained even for models sans BN only by passing training data once and storing the activations.\n* PII is only verified on the ImageNet dataset. I recommend the authors to use CIFAR-10 as Yin+20.\n\n# Comments\n\n* References are not well organized and written in a consistent format. For example, Santurkar+19 is accepted at NeurIPS 2019, but it is not written so. \n* An image is denoted as $x$ in p. 4, but $\\mathbf{x}$ in P5. The notation should be consistent, otherwise, it is difficult to follow.\n* Why a total-variation loss is used to visualize Figure 4, while, if I understand correctly, PII does not use the loss term?\n* Without a quantitative measure, how the hyperparameters of PII can be tuned in Section 4?\n* Section 3.3 says $e=8$ results in images of acceptable quality, while in the main experiment, $e$ is set to 32. If it is intended, it would be justified.\n* What are \"random augmentations\" in p. 6 Section 4?",
            "summary_of_the_review": "The model aims for a model-agnostic and hyperparameter-robust method to investigate vision models by model inversion. I highly appreciate this goal. Meanwhile, the current manuscript has several weaknesses. Therefore, I recommend this paper be marginally below the threshold.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}