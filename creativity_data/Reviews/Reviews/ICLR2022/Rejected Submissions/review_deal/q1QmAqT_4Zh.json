{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper proposes to improve offline RL by a data augmentation technique that exploits the symmetry of the dynamics using Koopman operator. The idea is interesting but the draft at its current form has several weaknesses as pointed out by the reviewers. The scores are borderlines at this point. I read the paper and find myself agree with reviewer ohJ3 in both the lack of  clarity and the gap in theory and empirical results. The math presentation still  a careful check and improvement. Eq(1)-(4) are already fairly confusing (should $Q_i$ and $\\pi_i$ be replaced by $Q$ and $\\pi$ in Eq(1)-(4), and $\\hat Q$ by $\\hat Q_i$ in Eq (2)-(3)?). I would like to suggest the authors to add a self-contained algorithm box for the practical algorithm procedure. Do the readers really need to understand the full Koopman theory (section 3.1) before understanding the algorithm? The authors could think about if it is better to present the practical algorithm first with minimum math, and then analyze the property of the algorithm using the math tools (and in this case, make it clear what theoretical guarantees we get exactly). I think making the paper more accessible can help the paper gain more popularity in ML readers."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper develops a new method (Koopman Forward (Conservative) Q-learning, KFC in short) for offline reinforcement learning by extending the static dataset to include new states that are computed by learning an action-invariant Koopman latent representation of the system. The Koopman transformation to obtain the transformed state transitions is build using a variational auto-encoder. Experimental results are provided on D4RL, RoboSuite and MetaWorld benchmarks. This is a well-written paper (there are some minor typos which the authors should rectify). The method developed here shows improved performance over current methods in a number of benchmark problems.",
            "main_review": "I have a few questions that I believe the authors should address in their revised version to help the reader understand the method and its effectiveness.\n\n1. Can you explain whether the Koopman representation in (12) holds for systems that are not control-affine?\n2. The square is missing in the Bellman error in (1), (4), and (18). \n3. Can you explain why using the symmetry generating function in (18) is not equivalent to using a different, say non-quadratic, Bellman error? In other words, I see KFC as a method that imposes the Bellman error at states that are outside the training dataset (this is great). But since we want hat{Q}_i and Q_i to be consistent across the entire state space in order to compute the correct fixed point. Therefore, the new states in (18) can be arbitrary and do not have to come from the symmetry generating function so long as they look like legitimate transitions of the dynamical system. For example, one can compute a PCA of the local neighborhood of the samples state and use the eigenvectors to perturb the states in the dataset and constrain the Bellman error to be small there. The paper does not convince that sampling states from the Koopman operator is essential.\n4. Have you tried a standard VAE to sample new states, i.e., obtaining transitions (s_t, tilde{s_{t+1}}) where tilde{s_{t+1}} is the reconstruction of an interpolation of the latent vector corresponding to s_t and s_{t+1}? I believe this should be competitive.\n5. In the same vein, are the transformed state trajectories sensible? For instance, in (16) if one computes the new trajectory as tilde{s_t), tilde{s_{t+1}), tilde{s_{t+2}}, ..., this trajectory could be replayed in the simulator or one can compute the actions/likelihood of the actions of the learned policy for this new state trajectory to ascertain that the transformations sampled from the VAE are sensible. This is essential in order to understand the method further because the symmetry in this computation can also be trivial because (I suspect) changing the origin of the state-space is a symmetry for all environments in Table 1.\n6. This paper should study the proposed method better and conduct ablation studies. For instance, the cummulative reward of KFC should degrade as more samples are drawn from the Koopman VAE. How many extra samples are drawn to augment the existing offline datasets?\n7. Do KFC and KFC++ use the same hyper-parameters as those in CQL? The narrative in Section 4 does not seem to clarify this. If not, it is difficult to claim that the improvements in performance in Table 1 come from the new method.\n8. How many seeds were used to run the experiments in Table 1? Please provide p-values for whether KFC obtains a better cummulative reward than a baseline method.\n9. The authors of https://arxiv.org/abs/2102.09225 found that the numerical performance reported in the original CQL paper is very different from the results obtained by implementing the code of the original authors. You should cite this paper and mention whether the numbers your observations with CQL (and KFC) are consistent with those of these authors.",
            "summary_of_the_review": "This paper proposes an interesting idea based on Koopman theory that augments the limited dataset in offline RL but it is not clear from the current manuscript whether the performance of the method comes from the proposed innovations. The authors should present results of ablation studies that convince the reader that Koopman-operator is essential and a similar performance boost cannot be achieved by other augmentation methods (I have suggested a few above).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper uses koopman theory to design principled data augmentation method for offline reinforcement learning. They learn a VAE style encoder-decoder model such that $D(E(s))=s$ and a forward model such that $F(s_t, a_t) = D((K_0 + \\sum_{i=1}^m K_i, a_{t,i})E(s_t)) = s_{t+1}$. The koopman operator $K$ is then used to generate symmetries which are applied to both $s_t$ and $s_{t+1}$ as data augmentation during bellman error minimization. The resulting algorithm KFC and KFC++ leads to overall better data augmentation and improves for S4RL and CQL.",
            "main_review": "Strengths:\n1. The paper provides a principled way to generate data augmentation for offline RL (and for dynamical systems in general)\n2. The paper improves over past data augmentation methods (S4RL variants) and show improved performance on D4RL tasks, meta world and robosuite environments\n\nConcerns:\n1. The paper claims \"Current algorithms over-fit to the training dataset and as a consequence perform poorly when deployed\nto out-of-distribution generalizations of the environment. We aim to address these limitations by learning a Koopman latent representation which allows us to infer symmetries of the system’s underlying dynamic.\" The statement is still unclear to me and most of the evaluations have been on same env (i.e. learned policy tested on the env in which the dataset was collected)\n2. I am not sure how KFC++ is different from KFC",
            "summary_of_the_review": "Weighing the strengths and concerns, I am recommending weak accept for now.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a symmetry-based data augmentation technique derived from a Koopman latent space representation based on some theoretical results on symmetries of dynamical control systems and symmetry shifts of data. The authors empirically evaluated their method on several benchmark offline reinforcement learning tasks D4RL, Metaworld and Robosuite and showed that their framework consistently improves the state-of-the-art of Q-learning algorithms.",
            "main_review": "-The general idea and the results of this work are interesting and seem to be novel. \n\n-However, I found the paper to be rather hard to understand. Some important assumptions are not so clear and require more clarification. Also, some points and notations should be better explained.\n\n\n**The main issues that, in my view, could improve the paper are:**\n\nFirst, there are some grammatical mistakes as well as missing words and typos, for instance\n- Page 5, line 23 and page 13, line 29:    .Which ---> which \n- On page 4, line 9 in the proof of Theorem 3.6, the sentence \"First of all note that by the definition the Koopman operator it obeys\" is grammatically incorrect\n- Page 16, line 1:  us ---> use\n- Page 16, the second line below eq. (27): an controllable ---> a controllable\n\nSecond, some important assumptions are not so clear and require more clarification:\n- On page 4, line 6, it is not clear what are f_i functions. Also, considering  \"f(s,a)=f_0(s) + \\Sum f_i (s) a_i \", it is not clear how eq. (7) can be written as eq. (8). Moreover, writing \"f_i=0, ..., m\" is a bit confusing.\n\nThere are also some comments on Theorems and their proofs:\n- In Theorem 3.4, eq. (12), the first term is \"g(s_{t+1})\" or \"g(s_{t+1}, a_{t+1})\"? Also, in this theorem it is not clear under which conditions we can obtain eq. (12). So, more clarification in this regard is needed (this is also needed for eq. (14) in Theorem 3.6).\n- In the proof of Lemma 3.3, only  \"σ_0∈ ∑\" is the identity element but not \"g\", although it is written \"Let σ_0 and g be the identity element\". This should also be considered in the proof of Lemma 3.5, i.e. only  \"σ_0∈ \\bar{∑}\" is the identity element. \n- In the proof of Theorem 3.4, line 7, \"σ^\" should be changed into \"σ\".\n- In the proof of Theorem 3.6, line 4, what is \"a\"? Is it \"a_t\"? Also the first term is \"g(s_{t+1})\" or \"g(s_{t+1}, a_{t+1})\"?\n- In the proof of Theorem 3.7, line 5, \"σ_{ε}^{a_t}\" should be better explained and needs to be clarified. \n",
            "summary_of_the_review": "This paper needs to be written in a more precise way. Especially, some important assumptions are not so clear and require more clarification.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper aims to improve generalization and data efficiency in offline RL using a latent-space data augmentation approach inspired by results from Koopman operator theory. The resulting method is evaluated on several environments against a similar method which uses a form of self supervision via data augmentation.",
            "main_review": "\n### Strengths\n- The idea of using learned symmetries of the environment transition operator to do data augmentation in latent space is an intriguing one and to my knowledge is novel.\n\n- The work provides sufficient background that a reader with a background in RL and with a passing familiarity with linear dynamical systems could understand the methodology and goal of the paper.\n\n- I didn’t notice any obvious mistakes in the proofs of the main theorems, though there were several typos (e.g. $ \\bar{\\sigma} *$ in place of $\\sigma \\bar{*}$).\n\n- Empirically, the method does seem to outperform the baselines the authors chose.\n\nWeaknesses:\n- The paper suffers from **lack of clarity**: some symbols are not defined and the types of certain functions and operators must be inferred by referring back to their initial definition. For example, the notation U(a)g used in equation 13 is ambiguous at first as to whether it is meant to refer to a composition of operators or to multiplication of the outputs.\n    - In lemma 3.3, $\\bar{\\Sigma}$ is not defined — further, using the most recent definition of the group would lead me to believe it acts on state-action pairs, however in Lemma 3.3 it is applied to individual states.\n    - The paper states that epsilon is sampled from normal distribution, but doesn’t state the precise variance, only claiming epsilon <<1.\n    - The operator $\\sigma^\\epsilon_{a_t}$ is not defined in Theorem 3.7, nor is it clear how it relates to the (presumed) group element $\\sigma$.\n    - The notation $\\mathcal{F}(S \\times A)$ is not defined. Further, the type/definition of U(a) doesn’t make sense to me: what is the value of (U(a)(g))(s’, a’) ?\n    - the notation $\\bar{\\Sigma}$, $\\hat{\\Sigma}$, etc. should be formally defined. Further, in many definitions the notations $\\phi$ and $*$ are used interchangeably. \n\t\t\n\n- There is a **large gap between the assumptions used in the theoretical results and the empirical setting**, both in terms of the assumptions required and in the outcome being measured. The theoretical results concern the equivariance properties of the Koopman operator, while the empirical results concern the performance of a learned model. \n    - The proposed method looks suspiciously similar to a VAE objective where the perturbation is defined by sigma. Thus it is not clear to me whether the properties of the learned transition model + invariances are actually important to the proposed success of the method, or indeed whether the learned symmetries can really be said to be true symmetries of the Koopman operator as opposed to simply latent-space perturbations\n    - The existence of the family of operators U(a) used in Lemma 3.5 is not shown in main paper, and indeed additional conditions are discussed in the appendix in order for these operators to exist. It is not shown that these conditions are satisfied in the settings the paper is interested in.\n    - It is not clear what types of symmetries exist in the evaluation environments, or whether KFC is able to learn a model that is equivariant to them. \n    - The jump from the theoretical results on equivariance to the empirical evaluation on performance is quite abrupt and it is not clear how the theoretical results are meant to indicate that the method will indeed improve performance.\n    - It’s not clear how the learned encoder/decoder/observables used in practice satisfy the assumptions laid out in the theoretical section.\n\n\n- **The empirical results are not convincing.** The observation that S4RL outperforms KFC on the -random split where model-learning is less useful suggests that most of the benefit of KFC is coming from the model learning component of the algorithm. S4RL and CQL are both model-free methods, so this seems to suggest to me that it might not be the learned latent-space symmetries but rather the model-learning auxiliary task that is making KFC outperform the selected baselines. Additionally,  a number of algorithmic details are missing from the description of the method, making it difficult to interpret the experimental results. \n    - I couldn’t find a description of KFC++ anywhere in the paper.\n    - How is the matrix representation of the koopman operator obtained?\n    - How many training steps do the methods get? Does the model-training phase count towards the  KFC method’s “optimization budget”?\n\n### Potential Improvements\n\n\n- Evaluation against stronger baselines that incorporate model learning and equivariance in the latent space (e.g. DeepMDP, DBC).\n\n- Rewriting the paper to improve the clarity: making sure the types of functions and operators are always clear, using consistent notation, explicitly stating the necessary assumptions for the theoretical results to hold, etc.\n\n- Using more targeted experiments to study the learned symmetries of the model will provide greater insight into whether the theoretical results hold in the latent space of KFC agents.\n\n\n### Notes\n-  I didn’t understand the claim “an exploration of the environment’s phase space” (section 1, page 2)\n- In environments that are not equivariant to any symmetry group, how would you expect the method to behave? \n- There are a number of typos in the manuscript: “the existence on nature” on p2, ’raod-map’ on p6, “regulizer” on pp 3 & 6, “in a the free” just after eq 8, etc. These were separate from my concerns about clarity.",
            "summary_of_the_review": "Overall, my concerns over the clarity of the paper, the gap between theory and experimental results, and the limited comparison to existing methods lead me to recommend that the paper be rejected.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}