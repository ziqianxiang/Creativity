{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper presents a method which selects feasible data augmentations suitable for contrastive time series representation learning. The topic in this paper is timely and interesting. One of 4 reviewers did not complete the review, not responding to a few reminders. So, one emergency reviewer, who is an expert in meta-learning was added. While there is one review that strongly supports this work, two reviews remained unsupportive after the discussion period ended. I appreciate the authors for making efforts in responding to reviewers’ comments. However, after the discussion period, most of reviewers had concerns in this work, pointing out that the technical correctness needs further justification and experiments should be improved.  While the idea is interesting, the paper is not ready for the publication at the current stage. I encourage to resubmit the paper after addressing these concerns."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes InfoTS, a method for learning augmentations that improve contrastive learning of time series data. The core contribution is a learnable augmentation strategy that uses Concrete/Gumbel-Softmax distributions. The paper shows empirical results on several time-series forecasting and classification benchmarks.",
            "main_review": "Concerns\n- page 4, right after eq (3): \"We dismiss the first part since the unconstrained entropy of v can be dominated by meaningless\nnoise.\" Why is it reasonable to drop H(v)? This is a pretty big assumption you make early on, which is never addressed in the paper.\n- Properties 1 and 2 are fairly trivial statements, which I don't think need proof.\n- I think this paper is best described as an online hyperparameter tuning method rather than a meta-learning method. While one can argue that hyperparameter tuning is an instance of meta-learning, I felt that this naming is misleading in this context.\n- All experiments: seeing error bars would be helpful because the differences between methods are fairly small in some cases.\n- Table 3: these results are so close that I think many of them are not statistically significant. In particular, removing components from the meta objective seems to have minimal effect on final performance.\n- I am not fully convinced that the proposed paper brings enough benefits to justify its complexity. For example, in Figure 8 and Table 5, the model mostly up-weights the subsequence policy, and the final performance is not very different from only using subsequence.\n\nMinor comments\n- Minor grammatical inaccuracies and typos throughout the paper. e.g., \"the information theory,\" \"important weight,\" \"combing candidate,\" to name a few.\n- page 3, \"High Fidelity\" paragraph: you call the augmented sequence v an augmentation. This is potentially confusing because augmentations typically refer to the mapping x->v, which you call g later.\n- page 3, \"High Fidelity\" paragraph: The information bottleneck paper of Tishby et al. is not a suitable reference for the general phrase \"information theory.\"\n- page 3, last paragraph: you state that v is a probabilistic function of x and noise variable epsilon. Based on later sentences, it seems that g is a deterministic function of x and epsilon.\n- Near eq (9), it would have been easier to understand how the method works if you described a few examples of transformation t_i you consider.\n- Table 3: inconsistent bolding. L_y=24+w/o Local+MAE, L_y=48+w/o Variety+(MSE, MAE) should be bolded. ",
            "summary_of_the_review": "While the paper studies an interesting problem, the reported performance gains are marginal, especially given the complexity of the model. I lean towards rejection.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This is a very good and solid paper that has both empirical elements and theoretical basis. As mentioned in the paper data augmentation in time series is a notoriously difficult problem for the simple reason that it can distort the time series completely - which in contrast to images - humans cannot verify this as it can happen with images. So the contribution of this paper is a new data augmentation approach based on information theory, a meta learning approach and an approach to select optimal data augmentation for contrastive learning.",
            "main_review": "The paper proposes a new data augmentation approach based on information theory (mutual information) and meta learning to identify optimal data augmentation approach. The rationale behind the method has been extensively described both in the paper and the supplementary material including proofs and additional ablation studies.\nThe paper is experimentally very strong with a comprehensive experiment section and results across various ablation studies.\nI do not see any weaknesses per se or limitations.\nPerhaps I missed it somewhere but is there any information on run times ans complexity?",
            "summary_of_the_review": "This is a very good submission that touches upon a kind of neglected and less fancy area of data augmentation for time series - authors propose a very neat solution that improves upon the state of the art and demonstrates good performance across datasets and various ablation studies.\nI do not think that being too picky on things that do not matter for the sake of finding some minor negative things that do not really affect the scientific merit of the paper.\nHaving said that, the although am working in contrastive learning and self supervised learning, time series data augmentation is not my cup of tea.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper describes an information-aware approach to representation learning for time series. The formulation focuses on how to obtain effective data augmentations and addresses the underlying problem from information-theoretic viewpoints, leading to the two optimization criteria, namely, high fidelity and high variety. The experimental results on several time series datasets for forecasting and classification show improvements over the methods in comparison. Detailed comments are listed below.",
            "main_review": "Detailed comments are listed below.\n\n1. About high fidelity: This criterion requires label information, where in the approach, both ground-truth labels and one-hot encoding pseudo labels have been exploited. Property 1 and Property 2 can be readily proved with the strong assumption of one-hot encoding pseudo labels. That is, the total number of classes is equal to the number of time series samples. While the assumption is hard to implement for practical use, the proposed relaxation reduces the number of (pseudo) classes to the batch size, and consequently weakly supports the validity of Property 1 and Property 2. What are the effects of this relaxation to the proposed approach, or more specifically, to the concept of high fidelity? \n\n2. About high variety: The technical correctness of this part needs to be justified. From (3), seeking an augmentation transform of high variety can be achieved by minimizing $\\mathrm{MI}(v; x)$, the mutual information between the augmented instance $v$ and the input $x$. The subsequent derivation seems to imply that minimizing the negative InfoNCE (as in (5)) can lead to minimize the above mutual information. This is questionable in that minimizing the negative InfoNCE is simply minimizing a lower bound of $\\mathrm{MI}(v;x)$; however, it does not ensure that $\\mathrm{MI}(v;x) $ will also be minimized.\n\n3. About the meta-contrastive learning in Section 2.3: While the local-wise contrastive loss in (7) follows Tonekaboni et al. (2021), the positive neighborhood and the negative neighborhood should be described in more detail. Also, the subscript $i$ in $\\mathcal{N}_i$ is confusing and undefined. The fusion scheme and (9) learn to yield a combined transform and appear to be heuristic.  The authors are expected to justify the connection of the proposed approach with meta learning. What are the justifications of naming the architecture as a meta-learner network?\n\n4. The experimental results are not convincing. From the ablation study in Table 3, the results suggest that using the sophisticated fusion scheme (Section 2.3.2) or random augmentations perform almost equally well, while using either “Fidelity” or “Variety” alone does not significantly degrade the MSE outcome at all.  In Table 2, as the model InfoTS_s indeed uses label information in training (to select suitable augmentations), the discussion (in the last paragraph of page 8) on outperforming other baselines may not be fair. \n",
            "summary_of_the_review": "Main concerns about the paper are its technical correctness and the experimental results, including the ablation analysis. This work seems to be not ready for publication yet.\n\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors propose a contrastive learning framework for time series data, where data augmentations are adaptively being selected, given a fidelity and variety criterion. Additionally to these two criteria, a contrastive learning objective is applied both on local and global level. The model is tested on a time-series forecasting and classification task on multiple datasets.\n\n",
            "main_review": "Strengths:\nThe authors propose an interesting solution to the challenge of seeking data augmentations on time-series data and provide a bunch of experiments on various datasets and with different benchmark models. The paper is well-written.\n\nWeaknesses:\nSome of the analyses and ablations could be more complete, in order to truly investigate whether the conclusions are correct.\n\nMore specific feedback:\n- It is unclear to me what the definition of the pseudo-labels is. Does it mean, if we have, e.g., 10k data points, that the pseudo label is a one-hot encoding with 10k elements? So each data points has its own 'class' label? A proper definition is lacking.\n- p4: The authors mention that direct optimization of Eq. 2 is inefficient and unscalable. But I don't really understand why, as it is in fact just a classification model like any other supervised classifier. So why is it impossible to use the label for each datapoint? And then second, how is it justified that the label of the full batch y_B does contain information about all data windows in the batch? What is it's definition? This addition to the model feels a bit strange, as it is also not further mentioned in the rest of the paper. \n- eq. 10: Are the p_i probabilities trainable parameters? And how do they relate to the importance scores mentioned in appendix D.3? Are the importance scores just unnormalized probabilities? How is the temperature set during training?\n- 3.1: This paragraph is a summation of a lot of models, but it does actually not explain the models that are finally used as benchmark models. If the reader is unfamiliar with any of the benchmark models, the paper does not provide any information to the reader about their difference compared to the proposed model. So I would extend this section with a (semi-technical) explanation of the benchmark models and how they differ in their main technique. For example, which of the proposed benchmarks is actually also a contrastive learning model, and which of the benchmarks is supervised? This information is useful to better interpret the provided results. \n- Contrastive Predictive Coding (van Oord et al., 2018) is another well-known contrastive learning method that is often used for time-series, but the authors did not mention it anywhere in the paper. Besides mentioning it in related work, it would be a very useful benchmark as well, possibly combined with the local and global loss as the authors proposed.\n- p7, last line: The authors mention that TS2Vec achies 2nd best perofrmance because it adopts subsequence by random cropping. How do the authors know this is the reason? No causal conclusions can be drawn from the presented Tabels.\n- Same remark for p8, where the authors argue that InfoTS can adaptively select the most suitable augmentations. At this point of reading, there is no proof of that yet. Later in the ablation studies the authors do however check for this, but the conclusion from Table 3 is mainly that all factors contributed (at least a bit), where the Fidelity and Variety criterion seemed to have contributed the least. So it's not super fair to state that the model's superior performance is (only) thanks to adaptive augmentation selection. In fact, from Fig. 7 it even seems that the model just learns to select one best augmentation, rather than a best combination of all of them. \n- Fig. 3: Can the authors also provide the plot for the ablation models that are not trained with the variety and fidelity criteria? Now it's unsure whether these criteria contributed to this positive relation, or whether this relation already exists by default in such models.  Also, how does this relation look like in the forecasting task?\n\nMinor things/ typos:\n- end p3:  \"parameterized\" instead of paramterized\n- I would refer to Fig. 2 already earlier, for example already both in the High fidelity and high variety sections. It helps the understanding of the reader.\n- p4: The authors mention that the nr of labels is equal to the number of instances in dataset X in the unsupervised case, but this is actually for supervised training right? In the unsupervised case there are no labels. Or do the authors refer to the pseudolabels then? But even then, in the supervised case this remark also holds. \n- p5: Is the batch X_b the same as the mini-batch used during training and mentioned later in the paper? Or are batch and mini-batch two \ndifferent entities in this work?\n- p5: \"non-neighboring samples\", is a sample here a subsequence, just like s?\n- eq. 10: The work from Jang et al., (\"Categorical reparameterization with gumbel-softmax\") concurrently invented the concrete/Gumbel-softmax distribution as the work of Madisson et al., so these works are typically cited together. \n- LSTnet is compared in table 1, but not cited in section 4.1, and StemGNN is cited but not added to the table. \n- 4.4: \"The advantage of adaptive selection\": So if I understand correctly with adaptive selection the authors refer to the concrete sample from a trained categorical over possible augmentations?\n- Appendix C.1: What's the difference between the cutout and the subsequence augmentation?\n- Appendix C.1: If time warping is applied, the number of samples per window is different right? So how do the authors deal with this? Is resampling applied maybe?\n- Appendix D.1: To which experiment does figure 5 relate? And are all runs run with the same randomized seed? \n- Appendix D.3: The MAE of Subsequence for L_y = 168 and 336 in Table 5 are missing a leading zero.",
            "summary_of_the_review": "The authors propose an interesting solution to the challenge of seeking data augmentations on time-series data. Downstream task performance seems promising compared to benchmark models. In general the paper is well-written, but some clarifying questions remain (see my earlier remarks). Also, some of the (ablation) analyses can be made more complete. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}