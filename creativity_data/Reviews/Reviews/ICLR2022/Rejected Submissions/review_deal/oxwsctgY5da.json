{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This work proposes a branch and bound framework for adversarial attacks, based on the MIP formulation of attacking against ReLU networks. It adopts several heuristic tricks to accelerate the attack efficiency, and shows better attack performance on hard examples, compared to off-the-shelf MIP solvers. \n\nThe main concerns in the first-round reviews include: \n1. The limited novelty, since the problem and formulation is not novel, and the proposed method is the combination of several heuristic tricks, without theoretical analysis. \n2. The experiments are insufficient, and only MIP solvers are compared, while other attack methods and the ablation study of different tricks are not presented. \n3. The efficiency is higher than off-the-shelf MIP solvers, but significantly lower than other adversarial attack methods.\n\nThe authors made great efforts to respond these concerns, such as adding some baseline attack methods and ablation studies. Most reviewers appreciated the authors' efforts and raised their initial score. However, after reading the revised manuscript, reviews and responses, I think many serious issues still exist. \n1. Since the proposed method is only applicable to the MIP formulation of attacking ReLU networks, it could not become a new baseline to attack mainstream deep neural networks, which significantly restrict its practical contribution to the community. And, it didn't provide novel theoretical tools or better theoretical results of analyzing the robustness of ReLU networks. It just reduce the gap to the verified robustness of existing verification methods. Thus, I cannot find significant contributions to the community of adversarial examples, from both practical and theoretical perspectives. \n2. The experiments are still insufficient. There have been massive advanced white-box and black-box attack methods. The added FAB, square (black-box), DIFGSM, MIFGSM (white-box), are popular methods, but not SOTA methods. Besides, only small images of MNIST and CIFAR-10 are tested, while large-scale images like ImageNet are not tested. It has been observed in many works, and according to my own experience, the attack performance on between small images (MNIST and CIFAR-10) and large images (ImageNet) is not always consistent. And, the low efficiency weakness (compared to other attack methods) of the proposed method may be further highlighted. \n\nIt is not easy to decide to reject a submission with average score 7. The authors's efforts during their submission and the responses are greatly appreciated. However, I would like to accept works that can bring in real contributions to the research community. Hope the reviews and meta review could be helpful to further improve this work."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, the authors propose to solve the adversarial attack problem of ReLU neural network by using a branch-and-bound procedure, and search adversarial examples within the activation space corresponding to binary variables of a mixed-integer programming formulation. The experiments showcase that such adversarial attack framework enables them to find adversarial examples for hard instances where existing adversarial attacks fail. ",
            "main_review": "This paper is neatly written, the intuition and heuristic method is easy to follow, and experiments are convincing.\nHowever, this paper is purely heuristic-based where some theoretical results would be much appreciated, and experiments are not comprehensive, I feel like by keep working towards either one of these two aspects will highly improve the quality of this paper. \nAlso, while the adversarial attack is a very important problem, I think the basic idea presented in this paper is not fundamentally novel and in that regard, the contribution of this paper seems a bit weak.\nIn the following I list some of the detailed comments.\n\n1. Throughout, \"branch-and-bound\" and \"branch and bound\" are both used. You should be consistent, and the first one is more commonly used. Also, its abbreviation is usually denoted as B&B.\n2. Line after equation (1): \"ball around input x\", here $x$ should be $x_0$, denoting the benign input point. \n3. When you mention \"projected gradient descent\" you should mention (PGD) as its abbreviation, since you used PGD heavily in the later context. \n4. You should specify that N is the number ReLU neurons here. \n5. Second paragraph, page 2: You should specify that $N$ is the number ReLU neurons here. \n6. Second line on page 3: \"adversarial adversarial attack\" is wrong.\n7. All Eq. \\ref{...} should be Eq. \\eqref{...}\n8. For Eq. (2), you should mention for i=1, ..., L. Also, I think you should also impose $\\hat{z}^{(i)}(x) \\geq 0$. \n9. Page 3: \"can be provable obtained\" should be \"... provably ...\"\n10. The end of page 3: \"... is well explored recently ...\" here a reference would be appreciated.\n11. \"Adversarial common pattern\" on page 6 should be highlighted in italic.\n12. Second paragraph of page 7: \"T percent of\" doesn't make sense, it should be \"100*T percent\".\n13. In Fig. 6, for the experiments in (c), I cannot see the obvious improvement for attack margin. \n14. Detailed information of those data-sets should be mentioned. \n15. In Experiment section, it's better to mention Fig. 6 somewhere in this section, while giving a more detailed explanation. \n16. Experiments can be carried out and presented in a more detailed fashion. ",
            "summary_of_the_review": "This paper can be much improved by conducting a more extensive numerical experiments, basic idea is obvious and not fundamentally novel. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces an efficient way to apply a branch-and-bound procedure to solve the mixed integer programming formulation of the problem of creating adversarial examples. This method of adversarial example creation is particularly designed to work in difficult cases where other methods fail.",
            "main_review": "Strengths:\n- The paper has good novelty, combining techniques from several other papers into an interesting new technique\n- The proposed method is shown to provide a significant speed improvement over a vanilla MIP approach on the given tasks\n\nWeaknesses:\n- The experiments are only run on the adversarial examples which could not be solved by any other method, and only compared to the vanilla MIP approach. I would like to see some numbers comparing the proposed approach to some different methods for time and efficacy (the proposed method is slow so I would not expect to see this tried on a large dataset).\n",
            "summary_of_the_review": "Overall the paper is good, demonstrating a novel method to quickly produce adversarial attacks in hard cases. It could be improved with the inclusion of more extensive experiments.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a branch-and-bound attack (BaB-Attack) to solve hard instances efficiently, where none of the existing adversarial attacks can succeed. Specifically, the BaB-Attack utilizes the bound propagation-based neural network verifiers on GPUs to rapidly evaluate a large number of searching regions, builds an adversarial candidates pool to guide the search, and refines candidates adversarially\nexamples using a bottom-up large neighborhood search. Experimental results show that BaB-Attack outperforms the existing attacks in both attack success rates and efficiency.",
            "main_review": "Strengths:\n- This paper utilizes several technologies to accelerate the branch-and-bound procedure on finding adversarial examples for deep neural networks.\n- Compared to the baseline attack method (MIP attack), the proposed BaB attack achieves higher attack success rates within much less time. \n\nWeaknesses:\n- One drawback of the BaB attack is speed. Compared to the gradient-based attacks, which takes only a few seconds to generate adversarial example, the time cost of the BaB attack is not negligible.\n- The BaB attack consists of several parts, including bean search guided by neural network verifiers, diving in branch and bound, and large neighborhood search. However, no ablation experiments were presented to verify the effect of each part.\n- In the design of the BaB attack algorithm, many are heuristic and lack theoretical analysis. For example, the BaB attack utilizes lower bounds given by the bound propagation method $\\alpha, \\beta$-CROWN to guide beam search.\n- The written is unclear and difficult to understand.",
            "summary_of_the_review": "Overall, I think this paper is marginally below the acceptance threshold.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Authors proposed a novel branch and bound attack, which searches adversarial examples in the activation space of binary variables in a mixed integer programming formulation. They also present several heuristics such as top-down beam-search, diving, and bottom-up large neighborhood search guided by the adversarial candidates pool to efficiently obtain strong adversarial attacks better than standard MIP solvers and other SOTA methods.  ",
            "main_review": "**Strengths:**\n1) New interesting way to approach adversarial attacks from a mixed integer programming perspective (although not fully clear why).\n2) Presented several heuristics that improves practicality and speed of the adversarial attack search.\n\n**Weaknesses:**\n1) Very difficult to understand the problem that the paper is trying to solve, the main idea, why the results are meaningful. \nWhy integer programming and such an esoteric formulation for adversarial attack search? \nWhat are the benefits of this formulation and method compared to the standard gradient based approach?\nI suggest rewriting the paper, especially the background part, to make it more understandable and accessible.\n2) Minor grammatical and punctual errors - “**an binary** encoding”, “locate adversarial examples **if exist**”, “**a**dversarial candidates pool dynamically filled...”, etc.\n",
            "summary_of_the_review": "Since it is hard to capture the main point of the paper and the problem it is trying to solve, I tend to be on the rejection side.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety",
                "Yes, Potentially harmful insights, methodologies and applications"
            ],
            "details_of_ethics_concerns": "New adversarial attack is presented with all corresponding concerns.",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}