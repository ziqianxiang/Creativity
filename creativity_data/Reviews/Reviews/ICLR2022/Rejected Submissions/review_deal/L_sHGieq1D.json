{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper presents a domain generalization method for semantic segmentation. The model is trained on synthetic data (source) and is tested on unseen real datasets (target). The authors propose a simple data augmentation method, AdvStyle, generating unconstrained adversarial examples for the training on the source domain.\n\nThere was no consensus on the method among the reviewers. Several issues have been raised. After rebuttal and discussion, no one really changed her/his mind. The motivation of why focus just on driving scenes is still questionable. Definitively, it could be interesting to investigate further why it is not straightforward to have gains on other kinds of scenes. Finally, we encourage the authors to address the raised concerns regarding the discussion with previous works and the comparisons for future publication."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies the problem of adversarial domain randomization for urban scene semantic segmentation. Specifically, it proposes an adversarial augmentation method called AdvStyle that injects adversarial signals into the channel-wise mean and standard deviation of images. The style augmentation is used when training on synthetic images from Synthia and GTAV datasets. This paper demonstrates promising results when applied the trained model to real semantic segmentation benchmarks.",
            "main_review": "Strengths:\n* This paper tackles a structured prediction problem (semantic segmentation) in the domain generation community.\n* The idea is clearly stated and straightforward with source code included in the appendix.\n\nWeaknesses:\n* The technical novelty is very limited. The key idea (augmenting channel-wise mean and standard deviation) has been explored in the cited reference [MixStyle; Zhou et al., 2021]. The difference is that this paper constrains the augmentation within the first layer with an adversarial formulation. The reviewer fails to perceive a broader impact on the community from this technical contribution.\n* At a high level, AdvStyle is a data augmentation method that generates unconstrained adversarial examples. In this sense, a prior work [**Ref1, Bhattad, et al., In ICLR 2020] is highly-related but not discussed in the paper. Bhattad et al. use a pre-trained colorization or texture-transfer network for adversarial example generation. Please elaborate on this in the rebuttal and incorporate the comparisons in the future version of the paper.\n* This paper only conducts experiments on sim-to-real transfer but does not evaluate real-to-sim transfer or real-to-real transfer. This makes an unfair comparison to the baseline methods including [Choi et al., 2021]. Please elaborate on this in the rebuttal. The reviewer would kindly suggest incorporating these comparisons in the future version of the paper.\n\nReferences:\n\n* Ref1: Unrestricted adversarial examples via semantic manipulation. Bhattad et al., In ICLR 2020.",
            "summary_of_the_review": "Overall, this is a borderline paper with promising results. The major concerns include the limited technical novelty, missing references, and unfair experimental comparisons. I would like to see the rebuttal and comments from the other reviewers to make a final decision. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper aims to address the domain generalization problem in semantic segmentation. Starting to synthetic source dataset, the authors propose to apply image-level style transfer to bridge the gap between source and unseen real dataset. Specifically, the image-level style is defined as the mean and variance of each image. And the proposed method learns to reconstruct scenes with their styles and further updates the segmentation model with both original images and reconstructed images.\n\nIn experiments, the authors show that the proposed method can:\n1. achieve SOTA performance on multiple real datasets \n2. generalize well with various backbones\n3. cover the data distributions of real dataset well",
            "main_review": "Strengths:\n1. Complete and solid experiments \n2. The image-level style transfer part is intuitive \n3. Paper is easy to follow\n\nWeakness:\nThe main concern I have is the model design and also not sure about some of the authors' intuitions behind:\n1. Based on the algorithm in Appendix B, we only will update the adversarial learning once, or the mean and variance once, then we feed the updated mean and variance to robust model part to reconstruct the scene and then further update the segmentation model. My main concern is about what is really learnt in this one update? Personally, I feel that when updating only once, the generator cannot really learn much, e.g. the reconstructed results can be very far away from the original image and cannot be very meaningful. Then if at later stage we force the predictor to minimize the segmentation loss of both original and reconstructed images, will this introduce noise to our predictor, e.g. the predictor then cannot really do well on either image. And is this scenario possible and how does the proposed method handle this problem?\n2. Is the segmentation model shared between adversarial and robust model learning process? I believe so, right? Then follow up for the first question, will the segmentation model be drifted away by the one-time update and then introduce additional errors to adversarial learning procedure?\n3. How do we decide the maximum number of iterations in algorithm?\n4. One corner/extreme case might be that the generator learns very well after many times of iterations and can perfectly reconstruct original images. Then under this scenario, the segmentation model do not need to learn anything but stay with what it has been initialized with would be the right answer for the model. Or we can relax a bit by thinking that what has been generated/reconstructed can be very close to the original images after many epochs and not much changes are needed for segmentation model. How will the proposed method handle this case?\n5. What is the difference/relationship between the proposed method and papers like \"LEARNING TO SIMULATE\"? \n6. Why the proposed method can produces new styles that cover the distributions of different datasets as shown in Fig.5? Any explanation? ",
            "summary_of_the_review": "In general, I feel that the paper provides very good experimental results but I have concerns about their model design. I am willing to change my rating if the authors can address my concerns above.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper introduces a domain generalization method for semantic segmentation, where one synthetic data is given as the source training dataset and the model is tested on unseen real datasets. The authors propose a simple yet effective method by introducing adversarial style augmentations. Specifically, the model decomposes the image into a style feature and a normalized image, and then uses the segmentation loss to update the style feature. With the updated style feature and the normalized image, it can resemble an augmented image, which is then used to optimize the segmentation model along with the original image via the segmentation losses. A few highlights of the proposed method are:\n- It appears to be a plug-in module, so that it can be used for different methods. architectures, and tasks\n- It shows state-of-the-art performance on the semantic segmentation task",
            "main_review": "Strength:\n- The paper is very well-written and easy to follow\n- The proposed method is simple yet effective with a good motivation\n- The proposed augmentation can be integrated into different methods\n- The paper shows good performance on two tasks: semantic segmentation and image classification\n\nWeakness:\n- The explanation of why the proposed augmentation performs well to cover unseen data distributions is not clear. For example, in Fig 5 of the t-SNE plot, GTAV is the only training data, but it can generate out-of-distribution samples (e.g., Adv GTAV), which does not seem very intuitive. Is it also because other data augmentations (color jittering and gaussian blur) are used? The authors should clarify this.\n\nExperimental comparisons\n- In Table 5, although there are different settings, the authors should try efforts to make fair comparisons, e.g., using the whole set of GTAV for training (setting I and II).\n- The setting in the paper only uses one source dataset. It would be interesting to report results of using multiple source datasets (like the ISW paper using both GTAV and Synthia).\n\nMinor issue\n- The ERM baseline in Sec 4.5 should have the reference, instead of having it in the appendix.\n\n##########################################################################\n\nPost-rebuttal:\nThe rebuttal well addresses my main concerns. I would encourage the authors to release the code and models if the paper is accepted.\n##########################################################################",
            "summary_of_the_review": "Although the proposed augmentation method is simple. it shows state-of-the-art performance for domain generalizable semantic segmentation. The proposed method can be also adopted in different methods, backbones, and tasks, which is beneficial to the field. However, the authors should address the raised concerns regarding the technical clarity and experimental comparisons.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": " The paper presents an adversarial style augmentation approach (referred to as AdvStyle) with the objective of improving the generalization of models from a synthetic domain (training) to a real domain (testing), for the task of scene segmentation in the context of driving. The approach is based on the idea of adversarial style learning and the training of a model using both original and adversarial images. A strong set of experiments showcase the benefits of the approach with respect to the state of the art.\n",
            "main_review": "Pros: \n- Definitely, the main point in favor of this paper is the good results obtained by the approach. I believe the approach is well evaluated, making the right choices of synthetic datasets (training), real datasets (testing), semantic segmentation architectures, and baselines (e.g. ISW, which is one of the best performing approaches for domain generalization in semantic segmentation).\n\n- The approach is orthogonal to other solutions, such as ISW. The combination of ISW and AdvStyle leads to even better accuracy in the downstream task (semantic segmentation).\n\n- The technique is conceptually simple and easy to reproduce.\n\n \n##########################################################################\n\nCons: \n \n- The t-SNE visualization (Figure 5) doesn’t seem to convey much information regarding what is happening during the training process. I understand it is typical to visualize features spaces in DA/DG papers, but in this case, it is not clear to me that the figure helps make any point. On the contrary, I would argue it distracts from the main point.\n \n##########################################################################\n\nQuestions during rebuttal period: \n \nI don’t have major concerns with this paper. However, I have a recommendation/thought for the authors.\n- Why focus just on driving scenes? It should be relatively straightforward to evaluate this approach in other types of scenes, for instance, indoor scenes, by leveraging NYU dataset + SceneNet or InteriorNet. This will help make an even stronger point.\n \n#########################################################################\nMiscellanea: \n\n- Figure 1 is cluttered and hard to understand. I would recommend removing b) and d).\n\n- Figure 5, as mentioned above, doesn’t seem to help with the narrative.\n",
            "summary_of_the_review": "My vote is towards accepting this paper. Similar concepts have been applied in the past to improve domain generalization but never reaching the quality achieved by the proposed approach. It is exciting to see how the application of adversarial style learning can boost results even surpassing existing state-of-the-art solutions, especially considering the ease of implementation of this idea. The experiments section is quite strong, leveraging well-known datasets, relatively modern segmentation architectures, and very recent baselines.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}