{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper offers flow-based alignment methods for alignment of distributions in a domain adaptation setting.  While there are many positive aspects of the submission, the experimental results only weakly support the results.  The AC agrees with the critical comments mentioned by reviewer sZ2C, and in particular observes that the experimentation is not state of the art with regard to current domain adaptation literature. Unfortunately the submission is not acceptable in present form."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents a unified framework for domain alignment through non-adversarial approaches. Instead of solving a min-max adversarial problem, this paper aims to solve a min-min optimization equivalent to minimizing the upper bound of JSD. It proves the equivalence and offers a computational and feasible solution that can be inserted into flow-based non-adversarial approaches in a plug-and-play fashion. Preliminary results on generating digits from different classes or domains have demonstrated the correctness of the model.",
            "main_review": "* The major contribution of this paper is providing new domain alignment loss with theoretical guarantee and connections with JSD.\n\n* The paper is well written and easy to follow. Details of experiments can be easily located and confirmed.\n\n* A major concern of this paper is to which extend the current model can be applied to more general learning tasks. The current experiments (most of them) show the produced samples, compared with two SOTAs. It seems to me that the advantage is not very significant. See Fig. 6. Also, the quantitative results through FID and AUB are comparable to AlignFlow.  \n\n* Authors may be interested in showing more results of different learning tasks. As the approach is mainly for domain alignment, it would be interesting to show, e.g., visual domain adaptation results.\n\n* More exploration and discussions are expected for high-dimensional or structured data, which may affect the design of transformation T and its inverse. The current model is only evaluated on simple or low-dimensional data, and the model generality is unclear. \n\n* While GAN model is computationally expensive and hard to optimize, the proposed model did not prove itself to be efficient or more optimizable in conventional vision tasks where GAN was testified.\n",
            "summary_of_the_review": "In brief, I was impressed by the theoretical results and connections of the new alignment loss and conventional JSD bound. Experiments seem to prove the model is workable on toy data and digits datasets. However, authors still need to explore and demonstrate its feasibility and value in more challenging learning tasks using high-dimensional or structured data.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "n/a",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper provides an interesting idea by unifying flow-based models under a non-adversarial framework to realize multiple-distribution alignment.",
            "main_review": "## Concerns:\n\nMy major concern is why adversarial learning is challenging for distribution alignment? Could you provide a concrete example like an experiment? Do the authors justify this only according to, \"However, adversarial learning can be quite challenging in practice\", with two references are both earlier than 2019. How about nowadays? As the author claimed, \"the auxiliary density model $Q_z$ may be more difficult to train than the auxiliary discriminator $D$\". Does this seem to be contradictory to your justification?\n\n1. The experiment design is trivial with MNIST. Using FID to measure generate data quality on MNIST is not well acknowledged. The authors should either choose a different dataset or report some other metrics.\n\n2. There exist lots of multi-domain translation models with GANs, e.g. MUNIT and StarGAN v2. Without this kind of comparison, adversarial learning models shouldn't be criticized.\n\n3. Since the proposed model introduces flow-based models, some ablation studies by changing the based model, e.g. Glow, NICE etc, would be better.\n\n4. Since the flow-based model is used, is there any way to visualize the latent space on real data?",
            "summary_of_the_review": "It's an interesting idea of using non-adversarial learning to realize multi-distribution alignment. But lots of concerns remain as given above. Thus, the impact of this paper is weak.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "no.",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a flow-based method for the unsupervised data set alignment problem. It firstly reveals that the minimization problem over density models can be addressed by optimizing the upper bound of generalized JSD. Based on this theoretical result, the authors propose a new regularizer for the multi-distribution alignment problem. Compared to prior work, e.g., AlignFlow and LRMF, the authors derive a more general framework for the unsupervised data set alignment problem. The authors also provide extensive experiments to verify its effectiveness and superiority.",
            "main_review": "Strengths:\n1. This paper theoretically gives an upper bound of GJSD with a learnable density function Q in a variational way, which extends prior method AlignFlow in multi-distribution alignment;\n2. The authors give extensive discussions about the relationship between prior methods (including LRMF that tackles two data set alignment) and a regularization term.  \n3.  The author provides extensive experiments to illustrate its effectiveness. Moreover, the author also experimentally verify the statement in the discussions about prior methods and a regularization term.\n\nWeaknesses:\n1. Compared to AlignFlow, this work provides a learnable Q rather than a fixed function. This design seems reasonable. Could the authors give more discussions about the learnable Q? The authors state that a fixed normal distribution Q is insufficient. However, VAE[1] can generates very realistic figures from a normal distribution in a reversible way? Under what cases is a fixed Q not enough? \n\n2. Compared to LRMF which tackles two data set alignment, this work can align multiple distributions. From Figure 3, the authors claim that if the density model class Q is not expressive enough, LRMF could fail to achieve the alignment. Could the authors explain the difference between the two methods (LRMF and yours) when optimizing the function Q?  Moreover, the number of the data sets to be aligned in the experiments is relatively small. When the number of distributions is large, is there some problems when the proposed method to align these distributions? This may be a common issue for existing methods, could the authors discuss it more?\n\n[1]Kingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\" arXiv preprint arXiv:1312.6114 (2013)",
            "summary_of_the_review": "The framework advances the improvements in the problem of multi-distribution alignment, although it is an extension of prior works.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}