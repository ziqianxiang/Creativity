{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper investigates the role of BPE and vocabulary sizes in memorization in transformer models. Through a series of experiments on random label prediction, training data recovery and membership inference attacks, the paper shows that larger vocabulary sizes lead to improved memorization. The Reviewers all agree that the paper investigates an important question and does so thoroughly. The main concerns were about: (1) the validity of the conclusion that it is sequence length indeed which affects memorization; and (2) the lack of more tasks to validate the findings. For (1) the authors added another set of experiments which further rule out frequency effects as a factor, but I agree with Reviewer KAZC that more evidence is needed which directly shows that sequence length is responsible (e.g. are shorter PAQ questions memorized better?). For (2) the authors shared a google drive link with additional results on NMT after the deadline, which the reviewers appreciated. Overall, however, the paper needs more work in order to unify all these results in a single draft."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper as the name suggests, tries to figure out whether and through which ways bpe can affect Transformer’s memorization capacity. It evaluates Transformer’s memorization under these 4 settings: memorizing random synthetic data, memorizing random labeled natural language data, recognizing training data with lower output entropy, and training data recovery QA. Experiments show that if we have more merge times for bpe (larger vocabulary size), the model’s performance on all the four settings would improve on 3 architectures, which shows that bpe indeed can affect the model’s memorization capacity. Larger the vocabulary size is, the better the model would perform on memorizing. Then, the paper tries to figure out why more merges in bpe would lead to better memorization. By excluding two other hypotheses, the paper concludes that more merges in bpe results in shorter input sequence and that makes memorizing easier for transformers.",
            "main_review": "I think this paper presents a thorough evaluation on how bep affects transformer’s memorization. My main concern is that their conclusion, shorter input sequences lead to better memorization, is drawn a bit hastily. The paper draws this conclusion indirectly by disproving the other two assumptions that they gave. However, are the 3 assumptions the only possible candidate theories? Or, are there ways to directly prove that it is the sequence length that makes a difference? One possible experiment can be, in the experiment of training data recovery, you train two different language models with the same data set, while for one you cut the long  input sentences into multiple short sequences (or concatenate sentences to make the input sequence longer), for the other you train the language model with the original data set. ",
            "summary_of_the_review": "Thorough empirical study on whether BPE affects memorization in transformers. While the final conclusion, shorter input sequences lead to better memorization, is not well supported by experiments.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies the memorization properties of an NLP models conditioned on how large is the vocabulary size. They concentrate on widely used BPE algorithm in order to split original data into subword units. Further they construct a test-bed consisting on several tasks where each task is related with a specific memorization aspect connected to the model such as capacity or preference which authors introduced themself.\n\nExperiments empirically validate the change of memorization properties as the vocabulary size is changing where it exhibits better memorization with larger vocab size. Further authors make multiple hypotheses of what might be the underlying explanation hidden behind the improved memorization. After checking these out they conjecture that the reduced sequence length is likely the major contributor explaining the underlying observation.",
            "main_review": "This work is placed on the border for me as it is investigating well crafted question and does some empirical validation of multiple hypotheses. On the other hand, there is not much of discussion on what can we do with long sequences when we require memorization? Authors provide very high-level paths such as 'Our findings can provide guidance for tuning the learned data structures', but I would be very curious to read more details. I think it would nicely fit as findings paper rather than work with the novel contribution.\n\nWhen it comes to strengths, I like the construction of memorization properties which allows to quantify the memorization by using the proposed probing tasks. In addition, authors tried to provide many details on specific hyper-parameters they used, although I left some comments below where more details would be welcome.\n\nRegarding weaknesses: while the memorization properties are clearly outlined, the construction of model parameterization in probing tasks is written on very high-level without any discussion of why this specific method of casting the model as classifier is chosen and how it may or may not provide necessary information towards research questions about memorization, this is mainly addressing section 3.3).\nIn addition, authors mention 'SOTA \\ state of the art' several times during the work while they do not much relate to the actual SOTA models. Please correct me here if I am wrong, but considered models are not in the same ballpark as SOTA models. I want to stress that the latter fact is not a bad thing, but then there is no need to relate with SOTA then.\n\nBelow I have noted multiple comments where it was hard to me to get all the details or where I felt the minor change / addon would improve the presentation:\n\nPage 3, *\"At test-time, we prompt the trained LM by a query followed with the separator token and check whether the trained LM reproduces the correct answer within top-1 or top-5 results returned by beam search (beam size 5).\"* : This is very specific design choice, why did you choose it? Model conditioned on the q gives the entire distribution on sequence-level and beam search is very sensitive to the beam size? I see an alternative as doing unbiased sampling and computing expected similarity with the answer. Some discussion on that would help to clarify this.\n\nBottom of page 3: you used word *setups* to refer to both tasks and models (right?) which is a bit confusing.\n\nSection 3.3: as I wrote above, in my opinion this section needs to be larger as it defines very important design of the model parameterization, right now it is not even clear enough what are 'target class' in the context of vocabulary tokens? I believe explaining this would improve the presentation of that part a lot.\n\nPage 5: *achieves 100% train accuracy* : in cases of MLM, was acc measured only on task class prediction or on other masked tokens as well?\n\nPage 5: *Hence, in this experiment we used a 1-layer*:  Could you explain why you chose to reduce the model size? In my understanding the task itself might be too easy so the other way is to alter the underlying task (since you specifically construct it). \n\nPage 5: *which was enough for the training loss to converge*: Converge to what? Was there an early stopping criteria on loss or acc?\n\nPage 8: *Thus, if the vocabulary growth alone can explain the observed effect, we will see that the datasets with “duplicated” tokens would also be easier to memorize.* : In your proposed construction the frequency distribution of tokens doesn't change relatively to each other, right?. Is it the same for BPE learning when number of merges is growing? Would be great to show this, otherwise it is hard to buy this statement.",
            "summary_of_the_review": "I set the score as marginally below the threshold given my concerns above where the main one is that the overall conclusions represents empirical findings without much of a contribution towards specific takeaways or practices which would be handy for the community. Nonetheless, I am open to discuss how this work can be positioned in this conference if there will be strong positive feedback from others.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper investigates the impact of subword vocabulary size on the memorization ability of Transformer models. The authors designed three types of tasks to evaluate the changes of model memorization, namely learning mappings with random labels, membership inference and training data recovery. Experimental results show that the memorization ability of Transformer model is stronger with the increase of subword vocabulary size, which the authors attribute to the reduction in the sequences' length.\n",
            "main_review": "Pros:\n1. The experiments are comprehensive. The authors design three different types of experiments to thoroughly compare the memorization ability differences between three different models (Encoder, LM, MLM).\n2. The paper explores the relationship between the memorization and generalization capabilities of the model, and shows that generalization is not directly at odds with memorization, which can inspire future model design.\n\nCons:\n1. The authors focus on three candidate causes, which the authors claimed are principal (side-)effects of applying BPE: (i) removing redundancy in the data (due to compression), (ii) increase in the number of the unique units used to represent the data, or (iii) reducing the length of the training sequences. Other factors that are closely related to the BPE vocabulary may be also important, such as the subword frequency. Can the authors explain why the three factors examined in this paper are more likely the causes than other factors (e.g., subword frequency).\n2. Although the paper presents several interesting conclusions, they can not be directly used to determine a suitable vocabulary size in practical tasks, where the demand of the model's memorization is unknowable.\n\n\nConcerns:\n1. The conclusions in this study are only validated on the SNLI dataset (PAQ is only used for the training data recovery experiment), which may threat the universality of the findings. Experiments on other datasets and tasks (e.g. the machine translation task where Transformer was invented) are necessary.",
            "summary_of_the_review": "The research questions explored in the work are very interesting and important. However, the experiments are relatively weak, and it is not clear how to apply their findings in practical tasks.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}