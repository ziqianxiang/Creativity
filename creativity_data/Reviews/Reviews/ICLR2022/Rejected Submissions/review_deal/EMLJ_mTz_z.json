{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper proposes to represent a deep neural network as a graph and analyze its learning dynamics as a time series of weighted graphs corresponding to the neural network. As the graph representations, the authors propose to use a rolled representation in addition to a unrolled representation. Then, they proposed to utilize the graph features of the representations for predicting its predictive accuracy. \n\nThis paper presents an interesting idea which could be used for predicting the test accuracy from the first few epochs training. However, there are also several weaknesses as pointed out by the reviewers. First, the justification of using the graph structure to predict the accuracy is weak (indeed, the graph structure can be used for prediction, but its necessity is not well supported), and there is no theory to support the proposed method. Second, the problem setting is a bit wired. The training data is generated by using the same architecture and data set. Although the authors gave additional experiments on the architecture generalization, it is still difficult to see how convincing the method is for more general settings. Third, baseline methods are not shown in their experiments.  \nIn addition to that, the thresholds for the classification tasks seem to be too small (like 40% in CIFAR10) which would make the problem too easy. Therefore, the practicality of the method is rather unclear. \n\nThis paper is quite on the borderline, but for the reasons listed above, it is a bit below the acceptance threshold."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a graph-based approach to assess the performance of deep neural networks in vision tasks. The approach is essentially based on representing the first few epochs of SGD-based training of the neural architecture seen as a graph (where nodes stand for neurons and edges stand for connections among neurons), followed by feature extraction, signature construction and finally a classifier (to predict the high or low level of final accuracy) or a regress or (to predict the exact finally accuracy score) layer.\nThe approach is assessed on several experimental settings, though limited to the case of static networks (e.g., without recurrent/recursive connections). The results seem encouraging and interesting",
            "main_review": "* Strenghts\n- The paper is rather well written, clear and coherent (I could only spot a typo “ changes of rolled graph graph between”,  with the repeated “graph” word)\n- The empirical analysis is rather extensive and the results seem to support the claims\n* Weaknesses\n- Lack of theoretical insights makes the contribution slightly less relevant and appealing\n- Lack of asymptotic computational (time and space) complexity analysis would definitely add some more value to the paper, especially when comparing the behavior wrt early stopping and the literature alternatives.\n",
            "summary_of_the_review": "The paper is overall convincing, even though lack of theoretical insights and of computational complexity analysis reduce a bit my final evaluation.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper tries to model the learning dynamics of a (deep) neural network using graphs. In particular, the authors propose to represent the learning process as a time-varying graph, which is then used to capture the structural changes through some simple graph statistics (such as weighted degree and eigenvector centrality), and eventually to predict the accuracy of the neural network (through some simple ML models such as SVMs or MLP).  ",
            "main_review": "The graph analysis perspective for understanding neural networks is definitely timely and promising. The proposed method seems (experimentally) efficient in terms of the number of epochs and prediction performance. Moreover, in comparison to state of the art methods such as Rieck et al.'19, the methods is computationally more efficient. \n\nThere are however different points that should be clarified in the text. \n\n1) The whole framework should be better explained. While Fig. 1 is very useful, the paper is missing a connection between Fig. 1 and the graph construction (Figs. 3,4). In particular, it would be useful to have a picture that shows the graph structure for a 'simple' deep neural network, with only a few filters and layers, as well as the number of edges corresponding to each step. Fig. 3 is good, but it does not give the complete picture to the reader. \n\n2) The authors should explain a bit more the intuition behind these graph signatures. What type of dynamics do they capture? What do they reveal about the architecture? What is the advantage in comparison to other graph features (local or global)?\n\n3) The authors claim that the method can be used in interpretability-related tasks. Can you elaborate on that or give some examples?\n\n4) How do you define the training set for a specific architecture? For one architecture, and one dataset, you have a single time-varying graphs, no? \n\n4) The paper needs some work in terms of presentation. There are different typos or expressions that should be clarified. Some of them are listed below: \n   - pg.3 \"results feature-map\" --> \"results in feature-map\"\n   - pg.3 \"number of nodes\" --> \"the number of nodes\"\n   - pg.3 \"layer of graph\" --> \"layer of the graph\" (the entire sentence needs to be rewritten)\n   - pg.4 Fig.3: K layers means K node types? Does the type of the node play a role in defining the features?\n   - pg.4: section 3.2: \"the introduced time-evolving graph representations\" . However, from my understanding, no time-varying graph representation has been introduced till that point. \n   - pg.6: Please clarify what is the binary classification in Table 2\n   - pg.7: \"Imagent\" --> \"ImageNet\"\n   - Please explain the green colour in Fig. 6.\n   - pg.8: \"changes of rolled graph graph\" --> \"changes of the rolled graph\"\n   - pg.8: \"a few epochs prediction model shows\" --> \"a few epochs, the prediction model shows\"\n   - pg.8: \"that needed for\" --> \"that were needed for\"\n   - pg.9: Limitations: please check different typos in that paragraph\n   - Please make references consistent; some of them are even missing the venue (e.g., Krizhevsky et al.) or page numbers. \n   - pg.12: 'results the poorest accuracy\" --> \"result the poorest accuracy\"",
            "summary_of_the_review": "The paper still needs some work to merit a publication. However, I would be willing the accept the paper if the authors do a careful revision and address all the comments raised by the reviewers. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper considers the problem of predicting test performance of a neural network model by using statistics about the parameter weights in relation to the network structure during the first few epochs of training. The authors propose two approaches, using degree centrality and eigenvector centrality, to compute a “signature” that summarizes the neural network’s state during a training epoch. They also propose a rolled-graph representation that uses fewer nodes to represent a convolutional neural network, thereby making the training and prediction process more efficient. Experimental evaluation shows proposed method \thaving similar predictive performance as unrolled representation, while being computationally faster. ",
            "main_review": "Technically the paper is sound and I enjoyed reading it. However, I have some concerns regarding the presentation and motivation of the problem considered. \n- The motivation for the problem is not clear to me. Sure, with this technique one could decide within a few epochs of starting training of a model, whether to continue or terminate training. However, to train such a predictor requires several rounds of training for the original task (under different hyperparameters) to already have been done. Why does one need to retrain for the original task is unclear to me. \n- One of the key claimed contributions of the paper is the rolled graph representation. However, it is not clear what is the difference between a rolled representation and an unrolled representation (i.e., section 3.1). E.g., the edge between v^i_k and v^j_l has weight norm(K(l,h_j,w_i,k)) but it’s unclear what the latter notation means. It would greatly help if the authors could explain (and justify) the differences better. \n- It seems bias parameters are not involved while summarizing the neural network state. Why is this the case. \n- Problem 1 in Section 3 needs clarification. The paper seeks to predict the accuracy of a new instance N_tst, but the accuracy of N_tst after how many rounds of training is not specified.  \n",
            "summary_of_the_review": "Technically sounds paper, but lacking in motivation and presentation. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The purpose of this research is to attempt to forecast a neural network's performance from early NN dynamics. The dynamics of the neural network are stored in a time-evolving graph. The summary of two node properties, the weighted degree, and the eigenvector centrality is extracted and utilized to train classification and regression algorithms. This methodology, when combined with the paper's suggested rolled graph representation for convolutional layers, results in faster prediction than the classic early stopping method. \nThe paper's primary contribution is that the suggested rolled graph model for convolutional layers improves time and space efficiency in comparison to the existing unrolled representation.",
            "main_review": "Strength: It appears as though the rolling graph representation is promising. The subject is novel and deserves more investigation. \n\nWeakness:\n - It's unclear why only degree and Eigen centrality are taken into account. There are other alternative measures of importance or centrality. \n- The proposed method is intuitive and lacks solid theoretical support.\n- The overview of node characteristics does not adequately reflect the structural evolution of large-scale NNs in the modern era (ResNet). \n- The neural networks empirically evaluated, including LeNet, AlexNet, and VGG, are somewhat out of date. It would be advantageous to consider some more recent NNs, such as ResNet. \n- To facilitate interpretation, node centralities are used to indicate the graph characteristic. Reintroducing them into SVM may not improve their interpretability in some way. \n- To make the results more understandable, the centralities can also be put into a more interpretable classification model, such as logistic regression or classification tree. \n- Baselines are omitted from the experiment.",
            "summary_of_the_review": "I recommend rejecting this article. Although predicting NN performance from the network structure and dynamics is an intriguing topic, it is not one that this research proposes. The method, as well as the experiment, are more about preliminary and experimental exploration. Apart from the rolled graph representation of the convolutional layers, there is only a little theoretical enhancement.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}