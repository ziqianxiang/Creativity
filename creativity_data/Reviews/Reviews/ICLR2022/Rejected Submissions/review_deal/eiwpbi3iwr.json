{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper received 2 marginally below and 1 marginally above ratings. We discussed the paper with the reviewers and there was broad consensus that 1) the paper lacked clarity; 2) multiple modeling choices were debatable (e.g., ordering or embedding of neurons and convolution over neurons!!) and not sufficiently justified (and these choices will critically impact the conclusions drawn from the analysis); 3) we were not convinced by the relevance of the synthetic data to reflect a meaningful biological process; 4) we did not see any meaningful knowledge gained for biology from this whole analysis. My recommendation is thus to reject this paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper uses CycleGAN to map neuronal activities of mice (as measured by Calcium traces) pre- and post-learning.\nThe main contributions are (1) empirical results of using CycleGAN to learn the pre- and post-learning mapping look promising. (2) using both attention mask (which is for gating residual concatenations) and Grad-CAM to help with interpretation. (3) sorting neurons with an autoencoder’s reconstruction error, essentially sorting them based on their importance.",
            "main_review": "Strength\n- Extensive ablation studies, although most are not in the main text but in the appendix.\n- Using an autoencoder to sort neurons without bias seem to work better than sorting them by firing rate.\n- Using paired synthetic data to show the effectiveness of applying CycleGAN. And for real data, cycled reconstruction and other distribution metrics are promising, interpretations from both attention masks and Grad-CAM comply well with experiment settings. \n\nWeakness\n- Figures are not explained clearly. What are 6-89 in the right columns of attention mask figures (like 3, 4, 5)?\n- The writing is not very effective: for example, the second to last paragraph in section 2.4 can be simplified to a much shorter one with the addition of an equation describing it. An equation, paired with the module figure, will also be easier to understand than this long paragraph.\n\nQuestion / suggestion\n- Is the model shared among all mice, or does each have its individual model? Namely, is this learned mapping more universal or more individual? \n- Formulation wise: self-attention can also be applied among different neurons (just like in graph attention networks), and this might eliminate the need for pre-sorting. Essentially disentangling spatial and temporal information, modeling the spatial relationship as a graph with a learned adjacency matrix. In this way, neurons will be permutation invariant/equivariant, and the sorting is not needed, and the whole model can be learned end to end. \n\nAnd lastly, it’s not a 9-page paper at all: there are too many places in the experiment section referring to appendix sections that **require** one to look into them for getting a full context. The same is true for the model architecture part. I feel I’m forced to read a 32-page paper…",
            "summary_of_the_review": "Empirically, applying CycleGAN to reveal the mapping of pre- and pos-learning neuronal activities shows good results! Although the architecture or method novelty is not significant, and there is some unclarity of the writing, it can be a good starting point for further explorations.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper presents a new method for learning the transformation in neural population activity that takes place during task learning. The method is based on CycleGAN, but includes additional modifications related to neural data and the manner in which it is collected. The paper also presents visual interrogations of the learned model to better understand details of the learning process.",
            "main_review": "strengths\n---------\nThe paper proposes a novel and creative analysis method for understanding learning-related transformations in neural activity; I am not aware of work like this in the neuroscience literature.\n\nInclusion of self-attention is a nice way get a better handle on these potentially complex transformations. Is there more that one can say about the masks extracted in Fig. 4?\n\nThe GradCAM localization maps are also very useful for understanding what the model learns; in particular, the \"positional attention maps\" in Fig. 5 are really cool. It would be neat to investigate these neurons/positions in more detail, especially if you could show this model uncovered some aspect of the data that would have been difficult to find with traditional methods.\n\n\nconcerns\n--------\nIntro: \"In other words, given the neural recordings of a novice animal, can we translate the neuronal activities that correspond to the animal with expertlevel performance, and vice versa?\" This is a super interesting question, and the answer this paper appears to give is \"yes\". However, I'm left scratching my head about what *exactly* one can learn from this translation. I'm not suggesting a new analysis (though ultimately the usefulness of this method will depend on whether or not it can uncover new insights/guide new experiments), but a more thorough discussion on how these translations can be used would make this a more compelling introduction.\n\n2.2: I found this section hard to follow; perhaps moving Fig. B.1 (or something similar) to the main text would help with this? Even more useful (but less general) would be an explanation of the CycleGAN in the context of the neural data. For example, \"Let X and Y be the neural activity before and after learning, respectively. The GAN-based framework consists of a generator G: X->Y that maps novice neural activity to expert neural activity; and a second generator F: Y->X that maps expert neural activity to novice neural activity...\" This would make it easier (for me at least) to have an intuitive understanding of what the different losses correspond to.\n\n2.3: Again, describing MAE(X, F(X)) etc would be a lot clearer in the context of the neural activity\n\n2.3.1: Why does this ordering process work? I understand that, in order to use 2D convolutions, there must be some non-random ordering to the cells, but it's a bit bizarre to me that reconstrutcion quality from an autoencoder would be meaningful in this way. Is it possible to motivate this choice better? Another useful baseline would be to just use 1D convolutions in time and remove the spatial structure. Of course this means you can no longer use architectures out of the box, but also removes a poorly understood aspect of the preprocessing.\n\n2.3.2: What is the motivation for this spatiotemporal transformation? While useful to show that the model can handle this, it seems fundamentally different from the types of transformations present in the neural data.\n\n2.4: There are a lot of details here that are important to document, but distract from the main point of the paper. Perhaps move most of this to supplemental and use the extra space for a model/process diagram?\n\n3.1: The raw MAE numbers are difficult to interpret as presented in the text. Maybe one part of table E.1 could be moved to the main text? Also, I think presenting Figure 2 first is a faster way to get an intuition for what the model is doing, and how well it is working.\n\n\nminor\n-----\ntypo, second paragraph in introduction: Prince et al exteneded the framework *to* work with...\n\ntable A2: day 4 -> day 1 rewards\n\n2.3: where do the splits 3000, 200, 200 come from? Is this the total number of segments? how did you arrive at this number, is this related to the stride of the sliding window? seems this would result in highly correlated data samples, is that an issue?\n\n3.2: Would be nice to see parts of Fig. F.1 in the main text; maybe show a single neuron, and present more in the supplemental",
            "summary_of_the_review": "The paper addresses an interesting neuroscience problem from a unique perspective; however, I am still unclear exactly what the method is learning, and how it can be used to gain additional insights into the data. My initial assessment is to not accept this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes to learn a mapping for neural activity in the mouse visual cortex: the mapping is from neural activity before learning to neural activity after learning, and this is achieved using CycleGAN. The paper also performs additional analysis to interpret the weights learned by the generator and discriminator networks, as well as assess the quality of the networks' reconstruction of the neural activity.",
            "main_review": "The approach mapping pre-learning neural activity to post-learning activity using GANs is interesting, as is the methodology to sort neurons based on an autoencoder reconstruction loss. It was also good to see the paper systematically exploring how to choose a loss function for training the GANs -- a non-trivial issue for GAN training in general, and not always addressed in GAN papers.\nHowever, there are some major concerns about the paper:\n1. The overall motivation of _why_ one would want to map pre-learning to post-learning neural activity was not clear. Although the introduction and discussion briefly discuss interpretability for neural learning, it was not clear how this analysis contributes to that.\n\n2. Using GradCAM maps to visualise \"regions of interest\" for the discriminator was interesting, but this analysis does not seem to lead to any deeper understanding about the neural activity. While the discriminators learn that the activity around the reward regions are critical to distinguishing pre- and post-learning activity (Figure 5), it is not clear why the generators don't do this. Moreover, it is possible that this effect would vanish, or other regions of interest might appear if the networks were conditioned on information about the stimulus or trials. It is also not clear how this analysis is generally applicable, or what insights can be gained if it were applied to neural data from a different task.\n\n3. Reordering the neurons in the data using an autoencoder reconstruction loss appears to be a critical preprocessing step in the training pipeline -- however, the choice of an autoencoder over other approaches to reordering are not clearly motivated. Although this does lead to better reconstruction of the neural data from the GANs, it appears to make the subsequent step with the CycleGAN redundant: if you can accurately reconstruct neural data from the autoencoder, then why train an additional set of adversarial networks to do the same thing again?\n\n4. It would be nice to have an estimate of the compute resources and time required to train all the networks in the pipeline (autoencoder, CycleGAN) and perform the post-hoc analysis with GradCAM, etc. In the light of doubts about motivation and benefits of the method, it would also be relevant to know how computationally expensive it is to implement.\n\n5. There was an overall lack of clarity, and particularly in the methods and results section:\n - all equations are inline and not numbered and therefore references to terms in the equation are hard to keep in mind while trying to understand section 2.2 and 2.3; \n - extensive details about architecture and training frequently detract from understanding what steps the training pipeline consist of (perhaps these should be moved to the appendix)\n- there was no explanation of how to interpret the GradCAM maps in Figures 4 and 5, or what the colours / numbers mean, and the explanation of their overlap with reward regions appeared to be handwaving. It would be nice to see the pre- and post-learning neural activity for precisely those neurons that the discriminator assigns attention to in Figure 4.\n- the description of the results was confusing, and many of the plots that the conclusions here rely on are in the supplementary section, making it hard for a reader to follow any reasoning based on these plots.\n\nMinor comments:\n1. Heatmaps in Figures 2 and 4 are hard to interpret without colourbars\n2. Neural activity in Figure 1 is barely visible due to the colour scheme\n3. The explanation for how plots in Figure 5 is generated appears only in the caption, with no elucidation in the text.\n4. There does not appear to be information of recording time per trial in the main paper\n",
            "summary_of_the_review": "The motivation for the methods presented in the paper are not clear, the conclusions are not very convincing and consequently, it is hard to judge the contributions of the paper. A lack of clarity in the methods and results section exacerbates this.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}