{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "After reading the reviews and the rebuttal I unfortunately feel the paper is not ready to be accepted. \n\nThe reasoning for this decision is as follows:\n* the empirical evaluation is somewhat weak in its current format, and even adding experiments going from BlockStacks to MNIST would have improved the results, or potentially other synthetically generated data. Or playing with which relation is used during the transfer phase. Something to give a bit more weight to the empirical section and help it connect better with the theoretical one\n * But maybe more importantly (and to some extend this is true for the formalism introduced as well), I think there needs to be a bit more context. After reading the reviews, I went and read the paper, and for example in results provided, it is not clearly explained what is the relationship between the proposed method and some of the baselines. I noticed that the related work section ended up in the appendix, which is fine, to the extent the main text can connect to the literature a bit. But while I agree that the introduction of the method seems good and clear, and this is a hard and important problem that lacks a proper framework and the proposal in the paper is quite interesting. It is also important to understand its relation to other frameworks, and to explain clearly what it tries to fix in other proposal. And to interpret the result, maybe justifying or providing some intuition of why the proposed model performs better. I think this is very crucial particularly for a topic that is still in a growing phase, which makes it harder to judge.\nI know in the appendix, the author mention domain adaptation which is also something that jumps in mind when looking at this architecture. However this point is not discussed or mentioned as much in the main paper.\n\nIn current form, while the paper reads well, one is left to trying to understand whether these results are significant. I think the work is definitely very interesting and I hope the authors will resubmit it with modification. I just feel in the current format it will not have the impact it should, because of a preserved weak experimental section and not a clear grounding in the literature, making readers unsure of the significance of the work."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The main motivation of this paper is the observation that once we humans have learned the meaning of a relation, we can apply it to different contexts and scenarios effortlessly. For instance, once we understand the meaning of a concept \"larger than\", we can apply this in many context such as integers, person lengths, building sizes, etc. The authors argue that it is interesting to study how we can build learning systems that similarly are able to transfers learned relations across domains.\n\nIn order to express relations, a language based on first-order logic is developed, and semantics is given to this language using an interpretation function, mapping relation symbols to the tuples of elements over which these relations hold. In order to facilitate learning these relations, the authors develop a quantitative account of the logic. They develop so-called \"soft structures\", which can essentially learn a symbolic structure over real-world domains. This learning is done using the Variational Auto-Encoder framework, where an encoder maps the real-world input (for instance, an image), to a latent space Z. The interpretation of relations over the real world data is then implemented by \"relation decoders\" (one decoder for each relation), which are belief functions assigning a number in (0, 1) to relations. In order to train such models, they define a measure on how well a soft structure support a symbolic structure, and they use this as a term in the loss function. They also provide a formal account of what it means for two soft structures to be \"coherent\", which intuitively mean that relations that apply to one domain (e.g., ordinality in numbers) also can be applied to another domain (e.g., ordinality in block sizes).\n\nThey authors then derive an efficient consistency loss, since the original one is intractable because it requires computing beliefs over all interpretations of the relations. They then propose a Dynamic Comparator relation decoder model, and a new learning task called \"Partial Relation Transfer learning\". They compare against several existing relation decoder models, and empirically show that their relation decoder retains coherence across domains, while achieving better transfer learning performance.",
            "main_review": "=== Strength ===\n* The paper is very well written and the organization is clear.\n* I find the way in which the authors develop a formal framework, and then provide a quantitative account for this in terms of soft structure, which are then used to train a Variational Auto-Encoder very appealing. I believe the proposed approach is advanced and brings together  insights from both logic and machine learning. Given the different approaches of these two fields, I find this impressive.\n* The topic is also interesting and relevant to AI.\n\n=== Weaknesses / Questions for authors ===\n1. \"Coherence\" seems to be an important topic of the paper. It is mentioned often, and Section 3.1 provide a formal definition of epsilon-coherence. However, in the empirical results this didn't seem to be mentioned anymore. It made me wonder: what is the use of the formal definitions in Section 3.1? I was expected this to be used to evaluate the models. Maybe it did, but then it wasn't clear to me, so in any case I think the relation between the experiments and Section 3.1 can be made clearer.\n\n2. I found the explanation of the newly proposed relation decoder the \"Dynamic Comparator\" too short. It was difficult for me to understand what it did. More importantly: it seems to outperform all other models very convincingly, but I could not find any discussion on why you believe this is the case. So I felt the empirical results deserve more detailed reflection. Perhaps an ablation study would be interesting?\n\n3. The empirical studies by itself are also somewhat one-sided (MNIST --> BlockStack). Did you also try the other direction? I.e., train on the BlockStack domain and then evaluate on MNIST? More generally, I was wondering whether the empirical setup is actually similar to how we humans learn. Can we really learn a relation such as \"larger than\" from one domain, and can we directly apply it to another? This is actually not directly clear to me. I can imagine we learn a relation in multiple domains, after which we are able to generalize to new domains.\n\n4. All appendices seem to be missing from the PDF.\n\n=== Detailed comments for improving the paper ===\n\nSection 2:\n- I liked the formalisation and I think it was well presented, also the example was helpful.\n\nSection 3:\n- \"Z is a latent variable, itself draw from marginal p_z\" --> \"draw\" should be \"drawn\". Also, I believe p_z is a prior instead of a marginal.\n- In Definition 3: $\\psi_S(S)$ is undefined, I supposed it means $\\psi_S(S) = \\{\\psi_S(s) | s \\in S\\}$, i.e. all encoding of S?\n- It could be helpful to add a sentence explaining the measure on substructures, e.g., saying that this value will be close to 1 if the soft-structure is similar to the structure.\n- \"It is straightforward to show that $\\sum_{S_\\sigma}...= 1$\" --> what are we summing over here? All possible interpretations of \\sigma use S? Please clarify this.\n- \"If we have a theory \\Tau over \\sigma\" --> I don't get this, isn't a theory defined over the language which contains the relations?\n\nSection 4:\n- Overall I found this section quite difficult to follow and I wasn't sure the details were relevant (but I could be wrong here). You could consider removing some technical details here (and moving them to the appendix), so that you have more space for possible additional experiments.\n- The grounding $s_{ijk}$ is used but only in the next paragraph it is explained what it means, so please define it beforehand.\n- It is not explained what an \"atomic subformula\" is.\n\nSection 5:\n- \"given a domain images\" --> remove \"a\"\n- \"latent space .\" --> remove space\n- The explanation on the DC is extremely dense, and I'd like to understand better why you developed it this way and why you think it works well.\n\nSection 8:\n- \"ordinaliety\" --> ordinality",
            "summary_of_the_review": "The paper addresses an important element of human learning, namely that we are able to apply our understanding of learned relations to new domains. The paper is very well written and brings together insights from logic and deep learning in an innovative way. The main weakness is that the empirical results felt somewhat underdeveloped, so I would recommend swapping out some of the technical details (e..g, Section 4) for more analysis on the empirical studies (see main review for more details).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work introduces a more general definition of structures namely soft structures that can be used to learn structure over richer domains in a data-driven manner. Further, they introduce suitable definitions of coherence and consistency for the proposed soft structures. Next, the paper proposes a neural architecture that is essentially, jointly learning relation encodings jointly with representations for set elements. The key argument of the paper is that transfer is to be expected across shared relations despite their overloaded usage across domains — for example, greater than (GE) can have completely different interpretations in the source / target domains. ",
            "main_review": "Strengths:\n- The paper makes multiple simple yet interesting contributions. The definition of soft-structure is useful and intuitive. \n- The experimental results, at least with the DC model, are consistent with the hypothesis of the work. \n- The paper is generally well-written and is easy to follow. \nWeaknesses: \n- While intuitive and backed by experimental results, the experiments feel nascent and it’s not clear whether the same trends will hold for more complex datasets / relations. \n\nMinor comments:\n- Repetition of background / definition can be cut down. \n    - And perhaps, the space can be used to make the definitions more concrete with example\n- Fix footnote 2",
            "summary_of_the_review": "The paper introduces soft structures along with allied definitions. Further, it introduces a neural architecture that jointly learns element and relation representations -- the experimental results do back the hypothesis of the paper. However, the experiments have a limited scope and therefore, I am inclined but not very strongly towards acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work presents a new neural network model that can learn some symbolic relations in a specifically designed neural network module, which can later generalize to other unseen data. The proposed method was evaluated on datasets MNIST and BlockStacks to demonstrate its potentials. ",
            "main_review": "My big concern about this work is *probably* a writing issue. Specifically, I had significant trouble identifying the relationship between sections 2-4 and section 5. The theory, definition, and discussion in sections 2 - 4 are interesting and I enjoyed reading it. But it seems to be disconnected from section 5. When I read it again, I found out that it's actually much easier to read by directly starting from section 5. To my understanding, the neural model proposed in this work is simply learning a tied latent representation, where the latent representations are constrained by some distance-based similarity measurement. To better achieve the goal of representation learning, this work further suggests using $\\beta$-VAE for disentangled representations. \n\nTo make sure my understanding is correct, I would like to ask a few questions\n\n- what is the main contribution of sections 2 - 4? \n- how the theoretical description in these sections can be connected to the neural model proposed in section 5?\n- on the other hand, if there is a connection, to what extent the model proposed in section 5 can realize those concepts discussed. For example, how to make sure an $\\epsilon$-consistency of sub-structure in the model? \n\nSome additional questions and comments\n\n- There is a missing reference in the footnotes on page 5\n- It would be great to report the numbers in figure 2, instead of using bar plots. A similar suggestion also applies to figure 3.\n- Furthermore, in figure 2, if my observation is correct, the proposed model performs much better on the out-of-domain data (nearly 100% accuracy on the BlockStacks data) than on the in-domain dataset (MNIST), how should we understand this difference? ",
            "summary_of_the_review": "The major concern is the disconnection between the theory and model realization, which led to the trouble of identifying the main contribution of this work. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a loss based on theory for the relation prediction problem, using the sentence of the relationship as the supervision. The paper designs an relation transfer learning experiment. By supervising one relation, other relations can be transferred.",
            "main_review": "strengths\n1. The thesis theoretically and rigorously expressed the relation prediction problem in the framework of universal algebra, which is inspiring. \n2. This paper proposes a loss based on theory for the relation prediction problem, using the sentence of the relationship as the supervision. This loss links the different relationships together and is a more general and universal form.\n3. The paper designs an relation transfer learning experiment. By supervising one relation, other relations can be transferred. It seems interesting.\n\nWeaknesses\n1. What are the benefits of using the sentences in the theorem to train relation prediction, compared to independent training of each relation? From Equation 8, the loss of a sentence seems to be the product of the loss of each relation in the sentence. So why not directly train the loss of each relation independently?\n2. What is the computational complexity of the loss function? For example, isGreater can be represented by the conjunction of several isSuccessors, but it is not feasible to list all these sentences when the domain is larger.\n3. About Definition of Equation 9: I don’t understand why we need to calculate expectation over s. The two terms in the formula seem to have been summed over s, and have nothing to do with s.\n4. About Experimental setting: What is the purpose of comparing DC with other relation representation models? The paper lacks an explanation for the motivation of DC. Why is DC better?\n5. The experiment aims to show that by supervising one relation, other relations can be transferred. The reason to use isSuccessor is “Our system of relations can all be expressed in terms of isSuccessor”. What if using relation other than isSuccessor for transferring?\n",
            "summary_of_the_review": "First,  the motivation of the work is not clear.  Second, the proposed method is straightforward and short of novelty. Finally, the task presented in the paper seems trivial.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}