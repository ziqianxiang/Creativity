{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper studies the loss landscape of domain adversarial neural networks for domain adaptation. First, the authors show that smooth minima with respect to adversarial loss leads to sub-optimal generalization on the target domain. Then, they suggest to enforce smoothness only with respect to the task loss. 3 reviewers are on negative sides, and 1 reviewer is on a positive side. All negative reviewers interacted with authors in the discussion period. After the discussion period, even the positive reviewer agreed negative comments of other reviewers and declined to champion this paper.  \n\nAC thinks that this is a borderline paper; the proposed claims (both theoretic and empirical) are interesting and there is no critical weakness of this paper. However, the results are not super excited, as evidenced by 3 negative reviewers. In particular, AC agrees with negative comments of reviewers on limited novelty and lack of strong theoretical motivation for the proposed scheme. AC also thinks the performance improvements in experiments are not that significant. Furthermore, the problem scope is narrow, i.e., the authors study a certain property (smoothness) of a special algorithm (adversarial training) for domain adaptation that is a particular way for domain generalization. Hence, the impact to the community can be not significant as well. Considering all aspects, AC is a bit toward to suggesting rejection."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This work studies the loss landscape of domain adversarial neural networks for domain adaptation. The authors claim that similarly to the iid setting, smooth minima might yield better generalization on the unsupervised domain adaptation framework via domain adversarial training but in case smoothness is enforced only with respect to the task loss. Experiments on the OfficeHome dataset indicated this hypothesis might be true. The authors then proposed to apply a previously proposed approach to enforce smoothness (Sharpness Aware Minimization), so that only smoothness with respect to the task loss would be enforced. Moreover, a theorem showing that the non-smooth domain discrepancy estimation is better than the smoother counterpart was introduced, along with a generalization bound for the risk on the target domain in terms of the smooth risk on the source domain. Finally, the authors showed that the proposed approach, SDAT, improved the performance on target domains of three domain adaptation datasets in comparison to the considered baselines. Further experiments showed that SDAT performed better than other smoothing techniques, as well as yields improved robustness to label noise in comparison to not enforcing smooth minima. ",
            "main_review": "The main contribution of this work is to propose applying Sharpness Aware Minimization (SAM) to smooth only the task loss term of domain adversarial training. From an empirical standpoint the paper is interesting and points to potentially relevant investigation directions, however, I have concerns regarding the significance of this study since there is no clear motivation as to why previous findings on the iid setting showing that smoother minima generalize better would transfer to the unsupervised domain adaptation setting. Moreover, the empirical validation of the proposed approach is not extensive enough to provide sufficient evidence for the soundness of the reported findings. In the following, I provide more details about my concerns along with questions and suggestions.\n\n- Motivation:\n  - Although the authors (to some extent) empirically show that SDAT can improve the performance on the target domain on the considered cases, there is no justification on why one would expect better out-of-distribution generalization for smoother minimum. Would the authors clarify that? More specifically, what is the motivation/context for investigating Conjecture 1? As of now, it seems to me that this work is extending an analysis for the iid setting to unsupervised domain adaptation without a clear reason. \n  - It is not clear to me why the authors decided to provide results that rely on Acuna et al. 2021 rather than consider the classic results from Ben-David et al. 2010. There is no clear motivation for this choice in the manuscript and I believe the authors should better justify this choice.\n\n\n- Results:\n  - The relevance of both theoretical results are not clear to me. Theorem 2, for example, requires unrealistic assumptions such as L-smoothness. Theorem 3, in turn, states a bound that is looser than the known results in the literature and which are already vacuous, so it is not clear to me what is the relevance of this result in the context of unsupervised domain adaptation.\n  - It is hard to assess the relevance of the reported results as no measures of statistical significance were reported. More specifically, the authors should include in the paper information regarding the number of runs considered for each experiment and report at least the average and standard deviation for all the quantities reported. Otherwise, I don’t think it is possible to rely on the current experimental set-up to support the claims of this contribution.\n  - Please clarify how the 50% partition of the source data was selected to estimate the Hessian for the three compared methods and if the same partition was used for all, otherwise results on Figure 3 could be noisy.\n  - SDAT requires an extra gradient step in order to estimate the smoothing penalty in Eq. 7. How does this affect the computational cost of SDAT and how SDAT stands in comparison with the considered baselines?\n\n\n- Other concerns/questions:\n  - Some statements of the manuscript are not rigorous and require rephrasing:\n     - Abstract: “combination of classification and adversarial terms”. In the considered setting, the adversarial term of the loss also stems from a classification task (domain discrimination), therefore, it is confusing to the denominate both component losses in such a way. I suggest referring to the loss term related to classifying labels regarding a specific task as task loss.\n     - Section 3.1: please specify what “works well on the dataset” means (i.e. low risk on the target distribution).\n     - Theorems 1/3: please precisely define what is the ideal classifier $h^*$.\n     - Section 4: “where we find that in contrast to supervised learning” notice that, in practice, unsupervised domain adaptation also corresponds to supervised learning since all losses require either task or domain labels, so it shouldn’t be referred to as a setting opposed to supervised learning.\n  - Table 1 caption: what exactly “sophisticated” means here? \n\n\n\n- Related work:\n  - Foundational literature on domain adaptation is missing in the related work section, for example, Ben-David et al. (2007) and Long et al. (2016). \n\nBen-David et al., Analysis of representations for domain adaptation, 2007.\nLong et al., Unsupervised domain adaptation with residual transfer networks, 2016.\n",
            "summary_of_the_review": "This work studies the loss landscape of adversarial domain adaptation in terms of the smoothness of the minima. Despite showing somewhat empirically promising results, I found this work lacks a solid motivation for the presented analysis (i.e. why should we expect that strategies that improve generalization in the iid case would help in a non-iid setting as well?) and a sound empirical validation of the proposed approach. Moreover, the relevance of the presented generalization bound is also unclear to me at this point. All in all, I think this contribution seems promising but due to the concerns I raised in my review, I believe it is not yet ready for publication. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper discussed a correlation of smoothness on **classification loss** and **generalization ability on target domain** and further develop a method to enhance such smoothness to achieve better performance on DA tasks. To do so, it adopted the losses based on Sharpness Aware Minimization, a minmax game of finding a smoother neighborhood of $\\theta$ , by computing first order deviation. Empirical studies are implemented to verify the theory and show the soundness of the proposed method.",
            "main_review": "## Strong points\n\n1. The paper takes issue with an interesting point of the reason for SGD optimizer outperforming Adam on DA tasks for reaching a smoother minima, develops it theoretically, and proposed a novel loss function focusing on smoothing classifier loss to improve generalization on target domain.\n\n2. It fully discussed why we should not apply the smoothing method **on the discrepancy term**, and verify the theory empirically through experiment, further developing smooth theory with regard to **adversarial objectives.**\n\n## Weak points\n\n1. The method for smoothing ERM is more directly adopted from SAM rather than a novel idea, and the relation **between** smoothness **and** better generalization has also been discussed by previous papers (SWAD), therefore renders this paper not insightful enough. \n\n2. The proposed smoothing method w.r.t discrepancy term tend to \"lead to a suboptimal solution\", therefore not significantly helpful when tackling DA tasks (and I think it is hard to interpret). What actually makes such difference on the finally result is still, smoothness on ERM term.",
            "summary_of_the_review": "Overall, the author has well established a positive correlation between smoothness of classification loss and generalization capability on target domain, and a negative correlation between adversarial counterparts. The method of acquiring a flat minima also brings promising results on multiple DA classification and detection datasets. However, as I can see the experimental studies of the proposed smoothing method are well-designed and theories are rigorously proved, I am not completely convinced by the novelty of the work. Hope the author can make further analysis and explanation.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces a smoothness penalty for domain adversarial training. The penalty encourages smoothness on the parameter space of a discriminative model. This smoothness penalty is motivated by results in Sharpness Aware Minimization. Results are included on the popular DA datasets such as Office-home and VisDA, where superior results are shown. Ablation experiments show how different smoothness penalties change the observed improvements. ",
            "main_review": "Strengths:\n\n  * Theoretical foundation for smoothness\n  * Results sections include improvements on both image classification and object detection. \n  * Ablation experiments provide insights to the effect of a smoothness parameter. \n\nWeaknesses:\n\n  * Figure 4: not clear why and how the optimum for rho differs per dataset. Does this depend on the dataset size or diversity of objects? Moreover, the vanilla ResNets have a batchnorm layer, so it is not clear why figure 4a has such a sharp optimum at all. \n* What is the final recommendation of the paper? If the paper recommends using smoothness penalties, then what are the limits? For example, how does the smoothness of the classifier (focus of this study) interplay with smoothness of the domain discriminator? I could imagine that when the discriminator has sharp decision boundaries, then enforcing smoothness on the classifier would be less useful. (But in practise people employ many tricks to get a smooth discriminator [1][2]).\n* Table 1: most improvements occur when combining SDAT with MCC. This combination is not well explained in the paper. What makes these approaches complementary and why are improvements small (or non-existent) for vanilla CDAN?\n* Theorem 2: I don’t see how this theorem relates to the point of the paper. From equation 11 it seems smoothness is applied to h_\\theta. \n\n[1] Gulrajani et al. \"Improved training of wasserstein gans.\" arXiv 2017.\n\n[2] Arjovsky et al. \"Towards principled methods for training generative adversarial networks.\" arXiv 2017.\n\n[3] Miyato et al. \"Spectral normalization for generative adversarial networks.\" arXiv 2018.\n",
            "summary_of_the_review": "Paper with theoretical motivation and results on both classification and object detection. However, the limitations of the proposed method are not clear. When would smoothness not be useful and how do the improvements depend on the other tricks for training Domain Adaptation models. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper analyzes the role of smoothness in domain adversarial training (DAT). The main insight of the paper is that smoother minima of the classification loss improve generalization in the target domain. This explains why SGD is usually preferred over Adam when optimizing the training objective of DAT. To further improve the generalization performance by leveraging this phenomenon the author(s) introduce(s) smooth domain adversarial training (SDAT) for classification and object detection. SDAT applies sharpness aware minimization (SAM) to find smoother minimia of the classification loss used during DAT.",
            "main_review": "STRENGTHS:\n- The paper is very well-written and introduces all used concepts appropriately. This makes the paper easy to understand even for readers that are not familiar with domain adaption.\n- The motivational experiments performed in Section 4 (Analysis of Smoothness) are well-explained and convincing.\n- The author(s) provide(s) a generalization bound (Theorem 2) for their proposed method which justifies it from a theoretical perspective.\n- The experimental evaluation is very extensive: the method is evaluated on three different domain adaption datasets for classification (Office-Home, VisDA-2017, and DomainNet) and compared with different existing domain adaption methods. It is shown that SDAT can be combined with the existing methods CDAN and CDAN + MCC to increase generalization performance.\n- Furthermore, improved performance on domain adaption datasets for object detection is reported.\n- Additional experiments show that SDAT also increases the robustness to label noise and that SAM outperforms other smoothing techniques. \n\nWEAKNESSES:\n- I see not major issues with this submission.\n\nMINOR REMAKS:\n- Some references are not correctly capitalized (e.g., \"Lower bounds for finding stationary points i\" or \"Faster r-cnn\") also conference names are sometimes capitalized and sometimes not.",
            "summary_of_the_review": "Overall, I would highly recommend to accept this submission to ICLR 2022. The theoretical and empirical results are convincing and the paper is of high quality.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}