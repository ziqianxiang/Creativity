{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "Paper studies if DNNs are modular and proposes statistical methods to quantify modularity.\ncluster the neurons of the network using spectral clustering applied to a graph that is weighted by similarity between the neurons.\n\nWhile the reviewers find the question of modularity relevant, they raise the issue that the results are inconclusive regarding the main stated contribution of the paper (i.e., if modularity is appropriately measured). After discussion, some concerns are answered. However, the main problem of inconclusive results stands. Therefore, this borderline paper is rejected."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper seeks to answer whether modern DNNs are modular and proposes statistical methods to quantify modularity. In this study, DNNs are described as modular to the extent they agree with 2 prototypical conditions of modularity, namely importance (which is mainly captured by the drop in accuracy after removing a candidate module) and coherence (which would measure the extent to which neurons in a single module are .activated by similar features). These proxies for modularity, importance (with respect to task performance) and coherence (degree of specialization), are computed based on two well-known DNN interpretability techniques, namely lesions and feature visualization.  ",
            "main_review": "Strengths: \n1.\tThe choice of metrics for modularity seems well-motivated and proposal to quantify the two proxies is seemingly a great strategy. \n2.\tThe paper is very well-written and all the analyses and experiments along with different choices seem reasonable and interesting. \n3.\tThe question of detecting modularity is a very interesting one \n\n \nCritiques: \n1. The paper claims they aim to detect/quantify modularity in DNNs but the proposed technique only seems to address whether spectral clustering-based partitioning can identify modular subsets (to the extent they are `more modular’ than random groups of neurons). The broader question of whether a DNN is modular or not or how its modularity compares against other networks remains untouched in this paper. \n\n2. The results seem more about clusterability than modularity. For instance, an important conclusion I draw from the paper is that the clustering scheme is useful to identify subsets of neurons that jointly serve as a coherent and important subset for a particular task. The extent of modularity quantified by the partitioning is only compared against random groups of neurons. This seems like a very crude baseline and it would have been nice to know if the metrics can be used to compare modularity across networks. \n\n3. Modularity is defined on top of clusterability – but what if the partitioning itself is imperfect. Clusters define candidate modules but what additional value does functional modularity analyses provide in this setting?  \n\n4. In the feature visualization experiment, the value of the maximization objective (the ‘score’) might be highly sensitive to the gradient optimization technique – are the authors doing unconstrained optimization in the input space? Importantly, the features highlighted by the visualization technique do not reveal anything interpretable and the visualizations for the true subclusters and random groups of neurons look very similar in all the datasets the authors tested (MNIST, CIFAR10 or ImageNet). Given this, the merits of using partitioning to analyze/interpret DNNs remains unclear.  \n\n",
            "summary_of_the_review": "While I enjoyed reading the paper and liked how the authors operationalized modularity, I don't think the paper is ready for publication yet as the results and experiment don't seem to add value or strongly support the practical utility of the proposed metrics and means to quantify them in studying DNNs.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This work aims to quantitatively evaluate modularity in neural networks (although, as detailed below, I am not sure this is what it ends up doing). To this end, the authors propose to cluster the neurons of the network using spectral clustering applied to a graph that is weighted by similarity between the neurons. They consider two approaches for defining similarity - either via similar responses to inputs (using Spearman or Pearson correlation) or by taking into account the weighted connections (leveraging the learned network weights) between them. There are some technical details regarding the division to layers, exact implementation, and especially the consideration of convolutional architectures (where certain neurons are grouped together along channels), which I will not refer to much here for brevity, but suffices to say that these are all well described in the manuscript and make sense without much need for justification. Once the clusters (or \"subclusters\" when divided to layers) are obtained, they are evaluated empirically to related them to the network's task. This portion is mostly based on image classification tasks, so clusters are evaluated based on their impact on classification accuracy, their importance in identifying each class, or coherence of visual features captured by them. The results are somewhat inconclusive (more details below), but it is appreciable that the authors do acknowledge this in a well balanced discussion section.",
            "main_review": "The paper is well written, and generally fair in reporting its findings without much exaggeration. The method proposed here is straightforward (perhaps naïve) on one hand, using rather standard tools for building a neuron similarity graph and clustering it, but on the other hand simplicity is not necessarily a bad thing. The results are intriguing and raise interesting questions, which the authors properly discuss and propose some future work for in Section 5. It is clear that the neuron subclusters here do isolate some encoded information in a way that differs from random clustering, and further it seems this property is robust to the design choices in the proposed procedure. \n\nHowever, I am not convinced this method really exposes any modularity in neural networks, which is the weakest point of this work and in some sense it does not fulfil its declared goal. The authors do acknowledge some limitations already in their discussion - stating there that it does not provide support for modular design. However, while they claim these results \"measure modularity\", it is unclear to me whether this is the case, or are they merely measuring redundancy in the network. Indeed, it is typically desired to have multiple pathways in the network encode similar information, as encouraged by dropout and leveraged in network pruning or sparsification (for example, based on the lottery ticket hypothesis). The authors show here that via their partitioning approach, they are able to isolate, and in the lesion case remove, all the neurons that relate to a certain aspect. When compared to random partitioning, the redundancy of information is clearly seen, as random partitions remains more robust or diverse, probably due to redundant information being encoded across many partitions. It is not clear how to go from this evidence of redundancy to saying the network is modular, which would imply that certain subnetworks can serve as individual \"modules\" that can operate in isolation (to some extent). To establish such evidence, one would at least expect to see some difference between the correlation-based construction (which clearly groups neurons together based on encoding similar information - i.e., providing redundancy) and the connectivity-based construction, which one would hope would provide some submodules of the network. The results on the differences between these approaches (or the global versus local methods) are inconclusive, and in any case there is no attempt here to extract clear modules from the network. ",
            "summary_of_the_review": "The approach provided in this work is nice (albeit somewhat simple or even straightforward) and provides a way to cluster together neurons that have some redundancy in their captured information, and therefore distil important information pathways or features in the network. The results are intriguing, but in my opinion do not lead to a clear conclusion, and I don't see how to leverage them towards better understanding of neural networks, their properties, or their design. As such, the impact and significance of this work are rather minor. Most importantly, while the paper claims to establish some quantitative approach to measure modularity in neural networks, the results mostly establish the redundancy of information without relating it in a clear way to modularity per se. Therefore, I believe this work is unfortunately slightly below the bar for acceptance to ICLR.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this work the authors provide an empirical definition of 'modularity' of trained deep networks. Their definition is ‘automated’ in the sense that is does not require any human identification and evaluation of the specific modules.\n\nThe proposed definition consists in the following steps.\n\n1) Construct an undirected graph from the nodes and weights of the trained-network\n\n2) Divide the graph in groups using a spectral clustering algorithm\n\n3)  Define ‘subclusters’ as the sets of all nodes that are in the same cluster and in the same layer\n\n4) For each subcluster compute an *importance* score and a *coherence* score\n\n5) If the sub-clusters are more important and coherent than randomly defined groups of nodes of the same size than the network is said to be ‘modular’.\n\nThe *importance* of a group of nodes is computed as the loss of accuracy that results from masking to zero that group of nodes. The greater the loss of accuracy, the greater the importance of the group.\n\nThe *coherence* of a group of nodes is computed as the maximum magnitude of the pre-activation weights of the group that is achievable with a single image.\n\nBy numerical testing, the authors find that it is indeed possible to find groups of nodes that are more important and coherent than random in a statistically significant way for different architectures.\n",
            "main_review": "The aim of this work is important and surely relevant. I find it likely that some degree of modularity exists in networks and that it is possible to empirically detect their existence.\n\nHowever I have some doubts on the methodology that is proposed in this paper.\n\n1) It is not immediately obvious that the 5 steps described above really provide a good indication of modularity.  As a counter example, imagine to train a network with most nodes masked to zero. In this scenario, at the end of training only a small group of nodes will be ‘active’ (connected by nonzero weights), and such group of nodes will be hugely more ‘important’ and ‘coherent’ than random sets of nodes, but this is *not* an indication of the network modularity. What is the authors’ opinion on this?\n\n2) Connected to the first point, I see an issue in the high level of arbitrariness in the definition of modularity given. In particular, for the scheme one needs to choose: the graph construction algorithm, the clustering algorithm and its parameters and the definition of importance and coherence scores. All these choices will give rise to *different modules* and I see no way in which one should prefer one scheme with respect to the other. \n\n3) I think that all the heuristic choices described in point 2 make the method difficult to reproduce and to extend, and hence there is a risk for this work to become an isolated publication generating little attention and very few further investigations.  \n\n3) What is the value in knowing that some 'modules' exist if we can never discover what these modules do in practice? The article would be hugely more impactful if the authors could provide an indication of the functioning of the modules detected. I would appreciate if the author could comment (both here and in the paper) on whether this could be done at all and, in case, on the possible ways in which it could be done.\n\n",
            "summary_of_the_review": "Detecting modularity in networks is surely an important and timely problem in deep learning. The authors proposal to address it contains some interesting elements of novelty, but I am uncertain that the method really measures modularity and I believe that the arbitrariness and the many heuristics involved in the definition of modularity make the methodology difficult to trust, reproduce, or extend. \n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper uses graph-based clustering methods to identify the humanly comprehensible modularities in the neural network. They thoroughly discussed how they construct the graph of neurons and carry out the clustering. They also proposed the fisher bates p-value for testing the significance of identified modules.",
            "main_review": "Strengths:\n1. This paper is very well written and easy to follow. The methods and results are convincing and clear. \n2. This paper carefully designed gratification methods for neural network neurons and proposed plausible methods for not only global clusters and also local clusters.\n3. They also provide a statistical method to identify the significant modules automatically. Though the power is very limited. \n\nSome comments (not exactly weakness):\n1. The global gratification is very interesting. I am wondering if the author looked into the special cases of clustering. For example, is there any chance that the global cluster is from disconnected layers? Specifically, a cluster that has neurons from layer 1 and layer 3 but does not have layer 2  neurons.\n2. What is the purpose of local clustering? Why the clustering number of local clustering has to be the same as the global clustering. And how to explain the discrepancy between local clustering and global clustering.\n3. The overall gratification method is somewhat heuristic. And I assume that is the reason why the p-value does not work. Because the gratification did not capture the very \"true\" connections of each neuron. But identifying such a \"true\" connection will be very difficult. I was wondering could the author consider using the unit interference of each neuron and test the impact of other neurons. And using the impact to reflect the connections of the neurons.\n4. Does the identified modules can be taken advantage of to train the neuron network in some way. Links to lottery tickets?\n5. Did the author consider other graph clustering methods? Like Louvain community detection, hierarchical clustering?   \n\n\n\n",
            "summary_of_the_review": "A good paper to explore the explainability of neuron networks with graph clustering methods. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}