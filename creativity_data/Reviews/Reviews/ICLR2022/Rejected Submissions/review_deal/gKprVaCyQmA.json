{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "As the reviewers say, the subject matter of this paper is important, and of interest to the ICLR audience (I discount tzHo's suggestion that the paper is more suited to other venues).\n\nHowever, there are three primary reasons this paper should not be published as is:\n1. A theoretical paper *must* be precise, accurate, and clear. \n  The reviewers universally consider the notation ambiguous, and the theorem unproved because of this ambiguity.\n 2. The leap from solving a series of tasks optimally to having solved the composition optimally is indeed poorly argued in the paper, and is not resolved by the discussion.\n 3. I would also strongly recommend showing a less trivial example.  It does not need to be \"real world\", but it should address numerically the specific doubt of BuW: the relationship of OTE of the composed model to OTE of the subtask models.\n\nIn summary: TaFL may be true, but this paper does not show it to be true; or conversely, TaFL may be false, in which case publishing this paper would be a grave error.  The authors should use the reviewers reports to clarify and strengthen the argument.  This does include showing numerical results, because inspection of the code generating such results can often aid reviewers and readers in judging the truth of the theoretical claims, and in finding subtle missteps in the derivations."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper is going beyond the No free lunch theorem and tries to answer the question: \"Is it possible to reorder tasks so that I can learn them better?\" The paper claims that there is an optimal sequence of task training, but it doesn't provide an algorithm for finding it. There are no real-world or nontrivial synthetic data experiments. One way of understanding the question of the paper is the following example: \nConsider a transformer network. We know empirically that training a task that predicts the next word and then a machine translation gives good results. Is that the optimal order of training these tasks?",
            "main_review": "The paper is not well written and the mathematical notation in the expression of the theorem Is very poor and there are definitions that are missing. For example, the \\theta sometimes appears only with a subscript index and sometimes with a subscript and superscript. Also the \"f(:\\theta)\" is also confusing. What is the purpose of the colon here? It is also unclear whether \\theta is a vector or a scalar. Also in equation 3  n,m,k are undefined. At last, the term serial tasks is probably not correct. task sequence would have been more appropriate.\nGiven the above problems in the notation, I wasn't able to follow the proof. I also wanted to criticize the approach to the problem which seems very abstract, very theoretical, and most likely does not seem to be useful. There are other approaches that although answer the same problem in a more practical manner. The recent paper \"Efficiently Identifying Task Groupings for Multi-Task Learning\" https://arxiv.org/pdf/2109.04617.pdf is very closely related to the problem posed here and provides a practical algorithm for solving the problem. There is a difference between the two problems. The paper under review claims that there is a sequence while the other paper trains them together. \n\nAt last, one of the things that the authors should have used in their paper is a connection to catastrophic forgetting. Catastrophic forgetting is a phenomenon that is caused by the sequential learning of tasks. It would have been nice to show how this is addressed by TAFL.\n",
            "summary_of_the_review": "I don't claim to be an expert in ML theory, but given the simplicity of the concepts used in the proof, it should have been easy to follow. This is not the case. An opinion from a theory expert should be more appropriate. It is my impression that the reviewers that would be capable of giving a clear opinion are probably not at ICLR. This paper should be submitted to venues like COLT or SODA. The paper needs more work and more clarity in the notation. My recommendation is to reject the paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper addresses an important topic in the theory of learning algorithms which regards the limits of learning algorithms. If correct, the theorem provided in the paper could have a strong theoretical impact on the field of machine learning and maybe also practical applications. ",
            "main_review": "After reading the manuscript I was left with lots of questions that undermined my capacity to evaluate its correctness and impact. I list the main questions below in the hope that each question provides an opportunity for the authors to improve the readability and notation of the paper:\n\n- Is the theorem concerned only with learning algorithms or algorithms with memory or is it also applicable to general optimization methods? Please state more clearly the differences in scope between TAFL and NFL.\n- In ${f_a (: \\theta_a )|\\theta_a ∈ R}$ is $\\theta_a$ a real number, a vector? If so, use the adequate symbol for the real set.\n- In $y = g_a (\\sum_i x^i \\theta_a^i + \\theta_a^b )$, why the superscript $b$ in $\\theta^b_a$? Is it connected with $f_b$? If so, please, explain how and why this is necessary.\n- In Eq. 2, $E_{ote}(L|d, f)$ is defined with $\\bf d$ sampled from $f$, since $d_i$ ∈ $f$ but in TAFL Theorem we have  $E_{ote}(L|d_a, f_b)$. How can $d_a$ be sampled from $f_b$? And how evaluating the performance of $L_a$ in $d_a^n$ can say anything about the performance of $L_b$ in $d_b^*$? This connection is not clear to me even after reading the proof provided.\n- In Eq 3, how $y_0$ can be equal to $x$? Does that imply certain assumptions about the mapping $f:x->y$? If so, what assumption? Similarly, why $f_b (x : \\theta_b^∗ ) = y_n$? What are the assumptions about $d$? Do $x$ and $y$ come from the same domain? For instance, in a binary classification, how can $x$ and $y$ domains match? What about $d_a$ and $d_b$? \n- What does $n$, $m$ and $k$ mean in Eq. 3?\n- In Eq. 5, what assumptions allow the composition of $f_s$ with $f_i$ and $f_j$? In other words, why can $(f_i, f_j)$ replace $x$?\n- In Section 2 $h$ is used to represent the learned model. In Section 4 $m$ is used. Is there a reason for the change? What is the difference between bold *$m$* and $m$?\n\nImprove presentation:\n- Please, review the sentence: “we can find a **serial** of tasks, represen**ting** by a **serial** of sets of samples”.  \"series of tasks\" or \"sequence of tasks\" would fit better in my opinion. Overall, the paper could benefit from an English revision.\n- Citations in the text should be fixed to use outer parentheses when the author’s names do not belong to the sentence.\n- Fix and standardize reference to textual elements: section.5 -> Section 5.\n",
            "summary_of_the_review": "Considering the difficulty to understand the proof presented in the article, I do not think the paper is ready to be accepted in its present form. I can reconsider this position if the needed clarifications and improvements are provided.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper provides a new optimization theorem called \"There Are Free Lunches\"\nwhich in particular argues the NFL theorem. Based on the assertion, although the\nNFL states that averaged overall data distribution all algorithms have the same\nerror rate, the TAFL theorem proposes that some algorithms can achieve the best\nperformance if tasks are given in special order. Also, it is declared that if more\nproblems are solved the difficulty of the new task will be decreased. They also\nmentioned an example to use the theorem. The proof of the TAFL theorem is\ninspired by the universal approximation theorem. The main contribution of the\npaper is to formulate the theorem and bring one example for the theorem.",
            "main_review": "+   Overall,   the   paper   is   well   written   in   terms   of   structure.   Also,   the   problem\nstatement is interesting and there can be many powerful works in this area. \n+ No grammatical errors or typos found in the paper.\n\nConcerns: \n- The key concern about the paper is that the assumptions made do seem strong, and\nthis is because the ordering of tasks and solving instances in a particular condition\nis only applicable in few contexts..\n- There are doubts in accepting the formulation because the proof is not clear, and\nthe example stated in the paper is trivial; no experiments are done to\nprove the formulation. Also, the conclusions made about the ordering of task seems\nstill unclear.\n- Another concern with the paper is the lack of a background section discussing\ndifferent things stated in the paper. There is not much background discussion about\nthe NFL theorem except the main paper. \n- Also, it would be nice if there was a piece of information about mathematical\nnotations like the off-training-set error stated in the paper, and also the universal\napproximation   theorem   which   the   proof   of   the   formulation   is   inspired   by   this\ntheorem but there is no discussion about that.\n- This lack of background section and some confusing denotations in the equations\nwith no explanation for them makes the paper hard to follow. I am not sure if I have\nmissed points while understanding the equations since some notations were unclear\nand confusing.\n- In equation 3, it is not clear how we can reach the point that if tasks are in specific\norder algorithm a can solve the b's distribution as optimal as algorithm b. I would\nexplain it more to make it more convincing.\n- It is not clear enough for me to accept the statement that the number of calls of\nthe   algorithm   would   decrease   when   the   number   of   previously   solved   tasks\nincreases.\nMinor Comments:\n- Figure 3's y-axis is mentioned to be in percentage but it's in the [0,1] range.",
            "summary_of_the_review": "Unclear and unconvincing.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper introduces the TAFL theorem \"There are free lunches\" proposing a way around the No-Free-Luch theorem. The idea is to split a learning task T that can be solved optimally by a learning algorithm L_b into a set of N learning tasks T_i. The tasks T_i are chosen in such a way that a  learning algorithm L_a (which can not solve T optimally) can solve each T_i optimally in the sense that the predicted model h_i minimize the out-of-sample-error on T_i given dataset D_i. The proposition is then that the composition of the learned models h_i(h_2...h_N(x))..) is equivalent to a model h^* found by L_b for T in the sense that it minimizes the out-of-sample-error.\n\nThe optimal task decomposition (or task order) is analyzed as well.",
            "main_review": "Note:Since i am unfamiliar with the notation and some of the terms used, i see a possibility for error in my review and lower my confidence as a result of this.\n\nI believe the statement is either wrong or trivial. \n\nFrom a philosophical standpoint, there is a very intuitive reason for this:\nLets assume a meta-algorithm L_m that given D for task T\n\na) finds a task split\n\nb) for each intermediate task selects a distribution and sampling strategy from which to draw the new labels\n\nc) finds the optimal model to solve the task using L_a.\n\nThen, the NFL theorem applies to L_m and there must exist a L_b with problem class C for which  L_m is dominated by L_b for all T in C, i.e. not optimal in the sense of out-of-sample-error. Even if the proposed theorem is correct, L_m is only expanding the set of tasks L_a can solve optimally, but the NFL then implies that there must be a set of tasks it can't solve (and even worse than L_a due to the equal averages of NFL)\n\nMoreover, I think that the theorem itself is wrong. Unfortunately the analysis of the paper does not take into account the accumulated composition errors of each task T_i. Even if L_a can solve each T_i optimally (in the sense of minimizing the out of sample error for this task), there is no guarantee that the final composition of the models returned by the meta strategy L_m has out-of-sample error on the same order as L_b would produce. The proof does not cover this aspect and assumes instead optimality of the composition.\n\n\nSmaller things:\n- The notation is poorly explained, e.g. the second paragraph of section 2 is quite unclear (D not defined, x/y and their relation to D only implicitly defined, and S is very poorly define given that there are quite a few choices for distribution spaces with different properties)\n\n- In the TAFL theorem, f_a should probably be defined more precisely. E.g., the sum should have an upper bound or requirements on the bounds should be given (e.g., i assume it should be finite). \n\n- It is unclear to me as i am no expert on generalized functions, but is it allowed to pick g_a=Id and the upper bound of the sum as 1? Would the theorem still hold? Or do you need some approximation properties between S and the model class f_a(:theta)?",
            "summary_of_the_review": "The theorem is either trivial (it is impossible to find an optimal task split) or wrong (solving the task in the task-split optimally does not mean solving the original task optimally).",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}