{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The four reviewers believed the paper was below threshold for acceptance to ICLR. They raised concerns with the experimental evaluation and thought that the paper could benefit from another edit to help with the clarity."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents a new bound as the objective for variational inference. The bound combines the recent progress of thermodynamic variational object which gives a tighter bound than the conventional ELBO, and the f-divergence which induces more possible distribution metrics. Experiments show its better performance on some Bayesian inference tasks.",
            "main_review": "The general idea does not seem surprisingly novel. Nevertheless, developing the objective and its calculation are technically nontrivial and worth a contribution. Still, I think the current paper does not seem to implement the idea in a comprehensive and compelling way.\n\nPresentation issues:\n* The main technique content introduces what the bound is, how is it developed and how to do the calculation. But I expect more comprehensive (unnecessarily deep and involved) technical investigations that help readers grasp a general understanding of the developed bound. For example, why is it better (e.g., how is it tighter if it is) than existing bounds, particularly f-VI and TVO? When is the bound tight? How does it relate to other bounds? These issues are also related to the motivation for developing this bound and explaining why the new bound achieves a better performance.\n* Eq. (17) seems to be the central technical contribution in this paper, but its derivation is missing. I took some effort and verified the equation myself by the facts listed in the paper, but I still think missing the derivation is a problem. The derivation is even more important than the proof of Theorem 2.\n* The potential energy function $U_\\beta(z)$ is introduced but not used anywhere.\n* I do not quite understand why Theorem 2 is explained as that \"$\\tilde\\pi_\\beta(z)$ is on the log $\\chi$ geodesic between $\\tilde\\pi_0(z)$ and $\\tilde\\pi_1(z)$\". To me, it just shows how $\\tilde\\pi_\\beta(z)$ interpolates between the two ends. If geodesic is mentioned, then (1) conceptually, specify the metric or Riemannian structure that defines the geodesic, and (2) why consider the geodesic, i.e. how the properties of geodesic relate to our desideratum.\n* Some claims are expecting proof or reference. For example, Eq. (6) (there is no reference in Sec. 2.2), the statement above Eq. (10), and Eq. (17).\n* Above Eq. (7), $Z_\\beta$ is a normalizing constant over $(x,z)$ or $z$?\n* There are some grammar and spelling typos (\"differeitiable\" and \"able to integral\" in abstract, \"knowledges\" in introduction, \"a exponential family\", \"two unnormalized distribution\" and \"pick the a list\" in Sec. 3.2).\n\nTechnical problems:\n* In Eq. (21), what is $q(z)$? To make the equality, it should be $q(z|x)$ right? If yes, then why does the reparameterization map $g_\\phi$ does not also take $x$ as an input?\n* Eq. (22) seems problematic. \"Defining $q(z|x) = p(\\epsilon)$\" may break the equality. Instead, $p(\\epsilon)$ in Eq. (22) should be $q(z=g_\\phi(\\epsilon) | x)$, which differs from $p(\\epsilon)$ by a factor $1 / \\sqrt{|\\Sigma|}$ (this can also be derived by the rule of change of variables), which cannot be ignored since it depends on $\\phi$ (and $x$).\n* The calculation of $w_n$ also seems problematic. In the equation below Eq. (23), the $1/N$ factor seems missing in the argument of the firxt $\\chi$. Also, the summation estimates $\\int \\tilde\\pi_\\beta(z) q(z|x) \\\\, \\mathrm{d}z$, but not $Z_\\beta$ which is $\\int \\tilde\\pi_\\beta(z) \\\\, \\mathrm{d}z$.\n* How is $\\tilde\\pi_\\beta(z)$ evaluated? It requires calculating the $\\exp_\\chi$ map, which by definition is rather implicit. So is it evaluated by iteratively solving for the inverse of $\\log_\\chi$, or is known in closed-form? If the latter, how is it known?",
            "summary_of_the_review": "Up to my understanding, there are some technical flaws and the paper does not investigate the proposed bound comprehensively (particularly, the motivation is not supported and the advantage is not clear).",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a novel f-divergence Thermodynamic Variational Objective (f-TVO) framework for VI, that extends the TVO towards, a more general, family of f-divergences. The authors propose to use a $\\chi$-deformed exponential distribution, which casts the f-TVO objective as integral along the $\\chi$-path between p(x,z) and q(z|x) (rather than the geometric path in TVOs) under $\\chi$-geometry. The authors propose different variants of f-TVO, that vary between the type of the f-divergance used, as well as how this integral is approximated (K-partitioned ) left-Riemann sum (related to ELBO), right-Riemann sum (related to EUBO) or a 'zig-zag' that alternates between the two. Besides theoretical justifications, results from two sets of experiments show that, in general, the proposed f-TVO perform comparable to or slightly better than the f-VI counterparts, but without clear conclusion wrt the choice of the f-divergence.",
            "main_review": "Overall the paper is well written, however, it lacks some more motivation (and insights) about the extension enabled by deformed geometry. Moreover, the experiments should be improved.\n\nstrengths:\n - novel extensions of TVO towards f-divergences\n - solid theoretical work  \n\nweakness: \n- experiments should be improved and better discussed\n- lack of discussion (and comparison) that connects to related TVO work [1]\n\n\n- It is not immediately clear what are the clear benefits of f-TVO, wrt other objectives that can be defined within TVO (ELBO, EUBO, Renyi, CUBO etc) [1]. \n- The related work section can be improved, discussing work on TVO that already have shown improvements (such as refined partitioning in [1]). \n- The experiments can also be improved, showing standard (from multiple runs) to begin with, and providing more discussion on the results. As of now, here isn't some significant or practical benefits between f-TVO variants and f-VI. The authors also introduce two additional divergences (c1 and c2) which are not motivated and discussed in more detail.\n\nOther comments:\n- Table 1: What is H_alpha ()? (Hellinger?)\n- How were the number of partitions (K=5) and the f-TVO variant (left) chosen for the experiments? It seems that the performance can slightly vary wrt. the choice of divergence and dataset? Is there any intuition behind the choice?\n\n[1] Brekelmans et al (2020). All in the exponential family: Bregman duality in thermodynamic variational inference.",
            "summary_of_the_review": "Overall the paper is well written and (mostly) easy to follow. The ideas and contributions are novel and solid: connecting f-divergances with TVO. However, it lacks some more motivation (and insights) about the connection with deformed geometry. The empirical results are not convincing, since the reported performances, while similar across methods, do not include standard error nor more discussion, which would better highlight the robustness and benefits of the proposed f-TVOs. \n\n----\nPost-rebuttal update:\nMany thanks to the authors for addressing some of my concerns. However, I still think that the experimental setup should be improved and some design choices (eg. wrt the custom divergences) better motivated and evaluated. With this in mind, as well as reading the other reviews (and responses), my initial recommendation will remain the same.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposed new variational inference that combines f-divergence variational inference and the thermodynamic variational objective. The authors introduced several new concepts of exponential families to extend TVO. Finally, the authors provided the estimator of the gradient of the objective function based on the reparametrization trick.",
            "main_review": "The authors provided an interesting theoretical extension of TVO to more general f-divergence families. However, this extension seems not surprising but straightforward. The critical issue of this work is that the authors did not present the motivation for the extension. I expected that numerical experiments support the motivation of extending the f-VI to f-TVO. But the presented numerical experiments are too weak, and I could not find the usefulness of the proposed method. It seems that standard KL-TVO still works very well. I strongly recommend adding additional experiments to support the usefulness of the f-TVO.\n\nPros\n-  Combine two important concepts in VI, TVO and f-VI.\n\nCons\n- Numerical experiments are too weak to support the usefulness of the proposed method. I could not find the practical benefit of the generalization of TVO to f-VI. \n- Experiments are only done for over-parametrized models. But there is no explanation why f-TVO is recommended to use for over-parametrized models.\n- The details of the experimental settings are lacking or insufficient to reproduce the results.\n\nComments and Questions:\n- Please provide the proof for the statement before Eq10\n- No proof of Eq17\n- Below Eq22, $q(z|x)=p(\\epsilon)$ seems strange, should be $p(g(\\epsilon))$ ?\n- Could not follow the discussion below Eq24. Please explicitly write how the authors used the logsumexp trick here. Moreover, if $R$ and $L$ are negative, $\\ln R$ and $\\ln L$ cannot be defined.\n\n- In the numerical experiments, the authors introduced the customized f-divergence, called $f_{c2}$. I know that they were introduced in the previous work [29], but the authors should explain why it is used in numerical experiments and what distinguished properties they have compared to other f-divergences so that non-experts can understand them.\n- What is the reason for introducing the zig-zag integral? In VAE experiments, it did not show significant improvements.\n- In VAE experiments, I could not find the network architectures. Also, I would like to know the performance in the more meaningful measures, such as the test log-likelihood. Moreover, the authors should compare the results with IWAE, since IWAE also uses the multi-sample bound. \n- Based on all the numerical experiments, it seems that KL-TVO seems to show the best performance on average and could not confirm why we use f-TVO.\n\n- All the experiments are done in over-parametrized models. Why?\n- I would like to see results of simple models, for example, GLM, mixture models, or Gaussian processes, in which we can estimate true posterior distributions.  We can understand the solution of f-TVO more intuitively in those models than in over parametrized models.",
            "summary_of_the_review": "The extension of TVO to f-TVO is an interesting direction, but I think the experimental results are too weak to support the usefulness of the proposed method. Moreover, the description of the experimental settings is limited to reproduce the results. I recommend improving writing and experimentation. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed an $f$-divergence TVO, which includes some existing works e.g., RVB, CUBO, ELBO into a unified framework. This paper's main idea is to transform $f$-divergence into a generalized $\\chi$-exponenetial family and integral TVO along the $\\chi$-path. The paper provides some theoretical analysis and the optimization methods of the suggested framework and supports the proposed $f$-TVO with numerical results. ",
            "main_review": "The generalized $\\chi$ exponential family part is interesting and new to me. But it seems inconsistency in the definition, the authors need to make careful and clear explanations and check every detail before submission.\n\n\nWeakness:\n- The definition of f-divergence is different from the commonly used one, $D_f(p||q) = \\int q f(p/q) dz$.\n\n- Equation 8 does not hold when $\\log_{\\chi}(u) = \\log u$, $\\chi(v)=1/v$, there is an additional constant 1.\n- What is the domain of the function $\\chi$? \n- Convex differentiable generation function f with $f(0)=1$ or $f(1)=0$?\n- How to guarantee the existence of the function \\chi for any generation function f? For example, when $f^*(u)=u^2-1$ is convex differentiable and $f^*(1)=0$. When u is larger than 1, $f^*(u)$ is positive while $-\\int_1^u \\chi(v)dv$ is negative based on the condition on function $\\chi$.\n- Equation 11 $D_f(p||q) = -\\int p(z) \\log_\\chi (\\frac{p(z)}{q(z)})dz$. \n- Can you provide the derivation of equation 17? I do not think this is a direct result. \n- I did not find the monotonicity of $S_\\beta$ in the paper. One key point in TVO is the integrand is monotonically increasing, thus the $\\log$ probability can be estimated by the Riemann sum. \n\ntypo: \n- page 2: $f$-divergence is a measures --> measure\n- page 2: $f$-TVO in contributions should use the same font as the other part of the paper.\n- page 4: we can define a exponential --> an exponential\n-page 4: $x$ should be $\\textbf{x}$ in definition 3.\n\n",
            "summary_of_the_review": "In all, the theoretical part is intriguing but not convincing enough. There are many typos and inconsistencies in the notations and computations, I expect the authors to provide some supplementary materials to support the theory, including all the mathematical derivations.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}