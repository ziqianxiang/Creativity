{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper analyzes the data scaling laws in NMT tasks with different network architectures and data qualities. The main purpose of this paper is to investigate how such different experimental setup affects the scaling law. The authors found that those difference does not have strong impact on the scaling exponent, and a small difference of model architecture and data noise can be compensated by larger data size.\n\nThis paper gives nice justification of data scaling law from some different aspects which is instructive to some extent. On the other hand, the paper has some weakness as listed in the following: (1) The scaling law itself has been analyzed by many papers, and its novelty is rather limited. I acknowledge that this paper investigates different aspects of the data scaling law and the size of experiments are larger than existing work. However, the result is rather unsurprising. (2) The experiments are conducted mostly on one language pair (English-to-German), it is still unclear whether the findings are universal to other language pairs. As the authors responded, exhaustive experiments over all language pairs are unrealistic but some more investigation to more general data sets could be conducted to strengthen the paper.  \n\nThis paper is around the borderline. Some reviewers were rather positive to this paper. However, they also pointed out the concerns I listed above and they do not show strong support on the paper.  \nIn summary, although this paper shows some instructive findings, it is still a bit below the threshold of acceptance."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper studies model and data scaling laws for Neural Machine Translation. It studies how the test cross-entropy loss scales with 1) Different seq2seq model architectures (transformer seq2seq, transformer LM and a transformer-LSTM hybrid) and asymmetric scaling of the encoder and decoder 2) (a) Training data size and composition - backtranslated data from models of varying size, filtered data using cleaning tools, synthetically introduced noise in the source and target languages (b) In-domain vs out-of-domain test data.",
            "main_review": "Pros:\n\n1. Well executed empirical study that complements the work of Ghorbani et al. 2021 by considering different architectures such as transformer LMs, transformer-LSTM hybrids, and data filtering along with results on publicly available web-crawled corpora.\n\n2. The paper offers clear suggestions on when to use noisy data based on available compute and model sizes.\n\nCons:\n\n1. A lot of the analysis and scaling results are already present in Ghorbani et al. 2021 which this paper borrows from. For example, 1) the asymmetric encoder-decoder scaling 2) OOD test set results on almost identical test sets 3) backtranslated vs forward translated data in this paper vs “original src” and “original tgt” in Ghorbani et al etc. \n\nQuestions:\n\n1. The paracrawl.eu website reports a lot less than 750M En-De sentences for Paracrawlv8. It would be best to report the exact source from which this data was downloaded.\n",
            "summary_of_the_review": "Overall this is a very thorough empirical study of NMT scaling that is sure to benefit the NMT research community immensely when read alongside Ghorbani et al. 2021.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper studies data scaling laws for NMT. Specifically, it investigates the following factors empirically:\n- model architecture\n- model sizes (different numbers of encoder or decoder layers)\n- data filtering\n- different types of manually-added noises.\n\nThe paper has performed a large number of studies to demonstrate some empirically-useful findings for training the NMT models. ",
            "main_review": "Strengths:\n- With the recent advances in large language models, scaling laws for NMT is timely and important.\n- A large number of empirical studies are performed to investigate the impacts of different model & data choices on the final NMT scaling laws.\n- The depicted scaling laws could provide empirical guidance to the NMT community.\n\nWeaknesses:\n- The studies are mostly focused on one language pair (English-to-German), there isn't clear evidence whether their findings could generalize to different language families.\n- Since the paper is mostly an empirical work, there's lack of novelty in methodology contributions. However, I am not sure if we should count too much on the methodology contribution for such scaling laws papers.\n- Some findings don't seem very informative, e.g., the scaling laws on model sizes and model family. \n- The following paper seems very relevant, which should be cited:\nScale Efficiently: Insights from Pre-training and Fine-tuning Transformers",
            "summary_of_the_review": "The major takeaways for the paper, I think, are:\n- Changing in model sizes and architectures have very similar scaling patterns, with a shared component. \n- Different noise reduction filtering methods (e.g., CDS and Bicleaner) can also be fit into the shared component.\n- Adding different types of noises can dramatically downgrade the NMT performance, while independent noises can still fit into the share the component, except the dependent noises via back-translation.\n\nOverall, these findings emphasizes again on the importance of data quality for NMT models, which is somehow known to the community. The paper further quantified such importance with the data scaling laws. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper provides an empirical study of scaling laws for neural machine translation with respect to data noise (filtered/unfiltered/back-translation) and model architectures (transformer encoder-decoder, transformer decoder, transformer-encoder LSTM decoder). Focus on data aspect in scaling laws, the paper carried out a series of experiments on multiple data scales ranging from low-resource (500K sentence pairs) to large scale in industrial setup (512M sentence pairs)\n\nScaling Laws: the paper shows that their scaling laws (in equation 1) can be fit five different architectures (2L6L, 6L2L, 6L6L, 28L6L, 6L28L) on in-domain testsets and 11 out-of-domain testsets using 6L6L models. The scaling laws also can be used to predict the test log-likelihood of an unseen model (Figure 2A).\n\nArchitecture: Experimenting with two different encoder-decoder architectures, namely transformer encoder-decoder and transformer-encoder LSTM decoder, the paper shows that marginally worse architecture can be boosted up by adding more data. \n\nData noise: Throughout a series of control experiments, the experiments show that data filtering can be replaced by adding more unfiltered data. The scaling laws can fit both independent noise and dependent noise (via back-translation)\n",
            "main_review": "**Strengths:**\n\n- The paper has strong empirical experiments at scale to validate the scaling laws. Compare with previous work (Gordon et. al), the training data is much larger, up to 512M sentence pairs for English->German. While I believe that the models used in the paper have a significantly large number of parameters, I couldn’t find this information in the paper. Could the authors elaborate the size of these models?\n\n- There are some interesting findings in the paper when scaling up the training data. For example, it seems that data filtering can be replaced with more unfiltered data. \n\n- The experiments with data noise are carefully designed and controlled. The results provide useful insights.\n\n**Weaknesses and Questions**\n\n- As the authors already called out in the paper, one major weakness I found is the use of log-perplexity as a proxy for language generation quality. *To what extent would improvement in test log-perplexity reflect in human evaluation (HE) and would the improvement in human evaluation follow dismissing returns laws as the amount of data increases?* Although the authors discussed about another potential metrics (e.g., COMET, BLEURT) I wonder if the authors have consider using human evaluation for one of those model (e.g., 6L6L) at different data scales? If yes, what prevented it from being done?\n\n- While the paper focuses mostly on test log-perplexity in scaling laws, I think there are other aspects of translation quality that are important for making deployment decisions. Larger models trained on large amounts of data could potentially exacerbate some known issues of NMT such as gender-biases. I understand that this is not the main focus of the paper, but I think it might be useful to have this angle in the discussions when deployment decisions are rarely made based on perplexity and BLEU scores.\n\n- As the training data is crawled from the web, I imagine that some part of the data could have translationese source. I wonder if the tetsets used in the work are source-original? Perhaps, my question would be *what the graph of fitting the scaling laws look like when evaluating on translating in the natural direction?*\n\n- While all the models in the paper are dense model, I wonder if the scalling laws hold for sparse models (e.g, Sparse Mixture of Experts)\n\n- What is the value of $L_\\infty$? Do you set it fixed for fit it?\n\n**Few recommendation for paper presentation:**\n- In the paragraph below equation 2, I think you meant 6L2L as a held out model, not 6L28L\n- In subsection 4.2.1 at the end of the first paragraph, I think you meant table 2 (i.e.The results are shown in Figure 1C and Table 3.)\n- Table 3 isn’t mentioned in subsection 4.2.2 DEPENDENT NOISE: BACK-TRANSLATION\n- If possible, I would recommend putting the figures where they are discussed. \n- In equation 2, are $p_e$ and $p_d$ are free parameters? They are not mentioned in the following paragraph.\n- I think it's worth to explain $L_\\infty$.\n- Some part of the paper should have been proof-read and cleaned up. In the implication paragraph, could the author ellaborate where the addtional amount of data $O(D^{−5/4}) $ and $O(D^{-2})$ come from?\n",
            "summary_of_the_review": "The paper shows strong empirical results on fitting scaling laws. The experiments are carried out on large scale dataset and large models. While this provides valuable insight for practictioners on making decision when training a NMT system, using log-perpelxity without human evaluation is problematic.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper verifies the scaling laws for neural machine translation models in terms of dataset size. In addition, with different model sizes, model architectures, and different noise level of the training data, the scaling law still holds. This means the effect of suboptimal model architectures and noisy data can be compensated with simply adding more data.",
            "main_review": "Reasons for score:\n\nI have major concerns about the contributions this paper adds compared to [1] and [2]. Most of the conclusions in the paper have already been confirmed by these previous works.\n\n- The scaling law of dataset size has also been thoroughly studied and verified by [2]. The form of scaling law used in this paper is the same as what in [2] except an extra $L_\\infty$ term to control the convergence.\n- [2] has already shown the effect of larger models on data scaling laws with models with different numbers of parameters. [1] has also thoroughly studied the effect of different model sizes on the scaling laws of neural machine translation models.\n\nIn addition, some conclusions from the paper are also not convincing:\n\n- The paper only conducts experiments on a single language pair (English - German), which doesn't necessarily mean all the patterns found in the paper would generalize to other datasets.\n- When testing for different models, there is only one data point for a type of model at a specific dataset size. However, the performance of a model is determined by lots of other hyper-parameters like the choice of the optimizer, the learning rate, dropout rate, etc. The authors didn't discuss how they decide these hyper-parameters and how they affect the scaling law.\n- In Figure 3A, the curve of the no-filter case misses the data points a lot. Also, while the three cases in this figure obviously have different test log-perplexity for the largest dataset case, the fitted curve converges to the same point, and in the main text the authors claim that \"Loss at convergence $\\alpha C^p$ is the same\". This conclusion is based on errored fitted curves and is consequently wrong.\n\nOther comments:\n\n- \"However, recent trend in machine learning largely confirms the trade-off between architectural biases and the amounts of data, namely tendency towards architectures with low inductive biases are being trained on large amounts of data, compute and parameters.\" Please add references for this claim.\n\nMinor Comments:\n\n- On page 4, please define $\\beta, N_e, N_d$ instead of only referring to previous works.",
            "summary_of_the_review": "The contributions of this paper are incremental and the conclusions are also not convincing.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}