{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper aims at improving AAEs with an intervention loss. While the topic is important, the reviewers agree that\n\n- The paper has poor clarity,\n- The related work is not adequately put into perspective,\n- There are concerns with technical correctness,\n- Experimental evidence is lacking,\n\nAs the authors have not addressed any of these concerns, the paper can not be accepted in its current form."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper aims to improve AAEs with the intervention loss (Liang et al., 2020) and SVGD (by constructing \"bridge distributions\") and demonstrates some empirical results.",
            "main_review": "Pros\n+ The topic is interesting.\n\nCons\n- The technical correctness is very concerning. There are many claims left unsupported (via references or experiments) or poorly explained at best. The most serious ones are about stability claims, including \"according to Figure 3, AAE is less stable compared to IVAAE\" on page 4 and \"we propose a generative model which possess robust and stable training\" on page 9. The only result which very weakly (given the limited scale of experiments) suggests better stability in the paper is the CIFAR10 panel in Figure 4, which is clearly insufficient to support the aforementioned claims. Also, Algorithm 1 has many forward and backward (backprop) passes (some likely redundant), but the speed (based on wall-clock time) is never discussed in the paper.\n- The novelty is quite poor. The intervention loss (Liang et al., 2020) is only slightly improved by introducing the radial substitution, which is very close to mixup in the latent space [1,2]. The addition of SVGD is somewhat random and poorly justified. Given that Gaussianization has been studied for a long time [3,4,5], it's unclear why the much more generic SVGD should be used instead. The \"proposed\" FLD is simply just [6] and not helpful in explaining the results (since it's uncommon). Normality tests [7] which can directly give probabilities would be much better in my opinion.\n- The significance is quite low. The scale of the experiments and the number of baselines are simply too small to convince the research community that the proposed algorithms are indeed better and the results will generalize. The FID scores and the quality of the generated images are also clearly too low for today's standards. Theorem 2 is basically reiterating (Liang et al., 2020).\n- The writing is poor and hard to follow given the amount of errors. Also, Eq 2 is clearly missing some subscripts. Fig 4 and 7 are not referenced in the maintext. AAE was authored by Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly and Ian Goodfellow, not just Makhzani and Shlens.\n\n[1] On Adversarial Mixup Resynthesis, NeurIPS, 2019.\\\n[2] Manifold mixup: Better representations by interpolating hidden states, ICML, 2019.\\\n[3] Gaussianization, NeurIPS, 2000.\\\n[4] Iterative gaussianization: from ica to random rotations, IEEE TNN, 2011.\\\n[5] Gaussianization flows, AISTATS, 2020.\\\n[6] The Fréchet distance between multivariate normal distributions, Journal of Multivariate Analysis, 1982.\\\n[7] https://en.wikipedia.org/wiki/Normality_test",
            "summary_of_the_review": "Given the concerning technical correctness, poor novelty, significance and writing, I recommend to reject this paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces an intervention adversarial autoencoder and claims this could improve VAE learning. ",
            "main_review": "## Strength:\nThe intervention loss for regularization seems novel in VAE training. But it's far below the bar of ICLR. I will describe the weakness as:\n\n## Weakness:\n1. Lots of related works are missing in this paper, e.g. ARAE [1] and VAE-SVGD [2].\n\n2. Though the method is motivated well, the proposed method doesn't seem to solve the problem of VAE, especially considering only WAE as baselines.\n\n3. The experiments are weak. Recall the baseline works that have been published several years ago, this paper is not even close to them.\n\n[1] Adversarially Regularized Autoencoders\n\n[2] VAE Learning via Stein Variational Gradient Descent",
            "summary_of_the_review": "I would suggest the authors choose another conference.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I have no ethical concerns about this paper.",
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper presents Intervention Adversarial auto-encoder to stabilize the training process of the latent variables of adversarial auto-encoders. Intervention Adversarial auto-encoder adopts a sequence of distributions to bridge the distribution of the learned latent variable and its prior distribution. The bridge distributions are implemented by a multi-output discriminator, which guides the initial latent distribution to the target distribution with a stable training process. The paper discusses several different types of the bridge distributions and applies\nStein variational gradient descent. Experiments on multiple real-world datasets are conducted.",
            "main_review": "Strengths:\n1. The paper targets on several serious concerns about generative modeling, such as unstable training process and mode collapse.\n\nWeaknesses:\n1. The novelty of this paper is not significant enough as similar ideas have been developed for GAN in \"Jiadong Liang, Liangyu Zhang, Cheng Zhang, and Zhihua Zhang. Intervention generative adversarial networks.\"\n2. The experiment evaluation is not sufficient as the only comparing method is WAE. There are many methods targeting on unstable training process and mode collapse in GAN, and more comparisons are needed, which should also be included in related work and reference.\n3. The improvement shown in experiments is marginal and not significant.\n4. As the key component of IVAAE, page 2 shows two substitutions, more systematic discussion is needed on how to develop and assess substitutions.\n5. On page 4, \"We address it in a heuristic way.\" Detailed settings for this heuristic study should be provided, why can this particular setting be representative and generalize to other settings?",
            "summary_of_the_review": "This paper targets on some important issues in generative modeling such as unstable training process and mode collapse. Novelty of this paper is low and evaluation is not sufficient.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}