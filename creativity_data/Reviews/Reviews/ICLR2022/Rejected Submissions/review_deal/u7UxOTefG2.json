{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The authors question the assumption that the epistemic uncertainty provided by Bayesian neural networks should be useful for out of distribution detection. They start their analysis in the infinite width limit so as to be able to understand how the induced kernels in a Gaussian process behave. The paper also discusses the potential tradeoffs between generalization and detection. Overall, the paper presents some facts that, while not surprising, (Reviewer fGuy), are helpful in questioning the default assumption. Overall, though, the combination of the lack of surprise with the multi-part, somewhat loosely connected message reduces the quality of the submission."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The manuscript challenges the widely believed assumption that Bayesian neural networks (BNNs) are well suit for out-of-distribution (OOD) detection, by showing empirical results obtained using infinite-width (allowing the exact inference, because a network can be equivalently represented by a GP with the included kernel) and finite-width networks (requiring the approximate inference). The manuscript provides several observations in line with this purpose (to disclose potential problems when BNNs are used for ODD detection).  For example, the exact inference in infinite-width networks does not necessarily lead to desirable OOD behavior, e.g., the posterior function standard deviation obtained from an infinite-width 2-layer ReLU does not reflect the underlying data generating process and this uncertainty is not suit for OOD detection. In addition, this observation is consistent with the corresponding finite-width networks. ",
            "main_review": "Strengths \n1. The manuscript includes not only finite-width networks but also infinite-width networks in the analyses. \n2. The manuscript points out potential problems when naively using BNNs for ODD detection. \n\nWeaknesses\n1. The manuscript does not provide any theoretical analyses for BNNs on OOD problems.\n2. All the conclusions are made from toy simulated datasets.",
            "summary_of_the_review": "The manuscript has a certain contribution that it points out potential problems when naively using BNNs for ODD detection. However, I think that this contribution is not enough due to the same reasons I listed as the weaknesses of this study above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In this work, the authors challenge the assumption that underlies many recent works that Bayesian neural networks should be well-suited to out-of-distribution detection.\nIn order to do this, the authors focus on a function-space view by examining the properties of infinite-width BNNs.\nThey use this analysis to argue that BNNs may not necessarily be well-suited to OOD detection.\nThey further argue that there is a tradeoff between OOD generalization and uncertainty, and finally propose an alternative method of validating OOD properties of models.",
            "main_review": "The paper is well-written and clear, and I enjoyed reading it.\nI think the topic is extremely timely and I fundamentally agree with the authors that there is not necessarily any good reason to think that BNNs should be good for OOD detection.\nWhile the analysis does not really involve anything new from a technical level, the observations the authors make have important implications for the field and have not, to the best of my knowledge, really been discussed before.\nHowever, there are aspects that I believe could be improved.\nTherefore, I am willing to accept the paper, but only tentatively.\n\nMy main reservation is that the paper only truly considers regression tasks, as the classification task it does consider is done via regression.\nWhile the authors do this to avoid having to use approximate inference, classification with classification likelihoods tends to perform quite differently to classification by regression.\nThis is particularly relevant, as most works assessing BNNs on OOD detection that I am aware of do so on classification, not regression.\nIt would be good if the authors could perform the same HMC using logistic regression on their toy problems.\n\nAnother reservation I have is that practically all the examples are low-dimensional and toy.\nWhile I don't think this is strictly necessary for acceptance, since the paper makes no strong claims about more difficult problems, the paper would be significantly strengthened by using more complicated problems.\n\nFinally, it would be good if the authors could comment more about OOD generalization.\nThis would be particularly relevant, as there has been a recent surge of interest in the performance of methods on OOD datasets such as CIFAR-10-C.\nIn particular, the authors propose a method for validating OOD properties in Sec. 7 as an alternative to these sorts of datasets.\nHowever, the authors do not really provide many details as to how one could achieve this, nor do they provide any experiments where they actually use this proposal.\nI think that an example of actually using this would be very useful in gauging the effectiveness of the authors' proposal.\n\nThere are also some references that it would be good if the authors could add or discuss, although this is more minor.\nFor instance, the NNGP equivalence for deep networks was derived concurrently with Lee et al. (2018) and more rigorously proven in [1].\nThe authors should also discuss the recent work of [2], which proposes a new BNN prior to improve OOD generalization.\nFinally, the authors may find it interesting to discuss [3], which provides an explicit example of how the uncertainty of a BNN may fail in classification settings.\n\n\nMinor points: \n- Have the authors checked how well the HMC converges? \nAccording to the experimental details, the HMC is only run for a relatively short amount of time, even accounting for parallel chains.\n\n\nReferences:\n[1] https://arxiv.org/abs/1804.11271\n[2] https://arxiv.org/abs/2106.11905\n[3] https://arxiv.org/abs/2010.02709",
            "summary_of_the_review": "In summary, I found that this paper represents interesting and timely work that should inform future discussion as to how we think about OOD detection and generalization with BNNs.\nHowever, I found the experimental evaluation somewhat lacking, and therefore am only tentatively recommending accept at the moment.\nI look forward to reading the other reviews and to hearing the author responses.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper carries out an analysis that motivates that the use of the Bayesian predictive distribution and its uncertainty is not appropriate for detecting out of distribution data. The paper focuses on the case of Bayesian Neural networks and its infinite-wide generalization. Namely, a Gaussian process. The paper has no experiments but gives illustrative insights about why the Bayesian posterior is not suitable for detecting out of distribution data. They show that exact inference with GPs (infinitely wide networks) does not lead to desirable OOD detection. They discuss desirable kernel features for OOD. They emphasize that the choice of weight-space prior has a strong effect on OOD performance. They argue that there is a trade-off between good generalization and having high uncertainty on OOD.\n",
            "main_review": "I believe this is an interesting paper. However, it lacks novelty in the sense that everything that is covered in the paper is more or less already known in the machine learning community. Furthermore, it is natural that the posterior predictive uncertainty is not suitable for OOD detection in some cases. The reason is that the posterior uncertainty can be high simply because there is no data in a particular region.\n\nIt is natural to expect that exact inference in infinite-width networks under common architectural choices does not necessarily lead to desirable OOD behavior. This is especially true if the model assumptions are wrong.\n\nThe idea that weight-space prior has a strong effect on OOD performance is something to be expected, since it will have a big impact in the posterior uncertainty.\n\nI do not see why the use of incorporating prior knowledge, that is usually encoded in an input-domain agnostic manner, can negatively affect OOD uncertainties. It will reduce uncertainty, but that need not be bad for OOD detection. In fact, it can be beneficial.\n\nSumming up, I believe that, although this paper shows some interesting concepts or ideas, it is does not provide a significant break thought in terms of analyzing OOD and the obtained results are more or less already known. This will limit its impact in the community.\n\nI also the paper a bit misleading since in several figures the data presented for training is incompatible with the assumptions implied by the chosen prior. For example, in Figure 6 it seems that the RBF kernel is better for OOD detection since it will lead to higher uncertainties. I do not see this. In fact, it seems to me that it will be better to use the ESS kernel for that. (I mean OOD in the y values no the x values).\n\nI also have the feeling that this paper is using the uncertainty on y to detect OOD in the x domain which is counterintuitive. I believe that if you want to detect OOD in the x domain you should have a model for x, not y given x, which is what BNN and GPs do.\n\nThe paper is more or less clear, however, and well written.\n",
            "summary_of_the_review": "A well written paper showing interesting concepts that are mostly well known in the machine learning community. The paper lack novelty.\n",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}