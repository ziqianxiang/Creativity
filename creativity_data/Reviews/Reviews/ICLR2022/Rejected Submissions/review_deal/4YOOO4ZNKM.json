{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper proposed a self-supervised learning view for sequential recommendation with different forms of model augmentation: neuron masking, layer dropping, and encoder complementing. Overall the scores are negative. The reviewers raised concerns mostly around the motivation of the proposed approach (which wasn't fully supported by the experimental results) as well as the limited contribution (especially considering some of the augmentation strategies have been proposed in the past). One reviewer also brought out an interesting connection between model augmentation and model regularization. The authors responded that they will keep improving the paper and hopefully we will see a much improved version in the next submission."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper  a new self-supervised learning (SSL) paradigm for sequence recommendation by  contrastive learning between positive and negative views of sequences based on model augmentation. The model augmentation methods includes neuron masking, layer dropping and encoder complementing. The proposed algorithm is evaluated with several real-world datasets, showing the efficacy of the proposed methods.\n\n",
            "main_review": "### Strong points\n1. two model augmentation methods for generating two views of a sequence.\n2. The detailed experiments show the effectiveness of the proposed augmentation.\n3. The paper is easy to read and follow\n\n###  Weak points\n1. overclaimed contributions. The authors should reorganize the contributions in the paper. \n2. lack technical contributions. Dropping the overclaimed contributions, the contributions are marginal\n3. lack significant test, since the improvements are very small, in the order of 0.001\n",
            "summary_of_the_review": "### Detailed comments\n\n1. The neuron masking model augmentation has been proposed in CL4SRec, but claimed as a contribution in the paper. In this way, this model augmentation can not be also considered as a contribution. \n2. Even though overclaimed contributions are included, the contributions may not sufficient. The proposed methods look a little straightforward and motivations are not supported by analysis. \n3. The detailed setting of baselinesa are not given.\n4. Regarding encoder complements, the authors should compare the baselines with GRU encoders as additional module. This is for illustrating the effectiveness of self supervised learning compared to simple ensemble .\n5. \"‘SRMA w/o D’ outperforms other baselines on the Sports dataset and has comparable performance to ‘CL4S.’, which indicates the model augmentation is of more impact in the SSL paradigm compared with data augmentation\". The authors should discuss more about why the superority of SRMA w/o D to CL4S can indicate that the model augmentation is of more impact in the SSL paradigm compared with data augmentation. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes three levels of model augmentation methods: neuron masking, layer dropping, and encoder complementing. This work opens up a novel direction in constructing views for contrastive SSL and does experiments to verify the efficacy of model augmentation for the SSL in the sequential recommendation.",
            "main_review": "Strengths:\n1. This paper put forwards three kinds of model augmentation methods: neuron masking, layer dropping, and encoder complementing.\n2. This work proposes an idea for constructing views for constrastive SSL.\nWeaknesses:\n1. What’s the motivation for using neuron masking/layer dropping/encoder complementing for model augmentation? Is there any theoretical analysis or intuition explanations?\n2. Although the authors claim the method is model augmentation, I still consider that the method is a kind of data augmentation, because this paper only uses the three levels of model augmentation to construct view pairs for training the model.",
            "summary_of_the_review": "This paper proposes three levels of model augmentation methods: neuron masking, layer dropping, and encoder complementing. But the novelty and contributions are limited. Besides, it fails to explain the motivation of the proposed augmentation methods.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper is trying to address the sequential recommendation problem in which the goal is to predict the next items in user behavior. The paper proposes 3 levels of model augmentation methods: neuron masking, layer dropping and encoder complementing.",
            "main_review": "Strengths:\n1. The paper shows the effectiveness of model augmentation over data augmentation.\n2. The paper shows that the effectiveness of model augmentation can help the model to achieve better performances.\n\nWeakness:\n1. The paper only considers model augmentation, but the model augmentation is closely related to model regularization. As shown in the paper \"SSE-PT: Sequential Recommendation Via Personalized\", regularization methods like SSE can help with the better performances too. Have the authors given much thoughts about the differences between model augmentation and model regularization? Are they similar concepts? If so, can we do some comparisons in experiments show the differences in terms of effectiveness?",
            "summary_of_the_review": "The paper addresses an important research problem and shows that a few model augmentation techniques can help with the sequential recommendation performances. My main concerns about the paper is the lack of explanation for the differences between model augmentation and regularization techniques. Addressing the concerns will help us understand us better if the proposed methods are general enough to be applied to other research problems.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}