{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper studies the problem of OOD classification: the test data and training data distribution can have different spurious feature-class dependencies.\n\nThe reviewers have stated that the proposed procedure is a natural choice, with simple implementation. Another positive point is that it could easily be incorporated in many off-the-shelf machine learning training algorithms.\n\nYet, the technical novelty was mentioned to be limited. The bilevel optimization point of view and the connection with min-max optimization problems raised some concerns, as the vocabulary used could be misleading.\nIt was also raised that the paper lacks theoretical supports: no formal analysis, most explanations are ad hoc, etc."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a new method called BLOOD for the problem of domain generalization. The proposed procedure has two broad steps: (i) Identify groups with different biases (ii) Minimize risk on each of these groups with the group DRO idea. Authors show promising results on colored MNIST and Camelyon17-wilds, FMoW-wilds. ",
            "main_review": "The paper proposes a novel approach for domain generalization. Overall, the paper is clearly written. However, it gets hard to follow in certain sections but it doesn't obscure the overall understanding (please see below). \n\nMajor concerns: \n- This paper is primarily empirical. While the results on the three datasets included in the experiments look promising, comparison on other datasets can strengthen the empirical efficacy of the proposed method BLOOD. For example, it would be interesting to evaluate and compare with datasets in DomainBed https://github.com/facebookresearch/DomainBed/. I encourage authors to compare their method with ERM and the best alternatives in [1]. This is my major concern. \n\n- Alternatively, it would also be interesting to include more details on the diversity of biases in the groups obtained with different shallow learners at least on the toy MNIST dataset. \n\n- The choice of shallow models used for bi-level learning is not clear in the experimental section. \n\nOther bits: \n- It would help a reader if a few lines can explain the notation used in Algorithm 1. Maybe add some notation in a paragraph before Section 3. For example, the following things were unclear in the first past (I found the description as I read Section 3 but it would be better to define the notation upfront): (i) the notation with (.) and (x); (ii) The role of q is not clear. \n- Why only worst-case region accuracy is included for FMoW. \n- How are hyperparameters tuned for Algorithm 1?\n\n[1] Gulrajani and Lopez-Paz, In Search of Lost Domain Generalization. https://openreview.net/pdf?id=lQdXeXDoWtI\n",
            "summary_of_the_review": "Overall, the paper is clear and proposes a novel method. However, the empirical evaluation can benefit from more exhaustive comparison, for example on Domain Bed. It is also not clear if the motivation to use shallow learners in the inner loop of bi-level optimization is practically achieved even in the toy set. Analysis highlighting the characteristics of the biases identified by groups can be insightful. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper considers the out-of-distribution (OOD) problem. To automatically remove multiple unknown types of biases without prior information, this paper proposes a bi-level learning framework, where in the inner-loop it aims to detect the biases while aiming to remove them in the outer-loop via group Distributionally Robust Optimization (DRO). Experimental results on synthetic and real datasets illustrates the effectiveness of the proposed method over other baselines.",
            "main_review": "\n-------------------------- pros\n1. This paper is overall well written. \n2. The proposed method achieves promising performance empirically.\n\n-------------------------- cons\n1. The technical novelty is limited since bilevel optimization framework has been widely used in machine learning.\n2. Precisely, the formulation of the proposed method is not bilevel optimization framework but triple-level like optimization framework since in the outer-loop it is a min-max optimization problem. Authors should make it more clear. \n3. This paper lacks theoretical supports including the perspectives of the generalization and optimization convergence. As mentioned in 2, the optimization problem is different from ordinary bilevel optimization problem.\n4. Empirically, is the proposed method more efficient than other baselines? Besides, more discussions should be added to explain why it works. Further, experiments might be conducted on more real-world datasets to support the claims.\n\n------------------------- minor comments\n1. In the abstract, what is DRO?\n2. In the synthetic experiments, what is the correlation? Pearson (linear) correlation? ",
            "summary_of_the_review": "Overall, I vote for rejecting mainly because I think the technical novelty is limited and it lacks theoretical supports.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper studies the problem of OOD classification: the test data and training data distribution can have different spurious feature-class dependencies. The goal is to have high test accuracy of a model trained in one environment. The paper designs a bi-level optimization problem: the lower-level is to re-group data in an environment (distribution) into two groups (correct and incorrect predictions), and the upper-level is to train a model that has different weights over the two groups to focus on the examples that have the changed spurious feature-class dependencies. Experiments on two real-world datasets and synthetic datasets show significantly improved OOD accuracy. There is no theoretical analysis of the method.",
            "main_review": "Strengths:\n+ OOD is challenging and the proposed method is novel and interesting. The dynamic re-grouping (rather than a one-shot grouping) is one of the inventions of the paper.\n+ Experimental results are good.\n\nWeaknesses:\n- the author emphasizes the necessity of using a shallow model in the LL problem (lines 2-7 in Alg.1). However, there is no ablation study about the shallow model. What can happen if the model is deep and does not overfit? Also, line 9 shows that the upper-level model uses the same \\theta, indicating that the UL model is a shallow model. Why not decouple the two models?\n- the formulation/algorithm is not really a bilevel optimization formulation/algorithm. When optimizing the upper-level variable \\theta, the gradient should not just depend on the current \\theta, but should also differentiate with respect to \\theta through the lower-level optimization variables (\\phi_i, the grouping variables, and the q_j). The algorithm is more similar to an alternative optimization of several sets of variables. See [1,2,3]. The author(s) did not cite papers on bi-level optimization.\n- the methods mostly rely on existing work. For example, group DRO has been proposed in [4]. The new dynamic regrouping does bring more improvement in OOD accuracy, so this is just a minor weakness.\n- In the experiments, there are several correlations not defined clearly, thus affecting the interpretation of the results.\n- there is a lack of ablation studies: what if the bias identification is not accurate? It seems that the success will depend on the identification of the bias.\n- typos: line 8 of Alg. 1 the denominator seems incorrect; line 9 of Alg. 1, the second q_j should have a negative sign before it.",
            "summary_of_the_review": "The studied problem is important and the empirical results are good. The major weaknesses are the proposed algorithm formulation, motivation, and the lack of ablation studies to verify the need/motivation of the components of the algorithm. There is no formal analysis or explanation -- most explanations are ad hoc.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper develops a bi-level algorithm that aims at automating the process of identifying biases in data and performing data re-weighting and splitting to eventually train a de-biased model. Numerical experiments are provided to demonstrate the performance of their approach.",
            "main_review": "Strengths:\n\nThe procedure proposed in this paper is a natural choice, the implementation is easy and can be incorporated in many off-the-shelf machine learning training algorithms.  In particular, given the recent rapid development of bi-level programming, their proposal might receive more refinement or improvement. The performance of the proposal is evaluated in synthetic datasets and shows substantial advantages when more than one spurious feature is present in the data, compared to other existing approaches, including IRM and PI. Thus given the failure of IRM proposed by Arjovsky et al., the proposed method of this paper might be a promising direction to try and see if the beautiful IRM concept can actually become a useful thing in practice.\n\nWeaknesses:\n\nApparently, this is an empirical paper: proposing a method, showing that it does what the authors expect in synthetic experiments and that it has practical relevance in real data. So I would not pick on the fact that there are no theoretical guarantees at all.\n\nThe authors demonstrate a scenario under which their adaptive method outperforms other existing methods like IRM and PI. The authors explained clearly why PI underperforms when there are two types of spuriously correlated features in their synthetic experiments. But for an empirical paper, I would love to see more discussions on when their methods might fail, which could give readers more insights on what is the best application scenario of the proposed method. I think this is the major limitation of this work.\n\nThe method, at least based on the current form, is based on shallow learning for identifying spurious correlations. For instance, the authors claimed, \"... spurious correlations are commonly characterized as simple surface patterns\". I believe the authors need to provide more evidence or explanation to support such a claim and evaluate their method when such a premise does not hold.\n\nFor the real data application part, I understand the authors' method achieves the highest OOD accuracy. But I think this section seriously lacks necessary explanations and details. For the two datasets, what are the potential source of biases? Just as in the synthetic experiments, the authors can easily use what BLOOD learned and see if there is any feature whose correlation with the prediction accuracy decreases as the algorithm updates, and also check if those features make any sense. Without such a sanity check, it is hard for me to trust BLOOD in such realistic settings yet, in particular considering that the improvement over some other methods is not that impressive (e.g. 2-3 %). \n\nMinor language issues:\n\nI understand ICLR's policy which asks referees not to pick on language issues. But the current paper contains numerous typos, grammatical errors, and confusing sentences. Just to name a few:\n(1) The second paragraph of Section 2.1 is difficult to read because of the incorrect grammar;\n(2) Several \"can not\" should be \"cannot\";\n(3) The first paragraph of Section 2.1.1 \"To obtain biased models while a training stable classifier\" should be \"To obtain biased models while training stable classifier\";\n(4) Section 2.1.1, in step 2 of the algorithm, \"use a trained classifier\" should be \"use the trained classifier\";\n(5) Before Figure 2, \"which is more close to\" should be \"which is closer to\".\nI cannot list all of them. But the authors should seriously take a more careful proofread of the paper if their paper receives more positive feedback from the referees. ",
            "summary_of_the_review": "Strengths: A easy-to-implement and automatic method that shows some advantage when more than one spuriously correlated feature is present in the data; It outperforms IRM in most settings, hence a promising direction to explore for actually fulfilling the yet unfulfilled promise of IRM.\n\nWeaknesses: The paper lacks (1) a discussion on the key assumptions under which BLOOD works, (2) a discussion on when BLOOD fails to work, and (3) a discussion on the potential source of biases in real data applications.\n\nGiven the above strengths and weaknesses, I evaluate the paper as \"the contributions are only marginally significant or novel\" in the empirical aspect. There is no novel contribution in the technical aspect. Taken together, I would evaluate the paper as \"marginally below the acceptance threshold\". But I do think there is room for improvement regarding the main weaknesses in my opinion.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}