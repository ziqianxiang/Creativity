{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The most positive reviewers have not decided to step forward to champion the paper. Others have a negative impression which has not sufficiently changed after the answers from authors. Actually, it is acknowledge that there have been many modifications, but they are not happy enough with this situation: modifications (some significant ones) cannot always be fully checked again and even with the efforts that were made by reviewers, strong concerns remained. It has been pointed out that the direction has potential. My recommendation is based on the data that I have available."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents slash a neuro symbolic system; the system presents strong results, but on few datasets",
            "main_review": "the topic of this paper, SLASH has a complex structure. It includes :\n\n- a NPP: which is a standard NN decription language\n Reading the paper, it looks like it can describe any NN, but  you also use\n- an ASP program, that computes probabilities by ASP eval.\n- Finally, the whole? thing is trained using grad ascent\n\n - the initial probabilities were obtained from? \n- ASP programs have multiple models, which have multiple atoms. \\sum Models = 1? P(M1 and M2) ? \n- Is it correct to use the word query for  a model?\n\n1. What is the point of the LP? It is not very well motivated.\n\n It would be nice to have examples showing how to write it?\n\n2. ASP; do you use non-strat neg? Agg? Everyting in your programs?\n\n3.  what goes in the NN is the solver output as a number? Ie, you run the solver every time?\n\nUser vs training loss: I got lost, what is the point of a loss function that is not used in training? TensorFlow and friends allow to define a second function on tuning data, is that it?\n\nEvaluation\ncan you give short info on dataset size at the beginning?\nslash(pc) and slash(dnn) have the same ASP?\nTable ii: why no ASP only? Such good result with low data suggest a very strong prior, \nagain, you allow users to define a loss funcion, but not to use it? Maybe I am missing the point.\n\nt SLASH’s batch-wise loss -> confirming? Had you discussed batched evaluation before? Isn't this standard in DNNs?\n\n\nSmall questions:\n gradient for the solution does not have to be positive: zero? This should not be in the appendix.\nAttention vs slash attention: you define the latter in page 8?\nPlease refer to the sw you use in the text (eg, which ASP solver?)",
            "summary_of_the_review": "I think this is a nice paper, suggesting the logic program provides strong background data for the network and that the gradient based search can  provide good prob  estimates.\n\nThe one flaw in this paper is that you only compare with DeepProblog, You drop NeurASP after the first table In general. it is hard for me to fully accept your claims :(",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents a new deep probabilistic programming language based on ASP. The key feature is the use of a single attention encoder paired with a collection of probabilistic circuits (one for each \"category\"/model solution of the neuro-symbolic task). ASP is finally used to answer a query given the probabilistic predicates returned by the circuits for the features extracted by the encoder and the logical program modelling the particular task under consideration. SOTA accuracies are achieved with advantages related to the generative nature of the considered approach (e.g., when coping with missing data) and good computation times (due to the parallelisation of the ASP tasks).\n",
            "main_review": "Even as a non-expert of DPPLs, I have found the SLASH language specification in S3 easy to understand.\nIn S3.1, I believe that the generative nature of SPNs is crucial and this point should be better stressed.\nThe number of queries to be computed should be made explicit, as well as the possibility of performing this in parallel (and the same holds for the ASP queries). More generally speaking a better characterisation of the inferential complexity of SLASH should be provided.\nRegarding the experiments some words should be spent about the computational efficiency (wrt DeepProbLog) when coping with missing data.\n",
            "summary_of_the_review": "A new ASP-based deep probabilistic programming language. Using generative probabilistic circuits allow to cope with missing data. This seems to be a novel approach and SOTA results are achieved. I think the paper can be safely accepted.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a neuro-symbolic model, dubbed SLASH, that extends previous deep probabilistic programming languages with probabilistic circuits (PCs). The advantage of this approach with respect to similar frameworks, such as DeepProbLog or NeurASP, lies in defining predicates using Sum-Product Networks (SPNs), a subclass of PCs that admit tractable marginal/conditional inference over any subset of variables. Additionally, neural networks and SPNs can be unified in the same framework, for instance by defining PCs on the latent representation extracted by an Attention Slot module. Experiments on different tasks show promising results for this approach.\n",
            "main_review": "Unifying subsymbolic/perceptual and symbolic/logical reasoning is a very active field of research and I found the core idea of this paper\ninteresting.\n\nThe paper is generally well written, but I wish that it focused less on the benefits of neuro-symbolic approaches, which are well known in literature, and more on the semantics of SLASH and the actual benefits of embracing PCs into the framework. I found the paper too hasty on the latter aspects and I think that some examples could definitely help. \n\nThe preliminary results reported are promising, although I found them overly enthusiastic at times. In Evaluation 1, the accuracy margin between SLASH and DeepProbLog/NeurASP is way too small to claim the superiority of the method. The positive results on RTE are only due to a parallel implementation rather than on the core idea beyond SLASH and I don't see why NeurASP couldn't implement a similar\ntechnique. The ability of SLASH of handling missing data in a principled way is indeed a welcome feature. I don't see why not reporting\nthe performance of NeurASP in Evaluation 2 though.\n\nEvaluation 3 and 4 shows that adding a logical component on top of a Slot Attention model is beneficial in the set prediction task. I think that DeepProbLog and NeurASP could also be applied in this setting, by definining the neural predicates on top of the latent representation provided by SA. If that's not the case, it would be useful to mention why.\n\nMinors:\n\n1) \"In contrast to query evaluation in Prolog (Colmerauer & Roussel,1996; Clocksin & Mellish, 2003) which may lead to an infinite loop,\nmany modern answer set solvers use Conflict-Driven-Clause-Learning (CDPL) which, in principle, always terminates.\"\n\nThis is a slightly reworded version of a sentence from the first paragraph of the ASP page on Wikipedia. DPLL (and modern variants such as CDCL) do terminate in principle *and* in practice. Guaranteed termination implies that, in contrast with Prolog, ASP is not Turing complete.\n\n2) \"due to SLASH’s semantics, our interest lies in rewarding the right solutions (v = c) and penalizing wrong ones (v != c)\"\n\nIsn't this true in most machine learning settings?\n\n3) The function f in the loss term (Eq.9) is not defined.\n\nTypos:\n\npage 2\n- end2end -> end-to-end\n- IN this way -> In ths way\n- CDPL -> CLCL\n\npage 3\n- MMC -> WMC\n\npage 5\n- referred to as stable model, I, in ASP -> referred to as stable model in ASP",
            "summary_of_the_review": "- Unifying PCs with neuro-symbolic approaches is an interesting research direction\n- The technical description of SLASH could be improved, possibly by shortening the introduction and motivation for neuro-symbolic approaches\n- The preliminary results are promising although the empirical evaluation could be improved. Most importantly, the experiments and the following discussion seem to oversell the SLASH framework rather than rigorously investigating the use of PCs in neuro-symbolic models.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper presents an approach for neuro-symbolic integration that differs from NeurASP because NN can be replaced by probabilistic circuits (PC) or by NN+PC.\n\nThe resulting system, SLASH, is applied to the problems of MNIST-Addition and set prediction on a variant of the ShapeWorld dataset.\n\nThe results on MNIST-Addition show that SLASH+NN is faster and more accurate than DeepProbLog and NeurASP. Moreover, when pixels are missing, SLAHS+PC has much better performance than DeepProbLog.\n\nOn ShapeWorld, SLASH is compared with Slot Attention (Locatello et al 2020) and found to have better avg precision especially in handling novel combinations of attributes that were not seen during training.",
            "main_review": "The idea of using PC instead of NN is novel to the best of my knowledge. It leads to interesting experimental results. However, the contribution seems rather incremental with respect to NeurASP and DeepProbLog and the experimental results leave some questions unanswered.\n\nBasically, the only difference of SLASH with respect to NeurASP and DeepProbLog is the possibility of having neural predicates connect to probabilistic circuits instead of NN. While the practical effects of such a possibility may be interesting, the experimental part in my opinion is not sufficient for assessing them.\n\nThe speed-up with respect to DeepProbLog in the MNIST-Addition seems to be due to a non-optimal use of hardware resources: while SLASH is parallelized, DeepProbLog is not, even if the derivation for different examples could be run in parallel there as well. The authors should either parallelize DeepProbLog or remove parallelization in SLASH to fairly compare the two. \n\nIn the MNIST-Addition task with missing pixel, the comparison with DeepProbLog where the NN interprets missing pixels as background is not fair, I believe an extra Boolean input per pixel should be added to the NN expressing whether the pixel is observed or not or other similar techniques for handling missing data in NN should be used.\n\nIn the ShapeWorld4, the authors should report the precise definition of Precision they used, since in (Locatello et al 2020) the precision depends also on a threshold on the distance between the prediction and a matching object. What was the threshold used for Slot Attention? Moreover, in the appendix the author state that they used a different approach for encoding empty slots, where that a slot is considered empty if all neural predicates assign a high probability to an extra value for all the attributes: what was the threshold used in this case to asses whether a probability is high and how was it chosen?\n\nThe sentence \"this trend still holds even when subtracting the higher precision scores observed in Condition (A).\" is not clear: which predictions were removed and how were they chosen?\n\nThe theoretical part on semantics and learning is missing some important aspects and looks imprecise in various places.\n\nFirst of all the authors introduce Neural-Probabilistic Predicates (NPP) without specifying how probabilities are assigned to the individual c=v predicates. For NN, one guesses from NeurASP and DeepProbLog papers that the output of the final softmax layer is used. For PC, this is less clear, as PCs have a single output that returns the joint probability of the configurations of variables at their input. How do you turn a single real value to a discrete distribution? Do you have multiple outputs sharing part of the circuit below them? This should be clarified.\n\nThe statement that the use of PCs allows the user to compute also P(X|C) and P(X,C) besides P(C|X) is not fully spelled out: from the probabilities computed by the PC, the semantics assigns an unconditional probability to queries, how do these different probability estimates influence the probability of queries?\n\nDefinition 3 states that the probability of a set of queries is given by the product of the probabilities of the individual queries: this is true only if no pair of queries depends on the same NPP. If the queries are really different examples in a learning problem, the independence assumption may hold but in general it does not.\n\nIn the definition of NPP the authors use a single argument for h while in the examples color_attr appears as color_attr(1,X): what is the meaning of 1?\n\nThe theoretical treatment of learning is confusing: the authors state that they want to maximize the log likelihood of a set of queries but then they state that they learn from a set of pairs (Query,hat p) where they want to match the probability assigned by the model with the one specified in the pair. The two statements seem to contradict each other. Moreover, the loss (equation 9) has a very strange form: it should provide the penalty incurred for example Q with the given probability hat p but in eq 9 hat p is absent... Eq 9 furthermore contains a gradient whose meaning is unclear: the gradient should appear in the derivatives of the objective function as a function of the parameters. Eq 9 also includes term f_\\theta^(C_j,X)(x) that is not explained.\n\nEq 9 seems more the expression of the overall gradient over the examples than the loss.\n\nProposition 1 is missing a proof or a reference where the proof can be found.\n\nThe bibliography contains errors.\nReference\n\nJiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B. Tenenbaum, and Jiajun Wu. The neurosymbolic\nconcept learner: Interpreting scenes, words, and sentences from natural supervision. In\n7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA,\nMay 6-9, 2019. OpenReview.net, 2019b.\n\nis repeated.\nThe reference to NeurASP has a wrong title\n\nZhun Yang, Adam Ishay, and Joohyung Lee. Einsum networks: Fast and scalable learning of tractable\nprobabilistic circuits. In IJCAI, 2020.\n\nfol->FOL",
            "summary_of_the_review": "The paper presents an incremental advance over the SotA that seems to have important practical consequences but the experiments do not clearly show them and the theoretical treatment is incomplete and imprecise.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}