{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper surveys a collection of existing works that the author frames as evidential deep learning.\n\nWhile the paper has been recognized as a nicely written survey, all reviewers have raised the major concern that the paper does not have a sufficient academic contribution compared to the surveyed papers. In particular, novelty appears to be limited as the paper does not offer novel views into the surveyed subfield.\n\nGiven the strong consensus among reviewers, I recommend rejecting this paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The proposed paper surveys recent work in evidential deep learning, and provides some potential directions for future work in this space. Evidential deep learning is a set of techniques for calibrating uncertainty of neural networks through second-order distributions.",
            "main_review": "**Strengths**:\n* In general, the paper is well written, structured, and easy to understand.\n* There is significant value in surveying evidential deep learning techniques as there has been some parallel work in this space that is not often connected. This survey covers and categorizes a large number of papers under the umbrella of evidential deep learning.\n* Fig. 1 is an excellent visualization and categorization of approaches in this space.\n* I liked the classification of the literature into prior and posterior methods throughout the survey.\n\n**Weaknesses**:\n* A significant portion of the survey repeats ideas from the Prior Network paper (Malinin and Gales, 2018) with some typos (e.g., in Eqs. 3 and 4, the condition on the dataset as per the Prior Network paper has been omitted). I am missing further insight and takeaways beyond the existing collection of papers surveyed. The discussion details some potential avenues for future work, and there are some insights in the footnotes. It would be good to bring these footnote insights into the paper and expound on them (particularly since there is enough space). However, as it stands, the survey does not provide sufficient additional insight or context for the ideas presented to form its contribution.\n* The representation gap (Nandy et al., 2020) and its resulting visualization were not described in sufficient detail.\n* Overall, it appears that there was insufficient material for a 9 page paper as equations were extremely spaced out (e.g., Eqs. 3 and 4), and even then the paper did not reach the page limit, making it look unpolished.\n* In general, the presentation of the paper needs improvement. There were frequent typos (e.g., 'We also to provide', 'e. 4', 'uncertaint-aware') and inconsistent formatting for referencing figures, sections, and equations (i.e., capitalization and abbreviation differences). There were some notational issues, as well. For example, it was confusing to see the definition $\\mu_k = P(y = k \\mid x, \\theta)$, with and without $\\theta$, and then to have the distribution $p(y \\mid \\mu)$. Furthermore, the references list is unpolished: repeating conference names, listing urls, etc.\n\n**Suggestions for improvement**:\n* My main recommendation is to work into the survey further insights and context from beyond the surveyed papers. For example, the origin of the term *evidential deep learning* comes from evidential theory [1], which relates to the Dirichlet distribution through the ideas in subjective logic [2]. It would be good to further highlight that prior networks collapse the uncertainty over the model parameters, as this insight is important and worth spending more space on in the paper.\n* The Sensoy et al. AAAI paper [3] is missing from the survey, and should be incorporated.\n* Additional investigation into the advantages and disadvantages of the different metrics used to evaluate the performance of evidential deep learning methods with respect to OOD inputs and uncertainty calibration would be valuable.\n* Since this field does not have an unreasonable number of papers, the authors should consider running some of their own experiments to provide empirical conclusions, comparing methods that were not already compared in existing work (e.g., (Charpentier et al., 2020) and (Sensoy et al., 2020)).\n* Lastly, the paper should be polished and proofread. I recommend the use of the cleveref package in LaTeX with the 'capitalise' option to avoid inconsistencies in referencing figures, equations, and sections. \n\n[1] A. P. Dempster. A generalization of Bayesian inference. Classic works of the Dempster-Shafer Theory of Belief Functions, pages 73–104, 2008.\n\n[2] A. Jøsang. Subjective Logic: A formalism for reasoning under uncertainty. Springer, 2016.\n\n[3] M. Sensoy, et al. Uncertainty-Aware Deep Classifiers Using Generative Models. In AAAI, 2020.",
            "summary_of_the_review": "The idea of a survey on evidential deep learning is excellent and valuable to researchers. However, in its current state, I do not believe the paper is ready for publication at ICLR. With improvements to the broader insights and takeaways from the survey as well as paper presentation, this work will become a good contribution to the academic community.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper surveys a collection of existing works that the author frames as evidential deep learning. For the classification case, evidential deep learning tries to train a network to output the parameters of a Dirichlet distribution, hoping the one could directly obtain the data uncertainty and model uncertainty from some functions of the output parameters. The authors provide a relatively comprehensive review of recent work in this direction. Besides classification, evidential deep learning for regression is also discussed briefly. ",
            "main_review": "Why is Sensoy et al. 2018 called ‘prior networks’ (it seems the original papers did not referred to their method as prior network either). According to the equation in Section 3.3.1, shouldn’t the prior be the flat Dirichlet? What is needed to be trained is more like an approximate posterior network that takes as input a new data x. It would be helpful for readers to elaborate on this.\n\nIn Equation 5, should $\\mu_0, …, \\mu_K$ be $\\mu_1, …, \\mu_K$? Otherwise, $\\mu_0$ will always be the largest by definition, which makes on sense. \n\nFor Equation 6, is some term related to $B(\\alpha)$ missing?\n\nThe argument that the model uncertainty can simply replaced by some function of $\\alpha$ is not very convincing, given that the network will directly output $\\alpha$. It would be helpful if more details and intuition can be provided. \n\nAs a survey, this manuscript seems to miss a lot of important related work on probabilistic neural networks and Bayesian deep learning [a-f]. \n\nMinor:\n\nP6: fig. 2 -> Fig. 2\n\n\n\n[a] Natural-Parameter Networks: A Class of Probabilistic Neural Networks, NIPS 2016\n[b] Feed-forward Propagation in Probabilistic Neural Networks with Categorical and Max Layers, ICLR 2018\n[c] Sampling-free Epistemic Uncertainty Estimation Using Approximated Variance Propagation, CVPR 2019\n[d] Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks, ICML 2015\n[e] Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks, ICML 2020\n[f] A Survey on Bayesian Deep Learning, ACM Computing Surveys, 2020\n",
            "summary_of_the_review": "Overall, the paper is informative and did a relatively good job in introducing the basic concepts as well as the motivation of evidential deep learning. However, it seems there are still some important related works that are missing from the references. Besides, the paper in its current form looks more like a review rather than a comprehensive thorough survey, partly because of the space constraints in ICLR. Therefore I am not sure that ICLR is the right venue for it. Perhaps it is more suitable as a long journal where more details and taxonomy could be included. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper is a survey of methods in evidential deep learning. It gives a brief motivation for this set of methods, explains a general framework, and describes previous works for classification and regressions tasks in varying amount of details. As a survey paper, it doesn't introduce novel ideas, but gives a useful overview for people who would like to start working on this topic. ",
            "main_review": "In my opinion, the paper did a very good job of collecting papers on evidential deep learning and  providing a brief overview of their ideas. As a person unfamiliar with this topic, I got interested and proceeded to read some of the references as I didn't fully grasp the motivation and all the details from a rather short introduction. The paper could have been more enjoyable if it wasn't limited to 9 pages and was written in a form of a tutorial with more intuition for all the equations. For example, it took me some time to interpret Eq.4,6,7. What bothers me about evidential deep learning is that the choice of the regularization term often seems arbitrary. I wish this paper had some deeper insights on  this matter. \n\nI haven't seen survey papers published at conferences before, so I'm hesitant to recommend its acceptance. It would have been different if the paper, in addition to being a survey, presented some fundamental insights into the nature of these methods, which could count as a novel contribution.\n\nI think it can become a well-cited journal or arxiv paper that can get people interested in the topic of evidential deep learning if the background sections are turned into a self-contained tutorial, and the survey parts include some additional motivation and intuition regarding the design choices that each of the papers make.    \n\nExtra remarks:\n- should Eq.2 be $p(\\mu | D, \\alpha)$ instead of $p(\\alpha | D, \\mu)$?  \n- section 3.2 typo: quanitified\n- section 3.3.2 typo: uncertaint-aware\n\n \n\n  ",
            "summary_of_the_review": "Contributions of this paper are not novel, which is normal for a survey paper. \nI think survey papers are not suitable for conferences as they need to be evaluated using a different set of criteria. \nTherefore, my recommendation would be to reject this paper purely based on its type. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper presents a survey of evidential deep learning, a family of machine learning methods that suggest accounting for various forms of uncertainties via a hierarchical predictive model whose hyperprior parameters are a function of input observations. The paper classifies evidential deep learning approaches into categories and points out the strengths and weaknesses of each category. It also presents some theoretical properties of the Dirichlet distribution that could be relevant for machine learning tasks.",
            "main_review": "This is a survey paper without any conceptual claims of novelty. Its main purpose is to make an emerging family of machine learning models more accessible to the community. I find this goal sensible and important.\n\nThe paper presents the technical material very clearly and provides a well-justified dichotomy of the evidential deep learning model family.\n\nI think the statement in Footnote 1 is a bit unnecessary confusion. The precision score of the Dirichlet distribution corresponds simply to the \"precision\" of a Gaussian distribution, which is customarily defined as the inverse of the covariance.\n\nThere exist few pieces of work that use Dirichlet priors on class probabilities, which are missed by this survey paper. For instance,\n\nJ. Gast and S. Roth, \"Lightweight Probabilistic Deep Networks\", CVPR, 2018\n\nM. Haussmann et al., \"Bayesian Evidential Deep Learning with PAC Regularization\", AABI, 2020\n\nThe paper could clarify the qualitative difference between distributional uncertainty and representation gap better. It looks to me like they both quantify the same source of uncertainty: whether a test-time samples is coming from a different distribution than the training-time samples. They only differ in the quantitative aspect: how much the model is confident that a sample is out-of-domain. I am missing the rationale behind introducing a new category of uncertainty only for the sake of this quantitative difference.\n\nThe paper claims to collect some theoretical properties of the Dirichlet distribution that could be useful for machine learning. However, going through the paper and the appendix, I am not able to identify theoretical content that provides any new insights on the use of Dirichlet distribution for machine learning. The presented calculations seem to have been taken from the original papers in their vanilla form and some additional properties, such as expected L-infty norm and moment generating function are rather textbook material.",
            "summary_of_the_review": "Having said that the paper touches the important topic of making a new model family more accessible to the audience, I am afraid I do not think it does it in a way that would add sufficient value on top of one reading the material from the original papers. I think this way because the paper adopts most of the content verbatim from the original sources and does not add a level of abstraction that helps the reader draw new insights that are not straightforward from the original sources. Nor does it highlight overlooked positive or negative properties of the evidential model and nor does it present any empirical outcomes that one would find surprising. Under these conditions, I am not able to recommend an accept for this paper in its current shape.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}