{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper proposes an empirical study on the effect of various types of output layers of deep neural networks in different scenarios of continual learning. The authors draw several insights, such as ways of selecting the best output layer depending on type of scenario and a description of the different sources of performance drop (forgetting, interference, and projection drifts). The paper proposes different ways of mitigating catastrophic forgetting: a weight normalization layer, two masking strategies, and a variant of NMC using median vectors.\n\nThe paper presented a detailed experimental setup covering a large number of scenarios of continual learning: incremental, Lifelong Learning and Mixed Scenario. This was highlighted by Reviewer BTLN, and the AC agrees. \n\nThe main point of criticism for the work is the lack of novelty and the low significance of the findings. These were highlighted by all four reviewers.\n\nPerhaps the aspect limiting significance is the fact that the feature extractors are assumed to be fixed, which is unlike most interesting settings in continual learning. This was mentioned by reviewers BTLN, uN9P, e1ZF. It is unclear whether the findings provided in this work would generalize to that setting. On that note, Reviewer e1ZF points out that not adapting the feature extractor could be the source of some inconsistencies observed. Studying this further would improve the work.\n\nOverall, all four reviewers recommend rejecting the paper. The AC agrees with this decision and encourages the authors to consider extending the analysis to situations where the feature extractor is not fixed."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a study on different last output layers, under the continual learning problem. More specifically, the study is conducted in a controlled environment without projection shift. The paper proposed several design choices of the last layer, including a modified weight normalization layer, masking operations, and median vector. Different scenarios of incremental/lifelong and mixed learning have been experimented with. ",
            "main_review": "Strength: \n+ The summary of different design choices, including the weight normalization, \n+ Some illustrations are valuable for understanding the cause of forgetting, eg. the norm, bias, and their changes during the incremental process; and the interference plots. \n\nWeakness: \n-  The assumption on non-projection-drift is not very realistic. In continual learning problems, it is very often that the feature representations are shifted over time, along with new data streams.  However, under the paper's assumption, it requires a fixed feature extractor. \n-  Since the study is based on a non-projection-drift setting, it requires pre-trained models as the feature extraction as stated in the experiment part, which is not often practical in many settings. Although it does not use the pre-trained models trained on the target dataset, it is still unfair to compare with other works in the literature. \n- For Figure 2 (interference), what is the root cause for the interference? Why the mean angle of z and A_i (middle) is not as discriminative as the angles among A_i (left).\n- The paper proposed a modified version of the weight normalization layer, but the proposed modified layer operation does not show clear improvement but slight drop over the original designs in most cases (weight_norm vs original_weight_norm in Table 1). Similar to the proposed median layer vs original mean layer. \n-  The proposed masking approach is not stable and tends to produce bad performance.  \n- The figure plots of accuracy are a bit cluttered and hard to read. ",
            "summary_of_the_review": "The study of the feature drift is important, otherwise, the study has to rely on the pre-trained feature model, which makes the setting impractical in many cases.  \nThe paper provides some summarization of multiple tracks to deal with the weights normalization and preserving in the last layer but the insights brought from the work are limited. The analysis is strait-forward on the observation of weights but there is not much deeper and richer analysis on the causes of such observation.  \nThe experiment results do not support most hypotheses made, but the cause of the failures remains unclear. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies the output layer in a deep neural network in the continual learning setting. The paper studies multiple types of output layers under different continual learning configurations. Some suggestions are made based on observed empirical trends.",
            "main_review": "The paper isolates the output layer for study yet in continual learning all layers are updated. No concrete motivation is provided as to why the output layer should be studied in isolation. \n\nMoreover, some of the observations highlighted in the paper may not hold if the neural network is allowed to be updated and the neural network is studied holistically.\n\nFurthermore, most observation (e.g., _masking is efficient in incremental settings to avoid weight modifications_) are well known from prior work. Most observations are not contrasted with prior work.",
            "summary_of_the_review": "The validity and novelty of the results and observations in the paper are somewhat dubious. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors analyzed the effect of changes to the last output\nlayers of the neural network in the continual, incremental learning scenario\nand effects of it two scenarios 1. weight modification 2.Inference.\nAuthors also claim to propose simplified weight normalization layer, two masking strategies, and an alternative to NearestMean Classifier using median vectors to address catastrophic forgetting in the output layer in both continual, Incremental scenarios.\n\nDuring the experiment setup authors separated the network into two parts\n\n1. feature extractor part consisting of all but the final layer (kept fixed to avoid projection drift)\n2. classifier part which was given by the output layer.[Much of the analysis is concentrated on Part-B]",
            "main_review": "Clarity:\n\nOverall writing quality of the paper can be improved a lot. Especially the Sec5 Results which needs to highlight the current \ncontributions and can explained bit more in-detailed. The method proposed is well described and it would take some time to have reproduce the results.\n\nNovelty:\n\nThe methodological contributions do not seem to be novel and all the results are as expected w.r.t  the current\nline of research of doing continual learning keeping the feature extractor part of the network fixed.\n\nPros:\nVery well detailed experimental setup covering all the scenarios. Authors evaluated the proposed ideas on Incremental Scenarios(CIFAR10,Core50,CUB200), Lifelong Learning Scenarios(Core10LifeLong, CIFAR100LifeLong) and Mixed Scenario(Cire10Mix)\n\nCons:\n\nAs mentioned the Novelty is pretty much limited and results as as expected w.r.t current line of research.\n\n",
            "summary_of_the_review": "Please refer before sections\n\nChanges:\nIn the Sec 5.2 (Median Layer...): Third line \"MeanLayer Could Show some more advantages against MeanLayer\"",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "the paper analysed behaviours of the last linear layer of pre-trained convolutional neural networks in the settings of continual learning where either new instances are provided in new episodes or new classes are given in new episodes. Based on arguments and observations provided in the paper, the authors proposed to constrain the weight matrix in the last linear layer to only have unit-length vectors, so that the lengths and biases of these vectors won't introduce any semantic drifting in continual learning.",
            "main_review": "1. I am not clear on why using neural networks became essential in this study. \n\nGiven that the feature extractor part of a given neural network is frozen, and the paper doesn't provide any insight on feature learning during continual learning, I'd recommend the authors to start from simple linear models, including logistic regression, and SVMs. In that case, the impact of the neural network architectures can be ruled out, and the conclusion could be clearer.\n\n2. As mentioned later in the paper, arguments made regarding the lengths and the biases of vectors in the weight matrix in the last layer don't seem consistent across various settings and datasets in continual learning.\n\nPersonally, I think the main issue is that the learnt feature spaces are drastically different within the selected models, and the confidence of the top linear layer in classification also varies, therefore, when only studying the top linear layers, behaviours may not be consistent. \n\nThe secondary issue is that the feature vectors are all in very high-dimensional space where, with high probability, vectors are equal-distant from each other, which causes trouble and issues when analysing their relations. That probably also explains why the proposed 'MedianLayer' performed similarly to the previously proposed 'MeanLayer'\n\n3. From the experiments and analyses in the paper, as also is mentioned in the discussion and conclusion section, we can see that classic prototype-based approaches still stand out, and the proposed methods don't add much more value to them, either performance or understanding in terms of their behaviours in continual learning. ",
            "summary_of_the_review": "I have major concerns about the clarity of messages conveyed in the paper, and also the insights that this paper could potentially provide on continual learning if the paper was accepted. Therefore, I do not recommend accepting this submission.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}