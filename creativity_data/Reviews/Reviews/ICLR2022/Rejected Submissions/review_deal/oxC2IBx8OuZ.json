{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper proposes “Continual Federated Learning (CFL)” to study time evolving heterogeneous data. To do this the authors introduce time-drift to capture data heterogeneity across time. The authors also present some preliminary convergence results. Finally, the authors carryout numerical experiments in time-varying and heterogeneous settings. The reviewers identified the following strengths: (1) combining FL and CL is interesting, (2) the development of a new algorithm and providing some initial analysis is a good step. They also identified weaknesses as follows: (1) limited technical novelty as the use of replay buffer is quite standard, (2) cumbersome and not easy to interpret results, (3) lack of time evolving patterns with a common component (4) lack of different metrics that demonstrate how the algorithm is able to maintain accuracy as time-shifts occur, (5) lack of questionable assumptions. The reviewers had a very bimodal view advocating acceptance with a score of 8 and 2 advocating a rejection and neither group changed their opinion. Although the authors thorough responses did alleviate the concerns IMO. My own reading of the paper is that this is an interesting paper working on an emerging area. However, I must agree with some of the reviewers that the final conclusions are not easy to interpret, and the assumptions are not fully motivated. After this is carried out, I think the novelty of the paper can also become much clear. Therefore, I cannot strongly advocate acceptance of the paper in its currently state given the scores. However, I very strongly encourage the authors to submit to a future ML venue after addressing the remaining comments of the reviewers. I would also like to commend the authors for a very strong rebuttal sorry the final decision couldn’t be more favorable given the borderline ratings and the aforementioned issues."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes to study time evolving heterogeneous data, and proposes Continual Federated Learning (CFL) to address this problem. Their analysis achieves this by introducing time-drift to capture data heterogeneity across time. Convergence results are presented followed by numerical results on time-varying and heterogeneous settings. \n",
            "main_review": "STRENGTHS:\n\n- The paper introduces clearly the problem and contribution, while clearly stating differences with state of the art in FL and CL. \n- The paper bridges between these two frameworks, and proposes a clear algorithm to learn from time evolving data. \n- Analyses and guarantees are provided under full knowledge of $f_t$\n\nIMPROVEMENTS:\n- I would suggest discussing how to extend CFL for the setting when clients participate at most once during training. I saw the comment in the experimental section but it would be nice to have a remark on the theoretical section describing it. \n- Time evolving patterns could have a common component across clients. It would be interesting to see experiments involving data partitions across time capturing this king of realistic trends. For example on Twitter data each user tends to have a drift (their own posting behavior) but there is also a time component (trending news, etc. )\n- There is no analyses on the real algorithm. How does CFL with specific function approximation behave? what is $R$ for the considered estimation methods? Perhaps it is not tractable but at least a connection, or a remark on this aspect, could make the transition between theory and experiments more smooth. \n-  Given the time evolving nature of data, it would be good to see different metrics (not only final accuracy) that represent how the algorithm is able to maintain accuracy as time-shifts occur. \n\nMinor comments: \n- I would suggest adding a subscript t in equation (2) to indicate that it is a time-evolving objective. \n",
            "summary_of_the_review": "This is a paper that clearly defines a problem in Federated Learning and proposes to extend existing tools from continual learning to this setting. The problem is well motivated, and clearly formulated. Convergence guarantees are interesting but it would be better to have the real bounds for the practical algorithms used, bounds that account for the error estimation of $f_t$. This would allow to see how practical the algorithm is in real settings. Experiments are consistent with claims and show the potential of this framework.\n\nMy score is based on above comments, but I think several of these can be addressed during the rebuttal. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper presents continual federated learning (CFL) to address the issue that data at clients in FL may vary over time. The main objective of CFL is to optimize the time-aggregated objective across multiple clients. While historical objective functions are usually not available, the paper considers a surrogate objective that approximates the original historical objective. A theoretical analysis is presented that takes into account the approximation error (referred to as information loss in the paper) and the time drift in local objective functions. Experiments were also conducted that show core set methods to perform well.",
            "main_review": "**Limited novelty:** The technical novelty of this paper is relatively limited. Using a replay buffer to approximate historical objectives is a well-known approach in continual learning. Extending it to FL seems to be straightforward as long as the replay buffer remains local to each client. The theoretical analysis is somewhat interesting but it relies on strong assumptions such as convexity (more details below), which does not hold for deep neural networks. Furthermore, the result is a bit cumbersome and difficult to interpret, and the analysis technique and result appear to be quite similar to Yin et al. (2020b).\n\n**Unrealistic assumptions:** It is evident that objectives related to deep learning models are not convex, so it would be good to analyze the convergence of non-convex objectives as well. Moreover, I feel that the assumption that the time drift is independent across both $t$ and $i$ (Remark 3.2) is a fairly strong assumption. Usually, the data varies gradually over time, so the time drift should also change gradually over time $t$, instead of being independent for each $t$. I further do not understand why $\\delta_i$ needs to be zero-mean. Usually an upper bound of the gradient drift across clients is sufficient for the analysis. In general, considering gradient drifts as random variables is problematic, since you are talking about the full (i.e., non-stochastic) gradients in the definition of drifts. These gradients only depend on the model parameter $\\omega$ and there should be no other random source (unless you consider the time evolution of data to be random, but even then it should be at least Markovian instead of fully independent).\n\n**Interpretation of results:** The results are generally cumbersome. It would be worthwhile to see whether some of the terms can be simplified in the $\\\\mathcal{O}(\\\\cdot)$ notation. I do not understand how Section 4.2 is related to time-varying scenarios. In particular, it is not clear why setting $p_{t,i}=1$ would eliminate $R$. Intuitively it does not seem to make sense, since the information loss (upper bounded by $R$) should affect the convergence even if $p_{t,i}=1$. I also do not understand what \"CFL methods accelerates the convergence by reducing the variance term\" means in Remark 4.5. While I see that the result in Theorem 4.4 has less terms compared to the result in Theorem 4.2, it is unclear how those terms are related to the variance.\n\n**Experiments:** When talking about generative methods, the paper mentions \"Maintaining a core set for each client may become impractical when\nlearning scales to millions of clients\". I'm not sure why the core set needs to be maintained collectively across different clients, and if this is the case in the core set method evaluated in the experiments, it may cause privacy issues. It seems sufficient for each client to separately select and manage its own core set. In other words, assuming that each client has a fixed amount of storage, whenever new data arrives, it has to delete some old data. The client can choose to delete the data samples that are less representative, and increase the weights of the remaining representative data samples. In this way, a core set would be constructed on each client alone, without involvement of other clients, so there will not be a scalability issue. In general, the use of replay buffer (e.g., in the core set method) for continual learning is quite standard.\n\nMinor: The paper should have a conclusion section highlighting the main results and findings.",
            "summary_of_the_review": "While the topic is interesting, the paper has limited novelty, unrealistic assumptions, and hardly interpretable results.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces the Continual Federated Learning framework that allows capturing time-evolving heterogeneity of FL. The authors introduce a new formulation of the problem and propose a carefully chosen approximation to work with the new problem. Also, the authors provide theoretical analysis for strongly convex and general convex settings. At the end of the paper, they provide experimental results for deep learning models.",
            "main_review": "This paper is well-written. It is easy to follow the narration, all assumptions are clearly described. The motivation of the problem is explained in detail. The notation might be confusing, for example $\\Delta \\boldsymbol{\\omega}_{t, i}=\\boldsymbol{\\omega}_{t, i, K}-\\boldsymbol{\\omega}_{t}$ has three subscript indexes, which is not comfortable to read. It might be useful to use superscript. \n\nTable 1 is illustrative, but it can be useful to add more paper with analysis of FedAvg, such as https://arxiv.org/pdf/2006.04735.pdf. It is not clear what is the CL rate of Yin et al. (2020b). Assumption 1 is not well-described. \nAssumption 1 (Smoothness and convexity). Assume local objective functions $f_{t, i}(\\boldsymbol{\\omega})$ are $L$-smooth, and in some conditions, $\\mu$-convex. If a function $f_{t, i}$ is both $L$-smooth and $\\mu$-convex, then it satisfies $\\frac{1}{2 L}\\left\\|\\nabla f_{t, i}(\\mathbf{x})-\\nabla f_{t, i}(\\mathbf{y})\\right\\|^{2} \\leq f_{t, i}(\\mathbf{x})-f_{t, i}(\\mathbf{y})-\\nabla f_{t, i}(\\mathbf{x})^{T}(\\mathbf{x}-\\mathbf{y})$, and $L \\geq \\mu$\n\nIn the formula, there is no any $\\mu$. It can be useful to have definitions of $L$-smooth function and $\\mu$ strong convexity. \n\nAssumption 2 is limited. \n\nAssumption $\\mathbf{2}$ (Bounded noise in stochastic gradient). Let $g_{t, i, k}(\\boldsymbol{\\omega})=\\nabla f_{t, i, k}(\\boldsymbol{\\omega})+\\boldsymbol{\\nu}_{t, i, k}$, where $\\boldsymbol{\\nu}_{t, i, k}$ is the stochastic noise of client $i$ on round $t$ at $k$-th local update step. We assume that $\\mathbb{E}[\\boldsymbol{\\nu} \\mid \\boldsymbol{\\omega}]=0$, and $\\mathbb{E}\\left[\\|\\boldsymbol{\\nu}\\|^{2} \\mid \\boldsymbol{\\omega}\\right] \\leq \\sigma^{2}$ \n\nIn the paper https://arxiv.org/pdf/1901.09401.pdf, it is shown that bounded variance assumption cannot capture all settings. In the paper https://arxiv.org/pdf/1909.04746.pdf, all results do not require a bounded variance assumption. \n\nAssumption 4 is questionable.\n\nAssumption 4 (Bounded information loss). We assume the information loss $\\Delta_{t, i}(\\boldsymbol{\\omega})$ can be bounded by an arbitrary non-negative value $R$, i.e. $\\left\\|\\Delta_{t, i}(\\boldsymbol{\\omega})\\right\\| \\leq R$.\n\nIt seems not realistic to have a constant bound for information loss, can you please show when this assumption holds in practice? \n\nTheoretical results seem to be sound. Unfortunately, this paper does not propose any non-convex analysis. This part is needed since experiments are done only for deep learning models, which are non-convex. \n\nThis paper has a wide set of different experiments. A broad comparison of different approximation approaches is done. Moreover, the authors compare a new method with other methods and results show that the new method outperforms other methods. It might be interesting to compare with a large number of federated learning algorithms. \n\nThe main issue of the experimental part is the lack of convex and strongly convex models. The theory is done only for convex and strongly convex settings, but experiments are done for deep learning models, so experiments cannot support the theory. \n",
            "summary_of_the_review": "This paper proposes a novel framework and considers the important problem. The theoretical results are obtained only for convex and strongly convex cases. Some assumptions are questionable and analysis can be generalized. Experiments are done only for deep learning models and cannot support the theory. \n\nI think that novelty of the paper is significant, but the paper has some issues. Overall, the paper is marginally above the acceptance threshold. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors study Federated Learning for time-evolving data. In particular, they study gradient based methods for learning parameter vectors and characterize their performance in terms of the approximation quality of a noisy gradient oracle. Numerical experiments compare the performance of the proposed method with existing FL methods. \n",
            "main_review": "My main concern is about the novelty brought by the paper: \n\n* As the first main contribution, authors list a novel CFL framework. I assume that authors refer to Eq. CFL as t\nhe \"CFL framework\". However, it seems that (CFL) is just a special case of the general FL objective (1). \nMaybe authors mean by CFL framework the data access model, i.e., online gathering of Local datasets over time? \nIf (CFL) framework does not target an online data access model, I don't see the fundamental difference \nbetween (CFL) and total variation type models that have already been proposed, e.g., in \n\nA. Jung, \"Networked Exponential Families for Big Data Over Networks,\" in IEEE Access, vol. 8, pp. 202897-202909, 2020, doi: 10.1109/ACCESS.2020.3033817.\n\nSarcheshmehPour, Y., Tian, Y., Zhang, L., and Jung, A., “Networked Federated Multi-Task Learning”, <i>arXiv e-prints</i>, 2021. https://arxiv.org/abs/2105.12769\n\n\nD. Hallac, J. Leskovec, and S. Boyd, Network Lasso: Clustering and Optimization in Large Graphs, Proceedings SIGKDD, pages 387-396, 2015.\n\n\nThese papers consider local models assigned to nodes of a graph or networks. These nodes could represent different time periods of the time-evolving datasets.\n\n* As the second main contribution authors list a convergence analysis of a gradient method for (CFL). However, it is not clear how the resulting convergence rates are better than what can be obtained from existing analysis techniques for (online) SGD of strongly convex functions, see e.g., \n\n[1]Rakhlin, A., Shamir, O., and Sridharan, K., “Making Gradient Descent Optimal for Strongly Convex Stochastic Optimization”, <i>arXiv e-prints</i>, 2011. https://arxiv.org/abs/1109.5647\n\nThe convergence rates depicted in Table I need more discussion. It is not clear to me how Table I shows that the proposed convergence rates are substantially \nbetter than rates of known FL methods. \n\n\n* As the third main contribution authors mention approximation techniques. However, it is unclear what precise approximation \ntechniques are proposed for solving (CFL). The relevant Section 3.2 only introduces a measure (information loss) for the approximation quality but \ndoes not discuss how precisely these approximations will be constructed for (CFL). \n\n* The main theoretical results of the paper are bounds on the number of iterations/rounds required to achieve prescribed accuracy. These bounds involve several parameters used by Assumption 1 - 4. However, i do not see how the current numerical experiments verify these bounds on the required rounds for achieving prescribed accuracy. \n\nThe clarity of presentation and quality of language needs improvement: \n\n* what is the output of Algorithm 1 ? Is Algorithm 1 meant to be run in an online fashion ? Otherwise the time horizon T should be listed as input parameter. How precisely is S_{t} constructed? The summation in step 6 seems to have flipped a \\tau for a t in the subscript of \\omega \n\n* \"...St is a subset of clients sampled from all clients set...\" How precisely is this set sampled ? \n\n* what is a \"cross-device setup\"?\n\n* \"We give the formal definition of CFL framework in Algorithm 1.\"  pls avoid the term \"framework\" when you actually mean a specific algorithm (your new algorithm 1) \n\n* \"...the previous local object functions cannot be properly approximated.\" ps provide more justification for this \"non-approximhatability\" \n\n* Definition 3.1 talks about approximating loss functions but Eq. (3) is about gradients \n\n* \"To analyze Equation (2) and Algorithm 1 in-depth, we propose the Gradient Noise Model...\" It seems a bit unusual to use a gradient noise model for analysing an  algorithm. The gradient noise model might be prescribed by the application setup (data access model) \n\n* should the LHS of (4) and (5) involve the gradient of local loss functions instead of the global loss function ? \n\n* \"...and in some conditions, μ-convex.\" \n\n* Assumption 2 and 3 involve conditional expectations given parameter vector \\omega. Pls provide more details about the proability distribution of the random variable \\omega. \n\n* There should be more separation between the cells of the last row in Table I. \n\n* \"We prove this comment...\" I would rather say to prove a theorem/lemma or claim. \n\n* \"..can be bounded by an arbitrary non-negative value...\" So we can choose this value arbitrarily small ? \n\n* \"... we analyze the theoretical performance of Algorithm 1 ...\" \n\n* \"..., despite that the term induced by information loss concurrently trades off the optimization....\"  Pls refer to the term using \\eqref{}\n\n* what is a \"...regular linear convergence term...\"?\n\n* \"...the model instead reaches the neighborhood of...\" Do you mean \"iterates\" by \"model\"?\n\n* what is a \"...smoother optimization phase.\"?\n\n* \"We consider to federated learn ...\"\n\n* \"...this (most) challenging time-varying scenario mimics the realistic client data sampling scheme (from some underlying distributions). \" in what precise sense is this the most challenging scenario ? \n\n* \"Note that the trade-off between Hessian estimation and computational overhead constrains the practical feasible of such approach.\" Unclear \n\n* \"... as a method to approximate diagonal Hessian matrix, is slightly preferable than Fisher Information Matrix, though the latter one involves less computation.\"\n\n* what is \"...challenging non-overlapping time-varying heterogeneous data\" ? \n\n* \"...we are the first to provide such theoretical guarantees ...\" what precisely do you mean by \"such guarantees\"?",
            "summary_of_the_review": "My main concern is about the novelty brought by the paper: \n\n* As the first main contribution, authors list a novel CFL framework. I assume that authors refer to Eq. CFL as t\nhe \"CFL framework\". However, it seems that (CFL) is just a special case of the general FL objective (1). \nMaybe authors mean by CFL framework the data access model, i.e., online gathering of Local datasets over time? \nIf (CFL) framework does not target an online data access model, I don't see the fundamental difference \nbetween (CFL) and total variation type models that have already been proposed, e.g., in \n\nA. Jung, \"Networked Exponential Families for Big Data Over Networks,\" in IEEE Access, vol. 8, pp. 202897-202909, 2020, doi: 10.1109/ACCESS.2020.3033817.\n\nSarcheshmehPour, Y., Tian, Y., Zhang, L., and Jung, A., “Networked Federated Multi-Task Learning”, <i>arXiv e-prints</i>, 2021. https://arxiv.org/abs/2105.12769\n\n\nD. Hallac, J. Leskovec, and S. Boyd, Network Lasso: Clustering and Optimization in Large Graphs, Proceedings SIGKDD, pages 387-396, 2015.\n\n\nThese papers consider local models assigned to nodes of a graph or networks. These nodes could represent different time periods of the time-evolving datasets.\n\n* As the second main contribution authors list a convergence analysis of a gradient method for (CFL). However, it is not clear how the resulting convergence rates are better than what can be obtained from existing analysis techniques for (online) SGD of strongly convex functions, see e.g., \n\n[1]Rakhlin, A., Shamir, O., and Sridharan, K., “Making Gradient Descent Optimal for Strongly Convex Stochastic Optimization”, <i>arXiv e-prints</i>, 2011. https://arxiv.org/abs/1109.5647\n\nThe convergence rates depicted in Table I need more discussion. It is not clear to me how Table I shows that the proposed convergence rates are substantially \nbetter than rates of known FL methods. \n\n\n* As the third main contribution authors mention approximation techniques. However, it is unclear what precise approximation \ntechniques are proposed for solving (CFL). The relevant Section 3.2 only introduces a measure (information loss) for the approximation quality but \ndoes not discuss how precisely these approximations will be constructed for (CFL). \n\n* The main theoretical results of the paper are bounds on the number of iterations/rounds required to achieve prescribed accuracy. These bounds involve several parameters used by Assumption 1 - 4. However, i do not see how the current numerical experiments verify these bounds on the required rounds for achieving prescribed accuracy. \n\nThe clarity of presentation and quality of language needs improvement: \n\n* what is the output of Algorithm 1 ? Is Algorithm 1 meant to be run in an online fashion ? Otherwise the time horizon T should be listed as input parameter. How precisely is S_{t} constructed? The summation in step 6 seems to have flipped a \\tau for a t in the subscript of \\omega \n\n* \"...St is a subset of clients sampled from all clients set...\" How precisely is this set sampled ? \n\n* what is a \"cross-device setup\"?\n\n* \"We give the formal definition of CFL framework in Algorithm 1.\"  pls avoid the term \"framework\" when you actually mean a specific algorithm (your new algorithm 1) \n\n* \"...the previous local object functions cannot be properly approximated.\" ps provide more justification for this \"non-approximhatability\" \n\n* Definition 3.1 talks about approximating loss functions but Eq. (3) is about gradients \n\n* \"To analyze Equation (2) and Algorithm 1 in-depth, we propose the Gradient Noise Model...\" It seems a bit unusual to use a gradient noise model for analysing an  algorithm. The gradient noise model might be prescribed by the application setup (data access model) \n\n* should the LHS of (4) and (5) involve the gradient of local loss functions instead of the global loss function ? \n\n* \"...and in some conditions, μ-convex.\" \n\n* Assumption 2 and 3 involve conditional expectations given parameter vector \\omega. Pls provide more details about the proability distribution of the random variable \\omega. \n\n* There should be more separation between the cells of the last row in Table I. \n\n* \"We prove this comment...\" I would rather say to prove a theorem/lemma or claim. \n\n* \"..can be bounded by an arbitrary non-negative value...\" So we can choose this value arbitrarily small ? \n\n* \"... we analyze the theoretical performance of Algorithm 1 ...\" \n\n* \"..., despite that the term induced by information loss concurrently trades off the optimization....\"  Pls refer to the term using \\eqref{}\n\n* what is a \"...regular linear convergence term...\"?\n\n* \"...the model instead reaches the neighborhood of...\" Do you mean \"iterates\" by \"model\"?\n\n* what is a \"...smoother optimization phase.\"?\n\n* \"We consider to federated learn ...\"\n\n* \"...this (most) challenging time-varying scenario mimics the realistic client data sampling scheme (from some underlying distributions). \" in what precise sense is this the most challenging scenario ? \n\n* \"Note that the trade-off between Hessian estimation and computational overhead constrains the practical feasible of such approach.\" Unclear \n\n* \"... as a method to approximate diagonal Hessian matrix, is slightly preferable than Fisher Information Matrix, though the latter one involves less computation.\"\n\n* what is \"...challenging non-overlapping time-varying heterogeneous data\" ? \n\n* \"...we are the first to provide such theoretical guarantees ...\" what precisely do you mean by \"such guarantees\"?",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}