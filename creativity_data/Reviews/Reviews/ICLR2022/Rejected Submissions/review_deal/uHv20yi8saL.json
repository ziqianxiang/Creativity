{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The submission cannot be accepted as there seems to be a mistake in the proof of the main contribution (Theorem 2)."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper works on extending the monotonic improvement guarantees of PPO to the multi-agent setting.",
            "main_review": "Improvements and Questions:\n- 0.1 Is a pretty standard clipping value, higher values are frequently not used for the reasons pointed out in this paper. I would have been very curious to see an ablation in the opposite direction, towards values < 0.1 since presumably the trust regions need to be smaller as the number of agents increase. Note, I am not suggesting that I would raise my score if this was done or requesting extra experiments, only that this would make for a better paper. \n- Proposition 4 and the subsequent discussion is slightly confusing to me; I accept that both admit unique fixed points under appropriate assumptions and so estimate the advantage identically at that fixed point. However, the assumption underlying the use of extra information is to make the learning of the value function easier; is the implication here that there are not effects of centralized value functions on the learning?\n- In Fig. 1d I find it surprising that the number of epochs appears to barely affect the total variational distance. This seems to suggest in turn that a large number of epochs should accelerate learning when the clipping ratio is 0.1; did you observe this?\n- What values are the number of epochs fixed to in Fig. 1b and c?\n- How does policies usually being recurrent in these settings factor into your results? \n\nClarity: \n- The x axis on most of the SMAC graphs should be in scientific notation. \n- The y axes on the SMAC graphs should probably not have underscores.\n- In the legend of Fig. 4 and 5, it’s not clear what the (4) is in all the legends.\n- Section 6.2 is written slightly confusingly in that it essentially says “a sufficient condition can be constructed to constrain independent ratios” and then follows up to say “ratio clipping is not sufficient to constrain independent ratios.” I think I understood what the author mean, that the estimation isn’t perfect so the constraint is not maintained, but I want to draw their attention to it having been confusing as a slight rewriting to clarify why the sufficient condition is not sufficient might be helpful. ",
            "summary_of_the_review": "A good paper that helps explain some of the recent results studying on-policy methods in MARL.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper investigates how to enforce the trust-region constraint by bounding independent ratios based on the number of agents for cooperative multi-agent reinforcement learning. The authors also show that the surrogate objectives of IPPO and MAPPO are essentially equivalent when their critics converge to a fixed point, which is also supported by the empirical results.",
            "main_review": "Strength:\n\n1. The paper is written clearly, and the technique is relatively straightforward.\n2. The analysis of ratio constraints between MAPPO and IPPO is interesting.\n\nWeakness:\n\n1. The paper considers the fully observable and cooperative case, which means all the agents have the same goal based on the same information. Therefore, it seems trivial to obtain the key result of the paper \"bounding independent ratios based on the number of agents\". Maybe the authors can further discuss the more general cases, like partial observation or competitive cases.\n2. The authors compared the MAPPO and IPPO on different SMAC. I think more experiments and baselines are required to verify the results. At least, the  JR-PPO should be included to show the differences between joint ratio and independent ratios.",
            "summary_of_the_review": "In summary, I think this paper has some interesting results but can be further improved on both theoretical and experimental sides.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper provides analysis showing monotonic improvements when in cooperative MARL settings, where independent, as opposed to joint ratios (over agents) are used. From a single agent’s perspective, a non-stationary distribution is experienced since other players are simultaneously performing updates to their policies, breaking the standard monotonic improvement property in TRPO. The authors’ propose a surrogate objective for decentralized policies, and show that the improvement in expected return can be bounded in terms of the sum of these (decentralized) surrogate objectives and a term proportionate to the total variation divergence between the 2 policies---analogous to the result by Schulman et al in 2005. Similarly, the authors proceed by showing that the TV divergence between policies can be bounded by enforcing constraints on independent ratios, where the strictness of these bounds depends on the number of agents. The trust region constraint is then split (independently) over all agents, and the authors show that prior methods like IPPO and MAPPO maximize an objective consistent with the proposed theory.",
            "main_review": "The theory explains some of the success (monotonic improvement) of IPPO and MAPPO. The motivation is clear, derivations are easy to follow, and is to the best of my knowledge, novel and non-trivial.\n\nHowever, while I like the theory presented, I am a little more skeptical with the impact of this paper, beyond reminding practitioners to decrease clipping ranges when there are more agents. I have a few minor gripes/questions\n1) Section 6.3 seems fairly out of place and not in line with the central message of this paper (which is about monotonic improvement, as opposed to being about IPPO or MAPPO specifically). \n\n2) Minor presentation issues. (i) Axis and labels on graphs are way too small (ii) Indices of summation can be explicitly stated for clarity. (iii) In section 6.1, is there a particular reason for using u^k as opposed to a^k? (iv) Why is the index k’ used in the definition of the surrogate objective and how is this different from k? (v) It would be very helpful to explain a little about the abbreviations used in SMAC (e.g., 10m vs 11m) etc, especially since these involve the number of agents (which is the key focus of this paper).\n\n3) I found the experiments section quite difficult to follow. The first set of experiments (clipping and ratio changes) shows that clipping roughly bounds independent ratios if *hyperparameters are properly set*. These hyperparameters include optimization epochs and clipping range. It is not clear what “properly” means here. Further, I think it would be helpful to explicitly state why this disagreement with theory occurs.\n4) The total variation reported in the second section of the experiments are based on samples collected by the behavior policy. Is this a good surrogate for the “true” TV between policies?\n\n5) In the last experimental section, the authors report that “as the number of agents increases … empirical returns drop from nearly 20.0 to 17.5”, presumably to show that having too large a trust region (due to there being too many agents) would negatively impact performance. This comparison does not seem fair, since these are 2 very different scenarios and perhaps, even the optimal policy would do worse in the latter case. Maybe a better comparison would be to compare clipping over *joint* policies (effectively fewer agents), but in the same environment, to decentralized policies. \n",
            "summary_of_the_review": "I recommend this paper for acceptance. The work is novel and does not have any glaring faults apart from some of my (possibly to-be-clarified) doubts with the experiments. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper tries to provide a theoretical monotonic improvement guarantees for  IPPO and MAPPO and shows enforcing independent trust region constraints could enforce the trust region constraint over joint policies. The empirical results are also provided to support the hypothesis.",
            "main_review": "**Strengths**\n\n- Decentralized policy learning with monotonic joint policy improvement is a very important problem for MARL.  \n- A theoretical understanding for the good performance of IPPO and MAPPO is also desirable. \n\n**Problems**\n\n- The main contribution is Theorem 2, but I think there might be some mistakes in the proof of Theorem 2. In the deductions at the top of the page 14, from the fourth line to the fifth line in the equations,   $r(s_i) + \\cdots$ **is not equal** to $A_{\\pi_j}(s_i, a_i)$. Although you have mentioned that you use an approximation for $A_{\\pi_j}(s_i,a_i)$ in the footnote, I think it is inappropriate to use such an approximation in the proof especially when this is the main contribution of this paper. Moreover, this approximation actually ignores the *non-stationarity* caused by independent learnings which is the major obstacle for this problem in theory. \n\nThis is the major issue of this paper. Please clarify if I misunderstood something. \n",
            "summary_of_the_review": "The approximation is inappropriate which makes the contribution of the paper meaningless, unless I left something important.\n\n### After rebuttal\n\nThere is an error in the proof of Theorem 2 which is claimed as the major contribution of this paper.  During rebuttal, the authors changed these equations (10 -15) several times, but unfortunately none of them are correct. In the latest revision (from equation 13 to 14), the $new$ definition of $A_{\\pi_j}$ is given (the definition below equation 15), but it does not have any actual meaning (i.e., it is *not* an advantage function), just a function by definition. This DOES NOT accord with the learning of IPPO, MAPPO, or any other MARL methods I know. \n\nThus, I keep my score unchanged. \n",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}