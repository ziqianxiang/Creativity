{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper exposes a method for video compression based on multi-head models.\nThe reviewers seem to agree that the results are interesting, and worth publishing.\nOn the other hand, there are many concerns raised on the quality of the writing, with grammatical mistakes and confusing parts. The motivation for the multi-head models, as well as its novelty, has been questioned in all reviews. Although the authors rebuttal has lead some reviewers to increase their score, it's still very concerning that authors needed to explain the main point of the paper to each reviewers. I think that the authors should polish this paper, taking into account the reviewers feedback, which would make a stronger paper, and submit it again in a future venue. I therefore recommend reject for this paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes an ensemble-based video compression model to capture the predictive uncertainty of intermediate predictions. A loss is constructed to encourage diversity between ensemble members, and the paper investigates the benefit of incorporating adversarial training in video compression. The experimental result shows that the proposed model can save more than 20% compared to DVC Pro. ",
            "main_review": "(+) Experimental results suggest that the ensemble and multihead based proposed method outperforms prior works. \n(-) Novelty of the paper is not clear. It seems that the general framework of the proposed compression scheme follows DVC but with multihead mv decoder based on equally-weighted Gaussian mixture. \n(-) The ensemble-based idea does not seem original as there have been several prior networks (Lakshmnarayanan et al, Agustsson et al. etc) as alluded by the authors. The difference between the proposed and prior work should be concisely and explicitly described. \n(-) Readability should improve with the notation used in the text (section 3.1) correlates with the figure 1. \n(-) Should make a performance comparison with the recent paper which is readily available on archive\nMissing reference \nHao Chen, Bo He, Hanyu Wang, Yixuan Ren, Ser-Nam Lim, Abhinav Shrivastava, NeRV: Neural Representations for Videos NeurIPS 2021\n",
            "summary_of_the_review": "It is difficult to pinpoint the novelty of the proposed compression algorithm as it stitches various ideas from various areas (ensemble, multi-head, FGSM) that have already been proposed. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper works on end-to-end deep learning video compression. The authors study the inherent uncertainty and accordingly propose a so-called ensemble approach which is in effect multi-head decoder. A so-called ensemble-aware loss is proposed to encourage the diversity between ensemble members. Further, adversarial training is incorporated. Experiments show that the proposed model outperforms previous state-of-the-art models such as DVC Pro (Lu et al., 2020b) and Lu et al. (2020a), and the ablation study proves the effectiveness of each module.\n",
            "main_review": "Strengths:\n+ The paper is well-structured. \n+ The proposed model outperforms previous state-of-the-art models of deep learning video codecs, and the ablation study proves the effectiveness of each module.\n\nWeaknesses:\n- There are quite some theoretical analysis in the paper to support the need of using ensemble/multi-head, which seems nice, but I am not sure if this is necessary. The idea of multi-head has been widely used in transformer models and it is well-known that this can significantly improve performance in practice. Can the authors better contrast their idea with the multi-head idea used in typical transformers?\n- In Eq 10, what does i stand for? each pixel? Also, why take summation of j=1..h, isn't the min is over j which means at 1 single location, only 1 prediction is used for computing L2? Further it would be very helpful if the authors explain how this is designed beyond just citing Lee et al. Why this loss function can encourage diversity? Pls add this in the main text as this is one of the main contributions of this paper.\n- For results in Fig 3, why the proposed method's curve stops earlier than other approaches? How would the method compare with other methods when bpp is high such as> 0.15 in (a), and can the proposed approach achieve the overall better PSNR when allowing larger bpp?\n- Compared to traditional codecs, the deep learning compressors have large model size in general, so that hard to deploy on low-capability device. I assume this proposed approach would have similar issue?",
            "summary_of_the_review": "I am on borderline as there are specific concerns outlined above regarding contribution of multi-head this simple idea, presentation of the ensemble-aware loss, results when bpp is high, etc. But I also believe deep codes is a promising direction and we shall encourage more work in this field and may go with a lower bar. If the authors can address my questions, I will lean to accept.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper aims to capture the predictive uncertainty and proposes an ensemble-based video compression approach. In the proposed approach, an ensemble-aware loss is also introduced to seek diversity among ensemble members. Experimental results show its performance.",
            "main_review": "This paper is interesting and a good try as a deep learning method for video compression. The experimental results seem strong. The ablation study looks extensive. However, the reviewer has several concerns.\n\n1, the motivation of multi-head, i.e., the ensemble, is not clear. Why ensemble? What is its benefit?\n2, in the introduction, the authors claim that existing methods suffer from the inaccurate estimation of optical flow. However, the proposed method also employs motion estimation, how can the proposed method avoid this issue?\n3, in the ablation study, multiple heads look useful. In this case, why not use more heads?\n4, poor representation. For example, the figures are not self-contained. One needs to refer to different parts in the texts to understand the figure, such as MV, Res in Fig. 1. There are many wrong sentences with grammar issues. Some are given but they are definitely not all.\na, caption in figure 2, \"are cannot be\"\nb, pp4, \"it follows that the upper ... is given by\"\nc, pp5, MEMSE\nd, pp4, Fig.9e should be Fig.2d?\nf, pp5. Fig.9f should be Fig.2e?\n\n",
            "summary_of_the_review": "In general, this paper solves a classic problem with deep learning, which is interesting. While there are several issues (see the main review section), which prevent the reviewer from scoring it high with the current status.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents an uncertainty-aware video compression framework with an ensemble of MV/residual decoders. To train the network, they use the ensemble-aware loss function which minimizes the loss function for the k best predictions. Moreover, this paper also analyzes underlying uncertainties in video compression, i.e., aleatoric and epistemic uncertainties, with visualization techniques for those uncertainties. Experimental results show that the proposed method can improve the compression performance by about 20% while not significantly increasing the computational complexity.",
            "main_review": "Here are issues or concerns regarding this paper. \n(1) Both F_i and x_i are used to denote the current frame, e.g., in Fig. 2 (a) and in Sec. 3.1. \n(2) What are the differences between the raw prediction and motion compensation prediction? \n(3) Section 3.3 explains that the ensemble-aware loss can be relaxed to have the k-smallest outputs. \nCan the relaxed prediction improve the prediction performance? If the k=1 is the best choice, why is that so? \n(4) There is a broken sentence at the end of Sec. 4.1. \n(5) What are the definitions for the Prediction Refine Net and Reconstruction Refine Net in Fig. 1(b)? \nAre they neural networks that are trained in the framework? \nIf so, does the prediction refine net take multiple predictions and refine them simultaneously? \nIf not, I think the authors should clarify how the underlying uncertainties are predicted and utilized to better compress the video in the entire framework. \n(6) Predictive uncertainties are analyzed by assuming the predictions from multi-head decoders follow the mixture of Gaussian model. \nI think the number of decoders should be sufficiently large to support this claim.\n(7) Check for typos, punctuations, and articles. \n(8) Dependency on the optical flow estimation method. \n(9) Failure cases? \n\n\n\n\n",
            "summary_of_the_review": "Overall, the paper was interesting because of the in-depth analysis and insights. However, I have a few concerns as stated in the main review. I would like to hear the answers to (3), (5), (6), (9) from the authors. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}