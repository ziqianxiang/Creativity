{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This work tries to tackle the problem of anomaly detection across different tasks. To do so, authors employ energy-based models (EBMs) and define an outlier score in terms of the EBM energies, having a shared sparse code for different tasks. This pipeline is tested on some image and video anomaly datasets for industrial inspection.\n\nThe reviewers highlighted some concerns that need to be addressed before the paper is ready for publication. \n\nFirst, a revision could benefit from a rewriting the clearly formalizes the learning problem from page 2 and then discusses about the possible modeling options given i) the task at hand and ii) some efficiency requirements.\n\nSecond, concerning the modeling choices of the proposed pipeline, the motivation behind the choice of EBMs should be strengthened. For example, it is not clear why the proposed sparse coding could be used for any other latent variable probabilistic model. As observed by one reviewer, the pros of having energies instead of probabilities (or just reconstructions from a deterministic autoencoder) is not discussed sufficiently. Additionally, the heuristics of running Langevin dynamics for only 5 steps should be backed up by stronger empirical evidence as it lacks theory, and it should be discussed how much you should run the Markov chain to obtain sensible negative samples.\n\nThird, conclusions over the experiments on the provided benchmarks seem preliminary. For instance, a new revision could benefit from adding a statistical significance analysis to the reported accuracies. I appreciate that authors added further ablation studies including experiments on contaminated data in the latest revision. I suggest them to extend the experimental suite to more benchmarks including the commonly used for anomaly detection."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a model for detecting irregularities in images, such as would occur in manufacturing acceptance testing.  As a form of anomaly detection, the claims made are for a principled modeling approach and an adaptive algorithm quick to learn from just a few samples.   Based on \"energy based models\" for modeling data densities, the paper claims improvements to avoid the need for retraining for new tasks, such as, instead of synthesizing negative samples rom noise, using a more targeted method of “learning from\ninpainting” operation to learn anomalies. \n\n",
            "main_review": "The paper claims a \"principled\" approach to detecting rare samples compared to normal ones.  One would expect that abnormality implies improbability.  The \"principle\" here is that something abnormal is something whose probability is small.  The paper never avails itself of any discussion of  what it means to be \"anomalous\" in terms of probability.  Similarly neither does the evaluation section mention anything about false positive or false negative detection rates. \n\nAs an example of this confusion, the use of the term \"normal\" in the introduction could refer to a normal, that is Gaussian distribution of the non-anomalous population. Fitting a normal distribution to samples, then looking for samples that fall on the tails of the distribution is a conventional method to detect anomalies.  Since this is not what the paper proposes, the authors may want to clarify this at the outset.  However it raises the speculation whether the mean squared error expressed in Equation 8 is just implicitly an appeal to a normal distribution. A quadratic error term is consistent with the use of a Gaussian (normal) distribution. \n\nHonestly I find it hard to tell if the evaluation presented in the paper makes the case for improvement over other deep learning methods, or more conventional image analysis methods.  It appears the main take-away from the evaluation section is the acceptable detection ability on limited number of samples.   How does this method stack up with previous methods when given comparably large numbers of training samples?  ",
            "summary_of_the_review": "In short, the term 'anomaly detection' has been applied to a wide range of unsupervised techniques, with little in common among them.  This literature, using deep learning methods that have no connection to the existing literature that is more than a decade old, calls into question whether the proposed methods are competitive with previous methods that do not originate by applying deep learning techniques.  One really has to look at the history of the field to claim to have made an advance. \n\nMy apologies for a shallow review due to a lack of familiarity with this branch of the field, however there are some basic questions that need to be raised about the lack of connection of the field with the vast work that precedes the current trend in deep learning to really understand the significance of the work. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a framework for anomaly detection and localization that allows fast adaptation to new tasks. \nSpecifically, the authors propose an energy-based model (EBM) with an adaptive sparse coding layer directly trained with normal features of a target task.\n\nA meta-learning process is followed to extract common knowledge across tasks enabling few shots adaptation. \nShrinkage functions, sparse coding with large receptive fields, and learning by inpainting are introduced to improve and accelerate the EBM\ntraining. ",
            "main_review": "Strengths:\n\n- The method adapts to new tasks autonomously;\n- Ablation study and comparison with supervised models;\n- Exhaustive implementation details in the Appendix section.\n\nWeaknesses: \n\n- Experimental analysis is limited to image and video datasets;\n- The mIoU metric is never defined in the paper;\n- Fairly limited scope of competitor methods (which could depend on the limited suitability of other methods in the adopted setting).",
            "summary_of_the_review": "The paper proposes an interesting anomaly detection approach and an experimental evaluation that also involves fully supervised models.\n\nResults are competitive, and some of them appear close to the upper bound performances provided by supervised alternatives.\n\nThe authors also provide an exhaustive description of the architecture and hyperparameters in the Appendix section.\n\nI think the main merit of the proposed method is the ability to achieve satisfactory anomaly detection performance without large availability of normal samples while adapting to new tasks.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes an image classification system, where a set of normal patterns are stored as a \"dictionary,\" and the degree of deviation is used as the anomaly score. \n \nThe overall architecture seems to feature a conventional deep encoder and a pattern matching module that compares the encoded latent vector against the pattern dictionary. The pattern matching is done by solving the lasso regression problem. \n\nThe authors propose a certain online learning approach, following existing few-shot learning methods, and also a synthetic sample generation approach using random perturbation combined with a gradient method. ",
            "main_review": "This paper can be viewed as a proposal of a new image anomaly detection system that combines existing methods. The proposed \"adaptive\" dictionary-based approach is not new. The use of a deep encoder for image analysis is, of course, not new. The term \"energy-based\" does not mean much because any probability distribution can be thought of as energy-based. So the question is whether the combination is innovative or not. \n\nAlthough I appreciate the authors' efforts to develop an industry-application-ready image processing system, I do not think the technical novelty meets the standard that ICLR papers are supposed to have. \n\n\nEq.(2)\nThe sign of ln Z?\n\nEq.(3) \ny is not defined in the generative model in Eq. (1). \n\np.3\n The problem setting should be clearly defined. What are the input and output? The anomaly score must be clearly defined in the main text as part of the problem setting. ",
            "summary_of_the_review": "- Good industrial use-case paper\n- Limited technical novelty -- less innovative combination of known methods. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The author proposes a fast adaptive anomaly detection method using an adaptive sparse coding layer in the few-shot setting. The proposed method outperforms baselines.",
            "main_review": "Strength:\n\n+ The experimental result on two benchmark datasets outperforms most of the baselines.\n+ An ablation study is presented to demonstrate the robustness of the proposed method.\n\nHowever, there are also some places where this paper needs further clarifications:\n- It is not clearly shown in the experiment as to how the technique in Section 3.1 improves the robustness of the network on different types of objects.\n- A small typo in Section 3.1 - visualizations of the hard shrinkage function and SigShrink with different values of $\\tau$ are presented in Fig. 3 rather than Fig. 7.\n- The caption of Table I suggests that “Col 2-5 are fully supervised methods trained with massive normal samples” and are considered as the “upper-bounds”. However, it seems like the first column with AE (SSIM) is able to deliver better results in many categories than these upper bounds? (such as Carpet, Grid, and Bottle).\n- It seems from Table 2 that the proposed method without leveraging any temporal information can achieve even better performance in the CUHK Avenue and the SH-Tech dataset. More discussions are encouraged on the benefit of incorporating such temporal information versus image frames randomly sampled from the target scenes.\n",
            "summary_of_the_review": "To summarize, this paper proposed a fast adaptive anomaly detection framework for anomaly detection in images. The proposed method is technically sound. However, the novelty is limited on the adaptive space coding layer with receptive field, while the rest of the network structure seems to be a big melting pot incorporating the Energy Bassed Model and episodic training in the context of meta-learning based few-shot learning. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper presents an anomaly detection algorithm that uses an EBM (Energy Based Model) to distinguish between 'normal' and 'anomaly'. This model generates pseudo-anomaly instances on-the-fly for each 'normal' instance and then learns to assign low energy to normal instances and high energy to pseudo-anomaly instances. The model is further designed to be able to adapt quickly (few 'normal' labeled examples) to new tasks.",
            "main_review": "Pros:\n1. Presents a well-reasoned set of design choices\n2. Good ablation studies\n\nCons:\n1. Assumes all training data is 'normal'\n2. Lacks experiments with contaminated training data\n\n\nMain Comments\n\n1. Expects all training data to be 'normal' -- effectively makes the algorithm fully supervised since we must manually make sure that all input train data is 'normal'.\n\n2. Should show performance of algorithm when training data is contaminated with anomalies (varying contamination fraction, say, from 0.0 ... 0.10).\n\n3. Section 3.1: \"The sparsity regularization to ... formulated as the mean squared error (MSE) between the original\" -- This is a nice explanation of the design choice.\n",
            "summary_of_the_review": "The paper mixes existing techniques in a nice way to make the overall solution very effective.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}