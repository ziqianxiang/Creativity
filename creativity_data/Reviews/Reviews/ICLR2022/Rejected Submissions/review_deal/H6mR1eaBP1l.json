{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper presents an approach for using prior knowledge to constrain transitions for consecutive time steps and aims to replace conditional random fields for sequence tagging tasks in sequence labeling. However, the paper seems incomplete with no experimental results and analysis to validate the proposed ideas."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors try to propose a `Prior Knowledge Layer' as an alternative to the CRF layer for the standard sequence labeling framework in NLP.",
            "main_review": "This is not a paper, instead technically more like a toy report. The architecture of the entire manuscript is way incomplete, without enough technique detail, not to mention the lost experiment part. Also, the idea of prior knowledge integration is naive.",
            "summary_of_the_review": "Introduction: without a motivation; Related work: not informative; Method: no detail & incomplete; Experiment: missing. Reference: bad formation. So I would recommend a rejection.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a prior knowledge matrix to displace CRF in sequence labeling. The author also claims that this approach is useful for low-resource settings, especially considering using pseudo-labeling.",
            "main_review": "I'm afraid that the idea of this paper is too simple. In fact, utilizing prior knowledge of BIO tagging scheme for safe decoding is very prevalent in practice. For example, I-ORG must follow B-ORG rather than O. Besides, no experiments are found in the paper. The whole paper just consists of 6 pages. It seems that the authors have submitted an incomplete version.",
            "summary_of_the_review": "1, too simple idea, even not a novel one\n2, no experiments",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a new type of classification layer, called the prior knowledge layer (PKL) that estimates the probability distribution of tokens and can incorporate prior knowledge about the prior knowledge of the structure of label sequences. The authors do not validate any claims made in the paper with experimental results, benchmarks, or datasets.",
            "main_review": "Strengths:\n- this paper attempts to address an important problem in sequence labelling of data sparsity, as well as a weakness of CRF classifiers.\n\nWeaknesses: \n- The technical and experimental rigour of this paper is critically lacking. \n- The paper has no experimental section - no benchmarks vs current state of the art, no ablations for the PKM layer, and no validation of any of the claims made about the effectiveness of the PKM layer.\n- For example, these claims are left completely unvalidated: \n-- The number of incorrect label sequences increases exponentially with the length of the label sequence, while the number of correct sequences increases much more slowly. This leads to the fact that the resulting multidimensional array is very sparse.\n-- better generalization capability, especially with a small amount of training data \n-- faster convergence, comparing with baseline model\n- the presentation and communication is also unclear in various areas, including when describing the current literature (e.g. unclear what tasks are being considered for sequence labelling)",
            "summary_of_the_review": "Overall, the paper critically lacks any experimental rigour so it is impossible to evaluate any of the technical claims made.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper formulated an approach to impose valid state transitions from t to t+1 for sequence labeling problems. The proposed approach replaces the usual conditional random fields with what is named as a prior knowledge layer (PKL), which simply multiplies a state transition matrix which zeros invalid transition probabilities. \n",
            "main_review": "Strengths:\n- The authors addressed state transition problems in sequence labeling problems, and proposed an approach that seems sound. This could be useful in semi-supervised learning scenarios when sequences are sparsely labeled at the word level.\n\nWeaknesses:\n- There is no experimental results that validates the proposed approach. The authors should conduct experiments to show that their approach outperforms CRF in the semi-supervised scenarios they proposed.\n- The authors should compare their approach with CRF with partially labeled sequences, e.g., [1].\n\n[1] Tsuboi, Yuta, et al. \"Training conditional random fields using incomplete annotations.\" Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008). 2008.",
            "summary_of_the_review": "I would recommend to reject this paper as the theoretical novelty is insufficient, and there are no empirical results.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Nil",
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}