{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper worked on an important problem (robustness concerning spurious correlations) and proposed a useful method (achieving SOTA worst-group performance without the true group labels). However, the motivation part is weak so that it is unclear why to go from the theoretical/empirical observations to the proposed method (more specifically the contrastive learning part). The novelty is also not very strong as argued by reviewers (the real novelty was not highlighted by the authors and thus cannot easily be appreciated by readers). It is indeed a borderline case but seems to be below the bar of acceptance and the two reviewers staying on the positive sides would not like to fight for it. Since there is still room for improvement, we hope the paper would benefit from a cycle of revisions for a re-submission and the improved version would be accepted in the near future.\n\nBy the way, what GgTx suggested is not really an out-of-scope study, as far as I understood. The authors certainly think that the paper/method has been clearly motivated. This reviewer was asking for a strong motivation, namely, what is missing or what is wrong in existing methods or the SOTA method so that we need/have to apply the proposed method? Without clarifying this point, the paper/method is partially but not fully motivated and the method may look like another alternative though it should be a better one. Instead of showing the better performance, the reviewer would like to see the conceptual advantage of the proposal by understanding what is missing/wrong in the current SOTA method. Therefore, I think this is a great question for the authors to maximize the impact of their work in the end."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper considers the goal of training classifiers that achieve strong worst-case performance across groups with different spurious features, without assuming access to supervision based on the spurious features. The paper proposes a two-step method, which fist trains a model with ERM, then re-trains the model using a supervised contrastive approach where positive and negative samples are selected on the basis of misclassification characteristics of the ERM model. \n\n The method addresses an important problem, and is well motivated & evaluated. In all this is a nice piece of work and I am cautiously happy to recommend its acceptance at this point. I do, however, have a couple of questions I would like to see some answers to (see below). Depending on the answers to these questions, and discussion with other reviewers, I am happy to consider raising my score. \n",
            "main_review": "\nThis paper takes a representation focused perspective on avoiding learning spurious corrections. The main motivation (well backed by experiments on toy datasets) is this: there is a positive correlation between within-class alignment loss, and worst-group error. On its own this observation isn’t hugely surprising, and arguably overlaps with observations in prior work. The novelty of this work comes from using this observation as the inspiration for CnC, a supervised contrastive approach to re-training the ERM model to reduce the within-class alignment loss.\n\nSome positives:\n\n- The paper is well written\n- The method is easy to implement, intuitive, and seems to work pretty well.\n- In section 3 the combination of empirical observation and theoretical bound make the conclusion quite convincing. \n- The method specifically samples hard positive/negative samples. This is potentially an even more important point on the novelty of the method than is currently emphasized [see the second main question below, about SupCon as a baseline]. \n- The logic and ideas in this paper are very linear, making it easy to quickly grasp the main takeaways. \n- The worst-group performance seems to decay slightly better than JTT as the level of spurious correlation increases (Fig. 7). \n\n(For weaknesses, see the questions below).\n\n\n---\n## Questions: \n\nI have *two major questions that I am hoping to see answers to:* \n\nFirst: The motivation for CnC is centered on the class-conditional alignment loss. There is even a bound on the worst-group loss in terms of the average-group and class-conditional alignment loss. So why not replace step 2, and instead fine-tune the model using L_avg_group + L_alignment? Or even just train models from scratch with this loss. It would be good to compare to these. If CnC is simply more empirically successful than this alternative, then it would be good to see this. \n\nSecond: In a related vein to the previous question, how much is CnC buying us as compared to the usual supervised contrastive training? It would be good to see SupCon as a baseline in Table 1. This seems an important baseline, since the main idea of CnC is to pull items from the same class together in feature space, which is also done using SupCon.  The main (even only?) difference is the hard positive/negative sampling approach of CnC. \n\n\n---\n\n## Miscellaneous comments and questions:\n\nThese are just a few things I was curious about. I am not per se asking for any response from the authors, but offer them up in the spirit of constructive feedback:\n\n- What if you iterate your method? That is, CnC samples positives and negatives according the *fixed* ERM model from step 1. What if you repeat step 2 again using the new and improved model obtained from the first step 2 run? Maybe it would just immediately saturate in performance, but I am curious. \n- Is there a way to incorporate spurious attribute information into the positive and negative sampling methods if it were available? \n- Do you have a rationale as to why CnC did worse than JTT for CivilComments? I’m not bothered at all by this result, since I would never ask for across-the-board improved empirical results. But I am curious at to whether any lessons can be learned about the relative strengths and weaknesses of the two methods. I notice that CivilComments has more (8) spurious feature values than the other datasets - could this be related?\n- Perhaps consider using more divergent colors in Fig 6. The different shades appear fine on my compute screen, but are hard to distinguish on a printout (maybe my printer is just bad…). \n",
            "summary_of_the_review": "\n The method addresses an important problem, and is well motivated and evaluated. In all this is a well executed piece of work and I am cautiously happy to recommend its acceptance at this point. I do, however, have a couple of questions I would like to see some answers to (see above). Depending on the answers to these questions, and discussion with other reviewers, I am happy to consider raising my score. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper studies training of models that are robust to spurious correlations without any supervision on spurious correlation revealing example groupings. \nThey observe that representations from an ERM model trained on such data, have strong correlation with the spurious attribute.\nTheir algorithm (CNC) is aimed at repressing spurious attribute information from the representations and was shown to be effective on standard sub-population shift datasets.\nAlso, CNC is shown to be more robust to noise in spurious attribute recovery than the existing methods. ",
            "main_review": "## Strength  \n- The paper is mostly well written and easy to follow. \n- Spurious correlation avoidance without assuming any prior knowledge of spurious features is an important problem with wide impact.\n\n## Weakness   \n**Standard Deviations** are important when reporting worst group accuracy metric. For example, the smallest group in CelebA (with supervised group labels) has only around 100 examples. \nExpect to see std. dev. from at least three runs for all the experiments. \nLooks like all your numbers are from a single run, given the typical std. dev. on these datasets and metric, I cannot judge the significance of your results.\n\n**More Comparisons** needed. There are some existing contrastive regularization based methods [1, 2], perhaps several more. \nAuthors should compare and argue the merits of theirs over others both intuitively or analytically and empirically. \n[1] proposed to learn representations that minimize the divergence between predictions on examples of the same label class but different partition (group).\nIn that regard, I find this work very similar to [1] with some differences as below: \n- [1] regularizes the differences in aggregate prediction probabilities while this paper minimize per-sample differences\n- [1] looks at prediction probability differences and KL measure while this work looks at representation differences and Eucledian distance.\n- [1] uses [3] for partitioning the dataset on spurious attribute while this work only uses the ERM trained base model. \nThe differences to me look only superficial. \n\n**Ablation study** on importance of first stage ERM training is needed. The authors state that the prediction accuracy of the spurious attribute in the case of CelebA is only around 59%.\nI wonder what is the significance of ERM base model at all and what would happen if we instead simply regularize the distances for any pair of points of the same true class (this would be similar to [2]).\n\n**Sensitivity to Stage 1 prediction (Sec 5.3):** \nI do not understand why in Fig. 7 (d), we see the average accuracy also decreasing with p. \nI expect the average accuracy to remain stable or increase as the worst group accuracy deteriorates. \nBoth average and worst group accuracy decreasing could indicate optimization problems?\nAlso, can you intuitively explain why you expect CNC to be more robust than JTT to stage 1 predictions?  \nAlso in Table 1, why is the Avg. accuracy of CNC so much worse than other methods on CivilComments dataset?\n\n## Minor\n- Around expression (5), inconsistency around use of hat: $\\hat L_{align}$ and $L_{align}$.\n- Again around the same expression, stick to using either $\\hat L_{align}(f_\\theta)$ or $\\hat L_{align}(f_{enc})$. \n- The theorem looks intuitive but I could not follow the proof due to notation difficulties. \n\n## References\n1. Ahmed, F., Bengio, Y., van Seijen, H. and Courville, A., 2020, September. Systematic generalisation with group invariant predictions. In International Conference on Learning Representations.\n2. Arpit, D., Xiong, C. and Socher, R., 2019. Predicting with high correlation features. arXiv preprint arXiv:1910.00164.\n3. Creager, E., Jacobsen, J.H. and Zemel, R., 2021, July. Environment inference for invariant learning. In International Conference on Machine Learning (pp. 2189-2200). PMLR.",
            "summary_of_the_review": "I have novelty, significance and experiment rigor related concerns as detailed in my review. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper focuses on improving the model robustness to group shifts without prior group information and bridges the gap to those methods with access to group labels (i.e., GDRO). It identifies the relation between the worst-group performance and representation alignment both empirical and theoretically, which motivates a contrastive approach for improving representation alignment and robustness. Empirically, the proposed method demonstrates improved worst-group performance over existing baselines. ",
            "main_review": "Strengths\n* This paper focuses on improving model robustness to group shifts in a practical setting where group information is not available. The proposed method achieves SOTA worst-group performance to be close to GDRO which uses the true group labels.\n* Some interesting empirical analysis are presented for relating the representation alignment with worst-group performance. \n\nWeakness\n* In general, the observation is not surprising, and the idea of aligning representation for improving model robustness is not novel. There are a lot of work with similar ideas in domain generalization/adaptation literature, e.g., [1], [2]. There’s also a recent work [3] that applies contrastive learning for doing so. A more comprehensive discussion for these related work needs to be included. \n* The assumption of Theorem 3.1 is not well explained and motivated. In particular, the assumption that “the loss function l(x; y) is 1-Lipschitz in x and bounded from above by one.” seems to be necessary and simplify the proof a lot, but does not hold for typical losses like cross-entropy for classification and MSE for regression.\n* Though the proposed contrastive method leads to improved worst-group performance, it seems to decrease the average-case performance compared to baselines. More crucially, neither part of the two-stage method is justified with sufficient motivation and empirical evidence, as detailed below:\n    * Using ERM prediction as the group label is not convincing enough, and it is not clear how it would affect the contrastive part. It could be interesting to more extensively analyze how the label prediction affects the improvement given by the contrastive method, probably using a scientific setup where the label prediction is controlled. \n    * For the contrastive part, the current empirical comparison obfuscates the advantage on its own. To decouple it from the effect of wrong group prediction, it is important to compare in the setting where group labels are available, i.e., GDRO vs GDRO + contrastive. Also, there could be a lot of choices of negative selections but only one is used without sufficient explanations, it would be great to include more explanation or compare with some other possible choices as an ablation study. \n\n\nAdditional questions & comments \n* In the last paragraph of introduction, it is claimed that “...only falling short of GDRO’s worst-group accuracy by *0.3%* absolute…”. However, in Table 1, the gaps between CNC and GDRO are 1.1%, 1.4%, 0.1%, 0.7%, respectively on each dataset, how is the 0.3% gap calculated?\n\n[1] [Domain-Adversarial Training of Neural Networks](https://arxiv.org/abs/1505.07818)\n\n[2] [Domain Generalization with Adversarial Feature Learning](https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Domain_Generalization_With_CVPR_2018_paper.pdf)\n\n[3] [Cross-domain Contrastive Learning for Unsupervised Domain Adaptation](https://arxiv.org/pdf/2106.05528.pdf)\n\n\n",
            "summary_of_the_review": "Overall, the observation of the paper is not novel and the theoretical analysis is rather weak. Though the proposed method leads to improved worst-group performance, it is not well developed and supported with sufficient empirical evidence. Thus, I recommend a ‘reject’ for the paper. \n\n\n++++++++ Post-rebuttal ++++++++\n\nI will increase my score to 5, but I still think the paper can be improved a lot before acceptance as detailed [here](https://openreview.net/forum?id=cVak2hs06z&noteId=rfOvGo4VyL9).\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper discusses a two-stage method for improving a model's subgroup robustness, first training an ERM classifier and then performing contrastive learning on the representations. They provide theoretical justification for this procedure and experimental verification of its performance.\n",
            "main_review": "\nStrengths:\n- it's a good idea to explore the connection between learned representations and subgroup performance\n- they show fairly clearly that in the explored methods, better separated representations often yield better predictions\n- the method seems to perform well experimentally\n\nWeaknesses:\n- I'm not sure I totally buy the proof being that intuitively useful - in particular, due to the bound B on the weight matrix. My hesitancy is because the weight matrix and the representations are learned jointly - in fact, we could get equivalent predictions by scaling the weight matrix down and the representations up. Also, the Lipschitz and boundedness constraints on the loss functions do not really apply in any of the settings explored experimentally.\n- I get a little lost in Sec 5.2. I don't what understand the role of ERM \"predicting the sensitive attribute\" - I thought the point was for ERM to predict the label? and how do ERM's predictions of the sensitive attribute play into the CNC algorithm?\n- there are some training details buried in the appendix which seem worth discussing - for instance the clustering-based prediction from the first step ERM model seems like an unintuitive step which may be fairly important to the functioning of the method. I would like to see this discussed in the main body, possibly with an ablation study. In my experience, clustering approaches can be quite helpful for these types of problems and I would like to know a bit more about the role it plays, given that it is far from the first thing you would think of doing (which would be just using the standard linear layer)\n\nOther thoughts:\n- In Figure 3, the relationship I would really like to see is L_align vs Accuracy: this is the one that makes your point most compellingly\n- In Fig 3c, I disagree with the characterization that high worst group accuracy corresponds to a combination of high I(Y,Z) and low I(A, Z). It looks like WG accuracy is mostly (but not fully) invariant to I(A, Z) in this plot, with the level-colour sets extending horizontally (more or less) across the plot\n- Some of the notation in the proof in 3.2 is a little sloppy - in particular, y is overloaded in the definitions of L_wg and L_avg, both being used inside the scope of the expectation and outside it\n",
            "summary_of_the_review": "The paper can use some cleaning up but the idea is interesting and clearly communicted enough to be of value to the conference.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}