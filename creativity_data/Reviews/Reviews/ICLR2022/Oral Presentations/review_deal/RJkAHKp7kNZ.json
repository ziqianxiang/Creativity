{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Oral)",
        "comment": "All reviewers consistently agree on the high quality of the research presented in this paper, such that it the paper clearly is significantly above the acceptance threshold of ICLR."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents an analysis of camera placement for vision-based manipulators. Specifically it compares the performance of a disembodied third person camera vs. place the camera on the robot's hand/gripper.\n\nThe authors find that the hand camera improves generalization and training performance in the cases where a hand camera still reveals enough information to complete the task.\n\nWhen the hand camera does not reveal enough information to perform the task, the third person camera is still needed and the authors propose to use an information bottleneck to reduce the amount of information used from the third person camera, thereby improving generalization even when it's needed.\n",
            "main_review": "### Strengths\n- Well motivated idea\n- Compelling results\n- Overall clearly written\n- Good ablations and the idea is shown for multiple algorithms and in a wide variety of settings\n- Interesting approach to generalize the hand camera to settings with a higher degree of partial observability\n\n### Weakness\n\n- $$z_\\text{shift}$$ is only explained in the appendix, it should be explained in the main paper.\n- The information bottleneck technique harms performance initially\n\n\n\n### Suggestions for improvement\n\n- In concurrent work, Szot et al (NuerIPS 2021) also used a hand/arm camera to learn manipulation policies and found similar trends. It may be worth citing as additional support for these finding.\n\n- How useful is the data-aug in DrQ for the hand camera? Part of the argument for DrQ is to reduce overfitting of the Q function during training. Perhaps with the hand camera you no longer need aug?\n\n- What about recurrent policies instead of the third person camera?\n\n\nSzot et al: https://arxiv.org/abs/2106.14405",
            "summary_of_the_review": "This paper presents thorough analysis of using a 3rd person camera vs. a hand camera and finds that hand cameras generalize better. I believe this work presents a useful contribution.\n\n\n### Post Rebuttal Update\n\nI thank the authors for their response. I continue to think this is a good paper that should be accepted for publication.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper studies the effect of visual perspective by using the images coming from a camera installed on the hand of the robot in the specific context of robot manipulation from raw observations.  Results demonstrate that such a choice of visual perspective requires no algorithmic changes but can improve OOD generalisation and training efficiency. Of course this does not mean that we abandon altogether the traditional third person perspective as in many cases just having a close-up view of one object may not be enough when making decisions about the scene as a whole. Therefore, they also show that combined with third person perspective with information bottleneck regularisation can improve the OOD generalisation. They show results on six different manipulation tasks adapted from Meta-World and their choice of perspective improves OOD generalisation. ",
            "main_review": "Specifics about the training \n- 84x84 RGB input images. \n- outputs 3D end-effector position relative to the robot base, 1D gripper width, and a boolean contact flag for each of two gripper fingers. No rotation.\n- Three learning algorithms: Dagger, DrQ, DAC. \n\nThe experimental set up to show that hand perspective is better than third perspective involves picking up a cube (which is somewhat trivial task and naturally favours hand perspective). My first impression was that it's certainly helpful to have hand perspective as it always gets a close up / zoomed-in view of the object free of any occlusions etc. so it makes sense that the hand perspective performs better. However, if you have a more complicated manipulator e.g. hands the self occlusions from fingers and as the hand starts to cage the object, you'd need a third person view to get a better view of the object. Secondly, I feel adding rotation in the end-effector target (which the current output parameterisation doesn't include) could make things even for third perspective too. Is there a reason why the network only outputs just 3D end-effector position? For this particular task I believe you don't need rotation but any general task you'd need to also parameterise rotations as rotations will bring occlusions for hand perspective too. \n\nIn the 6 meta-world tasks, they show that combining a third perspective together with information bottleneck regularisation leads to better generalisation. Though most (if not all) of these tasks involve decision making that has more to do with the object they are reaching to and less about doing any long horizon interaction with scene or other objects in the scene after interaction with the object they are reaching to. \n\nThe paper seems to suggest that a zoomed-in view of the object by using a hand perspective almost always helps which I agree with. It seems to highlight the design choices that we regularly make when doing manipulation with raw observations need to be carefully looked into. Although this is not the first paper to show that e.g. https://arxiv.org/pdf/2012.07975.pdf have also shown that adding hand perspective helps. This paper was also not cited. \n\n\n",
            "summary_of_the_review": "The paper is a good case study. The ideas presented in the paper are not something that's unknown but this paper does a good investigation on the choice of perspectives.  \n\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents an interesting empirical evaluation of the role of visual perspective in learning and generalization in the context of physical manipulation. The paper compares performances using third-person and in-hand visual perspectives, showing that hand-centric vision consistently improves training and out-of-distribution generalization. Authors also explore a combination of the two perspectives by proposing to regularize the third-person information stream to maintain generalization performance.",
            "main_review": "The paper is well motivated, clearly written and coherently structured. The exposition of the main ideas is linear and easy to follow. The contribution is clear, well presented and well motivated. The notation and the formulation of the proposed method are clearly presented. Claims are supported by thorough experimental results. Figures and tables are presented in a nice and easily readable way, and help grasping the contribution of the study. Videos are also helpful in understanding the experimental setup and the results in a qualitative way.\nYou mention tactile signals as a good example in robot manipulation of local streams of information. What is the applicability of your study to the tactile sensor modality?\nIt may be that some of the tasks could be solved using proprioceptive information only - do you have results using proprioception only as your observation space? Comparing the results presented in the paper with results obtained with proprioception only would be instrumental to understand the effect/contribution of vision (especially in the case of O_{h+p})\n",
            "summary_of_the_review": "The paper is well written, the contribution is clearly presented and the experimental results are thoroughly executed. An evaluation comparing the presented results with the proprioception-only case could further improve the analysis.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}