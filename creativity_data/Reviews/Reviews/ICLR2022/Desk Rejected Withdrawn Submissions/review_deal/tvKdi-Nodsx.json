{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors propose a relative instance credibility inference (RICI) framework, which uses a sparse linear model with incidental parameters to detect and remove outlier samples in the forward pass of each mini-batch, and runs standard backward algorithm using the remaining clean data. Besides, two variants are proposed to deal with different noise settings (i.e., symmetric and asymmetric noise). Detailed theoretical analysis is also provided to verify its ability to recover clean data from noisy dataset. Compared with other methods, RICI achieves the state-of-the-art results on a real-world noisy data challenge.",
            "main_review": "Strength:\n1.The authors propose a plug-in module for sample selection. Two variants of the proposed method are also provided to handle different noise settings.\n2.The authors provide a detailed and clear theoretical analysis to verify RICI can provide an identifiability result.\n3.In a real-world noisy dataset, RICI can achieve the state-of-the-art performance.\n\nWeakness:\n1.\tThe authors emphasize the proposed method is a plug-in module to select clean samples, however,  the experiments that compare or combine the proposed methods with other sample selection methods such as co-teaching and its variants are missed. Therefore, it is suggested that the authors incorporate RICI with existing state-of-the-art methods to verify if it will bring improvements to existing methods.\n2.\tIt seems that the proposed RICI is very similar to the method in [1], including the formula derivation and optimization process. Besides, for the proposed variants, it seems that RICIN is just a variant when γ is not zero, while RICIP combines the curriculum learning strategy. It is suggested that the authors highlight the main contributions of the proposed method.\n3.\tIt will be nice if the authors conduct extra experiments on large-scale real-world noisy dataset (Clothing1M) to further demonstrate the effectiveness of RICI.\n\n[1]Yikai Wang, Chengming Xu, Chen Liu, Li Zhang, and Yanwei Fu. Instance credibility inference for\nfew-shot learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, pp. 12836–12845, 2020.\n",
            "summary_of_the_review": "Overall, the whole paper is well-written and the theoretical analysis is clear. However, the claimed contributions are somewhat weak. The authors should further highlight the main contributions.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a sample selection framework to handle noisy labels, which is theoretically guaranteed. In particular, they introduce a relative instance credibility inference method, in which outliers are detected and remaining samples are used for the training. To determine the outliers, they measure the credibility of instances using the sparsity of incidental parameters.\n\nThe main contribution of the method is to present a theoretical method that can recover the clean data from  symmetric and asymmetric noisy data.\n",
            "main_review": "Using the sparsity of incidental parameters to determine outliers is somewhat novel. However, this statistical method can be highly dependent on hyper-parameters lambda of the sparse penalty, which is set differently according to various datasets. \n\nIn addition, if most portions of data in the dataset is noisy and these noisy data are removed from the dataset, the proposed method cannot work properly.  While there are recent works that can re-use the noisy data to improve the performance, the proposed method needs to be compared with the aforementioned method. Overly, related works are not well discussed and compared, \n\nThe datasets, MNIST and CIFAR10, are relatively small datasets. The proposed method needs to be evaluated using CIFAR100, Clothing 1M, and ImageNet datasets to demonstrate the effectiveness of the proposed method. \n\nComputational cost is not analyzed and compared with other methods. \n\nThere are many typos  and implementation details are missing. Definition of some notations are not well defined. \n\n",
            "summary_of_the_review": "In introduction, the method needs to be compared with small-loss criterion-based methods, robust generative classifier based methods, and loss/label correction-based methods. \n\nExperimental results are insufficient to demonstrate the effectiveness of the method. Additional large datasets are required to evaluate the proposed method and ablation study on hyper-parameter settings are needed. \n\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper propose a method for sample credibility modeling to tackle the problem of learning from noisy data, the modeling relies on simple incident parameter problem to identify potential noisy samples and is instantiated with specific design towards both symmetric and asymmetric noises (RICIN, RICIP). Authors also provide theoretical proof on how the algorithm recover clean sample sets from noisy raw data source. Experiments demonstrate the effectiveness of this method.",
            "main_review": "Strengths:\n+ Although with complicated assumption, authors provide concrete theoretical analysis on the sample selection algorithm to prove that the incidental parameter can guranttee the clean set recovery under certain conditions.\n\n+ Comprehensive experiments are conducted to show the effectivness of each variant of RICI, including detailed analysis of hyperparameters.\n\nWeakness:\n- One of my concern is that the core idea, the incidental parameters for data selection is almost identical to [1] with little additional methodology improvement. From my understanding, the selection pipline in [1] is exactly RICIC in this submission, both works focus on select informative samples but apply them under different scenarios --- few-shot learning in [1] and robust learning in this paper. Therefore, I think the contribution 1 & 2 are doubtful.\n\n- From last 3 rows of Table 1, we see the RICIP under high noisy rate of symmetric noise can still outperforms RICIC & RICIN, which is contrast to the conclusion from MNIST & CIFAR datasets, while this is in lack of discussion in the text part.\n\n- From the Table 3, we see the performance highly rely on the linear constraint with $l_p$, I wonder whether this penalty term will work if we choose other loss with better local linearity (e.g. marginal loss) instead of cross entropy ?\n\n- This is not a flaw but I think it is better to make comparison on Clothing1M [2], the currently largest datasets with real noise and high noisy rate to show the robustness of this method. Also, this work is in lack of comparison with some recent methods like PENCIL [3].\n\n- Small typo in Eq (2), since X is define in shape ($b \\times p$), the transposition superscript in Eq (2) should be removed ($X^T$ --> $X$)\n\n[1] Yikai Wang et al. Instance Credibility Inference for Few-Shot Learning. CVPR 2020\n\n[2] Tong Xiao et al. Learning from Massive Noisy Labeled Data for Image Classification. CVPR 2015\n\n[3] Kun Yi et al.  Probabilistic End-to-End Noise Correction for Learning with Noisy Labels. CVPR 2019.",
            "summary_of_the_review": "The overall writing and experiment results are good, but the core idea is almost identical to some existing work, some of the claims in this paper are also not solid enough, therefore I lean to rating below the acceptance bar.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}