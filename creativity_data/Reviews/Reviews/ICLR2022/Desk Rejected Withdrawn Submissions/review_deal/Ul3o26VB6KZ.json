{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors propose to define the graph convolutional neural network based on the spiking setup. ",
            "main_review": "Strengths:\nThis paper transfers the formula of graph convolution to the spike-based scene and performed experiments from many aspects to support their conclusions. \n\nWeakness and concerns: \n1. During the experiments, are the traditional methods and spiking ones using the same spiking input? \n2. From Figure 2, my understanding is that the proposed method changed the continuous activation values to the discretized spikes for the signal processing across layers. The optimization is executed through the gradient surrogate. Since there is no specially designed or modified structure for the SNN, the methodology here may be limited. It does not bring new knowledge to the GCN or SNN fields.\n3. It lacks an explanation of why the proposed SpikingGCN can outperform the traditional approaches. Based on the given content and my own experience on the SNN, the typically suffers a deficit inaccuracy if the infrastructure is shifted from an artificial neural network without a specialized setup on the type of the data. While I am conservative about further judgment, I am more than happy to learn why the proposed approach generates better generalizability. \n4. It would be also great if the authors can add more results on the grid images since the compared baseline is a bit out of time. ",
            "summary_of_the_review": "This paper extends GCN to the SNN manner. It provides an applicable pipeline but lacks sufficient insight of why it works and what it can bring to both sides. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed a new graph neural network by combine the graph convolutional networks and the spiking neural networks. The main part of the paper is to replace the activation part in GCN with a spiking neural network, which can possible lead to a energy efficient network. Experiments show that the proposed model can provide comparable results compared to SOTA.",
            "main_review": "The motivation of the paper is not so clear. It is true that spiking neural networks can be more energy efficient, however in the proposed SpikeGCN there is still graph convolution operation (in Eq(3) and (4)). The authors only replace the activation (or nonlinear) part of GCN with the spike neural network if my understanding is correct. Thus in this situation, it is also strange that a spikeGCN can be executed on so-called ROLL chip because it required MAC operator. Also the MAC part is the most time and energy consuming part of the neural network, it this part remains in the network, it is hard to say that a energy efficient model has been proposed. ",
            "summary_of_the_review": "Some of the fundamental claims of the paper might not be correct if my understanding to this paper is correct.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors proposed a neural network SpikingGCN, consisting of both ANN and SNN elements, for application scenarios in the graph domain. The proposed approach has three parts: representation encoding, a fully connected layer, and a LIF layer. It first converts aggregated graph features to spike trains through the representation encoding module; The generated spike trains are fed into the fully connected layer as input to generate membrane potentials, which are fed to the LIF layer. The effectiveness of the proposed approach has been demonstrated with different application scenarios, such as classification, active learning. The authors also implemented the proposed network onto neuromorphic hardware to show energy efficiency. ",
            "main_review": "**Strengths**:\n\nI appreciate the efforts in implementing the proposed method onto ROLL. With that, the authors can demonstrate the remarkable energy efficiency of neuromorphic hardware. \n\n**Weaknesses**:\n\n-1. The main argument I have is that I do not think the proposed approach is neither bio-fidelity nor bio-plausible, which the authors emphasized many times in the manuscript. Yet, the authors did not provide any biology or neuroscience evidence to support the claims. Based on my knowledge, the following items are not bio-fidelity:\n   * LIF is not bio-fidelity as the threshold is fixed, and it is just a specific case, a simpler version,  of the SRM model.\n\n   * From the neuroscience point of view, a negative spike does not make sense. The authors did not give any evidence to support the “negative spike” but claimed it is more bio-plausible.\n \n   * As illustrated in Figure 2, the proposed network only has one layer of LIF neurons but contains a fully connected layer. More importantly, the fully connected layer transfers spikes to potentials as input to LIF neurons, not bio-fidelity. \n\n   * The membrane potential resetting (i.e., Eq.9) is not bio-fidelity. I think the “leaky” part of LIF is more bio-fidelity than the one used in the proposed method.\n\n   * The proposed approach is only based on the number of spikes but totally ignores temporal information, which is not bio-fidelity. The authors even changed the “leaky” part of the LIF, which is a surprise. However, it seems the “negative spike” kind of played the “leaky” part. \n\n\n-2. It is unclear whether the results shown in Table 2 were from GPU or from ROLL. In addition, the authors did not give concrete experimental settings, such as membrane potential threshold, the T. \n\n-3. The authors showed how the “T” impacts the proposed approach’s performance, shown in Fig 3. But, the authors did not show the impacts of membrane potential threshold, which should be very important. \n\n-4. For the energy efficiency, it is not clear to me whether the author counted the representation encoding part. In addition, how the fully connected layer was implemented on ROLL. \n\n-5. Does ROLL support 16-bit floating points? If not, how does the bit reduction impact the performance of the proposed network?\n\n-6. Presentation issues: \n* In Fig 2, the “repeat T times” is pretty confusing. It looks like a spike loop, where generated spike at timestamp t-1 is also an input of the fully connected layer at timestamp t. However, I do not think it is the case.\n* In the representation encoding section, the authors claim \\lamda_j is “the j-th feature in the new representation for node i.” Is it for node “j”?\n* In the title of Fig 4, more information should be provided to make it self-explainable.  \n\n",
            "summary_of_the_review": "The authors tried to leverage neuromorphic hardware to achieve energy efficiency. However, the demonstrated energy efficiency is not because of the authors’ unique design but because existed neuromorphic hardware.  Besides, there is no evidence to support the authors’ claims related to bio-fidelity or bio-plausible components or methods. Therefore, I did not see enough contribution to the SNN community. If we regard the proposed approach as an ANN-based approach, I did not see enough contribution either. The network design is standard, and the performance is also not superior, especially with Split I. In addition, the presentation of the paper should be improved as many things (as I pointed out) are not clear to me.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "In this work, the authors have introduced the spiking graph neural networks, in an effort to address the large computation cost problem in graph convolution networks. The authors apply spike train encoding to the graph input and also use the leaky-and-fire neuron for building the spikingGCN. Empirical results are demonstrated to verify the author's method. ",
            "main_review": "To be honest, I'm familiar with spiking neural networks but I'm not an expert in graph neural networks. So I checked several cited GCN papers. First, I would appreciate that authors apply the spiking mechanism in the graph field. However, the methods and the technologies used in this work seem to be plain. \n\n**Pros:**\n+ This work may be the first work that adopts spiking neurons in graph neural networks.\n+ The authors' self-implemented experiments show promising results of SpikingGCN. \n\n**Cons:**\n- The contributions are somewhat vague. The authors claim the novel design of spiking encoder-decoder structure, however, this seems to be very common in the spiking image classification area. The images are encoded to spike trains and the output spikes rate is decoded to make the classification. Meanwhile, section 3 spends much space for LIF neurons, which is quite usual for the SNN literature. Can authors list new challenges for applying spiking neurons to GCN? \n- I am not very convinced of the use of negative spikes. These negative spikes are less bio-plausible and less energy-efficient on neuromorphic hardware. This means SpikingGCN-N cannot run on neuromorphic hardware. In addition, the negative spikes seem to be proposed in Spike-YOLO (Kim et al., 2020). \n- While I appreciate authors have implemented the baselines, the experiment results do not match other papers' results. For example, DAGNN got 84.4 on cora dataset while this work's implementation only has 83.0. Why your implementations are lower than DAGNN's report?\n",
            "summary_of_the_review": "Besides, I also have some questions:\n\n1. Why use Bernoulli encoding rather than others (for example Poisson)?\n2. Why use MNIST for grid images classification and superpixels images? Is there a more challenging dataset for these two applications?",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}