{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper explores data-efficient CL training in the absence of large datasets. In particular, it propose to leverage a generator to generate data similar to real but also is challenging to the main model. It also leverages the generator and its mean teacher to generate a pair of similar but distinct images to serve as positive pairs which complements the pairs generated by transformation. The experimental results seem promising. ",
            "main_review": "The presentation of the paper is very confusing and even unnecessarily complex. For example, while I look at the Eq. 2, I was wondering why a discriminator loss is missing in the generator. It seems that it si straightforward to adopt a GAN objective. However, the authors introducing it till the end of the section with a motivation of avoiding trivial solutions. I believe the GAN loss is critical here and should be introduced up-front. Also, as can ben seen from the Algorithm 1, the GAN loss (Eq.5) is first used to pre-train the generator. \n\nWhile Eq. 3 shows that G and the main model are jointly optimized as a Min-Max game, the algorithm 1 seems to suggest the two modules are actually optimized alternatively. To me, it is more like a GAN based data generator, which leverages a downstream `main model’ to select samples that performs bad for the model. I doubt the necessity of formulating such Min-Max game. As simultaneously playing the Min-Max game may make the data generator worse. As can be seen in Algorithm 1, G will be update twice in every n iteration, one  by Eq. 4 and the other by Eq. 5. What if Eq. 4 and Eq. 5 lead to contradictory gradients? How one shall balance the two gradients? So a baseline comparison the authors might be interested in is to compare with a fixed GAN model, and simply use the Max CL loss to select samples for CL further training.\n\n- Why jointly optimizing G and the main model as a Min-Max game can improve the quality of data? Does the main model serve as a discriminator?\n\n- Why the pair of data generated by G and G_{ema} with the same latent $z$ is considered hard positive? While there is minimal difference between G and G_{ema}, is there any guarantee that G and G_{ema} will be similar in appearance as well as semantics? One can think of the adversary samples, which only differ in a few pixels.\n\n- The Partially pseudo-labeled contrastive loss basically simultaneously consider two types of positive pairs, the ones generated by the transformation T and the ones generated by the G and G_{ema} with the same latent $z$. It is really not necessary to formulate a new loss function for it. \n\n- The transformations T must be differentiable. However, the authors did not provide any information regarding the transformation except for a reference to an open source differentiable computer vision library.  \n\n- For experiment, the methods in comparison is lacking the most recent work. For example, Joint Generative and Contrastive Learning for Unsupervised Person Re-identification (CVPR 2021), which also leverage GAN for data augmentation.\n\n- For the ablation, why G+P+Hard have a much better performance than G+Hard and G+pos (Fig 2)? \n\n- From Fig 4, it seems that the image quality drops while training progress.\n\n- How the momentum parameter $m$ influence the positive pair generation? \n",
            "summary_of_the_review": "Overall, the paper suffers from limited novelty, over-complicated and inconsistent presentation. Some important baseline comparison is also missing. Taking consideration of the above drawbacks, I would like to recommend a reject.  ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "n/a",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes to use GAN to generate hard examples for data-efficient contrastive learning. The GAN model is guided by maximising contrastive loss, to jointly update with the self-supervised model by minimising contrastive loss as a form of min-max game. This ensures that the generated samples are suitable for the current stage of self-supervised model. The paper applies this proposed framework on top of SimCLR, and shows better performance on CIFAR/FMNIST/ImageNet datasets with 10/20% training data, comparing to the original model and other data generation techniques.",
            "main_review": "General Comments: I like the motivation and proposed solution from this work. Particularly, guiding generative model with the same contrastive loss to generate suitable examples seems to be an elegant idea. However, the design of the experiments could be further improved, to be more fair and showcase the effectiveness of this method in a more extreme setting.\n\nDetailed comments:\n– Fair comparison to other baselines. The performance of SimCLR is known of depending on the number of negative samples, i.e. batch-size. Expect for SimCLR-2x which this paper has considered on this issue, other baselines : CLAE and CL-GAN which also in the design of pseudo-examples were not trained on the same number of data as for the proposed work, leading to unfair comparison. An easy fix is to change the current framework by generating/sampling half of the data in both real-data and generated-data batch.\n\n– Even fewer training data. GAN is known to have stability issue when training with very small amount of data. Though the current framework looks appealing, I am still wondering whether it’s scalable to say only applying on 1% of training data? Would the generalisation gap becomes smaller or larger compared to the original SimCLR framework would be interesting see.\n\n– Other contrastive frameworks. Though I know the number of experiments are bounded by the hardwares, but the choice of using SimCLR in the entire paper seems to be far-fetched. My concern is mainly due to the fact that SimCLR is limited by the number of training data, and this problem has been significantly improved by other modern contrastive frameworks like MoCo and BYOL. Applying such method on a contrastive framework which is more robustness on the number of training batches is important. This further verifies that the improved performance is mainly due to the new generated samples, rather than more training data per batch. ",
            "summary_of_the_review": "See the main review.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work focuses on the data-efficiency in contrastive learning since its performance would drop significantly with limited unlabeled data. The hard sample generator is involved to synthesize the infinite samples and most important thing - hard samples for contrastive learning under the low-data regime. Different from feeding the synthesis directly, the generator is also optimized jointly with contrastive learning, facilitating the learning throughout the training. Experiments results demonstrate its effectiveness.",
            "main_review": "Strengths:\n- Overall, this paper is well-organized and easy to follow. \n- Involving the training of the generator is pretty novel.\n- This work could be impactful to the direction that aims at using the generative models for representation learning, as it is quite effective on multiple benchmarks. \n\nWeakness:\n- The augmentations used by the baseline SimCLR are consistent with the proposed? Considering the back-propagation, the proposed method uses different augmentations from SimCLR, which usually affects the performances slightly.  Clarification is required to ensure a fair comparison.\n- The resolution of images seems missing, which would meet the different difficulties of generator training. \n- As the main contribution is to involve the generator in the entire training pipeline, a comprehensive analysis of the generator is required. For example, whether the generator is also improved? Maybe the FID before and after training could be reported. If the generator is not improved, an intuition of why is also necessary. \n- It seems that BigGAN is used for synthesis. However, BigGAN is a conditional generator that requires a class label as input. If so, it means the labels are used for unsupervised representation learning which is totally wrong. Clarification is required here.\n- It would be great if the limit of data efficiency could be included. For instance, given a set with 10/100 images, does the proposed method work well or not? \n- Importantly, the deployment of this approach seems to be bounded by the generator since the large-scale training of the unconditional generative model is still a challenging problem. Discussion is required here.",
            "summary_of_the_review": "Please refer to the Main Review section. I will definitely change my rating if my concerns could be well-addressed.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes to improve contrastive learning via generating hard samples by training GAN. The framework performs a Min-Max game: The main model (encoder) is trained to minimize the contrastive loss while the data generator G aims at maximizing the loss. A discriminator D is also trained to force synthetic generated distribution is aligned with the real data distribution. In this way, the generator could generate hard individual samples. Moreover, another generator G_{ema} updated with momentum is applied to generate hard positive samples together with G. Experimental results show superior accuracy of the proposed approaches with either full or limited training data.",
            "main_review": "Strength:\n1.\tThis work proposes a new framework to generate adversarial samples for CL without labels.\n2.\tThis work achieves superior results on classification tasks with either full or limited training data.\n\nWeakness:\n1.\tThe generator G needs pretraining, increasing extra computation.\n2.\tTransfer performances on other downstream tasks are absent (e.g., detection, segmentation)\n3.\tThe idea of “hard individual sample” generated by G is confusing. It’s roughly defined in paragraph “Generating individually hard samples” in page 6 that the main model cannot generate similar representations for this positive pair originating from x_{2i-1} (the hard individual sample). This claim seems to be incorrect, as the representations of the positive pair are not only determined by the input sample, but also the transformations. One can make the two representations identical by simply applying the same transformation twice. Thus, the idea of hard individual sample is hard to understand.\n",
            "summary_of_the_review": "This work proposes a new framework to generate adversarial samples for CL without labels, which is novel and unexplored. Models trained with these generated samples show superior performance on classification tasks with either full or limited training data. However, one important idea in this paper is not clearly stated. Moreover, results on standard benchmark ImageNet and transfer performances on other downstream tasks are absent.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}