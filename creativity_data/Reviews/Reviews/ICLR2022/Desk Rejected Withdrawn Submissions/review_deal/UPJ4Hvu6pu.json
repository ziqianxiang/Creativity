{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes an idea to train image segmentation models with noisy annotations. The idea is based on detecting when to start label correction based on model outputs and adding regularization based on consistency across scales. ",
            "main_review": "S1: The paper solves an important question, training image segmentation models from noisy annotations.\nS2: The paper is easy to read.\n\n\nW1: The proposed idea of picking start time of annotation correction looks quite straightforward adhoc. \nW2: There are no technical details and depth on the label correction algorithm, as this is a core component.\nW3: Some closely related work in weakly supervised learning from noisy segment labels is missing. ",
            "summary_of_the_review": "The paper solves an important problem but the solution lacks technical depth. Some closely related work is missing in the evaluation.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies the problem of learning from noisy annotation in semantic segmentation. Re-discovering the previously observed phenomenon in classification, the authors confirmed that the dichotomy in learning dynamics with noisy annotation also exists in semantic segmentation: early-learning followed by noise memorization. Unlike classification, however, the transition from early-learning to memorization begins differentially for each semantic category. Exploiting this, the authors proposed to detect the transition separately for each semantic category and correct the noisy annotations adaptively by replacing them with the outputs of the segmentation network. The authors also added a novel multi-scale consistency regularization to augment their method. The proposed method was demonstrated on (1) medical image segmentation with synthetic and controllable noises and (2) weakly-supervised semantic segmentation (WSSS).\n\n",
            "main_review": "### Strengths\n* It is novel to observe that the transition from early-learning to memorization occurs differentially for each semantic category.\n* The proposed method is simple and general, thus has practical impact.\n\n### Weaknesses\n* The proposed method was shown effective to only a limited class of segmentation noises, i.e., over/under-coloring. Although such noises may ubiquitously exist, they may not comprise the most critical kind of noises. For instance, instance-level missing or mis-categorization could be much more harmful than over/under-coloring. The proposed method cannot properly handle such noises (because it wasn't designed to do so) as can be seen in Fig. 7.\n* The design of the SegTHOR experiment with synthetic noise is unrealistic and inadequate. \n  - The synthetic noises were injected only to the training set, not to the validation set. In practice, it is highly likely that annotation noises exist in both training and validation sets. In that case, adaptive correction of annotations causes the training and validation annotations to diverge, becoming a source of confusion in practice. How is the proposed method supposed to handle it? \n  - The synthetic noises were injected to *all* categories. What if there exists a systemtatic bias that some categories are noisy and others are noise-free? How does the proposed method affect the performance of noise-free categories? \n* In the experiments, what kind of data augmentation was used? Extensive data augmentation may resist the noise memorization, so the efficacy of the proposed method should be measured against the different levels of data augmentation.\n* The proposed method is simple and general, but it is unclear how it can be further advanced beyond simply picking low-hanging fruits. Please discuss it more specifically. \n\n### Minor comments\n* It is unclear from the text how exactly the annotation correction was done. Was the model's output binarized or not when replacing the annotation?\n* When applying the multi-scale consistency regularization term $\\mathcal{L}_\\text{Multiscale}(x)$, it is said \"the term is only applied to the input $x$ where the maximum entropy of $q(x)$ is above a threshold $\\rho$.\" Please define and/or explain what the \"maximum entropy\" is.  \n* \"ADELE-M\" appears several times without any definition nor explanation.",
            "summary_of_the_review": "Overall, the paper is clearly written and well organized. The proposed method is simple and general, but it is unclear how it can be further advanced in the future to maximize its practical impact. The design of the synthetic noise experiment requires some improvment as well. In summary, I would recommend acceptance of the paper if the authors can address the weaknesses of the paper metioned above. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The work claims based on empirical evidence that segmentation models learn in two phases, an early learning phase - in which accurate labels are fit and an memorization phase - in which incorrect labels begin to be memorized. These phases are observed to happen at different time points for different classes. This observation is used to create a method, abreviated ADELE, which identifies and replaces wrong labels with model predictions in order to improve learning. It is evaluated on two datasets, one which involves organ segmentation in CT images where labels errors are artifically added (SegThor) and one which involves learning from weak labels (PASCAL VOC 2012).\n\nContributions and novelty - Similar ideas have been explored with classification problems previously as mentioned in the manuscript, however, this is appears to be a unique approach for segmentation.\n",
            "main_review": "- The manuscript claims that the network first fits clean labels and then starts to memorize. Looking at the results (Figure 2) this description of what happens does not seem entirely accurate to me. It seems to me that the network begins to learn wrong and correct labels at the same time, but whereas the learning of the correct labels reaches a maximum IoU and then decreases, the IoU with the wrong labels just keeps increasing.\n\n- The work proposes to use the deceleration of the performance measure IoU with training time to detect when the model is starting to move into the memorization phase and to use this to decide when to starting swapping out what are deemed to be wrong labels. I am not convinced this a good idea. This seems like something that should be backed up with either extensive experiments or supported with solid references. Yet this decision seems to have been based on the relatively limited experiments conducted in this work.\n\n- One page and two figures of the paper are used to describe how the somewhat unrelated and esoteric multiscale consistency technique is used to ensure model output quality is high enough to allow safe corrections of annotations. I do not see how this needed or relevant to the work. I think it distracts from the papers main message.\n\n- A big problem with the work is the experimental part is limited. Only two datasets are used and it is not written what data the approach was developed on and so as a reader we cannot assess the chance that this approach would generalize. There are many assumptions and parameter choices that are likely problem dependent and also matters for the results, such as the parameters of the curve fitting, when to start replacing labels and the degree to which this is done and the parameters of the multiscale consistency. However, we are still presented with results such as Figure 4, that likely shows the approach on data it was developed on.\n\n- The artificial annotation noise used (dilation and erosion) is rather simple and not representative of the range of errors humans make. Can the approach also improve performance when models are trained on real (not weak) uncorrupted annotations?\n\n- Figure 4, something with this plot does not make sense to me. As far as I understand the approach, ADELE works by replacing labels that are deemed to be wrong when learning decelarates. Yet looking at the results for Esophagus, Trachea and Aorta all seems to indicate that the IoU improvements from ADELE come much before learning even begins to decelerate. How is this possible?\n\n- Are the results shown in Figure 2, 8, and 9 the results of single training runs? If so they should really be repeated and means standard deviations reported.\n\n- Figure 7, what is the difference between the top left and bottom left scatter plots?\n\n- Early stopping is the classical way of dealing with overfitting and one would expect the decrease in IoU happening as a result of memorization can be prevented to some degree by using early stopping. An obvious question is if a per class early stopping approach could would work just as well as the label replacement technique proposed here?\n\n- Why update annotations that are deemed to be wrong as opposed to the perhaps more safe options of ignoring them?\n\n- p 3, itemization, the definition of early learning and memorization IoU could be more clearly written. Consider using a greater degree of writing parallelism to emphasize the differences in these two concepts.\n",
            "summary_of_the_review": "Although the results are not surprising to me, I find the early-learning vs memorization observations to be interesting. The results emphasize the importance of considering the learning characteristics of each class when fitting segmentation models. I am less convinced by the proposed ADELE approach to improve segmentation results. I don't think there is not enough empirical evidence or references to back up the choices made and it is only tested on two datasets, one of which has artificial errors added and the other is based on weak labels, which are relevant to look at, but perhaps also a special case. In short it has merit, but needs further work.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper focuses on handling the noisy labels for segmentation tasks. First, this paper observes that similar to classification networks, a segmentation network trained with noisy labels also undergoes two stages, i.e., early-learning and memorization. However, for segmentation such dynamics differ across each semantic category. Second, based on this observation, this paper proposes a new method, named ADELE, to adaptively correct the labels of each category. ADELE detects the beginning of the memorization phase by monitoring the IoU curve for each category during training, and then corrects the pixel labels using the network output. To promote the label quality, a regularization strategy is introduced to improve the robustness of the network to label noise. Experimental results on two datasets with different settings demonstrate the effectiveness of the proposed method.\n\nThe contributions of this paper include:\n1. This paper analyzes the behavior of segmentation networks trained with noisy annotation. In contrast to the classification networks, it observes a different phenomenon, i.e., each semantic category enters the memorization phase at different moments.\n2. A new method, ADELE, is proposed to deal with noisy labels for semantic segmentation. ADELE detects the memorization phase by monitoring the training IoUs of each category, whose label is corrected adaptively during training. In addition, a regularization strategy is introduced to improve the label correction quality.\n3. This paper investigates the performance of the proposed method on two different datasets with different settings. Extensive experiments are conducted to validate the effectiveness of the proposed design.",
            "main_review": "The strengths of this paper include:\n1. For semantic segmentation, this paper offers a new observation: the memorization phase happens at different moments for different semantic categories.\n2. To detect the memorization phase, this paper proposes to monitor the training IoUs for each category. In particular, this is achieved by fitting an exponential curve over the training IoUs and computing the point where the slope of the curve decreases. Although some previous methods also detect the memorization phase by monitoring the training performance, the idea of fitting a curve is new.\n3. A regularization term is introduced to further promote the network performance. In particular, it promotes the quality of corrected labels.\n4. Extensive experiments are conducted to evaluate the effectiveness of the proposed designs. These experiments, especially the ablation studies, are helpful in understanding the proposed method.\n\nThe weaknesses of the paper include:\n1. This paper proposes to detect the memorization phase by fitting a curve. However, this curve is designed to be an exponential parametric model. It is unclear if this kind of model is expressive enough to consider the general cases (i.e., the overall trend of training IoUs from arbitrary networks). Also, in some cases, we have a clean validation set (e.g., in SegTHOR dataset), and is it better to use the validation accuracy to monitor the memorization phase? Additional experiments are needed to clarify this.\n2. The detection of the memorization phase is performed by monitoring the training IoUs. I wonder if the accuracy of this detection is subject to the learning rate and network optimizer? More specifically, will a small learning rate affect the detection accuracy (e.g., in the fine-tuning scenario)? Also, will a different learning rate schedule affect the performance (e.g., cosine annealing or linear schedule)? In the experiments, the SGD optimizer is employed, but it is unclear that with other optimizers, such as Adam, the proposed strategy would still be effective.\n3. Although this paper observes that “in contrast to classification, memorization in segmentation does not arise simultaneously for all semantic categories”. But for classification tasks with unbalanced classes, I think it is also possible that the memorization happens at different moments for different categories. No evidence is provided to support the claim that such kind of memorization behavior is exclusive to segmentation tasks.\n4. In Figure 3, some visualizations of the corrected annotations are offered. Is there any specific number regarding the accuracy of the corrected annotations? Such numbers would be helpful in understanding the proposed method.\n5. In the experiments, no comparisons with previous noisy label-robust methods are provided. For example, for SegTHOR dataset, this paper only compares with one naive baseline method. However, although not many, there are some existing works on handling the noisy annotation for semantic segmentation, such as (Zhang et al, 2020c; Shu et al, 2019; Wang et al, 2020a; Min et al, 2019). It is suggested to also compare with some of these methods to further demonstrate the advantages of the proposed method.\n6. Although some of the existing methods are proposed for classification, they can be adapted to segmentation tasks. It is suggested to also compare with these methods, so as to show the advantages of the proposed method which is particularly designed for segmentation. Such existing methods can be those that design new noisy-resistant losses, such as GCE [1] and SCE [2], etc. Also, some methods for classification also propose to correct the labels for classification, such as LRT [3], etc. Finally, there are some existing methods that are developed for instance segmentation, and the idea can also be adapted to segmentation task; e.g., [4], etc.\n\nReferences:\n\n[1] Zhilu Zhang and Mert R. Sabuncu. Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels. In NeurIPS, 2018.\n\n[2] Yisen Wang, et al. Symmetric Cross Entropy for Robust Learning with Noisy Labels. In ICCV 2019.\n\n[3] Songzhu Zheng, et al. Error-Bounded Correction of Noisy Labels. In ICML, 2020.\n\n[4] Longrong Yang, et al. Learning with Noisy Class Labels for Instance Segmentation. In ECCV, 2020.\n\n7. Some typos need to be fixed.",
            "summary_of_the_review": "The problem this paper focuses on is important and has not received much attention in the community. In this paper, one interesting phenomenon is observed for the segmentation tasks: each semantic category suffers from the memorization phase at different moments. This paper claims that this phenomenon is unique to segmentation tasks, but no evidence to show if this phenomenon is also common in classification tasks. Based on this phenomenon, this paper develops a new method to detect the beginning of the memorization phase; and inspired by the idea of consistency regularization which is widely adopted in semi-supervised learning, this paper introduces a regularization term to better correct the noisy labels. Experimental results on two different datasets show the effectiveness of the proposed method to some degree. However, this paper still lacks comparisons with other noise-robust methods. Also, it is unclear if the proposed memorization phase detection method is robust to learning rate and optimizer, and would take into account the more general training scenarios. Finally, it is unclear if using a clean validation set would better detect the memorization phase.\n\nBased on the above considerations, I give my current rating for this paper. I will adjust my rating if the authors would address my concerns.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}