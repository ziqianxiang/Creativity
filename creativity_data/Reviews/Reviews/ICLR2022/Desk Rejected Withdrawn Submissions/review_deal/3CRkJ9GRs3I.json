{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper formulates the learning process of ResNet as a iterative system and explains its stability and accuracy using tools in discrete-time DS. The authors introduce the condition number of modules to describe the perturbation of output data. In addition, the inter-class and intra-class median principal angle is defined to analyze the classification efficiency of ResNet. ",
            "main_review": "-The problem considered is nice, but the main claims of the paper are incorrect.\n\n**Main concerns:**\n\n- The proof of lemma 1 is **incorrect**. Actually, the approximation \n\\begin{equation}\n|| W_l^{(1)} W_l^{(2)} + I ||_2= M_l^{(1)} M_l^{(2)} +1\n\\end{equation}\nis not correct **even for invertible weight matrices**. To see this, let \n\\begin{equation}\nW_l^{(1)} = \\begin{bmatrix}\n 1/10&0 \\\\\\\\  \n 0& 30\n\\end{bmatrix},    W_l^{(2)} = \\begin{bmatrix}\n 10&0 \\\\\\\\  \n 0& 1/30\n\\end{bmatrix},\n\\end{equation}\nthen \\begin{equation}|| W_l^{(1)} W_l^{(2)} + I ||_2=2,  \\ \\ but  \\ \\  M_l^{(1)} M_l^{(2)} +1=301. \\end{equation}\nFor non-invertible matrices it is much easier to see this is not a correct approximation.\n\n- Remark2 is **incorrect**: When the minimum\nsingular value of the matrix is zero, how the condition number tends to infinity?\n\n- The proof of lemma 2 is **incorrect**. Obviously, the result \n\\begin{equation}\n(W_l + I)^T x_l = a_l, \\ \\\n(W_l + I)^T \\triangle x_l = \\triangle a_l\n\\end{equation}\nis **incorrect**.\n\n\n- There are some typos, e.g:\n\n-Page 3, the second line below eq. (1), the term \"W_l^{(1)}\" should be \"W_l^{(2)}\".",
            "summary_of_the_review": "Overall, I lean on the rejection side: the main claims of the paper are incorrect.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "In this paper, the authors provide an analysis of residual networks, both theoretically and empirically. The theoretical analysis focuses on the condition number of a resnet block. The empirical analysis is based on a metric called the median principal angle, and is conducted on three datasets including Dogs vs. cats, Animals 10 dataset, and the Imagenet 2012 dataset.",
            "main_review": "The problem studied by the paper seems interesting. However, the analysis framework taken by the authors does not seem to be solid, which greatly undermines the significance of the paper. It seems both theoretical and empirical analyses are based on a few assumptions that seem to be dubious.\n\nFor the theoretical analysis, it is unclear to me what the conclusion is. I am not theoretically convinced that the conditional number of a resnet is always smaller than a base network counterpart. I think an empirical analysis could be helpful in verifying that. Also the analysis (e.g., lemma 1) seems to ignore the non-linear activation function in a resnet block. \n\nFor the empirical analysis, the authors seem to conflate the classification accuracy with the median principal angle (MPA). It is unclear to me whether a higher MPA always corresponds to a higher classification accuracy. Also the authors seems to be using the MPA across training steps as an indication of the model stability, which I could barely understand.\n\nA clarifying question: for the matrices U and V in Definition 1, what are they exactly in the analysis in Section 4.2? Does each column denote the last hidden representation of an input image?",
            "summary_of_the_review": "The claims in the paper is not well-supported and the conclusion from the analysis does not seem significant.",
            "correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes to understand ResNet using the techniques in discrete dynamical system and principal angle. Some numerical experiments are provided to support the validity of the proposed median principal angle for analyzing classification results of trained ResNet.",
            "main_review": "Strengths:\nNone.\n\nWeakness:\n1. It seems to me that the main claim is incorrect. In the last line of Page 3, if we let W1 and W2 be orthogonal, then the two conditions number are equal to one and the inequality does not hold. It is also incorrect to claim that W1*W2 + I has a smaller condition number than W1*W2. This can be easily seen by letting W1 and W2 be the identity matrix. Besides, it is incorrect to claim ResNet has a smaller condition number without taking account the nonlinear activation.\n2. This paper puts two orthogonal ideas in a single paper. Stability of the forward/backward propagation and classification results of trained ResNet. They have no relevance with each other.\n3. The paper has too many grammar mistakes. For example, in the abstract,\n(1) one of popular networks -> one of the popular networks. (2) recently years -> recent years. (3) a iterative -> an iterative. (4) are accordance with -> are in accordance with.",
            "summary_of_the_review": "As stated above, the main claims of the paper are incorrect. The organization and writing of the paper are also below the standard. Therefore, I vote for strong reject.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}