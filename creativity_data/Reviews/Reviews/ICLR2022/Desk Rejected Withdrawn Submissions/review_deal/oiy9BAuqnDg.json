{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "An active learning algorithm is proposed that acquires labels of samples which maximizes the amount of information gained with respect to the model's prediction on the unlabeled set. Here the acquisition function is model agnostic and the active learning algorithm operates in batch mode. In essence, the algorithm acquires a batch such that the model's prediction have highest statical dependency as possible with model's prediction on the entire unlabeled data set. On several image datasets, the proposed method improves performance in terms of model accuracy and negative log. likelihood.",
            "main_review": "(+) The paper is relatively easy to follow as it is written and organized adequately. The paper also references a significant selection of prior work. \n(+) The use of HSIC is certainly interesting but it is not intuitively clear how it might lead to better performance than other competitive algorithms. It is not clear how $\\widehat{dHSIC}$ is computed.\n(-) It is unfortunate that the paper does not provide the experimental results on large datasets such as tiny ImageNet and any real-world dataset. It would seem that the choice of the kernel function \n(-) Section 4 motivates the proposed algorithm stating that past algorithms are inadequate in dealing with imbalanced data. The performance of the proposed algorithm on imbalanced data should be shown. \n(-) How are the bandwidths of the kernels obtained?",
            "summary_of_the_review": "It is not in detail. But, in order to improve readability, the paper should be less pedantic and provide kind explanation. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "There are no ethical issues which needs to be considered. ",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents a new active learning method, called ICAL, via developing a new acquisition function based on the Hibert Schmidt Independence Criterion. It aims to acquire a batch of samples the prediction of which is highly correlated with the prediction over the entire unlabeled poor, which seems to be well motivated. The experimental results derived on several image datasets show that the new acquisition function can outperform methods, like BADGE, BatchBald, etc.",
            "main_review": "* the two motivations are reasonable, supported with examples in the appendix. I wonder how they proposed acquisition function deals with the imbalanced data, as in motivation example 1. It seems that all the datasets used in the experiment are balanced. \n* Further discussion on the link between the new acquisition function based on HSIC and the model uncertainty is needed. Is this just a simple replacement of MI? This question is also related to my concerns below on the convergence. \n* Validation set: The goal of active learning is to minimize the annotation cost. In the experiments, it is always assumed that there is a large validation dataset available, for example, the validation set size for EMNIST is 16388=5. Therefore, one will argue if it is even rational to assume that there is always such a large validation set available. Should the labelling cost of the validation set be considered in the overall annotation budget?\n* In the BADGE paper, it is reported that BADGE is better than random.  It is interesting that the reported results here show that Random outperforms BADGE, BALD, and FASS. Thus, further discussion of the possible reasons is needed. Meanwhile, it might be worth generating the pairwise comparison as in BADGE.\n* Oblation study on $r$: I wonder how the performance of the proposed method varies with the subsample size. \n* There is another line of active learning works that compute Expected Loss Reduction, such as weighted-MOCU by [2] and soft-MOCU by [1]. Both have a theoretical convergence guarantee. Can ICAL guarantee to convergence to the optimal classifier?\n\n* Some minor issues\n * In the last minus term in the equation on page 3: Should $k$ be $l$\n\nReferences\n[1] Zhao et al 2021, Bayesian Active Learning by Soft Mean Objective Cost of Uncertainty\n[2] Zhao et al 2021, Uncertainty-aware Active Learning for Optimal Bayesian Classifier",
            "summary_of_the_review": "The idea of condensing the information of the unlabeled poor with the Hilbert Schmidt independence is interesting and supported with improved performance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces a new acquisition function for active learning that the authors call: information condensing active learning. This approach is designed specifically for batched active learning. It intuitively attempts to choose the batch that maximized the dependency with the rest of the unlabeled data as measured by the Hilbert-Schmidt Independence Criterion, which the authors choose for efficiency in estimation and differentiability.\n",
            "main_review": "Strengths:\n\nThe problem is useful and the authors give a good background discussion of active learning and related prior work. The motivation for developing the proposed approach is reasonably clear.\n\nThe proposed acquisition function and the methodology for computing the dependency function appears to be novel and interesting, though I am not hugely well-versed in active learning literature. It could meet the bar for acceptance. \n\nThe experimental results seem promising, the method does appear to outperform competitors on a reasonable set of benchmark tasks including MNIST, fashion-mnist, extended-MNIST and cifiar.  \n\nThe figures are clear and useful in showing the performance benefits of the approach.\n\nWeaknesses/suggestions:\n\nExample 2 in section 4 is not very precise as written, though there is further expansion the in appendix. A figure accompanying section 4 and demonstrating intuitively how ICAL solves the problems highlighted could be extremely beneficial.\n\nThe ICAL acquisition function is poorly explained in general. I think the text in section 5 should be much more explicit in discussing how the acquisition function in computed in terms of the model parameters, the training and unlabeled data and the candidate batch. Perhaps with MI as an introductory example. \n\nThe portion on the efficient implementation of HSIC is quite condensed and also difficult to follow. In general, I think the methods section of this paper should be significantly expanded and clarified. This may be partially because I am not an expert in this domain, but I am finding it somewhat difficult to asses the technical merits in its current state. It seems that sections 1-4 could easily be compressed to leave room for an expanded methods section.\n\nSection 5 should also be broken into more digestible subsections. \n\nNo experiments are given for ICAL on a continuous domain. This is listed as one of the main benefits of the proposed approach, so it should be evaluated.\n\nThe notation seems somewhat inconsistent in the acquisition functions which is confusing. For example, just between the max entropy and batch BALD the notation for the model distribution and data changes significantly. Then the definition for ICAL doesn’t show dependence on the model distribution?\n",
            "summary_of_the_review": "This work seems to potentially be a useful contribution, but I feel the paper needs significant editing to better introduce the proposed approach. I also believe the experiments should be expanded on to show the claimed benefits of the approach.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "See Main Review section",
            "main_review": "The current reviewer reviewed the previous NeurIPS2021 submission of this paper and as far as the current reviewer understands, this submission is identical to the previous version even including typos, and therefore, all of the concerns that this reviewer had still stand. Please find the previous review below:\n\nThis paper presents a new batch-mode active learning algorithm where multiple data points are simultaneously selected for labeling. The authors propose a new acquisition function that maximizes a measure of statistical dependence, HSIC, between two sets of random variables each corresponding to model predictions on labeled and unlabeled training data. The authors evaluated the proposed algorithm on MNIST, Repeated MNIST, EMNIST, fashion-MNIST, CIFAR-10, and CIFAR-100 and demonstrated that the new algorithm outperforms BADGE, BALD, FASS, and BayesCoreset.\n\nStrengths\nActive learning is an important and active area of research. The authors contribute by a new acquisition function that maximizes the HSIC between model predictions made on labeled and unlabeled datasets. The proposed algorithm appears to be novel and the reported results outperform several existing algorithms.\n\nConcerns\n- The idea of maximizing the HSIC between the predictions of labeled and unlabeled data points appears to be new. However, the reviewer was not sure if this idea has been well-motivated: The authors claim that their strategy is to reduce the model uncertainty by achieving a high gain of ’information’. However, the ’information’ or ’information gain’ have not been formally defined and therefore, it is not clear how the HSIC, a measure of statistical dependence, is connected to the gain of information. The authors should explicitly demonstrate (e.g., via mathematical proof) such a connection. Often, information gain is defined as the amount of information gained about random variables, e.g., as the KL-divergence between the prior and the posterior (after taking observations) of distributions: It is not clear how maximizing the measures of statistical dependence, e.g. MI or HSIC, leads to maximizing the information gain in this context.\n\n- The reported accuracies on CIFAR-10 and CIFAR-100 seem to be much lower than the results reported in the literature, e.g., VAAL work. This might be caused by weak backbone networks. The reviewer wonders if the observed superior performance of the proposed method can be transferred to settings where stronger backbone networks, e.g., ResNet, are used.\n- It appears that the proposed method clearly outperforms existing methods for only (E)MNIST and fashion-MNIST where the numbers of classes are kept small. Experiments on more challenging problems with larger numbers of classes, e.g., Caltech-256 and ImageNet would help.\n\nMinor comments\n- The paper would benefit from thorough proofreading: There are typos throughout the entire manuscript. \n- In the experiments, the ranges of acquired dataset size varied significantly across datasets: For EMNIST and fashion-MNIST they lie in [50,350] while for CIFAR and CIFAR100 dataset size varied in [10000,35000]. Performing experiments on multiplicative intervals in [50,35000] would help gain insight into the effectiveness of the proposed algorithm on varying dataset sizes.\n",
            "summary_of_the_review": "- This paper presents a new acquisition function; \n- Not sure if the idea of maximizing the HSIC between the labeled and unlabeled data points has been well-motivated;\n- Experiments: Backbone networks seem to be too weak;",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}