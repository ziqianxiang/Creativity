{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper provides an information theory based analysis on the Unsupervised Domain Adaptation (UDA), where the authors provide the definitions of discriminability, compressibility and transferability under the conditional mutual information. To further achieve the domain invariance for the feature representation, the authors borrowed the idea of data augmentation from self-supervised learning, and formulate it into minimizing the distance between the target distribution and the augmented target distribution, as well as maximizing the mutual information between the target feature representation and the augmented target feature representation. As claimed by the authors, minimizing the distribution distance of D(P_s, P_t) and D(P_t, P_tss) are considered as constraining the global consistency, whereas the mutual information of I(Z_t; Z_tss) is considered as the local consistency. Experiments are conducted on four commonly used datasets for UDA, office-31, office-home, VisDA-2017 and Digits datasets. The results are extensively compared to state-of-the-art UDA methods and show consistently advantageous results. ",
            "main_review": "- Strength\n\n(1) the paper provides sufficient background and literature introduction to draw the connection from the existing works. Meanwhile, the preliminaries of problem introduction and notations are clear and mathematically meaningful. \n\n(2) the authors proposes three definitions to capture the property of UDA, namely, discriminability, compressibility and transferability in terms of mutual information. Though there is no justification on why those exactly indicates each of the three property, empirically I agree that those conditional mutual information points to the direction. Moreover, the authors provided theoretical analysis in both the methodology and the appendix sections to verify the correctness. \n\n(3) the proposed asymmetrically-relaxed Wasserstein of Wasserstein distance (AR-WWD) is some new metric to constrain the global consistency loss. It is motivated from Wu et al. 2019, with detailed theoretical formulation and illustration.\n\n(4) there are extensive experiments on four widely applied domain adaptation datasets, and the proposed method is compared to many state-of-the-art UDA methods. The proposed method shows some advantageous performance over the compared methods.\n\n- Weakness\n\n(1) As proposed for the three definitions (D 4.1, 4.2, 4.3), empirically, it is good to see if the learned feature numerically satisfies the definition, i.e., for discriminability, whether I(X_u;Y | Z_u) = I(Z_u;Y|X_u) and it is close to 0, which can be approximated by the KL divergence. The paper has some reasoning for the definitions. If empirical results can further support those definitions, it'll provide a solid validation.\n\n(2) Theorem 4.1 the proof in appendix does not fully address the claiming, i.e., the proof only shows by minimizing the KL divergence, I(X_s; Z_s | X_t) can be minimized, which is the transferability, where the Z_s discriminability and compressibility are not proved.\n\n(3) Theorem 4.2 is not any theoretically firm. The proof in appendix does not provide any theoretical proof but only with re-iteration of the conclusion. It is better to connect from the definition of discriminability, with the condition of Theorem 4.2, how to show I(X_t;Y|Z_t)=0. \n\nIn self-supervised setting, P_tss is to augment the P_t distribution with more variation. Usually, the distribution of P_tss is not technically too far away from P_t, compared to D(P_s, P_t). The discriminability captures the classification ability, i.e., 0-9 10-way digit classification, not to discriminate X_t and X_tss. In other words, for a training data point X_t (i.e., digit '9'), with data augmentation to get X_tss, they should both be recognized as digit '9'. Then, I(X_t, X_tss) actually is close to 0. So, it should be minimize this I(X_t, X_tss), not to maximize. \n\nSecond, minimizing D(P_t, P_tss) is to constrain the target and its augmented distribution tight, whereas the latent feature representation Z_t and Z_tss, their mutual information I(Z_t, Z_tss) will be small. So, maximize I(Z_t, Z_tss) and minimize D(P_t, P_tss) are contradictory to each other.\n\n(4) Though with theoretical assumption for \"f\" in Equation (8), i.e., continuous and bounded everywhere, it is not clear in each of the experiment, how such function is chosen. Without such information, it is hard to verify and replicate the claimed results.\n\n(5) it is good to have the Bayes error rate as the indicator for generalization classification error. But there is none of this error comparison in the experiment section.\n\n(6) In the experiments, the authors showed ablative study overall the module-wise methods as RLGC (without global constraint), RLGC* (without local constraint) and the overall method RLGLC. However, as this paper provides the quantitative measure for the discriminability, transferability and compressibility, with the learned feature representation, it is good to show for the ablations, the mutual information value for each of the method. It not only provides another quantitative measure to show the method's advantage, but also can validate the authors proposed three definitions.\n",
            "summary_of_the_review": "The paper provides certain amounts of insights and proposals to conduct UDA. There are interesting ideas such as the information theory based definitions of the discriminability, compressibility and transferability. There are also two-level (global and local) constraints to learn the feature representation. However, regarding the detailed loss design, there is some parts that is still unclear to me, i.e., I(Z_t;Z_tss) versus D(P_t, P_tss). Given that the two theorems (4.1,4.2) are not firm enough, and the experiments do not sufficiently validate the proposed definitions (Def 4.1, 4.2, 4.3), I think this paper lacks some important information to better understand it, as well to better help to replicate the method, i.e., the function f, the loss term hyper-parameters, etc. Further information (and/or with code) is needed to resolve the unclearness and replicability. Thus, I am not fully convinced yet on the technical contribution of the paper and provided the current rating.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a method for unsupervised domain adaptation. They analyze the conventional objective in the information theoretic view and propose additional terms that encourage the discriminability in the target domain. Based on this formulation, they propose a method that encourages global and local consistency. The experiments show that the proposed method improves accuracy on four popular datasets.",
            "main_review": "1. I think the analysis of conventional domain adaptation based on the information theoretic view is novel and interesting. However, I don't think the optimization problem stated in Section 3.2 can represent all the existing methods. Based on the similar motivation that aligning source and target distributions can not take into account the class-wise alignment, there are several existing approaches to alleviate the issue. Since they are targeting the similar problem, propoer comparison and discussion will be necessary.\n\n2. I think presentation could be improved. In the current version, it is not clear to me how the proposed global and local consistency based formulation relates to the framework proposed in section 4.2.\n\n3. Proof of the main theorem 4.2 is unclear to me. It is expected to show that minimizing Eq.5 achieves the discriminbility defined in Definition 4.1, however, it is not shown. How does the additional terms relate to label Y?\n\n4. It is good that they extensively evaluated their method on four popular domain adaptation datasets. Experiments show that the two proposed components, global and local consistenyc modules both improve accuracy, consistently over four datasets (Office-Home, Office-31, Digits, and VisDa-2017).\n\n5. Details of the data augmentation process is missing. How does the choice of augmentation affect the performance? I think it is an important detail that will affect the accuracy a lot.\n\n6. I think proper comparison with the baselines is necessary. As they propose a new metric (AR-WWD), comparison with the baselines that use other existing metrics is necessary. To show the effect of the proposed local consistency, comparison with the ordinary contrastive loss will be also necessary.",
            "summary_of_the_review": "In summary, I think the paper is interesting but the main theorem is not proved properly and connection to the proposed global and local consistency is not clear. In addition, some necessary analysis and comparison with baselines look missing.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper presents an unsupervised domain adaptation method for classification settings. The paper proposed a method RLGLC, which uses Wasserstein of Wasserstein distance to ensure transferability and compressability of features between source and target domains. An information theoretic framework for error bounds in the adaptation scenario is presented. Empirical results on Office-31, Office-Home, VISDA and Digits datasets are presented.  ",
            "main_review": "Strengths: \nThe paper presents a comprehensive information theoretic framework for analyzing error bounds for domain adaptation scenario. The proposed Wasserstein distance based measure is shown to have lower error bounds than existing prior art. Empirical results on several datasets are shown.\n\nWeakness:\nThe paper has several weaknesses which need to be addressed:\n1. The proposed methods, RLGC, RLGC* and RLGLC have not been tabulated as algorithm in the paper. It is hard to follow in the paper on which loss function these variants are using.\n\n2. There are several confusions in the notation and formulations in the paper:\n\na. In Definition 4.3, what does the term I(Z_u; Z_s | X_t) refer to. Does Z_u refers to the equation holding true for source and target domain? This does not seem consistent with the provided definition of \"Transferability\".\n\nb. In Section 4.2, self supervised features have been introduced without any prior definition of the terms. It is also not clear how the probabilities, P_{tss}(X) and P_{tss}(Z) are being computed. The line mentions stochastic augmentation, but does not mention further on the type of augmentation or self-supervision (e.g rotation-based pretraining or patch-based augmentations etc). Further the proof for Theorem A.2 is hand wavy, the motivations for mutual information between target feature and target self-supervised features are not provided before.\n\nc. The proposed asymmetrically-relaxed Wasserstein of Wasserstein distance does not seem well motivated. The derived guarantees of the method are using Wassertein distance between the distributions. But the jump to AR-WWD in Section 4.3 is confusing. The provided guarantees are for Wassertein distance, can the author relate the proposed metric with the original Eq 2 formulation. Also the notation W_{1. W_2, d_{\\omega}} is not clear, how to read it. The subscripts for source and target have been replaced by 1 and 2 here.\n\nd. How is the equation 9 optimized in the paper, can the authors provide the method for it. Currently it is not there.\n\n3. In the proofs for the paper, authors assume perfect transferability, discrimination and compressibility. These will not be true for any practical classifier, can the authors provide some insights into how the provided theorems will generalize without these assumptions.\n",
            "summary_of_the_review": "The paper presents a novel metric AR-WWD for unsupervised domain adaptation, and presents results on different adaptation benchmarks. An information theoretic analysis for error rates of the proposed method is presented. However, the paper has confusing notations in several places, and the proposed metric is not properly justified. Further, there are some questions about the assumptions for classifier being made in the paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethical concerns",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces an approach to unsupervised domain adaptation based on reasoning about notions of mutual information. Specifically, the authors define properties such as discriminability, compressibility and transferability in terms of mutual information, and design an approach based on an asymmetrically-relaxed version of the Wasserstein distance to satisfy all these properties.",
            "main_review": "Strengths:\n- The three properties that the authors reason about are intuitive.\n- The experimental results show the good behavior of the proposed method.\n\n\nWeaknesses:\n\n1) Correctness and clarity of the technical material.\n1.1) My main concern here is related to Theorem 4.2. The statement of Theorem 4.2 is quite vague and its proof is hand-wavy. Specifically, what does discriminability mean here? If the authors truly mean discriminability for the labels $Y$, then I doubt that the theorem is correct in general; it will depend on how representative of the classification task the self-supervised task is. The proof simply states that maximizing $I(Z_t;Z_{tss})$ will yield discriminability, but I believe that this statement is only true for the discriminability related to the self-supervised task, not to the classification one, which is the one we care about. In any event, this theorem should have a proper proof.\n\n1.2) The mathematical statement in Definition 4.3 seems incorrect (probably just a typo). If it is correct, then it is not very intuitive, and I recommend the authors to explain how it relates to the statement that \"the domain-specific information equals to zero\".\n\n1.3) Below Eq. 4, the authors state that \"Because we have...\". I do not understand why this is true.\n\n1.4) In the same sentence, the authors say that \"we can easily obtain...\". This may be true, but I do not understand why this is important.\n\n1.5) Theorem 4.1 is very intuitive, but it is not clear to me how it relates to the discussion above (the discussion after the three definitions). As such, I suggest to move this discussion to the appendix.\n\n1.6) At the beginning of Section 4.2 (bottom of Page 4), the authors mention a \"support set\". This notion has not been defined. Is it general to any self-supervised learning strategy, or specific to a contrastive learning one? I suspect that this may not apply to something like an image reconstruction task. The method is presented as being general for any self-supervised learning approach, but it may be worth making it more specific if some statements do not truly apply generally.\n\n1.7) In Eq. 5, maximizing $I(Z_t;Z_{tss})$ in fact encodes minimizing the self-supervised loss. This may be worth mentioning.\n\n1.8) At the beginning of Section 4.3.1, the authors refer to $P_r$. This has not been defined, and does not appear later in the text either.\n\n1.9) The notion of \"ground metric\" is not clearly defined.\n\n1.10) Above Eq. 7, the authors mention that they set \"p=1\". However, I do not see any \"p\" in the equations.\n\n1.11) Below Eq. 10, the authors state that $\\omega\" is a symmetric matrix. How are its values defined?\n\n1.12) In Section 4.3.2, wouldn't constraining the distribution of negative pairs to fill the entire [0,1] interval tend to decrease the discriminability in the target domain. What happens if the target samples in a batch all come from different classes? In this case, all negative similarities should be close to 0.\n\n1.13) In Eq. 11, the first sum should not be over $2N$ but only $N$ because there are only $N$ $Z_i$ with corresponding $\\hat{Z}_i$.\n\n2) Relation to existing work.\n2.1) As acknowledged by the authors, the asymmetrically-relaxed distance is motivated by the work of Wu et al., 2019. The authors should nonetheless explain how it differs from this work, particularly considering that Wu et al. also considered the case of the Wasserstein distance. Because of the relation to the work of Wu et al., I recommend the authors to compare their method to that of Wu et al. empirically, or potentially a modified version of their method with the distance replaced with that of Wu et al.\n\n2.2) Several works have proposed to use self-supervised learning for domain adaptation. Although most of them do not rely on contrastive learning, the work of Thota & Leontidis, \"Contrastive Domain Adaptation\", CVPR workshops, 2021, does. Therefore, similarly to my previous comment, I recommend the authors to compare their work to this one from both a theoretical and empirical perspective.\n\n3) Experiments: Although the results show the good behavior, the experiments could be improved in several ways.\n3.1) Different sets of baselines are reported in the different tables. I understand that these results are probably directly taken from the different papers, but it would be nice to see the results of the best-performing methods on all datasets.\n\n3.2) In particular, the gap w.r.t. CAN in Table 3 is quite small. As such, I would appreciate having the results of CAN in the other tables. Furthermore, I recommend the authors to comment more extensively on this small gap so as to give the reader an intuition of why it is small and whether or not the two methods could be used in conjunction to obtain even better results.",
            "summary_of_the_review": "Although the empirical results of this paper are reasonably convincing, the technical material needs much work, both in terms of clarity and correctness. Additional comparisons, both empirical and theoretical, to related methods should be performed.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}