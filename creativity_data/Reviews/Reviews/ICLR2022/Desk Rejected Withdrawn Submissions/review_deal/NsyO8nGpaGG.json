{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper sheds light on the bias and disparities prevalent in facial analysis frameworks. Bias in existing datasets is often due to uneven distribution of participants (based on gender or skin type). Data collected process on the other hand introduces disparities to different backgrounds, illumination, pose, etc. This is a well-known problem in the facial analysis domain and it is an interesting research question that the authors are tackling.\n",
            "main_review": "\nStrengths:\n-- The paper is well structured and presented.\n-- A new dataset (InterRace) was curated from existing CelebA and LFW datasets for experiments and the authors are willing to release it for future researchers.\n-- The number of responses collected through surveys to understand the bias exhibited by humans w.r.t gender and skin color.\n\nWeaknesses:\n-- Even though curation of a new dataset is useful to the research community, an automatic extension of this dataset seems to be difficult (considering the resources that went into it).  \n\nIt would be beneficial to reflect on the following: \n       --  Would it be more useful to have algorithmic techniques to tackle bias with enough input from subject matter experts? \n       -- Will the above approach lead to the development of bigger and better datasets?\n\n-- The experimental outcomes for the ability of humans in verification, and when and where computers outperform seems to be straightforward given the literature in this area. \n\n-- The authors only mention the use of Resnet 18, Resnet 50, and MobileFaceNet but didn't provide details of how they were finetuned for the task on hand. \n    -- Was it a case of using existing knowledge through transfer learning?\n    -- How was an optimum model selected?\n   ",
            "summary_of_the_review": "The paper does tackle a major issue in the facial analysis space. The experimental setup (manual curation of data, surveys, no of respondents, a curated dataset) is admirable and is a tedious job. However, technical aspects are limited. The experimental outcomes such as the efficacy of existing commercial models, ease of verification that identification, difficulty in identifying given a specific skin color are well explored in the literature.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper investigated the face recognition performance of humans and machine-learning methods. For this investigation, the authors improved the open dataset like LFW and CelebA, implemented the identification/verification quiz interface, and compared the performance for multiple aspects like gender and skin type. Through the experiments, they confirmed that the machine-learning methods also have a similar recognition bias to humans. ",
            "main_review": "Strengths:\n+ Interesting viewpoint. \n+ The authors took care of a fair comparison. For this purpose, they took great efforts to improve the datasets and they eliminated extreme cases on the investigation of human ability.\n\nWeaknesses: \n- Most experimental results about human performances seem too bad; much worse than machine performances. I guess it would be because they used crowdsource platform. I wonder if it is not reasonable to regard the human bias found from these experimental results as of a natural human and conclude as if it is general properties. ",
            "summary_of_the_review": "As discussed in \"Main Review,\" I wonder if the crowdsource did not reflect the human ability. Considering there is no technical novelty and the main contribution should be the facts obtained from the experiments, the reliability of the data is essential. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper attempts to better understand the machine bias present in facial recognition as it compares to humans. The authors posit that existing works do not compare the biases observed in machines with those observed in humans.  In addition, they claim that common facial recognition datasets do not contain the type of accurate metadata needed to measure these biases, and suffer from other issues such as: incorrect identities, low quality images, lack of color images, identical context (e.g. clothing) making the task trivial, and multiple faces in images.\n\nIn this paper, the authors have created a new dataset called InterRace.  This dataset was created by taking the LFW dataset, manually reviewing and correcting the labels; discarding low quality and duplicate images; and supplementing with images from CelebA to increase the number of images of faces with darker skin tones. \n\nThe authors also run a user study with 500+ individuals who perform facial verification and identification tasks.  Survey questions for the tasks are generated using the InterRace identities, and are designed to be nontrivial and to only rely on facial cues (not context).   The participants’ performance on these tasks is compared to that of 6 face recognition models and 3 commercial APIs.",
            "main_review": "Strengths:\n* (+) The datasheet for the dataset states that the authors will release this dataset to the public and provide support for it, which will be valuable for the community.\n* (+) The dataset and survey design is documented thoroughly, making it likely to be straightforward to reproduce.\n* (+) The paper is written clearly, and it is easy to understand.\n\nWeaknesses:\n* (-) While the discussion of the dataset and survey creation are quite thorough, there are minimal details provided as to how the face recognition models are trained.\n* (-) The face recognition models are not trained using the cleaned up InterRace dataset; it would be interesting to observe how performance changes/improves when the models use cleaner training data.\n* (-) The authors have presented a comprehensive analysis of the human and machine performance on the tasks, but have not provided actionable suggestions for how other researchers in the field should proceed and use this information.\n* (-) The dataset was created with a high level of manual curation and thus it is not scalable to expand it in the future.\n* (-) The dataset does not contain any individuals labeled outside of male or female. The authors acknowledge this.",
            "summary_of_the_review": "In this paper, the authors have designed a survey for comparing machine and human bias.  I find there to be value in having a clean dataset like InterRace to perform studies on biases. It is also convenient to have a measurement to compare machine and human performance on the same level.\n\nHowever, I’m not completely convinced that we should be looking at the biases between humans and machines in this context.  First, it’s not clear what value this comparison offers, as the authors have not provided recommendations for what to do with the analysis.  Second, the observations presented are relatively straightforward, so the insight gained from these results is somewhat limited.  Third, this study does not really comment on the other hidden factors that may influence human biases in facial recognition, namely race, ethnicity, and other cultural elements.  The results lump identities and participants with the same skin tone together, but they may belong to different races and thus have different inherent biases.  Given this, my impression is that this paper is slightly below the acceptance threshold but I’d be interested to get more perspective from the authors on the points above.\n\nMiscellaneous notes:\n* Section 1: 4th point: “Commercial APIs...across racial or gender lines”.  “Skin tone differences” should be used instead of race, because race and skin tone are very different dimensions.\n* Section 3.2: missing “skinned” in “lighter identities”\n* Section 4.1: 1st paragraph, last sentence is missing a period",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}