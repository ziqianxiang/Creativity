{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, the authors proposed to a non-parametric video prediction algorithm using Gaussian process. The authors proposed to apply use Gaussian process, without any adaptation to video prediction task. The authors evaluated the proposed method on synthetic data without any comparison with related work.",
            "main_review": "In general, this is a low-quality submission, because:\n\n1) The novelty of this work is very limited. The authors simply flatten a video as a vector and applies Gaussian process in a straight forward way, without utilizing particular properties of image or videos. This will lead sub-optimal results.\n\nFor example, in this work, the authors proposed to use RBF kernels to model the relationship between frames. In another word, it uses RBF to model motion. However, RBF is not a good model to formulate the Lagrangian motion, as it cannot model the pixel correspondence. I think this is why the proposed method can only work on simple synthetic video.\n\n2) The authors only evaluated on synthetic data without comparison with any related video prediction algorithm. Without proper comparison, I don't think the authors can claim that \"To overcome drawbacks\" in the previous work. Also, the extension of the proposed method to more realistic videos is unclear.\n\n3) The method proposed by the authors do not match what authors claimed in the introduction.\n\nFor example, the authors claimed that the other video prediction method is \"The predictive accuracy of such methods also breaks down without warning, when tested on data far outside their training distribution\". However, the proposed method only works for Gaussian distribution, and it is well-known that Gaussian distribution can poorly model the distribution of image, video, or motion, as images lies in a high-dimensional manifold space. \n\nThe authors also claimed that \"this problem is exacerbated by the fact that these networks can be prohibitively expensive to update with recent data acquired online\". However, non-parametric methods do not scale well when more training data is coming, as the complexity of the model grows when the number training data grows, while the inference time of a parametric model (say a normal convolution network) keep constant, no matter how many training data is used.",
            "summary_of_the_review": "Given that this work has the limited novelty and limited experiment, I suggest a strong reject.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a Gaussian process regression framework for video prediction alongside producing a confidence for the predictions. Experiments are provided on prediction tasks where the videos have smooth dynamics such as in predicting the vorticity of incompresssible fluids on a torus and demonstrate some promise.",
            "main_review": "Strengths:\n1. The paper is easy to read and follow.\n2. Experiments show some promise.\n\nWeakness.\n1. The paper lacks any novelty as far as I see. The presented approach is a very straightforward application of Gaussian process regression to the task of video prediction (without any deep learning components). \n\n2. There are prior works on video prediction using predictive uncertainty that the paper should cite and contrast against such as:\nA Hierarchical Variational Neural Uncertainty Model for Stochastic Video Prediction, Chatterjee et al., ICCV 2021.\n\n3. The experiments are quite shallow and there are no comparisons to prior methods on video prediction either with or without confidence. Further, using smooth dynamics is perhaps a strong assumption to use in the videos. I wonder why the paper did not chose to check how the performances are using some deterministic or stochastic deep models on the used datasets? ",
            "summary_of_the_review": "The paper lacks any significant novelty and experiments are significantly below the par for ICLR.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethical issues.",
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper investigates the application of Gaussian Processes to video data. The authors analyze a problem setting in which only the first k frames of a video are available during training. For this low-data regime, the authors propose to train a GP on sequences of pxp patches in the input video. The authors evaluate their model on synthetic videos that model solutions to the Navier-Stokes equations.",
            "main_review": "I found this paper easy to follow and well-written. The description in Section 4.3 of how a patch-based GP can be used to autoregressively generate future frames via moment matching seems interesting and novel to me. I also believe the \"zero-shot video modeling\" problem setting that the authors study is fairly novel.\nDespite these strengths, I do find this paper unsatisfying for a few reasons.\n\n(1) The title and introduction to the paper seem to imply that the strength of the paper comes from the use of GPs. However, my sense is that the main difference between the performance of GP and FNO in Figure 5 has more to do with the pre-processing that was done for the GP described in Section 4.2, not the use of a non-parametric model vs. a neural network. The authors need to train a neural network on the same path-based data that was used to train the GP in order to prove the claim that non-parametric models are out-performing parametric models in their problem setting.\n\n(2) More generally speaking, there's some disconnect for me between the {title, abstract, and introduction} vs. {model, experiments}. My sense when reading the start of the paper was that this method was motivated by the desire to model natural videos. However, the problem setting analyzed by the paper in which only the initial k frames are available for training doesn't match the problem of modeling natural videos; natural videos are available in abundance and in general it makes perfect sense to train a large model on as many videos as possible. Additionally, the patch-based structure of the model proposed by the authors limits the receptive field of the GPs in a way that would seriously bottleneck the performance of this model on natural images. Their model also assumes pixels are independent gaussians which is an especially poor assumption for natural images. Either the authors should showcase that their model does in fact have the potential to model natural videos as promised in the introduction, or they should motivate their contributions with an application that more closely matches the zero-shot prediction setting under study.\n\n(3) Using synthetic videos for experimental evaluation feels like an imperfect choice for a zero-shot prediction paper in that we can easily generate infinite synthetic videos for training. What would be the reason to restrict training to a single video for the problem of modeling solutions to the Navier-Stokes equations? Is there a different video prediction benchmark where restricting training to a single video is better motivated?\n\n(4) The paper consists of plots showing the performance of the model on example inputs, but there's no plot of \"average performance\" for comparing GP vs. baselines.\n\n(5) The metric Eq. 9 needs some justification - you can minimize this metric just by training a model to predict a large $z_\\sigma$. Shouldn't the authors evaluate using log-likelihood?\n",
            "summary_of_the_review": "This paper proposes to use GPs for video prediction. The paper focuses on a problem setting in which only k initial frames of a single video are available for training. Due to the \"zero-shot\" setting, the GPs are trained on sequences of small patches from the input images, thereby increasing the amount of training data but also making the strong assumption that dynamics are highly local and shared across all parts of the image. These are poor assumptions to make when modeling natural videos, but the authors test on videos of synthetic fluid simulations which satisfy these assumptions to a higher degree. As a result, the ultimate purpose of the model proposed in the paper is somewhat unclear - many of the modeling choices are tailored for the fluid dynamics videos used in the paper, but also for fluid dynamics videos it's easy to generate infinite training data so it's unclear why the authors would choose to restrict themselves to a problem setting in which only the initial k frames of a video are available for training. Additionally, the paper makes the claim that \"non-parametric models\" are optimal in this setting but they are missing a baseline in which they train a parametric model on the same \"patch-based\" input data that they use to train their GP.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}