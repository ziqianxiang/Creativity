{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper introduces ALANS - a neurosymbolic system, designed to do well on the reasoning task of Rave’s Progressive Matrices (RPM). In RPM, one is given a 3x3 grid of images, where the image in the 3rd row and 3rd column is missing. The goal is to select the best fit for the missing image from a number of candidate images. ALANS does this by combining 3 components. First, a convolutional NN (CNN) is used to separately process each object in each of the provided images. Second, the CNN’s outputs for all objects of a single image are aggregated using a “belief state inference engine”. Third, an “algebraic abstract reasoning” module is used to generate the answer. It induces an instance-specific transformation from the first 2 rows, which is then used to select the 3rd row’s final image. The approach is evaluated on RPM where it outperforms the baselines.\n",
            "main_review": "I enjoyed the introduction, as it was informative and filled with intriguing references.\n\nPros:\n\nP1) The formalism of the problem and of the algebraic abstract reasoning component provide an interesting direction of tackling abstract reasoning.\n\nP2) The idea of inducing operators on-the-go appears novel and promising.\n\nP3) The experiment section includes many baselines, which supports the method’s promise on this dataset.\n\nP4) The ablation experiments contribute to understanding the method’s performance.\n\nCons:\n\nC1) I found several issues with the paper’s clarity. \n--For instance, the RPM problem is described, but an example figure is not referenced. --Moreover, the text mentions that each object of the image could have different colors, while the example in Figure 1 leaves the reading with the impression that all input images are grayscale.\n--I found the description of the algebraic abstract reasoning module to be slightly confusing. Specifically, I’m unsure how the parameterised matrix M_0 is used. Does the kth value in the last sentence of page 5 indicate a power or an index?\n\n\nC2) The approach appears to be tailored to RPM. For instance, the CNN is hand-designed to take advantage of the structure of the inputs. The object function assumes that we know all attributes and that they are independent. The combiner, which yield probabilistic states also appears hand-engineered towards this problem (please correct me if I’m wrong). As a result, I’m unclear about the more broad applicability of this model beyond RPM. I might have missed it, but I didn’t find a strong argumentation of why the presented results indicate that this methods is promising for more than solving RPM. This is the main concern I have with the paper.\n\nC3) Generative Potential: Hinted at, but not well described. For instance, what are the limitations of this? If, after the original training, one was to generate the answer and use the L_2 distance from the presented choices, would it lead to the same performance?\n\nAdditional questions:\n\nQ1) What other problems, apart form RPM, can be solved using this method?\n\nQ2) Why do you think you don’t achieve 100% performance with perfect vision (ALANS-GT) in table 1?\n\nOverall, I found the setting and the idea of the paper interesting. However, I am concerned about the general applicability of the proposed method. The current solution appears hand-engineered towards RPM. As a result, I hesitate to recommend acceptance at this point.\n",
            "summary_of_the_review": "Overall, I found the setting and the idea of the paper interesting. However, I am concerned about the general applicability of the proposed method. The current solution appears hand-engineered towards RPM. As a result, I hesitate to recommend acceptance at this point.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This work presents ALgebra-Aware Neuro-Semi-Symbolic (ALANS) learner to improve systematic generation in reasoning in the context of the Raven's Progressive Matrices (RPM) task. ALANS constitutes a neural visual perception frontend and an algebraic abstract reasoning backend. The problem setting is similar to PrAE(Zhang et al. 2021) except here the probabilistic scene representation is transformed into an algebraic structure and the hidden operator is induced on the fly. The induced operator is executed to predict the representation of the solution.\n",
            "main_review": "## Strengths\n \nAt a first glance, this work may appear as an incremental improvement over PrAE. The ability to induce the hidden operator on-the-fly without access to the ground-truth semantics, on the other hand, is significant. \n* The evaluation is thorough. ALANS has been compared with 8 baselines. Ablation studies are carried out to understand the importance of the algebraic representation.\n* The paper is written well. I found Figure 3 to be helpful in getting a sense of the system’s capability.\n \n## Weaknesses/Suggestions\n \n* The scope and limitations of the approach are not made explicit. I would like the authors to discuss the limitations and assumptions. Is the approach too tied to this particular problem setting (RPM)? What are the other problem settings where it can be applied? What additional efforts would be required to do so? (e.g Can this approach be adapted for the Abstraction and Reasoning Challenge (ARC) problem?).\n* The model is compared exclusively with neural approaches. It would be nice to see how it stacks against the symbolic approaches (even those that use a problem specific DSL).\n \n* The evaluation is done on test/train splits based on the target principles(Systematicity, Productivity, and Localism). Although, this is required to support the claims, it would also be helpful to see the performance of ALANS on a random train/test split. This setting would be easier for the connectionist approaches.  But it would be helpful to see the difference.\n \n* The dataset is synthetically generated using the methods proposed in Zhang et al. (2019a) and Hu et al. (2020). The authors are probably aware of the underlying relations used. This might result in unconscious bias in designing the approach. I would like the authors to make explicit the assumptions about the operators. It would also be nice to evaluate the system on non-synthetic RPM datasets (if available).",
            "summary_of_the_review": "Overall, the work is a valuable contribution, especially the ability to induce the operator. However, I have difficulty in judging the scope and applicability of the approach. Currently it looks too specific to RPM-like problems. I must, however, admit my lack of expertise in representation theory. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes ALgebra-Aware Neuro-Semi-Symbolic (ALANS) learner, a neuro-symbolic architecture that exploits algebraic representation to improve systematic generalization. The authors demonstrate the advantages of ALANS for the abstract spatial-temporal reasoning task of Raven's Progressive Matrices (RPM).\n",
            "main_review": "### Strength\n\nThis paper studies an important problem:\n\n- Connectionist models' lack of systematic generalizability is a well-know problem and a fundamental limitation.\n- ALANS aims to be what the authors call neuro-semi-symbolic, where the involved operators can be learned instead of manually specified.\n\n### Weaknesses\n\nThe paper in its current form is extremely challenging to understand.\n\nThere is no proper background review, and many concepts are used without explanation, with vague, uninformative references to general texts. Two representative examples are:\n\n- The reference to *Arithmetices principia: Nova methodo exposita* for the Peano Axiom and its later use for constructing an integer-indexed set. It seems the authors are just trying to define a sequence of matrix multiplications. I fail to see the point of framing it as using the Peano Axiom.\n- The reference to *Introduction to Lie algebras and representation theory*, which seems to be a whole textbook, for representation theory. The paper vaguely mentions something about gleaning the hidden properties in the abstract structures/making abstract algebra amenable by reducing it onto linear algebra (last paragraph on page 5), none of which is explained in the context of this paper.\n\nMany concepts/terms/details of the model are not properly defined, and it looks close to impossible to understand what is really going on with the model. Some examples include:\n\n- The probabilistic belief state in the neural visual perception module in Sec. 3.1. I'm guessing it's the probability mass function for some of the summarized attributes, but I don't know for sure given the presentation of the paper. The paper references *Abstract spatial-temporal reasoning via probabilistic abduction and execution* for more details, but there is no mentioning of *belief state* in that paper. The referenced paper does mention a probabilistic scene representation, which seems very similar to the so-called probabilistic belief state. It would be helpful to clarify the connections. Also, since the neural visual perception module is the same as the referenced paper, I suggest moving the description to the (currently missing) background section, to make it clear that the neural visual perception module **is not** part of the contribution of this paper, but rather is taken directly from a previous paper. And it would be nice to avoid copying from the referenced paper almost word-for-word (e.g. for Eq. (2) and related texts).\n- It's not clear to me what an operator means in this paper. From the top paragraph of page 6, it seems like an operator is just a matrix? What do unary/binary/ternary operators mean? What are row-wise operators mentioned in **Algebraic Underpinning** on page 5?\n\nMy current understanding of the paper is that it reuses a neural visual perception module from a previous paper to extract distributions on a few panel attributes, and introduces a reasoning modules based on matrix computations. It looks possible to adopt a much simpler presentation, where the extracted distributions and the relevant matrices are explicitly defined. For example, how many probabilistic belief states do you have? How are they parametrized (as probability mass functions for discrete attributes/parametrized probability densities for continuous attributes? how many dimensions? what are the relevant parameters?)? What are the involved matrices? What are the dimensions of these matrices? What kind of matrix computations are involved? How are these computations related to RPM? Right now I don't see the value of all the algebra jargon (other than confusing the readers) for describing the actual model. In addition, there is no code attached, which is quite concerning for a paper whose computations are so hard to understand.\n\nI suggest the authors include a background section reviewing the neural visual perception module and any other relevant concepts, and consider cutting down many of the current algebra jargon and more explicitly present the model in terms of matrix computations. And it would helpful to include code implementing the model to make the details of the model clear.\n",
            "summary_of_the_review": "The paper studies an important and relevant problem, but the model description is poorly written and close to incomprehensible. I recommend rejection.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In this paper, the authors propose an innovative architecture that can learn to effectively solve abstract visual reasoning tasks belonging to the popular Raven’s Progressive Matrices test. The proposed system combines “perceptual” connectionist modules with “reasoning” backend modules that explicitly rely on algebraic processing. Notably, algebraic operators can be learned and adapted “on the fly” through an inner-level optimization. Moreover, the model can produce plausible top-down solutions exploiting generative processing combined with a rendering engine.",
            "main_review": "- This is a very well-written paper, which tackles an interesting and contemporary research problem. The literature overview contains most of the state-of-the-art approaches and provides a nice historical perspective on the debate between connectionists and algebraic modeling frameworks.\n- The text is sometimes a bit redundant (e.g., there are several duplicated sentences in Introduction vs. Sections 2.1 and 2.2) and could be shortened.\n- Is the assumption of independence among attributes justified (eq. 1)? If it holds only for the RPM domain, how could that assumption be relaxed in future extensions of the model?\n- The ALANS model strikingly outperforms other state-of-the-art approaches. On the one hand this is remarkable; on the other hand, one might wonder whether the proposed model could be easily extended to other reasoning domains (e.g., involving language, physical interactions, structured data…) or whether it is in fact tailored to solve Raven’s matrices. It is certainly useful to focus research on neuro-symbolic reasoning on RPM problems, since they constitute a standardized benchmark, but it would also be useful to demonstrate the generalization capability of the model on a variety of reasoning domains. This would be important especially considering that “algebraic engines” are supposed to guarantee better generalization compared to connectionist models. I am not asking the authors to perform experiments on other domains, but it would be nice to elaborate a bit on the generalization potential of the proposed framework.\n- The claim for “semantic interpretability” is exaggerated, since it is only covered with a brief discussion in Appendix F. Such argument should be better supported or de-emphasized.",
            "summary_of_the_review": "I think this paper presents high-quality research work. Though the debate between connectionists and symbolic approaches won't be settled by simulating reasoning over Raven's matrices, I think this paper would be of interest for the ICLR community and it will spur further research on the topic.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}