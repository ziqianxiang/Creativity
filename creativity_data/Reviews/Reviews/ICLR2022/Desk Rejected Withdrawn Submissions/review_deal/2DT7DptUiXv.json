{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper studies the problem of metric learning for handling catastrophic forgetting. All the reviewers recommended clear reject because of writing issues and lack of experimental investigation to support the ideas. The authors did not provide a rebuttal. Hence, the reviewers' opinion still remains the same. AC agrees with the reviewers and believes that the paper is not yet ready."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper investigates the viability of generating “embedding” exemplars from a VAE that can protect base knowledge in the intermediate to output layers of the neural networks. Experiments on the CUB-200 and CARS-196 datasets with an incremental similarity learning setup are conducted.",
            "main_review": "Generally, I think the novelty of this paper is somehow limited. Furthermore, It would strengthen the paper if there is some theory showing that why using the proposed CON-VAE can boost the performance. The motivation of using VAE seems not very clear.\n\nThe authors should claim the motivation of the tested datasets (CUB-200 and CARS-196). To my knowledge, these datasets are used for test fine-grained classification tasks. Also, why only metric learning tests are evaluated in the experiments? How about its performance on other tasks?\n\nWill be good if the author can articulate other impactful contributions of this approach beyond the CON-VAEr selling point. My sense is that there may be other good properties of this approach. More analyzes should be conducted.\n\nPage 4, Paragraph 2: “combine ideas from Rannen et al. (2017) and Rebuffi et al. (2017)”. This might be a typo.",
            "summary_of_the_review": "Overall, although this research topic seems an interesting problem, the novelty of the paper is somehow limited.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors propose some changes to an existing approach called FullVAE for incremental metric learning for the problem of catastrophic forgetting. Both ConVAER and FullVAE use VAEs for generating feature representation prototypes that could be passed through the intermediate layers of a network. The proposed changes are the position of feeding the generated prototypes from the VAEs to the network and a modified VGG network instead of a simple ConvNet. They evaluate their method on 2 real-world datasets and show improvement compared to the baselines.",
            "main_review": "Weaknesses: \n1. The evaluation of this work is weak. The reviewed literature seems not to be very recent. There are only a few papers from the 2020 or 2021 referenced. The authors are comparing their method to iCarl from 2017, and FullVAE (which again does not compare to works after iCarl). Recent SOTA works in incremental learning such as PODNet (Douillard et al., 2020) and CCIL (Mittal et al., 2021) are not referenced or compared to. The method is not evaluated on standard incremental learning datasets such as Cifar100, ImageNet-100, ImagNet.\n\n2. The paper is not well organized and structured. Parts of the method are in related work and instead, the experimental setup is written in the methodology section which should be in the results section.\n\n3. The contributions of the work are very limited, compared to FullVAE the only difference is moving the VAEs to the Conv layers instead of FC layers and a new architecture.\n\n4. The text, equations and figures are heavily borrowed and have a lot of overlap with FullVAE. Even if the authors are the same, this could count as self-plagiarism since the authors consider ConVAER an extension of FullVAE.\n\n5. There is no ablation study to show whether the change in the architecture or the change in the position of VAEs is affecting the improvement.\n\nStrength: \n1. The proposed changes are shown to improve FullVAE. \n2. The method is evaluated on 2 datasets and using 3 losses.\n",
            "summary_of_the_review": "Even though the suggested improvements by the authors seem to be effective, there are a lot of weaknesses in the work. I suggest rejection of this work since there are currently many issues with the current version.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "Yes, Research integrity issues (e.g., plagiarism, dual submission)"
            ],
            "details_of_ethics_concerns": "The text overlap with the FullVAE work (Huo and Zyl) is concerning.",
            "recommendation": "1: strong reject",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents the method for incremental similarity learning using feature replay with VAEs. The experimental section investigates the impact of different loss functions on the final performance of the model. Yet, the discussion of the results lacks any insights which could be beneficial for the community.\nThe idea to replay features instead of images is not novel and the proposed method is just a minor modification of the method introduced in the paper [1] (which was published on arXiv 4.10.2021 -- two days before the deadline of ICLR submissions).\nDue to the lack of novelty in this paper, it should be regarded as a form of ablation study for the paper [1] rather than a separate research paper.\n\n[1] Incremental Class Learning using Variational Autoencoders with Similarity Learning, J. Huo et al.\n[2] GDumb: A Simple Approach that Questions Our Progress in Continual Learning, A. Prabhu et al. (edited) ",
            "main_review": "Strengths:\n- The idea of exchanging data with its features to improve past experience replay is interesting and inline with the current trends in continual learning.\n\nWeaknesses:\n- The paper is poorly written and unstructured (e.g. the method is explained in the related work section, the related work section is not coherent) which makes this paper hard to read.\n- The literature review is insufficient. Citing three loosely related papers is far below the standards of the ICLR conference. Suggesting that results from 2017 (iCARL, EEBL, EWC) are currently the state of the art is simply untrue. For reference see [2]\n- This paper simply stacks a few previously introduced mechanisms/methods (VAE, feature replay, knowledge distillation, metric learning). However, there is no explanation why is it worth doing so and how these results could be useful for others. \n- The experimental details are confusing and should not be presented as incremental learning evaluations. The authors use two datasets with 196 and 200 classes. Yet, their experiments are performed with 160 classes. How these 160 classes are drawn and why the rest is abandoned? Additionally, the authors pretrain their models with 120 classes (75% of the whole dataset) in a standard (supervised learning) way and present the results for the remaining 40 classes learned incrementally. Such experiments are not challenging and bring no information about the method. ",
            "summary_of_the_review": "See the comments above.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "Yes, Research integrity issues (e.g., plagiarism, dual submission)"
            ],
            "details_of_ethics_concerns": "I'm unsure how to treat this submission as it is simply a minor extension of an arxiv paper (published before ICLR submission) with a lot of the text overlapping, hence the potential risk of plagiarism.",
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}