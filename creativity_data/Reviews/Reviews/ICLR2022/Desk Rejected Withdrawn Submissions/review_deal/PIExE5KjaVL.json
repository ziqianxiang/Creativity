{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper describes the development of an approach to policy optimization that incorporates a supervisory safety reference model which assumes control in dangerous situations in order to limit failures. As motivation the paper proposes studying the problem of autonomous racing. This setting is interesting because performing optimally requires achieving states which are very nearly unsafe (e.g. at the limits of tire friction). The paper highlights the connection of the proposed approach to existing work on Hamilton-Jacobi reachability. The method described enables the application of Hamilton-Jacobi reachability concepts to higher dimensional state observations while sacrificing some of the formal guarantees provided within traditional control-centric analysis. In order to demonstrate the effectiveness of the approach the paper considers three experimental settings. The first two toy experiments are used to evaluate the method against ground truth safety. The paper culminates with a demonstration of the method within a more realistic racing simulator. ",
            "main_review": "Strengths\n1. The problem of autonomous racing is generally very interesting because it highlights the insufficiency of pure performance or safety oriented methods and needs better solutions. \n2. The toy examples motivate the method.\n3. The experimental setting (e.g. the Learn2Race racing simulator) is a good benchmark.\n\nWeaknesses\n1. It is unclear what the proposed method can and cannot guarantee. It is described as principled, but as compared to model predictive control it is neither performant nor safe.\n2. The problem setting is insufficiently described in the introduction. It isn’t until the final experiment that it is clear that only single vehicle racing will be considered. Given that this is the case there is a stronger burden of proof necessary to motivate this method. There is a very large literature from the control community which uses similar state information to achieve much better results. The paper should motivate better why model free RL is appropriate for this task. \n3. The literature review doesn't cover some other work in this area:\na. RSS: https://arxiv.org/abs/1708.06374 (original) and link to HJ reachability formulation https://arxiv.org/abs/2107.14412\nb. Certified control: https://arxiv.org/abs/2104.06178\nc. Simplex Control: https://arxiv.org/abs/1908.00528\nd. (Bayesian) Learning MPC: https://arxiv.org/abs/2005.04755, https://ieeexplore.ieee.org/document/7171151, https://arxiv.org/abs/1901.08184, https://arxiv.org/abs/1711.06586\ne. Contraction theory/Robust Planning: https://ieeexplore.ieee.org/abstract/document/7989693\nf. Overview of autonomous racing sims/problems: https://proceedings.mlr.press/v123/o-kelly20a.html \n4. Many of the details about the SPAR policy are left to the appendix. Given the audience (ML community) the formulation of the SPAR policy is probably of larger interest than the details regarding the nominal reference model. \n5. The baseline comparison in the Learn-to-Race experiment is insufficient. It is disingenuous to not include model-based or control theoretic methods. Completing 80% of a lap in this context would lead to very different conclusions about the suitability of the proposed approach for further study. \n6. Safety margin, based on distance, and the approximation of the vehicle contour as a disk is a very flawed approach. A large number of the performance issues are likely attributable to this model and the fact that it fails to accurately encode the \"continuum\" of safe vs. unsafe states. \n7. The key aspect of HJ reachability is the maximization term inside equation (4), it is not at all clear that either the learned value function or the nominal model compute/estimate this term in a reasonable way. Much of the justification is contained in Fisac et al 2019, but isn't argued clearly in this paper. Moreover in Fisac 2019 they describe that in order to learn the value function it is necessary to experience unsafe states which could defeat the purpose of the approach. \n\nMinor\n1. “Livelyness” it is common to refer instead to “liveness” and its not clear to me that the informal definition here aligns with commonly accepted literature (that over an infinite horizon “always, eventually” the property in question is satisfied).\n",
            "summary_of_the_review": "The paper describes an interesting approach to improving the safety of model-free policy optimization in the context of autonomous racing. The theoretical aspects of the work are largely based on previous work and thus are limited in their contributions. Moreover, although the topic is of great interest, the empirical results do not demonstrate the suitability of the approach. The authors should revisit the implementation of the signed distance function encoding safety. Finally, additional comparisons to model-based methods (e.g. MPC) would provide a more reasonable baseline from which to judge the usefulness of this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Summary: This paper appears to solve a HJ Reachability problem for an unknown dynamical system by fusing CMDPs with RL. Little theoretical analysis is provided and the results are at best circumstantial.",
            "main_review": "+ Can the authors add a reference to the statement __\"Due to scalability\nissues with HJ reachability, these models tend to be low-dimensional representations of the true system (up to 5D for offline computation, and 2D for online computation)\"__? \n\n+ A citation is needed for this statement as well: __\"Because of this, the technique can only be used directly on systems of up to\n4-5 dimensions.\"__\n\n+ On page 3, near the bottom, under the HJ Reachability function, emphasize that the state $x$ is in an open set in $\\mathbb{R}^n$\n\n+ At the beginning of page 4, did the authors mean that the control is bounded and possesses Lipschitz continuity?\n",
            "summary_of_the_review": "Empirical paper.\n\nLittle theoretical result.\n\nLittle novelty.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper addresses the policy optimization task for autonomous racing under safety constraints by injecting the Hamilton-\nJacobi (HJ) reachability constraints into constrained MDP problems.\n\nDisclaimer: my background is in computer vision applied to autonomous driving, so I might not be the best person to review this paper. I have some knowledge on RL for AV and control. But apologize if I get certain ideas wrong.\n\nThe authors claim the following contributions:\n\n- The formulation of the HJ Bellman update rule, which is compared to learning a safety critic. The authors demonstrate that HJ Bellman updates are more accurate and sample efficient.\n- The authors also demonstrate that the HJ safety value function can be learned e2e from perception data.\n- Finally, they evaluate the methods on Safety Gym and Learn-to-Race, and report state-of-the-art results.\n\nI agree with the authors' assessments.\n\n",
            "main_review": "(+?) Novelty: The paper addresses a problem that important to autonomous driving, where unconstrained RL is not easily applicable. Judging only from the related works listed in the paper, I would perceive the work sufficiently novel, with my limited subject knowledge.\n\n(+) Sufficient experiments: The paper includes experiments on multiple datasets, from benchmarks where the safety is analytically known, to e2e RL from perception to control. Experiments are interesting and demonstrate the efficacy of the proposed model.\n\n(+) Well written: I really appreciated section 3 on the preliminaries to help me understand the novelty of the paper. Paper is written clearly.",
            "summary_of_the_review": "I think that the paper demonstrate sufficient novelty and experimentation.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes an approach, called Safety-aware Policy Optimisation for Autonomous Racing (SPAR), which combines a policy optimization algorithm with Hamilton-Jacobi (HJ) reachability analysis to infuse control theory and safety-awareness into Reinforcement Learning (RL) algorithms. The proposed approach combines a performance policy (trained using any RL algorithm) with a safety policy inspired by HJ reachability theory. The proposed approach is verified through multiple experiments, including an autonomous racing scenario. ",
            "main_review": "*** STRENGTHS ***\n\nThe problem addressed in this paper is interesting, as infusing safety into RL policies is critical to their successful deployment in real-world systems, including autonomous driving applications. The proposed approach appears quite effective, and the paper is, in general, well written.\n\n*** WEAKNESSES ***\n\nI have a number of concerns against this paper:\n\n(1) The problem formulation is somewhat unclear: specifically, in Section 3, the presentation of the constrained Markov decision process (CMDP) model and the overview of HJ reachability theory are somewhat unclear and disconnected. Specifically:\n-  CMDP: the MDP with $(\\mathcal{X},\\mathcal{U},R,\\mathcal{F})$ appears to be deterministic (since the authors write $\\mathcal{F}:\\mathcal{X}\\times\\mathcal{U}\\rightarrow\\mathcal{X}$). The policy is also deterministic, since the authors write $\\pi:\\mathcal{X}\\rightarrow\\mathcal{U}$. As such, it is unclear where the stochasticity comes from when stating the expected cumulative reward objective $V_R^{\\pi}(x)=E_{x_k,u_k\\sim\\pi}[\\sum_{k=0}^{\\infty} \\gamma^k R(x_k,u_k)|x_0=x]$.\n- HJ reachability: The authors assume deterministic dynamics $\\dot{x}=f(x,u)$ with no disturbances. In equation (2), the authors denote the state trajectory as $\\xi_{x,T}^{u,d}$. However, $d$ is undefined and the value function $V_S(x,T)$ does not have a dependency on $d$. In the literature on HJ reachability analysis, $d$ is often used to denote disturbances and the definition of the value function typically requires an additional $\\min/\\max$ computation over the disturbance $d$. Thus, the HJ setting considered in this paper is unclear.\n- Combined formulation: due to the ambiguity in the problem formulation, it is unclear whether disturbances are accounted for, either in a deterministic sense (as suggested by equation (2)) or in a stochastic sense (as is usual when formulating CMDPs). In other words, it is unclear what problem this paper wishes to address.\n- The proposed approach entails solving the problem stated in equation (5). However, in equation (5)  the constraint thresholds $d_i$ appearing in the CMDP formulation in equation (1) are no longer present, which is confusing. More broadly, the relation between the problem that the SPAR algorithm addresses (equation (5)) and the original CMDP problem (equation (1)) is unclear, and one wonders if the CMDP formulation should even be mentioned in this paper. \n\n(2) Some key claims are questionable: in particular, throughout the paper, the authors state that their proposed approach works \"directly on vision context\" whereas HJ reachability techniques \"can only be used directly on systems of up to 4-5 dimensions.\" However, in the racing car experiment, evaluating the function $\\ell(x)$ that measures the distance from the car to the road boundary requires knowledge of the position of the car. It is unclear how the algorithm would work \"directly on vision context\" if one had not access to this lower-dimensional state representation. Also, given the lack of clarity in the problem formulation, the claim \"we inject HJ reachability theory into the constrained Markov decision process (CMDP)\" is questionable.\n\n(3) The experimental evaluation requires stronger baselines: in Sections 5.1-5.2, the results demonstrate that SPAR works well and out-performs RL baselines which do not assume knowledge of the function $\\ell(x)$. The authors should also implement baselines that account for such information, for example, the authors could define an MDP with the added cost term $\\mathbb{E}[\\sum_{k=0}^\\infty \\gamma^k (-\\ell(x_k))]))$. \n\n(4) The literature review should be improved: since the main application of the proposed approach is autonomous racing, and since the authors assume 4D state knowledge to evaluate $\\ell(x)$ in the experiments, it would be interesting to compare the proposed approach with (or at least cite) specialized techniques for autonomous racing, for example, https://arxiv.org/abs/2103.04909. Also, the proposed approach is quite related to safety filter design. For instance, control barrier functions can be used to filter the output from a RL policy and guarantee the safety of a system. Adding references to related work on safe model-based dynamics learning, control and planning would strengthen the paper, for example arxiv.org/abs/1906.12189, ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9147584, and arxiv.org/abs/1812.05506\n\n\n\n\n\n\n",
            "summary_of_the_review": "While this paper addresses an interesting problem and proposes a reasonable solution, it suffers from a number of weaknesses, in particular (1) an unclear problem formulation (most importantly, the connection to CMDPs is very handwavy and it is unclear what problem this paper wishes to solve), (2) some claims are questionable, (3) the experimental evaluation requires stronger baselines, and (4) the state of the art review requires the addition of references that appear very related to the work presented in this paper. \n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}