{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a method for data augmentation that seems to improve generalization. The proposed method consist in augmenting the training dataset by randomly cropping the image in the surrounding of the key object. Results show a substantial improvement on two medical datasets, whereas only a marginal improvement on a subset of the well known MS-COCO.",
            "main_review": "Improving the performance of a classifier when only few samples are available is certainly an important topic, however I fell like the authors overlooked a large amount of related work.\n\nAuthors basically used the bounding box of the object (location of the fracture in the x-rays) to boost the model performance. This information is only available at training time and not at test time; this setting is also known as learning with \"privileged information\" [1].\n\nA discussion on all the literature related to this framework is completely missing [1-6] (note that the list is not exhaustive, but the works provide other valid references). I believe Authors should also compare with some of these methods that use the bounding box information.\n\nMoreover there are some parts that need further clarification:\n- Authors say that they eliminated the attention mining branch in AGN but including additional supervision; this modification requires further explanation, as the original implementation seems to have changed significantly.\n- why not using a pretrained backbone?\n- since authors use a validation set, which model is used on the testing set? the one at the end of the training or the model that performed best on the validation set?\n- which data augmentation techniques are used when training the base model?\n- Unless the x-ray datasets are going to be made public, I think it is beneficial to validate the method on a third publicly available dataset, since there seems to be a large performance difference between MS-COCO and the other x-ray datasets. Other datasets could be subset of ImageNet, or smaller ones like CUB200 (any other well known dataset with bounding boxes basically).\n- Additionally it would be nice to see how the proposed method is effective when the size of training set changes, see experiments in [2].\n\n[1] D. Pechyony and V. Vapnik, “On the theory of learning with privileged information,” in NeurIPS, 2010.\n\n[2] Lambert, John, Ozan Sener, and Silvio Savarese. \"Deep learning under privileged information using heteroscedastic dropout.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.\n\n[3] S. Motiian, M. Piccirilli, D. A. Adjeroh, and G. Doretto, “Information bottleneck learning using privileged information for visual recognition,” in CVPR, 2016\n\n[4] Y. Chen, X. Jin, J. Feng, and S. Yan, “Training group orthogonal neural networks with privileged information,” in IJCAI. AAAI Press, 2017\n\n[5] Rodriguez, Andres C., et al. \"Privileged Pooling: Better Sample Efficiency Through Supervised Attention.\" arXiv preprint arXiv:2003.09168 (2020).\n\n[6] V. Sharmanska, N. Quadrianto, and C. H. Lampert, “Learning to rank using privileged information,” in ICCV, 2013.\n",
            "summary_of_the_review": "The method proposed in this paper is rather simple but apparently effective. Although simplicity is not by all means a weakness, I believe that a much stronger experimental section with additional comparisons is needed, as well as a more thorough description of related works. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The authors present a data augmentation mechanism called Cut&Remain for training convolutional neural networks. A model can distinguish subtle and small critical regions using the technique suggested in this work. ",
            "main_review": "Strengths:\n- The motivation of the paper is clear, and the paper is well-organized.\n- The authors validate their proposed model in a variety of scenarios, including binary, multiclass, and multilabel cases.\n- Cut&Remain relies just on the base network while its counterparts require additional regional guidance.\n\nWeaknesses:\n- The authors appear to conduct their experiments (particularly, binary and multiclass classification tasks) in a controlled setup. Even the dataset for multiclass classification is curated from their own institute, whereas the dataset for the binary case is unknown. If the authors could compare their results to a variety of open-source medical datasets, the study would be strengthened and the performance would be clarified more completely.\n- Because of the extensive use of complex and long sentences, the manuscript is difficult to follow. The authors may consider how to address concerns of readability.\n- There are a few typos (e.g., earning --> learning) as well as grammatical errors (e.g., The yellow box refer ...). I would like the authors to double-check the manuscript.",
            "summary_of_the_review": "The study seems to be beneficial for the research community. However, I have concerns regarding dataset selection and the robustness of the model when applied to a variety of datasets beyond their own institution. While the authors claimed to have presented a novel augmentation technology, I think the contribution is incremental and just slightly different from existing techniques. Overall, I am leaning toward rejecting the manuscript in its current state.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)"
            ],
            "details_of_ethics_concerns": "I would like the authors to make sure that the study has received ethics clearance properly for medical datasets.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper presents a novel data augmentation strategy, called Cut&Remain, specifically designed for medical image classification where the area of interest in an image for a diagnosis can be rather small. In comparison to a baseline method, without advanced augmentation strategies and recent augmentation methods that utilize similar concepts, such as MixUp or CutMix, models trained with the proposed augmentation method show to perform superior for the task of image classification on two medical datasets and on par on a subset of the MSCoco dataset of natural images.",
            "main_review": "The paper is mostly well written and easy to understand. The method is well motivated and the methodology explained sufficiently. While most comparable methods have focused on natural images the proposed augmentation strategy aims to better incorporate small details in the image that in medical applications often provide the relevant features for a diagnosis.\nThe paper presents evaluations on two medical datasets as well as on natural images and ablation studies on the amount of data used for augmentation with respect to the resulting performance of the model. In addition with the Grad-CAM visualizations this provides a good insight to the reader of  how the model performs on natural images but especially on medical applications, i.e. fracture classification.\n\nDespite the aforementioned strengths, I do have a doubt about whether or not the method actually learns to identify meaningful features in the image, or, if maybe it is simply trained to remember the most probable lesion location as that is the only information constantly given during training whereas background regions are cut-out. With this aspect in mind the method might not generalize well to other medical applications where the locations of lesions are more distributed over the image space. That might also explain why the gap in performance, in comparison to the baseline methods, on the MSCoco dataset is much less significant, as the location of an object in the image can vary significantly. \n\nFurther, as far as I understood for the CutMix baseline the region within the bounding box of an image A remains along with its label A, while the region outside of the bounding box is taken from image B. However I was wondering if it is not also still possible that a region with class specific features, or fracture, of image B is included in the resulting augmented image? This in turn could then cause issues during training as the label is not changed accordingly.\n\nIn addition, the related work section of the paper could be improved with respect to medical image analysis. For instance, there have been many methods specifically used for medical image analysis with a focus on guiding attention of neural networks to the region of interest, that would be worth mentioning in my opinion. One example: “Schlemper, J., Oktay, O., Schaap, M., Heinrich, M., Kainz, B., Glocker, B., & Rueckert, D. (2019). Attention gated networks: Learning to leverage salient regions in medical images. Medical image analysis, 53, 197-207.”\n\nRegarding the feature representation property experiment (section 4.4.2.), I am unsure whether or not this comparison can actually indicate a better performance. As the Mixup baseline, for instance, mixes two images of different labels and was designed to learn representations between different classes, I would assume it also to produce different feature representations between the original and augmented image, which however does not indicate that a worse representation has been learned.\n\nIt would also be interesting to see the Grad-CAM visualizations for the AGN baseline.\n\nMinor questions/comments: \n- For the Mixup baseline how has lambda (or alpha) been chosen? It seems that this parameter can strongly influence the method’s performance.\n- AGN baseline: Why was the attention mining branch eliminated?\n- I was wondering what the authors reasons where to introduce supervised versions of the baseline methods? I think it would also be good to explicitly mention the that the not supervised results are in the supplementary material.\n- In the conclusion t-sne results are accidentally mentioned that are not in the main paper but in the supplementary material.",
            "summary_of_the_review": "While I currently do believe that the method might not generalize well to applications where the location of interest is highly distributed in the image space and think that this, along with the aforementioned weaknesses, should be addressed, overall the paper provides good insights into the proposed method and how applying such a method can improve the performance especially for medical applications. For this reason I am leaning towards the acceptance of the paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}