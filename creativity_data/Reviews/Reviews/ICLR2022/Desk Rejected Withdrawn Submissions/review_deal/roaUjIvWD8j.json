{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper investigates and analyzes fingerprints from images generated by single image super-resolution (SISR) networks. The authors show SISR networks with a high upscaling factor or trained with adversarial loss leave distinguishable fingerprints. They also show success in reverse engineering for hyperparameters of SISR networks, including scale and loss function.",
            "main_review": "Strengths:\n+ Clear writing and demonstrations.\n+ Meaningful research topic.\n+ Technically reproducible.\n\nWeaknesses:\n- The technical novelty is marginal.\n  - For model attribution, the design and configurations are similar to Yu et al. 2019.\n  - For reverse engineering, the design and configurations are similar to Oh et al. 2019 and [0].\n- The experiments are not convincing.\n  - SISR architectures involved are out of date (3+ years old) and therefore not covering enough. Since the experimental setup is scalable to the number of architectures and plug-and-play with them, please include at least three most recent state-of-the-art: SwinIR [1], LIIF [2], and SPSR [3].\n  - Model attribution for the open-world fails (Section 4.1.3. when the attribution classifier is tested on unseen SISR models). This indicates the current supervised design to overfit a classifier to a limited closed-world scope (108 SISR model candidates for training) is insufficient. Please explore unsupervised learning methods (including at least metric learning [4] and contrastive learning [5]) to be generalized to unseen SISR models. This would be more adaptable when facing the fast-evolving nature of unknown generative model techniques and the cat-and-mouse game between DeepFake generation and detection.\n  - Baseline comparisons are inadequate. The proposed method is similar in concept to Yu et al. 2019. Please compare to Marra et al 2019 as compared in Yu et al. 2019, as well as to [6], a more generalizable method towards unseen generators. In addition, compare to the unsupervised classifiers as mentioned above [5,6]. They are very likely to outperform the proposed supervised classifier for unseen generator attribution.\n\n[0] Asnani, Vishal, et al. \"Reverse Engineering of Generative Models: Inferring Model Hyperparameters from Generated Images.\" arXiv preprint arXiv:2106.07873 (2021).\n\n[1] Liang, Jingyun, et al. \"SwinIR: Image restoration using swin transformer.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\n\n[2] Chen, Yinbo, Sifei Liu, and Xiaolong Wang. \"Learning continuous image representation with local implicit image function.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n\n[3] Ma, Cheng, et al. \"Structure-preserving super resolution with gradient guidance.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n\n[4] Dai, Mengyu, and Haibin Hang. \"Manifold Matching via Deep Metric Learning for Generative Modeling.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\n\n[5] Chen, Ting, et al. \"A simple framework for contrastive learning of visual representations.\" International conference on machine learning. PMLR, 2020.\n\n[6] Wang, Sheng-Yu, et al. \"CNN-generated images are surprisingly easy to spot... for now.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.",
            "summary_of_the_review": "See the main review.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper explores the model fingerprint and image attribution of single image super-resolution (SISR) networks, and creates a dataset of 124 super-resolution methods. The authors demonstrate the fingerprints of the adversarially-optimized SISR models are highly sensitive to small changes of hyper-parameters. Besides, the authors train parsing classifiers to predict the hyper-parameters, scale and loss function. Moreover, the classifier achieves good generalization outside the training set.",
            "main_review": "1. Some improvements of SR should be made in this paper. In this paper, the authors mainly explore the fingerprints of super-resolution networks. However, it is not clear how to improve the performance of super-resolution by using these findings. It would be better to give some solutions to improve the performance of SR, and it will be helpful for the SR Community.\n\n2. More related work should be explored in the paper. The architectures discussed in this paper are very old. EDSR, RDN and RCAN are proposed before 2018. In recent years, many SISR methods are proposed to improve the performance of SR, e.g., Real-ESRGAN [1] and SwinIR [2]. Could you please further explore more architectures in the experiments?\n\n    [1] Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data, ICCVW 2021\n    [2] SwinIR: Image Restoration Using Swin Transformer, ICCVW 2021\n\n3. The novelty of the proposed method should be highlighted.  Previous studies explored the fingerprints of deep-learning based image generation models. The main contribution of this paper is to extend this research to single image super-resolution (SISR) networks. Some SISR networks are included in the deep-learning based image generation models. Therefore, some conclusions are the same in many cases.\n\n4. More general SR settings should be considered. This paper only considers the SISR settings. For the more general cases, e.g., blind SR modes, they also trained with GAN loss. It would be better to explore this kind of SR model.\n",
            "summary_of_the_review": "The novelty and experiments should be improved. It would be better to use the fingerprints of super-resolution networks to improve the performance of SR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes the first super-resolution fingerprint network for identifying the super-resolution architectures which generated the high-resolution images. Compared with other image generation tasks, identifying the super-resolution networks is more challenging since the difference between the generated HR image and ground true image is very small. Experimental results show that the proposed image classifier can successfully recognize the loss function, dataset, scale,  architectures, etc, accurately to some extends. Moreover, the proposed classifier can generalize to unseen models as well. ",
            "main_review": "Strengths:\n1. First work for super-resolution fingerprints.\n2. High accuracy in some tested datasets and models.\n3. Can be the basic work for more future works to super-resolution fingerprints or image enhancement fingerprints.\n\nWeaknesses:\n1. Seems a bit trival task to infer the super-resolution parameters.\n2. Practical use of this network/method can be limited. ",
            "summary_of_the_review": "I would recommend the acceptance of this paper since this paper is well written with substantial experimental results. Moreover, the motivation and justifications are well addressed. However, the scope of this paper can be limited to super-resolution fingerprints, which is a less attention area in the literature. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No.",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies the problem of fingerprinting SISR networks. It is a derivative of existing workings on fingerprinting GANs which have been studied for image forensic applications (e.g., DeepFake). This paper has adopted  XceptionNet (pretained on ImageNet) as the backbone classification network, which is also used in previous ICCV'2019 work of FaceForensics++. Despite extensive experimental results reported in this paper, I have found this submission carries little weight in terms of theoretical contribution. The technical contribution to SISR fingerprinting has some merit, but in my biased opinion, its motivation lacks substantial justification. In summary, I have found this paper is largely implementation-based and does not seem to reach the standard of ICLR whose main focus is on theory instead of applications.",
            "main_review": "Strengths:\n+ The problem formulation of SISR fingerprinting has some novelty. \n+ The reported experimental results on model attribution (sec. 4.1) and model parsing (Sec. 4.2) are promising. \nWeaknesses:\n- My major criticism will be about lack of theoretical contribution in this paper. For example, as mentioned by the authors in related works, Asnani et al. (2021) is closely related but that paper still contains the design of a new fingerprint estimation network (FET) along with a parsing network (PN) as their theoretical contribution. By contrast, I have found little new insight brought by this submission. The adoption of  XceptionNet as the backbone is presented without much further discussion. What is the fundamental reason for this option to work - from detecting manipulated face images (as in FaceForensics++) to detecting SISR generation (this work). Does there exist a \"visible\" fingerprint that can be visualized like Asnani et al. (2021)?  If not, I believe that this title of this paper could be misleading. Model attribution/parsing might be a better fit, in my biased opinion.\n- My other complaint will be about the motivation behind this line of research. When compared with image forensic applications such as Deepfake detection, I have found the significance of SISR fingerprinting unconvincing. Authors have stated \"SR, image denoising, and video interpolation are all commercially important applications a proprietor may wish to protect.\" I beg to differ because if we stretch this line of reasoning, we should have seen some evidence for protecting existing model-based proprietized image/video interpolation techniques. GAN-based deepfake detection makes sense because it has rich connection with social media and biometrics applications - personal identity is some sensitive information requiring protection. Can authors provide a more convincing argument for protecting the existing commercially important applications related to image/video interpolation?\n- Questions about experimental results. 1) Sec. 4.1 - I am baffled by the claim \"4x upscaling adds more detail than 2x. \" As a veteran in SISR, I personally believe upscaling at a high factor does not add more detail than a small factor. Such issue/hypothesis requires more caution to be addressed - e.g., what if someone use a \"2x\" upscaling model but applies it recursively twice to get 4x? Will you obtain \"2x\" or \"4x\" fingerprint? The observation \"average classification accuracy for 4x SISR models is 5.4% higher than for 2x models\" can be explained away by noting that a larger scaling ratio generally introduces more distortion (i.e., further away from the ground-truth HR), which can be exploited by the fingerprinting classification network. 2) Sec. 4.2 - I think for this task, authors can include Asnai et al. (2021) as a benchmark in their study. The FEN+PN design in Asnai et al. (2021) is general enough to include SISR as a special scenario. Without any baseline for comparison, I have found the experimental result reported for model parsing less convincing (\"chance baseline\" is too weak in my opinion).\n",
            "summary_of_the_review": "In summary, I have found the weaknesses of this submission outweigh its strengths. This paper lacks theoretical contribution and its experimental results lack some comparison against other competing approaches. I would suggest authors give more thoughts to the motivation behind this line of research, too. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}