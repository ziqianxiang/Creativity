{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This work presents a method for learning visual representation for the recognizing unseen classes, which is called open-set representation learning. The idea is, on the labeled set of data, to learn a series of classifiers according to different partitioning. The combined classification output on any data points from these classifiers are used as the representation of the data point. The author propose to learn the representation through four loss terms, the meta-classification loss, the base classification loss, the contrastive loss, and the pairwise metric learning loss.\n\nUsing this representation, the authors experiment on several moderately sized benchmark datasets in the tasks like image retrieval and novel class discovery. A significant improvement in accuracy is reported on most benchmarks. The authors also provide analysis on several design choices in the method. ",
            "main_review": "# Strength\n----\n- The task to learn visual representation for an open-set setting, i.e., on data from unseen classes, is important for real-world use cases so that the learn representation can generalize to unseen classes. \n\n- The method extends from the product quantization and allowed supervised representation, which is novel to my knowledge. \n\n- The experimental results are better than the compared baselines.\n\n# Weakness\n----\n- The first issue is on the presentation of this paper. First, the goal of the learning task is not clearly described. Reading from the text, I am not clear whether the goal is to learn a better feature extraction \"backbone\" model or to learn the classifiers. I have to guess that the goal is to learn better feature extraction models. Then how to use the learned \"combinatorial embedding\" is opaque. It is not described how the learned embedding can be used on data from unseen classes and how does that address the challenge of open-set recognition. The latter makes me very confused about the proposed open-set representation learning task and the common unsupervised learning task, where the data also has no label or semi-supervised learning, where the unlabeled subset has unseen classes.\n\n- The authors propose to split the base class set into `M` partitions, but how to do that is not described at all. One would imagine there are many ways to perform the partition and wonder whether the partition method would affect the results. There is also no experiment evaluation of the partitioning methods. The lack of this information renders the work not reproducible by the readers. \n\n - The experiment description also lacks many details. For example, in the novel class discovery experiment, it is unclear how the discovery is performed. The methodology text only introduces how to learn the representation but not how the novel class discovery is done. Is it through clustering of the learned representation? If so what is the clustering algorithm/model used? Without the information I am not able to judge the validity of the experiments. \n\n- Since the proposed task is not clearly distinguished from tasks like unsupervised representation learning or semi-supervised learning, it would be important to include the methods for these tasks in discussion and show how the proposed method compare with those methods under the problem setting. This is not found in the experimental evaluation. ",
            "summary_of_the_review": "Overall I believe the paper proposed one interesting idea about representation learning with unlabelled data. But the presentation is lacking and it is very difficult to reproduce this work based on the presented information. The problem setting also needs to be distinguished from related problems. \n\nBased on the current information, I cannot recommend acceptance of this paper. I have listed the weaknesses in the section above. I am looking forward to the authors to address the concerns.  ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduced a method for representation learning on both labelled and unlabelled data. The unlabelled data contain both old and new classes. The model consists of a shared feature backbone and multiple linear classification heads for the heterogeneous meta-classes. The representation for each image is the concatenation of features from different branches. The model is trained jointly on the labelled and unlabelled data with ground-truth supervision for the meta-classes on the labelled data and contrastive learning on both labelled and unlabelled data. Experimental results on image retrieval and novel category discovery are shown on public datasets. ",
            "main_review": "Strengths:\n+ Experimental results are good.\n+ The writing for the main body of combinatorial embedding learning is clear and easy to follow.\n\nWeaknesses:\n- The novelty of the method is somewhat limited. In particular, the idea is combinatorial embedding learning is similar to Seo et al 2019; contrastive learning has been used for novel category discovery in [A, B]; the pairwise learning on the unlabelled data is similar to RankStats (Han et al 2020). The use of cosine similarity has also been studied in [A, B, C].  \n- For retrieval experiments, as the proposed method is essentially learning representation, other retrieval methods based on metric learning should also be compared.\n- For the novel category discovery experiments, it is unclear how the new classes are discovered. Through predicted combinatorial labels from multiple heads? or an additional clustering step by running off-the-shelf methods? This should be clearly described, while I didn't find this information in the paper.\n- It is not clear how the meta-classes are constructed. It appears to be an unrealistic assumption to require all meta-class sets to have an identical number of classes. For example, retail products in the supermarket can be grouped by meta-classes of size, flavour, etc. Each type of the meta-classes will contain a different number of classes. If the meta-classes are required to be provided in each dataset, the method will not be applicable for real scenarios.\n- It is unclear what are the feature backbones used in the experiments. Thus, it is not quite clear whether part of the improvement comes from a different backbone or not.\n- Missing comparison to recent novel category discovering methods [A, B].\n\n[A] Zhong et al, Neighborhood Contrastive Learning for Novel Class Discovery, CVPR 2021\n\n[B] Jia et al, Joint Representation Learning and Novel Category Discovery on Single- and Multi-modal Data, ICCV 2021\n\n[C] Han et al, AutoNovel: Automatically Discovering and Learning Novel Visual Categories, TPAMI 2021\n",
            "summary_of_the_review": "Overall, the paper presented an interesting method to learn representation on the dataset that contains both labelled and unlabelled images. Good experimental results are obtained on public datasets. However, given the concerns above on the novelty, unclear key experimental information, and missing comparison with recent methods, I would hold a conservative view on this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper addresses representation learning under semi-supervised settings, in which seen and novel class data are presented with some are unlabeled. A combinatorial learning approach is presented, which aims to cluster and describe the aforementioned data via multiple trained meta-classifiers. With the proposed representations, data of novel concepts can be discovered. It has been shown that the proposed algorithm can be applied to image retrieval and novel class discovery tasks.",
            "main_review": "Strengths:\n1. This paper handles a challenging and unique semi-supervised setting. That is, a subset of training data are labeled while unlabeled ones may contain both known and novel classes. \n2. The idea of utilizing combinatorial embedding from meta-classes is interesting. The idea is very similar to hashing, yet the learning scheme can be realized in the above semi-supervised setting.\n3. Quantitative results on the tasks of novel-class image retrieval and novel category discovery were quite impressive. Significant performance gaps can be observed when compared to recent approaches.\n\nWeakness:\n1. First of all, the paper is a bit hard to follow, and more real-world applications are required to support the semi-supervised setting considered. The lack of proper illustration or workflow makes the understanding of the proposed scheme quite difficult. For example, Sect. 3.4 describes transductive metric learning via pairwise similarity measurement, but the idea and the rationale behind cannot be easily captured if not going over this section several times with sufficient technical backgrounds.\n2. While I understand retrieval of novel classes is one of the tasks of interest (and very promising results reported), the authors did not report the results on seen classes. Not sure whether the proposed method is applicable for base categories.\n3. I have no particular issues on the combinatorial learning part, since using (meta) class representation or distributions to describe data is a known technique in machine learning tasks. Similar ideas of combinatorial embedding have been utilized in hashing for information retrieval. While ablation studies have been provided (e.g., number of bits, loss terms deployed, etc.), I believe the performance would be sensitive to the selection of meta-classes. I did not see any standard deviation reported during quantitative evaluation, and thus I'm not sure whether the performance improvements were statistically significant.",
            "summary_of_the_review": "Overall, I find the unique semi-supervised setting needs to be justified, and the presentation of this paper needs to be improved. While there is no concern on the technical correctness, the novelty or technical contributions need to be better justified (and how different from hashing-based methods). The experimental results seem to be very impressive, but performances on both known and novel classes should be presented.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper aims to solve the open set representation learning problem that unlabeled data may contain both labeled and unlabeled classes.\nIt utilizes multiple loss functions such as supervised cross-entropy loss, contrastive loss, and pairwise pseudo-label loss.\nThe authors evaluate the effectiveness of the proposed method on the image retrieval tasks and show performance improvements.",
            "main_review": "Pros\n- The OPEN-SET REPRESENTATION LEARNING problem is realistic and valuable to study.\n- The experimental results (\"the numbers\") look good.\n\nCons\n- The writing is poor, with unclear illustrations and confusing logic. I feel the writing has to be significantly improved to be qualified as an ICLR paper. \n- The proposed method is highly complicated involving 4 loss functions and 2 relative importance coefficients, so it's very difficult to use.\n- The experiment results are not convincing. \n  - In table 2,3,4, only 1 or 2 baseline methods are compared.\n  - There is no explanation for the abnormal results, such as \"why adding consistency loss leads to performance drop in 12 bits setting In Table 5\".",
            "summary_of_the_review": "Given the issues in both experiments, method, and writing, despite the results looking promising, I think the paper in its current form does not meet the bar for ICLR.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}