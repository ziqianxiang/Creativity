{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors propose a convolutional \"pre-cortical module\" that is being added to the front of CNNs and it is aimed to function like the mammalian early visual pathway. The authors perform experiments with the LeNet-5 architecture and its variants (RetiLeNet and Mod Lenet-5 proposed by the authors) and show that the model RetiLeNet with pre-cortical module possesses improved robustness to global lighting and contrast distortions on image classification datasets MNIST, Fashion MNIST, SVHN.",
            "main_review": "Strengths:\n+ I believe that the idea the authors pursue -- to incorporate cortically inspired early visual computations into deep CNNs -- is a promising one. The motivation to perform these computations as the authors suggest, i.e. robustness to drastic changes in low-level stimulus dimensions such as luminance and contrast are valid in my opinion.\n+ The paper provides an elaborate description of related work and existing theory on computational modeling of early visual computations performed by the retina, LGN and V1. \n+ The authors perform several experiments to test the performance of LeNet-5 and their proposed RetiLeNet at different amounts of input distortion.\n\nWeaknesses:\n- I believe there are key flaws in the novelty and the methods of this paper; while the authors give an elaborate overview of cortical computations in Sections 3 and 4, their \"pre-cortical module\" is implemented using 3 convolutional layers as shown in Figure 4 that bear little similarity to the elaborate computational models described earlier on. \n- If I understand correctly, the models being compared (LeNet-5 and RetiLeNet) have different number of layers and hence different capacities. The reason for RetiLeNet's higher performance on the distorted test set could be that it has 3 more layers of processing and more parameters than the baseline. Hence, I don't think the experiments performed represent a fair comparison.\n- There is a Mod Lenet5 (modified LeNet-5) architecture mentioned in the tables, but I do not find details on what the modification is or the corresponding architecture in the main paper or in the SI. Also, Mod Lenet-5 has been left out of the analyses shown in Figures 6 - 8.\n- I don't find sufficient evidence suggesting that the RetiLeNet model is performing border and contrast enhancement as the authors claim.\n- Relatively minor weakness: the $\\mu$ and $\\sigma$ mentioned in the results section (Sec. 5.1) are not described in sufficient detail. What do these values correspond to in the pixel intensity scale? Does $\\mu$ = 1 correspond to a 1 (out of 256) pixel intensity change? It does not seem so from the Figure 5, which makes it unclear how big the distortions are.\n\nI thank the authors for their submission. I believe that the pursued idea of incorporating early visual computations into CNNs is highly important and promising. I really appreciate the thorough and elaborate overview of early visual computations in Sections 3, 4 and in the SI. I hope the authors incorporate aspects of these computations into their pre cortical module, this would be super interesting and impactful to both the communities of machine learning and computational neuroscience.",
            "summary_of_the_review": "Overall, I do not find novelty in the proposed pre cortical module (simply a stack of 3 convolution layers) as seen in Figure 4. It is unclear whether the biologically plausible details described in Sections 3 and 4 are in any way used in the implementation of RetiLeNet.\n\nI don't find sufficient evidence suggesting that the pre cortical module is performing biologically plausible computations, I believe that the improved performance of RetiLeNet can be attributed to it's increased capacity (via # layers and parameters) over the compared baseline model. For these major concerns about novelty and poor baselines, I do not recommend accepting this paper for presentation.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this manuscript, the authors present a mathematical model of early vision (retina, LGN, and V1), which as the authors state is not novel. Then, the authors add a precortical module to a small popular convolutional neural network (CNN) architecture (LeNet 5) and make the case that it helps the model in dealing in changes in luminance and contrast in very simple datasets (MNIST, FashionMNIST, and SVHN).",
            "main_review": "The topic of robustness in computational models for visual classification is a very important one and I salute the authors for their attempt in contributing to this challenging topic. Unfortunately, the current paper fails in making any progress towards this goal. Below I detail my main concerns with this paper.\n\n\n* Results are not novel: biological normalization improves robustness of CNNs\n\nIt is a widely established fact that pre-cortical stages in the visual pathway contain multiple mechanisms to deal with the large variance in contrast and luminance levels in visual stimuli. Some of these are the existence of different photo-receptors with different sensitivities, control of pupil diameter, and neuronal circuit motifs that enable lateral inhibition. These ideas, particularly lateral inhibition, have been widely incorporated in CNN architectures demonstrating improvements in dealing with luminance and contrast changes. For example,  Rad et al. 2020 compared different normalization methods, including the popular difference of Gaussians (DoG) in dealing with illumination changes (luminance, contrast, and color) for colored, high-resolution images. Evans et al. 2021 showed that a DoG pre-processing stage improved model robustness to changes in contrast and luminance in CIFAR-10 images. Both of these studies, and several others, show that normalization schemes inspired in biological early vision improve the robustness of ANNs in datasets that are considerably more complex and challenging that the ones used in this current paper. \n\n\n* Results are not novel: emergence of low-level visual features in early stages of CNNs\n\nThe studies that I cited before make the direct link between the usefulness of biological normalization schemes in dealing with variations in contrast and luminance. However, in this paper, the authors add trainable convolutional layers to a model and claim that they learn to stabilize activations over changes in luminance and contrast. This again, is also not novel. For example, Lindsey et al. 2019 shows that a CNN trained for object recognition in the CIFAR-10 dataset learns both retina-like receptive fields (RFs) with center-surround structure and V1-like Gabor RFs after introducing a bottleneck (small number of channels) in the early processing stages. Similarly, Morgenstern et al. 2014 showed that artificial networks also learn center-surround RFs that help them stabilize activations to changes in contrast. Ocko et al. 2018, show that multiple retinal cell types emerge in the first stage of an autoencoder trained on naturalistic movies.\n\n\n* Paper poorly written/structured\n\nI also found the paper very confusing to read. The authors dedicate more than three pages (and more on the supplementary materials) explaining the early stages of the visual pathway and a corresponding mathematical model that has no connection with the model that they implement. Particularly, there is a section explaining the different response types in V1, which have nothing to do with luminance or contrast responses and are not further explored in the experiments. Even the choice of the mathematical model used is very arbitrary with no reference to the DoG model, arguably the most popular and successful model in explaining retina and LGN responses (Enroth-Cugell and Robson 1966, Bonin et al. 2005 for example).\n\n\n* Methodological problems\n\nThe authors compare the performance of two models when dealing with changes in contrast and luminance. However, the models in question are not comparable since the model that the authors propose is an enhanced version of the base model with 3 additional processing stages and a higher number of trainable parameters. Furthermore, the authors optimize some of the model hyperparameters (such as the kernel size), which may give rise to overfitting. For a proper comparison, the authors need to add different model variants, controlling for number of parameters and rule-out overfitting from their reported improvements. \n\n\n* Study not properly contextualized\n\nThe paper is also missing multiple important references. In the topic of adding biologically-inspired pre-processing stages, for example. Dapello et al. (2020) showed that adding a model of V1 at the front of CNNs substantially improved their robustness in a wide range of perturbations in ImageNet (a dataset that is orders of magnitude more complex than the ones used in this study). The already mentioned Evans et al. 2021 and from the same authors Malhotra et al. 2020 showed the usefulness of biological constraints in improving CNNs robustness. Lindsey et al. 2019 and Ocko et al. 2018 showed the emergence of retina-like center-surround RFs in CNNs. Critically missing are also the first studies that performed extensive comparisons between CNNs trained in visual classification and responses in the primate visual pathway (for example, Yamins et al. 2014, Khaligh-Razavi 2014, and Guclu et al. 2015) and more recently with an emphasis on V1 neural activity (Cadena et al. 2019, and Marques et al. 2021).\n\n\n",
            "summary_of_the_review": "I cannot recommend this paper to be accepted. The results are not novel and trivial (contribution of pre-cortical processing, particularly lateral inhibition, for model robustness). Furthermore, the paper is very confusing with a detailed description of a mathematical model that has no relation to the model that is actually implemented and tested. Finally, there are critical flaws with the methodology and important literature is largely ignored.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper proposes an add-on module for Convolutional Networks that implements pre-cortical processing inspired by the LGN and area V1 cirtuits in the visual sytem of the brain. Experiments are perfomed using LeNet, and small-size data sets, using custom corruptions on the test data.\n",
            "main_review": "Although the idea is nice (not new), the paper has considerable flaws and is very far from being in a form that can be considered for publication at ICLR. I elaborate in the following.\n\nThe formulation of the method is presented unnecessarily overcomplicated, resulting in a not clear path to implementation and replication of results. The idea is simple (which is appreciable) and could be presented in a simpler and more immediate way, to facilitate understanding and re-implementation. \n\nThe major concerns are, however, in 1) the positioning of the work within the state of the art and in 2) the experimental analysis.\n\n1) apart from few older papers in the field of brain-inspired computer vision, the authors do not discuss recent works that model pre-cortical components of the visual pathway within CNNs. Examples are:\n- G. Zoumpourlis, A. Doumanoglou, N. Vretos and P. Daras, \"Non-linear Convolution Filters for CNN-Based Learning,\" 2017 IEEE International Conference on Computer Vision (ICCV), 2017, pp. 4771-4779, doi: 10.1109/ICCV.2017.510.\n- Strisciuglio, N., Lopez-Antequera, M. & Petkov, N. Enhanced robustness of convolutional networks with a push–pull inhibition layer. Neural Comput & Applic 32, 17957–17971 (2020). https://doi.org/10.1007/s00521-020-04751-8\n- Zahra Babaiee, Ramin Hasani, Mathias Lechner, Daniela Rus, Radu Grosu, On-Off Center-Surround Receptive Fields for Accurate and Robust Image Classification\n\nMotivations for this work and differences from other existing works are not evident. Clarifications about novelty are necessary.\n\n2) The experimental analysis is poor and limited to using LeNet and few small-size data sets, with custom corruptions. No comparison with other methods is performed. LeNet is not a SOTA architecture, and is normally used for toy examples nowadays. \nThe performed comparison of LeNet with and without the pre-cortical model is even unfair, as the extended version with the pre-cortical layers is deeper and has more parameters. \nThe authors should consider, for the future, to deploy their model within SOTA networks and test on larger benchmarks, such as ImageNet. They should also consider analysis on benchmark data sets of corruptions (or subsets of them), such as ImageNet-C, ImageNet-\\bar{C} and similar, and compare with other methods (both brain-inspired and not) that aim at improve some aspects of the robustness of existing CNNs.\n\n",
            "summary_of_the_review": "The presentation of the method is unnecessarly overcomplicated and not providing a clear path to implementation. Experimental analysis is poor, using only LeNet and small-scale data sets, without providing a comparison with other existing methods.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The authors propose to augment a standard small-scale CNN (LeNet-5) with a \"precortical module\" to improve robustness against shifts in brightness and contrast not encountered during training. They evaluate their approach on MNIST, Fashion MNIST and SVHN, and show that their modified RetiLeNet yields higher performance under shifts in brightness and contrast than standard LeNet.\n",
            "main_review": "## Strengths\n+ Potentially interesting and important finding (if it proves to be robust and holds beyond the narrow scope tested)\n\n## Weaknesses\n- The mechanism why this effect should occur remains unclear\n- No qualitative investigation how the \"precortical module\" achieves robustness\n- Not clear whether the robustness generalizes beyond toy datasets\n- Not clear whether it generalizes beyond brightness and contrast\n- Lots of mathy discussion with unclear relation to what's being done empirically\n\n## Detailed comments on weaknesses\n\n\n### Mechanisms\n\nAlthough the paper reports an interesting empirical finding, it remains unclear to me *why* this result should happen in the first place. All the authors do is adding three convolutional layers (albeit with non-standard sigmoid activation functions) in front of a standard small-scace CNN (LeNet-5). Why turning a five-layer CNN into an eight-layer CNN should increase robustness and invariance to brightness and contrast changes is not obvious to me and no motivation is given in the paper.\n\n\n### Qualitative investigation\n\nRelated to the previous point, I would have expected to see some qualitative results. If the authors intuition about the properties of biological vision are correct, then we would expect center-surround organization of the filters in the first layer./ However, when training CNNs on image data, one usually observes oriented filters in the early layers (see, e.g., AlexNet or ResNet) rather than center-surround organization.\n\n\n### Generalization beyond toy datasets\n\nTraining CNNs like ResNet on ImageNet is really not a challenge anymore these days. I would at least expect a demonstration of the reported effect on a larger-scale experiment. For instance, a comparison to ResNet-18 or ResNet-50 on ImageNet, following published training pipelines would allow comparing to state of the art and would provide some evidence that the effects are not simply due to some hyperparameter settings or other issues.\n\n\n## Generalization beyond brightness and contrast\n\nBeing invariant to brightness and contrast is trivial by adding an instance norm layer before the first conv layer and doesn't require any sophisticated processing. Thus, I would have hoped to see a demonstration of robustness beyond such \"trivial\" manipulations. The common corruptions in ImageNet-C would be an example that is being widely used by the community to test robustness of deep nets.\n\n\n### Mathiness\n\nThe paper contains a lot of maths -- essentially the first five pages -- whose significance remains unclear. At the end of the day, it is an empirical investigation motivated (very weakly) by biological vision. I am unsure what the math adds to this paper.\n",
            "summary_of_the_review": "The paper hints at a potentially interesting finding. However, it remains unclear why the \"precortical module\", that consists only of conv layers itself, should yield such robustness in the first place. Moreover, the authors do not sufficiently explore the observed effect. They neither demonstrate its applicability on larger-scale models and datasets (e.g. ResNet on ImageNet) nor on more realistic image perturbations (e.g. ImageNet-C). Overall, it is much too thin to meet the bar for ICLR.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}