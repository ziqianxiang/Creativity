{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studied the phenomenon that the larger model causes lower classification accuracy under DP. Based on a simple model for analysis, the author showed that when noise or dimension tends to infinity, the classifier using all features performs nearly the same as random guessing. Based on a robust distance criterion, the authors select the important features with probability one. Finally, the DFS algorithm was proposed to trade off the classification accuracy and privacy-preserving.",
            "main_review": "Hello authors,\n\nThank you for the submission. I enjoyed reading it and I think the paper is an interesting analysis that warrants publication. I have some small comments that I hope are helpful:\n\nStrong points:\n\n1. The paper is generally well organized. It is easy to understand the purpose and contribution of this paper.\n2. The literature review is clear. The relation to prior work is explained in detail.\n3. The author provides a clear illustration of ideas through a series of examples and experiments\n4. The definition of terminologies is clear.\n\nWeek points:\n\n1. The model setup in this paper is not general enough. It is based on the Gaussian Mixture model (GMM) for the DP mechanism. This may limit the generality of the results.\n2. Some results and formula need more comments and examples, such as (12) (13) (14).\n\nSome suggestions:\n1. In addition to the GMM model, extend to a more general model setup or add another model to analyze the impact of DP.\n2. Add some detailed introductions to the real dataset in the experiement\n\n",
            "summary_of_the_review": "Recommend to accept.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This article tries to explain why the larger the model, the worse the performance will be when differential privacy is utilized. On synthesized GMM data, the authors prove that the feature dimension plays an important role and the higher the feature dimension, the worse the performance will be. With the above intuition, the authors propose a feature selection method to improve the utility of the DP algorithm.\n",
            "main_review": "Strengths: \n\n1. It is a very important and meaningful question to study why the larger the model, the worse the performance will be when DP-SGD is applied to train a model. This paper, to the best of my knowledge, first formulates this problem and provides useful insights. \n2. The paper is well written, the authors do a good job presenting their motivations and intuitions. \n\nWeakness:\n1. The analysis is based on toy GMM data and fisher classifier, which may not be satisfied in real-world applications. \n2. The analysis assumes a binary classification task, it is not clear whether multi-way classification is a direct extension. \n3. For the Gaussian mechanism, I think the sensitivity should be defined by L2 norm rather than L1 norm in Section 2. \n\t\nMinors: \n1. It seems that both the private GMM analysis and experiments are conducted with noisy data rather than using DP-SGD in this paper. I recommend rephrasing the abstract and introduction.  “large model … trained by DP- SGD cannot perform better than the small model… , to better understand this phenomenon…”. This makes me at first glance feel this paper tries to improve DP-SGD. \n2. There are some typos, a Ref. error at the end of paragraph 4 of the introduction.\n\nGenerally I like this paper, and I am willing to discuss in the rebuttal session and raise my score after the above problems are addressed. \n",
            "summary_of_the_review": "None",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper observes that applying differential privacy onto large models degrades accuracy more than it does to small models. \nIt then analyzes this issue in the setting of Gaussian mixture models.\nThe work suggests that the accuracy of a Gaussian mixture model degrades with the increase of the underlying number of features. \nThe paper proposes to suggest a simple dimensionality reduction to enhance accuracy. \n",
            "main_review": "The paper poses a very interesting question. \nOne of my main criticism is that this work, perhaps unintentionally, oversells its contributions in the title, abstract, and introduction. \nIndeed, the setting studied is limited to a very specific context, Gaussian mixture model, and also follows very specific assumptions (i.e., the definition of classification error adopted). \n\nI suggest toning down the paper contribution in the title and abstract. \n\nIt is not clear how the feature selection is performed in the last experiment (Section 4.3). The authors say that they use the last layer of ResNet to represent input data in their algorithm. \nWhich input do you take? That of a non-privately trained ResNet or that of one trained with DP-SGD? \nIf it is the former, can you elaborate on how can you guarantee privacy with the respect to the inputs? \n\nIn terms of clarity, the paper is well presented, but it is often hard to read and its writing requires significant improvements. Some references are missing, and some sentences seem incomplete or miss structure. \n\nI also found that some introduced concepts are largely unjustified. For example, why focus on Fisher classifier and then define a \nclassification error on such classifiers? How does this relate with the general context motivating the paper? I'd be glad if the authors could clarify.\n\nI also believe that the assumption that the data is generated by a GMM process needs justification. \n\n",
            "summary_of_the_review": "The paper studies an interesting problem. The paper conclusions seem to go beyond what the analysis reports and its contribution is limited to the study of one specific setting. The clarity of the paper needs to be improved. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper gives generalisation bounds in simple GMM model under the constraint of differential privacy. It essentially attempts to show that larger model has worse generalisation guarantees under differential privacy. It also proposes a new feature selection filter to reduce dimensionality of the problem. Finally, it shows experiments on both synthetic and real data.",
            "main_review": "Strengths:\n\n--The experimental data shows that their algorithms work, especially in the case of their feature selection filter.\n\n--They have mathematical basis to support their work.\n\nWeaknesses:\n\n--The work doesn't seem that deep technically. The ideas were nice, but more could have been done show bounds on more complex models.\n\n--As far as I know, GMM's don't reveal labels on samples, that is, whether they're from class 1 or class 2. So, how do you make your filters work?\n\n--As far as the privacy is concerned, you seem to add noise that is scaled according to the largest norm of a data point. That's just wrong in the sense that if a point is private, then you cannot add data dependent noise. Am I missing something?",
            "summary_of_the_review": "Based on my feedback above, I feel that few things are possibly wrong or unrealistic in this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}