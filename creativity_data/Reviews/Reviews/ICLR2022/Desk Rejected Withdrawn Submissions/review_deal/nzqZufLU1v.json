{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper introduces a method to encode and compress point clouds. The paper proposes to use range image and then a neural network to compress the range image, which later can be used to recover the original point cloud. The neural network predicts the difference of next image pixel value in the range image. ",
            "main_review": "The paper is well motivated and organized. \n\nHowever, the novelty is limited. The use of range image to represent point cloud is already used everywhere. It is a one-to-one mapping, which nearly all the 3D vision and sensing professional knows and uses. \n\nThe use of neural network to compress images is also widely explored, as well as predicting the residuals in neighboring pixels. Applying the neural network to encode and compress another type of image should not be considered to be a novelty. \n\nThe experiments are not sufficient. The compared methods are published at the same level journal/conference or even not on official conference or journals. The authors should really compare with image compression methods that are published at the recent most top conferences. There are also so many compression methods that directly compress the 3D models (e.g., using math to represent the shape of local 3D shapes) that the paper should compare with.\n\nThe method is only applied to compress a single frame LiDAR sensing. However, a point cloud usually composes many frames registered. The authors did not demonstrate the proposed method can be applied to large scale 3D point clouds.\n\nThe writing is not carefully examined. E.g., LiDAR, Lidar, lidar different kinds of writing formats are used everywhere. \" a simple diff between\". Diff cannot be used as official document.      ",
            "summary_of_the_review": "From novelty, experiments, writing, the paper is not at the level of publication as detailed in the main review. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a deep neural net based compression method for Lidar range images. Instead of treating the Lidar data as 3d point clouds, they propose a prediction pattern that follows the Lidar scanning pattern, such that each pixel prediction depends on previous pixels predictions in the scanning path. The residual between the GT and predictive values are then further compressed with entropy encoder. Similar to CNN, this means the model can predict one pixel at a time. In order to speed up, an Lidar image is divided into numerous small patches for parallelism. Experiments show that the proposed method yields much better rate-distortion comparing to industrial standards such as G-PCC and Draco, as well as other SOTA research methods.",
            "main_review": "The general idea seems intuitive. Experiment results are encouraging. However writing seems rushed and causes a lot of confusion. \n\nIn section 3.1,  delta is defined as the difference between adjacent pixels, while residual means the difference between predicted and groundtruth values of the current pixel. Since entropy encoding is lossless, the residual map is compressed losslessly. Regardless the prediction model you use, any prediction error can be compensated by the residual map. This suggests the only source of distortion is from the quantization step? If so, how did you generate the rate-distortion curves in Fig 3 and 4? By varying the level of quantization?\n\nHowever, later in Sec 3.2, it says the residual (g_i) is also *predicted * by a model. So which one is it, calculated or predicted?\n\nIn fact the whole Sec 3.2, especially the *anchor classification and residual regression* part is rather confusing. There is no reference so I assume the idea and terminology are inspired by detection methods such as R-CNN. That said, it is still hard to connect the two and understand the analogy here. How do you define an anchor? What's the score s_i? \n",
            "summary_of_the_review": "It is a borderline to me, unless the rebuttal demystifies the confusing parts so I can properly evaluate the level of novelty.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "It proposes a CNN-based compression algorithm for a LiDAR range image. It claims to use a deep delta encoding, but its effectiveness is questionable. The performance comparison with existing methods seems not fair, as will be discussed below.",
            "main_review": "Weakness,\n1. In the second contribution on page 2, the authors claim to design an effective intra-frame predictive deep neural network. However, they use the conventional point-cloud network, PointNet. Thus, the second contribution should be reconsidered.\n2. There are various methods for range image compression as well as LiDAR data compression. Thus, authors should describe more related methods, including [R1-R4], in the related work section. \\\nIn addition, to emphasize the contribution of this paper by comparing it with the other methods, it would be better for the related work section to come after the introduction section.\n3. Comparison with the conventional range image compression algorithms is missing. If the comparison is not available, the authors had better mention the reason.\n4. On WOD, the results seem to be calculated on the range image, looking at the sentence \"For all comparisons, we measure the compression of the range channel.\" However, all metrics are defined as a point cloud, as shown in Eqs. (2), (3), and (4). \\\nIn addition, How did you measure the results of G-PCC and Draco, which are point cloud compression algorithms on WOD?\n5. Since three metrics and two datasets are used in the experiment, a total of six evaluations can be performed. However, only three evaluations are described in Figure 3. Why are the others omitted?\n6. As shown in the footnote on page 7, the results are from MUSCLE (Biswas et al. (2020)) by referring to their curves. While in MUSCLE, they used the metric as the symmetric Chamfer distance, authors used the metric as the max Chamfer distance in Figure 3 (right). Why is the metric different?\\\nIn addition, the authors use the ground truth point cloud as \"the point cloud unprojected from the uncompressed range image,\" which is not the same as the ground truth point cloud used in OctSqueeze and MUSCLE. It seems not fair. \n7. In analysis experiments, authors use the prediction accuracy metric. Is there a reason why you didn't use MSE or MAE? Why did you define a new metric instead of using the standard metric?\n\n----\nSuggestion,\n1. As in [R5], it is difficult to generalize range image compression algorithms since the range image only represents the environment of the actual viewpoint. Does deep delta encoding suffer from this issue? I would like to see the comparisons on the other datasets not used in training, such as the UrbanCity dataset.\n\n----\nTypos,\n* The more accurate the prediction model $\\textbf{is}$, the smaller the entropy of the residuals.\n* on downstream perception application$\\textbf{s}$.\n* Unify either raster scanning order or raster-scanning order.\n* We can use $\\textbf{a}$ local image patch of shape ...\n* A notation error -> $r_t$ is the difference between the ground truth pixel value and its corresponding prediction given by $r_t = x^{'}_t-\\hat{x}_t$; but $r_t$ are multiples.\n* Is correct the residual map of size $H\\times W$? If correct, how do you get the first pixel $r_{1,1}$ and why?\n* At inference time <-> At the decompression time. Please use determiner consistently.\n* Both the compression and decompression process$\\textbf{es}$ can be parallelized ...\n* (the input is $\\textbf{the}$ flattened range image patch)\n* Let $s_i$ be the predicted score$\\bcancel{s}$ ... and $g_i$ as the residual$\\bcancel{s}$. The scalar value $s_i$ and $g_i$ is not plural.\n* with the highest compression rate$\\bcancel{s}$.\n* between $\\bcancel{the}$ one.\n* on page 8, by using the point-cloud-based deep $\\cancelto{network}{net}$ adapted from PointNet.\n* Biswas et al. (2020) were published in $\\textbf{NIPS 2020}$.\n\nAbuse abbreviations,\n* diff\n* nets\n* esp.\n\n---\nReferences\n\n[R1] Ahn et al., \"Large-scale 3D point cloud compression using adaptive radial distance prediction in hybrid coordinate domains,\" in 2014.\n\n[R2] Nenci et al., \"Effective compression of range data streams for remote robot operations using H. 264,\" in 2014.\n\n[R3] Sun et al., \"A novel point cloud compression algorithm based on clustering,\" in 2019.\n\n[R4] Tu et al., \"Point cloud compression for 3D LiDAR sensor using recurrent neural network with residual blocks,\" in 2019.\n\n[R5] Wiesmann et al., \"Deep compression for dense point cloud maps,\" in 2021.",
            "summary_of_the_review": "The performance comparison with existing methods seems not fair, and also, the information of related works is poor. It's minor, but there are many typos, so It is not readable easily. Thus, it should not be published without significant modifications and revisions. It seems that the paper is not mature enough. The authors are encouraged to polish the paper and submit it to another venue.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}