{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a metric named IsoScore to measure the uniformity of the vectors (e.g., word emebddings). Given a set of points, $X$, in an embedding space and the proposed method can output a scalar in [0,1] for representing how isotropic $X$ is. The authors argue that previous metrics (e.g., average cosine similarity, partition scores) have not covered all desirable properties for measuring spatial utilization, and IsoScore is the first metric that covers all.  The authors verify the effectiveness with several tests and also study the contextualized embeddings in pre-trained LMs like BERT and present a few findings. ",
            "main_review": "Strengths:\nIsoScore is a new and comprehensive metric dedicated to measuring the uniformity of vectors in high-dimensional space. \n\nWeakness:\nThe empirical analysis of the benefits brought by IsoScore is quite limited. The experiments of using different metrics to measure contextualized word embeddings do not necessarily lead to the conclusion that IsoScore is better than others, although it leads to a few new findings. And there is no time/space-complexity analysis for comparing IsoScore and other metrics.",
            "summary_of_the_review": "The IsoScore is a nice metric while the paper doesn't show many benefits of using IsoScore over other alternatives in downstream applications. And the time/space-complexity is also not studied. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The importance of isotropy in word embedding spaces has been recognized recently in the ML/NLP community. The authors enumerated the requirements that an isotropy measure should satisfy and proposed a new measure, IsoScore, that satisfies all axioms. They also pointed out, theoretically or experimentally, that each of the existing isotropy measures does not satisfy some requirements.",
            "main_review": "**Strengths**\n\n- Some isotropy measures have been conventionally used in the community without being validated. The criticism in this paper is an important step for the sound development of the ML/NLP community in the future.\n- The authors proposed a specific method for sanity checking for each axiom to use the framework for subsequent studies efficiently. The original sanity check method, such as the “skewered meatball” test, is also an attractive feature of this paper.\n\n**Weaknesses**\n\n- Shift invariance invalidates the L2 norm and inner product, which we must say is an unnatural guideline for evaluating word embeddings. The L2 norm of a word vector is known to implicitly encode the importance of a word [1], and thus the norm acts as a weighting factor when the word vectors are added together to form a sentence vector [2]. The pioneering work on isotropy cited by the authors [3] also uses this method to generate sentence vectors. In other words, the word vector norm is often used for linguistic information in practical applications. Moreover, in general, isotropy is defined based on the inner product [4]. In summary, it would be pretty challenging to justify shift invariance, which makes the norm and inner product uninformative. I believe this research is attractive enough even though the authors remove the axiom of shift invariance. \n- Similarly, the fact that the sanity checking for scale invariance ignores the origin of the space and scales from the center of the distribution is also uncomfortable. The assertion in Table 1 that cosine does not have scaling invariance is very misleading, at least in light of mathematical terminology and conventional formulation. This problem can also be easily solved by removing the parallelism invariance from the axioms.\n- Section 6.2 compares the isotropy scores of the proposed and existing methods. However, these metrics are quite different in nature, as the authors showed in the previous sections. What the authors show throughout the paper is that the results measured by the existing scales, whether \"large\" or \"small,\" are uninformative, as they may be (mistakenly) dragged by some noise. It seems difficult to justify the approach of comparing the large and small relations. As an alternative, if the word vectors are used to create sentence vectors for the downstream tasks, as in [5], and if the IsoScore scores are correlated with the performance, the value of the proposed method will be significantly boosted. \n\n---\n\n- [1] Schakel and Wilson, Measuring Word Significance using Distributed Representations of Words (arXiv 2015)\n- [2] Yokoi et al, Word Rotator's Distance (EMNLP 2020)\n- [3] Mu and Viswanath, All-but-the-Top: Simple and Effective Postprocessing for Word Representations (ICLR2018)\n- [4] Vershynin, High-Dimensional Probability (Cambridge University Press 2018)\n- [5] Li et al, On the Sentence Embeddings from Pre-trained Language Models (EMNLP 2020)\n",
            "summary_of_the_review": "I believe that the research direction itself, a criticism of existing isotropy metrics, is of great value. Several shortcomings cannot be overlooked, but I believe that the authors can correct them.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes IsoScore, a metric to measure the isotropy of a point cloud. The target application is contextual word embeddings in the deep language models. The paper summarize existing metric, and proposes 6 axioms and argues that, the isotropy measure should satisfy these 6 axioms. The experiments on both synthesized point cloud, as well as contextual embeddings of BERT, validate the proposed IsoScore satisfy the 6 axioms.",
            "main_review": "The strength:\n1. Many papers discussed isotropy in contextual embedding space, e.g. Ethayarajh 2019, however, a proper definition of isotropy is indeed not well-studied in literatures. This paper address this problem and validated the proposed score by checking if it satisfy a few axioms. The way to construct such metric and validate, is interesting. So I enjoy reading the paper.\n2. A comparison with existing scores, is provided in Table 1, from different aspects. \n\nThe weakness:\n1. I didn't see a significant difference between the proposed IsoScore, and the commonly used Explained Variance after PCA. The proposed method is a combination of linear transformations, according to Algorithm 1. It seems an enhanced version on top of PCA. Unless I misunderstand some part, the major drawback would be that, it cannot handle embedded low-dimensional manifold. For example, if the point cloud is like a rolled paper sheet in a 3-D space, then variance on each dimension is significant, but I am not sure the fact that the points lying on the low dimensional manifold can be still viewed as isotropic. So I feel manifold intrinsic dimension and IsoScore would be a good complement of each other.\n2. The 6 axioms are not defined in a rigorous mathematic way. Some claims are not very convincing. Some are even not very clearly expressed. For example, Maximum Variance, should rather be \"restricted condition number\". \n3. It is not a proper way to show that IsoScore is superior, according to the axioms, when the \"axioms\" are also proposed by the authors. Unless the authors can show that, the proposed axioms, also apply to other well-known and widely-accepted metrics. Otherwise, you cannot propose an un-verified standard, then use the standard to verify another proposed method. When talking about metrics, some axioms like symmetry, non-negative, tri-angle inequality, applied to a majority of modern metrics, e.g. l2, l1, distance. \n\nI would like to see clarifications on above issues.",
            "summary_of_the_review": "The paper propose a new score to measure isotropy, which is something new and necessary. However, the axioms are not very convincing and anything on top of those are questionable. Other than that, I cannot tell if the IsoScore is very different from explained variance of PCA.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No concerns.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper defines 6 axioms that an isotropic metric should satisfy. Then, it empirically shows that none of the existing isotropic metrics designed for analyzing language models (LMs) satisfies all the axioms. The paper proposes a new isotropic metric called IsoScore and shows that it satisfies all the axioms. Based on this, this paper claims that IsoScore is a better isotropic metric for analyzing LMs.",
            "main_review": "This paper is motivated in the language model (LM) context. The proposed metric, IsoScore, is compared with the other isotropic metrics designed for LM. However, this paper fails to show whether the IsoScore is actually useful for LM. That is, does a higher IsoScore imply a better LM? \n\nIn fact, IsoScore might be useful for some other applications, but I do not think higher IsoScores positively correlate with a better LM performance. I won't be surprised if they are actually negatively correlated. This is because the magnitude of the final hidden state layer actually means the predicted inverse temperature in the softmax (i.e., the confidence of the next/masked word). Higher IsoScores means that the magnitude should be the same in all the directions (i.e., all the word predictions should have the same confidence), which are obviously not optimal.\n\nLet me use a simple example to explain my doubt more clearly. Let's look at Figure 2. Assume that the hidden state size of a LM is 2 and each point in the figure is the final layer of hidden state (contextualized embedding). Is the distribution in the leftmost subfigure (circle shape) better than the distribution in the rightmost subfigure (oval shape)? Not necessarily. Recall that the probability of the word w_i in GPT2 is computed by exp(hTw_i) / sum_i( exp(hTw_i) ). Let's say you have 4 words *a*, *b*, *c*, *d* on (1,0), (0,1), (-1,0), (0,-1), respectively. In some contexts, we are very certain that we should output *a* and in some contexts, we should only output *c*, so we should have high magnitudes on x axis. However, we never encounter the contexts that we should output *b* or *d* with high confidence, so we should have low magnitudes on y axis. Then, the rightmost subfigure is obviously better than the leftmost one.\n\nFrom this perspective, I believe that not considering the magnitude in the isotropy metric (as in AvgCosSim) makes more sense. If the main problem of AvgCosSim is not considering the average, why not simply minus the average embedding of all the points first and measure AvgCosSim next?\n\nEveryone can propose a metric. The difficult part is to show that your proposed metric is useful. For example, optimizing those metrics could improve the LM performance. Some axioms you defined are not enough to justify the usefulness of your metric. Furthermore, some axioms seem to be even defined for your metric. For example, IsoScore is computed using the covariance matrix and your first 3 axioms are also based on the covariance matrix, which further weakens your argument. \n\n\nMinor suggestions:\n1. In axiom 1, clarify what mean you refer to in \"changes in the mean\"? Average of all the hidden state embedding?\n2. In axiom 2, explain what scalar multiplications mean? Why isotropy metric should be invariant to this multiplication?  \n\n",
            "summary_of_the_review": "I vote for rejection because the paper proposes a metric, IsoScore, for analyzing LM's behavior but it does not provide enough evidence to justify the usefulness of the proposed metric. I even hypothesize that a higher IsoScore could lead to a worse LM performance and provide a concrete example to explain why.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}