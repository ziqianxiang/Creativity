{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "Disclaimer: this is an emergency review, and the reviewer may have missed some key aspects of the work due to the limited time\n\nThis work proposes a framework for the data-driven estimation of PDE dynamics. The framework is based on a reasonable idea: identifying a suitable low-dimensional representation in which the dynamics can be efffectively learned, and subsequently decode this information to retrieve the full scale solution. The overall framework is based on an autoencoder, in which the prescribed dynamics are imposed in the latent space through a differentiable solver. \nThe experiments are carried out on two simulated cases based on Advection Diffusion and Buoyancy driven dynamics. The results show that the proposed framework provides good reconstruction results when integrating with a finer steps in the forward pass, especially compared to the proposed variants. ",
            "main_review": "The framework is reasonable and well formulated. The proposed variants also offer a different range of modeling scenarios allowing to appreciate the contribution of each single components of the proposed network. Moreover, the experimental results are encouraging, generally showing a good performances with respect to the benchmark and baseline solvers. \n\n- Overall, I feel that the motivation for the proposed system is not completely clear. For example, what is the real benefit gained in knowing the latent dynamics? Is the interest mainly in the scalability of the integration? In this case, the improvement in computation time is not impressive as compared to the baseline integration, and it would be beneficial to better demonstrate the scalability of the proposed framework, for example with varying input dimensions and integrations steps. \n\n- Moreover, the integration of dynamical systems in the latent space is not a completely new idea in the machine learning literature, at least for what concerns the integration of ODEs (e.g. neuralODE and subsequent works). This kind of approaches should be acknowledged by the authors. \n\n- There are also a number of choices which sould deserve further clarification, such as the choice of the latent dimension for the latent space. This parametes seems critical, but is overlooked in the experimental part. \n\n- The manuscript is not really clear on the kind of integrator used: I assume that the specified system is the same of the one used to generate the solution, but this information is never explicitly stated in the manuscript. This application assumes the prior knowledge of the system, which is often not readily available. \n\n- Related to the previous question, would the framework perform equally well with any arbitrary system applied in the latent space? This verification seems beneficial to rule out the possibility of overfit. \n\n- I could not find the information about the number of steps used to integrate the baseline solution. This is another information quite crucial to appreciate the value of the experimental results.\n\n- Related to this last question, there seems to be no testing of the model in the extrapolation beyond the observed time range. Again, this kind of test would be relevant to appreciate the stability and generalization of the sytem.",
            "summary_of_the_review": "Overall the work seems reasonable and provides encouraging results. \nI would have appreciated a more thorough experimental assessment, as to my opinion there are several important implementation and testing details which are not clear in the current manuscript.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a method for coupling ML and PDE solvers in order to approximately solve the PDE with less computational cost than a full simulation. An autoencoder is coupled with a differentiable solver that operates in the latent space. The neural network training involves backpropagating through the solver so that the latent space is \"shaped\" to result in accurate solutions after being mapped back to the full space via the decoder. ",
            "main_review": "*Strengths:*\n* I think that this is a pretty novel approach to using ML to approximately solve PDEs. \n* I think that having an autoencoder coupled with a PDE solver that operates in the latent space is one of those great ideas that makes you surprised that no one else has done it before. \n\n*Weaknesses:*\n\nClarity of writing:\n\n1. Looking at Figure 2, the previous time step has an arrow into the decoder along with the predicted time step. For example, r^hat_t and r^hat_{t+1} have arrows into D to produce f^hat_t{t+1}. Does the decoder directly take both as inputs or just r^hat_{t+1}? If so, this doesn't seem to be referenced in the text and seems strange. If no, then I think the figure is confusing. \n2. Based on the body of the paper (\"we condition the encoder on g, which is provided as an additional input to this model\"), I thought that g was an input to the encoder for the Burgers equation example. However, the Appendix says \"the solver takes analytically downsampled force fields as external forcing in the reduced space\" so it sounds like g is not an input to the encoder? Or is g used both ways?\n\nExperimental set up:\n\n3. There are quite a few claims that the autonomy of the latent space is what leads to ATO having better results than the other methods and that it's interesting that the latent space looks much different than a traditional down-sampling. To see if this is true, I'd like to see an ablation study. I don't think the current comparisons isolate that the autonomy of the latent space is definitely why ATO has better performance. Here is why:\n    - ATO uses a U-Net architecture \"such that the information of the intermediate features from the encoder can be propagated through the decoder.\" These skip connections make it harder to interpret the latent space. For example, maybe applying the reduced solver to the unusual latent space results in some strange behavior and that information from intermediate features in the encoder help the decoder correct it, sort of like a discrepancy model. I would find the interpretation of the results more clear if there were no skip connections between the encoder and decoder.\n    - For ATO applied to Burgers equation, the encoder is conditioned on the external forces g (as mentioned above, I'm not sure how this is handled). For ATO applied to Navier-Stokes, the encoder transforms both velocity and marker fields (d), and both are used for the reduced solver. Then the decoder does not reconstruct the marker fields. Instead, it's passively advected using the restored velocity field. How do CEN & NON handle g and d? Is that a way that ATO has an advantage over the other methods?\n    - I think it's not mentioned what the decoder's architecture is for CEN & NON. However, we know that it can't be exactly the same as ATO because ATO has skip connections from the encoder. \n\n    For a good ablation study, it would be helpful to see versions of the methods that address the above three concerns. \n4. I didn't see any validation data mentioned. Was the test data used for any tuning of hyperparameters, picking the architecture, early stopping, etc., or was it completely held out until the end of the project? If it was used to make any decisions, then it's not a valid test set. Then a new test set should be generated and the paper updated with those results. \n\nWeakness of baselines:\n\n5. CLS (adding a constraint to their method) is an interesting comparison. However, the other methods that the authors compare against don't come with any particular papers cited. It is claimed in this paper that they are outperforming \"conventional\" models. I don't think that these comparisons are against state-of-the-art alternatives, and maybe not even alternatives that people are using (although I could be wrong, and the details weren't given). For example, [A] from 2019 would be a more sophisticated way to implement NON. For publication in a selective conference such as ICLR on a task that many people are working on (see the \"previous work\" section - many people are trying to use ML to solve PDEs faster), I'd like to see strong evidence that people should try this method. \n\nCorrectness of other claims:\n\n6. I don't fully understand the runtime performance section. For deploying the ATO method after training, based on Figure 2, I would assume that each simulation step requires one step of the reduced simulation plus applying the encoder and decoder. Are those the two numbers reported here? It seems that for the advection-diffusion solver, each step for ATO would be 0.01 + 0.02 = 0.03 s, which is higher than the 0.02 s reported for the reference. In that case, it's misleading to say \"For the advection-diffusion scenario, this difference is less pronounced...\"\n7. Talking about Figure 13, they say \"In these different metrics, our experiments consistently show that training with the autonomy leads to the best performing model while the constrained training deteriorates its performance.\" I think it should be explicitly mentioned that NON beats their method in the LSIM metric for the advection-diffusion case (Figure 13b).\n\nMinor comments (don't have to address in response period):\n\n- I'm just curious: why decode & encode between each subsequent step? (Figure 2) Perhaps the results would be improved by staying in the latent space to apply the PDE solver repeatedly?\n- This wording was hard for me to follow: \"For the interacting setups (i.e., ATO, CLS, and CEN), the models are trained using a differentiable physics framework such that the evaluation of trained models influences the approximated solution trajectory, where the number of recurrent interacting steps varies.\"\n- Figure readability: At 100% zoom, the text in most figures is too small. At 150% zoom, the color bar labels in Figures 1, 4, 8, 9 are too small, and some labels in Figures 3 and 13 are too small, but the rest become okay.\n\n[A] Fukami, et al. \"Super-resolution reconstruction of turbulent flows with machine learning\" 2019\n",
            "summary_of_the_review": "My main concerns are (1) that the experiments don't clearly demonstrate the core claim that autonomy in the latent space leads to better performance (missing ablation study), and (2) that the new method isn't compared to strong alternatives. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces a training method for PDEs,  where the authors use an encoder to reach a reduced latent space (hence reducing the degrees of freedom) from a finer state, use a solver on this reduced space and decode (using a decoder) the output back to the finer space. \n\nThe authors show that when the encoder and decoder are both parameterized by neural networks and are learned autonomously, the training procedure is able to recover the solutions with high low l2 loss as compared to versions where the learning is restricted.\n\nThe methodology is empirically evaluated over the Burgers equation and Navier Stokes.",
            "main_review": "The methodology introduced by the authors indeed recovers solutions with low l2 and SSIM scores as compared to other methods (constrained interaction and no interaction settings). \n\nHowever, I do have a few concerns with the way the methodology is presented, which makes it a bit hard to follow. \nSome of them are:\n*  In Constrained interaction: it is unclear what is the exact loss that the CLS and CEN setup are minimizing. While the authors have tried to explain in words what they are doing (i.e, for CLS penalizing the deviation from the physical state in reduced representation), explicitly writing it down in math is important to understand where the ground truth is coming from. \n* There are a bunch of side remarks based by the authors that are hard to follow: \n   - While explaining CLS, there is something mentioned about divergence-freeness constraints, that they don't elaborate upon (and it is not clear to me how it helps). \n   - In the last paragraph for ATO, where the authors say that training process tries to abstract states from accurate fine representation of the solution. There is no way to understand what they mean here. \n* In the second paragraph of section 2, the authors mention that $r_{t+1} = P(\\hat{r}_t)$. Should that be $\\hat{r}_t$ or $r_t$? \n* The authors should clarify what whey mean by the integrated steps. Is it the look ahead as in the Um et al., paper. If yes, I also think that the loss mentioned in eqs 3 and 6 should be appropriately updated? Rather, I am confused between what $N$ and $n$ represent. Are they the same thing?\n\nFew other questions regarding the network architectures and evaluation:\n* The authors are using U-Net as their encoder/decoder architecture. This implies that the encoder and decoder are not independent. It would be interesting to see if this architectural choice is important for their results, i.e., what happens when there is no feature propagation between the encoder and the decoder. \n* it is mentioned in the appendix that the weights are warm started for ATO models. I think this is an important detail, which should be included in the main paper. Furthermore, does that main that all the results with ATO have a warm start, if yes, I think that the authors should show what happens without the warm start, and how much does the performance deteriorate if this warm start is reduced. \n",
            "summary_of_the_review": "While the methodology introduced by the authors indeed is helpful in enabling use of a reduced space to solve for a PDE, I feel that there current version of the manuscript does needs work and is hard to follow. As mentioned in the main review, there are quite a lot of details missing from the main paper, and some of the terms used by the authors are confusing. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper presents a method for solving differential equations in a reduced space using a CNN encoder--decoder architecture. The idea is to take the initial state and encode it into a lower-resolution representation that can be processed with a differentiable solver. After iterating the solver for a desired number of timesteps, the solution can be extracted with a convolutional decoder. The authors find that this approach outperforms a baseline solver that operates on a low-resolution initial state without the encoder/decoder. The authors evaluate their approach and a number of variations on two problems involving advection-diffusion and buoyancy-driven flow. Overall, while the current evaluation is limited to relatively low-resolution 2D simulations the method may be of interest for reduced order modeling of PDEs.",
            "main_review": "**Strengths**\n\n- The method is conceptually straightforward and easy to understand, and the authors do a thorough evaluation of different variations of the approach.\n\n- The results demonstrate that the encoder--decoder architecture can significantly outperform the baseline on the example problems.\n\n- The paper is mostly clear and well written.\n\n**Weaknesses**\n\n- I'm wondering what the closest related work to this method is. The idea seems so simple that I'm doubtful it is completely novel. Therefore, I would expect some experimental comparison to the closest related work, but the authors only compare to their own baselines. Would the closest method be the learned solver of Kochkov et al. (2021)?\n\n- Another concern is that it's not clear how well the method might scale to larger problem domains or more practical situations. It's also not very clear what the network is actually learning or how well this would work for situations in which the solution is less \"sparse\". Most of the solutions shown in the paper seem to be non-zero for a large area of the domain. It would be interesting to see if this still works well for a \"denser\" problem(like the Kolmogorov flow used by Kochkov et al. (2021)).\n\n\n**Misc. Comments**\n\n- Why do NON and the baseline have the worst performance at timestep 0 and then improve for advection-diffusion? This is counter-intuitive to me and goes against the trends of the other methods (SSIM-- Fig. 13)\n\n- How are the metrics calculated (e.g., bar plots of Figs. 3, 12, 13, 14)? Are they averaged over all simulated timesteps? Do the error bars indicate the sample variance over the timesteps, or variance over multiple evaluation runs?\n\nFig. 1\nThe clarity of this figure could be improved:\n- What is the PDE that is solved here?\n- What is the considered the baseline-- is it the \"reduced\" low-resolution simulation or the \"full-resolution\" reference?\n- I assume the columns represent increasing time (from left to right), but this should be clarified.\n- The labels on the colorbar are too small to be legible (same for other figures).\n\n",
            "summary_of_the_review": "Overall I think this is a simple and elegant idea that may be of interest to the broader community using learned models to solve PDEs. The biggest drawback for me is the lack of comparison to related work and the lack of more sophisticated test problems. I'm leaning positive towards the paper, but would like to see the authors address some of these concerns (especially to more clearly identify the closest related work).\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}