{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper introduces an interesting problem for 3D shape mating. The paper reads well (at some level), and the experiment result shows that the proposed approach can successfully align two pieces of objects.",
            "main_review": "I have serious concerns after carefully reading the paper.\n\n**Problem definition**\n-\tThe paper argues that “we study the problem of 3D-assembly of unknown objects”. However, the proposed setting is not considered to be a general shape assembly problem. The keyword ‘assembly’ is more probable for the case where the geometric primitives are being combined to make new shapes. The paper should limit the applicability of the algorithm.\n\n**Exposition**\n-\tVery broad introduction, but it turns out to be a narrow problem. For instance, “putting a pen in a cap, or inserting a plug into a socket are all instances of geometric mating”. However, this paper is not tackling this problem. The first two paragraph states general problems “fit, snap, connect, or mate together.”, but in the third paragraph, the paper says, “we focus on pairwise shape mating…”\n-\tAuthors state that the problem is “important for the robotics…” or “fracture reassembly…”; however, the problem itself is not directly related to these problems. Rather than that, the problem seems to be synthetic and just focuses on the alignment of two pieces. There is no demonstration of how the multiple pieces can be combined (at least to apply resembling fragments of a broken base)\n-\tThe paper writing is not that clear. For example, the Transformer based approach without justification. The input and output dimensions, intermediate structures are not apparent in the main paper. On page 5, how are the features aggregated?\n-\tThe current writing states, “we select the Transformer network… we aggregate the feature h_i to form the feature H_i…”. Readers cannot have detailed information from this description. These paragraphs are identical to “we use Transformer to aggregate features”.\n-\tIn Section 4.3, what are P_i and P^{pred}? What is the difference between P_i and p_i?\n-\t“We adopt DGCNN as our point cloud encoder E, since DGCNN jointly considers local and global information during feature extraction”. It is not true. Both PointNet and PointNet++ jointly consider local and global information by using a feature pooling mechanism.\n \n \n**Approach**\n-\tSection 4 is not that clear. There could be multiple choices for the network design. Why do the authors choose to select this architecture? What is the crucial observation in designing this pipeline? Given the limited explanation, the channel seems to be just a combination of existing modules. \n-\tThe claim about the new dataset seems not that clear. The division of the objects can be conducted on the fly, which means the data loader would make an infinite number of combinations. In addition, the class of the dataset is quite limited (‘bag’, ‘box’, ‘jar’, and they have a similar topology). \n-\tThe approach requires a fixed number of points. How can the approach handle unbalanced point sets? For instance, a shape can be divided into a larger piece and a smaller piece. Then, given the same number of points, the density of the two-point sets could be quite different since N is fixed as 1024. Are there some rules for the data generation to cover challenging cases?\n-\tThe features are utilized for estimating canonical poses. Is this a plausible setting for the training? For instance, the same parts should have the same geometric features, and they should not be mapped to the different R^GT and T^GT.  \n\n**Experiments**\n-\tI am not sure the baseline approach is correctly selected. Are there other approaches that can be adopted for the registration? Do DCP and GNN is trained with the proposed dataset? Especially, ICP is intended for the local shape registration, not these kinds of global registration. The results of ICP and SparseICP just add some meaningless numbers. Consider comparing global registration techniques with the same training dataset. \n-\tMy feeling on the experiment section is aligning two small pieces with a minimal amount of overlaps. I don’t see a special idea for ‘assembly’ or ‘generalized mating’.\n-\tHow about the computation complexity of the approach? The approach consists of a signed distance field and its evaluation of the implicit function, so it would take some time even if the approach tackles the object scale problem.\n-\tHave authors tried other point cloud encoders? What about the results using PointNet and PointNet++? \n-\tIn Figure 3, on the column of ‘different cut types’, the fourth image has a cyan area around the yellow area. Is this natural decomposition?",
            "summary_of_the_review": "Overall, I am **not learning toward paper acceptance** due to the following reasons. \n-\tWeak technical contribution (combining popular modules (Transformers and SDF) to make it work) \n-\tWeak justification of the problem. I don’t think the paper is tackling general assembly problems. The network learns the canonical pose of the parts.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper focuses on a newly introduced task: \"shape assembly\": given two point clouds representing two parts of an object, find two rigid transforms st applying them to the input point clouds produces an assembled object. \nAuthors introduce a novel dataset for the task and a new method to solve it. \nThe dataset is synthetcally generated by cutting meshes from 3 categories into two parts with a set of pre-defined parametric cutting functions (planar, sine, etc, parameters are sampled randomly) and applying random rotations to the resulting two point clouds. \nThe new method is a rigid pose regressor that operates on pairs of point clouds, a combination of a PointNet and a transformer, and is trained to minimize a combination of regression and adversarial losses, as well as a learnable shape prior. \nExperimental evaluation suggests that the method outperforms all of the considered baselines, and the method is capable of generalizing to unseen object categories.\n",
            "main_review": "**Strengths:**\n\n+ Writing quality. The manuscript is relatively well-written and is easy to follow.\n\n+ Formulation and method. The general problem statement is sound, and the architecture and loss function choices seem reasonable.\n\n+ Experimental Evaluation. Elaborate experimental evaluation is conducted on the newly introduced dataset, and results suggest that the proposed method outperforms all of the considered baselines, which include both traditional registration methods and learning-based methods. Method also seems to generalize to unseen categories (although see below). Ablation study is present that evaluates the importance of individual loss terms.\n\n**Weaknesses:**\n\n- Reproducibility. Some technical details are missing. For example, it is not clear what exactly is meant by \"aggregate\" in Section 4.2. Generally, the explanation about how transformer is applied and how features are combined together is a bit vague. I understand that the code will be made publicly available, but it would be great if authors could make their paper more self-contained.\n\n- Dataset. Proposed dataset contains objects from three categories, which seems like a very restricted setting, and somewhat undermines the value of the new dataset. Although not exactly the same task, but a related work Form2fit claims to be generalizing to new shapes of objects. \n\n- Evaluation. Authors claim that the method can generalize to new categories, but given that there are only three categories in total, and they are very similar (jars, bags and boxes) it is very hard to infer how general this conclusion is. For example, if one took a category like \"airplanes\" from ShapeNet, is it reasonable to expect the method trained on jars and boxes to generalize? \n\n- Novelty. Although the complete method has not been proposed before, all of the individual components have been used before, as pointed by authors themselves: PointNet encoder to obtain feature representations, rigid pose regression, implicit reconstruction term prior.\n\n- Relevance / Applications. Authors did mention that their task and model has potential applications to fracture reassembly - which seems to be a particularly narrow domain (I would be open to be proven wrong on this!), and object packing - which seems like a more broad application, but for both of those suggested authors do not explicitly demonstrate performance of their method on corresponding datasets, nor elaborate on how exactly proposed task and method can be used to solve it. For example, fracture assembly (assembling a broken vase?) might involve a very large number of pieces, and it seems far from trivial to extend the proposed task and method to solve it. In order to make this work more compelling, I would encourage authors to demonstrate a realistic application that relies on the newly proposed method and dataset. Otherwise, I am afraid that this work might not be very relevant for the general research community.\n\n**Misc:**\n- It is a bit confusing why the number of points in both point clouds should be the same? Mb worth changing the notation.\n- It would be helpful to know what the values of N and d (or a rough range). \n",
            "summary_of_the_review": "The paper is well-written, the method seems reasonable, but the relevance and significance of both new dataset (task) and the method is questionable. The task itself seems very specific and not directly useful to the claimed potential applications, while the proposed method is a combination (admittedly, a novel one) of existing techniques, without major modifications. Evaluation seems insufficient to support the claim of generalization to new object categories. Thus, I am more leaning towards rejection, but would be eager to reconsider after hearing authors' response.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a solution to the task of aligning parts of shapes to retrieve the original object. The method focuses on learning alignment from geometric information rather than semantic information. Point clouds are fed to the pipeline that learns to approximate the spatial transformation that aligns two non overlapping pieces from the same shape. The authors propose a new synthetic dataset for the task and evaluate their method on that dataset. ",
            "main_review": "### Pros\n- The authors propose a novel application that corresponds to very relevant existing problems in robotics and could be applied in problems on proteins in biology as well.\n- The proposed architecture is interesting and the idea of using SDF reconstruction as a regularization for the main task seems quite efficient.\n- The proposed dataset corresponds to the task and would be interesting to use as a benchmark for future work on similar tasks.\n- The method is compared extensively to multiple categories of methods (classical point cloud registration, semantic part assembly). And an ablation study of the different components is provided.  \n \n\n### Cons\n\nIf my understanding is correct, the method is evaluated for aligning pairs of objects parts that are in correspondence and sampled from a synthetic dataset. The task being quite novel, it is important to be able to measure how useful it is for a range of real tasks.\n- While the authors give examples of the problem on non synthetic data (reconstructing broken vase, object packing), and also evaluate on noisy point clouds, it would make the paper a lot stronger to evaluate the method on such examples. Given that the current dataset is completely synthetic it is difficult to evaluate how well the method would work on real life examples or dataset. Some of which could be boxes, scans of broken objects, or proteins as used in “Fast end-to-end learning on protein surfaces”. Sverrisson et al. CVPR 2021.\n- A very interesting related task, that would help to highlight the practical uses of the method would be classification of compatible parts. Can the learned cross shape information help for estimating compatibility between parts of objects? For instance, given multiple pairs of object parts, is it possible to classify the corresponding pairs?\n   \n- Neural Surface Matching is compared to point cloud registration methods that are designed for point clouds with high levels of overlaps and GNN assembly which relies on semantic information. While these tasks are related, the methods were not designed for the type of alignment tasks considered and are not expected to perform well. The results would  have been more compelling if methods that are designed for low overlaps and for comparing geometric features such as  “PREDATOR: Registration of 3D Point Clouds with Low Overlap”,  Huang et al. CVPR 2021 or less recent methods for registration of robust shapes with incomplete overlapping, or “Fast end-to-end learning on protein surfaces. Sverrisson et al. CVPR 2021” were discussed and if the method was  compared to similar methods.\n- It would be useful to describe the complete architecture in more detail or add a figure of the complete pipeline with sizes of inputs, outputs and also the various layers (additionally to those provided in Sec 6 and A) as some points are not completely clear. What exactly is the input of the transformer network? Are the features hA computed from fA and fB or only fA?  How exactly are the features f_i aggregated to form F_i? Is a form of pooling used?\n\n### Minor comments:\n- It would be interesting to discuss the link between the method and partial shape matching ( for instance Litany et al. \"Fully spectral partial shape matching.\" Computer Graphics Forum)\n- Small typo in the introduction: “we also use an adversarial shape prior evaluate” -> “we also use an adversarial shape prior *to* evaluate”\n",
            "summary_of_the_review": "The task considered in the paper is novel and relates to very interesting applications. While the method is efficient on synthetic data, it is important to study how the method would perform on real data and how it compares to closely related baselines that process similar geometric information. A minor concern is the limited details provided on the architecture that limits the reproducibility from the paper alone.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper presents a new dataset and method to address the task of neural shape mating. The main idea is to decompose an object into k disjoint sets (in this work, k=2) and learn how to re-assemble such parts to a full object. Specifically, the goal is to predict an SE(3) transformation for each part in a self-supervised manner. The proposed network further computes a DeepSDF surface reconstruction of both input parts S_A and S_B and learns a shape prior of full shapes S_A v S_B via adversarial learning. ",
            "main_review": "Overall, the presented approach is technically sounds and reasonable. However, parts of the exposition are too vague and at times ambiguous. Detailed suggestions are listed below. \n\nAt first glance, the task of \"shape mating\" is intimately related to partial shape registration. Im my view, this does not limit the contribution of this work. The distinction between the two is subtle, but important:\n- The considered parts S_A and S_B are exactly disjoint, they do not overlap. \n- They sample points of solid, partial objects, rather than partial samples of the full surface.\n- The empirical comparisons clearly show that the proposed approach is more robust than such correspondence based methods. This justifies the need for specialized architectures.\n- Other part assembly methods typically rely on semantic labels.\n\nSince the proposed network predicts an SE(3) transformation for both input parts, the ground-truth assembly is inherently ambiguous. Applying a rigid transformation to the ground truth pose again yields a full, assembled object. How is this addressed in practice? Is the network biased to specific canonical poses? Other registration methods fix one of the two input poses. Does the loss function in Eq. (1) assume one \"ground truth\" pose, or can it account for rotated full objects?\n\nDataset:\n- The proposed dataset constitutes a useful contribution for future research. I find the diverse types of cuts compelling.\n- A major limitation of the dataset, on the other hand, is the limited scope of object classes. The considered object categories \"jar, box, bag\" are all fairly similar and geometrically plain. In comparison, most object categories in the source datasets Thingi10K (Zhou & Jacobson, 2016) and Google Scanned Objects (GoogleResearch, 2021) have significantly more geometric details. Include more diverse object classes should be straightforward, since the method is self-supervised.\n\nThe related work discussion is adequate. For completeness, the following references should be added:\n- [a] Zhou, Qian-Yi, Jaesik Park, and Vladlen Koltun. \"Fast global registration.\" ECCV 2016.\n- [b] Litany, Or, et al. \"Non‐rigid puzzles.\" Computer Graphics Forum 2016.\n\nDetailed comments on the paper's exposition:\n- Many details on individual components of the proposed networks are missing. Appendix A is too brief.\n- It is mentioned that the regressor consists of \"two FC layers\" and that quaternions are used to represent rotations. I would advise the authors to either add further details or provide a reference that describes what such a module looks like in practice.\n- Why is the discriminator loss in Eq. (2) preferred over a standard cross-entropy loss? \n- How is the adversarial shape prior trained? Adversarial learning is not equivalent to simply adding a loss function, further details are required.\n- How are the features f_i and h_i aggregated into global descriptors, before being passed to the registration module?\n- The benefit of the SDF reconstruction network is not evident. It requires to predict depth values for 40k points for a relatively small empirical improvement. I would like to see further ablations, e.g. showing how the SDF reconstruction affects the robustness to noisy observations.\n- When cutting meshes, how is the cut-off ratio (area percentage of the two parts) chosen? \n- How are the \"shell shapes\" obtained? How is the thickness of the outer shell chosen?\n\nMinor:\n- Page 2, first paragraph: \"an implicit shape prior [to] evaluate ...\"\n- Page 4, last paragraph: mentioned input features twice.",
            "summary_of_the_review": "In my view, the problem of learning to assemble disjoint parts of an object is compelling. The presented approach is technically sound. It has many moving parts, but ablations confirm that all components are necessary for an optimal empirical performance. My main concerns are the limited scope of considered object classes and problems with the exposition, as detailed above. I therefore lean towards rejecting the submission in its current form.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}