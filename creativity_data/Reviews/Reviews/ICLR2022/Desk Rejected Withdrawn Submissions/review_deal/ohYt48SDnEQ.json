{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper mainly focuses on improving the transferability of the model ensemble attack, using stochastic variance reduced gradient technique to correct the gradient of model ensemble, so as to better take advantage of the advantages of different surrogate models to generate more transferable adversarial examples. Experimental results show the superiority of the ASR under white-box attack, black-box attack and many defense measures.",
            "main_review": "Pros: \n1. For the model ensemble attack, this method uses the stochastic variance reduced gradient technique to correct the gradient results obtained under average solution when different surrogate models are used. Compared with averaging results on different models directly, this method can balance the gradients between different models better, thus enhancing the transferability of adversative examples.\n2.  In the view of experimental results, this method does have a certain effect on enhancing the transferability.\n\nCons:\n1. In terms of innovation, I don't think the contribution of this paper is enough. The most innovative point of the paper is to introduce some randomness to the gradient through an inner loop behind the average ensemble gradient. This is an easy idea to think of, and in terms of technical details it uses an existing method, which is not novel enough. \n2. The paper lacks certain theoretical support. As for the introduction of the stochastic variance gradient reduction technique, the authors do not analyze its influence on the classification model decision and gradient updating direction in detail from the theoretical point of view, which is more like an experimental verification conclusion. For other methods to improve the transferability, such as [1], the authors provide at least part of the analysis, I think this is very necessary.\n\n[1]. Dong, Yinpeng, et al. \"Evading defenses to transferable adversarial examples by translation-invariant attacks.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n",
            "summary_of_the_review": "In summary, although there are some improvements, the novelty is limited. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper considers the problem of black-box adversarial attacks based on adversarial transferability. In ensemble attacks, this paper proposes a new stochastic variance reduced attack method to improve the performance. The new method stochastically performs M steps of gradient updates to reduce the variance. Extensive experiments on ImageNet prove the effectiveness.",
            "main_review": "Strengths:\n\n- The paper is written clearly. The experiments are well-organized.\n- The propose method is simple yet very effective according to the experiments.\n\nWeakness:\n\n- As this paper proposes to reduce the variance of ensemble attacks, it fails to precisely define \"variance\" in adversarial attacks. Does it mean the variance during gradient updates or some others? Defining the variance is essential to fully understand the novelty and contributions of this work.\n- The new attack is proposed to reduce the variance, but this paper does not illustrate why the new method can reduce variance. Empirical or theoretical analyses are needed. \n- The experiments only show the attack success rate as the measurement, but do not show whether the variance is reduced. It is not clear whether the improved performance is due to the variance reduction.",
            "summary_of_the_review": "Although this paper proposes a new method to reduce the variance during ensemble attacks, it has some weaknesses as specified above.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper investigates the limitations on existing model ensemble attacks in adversarial settings and proposes an algorithm that incorporates stochastic variance reduced gradient technique into ensemble-based attack approach. Extensive experimental results have demonstrated that the proposed method can enhance the transferability of adversarial examples yielding better attack success rate.",
            "main_review": "***Pros:\n\n(1)The discussion of the studied problem is clear and the description of the proposed stochastic variance reduced ensemble attack method is well-written and easy to follow.\n\n(2)The experimental evaluations are thorough and well-organized to show the effectiveness the proposed attack method comparing to previous well-known gradient-based attacks on both normal cases and defense models.\n\n*** Cons:\n\n(1) The novelty is limited, since it brings a classic existing approach, variance reduced gradient method, to ensemble based adversarial attack.\nOther works in the line of ensemble adversarial attack [1] or highly related to variance tuning [2] technique in adversarial attack are not fully discussed and compared.\n\n[1 ] Che, Zhaohui, et al, “A New Ensemble Adversarial Attack Powered by Long-Term Gradient Memories”, AAAI 2020.\n\n[2] Wang, Xiaosheng, and Kun He, “Enhancing the Transferability of Adversarial Attacks through Variance Tuning”, CVPR 2021.\n",
            "summary_of_the_review": "The major concern is the limited novelty in comparison to some recent highly related works.\nSee Main Review for more details. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors propose a stochastic variance reduced ensemble attack (SVR-Ens) method to boost the transferability of ensemble-based transfer attacks. Instead of simply averaging the gradients of surrogate models, the authors leverage a stochastic variance reduced gradient (SVRG) method to find a better update direction. Extensive experiments are conducted to demonstrate the effectiveness of SVR-Ens.",
            "main_review": "Strengths:\n1.\tThis paper is clearly written and easy to follow.\n2.\tThe experimental results are good.\nWeaknesses:\n1.\tWhile the paper has good results, the novelty seems to be limited. It’s not clear why SVRG can boost transferability. The authors claim that previously computed gradient information is not utilized in existing methods, but in fact, prior works usually use a momentum factor to leverage historical gradients [1].\n2.\tAlthough the authors conduct an experiment to show the improvements are not caused by more gradient calculations, it’s better to conduct experiments under stronger attacks, especially random-based methods like SI-TI-DIM. MI-FGSM is a deterministic algorithm, so it is easier to converge. However, some random operations are introduced in SVR, which may play a role like data augmentation. Thus, from Figure 4, we can see that the SVR-Ens methods are worse than Ens under a few gradient calculations but better with more gradient calculations. The experiments will be more solid if the authors discuss other random-based attack methods and increase iterations to make all methods (SVR-Ens) converge like MI-FGSM.\n3.\tBesides SI-TI-DIM, it's necessary to compare with Variance Tuning Gradient-based Attack methods [2]. Both methods aim to reduce the gradient variance, and [2] discussed the difference between their methods and your SVR methods. Please see details in Section 3.1 of [2]. It's better to conduct experiments to verify whether SVR-Ens outperform [2] under the same gradient calculations times or compare the performance when both methods converge. \n4.\t[1] proposed to ensemble on logits to achieve higher transferability. This scheme can be naturally integrated with other methods, but I think it is incompatible with SVR-Ens. Is it a limitation of SVR-Ens?\n[1] Dong Y, Liao F, Pang T, et al. Boosting adversarial attacks with momentum[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 9185-9193.\n[2] Wang X, He K. Enhancing the Transferability of Adversarial Attacks through Variance Tuning[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 1924-1933.\n",
            "summary_of_the_review": "This paper proposes an ensemble-based attack method. The method is easy to be understand and has good results. However, the method is not novel and similar to exist work. Please address issues listed in the detailed comments during the rebuttal.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}