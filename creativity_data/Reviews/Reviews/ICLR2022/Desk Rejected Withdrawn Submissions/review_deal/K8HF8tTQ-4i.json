{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a method of controllable text generation where the goal is to generate text from a language model given an attribute such as a specific topic, sentiment, or toxicity. Presented as a step-wise approximation of a previously proposed EBM-based method [1], the method works by modifying the output softmax distribution at each decoding step of the language model to increase or decrease the influence of the desired attribute. The energy functions for desired controls are represented using the presence or absence of predefined keywords in the vocabulary. With this setup, the authors show improvements over several baselines on metrics such as fluency, diversity, and control on tasks of controlling topic, sentiment, and reducing toxicity in the outputs and their combinations. The authors also show that this formulation subsumes many related papers in this area which also modify output probabilities to enforce control.  ",
            "main_review": "Strengths: \n1. The presented solution is quite simple and the improvements obtained by using only keyword presence or absence-based controls are impressive especially compared to earlier work which uses more sophisticated methods based on classifiers or language models. \n\n2. The proposed approach is fast and has little overhead.\n\nWeaknesses:\n\n1. The motivation for the EBM formulation is not very clear. Although many papers (as the authors describe in the appendix) can be subsumed under this framework, it is not clear what insight it offers since it does not particularly give us a new way of designing constraints.\n\n2. \"> certain words carry important attribute-sensitive information\" \nThe constraints the author consider are keyword-based [1]. While this might work for cases such as topic or even sentiment. For more nuanced attributes not necessarily satisfied using keywords only or sentence-level attributes that cannot be measured just using the generated prefix (such as poetry generation, formality, etc), it's not clear how to define energy functions except for using classifiers or LMs which prior work like FUDGE or DExperts already does. How does this work differentiate from similar prior work in that case?\n\nSome questions/suggestions:\n1. Since the evaluation is quite subjective, it could benefit from some human evaluation to make the results more convincing.\n2. For measuring control for sentiment/toxicity the authors report the average probability of the desired attribute measured by the classifiers whereas prior work reports the accuracy of the desired attribute. If the generated text is say, non-toxic, as predicted by the classifier, does it matter if the probability was 0.9 or 0.6 (especially considering the classifiers may not be well-calibrated)?\n\nSome missing citations: \n[1] NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints (https://arxiv.org/abs/2010.12884)\n[2] CoCon: A Self-Supervised Approach for Controlled Text Generation (https://openreview.net/forum?id=VD_ozqvBy4W)",
            "summary_of_the_review": "The presented approach on controllable text generation while showing improvements on keyword-based controls like topic or sentiment, does not offer any new insights in its formulation as an energy-based model. Furthermore, it's not clear how keyword-based controls are flexible enough or can be extended to setups other than the ones presented in the paper. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Discrimination / bias / fairness concerns"
            ],
            "details_of_ethics_concerns": "Since the paper describes a method of controlling attributes of text generation, it could potentially also be used to increase toxicity or bias rather than decrease it, for example. Potential misuses or harms should be acknowledged in the paper. ",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed a step-wise energy-based method for controlled text sampling. The authors  introduce step-wise weighting approach with the conditional energy function as an extension to the probability function of the vanillia auto-regressive LMs.  Multiple energy functions are designed for different attribute-control scenarios. The control for different attributes all relies on whether the next generated tokens appears in a given keyword list. The method is only related to the sampling scoring function, so it requires no training/fine-tunining.\n",
            "main_review": "strengths：\n- The article is well written, rather clear and well structured.\n\nweaknesses：\n- On Page 3 above equation 5, author assume that h_theta is a constant which is not reasonable with no explain why that hypothesis holds.\n- The control for different attributes all relies on whether the next generated tokens appears in a given keyword list which is not reliable. Taking sentiment control as a example, words in positive list may express the negative sentiment \n   when it is concated with  negative word such as \"not\" or \"never\",\n- The framework proposed in this paper is incremental in nature and lacks novelty, which is only an extension to the probability function of the vanillia auto-regressive LMs. \n- The datasets in the experiments were only 100 samples for each compared method. It would be more convincing if some extra experiments were done with larger size of samples. \n- There is no reliable automatic evaluation metrics for text generation tasks, so human evaluations are necessary.\n",
            "summary_of_the_review": "The framework proposed in this paper is incremental and lacks novelty.\nThe control for different attributes all relies on whether the next generated token is in a given keyword list.\nThe evaluation in the experiments is on 100 generated samples for each compared method.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This work proposed a general framework for controllable text generation tasks, which approximates the sentence-level energy-based model to a product of step-wise ones and thus enjoys high training efficiency. Some energy functions are instantiated for different controllable signals and experiments. Experiments validate the performance of effectiveness and efficiency over some competitive methods.",
            "main_review": "First, it is meaningful to approximate the sentence-level EGM to step-wise EGM. However, I am not very clear why some approximations. In Eq.4, I think for different x’s, h(c|x) should not be a constant. Why here can make such assumption? How the approximation of using top-k sampling used in training? Especially when the target x_t^{(t)} has not yet been included in top k in the current iteration?\n\nSecond and also my major concern is about the energy function design. It seems not a good choice to pre-classify each word into certain sentiment or toxicity without a context. For example, if the previous generated text contains a negation such as “not”, “doesn’t”, the energy function will function in a wrong way? Also, I notice that in the experiment part of 3.4，the considered topics have no overlapping topic keywords. What would happen if the topics have overlapped keywords?\n\nFor the experimental results, considering that the major advantage of this method is its high efficiency, I am ok with the current results that the proposed model does not outperform some methods on most of the compared controllable generation tasks.\n",
            "summary_of_the_review": "Overall, the idea is interesting and useful to the community. However, some parts of the model designs are not clear enough. If the authors can answer my questions with supporting results, I will consider to raise my score. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a step-wise energy-based model (EBM) for controlled text generation (CTG). The authors first derive the step-wise EBM from sequence-level EBM, and then design different keyword-based energy functions for 5 typical scenarios of CTG. The authors also claim their method as a unified framework for CTG, which can be specialized to previous CTG frameworks via a specific energy function design.\n\nExtensive experiments on CTG are conducted based on the automatic metrics of control accuracy, fluency and diversity. Results show that the step-wise EBM can achieve state-of-the-art performance on the tasks of text generation with word / topic / multiple control(s). Also, it is the most efficient method among all the baselines.",
            "main_review": "Strengths:\n1) As a unified perspective for various CTG frameworks, the proposed step-wise EBM is somewhat novel and interesting. Although this paper only focuses on empirical designs of energy functions, I think the proposed method may be beneficial for further analysis on theoretical properties of various CTG frameworks.\n2) Comprehensive and extensive experimental results on automatic metrics show the effectiveness of the step-wise EBM on various CTG tasks. The high computational efficiency of the proposed method is also worth noting.\n\nWeaknesses:\n1) In Section 2.2, the derivation from sequence-level EBM to step-wise EBM is questionable. The assumption under Equation 4 and 5 is that $h_{\\theta}(c|x_{1:T-1})$ is constant, which is confusing for me. Common attributes to control such as sentiments and topics reflect sentence-level characteristics. So, I can’t understand why previous tokens $x_{1:t-1}$ don’t affect the attribute prediction at the timestep $t$.\n2) In Section 2.3, the details on how to choose keywords should be clarified. I wonder how to obtain an external classifier which can predict each word’s sentiment. Furthermore, since the keywords of attributes are still acquired from external attribute classifiers, what is the advantage of utilizing the keywords extracted by classifiers over using classifiers directly?\n3) The authors claim the high computational efficiency of the proposed method in Section 1. But I think the difference of efficiency between step-wise EBM and the existing work (such as GeDi) mainly falls into the choice of classifiers (keyword-based classifier vs. neural-network-based classifier) rather than the algorithm itself.\n4) This paper lacks human evaluation, which is important for evaluating CTG models and is commonly adopted by related works. The automatic metrics including perplexity, distinct n-grams, and attribute accuracy (from external classifiers) may not correlate well with human judgments.\n5) The choice of base models may cause an unfair comparison. From Section 3, the authors choose GPT-2 small as the base LM, which is different from several baselines. From Table 3, the authors explain that CTRL and DAPT perform better because they use GPT-2 large as the base LM. But in my view, the authors should make a fair comparison at least based on the same base LM to demonstrate the effectiveness of their own methods. Also, in Section 3.5, the computational efficiency is strongly affected by the model size. From Table 6, I feel that the superior efficiency of the proposed model mainly comes from the smaller base LM rather than the proposed method (i.e. step-wise EBM).\n6) I have a minor concern about the experiment. In Table 4, I see the perplexity of GPT-3 models is missing. The reason should be further clarified.",
            "summary_of_the_review": "Strengths:\n1) A somewhat novel and interesting EBM framework for CTG tasks\n2) Strong performance on automatic metrics\n\nWeaknesses:\n1) Questionable assumptions\n2) Lack of human evaluation\n3) Unfair experimental setups about base LMs\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}