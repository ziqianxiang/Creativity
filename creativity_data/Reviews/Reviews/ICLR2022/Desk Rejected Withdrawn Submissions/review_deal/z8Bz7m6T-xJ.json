{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This work proposed a multi-label iterated learning framework to overcome the label ambiguity of the existing datasets. The framework contains a teacher and a student networks. The teacher network will train for a few iterations and its multilabel predictions will be used as the pseudo labels for student training. After a few iterations, the student will be used as a teacher. The process alternated. Experiments show the proposed method has good results.",
            "main_review": "Strengths. \n\nThe problem this work is solving is very interesting. Most current benchmarks are singly labeled, while it is common that there are multiple categories exist in an image. The experimental results show the proposed method is effective.\n\nWeaknesses.\n\n1. iterated learning, self-training, teach and student networks are all very popular techniques. The technical contribution of this work is limited.\n\n2. it is very tricky to set the K_s and K_t. Too large K will lead to overfitting to the singly labeled dataset, while too small K results in underfitting. This drawback makes the method hard to be useful in real scenarios.\n\n3. the training is very computationally expensive. It is hardly to know how many iterated rounds are needed. Although, some improvements are shown in the experiments. It is not clear whether the improvement worth the cost.",
            "summary_of_the_review": "The major concern are the technical nolvelty, the hyper parameters and the training cost.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper aims to address the label ambiguity issue in network training, which is motivated by the mismatch between the multi-label nature of data and single-label based loss function. To address this problem, an interated learning strategy is adopted, where teacher training and student training are interated in order that the teacher learning elicits multi-label prediction by using binary CE, which is imitated by the student. Experiments on different experimental settings including ImageNet training, learning from noisy web data, domain generalization and self-supervised fine-tuning are conducted to evaluate the effectiveness of the method. ",
            "main_review": "Strength:\n\n1. This work provides insight about how to mine additional semantic information from image data to improve network training when the labeling is biased and insufficient. Something interesting is observed from the iterated training process such as the imitation training step should be controled in order to distill effective information from teachers.\n2. Comprehensive experiments are conducted to verify the effectiveness of the proposed iterated learning. \n\nWeakness:\n\n1. This work shares conceptual similarity to noisy student, although motived differently. From Fig. 4 (a), it can be observed the performance gap between noisy student with Sigmoid and optimal MILE is small. Then what is the essential advantage of MILE?\n2. MILE is somewhat sensitive to the training iterations of interactive learning and imitation learning phases. This discounts the value of the work.\n3. It will be necessary to probe whether the interactive learning indeed  learns meaningful multi-label information. What will the performance be like if simply performing logits perturbation such as label smoothing?",
            "summary_of_the_review": "This work addresses an important task in computer vision and it has some interesting observation from iterated training strategy. My major concern lies on the overlap with noisy student, the sensitivity to hyper-parameter and some indepth analysis. Hope the authors can clarify my concerns raised in weakness part. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed a novel approach for addressing the label ambiguity challenges which is suitable for most of the single-label datasets. Specifically, an instance could contains multiple positive labels while the dataset only assigns a single label, and this issue could be considered as the label ambiguity.\n\nThis paper proposed Multi-label iterated learning (MILe) approach. Specifically, a single-label classifier is modified and predict multi label results based on single-label supervision information. The confident predictions are considered as the pseudo labels and further train a student network. The obtained weights will transfer to teacher network and finished an iteration loop. All the networks are iteratively optimized and obtain the high performance. Experimental results demonstrate the effectiveness of the proposed model.\n",
            "main_review": "This paper proposed a novel approach for handling the label ambiguity challenge. The pros and cons are listed below:\n\nPros:\n\nThe high-level motivation of the proposed model is logical and reasonable. The motivation is clearly introduced, the introduction sections are comprehensive.\n\nExperimental results show the effectiveness of the proposed model, the ablation study also illustrates the module-level and activation function-level effectiveness of the modules.\n\nExperiments also illustrate the potential extension of the proposed model in a few more related tasks including domain adaptation and self-training fine-tunning.\n\nCons:\n\nThe novelty of the proposed model is not considered as significant. Specifically, the single-label/multi-label pseudo-label assignment and training strategy is widely used in self-supervised training and co-training related tasks. Various pseudo-label assignment and confident evaluation methods are proposed. To this end, the proposed pseudo-label module is not very novel.\n\nThe motivation of the teacher-student network and the training/iteration strategy is not clear. Specifically, there is a step where the weights of the student network will be copied to teacher network after the training stage supervised by the teacher network output as supervision knowledge. It is not clear why this step is necessary. It is more like a normalization procedure instead of a learning procedure.\n\nBased on the introduction of the training pipeline, seems like the training epoch (for each network) and the iteration for all networks are specifically tunned, and the overfitting should be carefully controlled to achieve the good performance. To this end, it is not convincing about which part (e.g., training procedure or the model structure) is the most effective reason for performance improvement.\n\nThe experimental results are not convincing. This paper claims that it mainly focus on solving the label ambiguity challenge. Based on my understanding, a high-performance in a general classification task should be the most convincing setting and should be well-explored. While, there are only a few numbers in Table 1 and discussion Section 4.1 for this setting, and there are no other state-of-the-art methods as baselines. This work introduced a few other settings (the experimental setting are not clear) including domain generalization and self-supervised fine-tuning. This does not match the motivation of the proposed model, and the setting and the problem solved are different. More explanations should be introduced.\n",
            "summary_of_the_review": "In summary, this paper proposed a novel approach for handling the label ambiguity challenges. However, the novelty of the model is not enough. The model design explanation should be added, and more experimental results should be discussed or introduced.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "To alleviate the suppression of classes that tend to co-occur in the data, this work proposes multi-label iterated learning (MILe) to incorporate the inductive biases of multi-label learning from single labels using the framework of iterated learning.  The proposed method\nalternates training a teacher and a student network with binary predictions to build a multi-label description of the images. Experiments on ImageNet show that MILe achieves higher accuracy and ReaL score than when using the standard training procedure, even when fine-tuning from self-supervised weights. Furthermore, MILe improves performance in class incremental settings such as IIRC and is robust to distribution shifts.\n",
            "main_review": "This paper has some positive aspects as follows:\n1.  This paper conducts experiments on multiple datasets and tasks, and shows the proposed method can achieve better performance when compared to other SOTA methods.\n2.  The paper is well written, the arguments are clear, and the methodology is well presented.\n\nHowever, the authors need to deal with some issues as follows:\n\n3. The motivation of the proposed method is not clear. Compared with the conventional teacher-student model, which can convert the one-hot label to soft-label, the main contribution of this paper is integrating the iterative procedure into the conventional teacher-student model. However, the explanation why this paper uses this operation needs to give more analysis.   \n4. Ablation study is not sufficient. From the technique view, as aforementioned, the main contribution of this paper is using iterated learning, yet the experiment in the ablation study is conducted on one dataset, and the improvement of the proposed is slight when compared to the NS+sigmoid. The authors should give more experimental results\n",
            "summary_of_the_review": "The paper is well written and the experiment is rich, which is conducted on multiple datasets and tasks. However, the motivation is unclear, and the ablation study is sufficient to confirm the effectiveness of the key module.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}