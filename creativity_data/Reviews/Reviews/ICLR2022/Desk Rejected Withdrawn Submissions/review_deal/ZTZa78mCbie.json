{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper investigates and analyzes how representations learned from supervised learning models behave as locality sensitive hash functions — this is such that they filter out nuisance factors of variability to learn invariant representations for classes — often leading to their superior performance on supervised tasks. The paper starts by studying a generative model of classes that is primarily defined by two latent factors — $\\gamma$ and $\\theta$, which, broadly speaking, correspond to the “content” and “style” of any given sample ‘x’. In other words, the goal of the learner is to “invert” the generative process and estimate $\\gamma$ accurately while learning invariance to $\\theta$. The paper provides theoretical evidence that with a few assumptions, representations learned by simple NNs are purely a function of $\\gamma$. Moreover, the paper provides some evidence to suggest that this is beneficial for one-shot learning of previously unseen classes using a nearest neighbor lookup. The main contribution of the paper is to define, analyze Geometry Sensitive Hashing (GSH) for NNs mainly for the test distribution, and extending this idea to previously unseen classes.\n",
            "main_review": "Strengths:\n* The paper rigorously studies an important problem that is fundamental to most of supervised learning. \n* The formulation of the problem in the paper is quite interesting and well motivated. I liked the general framework of analyzing samples from a particular class on different manifolds, with representation learning primarily being posed as one of inverting this generative process. On simple datasets, even simple models trained this way appear to reflect the GSH property to some degree. \n* On synthetic, MNIST and CIFAR the proposed method demonstrates the GSH property to varying degrees.  \n\nWeaknesses and Comments:\nAs I mentioned earlier, i thought this was an interesting theoretical paper that is explained fairly well. However, I have some reservations about some of the assumptions, terminology and experiments which I will try to outline here. \n* I find the basic generative model assumption to be quite simple — how realistic is the idea that every class lies on an separate manifold specified by $\\gamma$? In this formulation is the assumption that a data manifold (say \\mathcal{X}) is entirely defined as a cross-product space of these different manifolds? i.e., $\\mathcal{X} \\approx \\gamma_1 \\times \\gamma_2 \\times .. \\gamma_m$ ? this is making an explicit assumption that attributes are not shared across classes which is untrue (for e.g., semantic features of a dog vs cat). \n* I dont entirely follow the nuance between why GSH properties of a test distribution must be very different from the training distribution, assuming both are drawn from the same underlying data distribution? This could be further clarified so as to also better outline the contributions of this work from those of Papyan et al., 2020 & Han et al., 2021. \n* Next, The claim on unseen classes can be evaluated more thoroughly. The current setup basically argues that since networks exhibit the GSH property, a single example from an unseen class is sufficient to learn to classify that class going ahead. However, even in CIFAR10 the GSH property doesn’t seem to hold — how does the one shot learning function in this case? Presumably the performance degrades significantly. Its hard to assess the broader applicability from just synthetic datasets. For MNIST given $\\rho$ is sufficiently high, how does this compare with other few shot/one-shot techniques? \n* Throughout the paper, the current work on self supervised learning is largely overlooked. However, it strikes me as being extremely relevant to the formulation of the paper. The fact that many recent techniques are able to learn representations that perform extremely well even on ImageNet with just a linear classifier can be seen as a version of $B\\sigma(C)$ in the formulation outlined in sec 4.2. Granted they are optimizing for a different objective like contrasting and/or consistency. In this regard, its not entirely clear to me why a weighted mean squared error cost in (1) is optimized instead of more commonly used objectives for classification.\n\nA note on terminology: I found the word “manifold” is loosely defined here and quite confusing. It might help to explicitly define the manifold so as to avoid this confusion. For e.g. it is later stated that by fixing the functions ‘f’ to be a set of analytic functions, the different classes are all manifolds of shared geometry.. It’s not clear what this exactly means — does this mean the same distance metric is applicable across all the class-manifolds?What is the consequence of this? Aren’t these basically sub-manifolds of the data manifold $\\mathcal{X}$ from which they inherit the metric. Isn’t a “linear” manifold just a subspace of the Euclidean space?",
            "summary_of_the_review": "This is quite a dense, yet well written paper. The paper presents rigorous analysis of representations learned by NNs and interprets them as locality sensitive hash functions that are excellent at preserving intra class vs inter class distances accurately; followed up by extensive theoretical analysis and some empirical studies. It's not clear to me from the paper how one extends this analysis to more complex settings. I would have liked to see if GSH holds on more commonly used modern networks (resnets for e.g.) on some of the standard benchmarks to draw insights. The claims on unseen classes are a bit weak in my opinion. They could be evaluated more thoroughly other than simply on synthetic data. I appreciate the link between GSH properties and one-shot learning, but the empirical studies do not seem to back this up entirely. Finally, it seems like a lot of the recent work in self supervised learning is closely related to this work, considering it is also unsupervised and potential connections with those methods maybe useful for the general reader.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In this paper, the authors mainly investigated whether deep neural networks learn salient features which are informative for classification, while non-informative noises are eliminated. To verify this, they first generate synthetic data that drawn from delicately designed manifold distributions, then levearge DNNs to invert the manifold geometry. They elaborated theoretical analysis to show the DNNs work as a GSH-like functions to map inputs from the same class to the similar embeddings while any two inputs from different class to distinct embeddings. As one of the desirable consequences of sensitive hashing mapping, they proposed to apply it to one-shot learning.",
            "main_review": "Strengths:\n\n- The motivation is meaningful. It aims to help us get better understanding of how DNNs works, thereby aids moudlar design of DNN systems.\n- They proposed a reasonable data generating process to help in verifying their hypothesis that the DNNs work as GSH function to cluster input data. Besides, they also provided solid theoretical proof to show that.\n- On the synthetic data, they prove that GSH holds not only for known manifolds but also for unseen manifolds leading to effective one-shot learning. \n- They conducted experiments to valid their work.\n\nWeakness&major concerns:\n\n- Although the theoretical part is sound and solid, the experiments are mainly conducted on synthetic data results in the work less convincing.\n- Which loss has been used for training Myrtle-CNN on MNIST and CIFAR-10? Cross entrop loss or the proposed in eq (1)?\n- Could you please train a DNN model for synthetic data instead of the proposed MLP model and get some experiment results of it? I am quite interested in how it performs on a regular model (instead of delicately designed one) when your data already satisfied strong assumptions.\n- Is it possible to use some simple public benchmarks for one-shot learning? for instance omniglot.\n- Since for CIFAR-10 GSH doesn't hold, could you please give some application scenario? or could you please clarify the merit of this work?\n\nI would appreciate if the author can address my concerns and help me to see the impact of this work to the deep learning community.",
            "summary_of_the_review": "This work is quite interesting. Although the theoretical part is sound, the experiments are less convincing. Before my concerns are addressed, I recommend to weakly reject.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors define the notion of Geometry Sensitive Hashing (GSH) for neural networks evaluated on mixtures of manifolds, which is satisfied if the outputs of the neural network on any pair of points on the same manifold are close, and any pair of points on different manifolds are far.\n\nThey prove that this property holds under some particular conditions on the data distribution and neural network architecture.",
            "main_review": "\n**Caveats:**\n- I am not familiar with the literature in this area, so cannot determine the novelty of the results or whether there are missing citations.\n- I did not read the proofs in detail, so cannot vouch for the correctness of the mathematical results.\n\n\n\n**Review:**\n\n*Please take my review with a pinch of salt, as I am not familiar with this area of work and so am perhaps missing some important context. (That said, perhaps my comments are still valuable if you would like the paper to be more accessible to a wider audience.)*\n\n\nThis was an interesting paper to review, as I was unsure whether to give it a very low rating or a very high rating. In the end I decided to go with the low rating, on the basis that this will give the reviewers an incentive to clarify my questions and comments, after which I may increase my rating. \n\nIn brief, I'm not sure whether the results are \"obvious\"\\* and therefore uninteresting, or are very profound, providing a handle to theoretically study very difficult and important questions about fundamental properties of neural networks. [\\*I appreciate that even \"obvious\" things can be hard to prove, and it's clear to me that even if the results seem intuitive, actually proving them is non-trivial.]\n\nIn my mind, the results essentially boil down to saying: \n- very crudely: \"neural networks can do classification\"\n- more verbosely: \"neural networks can provably draw classification boundaries around distinct parts of the input space, and can learn to ignore irrelevant patterns across different classes so that new unseen classes are also well-separated, subject to assumptions on the input distribution and network architecture.\"\n\nI'm not quite sure why the authors do not provide a more layman-friendly explanation of their results. As an example, being a Locality Sensitive Hash (LSH) basically just means that you are a good classifier, in that the buckets are the discrete classifier outputs. But this isn't stated in the paper, which makes things harder to understand. \n\nA few other comments in no particular order:\n- I think the paper would benefit from having a candidate explanation of the assumptions that are being made on the data generating process, how this may differ from real-world data distributions, and -- importantly -- why it is reasonable to expect that the results of the paper would stem from these assumptions. E.g., in the linear case, it is essentially assumed that each manifold exhibits exactly the same structure, so from my layman perspective it seems kind of clear that the network would learn to be invariant to this intra-class structure, and therefore you would get one-shot learning (because one example is enough to get the representative of the class in the embedding space). \n- Why is the title of the paper about LSH, when the results are all about GSH? \n- The paper studies a very particular choice of architecture. What would happen with different architectures? \n- I believe the results all assume access to the population distributions (i.e. unlimited data). How might things change in the finite sample case?\n- Would these results be straightforward if you assumed arbitrary function approximator neural networks rather than the particular choice of architecture? If so, aren't these results more about the particular architecture being studied, rather than neural networks in generality? (Not that this would be a huge problem, since proving anything for any neural network is great. But this should be made clear so that readers do not misunderstand the extent of the results.)\n\n\n\n\n**Other random comments:**\n\nAbstract: \n- I was a little confused by the statement: \"Each input of a class is produced using two latent vectors\", should it not be \"output\" since these are the things being generated?\n- Please define the acronym LSH before using it the first time.\n\n\n\nPage 3: \n- Start of Section 2. I was a little confused a few times whether the manifolds are discrete objects indexed by discrete values of \\gamma, or whether they are supposed to be sub-manifolds of a higher dimensional manifold, indexed by a continuous variable \\gamma. My understanding is that it is the former, and so the fact that the individual realisations of \\gamma take value in a continuous space doesn't really matter -- they may as well be discrete. Is that correct, or have I overlooked something? Could you perhaps rephrase things to clarify either way?  [Edit: On further thinking, I suppose that if one makes assumptions about f, then assuming some geometry on \\gamma does bring something non-trivial. Perhaps you could clarify that? And my initial confusion about whether the manifolds are discrete or continuously varying still stands.] \n\n\nPage 5:\n- dim(A) = mxT, dim(B ) = TxD. Could you say what T is here? In particular, is T < m or T>= m? In the former case, it acts as a bottleneck. But in the latter case it doesn't do anything, so WLOG you could just have a single matrix here, no need for two. I am a bit confused why this is introduced, could you clarify this in the text for other readers?\n\n\n\n",
            "summary_of_the_review": "Interesting paper to review, but unsure whether it is proving kind-of-obvious results in an over-formalised setup, or a really great paper that provides a handle on studying hard and very important problems. \n\n[Edit: raised score to marginally below after author response]",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}