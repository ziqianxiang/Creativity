{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This work is an extension of the dense retrieval model ANCE. Specially, this work tries to further improve ANCE on domain shift. By coupling standard domain adaptation techniques, this work shows improved performance over baseline models on zero-shot setup. ",
            "main_review": "The idea of this work is straightforward, combining domain adaptation loss with standard ANCE training. The problem setup is reasonable, the idea is sound but the overall contribution is not that significant, in my option. To propose a general domain-invarinat dense retrieval model, I think the author should further test the proposed framework over DPR for generalization, especially as the author already state that a DPR model is trained for the experiments. Some other domain adaptation frameworks are also mentioned in the work with worse results, but not in details. As the major contribution of this work is on domain-invariant, I think the details and analysis on this part should not be omitted. I also do not understand the momentum setup clearly, why momentum setup is necessary instead of random sampling? the assumption to make source and target 1:1 in momentum seems also quite strict. ",
            "summary_of_the_review": "Overall, the work is targeting on a reasonable task and propose a reasonable framework. But the overall contribution may be not quite significant.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Improving generalizability for dense retrieval is an important direction. This paper focuses on learning domain invariant representation for dense retrieval models.  In particular, it focuses on the zero-shot setting where on the source domain there’re plenty of supervision data while no training data on the target domain. \n\nThey propose a Momentum Adversarial Domain Invariant Representations method (MoDIR) to co-train the dense retrieval (DR) model and the domain classifier so as to enable the DR to learn domain-invariant representations. The domain classifier is trained to discriminate between source and target embeddings and the DR needs to fool the classifier. Meanwhile a momentum queue is used to stabilize the training.",
            "main_review": "This paper is well motivated and gives a set of interesting analysis, such as the t-SNE for reranker and DE representations; learned representation for source-domain and target-domain queries. The momentum trick is neat and it’s great to see it works as the key to successfully train the domain classifier. \n\nOne major concern is that the setting in this paper doesn't compare to other models (e.g. GenQ) that only don't use relevance labels. In particular, the GenQ (question generation) model generates synthetic (Q,D) pairs on the target domain and doesn’t require relevance labels. In fact, this paper not only uses target-domain corpus, but also use domain target-query (more target-domain data than GenQ). As such, it’s actually a fair comparison to compare the proposed model with GenQ. Some important questions here are:\n- How much gain MoDIR achieved would still hold after combining with the GenQ method? \n- What is the difference between representations learned by MoDIR and GenQ?\n\nSome more questions regarding the experimental section:\n- Why is Global-Domain-Acc’s domain classifier always tested on unseen data?\n- Is it necessary to consider both query and document in the queue?\n- MoDIR introduces the most gains on Touche while it hurts the performance on SciFact/NQ. \n  - Is there any theory for decreased performance on these datasets? \n  - Why does it work the best on Touche? \nMore analysis on how the representation distribution/accuracy are correlated with performance would be more interesting and convincing. For example, what is a reasonable classifier accuracy (at the end of the training) that would lead to good DR performance?\n",
            "summary_of_the_review": "The paper is well motivated and learning domain-invariant representation is important. That said, it's lacking some important comparisons with other models such as GenQ to fully understand the model's performance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper proposes a momentum method in Dense Retrieval (DR) training process to learn domain invariant \nrepresentations. More specifically, the authors introduce an adversarial learning game between an auxiliary \ndomain classifier (as a Discriminator) and a DR encoder (as a Generator). While the Discriminator tries to \ndiscriminate Source or Target domain of inputs, the DR encoder minimizes the confusion loss to expect the \nDiscriminator confuse and gives random probability for any data points. To ensure stable and efficient of the \nadversarial learning, the author proposes a momentum queue of embedding saved from previous iterations \n(i.e., 1k iterations) to train the Discriminator",
            "main_review": "The strengths of this paper: \n* The experiments are comprehensive  \n\nThe main weaknesses of this paper are in two folds. Below are details comments: \n\n* (A) Although the authors presents an interesting idea, the novelty is limited. \nAs mentioned by the authors in Section 5, using adversarial learning is a \npopular technique in domain adaptation and zero-shot learning. The new technique of this work is momentum \nlearning; however, the motivation is not well described. For example, in Section 2.2, why there is a trade-off \nbetween efficiency and robustness? Is that correct that “unstable estimation of domain boundary” is because of\nthe small batch size? Does simply increasing batch size help? More importantly, the current results in \nsections 4.2, 4.3 do not show the contribution of the momentum learning to the final performance. \n\n* (B) The performance gains are not impressive, even using much more data than the baseline (ANCE), which do \nnot support the authors’ claim of the significant improvement. There are also some unclear results which need \nmore discussion. \n** (B1) In Table 1, the highest relative gain is 10.9%, however, it is because the absolute score of ANCE is \nrelatively low (i.e., 0.284). With the high absolute score of the baseline, the improvements are not significant \n(e.g., 0.5% on the Quora dataset). \n** (B2) In Table 1, there are several datasets that proposed method achieves much lower performance than BM25 \n(e.g., Touche’, DBPedia, NFCorpus, BioASQ). The author should have a discussion about other baselines (BM25, \nDPR-NQ/MARCO) instead of just listing their results.   \n** (B3) In Table 2, without Momentum (without the buffer $Q$), why does changing Momentum Step $N$ still \naffect the performance? \n** (B4) Can the authors provide a discussion of why increasing $N$ does not improve the performance as in TREC-\nCOVID? It would be better if the authors can provide the analytical experiments on (one or two) more datasets to see \nthe common pattern? \n** (B5) In Section 4.3, if just using a linear layer as a domain classifier $f$, why does the Local-Domain-Acc take \nlong training to converge (w/o Mom setting)? \n** (B6) If Local-Domain-Acc still converges to Global-Domain-Acc without Momentum, then why still need \nmomentum query, which costs much more computation.  \n** (B7) Moreover, as shown in Figures 3a, 3b, the Global-Domain-Acc diverges from Local-Domain-Acc in the latter\npart of training, which indicates that the domain classifier $f$ to be more inaccurate then why it still help?\n\nOther concerns:    \n* (C1) Why constructing Q requires q-d pairs $x^t$ from the target domain. Is it still a zero-shot setting?\n* (C2) Why using a Linear Layer as Domain Classifier is proper? As mentioned/visualized in Fig. 1, the original\nDR produces separate clusters of Source/Target domains, therefore, it is might be suitable to use a \nsimple classifier. However, when Source/Target domains become more intermingling, why low capacity\nDiscriminator is good? Comparing to GAN, the Discriminator is usually required to have high capacity \nto distinguish real/fake distribution. \n* (C3) How to sample $e$ from buffer $Q$ to train Discriminator in Eq. (6) and Eq. (10)?",
            "summary_of_the_review": "Overall, although I feel the work has some interesting ideas, I suggest a major revision as there are quite a few concerns given the current results.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper applies the Domain Adversarial Training (DAT) idea (Ganin & Lempitsky, 2015) to zero-shot dense retrieval (ZeroDR). In particular, they enforce the query and passage embeddings to be domain invariant by confusing a domain classifier in a GAN-style training. They find that the domain classifier needs more training than the encoders, as training the classifier with only samples from the current encoder-training batch is not sufficient. On the other hand, training it using a large number of samples is more computationally expensive, so they propose a momentum method where they cache the (detached) embeddings from the past n batches to be used for training the domain classifier.\n\nWhen evaluated on the BEIR benchmark, a collection of retrieval tasks for ZeroDR, their method generally improves over the baseline ANCE approach without domain adversarial training, yet rarely by large margins. For datasets where a simple BM25 significantly outperforms ANCE, the proposed method remains largely behind BM25 and doesn't make a qualitative difference.",
            "main_review": "**Strengths:**\n\n- The method is clearly presented, and the momentum method is a simple and clever trick for saving computation.\n\n- They adapted the DAT approach for dense retrieval, showing improvement over the baseline.\n\n- The detailed experiments and analyses are very helpful.\n\n**Weaknesses:**\n\n- The DAT approach is not new, and their main innovation, the momentum trick, is relatively straightforward to come up with. \n\n- While their method improves over the ANCE baseline on most datasets, the margin is usually moderate. For datasets to which ANCE fails to transfer, such as those beaten by BM25 by wide margins, the proposed method does not make a qualitative difference. Also, it would be nice to see the proposed method compared with other ZeroDR approaches in the literature.\n\n- While DAT does not require labeled data in the target domain, it does require unlabeled text for training, and a separate model needs to be trained for every target domain. This makes it relatively expensive to adapt to new domains.\n\n**Questions:**\n\nIn Table 2, what does \"momentum step = 1k\" for \"without momentum\" mean? Does it mean that the domain classifier is trained on 1k steps of samples, but their embeddings are recomputed using the current encoder?\nIf this is the case, why is it doing slightly worse than using momentum? Wouldn't this re-computation scheme more accurate? Or does this momentum trick provide some implicit regularization that not only saves computation but also improves model training?\n\nAssuming my understanding above is correct (please correct me if I'm wrong), I have some questions about the ablation studies.\nRegarding the momentum trick, I think there're two parts in it: i) The domain classifier needs more training than the encoder (which is not uncommon in DAT), which is why using momentum step = 1 doesn't work. ii) Re-encoding many batches of samples at each training step for training the domain classifier is expensive, resulting in the momentum or \"caching\" trick.\n\nTherefore, the ablations in Section 4.2 confound the impacts of these two factors by comparing \"momentum with n=1000\" and \"no momentum with n=1\". It would be great if separate ablations studies are performed to isolate the two. Using the same queue length for with and without \"caching\" to compare their accuracy and training speed would make be a fairer assessment of the impact of the momentum trick. On the other hand, if using \"caching\" not only saves computation but also outperforms the model without caching under the same queue length, it would be a very interesting phenomenon that's worth digging in.",
            "summary_of_the_review": "This paper applies the established Domain Adversarial Training technique to the Dense Retrieval task and proposes a momentum trick to save computation. The results show that it improves over the ANCE baseline on most datasets, but usually only by moderate margins. The method is sound but nothing too novel, and the experiment results show numerical improvements but the gains are less than exiting.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}