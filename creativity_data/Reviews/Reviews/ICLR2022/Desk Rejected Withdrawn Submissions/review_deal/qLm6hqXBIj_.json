{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper concentrates on the problem of generalising to out-of-distribution data at test time. The authors propose Transfer Risk Minimisation (TRM), a bi-level optimisation objective that involves learning a representation that enables robust transfer of per-domain predictors to other domains with little loss in empirical risk. Some theoretical analysis of the method is given, in the case where data is generated by Gaussian data, and a comparison is made with related approaches. Experimental results are provided on some domain generalisation benchmarks, where TRM typically outperforms other approaches.",
            "main_review": "Strengths\n=========\n* The paper is well-written and generally easy to read.\n* The proposed method achieves relatively good performance compared to previous approaches, when evaluated on synthetic data and real data.\n\nWeaknesses\n==========\n* The significance of Theorem 1 is not well explained. From what I can tell, the main take-away from this Theorem is that one can design a classifier that achieves low IRMv1 loss, high TRM loss, and behaves similarly to ERM in the target domain. Surely this means we should prefer IRMv1 over TRM?\n* There is little explanation for why this method works. Why should minimising transfer risk lead to better DG performance compared to ERM or IRMv1? What assumptions are required for this to be true? Is it possible to characterise which in situations this not true?\n\nMinor Details/Questions\n=======================\n* The paper frequently uses expected risk rather than empirical risk. This is somewhat confusing, since these are not the same thing.\n* How does using the stop gradient operation change the optimisation problem that is being solved? Does this not essentially change the objective function being optimised?",
            "summary_of_the_review": "The paper is well-written and the performance of the method is pretty good, but the explanation for why/when it works is insufficient.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper proposes to replace ERM with a penalty on the worst-case transfer risk of a predictor for one environment onto the convex hull of the other environments. They then give a method for efficiently solving this objective (shown to be similar to gradient matching), and present empirical results on two domain generalization benchmarks and some domain transfer tasks.",
            "main_review": "This paper presents a nice \"transfer risk\" objective based on convex hulls of training domains, and shows that this objective can be efficiently implemented by demonstrating that it is equivalent to a gradient matching penalty. However, I see several major issues with this submission. \n\nFirst of all, Theorem 1 does not even come close to saying what the paper claims it says, not to mention the fact that the proof itself is almost identical to that of Rosenfeld et al. The proof technique for Rosenfeld et al. fundamentally provides a *negative* result, and it cannot be applied in a positive sense as it is claimed here. \n\nThe authors present the theorem with the following explanation: \"Below we show that TRM can avoid the failure mode of IRM\".\n\nThe correct interpretation of Theorem 1 in this work is \"there exists a set of training environments and a predictor which has low IRMv1 loss and high transfer loss on these environments, such that the predictor performs like ERM at test time.\"  The authors are suggesting that by showing that there exists a predictor which \"tricks\" IRM but does not trick the transfer loss, they have shown that there does not exist a predictor which \"tricks\" the transfer loss.  **This is clearly false.** So, it most definitely does not provide justification for the proposed algorithm (in fact, I'm almost certain that the relevant negative result from Rosenfeld et al. could be applied to this objective as well).\n\nNext, the reported empirical results are not up-to-date. One of the primary findings of [1] was that a large portion of existing work on OOD generalization was not giving ERM a fair shake---evaluators often tune the hyperparameters post-hoc on the test data, and it is difficult to tell when they have made a best-faith effort to implement ERM as well as possible. In particular, [1] found that ERM with larger networks and stronger regularization significantly outperforms previously reported SOTA. \n\nIndeed, this paper reports results for the OfficeHome and PACS datasets which are *significantly* lower than the results reported in [1], for all algorithms. To be fairly compared, the algorithm should be re-evaluated against the current SOTA. I note that even if we take the reported results at face value, **the confidence intervals for the reported accuracies mostly overlap,** so there is not much indication that this method works better.\n\nAs an aside, I somewhat question the idea that the \"correct\" notion of transfer is to the convex hull of the remaining environments. This is very specific to the idea of group shift, but this paper appears to be arguing the merit of this model more generally. There is evidence that such a model does not suffice to model out-of-distribution risk [2, 3]. I appreciate that it makes the algorithm tractable but I would like to see some sort of explanation/analysis of the effect or downsides of using linear interpolation when modeling distribution shift for non-linear distributions.\n\n[1] In Search of Lost Domain Generalization. Ishaan Gulrajani and David Lopez-Paz, 2020.\n\n[2] An Online Learning Approach to Interpolation and Extrapolation in Domain Generalization. Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski, 2020.\n\n[3]  Generalizing to unseen domains via distribution matching. Isabela Albuquerque, João Monteiro, Mohammad Darvishi, Tiago H. Falk, Ioannis Mitliagkas, 2019.\n",
            "summary_of_the_review": "The lone technical result regarding the objective itself is almost copied from another work and does not at all give the intuitive result that the authors claim it implies. Further, the experimental results are very clearly not up-to-date and need to be re-evaluated properly.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a robustness criterion for out-of-distribution (OOD) generalization that measures the transfer risk of the optimal predictor trained on one environment to another. The proposed criterion leads to a TRM objective that can be optimized with implicit differentiation and demonstrates improved OOD robustness on various benchmarks.",
            "main_review": "Strengths\n* This paper is generally very well-written and easy to follow. The derivation of the proposed criterion and algorithm is very clear.\n* A practical algorithm for directly optimizing the proposed transfer risk is derived, which interestingly turns out to be a gradient matching objective. The proposed algorithm leads to better OOD performance over baselines on various benchmarks.\n\n\nWeakness\n* The proposed TRM criterion needs further (both theoretical and empirical) justifications, as detailed follow:\n    * The optimal predictor $w$ on one environment is not necessarily unique, but seems to be assumed unique in the paper. It needs to be clarified whether the uniqueness assumption is made, or if not, how to address the non-unique case.  \n    * The proposed transfer risk measures the transferability of the predictor, but for OOD setup, **both** the predictor $w$ and the feature extractor $\\psi$ needs to be transfered, are there any assumptions or justifications that support this fact?\n    * Based on the previous concern, the claim that “TRM is a better criterion than IRM for assessing OOD generalization” needs more justifications. Theorem 1 is a bit weak in the sense that it only shows that near-optimal IRM loss does not imply low TRM loss which illustrates the weakness of IRM, but it is not clear how well the TRM criterion serves an indicator for OOD generalization. Empirically, though Fig. 1 is interesting (and I like it), it would be great to have more extensive experiments that support the claim. For example, it could be interesting to empirically study the correlation between IRM/TRM criterions by having a scatter plot that shows OOD accuracy vs IRM/TRM losses for differently trained models.\n* The gradient matching term in the TRM loss seems to be computationally expensive due to HVPs, but leads to a rather marginal improvement from Table 1&2. It would be great to include a discussion of the *actual* computational overhead of the proposed algorithm (similar to Table 6, probably add another dataset) in the main paper. \n* The experimental setups on real-world datasets (i.e., PACS and Office-Home) are different from those used in common benchmark (in particular DomainBed):\n    * The smaller ResNet-18 model is used instead of ResNet-50, and only 2 datasets from DomainBed are selected. Is this because of the increased computational cost of TRM?\n    * Some hyperparameters like learning rate and momentum are pre-fixed instead of tuned as with DomainBed, what’s the reason for doing that?\n\n\nAdditional questions & comments \n* The text font seems to be inconsistent with ICLR format, which needs to be adjusted in the revised version.\n* The Talyer expansion of $H^{-1}$ does not generally converge unless an extra assumption is made on the Hessian norm. Is there any such assumption in the paper? The discussion needs to be included.\n",
            "summary_of_the_review": "Overall, the paper is well-written and interesting to read. Though the proposed algorithm leads to improved OOD robustness than baselines, my main concerns are 1) insufficient justification of the proposed TRM criterion; 2) the computational overhead of the proposed algorithm; 3) the smaller-scale experimental setups than common benchmarks. Thus I will recommend a “weak reject” for the paper, and will consider raising my score if my concerns are well addressed. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Authors tackle the domain generalization setting where a set of training domains, or distributions over the input space, are available during training, but new ones are expected at testing time. The authors then propose an approach aiming to train an encoder yielding representations that are domain-invariant. That is, the encoder projects data onto a space where the underlying domain from which the data was observed can no longer be determined, while class labels can still be predicted to good accuracy. The proposal relies on the following intuition: at the feature level, predictors trained on one particular domain should achieve low risk on another. Such intuition is then used to define a training strategy to train encoders satisfying such property. Specifically, a set of feature-level predictors is maintained, and the worst-case cross-domain risk is used as a learning signal to the encoder. A standard ERM-like loss is also used to ensure learned representations are useful for the underlying task.",
            "main_review": "Strengths:\n\n+ The approach is novel and well-justified.\n\n+ An efficient algorithm implementing the proposal is proposed and validated empirically.\n\n+ The evaluation is broad and seems to have been well executed since the authors used in-domain validation data for performing cross-validation.  I also appreciated the analysis reported in Section 5.1.2 relating risk with \"level of domain shift\". \n\nWeaknesses/Suggestions/Questions:\n\n- The setting under consideration is not very well defined. Authors never formally defined what they mean by an environment, and what changes between training and testing domains are supported. In particular, what is the set of test domains that are expected to yield low risk given models trained under the proposal?\n\n- Further stressing on the comment above on the lack of details in terms of the setting under consideration, there's at least one (strong) assumption that's not explicitly discussed in the text. It has been shown (c.f. http://proceedings.mlr.press/v97/zhao19a.html) that invariance-inducing approaches can only succeed if domains only shift in terms of data marginal distributions; that is, data conditional label distributions P(y|x) are fixed across domains. In other words, invariance inducing schemes require that data is such that observing x suffices in order to determine y, regardless of the underlying domain. That assumption should be made explicitly in the text.\n\n- The evaluation is broad and seems to have been well executed, but lack is supporting the central claim in the paper: TRM yields encoders inducing domain invariance. I suggest authors empirically verify that invariance is indeed achieved at the feature level. A suggested experiment would be to estimate the h-divergence between pairs of training domains using domain classifiers (using the same model class as \\omega). A low accuracy would be an indication of domain invariance. Please compare those results with other methods. If TRM does not result in more invariant, then we would need to understand what it is that it does to give models that generalize better.\n\n- Do authors have an idea as to how the number of training domains impacts the performance of models trained under TRM? Would the model benefit from having more domains somehow? If so, how? To my understanding of Algorithm 1, it seems that the training time per iteration does not scale with the number of training domains. Would you kindly confirm whether that's indeed the case?\n\nMinor comments:\n\n- Some equations are not numbered.\n\n- If possible, please expand Table 6 on Appendix C.3 and include time comparisons for other datasets/models. It would be interesting to get an idea of how practical the proposal is. I would recommend reporting at least a ResNet-50 on PACS.",
            "summary_of_the_review": "The proposal is interesting and works well on some well-known benchmarks, but the presentation needs improvements prior to publication. In particular, the setting under consideration needs to be defined as well as all underlying assumptions. The evaluation also needs improvements so as to support important claims. It is now unclear whether encoders trained under TRM indeed induce invariance on representations.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}