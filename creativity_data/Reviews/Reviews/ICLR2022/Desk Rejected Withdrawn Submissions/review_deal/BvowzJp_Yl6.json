{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a decentralized learning approach, called Homogeneous Learning, which relies on a combination of a local model and a reinforcement learning component that is shared accross the nodes, and selects the optimal node to use for training on each round. The authors perform experiments on the MNIST dataset and a decentralized setup of 10 nodes and demonstrate improvements compared to standalone training and random selection of nodes used for training.",
            "main_review": "NOTE: Following the authors' response and their improved version, several of the comments below have been addressed and therefore I have revised my score upwards.\n\nThe paper addresses the increasingly interesting problem of decentralized learning and it comes up with an interesting scheme that uses reinforcement learning on top of each node's and other nodes' model representations with the goal of learning to use the best possible node from the network in each round of training, where best possible is determined by a trade-off between highest reward (in terms of increasing validation accuracy) and lowest communication post. The authors provide some evidence that the proposed scheme is effective in an image classification scenario.\n\nDespite the merits of the paper, I am afraid that at its current state it suffers from some major issues in terms of methodology: in particular, the authors do not properly explain or analyze a number of assumptions or limitations in their approach. These include among others: a) The fact that the goal accuracy is known at training time. This implies a very good understanding of the global learning task, which to my understanding is not possible in a realistic decentralized scenario where nodes have only partial knowledge of the dataset. b) The fact that training takes place in a synchronized way, i.e. all nodes communicate regularly and in a synchronous way, which again is not necesarily the case in a decentralized setting, where nodes may go online and offline regularly. c) There is no discussion on the role of the memory-based replay of rewards in the training process. To my understanding, depending on the phase of training and the evolution of underlying models, replaying rewards by memory may actually not correspond to the actual current state of local models and might result in suboptimal decisions. The authors do not touch this issue. d) The method has some severe scalability issues since it requires all node models to be shared across the network in order for the RL scheme to work. This is clearly impractical in settings with too many nodes and/or too large models, since it would create a really big communication overhead. The authors do not discuss this.\n\nA second major issue is the limited evaluation of the proposed scheme. First, it focuses on a specific learning task and a specific dataset (which is relatively \"easy\"). Second, it compares with very simple baselines (centralized learning, standalone learning, ranodm node selection). Even a simple heuristic for node selection would probably improve performance but we do not know by how much.  \n\nMoreover, there are a number of other issues that would require further elaboration:\n\n- The related work section is quite limited. There is only a superficial listing of somewhat related works, but not any organization or systematic discussion with respect to their characteristics or methodology, and the relation to what the paper proposes is presented at the end of the section in a generic way without any concrete references.\n- The authors do not explain whether the concept of data heterogeneity is their own definition or whether they adopt it from the literature.\n- There is no justification of the decision to consider N equal to the number of nodes in the network during the PCA dimensionality reduction step used at the Reinforcement Learning phase.\n",
            "summary_of_the_review": "While the paper addresses a very interesting problem and proposes an interesting and potentially effective approach to tackle it, it is still in a premature state and not ready for acceptance in a venue such as ICLR. The authors should work more on better positioning their work in relation to existing decentralized learning schemes, explain better the assumptions and limitations of their approach and, importantly, considerably extend the experimental section of their work.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a self-attention decentralized deep learning model called Homogeneous Learning (HL) to solve the problem of non-IID data learning in decentralized Federated Learning. HL leverages a shared communication policy for adaptive model sharing among separated nodes.\nIn more details HL adaptively selects the next local node using shared DQN-based policy to be trained with a shared global ML task model. As a result HL reduces the total training rounds by 50.8% and the communication loss between local nodes by 74.6%.\n",
            "main_review": "Strengths: \nThis paper proposes the FL algorithm to solve practical problems of the data heterogeneity and device heterogeneity in Federated Learning \n\nWeakness: \nThe description of ML task model and RL model is ambiguous and sometimes makes it difficult for readers to understand your paper correctly.\nWhether the proposed algorithm contributes to the improvements of the global ML task model is ambiguous.  The training node selection is based on the reward function which considers the validation accuracy. Putting aside the communication loss the optimal policy selects the node which has better validation performance based on current trained model.\nThe precise communication costs design are difficult, but the model sharing costs are not enough considered and described to evaluate its contributions.",
            "summary_of_the_review": "To tackle the practical and important problems of the data heterogeneity and device heterogeneity in Federated Learning is interesting. For training node selection using DQN is also interesting. But there are many ambiguous points about design of DQN and the comparison.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes an algorithm for decentralized learning called homogeneous learning to address the non-iid data issue across different nodes. The algorithm applies reinforcement learning for sequential node selection in the training procedure. In particular, each node has two components. The first is the local foundation model for the ML task. The second is a reinforcement learning agent used to select the nodes to perform training next, based on the current nodes' inner state and other nodes' states. The paper evaluates the algorithm with an image classification task on the MNIST dataset. The results show that the proposed algorithm can achieve the training goal with fewer training rounds and less communication cost compared to baselines. ",
            "main_review": "The paper proposes a new algorithm called homogeneous learning (HL) for improving the efficiency of training with non-iid data across nodes in decentralized learning. HL assumes that each node has two models, the local foundation model for a specific ML task and a reinforcement learning model for selecting the nodes to perform training next. The paper implements the HL algorithm on an image classification task on the MNIST dataset and compares it with a few baselines. The results show that the newly proposed HL algorithm can achieve the training goal with fewer rounds and reduce the communication cost between nodes.\n\nThough the idea of adopting an RL agent for node selection sounds interesting, the proposed algorithm needs more theoretical or intuitive illustration and justification. The proposed model is doing training sequentially across nodes until the training goal is achieved, which does not well support the improved efficiency. Besides, the concept of self-attention is not clearly presented and justified in the proposed algorithm and can be misleading. Overall, the proposed algorithm lacks many necessary details to provide a complete and sound technical solution for decentralized learning. \n\nThe paper implements the HL algorithm to train an image classification model on MNIST data, which takes most of the contents in the paper. The paper compared HL with three elementary baselines and showed improved results on both the number of training rounds needed and   However, more advanced baselines would be more convincing. Moreover, given that the MNIST dataset is relatively small, and the number of classes (thus the number of nodes) is small, it is not under doubt how the algorithm can generalize to more complicated training tasks, such as training on the ImageNet dataset. ",
            "summary_of_the_review": "Overall, the paper lacks many necessary technical details and needs more comprehensive experiments to be convincing. The current submission does not meet the standard for acceptance. Therefore, I recommend reject on this paper. \n\nI highly appreciate the authors' efforts in the rebuttal. Though the authors' response clarifies some of the points, the technical details need major rethinking and revision. I believe the paper can be further improved and better submitted to another venue. Thus I will keep my rating. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}