{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper aims to address the lack of expressiveness, predictability, and interpretability in neural temporal point processes. To do so, they propose a simple neural model for expressive intensity function modeling. They design new sampling techniques which involve error metric-driven adaptive ﬁne-tuning of the hyperparameters. Finally, the authors addressed interpretability by learning the dependency among events and types. Experiments are performed on both synthetic datasets and public benchmarks.\n",
            "main_review": "**Since the paper did not change much compared to a previous version I have reviewed, I have just copied my previous review here**.\n\nOverall, I found the paper poorly written (notations, etc). Also, the authors make wrong/strong claims about existing NTTP models. The author claim that NTTP models lack expressiveness, predictability, and interpretability. There are multiple NTTP models that are both expressive and interpretable with good predictive accuracy. See [1]. Adjustments to the FullyNN method have already been proposed in the TPP literature. See [2] for example. This is not discussed in the paper.\n\n[1] Neural Temporal Point Processes: A Review\n\n[2] Neural Temporal Point Processes Modelling Electronic Health Records\n\nOther comments:\n\nThe NLL columns are identical. Please use a better presentation of the results.\nThere are multiple typos in the paper. For example, \"statistical frequency can calculated\".\nExpression (16) essentially evaluates model calibration. To properly evaluate prediction intervals, you should use scoring rules/functions (e.g. interval scores)\n\n----- \nAdditional comments (I/II):\n\nI have read all the reviews, and I have also read the paper a second time. Unfortunately, I am sorry I still suggest a rejection.\n\nIn its current form, I think the paper is not rigorous enough, makes strong claims, and writing needs significant improvements. Some additional comments:\n\nThe authors say \"In addition, it is inconvenient to get the intensity function, which fails to dig out more information such as inﬂuence\". This is not true for LogNormix. In fact, as explained in [1] (Appendix A), we can easily compute the intensity as a ratio of the density and the survival functions.\n\nGiven all the neural-based intensity parametrizations that have been proposed in the literature, expression (10) is not really novel. It is essentially an RNN embedding followed by a softplus.\n\nConcerning prediction intervals, the notations used are not standard. Furthermore, you have only measured calibration. To properly evaluate prediction intervals, you also need to measure sharpness (interval width). Reporting interval scores is also important to properly measure accuracy (see [2]).\n\nThe authors say \"However, the median prediction has been proven as a biased prediction such as Poisson process\". What does that mean? If your loss function is the mean absolute error, reporting the median is the optimal strategy.\n\nThe authors say \"The proof is given in Appendix E.\". There is not proof in Appendix E. Furthermore, the explanations given in (29) and (30) are not very clear.\n\nYou chose to perform your experiments using three real-world datasets (ATM, SO and NYSE). I am wondering why you did not consider the other six datasets that have been used in [1] to compare FullyNN, RMTPP and LogNormix. This is relevant since you are considering the three models in your experiments. Furthermore, note that the SO dataset is not ideal if you want to use flexible TPP models (see results in Figure 3 in [1]).\n\nFinally, having recently read a bunch of papers on neural TPP modelling, I find the contribution of this paper very limited when compared to recent neural TPP papers.\n\nReferences [1] Shchur, Oleksandr, Marin Biloš, and Stephan Günnemann. 2019. “Intensity-Free Learning of Temporal Point Processes.” arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1909.12127.\n\n[2]Brehmer, Jonas, and Tilmann Gneiting. 2020. “Scoring Interval Forecasts: Equal-Tailed, Shortest, and Modal Interval.” arXiv [math.ST]. arXiv. http://arxiv.org/abs/2007.05709.\n\n------\nAdditional comments (II/II):\n\n- The authors say \"But here we instead use the full parameterization on intensity which is new to our best knowledge\". However, there are dozens of papers on parametrizing the intensity function.\n\nFurthermore, while ensuring the non-termination of the process can be important in some cases, I do not think this can be considered as a major contribution.\n\n- If I understand correctly, searching for a specific u is equivalent to search for a quantile of the distribution. In that case, Section 4 is not clear. Related to this question, what do you mean by \"People may prefer a certain next event prediction instead of an uncertain one like expectation\"?\n\n- Properly measuring the accuracy of prediction intervals is important. I am not asking to derive a theory on prediction intervals for TPPs. I am just asking to compute multiple metrics for prediction intervals. Coverage is not enough since the (unconditional) empirical distribution is already well-calibrated (but not sharp).\n\nThe interval score is one way to measure the accuracy of prediction intervals. For more details, see expression (9), page 136 in Gneiting, Tilmann, and Matthias Katzfuss. \"Probabilistic forecasting.\" Annual Review of Statistics and Its Application 1 (2014): 125-151.\n\n\n- I respectfully disagree with the authors. The fact that (i) there are no theoretical contributions and (ii) the methodological contributions are limited (compared to existing neural TPP methods), requires a strong experimental contribution with data diversity and well-designed experiments.",
            "summary_of_the_review": "Since the paper did not change much compared to a previous version I have reviewed, I have just copied my previous review here. I think the author should take into account comments/suggestions made by reviewers at other conferences. Otherwise, it is just a waste of time for everyone.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper attempted to compare the expressiveness of different neural point processes, and proposed a method to train neural point processes together with a method to study the influences between events. \n",
            "main_review": "Strength: the paper did a lot of analysis and experiments, and thoroughly documented their studies. \n\nWeakness: major claims are wrong or problematic; lack of awareness or understanding of existing work. \n\nThe paper claimed that existing models can not handle non-terminating process, which is clearly wrong. Surely, RMTPP \"cannot avoid a positive probability of extinction at all times\" (quote Mei and Eisner 2017), other models don't have that problem. E.g., NHP's intensities will always approach positive constants as time goes to infinity, meaning that the integral of total intensity will eventually go to infinity as well; then the cumulative probability would surely be 1---this is a theoretical result. Therefore, Figure-1 must be wrong, and all claims based on that figure are wrong. \n\nThe paper also proposed a prediction method based on inversion sampling, and argued that it is better than \"thinning algorithm\". This section has a few fatal issues: \n\n(1) They are referring to the wrong \"thinning algorithm\"; the \"thinning algorithm\" for point processes is: \"Peter A Lewis and Gerald S Shedler. Simulation of nonhomogeneous Poisson processes by thinning.\"  \n\n(2) The authors claim that \"Sometimes uncertainty prediction (i.e. sampling) is not enough for predicting. People may prefer a certain next event prediction instead of an uncertain one like expectation.\" This is unacceptably wrong. Expectation is a minimum Bayes risk decode (MBR) and it marginalizes all the uncertainties; inversion sampling method is an uncertain one that relies on a single draw---the authors try to support their claims with a remark that actually goes against them. Moreover, they fix the random number $u$ to be 0.5 or learn $u$ from data---that is just another heuristic to marginalize uncertainties, but not as principled as expectation. \n\n(3) They argued that \"the thinning method is more suitable to generate whole sequences from scratch instead of predicting next event, as it fails to get the 1-to-1 mapping between u and the next event, which needs multiple random values to sample the next event\". First, drawing one sequence needs to draw \"next event\" successively; so I don't understand why thinning algorithm is not a good fit here. Moreover, it is true that thinning algorithm \"needs multiple random values to sample the the next event\", but drawing those values is still usually much cheaper than solving root-finding problem via Newton method---that is basically why that algorithm was invented in the first place. So this remark doesn't have its ground. \n\nThe paper proposed a method to analyze learned influences between events, which is very similar to CAUSE (Zhang et al. 2020): https://arxiv.org/abs/2002.07906. \n",
            "summary_of_the_review": "As what I have discussed for its weakness, I don't think the paper is ready for publication. \n",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a new neural temporal point process (NTPP) that enjoys model expressiveness, predictability, and interpretability. The expressiveness mainly addresses the issue that the density integral (8) does not equal 1, which is not desirable for modeling the non-terminating point process. For predictability, this paper proposes a new approach to predicting the next event based on the Time Change Theorem. And for interpretability, two measures are proposed to quantify influences between two types of events and two individual events, respectively. ",
            "main_review": "The paper is overall well written and I read the paper with interest.\n\n1. For the expressiveness, I understand the problem with some existing NTPPs that density integral (8) does not equal 1. However, I do not fully understand why the proposed model (10) can solve this issue. Is it because of the use of the activation function? Other than that, I cannot see much difference between (10) and (4). Can some specific examples of (10) be provided to demonstrate the key idea to fix the issue in equation (8)?\n\n2. In Figure 1(a)-(c), although for RMTPP, NHP, and FullyNN, the integral of intensity does not equal 1, they are all very close to 1. Is this that big of a deal? At least from the synthetic data experiments, I cannot see how serious the impact is.\n\n3. The use of the Time Change Theorem to form new predictions is an interesting idea, but it is not a property specifically attached to the proposed NTPP. Rather, it is a generic way to make predictions using any point process model. I was a bit disappointed to see that the new prediction method has little advantage over the expectation-based prediction, if not worse. This makes the proposal less interesting.\n\n4. The construction of new measures for quantifying influences is interesting but rather straightforward. The insights gained from the synthetic examples and real data analyses are rather superficial. It is something nice to know, but not quite exciting.\n\nMinor point: in the definition of the conditional density function (1), and many other places, the use of $\\mathcal{H}_j$ as the event history is a bit unconventional. It is typically denoted as $\\mathcal{H}_t$. If $\\mathcal{H}_j$ is used, I think it is better to clarify why the difference.",
            "summary_of_the_review": "Overall, I enjoyed reading the paper. But the novelty level does not meet the bar.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper discusses three aspects of existing neural TPP models: expressive power, predictive tasks and interpretability. For each of the above properties, this work points out limitations of existing approaches and proposes ways to fix them.\nMore specifically:\n1. Expressive power: Several existing neural TPPs are in fact terminating point processes, which might limit their applicability. This work suggests a new non-terminating neural TPP model.\n2. Predictive tasks: This work summarizes several known results on the connection between the integrated intensity function and the CDF of the inter-event time distribution. Based on them, various ways to summarize predictions of the model are proposed.\n3. Interpretability: This paper proposes a new simple approach for inferring the influence structure between (a) different event types or (b) individual events by inspecting the conditional intensity of the TPP model under removal of events from the sequence.",
            "main_review": "### Strengths:\n- The approach for inferring the influence structure (Section 5) is model-independent, well-motivated and novel. Experimental results show its promising performance compared to the baselines.\n- The paper provides a good overview of different aspects of TPP models, such as different approaches for generating predictions (Section 4)\n- The paper addresses a relevant topic\n\n### Weaknesses:\n\n**Presentation quality & clarity**\n1. The 3 topics of the paper (Sections 3, 4, 5) are only loosely connected. In my opinion, the paper would be a lot more convincing if it put more focus on one topic – with a more thorough experimental evaluation. See \"Experimental evaluation\" below for more details.\n2. The main paper is not self-contained, and some important content is missing, e.g.:\n    - Architecture of the proposed model is only mentioned in the appendix.\n    - The procedure for computing the integrated intensity $\\Lambda^*(t)$ of the proposed model is not described. Current definition seems to imply that numerical integration is necessary, which is a serious disadvantage compared to existing models.\n3. Novel contributions are not clearly separated from known results. For example, most of Section 4.1 consists of restatements of known connections between the integrated intensity function and the CDF of the inter-event time distribution.  used, e.g., in Omi et al. 2019.\n    \n\n**Technical claims:**\n\n4. *RNN-/Transformer-based models necessarily assume that the TPP is non-terminating* (Section 3.1):\n\n    The distinction between terminating and non-terminating TPPs is irrelevant in practice, when we consider a TPP on some interval $[0, T]$.\n    Suppose we observed events $(t_1, ..., t_{i-1})$.\n    In this case, the correct way to compute the termination probability is $\\epsilon = 1 - \\bar{F} = 1 - \\int_{t_{i-1}}^T f(t | \\mathcal{H}_t) dt$.\n    \n    This means that it's irrelevant if the conditional PDF of $t_i$ integrates to 1 over $[t_{i-1}, \\infty)$ (the definition used in the paper), since the two alternatives are equivalent\n\n    - in a \"terminating\" TPP, with probability $\\epsilon$ we will generate inter-event time equal to $\\infty$, so the sequence will terminate\n    - in a \"non-terminating\" TPP, with probability $\\epsilon$ we will generate an inter-event time greater than $T - t_{i-1}$, so the sequence will terminate.\n\n    Both \"terminating\" and \"non-terminating\" TPP have a non-zero probability of terminating, but, importantly, they have a non-zero probability of generating an arbitrary number of events before $T$ (i.e., completing the sequence $(t_i, ..., t_n)$ for arbitrary $n$).\n\n    To summarize, the distinction between terminating and non-terminating TPPs, as defined in Section 3, is unimportant and is already accounted for by the log-likelihood function. I will be happy to clarify this further, if necessary.\n\n5. *The intensity for the LogNormMix model is inconvenient to evaluate* \n\n    While, technically, the CDF of the normal distribution is not an analytic function, it can be easily computed in any deep learning framework using the `erf` function. Therefore, the intensity can be evaluated rather easily. This would also enable computing the quantiles of the inter-event time distribution via root-finding, which would enable median / adaptive quantile estimation in Table 2.\n\n**Unclear motivation for certain definitions and approaches in the paper**\n\n6. *Definition of between-event influence in Section 5:*\n    - Equation 21: What is the interpretation of $\\bar{p}\\_{ii}$? In case of a self-exciting process, $\\bar{p}_{ii}$ denotes the probability of the event being exogenous. However, it's unclear how this definition translates to a neural TPP model, since $\\bar{p}\\_{ij}$ are not valid probabilities, and hence $\\bar{p}\\_{ii}$ can take arbitrary values in $(-\\infty, \\infty)$.\n    - Based on the definitions in Equations 17/21, it seems that the influence is only defined when removing the preceding event in the sequence (i.e. change in intensity at time $t\\_i$ after removing $t\\_{i-1}$. Why doesn't this include cases when an earlier event was removed? For example, if we have a sequence with marks (1, 2, 3, 1, 2, 3, 1, 2, 3), how will we estimate the effect of mark 2 on mark 1, given that they never occur in this order?\n\n7. *Motivation for picking the predicting quantile $u$ that minimizes the RMSE loss:*\n\n    If we only care about minimizing the RMSE, why do we even need a point process model? Wouldn't it make more sense to define a model that produces a point estimate of the next inter-event time and train it by directly minimizing the RMSE loss?\n\n\n**Experimental evaluation:**\n\n8. *The choice of datasets and baselines for structure learning:*\n\n    The results would look more convincing if a comparison to more recent baselines for structure learning were made (CAUSE [Zhang et al., ICML 2020](https://arxiv.org/abs/2002.07906)). CAUSE, similar to the approach proposed in the paper, infers the structure by analyzing an RNN-based NTPP. Also, it's unclear why the LSTM model by [Xiao et al. 2017] is referred to as \"attention model\", instead of considering more recent transformer-based neural TPPs such as  [Zhang et al., ICML 2020](https://arxiv.org/abs/1907.07561) or [Sharma et al., KDD 2021](https://arxiv.org/abs/2008.11308).\n\n### Minor comments:\n- Typically $\\Lambda^*(t)$ denotes the total integrated intensity over $[0, t]$, while in this paper it denotes the integrated intensity over $[t_j, t]$. Calling it the integrated hazard function might be more appropriate (see Omi et al. 2019).\n- Meaning of different terms in Table 1 is unclear. For example, what is the difference between \"easy\" and \"convenient\"? P-NTPP and I-NTPP are also not defined in the paper until this point.\n- Remark in Section 4: Thinning algorithm can actually be used to sample a single event conditioned on the history from an NTPP by simply taking the first accepted event. However, this requires an upper bound on the intensity, which is unavailable for the proposed model.\n- Inconsistent notation $\\mathcal{H}_{t_j}$ in Equation 21",
            "summary_of_the_review": "The paper contains some interesting ideas, such as the proposed approach for inferring the influence structure between events. However, a more thorough discussion and evaluation of these ideas would be necessary to convincingly demonstrate their utility. Also, fixing the not fully supported claims and restructuring some parts of the paper would improve the overall clarity.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}