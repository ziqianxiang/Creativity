{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper compares several standard machine learning algorithms on the task of classifying whether an individual has COVID-19, based on 7 features: gender, age, cough, fever, sore throat, shortness of breath, headache. The paper finds similar results across all algorithms, with around 89% accuracy and 87% F1-score.",
            "main_review": "Overall, I do not recommend this paper for acceptance at ICLR. First and foremost, this is not the correct venue for a work like this: ICLR centers methodological advances of representation learning, or at the very least, machine learning applications executed in a novel and impactful manner. The work here does not provide any methodological advances, nor is implementation novel. Secondly, the results are not particularly significant or novel. My recommendation would be to reframe the paper and research question, and submit to a different venue. The underlying dataset (4.7M individuals) appears to be rich and has potential to answer a number of research questions that would be of interest to public health practitioners.\n\nPros:\n\nLarge dataset\nGenerally well-written paper\n\nCons:\n\nNo methodological novelty\nResults are not particularly surprising\nMissing features (vaccination status, loss of taste/smell, prior infection, etc)\n\nIn particular, I would recommend engaging with public health experts and finding research questions that would be directly impactful. Just as one example, how do symptoms vary by sex and age, or by timing, as strains have evolved over time? There are of course many questions that could be answered with this dataset, and I would encourage the authors to think creatively.\n",
            "summary_of_the_review": "Reject: low novelty and significance both technically and empirically. Suggest reframing research question and submitting to a more applied venue.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The objective of this paper is to predict if an individual has COVID-19 based on the symptoms. Data of this study was taken on June 18th from the Israeli Ministry of Health on COVID-19. The purpose of this study is to compare and analyze different models, which are Support Vector Machine (SVM), Logistic Regression (LR), Naive Bayesian (NB), Decision Tree (DT), Random Forest (RF) and Neural Network (NN).",
            "main_review": "- Experimental design is not properly explained, but it appear to be quite weak in terms of reproducibility given the limited number of resampling runs.\n- There are no CIs in the provided results, making it impossible to judge the statistical significance of the occurring differences.\n- Description of the Neural Network classifier is vague and useless from the point of view of reproducibility (\"Neural Network (NNs) is a kind of relatively complicated deep learning through constructing artificial systems of neurons to process information without supervision.\"). Further, all other methods are well known material included in any ML textbook that could just be mentioned without a dedicated description.\n- Introduction should be more focussed on the problem of predicting a disease from symptoms, rather than provide a generic overview of the use of ML in Covid-19 predictions.\n- The number of decimal digits shown in Tab. 1 and 2 should be reduced to two.\n- Results are evaluated in terms of Accuracy and F1-scores, measures known to be biased in several sense, and especially when data is unbalanced. Why not using a fairer metric such as MCC? Moreover, what is the distribution of the \"corona\" target variable? How unbalanced is the dataset?\n- Why not using a more robust method for feature importance such as SHAP, rather than relying on a quite empirical recursive strategy?\n- The contribution is very similar to [Zoabi, 2021], but the lack of the \"Contact with infected\" feature makes a big difference. Furthermore, the limited circulation of flu and other flu-like viruses in the last months can strongly undermine the application of the model to an external similar dataset.\n- Figure 1,2 are somewhat misleading, since the lower end of the y-axis is not starting from zero, providing a false impression of large difference among the classifiers. \n- Figure 3 should be removed, since it is not really adding any information to the main text.\n- A number of typos occur throughout the manuscript.",
            "summary_of_the_review": "The paper is barely a comparative classification exercise on a simple dataset with 8 features. There is no real added novelty neither on the ML side nor in the obtained results. Further, the experimental setup is not robust, and potential confounding factors are not taken into account.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper demonstrates some experimental machine learning results based on a type of covid19 related dataset, where individual symptoms are used as features for predicting the presentness of covid-19. Several standard classifiers are tested on three datasets. As the authors have suggested, the prediction results may help the government better allocate the medical resources during this pandemic.",
            "main_review": "Strengths: the idea presented in this paper, may be a good idea for promoting machine learning based insight tool that may help people make decisions at the population-level. But this is not a novel idea.\n\nWeaknesses: from an academic/research point of view, the methodology used and results obtained are rather weak.\n\nEvaluation is not properly done, the author should consider more robust methodologies, such cross-validation based or time-based dataset split methods. There is no novel research/results presented in the paper. The entire paper only describes a standard machine learning exercise. To be honest, no offence, I think this can be done by any early year undergraduate student in a weekend. I didn't find any insights that can be learned from reading the paper.",
            "summary_of_the_review": "Results are really weak, no new insights.\n\nMethodologies are weak. Very lengthy descriptions on the common algorithms and their parameters.\n\nRELATED WORK (section 2) is just a list of bullet points, with no discussion.\n\nI think the topic/problem itself is not bad, but the research done is just too rough. Clearly not met the standard of even a C-level conference.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}