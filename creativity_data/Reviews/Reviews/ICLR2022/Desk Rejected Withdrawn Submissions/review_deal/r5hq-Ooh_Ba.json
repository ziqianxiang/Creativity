{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper introduces a new semi-supervised learning (SSL) method that aims to exploit the low-confident samples to train the model. Compared with existing SSL methods, the proposed method adds a true-negative classifier to classify those low-confident samples as true negatives and further adds a consistency regularization on the true-negative predictions. Experiments show that the proposed method reaches significant improvement over existing methods, especially for the low-label regime. ",
            "main_review": "The advantages of this paper are as follows.\n1) This paper proposes a novel  SSL algorithm by exploiting complementary negative labels. \n2) Extensive experiments are conducted to evaluate the proposed method by comparing existing ones. \n3) The proposed method significantly extends the state-of-the-art performance. \n\nThe disadvantages of this paper are as follows. \n1) The results shown in Table 1 are impressive and the authors accredit this for the TNC module. However, If a random guess has an accuracy of 90% (10-class classification) for the true-negative classification, how could it bring such great improvement as the signal is not very informative. \n2) What is the effect of the consistency regularization against TNC's predictions. This component seems not studied.\n3) Why not report the complete results for FixMatch and CoMatch in Table 1? Considering that the authors have implemented FixMatch and CoMatch and conducted some experiments on them, it should be feasible to report the results for the other experimental settings, but why these results are missing.\n4)  Figure 9 in the last paragraph of Section 5 should be Figure 7. \n",
            "summary_of_the_review": "The proposed method looks simple yet highly effective. But the explanations for the impressive results are not very convincing and some experimental results are missing. With this consideration, I would recommend weak acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a framework of semi-supervised learning with mutex-baesd consistency regularization. On top of the framework of consistency-based regularization, the proposed method incorporates a new branch to learn from negative labels. Specifically, it uses a TNC module to predict the class with lowest confidence in TPC and perform consistency regularization for training examples with low confidence. Authors conduct experiments on various datasets to verify the effectiveness of the proposed method. They also present an ablation study to show the specific strategies of learning TNC are crucial to the good performance. ",
            "main_review": "Strengths\n1. Semi-supervised learning is an important problem. The proposed framework is well motivated by making good use of all unlabeled data in semi-supervised learning. \n2. Most parts of the paper are clearly written and easy to read. \n3. The ablation study gives empirical evidences for the effectiveness of the proposed method. \n\nWeaknesses\n1. The technical contribution is a bit incremental, since the core idea of utilizing negative labels has already appeared in previous SSL publications such as [1]. Moreover, it’s not clear why and whether the proposed way (involving an extra TNC) to employ negative labels is superior to existing manners such as NCE and BCE. \n2. Improvements on CIFAR-100 are not significant. I wonder whether the algorithm will perform well on datasets with more classes? To my understanding, predicting a specific negative label (the most negative one) sounds not reasonable when there are many classes. \n\n[1] In defense of pseudolabeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning. (ICLR’21)",
            "summary_of_the_review": "I recommend weak rejection considering the weaknesses in technical novelty and potential limitations.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "### New SSL algorithm that exploits mutual exclusions.\n\nThis paper proposed a novel semi-supervised algorithm that makes use of unlabeled examples that fall below the confidence threshold to additionally guide the network to learn *what it is not*, in addition to learning *what it is* using standard Fix-Match style. Overall, the method is simple and seems effective with little to no additional cost during training and testing. Extensive experiments provide meaningful insights into the model.",
            "main_review": "### Strengths\n\n- The paper is well written and the experiments are useful. \n- The idea to use the often-ignored lesser confident samples from the unlabeled set is novel and well motivated. \n- The overall framework using a true-negative classifier seems pretty general and easily adoptable to any existing approaches, although the proposed approach achieves SOTA using a FixMatch backbone. \n\n### Weaknesses\n\n- I did not get the logic behind enforcing consistency regularization against TNC's predictions. While TPC consistency means that weak and strong augmentation predictions match, similar logic doesn't hold for TNC prediction. For example, the same horse image can *not* belong to a dog class as well as *not* belong to a zebra class. Isn't this opposite to enforcing consistency?\n- From the Table 1, the numbers seem pretty strong. However, the variance of the reported accuracies for CIFAR-10 with 10 labels is very high. Although the absolute difference is ~10%, the variance is also ~10%, which requires further explanation.\n- Similarly, on CIFAR-10 with 40 and 80 labels as well as CIFAR-100 with 200 labels, the difference of accuracy between next best method (CoMatch) and MutexMatch is marginal (93% vs 93.4%, 94% vs 94.3%) and often equivalent to the reported variance (0.2% and 0.8%). (It is completely fine with me if your method is not SOTA, but the high variance requires some explanation).\n- Figure 9 is not present in sec 5.2. Did you mean Fig 7?\n- From fig 7a,b,c, it seems that the difference between various ways of training TNC give roughly the same result. So the take-home message of this whole ablation seems pretty weak to me.\n- From fig 7c, the complementary pseudo label accuracy seems low for Rev-Norm while the overall accuracy in fig 7a seems almost equal. This raises the question if the complementary accuracy and original accuracy have any correlation at all on this dataset?\n- Can the authors provide an ablation into the effectiveness of losses Lp and Ln from eq 1? By not using one or both of lambda_p and lambda_n, what would be the drop in performance? The ablation provided in Fig 9 in the supplementary seems odd to me. lambda_n is varies between 1-20 while lambda_sep is varies between 0.25-1.00, although the losses seem to be roughly of the same scale. A better ablation of the hyperparameters is needed to really distill the effectiveness of the proposed losses.\n- It is not really clear what happens at test-time. Do we simply drop the TNC classifier and predict using the TPC network?",
            "summary_of_the_review": "This paper proposed a novel technique for semi-supervised learning by effectively using the low-confident unlabeled samples. The overall framework is simple and well-motivated but few concerns regarding the analysis into the approach remain, which are mentioned above. Nevertheless, the method seems effective for SSL and and if the authors could clarify the questions raised, I would be happy to update the score. \n\nPost rebuttal \n-------------------------\nI appreciate the authors' efforts in addressing all the queries raised. While I feel this work has an interesting and technically novel motivation, I also think it requires further analysis, ablations and insights to match the intuition presented. Therefore, I am inclined to keep my score but would not argue if the paper gets accepted.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}