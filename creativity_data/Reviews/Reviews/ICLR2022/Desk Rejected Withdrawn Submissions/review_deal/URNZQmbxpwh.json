{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a new regularization technique for OOD generalization by performing domain-level gradient covariance matching. The connection between proposed method and Fisher Information is illustrated and extensive experiments are performed.",
            "main_review": "Strength:\n(1) The authors propose a new regularization form which characterize the learning process more comprehensively.\n(2) The proposed method is effectively optimized with faster approximation, which relieve the computational overhead.\n\nWeakness:\n(1) Maybe the biggest concern is the contribution over previous work. The proposed method can be seen as a heuristic extention of gradient alignment (e.g. fish). Though simple and easy to follow, the contribution is marginal. Proper theoretical justification is in absence.\n(2) There empirical results are not convicing enough to support the strong claim. The proposed method rarely beats all the baselines (1 out of 14 settings), and the average performance over all the datesets is extremely misleading. How could you take average on performance over benchmarks with different class number, sample size, distribution shift?",
            "summary_of_the_review": "This paper addresses the OOD generalization by regularizing gradient covariance discrepency. Although intuitions are provided, the technical and theoretical contributions over previous work are marginal. Moreover, the empirical results are not strong enough to support the claim.\n\n\n===========After Response===========\n\nThe authors have clarified some points regarding to the contribution, so I raised my scores.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper introduces a simple technique for out-of-distribution generalization, called Fishr. Intuitively, given the success of CORAL, Fishr enforces consistency through mean regularization between the element-wise variances of the gradients across domains. It is efficiently solvable using the existing BackPACK package. Several explanations have been provided for Fishr. Then, the paper concludes with applying Fishr to standard OOD benchmarks showing superior performance of Fishr in several different problems.",
            "main_review": "This paper introduces a simple technique for out-of-distribution generalization, called Fishr. Intuitively, given the success of CORAL, Fishr enforces consistency through mean regularization between the element-wise variances of the gradients in the last layer across domains. It is efficiently solvable using the existing BackPACK package. Several explanations have been provided for Fishr. Then, the paper concludes with applying Fishr to standard OOD benchmarks showing superior performance of Fishr in several different problems.\n\nOverall the algorithm is simple and the idea iand the empirical results are good, which is why I am in support of accepting the paper. However, the presentation of the paper needs major revision to make it more easily followable as suggested below.\n- The mathematical exposition of the paper is disjoint from the actual algorithm. For example, the objective in Section 3.1, Eq. (2) is not what is being solved. Please structure the paper to expose the objective being tackled from the beginning. The material on full covariance matrix belong to an appendix on further motivation of the problem, as it is confusing the reader.\n- Please explicitly call (3) mean regularization, and refer to it elsewhere as such too, as it is not clear from reading the abstract and intro how the consistency between element-wise variances of the gradients in the last layer is enforced.\n- Please restructure Section 3.3.1, and start with the well-known fact that under certain regularity assumptions the Fisher information matrix is proportional to the Hessian of the log loss. Then talk about the caveats of the empirical Fisher information. As is presented now, it is confusing the reader.\n- Please give due credit to original work; in several instances recent papers are cited for well-known results dating back several centuries.\n- Please bring a condensed version of the pseudo-code to the main paper and ground the discussion of the implementation on it, as it was confusing for me to follow the implementation.\n- In several instances, the algorithm refers to Eq. (2)-(4). This is not accurate as those equations capture the covariance of the gradients and not what is being implemented. By changing those equations to capture what is being implemented, this consistency will also be resolved.\n- Hyperparameter \\gamma is not defined in the implementation section while it is part of Sec 5.2.1 and the pseudo-code. Please move the exposition up to where it belongs.\n- The connections in Section A.2 with NTK are loose, but I think it is okay the way it is framed now.\n\nFrom a technical/theoretical standpoint, this paper is indeed weak. \n- Can you say something about what Fishr does in linear/logistic regression? In this case, the implementation captures the actual element-wise variances of the gradients? Is there a toy example that could be devised to be presented right in the beginning to ground the exposition? Is there simple theory that could be used to justify this choice, at least for linear models?\n- There are no convergence guarantees for the proposed algorithm.\n\n\nTypo:\n- Pg 5, Section 3.3.1: an unique -> a unique\n- Pg 8, Section 5.2.1: an high -> a high\n- Pg. 22, Section C.2.2: |\\mathcal{E}| + 1 times -> ( |\\mathcal{E}| + 1) times\n",
            "summary_of_the_review": "Overall, the paper provides a simple yet powerful method to address out-of-domain generalization with good empirical results, and hence I am in support of acceptance. However, the paper needs a major rewriting to flesh out the main ideas and make the exposition as straightforward as the proposed algorithm is. Also, the paper lacks theoretical justification for the choice of regularizer and convergence guarantees, which makes it weak from a technical perspective.\n\n=== after author response ===\n\nscore raised from 6 to 8. See comments below for details.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a regularization for Out-of-Distribution Generalization problem, which aims to align the gradient of different domains. Extensive experiments are performed to validate the effectiveness of the proposed method. And some intuitions are also given to demonstrate the Fishr method.",
            "main_review": "a)\tStrength: \ni.\tThe authors propose a new regularization for OOD Generalization and conduct extensive experiments to support the method.\nii.\tEffective optimization method is designed for the regularization.\nb)\tWeakness:\ni.\tThe proposed method is based on intuition and directly inherits from the previous methods, which I think is quite ad-hoc.\nii.\tThere is no theoretical analysis to support the regularization, for example, why it is necessary to incorporate the covariance, which setting can it solve, etc.\niii.\tThe experimental results are not good enough to validate the effectiveness of the proposed method. Firstly, why using the average accuracy of different datasets, since the difficulty of different datasets is obviously quite different, which is unreasonable. Secondly, the results are not good, since the increase in average accuracy across different datasets is entirely due to the colored MNIST dataset, which happens to be the simplest dataset. Thirdly, the fair setting(Table 4) does not show any benefits. \n",
            "summary_of_the_review": "This paper proposes a new regularization, and conducts extensive experiments. However, the method is quite ad-hoc and lacks technical contributions. And there also lacks theoretical analysis and the experimental results are not good enough to support the effectiveness of the method.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a new regularization method for OOD generalization. The central idea is to align the covariances of gradients between different domains. Specifically,\n- Authors first categorize different works in this area into three groups:\n    1. Methods that match **features** across domains such as those in adversarial training and most notably CORAL which considers the covariance of the **features**.\n    2. Methods that state that **the classifier on the top** should be invariant. Such as IRM.\n    3. Those that align **gradients** such as IGA.\n\n- Authors then propose Fishr which falls into the 3rd category. It aligns gradients between the domain but with the important different that it aligns the *covariance* of the gradients not the *average* of them.\n\n- Authors establish equivalences between the the covariance, the fisher information matrix, and the hessian which in fact describes the loss landscape.\n\n- As a practical approach, authors propose to match the **variances** instead of the **covariances** and also only the penultimate linear layer.\n\n- Finally, authors evaluate their approach on standard OOD benchmarks in two different setups:\n    1. When the hyper-parameters are tuned using the test set.\n    2. When the hyper-parameters are tuned using the training set.",
            "main_review": "Strengths:\n- The paper does a very good job at explaining the previous work in a coherent way.\n- The idea of matching the covariances of gradients is neat and well-motivated. Although hand wavy at points, but I enjoyed the connection to the loss landscape and the fisher.\n- The paper is **almost** well-written with some comments that I provide below.\n- I also found Figures 3-6 that visualize the dynamics intuitive.\n\nWeaknesses:\n- The paper first motivates that use of the covariance matrix but in the end, it uses a crude approximation of the method. The covariance matrix is approximated by the its diagonal (so variance not covariance). Also the method is only applied on the last layer.\n    - That being said, I understand that using the covariance matrix is impractical and I believe that penalizing the last layer only might be even a must not just an approximation (I outline below).\n- I have a hard time justifying myself, why the covariances must match. The distributions of the training domains **are** in fact different. As an example, in a dataset like PACS, I do not believe that the covariances of real images and sketch images should be matched. So it appears that authors are making an implicit assumption about the similarity of different training domains. However, I understand that it is an assumption being extensively used in this literature and is a step towards relaxing the IID assumption.\n- So, as I said, I believe that it might not make sense to match the covariances. However, thanks to your approximation (that the method is only applied to the last layer), matching the variances at the last layer, might still allow the network to have drastically different distributions in earlier layers. This is both good and bad. Good because it relaxes the assumption that all the domains should match. Bad because it defeats your motivation to some extent.\n- With that perspective, your method appears as a better approximation of IRM to me. Because it is only applied to the last layer, so making sure that the last layer is shared between the domains. Yet, it allows for the earlier layers to have domain-specific features.\n- The main weakness of this paper is the empirical results in my opinion. When the model selection is by using the training domain, all the methods are statistically the same. Even with the test set is used for model selection, Fishr does not perform very well.\n\nA comment regarding the writing:\n- The actual experimental results comes very late in the paper. I suggest swapping sections 4 and 5.\n\nMinor comments:\n- If the citations are in a different color, it would be easier to read.\n- In page 1, I am not sure what does the word \"feedback\" refer to.\n- Just before Eq. 1, use \\cite not \\citep for \"(Koyama & ...\"\n- I suggest rewriting the last sentence on page 3. \n- A dot is missing at the end of Eq. 2.\n- I suggest rewriting the sentence right after Eq. 4.\n- In the caption of the tables, mention what bold number and underlined number mean.\n",
            "summary_of_the_review": "As mentioned above, in summary,\n\n(+) The central idea of the paper is interesting.\\\n(+) The paper is rather well-written with very good related work section.\\\n(-) The practical implementation is a crude approximation of the central idea.\\\n(+) The colored-mnist experiments confirms the underlying intuition.\\\n(-) Other empirical results are very poor (in my opinion).\n\nMy questions:\n- I would like to know if the authors agree with me that only applying Fishr to the last layer might in fact be a necessity when the training domain are much more different. For example, when one domain is an mnist with 10 classes and another is an mnist with 5 classes.\n- I appreciate if the authors could comment on why not matching the **uncentered covariances**, i.e., matching the mean as well as the variance.\n- What would happen if you train your method for much more epochs (like 5000 epoch on the colored-mnist)? Most the OOD methods fall back to ERM in the long run because the penalty is zero even for ERM at the convergence. I am curious to see what would happen to Fishr.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}