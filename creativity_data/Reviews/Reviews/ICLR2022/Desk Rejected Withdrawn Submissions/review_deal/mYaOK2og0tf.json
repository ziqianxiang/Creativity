{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors consider the problem of generalization in deep neural networks from the perspective of a PAC-Bayesian method. The authors discuss the problem of using parameterization-dependent quantities (such as flatness), and attempt to improve upon such quantities by proposing to measure the trace of the Hessian. Consequently, the authors propose to make use of the trace as an additional regularization term in training neural networks. The authors demonstrate some empirical results on some standard image benchmarks.",
            "main_review": "The authors consider an interesting problem in obtaining informative bounds to measure the generalization of neural networks. Unfortunately, the quality of writing of the paper is poor, severely hindering the exposition of the results. Additionally, the proposed bound is obtained from the choice of normal prior and posterior distributions, which appears to have limited novelty (in fact, such a choice was already used by [1]), and although the choice of a Laplace approximation is different, it is not clear that it accurately captures the behavior of the non-stochastic network (see below). This is compounded by the authors not addressing technical issues in the use of PAC-Bayes bounds. Finally, I found the presentation of the empirical unclear and unconvincing. I will detail some comments below.\n\n**On the writing of the paper.**\nI found the overall presentation of the paper extremely confusing. The authors should make sure to consider the following. 1) Define all notation used in the paper (even when it might appear “obvious”), and ensure that it is consistent. In particular, I was very confused by eq. (3) where $p$ appears twice with (possibly?) different meanings. Similarly, $\\tilde{p}$ appears in the definition of $Z$ but is never defined. 2) Present a theorem for the main result. Given that the paper is titled “A [...] Generalization Bound”, the authors should present their main generalization bound as a theorem in order to clarify the precise statement intended and the conditions for its applicability.\n\nOn the related works section.\nThe related works section is inadequate and misses out on large parts of the literature concerning generalization bounds which are relevant to the problem considered in this paper. The authors should consider reviewing the existing literature more thoroughly (e.g. see [2] and references therein). In light of this, the authors should also use this section to clarify how the current work distinguishes itself from existing bounds (e.g. from [1] in particular, and from the many bounds considered in [3] in general), as the use of a Gaussian prior / posterior in the PAC-Bayes framework does not appear to be a significant contribution itself.\n\n**On the technical application of PAC-Bayes bounds.**\nAn important technical aspect of making use of PAC-Bayes bounds is that they apply not to a fixed model in the traditional sense, but rather a stochastic model (the posterior). In this paper the authors make the choice to instantiate that posterior as a Laplace approximation around the trained model. This choice should be discussed more thoroughly, in how it affects the robustness and error of the corresponding model (e.g. see the literature in Bayesian deep learning).\n\n**On the empirical results**\nI found the presentation of the empirical results in section 5 to be confusing and unconvincing. The authors should outline a clear goal of the statement which they attempt to empirically demonstrate, as well as the corresponding protocol. I would also advise the authors to defer details which are not necessary for the exposition (e.g. choice of optimizer, learning rate etc.) to the appendix in order to focus on the main claims. Finally, I did not find the protocol particularly convincing, especially in the light of recent work such as [3], which the authors should consider in designing their empirical protocols. Additionally, in section 6, table 7 and 8, the presented results do not match the claims in the text, as in table 8, the network with no regularization performs better. The authors should carefully check their empirical results and associated claims.\n\n\n**Miscellaneous.**\nPlease cite published versions of papers, e.g. “Pac-bayesian theory meets bayesian inference” (Germain et al.) appeared at NeurIPS 2016.\n\n**References**\n\n[1] “(Not) Bounding the True Error”, Langford and Caruana, NeurIPS 2002\n\n[2] “Generalization bounds for deep learning”, Valle-Perez and Louis, arXiv pre-print 2020\n\n[3] “Fantastic Generalization Measures and Where to Find Them”, Jiang et al.\n",
            "summary_of_the_review": "Although the paper presents some potentially interesting directions, the poor quality of the writing, the weak novelty / originality of the paper and the poor empirical evaluation do not justify acceptance at this stage.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors point out issues with flatness as a measure of generalization for neural networks. The argument is largely heuristic, based on the observation that for a ReLU network trained with cross entropy, for the loss to go to $0$ the weights must go to infinity, and as the weights go to infinity the Hessian tends to the $0$ matrix. The authors then make a heuristic argument based on a PAC-Bayes bound of Germain et al, 2016 to recommend training with a loss regularized using the squared norm of the weights and the trace of the Hessian. The authors show some experimental evidence in support of this objective function.",
            "main_review": "Most of my review is phrased as comments and questions, but I will briefly list the strengths and weaknesses of the paper as I see them.\n\n## Strengths\n- The theorem seems to stem from the observation that if the weights of the network diverge the Hessian tends to $0$. I have not looked at the proof in great detail, but this seems to be an interesting observation. \n- The emprical evidence for the method seems somewhat compelling.\n- The method seems relatively simple, which from a practical perspective is quite valuable.\n## Weaknesses\n- I think the discussion of the PAC-Bayes literature, particularly the relatively large body of recent work on applying PAC-Bayes in deep learning, could be improved substantially and would provide useful context. \n- I am not entirely clear if an actual bound on the generalization risk can be computed within the framework, and if so whether it leads to vaccuous bounds. Is that what the $\\mathfrak{a}$ in the table is?\n- Several derivations seem somewhat heuristic, and I think the tone of the paper over-sells the theoretical contribution of the work. This could be fixed by spending more time emphasizing and discussing empirical evidence for the method.  \n\n## Major comments and Questions\n\n* The derivation of the proposed loss seems heuristic. Several bounds are made to simplify the result, and it is unclear how we should expect these to effect the tightness of the bound or the generalization of the model.\n* The comparison to Dziugaite and Roy should be more thorough. In particular, it is not clear to me what the \"expensive\"  inner optimization loop you refer to is. In particular, it appears their algorithm involves first running \"vanilla\" SGD, then uses this as an intialization to minimize a PAC-Bayes bound. Note that this isn't an \"inner loop\", but more accurately a two-stage training approach, and shouldn't be that much more expensive than standard training. There are also a number of papers that follow up on Dziugaite and Roy, 2017 that would be relevant background. \n* Theorem 1 was interesting. However, essential to the proof seems to be that the algorithm doesn't converge in these settings and instead the weights diverge. 1. Does the gradient, as well as the Hessian, converge to 0 in this setting? 2. In practice, do the authors observe that the weights of a classifier trained with no regularization diverge? \n* Am I correct in saying that the section \"Why we can sub-sample the Trace and not the Log Determinant\" can be summarized by noting that the trace is linear, while the log determinant is not (so traces and expectations commute)? If so, I think this may not merit a full section.\n \n\n## Minor comments and Questions\n- Something strange has happened with formatting. At least in the pdf viewer I am using, there are lots of green boxes in the margins. I am not sure if this is due to some modification of the margins, or some other issue, most likely with the hyperref library. At the very least I would encourage the authors to pass the \"hidelinks\" argument when loading hyperref (assuming hyperref is the source of the issue), as the boxes are quite annoying. \n- The distinction being made between direct and indirect methods was not entirely clear in the introduction. \n- Some aspects of equation 1 seem quite speculative. In particular, can you clarify why it is reasonable to assume that the $w$ isn't correlated in some way with $H$? I wouldn't tend to assume that an optimum is at all typical, so I assuming that the projections of $w$ onto eigenvalues of $H$ are equidistributed seems heuristic. Is there empirical evidence for this?\n- The claim that this paper bridges that gap between theory and practice is overstated considering there is work investigating connections between flatness of optima and PAC-Bayes that leads to reasonably practical algorithms with generalization bounds.\n- In the contributions sections, the authors again claim to use a PAC-Bayes generalization bound (final section). But from what I gather the algorithm actually used doesn't yield a bound on generalization risk (or at least not one that the authors evaluated in practice).\n- $L_2$ regularization should be $\\ell^2$ regularization. \n- Equation 5 is confusing. What does $w_\\ell^* \\in w_\\ell^*$ mean? Is there a typo here?\n- In equation 6 did some $p$ become $\\ell$?\n- Lapalace -> Laplace on bottom of page 4\n- \"uniform prior\" -> \"Gaussian prior\" ?\n- The justification of weight decay as MAP inference with a Gaussian prior is reasonably common. While looking at it as a form of PAC-Bayes is a slightly different perspective, previous work on PAC-Bayes in neural networks has also used Gaussian priors, resulting in similar forms of regularization. I think the authors claiming this as novel is not entirely accurate. \n",
            "summary_of_the_review": "I do not feel the high-level tone of the paper is well-matched to the results in the paper, and have therefore recommended against acceptance. Particularly, the title and abstract of the paper lead me to believe that some form of probabilistic guarantees would be obtained on the risk of a classifier, but that does not appear to be the case. In particular, I do not see a bound on the generalization risk of the trained models reported. I also think comparisons to existing work on PAC-Bayes and connections to flatness of local optima could be improved. The experiments seem to give some evidence for the method, but I think the theoretical contributions of the paper are over-emphasized. Given the derivations seem quite heuristic, I would encourage the authors to spend more time discussing the empirical properties of the method which seem promising and de-emphasize the theoretical aspects. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper studies the problem of improving the generalization properties of deep neural nets by regularizing their weights using an approximation to their spectral properties. The paper develops a variational inference inspired loss function and links this to the PAC Bayesian framework. It eventually reports comparative generalization scores on a number of data sets.",
            "main_review": "The paper suffers from a number of fundamental weaknesses:\n\ni) The paper is lacking a concrete scientific hypothesis. The whole introduction section simply says that regularization is important in machine learning, which is common sense for the current practice anyway. Spectral norms and structural risks have abundant well-established use cases in the community. The paper should consolidate which particular pain point is in its target. The bullet items listed in Section 2 as contribution also do not define an unambiguous scientific problem, nor does it specify any original solution hypothesis to a known problem. Section 3 and 4 only present a number of trivial facts.\n\n\nii) I am not able to identify the conceptual difference of the proposed solution from the very well known spectral normalisation trick, which is widespread in GAN training:\n\nMiyato et al., Spectral Normalization for Generative Adversarial Networks, ICLR, 2018\n\nThe application of the same trick to nonadversarial training is of course much more trivial. What the paper claims on top of this is not obvious to me.\n\niii) The paper refers to PAC Bayesian generalization bounds right from the title onwards, but it does not use PAC Bayesian theory anywhere within the content. The objective presented in Eq 3 is the plain Evidence Lower Bound (ELBO) of a vanilla variational inference scheme. It is true that every ELBO can also be cast as a particular PAC Bayesian bound but why does it help us here in this context? What does the paper do to provide generalization guarantees on the test error? Or which property does it extract from a new bound statement?\n\niv) Section 5 is also lacking a clear focus right from the title. What does \"pathological\" refer to in this context? Which particular pathologies do the experiments address? Why are they pathologies in the first place? What do the error and loss differences stand for? Difference against what?",
            "summary_of_the_review": "The paper presents a mix of known trivial facts, it lacks a clear focus and a consolidated scientific claim. Its difference from the well known spectral norm is not identifiable. The relation of the presented content to PAC Bayesian theory is superficial. My initial vote is a clear reject.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}