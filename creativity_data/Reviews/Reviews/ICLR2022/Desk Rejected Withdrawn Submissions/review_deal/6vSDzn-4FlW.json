{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "\nInspired by biological neuronal networks, ANNs have loosely borrowed from biology and abstracted away perceived inessential characteristics, outperforming many other traditional statistical inference techniques in the process.  Many researchers continue to look at biology for further inspiration that might continue to improve ANNs, and the authors, in this present work, contribute to these efforts.  In particular, they question whether some inhomogeneities that have been eschewed in modern ANNs might be better kept. By looking at 3 different characteristics--heterogeneous learning rates, random weight reinitialization, and weight splitting or branching--the authors find that several standard networks and tasks are improved, in several cases substantially so.",
            "main_review": "The authors have presented plausible biological motivations for the relevance of different types of neuronal inhomogeneities to the performance of biological, and potentially the improvement of artificial, neural networks.  Fuzzy learning rates allow for a range of learning rates to be sampled, weight rejuvenation may regularize the model, facilitating the network's avoiding local minima, and weight splitting may allow for multiple channels of information and potentially disrupt gradient inversion attacks.\n\nThe authors further demonstrate the performance increases these noise-inducing changes correspond to.  Importantly, the authors' proposed biologically plausible adjustments improve the performance of deep networks, a strong limitation in other biologically inspired proposals. \n\nHowever, as a reader I was left with the impression of being presented with preliminary results regarding various types of heterogeneities that might be introduced to a network without any comprehensive or detailed efforts that illuminate the mechanism that any of the 3 changes enacts that lead to the observed improvements. Nor was I completely convinced that these improvements are not simply resultant from trivial aspects, including having a larger number of parameters, faster learning rate, or increased noise-induced improvements similar to those experienced through SGD or dropout. \n\nMore specifically:\n\n1 - The authors claim that the optimal $\\tau \\sim 0.1$.  Yet, in Fig. 3a, which they use to justify their choices, there appears to be very little difference that $\\tau$ has on the mean accuracy of the network, as the surface appears virtually flat in the $\\tau$ dimension.  Indeed, the inclusion of fuzzy rates alone does not seem to appreciably change any of the network accuracies, as seen in Table 1, row 5. Nor is this unexpected, as the learning rates are only subtly adjusted by multiplying them by a random factor between 0.9 and 1.1, as follows by their choice of parameter $\\tau \\sim 0.1$ \n\n2 - As small a change as $\\tau \\sim 0.1$ causes to the learning rates, there is at least some evidence of appreciable training time improvements, as seen in Table 2, row 5.  However, the variances are large, and so it seems less likely that such improvements are statistically significant.  If they are, we are left wondering whether these improvements are better than simply slightly increasing the learning rate overall, and, if so, why that might be the case.\n\n3 - The dynamic reset of the weights is quite interesting, but I am left wondering whether it is the reset or the erasure that is important.  If the former, how is this method advantageous compared to dropout?  The authors also mention the similarity to DropConnect, but provide no comparison to the method.  \n\n4 - Weight splitting is in principle an interesting proposal; however, are the improvements that are noted due simply to increasing the number of parameters in the networks? They find no improvement beyond $|\\Gamma| = 2$, suggesting that this method is also not a robust, scalable (across different $|\\Gamma|$ values) method.\n\n\nI would propose that the work presented would be more convincing and satisfying if the authors concentrated on one or at most 2 of the methods, and provided additional analyses that better elucidate the processes underlying the observed improvements, such as comparing fuzzy rates to increased rates, rejuvenation to DropConnect, and splitting to a simple, similar increase in network parameters.  This would also allow the authors to better explore the causes of the observed gradient inversion improvements, which certainly appear to be quite robust.\n\nMinor issues: \n\n- Please describe the middle column in Fig 4\n- What is $\\mu$ in eq 3?  Is it the mean of the layer's weights?\n- \"thereby\" --> \"therefore\" in at least some of the cases where the former is used\n- \"grater\" --> \"greater\" \n\n\n",
            "summary_of_the_review": "The authors provide sound biological motivation to introduce 3 different types of heterogeneities found in biological networks into ANNs.  They demonstrate notable accuracy and inversion attack resilience improvements as a result of various combinations of their proposed changes, at least some of which appear to be robust.  However, a survey-like approach to these different proposals is substituted for thorough analyses that would allow for a more reliable assessment of the authors' claims, as well as deeper insight into why the claimed improvements occur.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors present a neural network approach that incorporates synaptic diversity, weight resetting, and multi-synaptic connectivity.  Synaptic diversity is achieved by adding noise to the learning rates of each synapse and weight resetting results in synapses that are stochastically removed, depending on their strength (the stronger the less likely to be removed). Neurons can connect to other neurons with multiple connections, which the authors hypothesis should make these networks more resilient to gradient inversion attacks. The combination of these techniques results in some improvements in accuracy and learning speed for some of the tested neural architectures.\n",
            "main_review": "The idea to incorporate more complex biologically-inspired neural mechanisms into current neural architectures is interesting. All three mechanisms (synaptic diversity, weight resetting, and multi-synaptic connectivity) have shown to be useful in biological networks but their combination has not been very much explored in artificial neural networks. It would be great if the authors could motivate a bit more why exactly this *combination* of methods. \n\nThe biggest issue is that it is difficult to draw general conclusions from the presented results. As the authors note themselves, results are often not significantly different from the baseline and while there are effects in some experiments, there are almost no effects in others. Additionally, the methods are only evaluated on relatively simple datasets (which can be fine) but also the baseline performances themselves are relatively low.\n\nIn general, the ideas are exciting but why these techniques work in some cases and not in others should be explored in more detail. It would also be interesting to investigate if these mechanisms would help in reinforcement settings as well. ",
            "summary_of_the_review": "A paper that combines three interesting mechanisms found in biological neural networks (synaptic diversity, weight resetting, and multi-synaptic connectivity). However, results currently seem too inconclusive to draw general insights. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes 3 biologically-motivated architectural innovations to artificial neural network learning: fuzzy learning rates, weight rejuvenation and weight splitting. Empirically, the authors find that the methods achieve higher accuracies and require fewer training epochs. In addition, the methods yield higher resistance of the network to gradient inversion attacks.",
            "main_review": "Strengths:\n1. The ideas proposed in this paper are interesting. It certainly would be valuable if biologically inspired innovations can enhance performance and training speed of ANNs.\n2. Experiments are carefully performed with detailed results on hyperparameter selection, multiple trials and full ablation experiments on all 3 proposed methods.\n\nWeaknesses\n1. The methods are only evaluated on relatively simple datasets (MNIST and CIFAR). It would strengthen the paper to show results on a more challenging dataset like ImageNet.\n2. Performance of the baseline appears relatively poor. For example, in table 1, in the first row, CIFAR-10 does not achieve above 60% accuracy on any architecture. It would be ideal to achieve more competitive accuracies for the baseline method; this might require tuning over a larger hyperparameter range (e.g. tuning over learning rates and optimizers).\n3. The proposed methods are not compared with other defenses against gradient inversion attacks. Adding a baseline defense would be helpful to assess how practical the proposed methods are against gradient inversion attacks. For example, does the proposed method approach state of the art performance as a defense against this attack?\n4. It is unclear to me how weight splitting is functionally different from not having weight splitting, particularly since split weights share the same gradient updates. How is having multiple synapses between two neurons different from having a single synapse with weight equal to the total summed synaptic weight of the multiple synapses? The authors state that \"the non-linearity alters the activation so that the learning behavior changes.\" Unfortunately, I don't understand this point since the non-linearity appears after the multiple synaptic outputs are aggregated, so having multiple synapses appears as having a single synapse between neurons.\n5. As the authors note, it is unclear theoretically why the proposed method might be effective. Such an investigation could be left as a future work though, given stronger empirical results.\n\nMinor comments\n1. In section 2, the authors state that ANNs have a majority of small weights, and therefore rejuvenating small weights would not impede training. However, it is not clear to me why ANNs having majority small weights makes those weights less important to the network.",
            "summary_of_the_review": "Overall, this paper proposes some interesting ideas. The proposed methods are not theoretically motivated, so the empirical results are quite important. Unfortunately, the experimental results are relatively limited in terms of performance (including baseline performance) and don't consider more challenging settings. Thus, I believe more improvements may be necessary for this submission.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper presents three adaptations for neural network training, motivated by biological observations. Fuzzy learning rates, i.e. randomly drawn learning rates for each synapse should model diversity in synaptic plasticity. Weight rejuvenation, i.e. random setting of a weight to a random value models spontaneous spine remodeling. And weight splitting, i.e. having multiple synapses for one weight, corresponds to multi-synaptic connectivity. The three new concepts are tested in all combinations and compared to baseline networks for multiple architectures (MLP, AlexNet, ResNet56) and on 3 datasets (MNIST, CIFAR-10, CIFAR-100). The three newly introduced methods often improve over the baseline, and yield better final accuracy and faster training, although no conclusive picture was found. Also the robustness against gradient inversion is tested.",
            "main_review": "The paper is mainly an empirical study of the three new twists to neural network training, tested on 3 architectures and 3 standard benchmarks. While some combinations of the methods seem to be useful in most cases, there is no conclusive picture that would suggest that one or the other method should always be used. Also, from the three tested datasets and 3 architectures, it is unclear which method brings what benefit for different architectures. Overall, the message of the paper remains unclear, and presents more anectodal evidence that biology-inspired new tricks from neural network training might have a positive effect.\n\nStrengths:\n+ simple method with some benefit\n+ exhaustive experimental results in the benchmark cases\n\nWeaknesses:\n- unclear message, there is no conclusive evidence which combinations are generally useful\n- tested only on a very reduced benchmark set with specific neural network architectures\n- The obtained accuracies for the benchmark networks in Table 1 seem surprisingly low. E.g. even linear classifiers on MNIST obtain accuracies close to 90%, so a 76,83% accuracy for AlexNet seems unreasonably low. Similarly, all CIFAR results are very far away from current benchmark results. In the case of CIFAR-100 / AlexNet, the results are close to chance level. This severely calls into question the validity of the results, and suggests really suboptimal hyperparameter choices.\n- Overall it remains completely unclear what the take home message show be.",
            "summary_of_the_review": "The paper is merely an empirical study of the effect of biologically-inspired ideas for modifications to the ANN training procedure. There is no clear conclusion from the results, and some of the benchmark results used for comparison are well below expectations. In this form the paper will not be of significance to the community.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}