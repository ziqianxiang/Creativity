{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper introduces a model for temporal KG completion, i.e. prediction future links in KGs based on historical data. This paper adopts a path based approach in which starting from the query entity, it searches for the outgoing edges. Since the KG is temporal, following previous work, preference is to choose next hop which are closer in time. At each step only top-k entities are chosen based on the path scores. After each step of the hop. the queries are also updated where the entity representation is updated by a simple addition of the relation and the relation representation is updated by subtraction of the relation which was traversed. It is not clear why this update model was chosen. Also if the Trans-E formulation is chosen, the effect of the relation update cancel each other. Each path is scored by a combination of 3 scores —-(i) question matching degree, (ii) answer completing level, (iii) path confidence. I found this section very confusing and the motivation behind each of the scores was not clear to me (especially from a temporal forecasting point of view). ",
            "main_review": "\nStrengths:\n\n1. Temporal link prediction in knowledge bases is an important problem.\n\nWeaknesses/Questions for the authors:\n\n1. The main weakness of the paper is currently how it is written. I personally found the writing to be very confusing and most of the model decisions were not motivated properly. Even though the paper gets good results, the paper in its current form is not ready to be accepted.\n2. In equation 1, it is mentioned that an entity embedding is composed of static and dynamic components. However, it is not clear currently, how each of the components is learned.?\n3. It is not clear where or how equation 2 is used?\n4. What is the motivation behind eqn 3 and 4. Why is the relation embedding added to the entity representation to update it and why is it subtracted from the query embedding?\n5. If we add the updated representation of entities and relations (equations 3 and 4) don't the effect of relation cancel out?\n6. The scoring functions currently lack motivation. It is unclear why these scoring functions will help in temporal link prediction. \n7. In Table 2, the hits@10 of Re-Net is 65.81 which is 5 points more than the current method. Why is it not made bold in the table?\n8. Please don't bold every instance of the word \"path\" in section 5.3. It makes reading very hard.",
            "summary_of_the_review": "This paper introduces a model for temporal KG completion. The paper in its current form is very hard to understand. The writing and the motivation behind various modeling decisions need to be motivated much strongly. Therefore I am not recommending acceptance currently.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper introduces Interpretable Multi-hop Reasoning (IMR) for temporal knowledge graph forcasting. Unlike prior work that often lacks interpretability or is unable to combine paths with different hops for reasoning, IMR can perform interpretable operations on the query and measure paths of different hops equivalently, and utilize paths with different reasoning hops. \nSpecifically, IMR starts from the subject entity and finds out associate quadruples (1 hop path). Then it calculates the remaining queries for each path, and then IMR scores 1 hop path based on three indicates: query matching degree, answer completing level, and path confidence. To avoid searching space explosions it sample 1 hop path for the 2 hop path searching. Finally, it ranks the scores of all paths to obtain the preference answer. \nThey conduct experiments on two large-scale datasets ICEWS and YAGO, and IMR outperforms other baselines. \n",
            "main_review": "Strengths \n- They propose new interpretable and technically sound approaches for temporal knowledge graph reasoning. \n- Experimental results show they outperform other baselines on two widely used datasets. \n\nWeaknesses\n- It seems that improvements from multi-hop paths are somewhat limited, especially on ICEWS. I am not sure if the authors' argument that combining different reasoning hops helps is fully justified by the experiments. \n- Given Table 3, using three indicates do not really improve the performance from other settings (e.g., best HIT@1 and HIT@3 performance come from the $f_{ac}$  $f_{qmd}$ setting) on YAGO; performance gap between \"$f_{ac}$  $f_{qmd}$\" and \"$f_{ac}$  $f_{pc}$ $f_{qmd}$\" is non significant on ICEWS as well. In my opinion, those experimental results do not support the authors' claim that combining three indicators designed by IMR can effectively measure the reasoning paths. \n\nMinor comments\n- On Table 3 ICEWS14 HIT@3,  $f_{ac}$  $f_{qmd}$ shows 49.50 while $f_{ac}$  $f_{pc}$ $f_{qmd}$ shows 49.30 so the $f_{ac}$  $f_{qmd}$ cell should be bold. ",
            "summary_of_the_review": "Overall I think the paper introduces an interesting and technically sound approach for forecasting temporal knowledge graphs and empirically shows its competitiveness and effectiveness. However, I'm not fully convinced by some of the arguments due to the experimental results presented in Figure 2 and Table 3. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper presents an interpretable multi-hop reasoning approach for event prediction on temporal graphs (Graphs where each triplet of entities and relations has an associated timestamp). The task is ‘temporal KG forecasting’, where past historical facts are utilized to predict the future triplets. \n\nInspired from multi-hop question answering, interpretability in the paper is defined as finding the most appropriate path where the combination of relations is equivalent to the query’s relation. \nFor scoring and choosing the path, three indicators are proposed: Question matching degree to find the answer entity, which has the least distance from the query entity, Answer completing level to find the combination of paths which is the distance of the relations in the path to that of the query, Path confidence to measure the validity of each path.  \nThe paper includes empirical results and comparisons on ICEWS and YAGO, along with an ablation study for the three indicators.\n",
            "main_review": "Strength\n\nThe strength of the paper lies in the ability to provide a basis for path comparison. It can measure the paths of different hops and utilize them for reasoning. The problem handled is important for interpretability in temporal KGs. The inspiration taken from multi-hop QA is interesting and the proposed approach can be extended into further directions. \n\nWeakness\n\n1) In section 5.3 of ‘Case studies and Interpretability’, the authors show an example for one of the queries - (John Kerry, Make a visit, ?, 7536) and draw conclusions: ‘answer completing level can effectively indicate how well the combination of path relations equals to the relation of the query’, ‘ time distance between the paths and the query is gradually increasing, which means that the reliability of the paths gradually decreases.’ All these conclusions have been drawn from just one example from the dataset. It would make more sense to see in how many cases do these hold true. The first part is difficult to compute for all data samples but the second point could be shown for multiple samples and checked if the claim still holds true.\n\n2) ‘In the further analysis of paths, 97% of entities inferred by 3-hop paths are included in tails predicted by paths with one and two hops. Nearly no new positive samples are obtained, and numerous new negative samples are imported’ - This brings up the question of combining a multihop approach as opposed to an approach where the hops are fixed. In the experiments section, we are essentially combining paths that are 1 and 2 hops away. How would that be useful in terms of interpretability as opposed to when we have results from another fixed hop approach like ClusTer? Since we can just go till 2 hops the complexity of the problem reduces. How do the authors justify this approach to reasoning? Of course, using a richer dataset could be one of the ways but no conclusion can be drawn from the datasets used in the experiments.\n\n3) The standard deviations are not reported for the runs. Hence it is difficult to form conclusions especially for table 3 where the numbers are much close to each other. \n\n4) How do the authors justify the combination of the three indicators giving worse results for YAGO dataset in table 3? How does this worse performance affect the interpretability?\n\n5) ‘ IMR can always obtain the best inference performance by combining these three indicators.’ This is not evident from table 3 where the combination of all on Yago gives a worse performance.\n",
            "summary_of_the_review": "The authors propose an interesting approach and problem statement but the experiments do not fully justify the claims in the paper. Having variance for multiple runs, justification of why using three indicators reduces the performance and showing interpretability of multiple samples instead of just one would help in better evaluation. \n\nHere are some areas which would help in significantly improving the paper quality - \n\n1) Indicating the variance of multiple runs in the tables 2 and 3 along with just reporting the point accuracy would help in making the claims stronger.\n\n2) Supporting the claims made in the paper by relating to the numbers in table 3  would add credibility to the claims made. \n\n3) The effectiveness of the method would be highlighted by making a qualitative comparison by other methods such as ClusTer\nShowing that the claim is valid on multiple data points instead of just one would help in making the statements stronger.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, authors propose a novel framework called IMR(Interpretable Multi-hop Reasoning), which implements temporal knowledge graph forecasting by transforming reasoning into multi-step question answering. Considering the choice of multiple reasoning paths, the authors propose three scores to rank various paths.",
            "main_review": "Strengths\n1. The model improves over other temporal forecasting models by integrating paths of multiple hops and has good interpretability. The authors also provide a detailed case study to elucidate this algorithm and its advantage.\n\nWeaknesses\n1. What are the advantages of this method compared with methods based on reinforcement learning, like [1]? The score function (e.g., formula 5) designed in the paper can be understood as a greedy method, which preferentially selects the path whose destination is closer to the goal. Is such a greedy algorithm too simple and limited compared to RL method? \n2. This article attempts to solve the multi-hop reasoning problem on dynamic KG. However, the method of dealing with dynamic KG only includes the existing time-aware exponentially weighted sampling method. What are the innovations in this paper on this task?\n\nSome detailed question:\n1. What is remaining subject and relation in the model used for? I don’t see this symbol again in the paper. \n2. Why only sum rp1 and rp2 in Ep. 6? Here should be the sum of r on the entire path.\nI did not understand how to determine whether to stop, that is, to determine that the current end has been reached.\n3. The wording is confusing. For example, the e in Eq.7 is called query. I think what author want to express is the entity? There are many examples of this, which make it difficult to read the paper.\n\n[1] Lin, X. V., Socher, R., & Xiong, C. (2018). Multi-Hop Knowledge Graph Reasoning with Reward Shaping. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 3243-3253).\n",
            "summary_of_the_review": "Overall, the paper presents an incremental work.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents a multi-hop reasoning framework for forecasting future links on temporal KG. The novelty of this paper is that the proposed method designs three indicators to characterize the temploral KG and reasoning path. Overall, it is an interesting work. ",
            "main_review": "This paper presents a multi-hop reasoning framework for forecasting future links on temporal KG. The novelty of this paper is that the proposed method designs three indicators to characterize the temploral KG and reasoning path. Overall, it is an interesting work. \n\nStrengths:\n1. The idea is clear and the solution is somewhat novel. \n2. The paper is well written and the results are good. \n\n\nWeakness:\n1. The results on YAGO are not convincing. For example, the results for TTransE, TA-DisMult, TA-TransE and CyGnet are lower than 15% on Hits@10. But the Re-Net, zERTR and IMR obtain more than 60% on Hits@10. It is very strange. In fact, the dataset of YAGO in Table 1 hould not be used any more.  The authors should use the YAGO described in CyGNet (Zhu et al., 2020), DBKGE (Liao et al., 2021) and TITer (Sun et al., 2021). \nZhu et al., 2020. Learning from history: Modeling temporal knowledge graphs with sequential copy-generation networks. AAAI 2021.\nLiao et al., 2021. Learning Dynamic Embeddings for Temporal  Knowledge Graphs. WSDM 2021.\nSun et al., 2021. TimeTraveler: Reinforcement Learning for Temporal Knowledge Graph Forecasting. EMNLP 2021. \n\n2. The authors should compare with the latest studies DBKGE (Liao et al., 2021) and TITer (Sun et al., 2021). As you know, DBKGE has published on Feb, 2021, nearly 6 months ago before the deadline of ICRL 2022. \n\n3. The codes are not availabel, it is difficult for others to re-produce the results. \n\nI suggest the authors provide the results on YAGO described in CyGNet (Zhu et al., 2020), DBKGE (Liao et al., 2021) and TITer (Sun et al., 2021) and compare with DBKGE (Liao et al., 2021) and TITer (Sun et al., 2021) in the response phase. ",
            "summary_of_the_review": "This paper presents a multi-hop reasoning framework for forecasting future links on temporal KG. The novelty of this paper is that the proposed method designs three indicators to characterize the temploral KG and reasoning path. The idea is clear and the solution is somewhat novel. Overall, it is good paper. If the authors can well answer my questions and provide the new results, I will change the recommendation. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}