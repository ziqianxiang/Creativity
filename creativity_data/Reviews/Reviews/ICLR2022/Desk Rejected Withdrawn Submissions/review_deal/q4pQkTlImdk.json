{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes the AttndOut method, which is a meta-learning algorithm that learns how to dropout the attention weight matrix. The method is inspired by LSTM and consist of a forget gate and an input gate. The authors conducted experiments on various datasets to verify the effectiveness of this method.",
            "main_review": "Strength:\n-\tThe idea that adaptively change the dropout is a good point.\n-\tThe authors conducted experiments on various datasets.\n-\tNot too much extra parameters for model.\n\nWeakness:\n-\tThe title is confusing. What the paper is trying to do is just drop some attention weight, not get rid of attention mechanism.\n-\tThe motivation is the common dropout is predefined for all hidden layers. However, it’s not clear why the proposed meta-learning method is only applied to attention dropout. Although attention dropout is important for Transformer, other dropout layers in Transformer are also not neglectable and can be handled by same way.\n-\tIn Equation (7), the subscript s is not in the summed formula. More explanation of it is required. \n-\tIn the Table 3, the result of Scheduled Bernoulli on RTE is even better than AttendOut. What is the reason that AttendOut has lower variance? What is the statistical significance value when comparing Scheduled Bernoulli and AttendOut?\n",
            "summary_of_the_review": "I recommend rejecting because:\n-\tThe reason why the proposed meta-learning method is only applicable to attention dropout not other dropout layers, is not clear.\n-\tImprovement over the Scheduled Bernoulli baseline is limited, which makes the importance of LSTM questionable. \n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes to selectively adjust dropout rates which are governed by LSTM-based meta-networks for transformer-based language models. The meta-networks is \"nearly parameter-free\" compared to transformer models since it only concerns relatively small attention matrices. To reduce the computational cost due to a second-order optimization problem while meta-training the meta-networks, they exploit REINFORCE algorithm (Williams, 1992) and Gumbel-Sigmoid estimator (Maddison et al., 2014). ",
            "main_review": "### Strength\n\n**Better performances for BERT and RoBERTa.** The proposed method consistently outperforms the GLUE benchmark. Some results show significant improvement over their baselines. This work gives insight into the attention dropout in transformer networks in an aspect of meta-learning.\n\n### Weakness\n\n**W1. Unclear additional computational cost.** The most huddle to use this method in practice is the additional computational cost from meta-learning. Even if the meta-networks have *nearly parameter-free*, it involves K inner-step updates of task parameters which linearly increase memory footprints as shown in Figure 7 and presumably linearly increase the number of steps to converge the training curves. In a situation where abundant training data, this method compensates the number of training steps for large dataset significantly. For a strictly fair comparison, could you include the performance comparison where the training time or effective training steps is controlled?\n\n**W2. Weights Dropout and Scores Dropout is not equal.** Since the weights dropout applies the mask over the probability distribution which is summed to one, it makes that is no longer normalized where the sum is one. The 1/p does not recover this probability distribution. While the scores dropout applies to before the softmax function, it strictly maintains the probability distribution is normalized where the sum is one. Since the vanilla transformers use the weights dropout while the proposed method uses the scores dropout, there is some discrepancy applying attention dropout. The authors should clarify this difference is not significant, otherwise, the experiments are not fairly compared actually. ",
            "summary_of_the_review": "The paper is reasonably well-written and gives a good explanation of their idea. Only the hindered to recommend this paper strongly is W1) unclear additional computational cost from meta-learning steps, and wrong explanation on the difference between W2) weights dropout and scores dropout. W1 would be a significant huddle to adopt this method in practice, and W2 leaves a question on the fair comparison with competitive methods, although this would be a minor issue.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this work, the authors propose to apply meta-learning so that the dropouts in self-attention networks can be done in a unit-specific way. The proposed mechanism leverages Policy Gradients for learning, and several experiments have shown that this method should be applied to many network architectures for language models.",
            "main_review": "# Summarization\n\nIn this work, the authors propose that in self-attention networks, the performance can benefit from dropouts being  “smarter”, e.g. unit-specific. The author proposes to leverage the meta-learning framework and model the dropout as the update of LSTM cells.\n\n# Strong Points\nThis is an interesting problem to study. The authors challenge the view of having a uniformed dropout, which is a widely used practice. The author also shows interesting experiments including showing the significance and convergences, as well as ablation studies (a good job!) \n\n# Weak Points\n I found many issues (listed below) in the manuscript in its current form. Such issues should be addressed before readers can better understand the proposed method’s contributions.\n\n1. The narrative is relatively poor and needs improvement.\n    - The writing itself is not fully self-containing in a way that there are several mental gaps that need to be filled by looking at the referred paper. For example, the proposed use of  meta-learning in Section 4.1 and 4.2 is poorly explained and readers need to refer to [1] where it was originally proposed for details (even for the meaning of symbols).\n    - There are many missing details. For example,it remains unclear what are the dimensionalities of variables in Section 4.1., and how the formulate in Section 4.1 is instantiated for multiple layers.\n\n2. The technical novelty is limited. The meta-learning is mostly a verbatim account from [1] and other referred works (to a lesser extent). Thus in my understanding, the contribution is limited to applying the gradient policy (a well-known technique) for training.\n\n3. there are also several issues with the experiments:\n    - For fine-tuning, only three runs with random seeds are used for calculating the confidence level. Given the large reported std in Table 2, it may not be sufficient, and I would suggest that the authors have more runs.\n    - Comparison with vanilla dropout is missing. Since this manuscript argues for the superiority of “smart” dropout over vanilla dropout, a comparison with basic vanilla dropout would be helpful. I understand that the analysis into the *combination* with vanilla dropout is provided, however that may not shed the full light.\n\n# Assessment\nGiven the issues in narrative, limited technical novelty, and issues in the experiments, I would suggest rejecting as the manuscript in its current form is not good enough.\n\n# Additional Comments\n\nI would suggest the authors further proofread the writing. \n\n# Reference\n[1] Sachin Ravi and Hugo Larochelle, 2017: Optimization as a model for few-shot learning.\n",
            "summary_of_the_review": "Given the issues in narrative, limited technical novelty, and issues in the experiments, I would suggest rejecting as the manuscript in its current form is not good enough.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes AttendOut, which adopts the idea of meta-learning, to dynamically (in contrast to static vanilla dropout) drop the units in the attention matrix. The experimental results on various NLP datasets show that AttendOut yields improvement over various baselines.",
            "main_review": "Strengths:\n\n1. The proposed approach achieves better performance on various NLP datasets. (But I also have concerns about the clarity.)\n\n\n\nWeaknesses:\n\n1. The motivation of the utilization of LSTM for modeling is not clear. Why should it be modeled in a temporal manner? \n2. The paper suffers from clarity issues, such as the experimental setups, descriptions of the results, etc. Also, some of the claims are not convincing. Please see my comments in the next section.\n3. The authors claim that AttendOut features `faster tuning circle` in the abstract, but I did not see a specific analysis on this point.\n\n\n\nComments:\n\n1. Eq 2: Why is it scaled by 1/p? The original implementation in BERT does not apply 1/p scaling here.\n2. Section 4.1: `we assume ... between two models.` What are the `two models`?\n3. The paper does not say which version of BERT and RoBERTa were adopted. Base or large? Cased or uncased? Please be specific in illustrating your experimental setups.\n4. In Section 6.1, it is not clear how these numbers are calculated and why you use `relative growth rate` here? I tried to calculate one of them but failed to give the exact numbers. In this context, I can only rely on the results in Table 1 and 2, away from the distracting descriptions in Section 6.1.\n5. Figure 1: How about the curves in the top-most layer (closest to the output)? Also, why is there only one curve in STS-B? I don't think all four curves are identical.\n6. Figure 2: You mentioned that `we can see more steady declines in AttendOut case`. However, the observation is only clear in Figure 2b, but not in others. Maybe you should provide some statistics (such as variance) to support this claim.\n7. Figure 3: Please be more specific to describe the `experiment ID` and its real setting, but not only leave a sentence like `the experiment IDs are in order as they are mentioned`. ",
            "summary_of_the_review": "In the current stage, I cannot vote for accepting this paper due to the unclear motivation and clarity issues, which hinder me from understanding this paper properly. The authors are encouraged to improve their writing and be more specific in illustrating technical content.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}