{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposed an efficient point transformer structure, which consists of a centroid-aware voxelization module, a corresponding devoxelization module, and an efficient self-attention layer with coordinate decomposition in positional encoding to reduce space complexity. Experiments on ScanNet and S3DIS for tasks like segmentation and detection show the efficiency and effectiveness of the EPT network.",
            "main_review": "Strengths:\n1. The paper is well structured and easy to follow.\n2. The method follows MinkowskiNet / sparse convolution to use a hash map for searching neighboring voxels, which is faster than kNN. Also, the proposed coordinate decomposition when calculating the position embedding reduces the space complexity.\n3. Experiments are conducted on multiple tasks.\n\nWeaknesses:\n1. The K in positional encoding is not clear.  K nearest non-empty voxels or just K nearby voxels? If the former one, the space and time complexity may be larger than that analyzed in the paper. If the latter one, the number of valid voxels participated in the self-attention layer may be very small for some positions. Also, more analysis of K should be added in the experiment parts.\n2. Need more analysis for the design of the self-attention layer. Different from the conventional SA layer that computes the similarity between key and query features, the SA layer in this paper calculates the similarity between query features and the relative position embedding. It could be better if more analysis is added.\n3. The results on the segmentation task are not that convincing. For example,  MinkowskiNet reports 72.2 mIoU in validation set of ScanNet (2cm, no test augmentation), which is higher than the one (71.7) reproduced in this paper. Also, no test performance was reported. \n4. An experiment can be added: MinkowskiNet + centroid-aware voxelization/devoxelization, to show the superiority of ESA layer over Sparse Convolution.  ",
            "summary_of_the_review": "The attempt in the paper to improve the efficiency of self-attention in 3D tasks is inspiring, but more analysis of the designs and parameter choices is needed. Also, more powerful result is needed to support the statements in the paper. \n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper claims to introduce a new local self-attention layer for large 3d points clouds called ESA (\"efficient self attention\"). At its core are the following ideas 1) centroid-aware voxelization / devoxelization 2) coordinate decomposition technique for the attention kernel 3) replacing softmax with cosine distance in the attention weight computation. Experimental results on S3DIS and SCANNET dataset and on segmentation / 3d detection tasks suggest the technique is promising but are a bit inconclusive. ",
            "main_review": "--- Novelty and significance\n\nThe new layer and centroid-relative encodings are intuitive, but I have not seen this exact combination before. Still, voxel-centroid relative encodings / decodings have been done before for a long time -- see VoxelNet [Zhou2017], not cited. So this part -- 1) above -- does not seem novel to me compared to the x-v features in VoxelNet, even if authors claim \"The proposed centroid-aware voxelization is different from those methods in that it encodes the centroid-to-point position into f_i at continuous centroid coordinate c_i. Мaybe the authors can comment in a bit more detail here. 2) does seem novel, 3) is an interesting detail, but there's no ablation done to illustrate its importance. So to me of innovations 1-3 mostly 2) seems significant so far. That said, I find the overall model practical. \n\n--- Related work\n\nSome early 3d point cloud papers are not cited. MV3D [2017], VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection [Zhou et al 2018], PointRCNN [2018]. Also, the paper focuses on segmentation / 3d detection in large point clouds, that are typically created by aggregating many 3d scans, but seems to ignore many models popular in robotics that process individual 3d scans, which is important in domains with moving objects such as robotics. E.g papers on detection from 3D range images (e.g. LaserNet, etc), or methods that use range images and point clouds: e.g. End-to-end Multi-View Fusion for Object detection [Zhou et al 2019], etc. It's ok not to cite them, but may be useful to describe in a bit more detail the specific \"large 3d point cloud processing\" sub-domain this paper is addressing -- state more clearly your assumptions about the domain / problem statement. Within the sub-domain with the old work caveat above, the citations are satisfactory. \n\n--- Experimental results\n\nThe results do enough to suggest the utility of the proposed layer, especially in comparison to MinkowskiNet and some of the current current SOTA. The ablation in Table 3 is nice and shows that the abs-rel decomposition components work well together. The consistency wrt rigid transformations in Fig 3 are nice, too. \n\nThere appear to be some gaps, however: \n  1) It's important to see a comparison of the attention model to standard voxel/centroid embedding + sparseconv, not just the voxel Minkowski approach. I am concerned the gains with regards to that would be small. \n  2) Comparison of abs-rel decomposition to the basic more expensive kernel, showing the quality is comparable. \n  3) Ablation of using softmax vs cosine distance\n  4) In table 1 left, why is there no test mIoU? \n  \nA couple minor questions on the results: \n  1) In table 1 right, why did you never try EPT with 2cm resolution? Is the point cloud density a lot lower on this dataset? \n  2) For ablation in table 3 may have been better to do it with a resolution of 5cm or 2cm, as that is better performing? Generally, I assume the smaller the voxels however, the less the effect of the new modeling details. \n\n--- Clarity \n\nA couple areas could use a bit better description / explanation. When motivating cosine distance over softmax with N = 1, I assume the former could be +1 or -1 which is more expressive? Do you do any robustification for when any of the norms in the denominator are 0? \n\n\"This design (centroid-aware features) enables ESA layer to learn more coherent representation under the rigid transformations than sparse convolution based approach.\" Can you substantiate this claim in any way for rotations? Curious if there is a deeper argument to be made here than pointing to experimental results. \n\n-- Minor language/Typos\n\nIntro: “Show the lowered accuracies” \nSec 3.2: typo \"embded\"\n",
            "summary_of_the_review": "A bit on the incremental side, but generally an practical approach. It is a bit borderline to me, but with a few more ablations / clarification to the novelty, as discussed above (look forward to hear from the authors on that), I could raise my score further. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper mainly proposes a new architecture for point cloud feature extraction by applying a transformer module. It mainly contains three steps: centroids-aware voxelization, local self-attention feature transformation, and devoxelization. \nDue to the voxelization, the method is free from the heavy computation of neighboring search, and the details are encoded in centroid-aware position embeddings. The author demonstrates the effectiveness of the proposed method on two large benchmarks: ScanNet and S3DIS, and two perception tasks: semantic segmentation and 3D object detection. \n\n",
            "main_review": "Strength: the problem that the paper addressed: building an efficient architecture for 3D point cloud data feature extraction, is one of the bottleneck problems in 3D data. This paper proposes to apply a transformer module to solve the problem and shows some robustness to different transformations. Many methods have addressed this problem by using a transformer, due to its advantage to process irregular data. \n(1) The novelty of the paper is more or less incremental. In addition, the experiments are insufficient. For example, the methods proposed in [1, 2] are also applying a hybrid representation for feature extraction. \n(2). The paper fails to discuss the sensitivity of the neighboring size, which I think is of significance to the final performance.\n(3). The results of the experiments are quite confusing. For example, in Table 5, VoteNet with PointNet++ has much higher accuracy than the reported performance. In addition, using a stronger backbone like KPConv and Minkowski shows inferior results than PointNet++.\n\n[1]. Searching Efficient 3D Architectures with Sparse Point-Voxel Convolution\n[2]. Point-Voxel CNN for Efficient 3D Deep Learning\n\n",
            "summary_of_the_review": "In general, the proposed method once again demonstrates Transformer is quite suitable for 3D data processing. Although it shows some robustness to spatial transformation, the paper still has some spots that needed to clarify, as stated in the weakness part. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This submission tackles the task of large-scale point cloud processing (semantic segmentation, object detection). Motivated by the draw-backs of recent approaches (processing smaller chunks individually followed by stitching which leads to increased processing time, and voxelization which leads to discretization/quantization artifacts), this work proposes a voxelization based approach that relieves the quantization artifacts using a local self-attention mechanism.",
            "main_review": "The paper addresses a relevant aspect of processing continuous 3D data at the intersection of fast processing of large-scale point clouds and the impact of discretization artifacts due to voxelization used as data representations in current methods.\n\nThe paper also introduces a new metric that measures the consistency of the predicted labels under rigid transformations (rotation and translation). This new metric is motivated as an indicator for the impact of voxelization and how the proposed method improves on the voxelization artifacts. Under this new metric, we observe improved performance with smaller voxel sizes. This is to be expected as the voxelization artifacts become less important with smaller voxel sizes. In general the proposed method improves over the MinkowsiNet architecture by a solid margin. However, we can still observe a strong correlation between the reported scores and the voxel sizes which shows that even the new method cannot fully mitigate the effects of voxelization. Further, one would expect a diminishing improvement of the proposed method over MinkowskiNet as with smaller voxels the artifacts become less notable. However, the gap between Minkowski and the proposed method does not show a clear trend. Nevertheless, it is interesting that the proposed method appears to be more robust towards rotations - which could be seen as a step towards rotation invariant models, but this point would require further investigation.\n\nWhen compared to recent methods on the task of semantic segmentation (on ScanNet and S3DIS) the proposed method improves over MinkowskiNets at various voxel sizes. The improvement is the most significant when using relatively large voxel sizes (10 cm), and reduces with smaller voxels. This is in line with the motivation of the paper as voxelization artifacts become less important with smaller voxel sizes. At the level of 2 cm voxels, the proposed method performs similar to MinkowskyNets, i.e. it is not clear if it is statistically significant due to the lack of confidence intervals. Further, an evaluation on the hidden ScanNet test set is strongly encouraged.\n",
            "summary_of_the_review": "Overall, the paper proposes an extension of sparse convolutional networks by adding efficient self-attention layers. In experiments, the proposed method improves over previous methods in particular for large voxel-sizes. For small voxel sizes (2cm, mostly used), the improvement is less clear. In terms of processing time, the proposed method is only marginally slower than MinkowskiNets. If the code of the approach is released, the proposed method could be interesting for future developments in the area of 3D-data feature backbones. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}