{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The work discusses a neural decision layer with a DAG-connectivity and its sparseness properties. The term self-organized in the title is used to identify a sparsification process that from the initial (fully connected?) DAG yields a sparser graph with provably similar accuracy.",
            "main_review": "The idea of a self-organizing DAG-structured decision layer is, in itself, intriguing as I can see how it can prove advantageous in terms of reusing decision paths, due to removing the single-parent limitation of tree-like structures. The self-organization property can be interesting to provide a clearer insight into the decisional process, by way of pruning irrelevant decision paths. A richer structure in the decision layer might also have interesting consequences in terms of the richness of the information that can be attached to the decision nodes (e.g.  mapping DAG-taxonomies, Bayesian Networks, etc). So overall the work seems to be going into an interesting direction, but it does not seem to be going convincingly far enough down the path that is ahead. \n\nStrength:\n+ The motivations for DAG-structured decision layers are convincing\n+ The manuscript is technically sound and the associated proof are convincing (though I did not thoroughly check the proofs in appendix)\n\nWeaknesses\n- There is no clear discussion nor empirical proof of what one could expect as an advantage of the proposed method: apart from the general idea (not original from the paper) that DAGs allow to compress decision trees there are no further insights on their properties as compared to works in literature\n- Related to the point above: it is unclear if the use of a DAG-structured decision layer improves or reduces interpretability with respect to a tree (interpretability being one of the founding motivations of the use of this techniques). Is it easier or harder to interpret the SONG DAGs with respect to the model by Wan et al, ICLR 21? This is impossible to say, since Wan et al provide an articulated analysis in terms of interpretability of the discovered neural trees, including mapping of taxonomy concepts on the tree nodes, while the current paper only reports an example of a bare decision DAG for the very simple MNIST case. My suggestion is to consider how existing concepts map onto the SONG DAGs and to check, e.g. if it allows an easier mapping of more articulated ontologies (DAG structured) or perhaps BayesNet like descriptions (they are DAGs themselves). In the current version one does not understand what added value a sparse DAG offers in this sense\n- The empirical analysis is also unconvincing on the predictive performance side. First, it would be important to read clear statements as pertains training, validation and test splits, including model selection practices. Forward the reader to another paper where the same information is not easily identified is not an adequate strategy (unless the referenced paper is setting up a benchmark, which is not the case for Wan et al). Second, predictive performance does not show convincing advantages as pertains using SONG over NBDT (the former only “wins” on CIF10, which is toyish).   \n- No evidence is provided that having SONG-DAGs decisional layers brings substantial computational advantages over non-DAG neural decision layers. I warmly suggest that such a comparison is provided in the paper body.\n",
            "summary_of_the_review": "Overall, the paper fits into an interesting research line but it is not convincing in what advantage one can expect from SONG over existing approaches. There is no empirical clue, nor technical discussion, providing hints of solid advantages in terms of either interpretability, performance or computational effort. My intuition is that such advantages should be within reach of the model, but they are not convincingly analysed/experimented with in the paper, in its current version. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "It is a post processing of a DL model, e.g., CNN. The post processing method is not new since many Transductive learning on graphs has same effects.",
            "main_review": "I think the post-processing algorithm is similar to pagerank, Spectral clustering, and Ncut, transductive learning on graphs has the similar effect. \n\"Learning from Labeled and Unlabeled Data on a Directed Graph\" also used directed graphs and Markov process. I suggestion authors give more experiments comparing to algorithms like:\n1. Spectral clustering and transductive learning with multiple views\n2. Learning from Labeled and Unlabeled Data on a Directed Graph",
            "summary_of_the_review": "I think it is a post-processing algorithm and the results are not very good. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper describes a differentiable decision graph model called Self-Organizing Neural Graphs (SONGs) that can be trained end-to-end to learn a graph structure and the transition probabilities between the graph nodes to obtain a decision model analog to a Markov decision process. The model is inspired by Soft Decision Trees (SDTs) and Neural Backed Decision Trees (NBDTs) and seem to present slightly better results in comparison with these and the other competitor methods evaluated. Also, as the model is differentiable, it can be trained end-to-end in combination with deep neural networks allowing it to better deal with unstructured data. \n",
            "main_review": "## Positive Aspects of the Paper:\nThe proposed model incorporates a significant amount of novel contributions.\nThe assertions are backed up by both theoretical and empirical analyses.\nThough the results presented are just slightly better than previous models, the proposed model seems to be more practical and general due to the flexibility of end-to-end training.\n\n## Concerns and Points for Improvement:\n- The explanation of the proposed model is not very detailed and is difficult to follow. It seems that the inclusion of the theoretical analysis in the main paper resulted in a lack of space for the presentation of the model. For instance, model training, in my view a central subject in the paper, is mostly addressed only in the caption Figure 1, lacking details about, initialization distribution, when/how is the error backpropagated? after n steps?\n- Considering the lack of space, I’m not sure explaining SBDG is really necessary as a step to explain SONG. Maybe focusing on presenting only SONG would be better. \n- Mathematical elements are not precisely defined and detailed. Example: what is the difference between $v$ and $u$? Are $m^d_{ji}$ restricted to [0,1]?\n- When the paper refers to the transition probabilities, it is sometimes difficult to know if $m^d_{ji} $ or $σ_i^0 m^0_i + σ_i^1 m^1_i$ is meant.\n- Instead of referring the reader to Kronecker delta just present the equation used.\n\n## Improve Presentation:\n- Figure 3 is great but the reader should be warned that the binary matrices used are just a simplification when in fact they are matrices of real values to avoid confusion that will converge to nearly binary values at the end of training.\n- The text on some figures are too small and difficult to read.\n- In the sentence: “The first one, called node regularization, is based on (Frosst & Hinton, 2017) and encourages each internal node to make equal use of both sets of edges E0...” add and E1\n- Fix punctuation in: “Third, SONG tends to binarize what is positive in general, but if this binarization appears too early, the model can get stuck in a local minimum.”\n- number the equation before 4.2 and fix the duplicated parenthesis.\n",
            "summary_of_the_review": "I'm inclined to accept the paper considering the novelty of the proposed model. However, I'm not sure if ICLR is the best venue for it due to the limited size. If the other reviewers have no problem understanding it, I think it should be accepted.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors propose an end-to-end approach for achieving a neural graph decision architecture and theoretically and empirically show the effectiveness of their approach.",
            "main_review": "The paper is well-written and well-motivated. The authors successfully combine decision graphs with deep models in an end-to-end manner and theoretically justify the decisions. They also show the performance of the model on MNIST, CIFAR, etc. The main concern/question that I have are as follows:\n\n1- The scalability of the model. The authors show that it can be applied to medium or small sized datasets but would it be scalable to large datasets with the same performance?\n\n2- How the model would behave across modalities? Is it something that can be applied to NLP, speech, or graph benchmarks or it is tailored to vision tasks?",
            "summary_of_the_review": "The paper is well-written, well-motivated, and has a nice theoretical framework. However, it falls short on experimental side.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}