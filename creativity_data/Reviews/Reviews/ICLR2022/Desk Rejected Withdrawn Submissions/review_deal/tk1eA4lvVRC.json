{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a method to mitigate meta overfitting of initialization-based meta learning, specifically Reptile. During meta learning, for each task, instead of using the parameters of the last step to update the meta parameters, it uses a different (regularized) point in the weight space. The point is obtained fronm the direction with largest variance in the pool of the learner's weights at different adaptation iterations. The paper argues that such learning is robust to the variance in the sampling of few-shot learning tasks. Furthermore, they use a variant of self-paced learning with ensemble of networks, to make the meta-parameters robust to noisy labels in the meta training dataset. They test the method on Sinusoid regression, Mini-ImageNet, and CIFAR.",
            "main_review": "**Novelty and significance**\n+ (+) the idea of using the largest-variance direction for learner's parameter during meta learning seems to be novel to the best of the reviewer's knowledge.\n- (-) the idea of using an ensemble of classifiers (especially taken from different stages of optimization) has been around for quite a while. Just to mention a couple of works:\n\n[a] \"Self-Paced Learning with Diversity\", NeurIPS 2014\n\n[b] \"Self-Paced Boost Learning for Classification, IJCAI 2016\n\n**Hyperparameters**\n+ (+) Eigen-Reptile improves with larger number of iterations for base learner's at test time and then plateaus at update 6 and larger.\n- (-) the method has quite a few more hyperparameters compared to the baselines, this includes $\\gamma$, hps related to the decay schedule of $\\gamma$, $Q$, etc. \n\n**Clarity**\n- the paper can be significantly improved on its quality of presentation and clarity in general. For instance:\n   - I think algorithm 1 should be in the main paper since the full procedure is not clear otherwise, instead, the first part of section 4.1 can be summarized and get to the used procedure more quickly and ideally more sharply. \n   - the meta test algorithm is never discussed or presented. This should ideally come in the main paper as well. \n   - in Table 1, what is the difference between Eigen-Reptile (32) and Eigen-Reptile (64)?\n   - it was not until the experiments section that I realized it is only the meta training dataset which contains noisy labels and it is assumed that at test time adaptation it will receive clean labels. I couldn't find on a second quick glance, but even if the introduction and method sections currently reflect this somewhere, it is important to emphasize it more, not to cause confusion. \n\n**Questions to authors**\n- my first question is regarding the way the optimization of the \"main direction\" e is posed. Currently, it is found as the direction of the largest variance using the snapshots of the weights as (an unordered) *set*. However, for the purpose of using e as the direction of the task-specific updates, shouldn't e be determined directly by the update vectors instead $(w_{i+1}-w_i)$? Then probably the assumption of $\\bar{V}e>0$ would be true anyway.\n\n- In fact, to take the last question one step further, why not simply take $(w_n - w_0)$ for all tasks and use the average direction?\n\n- why is $\\bar{V}$ calculated as the mean of vectors connecting first and last, second and second last, third and third last, ... weights?\n\t\n- algorithm 1 calculates the mean direction $\\tilde{e}$. I did not find the meta-test algorithm. Is this $\\tilde{e}$ used as the direction for all meta-test tasks? If not, how is it used? If so, it is quite surprising how can a single update direction work for all possible unseen tasks.\n\n- in discussing Theorem 2, it is assumed that \"the discarded high loss samples have the same contributions $\\xi$ to $\\lambda$ and $\\lambda_o$\". How can this be the case when only clean&hard but all corrupted samples can incur a high loss?\n\n- how many iterations does algorithm 1 need before convergence?\n\n** Experiments**\n+ (+) the experiments shows a consistent and probably significant improvement of Eigen-Reptile over Reptile on various datasets and setups including clean and noisy meta training sets.\n- (-) projecting to any direction during meta training can have a regularization effect. I am missing a few baselines with regards to this fact, at least: 1) projection to random vectors, and 2) a simple meaningful direction of choice, maybe average of gradient update directions.\n",
            "summary_of_the_review": "On the one hand, the paper seems to have novelty which is conceptually simple on a simple meta learning baseline and brings consistent improvements which makes the work quite practical. On the other hand, there are several clarity and otherwise questions and concerns about the proposed method. So I keep my rating at borderline pending reading the authors' rebuttal and other reviews.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes two algorithms: one to fight sampling noise for Few-shot learning Reptile algorithm and another one, on top of that, to increase the robustness of the first one in the presence of label noise. \n\nThe first one works by defining an update direction as a minimization over the support samples. The authors were able to propose a solution that is given by the eigendecomposition of a matrix of gradient updates from a support set.\n\nThe second is a small modification over the Self-Paced Learning, that rejects samples with a high noise, thereby achieving a degree of robustness for label noise. \n\nThe algorithm seems to work fast and provide a good improvement over the baseline",
            "main_review": "The problem of sample noise is quite important given the few-shot nature of the problem. \nHowever, the paper feels very raw and unfinished. It was quite hard to read both in terms of English and math notation that the authors used. Given the issues, I'm not sure that I fully understood the contributions of the paper. Here are some of the comments that I have:\n\n* Fig.1 could be improved: black lines are not marked and absent on the second example. Grey lines are not marked. What is the difference between blur and orange nodes?\n* Notation below eq 1 is not clear. Is $U^n$ a function? How $q()$ is selected?\n* I would also clarify the logic behind the loss function `J(.)` and the whole section 4.1. To start with $\\bar w$ are introduced without definition and I'm not sure what they correspond to.\n* Why is the average direction constraint is needed? Isn't minimizing $J$ should be enough? Maybe the authors can come up with an example of when $e$ is not calculated properly. Also, $l$'s are computed from the loss function defined above eq 3, but $e$ is computed from the eq. 6. I think it doesn't matter (i.e. l would still have the same minima with constrains added), but it would be much clear if the authors just define one obj.fun right away instead of step-by-step narrative that they have selected. \n* Why is the condition on line 23 of Algorithm 1 is needed? Seems like an arbitrary hack in case the direction is not aligned with the main gradient direction. From eq.4 it looks like it should never happen. Im not sure I understand the logic the end of page 4 that explains why this constrain must remain in place. How often does this actually happen? From what I understand the Algorithm 1 the direction is chosen as the opposite, which is a pretty random choice. \n* Eq. 10 is not rigorous enough. From text $v$ (is its $v$ or $v_i$?) is binary, but the eq is not reflecting that. In fact right side of eq. 10 is unbounded, since you can factor $v_i$ out of equation.\n* Fig.2 is not clear as well. Does it suppose to motivate the algorithm? What different sample for the model suppose to represent?\n* Finally a lot of grammatical errors and stylistic errors in the paper , e.g.\n  * and the model will not only learnS the cont\n  * sampled samples\n  * Furthermore, conventional algorithms ABOUT learning with noisy labels req\n  * training A all-way classification\n  * And determine the signed distance\n",
            "summary_of_the_review": "Interesting idea of averaging the direction of all the samples to improve Few-shot Learning that unfortunately is clouded by poor presentation and notation issues.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a method to improve robustness against sample noise and label noise in the Reptile algorithm.\nTo this end, it updates the meta-parameters with the main direction of historical task-specific parameters, which is calculated by the eigenvector with the largest eigenvalue of the inner loop step scale matrix.\nIn addition, to improve the performance in label noise settings, the paper also proposes self-paced learning.\nExperiments are conducted to evaluate the proposed method.",
            "main_review": "Pros:\n- Improving robustness against sample noise and label nose is important in meta-learning.\n- The proposed solution has some novelty.\n\nCons and Questions:\n- The proposed method improves the robustness of Reptile. However, it is unclear why the authors focus on Reptile and how significant it is.\n- There are several methods that learn with noisy labels based on bi-level optimization like the proposed method [1,2,3]. It is better to discuss the relationship between these methods and the proposed method.\n- What is the definition of sampling noise? In Theorem 1, sampling noise seems to represent Gaussian noises, but in figure 1, it seems to represent what is due to the diversity of a concept. In experiments (sections 5.1 and 5.2), it seems that there is no noise. Are these experiments valid to evaluate the meta-learning capability to alleviate sampling noise?\n- It is unclear why the main direction of historical task-specific parameters can alleviate sample and label noises.\n- Could you explain the role of $\\bar{V}$ in detail used in eq. (6)\n\nMinor comments:\n- what do first $\\sum$ and $\\mathbb{E}$ mean in eq. (1)?\n- what is the difference between the terms \"inner loop steps\" and \"gradient update times\" in section 5.1?\n\n[1] Zheng, Guoqing, Ahmed Hassan Awadallah, and Susan Dumais. \"Meta label correction for noisy label learning.\" Proceedings of the 35th AAAI Conference on Artificial Intelligence. 2021.\n\n[2] Ren, Mengye, et al. \"Learning to reweight examples for robust deep learning.\" International Conference on Machine Learning. PMLR, 2018.\n\n[3] Wang, Zhen, Guosheng Hu, and Qinghua Hu. \"Training noise-robust deep neural networks via meta-learning.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.",
            "summary_of_the_review": "As described in Main Review, I have some concerns, and thus, vote to reject at this time.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces Eigen-Reptile (ER). It is a modification over Reptile meta-learning model, where the updates of the meta-parameters are done with the main direction of historical task-specific parameters. In order to accquire a more accurate main direction when noisy labels are present, the manuscript proposes the use of Introspective\nSelf-paced Learning (ISPL). Technically, ISPL is inspired by the standard SPL approach, and it constructs multiple prior models by a random sampling to discard high loss samples from the dataset.\n\nResults are reported in MiniImageNet setup. The proposed model exhibits an excellent performance compared with Reptile in the traditional meta-learning experimental setup without noise. When noisy labels are included, results are not so conclusive.\n",
            "main_review": "Strengths:\n-The comparison with the rest of works in Section 2 is addressed in the correct direction. These paragraphs clearly explain what has been done before, and WHY the proposed ideas are different. Good job!\n\n-Code is provided in the supplementary material.\n\n-The originality of the proposed ideas is relevant. No previous attempts to integrate SPL and Reptile meta-learning has been done in the way this paper describes. Eigen-Reptile approach is also novel. \n\nWeaknesses:\n\n-Clarity\na) Section 4 needs a revision to improve its readability. Too many important information is moved to the appendixes.\n\n\n-Originality/Technical. Somehow the theoretical analysis of Eigen reptile is not novel. The manuscript provides a detailed solution to overcome the computing cost of the eigenvalues and eigenvectors. But the formulation proposed can be considered as a standard PCA derivation.\n\n-Technical correctness:\na) I don't consider as correct that the proposed Eigen-reptile can be used as an approach to deal with the overfitting problem. To update the meta-parameters by the main direction of task-specific parameters does not necesarrily alleviate the overfitting of the meta-learner. Actually, this process only helps to mitigate the wrong updates of the parameters when noisy labels occur. Overall, I don't consider the proposed model as a solution for the overfitting problem in meta-learning.\nb) Technically, in a FSL scenario, where just a small number of samples for each tasks are available, is it appropriate to consider as representative for a task, the main direction of the task-specific parameters? In my opinion, this would make sense if we have many samples, which would make the direction representative for the class. Some methods (such as (Cao et al., 2019)) are used to increase the training shots in this approach, and I wonder how the approach would work when these are not used.\nc) I have a direct questions for the authors: Are the proposed ideas applicable to any gradient-based meta-learning approach? This discussion is not included in the paper, so , for the moment, I assume that they are not.\n\n\n-Experimental setup\na) Section 5 devotes too much space to the analysis of Eigen-Reptile in one scenario without addressing the issue of noisy samples, simply comparing it with Reptile. Although this experimental discussion is necessary, I believe it should be shortened in the article. Section 5.1 and 5.2 are too long, please, join and shorten them. This way, maybe some important details included in the appendixes can be incorporated into the paper (e.g. the pseudo code of the algorithms).\nb) Eigen-Reptile+ISPL has not been benchmarked with the rest of meta-learning methods. Authors should report these number in Table 1. This experiment would show how the complete approach works even with clean labels. Actually, in a real-world scenario, new tasks, with new annotations, arrive to the system, and one does not know beforehand whether they are noisy. Eigen-Reptile+ISPL should be able to deal with this situation as well.\nc) In the noisy label experiments I think I have found some deficiencies: 1) When clean labels are used ( column 1, p = 0.0 ) the numbers do not coincide with those reported in table 1, this needs and explanation. 2) Under this situation (p=0.0), ISPL does not improve the results, but degrades it. 3) When noisy labels are included, ISPL does not help standard Reptile, and just Eigen-Reptile. See the results AS with p=0.2 or S and AS for p=0.5. These numbers do not reveal the benefits assumed for the ISPL model.\nd)Instead of so many experiments in scenarios without noise (section 5.1 and 5.2), the article should also include results in other databases (e.g. Ominglot), and with noise. In this way we will be able to better judge the proposed ideas, analyzing whether the behavior holds with different databases. Results provided in CIFAR do not consider noise.\n\n\n\nMinor comments:\n\n-Page 1, Paragraph 2, lines 6 (P1P2L6): etc.. -> etc.\n-P1P2L10: the model will not only learns -> the model will not only learn\n-In figure 1, the example for label noise is not clear. Wouldn't it be better to plot the main direction of the gradients plot the green arrows for the noisy label?\n-Please, note that \"et al.\"  is a plural subject. Revise the manuscript to properly use this term.\n-Please, punctuate the equations.\n-P4P1L2 -> q(·) is not used in Eq 1.\n",
            "summary_of_the_review": "Although the ideas proposed seem novel, the article has some important weaknesses in the technical and experimental parts. Some hypotheses seem incorrect under the light of the results, and results on different databases have not been provided, in order to have more guarantees of the real applicability of the proposed model.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}