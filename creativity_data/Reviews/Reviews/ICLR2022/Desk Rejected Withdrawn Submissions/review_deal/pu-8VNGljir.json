{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "For the effective densely local features-based methods widely employed in few-shot learning, this paper points out that these methods generally perform classifications in a unidirectional query-to-support paradigm, which might be insufficient to match these local features. ",
            "main_review": "Pros:\nThis paper proposes a Mutual Centralized Learning (MCL) method to fully affiliate two disjoint sets of dense features in a bidirectional paradigm. The MCL associates each local feature with a particle that can bidirectionally random walk in a discrete feature space by the mutual affiliations, and takes the expected value of visits to support features in that class as the prediction probability for each class, which is modeled as a time-homogeneous Markov process. The strict deduction proves its reasonability of this method and experimental results demonstrate that the MCL can be utilized as a plug-and-play module in other traditional few-shot methods.\n\nCons:\n1. The concept of “particle” that could bidirectionally random walk in a discrete feature space is a bit abstract, which is not clear to understand. Please explain this concept with more words.\n2. In Section 3.6, the point 2 says that π(S) and π(Q) are calculated by Eq.(12). However, as the Lemma1 proved, π(S) should be equivalent to (x_s^Eigen)/(∑_(s^'∈S)▒x_(s^')^Eigen ). Therefore, it is not suitable to just say calculated by Eq. (12).\n3. The MCL and MCL-Katz seem to just differ in the value of α. Why not combine them into one method in the results Table, and utilize an ablation study to explain their difference?\n",
            "summary_of_the_review": "It has some innotative ideas, however,  some of the paper’s claims have minor issues.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper focuses on local-descriptor based FSL and proposes a bidirectional mutual centralized learning (MCL) method through bidirectional random walks to better use the mutual affiliations between the dense local features of the query image and support class. In addition, the authors also innovatively convert the traditional transductive methods to the inductive setting by simply treating the local features of the query image as a set of unlabeled data. Adequate experiments are conducted to verify the effectiveness of the proposed methods.",
            "main_review": "Pros:\n\n1. The motivation of introducing the mutual affiliations/information between the query and support is reasonable and interesting.\n2. The paper is well written and well organized, which is easy to follow.\n3. I appreciate that the authors reimplement DN4, DeepEMD and FRN with different backbones and different dense feature settings for a fair and thorough comparison, which well shows the potential of dense local features in FSL.\n\nCons:\n\n1. The authors use the K-shot averaged features to represent each support class. However, as we know, the spatial locations (or object’s sizes) of the local patches (objects) of different support images may not be aligned. Therefore, my concern is how to align the local features within a support class.\n2. Why use a scaled cosine similarity? Generally, a simple cosine similarity is just employed in FSL. The reason and advantage of using a scaled cosine similarity should be explained to make it clearer. In other words, as the authors said at the end of section 3.2, when ignoring the different scaling parameters \\gamma and \\tau, the local similarity matrices of the query-to-support and support-to-query are essentially symmetric. This part should be much clearer.\n3.  In the section of experiments, the authors said a pre-training stage is adopted for the ResNet-12 backbone. The details of the pre-training setting are not clear (no matter in the appendix). Importantly, it will be interesting to see the baseline’s result of only using pre-training. Also, what’s result of baseline+MCL?\n4. More analyses and illustrations on the performance of MCL and MCL-Katz are recommended to be added into the experimental section. \n5. Since the authors have re-implemented DN4, DeepEMD and FRN, why not perform them on the three fine-grained image datasets. In addition, why not report results of these methods with a backbone of ResNet-12. This will make the results more convincing.\n\n\n##########################################################################\n\nQuestions during rebuttal period: \n\nPlease address and clarify the cons above. \n\n#########################################################################\n\n",
            "summary_of_the_review": "The motivation of this paper is reasonable, the proposed method is novel, and the results are good. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies few-shot learning with dense features, which has been proved to work better than global features in the literature. Unlike prior work that does only query-to-support feature match, the authors have proposed a novel way to calculate a bi-directional paradigm that considers both query-to-support and support-to-query feature matches. They associate each local feature with a particle that random walks in the discrete feature space by affiliations between the query and support feature sets. Then they use the features' accessibility to predict the class label. The authors draw connection of their approach to graph centrality and proposed a fast solution. Experiments conducted on several different benchmarks have shown the advantages over other methods. The proposed approach can be used as a plug-and-play components to improve any FSL methods. ",
            "main_review": "Strengths:\n1. The motivation is very clear. It is very intuitive to consider bi-directional feature match between query and support sets. \n2. Although the reviewer did not check the math fully, the method itself seems interesting. The authors have draw connection with graph centrality and found a fast solution.\n3. Experimental results do show improvements of their approach over other methods.  \n\nWeaknesses:\n1. My main concern is about the inference speed. Bi-directional comparison is certainly slower than uni-directional. The authors do not make any comparison of speed in the main paper. There are some comparisons in the supplemental materials. However, it lacks some details. The authors mention the speed is for the entire method including feature extraction. As feature extraction is shared among all methods, it would be better to make a comparison only on the prediction side to get a full picture of this method. \n\n2. For the comparison in Table 1, although the proposed approach has shown better results than other baselines that are re-implemented by the authors, I would say the gap is not significant. Considering the difference between Conv 4 vs. ResNet-12 that has bring more than 10 points for almost all approaches, it does seem these methods can all benefit from a deeper feature extraction backbone. Such difference is very obvious compared to other improvements between different approaches. Other than this, I think it would also be good to compare to state-of-the-art methods following others' setting without re-implementation of others' approaches. \n\n3. The authors have used different datasets and feature extractors for different ablation study, which is a little confusing. It would be nice to fix one specific setting for all ablation study experiments. \n\n4. The ablation study experiments in Fig. 2, the gap is relatively small (<0.5) for all these different parameters. Maybe it would be good to try a larger span of parameter values. \n\n5. Minor: Table 3 caption says \"4-way 1-shot\", is that a typo and supposed to be \"5-way\"? ",
            "summary_of_the_review": "I think the method is well motivated. The solution is formulated well though I did not fully check all equations. My main concern is on the experiment side. I think the authors need to compare the inference speed where their method shows disadvantage. Ablation study needs to be conducted under the same setting and ideally show more obvious trends with various parameters. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "To tackle the task of few-shot learning, this paper leverages the theorem of single-mode centrality in their proposed method called Mutual Centralized Learning (MCL). By learning the centrality weighted vector representations for the joint set (query and support sets) with random walk, the method is able to be applied in plug-and-play manner on top of previous models using global feature matching. Experiments show that the method achieves the state-of-the-art on both miniImageNet and tieredImageNet as well as other datasets like CUB, meta-iNat, and tiered meta-iNat.",
            "main_review": "Pros:\n* The proposed method: mutual centralized learning (MCL) is strongly supported with the theorems regarding graph centrality behind.\n* The extensive results also support the effectiveness of both the MCL and MCL-Katz on several benchmarks.\n\nCons:\n* The intuition is not that straightforward. \nWhile the mutual centralized learning can benefit few-shot task (shown by the improvement in experimental results), it is not clear  which issue has been resolved by the algorithm. For example, the performance gain must come from the model resolving the inherent issues that previous models are not able to cover. What is the issue that the proposed bidirectional paradigm resolve so it improve the performance? The proposed theorem is correct but the connection with resolving the issue in few-shot learning is missing. More analysis is need to make the paper convincing instead of showing only experimental results and comparisons.\n\n* The pipeline needs more clarification.\nIt is a little bit unclear that what is the episode loss in whole MCL trying to update end-to-end. The weights of feature encoder or some parameters in random walk? If I understand correctly, the involved similarity or anti-diagonal matrices do not require additional learned parameters. In addition, what is the pipeline in inference stage for end-to-end one and plug-and-play. ",
            "summary_of_the_review": "Theoretically, the paper presents a strong learning algorithm supported by theorems. It improves previous models by a large margin. The major weakness is that the intuition is missing. Which issue appearing in the previous works does the proposed model resolve? That is the motivation may not be that straightforward. Overall, I think the paper is still worth reading for the audience.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}