{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper addresses the problem of defense of 3D point cloud network by proposing two contributions. First, a so-called CCDGN architecture is built upon the well-known model: DGCNN by smoothing neighboring features. Second, an augmentation algorithm is proposed to further boost up the model. The proposed method was evaluated on ModelNet40 and compared with state-of-the-art.",
            "main_review": "Strengths:\n1) Important research problem\n2) Well-written paper\n\nWeaknesses: I found the experiments are lacking in some aspects.\n1) First, I wonder how the proposed method performs on clean data only. In other words, would the proposed method get worse on clean data compared with its original version (i.e., DGCNN). For example, what if both DGCNN and CCDGN were test on ModelNet40 without using any adversarial attack.\n2) Second, ModelNet40 is small and synthetic dataset. I wonder how the proposed method performs on large-scale and real-world datasets, e.g., ScanNet [A], ScanObjectNN [B]\n\nMissing references:\n[A] ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes, CVPR17\n[B] Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data, ICCV19\n[C] Minimal Adversarial Examples for Deep Learning on 3D Point Clouds, ICCV21",
            "summary_of_the_review": " This is a good work. However, the method would be more convincing to be validated on large-scale and real-world datasets. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes two methods against adversarial attacks in terms of 3d point clouds. On one hand, the authors introduce a context-consistency module to smooth the noise in point clouds, and a k-measurement as a proxy of mutual information between clean and adversarial point clouds to improve adversarial robustness. An adaptive data-augmentation strategy named AA-AMS is another contribution for achieving robust models. Based on the accumulated average on clean examples during training, the AA-AMS controls the proportion of adversarial examples and mix-up samples injected into the training data. Experiment results can verify the effectiveness of the proposed methods.",
            "main_review": "Pros\n1. The context-consistency module for improving model robustness is simple yet effective.\n2. This paper finds a proxy function, k-measurement, of mutual information between clean and adversarial point cloud, and further proves the negative correlation between k-measurement and MI. \n3. This paper introduces both adversarial and mix-up examples for data-augmentation, and uses a binary threshold  for adaptive selection in such an augmentation during each step of the training.\n\nCons\n1. The correlation is not clear between the mutual information (or the k-measurement) and the robustness of the model. Theoretical and/or empirical explanation of such a correlation is required to support the idea of k-measurement.\n3. The effectiveness of CCM remains unclear. Firstly, the CCM has an additional \"conv + residual learning\" structure in each layer compared with DGCNN. Such a performance comparison could be unfair. Why not compare a module with avg pooling + residual learning to replace CCM module?\n4. What is the connection between the proposed CCM and AA-AMS? It seems to be two independent components.\n5. Ablation studies in Table 3 is incomplete. \"PointNet/DGCNN+AA-AMS\" in Table 4 ( black-box attacks ) is missing in Table 3 (white-box attacks).",
            "summary_of_the_review": "This paper includes a context-consistency module for improving adversarial robustness of point cloud classifiers, a proxy function named k-measurement to evaluate the robustness, and a data-augmentation for robust 3d networks. However, theoretical/empirical support of CCM and AA-AMS could make it less convincing. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors propose a new 3D DNN architecture, CCDGN, tailored to be more robust against adversarial examples. Further, for training, they propose a new data augmentation strategy AA-AMS, adaptively balancing the model accuracy and robustness. The architecture and augmentation strategy is then evaluated on ModelNet40. \n",
            "main_review": "This paper defines a new architecture CCDGN building on DGCNN by adding a Context Consistency Module. This module performs for every point a 2D convolution on the points neighbours followed by average pooling. The authors proceed by providing a robustness analysis inspired by mutual information through a substitute measure $M_k$ based on the cosine distance. This is motivated by Theorem 1, which states that a lower bound of the mutual information is negatively correlated with $M_k$. Further, an adaptive augmentation algorithm AA-AMS is proposed in Algorithm 1, taking into account the clean average accuracy at the current training epoch and comparing it against adversarial accuracies of perturbation and dropping attacks. Both, the architecture CCDGN and the augmentation strategy are then evaluated using the average accuracy under attack and the lowest accuracy under attack. \n\nPoint cloud robustness is an important area of research. This paper provides two novel ideas to improve empirical point cloud robustness. While most sections are easy to read, Section 3, leaves several questions open: What specifically does size of the receptive field $\\alpha$ exactly refer to? Does it referent to the kernel size? How are the neighbours of a point defined? In Definition 1: How is $d$ defined, and how is $D$ defined? Does $S_k$ from Definition 1 coincide with $S_k$ from Theorem 1? This question arrises as the cardinality of $S_k$ in Definition 1 seems to be $N$, thus coinciding with the cardinality of $S$, where as the cardinality of $S_k$ in Theorem 1 seems to not necessarily be $N$. Further, in Figure 4, the reported distances in the 4 layers in the beginning increase with the number of perturbed points, which seems intuitive. However, the drop soon after the beginning seems counterintuitive to me. Can the authors motivate why this is the case? \n\nThe results in the Evaluation seem to not significantly outperform the related work. Did the authors perform multiple runs with different seeds to substantiate the improvements? What are the variances? Could the authors also provide results on different datasets? Why is 68.30 in Table 1 fat? \n\nHow does this work relate to the following two works? Both of them investigate certified point cloud robustness. \n- “Robustness Certification for Point Cloud Models”, Lorenz et al. ICCV 2021\n- “Scalable Certified Segmentation via Randomised Smoothing”, Fischer et al. ICML 2021\n\nNo code was provided along the submission. Further no reproducibility statement and no ethics statement where provided in the paper. ",
            "summary_of_the_review": "As a core section leaves several questions to be answered and the experiments seem to lack a thorough evaluation with multiple runs to report variances and different datasets, there is currently no basis for acceptance. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduced a NN model and training strategy for processing point cloud that is robust to adversarial attacks. The NN model named CCDGN is an improvement of DGCNN and the training strategy named AA-AMS is a selection of an adversarial augmentation function that decreases the accuracy most in each epoch. The performance of the both method is evaluated in the ablation study and the complete method CCDGN+AA-AMS is compared with several combinations of model and training strategy. CCDGN+AA-AMS outperforms the other method compared in this paper in the total evaluation. ",
            "main_review": "Strength\n- The total performance is better than the other methods compared in this paper. \n- The training strategy AA-AMS is simple but it achieved some improvement in the performance. \n- The paper is well organized. \n\nWeakness\n- I thought that the conv2d([1, alpha]) in the CCM module dose not match the concept of DGCNN or other NN models for a point cloud. In my understanding, this conv2D layer is applied to the k points in the nearest order. Generally, a convolution layer is applied to adjacent data. However, this ordered data  is not guaranteed to be spatially adjacent because the third point may be in the opposite side of the second point. That's why the DGCNN employs a mlp layer for knn points in the EdgeConv module. Moreover, I think that the results shown in the table 1 supports my concern because the variation of alpha doesn't shows some kind of tendency. I therefore think that the average pooling layer may have some robustness for the adversarial attack but the conv2D layer may mean just additional parameters or a 1x1 convolution layer. \n\n\nOther comments\n- The metrics for the evaluation AAUA and LAUA is explained but I would recommend to show their definitions by equations. \n- As for the equation of the definition of k-Measurement, I understood as a summation of the all cosine distance between X_i and X_ji or X_hi. I think it'll be easy to understand if it was written with Sigma.\n- As for the Fig. 4, the most of the distances increase at first and then decrease very gradually according to the increase of the number of perturbed points. I thought that it's strange results because generally the distance should increase in proportion to the number of perturbed points. However, there are non-smooth point and it decreases the distance after that point. What is happening at that non-smooth point?\n- The performance improvement in the both ablation studies of CCM module and AA-AMS are small but the performance improvement by the CCGDN+AA-AMS is not small as the ablation studies. What is the effective thing in the combination of CCGDN and AA-AMS?",
            "summary_of_the_review": "As written in the main review,  the method proposed in this paper is outperformed in the comparison. However, I have a concern in the model design. Moreover, as I wrote some questions in this review, this paper needs additional discussions about the results.\nI therefore think this paper is weak reject. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}