{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This work aims to solve multi-source domain adaptation with data privacy protection. Concretely, this work firstly learns the statistics of source domain and then uses Gaussian Mixture Model to generate source features for domain alignment. In addition, this work designs a weight combination manner to generate the final model predictions for target samples.",
            "main_review": "My main concerns for the current version are the novelty and effectiveness of method.\n1. To protect data privacy, learning and using statistics of source domain to generate source features for distribution alignment is natural and intuitive manner. And SoFA [1] has explored this technique (GMM) for domain alignment without data exchange. Thus, the main contribution and novelty of this work is limited. In addition, I also have a question if using implicit source features for domain alignment actually exposes abundant source information to the third party.\n[1] Yeh, Hao-Wei, et.al. \"SoFA: Source-data-free Feature Alignment for Unsupervised Domain Adaptation.\" WACV 2021.\n\n2. The current version only evaluates the proposed method on four small-scale datasets. For multi-source domain adaptation, performing experiments on large-scale dataset such as DomainNet will be more convincing. Moreover, from Table 1, the baseline SHOT-Ens outperforms the proposed method in some cases. And one important reference FADA [2] is missing in experiment. It would be better to compare with FADA solving the same topic. Thus, the current experimental results are not promising. \n[2] Peng, Xingchao, et al. \"Federated adversarial domain adaptation.\" ICLR 2020.\n",
            "summary_of_the_review": "This work aims to solve multi-source domain adaptation with data privacy protection. Concretely, this work firstly learns the statistics of source domain and then uses Gaussian Mixture Model to generate source features for domain alignment. In addition, this work designs a weight combination manner to generate the final model predictions for target samples. However, my main concerns for the current version are the novelty and effectiveness of method.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper studies the data privacy challenge of multi-source unsupervised domain adaptation (MS UDA), which indicates that during the training process, the data between different sources and between sources and the target is not shared. A sequential MS UDA approach is proposed to address the privacy issue by an intermediate distribution learned on source emobeddings. A theoretically analysis is provided to show an upper bound. Experiments are conducted on four MS UDA datasets.",
            "main_review": "Originality: The studied secure domain adaptation setting is interesting, which is different from traditional DA settings. However, there are already some similar domain adaptation settings, such as federated domain adaptation and source-free domain adaptation. Please refer to \"Federated adversarial domain adaptation\", \"Universal source-free domain adaptation\". What is the difference and advantage of the proposed setting is not well explained. The technical contribution is also quite limited. The proposed prototypical GMM distribution and the final prediction as a combination of different source predictions have already been well studied, such as \"Prototypical Cross-domain Self-supervised Learning for Few-shot Unsupervised Domain Adaptation\", \"Deep Cocktail Network\", \"Distilling Domain Adaptation\".\n\nQuality: The reported results do not outperform the compared baselines. One important thing is that the comparison is unfair, since different backhones are used. For example, on Office-31, ResNet-50 is used in this paper, but AlexNet is used in MDDA. The authors evaluate the strengths to some extent but insufficient discussion on the weaknesses of the propoded method.\n\nClarity: The organization is good, but this paper is not well written. The motivation and comparison with similar topics are not well explained. The tables are confused. For example, the captions of Table 1 to 4 are not clear, what does SB, SC, MS mean is not explained, though I can infer that they are short for single best, source combined and multi source. It is wired that there is an empty Table 9. Comparison with exisiting domain adaptation in related work section is not satisfying. Adding some recent surveys would make more sense, such as \"A review of domain adaptation without target labels\", \"A Review of Single-Source Deep Unsupervised Visual Domain Adaptation\".\n\nSignificance: The results of the proposed method are not superior than the compared baselines. An expected better motivation would motivate future research.",
            "summary_of_the_review": "Interesting but already studied domain adaptation setting, lack of technical novelty, inferior performance, and insufficient analysis.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper presents an algorithm for unsupervised multi-source domain adaptation (MUDA) where learning is performed without the need to centralize all source and target data. The advantages of this paradigm are two-fold: i) preserves privacy and security of the data; ii) is beneficial when the amount of data is too large or there are bandwidth constraints. The approach is based on learning a neural network classifier on each source domain, modeling the latent distribution of each source classifier with a GMM, finetuning each feature extractor to match target and source marginal distributions, and finally ensembling the target-adapted classifiers to produce the final predictions. A theoretical analysis of the algorithm is presented and its performance is evaluated and compared with SOTA in a few benchmark datasets.",
            "main_review": "The paper has an important and well-defined motivation. The proposed methodology is described clearly and the paper is generally well written and pleasant to follow. Nonetheless, I have some concerns about the proposed methodology, specifically:\n\n(-) Although source data are not shared between any two sources and between each source/target pair, a trained neural network is indeed transferred to the target for finetuning. It is known (Melis et al, 2018) that data and feature leakage happen through the network parameters. Thus, avoiding sharing the raw data is insufficient to ensure that privacy is preserved.\n\n(-) The problem of negative transfer is overlooked. The authors try to mitigate it by employing the conditional entropy loss as a regularizer in the adaptation objective, but they should elaborate more on why such an approach is effective. Consistency regularization, as employed by e.g. Wang et al. (2020), Pernes and Cardoso (2020), have been adopted in literature and proven successful.\n\n(-) The assumption that there is a 1-to-1 correspondence between each class and a mode of the latent distribution is not obvious, even less when such latent space is high-dimensional. Thus, the decision of setting the number of components in the GMM to the number of classes seems questionable. I would like to see experiments showing how the performance varies when more components are used.\n\nI think the experiments have a few problems as well:\n\n(-) All datasets used for evaluation consist of image data. However, in principle, there is nothing that prevents the method from being used with other types of data. I suggest presenting results e.g. in the Amazon Reviews (Blitzer et al, 2017) dataset.\n\n(-) Office-Caltech is an extension of Office-31, so showing results in the former would suffice. On the other hand, the authors show no results in the important DomainNet dataset (Peng et al 2019), which has six domains and ~600k images from 345 classes, so it is much larger than any of the evaluated datasets.\n\n(-) An ablation study showing the effect of the conditional entropy loss for various values of $\\gamma$ is missing. This could help support the claim that this term mitigates negative transfer.\n\n(-) The method outperforms most SOTA MUDA algorithms, even those where all the source and target data are aggregated for training. However, there is no apparent reason for their method to outperform those since the setting here is harder in principle. Why are those gains observed, then? Would the proposed algorithm perform even better if the training was performed without the constraint of not sharing data between domains?\n\nFurthermore, the authors should review the statement in Theorem 5.1, since it is worded sloppily. This is a probabilistic bound, which depends on the choice of samples, and nothing in the theorem statement formalizes this. All terms in the bound should be formally defined as well.\n\nRefs.:\n\nMelis, Luca, et al. \"Exploiting unintended feature leakage in collaborative learning.\" 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 2019.\n\nWang, Kaihong, Chenhongyi Yang, and Margrit Betke. \"Consistency Regularization with High-dimensional Non-adversarial Source-guided Perturbation for Unsupervised Domain Adaptation in Segmentation.\" arXiv preprint arXiv:2009.08610 (2020).\n\nPernes, Diogo, and Jaime S. Cardoso. \"Tackling unsupervised multi-source domain adaptation with optimism and consistency.\" arXiv preprint arXiv:2009.13939 (2020).\n\nBlitzer, John, Mark Dredze, and Fernando Pereira. \"Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.\" Proceedings of the 45th annual meeting of the association of computational linguistics. 2007.\n\nPeng, Xingchao, et al. \"Moment matching for multi-source domain adaptation.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.",
            "summary_of_the_review": "The paper is interesting but there is room for improvement. The employed techniques are appropriate but rather straightforward and non-novel. For this reason, I think the paper would have to be more exhaustive and flawless in the experimental evaluation to be presented at ICLR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper aims to tackle the multi-source domain adaptation problem in a privacy-preserving manner: source data is inaccessible in adaptation process. For this purpose, authors utilized a \"data generation\"-like approach, which is straightforward: since we cannot access the source data, we can learn to generate its distribution in the source-only training process. Then, we can use the generated distributions to perform distribution matching for adaptation. For the inference on target, authors utilized a voting process. Experiments verify its effectiveness.",
            "main_review": "### Strength\n1. The problem setting is clear and realistic, meaningful to real-world applications.\n2. The method presentation is clear, making the paper quite easy to follow.\n3. Experimental results are fine.\n4. There are some theoretical analysis.\n\n### Weakness\n1. The problem definition has some overlap with \"source-free domain adaptation\" as SFDA also cannot access the source data. Plus, it also cannot access source models, which is more challenging than this setting. Moreover, it is hard to understand this setting \"the source data is inaccessible after its first training\". Since you cannot access it, why can we train it for the first time? From the privacy-preserving view, I think this setting is just a relaxed case of SFDA. Also, there is a recent paper on multi-source free DA [1] working on the same problem.\n2. The idea and method are not novel. Generating source distributions in face of inaccessible source data is not uncommon. It has been used in several source-free DA methods [2, 3, 4].\n3. There lacks motivation for choosing the sliced Wasserstein distance as the distribution matching measurement. From what I see, any distribution matching methods can replace it.\n4. One interesting question to ask: if we can learn GMM from the source models, then are we leaking training data?\n\nReferences:\n\n[1] Ahmed S M, Raychaudhuri D S, Paul S, et al. Unsupervised Multi-source Domain Adaptation Without Access to Source Data[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 10103-10112.\n\n[2] Li R, Jiao Q, Cao W, et al. Model adaptation: Unsupervised domain adaptation without source data[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 9641-9650.\n\n[3] Hou Y, Zheng L. Source free domain adaptation with image translation[J]. arXiv preprint arXiv:2008.07514, 2020.\n\n[4] Tian J, Zhang J, Li W, et al. VDM-DA: Virtual Domain Modeling for Source Data-free Domain Adaptation[J]. arXiv preprint arXiv:2103.14357, 2021.",
            "summary_of_the_review": "Overall, I think this paper is good, but its novelty is rather limited to be accepted by ICLR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}