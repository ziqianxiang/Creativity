{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors tackle the data heterogeneity in federated learning and proposed a novel data-free distillation method, namely FLBoost, which consists of a set of algorithms, such as focused knowledge distillation, attention-based ensemble, and adversarial learning schemes to train the global model and the generator.\n\n",
            "main_review": "This paper is well-written and easy to understand. The motivation is clear and the concept illustration is helpful to capture high-level ideas. The proposed method seems intuitive and technically sound. \n\nI have a few questions while reading this paper:\n\n\n- Additional server-side training costs per round: as the proposed method requires additional server-side training, many readers might want to know how long it will take in one communication round. \n\n\n- The trade-off between Performance vs Finetuning steps ($I$, $I_g$, and $I_d$): Can you provide an analysis of the effect of the different numbers of $I$, $I_g$, and $I_d$?\n\n\n- Learning curves for Table 2: can you provide learning curves corresponding to Table 2? It is way more insightful to see plots rather than analyze tables.\n\n\n- More datasets: please use more datasets and show if the results are consistent since some performances seem marginal compared to the baseline models.\n",
            "summary_of_the_review": "Overall, I enjoyed reading the paper. I'll raise my score if my concerns are successfully addressed.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper tackles the data heterogeneity challenge in federated learning from the aspect of model aggregation on the central server, which is different from many existing works focusing on the model update on the client. The authors propose a data-free knowledge distillation method dubbed FLBoost to enhance the model aggregation step. Specifically, a generator with an adaptive sampling scheme is trained to recover diverse yet fidelity data in the image space, and an attention-based ensemble scheme is leveraged for model aggregation. FLBoost is orthogonal to many client-level methods. Experiments on CIFAR datasets demonstrate the effectiveness of FLBoost.",
            "main_review": "## Strengths\n* Writing is well-organized and easy to follow.\n* FLBoost is effective on CIFAR datasets and outperforms other server-level methods under the same condition. Also, FLBoost is compatible with client-level methods, which is a benefit.\n\n## Weaknesses\n* This paper has marginal novelty. The proposed method FLBoost is incremental compared with FedGen [1] which also uses the data-free distillation. FLBoost uses the reweighting schemes for image generation or model aggregation, which are common operations and not novel. The remaining novelty seems to be the adversarial training scheme.\n\n* The experimental comparisons are problematic. **First**, experiments are conducted only on two small CIFAR datasets, which is far from extensive as claimed in the introduction. Results on other common benchmarks like Tiny-ImageNet or CINIC-10 are required. I also encourage the authors to provide results on large-scaled realistic datasets in [2]. **Second**, the experimental comparisons with other baselines are messy and unfair. FLBoost uses the state-of-the-art method SCAFFOLD as the default client-level method, while FedGen and FedDF [3] use the old method FedAvg. However, the authors did not remind the readers, and directly compared them in Table1, which is quite misleading. I think Table 1 and Table 3 should be changed to include results of the complete combinations between server-level methods (the # is 3) and client-level methods (the # is 4) on all datasets. Even based on the current results, if the client-level method is SCAFFOLD for all three methods in Table 3, I find the accuracy gaps between FLBoost and the other two server-level methods are significantly decreased. **Third**, I think using figures rather than tables to show the convergence is more straightforward. Figure 6 can be put in the appendix to give space for more results.\n\n* The proposed method explicitly violated the privacy protection regulation in FL: 1. Uploading classes statistics on the clients. 2. Recovering images of clients on the server. It is not a good clarification using the violation of other works to defend the proposed method.\n\n## Comments\n* Missing related works: client-level method MOON at CVPR'21 [4].\n* Symbols not clarified or formulations missing: Symbols inTable 4 are not consistent with those in Section 3.1. The diversity loss is missing both in this submission and FedGen. \n\n## References\n[1] Data-Free Knowledge Distillation for Heterogeneous Federated Learning, ICML'21\n\n[2] Federated Visual Classification with Real-World Data Distribution, ECCV'20\n\n[3] Ensemble Distillation for Robust Model Fusion in Federated Learning, NeurIPS'20\n\n[4] Model-Contrastive Federated Learning, CVPR'21\n",
            "summary_of_the_review": "In conclusion, I think this submission has weaknesses in the method novelty, experimental validation, and privacy concern. Thus, I decided to give a rating of 5 at the current stage.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "To tackle the heterogeneity challenge, this paper proposes on-the-fly fine-tuning the global model in server via data-free distillation to boost performance. Specifically, it utilizes an adversarial distillation scheme to generate pseudo data to fine-tune the global model. To maintain the consistency between the generated data and the overall data distribution of the clients, it utilizes focused knowledge distillation which considers the proportion of the amount of data in each category. In addition, it performs an attention-based ensemble according to the number of samples in each category of each client. This paper tries to solve data heterogeneity from the perspective of the server and it can achieve acceptable performance.",
            "main_review": "The work is interesting and makes sense to some extent. However, it still suffers from the following limitations: \n1. The method is not novelty enough. Data generalization in an adversarial style is a common way to obtain data and it has been introduced to federated learning. To obtain better performance, this paper only takes the proportion of data in each category into consideration, which may be not novelty enough.\n2. It is better to explain whether the data heterogeneity means label distribution shifts, the imbalance of the category, or other offsets. Data heterogeneity is a wide concept while this paper mainly focuses on label distribution shifts among clients.\n3. Please explain the meaning of 'wrong' in 'FedGen ignores the wrong knowledge in data heterogeneity scenario'. What is \"wrong\"?\n4. Please explain the meaning of R in Equation (4). This symbol is introduced and used without any explanation.\n5. Since there exists much work about label distribution shifts, it is better to utilize some common datasets and settings with existing work. For example, FedGen utilizes MNIST and some other datasets while MOON utilizes CIFAR-10, CIFAR-100, and Tiny-Imagenet. There is no need to perform all experiments from scratch, which may make results unconvincing.\n6. Please explain how to evaluate the performance. According to Equation (1), the goal of federated learning is to perform well on all clients, which means there needs a special test dataset for each client. In this situation, some methods, such as FedBN, which obtain different models for different clients may obtain better results.\n7. Since the paper focuses on label distribution shifts, it is better to evaluate on more datasets, including imbalance datasets. In addition, it is better that test sets and training sets have different label distributions. In reality, we have no prior on real data distribution in the server and it might be wrong to treat the combined data of all clients as the real distribution.\n8. Since the method generates data in the server with a large amount of computation, it is better to show time complexity of the proposed method.\n9. Some explanations of results are not clear enough. For example, FedGen is better than FedGen* while FLBoost-f is worse than FLBoost. In addition, it is better to add SCAFFOLD+FedGen* in Table 3.\n10. There are still some other problems to solve. For example, it is better to show the entire training process in Figure 3. In Table 4, it is better to keep the same setting with other experiments.\n\n",
            "summary_of_the_review": "Overall, I recommend rejecting the current version of the paper based on the above analysis.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}