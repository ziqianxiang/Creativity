{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a framework that combines the proposed Self-Organizing Maps models with relevance learning  (SOMRL) with autoencoders.  Under this framework, the SOMRL module can be jointly updated with autoencoders with gradient-based optimization. The authors justify the proposed method with both quantitative and qualitative results on benchmark image datasets.",
            "main_review": "This paper presents an interesting method to learn interpretable representations in time-series data with SOM-based techniques. The authors propose SOM with Relevance Learning to achieve gradient-based optimization, where each node in SOM competes with the relevance in a weighted form, and this weight will allow further insertion/removal operations. The SOMRL method can be naturally applied to autoencoder architectures to enhance representation learning.\n\nFrom the side of technique in the paper, the proposed method well addresses the difficulty of the non-differentiability of the SOM-based method, but it seems the advantage/inconvenience of this method is not sufficiently elaborated in the paper. After reading this paper, I had difficulty in finding reasons that convince me to prioritize these method over other SOM-based method. It could be better if the authors could provide more theoretical/empirical analysis on the differences. \n\nThe experiments show the results of clustering with SOMRL-AE, with k-means, SOM-VAE, DE-SOM^2 as baselines. From table 1, the SOMRL does not seem to show consistent improvement over these baselines. Especially, SOMRL cannot outperform k-means in some settings, which weakens the significance of the proposed method.     \n\nThe Lc weighted coefficients seem to be relatively small, according to table 2. Could the authors provide some ablation on the effect of Lc?\n\nMinors and typos:\n\nestablhishes -> establishes",
            "summary_of_the_review": "This paper shows an interesting way to deal with the SOM-based methods but lacks corresponding both theoretical and empirical analysis, and the clustering results do not show consistent improvement. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes to combine self-organizing maps (SOMs) with relevance learning (SOMRL), based on the LARFDSSOM model, with autoencoders (AEs) for representation learning. The authors assess the clustering performance on (Fashion-)MNIST benchmark data and qualitatively assess the interpretability of the learned representations.",
            "main_review": "Strengths:\n- Learning interpretable clusterings is an important problem\n- The proposed model seems to be novel\n\nWeaknesses:\n- Many design choices are not fully motivated\n- The hyperparameter tuning is questionable\n- Some relevant related work/baseline is missed\n- The empirical performance is rather poor\n\nDetailed comments:\n- There are many design choices in this model, such as the form of the activation function ac, the repel function, the relevance function omega, and the neighborhood function h. I have a hard time understanding why these functions are chosen exactly as they are. Are there mathematical reasons that motivate these choices, e.g., guarantee some kind of convergence? Or could those choices be different? If they are arbitrary, I would at least expect some empirical ablation studies that compare them against alternative choices for these functions.\n- There are many hyperparameters, e.g., a_t, lr, rho, ld, beta, s, gamma, and alpha. As far as I understand, these are tuned based on the clustering performance on the benchmark data. However, to compute this performance, one needs access to ground-truth labels, right? So in my understanding, this procedure turns the whole model into a supervised one, while clustering and representation learning are usually unsupervised tasks. That is, I wonder whether these parameters could not be tuned in some unsupervised way, which would seem much fairer also compared to the baselines, which often do not use supervised hyperparameter tuning.\n- It is claimed that the SOM-VAE and DE-SOM are the only relevant related models, but this overlooks the DPSOM [1] and T-DPSOM [2]. Since this model seems to outperform the other two (at least according to their paper), it should probably also be considered as a baseline in the experiments.\n- The empirical clustering performance of the proposed model is rather poor. While it is claimed that the performance is 'competitive' with the baselines, I think an NMI of 0.40 vs 0.54 (on FashionMNIST), that is a relative difference of 35% in performance, seems like quite a large margin to be called competitive. I think it should be discussed in more detail, why the proposed method performs so badly (even worse than the simple k-means baseline actually).\n- It is claimed that the relevance learning of the dimensions works well, given that only about a third of dimensions are highly relevant. However, while it does mean that the latent SOMRL can identify the relevant dimensions, it also means that the AE, which is trained in parallel, only encodes relevant information in a third of the dimensions. That seems like a wasteful way of training the AE. Could this be overcome with a smaller latent space, that is, if the latent space only had a third of the dimensions, would all of them be relevant? Generally, it seems that using more dimensions to encode the relevant information should be better for reconstruction and also for clustering, so it's curious that the dimensions are not used by the AE model. I think this should be further examined empirically.\n- The visualizations in Fig. 5 could be equally plotted for the baselines, right? I think this would be necessary to compare how interpretable the representations of the proposed method really are, compared to the baselines.\n\n\n[1] Manduchi, L., Hüser, M., Vogt, J., Rätsch, G., & Fortuin, V. (2019). DPSOM: Deep probabilistic clustering with self-organizing maps. arXiv preprint arXiv:1910.01590.\n\n[2] Manduchi, L., Hüser, M., Faltys, M., Vogt, J., Rätsch, G., & Fortuin, V. (2021, April). T-DPSOM: an interpretable clustering method for unsupervised learning of patient health states. In Proceedings of the Conference on Health, Inference, and Learning (pp. 236-245).",
            "summary_of_the_review": "The proposed method has a lot of unmotivated design choices, tunes the hyperparameters in a supervised way, and only yields poor performance compared to baselines, while not even all relevant baselines are considered. Based on this, I can only recommend rejection at this point.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper presents a representation learning framework that models the latent space of an autoencoder with self-organizing maps (SOM) with relevance learning. The SOMRL appeared to be based on a previously published work, and the main contribution of this paper is to combine the SOMRL with an AE. The method was evaluated on MNIST and FAshion-MNIST, and was compared to k-means and two other SOM-based autoencoders for clustering performance. Interpretations of the learned feature relevance and SOM prototypes are also presented.",
            "main_review": "Strength: \n\nThe SOMRL in the latent space, through the relevance vector, was able to provide interpretation as to which features are more important for clustering. This provides interesting values to deep clustering approaches. \n\nSOM in the latent space also allows the visualization and understanding of the relationship of the learned prototypes/clusters, which is not always available with other clustering methods.\n\n\nWeakness:\n\nThe contribution of the paper seems to be limited to incorporating SOMRL in an autoencoder architecture. It is not clear to which extent SOMRL itself has been previously published (section 3), or how much the reported SOMRL in section 3 was different from the method described in Bassani & Araujo 2015. It'd be important for the authors to clearly clarify their contribution in SOMRL. The contribution would be rather limited if the SOMRL was more or less previously published, and this work is limited to incorporating it within an AE.\n\nWhile the relevance learning is interesting, the motivation for being able to change the topology (node insertion and removal) of the SOM is not clear in this paper, and did not seem to be demonstrated in the experiments. Surely being able to change topology has its merit, but its value in this particular work was not clearly described. Emphases were put on the relevance vector, which seems to be achievable even using a fixed topology (no insertion or removal of nodes).\n\nThe comparison of clustering performance was limited to k-means and SOM-based autoencoders. It'd be necessary to include other deep-clustering methods for comparisons.\n\nTo understand the relevance vectors, it would be more meaningful to show 1) what latent features were considered relevant for each data set, and 2) whether and how these relevance vectors change from node to node. The global histograms in Fig 2 provided limited insights into the interpretation and benefits of the relevance vectors.\n\n\nIn Fig 5, please clarify about the positions of the prototypes presented. How were the positions of the prototypes determined on the visualization? It says in the text that \"connected prototypes are considered somehow similar\" --- few connections were seen in the prototypes within the same cluster? How far away are those prototypes? Instead of visualizing the prototypes in the t-SNE projection, it'd be much more intuitive to directly visualize the SOM in its own 2D grid (and perhaps color code the prototypes/nodes with the corresponding classes (for the majority of the samples it represents). After all, a main purpose of SOM is for visusalizing high-dimensional data.\n",
            "summary_of_the_review": "This paper provides some interesting ideas for deep clustering, especially in the possibility to provide interpretation to the relevance of the feature vectors in clustering. The work in its current form however is limited in contribution, and the improvement over existing deep clustering works needs to be better demonstrated. The benefits of many components of the method, such as topological change and feature relevance, can also better evaluated and demonstrated.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}