{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors propose a framework called 3D-MolGNN_RL to accelerate the discovery of novel drug candidates. With the aid of RL and a deep generative model, their approach generates small molecules specific to a protein pocket.",
            "main_review": "A fundamental weakness of this paper is that it lacks novelty, and for this reason, I consider it unsuitable for this venue. A (medicinal) chemistry-focused journal would be more appropriate.",
            "summary_of_the_review": "The presented manuscript does not contain the required novelty with respect to ML methodology to be of interest to the target group of this venue.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this manuscript, the authors developed an actor-critic RL framework for protein target-specific scaffold-based inhibitor design. Unlike the related works concentrated on generating molecules’ 2D representation, their RL agent generates 3D molecules by placing atoms in 3D space step by step. Utilizing GNN predictors, their RL critic could also capture 3D information from both target protein pocket and generated molecule to access whether the generated molecules satisfy the desired properties. Since the 3D molecule structure contains more information than 2D representation, the idea of this work is guaranteed. However, the paper looks underdeveloped with several writing errors and some important experiments are missing, more importantly, the evaluation is not convincing enough.",
            "main_review": "Specific comments follow below.\n1.\tThe spotlight of this manuscript should be the idea to generate 3D molecules and utilize 3D structure information of both target protein pocket and generated molecules. However, no ablation study was designed to prove their effectiveness.\n2.\tThe author seems to avoid comparing the binding affinity of the molecule generated by the 3D-MolGNNRL and other methods to the target pocket. The predicted affinity shown in Figure 2 is obviously not convincing enough. As far as I know, only through web-lab experiments can the superiority of 3D-MolGNNRL be proved. It’s necessary since the binding affinity is one of the most important metrics for designing protein target-specific inhibitors.\n3.\tThe atom placing agent is not clearly described. How to define ‘the next GT atom’ and does the structural symmetry and chirality taken into consideration? Generating 3D structures is more likely to produce invalid molecules, so have you tried to address this problem? How to deal with the contradiction among predicted pairwise distances and then determine the placed atom’s coordinate? Constructing atom distribution from a predicted pairwise distance seems to have been out of date, have you considered end-to-end atom coordinate prediction like AlphaFold2 do?\n4.\tWhy does 3D-MolGNNRL use the reward for every intermediate step of molecule generation while PM-GNNRL uses the reward at just the terminal state? Is there something that limits PM-GNNRL‘s reward usage in intermediate steps? Isn’t it unfair?\n5.\tThe author should try to explain why PM-GNNRL outperforms 3D-MolGNNRL when measured by QED or SA score. Is the 2D representation easier to capture these properties compared to the 3D structure?\n6.\tThe analysis of Table 1 is confusing. The authors chose only the top 3 candidates here, trying to prove that ‘molecules that are performing above average in one metric are not guaranteed to perform well in every metric’. Firstly, the chosen case is too few to prove the authors’ point of view. Secondly, this point of view is meaningless, considering the previously mentioned ‘A desirable drug candidate would score well in each of these metrics ‘, this analysis seems to show that both 3D-MolGNNRL and PM-GNNRL are not developed well enough.\n7.\tThe authors emphasized that ‘by incorporating more parameters into the multi-objective reward function, there is an improvement in the generation of novel drug candidates. Is there any theoretical support for this view? I believe that it is better to design a reward function that encourages diversity would be more effective.\n8.\tThe writing should be improved, there are several writing errors like ‘They key differences between the two methods’, and ’Firstly the from the protein-VAE’.\n",
            "summary_of_the_review": "I recommend the rejection of the paper due to the weakness I mentioned above at this time. I think these issues will have to be addressed before this manuscript can be considered for publication on ICLR2022.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper describes a method (3DMol-GNN) for generating small molecules with improved binding  against CoV2. Unlike existing methods, 3DMol-GNN 1) encodes the 3D structure of the CoV2 target instead of its protein sequence, and 2) generates molecules atom-wise instead of a SMILE string.",
            "main_review": "* The paper lacks essential ablation experiments and baselines to show the benefits of the proposed method.\n* The two contributions of the paper of 1) encoding the 3D structure the protein target, and 2) generating molecules atom wise, are not motivated clearly enough.\n* The paper is overall hard to understand due to jargon, a suboptimal structure, and spelling errors.",
            "summary_of_the_review": "1) Please motivate more clearly the benefit of generating 3D molecules instead of 2D molecules\n2) Please motivate more clearly the benefit of using the 3D structure of the target protein instead of just the protein sequence. The 3D structure is not always given and encoded in the protein sequence.\n3) Please show by ablation how the performance is affected by\n     - using the protein sequence instead of the 3D structure to encode the protein target\n     - generating a molecular graph instead of atoms of the molecules\n     - generating a SMILE string instead of atoms of the molecules\n4) Please compare to PaccmanRL \n5) Please also compare methods when used for generating molecules against protein targets other than CoV2.\n6) Please analyze if your method transfers knowledge learned by optimizing targets against one protein target to generate molecules against another protein target.\n7) Section 1.2 is partially redundant with section 1.1 and section 3, e.g. the differences between PacmanRL, PM-GNN, and 3D-Mol GNN are described multiple times. I suggest removing section 1.2 and describing methods clearly in section 3.\n8) Section 2 is hard to understand without knowing details about the method described in section 3. I therefore suggest describing details about the dataset in section 4.\n9) Section 3.1: Please motivate why you used two critics to predict both the activity and affinity. Why is it insufficient to predict the affinity alone? Molecules that do not bind should have a high affinity.\n10) Section 4: Please describe more clearly the  'unoptimized' baseline. What is unoptimized compared to PM-GNN and 3DMol-GNN?\n11) Throughout the paper: avoid or describe jargon such as 'scaffold', 'conformer', or 'piperazine' to make it more accessible to the general machine learning conference.\n12) Throughout the paper: avoid spelling and grammatical errors. \n",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes 3D-MolGNN_{RL}, a scaffold-based generative model of molecules that builds samples atom-by-atom by placing them in 3D space. Additionally, this work also introduces a simpler variant called PM-GNN_{RL}. The authors then evaluate both models on the task of generating molecules that bind to a specific protein target. The models achieve high binding scores while staying within reasonable values of several simple molecular properties.",
            "main_review": "### ===== Detailed pros: =====\n\n1. The paper focuses on binding affinity prediction, which is closer to real-world tasks that some of the tasks often studied in the literature (e.g. plain logp optimization). Moreover, it considers a scaffold-constrained case, which is again relevant for real-world drug discovery.\n\n### ===== Detailed cons: =====\n\n1. The results in the paper are unconvincing: \n\n- (a) In terms of activity, it seems the models are only compared to their untrained counterparts, which is a useful sanity-check, but otherwise a rather low bar. It would be more useful to also compare with some off-the-self generative models that can optimize towards any objective, like MSO [1], MNCE-RL [2], MoLeR [3] or baselines from Guacamol [4]. Otherwise it's hard to tell if 3D-MolGNN_{RL} is bringing anything in terms of performance. While the fact that (unlike most models) it operates directly in 3D is interesting conceptually, there should be empirical evidence that this actually works better than well-established models that generate 2D SMILES or simple molecular graphs. \n\n- (b) There are comparisons with existing active molecules, but only on simple properties (not on activity), and moreover it's not clear how strong of a baseline this is (i.e. how exhaustive this pre-existing set of actives is), so again comparing to existing models would make more sense. \n\n- (c) While going for a scaffold-constrained setting sounds promising, there should be evidence that this actually helps here. For example, one could run the models starting from scratch (empty graph), and see if the scores/metrics are worse in that case. Moreover, only one scaffold is tested, and it's a rather small one; it would be interesting to see more variety on that front. \n\n- (d) Apart from activity, the other investigated metrics are more of sanity checks than very strong indicators that the molecules are reasonable. It would make sense to also run some quality filters (e.g. [5] or similar), and compare the pass ratio of generated molecules with those generated by other models or existing in the training data. \n\n- (e) The comparison of Validity/Uniqueness/Novelty isn't very useful, as all models get scores close to 100% anyway, and it's unclear if pursuing 100% novelty instead of 93% is meaningful (and indeed, these three metrics are known to be an extremely weak sanity check, as any *untrained* graph-based model employing valence checks gets 100% on all of these by design). \n\n2. Novel parts of this work are not well separated from parts reused from prior works; also, the discussion of prior works should be extended: \n\n- (a) It seems most of the modelling novelty is already present in 3D-Scaffold and SchNet, whereas this paper mostly adds the (rather uncomplicated) RL component, and performs the empirical evaluation. While the latter is obviously a good contribution too, given milder novelty, for acceptance I would expect a more thorough empirical evaluation (see point (1) for reasons why I think it's currently insufficient). \n\n- (b) The related works section should also refer to more modern fragment-based generative models, like HierVAE [6], and its extension to scaffold-based generation MoLeR [3]. Many more other scaffold-based generative models exist (e.g. [7]) (both graph-based and SMILES-based), and given that this paper continues that trend, it would make sense to refer to them too. Finally, there are works on docking score optimization [8], which use 3D at least implicitly due to calling the docking software, these should be discussed as well. \n\n3. Flow of the paper could be improved: \n\n- (a) The paper introduces two methods (PM-GNN_{RL} and 3D-MolGNN_{RL}) side-by-side, whereas a lot is shared, and it's unclear if some of the differences are inherent to the different approaches or not. For example, as I understand these two methods use different training datasets, and optimize towards different reward functions; this makes it hard to attribute performance differences. If the reason for introducing PM-GNN_{RL} was to ablate some of the design choices in 3D-MolGNN_{RL}, then I'd encourage the authors to present it as an ablation, and ablate all the choices of interest in separation (training dataset, reward function, the use of 3D, or any others choices they wish to ablate). Also, the different variants should be easy to compare, while currently Figure 2 shows them separately (side-by-side), making comparison harder. \n\n- (b) Using two different reward functions R1 and R2 is a detail of the experimental setup, so introducing it when defining the model/method complicates things unnecessarily, since (as I understand) the framework is agnostic to the exact form of the reward function. If so, it's also confusing to include R1 and R2 (separated by a logical OR symbol?) in the explanatory Figure 1. \n\n4. While some details of this work and prior works it builds on are expanded on in detail, others are skipped or unclear: \n\n- (a) There is some explanation on how atom coordinates are predicted, but then no mention of how inference works exactly (I understand that at inference time, the model predicts distance buckets for every existing atom, but figuring out where the new atom should be sounds like an optimization problem in itself?). Some parts of the text talk about making predictions with respect to centre of mass (which I think comes from 3D-Scaffold?), but then that is not expanded on. \n\n- (b) As far as I understand SchNet, it uses an all-pairs information propagation scheme, so in a way it's not something that would normally be called a GNN, because no edges are specified (the graph is fully-connected by design). On the other hand, lots of naming in the paper (GNN_P, 3D-MolGNN_{RL}, PM-GNN_{RL}) is GNN-centric, which can be confusing for readers unfamiliar with SchNet. \n\n- (c) The dataset description in Section 2 is confusing: it seems the dataset was obtained in several rounds, by first training the GNN_P critic, and then using it to filter the data for some subsequent training. This should be clarified and there should be justification/ablation for why this two-step procedure was used. \n\n- (e) The method does not produce bonds explicitly, but implicitly through the 3D geometry. I understand the authors then use some off-the-shelf tool to infer the bonds to e.g. construct SMILES strings and be able to compute the various downstream metrics using rdkit. Yet, I couldn't find any mention of what tool is used for this. \n\n- (f) \"The policy is defined as the difference between the action-probabilities and the reward assigned by the critic at that step\" -> is this describing how actions are picked at inference time, or something else? \n\n- (g) The authors say they use various filters on the returned molecules, but then e.g. compute validity and it's not 100%. I'm wondering how that is possible, given that it seems evaluating the filters requires parsing the molecule with rdkit, so anything that survives the filtering should have 100% validity by design. I thus suspect Table 2 refers to raw unfiltered compounds, in which case that should be said explicitly. \n\n5. Many parts of the text are convoluted or hard to parse; I would encourage the authors to revise the text and also simplify the sentences in general, focusing on conveying the key information. Some examples which are unclear: \n\n- \"candidates with suitable activity against specific protein targets only narrows the search space significantly based on the critical fragments.\" \n\n- \"Here, we achieve fine-tuning by strictly filtering the training data.\" \n\n- \"Since 3D-Scaffold learns to predict atoms in 3D space, it is easier to convert the partially produced molecule to a GNN readable format\" -> I'm assuming you mean \"SchNet readable format\", which would then make sense, since SchNet needs to know atom positions. On the other hand, a \"GNN readable format\" would classically mean \"atoms and bonds\", so predicting 3D positions instead of explicit bond/bond types would actually make it harder to apply an off-the-shelf GNN. \n\n### =====  Other comments / nitpicks: ===== \n\nHere are several small problems not mentioned above; improving these would make the reading experience smoother: \n\n- The \"Related Works\" section starts with \"The current work\", which is not clear if it refers to the work done by the authors or the prior work (the latter, judging from the context, but this should be clear). \n\n- \"As an alternative, RL would provide\" -> \"(…) provides\" \n\n- \"To represent the definition of scaffold, we used Murcko scaffolds\" -> \"represent\" doesn't really fit here \n\n- \"The similar dataset\" -> \"A similar dataset\" \n\n- \"Both protein-VAE\" -> not clear which two protein-VAEs do you mean there \n\n- \"The RL workflow begins from\" -> \"from\" isn't the right word here \n\n- Figure 3 shows some curves, which I'm guessing aren't the real property value distributions, and rather gaussian distributions fitted to the values; if that's the case, this should be said explicitly. \n\n \n\nFinally, one naming nitpick: maybe drop the \"Mol\" from \"3D-MolGNN_{RL}\", as all models compared here work on molecules anyway (so why \"3D-MolGNN_{RL}\" would have \"Mol\" while PM-GNN_{RL} wouldn't?). \n\n### ===== References ===== \n\n[1] Efficient multi-objective molecular optimization in a continuous latent space \n\n[2] Reinforced Molecular Optimization with Neighborhood-Controlled Grammars \n\n[3] Learning to Extend Molecular Scaffolds with Structural Motifs \n\n[4] GuacaMol: Benchmarking Models for de Novo Molecular Design \n\n[5] https://github.com/PatWalters/rd_filters \n\n[6] Hierarchical Generation of Molecular Graphs using Structural Motifs \n\n[7] Scaffold-constrained molecular generation \n\n[8] We Should at Least Be Able to Design Molecules That Dock Well ",
            "summary_of_the_review": "While the methods explored in this paper seem reasonable on a high-level, and I don't doubt the authors put a lot of effort into their work, I also believe the depth and quality of the exploration is currently significantly below acceptance threshold. To add to this, the paper is unclear on many aspects, and would need a round of revisions to make is widely accessible and understandable.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}