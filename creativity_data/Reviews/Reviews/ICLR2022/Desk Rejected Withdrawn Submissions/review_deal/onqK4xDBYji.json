{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes to apply the ELMo-like linear combination to combine the scaled internal representations from different network\ndepths of BERT, and further show that such an approach can improve around 4% on the SentEval embedding probing dataset. Finally, when further applying model compression techniques (i.e., pruning), the proposed BERMo is more stable under different initialization, converges faster than the BERT baseline.",
            "main_review": "This paper proposes to apply the ELMo-like linear combination to combine the scaled internal representations from different network\ndepths of BERT. The ELMo-like linear combination is already studied as a feature-based approach in the original BERT paper, while this paper proposes to further fine-tune the parameters in BERT.\n\nThe main results of the paper are based on the probing tasks in SentEval. Compared to the Downstream tasks, I'm not sure whether SentEval probing tasks are a good testbed for testing the linguistic ability or the language understanding ability of neural models. I would suggest the authors apply the proposed BERMo method to standard linguistic benchmarks to see whether the proposed method can help improve the state-of-the-art of linguistic tasks.\n\nThe rest of the paper shows the benefit of the proposed model under model pruning. The results in Table 4 and Table 5 do not seem to be significant.",
            "summary_of_the_review": "Overall, I think the claim of the paper that the proposed method can utilize the fact that BERT \"captures a rich hierarchy of linguistic features\" is not well supported by the experiments. Also, the results for model pruning do not seem to be significant to me.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors propose a new method for utilizing pre-trained language model embeddings to solve natural language processing (NLP) tasks. The work is motivated by previous efforts in NLP studying the syntactic and semantic content found at different layers in the BERT model. The author's method combines the various layers through skip-connections to the final layer of the BERT model, which is one of the early proposed methods for combining layer information back from the original ELMO paper. The authors showcase a set of NLP tasks, of which their model improves the performance of semantic objectives. There're also results from a pruning task, but I don't fully understand it. I also don't fully understand why pruning is important to investigate for this model?",
            "main_review": "Strengths:\nThe method for linear skip connections is clearly described.\nThe result section was run 5 times to ensure consistency in results\n\nWeaknesses:\nLack of Novelty\nNo comparison to state-of-the-art\nAbout 15 F1 away from state-of-the-art on SQUAD leaderboard.",
            "summary_of_the_review": "The proposed method is not novel, it is a simple combination of two of the most cited pre-trained LM papers. The result section does not compare with the current state-of-the-art. A quick look-up at the SQUAD leaderboard shows that the current single-model state-of-the-art is about 92 F1, whereas the authors proposed model is 76.85 F1.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, authors introduce BERMo, which introduces linear combination scheme, used in ELMO, into BERT fine-tuning. The authors argue the proposed BERMo enables the model to better learn gradient flow than the original connection due to the direct connection to the gradient of the loss function, and further enhances the ability of model representation. The proposed method only needs a negligible parameter overhead to connect the outputs of each layer. Experimental results also indicate the effectiveness of the proposed method.",
            "main_review": "Strengths:\n1. It is appreciated that authors have released their code.\n2. The proposed method shows good stability at the pruning setting, while the original BERT is easy to diverge.\n\nWeaknesses:\n1. One weakness of this paper is its novelty. The proposed model of this paper seems like a combination of BERT and ELMO fine-tuning techniques (add normalized scalar parameter fuse each layer output), and then analyze its performance on the probing tasks and pruning task. Weight combination is not a new idea, and it has been applied in many NLP works previously, including transformer-based works and pre-trained models. For example, [a] has introduced a weighted transformer for handling translation tasks.  More insights and motivation of the proposed method should be provided. \n2. The results are not promising. For example, in Table 4, it seems that only QQP task in L0 and soft movement can obtain marginal improvement, and other datasets do not show any superiority. The same conclusion in Table 5, and the improvements in SQuAD/MNLI/QQP can be considered as the normal fluctuations, which can be ignored.\n\nQuestions:\n1. Results only for MNLI and QQP have been given. Why not report the results of all GLUE tasks. \n2. Are the results of SST-2, MNLI, and QQP conducted on dev set or test set? \n3. Authors argue that the proposed method can improve gradient flow since each layer has a direct connection to the gradient of the loss function. However, only residual connection also allows each layer to have a direct connection to the gradient of the loss function, the difference is BERMo applies learnable scalar parameters to adjust the outputs of each layer. So why can BERMo be better than residual connection? The authors should provide explanations about this part.\n4. The original ELMO uses normalized learnable weight for each layer fusion during the fine-tuning stage, and keeps ELMO weights fixed. In this paper, it seems authors use BERT fine-tuning techniques which enable all parameters to be fine-tuned. So do authors try to the same elmo fine-tuning technique for BERMo (e.g., only tune the learnable weighted scalar parameters of each layer and task head)?\n\nComments:\n1. The original BERT-based-uncased is 110M, while you report 84M (Section 4 on page 5). Maybe need a check.\n2. For SQuAD, EM (exact match) should also be provided.\n\nTypos:\n1. Section 4.2.3, \"the both the\" => \"both the\".\n2. Section 4.2.3, \" for the baseline our model\" = > \" for the baseline, our model\"\n3. There also exist many typos that need to be fixed. \n\n[a] Weighted Transformer Network for Machine Translation",
            "summary_of_the_review": "This paper introduces BERMo, a modified architecture to BERT. The authors argue the proposed model is able to improve the gradient flow and increase representative power. However, the novelty is limited, which just a combination of BERT and some ELMO training techniques. And the experimental results are not convincing, which cannot satisfy me to give acceptance for ICLR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Responsible research practice (e.g., human subjects, data release)"
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "When ELMo is used for downstream tasks, the layers are often combined in a weighted combination with learned layer weights (with the ELMo parameters kept fixed). This paper proposes to use that sort of weighted layer combination with BERT, hence the name \"BERMo\". Experiments are conducted on sentence probing tasks as well as a few NLP tasks, and additional experiments measure the compatibility with pruning methods and knowledge distillation. BERMo is better than BERT on the more semantic-oriented probing tasks. On the downstream tasks, BERT and BERMo perform similarly. When pruning parameters, BERMo leads to more stable training (fewer cases of divergence) and a larger amount of parameter pruning at the same levels of accuracy. There are also experiments with pruning combined with knowledge distillation, showing similar results between BERT and BERMo. \n",
            "main_review": "Strengths:\n\n1. The central idea is quite simple and easy to implement. \n\n2. BERMo outperforms BERT on the semantic probing tasks, presumably because it can upweight/downweight entire layers, only some of which are useful for each particular semantic task (though I would like to learn more about why BERMo works better). \n\n3. The pruning experiments show consistent benefit of BERMo over BERT, especially in terms of training stability. Sec. 4.2.1 shows that BERT usually diverges with 90% pruning on SST while BERMo does not. \n\nWeaknesses:\n\n1. Clarity. \n\nI have several concerns about the paper, but first I have fundamental questions that I was not able to resolve based on the paper or its appendices.\n\nThe usual way to finetune BERT for a downstream task is to finetune all of its parameters while learning the new parameters added for the downstream task. The usual way to use ELMo is to keep the ELMo parameters frozen and learn only the layer weights. Unfortunately, I was not able to determine based on the paper whether the experiments involve full finetuning or only learning of the layer weights. It's not at all obvious based on context, so this detail really needs to be clarified for each experiment in the paper. For example, for probing tasks like those in 4.1, researchers will often freeze the pretrained model parameters and only learn the probing classifier parameters, while for the NLP tasks considered in 4.2, researchers typically do full fine-tuning of all parameters. Therefore, it's really essential for the paper to clarify this detail. \n\nRelatedly, what model architecture is used for the probing tasks? BERT can provide a vector at each layer for each position in the sequence, including the CLS token position. What vector or function of vectors is used as input to the classifier? Some people average over positions and layers when using BERT for probing tasks, while others average over positions in the final layer, and others just use the hidden vector at the CLS position (either taking the final layer or averaging over layers). For BERMo there is also a choice among averaging over positions or choosing the CLS position, among other possibilities.  Also, what is the architecture of the probing classifier in 4.1 and the other classifiers in 4.2? E.g., do they have any hidden layers? \n\nHowever, even if the above questions are resolved, I still have significant concerns about the significance of the paper, described below.\n\n2. Significance of the key methodological idea. \n\nThe central idea---using a learnable weighted combination of layers with BERT---is quite common in NLP. The submission cites some related work that has done this in the past, but there is other work that is uncited that also does this. For example, Peters et al. (2019; https://aclanthology.org/W19-4302/) compared learning layer weights in a weighted layer combination with BERT (with fixed BERT parameters) to full fine-tuning with BERT across several NLP tasks.  Tenney et al. (from ICLR 2019, different from the Tenney et al paper that is cited; https://arxiv.org/abs/1905.06316) also used a learned weighted combination of layers with BERT. I think it would be good for this submission to be rewritten in light of the central idea already being well known in the community. It's certainly less common in my experience to use a learnable weighted layer combination in the context of full finetuning, but I am unsure whether the experiments in the paper involve full finetuning. \n\n3. Mixed experimental results. \n\nThe learnable weighted combination (BERMo) outperforms BERT on semantic probing tasks, but not necessarily on the other probing tasks and not consistently on downstream NLP tasks in a standard setting (see Tables 1 and 2). Also, in the knowledge distillation experiments (Table 5), the results are similar between BERT and BERMo. \n\n4. Lack of motivation for the application of BERMo to parameter pruning experimental settings. \n\nMany of the experiments in the paper consider various weight pruning methods from prior work. I was a little confused as to why a paper focusing on BERMo would include so many experiments with parameter pruning. Why is it natural to consider parameter pruning experiments when using BERMo? The pruning experiments were not motivated using an argument that relates to the BERMo architecture itself. \n\nIt seems that the connection is possibly due to the relationship between skip connections and pruning? There is discussion throughout the paper about how the BERMo architecture achieves the benefits of skip/residual connections. However, this can be confusing to readers because the transformer architecture already contains residual connections for each layer. Would the authors argue that the layer-weighted architecture is a superior style of skip connections than the residual connections that are already in BERT via its use of the transformer architecture? The paper really needs to discuss why BERMo's skip connections are expected to be more amenable to pruning than the skip connections already present in BERT. \n\n5. Lack of analysis. \n\nAll the above being said, the pruning experiments do show some significant differences between BERT and BERMo. This is a potentially interesting result. Why might this be the case? It would be nice if the paper could include some ablation experiments that modify the architecture in various ways in order to determine what exactly it is about the BERMo architecture that makes it more amenable to pruning. \n\n\n\nI had a few other questions/suggestions:\n\nSection 4 mentions a \"mask learning rate\" but it is not described -- what is it?\n\nIn Sec. 4.2.4, the paper states \"Our approach gives better results on SQuAD\". Is a difference of 0.16 F1 statistically significant?\n\nFor QQP, Tables 2 and 4 show accuracies being consistently higher than F1 scores, while Table 5 shows the opposite. Were the numbers in Table 5 inadvertently transposed?\n\nUnfortunately, BERT-base is not a very strong model. I'd suggest using RoBERTa-base or DeBERTa-base instead if larger models cannot be used. \n\n\n\nBelow are more minor notes:\n\nThe citations are formatted oddly: \"(Vaswani et al. (2017))\". Maybe this is due to a use of citet within parentheses? It should be \"(Vaswani et al., 2017)\" or \"Vaswani et al. (2017)\" depending on context.\n\nEquation (1) is not contained in the flow of the paper but is rather set off in a figure. It's not common to render an equation in a floating item such as a figure unless there is a series of related equations shown together for comparative purposes. I'd suggest moving Equation (1) to be in the flow of the paper rather than off to the side. \n\nEquation (1) has bold, non-italicized h, while the caption has non-boldface, italicized h. \n\nSec. 2.2: \"to distinguishing\" --> \"to distinguish\" or \"for distinguishing\"\n\nSec. 2.3.2: Use \\log instead of log in Eq 3.\n\nSec. 3.1: The term \"softmax normalized\" is used but the equation shown immediately thereafter is just standard normalization---there is no softmax. \n\nSec. 3.1: \"features maps\" --> \"feature maps\"\n\nSec. 4: \"higher learning rates for the skip connections\" -- do you mean learning rates for updating the alpha parameters?\n\nSec. 4: \"various experiment\" --> \"various experiments\"\n\nSec. 4.1: \"5 trails\" --> \"5 trials\"\n\nSec. 4.1: \"our approach outperform\" --> \"our approach outperforms\"\n\nSec. 4.2.2: \"smaller dataset\" --> \"smaller datasets\"\n\nSec. 4.2.2: \"at the end the fine-pruning\" --> \"at the end of fine-pruning\"\n\nSec. 4.2.2: \"roughtly\" --> \"roughly\"\n\nSec. 4.2.2: \"is lesser epochs\" --> \"in lesser epochs\"?\n\nSec. 4.2.3: \"the both the\" --> \"both the\"\n\nSec. 4.2.3: \"weights retain\" --> \"weights retained\"\n\n\n\nReferences:\n\n@inproceedings{peters-etal-2019-tune,\n    title = \"To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks\",\n    author = \"Peters, Matthew E.  and\n      Ruder, Sebastian  and\n      Smith, Noah A.\",\n    booktitle = \"Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)\",\n    month = aug,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W19-4302\",\n    doi = \"10.18653/v1/W19-4302\",\n    pages = \"7--14\",\n    abstract = \"While most previous work has focused on different pretraining objectives and architectures for transfer learning, we ask how to best adapt the pretrained model to a given target task. We focus on the two most common forms of adaptation, feature extraction (where the pretrained weights are frozen), and directly fine-tuning the pretrained model. Our empirical results across diverse NLP tasks with two state-of-the-art models show that the relative performance of fine-tuning vs. feature extraction depends on the similarity of the pretraining and target tasks. We explore possible explanations for this finding and provide a set of adaptation guidelines for the NLP practitioner.\",\n}\n\nIan Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R. Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, and Ellie Pavlick. \"WHAT DO YOU LEARN FROM CONTEXT? PROBING FOR SENTENCE STRUCTURE IN CONTEXTUALIZED WORD REPRESENTATIONS\", ICLR 2019.\n",
            "summary_of_the_review": "While the pruning experiments are promising, the lack of clarity, novelty, consistent improvement, and analysis prevent me from being able to recommend the paper for publication at ICLR.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}