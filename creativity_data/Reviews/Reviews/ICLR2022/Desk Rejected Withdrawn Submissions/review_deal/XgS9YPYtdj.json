{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "Starting from the meta-learning problem formalization from previous PAC-Bayesian works, the paper proposes improved bounds, that are later turned on learning algorithms and evaluated empirically. The use of localized priors is also studied.",
            "main_review": "For some part, the paper could serve as a much-needed panorama of the various PAC-Bayes results for meta-learning. Beginning from Table 1, the authors cite all the relevant works (up to my knowledge) and compare the numerous results with a unified notation.\n\nHowever, it is deplorable that most of the comparisons stay to the \"surface\", that is the bound statements are compared, but not the pathways that lead to these results. It seems that major parts are shared by these results. We could foresee this by looking at the proofs in the appendix, but the main paper is rather elusive on the similarities between the contribution and the existing literature. For instance, Lemmas 1 and 2, and Theorem 1, are very similar to results exploited in many PAC-Bayes papers, but related works are only (and shortly) discussed in Appendix. It would be honest to cite the previous works in the main paper, and highlight the key proof steps that set apart the proposed contributions. Moreover, I would suggest reorganizing the appendix to help the reader understand the connection between the proofs.  \n\nAs it is, a leery reviewer may ask if the main differences are \"simply\" due to the use of various choices of upper bounds on the $kl(.\\|.)$ term, leading to the three variants of Theorem 2. However, as it is very common in the PAC-Bayes literature to upper bound the kl to obtain declinations of the bound. The paper should not lure the reader and state clearly that the used upper bounds on the kl are taken from previous works.\n\nFrom the experiments, we could conclude that the so-called PAC-Bayes $\\lambda$ bound is the tightest. It is somewhat surprising that $\\lambda=1$ is fixed during the optimization, as one could expect even better results (accuracy and bound tightness) by optimizing over $\\lambda$. Also, the authors should consider minimizing the kl-bound. Although this has been considered a difficult task, some recent works present simple strategies based on gradient descent (see Reeb et al. 2018, Letarte et al. 2019).\nFinally, the use of localized priors in the context of meta-learning appears to be a much more original contribution and open interesting perspectives. It is unfortunate that this section is not more developed.\n\n### Minor comments:\n\n- Some parenthesis should be removed around in-text citations\n- i.i.d. : the trailing period should not be treated as an end to the sentence. \n- Page 6: typo: enumerator → numerator\n- Why corollary 2 (appendix) is Lemma 2 in the main paper? Please keep the same numbering.\n\n### References\n\nLetarte et al. Dichotomize and Generalize: PAC-Bayesian Binary Activated Deep Neural Networks. NeurIPS 2019\n\nReeb et al. Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds. NeurIPS 2018\n",
            "summary_of_the_review": "It is difficult to assess the novelty of the results. The authors should not be sparing in explaining the proof techniques reused from previous work. The paper would gain clarity and relevance for the community.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The present paper extends and improves upon a recent sequence of papers that make use of PAC-Bayes (PB) generalization bounds in meta-learning. The setup is that of a sequence of tasks observed by a learner that uses these in order to construct a hyper-posterior distribution that facilitates learning of a novel task. The setup was originally suggested in Baxter 2000, and developed within the PB framework by Pentina & Lambert 2014, followed by further later works. Given the theoretical elegance of PB bounds, and the often practical algorithms that can be derived from them, the extension to meta-learning holds great promise. The key novelty of the approach is the extension and improvement of previous results from the i.i.d. setting to the non-i.i.d. case, specifically, where the per-task distributions may differ. ",
            "main_review": "The main contributions of the paper are the following. (1) A lemma converting the classic tight KL PB bound from a non-i.i.d. setting to the more widely studied one of i.i.d. per-task distributions. This is an important and relevant result that, to the best of my knowledge, is new. (2) Derivation of 3 explicit bounds on the transfer error from the implicit KL bound, that enable the derivation of 3 learning algorithms minimizing the bounds.  Here the authors stress the advantage they achieve over previous results WRT the task-level complexity. Similar results for the iid case appear in Liu 2021, as noted by the authors. (3) Demonstration that when the number of tasks is large, the performance of the learner is of the same order as one using a localized prior that knows the test task data distribution, thus providing a rigorous explanation of the effectiveness of meta-learning by minimizing PB bounds. This is a nice result. (4) Empirical demonstrations attesting to the advantages of the approach compared to leading current methods. \nI found the paper to be very well written, providing a good overview of previous results in the field, and clearly stating and explaining the advantages over previous work. \nIn reviewing some of the proofs, I came upon a problem in the proof of Lemma 1 in appendix B.1. The authors use Markov's inequality in the second row of the sequence of inequalities. For this I would expect a probabilistic statement (as in Markov), but I do not see it. For example, \\delta should appear on both sides of the equation. Please explain.  \nI believe there was some typo here, but the authors should address this issue in their response. \nMinor issues: \\mu in Lemma 2 is not defined\n",
            "summary_of_the_review": "This is a nice paper with a solid and innovative contribution to the theory and practice of meta-learning. Please address my concern with the proof of Lemma 1. \n\nComments following rebuttal and reviewer response: I am lowering my score for the paper in view of the discussions and responses, as I feel, in light of other reviewers' comments, that the paper's novely and technical contribution is lower than I had originally thought. I still vote for acceptance, but with lower enthusiasm. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper presents new generalization bounds for meta-learning that upper bound the expected risk over tasks, drawn from an environment, of a model hyper-posterior from which a prior is drawn and used to learn a model on a new task. The bounds are derived via the PAC-Bayesian framework which requires setting a hyper-posterior and a hyper-prior distribution over priors to then bound the risk of a posterior learned from the task data given a prior drawn from the hyper-posterior. The derived bounds are then optimized to find the optimal hyper-posterior and posterior. The paper also shows that for a particular choice of hyper-posterior and for the number of tasks tending to infinity, the meta-learning bound is tighter than a bound that can be derived for a single task (without leveraging knowledge from other tasks).  ",
            "main_review": "The principal contribution of the paper is in deriving the kl-bound for meta-learning by proving that the kl-bound by Maurer and Seeger stands even when the data is drawn independently by not necessarily identically from the true distribution, which is the case in the meta-learning context. This is indeed **a novel, to the best of my knowledge, and impactful contribution as the kl-bound is known to provide the tightest guarantees**, which is especially important in the meta-learning context where bound convergence rate depends on the number of tasks which is small in practice.\nThree generalization bounds are then derived from it, using standard tools, which are shown to improve upon or achieve similar results than state-of-the-art PAC-Bayesian self-bounding methods. Moreover, the theoretical comparison with existing bounds are clearly summarized in the very useful Table 1.\n\nA minor problem on this part of the paper is that it is never explained why these explicit bounds need to be derived while the kl-bound itself can be estimated and optimized as done in [1]. \nIt would also be interesting to briefly discuss the benefit of using Theorem 1 instead of using existing bounds standing in the context of non i.i.d data, such those cited in the related work. Intuitively, the paper's result should provide better guarantees as it doesn't drop the assumption on the independence of draws, but discussing this advantage would help highliting the significance of this contribution. \n\nThe **significance of the contributions of Section 4.3 is hard to assess** for the following reasons:\n1. *The notion of localized prior is not sufficiently introduced*: in the related work a localised prior is defined as a data distribution dependent prior and later in Section 4.3. its definition is given as the Gibbs distribution over models with energy function the expected loss. However this prior depends on the true distribution of data, which is unknown, hence it is not clear how it is estimated. I would suggest to clarify the notion of localized prior from the introduction to better lead the reader into understanding why it is interesting to compare the theoretical guarantees of meta-learning with the ones of this localized prior context. \n2. *The conclusions of this section hold for a particular choice of hyper-posterior* - the Dirac centered in the expected risk averaged over the training tasks. This seems in discrepancy with the rest of the paper, where no assumptions are made on the hyper-posterior form. For instance in the experimental setting, the hyper-posterior is set to a normal distribution. \n\n*The experimental evaluation is interesting, in particular because it compares the test errors and bound values also for varying number of data points and tasks.* \nI have some concern about task generation by pixel permutation, because it is not clear to me how the swaps are applied while making sure that the tasks are diverse enough. Are the permutations applied per class of images depending on the task or another rule? Otherwise this procedure corresponds to adding the same type of noise to the images, without diversifying over tasks.\nIt would be useful to report in the main text the total number of parameters learned, to provide the reader with an idea of the size of the networks that can be learned with this method while keeping the bounds informative. \nFinally, it would be worthwhile to explain why no comparison is provided with the cited recent work [2], that combines uniform stability and PAC-Bayesian frameworks to derive PAC bounds on meta-learning that are shown to be state-of-the-art.\n\nOther minors:\n1. In the experiments, the hyper-posterior takes the form of an iso-tropic Gaussian distribution, with constant covariance and learned mean. Why isn't the covariance matrix learned as well? Is it necessary to limit the complexity of the hyper-posterior so that the environment-level complexity term in the bounds does not make them vacuous?\n2. Figures 1 and 2's legends are too small.\n3. RHS acronym for right-hand-side should be defined.\n4. A proof of Lemma 1 should be reported or referenced from another paper.\n\n[1] David Reeb, Andreas Doerr, Sebastian Gerwinn, Barbara Rakitsch: Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds. NeurIPS 2018\n[2] Alec Farid, Anirudha Majumdar: Generalization Bounds for Meta-Learning via PAC-Bayes and Uniform Stability. NeurIPS 2021",
            "summary_of_the_review": "The paper contributes to improving the generalization guarantees on meta-learning and it is generally well written. Because of the several unclear points highlighted in my review, I am assigning a score of 6 but I am willing to increase it if these points are addressed, especially those concerning the contribution of Section 4.3.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work builds on the PAC-Bayes-kl bound (Langford & Seeger (2001), Seeger (2002)) which upper-bounds the binary relative entropy between \"average empirical\" and \"average population\" risks of a distribution over hypotheses, say Q, in terms of the KL divergence between Q and a reference distribution P. Let's call Q the \"PAC-Bayes posterior\" and P the \"PAC-Bayes prior\" as per the literature on PAC-Bayes bounds. The main results of this work are about extending the PAC-Bayes-kl bound to meta-learning problems, which require considering distributions over a space of distributions over hypotheses, i.e. one extra level on top of the usual level considered by the usual PAC-Bayes bounds. To be specific, but concise, three PAC-Bayes style bounds are derived for meta-learning settings, and these bounds are analogous to similar bounds with similar names that have appeared in the literature, whereas this submission extends the bounds to meta-learning. Then, the proposed PAC-Bayes meta-learning bounds are turned into training objectives, and the properties to the hyper-distributions obtained by optimizing these objectives are explored in the experiments, and compared to the results obtained by other previous PAC-Bayes meta-learning methods and to classical methods that deal with a single task.",
            "main_review": "PROS\n\nInteresting problem (meta-learning) that is relevant for the readership.\n\nAdding to the limited literature on meta-learning methods inspired by PAC-Bayes bounds.\n\nTrying to bring in some theoretical contributions besides experiments.\n\nThis work may contribute to dissemination of PAC-Bayes bounds and their usability.\n\n\nCONS\n\nThis paper might be on the hard-to-read side of the spectrum, mainly because of the way it is written. In hits current form, I think this paper is not nearly sufficiently close to publishable form. The writing needs to be improved considerably for the sake of clarity and readability (see my editorial feedback below).\n\nAttributions to the literature are in some places unclear/imprecise or even misleading (idem).\n\nThe main contributions on the theory side are straightforward extensions of existing results. This per se is not necessarily to be counted against the paper, but it points that the authors need to make an effort to improve the discussions and to give fair attribution to the previous works/results on which their work is based.\n\nIn general, I think the discussion of theory and results is limited, but this could be fixed with some work.\n\n\nEDITORIAL FEEDBACK\n\nAbstract: try it like this\n\nBy incorporating knowledge from observed tasks, meta-learning algorithms inspired by PAC-Bayes bounds aim to construct a hyperposterior from which an informative prior is sampled for fast adaptation to novel tasks. The goal of PAC-Bayes meta-learning theory is thus to propose an upper bound on the generalization risk over a novel task of the learned hyperposterior. In this work, we first extend the tight PAC-Bayes-kl bound to the meta-learning setting. Based on the extended PAC-Bayes-kl bound, we further derive three improved PAC-Bayes generalization bounds for meta-learning, leading to better asymptotic behaviour than existing results. By minimizing objective functions derived from the improved bounds, we develop three PAC-Bayes meta-learning algorithms for classification. Moreover, we employ localized distribution-dependent PAC-Bayes priors for meta-learning to yield insights into the role of the hyperposterior for learning a novel task. In particular, we identify that when the number of training tasks is large, utilizing a prior generated from an informative hyperposterior can achieve the same order of PAC-Bayes-kl bound as that obtained through setting a localized distribution-dependent prior for a novel task. Experiments with deep neural networks show that minimizing our bounds can achieve competitive performance on novel tasks w.r.t. previous PAC-Bayes meta-learning methods as well as PAC-Bayes single-task learning methods with localized distribution-dependent prior.\n\n\nNo need to define \"i.i.d.\" in the abstract, it is better to define things in the main body of the paper. \n\nAlso note that \"i.i.d.\" entails two requirements: independence of the random variables, and identical distribution of the random variables. Then, saying \"extend to non-i.i.d.\" is a bit imprecise: your extension is to the case where the random variables are still independent, but not identically distributed (because each task has its own distribution). This should be mentioned in the introduction and other parts of the paper, to give the readers precise information about what this extension entails.\n\nSection 1 (Introduction):\n\nReplace \"comes into focus\" with \"has come into focus\"\n\nReplace \"is formulated by Baxter\" with \"was formulated by Baxter\"\n\n\"The pioneering theoretical framework for meta-learning was formulated by Baxter (2000) who assumed that all tasks in meta-learning are independent and identically distributed (i.i.d.) from an unknown distribution over tasks, referred to as the \\emph{environment}, to ensure the relatedness of different tasks. Under this assumption, [...]\"\n\n\"Particularly, PAC-Bayes bounds (McAllester, 1999) are regarded\" (notice the plurals)\n\nReplace \"most accurate\" with \"tightest\"\n\n\"suffer from a slow convergence rate\"\n\nParagraph starting \"In this work, [...]\": The discussion on i.i.d. versus non-i.i.d. needs to be clarified, as per my comment above, to clarify that the issue to be addressed is the lack of 'identical distribution' between samples from different tasks.\n\nNeed to insert reference for the bounds called \"PAC-Bayes classic/quadratic/$\\lambda$\" as these names arguably come from Perez-Ortiz et al. 2021 \"Tighter risk certificates for neural networks\" (which has been published in JMLR, the citation needs to be updated) and references.\n\n\"our derived PAC-Bayes meta-learning bounds\"\n\nReplace \"enumerator\" with \"numerator\"\n\nI reacted to the parts where you write \"our classic bound\" and \"our quadratic bound\" which implies claims of ownership/authorship. This has the potential to be misleading since these bounds are due to previous works and presumably other authors.\n\n\"to address the second issue, we use localized distribution-dependent PAC-Bayes priors (Catoni, ...)\"\n\nParagraph on contributions:\n\n(1) \"By reducing\" (replace \"converting\" with \"reducing\")\n\n(2) \"Based on relaxations of the extended PAC-Bayes-kl bound, we obtain three improved PAC-Bayes meta-learning bounds for the generalization risk of the hyperposterior, and three bound-minimization meta-learning algorithms\"\n\n(4) \"[...] and single-task PAC-Bayes learning methods that use a localized distribution-dependent prior\"\n\nA comment on the claimed contribution (2): these relaxations of the extended \"multi-task\" PAC-Bayes-kl follow the similar steps as the relaxations of the single-task PAC-Bayes-kl bound that lead to either the classic PAC-Bayes bound (McAllester) or to the PAC-Bayes-quadratic (Rivasplata et al., Perez-Ortiz et al.) or to the PAC-Bayes-$\\lambda$ (Thiemann et al.). Once again, this should be attributed for the sake of transparency (and honesty) while emphasizing that the contribution is in extending all these known bounds to meta-learning.\n\nSection 2 (Related Work):\n\nIn fact, PAC-Bayes bounds have been used in two main roles: One is for learning a PAC-Bayes posterior distribution and the other is for computing a numerical bound value for a distribution learned by any method (which could be PAC-Bayes method or some other method). This is discussed for instance in the introduction of Thiemann et al. (2017), I think, or in the discussion section of Rivasplata et al. (2020).\n\n\"PAC-Bayes bounds have been tightened\"\n\nBut the sentence is imprecise: McAllester proved the first PAC-Bayes bound, Langford and Seeger proved the PAC-Bayes-kl bound (they called it \"relative entropy bound\"), Maurer proved the sharp dependence of the PAC-Bayes-kl bound on the sample size, Catoni proved a new kind of PAC-Bayes bound (and many other things like what's the optimal distribution etc.)\n\nThe attributions in this section could (should?) be improved, to distinguish different works and what exactly each work contributed. Besides the clarifications just mentioned, another salient one is that the work of Rivasplata et al. (2020) showed PAC-Bayes bounds with data-dependent priors (the prior depends directly on data) while the works of Catoni and of Parrado-Hernandez et al. used PAC-Bayes bounds with distribution-dependent priors (e.g. prior is a Gaussian centered at the expected weight vector).\n\nNext paragraph on next page: \"introduced\" and \"provided\" and \"extended\"  and \"proposed\" and \"gave\" and \"utilized\" (use the past tense)\n\nReplace \"sing-task\" with \"single-task\"\n\nSection 3 (Preliminary):\n\nSection 3.1:\n\n\"For supervised learning problems $\\mathcal{Z} = \\mathcal{X}\\times\\mathcal{Y}$ is the product of input space $\\mathcal{X}$ and output space $\\mathcal{Y}$. The loss function $l$ is assumed to be bounded in the interval [0,1].\"\n\nJust a comment that in mathematics and probability theory, $\\mathcal{M}(A)$ denotes the space of all measures over a set $A$ (which should have a measurable structure, i.e. a sigma-algebra). Then it is preferable to use $\\mathcal{M}_1(A)$ for the space of probability measures over $A$, where the subscript 1 indicates the total mass for the measure to be a probability measure. For instance, Lebesgue measure on $\\mathbb{R}$ is in the space $\\mathcal{M}(\\mathbb{R})$, but not in $\\mathcal{M}_1(\\mathbb{R})$.\n\nLine after Eq.(1): delete \"say\"\n\nUse the LaTeX command \\operatorname{..} to produce nice quality operator names in math mode: $\\operatorname{KL}(Q \\Vert P)$ and $\\operatorname{kl}(q \\Vert p)$.\n\n\"the prior $P$ over $\\mathcal{H}$\"\n\n\"any posterior $Q$ over $\\mathcal{H}$\"\n\nThe citation to Maurer needs to be preceded by \"e.g.\" to indicate that this is one reference but not the original source of the PAC-Bayes-kl bound: \"(see e.g. Maurer 2004, Theorem 5)\" or even \"(see Maurer 2004, Theorem 5)\"\n\nIn general, for all references in the paper, try to make it clear for the reader if the citation is trying to point one reference (among possibly many) or trying to attribute a result (as in pointing the original source).\n\nSection 3.2: \n\nFirst paragraph: delete the content in parentheses saying something about covariance of S_i and S_j because this content is unclear and potentially misleading. Try just \"are independent but not identically distributed. Most existing [...]\"\n\n\"a predefined distribution $\\mathcal{P}$ over priors, called a \\emph{hyperprior} (i.e. $\\mathcal{P} \\in \\mathcal{M}_1(\\mathcal{M}_1(\\mathcal{H}))$).\"\n\nA bit further down: \"and computes a \\emph{hyperposterior} $\\mathcal{Q} \\in \\mathcal{M}_1(\\mathcal{M}_1(\\mathcal{H}))$. When learning the new task [...]\"\n\nLine above Eq. (4): replace \"the empirical estimates of\" with \"the empirical proxies for\"\n\nSection 4:\n\nAn unfortunate weakness of this section is that this section does a poor job at attributing the results, or at least the ideas/techniques of their proofs. Similar results (and proof techniques) have appeared in the literature, and this should be acknowledged in this section.\n\nLemma 1 is of course similar to a \"general PAC-Bayes theorem\" that has appeared in the works of Germain et al. (see \"PAC-Bayesian learning of linear classifiers\") and Begin et al. and more recently Rivasplata et al. (2020) but the latter in the context of stochastic kernels (data-dependent distributions over hypotheses).\n\nLemma 2 of course is part of Maurer (2004)'s Theorem 1 which in turn follows from Maurer (2004)'s Lemma 3.\n\nTheorem 1 is the PAC-Bayes-kl bound applied at \"environment-level\" (despite that this is formally presented for an abstract space $\\mathcal{F}$) and of course with the sharp dependence on the number $K$ as established by Maurer (2004).\n\nTheorem 2 presents three PAC-Bayes style bounds that are extensions of the PAC-Bayes-classic, PAC-Bayes-quadratic, and PAC-Bayes-$\\lambda$ bounds discussed by Perez-Ortiz et al. (2020). But note that PAC-Bayes-classic is essentially of the same form as McAllester (1999) and PAC-Bayes-$\\lambda$ is opriginally due to Thiemann et al. (2017). The PAC-Bayes-quadratic appeared first in Rivasplata et al. (2019) \"PAC-Bayes with backprop\" as far as I am aware.\n\nTheorem 3 is a combination of the PAC-Bayes-kl bound, and a result of Lever et al. for bounding KL(Q || P) when Q and P are Gibbs distributions with densities of similar forms as those defined in the paragraph before your Eq. (5).\n\nThe writing of these theorems and lemmas needs to be improved, so that all variables are declared/quantified and to clarify the parsing.\n\nFor Lemma 1: try \"Let $\\pi$ be any fixed distribution over $\\mathcal{F}$ that does not depend on $\\mathcal{S}$, let $t>0$, and let $\\Phi : [0,1]\\times[0,1] \\to \\mathbb{R}$ be any convex function. Then, for any $\\delta \\in (0,1)$, with probability of at least $1-\\delta$ over the draw of $\\mathcal{S}$, simultaneously for all distributions $\\rho$ over $\\mathcal{F}$ we have\"\n\nFor Theorem 2: declare/quantify $\\delta$ before the conclusion that with probability of at least $1-\\delta$ [...]\n\nAlso write explicitly the different conclusions:\n\n(i) PAC-Bayes-classic bound: simultaneously for all $\\mathcal{Q}$ we have\n\n(ii) PAC-Bayes-quadratic bound: simultaneously for all $\\mathcal{Q}$ we have\n\n(iii) PAC-Bayes-$\\lambda$ bound: simultaneously for all $\\mathcal{Q}$ and $\\lambda \\in [0,2]$ we have\n\nAgain, you need to mention that these bounds are analogous to similar bounds with similar (the same!) names that have appeared before, and cite the reference(s). It is probably fair to say that in your work these bounds are being extended to meta-learning problems, but give the explicit attributions to inform the readers of the previous works on which your work is based.\n\nParagraph at the bottom of page 7: I agree that Blundell et al. (2015) trained stochastic neural networks (more precisely, Gaussian distributions over the connection weights of a a given neural network architecture), but so did Langford and Caruana (2001) who also used the same \"stochastic neural networks\" so this citation needs to be improved. Try writing \"(e.g. Blundell et al., 2015)\" so that \"e.g.\" clearly signals that this is one reference, and avoid misleading the readers.\n\nSection 5:\n\nIn my opinion, this section is most important part of this submission with regards to novelty/significance.\n\nReferences:\n\nNeed to capital-protect the titles (e.g. to see \"PAC-Bayes\" or \"PAC-Bayesian\" in many references)\nSome references may need to be updated (e.g. venue where published, not just arXiv)\n\nOther references that might be relevant for discussion:\n\nFoong et al., (2021) \"How tight can PAC-Bayes bounds be in the small data regime?\"\n\n",
            "summary_of_the_review": "My main concern with this paper is the readability. In particular the presentation of the mathematical results (theorems and lemmas) is a bit weak, but possibly fixable with some effort. Another concern is regarding the attributions to the literature, which need improvement. On the editorial side, it looks from the amount of suggested edits that this submission needs considerable work before it is ready for publication. Arguably this could be fixed if the authors are willing to put in the effort to address all the feedback. The novelty of the theoretical results might be limited, considering that they are straightforward extensions of existing results, but nevertheless the instantiation to meta-learning problems is interesting and could contribute to the dissemination of PAC-Bayes bounds and their usability across learning problems.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I choose \"No\" assuming (hoping) that the authors address my comments about attributions to the previous works.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}