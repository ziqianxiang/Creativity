{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper aims to propose a new learning paradigm, lifelong learning, to enable the chatbots to conduct training on unfamiliar incoming data without training the model from scratch. The proposed system has an average confidence score of 0.81.",
            "main_review": "This paper acknowledges several problems we currently have: insufficient data, expensive training, and the difficulty of domain adaptation. \n\nHowever, there are some significant inadequacies:\n\n* This paper fails to connect itself to other research efforts in our field.\n* This paper fails to provide detailed empirical data/analysis\n* This paper needs serious proofreading",
            "summary_of_the_review": "This paper acknowledges some of the problems in the field, but its findings are not well-supported.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The given paper proposes a method for continual learning for chatbots/dialogue agents. It lays out some background work in chatbots and how continuous learning can help against retraining whenever a new dataset appears, which can cause catastrophic forgetting. The authors propose an algorithm for transfer learning whenever new data is injected into the current dataset and also have an experiment comparing one single training iteration using the complete dataset v/s continuously injecting new data every so often.\n",
            "main_review": "The paper does a good enough job of mentioning the history of the field and how catastrophic forgetting is a big problem for chatbots. The authors could rewrite some parts of the paper as the language is at times a bit confusing. There is no mention of the background work done in lifelong learning and no comparisons against existing approaches. The graph of results doesn’t have the Y-axis marked as the loss. The algorithm proposed to update weights is also not clear and why it should work. Algorithm 1 gives a method to update weights, but it is not clear what line 3 is for as size is not defined here. The update statement for adding weights is also not clear as to which weights are getting updated using the add operator there. Overall the algorithm doesn’t clearly highlight the key variables and how they are changing in this block. There is no proof/justification for the algorithm, and why it would work better than the baseline method of transfer learning. Finally, the paper lacks mathematical and empirical rigor in putting out hypotheses and testing them. The experiment laid out in section 4, splits the data for simulating the continual learning process. The authors mention that the dataset is customized for everyday conversation, however there are no concrete examples of these dialogues. Training loss is shown in the graph however the Y-axis hasn’t  been marked as training loss and instead the graph has been mistitled as training loss instead of a loss v/s time chart. The authors do explain some of the peculiar behaviour in the results section about the sudden peaks and how the model adjusts to it but going deeper into the exact examples where the model corrected itself would be more helpful.",
            "summary_of_the_review": "The paper talks about continuous learning in chatbots and gives an experiment to show how the proposed algorithm for updating the weights of the model works. The paper lacks clarity in explaining the algorithm as there are no clear update statements or written explanations. We are not given clear examples of the model’s improvement in performance across long time horizons or why confidence is a good metric for this setting. The authors explain some peculiarities in the training loss which might be a good starting point for further work, but don’t exactly tie up how these methods would help the model in generalization as there are no performance numbers for a test set up.\n",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper is about lifelong learning (also called continuous learning) of a conversational agent. The problem is interesting but there is no contribution.",
            "main_review": "This paper is very very preliminary, lacking details of contributions, awareness of the state of the art, baselines, proposed systems, dataset, or evaluation protocol. \n\nThis review is necessarily limited, as it is difficult to make constructive comments. ",
            "summary_of_the_review": "The paper does no make any contribution.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper addresses the lifelong learning for a chatbot. However, this paper is far below the quality of a research paper nor a technical report. It is of such a low quality that I suspect it is generated by a GPT3-like model (main content is only 4 pages). The claim is based on the following observations:\n1. The writing of the paper is hard to follow, with no connection between paragraphs: especially in the intro, when it tries to motivate the continual learning problem for chatbot --- the citations are very old, not knowing the recent advancements in the dialog systems. No mention of related work either.\n2. Not dataset description, no model description (only mentioned catastrophic forgetting problem of LSTM models), and the only Algorithm 1 description reads like garbage to me. There are many well-known dialog datasets to use and compare.\n3. The Figures and results are random: the training loss plot in Figure 3 is basically saying the proposed training is worse than the baseline. Also, Table 1 results confirm the same point. So what is the point of this paper? ",
            "main_review": "As mentioned above, no aspect of this paper is technically solid.\nIf this paper is written by human authors, here are some recommendations for improvement:\n1. Study and survey enough recent work on the problem the paper wants to address, in this case, continual learning for a chatbot, and understand what people have tried, what limitations or issues are not resolved, and what problem the paper is targeting on.\n2. Write a good introduction to guide readers into the problems/solutions that you proposed, and advocate what novelty/advancement the paper has made, by comparing it to existing related work\n3. Clearly write the problem setting, model description, experimental setup, and results to support your claims in the intro.\n4. Give an analysis of your results to provide a better understanding.",
            "summary_of_the_review": "I recommend a strong rejection of the paper (reasons are listed above) and sincerely hope this is NOT an auto-generated paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper aims to enable lifelong learning for a chatbot, i.e. let the chatbot learn to adapt to a new domain efficiently. The proposed method is based on sentence pattern matching. To my understanding, this paper proposed heuristics to decide whether adding a new data sample into training set, ways to adapt the existing neural network architecture when encountering new patterns, and scheduling new data injections to the existing dataset during training. However, most of the proposed methods are not discussed in details. Also, the evaluation were not rigorously done. As a result, I cannot draw conclusions on the contribution of the proposed methods.",
            "main_review": "#### Strength\n- The mentioned limitation of chatbots only performing well in training domain is indeed important. Attempts to enable or improve lifelong learning methods for chatbots is valuable.\n\n#### Weakness\n- The paper is generally not well polished. Many content are not clear or not well organized. It also includes a lot of typos and grammar errors.\n\n- The technical contribution is not clear to me. The proposed methods, in their current shape, do not carry much novelty or inspirations.\n\n- The experimental evaluation is not clear as well. The dataset is not described. Also, the numbers seem to show that the proposed method is not better than the baseline.\n",
            "summary_of_the_review": "This paper is focused on an important task, chatbots lifelong learning. Several methods were proposed but not in great detail and their novelty is unclear. The experiment results are also not rigorous or clear enough to support the proposed methods.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}