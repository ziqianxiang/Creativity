{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a training objective (EISL) that can replace the common cross-entropy loss. The training objective considers matching reference n-grams with ngrams in a candidate sequence. The paper proposes an efficient, differentiable way to achieve this by posing the computation as convolution and using the Gumbel softmax trick. Empirical comparisons between the cross-entropy loss and the EISL are provided n in noisy translation, style transfer, and non-autoregressive machine translation tasks. The results show the advantage of EISL over cross-entropy. ",
            "main_review": "**Strengths**\n- The problem of cross-entropy for sequence generation tasks is well motivated and addressed in the proposed method. \n- The improvements from EISL over cross-entropy are substantial and convincing. \n\n**Weaknesses**\n- Comparisons to some prior work that proposed similar objective functions for sequence modeling are missing in the paper, especially for non-autoregressive machine translation. For example, [Shao et al., 2020](https://arxiv.org/abs/1911.09320) proposed bag-of-ngrams differences that are similar to the proposed objective. [Li et al., 2021](https://arxiv.org/abs/2002.03084) also combined similar bag-of-words loss with cross-entropy. Empirical and methodological comparisons would strengthen the paper. \n- (Question) We see substantial improvements in Table 2 for non-autoregressive (NAR) machine translation in a single iteration, but all models except NAT-CRF and Vanilla-NAT are iterative NAR models. Did you experiment with multiple iterations? It would strengthen the argument if the improvement still remains with more iterations, which is probably a more reasonable downstream application of these models. ",
            "summary_of_the_review": "The reviewer thinks that the problem of cross-entropy and the proposed remedy are well motivated. However, there are several concerns about comparisons with prior work described in the weaknesses above. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a novel Edit-Invariant Sequence Loss (EISL), which is robust to various noises in the target sequence. Specifically, EISL computes the matching loss of a target n-gram with all n-grams in the generated sequence, which captures the edit invariance properties of text n-grams. To demonstrate the effectiveness of the proposed methods, the authors conducted experiments on three weak supervision tasks, i.e, machine translation, unsupervised text style transfer, and non-autoregressive generation.",
            "main_review": "Strengths:\n- The motivation of the work is clear, the idea is intuitive and the proposed approach has been described clearly.\n- The proposed approach is very interesting, and it provides a new perspective for investigating sequence training with noisy targets.\n- The experiments are conducted on three tasks and demonstrate the effectiveness of the proposed approach.\n\nWeakness:\n- The experiment lacks comparisons with some recent baselines, e.g., “CALCS: Continuously Approximating Longest Common Subsequence for Sequence Level Optimization” and “Improved Natural Language Generation via Loss Truncation”.\n- The experimental metrics for non-autoregressive generation and machine translation tasks are only BLEUs. They are more easily captured by the ELSL than CE loss.\n- Lack of efficiency analysis.\n- More case studies should be added in the appendix to illustrate the benefit of the proposed method.\n\nQuestions & Recommendations:\n- As shown in Figure 5(e), what is the reason that the performance of using lower grams is always better than higher grams?\n- It would be good if the authors could report the quantitative results of the time complexity.\n- In section A.2.1, there is an unfinished case study description.\n",
            "summary_of_the_review": "Overall, the paper proposes a simple yet effective technique. The proposed technique has been described clearly, the idea is intuitive. It would be good to see the authors add more analysis on experiment results and also compare with more baselines.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Cross entropy loss is often undesirable for training sequence generation models, since it is not robust to small errors in generated sequences. The likelihood is pushed down for all sequences besides the training sequence, regardless of how similar they are to the target sequence. \n\nThis paper introduces an approach for treating the target sequence as a bag of ngrams, where the loss penalizes differences between target ngram counts and expected ngram counts. This can be approximated using samples from the model at train time. Unlike RL approaches to minimize, for example, BLEU, this does not rely on score function estimators so it is better behaved in practice.\n\nThe performance improvement is noteworthy on a few NLP tasks.",
            "main_review": "=Major Comments=\n\nMost importantly, I'm unconvinced that the loss function is computing the desired quantity. The P matrix defined in the paragraph above (7) is defined by sampling the full sequence y' from the model. Here, each column is P(y'_i | y'<i). The convolution operation is computing the sum of the conditional probability of y^*_{i:i+n} occurring given y'_{<i}, across values of  i. However, the model is a fully-connected autoregressive model. To compute P(y^*_{i:i+n} | y_{<i}), we require that a forward pass in the model has been computed from position i to i+n using values from y*, not y'. Therefore, P does not have the right conditional probabilities, and there is no way to parallelize this across i.\n\nSecond, I do not have enough background on contemporary benchmarks in NLP to understand if the benchmark datasets and baselines are a good choice. Hopefully some other reviewer will know this, and if not I can ask some colleagues. \n\n\n=Minor Comments=\nYou penalize the negative log expected number of occurrences of an ngram. Does the loss behave reasonably if an ngram occurs multiple times in the ground truth sequence? \nI didn't follow why the \n\nThe training cost will depend on the number of train-time samples. Do you have any results on how accuracy changes based on the number of samples?\n\nCan you explain in more detail what this means? \"We apply sequence-level knowledge distillation to the dataset, which can reduce the complexity of the dataset, making it easier for the model to learn and improving the performance.\"\n\nThird, consider an RL formulation for the problem where the reward at step i is the fraction of target ngrams that have been generated so far. This could be trained with policy gradients, with per-step rewards. This differs from prior work that only considers a final reward (e.g., BLEU) after the entire sequence is generated. I think the objective function for that problem formulation and your problem formulation would be similar. Can you comment?\n\n\n==After author's response==\nSee discussion thread below. The authors agree with me that the equations regarding P were incorrect. The paper text will need to be changed considerably to address this. While the empirical results are strong, the paper will need another full round of review at another conference to make sure that these changes are made appropriately.",
            "summary_of_the_review": "I have a critical question around whether the parallelized version of the loss computation based on convolutions is actually computing the right thing. Otherwise, I found the empirical results satisfying. I am assigning a weak reject, and will raise to a higher score if it turns out that I was wrong about the loss.\n\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors of the paper propose a novel loss function called Edit-Invariant Sequence Loss (EISL) which is a matching loss between reference n-gram and all n-gram in candidate sequence (generated sequence). It is motivated from that cross-entropy loss penalizes valid sentences but not exactly matched with the target sentence such as paraphrases. They empirically show that the model trained with the proposed loss function is robust to noise in the target sentence or weak supervision such as unsupervised text style transfer.",
            "main_review": "## Pros\n- The paper is well motivated in that it tackles limitation of cross entropy (CE) loss in text generation. CE penalizes many possible paraphrases and fragile to noisy reference sentences. The authors propose alternative loss function that is invariant to the shift of the positions, assuming that reordering of n-gram does not change the semantics of original sentence.\n\n- The proposed method is simple and easy to implement with existing libraries.\n\n- They verify their method with solid experimental results. Especially, the results from noisy machine translation and non-autoregressive generation is impressive.\n\n- They derive upper bound of the marginalized n-gram matching loss, which enables trackable compuatation.\n\n## Cons\n\n-There is extra computational cost for the proposed loss function, but there is no explanation.\n\n- Needs some hyperparameters to be tuned such as how long do we need to train the model with \n n-gram with teacher forcing and which n-gram to use and their weights \n.\n\n- A shift translation of subsequence in text highly likely leads to grammatically wrong sentences, which might degrades the quality of generation. The authors have performed human evaluation for generated text in style transfer experiment. In my opinion, however, it cannot explain why the model trained with the proposed loss function does not generate grammatically wrong sentences.\n\n",
            "summary_of_the_review": "I think the proposed method is well motivated and interesting. Moreover it is easy to implement and effective method when the signal from supervision is noisy. But I do not understand how the proposed method prevent the model to generate grammatically wrong sentences even the shift translation of subsequence might result in sentences with grammatical errors. If the authors clearly address my concern,  I will raise my score.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}