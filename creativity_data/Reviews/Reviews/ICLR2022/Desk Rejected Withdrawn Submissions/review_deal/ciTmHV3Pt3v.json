{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors start from the hypothesis that current vision transformer lacks the ability to extract local information in images, thus some locality constraint is needed to improve the performance. The proposed algorithm contains a spatial weighting scheme which is designed to put higher weights on local patches and lower weights on remote patches. A stick-breaking transform is used for deciding the spatial weights. And also a dynamic programming method is adopted for computational efficiency. The authors test their algorithm on image classification and detection tasks and also conduct some ablation study to analyze the design of the algorithm.",
            "main_review": "Strengths:\n\n+   The algorithm is clearly introduced. The usage stick-breaking transform and dynamic programming is delicate.\n+   The efficient algorithm for backprop is interesting.\n+   The ablation study in Table 4 is well-designed.\n\n\nWeaknesses / Other comments:\n\n-    This paper is motivated by the conjecture that current vision transformer lacks the ability to extract local statistics in images and therefore is not the best design for vision tasks. But I think the authors haven't provide enough evidence to support their motivation. First of all, is ViT really not able to extract local information? In fact, some work has shown that ViT can also learn local attention despite it's computed globally [1]. Another question is, do we really more locality constraint in ViT? On one hand, locality constraint may have its own drawbacks, eg., making the model less robustness under image corruptions [2]. On the other hand, even for regular tasks of classification and detection on clean images, the authors did not show a very promising results of their model with locality bias. RIPPLE is not as good as CONVIT, another model with locality bias, on classification tasks, and also does not show advantages on the detection task.\n-    Discussion on some other baselines is missed. A bunch of works have also introduce locality bias into transformers, eg., constraining the range of attention [3], or combining convolution and self-attention [4]. Experiments with all these baselines can be time-consuming, but at least some justification of the relation between RIPPLE and the prior arts is helpful.\n-    The authors may also compare to some baselines of linearized attention. It seems the authors make some changes on previous linearized attention schemes, such as using a two-layer MLP instead of random features. Some ablation study on these changes can help clarify the contribution of the locality constraint itself.\n-    In the experiments the authors show that a hard-coded spatial weights is worse than learning the weights using stick-breaking transformation (RIPPLE vs. Fixed-RIPPLE). So if we don't have any constraint on the spatial weighting (except for positivity and unit sum),  can the network still learn the local bias?\n-    It seems the authors empirically choose the first 9 self-attention blocks to replace with RIPPLE. Does this setting apply to different tasks?\n\n\n\n[1] Raghu M, Unterthiner T, Kornblith S, et al. Do Vision Transformers See Like Convolutional Neural Networks?[J]. arXiv preprint arXiv:2108.08810, 2021.\n\n[2] Mao X, Qi G, Chen Y, et al. Towards Robust Vision Transformer[J]. arXiv preprint arXiv:2105.07926, 2021.\n\n[3] Liu Z, Lin Y, Cao Y, et al. Swin transformer: Hierarchical vision transformer using shifted windows[J]. arXiv preprint arXiv:2103.14030, 2021.\n\n[4] Srinivas A, Lin T Y, Parmar N, et al. Bottleneck transformers for visual recognition[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 16519-16529.",
            "summary_of_the_review": "The algorithm is properly designed and sensitive. But the motivation is not convincing enough and the experimental results do not well support the statements from the authors. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents ripple attention, which assigns different attention weights to patches at different distances. Ripple attention provides a feasible way of utilizing the locality bias in natural images, while still preserving the long-range modeling capability of the attention mechanism. The spatial weights are derived by a stick-breaking transformation and a dynamic programming algorithm is designed to execute the proposed ripple attention in linear observed time. Experiments show that the proposed ripple attention achieves some performance gain over baseline methods in image classification and object detection tasks.  ",
            "main_review": "It is widely acknowledged that locality bias in images (patches have stronger correlations with spatially closer patches) is very important and should not be neglected in vision transformers. The proposed ripple attention is a technically sound and neat solution to address this issue. However, the concerns come from the following aspects. \n\nFirst, there are many other ways to utilize locality bias in vision transformers, such as more complex positional embedding, local attention windows, or combination with convolutions. Ripple attention, although it is very neat, does not appear to be the most promising solution. In the experiments section, ripple attention is not compared with other methods that try to inject locality bias into transformer design (e.g. some work cited in the related work section).\n\nSecond, ripple attention is built upon linearized attention mechanism. It could be looked on as its advantage in complexity, but I would rather think of it as its disadvantage in performance. This reviewer appreciates the ablation study which compares ripple attention with fixed exponentially decayed weights. The advantage of ripple attention demonstrates the necessary of stick-breaking transformation. However, this reviewer does not understand the efforts put to the complexity reduction from O(HWR^2) to O(HWR), as R_{max} is set to 4 in the final implementation. \n\nOverall, this reviewer is not convinced that ripple attention strikes a good tradeoff between complexity and performance, although it provides a neat solution to leverage locality bias in vision transformers. ",
            "summary_of_the_review": "The proposed method is technically sound and addresses an important problem. The paper is well-written and easy to follow. However, the authors do not provide enough evidence that the proposed method is the best solution to address the problem of interest. The experimental results are mostly conducted with baseline solutions not competing solutions. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work focuses on the problem of strengthening the inductive bias of Transformer-based models within the computer vision domain. This problem is of interest in the field, as the increased flexibility of Transformers comes with a high price tag in terms of training data requirements.\n\nTo this end, the authors propose to inject a learned 2D spatial locality prior, called Ripple, into the Transformer's attention blocks. Concretely, the contribution of each key token to the response is scaled by a learned scalar weight, which is shared by all key tokens found at the same chessboard distance from the query. A soft prior is placed onto the learned weights, favoring higher magnitude weights for small chessboard distances, and thus encouraging 2D spatial locality.\n\nAlthough the method is general, being applicable to any kernelized version of attention, the authors focus on its application only in the context of linearized softmax kernel approximations, due to certain desirable computational properties. For such linear models, they show that dynamic programming can be used to efficiently forward propagate attention, keeping the sub-quadratic complexity of the vanilla (unweighted) linear variant.\n\nExperiments on image classification and object detection tasks show that Ripple, when applied to linearized models, can recover and even exceed the accuracy of the original softmax-based attention model. From the point of view of empirical inference speed, results are mixed, with significant speedups being observed in one classification experiment, but no speedups being noted for object detection.",
            "main_review": "### Strengths:\n\n- *Problem importance*: this work lies at the confluence of two hot topics in the field right now, namely the need for stronger inductive bias in Transformers and the need to improve their scalability.\n- *Presentation style*: the paper is clearly written, well structured and easy to follow.\n- *Novelty*: while not being the first time locality priors are proposed, up to my knowledge, the proposed method is sufficiently different from previous approaches, especially given its computational friendliness compared to alternatives.\n\n### Weaknesses:\n\n- *Strong complexity claims*: I am not convinced that the method is truly linear in the number of tokens, at least not for the typical use-case in computer vision, in which tokens become denser in image space.\n\n  The authors claim in section 3.3 \"[..] given a reasonable hyper-parameter choice of \\tau, the algorithm can achieve linear observed time in sequence length\". However, note that commonly, in computer vision, one scales the input not by increasing the field of view of the camera, but rather by increasing the resolution of the image or of the token sampling grid. Hence, the receptive field radius, when measured in tokens, must also scale linearly with the resolution, in order to capture objects and context at the same scale in the physical world. Hence, one would expect that $R$, $R_{max}$ and $\\hat{r}$ would need to increase linearly with the image resolution in order to keep the accuracy of the computer vision task. This implies a $O(T^{\\frac{3}{2}})$ complexity, which is still sub-quadratic, but not linear. I note that the authors themselves mention this in Appendix B, Table 5, which seems to contradict the linear complexity claim in section 3.3.\n\n- *Experimental procedure - relevance of running time vs. resolution experiment*: In light of the observation above, I consider that the analysis in Figure 2 is not entirely relevant for the typical computer vision use-case in which resolution (as opposed to camera field of view) is increasing. From what I understand, while varying the number of tokens, $R_{max}$ was kept constant in Figure 2, instead of scaling linearly with the input resolution.\n\n- *Experimental results - reduced impact for detection tasks*: Except for small objects, the proposed method does not seem to improve detection precision (Table 3), nor does it provide any inference time speedup.\n\n- *Experimental scope - accuracy analysis in the quadratic case:* The paper proposes two contributions, i.e. a generally applicable locality prior and efficient inference for the particular case of linear kernels. However, the accuracy impact of the former is only evaluated in case of linear kernels.\n\n  Granted, the Ripple prior is attractive in the linear setting, but it is still a generally applicable inductive bias that can potentially improve accuracy of the state-of-the-art softmax kernels. Adding a comparison against other inductive biases (e.g. CONVIT) in the quadratic complexity setting would help understand the suitability of the proposed bias from a machine learning perspective, and also clarify the performance gap introduced by the linear approximations for the proposed method.\n\n- *Analysis of core design choice - the ripple weights parametrization scheme:* the method requires the prediction of $R$ scalars ($\\alpha_r$) at each query point using a neural network. It is not clear whether this parametrization is really needed.\n\n  While the authors do experiment with exponentially decayed spatial weights, these values are not learned and may be a poor match to the weights learned by the stick-breaking transformation. It would be interesting to see a curve of the weights overlaid over the fixed exponential weights. Such an analysis may not only reveal the discrepancy, but also shed light on whether:\n\n  (1) There are simpler parametric curves that could be used, further increasing the speed of the method.\n  (2) It could be possible to use a logarithmic scale for the ripples and still match the curves well. That is, ripple thickness would grow exponentially (base 2) when moving away from the query token (currently all ripples have thickness of exactly 1 token). If a curve match is revealed, such a method would lower the complexity to $O(T log T)$, because the SAT trick could still be used to propagate ripples of any thickness.\n\n### Minor comments:\n\n- In Algorithm 1, Output field: $W(i,j,t)$ and $W(i,j,t-1)$ should read $W(i,j,r)$ and $W(i,j,r-1)$\n- In Equation 1, Attn($q_n$, K, V) is a row vector according to the scalar softmax formula, but is a column vector according to the matrix formula (right hand side):\n\n   - $V^{\\top}$ has size $C \\times M$\n   - $\\text{softmax}(K q_n)$ has size $M \\times 1$\n   - $V^{\\top} \\text{softmax}(K q_n)$ has size $C \\times1$\n\n   For mathematical correctness, one could re-write the matrix form as $\\text{softmax}(K q_n)^{\\top} V$, which would result in a row vector as well for the RHS as well.",
            "summary_of_the_review": "Overall, I think the paper addresses a relevant problem. The proposed solution, while not the first locality prior proposed for attention in Transformers, is elegant and computationally appealing. This paper is clearly written and well structured, and I enjoyed reading it. \n\nHowever, my *main concern* is the assumption that the locality prior strength, for the method as proposed, is independent on the number of tokens. This makes, in my view, some of the complexity claims too strong, and the speed measurement experiments less relevant for the typical practical use-case (in which scalability with input resolution, as opposed to field of view, is relevant).\n\nMy *secondary concern* is that for object detection the method does not show a clear benefit, although for image classification the method shows convincing results.\n\nFinally, while many open points are carefully considered, my *minor concerns* are related to two loose ends in the analysis, as I perceive them:\n\n- How does the locality prior look like in practice? Is the ripple parameterization scheme with $O(R)$=$O(T^{1/2})$ parameters really necessary, or would a logarithmic scheme with thicker ripples suffice, e.g. one having only $O(\\log R)$=$O(\\log T)$ parameters? \n- Complexity aside, how does the proposed inductive bias stack up against other state-of-the-art (i.e. un-approximated) approaches? \n\nGiven all of the above, I think in the current form, this work is marginally below acceptance threshold. However, my suggestion to the authors is to relax the complexity claims and re-run the empirical running time analysis assuming the $R_{\\text{max}}$ increased linearly with $\\sqrt{T}$. If a clear speedup is still observed in this scenario, this could make an argument for an increased impact for this work for publication. \n\nApart from this, including an analysis of the locality weight curves and possible logarithmic parameterization schemes would be a welcome addition. This may even reveal that further complexity/empirical speed improvements are possible, strengthening experimental results and complexity guarantees.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}