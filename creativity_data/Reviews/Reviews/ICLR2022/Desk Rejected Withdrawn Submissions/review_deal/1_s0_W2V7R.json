{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a modification of Gaussian Process learning and inference by changing the variational distribution. The experiments test the proposed idea on regression and reinforcement learning tasks.",
            "main_review": "While the motivation for using GPs to capture uncertainty for better regression and in turn better model-based reinforcement learning makes sense, it is difficult to parse the main ideas from the paper. For example:\n\nThe formulation of Gaussian processes doesn’t make sense, or is very non-standard.\n- The first paragraph introduces “machine learning models” as y = f(x, z, θ) where z is a latent variable, without really introducing a generative model, or a variational posterior.\n- There are no latent variables z in a Gaussian process, as described in the paragraph starting with “Gaussian Process (GPs)[14] is well-known for capturing uncertainty…”. What does p(z) refer to? A GP usually places a prior on a function - is p(z) a marginal distribution of a subset of function outputs? It is not clear what θ refers to - are they generative model parameters?\n- In Figure 2, while it is true that a prior p(z) is fixed for GPs, that doesn’t mean that GPs don’t use the information in the conditioning set X_hat, y_hat.\n\nThe description of the main method is unclear. In a setting like this, I would have expected a description of 1) the generative model family p, 2) the variational family of posteriors q and 3) the learning algorithm. It is also implicit, but I am assuming that the learning & inference algorithm is stochastic variational inference - based on the fact that the reparameterization trick is described at the start of section 3.\n\nThe difference between the proposed work and neural processes is unclear. One of the main novelties in this method, as described in the caption of Figure 2 seems to be that the variational distribution takes as input an encoding of the context set c. The differences between this paper and NPs is described in the penultimate paragraph of section 2, however with mischaracterizations, e.g. (but not limited to)\n- NPs do approximate inference -this paper also seems to be doing approximate variational inference, it’s just that it’s not explicitly stated,\n- NPs lack theoretical guarantees - there are well-defined lower bounds on the likelihoods for NPs while this paper doesn’t explicitly state the generative model, the inference network, and the learning algorithm,\n- “Instead, we apply Bayesian inference...” - NPs also perform Bayesian inference by virtue of doing stochastic variational inference.\nThe model is not clearly illustrated on the pedagogical Sinusoid Regression task. From Figure 3, it is unclear which row corresponds to the proposed model. It seems like GP is the proposed model. In that case, however, it would be instructive for the reader to understand the differences in performance between classical GPs (which are claimed to be bad in Fig 2), and this method.\n\nI’m not sure what to take away from the concept learning example. I’m not sure how this relates to the setting that has been described up to this point. What is being regressed to what?\n\nReinforcement learning examples seem to be constrained and it is unclear how GP regression fits into the picture, especially since the regression problem is now formulated as minimizing the squared error (equations 9 and 11).\n\nMinor comment: the references are not numbered and it is difficult to cross reference them while reading the main text.\n",
            "summary_of_the_review": "The proposed method is not explained within a coherent conceptual framework (what’s the generative model, what’s the variational approximation, what’s the learning algorithm, how does this relate to VI learning methods for GPs, how is this different from NPs). The first regression experiment doesn’t highlight the proposed method and the subsequent experiments don’t explicitly study regression performance.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "**Summary.** \n\nThe paper proposes to introduce a Gaussian Process (GP)-like prior to iteratively regularise the learning process as the context data changes or shifts. This allows quick adaptation of the model to adjust behaviours “on the fly” in reinforcement learning applications. The proposed model uses Multihead Attention to obtain the context-based representation.",
            "main_review": "**Strengths.** \n\nI consider strong the aim of the authors of providing a “continual update” to this sort of models in a way similar to online bayesian inference. That is, updating the prior beliefs encoded as a distribution which regularises the learning process with our posterior beliefs or something similar. Authors also structured very well the paper, particularly with the details on the methodology part. Unfortunately I found some points that are included in the lines below.\n\n**Weaknesses & Recommendations.**\n\nI find several points that should be pointed out:\n\n- [W1]: I consider that the paper refers a lot to Gaussian Process (GP) models, including the title, when the work is not (that much) focused on the main problems of GP literature, i.e. latent function inference, sparse approximation, kernel methods, etc . When one reads the title and the abstract it might seem confusing as one thinks that the work is gonna be focused on applying amortised inference (e.g. as in VAEs) to GP models, but it just the opposite, a vanilla GP regression model is placed on an already amortised model to improve adaptation.\n\nThis is just to clarify that the paper seems to be presented as a GP methodology contribution, when it is really an application of GPs to reinforcement learning or meta-learning alike problems.\n\nA point of evidence about this is that there is only one reference to Gaussian processes and a few more to Neural processes, that is something slightly different.\n\nThis also make difficult to understand the main contribution of the papers to the SOTA. Where would authors place their work? On the GP literature, on meta-learning methods or reinforcement learning.\n\n- [W2]: I also find some lack of consistency along the paper, both on notation, citations, etc. For instance, references are numbered but later bibliography is not. Another example is the use of the variable “c” as context in the beginning of Sec. 3.1, which is later re-defined in Eq. (1) and later again in the paragraph before Eq. (3). and before Eq. (5). Maybe I’m wrong, but this is a bit complicated to be followed, at least to me.\n\n- [W3]: Also with respect to the GP modelling, I find some statements that I’m not sure if they are correct, and I would like the authors to certify that. Some examples:\n\n>“Gaussian process (GPs) is well-known for capturing uncertainty in model parameters”. More about defining distributions on the space of functions, right?\n\n>“It (the GP) simply assumes a fixed Gaussian prior on latent variables”: Are there always latent variables in GP models? I think not.\n\n>“Gaussian process (GPs)[14] is well-known for capturing uncertainty, which specifies Gaussian priors on \\theta and \\bm{z}”. Is this correct? \n\n- [W4]: The idea of including the toy example on binary classification is great, but somehow stops the flow of the paper, and made me loose the path a bit. However, I found interesting the label and domain flip properties of the proposed model. Perhaps these points should be more clear.\n\n- [W5]: Figure 2 could be improved.\n\nA few recommendations for improvement:\n- [Rec1]. Review and check statements around GPs and their role. Better to talk about the model that is helped by the nice properties of the GP and particularly, the kernel function to build the covariance matrix.\n\n- [Rec2]. Check notation and consistency.\n\n- [Rec3]. Improve Figures and citations+references\n\n- [Rec4]. Make it clearer which is the main contribution of the paper and what really the work is leveraging.\n\n",
            "summary_of_the_review": "**Summary of the review.**\n\nInteresting idea but difficult orientation with respect to the GP part. I found critical weaknesses and gave some recommendations for improvements. However, in my opinion the current state of the paper is under the acceptance threshold.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes to parametrize the prior of a latent variable in a probabilistic model using a neural network, which aims to improve performance when encountering related tasks in a meta-learning setting.",
            "main_review": "It is not immediately obvious from abstract and introduction that this paper is about meta-learning. Its title refers to \"latent variables in Gaussian processes\", but does not seem to follow the common understanding of a Gaussian process as a distribution directly over functions (the 2006 textbook by Rasmussen & Williams would have been a standard reference) - instead, the authors place a Gaussian prior on the parameters of an (unspecified) parametric model. They also do not seem to have taken note of the long history of Gaussian process latent variable models, e.g. Lawrence (JMLR 2005) or Titsias & Lawrence (AISTATS 2010).\n\nThe paper does not clearly distinguish between observations of previous episodes (for the meta-learning), observations of the current episode (for the actual learning), and current time step (for actual next prediction).\n\nThe paper contains several statements that appear inconsistent or wrong, for example:\nSection 4.1: This paper states \"We further add Gaussian noise … consistent with MAML\", whereas the MAML paper (Finn et al., 2017) makes no mention of adding any noise.\nSection 2 suggests the authors use an RBF kernel, but in Section 3.1 the kernel is defined in terms of features $\\phi$ and some (arbitrary?) covariance matrix $\\Sigma_p$, without any reference to the input locations over which the RBF kernel would compute a covariance matrix.\n\nThe paper does not provide essential details to reproduce the results, for example, there are no details on architectures or choice of initial parameters. There are no error bars on the empirical results.\n\n\n### Questions to the authors:\n\nThe paper describes the latent variable $z$ with very high-level concepts such as \"feel like Prey has moved up\" - but how does that actually map into a latent variable?\n\nWhat are the functions $\\phi$ that project input vector into feature space?\n\nRegarding concept learning, can you clarify how you (in metrics) and the model (in computation) handle the \"cross\" cases ($c_0 \\land \\lnot c_1$ and $\\lnot c_0 \\land c_1$)?\n\nNPs and GPs solve the same problem (probabilistic function regression); why would NP not apply to domains like reinforcement learning but GPs do?\n\nIn Figure 5 (b), where does the EMAML performance lie?\n\n\n### Additional feedback to the authors:\n\nExperiments: I would suggest to the authors to start by thinking about what properties of their algorithm/method (and how it differs from previous methods) they want to assess. Then to devise experiments that do so one at a time. It is much easier to read: first, what property you want to demonstrate (aim of the experiment); second, the description of the experiment (how would I reproduce it) and how it will demonstrate that property/its aim; third, the supporting empirical results.\n\nAblation: for example, in the sinusoid regression example, it would be illustrative to demonstrate how different methods behave when given equivalent training points (as done by Finn et al. (2017)).\n\nReferences: the main text uses numbers (e.g. [1]) to refer to citations, whereas the list of references is sorted alphabetically instead. Please make sure that both text and references use the same citation style.\n\nInconsistency: in eqn. (5) in section 3.2, the authors state $\\mu_c = \\text{MultiheadAttention}(\\dots)$, but below in the text state that actually $h$ is result of a pooling layer (without giving any details).\n\nNotation: The manuscript introduces x-in-circle symbol (⊗, \\otimes) for element-wise multiplication, but this is commonly used to denote the tensor product. I would recommend to replace it with dot-in-circle (⊙, \\odot), which is the much more commonly used notation for the element-wise product.\n\nFigure 4: I would interpret \"Triangle is on the bottom of Circle\" as \"Triangle has to be directly below (below and adjacent to) Circle\", which is not the case for the right-most example. I would suggest a rewording such as \"Triangle is below Circle\".\n\nTypo: in eqn. (1), \"where $c = …$\" should be \"where $\\mu_c = …$\"\nTypo: at the end of the first paragraph of 3.3, the data point is expressed as {s, a, s, r, c}; this should be {s, a, s', r, c}.\n\nTypo: in the first and second paragraphs of 4.3.1, \"2ed\" should be \"2nd\" or \"second\".\n",
            "summary_of_the_review": "As it is, I found the paper very unclear and confusing. I recommend rejecting the manuscript at this point. The lack of clarity in presentation of the approach and lack of rigour/reproducibility in the experiments means that it is not possible to confidently assess the merit of the proposed method. I believe both the presentation of the method and empirical evidence require too much reworking for ICLR 2022's camera-ready deadline, and would warrant a re-review at a future date.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this work, the authors present a latent variable Gaussian process model, using a context-based represenation with a MultiheadAttention module to perform inference. They evaluate the model on regression, concept learning, and reinforcement learning tasks, reporting improvements over other models such as standard GPs and neural processes in these domains.\n",
            "main_review": "The demonstrated success of the model to these wide-ranging domains is certainly a positive, and I think that the problem the authors are trying to solve is interesting.\nHowever, the paper significantly lacks clarity in my view, to the point that I am still unsure what the proposed model is.\nMoreover, I have concerns about the relation to prior work, many of the claims being made, and a lack of detail in the experiments.\nTherefore, for these reasons, I am currently recommending rejection.\n\nClarity\n\nMy main concern with this paper is the clarity of the writing.\nIn my view, the paper lacks clarity to an extent that it is difficult to understand what the proposed model actually is.\nFor instance, an amortized posterior over latent variables is proposed in Eq. 1.\nHowever, as far as I can tell, these latent variables do not appear at any point later on, making their role in the model unclear.\nI also found that the description of $\\phi(\\cdot)$ was not particularly clear: what exactly is $\\phi(\\cdot)$?\nIt is described as a projection of an input to a feature vector, but as far as I can tell this projection is never explicitly defined.\nFinally, I found the toy example (pages 4 to 5) more confusing than helpful, particularly when the authors attempted to explain the model in terms of the RL problem from Fig. 1.\nI think the exposition of the model would benefit more from describing it in terms of a basic regression model with latent variables instead of jumping straight to an RL problem.\n\nRelation to prior work\n\nIt seems that the authors are unfortunately unaware of a significant line of work in the Gaussian process literature that provide inference methods for Gaussian process models with latent variables.\nThis ranges from the basic Gaussian process latent variable model [1] (which isn't applicable to regression), to works on latent variable regression [2] and similarly, conditional density estimation [3].\nIn particular, [3] provides an amortization network to infer the values of latent variables in the model.\nNote that these references are far from exhaustive as this problem has been studied in many contexts, and I would have expected at least some of them to be cited in a work on latent variable GP models.\nMore recently, [4] have proposed KITT, which uses transformers to identify suitable kernels from data, which may have similarities to the method proposed here.\n\nClaims & Technical details\n\nI have a few concerns about the technical content of the work beyond its clarity and relationship to prior work.\nFirst, the authors often claim that they are able to obtain \"exact uncertainty\"; I am not convinced that this is the case as there is an approximate posterior on the latent variables.\nThe authors repeatedly make claims along the lines that \"q(z|X, y) is fixed at p(z) during inference\" for Gaussian process models. \nIn light of the references I've provided above, I am not sure that this is true; would the authors be able to expand on this?\nFinally, the authors show that the model they end up with is a GP.\nWhile this is certainly true, I believe that it may not be best to think of it as a GP but rather as featurized Bayesian linear regression, with learned features.\nIndeed, the scalability of the method is a concern in the GP case, as it will have O(N^3) cost (N being number of datapoints), whereas featurized BLR is linear in the data and cubic in the number of features.\nFinally, recent work [5, 6, 7] has shown that GP models with NN-featurized kernels can have difficulty with overfitting; what steps did the authors take to mitigate this?\n\nExperiments\n\nI was unable to find any code or description of experimental details sufficient for reproducibility of the experimental results.\nThis includes architectural details, which for the comparisons presented here should be provided to determine whether the conclusions being drawn are fair.\nFor instance, there are many variants of neural processes, and different architectures can provide very different results.\nAs a particular point, I am quite puzzled by the results shown in Fig. 3: why do the predictions for the GP model have non-zero mean for no context points?\nIt is also not clear to me why the predictions for the neural process look so bad when there are no context points: could the authors expand on this?\n\nMinor points\n\n- The paper has quite a few typos; for instance the state $\\mathbf{s}$ is repeated in the description of a data point (page 5, before \"(i) Off-policy\"), and \"2ed\" in the caption for Fig. 6(b)\nI would encourage the authors to carefully go through the paper to correct these and other typos.\n- When using numbered references, the bibliography should contain the numbers so that they can be easily found.\n\nReferences\n[1] https://proceedings.neurips.cc/paper/2003/file/9657c1fffd38824e5ab0472e022e577e-Paper.pdf\n[2] https://arxiv.org/pdf/1707.05534.pdf\n[3] https://arxiv.org/pdf/1810.12750.pdf\n[4] https://arxiv.org/pdf/2106.08185.pdf\n[5] https://arxiv.org/abs/1912.08416\n[6] https://arxiv.org/abs/2102.11409\n[7] https://arxiv.org/abs/2102.12108",
            "summary_of_the_review": "While I think this paper could provide an interesting method, it currently suffers from a number of issues.\nThese include the clarity with which it describes its method, its relation to prior work, and the experiments themselves.\nTherefore, I am currently recommending that the paper be rejected.\nHowever, I am open to changing my view, and I look forward to seeing what the other reviewers have to say, and to reading the authors' responses.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}