{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper releases a large-scale, multi modal dataset including subtle short-duration actions labeled at a high temporal resolution. It also proposes an approach for high-resolution action identification, which directly predicts the sequence of actions. The proposed method was tested on the dataset and the experimental results prove the effectiveness of the method to some extent.",
            "main_review": "This paper releases a large-scale, multi modal dataset, which can be used for training and evaluating models to identify subtle actions at high temporal resolution. The action density of the new dataset is much higher than that of existing datasets, and the amount of data is large, which is very meaningful. However, I noticed that the dataset only focuses on daily actions, so the sampled action coverage is relatively small, and the scene is not rich (the indoor areas where patients live). And when collecting the dataset, only the arm movements and upper body movements are concerned.\n\nThis paper proposes a sequence-to-sequence method to predict a sequence of actions rather than individual, segmented actions. This allows the model to consider the division of actions from a high-level logical perspective, and brings a good improvement. I think this view is meaningful. But I noticed that the traditional segmented actions method can not only divide the action, but also locate the interval of the action in time, which is not possible with the sequential method. Although the sequence method can accurately divide and output the sequence of actions, it cannot locate the specific time period in which the action occurs.\n\nThe paper mentioned that the movement of the arm can be divided into three major stages: Reach, Transport, and Stabilize. But this idea is not expressed in the model. I think it makes sense to divide the movement into a series of meta-actions, and it should not be limited to the arms, but the whole body. It is not necessary to express the meta-actions explicitly, but implicitly in the model, which may be a way of designing the model, and is helpful for precise action division.\n\nI noticed that the comparisons in the article are all done with the baseline or the baseline with some additional modules. Although it has been compared with the segmented actions method, it should still be considered as part of the ablation experiment. It lacks comparison with some of the most advanced models.",
            "summary_of_the_review": "Due to the lack of the model novelty,  the variety of the dataset,  and the sufficient experiment comparison,  I think the paper is not ready for publication  at this conference.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper introduces StrokeRehab, a new multimodal dataset that includes temporal annotations of 5 fine-grained, short-duration functional action primitives performed by 41 stroke-impaired patients.  It also proposes a sequence-to-sequence architecture for predicting the sequence of activities in this dataset. \n\nThe proposed architecture is compared with action segmentation methods, by post-processing the segmentation output (frame-level action predictions)  to generate a sequence of action words. Experiments on 3 benchmark datasets (50Salads, Breakfast, Jigsaws) and the StrokeRehab dataset show that a sequence-to-sequence model that uses segmentation outputs (per frame softmax probabilities) as its input is able to outperform a segmentation method for the task of sequence predictions, as determined by edit score and word error rate metrics. The paper also showcases the basic difference of this dataset w.r.t. other benchmark datasets, namely the very short duration of fine-grained activities.",
            "main_review": "# Strengths\nS1. The major strength of the paper is the introduction of a new multimodal dataset (video and IMU kinematic data). The authors have identified a gap in existing datasets, namely the lack of multiple, very short activity instances (second- or sub-second-long). Importantly, the dataset is meticulously annotated by experts. Advances in action recognition in this dataset could also aid in rehabilitation of stroke-impaired patients, and in particular arm motion recovery.\n\nS2. Although it is not clearly mentioned in the manuscript, it seems that this work introduces a new action recognition task, the prediction of the sequence of activities as a sentence, instead of predicting activity segments (action label, start, end time). Prior work has evaluated action segmentation results in this way, by collapsing repeated labels to a single label, but this was not the primary task. Also, there is non-peer-reviewed prior work on this task: Yan Bi Ng, Human Action Sequence Classification, arxiv19.\n\nS3. The usage of segmentation outputs as inputs to the sequence-to-sequence model (instead of the raw video/kinematic data features) is a nice idea, and authors show that only in this way the sequence-to-sequence model can outperform segmentation-based baselines. This also shows that although the seq2seq model is widely used in many applications, it is not trivial to apply it for action sequence prediction. The authors might be interested in this recent paper, which also adapts seq2seq models for action segmentation.\n- Suri, Fast Weakly Supervised Action Segmentation Using Mutual Consistency, TPAMI21\n\nThere is also concurrent relevant work for action forecasting, object detection.\n- Yan Bin Ng et al, Forecasting future action sequences with attention: a new approach to weakly supervised action forecasting, arxiv20\n-  Chen et al, Pix2seq: A Language Modeling Framework for Object Detection, arxiv21\n\n# Weaknesses\nW1. Weak comparison with existing methods: As explained earlier, this paper and the proposed method tackles a slightly different task than most action detection/action segmentation works. Therefore, there is no clear state-of-the-art to compare with. That said, the authors only compare with one segmentation approach (MS-TCN), which is not state-of-the-art in action segmentation, e.g. it is outperformed by the following:\n- Wang et al., Boundary-aware cascade networks for temporal action segmentation, ECCV20\n- Gao et al, Global2Local: Efficient Structure Search for Video Action Segmentation, CVPR21\n- Chen et al, Action Segmentation with Joint Self-Supervised Temporal Domain Adaptation, CVPR20\n\nAlso, the paper misses baselines such as per-frame classification or action detection methods (such as BSN, BMN etc.). It is important to have strong baselines for a newly introduced dataset. At least some discussion of alternative detection-based baselines should be included in the related work section.\n- Lin et al, BMN: Boundary-Matching Network for Temporal Action Proposal Generation, ICCV19\n- Chao, et al., Rethinking the Faster R-CNN Architecture for Temporal Action Localization, CVPR18\n\nW2. The chosen task and metrics ignore the temporal location of identified actions. Since the paper proposes the task of action sequence prediction in the form of a sentence (e.g. [action A, action C, action B]), their metrics are inspired by NLP metrics, namely edit score (Levenshtein distance) and Action Error Rate (akin to word error rate). However, these metrics only evaluate the action sequence prediction as a sentence, while ignoring the temporal location of detections (the proposed model does not even output temporal locations). I believe that predicting the sequence of actions alongside their temporal location would be a more challenging task and would improve interpretability. Prior work has also combined frame error rate with word error rate metrics (e.g. Zhang, Exploring Contextual Information in a Layered Framework for Group Action Recognition). Maybe there could be two tracks for evaluation on this dataset, one that requires and evaluates only the sequence of actions, and another that also requires and evaluates the predicted temporal segments.\n\nW3. The introduced dataset is of a relatively small scale, compared to recent action recognition benchmarks. Although it has a large number of annotated instances (64284), these only correspond to 5 classes. It also contains 1763 trials from 41 subjects. Recent datasets with fine-grained activities, such as FineGym, also contain very short activities, e.g. with an average duration of 1.7 seconds, and they have hundreds of annotated classes. Maybe adding some hierarchy of annotated actions could help. Furthermore, the experiments show that action sequence prediction is not dramatically harder in this new dataset compared to e.g, 50 Salads (Table 1 and 2).\n\nW4. Limited novelty of proposed approach:  The proposed method is a direct application of a sequence-to-sequence model, which has been extensively used in NLP and Vision+Language approaches.\n\nW5. Some missing details regarding the method. The attention mechanism is not clear. What are the keys/values? Are they the hidden states of the f_enc? Is h in Eq.1 the last hidden state?\n\nW6. There are several confusing statements regarding prior work. (a) It is mentioned that datasets like JIGSAWS focus on coarse activities. Although, JIGSAWS activities might not be as short as StrokeRehab activities, they are still fine-grained, e.g. reaching for needle. (2) There is a confusion between action recognition tasks (action identification, action sequence prediction, action segmentation). Defining tasks early in the manuscript would aid understanding. Also, I disagree with the statement \"Most existing methods address the task of action sequence prediction by performing segmentation of the input data.\" These segmentation approaches address the task of per-frame action recognition or segment detection, i.e. temporal localization is at their core, while the new task does not require temporal predictions. It would be more accurate to say that the output of existing segmentation works can be post-processed to solve the new task.\n\n# Other detailed comments\nDC1: The notation h(\\theta_{enc}), s_i(\\theta), i.e. vector with parameters is a bit confusing. I would drop it and only mention the parameters in the function.\n\nDC2:  Hyperparameter selection. In Section D.3.1 we see that there many different architectures and hyperparameters chosen for different data types/datasets. Is there any justification for the choice of architectures? For example, why was an MS-TCN used to encode video data in StrokeRehab, while a bi-GRU is used to encode sensor data in StrokeRehab? How was the size of hidden representation chosen?\n\nDC3: Question regarding \"The raw2seq version achieves better performance on the sensor data of the StrokeRehab data, where the actions are very localized and do not require modeling long time dependencies\": Isn't this the case for video data of the StrokeRehab dataset as well? Why is seg2seq underperforming for sensor data?\n",
            "summary_of_the_review": "Overall, the main strength of the paper is the introduction of a new dataset, rather than the novelty/performance of the proposed method.\n The proposed method is a direct application of a sequence-to-sequence model, which has been extensively used in NLP and Vision+Language approaches, and it is not adequately compared with state-of-the-art methods. While the new dataset has high-quality annotations of very short functional action primitives and the task of action sequence prediction on this dataset is interesting, I am skeptical about the choice of metrics, missing baselines, and the very small number of action classes. Therefore, my initial recommendation is that the paper in its current format is not strong enough for acceptance in ICLR.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work addresses the problem of fine-grained action recognition from multimodal (IMU+video) data with an emphasis on applications for activity modeling in Stroke victims. \n\nThe primary contributions are:\n* Development and planned release of a dataset of 41 stroke victims performing activities. \n* Baseline and improved models on this dataset and 3 common benchmarks (50 Salads, Breakfast, JIGSAWS) with SOTA results. \n\nThe paper discusses limitations of many common segmentation-focused models and compare with a sequence-to-sequence-based approach, which tend to have many fewer spurious false positives.  ",
            "main_review": "Overall, this is an interesting paper and new dataset. As the paper describes, getting access to this kind of data and high-quality labels from skilled annotators is very challenging. \n\nStrengths:\n* State of the art in fine-grained activity analysis is well represented. \n* The dataset is a valuable addition to the fine-grained activity community. My impression is that the quality exceeds that of many existing multimodal/sensing datasets. If I was a PhD student working in this space I would love to use this data.  \n\nWeaknesses:\n* The sequence-to-sequence models are adaptations of encoder-decoder models used by various communities in the literature (e.g., speech, language). The methods have not been used on these datasets to my knowledge. \n* Page 8: I was confused by some of the design decisions described on Page 8. Specifically, the part about applying the seq2seq model to overlapping windows of short duration [...] and concatenating.\n\nOther\n* On page 7, there is discussion about greedy decoding versus been search. I wonder if one reason why green decoding performs as well as Beam Search is that there isn't a large enough penalty for transitioning between action classes. Old school HMM- or CRF-based models have an explicit tradeoff model of unary and pairwise terms. The pairwise term looks at the probability of class A going to B from frame-to-frame; if you never see A transition to C in your training data then P(C|A)=0, and so at test time you will never transition A=>C. Using a discriminative LSTM-based approach, you may never see examples of A=>C in your training data, so your model doesn't know that you _shouldn't_ transition from A=>C. This is one of the \"devil is in the details\" issues with some of these types of decodes. The way that these models are trained has a large impact on what the model should and should not do. \n\n",
            "summary_of_the_review": "I'm not sure that ICLR is the right venue, which I think should be discussed amongst reviewers and the AC. This seems like a better thematic fit at MLHC (ML for HealthCare), UbiComp/IMWUT, or something like the recent NeurIPs dataset track. The core technical contributions are adaptations of increasingly commonplace ideas within the sequence modeling community, so I'm not sure that this paper stands on its own at ICLR from that regards. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I'm not necessarily concerned, but am wondering if it makes sense for the authors to include a sample consent form given that the dataset contains people with medical conditions and that they are planning to release the data. ",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Long-duration human action detection has been widely explored before.\nThis paper focuses on short-duration human action detection problem.\nGenerally, this paper collects a large scale dataset for training and evaluation.\nThis dataset is designed for counting repeat numbers of daily living actions, which can be used for assisting stroke rehabilitation.\nAlso, this paper presents a sequence-to-sequence model, which outperforms previous human action detection models.",
            "main_review": "Strengths\n- This paper presents a large scale dataset for assisting stroke rehabilitation.\n- This paper presents a sequence-to-sequence model for short-term human action detection task, which achieves SOTA results on the presented dataset.\n\nWeaknesses\n- The key requirement of assisting stroke rehabilitation is to count repeat numbers of daily living actions. It seems unnecessary to locate action positions. Therefore, the application of the proposed problem is unclear.\n- The presented sequence-to-sequence model has been presented for previous speech recognition task. The novelty of this model is limited. ",
            "summary_of_the_review": "The presented dataset seems useful, but the novelty of the presented model is limited.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}