{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper is proposed to address the tiny object detection with the help of the context augmentation module (CAM) and feature refinement module (FRM). To obtain rich context information for feature augmentation, CAM merges multi-scale dilated convolution features. The proposed method has been verified on the PASCAL VOC dataset with the considerable improvements over the latest baseline methods. The major concern of this paper is the novelty that similar ideas such as context augmentation and multi-scale have been commonly applied in previous works. And authors failed to provide the results on the COCO benchmark, which is more important than PASCAL VOC. Moreover, the authors have not offered any rebuttal to address the reviewers' concerns."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper aims at the tiny object detection and point out the issues are small context feature, semantic feature conflicts, and less tiny objects in training data.  To solve the aforementioned problems, authors introduce context augmentation module (CAM), design a feature refinement module, and adopt data-augmentation manner in training process. Experiments are conducted on PASCAL VOC dataset to validate the proposed methods and modules.",
            "main_review": "## Strength\n### 1. The tiny object detection is a challenging and meaningful research topic in both theory and application.\n## Weakness\n### 1. The motivation of the work is not clear and the explanation is not convincing. In paper, the authors mention that \"different densities directly will cause semantic conflicts\", this should be justified experimentally or theoretically. \n### 2. The authors claim that the proposed CAM and FPM can solve the feature conflicts, this should extensively demonstrated and explained in-depth, not just some number and trivial feature visualization map.\n### 3. The novelty of proposed method CAM, FPM, and data augmentation methods are slim. CAM is initially proposed Yu & Koltun, 2015. Data augmentation is a common operation to improve performance. If the authors want to justify the superiority of the proposed data augmentation method, they should systematically compare theirs with other data augmentation methods.\n### 4. In order to validate the performance of the proposed method regarding tiny object, COCO dataset is more suitable than VOC.\n### 5. Too many typos. Here some of them are listed. In abstract, \"the precision of target targets\" might be \"the precision of tiny targets\"\n\"great progress(Tonget al., 2020\" should be \"great progress (Tong et al., 2020\", a space should be placed between text and bracket. In figure 1, the CEM should CAM. ",
            "summary_of_the_review": "Based on apparent weakness, the paper is nor ready to publish.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposed a method of combined context augmentation and feature refinement to eliminate the limitation of network and imbalance of dataset issues for tiny object detection. A data enhancement method is proposed to increase the contribution of tiny objects to loss during the training. ",
            "main_review": "There are several technical issues of this work.\n\n1) In context augmentation module, the method applies 1*1 convolutions to do the feature fusion. Although 1*1 convolution can improve the long-distance dependence to some extent, it requires much computations and overhead. So I\ndoubt if it is too heavy to apply so many 1*1 convolution in this module?\n\n2) In the feature refinement module, the expression and the symbol of variables are too complex that may affect reader's understanding. The method is somehow similar to the dual attention network in [R1], which proposed both spatial and channel attention to do the segmentation. However that paper is not cited.\n\n[R1] J. Fu, J. Liu, H. Tian, Y. Lin, Y. Bao, Z. Fang and H. Lu, “Dual Attention Network for Scene Segmentation,” In ICCV, 2019.\n\n3) In the copy-reduce-paste data part, there is no description regarding how to avoid the overlap issue of pasting images, which I believe to be important. If the pasted object and previous one have some overlapping, the training performance will be definitely affected.\n\n4) The paper lacks details on how data enhancement is performed, such as the selection of large objects to be copied and the scale to reduce the large objects. How to control such selections so that the dataset can be balanced?\n\n5) To my understanding, the approach of [R2] is similar or highly related to the proposed work in solving the data balancing issue in tiny object detection. I suggest the authors to compare results with [R2]\n\n[R2] M. Kisantal, Z. Wojna, J. Murawski, J. Naruniec and K. Cho, ”Augmentation for small object detection,” In CVPR 2019.\n\n6) Detailed implementation details of the proposed method is lacking.\n\n7) For the experiment, the paper utilized a different backbone that may make the comparison not fair.\nComparison results in Table 4 and Table 5 are not convincing. Table 4 compares the overall MAP on the VOC dataset (which is not designed specifically for tiny object detection). I think the authors should target datasets such as https://neurohive.io/en/news/a-summary-of-the-1st-tiny-object-detection-challenge/\n\nTable 5 compares the detection performance of tiny objects, however all comparison methods are not designed specifically for tiny object detection.\n\n9) As the title suggests, contexts are used for tiny object detection. However, there is no reference to relevant works that are specifically design to leverage contexts, such as \n\n[R3] J. Lim, M. Astrid, H. Yoon and S. Lee, ”Small Object Detection using\nContext and Attention,” In ICAIIC 2021.\n[R4] X. Tang, D. K. Du, Z. He and J. Liu, ”PyramidBox: A Context-assisted\nSingle Shot Face Detector,” In ECCV 2018.\n[R5] H. Hu, J. Gu, Z. Zhang, J. Dai and Y. Wei, ”Relation Networks for Object\nDetection,” In CVPR 2018.\n\n10) There are some obvious written errors in the paper such as CEM and\nFRM in Figure 1, which are supposed to be CAM and FRM.",
            "summary_of_the_review": "Both the technical method and evaluation results have many issues indicated above, so I recommend rejection.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "The ethics part is OK, as standard VOC dataset is used for object detection.",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper focuses on tiny object detection, and a new feature pyramid network is proposed to combine context augmentation and feature refinement. Experimental results show that the proposed method is better than YOLOV4, CenterNet, and RefineDet.",
            "main_review": "Strengths:\n1.\tThis paper mainly solve the problem of tiny object detection and obtain good results of tiny object detection on VOC dataset.\n2.\tA data augmentation method called copy-reduce-paste is proposed, which can increase the contribution of tiny objects to loss during training, ensuring a more balanced training.\nWeaknesses:\n1.\tThe innovation in the paper is limited, more like an assembly of existing work, such as DeepLabv3+, attention and spatial attention。\n2.\tThe proposed method was not evaluated on other datasets, such as MS COCO dataset.\n3.\tThe main focus of this paper is tiny object detection, but the analysis of small object is limited in the experimental results.\n\nQuestion:\n1.\tWhat’s the ‘CEM’ and ‘FPM’ mean in Figure 1?\n2.\tThe novelty of CAM is limited, A similar structure has been proposed in DeepLabv3+.\n3.\tThe proposed FRM is a simple combination of channel attention and spatial attention. The innovative should be given in detail.\n",
            "summary_of_the_review": "The innovation of this article is limited, and the methods proposed exist in prior works, with minor changes. The originality is not strong. And the experiments are not enough with only a relatively simple VOC dataset.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}