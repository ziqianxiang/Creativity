{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a novel STG network (learning semantic augmentations for each sample of head classes and\napplying in tail classes) to achieve sample-specific and context-aware augmentation to generate new samples for tail\nclasses which have few training data in the problem of long tail image classification. In their three-stage method, a\ndictionary-based memory mechanism is developed to ensure accuracy. The proposed method improves the\nperformance of augmentation and alleviate the problem of overconfidence and overfitting in long tail image\nclassification to some extent.",
            "main_review": "Originality: I think the main contribution of the paper is proposing a STG network to learn sample specific semantic transformations and using it to augment tail classes. The paper proposes some challenges in the augmentation-based method that ignored by many previous researchers. The method of learning the distribution of each sample is very novel. Many parts of the STG module is common or proposed previously, so I am not sure the originality of the design of STG module. The module used in first stage and part of the third stage is well-performed module in previous work.\nClarity: The paper is well organized in general. I suggest that the term “Context Aware” should be explained as clear as “Sample Specific”.\nWhat’s the advantage of “context aware” and the motivation of it?\nQuality: The authors have done many experiments to show the performance of their methods on different tasks. Experiment settings follow\nprevious work and reach a fair comparison. However, there are still a few problems:\n• On Places365-LT dataset, your method achieves the comparable overall accuracy, but performance on few set is worse than some of the\nprevious works. Performance in few classes (tail classes) is more important since the work aims to solve long tail classification challenges.\nIn addition, in page.7 Results on CIFAR-LT, it is said that your method can alleviate more extreme imbalanced distribution better.\nHowever, in Place365-LT with an imbalance factor of 996, which is bigger than that of other datasets, your method performs relatively\nworse than in other datasets.\n• Another concern is about the time and space cost. I am not sure if learning the augmentation distribution of each sample of head classes\nwith dictionary data costs more time and space than previous methods.\nSignificance: From the perspective of method and experiment effect, this paper made some contributions in the domain of augmentation-based method for long tail classification. The dictionary may be seen as a module to solve problems brought by STG, rather than problems in augmentation-based methods or the problem of lacking training data. So although it has some effect, there is still some distance from this\nmechanism and a real novel contribution from my perspective. I am not sure if this work can alleviate the problem of overconfidence in head\nclasses and overfitting in tail classes well at the same time.\nTypos: Page 5. Above section 3.4: “Moreover, the make the predictions”, to make.",
            "summary_of_the_review": "This paper proposes a novel STG network to achieve sample-specific and context-aware augmentation\nto solve long tail classification. The authors proved their method to be effective and can solve some\nproblems regarding augmentation in previous work. However, there are still some problems with\nexperiment on one dataset. Besides, contributions of the dictionary-based memory mechanism are not\nclear.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "===================\nSummary: \nThis paper proposes a three-stage method to address the long-tailed classification task. After the first stage of pretraining, they model the semantic within-class transformation that gives a specific Gaussian distribution for each sample. Such a semantic transformation generator (STG) is learned from head categories in the second stage. Besides, they also develop a dictionary-based memory mechanism in STG to make the estimations of the sample-specific mean and covariance more accurate. In the last stage, they apply STG to samples of tail classes for augmentation during the classifier-tuning. Experiments on CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and Places-LT datasets demonstrate the effectiveness of the proposed three-stage method.",
            "main_review": "===================\nStrengths:\n+ This paper introduces a new strategy to finetune a balanced classifier for the long-tailed classification task, which is different from the conventional re-balancing. Considering the diversity of samples within each class, it may provide a better estimation of the classifier boundaries than previous methods.\n+ Data augmentation is proved to be effective at solving the long-tailed problem, yet, the existing algorithms are uniformly applied to all samples, which ignores the inherent diversity of attributes in each sample. Therefore, sample-specific augmentation is an interesting direction.\n\n===================\nWeaknesses:\n- Based on my experience, I think the design of experiments in this paper is unfair. To be specific, this paper uses the mixup as the training strategy in the first stage, which gives the proposed method an unfair advantage. In long-tailed classification, although mixup itself won't significantly improve the performances on the balanced test set, it can significantly improve the performance of other methods, especially those two-stage algorithms (the proposed three-stage method is essentially similar to the conventional two-stage pipeline with an additional STG for the classifier-tuning stage). Although authors include cRT+mixup and LWS+mixup, they didn't mention how and where they add mixup. I noticed that the performances of cRT+mixup and LWS+mixup on ImageNet-LT are even worse than the results of vanilla cRT and LWS reported by the original paper. I have to assume that authors implement them in a wrong way, or add mixup on the second stage rather than the first stage pretraining. In my own experiments, I found that adding mixup to the first stage pretraining can improve cRT and LWS about 2-3 points, so I hope authors explain why they perform worse than expected in your experiments.\n- Besides, the main contribution of this paper is to introduce a sample-specific augmentation method, yet, the proposed STG takes both sample-specific features and the class-specific tokens as inputs. It makes the audience hard to distinguish which part contributes more in the whole algorithm. If STG is more relying on the class-specific tokens, it would be against the motivation of this paper.\n",
            "summary_of_the_review": "\n===================\nJustification of rating:\nIn summary, the paper is not convincing to me because it's hard to determine the effectiveness of the proposed algorithm and which part improves the performance based on the current experiments in this paper. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a new feature augmentation method for long-tail image classification. The basic assumption is that the different samples in long-tail classes are located in different regions in the feature space and should undergo the sample-specific transformations to account for their differences. A STG network is proposed to accomplish this task, where it defines the transformation by a Gaussian distribution, and trains the multilayer perceptrons to estimate the mean/covariance for the distribution of each long-tail-class sample by taking the means and covariances of the distributions on the head-class samples as the training ground truth. In this process, a dictionary based memory mechanism is also incorporated to account for the relations between samples and hence encode contextual information. Experiments on three long-tail image classification datasets verify the effectiveness of the proposed STG method by comparing with other recent long-tail image classification methods.   ",
            "main_review": "STRENGTHS:\n\n++ The sample-specific transformation is an interesting idea for feature augmentation given that the variance of the within-class samples could be quite different. This paper is one of the first efforts introducing this idea in long-tail image classification. \n\n++The adoption of a memory based mechanism helps to alleviate the sensitivity to small mini-batch size in training. \n\n++ The paper is well-written. \n\nWEAKNESSES:\n\n-- The technical novelty of this paper is limited. The distribution based data augmentation originates from the ISDA method, and the paper extends it to sample-specific fashion. The extension itself is a simple regression task to estimate the mean and covariance. The memory mechanism is also a well-known technique in literature. \n\n-- A few key assumptions this paper makes don’t have a theoretical justification. For example, 1) given that mini-batch is random, how to justify the ground truth mean and covariance are reliable GT for training ? 2) Why does learning STG on head classes generalize well on long-tail classes? 3) For the class-specific token, is one single vector sufficient for each class with large variances in the semantic space ? Isn’t such one holistic vector strategy conflicting with the whole sample-specific assumption this paper rests upon. \n\n-- Some key experiments are missing. 1) While sample-specific learning is appealing, a natural question arises on how the method works comparing with the region-specific learning (i.e., grouping similar samples as a set (smaller than a class) and learning a transformation for it). 2) The whole idea of feature augmentation and memory mechanism is related to the self-attention mechanism in transformers. How does the method work compared with attention based long tail classification methods in literature? e,g., Zhu et al. Inflated Episodic Memory with Region Self-Attention for Long-Tailed Visual Recognition. CVPR 2020. 3) Is the sample-specific strategy hurting accuracy on the head classes ? \n",
            "summary_of_the_review": "This paper proposes an interesting idea on learning sample-specific feature augmentation for long-tail image classification. However, it has some distinct drawbacks on the technical novelty, theoretical justification and experiment evaluations. I therefore learn towards a negative direction on this submission. \n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper provides a three-stage framework to tackle the long-tailed image recognition problem. Such a three-stage frame is built upon the existing decoupling training setup. The major contribution of the paper comes from the feature augmentation between representation learning and classifier learning. The proposed method differs from existing feature augmentation methods by learning a sample-wise and context-aware augmentation.",
            "main_review": " In general, the framework is demonstrated to be effective through the experiments and the authors accomplish their goal well. \n\nThere are a few questions of mine:\n1. ‘we use the token of the most similar head class for each sample of tail classes’ -> How is similarity measured?\n2. ‘we define learnable class-specific tokens {p1, · · ·, pc }’ -> why should the token be learned?\n3. ‘The estimated µi and Σi serve as the ground truth statistics of s(ai; θs) for the supervised learning of STG’ -> In the second stage where the backbone is frozen, why not use the ground truth statistics to augment the feature? In other words, what is the purpose of training an STG network?\n4. In table 4, the most similar head classes for samples from the same tail class are different. What is causing this? I would encourage the authors to be more thoughtful about this. This could probably reveal why sample-wise augmentation is feasible and indeed better than the class-wise counterpart.  \n5. In table 5, ‘In contrast, our method can achieve the same overall accuracy while preserving performances on head classes’ -> Does this mean the proposed feature augmentation is not as effective as MiSLAS on tail classes?\n6. What exactly does ‘context information' refer to in this paper? \n\nMinor issues:\n- ‘the more abundant the samples, the more accurate the estimated statistics’ -> ‘the more abundant the samples are, the more accurate the estimated statistics are’\n- ‘the make the predictions more stable, we smoothly update the estimated statistics for the same sample.’ -> ‘‘to make the predictions more stable, we smoothly update the estimated statistics for the same sample.\n- The usage of ’strengthen’",
            "summary_of_the_review": "In general, the paper in its current form is difficult for me to grasp the contribution given: \n\n1. The writing of the paper needs further improvements. I do suggest the authors revise the writing carefully.\n2. The paper lacks in-depth reasoning and analysis.\n\nTherefore, I lean toward a negative direction at this moment.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}