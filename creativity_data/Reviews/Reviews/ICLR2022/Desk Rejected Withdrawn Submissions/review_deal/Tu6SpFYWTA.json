{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper presents a new approach for distinguishing synonyms and antonyms via an extension of a parasiamese neural network, called \"the repelling parasiamese network\".  The strengths of the paper, as identified by reviewers, are a novel architecture for antonymy detection, a new dataset, and solid empirical results. However, there are major drawbacks identified by reviewers w5dj and hoTU. Specifically, there are clarity issues in writing, lack of a proper justification to the proposed architecture, insufficient details about the quality of datasets, insufficient contextualization in prior work. The scores are borderline, but unfortunately, the authors did not use the rebuttal opportunity to sufficiently address these questions/concerns raised by the reviewers. I thus recommend to reject the paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents the new approach for distinguishing antonyms and synonyms. This task could be interesting for further applications such as paraphrasing and text entailment. The authors present proposed the repelling parasiamese neural network. The model with several setups was tested on three datasets of antonyms and synonyms pairs showing the improvement over the baselines.\n",
            "main_review": "The task and the idea are indeed interesting. However, there are some moments that require clarification.\n\nIn Section 2.3.1, the expression (3) directly illustrates one part of the definition of antitransitivity relations. It is not clear why the special name “left anti-Euclidean” relation was introduced and why the Property occurs. Moreover, the name “anti-Euclidean” does not seem to be proper. If there is a need for such a term, then the Proof is inconsistent. As, again, expression (3) shows only one side of antitransitivity definition, then the proof should also cover a part when aRb /\\ bRc -> !(bRc).\n\nIt is not clear why in Section 4.1 three datasets are described, but the Table 3 with results consists only of two parts. Are Xie’s and Nguyen’s datasets incorporated in each other somehow?\n\nAlso, it would be better to show more details about datasets. It was stated that they consist of pairs of antonyms and synonyms relations. However, one of the main stated goals was to show that antitransitivity relations could be learnt by the model and illustrated on the data. Table 4 shows such an example set. But it is interesting to know if there are any such triangles in the train datasets originally and how the model behaves on such samples. \n\nThe work will also benefit from ablation study of the necessity of both types losses for model training. In Table 4 it is unclear what letter in brackets (T) and (P) are stand for. It can be guessed, but it requires direct description in the caption of the table. So, more clarification how losses were included in training, both of them or separately, would make the work more understandable.\n",
            "summary_of_the_review": "Overall, the paper presents an interesting approach. However, more attention should be dedicated to the details in theoretical part and more thorough testing of the proposed approaches.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a simple new architecture for the task of antonymy detection. The architecture is an extension of a previous architecture for the same task, known as the parasiamese network. The new architecture, called the repelling parasiamese network, essentially contains a copy of a siamese network and a parasiamese network tied together using a euclidean loss. Experimental results on several datasets demonstrate that this architecture can detect antonymy reliably and sometimes even beat the state of the art. ",
            "main_review": "While this paper proposes a new architecture for antonymy detection with provably strong results, I do not recommend this paper for acceptance due to several reasons, the chief among them being the lack of clarity in the paper.\n\n- First, the motivation for the architecture is very hand-wavy, and while it \"works\", the justification provided is not solid. It is is also very hard to connect the various parts of the paper. Part of this is the language of the paper (see next section), but also the connections between sections are not well made.\n- Second, the paper is couched in very unclear language which makes this further difficult to follow.  For instance, I do not understand this what this sentence means (Sec 2.2 -- \"Antitransitivity is a drawback if a distance function is pretended to be considered to distinguish antonymy, \"). Simplifying the language of the paper and improving the clarity will go a long way in improving the strength of the paper.\n- Finally, the paper does not contextualize itself very well with respect to prior work. Specifically, the work of Mrkšic´ et al. has been cited, but the concept of the repelling parasiamese network and the attract-repel framework of that paper have extremely similar philosophies. It would be useful to understand what is common with that work, and what is different (i understand the architecture is different, but the question is at a more conceptual label).\n- I am also uncertain about the quality of the dictionary based dataset. Can the authors comment on the how they ensured that the ground truth in this dictionary is actually of high quality? Was there any human evaluation done on a subset of entries of this dataset?",
            "summary_of_the_review": "This paper is currently not suitable for acceptance as it is extremely unclear and hard to follow, and does not contextualize itself with respect to prior work clearly.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The task is a binary classification task.  The system is given a pair of words that are either synonyms or antonyms.  The task is to say which pairs are synonyms and which are antonyms.\n\nTable 3 reports results on two datasets: (1) Nguyen's and (2) Fallows's.   The second dataset is a contribution.   This paper points out the usefulness of https://www.gutenberg.org/ebooks/51155\n\nThe paper proposes a new model, REPELLING PARASIAMESE NEURAL NETWORK.\n\nResults in table 3 are impressive, especially on Fallows's\n\nThe suggestion of using triplets is nice.",
            "main_review": "I think there are some nice contributions here.  It is always nice to find a new dataset such as Fallows.  The triplet suggestion is also nice.\n\nThe repelling suggestion is a nice improvement over Etcheverry and Wonsever.\n\nIt would help the community to provide a github.\n\nI found table 4 a bit hard to read.  I wonder if it would help to move table 4 closer to the discussion of triplets (3.1.2), and then make\nit clear how the values in the table correspond to variables in the formula.  ",
            "summary_of_the_review": "There are some nice contributions here.  The main innovation of the paper is the repelling contribution to Etcheverry and Wonsever, though the Fallows dataset might have more impact on future papers by other researchers.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}