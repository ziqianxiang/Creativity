{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper considers the problem of learning a generative model of the joint p(clean, noisy) image distribution from unpaired data (i.e., without a dataset of (clean, noisy) image pairs). The key idea is to assume that x (clean) and y (noisy) are conditionally independent given two latents z (content information) and z_n (degradation information). The conditional p(x, y | z, z_n) can then be factorized into p(x | z) p(y | z, z_n) which removes the dependence on paired data. Inference is performed using variational inference. The model can then be used to generate a synthetic dataset of paired images for training a supervised method for downstream tasks.\n\n\n\n",
            "main_review": "Strengths:\n- Interesting problem and approach\n- Shows good results in tested settings\n- Different generation options are ablated\n\nWeaknesses:\n- Applicability to other types of tasks? (e.g. non denoising)\n- Applicability to other downstream tasks? (e.g. style transfer)\n- Not sure if the basic idea has been explored in this setting (the authors discuss Wolf et al 2021 up front which seems different)",
            "summary_of_the_review": "Overall, the problem setting and the approach are interesting. My main question is regarding the applicability of the proposed approach to other settings and downstream tasks. I suggest borderline for now.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a method to learn the joint probability density function of data sampled from marginal distributions. The purpose of the method is to provide an alternative for tasks that rely on ‘paired data’, e.g. image restoration or super resolution. As collecting such paired datasets can be troublesome in practice, the paper describes a VAE based approach capable of learning from ‘unpaired’ data by making an inference invariant assumption (Learning from Unpaired Data VAE, or, LUD-VAE). They empirically show the utility of their LUD-VAE model on real-world image denoising and super-resolution tasks, where they perform on-par with other state-of-the-art methods.\n\nThe main contributions of the proposed model are:\n- Alleviate need for paired datasets\n- Training stability over alternatives\n- Fewer parameters than most recent competitive alternative (DeFlow from Wolf et al ‘21)\n",
            "main_review": "__Strengths__\n- Sections 3.1 and 3.2 as well as the appendix clearly describe the theoretical need for the proposed method\n- Compared to alternative methods, the basic model setup appears simple (this is a good thing)\n\n\n__Weaknesses__\n- As the paper suggests the LUD-VAE model as a replacement for models that require large amounts of paired-data, it would be useful to see experimental results as to how the performance of both types of models compare when paired-data is available, e.g. in experiment 4.3 on the Nitre20 dataset.\n- The empirical results do not seem to represent a significant improvement over the existing methods presented in this paper. For example:\n  - Table 1: scores between LUD-VAE and Impressionism are very close together, such that claims of robustness would be strengthened by providing the standard deviation over multiple random seeds.\n  - Figure 6: the paper claims that visual results of LUD-VAE are closer to the supervised DnCNN results than the other models, yet, this reviewer has difficulty confirming this.\n  - Figure 10: the visual results of the real-world image denoising from SIDD dataset, that contains various sample images with writing on them, appear quite problematic for the LUD-VAE model. Results are blurrier than the presented alternatives.\n- While on various occasions the paper highlights that the proposed LUD-VAE model uses fewer parameters than existing alternatives, it does not provide robust ​​quantification of the magnitude of the difference in parameters used, e.g. Table 1 provides a ‘Num of Parameters’ column, but fails to inform the reader what the model choices are that can increase/decrease these magnitudes in relation to performance. It also lacks the number of parameters for two of the comparison models. \n  More importantly, while the number of parameters used can be important from an environmental or ease of research iteration perspective, it is by now known that over-parameterized models often improve training, see e.g. Zhang et al ‘17 (Understanding deep learning requires rethinking generalization), Arora ‘18 (On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization), or more recently Buhai et al ‘20 (Empirical Study of the Benefits of Overparameterization in Learning Latent Variable Models). As such, a more interesting comparison is how the number of parameters would compare for the fully trained, distilled versions of both models. To avoid confusion, this reviewer is not suggesting the authors distill/compress all comparison models, but perhaps review some of the literature on compression/distillation of large neural networks to get an idea of how strongly deep models can often be reduced in size, e.g. Louizos et al ‘17 (Bayesian Compression for Deep Learning).\n\tTherefore the statement made in ‘Comparison with DeFlow/DeFlow-NP in section 4.3: “In addition,the amount of parameters in DeFlow is much larger than our model, which will bring difficulties to practical use”, is ungrounded. \n- While the authors highlight some of the perceived stability concerns of GAN-based models, they underrepresent the many known issues of learning with VAE-based models.\n- Most importantly, to this reviewer it is difficult to understand how their method works in practice and how it alleviates the need for paired data. Specifically, the following sentence in section 4.2 is unclear: After the training process, we use LUD-VAE to transfer the clean dataset to the degraded dataset, forming a paired training set with the high-resolution clean images\n\n\n__Correctness__\n- The inference invariance assumption, based on the graphical model presented in Figure 2, of z → x, (z, z_n) → y, seems problematic. Generally, one would not be able to say this as the graphical model has an inverted fork. However, while the first half of equation 8 is reasonable, i.e. choose a variational posterior such that the distribution of z only depends on x, and not on y, the second part makes a much stronger assumption. Namely, we now need to find q such that the distributions z are the same for all x and y, or put differently, that z is independent of both x and y. This seems like a very strong/odd assumption. It is unclear how the justification given in 3.2, i.e. In practice, this assumption is not strong and can be easily satisfied using a pre-trained network or predefined operations, further elaborated on in section 3.3, would alleviate these concerns.\n- The graphical model presented in Figure 2, in which z → x, and (z, z_n) → y, does not seem to be consistent with the model architecture in Figure 4, where z_n also connects to x.\n\n\n__Clarity__\n- In the beginning of 3.2, i.e. utility of a VAE over traditional EM, the paper might improve in clarity by providing a short description of the classic VAE learning objective. \n- The quantitative results presented in Tables 1, 2 and 3 would be easier to interpret if best results per column/row would be highlighted.\n- For the used evaluation metrics presented in section 4.1, it would likely benefit the reader if a more detailed explanation was given of how such metrics should be interpreted. For example, the explanation givens in section 4.3:\n\n> The evaluation metrics, PSNR and SSIM focus on the restoration of the overall content of the image, while LPIPS pays more attention to the image details, so these two types of metrics are mutually exclusive to each other. Most models tend to perform well on only one type of metric,\n\ncould be moved to 4.1 instead.\n- Section 4, ‘Experiments and Results’, is currently quite crowded with implementation/training details, which could distract the reader from interpreting the presented empirical results. The section could therefore benefit by moving many of the training implementation details, e.g. hyperparameter choices (4.2, beginning of 4.3, beginning of 4.4.), to the appendix to focus the reader’s attention on the task objective and results discussion in the main text.\n- The settings described at the end of section 4.2 for the different datasets, would likely be more clearly displayed in a small table.\n- The paragraph on KL-annealing in section 3.3 likewise discusses a specific implementation/training choice, and could thus logically be grouped with the training implementation appendix. The technical term the authors may want to use is ‘posterior collapse’.\n\n\n__Relation to prior work__\n- Classic (and recent) works on diffusion models seems relevant to discuss in related work, e.g. Chen et al ‘15, ‘16 (On learning optimized reaction diffusion processes for effective image restoration, Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration) \n- VAE use in super resolution, most recently by Gatopoulos et al ‘20 (Super-resolution variational auto-encoders)\n\n\n__Additional feedback, comments, suggestions for improvement and questions for the authors__\n- To quickly convince the reader of the importance/utility of this work, the paper would benefit by describing the importance of paired data for certain downstream machine learning tasks, and the difficulty/expense of creating such datasets directly at the start of the appendix, e.g. Paired data is an important/necessary input for state of the art machine learning models for tasks ABC. But although these sota models require paired data, creating paired data sets is time-consuming/expensive/difficult. Un-paired data on the other hand is widely available, which is why recent research has focused on designing models able to learn from un-paired data to alleviate the dependency on paired data.\n- There are a number of places where the paper makes strong claims without appropriate justification or providing references (see e.g. _introduction_: 1, 4, 5, and _related work_ 3 below in addition to the claims on model size discussed above).\n\n\n__typos/minor points__\n\n_Abstract_\n1. Collecting the paired training data is a difficult task in practice, but the unpaired samples broadly exist → Although unpaired data samples broadly exist, collecting paired training data is an expensive/time-consuming/… task.\n2. From the data sampled from → From data sampled from\n3. to the real-world image denoising and super-resolution tasks → to the real-world tasks of …\n4. Experimental results on four datasets validate the advantages of our method over other learnable approaches → add high-level description of advantages, e.g. quantitative, qualitative, ..\n\n_Introduction_\n1. have been an astonishing success → have had\n2. due to the high complexity of tasks → collection of data is difficult due to the task complexity? Unclear\n3. The large second paragraph could be broken up into multiple sub-paragraphs, e.g. the two most popular research approaches each get a paragraph\n4. However, these methods often require careful adjustment of different losses, and the heuristic constraint of cycle consistency is too weak for our problem and lacks theoretical rigorousness. More importantly, those GAN-based methods usually obtain a deterministic mapping while ignoring the randomness in the degradation generation process → there are a number of claims being made here that should have more justification.\n5. However, the training process of the DeFlow method encounters unstable problems → according to?\n6. In concrete, given x → Given x\n7. Using the idea from VAE, we introduce → We introduce\n8. We demonstrate the model performance of on two  → performance on two\n9. very competitive and using much fewer network parameters → competitive, using much\n\n_Related Work_\n1. can be considered as the image-to-image transfer task → as an image-to-image ..\n2. Most of the existing works employ the GANs (Goodfellow et al., 2014), mainly using cycle-consistency Bulat et al. (2018); Lugmayr et al. (2019a)  → Most existing work are GAN variants, using the cycle-consistency principle proposed in .. and/or domain adversarial techniques to characterize the …\n3. These methods often use heuristic losses, lack theoretical guarantees, and need elaborate fine-tuning of those losses → [...] losses that lack [..]. and need elaborate fine-tuning.\n4. Meanwhile → Additionally\n5. There are also handcrafted methods to synthesize degradation images (Ji et al., 2020), but lack generalization ability. → what are the pros of this method? In which way do these models lack generalization ability?\n6. Variational auto-encoder (VAE) (Kingma & Welling, 2013) based unpaired learning for degradation modeling is currently less developed; here, we investigate some related topics [...] → To the best of our knowledge, there are currently no unpaired learning models based on the VAE framework. We will therefore discuss a selection of work that similarly employs VAE based models for related tasks.\n\n_Our Methodology_\n1. one straightforward idea is to estimate the conditional density p(y | x). However, due to the lack of paired data, it is difficult to model the conditional density function directly → Ideally one would like to estimate the conditional density p(y | x). This is unfortunately difficult to model directly due to the lack of paired data.\n2. To conduct the inference of the graphical model given by Figure 2, we apply the → To perform inference on the graphical model [...], we use/utilize the\n3. we choose the inference model has the decomposition → we choose the following decomposition of the inference model\n\n_Conclusion_\n1. LUD-VAE is under the → LUD-VAE under the \n\n_Appendix C_\n1. Maximal Likelihood → Maximum Likelihood\n2. In the next → Next\n\n_Appendix D_\n1. For figures 8, 9, 10 it would be useful to keep the position of LUD-VAE fixed\n\n",
            "summary_of_the_review": "While the paper seeks to solve a seemingly interesting problem, namely alleviating the need for paired datasets for popular downstream tasks like super resolution or image denoising, the key assumption made in the theoretical justification of the proposed model appears incorrect.  \n  \nAdditionally, the paper makes a number of strong claims on several occasions that require more justification or relevant references. This is especially relevant for two of the stated contributions of the proposed model, (i) improved training robustness/stability over alternatives, and (ii) using fewer parameters than alternatives.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper deals with the problem of improving image quality (image super-resolution or denoising) without any paired training examples and proposes a generative model of pairs of clean and degraded images based on the framework of variational auto-encoders (VAEs). The proposed generative model named LUD-VAE introduces two different latent variables each corresponding to image contents and noises and decouples an encoder distribution conditioned on the pair into two independent ones. This enables us to simulate a joint distribution of the pairs with no paired examples. Experimental evaluations with several standard benchmarks for super-resolution and denoising tasks demonstrate the effectiveness of the proposed method against several previous methods in terms of PSNR.",
            "main_review": "[Advantages]\n- The proposed method effectively introduces the idea of variational auto-encoders into the problems of image denoising and super-resolution. This generative approach enables us to produce pseudo pairs of clean and noisy images without any paired training examples. Also, the introduction of two different latent variables is reasonable and technically sound.\n- The overall presentation and organization are satisfactory. The concept of the proposed method is clearly presented and easy to follow. \n\n[Drawbacks]\n- The paper title should be fixed since it is clearly overstated. The proposed method requires several strong assumptions on paired data. First, a pair should be organized by clean and noisy images, as presented in the first section of the paper. This indicates that the proposed method cannot be applied to pairs of different modal data (such as images and texts). Second, the proposed method requires Equation (8) for obtaining a joint distribution from unpaired data. This indicates that generative models for two examples constituting a pair should be the same and thus the proposed method cannot be applied to pairs of images with different contents. If the authors believe that the proposed method can be applied to any type of pair, they should justify it with concrete clues. Or, they should fix the paper title.\n- If my understanding is correct, possible applications of the proposed method would be only image denoising and super-resolution. This implies that paired examples can be easily generated if clean images (in the denoising case, images with high resolutions in the case of super-resolution) are available. From this viewpoint, I strongly recommend that the authors change the applications used in the experiments.\n- Other minor comments:\n-- Equations (3) and (4) contain the same typo: p(z, z_nx, y) --> p(z, z_n, x, y)\n-- The divergence term in Equation (4) lacks a pair of brackets.\n-- Figures (5) and (6): The original images should be presented. Smoothness is not always required for recovering the original image.",
            "summary_of_the_review": "Currently, I have a negative feeling about this paper since the assumptions required for the proposed method and its possible applications do not seem to be realistic. Fixing all the problems will require a substantial amount of revisions for the proposed method and experiments. However, if the authors can solve my possible misunderstandings, this paper might be able to be accepted as-is.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}