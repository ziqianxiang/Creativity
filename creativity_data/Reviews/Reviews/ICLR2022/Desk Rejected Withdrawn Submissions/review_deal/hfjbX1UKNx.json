{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, the authors use multiple choice learning to improve mode diversity in GAN training. In particular, the authors propose using a mixture of expert discriminators, each one focusing on a subset of dataset, which are in turn used to train the generator network. With several balancing terms in the objective, each discriminator is made to focus on subset of samples and the generator model is trained to fool every discriminator. Results show that using multiple discriminators improve sample quality and mode coverage.",
            "main_review": "While the authors demonstrate the use of multiple discriminators in GAN training, I have these major issues: (1) The idea is similar to GMAN and I feel authors have not done a good job in studying the differences between the approaches and justifying why (and what specific component) their approach is better than GMAN, and (2) With the provided experimental results, I am not very convinced the need for using multiple discriminators in the first place, (3) The approach seems to involve a lot of balancing terms which would need careful tuning to prevent some denegrate solutions.",
            "summary_of_the_review": "The idea of the paper is very similar to GMAN where the multiple discriminator setup is used. The authors need to talk about the differences more clearly. In my opinion, both GMAN and the current paper uses max-critic to train the generator. As the authors mentioned in last paragraph of page 1, the only difference lies in the method of ensembling. The authors should study the effect of this component in more depth since this is the only point of difference in both approaches.\n\nMore specifically, have the authors used the same architectures and tricks for comparing GAN training between GMAN and their approach, with the only point of difference being the ensembling approach? This experiment is needed to study the effect of ensemling.\n\nIn the approach, it is not clear how the variables u’s and v’s are optimized. Do we assign one vector for each sample and  optimize them? If so, the number of optimization variables increases with number of samples which may be problematic for large datasets. If not, then how are they optimized?\n\nThe approach seems to involve a lot of balancing terms which are really needed to ensure that all discriminators are utilized and each one focuses on a distinct subset of samples. This needs careful tuning which might not be too desirable.\n\nIn page 5, “for each example since the discriminator with the highest score is guaranteed to be chosen as an expert. “ Is this guaranteed? From the formulation, the decision to choose the expert relies on the variable v and u. Its not clear how v and u are optimized?\n\nThere are some papers that use multiple generators and one discriminator? The point being each generator focusses on one subset of the data. This makes sense. How does this compare with multi-discriminator setup used in the paper? Which one is better - what are the tradeoffs? Can multi-generator multi-discriminator setup be used?\n\nIf the discriminator is complex enough, do we need multiple discriminators? With the success of deep models like StyleGAN and BigGAN, the complexity of discriminators keep increasing drastically. This begs the question “what benefit do we really gain by using multiple discriminators?”\n\nFrom the experiments, the authors show that their approach is beneficial. But, the FID scores of SOTA models on CIFAR and CelebA have gone much lower than what has been reported here (For example, BigGAN has a FID of 14.73 in CIFAR). With this in mind, I am not sure about the importance of these results reported here.\n\nHow exactly are the precision  and recall metrics calculated here?\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors propose a technique to train GANs with multiple discriminators inspired from Multiple Choice Learning (MCL). This hasn’t been done to date in my knowledge. The idea is to make the discriminators specialize on a subset of the data via clever design of the loss function.",
            "main_review": "There are several things I like about the paper:\n1. The approach seems to be novel especially the part about balancing discriminator updates and non-expert training.\n2. A new technique (to my knowledge) in order to adjust the number of discriminators used during training on the fly.\n3. Good breadth of ablation studies (in the appendix)  \n\nHere are some of my thoughts/criticisms:\n1. Unclear why there is no comparison with Neyshabur et al. and Albuquerque et al. and other similar papers. These seem like direct competitors to the proposed method (multiple discriminators) and are more recent than GMAN (which is used as a baseline). I think this is the biggest drawback of the paper as it stands. There is no way at the moment to conclude how good the performance actually is wrt prior work.\n2. Training with multiple discriminators would increase model parameters. A fair comparison would require baselines which account for this.\n3. Datasets which are used in the paper are small. It is hard to tell whether the proposed technique works only in small settings (both in terms of image dimension and diversity) vs much more diverse settings like ImageNet (or its subsets). As it stands, the improvements in diversity seem to be marginal. \n\nFormatting/Typos:\nThere are several minor grammatical mistakes (too many to list). I hope the authors re-read the manuscript and correct them. Some examples:\n1. Section 4.1 “encourage the generator finds the closest mode” should be “encourage the generator to find the closest mode” \n2. Section 4.3 “This adjustment helps stable training and ” should be “This adjustment helps stablize training and ”",
            "summary_of_the_review": "Overall, the lack of a fair evaluation and writing issues lead me to not recommend publication.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work improves upon generative multi-adversarial networks (GMAN) by incorporating ideas inspired by multiple choice learning (MCL) to diversify the discriminators. By encouraging the discriminators to diversify and specialize in different modes of the data distribution, the authors hope to better avoid the problem of mode collapse for the generator. The number of modes in the data distribution is, in general, unknown, so they propose overpopulating the number of discriminator experts and then learning to rely on a smaller subset via L1-regularization. To reduce the overhead that naturally comes with training multiple discriminators, they propose sharing portions of the network across discriminators. Experiments on synthetic, text, and image data reporting precision, recall, FID, and other metrics support the efficacy of the approach.",
            "main_review": "Strengths: At a high level, the idea of diversifying the discriminators in GMAN to better specialize in distinct modes of the data distribution is sensible. And leaning on past approaches like multiple choice learning to encourage this behavior is a good idea. The approach also attains performance competitive with or better than prior models in many settings.\n\nWeaknesses:\n1) The precise approach taken is unclear. In particular, how are $v_{i,m}$ and $u_{j,m}$ set? These seem central to the training protocol. I understand the concepts from section 3 on multiple choice learning and the role of these variables, but I never saw a formula or learning rule provided for these variables. For example, if $v_{i,m} = 1$ iff $| \\\\{ p | D_m(x_i) < D_p(x_i) \\\\} | < k$, i.e., $D_m$ outputs one of the k-largest values, then this should be stated explicitly somewhere. Note this also implies that $v_{i,m}$ is a function of $D$ and a function of $D$'s parameters. When backprop'ing through the loss functions in equation (10), are these differentiated?\n2) Given my confusion around $v_{i,m}$ and $u_{j,m}$, I was also confused how the balance losses affect the selection of experts. I understood from your discussion that equation (8) was introduced to encourage the discriminators to be similarly confident about samples in each minibatch to avoid pathologies early in training. However, I could not connect this with $v_{i,m}$ for a deeper understanding.\n3) The losses used to train the discriminator and generator are not standard. The original GAN minimax objective is $V(G,D) = E_{x \\sim p(x)} \\log(D(x)) + E_{z \\sim p(z)} \\log(1-D(G(z)))$ where the generator minimizes V and the discriminator maximizes V (minimizes -V). To improve training speed, Goodfellow suggested replacing the second term in the generator's objective with $-E_{z \\sim p(z)} \\log(D(G(z)))$. In contrast, in your equation (3), the discriminator's loss is of the form $\\log(1-D(x))$ which does not match any form of the standard objective I just repeated. I was expecting to see the discriminator minimize $-\\log(D(x))$. Likewise, equation (4) has the discriminator additionally minimize $\\log(D(G(z))$. Normally, I would expect to see minimizing $-\\log(1-D(G(z)))$. To be clear, these objectives aren't entirely wrong, they are just not what are normally reported and no reason was give for this deviation from the norm.\n4) Equation (6) seems to exist to discourage an expert on data mode X from also being an expert on data mode Y. Is that correct? This seems sensible for training the expert discriminators, but the rationale for a similar objective for the generator in equation (7) was not clear to me. Can you explain why you include equation (7)?\n5) The comparison to GMAN is not clear. Note that in GMAN, the authors differentiate the discriminators by initializing them with different architectures. They give each discriminator a different dropout rate and vary the number of filters in the layers. They also feed each discriminator a different slice of the minibatch from the data. Did you do this as well? I would suggest pointing out in the text that GMAN differentiates discriminators through their architecture while you attempt to differentiate discriminators through which data you train them on. Also, GMAN introduces several variants. It explores using an arithmetic mean, harmonic mean, etc to aggregate the discriminators. It also introduces an automated way of adjusting the temperature of the softmax aggregator. Please specify these details in the paper.\n6) One piece of literature worth including in your review in section 2.1 is PacGAN: The Power of Two Samples in Generative Adversarial Networks --- (https://par.nsf.gov/servlets/purl/10168460).\n7) Please spend a few sentences explaining the metrics NDB/JSD and LPIPS. Also, does \"+MCL+MS\" refer to MSGAN with your additional losses added?",
            "summary_of_the_review": "Overall, I like the idea of diversifying the discriminators in GMAN to be experts on separate modes of the data and using MCL or other old techniques to accomplish this. But I felt like the approach was not described clearly which makes it difficult to assess. I also was unclear on which version of GMAN was being compared against. The exposition needs work.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes using multiple discriminators in GANs in order to better learn the diverse modes of the data and guide the GAN’s generator towards them, and therefore mitigate the problem of mode collapse. The main novelty compared to other multi-discriminator GANs is in the use of Multiple Choice Learning, where only a confident subset of discriminators are used for guiding the generator on each given sample, to ensure that discriminators specialize. The proposed model is applied to two GANs (StyleGAN2 and DCGAN) in various tasks, and shows improvements compared to some baseline single-discriminator and previous multi-discriminator GANs.",
            "main_review": "**Strength:**\n\nThe adaptation of Multiple Choice Learning for multi-discriminator GANs is novel, and the specifics of how to use MCL can potentially be useful for other applications of adversarial learning in general. The paper provides experiments on various tasks which provides a broad sense of how well the model works. The organization is good and easy to follow for the most part.\n\n\n**Concerns and Questions:**\n\n1- The advantage of using MCL is not well motivated, the paper’s motivation goes only so far as this one sentence: “Note that all the existing approaches learn the multiple discriminators independently and they may have strong correlations, which may not be appropriate for diversifying the generated samples.” The “may have” and “may not” are not good motivations/justifications for the need of MCL. The toy example of section 5.1 would be a good place to highlight the shortcomings (e.g. the suggested correlations) in previous multi-discriminator GANs, but this experiment only compares with a single-discriminator baseline.\n\n2- Another major concern is lack of comparison to the-state-of-the-art on the datasets used in the paper, namely small diverse datasets such as CIFAR-10. A recent finding is that the issue of mode collapse, which this paper is trying to address, could be the result of the discriminator overfitting to the limited training data, and consequently discriminator augmentations have been proposed as an effective solution [1]. This paper does not cite or compare with such works. In particular, StyleGAN2-ADA [1] is the current state-of-the-art on CIFAR-10 and several other small datasets, and given that the reported performance of that work far exceeds the numbers in this paper (see Figure 11a of [1]), it is unclear whether the proposed MCL-GAN is an orthogonal improvement to data discriminator augmentation, or will its effect fade when using the augmentations. I noticed that in Appendix I.2, the paper mentions using StyleGAN2-ADA repo but without its augmentation, which is the main contribution of that model, so why wasn't augmentation used?\n\n3- While the paper provides experiments over various tasks (which is great), it is lacking in terms of systematic comparison to other multi-discriminator GANs, which in my opinion is much more important given that a myriad of such models have been proposed and it is crucial to highlight the advantages of this particular new model with respect to them. Specifically, I’d like to know why some GANs are dropped from some experiments (for example Table 3 and Figure 3 only compare with one multi-discriminator baseline).\n\n4- A central claim in the paper is that the proposed MCL helps discriminators specialize and this will help improve multi-discriminator GANs’ performance. However, looking at Figure 4 in Appendix A, we see several discriminators (e.g. orange colored) cover multiple modes. Similarly in Figure 10 (k=1), several discriminators (e.g. mid to last rows) cover multiple modes. So the improvements cannot necessarily be the result of better specializations. Moreover, in Appendix F.3, the paper confirms that the use of L1 loss, which is proposed to ensure better specialization, is minimal on the performance metrics, placing more doubts on the main claim that more specialized discriminators results in less mode collapse (better performance). All these nuances, which seem contrary to the main premise of the paper, are absent from the main paper, and therefore could result in misleading conclusions for the reader.\n\n5- The loss functions in Eq. 3,4,5 are inconsistent with how the GAN optimization is commonly carried out to avoid vanishing gradients. To elaborate, the discriminator objective is commonly written as log(D(x)) over real samples and log(1-D(x)) over fake samples, and this ensures that incorrectly classified samples receive large gradients (i.e. real samples with small D(x), and fake samples with large D(x)). However, the way Eq. 3,4 is written, namely log(1-D(x)) for real samples and log(D(x)) for fake samples, gradients will only be large on samples that are already correctly classified (i.e. real samples with large D(x) and fake samples with small D(x)). Same goes for Eq. 5. Is this just a notational error, or is this a deliberate choice and is used in implementation? If so, why?\n\n[1] Karras, Tero, et al. \"Training generative adversarial networks with limited data.\" NeurIPS 2020 (2020).",
            "summary_of_the_review": "My main concern is whether this proposed model is in fact effective when combined with the current state-of-the-art discriminator augmentation GANs, particularly because these models already do a very good job of capturing variations in all the modes, and solve the mode collapse issue to a great extent (given that the paper already uses the StyleGAN2-ADA repo, it is not clear to me why the authors decided not to compare with StyleGAN2-ADA). The usefulness of the proposed model heavily relies on the aforementioned concern, and unless it is clarified, I cannot recommend this paper for acceptance. An additional concern is the paper's claim that MCL-GAN achieves better performance due to better specialization among discriminators, which is not consistent with some of the findings, as pointed out in the main review.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}