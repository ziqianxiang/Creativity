{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes the use of Reynolds operator for learning equivariant and invariant networks.\n\n\n",
            "main_review": "Overall the paper seem to build on a remarkable result that the Reynold operator can be represented as a sum over a subset instead of a sum over the whole group. I do think that this result has the potential to be very meaningful for learning task, but as far as I could read the paper it seems to remain in a mathematical abstract area and doesn't fully bring the potential of this result to anything concrete.\n\nThe authors are able to prove some universality results to their model, but eventually there is no real statement that using their methods they can achieve any meaningful improvement in any specific criteria.\n\nThe experiments are also too brief and too synthetic to be convincing.",
            "summary_of_the_review": "I found the theoretical results as well as the experimental results lacking.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper presents a method for designing invariant/equivariant networks. The method is based on the idea that invariant/equivariant functions can be constructed by averaging functions over the group elements. However, when the group size is large, summing over the group elements is infeasible. The main novelty in the proposed model is the ability to get an exact computation of the average by considering only a subset of group elements.\n",
            "main_review": "I think that the idea of Reynolds design is very interesting.The fact that Reynolds design leads to  universal equivariant models is a clear advantage over other design alternatives.\n\nHowever, I have some concerns regarding the paper in its current form. Comments are detailed next.\n\n*Motivation for the method*\n\nThe paper starts by stating two permutation invariant models, [1] and [2]. What are [1] and [2] shortcomings, which the current paper tries to overcome? I expected to see some discussion on this issue as part of the introduction. Moreover, what previous attempts have been made to construct equivariant models with Reynolds operators, and what are the key differences with the current one? I believe previous methods [3] have tried dealing with the computation challenge in a different way. Again, this should be discussed as part of the introduction. \n\n*Relation to parameter sharing*\n\nThe first paragraph in the introduction discussed parameter sharing as a motivation for some model designs. However, the suggested model does not enjoy such property. This should be discussed and emphasized in the paper. \n\n*Introduction for the invariant case*\n\nThe paragraph in the introduction related to invariant Reynolds design is hard to follow.\n\n*Potential Mistakes*\n\nIn the example after definition 3, in the computation of tau_sn , isn’t a (1/n) factor missing?\nIn theorem 7, isn’t the order of F_T composition with e_T,b is stated in the wrong direction? It should be e_T,b  ( F_T)?\nIn proposition 18, should it be definition 17?\nWhat is gamma_G in definition 17? Should it be tau_G ?\n\n*Reproducibility*\n\nSome important details are missing from the description of the experiments. For example, how many fully connected layers with how many neurons were used? What does applying ReyNets following [1] means? \n \n*Experiments*\n\nThe method is only tested with synthetic data. I think it is crucial to evaluate the method on real data as well. \nFurthermore, a comparison of forward time to [1] is expected as well.\n\n\n[1] Maron et al. (2018)\n\n[2] Zaheer et al. (2017)\n\n[3] van der Pol et al. (2020)\n",
            "summary_of_the_review": "* Interesting idea with some potential.\n* Paper is hard to follow. The main ideas are not presented well. An effort should be made to provide better explanations. Motivate the suggested method and identify its properties with respect to other alternatives.\n*Experiments with real data are missing.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper suggests a new family of S_n-invariant/equivariant neural networks for sets/graphs/hypergraphs with maximal expressive power (i.e., universality). There are two main ways in which one can construct invariant/equivariant models (Yarotsky, 2018): (1) by using invariant/equivariant building blocks (2) by using a powerful, yet not invariant /equivariant model (e.g. a fully connected network) and averaging over the group. The second option yields a provably universal model, but in many cases in which the group is large (S_n), it is not feasible. The paper tackles this strong limitation by suggesting averaging schemes with significantly fewer summands: for example n^2 instead of n! For second-order tensors (graph representation). The paper defines the new models, based on this more efficient summation, proves universality theorems, and provides a limited experimental section on simple invariant/equivariant tasks. \n",
            "main_review": "Strengths:\n-- The paper tackles an important problem: designing on S_n invariant/ equivariant models with maximal expressive power. Unlike most papers, this paper follows the averaging approach suggested in [Yarotsky 2018,2021] and tackles its main limitation. The fact that the number of summands can be significantly reduced while maintaining invariance/equivariance is beautiful.\n\nWeaknesses - I have two main reservations: Writing quality and experiments\n-- Writing: The paper is difficult to read. Specifically, the authors should make an effort to reduce the technical details in the main paper and try to convey the main ideas more clearly. Additionally, intuition is missing. I suggest deferring the proofs to the appendix and using the space in the main paper for providing more intuition and examples. \n-- Experiments: The experimental section is weak and contains comparison only to several simple tasks (introduced in Maron et al.). While these experimental results provide some knowledge about the model, and evaluation on real datasets (e.g., graph classification benchmarks ) would significantly strengthen the paper. If such an experiment is not possible for some reason I expect the authors to discuss this.\n",
            "summary_of_the_review": "The paper tackles an important problem and proposes a very nice way to overcome a significant obstacle in previous approaches. However, the writing is not ready for publication and the experimental results are lacking. I would be happy to raise my score if these two issues are properly addressed in the revision.\n  \nSpecific comments\n-- add “Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs.” in the second paragraph\n-- spherical design - add reference\n-- poor writing. Missing motivation for high order tensors, assumes previous knowledge (“taking the sum of the orbits” - which orbits?)\n-- The part about equivariance in the intro is not clear.\n-- “Kondor et al. (2018); Maron et al. (2019a;b); Chen et al. (2019) investigate more efficient graph neural networks” - not true.\n--  Universality prior work section is very inaccurate  \n-- “power of one variable” - missing scalar multiplication. Maybe define \\cong\n\n-- Section 4 - why are the diagrams important/related? Try to motivate\n-- Try to motivate thm 7.\n-- the paragraph at the bottom of page 6 is important. I would move it to the beginning of the section and use it as motivation.\n-- figure 3: please add a proper caption. Which experiment?\n \n\nPost rebuttal:\n---------------\nI am grateful to the authors for taking the time to address my concerns and revise the manuscript as a result. The experiments on real graph datasets have impressed me and I look forward to seeing more. My score has been raised to 6.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}