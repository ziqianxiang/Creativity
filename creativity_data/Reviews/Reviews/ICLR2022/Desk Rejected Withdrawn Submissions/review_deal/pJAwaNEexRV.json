{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper studies the problem of Assisted Learning (AL) where organizations assist each other to learn supervised tasks without sharing data, model and loss functions. The authors propose a new method Gradient Assisted Learning (GAL) inspired by Gradient Boosting for the vertically distributed federated learning setup. Key contributions include - extending loss functions to more general ones, private loss functions at each organization level and parallel aggregation of outputs from organizations and gradient assistance weights to control learning contribution from each organization. Empirical results show the correctness of the proposed method.",
            "main_review": "Overall I like the idea of applying gradient boosted inspired ideas to this problem setup and feel it is novel. It is of practical importance and will be interest to the privacy and federated learning communities. The ideas and technical quality of the paper is good however there is not enough clarity in the background and problem setup (I have outlined some questions I have about my understanding of the setup). I think the authors should give another pass to make these sections clearer. Empirical study is good, but not exhaustive in my opinion and can be made more stronger (more analysis and discussion about why less communication rounds are needed for GAL, discuss the statistical significance of the results). I like the ablation study performed to test the effect of various noise levels and the resulting outcomes from this experiment.\n\nQuestions/Comments:\n- Problem setup is not fully clear. In section 3.1, it needs to be clearly mentioned what \"collaborator\" means in this context - does a collaborator have access to part of Alice's data? or labels? or something else too?\n- \"pseudo-residuals\" -> not clear what this means in section 2 and why proposed method needs fewer rounds to converge compared to Federated learning setting. Later on in section 3.3, it is mentioned that Alice broadcasts psuedo residuals to other organizations, but not clear how these are computed (this becomes clear when you look at the algorithm later, but the earlier statement in section 3.3 should also briefly mention it so that the reader is not confused)\n- Are each of the organizations going to use the same loss? If yes, what's the need to introduce L_m? If not (which seems to be the case), I do not understand how we measure convergence and residuals when each organization is optimizing a different loss function?\n- How much is the cost for each organization to solve the local problem to find the optimal f_m^{t}?\n- How much is the cost to solve for the optimal gradient assistance weights w?\n- How much is the cost for the line search?\n- In the algorithm, I do not understand how the gradient assistance weights are maintained back on the probability simplex? Is there a\nprojection operation after optimizing these weights that maps them to lie on the simplex?\n- In the prediction stage, why is learning rate used while gathering the predictions from multiple organizations?\n- What is the intuition behind requiring less assistance rounds?\n",
            "summary_of_the_review": "There is some novelty in the proposed GAL algorithm and its inspired roots from Gradient Boosting. It is of practical value to privacy, federated learning and distributed optimization community - thus has a good impact factor. Technical content is good. Presentation and Empirical Study/Discussion are the weaker parts of the paper in my opinion at this point. I feel the authors can make this work stronger after these are addressed.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper considers the distributed learning scenario where the underlying entities may have little interest in sharing their data, proprietary models and objective functions. The authors propose a new method, Gradient Assisted Learning (GAL) , as a strategy for other entities to assist each other without sharing data, models, and objective functions. \n",
            "main_review": "This paper studies an interesting distributed setting where entities could help each other. This paper is well written and easy to follow. Experiments are extensive. I also have the following concerns.  \n\n1. The distributed setting considered in this paper is novel but may have some practical shortcomings. For example, for other entities, we need them to fit the “residuals”, which essentially requires regression objective functions. Does it mean that only entities with regression objective functions can assist the target entity? Furthermore, if most entities use classification objective functions, which is possible because of the variety of classification tasks, the benefits of the proposed method might be limited. I am quite worried that the proprietary loss functions at other entities may not be compatible with the residual fitting loss. \n\n2. The residual that needs to be approximated from Equation 2 is defined over distribution over all features p_{x,y}. Since Alice does not have access to all features, it’s not clear how the residual is computed.  \n\n3. Two sub-optimization problems need to be solved at each round in order to get weights $\\hat{w}_t$ and learning rate $\\hat{\\eta}^t$.  \nMore discussion on how costly it is to solve them could be very helpful. \n\n4. In the second paragraph of Section 3.2, what is y in the formula for $F_{Alone}$ and $F_{Joint}$? Is it a typo for $y_1$?\n",
            "summary_of_the_review": "I have been working on related areas and have read this paper carefully.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Setting: data is partitioned vertically across firms and each firm has a proprietary ML task they aim to solve. \n\nThe authors propose a method how the firms can assist each other in improving their service without sharing their data, models or training objectives.\nThe procedure generalizes gradient boosting and works as follows: Firm A fits a model using its local data. Then it computes the residual for each sample and shares this with the other firms. These firms fit the residual and share their predictions. Firm A then finds the optional weights to weight these predictions to best fit the residual for its local loss. The weights are stored, the residual is again computed and the procedure is repeated. At test time firm A needs to collect all the predictions of the residual models in order to aggregate them using the stored weights.  \nAn asymptotic optimality result is provided and empirically the method is compared to several baselines for different models and datasets. The authors conclude that their method offers competing performance to existing methods while requiring less communication.\n",
            "main_review": "**Strength**\n\n-\tThe paper is easy to follow and the procedure is well explained. \n-\tCollective learning without sharing data or models is an important problem.\n\n**Weaknesses**\n\nThe term assisted learning is a bit misleading and the procedure has important limitations that make it very unpractical. I would like to be convinced that there are setting where the required level of coordination is feasible.\n\ni) Assistance is not only required during training but also for every inference task. The procedure does not help firm A to train a better predictor, it only learns how to aggregate the residual predictions of other firms. This implies that it heavily relies on the other models being available for any inference task and having access to the respective features of the individual that needs to be predicted. \n\nii) You are not only asking additional training from other firms, but you ask them to store all the intermediate models trained to help firm A and these models need to be ready to be queried on demand. These models do not have any other purpose, so this is quite a lot to ask for.\n\niii) In each round you rely on each firm having access to different features of the same N samples. Furthermore you need to identify the individuals so you can match the different predictions. Could you justify scenarios where this is realistic to assume?\n\n*Some clarifying questions and comments*\n\n1. The role of the loss function for fitting the residual is not discussed much. Since you do not want to reveal the loss function, the residuals could be fit using a different loss function that the target. My intuition is that, in the spirit of boosting, you will be fine as long as the prediction provide some information gain. I would expect that the more the objectives are aligned the fewer boosting rounds you need. \n\n - Could you elaborate more on how different these loss functions can be from the target objective and what is beneficial for learning? \n - In your theoretical analysis what is the role of the assumption that L be in the spam of the organization specific function classes?  I would appreciate some intuition.\n\n2. You extend AL to train multiple organizations in parallel. Why do you want this? It seems to me that you need to demand less compute, storage and communication from each firm if you would fit them sequentially, which is what you care about. Or is this intuition not correct? I am not convinced by the claim that GAL is much better than AL.\n3. Can you give an example where you do not want to reveal your loss function because of privacy reasons?\n4. One of the main motivation for your method is to reduce communication. It would be nice is you could provide more discussion about the communication cost of your method in comparison to the baselines and evaluate or quantify it for the empirical results you provide.\n",
            "summary_of_the_review": "The paper is well written, the description of the method is clear and the idea to parallelize the residual computation in boosting without coordinating on the loss to be used seems novel. However I have a couple of questions and I am concerned that the proposed model of cooperation is highly unpractical so that the advantage of reducing communication costs is not significant enough to justify the required compromises. \n\nIf the authors can convince me otherwise and address my questions I am willing to increase my score.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes Gradient Assisted Learning, a method for decentralized supervised learning without sharing data, models, and objective functions among different organizations. It generalized Assisted Learning to allow private local training model and objective function, and parallel aggregations across multiple organizations. The authors develop GAL algorithm, provides asymptotic convergence analysis, and experimental results that shows the performance of GAL is close to centralized learning results.",
            "main_review": "Strength\n\n1) The proposed GAL approach is novel for allowing parallel optimization among assisting organizations, and generalizing loss functions.\n2) The authors provides comprehensive experiments, both classification and regression, to show the effectiveness of proposed GAL algorithm v.s. AL and VAFL. \n\nWeakness\n\n1) The authors advocates GAL over AL on reducing number of communication rounds and parallel optimization, and as a result has low communication and network costs. It would be great if the authors can provide the computational times in the experiment section to quantify the time-saving advantages of GAL decentralized learning.\n2) The authors claim that GAL significantly outperforms AL, and I only find one example from the paper which supports that (e.g. MIMIC3). It would be a more convincing statement if the same observation holds for the other two regression datasets (Diabetes/Boston Housing). The same goes for the computational time for GAL v.s. VAFL, as their accuracies on ModelNet40 don't differ much.\n\n\nSome typos:\n1) page 3, last paragraph, E_{N}L_1(y,F_1(x_1)) --> E_{N}L_1(y_1,F_1(x_1))\n2) page 4, second paragraph, a continuous - valued vector r_1 = [r_{i,1}]_{i=1}^N \\in R^{N \\times k}, what is k here? number of classes for a classification task?\n3) page 8, caption of figure 4, MIMIC3 (d-e) --> MIMIC3 (d-f)\n3) page 8, second last paragraph, 1) GAL requires much less number -->  2) GAL requires much less number \n",
            "summary_of_the_review": "Overall I vote for accepting. I like the novelty of the proposed GAL algorithm on parallel optimization across assisting organizations, and generalization of loss function over AL. My major request is more evidence for supporting statements that GAL outperforms AL, and GAL is computationally more efficient than AL and VAFL.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}