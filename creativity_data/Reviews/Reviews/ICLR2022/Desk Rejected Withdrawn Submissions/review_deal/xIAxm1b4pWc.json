{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper proposes to incorporate unsupervisedly extracted emotion-related tokens/embeddings to improve sentiment classifiers trained on top of BERT. The strengths of the paper, as identified by reviewers, are in the importance of the problem, a relatively easy-to-reproduce method, and a clear write-up. However, all the reviewers identify several major weaknesses, including the lack of a clear research question, unclear contribution, limited novelty of the method, missing baselines, and relatively small gains in the downstream task of sentiment analysis. In sum, all the reviewers agree that the draft is not yet ready for publication."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "##########################################################################\n\nSummary: \n\nThis works proposes a sentiment classification approach for transformer-based models that employs additional embeddings to represent emotion inputs. These additional emotion inputs are generated using pre-trained transformer in a zero-shot fashion. Experimental results show a modest improvement for existing approaches such as BERT and DistilBERT. \n\n##########################################################################",
            "main_review": "##########################################################################\n\nPros: \n\n1. Sentiment classification is an important task that has unlimited real-world applications and can also improve the performance of other NLP systems. \n\n2. Although the proposed pipeline is simple. I was easily able to follow the paper, yet I am unable to understand the contribution of the work.\n\n##########################################################################\n\nCons:\n\n1.  I am unable to see a technical contribution of this work. To me, emotion detection is a more challenging task than sentiment classification (the author also highlight this), whereas the proposed work is employing emotion classes to improve sentiment classification.\n\n2. The results do not look very different, with and without emotion information. Moreover, the way to incorporate emotion information in the existing transformers is straight-forward. \n\n3. Can you please share details on the t-test and how and whether the results are statistically significant.\n\n##########################################################################",
            "summary_of_the_review": "##########################################################################\n\nReasons for score:\n\nOverall, I vote for rejection. I like the application side of the paper. But, technically, I am unable to see a contribution of the proposed work. Moreover, the it is quite confusing to use emotions (i.e., more difficult task) for sentiment classification (i.e., relatively easier task).\n\n##########################################################################\n\nQuestions for rebuttal: \n\nFeel free to answer to all the concerns.\n\n##########################################################################",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed to add special emotion tokens and embeddings to pre-trained BERT models to improve performances on the sentiment classification task. It obtained modest but statistically significant improvements over the BERT and DistilBERT models on Senti140 and USAirlines datasets.",
            "main_review": "Strengths:\n- The proposed model is simple and easy to reproduce.\n- The custom embeddings help improve the BERT and DistilBERT models on two sentiment classification datasets.\n\nWeakness:\n- The idea is not novel. And it is straightforward to come up with the idea of prepending task-related tokens to the input texts.\n- The usage of citation styles is not correct in most cases.\n- The introduction part doesn't well describe the motivation of the proposed method.\n- Most of the related works are not closely related.\n\t- The authors should discuss more work on prepending tokens to the input of BERT models.\n\t- The authors should add comparisons with related work that utilizes emotion information to improve sentiment classification.\n\nWill such custom embeddings improve results on emotion classification? \nHow to adapt the model to other sentiment/emtion tasks beyond binary classification?",
            "summary_of_the_review": "The authors need to revise their description of the motivation of the proposed method. \nBesides, research works on emotion classification and prepending task-related information into BERT should be discussed.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a simple way to supplement emotions related information to a downstream classifier. Authors first utilize a pre-trained BART Model to predict probabilities of a pre-defined set of emotion-related words. Then, they prepend the emotion words as text input to the transformer-based classifier. On two public sentiment classification datasets, authors show that adding emotion information leads to decent performance gains.",
            "main_review": "### Strengths:\n- The authors propose an intuitive, easy-to-implement way to provide additional information in the form of emotion words to improve a downstream sentiment classifier. The paper shows that adding such information improves sentiment classification information on two sentiment classification datasets.\n- The paper describes the experiments in great detail.\n\n\n### Weaknesses:\n- The Paper lacks a research question that the authors are trying to answer. I would suggest authors first define a research problem that they are trying to solve and then should design experiments to answer that. For example, if the research question is to investigate ways in which one can augment pre-trained transformer models, then authors should compare multiple ways to inject such knowledge and carefully study the effectiveness of multiple methods using ablation studies. In the current form, the paper solely focuses on improving performance on a given dataset and reads like a course/Kaggle project report instead of a research paper.\n- Paper lacks a good baseline. As part of the zero-shot pipeline, you are running a BART model so one fair baseline could be to add embeddings generated from BART forward pass to the downstream classifier. Such a process will have an equivalent model capacity and runtime complexity, hence it's a fair baseline to have. Since adding additional information to BERT style models is not novel, authors should also consider comparing their approach with the previously proposed approach such as [1].\n- This work is naturally connected to prompting [2] as prompting provides a simple yet effective way to extract useful information from pre-trained models which can be used for classification. In fact, the 0-shot pipeline that authors are using is doing prompting with the BART model. So, I think it's important to connect this work to promoting literature. Further, I would argue that you don't need the BART model at all as you can simply use prompting to generate a probability distribution over the selected emotion words. Simply pass \"<Your sentences>. This was a {mask}\" to the BERT model and BERT can provide you conditional probabilities of all emotion words that you can use for your downstream classifier.\n- Authors spend a great amount of time discussing ensembling gains. On most of the tasks, we can improve performance using a model ensemble so this piece of information is not at all useful to the NLP community. I would recommend limiting ensemble discussion to just 1-2 sentences and adding additional experiments (ablation studies, comparison with other methods) to make this work interesting.\n \n\n### References: \n1. Yu, S., Su, J., & Luo, D. (2019). Improving BERT-Based Text Classification With Auxiliary Sentence and Domain Knowledge. IEEE Access, 7, 176600-176612. \n2. Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2021). Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. arXiv preprint arXiv:2107.13586.",
            "summary_of_the_review": "The paper in the current form does not thoroughly answer a single research question, hence I don't think it's ready for publication. The paper requires significant improvement on all fronts including experimental design as well as paper organization. ",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Authors are adding emotions related information to the text, it's possible that it might lead to bias amplification in certain cases. In particular, if the 0-shot pipeline is unfair for a given group (race, gender), it's very likely that adding emotion signals from such a pipeline will make the overall classifier's bias worse for that group.",
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}