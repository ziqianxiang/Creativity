{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a black-box label-based adversarial attack. The authors report the high efficiency of the attack, that occurs due to the usage of Bayesian optimization in a low dimensional space.",
            "main_review": "The paper seems to be quite similar to [1]:Binxin Ru also uses Bayesian optimization for a surrogate model for $g(x)$ in DBA scenario. They note the same challenges: a need for low-dimensional subspace and a need for continuous function optimize. So, they deal with the same statement from [2].\nIn contrast to this work, they provide many details on their approach and how do they overcome the limitations of GPs etc.\n\n\nExperimental results:\n* The dataset used for evaluation is hard to find (ImageNet?). \n* It is a bad practice to use only one dataset. It is useful to add CELEBA or CIFAR10 for the sake of comparison and to understand the limit of applicability of the proposed approach. Many modern approaches work better for one dataset and worse for others.\n\nHard to reproduce:\n* details on low dimensional input space and relation ablation study\n* no details are given on the quality of GP model\n\nPresentation:\n* A lot of misprints especially in formulas\n* Some spaces are dropped\n* Formulas: what is $\\delta$? Please, use specific commands for min, max, sign, argmax, exp; use correct size of brackets (e.g. $\\left(\\frac{a}{b} \\right)$ allows automatic selection of the size of the brackets\n* Formulas are part of the text. They should have the right punctuation inside and in a neighborhood of them: commas, dots, etc.\n* For Matern kernel $r = \\|x - x'\\|_2$ or $r = \\|x - x'\\|_1$, as it should be a scalar\n* Pay more attention to references. E.g. [Li, 2021] - no arxiv link, no conference name not specified\n* Double-blind policy is violated, as there is a direct link to GitHub repository in the paper \n* Figure 3 - better to add x-axis label\n\n[1] Binxin Ru, Adam Cobb, Arno Blaas, and Yarin Gal. Bayesopt adversarial attack. In International\nConference on Learning Representations, 2019\n[2] Minhao Cheng, Thong Le, Pin-Yu Chen, Jinfeng Yi, Huan Zhang, and Cho-Jui Hsieh. Query-\nefficient hard-label black-box attack: An optimization-based approach. arXiv preprint\narXiv:1807.04457, 2018.",
            "summary_of_the_review": "A paper of limited novelty due to the existence of [1].",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes an Bayesian optimization (BO) based approach to decision-based adversarial attacks. The basic idea is to minimize the distance to the desired output for a given direction in the input space. To avoid the high-dimensional optimization, a generator of the direction is employed, which can generate popular noise types such as the Perlin noise. The performance is evaluated by using well-known models such as ImageNet.  ",
            "main_review": "The proposed method is a simple application of BO to adversarial attacks. The basic idea would be fine, but I'd have to say that the technical novelty of the paper is somewhat weak. The framework is already established by Zhang2021 in a sense that to minimize the distance to the boundary, and the black box optimization is performed by using a similar binary-search based querying in that existing paper. As the authors mentioned, there are several differences including the perturbation generator, but technical significance of them would be a bit marginal, though the approach is reasonable. Although Zhang does not use BO, applying BO itself is not particularly novel since the problem is already known as a black-box optimization. \n\nThe authors mentioned that when the fine-grained search exceeds the input bounds, the maximum distance is assigned. For example, when the region of the target class is relatively small in the input space, this exceeding can occur in a wide range of the input space. Then, since the function g' is constant in that region, the optimization would become quite difficult.\n\nHow is the stopping criterion of binary search determined? If it stops too early, the output becomes non-continuous that can be difficult to fit by GP. If it is too strict, the number of queries in one iteration increases. \n\nHow \\eta in Algorithm 1 is determined? How can algorithm 1 be justified that it can find the minimum distance? In my understanding, the algorithm is an approximation in which it is possible that the true minimum can be overlooked. Is there any guarantee to find the true minimum or be close to the true minimum?\n\nAlgorithm 1 is similar to one used in Zhang2021, which should have been explicitly clarified.\n\nI could not find the setting of the dimension d' of \\delta in the experiments. Since BO is often sensitive to the dimension, readers would have interest on how large d' the proposed framework actually worked.\n\nWhy initial value of l_infty distances are different in Fig3?\n\nIn eq (3), \\theta should be normalized?",
            "summary_of_the_review": "The entire framework is reasonable and setting is interesting, but the proposed method is a mostly simple application of existing technique.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper aims to generate efficient adversarial attacks with higher success rates and fewer queries for handling the problem of hard label black-box adversarial attacks in low query budget regimes. More specifically, the authors adopt a Bayesian Optimization (BO) based approach to find adversarial perturbations. Experiments on architectures based on the ImageNet dataset demonstrate the efficacy of the proposed algorithm.",
            "main_review": "Strengths:\n- The paper is well written and easy to follow.\n- The algorithm is simple yet very effective and outperforms existing baselines by a considerable margin. \n\nWeaknesses:\n\n- The authors miss citing a very relevant paper using an almost identical approach to this paper. \n\" Simple and Efficient Hard Label Black-box Adversarial Attacks in Low Query Budget Regimes\" Shukla et.al., in KDD 2021.\n\n- I am afraid the techniques considered and developed in this paper have been already studied and well developed in Shukla et.al. Except for the binary search in distance evaluation, there's virtually no difference between the algorithm proposed in this paper and the one in Shukla et.al. I would recommend the authors to specifically point out as to what are the innovations on top of the algorithm in Shukla et.al., so as to set this algorithm apart. In particular, please also add a baseline to the experiments for the algorithm in Shukla et.al.\n\n- The experiments section leaves a lot wanting. The evaluation of the proposed attack scheme is only limited to untargetted attacks with $\\ell_{\\infty}$ being the distance metric. The evaluation is also only limited to ImageNet. I would recommend the authors to also include comparisons for MNIST and CIFAR-10 with $\\ell_{2}$ based attacks. If possible, please include targeted attacks as well. \n\n",
            "summary_of_the_review": "Recommend to reject as the algorithm is nearly identical to a previously published paper with no clear innovations and additions on top of the previous algorithm.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper proposes a new algorithm, BO-DBA, to conduct decision-based adversarial attacks. BO-DBA follows Cheng’s formulation and models the DBA as the search for the direction of adversarial noise. And BO-DBA uses the Bayesian optimization to the distance function of the directions so that the query efficiency of the attack is largely incrased. ",
            "main_review": "Pros\n1. While using Bayesian optimization is not novel for the black-box adversarial attacks (e.g [1]), there have not been many papers studying the it in the context of decision-based black-box attacks.\n\nCons.\n1. The paper hide too many details of the algorithms and the experiments so that it is hard to evaluate the real performance of BO-DBA. The paper does not post any number of success rate and average queries. Only the curve of the success rate and the average queries is not enough. And the paper emphasize that dimension reduction is important for BO-DBA. However, I do not know the exact dimension it uses for the perturbation generator.  It is shown in the curve of success rate in the Figure 1 that different methods use different number of images for the detection models. However, the number of images is not posted in the paper. Besides, the gnerator used in Figure 1 is not posted. There are many other unclear details make the paper hard to reproduce. \n\n2. The paper uses is relatively big adversarial budget $\\epsilon=16/255$. It there any reasons to choose this value? And it shown in RayS [3] paper that they achieve more than 80% success rate on Inception-V3 under 1000 queries (Figure 2 of RayS). However, it is not the case in Figure 1. Is there any reasons to explain the difference?\n\n3. I do not understand the ablation study in Table 1. As the adversarial budget is limited inside $16/255$, why is the number of $L_\\infty$ so large?\n\nOthers.\n1. For the writing of the paper, there should be a space between the citation and the context.\n2. In the first line of Algorithm 1, $\\frac{S(\\delta')}{S(\\delta')}$ should be $\\frac{S(\\delta')}{|S(\\delta')|}$\n3. As the paper is focusing on the black-box adversarial attack, which may bring threat to the practical systems of machine learning, ethics discussion of it should be added.\n\n[1] Binxin Ru et.al., BayesOpt Adversarial Attack, ICLR 2020\n\n[2] Jinghui Chen et.al., RayS: A Ray Searching Method for Hard-label Adversarial Attack, KDD 2020\n\n",
            "summary_of_the_review": "I think paper proposes an novel method for solving the decision-based adversarial attack. However, it lacks of too many details of the algorithms and the experiments. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}