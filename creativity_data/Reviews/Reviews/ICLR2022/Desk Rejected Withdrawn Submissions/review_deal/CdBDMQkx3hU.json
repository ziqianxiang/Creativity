{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a method to jointly search neural architectures and data augmentation policies.\nThe proposed method adopts Gumbel-softmax reparameterization for NAS task, and introduces a policy gradient-based method for augmentation search.\nThe paper discussed the strength of policy gradient algorithm(for augmentation search), multiple sampling, and joint searching.\nThe proposed method has been evaluated on Cifar10/Cifar100 and ImageNet datasets and shows competitive performance and efficiency.\n",
            "main_review": "Pros\nThe paper is generally well written and easy to follow.\nThe experiments show good results.\n\nCons\n1. The proposed method can be roughly summarized as Gumbel softmax-based DARTS + policy gradient-based AA + multiple sampling.\nAs already noted by the authors, Gumbel softmax-based DARTS and multiple sampling are existing works.\nHowever, the policy gradient-based AA, which is listed as the primary contribution, is not well distinguished from existing works like OHL-AA[1].\nBoth DAAS and OHL-AA apply REINFORCE to optimize augmentation policies. DAAS utilizes one-step approximation, while OHL-AA directly optimizes validation accuracies.\nThis should be properly addressed in Section 2 and Section 4.4.\n\n2. The combination of policy gradient-based AA and DARTS is the key point of this paper. But this point is not directly justified.\nFor example, have you compared your method against DARTS + DADA? Further, as noted many times, multiple sampling is an important technique for estimating gradients.\nHow would DARTS + DADA + multiple sampling perform?\n\n3. The experiments are not so convincing to some extent.\nIn Table 2, most of the compared methods(except for DHA) do not utilize searched augmentation policies, which makes the comparison unfair.\nWe can hardly answer the fundamental question: whether jointly optimizing NAS and AA brings substantial improvements over separated optimization.\nAlthough Table 6 gives an ablation on this question, the only experiment weakens the claim, let alone the minor improvements of 0.1%.\nThis problem is more clear in Table 3. The architecture searched by DAAS is at least 10% larger(in both FLOPs and Params) than other methods, and the compared ones do not utilize searched augmentation policies.\nThese two unfairness greatly weaken the 1% improvement.\n\nOther Questions\n1. In section 4.4, the paper claims that Gumbel reparameterization trick is problematic for augmentation policy parameters.\nIntuitively, this should hold for architecture parameters as well. So why still use Gumbel trick for NAS part?\nAre there any intrinsic differences between augmentation policy parameters and architecture parameters?\n2. The paper emphasizes the importance of multiple sampling many times. How does this technique affect the results?\n3. Table 4 and Table 5 seem duplicate, they basically address the same point. I suggest merging Table 4 into Table 5 for clarity.\n[1] Lin, Chen, et al. \"Online hyper-parameter learning for auto-augmentation strategy.\"",
            "summary_of_the_review": "The main idea of combining DARTS and policy gradient-based AA sounds, but the experiments are not thorough enough to justify the contribution.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a differentiable method to jointly search the neural architecture and data augmentation policies for the image classification task. Experimental results show that the proposed method is efficient and the searched results perform slightly better than the separately searched results with exist methods.",
            "main_review": "Strengths:\n1.\tThe idea of jointly searching the neural architecture and data augmentation policies is somewhat interesting.\n2.\tThe proposed search method is quite efficient.\n\nWeaknesses:\nThe improvement is not significant. From Table 6, we can observe that the proposed method (joint) only performs slightly better than the independent scheme. \nThe overall novelty is somewhat limited. The idea for architecture search is similar to GDAS (Dong & Yang, 2019) and ROME (Wang et al., 2020a), and the idea for data augmentation policies mainly comes from DADA (Li et al., 2020).\nThe presentation should be improved. I find some minors (e.g., page 2, line 5, ‘In contrast, a’) and irregular typesetting layouts (e.g., Figure 1).\n",
            "summary_of_the_review": "Based on the above mentioned strengths and weaknesses, I think it’s a marginal work for ICLR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This work proposes to jointly search for coupled neural architectures and data augmentation methods. For NAS tasks, the authors adopt a single-path based differentiable method with Gumbel softmax for memory efficiency. For auto-augmentation tasks, they propose to use a policy gradient based algorithm to search. The achieved accuracy is decent.",
            "main_review": "Strengths:\nThe targeting problem of jointly searching for architectures and augmentation policies is timely and promising.\nThe adopted policy gradient based search algorithm outperforms Gumbel reparameterization one in terms of computing workloads.\nThe authors argue that they for the first time propose the jointly search idea. While Table 1 seems to contradict this claim.\nThe performance is promising, 76.6 top-1 accuracy on ImageNet.\nThe ablation studies are comprehensive and validate the effectiveness of proposed joint search.\n\n\nWeakness:\nThe second bullet point of contribution is not complete.\nThe achieved results of DAAS seems to be comparable with prior work DHA when evaluating on CIFAR datasets, from which I cannot see too much benefit of the proposed methods. How about the comparison in ImageNet?\nHow comparable are the achieved accuracy to other NAS methods, e.g., FBNetv3, EfficientNet?\n",
            "summary_of_the_review": "This work proposes to jointly search for coupled neural architectures and data augmentation methods. I think this work is timely and the achieved results are decent.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a method to search the neural architecture and data augmentation jointly. For this, authors utilize bilevel optimization as in DARTS. The proposed method is validated on multiple datasets with its leading performances.",
            "main_review": "#### **Strong points:**\n1. The proposed method is simple, straightforward, and efficient.\n2. The discovered architecture and auto-augmentation are transferable to a more large-scale dataset.\n3. The paper is well-written and easy to follow.\n\n#### **Weak points:**\n1. The novelty is somewhat limited. As provided in the paper, there are already two works on joint search for data augmentation and the architecture. In addition, bilevel optimization, Gumbel reparameterization trick, and policy gradient method have been widely used in the AutoML community. \n2. I wonder if the “joint” optimization is required to achieve the leading performance of the proposed method. The main reason for it could be just a well-defined search space for auto-augmentation. Tables 4 and 5 reveal that the performance is always better with the found data augmentation. Also, results in Table 7 show that training other architectures with a found auto-augmentation yields almost similar performance (accuracy gaps on CIFAR-10 are smaller than 0.005 with no error bars).\n3. Tighter comparisons with DHA & Kashima et al. (2020) are needed. DHA is also a joint search method of data augmentations and neural architectures. However, essential results on DHA are missing in the paper, e.g., its results on ImageNet & # params in Table 2. Moreover, I cannot find any comparison with the results of Kashima et al. (2020).\n\n#### **Questions and comments:**\n1. I’m not fully convinced of the claim that a neural architecture requires tailored data augmentation. Could you provide more theoretical and empirical results on how and how much they are coupled?\n2. Bold fonts in Tables 2 and 5 are misleading. The result of DHA on CIFAR-10 in Table 2 is better than the proposed method but not marked in bold. In addition, the result of AA on CIFAR-100 in Table 5 is better than DAAS.",
            "summary_of_the_review": "It seems that the method can efficiently and effectively solve the joint-optimization problem. However, I think more investigations are needed to claim the necessity of jointly searching neural architectures and data augmentation.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}