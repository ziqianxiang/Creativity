{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents a regularizer that is computed per-layer in training a convolutional neural network. The regularizer is intended to induce equivaraince with respect to certain group-action on the feature-map. The primary motivation for such a model is to address what are described as limitations of steerable-CNNs which are based on restricting the kernel space to some pre-constructed basis depending on the transformation group in question. Several empirical results are presented and discussed in support of the approach. ",
            "main_review": "The motivation of the paper is very interesting and clearly described with a well written introduction section. I would like to encourage the authors to explore and develop the idea further. Below are some of my main concerns, questions and suggestions.\n\n- Core method:\n   - The definition of the regularizer is not clear Eq(5); why is the Euclidean difference between a transformed feature-map and a regular \nfeature map used as a measure of equivaraince? Could you also explain how this might lead to a kernel space that leads to equivaraint \nconvolutional operator? This is major point as the proposed method is attempting to show how such a solution can be equivalent if not \nsuperior to steerable-CNN, which define an explicit kernel space for the problem it it tries to solve.\n\n- Evaluation and experimental Performance:\n   - In the case of Rot-MNIST reported results are very close including CNN’s. Could the authors disclose the model capacity (complexity)? I believe this to be an important variable when assessing the impact of the proposed method. Mainly because even in CNN high capacity models does learn redundent feature detectors specializing in possible orientation of the input data. Hence, can exhibit high performance without being explicitly equivaraint. Even in the case of Rot-Tim, R2-Tim, CNN-augmented is performing on par which makes the argument for the IEN network not convincing enough. I would suggest to look at some specific experimental setups where CNN-augmented fails and Group-equivariant networks have a clear advantage. In such a case, the regularizer introduced in IEN can be evaluated and distinguish itself for better or worse. Example: 1) Consider evaluating the approach using a low-capacity models (# parameters significantly small). 2) Consider training on Rot-MNIST and testing on MNIST: In such a case a model that is mostly based on averaging variation (like augmentation) will clearly fail whereas a truly equivariant network retains its performance. \n- Missing references\n  - [1] Demisse et al. “Approximately Covariant Convolutional Networks” 2021. The works motivation, including the “Implicit Equivaraince Hypothesis”, and goal seem to be very similar with what was described in [1]  have you considered comparing your method and the method presented in [1] in both approach/formulation and result?  For instance, in [1] it was argued against the explicit use of regularization term to induce equivariance across layers. \n  - Missing reference for Rot-TIM, R2-TIM datasets. \n- Suggestions and comments:\n  - I would suggest to include and integrate what was discussed under “Implications”( a seemingly subsection of introduction) directly into the introduction and where the motivation for the work is discussed. \n  - Some abbreviation just appear in the middle of the writing. For example R4 and R8 (I am assuming the numbers are referring to the number of sample angles to represent a 2d rotation group)\n  -  First line of Section 3. “Equivaraince refers to the property of a function to commute with the actions of any transformation group G acting …. ”. What the statement describes is covariance. To be an equivariant operator, f does not need to commute with a group action but be predictable. \n  - Figure-1 is not adequately described for the reader to interperate.  I would suggest to direct the users to compare the feature-map of the first row (which presumably is under identity transformation) with the subsequent rows. In such a case, equivaraince of each method can be judged and compared, at least qualitatively.   ",
            "summary_of_the_review": "The work is very interesting in what it tried to achieve and its goals. However, its claims are not adequately demonstrated neither empirically nor formally.  ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper describes a simple method to obtain CNNs that behave equivariant with respect to transformations from chosen groups.\nInstead of hard-wiring group equivariance, the approach presents a regularization strategy that encourages equivariant features in a subset of hidden layers, gaining parameter efficiency and more expressive filters in comparison to previous provably equivariant methods.\nThe experiments support the claims and show (small) gains in tasks of rotated/reflected/scaled image classification and object tracking in comparison to several baselines.",
            "main_review": "The paper is very well written and well motivated. On a high abstraction level, the approach makes perfect sense to the reader and seems to be a simple and efficient alternative to group equivariant networks / Steerable CNNs. \nIt seems that true \"steerability\" is not achieved though, as the method only enourages that max-pooled fibres are invariant to local receptive field transformations.\n\n\n\nWhen diving deeper, the following technical details are left unclear to me. I would appreciate if the authors could answer the following questions:\n\n- What is the definition of the group action on feature maps $h$? In the following, I assume the group action of a group element $g$ on $h: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^d$ ($d$ feature maps) is defined as $(\\phi_g h)(x) = h(\\psi_g^{-1} x)$ (using appropriate representation $\\psi$, such as rotation matrices for SO(2)).\nThis would consider the induced representation of e.g. SO(2) on $\\mathbb{R}^2$. If g only acts on individual pixel fibres, the comparison of two fibres in Equation 5/8 would be wrong I think.\n- How is $S$ (Equation 6) defined for each experiment?\n- For providing data to $L_G$, are the training examples only rotated by steps of 90°? \n- If yes, why are there variants of the proposed architecture, where the feature group size is 8? You would only need 4 in this case to cover all rotations. \n- If no, one feature map needs to be re-sampled when comparing two pixel fibres in $L_G$. How is that done and does it lead to issues?\n- The same question applies to the scale equivariance experiments. Here, I assume, a re-sampling of feature maps would be needed.\n\nThe work avoids to model feature maps as vector fields or functions over $\\mathbb{R}^2$. I think this is okay to make it more readible, however, the questions above need to be answered in the text.\n\nFurther remarks/questions regarding experiments:\n- How well does the method generalize to unseen transformations (e.g. to random rotations when $L_G$ only considers 90° rotations)?\n- How does the parameter $\\beta$ influence the accuracy? I think a comparison between different configurations would improve the work.\n- The feature maps in Figure 6 do not look fully equivariant (e.g. in the third column, the wings produce different activations for different orientations). Can this be contributed to re-sampling?\n",
            "summary_of_the_review": "All in all, this paper describes a (presumably) simple method, which is able to outperform more sophisticated equivariant architectures. However, I think that too many details are left out in the paper, which are important for fully understanding the method. Depending on the author response, I will adjust my evaluation. For now, I consider it to be a borderline work and wait for clarifications.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Instead of hard-constraining the neural net to enforce Equivariance, the authors promote the desired Equivariance property by mainly adjusting the loss function.  ",
            "main_review": "The paper is well-written, easy to read and technically sound. \n\nHowever, I don't find novelty in the work: \n-Novelty: The idea of promoting the Equivariance by modifying the loss function is already explored in the literature.  In particular, the work [A] in IJCNN seems to explore already all the potential novel ideas of the paper. The authors should clarify the differences to this previous work in the literature.\n\n- The authors should also include in the experimental comparison the method from [A].\n\n-The adopted datasets/problems for the experimental also raise concerns. They kind of toy examples for todays standards, not showing th potential in any challenging / real application.\n\nReferences \n[A] Soft Rotation Equivariant Convolutional Neural Networks. E. Castro, J. C. Pereira, J. S. Cardoso, IJCNN 2020\n\n",
            "summary_of_the_review": "The lack of novelty and the incomplete discussion/knowledge of the state of the art method support the decision of recommending rejection.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors point out that designing steerable group convolutional neural networks (GCNNs) for each transformation can be difficult and/or sub-optimal for the task of interest. Instead, they propose adding loss terms to only encourage equivariance at different layers of the neural network in addition to minimizing the task-specific loss, rather than explicitly designing for exact equivariance with e.g. steerable filters. They perform experiments on multiple image recognition datasets as well as for object tracking and compare against both non-equivariant networks with data augmentation as well as exactly-equivariant G-CNNs.",
            "main_review": "Strengths:\n\n1. The idea of encouraging equivariant features is simple, intuitive, easy to implement and can be easily integrated into conventional neural networks.\n\n2. The paper is written and organized well, hence easy to follow overall. Figures and illustrations are well-made and useful.\n\n3. The experimental results are very supportive of implicit equivariance and also quite surprising. On Rot-TIM with both ResNet18 and VGG, the proposed IEN clearly outperforms E2CNN as well as CNN8-aug with R8 equivariance. \n\n\nQuestions and suggestions for improvement:\n\n1. The novelty in the method appears to be low. As the authors themselves point out, using an additional loss term to encourage equivariance is not entirely. However, the way in which it is used and the results are intriguing. \n\n2. The proposed idea loses the mathematical guarantees of equivariant networks to chosen input transformation. This seems to be a drawback to me, even though both the classification/tracking results as well as observed equivariance results are good.\n\n3. The motivation that the authors use that it is difficult to create steerable filters for other transformations is not fully demonstrated. For example, can the authors describe specific transformation groups where this would be true?\n\n4. The proposed method still needs transformed inputs for training. So, for more difficult transformations like illumination where it is not easy to build equivariance, the proposed method still does not present a clear advantage as it is not easy to obtain realistic transformations as inputs to promote implicit equivariance.\n\n5. I understand that the authors use equivariance loss only for transformations other than 2D translations, but do the ideas in the paper mean that we can also use the loss function to encourage equivariance to 2D translations instead of using 2D convolutions? What kind of transformations, do the authors believe, that the implicit equivariance should be used for?\n\n6. I have a few questions about the experimental details as some of the results are a little unexpected. The results in many cases seems to show that regular CNNs with augmentation are better than E2CNN. This seems to be different from the results that I have seen in the E2CNN paper as well as papers on equivariant networks in general. Is it because E2CNN (and IEN) in this paper do not use augmentations? Or could it be because the datasets and network architectures are different from the ones the authors of E2CNN use?\n\n7. Related to the above, why is E2CNN outperforming in the case of R2-TIM with VGG unlike the other combinations? What about VGG makes IEN less powerful?\n\n8. In the case of 4 or 8 rotations, are those fixed discrete rotations for which equivariance is achieved during training for E2CNN? If so, I wonder if that is why E2CNN is underperforming. There are new works which use Monte-Carlo approximations to get equivariance to the full continuous rotation group as in the paper by Benton et al. NeurIPS 2020 that the authors have cited. ",
            "summary_of_the_review": "Although the main algorithmic contribution in terms of a loss encouraging equivariance (rather than explicitly designing for equivariance) is not too novel and loses the mathematical guarantees of equivariant networks, the experimental results are very good and intriguing. I am on the fence, but inclining towards acceptance. Hope the authors can clarify some of the details and explain some of the unexpected results. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}