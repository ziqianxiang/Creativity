{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposed an one-shot gradient-free pruning method to prune randomly initialized neural networks. \nStarting from a theory on two-layer MLP, the method is derived and then extended to multi-layer MLP. \nThe authors evaluate their method and variants under different settings including `Pruning at initialization` and `Pruning after training`. ",
            "main_review": "* The authors claim that their method is designed to prune a randomly initialized neural network. In addition, **the ultimate goal** is to make sure that training the pruned neural network will eventually get a similar accuracy as training a dense one. However, during the author deriving their theory, their object function (equ.1) is **to minimize the cross-entropy loss after pruning at initialization**. I didn't follow why/how is equ.1 related to the **ultimate goal**. \n\n* `For deeper networks, we use a combination of OSSuM + Norm based pruning — the initial layers being pruned using norm of the neurons, followed by the use of OSSuM in the last layer.' I am not sure about what is the norm of neuron. Did the authors mean the norm of neuron's weights? If so, only the last layer is pruned with the proposed method. \n\n* All experiments are conducted on relatively simple architectures and small-scale datasets. Since the proposed method is a kind of greedy pruning method, I cannot expect how the proposed method perform on deeper convolution neural networks and larger datasets. \n\n* The comparison with APoZ [1] would be interesting. Both APoZ and OSSuM require a traversing of the training set and are gradient-free. \n\n[1] Hu, Hengyuan, et al. \"Network trimming: A data-driven neuron pruning approach towards efficient deep architectures.\" arXiv preprint arXiv:1607.03250 (2016).\n",
            "summary_of_the_review": "Pruning neural network at initialization is an important task for efficient training. However, the novelty, rationality, and effectiveness require more improvements. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a neuron pruning method called One-Shot Supermasking (OSSuM). It aims at introducing the first gradient-free supermask at initialization.  The proposed method is evaluated on MNIST and CIFAR-10 using a fully-connected network.",
            "main_review": "One of the main limitations of the proposed models lies in their evaluation. The paper could have been stronger if a better selection of benchmarking methods would have been used (e.g. Top KAST https://arxiv.org/abs/2106.03517), such that the overall results to be at least comparable with state-of-the-art methods (preferable also on larger datasets, such as ImageNet-2012) in order to fully support the claims.  Some more related works to one-shot pruning at initialization should be considered and used to refine the claims (e.g. https://arxiv.org/abs/2102.02887).\n\nAs for the model itself, I think that it lacks a significant novelty. In the end, it is not fully clear to me how the supermask is generated? To what extend is the proposed method different in comparison with other sparse initializations (for example, the coreset-based pruning). It is also not clear why and how the implementation code of the coreset-based pruning method was used (as stated in the appendix). ",
            "summary_of_the_review": "Overall I think that the paper needs improvements in order to support the claims.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors proposed a sparsification-at-initialization method that is gradient-free and structured at neuron level.  \n",
            "main_review": "The neuron scoring trick around a combinatorial optimization problem is clever.  However, I have the following\n\nMajor concerns:\n\n- The derivation is on classification objective.  Does this apply to regression?  \n- The networks and datasets/tasks demonstrated (MLP on MNIST and CIFAR-10) are not representative of recent SoTA results, thusly of limited practical value. \n- How does Ossum compare to gradient-based fine-grain sparsification-at-initialization methods such as GrASP (arXiv:2002.07376)?  \n\n",
            "summary_of_the_review": "The paper presented a clear idea that is of certain significance, but did not demonstrate it in a systematic and compelling way to show practical value.  \n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None.",
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper proposes a method to prune neurons of 2-layer multi-layer-perceptron for classification using a single pass over the training data.\nThe method scores each neuron of the single hidden layer according to a first-order approximation of the loss and removes the neurons with the lowest score.\n\nThe method is tested on MNIST and CIFAR-10 and compared to various baselines. An extension to deeper MLPs that involves combining the proposed method with existing baseline methods is briefly discussed.",
            "main_review": "The authors describe the method as gradient-free, although it uses a pass over the training set where updates a mask according to a first-order approximation of the loss, which is similar to computing a gradient. There is no discussion of the pros and cons of \"gradient-free\" vs gradient-based methods.\n\nAll experiments use very simple network architectures on only two old, small and easy datasets (MNIST and CIFAR-10), so it's not clear how they generalize to more realistic datasets and network architectures.\nThe experiments involving fine-tuning show no differences for a 2-layer MLP and slight improvements for deeper networks.\n\nOverall, I don't find the motivation compelling and the results convincing.\n",
            "summary_of_the_review": "Overall, I don't find the motivation compelling and the results convincing.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}