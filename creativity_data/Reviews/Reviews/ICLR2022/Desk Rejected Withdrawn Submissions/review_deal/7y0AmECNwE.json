{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "Authors proposed to transform the non-differentiable problem of finding optimal ΘSEIR to a differentiable one,\nwhere they first train a recurrent net to fit a small number of simulation data. Next, based on this recurrent net that is able to generalize SEIR simulations, they are able to transform the objective to a differentiable one with respect to ΘSEIR, and straightforwardly obtain its optimal value. The proposed strategy is both time efficient as it only relies on a small number of SEIR simulations, and accurate as\nthey are able to find the optimal ΘSEIR based on the differentiable objective. On two COVID-19 datasets, authors observe that the proposed strategy leads to significantly better parameter estimations with a smaller number of simulations.",
            "main_review": "Authors propose to transform the original non-differentiable simulation problem of SEIR parameter estimation into a differentiable one by leveraging neural recurrent nets. The recurrent net is first trained to fit a small number of simulation data, and then trained on the observation data to derive the optimal SEIR parameters. This strategy bypasses the needs of time-consuming simulations, and automatically induces the optimal parameters via gradient descent, leading to both accuracy and efficiency gains.",
            "summary_of_the_review": "Overall its a weak accept. I would like to see if it the proposed method works on a non-covid dataset.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This work proposed a new framework to estimate the disease parameters in the SEIR model. Specifically, a recurrent network was used to generate the SEIR simulations, then the disease parameters estimation problem in the SEIR model can be formulated as an optimization problem with the differentiable objective function. To show the effectiveness of the proposed model, some simulations based on the real COVID-19 dataset were implemented.",
            "main_review": "This work is well organized, the major idea is clear and valid, it is easy to follow even for readers who are not familiar with disease modeling. Besides, the proposed method is efficient and simulations are provided to prove the effectiveness.\n\nMy major concern is the novelty of this work. SEIR model is a classical epidemic model which has been proposed for a long time. Meanwhile, the LSTM is also a widely-used model. It seems like this work is just a combination of the two models and cannot provide much insight or benefit to machine learning or epidemic studies.\n\nBesides, the SEIR model is a simple epidemic model which can only provide limited information about the epidemics. On the other hand, there are a lot of more complicated epidemic models which can provide more information about COVID, and machine learning algorithms that can accurately estimate the infections have been developed. I wonder if the authors can extend the proposed method to other epidemic models like [1] and [2]?\n\n[1] https://www.nature.com/articles/s41591-020-0883-7\n[2] https://arxiv.org/pdf/2010.12923.pdf%7d%7barXiv:2010.12923.pdf\n\n Moreover, can you provide more simulations on some other datasets, and compare with other methods?\n",
            "summary_of_the_review": "I think the novelty of this work is limited, and it can also be further improved. Thus I vote for rejection.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes parameter estimation in the SEIR model using the recurrent net. The authors trained a recurrent net to fit the time-series data of SEIR based on simulations using different sets of parameters. The trained recurrent net can then be used to directly find the parameter set for SEIR. The simulation results show higher accuracy in predictions compared to other approaches such as Bayes opt, ABC-MCMC.",
            "main_review": "Strength:\n-The method to train the recurrent nets/ LSTMs is well explained. \n-They use a novel approach such as mapping to extract graph representation and fine-tuning of the transmission rate.\n-Extensive simulation results with performance comparisons are provided. \n  \nConcerns: \nEven though the proposed approach has several merits, the reviewer has the following concerns. \n1. The authors claim that the proposed solution transforms the non-differentiable problem into the differentiable one. The reason why the optimization problem with L2-norm is non-differential is the “discrete points”. But, if discreteness is the issue, many easier approaches such as approximation could be a cheaper solution than a neural network. \nIt seems like the authors highlight the point (i.e., transform non-differentiable one to differentiable one) as the most important contribution, more logical reasoning should be provided. \n2. The results show the prediction of the proposed model outperforms the others. However, the estimated SEIR parameters and corresponding interpretation are not provided even though those are the main goal of the paper. Specifically, it would be great to show the results of beta or beta_s, beta_a, beta_t, beta_c, respectively. \n3. In eq (9), the proposed solution uses “human prior knowledge”. What is it? Should the expert provide the Theta? If then, how do we get it, and why do we need this model instead of simply using the expert’s Theta?    \n4. Are the parameters time-varying or static? There is a sentence to use the same betta for 14 days, but more details should be provided. \n5. In eq(10), the paper assumes an addictive transmission rate, but there is no reason why additivity works. More discussion should be provided. \n6. The terminology is not consistent across the paper, so it is quite confusing. For example, transmission rate sometimes refers to the exposed rate. \n7. To the best of my knowledge reproducibility was not addressed.\n",
            "summary_of_the_review": "The provides a novel approach to predict SEIR model parameters, but there are several issues that need clarification. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper discusses how parameters of SEIR models could be estimated from empirical time series of infections using LSTMs. The idea is to first train LSTMs on many simulations from ‘microscopic’ (as opposed to mean-field) SEIR models, taking the known SEIR parameters of those simulations as additional inputs. In a second step, for estimation of the SEIR parameters from actual empirical observations, LSTM parameters are fixed and instead SEIR inputs to the LSTM are treated as trainable parameters. The approach is tested on two Covid19 data sets from China and the US for which in addition to number of infected subjects, location tracking, socioeconomic, and other information was present. It was compared to brute-force parameter search and Bayesian inference approaches.",
            "main_review": "I believe there are some valuable and interesting ideas in this paper that I liked. First, instead of just using population-averaged information, the approach models probabilistic behavior of single subjects (in my understanding) taking spatial (location) information and other factors (age, gender, …) into account in a graph-based approach using GNNs. Second, I like the two-stage procedure of first providing the LSTM with a lot of simulation data under many different conditions, and the in this case known epidemiological parameters, and then re-training only the SEIR parameters on the actual observations. Third, it seems to me that relevant benchmarks were included in the comparisons.\n\nHowever, a couple of issues prevented me from making a more positive evaluation (some of them may just need clarification from the authors):\n\n1) It remained in fact unclear to me how much in this paper is novel. It appears both the subject-level and graph-based methods, as well as using RNNs to make predictions on the observed data, have been introduced before, also on the same data sets. The authors should make much clearer what specifically differentiates their work from previous one.\n\n2) No error bars are reported for any of the results in the tables, making it difficult to judge their statistical significance. Moreover, my understanding is that the main objective was to infer epidemiological (SEIR) model parameters from real data, but – as far as I understood – only MSE statistics on the time series of infected individuals are reported. So I missed a validation (and graphical representation) of actual model parameter distributions, i.e. how close are estimated and true parameters for novel situations that haven’t been used in the training (and may be out-of-distribution even), compared for the different methods.\n\n3) In general I had difficulties understanding many of the details. While some parts in sect. 2 & 3 I found quite redundant (since they were already spelled out in the Intro for instance, or repeating eq. 2), other crucial bits of information were missing. I would like to get more information (perhaps with illustrations) of the mobility network and how specifically it was processed by the GNNs (their role was not even clear to me, as I thought the assignments of nodes is known at each time step). Likewise, since I thought all LSTM parameters are fixed and only the SEIR parameters are inferred during actual data applications, I wasn’t quite about how the time series predictions (as shown in Fig. 2 and quantified in the tables) were actually produced. Are these only 1-step-ahead predictions (which seems like a modest goal)? Many of the details, also on the competing models, were just not clear to me. No appendix was provided, so there would have been a lot of space to provide this info and potentially more results.\n\n4) I would think that this study clearly touches on ethical issues for several reasons. Most importantly, perhaps, detailed subject-level data (income, race, movement …) is included in the processed data sets and related to a health issue, clearly raising points of potential misuse and how anonymity of subjects is ensured. I’m aware these data sets were not collected by the authors themselves but just used here for model validation. Yet I felt some discussion on ethical aspects would have been in order here. Likewise, clearly with the information provided in the paper as is, hardly anyone would be able to reproduce the results. Nothing about availability of code is mentioned (nor was it provided), not sufficient details on procedures were provided (see above), nor was it clear to me whether and how at least the first of the two data sets is available. So I missed as well a discussion on reproducibility.\n\n5) Since also mean-field models (ODE systems) of disease dynamics have been applied with quite some success (e.g. Dehning et al. 2020, Science), I think this would be another crucial benchmark. In principle, one may ask why one can’t just infer a SEIR mean-field ODE-based model directly from observed data, as this is cheap and quick. This would directly yield model parameters, and with that ahead predictions of time series. Only mean field quantities (total numbers) were considered in the predictions (eq. 7,8) anyway, so that this would seem like a viable and quick alternative approach.\n\n6) Obviously one would expect significant improvement of the ‘vanilla’ grid search based methods as step size is decreased. Not sure whether some of the Bayesian approaches use grid search as well (as they were not described in sufficient detail). Therefore it seems the grid size would be an important hyper-parameter to mention. Also, although it is intuitive that such methods come with high computational costs, as this is an important line of argument for the authors, one wonders how the methods actually *do* compare in terms of run time for a given target precision?\n\nMinor points:\n- The SEIR model simulations should be described in more formal detail. In eq. 1, rates are interpreted as probabilities, but are they? They come in units of inverse time, don’t they?\n- Didn’t quite get the role of the GNNs (eq. 3) since assignments are given (I thought) by simulation and do not need to be inferred?\n- In eq. 8, these are all scalar quantities, right?\n- In eq. 10, the rate is given as a *sum* of rates resulting from different properties. Is this a proper model? Shouldn’t it be at best an average, or more properly some interaction of feature-specific transmission rates? Is there a reference for this? Why do $\\gamma$ and $\\kappa$ not depend on subject-specific properties?\n- Not sure how exactly Fig. 2 was produced (see above).\n- How do different methods compare in terms of free parameters? Was a hyper-parameter search just performed for the authors’ model, or also for the other algorithms? Does the ability of the authors’ model to take prior information on board bias results toward their own approach?\n",
            "summary_of_the_review": "Potentially good and important idea, but not enough info provided on 1) novelty, 2) detailed models and procedures, and not clear why mean-field SEIR model couldn't be used instead.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}