{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Spotlight)",
        "comment": "This paper proposes a tree-based method for interpretable policy learning, for fully-offline and partially-observable clinical decision environments. The models are trained incrementally, as patient information becomes available. \n\nThe method was overall deemed novel by the reviewers, and the interpretability of the model well validated by clinicians.\n\nNumerous points of clarification were brought up by reviewers, related to the notation, learning process and result reporting. All of the concerns were responded to by the authors in great detail and the manuscript was appropriately revised. All the reviewers have raised their scores as a result of the updates.\n\nThus, the paper is ready for acceptance."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a new method to learn (stationary) interpretable policies using soft decision trees in partially observed settings. The soft decision tree structure is extended to allow for recursion over time, and account for policy decisions based on history of collected data. An algorithm is presented to optimize the parameters of the soft decision tree as well as the structure/topology of the tree. The algorithm mainly proceeds by splitting nodes and locally optimizing the parameters of the the associated probability representation of the soft node, and recursively split (if local optimization does not improve validation performance) and fixed as leaf otherwise. A global update step is then used after topology is fixed followed by pruning low probability paths in the trees. Experimental validation on surveys with clinicians demonstrate reasonable interpretability and improved prediction performance on imitating clinician policy. ",
            "main_review": "The paper is well written and the problem well motivated. The key contribution seems to be extension of soft decision trees to the recurrent setting which is a nice and clinically useful contribution. The algorithm used to train is certainly a heuristic but seems reasonable. Empirical results are comparable although the algorithm does not seem to improve over state of the art in terms of interpretability always. \n\n\nWeaknesses:\n1. I am not sure how partial observability plays a role and the contributions from the partial observability perspective are unclear. Is the claim that the representations learned due to the recurrent setup is better for overcoming challenges of partial observability? If so I believe an additional evaluation is warranted for comparison. If not then I might have misunderstood and I believe for completeness authors should comment on partial observability. \n\n2. No additional discussion regarding the algorithm and its behavior is provided. I believe a discussion on potential failure cases and also choice of hyperparameters of the cost function will be helpful especially for experiments. \n\n3. I might have missed this but what exactly is the source of partial observability in all the empirical evaluation in the paper? Please add comments regarding the source and how the proposed method addresses it.",
            "summary_of_the_review": "Overall I believe this paper provides an interesting contribution for interpretable policy learning particularly for clinical decision-making. I do have a few followup questions that will make the contribution regarding some aspects clear. ",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Thank you to the authors for their discussion. I have increased the score to 8 but I do believe the partial observability claim is a bit overstated. Partial observability can be quite egregious and no amount of data can help in the worst case. To rely on predictive performance to make claims about partial observability is overstating it in my opinion. In any case, the ablation study makes sense, and I think modulo the PO claim, I am convinced about the utility of the paper. I would in fact suggest not highlight partial observability as being addressed unless you can claim to do so either theoretically or without relying on performance.",
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a novel approach for learning and representing human decision-making policies from observed behavioral data. The proposed approach emphasizes interpretability as a primary aim, while nevertheless seeking to maintain reasonable modeling accuracy. The decision tree model proposed extends canonical decision tree approaches to the probabilistic setting, allow for optimization of leaf-specific parameters via stochastic gradient descent. The proposed approach is evaluated both in terms of its interpretability (subjective measurements from a panel of licensed physicians) as well as its accuracy in recapitulating actions conditioned patient observations. The utility of the approach is demonstrated on both synthetic and real-world datasets.",
            "main_review": "I am admittedly not an expert in imitation learning/behavioral cloning, policy learning, or soft/probabilistic decision tree models. Nevertheless, having more familiarity with offline reinforcement learning and healthcare broadly, I was excited to read this paper. \n\nThe central premise of the paper - distilling inherent clinician policies down to an easily interpretable (and easily followable) decision tree model - seems like a compelling and important task, and the authors motivate this well in their introduction, highlighting the unnecessary costs of medical practice variability.\n\nThe algorithm is explained reasonably well in Section 2 (\"Problem Formalism\") and Section 3 (\"Interpretable Policy Learning with Decision Trees\"). \n\nSome of the notation was a bit confusing, but this is more of a minor point. For example, $a_t$ is a one-hot encoded target (top of page 4), but then $a_{t, k}^l$ is also the output probability for action class $k$ in leaf $l$ - why not denote the predictions using $\\hat{a}_{t, k}^l$? \n\nThere were also a few confusing sentences. Consider this on in the first paragraph of Section 3.2: \"Finally, as third leaf output with parameters $\\theta_z^l \\in \\mathbb{R}^D$, our model also predicts \\emph{patient evolution}, or observations at the next timestep $\\tilde{z}_{t + 1}$; to formalise a consideration of expected treatment effects (Yau et al, 2020).\" Not only is the line after the semicolon not an independent clause (making the use of the semicolon incorrect), it's also unclear to me where this line about expected treatment effects came from. What does patient evolution have to do with expected treatment effects? There's another related line in the \"Action value quantification through counterfactual evolution\" section that reads, \"Overall, thanks to its integral part of model design, assessment of counterfactual evolution becomes intuitive\". I was very confused by this line. What is the counterfactual here? And what does this have to do with the \"integral part of model design\"?\n\nOn that note, it was unclear to me why a hyperbolic tangent function is used to estimate $\\tilde{z}_{t + 1}^{l_0}$. \n\nI understand the value of introducing differentiable nonlinearities for the goal of flexible function approximation, but I thought that $z_t$ was supposed to be in the original output space? Is $\\tilde{z}_{t + 1}^{l_0}$ not also supposed to be in that same space? But using the hyperbolic tangent would map everything to $[-1, 1]$. Some clarity here would be helpful.\n\nI thought the comparison to related work was done well, and despite not being intimately familiar with the field I was able to appreciate both the existing challenges and opportunities present at the time the work was carried out. Table 2 was especially helpful for contextualizing the paper's contributions. Admittedly, it does seem that this paper is more of a convex combination of a few different ideas (soft/probabilistic decision trees from Frosst & Hinton [2017], cascaded trees from Ding et al [2021] for recurrence) rather than a seminal and novel work in its own right. The authors highlight differences between their approach and vanilla CARTs/Stochastic Decision Trees (SDTs) in Appendix B.2, but I didn't see a comparable exposition of differences and explanation of novelty/contribution relative to Ding et al (2021). That being said, if you believe (as I do) that creativity is just synthesizing existing ideas in novel ways, then I suppose you could call this paper creative. The question, then, is how much more useful the proposed amalgamation of ideas is over each idea in isolation?\n\nI was impressed by the experimental results. It does seem that there's a tradeoff between interpretability and performance (e.g., AUROC), but this particular approach at least seems to be on the current pareto frontier of this tradeoff and provides a useful approach for practitioners.\n\nI thought ADNI dataset application was a compelling one, and the problem itself was explained adequately; however, I really had to sit and scratch my head to work through Figure 3. For a paper nominally dedicated to producing interpretable decision policies, I had a hard time interpreting the policy represented in Figure 3(a). I think the vignettes of Patient A/B/C is insightful, but would need some additional guideposts to add to the paper rather than detract from it. What if, for example, you were able to color and label each of the tree branches with a different color for patient A, B, and C? (Or at very least indicate the path through the tree for each patient separately in the appendix). Also, it was unclear to me whether CDR-SB was being treated as a categorical or an ordinal random variable. For example, in the \"MCI\" sub-tree there is a leaf for \"CDR-SB questionable\". If the answer to this is \"No\", then does that imply that the value could be either \"CDR-SB severe\" or \"CDR-SB normal\"? Is an MRI really warranted in either case?\n\nI was also a bit lost with regards to the \"Decision-making uncertainty\" and \"Anomalous behavior detection\" sections. I think most practitioners would interpret the extracted policy as a deterministic one (not a probabilistic one), yet the underlying construction of the tree is inherently probabilistic. How are we to reconcile those two in terms of interpretation? As a concrete example, the statement is made, \"Visits where an MRI is predicted with 90% certainty make up 8.4% of ADNI\". But this certainty is a reflection of both the entropy in the path to the leaf in the decision tree as well as \"uncertainty\" in the action conditioned on the leaf itself. Disambiguating the two seems important for being able to decide whether an action is truly \"anomalous\" (because taking action 1 in leaf L is inappropriate) or just unlikely because there are very few patients that are represented by a particular leaf node. Maybe I'm misunderstanding something more fundamental here, but I'd welcome any additional clarity here.\n\nOne other note: the authors state, \"We must highlight the similarity between our decision tree policy and published guidelines for Alzheimer's diagnosis, reproduced in Appendix F\". These two policies were not at all similar, in my reading. Figure 10 makes no explicit mention of MRI, hippocampal volume, or the CDR-SB, nor is it recurrent. Figure 11 exhibits all of the above.\n\n=====POST-REBUTTAL COMMENTS========\nThe authors have thoughtfully addressed most of my concerns. I particularly appreciate the update to Figure 3(a) and I think it makes the figure much easier to parse. With the revisions, I'm happy to increase my score. I'll note, though, that I believe a typo was introduced in Equation (2). Check the parentheses in the far right $D_{KL}$ term of the equation. Also, the term to the left of equality should take $h_{t+1}$ rather than $h_t$ as an argument, I believe. \n\nI've had a chance to read through the other reviewers' comments and the authors' responses to said comments. I agree with reviewer Kc79's original concerns and feel that those have been adequately addressed. The same with reviewer FrRV. Honestly (and this is more for the meta-reviewer) I was left scratching my head at the comments made by reviewer wNRz. The request to compare the proposed approach to SVMs and GBMs doesn't make any sense to me - SVMs and GBMs are inherently not as interpretable as decision trees, in my opinion, and the whole point of the paper was to learn a policy representation in decision tree form that closely matched clinician behavior. This is, contrary to wNRz's concerns, very well suited to tools from behavioral cloning and imitation learning. No reward is needed because the authors aren't taking an inverse reinforcement learning. This is all fine, reviewers can have disagreements. What was most concerning to me, though, was the combination of a very low score by the reviewer and a high confidence rating. The reviewer's comments reflected neither the depth nor understanding that I would expect from such a high confidence rating.",
            "summary_of_the_review": "Overall, this is an interesting paper. The novelty and significance are positive, if not overwhelming. The utility for practitioners and potential impact in areas outside of machine learning, however, is nontrivial. The exposition of the method and its interpretation would benefit from additional refinement. Nevertheless, in its current state, I can recommend a marginal accept.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "  The authors argued that many methods failed the merits of interpretability in some important areas, e.g. clinical decision-making. Thus, this paper proposed a (soft) tree-based method for synthetic clinical datasets in the matter of interpretability. The authors model the clinical decision process as a partially observable Markov Decision Process (POMDP), which naturally fits the assumption of medical diagnosis.",
            "main_review": "Overall, I don't think the paper meets the requirement of ICLR in a few aspects:\nStrengths:\n- The motivation is strong, especially for clinicians\n- The paper is well written and easy to understand.\n- The experiments are completed and detailed , and  the results seem strong to me ( noted that I'm not a expert in clinical datasets)\n\nWeakness:\n- Some important classical machine learning methods are missing(e.g SVM, GBMs), which meet the needs of interpretability rather than deep learning methods. The policy learning methods(IL, AL, IRL) are not related to me as the reward function is not important in clinical settings. Some important works ([1][2]) for time-series data were also missed for discussion.\n\n1) Ke G, Meng Q, Finley T, et al. Lightgbm: A highly efficient gradient boosting decision tree[J]. Advances in neural information processing systems, 2017, 30: 3146-3154.\n2) Chen T, Guestrin C. Xgboost: A scalable tree boosting system[C]//Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. 2016: 785-794.\n\n- Novelty: the technical contributions are marginal to me as the main aspects of the proposed method are the combination of RNN and Soft Decision Trees.\n\n",
            "summary_of_the_review": "I'd give a rejection based on the comments above. And I would like to suggest the authors revise the paper for re-submission to another conference.\n\n----Post Rebuttal---\nTo Reviewer kv5i. To be honest, I'm still not convinced that the issues raised in this paper are more artificially fabricated than they are actually present. Clearly, if the goal of this paper is to discover machine learning models that can be used to explain, then decision tree models and support vector machine models are superior choices when compared to other benchmark models, and in fact, the interpretability of decision tree models would not lag behind the methods posed by the article. It is possible, however, that the assumption made about the problem encountered in the clinical data (a Markov process with partial observability) is ill-posed, i.e., that the requirement to take into account the impact brought by the medical regimen is incorrect.\n\n---- Post Post-Rebuttal ---\nI appreciate the author's thorough and precise arguments. After several days of consideration, I reviewed the entire paper and decided to increase my score. Thanks for your effort.",
            "correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "POETREE aims to construct an interpretable model for a policy over a time series using decision trees. The healthcare domain is particularly targeted. As opposed to other works, the model directly maps observations of a POMDP to actions. POETREE creates a decision tree from time series data. The decision tree can be conditioned on the history, allowing the tree to be different at different time steps, allowing for example the tree to model that an exam done previously that is no longer informative is no longer likely. Each tree is a soft-probabilistic model first grown incrementally by developing, optimized globally (as it is differentiable), then pruned. Finally, the tree is simplified for interpretability by limiting each condition to a single variable. POETREE is then empirically evaluated and compared to baselines in terms of distribution modeling, interpretability and policy learning.",
            "main_review": "**Strong points:**\n- Rather well written and clear paper.\n- The interpretability of the proposed approached is quantified by clinicians.\n- Interpretability of models is important, especially in healthcare.\n- Experiments on synthetic data and two real data sets.\n- Experiments include a comparison to what seems to be the most relevant existing method, Interpretable BC-IL (Huyuk et al., 2021). I like that at least one example clearly shows a situation where the proposed method is more interpretable than Interpretable BC-IL.\n- I liked the illustration of the model based on real data/examples. This is really nice.\n- Good job balancing the content between the main paper and the appendices. \n\n**Weak points:**\n- I did not understand the first term ($||z_t - \\tilde{z}_t||$) of equation 2. The input of the tree is $z_t$ and $h_t$, the observation at the current time step and history. Why is there a loss over these terms? What is $\\tilde{z}_t$ ? The observation at the next time step is defined as $\\tilde{z}_t+1$ so isn't that first term always 0?\n- The tree is first learned by considering all variables in a node and then simplified by only using one variable in a node. Even though a L1 regularization is used when learning each node, I am concerned about the impact this has and do not understand why a more direct approach such as learning a node directly with a single variable is not considered. See questions below.\n- I might be mistaken, but I think the impact of the different losses is not evaluated in the experiments.\n\n\n**Questions:**\n- Unless I am mistaken, the decision tree is modified after learning to make it interpretable by leaving only the variable with the highest weight in each node. I read appendix C and saw the reported loss of accuracy to be only 2%. Yet as I understand it this is a single empirical experiment. I am a bit uncomfortable, as I wonder whether this could lead to large changes in a policy when many variable have similar weights. I am concerned both with skewing the interpretation of the policy and with accumulations of errors within child branches. Could you please comment on that?\n- On a related note, is there any particular reason not to learn the tree by using directly a single variable in every node? This would guarantee that child branches are directly learned on the partition of the data that correspond to the inference setting.\n- Likewise, is there any reason to not use regular decision trees rather than probabilistic ones? Recurrent decisions trees could be used.\n\n**Details:**\n- I do not understand the purpose of the comparison to RNN in section 3.2.\n\n**Post-Rebuttal:**\nThank you for the detailed answers to my questions. This is an impressive amount of extra experiments. I found the answers very detailed and insightful. Most of my comments have been addressed beyond my expectation. I think the paper is well worth publishing at ICLR in its current state and have updated my score accordingly.\n\nOn the topic of learning an axis-aligned tree:\n- I think the novel approach mentioned in the rebuttal and learning multiple axis aligned threshold at every node is very interesting, but might be more difficult to interpret as many variables will be considered in each node. Nevertheless, it is impressive you could learn such a tree.\n- I now understand that this paper follows previous approaches to align the decision boundaries. I might well have missed it, but reading the paper initially, I thought that trees are not retrained after being axis aligned, which still seems strange to me. I could not see it said explicitly so perhaps I am wrong. Maybe this could be clarified.\n\nOn a final note, I share the sentiment of reviewer kv5i about other reviewers' comments. He said it better than I could.",
            "summary_of_the_review": "*Initial summary*: I think this is a very interesting research on an important topic. Experiments are well done. My main concern is that the simplification of the model might have some bad impact. \n\n*After discussion*: Concerns have been mostly addressed. I think the paper is worth publishing.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Responsible research practice (e.g., human subjects, data release)"
            ],
            "details_of_ethics_concerns": "The paper reports an evaluation of the models by human subjects (Appendix G p24), which seems similar to annotators to me. This section contains a short description of the  procedure followed to collect that data. While everything seems alright and well done to me, it does involve human subjects. I think it does not contain an assessment and/or report of \"ethical approvals from an appropriate ethical review board\", which is mentioned in the ICLR Code of Ethics. \n\nTo be clear, I do not think there is an ethical problem with the research done in the paper, rather with the approval and/or mentioning it in the paper. But unsure where the bar is, I decided to flag it.",
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}