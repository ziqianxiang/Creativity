{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Spotlight)",
        "comment": "The paper proposes to extend mirror descent to sampling with stein operator when the density is defined on a constrained domain and non euclidean geometry. All reviewers agreed on the novelty and the merits of the paper. Accept"
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper introduces algorithms for sampling constrained distributions. Assuming the existence of a mirror map that maps from the primal space to the dual space, the authors introduce an algorithm MSVGD that can perform gradient descent in the dual space, and map back to the primal space. They also propose SVMD, which uses a different algorithm to perform gradient descent in the primal space itself. The authors experimentally validate their algorithms on simulated data and one non-simulated dataset (Fig 4b).\n\n",
            "main_review": "Strengths:\n1. The premise of the paper is clear and interesting : in traditional optimization, mirror descent allows you to optimize over constrained feasible sets, and this paper attempts a similar approach to sampling.\n\n1. In order to achieve the sampling analogue of mirror descent, the authors define an infinitesimal generator for a Markov process that has an equilibrium density $ p $. Since $ p $ has constraints (for example, it should be a sparse Dirichlet distribution), the authors construct the generators via the mirror maps associated with the constraints. I think the ideas used to construct these generators are quite non-trivial.\n\n1. The authors show that their algorithm mixes quicker in simulated experiments.\n\nWeaknesses:\n1. The writing can be improved. The authors try to give a lot of information about gradient flows that are often repetitive and not particularly friendly to readers. For example, the paragraph between Eqn (4) and (5) will not help an unfamiliar reader. Additionally, I did not understand the details of the experiments in section 5.2 \n\n1. Some of the notation is quite confusing -- the authors use $ \\theta $ and $\\theta_t$ interchangeably at times. This is not a problem in some cases, like Eqn (10), but Eqn (11) is very confusing to me. In theorem 4, $ \\eta $ is a function of $ \\theta$, and $ \\theta$ is a random variable distributed according to $ p $. But then $ q_{t, H} (\\eta ) $ is a density of $ \\eta_t$, and then Eqn (11) contains an average over $ \\eta_t$, and no term except $ k_\\psi$ has a $ \\eta$ term. I'm still not sure I understand Eqn 11 completely. This issue gets even worse in Eqns (12) and (13), where a lot of terms are functions of $ t $ although the variables do not include $ t $.\n\n1. The limitations of this work should be addressed a little bit -- from what I understand, you need to be able to compute kernel functions quickly, and require closed form solutions for $ \\nabla \\psi $ and $ \\nabla \\psi^* $. \n\nMinor comments:\n1. Above eqn (2), the equality should be $ \\theta_{d+1} = \\sum_{i=1}^d \\theta_i$.\n\n1. The authors keep saying they want to generalize to non-Euclidean geometries. If SVGD considers the geometry induced by the KL-divergence, then isn't this already non-Euclidean?",
            "summary_of_the_review": "I think the result is intuitive and requires advanced techniques to construct the infinitesimal generator used for constrained sampling.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The aim of this work is to extend the existing particle evolution method Stein variational gradient descent or SVGD to constrained domains and non-Euclidean geometry. Three algorithms are proposed for this purpose based on mirrored Stein operators. The first is Stein variational mirror descent that runs SVGD in dual space s.t. the updated particles stay in constrained domains. The second one is Stein variational mirror descent defined with some adaptive kernels and it is also applicable to constrained domain problems. The third one is Stein variational natural gradient which is intended for unconstrained problems with informative metric tensors. Empirical and convergence analyses are further provided for all three proposed algorithms.",
            "main_review": "[Strengths]\nThe paper is overall well-written and makes reasonable attempts to provide sufficient background to understand the proposed algorithms. The literature review is thorough.\n\n[Weakness]\n- In the discussion in this work, constrained domains seem to be restricted to simplex. I wonder if MSVGD and SVMD are applicable to constrained domains in general, for example, a conjunction of non-overlapping simplexes and whether the convergence analysis still holds in this case.\n\n- At the end of Section 4.2, I find the statement that MSVGD does not necessarily match the modes of the target density lacks theoretical or empirical evidence. In the multimodal sparse Dirichlet experiments, MSVGD and SVMD have pretty similar performances. Since this statement is the motivation for SVMD, it would be more convincing to show why or when SVMD is able to capture the modes while MSVGD is not either theoretically or empirically. Also, a more detailed comparison of these two algorithms would be appreciated.\n\n\n[Minor Comments]\n- Some references are not properly presented. There are some cases where \\citep should have been used but \\citet is used; the opposite cases also happen. A careful pass on citations might be beneficial.\n- In Figure 2, the curves for MSVGD and SVMD are partially invisible when they are close to 0.0.",
            "summary_of_the_review": "The theoretical contribution of this work is solid. Still, quality and clarity need to be improved in several points as mentioned in main review.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper introduces new methods to run SVGD in constrained domains and non-euclidean geometries.\nThe authors develop the theory to combine mirror descent dynamics with the Stein's method via what they call mirrored Stein operators.\nThey also show experimental results on two concrete problems and prove convergence guarantees.",
            "main_review": "The paper tackles the important problem of non-Euclidean or constrained space with particle methods. Its significance is therefore very high.\nThe paper is very complete and introduces all the different notions needed to understand the theory of the proposed methods.\nThe only comment I would have is that with the appendix being itself ~14 pages, this submission would better fit as a journal paper as it is.\n\nQuestions/Comments:\n- How does the algorithm compare with vanilla SVGD combined with a bijection to solve the constraint problem (for example x->exp(x) for positive real values)?\n- Could you explain why \"the modes of the mirrored density $p_H(η)$ need not match those of the target density $p(θ)$\"? \n- Could you comment on the cost of computing eigenfunctions and eigenvalues for SVMD?",
            "summary_of_the_review": "This paper addresses an interesting problem and its development looks very exciting.\nThe work is very complete and addresses both theoretical and experimental aspects of the proposed methods.\nThe theory proposed looks sound with a strong background and the experiments look very convincing.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "10: strong accept, should be highlighted at the conference",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "the paper introduces a new family of deterministic particle samplers which apply mirror transformations to the Stein's variational gradient descent method. This approach can be used to generalize SVGD to both constrained and non-euclidean settings. The authors introduce two algorithms of this type that differ by the choice of the kernel function. One of these, SVMD is shown to reduce to regular mirror descent when a single particle is used. ",
            "main_review": "Strengths:\n- The paper is dense and offers a large number of both algorithmic and theoretical contributions. The use of mirror transformations to build specialized Stein's operators show a remarkable technical mastery.\n- The addressed problems are relevant. While several prior works have already addressed the Riemannian case, the convergence properties of this method seems to be superior. The application to constrained problems is novel and in my opinion particularly useful.\n- The writing is clear. Both prior work and contributions are clearly explained. \n- Good balance between theoretical and algorithmic contributions.\n\nWeaknesses: \n- The abundance of content makes the overall narrative difficult to follow. the paper introduces several related methods in order to solve several loosely related problems. I would have appreciated a more focused presentation.\n- The experiments are unfocused, with too little space devoted to each application. I would have preferred to see less experiments with more detailed discussion and analysis. ",
            "summary_of_the_review": "The contribution is novel and solid with a wide range of potential applications. The paper is slightly too dense and somewhat unfocused. However, the main contributions are presented in a clear and understandable way. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}