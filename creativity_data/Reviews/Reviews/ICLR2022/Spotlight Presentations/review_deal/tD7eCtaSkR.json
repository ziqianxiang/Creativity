{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Spotlight)",
        "comment": "The paper provides a procedure for certifying L2 robustness in image classification. The paper shows that the technique indeed works in practice by demonstrating it's accuracy on CIFAR-10 and CIFAR-100 datasets. \n\nThe reviewers are positive about the paper. Please do incorporate feedback, especially around experimental setup to ensure that the work compares various methods fairly and provides a clear picture to the reader."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors propose three methods to improve deterministic l2 robustness certificates of 1-Lipschitz convolutional neural networks. \n\n1. Last Layer Normalization (LLN): \n    (1) Relax the orthogonalization of the last weight layer of the network W. \n    (2) The direction of the rows in W can change freely; do not need to update other rows in W and forgot the learned information.\n    (3) Efficient than original robustness certificate when the number of classes K is large. \n2. Certificate Regularizer (CR): \n    (1) Enable the gradients to continue increasing the margin M_f(x) while entropy loss becomes small by adding the regularization term. \n    (2) The relu function in the maximization term ensures that the optimization tries to increase the certificates only for the correctly classified inputs.\n3. Householder Activation Functions (HH): \n    (1) Introduce a general linear GNP activation function named HH for the special case MaxMin used in Anil et al., 2018. and other works. \n    (2) Prove this HH transformation is necessary for any GNP piecewise linear function to be continuous. \n   \nTheir experimental results demonstrate the effectiveness of these proposed methods compared to the baseline method SOC. ",
            "main_review": "Pros: \n1. The authors find several limitations of existing works and propose three novel methods to address them. Both methods are very novel and have their advantages to address the problems. \n2. The authors present their findings and current problems and introduce the proposed methods very clear from a high level to a very detailed level. The notations, equations, and proofs are easy to follow. \n3. The figures and tables are clearly designed. Figure 1 illustrates the HH activation very clear and makes it easier to be understood. We can clearly see the improvements achieved by each method from Table1. \n4. This paper contributes a lot to the research area of 1-Lipschitz CNNs, especially the class of piecewise linear GNP activation functions HH. \n\nCons: \n1. A minor issue is the structure of this paper. In the Introduction, the authors present the three methods in the order: HH, LLN, CR. However, the order in the method sections is LLN, CR, HH. The logic is a little bit messed up. \n2. It is not clearly explained why the original robustness certificate (Eq 4.) has a problem when the number of class k is large. And why LLB can not achieve significant gains on CIFAR10, just because of the small number of classes? \n\nQuestion: \n1. From Table 1, why the performance of LipConvnet-40 (45.84) is even worse than LipConvnet-5 (46.36) and other shallow networks? ",
            "summary_of_the_review": "The paper proposed three novel methods to address some limitations of existing works. It appears to be technically sound, but I have not carefully checked every detail. The experimental evaluations convincingly support the main claims. This paper contributes some new ideas in this specific research area. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work is following the line of (Anil et al 2018), its goal is to propose criteria that allows to train models wirth orthogonal weights and to certify they are. The authors generalize (Anil et al 2018) by considering a more expressive non-linearity which leads to unitary jacobians, with a softer criterium during supervision which allows to obtain better accuracies. Overall, I feel the paper is well motivated, and the results are convincing.",
            "main_review": "Pros:\n- Excellent numerical improvements\n- The paper is clearly written\n- The contributions are mainly from the engineering point of view and this paper demonstrates the method works well, with coherent explanations.\n\nCons:\n- I have a minor concern w.r.t. the structure of the paper, I think some of the “Theorem” could be simply called “Proposition”: please don’t get me wrong, I simply think it’s good to distinguish crucial mathematical results from trivial properties (here continuous functions).\nTheorem 1, I think, should be phrased differently: it requires to introduce formally the robustness certificate first. Then, one find a property of this certificate which can be stated as a proposition. Again, I feel Theorem 2 is a too strong statement for this. It’s also strange to see that the Theorem 1 uses phrasing from the Definition 1 but is still above this latter.\n- I think the choice of the parameter $\\gamma$ should be fully detailed. In other words, that it has been cross-validated on a subset of the training set. Otherwise, a suspicious reader could believe the accuracy has been optimized on the test set.",
            "summary_of_the_review": "The scientific contribution of this paper is solid in my opinion: a problem is introduced, solved with a generalization of a previous framework. The explanations of the improvements are clear, and because the contribution is fully technical and the results are good, I think, except if I missed an element (such as a working with a similar result) that this paper would be a nice contribution to ICLR.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper addresses the problem of provable L2 robustness in image classification.\nThree techniques are proposed as additions on top of the SOC work (Singla & Feizi, 2021):\n1) let the last linear layer be non-orthogonal and adjust provable L2 robustness calculation accordingly;\n2) add a loss term that encourages larger margins in logits;\n3) a new nonlinearity.\n\nComparisons against the original SOC work are reported on CIFAR-10 and CIFAR-100.",
            "main_review": "The main issue of this paper is evaluation. And the SOC work (Singla & Feizi, 2021) has the same issue.\nThe Lipschitz constant of an SOC layer is not strictly bounded by 1 and is only approximately 1.\nLet X be the product of the Lipschitz constants of all layers in a network.\nWith many layers and multiplications, X could deviate sizably above 1.\nThis effect can get exacerbated after the extra loss term \"Certificate Regularizer\" (CR) is added which encourages the SOC layers to amplify logits and hence signals in all intermediate layers.\nThis explains why, in Table 2, the effect of CR grows stronger as the network gets deeper.\n\nTherefore, the reported provable robustness numbers, which are measured by margins in logits, are not reliable:\n* The absolute numbers of provable robust accuracies could be overestimated for all models in Tables 1 and 2.\n* The relatively comparisons in Tables 1 and 2 are not with constant X. Since the comparisons are in the range of a few percentage points, the actual robustness difference between models can easily get lost in the fluctuation of X of different networks.\n\nIn such situation, please consider the following:\n* Report measured robustness by running adversarial attacks. While doing that, the comparison should not be limited to SOC and should include other techniques like adversarial training.\n* After training is done, calculate the actual X of the final network and then divide logits by X before measuring margins for provable robustness assessment.\n",
            "summary_of_the_review": "The evaluation setup is flawed and therefore unable to judge the value of the proposed techniques. Update: ratings adjusted based on new results from authors.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposed a procedure to certify the robustness of 1-Lipschitz CNNs by \n\n(i) relaxing the orthogonalization of the last linear layer of the network, while requiring that all rows of the last layer matrix are normalized -- Last Layer Normalization;\n\n(ii) introducing a certificate regularization that increases the robust certificate for correctly classified examples;\n\n(iii) introducing a class of Gradient Norm Preserving activation functions called Householder activations which are necessary for any GNP piecewise linear function to be continuous.\n\nThey proved the success of the proposed procedure on CIFAR-10 and CIFAR-100 by showing improvements in provable robust accuracy with a comparable standard accuracy.",
            "main_review": "This paper is well-written. I am not very familiar with the field of certified robustness, but the three bullet points listed in my Summary of Paper are well motivated and justified, and their success has been proved in numerical experiments. My major concerns are about the explanation of the numerical results. The authors have observed improvement in standard accuracy in certain circumstances, which needs more explanation on why this happened. Is it because you relax the orthogonalization requirement of the last linear layer?\n\nA minor comment on Page 2, when introducing \\rho, it would be good to define what it is. For readers who are not familiar with the field, it looks a bit confusing. I only got what it means when reading later sections of the paper.\n\nAnother comment at the end of Section 2, where you mentioned some past work focusing on l1 norm certificate. Can you expand a little bit explaining what is the motivation for considering l2 certificate, difference and applicable settings for these two concepts?\n\nLastly about the numerical section, is it possible to include results on large datasets such as ImageNet, to test the effectiveness, scalibility of the proposed procedure? Also, you observed different performance gains on different architectures. Can you provide an explanation on why this is so, and give a short summary regarding when your procedure would work best, and when it yields negligible gains?",
            "summary_of_the_review": "Overall I like this paper and the proposed ideas were well justified. My comments on the weakness mainly involve the explanation of the numerical results, and whether it is possible to include more results on larger datasets. It would be good if the authors can provide a short summary on when their method would work the best. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}