{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Spotlight)",
        "comment": "The paper aims to solve the source-free domain adaptation, specifically on measurement shift. The proposed method lowers the domain gap via restoring the source feature distribution with a lightweight approximation. The effectiveness and performance are well validated by extensive experiments on various datasets compared with other recent methods, and the ablation analysis supports the claim of the paper well. The paper is well written with clear logic to follow."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper tackles the specific domain shift, named measurement shift on source-free adaptation setting. They analyze the drawbacks of existing entropy-based SFDA methods and instead propose a method to retore the source feature with a lightweight approximation. The paper emphasizes the difference of measurement shift with common concept shift, and their method can achieve significant performance on measurement shift setting compared to SOTA. ",
            "main_review": "Strengths\n1. The paper is very well-written and easy to follow. It targets the SFDA setting but with a different type of domain shift to the common setting. The measurement shift is indeed an important piece of domain shift on many applications. \n2. The proposed method is simple and effective. At the first glance, it might be doubtful that they use source features for training. The authors give a memory storage comparison for the estimated source distributions, proving it is very lightweight. \n3. Considering the simplicity of this method, it achieves promising results on several types of datasets in terms of accuracy and calibration compared to the SOTA. The ablation and analysis are sufficient to support the claim of this paper. \n\nWeakness:\n1. The main comparison of this paper is SHOT, which is an entropy-based method and thus has calibration problems and strict assumptions. I think it is also preferable to see how this method compares to other feature restoration type SFDA methods such as [1] and [2].\n2. 2nd point is not weakness. But it will be also helpful to include performance comparison on Office-31 or home as a baseline. \n\n[1]Li, Rui, et al. \"Model adaptation: Unsupervised domain adaptation without source data.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n[2] Liu, Yuang, Wei Zhang, and Jun Wang. \"Source-free domain adaptation for semantic segmentation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.",
            "summary_of_the_review": "This paper deals with the measurement shift in the source-free DA problem. The authors propose a simple but effective method to approximate source distribution in a lightweight manner. I recommend to accept this paper. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper focuses on the improvement of the source-free domain adaptation problem. While the previous studies destroy the model calibration to improve the domain generalization or update the source model to fit the feature distribution from the target domain, the proposed algorithm reduces the domain gap by restoring the distribution of source features at the adaptation phase. This feature restoration step is based on the assumption of the measurement shift that comes from the difference between the data-grabbing system and environments. Based on the assumption, the authors proposed the method of feature restoration (FR) and bottom-up feature restoration (BUFR) that is its extended version. The state-of-the-art performance of the proposed algorithm was validated by numerous datasets including the simple digit datasets and the real-world complicate datasets.",
            "main_review": "Strengths\n+ The detailed framework is well explained to be easily understood, and the figures were very helpful for understanding.\n+ The state-of-the-art performance was validated well by using various types of datasets and the compared algorithms were recent and reasonable.\n+ The empirical analysis was helpful to understand the overall workflow and solve the questions about the framework.\n\nWeaknesses\n- The analysis for the intuition and assumption of the proposed algorithm is not presented. Even though the empirical analysis for the algorithm is well described, the presence of measurement shift and its importance cannot be understood just through this paper. I agree that the measurement shift can be occurred by the measurement system, but it is hard to know how the shift looks like and which part of the model is affected by the measurement shift. With the description of the weak intuition, the design of the framework was hard to be followed. Furthermore, the bottom-up feature restoration assumes that the low-level features are affected by the measurement shift, but there is no related analysis showing the effect of measurement shift for the respective layers at all. Thus, I want to see the analysis of the measurement shift to explain the reason for the proposed architecture.\n- Some sentences are repeated in the abstract and the introduction. With the limited pages of paper, repeated sentences should be avoided to explain the proposed framework as much as possible with the various aspects. I recommend the rewriting of the abstract to improve the readability of the paper. The current abstract contains too much detailed information, which can let the readers confused before understanding the intuition of this paper.",
            "summary_of_the_review": "Even though the intuition of the algorithm is not given yet, the designed framework showed the state-of-the-art performance, which means that the measurement shift would be one of the hidden keys to improve the domain generalization. When the authors present adequately the additional analysis for its intuition and revise some repeated parts, I am preparing to increase my score.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper addresses the problem of source-free domain adaptation (SFDA) under measurement shifts. The measurement shifts are a subset of general domain shifts which arise from a change in measurement system. The proposed method aims to resolve this problem by restoring the target features to the source feature distribution. Towards this, the source distribution is approximated using a lightweight and flexible approximation, namely softly-binned histograms. For the target adaptation, the feature extractor is trained to re-align the target feature distribution (of a batch) with the saved source distribution. This method is termed as Feature Restoration (FR) and is performed for the feature activations and the pre-softmax activations. An extension of this method, called Bottom-Up FR (BUFR) is introduced which performs the feature restoration in a block-wise manner starting from the early layers of the network. The improvements of BUFR and FR are demonstrated on a new proposed EMNIST-DA dataset for simulating measurement shifts as well as on standard CIFAR10-C, CIFAR100-C (common corruptions) benchmarks and the Camelyon17 dataset that contains realistic measurement shifts. They perform several ablation studies on the EMNIST-DA dataset to highlight the effectiveness of the proposed components.",
            "main_review": "Strengths:\n- This paper addresses the interesting novel problem of measurement shifts, a subset of general domain shifts that occur due to changes in the measurement systems.\n- To approximate the source feature distributions, this work uses a softly-binned histogram and provides a novel differentiable implementation that is used in a loss function to adapt the model to the target domain.\n- The improvements of BUFR are demonstrated against prior SFDA works on the proposed EMNIST-DA dataset, CIFAR-10-C/100-C and Camelyon17 datasets. Extensive ablation studies are performed on EMNIST-DA to study the proposed components.\n\nWeaknesses:\n- This work attempts to illustrate the importance of measurement shifts (a subset of domain shifts) and to propose a method specific to tackling measurement shifts. Most of the empirical justifications rely on evaluations on the proposed EMNIST-DA dataset. However, there are several issues with the arguments, which are detailed as follows.\n\t- Considering Table 1, the authors do not mention which type of shifts are actually included in the severe category, except that the severe shifts cause a large drop in performance for the AdaBN prior art. Some of the shifts indicated in Fig. 7 like zig-zag, stripe and dotted line do not seem like natural measurement shifts as they occur only locally and may change the class label as well (like in the zig-zag example of Fig. 7, N looks like P). Conversely, the Camelyon17 dataset, with real-world measurement shifts, shows that measurement shifts tend to have more global effects on the images (in Fig. 9). The authors should clearly mention the criteria used for selecting shifts to represent measurement shifts. This is also important because the EMNIST-DA dataset is one of the contributions of this work. Hence, it is not clear whether these severe shifts are a good representation of measurement shifts and thus, whether evaluation on severe shifts is a good indicator of a method successfully tackling measurement shifts.\n\t- For the Camelyon17 dataset, representing real-world measurement shifts, the performance of all prior arts is competitive w.r.t. the proposed FR and BUFR methods, even when a very small number of target images are available for training. For example, when only 5 target images per class are available, all prior arts (AdaBN, PL, SHOT-IM) get ~82.6% accuracy while FR and BUFR get ~84.6% accuracy. This implies that the advantage of having a method specifically catered to measurement shifts is small. As the number of available target samples increases, the performance gap reduces and prior arts perform the same as the proposed methods. Further, in most practical scenarios, a large number of unlabeled target samples are usually available or easily obtainable.\n\t- For the CIFAR10-C/100-C benchmarks as well, the expected calibration errors (ECE) of prior arts (AdaBN and TENT) are on par with FR and BUFR (Table 13). Significant improvements to ECE are shown only for the synthetic EMNIST-DA dataset while the ECE metrics for Camelyon17 dataset are not reported. Thus, we cannot conclude whether the improvements w.r.t. usual DA methods are significant.\n\t- The previous three points illustrate that the significant improvements of this approach are on the synthetic EMNIST-DA dataset and not on the real-world measurement shift based Camelyon17 dataset or the standard CIFAR10-C/100-C benchmarks. Thus, it is not clear whether this method will give significant improvements over simpler and more generic DA techniques like PL (pseudo-labeling) or AdaBN on realistic measurement shift datasets.\n\t- Further, the ablations are performed only for the EMNIST-DA dataset. Specifically, the ablation studying the bottom-up hypothesis i.e. effect of number of blocks unfrozen for training (in Fig. 4b) is shown for the EMNIST-DA dataset only. In Table 6, it is observed that the FR performance is sometimes better than or very close to BUFR. While the bottom-up hypothesis is intuitive, these observations from Table 6 cast a doubt on it. Thus, ablations on the Camelyon-17 dataset will help clear these doubts and make the argument stronger as they represent realistic measurement shifts.\n\nMinor issues:\n- Sec. 2 (Feature restoration): $f_s = h(g_s(X_s))$. Here, $f_s$ is defined as the output of the network rather than the network itself. A possible correction could be $f_s = h \\circ g_s$.\n- A table of contents should be added for the Appendices, with hyperlinks to the various tables, figures and subsections. This will improve the readability of the paper, given its length.\n",
            "summary_of_the_review": "This work focuses on specifically tackling measurement shifts (subset of general domain shifts). Most of the justifications to highlight the importance of measurement shifts are based on evaluations on the proposed synthetic EMNIST-DA dataset. While the improvements are significant on EMNIST-DA, the simpler and more generic DA techniques obtain competitive performance on the real-world measurement shift dataset (Camelyon17) which casts doubt on the requirement of specific methods to tackle measurement shifts. See the main review for detailed comments. While the paper addresses an interesting problem with good results, I am not convinced by the paper’s argument that such a specific method is better suited for realistic measurement shift DA problems than simpler, generic methods like pseudo-labelling. Thus, I give the rating of “5: marginally below the acceptance threshold”.\n\n**Pose-rebuttal comments**\n\nI thank the authors for their efforts in the rebuttal period. Most of our concerns have been addressed by the authors. Further, having read the other reviews and considering that this work is the first that addresses measurement shift DA, I increase my score to 6: marginally above the acceptance threshold. I hope that the authors will include all the discussions from the rebuttal in their revised draft.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper tackles a variation of domain adaptation problem where the model is pre-trained on the source data and then deployed in the target domain for adaptation. The major challenge being the absence of source domain data during the adaptation process and hence generally used unsupervised domain adaptation methods are not useful in the case. Furthermore, the paper tackles a sub-set within the ''Source-Free Domain Adaptation'' setting, termed in the paper as *measurement shift*. The proposed method addresses this by aligning the target domain activation statistics with stored statistics of activations measured during development stage (i.e. source domain training). The experimental analysis provided in the paper and supplementary material shows that proposed method is able to outperform all existing methods for the *measurement shift* case.",
            "main_review": "### *Strengths:*\n- The paper is well structured and easy to follow. It is well written and the method is easy to understand.\n- The experimental analysis is very extensive. Most of the claims and arguments made in the earlier sections are validated with experimental analysis. Also, the proposed method for the most part is novel and quite interesting.\n- In my opinion, the major strength of the paper comes from its experimental analysis section. Specifically, extensive comparisons are provided with the most of the methods available in the literature. The paper considers many benchmarking datasets such as cifar-10/100, camelyon17 and also develops a new benchmark with character recognition dataset emnist. However, I would suggest omniglot [1] would be a more challenging dataset than emnist and could be considered in future updates of the work.\n- The paper also provides nice analysis of the activation statistics under the *measurement shift*, ablation analysis on which components are useful and discussions on the observations. Overall it provides great insights on the affects of *measurement shift* on activation statistics.\n\n\n### *Concerns:*\n- Though the paper has reasonable novelty and an extensive experimental analysis, there are some aspects of the work which are either not clearly explained or is not validated through experiments.\n- In the earlier sections, it is argued that methods such as [2] [3] [4] etc are not comparable to the proposed method as they \" are still classification-specific and rely on good initial feature-space class-separation for entropy minimization\". However, it is not a strong argument to avoid comparison with these methods which have previously addressed the problem of source-free adaptation. Furthermore, they are very closely related to the proposed method idea of activation distribution matching as compared to their approach of feature-distribution matching. Comparing with these methods would provide key insights into which type of feature-matching is better for the cases considered in the paper. Also, the argument that these methods are classification-specific is not properly evaluated, since the proposed method is also evaluated for only the task of classification.\n- The considered *measurement shift* case is widely established as performance under *common corruptions* in the literature, which is what the paper uses for performance evaluation. It is not entirely clear if they are one of the same, which it seems to be. Then why is there a need to define it as *measurement shift*. It would be helpful to get more clarification on the differences between *common corruptions* vs proposed *measurement shift*.\n- Also, there are methods like [5], [6] which consider generalization by improving training on source/clean data and without the need for any target/corrupted data. Adding those comparisons (I am assuming in most cases proposed FR/BURF would be better) would also be helpful for benchmarking results. An interesting addition in the experiment would be to consider these improved models [5] [6] as initialization for SFDA and comparing relevant methods.\n- I understand comparison with [6] would not have been possible as its a very recent work. However, some of the performances in [6] matches the SFDA method performance, which leads to a more general question about the problem, i.e., Is corrupted data required for model to generalize to those conditions? Should we consider common corruptions as a DA problem at all or is it better modeled as a generalization issue and the focus should be to improve source/clean data training?\n\n\n\n\n\n\n[1] https://github.com/brendenlake/omniglot\n\n[2] Li, Rui, et al. \"Model adaptation: Unsupervised domain adaptation without source data.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n\n[3] Morerio, Pietro, et al. \"Generative pseudo-label refinement for unsupervised domain adaptation.\" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2020.\n\n[4] Kurmi, Vinod K., Venkatesh K. Subramanian, and Vinay P. Namboodiri. \"Domain Impression: A Source Data Free Domain Adaptation Method.\" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2021.\n\n[5] Hendrycks, Dan, et al. \"AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty.\" International Conference on Learning Representations. 2019.\n\n[6] Wang, Haotao, et al. \"AugMax: Adversarial Composition of Random Augmentations for Robust Training.\" arXiv e-prints (2021): arXiv-2110.\n\n\n",
            "summary_of_the_review": "Overall, I think the paper has some interesting ideas and has a compelling experimental analysis. However, there still remain few concerns/confusions which require further explanation.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Paper proposes a new scenario for source-free domain adaptation where the domains undergo a measurement shift (characterized by a change in the measurement system). Other than the typical source-free DA scenario, in this case, you would not need new features but you would like to update the lower layers of the network. The paper proposes a method that is based on two ideas i) aligning the marginal feature distribution (with KL loss) and ii) performing updating in a bottom-up way (allowing lower layers to first adapt to the target domain). Results show that the method outperforms existing methods on this setting. ",
            "main_review": "The strengths of the papers: \na) The paper is very well written, well-motivated, well compared with existing literature and it was a pleasure to read.\nb) proposed method makes sense\nc) extensive results show that the method obtains good results on multiple datasets, outperforming existing source-free DA methods. \nd) the efficiency of proposed bottom-up feature restoration is ablated (and shows large gains for some experiments).\n\nThe weaknesses:\na) The proposed method is very simple (both the feature alignment and the bottom up feature restoration). However, I do not consider this a large weakness: results show that these first steps already provide large improvements. \nb) the results on the real application (Table 6) are maybe less convincing (especially the impact of bottom-up feature restoration is small) and it would be great if another real application would be found. The authors argue this scenario is not optimal for their method. Maybe they could extend a bit more on potential applciations. \n\nMinor: \nthe sentence 'Unlike most existing SFDA methods, we make no modifications ' would be nice to see references here to what SFDA methods the authors refer.\n\nI was wondering if the method could work for extending the number of channels of the input data (For exeample source only red-green channels and target red-green-blue). \n",
            "summary_of_the_review": "The authors propose a relevant new scenario for SFDA and propose a new method to address this setting. Results show that the existing methods struggle for this setting. The proposed method outperforms existing methods. I think the proposed setting is relevant and I would therefore recommend acceptance. The novelty of the proposed solution is not that large though. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}