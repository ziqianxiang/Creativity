{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The authors propose a neural network model to preserve the sub-class similarity. The key of the model is to add a prototype layer to a multi-scale deep nearest neighbor network. The prototype layer stores the representative prototypes of some fine-grained sub-classes. The use of the prototype layer preserves intepretability and computational efficiency. Experimental results demonstrate that the proposed approach reaches state-of-the-art prototype learning performance.\n\nThe reviewers generally find the paper clear and with sufficient contributions. The empirical validation is sufficiently thorough to back the claims in the paper. The main concern prior to the rebuttal among some of the reviewers was about the novelty of the paper (e.g. with respect to DkNN), but the authors convinced most of the reviewers in the rebuttal about the key differences. The authors are encouraged to highlight the novelty aspect more clearly in the revision. Another suggestion was to add an ablation study to justify the importance of the r1/r2 parameters, and the authors have done a successful job addressing the suggestion. Several other comments, such as explanations of the hyperparameters, have been taken into account in the revision. The reviewers thus reach the consensus to recommend acceptance."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a method to learn neural nets that preserves the subclass\nsimilarity in the embedding space. The proposed method adds a prototype layer,\nwhich stores the representative prototypes of some subclasses, then a fully\nconnected MLP is used to output the class label based on examples' distance to\nthe prototypes.",
            "main_review": "I am not expert in deep learning, but I know that prototype method was very\npopular in statistical learning. Many commonly used algorithms, such as KNN and\nK-means, are exploiting this idea.\n\nThe proposed method adapts the idea of prototype-based classification to deep\nneural networks, and uses the automatically extracted prototypes to increase the\nexplainability of neural nets. The proposed algorithm seems work well on MNIST\nand ImageNet benchmarks.\n\nMy main concern is the novelty of this work, and its lack of comparison to\nprevious work in similar direction. For example, the DkNN method mentioned in\nrelated works persues a very similar idea like this work, so I think the authors\nshould compare this work to it. Moreover, the main contribution of this work is\nit extends MsDNN with a prototype layer. Again, I'm not familiar with this area,\nso I'm not sure whether this improvement is significant or just incremental.\n\nOther than the above problem, I wonder how difficult it is to apply the proposed\nnetwork on real problems. The authors have state that it should be applied on\nclassification problems that each class consists of many subclasses. In order\nto show this idea, the authors manually create superclasses in MNIST and\nImageNet dataset. I understand that using this method can verify if the neural\nnet preserves the subclass structure in its embedding layer. Nevertheless, in\nreal problem we usually do not have such type of information, so I wonder how\nwill the proposed method perform on the original MNIST and ImageNet tasks\ncomparing to more related works.",
            "summary_of_the_review": "The novelty of this work could be limited, and the experiments seem not enough\nfor validating the effectiveness of the proposed approach, so I recommend to reject.\n=======================\nAfter reading other reviews and the authors' clarification, I have increased my rating.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper introduces a novel an interpretable neural network for classification tasks that works by assigning input cases to prototypical cases based on their euclidean distance in an embedding space learned by the network. This is achieved by minimizing a loss function consisting of three components: cross entropy loss; distance between each case and the prototype with the same class, distance between each prototype and the closest case to it. The proposed method is specially useful when classification at fine-grained level is performed where in addition to the class to which an instance belongs, predicting the subclass is desirable as well. Experimental results are provided in the paper that validates the merits of the method compared to a set of variations of the proposed method and a state of the art approach as well.",
            "main_review": "The paper addresses an interesting problems which is interpretability of the classification methods that can have various use cases and can demystify the neural net black box for technical and non-technical individuals. It is written well and is easy to follow. The method is positioned well in the existing body of works and the contributions of the work is clear. Experimental settings and results are throughly and very well discussed which makes the work repeatable. Authors have also done a good job discussing the experimental results and sharing the interesting observations.\n\nA couple of recommendations:\n- One of the main contributions of the paper that should get credit for it's superior fine-grained performance is the loss function introduced in equation 1. However, it's not clear to what extent r1 and r2 are contributing to the overall performance of the method and which one is more important. From the explanations at page 6, it looks like that the weight of the cross entropy component of the loss function is significantly higher than r1 and r2 weights which alludes to the fact that r1/2 play a less significant role in the method. It would have been good if the authors could have added one or more ablated versions to the experiments to check this.\n- Based on the experimental results, C-NN and F-NN mostly outperform Coarse and Fine which makes the reader wonder if instead of classification nearest neighbor search in the embedding space should have been suggested. If the concern is computational costs, it would have been interesting to see the performance of C-NN and F-NN by using approximate nearest neighbor search (e.g. using LSH or k-d trees).\n\n- Minor comments:\n-- P3: \"Training stops when accuracy using nearest-neighbor classification on a validation set is minimized\"\nIf I understand correctly, training stops when classification error is minimized not the accuracy. Please check.\n-- Some hyper parameters seem to be set arbitrarily (e.g. # prototypes = 30) and it's not clear how assigning a different value could have affected the accuracy of the proposed method or how authors have come up with the used values.",
            "summary_of_the_review": "Overall an interesting read and a well written paper. My recommendation is to accept the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a novel combination of prototype learning and deep nearest neighbor learning in order to achieve an embedding of the input data that is more friendly for prototype learning while maintaining the computational efficiency and intepretability of a prototype approach. In more detail, the approach first trains a Multi-scale deep nearest neighbor network to embed the input data. Then, it jointly learns a prototype layer and a fully connected layer which outputs class logits based on distances to prototypes. Finally, the learned prototypes are replaced by the closest sample from the actual training data to enhance interpretability. In experiments on MNIST, FashionMNIST, CIFAR-10, and ImageNet, the paper shows that the proposed approach outperforms state-of-the-art prototype learning.",
            "main_review": "The paper's main strengths are:\n* The combination of nearest-neighbor learning and prototype learning is very natural and appears to work well, empirically. The combination is also well-motivated from a pretty comprehensive literature review. I particularly appreciate the acknowledgment of early prototype work (e.g. Kohonen) which is typically omitted in the recent literature.\n* A particularly nice result is that a learned model can also be used as a one-nearest prototype classifier for finer-grained subclasses of the actual classes it was trained on. In other words: the proposed approach learns hierarchical structure that was not explicitly provided in the training labels. As far as I know, this result is a novelty in the literature and motivates the use of prototype/nearest neighbor approaches.\n* The paper provides reasonable ablation studies and close baselines, which enables the reader to tease apart the effect of most architectural choices. Similarly, the discussion of results is detailed and illuminating.\n* I found the paper easy to follow and clear, with each claim being justified both conceptually as well as empirically.\n\nThe paper's main weaknesses are:\n* It seems to me that the architecture of the last 2 layers is needlessly complicated. While this architecture is in Line with Li et al. (2018), a more common option (starting from Kohonen, 1995) is to assign a fixed label to each prototype and classifying data by assigning the label of the closest prototype (as the paper does for the fine-grained classification). Typical loss functions include the GLVQ loss from [Sato and Yamada (1995)](https://proceedings.neurips.cc/paper/1113-generalized-learning-vector-quantization.pdf) or variants of the [LMNN loss (2009)](https://www.jmlr.org/papers/volume10/weinberger09a/weinberger09a.pdf). Such an architecture would also be more in line with MsDNN.\nInstead, the present paper selects a pseudo-label for each prototype based on the closest data point and proposes new loss components. Why is that? Does it perform better? If so, I would appreciate another ablation baseline that drops the final, fully connected layer and, instead, uses only the distances to the prototypes for classification. \n* While the combination of MsDNN and prototype learning is very natural and makes a lot of sense, intuitively, it would have been nice to see a more formal, theoretical justification why this combination improves performance.\n* The experimental evaluation includes very reasonable baselines. However, more baselines would have been possible, taking more recent work into account, such as Chen et al. (2019) or [Hase et al. (2019)](https://ojs.aaai.org/index.php/HCOMP/article/view/5265).\n* The experimental hyper-parameter settings on page 6 appear ad hoc and are not justified.\n\nOverall, my impression is that the paper is not quite ready, yet. I believe that more experiments and theoretical analysis are needed to fully develop the proposed idea. I do appreciate the core idea, though, and believe that a future iteration of the paper may well be a good contribution to the field.\n\nBeyond the major points mentioned above, there are a few minor recommendations:\n\n* on page 4, the meaning of the hyperparameter $\\sigma$ should be quickly explained.\n* Please provide standard deviation (or another measure of variance) in Tables 1-3.",
            "summary_of_the_review": "Overall, my impression is that the paper is not quite ready, yet. I believe that more experiments and theoretical analysis are needed to fully develop the proposed idea. I do appreciate the core idea, though, and believe that a future iteration of the paper may well be a good contribution to the field.\n\n/edit The authors have resolved the most crucial points in their response. Provided that these crucial arguments are amended to the paper, I believe that it can be published.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}