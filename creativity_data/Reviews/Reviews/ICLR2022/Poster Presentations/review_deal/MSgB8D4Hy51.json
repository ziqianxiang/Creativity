{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper presents a new method for detection of backdoor attacks under strong limitations such as the lack of access to training data and the reference benign model. Its main idea is to utilize a new expected transferability statistic that can be used for detection in broad range of application domains. The effectiveness of the proposed approach is demonstrated experimentally."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposed a post-training BA detection approach for two-class classification problems, which can also be extended to scenarios with multiple attacks. The approach is derived based on a proposed notion of 'expected transferability', which works with a principled threshold that is irrespective of the domain nor the network or attack configurations. Empirical experiments verified the effectiveness of their approach.",
            "main_review": "This paper proposed a novel and working solution to a tough problem of backdoor attacks detection with binary or multiple labels. \n\nStrengths: \n* A novel notion of detection statistics called 'expected transferability' (ET) is proposed to help in detecting the target labels.\n* A domain/attack/network agnostic threshold (1/2) is used which is principled and has theoretical implications.\n* This approach is extendable to address more challenging scenarios, with a potential computation cost. \n\nConcerns:\n* One argued contribution of the work is that it does not need 'the training set of the classifier to be inspected'. However, the approach still requires collecting an individual set of clean samples. I think it would be better to remove this claim.\n* My major concern for this problem is that it seems very slow for the proposed algorithm to converge, as $ET$ is estimated by iterating each class $i$ and each of its samples $x_n^{(i)}$, until transferable set remain unchanged. Since the same procedure needs to be done for each class label, this issue might propagate with more class labels or clean samples. \n\nMinor comments:\nPage 4, definition 3.3 , the expectation $E$ should be over $X, Y \\sim P_i$ instead of  $X \\sim P_i$?",
            "summary_of_the_review": "This paper proposed a novel and working solution to a tough problem of backdoor attacks detection with binary or multiple labels. The solution is well motivated and theoretically justified. Although the convergence rate might be a potential drawback of this approach, it still makes solid contributions to the community.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a new engineered reverse-engine based backdoor model\ndetection method. It has stronger assumptions including: 1) no access to\ntraining data; 2) no access to benign reference model; 3) 2 or multi-class\nmodels. To detect backdoors in such scenarios, it leverages a new statistical\nmetric known as the expected transferability, which can derive a fixed threshold\nfor backdoored models detection. Results on six datasets show that the proposed\nmethod is effective for detecting backdoored models.",
            "main_review": "* Related work and novelty claims\n\nIt appears to me that the paper does not include discussions on recent work. Its\nkey selling point is that the proposed method works under three conditions: no\naccess to training data, reference model, and binary classifier. \n\nMany existing work also work under these constraints, such as ABS proposed by\nLiu et al. in CCS 2019. More broadly, the IARPA TrojAI competition include not\nonly these constraints but more, such as constrained time to finish scanning one\nmodel etc. It involves using a private dataset for training backdoor models\n(a.k.a., detectors cannot leverage training data or train their reference\nmodels), and also many tasks are binary classifiers, e.g., sentiment analysis.\nMany submitted solutions are based on reverse-engineering. Also, as a\nrequirement of this competition, all solutions are open sourced.\n\nThus, to me, I think many claims in this paper should be altered. Moreover, I\nthink the paper should compare with some of these solutions. I would suggest\nusing the TrojAI dataset (also open sourced on NIST web page) as their benchmark\nand compare with the leaderboard results (also open to access on NIST web page)\nso that we can better understand the effectiveness of proposed solution.\n\n* Design of ET and analysis\n\nDespite the formal representation of the method and discussion (which is\nappreciated), the design of this method is based on empirical observations on\nthe transferability of input samples. As such, there is no guarantee that the\nproposed method will work and the threshold value 1/2 is general.In fact, as\nshown in Figure 2, the proposed method also suffers some FP/FN, namely, some ETs\nfor benign classes are larger 0.5 and ET of backdoor target classes can be\nsmaller than 0.5.\n\nTo me, it is important to understand the applicable scenarios of the proposed\nmethod. Namely, why these cases fail? I personally suspect it is because of the\ntransferability assumption. Is it? I would strongly suggest putting such\nassumptions upfront so that we can understand the pros and cons of this method.\n\nAnother concern I have is that, many existing method does require tuning. But if\nwe can tune them to get better results, what is the advantage of the proposed\nmethod? More importantly, are there backup plans when the method fails? Or can\nwe know that when it will work or not? Otherwise, I do not see the fundamental\nbenefits of using this method.\n\n* Evaluation for multi-class, multi-attack scenario is not sufficient.\n\nIn Section 4.4, this paper provides the evaluation results on multi-class,\nmulti-attack scenarios. However, it only trains one model for each attack\nsettings and a single clean model for each dataset. There is no baseline method,\nand I am not sure if the proposed method can truly generalize to other datasets\nand models.\n\n* Countermeasures and ethical statement\n\nThere is no countermeasures discussed and no ethical statement.\n\n* CIFAR-10\n\nWhy the maximum ET for CIFAR-100 is much larger than that of other datasets? As\nshown in Table. 2, an interesting phenomenon is that the maximum ET statistic\nfor CIFAE-100 is much larger than that of other datasets (i.e., CIFAR-10,\nSTL-10). It would be better if this paper could provide some discussion about\nthis phenomenon.\n\n* Code and data\n\nWill the code and data be released?\n",
            "summary_of_the_review": "My main concern is the it lacks discussion and comparison with works that works\nunder the same setting. Its analysis is not sufficient to understand the\napplicable scenarios and its key benefit.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a class-specific metric called Expected Transferability (ET) that can determine if a classifier is targeted by a backdoor attack (or not). The threat model assumes no access to the model's training data. By the virtue of being class-specific, the metric allows one to examine classifiers regardless of the number of output classes. The author reason theoretical what values of ET indicates the presence (or absence) of backdoor attacks. Then they empirically demonstrate how this value can be estimated and leveraged.\n",
            "main_review": "What I liked:\n- The paper is well organized.\n- The use of a class-specific metric to figure out if a classifier is prone to backdoors, given existing works focus on inter-class metrics, is a novel idea. (Although, I have not been proactive in following work on these lines.)\n- I liked the idea of theoretically motivating the value for a metric and then empirically demonstrating its usefulness.\n- The authors conduct several empirical studies.\n\nWeakness/Clarification:\n- Some parts of the theoretical analysis to determine the value of ET seem to be hand-wavy. First, while it is intuitively understandable why Property 3.1 might hold in the context of non-backdoor-attack scenarios, it is not clear whether it will always hold. Second, there is no good definition of how small $\\epsilon$ has to be for the reasoning to hold.\n- The authors argue that existing approaches cannot work for 2-class classification problems (as their sample complexity is $O(K^2)$, $O(K)$ where $K$ is the number of classes). While I get that a method that needs fewer examples is better, how many samples are too few or too many? The author's approach uses 20 samples (why 20?), is that constant or is it ~$O(K^3)/O(K^4)$ for the 2-class classification task. Is there a theoretical bound here? \n- In the empirical section, there are several cases where a backdoor-poisoned classifier is determined to be benign as per the ET metric (16/20 for $A_3$ in Table 1) or vice-versa (16/20 for $C_4$). Is there any particular reason as to why this happens? Also, is there a confidence value associated with the metric (for example, would values far away from 1/2 strongly indicate that it is benign or backdoor-poisoned, or does no such correlation hold)? Looking at Fig 2, Col 3, I notice a few oranges close to 1, which signals that there are no guarantees of any kind.\n- How important is it to have a constant threshold (for ET-based methods) vs. estimate the boundary with a few samples (for other baselines)? Also, from Fig 2, it seems L2, when an optimal threshold value is used, might have better separability than E2. Yet, the ROC curve tells ET is much better than L2; what was the threshold used for L2 and how was is calculated?\n- Why do the authors simply show the max ET values in Table 2? I would be more interested to see aggregate statistics (similar to Table 1). The latter would give a better idea of how the ET-based approach performs on average (as opposed to in the best case, that too if values furthest from 1/2 imply best).",
            "summary_of_the_review": "See above.\n\n*[Update]* Having read the rebuttal (and looking at the additions to the revised paper), I would like to thank the authors for showcasing an honest effort to answer/address many of the comments/clarifications I initially had. I have updated my score to reflect the same.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a novel post-training backdoor attack detection algorithm using reverse-engineering defense. The authors design a new statistic called expected transferability (ET) for detection. The advantage of ET is that the detection threshold is a constant (1/2) and is independent of classifier domain and attack algorithms, so the proposed detection algorithm can be applied to a wide range of backdoor attacks on different databases.",
            "main_review": "Pros:\n1. The math derivation of ET and detection threshold is convincing. With a constant threshold, ET can be used to detect different backdoor attacks in different domains.\n2. The proposed BA detection algorithm using empirical estimate of ET can be applied to classifiers with arbitrary number of classes including two-class cases. \n3. Authors conducted comprehensive experiments on six benchmark databases using different backdoor patterns to demonstrate the performance of proposed algorithm.\n\nCons:\n\nThe technical part of proposed BA detection algorithm is interesting and convincing for me. I am curious about the patience parameter to determine convergence. Does the choice of 4 hold true for ensembles A1 to A10, C1 to C6 in the experiment? Does the number of clean images used during detection affect the detection accuracy? Is the a minimum number of clean images required for an effective detection?",
            "summary_of_the_review": "I will vote for accepting this paper. The proposed ET statistic is novel and technically convincing. Extensive experiments have been conducted to evaluate proposed BA detection algorithm.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}