{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "Initially, we had some borderline scores for this paper. After the (indeed very convincing!) rebuttal and a the end of the discussion phase, however, all reviewers agreed that this is a very solid piece of work, with significant methodological and practical contributions. I fully share this positive impression of the paper!."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "In this article, the authors propose a way to characterize graphs using topology and persistent homology. Indeed, graphs represented with adjacency matrices can be filtered using the corresponding edge weights, and the resulting persistence diagrams can then be used for encoding the topological structures of the graph. Moreover, since the topology of graphs can be easily controlled (the only features they have are connected components and loops), their persistence diagrams are simple enough so that matching and distances between them can be computed efficiently. However, since topology alone can miss important information, the authors suggest to combine this topological distance with a more standard distance, namely the Frobenius norm between the adjacency matrices themselves. Then, they show how to use these distances in an expectation-maximization-like algorithm, using some theoretical computation guarantees of the Fréchet mean associated to their distances. Finally, they provide experiments in which their procedure compares favorably to competitors on a few synthetic and real-world graph classification tasks.",
            "main_review": "The proposed method is definitely interesting and the provided scores in the experiments are impressive. Moreover, the algorithm is backed up by not-surprising yet nice theoretical guarantees. However, I also think that the writing and the experiments could be improved.\n\nIn particular, I also have the following comments:\n\n---Section 1, 2nd paragraph: it would be good to add a reference to the PersLay paper (http://proceedings.mlr.press/v108/carriere20a/carriere20a.pdf), which also provides a standard way to use (extended) persistence to characterize graphs. \n\n---Section 1, 3rd paragraph: it would be good to add a reference to the entropic regularization for persistence diagrams (https://papers.nips.cc/paper/2018/hash/b58f7d184743106a8a66028b7a28937c-Abstract.html), which also contains a standard approach for approximating topological distances.\n\n---Section 1, 4th paragraph: \"by projecting the persistence barcodes into one dimension\", it is a bit incorrect, as the proposed approach is not really about projecting 2D barcodes onto lines. The fact that the barcodes are 1D only comes from the data (i.e., graphs) on which they are computed. This should be corrected as otherwise it is confusing with actual projection techniques, such as, e.g., the sliced Wasserstein distance and kernel.\n\n---Section 2.2: \"there are |V|-1 connected components\": in which graph? G_{-\\infty} has one connected components and G_{\\infty} has |V| connected components, so it is unclear to what space this sentence applies to.\n\n---Section 4: the authors compare their method to k-means, but it is unclear on which data k-means is actually run. Is it over the adjacency matrices treated as vectors? But then, how is this different from the authors method applied with lambda=0? Similarly, isn't k-medoids with the bottleneck distance essentially the same than the authors method applied with lambda=1? \n\n---Section 4: all in all, the authors method simply separates the filtration values into two groups based on 0- and 1-dimensional persistent homology, and then compare graphs with the Euclidean distance computed on the sorted groups. So I really wonder (and I think this should be included in the baseline) if the improvements in score could be obtained by simply adding the Euclidean distance on the whole sorted filtration values (without running persistent homology).\n\n---It is always a bit suspicious to see p-values exactly equal to zero as in Table 1 (b). 100 iterations seems a bit low, maybe this number should be increased on a few thousands on these data sets.\n\n---The improvement on the scores is quite impressive, but on the other hand the baseline seems a bit naive. Since the number of networks is not so large in the experiments, I strongly suggest adding fancier methods in the baseline, such as, e.g., kernel methods or neural nets. Indeed, there is quite a lot of graph kernels (https://arxiv.org/pdf/2011.03854.pdf) and graph neural networks (https://arxiv.org/pdf/1812.08434.pdf) in the literature, some of them performing quite well in applications, so it would nice to add some more comparisons.\n\n---The authors distance is only presented on graphs with same number of nodes. Since their method extends naturally to graphs with different sizes (even though running time would probably be worse), it would be nice to discuss this at some point in the article.\n\n[Post rebuttal comment]: the rebuttal was nicely done, and I think that the paper is now good enough for publication.",
            "summary_of_the_review": "Overall I think that the technique proposed in the article is really promising, but that experimental results should be developed a little more before getting accepted.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents a novel algorithm for clustering networks based on\ntheir topological properties. To this end, an algorithm based on\npersistent homology (a method from computational topology that permits\nthe calculation of multi-scale features of unstructured and structured\ndata sets) is introduced. The key feature of the algorithm is that it\nmanages to substantially reduce the cost of 'matching' topological\nfeatures between two different data sets, thus making their comparison\nand similarity assessment computationally feasible. The paper provides\nan algorithm that can employ *both* geometrical and topological features\nof a network (with an appropriate regularisation term); experiments\ndemonstrate the general utility of the algorithm.\n",
            "main_review": "This is a paper about a timely and highly relevant topic, and I find\nmyself to be very excited about its results and promises. The paper\nstands on firm theoretical footing: the proposed algorithm is described\nin sufficient detail to be reproducible and a brief analysis of the\ntheory behind it is provided as well. The current write-up is already\nvery clear, and only suffers from minor formulation issues or clarity\naspects, on which I shall subsequently comment. The primary weakness of\nthe paper lies in the experimental section; here, I would suggest\nimprovements in terms of the discussion here, because the jump between\nsimulated networks and real-world networks might necessitate some\nexperiment 'in-between.'\n\n## Detailed Comments\n\n- When introducing graph filtrations, consider discussing that such\n  filtrations can also be generated using specific descriptor functions,\n  such as a heat kernel (Carrière et al., [PersLay: A Neural Network\n  Layer for Persistence Diagrams and New Graph Topological\n  Signatures](http://proceedings.mlr.press/v108/carriere20a/carriere20a.pdf)),\n  or they can even be *learned* in a task-specific manner (Hofer et al.,\n  [Graph Filtration\n  Learning](https://proceedings.mlr.press/v119/hofer20b.html)).\n  Moreover, it could e discussed that the presented filtration is only\n  one way of filtering over the network; this could be managed by\n  a brief discussion on sublevel or superlevel set filtrations, for\n  instance.\n\n- Moreover, it should be made clear that, unless I am mistaken, the type\n  of filtration described in the paper is a **highly specific** type of\n  filtration in the sense that not all filtrations will result in the\n  respective creation--destruction tuples (or birth--death tuples,\n  respectively). For instance, if a descriptor function (like the\n  aforementioned heat kernel) is used, creation tuples might be of the\n  generic form $(a, b)$ with $a, b \\in \\mathbb{R}$, as opposed to one of\n  them being infinite. I am mentioning this point not out of pedantry,\n  but because it should be clarified that the simplifications of the\n  Wasserstein distance later on are *contingent* on the tuples being of\n  that form. To some extent, this limits the general applicability of\n  the approach: if higher-dimensional simplices are present in the\n  network, cycles could be assigned finite persistence values (the same\n  holds for the calculation of extended persistence, or the use of\n  another descriptor function that does not necessarily result in\n  a fully-connected graph). It would immensely strengthen the current\n  write-up in the paper if these special properties were at least\n  briefly discussed.\n\n- To add to this, such special properties could also potentially be\n  mentioned in Section 3.1 when discussing how to derive the distance\n  function.\n\n- The notation for solving the optimisation problem could also be\n  improved. At first, the networks are described with a weight function\n  $\\mathbf{w}$ and $\\mathbf{u}$, respectively. Later on, this notation\n  is changed to include $\\mathbf{\\theta}$ for a cluster representative.\n  This should be clarified; I understand that $\\mathbf{\\theta}$ is just\n  another weight function, is this correct?\n\n- How should the regularisation strength $\\lambda$ be chosen in\n  practice? I really like the discussion of the 'extreme cases' that one\n  can obtain, but a more specific discussion later on in the\n  experimental section would be appreciated. I would also suggest to\n  consider the inclusion of a 'target function' plot in which $\\lambda$\n  is being varied; it would be interesting to see how the overall\n  accuracy, for instance, depends on this parameter. Knowledge about the\n  stability of a specific choice for $\\lambda$ would help to instil more\n  trust into the method.\n\n- As for the experimental section, I think it would strengthen the paper\n  if more details were provided, in particular when it comes to the\n  validation experiment. It is astonishing to me that existing methods\n  all *fail* to cluster such networks with pronounced modularities. \n  I would suggest to discuss this.\n\n- I also do not understand how the comparison partner methods are\n  working here; are all weights of the network being vectorised into\n  a feature vector of the same size? This points needs elucidation\n  because although the number of vertices is always the same, such\n  a vectorisation does not account for the fact that a graph-level\n  representation needs to be permutation-invariant here; node $1$ in one\n  network is *not* the same as node $1$ in another network. If the\n  vectorisation strategy does *not* account for this, it might be an\n  explanation for the bad performance of other methods.\n\n- Moreover, when it comes to the comparison of different methods, simple\n  statistical baselines (for instance a feature vector based on degrees,\n  overall modularity of nodes, clustering coefficient, etc.) could also\n  be employed (if they are unsuitable, this should at least be\n  discussed). I would anticipate that $k$-means based on network summary\n  statistics might perform better than $k$-means using vectorised\n  weights? It would also be interesting to see a simple graph kernel\n  being employed here, for instance a graph kernel using a graph-level\n  histogram; since the networks are not excessively large, adding such\n  additional comparison partners should be still be possible.\n\n- The same comments apply, *mutatis mutandis*, to the discussion of the\n  brain network data set. Here, it would be imperative to show different\n  results for different values of $\\lambda$. Moreover, given the large\n  standard deviations, it seems that almost all methods are performing\n  similarly here; is there a reason for such a high variance in the\n  results? This should be briefly discussed.\n\n- Out of curiosity: would such an experiment benefit from a more fuzzy\n  definition of clusters? The method should potentially allow for this,\n  I think, and this might result in better clusters, in particular when\n  it comes to an unclear delineation between wake and sedated states.\n\n## Typos, word-smithing, etc.\n\nOverall, the writing in this paper flows well and the language is clear.\nThere are some cases in which articles are missing or a plural form\nmight be employed, but this does not prevent a clear understanding of\nthe text. Here are two examples of this (additional ones can be found\nthroughout the text; since some of them boil down to personal\npreference, I will refrain from listing them):\n\n- 'cycle structure is ubiquitous' --> 'cycles are ubiquitous'\n\n- 'takes infinitely large amount of work' --> 'takes an infinitely large amount'\n\n",
            "summary_of_the_review": "Overall, this is a very interesting paper with a very relevant and\ntimely topic (potentially high impact). The theory is strong and\nwell-explained, even though the current write-up suffers from minor\nformulation issues, which, however, do not detract from the overall\nclarity of the message. I lean towards accepting the paper with the\nproviso that clarity is improved and, most importantly, my comments\nconcerning the experiments are being considered. At present, it is\nslightly unclear for non-expert readers to judge the overall utility of\nthe algorithm since the choice of comparison partners and their training\nhave yet to be clarified.\n\n**Update after rebutall**: I thank the authors for their updates to the paper;\nmy concerns were addressed, and I am happy to raise my score.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "Given a weighted graph, authors construct a filtration on top of it that is associated with a persistence diagram. This persistence diagram summarizes the topology of the weighted graph. Authors propose then to cluster different graphs using either the distance between the persistence diagrams (that they call the topological distance) or an interpolation between the L2 distance between the weights and the topological distance.\n\nThe relevance of this algorithm is then showcased on synthetic examples and real-world datasets.\n",
            "main_review": "The presentation of the paper is clear and the paper is well-written. The problem of clustering persistence diagrams (PDs) has attracted some attention over the recent years and is not a trivial one. To overcome the main computational challenges that arise when having to compute distances/barycenters of PDs, authors propose to consider simpler persistence diagrams that are one-dimensional (that is all points in the PDs have coordinates of the form $(-\\infty,d_i)$ or $(b_i,+\\infty)$). It is well-known that in one dimension, optimal transport essentially boils down to sorting algorithms, so that all the computational tasks (computing distances/barycenters) become trivial. A naive implementation of k-means is then proposed using the distance between PDs, that is able to attain a local minimum of the energy functional at stake.\n\nMy main issue with the article is that they never clearly acknowledge that they work with \"simple\" PDs that have a very particular form, and that this makes the problem much easier to solve. Those simpler PDs appear because the filtration F that they build on top of the weighted graph does not contain any two-dimensional simplices: as such the points of the PDs PD(F) are of the form $(-\\infty,d_i)$. What is usually done is to consider a filtration G with two-dimensional simplices appearing and \"filling\" the loops of the graph at some point, the corresponding PD PD(G) having points of the form $(b_i,d_i)$. To put it another way, we are considering a PD, PD(F), obtained by considering the projection of the points of PD(G) on the y-axis. We are therefore losing information while doing this. I have nothing against considering a simpler object if this allows one to also simplify computations, but this needs to appear explicitly in the paper.\n\nThe question is then: \"What exactly do we lose by considering the simple filtration F instead of G?\". I do not expect a mathematical treatment here, but it would seem fair to compare experimentally the method proposed in the paper with the alternative method with the filtration G used. More precisely, in the case $\\lambda =1$ (considering the topological distance), one could cluster graphs applying the k-mean algorithm on the PDs built with G, computing barycenters of PDs using one of the standard approaches [1,2]. We expect the second method to take more time, but to be more precise. Of course, a good selling point for the paper would be to show that using the filtration G instead of the filtration F (i) takes much more time and (ii) does not make us gain that much accuracy. Such an empirical confirmation should really be at the core of the paper in my opinion.\n \nOverall, the idea of considering simpler objects on which computations can be done is appealing, but this needs to be backed up by either theoretical or empirical evidence. With more experiments, I would be willing to improve my grade.\n\n\nMINOR COMMENTS:\n- p.1 \"Wasserstein distance can be used to interpolate networks while preserving topological structure,\" please give a ref\n- Eq (4): this would rather be d_net^2, if we want d_net to be a distance.\n- p.4 How is this algorithm different from Lloyd's algorithm (in a general metric space)?\n- p.5 bottom: comparing to k-medoids using the W2 distance instead of the bottleneck distance appears to be fairer, as it will be more able to assess the fine structure in the geometry of the points of the PDs.\n- Fig 5: this behavior is interesting, and should be commented on: taking $\\lambda = 0$ is a bad idea, but then, any positive value (that is still not too close to 1) appears to give a similar score. Are there any explanations about why this is the case?\n- On the experiments: it seems weird that they do not exist better alternative methods that are **at least** able to obtain a score similar to the one obtained by the paper's method. \n\n\n[1] Geometry Helps to Compare Persistence Diagrams - Michael Kerber, Dmitriy Morozov, Arnur Nigmetov\n\n[2] Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport - Theo Lacombe, Marco Cuturi, Steve OUDOT",
            "summary_of_the_review": "The proposed method to cluster graphs using persistence diagrams is computationally efficient, but at the price of losing some topological information in the process. This can definitely be a good approach in some problems, but I would like to have some empirical evidence that \"we do not lose too much information\" in the process, that is that this procedure competes with the (slower) one where we take into account the complete topological information.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}