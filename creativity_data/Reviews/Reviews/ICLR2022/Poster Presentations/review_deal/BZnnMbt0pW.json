{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper received two accepts and 1 marginally above acceptance recommendations. The authors provided satisfactory answers, mostly on clarifying the unsupervised learning methodology, in conjunction with the MAA recommendation. I recommend the paper be accepted as poster."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents an unsupervised RGB saliency detection model to learn from the pseudo-labels given by the traditional handcrafted approach. To enhance the quality of the pseudo labels, the author proposes to disentangle the depth data to promote the saliency signal and compress undesired noise. Last but not least, an attentive training strategy is integrated to teach the network from iteratively updating supervisory labels. Experimental results demonstrate the effectiveness of the proposed depth-disentangled saliency update framework and can help improve the performance of on-the-shelf approaches.",
            "main_review": "This paper is presented clearly, and the experiments are comprehensive. Additionally, the idea of jointly deriving the saliency training labels from the depth and RGB data is good. However, I have a few questions listed below:\n\n1.  Why discard the available depth signal during inference? This paper discusses RGBD saliency; however, the proposed method is still under the RGB saliency detection framework. The idea will be more impactful if a gated scheme fuses depth information to promote saliency whenever available. Otherwise, the experimental datasets you chose are RGBD, and you only use RGB & Depth to generate the training labels and discard the valid depth signal during inference. Is saving compute the primary reason? \n\n2. When salient objects contain different levels of depth (saying a bus in a frontal view), will the depth distilled saliency/non-saliency signal remain helpful to the pseudo-labels? My concerns come from the observation that D_{Sal} & D_{NonSal} looks similar to the depth map, so when there is a long object with a wide range of depth, the value among the object area in the D_{Sal} won't be uniform; further, if we element-wise multiply such map with the Sal_{pred} in the DLU, will it just make the result even worse?\n\n3. Does error propagation exist in your proposed iterative optimization scheme? What if the depth disentangled saliency signal becomes unreliable, and the iterative optimization scheme guides the network to learn in the wrong direction?   \n\n4. When comparing with the handcrafted UnSOD in Table1, do you retrain those methods on your training data to ensure a fair comparison?\n\n5. Inside ATS, given ten epochs, what epoch use step one, and what epoch use step two? Also, is there any stop mechanism besides the current heuristic one?\n\n6. The idea of utilizing the handcrafted saliency method as unsupervised training data and using auxiliary information to refine such training data for the more trustworthy signal is also presented in the following papers:\n(1) \"Deep co-saliency detection via stacked autoencoder-enabled fusion and self-trained cnns.\"\n(2)\"Unsupervised CNN-based co-saliency detection with graphical optimization.\" \nHowever, the difference separating with them is not discussed in the paper.",
            "summary_of_the_review": "Overall, I think it is currently a borderline paper since the idea is good, which can benefit researchers in related fields. Meanwhile, this work is presented well, and the experiments are comprehensive. However, I hope to check the answer to my questions before making further judgments.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper presents an unsupervised method for RGBD SOD. It internally generates pseudo labels for training by extracting and refining/updating handcrafted features under the framework of ‘depth-disentangling’. Since the updating module can be removed during the inference, it achieves high efficiency.  The method also demonstrates SOTA performance on several benchmarks. ",
            "main_review": "Strengths:\n\n1. The idea of decomposing depth cues into saliency-guided depth and non-saliency-guided is novel and makes a good sense, leading to the proposed network architecture and the design of the training loss.\n2. The evaluation is extensive and well designed ablation studies are provided.\n3. The paper is well organised.\n\nWeaknesses:\n\n1. The core issue is whether the work is an 'unsupervised' method or not given that this is an important claim made in the paper. In my opinion, this work is essentially a weakly supervised method for RGB SOD where the depth information is used as additional knowledge to improve the intial labels generated by the handcrafted method. I also notice that in Table 1, the proposed method is compared with USD and DeepUSPS, which are both unsupervised RGB SOD methods without any involvement of depth information. To this end, the comparison is barely fair as it is well-known that depth information can significantly improve SOD for the methods based only on RGB information.\n\n2. It is stated at the end of Section 3.2 that in the inference stage, \"only RGB images are used for predicting saliency\". I wonder if the learned mechanism which uses the depth information to refine the RGB-based pesudo label is generalised well on the images not from the same dataset. It might be worthy evaluating the method by training the DSU network on one dataset and then testing it on another one.\n\n3. Despite that the DSU network, particularly the depth-disentangling scheme, offers an effective way to exploit depth information for the improvement of RGB SOD, there is a lack of insightful analysis for the thorough understanding of the scheme. For instance, if we extend the \"saliency-guided and non-saliendy-guided\" binary taxonomy to a ternary one, would the DSU network performs better? Note that this won't slow down the detection in the inference. ",
            "summary_of_the_review": "Based on the strengths and weaknesses listed above, I am slightly negative to the paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposed an effective framework for the unsupervised RGB-D saliency detection task.\nThe proposed framework consists of two key components. One is the depth-disentangled saliency update framework that is iteratively refined & update the pseudo-labels. The other one is an attentive training strategy that alleviates the influence of noisy pseudo-labels.\nThe two components mainly tackle the important issues of deep unsupervised RGB-D saliency detection; accurate psuedo-label generation and noisy pseudo-label handling.\nBased on the proposed components, the proposed framework achieves state-of-the-art results.\n",
            "main_review": "Overall, the paper is well written and easy to understand.\nThis paper pointed out the two important issues of unsupervised RGB-D saliency detection; accurate pseudo-label generation and noisy label handling method.\nThe paper proposed an effective framework to solve the issues and the proposed method consists of two main components; Depth-disentangled Saliency Update (DSU) framework and Attentive training strategy (ATS).\nDSU framework generates and refines accurate pseudo-label by utilizing depth map disentanglement and iterative label refinement.\nThe depth map disentanglement and iterative label refinement complementarily improve each other's quality.\nATS reduces the influence of ambiguous pseudo-label and concentrates on the more reliable training examples by adaptive reweighting strategy.\nThe contributions of the proposed method are novel. The experimental results including qualitative and quantitative results are impressive.\nThe extensive ablation study and detailed analysis support the proposed method's effectiveness.\n\n[Minor issue]\n1. The description of \"Backbone\" in the legend of figure 4 is not described in sec 3.3 Attentive training strategy. \nIt seems the \"backbone\" is identical with the \"backbone\" of sec 4.3 Analysis of the empirical result.\nI recommend the author to add a description or point another description.\n",
            "summary_of_the_review": "This paper clearly states the problems of unsupervised RGB-D saliency detection and proposed appropriate solutions.\nThe contribution and novelty are clear. Extensive ablation studiesy reveal the effectiveness of its components.\nBased on proposed solutions, the proposed network achieves state-of-the-art results.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}