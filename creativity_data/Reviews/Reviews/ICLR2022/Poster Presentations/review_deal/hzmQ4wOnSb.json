{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes a graph soft counter (GSC) model which is very simple and lightweight  compared to the conventional graph neural network for solving QA tasks that benefit from knowledge graphs. Compared to the conventional KG-GNN combination, the proposed method is much simpler but produces better results for QA tasks. The paper originally dealt only with multiple-choice QA tasks, but during the rebuttal process, the authors added more complex QA tasks which the reviewers appreciated. Additionally, there was (and still remains) some concern over the exact reasons and mechanisms behind this \"too good to be true\" result, and the authors addressed this with additional ablation studies, to be included in the appendix. With the publicly released code, others will be able to try GSC and its too-good-to-be-true performance and figure out how it actually works."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper investigates several state-of-the-art GNN modules and finds that they are over-complicated: the initial node embeddings are dispensable and some layers are over-parameterized. Based on these observations, the paper designs Graph Soft Counter (GSC), a simple graph neural model which basically serves as a counter over the knowledge graph. Although GSC has less than 1% trainable parameters compared to existing GNN modules for QA, it outperforms state-of-the-art GNN counterparts on CommonsenseQA and OpenBookQA, two popular QA benchmark datasets which heavily rely on knowledge-aware reasoning. These experiments reveal that counting plays a basic and crucial role in reasoning and existing knowledge-aware GNN modules may only carry out some simple reasoning such as counting.",
            "main_review": "Strengths:\n1.\tThe analysis of existing GNN modules is interesting. The insights on dissection are novel and significant for building better reasoning modules.\n2.\tThe proposed Graph Soft Counter (GSC) is simple but efficient and interpretable, achieving impressive QA performance on two popular benchmarks.\n3.\tThe ablation study in Table 8 is helpful, which shows that even a simple hard counting model can achieve QA performance comparable to state-of-the-art GNN-based methods. \n\nWeaknesses:\n1.\tThe definition of multiple-choice question answering and some terms used in related work are not briefly introduced,  making it difficult to accurately understand some of the content. For example, “answer choice a \\in C” in Section 2.1 is sudden, “relevance score” that “measure the quality of a path and prune the sub-graph”  in Section 2.1 is incomprehensible, “sparse ratio” in Section 2 is counterintuitive (intuitively, the higher sparse ratio means more weights to zero and a part of the model is less important), and “Vh” and “Vx” in Figure 7 are unknown.\n2.\tIn Algorithm 1, the PyTorch-style code may be hard to read for some people, and the variable “inputs” is not stated.\n3.\tThe statement “Our GSC do not use node embedding” in Table 2 is not rigorous. Because node values can be viewed as 1-dimensional node embeddings, and the variable “node_emb” in Algorithm 1 reflects this view.\n\nQuestions:\n1.\tWhy is the input dimension of edge encoder 47? It is inconsistent with the description (2*4+38=46) that follows.\n2.\tIn GSC, why initialize node values to 0 and scale edge values in the range of (0, 1)? Any intuitive explanation？\n3.\tThe two datasets for the experiment mainly rely on common sense, and the complexity of reasoning is relatively low. Do the observations and hypotheses in the paper apply to other complex reasoning (e.g. multi-hop) QA datasets?\n",
            "summary_of_the_review": "The observations are novel, the proposed model is simple but efficient, and the experimental results are impressive. However, the description of some preliminaries and implementation details is not clear enough.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "For several knowledge intensive tasks such as question answering, it is common to use a mixture of language models (that encode knowledge implicitly in its parameters) with a graph neural network based model that can encode external knowledge from an knowledge graph (KG). This paper does an analysis of such GNN based QA models that do message passing over an external knowledge graph (KG) to gather external knowledge required to answer a question. They use sparse variational dropout to diagnose the contributions of various parts of the model and find that current GNN modules are over-complicated and over parameterized. Building upon their analysis, they design a simple 1-dimensional neural counter model that counts nodes/edges in the graph and find that they outperform existing complicated GNN architectures, suggesting that those complex architectures might just be performing some simple count-based operations.\n\nIn the design of their simple model they were able to remove all of the dense node embedding layer, represent edges as simple sparse vectors and messages were reduced to single numbers, thus achieving massing improvements in storage and efficiency.",
            "main_review": "Strengths:\n\n- The paper is clearly written and easy to understand\n- The analysis of the results done is exhaustive and insightful\n- They get decent improvements in two multiple choice QA dataset, however it is currently unclear how their method will work for non multiple choice datasets.\n\nWeaknesses /Questions for the authors\n\n- The model seems to be designed specifically for multiple choice questions. A context node, all question entities and answer entities connected to them. Moreover the score from the graph is read off from a single node (which I believe is the context node? Line 6 of Algorithm 1). Would the same simple neural counter work for problems where answer choices are not available, for example graph classification problems? I think the paper will benefit a lot if this method is shown to be effective for a dataset which does not have multiple choice questions.\n- The context node has all incoming edges and the mechanism in which the neural counter work all the weights of each edge will be added to the context node? Is there a correlation between how dense the context node is for a question and answer choice? For example, how does a simple baseline which predicts an option based on the number of incoming edges in the context node work?\n- The output of the edge encoder (47 X 32 X 1) converts the edge into a scalar message which is essentially passed around. That part of the network does not take into account any representation of the given question. I am unsure why that is the case. Arent the edge weights supposed to be learn wrt the question. But where is the question involved in this? Is it only in the subgraph creation process. i.e. the subgraph of each question is created wrt the question and that is usually enough to learn meaningful edge weights?\n- In Fig4, the node in the bottom right has a value of 0.3 at the start. However, if I understand correctly, nodes receive score only from incoming edges and nodes are initialzied with zero values. Then how does that node have a non-zero score at any iteration?\n- In algorithm 1, is the qa_context generated for each question answer pair? If so, how does this generalize to a setting when the answer options are not available at all?\n- In figure 6, why is the personality node missing from the graph in the right hand side? The personality node is gotten as a part of the question entity and hence should be common for all graphs\n- Minor: The edge embedding is said to be 47. However, each edge is represented as [u_s, e_{st}, u_t], which makes it 2 * 4 + 38 = 46. Can you tell me where did I miss 1 dimension?",
            "summary_of_the_review": "The paper is definitely very interesting and is fun to read. I think it would benefit from experiments on datasets which are not multiple-choice. \nAlso, there are applications where the learned entity representations from GNNs are used for downstream tasks. Since this method is advocating for removing node embeddings, there should be a discussion added on how to handle those situations (Note: I personally think removing entity representations is a good idea as it has lot of advantages such as generalizing to new entities etc, but for completeness, I think a discussion regarding the same should be added)\n\n======Update 11/26======\nMost of my concerns have been addressed through the author rebuttal and I am changing my score to accept.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In recent times, there has been a proliferation of QA systems that combine pre-trained Language Models (LMs) with Graph Neural Networks (GNNs) to solve QA tasks requiring human-like reasoning. The pre-trained language models facilitate access to the large knowledge which is implicitly coded into their parameters. On the other hand, GNN kind of performs reasoning over the explicit knowledge available in the form of KGs. Such systems have shown a significant performance improvement. The aim of this paper is to revisit these QA systems. The motivation behind this study is as follows. The paper starts with the premise that today’s QA systems have become more and more complicated and I fully agree with it. Therefore, this paper wants to revisit those systems and ask several basic questions: Whether GNN-based modules are under or over-complicated for QA?, What is the essential role they play in reasoning over knowledge? etc. \n\nTo answer these questions, this paper first analyzes SOTA GNN modules for QA and their reasoning capability. Further, this paper utilizes this analysis to design a simple yet effective graph-based neural counter that achieves improved QA performance on CommonsenseQA and OpenBookQA, two popular QA benchmark datasets which heavily rely on knowledge-aware reasoning. \n\nThese existing (LM + GNN) based approaches for QA systems follow a two-step paradigm: 1) schema graph grounding and 2) graph modeling for inference. In Step 1, a sub-graph of KG is retrieved that is related to the QA context and grounded on concepts. This graph is called a schema graph. In Step 2, graph modeling is carried out via an elaborately designed GNN module. This paper essentially analyzes SOTA GNN modules employed in Step 2 and their reasoning capability. For such an analysis, this paper employs SparseVD as a diagnostic tool. Using this tool, this paper finds that existing GNN modules used in QA systems are over-complicated for what they can accomplish in the QA reasoning process. This paper’s analysis reveals that knowledge-aware GNN modules may only carry out some simple reasoning such as counting and that counting of edges in the graph alone plays a crucial role in knowledge-aware reasoning. Based on these findings, this paper shows that even a simple counting model can achieve QA performance comparable to state-of-the-art GNN-based methods. Based on these insights, this paper proposes a Graph Soft Counter(GSC) which is a simple yet effective neural module as the replacement for existing complex GNN modules. The paper shows that with less than 1% trainable parameters compared to existing GNN modules for QA, the GSC module outperforms those complex GNN modules on two benchmark QA datasets. The hidden dimension of GSC layers is only 1, thus each edge/node only has a single number as the hidden embedding for graph-based aggregation. GSC is also claimed to be interpretable because the aggregation of 1-dimensional embedding can be viewed as soft counting of edge/node in graphs. \n",
            "main_review": "Strengths\n- Interesting study about overly complex QA solutions that have emerged in recent times and hold the crown of being SOTA.\n- A simple alternative to the complex GNN module for the QA systems which even beats the SOTA numbers in two benchmark datasets.\n\nWeakness\n-  The solution seems to be too good for the simplicity and the performance that it offers. It is hard to believe that such a simple model works so well. There ought to be better explanation/reasoning for one to convincingly accept the empirical findings of the paper about existing GNN. \n- Not much novelty in the proposed solution.\n- Writing can be improved to some extent.\n- Few other concerns which I have stated below.\n\nMain Review\n- Overall, I liked the goal of the paper and line of attack. However, I am still not fully convinced with their finding that existing GNNs mostly do counting of edges, and counting the edges in the graph alone plays a crucial role in knowledge-aware reasoning. \n\n- I am also not fully clear about the diagnostic tool called SparseVD. To make the paper self-contained, it's important to elaborate a bit more on SparseVD. \n\n- Using SparseVD this paper finds that these GNN modules are over-parameterized: some layers in GNN can be pruned to a very low sparse ratio, and the initial node embeddings are dispensable. I agree with this finding but how does this imply that GNN modules are merely counting edges in the KG? This part is unclear to me. Especially, in Section 2.3, the paper looks at the plot of the sparse ratio of some representative layers during the SparseVD training of GNN reasoning modules. Based on these observations alone, the paper seems to conclude that GNN modules are merely counting edges in the KG? This seems to be purely an experiment-based hypothesis but I fail to grasp the underlying intuition. \n\n- Moreover, this appears to be a somewhat straightforward application of SparseVD and the core novelty seems to be lacking.\n\n- The description of the \"Relevance Score\" in Section 2.1 is quite unclear and confusing. A bit of rewriting is required here to bring out clarity. Particularly, the precise definition of the \"context\" here, and how it is retrieved by the masked LM. \n\n- In Table 1 column titles, what is the meaning of “IH..”?",
            "summary_of_the_review": "See my main review.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper designs a new GNN+LM model to do question answering and commonsense reasoning over knowledge graphs. The authors propose graph soft counter, a surprisingly simple and effective GNN module that counts edge mentions over the extracted subgraph for a question-answer pair. It has less than 1% trainable parameters compared with state-of-the-art GNN+LM models. \n\n",
            "main_review": "I feel this is a great paper that is somewhat \"too good to be true\". The proposed GSC achieves better performance than UnifiedQA on the OpenbookQA dataset but using 1/30 number of parameters (actually is this accurate? find the detailed comments below). The authors also perform several analysis on the proposed GSC, e.g., the number of parameters, ablation of GSC and so on. \n\nMy main question and concern is how/why GSC achieves such high performance with a somehow “disentangled” GNN+LM framework. By “disentangled”, I mean that the final qa_score is a sum of context_score (from LM) and graph_score (from GNN and KG). But it seems that the two terms have no interaction at all in GSC before the summation, especially for the calculation of graph_score. Besides the small number of parameters, I think this is the biggest difference between the paper and prior works such as QAGNN. QAGNN initializes the node embedding of the Context node as the Roberta embedding, and after several rounds of GNN and message passing, the information in the Roberta embedding is propagated to other nodes from the KG subgraph. However, in this work the graph_score is only calculated using the KG subgraph. Then the GSC will perform exactly the same with Roberta in theory under the following circumstances. Consider two different questions but with the same entities and same four answer candidates. Although the Roberta embedding of the question context will be different, the KG subgraph will be the same or really similar. Then the graph_score will also be similar. GSC will rely on context_score to really differentiate the reasoning process of the two questions. One such example being a question and its version with negation added. \n\nSince the proposed GNN model is super simple (less than 10 lines as shown in Algorithm 1), I would strongly suggest the author open source their implementation during the review process and also for broader use of the method later.\n\n- caption in table 2, remove “is” from “which makes our model size is extremely small”\n- caption in table 7, are you sure unifiedQA and T5 are only 30x and 8x larger than your model? I feel these models are even larger.\n- What is the difference between Learnable Param and Model size in Table 2? Why does GSC have the same param and model size?\n- Figure 5 is interesting, it seems that even for a simple model like GSC, different random seeds still have a decent effect and the results still have around 8%-9% variance. Can the author explain the reason behind this?\n- Is conceptnet the only knowledge graph the paper experimented with? I think it would make the paper much more impactful if the author can show that GSC works on another QA dataset and knowledge graph.\n- Can it go beyond multiple choice question answering and find the answers over all the nodes on the KG?\n- Can you give a detailed description on MLP+Counter in Table 8?\n- Can you compare GSC with prior works on structured reasoning, e.g., negation?\n",
            "summary_of_the_review": "I am currently a little concerned about why the method achieves such high performance, but I would definitely increase my score after my concern/questions are addressed.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}