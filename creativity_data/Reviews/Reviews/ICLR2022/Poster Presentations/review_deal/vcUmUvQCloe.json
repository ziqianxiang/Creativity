{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The reviewers think the topic is important and challenging. The results are novel, and the experimental section provides a nice illustration how the joint Shapley values can be used. However, the paper can be improved by including more real world applications and experiments."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This work introduces \"joint Shapley values\", which directly extend Shapley’s axioms and intuitions: joint Shapley values measure a set of features’ average effect on a model’s prediction. This work naturally extends Shapley's axioms from a single feature, to sets of features. In a nutshell: joint Shapley values measure the average marginal contribution of a set of features to a model’s predictions. This work presents rigorous mathematical results for the joint Shapley values approach. This approach is then evaluated on several datasets, including: (i) simulated data, (ii) Boston Housing data, (iii) Movie Review data.",
            "main_review": "Strengths:\n- The code looks quite good. Has walkthroughs, examples, etc. Implementation looks clean.\n\n- The theoretical results look clean, intuitive, and well-presented.\n\n- The work inlcudes some discussions on practical questions, including the employed hardware resources, and algorithm complexity estimates\n\n- The work gives an overview of a good set of other SOTA approaches for Shapley\n\n\n\n\nWeaknesses/Considerations:\n- For XAI-based approaches, it is very important to consider their practical advantages, ease-of-use, and intuitiveness. Whilst this work gives a good treatment of the mathematical properties of the proposed approach (and related approaches), these properties are not necessarily tied to practical advantages. For example, emphasis is placed on the fact that \"interaction indices are computed with discrete derivatives\" (page 1), and yet, it is non-obvious what this implies from a practical standpoint.\n\n- Furthermore, it feels as if this work is lacking a general summary of how to apply this approach for gaining insights on model behaviour. Currently, evaluation is done by running the approach on several values of \"k\", comparing the different outcomes, and tying it to properties, such as \"negation effects\". However, such an approach feels quite manually-intensive, involving significant efforts of post-hoc interpretation of the results. This will especially be the case with a larger number of features, and larger values of \"k\". Including a short description of how to apply this proposed approach in order to gain insights from a model with minimal manual effort involved would be helpful.\n\n- Whilst this work lists numerous related SOTA approaches to feature importance (and Shapley values in particular), a comparison is only made on the toy benchmark datasets. Giving concrete examples of the differences in explanations provided by these approaches on the more complex cases (e.g. Boston Housing), would provide a much clearer view of their relative strengths and weaknesses. At the very least, a justification for why such a comparison is impossible would be helpful.\n\n- There are quite a few explanation properties introduced in the Applications section, such as the \"negation effect\", or the \"cancellation effect\". If this is novel terminology introduced in this work, it would be helpful to discuss this earlier on in the methodology section (or in the appendices). If these properties are based on prior work - it would be helpful to include references. If not - giving more intuition on these properties (perhaps with more illustrative toy examples) would help.\n\n\n\nOther Remarks:\n- \"evaluating it at a reference or baseline feature\" (page 1) - I think there's a typo in that sentence\n\n- The Introduction section is essentially merged with the Related Work section, making it a little hard to follow. I suggest splitting this into two separate sections for clarity.\n\n- Is there any particular reason for why the \"Applications\" section is not called \"Experiments\"?\n\n- Table 2: not sure if so many decimal places are required. Removing some of them could make the table more compact, and improve readability.\n",
            "summary_of_the_review": "The potential impact of this work is not clear as not enough is said about practical advantages.\n\nGaining some insights into the model behaviour would make the content of the paper stronger.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces joint Shapley values, which extend Shapley values to measure contributions of *sets*.\n",
            "main_review": "I agree with the theoretical significance of this work, which generalizes the Shapley value for assigning a contribution of *a set of agents*.\n\nHere are some comments:\n\n1. In practice, how can we choose k? It would be great if the authors could provide some rules. \n\n2. In the simulation, what is the explicit form of the set function? For example, in Table 2, even if there is an explicit form of a function f, it's nontrivial to derive the corresponding set function. \n\n3. Continuing from 2, I recommend adding discussion on the choice of the set function.\n\n\n\n\n\n",
            "summary_of_the_review": "- I agree with the theoretical significance of this work. \n\n- A few questions/comments on the perspective of practitioners are listed above. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes an extension of the Shapley values, namely, the joint Shapley values which measure a set of features' average effect of a models prediction. The uniqueness of the joint Shapley values is proved. Moreover, training details and tuning parameters are provided in the accompanying code.",
            "main_review": "Strengths. The paper is well written and the findings are well explained. The experimental section illustrates that the newly introduced joint Shapley values lead to reasonable results in real applications. Some examples of the joint Shapley values are provided in Table 5 to clarify the obtained results.  \n\nWeaknesses. The method is computationally heavy (but it is not easy to do it less computationally expensive). Indeed, the sampling can be done more efficiently, however, it is difficult to criticise this point much, since the authors mentioned it as their future work.\n",
            "summary_of_the_review": "The topic is important and challenging. The results are novel, and the experimental section provides a nice illustration how the joint Shapley values can be used.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}