{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper was seen positively by all reviewers. The strength of the paper are:\n- Intuitive and interesting combination of Koopman Operators and Optimal Control for Reinforcement Learning\n- Convincing experiments on challenging benchmark tasks\n- All of the issues of the reviewers (advantages to SAC, gaps in the theory and missing references) have been properly addressed in the rebuttal.\n\nI therefore recommend acceptance of the paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, authors propose  \"Deep Stochastic Koopman Operator\" which can handle uncertainties in the system dynamics. The authors demonstrate that their approach can produce state loss similar to large capacity MLPs, yet maintains the linear structure in the projected space that is suitable to use linear MPC control methods such as LQR. The proposed method can achieve best tracking performance compared with previous non-stochastic version and SAC trained policies.\n",
            "main_review": "The main strengths of the paper:\n\n(1) Extends the Deep-DMD work by allowing uncertainties in the system dynamics.\n(2) By projecting the system dynamics to linear spaces, one can explore existing optimal control methods such as LQR for linear systems.\n(3) Achieve good control results (i.e. lowest tracking error or and in general more stable) in standard benchmarks. \n\nThe  main  weaknesses of the paper includes:\n\n(1) Can use more experiments to show a more convincing picture. \n\n(2) Compared with SAC, the proposed method does not show a clear edge in many cases. \n\n(3) Explanation of how the Perron-Frobenius operator evolves the system distribution is not entirely clear, i.e. why $f^{-1}(A)$ ?\n\n(4) How does equation 3 change the training process compared with the DKO baseline? I assume it has to do with the expected distribution $E_D$ in equation 4 and 5? Please clarify, and also draw the similarity/difference with DKO side by side. \n\n(5) Is multi-step loss also included in DKO training? If not, I don’t think it is a fair comparison. Please clarify. \n\n",
            "summary_of_the_review": "The authors proposed a novel method that allows Deep Koopman Operators to handle noisy systems, and demonstrate that their approach beats various baselines. However, there are not enough experiment varieties, and the results are close to the SAC baseline (not by large margin).\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper leverage the Koopman operator theory to represent a nonlinear dynamics as a high dimensional linear dynamics. The map from the state space to the high-dimensional space as well as the Koopman Matrix (linear transition matrix) are learned from data. Similar ideas has been explored in existing works. The contribution of this work is bringing stochasticity into the learning of Koopman models. The paper assumes the data are noisy and try to uncover a Koopman model with noisy data. Another contribution is the joint learning of a control matrix in the Koopman setting and a robust control framework for the proposed method. The proposed robust control framework is based on model predictive control and is provably stable (thanks to the linear transition of the observables). The proposed method is tested on rigid body systems (CartPole and HalfCheetah), a soft robotic arm (SoPrA) and cell biology (GRN). The proposed method outperform existing Koopman-based method (DKO) and RL method (SAC).",
            "main_review": "The learning and control of dynamical system from noisy data is not new, but this paper brings a novel angle into solving this problem - stochastic Koopman operator. The learning of the Koopman model and the proposed robust control provides a strong approach in terms of learning accuracy and reliabilily of controller. The proposed approach outperforms existing models and opens up a new perspective for the important problem of learning and control for dynamical systems. \n\n",
            "summary_of_the_review": "Although the building blocks of this paper are not new, the paper leverage these ideas and empirically shows the advantage of the proposed framework. I recommend acceptance of this paper. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper exploits the duality between the Perron-Frobenius and Koopman operators to formulate a Deep Stochastic Koopman Operator (DeSKO) to control an unknown system.  In particular, in contrast to prior work in this space that assumes a deterministic system, the paper proposes to learn a distribution over observables (encoded via a probabilistic neural network) and linear dynamics that propagate this distribution forward.  Theoretically, it is shown that under certain assumptions, a model-predictive-controller (MPC) consisting of a nominal policy and a stabilizing feedback gain around the nominal trajectory can guarantee robust stability.  Empirically, extensive experiments are conducted across 8 (4 nominal + 4 perturbed) environments, showing that the proposed approach leads to favorable prediction error (Fig. 2), control performance (Fig.3), and robustness (Fig. 4) when compared to other Koopman and Model-Free RL algorithms.  Further an ablation study on the effect of an entropy constraint that is introduced is also performed (Fig. 5).",
            "main_review": "Strengths\n\n+ The proposed method is elegant and intuitive, and the resulting algorithm practical and easy to implement.\n\n+ The empirical evaluations are extensive and convincing, with the method performing favorably against strong baselines.\n\n+ The paper is well written and very clear\n\nWeaknesses\n\n- The theoretical results implicitly assume that the learned Koopman embedding (encoded in equation (6)) is exact in the absence of noise across the entire state-space.  This is easily seen by setting $w_t=0$ in equation (10).  Of course, this is never the case in practice, as only prediction error bounds on the parameters $(A,B)$ can be obtained, and these are distribution dependent: i.e., once we switch from the exploratory policy used to identify the parameters (such as random noise, as was used in the experiments) to the closed-loop control policy, we have no guarantees that equations (6) and (10) are valid.  This is one of the main challenges that imitation and reinforcement learning must deal with both practically and theoretically.  Therefore while the main theory result is correct, it is only correct under impractical assumptions and implies nothing about stability of the actual closed-loop system.  Further, the assumption that the lifted system can be written to be linear in the control input (i.e., that the control input enters as $Bu_k$ oin equation (1)) is also very strong, and not supported by the theory, see for example, section 3.2.2 of \n@article{korda2018linear,\n  title={Linear predictors for nonlinear dynamical systems: Koopman operator meets model predictive control},\n  author={Korda, Milan and Mezi{\\'c}, Igor},\n  journal={Automatica},\n  volume={93},\n  pages={149--160},\n  year={2018},\n  publisher={Elsevier}\n}\n\n",
            "summary_of_the_review": "If the issues with the theoretical statements are adequately addressed, I find this to be a nice paper with convincing empirical results.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces a new control framework that is based on Koopman theory. A key advantage of the proposed approach is the guaranteed stability, yielding a robust closed-loop controller. The method is evaluated on several challenging control benchmarks, and it is compared to several state-of-the-art approaches. The results highlight the advantages of the approach. In particular, in the setting of large external disurbances, the proposed method achieves the best results. ",
            "main_review": "This work presents a new and elegant approach to modeling uncertainty in data-driven dynamical systems methods. The proposed method is simple and easy to code, yet it achieves impressive results on challenging benchmark control tasks. The guaranteed stability is a nice addition to this framework, which further facilitates the design and application of this approach to new tasks. The extensive evaluation of the approach shows its features in comparison to other methods, and independently. Finally, the versailty of framework and its simplicity opens up new possibilities for future research as partially listed by the authors in the discssion section.\n\nMy main concern regarding this work is the somewhat not detailed discussion of related work. Specifically, the following references are missing and should be added:\n\n1. \"Learning Koopman invariant subspaces for dynamic mode decomposition\", Takeishi et al. 2017\n2. \"Physics-informed probabilistic learning of linear embeddings of nonlinear dynamics with guaranteed stability\", Pan et al. 2020\n3. \"Forecasting Sequential Data Using Consistent Koopman Autoencoders\", Azencot et al. 2020\n\nMoreover, I would like to better understand the differences of the current approach with respect to Morton et al. 2019, and Pan et al. 2020. The former work considers distribution of observables, whereas the latter work has stability guarantees. Similarly, the Azencot et al. 2020 work shows several examples with sensor noise, and they also discuss empirical stability.\n\n\nminor comments:\n\t- The reference noa 2016 in Sec. 2 seems to be wrong.\n\t- Please specify the domain and range of A and B in Eq. (1)\n\t- Why $\\mathcal{K}$ is separable in the dynamics and control?\n\t- I believe you should change $L_\\infty$ to $L_2$ below Eq. (3)\n\t- I would move Sec. 3.1 & 3.2 to the appendix. \n\t- The contribution of the Perron-Frobenius to this work is unclear. Please elaborate.\n\t- The subscript/superscript notation in Eq. (5) is inconsistent with Sec. 3.1\n\t- The Figs. 2, 4 & 5, and possibly 3 should use a log-scale on the y-axis.\n\t- Why SAC is not in Fig. 2? Similarly, why MLP is not in Figs. 3 & 4?\n",
            "summary_of_the_review": "This paper presents an elegant solution to the modeling of uncertainty in dynamical systems for the puprpose of designing closed-loop controllers. The model is backed by control theory and has a guaranteed stability. The method is evaluated on several tasks showing its properties.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}