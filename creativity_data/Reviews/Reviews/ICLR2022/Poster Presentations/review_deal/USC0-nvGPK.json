{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes a new approach to graph-based active learning, using the query whether the predictions made by the current model are correct or not.\nAlthough the theoretical underpinnings of the proposed approach are a bit weak, the problem formulation that is newly proposed in this paper makes sense from a practical point of view, and the paper makes a simple and interesting proposal that would be worth sharing with the community."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a new method active learning (AL) on graphs. Unlike other AL approaches, the proposed approach provides soft labels via *relaxed queries* to the *domain experts*. \n\n\n\nMain Contributions: \n\n1). The paper proposes a new innovative approach for graph active learning with soft labels. The key idea is to ask a human regarding whether the model prediction is correct or not (a binary classification task) as opposed to asking them the correct \"hard label\" of the node. The incorrect model predictions are also not \"thrown away\" and used as indirect supervision by performing a soft-max over the remaining classes. This leads to a new criteria for active learning, called \"maximizing information gain propagation\" as opposed to maximizing entropy as done by standard AL.\n\n\n2). Results are shown on a variety of real-world datasets which show the superior performance of the proposed method in achieving higher test accuracy with a certain labeling budget.",
            "main_review": "Originality & Quality: The paper is well written and puts itself nicely in context of previous work. The overall presentation of the paper is good except a couple typos. The proposed approach is a novel adaptation of AL to graphs (to the best of my knowledge).\n\n\n\n1). The idea of soft-labeling is intriguing! Though, the example that the paper provides in Section 1 regarding arXiv subject categories is misleading. The paper argues that a node may belong to more than one categories, e.g., mathematical finance and computational finance and that is hard for a human labeler to classify. However, it is unclear how the proposed approach solves that problem since the approach still relies on a model to make the label prediction, e.g., mathematical finance in the case above and then the human accepts it. So, we still have the same problem that the example was provided to get rid of. This is so because the example of arXiv classification is more of a multi-label classification problem and hence not a good example to motivate this paper in my opinion. \n\n\n\n2). It will be interesting to see the model accuracies as a function of the number of classes. If the humans doesn't agree with the model, the label is discarded and a soft-max is taken over the remaining classes. So it will be interesting to see how this weak labeling by the remaining classes performs when the number of classes is large and hence the prediction problem is hard. \n\n\n\nSignificance: The paper addresses an important problem of active learning on graphs using soft-labels.",
            "summary_of_the_review": "The paper provides an intriguing idea of soft-labeling to improve active learning (AL) on graphs. It seems more efficient than the conventional AL approaches on graphs and is more cost efficient. The results are mostly strong, except it is unclear what is the impact of the number of classes on the output performance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a new GNN-based active learning (AL) method for graph data, under a relaxed query setting where the oracle can only judge the correctness of the predicted labels. A new AL query criterion is proposed to select the nodes that can maximise the information gain propagation (IGP) in local neighbourhood. \n",
            "main_review": "Strengths:\n1. The relaxed query setting is well motivated for AL and it seems to be applicable in real-life scenarios.\n2. The proposed AL criterion takes both information gain and influence magnitude into consideration, which can explicitly maximise the propagation of information gain. \n3. The source code of the paper is released to ensure the reproductivity of results.\n4. Overall, this paper is well-written, though there are some typos in equations and text.\n \nWeakness:\n1. No complexity analysis on the AL query criterion of IGP. As IGP needs to maximise the propagation of information gain in local neighbourhood, it is expected to incur extra computational overhead. \n2. Missing discussion and comparison with recently published GNN-based AL methods, e.g.,\nLi et al. SEAL: Semi-supervised adversarial active learning on attributed graphs, IEEE TNNLS, 32 (7), 3136-3147, 2021. \n\n3. The discussions on related work are respectively given in Section 2.3 and Section 4.4. Would it be better to combine the two sections?\n4. Some symbols used in Eq.(8) are incorrect. e.g., would it be v_i - in the last term? \n",
            "summary_of_the_review": "This paper considers a new AL setting with relaxed queries. Under this setting, a new AL query criterion is proposed to incorporate soft labels and information gain propagation. The setting and idea of this paper are interesting, but there are some concerns, e.g,, the lack of computational analysis of the AL query criterion and comparison to some state-of-the-art GNN-based AL methods. \n\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The submissiom presents a GNN-based AL method using soft-label technique with 2 innovations different from existing works\n1. using relaxed queries and 2. building a new criteria of maximizing IGP for active learner with relaxed queries and soft labels. 3.outperforming SOTAs in performance.",
            "main_review": "1.  The strengths:\n1.1. present using the relaxied queries to replace commonly-used exact labeling strategy for AL, i.e., only judging the correctness of the predicted labels (a binary question) rather than identifying the exact class (a multi-class question), doing so is relatively easier and to be my best knowledge, it seems hardly to be done before.\n1.2. provide a new criteria for active learner with the help of such relaxed queries and soft labels via maximizing defined the IGP. \n1.3. obtain significant performance boost comparing with SOTAs.\nOne the whole, the proposed method can have more flexibility, e.g., being applicable to a large variety of GNN variants.\n2. The  weaknesses:\n2.1 Class-imbalance problem;\n2.2. Due to GNN characteristics, IGP inherits possible oversmoothness problem.\nIn addition, please concern possible relation with \"Two-dimensional active learning for image classification\" availavle at internet.",
            "summary_of_the_review": "In this submission, in my opinion, the authors consider using relaxied queries to replace exact labeling for active learner and define a new criterion with IGP  for learning. Using the relaxied queries indeed provides the oracle a relatively easier labeling andthus more reliable. While Theorem 3.1 gives some insight. The authors provide their codes for REPRODUCIBILITY and the experiments are also relatively sufficiently conducted and compared, the results are convincing! ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I do NOT find so-said concerns.",
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper proposes an active learning method for GNNs that is based on an information gain maximization where ethe information gain is obtained by querying a data point and looking at the influence of the queried node on the neighborhood relative to their previous information.  They also claim the setting of relaxing the oracle answer to be a binary confirmation of the most probable label. Experiments are presented where some advantage is shown for the method.",
            "main_review": "Strong points:\n1.\tThe paper provides a relative new framework for GNNs where the information gain propagation is maximized. \n2.\tThe setting of relaxed queries seems to be facilitative in this case.\n3.\tResults show some advantage over other methods\nWeak points:\n1.\tMotivation: except for the motivation for the relaxed queries, I do not see much motivation and discussion in the paper, especially a discussion around the state of the art in this area and how it related to the proposed method. Based on section 4.4 is the only advantage of IGP over others is the use of relaxed queries? What about the query criteria itself? What are its advantages relative to prior works.\nThere are many other mssign motivation throught the paper for example after the IG definition why is this a good a good tool to use?\nWhy relaxed queries are important, where in real life could this make a difference?\n2.\tPaper organization: is section 2.3 meant to be related work? How is it related to section 4.4 on prior work?\n3.\tTechnical errors:\na.\tequation (8) isn’t that supposed to be v_i – on the last component?\nb.\tEquation (4) the indicator is on I – an index of a node equal l – a class? That is incorrect use of the two different symbols in the indicator function\nc.\tWith respect to what is the entropy in eq (7) computed? What are the probabilities?\n4.\tTheoretical foundations: there is no sample complexity analysis or any optimality analysis for the given criterion. The only theorem provided is a rather trivial one showing that entropy doesn’t coincide with IG selection criterion.\n5.\tClarity:\na.\tUnclear sentences like: “Since the influence magnitude is diverse to the influenced nodes…” what does it mean?\n6.\tExperimental validation: I am left unimpressed by the rate of improvement shown by the proposed algorithm. Moreover, the analysis lacks error bars and standard deviation for the 10 executions.\n",
            "summary_of_the_review": "Strong points:\n1.\tThe paper provides a relative new framework for GNNs where the information gain propagation is maximized. \n2.\tThe setting of relaxed queries seems to be facilitative in this case.\n3.\tResults show some advantage over other methods\nWeak points:\n1.\tMotivation: except for the motivation for the relaxed queries, I do not see much motivation and discussion in the paper, especially a discussion around the state of the art in this area and how it related to the proposed method. Based on section 4.4 is the only advantage of IGP over others is the use of relaxed queries? What about the query criteria itself? What are its advantages relative to prior works.\nThere is lacking motivation throughoutt the paper for example after the IG definition why is this a good a good tool to use?\nWhy relaxed queries are important, where in real life could this make a difference?\n2.\tPaper organization: is section 2.3 meant to be related work? How is it related to section 4.4 on prior work?\n3.\tTechnical errors:\na.\tequation (8) isn’t that supposed to be v_i – on the last component?\nb.\tEquation (4) the indicator is on I – an index of a node equal l – a class? That is incorrect use of the two different symbols in the indicator function\nc.\tWith respect to what is the entropy in eq (7) computed? What are the probabilities?\n4.\tTheoretical foundations: there is no sample complexity analysis or any optimality analysis for the given criterion. The only theorem provided is a rather trivial one showing that entropy doesn’t coincide with IG selection criterion.\n5.\tClarity:\na.\tUnclear sentences like: “Since the influence magnitude is diverse to the influenced nodes…” what does it mean?\n6.\tExperimental validation: I am left unimpressed by the rate of improvement shown by the proposed algorithm. Moreover, the analysis lacks error bars and standard deviation for the 10 executions.\n7.\tThere is not discussion of parameter tuning nor running time of the proposed method.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}