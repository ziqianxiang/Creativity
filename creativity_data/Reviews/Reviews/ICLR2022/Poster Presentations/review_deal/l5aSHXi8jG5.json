{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper explores why adversarial examples do not transfer well in\nadversarial examples on automatic speech recognition systems. The authors\npropose a number of potential causes that are then quickly evaluated in\nturn.\n\nThis could be an excellent paper, but in its current form, it is borderline.\nThe main problem with the paper is that it proposes a number of causes for the\nlimited transferability, and then evaluates each of them with one quick\nexperiment and just a paragraph of text. In particular, none of the results\nactually convince me that the claim is definitely correct, and many of the\nexperimental setups are confusing or would have other explanations other than\nthe one variable that is aiming to be controlled for.\n\nThat said, even with these weaknesses, this paper raises interesting and new\nquestions with an approach I have not seen previosuly. So while I don't believe\nthe paper has done much to actually demystify transferability, it does take\nsteps towards performing scientific experiments to understand why it is so\nhard. And these experiments, while not perfect, can serve as the basis for\nfuture work to extend and understand which factors are most important."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies why optimization-based adversarial attacks have close to zero target transferability in attack real-world ASR pipelines.\nThe paper identifies 6 previously unknown factors that impact target transferability, including the input type, Mel Frequency Cepstral Coefficient (MFCC), the Recurrent Neural Network (RNN), output type, and the vocabulary and sequence sizes. \n",
            "main_review": "This paper studies an important problem and provides valuable insights into the mysterious fact of the very low target transferability between ASR models. The control experiments are carefully executed and provide clear takeaway insights. The paper is also well-written and nicely structured. Below are my comments that can further improve this paper:\n1. The experiments on the input type do not seem very interesting to me. Images are inherently 2-dimensional. Converting them to 1-dimensional naively can destroy the locality. There are more advanced ways to convert and an image to 1D, such as using a Hilbert curve.\n2. The paper only uses the vanilla attack. There have been quite a few papers in the adversarial machine learning literature on improving transferability (e.g., Expectation over Transformation, attacking an ensemble, etc). \n3. This paper only uses a single model, DeepSpeech, which is a character-based model. A word-based model may have different behaviors.\n",
            "summary_of_the_review": "A good paper that studies an important problem with carefully executed control experiments.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents an evaluation and explanation of the limited adversarial transferability in the ASR system. It first lists 11 known factors, e.g., smoothness of gradients, and then proposes four potential factors that limit the transferability. Then it examines the transferability in the DeepSpeech system and found its model is too complex for adversarial transferability. Hence, the author implements 5 ASR systems based on a simple model trained from the Google Speech Commands dataset. It generates 500 adversarial audio samples for each of the five ASRs and tries to transfer samples to others. The evaluation examines the target transferability rate of optimization attacks by one factor at a time. Then it gives some insights into the impact of each of the potential factors.",
            "main_review": "Strengths:\n\n+ The paper is well-written and easy to follow.\n\n+ The paper gives some takeaways about the limited adversarial transferability in ASR systems.\n\n+ The paper does lots of work for the system implementation and testing.\n\n+ The paper gives many details in implementation and evaluation.\n\nWeaknesses & comments:\n- I basically like the ideas and findings presented in this paper. However, I think this paper focuses on the measurement of ASR systems and may be more suitable for a security conference. \n\n- The method of how the authors come up with the factors is not explained. This is the main limitation of the paper. \n\n- The definition of a “factor” is not clear and is not clearly defined in this paper. For example, RNN is a factor. Also, Output Type is a factor, but specifically, Sequential Output is a factor/reason? Same with Input Type, and Output Complexity. Is Vocabulary a factor, or is Complexity a factor? Isn’t the total number of Output Labels factor the same as Output Type factor? So please define what is a factor. Please also see my comment on EFA.\n\n- As a consequence of the above point, don’t you think “model complexity” is also a factor? Maybe even experiment with transferability Vs. increasing model complexity?\n\n- How does “Number of models” simultaneously optimized in Equation 1 affect transferability? Do you think this could improve transferability? (e.g. optimize jointly on 3 models, test on 4th model).\n\n- The ASR pipeline in Section 2.2 should be generalized. For example, call the RNN as “ASR model”, MFCC as “Signal Processing Algorithm” and so on. Also, how did the authors give this particular pipeline as an example? Is it something that they have observed in existing literature?\n\n- I would like to see an EFA analysis on these factors. What are the groupings of these factors?\n\n- The second factor, MFCC, should be generalized. I am not an expert in this field, but I suppose there are more algorithms than just MFCC that do this operation. \n\n- I don’t understand the RNN factor, which is not clear. Is the RNN itself a factor, or any sequence model, such as RNN, LSTM … a factor?\n\n- The current evaluation is not extensive. The paper can benefit from giving a deeper evaluation of these identified factors. For example, what are the detailed impacts of each known factor in the control experiment? What will happen if you change two factors at the same time, e.g., remove MFCC but use a complex RNN? And what is the impact of using RNN with different complexity?\n",
            "summary_of_the_review": "Although this paper looks simple, it has actually identified an interesting, novel problem. I think the authors motivated this paper from a recent SOK paper published at the IEEE S&P'21 conference that has discussed related issues. I appreciate that the authors have done research on such an important topic. I would suggest accepting this paper as a short paper or a poster if possible.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper conducts a systematic study on the phenomenon that attacks targeting ASR systems often have low transferability. To do that, the authors take a representative ASR pipeline and perform ablation studies by modifying or removing the components that may have an effect on the attack transferability. Results show that many existing designs for improving the robustness of ASR can also prevent transfer attacks. Based on the findings, the authors also discuss the takeaways and future directions for the ASR.",
            "main_review": "# Strengths\n- A timely study on an important problem has been highlighted recently.\n- Ablation evaluation methodologies are systematic.\n- The finding on robustness improvement and transferability is interesting.\n\n# Weaknesses\n- Lack of in-depth root causes analysis on the findings. The paper provides some discussion in each ablation study. However, the current discussion does not go beyond describing the observations of the experimental results. For measurement papers, the readers are more interested (and will be more appreciated) if an in-depth analysis on the fundamental reasons why such feature affects the transferability. This is not an easy task, where additional small-scale experiments may also be required as the authors generate hypotheses.\n- The current discussion of the findings is limited to the ASR domain, however, as ASR and image tasks were discovered to have distinctive attack transferability properties, the author may consider drawing connections with the image space. For example, will the similar features also make transferability more difficult in the image tasks? Such analysis also helps to understand the unique challenges in the ASR and perhaps improve the robustness of image task models.",
            "summary_of_the_review": "The paper studies an important problem and presents many interesting findings. However, it still lacks root cause analysis on the findings to indeed “demystify” the low attack transferability in ASR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "It is known that targeted transferability is ineffective against typical ASR\nsystems, but it is not fully understand why.  In this work the authors show the\nimpact of targeted transferability against a simplified ASR system.\nSpecifically, they perform an ablation study to assess which components of an\nASR may be contributing to the non targeted transferability issue.  Their\nresults provide insights into ASR case, which may help against other\ntransferable attack types, and also help in other domains.\n",
            "main_review": "The authors design a simplified ASR system in order to show which components of\nsuch a system are affecting the targeted transferability issue. First, a\nsimplified ASR system is required, as it has yet to be shown that complex\nreal-world ASR systems have 0% targeted transferability.\n\nThe writing is clear, and the design is simple. The results provide some evidence\nas to which components contribute to targeted transferability. \n\nHowever, some of the choices in the modeling and explanations are a little weak in \nsome areas:\n\n1. The model is not fully specified within the text, only mentioned in a reference.\nThe model should be at least briefly summarized. In the least explain how the model\ngoes from frame level output labels to a label (CTC? RNN-T?).\n\n2. The authors discuss vocabulary size, but is this even handled within their model?\nThe model to me appears to only have 9 labels which are synonymous with vocabulary size.\nAlso, since there are no details of the model within the paper, how is the alignment issue handled?\n\n3. What about attacks on the mfcc themselves?\n\n4. Why wasn't there an ablation study on more complex RNN cells (LSTM, GRU). Should have been straightforward \nto run this test.\n\n5. Why is there no ablation study on the effects of dropout?\n\nSmaller points:\n\na. In the description of input types, what is the significance of having topographical input with respect\nto adversarial attacks.\n\nb. In 2.3.4, \" the victim ASR needs to assign the attacker chosen character to each frame of the adversarial audio\", \nbut this is highly dependent on the ASR model. For example in CTC or RNN-T, what excludes the possibility of\nmodifying only a handful of frames in order to affect the output.\n\nc. In 2.3.5 the frame level output for your simplified ASR model is indeed fixed. The output sequence is also\nfixed (albeit large).\n\nd. No reference for Deepspeech.\n",
            "summary_of_the_review": "I believe the authors provide a useful beginning of understanding why ASR systems may be \nnot susceptible to targeted transferability. However, I think a little further work\ncould have been done to improve the results as well as the explanations.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}