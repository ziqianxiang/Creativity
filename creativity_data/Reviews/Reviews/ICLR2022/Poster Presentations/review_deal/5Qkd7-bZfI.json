{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The authors investigate the claim that agents in emergent communication games will converge to a symmetric homogenous state.  In particular, the authors show/argue for diversity in the population to close the gap between observed trends in neural agents and those expected when studying natural languages (e.g. around structure).  Reviewers were generally positive, though requested a number of rhetorical changes needed and additional literature.  These have been addressed."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors refer to prior work in sociolinguistic literature to state that larger communities create more systematic languages. However, they point out, this apparent correlation between language structure and population size has evaded machine learning practitioners studying language emergence. This paper claims that populations explored in machine learning have largely been homogeneous and that population heterogeneity is key to the emergence of structure in artificial agents. The authors reproduce the failure to achieve systematic languages by scaling up the population and then show that they can indeed get more structure by introducing heterogeneity. They explore introducing asymmetry between the speaker and the listener based on model capacity and learning speed, leading to an increase in language structure when the speaker is faster or has more capacity. The authors note that this effect only depends on the relative differences between the speaker and the listener and not the absolute values (there is a correlation with absolute values but the variation has a low magnitude). Further, they show that larger networks need fewer epochs to reach similar training accuracy, concluding that network capacity is a confounding factor of training speed in their setting. Finally, the authors create a population of heterogeneous agents by imbibing them with different learning speeds by updating an agent $i$ with probability $p_i$ after each round of the Lewis game. Four properties of the emergent language are studied: speakers synchronization, (negative) conditional entropy given an object, topographic similarity, and generalization. These metrics either improve or remain approximately at the same values as the population size increases.",
            "main_review": "Strengths:\n- This is a well-written paper with a very engaging flow.\n- This paper provides important insights for language emergence research in machine learning.\n\nWeaknesses:\n- The largest effects of heterogeneity are on speakers synchronization and negative entropy; there is low, no, or negative effect on compositionality and generalization. The paper is overclaiming to say that the emergent language is more structured with heterogeneity when the compositionality and generalization (metrics we arguably care about more) are not significantly affected with increasing population or speaker-listener asymmetry (when $\\rho_\\bullet \\geq 10^0$).\n- The claim that network capacity is a confounding factor of training speed relies on the speed of achieving 95% training accuracy (related: Figure 2 left of [1]). However, is this sufficient to claim that the effect is equivalent in the setting you are studying? How models fit training data and how they generalize to unseen data can have different dynamics. Do these \"equivalent\" models (fast model with high model capacity and slow model with low model capacity) achieve similar values on the four language property metrics in the paper when they get to 95% training accuracy?\n\nOther questions:\n- When you split the data into train and test, did you try splitting them systematically? It would be interesting to evaluate whether the emergent language can generalize OOD.\n- I find this hypothesis interesting: \"extreme agents, especially slow listeners, behave as kinetic bottlenecks, forcing the speakers to structure their languages. Thus, language emergent properties would be particularly determined by fast speakers and/or slow listeners.\" Is there any intuition for why the relative speed differences would have this effect?\n\nSuggestions:\n- In Section 3.4 Control parameters of local asymmetry: Typo: should be $p^S$ instead of $p_S$ in the fifth line of the paragraph.\n- In Section 3.4 Distributing Population Heterogeneity: \"update probability factor\" in the last line is not clear until later in the paper.\n- Figure 3 caption: after \"pretrained with a speaker\", add \"(resp. listener)\"?\n- Section 5.2: Typo: \"statically\" -> \"statistically\".\n\nReferences:  \n[1] Kaplan, J., McCandlish, S., Henighan, T., Brown, T.B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J. and Amodei, D., 2020. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361.",
            "summary_of_the_review": "I believe this is an important paper to encourage future research into heterogeneity as a component for language emergence. The paper is well-written and the authors are able to scale up the Lewis game setting without observing a decline in desirable language properties. However, the paper in its current form makes claims that cannot be substantiated in the evidence, which I find to be a significant barrier for me to recommend acceptance.\n\nUPDATE AFTER REBUTTAL:\n\nAfter the discussion with the authors, the paper has toned down its claims and added clarity about what it does not claim: it does not present an overall better language emergence setup, and the goal is to primarily address the apparent decline in structure as population size goes up in machine learning in contrast to sociolinguistic studies. Thus, I am increasing my score for this paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper analyzes the structure of emergent languages in signaling games played by _populations_ of agents, motivated by a rich body of socio- and psycho-linguistics results showing that languages spoken by more people (and with more second-language learners) tend to be grammatically simpler (e.g. have a more impoverished morphology).  The authors measure various properties of the emergent languages as proxies for how \"systematic\" a language is, and show several things.  First, increasing the number of agents does not correlate with any of their measures, so population size alone does not suffice.  Second, in a minimally small population, various measures of \"diversity\" of the two agents do correlate with their systematicity measures.  Finally, in a large but diverse population, we do see correlations with population size and _some_ of the systematicity measures.  The paper is interesting and timely, and reports on a large number of experiments.  While I think the experiments could be more closely linked to the hypotheses from the sociolingusitic literature, the paper will be of interest to many researchers in emergent communication, NLP, and cognitive science, and could spur future work in this intersection.",
            "main_review": "\n# Summary\n\nThis paper analyzes the structure of emergent languages in signaling games played by _populations_ of agents, motivated by a rich body of socio- and psycho-linguistics results showing that languages spoken by more people (and with more second-language learners) tend to be grammatically simpler (e.g. have a more impoverished morphology).  The authors measure various properties of the emergent languages as proxies for how \"systematic\" a language is, and show several things.  First, increasing the number of agents does not correlate with any of their measures, so population size alone does not suffice.  Second, in a minimally small population, various measures of \"diversity\" of the two agents do correlate with their systematicity measures.  Finally, in a large but diverse population, we do see correlations with population size and _some_ of the systematicity measures.  The paper is interesting and timely, and reports on a large number of experiments.  While I think the experiments could be more closely linked to the hypotheses from the sociolingusitic literature, the paper will be of interest to many researchers in emergent communication, NLP, and cognitive science, and could spur future work in this intersection.\n\n\n* Strengths:\n\t- Thorough and competently executed experiments\n\t- Largest-scale study of the impact of population size on emergent language structure\n\n* Weaknesses:\n\t- The experiments could be motivated more precisely from the cited literature (see comments below)\n\t- Experimental results were not always clearly reported (see comments below)\n\t\n\n\n# Comments / questions:\n\n* The cited Raviv et al studies crucially manipulated not just population size, but also _network structure_ (e.g. scale-free vs complete graphs). While it is completely fine for the present paper to only focus on population size and the homogeneity of the population, I would encourage the authors to at least mention this important extra dimension of the Raviv et al papers.  As presently written, the reader can get the impression that those studies only look at population size.  This could also be re-mentioned in Section 3.2, where the authors helpfully point out some of their modeling assumptions.\n\n* I would also encourage the authors to cite Wray and Grace 2007 \"The consequences of talking to strangers\" (https://www.sciencedirect.com/science/article/pii/S0024384105000999) in their related work section.\n\n* Why did the authors choose the full object-reconstruction loss as opposed to a choose-among-distractors loss (as is slightly more common on the emergent communication literature)?  Did they try the latter and find similar results, or do the results depend on the object-reconstruction setting?\n\n* Was there a reason not to use the (straight-through) Gumbel Softmax trick for training here?\n\n* Presentation of Entropy in \\S3.3: (i) equation (5) is negative entropy, as the authors note at the end of the paragraph.  But the equation is introduced as just being entropy.  I would encourage them to make the definition (e.g. of $h$) include the negative sign, so that it's normal entropy, and then just mention that they report negative.  (ii) I don't know what it means to say that minimizing entropy \"reinforces the information bottleneck principle\", since the latter is about two forms of mutual information.  I'd like to either hear something more explicit/detailed here or have it dropped.\n\n* Reporting results: (i) I would like to see actual numbers and a statistical analysis for e.g. the results in 5.1 / Fig 1, even if in an appendix (as is done in S5.3).  (ii) Similarly, they write: \"In addition, we do not observe any language systematicity. By systematicity, we mean languages whose properties are stable across seeds.\"  It's hard to know what exactly the authors did and are reporting here, so a little more detail would be welcome.  (iii) I think a baseline of randomly-initialized / untrained agents for these metrics would be informative to see.\n\n* p 7: \"language neg-entropy is reaching almost 0, meaning almost a bijective language mapping\".  I might be misunderstanding, but won't your entropy also be minimized by a _uniform_ language, that outputs the same sequence of symbols with probability 1 for every object?  Since the entropy is taken over next-tokens in the sequence in average over each object, I don't see any pressure for distinct messages for distinct objects in that measure, which is what a bijective mapping sounds like to my ear.  In other words: doesn't your measure of entropy just measure how _deterministic_ the mapping from objects to messages is, not necessarily how bijective it is?  I may be misunderstanding, but it would help to clarify if so.\n\n\n# Typographic comments:\n\n* p 3: \"community size and leaning properties\" --> \"community size and learning properties\"\n\n* p 4, eqn (4): \"$m_i \\sim \\pi_{\\theta_1}(\\cdot | v)\": the \"\\theta_1\" here should be \"\\theta_2\"\n\n* Caption on Fig 2: the \"x\" in \"x-axis\" should be in math mode\n\n* page 7: the quotation marks around \"fast enough\" should be fixed to ``fast enough'' (and same for \"ease-of-teaching\")\n\n* page 9: \"actually be to simplistic\" --> \"actually be too simplistic\"",
            "summary_of_the_review": "The paper provides a rich set of experiments looking at the effect of population size and diversity of emergent languages, and so will be of interest to many working at the intersection of emergent communication in NLP and cognitive science.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper aims at solving a conflicting empirical observation and the present-state models for emerging languages. It has been observed that larger populations produce more structured languages. However, the state-of-art neural-based models have not been able to generate languages with such characteristics. This paper shows that a key ingredient is to allow population heterogeneity in the neural models rather than the current identically distributed specifications. ",
            "main_review": "I read with interest this nicely written paper and I think that there is good evidence towards the authors' conjecture. Furthermore, the authors strive to produce some intuitive rationale to explain why heterogeneity leads to more structured language. I have a generally positive view of the work but, as a non-expert, I saw some weaknesses in the paper.      \n\nThe most important objective of the paper is to demonstrate that a larger heterogeneous population leads to higher quality language. I was expecting a large variety of scenarios showing the impact of this heterogeneity. However, a single scenario is considered for the training speed, by sampling p_i from a log-normal(eta, sigma) with eta=-1 and sigma=1/2. These parameters do not lead to large heterogeneity. The distribution of p_i has expectation equal to exp(-1+(0.5^2)/2)=0.42 with variance equal to 0.05. This seems a very concentrated distribution. Given the main objective of this paper, it is interesting to see what is the impact of more dispersed distributions. Maybe not only varying the log-normal parameters to create a large variance but even considering other distributions such as the more natural Beta(a,b) distribution for the parameter p_i (which is a probability). What would be the impact on the increasing trends of neg-entropy and synchronization (see Figure 4) of having larger heterogeneity in the population? \n\nAgain, given that the main objective is to show that larger heterogeneous populations leads to higher quality language, I missed a larger variation on the population size. It increases linearly from N=2 to N=20 (meaning 10 senders and 10 receivers). It is not possible to simulate with much larger populations, with a geometrical increase? We are likely to see a more clear effect if populations change in orders of magnitude. I missed a larger range for his variation. \n\nIn page 8 and wrt Figure 4, the authors say that \"compositionally and generalization have a small positive but statistically significant correlation with Spearman coefficients above 0.3 (p-values> 0:05)\". This is not correct. Appendix C shows that, for generalization in heterogeneous populations, the Spearman correlation index is equal to -0.07, a negative and very low value. It is hard to believe that this low value is statistically significant and, worse yet, it is negative. Indeed, there is not a visually clear presence of a trend with the N increase in the compositionality and generalization plots in Figure 4. \n\nAlso, the statistical test is significant when the p-value is small, traditionally smaller than 0.05. In the excerpt copied above and in several other passages throughout the paper, the authors mention that statistical significance corresponds to having a p-value larger than 0.05. It should be smaller, not larger. \n\n",
            "summary_of_the_review": "I have a generally positive view of the work but, as a non-expert, I saw some weaknesses in the paper.      ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "# Summary \nThe manuscript \"On the role of population heterogeneity in emergent communication\" addresses the question why results on population size in deep language emergence have not, so far, mirrored the effects it is claimed to have on natural language. In a nutshell, in natural communication population size correlates with simpler grammars and less idiosyncratic languages. The effects of population size on the structure of neural emergent communication is less explored and has hitherto not reflected what we know about natural language. The authors argue that one of the reasons for this is that artificial populations are often homogeneous. They show, through simulations, that introducing asymmetries in the training speed of speakers and listeners leads to trends that are more in line with natural language: the size of heterogeneous populations weakly correlates with more aligned languages; higher neg-entropy; better generalization when communicating about novel objects; and more compositional languages (measured as topographic similarity).\n",
            "main_review": "\n# Main assessment \nThis work is interesting and the topic well worth exploring. The contribution to the area of deep language emergence is very clear and timely. That being said, I do have some concerns. First, I think much more care needs to be put in positioning this paper in the literature.  There is a large body of (non-neural) research on the emergence of compositionality, structure, and generalization that emphasizes that a \"transmission bottleneck\" (e.g., agents not having the capacity to fully observe/learn the language of their community) is what makes these properties emerge. After all, that's why these properties are useful in the first place: to overcome agents' limitations when learning/imitating/using language. Similar arguments have been put forward for other properties of natural languages, such as ambiguity and vagueness. The authors' main argument follows the same line of reasoning but does not engage with this literature, nor synthesize what we already learned from it. A good starting point is offered by the literature on iterated learning, some of which the authors cite but for other purposes. Another starting point is given by the research that more closely follows Lewis' original setup (e.g., work by and building on \"Signals\" by Skyrms 2010; or Wagner's \"Communication and Structured Correlation\"). Second, and more importantly still, while I found the narrative of the paper convincing, I also found the main results rather weak. The bars in Figure 4 strongly overlap. This suggests that there is so much variation between runs that the means are not very trustworthy to draw strong conclusions from. The correlations for heterogeneous populations in Appendix C's Table 2 are analogously weak. I worry that noise may be at play; and an unjustified significance threshold of 0.05 does not dispel this concern. \n\n# Minor comments\nThere are some issues with the terminology used. The main issue the paper addresses is not a paradox (p. 1) nor is there a contradiction (p. 5).\n The question why population size predicts\nstructure and complexity in natural language but not in neural language emergence is interesting. However, there is nothing paradoxical or contradictory about it. At most, one may find this puzzling. Similarly \"predictive\" does not need to mean \"causal\" (p. 2) and \"particularly significant\" is a vacuous term (p. 9). This may sound nit-picky but these are all technical term.\n\nI could not quite follow all the details of the equations in Section 3. Part of the reason is that not all symbols are clearly defined.\n For instance, from the text above Equation (1), it's unclear whether T is a set (since its cardinality, |T| is mentioned) or a number (which is what I am led to believe from the formulae that follow, or the text [e.g., p. 5]).\n The equations look reasonable to me but it would be nice if this part of the manuscript was easier to follow.",
            "summary_of_the_review": "This manuscript is on the target. It is interesting and the research is well worth pursuing. However, it has crucial issues that need to be addressed to better appreciate its contributions and scope. In particular, the results do not lend much support to an issue that has already received attention in related (non-neural) research on language emergence.\n\n\n# Recommendation update\n\nIn light of the authors' changes and discussion, I have updated my recommendation. The literature review is much more complete now, and I think weakening some of the statements has made the contribution much clearer. I am still concerned about the rather weak effects and correlations reported, but now the framing is much more in line with the content.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}