{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The reviewers agree that this paper studies an important problem, provides theoretically analysis to understand graph injection attack.\nThe authors propose a new regularizer to improve the attack success. Extensive experimental results also show the effectiveness of the proposed method."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies the problem of adversarial attack in graph neural networks. It aims to improve the unnoticeability of graph injection attack which injects carefully-crafted nodes into the graph data. In detail, it proposes the concept of homophily unnoticeability and studies the power of graph injection attack (GIA). Further, it observes that GIA can be easily defended by homophily defenders and proposes a harmonious adversarial objective to preserve homophily. Extensive experiments have demonstrated the effectiveness of the proposed method under various defenders.",
            "main_review": "It is an interesting research topic to enhance the unnoticeability of graph adversarial attack and bypass various defenders. The proposed attack is straightforward and empirically effective against different defense strategies. The performance proposed method is also impressive under the combination of different defense methods.  However, there exist several concerns:\n\n1. For the analysis on  the comparison between GMA and GIA (Theorem 1), the budgets of these two attacks are totally different and not directly comparable. The budget of GMA is measured by the changes in entries of adjacency matrix and feature matrix while that of GIA is measured by the number of nodes.  If we only consider the number of perturbed nodes, the budget of GMA would be much smaller and Theorem 1 may not hold.  Since GIA can inject nodes with arbitrary features, it is intuitively more flexible and harmful than GMA.\n2. The novelty of this paper is somewhat weak. It is widely received that attackers tends to connect dissimilar features and many defenders are designed to mitigate such influence. Thus, it is quite natural to circumvent those defenders by penalizing the homophily change brought by the perturbations. I think the main contribution of this paper is from the empirical side.\n",
            "summary_of_the_review": "This paper advances the field of graph adversarial attack by promoting homophily unnoticeability. The experimental results are impressive while there are still some concerns regarding some analysis.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper focuses on graph injection attacks (GIA) in which an adversary introduces new nodes and links such that the predicted label by a trained classifier for a victim node is changed. They compare GIA versus graph modification attacks (GMA), in which the existing links are manipulated, and theoretically prove the superiority of GIA in causing damage. They further address the vulnerability of GIA against homophily-based defense and propose a GIA attack that preserves the homophily and is robust against such defense mechanism.",
            "main_review": "I liked the approach and thoroughness of this paper. The claims and proofs are solid. The problem addressed is very interesting in terms of pointing out a major deficiency in robustness of neural graph embedding models against GIA attacks. I believe the contribution of this work is significant in that further work can be built on their results to address the discovered vulnerability in deep graph models. \n\nSome questions/suggestions for the authors:\n-\tIf the classifier does not rely on the node attributes and solely uses the graph structure (e.g., k-hop message passing), it seems that GIA and HAO both lose their advantage because homophily, as defined in eq. (6), will be meaningless. In this case, GIA will be at best as powerful as GMA. How can HAO be modified to still offer a better performance than GIA/GMA in this scenario?\n-\tApart from the point mentioned above, what are other limitations of your model? I feel the paper lacks this discussion.\n-\tTheoretically, how small can the attack budget of GIA/HAO get while still maintaining their utility?\n-\tIntuitively, why does HAO work? (or why do we expect it to work?) The answer to this question is important for guiding the future work in building more robust deep graph models and I believe it will be valuable to have a section discussing such intuition and possible future directions.\n-\tDo GIAs maintain the same advantage over GMA for different downstream tasks other than node classification (e.g., link prediction, graph clustering, etc.)?\n\n\nMinor modifications:\n-\tFirst line of section 2.2 should be changed to: “… fool a GNN model, f, trained on a ...”\n-\tThe definition of D_x in Section 2.2 is not clear. How are the min() and max() operators on the matrix X defined? What is the intuition behind D_x?\n-\tLast line of the paragraph after Definition 4.1 should be changed to: “…will trivially clip…”\n\n",
            "summary_of_the_review": "The claims and proofs are solid. The problem addressed is very interesting in terms of pointing out a major deficiency in robustness of neural graph embedding models against GIA attacks. I believe the contribution of this work is significant in that further work can be built on their results to address the discovered vulnerability in deep graph models. There is possibility of improvement (such as adding discussion on intuition behind the method, limitations of it, and in-depth discussion of implications and future directions). But, overall,  I evaluate this paper as “accept”.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies the advantages and drawbacks of node injection attacks to graph neural networks. The authors demonstrate that, in general, node injection attacks are more powerful than the node modification attacks when there is no defense. But when the model trainer adopts some homophily based defense, the node injection attacks suddenly become ineffective and even underperforms the node modification attacks. Based on the observation, the authors propose to add add homophily preservation as an additional regularizer for the attack to remain stealthy against defenses. Extensive experiments demonstrate that the proposed homophily indeed improve attack effectiveness against defenses. ",
            "main_review": "Overall, this paper is very well written and the experiments are also comprehensive. However, I have the following major concerns:\n1. The proof of the equivalence between node modification attack and node injection attacks assumes the search space of the features of the injected node is sufficiently large such that the equality in Eq. (17) and Eq. (21) hold. However, in practice, this may not always be true as it depends on the size of the search space of injected nodes and the degree of node $v$. Even with large valid search space, the equality may still not hold because of some strange degree values of node $v$. In addition, in the paper, the valid search space (of injected nodes) is set as the minimum and maximum of all the node features in the graph. I am not sure if such an assumption is realistic in practice, as maybe some features might be harder for the attacker to manipulate. The authors should provide more evidence on why the current search space for injected nodes is realistic. \n2. When showing that node injection strategies are stronger compared to node modification attacks under no defense, the paper assumes the node modification attack only performs indirect attack by changing some adjacent nodes to the test victim, but not the victim itself. However, previous work (Zugner et al., 2018) showed that direct attack (directly changing the test victim features and edges) is more powerful than the indirect attack. Therefore, the results in the paper become less interesting as there is still no clear relationship between direct node modification attacks and node injection attacks. When comparing the relationship between indirect node modification and node injection attacks, the problem also becomes somewhat trivial: when the search space of the injected node is sufficiently large, node injection will be better as the node modification attack are constrained to be within the (small) bounded $L_p$-norm ball around the original (semantically meaningful) node features. \n3. I also did not follow the proof of Theorem 1. In the proof sketch, the authors say that once (a) and (b) are proved, $\\mathcal{L}_{atk}(f_{\\theta}(\\mathcal{G}'_{GIA}))$ approaches $\\mathcal{L}_{atk}^{k}(f_{\\theta}(\\mathcal{G}'_{GMA}))$ from below when $\\Delta_{GIA}$ approaches $\\Delta_{GMA}$. How come the optimal loss function value of GIA is lower than that of GMA when $\\Delta_{GIA}$ approaches $\\Delta_{GMA}$ from below? Having smaller perturbation budget can only increase the value of the optimal loss function value. This part needs clear explanation and I am not sure if this will lead to any changes in the statement of $\\Delta_{GIA}\\leq \\Delta_{GMA}$ in Theorem 1. (For some reason, the math is not rendered correctly here, but the authors can past the original text into other typesetting tools to see the formula).      \n4. I am not sure how significant the proposed harmonious adversarial objective is. The whole optimization problem encourages each node to be as similar to the neighbors as possible while performing the attack. So, the contribution of the paper somewhat becomes spotting common weakness of node injection (and some node modification) attacks: injecting significantly different nodes to the graph and such a \"unconstrained\" behavior makes them vulnerable to simple homophily based detector. And then the paper enhances the original node injection attacks by adding homophily preservation as a regularizer. So the paper is more about designing adaptive attacks to a simple homophily defense and I am concerned that the contribution may not be significant.   ",
            "summary_of_the_review": "I am leaning towards weakly rejecting the paper because 1) node injection attacks are only shown to be stronger than indirect node modification attacks, which becomes less interesting. In addition, the equivalence proof between the node injection and modification attacks cannot always hold in practice, 2) the proposed harmonious adversarial objective is of some limited novelty.\n ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper first theoretically shows that graph injection attack (GIA) is more powerful than graph modification (GMA), and GIA will lead to great damage to homophily distribution, which makes GIA easily defended by homophily-based defense. To mitigate the issue, the authors further propose to add the homophily unnoticeability constraint to preserve homophily. The authors also theoretically show that with the GIA with homophily unnoticeability constraint is more powerful than GIA without the constraint.",
            "main_review": "Strength:\n1. The paper is well written and easy to follow\n2. The paper provides theoretical analysis to understand GIA and improve GIA, which is very solid\n3. The proposed method makes sense and experimental results show the effectiveness of the proposed method\n\nWeakness:\n1. The authors didn’t well motivate why evasion and inductive setting is a practical setting in real-world. It is unclear what is the real-world application scenario for such setting. The authors need to provide some motivation examples.\n\n2. The authors claim that ``nodes and edges involving test nodes are invisible to model f_\\theta during training.’’ It is unclear how the authors make the test nodes not involved in the training. During training, the authors adopt 3-layer GNN, which means that the 3-hop subgraphs centered at each training nodes involved in the training of the model. The 3-hop subgraphs will contain many unlabeled nodes, which might also contain test nodes. From the description of the experiments, I didn’t find how the authors make sure that these test nodes are not involved in the subgraphs. \n\n3. The paper assumes that the graph follows homophily assumption. What if the graph is a disassortative graph, does the proposed method still work? It would be interesting if the authors can discuss this.\n",
            "summary_of_the_review": "In summary, this paper studies an important problem, provides theoretically analysis to understand GIA and further propose a new regualrizer to improve GIA. Extensive experimental results also show the effectiveness of the proposed method.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}