{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper considers the problem of distributed optimization in the Federated Learning setting in particular when the data in the clients is non-i.i.d. The paper points to the problem of catastrophic forgetting during the local update stages to be a cause for the bad training of models and proposes to fix it via introducing a pseudo loss, which are based on adversarial examples of the global model in the previous step and the adversarial examples of the local model at current step. \n\nThe paper's core idea was generally appreciated by the reviewers as well as the favorable evaluation of the proposed method when compared with other existing algorithms. The authors also provided further additional information during the rebuttal period and addressed author comments adding enough justification to the paper to resolve issues in the submission. One lingering issue that remains is the hyper-parameter tuning on test set results that was performed. The authors have promised to redo experiments based on validation sets. \n\nOverall the paper is borderline but I am recommending accept based on novelty of the idea and strong experimental results."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper aims to alleviate forgetting in federated learning on non iid data. The method proposed FedReg focuses on regularizing locally trained parameters with the loss on generated pseudo data, which are based on adversarial examples of the global model in the previous step and the adversarial examples of the local model at current step. This paper experiments on several small scale dataset with large number of clients. It shows improved performance and less forgetting during the training.",
            "main_review": "Strength:\n(1) Very interesting and novel idea: it is the first paper I have read about showing adversarial examples of global model can help to prevent forgetting in local models. Previous works are mainly focused on directly regularizing the parameters or training on previous data samples.\n(2) good result comparing with other methods.\n\nWeakness:\n(1) writing is a little bit unclear in describing the method. Clearer definition of notations in section 3.1 and 3.2 will be really helpful. \n(2) experiments only focus on small scale dataset with small number of classes. It will be really helpful to include larger scale dataset with natural non-iid data distribution.   ",
            "summary_of_the_review": "Because I think the main idea of the paper is really interesting, I will give 6-7 grade. I am more than willing to increase my score if more large scale experiments are added and writing is improved.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper considers the catastrophic forgetting issue in federated learning. The authors observe that this issue is (at least partially) responsible for slow convergence of existing FL methods when the data are not independently and identically distributed (non-i.i.d.) across different clients. This paper proposes FedReg, an algorithm to alleviate the catastrophic forgetting issue by regularizing the local model parameters on the generated pseudo data. ",
            "main_review": "This paper adopts a new perspective to improve federated learning, i.e., alleviating the catastrophic forgetting issue. This paper is clearly written and it is easy to follow. The proposed method is well explained. Experiments are solid with different datasets and baselines. \n\nI have the following concerns and questions. I would really appreciate it if  the authors could address them.\n1. Catastrophic forgetting issue is mainly studied in the scenario where the neural network is trained sequentially on multiple tasks, such as continual learning. However, in federated learning, we only consider one task as the joint objective for all clients. It is not clear why catastrophic forgetting could occur in federated learning as well. I expect more discussion on the motivation of this problem under FL settings, especially why your solution intuitively solves it. \n\n2. Related to my first concern, the authors mentioned that “the locally trained models suffer from severe forgetting of the knowledge of previous training data”. Given that each selected client needs to do local training for S epochs, I am not exactly sure why previous training data could be forgotten. Is it because of random selection of clients? It would be helpful to precisely describe what “previous training data” means in FL.\n\n3. In Figure 1, I assume that loss^(t-1) is computed using the averaged model from all selected clients. How about loss^t?  I am not sure if loss^t is only using the local model at client i or the averaged model from all selected clients. \n\n4. The assumption (2) in Section 3 is highly related to the assumption that different clients should have similar examples (considering the perturbation). I am wondering how practical this assumption (2) is when the data is non-i.i.d. across different clients. \n\n5. The experiments showed that the proposed method converges faster than the baseline methods in terms of the number of rounds. However, the additional cost incurred by pseudo data generation and regularization could result in longer wall-clock time per round. It would be great if the authors can compare the convergence rate in terms of wall-clock time.  \n\n6. The dataset and data split mechanism in the evaluation section is not the real-world FL dataset (see reference [1-3] as below), which is hard to empirically convince me. For example, FedReg may benefit more by alleviating the catastrophic forgetting when each client only has one or two classes. So I would like to see stronger experiments including the settings and dataset.\n\nReference:   \n[1] Kairouz, Peter, et al. \"Advances and open problems in federated learning.\" arXiv preprint arXiv:1912.04977 (2019).   \n[2] Lai, Fan, et al. \"FedScale: Benchmarking model and system performance of federated learning.\" arXiv preprint arXiv:2105.11367 (2021).    \n[3] Yuan, Honglin, et al. \"What Do We Mean by Generalization in Federated Learning?.\" arXiv preprint arXiv:2110.14216 (2021)",
            "summary_of_the_review": "I have been working on related areas and I have read this paper carefully.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper addresses the problem of federated learning, they claim the main issue is catastrophic forgetting, which they solve by generating a synthetic dataset per client. ",
            "main_review": "Strength:\n-Empirical evaluations show strong results, in several experiments\n- Idea is novel\n\nWeaknesses:\n- My main issue is with the writing of this paper. They claim the main issue is catastrophic forgetting but they don't really show it. They show fig. 1 but should compare to homogenous data where the forgetting shouldn't happen\n- Also, they show good results also on homogeneous data (CIFAR-10 uniform) which again points at something else as the reason why their method works\n- It is also unclear why the synthetic dataset helps with catastrophic forgetting. Should be explain better\n- Assumption 2 is unclear and also I am not sure where exactly do they use it\n- Just below eq. 10 they claim that L_{\\theta^{t-1}} is optimal but that doesn't seem possible considering eq. 4 (in convex case we would have a fixed point right away).\n",
            "summary_of_the_review": "The algorithm seems to work well, but I am skeptical about the alleged problem it solves and that it really addresses it. Writing is the main issue.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors claim that in non-iid federated learning setups models experience catastrophic forgetting of previously encountered data. As a result, the performance of the model degrades and the convergence is slower. As a solution, the authors propose FedReg, a method to regularize the model with pseudo-data generated from the local data of the client. Two datasets are generated using the fast gradient sign method. The first dataset, termed pseudo-data, aims at simulating data of other clients in the system. The second dataset, termed perturbed data, aims at retaining the model power on the local dataset of the current client. These datasets are used along with the original data of the client to update the local model parameters. The authors further introduce a method to modify the gradients to enhance the protection of privacy. The authors compared their method against several baselines on MNIST, EMNIST, CIFAR-10, CIFAR-100, and CT images. The comparisons show that FedReg achieves significant improvements in accuracy and convergence, reduction in catastrophic forgetting, and better protection of privacy compared to baseline methods.",
            "main_review": "Strengths:\n- The problem presented in the paper is well-motivated and the proposed solution for handling it looks promising.\n- Generating the pseudo-datasets at the client using the global model is a good idea and avoids potential private information sharing.\n- The paper is technically correct. I have gone through its derivations and did not find any flaws.\n- The results of the method are strong compared to the baseline methods examined.\n- The protection of privacy is a nice addition to the paper which distinguishes it from standard papers in the field.\n- For the most part, the paper is written clearly.\n- Full experimental details and code were provided.\n\nWeaknesses:\n- Some parts of the method, in my opinion, could be motivated and explained better. For example:\n     1. Why did you choose to generate the pseudo-datasets via adversarial training? Several alternatives for generating and using pseudo data were proposed in the literature (e.g., [1, 2, 3, 4]). I think the authors should address this line of research in the paper. \n     2. Why did you need to perform Taylor expansion to Eq. 4 & 5? Why can't they be used directly?\n     3. Given the approximations made, can you please clarify what is the effect of replacing the inequality sign in Eq. 4  with equality (two lines below Eq. 10)?\n\n- Having a shared model only is fine, but the paper misses an important line of work of personalized federated learning which combats the data heterogeneity using personalized components of the model. I believe that the issue of catastrophic forgetting is less severe in these models as the personalized components should make up for that. Did you check that? I think that a comparison to recent strong methods (such as [1]) is missing.\n\nGeneral Questions:\n- Regarding the training procedure, why did you choose to perform one step on $\\mathbb{D}_i$ followed by one step on $\\mathbb{D}_i^s$ and $\\mathbb{D}_i^p$?\n\n- Some experimental details are not clear. For example, how did you choose the hyper-parameters based on the grid search? Did you have a validation set?\n\n\n[1] Achituve, I., Shamsian, A., Navon, A., Chechik, G., & Fetaya, E. (2021). Personalized Federated Learning with Gaussian Processes. arXiv preprint arXiv:2106.15482.  \n[2] Luo, M., Chen, F., Hu, D., Zhang, Y., Liang, J., & Feng, J. (2021). No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data. arXiv preprint arXiv:2106.05001.  \n[3] Hao, W., El-Khamy, M., Lee, J., Zhang, J., Liang, K. J., Chen, C., & Duke, L. C. (2021). Towards Fair Federated Learning with Zero-Shot Data Augmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 3310-3319).  \n[4] Goetz, J., & Tewari, A. (2020). Federated learning via synthetic data. arXiv preprint arXiv:2008.04489.",
            "summary_of_the_review": "Overall I think that this paper could be a nice contribution. I think that the experimental section can be improved, and some important references are missing. Upon addressing my concerns I am willing to reevaluate the paper.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}