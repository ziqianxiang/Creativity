{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The topic of the paper is the use of partial information decomposition (PID) for the analysis of interactions in latent representations.\n\nAll reviewers ended up appreciating the paper after a good extensive discussion with the authors. The numerical investigation is somewhat on the short side. One reviewer asks for more ablation studies and one reviewer asks for more investigation on real datasets to show the advantage of the method.\n\nThe paper is borderline. The theoretical development is fine. But one could argue that the paper could benefit from some more work on the experiments. However, the main points of the method is in place and further validation of the method can be left for future contributions."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a novel disentanglement metric 'Unibound'. To construct the metric the method uses partial information decomposition, which decomposes the the mutual information between the latent variables and the labels into a sum of other information terms with specific roles:\n- Redundant information\n- Unique information\n- Complementary information\n\nEach of these terms are precisely defined and an intuitive explanation os given.\nThe proposed UnibBund metric is defined similarly to MIG based on the above terms. The main difference is that UnibBund uses a better composition than MIG, that:\n- better captures our intuitive notion of disentanglement\n- handles adversarial representation attacks better",
            "main_review": "\nGood:\n\nThe paper is well written, the explanations are very clear. Not only the theory, but the experiments as well, e.g. Table 1 captures the high level experimental results nicely that otherwise would have been hard to decipher from the raw data (in the appendix)\n\nThe ideas behind the metric are intuitively appealing. The 3 main information terms are well defined and explained. The changes to MIG metric makes sense in this light, as it better captures which term should be counted positively and negatively in the metric (Fig 2)\n\nThe paper shows 2 adversarial attacks, where the latent vectors are perturbed with noise so each attack targets the redundancy and synergy term respectively.\n- It is shown theoretically on a toy example that UniBound responds better to redundancy attacks, i.e. converges to zero faster with more noise. For synergy attacks they are the same\n- It is shown on 2 datasets that UniBound performs better vs. other metricks against redundancy attacks.\n\nSeveral disentangling methods were compared not only with the proposed metric, but analysed w.r.t the a detailed decomposition of terms.\n\nBad:\n\n\"and the inference distribution p(z|x) and its marginals p(zl |x), p(z\\l |x) are all tractable (e.g., mean field variational models)\"\nPerhaps this is a strong assumption.\n\nMinor:\nThe notation could be a bit better.\n- The mutual information has a different font than than U, R, C. They should have the same font, as they are just a a renaming of the same function, but applied on different variables.\n- The above is confusing, when the 'interaction information of a triple' I is introduced with the same font as R, R and C.\n",
            "summary_of_the_review": "The proposed metric in the paper is well designed and supported by:\n- intuition\n- theory\n- experiments vs. adversarial attacks and compared with other metrics\n\n--------- UPDATE ---------\n\nI have read the other reviews and rebuttals. The authors clarified some details and notations. I keep my score and recommend the paper for publication.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes an information theoretic approach to analyze the disentanglement. Using Partial Information Decomposition (PID) framework, the authors attempt to characterize the interaction among latent factors, correlation/disentanglement, for more than two latent variables. They generalize the existing mutual information gap (MIG) metric for multiple latent variables, by decomposing mutual information term into unique, redundant, and complementary information. The authors discussed that the pairwise correlation analysis endorses a portion of the redundant information as a measure of disentanglement, which should have been considered as entanglement. Additionally, they derive bounds for the partial information terms and demonstrate the limitations of existing disentanglement measures, i.e., BetaVAE, FactorVAE, and MIG in quantifying multivariate correlation in the latent space. The authors also designed two entanglement attacks to assess the disentanglement measures under injected correlation to the latent representation. The authors used two datasets, dSprites and 3dshapes to empirically substantiate their findings. ",
            "main_review": "Originality: \nAnalyzing latent space and quantifying disentanglement is an open question in the representation learning field. The authors used PID to generalize the concept of information gap for multivariate analysis to assess the level of entanglement and disentanglement, which is rather novel and quite valuable. Deriving upper and lower bounds for the introduced partial information terms as a function of interaction information, $\\mathcal{I}(.)$, is original. The entanglement attacks design is not new but is well-justified for this work. \n\nStrengths: \n- The manuscript is well organized and well written. \n- The paper attempts to make a connection between the existing literatures in information gap theory and partial information decomposition to improve the entanglement analysis.\n- The experimental studies illustrate that the proposed metric successfully reveals the disentanglement decrement under entanglement attacks, while the comparable measures fail.\n\n\nLimitations: \n- Ablation study is a critical study for this topic. I expected to see detailed ablation studies, beyond the suggested entanglement attacks.\n- There is no analysis for robustness of partial information measures (the proposed bounds). \n- I think the traversal analysis is missing in this work, especially in entanglement attacks. It would be quite informative if the authors report some visual results.\n- I think the recent work by Do and Tran, ICLR2020, which formulates the disentanglement as another set of information-theoretic metrics is quite relevant to this work. It would be informative if the authors elaborate on those metrics as well and show which dimension(s) of information is missing in each framework.\n\nAdditional Comment/Questions:\n- For each VAE model, how does sampling affect the disentanglement metrics? Was the sensitivity of partial information calculation to the number of samples studied?\n- I wonder about entanglement attacks that may withstand being revealed by the proposed partial information measures. Any thoughts?\n- If I understand correctly, for JointVAE, the upper and lower bounds of partial information are quite close to each other (the bound is very tight). What does this exactly mean? Why does it happen mainly for JointVAE? \n- Did you consider both continuous and discrete variables when reporting the disentanglement? \n- Batch size for TCVAE is quite large. Is this the case in the original implementation as well?\n- The qualitative summary in Table 1 can be reported in the appendix and instead the bounds for each partial information can be reported. Or at least those qualitative measures can be elaborated in the main text.\n",
            "summary_of_the_review": "I think this is a good submission and the proposed information-theoretic framework is persuasive. However, I am on the borderline between acceptance and rejection. The main contribution seems limited and the ablation study including entanglement attacks only considers a few simple cases of entanglements. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a metric for evaluating disentanglement inspired by Partial Information Decomposition (PID). It also proposes 2 “entanglement” attacks to highlight the advantages of the proposed metric.",
            "main_review": "Pros:\n1) The problem that the authors want to address is important.\n2) The proposed metric is reasonable.\n\nCons:\n1) The paper misses important references and discussion of prior work.\n2) The presentation is not clear.\n3) Experiments are limited to only 2 toy datasets and do not really highlight the advantage of the proposed metric.\n4) The proposed metric seems not practical compared to existing metrics. \n",
            "summary_of_the_review": "1) Novelty:\n- The idea of an information-theoretic analysis framework for disentangled representations was proposed by Do & Tran [1] but is not discussed in the paper.\n- The metric UniBound proposed in the paper has a very similar formula to those of the WSEPIN and WINDIN metrics in [1] but with the input image x replaced by the label y. I think the authors should discuss this similarity in their paper.\n- The authors should also discuss and compare their metrics with other up-to-date improvements of MIG such as JEMMIG [1] or MIG-sup [2]. Please check [3] for more detail of these metrics.\n\n2) Clarity in the presentation:\n- I think the authors abuse notations in their paper which causes difficulty in reading. For example, if $\\mathcal{R}$, $\\mathcal{U}$, $\\mathcal{C}$, $\\mathcal{I}$ are just mutual information, the authors should write all of them as $I$. I think the variables inside these terms are enough to define their meanings. \n- I don’t understand the meaning of the symbol $\\backslash$ in the mutual information. Is it equivalent to the symbol $\\|$ for conditional probability? If they are equivalent, I think the authors should write $\\|$ to make the mutual information more familiar to readers. Otherwise, they need to write explicit formulas of $\\mathcal{U}(y_k; z_{\\ell} \\backslash z_{\\ell '})$ and $\\mathcal{U}(y_k; z_{\\ell '} \\backslash z_{\\ell})$ since I cannot guess what they are.\n- The derivation of the proposed metric UniBound in Eq. 5 only uses Unique Information ($\\mathcal{U}$) and neither Redundant Information ($\\mathcal{R}$) nor Synergetic Information ($\\mathcal{C}$). I wonder how the authors can relate their metric to “redundancy” and “synergy”?\n- How the lower bound and upper bound of each term are related to disentanglement is not well discussed. I am almost unable to deduce anything when looking at Fig. 3b.\n\n3) Correctness and practicality of the method:\n- I don’t really understand why the latent variable $z$ is concatenated with a new vector in case of Redundancy and Synergy attacks? Doesn’t it double the length of $z$ and make $z$ no longer a suitable input for the decoder?\n- I am concerned about the practicality of the proposed metric as it is computed by summing over many small probability density values ($\\log\\sum_{x} p(z|x)$ in Eq. 8), which often leads to numerical instability if $z$ is high-dimensional. This is serious because incorrect results can cause incorrect interpretations. MIG and its improvements (JEMMIG, MIG-sup), however, do not suffer from this problem since these metrics use the conditional probability of a single factor $p(z_{i}|x)$, not all factors. This problem was analyzed in [1] (Appdx. A5). I would like to hear the authors’ explanation about this. I also would like to know the dimensionality of the latent code z used in their experiments as I cannot see this value in Table 3, Appdx. C.\n- Clipping $I(y_{k}, z_{\\ell}) - I(y_{k}, z_{\\backslash \\ell})$ to be >= 0 makes the metric unable to compare between models that have $I(y_{k}, z_{\\ell}) \\ge I(y_{k}, z_{\\backslash \\ell})$. This is problematic because $I(y_{k}, z_{\\backslash \\ell})$ is likely to be larger than $I(y_{k}, z_{\\ell})$. An example of this is the UniBound values for JointVAE in Fig. 3a.\n- In Fig. 3a, UniBound produces very different results for FactorVAE on dSprite and on 3DShapes. I would like to hear the explanation for this.\n\n[1] Theory and Evaluation Metrics for Learning Disentangled Representations, Do & Tran, ICLR 2020\n\n[2] Progressive Learning and Disentanglement of Hierarchical Representations, Li et al., ICLR 2020\n\n[3] Measuring Disentanglement - A Review of Metrics, Zaidi et al., 2021",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The authors leveraged partial information decomposition (PID) for analyzing multi-variable interactions in latent representations. The PID framework shows that (i) the mutual information between a latent variable and a generative factor can be divided into unique, redundant, and synergistic information terms, and (ii) the uniqueness term corresponds to the degree of disentanglement. The authors also introduced a disentanglement metric by modifying MIG and conducted experiments with VAE-based models on two datasets.",
            "main_review": "[Strengths]\n- Applying PID for disentanglement analysis looks quite interesting, and the derivation generally looks thorough.\n- The paper proposes a new disentanglement metric to address the weakness of existing metrics, which do not capture multi-variable interactions properly.\n- The paper is well backed-up by a comprehensive supplementary material that seems to contain all the details required for reproducibility. The paper is fairly clearly written and easy to follow.\n\n[Comments]\n- It would be better to quantitatively and/or visually support the claim “Current metrics, however, may fail to detect entanglement that involves more than two variables, e.g., representations that duplicate and rotate generative factors in high dimensional spaces,” which is the most important motivation of this work.\n- Though simulating some entanglement attacks is worth trying, I am not sure whether these attacks actually and frequently happen in disentanglement learning. It would be better to find and show the cases similar with the redundancy and synergy attacks by analyzing learned features.\n- Unsupervised disentanglement learning with VAEs has been known to provide noisy results that are extremely affected by random seeds, architectures, and hyper-parameters (Locatello, 2019). Because the experiments merely relied on unsupervised VAEs with a single fixed architecture and few hyperparameter settings, I am not sure whether the results obtained under such a limited setup are reliable and whether this work could attract the attention of readers in the disentanglement learning field. For example, is the trend of the results in Figure 3 consistent for other architectures and settings? How did the authors set the regularization coefficients for disentanglement learning (beta, gamma) and other hyperparameters? Furthermore, I think drawing a conclusion described in Table 1 may be dangerous because the examined VAEs were tested under a very limited setup. I would suggest the authors to include (i) additional results under various settings and/or (ii) some results using semi- or weakly-supervised disentanglement models (Locatello, 2020a; Locatello, 2020b; Chen, 2020; Feng, 2018; Szabó, 2018; Kingma, 2014).\n-I am not sure whether enforcing nonnegativity in the RHS of eq. (5) using the max{0,*} operation is theoretically allowed. What happens if the max{0,*} operation is removed in the UniBound metric?\n- The results of JointVAE using the proposed metric seem weird. Though I checked the authors’ claims (This can be viewed as the effect of introducing a discrete variable into the representation; The high redundancy in JointVAE can also be explained by the lack of independence), they were unclear for me. In particular, the claim “As the capacities are positive at the end of training, this indicates that the KL terms, which include the total correlation of the latent variables (Kim & Mnih, 2018; Chen et al., 2018), are large in the trained model” may be incorrect because the KL term includes not only the TC term but also the data-latent MI and dimension-wise KL terms, meaning that a large KL does not directly indicate a large TC. It would be better to add more clear explanations (e.g., by actually measuring the TC terms). Furthermore, it would be helpful to see whether these results are also observed with other discrete-variable VAEs such as CascadeVAE (Jeong, 2019).\n- It would be better to include some qualitative results (latent traversal, t-SNE embedding space visualization) for visually understanding how feature spaces change according to the value of the metrics.\n- Abstract: asses -> assess\n\n(Locatello, 2019) Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations, ICML'19\n\n(Locatello, 2020a) Weakly-supervised disentanglement without compromises, ICML'20\n\n(Locatello, 2020b) Disentangling factors of variations using few labels, ICLR'20\n\n(Chen, 2020) Weakly supervised disentanglement by pairwise similarities, AAAI'20\n\n(Feng, 2018) Dual Swap Disentangling, NeurIPS’18\n\n(Szabó, 2018) Challenges in Disentangling Independent Factors of Variation, ICLRW'18\n\n(Kingma, 2014) Semi-supervised Learning with Deep Generative Models, NeurIPS’14\n\n(Jeong, 2019) Learning Discrete and Continuous Factors of Data via Alternating Disentanglement, ICML’19\n",
            "summary_of_the_review": "The main idea (applying PID for disentanglement analysis) looks interesting, and the underlying technical contributions seem good. However, the empirical results are very weak and not impressive. I thus find it difficult to argue for acceptance of the work.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}