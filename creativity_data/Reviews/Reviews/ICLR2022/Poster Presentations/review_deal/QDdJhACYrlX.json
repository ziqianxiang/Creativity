{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes a joint multi-agent trajectory prediction framework for multiple agents using a \"heatmap\" estimation approach employing a hierarchical strategy and sparse image generation for for efficient inference. The method takes a set of predicted trajectories for each agent produces reorderings. The work yields a top result on a competitive leaderboard. \n\nWhile multiple reviewers were initially concerned about the paper not making a single major contribution, the author response discussion helped to clear up the degree of novelty. Further experiments provided during the review also led to multiple reviewers increasing their score. In the end, all reviewers recommend acceptance of this paper.\n\nAs such the AC recommends accepting this paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This work proposes THOMAS, a hierarchical heatmap refinement scheme for multi-agent trajectory forecasting. At its core lies a GOHOME-style architecture with a few modifications (predicting only endpoints, iteraetively improving the heatmap output, collision-free output sampling, modality combination re-ranking) that yield scene-consistent predictions, which are demonstrated to yield better performance across a wide-variety of metrics on the Interaction dataset.",
            "main_review": "- The overall idea of iterative hierarchical heatmap refinement is interesting and appears to be novel. The experiments demonstrate the ideas validity, although there is definitely room for further strengthening.\n\n- The related work is thorough, one quick comment here is to also reference the following work in the discussion of methods which can predict multiple agents at the same time (beginning of the last paragraph before Section 3): \"MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control\" by B. Ivanovic, A. Elhafsi, G. Rosman, A. Gaidon, M. Pavone in CoRL 2020.\n\n- Acronyms should be explained when they are first used. For instance, it might not be obvious what a UGRU is in Section 3.1.1. What does MR optimization mean in Section 3.1.3?\n\n- Do not use contractions in scientific writing (e.g., change \"don't\" to \"do not\").\n\n- A thorough round of editing is necessary, there seem to be writing errors that materially change the meaning of sentences. For instance, \"The final output is therefore no strictly a re-ordering...\" Should this have said \"not strictly\"? Same question for \"which is JointMR where colliding modalities are also counted as misses even if they are closer than the defined threshold.\" Should this have just said \"where colliding modalities are also counted as misses?\" It is not very clear what these metrics mean here.\n\n- The novelty with respect to the original GOHOME work needs to be made clearer, there seem to be many reused components and it is difficult to tell which parts are new in this work.\n\n- Related to the above point, it is a bit difficult to understand this work's core contributions in Sections 3.2.1 and 3.2.2, also because the writing makes this difficult (e.g., a spurious use of \"However\" makes it difficult to determine if a statement is being negated or not).\n\n- There are some key insights missing from the experimental section, which will be expanded on below.\n\n- Ultimately, the method is only evaluated on one dataset, and it is difficult to determine if its performance would generalize to other datasets (for instance, what about nuScenes, Lyft, Waymo Open, Argoverse, etc?).\n",
            "summary_of_the_review": "While the overall idea of iterative hierarchical heatmap refinement is interesting, there are some significant areas of improvement that make it difficult to argue for the acceptance of this work as-is. For instance:\n- Writing errors in key areas make it difficult to parse what is going on internally in the model.\n- The novelty with respect to the original GOHOME model should be expanded upon, perhaps with a concrete sentence stating the core differences near the beginning of Section 3 and stating the relationship of this work to GOHOME in the related work.\n- The experiments are good at showing that the model works, but there are a bit of key insights missing. For example, why are only two rounds of heatmap upsampling done? What do the performance curves look like with increased points? What does the Pareto front look like with respect to computation time or required FLOPs (at least to indicate to a reader why stopping at two levels makes sense)?\n- Finally, another dataset would really strengthen this work and aid in convincing readers that the method's performance extends beyond the Interaction dataset.\n\nAddressing these would certainly ready this paper for publication in this or a similar venue.\n\n### Post-Rebuttal\n\nThe added results and comments in the author rebuttal address most of my concerns. I share the same overall sentiment as Reviewer PgCY, the paper may not have a single \"major\" novelty, but the set of presented incremental contributions are sufficient to convince me of the performance and utility of this work over prior approaches, and I believe this paper is now more suitable for publication.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper addresses the task of multi-agent multi-modal trajectory prediction in the context of autonomous driving. Inspired by previous works, the problem is divided into first estimate the goal (end-points), and then re-construct the full trajectory. For end-point estimation, this paper proposes hierarchical iterative refinement from a probability heatmap, with collision-aware greedy sampling to generate collision-free multi-agent trajectories. To further produce scene-consistent multi-agent multi-modal trajectories, the paper also proposes a modality combination ranking module that re-orders the modality of each agent. The method is validated on the Interaction multi-agent prediction challenge and ranks 2nd on the multi-agent track (the 1st-rank entry was submitted 9 days after submission) and 1st on the conditional multi-agent track.",
            "main_review": "Strengths:\n1. The paper is well written and easy to follow.\n2. Good performance was achieved on the Interaction multi-agent prediction challenge.\n\nWeaknesses:\n1. The method largely follows previous works, with little technical contributions. And even for these limited technical novelties, many of them are not well supported with experimemts.\nIn the end of introduction section, the authors summarize three main contributions:\n\ni) an efficient graph-based model. However, the implementation mainly follows LaneGCN and GOHOME.\n\nii) a collision-aware endpoint sampling. The algorithm mainly follows GOHOME, with a small modification in that when we sample an endpoint for actor a modality k, we not only mask out the same region for other modalities of actor a, but also mask out for other actors of modality k. However, this modification doesn't make sense to me, as we still have a scene-consistent modality recombination module afterwards, therefore the second mask-out won't make much difference here. I also don't see an ablation study for this specific change (ie, do not mask-out for other actors of modality k, which means exactly follows the original algorithm in GOHOME). I want to see this ablation for the last three rows in Table 3.\n\niii) a novel recombination model that could obtain scene-consistent trajectories across the agents. To me this is the core novelty of the paper. From the last two rows in Table 3 we can see that with the proposed recombination module joint metrics improve a lot. However, the marginal metrics degrade a lot (e.g., miss rate more than doubled). The only explanation is that with the proposed module, the same modality (also the sub-optimal one) of an actor is chosen for multiple times in scene-level multi-modalities. To me this may not be what we want: scene-level consistency, but sacrifices actor-level precision a lot. Further analysis is needed here to convince me that this trade-off is worthwhile.\n\n2. Another technical novelty that's not mentioned is the hierarchical iterative refinement of endpoints from the heatmap. However, no ablation study is done on this. I'd like to see a speed-performance comparison with original endpoint estimation model (as in GOHOME).\n\n3. Also, the overall runtime efficiency of the method is not given.\n\n4. GOHOME is the closest approach but I don't see it as a baseline in the experiments.",
            "summary_of_the_review": "Despite good results on the leaderboard, given the limited technical novelty without solid supporting evidences, I do not recommend this paper for acceptance at current status.\n\n**Updated review after rebuttal:**\n\nThanks to the authors for the revision that clarifies the technical novelity much better, and the additional experiments that compare with the GOHOME baseline thoroughly on more benchmarks. These address most of my concerns and therefore I raise my rating.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a multi-modal trajectory prediction pipeline.\nThe idea is that based on past trajectories and a map of the road a model\nis trained to predict a heat map with the most likely end-points.\nWith those end-points a trajectory can be inferred for each agent in a collision\nfree way by leveraging all heat  maps jointly.\nWith those trajectories, multiple, consistent scene level trajectories are predicted.\n\nThe main contribution of the paper is on the reasoning about the end-points\ngiven by the predicted heat map. ",
            "main_review": "\n### Strong Points\n\nThe idea of performing re-estimation based on the computed heat map end-points \nseems novel to me. This idea seems like a natural next step to improve multi agent motion \nprediction. The fact that you first get the end-point and then reason about the scene is \nintuitively sounding and seems to be a good solution for the problem.\n\nThe experiments on interact are a nice direction to be taken by the field.\n\nThe visualizations of the heat-maps and the different predictions was helpful.\n\n### Weak Points\n\n#### I could not find a clear distinction with literature\nWhile reading the related work section I found hard to contrast the ideas of the paper with the ones proposed on the literature.\nThe difference between this method and GOHOME was  not clear to me in this sense. \nFrom what I understood the main contribution here  is the modality combination based on the collision\nfree end-point sampling. However, this was not obvious for me when reading the paper.\n\n\n#### The implemented baselines seemed to have performed way worse than expected.\nFor example, both [1] and [7] are methods designed for *joint* prediction and scene level prediction. This is contradicted \nby the observations made by the authors on page 8, quote: \" ... This problem is aggravated in the joint training case, since the modality selected is\nthe same for all agents in a training sample....\". Both [1] and [3] fairly confidently claim producing multimodal joint predictions.\nEither the version implemented by the authors does not correctly match the other works in the literature or there are specific findings\non the limitations existent in other methods. \nAlso, the paper lack comparison with latent variable based [2][5][[6] multi modal prediction methods. They seem to perform\nbetter when the issue is diverse prediction. Definitely the mode does not tend to be the same for all predictions in those cases.\n\n\n#### A single dataset evalution might not be enough for the community to access the value of this paper.\n\n Motion prediction is currently a very competitive scene. Even though I appreciate the idea on focusing reporting results on multi-agents\nand joint prediction tasks, it is important to also evaluate the prediction on more standard benchmarks such as argoverse. \nWith results on argoverse, me and the rest of the community can more quickly access the the capabilities of the proposed \n heat map prediction pipeline, on producing consistent ego-agent motion prediction. I understand that this would not be the main\nresults, but it would be helpful. \n\n##### Computational cost is apparently not shown.\n \nI could not find the computational cost of running and training the proposed method on the paper. It seems that even\nwith the optimizations made on the heat map estimation the training time and inference time should be high.\nThose kinds of motion prediction models have the necessity to further scale with way more data. Thus, highly\ncomplex methods can be hard to train. There is also the case of potential future execution in an embedded hardware.\n\n### Specific Questions\n\nI am not  sure about the scene modality vectors ( Section 3.2.2), are they like seed parameters which are going to be used\nto incorporate the joint consistent scene level ? I couldn't really find any sort of detailed explanation on that.\n\nWhy the lack of ADE for scene level metrics or using similar metrics as [3] ?\n\n\n[1] Jiquan Ngiam, Benjamin Caine, Vijay Vasudevan, Zhengdong Zhang, Hao-Tien Lewis Chiang,\nJeffrey Ling, Rebecca Roelofs, Alex Bewley, Chenxi Liu, Ashish Venugopal, et al. Scene\ntransformer: A unified multi-task model for behavior prediction and planning. arXiv preprint\narXiv:2106.08417, 2021\n[2] Tang, Charlie, and Russ R. Salakhutdinov. \"Multiple futures prediction.\" Advances in Neural Information Processing Systems 32 (2019): 15424-15434.\n[3] Li, Lingyun Luke, et al. \"End-to-end contextual perception and prediction with interaction transformer.\" 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2020.\n[4] Yuan, Ye, et al. \"AgentFormer: Agent-Aware Transformers for Socio-Temporal Multi-Agent Forecasting.\" arXiv preprint arXiv:2103.14023 (2021).\n[5] Girgis, Roger, et al. \"Autobots: Latent Variable Sequential Set Transformers.\" arXiv preprint arXiv:2104.00563 (2021).\n[6] Casas, Sergio, et al. \"Implicit latent variable model for scene-consistent motion forecasting.\" Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, \n[7] Ming Liang, Bin Yang, Rui Hu, Yun Chen, Renjie Liao, Song Feng, and Raquel Urtasun. Learning\nlane graph representations for motion forecasting. In ECCV, 2020\n",
            "summary_of_the_review": "\nThe paper provides an incremental solution to heatmap based motion\npredictions that improves on scene level predictions.\nEven though this idea is interesting, the experiments were not able\nto convince me as this being an impactful approach for scene level prediction.\n\n# Post rebuttal review \n\nAfter carefully reading the authors rebuttal, I decided to increase my score.\nThe changes proposed by the authors and the explanations provided would increase the quality of the paper.\nThe two main problems: The fact that the contributions in comparison with GOHOME were not clear,\nand the lack of results in comparable benchmark were both carefully addressed.\n\nI am changing the score to a 6 provided that the authors proofread the paper as well recommended\nby reviewer 4LEw, add the other benchmark results and better compare with GOHOME.\n\nThe paper does not qualify as of containing major new contributions. However, I think\nthe incremental contributions shown are sufficient for me to lean towards acceptance.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a joint trajectory prediction framework. This means that the model produces multi-modal future predictions at the scene level (i.e., for all actors jointly). There has only been very recent research in this area despite its importance to autonomy and motion planning in particular, so the relevance of the paper to the broader motion forecasting field is high. I identify two main contributions in the paper: (i) hierarchical and sparse heatmap output representation and (ii) a recombination method that is pluggable in any multi-modal marginal prediction model.",
            "main_review": "### Strengths:\n- __Originality__: the two main contributions outlined in the summary of the paper are fairly distinctive from previous works.\n  - The hierarchical heatmap prediction tackles one of the main issues of heatmap representations, which is their heavy memory consumption.\n  - The learnable recombination method is general enough to be suitable for any marginal prediction model, which makes me think it would have a solid impact on the community.\n- Introduction and related work are succinct and touch upon the main relevant points to the future prediction task.\n- Figures are useful to understand the method as well as to evaluate the performance qualitatively.\n\n### Weaknesses:\n- __Writing ambiguity and lack of details__: I am not sure the write-up is polished enough for submission to ICLR. I outline a few reasons below:\n  - Throughout the paper, there is no mention or description of the loss functions utilized, and barely any mention of the overall training process (with the exception of a sentence in 3.1.3). In the appendix, the authors describe how the heatmap output is optimized, but there is no mention about how the learnable recombination module is trained, which is one of the main contributions of the paper.\n  - Because of this lack of description of the overall training process and loss functions, it is unclear if in the experiments the authors utilize 2 separate THOMAS models - one for marginal prediction and one for joint prediction. For instance, are the marginal metrics and joint metrics in Table 1 coming from a single model, or two separately trained models? A sentence that contributes to this confusion is in 3.1.3, where the authors mention that they decode K end points using the same MR optimization algorithm as Gilles et al. (2021b). However, in 3.2.1 the authors enhance this algorithm with collision-free sampling. Please clarify this in the rebuttal.\n  - The paper criticizes generative models in the second paragraph of the related work for not providing a probability value for each prediction, which makes me expect the method to provide such scores. However, there is no mention about it in the approach or experiments sections.\n  - In Table 3, the Marg and Joint objectives are not defined.\n- It is unclear how some pieces tie together. My main concern is with respect to collision-free end point sampling (3.2.1) and recombination (3.2.2). The heuristic in 3.2.1 seems to assume that the modalities are \"already ordered\" since the algorithm basically avoids sampling close end points across actors for a given modality k. However, the recombination can perform arbitrary linear combinations across modes, thus not respecting this. Is the idea that only one of the two methods are used to perform inference/training on a model? If so, I would suggest moving 3.2.1 to the experiments as a baseline/ablation, and I definitely would not claim it as a contribution (particularly since it's just a small tweak on top of a previously proposed algorithm).\n- Experiments are not as thorough as I would expect. This is understandable for the joint prediction setting as there are very few baselines and the dataset/benchmarks on this task have just started. In fact, I appreciate the effort of the authors of re-implementing ILVM and SceneTransformer. However, with respect to marginal prediction, there are a lot of methods and benchmarks out there. Another aspect that would have been great to get more insight on is the hierarchical heatmap output. What's the tradeoff between computation (both runtime and memory) and accuracy, with respect to dense heatmap approaches? How was the current 3-layer hierarchy chosen?\n\n### Additional feedback:\nIn this section I provide additional feedback for rebuttal, but please address first the main points above.\n- Re: training details in the appendix. I find it surprising that the method is trained with random sampling of up to 8 agents, given that for joint prediction there might be other agents that are particularly relevant to the task. Was this better than lowering the batch size? If so, is it because it is rare that a scene contains > 8 actors in the INTERACTION dataset?\n- The equation that describes the weighted linear combination of agent modalities seems incomplete. As far as I understand, there should be a weighted sum in the equation, using the scores coming out of the softmax.\n- Related work is missing some relevant works. In the last paragraph, joint autoregressive methods should be mentioned (e.g., PRECOG[A] - see references at the bottom) as they were the first to model the interactions across agents at the output level. With respect to generative models and their random sampling and lack of confidence scores per modality, LookOut[B] is a recent method that addresses both these concerns with a learnable diverse sampler and scene scoring. The authors can treat this as concurrent work since it was just published at ICCV, but please include it in the discussion as it is highly related.\n- Is the notation of the joint metrics coming from the Interpret challenge? If not, I would suggest unifying this with the names proposed originally in ILVM (e.g., minJointFDE --> minSFDE, CrossCollisionRate --> SCR).\n- While the sparse and hierarchical heatmaps make sense to mitigate their high resource consumption, I am a bit concerned about the fact that endpoints are only sampled from the finest resolution, as this might not contain more unlikely but safety-critical modalities. Overall, the heuristic refinement of the most likely grid cells seems contradictory with the endpoint sampling objective of maximizing coverage.\n- The writing would benefit from more intuitions. For instance, the method samples heuristically from the heatmaps to maximize coverage, but why is this important to the overall self-driving task?\n- I personally did not get much out of figure 4, perhaps adding the shapes of the tensors could be helpful.\n- I would avoid calling the combination method an \"ordering\", as the method is more general than that.\n- How come the CrossCollisionRate is still 2.6% when using the collision-free end point sampling? I would expect it to be zero.\n\n### Additional references:\n- [A] Rhinehart, Nicholas, et al. \"Precog: Prediction conditioned on goals in visual multi-agent settings.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.\n- [B] Cui, Alexander, et al. \"LookOut: Diverse multi-future prediction and planning for self-driving.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.",
            "summary_of_the_review": "I think this paper has significant contributions in terms of the presented method. However, my main concerns are related to the lack of details in the writing as well as the thoroughness of the experiments and the insights that can be extracted from them. For these reasons, I am leaning towards rejection, but I look forward to the authors' response during the rebuttal period.\n\n### Post-rebuttal\n\nAfter careful consideration of the rebuttal, I am happy to increase my score and I lean towards acceptance. My doubts were clarified, and the authors have timely adapted the write-up. Since my main issue was with the lack of clarity in some parts and that has been improved I raise my score to a 6. I am in between 6 and 8, but I think 8 is a bit too much since the improvements are incremental. I would rate it as a 7 if I had the option given that the proposed linear recombination of marginal predictions is very flexible and could be easily adapted to multiple prior works in the literature, thus raising the future impact of this work.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}