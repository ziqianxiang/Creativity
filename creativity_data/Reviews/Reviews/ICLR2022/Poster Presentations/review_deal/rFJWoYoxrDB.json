{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper makes the important, albeit somewhat unsurprising, finding, that cell-based NAS search spaces, and in particular the DARTS search space, include some operations that are much better than others. Reducing the search space to these allows even random architectures to yield good performance, similarly to the findings of \"Designing Network Design Spaces\", https://openaccess.thecvf.com/content_CVPR_2020/html/Radosavovic_Designing_Network_Design_Spaces_CVPR_2020_paper.html\n\nThis paper received mostly positive scores (5,6,6,8). While I agree with the negative reviewer that it would be good to study this on other benchmarks as well, I follow the positive reviewers in recommending acceptance. I encourage the authors to fix the remaining typos (there are still many) and to open source their code. This would increase the paper's impact a lot.\n\nFinally, I would like to ask the authors to avoid protraying the misconception that we don't need large and powerful search spaces. In fact, as already hinted on in Section 6, we *do* need larger and more exciting search spaces in order to discover entirely novel architectures. Also the multi-objective nature of NAS is not to be undervalued, so the take-away of the paper should *not* be that we should design NAS benchmarks with really small & strong search spaces, but that, given a specific problem and objective, it may be prudent to evaluate whether the whole power of a given NAS search space is needed or whether it can be reduced to its essential parts."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper performs a detailed analysis of the DARTS search space commonly used for weight-sharing neural architecture search. The authors used several simple statistical methods to identify salient features (ops or graphlet) that can best explain the higher-quality candidates. They also looked into the discovered patterns and reached the conclusion that the popular cell-based search space is highly redundant, as simply imposing two of the discovered constraints can result in strong performance even using random search.",
            "main_review": "Pros:\n\nThe paper is overall well-written and solid in terms of empirical studies. A key message to me is that high-performance architectures in the cell-based search space lie in a low-dimensional “manifold” which can be explained by several simple factors such as the inclusion of key ops and specific topological patterns. While this seems a known fact implied by several existing works on random search & performance predictors, results in this work are still quite informative (e.g., the authors explicitly summarized some of the most useful design choices of the best models).\n\nCons:\n\nOne of the main findings the authors reveal is that random search could perform well when augmented with simple heuristics, which further implies that the current search space is not practically interesting. This is only partially correct to me because the useful constraints discovered in the paper are arguably the outcomes of a search algorithm -- namely the one performed by nas-bench-301 (“50,000 architecture-performance pairs in the DARTS space using a combination of random sampling and more than 10 state-of-the-art yet technically diverse methods”). In other words, the constrained random search in this work is in fact heavily based on the prior knowledge discovered by search.\n\nAs far as I can tell the scope of the paper is restricted to cell-based NAS. However, people have also explored many other types of search spaces, such as the ones used in ProxylessNAS, MobileNetV3, EfficientNet, TuNAS and FBNets. Unlike the cell-based ones, those search spaces emphasize macro instead of micro decisions hence are less subject to the concerns raised. There are also other types of search spaces that are presumably less restrictive in terms of the choice of primitives, such as AutoML-Zero. While I agree with the authors that cell-based search spaces are still the mainstream for weight-sharing NAS, it would be more comprehensive to discuss the aforementioned works.\n\n",
            "summary_of_the_review": "Overall speaking, this is a good paper attempting to address an important topic in neural architecture search regarding search space redundancies. The message is not groundbreaking in my option given several existing works with similar implications, but the analysis and results are interesting enough to be informative.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper examines the NASNET cell spaced search space in NASBENCH-301 (darts search space) and NASBENCH-201. They conclude that Separable convolution and skip connections are the most important operations. By replacing the current operations with just this subset and also enforcing the skip connection to be used as a residual connection, they are able to achieve accuracy very similar to the networks discovered by other SOTA algorithms. They also demonstrate that one does not have to search for reduce cell and that it can just use the same architecture as that of the normal cell. Finally, they replace the SOTA architectures found by the most popular NAS algorithms and replace the cells to use only Separable conv and skip connections and show that the accuracy of the network is very close to the original network.",
            "main_review": "Strengths:\n1. The findings are very relevant to the NAS community. Rather than searching over all the operations and  spending a lot of computational effort during the search, by using all the operations, it is better to search on a subset if we know it is more promising\n2. By showing that skip connection is crucial for training as a residual connection, they point out that same intuition behind the designing of ResNet. \n3. Although the authors did not mention this, reducing the number of operations search space alleviates the problem of the ranking of the architectures sampled from supernet  based on their weight-sharing accuracy and the ranking of the same architectures when trained from scratch is not highly correlated. This has been plaguing the community and one of the solutions is to gradually pruning the less importations operations on an edge as the training proceeds. \n\nAdditional experiments requested:\n1. Could you create an additional table by running Darts and Bananas (and other NAS algorithm of if you have more time) on PrimSkip search space for Cifar 10 and transfer it to Imagenet space and see what the best accuracy is? How much is the run time reduced by? \n2. For Darts, what is the correlation of the ranking between the architectures based on their Supernet accuracy and that when trained from scratch in PrimSkip search space and the original darts search space? \n\nWeakness:\n 1. The only issue is the reliance on the surrogate model. In Figure 10(b), they did train the architectures, but 30 is very small to make a conclusive decision.  Also, for figure 10(a), could you increase the networks to 100?\n",
            "summary_of_the_review": "This paper focuses on an important topic of understanding the search spaces better. In addition to developing new algorithms, one also needs to investigate the characteristics of the search space and how one can improve it.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper analyses cell-based search spaces for neural architecture search based on the NASBench301 dataset. The main finding are that a) only a subset of the operations actually contribute to the final performance and b) well performing architectures exhibit common patterns from the literature (e.g res-net style motifs), questioning whether we actually find entirely new configurations with current search spaces.",
            "main_review": "\n# Merits\n\n- The paper addresses arguably one of the main challenges in current neural architecture search, the search space design. The provided results question the popular argument that a higher dimensional search space is automatically more expressive and leads to new promising architectures.\n\n- While one could argue that experiments are based mostly on the NASBench301 surrogate model, I do think they are sufficiently reliable. First, the surrogate models has been shown to provide reliable predictions and, second, the paper shows the same results emerge on a subset of architectures trained on the original data.\n\n- Even though I honestly found the results of the paper less surprising, I think the paper has a high chance to impact the future development of new search spaces\n\n- Overall I found the paper well written and easy to follow. Also, the proposed techniques to analyse operators and subgraphs seem sensible.\n\n\n\n\n# Concerns\n\n- The paper focuses mostly on the DARTS search space and NB201, which is a simplified version of the former. However, other search spaces (e.g NB101) assign operations to nodes instead of edges which might exhibit different properties than DARTS based search spaces. While I do not think that it effects the main findings, it would be great if the authors could comment on that in the paper.\n\n- I haven't fully understood how you account for the bias towards simpler subgraphs in your subgraph-level analysis in Section 4. How does this reference set of architectures with randomly sampled operations correct this bias?\n",
            "summary_of_the_review": "The paper points out several shortcomings of cell-based search spaces which are arguably the default in neural architectures search. In the long run, I think the paper can have a significant impact and help us to define better search spaces.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper strongly criticized the current cell-based NAS approach is limitiing research in NAS. The main points are:\n1. Redundancy in the cell-based search space: Performance of architecture is mostly attributed to a few important operations, while the 'unimportant' operations only add complexity to the search space. Essentially, the high-performing models share similar sub-graphs.\n2. Constrianting cells to similar patterns yields better results: By limiting the search space to important operations and similar sub-graphs, random sampling in NAS performs on par with most other NAS algorithms.",
            "main_review": "Pros:\n- Comprehensive studies on the DARTS search space, particularly operation importance and common subgraphs. These anlysis in a sense expose that redundancy and diversity issues that exist in the cell design of DARTS.\n- The paper gives some suggestions in the design of search space and benchmark for NAS: 1) search (grow the search space) and prune (remove redundancy). 2) focus on macro design choices rather than cell design choices.\n- Originally I am skeptical about using surrogate benchmark, as using predicted performance may draw biased conclusion on operation importance etc. The paper did verify this as seen in Figure 5 and Figure 10 (b).\n\nCons:\n- **Open questions are not discussed**: Despite many interesting findings, the authors left many questions in the end. What is a good search space? Can the authors suggest a list of good practices when designing a search space? \n- **Mainly based on NAS-Bench-3 / DARTS search space**: The analysis is mostly based on the DARTS cell. This show that problem exists in the DARTS search space, but it doesn't suggest that cell-based search space suffer from the same problems. As the authors also mentioned in the appendix, redundancy in NAS-Bench-201 is less significant. For example, the skip constraint does not impact the performance as much as DARTS.\n- **Merit of cell-based search space**: The paper heavily criticizes the cell-based search space. However, I am not convinced that the existing cell-based search space is not valuable. It is ideal if we can find SOTA model in the search space, but the main point of NAS search space is to provide a fair common ground to compare NAS methods. \n- **Operation importance**: Related to the previous point, the search space provides design trade-off but the operation importance is not considering this aspect. For example, one may find a model with better FLOPS or latency. Would the 'unimportant' operations such as pooling actually contribute to reducing computation cost?\n",
            "summary_of_the_review": "The findings in this paper are inspirataional. However, the analysis is limited to particular search space which doesn't mean that the cell-based approach is not valuable in general. The paper is trying to provide some insights on search space design but I would like to see more elaboration in this direction for this paper to be accepted.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Summary:\nThis paper studies the DARTS search space using predicted results from NAS-Bench-301 and presents several findings that suggest that SOTA performance on CIFAR-10 can be obtained via a relatively small subset of the space. They leverage these findings to suggest a simplified search space in which random architectures achieve strong performance and also to give suggestions for future development of NAS algorithms.",
            "main_review": "Strengths:\n1. Reducing the complexity of search spaces in NAS is a strong motivation.\n2. The authors identify multiple interesting redundancies that may help influence future designs.\n3. Paper is reasonably easy to read, although numerous grammatical errors (see comments for just the first part).\n\nWeaknesses:\n1. It is not at all clear how a result like this generalizes beyond CIFAR. While it is clear that, if the goal is to search for the best architecture on CIFAR, then reducing the search space in this way is useful. However, the point of CIFAR is really just to be a testing ground for algorithms run on other tasks. On those it is entirely unclear that the less useful operations will still not be useful; for example, larger dilations are good for sequence modeling while max-pooling is important for local invariance. The focus on CIFAR is interesting as a baseline but does not give evidence that these restrictions would work on other datasets.\n2. Another missing component is the question of compute time/energy use, which depends on the topology and operations. Many search spaces focus on more efficient architectures, which may themselves be more redundant in the full space and thus will be ignored in this study.\n\nComments:\n1. [*This simplification reduces the search space (but still highly complex),*] Unclear parenthetical.\n2. [*it is fair to state that such cell-based spaces currently dominates.] -> dominate\n3. [*high-level patterns only (Shu et al., 2020; Zela et al., 2020) We*] Missing period.\n4. [*NAS paradigms such as transformers*] -> Transformers\n5. [*Note that we may not obtain NB301 performance prediction on these architectures, as NB301 requires all 16 operations to be enabled with valid primitives.*] This does not make sense to me. If NB301 contains all architectures in DARTS, surely it contains those that do not have any of the removed operations.\n6. [*Fig. 4 shows that the OI distribution across all primitives are centered close to zero in reduce cells: both suggest that reduce cell is less important to the architecture performance.*] Unclear how this shows the reduce cell is unimportant, and not that it contains redundant operations.",
            "summary_of_the_review": "While the discoveries in the paper are interesting and may be useful for searching CIFAR, it is entirely unclear how they extend to more practical NAS settings, e.g. tasks beyond CIFAR and constraints beyond just the DARTS search space. Indeed the findings may not be relevant if they do not hold in other settings NAS may be applied to. I view answering these questions as critical and so lean against acceptance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}