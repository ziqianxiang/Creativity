{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The authors have done a good job methodologically addressing reviewer concerns. The empirical results are good, and the application impact is clear. There were some concerns about the technical heft of the approach, but there's overall agreement that the effective application to the domain is interesting and done very well. The AC is a bit concerned about the impact of the regularities of the domain used on the results, especially with regard to semantic regularities (homes have very particular regularities). But even without answering this question (it should be discussed in the camera ready though), this paper makes a solid contribution."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors propose a self-supervised representation learning method called environment predictive coding inspired by the context prediction in other representation learning works. This explicit spatial conditioning encourages learning representations that capture the geometric and semantic regularities of 3D environments. The learned representations can be used for downstream navigation tasks, achieving higher sample efficiency over standard image-representation learning.\n",
            "main_review": "Strengths:\n- This paper is a resubmission from last years’ ICLR, from what I can see many of the concerns from previous reviews have been addressed, and the paper has been thoroughly revised. To highlight:\n  - Many new baselines are added, SMT(Moco) is an interesting baseline showing that just with image-based representation learning it doesn’t perform so well. ANS is a very competitive baseline for exploration tasks.\n  - More tasks are added, especially the semantic navigation tasks. \n  - Added different exploration strategies \n- With the added experiments and baselines, the experiments and analysis are very thorough\n- The paper is generally well written and easy to follow.\n- The ablation study is very informative, it shows that using spatial conditioning is important for SSL for embodied tasks. It can provide guideline for the general recipe for pretraining embodied agents. \n\nWeaknesses:\n\n- “We learn the representations on a collection of video walkthroughs” is somewhat misleading, since the video walkthrough contains poses and people would think of video walkthroughs as those “house touring videos”. The authors said later “We now realize this process in photorealistic Gibson scenes; we leave leveraging in-the-wild consumer videos as a challenge for future work.” \n- It would be interesting to use the poses from visual odometry, apart from adding noise in ablation study 2. This will further lift the assumptions on walkthrough videos with pose\n- The authors should probably adapt ANS to make it work with the stop action, instead of letting it trivially fail.\n- (minor) In figure 5 different baselines seem to have different steps. Also the SMT (MoCo) doesn't seem to be converged yet.",
            "summary_of_the_review": "This is a good paper with thorough experimental analysis. It is significantly improved from the previous version and I would recommend accepting it. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The work builds upon the scene memory transformer (SMT, Fang et al., 2019) for visual navigation, which encodes and adds past observations to a memory and uses attention to exploit spatio-temporal dependencies.\n\nThe authors propose a self-supervised pre-training for the observation encoder using an encoder-decoder architecture with the encoded memory as the bottleneck (the decoder is only used for pre-training). Self supervision is achieved by using sequences of observations (posed RGBD images) and splitting them into batches of temporally consecutive frames (termed “zones” in the paper). Considering a subset of the zones as not observed, i.e. not available as input for the network, the goal of the encoder-decoder is to predict the features of an unseen zone from the seen input zones, conditioned on the pose of the unseen zone.\n\nCompared to a frame based masking, the zone (=spatio-temporal consecutive frames) based exclusion of data results in less overlap between seen and unseen scene parts, which is argued to learn higher-level semantic and geometric representation of the 3D environment\n\nContributions:\n- Approach for self supervision based on the prediction of visual-geometric features for unseen scenes.\n- Superior performance to SoTA on the navigation task.\n",
            "main_review": "**Strengths**\n\n***S1***: Pre-training aims at exploiting the higher level semantic & geometric features of an environment by predicting a scene representation \\hat(f)_i^u that should not have been observed before, such that lower, image-level interpolation of frames (without reasoning of semantics) is prevented. This is an interesting concept, which is applicable to many reasoning tasks.\n\n***S2***: Good experimental evaluation and ablation study including the SMT architecture with different pre-training techniques. This comparison demonstrates the usefulness of the proposed “environment-level” pretraining.\n\n***S3***: SoTA results on the chosen datasets for various robotic visual navigation tasks.\n\n\n**Weaknesses**\n\n***W1***: Insufficient argumentation and analysis for the proposed zone based masking approach.\n\nIt is argued that a (random) frame based masking “can result in poor representation learning since shared content from nearby unmasked frames can make the prediction task trivial”. A simple spatial sampling of frames would ensure that the visual overlap is minimized. The zone decoder would then become a frame decoder which predicts features for a masked frame, conditioned on the pose of the masked frame. This would still qualify as learning an “environment-level” representation as blending/inpainting is not possible. A comparison to such an approach is missing. The argument that zones result in a higher-level representation is not verified. Therefore, the advantage of using zones over frames in the pre-training is not at all clear.\n\n***W2***: The definition of zones solely on the number of frames does not account for the motion of the camera and thus does not avoid overlapping of zones.\n\nE.g. if the camera stands still for >N frames, then consecutive zones capture the same scene part and zone feature prediction based on the pose seems trivial. A definition of zones based on the camera pose (and not necessarily consecutive frames) would be more convincing, as it aims to minimize scene overlap.\n\nThe paper does not make any analysis of different zone selection strategies and the amount of overlap between seen and unseen zones is unknown. Though, this is important, as the authors argue that their zone based masking is superior to a frame based masking because of the reduced overlap (see W1).\n\n***W3***:  What prevents the zone decoder from ignoring the environment embeddings Epsilon and predicting \\hat(f)_i^u as only an embedding/projection of p_i^u?\nGiven that the supervising f_i^u is built from the RGBD frames AND their poses, see Eq. (2), this seems to be the trivial solution; i.e. the MLP would ignore the visual content X and just rely on the poses. The paper would benefit from explaining the choice of supervision better and in particular point out why the features f are a good choice for supervision.\n\n***W4***: The idea behind the usage of an egocentric view, i.e. usage of relative over absolute poses, is unclear.\n\nIn pre-training the poses of frames of seen zones are relative to the mean pose p_i^u of the unseen zone. When plugging the pre-trained encoder in the SMT architecture poses relative to the query o_t can still be used during training (unclear if this is actually done). Though, during inference o_t changes, which would require to update the relative poses of all previous observations and re-encode them into “environment embeddings”. This seems largely impractical. In contrast, one would only want to encode an observation once which argues for a scene-centric coordinate representation, e.g. use the first frame’s pose as reference.\n\n***W5***: Experimental evaluation on the very same dataset as the baseline SMT work is not provided.\n\n**Comments**\n\n***C1***: In Fig. 3 left it is illustrated that all frames of a zone are fed to a MLP, while it should be per frame to obtain the image-level embeddings. \n\n",
            "summary_of_the_review": "The paper presents an interesting idea for self-supervised pre-training of the encoder stage of the SMT architecture. The conceptual approach is not limited to visual navigation but applicable to a variety of (3D) reasoning tasks.\n\nThe paper lacks clarity in the details of the approach, see above weaknesses W1-W4. With that I’m concerned that the proposed masked-zone prediction task (which is the core contribution of the paper) is a good choice for handling the pre-training. While the approach achieves SoTA on the visual navigation task there are only limited learnings but numerous uncertainties for the reader why this is so.\n\nI would be willing to increase my rating, if the above weaknesses are addressed and it is shown that the proposed masked-zone pre-training is superior to alternative encoder pre-training approaches..\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The main contribution of this paper is a method for learning a spatial representation of an environment, called environment predictive encoding, that can be used for pre-training a network in an unsupervised manner for downstream embodied tasks such as navigation. The results show that the method significantly improves the sample efficiency of four common downstream tasks.",
            "main_review": "Please find below a detailed review of the strengths and weaknesses of the paper.\n\n**Strengths**\n\n- The paper addresses a challenging and pertinent problem i.e. how to learn representations of large environments that can help high level tasks. I think the approach is well-designed. I strongly agree with the hypothesis that pose information should help with learning representations grounded in 3D space, and the paper does a good job at verifying this hypothesis.\n\n- The experimental evaluation is really well done in almost all aspects. The authors have picked very good datasets to evaluate on that are challenging and representative of real-world applications. The tasks they have picked clearly demonstrate the advantages of the epc method and have practical interest. The methods against which the proposed approach are compared are appropriate. The ablation study is also excellent. I think the questions that the authors raise and answer in the ablation study are very relevant and helps to show why the specific components of the method (such as the spatial conditioning) are necessary. Overall, the experimental evaluation is well thought out and demonstrates the advantages of the method.\n\n- The results are very promising. The pretraining using EPC seems to help across all the tasks tested on and the improvement is statistically significant.\n\n\n**Weaknesses**\n\n- The main weakness of the paper is that there are lots of works in computer vision on “place recognition” (see [A]). In general, these methods also groups areas into “zones” and learn representative features of each zone. How would the proposed EPC features compare to those learned by a place recognition method such as [B]?  Also, a very related method is that of [C]. It would be good to include a discussion on this approach and how it compares.\n-  It would be good to show how the zone segmentation affects the performance of the method. Does it matter where the zone boundaries are chosen?\n\n[A] Lowry, Stephanie, et al. \"Visual place recognition: A survey.\" IEEE Transactions on Robotics 32.1 (2015)\n\n[B] Chen, Zetao, et al. \"Deep learning features at scale for visual place recognition.\" 2017 IEEE International Conference on Robotics and Automation (ICRA)  2017.\n\n[C] Lenton, Daniel, et al. \"End-to-End Egospheric Spatial Memory.\" International Conference on Learning Representations (ICLR) 2021.\n\n",
            "summary_of_the_review": "Overall I think this is an excellent paper that presents an idea that is both simple, practical and effective. The method is well validated on two challenging benchmark environments, MP3D and Gibson, and compared against numerous state of the art approaches and achieves great performance. In the response, i would like the authors to address the points in “weaknesses” above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper focuses on the problem of efficiently training an intelligent embodied agent for navigation purposes.\nTechnically, the manuscript introduces a technique named as Environment-Predictive Coding (EPC). It is a model for learning environment-level representations via self-supervision, just using video walkthroughs with masked zones. \nEPC proposes to learn an environment encoder, using a transformer-based encoding-decoding, that produces environment embeddings and that predicts feature encodings for the unseen areas. This is the main scientific contribution of the paper.\nThis environment encoder is finally integrated in the Scene Memory Transformer (SMT) (Fang et al., 2019) for navigation purposes.\nA thorough experimental evaluation is offered, using Matterport3D (MP3D) (Chang et al., 2017) and Gibson (Xia et al., 2018) for 4 navigation tasks. Reported results seem to explain the benefits of incorporating such a self-supervision mechanism. ",
            "main_review": "Strengths\n\n+Related work section has been clearly written. It contains not only a complete review of the literature, but also a clear discussion on why the proposed ideas are different from previous works.\n\n+Clarity and the way the article is written are two of its strongest points. Introduction has been nicely written, positioning the work clearly, and highlighting the main contributions. The figures and diagrams are quite elaborate, and help to understand many of the ideas proposed. Sections 3 and 4 do not skimp on details. Overall: good work!\n\n+The experimental evaluation design allows the impact of the proposed ideas to be assessed. Two different datasets are used, multiple baselines are reported, an ablation study with clear questions about possible limitations of the model, etc. Both SMT (MoCo) and SMT(Video) baselines are really informative. I appreciate when the experiments focus on trying to confirm the hypothesis proposed, and not only on beating a state-of-the-art performance.\n\n+As for the results, they look promising. Both WE and SE strategies, combining SMT with EPC, seem to lead the SMT model to provide better results on several problems.\n\nWeaknesses\n\n-Paper's strongest point is not originality. \na) In this work, the scene completion problem is addressed simply using a standard transformer encoder-decoder model. An MLP is employed to obtain image-level embeddings. No significant novelty is found in the formulation of the zone decoder. All these elements are trained end-to-end following a previous contrastive loss learning approach (Gutmann & Hyvärinen, 2010). I focus on judging the novelty of the article, dissecting the EPC module, because this is the main contribution. Overall, EPC is a standard trasformer encoder-decoder trained to learn and embedding of some selected features (those belonging to the marked/masked zones).\nb)The other contribution is also incremental. The encoder learned by EPC has simply been integrated into the SMT model, which is the one that performs all the navigation tasks.\nI would like the authors to offer a clear argument about the novelty of their paper for a conference such as ICLR.\n\n\n-The application of the EPC model to other non-SMT architectures remains unresolved. Although this is claimed in different parts of the paper, NO experiments are provided to support this claim. In my opinion, the proposed model will fit only in transformer-based solutions such as SMT. It would be useful to hear from the authors on this issue (has it been tested with any other architecture?). Perhaps some of the assertions made in the article might be relaxed.\n\n-Something similar occurs with the type of videos used to train the model. To conjecture that any videos of building walks could be used to train the model, and not those provided by the datasets used, is also not supported by the experiments provided.\n\n-There is another aspect for which I also find no evidence in the experiments, and which appears throughout the manuscript. Overall, the paper sells the idea that the proposed module is able to \"predict the spatial structure of 3D environments\". This claim is too ambitious in my humble opinion. The model is able to predict features for those masked zones. From here to understanding that the model predicts the 3D structure of the environment is a big leap. Moreover, no experiments are provided to support this claim. My advise: to revise (and relax) all those affirmations for which no experimental evidence is provided.\n\n\nMinor comments:\n-Figure 2 is difficult to follow, too many details in it.\n-Please, punctuate all the equations. They are part of the text.",
            "summary_of_the_review": "I like the work the authors have done with the article. I don't think we have a model of great originality, but rather of an incremental nature. However, the ideas are clearly stated, and the experiments are well designed and executed. I need the authors to defend their position on my criticisms of the novelty of their ideas, and to comment on those parts for which I have not found experimental evidence. Overall: I see here a borderline submission.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}