{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes a new architecture for point cloud processing, with good empirical results. All reviewers recommended accept. AC does not see a reason to overturn the consensus."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposed an alternative point cloud feature extractor, named PointMLP. PointMLP is composed of residual MLPs and geometric affine modules. Classification results on ModelNet40 dataset show the proposed methods achieves slightly better accuracy while using much smaller number of parameters and faster runtime. The proposed method achieves better accuracy in classification results on ScanObjectNN dataset and is on par with state-of-the-art methods for 3D shape part segmentation task on the ShapeNetPart benchmark.",
            "main_review": "The proposed PointMLP achieves better accuracy while being simple and faster. This is not surprising. Empirically for point cloud processing I also found a lot of 'sophisticated' networks can be easily outbeat by much simple networks with tuned #layers and #channels. \n\nMy biggest concern for this paper is the lack of novelty and depth of this paper. It simply present the model and results, without telling why this simple model can outperform other delicately designed networks. This is more like a technical report.\n\nSeveral claims made me confused:\n1. 'even without the carefully designed operations for local geometry exploration': geometric affine module still uses local geometry. Did you compare PointMLP w/o geometric affine module with other models? I did not see any evidence that networks without local geometry exploration work better.\n2. in part segmentation task, 'our method can achieve the best accuracy-speed tradeoff'. I did not see any speed comparison.",
            "summary_of_the_review": "My biggest concern for this paper is the lack of novelty and depth of this paper. I still give a positive review because I got sick of papers that boast about their fancy design but in reality cannot outperform a simple network. \n\n\n==========================================\n\nBased on other reviewers' comments and the authors' responses, I would like to keep my original score.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors present a refinement of PointNet++, called PointMLP, in which the MLPs using in the local feature extractions in PointNet++ are replaced by residual MLPs. Together with a lightweight geometric affine module to stabilize the training, PointMLP outperforms previous models in the classification tasks on ModelNet40 and ScanObjectNN.",
            "main_review": "*Strengths*\n- The paper is very well-written and easy to read.\n- The architecture of PointMLP is simple for implementation. Since PointMLP is mainly based on pure residual MLPs, we can take advantage of the efficiency from the highly-optimized MLPs when training PointMLP.\n- PointMLP outperforms previous SOTA models on ModelNet40 and ScanObjectNN.\n\n*Weakness*\n- As PointMLP is a refinement of PointNet++, I do not think the novelty of the idea is high.\n- The performance of PointMLP is comparable with CurveNet on ModelNet40. In my opinion, the improvement by 0.3% is not significant.\n- The results of the PointMLP in part segmentation task on ShapeNetPart are worse than the old architecture KPConv.\n\nSome more comments and questions:\n- Page 4, line 3: the local feature extraction of PointNet++ is formulated as\n$$g_i = \\mathcal{A}( \\{ \\Phi(f_{i,j})|j=1,...,K \\} ).$$\n- Similarly, in equation (4), the local feature extractor of PointMLP must be\n$$g_i = \\Phi_{pos}(\\mathcal{A}( \\{ \\Phi_{pre}(f_{i,j})|j=1,...,K \\} )).$$\n- Why the small $\\epsilon$ in equation (5) can stabilize the numerical computation?\n- The authors claim that PointMLP is much faster than KPConv in part segmentation tasks. But I do not find anywhere in the paper nor the tables that support this claim.\n- I am not sure if the performance of recent models based on sophisticated local geometric extractors is saturated or not as more and more efficient and accurate models of these kinds are still being investigated. Furthermore, as we see in the experiments, PointMLP does not outperform the previous SOTA model with significant margin (on ModelNet40 and ShapeNetPart). Therefore, stronger reasons are needed to support the claim that \"detailed local geometrical information probably is not the key to point cloud analysis\".",
            "summary_of_the_review": "Since the idea of PointMLP is quiet simple and it can be considered as a refinement of PointNet++, I do not think that the novelty is very high, although the experiments show some interesting results.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces a lightweight and fast neural network architecture processing 3D point cloud. While the idea is quite simple, the proposed architecture outperforms or matches the performance of the previous architectures in terms of both accuracy and also inference time with various tasks including ModelNet40 classification, ScanObjectNN classification, and ShapeNetPart segmentation, as shown in the experimental results. The main idea is to make two modifications in the PointNet++ architecture, 1) adding MLP layers after each of the point feature aggregation (max-pooling) steps, and 2) applying a geometric affine transformation to the features processed with an MLP in each small PointNet module. It's interesting to see that these small modifications (especially the second) make dramatic changes in the results.",
            "main_review": "The strength of this paper is the outperforming results and fast inference speed of the proposed method compared to most of the previous methods in various tasks, especially for a challenging task like classification with ScanObjectNN data. Also, the architecture seems very easy to implement from a PointNet++ code.\n\nBut, I also have several questions that I hope to be addressed by the authors in the rebuttal:\n\n- What is the \"voting\" in the experiments? (E.g., w/o vot and w/ vot in Table 2)? I couldn't figure out what this voting meant.\n- In Table 2, It seems the accuracy difference between CurveNet (Xiang et al., 2021) and the proposed method is marginal, while CurveNet is much lighter and faster. Also, the results of CurveNet seem to be without voting, so I guess there might be a chance for CurveNet to improve the accuracy if it uses the voting. What would be the other advantages of the proposed method compared to CurveNet? Would it be easier to implement? What happens if the proposed method is compared to CurveNet in the task of ScanObjectNN classification (Table 3) and ShapeNet classification (Table 6)?\n- Why is the proposed method lighter and faster than PointNet++? Is it because of the residual connections? What happens if only the residual connections are used in PointNet++?\n- It would also be great to see in Table 5 what happens when only one of the components in the columns on the left is used.\n- Wouldn't it be possible to apply the geometric affine transformation (Equation 5) to any other architectures (compared in Table 1, for example)? It seems like this is the core module improving the performance.\n\nThe followings are also comments/questions about correction/clarification:\n- What are the exact meanings of 24-Layers, 40-Layers, and 56-Layers in Figure 3 and Table 4? Is the number of MLP layers in \"each\" stage of the architecture shown in the appendix?\n- Is having the post-MLP (\\Phi_{pos}) the same as having a deeper pre-MLP in the intermediate stages, and adding an MLP at the end of the last stage? The effect of this post-MLP also seems marginal when seeing Table 5.\n- In Equation 5, shouldn't the (f_{i,j} - f_i)^2 be a squared norm (\\| f_{i,j} - f_i \\|^2) so that the \\sigma becomes a scalar? The text says that f_{i,j} and f_i are d-dimensional vectors.\n- In Section 3.2. our PointMLP still performances efficiently -> our PointMLP still performs efficiently.\n- In Equation 3, the symbol with a circle and a dot is not introduced in the text.\n",
            "summary_of_the_review": "I think this work introduces an interesting finding that small modifications in PointNet++ make dramatic changes in the results. But, more analyses would be needed to clearly see how each component in the proposed method (post-MLP, geometric affine, residual connections) affects the accuracy and inference time. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No issues.",
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}