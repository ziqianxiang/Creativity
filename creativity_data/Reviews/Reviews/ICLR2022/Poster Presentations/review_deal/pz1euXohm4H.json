{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper presents a method for target side data augmentation for sequence to sequence models.  The authors of the paper use a relatively straightforward method to generate pseudo tokens that are used for enhanced training.  The authors present results on dialog generation, MT and summarization where automatic metrics show improvements.  For really robust results, I would have preferred to see more human evaluations since BLEU and ROUGE are metrics that the NLP community is moving away from.  Overall, the majority of the reviewers are happy with the paper and there is significant back and forth between the reviewers and authors that have improved the paper;  I think the authors went to significant lengths to allay all concerns from the reviewers and the paper should be accepted."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper introduces a simple technique for target-side data augmentation. The high-level idea is to generate a \"soft token\" embedding by interpolating the target side word embeddings, with the output distribution generated by an initial model being the interpolation weight (after being adjusted by a temperature parameter $T$). The resulting training loss is in three terms: (1) original cross-entropy loss; (2) cross-entropy loss with the soft token embedding as the input; (3) a consistency loss controlling the distribution divergence of (1) and (2).\n\nResults show that the proposed data augmentation method is very helpful for the dialog generation task, while also being somewhat helpful with neural machine translation for abstractive summarization. Ablation studies show that the weight of (1) cannot be too low, and that the optimal temperature parameter has some negative correlation with the vocabulary size.",
            "main_review": "Strengths:\n+ The proposed technique is generally applicable to various NLG tasks.\n+ The paper is nicely-structured and very well-written. I like the presentation style of the paper -- a good mixture of formulas for mathematical rigor and textual/graphical explanations of the intuitions behind them.\n+ Experiments span three different generation tasks, showing the general benefit of the proposed augmentation technique, with a detailed ablation study on the sensitivity of some hyper-parameters.\n\nWeaknesses:\n+ The improvements in machine translation and abstractive summarization are marginal compared to other augmentation techniques, but this is not a non-fixable issue, see the first point in my detailed feedback.\n+ I imagine this augmentation method will be computationally expensive, since at every time step $O(|V|d)$ extra additions need to be done ($d$ being the number of word embedding dimensions). It will be useful to have some discussion on that. I also think the number of extra operations can be easily reduced by sparsifying the softmax distribution before doing the embedding interpolation.\n+ I have some minor doubts about the real-world usefulness of the method. For example, for machine translation, isn't this doing a similar job as back-translation?\n\nMore detailed feedback/suggestions:\n+ In the machine translation experiment, the authors compared their method with a series of other data augmentation methods such as WordDrop and SwitchOut, but I think they don't necessarily need to compete with each other -- how about, say, we use SwitchOut on the source side and the proposed augmentation method on the target side? Showing that the proposed method is stackable with other augmentation methods could make this work more impactful.\n+ Continuing on the previous point, it will also be interesting to see if the proposed method is also stackable with back-translation when extra monolingual data is provided, especially since the authors have already considered multi-round enhancement.\n+ Page 3: \"It may also contains\" -> \"It may also contain\"\n+ Page 4: Equation (4) -- should there be an extra summation over $j$?\n+ Page 8: I'm actually not sure why would higher temperature $T$ be helpful under smaller vocabularies. It would be nice to elaborate.",
            "summary_of_the_review": "This paper proposed a simple and novel target-side data augmentation technique that is at least helpful for some natural language generation tasks. I'm going with a weak-accept for now citing some doubts mentioned in the main review, but am happy to update with clarifications from the authors.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Traditionally, the decoder of Seq2Seq model takes ground truth words of previous steps as input during training, while at inference, its input are those generated tokens starting from scratch.\nThus there exists discrepancy between training and inference.\n\nThis paper presents an approach of data augmentation for the input of the decoder during training. \nSpecifically, the authors still feed the ground truth to the decoder, and then obtain its output vocabulary distributions that are multiplied with word embedding weights to get \"pseudo tokens\".\n\nThe contribution of this work comes from narrowing the gap of decoding procedure between training and testing.",
            "main_review": "### Strengths:\nThis paper presents an approach to tackle an important problem in the field of natural language generation.\nIts method is straightforward and well illustrated.\nFurthermore, the paper adheres to scientific standards as the authors release their code.\nIt is also very much appreciated that they illuminate and evaluate their model in different text generation tasks. \nFurthermore, the experimental results demonstrate certain improvements in these tasks.\n\n### Weaknesses:\nMy main concern with this paper is that since the augmented target-side input is produced by the decoder conditioning on the ground truth, this method seems helpful but limited.\nGenerally, given the ground truth, the model produces the target text that is quite similar to its corresponding ground truth, and the discrepancy between them is subtle.\nThus it still cannot narrow the gap of decoding between training time and inference time.\nThe modest improvements in the NMT task and abstract summarization task also indicate the existence of this problem, and cast doubt on its effectiveness.\n\n### Questions for the author(s):\nQ1. As far as I know, in the NMT task, en-->de newstest2014, the best BLEU result for \"OR-NMT\", \"Transformer+Cutoff\", \"Adversarial Training\" are 28.65, 29.1, and 29.52 in their corresponding papers respectively.\nAre there any mistakes?\n\nQ2. The usage of \\alpha on Eq(2) contradicts that on Eq(4)?\n\n",
            "summary_of_the_review": "Overall, this work tries to tackle the important problem of language generation and proposes a data augmentation method to give soft pseudo decoder input.\nAs what has been mentioned in the weaknesses part of Main Review, there still exist problems to solve and need to prove the effectiveness of such method. Therefore, I'm leaning towards a weak rejection of this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper experiments with a target-side sequence-level data-augmentation scheme for sequence-to-sequence generation tasks. The primary contribution of this work is an algorithm that leverages model-outputs to construct pseudo-target-side tokens (and consequently pseudo-sequences) for augmentation. It is done by incorporating soft-embeddings in the encoder-decoder model, a standard cross-entropy loss function supercharged with a consistency loss objective. One of the critical highlights is that this work doesn't require any external model for performing data augmentation. A comprehensive set of experiments on three sequence generation tasks are conducted to highlight the effectiveness of using such an approach for data augmentation.",
            "main_review": "Strengths: \n1. Comprehensive Experiments on three different domains - Dialog, Summarization, and Machine Translation.\n2. Data Augmentation doesn't require access to other resources than the primary model\n\nConcerns/Questions:\n- Renaming Sequence Generation to Sequence-to-Sequence Model (Or Encoder-Decoder) Generation since the domain is restricted to that in this work. Although sequence generation through Language Models might use a similar scheme, this work hasn't been experimented with.\n- Section 2: Comparison with KD: Our method focus on target input, not target output. This part is not very clear. If target output changes, doesn't it also affect target side inputs?\n- Why is training not stabilized with just equation (3). How do you define stabilization of training? Why does consistency loss make the training stable?\n- Number of turns in Tables 1, 2?\n- Is the number of training passes equal for all the methods in Table 3. If not, can it be standardized? It seems like the \"Ours\" model is trained through more passes of the dataset (+ augmentation)\n- Table 4 and 5: Are the results statistically significant? Would you please report those values?\n- Section 4.3: we select the BART to initialize our model, and fine-tune on the CNN/DM -> We fine-tune the BART model on the CNN/DM dataset\n- Section 4.4 [And consequently Table 6-9]: Ablation Study section is not an ablation study, which ideally involves removal of proposed changes [in terms of modeling changes or objective functions]. It seems more like hyperparameter tuning.\n- Section 4.4: How is the value of 55 chosen in $\\alpha$ tuning?\n- Table 10: What happens when \\beta = 0 ? Does the model empirically display stability issues (as mentioned earlier in the motivation for consistency loss)?\n- Study of divergence -> What is the intuition of doing this? Why does KL work better than JS? JS is symmetric, so shouldn't it help?\n- Improper use of \"significantly boost the model\" performance in conclusion when no statistically significant studies have been conducted.\n- Generative tasks require human judgments for proper analysis. Kindly evaluate that.\n- Future Work - \"how to combine this method with unlabeled data is also a significant challenge\" - Why is that so? I believe that the current model also does not utilize any labeled data. Would you please correct me if I am mistaken?\n\n\nTypo/Correction needed:\n- Section 2: Comparison with Iterative Refinement or NAR strategies: Claim about inference cost is incorrect since autoregressive methods are known to be slower than NAR.\n- Equation (3) -> There should be a negative sign in the loss function\n- Capitalize: Rouge -> ROUGE at all places",
            "summary_of_the_review": "The work proposes a data-augmentation strategy using soft labels during training instead of hard labels as in scheduled sampling.  One of the key highlights is that this work doesn't require any external model for performing data augmentation. However, the need for consistency loss is unclear, and using this model is not observable. While the paper reports incremental results, the lack of significance testing makes it difficult to comprehend if the results are not by-chance. The ablation study section is not an ablation study but hyper-parameter tuning. Additionally, the lack of experimental details regarding the number of examples seen by each model during training (number of epochs * samples) makes it unclear if the incremental results are due to more extended training or the overall augmentation strategy. \n\nIn its current form, and based on the reasons stated above, I would recommend a weak reject for this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper focuses on sequence generation tasks and proposes to perform data augmentation on the target side. During training, given an input-output pair ($x$, $y$), their model first uses teacher-forcing to get the output probability $p_y$ and then gets an augmented pair ($x$, $\\tilde{y}$) by using \"mixup\" to mix the embeddings of $y$ and $p_y$. They also propose to encourage the consistency of predictions between ($x$, $y$) and ($x$, $\\tilde{y}$) by minimizing the KL divergence of their output probabilities.\n\nThey experiment on three sequence generation tasks and demonstrate improvements over baselines.",
            "main_review": "Strengths:\n1. The paper performs comprehensive experiments on three different generation tasks (i.e. dialog generation, machine translation, and abstractive summarization) and demonstrates improvements over baselines.\n2. Their idea of constructing the augmented data can be viewed as a fast approximation of scheduled sampling, which is technically sound.\n3. The paper is easy to follow. \n\nWeaknesses:\n1. They seem to perform ablation studies and choose hyper-parameters on the test sets.\n2. The paper keeps emphasizing that target-side data augmentation has been \"overlooked\" or \"neglected\" in sequence generation throughout the paper, while a lot of papers in this direction have been proposed (e.g. scheduled sampling [1], many RL-based methods [2,3,4], some heuristics [5,6], self-training [7], ...).\n3. The consistency loss is unintuitive and more analyses are required. If the model is trained to output the same targets on the two views, we are already encouraging the consistency between them, so why would an extra consistency loss be helpful here?\n4. The comparisons with baselines are not fair in some cases. The author(s) state that \"for a fair comparison with previous works, we compute the BLEU score by the Moses script \", but the scores obtained by this script depend on the tokenizer, which can be different in different papers and SacreBLEU (https://github.com/mjpost/sacrebleu) is recommended for a truly fair comparison.\n\n\n\n[1] Bengio et al., Scheduled sampling for sequence prediction with recurrent neural networks, NeurIPS 2015.\n\n[2] Norouzi et al., Reward augmented maximum likelihood for neural structured prediction, NeurIPS 2016.\n\n[3] Ranzato et al., Sequence level training with recurrent neural networks, ICLR 2016.\n\n[4] Shen et al., Minimum risk training for neural machine translation, ACL 2016.\n\n[5] Sennrich et al., Edinburgh neural machine translation systems for WMT 16, WMT 2016.\n\n[6] Wang et al., SwitchOut: an Efficient Data Augmentation Algorithm for Neural Machine Translation, EMNLP 2018.\n\n[7] He et al., Revisiting Self-Training for Neural Sequence Generation, ICLR 2020.\n\n",
            "summary_of_the_review": "While I think their idea of augmenting the dataset is interesting and it does not introduce any inference burden, based on the weaknesses I mentioned above, I'm leaning towards a rejection of the paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}