{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "In this paper the authors proposes to use partial optimal transport to align point cloud in the presence of noise and partially observed data. To this end they express the partial Wasserstein Kantorovich-Rubinstein duality and use it to adapt the classical WGAN loss to partial OT. The optimal alignment between point clouds is then done by minimizing their proposed loss where the dual potential are modeled as deep neural network hence approximating the partial Wasserstein while being solved using mini-batches. Experiments show the interest of the method on a few well understood examples with ground truth from the Stanford repository. \n\nThe paper had originally borderline scores with some reviewers concerned about the theoretical contribution. The authors did a very good reply that that greatly appreciated by the reviewers, the one with the lowest score deciding to increase it. The new numerical experiments on the 3D human dataset were also appreciated. The consensus during the discussion was that the paper is worth accepting but that the authors should take into account the comments form the reviewers and better explain their contribution on the KR duality.\n\nFor these reason the AC recommends to accept the paper but urges the authors to take into account the comments from the reviewers. In particular the authors should better highlight their theoretical contribution and explain the link and differences with unbalanced minibtach OT."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper deals with  non-rigid point set registration via partial\ndistribution matching. The problem is formulated as\ncomputing partial Wasserstein-1 (PW) discrepancy between distributions of\nthe reference point set and of the transformed source point set.  As a\nmain feature, the paper derives the Kantorovich–Rubinstein dual form\nof the PW problem hence, allowing to lift the method to a large scale\nsetting. Overall the proposed method results in a min-max\nproblem (similar to Wassertein GAN) to learn the transformation function which minimizes the PW\ndiscrepancy. Empirical evaluations complete the paper. ",
            "main_review": " ***Strengths***\n- The paper  considers point set registration problem consisting in\n in learning a non-rigid transformation that matches a transformed\nsource set to a reference one while avoiding noisy points or outliers that do have\ncorrespondences in the other set.  To ensure the robustness of the\nmatching a partial distribution matching is sought using partial\noptimal transport.  Specifically the partial Wasserstein-1 (PW), where only a portion of the probability mass is moved,  is\nconsidered.\n\n- Two equivalent formulations are proposed, the plain PW problem\n  coined $\\mathcal{L}_{M,m}$ with explicitly mass constraint and the\n  \nrelaxed version $\\mathcal{L}_{D,h}$. The main results of the paper\n  are the derivation of the Kantorovitch-Rubinstein dual of both\n  problems. The dual is a constrained optimization problem\n  that involves a potential function defined as a neural network (NN). By\n  relaxation of the Lipschitz constraint on the NN, the dual  is amenable to a\ngradient framework and hence, to a large scale computation. \n\n- Learning of $\\mathcal{T}$ by minimizing the PW discrepancy with a\ncoherence regularization  leads to a min-max problem similar to  the\none of the Wasserstein GAN. The overall optimization algorithm is\ngiven.\n\n***Weaknesses***\n- As stated in the appendix, the Kantorovitch-Rubinstein (KR)  dual of  $\\mathcal{L}_{D,h}$ straightforwardly\nderives from (Lellmann et al., 2014; Schmitzer & Wirth, 2019). \nBy convexity argument, there exist $h \\geq 0$ such that problem  \n\n$\\mathcal{L}_{D,h}$ yields to a solution of problem\n\n$\\mathcal{L}_{M,m}.$\n\nHence, the dual Kantorovitch-Rubinstein  form of\n$\\mathcal{L}_{M,m}$ should follow. In that regard, the KR dual\nderivations of both PW problems appear issued directly from the\naforementioned works. This renders the main theoretical results of the\npaper rather incremental. \n\n- The relaxation  of the Lipschitz constraint on the NN implies that\n  the obtained dual objective function (even if the dual problem is\n  optimized to fully convergence) no longer represents the PW\n  discrepancy but an approximation. Hence, the gradient computation is biased and results in the loss of theoretical guarantees on the\nretrieved solution $\\mathcal{T}$ of the point set registration problem (3).\n\n- The paper lacks theoretical analysis of the convergence rate, the time\n  complexity of the PW computation.  In the same\n  vein, it lacks the comparison of the primal and dual solutions\n  (computation time, precision  of the PW losses) or the empirical convergence illustration of Algorithm 1.\n\n- It is not explicitly stated that Algorithm uses stochastic\n  gradient to gain in scalability. Nevertheless the paper does not\n discuss  reference  [1] dedicated to unbalanced minibatch optimal\n  transport (UOT) that can be a good alternative to the proposed method. [1]\n  established theoretical properties of UOT in presence of outliers,\n  in terms of gradient regularity hence the convergence property. How\n  the proposed method connects to [1]?\n\n- The transformation $\\mathcal{T}$ defined as an affine-like\n  deformation model is not fully explained nor justified. \n\n***Other comments***\n- How the final point set registration is obtained ? Does it require computing\n  the optimal transport map ? If so, how is it derived from the\n  prima-dual equation?\n- Report the means and the variances of the performances (MSE, computation time)\n  over the runs. That helps the reading of the results.\n- In Eq. (9), write $\\mathcal{T}_\\theta(y_j)$ rather than $y_j$.\n- In EQ. (19) $\\mathbf{G}$ should rather be $\\mathbf{G}_\\rho$.\n- In section 5.2 the number of samples is sufficiently reasonable to\nallow to compare primal solutions to dual ones in term of performances\nand computation time. This might highlight the efficiency brought by\nthe use of the dual form and better illustrates the trade-off\nefficiency vs precision. \n  \n***Reference***\n\n[1] Fatras, Kilian, et al. \"Unbalanced minibatch optimal transport; applications to domain adaptation.\" International Conference on Machine Learning. PMLR, 2021.\n\n**After rebuttal**\n\nI read authors rebuttal. They address some of the  raised points by  the review (use or not of stochastic gradient to gain in scalability, confidence interval of reported performances, better justification of the transformation $\\mathcal{T}$, gradient computation when relaxing the Lipschitz constraint...). \n\nThe strong point of the paper is the  KR dual form derivation of $\\mathcal{L}_{M,m}$ and this is not sufficiently highligthed in the paper. The authors should consider emphasizing more on that and better  highlight the novelty of the theoretical  KR dual form. During the discussion, the authors clarify how their approach connects to mini-batch regularized Unbalanced OT as promoted in Fatras et al. (2021) that solves the UOT problem in the primal.  This is also a good point. \n\nOverall the paper is  rather dense with almost 46 pages, the appendices  included. Nevertheless, provided aforementioned facts, I update my rating of the paper from 5 to 6. \n \n",
            "summary_of_the_review": "The paper proposes a theoretical and methodological framework to\nachieve robust  point set registration using scalable partial\nWasserstein based on the dual formulation. Their derivations somehow\nderive from existing works. To be efficient, the  algorithm\nrelaxes the\nLipschitz constraint hence, the overall algorithmic scheme lacks\ntheoretical  guarantees on the matched distribution. Also the paper\nlacks convergence, time complexity analysis of computing PW. Finally\nconnections to works related to minibatch unbalanced optimal\ntransport that can be competitors of the method are missing. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper deals with the problem of non-rigid point set registration, where a method for large scale partial distribution matching (PDM) problem is proposed by utilizing the partial Wasserstein-1 (PW) discrepancy.  The paper theoretically derive the Kantorovich–Rubinstein duality for the PW discrepancy, and show its gradient can be explicitly computed. Based on these theoretical results, the paper proposed a partial Wasserstein adversaria network (PWAN), which approximates the PW discrepancy by a neural network, and learns the transformation adversarially with the network. Experimental results on point set registration tasks such that the proposed PWAN is robust, scalable and performs more favorably than the state-of-the-art methods.",
            "main_review": "Strengths:\n\n+ The paper theoretically derives the Kantorovich–Rubinstein duality for two types of the PW discrepancy, i.e., the distance-type and the mass-type discrepancy\n\n+ The paper propose PWAN, for large scale PDM problem. \n\n+ Experimental results on the point set registration task prove that the proposed PWAN is robust, scalable and performs more favorably\nthan the state-of-the-art methods\n\nWeaknesses:\n\n-  The paper is rather dense, which may to some extent not well self-contained.\n\n-  The paper only evaluated on the point set registration task, other related task such as 2D shape matching could be exploited.",
            "summary_of_the_review": "The theoretical contributions are justified with experimental evaluation on the point set registration task. The experimental evaluations could be more extensive, for example, other related tasks.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I do not believe this paper involve any ethics issue.",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Paper proposes PWAN, a method that can be seen as an extension of WGAN in the presence of noise.\nIt uses the partial formulation of the wasserstein metric, allowing discarding points that are noise or outliers. It relies on the dual formulation of the problem to derive an efficient algorithm to learn a transformation that maps the target points toward the source points. Extensive experiments on toy datasets and 3 point clouds show that the method performs well, even in the presence of noise. ",
            "main_review": "The paper is interesting and deals with an important problem: how to deal with outliers when registering 3d shapes. \nThe transformation $\\mathcal{T}_\\theta$ is found by simultaneously find a global transformation and optimizing a partial optimal transportation distance.\nI have few concerns that should be clarified:\n- eq. (2) is a reformulation of eq. (1). If there is a reason to have the two formulations, it should be better highlighted. Otherwise, it would add some clarity to avoid considering equivalent formuations.\n- the dual of the partial optimal transport problem is described in [1]. If there is some novelty here, it should be emphasized. Otherwise, appropriate references should be cited.\n- the choice of the parameters $m$/$h$ is the key of the success of the method. It would be interesting to add a discussion about it. What happens if their values are under/over estimated? Is there any thumb rule to choose their values?\n- Section 5.2 is unclear. Is there any reason that the translated dataset should not match the outliers when t is large? What prevent PWAN to align dataset Y to outliers?\n\n\n[1] Caffarelli, L. A., & McCann, R. J. (2010). Free boundaries in optimal transport and Monge-Ampere obstacle problems. Annals of mathematics, 673-730.",
            "summary_of_the_review": "An interesting paper deals with an important problem but lacks some appropriate references.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a method for registration of two point sets by formulating the problem as partial distribution matching problem. The authors utilise the partial Wasserstein (PW) discrepancy, and show how its gradient can be computed. They further propose a partial Wasserstein adversarial network that approximates the PW discrepancy. The authors evaluate the method against four method against two artificial datasets in which the method shows good results.",
            "main_review": "As to the strengths of the paper, the authors are able to make a novel contribution to a classic problem. It is pleasing that the point sets are modelled as discrete distributions without the need of making smoothing like GMM based methods for instance do. The theoretical part of deriving the KR duality for the two types of chosen discrepancies is clearly a strength of the paper even though it is a harder part of the paper to read.\n \nAs to the weaknesses, the paper is generally relatively easy to read, however the toughest part in math could be improved for clarity to help the reader with the intuition what is going on. Especially the part related to the adversarial learning and the approximation of PW discrepancy could be described better. The experimental evaluation is performed with rather simplistic datasets for which more realistic data set could be used to improve the presentation.",
            "summary_of_the_review": "In summary, the work can be seen as well founded paper with clear theoretic contribution equipped with a practical method based on neural formulation of the registration problem. Good results on the selected datasets, though an evaluation with a more complicated datasets would improve the presentation. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a partial Wasserstein adversarial network to register two non-rigid point clouds.\n\nThe major contribution is deriving a dual optimization objective to avoid the computation of a dense matching matrix.\n\nExperiments on toy/synthetic datasets and one small-scale real-world face dataset show the effectiveness of the proposed method.",
            "main_review": "Strengths:\n\n1) It's very nice to have a method to avoid the computation of dense matching matrix in an optimal transport framework;\n2) The mathematical derivations are extensive and seem to be correct.\n\nWeaknesses:\n\nI would say the experiments are only validated on very small-scale synthetic and real-world datasets. I would expect the following experiments:\n\n1) Experiments on the 3D Human dataset [Section 4.3, Non-rigid Point Set Registration with Global-Local Topology Preservation]\n\n2) For synthetic experiments, it would be better to use the modelnet40 dataset, which contains many different shapes. Only using three shapes [bunny, armadillo and monkey] to train and validate methods has the risk of over-fitting.\n\n3) For the limited real-world experiment on the face dataset [E.10], it would be better to give more details. For example, what's the overlapping ratio between pairwise point clouds? How does the proposed method perform under different overlapping ratios? \n\n4) It's unclear whether the proposed method would be open-sourced. Since this paper contains many equations, re-implementing it would be very hard.",
            "summary_of_the_review": "Overall, It's very nice to have a method to avoid the computation of dense matching matrix in an optimal transport framework. However, the limited experiments have not convinced me of its effectiveness on real-world datasets.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}