{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper examines neural architecture search for multi-task networks, by associating model hyperparameters with a coding space and building an MLP predictor for mapping codes to task performance.  After the discussion phase, reviewers are marginally in favor or accepting the paper, pointing to the extensive experimental results as a convincing contribution."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper tackles neural architecture search (NAS), addressing the problem of finding architectures suitable for a multitude of vision-related tasks, ranging from object detection to semantic segmentation. To the best of my knowledge, this is the first attempt in NAS for computer vision models that explicitly design the search space that allows for a search of architectures that are broadly applicable to a variety of tasks that usually rely on the different granularity of feature representation. \nThis paper makes two important steps towards the automated search of such general, multi-purpose architectures: (1) to study this problem, the paper formalizes a multi-task NAS benchmark, covering recognition, detection, semantic segmentation, and activity recognition (video) datasets. This allows for assessing the generality of the sought architecture across vision tasks. (2) to tackle the architecture search in such a setting, this paper propose makes the following contributions. First, it augments the search space with multiple stages that extract feature maps at several resolutions, followed by a feature fusion step (the number of blocks and feat. map resolutions are governed by the network hyperparameters.). This seems to be one of the key features that help to find architectures suitable for tasks that differ as much as image classification and semantic segmentation. \nNext, for assessing the performance in this large search space, this paper builds on predictor-based methods, where the idea is to train a network that predicts the performance (i.e., the learned predictor) of the sought-network based on the (encoded) hyperparameters, governing the network architecture. Similarly, the proposed neural coding propagation (NCP) directly encodes the hyperparameters in the network coding space — those can thus be directly updated via back-propagation of the learned predictor. A predictor is learned for each task independently, and this way, gradients can be accumulated separately across different tasks before jointly updating the “architecture codes”. ",
            "main_review": "**Pros**\n\n\n* This paper tackles a relevant problem of finding versatile neural network architectures that should be suitable for a multitude of vision-related tasks that require different granularities of learned representations. This could bring the community a step closer towards unifying vision tasks and tackling several vision tasks (detection, segmentation …) using a single neural network. This has a potential for significant impact for the community: having general models and backbones could significantly ease the deployment of perception models in real-world scenarios (having several networks trained independently and tackling different sub-problems, and, in turn, requiring multiple forward passes, is not really a practical solution). \n* The problem is well-stated, and the methodology seems sound to me. To study this (cross-task) NAS problem, the paper first formalizes a test-bed, needed to study this problem, defines a search space that seeks representations that extract features at different granularities, and finally, proposes a method that can traverse the search space efficiently (and is applicable across tasks).\nThe paper is well-written and reasonably accessible to a reader, completely unfamiliar with NAS (i.e., this reviewer). \n* The experimental evaluation is thorough and supports the main claims (i.e., the proposed method can find both specialized network architectures as well as architectures that perform very well on recognition and segmentation tasks). \n\n\n**Cons**\n\n* From the eye of someone that is not familiar with NAS methodology and terminology, I was rather confused with a brief description of what the proposed neural coding propagation does (high-level description in the intro). I could only fully understand this part after fully reading Sec. 3. \nFrom the related work, it was unclear whether there have been any similar efforts in other fields (such as NLP) of formalizing NAS for finding versatile (instead of specialized) network architectures? \n* I think it would be fair to make it more explicit that the search space of the network architectures this method can find is still rather constrained and limited to convolutional neural networks and well-established and tested design patterns. It appears to me that the method will not be able to find a radically novel architecture but rather find “good configurations” within a well-constrained space. \n* The paper states that not all candidate models need to be evaluated by the neural predictor, but only those that are “in the search space along the gradient direction”. I would expect a more thorough justification for this. Also, how is exactly the search space along the gradient direction defined?\n",
            "summary_of_the_review": "I am absolutely no expert in the NAS area, so I can only provide an assessment of a reader that is not at all familiar with the related work. However, I find it that this paper tackles a very important problem of general cross-task vision architecture search and makes important steps in this direction by providing an evaluation test-bed and methodology that experimentally validates the claims. In particular, Tab. 2 confirms that the proposed method finds several well-performing network architectures for semantic segmentation, while ‘Cls+seg’ entry in Tab. 3 works very well for both semantic segmentation and ImageNet classification. I see this as evidence that the proposed methodology is indeed capable of finding versatile neural network architectures. \n\nBased on what I can conclude based on the manuscript I see this paper as a very solid contribution, and I think this paper should be accepted. I hope, however, that the other reviewers will be more familiar with NAS and can provide deeper insights (and spot potential issues that were missed by an “untrained eye,” in case they are present). \n\n** After rebuttal **\n\nThanks for answering my questions in the rebuttal! All my doubts were clarified. I have read other reviews and didn't spot any major weaknesses. I am retaining my rating (accept). ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Network Coding Propagation is proposed in the paper for NAS on multiple heterogeneous vision tasks.\n",
            "main_review": "strength:\n1. Good idea. The NCP trained on network codes instead of original data. Therefore the trained network can be used to update the architecture efficiently across datasets.\n2. Extensive experiments are conducted. Experiments are conducted on three settings: inter-tasks, cross-tasks, and intra-tasks. Results on these datasets demonstrate the effectiveness of the proposed NCP.\n\nweakness:\n1. The main weakness is about the evaluation of the main idea, network coding spaces. The main contribution of NCP is that NCP converts them into network coding spaces. However, very little understanding or intuition about the network coding space is provided. For example, is it continuous? Can we do interpolation between two codes? It is hard to tell what are the benefits and what are the disadvantages of optimizing on network coding spaces. Properties about the network coding spaces need to be further elaborated.\n2. The paper NAO (Luo et al., 2020) also propose to search on a continuous space. The difference between the proposed method and previous NAO needs more discussion. Why the proposed updating architecture codes along desired gradient directions for various objectives is novel, compared to NAO?\n\n",
            "summary_of_the_review": "The idea and the experiments of the paper are good, but some components need more explanation. Also, comparison with existing work needs to be more specific.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper organized a multi-task NAS benchmark including 4 widely used datasets and more than 20,000 models. It also proposed a searching architecture named Network Coding Propagation (NCP) to effectively find the optical model for specific tasks. Experimental results indicate that the proposed model can be applied to inter-task, cross-task, and intra-tasks problems and the authors also showed the generalization capability to other benchmarks. ",
            "main_review": "The authors first reorganized a NAS multi-task benchmark and trained and evaluate more than 20,000 models on this benchmark. The performance of these models can greatly inspire other following works regarding NAS tasks. \n\nFor the proposed NCP method, the overall idea is simple and sound. The overall assumption of the NCP is that the search space for model code e is continuously differentiable. Then the whole problem is essentially an optimization problem: given several samples [e_i, y_i], we wanted to find the \\hat{e} so that can maximize y. The authors trained a three-layer MLP as a predictor (function: f: e-->y). Here I feel curious and wish to raise a question, though what I can think about is also training an MLP as a predictor and using gradient descent to find the optimal, if some classic convex optimization algorithms can also solve this problem? And how about the performance? It is okay not to find another solution. \n\nAnother question is about the generalization of this method. If we would like to apply NCP for a new benchmark, e.g. COCO for segmentation, how can we use the knowledge we have on NAS-Bench-MR to find a proper parameter and architecture for the model? Since for NAS-Bench-MR, the authors trained a large number of the models to have the search space, which is not generalizable for each new dataset. \n\nBesides, the writing of this paper needs to be further revised. The current version is a little hard to follow and needs re-read to get the whole idea of the authors. \n\nSome typos with a glance:\n1) abstract: wildly used --> widely used\n2) caption of Fig. : 3th --> 3rd\n----------------------------- \nAfter rebuttal:  \nThanks for answering my questions in detail and the rebuttal fully addressed my concerns. I think this paper can be accepted to ICLR 2022. ",
            "summary_of_the_review": "The NAS benchmark (NAS-Bench-MR) contains valuable large-scale experimental results and be used to benefit other NAS research. The proposed NCP method is sound but kind of naive. The writing of this paper needs to be further revised for both method's details and organizations. Considering all these conditions, I would suggest accepting this paper to ICLR but would not champion it. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}