{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper considers the valuation problem for a cooperative game, and shows that some classical metrics (e.g. Shapley value), can be considered as approximations to the maximum entropy.\n\nReviewers were generally very positive. They especially praised the novelty and writing quality, while having some concerns about the quality of the empirical results. The authors did an excellent job responding to the reviewers, and resolved their main concerns. A few quibbles remain, however, and while the manuscript is very good as-is, please consider the reviewer criticisms in creating an updated version."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "Valuation criteria based on game-theory (e.g. Shapely value) have been used in the ML literature for analyzing feature importance and for data subset selection. These criteria serve as solution concepts for cooperative games and have been adapted by some works in ML for subset valuation problems.  \n\nThe present paper presents a probabilistic treatment of cooperative games, and shows that two classical valuation criteria can be seen as a one-step factored approximation to maximum entropy solution to the game. They then propose a new valuation criterion \"Variational Index\" that uses a multi-step factored approximation and show it satisfies some common axioms for cooperative games. The paper also has experimental results on the proposed criterion.\n\n",
            "main_review": "P. S. I'm somewhat of an outsider to this topic, with minimal familiarity with cooperative games. \n\nPros:\n- I find the observation that classical criteria such as Shapely value can be seen as one-step \"decoupling\" approximation to the maximum entropy probabilistic assignment to be quite interesting. In hindsight this seems like a natural connection, although I'm not sure if an expert on this topic would be equally excited about this result.\n- The multi-step approximation criterion that the authors propose also seems like a natural extension to existing game-theoretic criteria\n\nCons:\n- I don't find the experimental results to be compelling. They do not convincingly demonstrate that the proposed new criterion has some additional value over existing criteria for ML applications. I understand that the authors have chosen to make the mean-field perspective the central focus of the paper, but I think its important to also have a strong empirical section showcasing utility to an ML audience. \n- The feature selection experiments in Sec 5.2 show some improvements over two classical game-theoretic criteria, but the field of subset selection is now quite mature (e.g. https://arxiv.org/pdf/2006.15412.pdf), and comparing to just the two closest game-theoretic criteria doesn't seem to make a strong empirical case. \n- The new criterion comes with the added cost of Monte Carlo sampling to approximate exponential sums over multiple rounds, but I'm not entirely sure if the experiments justify this added cost needed.\n- The writing is accessible, but can be improved to better motivate the subset/feature selection applications, especially for an ML audience, and provide more elaborate intuition early on for the \"decoupling\" approximations that the classical criteria seek to compute.\n\nOther comments/questions:\n- Alg 1: You refer to this algorithm as performing gradient ascent. To me it appears more like a fixed point iteration algorithm, and not necessarily performing a gradient-based ascent step on the ELBO objective. Please correct me if I'm missing something here.\n- Sec 5: Might be good to mention how the decoupling error is computed in all your experiments, given that it requires calculating (an approximation of) the Boltzmann distribution.\n- Sec 5.1: I didn't quite understand the role of the data clustering in the experiment. On the x-axis in Fig 1, do you add clusters of data points instead of individual data points?\n- Sec 5.2: In Fig 2, you plot the predicted probabilities as you drop features. Is this the average probability predicted by the model across all test examples? Might be good to elaborate why this is a good evaluation metric to look at.\n- Sec 1/Intro: I think your mention of a solution concept \\phi(F) needs elaboration for audience not necessarily familiar with cooperative games. Similarly, in Sec 2, it wasn't initially clear to me how the importance weights you write out in (2) and (3) relate to the solution concept \\phi(F).",
            "summary_of_the_review": "The paper presents some interesting theoretical connections, but does not provide sufficiently compelling empirical results showcasing utility for applications in ML.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes an energy-based perspective on cooperative games that permits a gradient-based calculation of Shapley/Banzhaf values, as well as the definition of a new alternative value - the variational index. A quick summary of the paper's key ideas is:\n\n- For a given cooperative game $F$, we can seek an entropy maximizing distribution over coalitions $p(S)$ that satisfies a constraint on the mean coalition value $\\mu$\n- Solving the entropy maximization problem via its Lagrangian yields the Boltzmann distribution $p(S) \\propto \\exp(F(S)/T)$, where the temperature $T$ has a one-to-one correspondence with the mean coalition value $\\mu$ (this result is in the appendix). This distribution gives more probability mass to coalitions that achieve higher values\n- We can seek a simpler alternative to $p(S)$ by doing mean-field variational inference, i.e., finding a factorized surrogate $q(S)$ where each player's participation is determined by independent Bernoulli RVs. The result will intuitively assign higher probabilities to players that belong to high-value coalitions, so these probabilities can serve a function similar to Shapley/Banzhaf values\n- The VI approach suggests a KL divergence minimization (or ELBO maximization) objective for learning $q(S)$, which is parameterized by $x \\in [0, 1]^n$. Doing gradient descent on this objective yields a relatively simple update rule, where we repeatedly set $x_i^+ = \\sigma(\\nabla_i f_{mt}(x) / T)$ for $i = 1, \\ldots, n$\n- The authors define the \"variational index\" as a function of the solution to the KL divergence minimization problem: $s^* = T\\sigma^{-1}(x^*)$\n- The authors find that the Banzhaf value can be found using a single-step update to a particular initialization of the KL divergence minimization problem (luckily the temperature $T$ is not important for single-step updates). Similarly, they find that the Shapley value is the average of the single-step update applied to different initializations (again, the temperature doesn't matter). Finally, the authors point out that any single-step update applied to a symmetric initialization will be a probabilistic value (a class of solution concepts in cooperative game theory, of which Shapley/Banzhaf values are special cases)\n- Lastly, the authors suggest a practical sampling-based approach to calculating the necessary gradients, which are just as difficult to calculate as the Shapley/Banzhaf values because they require calculating the value for every coalition $S \\subseteq N$\n\nThe experiments compare the variational index to Shapley and Banzhaf values in data and feature removal tasks, finding that it performs quite favorably in the settings examined.",
            "main_review": "The energy-based perspective is, to my knowledge, a novel perspective for Shapley values and player valuation in ML, and I found it quite cool to see these tools (EBMs, mean-field VI) applied in this way. The variational index is an interesting and it appears to perform well in the experiments relative to Shapley/Banzhaf values.\n\nI have a couple questions/comments that I hope the authors will consider for improving the paper.\n\n**Premise of EBMs for cooperative games.** The idea of using EBMs to analyze cooperative games was a bit confusing and could probably be introduced better. To be specific, the paper starts by saying we should learn a probability distribution over coalitions, but this does not begin to sound like a worthwhile endeavor until several sections in. When we're using Shapley/Banzhaf values, we control the distribution over coalitions/orderings, so learning a distribution sounds (at least initially) like a somewhat pointless idea. Similarly, the idea of finding an entropy-maximizing coalition distribution (constrained to a mean value, which it's not clear how to choose!) does not initially sound useful. Of course it's not pointless, but what ultimately connects these EBM ideas to player valuation is the crucial step of doing mean-field VI. Because of the important role mean-field VI plays here, I wonder if it doesn't deserve a bit more attention and emphasis.\n\nAppendix A attempts to explain this a bit more, but I didn't find these reasons compelling (particularly the second paragraph). Unless I'm missing something, the real reason to use EBMs + mean-field VI is that it enables us to learn a factorized distribution over players that places higher probabilities on players that contribute more value, and this gives us a new perspective for defining player valuations, which happens to connect to existing ideas like Shapley/Banzhaf/probabilistic values.\n\n**Connection with multilinear extensions.** The idea of learning a factorized distribution over players is most similar to the idea of multilinear extensions in cooperative game theory (as in Okhrati and Lipani). In that work, Shapley values are defined as the expected marginal contribution where the preceding coalition is determined by a factorized distribution over players (integrated over a probability value); here, the probabilities of the factorized distribution are learned, but they can still coincide with Shapley values. I wonder if the authors can provide any more commentary on the implicit connection between these ideas, where the probabilities in a factorized distribution can induce player valuations vs. act as player valuations.\n\n**Cooperative game theory in ML.** The paper gives a nice overview of the use of Shapley values in ML, including uses in feature-based explanations, data valuation, and model ensemble valuation. However, a couple key papers are perhaps overlooked and could be cited: Lipovetski & Conklin (2001) and Strumbelj & Kononenko (2010) were some of the first papers to analyze statistical models using Shapley values, and Covert et al. (2020) (already cited) also provides an overview of other papers that use Shapley values, including SPVIM, SAGE and Shapley Effects, and it shows that many other ML explanation methods are also tied to cooperative game theory.\n\n**Entropy gradient.** In section 4.2, the gradient $\\nabla_i H(q) = \\log \\frac{1 - x_i}{x_i}$ is given but the result is not derived. It could be helpful to provide a derivation in the appendix because this result seems non-trivial, and it is important for the subsequent gradient descent routine.\n\n**Gradient descent derivation.** The update rule in algorithm 1 does not immediately look like gradient descent, and I expect it will be confusing to many readers. Where, for example, is the learning rate? I tried to derive this result and if I understand correctly, it comes from taking a gradient step on $\\sigma^{-1}(x_i)$ and then applying the sigmoid operation to get $x_i^+$, where the learning rate is chosen as a function of the current value $x_i$. I'm not sure if that's right or if there's a simpler explanation, but there is too much work left to the reader here.\n\n**Practical impact.** I found the ideas in this work very interesting and will view the paper favorably regardless of the answer to this question, but I just wanted to clarify the practical impact. Am I correct in understanding that this energy-based approach does not necessarily offer a more efficient algorithm to calculating Shapley/Banzhaf values? Is the main practical impact, then, proposing the variational index as an alternative to Shapley/Banzhaf values for valuation problems?\n\n**Applying existing Shapley value approximations to the variational index.** In section 3, it's stated that existing Shapley value estimation ideas can be applied directly (\"can be seamlessly lifted\") to calculating the variational index. That point didn't come up later in the paper and I don't see how that is the case. How, for example, could we use a permutation-based or weighted least squares-based Shapley value estimator to calculate the variational index? Or how could we use a model-specific Shapley value approximation like TreeSHAP? How could these things be integrated into algorithm 1, or be adapted into different routines for optimizing the KL divergence? I don't get this, some clarification on this point would be helpful.\n\n**Role of temperature.** It might be worth noting explicitly for eqs. 14-15 that the specific temperature value does not matter, and that it does not matter for any single-step update; currently, the reader must figure this out for themselves. Aside from that, it's a bit unsatisfactory that different temperatures yield different variational indices, and that we don't know much about the properties of the different solutions, but I suppose it's fine to leave further investigation to future work. It could also be nice to have either a footnote or brief appendix section showing why $T = 0$ and $T \\to \\infty$ induce even spread and 0/1 probabilities, respectively, as this is also currently left to the reader.\n\n**Role of initializer.** In section 4.2, there's a brief section discussing the initializer's role w.r.t. variational values. It seems mostly right, but I'm confused by the claim that the initializer doesn't matter if you plan on running GD to convergence. How can that be, given that the problem is non-convex (stated earlier in the paper)? These seem like contradictory ideas, please clarify if possible.\n\n**Additivity and efficiency properties.** In section 4.4, there's a paragraph discussing why variational values don't satisfy the additivity and efficiency properties satisfied by Shapley values. I found this paragraph a bit odd: in addressing this \"why\" question, your explanation addresses why they *shouldn't* (reasons why these properties might be unappealing), as if you had some choice in the matter, rather than the mathematical/mechanistic reasons why they don't. I would ask that you adjust this paragraph to clarify whether you're explaining i) why those properties aren't satisfied or ii) why it's okay that they're not satisfied.\n\nA couple things about the experiments:\n\n- In section 5.3 where we look at the convergence of algorithm 1, we can clearly see that it converges. But does it converge to the same point regardless of the initialization? This may be worth looking into due the problem's non-convexity.\n- Is it worth looking into whether algorithm 1 can yield efficient, low-variance Shapley/Banzhaf value estimates relative to existing estimators? Do you have any intuition about how the variance might compare for a fixed number of game evaluations?\n\nThere were a couple specific phrases that I thought could be improved:\n\n- The introduction says that you explore a \"probabilistic treatment\" of games. That's true, but it's not very specific because cooperative game formulations are sometimes probabilistic, there's work considering stochastic cooperative games, and Shapley/Banzhaf values have probabilistic formulations. It might be better to say that you propose learning a factorized distribution over players to arrive at player valuations, because that's what's unique here. The same paragraph says something like this later, but it leaves out the bit about learning a factorized surrogate distribution and the fact that the original distribution is encouraged to put more mass on players that contribute more value.\n- Also in the introduction, you state that you \"conduct learning and uncertainty analysis in a unified Bayesian manner.\" I'm not sure this is correct, your method of course does VI, but not uncertainty analysis or Bayesian inference (where's the prior, what's the data?).",
            "summary_of_the_review": "This paper introduces some very interesting ideas about the use of EBMs and mean-field VI in the context of player valuation for cooperative games. Their new perspective is connected to Shapley/Banzhaf/probabilistic values, it permits approximate optimization (the gradients require sampling), and they define a new value (the variational index) that performs quite well in their experiments.\n\nI had a couple questions and comments about the writing, but I expect these will be easy to address.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper studies valuation problems for cooperative games. It proposes a new valuation measure called Variational Index. The idea is to create a coalition probability distribution based on a maximum entropy criterion. Player valuations are then derived by creating decoupled surrogates of this distribution. The authors then present a gradient ascent algorithm to compute this decoupling. Classical valuation criteria like the Shapley value and the Banzhaf index can be recovered as special cases or modifications of the algorithms iterates.",
            "main_review": "Regarding strengths, to the best of my knowledge the proposed valuation of the framework is novel. It is well motivated and the connections with existing classical methods are very interesting. It also opens the door for further extensions as different surrogate models or application specific priors can be easily incorporated. While it is hard to argue (both in theory and in practice) that one valuation method is better than the alternatives, the empirical results seem to be reasonable. I believe that this paper can have significant impact in the area in the immediate future.\n\nRegarding weaknesses, the paper could be improved in terms of approachability to practitioners. Firstly, reporting the run times of the experiments and/or the accuracy-time trade-offs for MCMC methods would be useful for practitioners. Additionally, any advice on how users should interpret the absolute scores of the Variational Index (especially since $T$ affects their scaling) could be useful. This is especially true for cases where the rankings of different valuation methods are similar but the absolute scores are not. Moreover, the paragraph on why additivity or efficiency does not make sense for some games is very important for practitioners to understand. Practitioners may be easily tricked into thinking that the more properties a valuation measure satisfies the better regardless of the game they try to understand. Right now the paragraph is a bit dense and hard to follow for audiences not familiar with prior work on axiomatization of valuations in cooperative games. Toy numerical examples to demonstrate why additivity or efficiency can result in unintuitive/not-useful valuations could also help practitioners grasp what is the problem.\n\nThese weaknesses are minor so I am in favor of accepting this work. I have read the responses of the authors. I find that these additions are going to improve the paper. I thus maintain my score.",
            "summary_of_the_review": "A well written and novel work on a variational framework for player valuations in cooperative games. While approachability to practitioners could be improved, I am in favor of accepting this work.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies valuation problems from cooperative game theory. There are $n$ agents and a valuation function $F: [n] \\to R$ where $F(S)$ is the collective payoff of the coalition $S \\subseteq [n]$. The goal is to use this function $F$ to define an importance vector $\\phi(F) \\in R^n$. Examples include the Shapley value and Banzhaf index.\n\nThe authors introduce a probabilistic treatment of this problem, where they use $F$ to define a probability distribution $p$ where $p(S)$ is the probability that coalition $S$ forms. They then phrase the problem of defining an importance vector $\\phi(F)$ as a decoupling problem. Under $p$, the $n$ agents may be correlated in a complicated way, but to assign each of them an individual importance value, one must decouple their interactions, or simplify their correlations. The goal is then to find a product distribution $q$ that is as close to $p$ as possible under the KL divergence. Specifically, the authors define $q$ to be an $n$ independent Bernoulli distribution, where the probability that agent $i$ participates in the coalition is denoted $x_i$. The authors show how to optimize the probabilities $x_1, \\dots, x_n$ using coordinate ascent. Finally, they define the importance score of player $i$ as $\\log(x_i/(1-x_i))$ (ignoring a temperature $T$ term for simplicity). The authors show that the resulting importance vector satisfies many of the game-theoretic axioms that the Shapley value and Banzhaf index satisfy, like the null player, marginalism, and symmetric axioms.\n\nIn the experiments, the authors look at small instances with $n = 25$ where it is actually possible to compute the gradients exactly (as opposed to an approximate sampling method). The applications they look at are for data valuation and feature attribution in the context of machine learning. For these tasks, they show that their proposed approach performs about the same as the Shapley value and Banzhaf index, and sometimes a bit better.",
            "main_review": "Strengths:\n- The authors show that one can derive the Shapley value and Banzhaf index using one step of gradient ascent using specific initializations. I think it’s nice that these two criteria can be unified under this model.\n- The paper seemed polished and was easy to read.\n\nWeaknesses:\n- I think that the main way this paper could be improved is that I couldn’t quite understand the benefit of this approach to defining the importance scores over classic approaches like the Shapley value and the Banzhaf index. It’s not any easier to compute and at least according to what’s written in the paper thus far, it doesn’t seem to satisfy any additional game-theoretic axioms than the Shapley value or Banzhaf index. Lastly, in the experiments, it seems to perform about as well as these other two indices; the experiments don’t seem illustrate its superiority as decisively as one might hope.\n- There are a few ways that the model choices could be further justified. The paper is really built around the specific choice $p$ of the distribution over coalitions, which is justified in a few sentences in the third paragraph of the introduction. However, since the reader really has to buy in to this choice of $p$ to appreciate the rest of the paper, I think that a bit more justification would be useful. One other thing I couldn’t quite follow is why the importance score ends up being defined in terms of the inverse sigma functions.\n\nSmaller comments:\n- 3rd paragraph of Section 1: How is mu chosen? Why doesn’t it show up in Equation (1)?\n- 4th paragraph of Section 1: At first, I was confused about what the “valuation problem” is. Then I realized it’s the problem of defining the importance vector; it would be helpful to clarify this.\n- Last paragraph of Section 1: I have a few suggestions:\n   - I didn’t know what was meant by a “decoupling perspective” until I got to Section 4, so I wasn’t able to understand this sentence.\n   - “Intriguing properties” is a bit too vague, in my opinion. After reading Section 5, I’m not really sure what these intriguing properties would be, so it would definitely help to spell these out.\n",
            "summary_of_the_review": "Overall, I think that this paper was nicely written and I like that it unifies the Shapley value and Banzhaf index, but I don’t yet see why the proposed approach is necessarily better than using either of these two existing criteria, so I’m leaning towards rejection.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}