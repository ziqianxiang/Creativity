{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "All reviewers recommended accept after discussion. I am happy to accept this paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a method for deep-learning-based multi-view stereo. The contribution of the paper would be to adjust the scale of convolutional kernels according to the curvature of the target scene. Experiments show the proposed method (slightly) outperforms the existing deep-learning-based multi-view stereo methods. ",
            "main_review": "This paper is basically well written and has several strengths.\n+ Using dynamic scale convolution for learning-based multi-view stereo is new.\n+ Using the curvature of the target scene for determining kernel scale would be adequate.\n+ Well experimented (but only with learning-based methods)\n\n\nMy main concern for this paper is about the main contribution.\nUsing curvature information to select the patch scale is used in an MVS method (Xu et al. (2020)). \nAlthough the method does not use deep learning, it limits the technical contribution of this paper.\n\nIn the related work section, this paper claims that the proposed method should have an advantage of performance compared with Xu et al. (2020) because they do not rely on the handcrafting features.\nHowever, the claim was not confirmed through the experiments.\n\n*** After discussion phase ***\nDuring the discussion phase, the authors added a comparison of the proposed method with Xu et al. (2020).\nFrom the comparison, indeed the proposed approach shows advantages for both accuracy and computation time.\n\nTherefore, compared with the initial rating, I changed my rating to a positive one.\nA dynamic-scale method using curvature has been proposed so far, somehow limiting the novelty of this work.\nMeanwhile, developing a learning-based approach would be beneficial.",
            "summary_of_the_review": "*** For the initial review***\nI am concerned about the effectiveness of the main claim of this paper because it is not confirmed through the experiment, i.e., it is not compared with the most important existing method. \n\n***As for the final rating,***\nI acknowledged the comparison with the most important method and confirmed the advantage of the proposed method.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a method named CDSFNet for the multi-view stereo problem. The network is composed of curvature-guided dynamic scale convolution (CDSConv) layers to first estimate approximate normal curvature at different candidate scales, and then do a classification to find the optimal scale. The module is then embedded with cascade structure of CasMVSNet, to reduce the matching ambiguity by considering the proper pixel scales. The method is evaluated on DTU, BlendedMVS and Tanks & Temples datasets, which archives state-of-the-art performance compared with other related methods.\n",
            "main_review": "Strength:\n- The rationale behind finding the right scale to disambiguate matching is well written and quite reasonable. It would be good to pinpoint though, the exact example that suffers from the matching ambiguity issue, i.e. highlight some pixels in the image pairs about the wrong feature association.\n- The quantitative results show the method is competitive. \n- Run time is also lower when image resolution increases, compared with CasMVSNet and others. \n\nWeakness:\n- The writing can be improved. For example, the learnable normal curvature part is a bit hard to read.\n- It’d be good to add some ablation studies to show the delta brought by CDSConv and the MVS architectural changes compared with the baseline network, i.e. CasMVSNet.\n\n\nFeedback:\n- For the Tanks&Temple dataset, did you also evaluate the method using high-res images on the advanced cases? I found that the method ranks high on the intermediate cases but not on the advanced cases.\n- Is the major deduction of running time a consequence of only computing depths of half-resolution images and then upsample to the original resolution?\n- Add legend to the left image of Figure 3. Why is the GPU memory significantly lower when resolution is increased? It’s even lower compared with lower-res images, for ‘ours’.\n\n\n",
            "summary_of_the_review": "I recommend Accept for this paper since the strengths outweigh the weaknesses. The paper is generally written well with good performance. One thing that can be improved as I mentioned above is more ablation experiments.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a novel Deep Neural Net to address the problem of Multi-View Stereo (MVS) by introducing several claimed novel ingredients, ie, (i) CDFSNet: a scale-adaptive feature extraction network that takes into account (ii) an approximation of image-based 2D curvatures in a U-Net based network;\n(iii) CDS-MVSNet: is the actual reconstruction network that consider multiple resolutions and input feature scales into an aggregated, regularized multi-view cost-volume.\n\nThe end-to-end sequential pipeline forming the proposed contribution is evaluated on public, popular standard benchmarks in the field, showing promising results, despite the fairness of the experimental setup being in question (as detailed below in the review).",
            "main_review": "*** Strengths of the paper:\n\n(+) Conceptual novelty.\n\nWhile the proposed contributions do partially exist in the literature, their combination to address the problem of MVS per se is novel and interesting. This in turn leads to several interesting experimental discussions that are teased early-on in the paper (but lack in their execution, cf. weaknesses below for the missing expected pieces in the evaluation section in particular).\n\n(+) Reproducibility.\n\nThe amount of disclosed information regarding the method is fair, and makes uses of the supplementary material by providing comprehensive details regarding the curvature-aware formulation and its differentiable approximation, as well as the code of the proposed method that has also been submitted.\n\n(+) Related Work.\n\nThe section (2) is dense, well populated and structured and discusses the main key prior work in the field. While there could have been a broader discussion about the literature overlaps w.r.t aspects of the proposed contributions in difference applicative scopes (eg, the use of 2D curvatures in U-Net based networks), the section is already fairly long (1.2 page long) and serves its purpose relatively well.\n\n(+) Structure, Balance of the Contents.\n\nOverall, the paper is relatively well structured, each section is of pertinent relative size and the text real-estate is well utilized and efficient. To some extent, more qualitative results could make their way to the main paper, instead of predominantly relying on the supplementary material in this regard.\n\n\n*** Weaknesses of the paper.\n\n- (1) The fairness of the experimental setup is in question.\n\n(a) On the DTU dataset (page 8), as explicitly stated by the authors the proposed method is trained on the union of DTU and Blended-MVS datasets (training splits):\n\nAppendix, A3 page 15: \n\"Note that we trained the single model using both DTU and Blended datasets\ninstead of training individually on each dataset as in previous methods (Zhang et al., 2020; Luo\net al., 2020; Sormann et al., 2020). This procedure prevented the model from biasing to each dataset\nin the evaluation step; it guaranteed the generalized property of model.\"\n\nThis is a major issue because the reported performance figures of the competition in Table 1 are being trained on the conventional train split of DTU, without additions.\n\n(b) Appendix, A3 page 15:  It is factually not true that (Zhang et al., 2020; Luoet al., 2020; Sormann et al., 2020) perform training on DTU+Blended-MVS to test on DTU:\n\n(i) Zhang et al., 2020: \nThe experiments on DTU and Blended-MVS are performed by training on the respective conventional training splits, NOT on both training sets simultaneously. This is explicitly stated by the authors Page 7, sec 4.1 of their main paper.\n\n(ii) Luo et al., 2020: \nTheir model is trained and tested solely on DTU, using the conventional splits (sec 5.2 in their main paper).\n\n(iii) Sormann et al., 2020: \nExperiments on DTU: the training is performed solely on the training split of the dataset.\nFor Tanks and Temples and ETH3D (which is not considered in the proposed paper), the authors additional fine-tune on Blended-MVS on top of the conventional DTU training. This can be found in their main paper, sec 5.1.2 and sec 4 at length.\n\n(c) Regarding the provided experiments on Tanks and Temples (ToG 2017), Table 3:\n\nIt is a common practice in the field to train on either DTU  with or without fine-tuning on Blended-MVS (eg, resp. BP-MVS, AttMVS), not by training on the union of both dataset as it is done for the proposed method (Appendix A3).\n\nIn particular, given that AttMVS is the closest-performing competition w.r.t the proposed method, why not provide experiments with the same training setup / data?\n\nThis was an easy way to directly address the relative positioning against the most competitive player in the field. Chosing a different setup can be interpreted as a means to hide potential red flags.\n\n- (2) Certain claims and justifications are either ambiguous, inaccurate or even misleading.\n\nThis is the case in particular regarding the evaluation part above, and the pieces of justification that are specified in the appendix. This agin, is a relatively major concern as is.\n\n- (3) No ablation studies are provided.\n\nGiven the sequential pipeline nature of the proposed contributions, ie, feature extraction, approximate curvature priors, 3D cost volume aggregation and regularization, it is highly expected to provide a comprehensive ablation study (ie, activating/removing pieces of the pipeline) to help understand and assess the relative contribution of each individual piece / ingredient, in particular given:\n\n(a) It is a common practice in the field and within the realm for this particular literature (eg, BP-MVS, AttMVS, or even at BMVC which is a venue which much less text real-estate: Zhang et al. 2020).\n\n(b) This is all-the-more problematic given (1) above, that puts an even greater weight on the ablation analysis and the lack thereof.\n\n(c) Additionally, certain design choices and hyperparameters are not experimentally challenged to support their respective values are (at least near-) optimal, eg, \\lambda_1 and \\lambda_2 in sec 4.2, page 13: the number of different scales / number of stages that are typically considered.\n\n- (4) Missing prior work in the comparative evaluation.\n\nThis is relatively important given the proximity, performance-wise, w.r.t the proposed method, eg, (Sormann et al. 2020) BP-MVS (overall perf: 0.327 vs. 0.315).\n\n- (5) Relative positioning, performance-wise, is unclear.\n\nThis is a direct implication stemming from (1)+(3) above. The reported performance figures are hence uninformative and do not allow to properly assess the relative positioning of the proposed approach w.r.t existing work, and hence, the validate its usefulness.\n\n- (6) Readability.\n\nTo a lesser extent, the text as it currently stands, is still in a relatively rough, tough to digest state. There are numerous grammar issues and typos (a few example below). However and overall, the main ideas and key claims do not suffer substantially from the language-related issues and the articulations of the main ideas is often preserved.\n\nA few examples with suggestions for improvements:\n- abstract l3: by introducing a skilled design to cost formulation -> by designing aggregated 3D cost volumes and their regularization.\n- abstract: our final MVS architecture -> our resulting MVS architecture.\n- abstract: Moreover -> As a result,\n- abstract: can process the high resolution with faster run-time -> can process higher resolution inputs within faster runtimes\n- introduction, first paragraph: an object's scale varies extremely in images -> in presence of high/significant scale variations of objects in images\n- throughout: dynamic scale networks -> scale-adaptive networks",
            "summary_of_the_review": "*** Summary and justification of the initial rating.\n\nOverall, the paper presents very interesting and relatively new ingredients to address the problem of Multi-View Stereo using supervized learning. The presentation of the contents, despite a few substantial issues, also lies in the list of positives. \n\nHowever, as it currently stands, the proposed package suffers from major drawbacks in the evaluation department, as detailed above in the main review. In particular:\n\n(i) The proposed experimental comparisons are performed in a fair setup, for the most part and regarding the most important dataset / set of experiments.\n\n(ii) As an extension to (i), there are key claims, references and justifications that are inaccurate to say the least, that could easily mislead the reader.\n\n(iii) Given the nature of the proposed contributions forming a sequential pipeline, (ie: feature extraction, approximate curvature priors, 3D cost volume aggregation and regularization) it is highly expected to provide a comprehensive ablative study to analyze, motivate and qualtify the need of each individual ingredient. Such experiments have not been proposed.\n\nAs a result, the proposed package is very interesting and the results promising, but the execution of the evaluation part do not allow to validate the main claims and novelties so far. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper adds upon the recent line of MVSnet works, (specifically CasMVSNet) by explicitly treating the scale needed to reconstruct each part of the scene. This is done by estimating the local curvature of the surface prior to the depth, which is then used to select (in an attention sense) a kernel with an appropriate scale from a set of scaled features in the CDSConv. The curvature estimations is further constrained \nto the epipolar line of the relevant source image. The image is processed in a coarse to fine manner similar to CasMVSNet, except the finest resolution which is solved in a (naive?) 2D manner. ",
            "main_review": "The paper is generally well written and the main novelty of the curvature estimation is explained in a high level allowing an inexpert to follow. The authors properly cite previous works when necessary (except Do Carmo which is not the earliest use of curvature AFAIK)\n\nThis paper pushes the envelope and seem to provide better results in using less compute, which (IMHO) brings it over the conference's bar, but not by much.\n\nThe main area where I believe this paper can be improved is by providing deeper analysis of the novel parts. \nSpecifically:\n- Replacing Gxx with learned Kxx seems arbitrary: first, using G is quite tractable (only 3 derivatives). second, what promise do we have that all the K's are directional like the derivatives? e.g. Kxx can have some y meaning - lastly, this can easily be tested and showed in an experiment (i.e. show performance with G and then learned K)\n- Is the physical curvature/scale actually estimated? can you compare it to the one from the GT?\n- Is the curvature/scale consistent across the cascade? If not, is it getting better/worse compared to GT?\n- Are the CDSConv scale features (C1, ... Ck) constrained to be scaled versions of each other? otherwise it's not really a scale estimation, no?\n- The use of 2D CNN in the last layer seems to be for performance reasons (not clear from the text), but a comparison to another stage of 3D CNN should provide better results - why not show the impact here?\n\n\nTo summarize, most of my concerns can be addressed with either ad deeper explanation, or preferably an ablation (of using visibility-aggregation  K vs G, removing the last 2D CNN, whether to add the epipolar constraint)\n\n\nsmaller notes:\n- \"handcrafting\" --> \"handcrafted\"\n- Ixx, Iyy, Ixy in eq. 1 are used before definition\n- the G<<1 assumption should be better justified\n- regarding eq2 - first, why is it intractable? second, there are only 4 convolutions, not 5 (Ixy==Iyx)\n- Is the visibility-based aggregation in CDS-MVSNet novel or was it done in prior works? not clear from the text\n- are weights shared between cascade scales? (are stages 0,1,2 of Fig 4 identical weights)\n",
            "summary_of_the_review": "The paper is novel, well written, and provides nice SOTA results. \nMore justification of the design choices can turn it from weak to strong accept.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}