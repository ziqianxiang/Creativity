{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes a few-shot (untargeted) backdoor attack (FSBA) against siamese network-based visual object tracking. Contributions can be summarized as follows: First, this paper treats the attack task as an instance of multi-task learning and can be regarded as the first backdoor attack against VOT. Besides, a simple yet effective few-shot untargeted backdoor attack is proposed and achieves significant effectiveness in both digital and physical-world scenarios. This paper reveals the vulnerability of VOT to backdoor attacks caused by outsourced training or using third-party pre-trained models. One weakness is that threat model requires a very strong attacker with ability to modify the training algorithm, but only very simple defenses are considered. Overall, this is a good first attempt at showing vulnerability of VOT approaches."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "1. The paper introduces a variant of backdoor attacks against visual object tracking (VOT) networks. \n2. A baseline attack (BOBA) consisting of a standard classifier backdoor against the classification head of a Siamese network is proposed. \n3. An improved attack (FSBA) based on maximizing a particular loss in feature space is proposed, with better empirical results than the baseline attack. \n4. Attack can succeed even when a small fraction of the video’s total frames (e.g. 5%) contain the trigger. ",
            "main_review": "Strengths\n1. Novel application of backdoor attacks. \n2. Thorough empirical evaluation, covering different preprocessing techniques, backdoor triggers, fine tuning, and differing proportion of video frames containing the trigger, multiple datasets. \n3. Overall good presentation and writing. \n\nWeaknesses\n1. It’s not very clear why the BOBA attack fails. The paper notes trust the representations of the clean and poisoned data are similar under BOBA, which seems like a reasonable cause for its low attack performance, however it’s not clear why this is happening. I would have expected the representations to log very different. \n2. t-SNE plots are difficult to interpret. Perhaps a simpler visualization such as PCA would be clearer. \n3. Threat model requires a very strong attacker with ability to modify the training algorithm. \n4. Only very simple defenses are considered. ",
            "summary_of_the_review": "Overall this is an interesting new application of backdoor attacks with good empirical results. It is hard to tell why the main proposed defense outperforms the baseline attack and I hope that this will be addressed. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper investigates a few-shot backdoor attack for single object visual tracking. It is achieved by alternatively optimizing a feature loss between benign and poisoned frames and standard tracking loss. The authors empirically show that the presented attack is effective in both digital and physical-world scenarios.",
            "main_review": "Strengths:\n* This paper is well organized and easy to follow. \n* The authors claim that this is the first backdoor attack against VOT models.\n\nWeaknesses:\n* The core idea of the backdoor attach is to maximize the feature distance between  benign and poisoned frames, which seems to be trivial with limiited contribution and insight. \n* The proposed method is claimed to be able to operate in few-shot or one-shot mode. However, I cannot find any specific design of the proposed method to ensure it.\n* The proposed attack combines the feature loss and a standard tracking loss. Is the tracking loss computed over both benign and poisoned frames or is it like the loss function in Eq.3? How to implement it? More detailed explaination should be provided.\n* In the definition of \\alpha-Effectiveness, I think the first \\theta should be \\hat{\\theta}",
            "summary_of_the_review": "I think the overall contribution of this paper is limited and some implementation details are missing as mentioned above.\n=======================\nThe rebuttal has addressed most of my concerns. Therefore, I would like to upgrade my initial recommendation.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a few-shot (untargeted) backdoor attack (FSBA) against siamese network-based visual object tracking. Contributions can be summarized as follows: First, this paper treats the attack task as an instance of multi-task learning and can be regarded as the first backdoor attack against VOT. Besides, a simple yet effective few-shot untargeted backdoor attack is proposed and achieves significant effectiveness in both digital and physical-world scenarios.",
            "main_review": "Strengths:\nThis paper reveals the vulnerability of VOT to backdoor attacks caused by outsourced training or using third-party pre-trained models. As the first work that relates backdoor attacks against VOT, the paper's motivation is exciting and essential. The well-organized experiments and detailed analysis verify the proposed method can serve as a valuable tool to examine the backdoor vulnerability of visual object trackers.\n\nWeaknesses:\nThere are a few details that need to be explained further.\n(1) Section4.1 mentions that the frame attacking rate is set as 10% in FSBA under the few-shot mode, while Figure 7 shows that 5% is enough to attack trackers. Why not set this parameter as 5%?\n(2) Figure 8 shows four trigger patterns. What is the basis for choosing these patterns? Is it from the backdoor attack in the image classification mission? Or is it supported by knowledge of cognitive psychology?\n(3) The definition of Pr_B is a little bit misunderstood. How to understand \" the larger the Pr-B, AUC-B, and mSR50-B, the more stealthy the attack\"?\n(4) The experimental result is mainly a numerical analysis without further investigation. For example, why can trigger pattern B have a tracking effect on siamese trackers? Is it possible to analyze the changes in the tracker's heatmap to find out why the attack takes effect?\n",
            "summary_of_the_review": "As the first work that relates backdoor attacks against VOT, this paper reveals the vulnerability of VOT to backdoor attacks caused by outsourced training or using third-party pre-trained models and achieves valuable results. Although there are still some shortcomings in experimental analysis, this article is a good attempt on the security of the VOT and worthy of follow-up work.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}