{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper proposes Diversity-Regularized Training (DRT), a new training method for an ensemble classifier to improve its certified robustness when randomized smoothing is applied. Specifically, it trains a set of base classifiers to diversify their input gradients while maximizing the confidence margin of each. The method is backed up with a theoretical observation on robustness of ensembles of smooth classifiers.\n\nAfter the discussion phase, the reviewers unanimously ended up with supporting acceptance of this paper, and the authors were quite responsive to address the reviewers' concerns. Overall, the reviewers appreciated its strong empirical results with a theoretical support - AC also agrees on that, and thinks the paper presents a promising and under-explored direction to boost certified robustness of randomized smoothing."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes using an ensemble model to improve certified robustness. Based on the developed theory, it proposes Diversity-Regularized Training (DRT), a lightweight regularization-based ensemble training approach which composes of two simple yet effective and general regularizers to promote the diversified gradients and large confidence margins respectively. The experiments were conducted to show the merit of the proposed approach.",
            "main_review": "**Strengths of the paper**\n- This is a rigorous and solid paper in which the practical approach is developed based on theoretical findings.\n- The writing and presentation are generally good and motivating.\n- Convincing experimental results.\n\n**Weaknesses of the paper**\n- The findings of the paper are not really new. The usefulness of gradient diversity in improving the robustness of an ensemble model and the capability of a large confident margin in enhancing the robustness are well-known. Furthermore, randomized smoothing has been proposed before. However, this paper is good in the sense of putting together them in the theory development of an ensemble approach.",
            "summary_of_the_review": "It would be great if the authors offers more discussion about the variation of the upper bounds in equations (4,5) if we vary the robust radius $r$. The current analysis is done with a fixed $r$.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a new analysis for randomized smoothing based certified robustness of ensemble models. The analysis shows that the robustness radius depends on the l2 norm of the weighted sum of the gradients of the confidence margin of base models. A training strategy is then proposed to regularize this term by increasing the divergence of gradient vectors.",
            "main_review": "The theoretical analysis in this paper is correct, although a bit difficult to follow due to the redundant and non-traditional notations. The experiment results are sufficient to support the claim of this paper.\n\nOne question I have is how the weights of ensembles could affect the results. I didn’t find any explicit values for these weights, which should be included in the experiment section as what are the values and how these are chosen.",
            "summary_of_the_review": "See comments above.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes to train diverse classifiers to improve certified robustness of ensemble classifiers. More specifically, it proposes two regularization terms in training: (a) the Gradient Diversity (GD) loss, and (b) the Confidence Margin (CM) loss. This is motivated by a theoretical observation that one needs both (a) and (b) to achieve a robust ensemble model given that all the base classifiers are smooth. Experimental results on MNIST, CIFAR-10 and ImageNet show that the proposed training can consistently improve the certified accuracies of ensemble models compared to the ensemble of classifiers from the standard training. ",
            "main_review": "- The paper is clearly written and well-motivated. The motivation is theoretically supported, and the strong experimental results also confirm the effectiveness. I agree that exploring on the ensemble of smoothed classifiers is an important yet under-explored topic.\n- Although the paper motivates the method from Theorem 1, it was quite unclear to me when the paper proceeds from Theorem 1 to Ensemble-before-Smoothing (EBS): I can see that Theorem 1 holds only when all the base classifiers (\"before\" ensemble) are $\\beta$-smooth, but then why Theorem 2 shows the $\\beta$-smoothness of the classifier \"after\" ensemble? Does EBS guarantee that all the base classifiers before ensemble are $\\beta$-smooth? If not, how can one apply Theorem 1 to justify GD and CM losses?\n- I feel the paper could benefit from comparing Average Certified Radius (ACR) [Zhai et al., 2020] as well as the certified accuracies: overall, I could see that the proposed method improves certified accuracy, but generally the gains are not uniform (especially for the ImageNet results) so that the readers may be confused on interpreting them.\n- It would be helpful for the readers that the Table 1 and 2 could also present the single-model performance of DRT-trained models.\n- The paper should include a discussion about the computational costs of the proposed method - e.g., the increase in training time of DRT compared to the Gaussian training (or standard ensemble). Also, I would like to see the overheads in certification time, as the certification pipeline now includes an ensemble during smoothing.\n- I feel the results on ImageNet are relatively less significant, especially given the decrease in the clean accuracy of DRT+* models. The paper could include more discussion on it.",
            "summary_of_the_review": "Overall, I can see that the paper is clearly written and addresses an important research direction that explores a better ensemble scheme of smoothed classifiers. Although I feel a slight logical gap in Theorem 1 → EBS, the paper presents a novel and theoretical justification to motivate the new training method, and it is further supported with a strong empirical results.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors present theoretical and empirical findings on how ensembles can improve certifiable robustness of classifiers. The authors show that increased robustness requires diverse gradients among the ensemble members (as well as large confidence margins). The authors incorporate these findings into two regularization terms for training and show that these lead to improved certifiable robustness on MNIST, CIFAR10, and ImageNet.",
            "main_review": "### Strengths \n* The empirical results are strong, i.e., the proposed model outperforms baselines consistently.\n* The theoretical contributions appear sound and meaningful.\n* The paper is well-written and easy to follow.\n### Weaknesses\n* The authors only study a single setting of $N=3$. An interesting study would have been to see how increasing $N$ changes the certified robustness.\n* The authors do not make use of the fact that their theory allows to certify when the ensemble *cannot* be robust w.r.t. a sample.\n* The proposed method has the apparent drawback that the ensemble models cannot be trained in isolation.\n\n### Detailed comments\n* An interesting finding is the importance of gradient diversity for the ensemble robustness. This seems to align well with the fact that we favor diverse ensembles in practice. I wonder whether there is a deeper connection of gradient diversity for robustness to the diversity of the ensemble.\n* Out of curiosity, is there any theoretical indication that larger $N$ leads to more robustness? Intuitively, large $N$ should lead to a smoother ensemble function, but $N$ does not appear in the computation of the smoothness $\\beta$.\n* How are the $w_i$ optimized in the proposed approach?\n* An interesting aspect of the theoretical contribution is that Theorem 1 can also prove when a sample is *not* robust. It would have been interesting to show the share of *certifiably nonrobust* samples in addition to the certified accuracy in the figures and tables. This way we could also see how large the share of samples is for which we cannot certify (non-)robustness.",
            "summary_of_the_review": "The paper is well-written and easy to follow, and the theoretical and empirical contributions are interesting and appear meaningful. I would have liked to see different values of $N$ and a study of the *certifiable non-robustness* of the ensemble models. \n\nEdit: I have increased my score based on the authors' response.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper analyzed the certified robustness for ensemble ML models. It is proven that diversified gradient and large confidence margin are sufficient and necessary conditions for certifiably robust ensemble models under the model-smoothness assumption. The proposed Diversity Regularized Training (DRT) method performs better than current provable methods.\n\n",
            "main_review": "The ensemble model performs well in empirical defense, so its extension to provable robustness is essential. Some interesting insights are presented, but they also seem to be readily available from the empirical ensemble model defense. \n\nIn definition 1, To be consistent with randomized smoothing, should ${\\left\\|\\delta\\right\\|}_2 \\leqslant r$ be ${\\left\\|\\delta\\right\\|}_2 < r$? \n\nWhy is the empirical robust accuracy of DRT $(r=0)$ lower than the baseline on large-scale datasets?\n\nWhat is the motivation for Ensemble-before-Smoothing? Is it driven by the property of Theorem II or is it due to empirical observation? The EBS here seems trivial.\n\nI will consider raising my score based on the other reviewers' comments and the authors' responses.\n\n",
            "summary_of_the_review": "The paper has a lot of proof, which is great, but there are some questions about the experimental results and motivation that need to be clarified.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}