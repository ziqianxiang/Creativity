{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes a new method for domain generalization. The main idea is to encourage higher inner-product between gradients from different domains. Instead of adding an explicit regularizer to encourage this, authors propose an optimization algorithm called Fish which implicitly encourages higher inner-product between gradients of different domains. Authors further show their proposed method is competitive on challenging benchmarks such as WILDS and DomainBed.\n\nReviewers all found the proposed algorithm novel and expressed that the contributions of the paper in terms of improving domain generalization is significant. A major issue that came up during the discussion period was that we realized that the presented results on WILDS benchmark are misleading. In particular, the following statements in the manuscript are false because on \"CivilComments\" and \"Amazon\", Fish utilizes a BERT model (Devlin et al., 2018). However, other methods at WILDS benchmark use DistilBERT (Sanh et al., 2019):\n\n- Section 4.2: \"For hyper-parameters including learning rate, batch size, choice of optimizer and model architecture, we follow the exact configuration as reported in the WILDS benchmark. Importantly, we also use the same model selection strategy used in WILDS to ensure a fair comparison.\"\n\n- Appendix C2: \"Results: We compare results to the baselines used in the WILDS benchmark over 3 random seed runs in Table 10. All models are trained using BERT (Devlin et al., 2018).\"\n\nAuthors explained that the mismatch is because at the time they evaluated their model, an earlier version of WILDS benchmark was available but they later updated other methods' results on a newer version of WILDS benchmark. Of course, I do not think that this explanation makes the misleading statements OK. Authors promised to do the following for the camera-ready version to make sure it is not misleading:\n\n- Using \"Worst-U/R Pearson r\" as the comparison measure for \"PovertyMap\"\n- Submitting their method to WILDS benchmark making sure everything matches the baselines and then reporting the results on \"Amazon\" and \"CivilComments\" datasets.\n\nTherefore, I recommend acceptance and I hope that authors would stick to their promise and update the manuscript to include these changes."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The work tries to tackle the problem of domain generalisation in multi-source setting. The main claim of the paper is that by maximising inner product  between gradients from different domains leads to better learning of domain invariant features. The provide a meta-learning inspired algorithm Fish to approximate the second-order derivates. The results on several domain generalisation dataset is shown. ",
            "main_review": "- The paper is well written and is easy to follow\n- Multiple benchmarks are used to evaluate the method \n\nConcerns:\n- the claim that feature learnt are domain invariant is not really backed by a theoretical explanation or empirical. One way would be to show using tsne plot, that indeed features align as the gradient have same sign.\n- Algorithm 1 formulation looks similar to the Mean Teacher[1] formulation where \\tilde{\\theta} plays the role of student and \\theta as of teacher. \n- Regarding just empirical results Fish seems competitive but it is not clear in what cases it the best. Is just the low number of source domain it shines? If that's the case, more explanation is needed to highlight the reason.\n- Related Work section is needs to be improved, some works with which it is compared isn't discussed, for eg. Coral. \n- Why the data augmentation based methods are left out in the comparisons?\n\n[1] https://arxiv.org/abs/1703.01780",
            "summary_of_the_review": "The paper presents gradient alignment to induce feature invariance. Several comparisons are presented but paper lacks explanation on the central idea, that why invariance is achieved. Also, some clarifications mentioned in the main review are need. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "To improve the generalization in unseen domains, the paper proposes a regularizer based on align ing the gradient direction between training environments. The proposed approach achieve non-trivial improvement on bench marks such as WILDS.",
            "main_review": "The paper address an important problem in OOD generalization. The paper is well-written and the contributions are stated clearly. I have a few questions and concerns.\n\nPositive Points:\n\n1. The motivation and methodology is stated clearly. I can understand the approach by only read the paper once. I like figure 1 and section 3.2, which make the formulation itself very clear.\n\n2. Despite the simplicity of Fish, it achieves non-trivial improvement on WILDS benchmark, outperforming important baselines such as IRM. It good to see some approaches finally outperform ERM by a large margin, e.g., CAMELYON17.\n\n3. I like the extensive analysis in the experimental section, which provide valuable insights for future study.\n\nQuestions:\n\n1. I think objective (4) shares similar motivation to IRM in the sense that we want the model to update in directions (use features) that are beneficial for all domains. It would be great to provide more discussion and comparison w.r.t. IRM.\n\n2. I wonder whether the inner product of gradient in equation (4) could be related to bi-level / meta learning? For instance, check equation (12) in [1]. One may be able to explain the success of IDGM from the perspective of optimization, and further relates it to IRM. In particular, IRM defines its objective by measuring optimality, which is highly related to optimization. Note that this is different from analyzing approximation of IDGM such as Thm 3.1.\n\n3. The measure drawback of the paper is it lacks of rigorous analysis about why and how IDGM works. For instance, IRM performs a careful study to analyze the proposed objective from a causal perspective. One may also investigate the problem from information theory [2]. It would be great if the paper can have at least a few paragraphs for analyzing IDGM.\n\nOverall, there is no significant flaw in this paper. Although the proposed approach is not well analyzed, the empirical results are still impressive. \n\n[1] Ren et al., Learning to Reweight Examples for Robust Deep Learning, ICML 2018\n\n[2] Huszár, Invariant Risk Minimization: An Information Theoretic View, 2019",
            "summary_of_the_review": "Overall, I think this is a well-written paper with good empirical results. I did not observe obvious flaw in the paper.\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes to maximize the similarity of the gradients of the classification loss for different domains to learn domain-agnostic features.",
            "main_review": "Pros:\n\n1. This paper proposes to maximize the similarity of gradients of the classifcation loss for different domains to learn invariant features. This is an interesting way to address the domain generalization problem.\n\n2. This method also provides a effcient way to approximate the inner product between gradients due to the large computation cost. A theoretical proof is also given for this approximation.\n\nCons:\n\n1. The improvment is minor on DomainBed in Table 3. The results of baseline methods seem to be inconsistent with the results by facebook?  \nhttps://github.com/facebookresearch/DomainBed/blob/main/domainbed/results/2020_10_06_7df6f06/results.png  Since this paper is claiming that it is trying to obtain domain-invariant features which is also what  DANN wants to achieve, then why DANN is worse than ERM while the IDGM is better than ERM? It would be better to have an explanation for this observation and full comparison with DANN.\n\n2. It would be better to visualize (e.g., t-sne) the learned representations by the IDGM to see if the features are invariant across domains. \n\n\nUpdate:\n\nI have read the response by authors and other reviews. Part of my concern is addressed. So I raised my score to 6.\nBut I still share the same concern with another reviewer that it is unclear why this method works. If some domain-specific information is useful according to the response, then why the gradient matching helps preserves such information?",
            "summary_of_the_review": "This paper proposes to maximize the gradient similarity to learn invariant features across domains. But the improvment is minor and some critical explanations to the results are lacking.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Authors propose an inter-domain gradient matching objective that targets domain generalization by maximizing the inner product between gradients from different domains. Authors also give a computationally efficient optimization for the proposed method and give results on various datasets. ",
            "main_review": "Strength: \n\n1) Authors motivate a proposed method clearly with their illustration in figure 2 and explanation in section 3.3\n\n2) Contribution is a novel combination of existing ideas. Authors worked out the Taylor series expansion of the gradient and came up with a linear approximation. Authors modified the Reptile algorithm which works on improving the GIP inside a particular task (or domain) to improve the GIP across different tasks (or domains)\n\n3) By the virtue of their simplification, their model update process is much cleaner than it would have been had they used IDGM itself\n\n4) This linear approximation also helps to not worry about saving intermediate gradients of all the past steps as might be the case in Reptile.\n\nWeakness: \n\n1) It is not clear if the improvements given by the proposed method are statistically significant. It is also not clear why this method performs better in certain datasets and worse on others. \n\n2) Missing literature. \n\n3) Comparing Fish and IDGM might be necessary to confirm that the approximation works.\n\nReview:\n\n1) How is the concept of using gradient inner product different from using kernel methods? Can authors compare and contrast with a popular DG method [1]? \n\n2) Is there any way one can check or compare - how well the linear approximation is working? If given infinite resources, can authors improve their scores further? If authors can show this on at least a few dataset, it will really help to understand the method better. \n\n3) iWildCam is a much tougher dataset to work with where there are pictures of deers in grass (for ex) which is present throughout all the images. Similar vegetation is also present around other wild animals in other pictures. This aspect might have confused this approach significantly as it might think vegetation to be an invariant feature. This is where proposed method doesn’t perform too well. Can authors comment why?\n\n4) Gradient inner products are also related to Neural Tangent Kernels [2]. Can authors comment more on this?\n\n[1] Blanchard, Gilles, Aniket Anand Deshmukh, Ürün Dogan, Gyemin Lee, and Clayton Scott. \"Domain Generalization by Marginal Transfer Learning.\" arXiv preprint arXiv:1711.07910 (2017) J. Mach. Learn. Res. (JMLR) 22 (2021): 2-1.\n\n[2] Jacot, Arthur, Franck Gabriel, and Clément Hongler. \"Neural tangent kernel: Convergence and generalization in neural networks.\" arXiv preprint arXiv:1806.07572 (2018).\n\n",
            "summary_of_the_review": "Literature could be improved. For better understanding slow but exact algorithm could be tested on small dataset. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposed inter-domain gradient matching for domain generalization. They also approximated the proposed model with a simple first-order algorithm to avoid costly second-order computations.  The performance on the WILDs and DomainBed seems better than the ERM algorithm. ",
            "main_review": "Pros:\n\n(1) The theorem of FISH looks interesting, which can avoid costly second-order computations.\n\n(2) The pitfall of ERM is interesting to explain why ERM fail in the domain generalization.  \n\n(3) This paper is well written and easy to follow.\n\n(4) Experiments on the WILDs and DomainBed demonstrate the advantages of the proposed methods in a practical.\n\nCons:\n \n(1) The motivation for using gradient matching is not clear.  e.g., Why using gradient matching can achieve domain-invariant representations?  \n\n(2) Lack of comparative experiments of direct optimization of IDGM on the DomainBed.\n\n(3) Some sentences are not accurately described. For example: In the related work 5. Gradient alignment: \"While they achieve the best performance on the training set, both IGA and ERM could completely fail when generalizing to unseen domains.\"  Not all ERM algorithms fail [1][2].\n\n(4)The structure of the inner-loop and outer-loop is similar to MAML or Reptile. Need more explanation and the difference of MAML.\n\n\n\nReference:\n\n[1] Gulrajani et al 2020. In search of lost domain generalization. \n\n[2] Cha, Junbum, et al. \"Swad: Domain generalization by seeking flat minima.\" arXiv preprint arXiv:2102.08604 4 (2021).\n\n\n\n\n\n\n",
            "summary_of_the_review": "As stated in the main reviews, the motivation of using a matching gradient is not particularly impressive, but overall the paper does provide some interesting analysis that may encourage new ways of thinking about domain generalization problems. As such, I think this paper may be of interest to the ICLR community.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}