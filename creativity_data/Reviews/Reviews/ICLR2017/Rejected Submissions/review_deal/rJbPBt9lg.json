{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "The paper extends existing code completion methods over discrete symbols with an LSTM-based neural network. This constitutes a novel application of neural networks to this domain, but is rather incremental. Alone, I don't think this would be a bad thing as good work can be incremental and make a useful contribution, but the scores do not show an amazingly significant improvement over the baseline. There are many design choices that could be better justified empirically with the introduction of neural benchmarks or an ablation study. We encourage the authors to further refine this work and re-submit."
    },
    "Reviews": [
        {
            "title": "An interesting paper but only initial work about neural network based code completion.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "Pros:\n  using neural network on a new domain.\nCons:\n  It is not clear how it is guaranteed that the network generates syntactically correct code.\n\nQuestions, comments:\n  How is the NT2N+NTN2T top 5 accuracy is computed? Maximizing the multiplied posterior probability of the two classifications?\n  Were all combinations of NT2N decision with all possible NTN2T considered?\n\n  Using UNK is obvious and should be included from the very beginning in all models, since the authors selected the size of the\n  lexicon, thus limited the possible predictions.\n  The question should then more likely be what is the optimal value of alpha for UNK.\n  See also my previous comment on estimating and using UNK.\n\n  Section 5.5, second paragraph, compares numbers which are not comparable.\n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Great problem, too many decisions taken for granted and not explored",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper considers the code completion problem: given partially written source code produce a distribution over the next token or sequence of tokens. This is an interesting and important problem with relevance to industry and research. The authors propose an LSTM model that sequentially generates a depth-first traversal over an AST. Not surprisingly the results improve over previous approaches with more brittle conditioning mechanisms (Bielik et al. 2016). Still, simply augmenting previous work with LSTM-based conditioning is not enough of a contribution to justify an entire paper. Some directions that would greatly improve the contribution include: considering distinct traversal orders, does this change the predictive accuracy? Any other ways of dealing with UNK tokens? The ultimate goal of this paper is to improve code completion, and it would be great to go beyond simply neurifying previous methods.\n\nComments:\n\n- Last two sentences of related work claim that other methods can only \"examine a limited subset of source code\". Aside from being a vague statement, it isn't accurate. The models described in Bielik et al. 2016 and Maddison & Tarlow 2014 can in principle condition on any part of the AST already generated. The difference in this work is that the LSTM can learn to condition in a flexible way that doesn't increase the complexity of the computation.\n\n- In the denying prediction experiments, the most interesting number is the Prediction Accuracy, which is P(accurate | model doesn't predict UNK). I think it would also be interesting to see P(accurate | UNK is not ground truth). Clearly the models trained to ignore UNK losses will do worse overall, but do they do worse on non-UNK tokens?",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Ok paper, but not a big enough contribution",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This paper studies the problem of source code completion using neural network models. A variety of models are presented, all of which are simple variations on LSTMs, adapted to the peculiarities of the data representation chosen (code is represented as a sequence of (nonterminal, terminal) pairs with terminals being allowed to be EMPTY). Another minor tweak is the option to \"deny prediction,\" which makes sense in the context of code completion in an IDE, as it's probably better to not make a prediction if the model is very unsure about what comes next.\n\nEmpirically, results show that performance is worse than previous work on predicting terminals but better at predicting nonterminals. However, I find the split between terminals and nonterminals to be strange, and it's not clear to me what the takeaway is. Surely a simple proxy for what we care about is how often the system is going to suggest the next token that actually appears in the code. Why not compute this and report a single number to summarize the performance?\n\nOverall the paper is OK, but it has a flavor of \"we ran LSTMs on an existing dataset\". The results are OK but not amazing. There are also some issues with the writing that could be improved (see below). In total, I don't think there is a big enough contribution to warrant publication at ICLR.\n\nDetailed comments:\n\n* I find the NT2NT model strange, in that it predicts the nonterminal and the terminal independently conditional upon the hidden state.\n\n* The discussion of related work needs reworking. For example, Bielik et al. does not generalize all of the works listed at the start of section 2, and the Maddison (2016) citation is wrong\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}