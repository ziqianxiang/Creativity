{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "A summary of strengths and weaknesses brought up in the reviews:\n \n Strengths\n -Paper presents a novel way to evaluate representations on generalizability to out-of-domain data (R2)\n -Experimental results are encouraging (R2)\n -Writing is clear (R1, R2)\n \n Weaknesses\n -More careful controls are needed to ascertain generalization (R2)\n -Experimental analysis is preliminary and lack of detailed analysis (R1, R2, R3)\n -Novelty and discussion of past related work (R3)\n \n The reviewers are in consensus that the idea is exciting and at least of moderate novelty, however the paper is just too preliminary for acceptance as-is. The authors did not provide a response. This is surprising because specific feedback was given to improve the paper and it seems that the paper was just under the bar. Therefore I have decided to align with the 3 reviewers in consensus and encourage the authors to revise the paper to respond to the fairly consistent suggestions for improvement and re-submit."
    },
    "Reviews": [
        {
            "title": "Lacks Strong Baselines and Wall-Time Results",
            "rating": "3: Clear rejection",
            "review": "The authors present methods to speed-up gradient descent by leveraging asynchronicity in a layer-wise manner.\n\nWhile they obtain up-to 1.7x speedup compared to synchronous training, their baseline is weak. More importantly, they dismiss parameter-server based methods, which are becoming standard, and so effectively just do not compare to the current state-of-the-art. They also do not present wall-time measurements. With these flaws, the paper is not ready for ICLR acceptance.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Difficult to read paper. Lack of strong async baseline a major flaw.",
            "rating": "3: Clear rejection",
            "review": "This paper is relatively difficult to parse. Much of the exposition of the proposed algorithm could be better presented using pseudo-code describing the compute flow, or a diagram describing exactly how the updates take place. As it stands, I'm not sure I understand everything. I would also have liked to see exactly described what the various labels in Fig 1 correspond to (\"SGD task-wise, 1 comm\"? Did you mean layer-wise?).\nThere are a couple of major issues with the evaluation: first, no comparison is reported against baseline async methods such as using a parameter server. Second, using AlexNet as a benchmark is not informative at all. AlexNet looks very different from any SOTA image recognition model, and in particular it has many fewer layers, which is especially relevant to the discussion in 6.3. It also uses lots of fully-connected layers which affect the compute/communication ratios in ways that are not relevant to most interesting architectures today.\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "review for Leveraging Asynchronicity in Gradient Descent for Scalable Deep Learning",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper describe an implementation of delayed synchronize SGD method for multi-GPU deep ne training.\nComments\n1) The described manual implementation of delayed synchronization and state protection is helpful. However, such dependency been implemented by a dependency scheduler, without doing threading manually.\n2) The overlap of computation and communication is a known technique implemented in existing solutions such as TensorFlow(as described in Chen et.al) and MXNet. The claimed contribution of this point is somewhat limited.\n3) The convergence accuracy is only reported for the beginning iterations and only on AlexNet. It would be more helpful to include convergence curve till the end for all compared networks.\n\nIn summary, this is paper implements a variant of delayed SyncSGD approach. I find the novelty of the system somewhat limited (due to comment (2)). The experiments should have been improved to demonstrate the advantage of proposed approach.\n\n\n\n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}