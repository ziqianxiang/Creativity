{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "The idea of combining many modalities for product recommendation is a good one and well worth exploring. However, the approach presented in this paper is unsatisfying, as it involves combining several pre-trained models, in a somewhat ad hoc manner. Overall a nice problem, but the formulation and results are not presented clearly enough."
    },
    "Reviews": [
        {
            "title": "Interesting problem and good motivation, unconvincing solution architecture",
            "rating": "3: Clear rejection",
            "review": "The problem of utilizing all available information (across modalities) about a product to learn a meaningful \"joint\" embedding is an interesting one, and certainly seems like it a promising direction for improving recommender systems, especially in the \"cold start\" scenario. I'm unaware of approaches combining as many modalities as proposed in this paper, so an effective solution could indeed be significant. However, there are many aspects of the proposed architecture that seem sub-optimal to me:\n\n1. A major benefit of neural-network based systems is that the entire system can be trained end-to-end, jointly. The proposed approach sticks together largely pre-trained modules for different modalities... this can be justifiable when there is very little training data available on which to train jointly. With 10M product pairs, however, this doesn't seem to be the case for the Amazon dataset (although I haven't worked with this dataset myself so perhaps I'm missing something... either way it's not discussed at all in the paper). I consider the lack of a jointly fine-tuned model a major shortcoming of the proposed approach.\n\n2. The discussion of \"pairwise residual units\" is confusing and not well-motivated. The residual formulation (if I understand it correctly) applies a ReLU layer to the concatenation of the modality specific embeddings, giving a new similarity (after dot products) that can be added to the similarity obtained from the concatenation directly. Why not just have an additional fully-connected layer that mixes the modality specific embeddings to form a final embedding (perhaps of lower dimensionality)? This should at least be presented as a baseline, if the pairwise residual unit is claimed as a contribution... I don't find the provided explanation convincing (in what way does the residual approach reduce parameter count?).\n\n3. More minor: The choice of TextCNN for the text embedding vectors seems fine (although I wonder how an LSTM-based approach would perform)... However the details surrounding how it is used are obscured in the paper. In response to a question, the authors mention that it runs on the concatenation of the first 10 words of the title and product description. Especially for the description, this seems insufficiently long to contain a lot of information to me.\n\nMore care could be given to motivating the choices made in the paper. Finally, I'm not familiar with state of the art on this dataset... do the comparisons accurately reflect it? It seems only one competing technique is presented, with none on the more challenging cold-start scenarios.\n\nMinor detail: In the second paragraph of page 3, there is a reference that just says (cite Julian).",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "",
            "rating": "3: Clear rejection",
            "review": "This paper proposes combining different modalities of product content (e.g. review text, images, co-purchase info ...etc) in order to learn one unified product representation for recommender systems. While the idea of combining multiple sources of information is indeed an effective approach for handling data sparsity in recommender systems, I have some reservations on the approach proposed in this paper:\n\n1) Some modalities are not necessarily relevant for the recommendation task or item similarity. For example, cover images of books or movies (which are product types in the experiments of this paper) do not tell us much about their content. The paper should clearly motivate and show how different modalities contribute to the final task.\n\n2) The connection between the proposed joint product embedding and residual networks is a bit awkward. The original residual layers are composed of adding the original input vector to the output of an MLP, i.e. several affine transformations followed by non-linearities. These layers allow training very deep neural networks (up to 1000 layers) as a result of easier gradient flow. In contrast, the pairwise residual unit of this paper adds the dot product of two item vectors to the dot product of the same vectors but after applying a simple non-linearity. The motivation of this architecture is not very obvious, and is not well motivated in the paper.\n\n3) While it is a minor point, but the choice of the term embedding for the dot product of two items is not usual. Embeddings usually refer to vectors in R^n, and for specific entities. Here it refers to the final output, and renders the output layer in Figure 2 pointless.\n\nFinally, I believe the paper can be improved by focusing more on motivating architectural choices, and being more concise in your description. The paper is currently very long (11 pages) and I strongly encourage you to shorten it.\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The paper proposes a method to combine arbitrary content into recommender systems, such as images, text, etc. These various features have been previously used to improve recommender systems, though what's novel here is the contribution of a general-purpose framework to combine arbitrary feature types.\n\nPositively, the idea of combining many heterogeneous feature types into RS is ambitious and fairly novel. Previous works have certainly sought to include various feature types to improve RSs, though combining different features types successfully is difficult.\n\nNegatively, there are a few aspects of the paper that are a bit ad-hoc. In particular:\n-- There are a lot of pieces here being \"glued together\" to build the system. Different parts are trained separately and then combined together using another learning stage. There's nothing wrong with doing things in this way (and indeed it's the most straightforward and likely to work approach), but it pushes the contribution more toward the \"system building\" direction as opposed to the \"end-to-end learning\" direction which is more the focus of this conference.\n-- Further to the above, this makes it hard to say how easily the model would generalize to arbitrary feature types, say e.g. if I had audio or video features describing the item. To incorporate such features into the system would require a lot of implementation work, as opposed to being a system where I can just throw more features in and expect it to work.\n\nThe pre-review comments address some of these issues. Some of the responses aren't entirely convincing, e.g. it'd be better to have the same baselines across tables, rather than dropping some because \"the case had already been made elsewhere\".\n\nOther than that, I like the effort to combine several different feature types in real recommender systems datasets. I'm not entirely sure how strong the baselines are, they seem more like ablation-style experiments rather than comparison against any state-of-the-art RS.\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}