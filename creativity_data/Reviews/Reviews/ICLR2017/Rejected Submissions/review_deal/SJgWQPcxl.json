{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "The presented approach builds heavily on recent work, but does provide some novelty. The presentation is generally all right, but there are parts of the manuscript that the reviewers feel needed/needs work. All reviewers note that the evaluation and experimental work could be improved."
    },
    "Reviews": [
        {
            "title": "",
            "rating": "3: Clear rejection",
            "review": "The paper proposed conditional biGAN and its extension to multi-view biGAN. The main idea of conditional biGAN is to matching the latent variable distributions of two encoders, each of which are conditioned on the observation (\\tilde{x}) and the output (y), respectively, in addition to standard biGAN formulation.\n\nThe description on MV-GAN require more revision. Specifically, the definition on aggregating model, \\Phi, mapping v and a variable s should be clarified. Looking at Equation (8), I can't find a term that constrains the output domain of function v to be the same as a data domain. \n\nExperimental results are not convincing. In most generation results, the observation is not very well preserved. For example, in Figure 6 the second row, background changes significantly from the observation. We also observe such behavior in digit generation example. Preserving attributes like gender is interesting but doesn't seem to be a strong indication that the model learn to correlate observation and the output through latent variable. ",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "nice paper but seems somehow incomplete",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper builds in the bidirectional GAN (BiGAN) to obtain an extension which can handle multiple views of data. To this end, the authors extend the BiGAN for multiple view aggregation. This is an easy task and just requires the introduction of the additional distribution and accompanying discriminator. The main challenging and novel part is in regularizing the model to avoid instabilities. The authors propose a novel KL divergence based constraint.\n\nAs mentioned above, the approach builds quite heavily on previous ones but it has enough novel elements, in particular the constraint for regularization. This constraint is a reasonable assumption an in practice seems to work well. One downside is that it comes with a parameter \\lambda which controls its strength and which is not obvious how to find efficiently. For example, for the MNIST data it takes a very small value, 10^-5 and for the CELEBA it's 10^-3. It could be that the results are not very sensitive to this value, but there's no discussion concerning this aspect. \n\nApart from the regularization term, the rest of the model construction is well motivated, I agree with the authors that a multi-view approach employing GANs is an interesting topic to consider. \n\nPresentation is in general good although at parts readability is hindered. I feel that the notation is unnecessarily complicated, and some parts of the text too. Furthermore, it wasn't immediately obvious to me what is considered as \\tilde{x} and what is y in the experiments. \n\nAdditionally, most of the discussion on the well-studied area of multi-view learning (intro and sec. 6) omits reference to important prior work which is not based on neural networks. Indeed, some of the issues mentioned as common in today's methods (discrete outputs only, no density estimation...) do not actually exist in many non-neural network approaches. There are too many works to suggest including in the discussion, but I guess the most relevant ones are in the field of probabilistic and non-linear multi-view learning, which is also what MV-BiGAN is doing.\n\nThe experiments presented in the paper are nice illustrations but unfortunately insufficient. Firstly, they only cover the task of generating (small) images and correspond to non-real world settings (I'd actually consider all of the experiments as toy experiments). Furthermore, the most difficult of these experiments (sec. 5.3) is quite unconvincing. If Fig. 6 shows some of the best results that can be achieved, then this is rather disappointing. Important details are also missing: what is exactly the attribute vector used? How many instances exist?\n\nThe two other experiments on 5.1 and 5.2 are well executed. It's important that the authors show a comparison with \\lambda=0. \n\nHowever, beyond showing the validity of the KL term, one can't conclude much about the overall merit of the method as a multi-view learning approach, given the above experiments. \n\nOverall this was a nice paper to read, but seems somehow incomplete.\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "nice extensions to Bi-GAN",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper presents extensions of bidirectional generative adversarial networks to the conditional setting and multi-view setting. The methods are well-motivated, the mathematical derivations appear to be correct, and the presentation is clear enough to me. \n\nI would suggest this paper to be accepted. However, I find it somewhat limited to only present results for generation tasks. I think a main advantage of using bi-GAN (rather than the standard GAN) is the additional inference model that can learn useful features. I am curious about how good the features are for some other supervised (or semi-supervised) learning tasks and what have they really learned.\n\nI also find it interesting that the counterpart of these models under the VAE framework have also been proposed\n- Kihyuk Sohn and Honglak Lee and Xinchen Yan. Learning Structured Output Representation using Deep Conditional Generative Models. NIPS 2015.  (*** contitional VAE ***)\n- Weiran Wang, Xinchen Yan, Honglak Lee, and Karen Livescu. Deep Variational Canonical Correlation Analysis. In submission to ICLR 2017. (*** sort of multi-view VAE ***)\n\nIt would be nice to have discussions and comparisons in future work. ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}