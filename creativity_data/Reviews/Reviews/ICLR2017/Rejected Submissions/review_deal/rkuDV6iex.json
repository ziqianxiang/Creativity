{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "The paper proposes an empirical investigation of the energy landscape of deep neural networks using several stochastic optimization algorithms.\n \n The extensive experiments conducted by the authors are interesting and inspiring. However, several reviewers expressed major concerns pointing out the limitations of a experimental investigation on real-world datasets. The paper would benefit from additional experiments on simulated datasets. This would allow to complement the experimental analysis. Furthermore, theoretical analysis and analytical derivations, consistent with the simulated datasets, could shed light on the experimental results and allow to make more precise claims. \n \n A revised version, following the reviewers' suggestions, will result in a stronger submission to a future venue."
    },
    "Reviews": [
        {
            "title": "A good evaluation of optimization methods",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper provides an extensive analysis of the error loss function for different optimization methods. The presentation is well done and informative. The experimental procedure is clarified sufficiently well. Theoretical evaluations like this are crucial for a wide range of applications and help to better understand and improve the convergence behavior for a given system.\n\nPros:\n\n- Important analysis\n- Good visualizations\n\nCons:\n\n- The paper describes mostly the observation that the optima vary for different methods, however doesn't attempt to explain why it happens and how to solve it (aside from batch-norm)\n- Some fonts are very small (e.g. Fig. 5)\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "",
            "rating": "4: Ok but not good enough - rejection",
            "review": "I appreciate the work but I do not think the paper is clear enough. \nMoreover, the authors say \"local minimia\" ~70 times but do not show (except for Figure 11?) that the solutions found are not necessarily local minima. \nThe authors do not talk about that fact that slices of a non-convex problem can look like the ones they show. \nIt is well-known that the first-order methods may just fail to deal with certain non-convex ill-conditioned problems even in low-dimensional noiseless cases, the place/solution where they fail to make progress is not necessarily a local minimum. \nSome sentences like the one given below suggest that the study is too superficial:  \n\"One of the interesting empirical observation is that we often observe is that the incremental improvement\nof optimization methods decreases rapidly even in non-convex problems.\"",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting paper, but the message is not clear",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The paper is dedicated to better understanding the optimization landscape in deep learning, in particular when explored with different optimization algorithms, and thus it also characterizes the behavior of these algorithms. It heavily re-uses the approach of Goodfellow et al. (2015). I find it hard to understand the contributions of the paper, for example: is it surprising that different algorithms reach different solutions when starting from the same initialization? It would be useful if the authors build such basic intuition in the paper. I also did not receive a clear answer to the question I posed to reviewers regarding clarifying how does the findings of the paper can contribute to future works on optimization in deep learning. And this is what I find fundamentally missing. So for example, there are probably plenty of ways to modify approach of Goodfellow et al. (2015), and similar works, and come up with interesting visualization methods for deep learning - but the question is: how is this helpful in terms of designing better algorithms, gaining more intuition how the optimization surface looks like in general, etc.? This is an interesting paper, though I am fairly confident it is a better fit for the journal than this conference. \n\nIt would be interesting and instructive, even for sanity check, to plot the eigenspectra of the solutions recovered by the algorithms to see the order of critical points recovered.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}