{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "Reviewers agree that the findings are not clear enough to be of interest, though the effort to do a controlled study is appreciated."
    },
    "Reviews": [
        {
            "title": "Solid work, but inconclusive and of narrow interest",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This paper investigates the issue of whether and how to use syntactic dependencies in unsupervised word representation learning models like CBOW or Skip-Gram, with a focus one the issue of bound (word+dependency type, 'She-nsubj') vs. unbound (word alone, 'She') representations for context at training time. The empirical results are extremely mixed, and no specific novel method consistently outperforms existing methods.\n\nThe paper is systematic and I have no major concerns about its soundness. However, I don't think that this paper is of broad interest to the ICLR community. The paper is focused on a fairly narrow detail of representation learning that is entirely specific to NLP, and its results are primarily negative. A short paper at an ACL conference would be a more reasonable target.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper evaluates how different context types affect the quality of word embeddings on a plethora of benchmarks.\n\nI am ambivalent about this paper. On one hand, it continues an important line of work in decoupling various parameters from the embedding algorithms (this time focusing on context); on the other hand, I am not sure I understand what the conclusion from these experiments is. There does not appear to be a significant and consistent advantage to any one context type. Why is this? Are the benchmarks sensitive enough to detect these differences, if they exist?\n\nWhile I am OK with this paper being accepted, I would rather see a more elaborate version of it, which tries to answer these more fundamental questions.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Belowline",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This paper analyzes dependency trees vs standard window contexts for word vector learning.\nWhile that's a good goal I believe the paper falls short of a thorough analysis of the subject matter.\nIt does not analyze Glove like objective functions which often work better than the algorithms used here.\nIt doesn't compare in absolute terms to other published vectors or models.\n\nIt fails to gain any particularly interesting insights that will modify other people's work.\nIt fails to push the state of the art or make available new resources for people.\n\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}