{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "While this area chair disagrees with some reviewers about (1) the narrowness of the approach's applicability and hence lack of relevance to ICLR, and also (2) the fairness of the methodology, it is nonetheless clear that a stronger case needs to be made for novelty and applicability."
    },
    "Reviews": [
        {
            "title": "Review",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper proposes a sequence transduction model that first uses a traditional statistical alignment methods to provide alignments for an encoder-decoder type model. The paper provides experiments on a number of morphological inflection generation datasets. They shows an improvement over other models, although they have much smaller improvements over a soft attention model on some of their tasks. \n\nI found this paper to be well-written and to have very thorough experiments/analysis, but I have concerns that this work isn't particularly different from previous approaches and thus has a more focused contribution that is limited to its application on this type of shorter input (the authors \"suggest\" that their approach is sufficient for shorter sequences, but don't compare against the approach of Chorowski et al. 2015 or Jailty el at 2016).\n\nIn summary, I found this paper to be well-executed/well-written, but it's novelty and scope too small. That said, I feel this work would make a very good short paper. ",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Not novel enough",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The paper proposes an approach to sequence transduction for the case when a monotonic alignment between the input and the output is plausible. It is assumed that the alignment can be provided as a part of training data, with Chinese Restaurant process being used in the actual experiments. \n\nThe idea makes sense, although its applicability is limited to the domains where a monotonic alignment is available. But as discussed during the pre-review period, there has been a lot of strongly overlapping related work, such as probabilistic models with hard-alignment (Sequence Transduction With Recurrent Neural Network, Graves et al, 2012) and also attempts to use external alignments in end-to-end models (A Neural Transducer, Jaitly et al, 2015). That said, I do not think the approach is sufficiently novel. \n\nI also have a concern regarding the evaluation. I do not think it is fair to compare the proposed model that depends on external alignment with the vanilla soft-attention model that learns alignments from scratch. In a control experiment soft-attention could be trained to match the external alignment. Such a pretraining could reduce overfitting on the small dataset, the one on which the proposed approach brings the most improvement. On a larger dataset, especially SIGMORPHON, the improvements are not very big and are only obtained for a certain class of languages.\n\nTo sum up, two main issues are (a) lack of novelty (b) the comparison of a model trained with external alignment and one without it. \n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Nice idea, but limited applicability (need an auxiliary solver for alignments)",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The paper describes a recurrent transducer that uses hard monotonic alignments: at each step a discrete decision is taken either to emit the next symbol or to consume the next input token. \n\nThe model is moderately novel - similar architecture was proposed for speech recognition (https://arxiv.org/pdf/1608.01281v1.pdf). Soft monotonic alignemts are also enforced by A. Graves in https://arxiv.org/abs/1308.0850.\n\nThe difficult part in training the proposed model is backpropagation through the discrete decisions. Typically, reinforcement learning techniques are used. In this contribution, the authors side-step the issue by using a problem-dependent aligner to generate optimal decisions for which they train the model.\n\nThe results indicate that such specially supervised model is better than the generic soft-attention model that doesn't require any problem-dependent external supervision. However the authors did not attempt to work on regularizing the soft-attention model, which is not fair - the extra supervision by using the ground-truth alignment is a form of regularization and it could be used as e.g. an extra signal to the soft-attention model for a better comparison. That being said the authors reash state-of-the-art results against other domain specific methods.\n\nI believe the paper would more suit a NLP venue - it sound and properly written, but its applicability is limited to the considered NLP problem.\n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}