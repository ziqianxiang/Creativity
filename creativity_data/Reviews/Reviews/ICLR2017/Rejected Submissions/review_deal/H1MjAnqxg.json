{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "All reviewers have carefully looked at the paper and weakly support acceptance of the paper. Program Chairs also looked at this paper and believe that its contribution is too marginal and incremental in its current form. We encourage the authors to resubmit."
    },
    "Reviews": [
        {
            "title": "Original and creative work - hesitation about results.",
            "rating": "7: Good paper, accept",
            "review": "Summary: The authors propose an input switched affine network to do character-level language modeling, a kind of RNN without pointwise nonlinearity, but with switching the transition matrix & bias based on the input character. This is motivated by intelligibility, since it allows decomposition of output contribution into these kappa_s^t terms, and use of basic linear algebra to probe the network.\n\nRegarding myself as a reviewer, I am quite sure I understood the main ideas and arguments of this paper, but am not an expert on RNN language models or intelligibility/interpretability in ML.\nI did not read any papers with a similar premise - closest related work I'm familiar with would be deconvnet for insight into vision-CNNs.\n\nPRO:\nI think this is original and novel work. This work is high quality, well written, and clearly is the result of a lot of work.\nI found section 4.5 about projecting into readout subspace vs \"computational\" subspace most interesting and meaningful.\n\nCON:\n+ The main hesitation I have is that the results on both parts (ISAN model, and analysis of it) are not entirely convincing:\n   (1) ISAN is only trained on small task (text8), not clear whether it can be a strong char-LM on larger scale tasks,\n   (2) nor do the analysis sections provide all that much real insight in the learned network.\n\n(1b) Other caveat towards ISAN architecture: this model in its proposed form is really only fit for small-vocabulary (i.e. character-based) language modeling, not a general RNN with large-vocab discrete input nor continuous input.\n\n(2a) For analysis: many cute plots and fun ideas of quantities to look at, but not much concrete insights.\n(2b) Not very clear which analysis is specific to the ISAN model, and which ideas will generalize to general nonlinear RNNs.\n(2c) Re sec 4.2 - 4.3: It seems that the quantity \\kappa_s^t on which analysis rests, isn't all that meaningful. Elaborating a bit on what I wrote in the question:\nFor example: Fig 2, for input letter \"u\" in revenue, there's a red spot where '_' character massively positively impacts the logit of 'e'. This seems quite meaningless, what would be the meaning of influence of '_' character? So it looks ot me that the switching matrix W_u (and prior W_n W_e etc) are using previous state in an interesting way to produce that following e. So that metric \\kappa_s^t just doesn't seem very meaningful.\nThis remark relates to the last paragraph of Sec4.2.\n\nEven though the list of cons here is longer than pro's, I recommend accept; specifically because the originality of this work will in any case make it more vulnerable to critiques. This work is well-motivated, very well-executed, and can inspire many more interesting investigations along these lines.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "",
            "rating": "6: Marginally above acceptance threshold",
            "review": "Summary:  The authors present a simple RNN with linear dynamics for language modeling. The linear dynamics greatly enhance the interpretability of the model, as well as provide the potential to improve performance by caching the dynamics for common sub-sequences. Overall, the quantitative comparison on a benchmark task is underwhelming. It’s unclear why the authors didn’t consider a more common dataset, and they only considered a single dataset. On the other hand, they present a number of well-executed techniques for analyzing the behavior of the model, many of which would be impossible to do for a non-linear RNN. \n\nOverall, I recommend that the paper is accepted, despite the results. It provides an interesting read and an important contribution to the research dialogue. \n\nFeedback\n\nThe paper could be improved by shortening the number of analysis experiments and increasing the discussion of related sequence models. Some of the experiments were very compelling, whereas some of them (eg. 4.6) sort of feels like you’re just showing the reader that the model fits the data well, not that the model has any particularly important property. We trust that the model fits the data well, since you get reasonable perplexity results. \n\nLSTMS/GRUs are great for for language modeling for data with rigid combinatorial structure, such as nested parenthesis. It would have been nice if you compared your model to non-linear methods on this sort of data. Don’t be scared of negative results! It would be interesting if the non-linear methods were substantially better on these tasks. \n\nYou should definitely add a discussion of Belanger and Kakade 2015 to the related work. They have different motivations (fast, scalable learning algorithms) rather than you (interpretable latent state dynamics and simple credit assignment for future predictions given past). On the other hand, they also have linear dynamics, and look at the singular vectors of the transition matrix to analyze the model. \n\nMore broadly, it would be useful for readers if you discussed LDS more directly. A lot of this comparison came up in the openreview discussion, and I recommend folding this into the paper. For example, it would be useful to emphasize that the bias vectors correspond to columns of the Kalman gain matrix. \n\nOne last thing regarding LDS: your model corresponds to Kalman filtering but in an LDS you can also do Kalman smoothing, where state vectors are inferred using the future in addition to the past observations. Could you do something similar in your model?\n\nWhat if you said that each matrix is a sparse/convex combination of a set of dictionary matrices? This parameter sharing could provide even more interpretability, since the characters are then represented by the low-dimensional weights used to combine the dictionary elements. This could also provide more scalability to word-level problems. \n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A character language model that gains some interpretability without large losses in predictivity",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The authors present a character language model that gains some interpretability without large losses in predictivity. \n\nCONTRIBUTION:\n\nI'd characterize the paper as some experimental investigation of a cute insight.  Recall that multi-class logistic regression allows you to apportion credit for a prediction to the input features: some features raised the probability of the correct class, while others lowered it.  This paper points out that a sufficiently simple RNN model architecture is log-linear in the same way, so you can apportion credit for a prediction among elements of the past history.  \n\nPROS:\n\nThe paper is quite well-written and was fun to read.  It's nice to see that a simple architecture still does respectably.\nIt's easy to imagine using this model for a classroom assignment.  \nIt should be easy to implement, and the students could replicate the authors' investigation of what influences the network's predictions.\nThe authors present some nice visualizations.\n\nSection 5.2 also describes some computational benefits.\n\nCAVEATS ON PREDICTIVE ACCURACY:\n\n* Figure 1 says that the ISAN has \"near identical performance to other architectures.\"  But this appears true only when comparing the largest models.  \n\nExplanation: It appears that for smaller parameter sizes, a GRU still beats the authors' model by 22% to 39% in the usual metric of perplexity per word (ppw).  (That's how LM people usually report performance, with a 10% reduction in ppw traditionally being considered a good Ph.D. dissertation.  I assumed an average of 7 chars/word when converting cross-entropy/char to perplexity/word.)  \n\n* In addition, it's not known whether this model family will remain competitive beyond the toy situations tested here.\n\nExplanation: The authors tried it only on character-based language modeling, and only on a 10M-char dataset, so their ppw is extremely high: 2135 for the best models in this paper.  By contrast, a word-based RNN LM trained on 44M words gets ppw of 133, and trained on 800M words gets ppw of 51.  [Numbers copied from the paper I cited before: https://transacl.org/ojs/index.php/tacl/article/view/561 .]  Those are language models that are good enough to use for something; maybe the authors' model would continue to fare well in this regime, but we just don't know.  (Has the Text8 benchmark in this paper been seriously used for language modeling before?  It was designed for text compression, a rather different setting where smaller datasets are meaningful because compression is done online, without a training/test split as done for language modeling.  The baseline results in this paper are drawn from a contemporaneous submission with many of the same authors.)\n\nCAVEATS ON INTERPRETABILITY:\n\nI liked the visualizations as an educational tool.  Maybe they'll inspire other visualization ideas for other models.\n\nOn the other hand, I'm not sure whether one gets much actionable information from these visualizations:\n\n* Sometimes, visualization is used as a way to understand what a model is doing wrong so that you can fix the model.  But that might not work here: this model doesn't seem to have a lot of room for adjustment before it would stop being interpretable.  (Although you could leave the model alone and preprocess the input data, I guess ...)\n\n* Sometimes, visualization is used to explain a single machine prediction to a human who will make the final decision about whether to trust that prediction (e.g., Singh et al.'s LIME paper).  It's hard to imagine how that would work in this kind of SEQUENTIAL prediction setting, though.\n\nOTHER COMMENTS:\n\nMost of my technical reactions are already given in my pre-review questions.  Thanks to the authors for their answers, and I appreciate that they are running followup experiments for the next version of the paper!\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}