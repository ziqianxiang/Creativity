{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "The reviewers were very favourable, and the paper is on a highly-relevant topic and explores a useful practical trick.",
        "decision": "Accept (Oral)"
    },
    "Reviews": [
        {
            "title": "A demonstration that NPI can learn to solve Tower of Hanoi!",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "This paper argues that being able to handle recursion is very important for neural programming architectures — that handling recursion allows for strong generalization to out of domain test cases and learning from smaller amounts of training data.  Most of the paper is a riff on the Reed & de Freitas paper on Neural Programmer Interpreters from ICLR 2016 which learns from program traces — this paper trains NPI models on traces that have recursive calls.  The authors show how to verify correctness by evaluating the learned program on only a small set of base cases and reduction rules and impressively, show that the NPI architecture is able to perfectly infer Bubblesort and the Tower of Hanoi problems.  \n\nWhat I like is that the idea is super simple and as the authors even mention, the only change is to the execution traces that the training pipeline gets to see.  I’m actually not sure what the right take-away is — does this mean that we have effectively solved the neural programming problem when the execution traces are available? (and was the problem too easy to begin with?).    For example, a larger input domain (as one of the reviewers also mentions) is MNIST digits and we can imagine a problem where the NPI must infer how to sort MNIST digits from highest to lowest.  In this setting, having execution traces would effectively decouple the problem of recognizing the digits from that of inferring the program logic — and so the problem would be no harder than learning to recognize MNIST digits and learning to bubble sort from symbols.  What is a problem where we have access to execution traces but cannot infer it using the proposed method?\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Greatly improved training and analysis of NPI",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "review": "This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form. The authors show better sample complexity and generalization results for addition and bubblesort programs, and add two new and more interesting tasks - topological sort and quicksort (added based on reviewer discussion). Furthermore, they actually *prove* that the algorithms learned by the model generalize perfectly, which to my knowledge is the first time this has been done in neural program induction.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Nifty extension to make NPI more practical",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "This is a very interesting and fairly easy to read paper. \nThe authors present a small, yet nifty approach to make Neural Programming Interpreters significantly more powerful. By allowing recursion, NPI generalizes better from fewer execution traces.\nIt's an interesting example of how a small but non-trivial extension can make a machine learning method significantly more practical.\n\nI also appreciate that the same notation was used in this paper and the original Deepmind paper. As a non-expert on this topic, it was easy to read the original paper in tandem. \n\nMy one point of critique is that the generalization proves are a bit vague. For the numerical examples in the paper, you can iterate over all possible execution paths until the next recursive call. However, how would this approach generalize a continuous input space (e.g. the 3D car example in the original paper). It seems that a prove of generalization will still be intractable in the continuous case? \n\nAre you planning on releasing the source code?",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}