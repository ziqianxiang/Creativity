{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "This paper comes up with a novel approach to searching the space of architectures for deep neural networks using reinforcement learning. The idea is straightforward and sensible: use a reinforcement learning strategy to iteratively grow a deep net graph (the space of actions is e.g. adding different layer types) via Q-learning. The reviewers agree that the idea is interesting, novel and promising but are underwhelmed with the execution of the experiments and the empirical results. \n \n The idea behind the paper and the formulation of the problem are quite similar to a concurrent submission (https://openreview.net/forum?id=r1Ue8Hcxg) which has much higher scores. That paper formulates their reinforcement learning strategy using the REINFORCE algorithm while this one uses Q-learning. The major discrepancy between the papers is in the execution of the experiments. This paper had a much more restricted set of experiments on a smaller search space and thus had less impressive results. The other paper explored a much larger space of architectures and explored recurrent neural networks, achieving state-of-the-art on multiple tasks and finding exciting novel architectures that challenge current standard models (LSTMs). As a result that paper received three 9's and this one three 6's.\n \n The authors argue that they had almost the same idea but did not have access to the same amount of computing resources as the other paper. That certainly is warranted as the other paper used an *extreme* amount of compute resources for their experiments. \n \n Given the average scores of ICLR and target acceptance rate, three 6s should normally be considered a reject. Specifically, in the absence of the other paper this would be rejected. However, the authors argue that this would be unfair, since the major difference was simply in compute resources. A major concern of the reviewers was that this approach was too computationally expensive, which is strongly contradictory to the scores for the other paper. In reality, the other paper really is just much more interesting because of the empirical results. However, I sympathize with the authors as the other paper essentially demonstrates that their idea is sensible and effective (albeit only with obscene compute resources), and the paper would effectively be \"scooped\" from further submissions.\n \n (Note a contrarian viewpoint might take an analogy from other fields. e.g. experimental physics papers are likely rejected if they don't have multi-billion dollar equipment to run the right set of exhaustive experiments, which is the difference between e.g. the large hadron collider and most university depts.)\n \n Pros:\n - The paper proposes a novel approach to architecture search using reinforcement learning\n - The approach is technically sound and interesting\n - The authors achieve good results automatically on benchmark tasks using their approach\n - They empirically demonstrate that their method works (via plots demonstrating the behavior of the algorithm while varying how exploratory the algorithm is)\n \n Cons:\n - The search space is very constrained (too much for us to learn anything interesting from the results)\n - The experimental results are good but underwhelming\n - Compared to e.g. Bayesian optimization methods, this approach seems very wasteful in compute resources (e.g. 1500 runs of training before the approach starts exploiting).\n \n The Program Chairs have also reviewed this paper, and taken everything into account, have reccommended this paper for poster presentation at the main conference.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "review",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper introduces a reinforcement learning framework for designing a neural network architecture. For each time-step, the agent picks a new layer type with corresponding layer parameters (e.g., #filters). In order to reduce the size of state-action space, they used a small set of design choices.\n\nStrengths:\n- A novel approach for automatic design of neural network architectures.\n- Shows quite promising results on several datasets (MNIST, CIFAR-10).\n\nWeakness:\n- Limited architecture design choices due to many prior assumptions (e.g., a set of possible number of convolution filters, at most 2 fully-connected layers, maximum depth, hard-coded dropout, etc.)\n- The method is demonstrated in tabular Q-learning setting, but it is unclear whether the proposed method would work in a large state-action space.\n\nOverall, this is an interesting and novel approach for neural network architecture design, and it seems to be worth publication despite some weaknesses.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The paper looks solid and the idea is natural. Results seem promising as well.\n\nI am mostly concerned about the computational cost of the method. 8-10 days on 10 GPUs for relatively tiny datasets is quite prohibitive for most applications I would ever encounter.\n I think the main question is how this approach scales to larger images and also when applied to more exotic and possibly tiny datasets. Can you run an experiment on Caltech-101 for instance? I would be very curious to see if your approach is suitable for the low-data regime and areas where we all do not know right away how a suitable architecture looks like. For Cifar-10/100, MNIST and SVHN, everyone knows very well what a reasonable model initialization looks like.\n\nIf you show proof that you can discover a competitive architecture for something like Caltech-101, I would recommend the paper for publication.\n\nMinor: \n- ResNets should be mentioned in Table ",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review",
            "rating": "6: Marginally above acceptance threshold",
            "review": "Authors learn deep architectures on a few small vision problems using Q-learning and obtain solid results, SOTA results when limiting to certain types of layers and competitive against everything else. It would be good to know how well this performs when allowing more complex structures. Paper would be much more convincing on a real-size task such as ImageNet.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}