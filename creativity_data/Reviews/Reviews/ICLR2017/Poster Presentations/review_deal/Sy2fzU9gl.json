{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "This paper proposes a modification of the variational ELBO in encourage 'disentangled' representations, and proposes a measure of disentanglement. The main idea and is presented clearly enough and explored through experiments. This whole area still seems a little bit conceptually confused, but by proposing concrete metrics and methods, this paper makes several original contributions.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Very interesting results, but more details and more quantitative results are needed",
            "rating": "6: Marginally above acceptance threshold",
            "review": "\nThis paper proposes the beta-VAE, which is a reasonable but also straightforward generalization of the standard VAE. In particular, a weighting factor beta is added for the KL-divergence term to balance the likelihood and KL-divergence. Experimental results show that tuning this weighting factor is important for learning disentangled representations. A linear-classifier based protocol is proposed for measuring the quality of disentanglement. Impressive illustrations on manipulating latent variables are shown in the paper. \n\nLearning disentangled representations without supervision is an important topic. Showing the effectiveness of VAE for this task is interesting. Generalizing VAE with a weighting factor is straightforward (though reformulating VAE is also interesting), the main contribution of this paper is on the empirical side. \n\nThe proposed protocol for measuring disentangling quality is reasonable. Establishing protocol is one important methodology contribution of this paper, but the presentation of Section 3 is still not good. Little motivation is provided at the beginning of Section 3. Figure 2 is a summary of the algorithm, which is helpful, but it still necessary to intuitively explain the motivation at the first place (e.g., what you expect if a factor is disentangled, and why the performance of a classifier can reflect such an expectation). Moreover, 1) z_diff appeared without any definition in the main text. 2) Use “decoding” for x~Sim(v,w) may make people confuse the ground truth sampling procedure w ith the trained decoder. \n\nThe illustrative figures on traversing the disentangled factor are impressive, though image generation quality is not as good as InfoGAN (not the main point of this paper). However, 1) it will be helpful to discuss if the good disentangling quality only attribute to the beta factor and VAE framework. For example, the training data in this paper seems to be densely sampled for the visualized factors. Does the sampling density play a critical role? 2) Not too many qualitative results are provided for each experiment? Adding more figures (e.g., in appendix) to cover more factors and seeding images can strength the conclusions drawn in this paper. 3) Another detailed question related to the generalizability of the model: are the seeding image for visualizing faces from unseen subjects or subjects in the training set? (maybe I missed something here.)\n\nQuantitative results are only presented for the synthesized 2D shape. What hinders this paper from reporting quantitative numbers on real data (e.g., the 2D and 3D face data)? One possible reason is that not all factors can be disentangled for real data, but it is still feasible to pick up some well-defined factor to measure the quantitative performance. \n\nQuantitative performance is only measured by the proposed protocol. Since the effectiveness of the protocol is something the paper need to justify, reporting quantitative results using simpler protocol is helpful both for demonstrating the disentangling quality and for justifying the proposed protocol (consistency with other measurement). A simple experiment is facial identity recognition and pose estimation using disentangled features on a standard test set (like in Reed et al, ICML 2014). \n\nIn Figure 6 (left), why ICA is worse than PCA for disentanglement? Is it due to the limitation of the ICA algorithm or some other reasons? \n\nIn Figure 6 (right), what is “factor change accuracy”? According to Appendix A.4 (which is not referred to in the main text), it is the “Disentanglement metric score”. Is that right?\nIf so Figure 6 (right) shows the reconstruction results for the best disentanglement metric score. Then, 1) how about random generation or traversing along a disentangled factor? 2) more importantly, how is the reconstruction/generation results when the disentanglement metric score is suboptimal. \n\nOverall, the results presented in this paper are very interesting, but there are many details to be clarified. Moreover, more quantitative results are also needed. I hope at least some of the above concerns can be addressed. \n\n\n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The paper proposes beta-VAE which strengthen the KL divergence between the recognition model and the prior to limit the capacity of latent variables while sacrificing the reconstruction error. This allows the VAE model to learn more disentangled representation. \n\nThe main concern is that the paper didn't present any quantitative result on log likelihood estimation. On the quality of generated samples, although the beta-VAE learns disentangled representation, the generated samples are not as realistic as those based on generative adversarial network, e.g., InfoGAN. Beta-VAE learns some interpretable factors of variation, but it still remains unclear why it is a better (or more efficient) representation than that of standard VAE.\n\nIn experiment, what is the criteria for cross-validation on hyperparameter \\beta?\n\nThere also exists other ways to limit the capacity of the model. The simplest way is to reduce the latent variable dimension. I am wondering how the proposed beta-VAE is a better model than the VAE with reduced, or optimal latent variable dimension.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Simple and effective",
            "rating": "7: Good paper, accept",
            "review": "Summary\n===\n\nThis paper presents Beta-VAE, an augmented Variational Auto-Encoder which\nlearns disentangled representations. The VAE objective is derived\nas an approximate relaxation of a constrained optimization problem where\nthe constraint matches the latent code of the encoder to a prior.\nWhen KKT multiplier beta on this constraint is set to 1 the result is the\noriginal VAE objective, but when beta > 1 we obtain Beta-VAE, which simply\nincreases the penalty on the KL divergence term. This encourages the model to\nlearn a more efficient representation because the capacity of the latent\nrepresentation is more limited by beta. The distribution of the latent\nrepresentation is rewarded more when factors are independent because\nthe prior (an isotropic Gaussian) encourages independent factors, so the\nrepresentation should also be disentangled.\n\nA new metric is proposed to evaluate the degree of disentanglement. Given\na setting in which some disentangled latent factors are known, many examples\nare generated which differ in all of these factors except one. These examples\nare encoded into the learned latent representation and a simple classifier\nis used to predict which latent factor was kept constant. If the learned\nrepresentation does not disentangle the constant factor then the classifier\nwill more easily confuse factors and its accuracy will be lower. This\naccuracy is the final number reported.\n\nA synthetic dataset of 2D shapes with known latent factors is created to\ntest the proposed metric and Beta-VAE outperforms a number of baselines\n(notably InfoGAN and the semi-supervised DC-IGN).\n\nQualitative results show that Beta-VAE learns disentangled factors\non the 3D chairs dataset, a dataset of 3D faces, and the celebA dataset\nof face images. The effect of varying Beta is also evaluated using the proposed\nmetric and the latent factors learned on the 2D shapes dataset are explored\nin detail.\n\n\nStrengths\n===\n* Beta-VAE is simple and effective.\n\n* The proposed metric is a novel way of testing whether ground truth factors\nof variation have been identified.\n\n* There is extensive comparison to relevant baselines.\n\n\nWeaknesses\n===\n\n* Section 3 describes the proposed disentanglement metric, however I feel\nI need to read the caption of the associated figure (I thank for adding\nthat) and Appendix 4 to understand the metric intuitively or in detail.\nIt would be easier to read this section if a clear intuition preceeded\na detailed description and I think more space should be devoted to this\nin the paper.\n\n* Appendix 4: Why was the bottom 50% of the resulting scores discarded?\n\n* As indicated in pre-review comments, the disentanglement metric is similar\nto a measure of correlation between latent features. Could the proposed metric\nbe compared to a direct measure of cross-correlation between latent factors\nestimated over the 2D shapes dataset?\n\n\n* The end of section 4.2 observes that high beta values result in low\ndisentanglement, which suggests the most efficient representation is not\ndisentangled. This seems to disagree with the intuition from the approach\nsection that more efficient representations should be disentangled. It would\nbe nice to see discussion of potential reasons for this disagreement.\n\n* The writing is somewhat dense.\n\n\nOverall Evaluation\n===\nThe core idea is novel, simple and extensive tests show that it is effective.\nThe proposed evaluation metric is novel might come into broader use.\nThe main downside to the current version of this paper is the presentation,\nwhich provides sufficient detail but could be more clear.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}