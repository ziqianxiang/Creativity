{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "Quality, Clarity: \n  The paper is well written. Further revisions have been made upon the original.\n \n Originality, Significance:\n  The paper presents an action-conditional recurrent network that can predict frames in video games hundreds of steps in the future. This is done using a mix of (a) architectural modifications; (b) jumpy predictions; and (c) particular training schemes. The experimental validation is extensive, now including additional comparisons suggested by reviewers.\n There is not complete consensus about the significance of the contributions, with one reviewer seeking additional technical novelty. Overall, the paper appears to provide interesting and very soundly-evaluated results, which likely promises to be the new standard for this type of prediction problem.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Some interesting experimental observations, but significance and novelty of proposed architecture needs better justification",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The paper presents an action-conditional recurrent network that can predict frames in video games hundreds of steps in the future. The paper claims three main contributions: \n1. modification to model architecture (used in Oh et al.) by using action at time t-1 to directly predict hidden state at t\n2. exploring the idea of jumpy predictions (predictions multiple frames in future without using intermediate frames)\n3. exploring different training schemes (trade-off between observation and prediction frames for training LSTM)\n\n1. modification to model architecture\n+ The motivation seems good that in past work (Oh et al.) the action at t-1 influences x_t, but not the state h_t of the LSTM. This could be fixed by making the LSTM state h_t dependent on a_{t-1}\n- However, this is of minor technical novelty. Also, as pointed in reviewer questions, a similar effect could be achieved by adding a_t-1 as an input to the LSTM at time t. This could be done without modifying the LSTM architecture as stated in the paper. While the authors claim that combining a_t-1 with h_t-1 and s_t-1 performs worse than the current method which combines a_t-1 only with h_t-1, I would have liked to see the empirical difference in combining a_t-1 only with s_t-1 or only with h_t-1. Also, a stronger motivation is required to support the current formulation.\n- Further, the benefits of this change in architecture is not well analyzed in experiments. Fig. 5(a) provides the difference between Oh et al. (with traditional LSTM) and current method. However, the performance difference is composed of 2 components (difference in training scheme and architecture). This contribution of the architecture to the performance is not clear from this experiment. The authors did claim in the pre-review phase that Fig. 12 (a) shows the difference in performance only due to architecture for \"Seaquest\". However, from this plot it appears that the gain at 100-steps (~15)  is only a small fraction of the overall gain in Fig. 5 (a) (~90). It is difficult to judge the significance of the architecture modification from this result for one game.\n\n2. Exploring the idea of jumpy predictions:\n+ As stated by the authors, omitting the intermediate frames while predicting future frames could significantly sppedup simulations.\n+ The results in Fig. 5(b) present some interesting observations that omitting intermediate frames does not lead to significant error-increase for at least a few games.\n- However, it is again not clear whether the modification in the current model leads to this effect or it could be achieved by previous models like Oh et al.\n- While, the observations themselves are interesting, it would have been better to provide a more detailed analysis for more games. Also, the novelty in dropping intermediate frames for speedup is marginal.\n\n3. Exploring different training schemes\n+ This is perhaps the most interesting observation presented in the paper. The authors present the difference in performance for different training schemes in Fig. 2(a). The training schemes are varied based on the fraction of training phase which only uses observation frames and the fraction that uses only prediction frames.\n+ The results show that this change in training can significantly affect prediction results and is the biggest contributor to performance improvement compared to Oh et al.\n- While this observation is interesting, this effect has been previously explored in detail in other works like schedule sampling (Bengio et al.) and to some extent in Oh et al.\n\nClarity of presentation:\n- The exact experimental setup is not clearly stated for some of the results. For instance, the paper does not say that Fig. 2(a) uses the same architecture as Oh et al. However, this is stated in the response to reviewer questions.\n- Fig. 4 is difficult to interpret. The qualitative difference between Oh et al. and current method could be highlighted explicitly. \n- Minor: The qualitative analysis section requires the reader to navigate to various video-links in order to understand the section. This leads to a discontinuity in reading and is particularly difficult while reading a printed-copy.\n\nOverall, the paper presents some interesting experimental observations. However, the technical novelty and contribution of the proposed architecture and training scheme is not clear.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "rating": "7: Good paper, accept",
            "review": "[UPDATE]\nAfter going through the response from the author and the revision, I increased my review score for two reasons.\n1. I thank the reviewers for further investigating the difference between yours and the other work (Scheduled sampling, Unsupervised learning using LSTM) and providing some insights about it.\nThis paper at least shows empirically that 100%-Pred scheme is better for high-dimensional video and for long-term predictions.\nIt would be good if the authors briefly discuss this in the final revision (either in the appendix or in the main text).\n\n2. The revised paper contains more comprehensive results than before.\nThe presented result and discussion in this paper will be quite useful to the research community as high-dimensional video prediction involves large-scale experiments that are computationally expensive.\n\n- Summary\nThis paper presents a new RNN architecture for action-conditional future prediction. The proposed architecture combines actions into the recurrent connection of the LSTM core, which performs better than the previous state-of-the-art architecture [Oh et al.]. The paper also explores and compares different architectures such as frame-dependent/independent mode and observation/prediction-dependent architectures. The experimental result shows that the proposed architecture with fully prediction-dependent training scheme achieves the state-of-the-art performance on several complex visual domains. It is also shown that the proposed prediction architecture can be used to improve exploration in a 3D environment.\n\n- Novelty\nThe novelty of the proposed architecture is not strong. The difference between [Oh et al.] and this work is that actions are combined into the LSTM in this paper, while actions are combined after LSTM in [Oh et al.]. The jumpy prediction was already introduced by [Srivastava et al.] in the deep learning area. \n\n- Experiment\nThe experiments are well-designed and thorough. Specifically, the paper evaluates different training schemes and compares different architectures using several rich domains (Atari, 3D worlds). Besides, the proposed method achieves the state-of-the-art results on many domains and presents an application for model-based exploration.\n\n- Clarity\nThe paper is well-written and easy to follow.\n\n- Overall \nAlthough the proposed architecture is not much novel, it achieves promising results on Atari games and 3D environments. In addition, the systematic evaluation of different architectures presented in the paper would be useful to the community.\n\n[Reference]\nNitish Srivastava, Elman Mansimov, Ruslan Salakhutdinov. Unsupervised Learning with LSTMs. ICML 2016.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "The authors propose a recurrent neural network architecture that is able to output more accurate long-term predictions of several game environments than the current state-of-the-art.\nThe original network architecture was inspired by inability of previous methods to accurately predict many time-steps into the future,\nand their inability to jump directly to a future prediction without iterating through all intermediate states.\nThe authors have provided an extensive experimental evaluation on several benchmarks with promising results.\nIn general the paper is well written and quite clear in its explanations.\nDemonstrating that this kind of future state prediction is useful for 3D maze exploration is a plus.\n\n# Minor comments:\n`jumpy predictions have been developed in low-dimensional observation spaces' - cite relevant work in the paper.\n\n# Typos\nSection 3.1 - `this configuration is all experiments'",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}