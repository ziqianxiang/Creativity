{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "The paper explores a model that performs joint embedding of acoustic sequences and character sequences. The reviewers agree the paper is well-written, the proposed loss function is interesting, and the experimental evaluation is sufficient. Having said that, there are also concerns that the proxy tasks used in the experiments are somewhat artificial.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper proposes an approach to learning word vector representations for character sequences and acoustic spans jointly. The paper is clearly written and both the approach and experiments seem reasonable in terms of execution. The motivation and tasks feel a bit synthetic as it requires acoustics spans for words that have already been segmented from continuous speech - - a major assumption. The evaluation tasks feel a bit synthetic overall and in particular when evaluating character based comparisons it seems there should also be phoneme based comparisons.\n\nThere's a lot of discussion of character edit distance relative to acoustic span similarity. It seems very natural to also include phoneme string edit distance in this discussion and experiments. This is especially true of the word similarity test. Rather than only looking at levenshtein edit distance of characters you should evaluate edit distance of the phone strings relative to the acoustic embedding distances. Beyond the evaluation task the paper would be more interesting if you compared character embeddings with phone string embeddings. I believe the last function could remain identical it's just swapping out characters for phones as the symbol set.  finally in this topic the discussion and experiments should look at homophones As if not obvious what the network would learn to handle these.\n\n the vocabulary size and training data amount make this really a toy problem. although there are many pairs constructed most of those pairs will be easy distinctions. the experiments and conclusions would be far stronger with a larger vocabulary and word segment data set with subsampling all pairs perhaps biased towards more difficult or similar pairs.\n\n it seems this approach is unable to address the task of keyword spotting in longer spoken utterances. If that's the case please add some discussion as to why you are solving the problem of word embeddings given existing word segmentations. The motivating example of using this approach to retrieve words seems flawed if a recognizer must be used to segment words beforehand ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "well-done domain adaptation",
            "rating": "6: Marginally above acceptance threshold",
            "review": "this proposes a multi-view learning approach for learning representations for acoustic sequences. they investigate the use of bidirectional LSTM with contrastive losses. experiments show improvement over the previous work.\n\nalthough I have no expertise in speech processing, I am in favor of accepting this paper because of following contributions:\n- investigating the use of fairly known architecture on a new domain.\n- providing novel objectives specific to the domain\n- setting up new benchmarks designed for evaluating multi-view models\n\nI hope authors open-source their implementation so that people can replicate results, compare their work, and improve on this work.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The paper investigates jointly trained acoustic and character level word embeddings, but only on a very small task.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "Pros:\n  Interesting training criterion.\nCons:\n  Missing proper ASR technique based baselines.\n\nComments:\n  The dataset is quite small.\n  ROC curves for detection, and more measurements, e.g. EER would probably be helpful besides AP.\n  More detailed analysis of the results would be necessary, e.g. precision of words seen during training compared to the detection\n  performance of out-of-vocabulary words.\n  It would be interesting to show scatter plots for embedding vs. orthographic distances.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}