{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "The paper is well written and easy to follow. It has strong connections to other convolutional models such as pixel cnn and bytenet that use convolutional only models with little or no recurrence. The method is shown to be significantly faster than using RNNs, while not losing out on the accuracy.\n \n Pros:\n - Fast model\n - Good results\n \n Cons:\n - Because of its strong relationship to other models, the novelty is incremental.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Review",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper introduces the Quasi-Recurrent Neural Network (QRNN) that dramatically limits the computational burden of the temporal transitions in\nsequence data. Briefly (and slightly inaccurately) model starts with the LSTM structure but removes all but the diagonal elements to the transition\nmatrices. It also generalizes the connections from lower layers to upper layers to general convolutions in time (the standard LSTM can be though of as a convolution with a receptive field of 1 time-step). \n\nAs discussed by the authors, the model is related to a number of other recent modifications of RNNs, in particular ByteNet and strongly-typed RNNs (T-RNN). In light of these existing models, the novelty of the QRNN is somewhat diminished, however in my opinion their is still sufficient novelty to justify publication.\n\nThe authors present a reasonably solid set of empirical results that support the claims of the paper. It does indeed seem that this particular modification of the LSTM warrants attention from others. \n\nWhile I feel that the contribution is somewhat incremental, I recommend acceptance. \n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Nice paper",
            "rating": "7: Good paper, accept",
            "review": "This paper introduces a novel RNN architecture named QRNN.\n\nQNNs are similar to gated RNN , however their gate and state update  functions depend only on the recent input values, it does not depend on the previous hidden state. The gate and state update functions are computed through a temporal convolution applied on the input.\nConsequently, QRNN allows for more parallel computation since they have less  operations in their hidden-to-hidden transition depending on the previous hidden state compared to a GRU or LSTM. However, they possibly loose in expressiveness relatively to those models. For instance, it is not clear how such a model deals with long-term dependencies without having to stack up several QRNN layers.\n\nVarious extensions of QRNN, leveraging Zoneout, Densely-connected or seq2seq with attention, are also proposed.\n\nAuthors evaluate their approach on various tasks and datasets (sentiment classification, world-level language modelling and character level machine translation). \n\nOverall the paper is an enjoyable read and the proposed approach is interesting,\nPros:\n- Address an important problem\n- Nice empirical evaluation showing the benefit of their approach\n- Demonstrate up to 16x speed-up relatively to a LSTM\nCons:\n- Somewhat incremental novelty compared to (Balduzizi et al., 2016)\n\nFew specific questions:\n- Is densely layer necessary to obtain good result on the IMDB task. How does a simple 2-layer QRNN compare with 2-layer LSTM?  \n- How does the i-fo-ifo pooling perform comparatively? \n- How does QRNN deal with long-term time depency? Did you try on it on simple toy task such as the copy or the adding task? ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "good.",
            "rating": "7: Good paper, accept",
            "review": "\nThis paper points out that you can take an LSTM and make the gates only a function of the last few inputs  - h_t = f(x_t, x_{t-1}, ...x_{t-T}) - instead of the standard - h_t = f(x_t, h_{t-1}) -, and that if you do so the networks can run faster and work better. You're moving compute from a serial stream to a parallel stream and also making the serial stream more parallel. Unfortunately, this simple, effective and interesting concept is somewhat obscured by confusing language.\n\n- I would encourage the authors to improve the explanation of the model. \n- Another improvement might be to explicitly go over some of the big Oh calculations, or give an example of exactly where the speed improvements are coming from. \n- Otherwise the experiments seem adequate and I enjoyed this paper.\n\nThis could be a high value contribution and become a standard neural network component if it can be replicated and if it turns out to work reliably in multiple settings.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}