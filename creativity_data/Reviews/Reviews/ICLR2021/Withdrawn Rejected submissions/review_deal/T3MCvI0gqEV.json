{
    "Decision": "",
    "Reviews": [
        {
            "title": "SPL_Review",
            "review": "This paper presents a webly-supervised model for video recognition. The key idea od the proposed approach is to exploit the noisy data obtained from queried web videos as a weak supervision signal by introducing the concept of Sub-Pseudo Labels (SPL). These SPL are then used in a knowledge distillation framework to learn video representations. Interesting results are reported on several popular datasets such as HMDB51 and UCF101.\n\nPros:\n+ Overall, the paper is well written and easy to follow. The key ideas of this work (i.e. the SPL concept and the proposed knowledge-distillation architecture) are well presented and adequately supported by experiments.\n+ The most relevant related works are clearly presented, although the experimental results are not fully convincing in comparing the proposed model to similar previous webly-supervised action recognition models.\n+ Experimental results are reported on several public benchmarks and, in general, they are quite interesting and competitive with the state-of-the-art.\n\nCons:\n- Although interesting, the framework is a bit incremental (especially w.r.t Xie et al. 2020). The integration of the proposed SPL within a knowledge distillation architecture seems novel, but the comparison to the closest previous works could be improved.\n- Experimental results are interesting and the authors present results on several datasets. However, the comparison with similar webly-supervised frameworks is not fully convincing. In particular, there are several comparisons with other pre-training strategies, but it is hard to judge the effectiveness of the overall approach in comparison to other webly-supervised video understanding frameworks since there are no direct comparisons. \n\n\nMinor comments:\n- The prior works are well presented and most of the recent relevant works are properly cited. However, learning video recognition models from web videos (and web images) has been studied by many researchers. There are some related works that have not been discussed that are definitely relevant to this work, in particular in regards of the major challenges related to transferring the noisy knowledge coming from the web for video understanding tasks:\nC. Gan et al, \"You Lead, We Exceed: Labor-Free Video Concept Learning by Jointly Exploiting Web Videos and Images\", CVPR 2016\nS. Yeung et al, \"Learning to learn from noisy web videos\", CVPR 2017\nC. Rupprecht et al, \"Learning without Prejudice: Avoiding Bias in Webly-Supervised Action Recognition\", CVIU 2018\n- The motivations underlying the choice of the various datasets used in the experiments should be presented more clearly.\n- Section 4.6 is hard to follow; it's not clear to me what has been done here and how it relates to the prior works. It is nice to see how SPL generalizes to weakly-labeled images, but, as they stand, these preliminary experiments are briefly presented and not fully convincing.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Sub-pseudo labels for weak learning",
            "review": "Summary \n\nThe paper proposes a technique to improve action classification for the case that weakly labeled training samples are available, e.g. in form of search queries or tags, and that a pretrained 'teacher' model is available, that can also generate class labels on those data. In this case, instead of just training on weak labels only or on teacher labels only, the paper proposes to use subpseudo labels out of both modalities using different merging techniques with a binary merging turning out as giving the best performance. The evaluation is done on Kinetics-200, HMDB, UCF101, and SoccerNet with a pretraining on WebK200 and WebS4 resp.\n\nPaper strength\n\n- Overall the paper is able to present competitive results for the proposed method. Even when trained weakly with the same number of clips (Tab. 2), the subpseudo based training is able to outperform the weakly trained baseline.\n\n- The paper provides an extensive ablation study on the proposed idea.\n\n- The paper is well written and easy to follow.\n\nPaper weakness\n\n- I'm not sure how applicable the overall idea would be for everyday actions. Obviously, datasets like Kinetics, UCF101, and HMDB which are at least partly based on Youtube clips and also have a vocabulary that is easy to search for (in the end, this is how they were build) might profit from more data, even if it's just retrieved by search terms, but I'm not sure how this could be extended to data that does not fit this description e.g. Something-Something, Epic Kitchen etc. \n\n- As a related question in this line, would this still work if the teacher model would be from a different domain with different classes.\n\n- I have a feeling that the overall theoretical novelty of this paper might be a too limited for a machine learning conference, as the major contribution, in my impression, lays in the merging of weak labels and teacher predictions, which is a nice idea, but does not come with any theoretical foundation at this point. \n\nSummary\n\nOverall, I think that this is an interesting paper, but I'm not sure if it hits the mark for a major machine learning conference based on the points raised above. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "Summary\n-------\n\nThis paper proposes an approach to learning from large-scale webly-supervised video data for action recognition. Rather than training directly on the noisy web videos, a teacher model - trained on the target data - is used to identify alignment between the teacher and the noisy labels. Three reduced sub-pseudo label approaches are outlined to deal with clips that might not show the noisy web label. Experiments on existing datasets combined with new web videos show the potential of the proposed approach.\n\nStrengths\n---------\n\nThe notion of sub-pseudo labels is interesting and intuitive. In web videos, likely only a part of the long video shows the actual action, with the rest being noise. The ability to filter out such noise can boost video recognition from large-scale noisy sources.\n\nThe paper is clearly presented and comes with many experiments. Performing video experiments at scale is quite time-consuming, so the experiments are appreciated and help with understanding the pros and cons of the proposed approach and baselines. Figure 3 also helps with directly understanding the proposed variants and their relation to the baselines.\n\nWeaknesses\n----------\n\nA limitation of the proposed approach is that it is not possible to use arbitrary web videos for pre-training. The label spaces of D_t and D_p need to be identical to construct confusion matrix C. This is a restrictive setup and not of high practical value. More commonly, a model is trained on an arbitrary large-scale web video dataset, after which a parameter transfer is performed to any dataset. In the proposed setup, for each new target set D_t, a new web set D_p needs to be constructed. See for example the source set of (Ghadiyaram et al., 2019).\n\nThe limitation listed above also creates a problem with the experimental evaluation. For example, the comparison to (Ghadiyaram et al., 2019) is presumably done using the same D_p. This is however not fair to the baseline, as this baseline is not restricted in their choice of D_p. How does this baseline perform when using their proposed source set?\n\nOverall, the novelty of the paper is limited. Compared to current webly-supervised approaches, the proposed approach can assign sub-labels (Section 3.2) and then reduce the space of the sub-labels in three straight-forward ways (Section 3.3). While the simplicity of the approach is not negative at all (as it will enable a quicker integration into the field for one), the combination of limited technical novelty paired with modest improvements and a more restricted setup than baselines makes the paper low on impact overall.\n\nA number of other questions remain as well in the experiments:\n- What is the setup for HMDB51 and UCF101? Is K200 the target set for these datasets too?\n- Idem for SoccerNet, is SoccerNet the base network here, or K200? It is hard to extract the information from the text.\n- Why is Weak Label Train 82.8 in Table 1 and 83.9 in Table 2, even though Table 2 is with synthetic noise? Is it because the pre-training set is larger in Table 2?\n- If yes to the question above, the big question is: what does the comparison look like when using more clips in Table 1? Running many experiments on large dataset is understandably difficult, but the picture from current experiments is that the difference with current approaches disappears when using a larger D_p.\n\nConclusion\n----------\n\nThe paper presents a clear approach towards webly-supervised video action recognition. The notion of sub-pseudo labels is interesting and helps the recognition performance. There are however a number of pressing limitations, most notably regarding the strong limitation in the setup of D_p, subsequent restrictions to baselines in comparisons, and overall novelty of the paper. For the rebuttal, please address the concerns listed in the weaknesses.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}