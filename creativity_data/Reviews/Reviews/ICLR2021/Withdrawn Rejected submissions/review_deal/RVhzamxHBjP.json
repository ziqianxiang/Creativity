{
    "Decision": "",
    "Reviews": [
        {
            "title": "Breaking shift/flip symmetries in Fourier phase retrieval is interesting idea but the solution is heuristic and limited experiments",
            "review": "Summary: The paper mainly discusses the problem of symmetry breaking in phase retrieval problems. The most interesting (and heuristic) part of the paper is about shift/flip/sign ambiguities that arise in Fourier phase retrieval. The solution proposed in the paper on this particular topic is a heuristic that essentially says that do not use shifted versions of the images for training end-to-end networks. \n\nOriginality and significance: I think the most significant part among the problems discussed in the paper is about resolving shift and flip ambiguities that naturally arise in Fourier phase retrieval problem (sec 3.2). This is also the weakest part of this paper. \n- The heuristic proposed for symmetry breaking and experiments for this part require more explanation and clarity. I have read this part multiple times, but I failed to understand how the training data was created and how the symmetry patterns were broken. As far as I can tell, the authors centered the images at the time of training their U-net-A, but the images were not centered for U-net-B. If that is the case, then the results for flipped data set are confusing, because it seems both U-net-A and U-net-B were trained on the same dataset. \n- The authors claim that putting a black background in the images is something important that other papers ignore,  is that because the black background assumption almost never holds in reality?\n- The authors claim that they created 4 variants of Fashion MNIST, and it is the first rigorous evaluation. I have seen several papers that train networks with all kinds of rotated and translated versions of natural images (see prDeep as an example). \n\nQuality and clarity: The paper needs significant improvement. Some of the important things are missing or superficially treated. For example, it is unclear to me what is the reconstruction loss for the U-net-A for which the experiments are reported in the main text. \n\nI will encourage the authors to provide a clear description of how they trained the U-net-A and U-net-B for different scenarios. What training data was provided to both networks at the time of training and testing. It will also be useful to discuss how the authors will break symmetries for natural images with nonzero background, because in general the recovery of natural images with large dynamic range is much harder than reconstruction of Fashion MNIST or MNIST images. \n\n\nIn summary, the problem of breaking symmetry is interesting and relevant to Fourier phase retrieval, but the method and experiments presented in the paper are not convincing. \n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Neat & natural idea but I am not getting the message of the theoretical results",
            "review": "The paper discuss \"symmetries\" in inverse problems and most particularly in phase retrieval (PR). PR suffers from both obvious and more intricate indeterminacies, that depend on the setting. \nThree settings are considered: \n- real-valued signals, real-valued Gaussian sensing matrix\n- complex-valued signals, complex-valued Gaussian sensing matrix\n- complex-valued signals, complex-valued Fourier sensing matrix\n\nRecent work in PR has considered supervised learning-based approaches: pairs (x,y) of original and sensed signals (such that y ≈ |Ax|^2) are fed to a DNN. Learning will suffer from indeterminacies because x and, say, -x, will produce the same output and the network will waste much of its capacity trying to learn these irrelevant indeterminacies.\n\nAs such, the paper proposes to pre-process the training samples (more specifically x) so that learning is more efficient and robust to indeterminacies.\n\nThe idea is very neat and natural. The proposed pre-processings produce an improvement as shown experimentally. However the theoretical part (Section 2) of the paper is difficult to follow in my opinion: the nature and importance of the results is not clear.\n\nComments:\n- It's not clear to me if the pre-processings in Section 2 cover *all* possible indeterminacies or if there may be more ?\n- Many results revolve around the existence of a \"smallest representative set\" but the concept is not sufficiently well introduced nor discussed (it is indirectly introduced in Proposition 2.1)\n- I could follow Section 2.2 reasonably well but Sections 2.3 and 2.4 are quite abstract and I am not getting the message. What should be learnt from these sections ? What are the practical implications ? Are the given Propositions covering all possible indeterminacies ?\n- Why is \"any ray stemming from the origin a smallest representative subset for C\" ? This is an example of statements that are difficult to grasp without more background details.\n- Section 2.2: Proposition 2.1 seems to be covering sign ambiguities. What about translations ?",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A simple but effective method for identifying and learning sections (one-sided inverses) to functions which fail to be invertible due to symmetry.  Some issues with formulation of problem. ",
            "review": "\nThe authors use deep neural networks to learn inverse mappings $f^{-1} \\colon Y \\to X$, specifically fourier phase retrieval (FPR).  The main problem is that the ground truth $f \\colon X \\to Y$ may not be an injective function, so in general the fiber $f^{-1}(y)$ may be a set of points.  In this case, the authors show the neural network learns poorly, oscillating between different points in the fiber or choosing an average of the points in the fiber.   They solve this problem by learning a section $g$ of the map $f$ instead of an inverse.  That is, $g$ such that $f \\circ g = id$.    This is done by identifying a single representative for each fiber.  The set of such representatives $R$ is such that the restriction $f|_R$ is injective (up to a set of measure 0) and $g = f|_R^{-1}$.  The authors show that (in their example) if the set $R$ is chosen to be connected then $g$ is easier to learn.  Their main objective then becomes, given $f$ find the set $R$.  This can be done through theoretical analysis of the ground truth $f$.     \n\nMy summary above is written in more general language than employed in the paper.  I think it would be useful to frame it in this generality since lack of injectivity, not symmetry, is the main problem.\n\nIn the paper, they restrict to the special case that $f$ is a $G$-invariant function and the fibers $f^{-1}(y)$ are generically homogeneous $G$-spaces, that is a set of points $\\lbrace x \\rbrace$ related by the action of $G$.  In this case, finding $R$ amounts to finding a connected fundamental domain for the action of $G$.  One may also view this as a form of ```''canonicalization,’’ in which the goal is to define a canonical element of each fiber $f^{-1}(y)$ to use as a label.  \n\nIn Prop 2.1, Prop 2.2,  Prop 2.3, and Thm 2.4 the authors find connected fundamental domains for various $f$ which are all versions of taking the magnitude of the Fourier transform of a 1D or 2D signal.   The symmetries considered in the paper are translation, reflection and global phase shift (rotation of the signal at each point).\n\nMy opinion is that Prop 2.1, Prop 2.2,  Prop 2.3, and Thm 2.4 are all relatively straightforward exercises.  In no case is it very difficult to find a connected fundamental domain for these group actions.  The main contribution of the paper is not, then, in finding these domains but in recognizing that restriction to a fundamental domain for the symmetry group could be used to improve learning in the FPR problem.  This the authors demonstrate effectively in their experiments.  \n\nOne additional strength of the paper is in Section 2.4 in which the authors note that although it is very hard to find representatives for the translation symmetry analytically, they can still do fairly well using the heuristic canonicalization of centering the object in the frame.  In addition this can be done in combination with an analytic solution to the problem of finding representatives for the reflection and global phase shift symmetry.  \n\nIn fact, that only a result as simple as Thm 2.4 is needed is a consequence of the authors’ effective approach to the problem. A fundamental domain for reflection and global phase shift symmetries is hard to identify in sample space but easy to define in angle space.  Thus the authors create canonical representatives by first fixing the translation in sample space and then the reflection and global phase shift in angle space.  I agree with the suggestion that considering a mixture of transformed spaces may be a helpful approach for related problems.     \n\nMy borderline rating is due in part to the fact that the significance of the contribution may not warrant publication here.  The hybrid heuristic-analytic and angle space-sample space of Section 2.4 is a strength, but the problem formulation could be improved.  I am not familiar enough with FPR to know about the importance of method to this domain.\n\nSpecific Additional Points\n- Page 1, Sec 1.2: Why are intrinsic symmetries limited to non-linear functions?\n- Page 2, “Blind deconvolution:” This is less clearly defined than the other example, $y$,$a$,$x$ and circular convolution are not defined.\n- Page 1-2, Sec 1: As noted above this problem is introduced in terms of symmetries causing a problem, when in fact, it would be more natural to phrase it in terms of non-invertible functions of which quotient maps under groups actions are one kind.   \n- Page 2, Sec 1.3: Why do you call finding a connected set of representatives of equivalence classes, “symmetry breaking?”\n- Firstly, I am not sure that a connected representative set is really the property which is needed to prevent oscillations shown in Fig.1.  A more natural property might be that the section  $g = f|_R^{-1}$ is continuous.  For example, consider $f(x_1,x_2) = |x_1|$ where $ -1 \\leq x_1 \\leq 1$ and $x_2 \\in \\{ -1, 1 \\}$.  No representative set is connected due to the domain.  However, $R = [0,1] \\times \\lbrace -1, 1 \\rbrace$ has the desired property.  Practically many input distributions may be disconnected in this way.   For a different example consider $f \\colon [-1,1] \\to \\mathbb{S}$ where $f(x) = e^{2 \\pi i x}$.  Then $R = [-1/2,1/2 ]$ is connected, but there is an (unavoidable) discontinuity at $-1$.  Hence, for some $f$ it is not possible to choose $R$ such that $f|_R^{-1}$ is continuous. \n-Page 3, Section 2.2.  “For the sake of simplicity…”  I am not sure I agree it is simpler to omit the set of measure 0. The set\n $R=$ $\\brace x \\in \\mathbb{R}^n :\\text{ if } x \\not = 0, \\ \\exists k \\text{ s.t. } x_k > 0, x_j =0 \\text{ for } j > k \\rbrace$ is not that much more unwieldy, especially in the proof.\n-Page 6, Table 1.  It would be preferable to give a similar number of significant digits for each measurement and ideally std.dev over multiple trials.   \n-Page 6, Sec 3.2: The addition of zero padding to demonstrate the power of the current method for translations relative to other PR methods is a strength of the paper.  However, it would be good to see comparisons to these methods in the experiments.  Maybe this is what Table 3 is showing?  \n-Page 8.  In addition to some formatting issues, I can’t find where Fig. 5 and Table 3 are referenced in the text.  I’m not sure what ALM is.                  \t\n-Several points in the paper should use $\\subset$ not $\\in$, for example, Sec 2.3, $T \\in \\mathbb{C}$.  Also $\\mathcal{R} \\in $ after equation (2.4)\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A simple observation.",
            "review": "This paper makes the simple observation that if one is inverting a many-to-one function defined by samples (x,f(x)),\nit is better to canonicalize the inputs and invert a one-to-one function.  This is a trivial part of the analysis of phase retrieval\n(e.g. see Hayes 1982) and has to be discussed in any analysis of an inverse problem.  However if one is using a general\nmodel such as feed forward networks one might neglect this step.  \n\nThe paper discusses two examples with such an ambiguity due to a symmetry and thus not hard to remove, and shows that removing it is worth doing.  Both examples are phase retrieval tasks, in which the observations are the magnitudes but not the phases of low frequency modes of an image, and the goal is to reconstruct the image.  The first example uses random (Gaussian modes) and uniform random synthetic data, and the second uses Fourier modes and image data (Fashion MNIST).  A minimal set of experiments to support the observation are presented.\n\nIn my opinion the value of the paper depends on whether the audience needs to be reminded of the simple observation.\nLooking through various prior works, for example Kappeler et al's 2017 \"Ptychnet\", while the point is not made explicitly,\nthey take the inputs x from datasets which do not have this problem.  So it's hard to say that this point was neglected.\nOverall I would say that this is not substantial enough to support acceptance by ICLR.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}