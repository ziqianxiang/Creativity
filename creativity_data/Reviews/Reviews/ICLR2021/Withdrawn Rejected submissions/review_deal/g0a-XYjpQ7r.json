{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper studies personalized federated learning, mixing a global model with locally trained models.  Reviewers agreed on the relevance of the problem and that the work contains valuable contributions, such as the generalization bounds.\nAfter discussion, unfortunately consensus remained that the paper remains narrowly below the bar in the current form. \nConcerns remained on novelty over the Mapper optimization algorithm which also has adaptivity to the local/global combination of models, the dependence of the generalization bound on the mixing parameter as it converges to the global model, \nas well as on the strength of the experimental findings compared to well-known FedAvg and related method in a realistic benchmark environment (such as e.g. Leaf), since the dataset choice (and even more its partition among clients) is a crucial aspect for measuring personalization in a fair way. We hope the feedback helps to strengthen the paper for a future occasion."
    },
    "Reviews": [
        {
            "title": "Significant overlap with prior work",
            "review": "==================== Post rebuttal ====================\n\nI thank the authors for their response and additional experiments. Please see my comments below.\n\n**Relation to [1]** The first version of [1] appeared on arxiv in February. I am not sure if it has been published since then or not, but regardless it is sufficiently ahead of the ICLR submission deadline to consider it a prior work. [1] provides a Mapper optimization algorithm in Figure 4. There are some minor differences with your algorithm, but I don't see how they make your algorithm more communication efficient. Generalization analysis in [1] is for the mixing parameter learned from data (i.e. adaptive), that is why there is no dependency on it. Your analysis is for a fixed mixing parameter, but since it is not possible to know it in advance, learning it from data seems to be more reasonable. So I am not sure what is the advantage of a theorem with explicit dependence on it. I agree that the convergence analysis is new, but [1] also has two more algorithms.\n\n**Experiments** Despite that your paper has more experiments, EMNIST experiment in [1] is better suited for studying personalization in my opinion. EMNIST results in Appendix B in the submission are for **digits only** (and also use fewer clients, but that is less important). One of the reasons that a centrally trained model on EMNIST performs worse than personalized models is the shift in the distribution of characters and digits across clients. This is not the case for MNIST/CIFAR10: if I train a neural net using all of MNIST train data it will easily achieve 99+ average test accuracy (without any personalization). How the test data is split across clients does not matter because accuracy on each digit is roughly the same. That is what I meant by a \"single global model with good performance (i.e. trained on the full dataset)\".\n\nHaving worked on FL with personalization myself, I've noticed that it is quite hard to achieve a meaningful improvement over the vanilla FedAvg + fine-tuning. This is also evident from Table 2 of [1], where none of their algorithms offer a convincing improvement. This paper claims that an algorithm very similar to Mapper [1] indeed outperforms FedAvg + fine-tuning. I'd be happy if it is so, but I do not find the provided experimental evidence sufficient. I recommend reproducing the EMNIST experiment of [1] (please don't discard characters, use the same number of clients per communication, etc.). If your algorithm can achieve 91+ accuracy, I'd consider it an improvement. In that case, a more detailed discussion of the differences with Mapper [1] that enabled the improvement would also be great.\n\nRegarding the number of parameters, based on eq. (1), personalized model is a convex combination of **two** models. So if I understood correctly, the number of parameters is increased both during training and testing.\n\n====================================================\n\n\nThis paper considers the problem of personalization in federated learning. The proposed approach consists of allowing each client to have a local model for personalization and taking a convex combination of global and local models as personalized preditors. Authors also provide a theoretical analysis of the generalization and convergence guarantees and empirical evaluation.\n\nThe proposed method is equivalent to the Mapper algorithm from [1]. Generalization analysis is also very similar.\n\nThe empirical study is not conducted carefully:\n- Allowing for a separate local model for personalization increases the number of parameters which is not accounted for\n- Reported performance of the global model trained with FedAvg on MNIST and CIFAR10 is overly pessimistic. Prior works (e.g. [2]) report much better performance for the non-personalized model in similar heterogeneous data splitting scenarios.\n- Splitting MNIST and CIFAR10 datasets by classes is not a realistic way of simulating heterogeneous distributions in my opinion (see [3,4] for more recent strategies). It also does not seem appropriate for studying personalization as we know that there is a single global model with good performance (i.e. trained on the full dataset) and the key challenge is the optimization over heterogeneous datasets rather than the need for personalization. I recommend datasets such as FEMNIST [5] for studying personalization.\n\n[1] Three Approaches for Personalization with Applications to Federated Learning\n[2] Communication-Efficient Learning of Deep Networks from Decentralized Data\n[3] Bayesian Nonparametric Federated Learning of Neural Networks\n[4] Measuring the Effects of Non-Identical Data Distribution for Federated Visual Classification\n[5] https://leaf.cmu.edu/",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good story about federated learning.",
            "review": "## 1. Summary\n\nI do apologize for delaying the review process. I do spend lots of time and carefully read the paper. All comments listed below intend to help authors improve the quality of the manuscript. They are based on my understanding which might contain misunderstanding points if any. I hope comments are helpful and even the critiques are not discouraging your endeavor in the following.\n\nFirst of all, the manuscript proposed an adaptive personalized federated learning algorithm, where each client will train their local models while contributing to the global model. The convergence analysis and generalization bound for the algorithm are conducted.\n\n## 2. Major Comments:\n\n- Could please emphasize the motivation in figure 1, I cannot follow your statement.\n\n- The authors defined the average distribution $\\bar{\\mathcal{D}}=1/n\\sum_{i=1}^n\\mathcal{D}_i$. Why the global model can be obtained by minimizing the joint empirical distribution $\\bar{\\mathcal{D}}$ in the federated learning?\n\n- Why you only consider the smooth loss? \n\n- The optimal mixing parameter is the theoretical one. It seems cannot be used in practices. How do you think?\n\n## 3. Minor Comments:\n\n- Page 5, the first line, it should be ``model $v_i^{(t)}$''.\n\n- Definition 2 you should cite ``Li, Xiang, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. \"On the convergence of fedavg on non-iid data.\" arXiv preprint arXiv:1907.02189 (2019).''\n\n\t",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Complete story on optimization and generalization; Questions regarding the formulation and the adaptive case",
            "review": "This paper studies the personalization aspect of the federated learning problem. The authors propose a new framework in which they replace the common global model in the original federated learning formulation with a convex combination of the global model and a local model. They later introduce an adaptive optimization algorithm for their formulation and provide generalization bounds as well as convergence guarantees for both strongly-convex and nonconvex settings.  Finally, numerical experiments and comparison with other methods in the literature are provided to support the theoretical results.\n\nThe paper has a complete story. It provides generalization bounds, optimization results for both strongly convex and nonconvex functions, as well as experiments and comparison with other works.  \n\nHowever, I am slightly confused regarding the proposed formulation. In Section 2.1, for any agent $i$, and for a mixing weight $\\alpha_i$, $h_{loc,i}^*$ is defined as (I suppressed the hat notation over $h_{loc,i}^*$ and calligraphic font due to some compilation error here).\n\n$h_{loc,i}^* = argmin_{h \\in H} \\hat{L}_{D_i}(\\alpha_i h + (1-\\alpha_i) \\bar{h}^*).$\n\nThe authors then take $h_{\\alpha_i} := \\alpha_i h_{loc,i}^* + (1-\\alpha_i) \\bar{h}^*$ as the output, and claim that this is not the minimizer of $\\hat{L}_{D_i}$, since \"we optimize $h_{loc,i}^*$ with partially incorporating $\\bar{h}^*$.\" \n\nHowever, I am not sure if I follow the argument here, and it is not clear to me why $h_{\\alpha_i}$ is not the minimizer of $\\hat{L}_{D_i}$. Let's take $H = \\mathbb{R}^d$, as stated in Section 4. Also, let's denote the minimizer of $\\hat{L}_{D_i}$ as $h_{opt,i}$. Then, the solution to the minimization problem above would be\n\n$h_{loc,i}^* = (h_{opt,i} - (1-\\alpha_i) \\bar{h}^*) / \\alpha_i$\n\nwhich leads to having $h_{\\alpha_i} = h_{opt,i}$, the minimizer of $\\hat{L}_{D_i}$. \n\nI have the same confusion regarding Section 3 as well. There, the goal is to solve two minimization problems \n\n$ w^* = argmin_{w \\in \\mathbb{R}^d} \\frac{1}{n} \\sum_{i=1}^n f_i(w), \\quad v_i^* =  argmin_{v \\in \\mathbb{R}^d} f_i(\\alpha_i v+ (1-\\alpha_i)w^*),$\n\nand the output of the algorithm, for instance in Theorem 2, is $\\alpha_i v_i+ (1-\\alpha_i)w^*$ which is the minimizer of $f_i$. If this is the case, why we need to find $w^*$, and why not solving $argmin_{v \\in \\mathbb{R}^d} f_i(v)$ directly? \n\nIt is completely possible that I am missing something here. But I would appreciate it if authors provide a clarification on this.\n\nAs a second question, I am wondering if there is any connection between the sequence $\\alpha_i^{(t)}$ and the optimal $\\alpha_i^*$ derived in Section 2. In other words, for instance for the strongly convex case, does the sequence $\\alpha_i^{(t)}$ converge to any particular value close to $\\alpha_i^*$?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": " when $\\alpha$ gets smaller, the personalized models do not perform closer to the global model on validation data",
            "review": "In this paper, the authors propose a variant of FedAvg that not only produce the global training, but also a mixture of the local model and the global model, which is called personalized model. As a result, the personalized models show better validation accuracy. The theoretical and empirical analysis are provided.\nIn overall, I think the paper is technically sound, making reasonable contributions.\n\nHowever, some parts of the paper is unclear to me, which may affect the final score:\n\n1. In the exerpiments in Figure 2, it is still unclear to me how the \"local validation\" dataset is sampled, even after I read the appendix. The most important thing is, on each worker, does the validation dataset shares the same subsets of labels as the local training data? If not, then why call it \"local\"? Also, for the results in Table 1 and 2, are the validation dataset also \"local\"? My concern is that, if the local validation data is close to the local training data, and is not sampling from the global distribution, then this criterion is too beneficial to APFL, and not fair for the global models.\n\n2. Theoretically, when $\\alpha$ gets smaller, the personalized models also gets closer to the global model. Especially, when $\\alpha=0$, the presonalized model is equivalent to the global model, which is equivalent to the result of FedAvg. However, the empirical results indicate the opposite. In all the experiments (Figure 2, Table 1 and 2), when $\\alpha$ gets smaller, the validation accuracy gets farther away from FedAvg. Even with a pretty small $\\alpha$ (=0.25), the gap between APFL and FedAvg is still huge. However, the $\\alpha=0$ case seems not discussed in the theoretical analysis. Furthermore, the mismatch between the theoretical and empirical results when $\\alpha$ gets smaller is not explained.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}