{
    "Decision": "",
    "Reviews": [
        {
            "title": "Theory and experiments need improvement.",
            "review": "\n# Contributions\n\n1. This paper proposes a practical and effective way to reduce computations and accelerate FedSGD.\n\n2. This paper provides theoretical analysis of the convergence of the proposed algorithm.\n\n3. This paper provides numerical experiments to prove the performance in practice.\n\n# Strong points\n\n1. Decaying number of local SGD steps is a smart idea. In this way, FedSGD can both enjoy the fast initial phase and converge to a more stable point.\n\n2. The analysis brings some insights of the trade-off between the number of local SGD steps and speed of convergence.\n\n# Weak points\n\n1. The convergence  rate is not convincing enough. \nFrom Eq (12), $K_0$ needs to be smaller to make $\\sigma_c^2 \\kappa^2 K_0^2$ small. But $\\nu$ is lower bounded by $(b+1) \\| x_1 - x_1^* \\|^2$. Then the best $K_0$ would be the $K_0$ such that the two terms of $\\nu$ are balanced, $K_0 \\sim \\frac{G^2}{(b+1)\\mu^2 MB \\| x_1 - x^* \\|^2}$\n\n2. The local steps schedule.\n\t- The analysis uses $K_t =\\frac {K_0}{b + t}$. When $t \\geq K_0$, the actual number of updates will always be $1$. Then FedSGD reduces to batch SGD with diminishing step size.\n\t- The experiments uses $K_t = K_0 d^t$. Which will result in the same issue.\n\n3. From the experiments, it seems that decaying $\\gamma$ is necessary for FedSGD. But Fig 1 (a) has  no further comparison, e.g. $d_\\gamma = 0.995$ and $K = 1$.\n\n4. After ~200 steps the red line in Fig 1 (b), which is $d_K = 0.99$, should be close to the last part of the red line in Fig 1 (a). This can be confirmed by comparing the redlines above model value 0.5. The question is, is the acceleration a result of decaying $K_t$ or a result of more than $1$ local SGD steps? Can we decay $\\gamma_t$ with $K_t$ at the same time?\n\n5. In Fig 2, 3, 4, there are no experiments for $K=1$ for the first two schemes. But after some iterations, the proposed algorithm will reduce to this case. It is necessary to add this experiment.\n\n# Recommendation\nWeak reject. The authors propose a new way to accelerate FedSGD, which is novel and **very** practical. However, the analysis and experiments are a bit too simple. But I believe these can be improved in the next version.\n\n\n# Optional improvements\n\n1. The experiments can be strengthened. I suggest the authors run some large-scale experiments, and compare the results with Local SGD. From Fig 3, 4, it seems that the compared algorithms are kind of similar. But I suspect this is due to the small data set and simple model. It may be more convincing to show some more complicated models and larger datasets. E.g. ResNet50 on ImageNet.\n\n2. Add analysis for general (strongly) convex functions and non-convex function.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "initial review",
            "review": "The paper proposes to decay the number of local SGD steps in FL (under heterogeneous setting), so as to reduce the total number of computation.\n\n### pros\n* The paper extends the convergence analysis in Charles et al. and provides some theoretical justifications for their design choice.\n* A simple illustrative example, as well as large-scale realistic FL experiments (in terms of the total number of clients), are provided to justify the effectiveness of the proposed algorithm.\n\n### cons\n1. A list of related work for addressing the heterogeneity issue of the FL is missing, e.g. [1, 2, 3, 4]. Without comparing these algorithms, it is hard to identify the contribution of the proposed algorithm.\n2. The paper is motivated by the heterogeneous setting of the FL, however, the evaluations do not thoroughly examine this challenging scenario.\n3. It seems to me that a fixed (initial) learning rate has been used for different experiments, no matter the used number of local steps K, thus, it is hard to argue the fairness of the comparison in the experiment section. Besides, most of the results only visualize the training/test curves for a fixed method (but different K) and no cross-comparison can be found; it is hard to identify the performance difference of two different methods under the same x-axis (e.g. we cannot precisely compare the convergence speed of different methods w.r.t. the # of communication round).\n4. For FL, the number of communication rounds to the target performance is also an important metric; however, this metric has not been properly evaluated in the current manuscript.\n\n### reference\n1. SCAFFOLD: Stochastic Controlled Averaging for Federated Learning, ICML 2020.\n2. Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization, NeurIPS 2020.\n3. Federated Visual Classification with Real-World Data Distribution, ECCV 2020.\n4. Federated Optimization in Heterogeneous Networks, MLSys 2020.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review #3",
            "review": "Summary\n\nThis paper follows the theoretical framework of (Charles & Konecny, 2020) and shows that in order to let local-update SGD converge to the correct minimizer, one can choose to decay the number of local steps instead of decaying the learning rate. The authors conduct theoretical analysis in the quadratic case and their empirical results show that the proposed method can reduce the gradient computations at clients by up to 3.8x.\n\nPros\n1. **Good Clarity**: The paper is generally well-written and easy to follow.\n2. **Nice extension of (Charles & Konecny)**: This paper extends the theoretical analysis of [6] from fixing $K$ case to time-varying $K$ case.\n\nCons\n1. **Limited novelty and insufficient discussions with previous works**: The idea of decaying the number of local steps $K$ has the similar effects as decaying learning rate $\\gamma$ is not new. It was first identified and analyzed in [3]. The authors missed this important reference. Specifically, in [3], it has been shown that local-update SGD methods converge to a neighborhood of the stationary point and the size of the neighborhood is increasing with learning rate $\\gamma$ and local steps $K$. So in order to get closer to the stationary point at the end of training, one must either decay $\\gamma$ or $K$. Although the analysis of [3] is under IID setting, the conclusions can be easily extended to the non-IID case.  Also, there're a few literature on the topic of how to adaptively change $K$ to achieve the best convergence. The authors does not list any of them: [4, 5].\n2. **Weak theoretical analysis**: The analysis of this paper is only constrained to the quadratic case, which is quite limited, especially given the fact that non-convex analysis techniques are available and this quadratic analysis does not introduce significant novel insights. For example, in [3], the error under non-convex setting can be bounded as $1/(\\gamma K T) + O(\\gamma) + O(\\gamma^2 (K-1))$ (in the non-iid data case, the last term should be $\\gamma^2 K(K-1)$ as shown in [7]). From this bound, it is clear that when the communication rounds $T$ is sufficiently large, one should set either $\\gamma\\rightarrow 0$ or $K \\rightarrow 1$ to guarantee the convergence to the stationary point. Also, this bound suggest an interesting trade-off between the convergence speed and the final error. As we decrease the last term by decaying $\\gamma$ or $K$, the first term in the bound would increase. This trade-off is not discussed in the paper. If this trade-off does not exist, why not just use $K=1$ from the very beginning?\n3. **Weak empirical improvement over previous schemes**: From table 1, it seems that the decaying-$K$ schemes can only improve the accuracy with some specific $K$ values. Therefore, I feel the effectiveness of the proposed method is not validated. For a new dataset and a different starting value of $K$, running the proposed method has some chance to get even worse accuracy. The authors are supposed to discuss in which regime of $K$, their algorithm cannot work well.\n\nBesides, there're several misunderstandings of previous literature:\n1. The name FedSGD is not properly used. The authors claim that FedSGD is proposed in [1] as a generalized version of FedAvg. However, [1] does not use this name but uses FedOpt instead. FedSGD was actually first used in [2] and refers to the algorithm where each client performs local full-batch gradient descent.\n2. In the introduction, \"The authors provide convergence rates for FedAdam in the convex setting\" is not correct. [1] provides convergence analysis in the non-convex setting.\n\n\nRefs:\n\n[1] Reddi et al. Adaptive Federated Optimization. preprint 2020\n\n[2] McMahan et al. Communication-Efficient Learning of Deep Networks from Decentralized Data. AISTATS 2017\n\n[3] Wang and Joshi. Adaptive Communication Strategies to Achieve the Best Error-Runtime Trade-off in Local-Update SGD. MLSys 2019.\n\n[4] Haddadpour et al. Local SGD with Periodic Averaging: Tighter Analysis and Adaptive Synchronization. NeurIPS 2019.\n\n[5] STL-SGD: Speeding Up Local SGD with Stagewise Communication Period. Preprint June 2020.\n\n[6] Charles and Konecny. On the outsized importance of learning rates in local update methods. Preprint July 2020.\n\n[7] Yu et al. On the Linear Speedup Analysis of Communication Efficient Momentum SGD for Distributed Non-Convex Optimization. ICML 2019.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}