{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper addresses learning with noisy labels, by detecting and correcting samples with noisy labels. Reviewers had concerns about the empirical evaluations, specifically about comparing to additional methods, about hyperparameter tuning, and about the improvements being vey small. There was also a concern that the analysis of the objective does not take into account explicitly the L2 regularization induced by weight decay. Based on these concerns the paper is not ready yet for publication.\n\n\n"
    },
    "Reviews": [
        {
            "title": "The paper method can improve the performance to some extent, but the influence is not prominent.",
            "review": "This study introduces AutoCleansing to address the biased problem due to incorrect labels. This framework can automatically capture the effect of incorrect labels and mitigate it without removing mislabeled samples. There is some improvement in performance, but not much difference.\n\nWhere to improve:\n\nThe challenges of solving the problem of incorrect labels must be explained in-depth, but they are not introduced at all.\nSection 2 leaves me with an idea of incompleteness, and I would request the authors to make it a critical review and not just a list of methods.\nSection 3 for the proposed method AutoCleansing. The method is primarily described through equations. The authors may want to consider adding more descriptive text (and possibly figures) that would make the paper more accessible to readers without and extensive mathematics background.\nthe section Results should be substantially expanded. The authors should be explicit about the difference between the model proposed here and the models implemented by previous studies and how their model works compared to other methods.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This study provides a theoretical model to capture biased effect of incorrect labels automatically and address the prediction errors due to incorrect labels in training data.",
            "review": "This paper seems to be a useful contribution to the literature on deep learning with noisy datasets, showing a good improvement over the state of the art. \nThis work presents a theoretical model formulation to capture the biased effects of incorrect labels automatically \nThe paper is generally well-written and structured clearly. However, there are few small changes or suggestions to improve are as follows:\n•\tThe authors have not rationalized enough the performance of the AutoCleansing over the other methods and on the data sets in detail for better readability.\n•\tSummary of the data sets as a table provides better visibility and readability. \n•\tDetection of incorrect labels using the proposed method has been described in detail but why AutoCleansing does not require the threshold criteria of the drop rate needs further discussion. Please add additional details.\n•\tIn addition to the learning rate, weight decay, Epoch etc. the authors can add the time units for each of the datasets helps the future researchers. Please add.\n\nThe paper and the supplementary provided describes the theoretical formulation and other objective functions in full detail and provides enough information for an expert reader to understand and interpret the results.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting and simple idea but lacks comparison with any other methods for learning with noisy labels",
            "review": "The paper proposes an approach for handling noisy labels in predictive models without removing them. The approach is based on a base network and a category dependent constant. At test time the prediction is done using the base network. The paper is well-written and the ideas are explained clearly. I have the following comments and questions on the empirical and theoretical aspects of the work:\n\nAs far as I understand, theoretical analysis is only applicable to AC1 model but the more practical approach which is applicable to datasets such as imagenet is AC2. What portion of your results can be extended to AC2? \n\nThe experiments on CIFAR-10, CIFAR-100 and SVHN do not show a statistically significant improvement over the baselines; specifically after considering the confidence interval for the AA results (from table 2 of the AutoAugment paper). Adding experiments with synthetic datasets with different levels of noise can be helpful in understanding the advantages of AC1/AC2 over other methods for handling noisy labels. \n\nExperiments in Section 4.2 are only trimming the incorrect training labels; ideally, you also want to remove the noisy labels from the test set too. However, as far as I understand it’s not straightforward to apply AC1 to the test set and trim the noisy labels. Is this correct?\n\nOther methods for learning with noisy labels such as the ones that are mentioned in the Section 2: ‘Related Works’ should be added in order to provide a better picture of the pros and cons of the method. In the current version of the paper, the emphasis in the experiments is on augmentation methods which may not be the best choice.  For instance, “Unsupervised Label Noise Modeling and Loss Correction” by Arazo et al. has a similar approach to AC1 as it also models each sample and doesn’t require a matrix based noise model. This could be a good candidate baseline. \n\nOverall, I like the simplicity of the approach but I believe with the current state of the paper, it’s hard to judge the value of the approach over other methods for learning with noisy labels. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Serious Flaw in Problem Formulation and Subsequent Theorems",
            "review": "### Paper Summary\n\nIn this paper, the authors proposed to train high quality classifiers from datasets with some mislabels.\n\nFor this purpose, the authors considered adjusting the softmax prediction using an additional term $\\alpha$ as follows:\n$$\nP^C(i | x; \\theta) = \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))}\n$$\nwhere $m(\\cdot; \\theta)$ is a model and $\\theta$ is its parameter.\nThe authors claimed that, by adjusting $\\alpha$ through training, the trained model $m(\\cdot; \\hat{\\theta})$ with an optimal parameter $\\hat{\\theta}$ is asymptotically consistent with the model trained on a dataset with clean labels, i.e.,  the trained model without $\\alpha$ performs well on clean test data\n$$\nP(i | x; \\theta) =\\frac{\\exp(m_i(x; \\theta))}{\\sum_j \\exp(m_j(x; \\theta))}\n$$\nIn the proposed method, for the training set $D = \\\\{x_n, y_n \\\\}$, we first train the model by minimizing the following loss function:\n$$\n\\hat{\\theta}, \\hat{\\alpha} = \\arg\\min_{\\theta \\in \\Theta, \\alpha \\in \\mathbb{R}^{N \\times K}} -\\frac{1}{N} \\sum_{n=1}^N \\sum_{i=1}^K 1[y_n = i] \\log \\frac{\\exp(m_i(x_n; \\theta) + \\alpha_{ni})}{\\sum_j \\exp(m_j(x_n; \\theta) + \\alpha_{nj})}\n$$\nwhere $K$ is the number of classes. We then classify the new instance $x$ by $\\hat{y} =\\arg\\max_i m_i(x; \\hat{\\theta})$.\n\nIn Theorem 1, the authors claimed that the above estimator $\\hat{\\theta}$ converges to the *true* parameter $\\theta^*$.\n\n\n\n### Pros & Cons\n\n[Pros]\n\nThe experimental results indicate that the proposed method is effective on several datasets.\n\n[Cons]\n\nThe paper contains a serious flaw in its problem formulation and the subsequent theorems. The proposed problem formulation has a trivial solution which is completely useless. The effectiveness reported in the experiments seems to be just an artifact caused by the tunings of hyperparameters. See my comments in \"Quality\" below for the detail.\n\n\n\n### Quality\n\nThe paper contains a serious flaw in its problem formulation.\n\nRecall the training problem:\n$$\n\\hat{\\theta}, \\hat{\\alpha} = \\arg\\min_{\\theta \\in \\Theta, \\alpha \\in \\mathbb{R}^{N \\times K}} -\\frac{1}{N} \\sum_{n=1}^N \\sum_{i=1}^K 1[y_n = i] \\log \\frac{\\exp(m_i(x_n; \\theta) + \\alpha_{ni})}{\\sum_j \\exp(m_j(x_n; \\theta) + \\alpha_{nj})}\n$$\nThis problem has a trivial solution that $\\alpha_{n y_n} \\to +\\infty$ for $\\forall n$, which leads to\n$$\n\\frac{\\exp(m_i(x_n; \\theta) + \\alpha_{ni})}{\\sum_j \\exp(m_j(x_n; \\theta) + \\alpha_{nj})} \\to\n\\delta(y_n = i)\n$$\nwhere $\\delta(y_n = i) = 1$ if $y_n=i$ and 0 otherwise.\nNote that this trivial solution does not depend on the model $m(\\cdot; \\theta)$. Thus, any parameter $\\theta$ can be an optimal solution $\\hat{\\theta}$ as long as $m(\\cdot ;\\theta)$ is finite.\n\nThe above observation indicates that the proposed method do not work as expected if the training problem is solved appropriately. Thus, I conjecture that the good performances reported in the experiments are the artifact caused by the tuning of hyperparameters, e.g., the training converged to local optima that occasionally performed well.\n\nNote that the above observation on the training problem also suggests that the claim of Theorem 1 (the estimator $\\hat{\\theta}$ converges to the *true* parameter $\\theta^*$) is not correct.\n\nIn the proof, the authors considered the following objective function:\n$$\nL^C(\\theta, \\alpha) = - \\mathbb{E} \\sum_{i=1}^K \\left[ \\sum_{k=1}^K \\pi(i | k, x) P(k | x, \\theta^*) \\log P^C(i | x, \\theta) \\right]\n$$\nLet $U(i | x, \\theta^*) = \\sum_{k=1}^K \\pi(i | k, x) P(k | x, \\theta^*)$. We then have\n$$\nL^C(\\theta, \\alpha) = - \\mathbb{E} \\sum_{i=1}^K U(i | x, \\theta^*) \\log \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))}\n$$\nBy taking the derivative with respect to $\\omega \\in \\\\{\\theta, \\alpha\\\\}$, we have\n$$\n\\frac{\\partial L^C(\\theta, \\alpha)}{\\partial \\omega} = - \\mathbb{E} \\sum_{i=1}^K U(i | x, \\theta^*)\\left( \\frac{\\partial (m_i(x; \\theta) + \\alpha_i(x))}{\\partial \\omega} - \\sum_{k=1}^K \\frac{\\exp(m_k(x; \\theta) + \\alpha_k(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))} \\frac{\\partial (m_k(x; \\theta) + \\alpha_k(x))}{\\partial \\omega} \\right) \\\\\n= - \\mathbb{E} \\sum_{i=1}^K \\left( U(i | x, \\theta^*) - \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))} \\right) \\frac{\\partial (m_i(x; \\theta) + \\alpha_i(x))}{\\partial \\omega}\n$$\nThus, any $\\theta, \\alpha$ that satisfy $U(i | x, \\theta^*) = \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))}$ are optimal.\n\nIn the proof of Theorem 1, the authors only considered a specific $\\alpha$, and overlooked the existence of other $\\alpha$ that are equally optimal, which led to the wrong claim that $\\hat{\\theta}$ converges to $\\theta^*$.\n\n\n\n### Clarity\n\nApart from the serious flaw above, I think the paper is clearly written and the main claim of the paper is easy to follow.\n\n\n\n### Originality\n\nThe use of the adjustable parameters for fitting noisy data is studied in the literature of robust learning. I would like to suggest the authors to see [Ref1] and references therein. In [Ref1], an additional penalty is imposed on the adjustable parameter to avoid the trivial solution I raised above.\n\n[Ref1] Consistent Robust Regression, NeurIPS17.\n\n\n\n### Significance\n\nBecause of the flaw I raised above, I think the contribution of this paper is not significant.\n\n\n----------\n### Feedback after discussion\n\nI would like to clarify my thought here. Recall that using the weight decay is equivalent to adding the L2 regularization to the training objective. An important observation here is that the addition of the L2 regularization to the proposed objective will make the global optima non-trivial (apart from the trivial ones I raised), and there might be a hope that the new global optima has some useful properties. What this observation indicates is that the use of the L2 regularization (or weight decay) is an essential factor for the proposed method to output something meaningful. This fact also implies that the analysis of the objective function alone (without the regularization, in Section3) is no longer meaningful. Moreover, because the L2 regularization (or weight decay) is an essential factor, the tuning of its weight should have a major impact to the resulting model. I therefore think it will be important to investigate the effect of such a weight in the experiments, instead of just using a standard weight.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}