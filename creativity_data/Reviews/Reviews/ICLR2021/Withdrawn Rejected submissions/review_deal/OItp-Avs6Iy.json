{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes  to effectively learn representation of 3D data (point clouds/meshes) using a spherical GNN architecture over concentric spherical maps. A method for converting point clouds to concentric spherical images is also proposed. Evaluation is done via 3D classification tasks on rotated data.\n\nStrengths:\n- Interesting novel method for learning 3D representations\n- Technically sound\n- Performs similarly to spherical CNNs and other STOA on the Modelnet40 dataset\n\nWeaknesses:\n- Presentation of the work needs to be further improved such that it is easier for others to reproduce\n- More in-depth experiments are needed to justify how much Spherical GNN improves over other STOA, particular given how classification accuracy is very similar to STOA."
    },
    "Reviews": [
        {
            "title": "well presented and reasonable results; lack of sufficient details and not demo video for 3D visual results",
            "review": "This paper proposes a Spherical GNN approach for effective representation of 3D data (point clouds and surface meshes). \nThe main ideas are interesting and reasonably well presented. The results are convincing, being comparable to or better than SOTAs on benchmarks. \nHowever, I am not an expert in this area: It seems to be an interesting new idea proposed in this work; meanwhile, I feel a lack of sufficient technical details for reproduction.\nIt would be helpful if the authors could explain some of the key ingredients, such as the radial convolutions, inter/intro sphere convolutions in greater details. The proposed NN architecture, as illustrated in Fig. 3, still lacks in many details, and possibly is not sufficient for a faithful reimplementation/reproduction by other researchers.\nThe authors should make their code and processed data and results publicly available.\nThe empirical evaluation is also somewhat lacking in its breadth and depth. The shapenet, for example, also contains lots of 3D shapes of various types of objects, and could be a good dataset for evaluaiton. In terms of applications, it would be helpful to showcase a few application studies and to demonstrate the advantages of adopting the proposed scheme.\nThe authors should also present more visual results of their 3D shape representation in a supplementary video.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review of \"Concentric Spherical GNN for 3D Representation Learning\"",
            "review": "This paper addresses an important problem in 3D representation learning, which is how to design a robust convolution neural network for arbitrarily oriented inputs. They propose to use multi-sphere icosahedral discretization to representation 3D data at first. And then, several alternative convolution operations are used to further process features. The novel convolution operation is consisting of intra-sphere and inter-sphere convolution. They also design a mapping function to convert point cloud data to mesh data. The experimental results indicate the model can work well.\n\nStrengths:\n1.\tA novel method to discretize space, which can be used for represent 3D data.\n2.\tThe convolution combines intra-sphere information with inter-sphere information, it can keep rotation invariant.\n3.\tNew mapping is proposed to convert point cloud data to mesh data, it can make the model more general to deal with 3D data.\n4.\tResults show the model is effective and achieves SOTA.\n\nWeakness:\n1.\tMath symbols need to be unified.\n2.\tSome repeated words. E.g. “stacking” in “Radial Discretization”, Page 3, “point cloud” in “POINT CLOUD TO CONCENTRIC SPHERICAL SIGNAL”, Page 4.\n3.\tSome math symbols have no explanation, which may make readers cannot get your idea. E.g. d_u、d_v in Eq(1)。\n4.\tI don’t know what is Z_g in Eq(1), and the shape of this parameter. The oversimplified description of Z_g makes me can’t understand why Eq(1) can keep rotation invariant.\n5.\tWhat is the shape of W_{k+K/2} in Eq(2), is it a matrix ? Please add more description of your math symbels.\n6.\tHow to determine the neighbor range of point x in Eq(3) ? Are you use KNN or ball query methods ? Do you have some contrast experiments?\n7.\tOnly use the norm-2 to calculate Eq(3) may loss some direction information, how do you think of this question?\n\nAlthough the paper seems to propose an effective convolutional operation for point cloud representation, it is unclear how to maintain its rotation invariance. Possibly this is because of inconsisent and unclear symbols. Therefore, if the authors could show this factor satisfactory in the rebuttal and address the above concerns, I would like to move to a positive rating. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "In this paper, a multi-resolution convolutional architecture is proposed to learn from concentric feature maps. Different from single sphere representation, both graph convolutions and radial convolutions are employed to extract the intra-sphere and inter-sphere information. ",
            "review": "In this paper, a multi-resolution convolutional architecture is proposed to learn from concentric feature maps. Different from single sphere representation, both graph convolutions and radial convolutions are employed to extract the intra-sphere and inter-sphere information. Benefit form the radial discretization, the proposed CSGNN achieves state-of-the-art results in testing on arbitrarily rotated data under ModelNet40 dataset. However, there are several drawbacks in the  draft, such as ambiguous figure and  insufficient ablation study.\n\n## Summary\n\nIn CSGNN,  a  two-phase convolutional scheme for learning over a concentric spheres representation, by alternating between inter-sphere and intra-sphere convolutional blocks. Specifically, the graph convolutional network is applied to incorporate intra-sphere information, and 1D convolution to incorporate radial information. Different from previous works,  a multiple sphere representations are integrated in CSGNN, which is robust to rotation operations. In general, the proposed method is innovative on the basis of spherical discretization, but still has some limitations.\n\n## Strengths\n\n#### 1. A multi-sphere icosahedral discretization for representation of 3D data is proposed, which can enhance  representation ability and keep more details over single-sphere representations.\n\n#### 2. Both graph convolutional networks and 1D radial convolutions are employed to capture the intra-sphere and inter-sphere information of 3D objects.\n\n#### 3. The proposed CSGNN achieves state-of-the-art results in testing on arbitrarily rotated data.\n\n## Weaknesses\n\n#### 1. The complexity analysis is insufficient. In the draft, the author only provide the rough overall complexity. A better way is to show the comparison between the proposed method and some other methods, including the number of model parameter and network forwarding time.\n\n#### 2. In the converting of point cloud to concentric spherical signal,  the Gaussian radial basis function is adopted to   summarize the contribution of points. Is there any other function that can accomplish this job? The reviewer would like to the discussion about this.\n\n#### 3. The Figure 2 is a little ambiguous, where some symbols are not explained clearly. And the reviewer is curious about that  whether there is information redundancy and interference in the multi-sphere icosahedral discretization process.\n\n#### 4. There are some typos in the draft. The first is the wrong use of \"intra-sphere\" and \"inter-sphere\". The second is the use of two consecutive \"stacking\" in the Spherical Discretization subsection. Please check the full text carefully.\n\n#### 5. The center choice of the concentric spheres should be discussed both theoretically and experimentally. In the opinion, the center of spheres play a important role in the representation capturing of 3D point clouds in a sphere convolution manner.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "Summary:\nThis paper presents a novel multi-sphere icosahedral discretization for representation of 3D data. Given meshes or point cloud, the authors map them to multiple layers spheres and apply graph conv on the spheres to learn rotation-invariant features. In the final stage, all the layers are merged via a radial pool operator. The authors claim that such a structure could better preserve information of 3D objects and showcase on mesh and point cloud classification tasks.\n\nComments:\nThe authors extend the spherical CNN from a single layer to multiple layers and propose corresponding graph conv and pool operations for it. However, I have several concerns, as seen below:\n\nHierarchy v.s. partition: In my understanding, the authors use RBF to map each point to its nearest sphere vertex, as shown in Fig.1. Does it indicate the multilayer spherical CNN is not hierarchical but more about partition?  Also, RBF needs some explanation. I only see the abbreviation.\n\nMore explanation should be added in Sec.5.2, especially the way to do ray marching in multi-layer spherical CNN. It is a valid concern that the regular ray marching in Esteves 2018 would lose information for non-convex objects. But after reading the section, I am not exactly clear about how you preserve information for the multiple surfaces. Also, such new ray marching is more about hierarchy or partition?\n\nIn the experiments, I find the authors directly use the numbers in others' papers. This is not super fair since the experiments may be done in different settings. Why the number in Table 1(16 layers, SO3/SO3 is 0.884) and Table 3(16 layers, SO3/SO3 is 0.879?) are different?  Also, some time analysis is worth adding.\n\nConclusion: Overall, I think extending the spherical CNN from 1 layer to multiple layers is an interesting idea and one can foresee that such an extension would bring better performance, as shown in the paper. I think validating such an idea is a solid contribution and would bring insights to others. Thus I would like to accept this paper.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}