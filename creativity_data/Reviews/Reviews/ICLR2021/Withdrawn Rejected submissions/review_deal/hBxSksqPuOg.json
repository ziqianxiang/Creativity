{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes the generalization performance of distillation from random networks as a metric of diversity, named RND. Intuitively, the more diverse the generated datasets, the more difficult it should be for a model to learn a random computation. The reviewers agree that the metric has a novel perspective. Unfortunately, the paper is not sufficiently developed to be accepted at this point. It is currently missing a number of experiments that would demonstrate that this metric is indeed a measure of diversity:\n\n1.) RND shows sensitivity to the truncation trick in GANs (for images), and limiting the size of vocabulary in text, but does not show sensitivity to any other changes in diversity (such as human judgment of diversity)\n2.) It does not compare to previous metrics of diversity, of which there are many\n3.) How sensitive is RND to architecture choice.\n4.) It is non-obvious to what extent the metric is sensitive to image/text quality\n\nStrong metrics should demonstrate lack of \"failure modes\", as the utility of a metric is its inability to be gamed. Currently, the paper does not demonstrate this property, though I imagine that more work will help clear up the strengths and weaknesses of the metric.  As a result, I can only recommend rejection."
    },
    "Reviews": [
        {
            "title": "Interesting diversity measure idea, insufficient comparisons to other approaches",
            "review": "This paper proposes that generalization performance of distillations of random networks can be used as a good metric for the diversity of a data set: as a data set gets more diverse, it should be harder to learn to mimic a random computation on that data set.  After defining the metric, the paper compares it to FID in its ability to distinguish truncated GAN output, and applies it to compare different generative architectures and training settings, to compare different data sets such as imagenet classes, and to measure diversity of natural language model outputs.\n\nThe strength of the paper in its interesting viewpoint, that diversity can be viewed as the difficulty of a random learning task.  The framework and concept is promising.  It is good to see that, unlike FID, it detects the loss of diversity as a generator is truncated, without mixing the measurement with precision. And the comparisons of different models and data sets is interesting.\n\nHowever, in proposing that RND should be used as a diversity metric, the paper does not sufficiently compare the proposed method to previously proposed alternatives.  The paper should establish that the metric is meaningful and useful.  Three are three main issues.\n\n1. What is being measured by RND?  Beyond just the operational definition of how the metric is collected?  In what situations would measuring this quantity be expected to differ from other metrics, and what strength weaknesses do the proposed metric have compared to other methods?  It seems possible that the idea of diversity-through-learning complexity could have an interesting theoretical definition, but the paper does not attempt a theoretical characterization of exactly what quantity would ideally be estimated by the RND procedure.\n\n2. How does it compare to previously proposed metrics? A comparison to FID is done, but there are many other approaches for measuring diversity.  E.g., see [Borji 2018] for a survey of a large number of alternative metrics for diversity, many of which are designed to measure recall of a generative model compared to a known diverse ground truth.  Or see [Sajjadi 2018] or even the Parzen windows of [Goodfellow 2014].  Since RND measures diversity without need for a ground truth, it could be argued that RND allows new measurements.  But to establish the metric is sound, it should first be compared to a variety of recall metrics where a ground truth is known.  Comparisons should be done with different types of recall measures, and also different types of data distributions including toy examples where differences in diversity are easy to understand.\n\n3. It is a goal for RND to match human assessments of diversity?  It is argued that some complexity (such as noise) is uninteresting and should not be included in a diversity metric - but this seems to imply that the goal is to measure just the diversity that would be interesting or informative to a human.  If this is the goal, then the performance of RND should be compared to human assessments of diversity.\n\nThe idea and the topic of the paper is interesting and strong, but needs further development to argue that the proposed measure is meaningful and useful, especially compared to other approaches.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review and Questions",
            "review": "RND as a Diversity Metric\nThis paper proposes a new modality-independent diversity measure for generative models and examines this across image and natural language generation.  The idea repurposes an exploration technique from reinforcement learning:  random network distillation. The method produces a diversity score of data by splitting it into train and validation partitions. Then, a predictor network is trained via a mean-square error (MSE) to predict the resulting features of passing the train data through a fixed, randomly initialized target network. The diversity measure is then computed as the normalized MSE difference between the train and validation partitions. The intuition of the method is that if the train partition is diverse, then we would expect the predictor network to generalize well in predicting validation target features. If it’s not diverse, we would expect a large gap.\n\nI recommend acceptance. This appears to be a useful advance as a diversity measure that works across different modalities. I’m not aware of prior work doing this. The largest weakness, IMO, is that the work doesn’t do enough study into the importance and nature of the random target network. I imagine this is a critical decision (e.g. don’t use a MLP for a vision target network) and, if the authors want this to be widely adopted by different communities, should provide further guidance on this.\n\nNotes:\n* This has obvious failure modes. For instance, if the target network was a 0-network (all inputs mapped uniformly to a 0-vector), this trivially fails as a diversity measure. This paper should address more details about the requisite nature of the target network. This is the biggest weakness of this paper and I would upgrade my score with a more thorough scientific investigation here.  “The exact architecture and training procedure depends on the setting. For example, we use a transformer architecture to evaluate text, and we use a ResNet architecture to evaluate images (Vaswani et al., 2017; He et al., 2016).”\n* I enjoyed Section 2.1 “What do we want from a diversity metric?”. Capturing the notion of diversity, distinct from information-theoretic measures, is an important property.\n\nQuestions to authors:\n* What is the importance of the random network architecture? How does the “architectural prior” impact the efficacy of your approach as a data diversity measure?\n* Could you improve the clarity of Section 3.1? It reads as, “The bonus is tied to how “novel” an agent’s environment is - as measured by the distillation loss between a fixed, random target network, and a predictor network trained to mimic the features of the target network.”  I found myself re-consulting the original paper to make sure I knew what was going on. I found Section 3.2 to be much clearer.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Not confident on if this paper proposes a good definition on diversity.",
            "review": "I understand the authors goal on developing a diversity metric and evaluate models diversity. However, the concept of diversity is related to multiple factors and I don't agree to define diversity independent of memorization: a good memorization of diverse data also contributes to the diversity of models and sometimes good memorization suggests high capacity of model thus may lead to high diversity.\nIn the approach proposed, the memorization concept is implicitly wrapped into the size of the predictor model.  But there is no analysis on the effect of the predictor model sizes on the diversity scores.\nFor the experiment section, the evaluations are rather non-systematic, only a few categories' RND scores are shown. A table of overall performance will be good.\nMeasuring diversity of models is an important task, while this paper provides some interesting discussion on defining the diversity and proposed method to measure it. but the definition needs a bit refinement and the the author failed to prove that the propose method is a systematic metric on the diversity of models (only showed specific categories is not enough).",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An intuitive method for quantifying diversity, but the paper is missing baselines.",
            "review": "This paper applies random network distillation (RND) as a method for quantifying how diverse samples from a generative model are. Samples from the generative model (or any dataset) are used to train a neural network to mimic a randomly initialized network. Intuitively, this is a more difficult task on a more diverse dataset, and so the distillation loss can be interpreted as a measure of diversity. The authors argue that this approach has advantages over other diversity metrics because it can capture semantic diversity and does not require a second reference dataset.\n\nStrengths of paper:\n+ This article is well-written. The motivation and approach are very clear. \n+ The technique is demonstrated in several different domains, including image generation, text generation, and one-shot GANs.\n+ The approach is intuitive and agrees with qualitative notions of diversity across each domain it was tested in.\n\nWeaknesses of paper:\n- The original contribution is minimal as RND distillations loss is a known technique for quantifying exploration. The main originality comes from identifying it as a way to also quantify diversity in generative dataset.\n- The distillation loss metric is not compared to other diversity metrics. This would help demonstrate that the RND score is better aligned with diversity than other standard metrics.\n-  The claim that the RND score captures semantic diversity is not well supported. This deserves some scrutiny as the RND is a random feature detector, so it is not clear why it will generally favor semantic diversity. There is an experiment in the appendix to show that the RND score was greater for natural images than random ones,  but it is unclear whether other statistics of the random noise were controlled to make this a fair comparison. This should be expanded to determine that it generalizes. \n\nOverall, while the paper has some merits, it needs to compare its metrics to other available ones to better make its argument.\n\nComment:\nThe NLP model needs to be initialized with real text. It would be interesting to dive deeper into how context affects the diversity of the generated text.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting read, but not ready for publication",
            "review": "In this paper, the authors introduce a new quantitative diversity measure advocating its usage for generative models evaluation. In a nutshell, to measure the diversity of a particular set, the authors split it into disjoint train/val subsets and learn a DNN to predict the outputs of another randomly initialized DNN on the train set. Then the generalization gap of the trained DNN is computed on the unseen val subset, and the normalized value of this gap (averaged over several splits/initializations) is considered as a diversity measure.\n\nPros:\n\n(1) The authors tackle an important problem since the established measures like FID are known to sacrifice diversity in favor of perceptual quality.\n\n(2) The proposed measure is novel, the usage of random networks in a new context sounds interesting.\n\nCons:\n\n(1) The authors do not relate their measure to the very relevant line of existing works on measuring diversity via Precision/Recall:\n\nAssessing Generative Models via Precision and Recall. NeurIPS 2018\n\nImproved Precision and Recall Metric for Assessing Generative Models. NeurIPS 2019\n\nReliable Fidelity and Diversity Metrics for Generative Models, ICML 2020\n\nWithout explicit highlighting of RND's advantages over the Recall/Coverage measures, I cannot recommend to accept the paper.\n\n(2) The computation of RND requires several DNN trainings, which is time-consuming. This makes RND inconvenient for broad usage, and almost impossible to use in day-to-day research, e.g., for monitoring the training progress.\n\n(3) I am not quite convinced by the experiments, which support the RND applicability. For me, the most sensible experiment is in section 4.1, which shows that aggressive truncations decrease RND. Sections 4.2/4.5 show that newer GAN models typically achieve higher RND compared to older ones, but I cannot consider this as strong evidence, since we do not know if the advantage of newer models comes from diversity rather than perceptual quality.\n\nOverall, my current recommendation is (4), mostly because of missing a crucial part of related work and unconvincing experiments.\n\n::::::Post-Rebuttal update::::::\n\nAfter reading the new revision, I decided to keep my initial score. I do not consider the need of groundtruth real data for metric computation as a strong disadvantage. The authors report some numbers on Recall in Table 1 but it only shows that Recall is consistent with RND, being much cheaper to compute. Therefore, I do not see any reason to prefer RND over established diversity metrics.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}