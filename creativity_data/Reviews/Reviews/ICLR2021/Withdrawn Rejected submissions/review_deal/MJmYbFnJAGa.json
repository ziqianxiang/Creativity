{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The submission introduces a theoretically-justified solution to 'client-drift' in federated learning.  Generally, the reviewers agreed that this could be a strong paper, and several of their minor concerns have been addressed in the rebuttal. Unfortunately, a major issue raised during the discussion was the correctness of Lemma 7. Despite the extra clarifications provided by the authors, Reviewer2 still believes it is incorrect and R4 also sided with them.  As theoretical analysis is the major contribution of this work, we have to reject the submission. I would strongly encourage the authors to fix the issue (or clarify the proof), and resubmit it to one of the upcoming top ML conferences. "
    },
    "Reviews": [
        {
            "title": "Very interesting algorithm utilizing global statistics.",
            "review": "In the paper, authors proposed to utilize the global statistics in local client updates to mitigate the client drift problem. The algorithm mine and minelite are very interesting and look reasonable to me. They also prove the convergence rate of the proposed algorithm and evaluate its empirical performances on synthetic and real federated learning simulations.\n\nThe following are my concerns:\n1) At page 2, analysis of fedavg, the last sentence \"technically, it was a slightly modified FEDAVG version? P: FEDAVG as it is understood encompasses methods with server lr.\" looks very strange to me.\n2) typo in the sentence of eq (1) \"vour\".\n3) A more straightforward compared algorithm is fedavg using sgdm on clients. \n4) I am confused about the performance of fedsgdm and fedadam in the paper. According to \"Adaptive federated optimization\" paper, the accuracy of fedsgdm and fedadam achieve about 85%. However, in the paper, the results are far from that. \n5) The same question also applies to cifar100 experiments. Besides, it looks like that mimeadam stops converging after 600 rounds, however, fedadam will continue converging to about 50% according to the  \"Adaptive federated optimization\" paper.\n\n====\nAfter rebuttal:\n\nI read all reviews and rebuttals, especially the argument about Lemma 7. I agree with reviewer 2 that the Lemma 7 is not correct. The assumption of $\\mu\\eta < \\frac{1}{42k}$ contradicts with the requirement $\\mu\\eta > \\frac{1}{k}$ of term 4.  This error needs to be resolved before acceptance. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "I believe this paper adds decent contributions to the ICLR community. The presentation and the structure of the paper can be improved. ",
            "review": "Summary of the paper:\nThis paper introduces the MIME framework which can adopt standard centralized SGD methods in federated learning environments and this framework handles the well known \"client drift\" problem. It is done by cleverly using server statistics such as momentum in local devices. Ample empirical evaluations are provided in order to validate the theoretical claims.\n\nQuality:\nAlthough I did not check the proofs thoroughly, the presented theoretical results looks natural and believable.  Ample experiments are provided to validate the claims. Clarity of the paper is good in general but there are places that can be improved. The quality and the presentation of the paper can be improved significantly. \n- Most of the remarks under theorem 1 about the table 1 are redundant. The same remarks are given before the table and sometimes multiple times. For example, the claims about the case where $\\delta << L $ and claims about SCAFFOLD. These can be clearly stated in contributions.\n- In theorem 1, $\\mathbb{E}[||\\nabla  f (x^{out})||^2] \\le \\epsilon$, expectation over what? I believe it is $i$?\n- In assumptions A1, A2, the bound on gradient is defined over the expectation of local datasets $i$ but the Hessian bound is for all $i$. Is there any specific reason for this? Or is this a standard assumption?\n- Typos: Last line in the first paragraph of Related work, there is an extra \"?P:\". Page 3 before equation 1, \"vour\" -> \"our\".  In equation 5, nothing written after \"where\".\n\n\nOriginality and significance:\nI believe this paper adds decent contributions toward understanding of federated learning and and tackles the \"client drift\" problem in a simple way.\n\n\nPros:\n- Nice to have a flexible framework that can adopt standard centralized methods with similar guarantees.\n- Extensive experiments validates the provided theoretical claims.\n\nCons:\n- This work is incremental on the paradigm of using momentum in order to improve distributed SGD methods.\n\nOther comments:\nThe paper titled \"On the Linear Speedup Analysis of Communication Efficient Momentum SGD for Distributed Non-Convex Optimization\" seems to be discussing a similar approach that uses momentum updates in locally. Can the authors distinguish between these two results? \n\n\n===========================================================================================================\n\nAdded after author response:\n\n--------------------------------------------------------------------------------------------\n\nI have read the author responses and other reviews. I believe authors have a sufficiently addressed my concerns regarding the quality of the paper. I understand the improvement in using momentum in this way and I think it is decent contribution. However, considering this improvement and the concerns raised by other reviewers, I maintain my score.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Reviews",
            "review": "The paper proposes a new framework for solving federated learning. The authors consider a specific setting that there are many clients, and each client is allowed to compute the full gradient. The authors claim that the current setting’s main issue is the client drift, and the proposed framework can reduce such an issue and thus achieve a faster convergence rate. Here are my main concerns of the current paper:\n1. The client drift issue is not clearly defined in this paper.\n2. The comparisons in Table 1 are not fair since different methods have different assumptions. For example, the authors claim that the proposed MimeSGD algorithm can reduce communication costs compared with FedSGD. However, MimeSGD depends on the extra Hessian assumptions (A2).\n3. Assumption A2 seems to be a very strong assumption. Intuitively, it contains two variances: one from the gradient dissimilarity and another from the within-client variance. Therefore, why can we expect that delta is very small? In addition, is the improvement of your framework comes from this assumption?\n4. It seems that the algorithm with theoretical guarantees is different from the one implemented in experiments. To validate your results, the experiments should use the same algorithm.\n5. The parameter beta in Theorem 1 seems to be a very small value. However, the experiments suggest a very large beta. This seems to be inconsistent with your theorem. Is this due to the different algorithms you implement in experiments?\n6. What is the definition of x^out? \n7. The proposed framework requires additional communications due to the correction term c. Did you consider this extra communication cost in your experiments?\n8. In the experiments, since each client performs several epochs of updates, the comparison with the server-only method is not fair since it only performs one update each communication.\n9. In Figure 2, why is there a spike for your Mime method?\n10. Typos: relative slow-> relative low. vour-> our.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This paper proposes a way to apply various variance reduction/momentum based method to the federated learning scenario, especially when there is distribution drift among the clients.",
            "review": "This paper proposes a way to apply various variance reduction/momentum based method to the federated learning scenario, especially when there is distribution drift among the clients. The main claim of this paper is that the global statistics (momentum, control variance et al) should be update at the server side only, which is helpful to reduce the bias of these terms. The paper also provides convergence analysis for their methods and attains the best convergence result for their MimeMVR method.\nHowever, I find a key wrong in theoretical analysis. Specifically, in the proof of Lemma 7, the last second inequality in page 21 is wrong.  Thus I have difficulty judging the contribution of this paper.  \n\nSome comments are given as follows:\n\n1.\tIn the proof of Lemma 7, when the authors bound the distance between y and x, how do you get at the last second inequality in page 21, it seems to rely on: 1 + 2/k < 1 + 2/k - mu*eta* 3/k, which obviously not hold.\n2.\tFor the MimeMVR, the update rule for d^t_{i,k} in the equality (14), there is a  -1 term, which looks strange.  Why does this term exit?\n3.\tIn the proof of Lemma 8, the second equality at page 25 should be inequality.\n4.\tIn the proof of Lemma 9, there are typos using the brackets in the third equality at page 25.\n\n\n---------------------------------------------------------------------------------------------------\nAfter Rebuttals\n---------------------------------------------------------------------------------------------------\nThanks for your responses. I still have doubts about the proof of lemma 7. You not only change from '2' to '3', you also add a new term (the fourth term). I admit that $1 + 2/k < (1 + 3/k)(1 – \\mu*\\eta)$ holds under your assumption, but you also need: $\\mu*\\eta> 1/k$, i.e. let the fourth term be greater than zero, to make the inequality hold, however, this contradicts the previous assumption. So I still believe this inequality does not hold. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}