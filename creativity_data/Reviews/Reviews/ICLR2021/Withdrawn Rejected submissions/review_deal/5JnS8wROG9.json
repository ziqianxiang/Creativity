{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper considers a new model of input data specific for image classification problems. In particular, the high level idea is that each image contains certain patterns, and which patterns it contain decides its label. In this framework, under some stronger assumptions (e.g., patterns are orthogonal, one positive pattern and one negative pattern, PSI assumption, etc.) the authors showed that SGD on a 3-layer overparametrized convolutional network will be able to have a small sample complexity, while the VC dimension would be at least exponential in d. The paper also provided some empirical evidence on a modified MNIST dataset. While the idea seems to be an interesting first step, the reviewers find that the current version of theory still relies on fairly strong assumptions."
    },
    "Reviews": [
        {
            "title": "Restricted model and complex measures make this work less attractive",
            "review": "This paper studies a new theoretical framework to understand the ability of \nConvNets to deal with pattern recognition tasks. The authors suggest a new property \nof convents where filters have large dot products with patterns occurring in images classified as 1 and small dot products with patterns appearing with images classified as 0. \nIt is assumed that there are two unique patterns whose occurrence in an image determines if the image is classified by 1 or 0. \n\nI like the classification problem studied in the paper and the attempt to understand how ConvNets work from first principles.  \n\nMy issue with this paper is that it uses rather cumbersome measures (PSI and detection ratios). The setting is very specific (one type of architecture, realizability assumption, a single positive pattern and a single negative one). \nThe combination of these factors casts doubts on whether these measures and analysis will be of any use elsewhere.  The authors claim: \n\n\"Empirically, we identify a novel property of the solutions found by SGD. We observe that the statistics of patterns in the training data govern \nthe magnitude of the dot-product between learned pattern detectors and their detected patterns. Specifically, patterns that appear almost exclusively in one of the classes will have a large dot-product with the channels that detect them. On the other hand, patterns that appear roughly equally in both \nclasses, will have a low dot-product with their detecting channels. We formally define this as the “Pattern Statistics Inductive Bias” condition (PSI) and \nprovide empirical evidence that PSI holds across a large number of instances. We also prove that SGD indeed satisfies PSI in a simple setup of two points in the training set\" \n\nI find this somewhat unsatisfying. The novel property mentioned by the authors is one of the first that comes to mind when thinking about the success of ConvNets. It seems very \nunlikely that this has not been observed before (at least empirically). While obtaining rigorous proofs of properties of NN is hard, one would expect that for the simple setting studied \nby the authors there would be a simpler explanation for the so-called PSI. \n\nThis paper makes numerous restrictions and assumptions. \nSome examples: \n\n\"a natural model in this context is a 3-layer network with a convolutional layer, followed by ReLU, max pooling and a fully-connected layer.\"\nWhy is this a natural architecture? Has it been studied before or used before? \nAlso in the classification task why is it assumed that n<d? \n\nThere are many more such examples. \n\nThe proof of Theorem 5.1 uses the Sherman-Morrison formula without giving the formula and showing how it is used. \n\nThe survey of related work is very short, not mentioning many relevant works looking into similar pattern recognition problems. \n\nSome examples:\nLearnable and Nonlearnable Visual Concepts (Shvayster, 1990)On learning visual concepts and DNF formulae (Kushilevitz, Roth, 1996)",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "I vote for accept.",
            "review": "In this manuscript the authors derive theoretical analysis for the generalization guarantees of a naïve CNN (3-layers) where the task is a simplified binary classification task, under the assumption that the images contain orthogonal patches (a naïve assumption). They define a statistical phenomenon that holds in SGD in the proposed setting and call it Pattern Statistics Inductive Bias (PSI). Informally, this means that the magnitude of the dot-product between the learned pattern detectors and their detected patterns is correlated with the distribution of the patterns in the data.   They prove that if a learning algorithm  satisfies PSI then its sample complexity is O(d^2 log (d)), where d is the dimension of the filter. According to their empirical derivation SGD satisfies this property. In contrast there exist learning algorithms that have exponential sample complexity. \n\nPros.\n1.\tAddressing the problem of generalization guarantees is important and interesting.   \n2.\tNovelty. In some sense, this works shows theoretical results which are less restrictive than Yu at el, circumventing the dependence of the sample complexity on the network size. \n3.\tAlthough the setting presented in this manuscript is quite limited, empirical observations on MNIST are in line with the analysis. \n\nCons.\n1.\tIt is not easy / straightforward to follow the manuscript.\n2.\tSpecifically, the intuition, given in Sec. 4, is not clear.  \n3.\tThe proposed setting, which assumes orthogonal patches in images, is very limited and not natural.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "pattern statics inductive bias is an interesting idea but the theory is limited and requires unrealistic assumptions",
            "review": "This paper studied a simplified image classification task with orthogonal non-overlapping patches and is learned by a 3-layer CNN. The authors observed pattern statics inductive bias (PSI) in experiments. They proved that if a learning algorithm satisfies PSI, the sample complexity is nearly quadratic in the filter dimension; while the VC dimension of the network is at least exponential in the filter dimension. The authors also verified PSI in some task based on MNIST that has non-orthogonal patches.\n\nMy major concern about this paper is that the theory seems to only work under orthogonal patterns and non-overlapping filters, unfortunately, neither of which is true in practice. So it’s unclear if this theory can explain the success of CNN in practice. I also have other concerns:\n1. This is mainly a theory paper, but the theoretical contribution is pretty limited. The theory only considers orthogonal patterns and non-overlapping filters. Theorem 6.1 needs to assume that PSI holds and spurious patterns are unbiased; under these assumptions, the result is pretty straightforward. This paper didn’t prove PSI holds for SGD except in a toy example (two training points).\n2. The lower bound on the VC dimension is only exponential in the filter size. This lower bound is pretty weak since in practice the filter size is usually small (e.g. 3x3).\n3. The experiment is run on an artificial task based on MNIST images. It would be much more convincing if the experiment is on standard tasks (like 10-class classification in MNIST). Since the theoretical setting is limited, it needs experiments to show how the theory applies to practical tasks. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting ideas on theory for CNN's",
            "review": "This paper is concerned with the question of generalization of convolutional neural networks. For that, the authors study a simple toy model, where each data point consists of several patterns. All patterns are assumed to be orthogonal to each other. Those images should be learned with a 3-layer neural network. The contributions of this paper are as follows:\n\n1. The authors show that the networks, which are analyzed in this paper, have large VC dimension. In particular, this implies that generalization cannot be explained via generic VC theory. \n2. As a way out, the authors introduce the concept of Patterns Statistics Inductive Bias (PSI). This relates the weight to the patterns in the dataset. In particular, the authors prove that PSI implies good generalization.\n3. The authors study the conjecture, that training a neural network via gradient descent (with hinge loss) leads to a network, which satisfies the (PSI) condition.  They provide empirical as well as some theoretical evidence.\n\nI think this is an interesting paper, which develops a new point of view and contains interesting ideas. While, the paper does not provide full evidence that the (PSI) condition is the right way to look at the problem, it may open up a new research direction.\n\nOn a personal level, I think point 1. and 2. are argued convincingly in the paper, but 3. could be strengthened with more evidence. For example, Theorem 7.1 allows for only two data points. It would be interesting to see a more general version of this theorem.\n\nRemarks:\n-I was wondering about Figure 1c). What happens, if you increase $\\max (0, \\frac{s_i}{s_1}) $ above $1$?\n-Why do you choose $b=2$ for the experiments in Section 7?\n\n\nSome typos:\n-p. 6 Figure 1c): It should be $\\max (0, \\frac{s_i}{s_1}) $.\n\n--------------------------------\nI want to thank the authors for their rebuttal. I will stick to my decision and not change the score.\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}