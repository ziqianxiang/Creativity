{
    "Decision": "",
    "Reviews": [
        {
            "title": "This paper could be considered as a VAE-GAN with a contrastive loss function",
            "review": "This paper introduces a discriminator into the VAE framework. The original reconstruction loss is replaced by a adversarial loss and a contrastive loss upon features extracted by the discriminator. The author highlights the ability of reconstruction and generation ability compared with both VAE and GANs. Experimental results show that the proposed DC-VAE outperforms other auto-encoder-based generation methods and obtains comparable results with adversarial generative method. \n\nPros,\n1. Experimental results seem good.\n\n2. This paper is well-written and easy to read.\n\n3. The source code is provided to make the results reproducible.\n\nCons,\n1. Although a discriminator is introduced into DC-VAE, generation results are worse than GANs on most datasets. Considering that an encoder is also used in DC-VAE but not in GANs, these results seem to be less competitive. \n\n2. The contrastive loss is interesting, however, no experiment shows results obtained with  contrastive loss only. An ablation study is welcome.\n\n3. In experimental parts, some interesting generative models are missing, such as relativistic GAN [1], PUGAN [2], NVAE\n\n[1] \"The relativistic discriminator: a key element missing from standard GAN.\" International Conference on Learning Representations. 2018.\n\n[2] \"On Positive-Unlabeled Classification in GAN.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n\n[3] \"Nvae: A deep hierarchical variational autoencoder.\" arXiv preprint arXiv:2007.03898 (2020).\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper proposes DC-VAE, a modification of VAE/GAN model that uses contrastive learning to achieve improved perceptual quality in reconstructions and synthesized images, and meaningful semantic representations with respect to downstream classification tasks (MNIST only). Analysis experiments could have been more insightful.",
            "review": "The paper presents a novel approach to VAE based generative models, and claims to address the three tasks of reconstruction, synthesis and learning semantic representations. The primary contribution is a novel loss that combines a contrastive loss at the instance level, which assists more faithful reconstructions, with a GAN loss to introduce set-level fidelity, which assists the synthesis quality. Additionally, a multi-scale contrastive learning loss is also used by imposing losses across different layers of the network, as well as at different patches (receptive field sizes). This dual \"contradistinctive\" loss is well-motivated and appears to work well for datasets like CIFAR-10, STL-10, CelebA, CelebA-HQ and LSUN bedroom. The quantitative analysis is done using Inception Score (IS) and Frechet Inception Distance (FID), Pixel Distance, and Perceptual Distance. The paper shows good results on these datasets and settings. \n\nStrengths\n+ Quality of reconstructions and synthesis is very good, and better than state-of-the-art (Intro-VAE). The quantitative analysis is consistent with the qualitative superiority of the proposed method. \n+ The use of contrastive loss together with a GAN based loss is an interesting idea, and it seems to work well based on the qualitative and quantitative results. \n\nWeaknesses\n- Why is h(x,y) in Eq. (6) used as the cosine distance? Would changing it to L_1/L_2 distance help reconstruction better? The cosine similarity is probably appropriate in (He et al., 2020) because of their downstream task of classification, and not reconstruction. What is the impact of changing this critic function on reconstruction? \n\n- How is the number of negative samples determined for contrastive learning? Why is it 8096, and how do the results change if this number is reduced or increased. An analysis experiment around this could help understand the impact of the contrastive loss. \n\n- Does the stability of GAN training get impacted by the contrastive learning loss? Particularly, if the parameters like number of negative samples are changed? \n\n- The paper does not provide details about the training infrastructure used for training this model. It could be helpful to provide these details along with training time, etc. \n\n- Representation learning experiments are only done on MNIST. Conducting them on CIFAR-10 and/or STL-10 would add more value to the paper. MNIST not having been used elsewhere seems odd and gives the (possibly incorrect) impression that representation learning performance is not good for other datasets. \n\n\nOther (minor) issues \n- Please define i (index of anchor point?), and x_j (samples that are not x_i?) in Eq. (6). Please define D_l in the critic function definition that follows. The sentence before Eq. (6) also needs attention, as it refers to a minimization problem, which is not indicated in Eq. (6)\n- It seems the second last para before Sec. 4.1 has the Eq. numbers mixed up. It may be worth verifying. \n\nThe results obtained are impressive, however, not all claims are satisfied thoroughly, e.g., the representation learning experiments are weaker as they are only shown on the MNIST dataset. The analysis experiments are limited and do not entirely provide the view of the hyperparameter choices. These are the primary reasons for me to recommend marginally above acceptance threshold. \n\nI request the authors to comment on the following: \nIt will be helpful to understand the implications of the combination of contrastive loss and GAN based losses on the training. \nIt will also be helpful to comment on the choice of the critic function. \nShould we expect similar results of representation learning on datasets other than MNIST as well? ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review: DUAL CONTRADISTINCTIVE GENERATIVE AUTOENCODER",
            "review": "Review: DUAL CONTRADISTINCTIVE GENERATIVE AUTOENCODER\n\nSummary: The paper presents a new generative model called DC-VAE which leverages instance-level and set-level constrastive losses together to achieve simultaneously sharp outut images in reconstruction, in sampling and representation learning. The results appear to be similar or better than other comparable approaches like VAE-GAN (Larsen et al. 2016) which in itself improves upon VAE.\n\n##########################################################################\n\nReasons for score: \n\nWhile I appreciate the idea and the results look promising, a closer examination of the results raises several questions.\nThese questions must be addressed in order for me to raise the score.\n\n##########################################################################\n\nPros:\n- The model is interesting, the idea is well justified, and to my knowledge, this specific combination of ideas is novel, though the building blocks are largely well known.\n- The presentation is clear.\n- The model is general-purpose and hence potentially with wide range of applications.\n- There are indications of good performance.\n\n##########################################################################\n\nCons:\n- The experiments do not seem to form a coherent whole. Some results are only given in qualitative (visual) way which leaves room for heavy cherry-picking (faithfulness or LSUN reconstructions is only indicated in 3 images in fig 1, so are the reconstructions of CIFAR in fig.4, and the IntroVAE comparison). The faithfulness of reconstructions should be quantitatively measured if the authors want it to carry weight.\n- Some claims seem to imply that results in very different resolutions are comparable. One cannot make this assumption.\n- IntroVAE comparison is problematic. First, IntroVAE paper itself does not even claim that their reconstructions would retain the identity of the face, but only the general topology, and thus they often lose the identity. So it is a problematic comparison point to begin with since the authors do not discuss the identity question at all. Second, the authors compare 128x128 results of their model to 1024x1024 results of IntroVAE, and instead of granting that the capacity to learn a high resolution may cause more loss of details, they make the contrary claim that their model is \"already better\" at the low resolution. I do not agree with this interpretation. You cannot compare models that have this large of a difference in resolution and draw that kind of a conclusion.\n- Smoothness of latent space is not evaluated in any way (e.g. by interpolations)\n- Minor: There could be many more comparison points and it is not clear why these exact ones were chosen. E.g. [1-6] seem to be relevant prior work and some of them as potential baselines. Either (Donahue et al., 2018) or (Dumoulin et al., 2018) could also be better contrasted to or used as a baseline.\n\n##########################################################################\n\nQuestions during rebuttal period:\n- How is the FID of reconstructions computed exactly? Is the reconstructed set of (how many?) samples compared against the set of the original samples?\n- What do you mean by using ProgressiveGAN for the 128x128 architecture in 5.1? Do you mean you just use their 128x128 structure in a static manner, and not the progressive growing?\n- Can you show also latent interpolations or Perceptual Path Length (Karras et al., 2018) measurements?\n\n[1] A. Makhzani, J. Shlens, N. Jaitly, and I. Goodfellow. Adversarial autoencoders. In International Conference on Learning Representations (ICLR), 2016.\n[2] L. Mescheder, S. Nowozin, and A. Geiger. Adversarial variational Bayes: Unifying variational autoencoders and generative adversarial networks. In International Conference on Machine Learning (ICML), pages 2391–2400, 2017\n[3] A. Heljakka, A. Solin, and J. Kannala. Pioneer networks: Progressively growing generative autoencoder. In Asian Conference on Computer Vision (ACCV), pages 22–38, 2018.\n[4] D. Ulyanov, A. Vedaldi, and V. Lempitsky. It takes (only) two: Adversarial generator-encoder networks. In Proceedings of the Thirty-Second AAAI Conference on Artiﬁcial Intelligence (AAAI), pages 1250–1257, 2018.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Official Review for DC-VAE",
            "review": "This paper proposed to replace the ELBO loss in VAE-GAN with an instance-level contrastive loss to improve the performance of image synthesis and reconstruction. Experiments on multiple benchmarks of images demonstrate the effectiveness of DC-VAE on image synthesis and reconstruction, and latent representation learning.\n\nStrengths:\nThe improvements of DC-VAE on the benchmarks over VAE-GAN and other baselines are impressive.\n\nWeakness:\n1. The motivation of replacing the ELBO loss with the contrastive loss is not clearly introduced. Both the two losses work for the instance-level fidelity. Why the contrastive loss is better than the BLBO loss? \n\n2. The paper is not clearly written, some parts are confusing. For example, what is Theorem 1 telling us? I cannot understand it. Moreover, how to optimize the contrastive loss (6) in practice? \n\nOther comments and questions:\n\n1. Some notations are inconsistent. For example, in Eq (3), F_l() is denoted as the l-th layer feature embedding of D. But in Eq (6), D_l() is used. These inconsistent notations make the paper more difficult to be understood.\n\n2. In the first sentence of introduction, I cannot understand the three types of representation learning divided by the authors. Why CNNs are categorized as encoders and Transformers as autoencoders? \n\n3. In the last two sentences in the second paragraph, the authors claim \"once an encoder and a decoder are joined together, the reconstruction/synthesis of the decoder often becomes degenerated.\" I don't believe that it is the joint learning of encoder and decoder leads to degenerated decoder. And what is the relation of this sentence with the following one \"Note that Transformers, consisting of both encoder and decoder, are trained for temporal data with sequence-to-sequence prediction.\" I cannot follow what the two sentences want to say.\n\nOverall, the contrastive loss proposed in this paper is interesting, and the experimental results are impressive. However, the paper is not ready to be published and needs to be revised fundamentally.\n ",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}