{
    "Decision": "",
    "Reviews": [
        {
            "title": "A small modification on the  contextual graph projection line of work ",
            "review": "This paper proposes a small modification of GloRe (Chen et al.) and uses an attention-based way to construct a set of global descriptors for mapping the elements in the activation map to the graph nodes. The authors explained their methods in detail, and mentioned that instead of using convolution filters, an attention all over the map is used to derive the descriptors for graph pooling. Empirically the authors show that they achieved the state of the art on several semantic segmentation benchmarks.\n\nPaper pros:\n\n+ The intuition of global/holistic information might make sense\n\n+ The model achieves the SOTA\n\nPaper cons:\n\n- This paper to me seems to be a bit incremental. It's not super clear why this proposed way is better than convolution filters:\n  1. The high-level features already have enough FOV to get holistic information\n  2. We can simply achieve a more holistic view through adding more layers of convs, using larger conv filters, use non-local networks to generate pooling matrix. With all these works/techniques existing, not sure how useful the proposed one can be - or how different the proposed one is.\n\n- The key result for this paper to show is actually table 5 - using this attention-based feature only gives a 0.5% improvement, which is kind of statistically insignificant. Again as mentioned above, it's likely a better tuned version of GloRe with more layers/better filters/etc will have similar improvements.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Some important details are missing and empirical comparisons need to be improved.",
            "review": "Summary:\n\nThis paper presents a graph project and a reprojection module to help capture long-range dependencies within images for CNNs. Authors conduct experiments on several popular datasets to verify their claims.\n\nPros:\n\n1, The general motivation of introducing graphs to model longer range dependencies within images is very reasonable and is indeed an important research direction.\n\n2, Authors conduct experiments on 4 popular datasets and the results are better than other “graph-reasoning” based methods.\n\nCons & Questions & Suggestions:\n\n1, The problem definition of graph reasoning is vague from the writing. It could be a very broad topic but authors seem to only limit themselves to 2D image tasks like semantic segmentation. Therefore, I suggest the authors improve the writing to narrow down the topic and be more clear and specific. Also, it would be much better to first state the problem formally before introducing technical details like the projection matrix in the beginning.\n\n2, The description regarding how the graph is constructed is unclear if not missing. This is important since otherwise you do not need to call it graph reasoning. It would be great to improve the writing on this part. Also, it is important to perform an ablation study on different options of graph constructions.\n\n3, How do you determine the number of nodes? It seems that it is shared across multiple images which does not make much sense to me. The number of semantically meaningful parts should vary from image to images. That being said, it would be much better to visualize the graph on top of the real images to see whether this construction is interpretable or intuitive. This also relates to how to explain why the proposed method could improve empirical performances. \n\n4, Why are the performances of some baselines (e.g. OCRNet on PASCAL-VOC, PSPNet on COCO stuff) on several datasets missing in Table 1? I assume most methods like PSPNet are open-sourced and authors should be able to obtain the performances. The state-of-the-art claim is a bit problematic since the results on PASCAL-VOC are at least worse than other baselines, e.g., see [1]. It would be more convincing to add more non-graph-based baselines, e.g., those capture the long-range dependencies/contextual information without using graphs. \n\n5, It would be great to provide the #parameters, #flops, and FPS of the baseline in order to fully tell how efficient the proposed module is in Table 4. \n\n6, A few terminologies and notations are used without proper explanations. For example, what do you mean by the non-parametric adjacency matrix at the beginning of section 3.1? What are H, C, W, etc.? This also links to the previous point on introducing the problem definition.\n\n[1] Minaee, S., Boykov, Y., Porikli, F., Plaza, A., Kehtarnavaz, N. and Terzopoulos, D., 2020. Image segmentation using deep learning: A survey. arXiv preprint arXiv:2001.05566.\n\nConclusion: Although this paper seems to present some good empirical results, I found (1) the model design hardly brings something novel to the machine learning community, (2) some important details are missing as aforementioned, and (3) the empirical results on computer vision tasks are not strong enough. Therefore, I lean towards rejection. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official Blind Review #3",
            "review": "**Summary Of Contributions**:\nThe paper introduces Contextual Graph Reasoning, which learns a context-aware relation between features and a graph. The core contributions are the following two modules: DGP and NCR. DGP learns a global set of descriptors for projection matrix construction, capturing the contextual information for graph nodes, while NCR calibrates the features of graph nodes with the self-attention mechanism, further exploiting the benefit of contextual information. Finally, the paper presents experiments on semantic segmentation, instance segmentation, and 2D human pose estimation to demonstrate the effectiveness of the proposed model.\n\n**Strengths**:\nA) Overall this paper is well written and the technical details are easy to follow.\nB) The method achieves consistent improvements over the state-of-the-art for three different tasks: semantic segmentation, instance segmentation, and 2D human pose estimation.\nC) Although long-range modeling dependencies with graph reasoning methods are not a new approach, the importance of the problem is still significant.\n\n\n**Weaknesses**:\nI have some critical concerns about this work, which I expect the authors to address them in the rebuttal:\n\nA) I found the approach introduction from Section 3.1 very vague and confusing. The authors present two popular paradigms of constructing the projection matrix, however, it is unclear what the difference is between them. I understand the two paradigms aim to obtain the projection matrix $Q$, and the second approach learns $Q$ directly by a point-wise convolution, but I could not understand what and why the approaches are different. Also, the authors mentioned $W$ as the “Visual Code.” What is it, and what does it mean?. Besides, $W$ is defined twice, once as width and once as visual code. Unfortunately, I could not understand what the purpose of this subsection is. I hope the authors could clarify it better in their response.\n\nB) I am concerned with the limited novelty of the paper. As I mentioned below, [5] already proposed the Long-Term Feature Banks model for better long term dependencies, and it seems the proposed DGP module is similar to [5]. Moreover, GCN is already a trendy architecture, and hence the GC module also does not strike me as a novel. The authors should discuss how their approach is different from the already existing related work since graph reasoning methods have become popular in various tasks (see the missing related work subsection below).   \n\nC) The paper contains different sentences without supported facts, analysis of experiments. Here are some examples. 1) In section 3.2.1, “existing methods fail to explore the holistic information, which is crucial for effective graph representation” - what is holistic information, and can the author support or show it?. 2) In the intro, “Although existing methods have demonstrated the great potential of graph reasoning, the learned graph representation is not effective enough as the relation between feature and graph is under-explored.” These words alone do not help explain the failure of the current models -- rigorous experiments and analysis are needed to support these arguments. I have found the motivation of the paper not very clear. \n\nD) I agree with the authors that long-term dependency is a crucial problem in Machine Learning and Computer Vision in many different tasks, and the motivation for it is clear. However, the authors did not show experiments in their proposed approach that is actually improving this. One way to show it is to show it for the temporal domain of videos (where the temporal aspect is limited in current models) or show it on image and text tasks (e.g., VQA and more). I am not convinced how their proposed modules on semantic/instance segmentation tasks are relevant to this problem.\n\nE) In Table 2 (the ablation table), it seems the CGP + GC + MS are the significant factor. However, CGP is very similar to [5] or a Non-Local block (did the author ablate this module? They should have the results with a Non-Local block instead of CGP to understand the difference). GC and MS are the standard GCN multi-scale, which is common in other approaches. It seems that if we take only CGP + GC + MS (without NCR), the performance boost is limited.   \n\n\n**Suggestion To Authors (not considered for the final evaluation)**:\nA) This paper is well written and easy to follow.\nB) The paper contains some missing related work, which I think the author should include. Here are some highly related work:\n\n[1] Joanna Materzynska, et al. Something-Else: Compositional Action Recognition with Spatial-Temporal Interaction Networks. CVPR 2020.\n[2] Roei Herzig, et al. Spatio-Temporal Action Graph Networks. ICCVW 2020.\n[3] Moshiko Raboh, et al. Differentiable Scene Graphs. WACV 2020.\n[4] Xiaolong Wang, et al. Videos as Space-Time Region Graphs. ECCV 2018.\n[5] Chao-Yuan Wu, et al. Long-Term Feature Banks for Detailed Video Understanding. CVPR 2019.\n\nModeling long-term dependencies with graph reasoning methods has been a very active field in domains of Video Understanding, Scene Graphs, and Human-Object Interaction. I add some related papers such as [1,2,4,5], which proposed better video models by modeling graph reasoning methods for better action recognition models, while [3] proposed a latent scene graph approach for the VQA task.\nC) Table 2: Changing ‘CGP’ column -> ‘DGP’?\nD) The paper does not contain any results figures in the main text. It is an unfortunate consequence of the page limit (at least this information is present somewhere!), but it does make following this paper difficult for the reader. \n\n\n**Preliminary Rating Justification**:\nThe paper introduces Contextual Graph Reasoning with the following two modules: DGP and NCR. The paper presents strong experiments on semantic segmentation, instance segmentation, and 2D human pose estimation to demonstrate the effectiveness of the proposed model.\n\n\nOverall, the general problem of the paper is important, and the paper is well written. However, this paper is missing some related work, and an informative discussion of the proposed model and baselines comparison is missing. There are some critical concerns about this work regarding novelty and motivation. For example, it is not clear why the proposed model introduces a better approach to long-term dependency. In addition, some additional justifications would further strengthen the paper. I am open to the authors' feedback and other reviewers’ opinions.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}