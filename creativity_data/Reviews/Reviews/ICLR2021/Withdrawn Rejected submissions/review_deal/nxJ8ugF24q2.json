{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes to train a rejection sampler in the latent space of a GAN to learn disconnected data manifolds. Reviewers raised concerns about some theoretical aspects of the method as well as about the lack of larger scale datasets (ImageNet) in the experiments. Authors responded to these concerns but some of them still remain (including $\\hat{\\gamma}(z)$ not guaranteed to be a probability distribution and lack of more convincing experiments). I still think the work is promising, and encourage the authors to revise and resubmit the paper addressing these points highlighted by the reviewers. "
    },
    "Reviews": [
        {
            "title": "This work proposes a new rejection sampling technique for improving the quality of images generated from GANs",
            "review": "## Summary:\nThe paper proposes a new algorithm for improved sampling of GANs. Since GANs are continuous functions that act on a connected latent space, they will have trouble learning distributions whose support is disconnected (for e.g., clustered data). The proposed method tries to fix this issue and is motivated by rejected sampling. However, instead of using density based algorithms for rejecting samples, the authors take a fixed pre-trained generative model and train a neural network that learns to reject samples from the latent space.\n\n## Significance:\nThe problem is well motivated and seems significant. Learning distributions with disjoint support can be difficult using the traditional GAN training, and this paper addresses this problem by learning which areas in the latent space must be avoided. \n\n## Quality:\nWhile the problem is significant, I find that the proposed method has some weaknesses in its formulation and empirical evaluation. Please see the section \"Cons\" below.\n\n## Originality:\nThe proposed method seems sufficiently novel, but I am not familiar enough with this area to know if something closely related has been done before.\n\n## Pros:\n1. On synthetic data, the proposed method can capture modes better than the considered baselines.\n1. The proposed technique produces better quality samples on GANs trained on CelebA.\n\n## Cons:\n1. While some of the experiments are convincing, I do not buy some of the arguments made in the paper. Specifically, under eqn (3), it is argued that if the GAN $G$ is kept fixed and the following adversarial training is performed for a classifier $w_\\phi$ and discriminator $D_\\alpha$, then the following procedure:\n$$ \\sup_{\\alpha \\in A} \\inf_{\\phi \\in \\Phi} E_{x \\sim \\mu} D_\\alpha(x) - E_{z \\sim Z} [ w_\\phi(z) \\cdot D_\\alpha( G(z) )]$$\nwill produce a new distribution on $z$ which is $\\widehat{\\gamma}(z) \\propto \\gamma(z) w_\\phi(z)$.\nThere is no proof of this claim, and I further suspect that this claim in not correct.\n\n1. There exist several baseline methods that consider the problem of mode collapse. Examples like PAC-GAN [Lin et al 2017] have shown to be effective, and are also provably good. Other examples include those considered in table 5 of https://arxiv.org/pdf/2010.00654v1.pdf\nFor the Stacked-MNIST dataset, the algorithms listed in table 5 seem to have much better mode coverage than the algorithms in Table 1 of this submission.  While the paper I have linked is very recent, the baseline algorithms considered in the paper are published works from 2017 onwards.\nComparing to these algorithms would make this paper much stronger.\n\n1. There are a lot of unsubstantiated claims. Some include:\n    1. Modifying the loss in equation 3 gives a new distribution $\\widehat{\\gamma}$ defined underneath equation 3.\n    1. At the bottom of page 5, the authors remark \"In our method, on the contrary, we are still looking for the discriminator maximizing the Integral Probability Metric (Müller, 1997) in equation 3, linked to optimal transport.\" .\nIn equation 3, the authors take the dual optimization problem for estimating the Wasserstein distance, and modify it. With this modification, optimizing equation 3 will not give the Wasserstein distance any more.\n\n## Minor:\n1. Should there be a quanitifer in eqn (3) restricting $D_\\alpha$ to $1-$Lipschitz models?",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Treating the problem in latent space is promising, but experiments are not convincing",
            "review": "This work aims at improving the sample quality of generative models through better sampling, which is a relevant problem and has brought about a line of work [1,2,3,4,5], to name a few. By leveraging the idea of importance sampling, the authors train an additional network. The latter uses the information contained in the learned discriminator to assign importance weights to the latent points, thus defining a new distribution in the latent space. Subsequently, rejection sampling on the newly defined latent distribution is applied to obtain inputs for a generator network. By treating the problem in the latent space, the paper introduces latentRS method that compares favourably to several existing methods in terms of computational complexity for generating a sample. The authors propose one more method, latentGA, following the path in the latent space that maximizes the learned importance weights. The paper also discusses the limitations of the previously proposed methods and presents their empirical comparison on several datasets and metrics.\n\nThe method is concise and straightforward to be applicable by a broad community of ML practitioners. One of the proposed methods, latentRS, offers a significant speedup at the inference stage compared to analyzed methods while being similar in performance metrics. The paper also raises an interesting question of whether the existing enhanced sampling methods help when the target distribution is not sufficiently disconnected.\n\nHowever, there are several weaknesses in the experiments which lead to questioning the claims. While the paper's claim of careful comparison with the existing methods and the discussion of existing methods' limitations is indeed well-presented, the paper neglects the already recurring standard experiments for such methods or brushes them under the Appendix section. The generated samples from the Appendix figure for the mixture of Gaussians with n>9 show that the results are not as promising as the same experiments in the literature (the 'fake' clouds are not as nicely located on top of the true ones). n=25 is a recurring setting and seems to be a standard check for algorithms that refine GAN's sampling (e.g. DRS, DOT, DDLS). Table 2 in the Appendix lacks computer metrics for existing methods since it would demonstrate the tangible interpretable difference in this setting between comparable methods.\n\nThe paper misses some essential experiments to be faithfully compared with existing methods. It would be helpful to see the Swiss Roll experiment and the statistics on recovered modes and quality on 25 Gaussians for all the considered methods. As for more realistic image spaces, the CIFAR10 is a dataset that represents an undoubtfully disconnected manifold, and it has more potential to show the advantage of the proposed methods.\n\nReturning to the presented empirical study, these too raise a number of questions. The IPR results in Table 1 (and Table 3 in the Appendix) do not show consistent advantages for the proposed methods over the existing ones. It either favours latentRS or latentGA in terms of precision or recall alone, not both at the same time. It's understandable that when maximizing importance weights with latentGA we get higher precision; we force the generated samples to stay within true points at the cost of their diversity (which can also be seen in the synthetic experiment with Gaussians), so I guess the method is highly reliant on the hyperparameter m, which controls the 'conservativeness' of the trained importance weights network. It would be helpful to see an ablation study for the hyperparameters.\n\nGiven all the above, I am leaning towards a reject and my main concerns are as follows. The experiment with 25 Gaussians doesn't show as much improvement in sampling as existing methods implying there might be little effect in real-world datasets. I believe that the proposed methods have not been faithfully compared to the existing methods. There is no ablation study on the hyperparameters of the proposed methods.\n\nWhile the argument about one class CelebA has grounds, the DRS technique shows that it improves face generation by producing less warped nightmare-like faces. Thus, better GAN sampling techniques should ideally not only help avoid empty regions in the latent space between the nodes (inject disconnectedness) but also grasp the shape of those modes. In this regard, using an energy-based model for the latent variable might be an apt direction [5].\n\nThe authors state that they use image embeddings from corresponding classification networks for each of their datasets, but how do they obtain image embeddings for CelebA?\n\nSome minor points — the notation for the proposal and true distribution we want to sample from in section 3 is a bit confusing as the hat is usually used to denote an approximation. Also, the submission has quite a few typos — it needs proofreading.\n\nReferences:\n[1] Azadi, Samaneh, et al. \"Discriminator rejection sampling.\" arXiv preprint arXiv:1810.06758 (2018).\n\n[2] Turner, Ryan, et al. \"Metropolis-hastings generative adversarial networks.\" International Conference on Machine Learning. 2019.\n\n[3] Neklyudov, Kirill, Evgenii Egorov, and Dmitry P. Vetrov. \"The Implicit Metropolis-Hastings Algorithm.\" Advances in Neural Information Processing Systems. 2019.\n\n[4] Tanaka, Akinori. \"Discriminator optimal transport.\" Advances in Neural Information Processing Systems. 2019.\n\n[5] Che, Tong, et al. \"Your GAN is Secretly an Energy-based Model and You Should use Discriminator Driven Latent Sampling.\" arXiv preprint arXiv:2003.06060 (2020).",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "a straightforward amortization of the discriminator outputs with a limited empirical study",
            "review": "The paper proposes a method for an improvement of generative adversarial models via post-processing its latent variable distribution. To be more precise, the method proposes to train an additional neural network that outputs an important weight for each point of the latent space, thus reweighting the final distribution in the space of images. For the optimization of this network, the authors use the dual form of the Wasserstein distance, where they multiply the initial latent density by the output of the network. To fix the ill-behaved objective, the authors add two regularization terms to it. The proposed objective is then validated on 3 MNIST-like datasets quantitatively and on CelebA qualitatively.\n\nReview:\nMy major concern is the limited theoretical novelty together with modest empirical study. Let me clarify. I think the idea to put the filtering stage into the latent space is indeed worthy. However, the straightforward amortization of the discriminator network via a fully connected network is challenging due to the described computational problems and usually high dimensionality of the latent space. Furthermore, the verification of the method on MNIST-like data does not seem convincing, especially when the relevant works provide a comparison on ImageNet (Azadi 2018, Neklyudov 2019).\n\nAdditional comments:\n1. perhaps, I'm missing something, but for me, it is not clear why the objective in equation (3) corresponds to the optimization of Wasserstein distance in the space of images w.r.t. the parameters alpha and phi. I mean that there are even no guarantees that \\widehat{\\gamma} is a distribution.\n2. \"since the rejection sampling scheme is now tractable, we do not need to implement the MH algorithm or the importance sampling\". Firstly, I do not understand why the rejection sampling is tractable. The regularization term does not provide any guarantees for the maximum value of the density ratio. Secondly, even if the rejection sampling is tractable, I still find the MH algorithm more efficient: it does not require the evaluation of the constant; given the same proposal, MH's acceptance rate is greater or equal to the acceptance rate of the rejection sampling.\n3. the authors claim that reweighting in the latent space allows for better support coverage than the methods operating on the image space. Although I believe that such an effect occurs, I wouldn't expect the quality of images to be high. Indeed, this additional coverage could be produced by sampling from the low-density regions of the latent distribution. It is clear that such regions are underrepresented during the training. Moreover, there is empirical evidence of the deteriorating quality of images for latent distributions with higher variance (see Brock 2018).\n4. the bottom of page 3. DRS does not assure sampling from the target distribution since it adjusts the constant and uses an approximation of density ratio. In contrast, the MH algorithm provides some guarantees by upper bounding the total variation distance between the stationary distribution and the target (see Neklyudov 2019).\n\nminor comments:\n1. abstract. I would suggest finding a better analog for the phrase \"inject disconnectedness\". It does not sound like a desirable feature of your model when we speak about GANs, especially at the beginning of the paper, where few context is given. I would propose something like \"postselection\" or \"filtering\".\n2. eq. 4, the signs of regularization terms are incorrect\n3. typo on page 5, item 2). every methods -> every method\n\nReferences:\n1. (Azadi 2018) Azadi, Samaneh, Catherine Olsson, Trevor Darrell, Ian Goodfellow, and Augustus Odena. \"Discriminator rejection sampling.\" arXiv preprint arXiv:1810.06758 (2018).\n2. (Brock 2018) Brock, Andrew, Jeff Donahue, and Karen Simonyan. \"Large scale gan training for high fidelity natural image synthesis.\" arXiv preprint arXiv:1809.11096 (2018).\n3. (Neklyudov 2019) Neklyudov, Kirill, Evgenii Egorov, and Dmitry P. Vetrov. \"The Implicit Metropolis-Hastings Algorithm.\" In Advances in Neural Information Processing Systems, pp. 13954-13964. 2019.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}