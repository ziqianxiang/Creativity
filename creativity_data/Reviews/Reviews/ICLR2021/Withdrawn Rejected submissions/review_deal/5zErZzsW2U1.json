{
    "Decision": "",
    "Reviews": [
        {
            "title": "Review for Category Disentangled Context: Turning Category-irrelevant Features Into Treasures ",
            "review": "This paper introduces a category disentangled context model to improve image recognition. The method is evaluated on CIFAR and Imagenet. The improvements are clear. I have the following comments:\n\n1. One concern is that the CDC framework introduced more parameters to the original backbone. The complexity analysis is evaluated on ImageNet 32x32, how about the extra FLOPS on full ImageNet? When the network is small, the comparison might be not fair, e.g., the number of extra parameters is 0.35M while the ResNet-32 network contains 0.53M, \n\n2. It seems this paper combines some state-of-the-art modules (e.g., the loss in eq. 2 has been introduced and the Channel Compatibility Module is similar to Jetley et al. 2018) into a unified framework, while the technical contribution is limited. The introduced RL, CC, RU modules look incremental to me.\n\n3. In Table 5, the deeper the network, the better performance CDC obtained. On ResNet-18, the improvement is 1%, while the gain in ResNet-101 is 2.1%. 2.1% gain is significant on ImageNet. What module contributes most to the improvement?\n\n4. From the visualization results, it seems the baseline model is already good at capturing the saliency. Some classes may benefit more from the introduced CDC. The authors may consider analyzing the gains per category and drawing insightful conclusions on when CDC is beneficial (maybe CDC is better at small object recognition?).",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review with comments",
            "review": "This paper proposes a method task advantage of unhelpful contexts that seem to be unessential at training for the image classification task plugged into popular backbones such as ResNet50 and ResNet101. The authors performed extensive experiments to provide evidence of the effectiveness of the proposed method and the experimental results look promising\n\nPros)\n- The idea of utilizing the context information looks sound but needs to include the several related works \n\nCons)\n- The additional computational costs including the number of parameters and FLOPs caused by the appearance of the proposed module are not clearly stated. \n- All the experimental results need to be averaged after multiple training. I mean all the results need averaged accuracies with error bars to convince the readers easily. \n\nComments\n- How can the pretrained backbones that are plugged with the proposed module train on downstream tasks such as object detection? \n- Why the combination of SE or CBAM wit the proposed module degrades the accuracy?\n- The know performances of the baselines of ResNet50 and ResNet101 is about 76.5% and 77.4% accuracies, but the reported accuracies by the authors are quite low. I think this may be a minor issue, but if the authors can find the reasons then the proposed method would give more improved results over the baselines.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good paper but impact is not enough for ICLR",
            "review": "The proposed method uses an auxiliary network to predict category-irrelevant regions from an input image and use it to suppress the corresponding regions of the main CNN’s feature map to make the CNN focus more on category-relevant regions. A conditional AE is employed for the auxiliary network; to be specific, it is trained in an adversarial fashion to prevent a discriminator from predicting the object category while reconstructing the input image as accurately as possible. These ideas seem to be working as expected. So, there is not so critical a question, including the results of the experiments. I don’t see any major flaws in the paper. However, the main result is only that the accuracy for the ImageNet recognition can be improved by 1-2 percentage points; the gain is obtained by combining the proposed method with mediocre baseline CNNs that are not SOTA. This does not seem to have sufficient impact in terms of research and practicality to be accepted to ICLR.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Paper review from AnonReviewer4",
            "review": "Summary:\n\nThe paper proposes an attention method for image classification by considering the category-irrelevant information. Specifically, the authors first pre-train a network to extract the attention map as the category irrelevant cue. Then the paper introduces a few designs (feature channel-wise operations and the residual unit) to obtain a sharper attention map. Finally, the refined attention map can be multiplied with the feature maps to perform image classification. Experiments are conducted on CIFAR and ImageNet benchmark datasets.\n\nPros:\n\nThe idea of using category-irrelevant features or attentions could be interesting for various computer vision tasks.\n\nExperiments show good results on ImageNet compared to other attention-based baselines.\n\nCons:\n\nThe novelty and technical contributions are limited in the proposed method. For example, the CDC network to extract category-irrelevant cues is mostly based on the prior work (Lample et al., 2017) and the standard adversarial learning with a discriminator. In addition, the Channel Compatibility Module to refine the attention map is also similar to that in Jetley et al., 2018. Although experimental results seem promising, the proposed framework is more like an engineering pipeline.\n\nIt is not clear whether the category-irrelevant information could be properly disentangled from the relevant one through the CDC network with the discriminator that tries to predict the category label. For example, to predict the correct object category, the model needs not to see the entire object anyway, or it even needs to use the context information to guide the network. The authors may discuss more on the motivation of using category-irrelevant cues to help image classification, and whether the CDC network can suffice this need (e.g., visualizations in Figure 4 and 5 of the paper do not show good improvement on the attention map).\n\nOn CIFAR datasets (Table 3), the proposed method does not perform well compared to SE and CBAM baselines. Since CIFAR datasets contain the object in the center of the image, which is an easier case for localizing objects using the attention mechanism, the authors should discuss more on why the proposed attention-based method does not work well.\n\nOverall, the paper presents a framework to achieve good performance for image classification, but the main contributions are not clear, as well as the lack of novelty and explanations on how the category-irrelevant cues could be successfully extracted to improve model training.\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}