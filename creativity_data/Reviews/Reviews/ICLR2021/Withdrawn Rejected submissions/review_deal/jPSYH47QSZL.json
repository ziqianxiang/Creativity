{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes an unsupervised pretraining approach for 3D recognition, which is based on point cloud completion. The initial review receives a mixed rating, with two reviewers rate the paper below the bar and two above the bar. After the rebuttal, R3 changes the opinion from above the bar to a rejection recommendation. While several reviewers recognize the simplicity of the proposed method, R2 and R4 consider the proposed method a straightforward extension of known approaches for NLP and vision tasks. A lack of novelty was also pointed out as a weakness by R3 and R4. After consolidating the reviews and the rebuttal, the AC finds the weakness claims convincing and determines the paper is not ready for publication in the current form. "
    },
    "Reviews": [
        {
            "title": "Since the idea itself is simple enough, the reviewer would not argue too much about the technical contribution of this paper, but concerns more about the analytic contributions. The reviewer’s concerns lie as follows.",
            "review": "The idea of this paper is simple but fascinating. Actually there are many studies concerning the task of point cloud completion, but using it as the initialization approach to improve the other tasks is quiet novel. The experimental results seem solid and quantitatively prove the effectiveness of the OcCo-initialization.\n\nSince the idea itself is simple enough, the reviewer would not argue too much about the technical contribution of this paper, but concerns more about the analytic contributions. The reviewer’s concerns are as follows.\n1. In addition to verify the effectiveness of OcCo-initialization, more analysis on why this simple idea can take effect should also be given. For example, the author should go deeper to explain why OcCo-initialized PointNet can outperform the random initialized PointNet (e.g. by visualizing the learned features of the two kinds of PointNet, like Figure 3).\n2. The idea of OcCo-initialization can be concluded as some kind of task oriented initialization approach. Considering the simplicity of this idea, similar initialization strategy can be formulated, such as pre-training network on segmentation task and apply them on classification task. So why the author only chooses the completion task as the initialization strategy, or if task oriented initialization can be considered as a universal strategy in point cloud processing?\n3. Although the experimental results look solid, the reviewer still concerns if the proposed OcCo-initialization can achieve the SOTA results or close enough to the current SOTA. For example, PointCNN can achieve much better segmentation results compared to the methods in Table 3. So if the OcCo-initialization can still succeed in the PointCNN which has better ability of learning point cloud features?\n4. The author is advised to clarify the necessity of Sec 2.1, which is the main part of the model description. In reviewer’s opinion, a method to generate partial point cloud from single view is essentially not a technical contribution for this paper.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Limited novelty and weak improvements",
            "review": "The authors propose completing an occluded point cloud as a pretraining step for point cloud processing methods. Multiple occlusions are generated for the network to complete by simulating a camera perspective. \n\nPros: \n- First work analyzing this specific pretraining for point clouds\n\nCons:\n- Weak novelty\n- Limited experimental reliability\n\nOverall, the novelty of the paper seems rather weak. The only novel contribution is the idea of point cloud completion as a pretraining task. This idea is rather simple and similar techniques are well known and used in other fields such as NLP. Hence, it does not represent a significant methodological advancement.\nNevertheless, the paper would still be interesting if it showed extraordinary results in this particular field of application. Unfortunately, the experimental results seem weak as well. They show modest gains with respect to existing techniques and they lack any information on run-to-run variance. This makes it impossible to understand if the gains that are shown are statistically significant or just lucky runs with careful parameter tuning. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "paper shows promising results using point cloud completion tasks for pre-training representations, method is clearly described; however, highly related work not discussed that limits novelty of the proposed OcCo task, experimental setup not fully clear, making it hard to understand the results",
            "review": "The paper considers the problem of training networks for point cloud processing through a point cloud completion task. Given a point cloud, it is rendered from a set of viewpoints and for each viewpoint the set of visible points is determine. A network is then trained to generate the full point cloud from the partially observed point cloud for a given view. Here, an encoder-decoder architecture is used, where the encoder corresponds to the network that should be pre-trained. Experimental results show that the proposed method outperforms two baselines for three tasks (object classification, object part segmentation, and semantic segmentation), when using less training data, and that the pre-training on the occlusion task leads to faster convergence.\n\nOn the positive side, the occlusion completion (OcCo) task is clearly described and it should be fairly straightforward for a researcher to setup this task. The task requires no human annotation and is thus suitable for pre-training from large datasets captured in uncontrolled settings. The experiments cover a wide range of tasks and settings and show that the OcCo pre-training strategy outperforms random initialization and the approach from Saunders & Sievers. Here, the simplicity of the OcCo task coupled with its performance is clearly a major strength of the paper. In particular, Fig. 4 shows that the networks pre-trained on the OcCo task tend to converge much faster compared to the baselines.\n\nOn the negative side, I feel that the paper oversells the novelty of the OcCo task. The OcCo task is a variation of the (semantic) scene completion task that asks to complete a partial observation of a scene / object and is receiving attention in the computer vision community. Recent examples include [Dai et al.,  SG-NN: Sparse Generative Neural Networks for Self-Supervised Scene Completion of RGB-D Scans, CVPR 2020] and [Hou et al., RevealNet: Seeing Behind Objects in RGB-D Scans, CVPR 2020], with older works including [Firman et al., Structured prediction of unobserved voxels from a single depth image, CVPR 2016]. [Schönberger et al., Semantic Visual Localization, CVPR 2018] use (semantic) scene completion as a proxy task to train a 3D descriptors for 3D-3D matching between models. Given a voxelized partial observation of a scene, they train an encoder-decoder architecture to predict the complete volume (potentially also predicting semantic labels for each voxel). The embedding in the latent space are then used as 3D descriptors (i.e., the decoder part of the network is not needed at test time). In other words, they use the OcCo task for training their networks. They show that the learned representation generalizes between datasets and sensor modalities (training on 3D data obtained from stereo images, tested on LiDAR data). Given this result, I see limited novelty in using the OcCo task for pre-training point cloud networks and it does not seem very surprising that pre-training on the OcCo task should result in meaningful representations.\n\nMy second main point of criticism is the level of detail of the experimental evaluation. While the experiments cover a wide range of tasks and settings, I feel that crucial information needed to understand the results are missing:\n1) Is the same dataset (ModelNet40) used to pre-train on the OcCo task also used to pre-train the JigSaw approach from Sauder & Sievers? Unfortunately, no details on the latter are provided in the main paper (or I was not able to find them), making it hard to understand how meaningful the comparison is.\n2) There are no details on how the networks are trained for the different tasks, e.g., for how many epochs are the network trained for the task at hand?, do the networks converge for all pre-training strategies?\n3) How significant are the improvements over the two baselines. For most considered settings, the improvements seem rather small, e.g., often less than 1 point compared to the Rand baseline in Tab. 2 and 3. Is this a meaningful improvment? Or would simply using a different random seed for training explain such a difference? Given that the paper claims that \"These results demonstrate that the OcCo-initialized models have strong transfer capabilities on out-of-domain datasets\" and that \"OcCo-initialized models achieve superior results compared to the randomly-initialized models\", this is an important question to answer.\nI think there is enough space in the paper to include this information. Specifically, I do not think that Alg. 1 is necessary in the main paper (but would be good to have as an appendix) as the text and Fig. 1 already describe the approach in sufficient detail. Similarly, the z-Buffer algorithm is a classic computer graphics technique that is covered in basic lectures and does not need to be discussed in detail (e.g., see [Pittaluga et al., Revealing Scenes by Inverting Structure from Motion Reconstructions, CVPR 2019] briefly mentioning z-Buffering and the use of Delaunay triangulation for determining visibility). I think this space could be spend on providing more details.\n\nIn the current form, I do not think the paper is ready for publication as the paper, in my opinion, overclaims its contributions, misses relevant work (see also below), and misses crucial details necessary to understand the experimental results. As such, I am currently recommending to reject the paper. I believe that these issues can be addressed, but I would base my final recommendation based on the authors' feedback.\n\nHere are additional detailed comments:\n* In Sec. 2.1, I do not understand the comment \"Our goal is to learn a randomized occlusion mapping o : P → P (where P is the space of all point clouds) from a full point cloud P to an occluded point cloud P\". As far as I can tell, the mapping is not learned but follows a fixed pipeline.\n* I don't understand how Eq. 2 \"most closely approximates the inverse of eq. (1)\". Eq. 2 is the inverse of Eq. 1. The only approximation that I could see if the 2D projection coordinates are rounded to the nearest integer.\n* The introduction teases with the statement \"Current 3D sensing modalities (i.e., 3D scanners, stereo cameras, lidars) have enabled the creation of large repositories of point cloud data (Rusu & Cousins, 2011; Hackel et al., 2017).\" However, only synthetic data is used for pre-training, which is a bit disappointing. I am not convinced that the synthetic datasets \"are qualitatively similar to point clouds in datasets where points are collected via 3D imaging devices such as handheld scanners (Dai et al., 2017a; Armeni et al., 2016) and lidar (Geiger et al., 2012).\" Based on my experience, handheld scanners (RGB-D cameras or (multi-view) stereo cameras) produce much more noisy measurements with outliers while lidar sensors, especially for autonomous vehicles, typically produce sparser point clouds.\n* Sec. 3.2 states that \"We observe that, in early stage the encoder is able to learn low-level geometric primitives, i.e., planes, cylinders and cones, while later the network recognises more complex shapes like wings, leafs and upper bodies (non-rigid).\" I am not sure how I see this in Fig. 3 since I don't know what the color-coding signifies.\n* Looking at Fig. 3, I am not sure whether the statement that \"clearly separable clusters are formed for different object classes\" is true. There seems to be quite some overlap between classes, but this is also a bit hard to tell given the small size of the figure.\n* [Yang et al., PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows, ICCV 2019] and [Gadelha et al., Label-Efficient Learning on Point Clouds using Approximate Convex Decompositions, ECCV 2020]  both propose generative models for point clouds. Both of them show that they can be used for unsupervised representation learning and they show competitive results for the task of only training an SVM classifier on top of the learned representation for ModelNet. Both should be discussed in the related work.\n\n### After rebuttal phase ###\nThe comments by the authors and the revised version of the paper successfully address my concerns. I thus recommend to accept the paper.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A good one",
            "review": "This paper proposes a better pre-trained prior for a variety of downstream applications in point cloud analysis. The workflow of the pre-training mechanism is to first 1) generate occluded points that result from view occlusion and then 2) optimize the encoder to learn how to complete the occluded points from the partial point cloud. In downstream applications, the obtained encoder will be used as the initial weights in the network training. Empirical experiments have shown that such a pre-train mechanism can improve initialization over prior baselines and benefit a variety of tasks even with a large domain gap.\n\nPros:\n1. The experimental results have shown a steady improvement in performance by using the proposed pre-training approach in different encoder architectures and different downstream applications. That provides strong support for validating the effectiveness of the proposed approach.\n2. I also like the result that the initialization is only pre-trained on the occlusions generated from the ModelNet40 but still work in another dataset. And yet, the pre-training is done in a self-supervised manner. This is a great plus for this approach as it indicates that it could be a general-purpose booster for a wide range of applications without spending too much effort in collecting special-purpose dataset for pre-training. \n3. The paper is well written and presented.\n\nCons:\n1. The improvement, as shown in the statistics, is very incremental in most cases. I understand it is difficult to achieve better results on well-established benchmarks, but it somehow indicates the improvement is limited.\n2. Though the paper already stated some nice explanation of the idea behind this approach, I would appreciate it if a more in-depth analysis of why such a pre-training mechanism could work is provided. Specifically, I would like more analysis of why such a pre-training method can adapt to different datasets? What are the common features that OcCo captures across different datasets? \nSome visualization similar to Figure 3 would be helpful.\n\n---- Final Rating ----\n\nThe authors' response has resolved my concerns. I would keep my positive rating.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}