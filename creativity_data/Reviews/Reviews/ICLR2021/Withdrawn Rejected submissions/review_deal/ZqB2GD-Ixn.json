{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper deals with domain generalization with causal modeling. Specifically, it considers a broader class of distribution shifts, arising from the system intervention perspective, and proposes some robust learning principle to achieve domain generalization. The paper is well written and has some interesting ideas. However, as pointed by Reviewers #1 and #4, the exact problem setting should be made more explicit, the theory and algorithm should be more consistent, and some very relevant contributions in the literature should be discussed or compared with. "
    },
    "Reviews": [
        {
            "title": "Accounting for Unobserved Confounding in Domain Generalization",
            "review": "Summary: This paper proposes a new regularizer that can be plugged in gradient-based learning algorithms, which aims at solving the problems induced by unobserved confounders. And the authors provide the upper bound for one specific kind of distributionally robust optimization problem, whose uncertainty set is defined as the affine combinations of training distributions. And based on this the algorithm is proposed to deal with the problem of unobserved confounders. Experiments on three medical datasets validate the effectiveness of the method. \n\nStrengths: \n1.\tThe authors provide the upper bound of a group-DRO-like problem whose uncertainty set is the affine combination of training environments. \n2.\tThe authors provide the moment conditions for each pair of environments under linear settings with unobserved confounders and show that the gradients should not be forced to be zero. \n3.\tThree medical experiments validate the effectiveness of the proposed method. \n\n\nWeaknesses:\nIn spite of the strengths mentioned above, there are a few questions that are confusing. \n1.\tAs for the simulated experiment: What is the purpose of the third figure in Figure 1? It shows that the perfect causal model performs bad under unobserved, while the other three methods performs almost the same. Further, the performance of the proposed DIRM and DRO is quite similar in this setting, which does not account for the effectiveness of the method. Besides, the result of IRM for this experiment is missed. \n2.\tAs for the theoretical analysis: \na)\tFor Theorem 1, the right hand equation uses L_2 norm of a function of beta. I read the prove and I think this norm is defined as an integral which has nothing do with beta any more. Therefore, I wonder what does the regularizer proposed in equation(6) means since beta has already been integrated. \nb)\tFor Theorem 1, the core assumption is ‘the expected loss function as a function of beta belongs to a Sobolev space’, which is confusing. Could you provide some explanations of this assumption or give some examples of it?\nc)\tTheorem 1 provides an upper bound for one specific kind of DRO problem whose uncertainty set is formulated as an affine combination of training distributions. However, in this article, the authors do not state what is the definition of the invariance here and why solve such DRO problem could achieve the invariance. \n3.\tAs for the proposed objective function:\na)\tAs mentioned above, the L_2 norm is taken over a function of beta, which I think is not the Euclidean norm of the vector. Beta has already been integrated and this regularizer has nothing do with beta. I wonder how to compute this when optimizing?\nb)\tI wonder how this objective function can be optimized efficiently? The first concern is mentioned above as the computation of L_2 norm. The second concern is how to optimize the variance which is non-convex and hard to optimize. Namkoong et al. [1] convert the optimization of a variance-regularized problem to a f-divergence DRO for better optimization, while in this paper the authors take the opposite way. I wonder is there any theoretical guarantee of the optimization of the objective function(6). \n4.\tAs for the experiments:\na)\tThe experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, since the performance is similar to IRM, which I wonder if it is caused by the problems mentioned above(in 3).\n\n[1] Duchi, J. , & Namkoong, H. . (2016). Variance-based regularization with convex objectives.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Excellent paper with a few clarity issues",
            "review": "--- Update after discussion ---\n\nAfter looking at the concerns raised by the other reviewers and the author responses, I have the following comments:\n\n1. I think the that authors have more than adequately addressed the concerns raised by reviewer 4. With that said, I agree with reviewer 4 in that the link between theorem 1 and the proposed objective and its approximation is not made sufficiently clear in the text. \n\n2. I whole-heartedly agree with reviewer 1 that a clear and concise list of the assumptions made would improve the paper.\n\nOverall, however, I think the paper should still be accepted and will keep my original rating.\n\n--- Original review ---\n\nOverall, I found this to be an excellent paper. The topic of generalizing to new environments is clearly important and the authors do a good job motivating this problem. I found the paper well written and clear, with many intuitive examples. I found the method compelling and the theory appears correct. The experiments were well designed and convincing. Insofar as I have concerns with the paper, they relate to clearly communicating the specific setting considered by the authors and contrasting their work with others (details below).\n\n--- Comments --- \n\n1. One piece that was unclear to me was why if was necessary to assume that $\\mathbb{F}$ remains fixed. Shifts in $\\mathbb{F}$ are certainly possible in real applications (e.g., consider a change in a treatment policy relating observed lab measurements to observed treatments at a particular hospital). Is this a constraint on the method? That is, if the observed environments contain shifts in $\\mathbb{F}$, would the proposed method fail to produce a model that is robust to those shifts?\n\n2. More generally, I didn't think the assumptions were clearly communicated. I think paragraph 2 of A.3.1 should probably be moved into the main paper.\n\n3. I found the example in the intro a bit unclear. I would try to communicate earlier what you are hoping to show with the example. Additionally, at this point in the paper, it is not really clear what a \"causal solution\" is or how it differs from the proposed solution. \n\n4. I thought the remarks following Equation (5) were very helpful and would recommend adding a similar high-level discussion after Theorem 1. Something like: The first term on the RHS is the expected loss and the second term is zero if the constraints discussed above are satisfied, thus by minimizing the constrained expected loss, we are minimizing an upper bound on the LHS.\n\n5. By the time I got to Equation (6) I found myself wondering why *this* robust objective is better than all the others. This was then addressed, in part, by the last parts of 3.1 and 3.3, but I would consider including a more explicit contrast between these various objectives earlier in the paper. I think something like Section 2 of Kreuger et al. (2020) would help contextualize your contribution a bit better.\n\n6. Links to Equation (9) should be swapped for Equation (1) (e.g., page 1, par 2).\n\n7. I would recommend swapping $\\alpha$ for another symbol since $\\alpha_e$ is also used.",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "tackle the unobserved confounding to address cross-domain generalization",
            "review": "summary:\nThis paper proposes a new domain generalization (DG) method, which enjoys certain statistical invariance property in the presence of unobserved confounders. The method is motivated by causal understanding of the underlying generating distribution and it assumes that the distribution generating the unseen data is obtained by manipulating the distribution of exogenous variables in the causal model.\n\n\npros:\n- this work views the distribution family of training data as generated from manipulating a causal model $M$, which is novel in DG methods and of pracitical significance.\n\n- the idea is well motivated (section 2) and clearly presented (section 3)\n\n- related works are properly mentioned and discussed\n\n\ncons:\n- the considered distribution family seems a bit restrictive as it requires manipulation only on exogeneous variables in additive structural equations.\n\n- the algorithm is not available in both the main text and appendix.\n\n- the proposed DG method is not empirically studied on widely used benchmark data sets. \n\n\ndetailed comments:\n- It seems the method can only handle confounder of two variables with an additive structureal euqation relating them. If that is the case, it would be better to elaborate corresponding requirements in numbered assumptions.\n\n- The derivation of the last inequality in the proof of theorem 1 is not very straightforward. It would be better to elaborate its derivation in the appendix.\n\n- Since the analysis throughout the main text assumes a given $\\phi(x)$ but one has to learn both $f$ and $\\phi$ in practice, it would be better to give the algorithm used in experimental section in the main text.\n\n- Experiments on popular DG data sets (e.g., VLCS) are missing in this work. It would be better to show the performance of the proposed method on benchmark data set. If possible, it would  be great to also consider comparing with REx [1].\n\nminor:\n- typo under Eq. (5), *indeces*\n\n[1] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Remi Le Priol, and Aaron Courville. Out",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A new objective for out-of-sample generalization via causal invariances.",
            "review": "The authors propose an optimization objective for out-of-sample generalization that aims to exploit statistical structure that emerges from underlying causal mechanisms and is hence transferable across domains. Effectiveness of the approach is demonstrated on several real-world datasets.\nThe problem is thoroughly motivated and relevant literature reviewed. Experiments support the authors claims, although real-world examples seems somewhat contrived.\nThe paper lacks an investigation of where and how the proposed methodology fails. It would have been helpful to provide more intuition around the formal explanations in section 2 and 3.\n\n\n## Detailed Comments\n- \"new or related data\" -> what does \"related data\" mean?\n- \"Doing so is difficult however, some form of uncertainty about the distribution of new data is unavoidable.\" -> Please check grammar\n- (eq1): why are we taking the *supremum* of the expected loss over distributions?\n- \"to problem (9)\" -> I think you mean (1). Prolly the eqs (1) and (9) have the same latex equation label.\n- acronym DRO is not defined in text (only in figure caption)\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}