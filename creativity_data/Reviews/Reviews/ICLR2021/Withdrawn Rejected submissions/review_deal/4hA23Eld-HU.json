{
    "Decision": "",
    "Reviews": [
        {
            "title": "Recommendation to Reject",
            "review": "This manuscript applies the ellipsoid method to online LQR in order to achieve low regret. Online LQR has garnered a lot of interest in the last couple of years. Although tight bounds on regret are understood now, new approaches can bring significant gains in practice. \n\nUnfortunately, because of several critical issues, I have to recommend this manuscript to be rejected. \n\nPros:\n- proposing a new approach (which is classical in convex optimization) to tackling online LQR. \n\nCons: \n- the assumption that the A + BK has operator norm smaller than one is too stringent to make it interesting for control. I know that the first works looking at learning for LQR made this assumption, but recent results removed this assumption. \n\n- the authors show that the regret is O(T) worst case. Unfortunately, a regret bound that is linear in the horizon is not meaningful. Any stabilizing controller would achieve a regret bound that is linear in the horizon. There is no need to find a \"good\" controller. \n\n- The submission should be proof-read for English style and grammar issues.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "An ellipsoidal approach to adaptive control of linear systems; but the results and the presentation are premature",
            "review": "**General overview:**\nThe paper studies fully observable stochastic linear systems with unknown state dynamics (but known input dynamics) and bounded noises. The goal is to drive the system to a small neighborhood of a target state, which is assumed to be the zero vector. The paper applies a standard quadratic loss function and proposes an iterative method which recursively updates an ellipsoid based on a \"separation oracle\". Based on these ellipsoids, the linear controller at time t is defined by the center of the ellipsoid for time t. Theorems are also presented for upper bounding the number of time the \"separation oracle\" should be activated before the desired accuracy is reached; as well as giving a regret bound in case we have a predefined fixed running time.\n\n**Pros:**\n- The addressed problem is interesting and such adaptive approaches are worth the investigation.\n- The algorithm is precisely described and the paper is relatively well-written (apart from the issues listed below).\n- Theoretical results are presented about the worst-case number of steps needed to achieve a certain precision and also for the regret of the method, in case the number of steps are fixed.\n\n**Cons:**\n- The paper lacks a motivating example. At least one specific practical example should be given which can be formulated in this framework (namely: linear dynamics, full observability, known B matrix, known radius R, bounded noises with known bound, etc.) \n- It is not clear, how should one know matrix B and the bound on the noise, epsilon, in practice?\n- In (4) the authors refer to the optimal LQR controller which could be achieved, if we knew the state transition matrix. It would be good to actually define such a controller in the paper. In the classical case, we need additional assumptions (for example: the noises are i.i.d., zero mean and have finite second moments) to define the optimal controller via the Riccati equation. Do we need such assumptions to define the regret (4)?\n- The problem of learning the controller on the fly is addressed in the field of *adaptive control*. In this field adaptive LQR approaches are also studied. The paper should discuss adaptive control approaches of linear systems and compare the efficiency of the suggested method to state-of-the-art adaptive control algorithms.\n- Set membership type system identification methods also seem to be closely related to the suggested method, but they are not mentioned.\n- Assumption 2 is obscurely stated, a formal definition is needed. The current formulation is also misleading, as it starts with the phrase \"there exists K\" giving the impression that there is a universal K.\n- As matrix A is assumed to be unknown, this assumption is quite hard to verify in practice (apart from special cases).\n- Also, how should one choose R in practice to ensure that the feasible set is contained in a ball with radius R? It seems that one should know the dynamics, in order to properly choose R.\n- It is a bit strange that the controllability of the system is not assumed. Does it somehow follow from Assumption 2? If so, this should be noted.\n- Rather than just formally describing the method, an informal description would also be good, for example, interpreting the ellipsoids computed by the algorithm and explaining the ideas behind this particular construction.\n- The method is not implemented and no experimental results are shown (though there would still be space for them). Experiments about comparing the proposed algorithm to, for example, the optimal LQR regulator (assuming the system was know) and relevant adaptive control methods, would be crucial.\n- The paper does not have a conclusion/summary part, either.\n\n**Summary and recommendation:**\nTherefore, though the paper addresses an interesting problem, suggests an algorithm with theoretical guarantees, the current version of the paper has several shortcomings based on which it should not be accepted.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting paper but the results are not good enough",
            "review": "1. Paper's contribution summary\n    This paper is about online control for unknown linear time-invariant system. It proposes an Ellipsoid method based algorithm to enable learning the linear control parameter directly online without training phases or sub-optimal policies as initial input. It's also different from previous online control algorithms which usually include either system identification or value function estimation. By using Ellipsoid method, the total number of needed online linear constraints are upper bounded to ensure that the converged state to be around the desired state under bounded random noise in state space equation. \n\n2. Strong and weak points of the paper\n    1) Strong points: \n        Instead of doing system identification or value function evaluation for online control to unknown linear system, this paper uses Ellipsoid method to collapse the linear control parameter domain space every time when the defined ellipsoid inequality is violated, which is very interesting and new in online control area. This method also doesn't need initial sub-optimal policy to stabilize the system or training phases. It also proves that the total number of needed online linear constraints are upper bounded to ensure that the converged state to be around the desired state under bounded random noise in state space equation. \n\n    2) Weak points:\n        Although the method used in this paper is interesting and new to online control to the best of my knowledge, the obtained performance guarantee is not better or even close to the previous methods'. More specifically, the obtained regret guarantee w.r.t. the best linear controller is O(\\epsilon T), which is linear only when the bounded noise \\epsilon is T dependent like O(c/\\sqrt{T}), while it's proven to be O(\\sqrt{T}) or even O(\\log T) from prior works' results under the same setting, such as 'Improper Learning for Non-Stochastic Control' and 'Logarithmic Regret Bound in Partially Observable Linear Dynamical Systems'. Also, the latter one doesn't need an initial pre-stabilizing sub-optimal policy like this paper.\n\n3. My recommendation\n    Although I really like the idea of applying Ellipsoid method to online control, I would not recommend accepting this paper due to the (basically) linear order of horizon T in regret guarantee. \n\n4. Supporting arguments for my recommendation \n    Please see my comments in the 'weak points' part.\n\n5. Question\n    The only issue that bothers me from giving it a higher score is the regret guarantee this paper's propose method can achieve. Right now, it's of order O(\\epsilon T). And it can only be sub-linear when the noise magnitude is T dependent. Since the T dependent noise magnitude is really restrictive and not useful in practice, can the author/s provide any insight into this regret guarantee result?\n\n6. Other feedbacks\n    There are a few typos in the paper: the last sentence before Section 3; I guess the Eq.(24) refers to the equation above the current one. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Recommendation to Reject",
            "review": "This paper propose a novel online learning algorithm that does not require knowledge about initial policy and does not learn system parameters. The work is based both on reinforcement learning methods en control learning.\n\n strong points:\n- the paper is well organized\n- the new algorithm presented is clearly stated\n\nweak points:\n- Some notations are not clear and deserve more explanations. For example, the regret's definition involves k* which is defined based on K* which is defined with a limit when T tends to infinity. What does that mean ? Regret at time t is usually defined against the best policy up to time t. Here the limit is confusing, it deserves explanation on its meaning and how to compute it.\n\n- I do not understand Assumption2, what does \"placed arbitrarily\" mean?\n\n- I did not find converge results, although they are claimed in the abstract.\n\n- The last two sentences  of the paper are also confusing. Obtaining a linear regret is not a good result, that is also what a random algorithm obtains. Obtaining a constant regret is too beautiful, I'll be glad to believe it but it would need discussions on how such a result could be obtain.\n\n- I do not believe in the constant regret. Following the proof of theorem 3.3, t_c is independent of T. However t_c is dependent on epsilon, so epsilon can not depend on T, epsilon= 1/sqrt(T) is not possible without adding a term to the regret, that will not be constant.\n\n\nAdditional feedback \n- It would be interesting to illustrate the results with experiments on real or synthetic data, or to provide example of potential real life applications.",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}