{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper experimentally observes the negative transfer in Multi-task Graph Representation Learning and proposes to solve the negative transfer with a novel Meta-Learning based training procedure. However, the proposed methods seems not technically sound. There are some concerns about this paper：1. The technique contribution of this paper is limited. The method proposed in this paper is just an application of MAML in Graph Representation Learning with a little variation. 2. This paper only compares SAME with the vanilla MTL method, which adopts the uniform weights. However, the vanilla MTL method commonly performs poorly. The state-of-the-art MTL methods should be taken into comparison, for example MGDA [1]. 3. The traditional Meta-Learning framework introduced in Algorithm 4 is misleading.  4. The experimental analysis of this paper is not sufficient. For example, the paper has not analyzed whether the improvement comes from the meta updating or comes from the singularly training strategy.\n\n[1]. Sener, Ozan, and Vladlen Koltun. \"Multi-task learning as multi-objective optimization.\" NIPS 2018.\n\n"
    },
    "Reviews": [
        {
            "title": " interesting  problem ",
            "review": "The manuscript proposes SAME, a model based on GNN and meta-learning for learning multi-task node embeddings. Unlike multi-task learning setting, SAME aims at learning to quickly adapt to multiple tasks. Two model variants iSAME and eSAME are proposed base on different settings in inner/outer loop of parameter update. Experiments on several datasets demonstrate the good performance of SAME. \n\nPros\n1. The problem is new and interesting. It is the first work to study single set of node embeddings for multi-tasks in graph. \n2. The presentation is overall good. The content is clear for me. \n3. Introduce a new model for learning multi-task node embeddings through meta-learning way. The model is simple yet interesting for new problem. \n\nCons/Questions\n1. The novelty of this work incremental. Despite the new problem and different task settings, the model framework adopts the similar procedure as general meta-learning procedure. The model is quite simple. I would like to see more discussion about the contribution and novelty of this work as well as the potential future study. \n\n2. This work follows the meta-learning setting. Besides studying different graph learning tasks, it is better to provide content and add experiment for the scenario of few-shot labeled data. If I did not miss it, there is no discussion and experiment about this. I would suggest the authors to add comparison experiments for different tasks where only few-shot supervised data are available. \n\n3. Reference format is not consistent, typos, etc. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Direct extension of MAML",
            "review": "This paper formulates the learning of three tasks, including graph classification, node classification and link prediction, as a multi-task learning problem and adopts a meta learning approach to learn the three tasks together in the spirit of the Model-Agnostic Meta Learning (MAML) method.\n\nActually, there have been some works to study the three tasks (i.e., graph classification, node classification and link prediction) as a multi-task learning problem. Authors need to discuss differences with those works and compare with them in experiments.\n\nThe proposed meta learning approach seems a direct application of the MAML method. I cannot see much difference with the MAML method.\n\nIn the meta-objective, how to set different \\lambda’s? This is more important to the performance.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Graph Representation Multi-Task Learning.",
            "review": "This paper presents a multi-task framework to represent the node embedding for transferred knowledge. The methodology is based on the meta-learning, which is capable of producing multi-task node embedding. This paper is well-motivated and well-written. The experimental results illustrate the effectiveness of the model. I would like to recommend to accept this paper.\n\nMajor Concerns:\n1. The related work can be strengthened. In the current version, the related work seems to stack all the papers in sequence, which makes it tough to understand the development of this task. I suggest the authors to reformate this subsection to Mind Graph.\n2. Can you introduce the dataset more specifically?\n3. There shall be more baselines for the experiments.\n\nMinor Concern:\n1. Fig.1: the legend shall be outside the box.\n2. Sec 3 seems redundant to most related readers. ",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}