{
    "Decision": "",
    "Reviews": [
        {
            "title": "More clarity and explanations needed on methods and experiments",
            "review": "This paper studies the problem to derive sparse paths in a neural network for a specific input. The authors first show that existing methods may end up choosing paths containing “dead neurons”, i.e., those that are not activated in the original neural networks, which is undesirable. Then they propose to select paths based on neural contribution. They measure neuron contribution with two measures: the marginal contribution taylor, and the integrated gradient. The sparse paths are then constructed by selecting neurons with contribution measures larger than a threshold $c_{\\kappa}$. The authors conduct a series of analysis on the selected paths, and show how the selected paths can help interpretation of the model by input feature attributions etc. \n\nStrengths:\n- Selecting sparse paths in neural networks is an interesting topic in neural network interpretability\n- The explanations and experiments showing existing methods could select dead neurons are insightful\n- The proposed methods enjoy relative simplicity compared with other existing methods. \n\nWeakness:\n- The connection between some parts of the paper and the claim is not completely clear, e.g., the greedy algorithm, the local linearity etc.\n- Feature attribution experiments may need more explanations, especially on comparisons between the propose methods and GradCAM\n\nThe research problem studied in this paper is an important problem in understanding neural network response of a specific input. The authors point out a drawback of existing studies, where the selected paths can contain originally non-activated neurons. They show the percentages of dead neurons in some baselines in Figure 1. I think the motivation is quite insightful. The authors also present a greedy algorithm which they claim to be optimizing Eq. (1). I find this example less convincing and may be redundant given that Figure 1 already shows some real examples. \n\nThe proposed methodology is to measure neuron contributions to the final response and select the paths accordingly. The proposed neuron contribution measures guarantee that “dead neurons” would always have a contribution value of 0. Hence, using a thresholding method to select neurons can make sure dead neurons will not be included in the selected paths. In Section 3.1 the authors also present Proposition 5: the approximate model based on the selected path by the proposed methods will be locally linear. However, it is not completely clear why this property is unique to the proposed method. My question to the authors here is whether they can provide some explanation on why other path selection methods that are similarly performed on a network with piecewise linear activation functions will not yield a locally linear approximate model? If so, then how is Section 3.1 connected to other sections?\n\nI also have some concerns about the experiments, particularly in Figure 6. It seems that in all experiments GradCAM has similar performance with the proposed methods. However, the authors only mentioned that NeuronMCT and NeuronIntGrad are better than their input counterparts, but provided little explanation on comparison between the proposed methods and other strong baselines like GradCAM. \n\nGenerally, I think that the authors can work more on the clarity of the paper, especially in Section 3 to better support their claims. Some more explanations on how the experiments support the claims can help better understanding of the advantages of the proposed methods. I lean to reject this paper.\n\n\n\nMinor concerns and questions:\n- In Section 2.3 the authors mentioned that the comparison is network-wise instead of layer-wise. Did you try layer-wise and how did it perform compared to network-wise? Why is it worse (or better)?\n- GradCAM paper seems not cited despite being used as a baseline.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Reviews",
            "review": "Summary\n- The authors investigate the critical paths founded by previous works encompassing dead neurons which do not contribute to the final prediction. The newly identified paths can include critical segments of input, and having stable gradients. The authors evaluate the method on several benchmarks\n\nPros\n- The analysis is insightful and inspiring. The dead neuron phenomenon in critical paths is neglected in previous works, and it is important to discuss these issues profoundly for explaining and understanding neural networks\n- The proof of local linearity of critical paths is novel and can be beneficial for further works\n\nCons\n- Currently, attribution methods comparison is only evaluated based on human observation. To more rigorously compare the attribution results, I encourage the authors to conduct weakly supervised object localization and other quantitative experiments, similar in [1][2]\n- A major part of CDRP is used for analyzing and detecting adversarial example [3]. However, there are  no discussions on this topic in this paper, which makes current interpretation technique lack of practical application. I encourage the authors to report the performance of the proposed method on adversarial example detection.\n\n[1] Dabkowski, P., & Gal, Y. (2017). Real time image saliency for black box classifiers. In Advances in Neural Information Processing Systems (pp. 6967-6976).\n\n[2] Zhang, J., Bargal, S. A., Lin, Z., Brandt, J., Shen, X., & Sclaroff, S. (2018). Top-down neural attention by excitation backprop. International Journal of Computer Vision, 126(10), 1084-1102.\n\n[3] Wang, Y., Su, H., Zhang, B., & Hu, X. (2018). Interpret neural networks by identifying critical data routing paths. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 8906-8914).",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Results sound intriguing, but work lacks sufficient clarity to be evaluated",
            "review": "The authors examine “critical paths” in sparse, rectified deep networks. They develop an algorithm to establish that solutions to the pruning objective can include neurons that were once inactive (i.e. “dead”) and therefore not in fact a critical path, as well as examine other algorithms for this objective and arrive at the same conclusion. They introduce a path selection method based on evaluating individual neural contributions that does not produce the same, undesired results, and use the paths identified by this method to examine the relationship between the responses in the network and the network inputs.\n\nCollectively, the submission, to this reader, did not cross a critical, minimal clarity threshold required to assess the basics of its quality, and for that reason cannot be suggested for acceptance. I admit that I am not an expert in the principle focus of the submission. However, a minimal threshold for acceptance must be whether or not the work can be more-or-less understood in a timely manner by a general member of the machine learning community without undo and excessive additional reading (e.g. extensive reading into cited work) and guess-work into the stated approaches, and on that measure, this submission is insufficient. \n\nInsofar as I was able to assess other metrics, such as significance, (which all depend on clarity) the work appears to investigate a subject of sufficient significance that the authors’ work would probably be of interest to the rest of the community. I would be pleased to consider a re-submission with drastic improvements to the clarity of presentation, both in the details of the approach and the general motivation of the work, including a clear and concise statement of the shortcomings in the field the approach seeks to remedy. \n\nTo illustrate that this is not merely due to a lack of familiarity with the research questions, or for a lack of effort in attempting to understand the submission, I have outlined several of these shortcomings. This is not an exhaustive list, nor should it be the job of a reviewer to enumerate such a list when the authors have failed to meet a minimal clarity threshold. \n\n- Motivation: I was able to understand that the author’s greedy algorithm can identify what they call “undesirable paths”. But the authors fail to motivate why they are undesirable? What makes them undesirable? They state: “Such a selected path is an artificial construct, which does not reflect the original sparse encoding of the input” but what this means is anyone’s guess. I fundamentally failed to grasp what the authors are trying to convey with Fig1. I understand *what* they are illustrating (that all pruning methods include neurons that were previous “dead”) but why do I want to know that, and what does that tell me? What exactly about including dead neurons causes these pruning methods to be insufficient, in the authors’ eyes? \n\n- Section 2.3. The path selection procedure the authors describe is unclear, and this is in large part due to the poor explanation of their notation. For example, the notation e = [e^i_j ]^N is not explained, and hard to grasp exactly what they authors are referring to. A second point- the authors state “Marginal contribution requires response computation N times.” This is not self-evident. The authors need to unpack exactly what their method is doing in greater detail for anyone to follow along.\n\n- Section 2.4. The authors state: “In Fig. 3b, we perform a semantic sanity check on the selected top neuron on each path by analyzing its semantics.” No reasonable person could ever classify this sentence as clear. \n\n- Several references are made in 2.4 to “an optimization” (e.g. “In Fig. 3a, we perform the optimization on the paths selected by different methods”) but it’s not clear what they authors are talking about. Is this referring to the pruning objective, or some other optimization? If so, what is that objective function? A few sentences later, the authors state “When we restricted the network to the active path (Active Subnet), optimization attempts to reconstruct the image.” What optimization is this? Is this the same as the one above, same as the pruning objective? Care has not been taken to ensure that a reader can follow along.\n\n- Understanding Fig 6 in any detail, given what the authors stated, is impossible. “Following Ancona et al. (2017) we remove least relevant features first (LeRF). The results are depicted in Fig. 6(a,b,c).” What are LeRF? How did you identify them? Can you illustrate one in a figure?\n\n This list is not exhaustive, nor could I make one. Doing so would be unfairly burdensome to a reviewer. **Simply completing the above list for re-review will not be sufficient, in my eyes, to warrant acceptance**. An **exhaustive** overhaul of the presentation is required, in order for this submission to be ready for acceptance. The above points should act as “guide points” to illustrate my concerns, but more extensive clarifications are required. \n\nTo aide in this, the list below is a point by point illustration of the ways that, broadly speaking, a resubmission would need to achieve clarity:\n\n- The details of every method should be expressed clearly. Key areas that need improvement in this regard are 2.3, “Path decoding” in 2.4. and the details of 3.3\n- The introduction should include motivation at a more broad level, a level that would allow someone not intimately familiar with the research question (or, for example, the results of Wang 2018) to understand the very basics of the research question, including why it’s research worth addressing, and the basics of how the authors intend to tackle the question.\n- Results, broadly need to explained in greater detail. For example, the caption of Fig 6, ostensibly the main result of the paper, is only two sentences. Cleary, no amount of information can be gleaned in two sentences. For example, in Fig6, the authors show results from “GradCAM”- what is that method? I don’t recall seeing it in the main text, and if it was there, it was explained in such a rushed way that I obviously didn’t even notice it.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}