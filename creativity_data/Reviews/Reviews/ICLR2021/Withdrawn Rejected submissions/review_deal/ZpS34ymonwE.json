{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "I thank the authors and reviewers for the discussions. Reviewers agreed the work is interesting but there are some aspects of the paper that need improvements. In particular, authors need to better address concerns raised by R5. Given all, I think the work still needs a bit more work before being accepted.  "
    },
    "Reviews": [
        {
            "title": "Review of the paper \"meta adversarial training\"",
            "review": "#########################################################################\n\nSummary: \nThis paper uses meta learning to learn adversarial perturbations to improve the model robustness against universal patch attacks. \n\n#########################################################################\n\nPros:\n1. The proposed meta adversarial training (MAT) claims to learn a large & diverse collection of universal perturbations that aids the robust training. \nSpecifically, this paper leverages the “reptile” meta learning method to learn the better initial values of universal perturbations, which may lead to better universal perturbations for updating the model. \nThe meta learner can be trained in parallel to the robust training. \n\n2. The writing is sound. The logic flow is clear. \n\n#########################################################################\n\nCons:\n1 This paper mentioned existing defenses overfit universal perturbation. Would the proposed method MAT relieve this overfitting issue? \n\n2 How does the adversarial training (e.g., against l_p norm bounded attack) resist the universal perturbation, compared with specially designed defenses such as MAT? \nIn table 1, why AT cannot defense transfer attack? Could it be possible that the baseline methods are improperly configured?  \n\n3 How & why does the initialization of the universal perturbations matters most? (Since the author claims the meta learning can better help the initialization.)\nTo be specific,  are there any justifications & explanations on the better initialization for aiding robustness? \n\n4 Another drawback of this paper is the unclear/incomplete technical descriptions (including Section A.)\n#########################################################################",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting work MAT (by coupling adversarial training and meta-learning). ",
            "review": "The authors propose a novel meta adversarial training method. In particular, to improve the robustness against digital domain attacks, the proposed meta adversarial training (MAT) combines adversarial training and meta-learning, which reduces the computing cost compared with adversarial training by generating a set of stronger perturbations. The proposed approach sounds with extensive experimental results.\n\n* Pros:\n\n1.\tThe authors study a crucial issue of adversarial attacks, namely, a robust defense to perturbations. This problem is practical and of great importance to many areas, such as autonomous driving, robotics, etc.\n\n2.\tThe proposed MAT is designed for robust defense by combining adversarial training and meta-learning. \n\n3.\tIn MAT, meta-learning is used to meta-learn a set of initial perturbations and followed by a few gradient steps for adaptations. This method can avoid overfitting and the generated perturbations will try to focus on diverse weaknesses of the model, and thus the model is more robust. \n\n4.\tThe authors conducted comprehensive experiments, including image classification and object detection, with both qualitative analysis and quantitative results provided to show the effectiveness of the proposed model.\n\n* Cons:\n\n1.\tIn meta-training process, REPTILE is used to update the model $\\cal M$. However, it seems that in the testing stage, $\\cal M$ is directly used rather than adapted using training data from the testing task. As a result, the learned model $\\cal M$ is more like a pretrained model, rather than meta learning. It would nice if the authors can explain the details of testing process, and the design choice.\n\n2.\tIn Algorithm 1, it would be nice to explain in more details of the choices of INIT and SELECT functions, and their impacts to the algorithm performances. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good results on defending against universal patch attacks, but clarity of writing should be improved ",
            "review": "This paper studies the use of meta learning and adversarial training to defend against universal perturbations. This approach tries to learn a set of perturbations through meta-learning and train the model to defend against such attacks. Experimental results on Tiny ImageNet and the Bosch small traffic lights dataset show the method is effective in defending against universal patch-based attacks. \n\nAlthough the main idea of the paper is sound and empirical evaluations promising, there are some clarity issues with the writing of the paper: \n1. In Algorithm 1, important operations such as INIT, SELECT, and UPDATE are described informally in the text instead of defined properly. \n2. What is the attack method used in Table 1? The columns only describe the initialization. \n3. Is the AT model in Table 1 trained using patch-based attacks or usual whole image attack? \n4. The notations used in Section 3.2 is for \\xi is very confusing and too overloaded. What do the notations \\xi(\\theta_t_1), \\xi(\\theta_t_i)_{i=1}^N, \\xi_t^m, \\xi_{T=k}, \\xi_{t=K} mean? The authors are using notations liberally without definitions. \n5. What does S-PGD stand for? \n\nAlso, in learning meta-perturbations the authors use different step sizes \\alpha in I-FGSM and targeted attacks from different classes for a diverse collection of attacks. The same idea of diversifying the attacks can also be incorporated in AT, SAT or UAT training. Have the authors tried this when performing comparisons? \n\nOverall I think this paper is a solid piece of work, but the clarity of presentation has to be improved.  \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}