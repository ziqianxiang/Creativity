{
    "Decision": "",
    "Reviews": [
        {
            "title": "Official Blind Review#4",
            "review": "summary \nIn this paper, the authors consider the \"Out-of-domain generalization from a single source\" problem which is a worst case scenario in the meta-learning context. For this purpose, the proposed method not only performs feature augmentation but also label augmentation. These data augmentations are based on the domain uncertainties that are sequentially estimated in the algorithm and allow us to obtain a domain knowledge-independent model.\n\nThe strength of the proposed method, Bayesian meta-learning of the parameters for feature augmentation and label mixup, is that it can handle various tasks such as image classification, text classification, and speech recognition in the same training method. \n\nThe weakness of this paper is about the applicability of the proposed method. In this paper, the authors do not explicitly define 'out-of-domain'. Hence, while the accuracy of various tasks certainly seems to have improved, we can not evaluate how difficult a target domain to transfer the knowledge from the given source domain, from 'out-of-domain' view point. In other words, there seems to be little basis for determining whether the proposed method should be used when faced with a real problem. \n\nI think the idea is interesting, so I think it would be helpful to have an explanation of the fundamental setting of the problem like the above one. \n\nOverall, I think there is room for improvement in this paper.\n\nSome concerns:\n\n- p.3 \"safe domain generalization\", p.7 \"safe generalization\" \n  What does the word \"safe\" mean? How can we evaluate it?\n\n- How do you estimate the \\sigma(T) - \\sigma(S) / \\sigma(S), which is the variance of the new domain, included in the uncertainty score? \n\n- In the ABLATION STUDY, for example Table 5, the accuracy of the full model is almost the same to that of the model with estimating only one parameter of the normal distribution. Is this phenomenoa can be considered to generally occur? If so, I don't think there's much reason to use the full model. I think this argument can also be applied to the comparison of random mixup with the full model (Table 6), and the comparison of w/o minimizing \\phi_p with the full model (Table 7).\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Many unjustified claims, unclear contribution",
            "review": "This manuscript aims to tackle the problem of out-of-domain generalization. In particular, the setting studied in this paper is different from both domain adaptation and domain generalization, in the sense that there is only one source domain, and the learner does not have access to (even unlabeled) data from a target domain. Algorithmically, the main idea of the approach is to perturb both the input instances as well as the labels. To do this, two networks with tunable parameters are used to learn the mean and variance of the gaussian distribution (for features), as well as the pseudo-counts of the beta-distributio (for label mixup). Experiments on images, text and speech are performed to show the performance of the proposed approach. \n\nFirst of all, as a high-level principle, the authors should be aware of the no-free lunch theorem, which states that no algorithm could produce \"good\" results on any distribution. As a result, the goal of this paper, as stated by the authors, \"from a single source and expect it to generalize over many unknown distributions\", is not actually possible. In fact, even in the relaxed setting of unsupervised domain adaptation, where the learner has access to unlabeled data from a fixed target domain, domain adaptation is not possible without proper assumptions on the structure of and source and target domains. Hence the claims of worst-case generalization out-of-distribution in both the abstract and the introduction of this paper are very misleading, to put it at least. \n\nApart from the overclaims made in the manuscript, there are many claims in the paper that are not well justified, neither theoretically nor empirically. For example:\n\n-   In section 3.1, the authors claim to \"create S+ from S such that p(S+) can approximate the out-of-domain distribution of S\". This claim does not make sense to me: since the goal is to generalize in the worst case, and no sample from the target domain is available, what does it even mean to approximate? \n\n-   In the optimization formulation of Eq. (1), the optimization variable is \\phi_p, while \\phi_p does not appear in the objective function? Furthermore, if L is the cross-entropy loss, shoulnd't it be minimized instead of maximized? \n\n-   Again in section 3.1, \"we assume e follows a multivariate Gaussian,..., which can be used to access the uncertainty\". Why assuming it to come from a Gaussian gives you the ability to assess uncertainty? Also, why adding Softplus() to the Gaussian variables will help to stablize the training process? \n\n-   In section 3.2, why the specific choice of chance \\tau is used? Is there any justification, at least motivation, for this choice? Also, I don't quite understand why making a, b, \\tau parametric means to \"integrate the uncertainty of domain augmentation\".\n\n-   In section 3.3, I could understand that the the objective function here is an ELBO from variational inference, but why is this called Bayesian meta-learning? In particular, what's the prior distribution over {a, b, \\tau, \\mu, \\sigma}? Later in this section the authors called p(S+) to be the posterior distribution, which further confuses the problem here. Shouldn't the posterior be over {a, b, \\tau, \\mu, \\sigma} instead of the domain? A minor point: in VAE the authors didn't set p(h | x; \\theta, \\phi) to be Gaussian, but instead the prior p(h) is assumed to be Gaussian. \n\n[1]. Impossibility theorems for domain adaptation, AISTATS 2010\n[2]. On Learning Invariant Representation for Domain Adaptation, ICML 2019\n\n\nMore minor comments about the writing:\n-   In domain adaptation/generalization, usually the joint distribution over XxY is refered as a domain. It's perfectly fine that the authors would like to refer the marginal distributions over instances as domain, but it should be clearly stated first. \n\n-   Grammar error: \"meta-learning framework to maximizing a\" -> \"to maximize\"\n\n-   Grammer error: \"when inferencing\" -> \"when inferring\"\n\n-   Grammar error: \"we prefer the transportation is domain-knowledge-free\" -> \"we prefer the transport to be domain-knowledge free\"\n\n-   Grammar error: \"to inference\" -> \"to infer\"\n\n-   Others in the experiment section as well.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official Blind Review by reviewer3",
            "review": "This paper proposes a new mechanism to train a model to be generalized for out-of-domain generalization with a single source. They used adversarial training for a part of the model to make permutations causing as much as bigger loss and for another part to reduce the loss. They didn't permute raw data but representations and mix the label also to train the more robust model. They also designed their model in the Bayesian meta-learning framework to maximize the posterior about the permuted source.\n\nStrengths:\n\n1. They proposed a probabilistic permutation method, which showed better performance than deterministic ones in their ablation study.\n2. Not just reporting outperforming results from their model but also plentiful ablation study results, which are very helpful to understand deeply their model.\n\nWeaknesses:\n\n1. They designed their method in the Bayesian meta-learning framework, but I can't understand deeply it is required or the best choice. As I understand, they trained their model with the loss from permuted source on top of the update with original source. How about directly training the model only with the loss from the permuted source? BML can make better results?  Why the transferring meta-knowledge from the original source is important? I think that the authors tested before about it or have their own reasons about it, adding that on this paper can be helpful why BML is used I think.\n\nThe correctness of their claim and Clarity:\n\nThis paper is well written and correct.\n\nAdditional feedback:\n\nThank you for submitting and I enjoyed reading. I think that this paper is quite concrete with lots of comparison results and ablation studies. Probabilistic permutation and the effect on the generalization of the model are important enough to be shared in our community I think. However, for the BML part, I can't find the critical reason why it is needed to be used. If the authors will share their thought about it or updating their paper, I think that it can be more concrete.\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "More details should be provided",
            "review": "This paper proposes a new algorithm for generalization to unseen domains. The algorithm consists of several parts: the feature augmentation, pseudo labels using uncertainty, and Bayesian meta-learning. The authors provided experimental results on image classification, text classification and speech recognition and show that the algorithm outperforms several baseline algorithms.\n\nI think one strength of this paper is the comprehensive experimental study. The authors use a diverse set of tasks (image, text, speech) to demonstrate the benefits of their algorithm. I appreciate the comprehensiveness.\n\nOn the other hand, I found that some parts of the paper were not written very clearly. For example, I found section 3.3 Bayesian meta-learning not easy to follow. I was not very sure about how each step was conducted after reading this section. I would recommend having a pseudo code table (perhaps in the appendix) to better explain the algorithm.\n\nI also feel that the paper is not sufficiently novel, as it is a combination of several existing ideas, including feature augmentation (Volpi et al., 2018; Qiao et al., 2020),  meta learning for domain generalization (Qiao et al., 2020), and mixup (Zhang et al.) In fact, when reading this paper, I feel it is quite similar to M-ADA. The authors mentioned that one of the novelty is using pseudo labels (soft labels) in the augmentation process. I think this idea is not completely new either. Here are some references that I found:\nLiang et al. Exploring uncertainty in pseudo-label guided unsupervised domain adaptation\nZheng and Yang, Rectifying Pseudo Label Learning via Uncertainty Estimation for Domain Adaptive Semantic Segmentation\n\nOverall I recommend the authors to provide more details of the procedure of their algorithm and a better justification of the novelty.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}