{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes a method to identify informative latent variables by thresholding based on the conditional generative model. While the exposition of the paper has substantially improved during the discussion period, some major concerns remain after the discussion among the reviewers. In particular, the problem considered in the paper has a very limited scope. Moreover, the evaluation of the methods needs to be improved. The paper could benefit from discussing how it situates in the broader context."
    },
    "Reviews": [
        {
            "title": "Reservations arise about the exposition and content of the paper",
            "review": "This paper builds on top of the paper “Disentanglement by nonlinear ICA with General Incompressible-Flow Networks (GIN)” (Sorrenson, 2020) and argues that that paper’s method of identifying informative latent variables was wrong and instead suggests that informative latent variables can be identified by thresholding their mutual information with the auxiliary variable of the conditional generative model.\n\nOverall, I score this paper as a reject. Without judging the content as reason, the exposition of the paper is overly difficult to understand. It also makes very specific references to Sorrenson (2020) and Khemakhem (2020) and their proofs without providing context (Section 2). Similarly, it introduces nonlinear ICA without defining the model well (Section 1). This reviewer had to read the mentioned papers side-by-side to make sense of the paper under review. \n\n### Comments about the content\n\nGIN/Nonlinear ICA wants to recover the true generative latent variables $\\mathbf{z}$ for data $\\mathbf{x}$ given the conditioning variable $\\mathbf{u}$, which acts as the cause for the true latent. In particular, it would be important to mention that both data $\\mathbf{x}$ and auxiliary $\\mathbf{u}$ are observed. An example is given in Sorrenson (2020) for (E)MNIST: $\\mathbf{u}$ is the digit to draw, $\\mathbf{z}$ are the parameters that guide the drawing, $\\mathbf{x}$ is the output. The mentioned papers show that the true latent variables can be recovered up to affine transformations, and additional latent variables are noise.\n\nThis paper sets out to examine the question on how to separate informative latent variables from latent variables that encode noise (in the recovered latent) and claims that Sorrenson (2020) chooses the wrong metric for thresholding (they use the std deviation of the different latent variables). This reviewer could not find any particular mentions of this question in Sorrenson (2020), except for implicit usage in the experiment section.\n\nHowever, this paper claims that mutual information is a better metric and Sorrenson (2020) made a mistake in their proof. This reviewer did not retrace the proofs. Moreover, this reviewer could not understand how eq. (5) in this paper, which uses the data processing quality with the joint of the latent, motivates using the mutual information of the individual latent variables to identify informative ones. \n\nMoreover, intuitively, the MI with the auxiliary variable will tell us about the dependence of the two, which will identify latent variables that encode local information for the conditioning variable (eg digit) and which change a lot in their distribution depending on the conditioning variable (using the language from Sorrenson (2020)).\n\nThis leads to the question about “global” parameters, which do not change in distribution. For example, if MNIST was not grayscale but had digits with different colors (equally likely), the color could be a global parameter, which would be uncorrelated with the conditioning variable and thus have zero mutual information. This would mean that this paper would treat it as a noise variable, which it is not.\n\nAs such, this reviewer would ask the authors for clarification.\n\n### Additional comments\n\n1. The figures lack axis labels.\n2. FGSM is a rather weak adversarial attack.\n3. Section 5 and Figure 9 mentions that the learnt representation $\\mathbf{w}$ is very close to a permutation of the real latent variables. This is explained in Sorrenson (2020), Section 3.2: “when both the generating and estimated latent spaces follow a Gaussian distribution, the latent space variables are recovered up to a trivial translation and scaling.” This is the case here: there is no rotation, which leads to a permutation in the correlation matrix.\n\n---\nThis reviewer wants to thank the authors for their detailed reply and for updating the paper to make it more self-contained. It reads much better now and is much clearer. The review score has consequently been updated from 4 to 6. Stronger adversarial experiments would be encouraged. Could the authors also include a definition of the VAR criterion (even though it is trivial, just to avoid any ambiguities) and maybe include a paragraph for the future applications of this? For this reviewer, it is not entirely clear yet what the value of this finding is: is it going to help with downstream tasks for ICA? Is this another argument in favour of preferring Mutual Information as a metric over variances in general?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Ambiguous writing obscures the contribution ",
            "review": "This paper proposes a method to select informative latent variables for representation learning. The idea is to find variables that maximize mutual information with respect to observed auxiliary variables. The paper points out that in Sorrenson et al. the latent variable selection criteria does not lead to good guarantees, and empirically the new selection criteria has superior performance. \n\nPro: \n\nThe paper points out the problem that since the scale of the latent variable cannot be recovered, the scale cannot be used as a criteria for variable selection. This seems true and an important point to note. \n\nThe proposed alternative variable selection criteria seem reasonable, but the algorithm and its theoretical properties need to be rigorously stated.\n\nCon: \n\n\nThe writing is quite difficult to follow. One big issue is that this paper is not self contained, i.e. it inherits the notation in prior work (especially Sorrenson et al) without explaining what the symbols mean. Many notations are also confusing. For example in Eq.(5) what does w(z,eps) mean? I can kind of get you are trying to represent the dependence of w on z and eps, but this expression does not type check. \n\nHow is the mutual information criteria implemented in practice? I’m assuming you want to find a subset of variables that maximize mutual information w.r.t. u, but this is a problem known to be difficult (i.e. a naive solution has to enumerate every subset of variables). I inferred that you are finding **individual** variables that maximize mutual information with respect to u; However there is a big gap between Eq.(5) and the claim that you can maximize mutual information of each individual variable w.r.t. u. How is this justified, or did I misunderstand? I think you need to explicitly say exactly what algorithm you are using, and what property it should have. \n\nThe experimental settings are also not clearly explained. As a few confusing sentences (among many others), \"each latent variable is labeled by auxiliary variable\" or \"the signal provided by the informative latent variables may not be able to outstand\". I don't think I can understand what is going on exactly here with so much ambiguity. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A good improvement of informative latent variables selection in general incompressible-flow networks, but incremental for publication",
            "review": "This paper considers the problem of disentangled representation learning with an existing normalizing-flow-based approach, called general incompressible-flow networks (GIN). In the original approach, informative latent variables were separated from noise by considering the variances of learned latent variables and selecting ones with high variances. The current paper shows empirically that this approach can fail even when the underlying data generating process satisfies all assumptions needed for identifiability. The reasoning is simple: Latent variables can have different scales and their variances may not be indicative of informativeness. Instead, the current paper proposes to use the Shannon mutual information between the auxiliary observed variable (conditioned on which the true underlying factors of variation are conditionally independent and belong to the exponential family) and latent variables to separate informative latent variables from noise. With experiments on synthetic data and on EMNIST, the paper successfully shows that the proposed mutual-information-based approach works better than the original variance-based approach (in terms of recovering the ground truth latent factors, downstream classification accuracy, and out-of-distribution detection).\n\nThe paper achieves a good improvement in informative latent variables selection in GIN, but is not a significant contribution for ICLR publication. To improve the paper, the authors may consider proving that the mutual-information-based approach recovers the ground truth factors in the setting of equation (1) or (2). Additionally, the proposed approach of selecting informative latent variables can be considered more broadly in the context of other disentangled representation learning approaches.\n\n# Update\nThanks for the rebuttal. I have read the changes the authors did. The updated manuscript is more readable and more self-contained now. I am still of the opinion that the presented method should be put in a broader context (i.e., considering it in broader settings and/or for other methods) or be better analyzed theoretically. This way it will be much more useful for the community. For this reason, I keep the score the same.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "This paper considers the previously established Generative Incompressible Flow (GIN) model to perform disentangled representation learning and argues that the original method of identifying explanatory latent variables via their variance magnitude is flawed. Identification is necessary because flow models require the same number of latent variables as the data dimensionality, thus many latent variables are expected to be uninformative, due to the general low-dimensional data manifold hypothesis. This paper proposes the mutual information between a latent variable and an auxiliary variable (needed because otherwise, the disentanglement objective is unsolvable in general) as an identification criterion and shows that this outperforms the variance criterion, especially in cases where the noise magnitudes are of the same order as the magnitudes of the explanatory variables.\n\nI think this paper makes solid arguments for why the original variance criterion is flawed under certain conditions and why the mutual information criterion is better and I lean towards accepting.\n\nHere are a couple of comments, weak points, and questions:\n- Labeled axes would make the plots more readable without having to re-read the caption multiple times\n- At some point, you claim that the importance of any latent variable can be dependent on which auxiliary variable is used. The claim seems to be that the same data could have a set of latent variables that would have high MI with u1, and another set that would have high MI with u2. I see that this is feasible (and even probable), but you never show this, not even in synthetic data. In fact, in the synthetic data, your 8 noise variables are very idealistic. I would therefore either take out the claims or include experiments that show these effects, both in synthetic and real data.\n- In Figure 6, the performance decreases for MI as you include more variables. You discuss this in the text, but it is not satisfactory to me. Could you formulate more clearly what you mean here? Is the degradation an artifact of not being able to estimate these variables well? Or is your core assumption of a low-data manifold violated? Or could it be that the MI is a better, but still not the correct criterion?\n- How do you estimate the MI, in detail?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "## Summary\n\nThe authors propose an alternative method for finding informative latent variables in a model called General Incompressible-flow Networks (GIN). While previous work relied on the variance of the variables to assess informativeness, the authors argue that this is problematic when the scale of noise epsilon is large. They propose instead to use the mutual information between the variables and u instead.\n\nThe authors evaluate their alternative identification method on two tasks: a toy example of a mixture of gaussians and EMNIST. They show that when the variance of epsilon is large, then their method outperforms the variance based method (figure 3). However when the variance of epsilon is small, then VAR performs similarly to MI (Figure 8).\n\nOn EMNIST, it's clear that MI is able to identify the most important variables and outperforms the best VAR setting, however when more variables are included the MI method deteriorates quicker than VAR. \n\n## Review\n\nIn general I find the paper difficult to follow. Many paragraphs have an unclear structure and sentences are not linked. There are also many unsubstantiated, or unclear/imprecise claims. The derivations and equations seem correct and the figures are well made and understandable. Especially figures 1 and 2 are informative and clear.\n\nI think the paper would be a lot stronger if it was positioned as \"This is a failure case of using the VAR method with GIN, we propose a rigorous solution\". Currently the authors make statements such as \"Though Sorrenson et al. successfully establish the identifiability, their interpretation on the meaning of this result and the method they propose are incorrect\", \"it is unplausible to use the variances of the learned representation\" and \"while the original VAR criterion is not competent at all\" - despite clearly showing that the VAR method works well in a number of situations. I think it's worth being more nuanced about alternative methods and explicitly showing when the other method does not behave as described/expected (which you also do!).\n\nCould the authors comment on how the MI was computed and in particular the computational trade offs between using MI and VAR to select variables? I'm also curious why the MI method degrades so quickly in figure 6, how did you set up the classification task?\n\nHow did you \"apply defence\" in the adversarial defence experiment? You mention that VAR300 is only fooled by 56% of the cases without defence, but this cannot be compared because its \"clean accuracy\" is lower, could you expand on that? It seems to me that higher accuracy is always better? It seems in contradiction with the claim at the end of the paragraph that \"all results indicate that ... features selected by MI criterion are more reliable.\"\n\nIn general, a lot of the experiments seemed to be based on Sorrenson et al, but are not properly described in the paper. I would like to see at least a basic description.\n\nIn summary, I think the authors have identified an interesting improved that is worth publishing. However I think that the paper in its current form is not ready: it can benefit from significant rewriting for clarity (both in structure, as well as spelling) and further analysis of the behaviour in figure 6.\n\n## Notes:\n\n\"Incompressive\" --> incompressible  \n\"in nonlinear independent analysis theory\" - missing \"component\"?  \nW_{d+1:n} should be W_{n+1:d} (below equation 4)?  \n\"unplausible\" -> \"Implausible\"?  \n\"interpretation on\" -> \"interpretation of\"\n\nThere's a number of other, non-existent, words in the paper that will be caught by a spellcheck.\n\n## After updating paper\n\nAfter reading the updates, I think the authors have considerably improved their paper and I have increased my score.\n\nWhile the core contribution, using MI over VAR, is clear. The evaluation is not strong enough, I still don't understand why adversarial defense is a reasonable way to evaluate the different metrics. Further it's now clear that the author's use the sklearn implementation of MI estimation, which depends on several entropy estimators which have high variance in practice. While the authors comment that it's \"negligible\" I am not convinced that this is actually easy or reliable.\n\nIn summary I think the paper is not ready for publication.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}