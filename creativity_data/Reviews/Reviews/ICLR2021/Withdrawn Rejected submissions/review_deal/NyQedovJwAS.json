{
    "Decision": "",
    "Reviews": [
        {
            "title": "An OK study on pre-trained model adaptation for image anomaly detection with little conceptual novelty.  ",
            "review": "Methodology:\nThe paper studies the problem of pre-trained model adaptation for image anomaly detection. It is argued that previous model adaptation schemes either lost model capacity (DeepSVDD) or required extra data with marginal improvement (joint optimization). To alleviate these issues, the paper proposes to regularize the model adaptation process by either 1) sample-wise early stopping, or 2) regularize the model deviation from the initial one. For sample-wise stopping, a sequence of adapted models are recorded at fixed intervals during the adaptation process to produce anomaly scores for each query example, and each score is further normalized with those of the normal examples in the training set using the same model. The final anomaly score is the maximum of these normalized scores of the query example. For model deviation regularization, an extra term is added to the original compactness loss to quantify the deviation in the model natural gradient space. Results on several image anomaly benchmarks show that the proposed method improved on both self-supervised and naive model adaptation methods.\n            \nPros:\nThe paper approaches the problem of catastrophic collapse for image anomaly detection from a reasonable perspective, and the proposed solutions are shown to achieve desired effects.  \n\nCons:\n- The overall strategy and most observations are mostly known from other similar applications. \nEarly stopping is one of the basic tricks for deep model fine-tuning, and the use of natural gradient for model deviation (elastic weight consolidation (EWC)) was proposed in (Kirkpatrick et al., 2017). And all the rest are off-the-shelf implementations for image anomaly detection. Major observations are also not surprising: “We can therefore conclude that ImageNet-pretrained features typically have significant advantages over self-supervised features.” “This shows that one of the main concerns of using pre-trained features, namely, generalizing to distant domains is not an issue in practice.” These are all well known results in many other image modeling applications, and I have a hard time finding much novelty in these aspects.\n\n- Interesting cases are not tested enough to justify the advantages of the proposed methods. \nThe proposed sample-wise early stopping (and EWC too) compares only slightly favorably to the naive one that stops after a fixed number of iterations (fig 4). What about some other baseline adaptive early stopping schemes? E.g., cross-validating the #fine tuning iteration on the validation set, and so forth. I doubt that these easier early stopping methods would work better at a far less cost of the proposed SES as the latter needs to do T times number of inference for a single example. If so, why bother using the more expensive SES? \n\nMinor comments:\nIt looks to me that there are typos in some critical parts of the paper.\n- eq (3), it should be L(x, y; \\theta), instead of L(x,y); \\theta, right? The latter does not make sense to me…\n- eq (5), it should be log(1-\\sigma(w\\phi(x))) instead of log(\\sigma(1-w\\phi(x))), right? \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The paper explores some good practice for anomaly detection, but the contribution is marginal.",
            "review": "- The paper lacks of a clear definition of normal and anomaly in images. For example, this could be illustrated in the intro or in each dataset separately. Qualitative results could also be helpful examples. Otherwise, it is hard to understand why each proposed method works, and only quantitative results are not enough to understand the proposed method.\n\n- The paper argues that using pre-trained features in anomaly detection has the combating collapse, but why this happens in anomaly detection or why this problem is especially for anomaly detection is only explained in a few sentences. Another way to ask the question is that is it possible for the proposed method also works for other computer vision tasks or very related task (such as video anomaly detection)? Why?\n\n- The performance of the proposed method achieved good results on five benchmarks, however, it technical contribution is not significant. The contribution mentioned in the paper are more about providing some good practice and analysis about adapting pertained features for image anomaly detection, and its generalization ability is also not clear.\n\nOverall, I would lean to rating 5 before the rebuttal.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Lack of novelty and insight ",
            "review": "This paper proposed an algorithm for anomaly detection. The core of the approach includes two parts. One is sample-wise early stopping and anther is a new type of loss. Although the experiment on  the proposed algorithm has better performance on some datasets such as MNIST and CIFAR10, the proposed method does not provide insight understanding about where the performance gain come from. Further, the proposed method is rather a practical assemble of variant existing method which improve the result. For these reason, I do not think this paper is ready to publish.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A convincing comparison between self-supervised and domain transfer for anomaly detection with novel collapse avoidance methods",
            "review": "This paper proposes a method to combat feature collapse during model adaptation in anomaly detection (AD), while maintaining performance gains. Feature collapse happens during fine-tuning adaptation of a pretrained model when using a compactness loss and results in all samples, even the anomalous ones, being mapped to the same point. Previous approaches include: removing the bias in all network units as was proposed in DeepSVDD [Ruff 2018]; joint optimization (JO) by using some of the data used to train the pre-trained model [Perera 2019]. This paper proposes 2 novel approaches: 1) adaptive sample-based early stopping (SES) based on a set of checkpoint-saved models after different numbers of iterations and an-inference-time selection of the max anomaly score; 2) continual learning by elastic weight consolidation (EWC). These methods are compared to the baselines DeepSVDD and JO and shown to outperform them on several AD tasks. Another study compares self-supervised approaches to the pretrained approach and show the latter to be more performant. Outlier exposure OE can be added to the proposed method, resulting in new SOT performance for several datasets.\n \n PROS:\n \n  * The paper shows convincingly that pre-trained models are superior to self-supervised models, even for datasets where the domain is far from the one used for pretraining (e.g. MVTec,DIOR,FMNIST on ImageNet). \n  \n  * The paper proposes two techniques for domain adaptation of the pre-trained weights that mitigate the collapse problem. Those techniques are relatively simple and thus should be reproducible without too much difficulty. \n  \n  * The results show that adaptation of the pre-trained weights does provide an extra boost in performance.\n  \n  * The paper also studies which ResNET block need to be adapted for best results. It is shown that on CIFAR10, adapting only blocks 3+4 of the ResNET, result in the best performance.\n \n\n CONS:\n \n  * The paper does not study the computational complexity of the proposed methods. For example, the SES approach requires multiple inferences with several models and thus becomes much more costly. It is also unclear how the training time is affected by the EWC method.\n  \n  * It is not clear which anomaly scoring function is used in the experiments. It is stated that several scoring function are evaluated: Euclidian distance, Knn, K-means. However, nowhere is it said which one is finally used.\n  \n  * It is not specified which baseline results are taken from published papers, and which have been obtained by the authors. The numbers for JO, for example, seem to be obtained by the authors as the JO papers did not use the same datasets (CIFAR, etc.). On the other hand the DeepSVDD numbers seem to come from the published paper.\n \n\n Overall, this paper provides useful findings and novel approaches to weight adaptation in domain transfer for anomaly detection tasks. It is well written and contains a lot of relevant empirical experiments. The novel methods are clearly explained and should be reproducible. SOT is achieved on several AD benchmarks. A clear accept.\n \n ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}