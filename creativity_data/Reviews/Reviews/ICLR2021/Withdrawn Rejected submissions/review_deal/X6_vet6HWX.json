{
    "Decision": "",
    "Reviews": [
        {
            "title": "The paper's contribution is not significant.",
            "review": "Summary:\nThis paper analyzes the effect of having extra dimensions in the input to a neural network. It shows that extra dimensions containing information that is :\n- unrelated to the task is bad for the model (increases sample complexity), and\n- redundant but related (e.g. a linear transformation of the input) is not bad for the model.\n\nTheoretical analysis is presented for a linear network and experimental analysis is presented for various network types on both synthetic and real data.\n\nPros:\n- The experimental section extensively tests the proposed hypotheses, including linear networks, MLPs, and deep CNNs.\n- The analysis shows that, at least in the limiting case of having a very large number of extra unrelated dimensions, the drop in test performance can be explained as too much Tikhonov regularization being applied to the original (minimal) dimensional problem leading to underfitting. This is an interesting way of formulating the problem : it can be seen as both overfitting to the expanded dimensional inputs as well as underfitting to the minimal inputs.\n\nCons:\n- My concern is that the main contribution of this work is not significant. I could not understand what we learn from this paper that can help remove the extra dimensions or prevent them from adversely affecting neural network training. In other words, the main hypothesis is somewhat obvious : if there are extra dimensions that are unrelated to the task, more data would be needed to resolve the spurious correlations between those extra dimensions and the labels. It is also fairly obvious that extra dimensions that encode the same (but task relevant) input should not hurt. In my opinion, verifying these hypotheses by itself is not a significant contribution. One way to improve the paper is to emphasize how we can detect and alleviate the problem of having unnecessary dimensions.\n\nMinor typos and suggestions\n- In appendix B.1 : \"The white triangles in Fig. 8a\" -> \"8b\"\n- \"Lastly, in Fig. 8b\" ->  \"8a.\"\n-  This part was confusing: \" .. it is expected that as the task-unrelated dimensions increase there is more overfitting. Yet, there are exceptions to this intuition, e.g., when the labels of the dataset are noisy. To illustrate this point, we consider ..\" The argument that follows has nothing to do with noise in the labels.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A simple model of feature relevance sheds some light on the performance of DNNs, but is it sufficiently realistic?",
            "review": "This paper examines the effect of superfluous input dimensions on neural network learning. The authors consider a scenario in which additional dimensions are added of two different kinds: 'task-related', whose values are generated via a linear transformation applied to the original data, and 'task-unrelated', in which the values are generated independently according to identical gaussian distributions.\n\nThe authors first provide a theoretical analysis for each type of additional\ndimension. For the case of 'task-related' feature values, the learning problem\nunder linear transformation is shown to be equivalent to the original for\nlinear networks with squared euclidean loss. Their argument assumes that the\nsystem is over-parameterized (allowing the solution to be expressed using the\npseudo-inverse of the input) and that the transformation is a tight frame\n(which preserves the dimensionality of any linear manifold to which it is\napplied). \n\nFor the case of 'task-unrelated' feature values, the authors show that when\nthe number of new dimensions is sufficiently large, their impact approximates\nthat of a Tikhonov regularization term. The effect of this is to bias the\nsolution towards smaller vector norms as the gaussian variance increases.\n\nIn the remainder of the paper, the authors conduct experiments on linear\nnetworks, multilayer perceptrons, and deep convolutional neural networks, so\nas to test their theoretical conclusions: that adding 'task-unrelated'\nfeature values leads to a degradation in data efficiency, and that adding\n'task-related' values can counter this degradation.\n\nPros:\n-----\n\n1) The stated overal goal of the paper, that of characterizing the data efficiency of neural networks in terms of feature relevance, is important and interesting.\n\n2) For the model of feature relevancy considered, the experimental results do show the anticipated effects very clearly. The development of the discussion from an ideal situation involving linear transformation, through MLP to DCNNs, is (for this feature model) satisfying and convincing.\n\n3) The paper is generally well organized and presented. The descriptions are\nclear and accessible.\n\nCons:\n-----\n\n1) The authors' theoretical model of additional features is rather simplistic.  Adding 'task-related' features are guaranteed to leave the intrinsic dimensional characteristics of the original data unchanged - the linear transformation maps lower-dimensional manifolds into new subspaces of the same intrinsic dimension.\n\n2) 'Task-unrelated' features greatly change the underlying intrinsic dimensional characteristics of the data, to the extent that the resulting data would no longer have natural characteristics. Most real datasets are known to have quite low local intrinsic dimensionalities even when their representational dimensions are high; however, adding dozens or even hundreds of independent gaussian-distributed features would drive the intrinsic dimension to unrealistically high values.\n\n3) Given the restrictions they put on the nature of additional features, it is\ntherefore not surprising that the experimentation (on linear networks, MLPs,\nand DCNNs) confirms the authors' hypotheses regarding the impact of\n'task-related' and 'task-unrelated' features. The unrealistic nature of the\ndata augmentation should make it easy to distinguish the two cases, in a way\nthat might not be seen with more realistic data models.\n\n4) Local variations in data distribution or feature relevance (e.g. as with a mixture of local submanifolds of differing dimensionalities) is not considered at all.\n\nOther comments / questions:\n---------------------------\n\n1) It is true that not much work has yet been done on the concrete effects on intrinsic dimensionality due to the addition of new dimensions.  However, there is still quite a bit of recent work on the intrinsic dimensional characteristics of data, and the uses of intrinsic dimensional estimation in deep learning. It would be good to include in the paper a short survey and and a discussion of ID. Can you develop a model of additional features that is true to the intrinsic dimensional characteristics of real data?\n\n2) The data mining community has had much to say about models of feature\nrelevancy similar to the one considered in this paper, even down to the way in\nwhich datasets were generated for the experiments. Discuss?\n\n3) In section 3.2, in the discussion of the Stanford Dogs dataset, you expect no bias between dog classes due to the backgrounds. Could there be bias due to the size of the dog breed?\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Intuitive empirical findings, but missing a take-away message",
            "review": "### A. Summary\nThis paper studies the effect of unnecessary input dimensions on a model's data efficiency. They consider two types of necessary input dimension: task-related (duplicated dimensions), and unrelated dimension (noise). On a linear model, they provide theoretical justification that unrelated dimensions hurt the generalization performance while having task-related unnecessary dimensions helps to compensate the performance drop. The remainder of the paper provides empirical evidence on how this observation also applies to deep-nets with the architecture of MLP or CNN.\n\n### B. Decision\nI recommend a borderline reject for this paper. My main concerns are: (1) the assumptions on the ``unnecessary dimension’’ is a little bit strong. (2) The implication from this study seems unclear to me. For example, “These results highlight the need for ... crops or foveation for image classification.”. I mean, image classification datasets already crop the images so the label can be well defined.\n\n### C. Reasons\n1.\tThe task-related dimensions are defined to be linear combinations of the necessary dimensions. In other words, these extra dimensions do not contain any randomness given the necessary dimension. This assumption isn’t true for image data where each input dimension (pixel value) contains sensory noise that is independent of the object (the necessary dimension).\n\n2.\tIn A.1,  the paper shows that when the number of task-unrelated dimensions is large, then it corresponds to the Tikhonov regularization term. In A.2, it shows that this regularization is mitigated by the task-related dimensions. Specifically, the result in A.1 seems to be suggesting that the task-unrelated dimensions can “prevent” overfitting, as it is equivalent to regularization term? It is unclear to me what is the take-away message here; I thought of advocating for the removal of the task-unrelated dimensions. \n\n3.\tThe definition of AUTC in B.4 is confusing. “n_tr the amount of examples in the training set”; So n_tr is an integer? Yet, in Eq. (23) there is a $\\max(n_{tr})$. Following the equation, I am not exactly sure how AUTC is being computed. \n\n4.\tThe detailed and comprehensive empirical results is the main contribution, in my opinion. While the results might be expected and intuitive, at least in computer vision. I do think there is value in reporting and documenting intuition in a paper. However, I do think there needs to be a stronger motivation; I am not convinced by the cropping argument for object recognition. More specifically, wouldn’t the cropping procedure (if it is learning based) also be affected by these ``unnecessary dimension”? \n\n### D. Additional feedback \n•\tCaption of Fig. 6 “we move from the edges of the hidden representations of test images to their centers”. Not exactly sure what is being done here.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A disappointing paper",
            "review": "This paper aims to provide insights into the ''data efficiency'' of the deep learning system, by introducing the terms ''task-related'' and ''task-unrelated'' dimensions of the data. The main claims of this paper are: task-unrelated dimensions harm the data efficiency while increasing the task-related (redundant though) dimensions can neutralize this effect. \n\nI think the problem defined by this work is important and could have good impacts on this community. Also, the related work part regarding the ''impact of object's background'' is nicely summarized. I was really excited to read the sentence ''our work is the first to report that the presence of (the) object's background harms the data efficiency of the network when the object's background is unbiased''.\n\nHowever, neither the theoretical nor the experimental analysis convinces me, I will argue to reject this paper if no substantial improvement is made.\n\nTheoretical part: First of all, there is no formal definition for ''data efficiency'', it seems the authors are talking about the ''generalization error achieved by certain amounts of training data''. However, the equations are not focusing on this. Perhaps an error bound w.r.t the # of task-related/unrelated dimensions can be computed, which is much stronger than the current ones. Second, the conditions considered are too simple to support the claims. The definition of ''task-related dimensions'' is restricted to linear combinations of existing dimensions, while ''task-unrelated dimensions'' are only considered as Standard Gaussians. Under this assumption, it is not hard to obtain the conclusions on page 4, hence the novelty is limited in my opinion.\n\nExperimental part: The configurations of the experiments baffle me heavily in many ways: (i) The choice of datasets, (ii) the ways of the generation of task-related/unrelated dimensions, (iii) the designs of network structures, (iv) the analysis of the activations. \n(i) It is very unclear what is the minimal dimension for these digits to be classified correctly. For instance, does the thickness of the strokes matter? Can we consider the MNIST contains many task-related dimensions initially? In my opinion, the proof-of-the-idea has been achieved with artificial datasets, therefore you only need to focus on more complicated and large-scale datasets, such that the experiments could be more convincing.\n(ii) If I am not wrong, the generation of additional dimensions changes the structures of the networks, despite the ''adapt'' structure (btw I am also confused about the $r$ in Table 1). Therefore it is unsure if other factors affect the results of the experiments. \n(iii) To be honest, I have really no idea about what a network with a filter of 27x27 and a pooling size of 18x18 looks like. I do not think these experimental settings make sense in practice. I suggest the authors carefully exam the behaviors of the proposed network structures before using them as baselines.\n(iv) This analysis is just off-the-topic. The claim on how the network obtains data efficiency is just weak and weird to this paper.",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}