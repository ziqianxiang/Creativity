{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "Pros: Reviewers generally agreed the paper was well written and is easy to follow. The goal of learning loss functions also seems quite promising.\n\nCons: There were concerns about whether credit for experimental performance was attributable to the core algorithm+functional form presented in the paper. There was also some skepticism about the specific form of the learned loss. Of greatest concern, no reviewer argued for acceptance during discussion, and one reviewer lowered their score during discussion."
    },
    "Reviews": [
        {
            "title": "This paper investigates the optimization of loss functions through multivariate Taylor expansion. ",
            "review": "In this paper, the authors studied the optimization problem of loss functions, where the loss function is not referred to as the error criterion but the empirical error term in empirical risk minimization. The main approach proposed in this paper is the polynomial parametrization of the loss function via multivariate Taylor expansion, namely, equation (5), which should also be regarded as the main contribution of this paper.   \n\nPros: The paper is well written and is easy to follow. The main approach and its rationality are well articulated. It is good to see that different approximates of loss functions are compared. The effectiveness of the proposed approach is also well illustrated numerically.\n\nCons: While I believe that the proposed approach works, it is not clear to me what is the relation between the newly proposed approach and the original approach where loss functions are used directly instead of their approximates. In my opinion, the new approach works not because of the approximate of the loss function but because of the new error criterion which is essentially a polynomial. This gives my main concern. I'm expecting more comments in this regard.       ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting idea and exciting area of work! How can we isolate effects of loss fn optimization vs. learning rate, etc?",
            "review": "Warning: I'm not an expert in loss function metalearning, so I've attempted to provide my perspective as someone interested in the topic but unfamiliar with prior work.\n\n# Summary\n\nThis paper tackles the problem of loss function metalearning by proposing a novel parameterization of loss functions based on multivariate polynomial expressions.\n\nThe intuitive motivation is that any continuous and full differentiable loss function can be written as a $k$-th order multivariate Taylor expansion (i.e. a multivariate polynomial expression). So for high enough $k$, the space of such polynomials will be a reasonable approximation of the space of all loss functions we might care about.\n\nThe claimed advantages of the method are smoothness, lack of poles, compositionality, meaningful metric (closeness in parameter space ==> similar loss function), and tunable complexity (via $k$) of the search space.\n\nThe paper then proposes a loss function optimizer named TaylorGLO, which proposes to optimize loss functions in parameter space (i.e. coefficient space) using CMA-ES, which requires a continuous optimization space.\n\n# Strengths\n\nThis is a neat idea, although I think calling it TaylorGLO is a bit of a misnomer as we're not starting with arbitrary functions that we're then approximating via Taylor expansion. Rather, the paper optimizes directly in polynomial space. Maybe \"PolyGLO\" is a more accurate name? The point can be made within the paper text that for sufficiently high $k$, the space of polynomials becomes an arbitrarily good approximation of any cont/diffble loss function thanks to Taylor's thm.\n\nRegardless, I really like this approach! It definitely seems like a more promising approach than the referenced prior approach, which first optimizes the structure of the loss fn in discrete (tree) space and then optimizes the coefficients via continuous methods. The fact that the experiments found a function that outperforms \"BaikalCMA\" is welcome confirmation that we don't lose much by staying in continuous space.\n\n# Weaknesses / unanswered questions\n\nI'm worried that to some extent, the improvements from the new loss functions are thanks to an implicit learning rate tuning effect. The derivative of the loss function w.r.t. the model output directly scales the parameter updates for backpropogation-based SGD. So, maybe what's happening is that the learning rate is being tuned implicitly by TaylorGLO choosing a steeper or more compressed loss function. Maybe there's even a learning rate *scheduling* effect that's coming from TaylorGLO choosing loss functions with higher curvatures.\n\nI think it's quite important to disentangle the effects of the loss function optimization from an implicit learning rate tuning, so I would ideally like to see experiments comparing TaylorGLO's best-accuracy loss function with plain old CE sweeped across learning rates and LR scheduling approaches. The difference in accuracy between TaylorGLO and a comprehensive CE sweep will be a more accurate indication of the effects of the loss optimization itself.\n\nI'm also curious to know the extent of prior art in continuous loss function optimization. This approach seems like the first thing one would do if trying to design a loss function metalearning approach in continuous space, so I'd like to hear about what (if anything) has been done before.\n\n# Overall Rating\n\nI rate this paper a 6. I would be happy to see it in ICLR as is, but I think for its results to be exciting to the ICLR audience at large, the paper needs to convincingly isolate the effects of the function optimization itself.\n\n# Comments\n\n- p.1 \"arbitrarily long, fixed-length vectors in a Hilbert space\" seems self-contradicting. Is this meant to say \"arbitrary norm\"?\n- Formatting of some of the \\citep's can be improved, e.g. CMA-ES.\n- I'd love to see a comparison of classification accuracy between standard cross-entropy and $k$-th order approximations of CE to get a sense of how much the fidelity loss actually matters.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Interesting idea, but not convincing enough",
            "review": "This paper proposed a method, called TaylorGLO, to learn the loss functions, for training deep neural network, by meta-learning. Specifically, the authors proposed to parameterize the loss function with multivariate Taylor polynomial, and then learn the parameters in the polynomial using evolutionary algorithm within the meta-learning framework. The experiments showed improved performance of the TaylorGLO over cross-entropy baseline on several datasets and with different network architectures.\n\nAlthough the performance seems promising, there are several issues should be addressed:\n\n1. My major concern is about the parameterization of the loss function. As is well known, a qualified loss function in machine learning generally contains only one valley concerning its geometric shape. However, with Taylor polynomial parameterization, a function might have multiple valleys, or even have no minimum.\n\n2. The authors set the order of Taylor polynomial to 3, and simply claimed this is a better trade-off compared with other orders. However, this claim should be supported by empirical evaluations, i.e., use other orders to see the differences regarding the performance and evolution time.\n\n3. Since the expensive evolutionary process is required to learn the loss function before really train the model, the computational cost should be shown and discussed in detail, especially that the performance improvement is not that much in some cases as shown in Table 1.\n\n4. The comparison with GLO was only performed on MNIST dataset, where the accuracies between the two methods are very close.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Useful idea, but evaluation could be improved.",
            "review": "This paper presents the TaylorGLO method for learning loss functions for classification.\n\n## Pros\n1. The paper is well written and quite easy to follow.\n2. It proposes the novel idea of parameterising learned loss functions as Taylor polynomials, which overcomes the downside of previous work that relies on a slow two-stage optimisation process that first infers the structure of the loss function.\n3. Networks trained with the learned loss functions typically outperform those trained with cross entropy.\n4. Analysis is undertaken to determine why the learned loss functions work better than cross entropy (they penalise overly confident outputs), and also characterise when the loss functions discovered with TaylorGLO are most effective (better sample efficiency).\n\n## Cons\n1. The main performance comparison is with cross entropy, but there exist other methods for learning loss functions (e.g., GLO and [1]). The performance comparison with these methods should be more comprehensive: currently there is only a single comparison with GLO that uses a simple network trained on MNIST, which is not enough to make general conclusions about the relative performance of the two methods.\n2. The potential for impact is limited. The main improvements in performance over cross entropy are seen when using older network architectures, but when using state of the art networks the improvements are much smaller. If it was shown that the learned loss functions could be transferred to new tasks, hence resulting in a modest performance increase without any additional computational overhead, then I would be inclined to revisit this point.\n3. It is unclear what hypothesis is being tested when applying t-tests: given that the same data is used for each performance measurement it seems the hypothesis is that performance gains are robust to the choice of random seed. Hypothesis tests are typically used in machine learning to determine whether the experimental results will generalise to new tasks [2]. As they are currently presented, the results are likely to mislead some readers into inferring a false sense of generality of the results.\n\n## Questions\n1. Why use CMA-ES over gradient-based bi-level optimisation methods commonly used in meta-learning? Gradient-based optimisation is typically faster than evolutionary methods, and it seems like it would be possible to apply it in this situation.\n\n[1] Sarah Bechtle et al. Meta-Learning via Learned Loss. arXiv:1906.05374, 2019.\n[2] Janez Demšar. Statistical Comparisons of Classifiers over Multiple Data Sets. Journal of Machine Learning Research, 7(1):1−30, 2006.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}