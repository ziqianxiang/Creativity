{
    "Decision": "",
    "Reviews": [
        {
            "title": "Nice work but poor validation",
            "review": "##########################################################################\n\nSummary:\n\n \nThe paper proposes an attribution method via feature map importance. The method provides a way to solve the gradient saturation problem allowing the information to backpropagate even when the gradient approaches to zero. The paper is validated following 4 research questions.\n\n##########################################################################\n\nReasons for score: \n\n \nOverall, I vote for reject. I like the paper and I think that it provides nice ideas, however I think the experiment results are not sufficient.\n \n##########################################################################\n\nPros: \n\n \n1. The method. \n\n2. Research Question that tries to solve\n \n \n##########################################################################\n\nCons: \n\n1. The validation\n-  Regading RQ1. An average explanation of 86.9% is obtained with MNIST with 10 classes while 88.4% with Imagenet with 1.000 classes. It is surprising the high accuracy on Imagenet. However, on MNIST the accuracy is lower. Why is it happening? It would be interesting to see the show the resulting prototype and to justify the results.\n- Regarding RQ2. It would be great to visualize more examples. \n- RQ3 is only performed with (collie and Ibizan). More classes should be used\n- It would be great to visualize the weak point of the methods. Where is the method failing?\n\n\n\n \n##########################################################################\n\nQuestions during rebuttal period: \n\n \nPlease address and clarify the cons above \n\n \n#########################################################################\n\nSome typos: \n\nPage 1: aprroximation -> approximation\nPage 2: thier -> their\nPage 2: referece -> reference\nPage 2: embeding -> embedding\nPage 3: Backpropogation-> Backpropagation\nPage 8: Thier -> thier",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Well written paper; Interesting results; Limited contribution;",
            "review": "**Summary:**\nThis paper is about finding the attribution of regions in the input images of neural networks that most contribute to a certain classification result. The paper first summarizes and categorizes existing work in this research area and proposes a novel feature-map-based attribution model. Specifically, the authors address the gradient saturation problem in existing work (like grad-cam) and propose to alleviate it by approximating the gradient of non-linearity with a first order Taylor series. Similar to prior work, the authors also include a reference image in the estimation of attribution, but in this case for a feature-map-based model.\n\n\n**Pros:**\n- The paper provides a great summary and categorization of existing methods, which helps placing the proposed method in context.\n- In general, the paper is clear and well written. Particularly, I think the experimental section is great by explicitly addressing specific research questions.\n- Great that code is available for reproducing results!\n- The saturation problem is well described and the idea of approximating the gradient (with essentially a larger step size in the numerical approximation, I believe?) seems reasonable.\n\n\n**Cons:**\n- I would suggest pointing to the quantitative evaluation earlier in the paper (put it as first section in experiments or mentioning it earlier). Otherwise, one always questions how to tell if method A is actually better than method B, in a sense that \"Who says that certain areas are more predictive than just the edges?\"\n- Averaging FMI maps/scores over training images to build a prototype per class may not be representative. What if multi-modal distributions define a certain class?\n- I think the statement \"An image that has no specific information for any class, i.e., has a near-zero prediction score, can be a proper reference\" on page 5 is an important detail that should be highlighted and further detailed.\n\n\n**Open questions**\n- I do not quite understand the faithfulness analysis. This can only be about saying that the FMI maps are representative of the class predictions, but it does not tell anything about attribution (explaining contribution of input image regions to class predictions), right?\n- It seems the values of the saliency map can be arbitrary, according to Equation 7 (difference of feature maps). How is the saliency map then normalized to make it comparable to maps from other classes?\n- I'm wondering if data sets with bounding box annotations could help in creating other metrics for evaluating this attribution problem quantitatively?\n- If I understand Equation 2 correctly, it seems that with the reference (image) $\\bar{y}$ the \"delta\" ($y - \\bar{y}$) in the approximation of the gradient is relatively large to essentially overcome potentially flat areas in the non-linearity? If I would approximate the gradient accurately, I would choose smaller deltas. Is this understanding right?\n- Overall, gradient-based estimation seems flawed for this use case. Just because the gradients are zero does not necessarily mean the input is not used. It can be that an input leads to a negative activation before ReLU, thus zero after ReLU, and the following layer only outputs the bias term. Assume this negative activation only happens for one class while all other classes get a higher activation and thus higher than just the bias. Negating this number would be a good logit for this class of interest. Still, the gradient would be zero at the ReLU. I guess this what is described in Section 3 as \"Gradient Saturation Problem\", but I would not say it is a \"saturation\" problem, rather than a certain configuration of a neural network. I guess one often assumes a discriminative features is high for one class but low for others. However, the opposite is also discriminative.\n\n\n**Minors:**\n- Last line on page 6: Should this point to figure 3?\n- Page 8: \"However, THEIR performances are unstable\"\n- Page 8: The text points to Figure 9 instead of Figure 6 for the predictive performance analysis.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Method is a hybrid of DeepLIFT Rescale rule and Grad-CAM, but equivalence is NOT made clear",
            "review": "To avoid burying the lede, I'm foregoing the usual format of these reviews in order to get directly to the point. The methods section of this work consists of 7 equations. The first 5 of those equations have rederived the DeepLIFT Rescale rule **without acknowledging the equivalence** (note that DeepLIFT at the pixel level is one of the baselines considered in the work). Essentially, the FMI for channel $k$ is equivalent to averaging the \"modified gradients\" derived from the DeepLIFT Rescale rule over all spatial locations for channel $k$. The remaining two equations are highly analogous to equations 1 and 2 of the Grad-CAM paper - this similarity is acknowledged only tangentially (the authors write \"note that feature map importance $\\text{FMI}^c_k$ differs from the importance weights in Grad-CAM\").\n\nI give specific examples of the similarities below.\n\nFor equation 2, the authors write: \"To avoid unreasonable gradient vanishing, we employ the first order Taylor series to better estimate $\\sigma'(y)$ using a reference point $\\bar{y_j}^{(l)}$, as:\n$$\\hat{\\sigma'}(y_j^{(l)}) = \\frac{ \\sigma(y_j^{(l)}) -  \\sigma(\\bar{y}_j^{(l)})}{ y_j^{(l)} -  \\bar{y_j}^{(l)}}$$\n\nCompare this to the modified gradient that is used during backpropagation in the DeepLIFT Rescale rule, as described in Table 1 of Ancona et al.:\n$$g = \\frac{f(z) - f(\\bar{z})}{z - \\bar{z}}$$\n\nThe authors then go on to write \"we can define the modified gradient of the $l$-layer's output $x_j^{(l)}$ w.r.t. $x_i^{(l-1)}$ as $\\frac{ \\partial^{\\sigma} x_j^{(l)} }{ \\partial x_i ^{(l-1)} } = \\sum_i \\hat{\\sigma'}( y_j^{(l)} ) w_{ji}^{(l)} $\". I am not sure the summation over all $i$ is supposed to be present on the right-hand-side, because when this summation is present,  the right-hand-side marginalizes out the value of $i$ while the left-hand-side still depends on $i$. Compare it to the following statement in Ancona et al. - \"for two units $i$ and $j$ in subsequent layers we have $\\frac{ \\partial x_j}{\\partial x_i} = w_{ji} \\cdot f'(z_i) $\".\n\nFinally, for equation 4 the authors write \"We further apply the chain rule of gradient to estimate the attribution of the original input $x_i^{(0)}$ to the final prediction $y_c^{(L)}$ of the last layer (before softmax) as\":\n\n$\\frac{ \\partial^{\\sigma} y_c^{(L)} }{ \\partial x_i ^{(0)} } = \\sum_{p \\in P} (\\prod \\hat{\\sigma'}_p \\prod W_p)$\n\nCompare this to Equation 5 of Ancona et al:\n\n$\\frac{\\partial^g  x_c }{ \\partial x_i } = \\sum_{p \\in P_{ic}} ( \\prod w_p \\prod g(z)_p ) $\n\nFinally, Equation (5) in the text is essentially a combination of several equations in the DeepLIFT paper. This is Equation 5 in the text:\n$y_c^{(L)} - \\bar{y}_c^{(L)} = \\sum_i \\frac{ \\partial^{\\sigma} y_c^{(L)} }{ \\partial x_i^{(0)} } (x_i^{(0)} - \\bar{x}_i^{(0)})$\n\nConsider the following equations from the DeepLIFT paper:\n\n$\\Delta t = t - t^0$ (from section 3.1 of the DeepLIFT paper)\n\n$ \\sum_i^n C_{\\Delta x_i \\Delta t} = \\Delta t $ (Equation 1 of the DeepLIFT paper)\n\n$ m_{\\Delta x \\Delta t} = \\frac{C_{\\Delta x_i \\Delta t}}{ \\Delta x } $ (Equation 2 of the DeepLIFT paper)\n\nIf those equations from the DeepLIFT paper are combined, they give:\n\n$t - t^0  = \\sum_i^n m_{\\Delta x_i \\Delta t} (  x_i - x_i^0 )$\n\nThis makes the similarity to Equation 5 clear. Here, $t^0$ denotes the reference value of neuron $t$, and $m_{\\Delta x_i \\Delta t}$ denotes the modified partial derivative (equivalent to $\\frac{\\partial^{\\sigma} y_c^{(L)} }{ \\partial x_i^{(0)} }$).\n\nFurther, while the authors have presented DeepLIFT as a method that can only be applied at the pixel level, **there is nothing stopping a user from calculating the DeepLIFT contributions at intermediate layers of the network** (i.e. the feature map layer) - in fact, the Pytorch Captum repository explicitly implements a version of DeepLIFT that can be used to compute attributions at an intermediate layer: https://captum.ai/api/neuron.html#neuron-deeplift.\n\nThe place where this method differs from DeepLIFT is in equations 6 and 7, because the authors *average* the modified gradient on the feature map over all spatial locations and use this average modified gradient to weight the difference-from-reference of the feature map. In this respect, the method can be viewed as a hybrid of DeepLIFT and Grad-CAM, because Grad-CAM also averages the gradients over all spatial locations. To make the similarities concrete, Equation 6 of this paper begins as:\n$\\text{FMI}^c_k = \\frac{1}{N} \\sum_i \\sum_j \\frac{ \\partial^\\sigma y_c^{(L)} }{ \\partial A_{ij }} = \\text{...}$\n\nAnd Equation 7 of this paper is:\n$S^c_{\\text{A-FMI}} = \\sum_k \\text{FMI}^c_k \\cdot (A^k - \\bar{A}^k)$\n\nIn comparison,  Equation 1 of the Grad-CAM paper (analogous to Equation 6 from this paper) is:\n$\\alpha_k^c = \\frac{1}{Z} \\sum_i \\sum_j \\frac{ \\partial y^c }{ \\partial A^k_{ij}  }$\n\nAnd Equation 2 of the Grad-CAM paper (analogous to Equation 7 from this paper) is:\n$L^c_{\\text{Grad-CAM}} = ReLU (\\sum_k \\alpha_k^c A^k)$\n\nIn essence, they have replaced the gradients in Grad-CAM with the modified gradients from the DeepLIFT Rescale rule, have replaced $A^k$ in Grad-CAM with the difference-from-reference $A^k - \\bar{A}^k$ (note that the difference-from-reference concept stems from the DeepLIFT and Integrated Gradients papers), and have removed the $ReLU$ from Equation 2 of the Grad-CAM paper (the ReLU was added in the Grad-CAM paper to focus only on positive contributions).\n\nThe value of this work comes from the fact that it demonstrates that reference-based method like DeepLIFT (and likely also Integrated Gradients) can produce better results when applied to compute contributions at an intermediate feature map layer, as compared to when these methods are applied to compute contributions at the input layer. For whatever reason, many papers in the literature only evaluate DeepLIFT and Integrated Gradients at the pixel level, and evaluate Grad-CAM at an intermediate layer - no paper has evaluated what happens when the attributions of DeepLIFT/IG are simply computed at an intermediate layer. This paper is the first to do so, by creating the Grad-CAM equivalent of DeepLIFT. However, the considerable similarity to DeepLIFT is NOT made apparent to the reader.\n\nThe obvious baseline that is missing from this work is what happens when DeepLIFT (or Integrated Gradients) attributions are simply computed at an intermediate layer (using the same reference as what is used in this work), and then the attributions are summed over all feature maps $k$ at a given spatial location. Note that DeepLIFT attributions are \"multiplier (a.k.a. modified gradient) multiplied by difference-from-reference\". The main difference between this baseline and the proposed A-FMI method would be to remove the Grad-CAM-like averaging of the DeepLIFT \"modified gradients\" across all spatial positions. It has in fact been shown that the Grad-CAM-like averaging over spatial positions causes a degradation of the performance of Grad-CAM when it is applied to lower layers (see section \"Explanation of Grad-CAM failure mode\" in Rebuffi, Fong, Ji & Vedaldi, CVPR 2020 [2]), and the baseline I have suggested here (i.e. simply averaging the DeepLIFT attributions over all $k$ feature maps at a given spatial location) would be analogous to the \"linear approximation\" method used in [2] (but with the gradients replaced by DeepLIFT multipliers, and the activations replaced with the difference-from-reference). \n\nThere are additional baselines to consider, such as the FullGrad method (https://arxiv.org/abs/1905.00780). The authors should also explore more systematic benchmarks such as those offered by the BAM dataset: https://github.com/google-research-datasets/bam\n\nIn Figure 4, I find it odd that the visualizations for DeepLIFT appear to be completely identical for the three classes; it almost appears as though the same image may have been copy-pasted 3 times. The DeepLIFT method is known to exhibit class-specificity (https://arxiv.org/abs/1912.09818) and was also shown to have high correlation with Integrated Gradients [1], so it seems very odd that there is no apparent visual difference in the attributions for the 3 classes, when Integrated Gradients is showing a difference.\n\nOverall, I am very disappointed that the authors did not appropriately acknowledge the considerable similarity of their method to previous work. It is fine to present methods that are simple combinations of previous methods (so long as they are acknowledged as such), but for such papers the empirical benchmarking would need to be more thorough, and the authors would need to explore the space of possible method combinations more exhaustively. Based on this, I cannot recommend acceptance.\n\n\n[1] \"TOWARDS BETTER UNDERSTANDING OF GRADIENT-BASED ATTRIBUTION METHODS FOR DEEP NEURAL NETWORKS\", ICLR 2018: https://arxiv.org/pdf/1711.06104.pdf\n\n[2] https://openaccess.thecvf.com/content_CVPR_2020/papers/Rebuffi_There_and_Back_Again_Revisiting_Backpropagation_Saliency_Methods_CVPR_2020_paper.pdf",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review on Paper1669 ",
            "review": "Summary\n\nThis paper presents a method that devises feature map importance (FMI) to resolve the gradient saturation problem in feature map-based attribution methods. To be specific, this paper introduces the attribution method via FMI (A-FMI) equipped with difference-from-reference. Mathematically, this paper provides the derivation of A-FMI that can resolve the gradient saturation problem. Finally, there are four kinds of experiments to show the abilities of the proposed method. \n\nOverall,  about this paper, I am leaning on the positive side. My comments are as follows.\n\n Strength\n\nThe motivation of the paper is clean and looks sound. Also, the paper provides various analyses to demonstrate the benefits of the paper.\n\n\nComments and Weakness\n\nIn experiments about the faithfulness of A-FMI, the definitions of global and local faithfulness are ambiguous. It is better to explain the difference more clearly. Are reported 86.9% and 88.4% average of local faithfulness? Is there a performance report for global faithfulness?  Is the second paragraph of 4.1 section about local or global faithfulness? It would be better to understand if they are more kindly described. Also, is there any comparison experiment with other networks including ResNet other than VGG19? Finally, is there no comparison with other existing attribution methods?\n\nIn experiments about reference reliability,  if a natural image is used as a reference, what will the result be? And the results of DeepLIFT and IG are so bad compared to A-FMI, is there a special reason?\n\nIn experiments about class discriminability,  I wonder what happens if different rates are set than 10%. Also, I wonder what tendency when there are more than two objects.\n\nIn experiments about overall performance comparisons, what is the performance like when the proposed method is applied to various tasks such as object detection and segmentation? In particular, I wonder if there is a possibility of applying the A-FMI in weakly-supervised object detection or segmentation. If possible, what are the advantages of the proposed method over existing methods?\n\nTwo lines above equation6, there is a type “Equation equation”.\nAfter all equations, there should be a comma or period.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}