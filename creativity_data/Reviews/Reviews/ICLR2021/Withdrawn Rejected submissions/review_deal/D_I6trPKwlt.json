{
    "Decision": "",
    "Reviews": [
        {
            "title": "Official Blind Review #1",
            "review": "This paper proposes a new graph pooling algorithm that learns a coarsening matrix which maps nodes from an original graph to a coarsened graph. The learning/pooling loss comprises two terms: first,  based on the similarity/difference between node feature vectors and second, that encourages the original graph to be spectrally similar to the coarsened one. Experiments  are shown on graph benchmarks as well as  on image retrieval problem on visual scene graphs\n\nNovelty:\nThe paper mainly deviates from prior work by including spectral similarity between the original and coarsened graph into the overall pooling loss function. This spectral similarity is based on the Fiedler vector which is shown to approximate/upper bound the RSS approximation between two graphs (Loukas 2019).\n\nClarity and Presentation:\n The paper is overall well written and motivated.\nMinor comment: Given that it is a central point of the paper, I would have liked more discussion in the introduction on how maintaining topology during coarsening is very useful instead of one line. #Even though these approaches can be trained in an end-to-end manner, it is hard to maintain the topology#  Perhaps, authors can move Figure 3 earlier in the paper or refer to it in the introduction part.\n\nExperimental Validation:\nExperiments and Discussion on Visual Genome dataset are convincing and appreciated. Validation in Table 1 is not completely convincing though where this work lags behind some baselines that do not incorporate the two main findings of this work.\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This paper tackles an interesting problem on GNNs. However, the current presentation and evaluation of the paper is not good enough",
            "review": "Graph Neural Networks (GNNs) is an increasing popular topic of research in machine learning on irregular graph-structured data.  This paper tackles the problem of graph pooling and presents Spectrally Similar Graph Pooling (SSGPool) algorithm for learning hierarchical representations of the graphs. The main idea of the paper is to learn a coarsening matrix (surjective mapping of the nodes) to coarsen nodes while keeping the structural and feature information. To keep the structural information, it maximizes the similarity between the Fiedler vectors of the original and coarsened graphs while using standard GNNs for keeping feature information.\nThe idea of the new pooling algorithm is interesting. However, the current presentation of the paper has several shortcomings. I would suggest the following comments to further improve the quality of the paper. \n•\tThe contributions of the paper are not clearly mentioned in the current draft. I would suggest clearly mentioning the contributions and differentiate them with the existing methods. \n•\tThe proposed pooling algorithm uses Laplacian matrix to obtain adjacency matrix for the coarsened graphs- Eq. 5 (instead of the Adjacency matrix) which is quite interesting and has several benefits as compared to the existing approaches. I think it would be interesting to see a results comparison in terms of classification accuracy (Table 1) of using the adjacency matrix and the newly proposed Laplacian matrix for obtaining new coarsened adjacency matrix during the pooling.\n•\tMy major concern is the limited evaluation of the proposed method. Only four bioinformatics datasets: mutag, enzymes, proteins, and nci1 are chosen for the comparison. I would encourage the authors to run experiments on DD, collab, imdb-binary, imdb-multi, reddit-binary and reddit-multi datasets and provide a comparison. Such comparison would be helpful to better highlight the performance of the proposed method on different kinds of datasets. Also, the current results are marginally improved only on two datasets which is not enough for comparison  \n•\tWang et al., (2020) have recently proposed quite relevant graph pooling algorithm. Their results are encouraging, also the source code is publicly available. I would encourage the authors to consider this method for the comparison too.  \n•\tThe authors are encouraged to release their code and pre-trained models for foster reproducibility of the results\n•\tA proofread is suggested to avoid some minor mistakes, e.g., Fiedler vector vector (section 4.4) etc.\n\n\n\nReferences:\nWang, Z., & Ji, S. (2020). Second-Order Pooling for Graph Neural Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This is an interesting and well-motivated paper that proposes a method based on spectral similarity for learning hierarchical representations. This is a nice contribution to a developing literature using spectral methods to extend deep learning on graphs. ",
            "review": "This paper introduces a new pooling algorithm for hierarchical representation of graphs. The key idea is to combine structural and feature based approaches to coarsening using spectral similarity building on important recent work of Loukas and Loukas and Vandergheynst and a message passing formulation similar to recent work  by Xu et al. on Graph Isomorphism Networks. The specific pooling method also uses the Laplacian rather than the adjacency matrix for spectral similarity regularization. This approach is a very promising new direction, even if it isn't entirel novel in this paper, and the literature review presented here is a useful summary of the main contributions leading to this point. \n\nThe experiments presented are comprehensive and useful, particularly given the space constraints of the conference format and show that the method achieves near state of the art performance on a common set of benchmarks. The image retrieval example is an interesting way to highlight the hierarchical properties that are learned by the model and Figure 3 is a useful summary. \n\nFigure 2 is a little overwhelming and dense although it is helpful after parsing the rest of the paper.  ",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Official Blind Review #3",
            "review": "Summary:\\\nThis work follows the recent direction of investigating different pooling methods to better capture hierarchical structures in graphs. Authors propose to learn to coarsen a graph from node features in addition to graph structures and use the coarsened graph to aggregate information.\nThe proposed SSGPool coarsen based on pooling using spectral methods while also regularizes by maximizing a similarity between the spectral structure of the coarsened and the original graph.\n---\n+Strengths:\\\n+This paper tackles a relevant problem of better capturing hierarchical structure in graphs.\\\n+The approach is well motivated and outlined.\\\n+Beyond typical graph network benchmark, authors experiment on image retrieval problems using scene graphs where structure may be more apparent.\n---\n-Concerns:\\\n-Authors claim existing structure-based pooling methods do not incorporate node features. This claim is quite strong and not accurate. Methods like EigenPool cited in this paper incorporate node features in their spectral clustering approach and address very similar issue as this paper.\\\n-A key novelty is regularizing coarsening based on spectral similarity; this part could be explored better. The one ablation study included in table 1 is not very convincing that this is a good idea as regularization does not seem to lead to a significant improvement across settings. Other analysis including appendix do not investigate this difference further.\\\n-Many of the recent reviewed approaches in the related work are not included in the main table (Table1), and there are no comparison with approaches from this year (2020). This compounds previous concern on the validity of the claims.\n---\nRecommendation:\\\nThis paper propose a novel regularization method to maximize spectral similarity which I do find interesting. I am not thoroughly convinced by its efficacy based on provided experiments and have concern about some strong claims made by the paper. At the current state of the paper, my recommendation is borderline leaning towards rejection.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}