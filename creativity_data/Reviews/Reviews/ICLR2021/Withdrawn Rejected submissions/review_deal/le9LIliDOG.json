{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This work proposes an efficient method for modelling long-range connections in point-cloud data. Reviewers found the paper to be generally well-written. On the less positive side, reviewers felt that the novelty of the work was marginal, and that the experimentation, limited to synthetic data in one domain, was too limited. These concerns remain after the discussion phase. In addition, the authors stated during the discussion that \"Our goal is indeed to develop an efficient strategy to model LRIs in real chemical and materials systems”, which conflicts with the presentation of the work as motivated by more general point cloud modelling problems. Given these weaknesses, the final decision was to reject."
    },
    "Reviews": [
        {
            "title": "Utilizing the nonuniform FFT, a long range convolutional layer (LRC) is presented. A neural network which combines both LRC and short range conv layers are built. In a two-scale training strategy, first many small-scale data are trained without the LRC, then a small set of large-scale data are trained with both short and long range conv layers. The model is tested on 1D and 2D screened Coulomb particle configurations to estimate the overall potential energy and forces. ",
            "review": "The paper is clearly written, and presents an approach to efficiently utilize long range convolutions through a nonuniform FFT in for coulomb particle configurations. \n\nPros: \n- Presents a long range convolution layer, with an efficient implementation so that a neural network model can benefit from both short and long range interactions among data points. \n\n- To model pairwise relations between points of the N-body potential, two short range descriptor networks are utilized, where the input relations are constructed both repulsively and attractively. \n\nCons:\nExperimentally, the new long-short range NN model is validated only for computing the energy and forces for a N-body model. There are no experiments with real-life point cloud data.\n\nIn the proposed algorithm, a sampling in a regular grid is required. A fixed size Cartesian grid is utilized in the experiments, therefore, the effect of the gridding resolution is not analyzed.\n\nThe quantitative experimental results in Tables 1, 2, and 3 dwell on varying the screening coefficient mu, hence investigates how the test error changes for point configurations with varying screening parameters, which signifies the amount of diffusion of the potential. It can be seen that the test error for the proposed approach falls as the screening gets higher, that is when we have more localized interactions between the particles. What could be the significance of this finding for a practical application is not discussed, therefore not made clear. \n\nThe authors state that the proposed method could be a useful tool in a wide range of Machine Learning tasks. However, in the paper, only estimation of potential energy for Coulomb particle configurations is demonstrated as an application. I am curious to see how the presented approach could find use in learning tasks of real point cloud configurations.\n\nThe paper presents a way to incorporate long range convolutions in neural networks, which could be beneficial. However, experimental evaluation is not satisfactory, as immediate implications in point cloud analysis is not obvious. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper needs to make changes in some aspects.",
            "review": "This paper concentrated on exploring how to efficiently extract the interaction information from the point clouds.  A key point lies in utilizing the non-uniform Fourier transform, rather than the regular Fourier transform. However, there exist some issues that need to be solved. \n\n+ves: \n+ The exploration of long-range interactions for point clouds is interesting.\n\n+ The paper is well written. The related work makes a clear description of many fields about point cloud.\n\nConcerns: \n1. In the introduction part, the authors describe many tasks that rely on point-cloud presentation. However, the authors ignore pointing out the existing issues. The authors should clearly present them.\n\n2. In the algorithmic section, the authors claim that \"NUFFT serves as the corner-stone of the LRC-layer\". So \"NUFFT\" is the unique solution? Whether or not some operations can replace FFT? \n\n3. Point-cloud is indeed important for many tasks as described in the introduction part, but the authors just explore the effects of the proposed algorithm in a \"synthetic\" experiment. The experimental results are not convincing for readers, the authors should conduct more real-world tasks to verify the effectiveness of the proposed method.\n\n4. The presentation of this work needs to improve, if possible, the authors should provide an intuitive schematic diagram to present the procedure of proposing this idea.\n\n5. In the experimental section, the author should replot Figure2-3 to ensure clear enough for a better read.  \n\n#########################################################################\n\nMinor Comments:  \n\n(1)  “N_sample” and \"N\" maybe exist the inclusion relation，it will be better to replace one of them with the other form;\n\n(2)  The formula system is a little vague, if possible, the authors can simplify them to clearly describe.\n ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting work",
            "review": "The paper proposes an efficient long-range convolution method for point clouds by using the non-uniform Fourier transform. The long-range convolutional (LRC)-layer mollifies the point cloud to an adequately sized regular grid, computes its Fourier transform, multiplies the results by a set of trainable Fourier multipliers, computes the inverse Fourier transform, and finally interpolates the result back to the point cloud. The method is demonstrated to be effective by a N-body problem.\n\nOverall, the paper is clearly written with high quality. The originality of the paper seems to be not very strong since it directly adapts the NUFFT to this work. Besides that, there are several concerns about this paper that need to be addressed:\n\n1. How to choose the grid size L_{FFT} in the Fourier Space? How does this parameter affect the results?\n\n2. The global pooling layers in DNN can also capture the long-range information to some extent, and are also very efficient. How does the LRC compare with the global pooling layers?\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "good improvement of existing method is presented, experiments could be improved",
            "review": "Edit: I was unaware that papers could be submitted to arXiv simultaneously, I am sorry for that. Here is my (very late) review.\nI made it before reading other reviewers' reviews.\n\nAn efficient method for fitting long-range style interactions in point clouds is presented.\nIt makes use of NUFFT rather than convoluting a long-ranged (thus system-size and expensive) kernel directly in real space.\nAlong with this architecture, a method for training it efficiently is presented. This 2 steps strategy consists in training the short-range part of the kernels well with a lot of (supposedly inexpensive) short range data, and fitting the long-range kernels with less data in a second time.\n\nOverall, the paper is clearly written and clearly exposes the methods used.\nThe results are interesting for applications but do not seem ground-breaking (although I am not an expert of point clouds -specialized networks).\nIn terms of experimental results, I think a couple of points would deserved to be answered (see below).\n\nIn conclusion, I think the paper is marginally above acceptance level.\n\n\nIn terms of results, the paper clearly shows that NUFFT scales essentially like O(N) (with N the points number) whereas naive direct space convolution scales as O(N^2).\nHowever, when I read the algorithm (page 3), my main curiosity is : how well does the algorithm deals with large systems (large domain \\Omega), and the competing parameters seems to be the resolution of the function g_\\tau (which plays the role of mollified dirac) versus the system size \\Omega or L. Concretely, I expect that for too large \\tau/L (presented in appendix, Equation 20), the precision of the long range kernels will be poor and error will be large; and in the opposite case of very small \\tau/L, precision will be good but compute time will increase (I guess it would increase as FFT does, in O(L/\\tau log(L/\\tau))).\nProbably there is a regime where direct convolution (which does not need the approximation introduced by g_\\tau, as far as I understood), is better then the NUFFT approach introduced here. I would guess that in the large system size (large \\Omega=L^d) and small particles number N limit (i.e. the low density limit), the direct approach does well ?\nI think such a discussion (and possibly a couple of experiments) would improve the paper a lot, showing the limits of the method and letting the reader understand the reasons for its strengths (which are very real, I do believe it !)\n\n\nA bit more of commenting on the experiments' results would be appreciated. For instance, it seems that the 2-scale training strategy is especially efficient (not needing many samples) when the LRIs are sufficiently strong (figure 3, right). This is probably an effect of the \"screening\" of LRI by short-range Interactions when alpha_1 is tooo strong compared to alpha_2, making it harder to learn about LRIs.\nAlso, the fact that all curves essentially collapse beyond a given N_sample could receive a comment.\nA couple of remarks like that about the strengths and limits of the approach would be nice.\n\n\nAside from these 2 main comments, I have minor remarks of presentation:\n- figure 2 left and figure 3 both sides: poor choice of colors/linestyles. Curves come in pairs, and this should be suggested in the choice of display, using similar colors for pairs, and different linetyles in different pairs. It would improve readability (also, think of the color blind people!)\n- fig2 , right: the O(N), O(N^2) scalings are un-readable. make them parallel to the plots you do and simple black dashed to improve clarity.\n\nIn the tables, although here results are \"trivial\" (always the same line has the smallest error), you could use the convention of putting in bold the better numbers.\n\nTable 1, you say \"mu_2 can be arbitrary here\". What you mean is that it needs not be defined, because alpha_2=0 ?\nI found this sentence confusing (maybe it's just me).\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}