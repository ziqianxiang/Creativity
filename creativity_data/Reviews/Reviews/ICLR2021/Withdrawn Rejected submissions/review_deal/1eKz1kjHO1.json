{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The reviewers were split (with all scores hovering around borderline) and I found it difficult to reach a conclusion. I like the paper, and agree with the authors that it may offer an interesting \"middle ground\" between bottom-up and top-down approaches. On the other hand, I was concerned with some of the execution flaws that were brought up in the reviews, in particular, insufficient comparisons to other embedding methods, lack of results on COCO, and to a significant degree, lack of focus in presentation. I think this could be a much stronger paper, and it will benefit from additional time to line up those missing components.\nTo clarify the concern re: experiments on COCO, since the authors bring up computational constraints: I agree that running these experiments during the rebuttal period is not a reasonable expectation. But the conclusion is that these results should have been in the original submission! Semantic/panoptic segmentation is now a very mature area, and COCO (along with CityScapes) is one of the standard benchmarks. (BTW, \"different methods often perform similarly\"  on COCO and CityScapes, but not always -- partially due to the significant differences in the statistics of the two datasets). I don't think it's reasonable to have a submission in this area which does not include results on it, since it makes it very hard to assess how much empirical progress is being made."
    },
    "Reviews": [
        {
            "title": "This work proposes a metric-learning-based framework, panoptic segment sorting, for performing panoptic segmentation. The proposed approach achieves competitive performance on cityscapes and pascal voc.",
            "review": "Pros\n\nThis work is well written and easy to understand. The idea of assembling over-segments sorting, segments merging, dynamic partitioning, and seed selection is interesting, which can be applied to many downstream tasks, like panoptic segmentation and instance relationship modeling.\n\nCons\n\n1 This work emphasizes that the proposed approach can encode and discover object-centric context. Besides, it further designs experiments to compare the context errors between UPSnet and the proposed one. However, I am not quite sure what is the use of object-centric context? Is it meaningful for some applications?\n\n2 Even I consider the proposed idea is interesting, the overall pipeline seems more complex than many end-to-end panoptic segmentation frameworks such as UPSnet and panoptic-deeplab. Besides, the work does not achieve better performance than previous solutions. \n\n3 How about the generalization ability of this work? For example, can PSS be trained on Cityscapes and applied to coco-stuff based on a few-shot setting (i.e. only a few training samples are available)?\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting idea but seems to lack focus",
            "review": "The paper presents a pixel-wise embedding strategy for panoptic segmentation, which aims to learn a pixel representation that encodes both semantic and instance information. To this end, the proposed method builds on top of the Segment Sorting approach and extends its contrastive loss to the instance level by utilizing panoptic supervision. To predict instance segmentation,  the paper also designs a merging process to cluster the pixels into instances, which further employs an object center prediction module for localization and a dynamic partition strategy to cope with scale variation.  This method is evaluated on two panotpic segmentation benchmarks, including Cityscapes and PASCAL VOC 2012. \n\nStrengths:\n- The idea of learning a pixel-wise embedding for encoding instance-specific visual context seems interesting, which can be used for predicting both thing and stuff categories. \n\n- The performance of the proposed panoptic segmentation pipeline is comparable or slightly better than the published SOTA on two benchmarks.  \n\nConcerns:\n- The focus of this work is a bit unclear. It seems trying to tackle two related problems, one is the learning an object instance-specific visual context representation and the other is the panoptic segmentation. However, neither of them is explored in depth or with compelling results in this paper.     \n\n- The technical contribution of this work is a bit incremental. Most of the learning framework is based on the Segment Sorting paper and its extension to instance-level supervision seems straightforward. \n\n-  While learning embedding for object-centeric context is useful for certain applications, it also raise the question on the complexity of such holistic features and how well such a representation can generalize to different scenes.  Due to the compositionality of object and its surroundings, conceptually it seems challenging to learn such representations with limited model capacity. In particular, how well the learned representation is able to cope with an object out of its common context? \n\n- The evaluation of the panoptic embedding is a bit lacking. First, as the method is fully supervised, all different types of object-centric context do exist in the ground-truth label maps. As such, it seems while contexts are not annotated, they should be able to learned by the model via segmentation loss? Second, the CE metric is hard to interpret as it is a KL divergence measure. It would be more clear if common retrieval performance metrics can be adopted to show its improvement. Finally, the paper only compares two representations for object-centric embedding and it would more informative to show the performance of other types of features, such as SegSort, One-stage instance segmentation, etc.  \n\n- For the panoptic segmentation, the proposed pipeline adopts a complex post-processing stage to merge the pixel representations into instance segmentation. Without detailed ablative study, it seems unclear what components contribute to the final performance. Is the learned embedding or a better merging strategy? Moreover, the common practice in panoptic segmentation literature is to conduct evaluation on both COCO and CityScapes, and report detailed metrics on PQ, SQ, RQ. Here the COCO benchmark and some metrics are missing.   \n\nMinor comments:\nSec 1: Paragraph 2: extra words at the end: \"A major\"\n\n=====POST-REBUTTAL COMMENTS======== \n\nI thank the authors for the response and the efforts in the updated draft. Unfortunately,  I still think the results on the object representation is not convincing due to lack of comparisons with other embedding methods, and more needs to be done to study the generalizability of this method for complex non-street scenes.  I retain my original decision for these reasons.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting extension of SegSort, with unclear motivation",
            "review": "**Pros**\n\n* Competitive results on benchmarks. The PQ results are good, with relatively few additional \"tricks\" (assuming they're not simply left out of experimental section).\n\n* Complete ablation studies. This includes swapping in/out some proposed improvements to the underlying SegSort training, plus different components of the method used to construct panoptic segmentations from the oversegmentation.\n\n* Makes additional interesting observations about the behavior of the model/properties of the embeddings, in looking at the \"context.\"\n\n**Cons**\n\n* The motivation is somewhat unclear. The core \"segment sorting\" method is an unsupervised method. The method here only builds on the supervised variant of SegSort and introduces additional components that require supervision. So the main difference from existing panoptic segmentation methods is the use of an intermediate segmentation. The authors propose the embeddings are useful in \"context specific instance retrieval,\" but the importance of this task is unproven. The fact that it seems to improve panoptic segmentation results is more concrete, but it is less clear *why* this method would yield this improvement.\n\n* Description of hybrid scale exemplars is unclear, with very few details.\n\n**Typos**\n\n  * \"objects in different context\" -> \"objects in different contexts\" on page 1\n  * Typo \"differnet\" on p1\n  * Incomplete sentence \"A major...\" on p1\n  * \"equivalent to maximize the expected number\" -> \"equivalent to maximizing the expected number\" on p5\n  * Double periods after \"segment\" at top of p6\n  * \"to be certain [a] instance category\" on p7",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Official review",
            "review": "##########################################################################\n\nSummary:\n\nThis paper adapts Segment Sorting to panoptic segmentation and proposes a Panoptic Segment Sorting (PSS). The proposed method learns to sort segments according to both of its semantic and instance labels. The semantic label is acquired by simply mapping and classifying prototype feature and instances are formed by a clustering algorithm. A seeding branch is further used to guide merging and avoid false positives.\n\n##########################################################################\n\nPros:\n\n- The overall idea is very interesting, instead of using separate models (or branches) to learn instance segmentation and semantic segmentation, the proposed method directly learns a unified embedding that encodes both instance and semantic information. This make the model more consistent.\n- It is also shown in the experiment that the panoptic embedding is able to encode object-centric context.\n\n##########################################################################\n\nCons:\n\n- It is still not clear to me how does the learned panoptic embedding able to encode object-centric context. Throughout the paper I don't see any specific design to optimize to learn context and the authors also do not provide theoretical explanation. If this is the case, I don't think it is suitable to name it \"contextual image parsing\" and put \"discovering object-centric context\" in the motivation (or the goal), since I think it is not well studied.\n- If the proposed method indeed learns object-centric context, I think it is more reasonable to apply the method to tasks where object-centric context is important, e.g. relation detection.\n\n##########################################################################\n\nTypos:\n\n- Last sentence is not finished in paragraph 2 of Section 1, \"A major\"",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}