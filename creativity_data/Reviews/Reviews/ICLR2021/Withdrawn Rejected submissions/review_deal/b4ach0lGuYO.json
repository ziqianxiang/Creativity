{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The initial reviews were a bit split. R4 was slightly positive, R3 was slightly negative, and both R1 and R2 voted for rejection. The main issue was lack of proper comparisons with the SOTA methods and missing references. In the rebuttal, the authors added additional experiments as requested, but R1 and R2 were not convinced by the new results. In particular, R1 pointed out that even the unsupervised setup in [4] achieved 0.89 AUC, outperforming 0.86 as reported in the paper. The AC agrees with R1 and R2 that the paper cannot be published until more thorough comparisons are conducted.\n"
    },
    "Reviews": [
        {
            "title": "Simple and interesting idea with weak experimental evaluations",
            "review": "This paper presents an impainting-based method for anomaly localization on images. In the training time, a conditional GAN-based generative modeling approach is adopted. In the test time,  a mask matrix is adaptively estimated by thresholding the structural similarity index measure (SSIM) between the original images and reconstructed images. The idea is very intuitive and experiments demonstrate improved performance (especially on textures) over two recent baselines methods.  \n\nStrong points: \n\n- This paper improves the test time in unsupervised anomaly detection with an iteration scheme. Although similar ideas of iteratively focusing on refining the low-error regions and leaving alone the high-error regions have been proposed before, the residual-thresholding scheme proposed in this paper looks even simpler. \n\n- Another novelty is in the training time, the proposed approach using a conditional and GAN-based approach. This is in contrast with autoencoder-based reconstruction approaches which may lead to blurry image reconstruction. \n\nWeak points: \n\n-  The experiment evaluation is not quite convincing. Some of these numbers look worse than what is reported by Bergmann et al., 2018 and Dehaene et al., 2020. Are there any settings different when reproducing the baseline results?  \n\n- The qualitative comparison with Dehaene et al. 2020 is missing in Figure 3. \n\n- Figure 4 clearly shows the AUC improves with iterations. Would this SSIM-threshold scheme also benefit other approaches (e.g., a conditional autoencoder)? Are these performance improvements over baselines mainly attributed to the choices of free-form random mask and GAN, or the proposed SSIM-threshold scheme? Would it be better than other iterative schemes such as iterative projection with the same trained model? More ablation studies would be helpful. \n\nOther points to clarify: \n\n- I guess Table 1 AUROC is for pixel-wise segmentation rather than image classification, right?\n\n- How does the checkboard mask initialize the test? Applying different masks to 4 copies of images and then merge? \n\n- Stopping rule of iteration \n\nOverall, I think the idea in this paper is very interesting. I still have some conservations about experimental evaluation (as explained above) against me voting for acceptance. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This work, Iterative Image Inpainting for Anomaly Detection (I3AD), has focused on the reconstruction-based unsupervised Anomaly Detection (AD) which is known as rare event detection task.",
            "review": " This approach relies on learning merely normal training sample and then\ndistinguishing between normal and abnormal events regarding the threshold of the reconstruction error.\nI3AD exploits a combination of per-pixel identity function and conditional auto-encoder which is\ncapable of encoding only normal regions and decoding just anomalous regions.\nWeaknesses:\n-Although this paper has attempted to propose an efficient algorithm for anomaly detection, the\nthe general idea of this paper is not sufficiently innovative. \n-The most important works on the topics are not cited. \n-The proposed method is not comprehensively compared with the other solution.\n-A comprehensive analysis of the complexity of the proposed method is required. It seems the proposed method achieves the state-of-the-art performed at the expense of complexity. \n\nStrengths:\nThis paper is well written so that the structure is easy to follow. The majority of the obtained results\nare better than the state-of-the-art has been reported in this paper. The proposed method has tried\nto tackle two noticeable issues of using auto-encoders for the task of anomaly detection including\ntheir defect inappropriately modeling small detail as well as the existing object mismatching that\nthe models are trained to minimize total reconstruction errors\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "Limited contribution, missing literature and experiments",
            "review": "This work proposed a novel learning strategy for unsupervisedly anomaly detection. Particularly, authors propose to use an iterative mask generation process based on image impainting and reduction of a structural similarity metric (SSMI) between the input image and its reconstructed version. For evaluation purposes, authors resort to the public MVTec benchmark, showing better results than the baselines. Please find me comments below:\n\nStrengths\n-The paper is generally well written and easy to follow.\n-Results show that the proposed method outperforms the baselines.\n\nWeaknesses.\n-The methodological contribution is marginal/incremental. Similarly to several methods in weakly supervised segmentation (see [1] for example) authors use iterative steps to refine the initial segmentation mask. The only difference is that instead of mine regions based on classification activation maps and classification scores the authors use a structural similarity pixel-wise metric. Beyond that there is nothing novel in the proposed methodology.\n\n-Some ideas/motivations are unclear. For example, I don’t really understand why the mask initialization is needed at test time. Further, authors also mention in the Appendix. D that to cover whole images, they are split into X by X patches and then aggregated into four masks. Please provide more details since this is unclear. \n\n-Literature is poorly conducted with many relevant recent papers missing (furthermore, the literature comes late in the paper). In addition to the previous paper in weakly supervised segmentation, the works in [2-6] are recent works in anomaly detection, just to name a few. Authors should include all this papers, discuss their limitations and show how the proposed work can overcome these drawbacks. Authors mention that auto-encoders produce blurry images, which is true. Nevertheless, works including an adversarial discriminator have somehow addressed the issue of blurred reconstructed images. Given all this, authors should better motivate their work. \n\n-Among previous missing papers, there is the work in [2], which also employs an impainting strategy coupled with an adversarial model. Which are the differences with respect to this work?\n\n-Experiments need to be significantly extended. First, authors merely include two methods in their evaluation, while there exist more than those used in the comparisons. This is particularly important since some recent methods which have been omitted in the literature review made by the authors (e.g., [4]) significantly outperform the proposed method (0.863 vs 0.90 in AUC). Second, authors report results in terms of AUC, while I strongly suggest that they use the accuracy for individual classes, and the AUC as average of the classes. The reason for this is to better compare to related work (See for example Table 6 in [4]).\n\n\nReferences:\n[1] Wang et al. Weakly-supervised semantic segmentation by iteratively mining common object features. CVPR 2018.\n[2] Sabokrou et al. Avid: Adversarial visual irregularity detection. ACCV 2018 \n[3] Perera et al. Ocgan: One-class novelty detection using gans with constrained latent representations. CVPR 2019.\n[4] Venkataramananet al. Attention Guided Anomaly Localization in Images. ECCV 2020.\n[5] Deecke et al. Image anomaly detection with generative adversarial networks. In Joint european conference on machine learning and knowledge discovery in databases 2018.\n[6] Li et al. Exploring deep anomaly detection methods based on capsule net. In Canadian Conference on Artificial Intelligence 2020\n\n\nMinor: The paper in David Dehaene, Oriel Frigo, S´ebastien Combrexelle, and Pierre Eline. Iterative energy-based projection on a normal data manifold for anomaly localization. arXiv preprint arXiv:2002.03734 is an ICML 2020 published paper,\n",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "An interesting and novel approach to contrastive anomaly detection, but not ready for publication",
            "review": "This paper presents a method for contrastive anomaly detection (AD) using an iterative masked conditional autoencoder inpainting approach. An autoencoder network is trained using an adversarial approach to reconstruct a randomly masked part of the input image. At test time a mask is derived from the generated anomaly map (using SSIM index between the input and reconstructed image) and used to mask the input so that the process is repeated N times. The method is shown to produce SOT results on the MVTec AD benchmark.\n \n\n PROS:\n \n  * The method is novel and interesting. The iterative masked approach does provide a principled way to increase the signal-to-noise ratio in the reconstructed images.\n  \n \n CONS:\n \n  * The numbers given in table 1 for the baseline SOT methods are not from the literature. The authors reproduced the numbers but they appear to be much lower than those published. For example, the published value for the average AUC over 15 classes in Bergmann-2019 are L2=0.82;SSIM=0.86, while on table 1, these values are: L2=0.76;SSIM=0.76. This is a substantial difference, which is not explained at all. It makes the proposed method look much better than SOT, while in reality it appears to have similar performance.\n \n  * The number of iterations is not discussed. This is an important hyperparameter as it affects the overall speed of the approach. Only fig 4 shows the progression of the AUC during iterations but no discussion are provided. Also the actual number of iterations used to generate table 1 AUC scores is not given. Assuming the complexity is higher than other SOT methods due to the iterative aspect, and given that the performance is similar to SOT (see above point), this approach now looks a lot less convincing.\n  \n  * The paper is not well written and suffers from grammatically wrong and overly complicated sentences, to the point where it becomes distracting and confusing.\n \n \n Overall, this is an interesting and novel approach to contrastive anomaly detection. However, I think the paper is not ready for publication. The baseline SOT numbers need to be explained or changed to reflect previously published numbers. The computational complexity of the approach needs to be compared to these baselines. And finally the paper needs to be seriously proof-read.\n ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}