{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper studies robust learning in the presence of noisy labels and proposes a new loss function called the golden symmetric loss (GSL) combining both regular cross-entropy and reverse cross entropy and leveraging an estimate of the corruption matrix. The paper appears to be well-written.\n\nPros:\n- Good range of application domains (both vision and text).\n- Learning with noisy labels is an important practical problem.\n- Theoretical guarantees for the procedure using framework from recent work.\n\nCons:\n- Limited novelty as the method appears to be a weighted combination of two existing ideas. \n- Concerns about the baselines used: why are the same baselines not being used throughout?\n- Having at least a few trials with mean and standard deviation for the experiments would make the conclusions stronger.\n\nOverall, the limited novelty combined with the concerns about the empirical analysis was a key reason for rejection. "
    },
    "Reviews": [
        {
            "title": "an interesting work, but the novelty is not quite significant",
            "review": "###############\n\nSummary:\n\nThis paper proposes a robust loss function that combines both cross-entropy loss and reverse cross-entropy loss.\n\n\n###############\n\nComments:\n\n1.\tThe authors are motivated by observing that GLC cannot handle hard classes effectively. However, the why GSL can handle that is not clear to me. Is that because GSL loss function contains the reverse cross-entropy loss?\n2.\tThe contribution of this work is also not quite clear to me. As mentioned in Section 3, GSL borrows the idea from Symmetric Cross-Entropy loss from Wang et al (2019). Hence the major contribution of this work seems only proposing weights depending on the Noise Transition Matrix on the cross-entropy and reverse cross-entropy loss functions.\n3.\tFigure 1 is somehow hard to read. Figure 1 a) seems wrong to me. As the corruption matrix 1a) illustrates that there is no corruption. It could be better if there are more explanations for them.\n4.    A() and B() -- \" Final weights proportional to \\epsilon and J\". It is still not clear to me how to compute A and B, and why they have to be proportional to  \\epsilon and J. In addition, it is not clear to me how to obtain the value of \\epsilon. It is not clear to me when to estimate weights during the training process in Figure 3. \n5.    The proof on page 12 seems wrong to me. To see this, the first expectation in the first line of the proof is taken over x and \\tilde{y}, while the second expectation is conditional on \\tilde{y}. In fact, we have p(x,\\tilde{y}) = \\sum_y p(\\tilde{y}|y)p(y|x)p(x) (see Making Deep Neural Networks Robust to Label Noise: a Loss Correction Approach, Section 4, 2017 CVPR).\n6.    Still in the proof, it is not clear to me why R_\\epsilon (f^*-C^*) - R_\\epsilon (f-\\hat{C}) \\le 0 indicates that \\ell_ce with label\ncorrection is robust to noise.\n\n\n###############\n\nAdditional questions: \n\n1.\t“\\alpha and \\beta can significantly impact the final model accuracy”. I agree but the figure 2b) is somehow confusing to me. The values of \\alpha and \\beta for the orange curve are 60 times as large as those for the blue curves. And the orange curve is better. However, the corresponding optimization problems are the same, since the values of \\alpha and \\beta can be absorbed into the learning rate. If we use the blue curve setting and change the learning rate to 60 times as large as before, the results could be the same. The whole improvement could be resulting from changing the learning rate.\n2.\tThe clean data only used to estimate the Noise Transition Matrix proposed by GLC method (Hendrycks et al. (2018)). Then they are added to the final loss as the clean cross-entropy loss. I was wondering if there are any other benefits of clean data that we can leverage.\n\n###############\n\nThis paper proposes a noise-robust loss function where the contribution is leveraging the Noise Transition Matrix to estimate the weights on cross-entropy loss and reverse cross-entropy loss. It is interesting to introduce the reverse cross-entropy loss. But the novelty of this work does not meet the standard for an ICLR publication.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review for \"Robust Learning via Golden Symmetric Loss of (un)Trusted Labels\"",
            "review": "The authors of the paper propose a novel loss function termed the golden symmetric loss to tackle the important problem of learning with noisy labels. The proposed loss function, in essence, involves the use of a corruption matrix to correct the regular cross-entropy loss and, at the same time, to estimate the relative weighting of the corrected cross-entropy loss and that of reverse cross-entropy loss.  A series of empirical experiments were conducted to demonstrate the effectiveness of the proposed method. \n\nIn general, the paper is well written and the proposed method is technically sound. Extensive experiments across different domains and applications were also conducted to demonstrate the effectiveness of the proposed method. The idea to use a confusion matrix to automatically tune for the relative weighting between cross-entropy and reverse cross-entropy is also interesting. One significant weakness of the paper is the lack of novelty. To the best of my understanding, the paper is, in most part, a mere combination of two of the previous approaches (loss correction with corruption matrix and the Symmetric Cross-Entropy). As such, it is not surprising that it works better than these previously proposed strategies. In addition, while the idea of automatically determining the relative weighting is interesting, I am not fully clear about how the function $A(\\hat{C})$ and $A(\\hat{C})$ are determined. It was stated that the \"final weights proportional to $J$, $\\epsilon$\". Can you explicitly define the functions  $A(\\hat{C})$ and $A(\\hat{C})$? Does this mean that the exact weighting still needs to be tuned? If so, what is the point of using $A(\\hat{C})$ and $A(\\hat{C})$? Can't we just directly tune the weighting explicitly? I think further clarification and elaboration can be helpful. Due to the reasons mentioned above, I recommend weakly rejecting the paper. \n\nQuestions: \n1. How important is the clean dataset for the algorithm? Since the corruption matrix can be estimated without a clean dataset, it would be interesting to see experiments without a clean dataset. \n2. Why is the corruption matrix applied only to regular cross-entropy but not reverse cross-entropy?",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting direction to improve robust learning from noisy labels, but theory and experiments have a few issues",
            "review": "##### Summary\n\nThe paper proposes a golden symmetric loss method that combines cross entropy loss and reverse cross entropy loss, and at the same time performs forward loss correction for cross entropy loss, under the problem where we have noisy training labels and clean training labels. It shows theoretical results showing the robustness of cross entropy loss under forward loss correction, and shows that it can be regarded as a generalization of Ghosh et al. 2017's analysis. Empirically, it shows how loss correction on reversed cross entropy or the symmetric cross entropy performs worse compared with only cross entropy, and propose to use forward loss correction only on cross entropy term.\n\n##### Strengths \n\nTheoretical results show the robustness of cross entropy loss under forward loss correction and compares with Ghosh et al. 2017's analysis.\n\nExperiments show that the proposed method is better than baselines in vision and text datasets.\n\n##### Weaknesses\n\nThe theoretical analysis gives new insights to the properties of cross entropy loss with forward label correction, but it is only a special case of the proposed loss function in the paper when $B(\\hat{C})$ is 0.\n\nIt would be nice to have the same baselines for vision and text. For example, there is STMatrix in text but not vision, there is SCL in vision but not in text.\n\nI think I am a bit confused to why STMatrix performs worse than GSL in Table 2. Shouldn't STMatrix perform better than GSL if the only difference is whether the corruption matrix is true or estimated? Or does GSL have access to trusted data while STMatrix doesn't? Does STMatrix use the true matrix to derive the balance between the two losses?\n\n##### Comments and suggestions\n\nI'm guessing that a naive method would be to regard the balance between two losses in Eq.4 as an hyperparameter that can be tuned with validation data. How will that perform compared with determining the weight by Jain's fairness index and noise rate? This experiment might help to understand the additional value of the proposed weight determining procedures.\n\nIt looks like all hyper-parameters were fixed and experiments were only conducted once. It would be nice to have at least a few trials and report mean and standard deviation.\n\nTable 2 seems to be an average over different noise rates. Did each noise rate have a similar tendency to the average for the different methods? This is reported for Twitter dataset in Fig.4 in the Appendix but would be good to see the same figure for SST.\n\n\n##### AFTER RESPONSE\n\nThank you for answering. My concern on theory is resolved, but I still think an additional baseline of regarding it as a hyper-parameter would be helpful as a comparison, having at least a few trials with mean and standard deviation for the experiments would make the conclusions stronger, and unifying the baselines is important.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The algorithm is simple. There are some flaws in theoretical proofs. ",
            "review": "This work proposes a golden symmetric loss (GSL) for the noisy label learning problems. Compared to previous weighted symmetric cross-entropy losses, the proposed loss estimates the trade-off parameters using the transition matrix. Empirical studies demonstrate that the GSL method is better than some baselines.\n\nComments:\n1. The proposed GLS is simple. My main problem is that why should we estimate $A(\\hat{C})$ and $B(\\hat{C})$ simultaneously? As they are trade-off parameters, estimating one leads to the same results, but the trainable parameters can be reduced. Moreover, it seems that GSL loss only works when the noise data are generated via a transition matrix. Would it be better if we consider the instance-dependent case and relate the trade-off parameters to the feature $x$?\n2. There are some flaws and informal presentations in theoretical proofs.\n- Eq (7) basically follows Proof 2 in (Ghosh et. al. 2017). But, in the first equation, the law of total expectation should be $E_{x}E_{y|x}E_{\\tilde{y}|y,x}$ instead of $E_{x}E_{y|x}E_{y|\\tilde{y},x}$.\n- In the fourth equation, the expection should be equipped to $l_{ce}(\\cdot)$, since there are $f(x)$ in $l_{ce}(\\cdot)$. Hence, it is also desirable to take expection to define $\\mathcal{A}(\\hat{C}^Tf(x),y)$. Otherwise, $\\mathcal{A}(\\cdot)$ depends deeply on the instance $x$. \n- The biggest problem is $\\Delta\\mathcal{R}$ need not be non-positive. The reason is that $f*$ is the optimal solution to $\\arg\\min R(\\cdot,C*)$ instead of $\\arg\\min R(\\cdot,\\cdot)$. The non-positivity requires a detailed discussion, and I think this property does not hold in some conditions. \n- The lower bound of $\\Delta A / \\Delta R$ is not discussed. If $\\Delta A / \\Delta R < 1$, then the algorithm is able to learn from 100% noise data, which is not realizable.\n- What is the definition of noise-tolerant? The authors need to give a mathematical definition.\n- It is weird that Theorem 4.1 merely analyzed the vanilla cross-entropy loss. The authors need to bridge the results of Theorem 4.1 to GLS loss.\n\nMinor comments:\n1. The references are informal. Please put the author's names into the brackets.\n2. The experimental results seem to be far away from state-of-the-art noisy label learning methods, such as DivideMix [1]. While the SOTA performance is not the most essential issue for me to judge a paper, I highly recommend the authors to explore better model architectures that provide competitive results. \n3. The related works are not thorough for me. Some state-of-the-art noisy label learning methods (in 2019/2020), e.g. DivideMix, are not discussed. \n\n[1] Li J, Socher R, Hoi S C H. DivideMix: Learning with Noisy Labels as Semi-supervised Learning[C]//International Conference on Learning Representations. 2019.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}