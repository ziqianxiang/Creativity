{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "We thank the authors for their detailed answers and for providing an updated version of the paper addressing several of the issues raised by the reviewers, including new experimental results.\n\nThe paper is technically correct. The comparison with other methods is thorough and includes ablation studies clarifying the contributions of different aspects of the proposed method. One aspect that has been moderately addressed in the new version is the comparison between the \"learned lambda\" of the paper with a \"tuned lambda\" suggested by a reviewer. The authors added results where lambda is set to a particular value, however it would be more interesting relevant to consider a real \"tuned lambda\", i.e., a scalar parameter, shared by all vertices, that is optimized during training; the goal being to clarifying the benefit (if any) of parameterizing lambda as a function of the node, as opposed to a value shared by all nodes.\n\nThe paper is clearly written, particularly the revised version.\n\nThe novelty is the weakest aspect of the paper. While the specific problem of learning with noisy labels with GCNN may be new, the field of learning with noisy labels in general, and of using label propagation from clean labels to guide the prediction of uncertain labels, has been proposed before, and mentioned in the reviews. The specific instantiation of this idea to the GCNN framework is novel.\n\nThe significance of the work is rather positive. The revised version contains results on two real-world datasets, where the proposed method outperforms several existing ones. As mentioned by a reviewer, this paper may inspire other researchers to explore in more depth the specific problems of learning with noise on graphs with GCNN, and to exploit the knowledge of a limited set of clean labels which may have practical importance to reduce human annotation efforts.\n\nIn summary, the paper proposes a novel model and demonstrates its potential to address a possibly important problem.\nAlthough the reviewers did not update their reviews, the authors' responses and updated version correctly addresses several of the initial concerns. The limited conceptual novelty compared to existing work did however not convince us to recommend acceptance, given the high selectivity of the conference."
    },
    "Reviews": [
        {
            "title": "The paper is clear and in good quality",
            "review": "This paper presents the one technique using label propagation with meta learning. The label smoothness is used to pseudo label the nodes in the graph. The experimental results look promising in two conditions of label noises. The paper is presented clearly and easy to read. Overall, the quality is good.\n\nThe paper present the idea and experiments clearly.\n\nI checked a few literature and believe this work is original.\n\nPros:\n1. clear presentation\n2. method is simple but seem very effective\n3. the experimental results outperformed the state-of-the-arts in both synthetic label noise and real noise scenarios.\n\nCons:\n1. the contributions can be challenged. If check the GNN with label noise, I do can find some literature published on CVPR and ECCV. And the third one is evaluation result, cannot be categorized as a contribution.\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "interesting paper but not good enough",
            "review": "The paper proposes a robust training algorithm for graph neural networks against label noise. The authors assume the labeled nodes are divided into two parts, clean part without noise and train part with some noise. The proposed method contains two parts. Firstly, it leverages label propagation (LP) trained on the clean nodes to assign pseudo labels on train nodes with noisy labels. Secondly, the authors design a learnable weight \\lambda to learn the label for those noisy nodes where LP does not agree with the original labels. The final graph neural network is trained with clean nodes, high confidence train nodes, and uncertain train nodes with learned labels. The authors conduct experiments on four graph datasets with manual injected noise and one real-world noisy dataset to validate the proposed method.\n\nThe paper studies an important problem of graph neural networks with noisy label. I have several concerns for the paper.\n(1)\tThe idea of using LP (or another algorithm different from GNN) to create pseudo labels for uncertainty nodes is not a new idea (e.g., in [1]). Actually, the LP, original data and GNN are ensembled and the final label comes from the majority vote. When LP agrees with the original data (in noisy part), those labels are retained. \n[1] Li, Qimai, Zhichao Han, and Xiao-Ming Wu. \"Deeper insights into graph convolutional networks for semi-supervised learning.\" arXiv preprint arXiv:1801.07606 (2018).\n(2)\tWhy the joint learning of \\theta with GNN parameters is named meta-learning is not very clear. Algorithm 1 shows both \\theta and \\w_t are fixed to estimate labels for uncertain nodes. Then those parameters are updated with the estimated nodes. Besides, in the experiment part there is no tuned \\lambda compared (random is not good, a wrong \\lambda can hurt the performance). This makes the improvement from the learnable \\lambda less trustful.\n(3)\tThe experiments are less convincing because only one real-world noisy dataset is available. Because the authors have a strong assumption that both noisy and clean labels exist, it would be better if the authors can validate such assumption with some real-world data. The reported numbers show the improvement of proposed method is rather limited, I would suggest run the methods more times and report mean performance with variance. Results with manually tuned \\lambda should be reported. Besides, since GNNs are good for learning on graphs with few labeled nodes (such as the gcn paper actually only use several labeled nodes per class), I would suggest adding some additional experiments for the size of D_clean. How will the rest RL + learnable \\lambda contribute w.r.t the number of clean nodes?\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Anonymous review",
            "review": "This paper presents a label propagation based meta learning algorithm to address label noise. Label propagation helps re-label pseudo labels of noisy data and meta learning achieves aggregations. The method is evaluated on several node classification datasets and a custom version of Clothing1M image classification dataset. The comparison to multiple baselines shows better performance.\n\nPros:\n- The combination of graph neural network and meta learning is interesting and novel\n\nCons:\n- The paper is not well written. Some descriptions are unclear. For instance, the usage of $w$ is never defined. The usage of meta learning is not novel, which from a previous method - L2R, but it is never clearly mentioned. However, it tried to use several equations to explain the L2R method, which is not sufficient to be clear but makes unnecessary confusion.\n- Experiments might not be that convincing.\n  - The method is only tested on several graph datasets with synthetic noises, which were uncommon in previous papers. However, most compared methods are only evaluated on common image datasets. The comparison may not be very fair. Moreover, from Table 2 and 3. The proposed method is marginally better than several other methods.\n  - Although the method tries to tackle a real-world dataset Clothing1M, the scalability issue of this algorithm makes it difficult to work so it is only tested on a custom toy version. So the results are not generally useful to compare to other methods which have tested on full Clothing1M.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting work, but can be further improved",
            "review": "*quality*\nThis paper is well-organized. However, the contributions are not clear. Meanwhile, the experimental validation is weak and needs to be improved.\n\n*clarity*\nIt is not difficult to understand the framework of the proposed algorithm.\n\n*originality*\nIn this paper, the proposed algorithm focuses on the label noise existing in graph node classification tasks. The contributions are somewhat limited, since this is not the first work focusing on this problem. Besides, the main motivation is also not new for semi-supervised label propagation. \n\n*significance*\nAlthough the proposed algorithm is limited in its novelty, I feel that the significance of this paper will inspire researchers focusing on this domain.\n\n*pros and cons*\n\nPros:\n1.\tThe topic is practical in realistic machine learning problems, and the proposed method is helpful to reduce the human annotation efforts.\n2.\tThe theoretical study of this paper is meaningful.\n\nCons:\n1.\tThe authors claim that they are the first to focus on the label noise existing in graph node classification tasks. However, to the best of my knowledge, there already exist some prior works, such as ‘Learning with Inadequate and Incorrect Supervision’,‘Self-Training of Graph Neural Networks using Similarity Reference for Robust Training with Noisy Labels’, ‘Noise-robust semisupervised learning by large-scale sparse coding’, ‘Robust semi-supervised classification for noisy labels based on self-paced learning’, and ‘Label Diagnosis through Self Tuning for Web Image Search’. In this sense, the authors cannot claim that they are the first to solve the label noise in the label propagation or node classification task. Besides, the abovementioned works should be cited, discussed, and even compared.\n2.\tSome recent works on label propagation can be cited, such as ‘Label propagation via teaching-to-learn and learning-to-teach’, ‘Robust Triple-Matrix-Recovery-Based Auto-Weighted Label Propagation for Classification’, etc.\n3.\tIn Eq. (8), the authors calculate the final predictions by aggregating the original labels and pseudo labels, in order to fully exploit the abundant information contained in the left training nodes D_left. This is a bit confusing, since both the original label y_j and the pseudo label y^\\tilde_j may not be the correct labels. The motivation behind this aggregation process should be explained appropriately. \n4.\tIn the experiments, it seems that the author do not use the public splitting for Cora, CiteSeer, and PubMed datasets. As a consequence, the results reported in the paper may not be convincing enough. It would be better to follow the public split for fair comparison.\n5.\tThe proposed model outperforms the comparison methods when the level of flip noise is greater than 0, but cannot perform as good as L2RW when the level equals 0. The reason for such inconsistencies should be analyzed in the experiments.\n6.\tAs for me, the selection of clean labels is a critical step. However, the authors do not give enough details about this process. I suggest analyzing the influence of the scale of clean labels on different datasets.\n7.\tI cannot find the hyper-parameter configurations for the baselines, and these information should be provided. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}