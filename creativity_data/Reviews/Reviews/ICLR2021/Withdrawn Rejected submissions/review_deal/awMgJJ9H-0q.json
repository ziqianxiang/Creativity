{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes a discretization of Wasserstein gradient flow with an euler scheme, and propose a way to estimate each step of the euler scheme using ratio estimators from samples regularized with gradient penalties. Statistical bounds are given to bound the estimated flows from the wasserstein flow.  \n\nReviewers have raised concerns regarding the assumptions under which results present in the paper hold, this was clarified by the authors (goedesic lambda convexity, log sobolev constant for the target density . lipchitizity of velocity fields).  The paper needs a revision to incorporate that feedback and to be in shape for publication. \n\nOther concern were on earlier claims in the paper regarding the monge ampere equation and approximation of the optimal mapping this was addressed by the rebuttal. \n\nOther concerns were also on explaining the relation of the work to score based models and energy based models. \n\nOverall the paper needs to state in a clearer way the assumptions for the theoretical results and to acknowledge the limitations of those assumptions in analyzing the euler scheme. \n\n"
    },
    "Reviews": [
        {
            "title": "Technical sound while missing comparison with score-based generative models",
            "review": "==== Summary ====\n\nThis paper tackles generative modeling (sampling, in particular) via finding the push forward functions T (equivalently, the velocity fields v) that iteratively moves particles from a reference distribution toward the target data distribution. The velocity fields are solved by minimizing the f-divergence between the particle density at iteration k and the target data density, which is shown to be in the form of gradient of density ratio. Based on this intuition, the training stage becomes estimating the density ratio via neural networks, for each iteration k=1,...,K. However, estimating the density ratio can be quite difficult when two densities have little overlapping support. Thus, the author proposes to add gradient regularizer to the density ratio estimating function. The experiment on real-world computer vision benchmarks demonstrate reasonable sampling quality, and the FID score on CIFAR-10 is comparable to some GAN baselines in the generative modeling literature.\n\n\n==== Pros and Cons ====\n\nPros:\n\n(1) Technical sounds and interesting insights for non-parametric density ratio estimation with low-dimensional assumptions. \n\n(2) Writing is clear, sections/paragraphs are well structured.\n\nCons:\n\n(1) The training and inference time seems way larger than GANs because of the iterative updating nature. The inference time is more close to score-based generative models.\n\n(2) Finding velocity fields and conduct inference is very related to score-based generative modeling [1,2,3], and the author should discuss the connections, see detailed below.\n\n(3) The experiments on real-world datasets are not very compelling, and lack some ablation studies, see detailed below.\n\n\n==== Technical Questions ====\n\nQ1:What are the connections to score-based generative models? For example, [1] also analyze the particle evolution with the Vlasov process, and interpreting it as a gradient flow for minimizing the KL divergence. [2,3,4] are state-of-the-art score-based generative models that iteratively move particles based on the velocity field (i.e., score functions). The experimental comparison is missing.\n\nQ2: The learning objective of decoder G_theta is not justified. Why squared loss? Is that just memorizing the Y_tilde? \n\nQ3: Lack of ablation study for real-world datasets. What is the FID score in CIFAR-10 for your method without the outer loop in Algo 2?  What is the number of inner/outer iterations? Also from the Table A3 and A4, it seems like the coefficient for gradient regularizer alpha = 0. Does this mean that the density ratio estimation problem does not suffer from the no overlapping support issue? If so, why introducing it in Section 4?\n\nQ4: What are the training and inference time for high-dimensional image datasets such as CIFAR-10 and CelebA? In Algorithm 2, how many density ratio estimators R_{phi}^{k} do you learn? Is it that for each outer-inner loop (j,k) pair, you need to learn one? If so, that seems like a lot of models.\n\n==== Additional Feedback / minor suggestions ====\n\n(1) Subplots in Figure 3 are too small. I can not see the figures’ legend.\n\n(2) The Pytorch code of EPT link is not working (page not found on github).\n\n(3) In the first paragraph of Section 3, the right-hand-side of velocity fields seems to have unbalanced parenthesis: f’’(R)(x)) => f’’(R(x)) ?\n\n==== Reference ====\n\n[1] Stein Variational Gradient Descent as Gradient Flow, NeurIPS 2017\n\n[2] Generative Modeling by Estimating Gradients of the Data Distribution, NeurIPS 2019\n\n[3] Improved Techniques for Training Score-Based Generative Models, NeurIPS 2020\n\n[4] Denoising Diffusion Probabilistic Models, NeurIPS 2020\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The work is technically solid, but may not be doing what is claimed.",
            "review": "Pros:\n* The exploration to use a flow/transport map for generative modeling is inspiring and worth encouraging.\n* The writing roughly follows a clear logic flow.\n* The proofs seem valid to me.\n\nCons:\n* Method.\n  - My major concern is on whether the method indeed implements the optimal transport map. As I understand it, optimal transport map and gradient flow are two independent concepts. The former is determined by two distributions, while the latter by a function(al) of distribution which gives the gradient. I do not understand why various gradient flows can all approximate the optimal transport map. Particularly, the optimal transport map does not depend on the choice of the function f in the f-divergence, while different choices of f give different gradient flows.\n\n    It makes sense to approach to the target distribution $\\nu$ by minimizing the f-divergence of the current distribution $\\mu_t$ to $\\nu$, which can be done by approximating the gradient flow of the f-divergence. But it does not seem to have a relation to optimal transport, which is the claimed motivation of the work.\n* Writing.\n  - Some theoretical results seem to be already well-established, e.g., results in Theorem B.1 are all covered by Villani (2008) and Ambrosio et al. (2008). The authors may need to rephrase these results as an introduction to the background knowledge of this area, so that the novel theoretical contributions can be highlighted.\n  - The main paper frequently refers to the appendix, which feels a little disturbing.\n  - It seems to me that $q(x)$ in Eq. (2) should be $q(z)$, since $q$ is the density of $\\mu$, which represents the easy-to-sample measure/distribution on the latent space, and $Z \\sim \\mu$.\n\n=== EDIT: post-rebuttal ===\n\nI thank the authors for their patient and detailed replies regarding my concerns. I noticed that the authors have addressed the concerns to some extent in the updated paper (e.g., the remark in Conclusion). I'm also aware that the method can achieve the machine-learning goal of transporting a reference distribution to the data distribution, regardless of my concern. So I raised my score by 1 point.\n\nNevertheless, I still feel uncomfortable to give a positive score. The current presentation of the motivation may confuse or even mislead the community. The authors present the Monge-Ampere Eq. (2), which solves for the _optimal_ transport from the reference distribution to the data distribution. But the method is constructed by simulating the gradient flow of f-divergence. Although the resulting transport serves for transforming the reference distribution to the data distribution (since the gradient flow minimizes their f-divergence), the transport is unnecessarily _optimal_ (there may be multiple transports to transform the reference distribution to the data distribution; the gradient-flow transport is one of them, which may not be the optimal one that solves the Monge-Ampere equation).\n\nFor the authors' reply \"Our method is based on a first-order approximation to the Monge-Ampere equation\", I think the \"Monge-Ampere equation\" therein is different from the original one (Eq. (2)). If the method, which is constructed from simulating the gradient flow of the f-divergence, is to be treated as a first-order approximation to some Monge-Ampere equation, then the Monge-Ampere equation is between two adjacent/neighboring distributions on the gradient flow curve, but Eq. (2) is between the two ending points of the curve (i.e., the reference distribution and the data distribution). The two Monge-Ampere equations have different solutions unless the gradient flow coincides with the geodesic on the Wasserstein space, which is unnecessarily the case.\n\nI agree that \"An important advantage of the proposed approach is that it allows general energy functional in constructing the gradient flow from the reference distribution to the target distribution\". But I think it does not have much to do with _optimal_ transport or the Monge-Ampere equation. This thought works since the gradient flow minimizes the energy functional, whose minimum is achieved only when the two distributions coincide (when the energy functional is a proper divergence/discrepancy).",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting study but more rigor needed",
            "review": "This paper considers generative learning by discretizing a Wasserstein gradient with Euler methods. More precisely, some samples of a target distribution are given and the goal is to pushforward some samples of an initial distribution to the target distribution. The proposed method is obtained by  minimizing the f-divergence between the initial distribution and the target distribution, but considering the Wasserstein gradient flow of the f-divergence w.r.t. the target distribution (= the objective function). This Wasserstein gradient flow is discretized via Euler method to obtain the proposed algorithm. This Euler method involves the Wasserstein gradient of the objective, which is intractable. The authors describe a statistical methodology to compute this Wasserstein gradient based on the samples of the target distribution and samples from the current distribution. They also prove a bound for the estimated Wasserstein gradient wrt the true Wasserstein gradient. Finally, the paper presents relevant numerical experiments.\n\nOverall the approach is natural, the topic is interesting and paper is well written. The authors show how to approximate the Wasserstein gradient, which is the main technical point in the implementation of the ETP for f-divergences. They also prove a bound for it and the simulations are promising. \nHowever, some typos/approximative statements make the reading experience difficult (see below). \nEq (10). The linear convergence of the gradient flow to the target distribution is not something standard, since it usually requires the objection to be lambda-geo-convex (lambda > 0). It holds if the f-divergence is KL and the target strongly log concave but beyond this case I don't know. Could the author give other examples? Moreover, I don't believe that it is a good strategy to claim strong results like this without justifying.\nEq (11). I don't see why Eq B-10 holds here and I suspect that it does not. Can the authors prove that v_t is jointly Lipschitz? Otherwise, remove Eq (11). Moreover, Eq (11) does not imply convergence to the target distribution as claimed. The reason is that Eq (11) is a uniform convergence result over compact sets [0,T]. This does not imply convergence in the limit T = infty in general, as well documented in many works, see e.g. Kushner & Yin 2003. The situation is much more complicated (an additional stability result would be needed).\nTh 4.1. How reasonable is it to assume r Lipschitz. In the EPT, r depends on the current density, whose regularity is unknown. Moreover, How could be combine this bound in a study of the EPT itself. Can we study the convergence of the EPT? I understand that these questions are difficult and might not be answered by the authors now, but they should at least be raised as limitations of the paper. In the current form, the reader has the feeling that the authors just overlooked most of the fundamental questions.\nFinally, why the composition of transport maps constructed by the algorithm should approximately be the optimal one? This would depend on the objective function which is an f-divergence. I don't understand the linearization of Monge Ampere equation. \n\nOverall, the paper and the result are interesting but more rigor should be put on justifying the claims. Unjustified claims are not  unnoticed. Moreover, the fundamental questions should be raised. I rate the paper as marginally above, as I appreciate the bound on the Wasserstein gradient which is a first step toward analyzing the ETP (and is relevant from a statistical estimation point of view). The num exp also show interesting results for generative learning tasks.\n\nMINOR : \n\nETP vs EPT throughout the paper\nSection 2: \"Lebesque\"\nSection 3, line 6-7. typos (parentheses). Moreover, some notations are not yet defined\nMore details (like an intuitive explanation of Lemma 4.1) on the LSDR methodology would be appreciated in the main paper.\nAfter Lemma 4.1, \"Lipsichiz\"\nTh 4.1: \"with the bound B\" ??\nRelated works on discretized gradient flows : https://arxiv.org/pdf/2002.03035.pdf, https://arxiv.org/pdf/1704.07520.pdf, https://arxiv.org/abs/2006.02509, https://arxiv.org/abs/2006.09797 among others.\nCheck end of first paragraph of Page 7.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}