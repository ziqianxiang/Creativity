{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "Although the proposed method shows sota results, it is a simple combination of two existing methods, a bit of Bayesian + domain generalization.  It seems that the total improvement by the proposed method is just the sum of improvements by Bayesian and by domain generalization.  No synergy between Bayesian and domain generalization is observed.\n\nI personally doubt that the Bayesian treatment of the domain generalization loss is not essential.\nThe derivation in Sec. 2 is unnecessarily complicated.  In derivation from eq(3) to eq(5), the authors first \"extend\" (3) to (4), which is not appropriate ((4) can hold even if $p(y_{\\zeta}|x_{\\zeta})$ is highly diverse. ).  After that the authors apply Jensen to come back to an appropriate form (5), which is a weighted sum of distances (which is an appropriate criterion).\nIf they start from Eq.(5), the proposed objective is simply the sum of the standard ELBO (2) and a natural domain invariance loss (5).  For non-Bayesian treatment of the domain invariant loss, you could simply replace the KL by Lp norm between $y_s$ and $y_\\zeta$.  I expected that by answering to the question by Reviewer 1 the authors would prove synergy between Bayesian and domain generalization.  But the authors just excused that\n'' The feature distributions  are unknown without Bayesian formalism, leading to an intractable $L_I$. Therefore, we do not conduct the experiment with only the domain-invariant loss on both the classifier and the feature extractor.''\nI don't really understand what the authors mean, but the authors should have explained why you cannot replace the KL with non-Bayesian Lp loss.\n\n\n"
    },
    "Reviews": [
        {
            "title": "The paper introduces a variational invariant learning approach with Bayesian approximation for domain generalization.",
            "review": "########################\n\nSummary:\n\nThe paper introduces a variational invariant learning approach with Bayesian approximation for domain generalization.\n\n####################\n\nReason for score:\n\nOverall, the paper is above the borderline. I like the idea of utilizing the Bayesian variational learning to address the domain generalization problem, which is very novel and promising. My major concern is about some unclear parts described in the paper and insufficient experimental comparison (see cons below). Hopefully, it would be grateful that the authors could address my concerns during the rebuttal period.\n\n########################\n\nPros:\n\n(1) The proposed variational Bayesian learning framework in the paper to represent uncertainty and enhance the generalization is reasonable and interesting, which can inspire other researchers in related fields.\n\n(2) The introduced domain-invariant principle to establish a domain-invariant feature extractor and classifier seems promising, which can lead to an end-to-end framework with CNN and a Bayesian network.\n\n(3) Extensive experimental results on four domain generalization benchmarks show the proposed method obtains a new state-of-the-art performance, which is appealing and convincing.\n\n########################\n\nCons:\n\n(1) In the paper, the authors claim that they only apply the domain invariance to the last feature extraction layer. In order to examine the relevance between the number of layers and the performance, an ablation study about the number of feature extraction layers should be added. In addition, the efficiency discussion about the model layers will be better to denote the setting chosen in the work.\n\n(2) In Table 1, what happens if without Bayesian and with both invariant, i.e., only introducing invariant loss into both classifier and the feature extractor? I notice that such a certain situation is missing in the experiments.\n\n(3) As shown in Table 2 and Table 3, DSON and L2A-OT can outperform the proposed model in terms of certain metrics, it would be better if the authors can analyze the results and give some comparisons about that.\n\n(4) As for the uncertainty estimated by the proposed Bayesian network, is there any threshold being set in the model to determine which samples can be used in the training？ Moreover, how to utilized such estimated uncertainty should be discussed further.\n\n########################\n\nQuestions during the rebuttal period: \n\nPlease address and clarify the cons above. Thank you!\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "The authors propose a variational Bayesian approach to domain adaptation.  The goal is to achieve flexibility in specifying domain invariance as well as modeling uncertainty. The variational approach could also help generalization.\n\nThe key idea is simple and straightforward — a distribution over domains is first specified and variational approximation is then used for parameter estimation. In particular, the authors decompose the variational distribution in terms of the domain and classifier parameters, applying the approximation to the last two network layers. The objective function is given as a weighted sum of the KL divergence corresponding the two component distributions.\n\nIn the empirical evaluation, the authors compare the performance on in-distribution and out-of-distribution data. They conclude that the proposed method achieves generally improved accuracy on several image datasets, including PACS, Office-Home, as well as MNIST variants. \n\nStrengths:\n- The presentation is clear. The proposed Bayesian formulation is natural and the resulting learning problem is computationally practical.\n\nWeaknesses: \n- Some parameters such as the weights \\lambda_{\\phi} and \\lambda_{\\phi} do not have clear Bayesian interpretations.\n- In the experimental evaluation, different baseline methods are used for each datasets. \n\nQuestions:\nHow do the parameters \\lambda_{\\phi} and \\lambda_{\\phi} impact the performance? Could we interpret these parameters from the MLE perspective?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Although I like the research direction of this paper, I have some concerns about the technical novelty of this method ",
            "review": "Summary:\n- The paper proposes a Bayesian inference framework for domain generalization (DG) that deals with both the uncertainty and domain shit. \nThe proposed method treats the uncertainty effectively by applying the variational Bayesian inference to the last two layers of the model (feature representations and classifier layers).\nTo make the model domain-invariant, the proposed method introduces a domain-invariant principle that makes distributions of the model's outputs (representations) in the same class similar across domains. \nThe paper experimentally demonstrated the effectiveness of the method with four visual datasets.\n\nPros:\n- The problem tackled by this paper is very important because accurate prediction is generally difficult in DG due to the lack of target training data and therefore considering the uncertainty is especially important.\n- Experimental results with four widely used datasets show the effectiveness of the method.\n\nCons:\n-  The technical novelty of this method seems a bit low. This is because this method is a relatively simple combination of Bayesian modeling of neural networks and some existing techniques for DG. \nIn previous works for DG, techniques to bring distributions of model's outputs in the same class closer together across domains have been proposed.\nFor example, CCSA [1] learns the domain-invariant representations by matching the representations in the same class across domains.\n\n[1] Motiian et al., Unified deep supervised domain adaptation and generalization, ICCV2017\n\n- More analysis of hyperparameters such as $\\lambda_{\\phi}$, $\\lambda_{\\psi}$, and $\\pi$ would improve the quality of this paper.\n\nReasons for Scores:\n- Although I like the research direction of this paper as described in Pros, I have some concerns about the technical novelty of this method as described in Cons.\n\nMinor comments: \n- definition 2.1 (domain invariance) is a little confusing for me although I can see what the method wants to do by seeing Eq. (7). For example, what is the formal definition of domain-transform function?\n- Although the loss function for domain-invariant learning (7) seems to bring the distributions of the same class across domains closer together, can the method incorporate a\nmechanism to enhance dissimilarity of the different classes across domains? I think that it might improve performance.\n- There are some ambiguous statements. In Eq. (10), are $z_{s}$ and $z_{t}$ the means of distribution of $q(z|x,\\phi)$?\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Recommendation to Accept",
            "review": "Summary:\nThe paper proposes variational invariant learning (VIL) as a framework for probabilistic inference that jointly models domain invariance and uncertainty. The approach exploits variational Bayesian approximation in both feature encoding and classifier layers in order to facilitate domain generalization and invariance. The paper evaluates VIL on benchmarks for cross-domain visual object classification.\n\nPositives:\nThe paper presents their methodology and definitions very clearly. Comparisons to state-of-the-art methods are well presented. The ablation study is very clear to provide a thorough understanding of the approach. Overall I like this paper.\n\nConcerns:\nThe authors state: \"the Bayesian approach has not yet been explored in domain generalization\" or \"this is the first work to adopt variational Bayes to domain generalization\". I may not strongly agree on these statements in their current form. There has been some previous work on extending variational autoencoding frameworks for domain generalization from several perspectives (e.g, adversarial inference). This type of variational inference based models ideally exploit a Bayesian approach for domain generalization as well. I would expect the authors to rephrase their claims in a more specific manner to make this distinction. Regarding this concern, one example to consider for instance is \"The Variational Fair Autoencoder\" (Louizos et al., ICLR 2016) approach for invariant representation learning with variational autoencoders for domain generalization.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}