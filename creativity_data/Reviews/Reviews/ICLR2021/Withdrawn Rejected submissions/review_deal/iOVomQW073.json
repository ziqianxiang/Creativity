{
    "Decision": "",
    "Reviews": [
        {
            "title": "Review for \"Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations\"",
            "review": "## Summary\n\nThe paper aims to give a robustness guarantee for top-k prediction under $\\ell_0$-norm bounded adversarial perturbation of the input. To give such a guarantee authors study the randomized classifier constructed from the base deterministic classifier. \n\nAuthors randomize the base classifier by randomly ablating the input fed to the classifier, for a $d$-dimensional input selecting $e$ coordinates at random and set the remainder to a pre-specified value, call this classifier $g$. Since now the out put of $g$ is randomized, the top-k classifier is the $k$ labels with the largest probabilities, $g_k(\\mathbf(x))$.  For this source of randomness added to the classifier, authors derive $\\ell_0$-norm certified radius, $r_l$, for each input to the classifier, which is the largest number of coordinates modified by the adversarial noise $\\delta$ such that if $l \\in g_k(\\mathbf{x})$ then $l\\in g_k (x+ \\delta)$ (this is not exactly how the theorem is stated but see the question below). \n\n\n## Strengths\nThe problem authors are tackling is an important one. The experiments section is promising and demonstrates that empirically that the certified radius derived is the largest as compared to existing bounds. \n\n\n## Concerns + Questions\n1. Paper is not very easy to read. Theorems are written in a way that makes them hard to parse in the first read. Theorem 1 guarantees that any arbitrary label $l$, the $l\\in g_k(\\mathbf{x}+\\delta)$ but does not make any assumptions about $l\\in g_k(\\mathbf{x})$. For simplicity, assume $r = 0$, saying that adversary cannot modify any coordinates, then if $l\\not \\in g_k(\\mathbf{x})$, then no $t$ satisfies the inequality. Perhaps the statement of the theorem should be updated for the cases when $l\\in g_k(\\mathbf{x}) $? \n2. A more general issue I have that relates to the previous question: for some $e$,$f^*(\\mathbf{x}) \\not\\in g_k(\\mathbf{x})$, where $f^*$ is some true classifier. The relevance of this work relies on the smoothed classifier $g_k$ to be reasonably accurate wrt to the base classifier. In some sense, the robustness guarantee provided by the authors is with respect to this randomized classifier $g_k$ but the accuracy guarantee of $g_k$ is can be bad in practice. Can the authors also include experiments in the paper where this accuracy of $g_k$ is measured?  \n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Official Review 1",
            "review": "This paper studies the certified top-k adversarial robustness against L0 adversaries. The authors analyzed randomized ablation, a mechanism designed by (Levine & Feizi, 2019) for L0 robustness and extend their analysis to the top-k certification. The authors also provided an analysis of near-tightness for their ceritifiable radius, which is missing in prior works. Experiments on CIFAR-10 and ImageNet show some performance gains comparing to prior works. The paper is overall well-written.\n\nThe main contributions of this paper are three-fold:\n\n(1) First paper in Top-k L0 certification.\n\n(2) Lower bound for (Levine & Feizi, 2019).\n\n(3) Reasonably good experimental results.\n\nHowever, I do find the novelty of this paper be somewhat limited, especially in (1) and (3). (2) is a very nice contribution, but this alone isn't strong enough for an ICLR paper.\n\nRegarding (1): \nThis work provides the first Top-k certification for L_0 perturbation, while the prior works only gives Top-1 for L_0, or Top-k for L_2. However, I think the significance of this problem isn't well addressed (I did notice that the authors wrote a paragraph regarding Top-k). To be clear, the first work that provides L0 certification (Lee et al. NeurIPS 2019) and the first work that considered top-k certification (Jia et al. ICLR 2020) are both very good papers. Although there are some non-trivial technical challenges to extend the existing results to L0 + top-k, the significance and novelty of this problem is definitely not at the same level of the two prior works mentioned above. The paper would be much better if e.g. providing a unified way to extend top-1 certification to top-k certification.\nBesides, the smoothing mechanism in this paper is nearly the same as (Levine & Feizi, 2019), with the only difference being that this paper assumes feature space in the discrete domain {0, 1/256, 2/256, ..., 255/256} instead of [0,1], a very minor difference considering 256 is not a small integer. \n\nRegarding (3):\nThis work does show some improvement over Jia et al. 2020 in terms of L0 robustness. However, the method in Jia et al. 2020, is designed for the L_2 threat model which is significantly different from L_0. Although one can translate L_2 to L_0 by using the largest L_0 ball contained in an L_2 ball (which is what this paper did in experiments), these metrics have enough difference so one can expect the sub-optimality of Jia et al. 2020 's method in L_0 setting. Also, as I mentioned in the previous paragraph, this paper uses nearly the same algorithm as (Levine & Feizi, 2019), which again limits its novelty.\n\nTo summarize, I think the current state of this paper is still not good enough for ICLR.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "Summary.\n\nRandomized ablation is an existing ensemble technique by randomly setting some pre-specified number of input features to be a specific value, where a robustness certificate has been proposed for its top-1 prediction [1]. In this paper, the authors extend the prior work to a new, almost tight (see the definition therein) top-k certificates of robustness -- the true label provably remains in the top-K predictions under bounded adversary -- for randomized ablation under L0 norm in a discrete space. The method works well compared to an existing method.  Overall, the paper does not seem solid enough as an ICLR paper (see details below). \n\nMajor comments.\n\n1) Extending the existing scenario to the new top-K setting seems marginally more practical and interesting than the previous study of randomized ablation. While top-K certificates have been studied under a similar context for additive Gaussian noise under L2 norm [2], L0 norm has its own significance due to its interpretable nature. \n\n2) However, the technical depth of this paper seems limited. Given the proof framework of the existing top-K certificates of robustness under L2 norm [2], and the devision of the input space to regions with constant likelihood ratios [1], the application Neyman-Pearson lemma for getting the robustness certificate seems straightforward. \n\nAs mentioned by the author, the difference from [1] is the trick in Eq. (4). It is a cute trick, definitely worth mentioning, but not a strong argument at all to distinguish from [1] since the improvement is tremendously small in high dimension. \n\nOne technical concern is that the authors assume that there exists a region $A' \\subset C$ such that $\\Pr(U \\in A \\cup A') = \\underline{p_l'}$. However, it seems possible that $0 = \\underline{p_l'}$ but $\\Pr(U \\in A \\cup A')  > 0$. Please clarify this case. \n\n3) The almost tightness might be valuable in my opinion, because this is not shown in the original randomized ablation paper. However, the author does not elaborate this part in the main paper and leaving all the information in the appendix. \n\n4) I would suggest the author to spend more space on 3), rather than the comparison & computing $r_l$ sessions. Those sessions are mostly either redundant (already discussed in the intro) or not really the contribution of this paper (computing $r_l$). \n\nMinor comments.\n\n5) It worth mentioning clearly the discrete space that your work is basing on.\n\n6) The author mentioned \"Therefore, given a probability upper/lower ... to the given value\". The problem might disappear if you use the version of Neyman-Pearson lemma that allows stochastic classifiers. \n\nThis is a minor concern since improving this part will not change the result much. \n\n7) It seems weird to me that the comparison to [3] and [4] involves factor of 3 in the Lp norm adaptation. Since the discrete space where this paper is developed is compatible with the spaces used in [3, 4] (i.e., pixel channels rather than a whole pixel), it seems more fair to use the same input space rather than adapting norms. \n\nThis is a valid concern but I put it as minor here since [3] and [4] are not the main experimental comparison. \n\n8) It might be more convincing to really run some experiments coherent to the abstract (e.g., MLaaS, recommender system, & web searches). \n\n[1] Levine & Feizi (2019)\n\n[2] Jia et al. (2020)\n\n[3] Lee et al. (2019)\n\n[4] Cohen et al. (2019)",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Concerns about the assumptions and motivation",
            "review": "\nIn this paper, the authors propose l0-norm certified robustness of top-k predictions based on randomized ablation.  Some technique setting follows from (Jia et al. (2020)). The technical contribution is the analysis based on Neyman-Pearson Lemma, which leads to an almost tight l0-norm certified radius for top-k prediction.\n\n\n\nPros\n\n1. The paper is well written and well organized.\n\n2. It seems that the proposed method achieves a significantly higher certified l0-norm accuracy compared with  (Jia et al. (2020)). \n\n3.  Empirical sensitivity analysis of the hyperparameters is included for a straightforward understanding of the influence. \n\nCons\n1.  In the proof of Theorem 1, two assumptions are made (below Eq.(58) on page 15). However,  these assumptions are not presented in Theorem 1 in the main paper.   I am not sure why \\underline{p}'  _{_l}  + \\overline{p}'_{\\Upsilon_t} < 1 holds true. Did the authors check whether these assumptions hold true in the experiments?   Moreover, Eq.(7) may not have a feasible solution. \n\n2.  Why do l0-norm  certified robustness of top-k predictions be more important than l2-norm certified robustness in  (Jia et al. (2020))?   I am not sure about the motivation of this work. Does randomized ablation more practical than additive noise?  \n\n3 .  Eq.(19) on page 13 has typos.   The C(n,d) in Eq.(19) may be C(d,e). ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}