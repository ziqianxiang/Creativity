{
    "Decision": "",
    "Reviews": [
        {
            "title": "Official Blind Review #3",
            "review": "\n##########################################################################\n\nSummary:\nThis paper presents a new method for depth completion with a Plane-Residual (PR)\nrepresentation, in which the depth information is interpreted with the closest depth plane label and a residual value. Experiments show the effectiveness of the proposed method.\n\n##########################################################################\n\nPros:\n+ The paper is clear and easy to follow.\n+ The introduction of Plane-Residual (PR) representation for depth completion is interesting.\n+ The experiment part is well organized to show the effectiveness of each design in the network.\n\n##########################################################################\n\nCons:\n- The basic idea of the proposed PR representation is similar to the multiple-plane sweeping algorithms (e.g., [Gallup et al., 2007; Yu et al., 2020] ) for multi-view stereo. It is better to discuss these methods. \n\n- In the pipeline, only one layer of $r_{pred}$ is estimated. It seems not easier than estimating the depth value as its estimation only shares the same encoder and is conducted separately. Moreover, since the relative residual regression is adopted, it may be even harder to train as it also needs to deal with the different depth ranges between training data. How about conducting residual regression based on the output of the depth plane classification? More analysis and study of the architecture design is expected. \n\n- From Table 2, we can see that the proposed method has much worse performance in terms of the main evaluation metric (RMSE). In the paper, it is claimed this is due to \"the KITTI dataset ground truth depth map is too sparse to make a reliable depth plane ground truth labels\", while it is not very convincing as only 8 planes are used and there are thousands of ground-truth points. More explanation about this should be given.\n\nMissing references:\n* Gallup et al. Real-time plane-sweeping stereo with multiple sweeping directions. In CVPR 2007.\n* Yu et al. Fast-mvsnet: Sparse-to-dense multi-view stereo with learned propagation and gauss-newton refinement. In CVPR, 2020.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Reivew",
            "review": "The paper introduced a new depth completion algorithm. The proposed approach, first of all, propose a discrete set of depth proposals for each point, then learn to estimate the residual w.r.t the depth proposal. Experimental results demonstrate that the approach is promising on public leaderboards.\n\nThe novelty of the paper is the proposed depth estimation paradigm. The proposed idea makes sense and experimental results clearly demonstrate that it is effective. The writing is also clear and easy to follow, and the experimental result section contains ablation studies to help readers better understand the approach.\n\nI have a few questions regarding the paper, though:\n- For the descriptions in the experiments, it seems authors are using ResNet-18, is there any chance of testing the system using a better encoder? It's hard for me to understand why there is still a gap to the state-of-the-art approaches.\n- The number of plane proposals is relatively small. How would the model size increase when more plane proposals are used, is it going to increase exponentially or linearly?\n- Minor clarification question:  in table 3, are experiments in \"depth plane setup\" and \"number plane\" using l(p) filtering + confidence-guided method or not? That may help better understand which component is helping/hurting the performance\n- The loss function adds all the loss together, I wonder if performance can be further improved by using a weighted summation\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Plane-residual representation is not novel and the main claim about computation speed is not well supported",
            "review": "This paper tackles the problem of depth completion using plane-residual representation, i.e., representing each depth value with a closest depth plane label and a residual value. The proposed method is realized with a deep network consisting of a shared decoder and two decoders, with one for the depth plane classifier and the other for depth residual regression. The results are evaluated on standard benchmarks, including KITTI Depth Completion and NYU Depth V2.\n\nIn general, this paper is well written and easy to follow.  The idea of using plane-residual representation is simple and intuitive. However, this paper lacks in the following aspects:\n\n- While plane-residual representation for depth completion seems to be novel, it has been already used and well-known in other related areas, such as single image depth prediction, e.g., in the following DORN paper:\n\nH. Fu, et al. DORN: Deep Ordinal Regression Network for Monocular Depth Estimation. in CVPR 2018.\n\nThe first part of Eq. (2) in the paper is also widely used in stereo matching literature as a differentiable soft argmax operator, e.g., in the 2017 paper:\n\nA. Kendal et al. End-to-End Learning of Geometry and Context for Deep Stereo Regression. in CVPR 2017.\n\nOverall, the plane-residual representation for depth completion seems to be an incremental adaptation from existing methods in related areas.\n\n- The necessity of using residual representation is not ablated. In Eq. (2) of the paper, the first part can already represent the continuous depth value, as is done in the stereo matching literature. Then why do we still the second part, i.e., the residual part? This design is not validated in the ablation study.\n\n- The comparison for runtimes between the baselines is questionable. The runtimes reported in Table 2 seem to be directly copied from the KITTI leaderboard. However, different methods may be tested on different GPU devices, and then a direct comparison from the runtime numbers is not informative. Furthermore, it's not clear why the proposed method can achieve faster computational speed, as it also relies on a ResNet backbone.\n\n- The discussion on the number of planes used is not convincing:\n\n\"While Imran et al. (2019) has lower REL error, we believe that it is due to the fact that they used 80 channels of depth bases. Our algorithm uses only 8 depth planes, yet combines the strength of classification and regression, thereby shows better performance on other metrics.\"\n\nThis whole sentence does not make sense to me.  Imran et al. (2019) has a similar number of parameters in the network and shows a better REL number. Then what advantage does the proposed method have over Imran et al. (2019)?\n\nA few typos:\n- which plane a pixel should lie among a number of discretized depth planes ==> ... lie in among ... (and a few other places also miss \"in\")\n- every r values are ==>. every r value is\n- table 1 ==> Table 1 (capital T)\n- figure 1 ==> Figure 1 (capital F)\n- Table 2, RMSE for Qiu et al. 2019 is wrongly copied",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Not exactly clear what the contribution is.",
            "review": "This paper studies depth completion from a monocular image.  To perform depth estimation, it imagines placing a group of discrete fronto-parallel planes with different depth values in space, and then classifies which depth plane each pixel belongs to. It then predicts the pixel-wise residual depth map and adds it to the plane depth to obtain a final depth value. It claims to achieve comparable or superior performance with state-of-the-art methods while using fewer network parameters and less inference time.\n\nPros:\n+ The qualitative results look better than prior works.\n\nCons:\n- It is not clear what the contributions are.\n- The proposed Plane-Residual representation seems very similar to the one proposed in Fu et al. [1], which the paper fails to discuss. It is not clear how the proposed method fundamentally differs from that.\n- The effectiveness of the proposed Probability Volume Filtering looks very limited in the ablation study (Table 3). It makes little to none improvement to the final result.\n- The result on the KITTI RMSE metric is significantly worse than prior work, even though other metrics outperform. The provided justification is not convincing: the KITTI dataset ground truth depth map is too sparse to make a reliable depth plane ground truth labels? If so why is the proposed method better in terms of MAE/iRMSE/iMAE?\n- Overall the novelty of the paper is limited as major ideas overlap with prior work.\n\nQuestions:\n- What is the inference time on NYU?\n\n[1] Fu, Huan, Mingming Gong, Chaohui Wang, Kayhan Batmanghelich, and Dacheng Tao. \"Deep ordinal regression network for monocular depth estimation.\" In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2002-2011. 2018.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}