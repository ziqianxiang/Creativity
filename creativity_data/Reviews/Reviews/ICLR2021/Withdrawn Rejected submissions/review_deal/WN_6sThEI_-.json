{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper overall received borderline negative scores. All the reviewers agree that the paper proposed an interesting approach to exploration for RNN-based recommender systems. However, there are concerns around the experiments as well as the theoretical contribution. Specifically, a few reviewers pointed out that the experimental results are not convincing. Furthermore, some reviewers mentioned that the theoretical analysis is a relatively straightforward extension of LinUCB (to which the authors disagreed, but there wasn't any followup discussion from the reviewers). The bandit analysis is unfortunately outside my expertise. \n\nI think this paper touches upon two different domains (RNN-based recommender systems and bandit). If the authors consider that their contribution mainly lies in the latter, maybe ICLR is not the most suitable venue. "
    },
    "Reviews": [
        {
            "title": "The paper proposes an approach for exploration in collaborative filtering with theoretical justification. The proposed approach is relatively straightforward and lacks rigorous empirical evaluation.",
            "review": "The authors propose a recurrent neural network approach to jointly perform representation learning and exploration. At each recurrence step the user-item relevance score is combined with item diversity score. The diversity score compares the item to already recommended items in previous steps to encourage exploration. The trade-off between relevance and exploration is controlled with a hyper-parameter.\n\nI think the proposed approach is interesting, has good theoretical support and is presented well. However, I also have several major concerns. First, the exploration score is not used to update the RNN model or representations. From the second last paragraph in Section 3.3 the authors say that the model is trained using standard relevance objective and variance is fixed. I think the approach would have been more interesting/novel if the full equation 3 (or its approximation) was back-propagated to tailor the representations for exploration. In the current form the training algorithm is similar to the numerous item selection/sampling schemes that have been proposed.\n\nSecond, I don't think that the experimental set-up is fair. The models only get to see a small subset of data in [T0, T1), then predict on subsequent intervals and use these predictions for parameter updates. Having only been trained with data in [T0, T1) the models will be quite weak with highly unreliable predictions. This will cause the feed-back loops from subsequent intervals to also have poor signal resulting in very slow learning. Virtually any form of exploration will be beneficial here particularly for the Trivago dataset where there are only 25 alternatives. I don't think this stimulates any production environment since the models are too weak at the beginning to be deployed. This can be seen from the relatively easy MovieLens dataset where precision curves at the beginning are all near 0. I think the difference between properly trained relevance-only models and the proposed approach will be significantly smaller, especially over a longer time horizon and needs to be properly evaluated. Netflix experiments make a step in that direction but the time horizon is very short.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review on recurrent exploration networks",
            "review": "\nSummary\nThis paper proposes a model named recurrent exploration networks (REN) model to address the exploration problem in recommendation system without sacrificing the performance. The proposed approaches include an additional diversity term by using determinantal point processes. The model also adds an additional term to measure the uncertainty. The paper claims that the proposed approach can generate better long-term better performance.\n\nStrengths\n1. The diversity in recommendation is an important research topic. Being able to balancing performance vs exploration is important. This paper also identify another important aspect which is the uncertainty.\n2. The paper provides theoretical bounds for the proposed approach. \n\n\nWeaknesses\n1. The experiment of this paper is weak. For example, for the MovieLens dataset, it only selects 1000 users. Not sure why cannot compare the approach on all the users?\n2. The middle figure of Figure 3 also looks strange. Why the models' performance drops with more time steps. The authors should explain.\n3. It lacks parameter sensitive analysis to see how different values of lambda_d and lambda_u will impact the result.\n\nMinors:\n\" Essentially items\" =>  Essentially, items\n\"In this section we first\" => In this section, we first\n\nQuestions\n\nIn section 3.1 \"Strictly speaking, in an online setting where the model updates at every time step t, x_{k} also changes over time;\", why only when modeling updates in online setting, x_{k} change? Shouldn't already be changing even if it is not online setting?\nWhat is an encoder in an RNN? Did you mean input embedding?\nWhat is the time-complexity of the proposed approach? Does it impact the usage in real-time inference?\nIt is not very clear what are the time intervals to divide the data into different settings.\nWhat is the time dimension in the result figures? Are you predicting t time steps in the future?\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Limited Contribution and Weak Theoretical Results",
            "review": "Diversity is undoubtedly an important problem in recommender systems which now relies heavily on neural networks especially RNN. However, since RNN focus on a single output at each time step, it seems challenging to achieve satisfying diversified results in RNN based RS. Based on the similarity between greedy solution of DPP and exploration term in LinUCB, this paper proposes an additional diversity score for each candidate item and then uses the summation of diversity score and original RNN score to select final prediction at each step. Authors prove some theoretical results with regret bound $\\sqrt{T}$. Besides, numerical results validate the effects of proposed methods, which may be attractive to practitioners in RS. \n\nGiven the strength of this paper, I still have some concerns. First, the novel contrition of this paper seems limited. Though previous exploration term of LinUCB (or others) is calculated directly on the input feature, it is not very surprising to use it with respect to the embedding feature especially for highly sparse input, at least heuristically. Second, for theoretical results, I think the hardness mainly lies in dealing with $\\theta$ calculated by RNN instead of linear form. However, given the strong assumption 4.1, all the theoretical statements and corresponding proof seem to be nearly the same as LinUCB, and I didn't see the role of RNN. In particular, the notation $\\hat{r}_{t,k}$  in equation 4 is the same as  Line 9 in Algorithm 2, but their definitions are different, and all the proof seems to rely on notation defined in equation (4) instead of Line 9 in Algorithm 2. Third, since Algorithm 1 uses RNN through all the time horizon which may be infinite, I am not clear how to do BPTT with respect to RNN. It would be much better if authors could explain it in detail. \n\nSome other comments:\na. In the first line of section 3.3, there are two \"can\";\nb. Om the paper, authors assume the variance of $x_k$ is a diagonal matrix, I wonder whether results still hold if the covariant matrix is a general PSD matrix;\nc. $A_t$ defined in Algorithm 1 and Algorithm 2 are not used in algorithms, which can be removed;\nd. $\\hat{A}_s$ is undefined in the main content;",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A well-motivated and clearly written paper but with several issues",
            "review": "Summary:\nThe authors study the problem of exploration for recurrent neural networks in the sequential recommendation. This work presents a scoring function that combines relevance, diversity, and uncertainty during exploration.  A sublinear bound on the regret of the model is provided, and experiments show the model achieves higher reward at the final stage. \n\nPros:\n- This work incorporates diversity into recurrent neural networks with determinantal point processes. Improving diversity for recurrent neural networks is an important task in the sequential recommendation.\n- The idea of using the hidden state as the candidate estimate of \\theta in linear bandits is novel. It shows an approach to incorporate the exploration idea from bandits.\n- The effectiveness is demonstrated both theoretically and empirically. \n\nCons:\n- The reward is lower than other baselines at the beginning. I understand the model is exploring and gather information, but that would more or less hurt users' satisfaction when deploying the model to real-world recommender systems. \n- The datasets the authors used are subsets of movielens and trivago, which are a bit small.\n\nComments on the paper:\n- The performances are even worse than the RANDOM baseline at the beginning. Such a cold-start performance is not very appealing. Also how about the cumulative reward? It would be more reasonable to compare their cumulative reward to show the starting exploration is worthy.\n\n- It is said in Section 4 \"Note that unlike existing works which primarily consider the randomness from the reward, we take\ninto consideration the uncertainty resulted from the context\". Do you mean the reward r is fixed when x is fixed? And the randomness of r is dependent solely on the randomness of x? If so, this formulation is equivalent to the existing works, and why do you choose such a formulation?\n\n- The regret analysis seems to be a trivial application of LinUCB since \\sigma_k = 1 / \\sqrt{n_k}, which in total can be bounded in order of O(\\sqrt{T}). I would suggest not to sell this as a theoretical contribution.\n\n- It would be good to see how this result translates to other underlying distributions of item embeddings besides multivariate normal.\n\nOverall, this paper is well-motivated and clearly written but has several issues that remain to be clarified.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}