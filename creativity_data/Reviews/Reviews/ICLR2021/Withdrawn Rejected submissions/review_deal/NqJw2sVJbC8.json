{
    "Decision": "",
    "Reviews": [
        {
            "title": "weak model and missing some experiment details",
            "review": "This paper studies an important but less investigated domain of machine learning problems: high frequency trading, and proposes adversarial attacks against them, which is highly interesting. My summary above is somewhat less accurate, since machine learning has been a dominating class of approaches to a wide range of HFT strategies, though most of the advances are not revealed to the public to protect trading intellectual property; i.e., most public ideas, about market inefficiency, will become non-profitable very soon in the HFT domain, since players in this field will quickly pick up the ideas to trade them away.\n\nThis paper somehow suffers this problem as well: (1) the data used in this work contains less information than those typically used by trading firms; (2) the problem setup suffers small issues; (3) the model is not sophisticated enough; and (4) the performance might not lead to a useful strategy. I will talk about these issues one-by-one.\n\nFirst, the paper calculates SWAP sequences at 0.01sec intervals for one-minute periods using snapshots of top 10 levels of the order book. This is an aggregated dataset which have dropped off a lot of essential information for prediction. A straightforward alternative is to leverage the dim-20 vector of [p_i, s_i] directly rather than using the aggregated SWA data. A profitable strategy typically leverages much more information that can be drawn from the LOBSTER dataset than such a straightforward idea, let alone the models studied in this work use less. One main issue that I may worry about is that typically practitioners will indeed model such \"adversarial orders\" and generate corresponding features during the feature engineering phase before feeding them into a machine learning model. I will talk more on this issue later in the review.\n\nThis work considers a three-way classification problem: whether the price will increase above or drop below a threshold, or STAY. This problem itself may be valid: modeling if a stock will have a outstanding return. However, the description is not detailed enough on how the label is calculated and how the stats look like in the training and testing dataset. One key issue is to guarantee that the outstanding return will indeed appear in the future --- it does not clearly specify how the dataset is generated without suffering the \"forward-looking\" problem: predict some events that happened in the past of an observed data point. Further, for the future outstanding return to indeed be profitable, the thresholds need to be chosen properly, i.e., to cover the trading cost so that such a predicting model indeed induces a trading signal. We need all such details to determine if the problem is valid or not.\n\nThird, the model itself is not sophisticated enough; but maybe this is because the descriptions lack enough details about data preprocessing. I'll give one example to illustrate why this is an issue. The paper considers NVDA, whose price is in the range of 100$-200$ for the period of study. However, this price distribution will change, i.e., as of the day that this paper is reviewed, NVDA's price is in the range of 500$-600$. Machine learning models have intrinsic issues to deal with such data when its distribution is shifted, so the data (even for SWAP) typically need to be processed before feeding into a machine learning model. I do not see such details in the paper description.\n\nFourth, the model's performance (at best) is 37%, marginally better than 33.33% by a random guess strategy. Also, we do not know how much of such predictions lead to a trading signal --- the prediction is not STAY. A naive trading idea is to follow the prediction: if the prediction says the price will increase above the trading cost, the submit a BUY order. Then there is over 60% of the chance that the model will turn out to be wrong. In this case, the expectation of the return is likely negative. However, a more sophisticated strategy may leverage such a model to facilitate trading in a non-obvious way. \n\nAll above I only talk about the issues with the clean models studied in this work. Some fine-tune of problem setups could resolve these issues. I will briefly discuss some potential issues with the adversarial setup of this work. This paper considers submitting an limited order to manipulate the order book till the order is executed. Such an order typically has a market impact to the limited order book, and this is separately studied in the financial field. \n\nAlso, an adversary who can submit a manipulating limited order and also cancel the order to achieve the same goal, which is not considered in this work. In fact, some market makers indeed submitted and canceled orders to influence HFT traders in early years, and poses challenges to SEC to prevent such activities. As an important highly related research field, it would be interesting to study whether such \"adversarial orders\" can be detected from existing order books.\n\nOverall, I think this topic is interesting and worth studying. But the setup in this work is not sufficient to provide a lightening insight into this domain. Further development along the line can mitigate all these issues, and make the work more promising.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Unclear, insufficient experiments, incremental and not appropriate for ICLR's ML audience",
            "review": "### Summary\n\nThe paper presents adversarial attacks against automated high frequency trading\nsystems. The authors use historical and publicly available high frequency\ntransaction data to train a neural net based classifier at predicting whether\nthe unit price of a product (asset) will go up, down or stay constant. They\nthen propose two kinds of attacks --an untargeted white-box attack and a\nuniversal, targeted, transfer based attack-- under constraints on the attackers\nbudget and on the attack \"size\" (which enforces that changes to current orders\nbe small).  They show that their attacks significantly reduces the accuracy of\ntheir pre-trained classifiers even with very low budget (< 1$ in the white-box\nsetting) and/or attack size. Some of their universal attacks succeed on roughly\nhalf of the originally correct classifications, even when transferred to other\nclassifiers (although it's not clear from the text, if that classifier has the\nsame architecture or not). The authors also show that some of the universal\nattacks resemble a well-known \"attack\" forbidden by law called spoofing.\n\n\n### Overall rating\n\nOverall, the current text is often very approximate and not detailed enough\nfor experiments to be reproducible, nor results fully understandable. (See\ndetails below.) Moreover, the results are are very thin: the authors only\ntested their attacks on two or three classification systems: deep nets that\nthey trained on their own beforehand. Even the universal attacks were\ntransferred only two (similar) net architectures (one linear and one MLP), one\nof which was the architecture used to craft the attack. So it is utterly\nunclear whether these attacks really work/transfer to real-world systems. Also:\nhow would the attack work if the classifiers were trained using adversarial\nrobustification?  Finally, and most importantly, the main contribution\n--adapting FGSM/PGD to the particular and simplified case of high-freq trading\nsystem with its constraints that is considered-- seems really incremental and\nnot of big interest for the ML community. Therefore, I think that, even if\nimproved, this paper would inappropriate for the ICLR venue. I would rather\nsuggest to submit an improved version to a trading/finance conference.\nTherefore, to me, it is a clear reject.\n\n\n### Details\n\n1. Overall, it would be important to test your attack on more architectures (if\n  possible on real-world systems), and on robustified architectures (f.ex.\n  using adversarial training with your own attack).\n\nThe rest, in order of appearance in the text:\n\n2. Sec 3.1, regarding SWA: Why not keep all (1+1)*10 input dimensions? How\n  realistic is it that real-world price forecasts would use such SWAs? Does it\n  influence the vulnerability of the classifier?\n3. Sec 3.1, Why not use regression rather than three-class classification? The\n  data seems more adapted to regression, and it would not be difficult to\n  change the attack objectives accordingly.\n4. Sec 3.3: Could you explain the standard error upper bound?\n5. Sec 4.1: notation $\\{x_i\\}$ suggests that $x_i = ((p_{i,1}, s_{i,1}),...\n  (p_{i,10}, s_{i, 10}))$ from Sec 3.1. But later computations suggest that\n  $x_i = (s_{i,1}, ..., s_{i,10})$. A clear formula would help.\n6. Sec 4.1, def of $p_{\\{x_i\\}}$: it would help to have the input and output\n  dimensions, and work out an illustrative example to help understanding. (In\n  particular, I think that the sentence  \"The output is a perturbation\n  $\\{\\delta_i\\}$\" should be \"The output is a **sequence $\\{ \\delta_i \\}$** of\n  perturbations\".\n7. Sec 4.2: overall, the paragraph describing _cost_, _capital required_ and\n  _relative size_ is extremely unclear, especially if one isn't familiar with\n  trading. In particular, I don't fully understand the second sentence \"Since\n  assets include both cash and stocks ... filled). As for relative size, what\n  do you mean by \"as a percentage of total size on the book\": $\\delta_i / x_i$?\n  But $\\delta_i$ is multi dimensional. Did you mean it coordinate-wise; or\n  taking norms (which one)? In all this paragraphs, it would help to use clear\n  mathematical formulas.\n8. Sec 4.2: \"our algorithms limit perturbation size in terms of capital\n  required\" -> \"our algorithms limit _only_ perturbation size in terms of\n  capital required\".\n9. Sec 4.3: what means \"randomly inserting orders\"? There are many kinds of\n  randomness one could use: what size? What distribution? Right now,\n  experiments are not reproducible.\n10. Sec 4.3, last sentence: \"All random attacks have a _budget_ of ...\": cost or\n  capital? And if it's capital, does it make sense to compare it to the \\$1.00\n  from your previous sentence, which are average _costs_?\n11. Sec 4.4: $r=0.95$. Why this choice? Also, in the formula $R_r = [x + r]$, $x$\n  is a vector while $r$ is a scalar. So what do you mean?\n12. Sec 5: precise mathematical formula for $T(\\delta)$? This is **absolutely\n  essential**, since this objective is one of your main contributions.\n13. Table 2: What do you mean by \"Fooled\": is it the total proportion of changed\n  labels, or the only the proportion among the original correct\n  classifications? More generally, I suggest making the captions of your\n  figures and tables self-explanatory (so that the reader doesn't need to\n  search everything in the text).\n14. Sec 6: \"The perturbation ..., and when transferred to test data and a\n  different model, it fooled ...\" : which model architecture was it trained on,\n  and which one was it transferred to?",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting area of research, yet not qualified for publishment",
            "review": "# Main ideas of this work\nThis work introduces the popular topic of \"adversarial robustness\" into the area of algorithmic trading. It explains how to attack such a financial system as well as propose the corresponding defense.\n\n# Clarity\n1. The intention of this work is is rather straightforward. However, there are too many jargons and terms from the area of finance, which prevents researchers who do not have relevant experience to understand. These jargons and special knowledge are not general issues in the community and can not contribute to our understanding on representation learning or artificial intelligence.\n2. The reviewer can understand the formulation in the paper. Yet, due to the same reason above, I do not understand how these input and output can be adopted in practice. Perhaps the authors can provide some examples and illustrations about both standard training data and the adversarial data.\n\n# Quality\nThe method used in this work is very naive and primitive considering the current development of  deep learning. It also lacks of comparison with other methods. It seems to me that this work simply utilize the existing knowledge of adversarial robustness and put it into the area of financial problems.\n\n# Pros\nUtilizing deep learning to help financial problem is an interesting and practical topic. And according to our knowledge, this work is the first to to address the adversarial robustness issue in such an area.\n\n# Cons\n1. As a matter of fact, deep learning techniques have not been fully investigated and adopted in  the area of automatic trading. There hasn't been a canonical work about solving high-frequency trading with deep learning, making the main idea of this work, i.e. investigating adversarial robustness in high-frequency trading, not solid enough and a little bit of rushed. This fact is verified in the citation list of this work, where the author can only find relevant resources from Arxiv or amateur materials (websites or blogs).\n\n2.  The most outstanding fact of adversarial attack for computer vision is that, the malicious shift barely change appearance of the image according to human eyes. Yet, this factor is not verified in this paper. Although the author propose a distance metric to contain the shift, we haven't seen any evidence that the prediction should stay the same. This makes the motivation of this work become very questionable.\n\n3. When researchers apply the knowledge from an area (computer vision) to another (finance), they usually propose some special design and offer new insights. However, this is not true for this work. All the design are proposed in other works, and their combination also seems not an effective method",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}