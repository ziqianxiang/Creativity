{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper is very interesting and novel, and all reviewers are of the same opinion. \nThe main concern, however, is on the experimental section that is limited to image classification benchmarks and that some critical comparisons are missing (e.g. clarify factors that play key role in improvement, more computation and therefore more free parameters, how about non discriminative tasks, etc). \nThe heterogeneity question is in my opinion only partially answered by the authors but I also feel proper handling of this matter would require a proper multi-task setup and different target for the work.\nI also personally find applicability of the approach quite limited, I encourage the authors to further improve their work as I feel that with a proper revision would make a nice contribution for the community."
    },
    "Reviews": [
        {
            "title": "An interesing paper on introducing the top-down information as the supervision for multi-task neural network learning.",
            "review": "In this paper a novel top-down control network is introduced for multi-task learning. Different from the traditional bottom-up attention models, the authors introduce a top-down module to modify the activation of recognition network based on different tasks. Specifically，the proposed module consists of three identical networks, which are BU1, TD, BU2 streams. Given the input, the BU1 is firstly trained, and then the TD streams is trained by assigning the specific labels. After that, the BU2 is updated with the top-down parameters. Experimental results demonstrate the effectiveness of proposed model.\n\nStrength:\n1. It is interesting to introduce the semantic information from the top layer to guide the feature representation learning.\n\nWeakness:\n Although the experimental results show the better performance on the image classification, there are exist several unclear parts:\n\n1. The definition of multi-task in this paper refers to the different dataset’s classification? Or referring to the different tasks, e.g. localization, classification, and attributes predication. In my opinion, the authors should provide more details on designing the validation experiments. And the proposed model should be tested on different tasks instead of only on the task of visual recognition.\n2. Some bottom-up based model e.g. FiLM should be used as the baselines to validate the advantage of introducing the top-down stream.\n3. If the top-down stream would make the recognition be sensitive for the visual variations? Or the classification results may be dependent on the number of training samples?\n\n4. If the proposed model would be helpful for transfer learning?\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "More analysis would be appreciated.",
            "review": "The paper propose a way to combine image information and task information as controllers for multi-task learning. In this way, the authors expect to extract more task/image specific features in a shared backbone.\n\nThe proposed method seems novel and intuitive. Though there are some typos and grammar mistakes, overall the paper is easy to follow. \n\nMy major concerns are the followings:\n1. the claim that the proposed scheme provides scalability with the number of tasks is stretching: the number of tasks still need to predefine and the number of task heads are not optimized compared to previous algorithms. \n2. While there is improvement in performance, but it is not clear what factors causes the improvement. As compared to previous schemes the proposed model needs much more computationally (two bottom up runs and a top-down run) and utilizes more information.\n3. All the tasks are classification tasks /discriminative models. It is not demonstrated if this would be working with a mixture of generative/discriminative tasks.  \n\nIf possible, as the TD and BU's are sharing the same structures, it would be interesting to explore what are learned by visualizing the weights in each channels and layers. and further explore which feature map is heavily used for which specific task. These weights/activation distributions will help us to better understand what is actually learned in the proposed scheme.  The task spatial maps seems to be a good start, but it would be better if the author provide more analysis on intermediate layer activations ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "BU-TD Network for Multi-task Learning",
            "review": "This paper presents a new architecture for multi-task learning that uses a top-down control network to modulate the activations of the main (bottom-up) recognition network. The model is applied to four datasets/tasks: multi-MNIST, CLEVR, CELEB-A, and CUB-200, demonstrating good performance compared with baselines. I have the following comments and questions:\n\n- The proposed architecture requires the equivalent of three forward/backward passes: BU1, TD, and BU2. The number of parameters is used gauge complexity in Table 2 and Figure 3 but FLOPs might be a better metric here since BU1 and BU2 share parameters. How do the models compare in terms of FLOPs to baselines? \n- The datasets/tasks used herein are homogenous and therefore straightforward for multi-task learning. How does the proposed architecture fair in a more challenging setting involving heterogeneous tasks, e.g., Misra et al., 2016?\n- Re \"In some of the experiments of CLEVR and CUB-200 datasets we added an auxiliary loss at the end of the TD stream. The target in this case is a 224x224 mask, where a single pixel, blurred by a Gaussian kernel (s.d. 3 pixels) was labeled as the target location.\", How was this mask obtained? How do the models perform without the use of this auxiliary loss? Why was this loss only used in CLEVR and CUB-200?\n\nMinor:\n- Add references to first column in Table 2.\n\nTo conclude, the proposed architecture is novel, the paper is clear, but the experimental work leaves some questions unanswered.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}