{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "As the reviewer confidence of the reviews of 2.8 or lower, I made a full and detailed pass of submission as it was requested by the PCs. \n\nThe paper studies how to parallelization of MCTS affects its performance and provides the analysis of the excess regret - how much  \"error\" we incur by  parallelizing as opposed to single-threaded execution.  The submission however does not give convincing arguments on why existing parallel methods perform empirically under their sequential counterparts. This would be particularly useful for the settings described in the submission, which are only resembling the actual parallel solutions. \n\nFurthermore, the paper analysis of a \"cumulative regret\" in which it counts the errors made for the exploration - but the setting here is a MCTS (search, planning), when we access an oracle (a model of the environment) and we should be rather interested in the sample complexity, studied for example in https://www.cis.upenn.edu/~mkearns/papers/sparsesampling-journal.pdf that gave early results and many follow ups until OR  we should study how good the final policy it --- and in your parallel setting (which is indeed very timely), how small the excess error of this final policy is. [Or you only focus on a single action recommended by MCTS and you study some pure-exploration measure: best-arm identification, simple regret, \\eps-BAI, ... ]\n\nFrom the theoretical side modeling practice,  I don't see the theoretical framework provided to be suited with practical considerations that an MCTS is facing.  Specifically the need of condition 1 for the consequence of Theorem 1 to hold is very worrying.  Briefly it states that if  the value and the counts are not the same as reference method, then the results obtained from the that parallel executions would not match the results reference method.  While this true, it simply tells us that it would be good if the parallel threads came up with the same value as the reference method - the main issue that this does not tell the practitioner how to assure the condition states in Eq 8. It would be much more interesting to characterize that, i.e., under which conditions (in particular, that the practitioner can influence OR  at least verify prior to the execution) is the property stated in the Eq. 8 satisfied. \n\nTheorem 2 bring additional concerns. A book of Munos on MCTS (https://hal.archives-ouvertes.fr/hal-00747575v4/document) has Section 2.3 devoted why vanilla UCT has poor performance. There is work by  Kocsis and Szepesv√°ri studying under which conditions UCT can have favorable regret -  there is at least a discussion missing why Theorem 2 would be able to bypass known hardness for UCT for higher depths, and if not I question its utility. Finally, from finite time result excess I would expect more finite time lessons learned beyond \"regret term that converges to zero as n increases\". \n"
    },
    "Reviews": [
        {
            "title": "Parallel MCTS",
            "review": "The authors consider a general family of parallel MCTS algorithms, and  derive some properties which algorithms in this family must satisfy in order to converge to zero excess regret on any MDP. They then analyze various parallel MCTS algorithms against these properties and propose a new algorithm (BU-UCT) which satisfies them. Empirical results are given on Atari, showing BU-UCT outperforming baselines.\n\nI was unable to verify the key claim that all of the prior parallel MCTS algorithms are indeed members of the family of algorithms considered. ",
            "rating": "7: Good paper, accept",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "Interesting technique inspired by theoretical results",
            "review": "The paper looks at the issue of parallelising Monte Carlo Tree Search (MCTS). While existing techniques for doing this are well known and have been studied in practice, this paper makes theoretical contributions to understanding what properties a parallelisation scheme should have in order to minimise the performance losses inherent in parallelisation. Based on this, they propose a new parallelisation method and provide results showing it outperforming existing techniques.\n\nThe paper provides a sensible background to previous approaches. While it is rather brief due to the paper size, the important previous work is described at an understandable level. The related work section at the end of the paper is rather odd. Much of the research mentioned in here has already been mentioned much earlier in the paper - often in greater depth. It would be better to merge anything that only appears in this section into the introduction or preliminary material.\n\nThe presentation of the theoretical results is handled well. The results are first stated and explained in clear language with intuitive explanation of why they should help the search. This is later formalised in terms of regret. The main theoretical result in the paper have proofs in the supplemental material but this is not stated in the main paper - e.g. a reference to appendix C.1 is needed just above or below Theorem 1. The necessary conditions on Q appears hard to guarantee in practice (though future work might provide bounds to it or other approximations).\n\nThe new algorithm proposed is inspired by the theoretical results developed. That is to say, one of the necessary conditions appears essentially impossible for an algorithm to meet in practice so the technique derived aims to reduce the amount by which it is violated. As a result, the novel algorithm does not have any theoretically guaranteed behaviour, but the presented results indicate that it works well in practice.\n\nThe description of the \"aggregation\" in the algorithm is rather weak. What exactly is aggregated and when is it backpropagated? i.e. are statistics gathered and then the average only backpropagated when N have been seen (and if so what is N) or does aggregation only happen if several workers are currently exploring the same node? There are several ways that multiple scores could be aggregated and further description of how this works is definitely needed to make the algorithm understandable.\n\nAs the paper acknowledges the results are tentative rather than comprehensive. The setting doesn't appear in any way deliberately biased, but there is only a single setting of the algorithm considered. Given that the paper also presents both theoretical results and a novel technique, a slightly weak results section can probably be accepted.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Official Blind Review #2",
            "review": "This paper builds on WU-UCT and further explores effective parallelization of MCTS. It introduces two necessary conditions (Q, N) that are further used to motivate BU-UCT (and extension of WU-UCT). These conditions are then used for theoretical analysis in simplified settings (tree of depth 2). Furthermore, the paper includes interesting analysis, motivation and results on Atari games.\n\nStrong points:\n\n- Previous work is well cited (though I think in some cases misinterpreted, see the weak points).\n\n- The figure 2b is interesting, and nicely fits the presented motivation\n\n- BU-UCT is well motivated\n\n- I enjoyed the empirical analysis on Atari games.\n\n\nWeak points:\n\n- The paper (as well as the previous work of WU-UCT) claims that the virtual loss used in ALphaGo [Mastering\nthe game of go with deep neural networks and tree search. nature, 529(7587):484, 2016.] modifies value, while the innovation here is increasing the visit counts. This is not true, virtual loss (as used an described in AlphaGo and followup papers) modifies visit counts in the very same way WU-UCT and BU-UCT does!\n\n- The theoretical framework / claims is very limited, and follows easily from the bandit settings. It has limited connections to the MCTS settings - I appreciate though that the authors are very open about those limitations.\n\n-  The necessary conditions really just say \"one needs to have the same/similar visit counts (N) and value (Q) as if one ran sequential MCTS\".\n\nRecommendation:\nI think this is an ok paper - \"weak accept\". While the theory is not amazing, the motivations are solid and this paper brings some interesting insights. \n\nAdditional feedback:\nPlease see the virtual loss comment and fix the corresponding text and description, as it not correctly represents the previous work.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting insights into parallel MCTS",
            "review": "The paper discusses the theory behind parallelization of Monte Carlo Tree Search, and establishes some necessary conditions for excess regret to vanish asymptotically. The paper also provides a limited theoretical analysis of regret of WU-UCT, an earlier introduced parallel MTCS variant and the current state-of-the art, for a settings of tree depth bounded to 2 (that is, essentially flat MBA). A different algorithm, BU-UCT, is introduced in the paper which satisfies, like WU-UCT, the necessary condition. The algorithm builds on intuition of WU-UCT but also attempts to decrease the action value gap.  The algorithm is evaluated on 15 Atari games, showing performance comparable or exceeding that of WU-UCT and other parallel MCTS variants.\n\nI find the paper an interesting and easy to follow. Parallel MTCS (UCT) variants are indeed not analysed theoretically well enough (and in fact sequential UCT analysis is not flawless either) and any contribution in this direction is very welcome. This paper spots the importance of proper estimation of visit count and value gap (theorem 1). My main concerns with the paper are:\n\n1) somewhat imprecise definitions\n2)  superficial discussion of cumulative vs simple regret, with citations missing\n3) the theoretical analysis of WU-UCT, limited to depth 2 and nontrivial to extend to unlimited depth, is a minor contribution since behavior of bandit algorithms in trees can be very different than in this special case\n4)  limited empirical evaluation, on one domain and with settings to chosen for that particular domain.\n\nIn detail,\n\n* the paper defines MDP as a 5-tuple, including the discount factor. The discount factor is not a part of MDP, it is a trick used under certain conditions to analyse and search for policies in MDPs. In game settings in particular, the discounted MDP is often *not used* because the reward of individual actions is zero, and the value of a rollout is determined by the final action (win/loss and by what score) only.\n\n* the paper defines the cumulative regret (7) in a way that can be understood by someone who knows what cumulative regret is, but the same definition can be used for simple regret (!) with the same formula but different discussion. Bibliographic references cite papers on flat bandits rather than trees, and it would be hard to connect cumulative regret for MBA to the formula provided. Simple vs cumulative regret  was analysed  theoretically quite well (https://arxiv.org/abs/1207.5536 AAAI, https://arxiv.org/abs/1408.2048 UAI) and I believe these works should be cited, and the choice for cumulative regret justified in their light.\n\n* the theoretical analysis for depth tree 2 is not obvious to extend to a more general settings, and thus its importance is questionable. \n\n* BU-UCT introduced to highlight importance of design based on the theoretical analysis in the paper, analysed on a single domain with conditions tuned for that domain compared to algorithms chosen by paper authors. Performance numbers in this setting indicate that the domain for empirical evaluation is chosen well in favor of the proposed algorithm, but not necessarily that the algorithm is better than others. There are may be settings in which BU-UCT does not perform as well. I would prefer to either see insights (detailed analysis) why other algorithms failed or underpeformed when BU-UCT succeeded on selected problem, or an empirical evaluation which gives the impression of being unbiased. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}