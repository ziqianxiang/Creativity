{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "After the rebuttal phase, all scores are borderline (6) or negative (4). Among the most confident reviewers (confidence 5), one gives 6 and one gives 4. The reviewer with confidence 4 gives overall score 6 but states they cannot support the paper. There were several concerns about the novelty of the task and method, the challenge of the experimental settings, missing comparisons to recent prior work in the original paper, etc. While the reviewers see merit, the paper can benefit from another revision before being accepted, including to better position the novelty of its method and perhaps reduce claims of novelty of the task. "
    },
    "Reviews": [
        {
            "title": "The paper proposes a new problem setting for learning object detectors using weak supervision as well as a deep learning solution. However, the presentation and its relation to previous works should be improved.",
            "review": "\nThis paper defines cross-supervised object detection which learns a detector from both image-level and instance-level annotations. It proposes a unified framework along with a spatial correlation module for the task. The spatial correlation module is used for transfer mapping information from base categories to novel categories. It conducts experiments on the PASCAL VOC dataset and COCO dataset, demonstrating the effectiveness.\n\nPros:\n(1) The proposed spatial correlation module is a novel and effective transfer module.\n(2) The ablation studies are relatively complete. \n\nCons:\n(1) The structure of the proposed spatial correlation module should be described in more detail. What is the meaning of “replacing the backbone and feature pyramid network with five max-pooling layers.” in the heatmap detection part?\n(2) In Table 1, are the experimental settings of those competitors such as MSD-VGG16, MSD-Ens, and Weight Transfer et al. exactly the same as those used in this paper?\n(3) In Table 2, it seems like the method taking the non-VOC as the base classes while Hu et al. (2018) use the non-VOC as those classes without mask annotation. Can you tell me the reasons for this choice?\n(4) Some similar problem settings are defined in [a] and [b]. The paper fails to compare the problem settings and justify the usefulness of the proposed problem setting in real application scenarios.\n\nOverall evaluation: The major contribution of this paper comes from the spatial correlation module. However, I still have some doubts about the structure of this module. Since this task is first presented, I want to make sure that the comparison is as fair as possible. \n\n[a] Weakly- and Semi-Supervised Fast Region-Based CNN for Object Detection. Journal of Computer Science and Technology (JCST) 34(6): 1269–1278 Nov. 2019.\n[b] LSTD: A Low-Shot Transfer Detector for Object Detection, AAAI 2018",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Duplicate task settings and limited novelty",
            "review": "Paper summary:\nThe paper proposes a new task cross-supervised object detection, which trains object detectors on the combination of base class images with instance-level annotations and novel class image with only image-level annotations. A network with a recognition head which is trained by image-level annotations and a detection head which is trained by instance-level annotations is proposed for the task. To generate instance-level annotations for novel class images with only image-level annotations, the paper proposes a spatial correlation module to generate pseudo gt boxes from high-confidence boxes. Results on PASCAL VOC and COCO show that the proposed method obtains very promising object detection results for novel classes.\n\n\nStrengths:\n\n+ The paper is well written.\n\n+ Promising experimental results are obtained by the proposed method.\n\n+ The proposed spatial correlation module is interesting.\n\n\nWeaknesses:\n\n- Duplicate task settings.\nThe proposed new task, cross-supervised object detection, is almost the same as the task defined in (Hoffman et al. 2014, Tang et al. 2016, Uijlings et al. 2018). Both of these previous works study the task of training object detectors on the combination of base class images with instance-level annotations and novel class image with only image-level annotations. The work (Uijlings et al. 2018) also conducts experiments on COCO which contains multi-objects in images.\nIn addition, the work  (Khandelwal et al. 2020) unifies the setting of training object detectors on the combination of fully-labeled data and weakly-labeled data, and conducts experiments on multi-object datasets PASCAL VOC and COCO. The task proposed by this paper could be treated as a special case of the task studied in (Khandelwal et al. 2020).\nWe should avoid duplicate task settings.\n\n- Limited novelty.\nThe novelty of the proposed method is limited.\nCombining recognition head and detection head is not new in weakly supervised object detection. The weakly supervised object detection networks (Yang et al. 2019, Zeng et al. 2019) also generate pseudo instance-level annotations from recognition head to train detection head (i.e., head with bounding box classification and regression) for weakly-labeled data.\n\n\nReview summary:\nIn summary, I would like to give a rejection to this paper due to the duplicate task settings and limited novelty.\n\nKhandelwal et al., Weakly-supervised Any-shot Object Detection, 2020\n\n---------- Post rebuttal ----------\n\nAfter discussions with authors and reading other reviews, I acknowledge the contribution that this paper advances the performance of cross-supervised object detection.\n\nHowever, I would like to keep my original reject score. The reasons are as follows.\n\nExtending datasets from PASCAL VOC to COCO is not a significant change comparing to previous tasks. The general object detection papers also evaluated on PASCAL VOC only about five years ago and now evaluate mainly on COCO. With the development of computer vision techniques, it is natural to try more challenging datasets. So although this paper claims that this paper focuses on more challenging datasets, there is no significant difference between the tasks studied in previous works like [a] and this paper.\n\nIn addition, apart from ImageNet, the work [b] also evaluates their method on the Open Images dataset which is even larger and more challenging than COCO. The difference between the tasks studied in [b] and this paper is only that, [b] adds a constraint that weakly-labeled classes have semantic correlations with fully-labeled classes and this paper doesn't. This difference is also minor.\n\nTherefore, the task itself cannot be one of the main contributions of this paper (especially the most important contribution of this paper). I would like to suggest the authors change their title / introduction / main paper by 1) giving lower wights to the task parts 2) giving higher weights to intuitions of why previous works fail on challenging datasets like COCO and motivations of the proposed method.\n\n[a] YOLO9000: Better, Faster, Stronger, In CVPR, 2017\n\n[b] Detecting 11K Classes: Large Scale Object Detection without Fine-Grained Bounding Boxes, In ICCV, 2019",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Innovative formulation, but more comparisons are needed",
            "review": "**Summary and contributions**:\nThe paper presents a new task formulation for transferring knowledge for object detection from fully labeled classes to weakly labeled ones, with better results for complex scenes. So the authors propose to learn object detectors for novel classes (which were not seen at training time but specified apriori), based only on that object class label and the bounding boxes for other objects in the image (from the base classes). Compared with other works, the solution claims to be better on the localization aspect, focusing on the object as a whole, not only on its discriminative parts. Nevertheless, there are very few competitors taken into account. The model combines three components: a detection head and a recognition head, based on the same, unified backbone architecture, and a spatial correlation module that aligns the two heads. The authors test their solution, Cross-Supervised Object Detection, on PASCAL VOC and COCO (multi-object scenes).\n\n**Strengths**:\n- Proposing a model that succeeds in learning both novel and base classes at the same time, on two heads, extracting information from the weak labels (recognition head) and using it as supervision for the second head (detection head).\n- The qualitative results look significantly better compared with single heads, containing more of the entire object, not only the important/discriminatory parts as the authors pointed out.\n- FCOS with only 5 conv layers reaches a good enough performance.\n\n\n**Weaknesses**:\n* How does this work compare with other WSOD recent methods, e.g. C-MIL, [A, B, C] from the experimental results point of view, and the amount of supervision?\n* The text/figure should be adjusted to better map one each other: Sec. 3.2: “The image and proposals are fed into several convolutional layers”, but in the figure, the proposals skip those layers.\n* Section 3.2 is rather hard to read and understand (it has several inaccuracies in the formulas).\n\n**Quality**:\nThe paper is technically sound.\n\n**Clarity**: \nThe paper is mainly clearly written (except for Section 3.2 Recognition Head).\n\n**Novelty**:\nThe components are not novel, but the proposed learning paradigm is novel.\n\n**Significance of this work**:\nThe impact of the work is significant, enabling a new way (CSOD) of transferring knowledge between classes, using weak labels.\n\n**Typos**:\n- “corresponds to the respective element of the matrix...” the following formula is wrong (d should be replaced with r) \n- what does the upper index R mean and why is it useful?\n- matrices should be capital letters in bold\n- “which is expresses”\n\n\nWhile I have some doubts regarding the comparison with other works, I hope they will be clarified during the rebuttal.\n\n\n[A] High-Quality Proposals for Weakly Supervised Object Detection, Cheng, G., Yang, J., Gao, D., Guo, L., & Han, J..Transactions on Image Processing 2020 \n\n[B] Instance-aware, Context-focused, and Memory-efficient Weakly Supervised Object Detection. Zhongzheng Ren, Zhiding Yu, Xiaodong Yang, Ming-Yu Liu, Yong Jae Lee, Alexander G. Schwing, Jan Kautz. CVPR 2020\n\n[C] Mixed Supervised Object Detection with Robust Objectness Transfer, Yan Li, Junge Zhang, Kaiqi Huang, Jianguo Zhang. PAMI 2019",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good paper in every aspect, but with limited novelty.",
            "review": "This paper introduces a new method for training an object detector on a dataset that consists of some object categories with instance-level bounding box annotations, as well as some other object categories with only image-level labels. The topic is interesting, important, and potentially very useful for real applications. The authors propose an idea to transfer knowledge from a weakly supervised (WS) detection head into a fully supervised (FS) detection head, by producing pseudo-ground-truth bounding boxes for classes with image-level labels. The idea is straightforward and interesting. Experiments show significant and consistent gains in various scenarios. The paper is well-written.\n\nThe main drawback of this paper is the lack of substantial novelty. The authors claim to propose a \"novel paradigm\" named cross-supervised object detection, while this task has already been studied as reviewed in Section 2. Particularly, the idea of jointly training WS and FS heads on WS and FS labels with a shared backbone has been explored before (e.g. in [1], which should have been discussed in the related work). The idea of using a WS model to create pseudo-ground-truth bounding boxes for training another model has also been studied before (e.g. in [2]). The only novel idea of this paper seems to be the Spatial Correlation Module (SCM), which is discussed more below.\n\nSCM is used to transform proposal boxes selected by the WS detector head into more accurate bounding boxes to serve as pseudo-ground-truth for WS classes. To this end, the authors train a class-agnostic bounding box refinement module on FS classes, and apply it on the proposals of WS classes. However, a similar result could have been (probably) achieved by simply replacing the bounding box regression head of the Faster R-CNN with a class-agnostic head, and training it on base classes, while using it to refine the proposals of both base and novel classes during test. The authors did not explore such simple alternatives to SCM.\n\nAnother issue is that although the authors cited several existing methods for cross-supervised object detection in Section 2, they did not discuss why the proposed method is superior, and they did not include them in performance tables, claiming \"these methods can only perform object localization in single object scenes.\" I cannot verify the correctness of this claim, as any proposal-based model can detect multiple objects per image and per class. \n\nNevertheless, the paper has a clear motivation and idea, a scientifically sound analysis, and significant results and insights that can be helpful for future work. Therefore, I recommend acceptance. If the authors can convince me that the paper also has substantial novelty and advantages over all existing works, I am willing to raise my rating.\n\nMinor comment: In equation (1), the two terms of the binary cross-entropy should probably be placed in parentheses, so the sum is applied on both terms. Also in the paragraph above eq (1), that loss term should be defined as a multi-label cross-entropy, rather than multi-class.\n\n[1] Yang, Hao, Hao Wu, and Hao Chen. \"Detecting 11k classes: Large scale object detection without fine-grained bounding boxes.\" Proceedings of the IEEE International Conference on Computer Vision. 2019.\n\n[2] Tang, Peng, et al. \"Multiple instance detection network with online instance classifier refinement.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.\n\n######## Post-Rebuttal Updates:\n\nAfter reading the authors' response and other reviewers' opinions (especially R3), I would like to downgrade my rating slightly from 7 to 6. I still think the paper makes valuable contributions, but I also think the contributions are overstated and not precisely justified. Particularly:\n\n1. I agree with R3 that the limitation of novelty should be considered from the two perspectives of \"task\" and \"method\". The task is certainly not new, which should be made clear in the paper. The newest version of the paper still claims \"we define a new task—cross-supervised object detection\"\n\n2. The method is indeed somewhat new, due to the use of multi-task learning and SCM, but its novelty should be clarified, and compared to all similar methods, not only some of them which are weaker. For instance, the authors did not adequately justify whether/why their method is superior to YOLO 9000, or Yang et al ([1] above). They did mention some differences in response to R3's comments and mine, but I am not convinced. Moreover, the authors did not explicitly discuss and compare those distinctions in the paper, neither quantitatively nor intuitively.\n\n3. In response to R3, The authors claim they \"are the first to address this problem in situations of realistic complexity\", which is not accurate. Particularly, the paper reads \"While several works [...] have explored this problem before, [...] They struggle to learn under more complex and realistic scenarios, where there are multiple objects from potentially very different classes\" This is not entirely true, as Yang et al. successfully evaluate on Open Images (and also VOC and COCO in their supplementary materials). The authors do not provide a convincing reason or evidence of existing methods \"struggling\" in realistic settings. YOLO 9000 is open-source, and could have been compared to the proposed method to confirm that claim.\n\nAccordingly, I strongly encourage the authors to refine their claims and lay more emphasis on the actually novel aspects of their method, by thoroughly comparing those novelties with all similar methods. I still hope to see this paper accepted, but cannot endorse it due to insisting on inaccurate claims.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}