{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper introduces and analyses a method to train a population of VAEs with mixed continuous (referred to as \"style\") and discrete (referred to as \"labels\") latent-variables. The population is trained under the constraint that inferred discrete latent variables  to be the same for all models.\nThe paper also investigates a data augmentation mechanism inspired by  (Antoniou et al., 2017).\nThe presentation is overall clear and the idea is interesting, although the language of \"agents\" is not standard in generative model literature and is a bit confusing. The experiments also show very good clustering results of the proposed method.\nUnfortunately the pipeline was determined to be quite complex while the motivation for its design choices were unclear. This, combined with multiple concerns about the experimental validation, led to a reject decision.\n"
    },
    "Reviews": [
        {
            "title": "Interesting work, but some concerns with the current presentation",
            "review": "This work presents a new approach to handling categorical latent variables in VAEs. The method has two key components: a *multi-agent* architecture in which categorical assignments are generated through consensus across multiple VAE models and a data-augmentation method which allows each model (termed *agent*) to be trained on a perturbed version of the original data. The authors provide some theoretical justification for their approach and evaluate on two benchm`ark data-sets and one real-world application.\n\n**Strengths**\n1. The method presented seems to be quite novel, with various technical contributions required to jointly train the separate VAE models in a way that they didn't collapse to a single model.\n2. The evaluation on MNIST and dSprites provide empirical evidence that this method out-performs a number of baseline methods. To my knowledge, the methods selected are good candidates for being SOTA methods for VAEs with discrete latent variables.\n3. The application to the scRNA-seq provides further evidence that the method works well on real-world data.\n\nHowever, I have some concerns with the presentation of the paper as is. If the authors can address these, I am happy to increase my score.\n\n**Questions / Concerns**\n1. While I did not have time to check all the proofs in detail, I wasn't convinced by the proof of Proposition 1 in Appendix A. A few specific things on which I would appreciate clarification from the authors:\n\na) It seems like the proof (as stated) would follow if all the agents were identical, but this doesn't match what one would expect. Can the authors make the impact of using different agents more explicit in the assumptions and explain how this leads to the conclusion?\n\nb) The proof assumes the augmented samples are generated from p(x | \\phi = n) but the method generates augmented samples as augmentations of a specific training example x_n. Can the authors explain why they believe this isn't an issue to the relevance of their result?\n\nc) Going from (6) to (7) appears to assume that the probability for each augmented sample is the same. We would not expect this to be the case for a single agent or multiple agents. Can the authors explain the basis for this step?\n\n2. I believe there are a number of different lines of research which could be considered as relevant related work which the authors have missed. \n\na) Boosting Variational Inference [1,2] describes techniques which use a mixture of variational distributions within the VI setup to provide a better approximation to the posterior. While the method presented here is not strictly a boosting method, it is quite possible that the gains seen are a result of being able to better approximate the true posterior by allowing the model to fit multiple inference networks. \n\nb) Consensus clustering aggregates the results of a clustering algorithm over multiple initialisations [3]. This often gives an improvement over the output of a single instance of a clustering algorithm and can be applied post-hoc to any algorithm that outputs cluster assignment. For example, a consensus version of CascadeVAE could be considered as an additional method in the experiments.\n\nc) Co-training is a method for training classifiers on multi-view data such that they predict same labels for co-occurring patterns in each view. This was originally presented by Blum and Mitchell [4] as an approach for semi-supervised learning and was subsequently applied to unsupervised learning by Kumar and Daume III [5]. The key idea in methods that leverage co-tr`aining is to use consensus across the different models, which feels similar to the consensus constraint in equation (3). As well as being relevant related work, the theoretical perpsective of co-training might also be useful to address some of the concerns stated about the theoretical result in this paper.\n\n3. I'm not sure how informative Figure 3 is. It's to be expected that the best performance will come when the dimension of the latent variable is equal to the true number of classes, but this will not be available in the fully-unsupervised case where the true classes are unknown. It would be useful if model selection using AMP was shown to lead to the correct number of classes for MNIST, but it wasn't clear to me if this could be inferred from the plot. If this is what the authors intended to show, they should add some additional text to explain why this is the case.\n\n4. In the experiments on MNIST, the authors compare to the case where m=10, S=10 (Table 3 of Jeong and Song). But Jeong and Song reported higher accuracy (with lower variance) for  the case with m=4, S=10. Why did the authors choose to compare against the lower performing of the two configurations studied in Jeong and Song?  \n\n5. It wasn't 100% clear to me whether the model uses fully independent VAEs (i.e. separate parameters for encoder and decoder in each model), but I believe this is the case. It would be informative to compare against the case where the decoder network has the same parameters in each model. I suspect the gain is primarily due to the fact that we are aggregating over different encoders / inference networks and this additional experiment would make this clear. \n\n**References**\n1. Guo et al. (2016). Boosting Variational Inference\n2. Locatello et al. (2018). Boosting Black Box Variational Inference\n3. Monti et al. (2003). Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data\n4. Blum and Mitchell (1998). Combining labeled and unlabeled data with co-training\n5. Kumar and Daume III (2011). A co-training approach for multi-view spectral clustering",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "OK submission but lack of  motivation and proposed model is computationally expensive",
            "review": "This paper proposed a multi-agent VAE model that combines multiple copies of VAEs with coupling constraints to improve its latent representation learning (by encouraging discrete variable consistency). The experiments show that the proposed model outperforms other discrete&continuous VAE models in terms of clustering ACC. The experiment is conducted on MNIST and scRNA-seq datasets.\n\nOverall\n===\nI think this is a good submission in terms of describing its methodology. However, it is hard to justify its motivation as the model is over-complex, and the same task could be achieved by other approaches such as deep clustering. It is better if the authors could include such discussions in the paper. \n\nPros\n===\n1. This paper gives sufficient justification on why we need multiple copies of estimators to reach better estimation. \n2. The method description given in Section 3.1 is quite clear as the equations are self-explainable. \n3. Results shown in table 2 indicate significant performance improvement.\n\n\nCons\n===\n1. The approach proposed itself is very complex comparing to other generative model architecture. It is hard to justify if the model can generalize to other tasks other than simple, low-dimensional tasks. Consider maintaining multiple VAEs graphs in memory; it appears hard to take advantage of this work. Is the cost of deploying this model worth the performance improvement (as Table 1 shows limited improvement)? Also, to train such a model, the user also needs to produce a type-preserving augmentation, which is very costly for clustering.\n\n2. The proposed model jointly optimizes the main objective (as Equation 3) and also optimizes the relaxed equivalent constraints at the same time (as Equation 6 last component). Is there any justification why not alternative optimization but joint? As the DeepClustering paper mentioned, alternative optimization is better than joint in their case. Not sure if there will be a similar observation here. Isn't it comparable to the DeepClustering paper if the goal is to do the clustering and interpretation?\n\n3. The introduction of this paper gives me a hard time to follow as the terminology used is uncommon in generative model literature (single-agent, multi-agent). I was confused as it appears to be an RL paper at the beginning.\n\n\nMinors\n===\n1. Which style state shown in Figure 2 (b-e) if you have multiple agents? The description said those are four style/state dimensions, but there are two agents in the experiment setting, and each of them has 10 style/state dimensions. Please be more precise. \n2. Figure 1 (b-c) is not quite informative, and they are too close to each other. It is better to provide a more intuitive demonstrative figure. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The authors propose a framework to learn a mixture distribution (a distribution which consists of continuous and categorical variables) using a coupled variational autoencoder framework. The different autoencoders are trained using augmented samples which are generated using a VAE-GAN framework. The idea of using coupled autoencoders is compelling and it makes sense and is well-known that data augmentation increases performance - given the ‘new’ data is good enough. ",
            "review": "Quality\nThe paper proposes good ideas that are compelling and make sense. Using multiple agents and data augmentation seems directions worth pursuing to improve mixture representation learning.\nThe experiments are mostly clear and well-motivated. Unfortunately, the related work is limited and could be improved and extended. For the evaluation of the data augmentation step, there is only a qualitative evaluation in Figure 2. A more in-depth analysis regarding the type-consistency would strengthen this part of the pipeline.\nIn section 2, the authors say that previous work falls short in efficiently learning mixture distributions due to hyper-parameter tuning or additional cost due to the optimization procedure. In the proposed work, there are some (e.g. coupling hyper-parameter lambda, temperature tau or gamma in data augmentation) new hyper parameters introduced as well. This somehow contradicts the motivation of the method and it is not evident why the proposed method is more efficient. Additionally, ablation studies on critical hyper-parameters like lambda or the temperature parameter would be interesting to see and strengthen the paper. Without further evidence, the claim of a more efficient method is not really justified in my opinion.\n\nClarity\nIn general, the paper is well and clearly written. A related work section is missing which makes it more difficult to position the proposed work with respect to previous work. The authors motivate the representation learning part but sometimes use the term clustering. In my opinion, this weakens the motivation and goal of the paper.\n\nOriginality\nThe paper presents a novel view on mixture representation learning using data augmentation which itself is not a new idea nor do they use a new method to augment the data. The multi-agent view on mixture representation learning is a new idea (to my knowledge, but not aware of all related work) making the paper original.\n\nSignificance\nThe ideas of the paper are significant and worth pursuing.\n\nQuestions to the authors\n-Proof of Proposition 1, equation 7: I do not fully understand where the factor A is coming from in eq. 7. Isn’t this assuming that all agents agree on p(x_a | phi = m)? Is this valid? Thanks for explaining this a bit more in detail.\n-Is your final objective still a valid ELBO? In the proof in the appendix you use approximations to derive the objective, but not only bounds. So I am not sure if it is still an ELBO.\n-In the experiments (Table 1), why is only jointVAE used with augmented data and not cascadeVAE which seems to perform better in its vanilla version? \n\nFurther Comments\n-The work has limited comparison to previous work. Bouchacourt et al.’s “Multi-Level Variational Autoencoder: Learning Disentangled Representations from Grouped Observations” presents a similar idea of using content/class and style/state spaces (only with continuous variables). A comparison to this work showing the potential benefit of using a discrete class space would improve the quality of the paper. \n-I am happy to upgrade my score if the authors address my concerns.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Official review 4 on the borderline",
            "review": "====================================================================================================\n\nSummary : \n\nThe paper proposed the new disentanglement approach based on the \"wisdom of the crowd\". First, the proposed method enforces the consensus on the categorical assignments from the different agents. Each agent receives a similar image that is generated from the data augmentation method (based on the VAE-GAN technique).  The encoder of each agent first estimates the categorical distribution and estimates continuous variables from the categorical data and original image. The proposed method focuses on disentangling categorical information. The evaluation also focuses on categorical data and the proposed method outperforms the other single-agent baselines.  \n\n===================================================================================================\n\nReason for score: \n\nOverall, I'm on the borderline between acceptance and rejection. The proposed method is persuasive, but the ablation study is required to improve this paper. I will finalize my decision after reading the reviews from the other reviewers and authors' responses to my concerns.\n\n====================================================================================================\n\nStrong points: \n\n(1) I was impressed by the idea to generate a similar image with the same class label through techniques developed from VAE-GAN since this idea reverts the unsupervised setting into a weakly-supervised setting. In this regard, I have a concern (See cons). \n\n(2) I like the proposed multi-agent approach to increase the robustness of the classification label. Maybe this method largely reduces the variance from the different seeds.\n\n====================================================================================================\n\nCons :\n\nThe idea which leverages a similar image with the same class label is quite similar in the disentanglement under weakly supervised setting as in [1]. Therefore, type-preserving augmentation seems critical in the performance of the proposed method. In this sense, I believe the ablation study on the augmentation method is required to persuade readers and to provide guidelines for future research. (e.g. Adding gaussian noise, Mirror image)\n\nEven though the disentanglement score cannot be evaluated without supervision on the labels, I recommend authors to compare the disentanglement score with other baselines(Joint VAE, Cascade VAE), 'I(s;c)', and etc. \n\n=============================================================================================================\n\nAfter Rebuttal : \n\nSorry for the delay. I checked the comments of the other reviewers, responses, and the revised version. The authors address my concerns in the revised version. I vote for marginal acceptance. \n\n[1] Weakly-Supervised Disentanglement Without Compromises, ICML 2020",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}