{
    "Decision": "",
    "Reviews": [
        {
            "title": "Recommend to reject",
            "review": "The authors introduce an attention-based method for learning with noisy labels using multiple labelers based on learning a meta-model to provide attentional weighting of the labels. They compare their method against that of (Tanno et al., Learning From Noisy Labels By Regularized Estimation Of Annotator Confusion, 2019) and (Zhang et. al., \"When radiology report generation meets knowledge graph\", 2019) on CIFAR10 and chest x-ray datasets. \n\nI found the explanation of the method somewhat confusing. Overall, this appears to be a more complex method than Tanno et al.'s, and with limited improvement. Unconvincingly, in fact, it appears that the proposed method does not perform as well as any of the other methods compared including the baseline ResNet 50 on the MIMIC-CXR dataset, and not as well as Zhang et al.'s method (labeled NG) on OpenI dataset. \n\nMinor errors:\n\nUneven number of parenthesis in equation 2. \nTypo: \"with the attended label and a globla learning rate\"",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Novel approach; would be great to benchmark this technique against more baselines",
            "review": "In this paper, the authors propose a meta-training technique to work with image datasets with multiple noisy-label sets. I read this paper with great interest; this is a novel framework that is definitely worth exploring.\n\nI have a few questions and concerns that I’m hoping that the authors can help me with:\n1. Given multiple noisy label sets, it will be ideal if we can compare and benchmark your technique to: (1) majority vote: for every image, assign the label that appears in the majority of the noisy labels, and then train the image model using majority vote labels (2) assigning weights to noisy label sets based on how frequently they agree with the majority. For e.g. for the chest x-ray classification task where you have 4 labels sets: chexpert_u0, chexpert_u1, negbio_u0, and negbio_u1, let’s assign an overall weight to chexpert_u0 based on how many times chexpert_u0 agrees with the majority of the 4 label sets; similarly, let’s assign an overall weight to chexpert_u1, negbio_u0, negbio_u1. Now, let’s normalize the weights. For each image, the “final” label is the weighted sum over the label sets.\n2. I’m not fully convinced that “average y_bar = [] are in the range of [0, 1], which is rather ambiguous for the model to learn. Binarization will be useful to cast the value close to either 0 or 1”.  The range gives an insight into the “confidence” of the label. You can also discard images with labels that fall in the [0.45-0.55] range. Did you do this because there will be a lot of labels in the [0.45-0.55] range in the initial iterations of training?\n3. I’d make it explicit that you got labels for OpenI using negbio_u[0,1] and chexpert_u[0,1]. I was initially confused where you got multiple label sets for OpenI from, given that OpenI comes with hand labels and table 3 says OpenI (hand-labeled). I only cleared my confusion by reading the appendix.\n\nI’m supportive of accepting this paper; it would be great if we can get the techniques benchmarked against more baselines (as I mentioned in 1).",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This paper introduces a novel meta-learning framework with the attention-on-label mechanism for efficient learning from multiple sets of noisy annotators. The proposed network can learn, from both the image and its associated text, to predict the class membership through a weighted summation of individual noisy annotators. Comparisons with different methods on several datasets show that the proposed framework can lead to improvement in predictive accuracy.",
            "review": "Pros.\n\n    • The proposed training framework can calculate the image labels on-the-fly with an attention-on-label scheme.\n\n    • Gradient flows toward labels are employed to optimize the attention-on-label parameters.\n\n    • The performance of the proposed methodology is demonstrated through experiments on several datasets.\n\n\nCons.\n\n    • While the idea of learning from multiple annotations can prove to be useful, the rationale of learning from multiple noisy and automatically generated labels needs further justification since the model can only be as successful as the best algorithm by which the labels are generated; hence, instead of learning from the knowledge of human expert annotators, only an already known function is being estimated.\n\n    • The simulations can be improved for a more rigorous illustration of the method’s benefits. Simulations show marginal improvement over very common and baseline methods such as ResNet-50 network.\n\n    • Since the main novelty of the paper lies within learning an attention on the labels, it would be more appropriate if the comparison is made with other attention-based methods instead of baseline methods; however, those experiments are missing.\n\n    • There is a typo in the word \"globla\" in the line before Eq. (4).\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}