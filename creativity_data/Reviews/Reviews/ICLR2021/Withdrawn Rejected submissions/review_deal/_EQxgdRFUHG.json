{
    "Decision": "",
    "Reviews": [
        {
            "title": "Generating Unobserved Alternatives: A Case Study through Super-Resolution and Decompression",
            "review": "This paper considered a setting where the prediction problem is inherently one-to-many, but where the supervision is only one-to-one. They explored several problems with this characteristic and demonstrated that our approach was able to generate different plausible outputs for the same input, even though only one output per input is available as supervision. Moreover, they introduced an architecture for IMLE which outperformed GAN-based methods and can offer benefits like training stability and the lack of mode collapse.\n\n\n1.\tLack of more indicators to compare, such as PSNR, SSIM, etc.\n\n2.\tAs for the division of training set and test set, the experimental visualization result diagram scene is relatively simple and does not compare on the standard datasets such as SET14, Managa109, and its generalization ability remains to be proved.\n\n3.\tIn addition, the meaning of the tanh+ Offset in Figure 3 is not clearly explained.\n\n4.\tSome little spelling mistakes, the word \"thee\" in the third line from the bottom of page 3 should be changed to \"the\".\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper is targeting an attractive problem but further experiments are necessary to support the idea",
            "review": "This work should target a one-to-many task, which is an interesting topic. However, the study cases, i.e., SR and decompression, do not well demonstrate the claim of \"generating unobserved alternatives.\" Besides, these two cases may be unsuitable examples for generating alternatives since their goals should be identical recovery of the ground truth. For these tasks, the proposed work should be compared to SOTA in PSNR. \n\nIt may be unfair to compare to stacked ESRGAN since it is not trained jointed, while your model is directly optimized towards 16x. It would be better if compare at 4x. Moreover, it is still unfair to compare to standard SR methods using faithfulness-weighted variance because SR methods would avoid randomness in design. And the similar problem for the compression task.\n\nIn general, more suitable tasks would make the idea better motivated. \n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting problem but methodological contribution and experimental evaluation not compelling",
            "review": "The paper is about overcoming the limitation of current conditional generative imaging approaches to learning from data where only a single output image is available for a single conditioning. The paper builds upon IMLE [Li & Malik 2018] and [Li et al 2020]. In particular, the current approach seems to expand [Li et al 2020] with a mapping network. The benefits of the architecture are highlighted on two tasks: image super-resolution and image decompression. \n\nPros:\n-> the paper deals with a very interesting subject of interest to the ICLR community\n-> the reported results show superiority of the model over [Li et al 2020]\n\n\nCons:\n-> the paper's presentation could be improved, from the current version it is unclear what are the contributions of the work ,and the connection with Li et al 2020 are not explicitly discussed\n-> the model modification seem to be incremental\n-> there are some details missing in the experimental evaluation (e.g. number of trainable parameters).\n\n\nDetailed review and clarification question:\n\nPresentation: \n - The paper very heavily borrows from Li et al 2020 and this is not properly acknowledged in the current presentation of the paper. I would encourage the authors to rewrite the paper highlighting the connections and the differences with Li et al 2020 more explicitly. \n- From the current paper presentation, it is unclear what are the paper contributions. Based on my reading of the paper, it seems that the main paper contribution is in the model. However, stating the contributions clearly in the introduction and splitting the Methodology into \"Methodology\" (modifications w.r.t. prior approaches) and \"Background\" (overview of related works such as Li et al 20202 and Li & Malik 2018) would ease the understanding of the paper. \n\nChoice of tasks:\n- Why did authors decide to tackle these particular two tasks (super-resolution and decompression)? Why not include image synthesis from segmentation masks as in Li et al 2020?\n\nMethod:\n- There seem to be two changes in the model w.r.t. Li et al 2020: the second branch (mapping network) and weight normalization. Adding some explanation on why these design choices are beneficial for the task would make the methodological section stronger.\n- \"Regression models take the form of a deterministic function from x to y, and so p(yjx) is always a delta\". I think that this sentence is not 100% exact. This would depend on the formulation of the regression model, e.g. one could regress a Gaussian distribution and fit he model with gaussian log likelihood.\n\nEvaluation metric:\n- In general, I'm not convinced if FID is the right metric for the task. Could the authors motivate the use of FID metric? What is the effect of ImageNet pre-trained inception model on the metric values? Moreover, could the authors clarify what is the reference distribution used to calculate FID?\n\nExperimental evaluation:\n- Could the authors add the numbers of parameters next to each model? How many additional parameters does the introduced model have when compared to Li et al 2020? Could the authors comment on whether the observed improvements could be attributed to the potential increase in number of parameters as opposed to the model design choices?\n\nQuantitative results:\n- Although embedding videos in the pdf is a nice thing to do. It would also be beneficial to see images and difference maps in the main body of the paper. The embedded videos require Acrobat Reader software.\n\nThe paper lacks discussion on the method's limitations. Could the authors comment on the potential limitations of the proposed approach?\n\n\nOverall, I recognize the importance of the task that is being tackled in the paper. However, I find the presentation of the paper to be rather misleading (acknowledging the similarities/differences with Li et al. 2020 would be beneficial), the importance of methodological contributions to be unclear, and the experimental evaluation not fully compelling.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}