{
    "Decision": "",
    "Reviews": [
        {
            "title": "Review for the paper \"AFINets...\"",
            "review": "=== Summary ====\n\nThis paper proposes an attention module to improve results of image recognition models. The results demonstrate improved performance of the ResNet architecture with moderate computational cost.  \nMain paper contributions are stated to be as following:\nLightweight and Plug-and-Play: The AFI module is lightweight, which avoids the quadratic complexity of memory usage. Consequently, it is easy to apply the AFI module into CNNs. \nInterpretability: Through ablation study, Figure 2 shows that the borderline of the target is sharper by applying the AFI module. \nHigher Accuracy and Lower FLOPs: Experimental results show that our AFI module significantly improves the representational power of the network. \n\n== Comparison to previous work ==\n\nAuthors provide the following comparisons:\nComparison to SE modules: Proposed AFI module focus on explicitly modeling the feature integration instead of channel-wise selection of SE module.\nComparison to DenseNet: compared to DenseNet with the self-attention module like CAPR-DenseNet (Zhang et al., 2019), the proposed module can be applied to deeper and larger network, while avoiding quadratic complexity memory usage and running time by substituting the independent exciter for the shared attention mechanism.\nComparison to SKNEt: AFI module can utilize different level (e.g., positional and semantic) information by reusing features.\nThe experimental results are provided for the ResNet with SE modules only. The results for other comparisons would be beneficial for this study.\n\n=== Pros ==== \n\nThis work provides interesting results. \nThe proposed module provides increase in accuracy and FLOPs when applied to CNN models.\n\n=== Cons === \n\nIt’s unclear why authors provide different results for different types of experiments (AFI-Mobilenet, ResNet-50, ResNet-152, CBAM etc): multiple tables/models are slightly confusing. \n\n=== Basis for recommendation ===\nThe results are interesting and the proposed module improves the performance of some of the popular architectures. The idea is similar to SE module, but provides better results. Therefore, I recommend that the paper can be accepted for publication if authors provide more clarity on the experiments (the formulation of the results is somewhat confusing and the experiments are slightly inconsistent) and the second contribution (interpretability).  \n\n=== Questions to address in the rebuttal ===\n1.\tConsolidate results for each set of experiments for different models in one place (you are using different set of models fr different experiments, a small narrative on this would be beneficial)\n2.\tThe authors claim that the proposed module provide interpretable results. This claim needs to be demonstrated with experiments.\n3.\tIt this module is beneficial only for ResNets? It seems that the majority of experiments was done was ResNets, is there any particular reason for this?\n\n=== Minor comments and additional feedback (not necessary to address in rebuttal)===\n\nPage 1. “Firstly, for several successive feature maps (i.e., raw features) with C channels, each feature is extracted to a vector by a squeeze operation that captures information from a large spatial extent.” – not sure why authors mention C channels here, when this notation is addressed only on p.4\nPage 5. “As we can see in the Figure 2, our network has _more_details_ of detected things, and meanwhile, the heatmap generated by ResNet-50 is too smooth to draw the specific borderline of detected things”. It would be great if you address this statement in a more quantitative way.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "more robust experiments and analysis needed",
            "review": "This paper proposes an alternative skip-connection structure for blocks in a ResNet/DenseNet style architecture.  This \"Attentive Feature Integration\" (AFI) module produces, for each layer, a score vector over channels from a globally aggregated (squeezed over spatial dimensions) feature vector.  These are normalized via a softmax operation across corresponding channels of score vectors for layers withing a network stage.  The resulting score vectors modulate a ResNet-style weighted combination of feature maps, which is concatenated to the end of the stage.\n\nThe overall strategy is an ad-hoc combination of ResNet-style residual connections and DenseNet-style concatenation (which has been done before in Wang et al.'s Mixed link networks), but with the additional twist of learning a channel-wise attention weighting to modulate the residual connections.\n\nExperiments concentrate on CIFAR and ImageNet classification and show minor accuracy improvements for AFI variants of ResNet, ResNeXt, ShuffleNet, and MobileNet compared to their respective baselines.\n\nWhile these experiments might indicate the idea has promise, I am not convinced that the results are sufficiently interesting or impressive.  Accuracy gains over the baselines tend to be in the range of one percent (at equal parameters).  Due to the baselines chosen, none of the results (baseline or AFI variant) break any accuracy records for either dataset.  Given the marginal gains currently reported, I think a more robust experimental setting is needed to be convincing: (1) include comparison to multiple alternative skip-connection structures (e.g. mixed linked networks), (2) examine the full space of accuracy-parameter and accuracy-FLOP trade-off curves for each architecture family, and (3) demonstrate effectiveness in scenarios other than CIFAR/ImageNet classification.\n\nFigure 2 and the corresponding claims about attention are also not convincing.  The minor differences in Grad-CAM heatmaps for six example images are not sufficient to establish whether AFI-ResNet has more desirable attentional behavior than standard ResNet.  Doing so would, at minimum, require some type of quantitative benchmark that actually computed overlap statistics with known ground-truth object segmentations across a much larger set of examples.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "ok idea with weak experiments",
            "review": "Summary: This paper proposes a new network module called attentive feature integration (AFI) module, which aggregates features at different levels of the network through attention and concatenation. Experiments are performed on CIFAR and ImageNet to demonstrate the effectiveness of the proposed method.\n\nStrengths:\n1. Good observation that most operations proposed in prior work leverage either addition or concatenation for feature reuse, and there is disadvantage for both of them.\n2. The proposed method leads to some noticable gains and memory saving when adopted by state-of-the-art network designs such as ResNet, ShuffleNetV2, etc.\n\nWeakness:\n1. Poorly writen with many typos and grammar mistakes, some examples below. The paper should be carefully proofread before submission.\n   - space information -> spatial information\n   - can by adaptively integrates (abstract)\n   - by the attention mechanism ( which\n   ...\n2. Most of the experiments in the paper are conducted on CIFAR. Table 5 shows some results on ImageNet but only compares with ResNet-50, ResNet-152. To demonstrate the effectiness of the proposed module, the paper should also compare with more recent architectures such as DenseNet, ResNetXt, etc. which are reviewed in the related work section, especially those also propose ways to reuse features. Without such comparisons, it is inconvincing that the proposed module is superior to prior approaches.\n3. Ablations are needed to demonstrate the usefulness of each component of the proposed module as illustrated in Figure 1.\n4. Why the proposed module leads to more focused attended regions as shown in Figure 2 should be discussed.  Why this phenomeno is correlated with better performance? Calling this \"Interpretatbility\" also seems strange since adding this module doesn't make the network more interpretable.\n\nJustification of rating: This paper proposes a new generic network module called attentive feature integration (AFI) module. However, the experiments are not convincing enough to demonstrate that the proposed module is generally effective across different tasks, datasets, and backbones. The writing of the paper should also be improved for resubmission. Therefore, this reviewer recommends rejection of the paper in this current shape.",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A simple and effective plug-in architecture for ConvNets",
            "review": "This paper tackles the problem of poor memory usage and feature entanglement of modern skip-connection based ConvNets architectures. The authors present AFINets, a light-weight and pluginable ConvNet module that uses the attention mechanism to pool features in global context from different layers, and reuse them efficiently. AFINet modules can be plugged into existing ConvNets architectures, and the authors show that it improves the classification performance while using fewer computations. \n\n\nStrengths\n\n- The paper is well-written and easy to comprehend\n- The proposed AFINet module is lightweight and pluginable\n- AFINet-equipped ConvNets achieves higher classification accuracy with fewer parameters and FLOPs\n- Good and detailed ablation studies on the position and speed-vs-accuracy tradeoffs of AFINets.\n\nWeaknesses\n\n- To me the overall architecture of AFINets resembles the Squeeze-and-Excitation network hence it is not completely novel, but this is a relatively minor point\n- I am not very familiar with the classification literature but the improvement over accuracy does not seem too great to me according to Table 4 and Table 5, and there is no comparison against the state-of-art methods.\n\nOther Comments\n\n- The evaluation is solely based on image classification, I am wondering how AFINets would help the performance of ConvNets on detection or segmentation tasks.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}