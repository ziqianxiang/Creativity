{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The idea of combining instance-level contrastive loss and deep clustering is a promising direction in recent unsupervised/self-supervised visual representation learning studies. However, authors did a poor literature review and did not cite and compare with quite a few recent popular work exploring the similar direction. The proposed methodology is not particular novel and the experimental results are also not convincing. Overall, the paper explored a promising research direction, but the paper quality is clearly below acceptance bar. "
    },
    "Reviews": [
        {
            "title": "A method combining instance-level and cluster-aware contrastive loss for representation learning",
            "review": "[Overview]\n\nIn this paper, the authors augment the instance-level self-supervised learning with cluster-aware learning mechanism during the training procedure. Specifically, for each training batch, the authors project the instances into a clustering space and then utilize a cluster-aware contrastive loss to push the augmented samples from the same instance to belong to the same cluster, otherwise for different instances. To ensure the clustering not to collapse into a single or a few cluster to find the trivial solutions, the authors further add a penalization item keep the entropy of clustering assignment be uniform to some extent. The experimental results demonstrate that the proposed method can improve the representation learning performance over SoTA methods on several datasets, while also outperforms the previous methods on clustering task. Further ablation studies show that the loss is effective to ensure the learned representation more discriminative and clusterable.\n\n[Strength]\n\n1. The intuition behind the proposed method is intuitive and straightforward. It has been shown in previous work like [a] that combining them together can boost the self-supervised learning performance significantly. This paper further demonstrates the promise of this direction.\n\n[a] Unsupervised Learning of Visual Features by Contrasting Cluster Assignments. Caron et al.\n\n2. The authors performed experiments to show that the proposed method achieves better performance on both representation learning task and clustering task, on various image datasets, such as CIFAR-10, CIFAR-100 and STL-10. \n\n3. The ablation studies showed that the proposed clustering loss indeed helps to learn a better representation compared with the baseline model with a substantial margin, which demonstrates the effectiveness of the proposed method.\n\n[Weakness]\n\n1. The paper has a poor literature review of previous works. In the related work, both instance-level representation learning and deep clustering methods are not fully covered and compared. More importantly, the authors missed a very relevant and recent paper as pointed above [a]. The idea behind this paper is very similar to the above one.\n\n2.  In this paper, the authors merely presented the results on relatively small datasets. Though it is a bit harsh to always request experiments on the large-scale dataset, such as ImageNet, proving the efficiency seems necessary especially when it is known that keep training on a large-scale dataset for a long time may dismiss the gap.\n\n3. In table 3, it seems that only with multi-scale clustering loss, the performance will be improved across all metrics. This indicates that the proposed algorithm is a bit sensitive to the hyperparameter settings. Even with Eq.(1) + Eq.(5), the performance drops in some scenarios, which seems counterintuitive. All of these results demonstrate that the proposed method is still a bit mysterious and vulnerable. \n\n4. The notations in the paper is hard to interpret and a bit abuse. The formula of Eq.(4) is also a bit confusing. First, what does k stands for? Second, why the denominator excludes the case of i=k if it is a regular contrastive loss.\n\n[Summary]\n\nOverall, I think this paper is a good trial of combining instance-level contrastive loss and deep clustering philosophy into a single learning regime, which I think is a promising direction to explore. However, as I pointed above, the novelty of the paper should be better explained. Also, according to the ablation study, the performance seems vulnerable to the choice of hyperparameters, such as cluster numbers. This increases the uncertainty about the effectiveness of the proposed method. Furthermore, the proposed method is not demonstrated on large-scale dataset such as ImageNet, which is supposed to be a routine setting on self-supervised learning community. I would recommend the authors could answer my above questions raised above.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good paper, interesting results on preserving cluster structures, notation is a bit confusing",
            "review": "Pros:\n\n1- The paper presents a good solution for an important problem in self-supervised learning and contrastive learning. Proposed methods in the literature do not take the cluster structure of items into consideration. This paper proposes a hybrid loss function that aims to preserve the cluster structure (Equation 7)\n\n2- A wide range of experiments are conducted to evaluate the proposed method. C2BIN shows a significantly better performance using the kNN classifier (particularly on CIFAR100). The good performance is also evident in clustering experiments. Thus, as the method promises the cluster structure is better preserved.\n\nCons:\n\n1- The motivation part of the paper is not precise. The last sentence of the second paragraph of Section 1 states:\n\n“However, since aforementioned instance discrimination does not consider the semantic similarities of the representations (e.g., same class), it results the learned representations to be uniformly distributed (Wang & Isola, 2020).” \n\nIt is true that semantic similarities are not considered in self-supervised and contrastive learning settings. However, this is a part of the problem as class labels do not exist. Moreover, it is not clear to me why it would lead to a uniform distribution of representations. I agree that cluster structure might be lost.\n\n2- The notation used in Section 3 is confusing, I mention some possible misuses of notation or typos:\n\nSection 3.1, N is defined as the number of unlabeled images. Later in Section 3.3, second paragraph, N is used as the mini-batch size. \n \nSection 3.2 Equation (1), $P^a (z_a)$ is not properly defined. It refers to SimCLR and as I checked in the paper the same notation is not defined. Moreover, the paper should be written self-contained. Meaning that main formulation should be mentioned in the main body of the paper.\n\nFigure 3, two siamese networks, $E_\\theta$ and $E_\\phi$ are not depicted in the Figure.\n\n\nEquation 4, denominator, $i \\neq k$, should it be $i \\neq j$?\n\nAfter Equation 4, it is stated that: The vectors c’ and c’’ are obtained from x’_i and x’’_ i , respectively, using the encoder $F_\\theta$. This is not precise. The output of F would be r and it goes through $P^{c,k}$ to obtain z. Then c is computed using equation 3. \n\nComments and questions:\n\nTable 3 shows that the choice of set K is quite important. If we are not provided with proper K and we have no access to labels, can you recommend any strategy in this case? Do you think using a fixed K with various elements is good for any dataset?\n\nIt would be nice to sort the methods of table 7 chronologically.\n\nIt is not clear how Figure 9, 10 and 11 are produced. Are the grouped images random samples and nearest neighbors?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Official Blind Review #2",
            "review": "Summary:\\\nThis paper applies batch-wise cluster assignment with bootstrapping to learn unsupervised representation. This paper claims resulting representations are better suited to non-discriminative tasks where clustering is important.\n-----\n+Strengths\\\n+This paper motivates a good direction over current unsupervised representation learning. Considering clustering performance in addition to discriminative power is a fair research question in my opinion.\n+The proposed idea is interesting and seems reasonable.\n+Evaluating representation learning on non-discriminative tasks is a good idea.\n-----\n-Concerns\\\n-A critical concern is the experiment setup, particularly the choice of ResNet18 as backbone and only evluating on CIFAR/STL. These datasets are quite small and are not used as the primary performance benchmark for modern unsupervised image representation learning work. This paper claims improvement in certain aspects over SimCLR, MoCo v2, and BYOL which all experiment on much larger capacity models and much larger datasets. Many insights in these prior work tie heavily to scaling to larger dataset and model capacity. This makes it difficult to compare this work.\n-----\nRecommendation\\\nThe experiment setup in this paper deviates significantly from recent work of similar nature. Therefore I am not convinced by the findings presented and I recommend to reject this paper.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}