{
    "Decision": "",
    "Reviews": [
        {
            "title": "An adversarial training framework is proposed to add class-invariant features to enhance the discriminability of adversarial domain adaptation. The performance gain is limited and more recent STOA methods should be compared with the proposed one. ",
            "review": "A dual adversarial training framework that adds class-invariant features of the source domain in adversarial domain adaptation (ADA) is proposed. It can adjust the generalization error rate of the ideal joint labeling function on the source and target domains. Experiments on 4 benchmarks are conducted. \n\nPros\n+ The paper is easy to follow and the idea is presented quite clear.\n+ How to balance transferability and discriminability in ADA is a big issue and this paper proposed a feasible method to tackle the problem.\n\nCons \n- The performance gain of the proposed DAT is limited as shown in Table 1 and 2. A more detailed performance analysis should be conducted. \n- The author did not compare the proposed method with the recent SOTA methods that dedicated to solving the discriminability issue of ADA, such as [1][2]\n\n[1]Transferability vs. Discriminability: Batch Spectral Penalization for Adversarial Domain\nAdaptation, ICML2019 \n[2]Towards Discriminability and Diversity: Batch Nuclear-norm Maximization under Label\nInsufficient Situations, CVPR2020\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "In this work, the authors propose a dual adversarial training (DAT) framework for unsupervised domain adaptation. The DAT method introduces class-invariant features to adversarial domain adaptation. However, the similar idea has been proposed in many existing works. The experiments are insufficient and unimpressive.",
            "review": "This paper proposes a dual adversarial training framework for unsupervised domain adaptation, an interesting direction with many potential applications. The paper is well written and easy to read. However, there are many major concerns of this paper that enforce me to reject this paper:\n\n1. My main concerns about this work are the novelty issues and that the contributions are not strong enough. The class invariant adversarial learning for domain adaptation has been widely proposed. The novelty is very limited. There are many similar works, such as [*][#].The dual adversarial training framework has been mentioned and discussed clearly in prior works.\n\n[*]S. Li, S. Song, G. Huang, Z. Ding and C. Wu, \"Domain Invariant and Class Discriminative Feature Learning for Visual Domain Adaptation,\" in IEEE Transactions on Image Processing, vol. 27, no. 9, pp. 4260-4273, Sept. 2018, doi: 10.1109/TIP.2018.2839528.\n[#]Z. Ding, N. M. Nasrabadi and Y. Fu, \"Semi-supervised Deep Domain Adaptation via Coupled Neural Networks,\" in IEEE Transactions on Image Processing, vol. 27, no. 11, pp. 5214-5224, Nov. 2018, doi: 10.1109/TIP.2018.2851067.\n\n2. There are man unnecessary descriptions that are widely used and well known. For example, the adversarial domain adaptation in Section3.1 and the theory understanding in Section 3.5.\n\n3. Regrading experimental results, this paper should compare the proposed method with the existing SOTA methods, say more works in 2020. The compared baselines are far from enough. The performance improvement is not convincing.\n\n4. The results on more representative datasets are required, such as OFFICE-31, DomainNet, etc.\n\n5. Ablation studies are missing. Please clearly explain which part of the proposed method works better and contributes more to the results.\n\nOverall, this paper does not meet the bar of ICLR.\n\n\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "a method aiming to disentangle class-invariant and domain-invariant features for unsupervised domain adaptation ",
            "review": "This paper proposes a method for unsupervised domain adaptation (UDA) that attempts to separate class-invariant features and domain-invariant features via two different network components. \n\nStrength:\n1. paper is easy to follow\n\nWeakness:\n1. the motivation of separating features are hard to understand, domain-invariant features are possibly overlapped with class-invariant features with a large possibility. what is the motivation for including domain-invariant features into the cross-entropy classification term $L_c$? In fact, the motivation of domain separation network (DSN) sounds much more reasonable.\n2. the proposed method on several benchmarks can not achieve state-of-the-art results, which is over-claimed in this paper. Besides the ignorance of recent papers on UDA, the proposed can not even beta CDAN (NeurIPS 2018) on these datasets.\n3. the discussions with two recent papers [a,b] about conditional adversarial UDA are necessary\n4. while evaluating the model for target data, it still requires some randomly sampled source data? then where is the stability of this operation in the experiments? it seems the final target accuracy depends on the quality of source samples.\n\n[a]. Kurmi, Vinod Kumar, and Vinay P. Namboodiri. \"Looking back at labels: A class based domain adaptation technique.\" 2019 International Joint Conference on Neural Networks (IJCNN). IEEE, 2019.\n[b]. Cicek, Safa, and Stefano Soatto. \"Unsupervised domain adaptation via regularized conditional alignment.\" Proceedings of the IEEE International Conference on Computer Vision. 2019.",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "The idea of learning class-invariant features is not novel with weak experimental results",
            "review": "##### Summary of the paper\n\nThe paper proposes a dual adversarial training method for unsupervised domain adaptation. The key idea is to learn domain-invariant features while learning domain-invariant features. Thus, authors design two adversarial processes: one is the ordinary domain-adversarial training following DANN, the other is domain-adversarial training on the class features. Combining two processes with two tradeoff hyperparameters along with the training loss in cross-entropy, the dual adversarial training can be done. The experiments on Office-31, VisDA-17, Digits, Office-Home, and ImageCLEF-DA have shown its performance against several recent methods.\n\n##### Pros\n\n1. The structure and writing are good, making the paper easy to understand.\n2. The method is not so complicated and easy to implement.\n\n##### Cons\n\n1. The main issue with this paper is the limited novelty. The idea of learning class-invariant features with GAN is not new and has been explored by several existing methods with similar proposals but maybe different names such as disentanglement. Authors can see the refs in the end for more references. To me, this paper can only be seen as an extension to DANN.\n2. Motivation is not clear: what is exactly class-invariant features vs. domain-invariant features? Are they just the discriminative features that are helpful for classification? More explanations are needed. \n3. In para. 2, page 2, the expression \"domain alignment will inevitably distort the original feature distributions and enlarge the value of adaptability\" lacks sufficient evidences or references. Why domain alignment will \"distort\" the original feature distributions and why the specific word \"distort\"? Do you have any figures or graphs to explain this? Moreover, the sentence \"class-invariant features are supposed to contain domain-specific information\" also lacks support. Why a class-invariant feature is domain-specific? It seems that there coule be a feature can be both class- and domain-specific.\n4. The main contribution, i.e., Eq (4), is not novel. It is a simple replacement of binary domain classifier with a multinomial one. And what is $\\ell$ for evaluating the difference between domain classifier and $y^s$?\n5. Eq (5) is similar to disentanglement. What is the input dimension to the classifier $C$? The inputs to Eq (2) and (5) are different. Therefore, it is problematic. \n6. Section 3.5 is not even necessary since it cannot explain the theoretical motivation behind this paper, but only behind DANN.\n7. The results are too weak. On Office-31, it only achieves 0.2% improvements; On ImageCLEF-DA, 0.3%; On VisDA, 0.7%; On Office-Home, it can only beat JAN. Not to mention that the latest comparison method is CDAN which is in 2018. There are already a lot of published methods in 2019 and 2020. Therefore, the experimental results are too weak.\n8. Since it involves two adversarial training processes, the training time and convergence need to be analyzed. It will indeed take more time by its nature.\n\nReferences:\n\n[1] Pei Z, Cao Z, Long M, et al. Multi-adversarial domain adaptation[J]. arXiv preprint arXiv:1809.02176, 2018.\n\n[2] Du Y, Tan Z, Chen Q, et al. Dual Adversarial Domain Adaptation[J]. arXiv preprint arXiv:2001.00153, 2020.\n\n[3] Yu C, Wang J, Chen Y, et al. Transfer learning with dynamic adversarial adaptation network[C]//2019 IEEE International Conference on Data Mining (ICDM). IEEE, 2019: 778-786.\n\n[4] Zhang Y, Liu T, Long M, et al. Bridging theory and algorithm for domain adaptation[J]. arXiv preprint arXiv:1904.05801, 2019.\n\n[5] Gonzalez-Garcia A, Van De Weijer J, Bengio Y. Image-to-image translation for cross-domain disentanglement[C]//Advances in neural information processing systems. 2018: 1287-1298.\n\n[6] Cao J, Katzir O, Jiang P, et al. Dida: Disentangled synthesis for domain adaptation[J]. arXiv preprint arXiv:1805.08019, 2018.\n\n[7] Cai R, Li Z, Wei P, et al. Learning disentangled semantic representation for domain adaptation[C]//IJCAI: proceedings of the conference. NIH Public Access, 2019, 2019: 2060.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}