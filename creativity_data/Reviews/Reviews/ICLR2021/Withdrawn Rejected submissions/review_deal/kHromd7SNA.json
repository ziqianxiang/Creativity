{
    "Decision": "",
    "Reviews": [
        {
            "title": "results not convincing and lack of comparisons to strong competitors",
            "review": "This paper proposes a 2D part based approach to tackle the problem of motion transfer, an important problem in computer vision and video motion generation. \nThe paper has shown improved results comparing to FOMM, as in Table 2. Moreover, by decomposing an articulated object (e.g. human) to its body parts and deal with them individually, the approach is computationally economic.\nMy concerns are mostly from the empirical evalutions. Due to the proposed approach, it faces severe challenges in maintaining physical connections of the body parts to form a meaningful whole body pose dynamics. The demo video clearly suggests the many failures of the proposed work. \nResults are overall quite selectively presented in the main text. for example, the four images shown are clearly the best frames cherry picked from the generated video, where most of the time, severe geometry and texture distortions are presented, to a level that is hard to justify the real meaning and value of the current contributions. \nThe paper also lacks comparisons to existing efforts. Motion transfer has lots of recent efforts such as [1-3] and the authors should make strong efforts in comparing to these state-of-the-arts.\n\n[1] Animating Arbitrary Objects via Deep Motion Transfer, cvpr'19\n[2] Self-supervised animation synthesis through adversarial training, IEEE'20\n[3] First Order Motion Model for Image Animation, nerips'19\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Augmenting the previously published FOMM model for articulated object animation with region based representation via PCA, and adding bg noise model yields improved experimental results for the task",
            "review": "The strong point of this paper is that the proposed method deals better with articulated body parts as can be seen in the qualitative and quantitative results. \nThe weak point of this paper is how it is presented and explained. \n\nquality :The tone and style of the paper are not in line with the standard academic tone one can expect in high quality submissions. This takes away from the sense of quality and scientific rigor of the work. It is also not very clear what is actually being conveyed.  This is especially true for the introduction section. There is a lot of qualitative subjective comments where one would expect numbers or specifics. As an example - \"These contributions unlock significant gains in capability for unsupervised motion transfer methods, resulting in much improved animation.\" - what are \"significant\" gains? what is \"much improved\"?\n\nclairty : the introduction section is not clear and some of the issues are also related to the quality of the explanation. See comments below for specifics. \n\noriginality : The paper is a particular modification of one aspect of the previously published FOMM technique. As such I believe the entire introduction and motivation should clarify this is the case, and the motivating intuition for that, and present the work as such rather than making it considerably more abstract and only detailing this in section 3.1 . In addition the nature of the modification is using PCA to model the region based transformation, rather than a keypoint based one previously described. \n\nsignificance: the actual modification for a PCA based region representation while useful and a nice application is fairly modest as a contribution from a scientific perspective. It is linear, and does not account for shear. It is better than existing modeling and as such this is a nice contribution that highlights the need for better approaches since it's clearly a limited model for representing the full richness of the region based deformation. \n\nComments:\n1. some statements are missing references: \"including talking faces, taichi videos and animated pixel art\"\n2. some claimed are quite hyperbolic, rather than fact-driven: \"surpassing previous methods by a large margin\" what is a \"large\" margin? that's qualitative and subjective. It is better use some concrete numbers such as % improvement. \n3. The introduction section makes a lot of high-level unreferenced statements and could benefit from concrete examples. For instance: \"limit the scope of the core innovation to more trivial object categories and motions, [references?]\nand lower quality outputs [references?]\n4. The introduction was not very clear to me. The summary of contributions was confusing. For instance, a statement like \"first-order motion to be measured, rather than regressed.\" - in what context is it regressed if we are describing how to animate? or measured? \n\" This enables improved convergence\" convergence of what? no modeling has been described yet. It is only much later when the core contribution is expressed (the use of PCA based estimation) that these statements become clear. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting topic, unconvincing results, incremental.",
            "review": "The proposed paper introduces a novel method for learning motion representations for articulated characters shown in videos. The main objective of the introduced approach is to identify object parts in an unsupervised manner and to track these parts based on a driving video. The goal of the method is to apply the motion of the character in the driving video to a single still image of another character. A key feature of the proposed method is that it extracts consistent regions that describe locations, shape, and pose of object parts. \n\nStrengths:\n\n- Animation of still images and motion re-targeting are interesting topics. \n- The identification of regions, instead of key-points, seems to enable better convergence and more stable results. \n- The method explicitly models background motion between frames by predicting homography matrices, which enables the method to focus on foreground objects. \n\nWeaknesses: \n\n- Compared to existing work (FOMM) the method appears somewhat incremental.\n- While the results improve upon prior work, most examples still show severe artifacts that render the usefulness of the proposed method questionable. While some stills can be animated well, the methods falls short to animate most transitions. \n- The paper does not discuss any limitations. As is, it is not clear in which situations the method fails the most or in which situations the method cannot be applied at all. \n\nAdditional comments: \n\n- The sentence 'Imagine the Mona Lisa describing the manner it which she was painted, ...' is not clear. How is the creation process related to what is done in this paper?\n- Intro (P2): The sentence 'Significant progress on the several key challenges have been made, including training using image reconstruction as a loss, and disentangeling motion form appearance' should mention references for the listed statements. \n- It would help to more formally define what is meant by 'driving video'. The term is used a few times and it is not clear what is meant. \n- In Eqs (1), (2), (3) it is not clear what some of the introduced symbols are. E.g. U, S, K, A are not discussed anywhere. \n- In Section 3 it is not always clear what the contributions of the introduced method are compared to FOMM. The text mentions several times that it closely follows the FOMM implementation which blurs the lines between what is contribution and what is covered by existing work. Moreover, the extensions to FOMM often seem quite incremental (e.g. adding additional three input channels). \n- The method was evaluated on several datasets and it generates severe visual artifacts across all datasets. \n- Section 4.2. states that videos were removed from the TaiChiHD data set when the videos did not support the required resolution. How many videos were removed?\n- The evaluation against SOTA and the provided ablation studies seem technically sound and meaningful. \n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Articulated motion transfer",
            "review": "The paper takes a still photograph of an individual and generates animation that follows video of another individual moving. The key idea is to generalize the FOMM paper to segment and transform nearly-rigid regions rather than key points, thus leading to more accurate flow fields for articulated motion. The results look better than FOMM in the baseline comparisons. There are still visible artifacts, but this is an improvement.\n\nI tried reading the FOMM paper prior to this and I found it to be very difficult to read, so I had trouble following the details of this one too. But I think the idea and the approach make sense.\n\nMy main concern about the paper is that, while it is motivated by the goal of unsupervised transfer, all of the examples shown are on full-body character animation, where it is possible to get good results using existing body pose models. While it is impressive that the results look good with a prior body pose model, the proposed method doesn't seem that useful because there exist better methods for this problem. Perhaps the approach here could generalize to other subjects that the current methods can't? But it would be more convincing to show demonstrations on tasks that can't currently be addressed.\n\nAnother citation related to animating from a single image:\n\nPhoto Wake-Up: 3D Character Animation from a Single Photo\nChung-Yi Weng, Brian Curless, Ira Kemelmacher-Shlizerman\nCVPR 2019\nhttp://grail.cs.washington.edu/projects/wakeup/\n\n\nThe idea of handling articulated motion by clustering regions that move together is old and has been around a long time, and it would be worthwhile to acknowledge more of this literature. I don't know the area comprehensively, but examples that came up in a quick Google search include:  Datta et al, \"Linear Motion Estimation for Systems of Articulated Planes\"; Yan and Pollefeys \"Articulated Motion Segmentation Using RANSAC With Priors\".\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}