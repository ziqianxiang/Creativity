{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper received high variance in the reviews.\n\nI personally agree with AnonReviewer4 that the theoretical results presented in this paper are well-known results on the sensitivity analysis of linear programs. See for instance \"Introduction to linear optimization\" by Bertsimas and Tsitsiklis, Chapter 5.\n\nMore generally, these results are a special case of Danskin's theorem and the envelope theorem:\nhttps://en.wikipedia.org/wiki/Danskin%27s_theorem\nhttps://en.wikipedia.org/wiki/Envelope_theorem\n\nClarke's generalized gradients are just subgradients in the case of convex functions, which is the case here.\n\nMy recommentation to the authors if they want to publish their work is to focus on the applications and to stop claiming novelty on the theoretical side."
    },
    "Reviews": [
        {
            "title": "Interesting general method, but needs far more details about the resulting algorithm for concrete use-cases.",
            "review": "=quality=Proposed method is significantly more practical, both in terms of ease of implementation and speed, than prior related work for minimizing combinatorial losses. The paper's exposition needs to be improved considerably, though (see below).\n\n=originality=The paper draws on advanced concepts from combinatorial optimization that may be unfamiliar to many ICLR readers, but that have the potential for large impact.\n\n= significance=The paper's proposed method is practical for very common ML setups in NLP and computer vision that are used day-to-day.\n\n= Pros = Proposed method is interesting, practical, and relatively easy to implement.\n\n= Cons = Paper writing omits many key details necessary to use the method in practice. Experiments build the method on top of out-\ndated models and do not demonstrate that the method could be used with modern models (e.g. attention-based decoders).\n\n==Comments==I appreciate that you provide a very general recipe for constructing the differentiable combinatorial layers. However, the paper provides far too few details for the particular problems (bipartite matching and sequence alignment) that appear in the experiments. The supplementary material does not help. Your method is promising, and practitioners that do not have a background in combinatorial optimization may want to use it. The paper does not provide enough details to do so. I'd replace Algorithm 1 with a box specific to bipartite matching.\n\nYou need to provide far more detail/background on differentiable decoding for the secnod set of experiments. It was unclear what Softmax/ Gumbel-Softmax meant. Is Softmax not the same as MLE?\n\nWhile the second set of experiments provides useful ablation analysis of the impact of your method, it builds on an out-dated model. You write \"while this architecture is no longer the top performer in terms of ROUGE metric –currently, large pre-trained self-attention models are the state-of-the-art – it is much more efficient intraining, allowing for experimenting with different loss functions.\" Is the speed difference really that much? I'm surprised that that makes a difference in terms of which experiments are feasible.\n\nFigure 1: why is cvxpy timing u-shaped?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review for \"Differentiable Combinatorial Losses through Generalized Gradients of Linear Programs\"",
            "review": "The authors present a technique to integrate combinatorial optimization sub-problems into a gradient descent based application. The approach they describe relies only on differentiation of the value of the combinatorial program (instead of the solution vector), and can be done with relatively low overhead (compared to techniques that involve modifying combinatorial algorithms to differentiable elements, or the use of differentiable linear/quadratic programming layers)\n\nThey motivate and show the advantages of their approach using two natural and useful examples. The experimental results show promise, and the paper is well written, and motivated.\n\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Novel approach, comparisons don't compare to other combinatorial optimization differentiation methods",
            "review": "This paper shows how to differentiate through combinatorial\nlosses by differentiating through the ideal formulation LP.\nUnderstanding how to differentiate through combinatorial\noptimization so that it can be used as part of the model or\nloss is important as it captures many natural operations.\nI am giving this a weak accept as it is a novel approach\nfor differentiation that the community can build on,\nbut the positioning and relation to prior work and\nempirical comparisons could be stronger (more details below).\n\n# Strengths\nTo the best of my knowledge this is a novel approach that\nmakes the elegant and natural connections going from\na combinatorial problem to an ILP to an LP\nto differentiating through the LP using known methods.\n\n# Weaknesses\nThe biggest weakness is the lack of a comparison with related\napproaches for differentiating through combinatorial losses,\nsuch as some of the approaches discussed in the introduction\nas [Pogancic 2020] that consider similar problems.\nThe experimental settings considered in this paper compare to\nbaselines that *don't* differentiate through the combinatorial\naspect of the problem. While this is a great step of validating\nthe power of these approaches, I think that it would be significantly\nmore convincing to empirically compare to approaches that\ndifferentiate through the combinatorial losses.\n\nI also think it's important to discuss the comparisons to the\nrelated approaches for differentiating through parameterized\ncombinatorial optimization. Are the approaches using the same\ndefinition of a derivative? [Pogancic 2020] discusses an issue\nwith the real derivative through combinatorial optimization being\nuninformative or near-zero everywhere, is this also an issue in\nthe setting here?\nCan this approach be seen as an approximation or surrogate to\nthe derivative of the combinatorial problem as the other approaches?\n\nIf I understand correctly, this approach requires a known mapping from\nthe combinatorial problem to the ILP, and from the ILP to the LP,\nwhich could make it more involved to apply than some of the related\nmethods that don't require knowing this information.\n\n# Other questions and comments\nHow should the gradients of the continuous baselines (with CVXPY)\ncompare to the method being proposed in the experiments?\nIf they're using the ideal formulation LP, should they be the\nsame in theory (as Figure 1 validates), but in practice due\nto solver errors, gives suboptimal directions (as Table 1 shows)?\n\nThe last paragraph of the introduction presents a form of the\ncriterion with a loss and the combinatorial objective value\nwith notation that's not used later on in the paper.\n\nPage 2, second paragraph: The last sentence on differentiable\ncontinuous LPs/QPs seems separate from the rest of paragraph\non combinatorial solvers.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Well presented generic method for efficiently using combinatorial LP layers - albeit not completely novel",
            "review": "Summary\n-------\n\nThe authors propose a simple method to optimize objective values defined as the\noptimal value of a combinatorial integer linear program, whose parameter depends on the\noutput of a certain model. \n\nFor this, they note that generalized gradient of such objective values are\nefficiently computed using the primal and dual solution of the ILP itself. In\nparticular, the ILP can be solved using specialized and efficient solver,\ninstead of solving a generic LP, as proposed in concurrent work.\n\nThe authors propose two example applications, that are described precisely, and validated against generic LP solving approaches. Using combinatorial specialized solvers outperform generic LP solving approaches in term of computation, and in term of validation metrics, as generic LP solving is hindered by errors which makes the learning process diverge.\n\nReview\n------\n\nThe paper is well written and well organized. The theoretical aspects are well documented, and the examples are introduced precisely and pedagogically.\n\nThe method itself is interesting as it ensures that the generalized gradient of\nmany ILP problems are computable efficiently. Theorem 1 states those guarantees, and many examples are discussed.\n\nOn the other hand, the novelty of the method may be a little overstated. In\nparticular, it is known that using a generic LP solver is oftentimes not the\nmost efficient way of computing the gradient, and that specialized combinatorial\nsolver should be used. \n\nFor the problem of GSA, which corresponds to using a dynamic time warping loss,\nsolving the small LP is done using dynamic programming. Using a DTW loss on top\nof a deep neural network has already been studied (see e.g. the cited Mensch and\nBlondel paper, where the authors solve the LP using DP). Using a generic LP\nsolver such as the one in cvxpy is a little naive in that case, and it not\nsurprising that it performs poorly. \n\nIn this example, we only require the gradient with respect to the cost (P is\n\"primal-pdfiff-efficient\"). Arguably, this manuscript also enable us to\nbackpropagate through parametrized constraints, using the formula proposed in\nTheorem 1, which is little known in this community.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Differentiating over the objective of a linear (integer) program is not an interesting problem",
            "review": "The value of the optimal objective as a function of the cost vector $c$ can be written as $z^*(c) = c^T u^*(c)$ where the optimal solution $u^*$ also depends on $c$. The function $u^*(c)$ is piecewise constant -- there are finitely (resp. countably) many feasible solutions; candidates for $u^*$ -- and so the function $z^*(c)$ is a piecewise linear function of $c$, with gradient $u^*(c)$, wherever it exists (otherwise there is analogous subgradient). Obviously, all it takes for computing $u^*(c)$ is solving -- anyhow -- the combinatorial problem. This is all trivial and well-known, yet the authors do precisely that.\n\nCan it be saved by proposing gradients also of w.r.t. constraints? No. These results are (slightly) less trivial but -- as authors admit -- are known since 1975. Moreover, the gradient with respect to $c$ is the only one used in experiments, as far as I understand.\n\nIs there independent value in Theorem 1? I do not see it. It seems to be a bulky wrapper around the classical result. It only introduces some sort of transition from a vector specifying a combinatorial problem to a collection of vectors/matrices specifying an integer program. Also, the central concept of generalized gradient merely provides a formal framework to talk about non-unique gradients at boundary regions -- similarly to subgradient, subdifferential -- for the method itself, it has no specific relevance.\n\nThe claims of better performance compared to cvxpy are also absolutely non-surprising -- cvxpy currently uses a slightly suboptimal -- and a very expensive -- solver for linear programs. That is all.\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}