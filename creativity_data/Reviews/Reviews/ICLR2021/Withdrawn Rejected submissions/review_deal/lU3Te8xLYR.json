{
    "Decision": "",
    "Reviews": [
        {
            "title": "Comments on Self-supervised Bayesian Deep Learning for Image Denoising",
            "review": "In this paper, the authors aim to train a denoising NN on a dataset consisting of only noisy images. The authors utilize the idea of BNN which treats the weights in the denoising network as random variables, and sample a large amount of networks in the testing phase to achieve a MMSE of clean image. I tend to reject this paper due to the following reasons:\n1. The proposed method is very similar to [a1], which also only uses one noisy sample to train a denoising network. The only difference between this paper and [a1] is that this paper estimate \\mu and \\sigma explicitly to characterize \\theta while [a1] simply utilize dropout to obtain random networks. Based on the very similar results reported in this paper and [a1], the extra effort of characterizing q(\\theta|\\mu, \\sigma) seems not very important. I guess the key to the success of this paper and [a1] is introducing certain randomness in the inference process so that ensemble approach can be utilized. \n2. I suggest the authors to report the PSNR value v.s. MC sampling number T.\n\n[a1] Self2Self With Dropout: Learning Self-Supervised Denoising From Single Image. In CVPR 2020.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "I'm positive to this work.",
            "review": "The paper is well written. Even the idea of weighting uncertainty and Bayesian averaging is not new, they are applied to self-supervised denoising for the first time and are effetive. Thus, my attitute is positive to this work.\n\nBesides, I still has some concerns with this work:\n\n1. Bayesian averaging will make the model slow. It's better to also report the running time anc compare with the competing methods.\n2. The comparison with other self-supervised methods is not fair. From Eq. (22), the model parameters of the proposed method is based on noise variance, making it only applicable to AWGN and the noise variance should be known in advance.\n3. Some latest efforts on self-supervised denoising in CVPR'20 and ECCV'20 are also suggested to be discussed. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting idea, but still has some issues",
            "review": "The paper proposed an interesting method for image denoising. By combining existing self-supervised learning method and Bayesian neural network, this paper proposed a self-supervised deep learning method for denoising a single image without requiring training samples, which is appealing to the applications where collecting training samples is challenging, eg. biological imaging and medical imaging. The experiments showed that the performance is competitive to those state-of-the-art supervised ones. \n\nMerits of the paper:\n+ The idea of using Bayesian network for single image denoising is interesting and novel. To train a network without external training samples is useful in many scenarios, such as biological and medical imaging.\n+ The overall performance is good. It outperforms classical image denoising algorithm BM3D and deep learning based algorithm DIP. It also has competitive performance when comparing with N2N, N2V, and fully-supervised methods. \n\nIssues of the paper:\n- The motivation of this work is not well explained. More discussion should be provided about why the BNN achieves better performance. The paper has mentioned lots of different concepts, such as \"reducing variance\", \"handling overfitting\", and \"correcting bias\", which are vague and confusing. Please clarify the relationship between these concepts and why the proposed method has those advantages. Also, it is not clear how the regularization terms in (17) affect the performance. Further, it would be good if the paper can better explain why Gaussian distribution is a good assumption of p(theta|y).\n- In Section 4.1 and 4.2, the compared methods are kind of outdated. It would be good to include some more recent approaches, such as \"Learning Spatial and Spatio-Temporal Pixel Aggregations for Image and Video Denoising\", TIP'20, \"Reconstructing the Noise Variance Manifold for Image Denoising\", ECCV'20.\n- In Section 4.2, why further corrupt y with Gaussian noise? Is this step also required in testing?\n- In Section 5, it is not proper to claim potential applications in other image recovery tasks, as the proposed method highly relies on the specific task: image denoising (N2V and N2S). It is not quite obvious that the proposed method can be applied to other tasks.\n- Is the algorithm running at a reasonable speed? How long does it take to process one image?\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This paper proposes a self-supervised image denoising method based on a deep neural network. In order to avoid the trivial solutions, it proposes a Bayesian neural network. Experimental results show the effectiveness of the proposed method.",
            "review": "The paper proposes an effective BNN which is trained on single input image. It generates paired data by a Bernoulli matrix according to (12). The network training is achieved by minimizing e KL divergence (15). The quantitative results show that the proposed method performs better than the compared methods. \n\nThis paper has several problems. First, it is not clear why using Bernoulli distribution to generate the paired data. How about other distributions? In addition, it is not clear why the proposed method can avoid the trivial solutions. No theoretical analysis is provided. \n\nUsing Bayesian method in the deep neural network for self-supervised image denoising has been developed in prior works, e.g., Wu et al., Unpaired Learning of Deep Image Denoising. The authors do not clarify the differences from existing methods, and the novelty of the paper is not significant. \n\nMore analysis on the network design should be provided. For example, the authors should provide shows the model parameters of the network to examine whether the performance gains are due to the use of the large capacity models or not. What does Bayesian convolution mean? The motivation of designing such network for image denoising is not clear. \n\nFor experiments, it would be better to show whether the proposed method still performs well for the images with mixed noise levels. In addition, comparisons with Bayesian-based deep models are needed. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}