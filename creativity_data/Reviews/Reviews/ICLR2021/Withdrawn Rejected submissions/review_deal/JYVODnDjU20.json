{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes a two stage approach for anomaly detection - first train a low dimensional embedding potentially using self-supervised learning methods, and then train a discriminator on top of the embedding that takes in pairs of examples and outputs a score which can be used for anomaly detection. A test example is paired with the next nearest neighbor. A common concern of the reviewers was on the claim of the paper to be a general approach for anomaly detection whereas experiments are reported only on vision datatsets. The authors have addressed this by making changes to the title and to the claims made in the paper. However R1 and R2 still have concerns about insufficient empirical evaluations, in particular lack of non-vision datasets. \n\nAs the paper aims to tackle the problem where OOD examples are spread through the sphere, appearing mixed with normal examples, I think fitting a nonparametric density model (eg, using KDE) or parametric density model (eg, a mixture model) on the embeddings is a natural baseline to compare with. \n\nI encourage the authors to strengthen the empirical section of the paper based on reviewers' comments and resubmit to a future venue. "
    },
    "Reviews": [
        {
            "title": "interesting work but needs more clarification/verification on methods/details to validate the results ",
            "review": "Summary\n- Presents GenAD as a general framework for anomaly detection\n- Method builds on top of contrastive training and proposes to learn a discriminator to distinguish between semantically similar and dissimilar pair of examples\n- Results are SOTA but need verification through code and methods clarification\n\nClarity/Quality:\n\nPaper is overall written OK but several typos/grammatical errors as highlighted below:\n\n- “For visual data we show new state-of-the OOD classification accuracies for standard benchmark data sets” -> new state of the \n  “art” OOD classification\n- “The contrastive objective aligns feature vectors h = h(x)” -> consider using different symbols for the vector output and the \n   encoder function\n- “A statically meaningful score” -> statistically?\n- The notation “Pneg(x, x’) = Ppos(x)Ppos(x’)” is unclear. Is marginalization implied? (end of page 3)\n- “mainly affects the weights of a small subnetwork Frankle & Carbin (2019)” - missing parentheses around reference\n- “If we belief in the lottery hypothesis” -> belief to believe\n- “We expect to see a significant increase in OOD detection performance upon increasing network size, which left to future work.” \n -> which is left to future work\n\nNovelty:\n\nCentral claim - Contrastive training maps example to unit hypersphere but it is possible OOD examples can be in same neighborhood. Hence need a semantic discriminator and introduces it along with algorithms for sampling positives/negatives. \n\nSignificance:\n\nThe central idea is simple and well motivated. If (and it is a big if) the results are verified, this could be a very important paper in the field of OOD detection. \n\nQuestions/Comments/Clarification\n\n- Assumption is all OOD is semantic which may not always hold true especially if there are stylistic varaiations introduced using different imaging equipment\n- Unclear why gamma (Yneg and Ypos) was introduced\n- Unclear how encoder and discriminator are trained? Is it jointly or separately? Are these the same networks? Architecture diagram for network setup is needed to clarify details\n- Why does the discriminator enable learning of semantic dissimilarity?\n- While algorithm for sampling of positives is specified how are negatives sampled?\n- In Table 2, ablation corresponding to T(x) should be similar to results from (Winkens et al. 2020) right? However the \n  corresponding values are much higher (78.3 vs 89.3). The only difference seems network sizes. Not sure how these results came \n  about?\n- In Appendix C2 - “To train the discriminator s(x, x0 ), we use almost the same network structure as our contrastive encoder but \n  with smaller width and the MLP layer projects to a scalar output.” -> so do you not train the discriminator on top of contrastive \n  representations? If yes, then how is the network pruned to smaller width?\n- Why was ADAM used instead of LARS as in Chen et al?\n- Claim of general framework for OOD detection is strong as no results shown on non visual domains.\n\nOverall, this is an interesting idea but the method needs a lot more clarification and results need verification. Would encourage authors to share code to help verify the methods/results.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review AnonReviewer2",
            "review": "\n**UPDATE**\n\nI acknowledge that I have read the author responses as well as the other reviews. I appreciate the clarifications and improvements made to the paper and have increased my score 5.\n\nMy concerns about the generality of the framework (as also pointed out by Rev1) still hold, however, as an evaluation on non-image data is still missing. I encourage the authors to extend their work further into this direction, but as is, I would keep my recommendation to reject.\n\n#####\n\n**Summary**\n\nThis work presents a generic approach for out-of-distribution (OOD) detection or anomaly detection (AD) called GenAD. GenAD consists of two steps: First, (i) learning a spherical representation via contrastive learning to capture semantic similarities, followed by (ii) training a classifier to discern between semantically similar and dissimilar pairs of samples, given the representation from (i). An experimental evaluation on in-distribution vs. out-of-distribution dataset pairs (CIFAR-10 vs. SVHN, CIFAR-10 vs. CIFAR-100, CIFAR-100 vs. CIFAR-10) is presented which shows that GenAD outperforms previous OOD methods on these settings.\n\n\n**Pros**\n+ OOD detection is an important open problem that is relevant and of interest to the community.\n+ GenAD seems to improve over previous methods in the visual domain.\n+ GenAD, in principle, is applicable to general types of data (e.g., images, audio, text, etc.).\n\n\n**Cons**\n- There are some critical details missing about the specific choices made for sampling negative pairs, which makes it hard to assess the technical correctness and merit of the presented approach. In general, I find it hard to follow and exactly understand all the relevant details from reading the description of the method in Section 2.\n- Though the applicability of the approach to general types of data is emphasized, the experimental evaluation only includes image data.\n- Some recent related work from the out-of-distribution [6, 9, 10, 5] and deep anomaly detection [7, 3, 1, 2, 4, 8] lines of research are missing which also study representations that are effective for detecting semantic out-of-distribution samples and propose various solutions.\n\n\n**Recommendation**\n\nAs is, I recommend to reject this paper primarily due to a lack of clarity and missing details in the description of the approach, which makes it hard to assess the technical correctness and merit of GenAD.\n\nIn particular, how are $P_{pos}$ (via transformation or neighborhood or both?) and $P_{neg}$ exactly modeled in the experiments?\nIn Section 2.2, $P_{neg}$ is defined as the product of positive marginals, but how is this implemented?\nHow are the negative minibatch $\\{x_k^r\\}_{k=1}^N$ and the negative set of transformations in $T^{negative}$ in Algorithm 1 defined and chosen?\n\nThese details should be clarified and explained.\n\n\n**Additional feedback and ideas for improvement**\n- Include the missing details and try to explain the approach more clearly (there is one page of space currently left).\n- Include other types of data in the experimental evaluation, which would strengthen the generality claim of the proposed approach.\n\n\n**Minor Comments**\n\n1. The title of the paper is very generic.\n2. The figures in the paper are disproportionately large and waste quite some whitespace.\n3. The batch sizes reported in the experiments are uncommonly large (1024, 2048). What is the reason for this choice?\n4. I think Algorithm 2 can be removed, as it just describes $k$-NN using cosine similarity, right?\n5. Section 1: ‘Note that it is possible for a datapoint to have high likelihood under a distribution yet be nearly impossible to be sampled, a property known as asymptotic equipartition property in information theory.’ Citation?\n6. Section 1: ‘Intuitively, the OOD detection problem should be independent of the hardness of an in- distribution classification task.’ Why? I could imagine the hardness of an in-distribution classification task can be due to a complex in-distribution, for which the OOD detection problem is also more difficult.\n7. Make use of page 8 in the main paper, e.g. move interesting claims and derivations to the main paper.\n8. Section 3.1: ‘[...] - for both the encoder $f(x)$ and the *classifier* $s(x,x′)$.’ I would avoid to use the discriminator term.\n9. Table 1: Add space between method names and citations.\n10. Section 4: ‘[...], with increase in state-of-the-art AUROC from 0.783 to > 0.999.’ What about the 0.856 of OpenHybrid in Table 1?\n11. Section 4: ‘Note that $h(x)$ *encodes features* of semantic similarity but not necessarily *features that allow* to score semantic dissimilarity.’\n12. Section 4: ‘In fact, we observe for CIFAR-100 that examples from the same semantic neighbourhood do not always share the same label.’ Could you include some example images?\n\n\n#####\n\n**References**\n\n[1] F. Ahmed and A. Courville. Detecting semantic anomalies. In AAAI, pages 3154–3162, 2020.\n\n[2] L. Bergman and Y. Hoshen. Classification-based anomaly detection for general data. In ICLR, 2020.\n\n[3] I. Golan and R. El-Yaniv. Deep anomaly detection using geometric transformations. In NeurIPS, pages 9758–9769, 2018.\n\n[4] S. Goyal, A. Raghunathan, M. Jain, H. V. Simhadri, and P. Jain. DROCC: Deep robust one-class classification. In ICML, pages 11335–11345, 2020.\n\n[5] P. Kirichenko, P. Izmailov, and A. G. Wilson. Why normalizing flows fail to detect out-of-distribution data. arXiv preprint arXiv:2006.08545, 2020.\n\n[6] A. Meinke and M. Hein. Towards neural networks that provably know when they don’t know. In ICLR, 2020.\n\n[7] L. Ruff, R. A. Vandermeulen, N. Görnitz, L. Deecke, S. A. Siddiqui, A. Binder, E. Müller, and M. Kloft. Deep one-class classification. In ICML, pages 4393–4402, 2018.\n\n[8] L. Ruff, J. R. Kauffmann, R. A. Vandermeulen, G. Montavon, W. Samek, M. Kloft, T. G. Dietterich, and K.-R. Müller. A unifying review of deep and shallow anomaly detection. arXiv preprint arXiv:2009.11732, 2020.\n\n[9] R. T. Schirrmeister, Y. Zhou, T. Ball, and D. Zhang. Understanding anomaly detection with deep invertible networks through hierarchies of distributions and features. arXiv preprint arXiv:2006.10848, 2020.\n\n[10] Z. Wang, B. Dai, D. Wipf, and J. Zhu. Further analysis of outlier detection with deep generative models. arXiv preprint arXiv:2010.13064, 2020.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Recommendation to Accept",
            "review": "##########################################################################\n\nSummary:\n\nThe authors present a new Algorithm for performing unsupervised anomaly detection in diverse applications such as visual, audio and text data. They propose a two-step method in which first they utilise contrastive learning in order to find a semantically dense map of the data onto the unit-hypersphere. Then, they classify neighbouring pairs of test examples as in- or out-of- distribution based on the amount of the shared semantic information. Finally, they show that in several anomaly detection problems in the field of visual data their proposed method outperforms several existing methods.\n\n##########################################################################\n\nReasons for score: \n\nI recommend to accept the paper since the authors deal with an important problem and they propose a clear and well-written method that outperforms in their empirical applications, at least, several existing approaches. Please find below cons that I suggest the authors to address in the rebuttal period.\n\n##########################################################################\n\nCons: \n\n1) Although the authors refer to several existing anomaly detection methods I would suggest to add a separate and relatively small literature review section in the paper. In that section the authors should list the most relevant, existing, anomaly detection methods and briefly explain them. This will improve the readability of the paper.\n\n2) The authors identify that the main limitation of the proposed approach is the definition of a semantic similarity which in some applications can be very difficult. Therefore, I suggest the authors to perform a sensitivity analysis of their results with respect to the transformations that they use. I propose to add one or two tables similar to Table 1 in which they will compare versions of their method resulting from using different/misspecified transformations with the competing methods. They could for example add some 'noise' in the transformation that they use and re-perform the comparisons.\n\n3) The authors should make, within their main text, reference to the Figures and the Algorithms that they present. By giving briefly the utility of each of their Figures and Algorithms they will improve substantially the readability of the paper.\n\n##########################################################################\n\nMinor comments: \n\n1) Define d in 'd-dimensional' in page 2. \n\n2) Conduct an extensive search for typos, correct for example the punctuation in 'everything that is not noise' at the bottom of page 7.\n\n\n\n \n\n\n \n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A dimensionality reduction based approach to anomaly detection for images that tries to overcome certain disadvantages of autoencoders",
            "review": "The paper proposes an OOD detector algorithm that first learns a function to reduce the data dimensionality followed by learning a classifier discrimination model to separate in-distribution data from OOD.\n\nPro:\n1. The paper compares many baseline algorithms\n2. The paper tries to address an important problem (OOD detector)\n\nCon:\n1. The paper title is 'A General Framework...', however, the few datasets selected for experiments represent a very narrow domain. The paper title should be narrowed down or more domains should be included in experiments.\n2. There are gaps in the intuitions such as why would two instances in the same neighborhood in the reduced dimension not be expected to have similar labels.\n\nMain Comments:\n\n1. The overall approach is that of reducing the dimensionality of the data by projecting it onto a lower dimensional manifold (surface of hyper sphere) and then using a discriminator. This approach is not novel in general.\n\n2. While the paper claims that this is a general technique, it depends on the concept of 'semantic neighborhood' for which it only provides CIFAR variants as evidence. We do not know (contrary to claims) whether it might work on other types of data (audio, text, etc.)\n\n3. Section 4: \"Our interpretation ... includes all semantic information ... helps OOD detection. In contrast, learning from label information ... mainly the semantics that help predicting labels.\" -- The paper does admit that the 'semantic neighborhood' is ill defined (Section 6, Conclusion). Yet the paper assumes, in Section 4, that the proposed technique (using pairwise distance metric) learns it well for the image data it was tested on. It is hard to see how this interpretation is justified. My assumption is that the algorithm has only learned what is necessary for the task of OOD just as a classification algorithm will learn what is necessary for labeling. There are many critical decisions that have gone in to design the proposed OOD detector (such as the distance metric to use, which features to use for the discriminator, etc.). It is more conceivable that in the end the algorithm has learned just enough representation that makes the combined design choices work well on the specific dataset. It is hard to generalize given that the experiments cover so few datasets. I suggest the paper remove 'semantic neighborhood' terminology.\n\n4. Section 2.2: \"...belief in the lottery hypothesis...\" -- Many of the subnetworks might be sharing weights and are therefore not independent. This point becomes more important because as discussed in Section 3.1, a small network was used which increases the likelihood of weight-sharing. So, the true ensemble effect might be absent in reality.\n\n5. Section 2.2: \"The idea is now to make use of the fact that nearby examples on unit-hypersphere share semantic information if both come from the in-distribution but don’t share semantic information if one of the two examples is OOD.\" -- It is not clear to me why any two close examples would not share semantic similarities assuming that the mapping function is smooth. In case the contrastive objective results in such as case, then we might have very noisy labeled data.\n\n6. Section 3.1: \"We train at batch sizes of either 1024 or 2048 using ADAM optimizer.\" -- These batch sizes are quite large than conventional (e.g. 32, 64). Is there a reason for that?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}