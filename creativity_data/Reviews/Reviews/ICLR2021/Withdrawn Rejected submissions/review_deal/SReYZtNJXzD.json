{
    "Decision": "",
    "Reviews": [
        {
            "title": "A method trying to unify the design of example weighting",
            "review": "Summary:\nThis paper presents a method based on scaling gradients of examples for robust learning from noisy labels. The proposed method is close related to example reweighing according to their significance. Specifically, the proposed method considers Emphasis Mode and Emphasis Spread, which refer to those examples that own the largest weight and the spread of the weights. Based on proper scaling parameters, the proposed method covers standard losses such as CCE, MAE, and GCE. Experiments on image classification datasets CIFAR-10/100,  Clothing 1M and video retrieval dataset MARS, show that the proposed method achieves competitive results learning from for noisy data.\n\n\nPros:\n+ Authors try to unify the design of example weighting and loss function in a single framework equipped with hyper-parameters which control emphasis focus and spread. \n+ The proposed method is simple and the paper is easy to follow in general.\n+ Experiments on several datasets including image classification as well as video retrieval show that proposed method can improve upon baselines.\n\nConcerns:\n- One of the main concerns for the proposed method is the choice of newly introduced hyperparameters. A separate trusted validation set with clean labels are used to search hyperparameters. I'm wondering is that possible to set proper hyperparameters without relying on the clean data? Is there any clear rules to set them?\n\n- Comparisons with more recent state-of-the-art methods are missing. Most methods included for comparison are before year 2019. More recent methods published in year 2020 such as [a], [b] etc. \n\n[a] Normalized Loss Functions for Deep Learning with Noisy Labels, ICML 2020\n[b] IEG: Robust Neural Network Training to Tackle Severe Label Noise, CVPR 2020",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review for \"Derivative Manipulation for General Example Weighting\"",
            "review": "The authors of the paper address an important problem of robust learning under noisy labels and data imbalance. As a starting point, an interesting concept of “derivative manipulation” is introduced in order to evaluate the different performances of various loss functions like MAE and CCE in terms of the relative weighting of the gradients of different samples. With this concept in mind, instead of trying to deal with loss functions, the authors of the paper argue that it is more convenient and effective to directly manipulate the weights of the gradient of samples, and propose a general weighting scheme to adjust the weighting of gradients. Extensive experiments were conducted to evaluate the effectiveness of the proposed method. \n\nThe paper is easy to follow in general, and the idea of weighting gradients instead of devising alternative loss functions seems interesting. Ample experiments were also conducted to justify the effectiveness of the method. Nevertheless, there is one significant drawback of this submission. To be more specific, in my opinion, there is a significant overlap in terms of the content of the submission and that of [1]. For instance, the derivative analysis in section 3.1 of the submission also appeared in [1]. Moreover, the proposed exponential weighting scheme (Equation 12) of this submission (which in my opinion is one of the most significant contributions of the paper) is almost identical to the proposed “IMAE” loss in [1], to the best of my knowledge and understanding. As such, due to the similarity between these two papers, I think that there is very little novelty present in the submission. As such, I recommend rejecting the paper at the moment.\n\nOther comments:\n1. The concepts of “emphasis mode” and “emphasis variance” might need more elaboration? I am having a hard time understanding the importance in the contexts of the paper. For instance, it is stated that “Both emphasis mode and variance matter.” Why is this case? Could you elaborate on the two concepts introduced? \n2. Section 3.2.2 is a little bit confusing, and a lot of the statements made might need further description. \n\n[1] Xinshao Wang, Yang Hua, Elyor Kodirov, and Neil M Robertson. IMAE for noise-robust learning: Mean absolute error does not treat examples equally and gradient magnitude’s variance matters. arXiv preprint arXiv:1903.12141, 2019b. ",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting direction, but needs further analysis",
            "review": "Summary: the paper proposes derivative manipulation (DM). DM is inspired by the form of the gradient of the loss wrt logits in the final layer. The authors calculate the dependence of this factor on the class probabilities for a number of loss functions and propose a number of weighting schemes. The results are validated on standard datasets.\n\nReview: I certainly like the idea of derivative manipulation and I believe this work has great potentials. Especially, the beta distribution weighting is an interesting extension, which includes many other loss derivative forms. However, the authors miss some key theoretical considerations in their development. Namely, arbitrary weighting of the gradient leads to loss functions that are not proper, i.e. they are biased estimators of the true posteriors in the noise-free setting. Properness is an important property in many applications such as ranking. For instance, the generalized CE (GCE) loss function was extended by (Amid et al. 2019a) to a two-temperature variant with t1 and t2 where t1 = q and t2 = 1 recovers GCE. In that paper, Amid et al. showed that  their two-temperature extension bases on the Tsallis divergence (which includes GCE) is not a proper loss. More recently,  (Amid et al. 2019b) proposed the bi-tempered loss which provides a proper generalization of the CE loss and also includes MSE as a special case. The derivatives of the bi-tempered loss includes the power factors of class probabilities, which depend on the choice of temperatures. I highly encourage the authors to consider these work in their revision and provide an analysis of properness and Bayes-consistency in their submission. I believe with some extra effort on the theoretical side, this work could provide interesting insight on different loss functions.\n\nAdditional references:\n\n(Amid et al. 2019a) Amid et al. \"Two-temperature logistic regression based on the Tsallis divergence.\" In The 22nd International Conference on Artificial Intelligence and Statistics, 2019.\n\n(Amid et al. 2019b) Amid et al. \"Robust bi-tempered logistic loss based on Bregman divergences.\" In Advances in Neural Information Processing Systems, 2019.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "This paper introduces an interesting method, derivative manipulation, for robust training and learning with imbalance data. Although it provides some analysis about the loss function and the example weighting as well as the design of DM, it does not sufficiently explain the advantages of DM compared to previous state-of-the-arts. The results in some experiments are also not very appealing or convincing due to lack of the recent strong baselines.",
            "review": "This paper starts from the intuition that many commonly used losses like CCE, MSE, MAE etc, optimize the model in the same direction but with different magnitudes. Then, the authors proposed a DM to adaptively adjust the weight of the derivative originated from the supervision and prediction. It is interesting that it directly designs the derivative (concretely the scale of the derivative) instead of the loss. However, the main concerns are summarized as follows,\n\n1) For both designing the weight in the perspective of the derivative and in the perspective of the loss, we all require some heuristics about the noisy data from the knowledge or the phenomenon in the training. It is not clearly explained how DM incorporates such prior and performs better than previous works that also consider this.\n\n2) The experiments for training with noisy labels have not included some recent strong baselines like Mixup, DivideMix, MentorNet and MentorMix. According to the results reported in these works, it is not very convincing that DM can really performs better than them, which makes the weighting schema for DM is not very appealing.\n\n3) Learning with imbalance data seems to be another point that this paper focuses according to the abstract, introduction and the experiments. However, we do not see much analysis how the weight schema in DM solves the issue of imbalance data. It is similar to previous concerns that the authors have not sufficiently explained the advantages of DM compared to the previous baselines and when DM is a good choice for these tasks. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}