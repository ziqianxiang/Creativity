{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper investigates the problem of unsupervised domain adaptation and proposes a framework based on a specific type of disentangled representations learning. The paper is well written and the proposed method seems plausible. However, according to Reviewers #3 and #4, the proposed framework does not seems to be sufficiently different from existing ones, and the empirical results do not seem convincing enough. \n\nPlease also double check in C3, whether T and S should be marginally independent or conditionally independent conditioning on X."
    },
    "Reviews": [
        {
            "title": "The novelty is limited and the experiment of this paper is not strong enough.",
            "review": "This paper proposes a new framework for unsupervised domain adaptation by applying the disentangled representations learning (DiCyR). The core idea of DiCyR is to split the raw feature into the task-related one and its complimentary context where the task-related representations are projected into a shared space for alignment. From my point of view, disentangled representations learning is the most interesting part of this work.\n\n\n-Pros:\n1. This paper is well organized with clear logic to follow. The authors have introduced the problem statement and related works very well.\n2. The motivation of disentangled representations learning for domain adaptation is very straightforward and clear. \n3. The authors provide the demo code of this work to prove its reproductivity.\n4. There are some visual results that could attract readers a lot.\n\n-Cons:\n1. Novelty: \nTaking the cross-domain image translation is a smart way of data augmentation, which has been well studied. Since 2017, CyCADA has introduced the CycleGAN framework for domain adaptation and has received a significant impact since then. This work extends the image translation idea by applying the disentangled image generation based on cyclic consistency. Moreover, there are a lot of previous papers working on similar topics [1, 2, 3, 4]. In this way, I think the novelty of this paper is minor.\n\n2. Experiment:\nIn the domain adaptation task, the authors only evaluate its model on the toy datasets (Digital Datasets), which cannot fully prove this model's effectiveness. I am curious why not using the latest office-home, domainnet, or the Cityscapes-to-GTA5 as the main experiment. On MNIST to SVHN, the DiCyR performs rather weakly. Moreover, there are more recent works, such as [5] should be compared.\n\n3. Time and Computational Cost\nCycleGAN-based image translation usually takes a lot of training time. The author mainly used the small size images (32 \\times 32) for evaluation, and it requires a P100 GPU for training. What the time and computational cost will be if using large images such as 224 \\times 224? \n\nIf the authors could address all the concerns above, I will consider upgrading the score.\n\n\n[1] Cai R, Li Z, Wei P, et al. Learning disentangled semantic representation for domain adaptation. IJCAI, 2019.\n\n[2] Cao J, Katzir O, Jiang P, et al. Dida: Disentangled synthesis for domain adaptation[J]. arXiv preprint arXiv:1805.08019, 2018\n\n[3] Li H, Wan R, Wang S, et al. Unsupervised Domain Adaptation in the Wild via Disentangling Representation Learning. IJCV, 2020\n\n[4] Yang, Junlin, et al. \"Unsupervised domain adaptation via disentangled representations: Application to cross-modality liver segmentation.\" MICCAI, 2019.\n\n[5] Hosseini-Asl, Ehsan, et al. \"Augmented cyclic adversarial learning for low resource domain adaptation.\" ICLR, 2019.\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The paper proposes a disentanglement method, named DiCyR in the problem of unsupervised domain adaptation.",
            "review": "#####################\n\nSummary:\n\nThe paper proposes a disentanglement method, named DiCyR in the problem of unsupervised domain adaptation.\n\n#####################\n\nReason for score:\n\nOverall, the paper is above the borderline. I like the idea of utilizing disentanglement learning with a cycle constraint into the unsupervised domain adaptation issue. My major concern is about some unclear parts described in the paper and insufficient experimental comparison (see cons below). Hopefully, it would be grateful that the authors could address my concerns during the rebuttal period.\n\n#####################\n\nPros:\n\n(1) The idea in the paper to introduce disentanglement learning based on cyclic reconstruction to unsupervised domain adaptation is very novel and interesting, which can split the captured information from data into task-related representation and context-based features to help improve the domain generality of the model.\n\n(2) The disentanglement learning to split the information into a task-related representation and a context representation is reasonable and promising, which is beneficial to the task model adapted in different domains.\n\n(3) Extensive experimental results on several widely-adopted benchmarks show the effectiveness of the proposed model comparing with other state-of-the-art methods.\n\n#####################\n\nCons:\n\n(1) In the paper, the introduced disentanglement learning method can split information captured from images into a task-specific feature and another task-orthogonal representation. However, the proposed method cannot consider the domain-specific and domain-orthogonal information, which may degrade the performance in experiments and deserves to be discussed further. So how to learn the domain-invariant representation in the model? Please explain more details.\n\n(2) In the part of the experiment in the paper, the authors conduct the experiments on the task of image style transfer. However, the task of semantic segmentation on Cityscapes is always widely adopted in related UDA papers, which is not included in the paper. Please consider adding such experimental results and analysis to demonstrate the effectiveness of the proposed method in the paper if feasible.\n\n(3) In the paper, the author claims the proposed model can achieve high computational efficiency, but there are no figures or tables to demonstrate it. Please consider listing the comparison results of training time and test time in the experimental part.\n\n#####################\n\nQuestions during the rebuttal period: \n\nPlease address and clarify the cons above. Thank you!\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting idea, but incompetitive performance ",
            "review": "This paper studies the domain adaptation problem by addressing the challenge of splitting task-specific and task-orthogonal information in the target domain using the proposed disentangled cyclic reconstruction method. The authors further develop a variant for the unsupervised domain adaption (UDA) task. The authors argue that the existing adversarial classifier based UDA solutions do not guarantee that the domain specific information does not contain any information that overlaps with the shared information in the target domain. Another shortcoming of these baselines is the learned representation in their domain-invariant feature space might not allow for accurate labeling in the target domain. To solves these limitations, the authors directly minimize the information sharing between representation, instead of using domain adversarial classifier and adversarial label predictor.\n\nThis paper is well structured and easy to follow. The authors make several interesting and insightful statements. While the justifications of these main statements are not well presented theoretically/experimentally. \n\nIn page 3, the authors argue that the existing solutions achieve a domain-invariant feature space in which the representation might not allow for accurate labeling in the target domain. The following explanation reads vague to me. A qualitive example or an analytical experiment is encouraged to have to justify the mentioned “some elements” will hinder the performance.\n\nMy major concern is the evaluation results compared with the baselines is not competitive. As shown in Table 2, in the benchmark MNIST/USPS/SVHN datasets, the proposed method is inferior to the baselines like SEDA, DWT, SBADA-GAN. Since these datasets are relatively simple, I would encourage the authors to conduct experiments on other more challenging UDA benchmarks, like DomainNet [ref-1] and VisDA2017 [ref-2]\n[ref-1] X. Peng, et al., Moment matching for multi-source domain adaptation. In ICCV, 2019.\n[ref-2] X . Peng, et al. Visda:  The visual domain adaptation challenge.arXiv preprint arXiv:1710.06924, 2017.\n\nMissing some recent related works, including but not limted to\n[ref-3] Ryuhei Takahashi, et al: Partially-Shared Variational Auto-encoders for Unsupervised Domain Adaptation with Target Shift. ECCV 2020\n[ref-4] Jian Liang, et al: Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation, ICML 2020\n\nOther minor point. In page 3, last sentence in paragraph 4, “ a discriminator with a an inverted label loss”. Remove ‘a’.\n\nUpdates: Thanks for the authors' response. Some of my queries were clarified. However, unfortunately, I still think more needs to be done to show the superiority of the results. I retain my original decision.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}