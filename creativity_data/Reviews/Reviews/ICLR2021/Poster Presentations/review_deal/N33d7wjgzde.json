{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This article proposes a novel weakly supervised segmentation method that unifies several annotation types using contractive/metric learning. This method clearly outperforms the current SOTA. While the unified framework itself is not novel enough, the reviewers agree that the contrastive loss formulation is interesting and the extensive experiments show its effectiveness. Overall, I consider that this unified framework is well engineered, the formulations are insightful, and the results advance the SOTA of weakly supervised segmentation. Accordingly, I propose to accept this paper at ICLR 2021."
    },
    "Reviews": [
        {
            "title": "The paper performs pixel to segment metric learning based on various heuristics and obtains clear SOTA results on various weakly-supervised visual learning tasks",
            "review": "\nWeakly-supervised image/object segmentation can naturally be formulated as a pixel-level semi-supervised problem. To solve the insufficient supervision problem in weakly-supervised segmentation, the paper proposes to use four kinds of heuristics to provide supervision for training pixel-level metric learning. The takes the advantages of image segments generated from edge detectors (HED & gPB), then low-level image similarity, semantic annotation, semantic co-occurrence, and feature affinity.\n\nThe paper has obvious advantages summarized as follows.\n1. It unifies various weakly-supervised segmentation tasks by proposing pixel-level metric learning.\n2. The paper obtains clear SOTA results and significantly promotes the development of weakly-supervised segmentation.\n\nThe weakness of the paper is its clarity. Lots of details are missing in the paper, e.g., I cannot find how to apply semantic co-occurrence applied in training segmentation models using image classification models. I think this is not the authors' fault. The problem is caused due to there are so many contents in the paper. Thus, I think source codes should be released and well-organized to ensure the reproducibility of the paper.\n\nBesides, the terms in the papers can be re-considered. (1)  Although contrastive learning is very popular now, I think the method is better termed as metric learning - its original name. (2) I think there are some redundancy in semantic annotation, semantic co-occurrence, and feature affinity. The relation between them should be clarified and justified.\n\n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "great performance but a bit incremental",
            "review": "The submission proposes a unified framework for weakly supervised semantic segmentation which is compatible with different types of annotations including image tag, bounding box, points and scribbles. With different kinds of labels, the method derives positive and negative segments for each labels and via metric learning the network learns to predict class label for each pixel. While the proposed method obtained STOA or close to SOTA performance on VOC2012 and densepose dataset, the reviewer feels that the novelty of the proposed method is not significant enough. A unified framework for semantic segmentation is appealing but it isn't new. E.g. Guided Attention Inference Network, TPAMI 2019 proposed a way to use gradient-based attention weakly supervised semantic segmentation framework which is compatible with image tags, bounding boxes and pixel-level annotations. In their work, different kinds of annotations are converted into supervision on class-specific attention maps and no parameters need to be tuned based on the ratio/types of annotations are used in the training, whereas the proposed method here needs different parameter choices for different lables/dataset. In the reviewer's eyes the submission follows a similar direction, although the framework design and objectives are different. The reviewer hope the authors can clarify their contribution and add discussions comparing to other similar approaches. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "WSSS approach which leverages a single pixel-to-segment contrastive learning",
            "review": "Summary:\nThis paper talks about a novel weakly-supervised semantic segmentation (WSSS) approach which leverages a single pixel-to-segment contrastive learning formulation. The key idea is to map each pixel into a point in the feature space so that the pixels in the same semantic categories are embedded closely. It is interesting to note that they have also incorporated the analysis of unlabeled pixels across the images to harvest their patterns/clusters for better discrimination.\n\nPros:\n- Motivation was well described.\n- It is interesting to see that four different types of pixel-to-segment (where same segmentation entities were sometimes regarded as different categories) relationships were leveraged in a combined manner to eventually pull up the performance.\n- Experiments are reasonably carried out both qualitatively and quantitatively.\n\nCons/Questions:\n- Would there be a reasonable explanation of why a big performance gain was acquired for the \"labeled points\" case while the jump was relatively small on other weak supervision cases (image tags, bounding boxes, scribbles)?\n- A paper by Sun et al. (Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation, ECCV 2020) also claims that their approach is novel in that they make use of the intra-image information which is somewhat similar to the proposed approach. A paper by Fan et al. (Learning Integral Objects With Intra-Class Discriminator for Weakly-Supervised Semantic Segmentation, CVPR 2020) seems highly relevant to the proposed approach, especially with the CAM-driven WSSS approaches. \nSince these recent papers have not been included in the reference of the submitted manuscript, it would be interesting to elaborate on how the proposed approach is unique/strong when compared.\n- For Table 2, what is the accuracy measure for the numbers shown?\n- It is hard to tell how the lambda values were chosen. (Table 1)\n- Some descriptions/explanations are rather redundant and verbose which makes it hard to read.\n\nTypo:\nIn Section 1, \"have have\"  --> \"have\"",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Universal Weakly Supervised Segmentation by Pixel-to-Segment Contrastive Learning",
            "review": "In this paper, the authors proposed a metric learning-based semi-supervised semantic segmentation approach. In the proposed method, unlike the conventional semantic segmentation scheme that cast semantic segmentation as pixel-wise classification, they formulate semantic segmentation as pixel-segment contrastive learning. To that end, the authors introduced different positive and negative samples mining mechanisms such as low-level image similarity, semantic annotation, semantic co-occurrence, and feature similarity. Furthermore, the proposed method leverage unlabeled data in discriminative feature learning both within and across images. The validity of the proposed method is demonstrated on Pascal Voc and Dense Pose benchmark datasets.\n\n##########################################################################################\n\n*Strength:Â The formulation of pixel-to-segment based contrastive learning is intriguing. In addition to that, the authors introduced a new insight into collecting positive and negative samples that would be leveraged in contrastive learning. Moreover, the samples involve pixels that come from both intra and inter images.\n\n\n#################################################################################\n\n*Weakness:- The sub-modules used in the proposed approaches are adopted from existing methods thus there is no enough novelty in there.\n-The resulting improvement achieved is impressive however the work lacks theoretical novelty.\n\nQuestion: As some of the semantic relationships are basically generating pseudo-labels, for example, Feature Affinity. Have you conducted any experimental analysis to assess the impact of accumulated error that comes from these Pseudo labels?\n\n######################################################################################\n\n*Reason for score:\nThe proposed work is more of engineering, and it does not have any theoretical novelty; however, formulating semantic segmentation in a contrastive learning context is interesting. Furthermore, the authors demonstrate the effectiveness of the proposed method by showing improvements over the state of the art methods. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Paper review from AnonReviewer3",
            "review": "Summary:\n\nThe paper proposes a unified framework for weakly-supervised semantic segmentation that can take various types of weak labels as the input, e.g., points, scribbles, boxes, image tags. The authors formulate it as a contrastive learning framework by considering pixel-to-segment relationships, i.e., for each pixel, finding positive and negative segments to perform contrastive learning objectives. Specifically, the paper introduces four types of relationships between pixels and segments, i.e., image similarity within the image, semantic relationship, semantic co-occurrence, and feature affinity across images. In experiments, results with various weak labels show SOTA performance on the PASCAL and DensePose datasets.\n\nPros:\n\nThe paper is well written and is easy to follow. The proposed unified framework using the idea of pixel-to-segment contrastive learning is interesting for the weakly-supervised semantic segmentation task. \n\nThe proposed four types of pixel-to-segment relationships seem mostly reasonable and effective for different types of weak label inputs.\n\nExtensive experiments are conducted to demonstrate the effectiveness of the proposed framework and show strong performance on the PASCAL and DensePose datasets.\n\nCons:\n\nAlthough using pixel-to-segment contrastive learning is interesting for weakly-supervised semantic segmentation, the technical contribution is a bit limited as it mostly derives from the recent work in Hwang et al., 2019.\n\nIt is not clear to fully understand the effectiveness of the introduced four types of relationships. For example, for semantic co-occurrence, it is doubtful to form positive pairs simply based on the co-occurrence, as the features in two images could be very different even they share at least one same label. This situation could be more significant if performing on more challenging datasets that contain diverse scenes and more categories, e.g., COCO, ADE20K. The authors should make comments on this or provide more analysis for reasoning this design choice, e.g., one easy thing to consider could be weighting this relationship based on the co-occurrence rate.\n\nIt appears that feature affinity is less effective or not used in some settings. Although the authors explain the reason in the appendix (due to noisy label propagation), it may not be a principal way to integrate this feature affinity into any dataset. Moreover, Table 1 shows different configurations for different label types, and it could also vary across different datasets. Although there are ablation studies provided in Table 5 and 6 of the appendix, it is difficult to draw conclusions on how to choose the proper weights. In this way, it makes the practical usage harder to scale up to more challenging datasets.\n\nAnother concern is the motivation and usefulness of the unified framework. In the literature, there exist specific frameworks optimized for different types of weak labels. Previous frameworks could not use all the weak labels at the same time, which is on the contrary the advantage of the proposed method. Therefore, it is of great interest to see whether the method can simultaneously leverage different weak labels and achieve better performance, e.g., using image tags + boxes against only boxes.\n\nOverall, the paper presents an interesting and effective framework. I would like to hear the feedback from the authors about the above-raised points and may update the rating (my current rating is more like a borderline).\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}