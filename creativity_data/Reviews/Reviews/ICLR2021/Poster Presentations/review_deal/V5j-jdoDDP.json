{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper combines considers the task of finding a minimal set of inputs that explain predictions of trained neural models. The authors propose a method that they refer to as \"scaling symbolic methods using gradients\" (SMUG). This method use integrated gradients methods to score first-layer neurons on the degree to which they influence the prediction and then produces and solve an SMT problem (restricted to first-layer activations) that finds the minimal mask that changes these influential neurons. \n\nReviewers had somewhat mixed perspectives on this submission. All reviewers were broadly in agreement that the paper is clearly written and presents an interesting combination of symbolic (i.e. SMT-based) and gradient-based methods for model explanation. R2 questions the need for sparsity (and therefore the SMT component) in model explanations, and R3 similarly notes that SMUG does not necessarily rely on SMT at all. That said, no reviewers raise major concerns with the quality of exposition, experimental evaluation, or the level of technical contributions in this work. The metareviewer is inclined to say that this work is above the bar for acceptance, and represents a reasonable approach to integrating SMT-based and gradient-based methods for model explanation."
    },
    "Reviews": [
        {
            "title": "Interesting and noval (AFAICT) combination of integrated gradients and SMT that leverages strengths of each.  Some choices need more justification and explanation.",
            "review": "## Summary\n\nThis paper presents a method to encode the minimal input feature discovery problem -- finding the minimal set of features in a input that is necessary for a prediction -- into a form that can is amenable to satisfiability modulo theory (SMT) solvers.  In particular they first use the integrated gradients methods to score first-layer neurons on the degree to which they influence the prediction.  Then, they produce and solve an SMT problem that finds the minimal mask that changes these influential neurons.  They demonstrate their approach on several problems.\n\n## Review\n\nOverall I thought this was an interesting paper with practical utility.\n\n- The formulation is interested and is a novel balance of quite different methodologies with useful results\n- The paper is clear and fairly well written, but some higher level intuition about the approach would help\n- I'd like to see some more justification for focus on the first layer, and experiments (described below)\n\nIn section 3.2 you mention that you use IG to \"score the neurons in order of relevance by treating the first layer activations as an input to the subsequent network\".    It's not clear to me whether the $d$ in the function $F: R^{a\\times b \\times c} \\to [0, 1]^d$ is the set of all nodes in the neural network or just the first layer or just the final layer?   It seems the latter is the case, based on Equation 2.\n\nMore generally, it's not clear to me what privileges the first layer in this work (Eq 2).  My understanding is that\n1. simply that restricting attention to the first layer allows SMT to be applicable\n2. You use IG to integrates information from all layers, and by restricting Eq 2 to $D^k$ you are effectively combining both methods\n\nThis leads to an experimental question: do your explanations improve if you include more than one layer?  This seems like something that is easily testable, at least on small examples.\n\nWriting wise, some of the terms could me more clearly defined.  For instance in the definition of $F$ above, I am left guessing as to what what $a$, $b$, $c$ and $d$ are, and assume they are simply place holders.  Similarly, sometimes we have $N_\\theta(x)$ and sometimes $N_\\theta(X)$.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting work, but the need for it is unclear",
            "review": "This paper addresses the question of identifying which input features are most important for a neural network's decision. To do so, it frames the problem as an SMT problem that seeks to select the best input features, without changing the state of the first layer too much. The paper shows experiments, primarily on image classification, and also examples of how the approach may be applied to text classification.\n\nThere are a couple of things that the paper combines in its final work: (a) using integrated gradients to score the first layer nodes, (b) restricting the search to only the top-k layer one neurons, and (c) applying SMT to find the subset among them that best preserves the layer 1 activations. The experiments do a good job of comparing the contribution of these components.\n\nHowever, from the experiments, it looks like the third step (i.e. SMT) is not really necessary, both from the quantitative and qualitative results. The paper argues in the paragraph titled SMUG vs SMUG_{base} that the latter does not provide sparse input features. It is not clear why sparsity is a desirable quality here. We are looking for image regions that best contribute to the output, in which case smoothness in the regions may even be preferred over sparse explanations that pick out specific pixels. It would be good to clarify this.\n\nThe paper claims that it is not a good idea to use an SMT based explanation that focuses on the final layer. The complexity argument makes sense but could perhaps be mitigated by an extension of the top-k strategy, perhaps. But the argument that the masked inputs are out of training distribution is not mitigated by the proposed approach. If the masked inputs are out of distribution for the full network, then certainly they are out of distribution for the layer one activations too (eq 2). Is the out-of-distribution issue really a problem, and if so, why doesn't it affect the first layer?\n\nThe SMT problems in (2) and (3) ask for a mask such that for every node in the k selected ones, the first layer activation with masked inputs is more than a scaled version of the first layer activation for the original input. This one-sided inequality seems to be tied to the fact that the experiments use ReLU activations. For example, if an activation for a certain neuron is highly negative, and we use a different activation function (say tanh), then we would want a similarly negative output for the masked inputs too. It may be worth mentioning this somewhere (maybe a footnote).\n\nThe experiments on images seem interesting (with the caveat about the need for SMT at all). But the experiments with text only show examples, which makes it only anecdotal. It would be interesting to compare to the results of crowd sourcing experiments where the most important words are chosen, or perhaps asking turkers to pick from the words selected by the proposed method and other interpretability methods (e.g. HotFlip, etc).\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting idea about using IG for fast mask generation",
            "review": "This paper provides an interesting pos-hoc explanation method to identify relevant features in an input that may inform a trained neural model's prediction. The task is to identify a binary mask over input image/text such that the masked input yields almost similar prediction as original input. The author formulates this as an SMT solver task, but instead of making sure that the output prediction is similar (which involve multiple time consuming pass over potentially huge networks), they make sure that high influential neurons in first layer of the network are still activated. This provides a less time consuming way to evaluate invariance of masked input.\n\nThe evaluation is done on multiple datasets - ImageNet, MNIST and Beer Reviews. The authors compare against previous continuous saliency baselines (IG and GradCAM) and full SMT solver method SIS, in addition to ground truth annotations for bounding boxes. They find that their method, called SMUG, is better performing in terms of LSC metric (which measure the log ratio of percentage of pixels preserved vs confidence in ground truth prediction). They also do some qualitative analysis and found that SMUG tend to produce low area masks. They do not perform any systematic human study to evaluate their method.\n\nThe paper as written is quite clear and I was able to parse the information with reasonable ease. \n\nAs it is, I will recommend acceptance for the paper. But I believe addressing following comments will make this paper better.\n\nQuestions/Comments:\n1. The LSC metric is combines the two quantities that don't have any direct scaling relation with each other - area of box and confidence in prediction. For example, going from 0.5 to 0.6 is more important than going from 0.8 to 0.9 in terms of confidence. The same cannot be said for the area. Putting the two together hides information necessary for comparison. For example, are the low values for IG mainly because of large bounding boxes ? I would suggest presenting both results separately along with LSC.\n\n2. A proxy for human study would be to measure the overlap of SMUG results with provided bounding boxes.\n\n3. Why does bilinear interpolation not move data out of distribution ? For example, focusing on face of cat as bounding box and then blowing up should clearly put it OOD ? Am I missing something here ?\n\n4. I am not clear on why restricting your analysis to top-k influential neurons is correct. What if the masked image activate the non-influential neurons -- one see no reason why it won't change the prediction. The IG values are only true for the original image. For example, say for original image, the set of influential neurons is IF and non-influential ones are NIF. If the SMUG masked image activates all of IF neurons and only 10% of NIF neurons, we can get completely predictions. And vice versa. I would suggest running an experiment (for even a small task) where all neuron values are considered and see what the behavior is. (If you have done this experiment, please point me to the relevant section in the paper -- I can't seem to find it).\n\n5. While they are not pos-hoc methods, following paper also try to learn masks as form of interpretation. Please consider citing them -\nhttps://arxiv.org/pdf/1802.07814.pdf , https://arxiv.org/abs/1606.04155, https://www.aclweb.org/anthology/P19-1284v1.pdf, https://arxiv.org/abs/2005.00115, https://arxiv.org/abs/2004.14992\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Incremental improvement, paper title and pitch is a bit misleading",
            "review": "Summary: This paper improves the Integrated Gradient (IG) based model explanations by picking the top-k activated neurons in the first layer and choosing a subset of inputs making sure top-k activated neurons still active enough according to a certain threshold. \n\nI appreciate the authors' contribution to improving IG, but feel certain claims are inappropriate. I hope the authors could help to clarify and correct any misunderstandings I may have. \n\nAlthough the paper title suggests scaling symbolic methods (e.g. SMT-based approaches), the proposed approach SMUG does not necessarily rely on SMT at all. Since ReLU is not considered by SMUG, integer programming (for encoding whether an input dimension is selected) should be sufficient. The way of scaling symbolic methods appears to be simply \"avoid using them\". Also, it is unfair to blame that SMT-based approaches for neural network verification are not scalable while SMUG could handle much larger networks, because SMUG really solves a _different_ problem. \n\n\nQuestions:\nQ1: The authors argue \"From Table-1, we observe that SMUG and SMUGbase achieve a significantly better score (−1.26 and −1.23 resp.) compared to IG (−0.34).\"  However, IG actually achieves -0.29, which is more closer to the GroundTruth (-0.34). Does that imply IG is actually better?\n\nQ2: In figure-5, the mask achieves fairly low confidence (e.g. less than 0.7 for most examples). Why is that?\nIs it a fundamental weakness even for full SMT encoding?  Furthermore, suppose scalability is not an issue, would SMUG always behave worse than full SMT encoding (thus suffer from the same weakness)?\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}