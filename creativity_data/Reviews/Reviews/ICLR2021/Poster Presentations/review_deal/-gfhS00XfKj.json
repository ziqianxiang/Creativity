{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper shows that transformer models can be used to learn certain advanced mathematical concepts such as the local stability of differential equations. Reviewers found this surprising and useful for engineers, and the evaluation was adequate. They also felt that it opens the doors to similar studies on other aspects of mathematics."
    },
    "Reviews": [
        {
            "title": "Clear, well-executed, interesting paper",
            "review": "This paper shows that transformer models can be used to accurately learn advanced mathematical computations from millions of examples.  The problems are drawn from the fields of differential equations and control theory.  The selected problems are ones that are solvable using known algorithms; however, these algorithms involve a sequence of advanced mathematical operations (e.g., differentiation, calculating the rank of a matrix, calculating the eigenvalues of a matrix, etc), for which no known simple shortcuts exist. For the experiments in this paper, for each problem a large number (50 million) of training examples are randomly generated, and are then used to train a transformer model.  Across these problems, the paper shows that the neural network is able to solve these problems at high accuracy (96-99.7% accuracy).\n\nStrengths\n- The paper ask a well-motivated question regarding whether neural networks are able to learn complex mathematical operations from examples.\n- The paper is clearly written, and the experimental rigor/quality appears quite high.\n- The empirical results are quite intriguing, and raises many interesting questions for future research.  For example, (1) how is a transformer model managing to attain such high accuracy on these problems, (2) what other complicated mathematical problems might be similarly learnable, (3) what are the practical implications to real systems of these results.\n- The paper does a good job considering the various potential counterarguments to its conclusions in the discussion section (Section 5.4).  For example, the paper argues convincingly that (1) it’s unlikely the model is exploiting some trivial distinction between the positive vs negative examples because the examples are sampled randomly, and that (2) it’s unlikely the model is interpolating between solutions because the problem space is so much larger than the training set (and because small models which would be unable to memorize the training set also perform well).\n\n Weaknesses\n- I would have appreciated more of a discussion about the computational cost of solving these problems mathematically vs. solving them with a neural network.  What is the computational complexity (Big-O) of each of the known mathematical algorithms for solving these problems?  Are there large computational savings from using a neural network?  What are the practical implications of the results shown in this paper?\n- I think including a few more baselines would have been useful.  Also, a brief description of the FastText model would make the paper more self-contained.   One question: Why is the FastText model in Section 5.1 only trained with 2 million examples, while the transformer model is trained with 50 million examples?\n- In the current experiments, the test set is drawn from the same exact (random) distribution as the training set.  I was very curious whether the model would have been able to attain high test-time accuracy, had the test examples been drawn from a different distribution.  In particular, I’d be curious how difficult it would be to construct a test distribution on which the current model performs terribly.  This line of questioning would be able to start better answering whether the model is solving the problem in a way that truly generalizes.\n- I think the paper could be strengthened by adding additional error analysis to try to better understand the errors made by the transformer model.\n- The paper says “training is performed on 8 V100 GPUs with float16 operations”: It would have been nice to hear more about the training process: For example, low long did training take for the various problems, and how was training distributed across the GPUs?\n- I would have appreciated more of a discussion about the broader implications and significance of these results.\n\nOverall, I thought the paper was very interesting and well executed, and I think it would make a very nice addition to ICLR 2021.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Really neat new dataset and application ",
            "review": "=Quality=\nHigh: well executed and motivated\n\n=Clarity=\nWell-situated wrt to related work.  Baseline needs to be explained more (see below).\n\n=Originality=\nThe ML method is standard. The novelty is in setting up the datasets and evaluation metrics. Doing was technically complex. The datasets very valuable and will hopefully be open-sourced.\n\n=Significance=\nThis paper demonstrates that neural networks are surpisingly good at the task of predicting certain properties of differential systems, such as their stability. This is a neat result and is sufficient for publication. However, the paper would have more impact if there was a concrete proof of concept of how such a tool could be used to improve the lives of practioners.\n\n=Motivation/Introduction=\nI agree with you that it is very impressive that neural networks can nearly solve these tasks. It would be helpful if you devoted more of the exposition to explaining how your classifiers could be used by practitioners to improve their workflows. Are there engineering applications, for example,  where the classifier could be used to quickly screen proposed systems?\n\nAlso, I'd like to better understand what the novel capability of your tool is. Is it faster than numerical methods for verifying these properties? More accurate? Applicable in situations where symbolic manipulation is impossible?\n\n=Predicting Control feedback matrices=\nI found this section very cool and encouraging for future work! I'd mention it in the intro more.\n\n\n=Baseline classifier=\nMy primary hesitation with the paper is that there is not enough justification for why your baseline is sufficient. \n\nYou need to provide far more details about the FastText baseline. Describing the name of the software package is insufficient. What is the actual model? \n\n\"Such high performances over difficult mathematical tasks may come as a surprise, and one\nmight wonder whether the model is exploiting some defect in the dataset, or some trivial\nproperty of the problems that would allow an easy way to correct solutions. We believe\nthis is very unlikely...because a trivial solution would be found by the text classification tool we use as a baseline.\"\n\nThis argument is weak without an explanation of what the baseline model is and what its inductive biases are.\n\n\nAre there no heuristics from the application community that would serve as baselines? \n\n\nIn the discussion, you mention in passing that \"providing at train time intermediate results that would help a human calculator (frequencies for PDE, or Jacobians for stability) does not improve accuracy.\" It seems to me that a baseline method would be a simple machine learning model on top of some hand-crafted features of these intermediate results.\n\n\n=Discussion section=\n\"in some of our problems, even a model with one layer and 64 dimensions\nobtains a high accuracy, and such a small model would never be able to memorize that\nmany examples.\"\nEither make this precise or remove it. At first glance, it seems to be that 64 dimensions has a lot of capacity. For example, 2^64 is much bigger than the size of your dataset.\n\n\n=Open Sourcing=\nWill you be able to open-source the datasets? Doing so would considerably increase the future impact of your work, as it would provide a benchmark for future ML methods.\n\n=Evaluation set=\nIt would be cool if you could have a couple of anecdotes of applying your classifier to famous equations from papers, particularly ones where the derivations to prove stability, for example, were quite tedious. You argue that the test set is representative, since it is uniformly sampled, but are the equations of interest to the community in some corner of this space?\n\n=Analysis/interpretation=\n\nDo the attention patterns of the transformer reveal anything interesting?\n\nWhat seems to characterize the equations that the model makes mistakes on?\n\nCan you use your model to get  per-equation embeddings? Do they reveal interesting cluster structure in the data?\n\n*** After reading the authors' responses ***\nI have raised my score to a 7. I felt that some of the key questions, e.g. regarding generalization to mathematical expressions that are qualitatively different than the training data,  were answered well. This paper should not be reviewed as being methods-driven. It's about demonstrating a new way that deep learning could be transformative for engineering, by allowing engineers to screen proposed designs for stability, etc.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Lack of methodological contribution",
            "review": "This paper empirically demonstrated the effectiveness of neural networks for learning to predict different mathematical properties of dynamical systems, which achieve high accuracy on synthetic datasets generated by the authors.\n\n\nPros:\n+ the paper is clearly written and easy to follow\n+ the dataset seems to be carefully generated and is large.\n\nCons:\n- The authors do not clearly state their methodology, including the concrete architecture of the transformer-based model, and the training loss for optimizing the model. As shown in the experiments, the accuracy of the proposed model is much higher than the baseline, but it is not clear what the major reason is, and why.\n- As the dataset contains about 50 million samples, and only 10000 of them are held out for test and validation, which means the training dataset contains sufficient data and the result could just be overfitting. Besides, the authors do not describe clearly how they generate the dataset and what is the problem distribution. For some distribution (e.g., those with smaller variance), maybe 50 million is large enough and there won't be a generalization issue. As a well-known fact that neural network has universal approximation ability, it is not surprising that it can learn to predict the mathematical properties given enough data. It will be better if the authors could show a '#training sample VS test accuracy' curve to show how the method behaves differently given different numbers of training samples.\n\nOverall this paper does not have enough technical contributions, so I vote for a clear reject.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review of Transformers for differential systems",
            "review": "This paper investigates the use of deep learning models, and specifically transformers, to learn mathematical properties of differential systems. Authors tackle three problems:\n\n* Local stability: where the goal is predicting the stability of a given system at a given point, similar to Spectral Mapping Theorem.\n* Control theory: where the goal is predicting controllability and computing the control feedback matrix as in Kalman condition.\n* Stability of PDEs using Fourier transform: where the goal is to predict the existence and stability of a PDE given its differential operator.\n\nOverall, this paper is well written and tackles an intersting problem with potential useful insights. I believe it can be improved by making the discussion more rigorous:\n\n1. How general are the class of functions considered in each problem? For example, you generate random functions by sampling unary- binary trees. Does this give the guarantee that the majority of solutions for each of three problems can learned by deep learning methods?\n\n2. How this work compares to previous ones such as (Lample and Charton 2020) that study learning symbolic mathematics using deep learning? Any distinct insight when investigating numerical and differential systems?\n\n3. It is useful to see if generalizability of learned mathematical computation can be assessed by experiments, where training datasets are generated using some class of functions, and they are tested on a separated class of functions. Are such experiments feasible using unary- binary trees?\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}