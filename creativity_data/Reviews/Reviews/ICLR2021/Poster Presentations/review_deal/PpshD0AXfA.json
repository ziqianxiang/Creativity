{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "Nice ideas with practical advantages.  "
    },
    "Reviews": [
        {
            "title": "Interesting flow-based generative model for time-series",
            "review": "The authors propose a flow generative model for time-series in the Fourier domain. The time-series data are first converted to the Fourier domain. Instead of the affine coupling layer previously presented in literature, the authors have designed a frequency domain version of the same.\n\nPros:\n1. The paper is well-written and is largely easy to follow. \n2. Operating in the Fourier domain as well the affine coupling layer proposed in the paper are interesting novel contributions in the context of designing flow models for time-series.\n3. Based on the experiments presented, Fourier Flow is surprisingly effective when compared to RealNVP, and also slightly outperforms other methods like TimeGAN. \n\nCons:\n1. The authors should try to explain what it is about operating in the Fourier domain causes the improvements in prediction error. As the Fourier transform is invertible, I would imagine that the novel affine coupling layer has a larger role to play in this. This is also what the authors seem to suggest in Section 4.3. It would be great if the authors could add a baseline experiment operating in the time domain with the proposed affine layer (Equation (8)). \n2. In terms of the explanations in the paper, a lot of space has been devoted to explain the Fourier transform, its properties and how to compute it efficiently. While it is done well, I feel these are very well known facts. For the determinant of the Fourier matrix, we can just use the fact that it is unitary and we immediately have |det(W)| = 1. Instead, additional experiments analysing the experiments could be more useful, such as understanding the role of network depth etc. for this particular method, or additional t-SNE plots for the remaining datasets. \n3. As in all papers such as this one, it is not easy to see how the baseline approaches have been trained and how well the hyperparameters have been tuned. \n\nBased on the author response, I am willing to increase my rating for this paper. \n\nUPDATE AFTER AUTHOR RESPONSE:\n\nThe authors have addressed all my queries and made the changes that I requested. I am increasing my rating reflecting this. The paper has novelty, good experiments and improved performance. I would like to see the paper accepted. \n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The Fourier Flow approach is novel and the paper is well-written.",
            "review": "Pros:\n+ This paper proposed a novel generative model named Fourier flow for modeling time series data. The model incorporates Fourier transformation into normalizing flows and considers the time series on the frequency domain, rather than the time domain. Such a combination looks interesting and novel. I think this paper will have some impact on the field of normalizing flows and time series analysis.\n+ The writing of this paper looks good, which makes it easy to follow.\n\nCons:\n- The empirical study is somewhat weak. The experimental results are not very impressive in the paper. The improvement of the performance seems to be marginal. Only one real-world dataset is considered. Please give a short description of the dataset. As the proposed method is for the general time series, the authors are suggested to evaluate their method on more datasets, especially from various fields. Besides, please give a definition of the metric predictive score. \n- The paper mentions that the computational cost is no larger than some SOTAmethods. It would be better to give a discussion on the complexities of your method and the SOTAs. It would also be more convincing if the authors can show the running time in the experiment.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Simple but powerful new convolutional flow architecture with impressive performance on time series problems",
            "review": "Summary:\nThe paper introduces a new convolutional flow architecture that uses the DFT to convert the generated time series to the frequency domain. Convolutions are performed by multiplication in the frequency domain through a spectral affine layer that transform the even or odd part of the signal using a data dependent filter. The resulting time-domain convolution has input dependent weights, an interesting and original approach clearly different from other convolutional flow such as [1]. \n\nRelevance:\nTime series generative modeling has a wide range of crucial applications in fields ranging from medicine to finance. The new method shows very promising performance and it has the potential to become a state-of-the-art method for time series generation.\n\nOriginality:\nThe use of the DFT and spectral affine layers is original in the context of normalizing flows. Importantly, the DFT is very suitable for flows since it is an isometry and has therefore a trivial Jacobin. The use of input dependent convolutions is very interesting even in the context of regular ConvNet architectures. \n\nScientific quality:\nThe method is clearly presented and well motivated. The experiment section cover a decently large set of experiments and performance are compared with a very large number of state-of-the-art baselines.\n\nPros:\n- Original new architecture well motivated for time series applications\n- Rigorous experiments with multiple relevant baselines\n- Very promising experimental results\n\nCons:\n- It would have been useful to see a wider range of real world applications\n\nMinor points:\n- I would like to have a figure with the time domain sampled generated by the FF and the other baselines. It is strange to see a generative modeling paper without a figure showing the generated samples.\n\nReferences:\n[1] Karami, Mahdi, et al. \"Invertible convolutional flow.\" Advances in Neural Information Processing Systems. 2019.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A Time Series Flow-based Generative Model using DFT",
            "review": "### Summary\n\nThe paper presents Fourier Flows (FF), which is a time series generative model in the frequency domain. It shows that the Jacobian of the DFT is equal to 1, which means that DFT does not add too much overhead. The results on the real-world datasets are encouraging and expected because the predictive results mainly rely on the overall trend of the time series. By analysis in the frequency domain, we usually can capture the main trend accurately. The main concerns for the paper are the computational overhead on the proposed algorithm on non-periodic, long, and variable-length time series.\n\n\n\n### Feedback\n\n* The strongest point of the paper is when the authors show that the Jacobian of the DFT matrix is 1. Thus, taking DFT does not make the generative model much more complex.\n* The other advantage of FF can be in handling missing values. Unfortunately, the authors do not expand on this aspect.\n* The main issue with the FF is its computational complexity. The authors write: \"To guarantee a lossless recovery of the time-series x via inverse DFT, we ensure that $N\\geq T$.\" This means FF is impractical for long time series and quite inefficient in handling variable-length time series.\n* Moreover, Fourier transforms are mainly intended for periodic signals and do not provide concise representations of non-stationary signals. This inefficiency is why Wavelets and DWT have been invented. The synthetic data generation model gives an unfair advantage to FF because it uses periodic signals.\n* The authors' description for Eq. (8) is misleading. $\\mathbf{H}$ and $\\mathbf{h}$ are not fixed parameters, they are functions of the input. Thus, the model is a form of self-attention. I hope that the authors have done the training correctly. \n*The authors criticize GANs for memorization but never show that FFs do not memorize data points.\n* The choice of generating H using a BiRNN on only the $Im(X)$ is puzzling. Why didn't the authors use complex-valued RNNs to operate on both real and imaginary parts and not lose the phase information?\n* On page 2, the authors discuss a parametric model for T, but they never elaborate further on it.\n* \"where $x_-$ signifies the reversed version of $x$\": the authors should clarify that this is the reflection with respect to $x=0$ axis. Otherwise, we should add a time-shift operation too.\n\n----\n### Post-Response Update\nI don't think the authors have answered my second set of questions. While there are some doubts remaining in the paper, the idea looks fine. Although, I think a new paper with DWT will outperform this approach soon. I do not change my vote at this time.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}