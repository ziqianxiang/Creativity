{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This work provides additional insights into a class of generative models that is rapidly gaining traction, and extends it by potentially providing a faster sampling mechanism, as well as a way to meaningfully interpolate between samples (an ability which adversarial models, currently the most popular class of generative models, also have). The revised manuscript includes an extension to discrete data, which could potentially amplify the impact of this work. The authors have also run additional experiments in response to the reviewers' comments.\n\nReviewer 1 raised several concerns about the choice of language (i.e. referring to the proposed model as a diffusion model, and the precise meaning of 'implicit' in the context of generative models). This is a fair point, as the authors introduce changes that affect the Markovian nature of the \"diffusion\" process, and a diffusion process is supposed to be Markovian by definition.\n\nHowever, I think there is something to be said for the authors' argument of using the word 'diffusion' to clearly link this work to the prior work on which it is based. Given that technically speaking, the original DDPM work already 'abuses' the term to refer to a discrete-time process, it is difficult to argue compellingly that 'diffusion' should not feature in the name of the proposed model. Referring to 'non-Markovian diffusion processes' however seems more problematic, as this is a direct contradiction. If the authors wish to use this phrase, adding a few sentences to the introduction that justify this use would be helpful, and personally I feel this would be sufficient to address the issue (I noted that Section 4.1 already acknowledges that the forward process is no longer a diffusion). Plenty of work in our field abuses notation and this is justified simply with the phrase \"with (slight) abuse of notation...\"; I don't think this would be any different.\n\nReviewer 1 is technically correct that 'stochastic' is an absolute adjective, i.e. something can only be stochastic or deterministic, there is nothing in between, and there are no degrees/levels of stochasticity or determinism. In practice however, it is quite often used in a comparative sense, and I believe I have in fact been guilty of this myself! I do not feel that it causes any ambiguity in this case. Indeed, the phrase 'degree of stochasticity' seems to be in relatively common use in literature. While there may be more correct terms to use, I subscribe to the descriptivist view on language, and I do not think the comparative use of 'stochastic' is a major issue here. The alternatives I can think of seem potentially more cumbersome (e.g. I wager that 'more/less entropic' would be more poorly understood than 'more/less stochastic'). Still, I recommend that the authors consider potential alternatives in the future, to avoid any confusion.\n\nOverall, I think the reviewers' major concerns have been addressed in the revised manuscript. Given that all reviewers consider the idea worthwhile, I will join them in recommending acceptance."
    },
    "Reviews": [
        {
            "title": "Keen insights, good results",
            "review": "Summary:\n\nThis paper proposes a change to the recently popular diffusion models, motivated by increasing the speed of sampling. This is accomplished by changing the “forward” process which adds noise to the data. In the original diffusion models, this forward process is a Markov process whose marginals and conditionals can be computed efficiently in closed form. This paper proposes to replace this Markov forward process with a non-markovian process that is designed to have the same marginals. The generative model, in this case, changes such that to predict the next step in the process, the model must first predict the “clean” sample at the end of the chain which is then used to give an estimate for the next step in the chain. \n\nIntriguingly, the objective for training this new generative model is identical to training a standard diffusion model. Thus, the models differ only at sampling time. Under the new interpretation, we can sample from a family of models after training. This family can be tuned to increase the speed of sampling, at the cost of some sample quality. Inside this family, there also exists an implicit generative model which can be sampled from in a more deterministic fashion than the other members -- hence the name of the paper. \n\nThe authors present a number of image generation experiments and study the impact of the sampling parameters on sample quality. They find that in settings where the efficiency of sampling is greater than the original diffusion model, the proposed approach achieves higher sample quality -- although never as high as the original diffusion model. \n\nBecause the model can be sampled in a deterministic fashion, the authors note that fixing the latent variables during sampling results in consistent samples. This allows a much more controlled generation compared to the original diffusion model. \n\n\nStrong areas:\n\nI quite enjoyed this paper. These diffusion models have gained considerable attention and this work addresses what is likely their largest issue -- the slow speed of sampling. Most interesting to me is these new ideas can be applied to the original diffusion models without retraining. \n\nI find that this work provides more insight into how these diffusion models work and which choices in the original presentation are important for their performance and which (like the inference process) can be changed. These are important insights and should be impactful for further research on this class of models. \n\n\nWeaknesses:\n\nWhile this is a strong paper, there are a few issues in my opinion. I found some of the experimental details difficult to understand. Were all the results presented generated from the same DDIM? Or were the models trained separately for each sampling parameter set? This should be made more clear. \n\nIn section 3.2 you claim some equivalence between the original DDPM objective and the variational bound in your model. This looks like re-weighting the various terms in the objective. In the DDPM work, they discuss the impact of this re-weighting. I would have liked to see a similar discussion here. They found it improved sample quality but decreased likelihood. I would have loved a comparison of the various training procedures but I did not find one. Along the same line, you present no likelihood results. You should be able to generate a lower-bound on likelihood using your model (except for the eta=0 model I believe). I am curious how the various sampling schemes impact likelihood. It is not necessary for the proposed approach to be appealing but would definitely complete the picture. \n\n\nNit-picky issues:\n\nI think the abstract could be a bit more descriptive. You should add some information saying what differs between your approach and standard diffusion models. In reading the abstract, it was not clear to me that using a non-markovian forward process would make sampling faster. This became clear as I read the paper. You could add a little more information to make that clear in the abstract.\n\n\nMy recommendation:\n\nI think this paper was clearly written and proposed a strong contribution to the field of generative modeling. I think the insights presented here give us more understanding of diffusion models and while also improving their sampling speed. I will recommend accepting this paper. \n\nSome questions:\n\nDo you think these same insights could be applied to discrete diffusion models proposed in the original work on non-equilibrium thermodynamics? \n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Very good, clean, paper",
            "review": "Summary : This paper develops a variant (DDIM) of an existing method (DDPM) with the goal of accelerating it greatly while still maintaining performance. The authors are working in the context of a denoising process that runs in the reverse direction to a sequence of steps that each add a small amount of Gaussian noise to the original data. The proposal is to introduce an auxiliary function that breaks the Markov assumption by leaking some information in a controlled way about the training points x0, and then use this auxiliary function as scaffolding to train the actual Markov chain of denoising functions.\n\nThis paper builds on other works in the recent literature and proposes something useful and novel. They propose something relatively down-to-earth and then they methodically analyze the consequences and derive all the mathematical formulas that follow. I feel that the dose of mathematical content is just appropriate for what they set out to do. Less would be too vague, more would be excessive.\n\nThe direction that they are proposing is relevant, contrary to certain other papers that involve a lot of correct equations but don't take us anywhere interesting. In my mind, this is a very good clean paper. \n\nI appreciated the authors taking the time to mention the connection with ODEs, and I thought they would mention Neural ODEs in section 7 as a nod to the recent surge of interest in ODEs in the context of Deep Learning sparked by that paper.\n\nThe only bad things that I could possibly say about this paper would involve comparing it to certain other wildly creative papers, and to say that it's not as innovative or throught-provoking as those papers. And that's not a fair thing to say.\n\nI would like to ask the authors if, with their framework, there is a need to train a completely different epsilon_t for every t=1..T ? I understand these models to be U-Nets, as mentioned in the appendix. I presume that the thing that makes this reasonable is the fact that S < T, and only S different models need to be trained?",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting approach but difficult to disentangle the explicit contributions. ",
            "review": "#### DESCRIPTION \nThis paper consider tweaks to denoising diffusion models, exploring non-Markovian inference models, as well as shorter and possibly deterministic generative trajectories. \n\n#### DISCUSSION\n\nI'm having difficulty placing this work in the correct context, and disentangling exactly what the contributions are. From my understanding of denoising diffusion models (as presented in Sohl-Dickstein et al (2015) and Ho et al (2020)), the following hold:\n\n(i) At test time, the variance of each step of the generative process can be set to a different value than at training time, effectively evaluating a different model than the one that was trained. This is exploited by Ho et al (2020) to remove the weights in the variational lower bound at training time (they effectively set sigma such that the weights are 1 at training time).   \n\n(ii) At test time, it is possible to select a subset of the timesteps used at training time, and generate a corresponding schedule for those selected timesteps, possibly leading to more efficient sample generation at the expense of sample quality.\n\n(iii) Any inference process which satisfies the Markov property (as in Sohl-Dickstein et al or Ho et al) admits the factorization given in eq. (6). \n\nNow, I would have thought the first port of call would be to compare the proposed method in this paper to (i) and (ii). Moreover, while I *think* the choice of q(xt-1 | xt, x0) in eq. (7) indeed means that q(xt | xt-1, x0) =\\= q(xt | xt-1) (i.e. the process which starts at data and ends at noise is indeed non-Markovian), the lack of the comparisons with (i) and (ii) makes it unclear whether this step actually needs to be introduced, and the fact that the parameter sigma appears in both the mean and variance of q(xt | xt-1, x0) ties the mean and variance in a somewhat opaque way. \n\nI'm also a little confused by the choice of language in the paper. Traditionally, a diffusion process describes a continuous-time stochastic process which satisfies the Markov property. 'Denoising diffusion models' stretch the term diffusion to describe a finite discretization of this diffusion process, but explicitly retain the Markov property, and have a clear interpretation as a generative models which iteratively denoises a white noise sample. If you further make the inference process non-Markovian, so that you have a non-continuous, non-Markovian process, does it make sense to persist in using the word diffusion to describe the model? \n\nThis may be a nitpick, but I'm also not sure about the sense in which this model can be described as 'implicit'. The term implicit is typically used to describe generative models which specify the data-generating procedure mechanistically as a series of prescribed operations (possibly stochastic) applied to some given inputs, so that the resulting output distribution is defined 'implicitly' by these generative steps, and *crucially* marginalizing over any associated latent variables is intractable. The 'implicit' model described in this paper is formulated as the deterministic limit of a standard latent variable generative model fit using amortized stochastic variational inference. Recent work has examined normalizing flows as the deterministic limit of a Markovian generative model (e.g. \"Stochastic Normalizing Flows\", Wu et al (2020), \"SurVAE Flows\", Nielsen et al 2020) and indeed, the sentence \"The resulting model becomes an implicit probabilistic model, where samples are generated from latent variables with a fixed procedure.\" from this paper could equally describe a standard normalizing flow, which is certainly not an implicit model. \n\nAs far as the experiments are concerned:\n\n- It seems the takeaway message from section 5.1 is that the proposed model better adapts to evaluation with shorter trajectories when eta is small, and that the original DDPM doesn't fare well with shorter trajectories. The sample quality gets worse the shorter the trajectory (which is expected), but the best results are still given by evaluating the full DDPM model with 1000 steps.   \n\n- In section 5.2, I suppose it's expected that samples generated using different length trajectories from the same starting point are similar given that the generative process likely corresponds to some ODE discretization (as you've mentioned in the conclusion), but it's good to have it tested.   \n\n- In section 5.3, I don't really understand the purpose of interpolations for demonstrating the capabilities of generative models. What exactly do they demonstrate? \n\n#### EXTRA NOTES\n\nWhy are 'joint' and 'marginals' repeatedly placed in quotation marks? \n\n\"The magnitude of σ controls the how stochastic the forward process is.\", \"...the stochasticity of the process\", \"...compared to its less stochastic counterparts\" What does it mean for something to be more or less 'stochastic' than something else? How can 'stochasticity' be used as a quantitative measure?\n\n\"Fenchel Inception Distance\" -> \"Frechet Inception Distance\"\n\n#### CONCLUSION \nOverall, I think fundamental idea of improving the long sampling trajectories of DDPMs is certainly interesting. However, I'm finding it difficult to understand the extent to which the proposed non-Markovian inference process is really necessary i.e. I'd like to see baseline comparison with points (i) and (ii) above. Right now, I'm not able to disentangle which components of the proposed method are actually necessary.  ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}