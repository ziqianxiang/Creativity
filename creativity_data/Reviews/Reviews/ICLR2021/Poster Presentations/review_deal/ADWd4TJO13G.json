{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper addresses lifelong/continual learning (CL) by combining reusable components. The algorithm is based on, updating components, updating how they are combined for a given task and adding new components. \n\nReviewers had concerns about the learning workflow, how it could scale to harder CL streams and how it differs from existing LL/CL work.  They also asked for clarifications about compositionality. They highlighted the experiments as a point of strength.  After the rebuttal, all reviewers found the paper to be above the acceptance bar. "
    },
    "Reviews": [
        {
            "title": "No comparison to previous work, unclear why",
            "review": "### Summary\nThe paper attempts to solve lifelong/continual learning (CL) by building reusable components and learning both the way of combining them and the components themselves. To do this, the authors present a framework of algorithms which is based on three abstract elements which are iterated:\na. Updating the components itself\nb. Updating the way the components are combined (structure) for a given task\nc. Adding new components\n\nThe framework is instantiated as a concrete algorithm in several different ways whose performance is evaluated through extensive experiments.\n\n### Concern\nMy biggest concern regarding the work is lack of comparison with previous CL literature. Authors do a good work listing previous contributions in CL (in Sec. 2), and provide two claims, which, as implied, would make the previous models significantly different from their work:\nA: \"it is unclear what the reusability of these parameters [of previous works] mean\"\nB: \"the way in which parameters are reused is hard-coded into the architecture design\"\n\nA. Many of the previous works (in particular Achille et al. 2018 and Rao et al. 2019) contain a shared sub-model which maps data into a representation which is further processed to predict task-specific labels. The ability to extract structure from data coming from various tasks is, on the level of the objective, the same \"reusable knowledge\" that the authors' work attempts to gather. One could argue that the way previous work learn this knowledge could be improved: to do this, one should compare the new model with the previous ones using the existing objectives which try to assess the level of forward/backward transfer (which, arguably, is an established way of measuring \"reusability of the knowledge\") or by proposing a different metric for quantifying the \"discovery of reusable knowledge\". The work under review does neither.\nB. Authors claim that hard-coded network architecture is an unsatisfactory element of previous work, in particular because it makes it harder \"to learn tasks with high degree of variability\". Deciding which part of the NN-based algorithm is \"architecture\" is fuzzy at best. I believe that the authors' work (in particular \"soft layer ordering\" compositional structure) can also be interpreted as learning a neural network with a fixed architecture, sharing many layers, and placing non-linearities every second layer (see * below). I would like to ask the authors to clarify what formally they mean by \"hard-coding architecture\". Furthermore, the hypothesis of \"methods with hard-coded architecture have a disadvantage at 'hard' tasks\" needs experimental verification, which I found lacking in the paper.\n\n### Smaller statements\n1. The paper is well-written and relatively easy to understand.\n2. The work seems very related to the domain of Neural Architecture Search: I believe a reference to this line of work is warranted.\n3. If I understood correctly, the method is trained on batches of 4 tasks (or are 4 tasks present only in the first batch?) at a time. This is a significant simplification of the classical CL setting where only one task can be observed at a time. I believe a big part of the CL problem is that one never has an access to the level of \"task variability\" and thus needs to trade-off overfitting and underfitting without having access to the meta-task.\n4. The work is missing a clear message: the presented framework is a generalization of some previous methods, but it's far from clear why the algorithms fitting to the framework would be beneficial over the others solving the same problem of CL nor what other benefit does thinking in terms of the proposed framework gives.\n\n### A question\nwhy $\\psi$ and $s_j$ sum to 1 in Sec. 4.1?\n\n### Review summary\nI find the overall method interesting and a potentially advantageous approach to CL. At the same time, despite extensive experiments and a detailed writeup (spilling, a bit unfairly, crucial parts of the work (like an algorithm diagram) into a 10+ page-long appendix), I feel that placing the work in the contemporary CL+NAS literature is inadequate, making it impossible to appreciate the benefits of the work.\n\n*\nLet $x \\in R^d$: a data point, $\\sigma$: a non-linear function, $A_{1, 2}$: activation matrix $\\in R^{d \\times d}$.\n\nA typical, 2-layer network could be described as:\n$$\nf(x) = \\sigma(A_2 \\sigma (A_2 x))\n$$\n\nYour soft layer ordering model is (dropping some indices):\n$$\nf(x) = \\sum_i \\psi_{i,1} m_i \\circ \\sum_j \\psi_{j, 2} m_j(x) =\n$$\n$$\n= \\sum_i \\psi_{1, i} \\sigma \\Big( \\phi_i^T \\times \\big(\\sum_j \\psi_{2, j} \\sigma(\\phi_j^T x)\\big)\\Big) =\n$$$$\n= \\psi_1 \\sigma(\\phi \\psi_2 \\sigma(\\phi x))))\n$$\nWhere $\\phi$ is of shape $k \\times d \\times d$ and $\\psi_1, \\psi_2 \\in R^k$\nIn other words, the proposed model behaves like a neural network with interleaving $d$- and $k$-units-wide hidden layers, with and without non-linearities and some extra weight sharing and broadcasting.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good framework, would be interesting to have more results specific to the compositional property of the model.",
            "review": "The authors propose a new framework for compositional lifelong learning. In the proposed approach, the composition and adaptation parts are separated when a lifelong learner faces a new task: first, learn the best way to compose all existing components for the new task (and train an optional new component if exiting components aren't sufficient to reach a good performance), and only then adapt the components parameters to better fit the new problem. This new framework is validated on extensive experiments, using three composition and 3 adaptation strategies from the literature on 9 datasets. The paper is pleasing to read, each choice is discussed and justified\n\nMy main concern is about the scalability and the resilience to harder streams of tasks. Compositional and dynamic approaches are necessary when tackling complex streams of tasks, for example when having to deal with different modality or a large number of tasks.\nAll experiments in the main paper use relatively short sequences of tasks in which it makes sense to reuse all components on the new tasks since all tasks are strongly related (all coming from the same data set). I would be interested to see the performance of standard continual learning techniques from the literature on the same streams of tasks to demonstrate that there is indeed a gain in using this approach even on standard streams.\nI would also be interested in seeing how sharp the component selection is on each task, is the assimilation step selecting only one or two components per layer or is it blending them all? We could expect a sharp component selection on the compositional dataset (appendix D), which would confirm that the different components are indeed specialized to handle specific properties of the tasks. \n\nMinor questions and remarks:\n- Appendix E.1 mentions that the validation set is only used for selecting whether to keep the new component. How are the hyper-parameters ( $\\tau$, learning rates, number of samples to keep around for ER, $\\lambda$, $T_{init}$, number of assimilation/adaptation epochs, ...) selected?\n- Some papers on dynamic/compositional methods for continual learning should be discussed in the related work [1, 2, 3]\n\n\n[1] Lifelong Learning with Dynamically Expandable Networks. Yoon et. al. [2017]\n\n[2] Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting. Li et. al. [2019]\n\n[3] An Adaptive Random Path Selection Approach for Incremental Learning. Rajasegaran et. al. [2019]\n\nEdit: Upgrade from 5 to 6 after the author's response.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Thorough contribution, which, maybe, lacks a \"cherry on top\".",
            "review": "** Summary **\n\nThe paper proposes a novel approach to lifelong learning, which builds upon the idea of gradually construcing a set of reusable components.\nThrough extensive experiments on different underlying architectures, the authors demonstrate the promise of their approach.\n\n** Strengths **\n\nThe paper addresses a highly relevant problem.\nThe paper provides a very thorough evaluation of the proposed approach in a range of conditions.\nThe paper is very well written and is a pleasure to read.\nIn general, the contribution approaches the ideal when it comes to result reporting, ensuring reproducibility, and the thoroughness of experimental evaluation.\n\n** Weaknesses **\n\nWhile extremely thorough, the experiments are somewhat repetitive. I.e. overall we can confidently say that the method performs well on the selected tasks, but it seems that these experiments do not fully investigate the potential of the proposed architecture in diverse enough conditions.\n\nThe main selling point of the contribution is the ability to acquire compositional problem-solving components, but the qualitative analysis into whether the problem-solving components are actually compositional is very limited. The results given in appendix G and on the figure 3 are not very convincing, in my opinion. Similarly, in appendix D, when the architecture is applied in an intentionally compositional setting, the authors only report performance metrics.\n\nOverall, it remains largely unclear whether the proposed method is truly leveraging compositionality, or is more of an efficient way of constructing an ensemble of classifiers.\n\nNevertheless, I believe that this paper remains above the acceptance threshold, despite these limitations.\n\n** Typos **\n\n\"Qualitatively, we show that the components learned by an algorithm that subscribes our framework correspond to self-contained, reusable functions.\" - \"subscribes\" seems like a typo in this context.\n\n** Questions **\n\n- Intuitively, it seems that using component dropout introduces a conflict with the goal of obtaining disentangled/compositional components.\nI.e. the authors say \"Intermittently bypassing the new component ensures that existing components can compensate for it if it is discarded\", \nbut at the same time it seems that for compositionality, we want different components to be unique and independent of each other. I would like the authors to clarify their reasoning behind using component droupout.\n\n** Conclusion **\n\nThe paper is an extremely thorough and a very polished piece of work, which compensates what it somewhat lacks in \"wow-effect\" with general thoroughness and high quality of experiments, writing, and reporting.\nAfter reading the paper I felt genuinely grateful to authors for putting this work together in such a thorough and thoughtful manner.\n\nOverall, in my opinion, the contribution is above the acceptance threshold.\n\n** Suggestions **\n\nThe paper abruptly ends with no summary or conclusion, which, in my opinion, severely affects its perception. While I understand that\nthis is due to the strict page limit, in my opinion, sacrificing conclusion is not reasonable. It is possible to move of the tables 3 or 4 to the appendix,\nsince they convey the same general message (the message being that the model performs well).\n\nIf the paper is not accepted to publication now, I would suggest moving some of the experimental evaluations tables into appendix and putting more effort into testing the model on qualitatively different tasks. It would be very interesting to see how the model performs on nontrivial problems requiring compositional reasoning,\nand maybe less directly rooted in the visual domain. Even if staying in the visual domain is desirable, there is still room for improvement. For example, maybe would be possible to adapt the model to the RAVEN (https://arxiv.org/abs/1903.02741) dataset (after adapting it to the lifelong-learning setting) or similar tasks.\n\n** Update after rebuttal **\n\nI appreciate that the authors addressed my comments. After reading the authors response and other reviews, I still believe that it is a good paper that should be accepted to the conference.\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review for submission",
            "review": "This paper addresses lifelong learning of compositional structures by proposing a general-purpose framework, which separates the learning process to two stages: combine existing components for assimilation; adapt existing components for accommodation and optionally add new components.\n\nThe strong point is that the approach is general for model architectures and can be combined with different catastrophic forgetting mechanisms. There are many evaluation datasets and settings. Also, it has visualization to analyze the learnt models. The weak point is that the arguments and evaluations do not support the claims very well.\n\nMy recommendation is that this paper is below the acceptance bar.\n\nThe reasons are mainly from concerns for compositional structure learning and catastrophic forgetting evaluation.\n1. The paper does not clearly explain why separating assimilation and accommodation leads to learning compositional structure and components from a machine learning perspective. Even an intuitive explanation or a concrete example may be more helpful.\n2. The evaluation does not directly support that compositional the structure is learnt. The main evaluation metric is the final accuracy, which may tell that the proposed approach works as a good pre-training algorithm for reusable modules, but this does not mean the compositional structure and components are learnt. Though there are visualizations, it still lacks numerical evaluation for this purpose.\n3. If this paper emphasizes ability as a pre-training algorithm, it should compare with other pre-training algorithms.\n4. This paper does not explain why the proposed approach is helpful for catastrophic forgetting.\nThe experiment setting has the first 99 epochs solely for assimilation and the last epoch for adaptation. So a possible explanation is that the proposed approach has 99% less iteration to update the parameters then baselines, hence it better avoids catastrophic forgetting, and just stores task specific parameters. This seems trivial and is not a stand-alone significant contribution.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Excellent paper on lifelong learning",
            "review": "Summary: \n\nThe paper introduces a framework for lifelong learning of compositional structures. The algorithm is loosely inspired by biological learning and consists of two main steps. The step of component selection relies on existing methods that can learn task-specific structure. In the next step (adaptation), the algorithm adapts the knowledge from the previous tasks to the current task and if that is insufficient to solve the task, new components are added. Adaptation step relies on existing methods for adapting the knowledge state given a new task in continual learning (component parameters are updated). Knowledge expansion (adding new components) uses component dropout, a method proposed by the authors which combines pruning and alternating backpropagation steps with and without the potential new component. The proposed method is beneficial in terms of computational complexity in comparison with the standard lifelong learning methods. The authors evaluate the method on three compositional structures and show that it outperforms the baselines. The paper includes visualisation of the learned components, extensive appendix with additional experiments and ablation studies, and a systematic overview of the prior work in learning compositional structures and lifelong learning.\n\nScore justification:\n\nThe paper is exceptionally well-written and rich in terms of experimental results and ablation studies. The proposed algorithm combines existing methods in a novel way and extends them with component dropout. The topics of learning compositional structures and lifelong/continual learning are of high interest to the community. The new procedure (Algorithm 1) balances out the key problems of retaining existing knowledge and expanding it without frequent expensive data revisiting steps. The only concern would be the lack of conclusion and sporadic vague phrasing. Overall the paper is very interesting to read and it should have a strong impact on the research in lifelong learning. \n\nPros: \n\nThe justified parallel between the algorithm and children development research\n\nThe contributions are well-positioned in comparison to the existing work (in the Related work section and throughout the paper)\n\nComputational complexity is discussed\n\nExtensive experiments which show strong results in learning components of an increasing complexity \n\nCode is released for reproducibility\n\nCons:\n\nThe main paper combined with the appendix is quite long for a conference paper\n\nConclusion is missing\n\nFrom the sentence “Our framework separates the learning process into two broad stages:learning how to best combine existing components in order to assimilate a novel problem, and learning how to adapt the set of existing components to accommodate the new problem.” it is unclear how the two stages differ\n\nIn Table 1, you could mention the meaning of the symbols which parametrize the complexities in the caption so that it is possible to better understand the computational complexity analysis without the appendix\n\nQuestions during rebuttal period: \n\nPlease address and clarify the cons above  \n\nTypos: None were found\n",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}