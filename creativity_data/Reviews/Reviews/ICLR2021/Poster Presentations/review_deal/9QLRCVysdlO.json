{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The authors propose techniques to deal with binarization of 3D point clouds and propose EMA and layer wise scale recovery that improve results across the board for PointNet style models.\nAn accept."
    },
    "Reviews": [
        {
            "title": "a good paper but probably not good enough",
            "review": "This paper proposes a method to apply binary networks on point clouds. To my knowledge this is the first time that this is attempted so unquestionably the topic of the paper is interesting. From what the authors show a vanilla BNN (XNOR-Net) applied to point clouds does not give very good results and for this reason the authors identify solutions that boil down to applying a shift and a scaling. This is really my main problem with the paper: the proposed methods are too simple and the accompanying theory does not look to be so convincing in order to theoretically support the contributions which are just a simple shift and scaling. Actually the authors show that one of the variants of their method  can be reduced to average pooling which does not require some sophisticated explanation to convince the reader why it works.\n\nMoreover the proposed learnable layer-wise scaling factor is not new and was previously usedat a) layer-level ( Towards Accurate Binary Convolutional Neural Network, Lin et al, NeurIPS’17) and b) channel-level (XNOR-Net++: Improved Binary Neural Networks, Bulat&Tzimiropoulos, BMVC’19). In fact, the problem itself is known since at least 2016, where in the (XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks, Rastegari etal, ECCV’16) identifies this problem and proposes an analytically-computed scaling factor.\n\nOther issues:\n“even global pooling provides strong recognition performance. However, this practice poses challenges for binarization” – there is no justification provided of why pooling may pose issues for binarization. Avg and max-pooling is used with success in contemporary binary networks. \n\nExisting BNNs “are not readily transferable to point clouds.” – In the paper it is mentioned that this is shown and evaluated in the method section. However, many of the listed methods are not in fact evaluated. This is especially important for methods that also learn to recover the scaling factors.\n\nGiven that for image classification, at least for ResNet the last layer before the linear classifier is a global pooling operation, how does the proposed EMA changes the results when applied to image classification, on a ResNet18 on Imagenet? Are there any improvements measurable in that case too?\n\n“Despite that model binarization has been studied extensively in 2D vision tasks (Krizhevsky et al.,2012; Simonyan & Zisserman, 2014; Szegedy et al., 2015; Girshick et al., 2014; Girshick, 2015;Russakovsky et al., 2015; Wang et al., 2019b)\" – the cited works don’t support the author statement, since none them perform binarization. \n\n$\\textbf{Final Rating}$\n\nBased on the authors' responses during the rebuttal period, I don't believe that the paper makes a sufficient contribution for ICLR. Hence I will stick to my original score.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review for ICLR 2021 submission \"BiPointNet\"",
            "review": "This paper proposes a method for binarization of neural networks of 3d point clouds. Two modules of entropy maximum aggregation and layer-wise scale recovery are proposed to conquer the problems of discrimination loss induced by feature homogenization and scale imbalance, which are caused by model binarization. The authors provide theoretical analysis about the proposed method. Experiments on various backbones and tasks demonstrate the effectiveness of the proposed method. A practical implantation of BiPointNet on ARM also demonstrates significant speedups over PointNet and large memory savings.\n\nStrength:\n1. Binarization of CNN models designed for 2D images has been studied in the past years, this paper extends this problem into 3D point cloud models. The authors show that the existing methods for binarization of 2D CNN models can not work well on this new problem. \n2. For this new problem, the authors analysis its performance degradation based on PointNet and proposed effective solutions.\n3. Experiments on several tasks show that the proposed method can obtain highly compact models with acceptable accuracy degradation. Experiments on other backbones also show that the proposed method is general, although its analysis is based on PointNet.\n\nFor the weakness, I only have some minor comments.\n1. The discussion on related work could be enlarged. For example, the following papers are well known point cloud networks proposed recently\n(a) PointConv: Deep Convolutional Networks on 3D Point Clouds. CVPR 2019\n(b) Relation-Shape Convolutional Neural Network for Point Cloud Analysis. CVPR 2019\n(c) ShellNet: Efficient Point Cloud Convolutional Neural Networks using Concentric Shells Statistics. ICCV 2019\n\nMixed precision quantization is also an active direction after binarization of neural networks, it could also be mentioned as a possible improvement in the future.\n(d) Mixed Precision Quantization of Convnets via Differentiable Neural Architecture Search. ICLR 2019\n(e) Search What You Want: Barrier Panelty NAS for Mixed Precision Quantization. ECCV 2020.\n\n2. Some references miss publication type, i.e.,  conference or journal and where they are published.\n3. Figure 1 can be improved. It is unclear how LSR works in the whole framework.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Strong empirical and theoretical results",
            "review": "This paper proposes a method for learning binary neural networks on point cloud inputs. They provide an entropy analysis of the binarized distributions as well as an offset transform to maximize entropy. Then they analyze the scale of binary activations and propose a learnable scaling to reduce the effects of scale distortion. They show that their method is competitive with other binary neural network methods and even full precision methods. Finally they show performant speed and storage results on a Raspberry Pi.\n\nStrengths:\n- Strong empirical results backed by theoretical analysis\n- Experiments are comprehensive and show competitive results on accuracy and speed\n\nConcerns:\n- If speed vs accuracy is the main trade-off, I would like to see a more thorough evaluation of all the models and baselines on a speed vs accuracy tradeoff plot\n\nGiven the strong empirical and theoretical results, I would recommend an accept. I would still like to see the authors strengthen their paper with a more detailed speed/accuracy trade off.\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A novel work on the binarization of point cloud models for time efficiency and storage saving.",
            "review": "The paper proposes a binarization approach for efficient deep learning on point clouds, called BiPointNet. The authors claim that the immense performance drop of binarized models is caused by the aggregation-induced feature homogenization and scale distortion. The authors propose Entropy-Maximizing Aggregation(EMA) and Layer-wise Scale Recovery(LSR) to reduce the side-effects of binarization. Experiment results demonstrate that the proposed BIPointNet is able to achieve state-of-the-art results and gives an impressive speedup and storage saving. \n\nBesides the major contribution of the paper, the writing of the paper is concise and the illustrations are clear. However, the paper mainly focuses on PointNet-kind of structure, such as PointNet++, and DGCNN, etc. It would be better if the authors could give more discussion on the application of the EMA and LSR on more advanced methods, such as KPConv and PointConv, etc.\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}