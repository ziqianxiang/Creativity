{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This is an unusual, but interesting submission. Can we use a simple \"quantum computer\" (in fact, physical system) to solve classification problems in ML? A single photon passes through the screen. Its state is described by the complex vector. A quantum computer makes a unitary linear transformation on this state in such a way that it maximizes the overlap with a corresponding class. Such a model can be parametrized by conventional means, and trained and later possibly realized by an quantum system\n\nPros:  \n1.  The area of QC is very important, and such papers shed a new light on the subject. \n2. Inspiration to the ICLR community to work on in this area.\n3. Technically correct.\n\n\nCons: \n1. The accuracies are far from SOTA and use very toy datasets. It is not clear, how to get to the accuracies needed in practice.\n2. The actual computational speed of inference is not clear.\n3. Discussion of more complicated models and their possibility is necessary.\n4. Quite a few misprints are in the text which need to be fixed in the final version.\n\n\n\n"
    },
    "Reviews": [
        {
            "title": "Accessible contribution at intersection of ML and quantum mechanics",
            "review": "The paper identifies two atomic problems, respectively in fields of ML (MNIST classification) and quantum mechanics (measuring a single photon), and brings them together in a simplified setup that uses a single photon emitted according to the spatial distribution of images to classify MNIST/Fashion-MNIST. The introduction of quantum mechanics into the problem is through a trainable computational model of a beam splitter/phase shifter mechanism, aka a rotation in a high dimensional complex space, that's allowed to alter the photon's state before hitting the measurement device. The paper shows that using this overly simplified (and claimed to be physically feasible) quantum computer, which acts as the representation learning layer, improves classification accuracy over any other representation learning method that doesn't use quantum computing. The major take-away is an accessible demonstration of how an elementary quantum computer might work for ML, and what may be possible with actual qubits.\n\nStrengths:\n* The paper sets out to use two textbook problems in ML and quantum mechanics to introduce a textbook problem at the intersection, and does a fairly good job at analyzing the problem extensively. Given that the overall problem is of broad interest to the representation learning community, the solid execution of the paper is itself a good argument for acceptance.\n* Accessible explanation of quantum states, the measurement process, and the building blocks of quantum computing.\n\nComment:\n* The paper analyzes a single problem where no classical representation learning method can improve accuracy due to the fact that there is a single photon. It would be very beneficial to allude to other setups, perhaps in a related work section, to provide broader context and help the reader understand better the significance of the problem.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Bringing the ML and QC worlds together using single-photon classification",
            "review": "The paper studies that  a ML system using quantum interference gives better classification accuracy than a vanilla ML system, under the  constraint that a classification decision has to be made after detection of the very first photon that passed through an image-filter.\n\nThe reader can gather that this work brings together the ML and QC worlds but it is not clear what the real motivation of this work is and primarily why is ‘single-photon’ important. Does single photon equate to a single pixel? Or is this denoting the very first photon that passed the filter? Also is this constraint of detecting the very first photon valid? \n\nIt might be good to know which audience reads the paper. If it is the ML audience, then a section on QC basics/terminology will help. Or at least a graphical abstract to drive home the point home, will be helpful. \n\nWas there a reason to use the Fashion-MNIST in conjunction with MNIST dataset? The authors can also consider to abbreviate Fashion-MNIST to F-MNIST throughout the paper. \n",
            "rating": "3: Clear rejection",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "A new approach for quantum computing based machine learning",
            "review": "This paper focuses on the quantum computing based machine learning and proposes a toy model to illustrate the quantum information processing. On the common used handwritten digit dataset MNIST, more than 40% images can be classified accurately. The proposed method looks interesting and the focused problem (combining quantum computing and machine learning) is of certain significance.\n\nStrength:\n+ The topic is interesting, which inspires the following researchers to focus on the combination of quantum computing and machine learning. Both the theoretical analysis and experimental results demonstrate that the proposed classifier works well.\n+ The visualization results in Figure 4 are interesting. With the proposed photon classifier, the semantic information of the input images can be well extracted. The photon classifier tends to produce large amplitudes for the right classes.\n+ The proposed method is analyzed in detail from multiple perspectives, including results on MNIST, confusion matrices and visualization.\n\nWeakness:\n+ In the Results section, only experiment results of the proposed method is shown. There are some previous works related to this paper, such as [r1]. More comparisons and discusses between the proposed method and previous methods are desired. \n+ The experiments are conducted on two simple datasets, MNIST and Fashion-MNIST. Real image data are more complex, such as colored natural images. Could the proposed method be applied on more complex data? If can, how to extend and apply it? Please provide such a discussion.\n[r1] Erfan Khoram, Ang Chen, Dianjing Liu, et.al. Nanophotonic media for artificial neural inference. Photon. Res., 7(8):823–827, Aug 2019.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting work",
            "review": "The goals of this work are ambitious: to clearly define a setting useful to both physicists and machine learning practitioners.\n\nThe current paper is an excellent step in this direction.\n\nHowever, with several semesters of undergrad quantum mechanics courses, I found it difficult to follow the calculations needed to compute predictions. \n\nMoreover, given my graduate-level experience in machine learning, it was even more difficult to clearly understand the data and training algorithm. \n\nIn the current state I do not think ICLR is an appropriate venue for this work, as it may confuse machine learning practitioners. (Though, I think the original goal of the paper is very worthy, and look forward to the final version of this work!)\n\nTo try to give constructive critique:\n\n- it took me a long time to understand the setup of the problem. An illustration of FashionMNIST or MNIST would help, with an incoming photon, an arrow through the cut-out of the image (clearly delineating that the image is binarized, and that white pixels are cut out, allowing the photon to pass through), and a detector (An LCD screen is described — is this the detector as well? Or does the photon bounce back and is then detected?). Such an illustration would go a long way for a machine learning practitioner unfamiliar with the double slit experiment and whatnot.\n\n- an algorithm box. A machine learning audience is used to thinking in terms of training data and algorithms. In this case, an algorithm box would help, specifically as it shows where the additional information is coming from. It seems like the 'training' is in optimizing the parameters of the unitary transform. Clearly delineating input, output, and optimization steps will help clarify the method. \n\n- an equation for computing the predictions of the trained model. Given a photon that passed through a mask, a clear formula for computing the class probability with the trained unitary operator parameters.\n\n- clearly describing the baseline. It was hard to find the details of the classical performance reported. 'maximal classical performance' is confusing wording, and implies that 'maximal' is proven theoretically. Is there a citation for this? I may have missed it. If it is not proven theoretically, then the wording should be changed, and a clear description of the architecture, training data, and training algorithm should be used, and code should be included in the supplement. This will help machine learning folks understand exactly what the comparison is against. From a machine learning standpoint, is the single pixel input to the model randomly sampled every time? \n\n- developing an additional baseline. Finding a unitary transform to find bases corresponding to style and class is unfair to the classical method, which does not have access to this information. Not having a baseline that uses this additional information will further confuse machine learning folks, as it seems obvious that a model that uses additional information will outperform a 'classical' model that does not use this information. For example, a tensor decomposition/SVD that uses information about style and class might be possible.\n\nHope this is helpful; I think with this additional work it could be quite a valuable contribution, as I think the ICLR community could be inspired to develop more methods that require complex-valued numbers such as this one.\n\nEdit:\n\n- the authors meaningfully addressed the above points. I have raised my score accordingly.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}