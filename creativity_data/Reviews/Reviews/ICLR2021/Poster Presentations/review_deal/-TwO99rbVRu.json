{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The authors introduce an approach for designing pseudo-labels in semi-supervised segmentation.\nThe approach combines the idea a refining pseudo-labels with self-attention grad-CAM (SGC) and a calibrated prediction fusion, and consistency training by enforcing pseudo labels to be robust to strongly-augmented data. \n\nThe reviewers overall like idea and point out the good level of performance obtained by the method in the challenging semi-supervised context. However, they also point out the limited novelty of the approach, and the need for a better positioning with respect to related works. After rebuttal, reviewers were satisfied with authors' answers and paper modifications, and all recommend acceptance. \\\nThe AC considers that the submission is a nice combination of existing techniques and likes the simplicity of the one-stage approach, which reaches good performances. Therefore, the AC recommends acceptance."
    },
    "Reviews": [
        {
            "title": "An incremental approach showing good performances",
            "review": "**Summary:**\n\nThis paper introduces a model to improve semantic segmentation by using a limited amount of pixel-labeled data and unlabeled data or image-level labeled data. The authors use a Self-attention Grad-CAM (SGC) and segmenter to generate the pseudo-labels during training. The approach shows good results on Pascal VOC and COCO datasets and is well analyzed. \n\n\n**Reasons for score:** \n\nI do not think the technical contribution is strong enough for ICLR. The paper is incremental and the proposed approach is a combination of a lot of existing approaches. But I also want to highlight that the experimental section is strong and detailed.\n\n\n**Pros:**\n\n- The idea of using pseudo-labels is interesting because it allows to build larger dataset without increasing the annotation cost.\n- The approach is evaluated in the settings of using unlabeled data and using image-level labeled data.\n- The ablation study section gives a lot of details about the model. The authors analyzed a lot of things: expected calibration error, hypercolumn feature, soft vs hard label, temperature sharpening, color jittering strength, backbone architecture.\n- The approach shows good results on Pascal VOC and COCO datasets.\n- The proposed method achieves good performance in the low-data regime\n\n\n**Cons:**\n- The overall approach seems incremental because it is a combination of a lot of existing approaches and there is not a strong technical contribution. For instance, the model uses several loss functions and all the losses are jointly optimized.\n- I think the related work section should be in the main paper instead of the supplementary. \n- I feel some parts are a bit difficult to read because of some misleading information. For example, the title of section 3.1 is “Experiments using unlabeled data” but the model still uses some labeled data. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A simple and effective method for semi-supervised semantic segmentation",
            "review": "Summary:\nThis paper focuses on the problem of semi-supervised semantic segmentation, where less pixel-level annotations are used to train the network. A new one-stage training framework is proposed to include the process of localization cue generation, pseudo label refinement and training of semantic segmentation. Inspire by recent success in the semi-supervised learning (SSL), a novel calibrated fusion strategy is proposed to incorporate the concept of consistency training with data augmentation into the framework. Experiments on PASCAL VOC and MSCOCO benchmarks validate the effectiveness of the proposed method.  \n\nPro:\n+ The proposed one-stage training framework is elegant compared with two stage methods in this area which include one step for pseudo-label generation and another step for refinement then semantic segmentation training. \n+ The new designed calibrated fusion strategy well incorporate the concept of consistency training with data augmentation into the same framework.\n+ Achieve a new state-of-the-art on both PASCAL VOC and MSCOCO benchmarks compared with recent semi-supervised semantic segmentation methods.\n\nQuestions:\n- CCT (Ouali et al., 2020) includes the consistency training with perturbations which can be treated as a kind of data augmentation on features. I'm wondering if authors can provide some insights about why the proposed method can achieve better performance than CCT when they both include the consistency training and data augmentation in the designs.  \n- In table 3, I suggest to include the segmentation framework used by each method in the table. In early works, old version of deeplab is usually treated as the standard. I understand using deeplab v3 is a fair comparison with CCT. It would be good to make this information clear in the table.\n- It is also suggested to report the performance on PASCAL VOC test set as it is a common practice in this area (although CCT does not do so).\n- Sine the unlabeled data training branch does not rely on any pixel-level annotations, I'm wondering if the proposed method can also work under weakly-supervised setting, where no pixel-level annotations are available during the training. ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting paper, good results",
            "review": "** Summary\nThis work addresses the task of semi-supervised learning (SSL) in semantic segmentation. Following recent SOTAs in SSL, this work also advocates for the use of pseudo-labels on unlabeled data and heavy data augmentation. The main novelty of this work is the novel way to construct higher-quality pseudo-labels: besides the pixel-wise classifier's probabilistic outputs, the authors leverage as well CAM-based activation maps, named as SGC, as an additional pseudo-label source.  The final set of pseudo-labels is determined by linear combining the two soft pseudo-label sources with temperature adjustment. The authors conducted extensive experiments with lots of ablation studies to validate the proposed framework.\n\n** Strengths:\n- The paper is well-written, easy to follow\n- Extensive experiments with adequate discussions\n- Improvements over SOTAs on the addressed benchmarks.\n\n** Weakness/concerns:\n - Does \"distribution sharpen operation\" always use temperature < 1? If yes, what is the reason?\n - How is the temperature $T$ is chosen? May the authors produce a performance analysis over T?\n - In Sec 3.4, it's not clear to me the advantage of proposed method on boundaries. CAM-based activations mostly focus on most discriminative areas (usually inner areas). So hardly SGC can find pseudo-labels on boundaries. Why does the proposed method have an advantage there?\n - More and more segmentation works report results in urban datasets like cityscapes or camvid. It would be interesting to see results on those datasets. One interesting aspect in urban datasets is the natural long-tail class distributions, which severely damages performance on minor classes, especially in low-data regime.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}