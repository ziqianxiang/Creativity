{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper proposes a sensitivity-based pruning method at initialization. For fully connection and and convolutional neural networks, it shows that the model is trainable only when the initialization satisfies Edge of Chaos (EOC). The paper also provided a rescaling method so that the pruned network is initialized on the EOC. For Resnet, the paper shows that the proposed pruning satisfies the EOC condition by default and further provides re-parameterization method to tackle exploding gradients. The experiments show the performance of the proposed method on fully connected and convolution neural network, as well as ResNet. There were some concerns about the contribution of the paper compared to that of [1]. I read the two papers carefully and while both papers aim at addressing a similar problem, i.e., pruning at initialization while avoiding layer collapse, the paper provides a different perspective on the problem, and provides enough theoretical contribution and insights to be found helpful and interesting by the community. \n"
    },
    "Reviews": [
        {
            "title": "A solid paper lacking some experiments",
            "review": "### Contents of the paper\n\nThe contributions of the paper are three folded: 1) It proposes an essential for pruning at initialization, namely the NN must be initialized with EOC. 2) It proposes a trick to pull the pruned network back into EOC. 3) Some specific research about  ResNet.\n\n### Advantages of the paper\n\n1. The paper seems to be solid with enough motivation and proofs.\n2. The experimental results show that the proposed algorithm achieves about 1% higher accuracy on ResNet than other algorithms.\n\n### Weakness\n\n1. Lack of experiments on larger datasets such as ImageNet\n2. The authors claim an exploration on FFNN and CNN. However, only results on ResNet are provided. In other words, the effectiveness of the algorithm on other networks are doubtful.\n3. Lack of ablation study or case study experiments. For example, what if we prune a CNN without EOC? \n\n#### Updates after rebuttal\n1. The authors have provided more results I concerned, which seems to be accord with their conclusions in the paper.\n2. Initialization of CNN or other networks is an interesting topic which affects the performance of pruned models. However, there are few papers about the topic. I think the paper is a good example which may arouse more concerns about it.\n3. I am willing to increase my rating to 6.\n\n### Question\n\n1. In table 1, why the results on ResNet104 are far better than those on ResNet32 and ResNet50? Especially when the pruning rate is 90%\n\nI'll consider to increase my rating if the authors can provide more convicing results",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Rescaling trick to avoid an entire layer pruning phenomena",
            "review": "The given paper carries two main contributions: 1) theoretical study of the pruning at initialization (i.e. before training); 2) proposing a new rescaling trick to avoid issues (namely, entire layer pruning) that are common for such pruning mechanisms. \n\nMajor concerns:\\\n  . Theoretical contribution: First of all, I would like to mention that I am not an expert in one-shot pruning and pruning at initialization. However, I strongly believe that the layer pruning problem is commonly observed and studied phenomena (which is stated by authors as well) and it was theoretically studied before. For example, I suggest authors refer to the recent work from [1] where they call it \"layer collapse\". Furthermore, it was shown that layers with the smaller size have more likelihood of getting entirely pruned. Here, we observe similar behavior (called \"layer ill-conditioning\") but due to EOC.\\\n  . Methodological contribution: again, as it is done in [1], the main propose of the rescaling trick is to make sure that the sensitivity score is uniformly distributed to avoid layer pruning. I believe, there are other ways to achieve this goal and thus, contribution is marginal.\n\n[1] Tanaka et al. Pruning neural networks without any data by iteratively conserving synaptic flow. June, 2020.\n\nMajor advantageous:\\\n  . Authors theoretically justify their proposed method;\\\n  . Experiments show a consistent improvement over the SoA baselines (Snip, Grasp). The improvement is even drastic for ResNet104; However, it will be nice to have a comparison with [1].\n\n\n---- update after authors' response ----\\\nThanks for clarification and providing additional experiments. I'm changing my final evaluation to weak accept. Yes, this paper does provide some interesting insights, but I still think that it has a limited potential impact (see above for major drawbacks).\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The paper proposed a sensitivity-based pruning at initialization and discussed it from both theoretical and empirical angles. ",
            "review": "The theoretical analysis is clearly stated in an well-organized way and the derived sparsity bound is reasonable. With FFNN and CNN, a theorem is given to show that the model is trainable only when the initialization on Edge of Chaos (EOC) and also provided a rescaling method to make the pruned NN into EOC regime. With Resnet, it proves the pruning satisfies the EOC condition by default and further provides re-parameterization method to tackle exploding gradients. The experiments well support theoretical results for both FFNN/CNN and resNet. \n\nI would recommend an accept on this paper.\n\nQuestions during rebuttal period: \nThe theorem 2 is stated for resNet with ReLU activation function. Is proposition 2 and section 4.2 only for ReLU as well? Please state the dependence on activation function more clearly in the paper. \n\nOne typo: In section 4.1, the figure should be Figure 3 rather than Figure 5. \n\n      ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}