{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "There is a lot of agreement on this paper, also reflected in the ratings. There were some technical comments initially, on the approach not being IC and interpretable, missing links to other works and technical descriptions of the network and experiments. The authors cleared up many of these issues though with their responses, providing good arguments in favor of their work. In general, reviewers agree the paper would be interesting to be included in ICLR."
    },
    "Reviews": [
        {
            "title": "ICLR 2021 Conference Paper2740 AnonReviewer5",
            "review": "This paper studies how to design auctions using deep learning, as initiated by the work of Duetting et al. (2019). The authors argue that their new framework addresses several undesirability of the previous works, including extensive hyper-parameter tuning and unclear comparison between two auctions with different revenue and regret performance. Moreover, the new framework can be easily generalized to online environment.\n\nThe main novelty of this paper is to use a new optimization objective without relying on the Lagrangian method to formalize the objective. The new optimization objective is backed by a theorem stating that for a single-bidder environment, an auction with regret can be converted to an auction without regret with a revenue loss bounded by the square root of the regret, which also provides a convenient way to compare two auctions. Since the new objective does not consist of Lagrangian multipliers, no hyper-parameter tuning is required.\n\nThe empirical results further demonstrate the advantage of their new architectures.\n\nComments:\n\nThis paper is generally well-written and clear. The problem it studies is interesting and important, related to both game theory and deep learning, which is relevant and interesting to the deep learning community. It is nice to have a new architecture without extensive hyper-parameter tuning\n\n1. The author mentions that the theorem (that for a single-bidder environment, an auction with regret can be converted to an auction without regret with a revenue loss bounded by the square root of the regret) can be extended to the multi-bidder environment if using the notion of BIC. However, according to the definition, the regret is still computed in the ex-post level, which seems a bit strange. Could you elaborate more on this?\n\n2. Is it true that the misreport's utility is always 0 in any Nash equilibrium of the two-player game? Or this is only true for the optimal solution?",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A good empirical paper, which simplifies the training procedure proposed by the original paper on this topic [Duetting et al '19]. However, the authors need to clarify some overstatements in the paper. I think this paper can be accepted if there is room.",
            "review": "This paper studies the auction design project through deep learning, following the direction pioneered by [Duetting et al '19]. The main contribution of this paper lies in two aspects: 1) they propose a time-independent lagrangian loss function which is motivated from eps-BIC to BIC transformation in [Rubinstein & Weinberg '18], and 2) the authors propose a GAN structure to compute the regret during training. The idea is simple and clean: design another NN to approximately compute the optimal misreport for each bidder.\n\nThe good:\n\n1. It lies in the intersection between Game Theory/Mechanism Design and Machine Learning, it should be of interest to a lot of people on both sides. It is a good fit for ICLR community.\n2. It focuses on an important question in mechanism design literature: multi-dimensional revenue-maximizing auction design.\n3. It is interesting and important that it can avoid hyper-parameter tuning for lagrangian loss function during training.\n\nThe drawbacks:\n\n1. It follows the spirit of [Duetting et al.] and also inherits the drawback there: the trained mechanism is not strictly IC and uninterpretable.\n\n2. The authors claim that they propose a metric to measure the performance of the nontruthful auctions, however, based on my understanding, it only holds for the single bidder case. For multiple bidders setting, as the authors state, they need to change to the BIC version of the regret, which is quite different with the expected ex post regret defined in this paper and the prior work [Duetting et al '19].  In this paper, all the simulations are based on the expected ex post regret. Therefore the new metric statement doesn't seem solid and the authors need to clarify.\n\nIn summary, this work is a good empirical paper, which simplifies the training procedure proposed by the original paper in [Duetting et al '19]. However, the authors need to clarify some statements in the paper. I think this paper can be accepted if there is room.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Optimal auction design using DNN as a two player game through hyper-parameter free and robust loss function is studied. The paper is not well placed in the literature, making the contributions hard to judge. ",
            "review": "The authors study the problem of optimal auction design using deep neural networks. Based on the structural insights in optimal mechanism in an additive auction with 1 bidder and m items, they propose a new loss function. This loss function is hyper-parameter free unlike Duetting et al. (2019) which is one of the early works in this field, making it more robust and interpretable. \nThe authors then propose a training method that resembles a two-player game to optimize the new loss function. The synthetic experiments (Table 3) show the designed algorithm, which does not require hyperparameter tuning, is comparable to the work of Duetting et al. (2019). \n\nPros: \n* The connection to the structural results in Balcan et al. (2005) to design the loss function.  \n* The illustration of the sensitivity of the loss function in Duetting et al. (2019) solidifies the message. \n* The training method that resembles a two-player game brings a new perspective to the problem (*)\n\nCons/Questions:\n* The paper lacks adequate comparisons, both conceptual and experimental, to other existing works.\n* In the experiments section, for Table 3 how the hyperparameters for RegretNet (Duetting et al. (2019)) is tuned is not clear. Such tuning is crucial for RegretNet as mentioned by authors. \n* In Table 2. comparison with RegretNet will be useful. \n* In Fig 1. why the online RegretNet and ALGnet converge to the same solution, despite the different loss functions?  \n* What are the depth and the width of the neural networks used in the experiments?\n* Is RegretNet the state-of-the-art for the different settings mentioned? (*) \n\nMinor:\n* The auctions reported have a maximum size of 5x10, which, in my opinion, should not be called a large scale.   \n\n\n(*) As an outsider to this field, whether this method is truly novel is hard for me to judge. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Nice paper! I have a question about relation to other work.",
            "review": "This paper revisits a recent deep learning framework by Duetting et al (ICML’19) for learning Bayesian optimal auctions, which is a notoriously hard problem in theory. They propose two modifications to the Duetting et al architecture:\n•\tThe auctions computed by these algorithms are not exactly IC. To cope with that the learning objective penalizes by the regret of each agent from truthfully reporting their type. This leads to a question of choosing the relative weights of the revenue and the regret. Previous work had a complicated and brittle way of doing it, and the new paper proposes a simple formula that is inspired by auction theory and seems to work well in practice. The authors also propose to use this formula as a benchmark for comparing auctions with different revenue and regret guarantees.\n•\tThe training algorithm has to estimate the regret at each step, which requires an expensive optimization for the optimal deviation. The new paper proposes to amortize this optimization: after each gradient step of the auction, the optimal deviation probably did not change much so we can start it from the previous optimal deviation.\n\n\nThis paper makes nice contributions in an exciting new research direction towards insights on a classical problem. \n\n\nI’m still concerned about a couple of issues:\n•\tI don’t understand the relationship between this paper and Rahme et al. (“A Permutation-Equivariant Neural Network Architecture For Auction Design”): It also mentioned in passing in the introduction. I’m not familiar with the details of Rahme et al., but based on the abstract it seems like both propose improvements to the same Duetting et al. paper in the same setting. Many parts, e.g. structure of the introduction, are almost identical. Moreover, Rahme et al. claim to have a better algorithm than Duetting et al., so I’m not sure why the current paper doesn’t compare performance to that algorithm. (If these were written by the same authors, I’m not sure why they wrote 2 different papers?)\n•\tThe authors propose that the same theory-inspired formula they used for balancing regret and revenue be used to compare different mechanisms with different levels of revenue/regret. For multi-agent settings this approach sounds like a plausible heuristic, but they don’t bring enough support to convince me to use it as a metric. For single-agent settings, I would advocate to just apply the usual reduction to revelation principle, i.e. ask how much revenue the mechanism would get with a rational agent who exactly optimizes their bid. \n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review of Auction Learning as a Two-Player Game",
            "review": "Objective of the paper:\nThe objective of the paper is to show that auction design can be views as a two-player game;  improving on past work, they provide schemes that give better performance and better time for learning.\n\nStrong Points:\n1)  The paper seems to offer improvements on recent past work.\n2)  The paper provides a clear background on auction theory relevant to the problem.\n3)  The paper delivers on the abstract.  \n4)  Some code is provided.  \n\nWeak Points:\n1)  It is not clear that the improvement over past work is large.  \n2)  The improvements/framework seem to rest on unproven assumptions, e.g., the use of the loss function in section 3.2.2, and the discussion of \"closeness\" in section 3.3.  This makes the paper somewhat unclear in terms of what it is offering -- heuristic approaches that improve (empirically) on the previous work?  If so, what are the limitations?  Are there situations the heuristic might be troublesome?  (Can you emphasize more clearly that your results are heuristic in nature, albeit based on theoretical formulations.)  \n\nOverall Rating:  I think this is an interesting paper.  I think the heuristics proposed offer benefits empirically and are well grounded, but the authors could do a better job clarifying the possible weak points of this heuristic approach compared to previous work.  The result is perhaps of interest to a specialized audience (people interested in auctions);  it's not clear that more general applications of the techniques are available.  \n\nQuestions for Authors:\nI was confused by Table 2 where you describe comparing to the \"optimal\" auction that has lower revenue than your auction results in 2 of 3 cases.  Is \"optimal\" here just signifying zero-regret?  Or is something else going on?\n\nIt is not clear to this reviewer that the auctions chosen are representative in any way -- I assume they've been used in previous works or are otherwise standard?  \n\nOther Feedback:  The paper is a bit confusing at times, but I think that is because the authors were forced to keep descriptions short in order to fit within page limits.  I think going back and offering a bit more description for a longer version would be useful.  Overall though the writing is fine.  \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}