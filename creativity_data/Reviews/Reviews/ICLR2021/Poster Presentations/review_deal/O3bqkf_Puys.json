{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper presents a construction for deep learning on point clouds that evolve over time. The key characteristics of the data are irregular sampling in the spatial domain and regular sampling in the temporal domain. The presented construction addresses both these aspects of the data. The review by R3 was negative but was addressed by the authors and R3 did not participate in the discussion. The AC supports acceptance."
    },
    "Reviews": [
        {
            "title": "Principled and clearly presented; empirical justification needs improvement.",
            "review": "This paper introduces a new convolutional approach to directly process raw spatiotemporal (ST) point cloud data. The proposed point spatio-temporal (PST) convolution operates on \"point tubes\" and decouples space and time through a shared spatial convolution at each timestep, followed by a temporal convolution. It also introduces a transposed PST to enable point-wise predictions in an encoder-decoder framework (PSTNet). The presented experiments demonstrate the effectiveness of these convolutions by using PSTNet for action recognition and semantic segmentation on point cloud sequences, showing improvement over relevant recent work.\n\nStrengths:\n+ The approach is technically novel. Processing raw 4D point clouds of arbitrary length is a relatively new direction, and I have not seen a convolutional approach before.\n+ I like the idea of decoupling spatial and temporal convolutions. As the paper points out, this should allow better handling of varied spatial sampling over time.\n+ Though the ST neighborhood size (i.e. temporal kernel size and spatial search radius) must be manually set and tuned, these neighborhoods are defined and structured in a principled way similar to grid-based CNNs which could make tuning easier than in prior work (e.g. MeteorNet).\n+ Experiments show slight improvement over the most relevant SOTA MeteorNet and MinkowskiNet for action recognition and semantic segmentation from depth sequences. I also appreciate the analysis of sensitivity to ST neighborhood parameters and the informative visualization of learned features (Fig 4, 12, and 13).\n+ The paper is, for the most part, well-written and nicely presented (e.g. Fig 2). The detailed supplementary material and promised code release enabled reproducibility. \n\nWeaknesses:\n- The paper could better situate the proposed method in the context of relevant prior work (see \"Related Work\" below).\n- The proposed PST convolution is described as \"generic\", but as far as I can tell it would struggle with irregular temporal sampling. The architecture operates on ordered point cloud sequences but does not leverage timestamps, so there is an underlying assumption that point clouds are sampled at a fixed rate that does not change from training to test time.\n- Various claims and design decisions could be better supported through additional experiments; in particular, the choice to decouple space and time and the spatial kernel design (see \"Experiments\" below). \n- There is no discussion about the limitations of the proposed method in the paper.\n\nBased on these points and the ones detailed below, I initially lean towards accepting the paper. The proposed method is technically novel and principled, and the experiments are sufficient to show PSTNet can extract useful features. The ability to handle irregular timestamps and additional experiments to characterize the advantages of space/time decoupling would improve the paper, but their absence does not outweigh the contributions for me. My other concerns about related work and a discussion of limitations can be addressed in a revision.\n\nRelated work:\n- PSTNet should be compared and contrasted to MeteorNet in more detail since this is the most relevant prior work. Currently, MeteorNet is described in an oversimplified way as applying PointNet++ to 4D points, but there are actually many similarities to the proposed method (\"point tubes\" are analogous to neighborhood grouping and the PST convolution to PointNet aggregation).\n- The proposed spatial kernel (Eq 5) is not compared to or motivated by related static point cloud convolutional methods in the Related Work or Methods sections. Additionally, some important relevant works are not cited, e.g., [1][2].\n- Other relevant works that consider spatiotemporal point clouds in a less general setting may be worth mentioning: e.g. in scene flow estimation [3] or learning from spatiotemporal object point clouds [4].\n\n[1] PointCNN: Convolution on X-Transformed Points, Li et al., 2018\n\n[2] Dynamic Graph CNN for Learning on Point Clouds, Wang et al., 2019\n\n[3] HPLFlowNet: Hierarchical Permutohedral Lattice FlowNet for Scene Flow Estimation on Large-scale Point Clouds, Gu et al., 2019\n\n[4] CaSPR: Learning Canonical Spatiotemporal Point Cloud Representations, Rempe et al., 2020\n\nExperiments:\n- The decision to decouple spatial/temporal convolutions would be more convincing with: (1) a comparison to a baseline PST convolution that does not fully decompose space and time (Eq 2), and (2) an evaluation on LIDAR data where spatial sampling can be highly irregular and variable over time. For example, the task of scene flow estimation from LIDAR would indicate if PSTNet can deal with high spatial irregularity while still encoding necessary local details.\n- The design of the learned spatial kernel f (Eq 5 and following paragraph) is not extensively motivated or justified in the text or by experimental results. How does the displacement/sharing kernel design affect performance or compare to using an MLP or other prior work like PointConv which considers point density? \n- If possible, a runtime comparison to MeteorNet/MinkowskiNet would be useful since these are similar generic ST point processing approaches.\n\nMinor Suggestions:\n- The formulation in Sec 3.2 unclear and inconsistent at times: e.g. (1) the displacement vector is described as a real number following Eq 3, but as a vector following Eq 5, and (2) the shape of F is not detailed for Eq 2-5. In general, I think the exposition in Sec 3.2 would be improved by intuitively describing the \"Point Tube\" idea before the precise mathematical formulation.\n- In Fig 5, GPU runtime is longer than CPU?\n- Typo in Sec 4.3, second paragraph: \"kennel size\" -> \"kernel size\".",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "PSTNet: Point Spatio-Temporal Convolution on Point Cloud Sequences",
            "review": "This paper aims to process the point cloud data in a convolution manner. The authors propose the PST convolution and deconvolution operations to handle the different tasks such as the classification and segmentation on point cloud. The extensive experiments verify the effectiveness of the proposed method and achieve state-of-the-art results on multiple benchmark datasets. Overall, the paper is well-written and organized. \n \nStrength:\n •\tIn this paper, the authors introduce a method named PST convolution which could directly handle the sequential point cloud data. The PST convolution could capture the spatio-temporal in a convolution manner. They decompose the spatial and temporal information and conduct convolution on them respectively. \n•\tIn order to handle both the abstraction level and point-wise level tasks, they build a complete convolution system including convolution and deconvolution. Also, the point tube concept is introduced here to preserve the spatio-temporal structure. \n•\tThe experiments are exhaustive and impressive. Especially the author adopts various kinds of demonstration to show the effectiveness. \n \n Weakness:\n •\tEven through the experiments results look pretty good, the novelty of this paper is still limited. In this paper, compared to the previous paper such as MeteorNet, the authors explicitly promotes the concept of capturing the spatial and temporal information. There is no significant difference with MeteorNet or even PointNet++. The MeteorNet also extracts the spatio-temporal information by chain-flow radius search. No matter the point tube or the anchor points extracted in the spatial and temporal domain, the main idea is finding a good neighbor for the current point. It should be described clearly in details for the novelty in the future revised version. \n•\tAlso, even the convolution adopted in this paper could make the point processing more convenient, I have a concern about the efficiency of the proposed method. The computation cost including stacked convolution layers, the FPS sampling, and the nearest neighbor search are all heavy. So the authors may provide some efficiency comparison in the future. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Promising results and well elaborated",
            "review": "The paper introduces point spatio-temporal convolutions, which are used for the feature extraction of point cloud sequences. A trainable kernel is used which is applied locally as a continuous convolution. An important aspect is that the temporal dimension is processed separately, with an additional convolution, instead of simply using a 4D convolution. The authors claim that in this way the network will achieve a better understanding of the dynamics of the input.\n\nThe presented method is very interesting in my eyes. I find the argumentation concerning the construction of the spatio-temporal conclusive and it is supported by the experiments. Together with the presented striding, based on farthest point sampling, and the transposed convolution, the method seems to be very versatile, as it was shown in the results. However, a few points are still not quite clear to me:\n* Why is striding used for the semantic segmentation test? Theoretically, this problem could be solved much easier without striding and transposed convolutions.\n* The results were mainly sequences where the points of the frames do not correlate. What about data where the points correlate, like in physical simulations? Would the presented point tubes make sense there?\n\nThe paper is written understandably and the evaluations are sufficient, IMO, to confirm the claims given by the authors. Maybe the following papers could be relevant as related work: Occupancy Flow: 4D Reconstruction by Learning Particle Dynamics and Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds, since they also deal with point sequences. \nIn section 3.1 there is a small typo (... CNNs usually adopt small ~~kennel~~ **kernel** sizes ...), just like at the beginning of section 4.3 (Temporal ~~kennel~~ **kernel** size...).\n\nAll in all I find the method simple but promising. The paper seems well elaborated and I would tend to accept it.\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}