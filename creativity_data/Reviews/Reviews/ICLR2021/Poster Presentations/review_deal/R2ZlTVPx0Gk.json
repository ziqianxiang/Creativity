{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes a new method of learning ensembles of neural networks based on the Information Bottleneck theory, which increases the diversity in an ensemble by minimizing the mutual information between latent features of the different ensemble models. It shows promising results on classification, calibration and uncertainty estimation. The paper is well-written and the comments were properly addressed."
    },
    "Reviews": [
        {
            "title": "Interesting idea with nice theoretical part, however limited experimental validation",
            "review": "This paper  addresses the problem of training an ensemble of learning algorithms so to boost the diversity among single learners while preserving the accuracy of each learner.\nThe paper is well written, the addressed problem is well exposed and relevant for this audience, the literature review is more than adequate.\nThe core idea and main contribution of this paper is to enforce diversity in the fature space rather than in the outputs.\nThe formalization of the approximated solution in Sec 2B has merit, however it is not clear if this is a first or higher order approximation and in the case why not considering an higher order ?\nResults on small datasets show some improvements, in some cases above 1%; yet, it is not clear how the proposed technique would perform on larger datasets such as ImageNet, which downtones a bit the value of this contribution.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "information theory for ensembles",
            "review": "Summary:\nThis paper proposes a method of learning ensembles that adhere to an \"ensemble version\" of the information bottleneck principle. Whereas the information bottleneck principle says the representation should avoid spurious correlations between the representation (Z) and the training data (X) that is not useful for predicting the labels (Y), i.e. I(X;Z) or I(X;Z|Y), this paper proposes that ensembles should additionally avoid spurious correlations between the ensemble members that aren't useful for predicting Y, i.e. I(Z_i; Z_j| Y). They show empirically that the coefficient on this term increases diversity at the expense of decreasing accuracy of individual members of the ensemble.\n\nEvaluation:\nOverall, this is a strong submission and should be accepted. It is well-written and thoroughly cites and explains prior work - in several cases, I find their explanations of prior work more clear than the original papers. It makes a clear and (as far as I know) novel contribution in terms of the approach, and the empirical results seem thorough and fair. In particular, the experiments for classification accuracy are thorough and make meaningful improvements over information bottleneck baselines (VIB and VCEB). I would (of course) like to see ImageNet experiments, but given that these are ensembles of relatively large networks (ResNet32 and ResNet110) and they include CIFAR-100 results on a number of architecture variants and a handful of baselines, I think these experiments are sufficient for acceptance. I don't have enough expertise in the uncertainty and calibration results to evaluate whether those empirical results are especially strong.\n\nSuggestions for improvement:\n- Page 4, Empirical Neural Estimation: I'm not clear on one thing here - when you are sampling B_p from the product distribution, you talk about p(z_2|y) as though you have access to the true distribution here, but I'd expect that here you would only have the backward encoder distribution b(z_2|y), a variational approximation to the true p(z_2|y). (And then when you're optimizing w towards the optimal w*, you would be optimizing w towards the optimal w* for that approximate distribution, not the true distribution?) I think this is what you are alluding to when you call this the \"false product distribution\" in the next paragraph, but it wasn't clear. I believe this is inconsequential because you then drop this term entirely, but this point could use better explanation.\n- It would be useful to include an explanation of how you chose the value of beta for the VIB and VCEB baselines. (I see in a section titled \"Scheduling\" that you anneal beta according to a specific schedule, but I wasn't clear on why or whether you tuned this at all.)\n- The ensemble experiment results (Section 4C and Table 2) are really hard to understand and interpret. The acronyms in the table should be spelled out (maybe in the caption), and in Section 4C when you mention ECE and TACE for the first time, you should write out the acronyms and also cite where these metrics were introduced.\n- I'd suggest citing the ensemble + uncertainty results from Ovadia et al. 2019 (https://arxiv.org/pdf/1906.02530.pdf).",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Increasing ensemble performance by reducing conditional mutual information",
            "review": "## Summary\nThis paper introduces a training procedure for ensembles of neural networks that improves intra-member diversity to achieve better accuracy and calibration.\n\n## Originality\nThis paper augments the VIB training objective of (Alemi et al., 2017) with two modifications: \n- adding a mutual information penalty between encodings of the same input by different ensemble members\n- conditioning the mutual information between encodings on the _input label_\n\nThe use of mutual information in training neural networks is not novel; indeed, as the authors point out, using mutual information between input and encoding; encoding and output during training is common. However, explicitly reducing mutual information between separate feature representations is, to the extend that I am aware of, a novel and intuitive contribution.\n\n## Significance\nThis paper addresses a well-known, yet still only partially understood, fundamental problem in ensemble learning: improved diversity between ensemble members is correlated with improved ensemble performance, even though requiring diversity within logits reduces each member's accuracy on what should often be easy-to-predict inputs. \n\nThe authors address this paradox by choosing instead to favor diversity within the ensemble member's feature spaces, using a mutual-information based loss, and introduce approximations to efficiently minimize this loss.\n\n## Clarity\nI found the beginning of the paper very clear and well exposed; however, section 2 requires careful reading and several passes to understand completely; given that it contains the crucial definition of this paper's main contribution, this made the overall understanding of this paper more complicated.\n\nI would recommend assigning more space to the equations, and perhaps removing Figure 3 (which, even on a screen for a non color-blind person, was difficult to parse) to allocate more space to defining crucial components of section 2.B.1.\n\nI am very open to improving my score as these concerns are addressed.\n\n## Pros/Cons\n\nThe idea behind this paper is both intuitive and elegant; however, I had a difficult time following anything more than the high-level explanation for VCEB. Although this may in part be my lack of familiarity with recent results, I found the explanation of this central part of the paper confusing.  \n\n- The appendix E.4 was helpful, but I would strongly recommend that the authors provide some clarifications in the main text: namely, defining the encoder, backward decoder, and the other terms that define the training loss.\n\n- For the empirical neural estimation: how does the discriminator $w$ scale with the size of the ensemble? I would imagine that as $M$ increases (or as the complexity of the neural networks themselves increases), $w$ scales as well.\n\n- Minor: I understand that it is difficult to fit all experimental results within the paper; however, Table 1 really needs to be larger.\n\n- Pro: the authors included significant ablation studies for each component introduced in their training loss, and show meaningful (outside of standard deviation) improvement over several important baselines.\n\nFinally, the authors may be interested in the recent work by A. Masegosa: [Learning under Model Misspecification: Applications to Variational and Ensemble methods](https://arxiv.org/pdf/1612.00410.pdf), which provides a theoretical justification for the use of diverse ensembles in improving predictive accuracy and calibration.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A novel application for IB objectives and information-theoretical quantities that improves diversity in ensembles",
            "review": "The paper introduces a new training criterion based on Information Bottleneck theory, which increases the diversity in an ensemble by minimizing the mutual information between latents of the different ensemble models. This leads to more diverse encodings that are useful for the task, which leads to better ensemble performance overall.\n\nOverall, I’m scoring the paper with a weak accept. It provides a new principled application of Information Bottleneck objectives with good experimental results in a new area of application. I hope a baseline implementation of this new objective will be made available for others to use. However, I have a few concerns which I detail below which the authors will hopefully be able to resolve easily.\n\n### Strengths\n\nThe paper is written very well. Overall, it is clear and engaging. The I-diagram helps understand the trade-offs within the objectives and makes it easy to see the information-theoretical equivalence of IBR and DICE (1).\n\nThe main conceptual idea is to add a term to minimize the (conditional) redundancy between latents of different ensemble members, which is expressed as the mutual information of the latent $I[Z_1;Z_2]$ in the case of an ensemble with two members. This term targets correlations between the latents which otherwise would add bias to the ensemble members.\n\nThe paper clearly describes the path from the general IB objective and the conceptual idea of reducing “redundancy” between (by minimizing to the CEB objective (Fischer, 2020) on to estimating the conditional redundancy.\n\nIt provides various experiments that show that this new method achieves better ensemble performance than similar approaches or independent ensembles that do not optimize for diversity.\n\n### Concerns\n\n1. The paper mentions that the second term on the RHS of (3) is not empirically necessary. However, they do not provide an ablation/experimental results that show the performance without dropping that term. For the sake of being principled, it would be nice to show evidence that dropping the term does not affect performance.\n\n2. Using information-theoretic principles to increase diversity is great. This reviewer wonders if the IB objective is necessary at all however: \nConditional redundancy could also be minimized independently as the idea is not itself connected to the IB objective. $I[Z_1;Z_2|Y]$ could also be meaningfully computed for deterministic encoders, for example. As such, the applicability of the contribution could be increased by applying CR as regularizer to ensembles. \n\n3. The authors write in 2.A.2: “The problem is that IBR ignores Y in the compression & redundancy terms which cause loss of necessary information” as motivation for the CEB. However, this is not true. Indeed, the CEB is equivalent to the regular IB objective for $\\beta=2$. As such, there is not conceptual difference, above statement is misleading. The reviewer speculates that CEB might allow for stabler optimization compared to the regular IB objective because the terms in the regular IB objective are “fighting” against each other by both “including” $I[Y;Z]$ within its terms: one term to minimize it, the other to maximize it. As the two terms are usually estimated separately this can lead to instability and “infighting”. Another speculation is that VCEB is more flexible than DVIB in its variational approach.\n\n---\nFollowing the author's reply, I've raised my score from a 6 to a 8.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}