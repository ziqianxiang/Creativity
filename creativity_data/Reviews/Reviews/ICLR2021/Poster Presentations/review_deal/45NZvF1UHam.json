{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes a meta-learning approach for inferring the Hamiltonian governing the dynamics of physical systems from observational data, and using it to adapt to new systems from the same class of dynamics quickly. The paper does this by effectively combining the previously published Hamiltonian Neural Networks and MAML/ANIL. The reviewers agree that the paper is well written, and the experiments are comprehensive, however, they also have reservations about the technical novelty of the proposed solution, given that it appears to be combination of pre-existing models. Saying this, the authors were able to  address a lot of the reviewers' concerns during the discussion period, hence I recommend this paper for acceptance."
    },
    "Reviews": [
        {
            "title": "Interesting contribution in structure learning of Hamiltonians using Meta-Learning",
            "review": "The paper introduces a meta-learning approach in Hamiltonian Neural Networks to find the structure of the Hamiltonian that can be adapted quickly to a new instance of a physical system.\n\nThe contribution is novel and the paper is well written. The presentation is mostly clear, however, some improvements are needed.\n\nStrength:\n- Clean methodology\n- good performance on the task of few-shot learning on a new system\n- nice visualization of the vector fields\n\nWeaknesses:\n- No real-world problem\n- The meta-learner, in particular HANIL, is clearly not adjusting the parameters of the Hamiltonian as we would expect it, like the physical parameters, which would be more at the beginning of the network.  It only adjusts the read-out layer. In this way, it is hard to understand what is really happening.   \n- You need a dense sampling of the meta-world. Really you have to look at 10000 tasks? A latent variable estimation model would have been a good baseline, or alternative to the Meta-learning framework, for instance, a VAE.\n  \nDetails:\n- below Eq 3: consider calling beta not a learning rate, because it is more a step-size since nothing is really learned in the inner loop\n- related work: machine learning methods to perform symbolic regression directly, such as \"Learning Equations for Extrapolation and Control\"\nSahoo et al, ICML 2018, might be good to add\n- Fig 3: font size is far too small, lines are too thin\n- Fig 3: consider using a log-scale for the MSE plots\n\n----\nPost rebuttal update:\nI  read the response and commented on it. The authors clarified my questions and updated the paper accordingly. So I think my score of 7 is supported.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Well written paper with solid contributions ",
            "review": "The paper presents a meta-learning method for learning Hamiltonian dynamic systems from data. More specifically, the novelty is incorporating Hamiltonian Neural Networks (HNNs) within known meta-learning methods (MAML and ANIL) in order to model new dynamical systems (with previously known structures but unknown parameters) from partially observed data. The results from the experimental evaluation (on three well-known systems) show that such an approach, and in particular HNNs w/ ANIL (HANIL), leads to more accurate models of unseen dynamics compared to other benchmarks methods such as \"vanilla\" HNNs and HNNs w/ MAML (HAMAML).\n\nOverall, the paper is well written and the contributions are solid: leading to reasonable improvements over recent work on modeling Hamiltonian systems while offering better understanding of the underlying modeling problem. However, I have some concerns regarding the experimental set-up as well as the discussion of related work (and the motivation, thereof), which are reflected in my score. \n\nFirst, it is unclear to me how the meta-training is performed: The authors state that 10K tasks are being sampled into the meta-training sets -  are these 10K sampled for each of the 3 systems (leading to 30K in total) or 10K in total (what is the task/system distribution in this case)? Is the meta-leaning performed on tasks sampled from all 3 dynamic systems (i.e. one meta-optimization for all 3 systems) or this is done per system (as Fig1 suggests)? The choice of 10K seems a bit arbitrary, how does this choice affects the overall performance? An ablation study on the size of the meta-sets will further highlight the strengths of the proposed method.  \n\nSecond, the authors chose two benchmarks which address modeling Hamiltonian systems (HNNs) \"by design\" i.e. vanilla HNNs trained from scratch (for a given task) and Pretrained HNNs (using the meta-sets). Recent work (for instance Symplectic Recurrent Neural Networks (Chen et. al 2020); Hamiltonian Graph NNs (Sanchez-Gonzalez et al. 2019); Symplectic ODE-net (Zhong et al 2020); SympNets (Jin et al 2020)) has shown improvements over the vanilla HNNs both in terms of accuracy and stability. Although these methods are very briefly mentioned in the paper, they are never in-depth discussed nor considered. It would be helpful if (at least) such a discussion is given, as well as maybe discussing possible extensions(eg. SRNN with ANIL).\n\nNext, the authors should consider extending the related work section in few directions. First, since one of the major contributions is related to meta-learning, the authors should provide a related-work segment discussing related meta-learning approaches which would further justify their design choices (eg. why wasn't Reptile considered). Next, in Sec 4.1., the authors state that the \"most related\" are HNN but omit any further discussion regarding eg. SRNNs (or HGNNs) - why SRNNs are not up-there with HNNs? IMO such a discussion will further motivate the contributions of the paper.\n\nI respectfully disagree with the last statement in Sec 4.2,  - that \"In contrast to our work, the existing methods of identifying the governing representations used the symbolic representation underlying the assumptions that the unknown physical laws are expressed by combinations of mathematically known expressions.\" Namely, the methods in this study also 'implicitly' build upon the very same physical laws (which are combinations of known expressions). The meta-tasks sampling is performed over systems with known structures therefore the very same assumptions still hold.\n\nOther comments:\n- Figure 2, while taking a whole page, is a bit unreadable and confusing to follow. More elaborative discussion will help with conveying the message better.\n- Can you clarify the difference in the results presented in Table 1 and Figure 3? More specifically, in Figure 3a, the coordinates MSE shows that HAMAML is diverging (while Pre-trained HNNs seem more stable). In Table 1, on the other hand, PreHNN are worse than HAMAML. Are these the same 10 \"new\" system but at different gradient steps, or? \n- In Sec 6, can you clarify this statement \"That is because the standard supervised learning scheme is not efficient for the model to learn appropriate shared representation across the systems. \"? What is a \"standard\" supervised scheme and why is not efficient?\n- The very next sentence (in Sec 6) states that \"Naive NNs ... also fail ... because are hard to grasp the continuous and conservative structure of the vector fields\". Can you also clarify this? \n\n----\nPost Rebuttal Update:\n\nThe authors addressed and clarified many of my concerns, therefore I updated my score. ",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Combination of HNNs and MAML/NIL",
            "review": "The authors combine Hamiltonian neural networks (HNN) with the MAML and ANIL neural learning approaches for Meta-Learning. The results are mostly consistent with what would be expected when combining them.\nThe paper is easy to follow and nice to read, and seems to have sufficient implementation details for reproducibility.\n\nMy main criticism is that there is not really novel technical content: the model is a trivial combination of MAML/NIL with HNNs. This could be ok in the following scenarios:\n* If results were given on well-known important domains achieving state of the art. Currently all domains are very toy.\n* If the paper gave a hint of what real-world problem settings could benefit from this specific combination, which does not seem to be part of the discussion.\n* If the paper did a very thorough empirical investigation. The results are nice (I really like Figure 2), but otherwise none of the insights are really new, but just the union of the conclusions of the MAML/NIL papers and the HNN paper.\n\nbut those are not really well covered. \n\nProbably the biggest value of the paper is that it brings together the HNN community (often closer to natural sciences communities) to the meta-learning community (often closer to data-science communities), and this paper may be a gateway from people from the former one to learn more about meta-learning, but I am not if this is sufficient to grant acceptance. I would not oppose an acceptance decision if the AC, or other reviewers decide to accept it on these grounds in its current form.\n\nAdditional comments:\n\nI am a bit surprised HANIL is so much better than HAMAML, considering Naive ANIL is not so much better than Naive MAML comparatively (specially in SpringMass and and Pendulum point dynamics).\n\nWas the number of gradient steps during evaluation fine-tuned for each baseline separately? Could this be the reason why MAML is comparatively worse? This is hinted in “while HAMAML is slower than HANIL to adapt the true vector fields because of the larger number of parameters to update in adaptation process”, but it would be nicer to see more supporting evidence or additional investigations.\n\nAll of the results in Table 1 corresponds to the evaluation of the loss of the derivatives, and not the error over an integrated trajectory right? I find it a bit unintuitive that the Naive network is on pair with the model on Kepler, but not on the other two domains. I would expect most of the advantage of the Hamiltonian model would come from the stability when integrating over longer trajectories, but not so noticeable on the predictions of gradients at single points. In fact in Table 1 from the original HNNs paper, they precisely show that the differences between the Baseline and the HNN are mostly w.r.t. preservation of energy, but that the losses on the derivatives are nearly identical.\n\nIt would be nice to see some experiments where the functional form of the Hamiltonian itself (rather than just hamiltonian parameters change across time). The title, introduction and related work, somehow makes it look like different physical laws will be inferred during the meta learning stage, however in practice the meta-learning task covers the same physical laws than those seen during training with different parameters. Otherwise the title is highly misleading, since it does not identify physical laws, but to identify specific instances of the same physical law.\n\nHow were the trajectories from Figure 3 chosen, fully at random?\n\nMinor comments/typos (have not affected my decision):\n\nTable 1: Possibly bold font for best model, or even better, some bar plots would make it easier to visualize the data.\n\nweird grammar: “with sufficient data to discover Hamiltonian.”\nmissing space: “partial differentiations(Rudy”\n\nAre the numbers in the last row of the results table truly exactly the same for Point dynamics and Trajectories (0.33±0.19 0.33±0.18 0.33±0.19 0.33±0.18), or is this an editing error?\n\n> When observing 25-shot point dynamics and 5-shot trajectories, the number of given samples in the phase space is the same, and the same is true for observing 50-shot point dynamics and 10-shot trajectories. \nWould be good to refer to L=5 again at this point.\n\nFig 2 (b-c) I would recommend to add some sort of labels indicating what each of the 4 rows on the left of the plot.\n\nOne model seems to be missing from Figure 3(a).\n\nFigure 3(a) caption mentions “after 50 gradient steps” but other places say “10 gradient steps”, not sure if this was changed for Fig 3, or this is a typo.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}