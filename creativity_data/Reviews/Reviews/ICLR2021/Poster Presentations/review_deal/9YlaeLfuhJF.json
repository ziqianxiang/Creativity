{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper presents an approach for mitigating subgroup performance gap in images in cases when a classifier relies on subgroup specific features. The authors propose a data augmentation approach, where synthetically produced examples (by GANs) act as instantiations of the real samples in all possible subgroups. By matching the predictions of original and augmented examples, the prediction model is forced to ignore subgroup differences encouraging invariance. The proposed method of ‘controlled data augmentations’ (as precisely called by R4) is relevant and well-motivated, the theoretical justifications support the main claims, and the experimental results are diverse and demonstrate merits of the proposed approach. As rightly pointed out by R3, ‘The appendices are also very thorough, and the code is organized well’.\n\nIn the initial evaluation, the reviewers have raised (in unison) concerns regarding overlapping subgroups per class, and an imbalance problem in the subgroups when training GANs. There were also questions reg. theoretical justifications, and empirical evaluations of the baseline methods. The authors have addressed all major concerns in the rebuttal. Pleased to report that based on the author respond with extra experiments and explanations, R2 has raised the score from 6 to 7. In conclusion, all four reviewers were convinced by the author’s rebuttal, and AC recommends acceptance of this paper – congratulations to the authors!\n\nThere is a colossal effort in the community addressing a goal similar to this work – learning invariant representations w.r.t. sensitive features by means of algorithmic fairness methods. (R1 and R3 relate to it). When preparing the final version, the authors are encouraged to elaborate more on the discussion/comparison to fairness-based methods, ideally including empirical evidence where possible (where subgroups overlap, e.g. CelebA). The AC believes this will strengthen the final revision and will have an even broader impact in the community.\n"
    },
    "Reviews": [
        {
            "title": "Interesting, well-written paper in an important topic",
            "review": "The authors consider the problem  of differential  performance across subgroups commonly present in classifiers, and propose to mitigate it. They augment subgroup data for each class using CycleGAN, and balance the performance across subgroups in each class using a consistency regularizer and a robust objective that minimizes the difference between the minimum and maximum subgroup performance.  This approach is demonstrated in several datasets including the ISIC skin cancer data.\n\nThe paper is written well, easy to follow, and I was able to understand and appreciate the contributions quickly. The appendices are also very  thorough and the code is organized well. There is sufficient detail to help readers reproduce the results.\n\nComments:\n1. The authors can specify very early on that the subgroups are pre-specified by the user, and not automatically discovered.\n2. Relations to the  area of group fairness may be helpful. The goal there is also  to ensure parity of predictions among groups, and various methods are used. The groups though are assumed to be common across classes. It may be possible to extend this approach to that area, and the idea of data augmentation may be very appealing there. A small discussion on this can be quite informative to the community. There is also the notion of  subgroup fairness discussed here which considers exponentially or infinitely many subgroups\nhttp://proceedings.mlr.press/v80/kearns18a.html \n3. Have the authors considered how their methods can be modified when the subgroups are common  across classes (this points directly to the group fairness comment  before)?\n4. Just to clarify, the robustness metric used in the experiments is the same as the metric of interest for GDRO in Table 1, correct? And is the gap same as the metric of interest for SGDRO? Does the performance for groups in each class vary between robust accuracy, and robust accuracy + gap? How are the metrics reported in the experiments consolidated across classes? It may be helpful to define the experimental metrics explicitly.\n5. Saying that your minimization of I(\\hat{Y}; X | [X]) is parallel to Lemma 1 is confusing, since you minimize the upper bound (in Thm. 1) and Lemma 1 minimizes the lower bound. Agree that your minimization is stronger.\n6. Have you tried  any preliminary experiments with greater than 2 subgroups per class? Just curious what it takes to use something like StarGAN like you mention.\n7. What are the risks of letting the users specify the subgroups? In some problems it may be hard to diagnose which subgroups are meaningful. Is minimizing the worst case performance over many possible automatically discovered subgroups an interesting future  direction in your opinion?  What does it take to do that?\n8. How well  will  this method work when there is considerable imbalance in the subgroups considered?\n9. In table 5,  what do the quantities in the parenthesis mean?\n\nTypo:\nSec. D.4.2 (GDRO): weighte ->  weight",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Intuitive and compelling solution to an interesting problem.",
            "review": "The paper focuses on data augmentation in cases when the classifier performance is worse on specific parts of the data. The problem is also closely related to that of the spurious correlation problem, the setting where the classifier might pick up on \"random\" patterns in the data to make its decision. The solution proposed by the paper is quite intuitive: first, given the subgroups in a class, a CycleGAN model is used to learn different versions of the same training example, each corresponding to a different subgroup. Once the augmented versions of the examples are available, the the classifier is then trained with additional penalty terms, ensuring that the predictions are consistent across different versions of the same training example. Empirical results show that the proposed method does reasonably well as compared to the competitors.\n\nWhile the reviewer is not an expert in the area, the contribution of the paper indeed sounds appealing. The proposed method is quite intuitive and simple to implement; and the empirical results are quite encouraging. On top of that, the proposed method is quite general (does not seem to be limited to just images) and can be applied to a variety of domains. One drawback of course is the need for manual identification of the subgroups, but given that state-of-the-art methods also need manual annotations (at least to my knowledge), that is probably fine. Finally, the paper is quite well written and easy to follow.\n\nA few comments and suggestion:\n\n- The current assumption is that the subgroups are specific to a single class. However, that may not always be the case in the real world. Consider for instance the problem of fair classification where subgroups (e.g., socially salient groups) might span multiple classes. Does the proposed method extend to such cases? From the first sight, that does not seem to be the case.\n\n- It is not clear what is meant by the statement \"handcrafting these augmentations may be impossible if the subgroup differences are difficult to express\". However, if the differences are difficult to express, wouldn't it also mean that separating these subgroups is difficult in the first place? In such cases, even the proposed method would also have a problem.\n\n- One potential problem with the proposed approach is its application in domains with small training datasets. It looks like training the CycleGAN would require a relatively large amount of data. How does the proposed approach expected to perform in such cases?\n\n- In Eqs. 2 and 3, the KL divergence is computed between the predicted distributions (presumably, softmax output). Given that DNNs tend to be quite badly calibrated (https://arxiv.org/pdf/1706.04599.pdf), is it worth computing the full KL divergence? Shouldn't minimizing the difference between the argmax class be sufficient?",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A model patching based method to design a robust classifier: experiments show reduced subgroup discrepancy on standard datasets",
            "review": "Machine learning models are trained to optimize performance on the entire training set, and can often exhibit inaccurate performance on a subgroup. Such inaccuracy often results from the model’s dependence on spurious features. This paper proposes model patching — a two-step method to avoid this problem. The first step learns inter-subgroup transformations where an example from one subgroup is transformed into examples of all the other subgroups within a class. The second stage uses these transformations as controlled data augmentations to learn a classifier that is robust to subgroup-specific variation.\n\nIn particular, the paper uses CycleGAN to learn the transformations between pairs of subgroups. The second stage uses the original data and the augmented data from stage 1 and minimizes a subgroup robust objective plus a self-consistency loss. The subgroup robust objective captures the discrepancy between the best and the worst performing subgroup within a class. On the other hand, the self-consistency loss enforces consistency on the augmented data. \n\nExperiments: The authors perform extensive experiments on three benchmark datasets — MNIST, CelebA, and Waterbirds. On all the datasets CAMEL improves both aggregate and robust accuracy by at least 5.3% and also reduces the subgroup gap significantly. Then the authors perform ablations on the two major components of the framework. It seems that learned augmentations perform better than other heuristic augmentations, and substituting the consistency loss with other losses reduces the robust accuracy by 2.5%. Finally, the authors apply the proposed framework on the real-world ISIC skin cancer dataset and found that it improves robust accuracy by 11.7% compared to the other methods.\n\n\nStrengths:\n- Extensive experimentation: I thought that the experiments were sufficient to demonstrate the effectiveness of the proposed approach. In particular, I liked the Model patching ablations experiments, which showed that both the learned augmentations and the subgroup consistency regularizer are important.\n- I thought that the use of CycleGAN and SGDRO is well-motivated and appropriate for this setting. \n\nWeaknesses:\n- No overlapping subgroups across classes. This paper considers a setting where each class is partitioned into multiple subgroups. I am not sure whether the proposed framework can be easily generalized for the setting when the subgroups are overlapping across multiple classes.\n\n\n\nQuestions for the authors:\n1. What happens if the group information is not known or noisy/incorrect? Can the objective function in subsection 2.2.1 be modified to handle such situations?\n2. If I expand the square term given in theorem 1, there will also be a product term in addition to the consistency loss and CycleGAN loss. However, this additional product term is absent from the objective considered by CAMEL. So I did not follow why CAMEL induces the desired conditional independence (\\hat{Y} \\perp Z | [X]).\n3. In table 4, why does CAMEL + Heuristic have very low robust acc (~53%) for \\lambda=200? Moreover, for this value of \\lambda, the maximum subgroup gap is quite large.\n4. Subsection 4.2.2 does not report performance for the datasets — CelebA and MNIST. What is the effect of consistency loss ablations on these datasets?\n\n\nIn summary, this paper proposes a model patching based two-step method to design a classifier that is robust and reduces performance disparity across different subgroups. Experiments on standard datasets clearly show that the proposed method is more effective than some of the existing approaches.",
            "rating": "7: Good paper, accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Review",
            "review": "# Summary\n\nThis paper introduces a method (CAMEL) to make CNN models robust to the effect of subgroups in classes. CAMEL uses CycleGAN to transfer the subgroup of each input image in each class and applies consistency regularization among transferred images. This paper additionally introduces a novel objective (SGDRO). CAMEL shows preferable performance on various data, including a real-world dataset of skin cancer classification.\n\n# Strengths\n\n1. The proposed method is straightforward and sound.\n1. The authors conducted extensive experiments with various datasets, including a real-world dataset of skin cancer classification. They also performed comprehensive ablation studies to show how and why CAMEL works.\n1. CAMEL can be combined with heuristic augmentation (e.g., rotations) to improve robustness.\n\n# Weaknesses\n\n1. The datasets used in the experiments are too simple to show the effectiveness of CAMEL and SGDRO. Specifically, the number of subgroups in each class of all datasets is at most 2. On the other hand, especially SGDRO assumes that subgroups have structure. A more complicated subgroup setting should be considered.\n1. When the number of subgroups in each class and the number of classes is limited as the experiments, one can treat $\\mathcal{Y}\\times\\mathcal{Z}$ as target and use ERM. This should be a strong baseline.\n1. I concern the scalability of this method. If CycleGANs are used as the paper, $\\sum_{y\\in\\mathcal{Y}}\\frac{\\|\\mathcal{Z}_y\\|!}{2}$ CycleGAN models need to be trained on a pair of subgroups beforehand and used during CAMEL training. Even StarGANs are used, $\\|\\mathcal{Y}\\|$ StrarGANs are required.\n\n# Feedbacks\n\nThe paper will be improved if generated images of CycleGANs are presented to visually show how CycleGANs change subgroups.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}