{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper shows that hat if the goal is to find invariant mechanisms in the data, these can be identified by finding explanations (e.g. model parameters) that are hard to vary across examples. To find those \"explanations\" it then proposes to combine gradients across examples in a \"logical AND\" fashion, i.e., pooling gradients sing a geometric mean with a logical AND masking. All reviewers agree that the direction is very interesting. While indeed mentioning sum and products of experts might be good, the overall idea is still very much interesting, also to the ICRL community, since it paves the way to apply this to larger set of machine learning methods, as actually shown in the experimental evaluation. Still, the authors should make the link to causality more obvious from the very beginning. This should also involve clarifying that \"explanations\" here do not refer to \"explanations\" as used in Explainable AI. Overall, this is an interesting and simple (in a positive sense) contribution to the question of getting at least \"more\" causal models. "
    },
    "Reviews": [
        {
            "title": "Evaluations of Paper \"Learning explanations that are hard to vary\"",
            "review": "The authors introduce and formalize the concept of Invariant Learning Consistency (ICL), which is motivated by the idea that \"good explanations are hard to vary\" in the context of deep learning. Instead of using the arithmetic mean to pool gradients (logical OR), the authors propose to use the element-wise geometric mean of gradients with a logical AND masking. Experimental results on both synthetic and real-world data sets are reported under the setup of supervised learning and reinforcement learning. \n\nThis paper is well written and clearly presented. The exploration of using geometric mean with a logical AND masking to pool gradients in deep learning is very interesting and novel. The proposed method learns invariances in gradient-based optimizations and can help with the memorization issue. This work has made good efforts towards a better understanding of learning, memorization and generalization of OOD. Experimental results on both synthetic and real-world data sets have demonstrated the effectiveness of the proposed AND-mask, comparing with commonly used regularizers and several baselines. \n\nAs the authors point out, the AND-mask is one of multiple possible ways to improve consistency, and it is unlikely to be a practical algorithm for all applications. It would be great if the authors can provide further insights on what kind of data distributions (or applications) could potentially benefit from the proposed method versus using the arithmetic mean. In addition, it would be interesting to explore hybrid methods that combine the advantages of pooling gradients using arithmetic mean and geometric mean (i.e., AND-mask).",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting",
            "review": "this work posits that invariant mechanisms exist in a dataset. a machine learning algorithm that is trained using gradient descent usually averages gradients across examples. the thesis is that by averaging gradients, information is lost. the method posits that in a gradient descent algorithm, instead of an arithmetic average, a geometric (or karcher) mean can be used to preserve information about invariant mechanisms - while ignoring confounders. there are difficulties in a straightforward application of the geometric mean, so a simple heuristic algorithm is developed, involving masking gradients depending on whether the sign of the gradient agrees across a batch of examples (or, whether some agreement threshold is reached). this algorithm is tested on a synthetic dataset, a semi-synthetic task on CIFAR-10, and coinbase, an RL algorithm. \n\nrecommend major revisions and baselines. it is interesting ideas and it would do the ideas justice to put a lot of effort into a rewrite so the ideas are properly understood by the ICLR community. clarity needs to be significantly improved in the introduction and conceptual framing (mainly in intro/methods sections)—the rest of the paper is largely well-written, the experiments are well-documented in the appendix, relationship to invariant risk minimization and causality is documented in appendix.\n\nbaselines: sum vs geometric mean is a well-known effect in products of experts vs sums of experts work. i think this should be the right baseline to compare to. train separate classifiers and use them as a product of experts, and you should get the same performance as in this paper. definitely need to discuss this related work and how learning consistency /geometric mean measures differ and warrant comparison.\n\nthe writing is more difficult to read than it ought to be. more work is needed to re-use existing concepts. for example, consistency is overloaded here (it might confuse some readers from a statistics background). the paper's title has the concepts of varying and explanations (variance and explanations do not appear in the method). small things like this abound. trying to find specific examples where i have a strong opinion to help:\n\n* instead of consistency, it may be worth spending some time to think of another word that is less confusing. congruence? concordance? 'learning invariant mechanisms with geometric mean gradient descent' is an example of a title that would be easier to understand: (1) mechanisms relates to prior work such as the pearl work that is cited (indeed, in the appendix the authors state 'causality... is a key element informing our exposition'). a causal mechanism is a well-known concept to the ICLR community. (2) concordance is still overloaded (e.g. this is a major concept in biostatistics) but not to the degree that consistency is. similarly, if you choose congruence, this could have the nice geometric interpretation in the hessian example that is helpful for understanding the work in figure 3.\n\n* the david deutsch quote distracts and confuses, remove it (i also know some researchers that might be immediately skeptical of a david deutsch citation in an ICLR paper). see above for ideas on title changes.\n\n* the first example is helpful to understand the goals of the paper. however, figure 1 --  the symbol with the plus sign and arrow is confusing, all the axes tick labels need to be much larger\n\n* the 'an example' chess example in the gray box on page 2 is unnecessary and distracting. instead, the discussion of the relationship to arjovsky et al could be inserted (with grass and cows), which is much more interesting and useful to a reader. \n\n* equation 1 engenders a double negative throughout the conceptual framing of the paper. i highly suggest considering renaming this to a 'consistency' score to reflect the name of the method; this will make it easier for readers to understand. \n\n* 'patchwork' may be another jargon word, try to find another one that is easier to understand. on page 3: 'low consistency of a classic patchwork solution' is loaded with jargon. first, a patchwork solution is not defined here or in previous work. second, a 'classic patchwork' solution is more confusing. removing adjectives such as 'classic' or even 'patchwork' throughout the paper may help readability and clarity. \n\n* i found the synthetic memorization dataset very difficult to understand. never start a sentence with math like p(y | x_{d_M}), it looked like it was connected to the previous with a \\cdot. ideally write out the functional form of the mechanism. the axes in figure 5 are not labeled, so i have a hard time understanding what we are looking at: are the x and y axes d_S or d_M? how is environment A vs environment B defined? \n\n* re: wording -- ideally delete shortcuts. do not introduce more unnecessary lingo, because it leads to sentences like 'the shortcuts are not shared across environments, but provide a simple way to classify the data, even when pooling all the environments together'. this is asking a reader to do a lot of work: (1) what is pooling? this has a standard usage. (2) what are environments? this is used in RL (3) what are shortcuts, and how do they relate to environments? trying to rewrite this, i would want something with fewer novel concepts, that focuses on mechanisms that are invariant across datapoints or groups of datapoints (groups of data arising from causal graphs, e.g. in causal inference terminology).\n\n* extremely minor, a few typos and inconsistent capitalization (section 3.1 is not capitalized, figure titles not capitalized, paragraph headings, figure legends not capitalized , good to pick one and stick to it)",
            "rating": "2: Strong rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This paper studies learning invariances to improve generalization of models. The paper is novel and solid, thus I suggest acceptance of the paper. ",
            "review": "This paper investigates one possible pitfall of current gradient descent method that averaging gradients over different examples failed to capture the invariance between different examples, through it can learn quickly by memorizing data. The authors claim that this is one important reason that machine learning with GD can't generalize well to out of domain dataset. To solve this issue, this paper focus on developing a method to learning the invariant explanations. The authors firstly formalize the a notion of consistency of the loss surface and also propose a practical algorithm, AND-mask. The authors also carried experiments and analysis on synthetic dataset to validate the effective the method. Overall, the work is important and the paper is well presented. I vote for accepting. \n\n\n##########################################################################\nPros \n\t1. The paper studied the important problem of model generalization. The paper is well motivated and the knowledge presented can benefit the community. \n\t2. The paper defines the invariance as the consistency for minima of the loss surface. The author presented case study examples as well as math formulations. The presentation is clear and easy to understand.\n\t3. The authors validate the value of capturing invariance through the implementation of a practical AND-mask, and run experiment on a set of tasks. The baselines are reasonably chosen. The proposed method greatly outperforms other baselines. \n\t4. The synthetic tasks unveil the difference between ILC and gradient averaging. It is very helpful for the readers. \n\n##########################################################################\nCons\n\t1. The work claim that they run experiments on a set of real-world tasks. The authors introduce artificial label noisiness in CIFAR-10 by randomly shuffling the labels. However, recently work (e.g https://arxiv.org/pdf/2001.10528.pdf) found that noisiness exists in many popular datasets. It would be interesting to show that ILC can also handle such naturally introduced noises. \n2. What is the connection between invariance and model casual explanation?",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Ingenious approach to learn invariant solutions across environments but connections to causality are too vague",
            "review": "The authors attempt to recover invariant solutions, defined as those with a similar loss neighbourhood across environments. This concept is interesting, especially since it can be incorporated with a clever understanding of loss gradients and hessians which underlies the generality of the proposed approach. \n\nThe presentation is puzzling to me. The objective for all intents and purposes is to recover the causal solution from data in multiple environments, but this is never explicitly mentioned even though causality is said to be a \"key element\" in the Appendix. In this area, also precise conditions are needed on data distributions from different environments which seem to play no role in this paper. A more thorough description of what can be expected from invariant solutions and when we are expected to consistently recover them is needed in my opinion. The introduction is therefore also vague, what do we mean by generalizing out-of-sample? Is the objective to ensure good performance with arbitrary shifts in distribution while maintaining a causal graph? Is there an assumption that the invariant mechanism is unique among available environments?\n\nRegarding the ILC, hessians and gradients I do see they are related but it is not lear to me how changing hessians would lead to optimizing for the ILC. The ILC is defined with respect to all local minima, I am not sure how such an objective would be attainable. More details here would be helpful.\n\nIn general, I found all experiments highly constructed and nothing like what you'd expect to see in reality. If the objective is improved performance out-of-sample, why not evaluate the method on domain generalization tasks (office, caltech datasets, etc.)? Invariant solutions may also be defined as minimizing a worst-case optimization problem across environments, yet the robust optimization literature is not mentioned.\n\nMinor comments:\n- I may be misunderstanding, but as described in the Appendix, does the synthetic experiment have shortcuts for both labels sampled from the same distribution?\n- With unobserved confounding, it is known that the causal solution does not have zero loss gradient (for example in a linear model, least squares returns biased parameter estimates), what can we expect in that case?\n\n\nIn summary, I do believe the proposed approach to be interesting but the context in which it is expected to work, as well as its relationships with causality, robust optimization and domain generalization are not well described; this prevents me from raising my score at this moment. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}