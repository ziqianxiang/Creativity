{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes to enhance the robustness of RL and supervised learning algorithms to noise in the observations by dropping input features that are irrelevant for the task. It relies on the information bottleneck framework (well derived in the paper) and learns a parametric compression of the input features that sets them to zero if they are not relevant for the taskn. The method is extensively evaluated on several RL tasks (exploration in VizDoom and DMLab with a noisy “TV” distractor) and supervised tasks (ImageNet or CIFAR-10 classification with noise).\n\nReviewers have praised the idea, derivation and writing, as well as the extensive experiments on RL and supervised tasks. Critique focused on:\n* the contrived nature of the TV noise (localised always in the same corner of the image -- a standard evaluation according to the authors),\n* lack of comparison with other feature selection methods,\n* lack of comparison with Conditional Entropy Bottleneck (done during rebuttal),\n* more general noise than just specific pixels (clarified by the authors as being the features coming out of a convnet)\n\nGiven that the reviewers’ comments were largely addressed by the authors, and given the final scores of the paper, I will recommend acceptance.\n"
    },
    "Reviews": [
        {
            "title": "information bottleneck that drops input features with probability p",
            "review": "Summary:\nThis paper proposes an information bottleneck method, Drop-Bottleneck, that allows the input to be compressed by dropping each input feature with probability p_i. The model then learns the drop probability vector p = [p_1, ... , p_n], where dropping \"redundant\" features will reduce the \"compression penalty\" term I(XZ). The approach is demonstrated in experiments in (1) robust exploration setting for RL, (2) adversarial attacks on ImageNet, and (3) an experiment showing that their approach is able to maintain performance on ImageNet with reduced dimensionality.\n\nEvaluation:\nI found this paper to be clear and the experiments seem reasonable. I don't know of any prior work that takes this approach. I'm not an RL expert so I won't comment on the strength of the RL results, other than that their methods were clear and they seem to have been careful and fair in choosing baselines. My biggest criticism is that the robustness experiments on ImageNet compare to VIB (Alemi et al 2017) as a baseline, but they should really compare to the more recent adversarial results on Conditional Entropy Bottleneck (another information bottleneck approach that outperforms VIB) given in Fischer and Alemi 2020 (https://arxiv.org/pdf/2002.05380.pdf). I'd like to see that added to the revised version.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting idea but a little bit too simple?",
            "review": "**Summary**\nThis paper proposes the Drop-Bottleneck (DB) method that performs feature selection during the training with the mutual information. It achieves the state-of-the-art result in few reinforcement learning tasks, and trains a more robust model.\n\n**Originality and significance aspect**\nThis paper combines mainly two ideas 1) classic feature selection (choose Xis to drop) with respect to the mutual information (between X and Y) 2) Information Bottleneck (IB) formulation that maximizes the prediction-term mutual information term (between Z and Y) and minimizes the compression information (between X and Z) simultaneously. It is actually fairly close to the core idea of the feature selection because it finds the compression by dropping the original feature or not unlike the other IB compression methods. In other words, DB is a modernized version of the feature selection that automatically drops a feature based on the IB-style loss. I would say the idea is not entirely new (somewhat limited), but it could be still useful to the community. \n\nIn the significance aspect, I wanted to see authors to apply this method on other noisy setup tasks (e.g. computer vision tasks with noise), outside of the reinforcement learning tasks. The improvement on the RL tasks seems to be substantial; however, I would like to know how DB performs when there is correlation between feature dimensions (see below clarification question to see more details).\n\n**Quality and clarity aspect**\n\nThe paper was overall easy to follow. Here are a few questions to authors:\n\n* What if we just drop the feature space only using the mutual information between X and Y and drop them to achieve a similar number of features that was resulted by DB -- it is basically the classic mutual information feature selection. Would that perform as good as DB? Can you make a comparison?  I think this should be one of the baseline. If that's similar to DB, what would be the benefit of DB?\n* Does DB always minimize \\hat{I}(Z; X) -- with the independent assumption? When some of the Xis are correlated (e.g. consider a vision task), there could be quite a gap between I(Z; X) and the independent assumption version. \n\n**Recommendation**\nI think the paper is at the borderline. Looking forward to seeing more discussion with the classic feature selection method and some evaluation on tasks outside of RL (if possible). I would be happy to revisit my score\n\n\n-----\n**Post rebuttal comment**\nI thank the authors for the rebuttal. Authors have addressed my concerns and clarified some of the confusing points that I had. I would like to recommend this paper to be accepted.\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A simple yet efficient idea for a new IB objective that works well across the board",
            "review": "The paper proposes a new Information Bottleneck objective, which compresses the latent by learning to drop features similar to DropOut. Unlike DropOut, a different probability is learnt for each latent feature/dimension using Concrete Relaxation. The experiments show that the works well.\n \nOverall, I score this paper as an accept. While the approach is limited to dropping input features, which does not make it a general IB objective, it seems to work very well in the presented RL experiments as well as show robustness that is better than DVIB’s. Moreover, the paper is clearly written and engaging.\n \n### Strengths\n \nThe paper proposes a simple yet effective idea. Using a Concrete Relaxation to learn DropOut probabilities has been done before, but the idea to have a separate probability per latent dimension is novel. The Drop-Bottleneck objective works directly on the input/latent layer, which means that the compression objective is easy to compute. This is nice because IB terms are usually cumbersome to compute. (However, this also requires the input/latent to already be disentangled, as dropping out features is limited in its expressiveness.) \n \nThe RL experiments on VizDoom and DMLab are convincing as are the ones on ImageNet. The additional experiment on the Occluded CIFAR-10 dataset in the appendix is also well thought-out and shows the advantage of this straightforward method over DVIB.\n \nMoreover, once trained, features can be dropped out deterministically if so required, which allows for proper compression and consistent behaviour.\n \n### Questions\n \nGiven the simple conceptual idea, this reviewer would be interested to see an ablation with using other methods of enforcing sparsity in the latent. Could L1 regularization of the latent activations be used instead of the $I[Z; X]$ term?\n \nDB cannot provide the same generality as other IB objectives: the input (latent) has to be sufficiently disentangled already as the objective itself does not encourage further disentanglement by itself. Do the ImageNet experiments use extracted/pre-trained embeddings as latents?\n\n---\n### Rebuttal\n\nI thank the authors for their reply. I'm more confident this is a good paper now.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "I am leaning towards recommending to reject this paper, mainly because the focus on the noisy TV problem is very narrow and the additional experiments on ImageNet do not fit to the paper's focus. Furthermore, the work does not discuss its relation to other feature selection works. However, the ImageNet experiments show that the presented idea can be useful.",
            "review": "Summary:\nThe paper contributes a novel method, Drop-Bottleneck (DB), for discretely dropping input features that are irrelevant for predicting the target variable. Key idea is to instantiate the compression term of the information bottleneck framework with learned term that sets irrelevant feature dimensions to 0. To this end, a drop probability is learned for each dimension. Dimensions that have a lower probability than 0.5 (a fixed threshold) of being relevant are set to 0.\n\nStrong Points:\n- The paper is well-written and easy to understand.\n- Experiments show that DB works better than VIB in VizDoom and DMLab when a noisy-TV noise is added to the input images. Different noisy-TV noises are considered: changing the image when the agent performs an action, adding random noise to the TV, and adding random noise when the agent performs an action.\n- Experiments also show that the obtained representation is more robust against l_2 and l_inf attacks in ImageNet. Furthermore, the experiments show that the approach can drop many ImageNet features while almost preserving the accuracy of a ResNet.\n- The paper comes with code in the supplementary material.\n\nWeak Points:\n- I found the reinforcement learning experiments not convincing since only a fixed region of the input is modified by noise (ie. the noisy TV). Hence, the approach essentially identifies irrelevant pixel locations. Such a problem could be solved by a simple pre-processing step. The method won't work if the location of the noise changes. In general, limitations of the work are not discussed.\n- The experiments on ImageNet are more interesting. However, the fact that individual dimensions (i.e. specific pixel locations) are identified as irrelevant is still a limiting factor. Furthermore, the experiments do not fit to the focus of this paper on reinforcement learning.\n- The paper does not discuss connections of the presented approach to prior works for (discrete) feature selection. It only discusses connections to prior bottleneck methods.\n- The paper does not perform experiments on datasets with meaningful features where a feature selection makes more sense than for specific pixels in images.\n\nAdditional feedback:\n- It could be stated explicitly that H refers to the entropy. Currently, it is only implicitly defined in Eq. 6.\n- I think it would be better to also cite Jang et. al (Categorical Reparameterization with Gumbel-Softmax) for the Concrete relaxation of the Bernoulli distribution.\n- Figure 1 should either be improved or removed. I don't see much additional insights that can be gained from this figure.\n- Of course, it would be very interesting to see if the drop probabilities correlate with the location of the noise inputs. It would be great if such an analysis could be added. This could replace Figure 1.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}