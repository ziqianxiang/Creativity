{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper was reviewed by four experts in the field. Based on the reviewers' feedback, the decision is to recommend the paper for acceptance to ICLR 2021. The reviewers did raise some valuable concerns that should be addressed in the final camera-ready version of the paper. The authors are encouraged to make the necessary changes and include the missing references."
    },
    "Reviews": [
        {
            "title": "A tidy model, with impressive results",
            "review": "Summary:\n\nThis paper introduces a method for predicting future trajectories of sets of objects.\nThey generate features for each object in the scene using a CNN followed by ROIPooling for each object.\nThey employ Interaction Networks to implement an update function that uses the relations between the object states.\nBecause they use spatial features for each object, they update the original Interaction Networks to take spatial blocks as opposed to vectors with convolutions instead of mlp's.\nTheir models output predicted bounding boxes, but can also be trained to output a mask (21x21) for each predicted object bounding box.\n\nReason for Score:\n\nI vote for accepting.\nThe method is clear, and the results are good.\nI would be interested in applications of this method to real world video using off the shelf object detectors.\n\nPros:\n\nROIPooled object features from CNN outputs have been demonstrated to be packed with information about both the objects and their context.\nThe enhancement to the original Interaction Networks (using convolutions) seems to bring performance improvements (Table 1).\nThe videos (especially for PYHRE dataset) are impressive.\nThe benefits of being able to make long term predictions when planning are clear.\n\nCons:\n\nI am a little worried about the size of the input images (eg. 128x128 for PYHRE ) and the size of the spatial output of the CNN that is used for ROIPooling of the objects. I cannot see this size in the paper (should be in A.1?). It seems it might be too small to properly use ROIPooling that discriminates between close objects.\nI am not sure the baseline comparisons are very fair, since it is stated that they are either video based or do not have mechanism to cope with \"background\" objects.\n\n \n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Simple, effective method to incorporate spatial information in learning visual dynamics",
            "review": "The authors propose a novel architecture RPIN (region proposal interacion networks) to learn physical interaction dynamics directly from visual input using region of interest features and a convolutional interaction module which retains spatial information. The authors showcase improvements in 4 different datasets for long term prediction, planning and generalization.\n\n\nStrengths:\n* Simple and effective idea to encode spatial information and use environment information via convolutional and RoI features respectively.\n* Improvements on RealB and Phyre-C seem to be very promising (esp in the longer than training horizon setting).\n\n\nWeaknesses:\n* Evaluation and insight into how changing feature representation for interaction networks impacts long term prediction seems to be missing from the paper.\n\nQuestions: \n\n1. How does Fp (equation 2) work for scenes with different number of objects as your number of channels would change with changing number of objects in a scene.\n\n\n2. The authors mention that \"In SimB, the improvement is not as significant because there is no environment information needed to infer future dynamics\". This doesn't seem to be true as you need scene context to perform prediction even in the simulated environment?",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Leaning towards accept, but low technical novelty",
            "review": "*Summary*: The paper presents a DNN for learning dynamical models using the SOTA in deep learning-based computer vision literature.\n\nStrengths:\n1. The main strength of the paper is that it uses the SOTA in computer vision (DNNs for image and object understanding) to achieve a different goal in an area in which research has not yet matured (at least to my understanding). By doing so, it helps stimulate and ease further research in the latter area .\n\n2. There are clear experiments that effectively demonstrate the contribution of the paper.\n\nWeaknesses:\n\n1. I would like to have seen some qualitative comparisons with the baselines to get a better sense of the superiority of the method.\n\n2. The technical novelty is low as it seems the main technical contribution is to only replace the MLP from related work with a ConvNet\n\n\nComments/Questions to authors:\n1. In the introduction, you write *\"... those methods operate in the state space, or ignore the environment information\"*. Could you elaborate a bit on this point. Folks outside the field may not understand what it means to \"operate in the state space\" and why it that not good ?\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Promising approach with object centric representations",
            "review": "Paper Summary\n-----------------------------------\nThe paper proposes a variation of interaction networks (IN) called region proposal interaction networks. The key idea is to have a richer object-centric feature representation using ROI-Pooling to encode the objects for prediction and use convolution operators to help the IN handle the change in the dimensionality of the feature representation. The paper is well-written and is evaluated on several popular benchmarks. The proposed variations seem to have a considerable effect on the performance to offer significant gains on challenging benchmarks.\n\nComments:\n- The predictions for time t+1 is a function of features from t-k to t. What is the value of 'k' used in the experiments? How is this chosen? Does this change across datasets, environments, tasks, etc.? k has a direct effect on the number of parameters in the network W_p and it would be interesting to see how it affects the predictions.\n- On that note, are the object features re-computed using ROI pooling at every time step, or are the predicted features used recursively? Have you tried generating frames based on the predictions to see if it helps capture the interaction/context between the different objects in the scene based on predictions? \n- How are the objects registered across time? In other words, is there some tracking used to map the object bounding boxes across time to ensure that consistency is enforced when modeling the interaction of the same object over time? If there is no explicit registration, then is the interaction modeled on a per-frame basis i.e. ground truth is used to ensure that the features of each object are used for its interaction modeling? If the GT is used, then I am not sure how would the model fare without access to such explicit information when encountering unseen objects?\n- I am not convinced about the use of the term 'spatial information' when using ROI pooling. From what I can see, ROI pooling results in a 3-d representation of the object as opposed to 1-d representations obtained when using cropped images. This offers a richer representation that captures object-centric features that is invariant to the spatial dimensions of objects. But I do not think that the spatial information is explicitly coded into the features are any point. \n- While the paper is well written, there are some inconsistencies in notations that are hard to follow. For example, in Equation 2, the parameters to the function f_Z has 'h' which in the writing refers to the height of the object-centric representation vector. Following consistent notations will greatly improve the readability.\n- The paper would benefit from a more thorough ablation study. There are several factors that are used in the proposed framework that could have a considerable effect on the performance but not discussed such as the temporal parameter 'k' mentioned above.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}