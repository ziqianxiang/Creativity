{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper studies the problem of visual question answering in multi-turn dialogues.\nThe proposed method is to identify relevant dialog turns as a path in a semantic graph that connects the dialogue turns. Empirical performance of the proposed method is strong. Reviewers concerns have been compressively addressed. Overall, the paper has novelty, and explores an interesting direction in this line of work."
    },
    "Reviews": [
        {
            "title": "Learned reasoning paths are very interesting but ablation studies show limited benefits of proposed components",
            "review": "This paper proposes creating a semantic graph connecting the multiple turns in a dialogue and subsequently learning reasoning paths in that graph to find the most relevant nodes for answering a given question in a dialogue context.\n\nStrengths:\n* This paper proposes to learn non-linear information flows in a sequential data which is a well-motivated problem.\n* The proposed method is novel. Training a transformer decoder to learn reasoning paths and using BFS supervision to find the ground-truth paths is very interesting (however empirical support that this is effective is lacking, see Weaknesses below).\n* The proposed approach significantly and consistently outperforms existing benchmarks on the AVSD dataset.\n* The illustration in Fig 3 demonstrates the benefit of using the selected nodes from the graph.\n\nWeaknesses:\n* From the results in Table 1, 3, it is clear that multimodal reasoning over \"relevant\" nodes in the semantic graph (termed as reasoning path in the paper) helps the model by reducing the noise. However, whether there is any benefit to learning that path is unclear from the ablation study present in Table 5 where there is no noticeable difference in the results between learned v/s fixed paths. In fact, \"Path through last 7 turns\" performs comparable to the \"Learned Path\" which raises question about the usefulness of transformer decoder based path learner.\n* Similarly results in Table 4 seem within noise error from each other, hence making the arguments \"component lexical overlap is better than global lexical overlap\" weak.\n* It is unclear if this approach of creating the graph (by finding pairwise semantic similarity) is scalable to real world datasets containing several turns with potentially large number of tokens. There is no analysis of information redundancy among the nodes of the graph which can help prune the graph.\n* The results are only presented on one dataset. The transformer decoder learning seems to be tuned to this particular dataset (\"greedy approach works better due to small size of V\"). This questions the generality of the proposed approach.\n\nQuestions / Suggestions\n* It is unclear what (if) makes this method specific to video-grounded Q/A. Can this methodology be applied to other problems involving dialogues? Can this be applied to any problem containing time series data?\n* There needs to be some discussion as to why RLM performs better/comparable (Table 1) when using pretraining.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Moderate contribution but lacking some details concerning the implementation",
            "review": "The paper studies the problem of video-grounded multi-turn QA and adopts reasoning paths to exploit dialogue information.\n\nSequential: fail to exploit long turn dependencies\nGraphical: fixed structure, fail to factor temporal dependencies\nThe proposed reasoning path method: balanced between sequential and graphical\n\nIt first constructs a turn-level semantic graph based on overlapping lexical span:\n- Extract lexical spans from each turn (<Q, A> pair) using a (Stanford) parser\n- Two turns are connected if one of their corresponding lexical spans are similar (in terms of word2vec embedding).\n\nThen it trains a path generator to predict paths from each turn to its preceding turns:\n- It starts from the current turn and auto-regressively finds the most dependent preceding turn with Transformers\n- The turn-level semantic graph is used to mask the dependencies.\n- It is trained with supervised loss where the target paths are constructed by running BFS on the semantic graph\n\nFinally, the proposed paths are used to employ multimodal reasoning:\n- Visual features are combined with turn level attention\n- Multi-model turn-level embeddings are propagated using GCN\n- Then use SOTA decoder to generate language response\n\nThe author conducts experiments on a benchmark, and the proposed method achieves better QA performance than SOTA without a pre-trained language model and achieves comparable performance when the pre-trained language model is involved.\n\nThe author further studies different variations of graph structures and show that using graphs constructed based on lexical spans is better than fully connected graphs or graphs based on whole sentence embedding. And it also shows that including bidirectional edges does not necessarily improve the performance.\n\nA nice feature of the method is that the generated reasoning path can serve as extra explanations for the answer.\n\nSome concerns:\n\n- The model is graph-based thus is restricted to scenarios with a small number of turns, and becomes computationally expensive for long-conversation scenarios.\n- Need a more detailed explanation of how the message passing part (section 3.4) is trained.\n- Each pair of turns may share multiple pairs of lexical spans that are identical, e.g. Figure 3-A, “she” in turn 10, but there are 2 “she”s in turn 9. Does the frequency influence the similarity?\n- It would be more convincing if it gives an analysis of failure cases.\n- Section 3.3: Eq.(4), what is the initial $D_0$ correspond to $Z_0$?\n- The reasoning path generator uses $C_t$ as input, does it include $A_t$ during inference?\n\nMinor concerns:\n\n- Many symbols are used before their definition:\n    > Explanation of $\\mathcal{V}$ is first given in Algorithm 1 (section 3.2) but first used in Eq.1 (section 3.1).\n    > Section 3.3, 2nd paragraph, 4th line: undefined symbols $\\hat{r}_1,\\dots,\\hat{r}_{m-1}$. They are later mentioned as turn indices in section 3.4, last line of page 5.\n- Page 5, line 2: “incorporate” —> “incorporates”.\n- Index m is used as a word position in Eq.(1) but becomes a decoding step from section 3.3.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting engineering contribution, but the underlying principle seems not really new and lack of discussion with relevant related works",
            "review": "Summary:\n\nThis paper addresses the visual question answering in a multi-turn or conversational setting. Given a video (series of frames or images), a model has to reason across space and time to arrive at a correct answer for a given question. This task involves understanding the content and context of dialogue turns, i.e., given a question and N dialogue turns, only M<<N of the dialogue turns are strongly related to the question posed. This paper proposes to simulate the dependencies between dialogue turns, forming a reasoning path, to answer a given question. In a way, the proposed approach selects relevant dialogue turns that are useful to answer the question.  \n\nThere are two steps to make the reasoning path:\n(1) At each dialogue turn, a graph network is constructed at the turn level. Any two turns are connected if they have an overlapping lexical span or if their lexical spans are semantically similar.\n(2) Secondly, a path generator is trained to predict a path from the current dialogue turn to past dialogue turns that provide additional and relevant cues to answer the current question. \n\nUltimately, the main idea to create a reasoning path is based on compositional semantic similarities.\n\n\n\nComments (Technical, Major Flaws of this paper): \n\n(A) I am not sure whether the author(s) is aware, but from the NLP perspective, the current method (step 1) is trying to simulate the discourse structure of dialogues. I believe that this is an important direction, and the uniqueness of this works lies in the multi-modality of the input, i.e., possibility of the interplay between texts and images (using the information in both modalities). \n- The claimed novelty in this paper is in the construction or usage of reasoning graph, i.e., to construct a graph structure to connect turn-level representations in dialogue. However, in Step 1, the use of entity and/or compositional similarity to create a graph structure out of a text is not new at all, and the paper fails to cite related works, as if it is the first one to propose this. In fact, the idea has been used in NLP for a long time (albeit mostly in the monologue). \n- I am not sure whether combining entity with action phrases (called \"lexical spans\" in the paper) is new. Can you confirm whether the proposed \"lexical spans\" is indeed new to construct/simulate the discourse structure?\n- Regarding step 1, perhaps the main contribution of this paper is applying the idea to dialogues, instead of monologues? Another possible contribution is \"filtering out\" unimportant semantic relations. In normal discourse structure, all parts of texts are connected in a single structure. However, in the context of this paper, only edges that are relevant to the posed question are used. \n- Unless the paper can discuss the related NLP works for step 1, I can only treat this paper as the extension of the corresponding NLP method in a multi-modal setting. There is an engineering contribution, but not from the methodological (theoretical) perspective.\n- I think the author(s) will benefit much by surveying papers on discourse structures (or the ``shallow\" construction of them), instead of machine reading comprehension. Many studies tried to establish discourse structure (albeit in a monologue) using entities that are mentioned and their semantic representations. A few of such works are:\n  R. Barzilay and M. Lapatta. 2008. Modelling Local Coherence: An Entity-based Approach. https://www.aclweb.org/anthology/J08-1001.pdf\n  C. Guinaudeau and M. Strube. 2013. Graph-based Local Coherence Modeling. https://www.aclweb.org/anthology/P13-1010/\n  J.W.G. Putra and T. Tokunaga. 2017. http://www.aclweb.org/anthology/W/W17/W17-2410.pdf \n- The currently proposed method step 1 seems to be the combination of entity graph + semantic similarity graph in these related works, but the current paper \"filters\" only edges relevant to the posed question. \n- A related work to construct the discourse structure in dialogues:\n+ G. Morio and K. Fujita. 2018. End-to-end Argument Mining for Discussion Threads Based on Parallel Constrained Pointer Architecture. https://www.aclweb.org/anthology/W18-5202.pdf\n\n(B) The reasoning model, which is a combination of GCN + transformer can be interesting. However, the idea of cross-modality representation refinement is somewhat similar to what has been studied in VQA.\n  Le, T. M., Le, V., Venkatesh, S., & Tran, T. (2020). Dynamic Language Binding in Relational Visual Reasoning. In IJCAI 2020.\n  Gao, P., Jiang, Z., You, H., Lu, P., Hoi, S. C., Wang, X., & Li, H. (2019). Dynamic fusion with intra-and inter-modality attention flow for visual question answering. In CVPR 2019.\n\n(C) After constructing the reasoning path (in response to the given question), the next step is to decode such representation to generate the answer. This paper proposes to use the transformer model to do that. I believe the use of the transformer model to generate text is not new. In fact, the author(s) mentions this in the paper (the last paragraph of Section 3.4). \n\n(D) In overall, if we look at the pipeline (system) level, the proposed pipeline is new (the whole process). However, I seriously concern about the step (1) of the proposed method (page 1). My main concern about this paper is its lack of awareness of related works in text processing (step 1 of their method). In fact, it fails to cite relevant works (that are very similar to this work). I might appreciate this paper in terms of engineering contribution (in a multi-modal setting), but I cannot acknowledge that step 1 is novel. Having that said, I think the authors need to provide a comparison to related works, proving the novelty of the current method. I am willing to increase the rating if the authors can properly address my concerns during the rebuttal phase.\n\n(E) The content from 3.3 to 3.4 is very hard to follow. \nCorrection of terms:\n\t- linguistic dependency parsers --> \"syntactical\" dependency parsers (this is the correct term)\n\t- linguistically, the term \"lexical span\" is weird. A span is a series of continuous lexicons (in the text surface). I suggest using a better term, as the \"lexical span\" in this paper might be discontinuous (do I misunderstand?).",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}