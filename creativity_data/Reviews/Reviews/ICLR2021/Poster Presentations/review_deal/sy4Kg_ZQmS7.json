{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The reviewers appreciated the paper's applied neural net approach to the problem of designing features for 2SLS regression for IV analysis as an alternative to sieve approaches. The paper would make a good contribution to ICLR. While the paper does not focus on theory -- learning data-driven features appears to be mostly heuristic -- it should still be grounded in a sound approach to the IV problem, and the reviewers recommend various important technical clarifications regarding the foundations of IV models; the authors should implement these suggestions very carefully and correctly in future versions. For example, even if the structural models are well-specified in that Eq. (5) holds for some parameters, since the dependence is non-linear on parameters, it is not clear when we should expect this to be identifying of (theta_X,theta_Z) (these are in fact not identifiable in general) and when we should expect the proposed method to be consistent."
    },
    "Reviews": [
        {
            "title": "Promising results, concerns with the assumption, theoretical justifcations, and experiments",
            "review": "Summary:\n\nThis paper proposes the deep feature instrumental variable algorithm that has two stages of regressions and uses deep features. This paper demonstrates that this algorithm has a good performance on several applications.\n\nThis paper is generally well written. Moreover, the experimental results look promising. However, this paper does not theoretically justify its solution that is in general relevant in the IV literature. Instead, this paper emphasizes its algorithm's prediction performance.  It needs some clarification and justification on why the results in this paper can help people better identify and correctly estimate causal effects, which is the primary goal of IV (inference is important in IV). Also, there seem to have some issues with the assumption. \n\nMajor comments:\n\n1. Identification: The purpose of IV is to identify and consistently estimate the causal effect in the presence of the unobserved confounders (Angrist et al., 1996). How can we uniquely identify the treatment effect using the DFIV algorithm? And why is the causal effect estimated from the DFIV algorithm consistent? As a reference, causal effects estimated from 2SLS are consistent and asymptotically normal. Moreover, Theorem 2 in Bennett et al (2019) shows the estimated parameters (and treatment effect) converge in probability to the true value. Since IV is not generally used for prediction problems, a careful discussion on identification (and consistency) will be helpful.\n2. Assumption 1: In 2SLS, Assumption 1 ($\\mathbb{E}[\\varepsilon|Z]=0$) is sufficient to prove the estimated treatment effect is consistent and asymptotic normal because the model is linear. However, this assumption is not sufficient for the DFIV algorithm because $\\phi(Z)$ is nonlinear. It seems the correct assumption is if $\\phi(\\cdot)$ is unknown, then $\\varepsilon$ needs to be independent of $Z$; if $\\phi(\\cdot)$ is known, then $\\mathbb{E}[\\varepsilon|\\phi(Z)]=0$.\n3. Off-policy policy evaluation experiment:  First, what is the treatment variable in the problem? Second, why does this application use absolute error while the demand and dsprites application use out-of-sample MSE? Third and most importantly, the IVs used in this paper are $Z=(s,a)$.  Why is $\\mathbb{E}[\\varepsilon|Z]=0$ or $\\varepsilon$ independent of $Z$ given $\\varepsilon$ is also a function of $s$ and $a$ because in the two expectations in $\\varepsilon$, $s^\\prime  \\sim P(\\cdot|s, a)$ and $r\\sim R(\\cdot|s,a)$? \n4. dSprites experiments: The outcome variable $Y$ is quite important when people use IV, but it is not stated in the main text that seems to be confusing. What is the interpretation of $Y$ based on the DGP provided in Appendix D.2? Why should we care about this $Y$?\n\nMinor comments:\n\n1. Typo: P2. six to the last line: \". an unobserved confounder\" -> \". $Z$ is an unobserved confounder\". \nP2. last line: \"which we assume to be a continuous\" -> \"which we assume to be continuous.\"",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting Idea; Conservative Score",
            "review": "The authors consider the problem of learning the structural equation governing the relationship between a treatment and outcome in a causal model. They assume an instrumental variable setting and use neural networks to fit non-linear models as part of the conventional 2SLS approach to parameter estimation in IV models.\n\nIn general I found the paper to be pretty clearly written and I think it shows promise. That said, there are some points of confusion/clarification discussed below. In light of these, I've opted to conservatively score this paper as a weak reject for the pre-rebuttal/pre-discussion phase and will reevaluate and consider raising my score later in the review process.\n\nDetailed comments (major concerns denoted by **):\n\nIn the intro (paragraph 3) the authors describe the characteristics necessary for something to be a valid instrument. I recommend also adding that the instrument Z cannot have an incoming edge from the latent confounder that is also a parent of the outcome.\n\nIn the intro the authors state \"Although these emthods enjoy desireable theoretical properties, the flexibility of the model is limited, since existing work uses prespecified features\". Can the authors clarify what's meant by \"prespecified\"? It's not obvious how exactly this is a limitation.\n\nIn a similar vein, later in the intro, the authors refer to DeepGMM as having an \"unstable\" learning procedure since it involves solving a smooth zero-sum game. The authors should clarify why this is the case, since many readers, especially in the more traditionalist IV community, may not be familiar with the subtleties of recent competitor methods like DeepGMM.\n\n**How does the assumption of additive noise constrain the problem? What happens if this assumption is dropped? Is the structural function then not identifiable? The authors don't seem to use this assumption later in their argumentation for why their method works and so I'm curious whether either i) the assumption isn't necessary or ii) the assumption is trivializing the problem in some way. In general additive noise is a pretty strong assumption and so this could drastically limit the efficacy of the proposed method.\n\nIn line with above comments about clarifying background details about competitor models, can the authors provide more background on Hermite polynomials?\n\n**I'm a bit concerned about the use of regularization in the fitting procedure (Equations 6 and 8). Both of these models are _nuisance_ models. While the authors frame the problem as trying to learn the structural function that governs the X->Y relationship, ultimately what a practitioner cares about is evaluating effects like E[Y(x) - Y(x')]. Traditionally, one has to be very careful about employing regularization in causal modeling since you might regularize an effect to zero in the service of trying to improve prediction performance for the nuisance model. As a toy example, consider a simple linear causal model where Y = Beta X. If the true effect for some element of X, say X_2, is small but nonzero (i.e. epsilon > Beta_2 > 0), then regularizing could make us learn a \\hat{Beta} such that \\hat{Beta}_2 == 0 which is a biased effect estimate. Perhaps the dynamics are different here because of non-linearities and the regularization does help empirically with the problem the authors consider. But in general I'm not sure that's the case -- the authors should clarify this point in their argumentation and think carefully about this issue in the context of their experiments.\n\n**Some questions about sample efficiency. The authors give some commentary on the computational complexity. This is certainly important, but typically of equal or greater concern is whether the models can actually converge to the true parameter. As far as I know, there are few (if any) results on the sample efficiency of NNs in general and so it's hard (impossible) to say whether or not they are consistent (converge to an unbiased estimator of the true parameter). Is there a sense in which this can be known for the class of NNs the authors consider? What is the rate of convergence of the fitting procedure?\n\nIn the airplane experiment, why does time range from 0 to 10 rather than, say 0 to 11 or 1 to 12?\n\nIs there a substantive interpretation for rho in the airplane example? Is there a reasonable latent confounder that this might correspond to that does not act as a causal parent of Z? I realize that it exists as an artifact of the simulation DGP from the Hartford paper but it makes the example somewhat weaker that it might not be something that can be mapped to a fully realistic modeling problem.\n\n\"This may be due to the current DeepGMM approach to handling observable confounders, which may not be optimal\" -- what is the 'current approach' and why is it suboptimal?\n\n**In the DSprites experiment, what is the outcome Y?\n\n**The authors should strongly consider adding an experiment in which they actually intervene on X. The task of learning f(X) is very close to estimating an effect, but I'm curious to know i) how well their algorithm actually does for effect estimation and ii) whether their model's outperformance relative to competitors is as drastic in that situation. In that case, because they are using a synthetic DGP, it would be possible to know the ground truth effect of the intervention and thus they'd have a principled way to evaluate the performance on the effect estimation task.\n\nTo the other reviewers/ACs, I'm not really qualified to evaluate the experiment and claims discussed in section 4.3 regarding off-policy evaluation. To the authors, however, in line with above comments about defining terms from the literature, many readers will not have a clue what things like 'catch and mountain car' are or what the details of the FQE model are and so you should strongly consider clarifying the task and details of the competitor model if space allows.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Nice paper!",
            "review": "The main idea in this paper is very nice and is as follows:\n\nSuppose we have the standard IV setup which is\nX = m(U) + f(Z) \nY = q(U) + b(X)\n\nWhere U is some unobserved confounder.\n\nTypically we are interested in the linearized version of this model. If we regress Y on X, we get a biased estimate of B(X) because U is a common unobserved cause. We can deal with this by first regressing X on Z, then regressing Y on the predicted values of X given Z. It is well known that using any other method than linear regression in this context leads to \"forbidden regression\" problems. So, typically people just estimate the average effect.\n\nHowever, with bigger data we might be interested in trying to get more precise estimates of the function b(X) and also f(Z). Typically this is done by hand-crafting a basis (interacting instruments with things, usually). The authors propose using deep networks to learn linear bases and then essentially do 2SLS on top of them (technically this is all trained together, but I am simplifying for the review).\n\nOverall, while I think there are many unanswered questions in this paper, I think it should be accepted for the community to build on it. IV is a tricky area and there is no way to show everything we need to know about a method in one paper.\n\nBelow I list several questions I had about the paper which I think the authors could incorporate in various formats (or educate me on how they have already answered them and I missed it):\n\n- Assumptions required\nThe authors state that the only assumption that is required is the standard exclusion restriction. I feel like that is not necessarily correct. For example, in 2SLS if we assume underlying heterogeneity (which, we must assume in this case otherwise why would we be learning a basis for this heterogeneity?) then if it the heterogeneity is not proxied by observed variables correctly we need some additional assumptions like monotonicity to get an interpretation of the IV estimate as some kind of causal effect (e.g. a LATE). Similarly, even with no covariates if we're trying to estimate the full function b(X), don't we need some assumption about how the IV affects X in the whole support in order to guarantee that we can use the IV to learn b(X)?\n\n- Regularization parameters \nAs I understand it, and the authors can correct me if I'm wrong, the hyperparameters for the regularizers are set by holding out some (x,z) and some (y, x) and then evaluating standard out of sample predictive loss? This is also what is done in DeepIV. This has been shown to not be an optimal way of choosing hyperparameters in Peysakhovich and Eckles (2018) which talks about \"Causal Cross-validation\" for adapting split-sample IV ideas from (Angrist & Krueger, 1995; Imbens et al., 1999; Hansen & Kozbur, 2014). The setting in that paper is specifically discrete instruments rather than continuous ones, so that procedure can't exactly be adapted in all the cases here, but it still may be worthwhile to mention as a future direction. Overall, hyperparameter tuning for these problems is really important and even more so when you have these deep feature generators.\n\n- Comparison to control functions / 2 stage residual inclusion\nCurrently the only comparison made are to other 2sls type methods where endogenous variables are changed to their predicted values. There is another way to estimate IV which is the control function/2 stage residual inclusion approach which seems to lend itself naturally to neural networks/function approximators since all you need to do is include the residual from the first stage into the second stage to get a correct estimate of b(X). It seems like it would be pretty easy to add this as a baseline to at least the high-D demand experiment.\n\nTypo:\nThe abstract states: \"In this case, deep neural nets are trained to define informative nonlinear features on the instruments and treatments.\" I believe this should say \"linear features\" in the sense that you are learning the correct basis for 2SLS?\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "interesting paper; experiments could be improved a bit.",
            "review": "I liked reading this paper. It is reasonably well-written and tackles an important problem in an interesting way. I list the issues I had with the paper below. I believe one advantage of DFIV is that it does not rely on some relaxed optimization problem like DeepIV. The main idea in the paper is learning a set of basis functions such that the structural function is a linear combination on them; the learning itself relies on predicting the basic functions from the IV which ensures that confounding information is projected out.\n\nFirst, while I think the method is well motivated, I am confused by the discussion around 'forbidden regression'. I believe the statement made in the paper about 'high variance' may be misleading. 'Forbidden regression' is a statement about the mis-specification of the conditional density model which may lead to an identification failure. Can the authors point out the exact part of Angrist where high variance is called the 'forbidden regression' problem?\n\nI think the proposed method does not face the forbidden regression problem because of the linear relationship between the IV and the outcome implied by the proposed model. \n\nSecond, I believe it would be in support of the method to expand the experiments to include the high-dimensional IV and treatment experiments from DeepGMM. \n\nI would like the authors to clarify the following:\n\n1. In 4.2, if the image is given as treatment to the model, isn't the confounder posY be specified as a function of the treatment?\n2. In the OPE experiment, the DFIV (and DeepGMM to a lesser extent) does not  exhibit monotonic behavior with noise increase. Could the authors explain if this is randomness? if it is not, could the authors provides results over a larger number of seeds?\n\nFinally, could the authors expand on any convergence issues during training due to the coupled optimization and how they fixed them? ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}