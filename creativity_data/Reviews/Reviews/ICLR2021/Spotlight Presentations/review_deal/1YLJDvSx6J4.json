{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Spotlight)",
        "comment": "This work uses a graph representation of the protein backbone and a GNN for model quality assessment (MQA) and protein design. The proposed GNN has the property that the vector and scalar outputs are equivariant and invariant with respect to composition of 3D rotations and reflections. Overall speaking, the reviewers like this paper very much (especially its technical novelty), and provide quite positive comments. On the other hand, there are also some concerns being mentioned:\n\n1)\tThe datasets used in the experiments are a little old â€“ experiments on CASP 13 are preferred.\n2)\tSome technical details are not very clear and the paper writing needs improvements\n3)\tExperimental comparison with some recent baselines is missing.\n\nThe authors did a good job in their rebuttal and paper revision. Most of the above concerns have been addressed. Therefore, we think the current version of the paper is clearly beyond the bar of ICLR.\n"
    },
    "Reviews": [
        {
            "title": "The idea that leverages the geometric and relational aspects of the 3D structure is novel. However, some details of the approach are not clear, which hurt the readability of the paper.",
            "review": "This paper aims to leverage the geometric and relational aspects of the 3D structure\nsimultaneously with the proposed GVP layer. The approach extends standard dense layers. The\nauthors claim that GNNs with such layers can perform both geometric and relational reasoning\non representations of macromolecules. The experiments on two problems in protein structure\nlearning show improvement over CNN and GNN. However, some details are missing, and the\nintuition of the methods is not clear. The draft needs to be refined and organized well.\nPros:\n1. The proposed GVP can learn geometric features from protein structure and is\nrotation/reflection-invariant.\n2. The learned vector features in the intermediate layer are interpretable.\n\nCons:\n1. Fig.1 A is not clear. The intermediate layer and weight matrices are all represented with\nblocks. The schematic diagram needs to be refined.\n2. Some equations are not clear. In equation (2) and (3), the subscripts j, m, e, v are not\ndefined.\n3. The writing and format of the paper are hard to read. In the 3.2 section, lots of symbols\nare used without definition (e.g. C, $alpha$, RBF). In the 3.3 section, h_v^j, h_v^i is not\nclear. some schematic diagrams will be helpful for illustrating the network structure.\n4. The intuition and motivation of the methods are not clear. For example, why is it easier\nfor GNN to access the global geometric properties of protein structure with GVP?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Applying a GNN with a modified layer on protein backbones for quality assessment and design",
            "review": "This work uses a graph representation of the protein backbone and a GNN\nfor model quality assessment (MQA) and protein design.\n\nStrengths:\nThe GNN architecture proposed has the important property that the vector and scalar outputs\nare equivariant and invariant with respect to composition of 3D rotations and reflections.\n\nThe submission is clear and correct, and the experiments are reproducible.\n\nWeaknesses:\nMost datasets used in this work and methods compared with are from 2016 or earlier (CASP12 or earlier, and for example ProQ3D);\nwhereas a more relevant comparison would use datasets from CASP13 (or even 14) and recent methods (for example ProQ4).\nNearly none of the methods in CASP 12 (2016) and earlier CASPs used deep learning\nsince Tensorflow was released in 11.2015 and PyTorch in 9.2016.\nOnly in CASP13 (2018) did the majority of groups use deep learning. \nThere is an inconsistency between the text describing the dataset used for MQA in section 4 and Table 6 in Appendix C, which may be clarified in the text by mentioning CASP13.\n\nWhile the work does compare against several GNNs, a comparison with important recent work on protein design using GNNs \nsuch as ProteinSolver [1] or a reference would improve the paper.\nOther missing references on protein design are methods using 3D CNNs [2] conditional VAE [3] and conditional GAN [4],\nas well as work on MQA [5]. Therefore, the unequivocal conclusion that the method \"empirically outperforms existing architectures on learning quality scores and sequence designs, respectively, from protein structure\" is partially accurate and may be rephrased to improve the paper.\n\n[1] Fast and Flexible Protein Design Using Deep Graph Neural Networks, Strokach et al, 2020.\nhttp://design.k8s.proteinsolver.org\n[2] A structure-based deep learning framework for protein engineering, Shroff et al, 2019.\n[3] Design of metalloproteins and novel protein folds using variational autoencoders, Greener et al, 2018.\n[4] Structural bioinformatics de novo protein design for novel folds using guided conditional Wasserstein generative adversarial networks, Karimi et al, 2019.\n[5] Deep transfer learning in the assessment of the quality of protein models, Hurtado et al, 2018.\nhttps://github.com/ElofssonLab/ProQ4",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper addresses an important issue in computational biology. The paper is well written and steps are well explained. ",
            "review": "In this paper, the authors introduce a novel procedure to predict or acquire insights from the structure of a macromolecule (such as a protein, RNA, or DNA), represented as a set of positions associated with atoms or groups of atoms in 3D Euclidean space. Their approach, called GVP-GNN, can be applied to any problem where the input domain is a structure of a single macromolecule or molecules bound to one another. Their approach is divided into two steps: model quality assessment and computational protein design. \nThe paper addresses a notable problem in computational biology: learning on 3D structures of large biomolecules.  I have noticed various industry-based studies struggling to find the right solution. \nThe paper is powerfully written, and the approach is novel. The steps are described explicitly, which helps the reader to understand them. \n\nI have a few suggestions for the Authors. Please grammar proof the paper thoroughly to avoid small grammatical mistakes such as articles, or typos. \nIn the results, please refer to the suggested approach as GVP-GNN. Sometimes, you refer to your method as \"ours\". Please be uniform. \nThe availability of a dataset, especially the synthetic dataset, will allow the paper to be reproducible by others. \n",
            "rating": "10: Top 5% of accepted papers, seminal paper",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting paper introducing GVP architecture and showing that it results in good performance for relevant tasks",
            "review": "The challenge of predicting the structure of biological macro-molecules is widely relevant in many applications and difficult to address. This paper divides the types of approaches taken to address this challenge into those that use \"geometric\" information (i.e. positions of molecules in space), and those that utilize \"relational methods\" mainly through graphs (how different parts of molecule relate). This study is an attempt to integrate the two source of information by a novel network architecture. They introduce geometric vector perceptrons as a way of summarizing geometric information for graph layers without loss of information as it happens in dense layers. They evaluate the performance of these architectures on MQA and CPD tasks, both relevant and standard benchmarks in the field. \n\nPositives:\n\n- The paper well-written and sets up the problem and how it supposed to be solved very well. \n\n- The method seems to be high-performing on well-established benchmarks. \n\n- The conceptual contribution of GVP seems promising, intuitively relevant and usable.\n\n- Ablation and hyper-parameter studies are well-scoped. \n\nAreas for improvement: \n\n- The authors advertise GVPs as a \"drop-in replacement\" for MLP layers, however, looking at their ablation studies, while the MLP layer is less performant than GVP, it still is outperforming many SOTA methods. For this reason I suggest including the MLP results in the main text, so that the performance improvement is clear. It is also relevant to discuss what drives the performance of the method such  that even with MLP, it outperforms sophisticated architectures introduced before.\n\n- For MQA tasks, A discussion and ideally quantitative comparison with Ingraham 2019 ICLR (Differentiable Simulator), and AlphaFold (Senior et al 2020 Nature) seems pertinent. At least to me it is not immediately obvious if learning seq -> structure is a sufficiently different task not to be considered/discussed here. Presumably sequence data is more widely available than the geometry.  \n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}