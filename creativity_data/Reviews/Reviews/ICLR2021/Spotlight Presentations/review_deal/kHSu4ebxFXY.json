{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Spotlight)",
        "comment": "This work proposes a method for generating candidate molecules using a novel fragment-based MCMC proposal mechanism.\n\nPros:\n* Well-written paper\n* Novel idea for an important application\n* Very good empirical performance compared to the state-of-the-art in multi-objective molecule generation\n* Careful ablation studies\n\nCons:\n* Some details were missing (runtime, experimental details) and have been added to the revised version.\n\nThe authors engaged in an extensive discussion with the reviewers and modified their paper to address the reviewer concerns.\n\nAfter discussions three reviewers recommend accepting the work and consider it a novel and useful contribution to the field.\n\nOne reviewer (Reviewer 3) is not satisfied by the authors comments and has concerns about the work regarding: asymptotic correctness of the sampling; fairness of the experimental comparison; and computational complexity.  The authors provide detailed justifications for their choices.  After looking at the discussion there are two factors:\n1. technical arguments regarding the correctness of the sampling method; the authors justify the correctness by known results for adaptive MCMC methods, and the argument is sound, and the area chair fully accepts the authors' arguments as correct and applicable.\n2. extend of the experimental evaluation and suitable baseline methods; this is partially subjective.  The authors provide extensive experiments in their work and justify exclusion of certain methods in that they do not easily apply to the multi-objective setting.  In addition, Reviewer 3 demands a comparison of generated molecules per time, which is plausibly useful, however, none of the prior works have used such a metric in a consistent manner and it is clearly challenging to do so fairly as such metric would depend on specifics of the implementation and computer.  The authors have updated their paper and added runtime information for their method.  The area chair fully accepts the authors' arguments and justification for the current experimental scope.\n\nIn summary the area chair considers the remaining concerns by Reviewer 3 as invalid; in particular, the authors have made extensive efforts to engage and educate the reviewer."
    },
    "Reviews": [
        {
            "title": "Review of MARS for multiobjective drug discovery optimization",
            "review": "SUMMARY: The authors present an elegant Markov-Chain Monte Carlo (MCMC) method to carry out the task of generating molecular structures that satisfy several objectives.\n\nPROS: \n- The work is well written, concise and easy to follow\n- The methodology is competitive with other approaches that are state-of-the-art in the optimization of single properties (such as GA-D) and show that they outperform them in most cases.\n- The references that it cites are balanced.\n- The multiobjective optimization is based on biological objectives\n\nCONS:\n- I see no major cons with this work.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Recommendation to accept",
            "review": "##########################################################################\n\nSummary:\n\nThis paper proposes a method to generate molecular graphs with multiple optimized properties. Molecular graphs are constructed/edited by the iterative addition and removal of molecular fragments. A MCMC search procedure, guided by a learned graph neural network that proposes good graph edit actions, is used to sample molecules with optimized properties. The proposed model is compared with some baselines on a few multi-objective optimization tasks and shows good performance.\n\n##########################################################################\n\nReasons for score: \n\nOverall, I vote for acceptance. The paper presents an interesting method for multi-objective molecule optimization that shows good performance in the evaluation. However, I have some concerns about the benchmark tasks and baselines that hopefully could be addressed\n\n##########################################################################\n\nStrengths:\n\n*Paper is written in a clear way, and is well structured\n\n*Proposed model shows very good performance in the evaluation, compared to other baselines\n\n*Ablation studies that provide useful insight about the model\n\nWeaknesses:\n\n*Some concerns about the benchmark tasks and baselines (see below)\n\n##########################################################################\n\nQuestions and other comments:\n\n*I think that the summary product score (success rate x novelty x diversity) could be a bit misleading for the casual reader. Looking at Table 2, it is clear to me that different models have different performance characteristics in relation to the success rate, novelty and diversity model performance metrics. In a practical use case, one may not equally weight the importance of these performance metrics, and instead decide on a trade off depending on the specific problem. Eg based on Table 2, we would pick the MARS model for high success rate, GA+D for high novelty, RationaleRL for high diversity. However, the simple summary product score (especially with the highlighted column in Table 1 and 2) make this nuance harder to see.\n\n*The abstract claim: \"[The method] outperforms the best prior methods by 100% in terms of success rate, novelty, and diversity of generated molecules.\" is a bit ambiguous, since it seems to only happen with the product score in 1 of the 6 tasks\n\n*Do you have any data on the ability of the proposed model to optimize raw property scores? Although it is useful to see the proportion of molecules generated containing properties above a predefined threshold, sometimes we may be interested getting the handful of best molecules. Eg the most potent inhibitor, or to a lesser extent the molecules with the highest QED and SA scores.\n\n*For the success rate metric, what was the reasoning for the thresholds? Eg GSK3B/JNK3 > 0.5, QED > 0.6, SA > 0.67\n\n*How did you implement the weighting for the multiple objectives (GSK3B/JNK3, QED, SA) in GCPN and JT-VAE? It seems that the weighting of the different objectives is another set of model hyperparameters that requires appropriate tuning.\n\n*Any thoughts about the applicability of some public molecule generation/optimization benchmarks for this work, eg https://github.com/BenevolentAI/guacamol?  \n\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Multi-objective molecules optimization using MCMC",
            "review": "Summary:\n\nThe authors propose a novel way to generate molecules with specified objectives, named MArkov moleculaR Sampling (MARS). The idea of MARS is based on generating the chemical candidates by iterative editing fragments of molecular graphs. To transform a molecule x into another molecule xâ€², the authors considers two sets of graph editing actions fragment adding and fragment deleting, where fragments are connected components in molecules separated by single bonds. To generate the molecules with desired objectives, MARS is using Markov chain Monte Carlo sampling with specified annealing scheme, together with graph convolutional neural network. The results reported in the following paper are very promising and show that this could be a good direction in the area of multi-objective molecules optimization.\n \n\n=============================================================================\n\nPros:\n\n1. The idea proposed by authors seems novel. It is the combination of MCMC based on molecules, together with message passing neural networks.\n\n2. The proposed model is a new state of the art in the area of multi-objective molecules optimization. In the experimental section the authors shows that molecules generated by MARS have the highest desired objectives in 5 out of 6 proposed tasks. Simultaneously the generated set of molecules seems novel and diverse.\n\n3. The molecules generated by MARS are evenly distributed in the space with a range of novel regions covered, as showed in Figure 3. This is a desirable behavior, better than in the other generative models, where we can see clusters of generated molecules.\n\n=============================================================================\n\nCons:\n\n1. The proposed strategy seems constrained by the selection of the fragment dataset.\n\n2. The instruction of calculating probability densities over fragments in the vocabulary is not clear. More precisely, the authors states that hidden state for fragment graphs is given by h^{graph} = MaxPooling({h^{node}_{u}}), however they do not state whether the nodes taken for aggregation are from the fragment itself or from combined fragment and molecule x or whether from the molecule x only.  \n\n\n=============================================================================\n\nQuestions during rebuttal period:\n\n1. It is not stated in the text what is the initial molecule. Do you have some starting set of molecules or always start from the same?\n\n2. How fast is the convergence of the proposed method? It would be nice to see some plot with time steps on X axis and score on Y axis.\n\n3. The authors did not state what was the number of train steps used to converge MARS in their experiments. What number of time steps did you use? How long does the MARS training takes, compared to other methods?\n\n=============================================================================\n\n=============================================================================\n\nReasons for score: \n \nOverall, I vote for accepting this paper. The problem of multi-objective molecules optimization is hard and really important in cheminformatics. The idea proposed by the authors is novel and confirmed experimentally. Hopefully the authors can address my concern in the rebuttal period. \n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review",
            "review": "Summary: The paper proposes a sampling-based approach for multiple property optimization in molecule generation.\n\nStrength: the sampling approach is an interesting new direction for molecule generation. Also multi-objective molecule generation is an important task.\n\nWeakness: I have several concerns regarding this paper.\n\n(1) Section 3.2 is unclear, with lots of details missing. For example,\n--- what is the input for MPNN? i.e., x in M_\\theta(x).\n--- How to determine the supervision signal p_add, p_delete for M_\\theta(x)?\n--- When  add/deleted fragments, how many fragments are added/deleted in a single transition kernel?\n--- If multiple fragments are added/deleted, are they added/deleted sequentially or following some particular rule?\n--- The MPNN description (Eq.5--9) is borrowed from [1], please cite the paper.  \n--- The paper trains the MPNN during sampling procedure, which seems very challenging, in the first several steps the model is from scratch, how to guarantee the sampled molecule is reasonable? If initially, the sampled molecules can not provide informative supervision, it will be hard to train a strong MPNN model. Also, the number of training samples also looks very limited. In [1], it requires a large amount of existing drug molecules to pretrain a good MPNN model. \n\n(2) Unfair comparison between the proposed sampling model and non-sampling baselines. For example, when sample size N=5000, the proposed model will query oracle to select a subset of generated molecules. \nHowever, baselines such as JTVAE directly output the generated molecules, all of which are kept. Therefore, in performance comparison if you compare the best molecules in 5000 molecules with a single molecule generated by JTVAE, this is unfair. Please clarify.\n\n(3) complexity issue: How many times do the authors need to query the oracles when performing optimization using the proposed sampling algorithm? How does this compare to the baselines? Each time you sample a new molecule, you need to evaluate the acceptance rate in Eq.2, while such an evaluation requires evaluation of target distribution in Eq.1 as well as need to call the oracle (e.g., evaluating the property), which is very expensive.\n\n(4) Lack of theoretical guarantee. The authors need to show the sampled molecules follow target distribution. The authors also argue they adaptively train the MPNN, so the transition kernel will change during sampling. It is non-trivial to guarantee the convergence to target distribution. \n\n(5) There are also issues with experimental setting and results. For example\n--- Important baselines are missing. For example, Graph2Graph [2] and hierarchical generation [3].\n--- One baseline RationaleRL outperform the proposed MARS in terms of success rate in many settings.\n--- The fairness in model comparison issue I mentioned in (2)\n--- How to use t-SNE to visualize molecule distribution? It needs more details.\n\n[1] Hu et al, ICLR 2020, Strategies For Pre-training Graph Neural Networks\n[2] Jin et al, ICLR 2019, Learning Multimodal Graph-to-Graph Translation for Molecule Optimization.\n[3] Jin et al, ICML 2020, Hierarchical Generation of Molecular Graphs using Structural Motifs.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}