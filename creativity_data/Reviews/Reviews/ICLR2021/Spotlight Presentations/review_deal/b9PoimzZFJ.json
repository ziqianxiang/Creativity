{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Spotlight)",
        "comment": "All reviewers seems in favour of accepting this paper, witht he majority voting for marginally above acceptance threshold. \nThe authors have taken special heed of the suggestions and improved the clarity of the paper. \nFrom examination of the reviews, the paper achieves enough to warrant publication. \nMy recommendation is therefore to accept the manuscript. "
    },
    "Reviews": [
        {
            "title": "Reasonable paper, some clarity issues",
            "review": "Overall, I found the paper well-written, the methods appear reasonable and the math appears correct. I think the case made for the importance/significance of the method could be improved, but think the paper should be accepted regardless.\n\n--- Comments ---\n\n1. I thought the introduction did a good job setting up the high-level problem, but did not really establish why a new method is needed. I got to the end of the intro and wondered why I couldn't use any one of a dozen DRO type methods to get the type of robustness described. The experiments do a reasonable job of demonstrating the utility of the proposed method, but I recommend adding something to the intro like: Methods have been proposed that promote robustness to distributional shift, however, these methods fail to capture XYZ shifts because ABC.\n\n2. I really liked the examples of the different types of shifts that the authors are interested in, but thought the paper could do a better job arguing why these specific shifts are important or relevant. Perhaps swapping the \"red chair\" example for something more compelling might do the trick. In particular, it is worth giving a compelling reason why the drop in average performance might be worth an improvement in, for example, anomaly detection. \n\n3. I found the early parts of Section 3 a bit confusing because it was unclear at that point in the paper where the \"majority\" and \"minority\" groups were coming from. I recommend adding a few sentences to the beginning of that section like: Suppose that we knew the collection of non-semantic features and thus new the relevant majority and minority groups. This will not, in general, be the case and we will show how to derive such groups from the data, but we first establish our method as if such groups were known.\n\n4. I found Equation (10) very hard to follow. First, the notation has *many* problems (superscripts from earlier in the section are changed to subscripts; no domain is given for $\\alpha$; it is not clear what it means to index $\\alpha$ by $e$; $\\mu$ is not defined; $\\gamma$ is not defined). Second, I would give a few sentences explaining what the pieces of this objective are doing and why it achieves the goal of splitting the data into relevant majority and minority groups.\n\n--- Minor comments ---\n\n1. Page 2, par 3, line 1: Not clear what \"modeling bias\" refers to here or why it affects the dataset.\n\n2. Equations (1) and (2) don't really seem necessary for the rest of the work. In particular, $\\mathcal{C}$ isn't reference anywhere else in the paper. I would just define $h_s$ and $h_n$ and move on.\n\n3. I found the $\\not\\sim$ notation a bit confusing. Does it mean \"sampled from any distribution other than $p$? Based on the description, it seems more like it means \"sampled from outside the support of $p$\" which matches the examples given in Fig 1.\n\n4. Equation 6: $\\ell$ is not defined.\n\n5. Equation 9 and surrounding text: I would change reverse-KL to just KL since, in this context, this not an obvious forward/reverse direction.\n\n6. Text under Equation 9: It doesn't really make sense for a categorical distribution to be multi-modal since there is no inherent ordering to values in the support (unless there are literally two or more equivalent modes). I would recommend changing unimodal/multi-modal to peaked/flat or low-entropy/high-entropy.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Well written paper, perhaps a bit incremental improvement but interesting and well executed",
            "review": "Summary: the paper studies a setting where there are simple correlations with the target variables (that are not however robust) and more complex but robust features. The simple correlation is usually such that in most cases the feature is descriptive of the label, but at times it takes values that are part of a “minority group” that is not descriptive of any one class in particular.\nSystematic-shift generalization is tested using the same spurious features that are present in training, in all combinations except the usual pairing of spurious feature and class.\nNon-systematic shifts are tested using novel spurious features.\nAnomaly detection is tested with unseen robust features.\nNeural networks trained with standard ERM notoriously pick up on all features that correlate with the label, and the paper compares several methods (including IRMv1, REx, and GroupDRO) to the proposed Predictive Group Invariance. The latter is shown to work better than the baselines (even when using class conditioning) on systematic shifts and anomaly detection, and often non-systematic shifts.\n\nI found the paper to be mostly very well written (with few exceptions), and especially sections 1 and 2 very easy to read and understand. The experiments setting is clear and not at all trivial.\n\nMy main questions and concern:\n- The description of PGI could be improved, I would suggest adding an algorithm box that sums up what is described.\n- “environments” and “partitions” are the same thing for PGI? How are “environments” chosen for the baseliness that need them? With the same partition networks used for PGI? If not, it might be hard to disentangle the role of using the partition networks from the KL objective of PGI. \n- The part about partitioning is not detailed enough. P13: \"We use a separate network for each object category” what is an object category? From page 3 I understood that there might be 2 categories (easy and hard), is this the case? Is it correct to think of the role of these partition predicting networks as a sort of clustering that focuses on the most easy-to-find features?\n- I haven’t seen any mention of early stopping in the experiments. It sounds like the performance reported is the one at the end of all training epochs. This might explain why for example ERM on COCO-on-Colours only achieves a 1.10% accuracy on Systematic shift. If this is correct, why not using early stopping, given how prone to overfitting these networks might be?\n\nOverall, based on the results, the proposed PGI seems to improve the accuracy over the baselines, even though it seems to be more of an incremental improvement than a substantial and conceptual one.\nI look forward to a constructive discussion with the authors and hope my questions and concerns will be clarified.\n\n\nMinor:\n- I think the blanket statement “it has been reported that highly competitive performances can often be achieved with a baseline model on such domain generalisation benchmarks (Gulrajani & Lopez-Paz, 2020), similarly as in Table 1. “ is a bit too vague, and since it questions the validity of the results in all papers mentioned before, it should be either properly justified or adjusted to make sure that what it says actually applies to all of them.\n- Figure 3 is referenced in the text instead of Figure 2 (perhaps it was not referenced with \\ref )\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good work introducing a simple method to improve systematic generalisation",
            "review": "This paper shows that group invariance methods across inferred partitions show better generalization in (non-)systematic distributional shifts and anomaly detection settings. It also suggests a new invariance penalty and empirically shows that it works better on three synthetic datasets viz. coloured-MNIST, COCO-on-colours, and COCO-on-places.\n\nThe paper is written well and starts off by giving an intuition of why IRM-like methods are important by presenting the results of a simple experiment on coloured-MNIST (table 1). It then goes on to talk about (non-)systematic generalization before introducing the proposed method. The authors use reverse KL divergence between the group distributions as the penalty and use prior work to partition the datasets into groups. They use \n\nThe results look promising across datasets, though it is slightly lower in the 'in-distribution' setting. I am happy to see that they also talk extensively about hyperparameter selection especially in the case where they assume no access to validation sets with a distributional shift.\n\nOverall, I like the work and would like to see it presented at the conference.\nOne minor point: cite work the first time you introduce something, not later on. It can be a little confusing for the readers. I wondered if I missed something. For ex: \"We find that a recently proposed method can be effective at discovering...\", \"IRMv1\", etc.\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official review",
            "review": "Summary:\nThis paper studies the behaviour of deep neural networks in situations where simple but irrelevant correlations exist between input and output, and dominate more complex but relevant correlations. The authors conduct experiments on synthetic datasets (like coloured MNIST) and show that an invariance penalty helps the network focus on relevant correlations. \n\nPros:\n- The paper studies neural network behaviour with respect to systemic biases that are likely faced by most neural networks in some form or the other. To make the study tenable, the authors make use of meaningful synthetic datasets, and propose an intuitive regularization to overcome the systemic biases. \n- The analysis done in the paper is very methodical, and the presentation is very clear.\n- The numerical simulations are comprehensive and convincing.\n\nCons:\n- It would be nice to see how this would be applicable to real world datasets. The paper is interesting even without it, and I also appreciate that the authors are honest about it - so I would not hold it against the authors. But it would further strengthen the paper if some basic experiments are done on real world datasets. For instance, will one be able to find a partition on ImageNet?\n\nComments:\n- Section 5.1: Minimization is spelt incorrectly.\n- Equation (6-7): I am not entirely sure what is happening with respect to the constraint on \\theta. What does capital \\theta correspond to? And if \\theta itself is the result of an optimisation (argmin), then why is there another optimisation on the same \\theta in the loss function?\n- In the text that appears before equation (3), it is mentioned that the predicted features f_\\theta will be matched for the two partitions, but equation (7) matches the predicted output post softmax. Could you please clarify?",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}