论文题目,会议名称
 Persistent anti-muslim bias in large languagemodels, arXiv preprint arXiv:2101
 Wildlife insights: Aplatform to maximize the potential of camera trap and other passive sensor wildlife data for theplanet, Environmental Conservation
Leveraging unlabeled whole-slide-images for mitosis detection, Computational Pathology andOphthalmic Medical Image Analysis
 Deep learning for segmentation of brain tUmors:Impact of cross-institUtional training and testing, Med Phys
 Big self-supervisedmodels advance medical image classification, arXiv preprint arXiv:2101
From detection of individual metastases to classification of lymph node status at the patient level:the CAMELYON17 challenge, IEEE Transactions on Medical Imaging
 Recognition in terra incognita, In European Con-ference on Computer Vision (ECCV)
 Efficient pipeline for camera trap image review, arXivpreprint arXiv:1907
 The iwildcam 2020 competition dataset, arXiv preprintarXiv:2004
 A theory of learning from different domains, Machine Learning
 Ethical considerations when using geospatialtechnologies for evidence generation, Innocenti Discussion Paper
 Adamatch:A unified approach to semi-supervised learning and domain adaptation, arXiv preprintarXiv:2106
" Experiment tracking with weights and biases, 2020", URL https://www
" Biographies, bollywood, boom-boxes andblenders: Domain adaptation for sentiment classification", In Proceedings of the 45th annualmeeting of the association of computational linguistics
 Pubchem: integrated plat-form of small molecules and biological activities, In Annual reports in computational chemistry
 Man isto computer programmer as woman is to homemaker? Debiasing word embeddings, In Advancesin Neural Information Processing Systems (NeurIPS)
" Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx,Michael S", Bernstein
 Nuancedmetrics for measuring unintended bias with real data for text classification, In World Wide Web(WWW)
" Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M",Ziegler
 D, Maloney
 Semantics derived automatically fromlanguage corpora contain human-like biases, Science
 Un-supervised learning of visual features by contrasting cluster assignments, In Advances in NeuralInformation Processing Systems (NeurIPS)
 LEGAL-BERT:”preparing the muppets for court”, In Empirical Methods in NaturalLanguage Processing (EMNLP)
 A simple framework forcontrastive learning of visual representations, In International Conference on Machine Learning(ICML)
 A simple framework forcontrastive learning of visual representations, In International conference on machine learning
 Functional map of the world,In Computer Vision and Pattern Recognition (CVPR)
 Self supervised contrastive learning for digital histopathol-ogy, arXiv preprint arXiv:2011
 Tydi qa: A benchmark for information-seeking question answering intypologically diverse languages, arXiv preprint arXiv:2003
 When doescontrastive visual representation learning work? arXiv preprint arXiv:2105,05837
 Cross-lingual language model pretraining, In Advances inNeural Information Processing Systems (NeurIPS)
 Xnli: Evaluating cross-lingual sentence representations, InEmpirical Methods in Natural Language Processing (EMNLP)
 The cityscapes dataset for semantic urbanscene understanding, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Randaugment: Practical automateddata augmentation with a reduced search space, In Computer Vision and Pattern Recognition(CVPR)
" Mine the easy, classify the hard: a semi-supervised approach toautomatic sentiment classification", In Conference on Natural Language Processing (KONVENS)
" Chapman, Frederic Baret, Ian Stavness, and WeiGuo", Global wheat head detection (gwhd) dataset: a large and diverse dataset of high-resolutionrgb-labelled images to develop and benchmark wheat head detection methods
 A, Tahir
 Self-supervision closes the gap between weak and strong supervision in histology, arXiv preprintarXiv:2012
 BERT: Pre-training of deepbidirectional transformers for language understanding, In Association for Computational Linguis-tics (ACL)
 Improved regularization of convolutional neural networkswith cutout, arXiv preprint arXiv:1708
 Onrobustness and transferability of convolutional neural networks, arXiv preprint arXiv:2007
 Adaptive methodsfor real-world domain generalization, In Computer Vision and Pattern Recognition (CVPR)
" Why does unsupervised pre-training help deep learning? In Artificial Intelligence and Statistics (AISTATS), pp", 201-208
 Domain-adversarial training of neural networks,Journal of Machine Learning Research (JMLR)
 Word embeddings quantify 100years of gender and ethnic stereotypes, Science
 Real-toxicityprompts: Evaluating neural toxic degeneration in language models, arXiv preprintarXiv:2009
 Shortcut learning in deep neural networks, NatureMachine Intelligence
 UnsUpervised representation learning bypredicting image rotations, In International Conference on Learning Representations (ICLR)
 Deep sparse rectifier neUral networks, InArtificial Intelligence and Statistics (AISTATS)
 Entropy regUlarization, In Semi-Supervised Learning
 Domain-specific langUage model pretraining for biomedicalnatUral langUage processing, arXiv preprint arXiv:2007
 In search of lost domain generalization, arXiv preprintarXiv:2007
 Don’t stop pretraining: adapt langUage models to domains and tasks, arXivpreprint arXiv:2004
 Realm: Retrieval-augmented language model pre-training, In icml
 Deep residual learning for image recog-nition, In Computer Vision and Pattern Recognition (CVPR)
 Momentum contrast for un-supervised visual representation learning, In Computer Vision and Pattern Recognition (CVPR)
Pretrained transformers improve out-of-distribution robustness, arXiv preprint arXiv:2004
 Distilling the knowledge in a neural network, InNIPS Deep Learning and Representation Learning Workshop
" Efros,and Trevor Darrell", Cycada: Cycle consistent adversarial domain adaptation
Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generaliza-tion, arXiv preprint arXiv:2003
 Open Graph Benchmark: Datasets for machine learning on graphs, In Ad-vances in Neural Information Processing Systems (NeurIPS)
 Strategies for pre-training graph neural networks, In International Conference onLearning Representations (ICLR)
 Densely connectedconvolutional networks, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Hull, A database for handwritten text recognition research
" Matthew Davis, David B", Lobell
 Semi-supervised deep kernel learning: Regres-sion with unlabeled data by minimizing predictive variance, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Transfer learning library, https://github
 Selective question answering under domain shift, InAssociation for Computational Linguistics (ACL)
 Half a percent of labels isenough: Efficient animal detection in uav imagery using deep cnns and active learning, IEEETransactions on Geoscience and Remote Sensing
" Earnshaw, Imran S", Haque
 Machine learning methods for histopathological imageanalysis, Computational and structural biotechnology journal
 Self-path: Self-supervision for classification of pathology images with limitedannotations, IEEE Transactions on Medical Imaging
 Gradient-based learning applied todocument recognition, Proceedings of the IEEE
 Pseudo-label: The simple and efficient semi-supervised learning method for deepneural networks, In ICML Workshop on Challenges in Representation Learning
 Predicting what you already know helps:Provable self-supervised learning, arXiv preprint arXiv:2008
 Biobert: a pre-trained biomedical language representation model for biomedical textmining, Bioinformatics
" Bart: Denoising sequence-to-sequence pre-trainingfor natural language generation, translation, and comprehension", In Association for Computa-tional Linguistics (ACL)
" Deeper, broader and artier domaingeneralization", In Proceedings of the IEEE international conference on computer vision
 Semi-supervised learningfor imbalanced sentiment classification, In International Joint Conference on Artificial Intelli-gence (IJCAI)
 Learning transferable features withdeep adaptation networks, In International conference on machine learning
 Deep transfer learning with jointadaptation networks, In International conference on machine learning
 Conditional adversarialdomain adaptation, In Advances in Neural Information Processing Systems (NeurIPS)
 Semi-supervisedhistology classification using deep multiple instance learning and contrastive predictive coding,arXiv preprint arXiv:1910
 Domain adaptation with multiplesources, In Advances in Neural Information Processing Systems (NeurIPS) 
 The effect of natural distributionshift on question answering models, arXiv preprint arXiv:2004
 Accuracy on the line: on the strong correlationbetween out-of-distribution and in-distribution generalization, In International Conference onMachine Learning (ICML)
 Surprisingly simple semi-supervised do-main adaptation with pretraining and consistency, arXiv preprint arXiv:2101
 Stereoset: Measuring stereotypical bias in pretrainedlanguage models, arXiv preprint arXiv:2004
 Participatory re-search for low-resourced machine translation: A case study in African languages, In Findings ofEmpirical Methods in Natural Language Processing (Findings of EMNLP)
 Readingdigits in natural images with unsupervised feature learning, In NIPS Workshop on Deep Learningand Unsupervised Feature Learning
 Justifying recommendations using distantly-labeled re-views and fine-grained aspects, In Empirical Methods in Natural Language Processing (EMNLP)
 A deep active learning system for species identification and counting in camera trapimages, Methods in Ecology and Evolution
 inaturalist, Science Scope
 Distributionally robust lan-guage modeling, In Empirical Methods in Natural Language Processing (EMNLP)
 Focus on the positives: Self-supervised learning for biodiversity monitoring, arXiv preprint arXiv:2108
 A cluster-then-label semi-supervised learning approach for pathology image classification, Scientific reports
Visda: A synthetic-to-real benchmark for visual domain adaptation, In Computer Vision andPattern Recognition (CVPR)
 Moment matchingfor multi-source domain adaptation, In International Conference on Computer Vision (ICCV)
 Lawrence,Dataset shift in machine learning
 Learning transferable visual models from natural language supervision, In Interna-tional Conference on Machine Learning (ICML)
 Learning transferable visualmodels from natural language supervision, arXiv preprint arXiv:2103
" Reed, Xiangyu Yue, Ani Nrusimha, Sayna Ebrahimi, Vivek Vijaykumar, Richard Mao,Bo Li, Shanghang Zhang, Devin Guillory, Sean Metzger, Kurt Keutzer, and Trevor Darrell", Self-supervised pretraining improves self-supervised pretraining
 Adversarial domain adapta-tion for classification of prostate histopathology whole-slide images, In International Conferenceon Medical Image Computing and Computer-Assisted Intervention
" Girshick, and Jian Sun", Faster R-CNN: Towards real-timeobject detection with region proposal networks
 Playing for data: Ground truthfrom computer games, In European conference on computer vision
 The gbif integrated publishing toolkit: facilitatingthe efficient publishing of biodiversity data on the internet, PloS one
 Model-based domain generalization, arXivpreprint arXiv:2102
 Extended-connectivity fingerprints, Journal of Chemical Infor-mation and Modeling
 Thesynthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes,In Proceedings of the IEEE conference on computer vision and pattern recognition
 ImageNet large scale visualrecognition challenge, International Journal of Computer Vision
 Adapting visual category models to newdomains, In European conference on computer vision
" Hashimoto, and Percy Liang", Distributionally robustneural networks for group shifts: On the importance of regularization for worst-case generaliza-tion
 Asymmetric tri-training for unsuperviseddomain adaptation, In International Conference on Machine Learning (ICML)
 Maximum classifier dis-crepancy for unsupervised domain adaptation, In Proceedings of the IEEE conference on com-Puter vision and pattern recognition
 Tuneit the right way: Unsupervised validation of domain adaptation via soft neighborhood density,arXiv preprint arXiv:2108
" Distilbert, a distilled version ofbert: smaller, faster, cheaper and lighter", arXiv preprint arXiv:1910
 Teacher-student chain for efficient semi-supervised histology image classification, arXiv preprintarXiv:2003
" Cubuk,Alex Kurakin, Han Zhang, and Colin Raffel", Fixmatch: Simplifying semi-supervised learningwith consistency and confidence
 Image representations learned with unsupervised pre-trainingcontain human-like biases, In ACM Conference on Fairness
 The semi-supervised inaturalist-aves challenge at fgvc7 work-shop, arXiv preprint arXiv:2103
 Deep coral: Correlation alignment for deep domain adaptation, InEuropean Conference on Computer Vision (ECCV)
 Return of frustratingly easy domain adaptation, InAssociation for the Advancement of Artificial Intelligence (AAAI)
 Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization, In Interna-tional Conference on Learning Representations (ICLR)
 Assessing social and intersectional biases in contextualized wordrepresentations, arXiv preprint arXiv:1911
 Measuring robustness to natural distribution shifts in image classification, arXiv preprintarXiv:2007
 Quantifying the effects of data augmentation and stain color normaliza-tion in convolutional neural networks for computational pathology, Medical Image Analysis
 Conditional contrastive learning: Removing undesirable information in self-supervised representations, arXiv preprint arXiv:2106
 An empirical study on robustness to spuriouscorrelations using pre-trained language models, Transactions of the Association for Computa-tional Linguistics (TACL)
Benchmarking representation learning for natural world image collections, In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition
 Deephashing network for unsupervised domain adaptation, In Computer Vision and Pattern Recogni-tion (CVPR)
 Towards domain-agnosticcontrastive learning, In International Conference on Machine Learning (ICML)
 Mitosiscounting in breast cancer: Object-level interobserver agreement and comparison to an automaticmethod, PloS one
 Extracting andcomposing robust features with denoising autoencoders, In International Conference on MachineLearning (ICML)
 Cross-domaincontrastive learning for unsupervised domain adaptation, arXiv
 Why do pretrained language models help in down-stream tasks? an analysis of head and prompt tuning, arXiv preprint arXiv:2106
 Individualtree-crown detection in rgb imagery using semi-supervised deep learning neural networks, RemoteSensing
 A generaldeep learning model for bird detection in high resolution airborne imagery, bioRxiv
 The cancer genome atlas pan-cancer analysis project, Nature genetics
 Moleculenet: a benchmark for molecular machine learn-ing, Chemical science
 Transfer learning fromdeep features for remote sensing and poverty mapping, In Association for the Advancement ofArtificial Intelligence (AAAI)
 Le, Self-training with noisy studentimproves imagenet classification
In-N-out: Pre-training and self-training using auxiliary information for out-of-distribution robust-ness, In International Conference on Learning Representations (ICLR)
 Self-supervised learningof graph neural networks: A unified review, arXiv preprint arXiv:2102
 Larger norm more transferable: An adap-tive feature norm approach for unsupervised domain adaptation, In International Conference onComputer Vision (ICCV)
 Using publicly available satellite imagery and deep learning tounderstand economic well-being in africa, Nature Communications
 Collaborative and adversarial networkfor unsupervised domain adaptation, In Computer Vision and Pattern Recognition (CVPR)
 Semi-supervised modelsare strong unsupervised domain adaptation learners, arXiv preprint arXiv:2106
 From whole slide imaging to microscopy: Deep microscopyadaptation network for histopathology cancer image classification, In International Conferenceon Medical Image Computing and Computer-Assisted Intervention
 Bridging theory and algorithm fordomain adaptation, In International Conference on Machine Learning (ICML)
"Han Zhao, Shanghang Zhang, Guanhang Wu, Jose MF Moura, Joao P Costeira, and Geoffrey J Gor-don", Adversarial multiple source domain adaptation
1 iWildCam2020-wilds ,
	Source: 243 camera traps,2
 Each domain corresponds to a different year and geographicalregion,3
" We augment the datasetwith 340,469 unlabeled images", These images come from two sources:1
", 2020)", However
", 2011)", While there is limited prior work on leveraging unlabeled data from extradomains
", 2020b; Caron et al",
