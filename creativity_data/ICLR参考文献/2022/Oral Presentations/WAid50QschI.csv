论文题目,会议名称
 Logistic-normal distributions: Some properties and uses, Biometrika
 Interpretable neural predictions with differentiablebinary variables, In Proceedings of the 57th Annual Meeting of the Association for ComputationalLinguistics
 Baum and J, A
 Learning with differentiable pertubed optimizers, In H
T, Martins
 How agents see things: On visual representations in anemergent language game, In Proceedings of the 2018 Conference on Empirical Methods in NaturalLanguage Processing
 Bridle, Probabilistic interpretation of feedforward classification network outputs
 DecoUpling sparsity and smoothness in the dirichlet variationalaUtoencoder topic model, Journal of Machine Learning Research
" A course in functional analysis, volUme 96", Springer
 Efficient marginalization of discreteand strUctUred latent variables via sparsity, In H
 Differentiable pertUrb-and-parse: Semi-sUpervised parsing with astrUctUred variational aUtoencoder, In International Conference on Learning Representations
 Elements of Information Theory, John Wiley & Sons
 Excavating AI: The politics of images in machine learning trainingsets, Accessed 28 May 2021
 Imagenet: A large-scale hier-archical image database, In 2009 IEEE Conference on Computer Vision and Pattern Recognition
 Hierarchical neUral story generation, In Proceedingsof the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: LongPapers)
 Implicit reparameterization gradi-ents, In S
 Learn-ing to commUnicate with deep mUlti-agent reinforcement learning, In D
 NUmerical compUtation of mUltivariate normal probabilities, Journal of computationaland graphical statistics
 The continUoUs categorical:a novel simplex-valUed exponential family, In Hal DaUme III and Aarti Singh (eds
" Convex polytopes, volume 221", Springer
" Measure Theory, volUme 18", Springer
 Emergence of language with multi-agent games: Learning tocommunicate with sequences of symbols, In I
 Generative models for discovering sparse distributedrepresentations, Philosophical Transactions of the Royal Society of London
 Simulating sticky particles: A Monte Carlo method to sample a stratification,The Journal of Chemical Physics
 Spike and slab variable selection: frequentist and bayesianstrategies, Annals of Statistics
Evidential sparsification of multimodal latent spaces in conditional variational autoencoders,In H
 Categorical reparameterization with gumbel-softmax, In 5thInternational Conference on Learning Representations
 Kingma and Max Welling, Auto-encoding variational bayes
 Rankmax: Anadaptive projection alternative to the softmax function, In H
 On controllable sparse alternatives to soft-max, In S
 Emergent multi-agent communication in the deep learningera, preprint arXiv:2006
 MNIST handwritten digit database, Available online:<http://yann
 The continuous bernoulli: fixing a pervasive errorin variational autoencoders, In H
 Kingma, Learning sparse neural networks through l0regularization
 Individual choice behavior: A theoretical analysis, New York: Wiley
" Maddison, Andriy Mnih, and Yee Whye Teh", The concrete distribution: A continuous relax-ation of discrete random variables
 From softmax to sparsemax: A sparse model of attention andmulti-label classification, In Maria Florina Balcan and Kilian Q
 Bayesian variable selection in linear regression, Journal ofthe American Statistical Association
 NeUral variational inference and learning in belief networks,In Proceedings of the 31st International Conference on International Conference on MachineLearning - Volume 32
 Probabilistic models for joint classification and rationale extraction, Master’s thesis
 SparseMAP: Differentiablesparse strUctUred inference, In Jennifer Dy and Andreas KraUse (eds
 Entropies and cross-entropies of exponential families, In 2010IEEE International Conference on Image Processing
" A guide to NumPy, volUme 1", Trelgol PUblishing USA
 Methods for stochastic collection andreplenishment (scar) optimisation for persistent aUtonomy, Robotics and Autonomous Systems
 YUille, PertUrb-and-map random fields: Using discrete optimizationto learn and sample from energy models
" Pytorch: An imperative style, high-performancedeep learning library", In H
 Gradient estimationwith stochastic softmax tricks, In H
" Pedregosa, G", VaroqUaUx
 T, Martins
 Languagemodels are unsupervised multitask learners, OpenAI blog
 Discrete variational autoencoders, In 5th International Conference on LearningRepresentations
 Evidential deep learning to quantify classifi-cation uncertainty, In S
 Shannon, A mathematical theory of communication
 Very deep convolutional networks for large-scale imagerecognition, In Yoshua Bengio and Yann LeCun (eds
 Recherches Sur les fonctions Cylindriques etle d6veloppement des fonctions continues enSeries, Mathematische Annalen
DVAE++: Discrete variational autoencoders with overlapping transformations, In Jennifer Dy andAndreas Krause (eds
 Improving controllable generation with semi-supervised deep generative models,Master’s thesis
 Drake, Python 3 Reference Manual
 SciPy 10: Fundamental Algorithms for Scientific Computing in Python, NatureMethods
" Graphical models, exponential families, and variationalinference", Foundations and Trends® in Machine Learning
 The NumPy array: a structure for efficientnumerical computation, Computing in Science & Engineering
 Williams, Simple statistical gradient-following algorithms for connectionist reinforcementlearning
 Fashion-MNIST: a novel image dataset for bench-marking machine learning algorithms, preprint arXiv:1708
" Lectures on polytopes, volume 152", Springer
