Table 1: Summary of different gradient penaltiesto smooth out the loss surface. The method exploits the distributional information in a mini-batchto prevent mode collapse. VEEGAN (Srivastava et al., 2017) uses an inverse of the generator tomap the data to the prior distribution. The mismatch between the inverse mapping and the prior isused to detect mode collapse. If the generator can remember the entire training set, then the inversemapping can be arbitrarily close the the prior distribution. It suggests that VEEGAN might not beable to help GAN to generalize outside of the training dataset. Our method helps GANs to discoverunseen regions of the target distribution, significantly improve the diversity of generated samples.
