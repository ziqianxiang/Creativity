Table 1: Our model significantly outperforms previous PL-oriented and NMT models. Anothervisualization can be found in Appendix E.
Table 2: Our model outperforms previous work in the code captioning task. ^Results previouslyreported by Iyer et al. (2016), and verified by us. Another visualization can be found in Appendix D.
Table 3: Variations on the code2seq model, performed on the validation set of Java-med.
Table 4: Our model significantly outperforms code2vec on the code2vec dataset.
Table 5: Statistics of our datasets.
