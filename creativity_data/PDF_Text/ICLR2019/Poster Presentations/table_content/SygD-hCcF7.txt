Table 1: NPR performance (in %) for different values of κκ	1	2	5	10	50	100	κ	1	2	5	10	50	100logits	6.3	8.7	12.4	16.0	28.2	36.5	logits	1.7	2.8	4.8	6.9	17.0	24.7PCA	0.1	0.2	0.3	0.8	3.2	5.9LLE	1.3	1.6	3.4	4.2	9.8	15.6ISOMAP	0.2	0.3	0.6	1.0	4.1	7.5t-SNE	1.9	2.7	4.1	5.6	12.8	19.5DRPR	8.4	10.2	13.2	15.2	21.1	26.6logits	5.9	8.4	11.8	14.8	25.5	32.4PCALLEISOMAPt-SNEDRPR (Ours)14190.0.0.5.
Table 2: CDPR performance (in %)	model	MNIST	STL	CIFAR10	CIFAR100	logits	81.5	80.6	79.9	67.9dim reduction	PCA	69.1	66.9	67.4	56.4	LLE	53.9	55.3	56.5	53.8	ISOMAP	67.9	70.1	69.5	58.7	t-SNE	52.8	65.9	66.5	60.4	DRPR (ours)	76.7	70.5	70.0	69.0distance). It is averaged over all images i. This metric evaluates how much images that have similarprobability scores are close to each other with the student representation. (2) Clustering DistancePreservation Ratio (CDPR): we randomly sample 105 triplets of images (i, i+, i-) such that the3 images all belong to different categories and i has closer probability score to i+ than to i- w.r.t.
Table 3: Test accuracy on CUB		Table 4: Test accuracy on Flowers dataset	Method	Accuracy	Method	AccuracyTMV-HLP Oquab et al. (2014)	47.9 %	DS-SJE Reed et al. (2016) (Char CNN)	47.3 %SJE Akata et al. (2015)	50.1%	DS-SJE Reed et al. (2016) (Bag-of-words)	57.7 %DS-SJE Reed et al. (2016) (Bag-of-words)	44.1 %	DS-SJE Reed et al. (2016) (Word CNN)	60.7 %DS-SJE Reed et al. (2016) (Char CNN-RNN)	54.0 %	DS-SJE Reed et al. (2016) (Char CNN-RNN) [reported]	63.7 %Ziming & Saligrama Zhang & Saligrama (2016)	55.3 %	DS-SJE Reed et al. (2016) (Char CNN-RNN) [publicly available]	59.6 %DS-SJE Reed et al. (2016) (Word CNN-RNN)	56.8 %	DS-SJE Reed et al. (2016) (Word CNN-RNN)	65.6 %Prototypical Networks Snell et al. (2017)	58.3 %	Prototypical Networks Snell et al. (2017)	63.9 %Ours - using DS-SJE (Char CNN-RNN) as supervision	57.7 %	Ours - using DS-SJE (Char CNN-RNN) [publicly available]	62.4 %Ours - using Prototypical Networks as supervision	60.3 %	Ours - using Prototypical Networks as supervision	68.2 %which they learn a representative vector (e.g., based on Char CNN-RNN (Zhang et al., 2015)). Theimage representations of examples and the text representations of categories are learned jointly sothat each image is more similar to the representative vector of its own category than to any other.
Table 5: Test accuracy (in %) as a function of d when using DS-SJE (Reed et al., 2016) (CharCNN-RNN) as supervision on CUBDimensionality d	16	32	64	128	256	512Linear model	75.1	82.2	82.4	82.6	82.6	82.41 hidden layer	77.0	81.9	82.1	82.4	83.3	82.92 hidden layers	72.4	72.9	75.6	77.5	79.7	79.7Table 6: Validation accuracy (in %) as a function of the output dimensionality d when using ProtoNet(Snell et al., 2017) as supervision on CUBDimensionality d	16	32	64	128	256	512Linear model	56.0	58.3	58.6	58.6	58.6	58.41 hidden layer	57.7	59.8	60.2	60.3	60.3	60.02 hidden layers	57.4	58.5	59.4	59.6	59.5	59.3Table 7: Test accuracy (in %) as a function of the output dimensionality d when using ProtoNet(Snell et al., 2017) as supervision on CUBDimensionality d	16	32	64	128	256	512	1024Linear model	49.6	62.5	76.3	82.6	86.5	87.7	87.61 hidden layer	86.7	87.1	87.1	87.3	87.7	87.9	87.82 hidden layers	86.3	86.3	87.3	87.5	87.6	88.1	87.9Table 8: Validation accuracy (in %) as a function of the output dimensionality when using ProtoNet(Snell et al., 2017) as supervision on Flowers
Table 6: Validation accuracy (in %) as a function of the output dimensionality d when using ProtoNet(Snell et al., 2017) as supervision on CUBDimensionality d	16	32	64	128	256	512Linear model	56.0	58.3	58.6	58.6	58.6	58.41 hidden layer	57.7	59.8	60.2	60.3	60.3	60.02 hidden layers	57.4	58.5	59.4	59.6	59.5	59.3Table 7: Test accuracy (in %) as a function of the output dimensionality d when using ProtoNet(Snell et al., 2017) as supervision on CUBDimensionality d	16	32	64	128	256	512	1024Linear model	49.6	62.5	76.3	82.6	86.5	87.7	87.61 hidden layer	86.7	87.1	87.1	87.3	87.7	87.9	87.82 hidden layers	86.3	86.3	87.3	87.5	87.6	88.1	87.9Table 8: Validation accuracy (in %) as a function of the output dimensionality when using ProtoNet(Snell et al., 2017) as supervision on FlowersDimensionality d	16	32	64	128	256	512	1024Linear model	54.6	58.0	61.5	64.2	64.2	64.7	64.41 hidden layer	66.8	66.5	65.9	65.9	65.9	66.7	65.32 hidden layers	67.2	67.3	67.9	67.7	67.7	68.2	66.0Table 9: Test accuracy (in %) as a function of the output dimensionality when using ProtoNet (Snellet al., 2017) as supervision on Flowers
Table 7: Test accuracy (in %) as a function of the output dimensionality d when using ProtoNet(Snell et al., 2017) as supervision on CUBDimensionality d	16	32	64	128	256	512	1024Linear model	49.6	62.5	76.3	82.6	86.5	87.7	87.61 hidden layer	86.7	87.1	87.1	87.3	87.7	87.9	87.82 hidden layers	86.3	86.3	87.3	87.5	87.6	88.1	87.9Table 8: Validation accuracy (in %) as a function of the output dimensionality when using ProtoNet(Snell et al., 2017) as supervision on FlowersDimensionality d	16	32	64	128	256	512	1024Linear model	54.6	58.0	61.5	64.2	64.2	64.7	64.41 hidden layer	66.8	66.5	65.9	65.9	65.9	66.7	65.32 hidden layers	67.2	67.3	67.9	67.7	67.7	68.2	66.0Table 9: Test accuracy (in %) as a function of the output dimensionality when using ProtoNet (Snellet al., 2017) as supervision on FlowersC.3 Generalization to hard clusteringWe validate that DRPR can be used to perform hard clustering as in Snell et al. (2017) but withimplicit centers. To this end, we train a neural network with 2 convolutional layers on MNIST (LeCunet al., 1998) followed by a fully connected layer. Its output dimensionality is d = 2 or d = 3, themini-batch size is n = 1000, the number of categories is k = 10 and the target hard assignmentmatrix Y ∈ {0, 1}n×k contains category membership information (i.e., Yic is 1 if the example fi
Table 8: Validation accuracy (in %) as a function of the output dimensionality when using ProtoNet(Snell et al., 2017) as supervision on FlowersDimensionality d	16	32	64	128	256	512	1024Linear model	54.6	58.0	61.5	64.2	64.2	64.7	64.41 hidden layer	66.8	66.5	65.9	65.9	65.9	66.7	65.32 hidden layers	67.2	67.3	67.9	67.7	67.7	68.2	66.0Table 9: Test accuracy (in %) as a function of the output dimensionality when using ProtoNet (Snellet al., 2017) as supervision on FlowersC.3 Generalization to hard clusteringWe validate that DRPR can be used to perform hard clustering as in Snell et al. (2017) but withimplicit centers. To this end, we train a neural network with 2 convolutional layers on MNIST (LeCunet al., 1998) followed by a fully connected layer. Its output dimensionality is d = 2 or d = 3, themini-batch size is n = 1000, the number of categories is k = 10 and the target hard assignmentmatrix Y ∈ {0, 1}n×k contains category membership information (i.e., Yic is 1 if the example fibelongs to category c, 0 otherwise). We train the model on the training set of MNIST and plot inFig. 6 the representations of the test set. By assigning each test example to the category with closestcentroid (obtained from the training set), the model obtains 98% (resp. 99%) accuracy when d = 2(resp. d = 3). DRPR can then be learned for hard clustering when the centers are implicitly writtenas a function of the mini-batch matrix representation F and the target hard assignment matrix Y .
Table 9: Test accuracy (in %) as a function of the output dimensionality when using ProtoNet (Snellet al., 2017) as supervision on FlowersC.3 Generalization to hard clusteringWe validate that DRPR can be used to perform hard clustering as in Snell et al. (2017) but withimplicit centers. To this end, we train a neural network with 2 convolutional layers on MNIST (LeCunet al., 1998) followed by a fully connected layer. Its output dimensionality is d = 2 or d = 3, themini-batch size is n = 1000, the number of categories is k = 10 and the target hard assignmentmatrix Y ∈ {0, 1}n×k contains category membership information (i.e., Yic is 1 if the example fibelongs to category c, 0 otherwise). We train the model on the training set of MNIST and plot inFig. 6 the representations of the test set. By assigning each test example to the category with closestcentroid (obtained from the training set), the model obtains 98% (resp. 99%) accuracy when d = 2(resp. d = 3). DRPR can then be learned for hard clustering when the centers are implicitly writtenas a function of the mini-batch matrix representation F and the target hard assignment matrix Y .
