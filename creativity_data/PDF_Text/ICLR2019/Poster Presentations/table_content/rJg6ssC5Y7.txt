Table 1: Overview of the test problems included in DeepOB S with their properties showing if thetest problem includes convolutional layers (Conv), recurrent neural network cells (RNN), dropoutlayers (Drop), batch normalization layers (BN) or weight decay (WD). The first column highlightsthe machine learning task that the model performs, i.e. image classification ∙ , generative model ∙,natural language processing ∙ or problems where the loss function is given explicitly ∙ . Testproblems marked in ■ and ■ are part of the small and large benchmark set, respectively.
Table 2: DeepOB S benchmark for the baseline optimizers, showing the performance, speed andtuneability measures for SGD, Momentum and Adam on all eight test problems. The performanceis measured using the test accuracy in percent (when available, otherwise the test loss) and the speedusing the number of iterations to reach the convergence performance. All numbers are averaged overten runs with the same hyperparameter settings. The tuneability row indicates the best performing setof hyperparameters per test problem.
