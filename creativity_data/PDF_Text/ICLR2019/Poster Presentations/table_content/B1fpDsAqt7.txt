Table 1: Performance of MrelModel	Composition			Acc. (%)		BASE	OBJ	ATT	Object Subject	Mrel0	✓	-	-	51.0	55.9Mrel1	✓	Mobj	Matt	53.4	57.8Table 2: Accuracy for McntModelCompositionBASE OBJ ATTRELAcc. (%)Mcnt0	✓	-	--	45.4Mcnt1	✓	Mobj	Matt	-	47.4Mcnt2	✓	Mobj	Matt Mrel1	50.0Object Counting. We extract questions starting with ‘howmany' from VQA 2.0 which results in a training set of 〜50K questions. We additionally create 〜89Ksynthetic questions based on the VG dataset by counting the object boxes and forming ‘how many’7Published as a conference paper at ICLR 2019Table 3: Model ablation for VQA. We
Table 2: Accuracy for McntModelCompositionBASE OBJ ATTRELAcc. (%)Mcnt0	✓	-	--	45.4Mcnt1	✓	Mobj	Matt	-	47.4Mcnt2	✓	Mobj	Matt Mrel1	50.0Object Counting. We extract questions starting with ‘howmany' from VQA 2.0 which results in a training set of 〜50K questions. We additionally create 〜89Ksynthetic questions based on the VG dataset by counting the object boxes and forming ‘how many’7Published as a conference paper at ICLR 2019Table 3: Model ablation for VQA. Wereport mean±std computed over threeruns. Steady increase indicates that in-formation from modules helps, and thatPMN makes use of lower modules ef-fectively. The base model Mvqa0 does
Table 3: Model ablation for VQA. Wereport mean±std computed over threeruns. Steady increase indicates that in-formation from modules helps, and thatPMN makes use of lower modules ef-fectively. The base model Mvqa0 doesnot use any lower level modules otherthan the residual and attention modules.
Table 4: Comparing VQA accuracy of PMN with state-of-the-art models. Rows with Ens ✓denote ensemblemodels. test-dev is development test set and test-std is standard test set for VQA 2.0.
Table 5: Average human judg-ments from 0 to 4. ✓ indicatesthat model got final answer right,and X for wrong.
Table 6: Absolute gain in accuracy when US- ~~~^ …CA , ∙ .~~7T^Γ^Σ7	；	；	~ 三 Z~~7Σ~g	y	Fraction of VQA training data (in %)	1	5	10 25 50 100ing a fraction of the training data.	-----------------------------------------------------Absolute accuracy gain (in %)	-0.49 2.21 4.01 2.66 1.79 2.045 Conclusion and DiscussionIn this work, we proposed Progressive Module Networks (PMN) that train task modules in a com-positional manner, by exploiting previously learned lower-level task modules. PMN can producequeries to call other modules and make use of the returned information to solve the current task.
