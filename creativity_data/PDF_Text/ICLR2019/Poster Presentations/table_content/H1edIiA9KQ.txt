Table 1: Comparison of the Inception Score (IS) and Frechet Inception Distance (FID) on the MS-COCO data set for different models. Note: the IS and FID values of our models are not necessarilydirectly comparable to the other models, since our model gets at test time, in addition to the imagecaption, up to three bounding boxes and their respective object labels as input.
Table 2: Overview of the individual layers used in our networks to generate images of resolution64 × 64 / 256 × 256 pixels. Values in brackets (C, H, W) represent the tensor’s shape. Numbers inthe columns after convolutional, residual, or dense layers describe the number of filters / units in thatlayer. (fs=x, s=y, p=z) describes filter size, stride, and padding for that convolutional / residual layer.
Table 3: Words that were used to identify given labels in the image caption for the YOLOv3 objectdetection test.
Table 4: Results of YOLOv3 detections on generated and original images. Recall provides the fractionof images in which YOLOv3 detected the given object. IoU (Intersection over Union) measures themaximum IoU per image in which the given object was detected.
