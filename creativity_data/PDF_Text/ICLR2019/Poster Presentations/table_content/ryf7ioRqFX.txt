Table 1: Accuracy on transfer copying task. We find that the generalization of LSTMs trained withh-detach is significantly better compared with vanilla LSTM training when tested on time delayslonger that what the model is trained on (T = 100).
Table 2: A comparison of test accuracy on pixel by pixel MNIST and permuted MNIST (pMNIST)with existing methods.
Table 3: Test performance on image captioning task on MS COCO dataset using metrics BLEU1 to 4, METEOR, and CIDEr (higher values are better for all metrics). We re-implement bothShow&Tell (Vinyals et al., 2015) and Soft Attention (Xu et al., 2015) and train the LSTM in thesemodels with and without h-detach.
