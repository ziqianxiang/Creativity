Table 1: Overview of each dataset’s detailed properties. Image dimensions are given as width × height ×channels. Concerning data imbalance, the largest percentual difference in sample count between any twoclasses is given for training and test data, a value of 0 indicating a perfectly balanced dataset.
Table 2: Overview of all SLTs. The assignment of classes to sub-tasks D1 and D2 are disjunct, except forDP10-10 where two different seeded random image permutations are applied.
Table 3: Summary of incremental learning quality q~*, see Alg. 1, over SLTs of type D9-1, D5-5 and DP10-10(see also Tab. 5). For aggregating results over SLTs of the same type, the minimal value of q~* is taken. Eachcell contains two qualities evaluated according to the “best” and “last” criteria, see Alg. 1. Cell coloring wasdetermined according to “best”. For DP10-10 and D5-5 type tasks, CF (black cells) is indicated by qualities< 0.5. The corresponding threshold for D9-1 type tasks is 0.9. Only when the threshold is exceeded, re-trainingcan be regarded as successful which is visualized by a grayscale gradient (black - gray - white).
Table 4: Summary of incremental learning quality q~, see Alg. 1, for the IMM model, evaluated on SLTs oftype D9-1, D5-5 (DP10-10 is omitted because near-perfect performance Was alWays attained). For aggregatingresults over SLTs of the same type, the minimal value of q~* (the best) is taken, as the presence of CF isindicated by a single occurrence of it in any SLT of the same type. To be interpreted as Tab. 3.
Table 5: Results of Tab. 3, using the measure Ωaiι from Kemker & Kanan (2017). This is achieved by dividingthe “best” measure from Tab. 3 by the baseline performance. Each table entry contains two numbers: thebaseline performance and Ωaiι, and cell coloring (indicating presence or absence of CF) is performed basedon Ωaiι. The overall picture is similar to the one from Tab. 3, as indicated by the cell coloring. A notableexception is the performance of the CONV and D-CONV models on the SVHN dataset, where Ωaiι shows anincrease, but we do not consider this significant since the already the baseline performance is at chance levelhere. That is, this problem is too hard for the simple architectures we use, in which case a small fluctuationdue to initial conditions will exceed baseline performance. We therefore conclude that Ωaiι is an importantmeasure whenever baseline performance is better than random, in which case is it not meaningful. On the otherhand, our measure works well for random baselines but is less insightful for the opposite case (as the presenceof CF is not immediately observable from the raw performances. A combination of both measures might beinteresting to cover both cases.
