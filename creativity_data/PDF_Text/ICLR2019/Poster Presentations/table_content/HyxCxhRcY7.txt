Table 1: Out-of-distribution image detection for the maximum softmax probability (MSP) baselinedetector and the MSP detector after fine-tuning with Outlier Exposure (OE). Results are percentagesand also an average of 10 runs. Expanded results are in Appendix A.
Table 2: Comparisons between the MSP baseline and the MSP of the natural language classifierfine-tuned with OE. Results are percentages and averaged over 10 runs.
Table 3: Comparison among the maximum softmax probability, Confidence Branch, and ConfidenceBranch + OE OOD detectors. The same network architecture is used for all three detectors. Allresults are percentages, and averaged across all Doteustt datasets.
Table 4: Comparison among the maximum softmax probability (MSP), MSP + GAN, and MSP +GAN + OE OOD detectors. The same network architecture is used for all three detectors. All resultsare percentages and averaged across all Doteustt datasets.
Table 5: OOD detection results with a PixelCNN++ density estimator, and the same estimator afterapplying OE. The modelâ€™s bits per pixel (BPP) scores each sample. All results are percentages. Testdistributions Doteustt are described in Appendix A.
Table 6: OOD detection results on Penn Treebank language models. Results are percentages aver-aged over the Doteustt datasets. Expanded results are in Appendix F.
Table 7: Vision OOD example detection for the maximum softmax probability (MSP) baseline de-tector and the MSP detector after fine-tuning with Outlier Exposure (OE). All results are percentagesand the result of 10 runs. Values are rounded so that 99.95% rounds to 100%. More results are inAppendix E.
Table 8: NLP OOD example detection for the maximum softmax probability (MSP) baseline detec-tor and the MSP detector after fine-tuning with Outlier Exposure (OE). All results are percentagesand the result of 10 runs. Values are rounded so that 99.95% rounds to 100%.
Table 9: Results using an All Convolutional Network architectures. Results are percentages and anaverage of 10 runs.
Table 10: Comparison between the maximum softmax probability (MSP) and H (U ; p) OOD scoringmethods on a network fine-tuned with OE. Results are percentages and an average of 10 runs.
Table 11: OOD detection results on Penn Treebank examples and English Web Treebank outliers.
Table 12: Calibration results for the temperature tuned baseline and temperature tuning + OE.
Table 13: Calibration results for the softmax temperature tuning baseline, the same baseline afteradding Posterior Rescaling, and temperature tuning + Posterior Rescaling + OE.
