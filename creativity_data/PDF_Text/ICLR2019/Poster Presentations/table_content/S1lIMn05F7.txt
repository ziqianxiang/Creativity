Table 1: Classification accuracies under white box and black box attack on MNIST ( = 0.3)training method∖attack	white box			black box						No Noise FGS		PGD	FGS(A')PGD(A')		FGS(B’) PGD(B’) FGS(C’) PGD(C’)			Standard(A)	96.34%	64.64%	3.69%	69.47%	49.92%	56.46%	44.25%	89.71%	83.02%adversarial PGD(B)	87.45%	55.94%	42.96%	85.21%	83.46%	59.09%	48.20%	87.41%	83.23%adversarial network(C)	96.34%	91.51%	37.97%	90.02%	88.04%	75.34%	57.52%	91.48%	81.68%Table 2: Classification accuracies under white box and black box attacks on SVHN ( = 0.05)et al., 2016) adapted to 32x32 images as our discriminative networks. For the generator in ouradversarial network we use an encoder-decoder network based on residual blocks from ResNet. SeeModel D2 and Model G1 in the Appendix for details. For the discriminative networks we use SGDwith learning rate of ηD = 0.01 and momentum 0.9, batch size of 64, weight decay of 1E-4 and runfor 100k iterations, and then decrease the learning rate to 0.001 and run for another 100k iterations.
Table 2: Classification accuracies under white box and black box attacks on SVHN ( = 0.05)et al., 2016) adapted to 32x32 images as our discriminative networks. For the generator in ouradversarial network we use an encoder-decoder network based on residual blocks from ResNet. SeeModel D2 and Model G1 in the Appendix for details. For the discriminative networks we use SGDwith learning rate of ηD = 0.01 and momentum 0.9, batch size of 64, weight decay of 1E-4 and runfor 100k iterations, and then decrease the learning rate to 0.001 and run for another 100k iterations.
Table 3: Classification accuracies under white box and black box attack on CIFAR10 ( = 8/256)training method\attack	white box No Noise FGS PGD	black box FGS(A’)PGD(A,) FGS(B’)PGD(B’)FGS(C’)PGD(C')ensemble(MNIST, = 0.3) adv. net(MNIST, = 0.3)	98.65%^^2.52%^^0.00% 99.03% 94.66% 87.09%	90.91% 93.91% 90.94% 88.12% 90.79% 89.61% 95.75% 96.19% 96.15% 95.24% 96.96% 95.78%ensemble(SVHN, = 0.05) adv. net(SVHN, = 0.05)	95.30% 79.16% 2.74%= 96.34% 91.51% 37.97%	95.32% 93.88 % 67.97% 54.81% 95.60% 93.21% 90.02% 88.04% 75.34% 57.52% 91.48% 81.68%ensemble(CIFAR10, e = ^^) adv. net(CIFAR10,e =嘉)	87.17%^^57.91% 11.35% 91.08% 72.81% 44.28%	85.01% 85.19% 68.76% 67.41% 79.64% 70.98% 81.74% 79.48% 77.23% 74.04% 78.51% 66.74%Table 4: Classification accuracies under white box and black box attacks on ensemble adversarialtraining and adversarial networks on different datasetsB’, and offers the smallest drop in accuracies in general. But its overall results are not the best sinceit suffers from the disadvantage of having a lower baseline accuracy on clean examples.
Table 4: Classification accuracies under white box and black box attacks on ensemble adversarialtraining and adversarial networks on different datasetsB’, and offers the smallest drop in accuracies in general. But its overall results are not the best sinceit suffers from the disadvantage of having a lower baseline accuracy on clean examples.
Table 5: Attack performance of various generator networks against an undefended network in termsof test accuracies. First column is the accuracy on the discriminative model Dθ that the generativeattacker Gφ is trained on (similar to white box attacks). The next three columns are the attackaccuracies on other models by the learned Gφ (similar to black box attacks)training method\attack	No Noise	white box FGS	PGD	black box							FGS(A')	PGD(A’)	FGS(B’)	PGD(B’)autoencoder(8 filters)	88.70%	67.28%	33.56%	78.94%	74.15%	70.70%	68.54%autoencoder(64 filters)	89.10%	67.05%	33.38%	79.56%	74.40%	70.52%	68.66%random Gaussian	89.73%	69.43%	35.16%	80.09%	76.02%	71.22%	69.66%label	88.72%	67.09%	37.70%	80.95%	77.80%	70.90%	68.81%Table 6: Classification accuracies under white box and black box attacks on CIFAR10 for adversarialnetworks trained with different generative adversaries ( = 8/256)4.5	Examining the Generative NetworksWe also did a more in-depth study on the generative network with CIFAR10. We want to understandhow the capacity of the generative network affects the quality of saddle point solution, and alsothe power of the generative networks themselves as adversarial attack methods. First we study theability of the generative networks to learn to attack a fixed undefended discriminative network. Thearchitectures of the generative networks (G1, G2, G3) are described in the Appendix. Here we studya narrow (G1, k = 8) and a wide version (G1, k = 64) of autoencoder networks using the inputimages as inputs, and also decoder networks G(z) using random Gaussian vectors z ∈ Rd (G2) or
Table 6: Classification accuracies under white box and black box attacks on CIFAR10 for adversarialnetworks trained with different generative adversaries ( = 8/256)4.5	Examining the Generative NetworksWe also did a more in-depth study on the generative network with CIFAR10. We want to understandhow the capacity of the generative network affects the quality of saddle point solution, and alsothe power of the generative networks themselves as adversarial attack methods. First we study theability of the generative networks to learn to attack a fixed undefended discriminative network. Thearchitectures of the generative networks (G1, G2, G3) are described in the Appendix. Here we studya narrow (G1, k = 8) and a wide version (G1, k = 64) of autoencoder networks using the inputimages as inputs, and also decoder networks G(z) using random Gaussian vectors z ∈ Rd (G2) ornetworks G(y) using the labels y (G3) as inputs. We run SGD for 200k iterations with step size0.01 and momentum of 0.9, and use weight decay of 1E-5. We report test accuracies on the originaldiscriminator after attacks.
Table 7: Classification accuracies under white box and black box attacks on CIFAR100 ( = 8/256)13Published as a conference paper at ICLR 2019Input: 28x28 image with c channelsconv2d(5,2,64) - BN - ReLUconv2d(5,2,128) - BN - ReLUdeconv2d(5,2,64) - BN - ReLUdeconv2d(5,2,c) - BN - ReLUTanh(a)	G0Input: Random Gaussian z ∈ R256kreshape(8,8,4k)residual-block(3,1,4k) ×6deconv2d(3,2,2k) - BN - ReLUdeconv2d(3,2,k) - BN - ReLUconv2d(3,1,c)Tanh(c) G2Input: 32x32 image with c channelsconv2d(3,1,k) - BN - ReLU
Table 8: Classification accuracies under white box and black box attacks on CIFAR10 with WideResNet ( = 8/256)Table 8 gives the results on CIFAR10 using a wider version of Resnet (Model D2), by multiplyingthe number of filters in each convolutional layer by a factor of 10. Some of the previous works inthe literature use models of larger capacity for training adversarially robust models, so we performexperiments on these large capacity models here. First the accuracies increase across the board withlarger capacity models. The accuracy gap on clean data between adversarial PGD and standardtraining still exists, but now there is also a small accuracy gap between our adversarial networkapproach and standard training. For the rest of the white box and black accuracies the story is similar,the models are weakest against attacks trained with the same method but with a different randomseed. Our adversarial network approach has very good performance across different attacks, even asit is not always the winner for each individual attack. Table 9 gives the results of Wide ResNet onCIFAR100, and the results are qualitatively similar.
Table 9: Classification accuracies under white box and black box attacks on CIFAR100 with WideResnet ( = 8/256)14Published as a conference paper at ICLR 2019Generator	Original (B)	Standard(A’)	adversarial PGD(B’)	adversarial network(C’)original accuracy	75.30%	90.54%	75.71%	89.21%autoencoder(8 filters)	72.74%	88.38%	73.07%	87.89%autoencoder(64 filters)	71.26%	87.64%	71.98%	87.02%random Gaussian	74.13%	88.71%	74.70%	88.45%label	70.15%	84.95%	70.10%	84.96%Table 10: Attack performance of various generator networks against a network trained with adver-sarial PGD in terms of test accuracies. First column is the accuracy on the discriminative model Dθthat the generative attacker Gφ is trained on (similar to white box attacks). The next three columnsare the attack accuracies on other models by the learned Gφ (similar to black box attacks)Generator	Original (C)	Standard(A’)	adverSarial PGD(B’)	adverSarial network(C’)original accuracy	91.08%	90.54%	75.71%	89.21%autoencoder(8 filters)	74.66%	66.95%	74.42%	80.55%autoencoder(64 filters)	53.68%	46.37%	73.08%	72.18%random Gaussian	85.91%	71.00%	75.00%	86.55%label	81.46%	77.46%	73.09%	83.98%
Table 10: Attack performance of various generator networks against a network trained with adver-sarial PGD in terms of test accuracies. First column is the accuracy on the discriminative model Dθthat the generative attacker Gφ is trained on (similar to white box attacks). The next three columnsare the attack accuracies on other models by the learned Gφ (similar to black box attacks)Generator	Original (C)	Standard(A’)	adverSarial PGD(B’)	adverSarial network(C’)original accuracy	91.08%	90.54%	75.71%	89.21%autoencoder(8 filters)	74.66%	66.95%	74.42%	80.55%autoencoder(64 filters)	53.68%	46.37%	73.08%	72.18%random Gaussian	85.91%	71.00%	75.00%	86.55%label	81.46%	77.46%	73.09%	83.98%Table 11: Attack performance of various generator networks against our adversarial network interms of test accuracies. First column is the accuracy on the discriminative model Dθ that thegenerative attacker Gφ is trained on (similar to white box attacks). The next three columns are theattack accuracies on other models by the learned Gφ (similar to black box attacks)undefended network in Section 4.5. Table 10 shows the results of various generative networks inattacking a network trained with adversarial PGD. The adversarial PGD network is very robust, andthe generative networks can at most reduce the accuracy by 5%. Interestingly, the strongest attackcome from the more restrictive generative network using only the label as input. It is also the mostsuccessful in transferring to other networks. However, since the adversarial PGD network is sorobust, none of the generative networks can learn much from it in generating adversarial examples.
Table 11: Attack performance of various generator networks against our adversarial network interms of test accuracies. First column is the accuracy on the discriminative model Dθ that thegenerative attacker Gφ is trained on (similar to white box attacks). The next three columns are theattack accuracies on other models by the learned Gφ (similar to black box attacks)undefended network in Section 4.5. Table 10 shows the results of various generative networks inattacking a network trained with adversarial PGD. The adversarial PGD network is very robust, andthe generative networks can at most reduce the accuracy by 5%. Interestingly, the strongest attackcome from the more restrictive generative network using only the label as input. It is also the mostsuccessful in transferring to other networks. However, since the adversarial PGD network is sorobust, none of the generative networks can learn much from it in generating adversarial examples.
