Table 1: Results of ablation testing on our verifier, where each test removes a single optimization. Thetask was to determine the adversarial accuracy of the MNIST classifier LPd-CNNA to perturbationswith l∞ norm-bound = 0.1. Build time refers to time used to determine bounds, while solvetime refers to time used to solve the main MILP problem in Equation 2 once all bounds have beendetermined. During solve time, we solve a linear program for each of the nodes explored in the MILPsearch tree.
Table 2: Adversarial accuracy of MNIST and CIFAR-10 classifiers to perturbations with l∞ norm-bound . In every case, we improve on both 1) the lower bound on the adversarial error, found byPGD, and 2) the previous state-of-the-art (SOA) for the upper bound, generated by the followingmethods: [1] Kolter & Wong (2017), [2] Dvijotham et al. (2018), [3] Raghunathan et al. (2018). Forclassifiers marked with a X, we have a guarantee of robustness or a valid adversarial example forevery test sample. Gaps between our bounds correspond to cases where the solver reached the timelimit for some samples. Solve statistics on nodes explored are in Appendix F.1.
Table 3: Determinants of verification time: mean verification time is 1) inversely correlated to thenumber of labels that can be eliminated from consideration and 2) correlated to the number of ReLUsthat are not provably stable. Results are for = 0.1 on MNIST; results for other networks are inAppendix F.2.
Table 4: Performance of verifier with different MILP solvers on MNIST LPd-CNNA network withE = 0.1. Verifier performance is best with Gurobi, but our verifier outperforms both the lower boundfrom PGD and the upper bound generated by the SOA method in Kolter & Wong (2017) when usingthe Cbc solver too.
Table 5: Solve statistics on nodes explored when determining adversarial accuracy of MNIST and CIFAR-10 classifiers to perturbations with l∞ norm-bound . We solve a linear program for each of the nodes explored in the MILP search tree.										Dataset	Network		Mean Time /s	Nodes Explored										Mean	Median	90	Percentile		99.9	Max							95	99		MNIST	LPd-CNNB	0.1	46.33	8.18	0	0	0	1	2385	20784	LPd-CNNA	0.1	3.52	1.91	0	0	0	1	698	1387	Adv-cnnA	0.1	135.74	749.55	0	201	3529	20195	31559	50360	Adv-mlpB	0.1	3.69	87.17	0	1	3	2129	11625	103481	SDPd-MLPA	0.1	312.43	4641.33	39	17608	21689	27120	29770	29887	LPd-CNNA	0.2	7.32	15.71	0	1	1	540	2151	7105	LPd-CNNB	0.3	98.79	305.82	0	607	1557	4319	28064	185500	LPd-CNNA	0.3	5.13	31.58	0	5	119	788	2123	19650	LPd-CNNA	0.4	5.07	57.32	1	79	320	932	3455	43274CIFAR-10	LPd-CNNA	2 255	22.41	195.67	0	1	1	4166	29774	51010	LPd-RES	255 255	15.23	41.38	0	1	3	1339	4239	5022Table 6: Solve statistics on number of labels that can be eliminated from consideration, and numberof ReLUs that are provably stable, when determining adversarial accuracy of MNIST and CIFAR-10classifiers to perturbations with l∞ norm-bound .
Table 6: Solve statistics on number of labels that can be eliminated from consideration, and numberof ReLUs that are provably stable, when determining adversarial accuracy of MNIST and CIFAR-10classifiers to perturbations with l∞ norm-bound .
Table 7: Effect of sparsification of SDPd-MLPA on verifiability. Test error increases slightly as largerfractions of kernel weights are set to zero, but the certified upper bound on adversarial error decreasessignificantly as the solver reaches the time limit for fewer samples.
