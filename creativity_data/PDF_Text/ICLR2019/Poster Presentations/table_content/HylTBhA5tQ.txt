Table 1: Average K-L divergence and normalized `2 distance between training and test sets acrossall classes. We use both adversarially trained networks (adv.) and naturally trained networks (nat.)as our feature extractors when computing K-L divergence. Note that we only attack images that arecorrectly classified and report success rate on those images.
Table 2: Attack success rate (suc. rate) and test accuracy (acc) of scaled and shifted MNIST. Anattack is considered successful if its '∞ distortion is less than thresholds (th.) 0.3 or 0.3α.
Table 3: Attack success rate (suc. rate) and test accuracy (acc) of scaled and shifted Fashion-MNIST.
Table 4: Blind-spot attack on MNIST and Fashion-MNIST for robust models by Kolter & Wong(2018)15Published as a conference paper at ICLR 2019MNIST	α, β	α = 1.0	α = 0.95				α = 0.9					β = 0	β=0		β = 0.025		β=0		β = 0.05		Accuracy	98.7%	985%		98.6%		987%		984%		Success criterion ('2 norm)	2	2	1.9	2	1.9	2	1.8	2	1.8	Success rates	12.2%	27.05%	22.95%	36.15%	30.9%	45.25%	31.55%	58.9%	45.6%Fashion-MNIST	α, β	α = 1.0	α = 0.95				α = 0.9					β = 0	β = 0		β = 0.025		β = 0		β = 0.05		Accuracy	88.5%	883%		88.2%		88.1%		87.8%		Success criterion ('2 norm)	2	2	1.9	2	1.9	2	1.8	2	1.8	Success rates	31.4%	46.3%	41.1%	58 %	53.3%	61.2%	51.8%	69.1%	62.85%Table 5: Blind-spot attack on MNIST and Fashion-MNIST for robust models by Sinha et al. (2018).
Table 5: Blind-spot attack on MNIST and Fashion-MNIST for robust models by Sinha et al. (2018).
