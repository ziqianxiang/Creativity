Table 1: Best inception scores (averaged over 5 runs) achieved on CIFAR10 for every considered Adam variant.
Table 2: DCGAN architecture used for our CIFAR-10 experiments. When using the gradient penalty(WGAN-GP), we remove the Batch Normalization layers in the discriminator.
Table 3: Best inception scores (averaged over 5 runs) achieved on CIFAR10 for every consid-ered Adam variant. We see that the techniques of extrapolation and averaging consistently enableimprovements over the baselines (in italic).
Table 4: ResNet architecture used for our CIFAR-10 experiments. When using the gradient penalty(WGAN-GP), we remove the Batch Normalization layers in the discriminator.
Table 5: Best FID scores (averaged over 5 runs) achieved on CIFAR10 for every considered Adamvariant. OptimAdam is the related Optimistic Adam (Daskalakis et al., 2018) algorithm. We see thatthe techniques of extrapolation and EMA consistently enable improvements over the baselines (initalic).
