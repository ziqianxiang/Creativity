Table 1: Negative Log-likelihood (NLL) results for different few-shot settings on Omniglot and miniImageNet.
Table 3: Accuracy results for different few-shot settings on Omniglot and miniImageNet. The ± sign indicatesthe 95% confidence interval over tasks using a Student’s t-distribution approximation. Bold text indicates thehighest scores that overlap in their confidence intervals.
Table D.1: Feature extraction network used for Omniglot few-shot learning. Batch Normalization and dropoutwith a keep probability of 0.9 used throughout.
Table D.2: Feature extraction network used for miniImageNet few-shot learning. Batch Normalization anddropout with a keep probability of 0.5 used throughout.
Table D.3: Amortization network used for Omniglot and miniImageNet few-shot learning.
Table D.4: Linear classifier used for Omniglot and miniImageNet few-shot learning.
Table E.1: List of ShapeNet categories used in the Versa view reconstruction experiments.
Table E.2: Encoder network used for ShapeNet few-shot learning. No dropout or batch normalization is used.
Table E.3: Amortization network used for ShapeNet few-shot learning.
Table E.4: Generator network used for ShapeNet few-shot learning. No dropout or batch normalization is used.
