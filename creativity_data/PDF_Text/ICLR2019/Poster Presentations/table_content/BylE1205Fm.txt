Table 1: A comparison to other unsupervised guided image to image translation methods. *k = 5 isthe number of pre-segmented face parts. ^Used for domain confusion, not on the output.
Table 2: Runtime and memory footprint statistics for our method, the two guided translation methodsfrom the literature (MUNIT and DRIT), and the Fader network disentangled representation method.
Table 3: User study results. In each cell is the ratio of images, were users selected a real image asmore natural than a generated one. Closer to 50% is better for the method.
Table 4: Classifier results for the image obtained after removing the desired feature. Results are themean probability of domain B for images that were transformed to domain A.
