Table 1: Naturalness of the adapted voices using a 5-scale MOS score (higher is better) with 95%confidence interval on the LibriSpeech and VCTK held-out adaptation datasets. Numbers in bold arethe best few-shot learning results on each dataset without statistically significant difference. van denOord et al. (2016) was trained with 24-hour production quality data, Nachmani et al. (2018) used allsamples of each new speaker, Arik et al. (2018) used 10 samples, and Jia et al. (2018) used 5 seconds.
Table 2: Voice similarity of generated voices using a 5-scale MOS score (higher is better) with 95%confidence interval on the LibriSpeech and VCTK held-out adaptation datasets.
Table 3: Equal error rate (EER) of real and few-shot adapted voice samples for evaluation of voicesimilarity. Varying adaptation dataset sizes were considered.
