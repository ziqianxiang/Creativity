Table 1: Comparing an LSTM trained with fixed and per-turbed output dropouts, an STN, and LSTM trained with the Figure 3: Dropout schedules found by the ST-STN schedule.	LSTM for different initial dropout rates.
Table 2: Final validation and test performance of each method on the PTB word-level language modeling task,and the CIFAR-10 image-classification task.
Table 3: Table of Notationλ, Wλo, W0n, mf(λ, w),F (λ, w)rLτ(λ, w), LV(λ, w)Hyperparameters and parametersCurrent, fixed hyperparameters and parametersHyperparameter and elementary parameter dimensionLower-level & upper-level objectiveFunction mapping unconstrained hyperparameters to the appropriate restricted spaceTraining loss & validation loss - (LT (r(λ), w), LV (r(λ), w)) = (f (λ, w), F(λ, w))w*(λ)F *(λ)λ*W φ(λ)φσσ
