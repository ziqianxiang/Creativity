Table 1: BLEU scores on IWSLTDe什En translation. “KD”, “BT” and “Dual” stands forknowledgedistillation, back translation and dual learning respectively.
Table 2: BLEU scores on the translations between {Es, Ru, He} and En.
Table 3: BLEU scores on WMT14 En分De translation. “Bitext” and “Mono” respectively representsusing bilingual data only and using the mix of bilingual&monolingual data.
Table 4: BLEU scores on WMT {16, 17, 18} En→De. The single models are independently trainedfor six times, with mean and standard derivation values reported; the ensemble models are the en-Semble results of all different runs._____________________________________________	2016	2017	2018Google Translator	38.03	31.41	47.67FAIR (Single)	37.04 ± 0.16	31.86 ± 0.21	44.63 ± 0.12Ours (Single)	40.68 ± 0.11	33.47 ± 0.16	48.89 ± 0.13MS-Marian (Ensemble)	39.6	31.9	48.3FAIR (Ensemble)	37.99	32.80	46.05Ours (Ensemble)	41.23	34.01	49.613.5	Results of NMT with Monolingual Data OnlyUnsupervised NMT is studied recently to learn two translation models without bilingual data (detailsin Appendix C). We pre-train two unsupervised NMT models with different initialization, use themto translate the 50M monolingual sentences, and apply KD, BT and dual learning algorithms.
Table 5: BLEU scores on WMT 2016 UnsUPvised NMT En什De translation.
Table 6: FID scores on Painting→photos translation.
Table 7: FCN-SCoreS on cityscapes labels→photos translation.
Table 8: Classification performances of Cityscapes photo → labels translation.
