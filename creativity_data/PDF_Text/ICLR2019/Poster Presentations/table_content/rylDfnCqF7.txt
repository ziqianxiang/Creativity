Table 1: Results on Yahoo and Yelp datasets. We report mean values across 5 different random restarts, andstandard deviation is given in parentheses when available. For LSTM-LM* We report the exact negative loglikelihood.
Table 2: Results on OMNIGLOT dataset. We report mean values across 5 different random restarts, andstandard deviation is given in parentheses when available. For PixelCNN* we report the exact negative loglikelihood.
Table 3: Comparison of total training time, in terms of relative speed and absolute hours.
Table 4: Results on Yelp dataset using a fixed budget of inner encoder updates# Inner Iterations	NLL	KL	MI	AU	Hours10	357.9	1.1	1.0	3	11.9730	357.1	3.6	2.5	8	22.3150	356.9	4.2	2.8	9	29.5870	357.1	4.4	2.7	10	24.18convergence	357.0	3.8	2.6	8	21.446.4	Analysis of BaselinesWe analyze the difference between our approach and the methods that weaken the KL regularizerterm in ELBO, and explain the unwanted behavior produced by breaking maximum likelihood es-timation. As illustrative examples, we compare with the KL cost annealing method and Î²-VAE.
Table 5: Results on Yahoo and Yelp datasets. We report mean values across 5 different random restarts, andstandard deviation is given in parentheses when available. For LSTM-LM* We report the exact negative loglikelihood.
Table 6: Results on OMNIGLOT dataset. We report mean values across 5 different random restarts, andstandard deviation is given in parentheses when available. For PixelCNN* we report the exact negative loglikelihood.
Table 7: Evaluation of a trained VAE model trained by our approach across 10 different random seeds. Meanvalues are reported and variance is given in parentheses. IW denotes the approximation to NLL we used inSection 6.
Table 8: Evaluation of a trained VAE model trained by basic VAE training across 10 different random seeds.
Table 9: Results on Yahoo and Yelp datasets, with different annealing schedules. Starred entries representoriginal annealing strategy.
Table 10: ResultsonYelpdatsetvaryinglearnigrateofinferencenetwork.
