Table 1: MNIST Autoencoder We display the training MSE for the hyperparameter setting that achieved thebest training loss. The validation and test errors are displayed for the hyperparameter setting that achieved thebest validation MSE. In each CaSe the average loss and standard deviation over 15 runs is displayed.
Table 2: Classification accuracy on CIFAR-10 and CIFAR-100 We display results using the optimal hyper-parameters for CM, Nesterov, Adam and AggMo on the validation set and also with default settings for CM,Figure 6: ResNet-32 Trained On CIFAR-100 The training loss and validation accuracy during training onCIFAR-100 for each optimizer.
Table 3: Penn Treebank LSTM Perplexity across different optimizers. We display the train, validation, and testerror for the optimization run that produced the best validation loss. * uses ASGD (Polyak & Juditsky, 1992)and corresponds to the base model reported in Merity et al. (2017)observed all momentum-based optimizers but CM outperform SGD without momentum. Surprisingly,we found that Adam is well-suited to this task and achieves the best training, validation, and testperformance. We believe that the heavy regularization used when training the network makes Adama good choice. AggMo is very close in terms of final performance to Adam.
Table 4: MNIST Autoencoder with default settings We display the training MSE for the initial learning ratethat achieved the best training loss. The validation and test errors are displayed for the initial learning rate thatachieved the best validation MSE.
