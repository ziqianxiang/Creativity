Table 1: A comparison of returns for continuous environments. The returns were computed using300 episodes. Our approach gives comparable returns to using GAIL but also segments expertdemonstrations into sub-tasks. The proposed Directed-Info GAIL approach improves over the policylearned from the VAE pre-training step.
Table 2: Mean returns over 100 episodes onFetchPickandPlace-v1 environment, calculated us-ing the ‘dense’ reward setting.
Table 3: Experiment settings for all the different environments for both DirectedInfo-GAIL andVAE-Pretraining step respectively.
