Table 1: Comparison with state-of-the-art image classifiers on CIFAR-10 (lower error rate is better).
Table 2: Comparison with state-of-the-art language models on PTB (lower perplexity is better). Notethe search cost for DARTS does not include the selection cost (1 GPU day) or the final evaluationcost by training the selected architecture from scratch (3 GPU days).
Table 3: Comparison with state-of-the-art image classifiers on ImageNet in the mobile setting.						Architecture	Test Error (%)		Params (M)	+× (M)	Search Cost (GPU days)	Search Method	top-1	top-5				Inception-v1 (Szegedy et al., 2015)	30.2	101	6.6	1448	-	manualMobileNet (Howard et al., 2017)	29.4	10.5	4.2	569	-	manualShuffleNet 2× (g = 3) (Zhang et al., 2017)	26.3	—	〜5	524	—	manualNASNet-A (Zoph et al., 2018)	26.0	8.4	5.3	564	2000	RLNASNet-B (Zoph et al., 2018)	27.2	8.7	5.3	488	2000	RLNASNet-C (Zoph et al., 2018)	27.5	9.0	4.9	558	2000	RLAmoebaNet-A (Real et al., 2018)	25.5	8.0	5.1	555	3150	evolutionAmoebaNet-B (Real et al., 2018)	26.0	8.5	5.3	555	3150	evolutionAmoebaNet-C (Real et al., 2018)	24.3	7.6	6.4	570	3150	evolutionPNAS (Liu et al., 2018a)	25.8	8.1	5.1	588	〜225	SMBODARTS (searched on CIFAR-10)	26.7	8.7	4.7	574	4	gradient-based3.3	Results AnalysisThe CIFAR-10 results for convolutional architectures are presented in Table 1. Notably, DARTSachieved comparable results with the state of the art (Zoph et al., 2018; Real et al., 2018) while usingthree orders of magnitude less computation resources (i.e. 1.5 or 4 GPU days vs 2000 GPU days forNASNet and 3150 GPU days for AmoebaNet). Moreover, with slightly longer search time, DARTSoutperformed ENAS (Pham et al., 2018b) by discovering cells with comparable error rates but less
Table 4: Comparison with state-of-the-art language models on WT2.					Architecture	Perplexity		Params (M)	Search Cost (GPU days)	Search Method	valid	test			LSTM + augmented loss (Inan et al., 2017)	91.5	87.0	28	-	manualLSTM + continuous cache pointer (Grave et al., 2016)	-	68.9	-	-	manualLSTM (Merity et al., 2018)	69.1	66.0	33	-	manualLSTM + skip connections (Melis et al., 2018)	69.1	65.9	24	-	manualLSTM + 15 softmax experts (Yang et al., 2018)	66.0	63.3	33	-	manualENAS (Pham et al., 2018b)* (searched on PTB)	72.4	70.4	33	0.5	RLDARTS (searched on PTB)	71.2	69.6	33	1	gradient-based* Obtained by training the corresponding architecture using our setup.
