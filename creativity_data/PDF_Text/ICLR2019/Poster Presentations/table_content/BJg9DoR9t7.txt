Table 1: Reference for common f -divergences and corresponding MIGf ’s building blocks. Thistable is induced from Nowozin et al. (2016).
Table 2: Accuracy on LabelMe (real-world crowdsourced labels)Method Majority Vote Crowd Layer Doctor Net AggNet Max-MIGAccuracy	80.41 ± 0.56	83.65 ± 0.50	80.56 ± 0.59 85.20 ± 0.26 86.42 ± 0.36Figure 4: Results on Dogs vs. Cats, CIFAR-10, LUNA16.
Table 3: Data-Crowds Forecaster Comparison: Max-MIG VS AggNetDataset	Method	4.1(H)	4.2(H)	4.3(H)	4.1(L)	4.2(L)	4.3(L)	Max-MIG (d)	79.52	80.25	78.94	71.44	71.07	68.40Dogs vs.Cats	Max-MIG (dc)	88.80	87.60	87.17	73.99	73.38	70.75	AggNet (d)	79.36	79.53	71.97	70.46	70.07	63.85	AggNet (dc)	88.00	88.56	75.00	71.27	70.75	61.14	Max-MIG(d)	86.33	86.55	86.71	70.16	69.99	67.59CIFAR-10	Max-MIG(dc)	98.10	98.18	99.06	75.55	75.11	72.47	AggNet(d)	86.13	86.27	63.91	70.21	62.50	38.27	AggNet(dc)	99.05	99.01	70.01	74.76	72.02	29.03	Max-MIG(d)	90.88	91.06	91.15	88.90	89.04	88.85LUNA16	Max-MIG(dc)	94.56	93.97	92.63	91.16	91.23	92.05	AggNet(d)	89.56	90.23	83.47	81.42	83.53	81.68	AggNet(dc)	91.13	91.94	65.14	70.97	74.41	61.76Here (dc) is the shorthand for data-crowds forecaster and (d) is the shorthand for data-classifier. Wetake the average of five times experiments and the variance is pretty small. Due to space limitation,we omit the variance here.
