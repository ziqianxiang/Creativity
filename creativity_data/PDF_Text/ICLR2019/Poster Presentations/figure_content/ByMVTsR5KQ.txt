Figure 1:	First eight principal components for 5x5 patches from natural images (left) versus thoseof length-25 audio slices from speech (right). Periodic patterns are unusual in natural images but afundamental structure in audio.
Figure 2:	Depiction of the transposed convolution operation for the first layers of the DCGAN (Rad-ford et al., 2016) (left) and WaveGAN (right) generators. DCGAN uses small (5x5), two-dimensional filters while WaveGAN uses longer (length-25), one-dimensional filters and a largerupsampling factor. Both strategies have the same number of parameters and numerical operations.
Figure 3: At each layer of the Wave-GAN discriminator, the phase shuffleoperation perturbs the phase of eachfeature map by Uniform 〜 [-n, n]samples, filling in the missing samples(dashed outlines) by reflection. Here wedepict all possible outcomes for a layerwith four feature maps (n = 1).
Figure 4: Top: Random samples from each of the five datasets used in this study, illustrating thewide variety of spectral characteristics. Middle: Random samples generated by WaveGAN for eachdomain. WaveGAN operates in the time domain but results are displayed here in the frequencydomain for visual comparison. Bottom: Random samples generated by SpecGAN for each domain.
Figure 5: (Top): Average impulse response for 1000 random initializations of the WaveGAN gen-erator. (Bottom): Response of learned post-processing filters for speech and bird vocalizations.
Figure 6: Depiction of the upsampling strategy used by transposed convolution (zero insertion) andother strategies which mitigate aliasing: nearest neighbor, linear and cubic interpolation.
Figure 7: Compared to resting state, this cat’s level of alertness increased when presented birdvocalizations synthesized by WaveGAN and SpecGAN.
