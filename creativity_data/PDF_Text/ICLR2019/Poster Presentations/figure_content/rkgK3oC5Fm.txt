Figure 1: Blue: Groundtruth distri-bution. Black: Models sampled atrandom from the model distribution.
Figure 2: The architecture of our ResNet based gener-ative models for street scene prediction in our modeldistribution q(ω).
Figure 3: Left: MNIST generations: The models see the non grayed-out region of the digit. The samples aregenerated from models drawn at random from ω 〜q(ω). Right: Top-10% accuracy on MNIST generation.
Figure 5: Bayes-WD-SL (top 1) vs ResG-Mean. Cyan: Bayes-WD-SL is correct and ResG-Mean is wrong.
Figure 6: Random samples from our Bayes-WD-SL model corresponds to the range of likely movements ofbicyclists/pedestrians.
Figure 4: Uncertainty calibration at t + 10.
Figure 7: Blue: Data points. Black: Sampled modelsω ∈ q(ω) learned by the Bayes-S approach. Allmodels fit to the mean.
Figure 8: Blue: Data points. Black: Sampled modelsω ∈ q(ω) learned by the Bayes-SL approach. Werecover models covering both modes.
Figure 9: Predicted radar intensity to the true mean observed intensity.
Figure 10: Example Top-1 predictions by our Bayes-WD-SL model.
