Figure 1: An illustration of the domains and functionsemployed in our work. DA and DB are the distribu-tions of images in the two domains. e1 and e2 the twopathways of the encoder, g is the decoder, which isapplied to f, which aggregates the output of the twoencoder pathways. There are only three constraintsused while training, shown in red: (i) a reconstructionloss in domain A, comparing g ◦ f (a, a) with a, (ii)a reconstruction loss in domain B , and (iii) a measureof the discrepancy between the distributions e1 ◦ DAand e1 ◦DB, measured with a domain confusion term.
Figure 5: Interpolation experiments, where the content representation is linearly mixed between theone extracted from the left image and the one extracted from the right image.
Figure 6: A comparison to the Fader networks of Lample et al. (2017) for the task of removing afeature. (a) Glasses. (b) Facial hair. (c) Mouth opening.
Figure 8: Facial hair transfer. Our method vs. the literature baselines.
Figure 9: A mix and match experiment for no smile to smile translation, using only domain BFigure 10: A mix and match experiment for the facial hair transfer, using only domain B images.
Figure 10: A mix and match experiment for the facial hair transfer, using only domain B images.
Figure 11: More eyewear transfer examples.
Figure 12: More smile transfer examples.
Figure 13: More facial hair transfer examples.
