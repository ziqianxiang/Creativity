Figure 1: Restorations using the same Latent Convolutional Model (images 2,4,6) for different imagedegradations (images 1,3,5). At training time, our approach builds a latent model of non-degradedimages, and at test time the restoration process simply finds a latent representation that maximizes thelikelihood of the corrupted image and outputs a corresponding non-degraded image as a restorationresult.
Figure 2: The Latent Convolutional Model incroprorates two sequential ConvNets. The smallerConvNet f (red) is fitted to each training image and is effectively used to parameterize the latentmanifold. The bigger ConvNet g (magenta) is used as a generator, and its parameters are fitted to alltraining data. The input s to the pipeline is fixed to a random noise and not updated during training.
Figure 3: Results (perceptual metrics - lower is better - and user preferences) for the two datasets(CelebA - left, Bedrooms - right) and three tasks (inpainting, super-resolution, colorization). For thecolorization task the perceptual metric is inadequate as the grayscale image has the lowest error, butis shown for completeness.
Figure 4: Qualitative comparison on CelebA (see the text for discussion).
Figure 5: Qualitative comparison on SUN Bedrooms for the tasks of inpainting (rows 1-2), superreso-lution (rows 3-4), colorization (rows 5-6). The LCM method performs better than most methods forthe first two tasks.
Figure 6: A comparision of optimization over the convolutional manifold (column "OptConv"),the z-space (column "OptZ") and the Progressive GAN (Karras et al., 2018) latent space (column"PGAN") on the CelebA-HQ dataset (Karras et al., 2018).
Figure 8: Image inpainting on CelebA with 95% of randomly chosen pixels missing.
Figure 9: Image inpainting using GLO models with latent spaces of different dimension and structure.
Figure 10: Image reconstruction using the WGAN-GP with gradually increasing penalties on thenorm of the latent representation z as justified by the probabilistic model behind GANs. Increasingthe weight of this penalty (shown above) leads to worse underfitting without improving the quality ofthe reconstruction. Therefore the comparisons in the main text use the variant without such penalty.
Figure 11: Additional qualitative comparisons on the Bedrooms dataset (see main text for discussion).
Figure 12: Interpolations in the latent space of the LCM model (top row), the convolutional GLOmodel (middle row). For the reference, we also provide linear cross-fade in the image pixel spacein the bottom row. In the case of our model, the interpolation is performed between φ1 and φ2, i.e.
Figure 13: Image restoration from heavy JPEG compression. Left - the input, middle - restored,right - ground truth. Rather than modeling JPEG degradation with a specific likelihood function, Weused a simple quadratic (log)-likelihood potential (corresponding to Gaussian noise corruption).
Figure 14: Unconditional Image Generation. We first project the latent parameters, the φ's, to a lowerdimensional space using PCA and then sample from it. The details are given in the text.
