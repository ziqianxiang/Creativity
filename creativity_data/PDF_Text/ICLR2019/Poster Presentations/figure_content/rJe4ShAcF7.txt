Figure 1: RelatiVe global attention: the bottom row describes our memory-efficient “skewing”algorithm, which does not require instantiating R (top row, which is O(L2D)). Gray indicatesmasked or padded positions. Each color corresponds to a different relatiVe distance.
Figure 2: Relative local attention: the thumbnail on the right shows the desired configuration for Srel .
Figure 3: Unconditioned samples from Transformer without (left) and with (right) relative self-attention. Green vertical boxes indicate the endings of (sub)phrases where cadences are held.
Figure 4: Transformer with relative attention (three random samples on the top row) when given aninitial motif (top left) generates continuations with more repeated motifs and structure then baselineTransformer (middle row) and PerformanceRNN (bottom row).
Figure 5: Samples from the Transformer with our efficient relative attention were rated more musicalmore times than LSTM and baseline Transformer. Error bars show standard deviation of the mean.
Figure 6: The opening measure of BWV 428 is visualized as a pianoroll (left, where the x-axis isdiscretized time and y-axis is MIDI pitch number), and encoded in grid representation with sixteenthnote resolution (right). The soprano and alto voices have quarter notes at pitches G4 (67) and D4 (62),the tenor has eighth notes at pitches B3 (59) and A3 (57), and the bass has eighth notes at pitches A2(45) and G2 (43).
Figure 7: A snippet of a piano performance visualized as a pianoroll (left) and encoded as performanceevents (right, serialized from left to right and then down the rows). A C Major chord is arpeggiatedwith the sustain pedal active. At the 2-second mark, the pedal is released, ending all of the notes. Atthe 3-second mark, an F is played for .5 seconds. The C chord is played at velocity 80 and the F isplayed at velocity 100.
Figure 8: This piece has a recurring triangular contour. The query is at one of the latter peaks and itattends to all of the previous high notes on the peak, all the way to beginning of the piece.
Figure 9: The query a note in the left-hand, and it attends to its immediate past neighbors and mostlyto the earlier left hand chords, with most attention lines distributed in the lower half of the pianoroll.
Figure 10:	Relative global attention: Steps (from left to right) for “skewing” an absolute-by-relative(iq, r) indexed matrix into absolute-by-absolute (iq,jk). Grey indicates self-attention masks or entriesintroduced by the skewing procedure. Positions with relative distance zero are marked. Entriesoutlined by purple are removed in step 3.
Figure 11:	Relative local attention: Steps (from left to right) for “skewing” an (iq , r) indexed matrixwith 2N - 1 ranged relative indices r into (iq , jk indexed. Shapes are indicated above the boxes,while indices in the boxes give relative distances.
