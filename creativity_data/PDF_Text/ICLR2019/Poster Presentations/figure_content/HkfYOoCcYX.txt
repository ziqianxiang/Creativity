Figure 1: Flowchart of Double Viterbi compression. W is the weight of an original network and WP,Wpq, and WPQ represent the compressed weights after each process. M ∈ {0,1} is an index matrixwhich indicates whether each weight is pruned or not, and means element-wise multiplication.
Figure 2: Structure of Viterbi decompressor (VD) which decodes a binary code compressed to 1/4times. "D" indicates a D Flip-Flop which delays an input data for a clock cycle in the design and Lindicates an XOR gate.
Figure 3:	Proposed process of sparse-to-dense matrix conversion for the Viterbi-based compressedmatrix. This figure shows an example such that weight values and weight index values are generatedby independent Viterbi decompressors simultaneously.
Figure 4:	(a) Target binary weight code bi and (b) corresponding bi generated from VD. x indicatesa pruned "Don’t care" term, and elements with underline indicate surviving weights. ‘0’ in (b)corresponds to ‘-1’ in (a).
Figure 5:	Trellis diagram of the VD in Figure 2. Each circle indicates a state. A circle which is thesource point of arrows indicates a current state and a circuit which is the sink point of arrows indicatesa next state. The arrow indicates a transition from the current state to the next state. Depending onthe input to VD, each current state can be switched to one of the two potential next states in the nextclock. The number in a circle indicates the index for the state.
Figure 6: (a) Simplified diagrams of baseline and (b) Viterbi-based computation architectures. (c) Rateof parameter feeding into PEs for the proposed scheme compared to those for the baseline structure,which receives the dense matrix data directly from DRAM, and Lee et al. (2018). We assumed thenumber of VD outputs for the index Nind = 3, 4, 5, 6, 10, 10 respectively as the reciprocal of eachsparsity value. We used Nind = 10 for 95 % sparsity since we compressed matrices with over 90% sparsity with Nind = 10. We also assumed k = 3, and 1 % bit-wise difference between bi andbi during simulation. We also assumed that 16 non-zero parameters can be fed into the PE array inparallel and DRAM requires 10 cycles to handle a 256 bit READ operation.
