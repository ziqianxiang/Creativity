Figure 1: Approximate posterior obtained by different methods.
Figure 2: Average test RMSE and predictive negative log-likelihood, on UCI regression datasets.
Figure 3: Accuracy on adversarial examples.
Figure 4: Posterior approximations obtained by weight space (up) and function space (down) vari-ants of other POVI methods.
Figure 5: Posterior approximations on increasingly complex models. L denotes the number ofhidden units in each layer. We can see a clear trend of degeneration for weight-space method.
Figure 6: Heldout NLL as a function of training time (in epochs) during a sample run on the Concretedataset.
Figure 7: Visualization of the wheel bandit, taken from (Riquelme et al., 2018). Best viewed incolor.
Figure 8: Posterior approximations with weight-space SVGD and alternative kernels. k,f cor-responds to the function-value kernel, and k_a the activation kernel. We include the results forf-SVGD and HMC for reference.
Figure 9: Estimated KL (qkp) w.r.t. training iterations, for f-SVGD using different sets of approx-imations. A baseline value is presented to help understanding the scale of KL divergence in thisexperiment; see below for details.
