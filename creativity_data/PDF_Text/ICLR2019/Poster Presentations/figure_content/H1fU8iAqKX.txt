Figure 1: Rotation-equivariant CNN architecture. A. The network consists of a rotation-equivariantconvolutional core common for all neurons (blue box) and a neuron-specific readout [red box (Klindtet al., 2017)]. Inputs are static images from ImageNet. Prediction targets are responses of 6005 V1neurons to these images. Rotation equivariance is achieved by using weight sharing across filterorientations. Therefore, eight rotated versions of each filter exist, resulting in eight groups of featuremaps (depicted by rainbow colored boxes). B. Illustration of weight sharing across orientations forthe second and third layer. The previous layer’s output consists of eight groups of feature maps (onefor each rotation angle). The output is generated by applying a learned filter to each of the inputfeature maps (here 8 × 16 kernels shown in the first row). Rotated versions (2nd and followingrows) are generated by rotating each kernel and cyclically permuting the feature maps. C. Filters arerepresented in a steerable basis (2d Hermite functions). Functions up to rank 5 are shown here.
Figure 2: Model comparison via loss on the val-idation set. Large dots: model with lowest losson validation set; small dots: top five modelfits according to loss on validation set. Red dot:model used for subsequent analyses. 16 featuremaps provides a good trade-off between modelcomplexity and predictive performance.
Figure 4: Feature weights are sparse. A. We group the neurons into 16 groups by their strongestfeature weight. Within each group, we sort the neurons by the sparsity of their weights (in descendingorder). Within each block labeled 1-16, each row is one feature and each column is one neuron.
Figure 5: Feature weights have consistent sign acrossneurons. Note that the majority of weights is zero; thecentral bin has been excluded for clarity.
Figure 6: Linear receptive fields for all 16 groups of neurons, obtained by computing the gradient ofthe model at a constant gray image. For each group, we show the 16 neurons with the sparsest featureweights that have an average correlation of the model prediction with the neural response of at least0.2 on the validation set. Thus, neurons are in the upper 50th percentile, but not cherry-picked to beparticularly well-predicted examples. Crops are roughly 70 X 70°.
