Figure 1: Half-cheetah agent, shoWntraversing a landscape With ‘basins’adaptation (as opposed to assuming a single model can encompass everything), While the bad per-formance of model-based RL With online gradient updates indicates the need for a meta-learnedinitialization to enable online learning With neural netWorks.
Figure 2: Results on half-cheetah terrain traversal. The poorly performing model-based RL shows that asingle model is not sufficient, and model-based RL with online gradient updates shows that a meta-learnedinitialization is critical. The three meta-learning approaches perform similarly; however, the performance ofk-shot adaptation deteriorates when the task calls for taking multiple gradient steps away from the prior.
Figure 3: Latent task distribution over time for two half-cheetah landscape traversal tasks, where encounteredterrain slopes vary within each run. Interestingly, we find that MOLe chooses to only use a single latent taskvariable to describe varying terrain.
Figure 4: Results on the motor malfunction trials, where different trials are shown task distributions thatmodulate at different frequencies (or stay constant, for the first category). Here, online learning is critical forgood performance, k-shot adaptation is insufficient for such different tasks, and continued gradient steps leadsto overfitting to recently seen data.
Figure 5: Latent task variable distribution over the course of an online learning trial where the underlyingmotor malfunction changes every 500 timesteps. We find that MOLe is able to successfully recover the taskstructure, recognize when the underlying task has changed, and recall previously seen tasks.
Figure 6: Six-leggedcrawler robot, shownwith crippled legs.
Figure 7: Quantitative results on crawler. For a fixed task, adaptation is not necessary and all methods performwell. In Contrast, when tasks Change dynamiCally within the trial, only MOLe effeCtively learns online.
Figure 8: Results on crawler experiments. Left: Online recognition of latent task probabilities for alternatingperiods of normal/crippled experience. Right: MOLe improves from seeing the same tasks multiple times.
Figure 9: Performance on test tasks (i.e., unseen during training) of models that are meta-trained with differingamounts of data. Performance numbers here are normalized per agent, between 0 and 1.
