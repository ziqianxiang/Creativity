Figure 1: (a) The general information structure under the “information intersection” assumption.
Figure 2: Medical image labeling example: we want to train a data classifier to classify the medicalimages into two classes: benign and malignant. Each image is labeled by several experts. The expertsare from different hospitals, say hospital A, B, C. Each hospital has a senior who has a high expertise.
Figure 3: Max-MIG overview: Step 1: finding the “information intersection” between the data andthe crowdsourced labels: we train a data classifier h and a crowds aggregator g simultaneously tomaximize their f -mutual information gain MIGf (h, g, p) with a hyperparameter p ∈ ∆C. h mapseach datapoint xi to a forecast h(xi) ∈ ∆C for the ground truth. g aggregates M crowdsourcedlabels yi[M] into a forecast g(yi[M]) ∈ ∆C by “weighted average”. We tune the parameters of h andg simultaneously to maximize their f -mutual information gain. We will show the maximum is thef -mutual information (a natural extension of mutual information, see Appendix C) between the dataand the crowdsourced labels. Step 2: aggregating the “information intersection”: after we obtain thebest h, g, p that maximizes MIGf(h, g, p), we use them to construct a data-crowds forecaster ζ thatforecasts ground truth based on both the datapoint and the crowdsourced labels.
Figure 4: Results on Dogs vs. Cats, CIFAR-10, LUNA16.
