Figure 1: ACD illustrated through the toy example of predicting the phrase “not very good” asnegative. Given the network and prediction, ACD constructs a hierarchy of meaningful phrases andprovides importance scores for each identified phrase. In this example, ACD identifies that “very”modifies “good” to become the very positive phrase “very good”, which is subsequently negated by”not” to produce the negative phrase “not very good”. Best viewed in color.
Figure 2: ACD interpretation of an LSTM predicting sentiment. Blue is positive sentiment, whiteis neutral, red is negative. The bottom row displays CD scores for individual words in the sentence.
Figure 3: ACD interpretation for a VGG network prediction, described in 4.2.1. ACD shows thatthe CNN is focusing on skates to predict the class “puck”, indicating that the model has captureddataset bias. The top row shows the original image, logits for the five top-predicted classes, and theCD superpixel-level scores for those classes. The second row shows separate image patches ACDhas identified as being independently predictive of the class “puck”. Starting from the left, eachimage shows a successive iteration in the agglomeration procedure. The third row shows the CDscores for each of these patches, where patch colors in the second row correspond to line colors inthe third row. ACD successfully finds important regions for the target class (such as the puck), andthis importance increases as more pixels are selected. Best viewed in color.
Figure 4: Results for human studies. A. Binary accuracy for whether a subject correctly selected themore accurate model using different interpretation techniques B. Average rank (from 1 to 4) of howmuch different interpretation techniques helped a subject to trust a model, higher ranks are better.
Figure S1:	Intuition for CD run on a corner-shaped blob compared to build-up and occlusion. CDdecomposes a DNN’s feedforward pass into a part from the blob of interest (top row) and everythingelse (second row). Left column shows original image with overlaid blob. Other columns show DNNactivations summed over the filter dimension. Top and third rows are on same color scale. Secondand bottom rows ar	-	-Figure S2:	Comparing unit-level CD scores for the correct class to scores from baseline methods.
Figure S2:	Comparing unit-level CD scores for the correct class to scores from baseline methods.
Figure S3:	Example of ACD run on an image of class 0 before and after an adversarial perturbation(a DeepFool attack). Best viewed in color.
Figure S4:	Examples of attacks for one image. Original image (left column) is correctly predicted asclass 0. After each adversarial perturbation (middle column), the predicted class for the adversarialimage (right column) is now altered.
Figure S5: Comparing unit-level CD scores to CD scores from the naive extension of CD to CNNs,independently developed by Godin et al. (2018). Labels under the bottom row signify the minimumand maximum scores from each column. Altering the bias partition and ReLU decomposition qual-itatively improves scores (e.g. see scores in bottom row corresponding to the location of the crane),and avoids extremely large magnitudes (see values under left two columns). Blue is positive, whiteis neutral, and red is negative. In each case, scores are for the correct class, which the model predictscorrectly (shown on the y axis).
