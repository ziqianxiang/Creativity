Figure 1: Behavior-based Regularization using Feature Maps with Attentions(xi,yi) and for 1 ≤ i ≤ n, the proposed regularize] Ω(ω, ω*, x,, y,, z) is capable of regularizingthe behavioral differences of network model z based on each labeled sample (xi, yi) in the dataset,using the parameters ω and ω* respectively.
Figure 2: Learning curves of the proposed feature map based regularization(DELTA) comparedwith weight based regularization(L2 -SP) on the Stanford Dog 120 benchmark using different meth-ods to adjust the learning rate. StepLR: setting the learning rate to the initial value decayed by 0.1after 6000 iterations (32 epochs for the Stanford Dogs dataset). ExponentialLR: setting the learningrate to the initial value decayed by 0.93 every epoch.
Figure 3: Distribution of the distance of parameters from the starting point. In ResNet-101, conv2_x,conv3_x, conv4_x, conv5_x represent for four main stages each of which has stacked convolutionlayers. The blue line represents for the result of L2-SP, and the orange line for DELTA.
Figure 4: Illustration of the effect of the attention mechanism for fine-tuning. DELTA w/o ATT:DELTA without Attentions.
