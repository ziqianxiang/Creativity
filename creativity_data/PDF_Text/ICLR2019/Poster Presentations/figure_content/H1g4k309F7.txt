Figure 1: Comparison of the ensembling methods on COCO validation set using GloVe-based sim-ilarity matrix K for 2 versions of beam search: topK (left panel) and randomized (right panel). Thex-axis shows ∣∣K -1∣∣f, which corresponds to a different regularization parameter ε (varied form 1to 50). We can see that for topK beam search (left panel) the further K is from the identity matrix,the larger the similarity neighborhood of each word, the more diverse are the generated captions (thebarycenter has higher entropy), while still remaining semantically close to the ground truth. On theother hand, for randomized beam search (right panel), it is important to maintain a smaller similarityneighborhood, so that the generated sentences are not too different from the referenced ground truth.
Figure 2: Left and Center Panels: Comparison of the ensembling methods on COCO validationset using SynOnymS-based similarity matrix with topK and randomized beam search. Right Panel:Comparison of ensembling methods when the predictions of the input models are shuffled accordingto the neighborhood structure defined by K. It can be seen that the W. Barycenter ensembling is ableto recover from the word shuffling and produce better captions then the simple averaging methods,which are not able to exploit the provided side information.
Figure 3: Human evaluation results. Left: Percentage of human picking best captions in terms ofcorrectness and detail. Right: Mean Opinion Score on a scale 1 to 5.
Figure 4: Visualization of the word distributions of W. barycenter, arithmetic and geometric meansbased on four captioning models, whose input image is shown on top (one of the ground-truthhuman-annotated captions for this image reads: A police car next to a pickup truck at an intersec-tion). The captioner generates a sentence as a sequence of words, where at each step the output isa distribution over the whole vocabulary. The top four histograms show a distribution over the vo-cabulary from each of the model at time t = 3 during the sentence generation process. The bottomthree histograms show the resulting distribution over the vocabulary for the ensembles based on W.
Figure 5: Visualization of the word distributions of W. barycenter for different similarity matricesK based on GloVe (rows denote the distance of K from identity kK - I kF and corresponding ).
Figure 6: Examples of captions for several images. BA: Wasserstein Barycenter, AM: Arithmeticmean, GM: Geometric mean, GT: Ground truth.
