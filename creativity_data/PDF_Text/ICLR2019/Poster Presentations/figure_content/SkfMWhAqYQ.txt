Figure 1: Deep bag-of-features models (BagNets). (A) The models extract features from smallimage patches which are each fed into a linear classifier yielding one logit heatmap per class. Theseheatmaps are averaged across space and passed through a softmax to get the final class probabilities.
Figure 2: Heatmaps showing the class evidence extracted from of each part of the image. The spatialsum over the evidence is the total class evidence.
Figure 3: Most informative image patches for BagNets. For each class (row) and each model (column)we plot two subrows: in the top subrow we show patches that caused the highest logit outputs for thegiven class across all validation images with that label. Patches in the bottom subrow are selected inthe same way but from all validation images with a different label (highlighting errors).
Figure 4: Images misclassified by BagNet-33 and VGG-16 with heatmaps for true andpredicted label and the most predictive im-age patches. Class probability reported forthe ground-truth class "cleaver" was confused with"granny smith" because of the green cucumber at thetop of the image. Looking at the three most predictivepatches plotted alongside each heatmap, which showthe apple-like edges of the green cucumber pieces, thisBagNet-33 (left) andchoice looks comprehensible. Similarly, the local patches in the "thimble"VGG (right).
Figure 5: Examples of original and texturised images. A vanilla VGG-16 still reaches high accuracyon the texturised images while humans suffer greatly from the loss of global shapes in many images.
Figure 6: Interaction of spatially separated image parts. (A) Changes in class-evidence when singleimage patches are masked (centre) versus change when all patches are masked simultaneously (right).
Figure 7: Scatter plots of class-conditional top-5 errors for different models.
Figure 8: Similarity of image features used for object classification. (Top) Decrease of leading classprobability in VGG-16, ResNet-50, ResNet-152 and DenseNet-169 if increasingly more patchesare masked according to the heatmaps of BagNets and several popular attribution methods. Thefaster the decrease the more closely does the heatmap highlight image parts relevant for the modeldecisions making. Image parts relevant to the BagNets turn out to be similarly relevant for all modelsand outperform post-hoc attribution methods. (Bottom) The first four heatmaps show attributionscomputed on VGG-16, the other three heatmaps show the class evidence of BagNets.
