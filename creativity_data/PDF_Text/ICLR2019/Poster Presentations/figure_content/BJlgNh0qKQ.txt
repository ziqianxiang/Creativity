Figure 1: Dependency tree example: each arc repre-sents a labeled relation between the head word (thesource of the arc) and the modifier word (the destina-tion of the arc). The first token is a fake root word.
Figure 2: (a) Illustration of our probabilistic model with random variables s, T and z for sentences,dependency trees and sentence embeddings, respectively. The gray area delimits the latent space.
Figure 3: Partial derivatives of the backpointer reconstruction algorithm21Published as a conference paper at ICLR 2019Algorithm 7 Backpointer reconstruction algorithm - Backward passfunction BACKPROP-BACKPTR(n)for l = 1 ...n dofor i = 0 ...n — l doj — i + l⅛⅛ J0, ⅛⅛ J0, ⅛⅛ J0, ∂⅛ J0for k = i ...j — 1 do∂L	J ∂L LΓi r1 j][k] +	∂L	LΓi r1 j][k]∂δ[idj] J ∂W4] b[i□川k]+ ∂c[k+ι∕j] b[i□川k]—dL— j dL-c[i d j] +_________dL-^Cri ≤ι j]∂b[i曰j][k] J ∂δ[il∖k] cr j]+ ∂C[k+1∕j]cr j]for k = i . . . j — 1 do∂L +	∂L lγ√ Z ∙λ∖ic∖ i ∂L lγ√ Z ∙λ∖ic∖∂加j] J ∂δ[iNk] b[i 口川k]+ ∂C[k+1∕j] b[i 口川k]"丽 J ∂⅛ic[i b j] + ∂⅛c[i 4 j]for = i . . . j — 1 doW ≠ ∂⅛b[iZj∏kl + ∂⅛"i/j][k]
Figure 4: Partial derivatives of the inside algorithm23Published as a conference paper at ICLR 2019Algorithm 8 Inside algorithm - Backward passfunction BACKPROP-INSIDE(n)for i = 0 ...n dofor j = i. ..n dodL .	J 0. d∖	J 0. dL .	J 0. dL .	J 0∂c[i∕j]	,	∂c[iNj]	, ∂c[it≤lj]	,	∂c[i≥)j]for l = n ... 1 dofor i = 0 ...n — l doj J i + l.Backpropagation through the “inside“ algorithmfor k = i ...j — 1 do∂启][k] J ⅛⅛α∣i / j∏k]WL丽 J ∂⅛] b[i / 力网S = Pij-I w‰rb[i/j][k]for k = i . . . j — 1 do∂α[i∂j][k] J b[i ∕jIk] ( ∂b[禽[k]for k = i . . . j — 1 do
