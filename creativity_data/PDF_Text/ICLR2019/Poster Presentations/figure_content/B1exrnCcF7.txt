Figure 1: Overview of the proposed DIMNet and its comparison to the existing approaches. (a) Seeing facesand hearing voices from Nagrani et al. (2018b). (b) Learnable PINs from Nagrani et al. (2018a). (c) Learningface-voice association from Kim et al. (2018). (d) Our proposed DIMNets. DIMNets present a joint voice-faceembedding framework via multi-task classification and require no pair construction (i.e., both voices and facescan be input sequentially without forming pairs).
Figure 2: Our DIMNet framework. The input training data can be either voice or face, and there is no needfor voices and faces to form pairs. Modality switch is to control which embedding network (voice or face) toprocess the data. While the embeddings are obtained, a multi-task classification network is applied to supervisethe learning.
Figure 3: Performance of 1:N matchingand gender are used as supervision covariates. However, The results obtained using only genderinformation as covariate is much worse, which is also consistent with our analysis in Appendix B.
Figure 4: Visualization of voice and face embeddings using multi-dimensional scaling Wickelmaier (2003) .
