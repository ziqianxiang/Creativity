Figure 1: The mapping process of the generator of the baseline cGAN (in (a)) and our model (in (b)).
Figure 2: Schematic of the generator of (a) cGAN versus (b) our proposed RoCGAN. The singlepathway of the original model is replaced with two pathways.
Figure 3: Qualitative results in the synthetic experiment of sec. 3.4. Each plot corresponds to therespective manifolds in the output vector; the first and third depend on both x, y (xyz plot), while therest on x (xz plot). The green color visualizes the target manifold, the red the baseline and the blueours. Even though the two models include the same parameters during inference, the baseline doesnot approximate the target manifold as well as our method.
Figure 4: Qualitative results (best viewed in color). The first row depicts the target image, thesecond row the corrupted one (used as input to the methods). The third row depicts the output of thebaseline cGAN, while the outcome of our method is illustrated in the fourth row. There are differentevaluations visualized for faces: (a) denoising, (b) denoising with additional noise at test time, (c)sparse inpainting, (d) sparse inpainting with 75% black pixels. For natural scenes the columns (e)and (f) denote the denoising and sparse inpainting results respectively.
Figure 5: Qualitative results in the synthetic experiment (main paper). Output of the 1st function.
Figure 6: Qualitative results in the synthetic experiment (main paper). Output of the 2nd function.
Figure 7: Qualitative results in the synthetic experiment (main paper). Output of the 3rd function.
Figure 8: Qualitative results in the synthetic experiment (main paper). Output of the 4th function.
Figure 9: Projection to linear subspace. The original image on the left was corrupted (downscaled ×4).
Figure 10: Qualitative results; best viewed in color. The first row depicts the ground-truth image,the second row the corrupted one (input to methods), the third the output of the baseline cGAN, thefourth illustrates the outcome of our method. The four first columns are based on the protocol of‘4layer’ network, while the four rightmost columns on the protocol ‘4layer-50k’. There are differentevaluations visualized for faces: (a), (e) Denoising, (b), (f) denoising with augmented noise at testtime, (c), (g) sparse inpainting, (d), (h) sparse inpainting with 75% black pixels.
Figure 11: Cosine distance distribution plot (sec. D.4). A perfect reconstruction per compared imagewould yield a plot of a Dirac delta around one; a narrow distribution centered at one denotes proximityto the target images, embeddings. The word ,den, abbreviates denoising and ,inp, sparse inpainting.
Figure 12: The layer schematics of the generators in case of (a) the ‘4layer-skip’ case, (b) the ‘5layer’case.
Figure 13: Histogram plots for different noise cases (experiment of sec. E.3). The distribution that ismore concentrated to the right of the histogram is closer to the target distribution. In (a) we note thateven in the training noise case, the two histograms differ with ours concentrating towards the right.
Figure 15: Qualitative figure illustrating the different noise levels (sec. E.3). The first row depictsdifferent target samples, while every three-row block, depicts the corrupted image, the baseline outputand our output. The blocks top down correspond to the 25%, 35%, 50% noise (25/0, 35/0 and 50/0).
Figure 16: Qualitative figure for different type of noise during testing (see Fig 15). The first rowdepicts different target samples, while every three-row block, depicts the corrupted image, the baselineoutput and our output. The blocks top down correspond to the 25/10, 25/20, 25/25 cases (differenttype of testing noise). The last block contains the most challenging noise in this work, i.e. bothincreased noise and of different type than the training noise. Nevertheless, our model generates amore realistic image in comparison to the baseline.
