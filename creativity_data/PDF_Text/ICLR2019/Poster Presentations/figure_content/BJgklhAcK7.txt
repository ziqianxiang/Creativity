Figure 1: High-level intuition for LEO. WhileMAML operates directly in a high dimensionalparameter space Θ, LEO performs meta-learningwithin a low-dimensional latent space Z, fromwhich the parameters are generated.
Figure 2: Overview of the architecture of LEO.
Figure 3: Meta-learning with LEO of a multimodal task distribution with sines and lines, using5-shot regression with noisy targets. Our model outputs a distribution of possible solutions, whichis also multimodal in ambiguous cases. True regression targets are plotted in black, while the 5training examples are highlighted with red circles and vertical dashed lines. Several samples fromour model are plotted with dotted lines (best seen in color).
Figure 4: t-SNE plot of latent space codes before and after adaptation: (a) Initial codes zn (blue)and adapted codes z0n (orange); (b) Same as (a) but colored by class; (c) Same as (a) but highlightingcodes zn for validation class “Jellyfish” (left) and corresponding adapted codes z0n (right).
Figure 5: Curvature and coverage metrics for a number of different models, computed over 1000problem instances drawn uniformly from the test meta-set. For all plots, the whiskers span from the5th to 95th percentile of the observed quantities.
