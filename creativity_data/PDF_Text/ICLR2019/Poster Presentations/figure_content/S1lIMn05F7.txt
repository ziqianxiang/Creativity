Figure 1: Architecture diagram of our adversarial networksThe inner maximization requires a separate oracle for generating the perturbations ∆x. FGS is acommon method for generating the adversarial perturbations ∆x due to its speed. Madry et al.
Figure 2:	Residual block used in the network definitionsconv2d(5,1,32)maxpool(2)conv2d(5,1,64)maxpool(2)FC(10)(a) D1conv2d(3,1,16)residual-block(3,1,16) ×3residual-block(3,2,32)residual-block(3,1,32) ×2residual-block(3,2,64)residual-block(3,1,64) ×2avgpool(8)FC(10)(b) D2Figure 3:	Discriminative networks used in this papergenerative networks used in this paper. G0 and G1 are encoder-decoder networks, while G2 and G3are decoder networks using a random vector and a one-hot encoding of the label respectively. Thegenerative networks are parameterized by a factor k determining the number of filters used (width
Figure 3:	Discriminative networks used in this papergenerative networks used in this paper. G0 and G1 are encoder-decoder networks, while G2 and G3are decoder networks using a random vector and a one-hot encoding of the label respectively. Thegenerative networks are parameterized by a factor k determining the number of filters used (widthof network). As default we use k = 64, and k = 16 for networks using labels as inputs.
Figure 4: Generative networks used in this papertraining method∖attack	white box			black box						No Noise FGS		PGD	FGS(A’)PGD(A')		FGS(B’) PGD(B’) FGS(C’) PGD(C’)			Standard(A)	94.69%	62.36%	1.08%	69.89%	9.14%	85.05%	82.82%	76.27%	45.16%adversarial PGD(B)	83.50%	67.92%	60.15%	83.21%	82.96%	72.66%	68.82%	82.01%	78.59%adversarial network©	91.32%	73.77%	49.55%	83.29%	81.65%	79.32%	76.00%	79.32%	62.71%Table 8: Classification accuracies under white box and black box attacks on CIFAR10 with WideResNet ( = 8/256)Table 8 gives the results on CIFAR10 using a wider version of Resnet (Model D2), by multiplyingthe number of filters in each convolutional layer by a factor of 10. Some of the previous works inthe literature use models of larger capacity for training adversarially robust models, so we performexperiments on these large capacity models here. First the accuracies increase across the board withlarger capacity models. The accuracy gap on clean data between adversarial PGD and standardtraining still exists, but now there is also a small accuracy gap between our adversarial networkapproach and standard training. For the rest of the white box and black accuracies the story is similar,the models are weakest against attacks trained with the same method but with a different randomseed. Our adversarial network approach has very good performance across different attacks, even asit is not always the winner for each individual attack. Table 9 gives the results of Wide ResNet onCIFAR100, and the results are qualitatively similar.
