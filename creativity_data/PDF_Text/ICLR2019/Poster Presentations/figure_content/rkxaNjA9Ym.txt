Figure 1: Problem setup: FX training at layer l of a DNN showing the quantized tensors and the associatedprecision configuration Cl = (BWl, BAl, BG(W) , BG(A) , BW (acc))errors propagate to the network output thereby directly affecting its accuracy (Lin et al., 2016); 2)precision requirements of different variables in a network are interdependent and involve hard-to-quantify trade-offs (Sakr et al., 2017); 3) proper quantization requires the knowledge of the dynamicrange which may not be available (Pascanu et al., 2013); and 4) quantization errors may accumulateduring training and can lead to stability issues (Gupta et al., 2015).
Figure 2: The predicted precision configurations Co for the CIFAR-10 ConvNet (a), SVHN ConvNet (b),CIFAR-10 ResNet (c), and CIFAR-100 ResNet (d). For each network, the 5-tuple Co represents the averagenumber of bits per tensor type. For the ResNets, layer depths 21 and 22 correspond to the strided convolutions inthe shortcut connections of residual blocks 4 and 7, respectively. Activation gradients go from layer 2 to L + 1and are “shifted to the left” in order to be aligned with the other tensors.
Figure 3: Convergence curves for the CIFAR-10 ConvNet (a), SVHN ConvNet (b), CIFAR-10 ResNet (c), andCIFAR-100 ResNet (d) including FL training as well as FX training with precision configurations Co, C1, andC-1.
Figure 4: Additional experiments on minimality and sensitivity of Co : relative test error deviationwith respect to Co as a function of (a) random fractional precision perturbations, and (b) 1-b precisionreduction per tensor type.
Figure 2:Layer Index l	1	2	3	4	5	6	7	8	9BW(Acc)	^4~	17	^T6^	^T6^	15	^T7^	^20^	23	^20^E.3 CIFAR- 1 0 ResNetFeedforward Precisions: The quantization noise gains are used to obtain values for the precisionsas a function of B(min) as summarized below:22Published as a conference paper at ICLR 2019Layer Index l	1	2	3	4	5	6EWl →Pm	2.41E+03	9.80E+02	1.22E+03	1.62E+03	1.52E+03	3.05E+03BWl	11+Bgin)	10+B(min)	10+B (min)	10+Bgin)	10+Bgin)	11+B (min)EAl→Pm	7.32E-01	5.15E-01	1.29E-01	1.12E-01	7.31E-02	8.98E-02BAl	5+Bgin)	5+Bgin)	4+B(min)-	4+B(min)-	3+B(min)	3+B(min)Layer Index l	7	8	9	10	11	12EWl →Pm	1.47E+03	2.15E+03	2.74E+03	4.96E+03	4.23E+03	4.20E+03BWl	IO+Bgin)	11+Bgin)	11+B (min)	11+B(min)	11+B(min)	12+B (min)EAl→Pm	7.70E-02	8.39E-02	6.38E-02	1.92E-01	1.54E-01	1.33E-01BAl	3+B(min)	3+B(min)	3+B(min)	4+B(min)-	4+B(min)-	4+B(min)-Layer Index l	13	14	15	16	17	18EWl →Pm	7.25E+03	2.99E+03	2.86E+03	3.00E+03	5.02E+03	4.34E+03
Figure 2:Layer Index l	1	2	3	4	5	6	7	8	9BW(Acc)	^4~	17	^T6^	^T6^	15	^T7^	^20^	23	^20^E.3 CIFAR- 1 0 ResNetFeedforward Precisions: The quantization noise gains are used to obtain values for the precisionsas a function of B(min) as summarized below:22Published as a conference paper at ICLR 2019Layer Index l	1	2	3	4	5	6EWl →Pm	2.41E+03	9.80E+02	1.22E+03	1.62E+03	1.52E+03	3.05E+03BWl	11+Bgin)	10+B(min)	10+B (min)	10+Bgin)	10+Bgin)	11+B (min)EAl→Pm	7.32E-01	5.15E-01	1.29E-01	1.12E-01	7.31E-02	8.98E-02BAl	5+Bgin)	5+Bgin)	4+B(min)-	4+B(min)-	3+B(min)	3+B(min)Layer Index l	7	8	9	10	11	12EWl →Pm	1.47E+03	2.15E+03	2.74E+03	4.96E+03	4.23E+03	4.20E+03BWl	IO+Bgin)	11+Bgin)	11+B (min)	11+B(min)	11+B(min)	12+B (min)EAl→Pm	7.70E-02	8.39E-02	6.38E-02	1.92E-01	1.54E-01	1.33E-01BAl	3+B(min)	3+B(min)	3+B(min)	4+B(min)-	4+B(min)-	4+B(min)-Layer Index l	13	14	15	16	17	18EWl →Pm	7.25E+03	2.99E+03	2.86E+03	3.00E+03	5.02E+03	4.34E+03
Figure 2:Layer Index l	1	2	3	4	5	6	7	8	9BW(Acc)	^4~	17	^T6^	^T6^	15	^T7^	^20^	23	^20^E.3 CIFAR- 1 0 ResNetFeedforward Precisions: The quantization noise gains are used to obtain values for the precisionsas a function of B(min) as summarized below:22Published as a conference paper at ICLR 2019Layer Index l	1	2	3	4	5	6EWl →Pm	2.41E+03	9.80E+02	1.22E+03	1.62E+03	1.52E+03	3.05E+03BWl	11+Bgin)	10+B(min)	10+B (min)	10+Bgin)	10+Bgin)	11+B (min)EAl→Pm	7.32E-01	5.15E-01	1.29E-01	1.12E-01	7.31E-02	8.98E-02BAl	5+Bgin)	5+Bgin)	4+B(min)-	4+B(min)-	3+B(min)	3+B(min)Layer Index l	7	8	9	10	11	12EWl →Pm	1.47E+03	2.15E+03	2.74E+03	4.96E+03	4.23E+03	4.20E+03BWl	IO+Bgin)	11+Bgin)	11+B (min)	11+B(min)	11+B(min)	12+B (min)EAl→Pm	7.70E-02	8.39E-02	6.38E-02	1.92E-01	1.54E-01	1.33E-01BAl	3+B(min)	3+B(min)	3+B(min)	4+B(min)-	4+B(min)-	4+B(min)-Layer Index l	13	14	15	16	17	18EWl →Pm	7.25E+03	2.99E+03	2.86E+03	3.00E+03	5.02E+03	4.34E+03
