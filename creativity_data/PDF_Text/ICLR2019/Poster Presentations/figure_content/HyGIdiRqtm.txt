Figure 1:	Average times for determining bounds on or exact values of minimum targeted adversarialdistortion for MNIST test samples. We improve on the speed of the state-of-the-art complete verifierReluplex by two to three orders of magnitude. Results for methods other than ours are from Wenget al. (2018); results for Reluplex were only available in Weng et al. (2018) for the l∞ norm.
Figure 2:	Bounds on or exact values of minimum targeted adversarial distortion for MNIST testsamples. The gap between the true minimum adversarial distortion and the best lower bound issignificant in all cases, increasing for deeper networks. We report mean values over 100 samples.
Figure 3: Fraction of samples in the MNIST test set vulnerable to attack for which PGD succeedsat finding an adversarial example. Samples are binned by their minimum adversarial distortion (asmeasured under the l∞ norm), with bins of size 0.01. Each of these are LPd-CNNA networks, andwere trained to optimize for robustness to attacks with l∞ norm-bound . For any given network, thesuccess rate of PGD declines as the minimum adversarial distortion increases. Comparing networks,success rates decline for networks with larger even at the same minimum adversarial distortion.
Figure 4: Comparison of provably ReLU stability for networks trained via different robust trainingprocedures to be robust at = 0.1, when varying the maximum allowable l∞ norm of the perturbation.
