Figure 1: Illustration of (approximate) personalized propagation of neural predictions (PPNP,APPNP). Predictions are first generated from each node’s own features by a neural network andthen propagated using an adaptation of personalized PageRank. The model is trained end-to-end.
Figure 2: Accuracy distributions of different models. The high standard deviation between datasplits and initializations shows the importance of a rigorous evaluation, which is often omitted.
Figure 3: Accuracy for different training set sizes (number oflabeled nodes per class) on Cora-ML.
Figure 4: Accuracy depending on the number of propagation steps K . The accuracy breaks down forthe GCN-like propagation (α = 0), while it increases and stabilizes when using APPNP (α = 0.1).
Figure 5: Accuracy depending on teleport probability α.
Figure 6: Accuracy of APPNP with propagation used only during training/inference. Best resultsare achieved with full propagation, but propagating only during inference also achieves good results.
Figure 7: Illustration of the node sampling procedure.
Figure 8: Validation accuracy of APPNP for varying numberS of neural network (NN) layerS. DeepNNS do not improve the accuracy, which iS probably due to the Simple bag-of-wordS featureS andthe Small training Set Size.
Figure 9: Accuracy for different training set sizes on CITESEER.
Figure 10: Accuracy for different training set sizes on PubMed.
Figure 11: Accuracy for different training set sizes on Microsoft Academic.
Figure 12: ∆ Accuracy (%) denotes the average improvement in percentage points of APPNP overGCN depending on the distance (number of hops) from the training nodes on Cora-ML. n denotesthe average number of nodes at each distance. The improvement increases with distance.
Figure 13: ∆ Accuracy (%) denotes the average improvement in percentage points of APPNP overGCN depending on the distance (number of hops) from the training nodes on different graphs. ndenotes the average number of nodes at each distance over different splits.
