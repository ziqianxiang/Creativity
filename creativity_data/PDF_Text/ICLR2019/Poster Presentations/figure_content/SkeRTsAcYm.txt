Figure 1: Effects of reusing phase of noisy speech under different SNR conditions.
Figure 2: Illustration of speech enhancement framework with DCUnet.
Figure 3: Illustration of three cRM methods and their corresponding output range in complex space.
Figure 4: Scatter plots of estimated cRMs with 9 different mask and loss function configurations fora randomly picked noisy speech signal. Each scatter plot shows the distribution of complex valuesfrom an estimated cRM. The leftmost plot is from the cIRM for the given input. We can observethat most real-values are distributed around 0 and 1, while being relatively sparse in between. Theconfiguration that fits the most to this distribution pattern is observed in the red dotted box which isachieved by the combination of our proposed methods (Bounded (tanh) and weighted-SDR).
Figure 5: Illustration of four wave-plot segments of estimated speech with reference clean speech.
Figure 6: Illustration of (a) real-valued convolution and (b) complex-valued convolution.
Figure 7:	DCUnet-20 (20-layer): a model with 20 convolutional layers.
Figure 8:	DCUnet-16 (16-layer): a model with 16 convolutional layers.
Figure 9:	DCUnet-10 (10-layer): a model with 10 convolutional layers.
Figure 10: Large-DCUnet-20: a model with 20 convolutional layers with more number of channelsper layer.
Figure 11: Description of encoder and decoder block. Ff and Ft denote the convolution filter sizealong the frequency and time axis, respectively. Sf and St denote the stride size of convolution filteralong the frequency and time axis, respectively. OC and OR denote the different number of channelsin complex-valued network setting and real-valued network setting, respectively. The number ofchannels of OR is set to be roughly âˆš2 times the number of channels of OC so that the number oftrainable parameters of real-valued network and complex-valued network becomes approximatelythe same.
Figure 12: TWo cases of possible irreducible error types in a TF bin in spectrogram. (a) The casewhere phase is not estimated and phase of mixture is reused. Even if the magnitude estimationis assumed to be perfect, there is still an irreducible phase error between the true source and theestimation. (b) The case where the magnitude of an estimated mask is bounded to 1. This againinduces an irreducible error since there can be sources which have a higher magnitude than themagnitude of a mixture.
Figure 14: Illustration of phase group delay. The group delay of the estimated phase from our model(c) shows the similar pattern to that of clean speech (d). For better visualization, we only show theTF bins where the magnitude of clean speech spectrogram exceeds certain threshold 0.01.
Figure 13: Four different scatter plots of cIRM according to the four different SNR values of inputmixture in training set, (a) SNR: 0 (dB) (b) SNR: 5 (dB) (c) SNR: 10 (dB) (d) SNR: 15 (dB).
Figure 15: (a) The case where SNR of given mixture is high. In this case the source is likely to bedominant in the mixture. Therefore it is relatively easier to estimate ground truth source with betterprecision even when the phase is not estimated. (b) The case where SNR of given mixture is low. Inthis case the source is not dominant in the mixture. Therefore, the irreducible phase error is likely tobe higher in low SNR conditions than higher SNR conditions. Under this circumstance, We assumethe lack of phase estimation will result in a particularly bad system performance.
