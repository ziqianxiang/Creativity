Figure 1: Final layer activations for inputs to a small BNN with two output classes (o1 and o2)as a single input dimension (x1) is varied. The relative activations of the two classes differ signifi-cantly between the true BNN (left) and an approximation of the BNN (right) used to enable gradientcomputations for PGD.
Figure 2: Proportion of samples for which the final prediction was flipped to the target class (y-axis)by MIP vs. PGD vs. IProp attacks with varying network architectures (x-axis) and varying(left-right), on the MNIST dataset.
Figure 3: Proportion of samples for which the final prediction was flipped to the target class (y-axis)by PGD vs. IProp attacks with varying network architectures (x-axis) and varying (left-right),on the Fashion-MNIST dataset.
Figure 4: Summary statistics for the normalized objective value of attacks obtained by IPropversus PGD (y-axis) with varying in networks with different architectures, on MNIST.
Figure 5: Average normalized solution objective value (y-axis) versus runtime (x-axis) for IPropversus PGD on MNIST samples.
Figure 6: Proportion of MNIST samples on which the final prediction was flipped to the target classby IProp with adaptive or constant step sizes. The adaptive step size performs relatively wellacross networks of varying size and different values of .
Figure 7: Proportion of MNIST samples on which the final prediction was flipped to the target classby IProp starting with zero perturbation or with an initial perturbation found by running PGD fora short amount of time.
Figure 8: Proportion of samples for which the final prediction was flipped to the target class (y-axis)by SPSA vs. IProp attacks with varying network architectures (x-axis) and varying (left-right),on the MNIST dataset.
