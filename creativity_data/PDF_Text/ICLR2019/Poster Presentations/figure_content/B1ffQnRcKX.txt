Figure 1: (a) Consider a multitask family of problems, whose subproblems are shared within and acrossproblems. Standard approaches either (b) train a separate learner per task or (c) train a single learner for alltasks. Both have difficulty generalizing to longer compositional problems. (d) Our goal is to re-use previouslylearned sub-solutions to solve new problems by composing computational modules in new ways.
Figure 2: Compositional recursive learner (CRL): top-left: CRL is a symbiotic relationship between acontroller and evaluator: the controller selects a module m given an intermediate representation x and theevaluator applies m on x to create a new representation. bottom-left: CRL learns dynamically learns thestructure of a program customized for its problem, and this program can be viewed as a finite state machine.
Figure 3: Multilingual Arithmetic (Quantitative). CRL generalizes significantly better than the RNN,which, even with ten times more data, does not generalize to 10-length multilingual arithmetic expressions.
Figure 4: Left: For multilingual arithmetic, blue denotes the language pairs for training and red denotesthe language pairs held out for evaluation in Fig 3b,c. Center: For transformed MNIST classification, bluedenotes the length-2 transformation combinations that produced the input for training, red denotes the length-2transformation combinations held out for evaluation. Not shown are the more complex length-3 transformationcombinations (scale then rotate then translate) we also tested on. Right: For transformed MNIST classification,each learner performs better than the others in a different metric: the CNN performs best on the trainingsubproblem combinations, the STN on different subproblem combinations of the same length as training, andCRL on longer subproblem combinations than training. While CRL performs comparably with the others inthe former two metrics, CRL's 〜40% improvement for more complex image transformations is significant.
Figure 5: Multilingual Arithmetic (Qualitative). A randomly selected execution trace for generalizing fromlength-5 to length-10 expressions. The input is 0 -6+ 1 +7 × 3 × 6 -3+7- 7 × 7 expressed in Pig Latin. Thedesired output is seis, which is the value of the expression, 6, expressed in Spanish. The purple modules arereducers and the red modules are translators. The input to a module is highlighted and the output of the moduleis boxed. The controller learns order of operations. Observe that reducer m9 learns to reduce to numerals andreducer m10 to English terms. The task-agnostic nature of the modules forces them to learn transformationsthat the controller would commonly reuse across problems. Even if the problem may not be compositionallystructured, such as translating Pig Latin to Spanish, CRL learns to design a compositional solution (Pig Latinto Numerals to Spanish) from previous experience (Pig Latin to Numerals and Numerals to Spanish) in orderto generalize: it first reduces the Pig Latin expression to a numerical evaluation, and then translates that to itsSpanish representation using the translator m6 . Note that all of this computation is happening internally to thelearner, which computes on softmax distributions over the vocabulary; for visualization we show the token ofthe distribution with maximum probability.
Figure 6: Image Transformations: CRL reasonably applies a sequence of modules to transform a transformedMNIST digit into canonical position, and generalizes to different and longer compositions of generative trans-formations. m0 is constrained to output the sine and cosine of a rotation angle, m1 is constrained to output thescaling factor, and m2 through m13 are constrained to output spatial translations. Some modules like m2 andm6 learn to translate up, some like m3 and m10 learn to translate down, some like m7 learn to shift right, andsome like m13 learn to shift left. Consider (d): the original generative transformations were “scale big” then“translate left,” so the correct inversion should be “translate right” then “scale small.” However, CRL chose toequivalently “scale small” and then “translate right.” CRL also creatively uses m0 to scale, as in (e) and (f),even though its original parametrization of outputting sine and cosine is biased towards rotation.
Figure 7: Numerical math task. We compare our learner with the RNN baseline. As a sanity check, wealso compare with a version of our learner which has a hardcoded controller (HCC) and a learner which hashardcoded modules (HCF) (in which case the controller is restricted to select windows of 3 with an operator inthe middle). All models perform well on the training set. Only our method and its HCC, HCF modificationsgeneralize to the testing and extrapolation set. The RNN requires 10 times more data to generalize to the testingand extrapolation set. For (b, c) we only show accuracy on the expressions with the maximum length of thoseadded so far to the curriculum. “1e3” and “1e4” correspond to the order of magnitude of the number of samplesin the dataset, of which 70% are used for training. 10, 50, and 90 percentiles are shown over 6 runs.
Figure 8: Variations: The minimum number of reducers and translators that can solve the multilingual mathproblems is 1 and m respectively, where m is the number of languages. This is on an extrapolation task, whichhas more terms and different language pairs. (a, b): Four reducers and zero translators (red) is a pathologicalchoice of modules that causes CRL to overfit, but it does not when translators are provided. (c) In the non-pathological cases, regardless of the number of modules, the learner metareasons about the resources it has tocustomize its computation to the problem. 10, 50, and 90 percentiles are shown over 6 runs.
Figure 9: ExtrapolationD.4 Execution Traces: Function Selection(a) Validation (length 5)(b) Test (length 5)(c) Test (length 10)Figure 10: Multilingual Arithmetic Execution TracesFig. 10 compares the execution traces of CRL on different language pairs from training of (a,b)length 5 and of (c) length 10. We observe that in many cases the controller chooses to take anadditional step to translate the fully reduced answer into an answer in the target language, whichshows that it composes together in a novel way knowledge of how to solve a arithmetic problemwith knowledge of how to translate between languages.
Figure 10: Multilingual Arithmetic Execution TracesFig. 10 compares the execution traces of CRL on different language pairs from training of (a,b)length 5 and of (c) length 10. We observe that in many cases the controller chooses to take anadditional step to translate the fully reduced answer into an answer in the target language, whichshows that it composes together in a novel way knowledge of how to solve a arithmetic problemwith knowledge of how to translate between languages.
