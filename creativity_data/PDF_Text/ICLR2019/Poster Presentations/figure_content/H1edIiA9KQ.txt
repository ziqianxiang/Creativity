Figure 1: Both the generator and the discriminator of our model consist of a global and an objectpathway. The global pathway focuses on global image characteristics, such as the background, whilethe object pathway is responsible for modeling individual objects at their specified location.
Figure 2: Multi-MNIST images generated by the model. Training included only images with threeindividual normal-sized digits. Highlighted bounding boxes and yellow ground truth for visualization.
Figure 3: Images from the CLEVR data set. The left image of each pair shows the rendered imageaccording to specific attributes. The right image of each pair is the image generated by our model.
Figure 4: Examples of images generated from the given caption from the MS-COCO data set. A)shows the original images and the respective image captions, B) shows images generated by ourStackGAN+OP (with the corresponding bounding boxes for visualization), and C) shows imagesgenerated by the original StackGAN (Zhang et al., 2017)3a different model. As opposed to the StackGAN, the AttnGAN consists of only one model which istrained end-to-end on the image captions by making use of multiple, intermediate, discriminators.
Figure 5: Examples of images generated from the given caption from the MS-COCO data set. A)shows the original images and the respective image captions, B) shows images generated by ourStackGAN+OP (with the corresponding bounding boxes for visualization) with the object pathwayenabled, C) shows images generated by the our StackGAN+OP when the object pathway is disabled,and D) shows images generated by the our StackGAN+OP when the global pathway is disabled.
Figure 6: Systematic test of digits over vertically different regions. Training set included threenormal-sized digits only in the top half of the image. Highlighted bounding boxes and yellow groundtruth for visualization. We can see that the model fails to generate recognizable digits once theirlocation is too far in the bottom half of the image, as this location was never observed during training.
Figure 7: Additional StaCkGAN examples - refer to Page 17 for information about the figure.
Figure 8: Additional AttnGAN examples - refer to Page 17 for more information about the figure.
Figure 9: StackGAN examples with random locations - refer to page 17 for more information.
Figure 10: AttnGAN examples with random locations - refer to page 17 for more information.
Figure 11: Distribution of recall and IoU values in the YOLOv3 object detection test.
