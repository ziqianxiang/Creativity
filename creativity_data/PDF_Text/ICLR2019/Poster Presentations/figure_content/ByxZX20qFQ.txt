Figure 1: Illustration of adaptive input representations. Words are assigned to clusters Vi based ontheir frequency which determines the size of the representations. Embeddings are projected to acommon dimension d before being fed to the model.
Figure 2: Loss of models binned by word frequency on the test set of wikitext- 1 03. Bins are notcumulative.
Figure 3: Loss of models when binning by the frequency of the previous word measured onwikitext- 1 03 (cf. Figure 2).
Figure 4: Loss of models when binning by word frequency on the test set of billion word. Binsare not cumulative.
Figure 5: Loss of models when binning by the frequency of the previous word measured on BILLIONword (cf. Figure 3).
