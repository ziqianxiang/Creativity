Figure 1: Diagram of the proposed method for one episode, of which several are seen duringmeta-training. The task is to learn new classes given just a few sample images per class. In thisillustrative example, there are 3 classes and 2 samples per class, making each episode a 3-way, 2-shotclassification problem. At the base learning level, learning is accomplished by a differentiable ridgeregression layer (R.R.), which computes episode-specific weights (referred to as wE in Section 3.1and as W in Section 3.2). At the meta-training level, by back-propagating errors through many ofthese small learning problems, we train a network whose weights are shared across episodes, togetherwith the hyper-parameters of the R.R. layer. In this way, the R.R. base learner can improve its learningcapabilities as the number of experienced episodes increases.
Figure 2: Binary classification accuracy on two datasets and two setups at different number of steps ofthe base learner for MAML, R2-D2 and LR-D2. Shaded areas represent 95% confidence intervals.
Figure 3: Shaded areas represent 95% confidence intervals.
