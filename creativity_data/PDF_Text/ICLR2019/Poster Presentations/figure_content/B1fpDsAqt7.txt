Figure 1: An example computation graph forPMN with four tasks. Green rectangles denoteterminal modules, and yellow rectangles denotecompositional modules. Blue arrows and red ar-rows represent calling and receiving outputs fromsubmodules, respectively. White numbered cir-cles denote computation order. For convenience,assume task levels correspond to the subscripts.
Figure 2: Example of PMNâ€™s module execution trace on the VQA task. Numbers in circles indicate the orderof execution. Intensity of gray blocks represents depth of module calls. All variables including queries andoutputs stored in V are continuous vectors to allow learning with standard backpropagation (e.g., caption iscomposed of a sequence of softmaxed W dimensional vectors for vocabulary size W). For Mcap, words withhigher intensity in red are deemed more relevant by Rvcaqpa. Top: high level view of module execution process.
Figure 3: Example of PMN,s reasoning pro-cesses. Top: it correctly first find a personand then uses relationship module to find thetree behind him. Bottom: it finds the wireformance even when using a fraction of the training and then use attribute module to correctly in-data. Table 6 presents the absolute gain in accuracy fer its attributes - white, long, electrical - andPMN achieves. For this experiment, we use Lvqa = then outputs the correct answer.
Figure 4: Example of PMN,s module execution trace on the VQA task. Numbers in circles indicate the order ofexecution. Intensity of gray blocks represents depth of module calls. All variables including queries and outputsstored in V are vectorized to allow gradients to flow (e.g., caption is composed of a sequence of softmaxed Wdimensional vectors for vocabulary size W). For Mcap, words with higher intensity in red are deemed morerelevant by Rcvaqpa .
Figure 5: Example of PMN's reasoning processes compared with the baseline given the question on the left.
