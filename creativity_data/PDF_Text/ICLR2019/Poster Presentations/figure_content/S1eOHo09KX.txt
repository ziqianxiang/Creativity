Figure 1: Network architecture of the proposed approach for prediction and action value estimation.
Figure 2: Evaluation of the proposed method onMNIST dataset. Accuracy vs. number of ac-quired features for OL, RADIN (Contardo et al.,2016), GreedyMiser (Xu et al., 2012), and a recentwork based on reinforcement learning (RL-Based)(Janisch et al., 2017).
Figure 3: Evaluation of the proposed method onLTRC dataset. NDCG vs. cost of acquired fea-tures for OL, CSTC (Xu et al., 2014), Cronus(Chen et al., 2012), and Early Exit (Cambazogluet al., 2010) approaches.
Figure 4: Evaluation of the proposed method on the diabetes dataset. (a) Visualization of featureacquisition orders for 50 test samples (warmer colors represent more priority). (b) Accuracy vs. costof acquired features for this paper (OL), an exhaustive sensitivity-based method (Exhaustive) (Earlyet al., 2016a), the method suggested by Janisch et al. (2017) (RL-Based), and using gating functionsand adaptively trained random forests (Nan & Saligrama, 2017) (Adapt-GBRT).
Figure 5: (a) The average prediction accuracy versus the certainty of samples reported using theMC-dropout method (1000 samples) and directly using the softmax output values. (b) The accuracyversus cost curves for using the MC-dropout method and directly using the softmax output values.
Figure 6: The speed of convergence using thesuggested sharing between the P and Q networks(W/ Sharing) compared with not using the sharingarchitecture (W/O Sharing).
Figure 7: Accuracy versus cost curves achievedusing different budget levels: 25 %, 50%, 75%,and 100% of the cost of acquiring all features.
Figure 8: The validation set accuracy and AUACC values versus the number of episodes for the (a)MNIST and (b) Diabetes datasets.
