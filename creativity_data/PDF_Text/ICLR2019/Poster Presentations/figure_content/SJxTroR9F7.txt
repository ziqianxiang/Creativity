Figure 1: SPU versus TRPO, PPO on 10 Mujoco environments in 1 million timesteps. The x-axisindicates timesteps. The y-axis indicates the average episode reward of the last 100 episodes.
Figure 2:	High-level overview of results on Atari7 AcknowledgementsWe would like to acknowledge the extremely helpful support by the NYU Shanghai High PerformanceComputing Administrator Zhiguo Qi. We also are grateful to OpenAI for open-sourcing their baselinescodes.
Figure 3: Performance of SPU versus TRPO on 10 Mujoco environments in 3 million timesteps. Thex-axis indicates timesteps. The y-axis indicates the average episode reward of the last 100 episodes.
Figure 4: Sensitivity Analysis for SPU18Published as a conference paper at ICLR 2019F.3 Atari ResultsFigure 5, Figure 6 and Figure 7 illustrate the performance of SPU vs PPO throughout training in 60Atari games.
Figure 5: Atari results (Part 1) for SPU vs PPO. The x-axis indicates timesteps. The y-axis indicatesthe average episode reward of the last 100 episodes.
Figure 6: Atari results (Part 2) for SPU vs PPO. The x-axis indicates timesteps. The y-axis indicatesthe average episode reward of the last 100 episodes.
Figure 7: Atari results (Part 3) for SPU vs PPO. The x-axis indicates timesteps. The y-axis indicatesthe average episode reward of the last 100 episodes.
