Figure 1: The algorithm learned by the agent. Each curve in Figure 1a plots the probability thatadvertiser i (as seen by the network) is allocated as a function of their spend when all other advertiserhave spend 0.5 and all advertiser have value 1. plots the following curves. Figure 1b is obtained byaveraging the curves in Figure 1a.
Figure 2: The agent’s learned algorithm for the online Knapsack problem where the values andsizes are picked i.i.d. from U2 [0, 1]. The budget and length of sequence vary in the three figures:(B, n) = (20, 200) (left), (B, n) = (50, 500) (center), and (B, n) = (50, 1000) (right). The top rowdepicts the probability that the agent will accept an item as a function of its value-by-size ratio. Thebottom row depicts the histogram of items as a function of their value-by-size ratio (“all” is over allitems in the sequence, and “taken” is over only the items that the agent accepts into the knapsack).
Figure 3: Figure 3a compares the agent’s learned algorithm with the optimal algorithm in the binarysetting. Figure 3b plots the threshold for the agent’s learned algorithm in the value setting withchanging distributions. Observe that both have learned a threshold at around 1/e.
Figure 4: The tWo special graphs for the online bipartite b matching problem. Figure 4a shoWs theadversarial graph. In the graph, each advertiser has budget of 100. Hence, there exists a perfectb-matching by allocating the first 100 copies to advertiser 1, the second 100 copies to advertiser 2,etc. HoWever, for any randomized algorithm, here is alWays a permutation of the vertices on the lefthand side that Will yield a competitive ratio of at most 1 - 1/e. Figure 4b shoWs the thick-z graph.
Figure 5: This figure displays the evolution of the advertisers’ dual as for BALANCE the learnedagent. All the curves correspond to the worst case instance for online bipartite b-matching. Fig-ure 5a, Figure 5b, Figure 5c, Figure 5d, Figure 5e, and Figure 5f compares the evolution of the dualsfor the advertiser that wants the first 10%, 30%, 40%, 70%, 90%, and 100% of the ads, respectively.
Figure 6: The agent’s algorithm learned algorithm for the bipartite b matching problem where thevalue and spent space has been discretized into 5 buckets. The plots are to be interpreted as follows.
Figure 7: The algorithm learned by the agent. Figure 7a plots the following curves. Fix advertiser i.
Figure 8: In Figure 8a, the learner with augmented state accepts only items of size 1 for type X ,and only items of size k for type Y . In Figure 8b, the learner without the augmented state acceptsitems of size 1 and k for type X (which is suboptimal for X), and only of size k for type Y (whichis optimal for Y ).
Figure 9: The agent’s algorithm for the secretary problem compared with the optimal algorithm forthe secretary problem.
Figure 10: The agent’s algorithm for the secretary problem with i.i.d. values for various values ofthe input length n.
