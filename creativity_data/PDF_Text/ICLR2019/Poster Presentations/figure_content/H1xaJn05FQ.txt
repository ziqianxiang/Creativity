Figure 1: The Wasserstein distance for one-dimensional probability distributions pX and pY (topleft) is calculated based on equation 9. For a numerical implementation, the integral in equation 9 issubstituted with M PMM=I am where, am = c(Pχ1 (τm), P-1(τm)) (top right). When only samplesfrom the distributions are available Xn 〜pχ and yn 〜Y (bottom left), the WaSSerStein distance isapproximated by sorting xms and yms and letting am = c(xi[m] , yj[m]), where i[m] and j[m] are thesorted indices (bottom right).
Figure 2: SW approximations (scaled by 1.22√d) of the W-distance in different dimensions, d ∈ {2n}1n0=1, and differentnumber of random slices, L.
Figure 5: Interpolation in the latent SpaCe, ψ(tφ(I0) + (1 - t)φ(I1)) for t ∈ [0, 1].
Figure 3: The results of SWAE on the MNIST dataset with a two-dimensional embedding space forfour different distributions as ,qZ , namely the ring distribution (top left), the uniform distribution(bottom left), the uniform polar distribution (top right), and a custom polar distribution (bottom right).
Figure 4: Sample convergence behavior for our method compared to the WAE-GAN, where qZ is setto a ring distribution (Figure 3, top left). The columns represent batch iterations (batchsize= 500).
Figure 6: These plots show W1(p, qτ) and JS(p, qτ) where p is a uniform distribution around zeroand qτ (x) = p(x - τ). It is clear that JS divergence does not provide a usable gradient whendistributions are supported on non-overlapping domains.
Figure 7: The optimal coupling (i.e., transport plan) between pX and pY could be equal or differentfromγ(x, y) = δ(y-ψ(φ(x)))pX(x). This leads to the scenario on the right where Wc(pX, pY ) = 0but Wj (PX ,pγ) > 0.
Figure 8: Visualization of the slicing process defined in equation 10Figure 9: Trained SWAE outputs for sample input images with different embedding spaces of sizeK = 2andK = 128.
Figure 9: Trained SWAE outputs for sample input images with different embedding spaces of sizeK = 2andK = 128.
Figure 10: Interpolation results for on the MNIST dataset with various dimensions of the latent space.
Figure 11: Sample convergence behavior for our method compared to the WAE-GAN Tolstikhin et al. (2017), where qz is set to the ring distribution. The columnsrepresent batch iterations φatchsize= 500). The top half of the table shows results of ιψ[z) for Z 〜qz, and the bottom half shows Z 〜qz and φ{x} for X 〜pχ. Itcan be seen that SWAE provides a superior match between φ(x) (i.e. pz) and qz while being less computationally expensive and not requiring adversarial training.
Figure 12: Sample convergence behavior for our method compared to the WAE-GAN Tolstikhin et al. (2017), where qz is set to the uniform polar distribution. Thecolumns represent batch iterations (batchsize= 500). The top half of the table shows results of ιψ[z) for Z 〜qz, and the bottom half shows z ~ qz and φ(x) forx 〜pχ.It can be seen that SWAE provides a superior match between φ{x) (i.e. PZ) and qz while being less computationally expensive and not requiring adversarialtraining.
