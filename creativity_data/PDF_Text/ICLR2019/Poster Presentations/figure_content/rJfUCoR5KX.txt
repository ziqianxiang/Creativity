Figure 1: A convolutional kernel in a Binary Neural NetWork is binary (left) but its values are derivedfrom a full-precision proxy learned using the STE estimator (right). At the end of the training, theproxy kernel is used for one last time to compute final binary values.
Figure 2: Convergence speeds of two binary models trained with different optimisers. We foundADAM to be consistently faster in training BNNs compared to other optimisers. Figure (c) showsthe effect of various momentum rates for ADAMâ€™s first and second moment estimates on the con-vergence of BNNs.
Figure 3: Changing the order of pooling operation within a convolutional block is necessary whentraining binary models.
Figure 4:	A binary model (red) is initialised from a full precision model (blue) and reaches topaccuracy in a fraction of the epochs that would require to train a binary model (green) end-to-end.
Figure 5:	Impact of gradient and weight clipping on convergence speed of binary VGG-10 withlarge learning rates (0.1).
