Figure 1: Test errors OfLeNets pruned at varying sparsity levels κ, where 后=0 refers to the referencenetwork trained without pruning. Our approach performs as good as the reference network acrossvarying sparsity levels on both the models.
Figure 2: Visualizations of pruned parameters of the first layer in LeNet-300-100; the parameters arereshaped to be visualized as an image. Each column represents the visualizations for a particularclass obtained using a batch of 100 examples with varying levels of sparsity κ, from 10 (top) to 90(bottom). Bright pixels indicate that the parameters connected to these region had high importancescores (s) and survived from pruning. As the sparsity increases, the parameters connected to thediscriminative part of the image for classification survive and the irrelevant parts get pruned.
Figure 3: The effect of different batch sizes: (top-row) survived parameters in the first layer ofLeNet-300-100 from pruning visualized as images; (bottom-row) the performance in errors of thepruned networks. For ∖Db∖ = 1, the sampled example was 8; our pruning precisely retains the validconnections. As ∖Db∖ increases, survived parameters get close to the average of all examples in thetrain set (last column), and the error decreases.
Figure 4: The sparse model pruned bySNIP does not fit the random labels.
Figure 5: Results of pruning with SNIP on inverted (Fashion-)MNIST (i.e., dark and bright regions areswapped). Notably, even if the data is inverted, the results are the same as the ones on the original(Fashion-)MNIST in Figure 2.
Figure 6:	Results of pruning with ∂L∕∂w on the original and inverted (Fashion-)MNIST. Notably,compared to the case of using SNIP (Figures 2 and 5), the results are different: Firstly, the results onthe original (Fashion-)MNIST (i.e., (a) and (c) above) are not the same as the ones using SNIP (i.e., (a)and (b) in Figure 2). Moreover, the pruning patterns are inconsistent with different sparsity levels,either intra-class or inter-class. Furthermore, using ∂L∕∂W results in different pruning patternsbetween the original and inverted data in some cases (e.g., the 2nd columns between (c) and (d)).
Figure 7:	The effect of varying sparsity levels (κ). The lower K becomes, the lower training loss isrecorded, meaning that a network with more parameters is more vulnerable to fitting random labels.
