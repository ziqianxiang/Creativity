Figure 1: Functional representations of (a) Gaussian policy and (b) proposed policy.
Figure 2: The cumulative reward (normalized) vs. the number of trajectories in a dataset. The resultsin sparse and dense sampling setup are depicted on top and bottom row, respectively.
Figure 3:	The cumulative reward (normalized) vs. training time (top row) and the number of envi-ronment interactions (bottom row).
Figure 4:	The cumulative reward (normalized) vs. the number of environment interactions on Ant-v1in the ablation experiment.
