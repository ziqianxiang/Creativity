Figure 1: Learning rates of sampled parameters. Each cell contains a value obtained by conductinga logarithmic operation on the learning rate. The lighter cell stands for the smaller learning rate.
Figure 2: Training (left) and test accuracy (right) for feedforward neural network on MNIST.
Figure 3: Training and test accuracy for DenseNet-121 and ResNet-34 on CIFAR-10.
Figure 4: Perplexity curves on the test set comparing Sgd, Adam, AdaB ound and AMSBoundfor the LSTM with different layers on Penn Treebank.
Figure 5: Test accuracy of ADABOUND with different β using ResNet-34 on CIFAR-10.
Figure 6: Test accuracy of SgdM/ADABOUND with different a∕α* using ResNet-34 on CIFAR-10.
Figure 7: Comparison of test accuracy between SGDM and AdaBound with different ɑ/ɑ*.
Figure 8: The evolution of learning rates over time in two randomly chosen layers.
