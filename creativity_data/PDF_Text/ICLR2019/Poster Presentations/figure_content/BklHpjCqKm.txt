Figure 1: The computational graph of the Deep Lagrangian Network (DeLaN). Shown in blue andgreen is the neural network with the three separate heads computing g(q), ld(q), lo(q). The orangeboxes correspond to the reshaping operations and the derivatives contained in the Euler-Lagrangeequation. For training the gradients are backpropagated through all vertices highlighted in orange.
Figure 2: (a) Computational graph of the Lagrangian layer. The orange boxes highlight the learnableparameters. The upper computational sub-graph corresponds to the standard network layer whilethe lower sub-graph is the extension of the Lagrangian layer to simultaneously compute ∂hi/∂h*ι.
Figure 3: (a) Real-time control loop using a PD-Controller with a feed-forward torque TFF, compen-sating the system dynamics, to control the joint torques T. The training process reads the joint statesand applies torques to learn the system dynamics online. Once a new model becomes available theinverse model f 1 in the control loop is updated. (b) The simulated 2-dof robot drawing the cosinetrajectories. (c) The simulated Barrett WAM drawing the 3d cosine 0 trajectory. (d) The physicalBarrett WAM.
Figure 4: (a) The torque τ required to generate the characters ’a’, ’d’ and ’e’ in black. Using thesesamples DeLaN was trained offline and learns the red trajectory. DeLaN can not only learn thedesired torques but also disambiguate the individual torque components even though DeLaN wastrained on the super-imposed torques. Using Equation 6 DeLaN can represent the inertial force Hq(b), the Coriolis and Centrifugal forces c(q, q) (c) and the gravitational force g(q) (d). All componentsmatch closely the ground truth data. (e) shows the offline MSE of the feed-forward neural networkand DeLaN for each joint.
Figure 5:	(a) The average performance of DeLaN and the feed forward neural network for eachcharacter. The 4 columns of the boxplots correspond to different numbers of training characters,i.e., n = 1, 6, 8, 10. (b) The median performance of DeLaN, the feed forward neural network andthe analytic baselines averaged over multiple seeds. The shaded areas highlight the 5th and the95th percentile. (c) The qualitative performance for the analytic baselines, the feed forward neuralnetwork and DeLaN. The desired trajectories are shown in red.
Figure 6:	The tracking error of the cosine trajectories for the simulated 2-dof robot (a & b), thesimulated (c & d) and the physical Barrett WAM (e & f). The feed-forward neural network andDeLaN are trained only on the trajectories at a velocity scale of 1×. Afterwards the models are testedon the same trajectories with increased velocities to evaluate the extrapolation to new velocities.
Figure 7: The mean squared error averaged of 20 seeds on the training- (a) and test-set (b) of thecharacter trajectories for the two joint robot. The models are trained offline using n characters andtested using the remaining 20 - n characters. The training samples are corrupted with white noise,while the performance is tested on noise-free trajectories.
Figure 8: The mean squared error of the cosine trajectories for the simulated (a, b) and the physicalBarrett WAM (c and d). The system identification approach, feed-forward neural network andDeLaN are trained offline using only the trajectories at a velocity scale of 1×. Afterwards the modelsare tested on the same trajectories with increased velocities to evaluate the extrapolation to newvelocities.
Figure 9: The mean squared error on the simulated and noise-free cosine trajectories with velocityscale of 1x. For offline training the samples are corrupted using i.i.d. noise sampled from amultivariate Normal distribution with the variance of σ2I.
Figure 10: The qualitative performance for the analytic baselines, the feed forward neural networkand DeLaN for different number of random training characters. The desired trajectories are shownin red.
Figure 11: The average performance of DeLaN and the feed forward neural network for eachcharacter. The columns of the boxplots correspond to different numbers of training characters, i.e.,n= 1,2,4,6, 8, 10, 12.
