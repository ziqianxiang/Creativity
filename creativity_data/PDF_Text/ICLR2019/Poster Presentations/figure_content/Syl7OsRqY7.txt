Figure 1: The Coarse-grain Fine-grain Coattention Network.
Figure 2: Coarse-grain module.
Figure 3: The fine-grain module of the CFC.
Figure 4: An example from the Qangaroo WikiHop QA task. The relevant multiple pieces of evi-dence required to answer the question is shown in red. The correct answer is shown in blue.
Figure 5: WikiHop dev errors across query lengths, support documents lengths, number of supportdocuments, and number of candidates for the coarse-grain-only and fine-grain-only models.
Figure 7:	Fine-grain coattention and self-attention scores for for the querylocated_in_the_administrative-territorial-entity hampton Wick warmemorial, for which the answer is “London borough of Richmond Upon Thames”. Thecoattention tends to align the relation part of the query to the context in which the mention occursin the text. The first, second, and fourth mentions respectively describe Hampton Wicks, HamptonHills, and Teddington — all of which are located in Richmond upon Thames. The third describesRichmond upon Thames itself.
Figure 6: Coarse-grain summaryself-attention scores for the querycountry_of.origin thetroll, for which the answer is“United Kingdom”. The summary self-attention tends to focus on documentsrelevant to the subject in the query. Thetop three support documents 2, 4, 5respectively present information aboutthe literary work The Troll, its authorJulia Donaldson, and Old Norse.
Figure 8: Accuracy convergence plot.
Figure 10: Top supporting documents.
Figure 12: Top supporting documents.
Figure 14: Top supporting documents.
Figure 16: Top supporting documents.
