Figure 1: Representations arising from a commu-nication game. In this game, an observation (b) ispresented to a learned speaker model (c), whichencodes it as a discrete character sequence (d) tobe consumed by a listener model for some down-stream task. The space of inputs has known com-positional structure (a). We want to measure theextent to which this structure is reflected (perhapsimperfectly) in the structure of the learned codes.
Figure 2: Meta-Iearning task: learners are presented withtwo example images depicting a visual concept (a), andmust determine whether a third image (b) is an example ofthe same concept (c).
Figure 3: Relationship between reconstruction error TRE and mutual information I(θ; X) betweeninputs and representations. (a) Evolution of the two quantities over the course of a single run. Bothinitially increase, then decrease. The color bar shows the training epoch. (b) Values from ten trainingruns. (c) Values from the second half of each training run, taken to begin when I(θ; X) reaches amaximum. In (b) and (c), the observed correlation is significant: respectively (r = 0.70, p < 1e-10)and (r = 0.71, p < 1e-8).
Figure 4: The communication task:A speaker model observes a pairof target objects, and sends a de-scription of the objects (as a dis-crete code) to a listener model. Thelistener attempts to reconstruct thetargets, receiving fractional rewardfor partially-correct predictions.
Figure 5:	Relationship between tre and reward. (a) Compositional languages exhibit lowergeneralization error, measured as the difference between train and test reward (r = 0.50, p < 1e-6).
Figure 6:	Fragment of languages resulting from two multiagent training runs. In the first section, theleft column shows the target referent, while the remaining columns show the message generated byspeaker in the given training run after observing the referent. The two languages have substantiallydifferent TRE, but induce similar listener performance (Train and Test reward).
