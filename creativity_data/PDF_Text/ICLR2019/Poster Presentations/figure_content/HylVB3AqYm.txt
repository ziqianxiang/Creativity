Figure 1: ProxylessNAS directly optimizes neural network architectures on target task and hard-ware. Benefiting from the directness and specialization, ProxylessNAS can achieve remarkablybetter results than previous proxy-based approaches. On ImageNet, with only 200 GPU hours (200X fewer than MnasNet (Tan et al., 2018)), our searched CNN model for mobile achieves the samelevel of top-1 accuracy as MobileNetV2 1.4 while being 1.8 × faster.
Figure 2: Learning both weight parameters and binarized architecture parameters.
Figure 3: Making latency differentiable by introducing latency regularization loss.
Figure 4: ProxylessNAS consistentlyoutperforms MobileNetV2 under vari-ous latency settings.
Figure 5: Our mobile latency model isclose to y = x. The latency RMSE is0.75ms.
Figure 6: Efficient models optimized for different hardware. “MBConv3" and “MBConv6" denotemobile inverted bottleneck convolution layer with an expansion ratio of 3 and 6 respectively. In-sights: GPU prefers shallow and wide model with early pooling; CPU prefers deep and narrowmodel with late pooling. Pooling layers prefer large and wide kernel. Early layers prefer smallkernel. Late layers prefer large kernel.
