Figure 1: Translation results of the prior work (CycleGAN, Zhu et al. (2017)), and our proposedmethod, InstaGAN. Our method shows better results for multi-instance transfiguration problems.
Figure 2: (a) Overview of InstaGAN, where generators GXY, GYX and discriminator DX, DY followsthe architectures in (b) and (c), respectively. Each network is designed to encode both an image andset of instance masks. G is permutation equivariant, and D is permutation invariant to the set order.
Figure 3: Overview of the sequential mini-batch training with instance subsets (mini-batches) of size1,2, and 1, as shown in the top right side. The content loss is applied to the intermediate samples ofcurrent mini-batch, and GAN loss is applied to the samples of aggregated mini-batches. We detachevery iteration in training, in that the real line indicates the backpropagated paths and dashed linesindicates the detached paths. See text for details.
Figure 4: Translation results on clothing co-parsing (CCP) (Yang et al., 2014) dataset.
Figure 5: Translation results on multi-human parsing (MHP) (Zhao et al., 2018) dataset.
Figure 6: Translation results on COCO (Lin et al., 2014) dataset.
Figure 8: Translation results on CCP dataset, using predicted mask for inference.
Figure 11: Trend of the translation results of our method over epoch increases.
Figure 12: Translation results for images searched from Google to test the generalization perfor-mance of our model. We used a pix2pix (Isola et al., 2017) model to predict the segmentation.
Figure 13: More translation results on MHP dataset (pants→skirt).
Figure 14: More translation results on MHP dataset (skirt→pants).
Figure 15: More translation results on COCO dataset (sheep→giraffe).
Figure 16: More translation results on COCO dataset (giraffe→sheep).
Figure 17: More translation results on COCO dataset (zebra→elephant).
Figure 18: More translation results on COCO dataset (elephant→zebra).
Figure 19: More translation results on COCO dataset (bird→zebra).
Figure 20: More translation results on COCO dataset (zebra→bird).
Figure 21: More translation results on COCO dataset (horse→car).
Figure 22: More translation results on COCO dataset (car→horse).
Figure 23: Comparisons with CycleGAN+Seg on MHP dataset (pants→skirt).
Figure 24: Comparisons with CycleGAN+Seg on MHP dataset (skirt→pants).
Figure 25: Comparisons with CycleGAN+Seg on COCO dataset (sheep→giraffe).
Figure 26: Comparisons with CycleGAN+Seg on COCO dataset (giraffe→sheep).
Figure 27: Nearest training neighbors of translated masks.
Figure 28: Translation results of crop & attach baseline.
Figure 29: Original images (row 1) and translated results of our method (row 2) on a video searchedfrom YouTube. We present translation results on successive eight frames for visualization.
