Figure 1: DeepSSRR uses convolutional layers to learn a transformation from signals to undersampledmeasurements and an inverse transformation from undersampled measurements to signals. Note thatoperations are performed right to left.
Figure 2: Graphical interpretation of convolution parallelization in sensing (right side of Figure 1)and deconvolution parallelization in recovery (left side of Figure 1): Converting a strided convolution(deconvolution) into the summation of several parallel convolutions (deconvolutions).
Figure 3: (a) Embedding size M vs. empirical isometry constant for CIFAR-10 dataset. DeepSSRRsignificantly outperforms other methods for a wide range of values. (b) Fraction of k-nearestneighbors that are preserved in an M -dimensional embedding compared to the N -dimensional datafor CIFAR-10 images. For NuMax and random embedding M = 65 in (i) and M = 289 in (ii). Fordeep networks (DeepSSRR and DCN) M = 64 in (i) and M = 256 in (ii).
Figure 4: Reconstructions of 512 × 512 test images sampled at a rate of MN = 0.25. DeePSSRR doesa better job in recovering fine textures as compared to DAMP and LDAMP.
Figure 5: (a) The blue curve is the `1 phase transition. The circular and square points denote probleminstances for DeepInverse and DeepSSRR, respectively. Arrows show different configurations for thesame set of signals. (b) Test MSE of DeepInverse and DeepSSRR during different training epochs.
Figure 6: (a) Reconstruction of the 512 × 512 mandrill image sampled at the rate of M = 0.25. (b)Zoomed in reconstruction of mandrill’s nose and cheeks.
