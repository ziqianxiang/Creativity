Figure 1:	Illustration oftracking-based RL training.
Figure 4: Schematic of the architecture: a high-level controller (HL) selects among multiple low-level (LL) control fragments, which are policies with proprioception. Switching from one controlfragment to another occurs every k time steps.
Figure 5: A. Go-to-target: in this task, the agent moves on an open plane to a target provided inegocentric coordinates. B. Walls: The agent runs forward while avoiding solid walls using vision.
Figure 6: Performance of various approaches on each core task. Of the approaches we compared,discrete switching among control fragments performed the best. Plots show the mean and standarderror over multiple runs.
Figure 7: Example agent-view frames and corresponding visuomotor salience visualizations. Notethat the ball is more sharply emphasized, suggesting the selected actions were influenced by theaffordance of tacking toward the ball.
