Figure 1: Visualization of an RNN that highlights a cell (purple), a layer (red) and the initial hidden state ofeach layer (green). (Best viewed in color.)such nonlinearities have recently gained considerable attention due to their ability to combat theexploding gradient problem; with proper initialization (Le et al., 2015; Talathi & Vartak, 2016) andclever parametrization of the recurrent weight (Arjovsky et al., 2016; Wisdom et al., 2016; Jinget al., 2017; Hyland & Ratsch, 2017; Mhammedi et al., 2017; HeIfrich et al., 2018), these RNNsachieve performance on par with more complex ones such as LSTMs. Below is a summary of ourkey contributions.
Figure 2: t-SNE (van der Maaten & Hinton, 2008) visualization of the evolution of the RNN partition codesof input sequences from the MNIST test set. Each color represents one of the ten classes. We see clearly thatthe RNN gradually develops and refines the partition codes through time to separate the classes.
Figure 3: Templates corresponding to the correct (left) and incorrect class (right) of a negative sentiment inputfrom the SST-2 dataset. Each column contains the gradient corresponding to an input word. Quantitatively, wecan see that the inner product between input and the correct class template (left) produces a larger value thanthat between input and the incorrect class template (right).
Figure 4: Visualization of the regularization effect of a random initial hidden state on the adding task (T =100). (Top) Norm of Ah every 100 iterations; (Middle) norm of the gradient of the recurrent weight every 100iterations; (Bottom) validation loss at every epoch. Each epoch contains 1000 iterations.
Figure 5: Visualization of partition codes for pixel-by-pixel (i.e., flattened to a 1-dimensional, length784 vector) MNIST dataset using a trained ReLU RNN (one layer, 128-dimensional hidden state).
Figure 6: t-SNE visualization of MNIST test set images using raw pixel representation (left) andRNN VQ representation (right). We see more distinct clusters in the t-SNE plot using RNN VQrepresentation of images than the raw pixel representation, implying the useful information thatRNN extracts in the form of VQ.
Figure 7: Nearest and furthest neighbors of a postive movie review. The sentiment (+ or -) and theeuclidean distance between the input and the neighbor vector quantizations are shown in parenthesisafter each neighbor.
Figure 8: Templates of three selected MNIST images. The leftmost column are the original inputimage. The next ten images of each row are the ten templates of a particular input image corre-sponding to each class. For each template image, we show the class and the inner product of thistemplate with the input. Text under the template of the true class of each input image is bolded.
Figure 9: Additional template visualizations of an example from the SST-2 dataset. Each word inthe sentence is marked as a tick label in the x axis. The values of inner products are marked beloweach template. The template that has the bigger inner product is the true class of the sentence. Wesee that the template corresponding to the correct class produces a significantly bigger inner productwith the input than other templates.
Figure 10: Various plots during training of add problem (T=100, regression). Top: norm of Ah atevery 100 iterations; Middle: norm of gradient of recurrent weight at every 100 iterations; Bottom:validation loss at every epoch. Each epoch contains 1000 iterations.
