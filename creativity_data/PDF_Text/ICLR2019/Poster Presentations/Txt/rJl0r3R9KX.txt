Published as a conference paper at ICLR 2019
Regularized Learning for Domain Adaptation
under Label Shifts
Kamyar Azizzadenesheli
University of California, Irvine
kazizzad@uci.edu
Anqi Liu
California Institute of Technology
anqiliu@caltech.edu
Fanny Yang
Institute of Theoretical Studies, ETH Zurich
fan.yang@stat.math.ethz.ch
Animashree Anandkumar
California Institute of Technology
anima@caltech.edu
Ab stract
We propose Regularized Learning under Label shifts (RLLS), a principled and a
practical domain-adaptation algorithm to correct for shifts in the label distribution
between a source and a target domain. We first estimate importance weights using
labeled source data and unlabeled target data, and then train a classifier on the
weighted source samples. We derive a generalization bound for the classifier on the
target domain which is independent of the (ambient) data dimensions, and instead
only depends on the complexity of the function class. To the best of our knowledge,
this is the first generalization bound for the label-shift problem where the labels in
the target domain are not available. Based on this bound, we propose a regularized
estimator for the small-sample regime which accounts for the uncertainty in the
estimated weights. Experiments on the CIFAR-10 and MNIST datasets show that
RLLS improves classification accuracy, especially in the low sample and large-shift
regimes, compared to previous methods.
1	Introduction
When machine learning models are employed “in the wild”, the distribution of the data of inter-
est(target distribution) can be significantly shifted compared to the distribution of the data on which
the model was trained (source distribution). In many cases, the publicly available large-scale datasets
with which the models are trained do not represent and reflect the statistics of a particular dataset
of interest. This is for example relevant in managed services on cloud providers used by clients in
different domains and regions, or medical diagnostic tools trained on data collected in a small number
of hospitals and deployed on previously unobserved populations and time frames.
There are various ways to approach distribution shifts between	COvariate Shift	LabelShift
a source data distribution P and a target data distribution Q. If p(x) = q(x) p(y) = q(y)
we denote input variables as X and output variables as y, we	p(y|x) = q(y|x) P(Xiy) = q(x|y)
consider the two following settings: (i) Covariate shift, which
assumes that the conditional output distribution is invariant: p(y|x) = q(y|x) between source and
target distributions, but the source distribution p(x) changes. (ii) Label shift, where the conditional
input distribution is invariant: p(x|y) = q(x|y) and p(y) changes from source to target. In the
following, we assume that both input and output variables are observed in the source distribution
whereas only input variables are available from the target distribution.
While covariate shift has been the focus of the literature on distribution shifts to date, label-shift
scenarios appear in a variety of practical machine learning problems and warrant a separate discussion
as well. In one setting, suppliers of machine-learning models such as cloud providers have large
resources of diverse data sets (source set) to train the models, while during deployment, they have no
control over the proportion of label categories.
In another setting of e.g. medical diagnostics, the disease distribution changes over locations and
time. Consider the task of diagnosing a disease in a country with bad infrastructure and little data,
1
Published as a conference paper at ICLR 2019
based on reported symptoms. Can we use data from a different location with data abundance to
diagnose the disease in the new target location in an efficient way? How many labeled source and
unlabeled target data samples do we need to obtain good performance on the target data?
Apart from being relevant in practice, label shift is a computationally more tractable scenario than
covariate shift which can be mitigated. The reason is that the outputs y typically have a much lower
dimension than the inputs x. Labels are usually either categorical variables with a finite number
of categories or have simple well-defined structures. Despite being an intuitively natural scenario
in many real-world application, even this simplified model has only been scarcely studied in the
literature. Zhang et al. (2013) proposed a kernel mean matching method for label shift which is
not computationally feasible for large-scale data. The approach in Lipton et al. (2018) is based on
importance weights that are estimated using the confusion matrix (also used in the procedures of
Saerens et al. (2002); McLachlan (2004)) and demonstrate promising performance on large-scale
data. Using a black-box classifier which can be biased, uncalibrated and inaccurate, they first estimate
importance weights q(y)/p(y) for the source samples and train a classifier on the weighted data. In
the following we refer to the procedure as black box shift learning (BBSL) which the authors proved
to be effective for large enough sample sizes.
However, there are three relevant questions which remain unanswered by their work: How to estimate
the importance weights in low sample setting, What are the generalization guarantees for the final
predictor which uses the weighted samples? How do we deal with the uncertainty of the weight
estimation when only few samples are available? This paper aims to fill the gap in terms of both
theoretical understanding and practical methods for the label shift setting and thereby move a step
closer towards having a more complete understanding on the general topic of supervised learning for
distributionally shifted data. In particular, our goal is to find an efficient method which is applicable
to large-scale data and to establish generalization guarantees.
Our contribution in this work is trifold. Firstly, we propose an efficient weight estimator for which
we can obtain good statistical guarantees without a requirement on the problem-dependent minimum
sample complexity as necessary for BBSL. In the BBSL case, the estimation error can become
arbitrarily large for small sample sizes. Secondly, we propose a novel regularization method to
compensate for the high estimation error of the importance weights in low target sample settings.
It explicitly controls the influence of our weight estimates when the target sample size is low (in
the following referred to as the low sample regime). Finally, we derive a dimension-independent
generalization bound for the final Regularized Learning under Label Shift (RLLS) classifier based on
our weight estimator. In particular, our method improves the weight estimation error and excess risk
of the classifier on reweighted samples by a factor of k log(k), where k is the number of classes, i.e.
the cardinality of Y .
In order to demonstrate the benefit of the proposed method for practical situations, we empirically
study the performance of RLLS and show weight estimation as well as prediction accuracy comparison
for a variety of shifts, sample sizes and regularization parameters on the CIFAR-10 and MNIST
datasets. For large target sample sizes and large shifts, when applying the regularized weights fully,
we achieve an order of magnitude smaller weight estimation error than baseline methods and enjoy at
most 20% higher accuracy and F-1 score in corresponding predictive tasks. For low target sample
sizes, applying regularized weights partially also yields an accuracy improvement of at least 10%
over fully weighted and unweighted methods.
2	Regularized learning of label shifts (rlls)
Formally let us the short hand for the marginal probability mass functions of Y on finite Y with
respect to P, Q as p, q : [k] → [0, 1] with p(i) = P(Y = i), and q(i) = Q(Y = i) for all i ∈ [k],
representable by vectors in Rk+ which sum to one. In the label shift setting, we define the importance
weight vector W ∈ Rk between these two domains as w(i)=犒.We quantify the shift using the
exponent of the infinite and second order Renyi divergence as follows
d∞(q∣∣p):= sup
i
q7iτ , and d(q∖∖p) ：= EY〜Q [w(Y)2] = X q(i)qvir.
p(i)	p(i)
2
Published as a conference paper at ICLR 2019
Given a hypothesis class H and a loss function ` : Y × Y → [0, 1], our aim is to find the hypothesis
h ∈ H which minimizes
L(h) = Ex,y〜Q ['(Y, h(X))] = Ex,y〜P [w(Y)'(Y, h(X))]
In the usual finite sample setting however, L unknown and we observe samples {(xj, yj)}jn=1 from P
instead. If we are given the vector of importance weights w we could then minimize the empirical
loss with importance weighted samples defined as
1n
LnS) = — Ew(yj )'(yj,h(Xj))
n j=1
where n is the number of available observations drawn from P used to learn the classifier h. As w is
unknown in practice, we have to find the minimizer of the empirical loss with estimated importance
weights
1n
Ln(h;w) = n^2wbb(yj )'(yj, h(xj))	(I)
where wb are estimates of w. Given a set Dp of np samples from the source distribution P, we first
divide it into two sets where we use (1 - β)np samples in set Dpweight to compute the estimate wb
and the remaining n = βnp in the set Dpclass to find the classifier which minimizes the loss (1), i.e.
hwb = arg min h∈H Ln(h; wb). In the following, we describe how to estimate the weights wb and
provide guarantees for the resulting estimator hwb .
Plug-in weight estimation The following simple correlation between the label distributions p, q
was noted in Lipton et al. (2018): for a fixed hypothesis h, if for all y ∈ Y it holds that q(y) ≥ 0 =⇒
p(y ) ≥ 0, we have
kk
qh(i) :=Q(h(X)=i)=XQ(h(X)=i|Y=j)q(j)=XP(h(X)=i|Y=j)q(j)
j=1	j=1
k	q(j)	k
X P(h(X) = i,Y = j) pj) = X P(h(X ) = i,Y = j)wj
for all i, j ∈ Y . This can equivalently be written in matrix vector notation as
qh = Chw,	(2)
where Ch is the confusion matrix with [Ch]i,j = P(h(X) = i, Y = j ) and qh is the vector
which represents the probability mass function of h(X) under distribution Q. The requirement
q(y) ≥ 0 =⇒ p(y) ≥ 0 is a reasonable condition since without any prior knowledge, there is no
way to properly reason about a class in the target domain that is not represented in the source domain.
In reality, both qh and Ch can only be estimated by the corresponding finite sample averages
qbh, Ch. Lipton et al. (2018) simply compute the inverse of the estimated confusion matrix Ch in
order to estimate the importance weight, i.e. wb = Cbh-1qbh. While Ch-1qbh is a statistically efficient
11
estimator, wb with estimated Ch-1 can be arbitrarily bad since Ch-1 can be arbitrary close to a singular
matrix especially for small sample sizes and small minimum singular value of the confusion matrix.
Intuitively, when there are very few samples, the weight estimation will have high variance in which
case it might be better to avoid importance weighting altogether. Furthermore, even when the sample
complexity in Lipton et al. (2018), unknown in practice, is met, the resulting error of this estimator is
linear in k which is problematic for large k .
We therefore aim to address these shortcomings by proposing the following two-step procedure to
compute importance weights. In the case of no shift we have w = 1 so that we define the amount
of weight shift as θ = w - 1. Given a “decent” black box estimator which we denote by h0 , we
make the final classifier less sensitive to the estimation performance of C (i.e. regularize the weight
estimate) by
3
Published as a conference paper at ICLR 2019
1.	calculating the measurement error adjusted θ (described in Section 2.1 for h0) and
2.	computing the regularized weight wb = 1 + λθb where λ depends on the sample size (1-β)np.
By "decent" we refer to a classifier h0 which yields a full rank confusion matrix Ch0 . A trivial
example for a non-”decent” classifier h0 is one that always outputs a fixed class. As it does not
capture any characteristics of the data, there is no hope to gain any statistical information without any
prior information.
2.1	Estimator correcting for finite sample errors
Both the confusion matrix Ch0 and the label distribution qh0 on the target for the black box hypothesis
h0 are unknown and we are instead only given access to finite sample estimates Cbh0 , qbh0 . In what
follows all empirical and population confusion matrices, as well as label distributions, are defined
with respect to the hypothesis h = h0 . For notation simplicity, we thus drop the subscript h0 in what
follows. The reparameterized linear model (2) with respect to θ then reads
b := q - C1 = Cθ
...	「 C J	I	... G
with corresponding finite sample quantity b
ʌ AY 5 八 A.	∙	..	CA
qb- C1. When C is near singular, the estimation of θ
becomes unstable. Furthermore, large values in the true shift θ result in large variances. We address
this problem by adding a regularizing `2 penalty term to the usual loss and thus push the amount of
shift towards 0, a method that has been proposed in (Pires & SzePesv制,2012). In particular, We
compute
θb= arg min kCbθ - bbk2 + ∆C kθk2
θ
(3)
Here, ∆C is a parameter which will eventually be high probability upper bounds for kCb - Ck2 . Let
∆b also denote the high probability upper bounds for kb - bk2 .
Lemma 1 For θb as defined in equation (3), we have with probability at least 1 - δ that1
kθb- θk2 ≤ θ(np,nq, kθk2, δ)
where
S(n”nq，kθk2,δ) ：= O 1Λ (kθk2∖S 鲁等 + SWT+ \「)
σmin (1 - β)np (1 - β)np	nq
The proof of this lemma can be found in Appendix B.1. A couple of remarks are in order at this
point. First of all, notice that the weight estimation procedure (3) does not require a minimum
sample complexity which is in the order of σm-i2n to obtain the guarantees for BBSL. This is due to
the fact that errors in the covariates are accounted for. In order to directly see the improvements
in the upper bound of Lemma 1 compared to Theorem 3 in Lipton et al. (2018), first observe
that in order to obtain their upper bound with a probability of at least 1 - δ, it is necessary that
3knp-10 + 2knq-10 ≤ δ. As a consequence, the upper bound in Theorem 3 of Lipton et al. (2018)
is bigger than ^1- (kθk2 JIog(3k∕δ) + Jk Iogn2k®). ThUS Lemma 1 improves upon the previous
upper bound by a factor of k.
Furthermore, as in Lipton et al. (2018), this result holds for any black box estimator h0 which enters
the bound via σmin (Ch0). We can directly see how a good choice of h0 helps to decrease the upper
bound in Lemma 1. In particular, if h0 is an ideal estimator, and the source set is balanced, C is the
unit matrix with σmin =1/k. In contrast, when the model h0 is uncertain, the singular value σmin is
close to zero.
Moreover, for least square problems with Gaussian measurement errors in both input and target
variables, it is standard to use regularized total least squares approaches which requires a singular
value decomposition. Finally, our choice for the alternative estimator in Eq. 3 with norm instead of
norm squared regularization is motivated by the cases with large shifts θ, where using the squared
norm may shrink the estimate θ too much and away from the true θ.
1Throughout the paper, O hides universal constant factors. Furthermore, we use O (∙ + ∙) for short to denote
o (∙) + o(∙).
4
Published as a conference paper at ICLR 2019
Algorithm 1 Regularized Learning of Label Shift (RLLS)
1:	Input: source set Dp, Dq, θmaχ, estimate of σma, black box estimator h°, model class H
2:	Determine optimal split ratio β? and regularizer λ? by minimizing the RHS of Eq. (6) using an
estimate of σmin
3:	Randomly partition source set Dp into Dplass, DweightSUch that |Dplass| = β?n? =: n
一	. ʌ 一 、O
4:	Compute θ using Eq. (3) and W :=1 + λ*θ
5:	Minimize the importance weighted empirical loss to obtain the weighted estimator
1
hw = argmιn Ln(h; w),	where	Ln(h; w) = —	>	w(y)'(y, h(x))
h∈H	n
(x,y)∈Dcplass
，C I G ♦…	.…	.一
6:	Deploy hwb if the risk is acceptable
2.2	Regularized estimator and generalization bound
When a few samples from the target set are available or the label shift is mild, the estimated weights
might be too uncertain to be applied. We therefore propose a regularized estimator defined as follows
wb = 1 + λθb.
(4)
Note that wb implicitly depends on λ, and β. By rewriting wb = (1 - λ)1 + λ(1 + θ), we see that
intuitively λ closer to 1 the more reason there is to believe that 1 + θ is in fact the true weight.
Define the set G(', H) = {gh(x, y) = w(y)'(h(x), y) : h ∈ H} and its Rademacher complexity
measure
Rn(G) :=
E(Xi,Yi)〜P"∈[n]
Eξi"∈[n] n
n
sup X
h∈H i=1
ξigh(Xi,h(Yi))
))
with ξi , ∀i as the Rademacher random variables (see e.g. Bartlett & Mendelson (2002)). We can now
state a generalization bound for the classifier hwb in a general hypothesis class H, which is trained on
source data with the estimated weights defined in equation (4).
Theorem 1 (Generalization bound for hwb ) Given np samples from the source data set and nq
samples from the target set, a hypothesis class H and loss function `, the following generalization
bound holds with probability at least 1 - 2δ
.,^ . . , _ . , _ , . . .. _ , .. _ _
L(bhwb) - L(h ) ≤ G (np, δ, β) + (1 - λ) kθk2 + λθ (np, nq, kθk2, δ, β).	(5)
where
，G(np, δ) := 2Rn(G) + mm 卜∞(q∣叫/^, 2般(*)10以20 +	).
βnp	n	n
The proof can be found in Appendix B.4. Additionally, we derive the analysis also for finite hypothesis
classes in Appendix B.6 to provide more insight into the proof of general hypothesis classes. The
size of Rn(G) is determined by the structure of the function class H and the loss `. For example for
the 0/1 loss, the VC dimension of H can be deployed to upper bound the Rademacher complexity.
The bound (5) in Theorem 1 holds for all choices of λ. In order to exploit the possibility of choosing
λ and β to have an improved accuracy depending on the sample sizes, we first let the user define a set
of shifts θ against which we want to be robust against, i.e. all shifts with kθk2 ≤ θmax. For these
shifts, we obtain the following upper bound
C∕7*∖/
L(hwb ) - L(h ) ≤ G (np , δ) + (1 - λ) θmax + λθ (np, nq, θmax, δ)	(6)
The bound in equation (6) suggests using Algorithm 1 as our ultimate label shift correction procedure.
where for step 2 of the algorithm, we choose λ? = 1 whenever nq
1
一θmax(σmin-
-√1T)2 (hereby
neglecting the log factors and thus dependencies on k) and 0 else. When using this rule, we
5
Published as a conference paper at ICLR 2019
1 , ∙ C/G ∖	c∕7*∖/	/ r∖	∙ C /-1	/	八	r∖ 1 ι ∙ ι	ιι ,ι ,ι
obtain L(hw) - L(h*) ≤ eg(np,δ) + mrn{θmaχ,eθ(np,nq,θmaχ,δ)} which is smaller than the
unregularized bound for small nq , np. Notice that in practice, we do not know σmin in advance so
that in Algorithm 1 we need to use an estimate of σmin, which could e.g. be the minimum eigenvalue
^
of the empirical confusion matrix C with an additional computational complexity of at mos
Figure 1 shows how the oracle thresholds vary with nq and σmin
when np is kept fix. When the parameters are above the curves for
fixed np , λ should be chosen as 1 otherwise the samples should
be unweighted, i.e. λ = 0. This figure illustrates that when the
confusion matrix has small singular values, the estimated weights
should only be trusted for rather high nq and high believed shifts
θmax . Although the overall statistical rate of the excess risk of the
classifier does not change as a function of the sample sizes, θmax
could be significantly smaller than eθ when σmin is very small and
thus the accuracy in this regime could improve. Indeed we observe
this to be the case empirically in Section 3.3.
t O(k3).
θmax , λ switches from 0 to 1 at a
particular nq. np and k are fixed.
In the case of slight deviation from the label shift setting, we expect the Alg. 1 to perform reasonably.
For de(q||p) := E(χ,γ)〜Q 口1 - p(X∣Y) ∣] as the deviation form label shift constraint, i.e., zero under
label shift assumption, we have
Theorem 2 (Drift in Label shift assumption) In the presence of de(q||p) deviation from label shift
assumption, the true importance weights ω(x, y) := Pxy, the RLLS generalizes as;
L(bhwb, ω) - L(h ; ω) ≤ eG(np, δ) + (1 - λ) kθk2 + λeθ (np, nq, kθk2, δ) + 4 (1 - λ) de(q||p)
with high probability. Proof in Appendix B.7.
3	EXPERIMENTS
In this section we illustrate the theoretical analysis by running RLLS on a variety of artificially
generated shifts on the MNIST (LeCun & Cortes, 2010) and CIFAR10 (Krizhevsky & Hinton, 2009)
datasets. We first randomly separate the entire dataset into two sets (source and target pool) of the
same size. Then we sample, unless specified otherwise, the same number of data points from each
pool to form the source and target set respectively. We chose to have equal sample sizes to allow for
fair comparisons across shifts.
There are various kinds of shifts which we consider in our experiments. In general we assume one of
the source or target datasets to have uniform distribution over the labels. Within the non-uniform set,
we consider three types of sampling strategies in the main text: the Tweak-One shift refers to the case
where we set a class to have probability p > 0.1, while the distribution over the rest of the classes
is uniform. The Minority-Class Shift is a more general version of Tweak-One shift, where a fixed
number of classes m to have probability p < 0.1, while the distribution over the rest of the classes is
uniform. For the Dirichlet shift, we draw a probability vector p from the Dirichlet distribution with
concentration parameter set to α for all classes, before including sample points which correspond to
the multinomial label variable according to p. Results for the tweak-one shift strategy as in Lipton
et al. (2018) can be found in Section A.0.1.
After artificially shifting the label distribution in one of the source and target sets, we then follow
algorithm 1, where we choose the black box predictor h0 to be a two-layer fully connected neural
network trained on (shifted) source dataset. Note that any black box predictor could be employed
here, though the higher the accuracy, the more likely weight estimation will be precise. Therefore,
we use different shifted source data to get (corrupted) black box predictor across experiments. If not
noted, h0 is trained using uniform data.
In order to compute ωb = 1 + θ in Eq. (3), we call a built-in solver to directly solve the low dimensional
problem minθ kCθ - bk2 + ∆C kθk2 where we empirically observer that 0.01 times of the true ∆C
yields in a better estimator on various levels of label shift pre-computed beforehand. It is worth
noting that 0.001 makes the theoretical bound in Lemma. 1 O(1/0.01) times bigger. We thus treat it
as a hyperparameter that can be chosen using standard cross validation methods. Finally, we train
6
Published as a conference paper at ICLR 2019
a classifier on the source samples weighted by ωb , where we use a two-layer fully connected neural
network for MNIST and a ResNet-18 (He et al., 2016) for CIFAR10.
We sample 20 datasets with the label distributions for each shift parameter. to evaluate the empirical
mean square estimation error (MSE) and variance of the estimated weights Ekwb - w k22 and the
predictive accuracy on the target set. We use these measures to compare our procedure with the
black box shift learning method (BBSL) in Lipton et al. (2018). Notice that although KMM methods
(Zhang et al., 2013) would be another standard baseline to compare with, it is not scalable to large
sample size regimes for np , nq above n = 8000 as mentioned by Lipton et al. (2018).
3.1	Weight Estimation and predictive performance for source shift
In this set of experiments on the CIFAR10 dataset, we illustrate our weight estimation and prediction
performance for Tweak-One source shifts and compare it with BBSL. For this set of experiments, we
set the number of data points in both source and target set to 10000 and sample from the two pools
without replacement.
Figure 2 illustrates the weight estimation alongside final classification performance for Minority-Class
source shift of CIFAR10. We created shifts with ρ > 0.5. We use a fixed black-box classifier that is
trained on biased source data, with tweak-one ρ = 0.5. Observe that the MSE in weight estimation is
relatively large and RLLS outperforms BBSL as the number of minority classes increases. As the
shift increases the performance for all methods deteriorates. Furthermore, Figure 2 (b) illustrates
how the advantage of RLLS over the unweighted classifier increases as the shift increases. Across
all shifts, the RLLS based classifier yields higher accuracy than the one based on BBSL. Results for
MNIST can be found in Section A.1.
Figure 2: (a) Mean squared error in estimated weights and (b) accuracy on CIFAR10 for tweak-one
shifted source and uniform target with h0 trained using tweak-one shifted source data.
3.2	Weight estimation and predictive performance for target shift
In this section, we compare the predictive performances between a classifier trained on unweighted
source data and the classifiers trained on weighted loss obtained by the RLLS and BBSL procedure
on CIFAR10. The target set is shifted using the Dirichlet shift with parameters α = [0.01, 0.1, 1, 10].
The number of data points in both source and target set is 10000.
In the case of target shifts, larger shifts actually make the predictive task easier, such that even a
constant majority class vote would give high accuracy. However it would have zero accuracy on
all but one class. Therefore, in order to allow for a more comprehensive performance between
the methods, we also compute the macro-averaged F-1 score by averaging the per-class quantity
2(PreCiSion ∙ recall)/(precision + recall) over all classes. For a class i, precision is the percentage
of correct predictions among all samples predicted to have label i, while recall is the proportion of
correctly predicted labels over the number of samples with true label i. This measure gives higher
weight to the accuracies of minority classes which have no effect on the total accuracy.
Figure 3 depicts the MSE of the weight estimation (a), the corresponding performance comparison on
accuracy (b) and F-1 score (c). Recall that the accuracy performance for low shifts is not comparable
with standard CIFAR10 benchmark results because of the overall lower sample size chosen for the
comparability between shifts. We can see that in the large target shift case for α = 0.01, the F-1
7
Published as a conference paper at ICLR 2019
(a)	(b)	(c)
Figure 3: (a) Mean squared error in estimated weights, (b) accuracy and (c) F-1 score on CIFAR10
for uniform source and Dirichlet shifted target. Smaller α corresponds to bigger shift.
score for BBSL and the unweighted classifier is rather low compared to RLLS while the accuracy is
high. As mentioned before, the reason for this observation and why in Figure 3 (b) the accuracy is
higher when the shift is larger, is that the predictive task actually becomes easier with higher shift.
3.3	Regularized weights in the low sample regime for source shift
In the following, we present the average accuracy of RLLS in Figure 4 as a function of the number of
target samples nq for different values of λ for small nq . Here we fix the sample size in the source set
to np = 1000 and investigate a Minority-Class source shift with fixed p = 0.01 and five minority
classes.
A motivation to use intermediate λ is discussed in Section 2.2, as λ in equation (4) may be chosen
according to θmax , σmin . In practice, since θmax is just an upper bound on the true amount of shift
∣∣θk2, in some cases λ should in fact ideally be 0 When 市~~1——1	1 2 ≤ nq ≤	1	1 2.
θmaχ (σmin - √nq)	kθk2 (σmin - √nq)
Thus for target sample sizes nq that are a little bit above the threshold (depending on the certainty of
the belief hoW close to θmax the norm of the shift is believed to be), it could be sensible to use an
intermediate value λ ∈ (0, 1).
(b)
(a)
(c)
Figure 4: Performance on MNIST for Minority-Class shifted source and uniform target With various
target sample size and λ using (a) better predictor h0 trained on tWeak-one shifted source With
ρ = 0.2, (b) neutral predictor h0 With ρ = 0.5 and (c) corrupted predictor h0 With ρ = 0.8.
Figure 4 suggests that unWeighted samples (red) yield the best classifier for very feW samples nq ,
While for 10 ≤ nq ≤ 500 an intermediate λ ∈ (0, 1) (purple) has the highest accuracy and for
nq > 1000, the Weight estimation is certain enough for the fully Weighted classifier (yelloW) to have
the best performance (see also the corresponding data points in Figure 2). The unWeighted BBSL
classifier is also shoWn for completeness. We can conclude that regularizing the influence of the
estimated Weights alloWs us to adjust to the uncertainty on importance Weights and generalize Well
for a Wide range of target sample sizes.
Furthermore, the different plots in Figure 4 correspond to black-box predictors h0 for Weight
estimation Which are trained on more or less corrupted data, i.e. have a better or Worse conditioned
8
Published as a conference paper at ICLR 2019
confusion matrix. The fully weighted methods with λ = 1 achieve the best performance faster with a
better trained black-box classifier (a), while it takes longer for it to improve with a corrupted one (c).
Furthermore, this reflects the relation between eigenvalue of confusion matrix σmin and target sample
size nq in Theorem 1. In other words, we need more samples from the target data to compensate a
bad predictor in weight estimation. So the generalization error decreases faster with an increasing
number of samples for good predictors.
In summary, our RLLS method outperforms BBSL in all settings for the common image datasets
MNIST and CIFAR10 to varying degrees. In general, significant improvements compared to BBSL
can be observed for large shifts and the low sample regime. A note of caution is in order: comparison
between the two methods alone might not always be meaningful. In particular, there are cases when
the estimator trained on unweighted samples outperforms both RLLS and BBSL. Our extensive
experiments for many different shifts, black box classifiers and sample sizes do not allow for a final
conclusive statement about how weighting samples using our estimator affects predictive results for
real-world data in general, as it usually does not fulfill the label-shift assumptions.
4	Related Work
The covariate and label shift assumptions follow naturally when viewing the data generating process
as a causal or anti-causal model (ScholkoPf et al., 2012): With label shift, the label Y causes the
input X (that is, X is not a causal parent of Y, hence "anti-causal") and the causal mechanism that
generates X from Y is indePendent of the distribution of Y . A long line of work has addressed the
reverse causal setting where X causes Y and the conditional distribution of Y given X is assumed to
be constant. This assumPtion is sensible when there is reason to believe that there is a true oPtimal
maPPing from X to Y which does not change if the distribution of X changes. Mathematically this
scenario corresPonds to the covariate shift assumPtion.
Among the various methods to correct for covariate shift, the majority uses the concePt of imPortance
weights q(x)/p(x) (Zadrozny, 2004; Cortes et al., 2010; Cortes & Mohri, 2014; Shimodaira, 2000),
which are unknown but can be estimated for examPle via kernel embeddings (Huang et al., 2007;
Gretton et al., 2009; 2012; Zhang et al., 2013; Zaremba et al., 2013) or by learning a binary discrimi-
native classifier between source and target (LoPez-Paz & Oquab, 2016; Liu et al., 2017). A minimax
aPProach that aims to be robust to the worst-case shared conditional label distribution between
source and target has also been investigated (Liu & Ziebart, 2014; Chen et al., 2016). Sanderson
& Scott (2014); Ramaswamy et al. (2016) formulate the label shift Problem as a mixture of the
class conditional covariate distributions with unknown mixture weights. Under the Pairwise mutual
irreducibility (Scott et al., 2013) assumPtion on the class conditional covariate distributions, they
dePloy the Neyman-Pearson criterion (Blanchard et al., 2010) to estimate the class distribution q(y)
which also investigated in the maximum mean discrePancy framework (Iyer et al., 2014).
Common issues shared by these methods is that they either result in a massive comPutational burden
for large samPle size Problems or cannot be dePloyed for neural networks. Furthermore, imPortance
weighting methods such as (Shimodaira, 2000) estimate the density (ratio) beforehand, which is a
difficult task on its own when the data is high-dimensional. The resulting generalization bounds
based on imPortance weighting methods require the second order moments of the density ratio
(q(x)/p(x))2 to be bounded, which means the bounds are extremely loose in most cases (Cortes
et al., 2010).
DesPite the wide aPPlicability of label shift, aPProaches with global guarantees in high dimensional
data regimes remain under-exPlored. The correction of label shift mainly requires to estimate the
imPortance weights q(y)/p(y) over the labels which tyPically live in a very low-dimensional sPace.
Bayesian and Probabilistic aPProaches are studied when a Prior over the marginal label distribution is
assumed (Storkey, 2009; Chan & Ng, 2005). These methods often need to exPlicitly comPute the
Posterior distribution of y and suffer from the curse of dimensionality. Recent advances as in LiPton
et al. (2018) have ProPosed solutions aPPlicable large scale data. This aPProach is related to Buck
et al. (1966); Forman (2008); Saerens et al. (2002) in the low dimensional setting but lacks guarantees
for the excess risk.
Existing generalization bounds have historically been mainly develoPed for the case when P = Q
(see e.g. VaPnik (1999); Bartlett & Mendelson (2002); Kakade et al. (2009); Wainwright (2019)).
9
Published as a conference paper at ICLR 2019
Ben-David et al. (2010) provides theoretical analysis and generalization guarantees for distribution
shifts when the H-divergence between joint distributions is considered, whereas Crammer et al. (2008)
proves generalization bounds for learning from multiple sources. For the covariate shift setting,
Cortes et al. (2010) provides a generalization bound when q(x)/p(x) is known which however does
not apply in practice. To the best of our knowledge our work is the first to give generalization bounds
for the label shift scenario.
5	Discussion
In this work, we establish the first generalization guarantee for the label shift setting and propose an
importance weighting procedure for which no prior knowledge of q(y)/p(y) is required. Although
RLLS is inspired by BBSL, it leads to a more robust importance weight estimator as well as general-
ization guarantees in particular for the small sample regime, which BBSL does not allow for. RLLS
is also equipped with a sample-size-dependent regularization technique and further improves the
classifier in both regimes.
We consider this work a necessary step in the direction of solving shifts of this type, although the
label shift assumption itself might be too simplified in the real world. In future work, we plan to also
study the setting when it is slightly violated. For instance, x in practice cannot be solely explained
by the wanted label y, but may also depend on attributes z which might not be observable. In the
disease prediction task for example, the symptoms might not only depend on the disease but also on
the city and living conditions of its population. In such a case, the label shift assumption only holds
in a slightly modified sense, i.e. P(X |Y = y, Z = z) = Q(X|Y = y, Z = z). If the attributes Z are
observed, then our framework can readily be used to perform importance weighting.
Furthermore, it is not clear whether the final predictor is in fact “better” or more robust to shifts
just because it achieves a better target accuracy than a vanilla unweighted estimator. In fact, there
is a reason to believe that under certain shift scenarios, the predictor might learn to use spurious
correlations to boost accuracy. Finding a procedure which can both learn a robust model and achieve
high accuracies on new target sets remains to be an ongoing challenge. Moreover, the current choice
of regularization depends on the number of samples rather than data-driven regularization which is
more desirable.
An important direction towards active learning for the same disease-symptoms scenario is when
we also have an expert for diagnosing a limited number of patients in the target location. Now the
question is which patients would be most "useful" to diagnose to obtain a high accuracy on the
entire target set? Furthermore, in the case of high risk, we might be able to choose some of the
patients for further medical diagnosis or treatment, up to some varying cost. We plan to extend the
current framework to the active learning setting where we actively query the label of certain x’s
(Beygelzimer et al., 2009) as well as the cost-sensitive setting where we also consider the cost of
querying labels (Krishnamurthy et al., 2017).
Consider a realizable and over-parameterized setting, where there exists a deterministic mapping
from x to y, and also suppose a perfect interpolation of the source data with a minimum proper
norm is desired. In this case, weighting the samples in the empirical loss might not alter the trained
classifier (Belkin et al., 2018). Therefore, our results might not directly help the design of better
classifiers in this particular regime. However, for the general overparameterized settings, it remains
an open problem of how the importance weighting can improve the generalization. We leave this
study for future work.
6	Acknowledgement
K. Azizzadenesheli is supported in part by NSF Career Award CCF-1254106. This research has been
conducted when the first author was a visiting researcher at Caltech. Anqi Liu is supported in part
by DOLCIT Postdoctoral Fellowship at Caltech and Caltech’s Center for Autonomous Systems and
Technologies. Fan Yang is supported by the Institute for Theoretical Studies ETH Zurich and the Dr.
Max Rossler and the Walter Haefner Foundation. A. Anandkumar is supported in part by Microsoft
Faculty Fellowship, Google faculty award, Adobe grant, NSF Career Award CCF- 1254106, and
AFOSR YIP FA9550-15-1-0221.
10
Published as a conference paper at ICLR 2019
References
Animashree Anandkumar, Daniel Hsu, and Sham M Kakade. A method of moments for mixture
models and hidden markov models. In Conference on Learning Theory, pp. 33-1, 2012.
Kamyar Azizzadenesheli, Alessandro Lazaric, and Animashree Anandkumar. Reinforcement learning
of pomdps using spectral methods. arXiv preprint arXiv:1602.07764, 2016.
Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463-482, 2002.
Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling modern machine learning
and the bias-variance trade-off. arXiv preprint arXiv:1812.11118, 2018.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from different domains. Machine learning, 79(1-2):151-175, 2010.
Alina Beygelzimer, Sanjoy Dasgupta, and John Langford. Importance weighted active learning. In
Proceedings of the 26th annual international conference on machine learning, pp. 49-56. ACM,
2009.
Gilles Blanchard, Gyemin Lee, and Clayton Scott. Semi-supervised novelty detection. Journal of
Machine Learning Research, 11(Nov):2973-3009, 2010.
AA Buck, JJ Gart, et al. Comparison of a screening test and a reference test in epidemiologic studies.
ii. a probabilistic model for the comparison of diagnostic tests. American Journal of Epidemiology,
83(3):593-602, 1966.
Yee Seng Chan and Hwee Tou Ng. Word sense disambiguation with distribution estimation. In IJCAI,
volume 5, pp. 1010-5, 2005.
Xiangli Chen, Mathew Monfort, Anqi Liu, and Brian D Ziebart. Robust covariate shift regression. In
Artificial Intelligence and Statistics, pp. 1270-1279, 2016.
Corinna Cortes and Mehryar Mohri. Domain adaptation and sample bias correction theory and
algorithm for regression. Theoretical Computer Science, 519:103-126, 2014.
Corinna Cortes, Yishay Mansour, and Mehryar Mohri. Learning bounds for importance weighting.
In Advances in neural information processing systems, pp. 442-450, 2010.
Koby Crammer, Michael Kearns, and Jennifer Wortman. Learning from multiple sources. Journal of
Machine Learning Research, 9(Aug):1757-1774, 2008.
George Forman. Quantifying counts and costs via classification. Data Mining and Knowledge
Discovery, 17(2):164-206, 2008.
David A Freedman. On tail probabilities for martingales. the Annals of Probability, pp. 100-118,
1975.
Arthur Gretton, Alexander J Smola, Jiayuan Huang, Marcel Schmittfull, Karsten M Borgwardt, and
Bernhard Scholkopf. Covariate shift by kernel mean matching. 2009.
Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Scholkopf, and Alexander Smola. A
kernel two-sample test. Journal of Machine Learning Research, 13(Mar):723-773, 2012.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016.
Daniel Hsu, Sham M Kakade, and Tong Zhang. A spectral algorithm for learning hidden markov
models. Journal of Computer and System Sciences, 78(5):1460-1480, 2012.
Jiayuan Huang, Arthur Gretton, Karsten M Borgwardt, Bernhard Scholkopf, and Alex J Smola.
Correcting sample selection bias by unlabeled data. In Advances in neural information processing
systems, pp. 601-608, 2007.
11
Published as a conference paper at ICLR 2019
Arun Iyer, Saketha Nath, and Sunita Sarawagi. Maximum mean discrepancy for class ratio estimation:
Convergence bounds and kernel selection. In International Conference on Machine Learning, pp.
530-538, 2014.
Sham M Kakade, Karthik Sridharan, and Ambuj Tewari. On the complexity of linear prediction: Risk
bounds, margin bounds, and regularization. In Advances in neural information processing systems,
pp. 793-800, 2009.
Akshay Krishnamurthy, Alekh Agarwal, Tzu-Kuo Huang, Hal Daume III, and John Langford. Active
learning for cost-sensitive classification. arXiv preprint arXiv:1703.01014, 2017.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images.
Technical report, Citeseer, 2009.
Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http://yann.
lecun.com/exdb/mnist/.
Zachary C Lipton, Yu-Xiang Wang, and Alex Smola. Detecting and correcting for label shift with
black box predictors. arXiv preprint arXiv:1802.03916, 2018.
Anqi Liu and Brian Ziebart. Robust classification under sample selection bias. In Advances in neural
information processing systems, pp. 37-45, 2014.
Song Liu, Akiko Takeda, Taiji Suzuki, and Kenji Fukumizu. Trimmed density ratio estimation. In
Advances in Neural Information Processing Systems, pp. 4518-4528, 2017.
David Lopez-Paz and Maxime Oquab. Revisiting classifier two-sample tests. arXiv preprint
arXiv:1610.06545, 2016.
Geoffrey McLachlan. Discriminant analysis and statistical pattern recognition, volume 544. John
Wiley & Sons, 2004.
Bernardo Avila Pires and Csaba Szepesvdri. Statistical linear estimation with penalized estimators:
an application to reinforcement learning. arXiv preprint arXiv:1206.6444, 2012.
Harish Ramaswamy, Clayton Scott, and Ambuj Tewari. Mixture proportion estimation via kernel
embeddings of distributions. In International Conference on Machine Learning, pp. 2052-2060,
2016.
Marco Saerens, Patrice Latinne, and Christine Decaestecker. Adjusting the outputs of a classifier to
new a priori probabilities: a simple procedure. Neural computation, 14(1):21-41, 2002.
Tyler Sanderson and Clayton Scott. Class proportion estimation with application to multiclass
anomaly rejection. In Artificial Intelligence and Statistics, pp. 850-858, 2014.
Bernhard Scholkopf, Dominik Janzing, Jonas Peters, Eleni Sgouritsa, Kun Zhang, and Joris Mooij.
On causal and anticausal learning. arXiv preprint arXiv:1206.6471, 2012.
Clayton Scott, Gilles Blanchard, and Gregory Handy. Classification with asymmetric label noise:
Consistency and maximal denoising. In Conference On Learning Theory, pp. 489-511, 2013.
Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-
likelihood function. Journal of statistical planning and inference, 90(2):227-244, 2000.
Amos Storkey. When training and test sets are different: characterizing learning transfer. Dataset
shift in machine learning, pp. 3-28, 2009.
Joel A Tropp. User-friendly tail bounds for sums of random matrices. Foundations of computational
mathematics, 12(4):389-434, 2012.
Vladimir Naumovich Vapnik. An overview of statistical learning theory. IEEE transactions on neural
networks, 10(5):988-999, 1999.
M. J. Wainwright. High-dimensional statistics: A non-asymptotic viewpoint. Cambridge University
Press, 2019.
12
Published as a conference paper at ICLR 2019
Yiming Ying. Mcdiarmid’s inequalities of bernstein and bennett forms. City University of Hong
Kong, 2004.
Bianca Zadrozny. Learning and evaluating classifiers under sample selection bias. In Proceedings of
the twenty-first international conference on Machine learning, pp. 114. ACM, 2004.
Wojciech Zaremba, Arthur Gretton, and Matthew Blaschko. B-test: A non-parametric, low variance
kernel two-sample test. In Advances in neural information processing systems, pp. 755-763, 2013.
KUn Zhang, Bernhard Scholkopf, Krikamol Muandet, and Zhikun Wang. Domain adaptation under
target and conditional shift. In International Conference on Machine Learning, pp. 819-827, 2013.
13
Published as a conference paper at ICLR 2019
A More experimental results
This section contains more experiments that provide more insights about in which settings the
advantage of using RLLS vs. BBSL are more or less pronounced.
A.0. 1 CIFAR10 Experiments under tweak-one shift and Dirichlet shift
Here we compare weight estimation performance between RLLS and BBSL for different types of
shifts including the Tweak-one Shift, for which we randomly choose one class, e.g. i and set p(i) = ρ
while all other classes are distributed evenly. Figure 5 depicts the the weight estimation performance
of RLLS compared to BBSL for a variety of values of ρ and α. Note that larger shifts correspond to
smaller α and larger ρ. In general, one observes that our RLLS estimator has smaller MSE and that
as the shift increases, the error of both methods increases. For tweak-one shift we can additionally
see that as the shift increases, RLLS outperforms BBSL more and more as both in terms of bias and
variance.
(a)	(b)
Figure 5: Comparing MSE of estimated weights using BBSL and RLLS on CIFAR10 with (a)
tweak-one shift on source and uniform target, and (b) Dirichlet shift on source and uniform target. h0
is trained using the same source shifted data respectively.
A.1 MNIST Experiments under Minority-Class source shifts for different
VALUES OF p
In order to show weight estimation and classification performance under different level of label
shifts, we include several additional sets of experiments here in the appendix. Figure 6 shows the
weight estimation error and accuracy comparison under a minority-class shift with p = 0.001. The
training and testing sample size is 10000 examples in this case. We can see that whenever the weight
estimation of RLLS is better, the accuracy is also better, except in the four classes case when both
methods are bad in weight estimation.
(a)
Number of Minority Class
Figure 6: (a) Mean squared error in estimated weights and (b) accuracy on MNIST for minority-class
shifted source and uniform target with p = 0.001.
(b)
Figure 7 demonstrates another case in minority-class shift when p = 0.01. The black-box classifier is
the same two-layers neural network trained on a biased source data set with tweak-one ρ = 0.5. We
observe that when the number of minority class is small like 1 or 2, the weight estimation is similar
14
Published as a conference paper at ICLR 2019
between two methods, as well as in the classification accuracy. But when the shift get larger, the
weights are worse and the performance in accuracy decreases, getting even worse than the unweighted
classifier.
(a)
(b)
Figure 7: (a) Mean squared error in estimated weights and (b) accuracy on MNIST for minority-class
shifted source and uniform target with p = 0.01, with h0 trained on tweak-one shifted source data.
(a)
Figure 8 illustrates the weight estimation alongside final classification performance for Minority-Class
source shift of MNIST. We use 1000 training and testing data. We created large shifts of three or
more minority classes with p = 0.005. We use a fixed black-box classifier that is trained on biased
source data, with tweak-one ρ = 0.5. Observe that the MSE in weight estimation is relatively large
and RLLS outperforms BBSL as the number of minority classes increases. As the shift increases the
performance for all methods deteriorates. Furthermore, Figure 8 (b) illustrates how the advantage
of RLLS over the unweighted classifier increases as the shift increases. Across all shifts, the RLLS
based classifier yields higher accuracy than the one based on BBSL.
(b)
Figure 8: (a) Mean squared error in estimated weights and (b) accuracy on MNIST for minority-class
shifted source and uniform target with p = 0.005, with h0 trained on tweak-one shifted source data.
A.2 CIFAR10 Experiment under Dirichlet source shifts
Figure 9 illustrates the weight estimation alongside final classification performance for Dirichlet
source shift of CIFAR10 dataset. We use 10000 training and testing data in this experiment, following
the way we generate shift on source data. We train h0 with tweak-one shifted source data with
ρ = 0.5. The results show that importance weighting in general is not helping the classification in
this relatively large shift case, because the weighted methods, including true weights and estimated
weights, are similar in accuracy with the unweighted method.
A.3 MNIST Experiment under Dirichlet Shift with low target sample size
We show the performance of classifier with different regularization λ under a Dirichlet shift with
α = 0.5 in Figure 10. The training has 5000 examples in this case. We can see that in this low target
sample case, λ = 1 only take over after several hundreds example, while some λ value between 0
and 1 outperforms it at the beginning. Similar as in the paper, we use different black-box classifier
that is corrupted in different levels to show the relation between the quality of black-box predictor
and the necessary target sample size. We use biased source data with tweak-one ρ = 0, 0.2, 0.6 to
train the black-box classifier. We see that we need more target samples for the fully weighted version
λ = 1 to take over for a more corrupted black-box classifier.
15
Published as a conference paper at ICLR 2019
(b)
(a)
Figure 9: (a) Mean squared error in estimated weights and (b) accuracy on CIFAR10 for Dirichlet
shifted source and uniform target, with h∩ trained on tweak-one shifted source data.
AoPJnoo< θ6pjθλv
Figure 10: Performance on MNIST for Dirichlet shifted source and uniform target with various target
sample size and λ using (a) better predictor, (b) neutral predictor and (c) corrupted predictor.
B Proofs
B.1 Proof of Lemma 1
L	E	C ，∙	∕C∙	CC	，∙…C、	1	J ,*	1	,∙	/C、	.，、
From Thm. 3.4 in (Pires & SZePeSvan, 2012) We know that for θ as defined in equation (3), if With
1 1 ∙1 ∙ .	/F ,r UIl 介 —II JA	Fllr 7 I I JA FFF ・ F,	1 T
Probability at least 1 - δ, kC - C k2 ≤ ∆C and kb - bk2 ≤ ∆b hold simultaneously, then
Υ(θb) ≤ inf {Υ(θ0) +2∆Ckθ0kα}+2∆b.
θ0 ∈Rk
(7)
where we use the shorthand Υ(θ0) = kCθ0 - bk2.
We can get an upper bound on the right hand side of (7) is the infimum by simply choosing a feasible
θ0 = θ. We then have kCθ - bk2 = 0 and hence
iθn0f{Υ(θ0)+2∆Ckθ0k2}≤2∆Ckθk2
as a consequence,
ʌ
ʌ
ʌ
Υ(θ)=kCθ-bk2=kC θ-θ k2≤2∆Ckθk2+2∆b
ʌ
ʌ
Since kC θ - θ k2 ≥ σmin(C)kθ - θk2 by definition of the minimum singular value, we thus have
1
kθ - θ∣∣2 ≤ σ--(2∆ckθk2 + 2∆b)
Let us first notice that
bh = qh - C 1 = qh - ph
16
Published as a conference paper at ICLR 2019
The mathematical definition of the finite sample estimates Ch, bh (in matrix and vector representation)
with respect to some hypothesis h are as follows
1
[Ch]ij = (1 - β)n	工 Ih(X)=i,y=j
p (x,y)∈Dp
11
[bh](i) = m T Ih(X)=i-(1 — β)	T	Ih(X)=i
(x,y)∈Dq	p (x,y)∈Dpweight
where m = |Dq | and I is the indicator function. Ch , bh can equivalently be expressed with the
population over P for Ch and over Q for bh respectively. We now use the following concentration
Lemmas to bound the estimation errors of Cb, bb where we drop the subscript h for ease of notation.
Lemma 2 (Concentration of measurement matrix C) For finite sample estimate C we have
方	2log(2k∕δ)	S 2log(2k∕δ)
kC -Ck2 ≤ 3(1-β)np +V(1 — β)np
with probability at least (1 - δ).
Lemma 3 (Concentration of label measurements) For the finite sample estimate b with respect to
any hypothesis h it holds that
kbbh - bh k2 ≤
√log(2) ∖ √(1 - β)np
√log(1∕δ) + √log(1∕δ)
√nq
2
with probability at least 1 - 2δ.
By Lemma. 2 for concentration of C and Lemma. 3 for concentration of b we now have with
probability at least 1 - δ
kθb - θk2
≤ 1 (2∣∣θ∣∣2log(2k∕δ) I	/l8log(4k∕δ)
一σmin1	(1 一 β)np	2 y (1 一 β)np
+
/36log(2∕δ)
V	nq
/36log(2∕δ)
V (1 - β)np
which, considering that O( √n) dominates O(n), yields the statement of the Lemma 1.
B.2 Proof of Lemma 2
We prove this lemma using the theorem 1.4[Matrix Bernstein] and Dilations technique from Tropp
(2012). We can rewrite Ch = E(χ,y)〜P [eh(x)e>] Where e(i) is the one-hot-encoding of index i.
Consider a finite sequence {Ψ(i)} of independent random matrices with dimension k. By dilations,
lets construct another sequence of self-adjoint random matrices of {Ψ(i)} of dimension 2k, such that
for all i
Ψe(i)
0	Ψ(i)
Ψ(i)>	0
therefore,
Ψe(i)2
Ψ(i)Ψ(i)>	0
0 Ψ(i)>Ψ(i)
(8)
1 ∙ 1	1 . ♦ Il S' / ∙∖ Il	I I ,ʃ, / ■ ∖ I I El 1∙1 . ∙	1	.	1 .	.1 ∙ ∙ . ∙ 1	C	1
which results in kΨ(i)k2 = kΨ(i)k2. The dilation technique translates the initial sequence of random
matrices to the sequence of random self-adjoint matrices where we can apply the Matrix Bernstein
theorem which states that, for a finite sequence of i.i.d. self-adjoint matrices Ψ(i), such that, almost
surely ∀i, E hΨe(i)i = 0 and kΨe(i)k ≤ R, then for all t ≥ 0,
k1XX ψ (i)k ≤ Rl0gy∕δ) + r2%2 log(2k∕δ)
17
Published as a conference paper at ICLR 2019
with probability at least 1 - δ where %2 := kE hΨe2 (i)i k2, ∀i which is also %2 = kE Ψ2(i) k2, ∀i
due to Eq. 8. Therefore, thanks to the dilation trick and theorem 1.4[Matrix Bernstein] in Tropp
(2012),
k t XX Ψ(i)k≤ Rof≡ + J
i=1
with probability at least 1 - δ.
2%2 log(2k∕δ)
t
Now, by plugging in Ψ(i) = eh(x(i))ey>(i) - C, we have E Ψe(i) = 0. Together with kΨe(i)k ≤ 2 as
well as %2 = kE Ψ2(i) k2 = 1 and setting t = n, we have
方	2log(2k∕δ)	S 2log(2k∕δ)
kC - Ck2 ≤ 3(1-β)n + V (1-β)n
B.3 Proof of Lemma 3
The proof of this lemma is mainly based on a special case of and appreared at proposition 6 in
Azizzadenesheli et al. (2016), Lemma F.1 in Anandkumar et al. (2012) and Proposition 19 of Hsu
et al. (2012).
Analogous to the previous section we can rewrite bh = E(x,y)∈Q[eh(x)] - E(x,y)∈P[eh(x)] where e(i)
is the one-hot-encoding of index i. Note that (dropping the subscript h) we have
kbbh - bhk2 ≤ kqbh - qhk2 + kpbh - phk2
We now bound both estimates of probability vectors separately.
Consider a fixed multinomial distribution characterized with probability vector of ς ∈ ∆k-ι where
∆k-1 is a k - 1 dimensional simplex. Further, consider t realization of this multinomial distribution
{ς(i)}it=1 where ς(i) is the one-hot-encoding of the i’th sample. Consider the empirical estimate
mean of this distribution through empirical average of the samples; b = t P(i)tς(i), then
kb - ς k≤√r 严>
tt
with probability at least 1 - δ.
By plugging in ς = qh, b = b with t = n and finally {ς(i)}n= 1 = {eh(x(i))}(i)nq and equivalently
for ph we obtain;
∣∣b	a U J PlOg(10 , PlOg(10、J 1	,	1 ʌ
kbh - bhk2 ≤ (p(1-β)np +	) + (p(1-β)np + √nq)
with probability at least 1 - 2δ, therefore;
b k ≤	2 P PogW + P⅞Wδ)
h PlOg(2) 1P(1- β)np √nq
resulting in the statement in the Lemma 3.
B.4 Proof of Theorem 1
5 T	. . t . ∙	. t Λ	IlC /G ∖	r> / 7 ⅛∖ I ɪʌ t t∙ .∙	t F, J	1
We want to ultimately bound |L(hwb) - L(h?)|. By addition and subtraction we have
L(bhwb) - L(h?)
L(hwb ) - Ln (hwb ) + Ln (hwb ) - Ln (hwb ; wb)
(b)
(a)
+ Ln(bhwb; wb) - Ln (h ; wb) + Ln (h ; wb) - Ln(h ) + Ln (h ) - L(h )
} X} X}
≤0	(a)	(b)
(9)
.	C	1	1	/	CGTT	ZX...	...	…、♦ T
where n = βnp and we used optimality of hwb . Here (a) is the weight estimation error and (b) is the
finite sample error.
18
Published as a conference paper at ICLR 2019
Uniform law for bounding (b) We bound (b) using standard results for uniform laws for uniformly
bounded functions which holds since ∣∣w∣∣∞ ≤ d∞(q∣∣p) and ∣∣'k∞ ≤ 1. Since ∣w(y)'(h(x),y)∣ ≤
d∞(q∣∣p), ∀x, y ∈ X ×Y ,by deploying the McDiarmid,s inequality We then obtain that
sup ∣Ln(h) - L(h)∣ ≤ 2Rn(G(', H)) + d∞(q∣∣p)
h∈H
where G(', H) = {gh(χ, y) = w(y)'(h(χ), y) : h ∈ H} and the Rademacher complexity is defined
as Rn(G)= EX(i),Y(i)~Pιi∈[n] [Eσ小i∈[n] n [suph∈H Pi =1 σiw(yi)'(xi, h(Ui))]] .
of the hypothesis class H (see for example Percy Liang notes on Statistical Learning Theory and
chapter 4 in Wainwright (2019))
Bounding term (a) Remember that k = |Y | is the cardinality of the finite domain of Y , or the
n
number of classes. Let us define ' ∈ Rk with 'j = Ei=I Iy(i)=j'(y(i), h(χ(i))). Notice that by
definition ∣∣'∣ι ≤ n and ∣∣'∣∞ ≤ n from which it follows by Hoelder S inequality that ∣∣'∣2 ≤ n.
Furthermore, we slightly abuse notation and use w to denote the k-dimensional vector with wi = w(i).
Therefore, for all h we have via the Cauchy Schwarz inequality that
1n
ILn (h; W)-Ln((V, w)| = |- E(W(y(i)) — w(y(i)))'(h(x(i)),y(i))l
n i=1
j=1
1
≤ n∣w - wk2ke∣∣2 ≤ IlW - w∣∣2
^ .. ............. ..^ ..
≤ ∣λθb-θ∣2 ≤ (1 -λ)∣θ∣2+λ∣θb-θ∣2	(10)
It then follows by Lemma 1 that
sup ILn (V; W) - Ln(V; Wb)I ≤ (1 - λ)∣θ∣2
h∈H
O λ ɪ ((1^12)1/^1 + ∖∕Wr∖「)!
σmin	(1 - β)np	(1 - β)np	nq
Lemma 4 (McDiarmid-Doob-Freedman-Rademacher) For a given A hypothesis class H, a set
G(', H) = {gh(x, y) = w(y)'(h(x), y) : h ∈ H}, under n data points and loss function ' we have
sup ∣Ln(h) — L(V)I ≤ 2R(G(',H)) +
h∈H
with probability at least 1 - δ
2d∞(q∣∣p)log(2∕δ)
ι	/2 d(q∣∣p)log(2∕δ)
n
n
Plugging both bounds back into equation (9) concludes the proof of the theorem.
B.5 Proof of Lemma 4
With a bit abuse of notation let’s restate the empirical loss with known importance weights instead on
the random variables {(Xi, Yi)}1n
1n
Ln(V) = n ∑w(Yj')'(Yj,h(Xj))
We further define a ghost data set {(Xi0, Yi0)}1n and the corresponding ghost loss;
1n
Ln(V) = - EW(YG'(Yj,h(Xj)
j=1
19
Published as a conference paper at ICLR 2019
Let’s define a random variable Gn := suph∈H Ln(h) - L(h). This random variable is the key to
derive the tight generalization bound in Lemma 4.
This random variable has the following properties;
E[Gn] =E sup Ln(h) - E [L0n(h)]
h∈H
Which we can rewrite as
E [Gn] =E supE hLn(h) -L0n(h){(Xi,Yi)}1ni
h∈H
and swapping the sup with the expectation
E [Gn] ≤E E sup Ln(h) -L0n(h){(Xi,Yi)}1n
h∈H
We can remove the condition with law of iterated conditional expectation and have expectation on
both of the data sets;
E[Gn] ≤E sup Ln(h) -L0n(h)
h∈H
we further open the expression up;
1n
E[Gn] ≤ E sup- Ewi'(h(XMYi)- w0'0(h(X0),Yi0)
h∈H n i	i	i i
In the following we use the usual symmetrizing technique through Rademacher variables {ξi }1n . Each
ξi is a uniform random variable either 1 or -1. Therefore since '(h(X0),Y0) - '0(h(X0), Y0) is a
symmetric random variable we have
E [Gn] ≤ E
1n
hUH - X ξi [w(YMh(Xi),γo-w*0(hx),γ0)]
where the expectation is also over the Rademacher variables. After propagation sup
E [Gn] ≤ E
1n	1n
hUH n X ξiw(γ≡(Xi)，Yi)+hUH n X
-ξiw(Y0)'0(h(X0),Y0)
By propagating the expectation and again symmetry in the Rademacher variable we have
E [Gn] ≤ 2E sUp
1n
h.H - X
ξiw(Yi)'(h(Xi),Yi)
2R(G(', H))
where the right hand side is two times the Rademacher complexity of class G(', H). Consider a
sequence of Doob Martingale and filtration (Uj, Fj) defined on some probability space (Ω, F,Pr);
n
Uj= E sup- X w(K)'(h(Xi),Yi)∣{(Xi,Yi)}1
h∈H n i
and the corresponding Martingale difference;
Dj := Uj - Uj-1
In the following we show that each |Dj | is bounded above.
n
Dj=E hUH n X W(Y≡(Xi)，Yok(Xi,匕阳-E
n
hUH - X W(Y^⑹占川(Xi ,匕)}1-1
≤ max E
xj,yj
n
hUH nX W(Y≡Xi),W(Xi,匕)}1-1
, xj , yj
-n
-mine hUHnXW(Yo'(h(Xi),Yi)I{(Xi,Yi)}1	,xj,yj
20
Published as a conference paper at ICLR 2019
Let’s define xjmax, yjmax as the solution to the maximization and xjmin , yjmin the solution to the
minimization, therefore,
n
Dj ≤E hUHnXW(YiMh(Xi)Mk(XiM}1-1,，严,，严
E sup
h∈H
1n
-	E sup - X w(Yi)'(h(Xi), Yi) I{(Xi, Yi)}i-1,xmin, yjmin
1 Xw(Yi)'(h(Xi),Yi) + w(yjmin)'(h(χmin),yjmin) - w(yjmin)'(h(χmin),yjmin)^ ∣{(xi,yi)}1-1 ,χmax,yjmax
E
1n	I
-	E sup- X W(Yw, Yi) ∣ {(Xi, Yi)}1-1,χmin, yjmin
h∈H n i	1 j j
sup (1 Xw(Yi)'(h(Xi),Yi) + w(yjmax)'(h(χmax),yjmax) - w(yjmin)'(h(χmin),yjminζj ∣{(xi,yi)}1-1,χmin,yjmin
n
-	E sup- X W(Yw, Yi) ∣ {(Xi, Yi)}1-1,χmin, yjmin
h∈H n i	1 j j
≤ 1sup∣w(ymax)'(h(xmax),ymax) - w(ymin)'(h(xmin),ymin)∣ ≤ d∞?1P)
The same way We can bound -Dj. Therefore the absolute value each Dj is bounded by d∞*llp). In
the following we bound the conditional second moment, E Dj2 |Fj-1 ;
E
/
∖2
n
n
E huH n XW(Yi)'(h(Xi),w∣{(Xi,匕比
{z^
(a0)
n
-HhUH n X W(Yi)'(h(Xi),κ)∣{(Xi,Yi)}IT
}|
{z^
(b0)
∣∣{(Xi,Yi)}j1-1
I
∖
i
}
/
Let’s construct an event Cj the event that a0 is bigger than b0, and also Cj0 its compliment. Therefore,
for the E Dj2|Fj-1 we have
n
E E huHnXW(Yi)'(h(Xi),K)∣{(Xi,匕比
1n	∣
-E sup- X W(Yi)'(h(Xi),Yi)∣{(Xi,Yi)}1-1
h∈H n i	1
n
+ E E sup- X W(Yi)'(h(Xi),匕)∣{(Xi,Yi)}1
h∈H n i	1
n
-E sup- X W(Yi)'(h(Xi),Yi)∣{(Xi,Yi)}1-1
h∈H n i	1
∣∣∣{(Xi,Yi)}j1-1,Cj
P(Cj|Fj-1)
∣{(Xi,Yi)}1-1,Cj P(CjIFj-1)
(11)
21
Published as a conference paper at ICLR 2019
For the firs term in Eq. 11 after again introducing ghost variables X0 , Y 0 we have the following upper
bound
1n	1
sup - X W(Yi)'(h(Xi), Yi) + — sup W(Yj )'(h(Xj ),Yj )∣{(Xi,Yi)}1
h∈H n	n h∈H	1
i6=j
n
-E sup- X w(Yi)'(h(Xi),Yi)∖{(Xi,Yi)}Γγ
h∈H n i	1
∖{(Xi,Yi)}iT1,Cj# P(CjIFj-ι)
-n	-	-	∖
≤ E(E sup- X w(Yi)'(h(Xi),Yi) + — w(Y)'(h(X0 ),Y) + — SUp W(Yj )'(h(Xj ),Yj )∖{(Xi,Yi)}1
h∈H n i6=j	n	nh∈H
-E
-n	∖
huH - X W(Y0'(心),匕)\{(XiM}1-1
∖∖∖{(Xi,Yi)}j1-1,Cj
P(Cj|Fj-1)
-n	∖	-
huH - X W(Y≡Xi),Yok(Xi,匕)}1-]+ n 跷 W(Y )`(h(Xj)，Yj)
n
-E sup- X W(Yi)'(h(Xi),Yi)∖{(Xi,Yi)}Γγ
h∈H n i	1
∖∖∖{(Xi,Yi)}j1-1,Cj
≤E (-huHW(X)'(h(Xj)，Yj)) \{区，匕)}1-1，CjP(Cj")
≤E〕(- huH W(X )'(h(Xj ),Y- ))2\{(Xi,匕比T
P(Cj|Fj-1)
P(CjFj-I) ≤ d(n2p)P(CjIFj-1)
So far We have that the first term in Eq. 11 is bounded by d(n2p). Now for the second term We have
the following upper bound;
n
E E sup- X W(Yi)'(h(Xi),Yi)∖{(Xi,Yi)}1-1
h∈H n i	1
n
- EbUH n XW(Y≡(Xi),K)∖{(Xi,匕比
∖∖∖{(Xi, Yi)}j1-1, Cj0 #P(Cj0 IFj-1)
-n	-	∖
≤ E E sup- X W(Yi)'(h(Xi),Yi) + -sup W(Yj )'(h(Xj ),Yj )∖{(Xi,Yi)}1-1
h∈H n	n h∈H
i6=j
-E
n
sup- X W(Yi)'(h(Xi),Yi)∖{(Xi,Yi)}Γr
h∈H n	1
i6=j
≤ (E [-huHW(X)'(h(Xj),Yj)\{(χi，γi)}1-1
≤ (E -W(Yj)∖{(Xi,Yi)}jι-1
∖∖∖{(Xi,Yi)}j1-1,Cj0
Therefore, since d(q IIp) ≥ -
E [D2∣Fj-l] ≤ 普P(Cj IFj-I) + JP(CjIFj-1) ≤ ¥
For the first inequality, We used the fact that the loss is Within [0, -] and the second one is from Eq. 12.
Since the first term in RHS is (b0), therefore, second moment of each Dj ∣Fj∙-1 is bounded by 2d(nllp).
22
Published as a conference paper at ICLR 2019
Therefore for the Doob Martingale sequence of Dj we have |Dj | ≤ d∞nqllp) as well as
Pn Dj∖Fj-ι ≤ d(qnp). Using the Freedman's inequality Freedman (1975), we have
P (X Dj = Gn - E [Gn] ≥ α) ≤ exp (- 2( d(q||p) + αd∞(q∣∣p)))
Moreover, if we multiply each loss with -1, it results in hypothesis class of -H which has the same
Rademacher complexity as H, due the symmetric Rademacher random variable. Let Gn denote the
same quantity as Gn but on -H. We use this slack variable in order to bound the absolute value of
Gn . Therefore
P(Gn ≥E[Gn] + ) ≤exp
≤ exp
€2
2( d(q||P) + e
€2
2( d(q||P) + e
卜九丁
d∞(qUP)
d∞(qUP)
≤ δ∕2
—
—
n
)
n
)
and the same bound for Gn . By solving it for € and δ we have
|Gn| ≤ 2R(G(', H)) + 2d∞⑷Ip)Iog(20 + \卜2d(q"M)
nn
Note: A few days prior to the camera ready submission, we realized that a quite similar analysis and
statement to Theorem 4 is also studied in Ying (2004).
B.6 Generalization for finite hypothesis classes
For finite hypothesis classes, one may bound (b) in (9) using Bernstein’s inequality.
Webound (b) by first noting that W(Y)'(Y, h(X)) satisfies the Bernstein conditions SothatBernStein's
inequality holds
EP[w(Y)] = 1,	EP[w(Y)2] = d(q||p), σP2(w(Y)) = d(q||p) - 1	(12)
by definition. Because we assume ` ≤ 1, we directly have
EPw(Y)2l2(Y,h(X)) ≤ EPw(Y)2 = d(q||p)	(13)
Since we have a bound on the second moment of weighted loss while its first moment is L(h) we can
apply Bernstein's inequality to obtain for any fixed h that
2(d(q∣∣p)-L(h)2 )log( δ)
n
ILn(h) -L(h)I≤ 2d∞(qlFog(2) +J
3n
For the uniform law for finite hypothesis classes make the union bound on all the hypotheses;
sup ILn(h) -L(h)I ≤ 2d∞(吗log") + S…]*
h∈H	3n	n
The second moment of the importance weighted loss EP ω (Y)2 `2 (h(X), Y) , given a h ∈ H0 can
be bounded for general α ≥ 0, potentially leading to smaller values than d(q||p):
23
Published as a conference paper at ICLR 2019
k
X p(i)
i
q⑶
p2(i)
EX 〜p(X∣Y=i)
X q⑶ 1 * q⑶ O-I EX~p(X∣Y=i)
i
(14)
where the first inequality follows from Holder,s inequality, the second one follows from Jensen's
inequality and the fact that the loss is in [0, 1] as well as the fact that the exponentiation function is
convex in this region. Moreover, since 1 + 1 ≥ 1 and upper bound for the loss square, l(∙, ∙)2 ≤ 1,
then;
1
α k
X q(i)Eχ〜PΙY=i ['2(h(X),i)]1-α
i
which gives bound on the second moment of weighted loss.
B.7 Slight drift from the Label Shift
Drift in label shift assumption: If the label shift approximation is slightly violated, we expect
the generalizing bound to deviate from the statement in the Theorem. 1. Define de(q||p) :=
Ε(x,y)〜Q 口1 - p(X∣Y) ∣] as the deviation form label shift constraint which is zero in label shift
setting.
Remark 1 (Drift in Label shift assumption) If the label shift assumption slightly violates, for the
true importance weights ω(x, y) := P(Cry, the RLLS, with high probability generalizes as;
L(bhwb, ω)	- L(h ; ω) ≤	G (np,	δ) + (1 -	λ)	kθk2	+ λθ (np,	nq, kθk2, δ) + 4 (1 -	λ)	de(q||p)
Consider the case where the Label shift assumption is slightly violated, i.e., for each covariate and
label, We have p(x∣y) ` q(x∣y), resulting importance weight ω(x, y) := P(Xy) for each covariate
and label. Similar to decomposing in Eq. 9, we have
,^
,^
,^
,^
,^
,^

L(hwb; ω) - L(h?; ω) = L(hwb; ω) - L(hwb) + L(hwb) - Ln(hwb) + Ln(hwb) - Ln(hwb; wb)
|
^{z
(c)
} X--------------
(b)
}|
^{z
(a)
}
+ Ln(bhwb; wb) - Ln (h ; wb) + Ln (h ; wb) - Ln(h ) + Ln (h ) - L(h ) + L(h ) - L(h ; ω)
|
{z^
≤0
}|
{z^
(a)
} '----------{---------} '-----------{-------
(b)	(c)
(15)
}
where the desired excess risk is defined with respect to ω. The differences between Eq. 15 and Eq. 9
are in a new term (c) as well as term (a). The term (b) remains untouched.
24
Published as a conference paper at ICLR 2019
Bound on term (c) For any h, the two contributing components in (c), i.e., L(h; ω) and L(h) are
as follows;
L(h) = E(χ,γ)〜P [w(Y)'(Y, h(X))], and L(h; ω)= E(χ,γ)〜Q ['(Y, h(X))] = E(χ,γ)〜P [ω(X, Y)'(Y, h(X))]
For their deviation we have
L(h; ω) - L(h) = E(χ,γ)~p [(ω(X, Y) - W(Y)) '(Y, h(X))]
一	∖(q(X,Y)	q(Y)储“*γ"
=E(X，Y 卜P Kp(XYy- p(Y)) '(Y, h(X))_
=E(X,Y)〜Q [(1 - PXYy) '(Y, h(X))1 ≤ de(q∣lp) := E(X,Y)~Q 1| 1 - PXYy I
q(X |Y)	q(X|Y)
Where in the last inequality we deploy Cauchy Schwarz inequality as well as loss is in [0, 1] and hold
for h ∈ H. It is worth noting that the expectation in de(q∣∣p) is with respect to Q and does not blow
up if the supports of P and Q do not match
Bound on term (a) For any h ∈ H, similar to the derivation in Eq. 10 we have
∣Ln(h) - Ln (h; wb)∣ ≤ kwb - wk2 ≤ kλθb - θk2 ≤ (1 - λ)kθk2 + λkθb - θk2
The previous weight estimation analysis does not directly hold for this case where the label shift
is slightly violated, but with a few modification we provide an upper-bound on the error. Given a
classifier h0
qh0(Y=i) =	q(h(X) = i∣Y = j)q(j)
j
(q(h0(X) = i∣Y = j) - p(h0(X) = i∣Y = j)) q(j) +	p(h0(X) = i∣Y = j)q(j)
jj
(q(h0(X) = i∣Y = j) - p(h0(X) = i∣Y = j)) q(j) +	p(h0(X) = i,Y = j)wj
jj
e(X,Y )〜Q
p(h0 (X) = i) 1 -
p(X∣Y) ʌ
q(X∣Y P
+	p(h0 (X) = i, Y = j)wj
j
where p(h0 (X) = i) = q(h0 (X) = i), resulting;
qh0 = be + Cw
where we drop the h0 in both be and C . Both the confusion matrix C and the label distribution qh0
on the target for the black box hypothesis h0 are unknown and we are instead only given access to
finite sample estimates Cbh0 ,
qbh0 . Similar to previous analysis we have
b := q - C1 = Cθ
with corresponding finite sample quantity bb = qb - Cb1. Similarly to the analysis when there was
no violation in label shift assumption, we have Υ(θ0) = kCθ0 - b - bek2 and the solution to Eq. 3
satisfies;
Υ(θb) ≤ inf {Υ(θ0) + 2∆Ckθ0kα} + 2∆b + 2kbek2.	(16)
θ0 ∈Rk
We can simplify the upper bound by setting θ0 = θ. We then have
Υ(θb) = kCθb-b-bek2 = kC θb-θ k2 ≤ 2∆Ckθk2 + 2∆b + 2kbek2 ≤ 2∆Ckθk2+2∆b+2de(q∣∣p)
resulting in
1
kθ - θk2 ≤ --- (2δc kθk2 + 2δb + 2de(q∣ Ip))
σmin
25