Published as a conference paper at ICLR 2019
Global-to-local Memory Pointer Networks
for Task-Oriented Dialogue
Chien-Sheng Wu**, Richard Socher^ & Caiming Xiong^
^Salesforce Research
{rsocher,cxiong}@salesforce.com
*The Hong Kong University of Science and Technology
jason.wu@connect.ust.hk
Ab stract
End-to-end task-oriented dialogue is challenging since knowledge bases are usu-
ally large, dynamic and hard to incorporate into a learning framework. We propose
the global-to-local memory pointer (GLMP) networks to address this issue. In our
model, a global memory encoder and a local memory decoder are proposed to
share external knowledge. The encoder encodes dialogue history, modifies global
contextual representation, and generates a global memory pointer. The decoder
first generates a sketch response with unfilled slots. Next, it passes the global
memory pointer to filter the external knowledge for relevant information, then in-
stantiates the slots via the local memory pointers. We empirically show that our
model can improve copy accuracy and mitigate the common out-of-vocabulary
problem. As a result, GLMP is able to improve over the previous state-of-the-
art models in both simulated bAbI Dialogue dataset and human-human Stanford
Multi-domain Dialogue dataset on automatic and human evaluation.
1	Introduction
Task-oriented dialogue systems aim to achieve specific user goals such as restaurant reservation
or navigation inquiry within a limited dialogue turns via natural language. Traditional pipeline
solutions are composed of natural language understanding, dialogue management and natural lan-
guage generation (Young et al., 2013; Wen et al., 2017), where each module is designed separately
and expensively. In order to reduce human effort and scale up between domains, end-to-end dia-
logue systems, which input plain text and directly output system responses, have shown promising
results based on recurrent neural networks (Zhao et al., 2017; Lei et al., 2018) and memory net-
works (Sukhbaatar et al., 2015). These approaches have the advantages that the dialogue states
are latent without hand-crafted labels and eliminate the needs to model the dependencies between
modules and interpret knowledge bases (KB) manually.
However, despite the improvement by modeling KB with memory network (Bordes & Weston, 2017;
Madotto et al., 2018), end-to-end systems usually suffer from effectively incorporating external KB
into the system response generation. The main reason is that a large, dynamic KB is equal to a
noisy input and hard to encode and decode, which makes the generation unstable. Different from
chit-chat scenario, this problem is especially harmful in task-oriented one, since the information in
KB is usually the expected entities in the response. For example, in Table 1 the driver will expect
to get the correct address to the gas station other than a random place such as a hospital. Therefore,
pointer networks (Vinyals et al., 2015) or copy mechanism (Gu et al., 2016) is crucial to successfully
generate system responses because directly copying essential words from the input source to the
output not only reduces the generation difficulty, but it is also more like a human behavior. For
example, in Table 1, when human want to reply others the Valero’s address, they will need to “copy”
the information from the table to their response as well.
Therefore, in the paper, we propose the global-to-local memory pointer (GLMP) networks, which
is composed of a global memory encoder, a local memory decoder, and a shared external knowl-
edge. Unlike existing approaches with copy ability (Gulcehre et al., 2016; Gu et al., 2016; Eric &
* All work was done while the first author was an intern at Salesforce Research.
1
Published as a conference paper at ICLR 2019
Table 1: An in-car assistant example on the navigation domain. The left part is the KB information
and the right part is the conversation between a driver and our system.
Point of interest (poi)	Distance	Trafic	Poi type	Address	Driver	I need gas
Toms house	3 miles	heavy	friend’s house	580 Van Ness Ave	System	GLMP: There is a gas station locally Valero is 4 miles away Gold: Valero is 4 miles away
CoUpa	2 miles	moderate	coffee or tea place	394 Van Ness Ave		
Panda express	2 miles	no	Chinese restaurant	842 Arrowhead Way	Driver	What is the address ?
Stanford express Care	5 miles	no	hospital	214 El Camino Real	System	GLMP: Valero is located at 200 Alester Ave Gold: Valero is at 200 Alester Ave
VaIero	4 miles	heavy	gas station	200 AIeSter AVe		
Starbucks	1 miles	heavy	coffee or tea place	792 Bedoin St	Driver	Thank you!
Manning, 2017; Madotto et al., 2018), which the only information passed to decoder is the encoder
hidden states, our model shares the external knowledge and leverages the encoder and the external
knowledge to learn a global memory pointer and global contextual representation. Global memory
pointer modifies the external knowledge by softly filtering words that are not necessary for copying.
Afterward, instead of generating system responses directly, the local memory decoder first uses a
sketch RNN to obtain sketch responses without slot values but sketch tags, which can be considered
as learning a latent dialogue management to generate dialogue action template. Then the decoder
generates local memory pointers to copy words from external knowledge and instantiate sketch tags.
We empirically show that GLMP can achieve superior performance using the combination of global
and local memory pointers. In simulated out-of-vocabulary (OOV) tasks in the bAbI dialogue
dataset (Bordes & Weston, 2017), GLMP achieves 92.0% per-response accuracy and surpasses ex-
isting end-to-end approaches by 7.5% in full dialogue. In the human-human dialogue dataset (Eric
et al., 2017), GLMP is able to surpass the previous state of the art on both automatic and human
evaluation, which further confirms the effectiveness of our double pointers usage.
2	GLMP MODEL
Our model 1 is composed of three parts: global memory encoder, external knowledge, and local
memory decoder, as shown in Figure 1(a). The dialogue history X = (x1, . . . , xn) and the KB
information B = (b1 , . . . , bl) are the input, and the system response Y = (y1, . . . , ym) is the
expected output, where n, l, m are the corresponding lengths. First, the global memory encoder uses
a context RNN to encode dialogue history and writes its hidden states into the external knowledge.
Then the last hidden state is used to read the external knowledge and generate the global memory
pointer at the same time. On the other hand, during the decoding stage, the local memory decoder
first generates sketch responses by a sketch RNN. Then the global memory pointer and the sketch
RNN hidden state are passed to the external knowledge as a filter and a query. The local memory
pointer returns from the external knowledge can copy text from the external knowledge to replace
the sketch tags and obtain the final system response.
2.1	External Knowledge
Our external knowledge contains the global contextual representation that is shared with the encoder
and the decoder. To incorporate external knowledge into a learning framework, end-to-end memory
networks (MN) are used to store word-level information for both structural KB (KB memory) and
temporal-dependent dialogue history (dialogue memory), as shown in Figure 1(b). In addition,
the MN is well-known for its multiple hop reasoning ability (Sukhbaatar et al., 2015), which is
appealing to strengthen copy mechanism.
Global contextual representation. In the KB memory module, each element bi ∈ B is represented
in the triplet format as (Subject, Relation, Object) structure, which is a common format used to
represent KB nodes (Miller et al., 2016; Eric et al., 2017). For example, the KB in the Table 1 will
be denoted as {(Tom’s house, distance, 3 miles), ..., (Starbucks, address, 792 Bedoin St)}. On the
other hand, the dialogue context X is stored in the dialogue memory module, where the speaker and
temporal encoding are included as in Bordes & Weston (2017) like a triplet format. For instance,
the first utterance from the driver in the Table 1 will be denoted as {($user, turn1, I), ($user, turn1,
need), ($user, turn1, gas)}. For the two memory modules, a bag-of-word representation is used
as the memory embeddings. During the inference time, we copy the object word once a memory
position is pointed to, for example, 3 miles will be copied if the triplet (Toms house, distance, 3
miles) is selected. We denote Object(.) function as getting the object word from a triplet.
1https://github.com/salesforce
2
Published as a conference paper at ICLR 2019
(a) Block diagram
Figure 1: The proposed (a) global-to-local memory pointer networks for task-oriented dialogue
systems and the (b) external knowledge architecture.
Knowledge read and write. Our external knowledge is composed of a set of trainable embedding
matrices C = (C1,..., C K+1), where Ck ∈ RIV l×demb, K is the maximum memory hop in the
MN, |V | is the vocabulary size and demb is the embedding dimension. We denote memory in the
external knowledge as M = [B; X] = (m1, . . . , mn+l), where mi is one of the triplet components
mentioned. To read the memory, the external knowledge needs a initial query vector q 1 . Moreover,
it can loop over K hops and computes the attention weights at each hop k using
pik = Softmax((qk)Tcik),	(1)
where cik = B(Ck (mi)) ∈ Rdemb is the embedding in ith memory position using the embedding
matrix Ck, qk is the query vector for hop k, and B(.) is the bag-of-word function. Note that pk ∈
Rn+l is a soft memory attention that decides the memory relevance with respect to the query vector.
Then, the model reads out the memory ok by the weighted sum over ck +1 and update the query
vector qk+1. Formally,
ok =Xpikcik+1,	qk+1 =qk+ok.	(2)
i
2.2	Global Memory Encoder
In Figure 2(a), a context RNN is used to model the sequential dependency and encode the context
X . Then the hidden states are written into the external knowledge as shown in Figure 1(b). After-
ward, the last encoder hidden state serves as the query to read the external knowledge and get two
outputs, the global memory pointer and the memory readout. Intuitively, since it is hard for MN
architectures to model the dependencies between memories (Wu et al., 2018), which is a serious
drawback especially in conversational related tasks, writing the hidden states to the external knowl-
edge can provide sequential and contextualized information. With meaningful representation, our
pointers can correctly copy out words from external knowledge, and the common OOV challenge
can be mitigated. In addition, using the encoded dialogue context as a query can encourage our
external knowledge to read out memory information related to the hidden dialogue states or user
intention. Moreover, the global memory pointer that learns a global memory distribution is passed
to the decoder along with the encoded dialogue history and KB information.
Context RNN. A bi-directional gated recurrent unit (GRU) (Chung et al., 2014) is used to encode
dialogue history into the hidden states H = (he1, . . . , he1), and the last hidden state hen is used to
query the external knowledge as the encoded dialogue history. In addition, the hidden states H are
written into the dialogue memory module in the external knowledge by summing up the original
memory representation with the corresponding hidden states. In formula,
cik	= cik + hemi if mi ∈ X and ∀k	∈	[1,K+	1],	(3)
Global memory pointer.	Global memory pointer G = (g1,	. .	. ,gn+l)	is a vector	containing real
values between 0 and 1. Unlike conventional attention mechanism that all the weights sum to one,
3
Published as a conference paper at ICLR 2019
Figure 2: The proposed (a) global memory encoder and the (b) local memory decoder architecture.
each element in G is an independent probability. We first query the external knowledge using hen
until the last hOp, and instead Of applying the SOftmaX functiOn as in (1), we perfOrm an inner
prOduct fOllOwed by the SigmOid functiOn. The memOry distributiOn we Obtained is the glObal
memOry pOinter G, which is passed tO the decOder. TO further strengthen the glObal pOinting ability,
we add an auXiliary lOss tO train the glObal memOry pOinter as a multi-label classificatiOn task. We
shOw in the ablatiOn study that adding this additiOnal supervisiOn dOes imprOve the perfOrmance.
Lastly, the memOry readOut qK+1 is used as the encOded KB infOrmatiOn.
In the auXiliary task, we define the label Glabel = (g1l , . . . , gnl +l) by checking whether the Object
wOrds in the memOry eXists in the eXpected system respOnse Y . Then the glObal memOry pOinter is
trained using binary crOss-entrOpy lOss Lossg between G and Glabel . In fOrmula,
gi=Sigmoid((qK)TciK), gil= 01 iofthOebrwjeicste(mi) ∈Y
Lossg = -Pin=+1l[gil × log gi + (1 - gil) × log (1 - gi)].
(4)
2.3	Local memory decoder
Given the encOded dialOgue histOry hen, the encOded KB infOrmatiOn qK+1, and the glObal memOry
pOinter G, Our lOcal memOry decOder first initializes its sketch RNN using the cOncatenatiOn Of hen
and qK+1, and generates a sketch respOnse that eXcludes slOt values but includes the sketch tags.
FOr eXample, sketch RNN will generate “@poi is @distance away”, instead Of “Starbucks is 1 mile
away.” At each decOding time step, the hidden state Of the sketch RNN is used fOr twO purpOses:
1) predict the neXt tOken in vOcabulary, which is the same as standard sequence-tO-sequence (S2S)
learning; 2) serve as the vectOr tO query the eXternal knOwledge. If a sketch tag is generated, the
glObal memOry pOinter is passed tO the eXternal knOwledge, and the eXpected Output wOrd will be
picked up frOm the lOcal memOry pOinter. Otherwise, the Output wOrd is the wOrd that generated by
the sketch RNN. FOr eXample in Figure 2(b), a @pOi tag is generated at the first time step, therefOre,
the wOrd Starbucks is picked up frOm the lOcal memOry pOinter as the system Output wOrd.
Sketch RNN. We use a GRU tO generate a sketch respOnse Y s = (y1s, . . . , yms ) withOut real slOt
values. The sketch RNN learns tO generate a dynamic dialOgue actiOn template based On the encOded
dialOgue (hen) and KB infOrmatiOn (qK+1). At each decOding time step t, the sketch RNN hidden
state htd and its Output distributiOn Ptvocab are defined as
hd = GRU(C 1(yS-ι), hd-ι), PFb = SOftmaX(Whd)
We use the standard cross-entropy loss to train the sketch RNN, we define Lossv as.
m
Lossv = X-log(Ptvocab(yts)).
t=1
(5)
(6)
4
Published as a conference paper at ICLR 2019
We replace the slot values in Y into sketch tags based on the provided entity table. The sketch tags
ST are all the possible slot types that start with a special token, for example, @address stands for
all the addresses and @distance stands for all the distance information.
Local memory pointer. Local memory pointer L = (L1, . . . , Lm) contains a sequence of pointers.
At each time step t, the global memory pointer G first modify the global contextual representation
using its attention weights,
cik = cik × gi,	∀i ∈ [1, n + l] and ∀k ∈ [1, K + 1],
(7)
and then the sketch RNN hidden state htd queries the external knowledge. The memory attention
in the last hop is the corresponding local memory pointer Lt , which is represented as the memory
distribution at time step t. To train the local memory pointer, a supervision on top of the last hop
memory attention in the external knowledge is added. We first define the position label of local
memory pointer Llabel at the decoding time step t as
Llabel = max(z)	if ∃z s.t. yt = Obj ect(mz),
t n + l + 1 otherwise.
(8)
The position n+l+1 is a null token in the memory that allows us to calculate loss function even if yt
does not exist in the external knowledge. Then, the loss between L and Llabel is defined as
m
Lossl = X - log(Lt(Lltabel)).	(9)
t=1
Furthermore, a record R ∈ Rn+l is utilized to prevent from copying same entities multiple times.
All the elements in R are initialized as 1 in the beginning. During the decoding stage, if a mem-
ory position has been pointed to, its corresponding position in R will be masked out. During the
inference time, yt is defined as
arg max(Ptvocab)
O bj ect(marg max(LtR)
if arg max(Ptvocab) 6∈ ST,
) otherwise,
(10)
where is the element-wise multiplication. Lastly, all the parameters are jointly trained by mini-
mizing the weighted-sum of three losses (α, β, γ are hyper-parameters):
Loss = αLossg + βLossv + γLossl
(11)
3	Experiments
3.1	Datasets
We use two public multi-turn task-oriented dialogue datasets to evaluate our model: the bAbI di-
alogue (Bordes & Weston, 2017) and Stanford multi-domain dialogue (SMD) (Eric et al., 2017).
The bAbI dialogue includes five simulated tasks in the restaurant domain. Task 1 to 4 are about call-
ing API calls, modifying API calls, recommending options, and providing additional information,
respectively. Task 5 is the union of tasks 1-4. There are two test sets for each task: one follows the
same distribution as the training set and the other has OOV entity values. On the other hand, SMD is
a human-human, multi-domain dialogue dataset. It has three distinct domains: calendar scheduling,
weather information retrieval, and point-of-interest navigation. The key difference between these
two datasets is, the former has longer dialogue turns but the regular user and system behaviors,
the latter has few conversational turns but variant responses, and the KB information is much more
complicated.
3.2	Training details
The model is trained end-to-end using Adam optimizer (Kingma & Ba, 2015), and learning rate
annealing starts from 1e-3 to 1e-4. The number of hop K is set to 1,3,6 to compare the performance
difference. The weights α, β, γ summing up the three losses are set to 1. All the embeddings are
initialized randomly, and a simple greedy strategy is used without beam-search during the decoding
stage. The hyper-parameters such as hidden size and dropout rate are tuned with grid-search over
5
Published as a conference paper at ICLR 2019
Table 2: Per-response accuracy and completion rate (in the parentheses) on bAbI dialogues. GLMP
achieves the least out-of-vocabulary performance drop. Baselines are reported from Query Reduc-
tion Network (Seo et al., 2017), End-to-end Memory Network (Bordes & Weston, 2017), Gated
Memory Network (Liu & Perez, 2017), Point to Unknown Word (Gulcehre et al., 2016), and
Memory-to-Sequence (Madotto et al., 2018).
Task	QRN	MN	GMN	S2S+Attn	Ptr-Unk	Mem2Seq	GLMPKI	GLMP K3	GLMP K6
T1	99.4(-)	99.9 (99.6)	100 (100)	100 (100)	100(100)	100 (100)	100(100)	100 (100)	100 (100)
T2	99.5(-)	100 (100)	100 (100)	100 (100)	100 (100)	100 (100)	100(100)	100 (100)	100 (100)
T3	74.8 (-)	74.9 (2.0)	74.9 (0)	74.8 (0)	85.1 (19.0)	94.7 (62.1)	96.3 (75.6)	96.0 (69.4)	96.0 (68.7)
T4	57.2 (-)	59.5 (3.0)	57.2 (0)	57.2 (0)	100 (100)	100 (100)	100(100)	100 (100)	100 (100)
T5	99.6 (-)	96.1 (49.4)	96.3 (52.5)	98.4 (87.3)	99.4 (91.5)	97.9 (69.6)	99.2 (88.5)	99.0 (86.5)	99.2 (89.7)
T1 oov	83.1 (-)	72.3 (0)	82.4 (0)	81.7 (0)	92.5 (54.7)	94.0 (62.2)	100 (100)	100 (100)	99.3 (95.9)
T2 oov	78.9 (-)	78.9 (0)	78.9 (0)	78.9 (0)	83.2 (0)	86.5 (12.4)	100 (100)	100 (100)	99.4 (94.6)
T3 oov	75.2 (-)	74.4 (0)	75.3 (0)	75.3 (0)	82.9 (13.4)	90.3 (38.7)	95.5 (65.7)	96.7 (72.9)	95.9 (67.7)
T4 oov	56.9(-)	57.6 (0)	57.0 (0)	57.0 (0)	100 (100)	100 (100)	100(100)	100 (100)	100 (100)
T5 oov	67.8 (-)	65.5 (0)	66.7 (0)	65.7 (0)	73.6 (0)	84.5 (2.3)	92.0 (21.7)	91.0 (17.7)	91.8 (21.4)
Table 3: In SMD dataset, our model achieves highest BLEU score and entity F1 score over baselines,
including previous state-of-the-art result from Madotto et al. (2018). (Models with * are reported
from Eric et al. (2017), where the problem is simplified to the canonicalized forms.)
Automatic Evaluation
	Rule-Based*	KVR*	S2S	S2S + Attn	Ptr-Unk	Mem2Seq	GLMP K1	GLMP K3	GLMP K6
BLEU	6.6	13.2	8.4	9.3	-83-	12.6	-13.83-	14.79	12.37
Entity F1	43.8	48.0	10.3	19.9	-22.7-	33.4	-57.25-	59.97	53.54
Schedule F1	613	62.9	9.7	23.4	-26.9-	49.3	-68.74-	69.56	69.38
Weather F1	39.5	47.0	14.1	25.6	26.7	32.8	60.87	62.58	55.89
Navigation F1	40.4	41.3	7.0	10.8	14.9	20.0	48.62	52.98	43.08
Human Evaluation
	Mem2Seq	GLMP	Human
Appropriate	3.89	4TΓ5	4.6
Humanlike		3.80		4.02		4.54	
the development set (per-response accuracy for bAbI Dialogue and BLEU score for the SMD). In
addition, to increase model generalization and simulate OOV setting, we randomly mask a small
number of input source tokens into an unknown token. The model is implemented in PyTorch and
the hyper-parameters used for each task and the dataset statistics are reported in the Appendix.
3.3	Results
bAbI Dialogue. In Table 2, we follow Bordes & Weston (2017) to compare the performance
based on per-response accuracy and task-completion rate. Note that for utterance retrieval methods,
such as QRN, MN, and GMN, cannot correctly recommend options (T3) and provide additional
information (T4), and a poor generalization ability is observed in OOV setting, which has around
30% performance difference in Task 5. Although previous generation-based approaches (Ptr-Unk,
Mem2Seq) have mitigated the gap by incorporating copy mechanism, the simplest cases such as
generating and modifying API calls (T1, T2) still face a 6-17% OOV performance drop. On the
other hand, GLMP achieves a highest 92.0% task-completion rate in full dialogue task and surpasses
other baselines by a big margin especially in the OOV setting. No per-response accuracy loss for
T1, T2, T4 using only the single hop, and only decreases 7-9% in task 5.
Stanford Multi-domain Dialogue. For human-human dialogue scenario, we follow previous
dialogue works (Eric et al., 2017; Zhao et al., 2017; Madotto et al., 2018) to evaluate our system
on two automatic evaluation metrics, BLEU and entity F1 score 2. As shown in Table 3, GLMP
achieves a highest 14.79 BLEU and 59.97% entity F1 score, which is a slight improvement in BLEU
but a huge gain in entity F1. In fact, for unsupervised evaluation metrics in task-oriented dialogues,
we argue that the entity F1 might be a more comprehensive evaluation metric than per-response
accuracy or BLEU, as shown in Eric et al. (2017) that humans are able to choose the right entities
but have very diversified responses. Note that the results of rule-based and KVR are not directly
comparable because they simplified the task by mapping the expression of entities to a canonical
form using named entity recognition and linking 3.
2BLEU: multi-bleu.perl script; Entity F1: Micro-average over responses.
3For example, they compared in "@Poi is @PoLdistance away,” instead of “Starbucks is Ijnile away”
6
Published as a conference paper at ICLR 2019
Table 4: Ablation study using single hop model.
	bAbI Dialogue OOV Per-response Accuracy					SMD Entity F1
	T1	T2	T3	T4	T5	An
GLMP	-100D-	100 (-)	95.5(-)	100 (-)	92.0 (-)	-57.25(-)
GLMP w/o H	90.4 (-9.6)	85.6 (-14.4)	95.4 (-0.1)	100 (-0)	86.2 (-5.3)	47.96 (-9.29)
GLMP w/o G	100 (-0)	91.7 (-8.3)	95.5(-0)	100 (-0)	92.4 (+0.4)	45.78 (-11.47)
Moreover, human evaluation of the generated responses is reported. We compare our work with
previous state-of-the-art model Mem2Seq 4 and the original dataset responses as well. We randomly
select 200 different dialogue scenarios from the test set to evaluate three different responses. Ama-
zon Mechanical Turk is used to evaluate system appropriateness and human-likeness on a scale from
1 to 5. As the results shown in Table 3, we see that GLMP outperforms Mem2Seq in both measures,
which is coherent to previous observation. We also see that human performance on this assessment
sets the upper bound on scores, as expected. More details about the human evaluation are reported
in the Appendix.
Ablation Study. The contributions of the global memory pointer G and the memory writing of
dialogue history H are shown in Table 4. We compare the results using GLMP with K = 1 in bAbI
OOV setting and SMD. GLMP without H means that the context RNN in the global memory encoder
does not write the hidden states into the external knowledge. As one can observe, our model without
H has 5.3% more loss in the full dialogue task. On the other hand, GLMP without G means that
we do not use the global memory pointer to modify the external knowledge, and an 11.47% entity
F1 drop can be observed in SMD dataset. Note that a 0.4% increase can be observed in task 5, it
suggests that the use of global memory pointer may impose too strong prior entity probability. Even
if we only report one experiment in the table, this OOV generalization problem can be mitigated by
increasing the dropout ratio during training.
Visualization and Qualitative Evaluation. Analyzing the attention weights has been frequently
used to interpret deep learning models. In Figure 3, we show the attention vector in the last hop
for each generation time step. Y-axis is the external knowledge that we can copy, including the KB
information and the dialogue history. Based on the question “what is the address?” asked by the
driver in the last turn, the gold answer and our generated response are on the top, and the global
memory pointer G is shown in the left column. One can observe that in the right column, the final
memory pointer successfully copy the entity chevron in step 0 and its address 783 Arcadia Pl in step
3 to fill in the sketch utterance. On the other hand, the memory attention without global weighting is
reported in the middle column. One can find that even if the attention weights focus on several point
of interests and addresses in step 0 and step 3, the global memory pointer can mitigate the issue as
expected. More dialogue visualization and generated results including several negative examples
and error analysis are reported in the Appendix.
4	Related Works
Task-oriented dialogue systems. Machine learning based dialogue systems are mainly explored
by following two different approaches: modularized and end-to-end. For the modularized sys-
tems (Williams & Young, 2007; Wen et al., 2017), a set of modules for natural language under-
standing (Young et al., 2013; Chen et al., 2016), dialogue state tracking (Lee & Stent, 2016; Zhong
et al., 2018), dialogue management (Su et al., 2016), and natural language generation (Sharma et al.,
2016) are used. These approaches achieve good stability via combining domain-specific knowledge
and slot-filling techniques, but additional human labels are needed. On the other hand, end-to-end
approaches have shown promising results recently. Some works view the task as a next utterance re-
trieval problem, for examples, recurrent entity networks share parameters between RNN (Wu et al.,
2017), query reduction networks modify query between layers (Seo et al., 2017), and memory net-
works (Bordes & Weston, 2017; Liu & Perez, 2017; Wu et al., 2018) perform multi-hop design
to strengthen reasoning ability. In addition, some approaches treat the task as a sequence genera-
tion problem. Lei et al. (2018) incorporates explicit dialogue states tracking into a delexicalized
sequence generation. Serban et al. (2016); Zhao et al. (2017) use recurrent neural networks to gen-
erate final responses and achieve good results as well. Although it may increase the search space,
4Mem2Seq code is released and we achieve similar results stated in the original paper.
7
Published as a conference paper at ICLR 2019
Delexicalized Generation: @poi is at @address
Final Generation: chevron is at 783_arcadia_pl
Gold: 783_arcadia_pl is the address for chevron gas-station
Po∣nterw∕o G
Final Pointer
[B30_a ImanoNn] address taljjan —
[chlnese-restaurant] pol-type taljjan —
[no-trafflc] trafflcjnfo tal-pan
[6-mlles] distance taljjan —
[tal-pan] pol chlnese-restauraπt no-trafflc 6-mlles —
[63B_amherst_st] address slgona-ftiπners-market —
[grocery-store] pol-type slgona_farmers_martet —
[heavy_trafflc] trafflcjπfo slgona-farmer5-marlffit —
[l-mlles] distance slgona-fa rmer5-martet —
[slgona-farmer5-market] pol grocery_store heavy-trafflc l-mlles —
[657-ames-ave] address the-clemenl^hotel —
[rest-stop] pol-type the-clemenl^hotel —_____________________________
[no-trafflc] trafflcjnħ> the-clemeπt-hotel —
[4-mlles] distance the-clement-hotel —
[the-clement-hotel] pol rest-stop no_trafflc 4-mlles —
[5671-barr1 ngerjstreet] address home —
[home] pol-type home —
[heavy_trafflc] trafflcjnfo home —
[6-mlles] distance home —
[home] pol home heavy_trafflc 6-mlles —
[B64-almanorJn] addressjacks-house —
[friends-hoιtse] pol-type jacks-house —
[no-trafflc] trafflc_lnfojacks_house —
[5-mlles] distance Jacks-house —
[Jacks-house] pol frlends_house no-trafflc 5-mlles —
[3B3_unlverslty_ave] address town_and_country —
[shopplng,eenter] pol-type town_and_country —
[no-trafflc] trafflcjπfo town-and-couπtry —
[5-mlles] distance town_and_country —
[town-and-country] pol ShOPPIngLCenter no-tn>fflc 5-mlles ______
[7B3_arc8dla_pl] address chevron -
[gas-statlon] POLtyPe chevron —
[moderate-tn>fflc] trafflcjπfo chevron 一
[5-mlles] distance chevron —
[chevron] pol gasjstatlon moderate_trafflc 5-mlles —
what —
gasjstatlon —
are —
here —
good -
I -
please —
pick —
the —
quickest —
route —
to —
get -
there —
and —
avoid —
all —
heavy-trafflc —
-I -
taking —
—
to —I
chevron —
what —
is
the —
address -
G
Figure 3: Memory attention visualization in the SMD navigation domain. Left column is the global
memory pointer G, middle column is the memory pointer without global weighting, and the right
column is the final memory pointer.
these approaches can encourage more flexible and diverse system responses by generating utterances
token-by-token.
Pointer network. Vinyals et al. (2015) uses attention as a pointer to select a member of the input
source as the output. Such copy mechanisms have also been used in other natural language pro-
cessing tasks, such as question answering (Dehghani et al., 2017; He et al., 2017), neural machine
translation (Gulcehre et al., 2016; Gu et al., 2016), language modeling (Merity et al., 2017), and
text summarization (See et al., 2017). In task-oriented dialogue tasks, Eric & Manning (2017) first
demonstrated the potential of the copy-augmented Seq2Seq model, which shows that generation-
based methods with simple copy strategy can surpass retrieval-based ones. Later, Eric et al. (2017)
augmented the vocabulary distribution by concatenating KB attention, which at the same time in-
creases the output dimension. Recently, Madotto et al. (2018) combines end-to-end memory net-
work into sequence generation, which shows that the multi-hop mechanism in MN can be utilized to
improve copy attention. These models outperform utterance retrieval methods by copying relevant
entities from the KBs.
Others. Zhao et al. (2017) proposes entity indexing and Wu et al. (2018) introduces recorded
delexicalization to simplify the problem by record entity tables manually. In addition, our approach
utilized recurrent structures to query external memory can be viewed as the memory controller
8
Published as a conference paper at ICLR 2019
in Memory augmented neural networks (MANN) (Graves et al., 2014; 2016). Similarly, memory
encoders have been used in neural machine translation (Wang et al., 2016) and meta-learning appli-
cations (Kaiser et al., 2017). However, different from other models that use a single matrix represen-
tation for reading and writing, GLMP leverages end-to-end memory networks to perform multiple
hop attention, which is similar to the stacking self-attention strategy in the Transformer (Vaswani
et al., 2017).
5 Conclusion
In the work, we present an end-to-end trainable model called global-to-local memory pointer net-
works for task-oriented dialogues. The global memory encoder and the local memory decoder are
designed to incorporate the shared external knowledge into the learning framework. We empirically
show that the global and the local memory pointer are able to effectively produce system responses
even in the out-of-vocabulary scenario, and visualize how global memory pointer helps as well. As
a result, our model achieves state-of-the-art results in both the simulated and the human-human dia-
logue datasets, and holds potential for extending to other tasks such as question answering and text
summarization.
References
Antoine Bordes and Jason Weston. Learning end-to-end goal-oriented dialog. International Con-
ference on Learning Representations, abs/1605.07683, 2017.
Yun-Nung Chen, Dilek Hakkani-Tur, Jianfeng Gao, and Li Deng. End-to-end memory networks
with knowledge carryover for multi-turn spoken language understanding. 2016.
Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation of
gated recurrent neural networks on sequence modeling. NIPS Deep Learning and Representation
Learning Workshop, 2014.
Mostafa Dehghani, Sascha Rothe, Enrique Alfonseca, and Pascal Fleury. Learning to attend, copy,
and generate for session-based query suggestion. In Proceedings of the 2017 ACM on Conference
on Information and Knowledge Management, CIKM '17, pp. 1747-1756, New York, NY, USA,
2017. ACM. ISBN 978-1-4503-4918-5. doi: 10.1145/3132847.3133010. URL http://doi.
acm.org/10.1145/3132847.3133010.
Mihail Eric and Christopher Manning. A copy-augmented sequence-to-sequence architecture gives
good performance on task-oriented dialogue. In Proceedings of the 15th Conference of the
European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers,
pp. 468-473, Valencia, Spain, April 2017. Association for Computational Linguistics. URL
http://www.aclweb.org/anthology/E17-2075.
Mihail Eric, Lakshmi Krishnan, Francois Charette, and Christopher D. Manning. Key-value retrieval
networks for task-oriented dialogue. In Proceedings of the 18th Annual SIGdial Meeting on
Discourse and Dialogue, pp. 37-49. Association for Computational Linguistics, 2017. URL
http://aclweb.org/anthology/W17-5506.
Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. CoRR, 2014.
Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-
Barwinska, Sergio Gomez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou,
et al. Hybrid computing using a neural network with dynamic external memory. Nature, 538
(7626):471-476, 2016.
Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. Li. Incorporating copying mechanism in
sequence-to-sequence learning. In Proceedings of the 54th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers), pp. 1631-1640, Berlin, Germany, Au-
gust 2016. Association for Computational Linguistics. URL http://www.aclweb.org/
anthology/P16-1154.
9
Published as a conference paper at ICLR 2019
Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati, Bowen Zhou, and Yoshua Bengio. Pointing the
unknown words. In Proceedings of the 54th Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers), pp. 140-149, Berlin, Germany, August 2016. As-
sociation for Computational Linguistics. URL http://www.aclweb.org/anthology/
P16-1014.
Shizhu He, Cao Liu, Kang Liu, and Jun Zhao. Generating natural answers by incorporating copying
and retrieving mechanisms in sequence-to-sequence learning. In Proceedings of the 55th Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 199-
208, Vancouver, Canada, July 2017. Association for Computational Linguistics. URL http:
//aclweb.org/anthology/P17-1019.
Lukasz Kaiser, Ofir Nachum, Aurko Roy, and Samy Bengio. Learning to remember rare events.
International Conference on Learning Representations, 2017.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. International
Conference on Learning Representations, 2015.
Sungjin Lee and Amanda Stent. Task lineages: Dialog state tracking for flexible interaction. In
Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,
pp. 11-21, 2016.
Wenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun Ren, Xiangnan He, and Dawei Yin. Sequicity:
Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures. In
Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers), volume 1, pp. 1437-1447, 2018.
Fei Liu and Julien Perez. Gated end-to-end memory networks. In Proceedings of the 15th Confer-
ence of the European Chapter of the Association for Computational Linguistics: Volume 1, Long
Papers, pp. 1-10, Valencia, Spain, April 2017. Association for Computational Linguistics. URL
http://www.aclweb.org/anthology/E17-1001.
Andrea Madotto, Chien-Sheng Wu, and Pascale Fung. Mem2seq: Effectively incorporating
knowledge bases into end-to-end task-oriented dialog systems. In Proceedings of the 56th An-
nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp.
1468-1478. Association for Computational Linguistics, 2018. URL http://aclweb.org/
anthology/P18-1136.
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture
models. International Conference on Learning Representations, 2017.
Alexander Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Jason
Weston. Key-value memory networks for directly reading documents. In Proceedings of the
2016 Conference on Empirical Methods in Natural Language Processing, pp. 1400-1409, Austin,
Texas, November 2016. Association for Computational Linguistics. URL https://aclweb.
org/anthology/D16-1147.
Abigail See, Peter J. Liu, and Christopher D. Manning. Get to the point: Summarization
with pointer-generator networks. In Proceedings of the 55th Annual Meeting of the Asso-
ciation for Computational Linguistics (Volume 1: Long Papers), pp. 1073-1083, Vancouver,
Canada, July 2017. Association for Computational Linguistics. URL http://aclweb.org/
anthology/P17-1099.
Minjoon Seo, Sewon Min, Ali Farhadi, and Hannaneh Hajishirzi. Query-reduction networks for
question answering. International Conference on Learning Representations, 2017.
Iulian Vlad Serban, Alessandro Sordoni, Yoshua Bengio, Aaron C Courville, and Joelle Pineau.
Building end-to-end dialogue systems using generative hierarchical neural network models. In
AAAI, pp. 3776-3784, 2016.
Shikhar Sharma, Jing He, Kaheer Suleman, Hannes Schulz, and Philip Bachman. Natural language
generation in dialogue using lexicalized and delexicalized data. International Conference on
Learning Representations, 2016.
10
Published as a conference paper at ICLR 2019
Pei-Hao Su, Milica Gasic, Nikola Mrksic, Lina Rojas-Barahona, Stefan Ultes, David Vandyke,
Tsung-Hsien Wen, and Steve Young. On-line active reward learning for policy optimisation in
spoken dialogue systems. Association for Computational Linguistics, 2016.
Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. End-to-end memory networks. In Advances
in neural information processing systems, pp. 2440-2448, 2015.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Eukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Infor-
mation Processing Systems, pp. 6000-6010, 2017.
Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. In C. Cortes, N. D. Lawrence,
D. D. Lee, M. Sugiyama, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 28, pp. 2692-2700. Curran Associates, Inc., 2015. URL http://papers.nips.
cc/paper/5866-pointer-networks.pdf.
Mingxuan Wang, Zhengdong Lu, Hang Li, and Qun Liu. Memory-enhanced decoder for neural
machine translation. In Proceedings of the 2016 Conference on Empirical Methods in Natural
Language Processing, pp. 278-286, Austin, Texas, November 2016. Association for Computa-
tional Linguistics. URL https://aclweb.org/anthology/D16-1027.
Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Lina Maria Rojas-Barahona, Pei hao Su, Stefan
Ultes, David Vandyke, and Steve J. Young. A network-based end-to-end trainable task-oriented
dialogue system. In EACL, 2017.
Jason D Williams and Steve Young. Partially observable markov decision processes for spoken
dialog systems. Computer Speech & Language, 21(2):393-422, 2007.
Chien-Sheng Wu, Andrea Madotto, Genta Winata, and Pascale Fung. End-to-end recurrent entity
network for entity-value independent goal-oriented dialog learning. In Dialog System Technology
Challenges Workshop, DSTC6, 2017.
Chien-Sheng Wu, Andrea Madotto, Genta Winata, and Pascale Fung. End-to-end dynamic query
memory network for entity-value independent task-oriented dialog. In 2018 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6154-6158, April 2018.
Steve Young, Milica Gasic, Blaise Thomson, and Jason D Williams. PomdP-based statistical spoken
dialog systems: A review. Proceedings of the IEEE, 101(5):1160-1179, 2013.
Tiancheng Zhao, Allen Lu, Kyusong Lee, and Maxine Eskenazi. Generative encoder-decoder mod-
els for task-oriented spoken dialog systems with chatting capability. In Proceedings of the 18th
Annual SIGdial Meeting on Discourse and Dialogue, pp. 27-36. Association for Computational
Linguistics, August 2017. URL http://aclweb.org/anthology/W17-5505.
Victor Zhong, Caiming Xiong, and Richard Socher. Global-locally self-attentive dialogue state
tracker. In Association for Computational Linguistics, 2018.
11
Published as a conference paper at ICLR 2019
A	Tables
A.1 Training parameters
Table 5: Selected hyper-parameters in each dataset for different hops. The values is the embedding
dimension and the GRU hidden size, and the values between parenthesis is the dropout rate. For all
the models we used learning rate equal to 0.001, with a decay rate of 0.5.
	T1	T2	T3	T4	T5	SMD
GLMP K1	64 (0.1)	64 (0.3)	64 (0.3)	64 (0.7)	128 (0.3)	128 (0.2)
GLMP K3	64 (0.3)	64 (0.3)	64 (0.3)	64 (0.7)	128 (0.1)	128 (0.2)
GLMP K6	64 (0.3)	64 (0.3)	64 (0.5)	64 (0.5)	128 (0.1)	128 (0.3)
A.2 Dataset Statistics
Table 6: Dataset statistics for 2 datasets.
Task	1	2	3	4	5		SMD			
						Calendar	Weather	Navigation
Avg. User turns	-4-	6.5	6.4	3.5	12.9	2.6		
Avg. Sys turns	-6-	9.5	9.9	3.5	18.4	26		
Avg. KB results	-0-	-0-	24	-7-	23.7	66∏		
Avg. Sys words	6.3	6.2	7.2	5.7	6.5	86		
Max. Sys words	9	9	9	8	9	87		
Nb. Slot Types		7						6	4	5
Nb. Distinct Slot values	-					79	65	140
Vocabulary	3747					1601		
Train dialogues	1000					2425		
Val dialogues	1000					302		
Test dialogues	1000 + 1000 OOV					304		
Total Nb. Dialogues	4000	4000	4000	4000	4000	1034	997	1000
A.3 Human Evaluation
Figure 4: Appropriateness and human-likeness scores according to 200 dialogue scenarios.
Appropriateness
5: Correct grammar, correct logic, correct dialogue flow, and correct entity provided
12
Published as a conference paper at ICLR 2019
4: Correct dialogue flow, logic and grammar but has slightly mistakes in entity provided
3: Noticeable mistakes about grammar or logic or entity provided but acceptable
2: Poor grammar, logic and entity provided
1: Wrong grammar, wrong logic, wrong dialogue flow, and wrong entity provided
Human-Likeness (Naturalness)
5: The utterance is 100% like what a person will say
4: The utterance is	75%	like	what	a person	will	say
3: The utterance is	50%	like	what	a person	will	say
2: The utterance is	25%	like	what	a person	will	say
1: The utterance is	0% like what a	person will say
B Error Analysis
For bAbI dialogues, the mistakes are mainly from task 3, which is recommending restaurants based
on their rating from high to low. We found that sometimes the system will keep sending those
restaurants with the higher score even if the user rejected them in the previous turns. On the other
hand, SMD is more challenging for response generation. First, we found that the model makes
mistakes when the KB has several options corresponding to the user intention. For example, once the
user has more than one doctor appointment in the table, the model can barely recognize. In addition,
since we do not include the domain specific and user intention supervision, wrong delexicalized
responses may be generated, which results in an incorrect entity copy. Lastly, we found that the
copied entities may not be matched to the generated sketch tags. For example, an address tag may
result in a distance entity copy. We leave the space of improvement to future works.
C Additional Discussion
One of the reviewers suggested us to compare our work to some existing dialogue framework such
as PyDial 5. To the best of our knowledge, in the PyDial framework, it requires to have the dialogue
acts labels for the NLU module and the belief states labels for the belief tracker module. The biggest
challenge is we do not have such labels in the SMD and bAbI datasets. Moreover, the semi tracker
in PyDial is rule-based, which need to re-write rules whenever it encounters a new domain or new
datasets. Even its dialogue management module could be a learning solution like policy networks,
the input of the policy network is still the hand-crafted state features and labels. Therefore, without
the rules and labels predefined in the NLU and belief tracker modules, PyDial could not learn a good
policy network.
Truly speaking, based on the data we have (not very big size) and the current state-of-the-art ma-
chine learning algorithms and models, we believe that a well and carefully constructed task-oriented
dialogue system using PyDial in a known domain using human rules (in NLU and Belief Tracker)
with policy networks may outperform the end-to-end systems (more robust). However, in this paper,
without additional human labels and human rules, we want to explore the potential and the advan-
tage of end-to-end systems. Besides easy to train, for multi-domain cases, or even zero-shot domain
cases, we believe end-to-end approaches will have better adaptability compared to any rule-based
systems.
5http://www.camdial.org/pydial/
13
Published as a conference paper at ICLR 2019
D Visualization
Delexicalized Generation: the nearest @poi_type is @poi. ©distance away at ©address
Final Generation: the nearest grocery尸tore is willows-market, 3-miles away at 409-bo∣∣∣
Gold: we are 3-miles away from willows-market but there is a car_collision_n
VwUIMdrwscwpa -
[coff*⅞jor∕e⅜jtκΦ] poijype cwpa -
[E<U3b*_ngt>yigMcJMb8vpa -
[6aaπdteβ3 Utatance cwpa -
teŋu网PQlcof⅛⅛,orte⅛j⅛ceTOdJiocXjiearby6-mlteβ -
[990	lXeot_av«l wHrws pMettjcof⅛e -
[coff*⅞jor∕e⅜jiκΦ] poijype pM⅞-C0f⅜e -
[modGre-EmCj tτ¾fflcjn⅛ peetβ-roft⅛e
t JEleej device peetβ-roft⅛e
tpmtβJCOffPQl coff*⅞jor∕e⅜jiκe EOderate-EfttC，(JnRe -
tei-6L3mMθ-H"⅛«87β -
g加SlMJypeTC -
[car_coiWori_neart>y] EmJlrτ⅛ 76
[SjnIIeddgmeTe
(70 POlgg-Mndon c⅞ζ-ElMon-nev⅛y 5-Elee -
1加9」Vneef 3 Mges avW∏L6∙denβJιgh -
[hoβpkal] poljype β⅞nfQ∏L,chlldrwJiM*h -
[EOderarejramcj gfl⅛-Mg Man⅛r⅛b<>>iφ^ns-heaMt>
[5.πleβ3 db⅛nw β⅛nfoe⅛-tfιlWrw-hes*h
tβ⅞ne∏L"~njhα>M] pol hoβpital EEeetjE”C 5」Tge -
I4βl-amsran0-aw] adφwβ PeIJaIeJr -
⅛***"(LS*S9>]P⅛W。闷。-WBJ^raW -
tnoj1*nc] ttaflKJn⅛ paIo_W8jgrB6_r -
[5.πleβ3d∣s⅞nce pelo_altoj»ar»ge_r -
tpslo_alCOjffara9ej3 poɪ part*>sjffar¾9e noJnfflc SjnIIee -
t842_arrwhe»4_wa)0 adφwβ panʤjwɪprwe -
tcHneee_ra«ww*] po<jype pβn⅛jBiφrwβ -
[rno<>er⅞⅞jτafflc] trafflςj rτ⅛ pand ⅛jB*prwβ -
[5.πlleβ3 <>scvκe p⅝n<S⅝-eiφrwβ -
IpandajBpeeejpojShM-EaqeneEEeetjEMcS-EIee -
[113jιrMj*] «d*«ee J∏9Lfn9 -
ttfιhwe-r^Λaqr⅛r*3 poljype 9n9Jr^ ~
ICa 匚例 bl5_neartiyi ET⅛-Me jnŋjnŋ
[3aaπdteβ3 Utatance Jn9Jng
O∣n9Jln9]PQIchh«e_r^«aqraneCaekElIUon_nwt>y⅞mllw -
[409Jioi ⅛r⅛,stj addπ∞ MIoWe-Eartret
typcery-Λoro] po<J⅜pe MlOwe-Earket
[car^kEldOnAWbyl EfttJhe wiι∣owβ-∏ιv⅛ct
[3_ndt«e3 (fβc⅝nce MlOWtt_mwfc«e
[wiι∣owβ-∏ιv¼vιo PT ypcery-Λoro car^lWon-nβ*by 3_mllw
«l»-
me -
dEHon，-
B -
Ihe
clκeβt
grŋeerXJtw
Pointer VtfaG
Final Pointer
0 123456789
0123456789
Figure 5: Memory attention visualization from the SMD navigation domain.
Delexicalized Generation: the nearest @poi_type is @poi at ©address
Final Generation: the nearest hospital is stanford_express_care at 214_el_camino_Feal
Gold: stanford_express_care is at 214jeΓcamiπoZreal
PolnterwZOG
Flnal Pointer
[5S3jdeβewjwφ] wHrws pHIz -
tcσffeejxjw⅛j⅛ce] po<_type pHlz -
tevj:MMon-new⅛y3 gM jMe pHIz
14IElM dβ⅞∏8 pHIz
tpHI⅛PUcof⅜⅞jQrje⅝lP⅛ceCarjcQlIIeIonnevty4jnlleβ -
t842_arrwhe»4_wa)o adΦws panʤjwɪprwe -
tcHneee_ra«ww*] po<jype pβn⅛jBiφrwβ -
[huvyjraffic] tτafflςjrτ⅛ pβn⅛jBiφrwβ -
[2arnlleβ] <>βcvκe p⅝n<S⅝-eiφrws -
[pand⅛jMφrwβ] POi 6h«e_r^aqrw* hwχjτafflc 2arnlleβ -
[4βl_amerantŋw] adΦwβ PeIJaIeJffaraŋjr -
⅛***"(LS*S9>]P⅛W。闷。-WBJ^raW -
[rwUdode_newt>y3 tτaπςjn<b PeIjaIeJgrB jr -
[2arnleβ3dlβcvκe PsIJaIeJJaraŋjr -
tpato_atoj0ar»9e_r3 pot PartdFLJar»9« Ed」iBc_neert>y 2-TmM -
[590_wi_n«e9jii«] wMrws toπ9aahowe -
[Men*-houK] polj)pe toπ9aahowe -
tnojrvfflc] t1*fflςjnfθ toπ9aahowe -
[2arnlte03 <>β⅞nce toπ9aahowe -
[eome_how«] PR MemIJhOU8 nojr*Hc 2_mllw -
[ββ9Jjljcwnhojval] wMrvββ R-∙J--Jch*>95 -
[cNnw⅞.rwuιnntJ pdjype p_._f_-_chsng« -
[mo4erat⅞jrafn^ traHςJnfO p-⅛Λ,-j⅛an9J -
[6aπ∏eβ3dβ⅞nceR-∙-t,-J≡h**95 -
IR-J-J6angβ3 pol cMn«e_r^«aqrane EOderate_E”c 6_mlee -
[214jBljCimg-EqM⅛wββ⅛nfor⅛JwPr^Se-Care -
IhOepiBl]p⅛βφ∙β⅛n⅛r⅛jBJφrw5JCee -
[moderateJTama tτ¾fflcjrτ⅛ Λanfor⅛,eιqrBsβ-carB
t⅞jnleβ3 <> Stancv WanfOe⅛jwprWe-Care
[β⅞n⅝∏LeiφRβsj!wV] po< Hoepital EOderate-EMC 5.πlleβ
t338_alee»r_aw] adΦ^sβ mlAown_rtioppinfl_cwtBr -
tβħopfi∏9LWnBnPol_typeEAown_rtioppiB_cwer -
[no_EMcj EmJlrι⅛ mldto⅛*ι-⅛ιo^nfl-c*n⅛r -
[⅞jnlleβ3 <>scvκe rnl<kQwi,ʃhop0n9^c«nt«r -
[πi*Qwι-pħQppinQjcenev3 pel βhφpkiQ-cene*rnojτafflc 5.πlleβ -
O04-vwιaneβ9jwφ] ⅞d<lrws c0*4>a -
[coff*⅞jor∕e⅜jlκΦ] po^jyρκ c0*4>a -
g_EmejgMJhiVCO>4> a —
ISFMdBBnce co*4> a -
IcwpS] PQl COff*⅞joς∕e⅞BPlKe noj>>fflc ⅞jnlleβ -
Ilnd -
Ihe
⅜dφwβ
1 -
h却Ol
or —
B -
Figure 6: Memory attention visualization from the SMD navigation domain.
14
Published as a conference paper at ICLR 2019
Delexicalized Generation: the nearest @POLtyPe is @poi, ©distance away at ©address
Final Generation: the nearest parking_garage is civic-ceπter^arage . 4-miles away at 5-miles
Gold: the closest parking_garage is CiVijCenterJgarage , located 4-miles away at 270_altaire_walk
Pointer WM G	Fln*l Pointer
I783-art⅜d⅛jl] adΦwβ dwŋn -
(9V,βWlon] po∣Jypκ (>wnn -
[mo<>er⅝⅞Jτafflc3 ttιfll jMe ehewŋn
[3aπdlw3 dBBnce tiwπr>
[Φe⅜ron]PQIg«t_«adonEOderate-BMC3aπlleβ -
[271^r*ιQer^UMQ ⅞d<Jrwβ mandvin_rooF -
tcHneee_ra«ww*3 poLe)Φ¢ nwn⅛r1n-rvo*B -
[rno<>er⅞⅞jτafflc] tra∏1ςjn<b nwi4ar1n_roo» -
t4jnlleβ] <fstvκe man⅛r1n-rvotβ
[man 由TILEttl POl <Mneg-gwv< EEeetjE"C 4_mlee
[40⅞-uriversItyjwΦ] WMrvss tτwiβrjoes -
tgrŋWrxJteæl pef_getr»decJoe« -
InoJraffic] Eftlςjn⅛ rr⅞derjoeβ
t5_mlles] d^vκe trade rjoβs
[tτwierj09β3 PR ^ŋeerXJew nojrβfflc ⅞-πlleβ -
[O9jvnh«rv:_M] ad*wβ rf9on⅛-⅛rπιera-markee -
(7QcerχjevV] poLe)Φ* d9on⅛.⅛rπιera-nιarkee -
tnoj1*nc] tιβ∏KJn⅛ d9θn⅛.⅛rπιera-markw
t4jnlw3dl^vκx "9on⅛-⅛rnιe∏(-Eark*
tdgon⅛j⅛mw‰πwfc*e3 pol ^ŋeerXJew noj>⅛fflc，(JnRe -
[347jriι⅞arnw⅝a,⅞vφ] ⅞d<lrwβ jll9,howe -
IMendsJwuse] pol_type )llβ-house -
thWyjTaMQgfl⅛Jn⅛ MMgBe -
[4jnleβ3 Utatance jll9aah0we
IJWJhOwel po* MenaJW18 hwχjτafflc 4jnlteβ -
t270_afcalr«_walc] adΦ⅞βs	-
[pvMngj0βr⅞ge] poLe)Φ*	-
tnojτ¾fflc3 gfl⅛-MlV cl⅛¼jχr> t*rjjar⅞9e
[4jτdteβ3 (Jbence
RSJCgeE3aE9el po∣ p Vfcfri gj0vage ∏ojτafl⅛ 4jnltes
I434_arMtr«dero_r4] adφwβ rw∏sww4-⅛>oppinfljχr>⅛r -
[βħφ0n9□Mnt*r3 pdjyp^ rwwsww4,rtioppinfl_cwter -
thwyjτβfflc3 tτafflςjn⅛ rwtnsww4,rtioppinŋjwter -
t4_mllw] dαance rwwsww4,rtioppinŋjwiter -
[rwtnsWWLrtWP*ns_c***3pQ βħςppln9jcer*vhwχjτafflc 4jnlleβ -
what -
VT -
Ihe -
dEHon，-
B -
Ihe -
clκeβt

0 123456789
0123456789
Figure 7: Memory attention visualization from the SMD navigation domain.
Delexicalized Generation: the nearest @poi_type is @poi. ©distance away at ©address
Final Generation: the nearest grocery-store is sigona-fermers-mar1<et, 4-miles away at 819_alma_st
Gold: there are whole-foods 2-miles away and sigona_farmers_market 4-miles away where do we go ?
PoInterwZOG
Flnal Pointer
[Men*-houK] polj)pe toπ9aahowe -
tljnlte03 <>nance toπjhow∙
[eome_how«] pd ttend‰houβe nojraffle ljnllw -
[271.^r*iQerj&««e3 wldrws rwi4ar1n_roo» -
tcHneee_ra«ww*3 poLe)Φ¢ nwn⅛r1n-rvo*B -
[4βl_amerantŋw] adΦwβ PeIJaIeJffaraŋjr -
tpslo_alCOjffara9ej3 poɪ part*>sjffar¾9e moΛrat¾Jτaflfc 2-mlleβ -
[329jBljcwτinojval] wMrvββ M-We 必
[rwtjκp]pdjwetħ⅞wegιk> -
t580_wi_neee_aw] adΦwβ Wm JhWS0
tnojr¾ffic] lτ¾fflςjrτ⅛ WnlJhW
[773jri9vjdr3 s<>(twβ WanfOe4_rtioppinfl_cwer -
[2jnlleβ] ^∏ror⅛,⅛∣ optJ ng_cvi n
WrW»ol«bE po<_type WhoteJVode
Ihwy_EECj Emςjn⅛ WhoteJVode
[63e_aniher«_«j ⅞d*Bββ deor^ʃamIerS-Earket
t4jnlw3dl^vκx "9on⅛-⅛rnιe∏(-Eark*
Mflon⅛j⅛rτnera-nwk«] pd ^cerχjew nojrβfflc，(JnUe
[rno<>er⅞⅞jτafflc] tτafπςjn<b πwι⅛r1n-roow
[2arnleβ3 distance palo.al	-
InoJraffic] gmςjn⅛ ⅛ιe-west>>
[βħopFinQjcenev3 pol.⅞φe βc⅝nfQ∏Lpħop0n9□Mnt9r -
[e OderaceJraffl CJEMjl n⅛ s⅛nfor⅛,⅛ι Offd ng_c«r>tw -
typcery-Λoro] po<_type deor^ʃamIerS-Earket
tnoj1*nc] tιβ∏KJn⅛ d9θn⅛.⅛rπιera-markw
⅛***"(LS*S9>]P⅛W。闷。-WBJ^raW -
[rno<>er⅞⅞jτafflc] tr⅛fl⅛J rτ⅛ pal o_al to_ffange_r -
t4jnlleβ] <fstvκe man⅛r1n-rvotβ
[man 由TILEttl POl <Mneg-gwv< EEeetjE"C 4_mlee
[2_ndt«e3 dβ⅞∏8 3ιRς-gl6
IwhoIeJwds] P 城 ^vcvyjxom hwyjτ¾fflc 2_mllw
[4.πllw3 1fβaκt ⅛⅞weβ*ι
(tħejwβHn] pd EUBP npjnfflc 4_mlle«
[βc⅝n<tx⅞^ħQpFinQjcenev3 pel βhφphQjMnt*rπo4er⅝⅞Jτafflc 2-EK
[919jyrn⅞je3 MdES 3i*_g|
«l»-
Iiiiiiiiii
0123456789
0123456789
Figure 8:	Memory attention visualization from the SMD navigation domain.
15
Published as a conference paper at ICLR 2019
Delexicalized Generation: okay, setting a reminder for your ©event with @party ©date at ©time
Final Generation: okay , setting a reminder for your dinner with marie 7pm at the_6th
Gold: i will set a re mi nder for di nner at 7pm, for the_6th cf this month with marie
Pointer WM G	Fln*l Pointer
what —
time -
shall -
tHg -
∏wt>⅛> —
5lħ —
012 34 5 67 8 91QI12
012345678 9iaH2
Figure 9:	Memory attention visualization from the SMD schedule domain.
Delexicalized Generation: your ©event is on @date at @time
Final Generation: your tennis-activity is on the_4th at 5pm
Gold: your tennisjactivity is on the_4th at 5pm and your sister will be attending
PolnterwZOG
MΛer3 party SWfcnmIrnLacfMty —
[tħ⅞4th] <Stfe βv*nrnInQjκtMey —
tlθsm] ⅛nβ S'**nπιln⅛-⅜cdvity -
[eornl pwty8c{Q<jypRnmιene —
(tħ⅞Jtħ] <SMe tfκnrjw^,rm>nc
I3pm] dme doσor-afφo<nmιent
tmβrtha] party yo9⅛-actMty —
(tħ⅞,l(Ht] date yβ0uκ(Mty
IIlaE dme yo9⅞-κtMty
[s⅛)vdpvty t
[tħwBday] date t
[2pnι] time <
[wQ party α∏∏b —
[sw>day] dare dnr>er
ITpmj dπedrr>er
[e∣md pany MHitljKtMty
(tħe-4tit] <im BHi JKtMty
[5pπ] time MnrisjKtMty
Flnal Pointer
Ilnd -
Ihe —
daw -
and -
time -
⅛r —
Figure 10:	Memory attention visualization from the SMD schedule domain.
16
Published as a conference paper at ICLR 2019
[Cpm] ttne eonfʤr^nee -
[tħ4j7lħ16te∙cB(jVP*Ent -
[tħ⅞-17th] date <wιer -
[brŋaw] psrty 1⅛0bal-κa⅛dty -
(«0*1 <i>n AwthSlJKtMty -
Delexicalized Generation: your next ©event is on @date at (Stime
Final Generation: your next tennis-activity is on the_13th at 6pm
Gold: your next tennisjactivity is on the_4th at 5pm with your mother
PoInterwZOG
Flnal Pointer
[aunt] party doσor-afφointment
[ιħwBdayj dare SW_a“> Tnrnie nt
[3PrnIHE¢800CaPPTr*π*r* -
[90_wr_qusrtei%,r^port] a9en⅛ con⅛rwκe -
[con⅜r⅝nc⅞.rQQm-WCQ rŋem cςn⅛rerxΛ 一
PnfrWtnKmateVnlPWtyCQnfiBWκ∙-
[tħ⅞j6tħ] <Stfe eonfʤr«nee -
[alev] party doσor-afφointment
t7pm] Mme do σor-afφ oirtrne nt
[<pmj PartyWrWJaCWty
(tħ⅞,13Ht] Ste BrHjactMty
[5pπ] time MnisjKtMty
tawɪɑ Psrtydnner
[6pmjdmedπ
[πoβw] pwty MHijacM
(tħe-4βt] <im BnrtjscH
[5pπ] time MnisjKtMty
Oem pwty MHi 6jκtMty
(tħ⅞,lU>t] dste BHi 6jκtMty
t7pn] βme BHijactMty
[<*π] βme ⅛θtιsljca⅛dty
what -
time 一
Ie
mat
MHisjKtMty
wll
be -
0 1234567
01234567
my -
and -
who -
art≡ndno -
Figure 11: Memory attention visualization from the SMD schedule domain.
Delexicalized
Generation: your ©event is on @date at @time with ©party
Final Generation: your doctor is on the_5th at 6pm with alex
Gold: are you talking about the docto^appointment on Wednesday or the one on the_5th
[alev] party (
[wx>⅛yj da⅛ <
[2pm] dme I
[<>κw9Jħ⅞arner9er3 a9en<Sβ eonfʤr^nee —
INπfl pwty 1⅛0tιsljca⅛dty
(«0*1 SB ⅛β⅛al-κtMty
[βvn] time 1⅛0tιsljca⅛dty
[con⅛rv∣ce-rponι-5α] room con⅛rv∣ce —
[πm9emene3 pwty eonfʤr«nee —
[Mdayj date con⅛rwce
[IQvn] ttne eonfʤr^nee —
MΛer3 party SWfcnmIrnLacfMty —
[⅛<t>ed party SCtOr_却 TnmienC
[Wednesday] dare SCtOr_却 Tnmlene
t7pm] Mme do σor-afφ oirtrne ne
[Jon] party t
IttWWfayJ *w <
[2pm] dme 1
Wecuse_the_compeny_plcnlc] agenda rneednŋ —
(tħ⅞,13th] Ste ,5rnnlEjKtMty
(lpm] r*ne s'**nπιln⅛-⅜cdvity
[alev] party doσor-afφointment
(tħ⅞Jtħ] <SMe tfκnrjw^,rm>nc
[6pm] dme do σor-afφ ointrπe nt
[100jnnfier«nce_rocrT0 rpom rnmdng —
tnwι ⅜9era ent] party meednŋ
Itħ⅞Jπfl <Mn n>M(Ing -
[2pm] Hrne meeting
what —
my -
HEe
Ie
4κtw
apartπιert
and -
who -
Ia
Pointer Wfo G	Fln*l Pointer
ιιιιιιιιι	Iiiiiiiii
012345678	012345678
Figure 12: Memory attention visualization from the SMD schedule domain.
17
Published as a conference paper at ICLR 2019
Delexicalized Generation: it will not be @weather_attribute in ©location @weekly_time
Final Generation: it will not be drizzle in redwood-city weekend
Gold: there will be no drizzle in redwood_cityfthis weekend
Polnterw/oG
Final Pointer
[6Ofl high SUnd
[5t>fl low SUnd
[rain] auιιuβy IiwiiIiouaiI -
[10W] high SetUEay rɪwnhatun -
[90f] taw »tuiid«y rɪwnhatun -
[raining] sβturdey mnhβtUn —
[4βf] high fr⅛i*y m*nhatun —
[20∏ law frid*y m*nhβtun —
[rain] f riday InanhatUn -
thursday mnhβtun —
thursd*y πwnhβtun —
MeWIwednesdaynwnhatWn —
[IOOH high tuesdey πwnhβtun -
[80f] low tuesd*y πwnhβtun -
[rain] Uesdey πwnhβtun -
[βθ∏ high mαnday πwnhβtun —
[4W] low monday m*nhatun —
[ClMJSkiW] mgnday m*nhβtun -
[iθθf] high SUnd«y compton -
[90f] Iow IldWcompton -
[raining] sund«¥ cβmρtβn —
[50f] high Mturdw compton -
[4β⅛ low »turd«y compton -
⅛verωst] s»turd«y compton -
[80f] high frid«y cβmρtβn —
[60fJ lowfrid*y compton -
[drizzle] frid*y compton
[100Π high thursd*y compton -
[90Π kɪw thuradw compton -
[misty] thuisd«y compton —
[80f] high w«lnesd«y compton -
[60fJ low we<inesd*y compton -
[dew] we<inesd*y compton -
[100f] high tuesd*y compton -
[90f] lowtuesd*y compton -
[αve∣C4St] tuesd*y compton -
[M∏ high mcnd«y compton -
[70f] taw mcn<i«y compton -
[dew] mendw compton -
[40H high SUndw n«iwaid_CiW -
[3t>fl low Sunday nrfwood_ci& -
[CleersWeslSUnd«ynedwoid_ci& -
[60fl high s»turd«y nκiwooti-ci⅛ -
[4βf] low »turd«y nedw8d_ci& -
[dry] s«turti»y ∏edwoo<ci⅛ -
[βθf] high frid*y nedw8d_ci& -
[40f] low frid*y nedw8d_ci& -
[windy] frid*y nκiw<ιod-ci⅛ -
[IOOH high thursd*y nedw8d_ci& -
[90⅛ taw thu∣sday nrfwood_ci& -
[humid] thu∣sday ∣cdwααd-ci⅛r -
[100f] high Wednesday re<twood_city -
[80fJ low Wednesday re<twood_city -
[hot] Wednesday redwood^city -
[Mf] high tuesday re<twoo<city -
[70f] lew tuesd*y Ewoodfig -
nedwoo<ci⅛
nκiwoβ<l-ci⅛r —
[30f] law mcnd*y Ewoodfig -
[⅛ggy] rrwnd«y nedwoo<ci⅛ -
[40H high Sunday san-rnetea -
[30f] k∣w sαnday san-mateβ -
idιy] SunSysanjnrtec -
[70H high SetUEay SarLnwɪee -
[60⅛ taws«turd«ys«n_m«te<i -
[rsin] SataEaysanjnrtec -
MWJhighfrWaysanjnatee —
[20⅛ taw friday SanjneteO —
Wry] frittay	-
[50H high thurStiaySarLnwɪee -
[30fJ tawthursd«ysen_m«te<i -
[cle«r_skies] thursd*y s«n_m«te<i -
[70Π high wed nesd*y s« n_m«teo -
【5OfI IowwednesdaysaiviwtKi -
[rain] WetineSdaySanJnrtetI -
[50HhightUeSday SanJnetee -
[4θh lcwtuesd«ys«n_m«te<i -
M∣⅛zle] tαesd*y s«n_m«t«o T
[50f] high mcnday SanJnrtec -
[30f] low mcnday sanjn*tec -
[mis⅛l mcnti⅛ys*n-πwtec -
[βOH high SUmlaygEmLEPiete -
[4ff] law Sunday gmnd-mρi<ls -
[stormy] sundry gmπd-mρids -
[ðθŋ high MHlRlaygEmLEPiete -
[SOT IowsetuEaygrsnLrspitis -
[humM] MHirdaygemLEPiete -
[70H high frW«ygran<l_rapi<ls -
[SOT lcwfrid«ygrsnd_rspitis -
[drizzle] frid*y grsnd_rspids
[MF] high thurKlaygmmLmPMS -
[4βf] tawthursd«ygrsnd_rspids -
[frost] thursd*y grsnd_rspids -
[60f] highwedneSdaygrSntc
[4βf] IoWWedneSdaygrSnd-
dZraρids -
d-mρids -
∏ ECH∙一
Irainingh---------
[60f] high t∪esdaygr8∏<raρitis -
[4θh tawtuesd«ygrsnd_rspids -
M∣⅛zle] tuesd«y gmnd-reρids
[70f] high mαn<l<ygran<l-raρi<ls -
[5t>⅛ low mcnti«ygrsnd_rspitis -
[snβw] manday gemLEPiete -
[Mf] high sanday mαuπtaiπ-view —
[80f J lew sunday moIintainjriew —
[h«il] sunday mαuπtaiπ-view —
【6OfI high SetuEaymcurrtain
[5t>fl IowsatuEaymcunmin
[Wizard] SatUEay mount«in_
[60fl high fr⅛i*y IneUnttdn_
[50f] taw frW«y mounUin2
[rain] friday mβuntain.
[stom⅛
[4βf] high *
[2t>f] low *
igh thursdey meunuin2
OWthursdaynMunttin;
ιy] Htursday mountti∏2
I Wednesday rrtQU∏tnin-
n_view -
n_view -
n_view -
n_view -
n_view -
n_view -
n_view -
[h«il] wee
[5Of] high 1
【3OfI taw I
Vnesday mou∏Min-view
Vnesday mou∏Min-view
I tuesd*y mounuin-
I tuesd*y mounuin
[rain] tuesday mαuπtaiπ-view —
[30H high nwnday mauntain-view —
[2t>f] low mβnday nκκ∣ntai∏Zview —
M∣y] Inamlay InaQiItaiiI二VieW —
[50f] high SUndaydrWn -
[30f] law sunday C4∣sβn -
Iwindylsundaygrwn -
[4tf] high SMuEaysrwn -
POfJ tawseturd⅛yc*rwn -
[dew] SatuEaysrwn -
[50H high fridayca∣sβn -
[30f] Iawfridayuisen -
[ftggy] frWayuisen -
[90f] high thursdayC4∣sβn -
[70fl low thursd*y c«rwn -
[snew] thursd*y c«rwn -
[30H high Wednesday c*rwn -
[2θh lowwe<ir∣esd*yc*rwn -
[snαw] Wednesday c»r»n -
[30H high tuesd«yc«rwn -
[20f] tawtuesd«yc«rwn -
[cle«r_slciesl tuesd*y c«rwn -
[β∂q high mond«yc«rwn -
mondaysrwn -
mond«yc«rwn -
[mend»y] tβdey -
will T
there —
be -______
driz:ie
Jn
BdWtKld-City
-th⅛ -
weekend
G
01234567
01234567
Figure 13: Memory attention visualization from the SMD weather domain.
18
Published as a conference paper at ICLR 2019
Delexicalized Generation: there will be @weather_attribute in ©location on ©date
Final Generation: there will be clear-skies in danville on tħursday
Gold: dew is predicted in danville on thursday
Polnterw/oG
Final Pointer
【MH Iiighsundaydanville -
[8t>f] low sundry danville -
[misty] SUndeydsnviIIe -
[60f] high »turd«y d«nville -
[4βf] low »turd«y d«nville -
[fg9gy] Mtanlaydtnville -
[10Wl Iiighfridwdanville -
BOfl k∣w frid«y danville -
[misty] fridey Jsnville -
【4OfI high thursd*y danville -
[20f] lew thursd*y danville -
[dew] Ihursdaydanville -
[60fl high WMinesdwdanviIIe -
[4W] WwwMinesdwdanviIIe -
Idiylwwinesdaydanville -
[30f] high tuesd*y danville -
[20f].k>wtuesdty d»nville -
[mining] tuesdey∣
[60f] high mcndayι
[5t>f] Iow rrwndey ɪ
[fros*∙'-------1--∙-
OStl rrwndey I
[50f] high Sundeysetttle -
[4β∏ Iowsundayseettle -
[Wizard] sund«y Seattle -
[50f] high SetUEaySMttle -
[4βfl low »turd«y seattie -
[dri≡lel SrtuEay seett∣e -
[5t>∏high frid«y se⅛ttle -
[30f] Iowfritieyseattle -
[mistyl frid«y seβttle -
Hiursdayseattle -
thurSdaySeattle -
[warm] thursday settle -
[l<X>f] high Wednesdayseattle -
[90f] IowwMlnesdayseettIe -
[
[het] Wednesdayswttle -
[6βfi high tuesd*y se⅛ttle -
WWJklWtUeSdwSMttie -
[r#in] tuesd*y se⅛ttle -
[4W] high mcnday settle -
[3t>fl taw mcnday settle -
M∣y]mβndty se«ttle -
[30Π high SUnsy fnesnc -
[2θh law SUnS	-
[frost] suntto
[40H high s«tjjrd«y fnesnc -
[3t>f] lows«tjjrd«yfnesno -
M∣y] s»tur<i«y fnesnc -
[100f] highfrittayfnesno -
[9W1 lew frittay fnesnc -
[humid] frid«y ftesno -
[100Π high thursd*
[80f] IOWthUrsda
[dew] thu∣sdt
[70f] high WetineSS
IBOfl lew WedneSSy fnesnc -
h⅛My] Minesdayfnesna -
[50f] high taes<toy fnesnc -
[4βf] Iowtuesttoyfnesno -
[frost] tues<toy fnesno -
[70f] high mcnttoyfnesnc -
[60f
[60f] high t__.
[50fl IOWSUnday
[1⅛ggy] SUMay
[3OfI high saturd«yo«ktant
【2OfI IoWSatUEaygktand
[misty] SatUEaygktand
[l∞f] highfrid«yo«ktand
[90fl IoWfridaygktand
Miy]frid«y osktend
【«*】 high thurSdaygktand
[50fl IoWthUrsdaygktand
IfcggyJ thursday tɪaktend
[lOOf] high Wednesdaygktand
[90fl IOWWedneSdaygktand
[hot]wednesdeyι
UOOT high I
【9OfI Iowi
ItUeSdayl
ituesd«yo«ktant
EaudyltueSdaygktand -
[l<X>fl high mcnd«y o*ktant -
[SOT low mcnd*yo*ktant -
[clwrsIdesl mcnd∙yαaktand -
[40H high S(IndayeXeter -
[20f] IOWSUndayeXeter -
gverwst] SUndayexeter -
[80f] high SetUEayeXeter -
[60⅛ taw saturd«yexeter -
[rain] s«turd«y exeter -
UofI high Mtlayexeter -
IBWl WWfridayeXeter -
[fβggy]frW*yexeter -
[6«J high HIUretiayexeter -
[50f] Iowthursdeyexeter -
[βveιcβst] thursd«y exeter -
[40H high WetineSdayeXeter -
[2θh IoWWedneSdayeXeter -
[snow] WedneSdayeXeter -
[70f] high tuesd*yexeter -
[50f] Iowtuesdeyexeter -
【windyItUeSdayexeter -
[100f] high mcnday exeter -
[9OT low rrwnd*yexeter -
M∣y] mcnd«yexeter -
[TOflhighsundayaIhambrs -
[50fl Iowsundeyslhsmbrs -
[50H high s«tu
[3t>f] Iowsat
[dew] sat _...
[70∏ high frWayaIh
[50f] IoWfrwayaIh
[dew] f riday Hh
[70f] high ChuMayaIh
[60f] IOWthUrSdayaIh
M∣y] thursdβyβlh
[60f] high Wednesdayalh
[50f] IOWWedneSdwaIh
[foggy] wednesd«y«lh
【6OfI high I
[W] Iowi
w∣yl -
[7t>f] high
[60f] low
,[⅛ggyi
[9Of] high：
[70f]lcw:
Ituesdayalh
Muesdayalh
ItUeSdayaIh
I mcnd«y«lh
,mcnd«y«lh
ɪ mcnday a Ihambrs -
∣sundey bnentwoot -
∣sundey bnentwoot -
[r«in] sundry bnentwwd -
[100f] high Mturdw bnentwooc -
[8t>⅛ low Mturdw bnentwoot -
[ftιggy] SrtUEw bnentwwd -
[90fJ high frid«y tɪnentwood -
[80fJ lew frid»y bnentwood -
[overwstɪ frid*y bnentwood -
[IOOH high thursd*y bnentwood -
[βθ∏ lew thuisd«y bnentwoot —
[ft⅛gy] thuisd«y bnentwwd -
[80f] high Wednesday breπtwoo< -
[60fJ lew wednesdw bnentwoot -
nesd«y bnentwwd -
UeSd«y bnentwoot -
[50f] low tuesd*y bnentwoot -
[rain] tuesd*y bnentwood -
[IOOH high mendw bnerrtwood -
[9βf] taw mendw tɪnentwood -
[Steimyl mcnd*y Dnentwood -
[mondeJdtodaj
there -
01234567
Figure 14: Memory attention visualization from the SMD weather domain.
19