Published as a conference paper at ICLR 2019
signSGD via Zeroth-Order Oracle
Sijia Liut	Pin-Yu Chent Xiangyi Chen^ Mingyi Hong^
tMIT-IBM Watson AI Lab, IBM Research
^University of Minnesota, Twin Cities
Ab stract
In this paper, we design and analyze a new zeroth-order (ZO) stochastic opti-
mization algorithm, ZO-signSGD, which enjoys dual advantages of gradient-free
operations and signSGD. The latter requires only the sign information of gradient
estimates but is able to achieve a comparable or even better convergence speed
than SGD-type algorithms. Our study shows that ZO-SignSGD requires √d times
more iterations than signSGD, leading to a convergence rate of O(√d/√T) under
some mild conditions, where d is the number of optimization variables, andT is
the number of iterations. In addition, we analyze the effects of different types of
gradient estimators on the convergence of ZO-SignSGD, and propose several vari-
ants of ZO-signSGD with O(√d/√T) convergence rate. On the application side
we explore the connection between ZO-signSGD and black-box adversarial attacks
in robust deep learning. Our empirical evaluations on image classification datasets
MNIST and CIFAR-10 demonstrate the superior performance of ZO-signSGD on
the generation of adversarial examples from black-box neural networks.
1	Introduction
Zeroth-order (gradient-free) optimization has attracted an increasing amount of attention for solving
machine learning (ML) problems in scenarios where explicit expressions for the gradients are difficult
or infeasible to obtain. One recent application of great interest is to generate prediction-evasive
adversarial examples, e.g., crafted images with imperceptible perturbations to deceive a well-trained
image classifier into misclassification. However, the black-box optimization nature limits the practical
design of adversarial examples, where internal configurations and operating mechanism of public
ML systems (e.g., Google Cloud Vision API) are not revealed to practitioners and the only mode of
interaction with the system is via submitting inputs and receiving the corresponding predicted outputs
(Papernot et al., 2017; Liu et al., 2017; Chen et al., 2017; Tu et al., 2018; Ilyas et al., 2018b; Cheng
et al., 2018; Bhagoji et al., 2018). It was observed in both white-box and black-box settings1 that
simply leveraging the sign information of gradient estimates of an attacking loss can achieve superior
empirical performance in generating adversarial examples (Goodfellow et al., 2015; Madry et al.,
2018; Ilyas et al., 2018a). Spurred by that, this paper proposes a zeroth-order (ZO) sign-based descent
algorithm (we call it ‘ZO-signSGD’) for solving black-box optimization problems, e.g. design of
black-box adversarial examples. The convergence behavior and algorithmic stability of the proposed
ZO-signSGD algorithm are carefully studied in both theory and practice.
In the first-order setting, a sign-based stochastic gradient descent method, known as signSGD, was
analyzed by (Bernstein et al., 2018; Balles & Hennig, 2017). It was shown in (Bernstein et al., 2018)
that signSGD not only reduces the per iteration cost of communicating gradients, but also could yield
a faster empirical convergence speed than SGD (Kinga & Adam, 2015). That is because although
the sign operation compresses the gradient using a single bit, it could mitigate the negative effect of
extremely components of gradient noise. Theoretically, signSGD achieves O(1∕√T) convergence
rate under the condition of a sufficiently large mini-batch size, where T denotes the total number of
iterations. The work in (Balles & Hennig, 2017) established a connection between signSGD and
Adam with restrictive convex analysis. Prior to (Bernstein et al., 2018; Balles & Hennig, 2017),
although signSGD was not formally defined, the fast gradient sign method (Goodfellow et al., 2015)
to generate white-box adversarial examples actually obeys the algorithmic protocol of signSGD.
The effectiveness of signSGD has been witnessed by robust adversarial training of deep neural
networks (DNNs) (Madry et al., 2018). Given the advantages of signSGD, one may wonder if it can
1‘white-box’ (vs ‘black-box’) implies whether the knowledge on the target model is known a priori.
1
Published as a conference paper at ICLR 2019
be generalized for ZO optimization and what the corresponding convergence rate is. In this paper, we
answer these questions affirmatively.
Contributions We summarize our key contributions as follows.
•	We propose a new ZO algorithm, 'ZO-signSGD'，and rigorously prove its convergence rate
of O(√d/√T) under mild conditions.
•	Our established convergence analysis applies to both mini-batch sampling schemes with
and without replacement. In particular, the ZO sign-based gradient descent algorithm can be
treated as a special case in our proposed ZO-signSGD algorithm.
•	We carefully study the effects of different types of gradient estimators on the convergence of
ZO-signSGD, and propose three variants of ZO-signSGD for both centralized and distributed
ZO optimization.
•	We conduct extensive synthetic experiments to thoroughly benchmark the performance of
ZO-signSGD and to investigate its parameter sensitivity. We also demonstrate the superior
performance of ZO-signSGD for generating adversarial examples from black-box DNNs.
Related work Other types of ZO algorithms have been developed for convex and nonconvex
optimization, where the full gradient is approximated via a random or deterministic gradient estimate
(Jamieson et al., 2012; Nesterov & Spokoiny, 2015; Ghadimi & Lan, 2013; Duchi et al., 2015;
Gao et al., 2014; Shamir, 2017; Hajinezhad et al., 2017; Ghadimi et al., 2016; Lian et al., 2016;
Liu et al., 2018b;c; Wang et al., 2018). Examples include ZO-SGD (Ghadimi & Lan, 2013), ZO
stochastic coordinate descent (ZO-SCD) (Lian et al., 2016), and ZO stochastic variance reduced
gradient descent (ZO-SVRG)(LiU et al., 2018c;a; Gu et al., 2016). Both ZO-SGD and ZO-SCD can
achieve O(√d/√T) convergence rate. And ZO-SVRG can further improve the iteration complexity
to O(d/T) but suffers from an increase of function query complexity due to the additional variance
reduced step, known as ‘gradient blending’ (Liu et al., 2018c), compared to ZO-SGD. The existing
work showed that ZO algorithms align with the iteration complexity of their first-order counterparts
up to a slowdown effect in terms of a small-degree polynomial of the problem size d.
2	signSGD & Its Connection to Adversarial Machine Learning
In this section, we provide a background on signSGD, together with the problem setup of our interest.
In particular, we show that the commonly-used methods for generating adversarial attacks fall into
the framework of signSGD.
Preliminaries on signSGD Consider a nonconvex finite-sum problem of the form
minimize f(x) := (1/n) Pin=1 fi(x),	(1)
x
where x ∈ Rd are optimization variables, and {fi} are n individual nonconvex cost functions. The
finite-sum form (1) encompasses many ML problems, ranging from generalized linear models to
neural networks. If the gradients of {fi} are available, then problem (1) can be solved by many
first-order methods such as SGD, SCD, and signSGD. The method of our interest is signSGD, which
differs from SGD and SCD, takes the sign of gradient (or its estimate) as the descent direction. It was
recently shown in (Bernstein et al., 2018) that signSGD is quite robust to gradient noise and yields
fast empirical convergence.
Algorithm 1 provides a generic sign-based gradient descent framework that encapsulates different vari-
ants of signSGD. In Algorithm 1, GradEstimate(∙) signifies a general gradient estimation procedure,
which adopts either a stochastic gradient estimate in the first-order setting (Bernstein et al., 2018) or
a function difference based random gradient estimate in the ZO setting (Nesterov & Spokoiny, 2015;
Duchi et al., 2015). We call the ZO variant of signSGD ‘ZO-signSGD’, which will be elaborated on
in Sec. 3.
Adversarial attacks meet signSGD It is now widely known that ML models (e.g., deep neural
networks) are vulnerable to adversarial attacks, which craft inputs (e.g., images) with imperceptible
perturbations to cause incorrect classification (Szegedy et al., 2013; Goodfellow et al., 2015; Kurakin
et al., 2017; Lin et al., 2019). The resulting inputs crafted by adversaries are known as adversarial
examples. Investigating adversarial examples not only helps to understand the limitation of learning
models, but also provides opportunities to improve the models’ robustness (Papernot et al., 2016;
2
Published as a conference paper at ICLR 2019
Algorithm 1 Generic sign-based gradient descent
1:	Input: learning rate {δk}, initial value x0, and number of iterations T
2:	for k = 0, 1, . . . , T - 1 do
3： gk4一 GradEstimate(Xk) # applies to both first and zeroth order gradient estimates
4:	sign-gradient update
Xk+ι = Xk — δksign(^k), where Sign(X) takes element-wise signs of X	(2)
5： end for
Athalye et al., 2018; Madry et al., 2018). In what follows, we show that the generation of adversarial
examples in (Goodfellow et al., 2015; Kurakin et al., 2017) can be interpreted through signSGD.
Let X0 denote the natural (legitimate) input of an ML model associated with the true label t0, and
X0 = X0 + δ be the adversarial example to be designed, where δ are adversarial perturbations. If
f(X, t0) is the training loss of a learning model, then the goal of (white-box) adversarial attack is to
find minimal perturbation δ that is sufficient to mislead the learning model, namely, to maximize
the loss f (X0 + δ, t0). Taking the first-order approximation of f (X0, t0) around X0, we obtain
f (x0, to) ≈ f (x0, to) + Exf (xo,to), δi. By constraining the strength of perturbation in the '∞
ball of small radius (i.e., kδk∞ ≤ ), the linear approximation of f(X0, t0) is then maximized
at δ = E sign(Vxf (xo, to)) (Shaham et al., 2018). Therefore, generation of adversarial examples
proposed in (Goodfellow et al., 2015) obeys the sign-gradient update rule in (2),
x0 = xo — e sign(-Vχ f (xo,to)).
Such a connection between adversarial example generation and signSGD also holds in other attacks,
e.g., the iterative target attack method (Kurakin et al., 2017). Similarly, a so-called black-box attack
(Ilyas et al., 2018a; Bhagoji et al., 2018) is associated with our proposed ZO-signSGD algorithm.
3 ZO-signSGD for Black-Box Optimization
One limitation of signSGD (Bernstein et al., 2018) is the need of first-order information, i.e., stochastic
gradients. However, there exists a large practical demand for solving ML problems where explicit
expressions of the gradients are difficult or infeasible to obtain, e.g., the generation of adversarial
examples from black-box neural networks as discussed in Sec. 1 and 2.
Gradient estimation via ZO oracle In the ZO setting where the first-order information is unavail-
able, the gradient estimator at Step 3 of Algorithm 1 has only access to function values of {fi(X)}
given a query point X. Based on that, we construct a ZO gradient estimate through a forward differ-
ence of two function values (Nesterov & Spokoiny, 2015; Gao et al., 2014; Duchi et al., 2015). In
Algorithm 1, GradEstimate(X) is then specified as
GradEstimate(X) = b- X X Vfi(x; Ui,j), Vfi(x; Ui,j) := d[fi(x + μui,j)fi(x)] ui,j, (3)
q i∈Ik j = 1	μ
where X = Xk in Algorithm 1, Ik is a mini-batch of size |Ik| = b, {ui,j}jq=1 are i.i.d. random
directions drawn from a uniform distribution over a unit sphere, and Vfi (X; ui,j) gives a two-point
based random gradient estimate with direction Ui,j and smoothing parameter μ > 0. We remark
that the random direction vectors in (3) can also be drawn from the standard Gaussian distribution
(Nesterov & Spokoiny, 2015). However, the uniform distribution could be more useful in practice
since it is defined in a bounded space rather than the whole real space required for Gaussian.
We highlight that unlike the first-order stochastic gradient estimate, the ZO gradient estimate (3) is a
biased approximation to the true gradient of f. Instead, it becomes unbiased to the gradient of the
randomized smoothing function fμ (Duchi et al., 2012; Gao et al., 2014),
-n	-n
fμ (χ) = Ev [f(χ + μv)] = — £Ev[fi (χ + μv)] = — £ fi,μ (χ),	(4)
n i=1	n i=1
where fi,μ gives the randomized smoothing version of fi, and the random variable V follows a
uniform distribution over the unit Euclidean ball. Clearly, there exists a gap between a ZO gradient
estimate and the true gradient of f, but as will be evident later, such a gap can be measured through
the smoothing function fμ.
3
Published as a conference paper at ICLR 2019
Motivations of ZO-signSGD. Compared to SGD-type methods, the fast empirical convergence of
signSGD and ZO-signSGD has been shown in the application of generating white-box and black-box
adversarial examples (Goodfellow et al., 2015; Madry et al., 2018; Ilyas et al., 2018a). As mentioned
in (Bernstein et al., 2018), the sign operation could mitigate the negative effect of (coordinate-wise)
gradient noise of large variance. Recall that the ZO gradient estimate is a biased approximation to the
true gradient, and thus, could suffer from having larger noise variance than (first-order) stochastic
gradients. In this context, one could benefit from ZO-signSGD due to its robustness to gradient
noise. In Appendix 1, we provide two concrete examples (Fig. A1 and Fig. A2) to confirm the
aforementioned analysis. In Fig. A1, we show the robustness of ZO-signSGD against sparse noise
perturbation through a toy quadratic optimization problem, originally introduced in (Bernstein et al.,
2018) to motivate the fast convergence of signSGD against SGD. In Fig. A2, we show that gradient
estimation via ZO oracle indeed encounters gradient noise of large variance. Thus, taking the sign of
a gradient estimate might scale down the extremely noisy components.
ZO-signSGD & technical challenges beyond signSGD Algorithm 1 becomes ZO-signSGD as
the ZO gradient estimate (3) is applied. We note that the extension from first order to ZO is nontrivial,
as the proposed ZO-signSGD algorithm yields three key differences to signSGD.
First, ZO-SignSGD has milder assumption on the choice of mini-batch sampling. Recall that SignSGD
in (Bernstein et al., 2018) achieves O(1/√T) convergence rate given the condition that the mini-batch
size is sufficiently large, b = O(T). However, this condition only becomes true when the mini-batch
sample is randomly selected from [n] with replacement, which is unusual when n ≤ T. Here [n]
represents the integer set {1, 2, . . . , n}. And signSGD fails to cover signGD when b = n, since
sampling with replacement leads to Ik 6= [n] even if b = n. In the proposed ZO-signSGD algorithm,
we will relax the assumption on mini-batch sampling.
Second, in ZO-signSGD both the ZO gradient estimator and the sign operator give rise to approxi-
mation errors to the true gradient. Although the statistical properties of ZO gradient estimates can
be acquired with the aid of the randomized smoothing function (4), the use of mini-batch sampling
without replacement introduces extra difficulty to bound the variance of ZO gradient estimates since
mini-batch samples are no longer independent. Moreover, the sign-based descent algorithm evaluates
the convergence error in the '1 -norm geometry, leading to a mismatch with the '2 -norm based gradient
variance. Besides translating the the gradient norm from `1 to `2, the probabilistic convergence
method (Ghadimi & Lan, 2013) is used to bound the eventual convergence error of ZO-signSGD.
Finally, beyond the standard ZO gradient estimator (3), we will cover multiple variants of ZO-
signSGD for centralized or distributed optimization.
4 Convergence Analysis of ZO-signSGD
In this section, we begin by stating assumptions used in our analysis. We then derive the convergence
rate of ZO-signSGD for nonconvex optimization. Assumptions of problem (1) are listed as follows.
A1: Functions {fi} have L-Lipschitz continuous gradients, where L ∈ (0, ∞).
A2: At time k, the gradient of f is upper bounded by ∣Nfi(Xk)k2 ≤ σ for i ∈ [n].
Both A1 and A2 are the standard assumptions used in nonconvex optimization literature (Bernstein
et al., 2018; Reddi et al., 2018; Chen et al., 2018). A1 implies the L-smoothness of fi, namely, for
any X and y We obtain fi(x) - f (y) ≤ "fi(y), X - y)+ (L∕2)∣∣x - y∣∣2. A2 implies the bounded
variance of Vfi in (Bernstein et al., 2018, Assumption 3), namely, n Pn=IIl Vfi(x) — Vf (x)k2 ≤
4σ2, where we have used the fact that ∣Vf (x)k2 ≤ σ under A2. Throughout the paper, we assume
that problem (1) is solvable, namely, f (x*) > -∞ where x* is an optimal solution.
We recall that Algorithm 1 becomes ZO-signSGD when the gradient estimation step (3) is applied.
For nonconvex problems, the convergence of an algorithm is typically measured by stationarity, e.g.,
using IVf (X)I22 in SGD (Ghadimi & Lan, 2013) and IVf (X)I1 in signSGD (Bernstein et al., 2018).
For the latter, the '1 geometry is met when quantifying the stochasticity through the (non-linear) sign
operation. Different from signSGD, ZO-signSGD only obtains a biased estimate to the true gradient.
In Proposition 1, we bypass such a bias by leveraging the randomized smoothing technique used for
ZO optimization (Gao et al., 2014; Nesterov & Spokoiny, 2015; Duchi et al., 2015).
4
Published as a conference paper at ICLR 2019
Proposition 1 Under A1, the outputs {xk}kT=-01 of ZO-signSGD, i.e., Algorithm 1 with (3), satisfies
T-1	T-1 ∣-	__________________
X (δkE[kVfμ(xk)kι])	≤E[fμ(xo) -	fμ(XT)] + X	2δk√dyE[kgk	-Vfμ(xk)k2]
k=0	k=0
T1
+ dL X δk,
k=0
(5)
where the expectation is taken with respect to all the randomness ofZO-signSGD, fμ is the randomized
smoothing function of f in (4), and gk = GradEstimate(Xk) in (3).
Proof: See Appendix 2.
In Proposition 1, the rationale behind introducing the smoothing function fμ is that Vfμ(xk) is the
mean of ZO gradient estimate gk. And thus, the convergence of ZO-SignSGD is now linked with the
variance of gk, i.e., E[∣∣gk — Vfμ(xk)k2]. This crucial relationship presented in Proposition 1 holds
for a general class of signSGD-type algorithms that use different ZO gradient estimators. Spurred by
(5), we next investigate the second-order moment of gk in Proposition 2.
Proposition 2 Under A1 and A2, the variance ofZO gradient estimate gk is upper bounded by
E [kgk — Vfμ(xk)k2] ≤ 4αb(q+ 1 σ2 + (2αbb+ βb) C(d,μ),	(6)
where C(d,μ) := 2dσ2 + μ2L2d2∕2. In (6), ab and βb are Boolean variables depending on the
choice of mini-batch sampling,
αb= 1, βb= 0	for mini-batch with replacement
αb= I(b < n), βb= I(b > 1) for mini-batch without replacement,	()
where I(x > a) is the indicator function ofx with respect to the constraint x > a, and I(x > a) = 1
if x > a and 0 otherwise.
Proof: See Appendix 3.
Compared to the variance bound (σ2 ∕b) of the stochastic gradient estimate off in signSGD (Bernstein
et al., 2018), Proposition 2 provides a general result for the ZO gradient estimate gk. It is clear that
the bound in (6) contains two parts: hi := 4αbbq+1) σ2 and h2 := (2，+曲) C(d, μ), where the former
h1 = O(σ2∕b) characterizes the reduced variance (using b mini-batch samples) for the stochastic
gradient estimate of the smoothing function fμ, and the latter h2 =O(C(d, μ)∕(bq)) reveals the
dimension-dependent variance induced by ZO gradient estimate using b mini-batch samples and q
random directions. If a stochastic gradient estimate of f is used in signSGD, then h2 is eliminated
and the variance bound in (6) is reduced to (σ2∕b).
Furthermore, Proposition 2 covers mini-batch sampling with and without replacement, while signSGD
only considers the former case. For the latter case, Proposition 2 implies that if b = n (i.e., Ik = [n]
for ZO-signGD), then the variance E [∣∣gk — Vfμ(xk)|团 is reduced to O(C(d, μ)∕(nq)), corre-
sponding to αb = 0 and βb = 1 in (7). In the other extreme case of b = 1, both the studied mini-batch
schemes become identical, corresponding to αb = 1 and βb = 0. Proposition 2 also implies that
the use of large b and q reduces the variance of the gradient estimate, and will further improve the
convergence rate.
With the aid of Proposition 1 and 2, we can then show the convergence rate of ZO-signSGD in terms
of stationarity of the original function f. The remaining difficulty is how to bound the gap between f
and its smoothed version f*. It has been shown in (Gao et al., 2014; Nesterov & Spokoiny, 2015) that
there exists a tight relationship between fμ and f given the fact that the former is a convolution of the
latter and the density function of a random perturbation v in (4). We demonstrate the convergence
rate of ZO-signSGD in Theorem 1.
Theorem 1 Under A1 and A2, ifwe randomly pick XR from {Xk}kT=-01 with probability P(R = k)
δk
PT-I δk
, then the convergence rate of ZO-signSGD is given by
√2(ff(o) a∣∣ 1‹√2(f (xo) — f* + μ2L) , dL PT-OL δ2 , μLd
E[kVf (XR )k2] ≤-----LT-1 a------- + √ LT-IA + ~√
k=0 δk	2 k=0 δk	2
+
2√2√dp4αb(q + 1)σ2 + C(d, μ)(2αb + βb)
√bq
(8)
where f * denotes the minimum value.
5
Published as a conference paper at ICLR 2019
Proof: See Appendix 4.
In Theorem 1, we translate the gradient norm from `1 to `2 , and adopt a probabilistic output xR
(Ghadimi & Lan, 2013; Lei et al., 2017) to avoid exhaustive search over {xk} for mink ∣∣Vf (Xk)Il2.
Note that the convergence rate of ZO-signSGD relies on the learning rate δk, the problem size d,
the smoothing parameter μ, the mini-batch size b, and the number of random perturbations q for
ZO gradient estimation. We next obtain explicit dependence on these parameters by specifying
Theorem 1.
If δk = δ = O(√=) and μ = O(√=), then the convergence in (8) simplifies to
E[kVf(xR)k2] ≤ O (√T + √dpαbq√(αb + 仇)d! ,	⑼
where αb and βb were defined in (7), and 1 ≤ (αb + βb) ≤ 2. We provide several key insights on the
convergence rate of ZO-signSGD through (9).
First, the convergence rate of ZO-signSGD is measured through ∣Vf(XR)∣2 rather than its squared
counterpart ∣Vf(XR)∣1 22, where the latter was used in measuring the convergence of ZO-SGD. We
recall from (Ghadimi & Lan, 2013, Theorem3.2 & Corollary 3.3) thatZO-SGD yields the convergence
error E [∣Vf(XR)|2] ≤ O(√T). Since ∣∣Vf(xr)∣2 ≤ ∣∣Vf(xr)∣2 as ∣∣Vf(xr)∣2 ≤ 1, the
convergence of ZO-signSGD meets a stricter criterion than that of ZO-SGD. The possible downside
of ZO-signSGD is that it suffers an additional error of order O(√d + √∣) in the worst case. The
aforementioned results imply that ZO-signSGD could only converge to a neighborhood ofa stationary
point but with a fast convergence speed. Here the size of the neighborhood is controlled by the
mini-batch size b and the number of random direction vectors q.
Also, our convergence analysis applies to mini-batch sampling both with and without replacement.
When b ∈ [1, n), ZO-signSGD achieves O(√d + √d + √d=) convergence rate regardless of the
choice of mini-batch sampling. When b = n, it is known from (9) that the use of mini-batch
without replacement recovers ZO-signGD, yielding the convergence rate O(√T + √n=). By contrast,
the use of mini-batch with replacement leads to the worse convergence rate O(√T + √= + √d).
Clearly, as b = n and n < T, ZO-signSGD using mini-batch with replacement fails to achieve
the rate O( √T) regardless of the choice of q. By contrast, ZO-signSGD using mini-batch without
replacement recovers O(√d) as q = O(dT). When b > n, ZO-signSGD is restricted to using
mini-batch sampling with replacement. Similar to signSGD (Bernstein et al., 2018), we can obtain
O(√T) convergence rate as b =O(T) and q = O(dT), where the dependence on q is induced by
the use of ZO gradient estimation.
5 Variants of ZO-signSGD
Here we study three variants of ZO-signSGD, where the gradient will be estimated using a) the
central difference of function values, b) the sign of ZO gradient estimates with majority vote, or c)
the sign of ZO gradient estimates with majority vote for distributed optimization. That is,
a) GradEstimate(x)
d[fi(X + μuij) — fi(X — μuij )]uij
2μ
(10)
b)	GradEstimate(X)
c)	GradEstimate(X)
b1q X X sign (vfi(X； Uij D ,
i∈Ik j =1
MXIsign(bmq.X XVfi(x；Uij)，
m=1	i∈Im,k j=1
(11)
(12)
1	r	T	1	f /	∖ Λ	Λ	1 f' 1 ∙	∕C∖ EI	1∙	.	/1 C∖ ♦	1 i'
where {ui,j} and Vfi(x; ui,j) have been defined in (3). The gradient estimator (12) is proposed for
distributed optimization over a star network that consists of M agents and 1 central processor. Each
agent m ∈ [M] has only access to nm data (in terms of nm individual costs {fi}) with PmM=1 nm =
n, and the mini-batch Im,k per agent satisfies bm = |Im,k| ∈ [1, nm]. According to (12), the
6
Published as a conference paper at ICLR 2019
central processor receives 1-bit compressed gradients sign
(bm,q Σ^i∈Im,k Pq=I 十 fi(X； ui,j))
from
M agents and then performs the sign-based descent (2) and sends its 1-bit update back to every agent.
The ZO gradient estimator (10) was used in (Shamir, 2017) for bandit convex optimization and in
(Ilyas et al., 2018a) for designing black-box adversarial attacks. Compared to the form of forward
difference (3), the central difference (10) requires b(q - 1) times more function queries in gradient
estimation. At the cost of more function queries, one may wonder if the convergence rate of
ZO-signSGD can be further improved.
Corollary 1 Suppose that the conditions in Theorem 1 hold, ZO-signSGD with gradient estimator
(10) yields the same convergence rate of ZO-signSGD that uses the estimator (3).
Proof: Recall that Proposition 1 is independent of specific forms of gradient estimators, and thus
holds for (10). Although Proposition 2 relies on the second-order moments of each gradient estimator,
we prove that under A1 and A2, both (3) and (10) maintain the same statistical properties. As a result,
Proposition 2 and Theorem 1 also hold for (10); see more details in Appendix 5.
We next study the gradient estimator (11), whose sign is equivalent to the majority vote (i.e., the
element-wise median) of signs of individual gradient estimates {Vfi(x; u%,j)}. It was shown in
(Bernstein et al., 2018) that signSGD with majority vote has a better convergence rate under additional
assumptions of unimodal symmetric noise distribution of coordinate-wise gradient estimates. In
Corollary 2, we show that such a speed-up in convergence can also be achieved by ZO-signSGD with
majority vote, which we refer to as ‘ZO-M-signSGD’.
Corollary 2 Suppose that the conditions in Theorem 1 hold, and the distribution of gradient noise is
Unimodal and symmetric. Then, ZO-M-SignSGD with δk = O( √=) and μ = O( √=) yields
E[∣Nf(XR)Il2] = O (√d∕√T + d/pbq).
(13)
Proof: See Appendix 6.

We recall from Theorem 1 that under the same parameter setting of Corollary 2, ZO-signSGD
yields O(√√d
+ √d + 岛) convergence rate in the worst case. It is clear from (13) that the error
correction term of order √ is eliminated in ZO-M-SignSGD. Such an improvement in convergence
is achieved under the condition of unimodal symmetric gradient noise. We remark that different from
the stochastic gradient noise studied in (Bernstein et al., 2018), the ZO gradient estimation noise
could violate this assumption. For example, in a scalar case, if the gradient estimate g follows the
distribution where g = 1 with probability 0.9, g = -10 with probability 0.1, then E[g] < 0 and
sign(E[g]) < 0. However, E[sign(g)] > 0. This implies that without the assumption of symmetry,
the sign of gradient estimates with majority vote (E[sign(g)]) can be in the opposite direction of the
sign of averaged gradients (sign(E[g])). Our results in the next section show that ZO-M-signSGD
may not outperform ZO-signSGD.
Lastly, we focus on the gradient estimator (12), whose sign can be interpreted as the major vote of M
distributed agents about the sign of the true gradient (Bernstein et al., 2018). The resulting variant
of ZO-signSGD is called ‘ZO-D-signSGD’, and its convergence rate is illustrated in Corollary 3.
Compared to ZO-M-SignSGD for centralized optimization, ZO-D-SignSGD suffers an extra error
correction term 0(√d) in the distributed setting. It is also worth mentioning that if M = n and
q = 1, then the gradient estimator (12) reduces to (11) with Zk = [n]. In this case, Corollary 2 and 3
reach a consensus on 0( √d + √n) convergence error.
Corollary 3 Suppose that the conditions in Corollary 2 hold. ZO-M-SignSGD with bm = [ MC,
δk = O( √dτ) and μ = O( √dτ) yields
E[kvf(xr)∣2] = o (√d∕√T + √d∕√n + d∕√nq).	(14)
Proof: See Appendix 7.

7
Published as a conference paper at ICLR 2019
(a)
(b)
(d)
045 →-	SGD	-→-	ZO-SCD
―*—	signSGD	―♦—	ZO-SignSGD
0∙4°' —ZO-SGD	τ-	ZO-M-SignSGD
20	40	60	80	100
ltreations/50
(C)
——ZOSGD (d=200)	——ZO-SignSGD (d=200)
---ZOSGD (d=400)	--- ZO-signSGD (d=400)
——ZOSCD (d=200)	---ZO-M-signSGD (d=200)
——ZOSCD (d=400)	——ZO-M-SignSGD (d=400)
Figure 1: PerformanCe Comparison of ZO-signSGD, ZO-M-signSGD, ZO-SGD, ZO-SCD, signSGD and SGD
under a synthetiC dataset. The solid line represents the loss/aCCuraCy averaged over 10 independent trials with
random initialization, and the shaded region indiCates the standard deviation of results over random trials. (a)-(b):
Training loss and test aCCuraCy versus iterations. (C)-(d): EffeCts of mini-batCh size q and number of random
direCtion veCtors q on the ConvergenCe of studied algorithms. Here (C) presents the training loss versus iterations,
and (d) is the heat map of the final loss for different values of b and q. (e)-(f): EffeCts of problem size d. Here (e)
shows the final training loss versus d, and (f) presents the ConvergenCe trajeCtory when d ∈ {200, 400}.
6	Experiments
In this seCtion, we empiriCally show the effeCtiveness of ZO-signSGD, and validate its ConvergenCe
behavior on both synthetiC and real-world datasets suCh as MNIST and CIFAR-10. For the synthetiC
experiment, we study the problem of binary ClassifiCation in the least squared formulation. For the
real-world appliCation, we design adversarial examples from blaCk-box neural networks as mentioned
in SeC. 2. Throughout this seCtion, we Compare ZO-signSGD and its variants with SGD, signSGD
(Bernstein et al., 2018), ZO-SGD (Ghadimi & Lan, 2013), and ZO-SCD (Lian et al., 2016).
Binary classification We Consider the least squared problem with a nonconvex loss funCtion (Xu
et al., 2017; Liu et al., 2018b) minχ∈Rd 1 £二1。- 1/(1 + e-aTX))2, which satisfies AssumP-
tion A2 by letting σ = maxi{2kai k2}. Here instead of using the Conventional Cost funCtion of
logistic regression (a convex function), the considered least squared formulation is introduced to align
with our nonconvex theoretical analysis. For generating the synthetic dataset, we randomly draw
samPles {ai} from N (0, I), and obtain the label yi = 1 if 1/(1 + e-aiTx) > 0.5 and 0 otherwise.
The number of training samPles {ai, yi} is set by n = 2000 against 200 testing samPles. We find the
best constant learning rate for algorithms via a greedy search over η ∈ [0.001, 0.1] (see APPendix 8.1
for more details), and We choose the smoothing parameter μ = 10∕VTd. Unless specified otherwise,
let b = q = 10, T = 5000 and d = 100.
In Fig. 1, we report the training loss, the test accuracy, as well as the effects of algorithmic parameters
on the convergence of the studied algorithms. We observe from Fig. 1-(a) and (b) that ZO-signSGD
outperforms other ZO algorithms, and signSGD yields the best convergence performance once the
first-order information is available. In Fig. 1-(c) and (d), we observe that the convergence performance
of ZO algorithms is improved as b and q increase. In particular, ZO-signSGD and ZO-M-signSGD at
b = q = 30 approach to the best result provided by signSGD. In Fig. 1-(e) and (f), the convergence of
all algorithms degrades as the problem size d increases. However, ZO-signSGD and ZO-M-signSGD
converge faster than ZO-SGD and ZO-SCD. In Fig. 2, we demonstrate the convergence trajectory
of different variants of ZO-signSGD for b ∈ {40, 400}. To make a fair comparison between ZO-
signSGD and ZO-D-signSGD, let each of M = 40 agents use a mini-batch of size b/M. As we
can see, ZO-signSGD outperforms ZO-M-signSGD and ZO-D-signSGD. And the convergence is
improved as the mini-batch size increases. However, we observe that in all examples, ZO-signSGD
8
Published as a conference paper at ICLR 2019
Figure 2: Training loss (left) and testing accuracy (right) of ZO-signSGD, ZO-M-signSGD, ZO-D-signSGD
and ZO-SGD versus iterations.
(a) MNIST-ID 2
(b) MNIST-ID 34
(c) CIFAR-10 - ID 6
(d) CIFAR-10 - ID 10
Figure 3: Black-box attacking loss versus iterations. The solid marker indicates the iteration number that finds
the first successful adversarial example, and its loss corresponds to the squared `2 distortion.
and its variants converge to moderate accuracy much faster than ZO-SGD, only within a few tens of
iterations.
Generating black-box adversarial examples Here we study adversarial robustness by generating
adversarial examples from a black-box image classifier trained by a deep neural network (DNN)
model; see details on problem formulation in Appendix 8.2. We recall from Sec. 2 that the task of
black-box adversarial attack falls within the category of ZO optimization as one can only access to
the input-output relation of the DNN while crafting adversarial examples.
The DNN models trained on MNIST and CIFAR-10 (Carlini & Wagner, 2017) are performed as the
zeroth-order oracle2. We select one image from each class of MNIST and CIFAR-10 and separately
implement black-box attacks using the same attacking loss function (see Appendix 8.2) but with
different ZO optimization algorithms (ZO-SGD, ZO-signSGD and ZO-M-signSGD). We also set the
same parameters for each method, i.e., μ = 0.01, q = 9, and δ = 0.05 for MNIST and δ = 0.0005 for
CIFAR-10, to accommodate to the dimension factor d. Moreover, we benchmark their performance
with the natural evolution strategy (NES) based two-point gradient estimator in (Ilyas et al., 2018a)
for solving the same attacking loss function, where the sign of gradient estimate is also used in the
2https://github.com/carlini/nn_robust_attacks
9
Published as a conference paper at ICLR 2019
111111114	4
O 40	80	120	145	202	240	280	320	359
Table 1: Iteration comparison of attacking black-box DNN on MNIST (image ID 2).
Iteration	0	40	80	120	160	200	240	280	3Γ2	35^
ZO-SGD
Classified as
Iteration
ZO-signSGD
Classified as
Iteration
ZO-M-signSGD
Classified as
Iteration
ZO-NES
Classified as 1	1	1	1	1	1	4	4	4	4
descent step. We call the resulting black-box attack generation method ‘ZO-NES’. Similar to (10),
NES computes the ZO gradient estimate using the central difference of two function values. Thus,
one iteration of ZO-NES requires 2q function queries and thus we set q = 5 to align with the number
of function queries used in other ZO methods. All methods use the the same natural image as the
initial point for finding adversarial examples.
Fig. 3 shows the plots of black-box attacking loss versus iterations (more results are shown in
Appendix 8.3). We find that ZO-signSGD usually takes significantly less iterations than other
methods to find the first successful adversarial example with a similar attacking loss. For MNIST, the
average iteration over all attacked images in Table A1 to find the first successful adversarial example
is 184 for ZO-SGD, 103 for ZO-signSGD, 151 for ZO-M-signSGD, and 227 for ZO-NES. Their
corresponding average `2 distortion is 2.345 for ZO-SGD, 2.381 for ZO-signSGD, 2.418 for ZO-M-
signSGD, and 2.488 for ZO-NES. For CIFAR-10, the average iteration over all attacked images in
Table A2 to find the first successful adversarial example is 302 for ZO-SGD, 250 for ZO-signSGD,
389 for ZO-M-signSGD, and 363 for ZO-NES. Their corresponding average `2 distortion is 0.177
for ZO-SGD, 0.208 for ZO-signSGD, 0.219 for ZO-M-signSGD, and 0.235 for ZO-NES. As a visual
illustration, we compare the adversarial examples of a hand-written digit “1” of each attacking
method at different iterations in Table 1, corresponding to Fig. 3-(a). As we can see, ZO-signSGD and
ZO-M-signSGD can reduce roughly 54% of iterations (around 600 less model queries) than ZO-SGD
to find the first successful adversarial example. Given the first successful adversarial example, we
observe that ZO-signSGD yields slightly higher `2 distortion than ZO-SGD. This is not surprising
since Theorem 1 suggests that ZO-signSGD might not converge to a solution of very high accuracy
but it can converge to moderate accuracy sufficient for black-box attacks at a very fast speed. Note
that the first successful adversarial examples generated by different ZO methods are all visually
similar to the original ones but lead to different top-1 predictions; see more results in Appendix 8.3.
In addition, we observe that ZO-NES is not as effective as ZO-signSGD in either query efficiency
(given by the number of iterations to achieve the first successful attack) or attack distortion. Thus,
compared to ZO-NES, ZO-signSGD offers a provable and an efficient black-box adversarial attacking
method.
7 Conclusion
Motivated by the impressive convergence behavior of (first-order) signSGD and the empirical success
in crafting adversarial examples from black-box ML models, in this paper We rigorously prove the
O(√d/√T) convergence rate of ZO-SignSGD and its variants under mild conditions. Compared to
signSGD, ZO-signSGD suffers a sloWdoWn (proportional to the problem size d) in convergence rate,
hoWever, it enjoys the gradient-free advantages. Compared to other ZO algorithms, We corroborate
the superior performance of ZO-signSGD on both synthetic and real-Word datasets, particularly for
its application to black-box adversarial attacks. In the future, We Would like to generalize our analysis
to nonsmooth and nonconvex constrained optimization problems.
10
Published as a conference paper at ICLR 2019
Acknowledgments
This work was supported by the MIT-IBM Watson AI Lab. Mingyi Hong and Xiangyi Chen are
supported partly by an NSF grant CMMI-1727757,and by an AFOSR grant 15RT0767.
References
A. Athalye, N. Carlini, and D. Wagner. Obfuscated gradients give a false sense of security: Circumventing
defenses to adversarial examples. arXiv preprint arXiv:1802.00420, 2018.
L. Balles and P. Hennig. Dissecting adam: The sign, magnitude and variance of stochastic gradients. arXiv
preprint arXiv:1705.07774, 2017.
J. Bernstein, Y.-X. Wang, K. Azizzadenesheli, and A. Anandkumar. signsgd: compressed optimisation for
non-convex problems. arXiv preprint arXiv:1802.04434, 2018.
A. N. Bhagoji, W. He, B. Li, and D. Song. Practical black-box attacks on deep neural networks using efficient
query mechanisms. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 154-169,
2018.
N. Carlini and D. Wagner. Towards evaluating the robustness of neural networks. In IEEE Symposium on
Security and Privacy, pp. 39-57, 2017.
P.-Y. Chen, H. Zhang, Y. Sharma, J. Yi, and C.-J. Hsieh. Zoo: Zeroth order optimization based black-box attacks
to deep neural networks without training substitute models. In Proceedings of the 10th ACM Workshop on
Artificial Intelligence and Security, pp. 15-26. ACM, 2017.
X. Chen, S. Liu, R. Sun, and M. Hong. On the convergence of a class of adam-type algorithms for non-convex
optimization. arXiv preprint arXiv:1808.02941, 2018.
M. Cheng, T. Le, P.-Y. Chen, J. Yi, H. Zhang, and C.-J. Hsieh. Query-efficient hard-label black-box attack: An
optimization-based approach. arXiv preprint arXiv:1807.04457, 2018.
J. C. Duchi, P. L. Bartlett, and M. J. Wainwright. Randomized smoothing for stochastic optimization. SIAM
Journal on Optimization, 22(2):674-701, 2012.
J. C. Duchi, M. I. Jordan, M. J. Wainwright, and A. Wibisono. Optimal rates for zero-order convex optimization:
The power of two function evaluations. IEEE Transactions on Information Theory, 61(5):2788-2806, 2015.
X. Gao, B. Jiang, and S. Zhang. On the information-adaptive variants of the ADMM: an iteration complexity
perspective. Optimization Online, 12, 2014.
S. Ghadimi and G. Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic programming. SIAM
Journal on Optimization, 23(4):2341-2368, 2013.
S. Ghadimi, G. Lan, and H. Zhang. Mini-batch stochastic approximation methods for nonconvex stochastic
composite optimization. Mathematical Programming, 155(1-2):267-305, 2016.
I. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. 2015 ICLR, arXiv
preprint arXiv:1412.6572, 2015.
B. Gu, Z. Huo, and H. Huang. Zeroth-order asynchronous doubly stochastic algorithm with variance reduction.
arXiv preprint arXiv:1612.01425, 2016.
D. Hajinezhad, M. Hong, and A. Garcia. Zenith: A zeroth-order distributed algorithm for multi-agent nonconvex
optimization. 2017.
A. Ilyas, L. Engstrom, A. Athalye, and J. Lin. Black-box adversarial attacks with limited queries and information.
In International Conference on Machine Learning, 2018a.
A. Ilyas, L. Engstrom, and A. Madry. Prior convictions: Black-box adversarial attacks with bandits and priors.
arXiv preprint arXiv:1807.07978, 2018b.
K.	G. Jamieson, R. Nowak, and B. Recht. Query complexity of derivative-free optimization. In Advances in
Neural Information Processing Systems, pp. 2672-2680, 2012.
D. Kinga and J. B. Adam. A method for stochastic optimization. In International Conference on Learning
Representations (ICLR), 2015.
11
Published as a conference paper at ICLR 2019
Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial machine learning at scale. 2017 ICLR, arXiv
preprint arXiv:1611.01236, 2017. URL http://arxiv.org/abs/1611.01236.
L.	Lei, C. Ju, J. Chen, and M. I. Jordan. Non-convex finite-sum optimization via scsg methods. In Advances in
Neural Information Processing Systems, pp. 2345-2355, 2017.
X.	Lian, H. Zhang, C.-J. Hsieh, Y. Huang, and J. Liu. A comprehensive linear speedup analysis for asynchronous
stochastic parallel optimization from zeroth-order to first-order. In Advances in Neural Information Processing
Systems, pp. 3054-3062, 2016.
J. Lin, C. Gan, and S. Han. Defensive quantization: When efficiency meets robustness. In International
Conference on Learning Representations (ICLR), 2019.
L. Liu, M. Cheng, C.-J. Hsieh, and D. Tao. Stochastic zeroth-order optimization via variance reduction method.
arXiv preprint arXiv:1805.11811, 2018a.
S. Liu, J. Chen, P.-Y. Chen, and A. O. Hero. Zeroth-order online ADMM: Convergence analysis and applica-
tions. In Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics,
volume 84, pp. 288-297, April 2018b.
S. Liu, B. Kailkhura, P.-Y. Chen, P. Ting, S. Chang, and L. Amini. Zeroth-order stochastic variance reduction for
nonconvex optimization. arXiv preprint arXiv:1805.10367, 2018c.
Y. Liu, X. Chen, C. Liu, and D. Song. Delving into transferable adversarial examples and black-box attacks.
ICLR, arXiv preprint arXiv:1611.02770, 2017.
A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to
adversarial attacks. ICLR, 2018.
Y. Nesterov and V. Spokoiny. Random gradient-free minimization of convex functions. Foundations of
Computational Mathematics, 2(17):527-566, 2015.
N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and A. Swami. The limitations of deep learning in
adversarial settings. In Security and Privacy (EuroS&P), 2016 IEEE European Symposium on, pp. 372-387.
IEEE, 2016.
N.	Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and A. Swami. Practical black-box attacks against
machine learning. In Proceedings of the 2017 ACM on Asia Conference on Computer and Communications
Security, pp. 506-519. ACM, 2017.
S. J. Reddi, S. Kale, and S. Kumar. On the convergence of adam and beyond. In International Conference on
Learning Representations, 2018.
U. Shaham, Y. Yamada, and S. Negahban. Understanding adversarial training: Increasing local stability of
supervised models through robust optimization. Neurocomputing, 2018.
O.	Shamir. An optimal algorithm for bandit and zero-order convex optimization with two-point feedback.
Journal of Machine Learning Research, 18(52):1-11, 2017.
C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing properties of
neural networks. arXiv preprint arXiv:1312.6199, 2013.
C.-C. Tu, P. Ting, P.-Y. Chen, S. Liu, H. Zhang, J. Yi, C.-J. Hsieh, and S.-M. Cheng. Autozoom:
Autoencoder-based zeroth order optimization method for attacking black-box neural networks. arXiv preprint
arXiv:1805.11770, 2018.
Y. Wang, S. Du, S. Balakrishnan, and A. Singh. Stochastic zeroth-order optimization in high dimensions. In
Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics, volume 84,
pp. 1356-1365. PMLR, April 2018.
P.	Xu, F. Roosta-Khorasan, and M. W. Mahoney. Second-order optimization for non-convex machine learning:
An empirical study. arXiv preprint arXiv:1708.07827, 2017.
12
Published as a conference paper at ICLR 2019
Appendix
1 M otivating Examples of Fast Convergence of ZO-signSGD
1.1	Example of sparse noise perturbation
We consider to minimize the function f (x) = 1 ∣∣xk2. Similar to (Bernstein et al., 2018, FigUre A.1), We assume
that the ZO gradient estimate of f (x) and its first-order gradient Vf (x) = X suffer from a sparse noise vector v,
where v1 ∈ N (0, 1002), and vi = 0 for i ≥ 2. As a result, the used descent direction at iteration t is given by
Vf (Xt) + V or Vf (Xt) + v. Fig. A1 presents the convergence performance of 5 algorithms: SGD, signSGD,
ZO-SGD, ZO-signSGD and its variant using the central difference based gradient estimator (10). Here we
tune a constant learning rate finding 0.001 best for SGD and ZO-SGD and 0.01 best for signSGD and its ZO
variants. As we can see, sign-based first-order and ZO algorithms converge much faster than the stochastic
gradient-based descent algorithms. This is not surprising since the presence of extremely noisy component v1
leads to an inaccurate gradient value, and thus degrades the convergence of SGD and ZO-SGD. By contrast,
the sign information is more robust to outliers and thus leads to better convergence performance of sign SGD
and its variants. We also note that the convergence trajectory of ZO-signSGD using the gradient estimator (10)
coincides with that using the gradient estimator (3) given by the forward difference of two function values.
Figure A1: Comparison of different gradient-based and gradient sign-based first-order and ZO algorithms
in the example of sparse noise perturbation. The solid line represents the loss averaged over 10 independent
trials with random initialization, and the shaded region indicates the standard deviation of results over random
trials. Left: Loss value against iterations for SGD, signSGD, ZO-SGD, ZO-signSGD and ZO-signSGD using
the central difference based gradient estimator (10). Right: Local regions to highlight the effect of the gradient
estimators (3) and (10) on the convergence of ZO-signSGD.
1.2	Statistics of gradient estimates
The intuition behind why ZO-signSGD could outperform ZO-SGD is that the sign operation can mitigate the
negative effect of (coordinate-wise) gradient noise of large variance. To confirm this point, we examine the
coordinate-wise variance of gradient noises during an entire training run of the binary classifier provided in the
first experiment of Sec. 6. At each iteration, we perform an additional 100 random trials to obtain the statistics
of gradient estimates. In Fig. A2-(a), we present the `1 norm of the mean of gradient estimates (over 100 trials)
versus the number of iterations. As we can see, both signSGD and ZO-signSGD outperform SGD and ZO-SGD,
evidenced by a fast decrease of the `1 norm of gradient estimate. In Fig. A2-(b), we present the coordinate-wise
gradient noise variance (over 100 trails at each coordinate) against the number of iterations. It is not surprising
that compared to first-order methods, ZO methods suffer gradient noise of larger variance. In this scenario, we
could benefit from ZO-signSGD since taking the sign of gradient estimates might scale down extremely noisy
components. Indeed, we observe a significant decrease of the noise variance while performing ZO-signSGD
compared to ZO-SGD.
13
Published as a conference paper at ICLR 2019
Mpe-Iu JO E」OU I，
(υ3UE∙≡e>(L)SOU MP(c」0
0.02 -
0.12 -
0.10 -
0.08-
0.06-
0.04-
(a)	(b)
Figure A2: Statistics of gradient estimates during an entire training run of the binary classifier provided in the
first experiment of Sec. 6. a) The `1 norm of the mean of gradient estimates versus iteration. b) Coordinate-wise
gradient noise variance versus iteration. The solid line represents the variance averaged over all coordinates, and
the shaded region indicates the corresponding standard deviation with respect to all coordinates at each iteration.
2	Proof of Proposition 1
Based on the definition of the smoothing function fμ, for any X and y We have
l∣Vfμ(x) - Vfμ(y)k2 =IlEv[Vxf(x + μV)- Vyf(y + μV)]∣∣2
≤E[kVχf(x + μv) - Vyf(y + μv)k2] ≤ Lkx - y∣∣2,	(15)
Where the first inequality holds due to Jensen’s inequality, and the second inequality holds due to A1. It is knoWn
from (15) that fμ has L-LiPsChitz continuous gradient.
By the L-smoothness of fμ, we obtain that
fμ (xk + l) ≤fμ(xk) + hVfμ(xk), xk+1 — xk)+ IL ∣∣xk + 1 — xk ∣∣2
= fμ(xk) — δk hVfμ(xk), sign(gk )i + L δ2 Ilsign(gk)k2
= fμ(xk ) - δk ||VfH (Xk)III +-k2—
d
+ 2δk X ∣(Vfμ(xk))i∣I [sign(gk,i) = sign((Vfμ(xk))i)] ,	(16)
i=1
where (Vfμ(x))i denotes the ith element of Vfμ(x).
Taking exPectation for both sides of (16), we obtain that
E[fμ(xk + 1 ) - fμ(Xk)] ≤ - 6k||VfH(Xk)IlI +-:—
d
+ 2δk X ∣(Vfμ(xk))i∣Prob [sign(gk,i) = sign((Vfμ(xk))i)] .	(17)
i=1
Similar to (Bernstein et al., 2018, Theorem 1), we relax Prob [sign(gk,i) = sign((Vfμ(xk))i)] by Markov's
inequality,
Prob [sign(^k,i) =sign((Vfμ(xk))i)] ≤Prob[∣^k,i — (Vfμ(Xk))i| ≥ ∣(Vfμ(xk))i|]
≤ E[|gk,i — (V-(xk ))i|]
≤	l(Vfμ(Xk))i∣	.
(18)
14
Published as a conference paper at ICLR 2019
Substituting (18) into (17), we obtain
E[fμ (Xk+1)- fμ (Xk )] ≤ - δk kVfμ(xk )k1 +-'-+ 2δk ^X E[| gk,i - ^fμ (Xk ))i|]
i=1
=-δkkvfμ (Xk )k1 +--k2--+ 2δkE[kgk - V fμ(Xk )k1]
≤ - δkkvfμ(Xk )k1 +-k2--+ 2δk√dE[kgk - vfμ (Xk ) k2]
≤-δkkVfμ(Xk)kι + δk2L +2δk√dqE[∣∣gk -Vfμ(Xk)k2],	(19)
where the second inequality holds due to |因卜 ≤ VzdkXk2, and the last inequality holds by applying Jensen's
inequality to the concave function √∙, i.e., E[∣∣gk — Vfμ(Xk)∣∣2] ≤ pE[∣∣gk — Vfμ(Xk)k2].
Taking sum of both sides of (19), we then obtain (5).
3 Proof of Proposition 2
We recall from (3) that
1	1q
gk = b E Vfi(Xk), Vfi(Xk) = q 5^Vfi(Xk； Ui,j).	(20)
τ ,	C /	∖	τ-! C /	∖	1	C /	∖	τ-! f /	∖ mi
Let Zi := Vfi(Xk) — Vfμ(Xk) and zi,j = Vfi(Xk; ui,j) — Vfμ(Xk). Thus,
gk- Vfμ(Xk) = b X Zi = bq X X zi,j	(21)
i∈Ik	q i∈Ik j=1
where there are two sources of randomness: a) minibatch sampling i ∈ Ik, and b) the random direction sampling
u = ui,j. Note that these two sources of randomness are independent, and the random direction samples {ui,j}
are i.i.d..
Next, we discuss two types of mini-batch sampling: a) mini-batch samples without replacement, and b) mini-
batch samples with replacement.
Suppose that Ik is a uniform random subset of [n] (no replacement), motivated by (Lei et al., 2017, Lemma A.1)
we introduce a new variable Wi = I(i ∈ Ik), where I is an indicator function, and I(i ∈ Ik) = 1 if i ∈ Ik,
and 0 otherwise. As a result, we have
E[Wi2] = E[Wi] = b,	E[WiWj] = b(b — 1) , i = j.	(22)
n	n(n — 1)
From (21), the variance of gk is given by
T bb	XEu[kzik2]+	b(b —	1)	XEu[zi]	—	b(b-	1)	X kEu[zi]∣∣2!
b2 1n± u i	+ n(n — 1) 士	i∖	九仇—u )
nn
=ɪ XEu[kzik2] - h( 1 X kEu[zi]k2
bn	b(n — 1)n
nnn
=bnX Eu[kzik2]—b(n∈⅛ X Eu[kzik2]+b(n-ιnX(5㈤冏一画印2)
(b) n b 1 n	b 1 n
= (n—l) bn X Eu[kzik2 ] + 如F X Eu[kV fi(Xk) - Vfw(Xk)k2].
(23)
In (23), the equality ⑶ holds since Eu[z" = Vfi,μ(Xk) — Vfμ(Xk) and fμ(X) = 1 Pi=ι fi,μ(X from (4),
where we have used the fact that Eu[Vfi(Xk)] = Vfi,μ(Xk) (LiU et al., 2018c, Lemma. 1), and recall that fi,μ
denotes the smoothing function of fi. The above implies that pn=ι Eu[z" = Pi Vfi,μ(Xk) — nVfμ(Xk) = 0.
And the equality (b) holds due to Eu [kzi k22] — kEu [zi]k22 = Eu kzi — Eu [zi]k22 .
15
Published as a conference paper at ICLR 2019
On the other hand, suppose that the mini-batch Ik contains i.i.d. samples (namely, with replacement), the vectors
{zi } are then i.i.d. under both mini-batch sampling and random direction sampling. Therefore, we obtain that
2
E
1X
zi
i∈Ik
b E X ι∣zik2
i∈Ik
+ E	hzi,zji
i6=j,i,j∈Ik
1	1n
=1 Eu[Ei∈ik [kzik2]] = bn X Eu[kzik2 ],
n i=1
(24)
where the second equality holds since Ei∈ik,u[zi] = 1 Pi=ι Eu[zi] = 1 Pi=ι Vfi,μ(xk) - Vfμ(xk) = 0.
Combining both (23) and (24), we obtain that
E
1 X Zill	≤ αb X Eu[kZik2] + bn X Eu[kV fi(Xk) -Vfi,μ(Xk)k2].
i∈Ik	2	i=1	i=1
(25)
In (25), αb = 1 and βb = 0 if the mini-batch contains i.i.d. samples from [n] with replacement, and
αb = I(1 < n) and βb = I(1 > 1) if samples are randomly selected without replacement.
In (25), we next bound 1 Pi Eu[∣∣Zi∣∣2],
n	nq
-XEu[∣Zik2] (=)-XEu	-XZi,j
n	n	q
i=1	i=1	j=1
Eu[ιzi,jι22] +	hEu[zi,j],Eu[zi,k]i
j	j 6=k
ι22] + (q2 - q)ιEu[zi,1]ι22
ιEu [zi,1]ι22,
i
(26)
where we have used the facts that Eu [zi,j] = Eu[zi,1] and Eu[ιzi,j ι22] = Eu[ιzi,1ι22] for any j since random
direction vectors {ui,j }jq=1 are i.i.d. samples.
In (26), we further bound Pi Eu [ιzi,1ι22],
n X Eu[kZi,1 k2] = 1 X EukV fi(Xk ； Ui,1) - Vfμ(Xk )k2
ii
=1 X Eu[kVfi- Vfi,μ + Vfi,μ - Vfμk2]
n
i
22
≤ n £Eu[kV fi- Vfi,μ∣2] + n E kVfi,μ — Vfμ∣2,	(27)
ii
where for ease of notation, let V f := Vfi(xk； Ui,ι), Vfi,μ := Vfi,μ(xk) and Vfμ := Vfμ(xk). According
to (Liu et al., 2018c, Lemma 1), the first term at RHS of (27) yields
2 22	2 22
Eu[kVfi- Vfiμk2] ≤ 2d∣Vfik2 + μτ2- ≤ 2dσ2 + μτ2- := C(d,μ),	(28)
where the last inequality holds due to A2. Based on the definition of fμ,the second term at RHS of (27) yields
1 X kVfi,μ - Vfμk2 = - X kEv[Vfi(xk + μv) - Vf (Xk + μv)]k2
≤1 XEv[∣∣Vfi(xk + μv) - Vf(Xk + μv)k2] ≤ 4σ2,	(29)
n
i
where we have used the Jensen,s inequality and 1 Pn=IkVfi(X) — Vf (x)k2 ≤ 4σ2 under A2.
Substituting (28) and (29) into (27), we have
-X Eu[∣Zi,1k2] = 1 X Eu[kV fi-Vf"k2] ≤ 4dσ2 + μ2L2d2 +8σ2 = 2C(d,μ) + 8σ2,	(30)
ii
where C(d, μ) was defined in (28).
16
Published as a conference paper at ICLR 2019
We are now ready to bound (26). Based on 1 PikEu[zi,ι] k2 = 1 PiII▽/" - Vfμk2 ≤ 4σ2 from (29), and
substituting (30) into (26), we obtain that
n χ Eu[∣zik2 ] ≤
i
2C(d, μ) + 8σ2	4(q — 1)σ2
q	q
(31)
In (25), We also need to bound Eu[∣∣Vfi(xk) - Vfi,μ(xk)∣∣2]
q
Eu	∣∣V fi(xk) - VfE(Xk )∣∣J (=) Eu	- X (V fi(x; Ui,j) - Vfi,μ(x))
=)1 Eu
q
Vfi(x; Ui,1) - Vfi,μ(x)∣∣j
(28) 1" + 中)=安
(32)
1	,1	T1 / ∖ 1 11	∙	τπ Γ C /	∖ 1	τ~~7 c ∕∖c	∙	∙	1 /ɪ ∙	,1 CCrC
where the equality (a) holds since Eu[Vfi(x; Ui,j)] = Vfi,μ(x) for any j, given by (LiU et al., 2018c,
Lemma 1).
Substituting (31) and (32) into (25)
E [kgk -Vfμ(xk)∣∣2] = E
1「 ∣∣ ] Jab 2C(d,μ) +4σ2 +4σ2q	βbC(d,μ)
b i∈Ik zM ≤ 万	q +
= 4ɑ") σ2 + C^(2a + βb).
bq	bq
(33)
4 Proof of Theorem 1
Substituting (6) into (5), we obtain
T-1
E X δk∣∣Vfμ(xk)∣ι
k=0
T-1
≤E[fμ(xθ) - fμ(xτ)] + X
k=0
T1
+ dL X δk.
2 k=0
一 √d ,——;------:——_	.,-------
2δk	ʌ/4αb(q + 1)σ2 + C(d, μ)(2ab + βb)
bq
(34)
It is known from (Liu et al., 2018c, Lemma 1) that
kVf(x)k2 ≤ 2kVfμ(x)k2 + μLd-, ∣fμ(x) -f(x)∣≤ μ-L.	(35)
From(35)wehavefμ(xo)-f(xo) ≤ μ2L and f *-f； ≤ μ2L ,where f； =minχ fμ(x) and f * =minχf(x).
This yields fμ(xo) - f (xo) + f * - f； ≤ μ2L, and thus
fμ(xo) - fμ(xτ) ≤ fμ(xo) - f1 ≤ (f(x。)- f')+ jL	(36)
Substituting (36) into (34), we obtain
T-1
E X δk∣Vfμ(xk)kι
k=0
≤E[f (XO)- f * )] + μ2 l
T-1
+X
k=0
ʌ/d	l----:----：  -----:--------------
2δk Zr- 4a4ab(q + 1)σ+ C(d, μ)(2ab + 仇)
bq
T-1
+ dL X δ2.
2 k=0
(37)
Due to ∣∣Vfμ(xk)∣2 ≤ ∣∣Vfμ(xk)∣ι and dividing PT-CI δk for both sides of (37), we obtain that
E
T-1
X
k=C
δk
PT-(I δk
kVfμ (xk )∣2
≤ f(x0匕f1 + μ2L + 竺P4ab(q + 1)σ2 + C(d, μ)(2ab + βb)
ET-(I δk	√bq
+ dL PT-1 δ2
2 PT-(I δk.
(38)
17
Published as a conference paper at ICLR 2019
By introducing the random variable R With probability P(R = k) = τ--, We then obtain that
k=0 δk
T-1
E[Wfμ(xR)k2] = E[ER[∣Nfμ(xR)k2]]= E X P(R = k)kVfμ(Xk)k2 .	(39)
k=0
Based on (35), We further have
E [kVf(xR)k2] ≤E y4kVfμ(xR)k2 + μ2L竺
≤√2E[kVfμ(xR)k2] + μLd,	(40)
2
where We have used the fact that √α2 + b2 ≤ (a + b) for a, b ≥ 0.
Substituting (38) and (39) into (40), We finally obtain (8).
5 Proof of Corollary 1
Upon defining Vfi(x; U) = dfi(x+μu)-fi(x-μu)]u (against Vfi(x; U) in (3)), our major task is to derive the
1-	.	1	1	1	.	l' ɪɪ7 C /	∖
first- and second-order moments of Vfi (x; U).
Given x, We first study the mean of Vfi (x; U),
Eu [Vfi(x; u)i = Eu
Lfi(X + μu) — fi(x — μu))u
2μ
=Eu Trfi(X + μu)u + Eu —fi(x — μυ)(-u) =) Eu -fi(x + μu)u
L2μ	」 L2μ	」	Lμ
=Eu - (fi(x + μu) — fi(x)) U = EuhVfi(x; u)i = Vfi,μ(x),
(41)
Where (a) holds since the distribution of U is symmetric around the origin, (b) holds since E[U] = 0, and (c)
holds since Vfi,μ(x) = Eu ∖ffi(x + μu)u] obtained from (Gao et al., 2014, Lemma4.1). It is clear from
(41) that Eu [Vfi(x; u)] = EuhVfi(x; u)].
<τr	,	,	1	,1	1	1	, c- ∙τ-^-r l∙ /	∖
We next study the second-order moment of Vfi (x; u),
EuhkVfi(x; u)k2i = 4-22Eu [(fi(x + μu) — fi(x — μu))2kuk2]
-2
≤2μ2Eu [(fi(x + μu) — fi(x)) + (fi(x) — fi(x — μu))2]
=Eu
-(fi(x + μu) — fi(X))UH = EuhkVfi(x; u)k2i ,
(42)
Where We have used the fact that kUk2 = 1.
Based on (41) and (42), We can conclude that both (3) and (10) maintain the same statistical properties. FolloWing
the proofs of Proposition 2 and Theorem 1, it is not difficult to reach the convergence rate in (8).
6 Proof of Corollary 2
- .Sd ʌ „ ,	、一	-	.	.-.Sd. 一一.	-	-
Let gkj := Vfi(Xk； ui,j). If we replace gk with g『in (18), we then have
|(Vf“(Xk))i|Prob hsignG⅛j) = Sign((Vfμ(xk))1)] ≤E[mk,,j — (Vf“(Xk))1U,	(43)
where gk,j is the lth coordinate of gɪ,j.
By letting b = 1 and q = 1 in Proposition 2, we know that E [∣∣gk,j — Vfμ(xk )k2] is upper bounded. Moreover,
by Jensen’s inequality we have
E[∣^k,,j — (Vfμ(xk))ι∣] ≤ qE[(^k,j — (Vfμ(Xk))1)2] := ξl,	(44)
18
Published as a conference paper at ICLR 2019
where ξl is finite since E [k^k,j - Vfμ(xfc)∣∣2] isupperbounded.
Substituting (44) into (43), we have
∣(Vfμ(xfc))ι∣ Prob [sign(^k,,j) = Sign((Vfμ(xk))川 ≤ξι.	(45)
With the new gradient estimate gk = PiETk Pq=ι sign(gk,j) in (11), We require to bound
Prob [sign(^k,ι) = Sign((Vfμ(xk))ι)] ,	(46)
where gk,ι is the lth coordinate of gk.
We recall that gk,j is an unbiased stochastic approximation to gradient component (Vfμ (Xk)) ι with variance ξ2.
Under the assumption that the noise distribution is unimodal and symmetric, we know from (Bernstein et al.,
2018, Lemma D1) that
2	2	ι	s > _2_	ι
Prob [sign(襦)= Sign((Vfμ(xk H	= Q ≤∣	1S2 篇	otherwise	< 2，
(47)
where S := ∣(Vfμ(xk))ι∣∕ξι.
Let Z count the number of estimates {^k,j} yielding the correct sign of ((Vfμ(xk))ι. Thus, the probability of
error in (46) is equal to
Prob [sign(gk,ι) = Sign((Vfμ(xk))ι)] = Prob Z ≤ bq
(48)
Following the proof of (Bernstein et al., 2018, Theorem 2b) under (47), it is not difficult to obtain that
That is,
Prob Z ≤ bq
-2
≤√bqS.
I(Vfμ(χk沏PMgnOMinE(Xk))l)]≤ 篇.
(49)
(50)
Replace gk with gk in (17), we obtain that
E[fμ(xk + 1) - fμ (Xk )] ≤ - 6kkVfH (Xk )k1 +-k2~
d
+ 2δk X ∣(Vfμ(xk))ι∣Prob [sign(gk,ι) = Sign((Vfμ(xk))ι)]
l=1
(50)	δ2dL	1
≤ - δkkVfμ (Xk )kι + δk2dL +2δk √bq kξkι
≤ - 6kkVfH (Xk )k1 + -k2- + 2δk √bq q kξk2
(=) - δkkVfμ(Xk)kι + δkdL + 2δk√bqqE[k^k,j -Vfμ(Xk)k2].	(51)
Compared (51) with (19), the standard deviation jE[∣∣gk,j — Vfμ(Xk)k2]
According to Proposition 2, let b = q = 1, we obtain
is reduced by the factor 1∕√bq.
E h∣∣gk,j - Vfμ(Xk)k2i ≤8αbσ2 + (2αb + βb)C(d,μ).
Based on (51)-(52) and following the proof of Theorem 1, we have
E [kVf (XR)k2] ≤ √2f(X03f； + “2L
k=0 δk
2√2√d /-------5---ʒ-ʒ一r7-------丁 dL PT-0" δ2 μLd
+----^W=- V8αbσ2 + C (d,μ)(2αb + βb) +—-7=	τ-ι	+---,=-,
bq	2	kT=-01 δk 2
where C(d,μ) := 2dσ2 + μ2L2d2∕2.
If μ = O(√=) and δk = O(√=), then the convergence rate simplifies to O(√d + √d=).
(52)
(53)
19
Published as a conference paper at ICLR 2019
7 Proof of Corollary 3
Let gm := bmmq Pi∈ιm,k Pq=1 ξ7f<xk Uij) and gk = M PM=I sign(gm). Following (43)-(50), We can
similarly obtain that
|(Vfμ(xfc))11 Prob [sign(gk,ι) ≠sign((Vfμ(xfc))ι)] ≤ -ξ=,	(54)
where ξ := jE[(^mι — (Vfμ(xk))ι)2]. By mimicking the derivation in (51), we have
E[fμ(xk+ι) — fμ(xk)] ≤ —δkkVfμ(xk)kι + 斗 + 2δfc条 jE[∣∣gm -Vf“(x)k2].	(55)
2M
According to Proposition 2, let b = bn/M c, we obtain
E [kgm — Vfμ(xfc)k2] ≤4(qb+ 1)σ2 + bqC(d,μ).	(56)
Based on (55)-(56) and following the proof of Theorem 1, we have
E [kVf (xr)k2] ≤ √2f (XcPT f + “2L
k=0 δk
, 2√2√d PM	, dL PT-(I δ2	μLd
+ VW 4(q+ + 1)σ +3C(d,μ)+ √2 PT-(I δk + √2,	()
where C(d,μ) := 2dσ2 + μ2L2d2∕2.
Since μ = O(√dT), δk = O(√dT) and bM ≈ n, then the convergence rate simplifies to O(√√T + √d + √⅛q).
8 Supplemental Experiments
8.1	Synthetic experiments
In Fig. A3, we demonstrate the effect of the learning rate δ on the training loss of SGD, signSGD, ZO-SGD,
ZO-SCD, ZO-signSGD and ZO-M-signSGD. We observe that compared to the gradient-based algorithms (SGD,
ZO-SGD and ZO-SCD), the gradient sign-based algorithms support a more flexible choice of learning rates
(corresponding to less variance), since the sign operation has an normalization effect to reduce oscillations
in convergence. We find δ = 0.1 best for SGD, δ = 0.009 best for signSGD, δ = 0.1 best for ZOSGD and
ZOSCD, δ = 0.0178 best for ZOsignSGD, andδ = 0.0501 best for ZO-M-signSGD.
Figure A3: The training loss at the last iteration versus the constant learning rate δ ∈ [10-3, 0.1]. Here the
solid line represents the loss averaged over 10 independent trials with random initialization, and the shaded
region indicates the standard deviation of results over random trials.
20
Published as a conference paper at ICLR 2019
8.2	Black-box attack formulation
The target DNN classifier F = [F1 , F2 , . . . , FK] takes an image as an input and produces the classification
predictions (here the probability distribution) of K image classes, where Fk denotes the prediction of class k.
Given F , an adversarial example x of a legitimate example x0 means it is visually similar to x0 but will yield a
different top-1 prediction than x0 .
Let (x0 , t0) denote a legitimate image x0 and its groundtruth label t0 ∈ {1, 2, . . . , K}. Without loss of
generality, we assume the pixel value range of x0 lies within [-0.5, 0.5]d. By using the tanh transformation on
the adversarial image x such that x = tanh(w)/2, where w ∈ Rd, we adopt the untargeted black-box attacking
loss designed in (Chen et al., 2017), which is defined as
minimize c ∙ max {log Ft0 (tanh(w)∕2) — max log Fj (tanh(w)∕2), 0} + ∣∣ tanh(w)∕2 — xo∣∣2,	(58)
w∈Rd	j6=t0
where c is a regularization coefficient and x = tanh(w)/2 ensures x lies within the valid image space
[—0.5, 0.5]d. The first term in the attacking objective is a hinge loss function that penalizes the top-1 prediction
of X being to. The log F(∙) operation preserves the class prediction ranking and better handles numerical
stability. The second term encourages the visual similarity between x and x0 through penalizing their squared `2
difference (i.e., the squared distortion). In our experiment, we set c = 1 for MNIST and c = 0.1 for CIFAR-10.
We also note that different from the use of signed gradients in existing black-box attacks (e.g., Ilyas et al. (2018a);
Bhagoji et al. (2018)) due to the explicit '∞ perturbation constraint, the use and benefit of ZO-SignSGD for
solving (58) in our experiment are non-trivial since the attacking objective does not impose any '∞ constraint.
8.3	Additional black-box attacking results on MNIST and CIFAR- 1 0
Table A1: First successful adversarial examples attacking black-box DNN on MNIST.
ImageID 3	2	38	44	4	15	21	34	177	7
Original
Classified as
0123456789
21
Published as a conference paper at ICLR 2019
Table A2: First successful adversarial examples attacking black-box DNN on CIFAR-10.
25
5
Image ID
10
6
68
17
1
28
36	33
ZO-signSGD

truck
automobile
truck
Classified as bird
蟠戚iΛ
dog horse cat cat dog truck
Table A3: Iteration comparison of attacking black-box DNN on MNIST (image ID 177).
Iteration 0	30	60	90	120	162	181	210	241	271
Iteration 0	30	60	90	120	150	180	198	240	271
22
Published as a conference paper at ICLR 2019
(d) MNIST-image ID 15
(e) MNIST - image ID 21
(f) MNIST - image ID 38
(g) MNIST - image ID 44
(h) MNIST - image ID 177
Figure A4: Additional plots of black-box attacking loss versus iteration on MNIST. The solid marker indicates
the iteration number that finds the first successful adversarial example, and its loss corresponds to the squared `2
distortion.
23
Published as a conference paper at ICLR 2019
(a) CIFAR-10-image ID 1
(b) CIFAR-10 - image ID 5
(C) CIFAR-10 - image ID 17
(d) CIFAR-10 - image ID 25
(e) CIFAR-10 - image ID 28
(f) CIFAR-10 - image ID 33
(g) CIFAR-10 - image ID 36
(h) CIFAR-10 - image ID 68
Figure A5: Additional plots of black-box attacking loss versus iteration on CIFAR-10. The solid marker
indicates the iteration number that finds the first successful adversarial example, and its loss corresponds to the
squared `2 distortion.
24