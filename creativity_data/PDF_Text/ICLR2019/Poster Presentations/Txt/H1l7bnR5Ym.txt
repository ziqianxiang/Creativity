Published as a conference paper at ICLR 2019
Prob GAN: Towards Probabilistic GAN
with Theoretical Guarantees
Hao He, Hao Wang, Guang-He Lee, Yonglong Tian
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
{haohe,hwang87,guanghe,yonglong}@mit.edu
Ab stract
Probabilistic modelling is a principled framework to perform model aggregation,
which has been a primary mechanism to combat mode collapse in the context of
Generative Adversarial Networks (GAN). In this paper, we propose a novel prob-
abilistic framework for GANs, ProbGAN, which iteratively learns a distribution
over generators with a carefully crafted prior. Learning is efficiently triggered by a
tailored stochastic gradient Hamiltonian Monte Carlo with a novel gradient approx-
imation to perform Bayesian inference. Our theoretical analysis further reveals that
our treatment is the first probabilistic framework that yields an equilibrium where
generator distributions are faithful to the data distribution. Empirical evidence
on synthetic high-dimensional multi-modal data and image databases (CIFAR-10,
STL-10, and ImageNet) demonstrates the superiority of our method over both
start-of-the-art multi-generator GANs and other probabilistic treatment for GANs.
1	Introduction
Generative Adversarial Networks (GAN) (Goodfellow et al., 2014) is notoriously hard to train
and suffers from mode collapse. There has been a series of works attempting to address these
issues. One noticeable thread focuses on objective design, which improves the original Jensen-
Shannon divergence with more stable pseudo-metrics such as f -divergence (Nowozin et al., 2016),
χ2-divergence (Mao et al., 2017), and Wasserstein distance (Arjovsky et al., 2017). However, such
treatment is inherently limited when a single generator does not include enough model capacity to
capture the granularity in data distribution in practice. Clearly, such a generator can hardly produce
accurate samples regardless of the choice of objectives.
An alternative remedy is to learn multiple generators instead of a single one. This type of meth-
ods (Hoang et al., 2018; Tolstikhin et al., 2017; Wang et al., 2016b) is motivated by a straightforward
intuition that multiple generators can better model multi-modal distributions since each generator
only needs to capture a subset of the modes. To entail model aggregation, probabilistic modelling is a
natural and principled framework to articulate the aggregation process.
Recently, Saatci & Wilson (2017) propose Bayesian GAN, a probabilistic framework for GAN
under Bayesian inference. It shows that modelling the distribution of generator helps alleviate mode
collapse and motivates the interpretability of the learned generators. This probabilistic framework is
built upon Bayesian models for generator and discriminator, whose maximum likelihood estimation
can be realized as a metaphor of typical GAN objectives.
While empirical study on semi-supervised image classification tasks shows the effectiveness of
Bayesian GAN, a critical theoretical question on this framework remains unanswered: Does it really
converge to the generator distribution that produces the real data distribution? Indeed, our theoretical
analysis and experimental results on a simple toy dataset reveal that the current Bayesian GAN falls
short of convergence guarantee.
With this observation, we follow the prior work to exploit probabilistic modelling as a principled
way to realize model aggregation, but approach this problem from a theoretical perspective. We
analyze the developed treatment, including the choice of priors, approximate inference, as well as its
1
Published as a conference paper at ICLR 2019
Table 1: Common GAN objective functions.
	φ1 (D)	φ2(D)	φ3(D)	Min-max S tyle
GAN (min-max)	log(D)	log(1 - D)	- log(1 - D)	Yes
GAN (non-saturating)	log(D)	log(1 - D)	log(D)	NO
Wasserstein GAN	D	-D	D	Yes
Least-Squares GAN	(D-1)2	D2	(D-1)2	NO
convergence property, and simultaneously propose a new probabilistic framework with the desirable
convergence guarantee and consequently superior empirical performance.
Our main contributions are:
•	We theoretically establish, to our best knowledge, the first probabilistic treatment of GANs
such that any generator distribution faithful to the data distribution is an equilibrium.
•	We prove the previous Bayesian method (Saatci & Wilson, 2017) for any minimax GAN
objective induces incompatibility of its defined conditional distributions.
•	We propose two special Monte Carlo inference algorithms for our probabilistic model which
efficiently approximate the gradient of a non-differentiable criterion.
•	Empirical studies on synthetic high-dimensional multi-modal data and benchmark image
datasets, CIFAR-10, STL-10, and ImageNet, demonstrate the superiority of the proposed
framework over the state-of-the-art GAN methods.
2	Related Work
Generative Adversarial Networks is a powerful class of methods to learn a generative model for
any complex target data distribution. There is a game between a generator and a discriminator. Both
of them adapt their strategies to maximize their own objective function involving the other:
mθax jd(θd; θg ) = Ex 〜Pdata[φ1 (D(X； θd)D] + Ex 〜pgen(<θg)[φ2(D(X； θd ))],
max jg (θg ； θd) = Ex〜pgen(<θg )[φ3 (D(X； θd))].
θg
(1)
Eqn. 1 gives a general mathematical form where Pdata is real data distribution and pgen(∙; θg)
are generated data distribution with generator parameter θg. The objective functions φ1 , φ2, φ3
(termed as GAN objective in this paper) are elaborately chosen such that at the equilibrium, the
generator generates the target data distribution. Table 1 summarizes several widely used GAN
objectives, including the original min-max version, non-saturating version of original GAN (Good-
fellow (2016)), LSGAN (Mao et al. (2017)), and WGAN (Arjovsky et al. (2017)). As reported in
Table 1, some GAN objectives, satisfying φ3(∙) = -φ2 (∙), actually represent a min-max game, i.e.
minθg maxθg Jd(θd; θg).
Training GAN with multiple generators is considered in several recent works to mitigate the mode
collapse problem. In the spirit of boosting algorithm, Wang et al. (2016b) propose to progressively
train new generator using a subset of training data that are not well captured by previous generators,
while Tolstikhin et al. (2017) further propose a more robust mechanism to reweight samples in the
training set for a new generator. From the perspective of game theory, MIX-GAN (Arora et al.,
2017) extends the game between a single generator and discriminator to the multiple-player setting.
Other works resort to third-party classifiers to help multiple generators and discriminators achieve
better equilibrium, such as MAD-GAN (Ghosh et al., 2017) and the recent state-of-art method,
MGAN (Hoang et al., 2018).
Bayesian GAN proposed by Saatci & Wilson (2017) adopts a different approach which models
generator and discriminator distributions by defining the conditional posteriors (Eqn. 8). The
likelihood model is specially designed such that maximizing it exactly corresponds to optimizing
GAN objectives. The authors argue that compare to point mass ML estimation, learning the generator
distribution which is multi-modal itself offers better ability to fit a multi-modal data distribution.
To facilitate discussion, we categorize GAN frameworks into the following taxonomy: optimization-
based methods and probabilistic methods. Optimization-based methods set up an explicit mini-max
game between the generator and discriminator, where an ideal equilibrium typically characterize
a generator faithful to data distribution. In probabilistic methods, generators and discriminators
2
Published as a conference paper at ICLR 2019
evolve as particles of underlying distributions, where an equilibrium is searched from a stochastic
exploration in the distribution space (of the generators and discriminators).
3	Methodology
We first summarize the notations. Second, we elaborate ProbGAN, our probabilistic modelling
for GAN, and introduce its Bayesian interpretation by developing constituent prior and likelihood
formulations. Finally, we develop inference algorithms for ProbGAN. A detailed discussion of the
motivation of our modelling and the comparison with Bayesian GAN is included in Section 4.
3.1	Notations
pdata (x) over a sample space X is the target data distribution we want to learn. Our generator
and discriminator are parameterized by θg ∈ Θg and θd ∈ Θd. A generator with parameter θg
defines a mapping from a random noise vector Z 〜Pz to a random vector G(z; θg). The induced
probability density of G(z; θg) is denoted as pgen (x; θg). A discriminator is a function that maps
data to a real-valued score, i.e. D(x; θd) : X → [0, 1] (or X → R in some settings). Further, we
use qg(θg) ∈ PΘg, qd(θd) ∈ PΘd to denote the distribution over generators and discriminators
respectively.
The total data distribution generated by generator following the density qg(θg) is naturally a mixture
of data distribution given by every single generator, Pmodel(x; q§) = Eθg〜qg(θg)[Pgen(x; θg)].OUr
goal is to find a generator distribution qg(θg) such that the total generated data distribution matches
our target, i.e. Pmodel(x; qg) ` Pdata(x).
Jg(θg; θd) and Jd(θd; θg) denote objective functions of generator and discriminator as introduced
in Eqn. 1. The common choices1 are listed in Table 1. With a slight abuse of the notation, we
extend the notation Jg(θg; D*) by replacing D(x; θd) in equation 1 with any score function D*.
Then Jg(θg; θd) can be viewed as an abbreviation of Jg(θg; D(∙; θd)). Likewise, Jd(θd;Pgen(∙))
represents discriminator objective given a virtual generator that generates data with density Pgenq).
3.2	PROBGAN
Like Bayesian GAN, ProbGAN learns distributions of the generator and the discriminator. During
training, the target data distribution is given (by samples) and treated as an fixed environment. While
for the generator/discriminator, they observe each other and adapt their own parameters based on
the observation. To facilitate the comparison to Bayesian GAN, we state ProbGAN in a Bayesian
formulation. Every generator/discriminator distribution update can be viewed as the following
posterior inference process.
Posterior. ProbGAN updates generator/discriminator distributions based on their distributions in
previous time step and the target data distribution as shown in Eqn. 2. We we denote qg(t) and qd(t) as
distributions at time step t.
qgt+1)(θg) (X exp{Jg(θg;D㈤)}∙ qgt)(θg), qdt+1)(θd) (X exp{Jd(θd;Pm)odel)}.	⑵
To understand it is a posterior modelling, we further interpret the terms in Eqn. 2 as likelihood term
and prior term seperately.
Likelihood. We call the exponential terms in Eqn. 2 as likelihood terms.
P(θg) X exP{Jg(θg; D(t))}, P(θd) X eχp{Jd(θd;Pmode吊.	⑶
wherePmodel(X) = E° 〜勺⑴[Pgen(x; θg)] is the mixed data distribution under the current generator
distribution qgt) and D(t)(∙) = Eθ^〜勺⑴ [D(∙; θd)] is the averaged discriminating score function under
current discriminator distribution qd(t).
1 The concepts of minimax version and non-saturating version of vanilla GAN are first introduced in Good-
fellow (2016).
3
Published as a conference paper at ICLR 2019
These likelihoods indicate a preference for generators and discriminators, given current distributions
of generator and discriminator. More specifically, likelihoods in Eqn. 3 encode the information that
distributionally reflect the objective of generators Jg and discriminators Jd. Such quantities evaluate
the fitness between the generator and the discriminator.
We emphasize, although sharing the same spirit of reflecting the GAN objectives in likelihood, there
is a crucial difference between our likelihood model and that of Bayesian GAN. We will revisit it in
the later theory section.
Prior. Unlike Bayesian GAN using normal distributions for both generator and discriminator,
ProbGAN has less standard priors. As Eqn. 2 suggests, we set different priors for the two players.
For the generator, we use the generator distribution in the previous time step as a prior. The intuition
is following. When the generated data distribution is increasingly close to the real data distribution,
there will be less information for discriminator to distinguish between them; consequently, the
discriminator tends to assign equal scores to all data samples, resulting in equal likelihoods for
all generators. At that stage, a good strategy is to keep the generator distribution the same as the
previous time step, since it already generates the desired data distribution perfectly. Hence, we use
the generator distribution in the previous time step as a prior for the next Such dynamically evolving
prior for generator turns out to be crucial. In Section 4.2, we show the Bayesian GAN suffers from
bad convergence due to its fixed and weakly informative prior. In contrast, we set a uniform improper
prior on the discriminator to pursuit unrestricted adaptability to evolving generators.
3.3	Inference Algorithm
So far we have introduced our ProbGAN model. In this section we develop novel inference algorithms
to compute the posterior. Similar to most advanced Bayesian methods, exact calculation of the
posterior is intractable. Following the strategy in Saatci & Wilson (2017), we adopt Stochastic
Gradient Hamiltonian Monte Carlo to generate samples from the posterior. In each iteration, M
samples {θg(t,)m}mM=1 are used to approximate the generator distribution qg(t).
1 Mg
Vθdlθg qdt+1)(θd) = Vθd Jd (θd ； Pmodel) ≈ Mr ]TVθd Jd(θd; Pgen(∙;。2)),	(4)
g m=1
Vθg log qgt+1)(θg) = Vθg (Jg (θg ；D㈤)+lθg qgt)(θg)) ≈ Vθg (Jg (θg ； M X D(∙; θdtmm))+lθg qgt)(θg)).
Md
m
(5)
Empowered by the adapted SGHMC (Algorithm 1 in the appendix), we are able to sample from
qg(t+1) and qd(t+1) based on gradients in Eqn. 4 and Eqn. 5. The gradients come from two sides: the
GAN objective Jg, Jd and the prior qg(t). Getting GAN objective’s gradient is easy while computing
the prior’s gradient, Vθg log qg(t)(θg), is actually non-trivial since we have no exact analytic form
of qg(t) (θg). To address this challenge, we propose the following two methods to approximate
Vθg log qg(t)(θg), leading to two practical inference algorithms.
Gaussian Mixture Approximation (GMA). Although the analytic form of the distribution qg(t)(θg)
is unknown, we have Mg Monte Carlo samples {θg(t,)m }mM=g 1 which enables us to directly approximate
the distribution as a Mixture of Gaussian in the left side of Eqn. 6, where σ is a hyper-parameter and
C is the normalization constant. Then we derive the prior gradient approximation as shown in the
right side of Eqn. 6.
Mg kθ	θ(t) k2	Mg 1
qgt+1)(θg) ≈ Ceχp{ X	g 2 g, 2 }⇒Jg log qgt+1)(θg) ≈ X — (θg - θgtm).	⑹
m=1	2σ	m=1 σ
Partial Summation Approximation (PSA). From Eqn. 5, actually we can make an interesting
observation that the prior gradient can be recursively unfolded as a summation over all historical
GAN objective gradients, shown as:
Vθg log qgt+1)(θg) = Vθg Jg(θgRt)) + Vθg log qgt)(θg) = X Vθg Jg(θg;D(i)).	(7)
i=0
4
Published as a conference paper at ICLR 2019
0.20	0.20 -j	0.20 -I	M	0.20 -I	0.20 -I
0.15 -	0.15 -	0.15 -	0.15 -	0.15 -
::lmiuliln::)____b‰ιllJ⅛LL∣llιJ⅛LιJllιJ
XXXXX
(a) Lbgan/Pbgan	(b) Lour/Pbgan	(c) Lbgan/Pour	(d) Lour/Pour	(e) Ground Truth
Figure 1: An example of data distributions produced by converged models in the toy experiment on
categorical distribution. We examined four possible combinations of likelihoods and priors. Lour ,
Lbgan stand for the likelihoods of our ProbGAN model and BGAN model. Pour and Pbgan stand for
the priors. Only our model (Figure 1(d)) learns the target data distribution (Figure 1(e)).
Therefore if we store all historical discriminator samples {θd(i,)m}it=,M1,dm=1, the prior gradient can be
computed accurately via simple summation. Practically, computing gradients with all discriminator
samples costs huge amount of storage and computational time, which is unaffordable. Hence we
propose to maintain a subset of discriminators by subsampling the whole sequence of discriminators.
4	Theory
In this section, we first present the good convergence property of ProbGAN. Second, we theoretically
analyze the distribution evolution of Bayesian GAN (which will be referred to as BGAN in the rest of
the paper) and compare BGAN with ProbGAN. All proofs are included in the appendix (Section A).
4.1	Convergence Property of ProbGAN
We say a generator distribution is ideal if the generator following this distribution produces the target
data distribution. Theorem 1 shows that any ideal generator distribution is an equilibrium of the
dynamics defined in Eqn. 2. Although its mathematical proof involves more elaboration, the idea
behind is quite simple. When the generator distribution is ideal, the discriminator is not able to
distinguish the synthetic data from real. Thus the averaged discriminator function will degenerate
to a constant function. Afterwards, the generator distribution will remain unchanged since the
discriminator essentially puts no preference over generators. Here, we note that the discriminator is
only involved in the likelihood. The prior still needs to be carefully designed so that the model can
converge to an equilibrium where the generator is ideal. Simply choosing a weakly informative prior
as Bayesian GAN did will not give Theorem 1.
Theorem 1. Assume the GAN objective and the discriminator space are symmetry. For any ideal
generator distribution qg(θg) satisfying Pmodel，Eθg〜qg [pgen(∙; θg)] = Pdata, there exists a dis-
criminator distribution q； such that D*(∙) ，Eθd〜若D(∙; θd) ≡ C. Moreover, qg and q； is an
equilibrium of the dynamic defined in Eqn. 2.
4.2	ProbGAN v.s. Bayesian GAN
This section presents analyses of the BGAN algorithm, where we find a theoretical issue in its
convergence and highlight the importance of our renovation of the prior and likelihood.
Corollary 1 states our derivation of posterior modelling in BGAN, where pg (θg ; αg), pd(θd; αd) are
the predefined priors. In practice, BGAN use a fixed Gaussian prior.
Corollary 1. The Bayesian GAN algorithm actually performs distribution dynamics in Eqn. 8.
qgt+1) Y exp{Eθd^q(t)Jg(θg; θd)}Pg(θg; ag),qdt+1) Y exp{Eθg〜q(t)J；(θd; θg)}Pd(θd; a) ⑻
Difference in Likelihood. The subtle adjustment of our likelihood term lies in the order of taking
expectation. As shown in Eqn. 3, our choice of likelihood yields a concrete physical meaning. Our
discriminator likelihood explicitly evaluates the discriminator ability of distinguishing real data
distribution and total data distribution generated by all generators. Hence, our approach matches the
target data distribution with mixed data distribution produced by generators, while BGAN may not.
Difference in Prior. The choice of prior also plays an important role in convergence. A weakly/non-
informative prior, as adopted in BGAN, prevents the generators from convergence even if they already
produce the data distribution faithfully. The phenomenon arises from the fact that the information
provided by discriminator vanishes when the generators are ideal and the resulting generator posterior
5
Published as a conference paper at ICLR 2019
will degenerate to the prior. To remedy this issue, our solution is to take generator distribution at
previous time step as the prior. Then whenever the discriminator degenerates to a constant, the
generator distribution will stay unchanged because the prior is itself.
An Analytical Case Study. We demonstrate the superior convergence property of our model on a
categorical distribution, where analytic posterior computation of various choices of likelihood and
prior are feasible; we compute the exact equilibrium of GAN models under all the four combinations
of the priors and likelihoods(ProbGAN’s choices v.s. BGAN’s choices). The experiment details are
in the appendix (section D). Figure 1 is an example of the data distributions generated by each model
after it converges. Among all the combinations, our model is the only formulation that yields proper
convergence, which validates our theoretical analysis.
Compatibility Issue. We further show BGAN’s choice of likelihood and prior leads to theoretical
issues. Specifically, BGAN is not suitable for any minimax-style GAN objective due to the incompat-
ibility of its conditional posteriors. This problem may limit the usage of BGAN since many widely
used GAN objective is in min-max fashion, such as the original GAN and WGAN.
Consider a simple case where we use only one Monte Carlo sample for the distributions qg(t) and qd(t) .
Then the distribution evolution in Eqn. 8 will degenerate to a Gibbs sampling process.
θgt+1)〜qgt+1) (θg)
θdt+1)~ qdt+1)(θd)
H
H
exP{Jg (θg ； θd = θdt))}p(θg lag)
exp{Jd(θd; θg = θgt))}p(θd∣αd)
(9)
Thus θg(t) and θd(t) are implicitly sampled from a joint distribution of θd and θg defined by the
conditionals p(θg&) = exp{Jg(θg; θd)}p(θg∣αg) and p(θd∣θg) = exp{Jd(θd; θg)}p(θd∣ɑd).
However, our theoretical analysis shows that such a presumed joint distribution does not exist
when Jd(θd; θg) = -Jg(θg; θd). Specifically, Lemma 1 shows the existence of a joint distribu-
tion satisfying the conditionals in Eqn. 9 requires the GAN objective to be decomposable, i.e.
∃φg, φd, s.t. Jd(θd; θg) = φg(θg) + φd(θd). Apparently, no valid GAN objective is decomposable.
Therefore, conditionals in Eqn. 9 are actually incompatible. Sampling with incompatible conditional
distribution is problematic and leads to unpredictable behavior (Arnold & Press, 1989).
Lemma 1. Consider a joint distribution p(x, y) of variable X and Y . Its conditional distributions
can be represented in the forms of p(x|y) H exp{L(x, y)}qx(x) and p(y |x) H exp{-L(x, y)}qy(y)
only if X and Y are independent, i.e., p(x, y) = p(x)p(y) and L(x, y) is decomposable, i.e.,
∃Lx and Ly, L(x, y) = Lx(x) + Ly(y).
5	Experiments
In this section, we evaluate our model with two inference algorithms proposed in Section 3.3 (denoted
as ProbGAN-GMA and ProbGAN-PSA). We compare with three baselines: 1) GAN (or DCGAN2):
naively trained multiple generators in the vanilla GAN framework; 2) MGAN : Mixture GAN (Hoang
et al., 2018) which is the start-of-art method to train GAN with multiple generators; 3) BGAN:
Bayesian GAN (Saatci & Wilson, 2017).
For each model, we conduct thorough experiments with the four different GAN objectives introduced
in Table 1, which are referred to as GAN-MM, GAN-NS, WGAN and LSGAN here. For a fair
comparison, each model has the same number of generators with the same architecture. Discriminator
architectures are also the same except for that of MGAN which has an additional branch of the
classifier. To facilitate reproducibility, we report implementation and experiment details in Section B
of the appendix.
5.1	High-dimensional Multi-modal Synthetic Dataset
Dataset. Consider learning a data distribution in a high dimensional space X = RD, which is a
uniform mixture of n modes. Each mode lies on a d-dimensional sub-space of X . We call this
d-dimensional sub-space as mode-space of the i-th mode. Specifically, the data of the i-th mode is
generated by the following process,
2We use original GAN for synthetic dataset and DCGAN for image generation task
6
Published as a conference paper at ICLR 2019
Figure 2: Visualization of projected hit sets. Rows from top to bottom correspond to MGAN, BGAN,
and ProbGAN-PSA trained with GAN-MM objective. See Figure 6 (in appendix) for results of
all models. In one row, projected hit sets for each mode are plotted in different panels, where the
red boxes indicate real data regions U [-1, 1]2. Different colors indicate samples from different
generators.
Z ~U[-1,1]d, X = Ai(Z + bi), Ai~N(0,σAI0×d), bi~N(0,σ2Id)	(10)
In our experiment, n, D, and d are set to 10, 100, and 2. Hyper-parameters for A and b are set to be
σA = σb = 5. Each model train ten generators.
Metric. We define projection distance p for generated data sample X as the minimum of Euclidean
distance from X to any of mode-spaces i.e. p(X) = mini i(X) , kX - Ai(AiTAi)-1AiTXk2. Then
we set a threshold 3 η to test the belonging of X, i.e. the data samples whose Euclidean distance to the
mode-space is below η are considered as belonging to that mode. The trained models are evaluated by
the samples {xk}3ι 〜PmodeI it generates. We define hit set Hi，{xk匕⑶)< η} to indicate the
samples belong to each mode. We further define projected hit set, PHi , {(AiTAi)-1AiTX-bi|X ∈
Hi } by projecting data in each hit set back to the canonical low dimensional space.
Now we introduce three evaluation metrics: hit ratio, hit distance, and cover error. Hit ratio
Hr , Pin=1 |Hi | /K is the percentage of generated data belonging to any of the modes of real
data. Hit distance Hd , Pin=1 Px∈H i(x)/ Pin=1 |Hi| is the averaged projection distance over all
data in the hit set. Lastly, cover error Ce evaluates how well the generated data covers each mode.
Essentially it computes the KL-divergence between the estimated distribution of samples in PHi and
the uniform distribution over [-1, 1]d. Formally, it is defined as the averaged KL-divergence on n
modes i.e. Ce，* PNi KL(p^(∙; PHi)kU[-1,1]d). The intuition is that if data generated is close to
the ground truth distribution, they should be uniformly distributed in the square area of each mode.
Optimization-Based v.s. Probabilistic. The left part of Table 2 summarizes the results in terms
of hit ratio and hit distance. Probabilistic methods including our algorithms and BGAN always
achieve a hit ratio of 1, which means every data point generated from these models is very close
to one mode of the target distribution. On the other hand, optimization based methods, both GAN
and MGAN, consistently have a significantly larger hit error, and sometimes may even generate
data samples that do not belong to any mode. Moreover, the data distribution generated by the
optimization-based methods fits the target uniform distribution much worse than its probabilistic
counterparts, which is quantitatively reflected by the cover error showed in the right side of Table 2
and visually demonstrated by the projected hit sets in Figure 2. According to the visualization, data
generated by GAN or MGAN tend to be under dispersed and hardly cover the whole square region of
the true mode, while data generated by probabilistic methods align much better with the ground truth
distribution. We attribute this superiority to stronger exploration power in the generator space coming
from the randomness in probabilistic methods.
Bayesian GAN v.s. ProbGAN. The incompatibility issue of BGAN with minimax-style GAN
objectives theoretically derived in Section 4.2 is empirically verified in our experiments. As visualized
in Figure 2, with the GAN-MM objective, BGAN is trapped in a local equilibrium and fails in
capturing one mode of the true data. Besides, as shown in Table 2, BGAN with the WGAN objective
achieves much poorer coverage than with other GAN objectives, while our model is much more
robust to the choice of GAN objectives (consistently lower cover errors). A qualitative comparison is
made in Figure 9 (in the appendix) which shows the data distribution generated by BGAN trained
3 Based on the fact that the average distance between the data from two different modes is 800, we set a
threshold of η = 40.
7
Published as a conference paper at ICLR 2019
Table 2: Hit ratios (Hr), hit distances (Hd), cover errors (Ce) results. Note, if the model failed to
capture all the modes of real data, by definition its cover error is ∞. In that case, we report the
averaged KL-divergence on modes captured by the model in brackets.
I Hr (HIGHER IS BETTER), Hd (LOWER IS BETTER) ∣						Ce (LOWER IS BETTER)		
	GAN-MM	GAN-NS	WGAN	LSGAN	GAN-MM	GAN-NS	WGAN	LSGAN
GAN	0.86, 22.6	0.85, 23.1	0.78, 26.7	0.74,23.1	12.11	8.86	7.20	∞ (12.07)
MGAN	0.82, 24.2	0.84, 25.5	0.67, 31.7	0.81, 23.6	5.46	6.31	5.00	∞ (4.25)
BGAN	1.0, 5.5	1.0, 6.4	1.0, 12.1	1.0, 6.3	∞ (1.73)	1.76	4.32	1.80
PROBGAN-GMA	1.0, 7.4	1.0, 7.7	1.0, 15.5	1.0, 5.3	1.84	1.73	3.01	1.79
PROBGAN-PSA	1.0, 5.8	1.0, 6.4	1.0, 12.5	1.0, 6.4	1.75	1.75	2.28	1.74
Table 3: Inception score and FID results on CIFAR-10. Results of each model trained with 4 different
GAN objectives are all reported.
	Inception scores (higher is better)				FIDs (lower is better)			
	GAN-MM	GAN-NS	WGAN	LSGAN	GAN-MM	GAN-NS	WGAN	LSGAN
DCGAN	6.53	7.21	7.19	7.36	35.57	27.68	28.3 1	29.11
MGAN	7.19	7.25	7.18	7.34	30.01	27.55	28.37	30.72
BGAN	7.21	7.37	7.26	7.46	29.87	24.32	29.87	29. 19
PROBGAN-PSA	7.75	7.53	7.28	7.36	24.60	23.55	27.46	26.90
with WGAN objective tends to shrink. More visual illustrations under different GAN objectives are
placed in Section E of the appendix.
5.2	Natural Image Dataset
Datasets. We evaluate our method on 3 widely-adopted datasets: CIFAR-10 (Krizhevsky et al.,
2010), STL-10 (Coates et al., 2011) and ImageNet (Deng et al., 2009). CIFAR-10 has 50k training
and 10k test 32x32 RGB images from 10 classes: airplane, automobile, bird, cat, deer, dog, frog,
horse, ship, and truck. STL-10, containing 100k 96x96 RGB images, is a more diverse dataset than
CIFAR-10. ImageNet has over 1.2 million images from 1,000 classes and presents the most diverse
dataset. For a fair comparison with baselines, we use the same settings as MGAN. We resize the
STL-10 and ImageNet images down to 48x48 and 32x32 respectively.
Evaluation Protocols. We employ two common image generation metrics: Inception Score (Sali-
mans et al. (2016)) and Frechet Inception Distance (Heusel et al. (2017)). Inception Score computes
exp(Ex[KL(p(y|x)kp(y))]) where p(y|x) standards the predicted label distribution by a pre-trained
Inception model (Szegedy et al., 2015) and p(y) is the average of p(y|x) over all images in the
dataset. Inception Score (IS) reflects the fidelity and diversity of images and is well-correlated with
human judgment (Salimans et al., 2016). However, it does not measure the similarity between the
real data and the synthetic data. Therefore, as a complementary, We use Frechet Inception Distance
(FID). Specifically, it measures the FreChet distance between two image distributions in the feature
embedding space conduct by the Inception model. More details are included in the appendix
Model Architectures. Inspired by Hoang et al. (2018), we adapted the parameter sharing technique
for both generators and discriminators. Specifically, generators (of one model) are not disjoint neural
networks. They only differ at the first layer and sharing all parameters at the following layers. This
tied parameter design reduced the model complexity and boost the performance. Especially for the
probabilistic model such as Bayesian GAN, we observe a significant enhancement of generated image
qualities compare to the original result (Figure 7 in Saatci & Wilson (2017)). More implementation
details such as hyper-parameters of network layers are reported in the appendix (Section B).
Quantitative Results. Table 3 and Table 4 summarize the Inception scores and FIDs on the three
benchmark datasets for our model and baselines. For each model, we denote the epoch delivering
highest ’IS-0.1FID’ as the best epoch and report the scores of the model at this epoch. We design
this ’IS-0.1FID’ principle to neutralize the discrepancy between Inception score and FID. Because
Inception score and FID may not be consistent with each other, it is possible that the Inception score
improves but the FID gets worse when we evaluate the model at a different checkpoint. Hence, we
need a rule to pick one point of the Pareto frontier of the model performance.
8
Published as a conference paper at ICLR 2019
Table 4: Inception score and FID results on STl-10 and ImageNet. Each model is trained with
GAN-NS objective.
Dataset	STL-10		IMAGENET INCEPTION SCORES	FIDS
	Inception scores	FIDs		
DCGAN	8.05 ± 0.101	51.01	7.66 ± 0.113	48.99
MGAN	8.72 ± 0.096	51.56	7.77 ± 0.108	45.75
BGAN	8.84 ± 0.100	47.35	8.52 ± 0.075	29.68
PROBGAN-PSA	8.87 ± 0.095	46.74	8.57 ± 0.073	27.69
(b) BGAN (Epoch 250)
(a) MGAN (Epoch 250)
(c) ProbGAN-PSA (Epoch 250)
(a) ImageNet (randomly picked)
(b) STL-10 (randomly picked)
Figure 3: Images generated by MGAN, BGAN and our model trained on CIFAR 10 with GAN-NS
objective. The tenth generator of MGAN (Figure 3(a)) and the first of BGAN (Figure 3(b)) collapse
while generators of our method all work well. DCGAN (Figure 10 in the appendix) also presents
’single generator collapse’ issue. Note that, mode collapse also happens when baseline models trained
with other GAN objectives.
(c) STL-10 (cherry-picked)
Figure 4: Images generated by ProbGAN trained on ImageNet (left) and STL-10 (middle, right).
Figure 4(c) are cherry-picked synthetic images on STL-10.
Overall, our proposed ProbGAN outperforms the baselines on all three benchmark image datasets.
Furthermore, according to results on CIFAR-10, our model achieves the best performance under all
GAN objectives. Generally, probabilistic methods achieve better scores than optimization based meth-
ods, which indicates that injecting stochasticity into GAN training helps generate more multi-modal
images. Note that the performance gap increases as the dataset gets more diverse. Specifically, when
using GAN-NS objective, our model improves FID by 4.00 on CIFAR-10 (Table 3) in comparison
to MGAN. While the FID improvements are 4.82 and 18.06 on STL-10 and ImageNet (Table 4),
respectively.
Besides, we note that Bayesian GAN has a significant performance drop when accompanied by
min-max style GAN objectives, which provides another empirical evidence for our theory analysis in
Section 4.2. By contrast, ProbGAN fits any GAN objectives and constantly performs well.
Qualitative Results. Figure 3 displays the samples randomly generated by the baselines and our
ProbGAN. Each row in the figure contains samples of one learned generator. In Figure 3 and Figure 10
(in the appendix), all the three baselines noticeably suffer from mode collapse. Indeed, almost in
every training trial, one or two generators of the baseline models degenerate during the training.
Hoang et al. (2018) already notice that mode collapse in one of the generators could happen after a
9
Published as a conference paper at ICLR 2019
long training procedure (around 250 epochs). Our experiment shows Bayesian GAN also have this
issue. However, ProbGAN is robust to mode collapse. Visual results for the entire ablation study on
CIFAR-10 are included in Section F of the appendix.
Figure 4(a) and Figure 4(b) display images generated by our model trained on ImageNet and STL-10.
Each row in these two figures contains generated images from one generator. The results show that
our method is robust to ’single generator mode collapse’ in both STL-10 and ImageNet. We also
include cherry-picked results on STL-10 to exhibit the capability of our model to generate visually
appealing images with complex details while improving the robustness against mode collapse.
6	Discussion
In this paper, we propose ProbGAN, a novel probabilistic modelling framework for GAN. From
the perspective of Bayesian Modelling, it contributes a novel likelihood function establishing a
connection to existing GAN models and a novel prior stabilizing the inference process. We also
design scalable and asymptotically correct inference algorithms for ProbGAN. In the future work, we
plan to extend the proposed framework to non-parametric Bayesian modelling and investigate more
theoretical properties of GANs in the probabilistic modelling context.
Developing Bayesian generalization for deep learning models is not a recent idea and happens in
many fields other than generative models such as adversarial training (Ye & Zhu, 2018) and Bayesian
neural networks (Wang et al., 2016a). By this work, we emphasize the importance of going beyond
the intuition and understanding the theoretical behavior of the Bayesian model. We hope that our
work helps inspire continued exploration into Bayesian deep learning (Wang & Yeung, 2016) from a
more rigorous perspective.
References
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein gan. arXiv preprint
arXiv:1701.07875, 2017.
Barry C Arnold and S James Press. Compatible conditional distributions. Journal of the American
Statistical Association, 84(405):152-l56,1989.
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium
in generative adversarial nets (gans). arXiv preprint arXiv:1703.00573, 2017.
Shane Barratt and Rishi Sharma. A note on the inception score. arXiv preprint arXiv:1801.01973,
2018.
Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient hamiltonian monte carlo. In
International Conference on Machine Learning, pp. 1683-1691, 2014.
Adam Coates, Andrew Ng, and Honglak Lee. An analysis of single-layer networks in unsupervised
feature learning. In Proceedings of the fourteenth international conference on artificial intelligence
and statistics, pp. 215-223, 2011.
J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical
Image Database. In CVPR09, 2009.
Arnab Ghosh, Viveka Kulharia, Vinay Namboodiri, Philip HS Torr, and Puneet K Dokania. Multi-
agent diverse generative adversarial networks. arXiv preprint arXiv:1704.02906, 2017.
Ian Goodfellow. Nips 2016 tutorial: Generative adversarial networks. arXiv preprint
arXiv:1701.00160, 2016.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural informa-
tion processing systems, pp. 2672-2680, 2014.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans
trained by a two time-scale update rule converge to a local nash equilibrium. In Advances in Neural
Information Processing Systems, pp. 6626-6637, 2017.
10
Published as a conference paper at ICLR 2019
Quan Hoang, Tu Dinh Nguyen, Trung Le, and Dinh Phung. Mgan: Training generative adversarial
nets with multiple generators, 2018.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced
research). 2θ1θ. URL http://www.cs.toronto.edu/~kriz/cifar.html.
Andrew L Maas, Awni Y Hannun, and Andrew Y Ng. Rectifier nonlinearities improve neural network
acoustic models. In Proc. icml, volume 30, pp. 3, 2013.
Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smolley. Least
squares generative adversarial networks. In 2017 IEEE International Conference on Computer
Vision (ICCV),pp. 2813-2821.IEEE, 2017.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. In Advances in Neural Information Processing Systems,
pp. 271-279, 2016.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. 2017.
Yunus Saatci and Andrew G Wilson. Bayesian gan. In Advances in neural information processing
systems, pp. 3622-3631, 2017.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. In Advances in Neural Information Processing Systems, pp.
2234-2242, 2016.
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Du-
mitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1-9, 2015.
Ilya O Tolstikhin, Sylvain Gelly, Olivier Bousquet, Carl-Johann Simon-Gabriel, and Bernhard
SchOlkopf. Adagan: Boosting generative models. In Advances in Neural Information Processing
Systems, pp. 5430-5439, 2017.
Hao Wang and Dit-Yan Yeung. Towards Bayesian deep learning: A framework and some existing
methods. IEEE Transactions on Knowledge and Data Engineering, 27(5):1343-1355, 2016.
Hao Wang, Xingjian Shi, and Dit-Yan Yeung. Natural-parameter networks: A class of probabilistic
neural networks. In Advances in Neural Information Processing Systems, pp. 118-126, 2016a.
Yaxing Wang, Lichao Zhang, and Joost van de Weijer. Ensembles of generative adversarial networks.
arXiv preprint arXiv:1612.00991, 2016b.
Nanyang Ye and Zhanxing Zhu. Bayesian adversarial learning. In S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural In-
formation Processing Systems 31, pp. 6892-6901. Curran Associates, Inc., 2018. URL http:
//papers.nips.cc/paper/7921-bayesian-adversarial-learning.pdf.
A Omitted proofs
Theorem 1. This theorem is general and holds when the GAN objective and the discriminator
space have symmetry. The symmetry of GAN objective means its functions φ1 and φ2 satisfy that
∃c ∈ R, ∀x ∈ R, φ1 (x) ≡ φ2(c - x). While the symmetry of discriminator space Θd indicates that
for any θd ∈ Θd, there is a θd0 ∈ Θd such that D(x; θd) ≡ c - D(x; θd0 ). Note that the symmetry
condition are very weak, first it holds for all the common choices of GAN objectives such as those
listed in Table 1. Second, it holds for neural network which is the most common parameterization for
discriminator in practice.
11
Published as a conference paper at ICLR 2019
Proof.
qd(θd) Y eXP(Ex〜Pdata[φ1 (D(X； θd))] + Ex〜Pmodel [φ2 (D(X； θd))])
=eχp(Ex〜Pdata [φl(D(χ; θd)) + φ2(D(X； θd))])
=exp(Ex〜Pdata [φ2(c - D(x; θd)) + φι(c - D(x; θd))])	(II)
=exP(Ex〜Pdata [φ2 (D(X； S(Od))) + φ1(D(X； S(Od)))D
⇒ qd(θd) = qd(S Ied)),
D*(x) = Eθd〜qdD(x; θd) = /	q煎θd)D(x; θd)dθd
θd ∈Θd
= 1(/	qd(θd)D(x; θd)dθd + [	qd(θd)D(x; θd)dθd)
2 θd∈Td	θd0 =S(θd)∈Td
=1 /	qd(θd)(D(x; θd) + D(x; S(θd)))dθd
2 θd∈Θd
(12)
2 ∙Lθdqd(θd) ∙C ∙ dθd=c
Eqn. 11 and Eqn. 12 prove that qdd(Od) (X eχP(Jd(θd; Pmodel)) SatiSfieS Eθd 〜q二 D(∙; θd) ≡ C .
Note that, in the above equations, S(Od) denotes the symmetric discriminator of Od satisfying
D(x; S(Od)) ≡ c - D(x; Od). Hence according Eqn. 13, we know Jg(Og; Dd) iS a conStant.
Jg(θg； Dd)= Ex〜Pgen(M)[φ3(Dd(x))] = Φ3(C), ∀x ∈ X.	(13)
ThuS the generator diStribution will not change baSed on the dynamicS in Eqn. 2 Since qgd(Og) X
exp{Jg (θg W*)}qg(θg).	□
Corollary 1
Proof.
Jg Jd
log qgt+1)(θg ) = TT XX log PIeg ∣z(i),θk)	(14)
JgJd i=1 k=1
log qgt+1)(θg) ' Eθd^qd(θd)Jg (θg ； θd) + logP(θg |ag )	(15)
Algorithm 1 from the original paper (Saatci & Wilson, 2017) implies that Eqn. 14 where θdk 〜qdt (θd)
are Monte Carlo SampleS of diScriminator and every z(i) iS a mini-batch containing ng noiSe SampleS.
Be definitionp(θg∣z(i),θk) X Qn= 1 D(G(Zji); θg); θdk)p(θg ∣αg) (Eqn. 1 in the original paper), each
term4 logp(θg∣z(i),θk) = Pn= 1 φ3(D(G(zji; θg); θk))+logp(θg ∣αg). Hence, the total summation
is a Monte Carlo approximation of the expectation in the right side of Eqn. 15. The same derivation
can be done to qdt+1). Together, we get Corollary 1.	□
Lemma 1
Proof.
P(X|y) = α(y) exp{L(X, y)}qx(X),
P(y|X) = β(X) exp{-L(X, y)}qy(y),
=⇒ P(X, y)2 = P(X|y)P(y) × P(y|X)P(X)
= P(X)P(y)α(y)β(X)qx (X)qy (y)
=⇒ X, Y are independent.
=⇒ P(X) = P(X|y)
=⇒ L(X, y) = log P(X) - log qx(X) - log α(y)
=⇒ L(X, y) is decomposable.
4Note that in BGAN paper, the GAN objective is GAN-NS. Thus φ3 equals log(∙).
(16)
12
Published as a conference paper at ICLR 2019
where α(y) = (J exp{L(x,y)}qχ(x)dx)-1 and β(x) = (J exp{-L(x,y)}qy (y)dy)-1.	□
B Experiment details
B.1	Natural Image Dataset
For MGAN results, we adopt the official Tensorflow implementation5. While, for our model and
other baselines, we implement them in PyTorch (Paszke et al., 2017).
Remark on Inception score and FID. Barratt & Sharma (2018) point out that Inception score is
sensitive to the inception model used and the number of data splits in the computation. This is also
true for Frechet Inception Distance (FID). We find that the FID computed by a PyTorch Inception
model6 is much lower than the FID given by a Tensorflow model7.
In our experiments, to facilitate a fair comparison with prior work, we compute Inception score and
FID using the Tensorflow Inception model. We adopt the official Tensorflow implementation for FID
to compute both Inception score and FID. We will release our evaluation code soon.
Model architecture: In our experiments, each model is trained with 10 generators. As for discrim-
inator, DCGAN and MGAN have one discriminator while probabilistic models (BGAN and ours)
have 4 discriminators (i.e. 4 Monte Carlo samples from discriminator distribution).
The neural network structures are the same as MGAN. As reported in Table 4,5,6 in Section C.2 of
the original MGAN paper. Briefly, the structures are the following.
Generator architecture has four (or five) deconvolution layers (kernel size 4, stride 2) with the
following input, hidden feature-maps, output size: 100x1x1 → 512x4x4 → 256x8x8 → 128x16x16
→ 3x32x32. Every deconvolution layer is followed by batch-normalization layer and Relu activation
except for the last deconvolution layer who is followed by Tanh activation.
Discriminator architecture has four (or five) convolution layers (kernel size 5, stride 2) with the
following input, hidden feature-maps, output size: 3x32x32 → 128x16x16 → 256x8x8 → 512x4x4 →
1x1x1. Batch-normalization is applied to each layer except the last one. Activations are leaky-ReLU.
Training hyperparameters: All models are optimized by Adam(Kingma & Ba, 2014) with a learning
rate of 2 × 104. For probabilistic methods, the SGHMC noise factor is set as 3 × 102. Following the
configuration in MGAN, the batch size of generators and discriminators are 120 and 64. Note that,
since probabilistic model has 10 generator Monte Carlo samples and 4 discriminators, indeed batch
size for every generator and discriminator is 12 and 16 respectively.
B.2	High-dimensional multi-modal synthetic dataset
Model Architecture: Each generator or discriminator is a three layer perceptron. For the generator,
the dimensions of input, hidden layer and output are 10, 1000, and 100 respectively. For the
discriminator, the dimensions of input, hidden, output layers are 100, 1000, and 1. All activation
functions are leaky ReLU(Maas et al., 2013).
Training hyperparameters: All models are optimized by Adam (Kingma & Ba, 2014) with a
learning rate of 10-4. For probabilistic methods, the SGHMC noise factor (α in algorithm 1) is set as
10-1.
C Inference algorithm
Stochastic Gradient Hamiltonian Monte Carlo (Chen et al., 2014) is a gradient based MCMC
sampling method. It use noise gradient estimation of potential function to generate sample from a
given distribution. Our inference algorithm (algorithm 1) is based on this brilliant algorithm.
5MGAN Code: https://github.com/qhoangdl/MGAN
6 https://github.com/mseitzer/pytorch-fid
7https://github.com/bioinf-jku/TTUR
13
Published as a conference paper at ICLR 2019
Input: Initial Monte Carlo samples of {θd(0,m) }mM=d 1 and {θg(0,m) }mM=g 1, learning rate η, SGHMC
noise factor α, number of updates in SGHMC procedure L, number of updating iterations T .
for t = 1 to T do
for m
θd,m
1 to Md do
for l =
vJ
θ(t)
d,m
1 to L do
(1 — α)v + ηVθd log qdt+1) (θd,m) + n; n 〜N(0,2αηI)
θd,m J θd,m + v
end for
θd(t,+m1) J θd,m
end for
for m = 1 to Mg do
θg,m J θg(,)m
for l = 1 to L do
V J (1 — α)v + ηVθg log qgt+1) (θg,m) + n; n ~ N(0, 2αηI)
θg,m J θg,m + v
end for
θ(t+1) J θ
g,m J g,m
end for
end for
Algorithm 1: Our Adapted SGHMC Inference Algorithm
Table 5: Configuration of four models in comparison.
Model
A
B
C
D
Likelihood
expectation of objective value
objective value of expectation
expectation of objective value
objective value of expectation
Prior
Gaussian: Pg(θg) Y N(0,1), Pd(θd) Y N(0,1)
Gaussian: Pg(θg) Y N(θ, l), pd(θd) Y N(θ, l)
ProbGAN: Pg(θg) Y qg(t) (θg), Pd(θd) Y 1
ProbGAN: Pg(θg) Y qg(t) (θg), Pd(θd) Y 1
D Toy experiment on categorical distribution
O 200	400	600	800 IOOO
# of iterations
-1.8 -l-∣-------1-------1--------1-------1-------1—
0	200	400	600	800	1000
# of iterations
J
(a) GAN-NS objective	(b) GAN-MM objective
Figure 5: The l1 distances between model generated data distribution and target data distribution at
each iteration step. Results of model A, B, C, D are denoted by different colors.
Setup. In this toy example, we consider the case where X , Θg , and Θd are all finite sets, specifically
X = {xι,…，XN}, Θg = {θ∖ …，θNg}, Θd = {θ^1,…，θNd }. The target data distribution is
a categorical distribution Cat(λi:N) where λi = Pdata(Xi) is the probability of generating data
Xi. Generator Gi generates data following the categorical distribution Pdata(x; θg) = Cat(αj∙N).
14
Published as a conference paper at ICLR 2019
Further, the probability distributions of generator and discriminator are categorical distributions
qg(θg) = Cat(βi:Ng) and qd(θd) = Cat(γi:Nd).
In practice, we set N = 10, Ng = 20, Nd = 100. In each experiment trial, target data distribution
λi:N and data distributions for each generator a\N are fixed and initialized by the following
categorical distribution generating procedure. We first independently sample from the uniform
distribution U[0,1] to get {λj}储 and then normalize them to get a categorical distribution λj =
~
λj
PNI^.
For the discriminators, their function values are randomly generated from a uniform distribution, i.e.
{DM; Oj)}NNd=ι ~U[0,1].
Models in comparison. As listed in Table 5, we compare four models with different pairs of
likelihood and prior. There are two choices of likelihood, expectation of objective value and objective
value of expectation. Mathematically, expectation of objective value likelihood has the following
formula:
•	Generator likelihood lg(θg) of observing discriminator distribution qd(θd) is proportion to
eMEθd〜qd(θd) Jg (θg ； θd)}.
•	Discriminator likelihood ld(θd) of observing generator distribution qg(θg) is proportion to
exP{Eθg j(θg) Jd(θd； θg)}.
While the objective value of expectation likelihood is different as follows:
•	Generator likelihood lg(θg) of observing discriminator distribution qd(θd) is proportion to
exP{Jg (θg ； Eθd 〜qd(θd)D(∙; θd))}.
•	Discriminator likelihood ld(θd) of observing generator distribution qg(θg) is proportion to
exP{Jd(θd; Eθd 〜qd (θd)Pgen(∙; θg ))}.
Thus model A indeed is the design of Bayesian GAN, while model D is our proposed model. Model
B and C are introduced to conduct the ablation study.
Metric. We employ l1 distance for evaluation which can be directly computed on categorical
distributions as follows.
Dl1 (pdata, pmodel ) =	|pdata (x) - pmodel (x)|.	(17)
x∈X
Evaluation. In the categorical distribution settings, all the likelihood, prior and posterior computing
can be done analytically. For each model, we update the generator and discriminator distributions
iteratively and monitor the distance between the target data distribution and the data distribution
generated by the model. We experiment with two different choices of GAN objectives, GAN-MM
and GAN-NS. Note GAN-MM is a minimax-style objective.
Result. Figure 5 shows how l1 distance changes as the number of updating iterations increases. As
we can see, model A and model B are easily and quickly trapped into bad local minima, indicating
the convergence issue caused by non-informative prior. Interestingly, model C presents bifurcate
results when accompanied by different GAN objectives. Its abnormal behavior in the setting of using
GAN-MM objective indicates that the expectation of objective value likelihood used in Bayesian
GAN does not fit the minimax-style GAN objectives. Finally, our ProbGAN converges the fastest
(towards the global optima) and is robust to all GAN objectives.
15
Published as a conference paper at ICLR 2019
E A full visualization of projected hit sets
In this section, we shows projected hit sets for all models under different GAN objectives.
GAN + GAN-MM
MGAN + GAN-MM
BGAN + GAN-MM
ProbGAN-GMA + GAN-MM
ProbGAN-PSA + GAN-MM
Figure 6: Visualization of the projected hit sets of all models trained with GAN-MM objective.
The top two rows show the results of optimization based methods.The bottom three rows present
probabilistic method results. In each row, projected hit sets for each mode are plotted in different
panels. The red boxes in each panel indicate the region U [-1, 1]2 where the target data uniformly
distributed. The data points produced by different generators of a model is painted with different
colors.
16
Published as a conference paper at ICLR 2019
GAN + WGAN
MGAN + WGAN
BGAN + WGAN
ProbGAN-GMA + WGAN
ProbGAN-PSA + WGAN
Figure 7: Visualization of the projected hit sets of different models trained with the WGAN objective.
As we can see, training the WGAN objective leads to much worse performance for both optimization-
based methods and BGAN. On the other hand, our methods are robust to the choice of different GAN
objectives and do not suffer from significant performance drop when using the WGAN objective.
17
Published as a conference paper at ICLR 2019
GAN + LSGAN
MGAN + LSGAN
BGAN + LSGAN
ProbGAN-GMA + LSGAN
ProbGAN-PSA + LSGAN
Figure 8: Visualization of the projected hit sets of different models trained with the LSGAN objective.
Three probabilistic models performs perfectly in this case, while both the two optimization-based
methods miss one mode of the true distribution. This experiment illustrates that although MGAN
employs an additional classifier to force the data generated by different generators to be disjoint, it
still suffers from mode collapsing problem. This is because in MGAN, generators may still generate
disjoint data samples in the same mode and fail in capturing other modes.
18
Published as a conference paper at ICLR 2019
GAN + GAN-NS
MGAN + GAN-NS
BGAN + GAN-NS
ProbGAN-GMA + GAN-NS
ProbGAN-PSA + GAN-NS
Figure 9: Visualization of the projected hit sets of different models trained with the GAN-NS
objective. All the models succeed in fitting each mode of true distribution with one of their generator.
Specifically, three probabilistic models generate data almost perfectly covering the ground-truth
‘squares’ while the optimization-based methods have difficulty covering the whole ‘squares’ and tend
to yield under-dispersed data distributions. Note that since the GAN-NS objective is not in a min-max
style, the success of BGAN is expected.
19
Published as a conference paper at ICLR 2019
F More CIFAR- 1 0 generated image results
In this section, we shows images generated by all models trained on CIFAR-10 under different GAN
objectives.
Figure 10: Images generated by DCGAN trained on CIFAR-10 with GAN-NS objective at epoch
250. Redbox indicates the collapsed generator.
Figure 11: Images generated by ProbGAN-PSA model trained on CIFAR-10 with GAN-NS objec-
tive.Images in different rows are generated by different generators.
20
Published as a conference paper at ICLR 2019
Figure 12: Images generated by ProbGAN-PSA model trained on CIFAR-10 with LSGAN objec-
tive.Images in different rows are generated by different generators.
Figure 13: Images generated by ProbGAN-PSA model trained on CIFAR-10 with GAN-MM
objective.Images in different rows are generated by different generators.
21
Published as a conference paper at ICLR 2019
Figure 14: Images generated by ProbGAN-PSA model trained on CIFAR-10 with WGAN objec-
tive.Images in different rows are generated by different generators.
objec-
Figure 15: Images generated by Bayesian GAN trained on CIFAR-10 with GAN-NS
tive.Images in different rows are generated by different generators.
22
Published as a conference paper at ICLR 2019
Figure 16: Images generated by Bayesian GAN trained on CIFAR-10 with LSGAN objective.Images
in different rows are generated by different generators.
Figure 17: Images generated by Bayesian GAN trained on CIFAR-10 with GAN-MM objec-
tive.Images in different rows are generated by different generators.
23
Published as a conference paper at ICLR 2019
Figure 18: Images generated by Bayesian GAN trained on CIFAR-10 with WGAN objective.Images
in different rows are generated by different generators.
Figure 19: Images generated by MGAN trained on CIFAR-10 with GAN-NS objective.Images in
different rows are generated by different generators.
24
Published as a conference paper at ICLR 2019
Figure 20: Images generated by MGAN trained on CIFAR-10 with LSGAN objective.Images in
different rows are generated by different generators.
Figure 21: Images generated by MGAN trained on CIFAR-10 with GAN-MM objective.Images in
different rows are generated by different generators.
25
Published as a conference paper at ICLR 2019
Figure 22: Images generated by MGAN trained on CIFAR-10 with WGAN objective.Images in
different rows are generated by different generators.
Figure 23: Images generated by DCGAN trained on CIFAR-10 with GAN-NS objective.Images in
different rows are generated by different generators.
26
Published as a conference paper at ICLR 2019
Figure 24: Images generated by DCGAN trained on CIFAR-10 with LSGAN objective.Images in
different rows are generated by different generators.
Figure 25: Images generated by DCGAN trained on CIFAR-10 with GAN-MM objective.Images in
different rows are generated by different generators.
27
Published as a conference paper at ICLR 2019
Figure 26: Images generated by DCGAN trained on CIFAR-10 with WGAN objective.Images in
different rows are generated by different generators.
28