Published as a conference paper at ICLR 2019
The relativistic discriminator: a key element
missing from standard GAN
Alexia Jolicoeur-Martineau
Lady Davis Institute
MILA, Universite de Montreal
Montreal, Canada
alexia.jolicoeur-martineau@mail.mcgill.ca
Ab stract
In standard generative adversarial network (SGAN), the discriminator D estimates
the probability that the input data is real. The generator G is trained to increase
the probability that fake data is real. We argue that it should also simultaneously
decrease the probability that real data is real because 1) this would account for a
priori knowledge that half of the data in the mini-batch is fake, 2) this would be
observed with divergence minimization, and 3) SGAN would be more similar to
integral probability metric (IPM) GANs.
We show that this property can be induced by using a “relativistic discriminator”
which estimate the probability that the given real data is more realistic than a
randomly sampled fake data. We also present a variant in which the discriminator
estimate the probability that the given real data is more realistic than fake data,
on average. We generalize both approaches to non-standard GAN loss functions
and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic
average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs
which use the identity function.
Empirically, we observe that 1) RGANs and RaGANs are significantly more stable
and generate higher quality data samples than their non-relativistic counterparts,
2) Standard RaGAN with gradient penalty generate data of better quality than
WGAN-GP while only requiring a single discriminator update per generator update
(reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs
are able to generate plausible high resolutions images (256x256) from a very small
sample (N=2011), while GAN and LSGAN cannot; these images are of significantly
better quality than the ones generated by WGAN-GP and SGAN with spectral
normalization.
The code is freely available on https://github.com/AlexiaJM/RelativisticGAN.
1	Introduction
Generative adversarial networks (GANs) (Hong et al., 2017) form a broad class of generative models
in which a game is played between two competing neural networks, the discriminator D and the
generator G. D is trained to discriminate real from fake data, while G is trained to generate fake data
that D will mistakenly recognize as real. In the original GAN by Goodfellow et al. (2014), which
we refer to as Standard GAN (SGAN), D is a classifier, thus it is predicting the probability that the
input data is real. When D is optimal, the loss function of SGAN is approximately equal to the
Jensen-Shannon divergence (JSD)(GoodfelloW et al., 2014).
SGAN has two variants for the generator loss functions: saturating and non-saturating. In practice, the
former has been found to be very unstable, While the latter has been found to more stable (GoodfelloW
et al., 2014). Under certain conditions, Arjovsky & Bottou (2017) proved that, if real and fake data
are perfectly classified, the saturating loss has zero gradient and the non-saturating loss has non-zero,
but volatile gradient. In practice, this means that the discriminator in SGAN often cannot be trained
to optimality or With a too high learning rate; otherWise, gradients may vanish and, if so, training Will
stop. This problem is generally more noticeable in high-dimensional setting (e.g., high resolution
1
Published as a conference paper at ICLR 2019
images and discriminator architectures with high expressive power) given that there are enough
degrees of freedom available to perfectly classify the training set.
To improve on SGAN, many GAN variants have been suggested using different loss functions and
discriminators that are not classifiers (e.g., LSGAN (Mao et al., 2017), WGAN (Arjovsky et al.,
2017)). Although these approaches have partially succeeded in improving stability and data quality,
the large-scale study by Lucic et al. (2017) suggests that these approaches do not consistently improve
on SGAN. Additionally, some of the most successful approaches, such as WGAN-GP (Gulrajani
et al., 2017), are much more computationally demanding than SGAN.
Many of the recent successful GANs variants have been based on Integral probability metrics (IPMs)
(Muller, 1997)(e.g., WGAN , WGAN-GP, Fisher GAN (MroUeh & SercU,2017), Sobolev GAN
(Mroueh et al., 2017)). In IPM-based GANs, the discriminator is real-valued and constrained to a
specific class of fUnction which regUlarize the discriminator. See MroUeh et al. (2017) for a review of
the different IPMs.
These IPM constraints have been shown to be beneficial even in non-IPM based GANs. Spectral
normalization (Miyato et al., 2018) improves the stability of varioUs GANs and it consists in making
the discriminator Lipschitz-1, which is the constraint of WGAN. Similarly, the gradient penalty of
WGAN-GP also provides improve the stability of SGAN (FedUs et al., 2017). AlthoUgh this shows
that certain IPM constraints improve the stability of GANs, it does not explain why IPM-based GANs
generally provide increased stability over other metrics/divergences in GANs (e.g., JSD for SGAN,
f -divergences for f -GANs (Nowozin et al., 2016)).
Note that althoUgh powerfUl, IPM-based GANs tend to more compUtationally demanding than other
GANs. Certain IPM-based GANs Use a gradient penalty (e.g. WGAN-GP, Sobolev GAN) which is
very compUtationally costly and most IPM-based GANs need more than one discriminator Update per
generator Update (WGAN-GP reqUires at least 5 (GUlrajani et al., 2017)). AssUming eqUal training
time for D and G, every additional discriminator Update increase training time by a significant 50%.
In this paper, we argUe that non-IPM-based GANs are missing a key ingredient, a relativistic
discriminator, which IPM-based GANs already possess. We show that a relativistic discriminator is
necessary to make GANs analogoUs to divergence minimization and prodUce sensible predictions
based on the a priori knowledge that half of the samples in the mini-batch are fake. We provide
empirical evidence showing that GANs with a relativistic discriminator are more stable and prodUce
data of higher qUality.
2	Background
2.1	Generative adversarial networks
GANs can be defined very generally in terms of the discriminator in the following way:
LD = Exr〜P [fι(D(xr))i + Ez〜Pzhf2(D(G(z)))i ,	(1)
and
LG = Exr〜P [gι(D(xr))] + Ez〜Pz ®2(D(G(z)))],	(2)
where fι, /2, gι, g2 are scalar-to-scalar functions, P is the distribution of real data, Pz is generally a
mUltivariate normal distribUtion centered at 0 with variance 1, D(x) is the discriminator evalUated at
x, G(z) is the generator evaluated at z (Q is the distribution of fake data, thus of G(z)). Note that,
through the paper, we refer to real data as xr and fake data as xf . Without loss of generality, we
assume that both LD and LG are loss functions to be minimized.
Most GANs can be separated into two classes: non-saturating and saturating loss functions. GANs
with the saturating loss are such that gι=-fι and g2=-f2, while GANs With the non-saturating loss
are such that g1=f2 and g2=f1. Saturating GANs are intuitive as they can be interpreted as alternating
between maximizing and minimizing the same loss function. After training D to optimality, the loss
function is generally an approximation of a divergence (e.g., Jensen-Shannon divergence (JSD) for
SGAN (Goodfellow et al., 2014), f -divergences for F-GANs (Nowozin et al., 2016), and Wassertein
distance for WGAN (Arjovsky et al., 2017)). Thus, training G to minimize LG can be roughly
interpreted as minimizing the approximated divergence (although this is not technically true; see
2
Published as a conference paper at ICLR 2019
Jolicoeur-Martineau (2018)). On the other hand, non-saturating GANs can be thought as optimizing
the same loss function, but swapping real data with fake data (and vice-versa). In this article, unless
otherwise specified, we assume a non-saturating loss for all GANs.
SGAN assumes a cross-entropy loss, i.e., f1 (D(x)) = - log(D(x)) and f2(D(x)) = - log(1 -
D(x)), where D(x) = sigmoid(C(x)), and C(x) is the non-transformed discriminator output (which
we call the critic as per Arjovsky et al. (2017)). In most GANs, C(x) can be interpreted as how
realistic the input data is; a negative number means that the input data looks fake (e.g., in SGAN,
D(x) = sigmoid(-5) = 0), while a positive number means that the input data looks real (e.g., in
SGAN, D(x) = sigmoid(5) = 1).
2.2	Integral probability metrics
IPMs are statistical divergences represented mathematically as:
IPMF(P||Q) = sup Ex〜p[C(x)] - Ex〜q[C(x)],
C∈F
where F is a class of real-valued functions.
T 1 ʌ» r 1 1 √-1 * TL T	1 1 i' 1 ♦	. ∙ -t IC 1	/∕7^Λ∕∖∖ ~∕7^Λ∕∖∖	7^Λ∕∖
IPM-based GANs can be defined using equation 1 and 2 where fι(D(X)) = g2(D(χ)) = -D(χ)
and f2(D(x)) = gι(D(x)) = D(χ), where D(X) = C(x) (i.e., no transformation IS applied). It can
be observed that both discriminator and generator loss functions are unbounded and would diverge
to -∞ if optimized directly. However, IPMs assume that the discriminator is of a certain class of
function that does not grow too quickly which prevent the loss functions from diverging. Each IPM
applies a different constraint to the discriminator (e.g., WGAN assumes a Lipschitz D, WGAN-GP
assumes that D has a gradient norm equal to 1 around real and fake data).
3	Missing property of SGAN
We argue that the key missing property of SGAN is that the probability of real data being real
(D(Xr)) should decrease as the probability of fake data being real (D(Xf)) increase. We provide
three arguments suggesting that SGAN should have this property.
3.1	Prior knowledge argument
Assuming a rational human was shown half real data and half fake data. If they perceived all samples
shown as equally real (C(Xf) ≈ C(Xr) for most Xr and Xf), they would assume that each sample
has probability .50 of being real. However, this is not the case for the discriminator in SGAN. If
all samples looked real (C(Xf) ≈ C(Xr) ≥ 3), D would assume incorrectly that they are indeed all
real (D(X) ≈ 1 for all X). Of course, once trained with the labels, D would decrease D(Xf) and
thus would obtain more reasonable estimates. However, if D(Xr) decreased as D(Xf ) increased, we
would have had that D(X) ≈ .50 for all X before even retraining D. A rational human would not
require retraining. IPM-based GANs implicitly account for the fact that some of the samples must be
fake because they compare how realistic real data is compared to fake data. This is the behavior that
we would want.
3.2	Divergence minimization argument
In SGAN, when optimized, we have that the discriminator loss function is equal to the
Jensen-Shannon divergence (JSD) (Goodfellow et al., 2014). The JSD is minimized (JSD(P||Q)=
0) when D(Xr) = D(Xf) = 1 for all Xr ∈ P and Xf ∈ Q and maximized (JSD(P||Q) = log(2))
when D(Xr) = 1, D(Xf) = 0 for all Xr ∈ P and Xf ∈ Q. Thus, if we were directly minimizing the
divergence from maximum to minimum, we would expect D(Xr) to smoothly decrease from 1 to
.50 for most Xr and D(Xf) to smoothly increase from 0 to .50 for most Xf (Figure 1a). However,
when minimizing the saturating loss in SGAN, we are only increasing D(Xf), we are not decreasing
D(Xr) (Figure 1b). Furthermore, we are bringing D(Xf) closer to 1 rather than .50.
This means that SGAN dynamics are very different from the minimization of the JSD. To bring
SGAN closer to divergence minimization, training the generator should not only increase D(Xf) but
3
Published as a conference paper at ICLR 2019
Figure 1: Expected discriminator output of the real and fake data for the a) direct minimization of the
Jensen-Shannon divergence, b) actual training of the generator to minimize its loss function, and C)
ideal training of the generator to minimize its loss function (lines are dotted when they cross beyond
the equilibrium to signify that this may or may not be necessary).
also decrease D(xr) (Figure 1c). Note that although specific to the JSD, similar dynamics are true for
other divergences; when the divergence is maximal, D(xr) and D(xf) are very far from one another,
but they converge to the same value as the divergence approach zero. Thus, this argument applies to
other divergences.
3.3	Gradient argument
We compare the gradients of standard GAN and IPM-based GANs for further insight. It can be shown
that the gradients of the discriminator and generator in non-saturating SGAN are respectively:
VwLDAN = -Exr〜P [(1 - D(Xr))VwC(Xr)] + Exf〜Qθ [D(xf XwC(Xf)],	⑶
VeLGAN = -Ez〜P= [(1 - D(G(Z)))VxC(G(Z))JθG(z)],	(4)
where J is the Jacobian.
It can be shown that the gradients of the discriminator and generator in IPM-based GANs are
respectively:
VwLDPM = -Exr〜P[VwC(Xr)]+ Exf 〜Qθ [VwC(Xf)],	(5)
VθLIGPM =-Ez 〜Pz [VxC(G(Z))JθG(Z)],	(6)
where C(X) ∈ F (the class of functions assigned by the IPM).
From these equations, it can be observed that SGAN leads to the same dynamics as IPM-based GANs
when we have that:
1.	D(Xr) = 0, D(Xf) = 1 in the discriminator step of SGAN
2.	D(Xf) = 0 in the generator step of SGAN.
3.	C(X) ∈ F
Assuming that the discriminator and generator are trained to optimality in each step (which we
sometimes do for D, but never for G) and that it is possible to perfectly distinguish real from the
fake data (strong assumption, but generally true early in training); we would have that D(Xr) = 1,
D(Xf) = 0 in the generator step and that D(Xr) = 1, D(Xf) = 1 in the discriminator step for
most Xr and Xf (Figure 1b). Thus, the only missing assumption would be that D(Xr) = 0 in the
discriminator step.
Although the above scenario is not realistic (because we never train G to optimality), if all the
assumptions were respected and the generator could indirectly influence D(Xr), we would have
that D(Xr) = 0, D(Xf) = 1. Thus, SGAN would have the same gradients as IPM-based GANs.
We conjecture that making SGAN more similar to IPM-based GANs could potentially improve its
stability (our results will show that it does in fact improves stability).
4
Published as a conference paper at ICLR 2019
4	Method
4.1	Relativistic standard GAN
In standard GAN, the discriminator can be defined, in term of the non-transformed layer C(x), as
D(x) = sigmoid(C(x)). A simple way to make discriminator relativistic (i.e., having the output of
D depends on both real and fake data) is to sample from real/fake data pairs x = (xr ,xf) and define
it as D(X) = sigmoid(C(Xr) - C(Xf)).
We can interpret this modification in the following way: the discriminator estimates the probability
that the given real data is more realistic than a randomly sampled fake data. Similarly, we can
define Drev(X) = Sigmoid(C(Xf) — C(Xr)) as the probability that the given fake data is more
realistic than a randomly sampled real data. An interesting property of this discriminator is that we
do not need to include Drev in the loss function through log(1 - Drev (X)) because We have that
1 - Drev(X) = 1 - SigmOid(C(Xf) - C(Xr)) = SigmOid(C(Xr) -C(Xf)) = D(X); thus, log(D(X))
=lθg(1 - Drev (X)).
The discriminator and generator (non-saturating) loss functions of the Relativistic Standard GAN
(RSGAN) can be Written as:
LRSGAN = -E(xr,xf)〜(P,Q) [log(SigmOid(C(Xr) - C(Xf)))].	⑺
LGSG AN = -E(χr,χf )〜(P,Q) [log(sigmoid(C (Xf) - C(Xr )))] .	(8)
4.2	Relativistic GANs
More generally, We consider any discriminator defined as a(C(Xr) -C(Xf)), Where a is the activation
function, to be relativistic. This means that almost any GAN can have a relativistic discriminator.
This forms a neW class of models Which We call Relativistic GANs (RGANs).
Most GANs can be parametrized very generally in terms of the critic:
LGAN = Exr〜P [fl(C(Xr))] + Exf〜Q [f2(C(Xf ))]	(9)
and
LGAN = Exr〜P [gl(C(Xr))] + Exf〜Q [g2(C(Xf ))],	(10)
Where f1, f2, g1, g2 are scalar-to-scalar functions. If We use a relativistic discriminator, these GANs
noW have the folloWing form:
LGGAN = E(xr,xf)MP,Q) [fι(C(Xr) - C(Xf))]+ E(xr,xf)MP,Q) [f2(C(Xf) - C(Xr))]	(11)
and
LRGAN = E(xr,xf )〜(P,Q) [gι(C(Xr ) - C(Xf ))]+ E(xr,xf )〜(P,Q) [g2(C(Xf ) - C(Xr ))] .	(12)
If one use the identity function (i.e., f1(y) = g2(y) = -y, f2(y) = g1 (y) = y), this results in a
degenerate case since there is no supremum/maximum. HoWever, if one adds a constraint so that
C(Xr) - C(Xf) is bounded, then there is a supremum and one arrives at IPM-based GANs. Thus,
although different, IPM-based GANs share a very similar loss function focused on the difference in
critics.
Importantly, g1 is normally ignored in GANs because its gradient is zero since the generator does not
influence it. HoWever, in RGANs, g1 is influenced by fake data, thus by the generator.
4.3	Relativistic average GANs
The discriminator has a very different interpretation in SGAN compared to RSGAN. In SGAN, D(X)
estimates the probability that X is real, While in RGANs, D(Xr, Xf) estimates the probability that
Xr is more realistic than Xf. As a middle ground, We developed an alternative to the Relativistic
Discriminator, Which retains approximately the same interpretation as the discriminator in SGAN
While still being relativistic.
5
Published as a conference paper at ICLR 2019
We propose the Relativistic average Discriminator (RaD) which compares the critic of the input data
to the average critic of samples of the opposite type. The discriminator loss function for this approach
can be formulated as:
LDaSGAN = -Exr〜P [log (D(Xr)))] - Exf〜Q [log (1 - D(Xf ))] ,	(13)
where
D(X)
ʃsigmOid(C(X) - Exf 〜QC(Xf))
ISigmOid(C(X)- Exr〜PC(Xr))
if X is real
if X is fake.
(14)
RaD has a mOre similar interpretatiOn tO the standard discriminatOr than the relativistic discriminatOr.
With RaD, the discriminator estimates the probability that the given real data is more realistic
than fake data, on average.
As befOre, we can generalize this apprOach tO wOrk with any GAN lOss functiOn using the fOllOwing
fOrmulatiOn:
LRaGAN = Exr〜P [fl (C(Xr) - Exf〜QC(Xf )))] + Exf〜Q [f2 (C(Xf ) - Exr〜PC(Xr))] . (15)
LRaGAN = Exr〜P [g1 (C(Xr) - Exf〜QC(Xf )))] + Exf〜Q [g2 (C(Xf ) - Exr〜PC(Xr))] . (16)
We call this general apprOach Relativistic average GAN (RaGAN).
5	Experiments
Experiments were cOnducted On the CIFAR-10 dataset (Krizhevsky, 2009) and the CAT dataset
(Zhang et al., 2008). COde was written in PytOrch (Paszke et al., 2017) and mOdels were trained using
the Adam Optimizer (Kingma & Ba, 2014) fOr 100K generatOr iteratiOns with seed 1 (which shOws
that We did not fish for the best seed, instead, We selected the seed a priori). We report the Frechet
InceptiOn Distance (FID) (Heusel et al., 2017), a measure that is generally better cOrrelated with data
quality than the Inception Distance (Salimans et al., 2016) (Borji, 2018); loWer FID means that the
generated images are of better quality.
For the models architectures, We used the standard CNN described by Miyato et al. (2018) on CIFAR-
10 and a relatively standard DCGAN architecture (Radford et al., 2015) on CAT (see Appendix).
We also provide the source code required to replicate all analyses presented in this paper (See our
repository: [Anonymous until peer revieW is finished]).
5.1	CIFAR- 1 0
In these analyses, We compared standard GAN (SGAN), least-squares GAN (LSGAN), Wassertein
GAN improved (WGAN-GP), Hinge-loss GAN (HingeGAN) (Miyato et al., 2018), Relativistic
SGAN (RSGAN), Relativistic average SGAN (RaSGAN), Relativistic average LSGAN (RaLSGAN),
and Relativistic average HingeGAN (RaHingeGAN) using the standard CNN architecture on stable
setups (See Appendix for details on the loss functions used). Additionally, We tested RSGAN and
RaSGAN With the same gradient-penalty as WGAN-GP (named RSGAN-GP and RaSGAN-GP
respectively).
We used the folloWing tWo knoWn stable setups: (DCGAN setup) lr = .0002, nD = 1, β1 = .50
and β2 = .999 (Radford et al., 2015), and (WGAN-GP setup) lr = .0001, nD = 5, β1 = .50 and
β2 = .9 (Gulrajani et al., 2017), Where lr is the learning rate, nD is the number of discriminator
updates per generator update, and β1 , β2 are the ADAM momentum parameters. For optimal stability,
We used batch norm (Ioffe & Szegedy, 2015) in G and spectral norm (Miyato et al., 2018) in D.
Results are presented in Table 1. We observe that RSGAN and RaSGAN generally performed better
than SGAN. Similarly, RaHingeGAN performed better than HingeGAN. RaLSGAN performed on
par With LSGAN, albeit sightly Worse. WGAN-GP performed poorly in the DCGAN setup, but very
Well in the WGAN-GP setup. RasGAN-GP performed poorly; hoWever, RSGAN-GP performed better
than all other loss functions using only one discriminator update per generator update. Importantly,
the resulting FID of 25.60 is on par With the loWest FID obtained for this architecture using spectral
normalization, as reported by Miyato et al. (2018) (25.5). Overall, these results shoW that using a
relativistic discriminator generally improve data generation quality and that RSGAN Works very Well
in conjunction With gradient penalty to obtain state-of-the-art results.
6
Published as a conference paper at ICLR 2019
Table 1: Frechet Inception Distance (FID) at exactly 100k generator iterations on the CIFAR-10
dataset using stable setups with different GAN loss functions. We used spectral norm in D and batch
norm in G. All models were trained using the same a priori selected seed (seed=1).
lr = .0002	lr= .0001
β= (.50,.999) β = (.50,.9)
Loss	nD = 1	nD = 5
SGAN	40.64	41.32
RSGAN	36.61	55.29
RaSGAN	31.98	37.92
LSGAN	29.53	187.01
RaLSGAN	30.92	219.39
HingeGAN	49.53	80.85
RaHingeGAN	39.12	37.72
WGAN-GP	83.89	27.81
RSGAN-GP	25.60	28.13
RaSGAN-GP	331.86	
5.2	CAT
CAT is a dataset containing around 10k pictures of cats with annotations. We cropped the pictures
to the faces of the cats using those annotations. After removing outliers (hidden faces, blurriness,
etc.), the CAT dataset contained 9304 images ≥ 64x64, 6645 images ≥ 128x128, and 2011 images ≥
256x256. The CAT dataset is particularly challenging due to its small sample size and high-resolution
images; this makes it perfect for testing the stability of different GAN loss functions.
We trained different GAN loss functions on 64x64, 128x128, 256x256 images. For 256x256
images, we compared RaGANs to known stable approaches: SpectralSGAN (SGAN with spectral
normalization in D) and WGAN-GP. Although some approaches were able to train on 256x256
images, they did so with significant mode collapse. To alleviate this problem, for 256x256 images,
we packed the discriminator (Lin et al., 2017) (i.e., D took a concatenated pair of images instead of a
single image). We looked at the minimum, maximum, mean and standard deviation (SD) of the FID
at 20k, 30k, ..., 100k generator iterations; results are presented in Table 2.
Overall, we observe lower minimum FID, maximum FID, mean and standard deviation (sd) for
RGANs and RaGANs than their non-relativistic counterparts (SGAN, LSGAN, RaLSGAN).
In 64x64 resolution, both SGAN and LSGAN generated images with low FID, but they did so in a
very unstable matter. For example, SGAN went from a FID of 17.50 at 30k iterations, to 310.56 at
40k iterations, and back to 27.72 at 50k iterations. Similarly, LSGAN went from a FID of 20.27 at
20k iterations, to 224.97 at 30k iterations, and back to 51.98 at 40k iterations. On the other hand,
RaGANs were much more stable (lower max and SD) while also resulting in lower minimum FID.
Using gradient-penalty did not improve data quality; however, it reduced the SD lower than without
gradient penalty, thus increasing stability further.
SGAN was unable to converge on 128x128 or bigger images and LSGAN was unable to converge
on 256x256 images. Meanwhile, RaGANs were able to generate plausible images with low FID in
all resolutions. Although SpectralSGAN and WGAN-GP were able to generate 256x256 images of
cats, the samples they generated were of poor quality (high FID). Thus, in this very difficult setting,
relativism provided a greater improvement in quality than gradient penalty or spectral normalization.
6	Conclusion and future work
In this paper, we proposed the relativistic discriminator as a way to fix and improve on standard GAN.
We further generalized this approach to any GAN loss and introduced a generally more stable variant
called RaD. Our results suggest that relativism significantly improve data quality and stability of
7
Published as a conference paper at ICLR 2019
Table 2: Minimum (min), maximum (max), mean, and standard deviation (SD) of the Frechet
Inception Distance (FID) calculated at 20k, 30k . . . , 100k generator iterations on the CAT dataset
with different GAN loss functions. The hyper-parameters used were lr = .0002, β = (.50, .999),
nD = 1, and batch norm (BN) in D and G. All models were trained using the same a priori selected
seed (seed=1). Note: A missing number imply that the model did not converge and became stuck in
the first few iterations.______________________________________________
Loss	Min	Max	Mean	SD
64x64 images (N=9304)				
SGAN	16.56	310.56	52.54	96.81
RSGAN	19.03	42.05	32.16	7.01
RaSGAN	15.38	33.11	20.53	5.68
LSGAN	20.27	224.97	73.62	61.02
RaLSGAN	11.97	19.29	15.61	2.55
HingeGAN	17.60	50.94	32.23	14.44
RaHingeGAN	14.62	27.31	20.29	3.96
RSGAN-GP	16.41	22.34	18.20	1.82
RaSGAN-GP	17.32	22	19.58	1.81
128x128 images (N=6645)				
SGAN	-	-	-	-
RaSGAN	21.05	39.65	28.53	6.52
LSGAN	19.03	51.36	30.28	10.16
RaLSGAN	15.85	40.26	22.36	7.53
256x256 images (N=2011)				
SGAN1	-	-	-	-
RaSGAN	32.11	102.76	56.64	21.03
SpectralSGAN	54.08	90.43	64.92	12.00
LSGAN1	-	-	-	-
RaLSGAN	35.21	299.52	70.44	86.01
WGAN-GP	155.46	437.48	341.91	101.11
GANs at no computational cost. Furthermore, using a relativistic discriminator with other tools of
the trade (spectral norm, gradient penalty, etc.) may lead to better state-of-the-art.
Future research is needed to fully understand the mathematical implications of adding relativism to
GANs. Furthermore, our experiments were limited to certain loss functions using only one seed,
due to computational constraints. More experiments are required to determine which relativistic
GAN loss function is best over a wide-range of datasets and hyper-parameters. We greatly encourage
researchers and machine learning enthusiasts with greater computing power to experiment further
with our approach.
References
Martin Arjovsky and Leon Bottou. Towards principled methods for training generative adversarial
networks. arXiv preprint arXiv:1701.04862, 2017.
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein generative adversarial networks.
In International Conference on Machine Learning, pp. 214-223, 2017.
Ali Borji. Pros and cons of gan evaluation measures. arXiv preprint arXiv:1802.03446, 2018.
William Fedus, Mihaela Rosca, Balaji Lakshminarayanan, Andrew M Dai, Shakir Mohamed, and Ian
Goodfellow. Many paths to equilibrium: Gans do not need to decrease adivergence at every step.
arXiv preprint arXiv:1710.08446, 2017.
8
Published as a conference paper at ICLR 2019
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani,
M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger (eds.), Advances in Neural
Information Processing Systems 27, pp. 2672-2680. Curran Associates, Inc., 2014. URL
http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville.
Improved training of wasserstein gans. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 30, pp. 5767-5777. Curran Associates, Inc., 2017. URL http://papers.nips.cc/
paper/7159- improved- training- of- wasserstein- gans.pdf.
Martin HeUseL HUbert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Gunter Klambauer, and
Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a nash equilibrium.
arXiv preprint arXiv:1706.08500, 2017.
Yongjun Hong, Uiwon Hwang, Jaeyoon Yoo, and Sungroh Yoon. How generative adversarial nets
and its variants work: An overview of gan. arXiv preprint arXiv:1711.05914, 2017.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
Alexia Jolicoeur-Martineau. Gans beyond divergence minimization. arXiv preprint arXiv:1809.02145,
2018.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
Zinan Lin, Ashish Khetan, Giulia Fanti, and Sewoong Oh. Pacgan: The power of two samples in
generative adversarial networks. arXiv preprint arXiv:1712.04086, 2017.
Mario Lucic, Karol Kurach, Marcin Michalski, Sylvain Gelly, and Olivier Bousquet. Are gans created
equal? a large-scale study. arXiv preprint arXiv:1711.10337, 2017.
Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smolley. Least
squares generative adversarial networks. In 2017 IEEE International Conference on Computer
Vision (ICCV), pp. 2813-2821. IEEE, 2017.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for
generative adversarial networks. arXiv preprint arXiv:1802.05957, 2018.
Youssef Mroueh and Tom Sercu. Fisher gan. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 30, pp. 2513-2523. Curran Associates, Inc., 2017. URL http://papers.nips.cc/
paper/6845- fisher- gan.pdf.
Youssef Mroueh, Chun-Liang Li, Tom Sercu, Anant Raj, and Yu Cheng. Sobolev gan. arXiv preprint
arXiv:1711.04894, 2017.
Alfred Muller. Integral probability metrics and their generating classes of functions. Advances in
Applied Probability, 29(2):429-443, 1997.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training genera-
tive neural samplers using variational divergence minimization. In D. D. Lee,
M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (eds.), Advances in Neu-
ral Information Processing Systems 29, pp. 271-279. Curran Associates, Inc., 2016.
URL	http://papers.nips.cc/paper/6066-f-gan-training-generative-
neural-samplers-using-variational-divergence-minimization.pdf.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. 2017.
9
Published as a conference paper at ICLR 2019
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, and
Xi Chen. Improved techniques for training gans. In D. D. Lee, M. Sugiyama, U. V. Luxburg,
I. Guyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems 29, pp.
2234-2242. Curran Associates, Inc., 2016. URL http://papers.nips.cc/paper/612 5-
improved-techniques-for-training-gans.pdf.
Weiwei Zhang, Jian Sun, and Xiaoou Tang. Cat head detection-how to effectively exploit shape and
texture features. In European Conference on Computer Vision, pp. 802-816. Springer, 2008.
10
Published as a conference paper at ICLR 2019
Appendices
A Intuitive and memeful visual representation of RaGANs
Table 3: An illustrative example of the discriminator’s output in standard GAN as traditionally
defined (P (xr is real) = sigmoid(C(xr))) versus the Relativistic average Discriminator (RaD)
(P(Xr is real|C(Xf)) = Sigmoid(C(Xr) - C(Xf))). Breads represent real images, while dogs
represent fake images.
Scenario	Absolute probability	Relative probability
(Standard GAN) (Relativistic average Standard GAN)
Real image looks real
and
fake images look fake
C (Xf) = -5
P(Xr isbread∣C(Xf)) = 1
C(Xr) = 8
P(Xr is bread) = 1
Real image looks real
but
fake images look
similarly real on average
C (Xf) = 7
P(Xr is bread∣C(Xf)) = .73
C(Xr) = 8
P(Xr is bread) = 1
Real image looks fake
but
fake images look more
fake on average
C (Xf) = -5
P(Xr is bread∣C(Xf)) = .88
C(Xr) = -3
P(Xr is bread) = .05
B Intuition behind RaGANs
Although the relative discriminator provide the missing property that we want in GANs (i.e., G
influencing D(Xr)), its interpretation is different from the standard discriminator. Rather than
measuring “the probability that the input data is real”, it is now measuring “the probability that the
11
Published as a conference paper at ICLR 2019
input data is more realistic than a randomly sampled data of the opposing type (fake if the input
is real or real if the input is fake)”. To make the relativistic discriminator act more globally, as in
its original definition, our initial idea was the following: average the relativistic discriminator over
random samples of data of the opposing type. This can be conceptualized in the following way:
P(Xr is real) := Exf 〜q[P(Xr is more real than Xf)]
=Exf〜Q[sigmoid(C(xr) - C(Xf))]
=Exf 〜Q[D(Xr ,Xf)],
P(Xf is real) := Exr〜p[P(Xf is more real than Xr)]
=Exr〜p[sigmoid(C(Xf) - C(Xr))]
=Exr 〜p[D(Xf,Xr )],
where D(Xr, Xf) = sigmoid(C(Xr) - C(Xf)).
Then, the following loss function for D could be applied:
LD = -Exr〜P [log (Exf〜QD(Xr,Xf)]))[- Exf〜Q [log(1- Exr〜p[D(Xf,x)])].	(17)
The main problem with this idea is that it would require looking at all possible combinations of real
and fake data in the mini-batch. This would transform the problem from O(m) to O(m2) complexity,
where m is the batch size. This is problematic; therefore, we do not use this approach.
Instead, we propose to use the Relativistic average Discriminator (RaD) which compares the critic of
the input data to the average critic of samples of the opposite type (See section 4.3). This approach
has O(m) complexity.
C Gradients
C.1 SGAN
PWL(DAN = -VwExr〜P [log D(Xr)] - VwExf 〜Qθ [log(1 - D(Xf))]
eC(xr)	eC(xf)
-VWExr〜P log (eC(xr)+ i J — VWExf〜qθ log (1 — eC(xf) + i J
-VwExr〜P [c(Xr) - log 卜C(Xr) + 1)i - VwExf〜Qθ [log(1) - log 卜C(Xf) + 1)]
-Exr 〜P [Vw C(Xr )]+ Exr 〜P
eC(xr)
eC(xr) + 1 VW C (Xr)
+ Exf 〜Qθ
eC(xf)
eC(xf) + 1 VW C(Xf)
-Exr 〜P [Vw C(Xr )]+ Exr 〜P D(Xr )Vw C(Xr )] + Exf 〜Q° D(Xf NW C(Xf )]
-Exr 〜P [(1 — D(Xr))VW C(Xr )] + Exf 〜q@ [D(Xf ) Vw C(Xf )]
VθLGAN = -VθEz〜Pz [logD(G(Z))]
eC(((z))
=-vθEzf悭(eC(G(z)) + 1 力
=-VθEz〜PzhC(G(Z))- log 卜C(G(Z)) + 1)]
eC(G(z))
=-Ez〜Pz VxC(G(z))JθG(z) - QC(G(Z))+ 1 ∖ VxC(G(z))JθG(Z)
=-Ez〜Pz [(1 - D(G(z)))VxC(G(z))JθG(z)]
C.2 IPM-based GANs
VWLDPM = -VWExr〜P [C(Xr )]+ VWExf 〜Qθ [C(Xf )]
=-Exr 〜P[Vw C(Xr )]+ Exf 〜Qg[Vw C(Xf )]
12
Published as a conference paper at ICLR 2019
Vθ LGPM = -VθEz 〜Pz[C(G(z))]
=-Ez 〜Pz[VχC(G(z))Jθ G(z)]
D Simplified form of relativistic saturating and non-saturating GANs
The formulation of RGANs can be simplified when we have the following two properties: (1)
f2(-y) = f1(y) and (2) the generator assumes a non-saturating loss (g1(y) = f2(y) and g2(y) =
f1(y)). These two properties are observed in standard GAN, LSGAN using symmetric labels (e.g., -1
and 1), IPM-based GANs, etc. With these two properties, RGANs with non-saturating loss can be
formulated simply as:
and
LDAN= = E(Xr,Xf )〜(P,Q) [f1(C(xr) -C(xf))]	(18)
LRGAN* = E(χr,χf)MP,Q) [fι(C(xf) - C(Xr))].	(19)
Assuming f2(-y) = f1(y), we have that
LDGAN =旧(方一方于)〜(p,Q) [f1(C(Xr) - C(Xf ))] + E(xr,xf)〜(P,Q) [f2(C(Xf ) - C(Xr))]
=E(xr,Xf)〜(P,Q) [f1(C(Xr ) - C(Xf ))] + E(Xr ,Xf)〜(P,Q) [f1(C(Xr ) - C(Xf ))]
=2E(Xr,Xf)〜(P,Q)[f1(C(Xr) -C(Xf))].
If g1(y) = -f1 (y) and g2(y) = -f2 (y) (saturating GAN), we have that
LRgan-S = E(xr,Xf)〜(P,Q) [gι(C(Xr) - C(Xf))]+ E(xr,Xf)〜(P,Q) [g2(C(Xf) - C(Xr))]
=-E(xr,Xf)〜(P,Q)	[f1(C(Xr )	- C(Xf ))] - E(xr,Xf)〜(P,Q)	[f2(C(Xf )	- C(Xr ))]
=-E(xr,Xf )〜(P,Q)	[fl(C(Xr )	- C(Xf ))] - E(χr,χf )〜(P,Q)	[fι(C(Xr )	- C(Xf ))]
=-2E(xr,Xf)〜(P,Q) [f1(C(Xr ) - C(Xf ))] .
If g1 (y) = f2(y) and g2 (y) = f1(y) (non-saturating GAN), we have that
lRgan-NS =	E(Xr,Xf)〜(P,Q)[gl (C(Xr )	-	C(Xf ))]+	E(χr,χf )MP,Q)	[g2(C(Xf )	- C(Xr ))]
=E(Xr,Xf )〜(P,Q)	[f2(C(Xr )	-	C(Xf ))] +	E(Xr,Xf )〜(P,Q)	[f1(C(Xf )	- C(Xr ))]
=E(xr,Xf)〜(P,Q) [f1(C(Xf ) - C(Xr))] + E(xr,Xf)〜(P,Q) [f1(C(Xf ) - C(Xr))]
=2E(xr,Xf)〜(P,Q) [f1(C(Xf ) - C(Xr))] .
E Testing the gradient argument
Previously, we argued that SGAN could be equivalent to IPM-GANs under very strict conditions
and assumptions. We mentioned that although most assumptions are reasonable, the assumption that
the generator is trained to optimality is unrealistic. In which case, SGAN would not be equivalent to
IPM-based GANs since D(Xr) would not reach 0.
As an experiment, we calculated the mini-batch average of D(Xr) in the first 100 iterations of the
training for the CAT dataset in 256x256. Note that SGAN becomes stuck at around 200 iterations
and can never go beyond generating noise. Thus, a difference in the distribution of D(Xr ) could
reveal something meaningful about why Relativistic GANs can converge while their non-relativistic
counterparts cannot.
In those 100 iterations, we have that the distance between P and Q is maximal since G only generate
noise. Thus, we can perfectly distinguish real from fake data, which is one of the assumptions. The
remaining assumptions were that D and G would be trained to optimality. Although we did not train
D more than once, after the discriminator step, we generally had that D(Xr) ≈ 1. What we wanted
to verify is whether D(Xr) ≈ 0 after the generator step in Relativistic GANs, even though we did not
train G enough to reach optimality.
13
Published as a conference paper at ICLR 2019
Testing gradient argument (Giters = 1) Testing gradient argument (Giters = 2)
0 5 0 5
2 11
A=SU①P
0∙∣
0.00	0.25	0.50	0.75	1.00
mean(D(Xr))
SGAN
RSGAN
RaSGAN
4 3 2
A=SU①P
0∙∣ 厂 ，
0.00	0.25	0.50	0.75	1.00
mean(D(Xr))
SGAN
RSGAN
RaSGAN
Figure 2: Density plots of the mini-batch average of D(xr) during the first 100 iterations of training
on CAT with 256x256 images using only one or two generator updates per discriminator updates. If
D(xr) = 0 in all iterations, this would mean that the loss function would be the same as IPM-based
GANs.
Results are shown in Figure 2. We observe that with only one generator update per discriminator
update (nG = 1), RSGAN and RaSGAN never reach an average D(xr) of 0 but the distribution is
much less concentrated around 1 than with SGAN. With nG = 2, RSGAN and RaSGAN sometimes
reach an average D(xr) of0 and they form an almost uniform distribution around [0, 1]. This suggests
that with the missing property (i.e., using Relativistic GANs), SGAN can be made more similar to
IPM-based GANs, but never equivalent. Thus, Relativistic Standard GANs can be seen as having a
dynamic in-between SGAN and IPM-based GANs.
F CIFAR- 1 0 Hard/unstable experiments
In these analyses, we compared SGAN, LSGAN, WGAN-GP, RSGAN, RaSGAN, RaLSGAN, and
RaHingeGAN with the standard CNN architecture on unstable setups in CIFAR-10. Unless otherwise
specified, we used lr = .0002, β1 = .5, β2 = .999, nD = 1, and batch norm (Ioffe & Szegedy,
2015) in G and D. We tested the following four unstable setups: (1) lr = .001, (2) β1 = .9, β2 = .9,
(3) no batch norm in G or D, and (4) all activation functions replaced with Tanh in both G and D
(except for the output activation function of D).
Results are presented in Table 4. We observe that RaLSGAN performed better than LSGAN in
all setups. RaHingeGAN performed slightly worse than HingeGAN in most setups. RSGAN and
RaSGAN performed better than SGAN in two out of four setups, although differences were small.
WGAN-GP generally performed poorly which we suspect is due to the single discriminator update
per generator update. Overall, this provide good support for the improved stability of using the
relative discriminator with LSGAN, but not with HingeGAN and SGAN. Although results are worse
for the relativistic discriminator in some settings, differences are minimal and probably reflect natural
variations.
It is surprising to observe low FID for SGAN without batch normalization considering its well-known
difficulty with this setting (Arjovsky et al., 2017). Given these results, we suspected that CIFAR-10
may be too easy to fully observe the stabilizing effects of using the relative discriminator. Therefore,
in the manuscript, we focused on the more difficult CAT dataset with high resolution pictures.
G Loss functions used in experiments
G. 1 SGAN (non-saturating)
LDGAN = -Exr〜P [log(sigmoid(C(Xr)))] - Exf 〜Q [log(1 -Sigmoid(C(Xf)))]	(20)
LGGAN = -Exf 〜Q [log(sigmoid(C(Xf)))]	(21)
G.2 RSGAN
LRSGAN = -E(xr,x	(p,Q) [log(sigmoid(C(Xr) - C(Xf)))]	(22)
14
Published as a conference paper at ICLR 2019
Table 4: Frechet Inception Distance (FID) at exactly 100k generator iterations on the CIFAR-10
dataset using unstable setups with different GAN loss functions. Unless otherwise specified, we used
lr = .0002, β = (.50, .999), nD = 1, and batch norm (BN) in D and G. All models were trained
using the same a priori selected seed (seed=1).
Loss	lr = .001	β =(.9,.9)	No BN	Tanh
SGAN	154.20	35.29	35.54	59.17
RSGAN	50.95	45.12	37.11	77.21
RaSGAN	55.55	43.46	41.96	54.42
LSGAN	52.27	225.94	38.54	147.87
RaLSGAN	33.33	48.92	34.66	53.07
HingeGAN	43.28	33.47~	34.21	58.51
RaHingeGAN	51.05	42.78	43.75	50.69
WGAN-GP	61.97	104.95	85.27	59.94
LRSGAN = -E(χr,χf )MP,Q) [log(sigmoid(C(Xf) - C(Xr)))]	(23)
G.3 RASGAN
LDSGAN = -Exr〜P [log (D(Xr))] - Exf〜Q [log(1 - D(Xf 川	(24)
LRaSGAN = -Exf〜Q [log (D(Xf ))i - Exr〜P [log(1 - D(Xr))]	(25)
D(Xr) = sigmoid (C(Xr) - Exf 〜QC(Xf))
D(Xf) = sigmoid (C(Xf) - Exr〜PC(Xr))
G.4 LSGAN
LlDIGAN = Exr〜P [(C(Xr) - 0)2] + Exf 〜Q [(C(Xf) - 1)2]	(26)
LGSGAN = Exf〜Q [(C(Xf )-0)2]	(27)
G.5 RALSGAN
LDaLSGAN = Exr〜P [(C(Xr) - Exf 〜QC(Xf) - 1)2] + Exf〜Q [(C(Xf) - Exr〜PC(Xr) + 1)2]
(28)
Ra LG	LSGAN = Exf 〜P [(C(Xf ) - Exr〜PC(Xr ) - 1)2] + Exr〜P [(C(Xr ) - Exf 〜QC(Xf ) + 1)2] (29)
G.6	HINGEGAN
	LHngeGAN = Exr〜P [maχ(0,1 - C(Xr))]+ Exf〜Q [maχ(0,1 + C(Xf))]	(30)
	LGirneGAN = -Exf 〜Q [C(Xf )]	(31)
G.7	RAHINGEGAN
	LHngeGAN = Exr〜Phmax(0,1 - D(Xr))] + Exf 〜Qhmax(0,1 + D(Xf))]	(32)
	LHngeGAN = Exf 〜Phmax(0,1 - D(Xf))] + Exr〜Q [max(0,1 + D(Xr))]	(33)
ΓΛ /	∖ zɔ/ ∖ TTT>	zɔ/ \
D(Xr )	=	C(Xr )	-	Exf 〜QC(Xf )
γλ /	∖	zɔ/ ∖	πτ> zɔ/	\
D(Xf )	=	C(Xf )	-	Exr ~PC(Xr )
15
Published as a conference paper at ICLR 2019
G.8 WGAN-GP
LDGAN-gp = -Exr〜P [C(xr)]+ Exf〜Q [C(Xf)]+ λEx〜Px [(∣∣V^C(X) ||2 - 1)2]
LWGAN-GP = -Exf 〜Q [C(xf)]
(34)
(35)
Px is the distribution of X = Exr + (1 - E)Xf, where Xr 〜P, Xf 〜Q, C 〜U[0,1].
G.9 RSGAN-GP
LRSGAN = -E(xr,xf7P,Q) [log(sigmoid(C(Xr) - C(Xf)))] + λE^〜Px [(IIVxC(X) ||2 - 1)2]
(36)
LRSGAN = -E(xr,xf)〜(P,Q) [log(sigmoid(C(Xf) - C(Xr)))]	(37)
Px is the distribution of X = EXr + (1 - E)Xf, where Xr 〜P, Xf 〜Q, E 〜U[0,1].
G.10 RASGAN-GP
LDlSGAN = -Exr〜P [log (D(Xr))]-Exf〜Q [log(1 - D(Xf)J+λE^〜Px [(IVxC(X) ||2 - 1)2]
(38)
LRaSGAN = -Exf〜Q [log (D(Xf ))i - Exr〜P [log(1 - D(Xr))]	(39)
D(Xr) = sigmoid (C(Xr) - Exf 〜QC(Xf))
D(Xf) = sigmoid (C(Xf) - Exr〜PC(Xr))
Px is the distribution of X = EXr + (1 - E)Xf, where Xr 〜P, Xf 〜Q, E 〜U[0,1].
H Algorithms
Algorithm 1 Training algorithm for non-saturating RGANs with symmetric loss functions
Require: The number of D iterations nD (nD = 1 unless one seeks to train D to optimality), batch
size m, and functions f which determine the objective function of the discriminator (f is f1 from
equation 10 assuming that f2(-y) = f1(y), which is true for many GANs).
while θ has not converged do
for t = 1, . . . , nD do
Sample {X(i)}m=ι 〜P
Sample {z(i)}m=ι 〜Pz
Update W using SGD by ascending with Vwm Pm=ι f (Cw(X(i)) - Cw(Gθ(z(i))))]
end for
Sample {X(i)}m=ι 〜P
Sample {z(i)}m=ι 〜Pz
Update θ using SGD by ascending with Vθm1 Pm=ι f (Cw(Gθ(z(i))) - Cw(X⑴))]
end while
16
Published as a conference paper at ICLR 2019
Algorithm 2 Training algorithm for non-saturating RaGANs
Require: The number of D iterations n° (nD = 1 unless one seek to train D to optimality), batch
size m, and functions f1 and f2 which determine the objective function of the discriminator (see
equation 10).
while θ has not converged do
for t = 1, . . . , nD do
Sample {χ(i)}m=ι 〜P
Sample {z(i)}m=ι 〜Pz
Let Cw(Xr) = m1 pm=ι Cw(X⑴)
Let Cw(Xf) = * Pm=ι Cw(Gθ(Z⑴))
Update w using SGD by ascending with
Vw m1 Pm=IhfI(Cw (x(i)) - CW (Xf )) + f2 (CW (Gθ (Z(i))) - CW(Xr ))i
end for
Sample {X(i)}m=ι 〜P
Sample {z(i)}m=ι 〜Pz
LetCW(XT) = ml Pi=ι CW(X(i))
Let Cw(XfI = m Pm=ι Cw(Gθ(Z⑴))
Update θ using SGD by ascending with
V θ~m Pm=IhfI(CW (Gθ (Z(i))) - CW (Xr )) + f2(CW (X(i) ) - CW (Xf ))i
end while
I Architectures
I.1 STANDARD CNN
Generator	Discriminator
	X ∈ R3x32x32
	Conv2d 3x3, stride 1, pad 1, 3->64
z ∈ R128 〜N(0,I)	LeakyReLU 0.1
	Conv2d 4x4, stride 2, pad 1, 64->64
linear, 128 -> 512*4*4	
	LeakyReLU 0.1
Reshape, 512*4*4 ->512x4x4	
	Conv2d 3x3, stride 1, pad 1, 64->128
ConvTranSPose2d 4x4, stride 2, pad 1, 512->256	
	LeakyReLU 0.1
BN and ReLU	
	Conv2d 4x4, stride 2, pad 1, 128-›128
ConvTranSPose2d 4x4, stride 2, pad 1, 256-›128	
	LeakyReLU 0.1
BN and ReLU	
	Conv2d 3x3, stride 1, pad 1, 128-›256
ConvTranSPose2d 4x4, stride 2, pad 1, 128->64	
	LeakyReLU 0.1
BN and ReLU	
	Conv2d 4x4, stride 2, pad 1, 256-›256
ConvTranspose2d 3x3, stride 1, pad 1, 64->3	
	LeakyReLU 0.1
Tanh	
	Conv2d 3x3, stride 1, pad 1, 256-›512
	
	Reshape, 512x4x4-> 512*4*4
linear, 512*4*4 -> 1
17
Published as a conference paper at ICLR 2019
I.2 DCGAN 64X64
Generator	Discriminator
Z ∈ R128 〜N(0,I)	
	X ∈ R3x64x64
ConvTranspose2d 4x4, stride 1, pad 0, no bias, 128->512	
	Conv2d 4x4, stride 2, pad 1, no bias, 3->64
BN and ReLU	
	LeakyReLU 0.2
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 512->256	
	Conv2d 4x4, stride 2, pad 1, no bias, 64->128
BN and ReLU	
	BNandLeakyReLU 0.2
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 256->128	
	Conv2d 4x4, stride 2, pad 1, no bias, 128-›256
BN and ReLU	
	BNandLeakyReLU 0.2
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 128->64	
	Conv2d 4x4, stride 2, pad 1, no bias, 256->512
BN and ReLU	
	BNandLeakyReLU 0.2
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 64->3	
	Conv2d 4x4, stride 2, pad 1, no bias, 512->1
Tanh	
I.3 DCGAN 128X128
Generator	Discriminator
z ∈ R128 〜N(0,I)	
	X ∈ R3x128x128
ConvTranSPose2d 4x4, stride 1, pad 0, no bias, 128->1024	
	Conv2d 4x4, stride 2, pad 1, no bias, 3->64
BN and ReLU	
	LeakyReLU 0.2
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 1024->512	
	Conv2d 4x4, stride 2, pad 1, no bias, 64->128
BN and ReLU	
	BN and LeakyReLU 0.2
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 512->256	
	Conv2d 4x4, stride 2, pad 1, no bias, 128-›256
BN and ReLU	
	BN and LeakyReLU 0.2
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 256->128	
	Conv2d 4x4, stride 2, pad 1, no bias, 256-›512
BN and ReLU	
	BN and LeakyReLU 0.2
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 128->64	
	Conv2d 4x4, stride 2, pad 1, no bias, 512->1024
BN and ReLU	
	BN and LeakyReLU 0.2
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 64->3	
	Conv2d 4x4, stride 2, pad 1, no bias, 1024-›1
Tanh	
18
Published as a conference paper at ICLR 2019
I.4 DCGAN 256X256
Generator	DiScriminator(PACGAN2 (Lin et al., 2017))
Z ∈ R128 〜N(0,I)	x ∈ R3x256x256 , x ∈ R3x256x256
ConvTransPose2d 4x4, stride 1, pad 0, no bias, 128->1024	Concatenate [χ1,χ2] ∈ R6x256x256
BN and ReLU	Conv2d 4x4, stride 2, pad 1, no bias, 6->32
ConvTranSPose2d 4x4, stride 2, pad 1, no bias, 1024->512	LeakyReLU 0.2
BN and ReLU	Conv2d 4x4, stride 2, pad 1, no bias, 32->64
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 512->256	LeakyReLU 0.2
BN and ReLU	Conv2d 4x4, stride 2, pad 1, no bias, 64->128
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 256->128	BN and LeakyReLU 0.2
BN and ReLU	Conv2d 4x4, stride 2, pad 1, no bias, 128-›256
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 128->64	BN and LeakyReLU 0.2
BN and ReLU	Conv2d 4x4, stride 2, pad 1, no bias, 256-›512
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 64->32	BN and LeakyReLU 0.2
BN and ReLU	Conv2d 4x4, stride 2, pad 1, no bias, 512->1024
ConvTranspose2d 4x4, stride 2, pad 1, no bias, 64->3	BN and LeakyReLU 0.2
Tanh	Conv2d 4x4, stride 2, pad 1, no bias, 1024-›1
J Samples
This shows a selection of cats from certain models. Images shown are from the lowest FID
registered at every 10k generator iterations. Given space constraint, with cats in high reso-
lution, we show some of the nicer looking cats for each approach, there are evidently some
worse looking cats (See https://github.com/AlexiaJM/RelativisticGAN/tree/
master/images/full_minibatch for all cats of the mini-batch).
19
Published as a conference paper at ICLR 2019
Figure 3: 64x64 cats with RaLSGAN (FID = 11.97)
20
Published as a conference paper at ICLR 2019
Figure 4: 128x128 cats with RaLSGAN (FID = 15.85)
21
Published as a conference paper at ICLR 2019
Figure 5: 256x256 cats with GAN (5k iterations)
Figure 6: 256x256 cats with LSGAN (5k iterations)
22
Published as a conference paper at ICLR 2019
Figure 7: 256x256 cats with RaSGAN (FID = 32.11)
23
Published as a conference paper at ICLR 2019
Figure 8: 256x256 cats with RaLSGAN (FID = 35.21)
24
Published as a conference paper at ICLR 2019
Figure 9: 256x256 cats with SpectralSGAN (FID = 54.73)
25
Published as a conference paper at ICLR 2019
Figure 10: 256x256 cats with WGAN-GP (FID > 100)
26