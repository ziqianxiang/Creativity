Published as a conference paper at ICLR 2019
Anytime MiniBatch: Exploiting Stragglers in
Online Distributed Optimization
Nuwan Ferdinand, Haider Al-Lawati, & Stark Draper
Department of Electrical and Computer Engineering, University of Toronto
{nuwan.ferdinand@,haider.al.lawati@mail.,stark.draper@}utoronto.ca
Matthew Nokleby
Department of Electrical and Computer Engineering, Wayne State University, Detroit, MI
matthew.nokleby@wayne.edu
Ab stract
Distributed optimization is vital in solving large-scale machine learning problems.
A widely-shared feature of distributed optimization techniques is the requirement
that all nodes complete their assigned tasks in each computational epoch before
the system can proceed to the next epoch. In such settings, slow nodes, called
stragglers, can greatly slow progress. To mitigate the impact of stragglers, we
propose an online distributed optimization method called Anytime Minibatch. In
this approach, all nodes are given a fixed time to compute the gradients of as
many data samples as possible. The result is a variable per-node minibatch size.
Workers then get a fixed communication time to average their minibatch gradients
via several rounds of consensus, which are then used to update primal variables via
dual averaging. Anytime Minibatch prevents stragglers from holding up the system
without wasting the work that stragglers can complete. We present a convergence
analysis and analyze the wall time performance. Our numerical results show that
our approach is up to 1.5 times faster in Amazon EC2 and it is up to five times
faster when there is greater variability in compute node performance.
1	Introduction
The advent of massive data sets has resulted in demand for solutions to optimization problems that
are too large for a single processor to solve in a reasonable time. This has led to a renaissance in the
study of parallel and distributed computing paradigms. Numerous recent advances in this field can
be categorized into two approaches; synchronous Dekel et al. (2012); Duchi et al. (2012); Tsianos
& Rabbat (2016); Zinkevich et al. (2010) and asynchronous Recht et al. (2011); Liu et al. (2015).
This paper focuses on the synchronous approach. One can characterize synchronization methods
in terms of the topology of the computing system, either master-worker or fully distributed. In a
master-worker topology, workers update their estimates of the optimization variables locally, followed
by a fusion step at the master yielding a synchronized estimate. In a fully distributed setting, nodes
are sparsely connected and there is no obvious master node. Nodes synchronize their estimates via
local communications. In both topologies, synchronization is a key step.
Maintaining synchronization in practical computing systems can, however, introduce significant
delay. One cause is slow processing nodes, known as stragglers Dean et al. (2012); Yu et al. (2017);
Tandon et al. (2017); Lee et al. (2018); Pan et al. (2017); S. Dutta & Nagpurkar (2018). A classical
requirement in parallel computing is that all nodes process an equal amount of data per computational
epoch prior to the initiation of the synchronization mechanism. In networks in which the processing
speed and computational load of nodes vary greatly between nodes and over time, the straggling
nodes will determine the processing time, often at a great expense to overall system efficiency.
Such straggler nodes are a significant issue in cloud-based computing systems. Thus, an important
challenge is the design of parallel optimization techniques that are robust to stragglers.
To meet this challenge, we propose an approach that we term Anytime MiniBatch (AMB). We
consider a fully distributed topologyand consider the problem of stochastic convex optimization
1
Published as a conference paper at ICLR 2019
via dual averaging Nesterov (2009); Xiao (2010). Rather than fixing the minibatch size, we fix
the computation time (T) in each epoch, forcing each node to “turn in” its work after the specified
fixed time has expired. This prevents a single straggler (or stragglers) from holding up the entire
network, while allowing nodes to benefit from the partial work carried out by the slower nodes. On
the other hand, fixing the computation time means that each node process a different amount of
data in each epoch. Our method adapts to this variability. After computation, all workers get fixed
communication time (Tc) to share their gradient information via averaging consensus on their dual
variables, accounting for the variable number of data samples processed at each node. Thus, the
epoch time of AMB is fixed to T + Tc in the presence of stragglers and network delays.
We analyze the convergence of AMB, showing that the online regret achieves O(√mm) performance,
which is optimal for gradient based algorithms for arbitrary convex loss Dekel et al. (2012). In here,
m is the expected sum number of samples processed across all nodes. We further show an upper
bound that, in terms of the expected wall time needed to attain a specified regret, AMB is O(√n — 1)
faster than methods that use a fixed minibatch size under the assumption that the computation time
follows an arbitrary distribution where n is the number of nodes. We provide numerical simulations
using Amazon Elastic Compute Cloud (EC2) and show that AMB offers significant acceleration over
the fixed minibatch approach.
2	Related work
This work contributes to the ever-growing body of literature on distributed learning and optimization,
which goes back at least as far as Tsitsiklis et al. (1986), in which distributed first-order methods were
considered. Recent seminal works include Nedic & Ozdaglar (2009), which considers distributed
optimization in sensor and robotic networks, and Dekel et al. (2012), which considers stochastic
learning and prediction in large, distributed data networks. A large body of work elaborates on these
ideas, considering differences in topology, communications models, data models, etc. Duchi et al.
(2012); Tsianos et al. (2012); Shi et al. (2015); Xi & Khan (2017). The two recent works most similar
to ours are Tsianos & Rabbat (2016) and Nokleby & Bajwa (2017), which consider distributed online
stochastic convex optimization over networks with communications constraints. However, both of
these works suppose that worker nodes are homogeneous in terms of processing power, and do not
account for the straggler effect examined herein. The recent work Pan et al. (2017); Tandon et al.
(2017); S. Dutta & Nagpurkar (2018) proposed synchronous fixed minibatch methods to mitigate
stragglers for master-worker setup. These methods either ignore stragglers or use redundancy to
accelerate convergence in the presence of stragglers. However, our approach in comparison to Pan
et al. (2017); Tandon et al. (2017); S. Dutta & Nagpurkar (2018) utilizes work completed by both fast
and slow working nodes, thus results in faster wall time in convergence.
3	System model and algorithm
In this section we outline our computation and optimization model and step through the three phases
of the AMB algorithm. The pseudo code of the algorithm is provided in App. A. We defer discussion
of detailed mathematical assumptions and analytical results to Sec. 4.
We suppose a computing system that consists of n compute nodes. Each node corresponds to a vertex
in a connected and undirected graph G(V, E ) that represents the inter-node communication structure.
The vertex set V satisfies |V | = n and the edge set E tells us which nodes can communicate directly.
Let Ni = {j ∈ V : (i, j) ∈ E, i 6= j} denote the neighborhood of node i.
The collaborative objective of the nodes is to find the parameter vector w ∈ W ⊆ Rd that solves
w* = arg min F(W) where F(W) := Eχ[f (w,x)].	(1)
w∈W
The expectation ExH is computed with respect to an unknown probability distribution Q over a set
X ⊆ Rd. Because the distribution is unknown, the nodes must approximate the solution in (1) using
data points drawn in an independent and identically distributed (i.i.d.) manner from Q.
AMB uses dual averaging Nesterov (2009); Dekel et al. (2012) as its optimization workhorse and
averaging consensus Nokleby & Bajwa (2017); Tsianos & Rabbat (2016) to facilitate collaboration
among nodes. It proceeds in epochs consisting of three phases: compute, in which nodes compute
2
Published as a conference paper at ICLR 2019
local minibatches; consensus, in which nodes average their dual variables together; and update, in
which nodes take a dual averaging step with respect to the consensus-averaged dual variables. We let
t index each epoch, and each node i has a primal variable wi(t) ∈ Rd and dual variable zi(t) ∈ Rd.
At the start of the first epoch, t = 1, we initialize all primal variables to the same value w(1) as
wi(1) = w(1) = arg min h(w),	(2)
w∈W
and all dual variables to zero, i.e., zi (1) = 0 ∈ Rd. In here, h : W → R is a 1-strongly convex
function.
Compute Phase: All workers are given T fixed time to compute their local minibatches. During
each epoch, each node is able to compute bi(t) gradients of f(w, x), evaluated at wi(t) where the
data samples xi(t, s) are drawn i.i.d. from Q. At the end of epoch t, each node i computes its local
minibatch gradient:
gi(t)
1
bi(t)
bi(t)
):RW f (wi (t), Xi (t, S)).
s=1
(3)
As we fix the compute time, the local minibatch size bi (t) is a random variable. Let b(t) := Pin=1 bi(t)
be the global minibatch size aggregated over all nodes. This contrasts with traditional approaches
in which the minibatch is fixed. In Sec. 4 we provide a convergence analysis that accounts for the
variability in the amount of work completed by each node. In Sec. 5, we presents a wall time analysis
based on random local minibatch sizes.
Consensus Phase: Between computational epochs each node is given a fixed amount of time, Tc,
to communicate with neighboring nodes. The objective of this phase is for each node to get (an
approximation of) the following quantity:
1 n	1 n	1 n bi(t)
而 X bi(t)[Zi(t) + gi(t)]=丽 X bi(t)Zi(t) + 而 XX Vw f(Wi(t), Xi(t, S))
i=1	i=1	i=1 s=1
:=z(t) + g(t).
(4)
The first term, z(t), is the weighted average of the previous dual variables. The second, g(t), is the
average of all gradients computed in epoch t.
The nodes compute this quantity approximately via several synchronous rounds of average consensus.
Each node waits until it hears from all neighbors before starting a consensus round. As we have fixed
communication time Tc, the number of consensus rounds ri(t) varies across workers and epochs due
to random network delays. Let P be a positive semi-definite, doubly-stochastic matrix (i.e., all entries
of P are non-negative and all row- and column-sums are one) that is consistent with the graph G (i.e.,
Pi,j > 0 only if i = j or if (i, j) ∈ E). At the start of the consensus phase, each node i shares its
message mi(0) = nbi(t)[zi(t) + gi(t)] with its neighboring nodes. Let [r] stand for [r] ∈ {1, . . . r}.
Then, in consensus iteration k ∈ [ri(t)] node i computes its update as
nn
mi(k) = X Pi,j m(jk-1) = X(Pi,j)km(j0).
j=1	j=1
As long as G is connected and the second-largest eigenvalue of P is strictly less than unity, the
iterations are guaranteed to converge to the true average. For finite ri(t), each node will have an error
in its approximation. Instead of (4), at the end of the rounds of consensus, node i will have
zi(t + I) = z(t) + g(t) + ξi(t),	(5)
where ξi(t) is the error. We use D(ri (t)) {yj}j∈V , i to denote the distributed averaging affected by
ri(t) rounds of consensus. Thus,
zi(t+ι)=b(ɪt)Dg⑴)(nnbj(t)[zj(t)+gj(t)]]}j∈V,i)=百mfr®).	(6)
We note that the updated dual variable zi(t + 1) is a normalized version of the distributed average
solution, normalized by b(t) = Pin=1 bi(t).
3
Published as a conference paper at ICLR 2019
Update Phase: After distributed averaging of dual variables, each node updates its primal variable
as
wi(t + 1) = arg min w, zi(t + 1) + β(t + 1)h(w) ;	(7)
where〈•，•〉denotes the standard inner product. As will be discussed further in our analysis, in this
paper we assume h : W → R to be a 1-strongly convex function and β(t) to be a sequence of
positive non-decreasing parameters, i.e., β(t) ≤ β(t + 1). We also work in Euclidean space where
h(w) = kwk2 is a typical choice.
4 Analysis
In this section we analyze the performance of AMB in terms of expected regret. As the performance
is sensitive to the specific distribution of the processing times of the computing platform used, we first
present a generic analysis in terms of the number of epochs processed and the size of the minibatches
processed by each node in each epoch. Then in Sec. 5, in order to illustrate the advantages of AMB,
we assert a probabilistic model on the processing time and analyze the performance in terms of the
elapsed “wall time” .
4.1 Preliminaries
We assume that the feasible space W ∈ Rd of the primal optimization variable w is a closed and
bounded convex set where D = maxw,u∈w ∣∣w - u∣∣. Let k ∙ k denote the '2 norm. We assume the
objective function f(w, x) is convex and differentiable in w ∈ W for all x ∈ X. We further assume
that f(w, x) is Lipschitz continuous with constant L, i.e.
∣f(w,x) — f(W,x)∣≤ Lkw — W∣, ∀ X ∈ X, and ∀ w,W ∈ W.	(8)
Let Vf (w, x) be the gradient of f (w, x) with respect to w. We assume the gradient of f (w, x) is
Lipschitz continuous with constant K, i.e.,
∣Vf(w,x) -Vf(w,x)k≤ K kw — wk, ∀ x ∈ X, and ∀ w,w ∈ W.	(9)
As mentioned in Sec. 3,
F(w) =E[f(w,x)],	(10)
where the expectation is taken with respect to the (unknown) data distribution Q, and thus VF (w) =
E[Vf (w, x)]. We also assume that there exists a constant σ that bounds the second moment of the
norm of the gradient so that
E[kVf(w, x) - VF (w)k2] ≤ σ2,∀x ∈ X,and∀w ∈ W.	(11)
Let the global minimum be denoted w* := arg minw∈w F(w).
4.2 Sample path analysis
First we bound the consensus errors. Let z(t) be the exact dual variable without any consensus errors
at each node
Z⑴=z(t - I)+ g(t - I).	(12)
The following Lemma bounds the consensus errors, which is obtained using (Tsianos & Rabbat,
2016, Theorem 2)
Lemma 1 Let zi(r) (t) be the output after r rounds consensus. Let λ2(P) be the second eigenvalue of
the matrix P and let ≥ 0, then
kzi(r)(t) - z(t)k ≤, ∀i∈ [n],t∈ [τ],	(13)
if the number of consensus rounds satisfies
ri(t) ≥ [lθg(2√n(1+2L∕e”]，∀i ∈ [n],t ∈ [τ]∙	(14)
1 - λ2(P)
4
Published as a conference paper at ICLR 2019
We characterize the regret after τ epochs, averaging over the data distribution but keeping a
fixed “sample path” of per-node minibatch sizes bi (t). We observe that due to the time spent in
communicating with other nodes via consensus, each node has computation cycles that could have
been used to compute more gradients had the consensus phase been shorter (or nonexistent). To
model this, let ai(t) denote the number of additional gradients that node i could have computed had
there been no consensus phase. This undone work does not impact the system performance, but does
enter into our characterization of the regret. Let ci(t) = bi(t) + ai(t) be the total number of gradients
that node i had the potential to compute during the t-th epoch. Therefore, the total potential data
samples processed in the t-th epoch is c(t) = Pin=1 ci(t). After τ epochs the total number of data
points that could have been processed by all nodes in the absence of communication delays is
τ
m = X c(t).	(15)
t=1
An important quantity is the ratio of total potential computations in each epoch to that actually
completed. Define the maximum such minibatch “skewness” as
γ = max
t∈[τ -1]
c(t + 1)
~~WΓ
(16)
It turns out that it is important to compute this skewness across epochs (i.e., c(t + 1) versus b(t)) in
order to bound the regret via a telescoping sum. [Details can be found in the supplementary material.]
In practice, ai(t) and bi(t) (and therefore ci(t)) depend on latent effects, e.g., how many other virtual
machines are co-hosted on node i, and therefore we model them as random variables. We bound
the expected regret for a fixed sample path of ai (t) and bi (t). The sample paths of importance
are ctot (τ) = {ci(t)}i∈V,t∈[τ] and btot (τ) = {bi (t)}i∈V,t∈[τ], where we introduce ctot and btot for
notational compactness.
Define the average regret after τ epochs as
τ n ci(t)
R(T) = E[Rlbtot(τ ),ctot(τ)] = E XXX [f (wi(t),xi(t, S)) - F(W*)] ,	(17)
t=1 i=1 s=1
where the expectation is taken with respect the the i.i.d. sampling from the distribution Q. Then, we
have the following bound on R(τ).
Theorem 2 Suppose workers collectively processed m samples after τ epochs, cf. (15), minibatch
skewness parameter γ, cf. (16), and let CmaX = maxt∈[τ] c(t), CaVg = (l∕τ) ET=I c(t) and δ =
max{t,t0}∈{1,τ -1} |c(t) -c(t0)| be the maximum, average, and variation across c(t). Further, suppose
the averaging consensus has additive accuracy , cf. Lemma 1. Then, the expected regret is
3K22C	3/2
R(T) ≤ Cmax [F (W(1)) — F (W* ) + β(τ )h(w*)] + ---max^-
+ δ ((l + 2) F(w*) + h(w*) (K + τ 1/2c-/)) τ
+ CKDe + Y^——+ 2Lecmax + 2δKDeτ) √m. (18)
Theorem 2 is proved in App. B of the supplementary material.
We now make a few comments about this result. First, recall that the expectation is taken with
respect to the data distribution, but holds for any sample path of minibatch sizes. Further, the regret
bound depends only on the summary statistics Cmax, CaVg , δ, and γ. These parameters capture the
distribution of the processing speed at each node. Further, the impact of consensus error, which
depends on the communication speed relative to the processing speed of each node, is summarized in
the assumption of uniform accuracy e on the distributed averaging mechanism. Thus, Theorem 2 is a
sample path result that depends only coarsely on the distribution of the speed of data processing.
Next, observe that the dominant term is the final one, which scales in the aggregate number of samples
m. The first term is approximately constant, only scaling with the monotonically increasing β and
5
Published as a conference paper at ICLR 2019
cmax parameters. The terms containing characterizes the effect of imperfect consensus, which can
be reduced by increasing the number of rounds of consensus. The effect of variability across c(t) is
reflected in the terms containing the Cmaχ, Cavg and δ parameters. If perfect consensus were achieved
(E = 0) then all components of the final term that scales in √m would disappear except for the term
that contains the minibatch skewness parameter γ. It is through this term that the amount of useful
computation performed in each epoch (bi(t) ≤ ci (t)) enters the result.
In the special case of constant minibatch size cmax = cavg and δ = 0, we have the following corollary.
Corollary 3 If c(t) = c for all t ∈ [τ] and the consensus error E ≤ 1/c, then the expected regret is
R(T)=O(C + √m).	(19)
Furthermore, if C = mρ fora constant P ∈ (0,1/2] ,then R(T) = O(√m).
4.3 Expected regret analysis
We can translate Theorem 2 and Cor. 3 to a regret bound averaged over the sample path. Since the
summary statistics Cmax, Cavg , δ, and γ are sufficient to bound the regret, we assert a joint distribution
p over these terms rather than over the sample path btot (T), Ctot (T). For the following result, we need
only specify several moments of the distribution. In Sec. 5 we will take the further step of choosing a
specific distribution p.
Theorem 4 Let C = Ep[c(t)] so that m = τc is the expected total work that can be completed in
T epochs. Also, let 1/b = Ep[1/b(t)]. If averaging consensus has additive accuracy E, then the
expected regret is bounded by
3	-	3	3K 2E2C5/2	/	Cσ2	∖ 一
Ep[R(τ)] ≤ c[F(w(1)) — F(w*) + β(τ)h(w*)] +-----------------+ FKDE +----^ + 2LeC)√C.
Theorem 4 is proved in App. F of the supplementary material. Note that this expected regret is over
both the i.i.d. choice of data samples and the i.i.d. choice of (b(t), C(t)) pairs.
Corollary 5 If E ≤ 1/CC, the expected regret is
Ep[R(τ)] ≤ O(C + √C).	(20)
Further, if C = mP fora constant P ∈ (0,1/2), then E[R] ≤ O( √^C).
Remark 1 Note that by letting E = 0, we can immediately find the results for master-worker setup.
5	Wall Time analysis
In the preceding section we studied regret as a function of the number of epochs. The advantages of
AMB is the reduction of wall time. That is, AMB can get to same convergence in less time than fixed
minibatch approaches. Thus, in this section, we caracterize the wall time performance of AMB.
In AMB, each epoch corresponds to a fixed compute time T . As we have already commented, this
contrasts with fixed minibatch approaches where they have variable computing times. We refer
“Fixed MiniBatch" methods as FMB. To gain insight into the advantages of AMB, we develop an
understanding of the regret per unit time.
We consider an FMB method in which each node computes computes b/n gradients, where b is the
size of the global minibatch in each epoch. Let Ti(t) denote the amount of time taken by node i to
compute b/n gradients for FMB method. We make the following assumptions:
Assumption 1 The time Ti(t) follows an arbitrary distribution with the mean μ and the variance σ2.
Further, Ti(t) is identical across node index i and epoch index t. .
Assumption 2 If node i takes Ti (t) seconds to compute b/n gradients in the t-th epoch, then it will
take nTi(t)/b seconds to compute one gradient.
6
Published as a conference paper at ICLR 2019
Lemma 6 Let Assumptions 1 and 2 hold. Let the FMB scheme have a minibatch size of b. Let b be
the expected minibatch size of AMB. Then, if we fix the computation time of an epoch in AMB to
T = (1 + n∕b)μ, we have b ≥ b.
Lemma 6 is proved in App. G and it shows that the expected minibatch size of AMB is at least as big
as FMB if we fix T = (1 + n∕b)μ. Thus, We get same (or better) expected regret bound. Next, We
show that AMB achieve this in less time.
Theorem 7 Let Assumptions 1 and 2 hold. Let T =(1 + n∕b)μ and minibatch size of FMB is b. Let
SA and SF be the total compute time across τ epochs of AMB and FMB, respectively, then
SF ≤ (l + μ√n - 1) SA.	(21)
The proof is given in App. G. Lemma 6 and Theorem 7 show that our method attains the same (or
better) bound on the expected regret that is given in Theorem 4 but is at most(1 + σ∕μ√n - 1)
faster than traditional FMB methods. In Bertsimas et al. (2006), it was shown this bound is tight
and there is a distribution that achieves it. In our setup, there are no analytical distributions that
exactly match with finishing time distribution. Recent papers on stragglers Lee et al. (2018); S. Dutta
& Nagpurkar (2018) use the shifted exponential distribution to model Ti(t). The choice of shifted
exponential distribution is motivated by the fact that it strikes a good balance between analytical
tractability and practical behavior. Based on the assumption of shifted exponential distribution, we
show that AMB is O(log(n)) faster than FMB. This result is proved in App. H.
6	Numerical evaluation
To evaluate the performance of AMB and compare it with that of FMB, we ran several experiments
on Amazon EC2 for both schemes to solve two different classes of machine learning tasks: linear
regression and logistic regression using both synthetic and real datasets. In this section we present
error vs. wall time performance using two experiments. Additional simulations are given in App. I
6.1	Datasets
We solved two problems using two datasets: synthetic and real. Linear regression problem was solved
using synthetic data. The element of global minimum parameter, w* ∈ Rd, is generated from the
multivariate normal distribution N (0, I). The workers observe a sequence of pairs (xi (s), yi (s))
where s is the time index, data xi(s) ∈ Rd are i.i.d. N (0, I), and the labels yi(s) ∈ R such that
yi(s) = xi(s)Tw* + ηi(s). The additive noise sequence ηi(s) ∈ R is assumed to be i.i.d N (0, 10-3).
The aim of all nodes is to collaboratively learn the true parameter w*. The data dimension is d = 105.
For the logistic regression problem, we used the MNIST images of numbers from 0 to 9. Each image
is of size 28 × 28 pixels which can be represented as a 784-dimensional vector. We used MNIST
training dataset that consists of 60,000 data points. The cost function is the cross-entropy function J
J (y) = - X i[y = i]P(y = i∣χ)	(22)
i
where x is the observed data point sampled randomly from the dataset, y is the true label of
x. 1[.] is the indicator function and P(y = i|x) is the predicted probability that y = i given
the observed data point x which can be calculated using the softmax function. In other words,
P(y = i|x) = ewix/ Pj ewjx . The aim of the system is to collaboratively learn the parameter
w ∈ Rc×d, where c = 10 classes and d = 785 the dimension (including the bias term) that minimizes
the cost function while streaming the inputs x online.
6.2	Experiments on EC2
We tested the performance of AMB and FMB schemes using fully distributed setup. We used a
network consisting of n = 10 nodes, in which the underlying network topology is given in Figure 2 of
App. I.1. In all our experiments, we used t2.micro instances and ami-6b211202, a publicly available
7
Published as a conference paper at ICLR 2019
(a) Linear reg. - distributed.
Figure 1: AMB vs. FMB performance comparison on EC2.
(b) Logistic reg. - distributed.
Amazon Machine Image (AMI), to launch the instances. Communication between nodes were
handled through Message Passing Interface (MPI).
To ensure a fair comparison between the two schemes, we ran both algorithms repeatedly and for a
long time and averaged the performance over the same duration. We also observed that the processors
finish tasks much faster during the first hour or two before slowing significantly. After that initial
period, workers enter a steady state in which they keep their processor speed relatively constant
except for occasional bursts. We discarded the transient behaviour and considered the performance
during the steady-state.
6.2.1	Linear regression
We ran both AMB and FMB in a fully distributed setting to solve the linear regression problem. In
FMB, each worker computed b = 6000 gradients. The average compute time during the steady-state
phase was found to be 14.5 sec. Therefore, in AMB case, the compute time for each worker was
set to be T = 14.5 sec. and we set Tc = 4.5 sec. Workers are allowed r = 5 average rounds of
consensus to average their calculated gradients.
Figure 1(a) plots the error vs. wall time, which includes both computation and communication times.
One can notice AMB clearly outperforms FMB. In fact, the total amount of time spent by FMB to
finish all the epochs is larger than that spent by AMB by almost 25% as shown in Figure 1(a) (e.g.,
the error rate achieved by FMB after 400 sec. has already been achieved by AMB after around 300
sec.). We notice, both scheme has the same average inter-node communication times. Therefore,
when ignoring inter-node communication times, this ratio increases to almost 30%.
6.2.2	Logistic regression
In here we perform logistic regression using n = 10 distributed nodes. The network topology is as
same as above. The per-node fixed minibatch in FMB is b/n = 800 while the fixed compute time in
AMB is T = 12 sec. and the communication time Tc = 3 sec. As in the linear regression experiment
above, the workers on average go through r = 5 round of consensus.
Figures 1(b) shows the achieved cost vs. wall clock time. We observe AMB outperforms FMB by
achieving the same error rate earlier. In fact, Figure 1(b) demonstrates that AMB is about 1.7 times
faster than FMB. For instance, the cost achieved by AMB at 150 sec. is almost the same as that
achieved by FMB at around 250 sec.
7	Conclusion
We proposed a distributed optimization method called Anytime MiniBatch. A key property of
our scheme is that we fix the computation time of each distributed node instead of minibatch size.
Therefore, the finishing time of all nodes are deterministic and does not depend on the slowest
processing node. We proved the convergence rate of our scheme in terms of the expected regret
bound. We performed numerical experiments using Amazon EC2 and showed our scheme offers
significant improvements over fixed minibatch schemes.
8
Published as a conference paper at ICLR 2019
8	Acknowledgment
This work was supported by the National Science Foundation (NSF) under Grant CCF-1217058, by
the Natural Science and Engineering Research Council (NSERC) of Canada, including through a
Discover Research Grant, by the NSERC Postdoctoral Fellowship, and by the Oman Government
Post Graduate Scholarship
References
Barry C. Arnold and Richard A. Groeneveld. Bounds on expectations of linear systematic statistics
based on dependent samples. Ann. Statist.,7(1):220-223,01 1979. doi: 10.1214∕aos∕1176344567.
Dimitris Bertsimas, Karthik Natarajan, and Chung-Piaw Teo. Tight bounds on expected order
statistics. Probab. Eng. Inf. Sci., 20(4):667-686, October 2006. ISSN 0269-9648.
Jeffrey Dean, Greg S. Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Quoc V. Le, Mark Z.
Mao, Marc’Aurelio Ranzato, Andrew Senior, Paul Tucker, Ke Yang, and Andrew Y. Ng. Large
scale distributed deep networks. In Proceedings of the 25th International Conference on Neural
Information Processing Systems, NIPS’12, pp. 1223-1231, USA, 2012. Curran Associates Inc.
Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, and Lin Xiao. Optimal distributed online prediction
using mini-batches. Journal of Machine Learning Research, 13(Jan):165-202, 2012.
John C Duchi, Alekh Agarwal, and Martin J Wainwright. Dual averaging for distributed optimization:
Convergence analysis and network scaling. IEEE Transactions on Automatic control, 57(3):
592-606, 2012.
K. Lee, M. Lam, R. Pedarsani, D. Papailiopoulos, and K. Ramchandran. Speeding up distributed
machine learning using codes. IEEE Trans. on Inf. Theory, 64(3):1514-1529, March 2018. ISSN
0018-9448. doi: 10.1109/TIT.2017.2736066.
Ji Liu, Stephen J. Wright, Christopher R6, Victor Bittorf, and Srikrishna Sridhar. An asynchronous
parallel stochastic coordinate descent algorithm. J. Mach. Learn. Res., 16(1):285-322, January
2015. ISSN 1532-4435.
Angelia Nedic and Asuman Ozdaglar. Distributed subgradient methods for multi-agent optimization.
IEEE Transactions on Automatic Control, 54(1):48-61, 2009.
Yurii Nesterov. Primal-dual subgradient methods for convex problems. Math. Program., 120(1):
221-259, April 2009. ISSN 0025-5610.
M. Nokleby and W. U. Bajwa. Distributed mirror descent for stochastic learning over rate-limited
networks. In 2017 IEEE 7th International Workshop on Computational Advances in Multi-Sensor
Adaptive Processing (CAMSAP), pp. 1-5, Dec 2017. doi: 10.1109/CAMSAP.2017.8313171.
Xinghao Pan, Jianmin Chen, Rajat Monga, Samy Bengio, and Rafal J6zefowicz. Revisiting distributed
synchronous sgd. In Int. Conf. on Learning Representations Workshop Track’17, 2017.
Benjamin Recht, Christopher Re, Stephen Wright, and Feng Niu. Hogwild: A lock-free approach to
parallelizing stochastic gradient descent. In Advances in Neural Information Processing Systems
24, pp. 693-701. 2011.
S. Ghosh P. Dube S. Dutta, G. Joshi and P. Nagpurkar. Slow and stale gradients can win the race:
Error-runtime trade-offs in distributed SGD. In in Proc. of the Int. Conf. on Artificial Intelligence
and Statistics (AISTATS), 2018.
Wei Shi, Qing Ling, Gang Wu, and Wotao Yin. Extra: An exact first-order algorithm for decentralized
consensus optimization. SIAM Journal on Optimization, 25(2):944-966, 2015.
R. Tandon, Q. Lei, A. G. Dimakis, and N. Karampatziakis. Gradient Coding: Avoiding Stragglers
in Distributed Learning. In in Proc. of the Int. Conf. on Int. Conf. on Machine Learning (ICML),
2017.
9
Published as a conference paper at ICLR 2019
Konstantinos I Tsianos and Michael G Rabbat. Efficient distributed online prediction and stochastic
optimization with approximate distributed averaging. IEEE Transactions on Signal and Information
Processing over Networks, 2(4):489-506, 2016.
Konstantinos I Tsianos, Sean Lawlor, and Michael G Rabbat. Push-sum distributed dual averaging
for convex optimization. In Decision and Control (CDC), 2012 IEEE 51st Annual Conference on,
pp. 5453-5458. IEEE, 2012.
John Tsitsiklis, Dimitri Bertsekas, and Michael Athans. Distributed asynchronous deterministic
and stochastic gradient optimization algorithms. IEEE Transactions on Automatic Control, 31(9):
803-812, 1986.
Chenguang Xi and Usman A Khan. Dextra: A fast algorithm for optimization over directed graphs.
IEEE Transactions on Automatic Control, 62(10):4980-4993, 2017.
Lin Xiao. Dual averaging methods for regularized stochastic learning and online optimization.
Journal of Machine Learning Research, 11(Oct):2543-2596, 2010.
Q. Yu, M. Maddah-Ali, and S. Avestimehr. Polynomial codes: An optimal design for high-dimensional
coded matrix multiplication. In Advances Neural Inf. Proc. Systems, 2017.
Martin Zinkevich, Markus Weimer, Lihong Li, and Alex J. Smola. Parallelized stochastic gradient
descent. In Advances in Neural Information Processing Systems 23, pp. 2595-2603. Curran
Associates, Inc., 2010.
10
Published as a conference paper at ICLR 2019
A AMB Algorithm
The pseudocode of the Anytime Minibatch scheme operating in a distributed setting is given in
Algorithm 1. Line 2 is for initialization purpose. Lines 3 - 8 corresponds to the compute phase
during which each node i calculates bi (t) gradients. The consensus phase steps are given in lines
9 - 21. Each node first averages the gradients (line 9) and calculates the initial messages mi(t) it
will share with its neighbours (line 10). Lines 14 - 19 corresponds to the communication rounds that
results in distributed averaging of the dual variable zi(t + 1) (line 21). Finally, line 22 represents the
update phase in which each node updates its primal variable wi(t + 1).
For the hub-and-spoke configuration, one can easily modify the algorithm as only a single consensus
round is required during which all workers send their gradients to the master node which calculates
z(t + 1) and w(t + 1) followed by a communication from the master to the workers with the updated
w(t + 1).
Algorithm 1 AMB Algorithm
1: 2: 3: 4: 5: 6: 7: 8: 9: 10:	for all t = 1, 2, ... do initialize gi (t) = 0, bi (t) = 0 T0 = current_time while current_time - T0 ≤ T do receive input xi(t, s) sampled i.i.d. from Q calculate gi (t) = gi (t) + Nf (wi (t), xi(t, s)) bi(t) + + end while start consensus rounds gi ⑴=bi(t) gi(t)
11: 12:	mi(0) = nbi(t)[zi(t) + gi(t)] set k = 0
13:	T1 = current_time
14:	while current_time - T1 ≤ Tc do
15:	receive mjk , ∀j ∈ Ni
16:	mi(k+1) = Pj∈NiPi,jmjk
17:	send mi(k+1) to all nodes in Ni
18:	k++
19:	end while
20:	ri(t) = k
21:	zi(t + I)= b1t) m(ri(t))
22:	wi(t + 1) = arg minw∈W hw, zi(t + 1)i + β(t + 1)h(w)
23:	end for
B Proof of Theorem 2
In this section, we prove Theorem 2. There are three factors impacting the convergence of our
scheme; first is that gradient is calculated with respect to f(w, x) rather than directly computing the
exact gradient NwF(w), the second factor is the errors due to limited consensus rounds, and the last
factor is that we have variable sized minibatch size over epochs. We bound these errors to find the
expected regret bound with respect to a sample path.
Let w(t) be the primal variable computed using the exact dual z(t), cf. 12:
w(t) = arg min {hw, z(t)i + β(t)h(w)}
w∈W
(23)
11
Published as a conference paper at ICLR 2019
From (Tsianos & Rabbat, 2016, Lemma 2), we have
kwi(t) - w(t)k ≤ tj^kz llzi(t) -
β(t)
≤ β(t).
(t)k, ∀i∈ [n]
(24)
Recall thatzi(t) is the dual variable after r rounds of consensus. The last step is due to Lemma 1.
Let X (t) be the total set of samples processed by the end of t-th epoch:
X(t) := {xi(t0, s) : i ∈ [n], t0 ∈ [t], s ∈ [c(t)]} .
Let E[∙] denote the expectation over the data set X(T) where We recall T is the number of epochs.
Note that conditioned on X(t - 1) the wi(t) and xi(t, s) are independent according to equation 7.
Thus,
E[f(wi(t),xi(t,s))]=EExi(t,s)[f(wi(t),xi(t,s))|X(t-1)]
= E [F (wi (t))] .	(25)
where equation 25 is due to equation 10. From equation 17 we have
τ n ci (t)
E[R∣btot(τ),ctot(τ)] = XXX E[f(wi(t),xi(t, s)) — F(WF	(26)
t=1 i=1 s=1
τ n ci (t)
=XXX
E [F(wi(t)) — F(w*)] .	(27)
t=1 i=1 s=1
Now, we add and subtract F (w(t)) from equation 17 to get
τ n ci (t)
E[R|btot(T), ctot(T)] = XXX
E [F(w(t)) — F(w*) + F(wi(t)) — F(w(t))]
t=1 i=1 s=1
τ	τn
=X c(t)E[F (w(t)) - F (w*)]+ XX Ci(t)E[F (Wi ⑻—F (w(t))]
t=1	t=1 i=1
τ	τn
≤ Xc(t)E[F(w(t)) — F(w*)]+ XXCi(t)LE[∣Wi(t) — w(t)k] (28)
t=1	t=1 i=1
τ ≤X t=1 τ =X t=1	C(t)E[F (W(t)) —F(w*)]+ X X R	(29) t=1 i=1 β(t) c(t)E[F(w(t)) — F(w*)]+ Le X +.	(30)
Note that equation 28 and equation 29 are due to equation 8 and equation 24. Now, we bound the
first term in the following Lemma, which is proved in App. C.
Lemma 8 Let β(t) = K + α(t) where α(t) = ʌ μ. Then
ττ
X c(t)E [F(w(t)) — F(w*)] ≤ c(1)[F(W(I))- F(w*)] + X(C(T) — c(t))F(w*)
t=1	t=2
/ S m *、τ-1 KDe	τ-1 c(t + 1)σ2
+ C(T)β(τ阿W ) + ∑ 7W + ∑ EW
K2e2 X-1 c(t + 1)
+ ~ t=1 α(t)β(t)2
+ E[ψ] (31)
where
τ-1
E[ψ] ≤ X(c(t) — c(t + 1)) ((t — 1)F(w*) + β(t)h(w*) + 2KDe√μt).
t=1
(32)
12
Published as a conference paper at ICLR 2019
In equation 31, the first term is a constant, which depends on the initialization. The fourth and the
sixth terms are due to consensus errors and the fifth term is due to noisy gradient calculation. The
second and the last term E[ψ] are due to variable minibatch sizes.
Now, the total regret can be obtained by using Lemma 8 in equation 30
T
E[R∣btot(τ),ctot(τ)] ≤ c(1)[F(w(1)) - F(w*)] + X(C(T) - c(t))F(w*) + C(T)β(τ)h(w*)
t=2
KDe	c(t + 1)σ2 K2e2	c(t + 1)	YT^ c(t)
+X 而++X -≡⅞τ+-X 0ww+E["]+Le X 丽∙ (33)
Define Y = maxt∈{1,τ —1} c(bt+p/max = maxt∈[τ] c(t), and δ = max{t,tq∈{1,τ-1} ∣c(t) - c(t0)∣.
Then
T
E[R∣btot(τ),ctot(τ)] ≤ Cmax[F(w(1)) - F(w*) + β(τ)h(w*)]+ X δF(w*)
t=2
,X KDe , γσ2 X 1	, K2e2cmax X 1	l * 1 l r	X 1
+ g 行 + 丁 N 西+ ~g 丽可 + EM+ Lecmax g 丽
In App. D, We bound PT=IL 0⅛) and PT—ι α(t)β(t)2 terms. Using them, we have
E[R∣btot(τ),ctot(τ)] ≤ cmax[F(w(1)) - F(w*) + β(τ)h(w*)] + δτF(w*) + 2KDe√μτ
2γσ2√μτ	3K 2e2 cmaxM3/2	T	.— Er
+------4------1-------4--------+ 2Lecmax√μτ + E[ψ]
E[R∣btot(τ),ctot(τ)] ≤ cmax[F(w(1)) - F(w*) + β(τ)h(w*)] + δτF(w*)
3K"max43/2 JDND 1 Yσ2 1 9F ∖ /—IImI
+------------------------------4---------+ I 2KDe + 2------+ 2Lecmax I √μτ + E[ψ]
Now We bound E[ψ]. Using δ = max∣t,tz}∈{1,T —1} ∣c(t) - c(t0)∣ in equation 32, we can write
T 一 1
E[ψ] ≤ X δ ((t - 1)F(w*) + β(t)h(w*) + 2KDe√μt)
t=1
T — 1
T — 1
1
(34)
(35)
(36)
≤ δ F(w*)£(t- 1) + h(w*)E K +
∖	t=1
≤ δ T2FF(w*) + h(w*) (K +
≤ δ(2F(w*) + h(w*) (K +
By substituting equation 37 in equation 36
t=1
+ 2KDe√μττ
2KDe√μτ I τ
(37)
1
E[R∣btot(τ),ctot(τ)] ≤ Cmax[F(w(1)) - F(w*) + β(τ)h(w*)] + δτF(w*)
+ 3K2'2cmaxB2 + CKDe + γ∣2 + 2L“max) √μT
+ δ(TF(w*) + h(w*) (K +
2KDe√μτ I T
(38)
By rearranging terms
3K 2e2c	〃3/2
E[R∣btot(τ),ctot(τ)] ≤ Cmax[F(w(1)) - F(w*)+ β(τ)h(w*)] +--------------max^
+ δ((1 + T) F(w*) + h(w*) (K + O
+(2KDe + ɪ—+ 2LeCmax + 2δKDeτ∖ √μτ
(39)
13
Published as a conference paper at ICLR 2019
Let μ = Cavg = (1∕τ) PT=ι c(t), then from equation 15 μτ = m and We substitute
3K22c	3/2
E[R∣btot(τ),ctot(τ)] ≤ Cmaχ[F(w(1)) - F(w*)+ β(τ)h(w*)] +------4max^-
+ δ ((i + 2) F(w*) + h(w*) (K + T1/2C-Z2)) T
+(2KDe + ɪ—+ 2L6Cmaχ + 2δKDeτ) √∕m. (40)
This completes the proof of Theorem 2.
C Proof of Lemma 8
Note that g(t) is calculated with respect to wi(t) by different nodes in equation 3. Let g(t) be the
minibatch calculated With respect to w(t) (given in equation 23) by all the nodes.
1 n bi (t)
g(t)= 焉XXVw f (w(t),Xi(t,s)).	(41)
b(t) i=1 s=1
Note that there are two types of errors in computing gradients. The first is common in any gradient
based methods. That is, the gradient is calculated with respect to the function f(w, x), which is based
on the data x instead of being a direct evaluation of VwF(w). We denote this error as q(t):
q(t) = g(t) - VwF(w(t)).	(42)
The second error results from the fact that we use g(t) instead of g(t). We denote this error as r(t):
r(t)= g(t) — g(t).	(43)
Lemma 9 The following four relations hold
E[hq(t),w*- w(t)i]=0,
E[hr(t),W*- W(t)i]=箸,
E[kq(t)k2]
E[kr(t)k2]
σ
丽,
K 2e2
∙
The proof of Lemma 9 is given in App. E. Let lt(w) be the first order approximation of F(w) at
w(t):
lt(W) = F (W(t)) + hVw F (W(t)), W - W(t)i.
Let lt (W) be an approximation of lt (W) by replacing VwF (W(t)) with g(t)
lt(W) = F(W(t)) + hg(t), W - W(t)i
= F (W(t)) + hVwF(W(t)), W - W(t)i + hq(t),W - W(t)i + hr(t), W - W(t)i
= lt(W) + hq(t),W - W(t)i + hr(t), W - W(t)i∙
(44)
(45)
(46)
(47)
Note that equation 46 follows since g(t) = q(t) + r(t) + Vw F (w(t)). By using the smoothness of
F (w), we can write
K
F(W(t + I)) ≤ lt(w(t + I)) + -2∣∣w(t +I) - W⑴Il
K
Lt(W( + 1)) 一 hq(t), w - w(t)i - hr(t), W - W(Xi + -2∣∣w(t + 1) 一 w(t)∣2
K
lt(W) + kq(t)k∣W — W(t)k + kr(t)k∣W — W(t)k + 工|便(力 +1) — W(t)k2∙ (48)
14
Published as a conference paper at ICLR 2019
The last step is due to the Cauchy-Schwarz inequality. Let α(t) = β(t) - K. We add and subtract
α(t)kw(t + 1) - w(t)k2 /2 to find
F (w(t + 1)) ≤ lt(w(t + 1)) + kq(t)kkw - w(t)k- α4t) kw(t + 1)-w(t)k2 + kr(t)kkw - w(t)k
-----------------------------4^^kw(t + 1) - w(t)k2 + I()llw(t +I) - w(t)k2.
Note that
Ilq(t)kkw - w(t)k —4^l∣w(t + 1) - w(t)k2
2
≤
kq(t)k2
4α(t)
"ɪllw(t + 1) - w(t)k
kq(t)k2
4α(t)
(49)
Similarly, we have that
∣∣r(t)kkw - w(t)k —? ∣∣w(t+1) - w(t)k2 ≤ m.	(50)
4	4α(t)
Using equation 49, equation 50, and β(t) = K + α(t) in equation 48 we have
F(w(t +1)) ≤ lt(w(t + 1)) + 与 kw(t + 1) - w(t)k2 + lq≡2 + M2	(51)
2	4α(t)	4α(t)
EI Cll ♦ T	♦	1	1	/ > ∖	∙>7∕∕,∖∖
The following Lemma gives a relation between w(t) and lt(w(t))
Lemma 10 The optimization stated in equation 23 is equivalent to
w (t)
arg min
w∈W
3(W) + β(t)h(w)}.
(52)
By using the result (Dekel et al., 2012, Lemma 8), we have
—2-∣∣w(t + 1) - w(t)k ≤ ^X 40(w(t +I)) + (e(t))h(w(t +I))
t0=1
t-1
- X lt0(w(t)) + (K + β(t))h(w(t)).
t0=1
(53)
Use equation 51 in equation 53 and substituting in β(t) = K + α(t) we get
t-1	t-1
F(w(t + 1)) ≤ lt(w(t +1)) + X k0(w(t + 1)) - X lt0(w(t)) + (K + α(t))h(w(t + 1))
t0=1	t0=1
- (K + α(t))h(w(t)) +
kq(t)k2 + kr(t)k2
4α(t)
t	t-1
≤ X ： it/ (w(t + 1)) - X ： * (w(t)) + (K + α(t + 1))h(w(t + 1))
t0=1	t0=1
- (K + α(t))h(w(t)) +
∣q(t)∣2 + ∣r(t)∣2
(54)
4α(t)
15
Published as a conference paper at ICLR 2019
where equation 54 is due to the fact that α(t + 1) ≥ α(t). Now, we use β(t) = K + α(t), multiply
by c(t + 1) and rewrite
t	t-1
c(t +1)F(w(t + 1)) ≤ X c(t +1)lt0(w(t +1)) - X c(t)lt0(w(t)) + c(t + 1)β(t + 1)h(w(t +1))
t0=1	t0=1
kq(t)k2 + kr(t)k2
4α(t)
- c(t)β (t)h(w(t)) + c(t + 1)
t-1
-(c(t + 1)- c(t)) X k，(w(t))+ β(t)h(w(t)) . (55)
t0=1
Summing from t = 1 to τ - 1 we get
τ	τ-1	τ-1
XC⑴F (W⑴)≤ XC(T )lt(w(τ)) +C(T )β (T Ih(W(T)) + X c(t +1)
t=2	t=1	t=1
kq(t)k2 + kr(t)k2
4α(t)
τ-1
+ X(C(t) - C(t + 1))
t=1
t-1
X It，(w(t)) + β(t)h(w(t))
t0=1
Let ψ be the last two terms, i.e.,
τ-1
ψ = X(C(t) -C(t+1))
t=1
t-1
X lt' (w(t)) + β(t)h(w(t))
t，=1
(56)
Then, using Lemma 10
τ	τ-1	τ-1
Xc(t)F(w(t)) ≤ XC(TIit(W*1 +C(T)β(τ)h(w*) + Xc(t + 1)
t=2	t=1	t=1
kq(t)k2 + kr(t)k2
4α(t)
+ ψ.
By substituting in equation 45 we continue
τ	τ-1	τ-1
X C(t)F (W(t)) ≤ X C(T)lt(W*) + Xhq(t), W - W(t)i + hr(t), W - W(t)i
t=2	t=1	t=1
q / ∖R( *hl *, X .ilJ∣q(t)k2 + kr(t)k2q /
+C(T)e(T)h(w ) + ZAt +I)-----------4o(^---------+ ψ
τ-1
≤ (T - 1)C(T)F (W*) + Xhq(t), W - W(t)i + hr(t), W - W(t)i
t=1
工(、/√ *、^X r^1J∣q(t)k2 + kr(t)k2j/	5
+C(T)e(T)h(w ) + 与C(t +1)----------40")---------+ψ	(57)
where equation 57 is due to convexity of F(W), i.e., Ptτ=-11 lt(W*) ≤ (T - 1)F (W*). Adding and
subtracting terms we find that
ττ
X C(t)[F (W(t)) - F (W*)] ≤ C(1)[F (W(1)) - F (W*)] + X(C(T) - C(t))F (W*)
τ-1
+ Xhq(t), W - W(t)i + hr(t), W - W(t)i
t=1
+ C(T)β(T)h(w*) + X C(t +1)≡-+∣≡ + ψ
t=	4α(t)
16
Published as a conference paper at ICLR 2019
Taking the expectation with respect to X(τ - 1)
τ
X c(t)[F (w(t)) - F (w*)]
t=1
τ
≤ C(1)[F (W(1)) - F (W*)] + X(C(T) - C(t))F (W*)
t=2
τ-1
+ c(τ)β(τ)h(w*) + X E[hq(t), w - w(t)i] + E[hr(t), w - w(t)i]
t=1
E[kq(t)k2] + [kr(t)k2]
4α(t)
+ E[ψ]
We use the bounds in Lemma 9 to get
E c(t)[F(w(t)) - F(w*)] ≤ c(1)[F(w(1)) - F(w*)]+ E(C(T) - c(t))F(w*)
t=1
t=2
* KD	C(t + 1)	σ2	K22
+ C(T)β(τ)h(W ) + ∑ 西 + 之 Fr (而 +	+ E[ψ].
We rewrite by rearranging terms
τ
X c(t)[F (w(t)) - F (w*)]
t=1
τ
≤ C(1)[F (W(1)) - F (W*)] + X(C(T) - C(t))F (W*)
*	τ-1 KD	τ-1 c(t + 1)σ2
+C(T BT )h(w*)+X E X ⅛⅛r
Now we bound E[ψ]. From equation 56 we find
τ-1
t=2
+ ? X 曰 + E[ψ](58)
4 t=1 α(t)β(t)
ψ =	(c(t) -c(t+ 1))
t=1
τ-1
≤X(c(t)-c(t+1))
t=1
τ-1
= X(c(t) -c(t+1))
t=1
~ ,一 _ , , , ,一
lf0 (w(t)) + β(t)h(w(t))
lf0(W ) + β(t)h(w )
(59)
τ-1
(If/(w*) + hq(t0), W* - w(t0)i + hr(t0), w* - w(t0)i) + β(t)h(w*)
(60)
t-1
≤	(c(t)	-	c(t	+ 1)) (t - 1)F (W*)	+	β(t)h(W*)	+	hq(t0), W* - W(t0)i +	hr(t0), W*	- W(t0)i	,
t=1
t0=1
E
E
E
τ
τ
(61)
where equation 59 is due to Lemma 10, equation 60 is simple substitution of equation 45, and the last
step is due to convexity of F (w). Now, we take the expectation over data samples X(τ - 1)
E[ψ]
τ-1
t-1
≤	(c(t)	-	c(t	+ 1)) (t - 1)F (W*)	+	β(t)h(W*)	+	E[hq(t0), W* - W(t0)i] + E[hr(t0),	W*	- W(t0)i]
t=1	t0=1
τ-1	t-1
≤X(c(t)-c(t+1)) (t - 1)F (w*) + β(t)h(w*) + X
(62)
t=1
τ-1
t0=1
≤ E(c(t) - c(t + 1)) ((t - 1)F(w*) + β(t)h(w*) + 2KDe√μt)
(63)
t=1
where Lemma 9 is used in equation 62 and the last step is due to equation 64. This completes the
proof of Lemma 8.
17
Published as a conference paper at ICLR 2019
D Proof of bounds used in App. F
We know β(t) = K + α(t). Let α(t) = ʌ/^t. Then, We have
TT 1
XXX 而 ≤ 2√μτ.
(64)
Similarly,
τ-1
X
t=1
1	τ-1	1
—1_ = X__________1_____
α(t)β(t)2 t=1 α(t)(K + α(t)2)
τ-1
μ3/2 X t-3/2
t=1
≤ 3μ3/2.
(65)
X 1
W = Mt)3
E Proof of Lemma 9
Note that the expectation with respect to xs (t)
E[f (w(t), xs(t))] = E[F (w(t))].	(66)
Also we use the fact that gradient and expectation operators commutes
EKVf(W(t)), xs(t), w(t))] = EKF(w(t)), w(t)〉].	(67)
Bounding E[hq(t), w* - w(t)i] and E[kq(t)k2] follows the same approach as in (Dekel et al., 2012,
Appendix A.1) or Tsianos & Rabbat (2016). Now, we find E[hr(t), w* - w(t)i]
E[hr(t), w * - w(t)i]
E
E
「/ 1 n bi(t)	1 n bi(t)
K 丽 ΣΣ Vw f (Wi(t), Xi(t, S))-丽 XX Vw f (w(t),Xi(t, s)), W*
Γ / 1 n Mt)	1 n bi(t)	\ ]
K丽 XX VwF(Wi(t))-丽 XXVwF(w(t)), W* — w(t)) I
-w
司
1n
诉 E bi(t)E [hVwF(wi(t)) - VwF(w(t)), w* - w(t)〉]
b(t) i=1
1n
≤ 而 Nbi(t)E[∣∣VwF(wi(t))-VwF(w(t))kkw* - w(t)k]	(68)
1n
≤ 而 ∑bi(t)E [Kkwi(t) - w(t)∣∣D]	(69)
where equation 68 is due to the Cauchy-Schwarz inequality and equation 69 due to equation 9 and
D = maxw,u∈W kw - uk. Using equation 24
*	1 n bi (t)KD
E[hr(t)，w - w(t)i] ≤ 丽 X -kkτ
KD
β (t).
(70)
18
Published as a conference paper at ICLR 2019
Now we find E[kr(t)k2].
E[kr(t)k2] = E
≤E
n bi (t)
XX
Vwf(wi(t), xi(t, s)) - Vwf(w(t), xi(t, s))
i=1 s=1
Vwf (wi(t), Xi(t, S))- Vwf (w(t), Xi(t, s))k
Γ ( 1 n bi(t)	∖ 2
≤ Ell 而 XX K kWi(t) - w(t)k∣
( 1 n bi(t) K ∖2
≤l 而 i=1 S=ι 丽)
_ K2e2
=β(Ψ.
(71)
F Proof of Theorem 4
By definition
n
c(t) = Xci(t)
i=1
(72)
where ci (t) is the total number of gradients computed at the node i in the t-th epoch. We assume
ci(t) is independent across network and is independent and identically distributed according to some
processing time distribution P across epochs. Let C = Ep[c(t)] and let 1/b = Ep[1∕b(t)]. From
Lemma 8 we have that
ττ
Xc(t)E[F(w(t)) - F(w*)] ≤ c(1)[F(w(1)) - F(w*)]+ X(C(T) - c(t))F(w*)
t=1	t=2
+ C(T)β(τ)h(W*) + X KD
τ-1 C(t + 1)σ2	K22 τ-1 C(t + 1)
+ X 4b(t)α(t) + ~T- X 而而 + [ψ].
(73)
Let α(t) = t∕t∕δ. Now take expectation over the c(t) to get
τ
Ep XC(t)E[F(w(t))-F(w*)]
t=1
τ-1
≤ c[F(w(1)) - F(w*)] + cβ(τ)h(w*) + X
t=1
KDe
β⑴
τ-1
+XEp
t=1
∣^c(t + 1)
4α(t)
(+ K± ʌ
V(t) + β(t)27
+ Ep [E[ψ]]
c[F (w(1)) — F (w*)] + cβ(τ )h(w(τ))
τ-1
+X
t=1
KDe
β(t)
τ-1
+X
t=1
Cc
4a(t)
(σ + K22 ʌ
U + β(t)2J .
(74)
19
Published as a conference paper at ICLR 2019
The last step is due to the fact that c(t + 1) and b(t) are independent since these are in two different
epochs. Further Ep [E[ψ∣c(t)]] = 0. After further simplification through the use of Appendix D, We
get
τ
Ep Xc(t)E[F(w(t)) — F(w*)]
t=1
≤ c[F(w(1)) — F(w*) + β(τ)h(w(τ))] + 2KDe√Eτ
cσ2√CT	3K 2 e2c5/2
+---ʌ---1---■—
2b	4
(75)
Taking the expectation over c(t) in equation 30, We have
τ
Ep[E[R∣btot(τ),ctot(τ)]] ≤ Ep X c(t)E[F(w(t)) — F(w*)]
t=1
By definition
τ
+Le X 西
≤ c[F(w(1)) — F(w*) + β(τ)h(w(τ))] + 2KDe√Cτ
cσ2√CT	3K2e2c5/2	…_ r-
+-----K----1-----------+ 2Lecy cτ.
2b	4
(76)
τ
m = c(t).
t=1
(77)
Then mc = Ep = ccτ . By substituting mc and rearranging We find that
3K2e2c5/2
Ep[E[R∣btot(τ),ctot(τ)]] ≤ c[F(w(1)) — F(w*)+ B(T)h(w(T))] +	4
+(2KDe +	+ 2Lec] √C
V 2b 7
(78)
G Proof of Theorem 7
Proof: Consider an FMB method in Which each node computes b/n gradients per epoch, With Ti (t)
denoting the time taken to complete the job.
Also consider AMB With a fixed epoch duration of T . The number of gradient computations
completed by the i-th node in the t-th epoch is
bT
bi(t) = [n®
≥ 工—1.
≥ nTi(t)
(79)
Therefore, the minibatch size b(t) computed in AMB in the t-th epoch is
nn
b(t)=Xbi(t)≥X
i=1	i=1
bT
nTi (t)
bT n 1
—n = K i=1 币-n.
(80)
Taking the expectation over the distribution of Ti (t) in (80), and applying Jensen’s inequality, We
find that
bT n
Ep[b(t)] ≥	〉： Ep
n i=1
1
Ep 田(t)]
—n = bTμ-1 — n.
where Ep田(t)] = mu. Fixing the computing time to T =(1+ n∕b)μ We find that Ep[b(t)] ≥ b,
i.e., the expected minibatch of AMB is at least as large as the minibatch size b used in the FMB.
The expected computing time for T epochs in our approach is
SA = τT = τ (1 + n∕b)μ.	(81)
20
Published as a conference paper at ICLR 2019
In contrast, in the FMB approach the finishing time of the tth epoch is maxi∈[n] Ti (t). Using the
result of Arnold & Groeneveld (1979); Bertsimas et al. (2006) we find that
Ep[maxTi(t)] ≤ μ + σ√n — 1,	(82)
i∈[n]
where σ is the standard deviation of Ti(t). Thus τ epochs takes expected time
SF = TEp[maxTi(t)] ≤ T (μ + σ√n — 1)	(83)
Taking the ratio of the two finishing times we find that
SF ≤ μ+片-ɪ =(1 + σ√n-3) (1 + n/b)-1.	(84)
SA	(1 + n∕b)μ	∖ μ )
For parallelization to be meaningful, the minibatch size should be much larger than number of nodes
and hence b n. This means (1 + n/b) ≈ 1 for any system of interest. Thus,
SF ≤ (1 + μ √n — 1) SA,	(85)
This completes the proof of Theorem 7.
H Shifted exponential distribution
(87)
(88)
(89)
(90)
The shifted exponential distribution is given by
PTi(t)(z) = λexp(一λ(z — Z)), ∀z ≥ Z	(86)
where λ ≥ 0 and ζ ≥ 0. The shifted exponential distribution models a minimum time (ζ) to
complete a job, and a memoryless balance of processing time thereafter. The λ parameter dictates the
average processing speed, with larger λ indicating faster processing. The expected finishing time is
Ep[Ti(t)] = λ-1 + Z. Therefore,
SA = τT = τ (1 + n∕b)(λ-1 + Z).
By using order statistics, we can find
Ep[max Ti(t)] = λ-1 log(n) + Z,
i∈[n]
and thus T epochs takes expected time
SF = T (λ-1 log(n) + Z)
Taking the ratio of the two finishing times we find that
Sf _ (λ-1log(n) + Z)
	= ------:~~:~~:-:-----.
Sa--------------------------(1 + n∕b)(λ-1 + Z)
For parallelization to be meaningful we must have much more data than nodes and hence b n.
This means that the first factor in the denominator will be approximately equal to one for any system
of interest. Therefore, in the large n regime,
lim SF
n→∞
log(n)
1 + λZ SA,
(91)
which is order-log(n) since the product λZ is fixed.
I Supporting discussion of numerical results of main paper and
ADDITIONAL EXPERIMENTS
In this section, we present additional details regarding the numerical results of Section 6 of the
main paper as well as some new results. In Appendix I.1, we detail the network used in Section 6
and, for a point of comparison, implement the same computations in a master-worker network
21
Published as a conference paper at ICLR 2019
Figure 2: The topology of the network used in our experiments on distributed optimization.
topology. In Appendix I.2, we model the compute times of the nodes as shifted exponential random
variables and, under this model, present results contrasting AMB and FMB performance for the linear
regression problem. In Appendix I.3 we present an experimental methodology for simulating a wide
variety of straggler distributions in EC2. By running background jobs on some of the EC2 nodes
we slow the foreground job of interest, thereby simulating a heavily-loaded straggler node. Finally,
in Appendix I.4, we present another experiment in which we also induce stragglers by forcing the
nodes to make random pauses between two consecutive gradient calculations. We present numerical
results for both settings as well, demonstrating the even greater advantage of AMB versus FMB when
compared to the results presented in Section 6.
I.1	Supporting details for results of Section 6 and comparative results for
hub -and-spoke topology
As there was not space in the main text, in Figure 2 we diagram the connectivity of the distributed
computation network used in Section 6. The second largest eigenvalue of the P matrix corresponding
to this network, which controls the speed of consensus, is 0.888.
In Section 6, we presented results for distributed logistic regression in the network depicted in
Figure 2. Another network topology of great interest is the hub-and-spoke topology wherein a central
master node is directly connected to a number of worker nodes, and worker nodes are only indirectly
connected via the master. We also ran the MNIST logistic regression experiments for this topology.
In our experiments there were 20 nodes total, 19 workers and one master. As in Sec.6 we used
t2.micro instances and ami-62b11202 to launch the instances. We set the total batch size used in
FMB to be b = 3990 so, with n = 19 worker each worker calculated b/n = 210 gradients per batch.
Working with this per-worker batch size, we found the average EC2 compute time per batch to be 3
sec. Therefore, we used a compute time of T = 3 sec. in the AMB scheme while the communication
time of Tc = 1 sec. Figure 3 plots the logistical error versus wall clock time for both AMB and FMB
in the master-worker (i.e., hub-and-spoke) topology. We see that the workers implementing AMB far
outperform those implementing FMB.
I.2	Modeling stragglers using a shifted exponential distribution
In this section, we model the speed of each worker probabilistically. Let Ti (t) denote the time taken
by worker i to calculate a total of 600 gradients in the t-th epoch. We assume Ti(t) follows a shifted
exponential distribution and is independent and identically distributed across nodes (indexed by i) and
across computing epochs (indexed by t). The probability density function of the shifted exponential
is PTi(t)(z) = λe-λ(z-ζ). The mean of this distribution is μ = Z + λ-1 and its variance is λ-2.
Conditioned on Ti(t) we assume that worker i makes linear progress through the dataset. In other
words, worker i takes kTi(t)/600 seconds to calculate k gradients. (Note that our model allows k
to exceed 600.) In the simulation results we present we choose λ = 2/3 and ζ = 1. In the AMB
scheme, node i computes bi(t) = 600T/Ti(t) gradients in epoch t where T is the fixed computing
time allocated. To ensure a fair comparison between FMB and AMB, T is chosen according to
Thm. 7. This means that E[b(t)] ≥ b where b(t) = Pi bi(t) and b is the fixed minibatch size used by
FMB. Based on our parameter choices, T = (1 + n∕b)μ = (1 + n/b) (λ-1 + Z) = 2.5.
Figure 4 plots the average error rate of the linear regression problem versus wall clock time for both
FMB and AMB assuming a distributed computation network depicted in Figure 2. In these results, we
22
Published as a conference paper at ICLR 2019
Figure 3: MNIST logistic regression training results for AMB and FMB operating in the hub-and-
spoke topology.
Time (sec)
Figure 4: Linear regression error of AMB and FMB operating in the fully distributed topology of
Figure 2 for 20 sample paths of {Ti (t))} generated according the the shifted exponential distribution.
We plot error versus wall clock time where there are five rounds of consensus.
generate 20 sample paths; each sample path is a set {Ti(t)} for i ∈ {1, . . . , 20} and t ∈ {1, . . . 20}.
At the end of each of the 20 computing epoch we conduct r = 5 rounds of consensus. As can be
observed in Fig. 4, for all 20 sample paths AMB outperforms FMB. One can also observe that there
for neither scheme is there much variance in performance across sample paths; there is a bit more
for FMB than for AMB. Due to this small variability, in the rest of this discussion we pick a single
sample path to plot results for.
Figures 5a and 5b help us understand the performance impact of imperfect consensus on both AMB
and on FMB. In each we plot the consensus error for r = 5 rounds of consensus and perfect consensus
(r = ∞). In Fig. 5a we plot the error versus number of computing epochs while in Figure 5b we plot
it versus wall clock time. In the former there is very little difference between AMB and FMB. This is
due to the fact that we have set the computation times so that the expected AMB batch size equals
the fixed FMB batch size. On the other hand, there is a large performance gap between the schemes
when plotted versus wall clock time. It is thus in terms of real time (not epoch count) where AMB
strongly outperforms FMB. In particular, AMB reaches an error rate of 10-3 in less than half the
time that it takes FMB (2.24 time faster, to be exact).
23
Published as a conference paper at ICLR 2019
(a) Effect of imperfect consensus versus epoch.	(b) Effect of imperfect consensus versus time.
Figure 5:	The effect of imperfect consensus on AMB and FMB.
I.3 Performance with induced stragglers on EC2
In this section, we introduce a new experimental methodology for studying the effect of stragglers. In
these experiments we induce stragglers amongst our EC2 micro.t2 instances by running background
jobs. In our experiments, there were 10 compute nodes interconnected according to the topology
of Figure 2. The 10 worker nodes were partitioned into three groups. In the first group we run two
background jobs that “interfere” with the foreground (AMB or FMB) job. The background jobs we
used were matrix multiplication jobs that were continuously performed during the experiment. This
first group will contain the “bad” straggler nodes. In the second group we run a single background
job. These will be the intermediate stragglers. In the third group we do not run background jobs.
These will be the non-stragglers. In our experiments, there are three bad stragglers (workers 1, 2, and
3), two intermediate stragglers (workers 4 and 5), and five non-stragglers (workers 6-10).
We first launch the background jobs in groups one and two. We then launch the FMB jobs on all
nodes at once. By simultaneously running the background jobs and FMB, the resources of nodes
in the first two groups are shared across multiple tasks resulting in an overall slowdown in their
computing. The slowdown can be clearly observed in Figure 6a which depicts the histogram of the
FMB compute times. The count (“frequency”) is the number of jobs (fixed mini batches) completed
as a function of the time it took to complete the job. The third (fast) group is on the left, clustered
around 10 seconds per batch, while the other two groups are clustered at roughly 20 and 30 seconds.
Figure 6b depicts the same experiment as performed with AMB: first launching the background jobs,
and then launching AMB in parallel on all nodes. In this scenario compute time is fixed, so the
histogram plots the number of completed batches completed as a function of batch size. In the AMB
experiments the bad straggler nodes appear in the first cluster (centered around batch size of 230)
while the faster nodes appear in the clusters to the right. In the FMB histogram per-worker batch size
was fixed to 585 while in the AMB histograms the compute time was fixed to 12 sec.
We observe that these empirical results confirm the conditionally deterministic aspects of our statistical
model of Appendix I.2. This was the portion of the model wherein we assumed that nodes make linear
progress conditioned on the time it takes to compute one match. In Figure 6a, we observe it takes the
non-straggler nodes about 10 seconds to complete one fixed-sized minibatch. It takes the intermediate
nodes about twice as long. Turning to the AMB plots we observe that, indeed, the intermediate
stragglers nodes complete only about 50% of the work that the non-straggler nodes do in the fixed
amount of time. Hence this “linear progress” aspect of our model is confirmed experimentally.
Figure 7 illustrates the performance of AMB and FMB on the MNIST regression problem in the
setting of EC2 with induced stragglers. As can be observed by comparing these results to those
presented in Figure 1b of Section 6, the speedup now effected by AMB over FMB is far larger. While
in Figure 1b the AMB was about 50% faster than FMB it is now about twice as fast. While previously
AMB effect a reduction of 30% in the time it took FMB to hit a target error rate, the reduction now
24
Published as a conference paper at ICLR 2019
刷
2001
AOU3nbalu-
500
500-
0——————
0	5	10
Time (sec)
(a)	FMB: number of batches completed by each
worker versus time to complete each batch; batch
size fixed.
^Hworker 2
worker 3
worker 4
worker 5
worker 6
worker 7
worker 8
Aοuenbes
200
2oo
300	400
^HWorker 9
^HWorker 10
500	600	700	800	900	1000
Batch Size
(b)	AMB: number of batches completed by each
worker versus size of each batch; compute time
fixed.
Figure 6:	Histograms of worker performance in EC2 when stragglers are induced.
Figure 7: MNIST logistic regression performance of AMB and FMB on EC2 operating with induced
straggler nodes.
is about 50%. Generally as the variation amongst stragglers increases we will see a corresponding
improvement in AMB over FMB.
I.4 Performance with induced stragglers on an HPC platform
We conducted another experiment on a high-performance computing (HPC) platform that consists
of a large number of nodes. Jobs submitted to this system are scheduled and assigned to dedicated
nodes. Since nodes are dedicated, no obvious stragglers exist. Furthermore, users of this platform do
not know which tasks are assigned to which node. This means that we were not able to use the same
approach for inducing stragglers on this platform as we used on EC2. In EC2, we ran background
simulations on certain nodes to slow them down. But, since in this HPC environment we cannot tell
where our jobs are placed, we are not able to place additional jobs on a subset of those same nodes to
induce stragglers. Therefore, we used a different approach for inducing stragglers as we now explain.
First, we ran the MNIST classification problem using 51 nodes: one master and 50 worker nodes
where workers nodes were divided into 5 groups. After each gradient calculation (in both AMB
25
Published as a conference paper at ICLR 2019
500
Oooo
5 0 5 0
2 2 11
Aouenbe
0	0.2	0.4	0.6	0.8	1
Time (sec)
(a) FMB: number of batches completed by each
worker versus time to complete each batch; batch
size fixed.
group 1
group 2
■ group 3
■ group 4
group 5
ffu∙nb∙q
1000
500
10	20	30	40	50
Batch Size
(b) AMB: number of batches completed by each
worker versus size of each batch; compute time
fixed.
Figure 8: Histograms of worker performance in HPC when stragglers are induced.
and FMB), worker i pauses its computation before proceeding to the next iteration. The duration
of the pause of the worker in epoch t after calculating the s-th gradient is denoted by Ti (t, s). We
modeled the Ti(t, s) as independent of each other and each Ti(t, s) is drawn according to the normal
distribution N(μj, σj) if worker i is in group j ∈ [5]. If Ti(t, S) < 0, then there is no pause and
the worker starts calculating the next gradient immediately. Groups with larger μj model worse
stragglers and larger σj2 models more variance in that straggler’s delay. In AMB, if the remaining
time to compute gradients is less than the sampled Ti (t, s), then the duration of the pause is the
remaining time. In other words, the node will not calculate any further gradients in that epoch but will
pause till the end of the compute phase before proceeding to consensus rounds. In our experiment, we
chose (μ1, μ2, μ3, μ4, μ5) = (5, 10, 20, 35, 55) and σj2 = j2. In the FMB experiment, each worker
calculated 10 gradients leading to a fixed minibatch size b = 500 while in AMB each worker was
given a fixed compute time, T = 115 msec. which resulted in an empirical average minibatch size
b ≈ 504 across all epochs.
Figures 8a and 8b respectively depict the histogram of the compute time (including the pauses) for
FMB and the histogram of minibatch sizes for AMB obtained in our experiment. In each histogram,
five distinct distributions can be discerned, each representing one of the five groups. Notice that the
fastest group of nodes has the smallest average compute time (the leftmost spike in Figure 8a) and
the largest average minibatch size (the rightmost distribution in Figure 8b).
In Figure 9, we compare the logistic regression performance of AMB with that of FMB for the
MNIST data set. Note that AMB achieves its lowest cost in 2.45 sec while FMB achieves the same
cost only at 12.7 sec. In other words, the convergence rate of AMB is more than five times faster than
that of FMB.
26
Published as a conference paper at ICLR 2019
Figure 9: MNIST logistic regression performance of AMB and FMB on HPC operating with induced
straggler nodes.
27