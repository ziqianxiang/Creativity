title,year,conference
 Neural machine translation by jointlylearning to align and translate,2015, ICLR
 Skip rnn:Learning to skip state updates in recurrent neural networks,2018, ICLR
 Long short-term memory-networks for machinereading,2016, Conference on Empirical Methods in Natural Language Processing (EMNLP)
 Empirical evaluation ofgated recurrent neural networks on sequence modeling,2014, arXiv preprint arXiv:1412
 The goldilocks principle: Readingchildrenâ€™s books with explicit memory representations,2016, In Proceedings of the 4th InternationalConference on Learning Representations (ICLR 2016)
 Long short-term memory,1997, Neural computation
 Length adaptive recurrent model for textclassification,2017, In Proceedings of the 2017 ACM on Conference on Information and KnowledgeManagement
 Learning when to skim and when to read,2017, In Proceedingsof the 2nd Workshop on Representation Learning for NLP
 Actor-critic algorithms,2000, In Advances in neural informationprocessing systems
 Recurrent models of visual attention,2014, InAdvances in neural information processing systems
 Asynchronous methods for deep reinforcementlearning,2016, In International conference on machine learning
 Phased lstm: Accelerating recurrent network train-ing for long or event-based sequences,2016, In Advances in Neural Information Processing Systems
 Glove: Global vectors for wordrepresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 Neural speed reading via skim-rnn,2018, ICLR
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Character-level convolutional networks for text clas-sification,2015, In Advances in neural information processing systems
