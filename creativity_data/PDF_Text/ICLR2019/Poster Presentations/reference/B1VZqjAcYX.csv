title,year,conference
 Stronger generalization bounds fordeep nets via a compression approach,2018, ICML
 Better subset regression using the nonnegative garrote,1995, Technometrics
" â€œLearning-compression"" algorithms for neuralnet pruning",2018, CVPR
 A back-propagation algorithm with optimal use of hidden units,1989, NIPS
 Learning phrase representations using rnn encoder-decoderfor statistical machine translation,2014, EMNLP
 Learning to prune deep neural networks via layer-wiseoptimal brain surgeon,2017, NIPS
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, AISTATS
 Compressing deep convolutional net-works using vector quantization,2014, arXiv preprint arXiv:1412
 Deep learning,2016, MIT pressCambridge
 Dynamic network surgery for efficient dnns,2016, NIPS
 Deep learning withlimited numerical precision,2015, ICML
 Optimal brain surgeon and general networkpruning,1993, Neural Networks
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, ICCV
 Binarizedneural networks,2016, NIPS
 Structural learning with forgetting,1996, Neural Networks
 Speeding up convolutional neural networkswith low rank expansions,2014, BMVC
 A simple procedure for pruning back-propagation trained neural networks,1990, NeuralNetworks
 Adam: A method for stochastic optimization,2015, ICLR
 Understanding black-box predictions via influence functions,2017, ICML
 Imagenet classification with deep convo-lutional neural networks,2012, 2012
 A simple way to initialize recurrent networksof rectified linear units,2015, CoRR
 Optimal brain damage,1990, NIPS
 Efficient backprop,1998, NeuralNetworks: Tricks of the Trade
 Pruning filters forefficient convnets,2017, ICLR
 Learning sparse neural networks throughl0 regularization,2018, ICLR
 Scalable training of artificial neural networks with adaptive sparse connec-tivity inspired by network science,2018, Nature Communications
 Variational dropout sparsifies deep neuralnetworks,2017, ICML
 Skeletonization: A technique for trimming the fat from anetwork via relevance assessment,1989, NIPS
 Exploring sparsity in recurrentneural networks,2017, ICLR
 Tensorizing neuralnetworks,2015, NIPS
 Deep expander networks: Efficient deepnetworks from graph theory,2018, ECCV
 Pruning algorithms-a survey,1993, Neural Networks
 Compression of neural machinetranslation models via pruning,2016, CoNLL
 Very deep convolutional networks for large-scale imagerecognition,2015, ICLR
 Learning structured sparsity indeep neural networks,2016, NIPS
 Wide residual networks,2016, BMVC
 Understandingdeep learning requires rethinking generalization,2017, ICLR
