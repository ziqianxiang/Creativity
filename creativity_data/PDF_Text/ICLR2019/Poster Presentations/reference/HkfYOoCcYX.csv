title,year,conference
 Predictingparameters in deep learning,2013, In Advances in Neural Information Processing Systems
 The Viterbi algorithm,1973, Proc
 Understanding the difficulty of training deep feedforwardneural networks,2010, In Yee Whye Teh and Mike Titterington (eds
 Network sketching: Exploiting binarystructure in deep cnns,2017, International Conference on Machine Learning (ICML)
 Comparing biases for minimal network construction withback-propagation,1989, In Advances in neural information processing systems
 Dynamic evaluation of neuralsequence models,2017, CoRR
 Viterbi-based efficient test data compression,2012, IEEE Trans
 Viterbi-based pruningfor sparse matrix with fixed and high index compression ratio,2018, International Conference onLearning Representations (ICLR)
 Building a large annotatedcorpus of english: The penn treebank,1993, Computational Linguistics
 Statistical language models based on neural networks,2012, PhD thesis
 Convolutional neural networks usinglogarithmic data representation,2016, CoRR
 Breaking the softmax bottle-neck: A high-rank RNN language model,2018, International Conference on Learning Representations(ICLR)
 Dorefa-net: Traininglow bitwidth convolutional neural networks with low bitwidth gradients,2016, CoRR
