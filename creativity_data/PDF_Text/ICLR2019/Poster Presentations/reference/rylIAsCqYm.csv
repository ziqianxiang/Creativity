title,year,conference
 Katyusha: The First Direct Acceleration of Stochastic Gradient Methods,2017, InProceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing
 Even Faster Accelerated CoordinateDescent Using Non-Uniform Sampling,2015, arXiv:1512
 Limitations on Variance-Reduction and Acceleration Schemes for Finite SumsOptimization,2017, In Advances in Neural Information Processing Systems 30
 Revisiting asynchronous linear solvers: Provable convergencerate through randomization,2014, In Paral lel and Distributed Processing Symposium
 Paral lel and Distributed Computation: NumericalMethods,1997, Athena Scientific
 AsynchronousParallel Algorithms for Nonconvex Big-Data Optimization,2017, Part II: Complexity and NumericalResults
 LIBSVM: A Library for Support Vector Machines,2011, ACMTrans
 Chaotic relaxation,1969, Linear Algebra and its Applications
 Accelerating Asynchronous Algorithms for ConvexOptimization by Momentum Compensation,2018, arXiv:1802
 Asynchronous Stochastic Gradient Descent with Variance Reductionfor Non-Convex Optimization,2016, arXiv:1604
 Projective Splitting with Forward Steps: Asynchronousand Block-Iterative Operator Splitting,2018, arXiv:1803
 An optimal randomized incremental gradient method,2015, arXiv:1507
 Efficient Accelerated Coordinate Descent Methods and Faster Algorithmsfor Solving Linear Systems,2013, In 2013 IEEE 54th Annual Symposium on Foundations of ComputerScience
 Efficient Accelerated Coordinate Descent Methods and FasterAlgorithms for Solving Linear Systems,2013, arXiv:1305
 Asynchronous Decentralized Parallel StochasticGradient Descent,2018, In International Conference on Machine Learning
 An Accelerated Proximal Coordinate Gradient Methodand its Application to Regularized Empirical Risk Minimization,2014, arXiv:1407
 An AsynchronousParallel Stochastic Coordinate Descent Algorithm,2014, In International Conference on MachineLearning
 On the complexity analysis of randomized block-coordinate descentmethods,2014, Mathematical Programming
 On the Convergence of AsynchronousParallel Iteration with Unbounded Delays,2016, arXiv:1612
 A Stochastic Gradient Method with anEXponential Convergence _Rate for Finite Training Sets,2012, In Advances in Neural InformationProcessing Systems 25
 Accelerated proXimal stochastic dual coordinate ascent forregularized loss minimization,2016, Mathematical Programming
 A Differential Equation for Modeling Nesterovâ€™sAccelerated Gradient Method: Theory and Insights,2014, In Advances in Neural Information ProcessingSystems 27
 Asynchronous Coordinate Descent under More RealisticAssumptions,2017, In Advances in Neural Information Processing Systems 30
 On accelerated proXimal gradient methods for conveX-concave optimization,2008, Departmentof Mathematics
 DSCOVR: Randomized Primal-DualBlock Coordinate Algorithms for Asynchronous Distributed Optimization,2017, arXiv:1710
 0 is the Kronecker product,2019, Each computingnode has local outdated versions of p
