title,year,conference
 Normalization propagation: Aparametric technique for removing internal covariate shift in deep networks,2016, In Proceedings of the33 rd International Conference on Machine Learning
 Layer normalization,2016, arXiv:1607
 Conditional computationin neural networks for faster models,2016, In International Conference on Learning Representations
 Understanding batch normaliza-tion,2018, In Advances in Neural Information Processing Systems 31
 A parallel mixture of SVMs for Very large scaleproblems,2002, In Advances in Neural Information Processing Systems 15
 ImageNet: A large-scalehierarchical image database,2009, In Computer Vision and Pattern Recognition
 Learning where to attend withdeep architectures for image tracking,2012, Neural Computation
 Natural neural networks,2015, In Advancesin Neural Information Processing Systems 28
 Learning factored representations in a deepmixture of experts,2013, arXiv:1312
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the 13th International Conference on Artificial Intelligence andStatistics
 Deep residual learning for imagerecognition,2016, In Computer Vision and Pattern Recognition
 Squeeze-and-excitation networks,2018, In Computer Vision and PatternRecognition
 Batch renormalization: Towards reducing minibatch dependence in batch-normalizedmodels,2017, In Advances in Neural Information Processing Systems 30
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In Proceedings of the 32nd International Conference on MachineLearning
 Adaptive mixtures oflocal experts,1991, MIT Press
 Training faster by separating modes of variation in batch-normalized models,2019, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Towards a theoretical understanding of batch normalization,2018, arXiv:1805
 Learning multiple layers of features from tiny images,2009, MSc thesis
 ImageNet classification with deep convolu-tional neural networks,2012, In Advances in Neural Information Processing Systems 25
 Efficient backprop in neuralnetworks: Tricks of the trade,1998, Lecture Notes in Computer Science
 Online EM for unsupervised models,2009, In Proceedings of human languagetechnologies: The 2009 annual conference of the North American chapter of the association forcomputational linguistics
 Network in network,2014, In Proceedings of the 2ndInternational Conference on Learning Representations
 Nonlinear image representation using divisive normalization,2008, InComputer Vision and Pattern Recognition
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS Workshop on Deep Learningand Unsupervised Feature Learning
 Automatic differentiation inPyTorch,2017, In NIPS Autodiff Workshop
 Efficient parametrization of multi-domain deep neuralnetworks,2018, In Computer Vision and Pattern Recognition
 Learning multiple visual domains withresidual adapters,2017, In Advances in Neural Information Processing Systems 30
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, InProceedings of the 5th International Conference on Learning Representations
 Mastering the game of Gowithout human knowledge,2017, Nature
 Very deep convolutional networks for large-scale imagerecognition,2015, In Proceedings of the 3rd International Conference on Learning Representations
 Mixtures of Gaussian processes,2001, In Advances in Neural Information ProcessingSystems 14
 Improved texture networks: Maximizingquality and diversity in feed-forward stylization and texture synthesis,2017, In Computer Vision andPattern Recognition
 Show and tell: A neural imagecaption generator,2015, In Computer Vision and Pattern Recognition
 Fashion-MNIST: a novel image dataset for bench-marking machine learning algorithms,2017, arXiv:1708
 Maximum margin clustering,2005, InAdvances in Neural Information Processing Systems 18
