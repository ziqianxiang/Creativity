title,year,conference
 Towards principled methods for training generative adversarialnetworks,2017, arXiv preprint arXiv:1701
 Eigenvalue corrected noisy natural gradient,2018, arXivpreprint arXiv:1811
 The Numerical Treatment of Integral Equations,1997, Clarendon Press
 Weight uncertainty inneural network,2015, In International Conference on Machine Learning
 Random feature expansionsfor deep Gaussian processes,2017, In International Conference on Machine Learning
 Uncertaintydecomposition in Bayesian neural networks with latent variables,2017, arXiv preprint arXiv:1706
 Analysis and probability on infinite-dimensional spaces,2016, arXiv preprintarXiv:1607
 Mapping Gaussian process priors toBayesian neural networks,2017, In NIPS Bayesian deep learning workshop
 Dropout as a Bayesian approximation: Representing modeluncertainty in deep learning,2016, In International Conference on Machine Learning
 Concrete dropout,2017, In Advances in Neural InformationProcessing Systems
 Generative adversarial nets,2014, In Advances in NeuralInformation Processing Systems
 Practical variational inference for neural networks,2011, In Advances in Neural InformationProcessing Systems
 Entropy and Infomation Theory,2011, Springer
 Reliable uncertaintyestimates in deep neural networks using noise contrastive priors,2018, arXiv preprint arXiv:1807
 Gaussian processes for big data,2013, In Uncertaintyin Artificial Intelligence
 Scalable variational Gaussianprocess classification,2015, In Artificial Intelligence and Statistics
 Probabilistic backpropagation for scalable learningof Bayesian neural networks,2015, In International Conference on Machine Learning
 Predictive entropysearch for efficient global optimization of black-box functions,2014, In Advances in Neural InformationProcessing Systems
 Variational inference using implicit distributions,2017, arXiv preprint arXiv:1702
 Scalable gaussian processes with billionsof inducing inputs via tensor train decomposition,2017, arXiv preprint arXiv:1710
 Auto-encoding variational Bayes,2013, arXiv preprintarXiv:1312
 Variational dropout and the local reparameteri-zation trick,2015, In Advances in Neural Information Processing Systems
 AutoGP: Exploring thecapabilities and limitations of Gaussian process models,2016, arXiv preprint arXiv:1610
 Fastfood - approximating kernel expansions in loglineartime,2013, In International Conference on Machine Learning
 Deep neural networks as Gaussian processes,2018, In International Conference onLearning Representations
 Automatic construction and natural-language description of nonparametric regressionmodels,2014, In AAAI
 Structured and efficient variational deep learning with matrixGaussian posteriors,2016, In International Conference on Machine Learning
 Multiplicative normalizing flows for variational Bayesian neuralnetworks,2017, In International Conference on Machine Learning
 Bayesian compression for deep learning,2017, InAdvances in Neural Information Processing Systems
 Variational implicit processes,2018, arXivpreprint arXiv:1806
 Learning from uncertain curves: The 2-wasserstein metric forGaussian processes,2017, In Advances in Neural Information Processing Systems
 Bayesian Learning for Neural Networks,1995, PhD thesis
 A mean field theory learning algorithm for neural networks,1987, Complex systems
 Random features for large-scale kernel machines,2008, In Advances inNeural Information Processing Systems
 Occamâ€™s razor,2001, In Advances in Neural InformationProcessing Systems
 Deep Bayesian bandits showdown: An empiricalcomparison of Bayesian deep networks for thompson sampling,2018, In International Conference onLearning Representations
 Doubly stochastic variational inference for deep Gaussianprocesses,2017, In Advances in Neural Information Processing Systems
 Student-t processes as alternatives to Gaussianprocesses,2014, In Artificial Intelligence and Statistics
 Kernel implicit variational inference,2018, In InternationalConference on Learning Representations
 A spectral approach to gradient estimation for implicitdistributions,2018, International Conference on Machine Learning
 Sparse Gaussian processes using pseudo-inputs,2006, InAdvances in Neural Information Processing Systems
 On the likelihood that one unknown probability exceeds another in view ofthe evidence of two samples,1933, Biometrika
 Variational learning of inducing variables in sparse Gaussian processes,2009, In ArtificialIntelligence and Statistics
 Max-value entropy search for efficient Bayesian optimization,2017, InInternational Conference on Machine Learning
 Using the NystrOm method to speed UP kernelmachines,2001, In Advances in Neural Information Processing Systems
 Noisy natUral gradient asvariational inference,2018, In International Conference on Machine Learning
