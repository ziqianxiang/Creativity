title,year,conference
 Stronger generalization bounds for deep nets via acompression approach,2018, In ICML
 Learning with pseudo-ensembles,2014, In Advances in NeuralInformation Processing Systems
 Entropy-SGD: Biasing Gradient Descent Into Wide Valleys,1611, arXiv:1611
 Sharp minima can generalize for deep nets,2017, In ICML
 Self-ensembling for visual domain adaptation,2018, InInternational Conference on Learning Representations
 Shake-shake regularization,2017, CoRR
 Generative adversarial nets,2014, In Advances in neural information processing systems
 Qualitatively characterizing neural network optimizationproblems,2015, International Conference on Learning Representations
 Gradient descent happens in a tiny subspace,2018, In CoRR
 Deep residual learning for image recognition,2015, CoRR
 On large-batch trainingfor deep learning: Generalization gap and sharp minima,2017, ICLR
 Adam: A method for stochastic optimization,2015, ICLR
 Temporal Ensembling for Semi-Supervised Learning,2016, arXiv:1610
 Temporal ensembling for semi-supervised learning,2017, International Conferenceon Learning Representations
 SGDR: stochastic gradient descent with restarts,2016, CoRR
 Smooth neighbors on teacher graphs for semi-supervisedlearning,2018, In CVPR
 Stochastic gradient descent as approximate bayesianinference,2017, arXiv preprint arXiv:1704
 Virtual adversarial training: a regularization methodfor supervised and semi-supervised learning,2017, CoRR
 Sensitivity and generaliza-tion in neural networks: an empirical study,2018, ICLR
 Realistic evaluation of deepsemi-supervised learning algorithms,2018, ICLR Workshop
 Adversarial Dropout for Supervised and Semi-supervised Learning,1707, arXiv:1707
 Empirical analysis of the hessian ofover-parametrized neural networks,2017, CoRR
 Regularization With Stochastic Transformations andPerturbations for Deep Semi-Supervised Learning,2016, arXiv:1606
 Flat minima,1997, Neural Computation
 A DIRT-t approach to unsupervised domain adaptation,2018, InInternational Conference on Learning Representations
 Mean teachers are better role models: Weight-averaged consistencytargets improve semi-supervised deep learning results,2017, In NIPS
 80 million tiny images: A large data set for nonparametricobject and scene recognition,2008, IEEE Trans
 The UnusualEffectiveness of Averaging in GAN Training,2018, ArXiv
 Semi-Supervised Learning Using Gaussian Fields andHarmonic Functions,2003, ICML
