title,year,conference
 High-dimensional dynamics of generalization error in neuralnetworks,2017, arXiv preprint arXiv:1710
 Spectrally-normalized margin bounds forneural networks,2017, In Advances in Neural Information Processing Systems
 Kernel methods for deep learning,2009, In Advances in neuralinformation processing systems
 Input-output maps are strongly biasedtowards simple outputs,2018, Nature communications
 Sharp minima can generalize fordeep nets,2017, In Proceedings of the 34th International Conference on Machine Learning
 Essentially no barriersin neural network energy landscape,1309, In Proceedings of the 35th International Conference onMachine Learning
 Data-dependent pac-bayes priors via differentialprivacy,2018, arXiv preprint arXiv:1802
 Generalization ability of boolean functions implemented in feedforward neuralnetworks,2006, Neurocomputing
 On a generalization complexity measure for boolean func-tions,2004, In Neural Networks
 Deep convolutionalnetworks as shallow Gaussian processes,2018, arXiv preprint arXiv:1808
 Pac-bayesian theorymeets bayesian inference,2016, In Advances in Neural Information Processing Systems
 Size-independent sample complexity ofneural networks,2018, In Proceedings of the 31st Conference On Learning Theory
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Nearly-tight VC-dimension bounds forpiecewise linear neural networks,1064, In Proceedings of the 2017 Conference on Learning Theory
 Flat minima,1997, Neural Computation
 On large-batch training for deep learning: Generalization gap and sharp minima,2016, CoRR
 Adam: Amethod for stochastic optimization,2014, In Proc
 Bounds for averaging classifiers,2001, 2001
 No free lunch versus Occamâ€™s razor in supervised learning,2013, InAlgorithmic Probability and Friends
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Deep learning,2015, Nature
 Deep neural networks as gaussian processes,2017, arXiv preprint arXiv:1711
 On the complexity of finite sequences,1976, IEEE Transactions oninformation theory
 Theory of deep learning ii: Landscape of the empirical risk in deeplearning,2017, arXiv preprint arXiv:1703
 Pac-bayesian model averaging,1999, In COLT
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 On the importance ofsingle directions for generalization,2018, arXiv preprint arXiv:1803
 Generalization and parameter estimation in feedforward nets:Some experiments,1990, In Advances in neural information processing systems
 Norm-based capacity control in neuralnetworks,2015, In Conference on Learning Theory
 A pac-bayesian approach to spectrally-normalized margin bounds for neural networks,2017, arXiv preprintarXiv:1707
 Exploring general-ization in deep learning,2017, In Advances in Neural Information Processing Systems
 To-wards understanding the role of over-parametrization in generalization of neural networks,2018, arXivpreprint arXiv:1805
 Bayesian convolutional neural networks with many channels aregaussian processes,2018, arXiv preprint arXiv:1810
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2016, In Proceedings of the International Conference onLearning Representations (ICLR)
 Gaussian processes in machine learning,2004, In Advanced lectures on machinelearning
 Modeling by shortest data description,1978, Automatica
 Empirical analysis ofthe hessian of over-parametrized neural networks,2017, arXiv preprint arXiv:1706
 Discovering neural nets with low kolmogorov complexity and high general-ization capability,1997, Neural Networks
 Deep learning in neural networks: An overview,2015, Neural networks
 Deep informa-tion propagation,2017, In Proceedings of the International Conference on Learning Representations(ICLR)
 Understanding machine learning: From theory to algo-rithms,2014, Cambridge university press
 A bayesian perspective on generalization and stochastic gradientdescent,2017, CoRR
 The implicit bias of gradient descent on separabledata,2017, arXiv preprint arXiv:1710
 Deep neuroevolution: Genetic algorithms are a competitive alternative for trainingdeep neural networks for reinforcement learning,2018, NIPS Deep Reinforcement Learning Workshop
 On the depth of deep neuralnetworks: A theoretical view,2016, In AAAI
 Towards understanding generalization of deep learning: Perspectiveof loss landscapes,2017, arXiv preprint arXiv:1706
 Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms,2017, CoRR
 Robustness and generalization,2012, Machine learning
 On early stopping in gradient descent learn-ing,2007, Constructive Approximation
 Energy-entropy competition andthe effectiveness of stochastic gradient descent in machine learning,2018, Molecular Physics
