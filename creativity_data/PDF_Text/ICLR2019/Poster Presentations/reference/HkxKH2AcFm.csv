title,year,conference
 Towards Principled Methods for Training Generative AdversarialNetworks,2017, arXiv
 Wasserstein gan,2017, arXiv preprintarXiv:1701
 Do gans actually learn the distribution? an empirical study,2017, arXivpreprint arXiv:1706
 A note on the inception score,2018, arXiv preprint arXiv:1801
 The cramer distance as a solution to biased wasserstein gradients,2017, arXivpreprint arXiv:1705
 DemystifyingMMD GANs,2018, In International Conference on Learning Representations
 Infogan:Interpretable representation learning by information maximizing generative adversarial nets,2016, InAdvances in Neural Information Processing Systems
 Good semi-supervised learning that requires a bad gan,2017, In Advances in Neural Information Processing Systems
 Compari-son of Maximum Likelihood and GAN-based training of Real NVPs,2017, arXiv
 Compari-son of maximum likelihood and gan-based training of real nvps,2017, arXiv preprint arXiv:1705
 ImageNet: A large-scalehierarchical image database,2009, In IEEE Conference on Computer Vision and Pattern Recognition
 Flow-GAN: Combining maximum likelihood andadversarial learning in generative models,2017, arXiv preprint arXiv:1705
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In Proceedings of the IEEE internationalconference on computer vision
 Ganstrained by a two time-scale update rule converge to a local nash equilibrium,2017, In Advances in NeuralInformation Processing Systems
 Generative adversarial imitation learning,2016, In Advances in NeuralInformation Processing Systems
 Stacked generativeadversarial networks,2016, arXiv preprint arXiv:1612
 Quantitatively evaluating ganswith divergences proposed for training,2018, arXiv preprint arXiv:1803
 Mmd gan:Towards deeper understanding of moment matching network,2017, In Advances in Neural InformationProcessing Systems
 Approximation and convergence propertiesof generative adversarial learning,2017, arXiv preprint arXiv:1705
 Revisiting classifier two-sample tests,2016, arXiv preprintarXiv:1610
 Conditional image synthesis with auxiliaryclassifier gans,2016, arXiv preprint arXiv:1610
 Realisticevaluation of deep semi-supervised learning algorithms,2018, arXiv preprint arXiv:1804
 A deep reinforced model for abstractivesummarization,2017, arXiv preprint arXiv:1705
 A call for clarity in reporting bleu scores,2018, In Proceedings of the Third Conference onMachine Translation (WMT)
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2015, arXiv preprint arXiv:1511
 mir_eval: A transparent implementation of common MIR metrics,2014, In Proceedingsofthe 15th International Societyfor Music Information RetrievaI Conference
 Swish: a self-gated activation function,2017, arXivpreprint arXiv:1710
 Variationalapproaches for auto-encoding generative adversarial networks,2017, arXiv preprint arXiv:1706
 PixelCNN++: Improving thePixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications,2017, arXiv
 Ac-gan learns a biased distribution,2017, 2017
 Generative models and model criticism via optimized maximum meandiscrepancy,2016, arXiv preprint arXiv:1611
 Rethinking theinception architecture for computer vision,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 A note on the evaluation of generativemodels,2015, arXiv
 The nature of statistical learning theory,1995, 1995
 On the quantitative analysis ofdecoder-based generative models,2016, arXiv preprint arXiv:1611
