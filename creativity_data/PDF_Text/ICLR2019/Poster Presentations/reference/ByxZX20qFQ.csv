title,year,conference
 Character-level lan-guage modeling with deeper self-attention,2018, arXiv
 Pragmatic neural language modelling in machine translation,2015, InProc
 A Neural ProbabilisticLanguage Model,2003, JMLR
 Neural lattice language models,2018, TACL
 Strategies for training large vocabulary neurallanguage models,2016, In Proc
 Language modeling with gatedconvolutional networks,2017, In Proc
 Classes for Fast Maximum Entropy Training,2001, In Proc
 Improving neural language models with acontinuous cache,2016, arXiv
 Efficientsoftmax approximation for gpus,2017, In Proc
 Deep Residual Learning for ImageRecognition,2015, In Proc
 Tying word vectors and word classifiers: Aloss framework for language modeling,2016, arXiv
 Exploring thelimits of language modeling,2016, arXiv
 Character-aware neural languagemodels,2015, arXiv
 Character-aware neural languagemodels,2016, In AAAI
 SGDR: stochastic gradient descent with restarts,2016, arXiv
 Pointer sentinel mixturemodels,2016, arXiv
 An analysis of neural language modelingat multiple scales,2018, arXiv
 RecurrentNeural Network based Language Model,2010, In Proc
 Exten-sions of Recurrent Neural Network Language Model,2011, In Proc
 Analyzing uncertainty in neuralmachine translation,2018, In Proc
 On the difficulty of training recurrent neuralnetworks,2013, In Proc
 Using the output embedding to improve language models,2017, In Proc
 Fast parametric learning withactivation memorization,2018, arXiv
 Neural machine translation of rare words withsubword units,2016, In Proc
 On the importance ofinitialization and momentum in deep learning,2013, In Proc
 Decoding with Large-scaleNeural Language Models improves Translation,2013, In Proc
 Attention Is All You Need,2017, In Proc
