title,year,conference
 Surprise-based intrinsic motivation for deep reinforcementlearning,2017, arXiv:1703
 Variational option discoveryalgorithms,2018, arXiv preprint arXiv:1807
 Playinghard exploration games by watching YouTube,2018, arXiv preprint arXiv:1805
 A distributional perspective on reinforcementlearning,2017, arXiv preprint arXiv:1707
 UCB and infogain explorationvia q-ensembles,2017, arXiv:1706
 Learning phrase representations using RNN encoder-decoder forstatistical machine translation,2014, arXiv preprint arXiv:1406
 Learning to perform physics experiments via deep reinforcement learning,2016, arXiv preprintarXiv:1611
 Diversity is all you need:Learning skills without a reward function,2018, arXiv preprint
 Dora the explorer: Directed outreachingreinforcement action-selection,2018, International Conference on Learning Representations
 EX2: Exploration with exemplar models for deepreinforcement learning,2017, NIPS
 Expert-augmented actor-critic forvizdoom and montezumas revenge,2018, arXiv preprint arXiv:1809
 Variational intrinsic control,2017, ICLRWorkshop
 Learning to play with intrinsically-motivated self-aware agents,2018, arXiv preprint arXiv:1802
 Rainbow: Combining improvements indeep reinforcement learning,2017, arXiv preprint arXiv:1710
 Distributed prioritized experience replay,2018, arXiv preprint arXiv:1803
 VIME:Variational information maximizing exploration,2016, In NIPS
 Adam: A method for stochastic optimization,2015, ICLR
 Hierarchical deepreinforcement learning: Integrating temporal abstraction and intrinsic motivation,2016, In Advances inneural information processing systems
 Exploration in model-basedreinforcement learning by empirically estimating learning progress,2012, In NIPS
 Revisiting the arcade learning environment: Evaluation protocols and open problems forgeneral agents,2017, arXiv preprint arXiv:1709
 Count-based exploration with thesuccessor representation,2018, arXiv preprint arXiv:1807
 Playing Atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Asynchronous methods for deep reinforcementlearning,2016, In ICML
 The uncertainty Bellmanequation and exploration,2017, arXiv preprint arXiv:1709
 Self-imitation learning,2018, arXiv preprintarXiv:1806
 Deep exploration viabootstrapped DQN,2016, In NIPS
 Randomized prior functions for deep reinforcementlearning,2018, arXiv preprint arXiv:1806
 Count-based explorationwith neural density models,2018, International Conference for Machine Learning
 Intrinsic motivation systems for au-tonomous mental development,2007, Evolutionary Computation
 Curiosity-driven exploration byself-supervised prediction,2017, In ICML
 Observe and look further:Achieving consistent performance on Atari,2018, arXiv preprint arXiv:1805
 Temporal difference models: Model-free deep RL for model-based control,2018, arXiv preprint arXiv:1802
 Random features for large-scale kernel machines,2008, In Advances inneural information processing Systems
 Curious model-building control systems,1991, In Neural Networks
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Mastering the game of Go withdeep neural networks and tree search,0028, Nature
 Incentivizing exploration in reinforcementlearning with deep predictive models,2015, NIPS Workshop
 Deep curiosity search: Intra-life exploration improves perfor-mance on challenging deep reinforcement learning problems,2018, arXiv preprint arXiv:1806
 An information-theoretic approach to curiosity-driven reinforcementlearning,2012, Theory in Biosciences
 Intrinsic motivation andautomatic curricula via asymmetric self-play,2018, In ICLR
 Deep fried convnets,2015, In Proceedings of the IEEE International Conference on ComputerVision
 Neural architecture search with reinforcement learning,2016, arXiv preprintarXiv:1611
