title,year,conference
 Tensorflow: Large-scale machine learning on heterogeneousdistributed systems,2016, arXiv preprint arXiv:1603
 Neural network learning: Theoretical foundations,2009, cambridge universitypress
 Stronger generalization bounds for deep nets via acompression approach,2018, arXiv preprint arXiv:1802
 Obfuscated gradients give a false sense of security:Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th International Conference onMachine Learning
 Spectrally-normalized margin bounds for neuralnetworks,2017, In Advances in Neural Information Processing Systems
 Defensive distillation is not robust to adversarial examples,2016, arXiv preprintarXiv:1607
 Towards evaluating the robustness of neural networks,2017, In 2017 IEEESymposium on Security and Privacy (SP)
 Parseval networks:Improving robustness to adversarial examples,2017, arXiv preprint arXiv:1704
 Entropy-sgd optimizes the prior of a pac-bayes bound: Data-dependent pac-bayes priors via differential privacy,2017, arXiv preprint arXiv:1712
 Robustness of classifiers: fromadversarial to random noise,2016, In Advances in Neural Information Processing Systems
 Adversarial vulnerability for any classifier,2018, arXiv preprintarXiv:1802
 Adversarial spheres,2018, arXiv preprint arXiv:1801
 Generative adversarial nets,2014, In Advances in neural information processingsystems
 Regularisation of neural networks by enforcinglipschitz continuity,2018, arXiv preprint arXiv:1804
 Identity mappings in deep residual networks,2016, InEuropean conference on computer vision
 Batch normalization: Accelerating deep network training by reducinginternal covariate shift,2015, arXiv preprint arXiv:1502
 Onlarge-batch training for deep learning: Generalization gap and sharp minima,2016, arXiv preprint arXiv:1609
 Adversarial machine learning at scale,2016, arXiv preprintarXiv:1611
 Towards deeplearning models resistant to adversarial attacks,2018, In International Conference on Learning Representations
 Spectral normalization for generativeadversarial networks,2018, arXiv preprint arXiv:1802
 Deepfool: a simple and accuratemethod to fool deep neural networks,2016, In Proceedings of 2016 IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 Norm-based capacity control in neural networks,2015, InCOLT
 A pac-bayesian approach tospectrally-normalized margin bounds for neural networks,2017, arXiv preprint arXiv:1707
 Exploring generalization in deeplearning,2017, In Advances in Neural Information Processing Systems
 Distillation as a defense toadversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium on Security and Privacy(SP)
 Adversariallyrobust generalization requires more data,2018, arXiv preprint arXiv:1804
 The singular values of convolutional layers,2018, arXiv preprintarXiv:1805
 Certifiable distributional robustness with principledadversarial training,2018, In International Conference on Learning Representations
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensembleadversarial training: Attacks and defenses,2018, In International Conference on Learning Representations
 User-friendly tail bounds for sums of random matrices,2012, Foundations of computational mathematics
 Lipschitz-margin training: Scalable certification ofperturbation invariance for deep neural networks,2018, arXiv preprint arXiv:1802
 Analyzing the robustness of nearest neighbors toadversarial examples,2017, arXiv preprint arXiv:1706
 Spectral norm regularization for improving the generalizability of deeplearning,2017, arXiv preprint arXiv:1705
 Understanding deep learningrequires rethinking generalization,2016, arXiv preprint arXiv:1611
24CIFAR10	AlexNet	FGM `2	407 s	463 s	1,2019,14CIFAR10	AlexNet	FGM 'âˆž	408 s	465 s	1
