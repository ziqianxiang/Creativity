title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Measuring neural net robustness with constraints,2016, In Advances in NeuralInformation Processing Systems
 Julia: A fresh approach tonumerical computing,2017, SIAM Review
 Convex Optimization,2004, Cambridge University Press
 A unifiedview of piecewise linear neural network verification,2018, In Advances in Neural Information ProcessingSystems
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 EAD: elastic-net attacksto deep neural networks via adversarial examples,2018, In AAAI Conference on Artificial Intelligence
 Jump: A modeling language for mathematicaloptimization,2017, SIAM Review
 Output range analysis fordeep feedforward neural networks,2018, In NASA Formal Methods Symposium
 Adual approach to scalable verification of deep networks,2018, In Conference on Uncertainty in ArtificialIntelligence
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Gurobi Optimization,2017, Gurobi optimizer reference manual
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Safety verification of deep neuralnetworks,2017, In International Conference on Computer Aided Verification
 Nonconvex piecewise linear functions: Advanced formulationsand simple modeling tools,2017, arXiv preprint arXiv:1708
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In Proceedings of the 32nd International Conference on MachineLearning
 Reluplex: An efficientSMT solver for verifying deep neural networks,2017, In International Conference on Computer AidedVerification
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, In Proceedings of the 35th International Conference on Machine Learning
 An approach to reachability analysis for feed-forward ReLUneural networks,2017, arXiv preprint arXiv:1706
 Introduction to Interval Analysis,2009, SIAM
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Certified defenses against adversarialexamples,2018, In International Conference on Learning Representations
 Towards verification ofartificial neural networks,2015, In MBMV
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Mixed integer linear programming formulation techniques,2015, SIAM Review
 Towards fast computation of certified robustness for ReLU networks,2018, InProceedings of the 35th International Conference on Machine Learning
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems
 Output reachable set estimation andverification for multi-layer neural networks,2018, IEEE Transactions on Neural Networks and LearningSystems (TNNLS)
