Figure 1: The label-propagation layer with attention (Sec. 3.1) and bifurcation (Sec. 3.2)Node-feature similarities: when available, node features can be used to define edge features by incorporatingvarious similarity measures such as cosine similarity (φij = xi>xj /kxi kkxj k) and Gaussian similarity(φij = exp{-∣∣xi - Xj k2∕σ2}), where each similarity measure induces a distinct feature.
Figure 2: (Left) A real example of an information-gated attention update. Green bars depict soft labels h(C = 4), stars mark true labels. Red and blue bars (right) show values of θ. Arrow width indicates attentiveweight. determined by e and d (boxed bars), which are computed using h(t) and θ. Here θ directs attention atthe informative and similar neighbor (thick arrow), and the update amplifies the value of the correct label.
Figure 3: As learning progresses, the Laplacian’s 2ndsmallest eigenvalue increases, and accuracy follows.
Figure 4: The added gain of controlling label conver-gence rates with a bifurcation mechanism.
