Figure 1: Illustration of domains with common (a) and pairwise-shared spaces (b). We tackle the domain adaptationtask when all domains share a common task/space, which is then leveraged to transfer knowledge across multiple targetdomains.
Figure 2: MDTA-ITA: The encoder Es(x) captures the feature representations (zs) for a given input sample x that areshared among domains. Ep(X) captures domain-specific private features (Zp) using the shared private encoder. Theshared decoder F(zp, zs) learns to reconstruct the input sample by using both the private and shared features. The domainclassifier D learns to correctly predict the domain labels of the actual samples from both their shared and private featureswhile the classifier C learns to correctly predict the class labels from the shared features.
Figure 3: Exemplary images from different datasets. a) Digits datasets, b) PACS datatset (first row: Art-painting,second row: Cartoon, Third row: Photo, last row: Sketch), c) Multi-PIE dataset (each row corresponds to a differentcamera angle and each subject depicts an expression(normal, smile, surprise, squint, disgust, scream) at every cameraposition).
Figure 4: Ablation of MTDA-ITA on Digit dataset. We show that each component of our method, Reconstruction loss,Classifier entropy loss with separating shared/private features, contributes to the overall performance.
Figure 5: Feature visualization for embedding of digit datasets using t-SNE algorithm. The first and the second columnsshow the domains and classes, respectively, with color indicating domain and class membership. (a),(b) Original features.
Figure 6: Feature visualization for embedding of digit datasets using t-SNE algorithm. The first and the second columnsshow the domains and classes, respectively, with color indicating domain and class membership. (a),(b) Original features.
