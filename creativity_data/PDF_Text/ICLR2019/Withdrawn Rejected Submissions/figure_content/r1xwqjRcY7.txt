Figure 1: Schematic of the PSE model.
Figure 2: 2D embedding space visualisations of MNIST characters. Best viewed in colour. Points arethe latent image embedding codes, and different colours represent different labels. We can see thatthe learned latent dimensions of CVAE does not obtain a semantic embedding space. The JMVAE,the TrELBO model and the SCAN (in SCAN, images are encoded with a pre-trained β-VAE.) forcelearnt latent distributions to match with the Gaussian prior; therefore there is serious overlap inthe embedding space. Our PSE and PSE* label embedding models provide better separation ofclasses whilst capturing visual similarity, with PSE* showing the greater separation of classes. SeeAppendix B for a larger visualisation of the PSE and PSE* latent spaces.
Figure 3:	Generated samples of the TrELBO model and our model. We see that the TrELBO can notcreate accurate images without a higher hyperparameter λ1 .
Figure 4:	Our model can learn the gradual visual changes. By exploring the embedding space, aseries of images can be generated to illustrate how one class of images change to their visual-semanticneighbours.
Figure 5: Images generated from a PSE* model trained with word2vec encoded labels and labelcompositions. Images represent: ‘Sneaker’, 0.5(‘Sneaker’+‘Ankle Boots’), ‘Ankle Boots’ & ‘Tshirt’,0.5(‘Tshirt’+‘Shirt’), ‘Shirt’With pre-trained word2vec, prior knowledge learnt from the text domain can be exploited to imagineimages with unseen labels — we can generate images for terms that were not used in the trainingset. Figure 6 shows six examples generated from words semantically close to, but different from, thetraining labels.
Figure 6: Generated samples for unseen labelsWe can see that our models can leverage the similarity in the text domain and generate relevantvisual features. We find that prior knowledge from a pre-trained word2vec contains some noise forvisual-semantic information. For example, in the image generated in Figure 6e for the term “Bootcut”could be considered to be incorrect, as we would most likely expect an image that looks like a pairof trousers. However, in the pre-trained word2vec model, “Bootcut” is most similar to “Pullover”.
Figure 7: 2D latent space of MNIST with the PSE model.
Figure 8: 2D latent space of MNIST with the PSE* model.
Figure 9: 2D latent space of Fashion-MNIST with the PSE model.
Figure 10: 2D latent space of Fashion-MNIST with the PSE* model.
