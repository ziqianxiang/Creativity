Figure 1: Our simulated environment and the bone positions on the agent model. The head pose,facial expressions, skin type, age, camera position and lighting are all fully customizable.
Figure 2: The composite function, which takes as input the simulation parameters θ, in order to firstproduce a simulation s(θ). This in turn is fed into a machine classification system to compute a lossfunction characterizing whether the system performed correctly or poorly.
Figure 3: Top) Cropped views of the face from our simulated environment and variations in appear-ance with i) skin type, ii) age, iii) head yaw, iv) head pitch, v) mouth open, vi) eyes closed.
Figure 4: Distribution of each simulation parameter for successfully detected faces and missed de-tections. The distribution for skin types and ages skews darker and older respectively for falsenegatives than for true positives. The Bayesian optimization reveals this difference with fewer sim-ulations, such that given 1000 samples the differences are apparent with BO and not with randomsampling. The skin tone ranges from light (0) to dark (1) and age ranges from young (0) to old (1).
Figure 5: Sample efficiency of finding false negatives (missed face detections). a) Results for each ofthe face APIs individually. b) Results aggregated across all APIs. Red - Using random sampling (thisis the same as chance performance). Blue - Using Bayesian optimization. Shaded area correspondsto the standard error.
