Figure 1: An illustration of GSFP. Each circle with a color represents the saliency score of a fil-ter, and the rectangle represents the generated filter mask. The schematic diagram is divided intofour parts: the top represents the training process and the bottom represents the pruning process.
Figure 2: Different method and networks pruning training curves on CIFAR-10.
Figure 3: The saliency scores visualization for LeNet-5 on 10 epoch. The top figure shows saliencyscores for CONV1, bottom figure shows the saliency scores for CONV2. The pruning rate are 70%,80%, 85% and 90%, respectively.
Figure 4: Different layers of pruning distribution curves on ImageNetT ConV2d-2T Conv2d-3―■—COnV2d-7♦ COnV2d-9■ Conv2d-10T Conv2d-13一COnV2d-16—Conv2d-18T-Conv2d-19-*-Conv2d-20Conv2d-26—■ Conv2d-28—X—Conv2d-304.3	RESNET ON IMAGENETWe also test our pruning scheme on the large scale ImageNet classification task. ResNet is currentlythe most widely used network structure, so in the experiment we chose ResNet-18 and ResNet-32for pruning. During the pruning process, since the ResNet cross-layer contains a lot of information,we do not pruned the shortcut convolution layer. Table 5 shows the pruning results of ResNet onImagenet. For ResNet-18, GSFP reduced the FLOPs by 47.06% , with a Top-1 accuracy drop 2.95%.
