Figure 1: A supervised classifier ‘cheetah vs. snow-leopard’ that uses unrelated evidence (ofhabitat) over relevant evidence (of fur patterns). As shown by the pixel importance maps, the modelsuffers from the negative transfer prevalent in a typical animal image dataset skewed towards theanimal’s typical habitat and fails to generalize to rare samples.
Figure 2: An illustration ofinstance source distributionover 2D space.(a) Source dis-tribution with correlated la-bels (b) Closest uncorrelateddistribution is the desired tar-get distribution.
Figure 3: Synthetic experiment results:(a) Mean average precision over test set with varyingP(Yp|Ya), when trained on data with P(Yp|Ya) = 0.8. (b) Mean average precision over test setwith P(Yp|Ya) = 0.5 when train set with P(Yp|Ya) = 0.8, varying max auxiliary accuracy.
Figure 4: Mean average precision over test split of AwA per group. The proposed ALadvC out per-forms the MLP baseline model, while the LR+FS-adv outperforms its baseline LR and LR+FS, formultilabel attribute prediction on held-out classes. (b) The training performance of the model withadversarial loss is corrected to reflect the true performance of the model, improving generalization.
Figure 5: Mean average precision over validation and test split of CUB per group. The proposedALadvC out performs the MLP baseline model, while the LR+FS-adv outperforms its baseline LRand LR+FS, for multilabel attribute prediction on held-out classes. (b) mAP of MLP and proposedALadvC model on train and test against epochs. The training performance of the model with adver-sarial loss is corrected to reflect the true performance of the model, improving generalization. (c)The CUB dataset consists of 28 groups, increasing number of adversarial tasks from most correlatedto least helps improve performance on test splits.
Figure 6: Maximumcross-correlation be-tween the groupedattributes from trainsplits of AwA and CUBdataset.
