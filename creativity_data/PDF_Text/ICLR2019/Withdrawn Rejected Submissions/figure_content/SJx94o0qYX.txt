Figure 1: Comparison of conventional quantization and our proposed idea on residual network.
Figure 2: Comparison on residual network.
Figure 3: Weight histogram and Laplace approximation(dashed line) of the convolutional layer of a trainedfull-precision ResNet-50.
Figure 4: Quantization error accumula-tion across residual blocks in ResNet-50.
Figure 5: Loss surface of ResNet-18 on Cifar-10: (a) full-precision model (FP), (b) 1-bit activationand 2-bit weight quantized model (1A2W) without precision highway (PH), (c) 1A2W with precisionhighway, and (d) cross-section of loss surface.
Figure 6: Comparison of chip area and energyconsumption on the hardware accelerator.
