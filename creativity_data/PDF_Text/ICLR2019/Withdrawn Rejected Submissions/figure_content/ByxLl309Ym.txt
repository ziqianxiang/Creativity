Figure 1: Proposed Cross-coding framework for conditional inference with variational auto-encoders.
Figure 2: One conditional inference example for MNIST. In all plots, the evidence subset has whitereplaced with orange and black replaced with blue. (a) The original digit t, the subset selected forevidence x, and the remaining ground truth query y. (b-f) Nine sample queries from method.
Figure 3: p(z|x) for the MNIST example in Figure 2. The contour plot (left) shows the truedistribution. The remaining plots show samples from each method overlaid on the true distribution.
Figure 4: (a) Pairwise C-ELBO comparison of different XCoder methods evaluated over the 50randomly generated evidence sets for MNIST. (b) Violin (distribution) plots of the Query MarginalLikelihood for the same 50 evidence sets from (a), with each likelihood expectation generated from500 samples. For both metrics, higher is better.
Figure 5: One conditional inference example for Anime. (a) The original image t, the subset selectedfor evidence x, and the remaining ground truth query y. (b-d) 25 sample queries from each methodwith the evidence superimposed on each image. (c,d) NF and HMC demonstrate poor coverage.
Figure 6: One conditional inference example for CelebA. (a) The original image t, the subset selectedfor evidence x, and the remaining ground truth query y. (b-d) 25 sample queries from each methodwith the evidence superimposed on each image. (d) HMC demonstrates poor coverage.
Figure 7: (left)(a,b) Pairwise C-ELBO comparison of GVI vs. FCN and (right)(a,b) Violin (distribu-tion) plots of the Query Marginal Likelihood for (a) Anime and (b) CelebA. Evaluation details matchthose of Fig. 4 except with 25 conditional inference queries. For both metrics, higher is better.
Figure 8: Comparison of different inference methods on modeling a Gaussian mixture modeldistribution. The true distribution samples are directly sampled from a Gaussian mixture model.
Figure 9: Comparison of different conditional inference methods include the Rezende method on theMNIST dataset. (a) Shows one intuitive example. The first row shows the evidence observed, and thefollowing rows show the mean of generated samples from the different algorithms. We note that withvery high evidence, the posterior becomes extremely concentrated, meaning the rejection rates forrejection sampling become impractical. (b) The mean squared error between query variables of theoriginal image and the generated samples of different algorithms. The results and standard deviationsat each observation percentage come from 50 independent randomly selected queries.
Figure 10: Boxplots of acceptance rate distribution of HMC for 30 Markov Chains vs different on(a) Anime and (b) CelebA. Each Markov chain ran for 10,000 burn-in samples with 10 leapfrog stepsper iteration.
Figure 11: Samples from each of the pre-trained VAE models.
Figure 12: Another conditional inference example on Anime dataset(a) Data(a) Data(b) GVI Samples(c) NF Samples(d) HMC SamplesFigure 13: Another conditional inference example on CelebA dataset.
Figure 13: Another conditional inference example on CelebA dataset.
