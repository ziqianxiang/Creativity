Figure 1: Performance comparison of Padam with different choices of p for training ResNet onCIFAR-10 / CIFAR-100 dataset.
Figure 2: Train loss and test error (top-1 error) of three CNN architectures on Cifar-10. In all cases,Padam achieves the fastest training procedure among all methods and generalizes slightly better thanSGD-momentum.
Figure 3: Top-1 and Top-5 error for VGGNet and ResNet on ImageNet dataset. In all cases, Padamachieves the fastest training speed and generalizes as well as SGD with momentum.
Figure 4: Train loss and test error (top-1 error) of three CNN architectures on CIFAR-100. In allcases, Padam achieves the fastest training procedure among all methods and generalizes as well asSGD with momentum.
Figure 5: Plots for kθt-θ0k2 against training epochs. Both experiments adopts VGGNet on CIFAR-10 and CIFAR-100 datasets.
