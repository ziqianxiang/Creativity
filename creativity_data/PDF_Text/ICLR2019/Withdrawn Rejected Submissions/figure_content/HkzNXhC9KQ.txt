Figure 1: Reconstructed images with different compression methods.
Figure 2: Rate-distortion tradeoff curves evaluated for different methods on the Kodak dataset. Thehorizontal axis represents bits-per-pixel (bpp) and the vertical axis represents the average multi-scale structural similarity (MS-SSIM) computed over RGB channels. The right two panels are themagnifications of the leftmost panel. Regarding the RD curves of Rippel & Bourdev (2017), wecarefully traced the RD curve from the figure of their paper, because the original paper did notprovide the exact values at each point. As for the RD curve of Johnston et al. (2017), we used thevalues provided by the authors via personal communication.
Figure 3: Overall architecture of the proposed model.
Figure 4:	Outline of ASAP coding for image compression.
Figure 5:	The grouping scheme for the coordinates of Z. This is an imitation of the procedure usedin Nakanishi et al. (2018)by recursively approximating p* (Z(AoIz(I:k-1)) With some probability distribution n(Z(k)|Z(1:k-1))with discrete support. For ease of notation, we would occasionally use ∏(k)(z(k)) to denote the samedistribution. In this model, we assume that each coordinate of Z(k) is approximately independentconditional to z(1:k-1). ThiS way, we can resort to the power of parallel computation and greatlyspeed up the algorithm. For more details of this procedure, please see Nakanishi et al. (2018). Forthe task of compressing other type of data, one can choose different type of partitioning that isnatural to the situation.
Figure 6: Detailed architecture of the quantizer. The solid line represents the operation subject toback propagation, and the dotted line represents the operation that is not subject to back propagation.
Figure 7: Rate-distortion tradeoff curve for the ASAP model trained with different objective func-tions. For the Multiplicative loss, Multiplicative rate-distortion trade-off function. For the additivecosts, we run experiments with few selected values of C and varied the choice of λ only. This isbecause the computational cost would explode if we are to do the parameter search of λ for largenumber of C . We should add, as a cautionary remark, that the results shown hereof are the resultsobtained with less number of iterations (0.1M) than the results in Figure 2 (0.3M).
Figure 8:	The heat map of μ, σ, q produced by a trained ASAP model for a Kodak image. Thestacked pair of images corresponds to the heat maps of a selected pair of channels. Notice that thenetwork is choosing larger value of q for a channel containing more information.
Figure 9:	Performances of various compression methods, evaluated in terms of PSNR.
Figure 10:	(a) Ablation study for the effect of adaptive quantization width. The adaptive quantiza-tion width works equally well with the best fixed quantization width, which was found through anextensive grid search. (b) The same ablation study conducted with a smaller version of the ASAPmodel (normal convolution layers in place of resblocks, smaller number of channels). The adaptivequantization width works better than the best fixed quantization width.
Figure 11:	Detail architecture of proposed model.
Figure 12: CNNs architecure for the map fromZ(1:kT) to μ(k), σ(k), and q(k). The map des-Batch NormalizationConvolution 1x1 (no bias)Batch NormalizationReluConvolution 3x3 (no bias)Batch NormalizationReluConvolution 1x1 (no bias)Batch NormalizationAddignated as”Function” stands for an element-wisenon-linear function, which in our caseis tanh for Figure 13: Detail architecture of one ResBlock.
Figure 14:	Construction of (μ(1), σ(1), q(I)). One set of parameters was created for each channel,and same parameter set was assigned to all the coordinates belonging to same channel.
Figure 15:	Rate-distortion tradeoff curves evaluated for different methods on resized RAISE-1K (Dang-Nguyen et al., 2015) dataset.
Figure 16: Images reconstructed with various coding methods.
Figure 17: Images reconstructed with various coding methods (con’d).
Figure 18: Images reconstructed with various coding methods (con’d).
Figure 19: Comparison of the visual results of the reconstruction for middle-high bpp range.
Figure 20: Comparison of the visual results of the reconstruction for middle-high bpp range (con’d).
Figure 21: Comparison of the visual results of the reconstruction for middle-high bpp range (con’d).
Figure 22: Comparison of the visual results of the reconstruction for middle-high bpp range (con’d).
Figure 23: Comparison of the visual results of the reconstruction for middle-high bpp range (con’d).
Figure 24: Comparison of the visual results of the reconstruction for middle-high bpp range (con’d).
