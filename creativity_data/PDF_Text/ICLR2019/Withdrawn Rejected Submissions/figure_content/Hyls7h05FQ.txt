Figure 1: Network struturewith an example of our gasimodel which learns a set ofglobal context embeddingsC and a set of sense embed-dings Sdifferentiability via a scaled variant of the Gumbel Softmax function (Section 3.2). This modelingcontribution—Scaled Gumbel Softmax—is critical for disambiguating senses.
Figure 2: As the scale factor β increases, the sense selection distribution for “bond” given examplesfrom SemCor 3.0 for synset “bond.n.02” becomes flatter, indicating less disambiguated sense vectors.
Figure 3: Our hard attention mechanismis approximated with Gumbel softmax onthe context-sense dot product c> Sk (EqUa-tion 13), whose mean and std plotted hereas a function of iteration. The shadowedarea shows that it has a smaller scale thanthe gumbel noise gk , such that gk , ratherthan the embeddings, dominates the senseattention.
Figure 4: t-SNE projections of nearest neighbors for “bond” by hard-attention models: 1) previousSOTA model MUSE (RL-based); 2) our proposed GASI-β. Trained on same dataset and vocabulary,both models learn three vectors per word. Here, words represent the i-th vector for word. Our GASI(right) learns three distinct senses of “bond” while Muse (left) learns overlapping senses.
Figure 5: Word intrusion task prompt10MSSG has two settings; we run human evaluation with mssg-30K which has higher correlation withMaxSimC on scws.
Figure 6: An example (target: bond) of thecontextual word sense selection task; eachoption contains top ten nearest neighbors ofa sense embedding learned by the model;senses in this example are from our GASI-β(1. 007; 2. chemical; 3. financial).
Figure 7: More distinct senses within each wordlead to higher inter-rater agreementaccuracy	# of questionsFigure 8: Higher inter-rater agreement corre-lates with higher human-model consistency.
Figure 8: Higher inter-rater agreement corre-lates with higher human-model consistency.
Figure 9: Histogram of number of senses left after post-training pruning for two models: GASI-0.4initialized with three senses and gasi-0.4 initialized with five senses. We rank the number of sensesof words by their frequency from high to low.
