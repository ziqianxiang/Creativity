Figure 1: The toy dataset.
Figure 2: Evolution of scores for each metric according to a given constant uncertainty estimatorFigure 3: Evolution of the MeRCI score for each method based on the chosen percentile. The redline marks the actual percentage of outliersexpected inliners increases. Besides, MeRCI is robust to outliers since it ranks the different uncer-tainty estimation techniques in the same order given sufficient data (here from the 74th percentile)and until the outliers upset the scores with too much weight in the final decision (92th percentile). Inpractice, the percentile should be chosen according to the number of supposed outliers. Yet it is alsonoticeable that knowing the exact amount of outliers is not strictly needed to obtain a meaningfulMeRCI score. Indeed, there is no brutal change around the correct outlier ratio (red line). Thereforein later experiments, we use the 95th percentile, giving some latitude to handle up to 5% of possibleoutliers.
Figure 3: Evolution of the MeRCI score for each method based on the chosen percentile. The redline marks the actual percentage of outliersexpected inliners increases. Besides, MeRCI is robust to outliers since it ranks the different uncer-tainty estimation techniques in the same order given sufficient data (here from the 74th percentile)and until the outliers upset the scores with too much weight in the final decision (92th percentile). Inpractice, the percentile should be chosen according to the number of supposed outliers. Yet it is alsonoticeable that knowing the exact amount of outliers is not strictly needed to obtain a meaningfulMeRCI score. Indeed, there is no brutal change around the correct outlier ratio (red line). Thereforein later experiments, we use the 95th percentile, giving some latitude to handle up to 5% of possibleoutliers.
Figure 4: A NYU Depth v2 test case. First row: the test image along with a predicted depth mapand the corresponding absolute errors. Remaining rows: predictive uncertainties.
Figure 5: Qualitative analysis of several NYU Depth v2 testset images (rows). Columns from left to right represent: input image, prediction, ground-truth, absolute error and MI, Bagging, MCD, ME, MN, LE uncertainty maps. For each example, the MeRCI scores are computed and the methodsranking are displayed under the uncertainty estimations.
Figure 6: Qualitative analysis of several NYU Depth v2 testset images (rows). Columns from left to right represent: input image, prediction, ground-truth, absolute error and MI, Bagging, MCD, ME, MN, LE uncertainty maps. For each example, the MeRCI scores are computed and the methodsranking are displayed under the uncertainty estimations.
