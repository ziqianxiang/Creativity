Figure 1: Potential outcomes of regression with negative examplesNow, let us consider negative examples in the ReNeg framework. For example, as shown in Figure1, if we perform a regression on positive and negative examples with more negative examples thanpositive in one state, we may wind up in a case where our loss is minimized by a prediction ofpositive or negative infinity, and thus our regression is “overwhelmed” by the negative examples.
Figure 2: Types of driving:swerving (left), lane change(right)3.3	“Backseat Driver” FeedbackBackseat Driver is the framework we use to compute and collectfeedback in the AV context. Our feedback includes much more information than just a reward (as isused in RL): we take our label to directly measure how “good” an action is relative to other possibleactions. We use this approach instead of labeling rewards for actions both because we found it aneasy way to label data with feedback, and because it contains more signal. How exactly to label thedata with feedback, however, is non-obvious. At first, we considered labeling using a slider from -1to 1. However, using a slider can be non-intuitive in many cases and there would be discontinuitiesin feedback you would want to give. For example, if the demonstrator is driving straight off theroad and then starts to turn left back onto the road, there would be a large discontinuity in the verynegative and then slightly positive feedback.
Figure 3:	Initial comparison of loss functions.
Figure 4:	Scalar loss function performance in-cluding negative examples vs. only positive ex-amplesnot be run in a simulator. This would work just as well in the real world. We only used a simulatorbecause it was all we had access to.) We first tested our PNet with the scalar loss, our PNet withthe exponential loss, and our FNet. We plotted their mean times over the eight runs with standarddeviation. See Figure 3 below. (All of these were on the default hyperparameters listed in theappendix, except for the exponential loss model, for which we set α to 0.1 since otherwise we couldnot get it to converge.) Based on the predicted angles, the FNet seemed to primarily predict feedbackbased on state, not angle; this makes sense given that the feedback in “bad” states is generally “bad”,except for the split second when the “good” action takes place.
Figure 5: Over 3 trainingruns, our scalar loss modelperformed over 1.5 times aswell as the behavioral cloningbenchmark, with significantlyless variance.
Figure 6: The scalar loss performed best with a learning rate of 1e-5.
Figure 7: The behavioral cloning loss performed best with a learning rate of 1e-5.
