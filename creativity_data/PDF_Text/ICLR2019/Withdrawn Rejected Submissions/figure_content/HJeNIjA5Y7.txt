Figure 1: From top to bottom: bad images, bad features, good images, good features. Features arefeature maps generated by one filter in the first convolutional layer of a pretrained CNN. Our methodassigns scores to automatically differentiate good and bad images.
Figure 2: Scores of images in CIFAR-10 (class 0) dataset, pre-trained 50 epochs on VGG16. Classtesting accuracy is 90.4%. Vertical axis in the left image represents labeling accuracy; verticalaxis in the right image represents proportion of images falls into a certain interval of image score.
Figure 3: Scores of images in CIFAR-10 (class 0) dataset, pre-trained 500 epochs on VGG16. Classtesting accuracy is 90.9%.
Figure 4: Scores of images in CIFAR-10 (class 0) dataset, pre-trained 10 epochs on VGG16. Classtesting accuracy is 83.7%.
Figure 5: Labeling accuracy of CIFAR-10 (class 0) dataset. The model is pre-trained on ResNet18for 100 epochs and then re-trained for another 100 epochs via semi-supervised learning (top) andsoftmax baseline training.
