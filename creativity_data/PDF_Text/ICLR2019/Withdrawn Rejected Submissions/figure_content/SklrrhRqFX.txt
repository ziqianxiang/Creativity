Figure 1: Two different environments with object dy-namics that obey the common laws of physics. Agentsthat have a knowledge of general physics will be able toadapt quickly to either environment.
Figure 2: Overview of the SpatialNet architecture. SpatialNet takes an RBG image as input and passes it intoencoder (E) consisting of two residual blocks to form an input encoding zt . zt is processed by a spatial memorymodule (Ïƒ) to obtain an output representation ot , which is used by the decoder (D) to predict the next frame.
Figure 3: Visualization of multi-step predictions of SpatialNet and RCNet. After 20 steps of self prediction,SpatialNet maintains the internal wall and all seven objects in the scene while RCNet (Oh et al., 2015) loses theinternal wall and 3 of the moving objects. ConvLSTM loses shape information and has less accurate dynamicsprediction. SpatialNet is the most consistent in obeying physical laws.
Figure 4: MSE loss When SpatialNet istrained on PhysShooter environment With orWithout PhysVideos initializationResults. We detail the performance of our approach com-pared to the baselines in Table 2 and shoW learning curvesin Figure 5. Quantitatively, We find large gains in per-formance in all three tasks in PhysWorld using IPA WithSpatialNet. We find that IPA With RCNet or ConvLSTMprovides less benefits, due to sloWer learning than Spa-tialNet. We also find PPO With value expansions alsoprovides slight gains, but significantly less than the gainsconferred by IPA. We find that I2A leads to no gains inperformance, likely due to a global encoding of a imagedestroying local dynamics information of objects. We alsofind that both ISP and JISP perform Worse than IPA ex-cept on PhysForage. On PhysForage, We find that JISPperforms better, likely due to increased policy capacitycompared to IPA.
Figure 5: Training curves for PPO and IPA agents on PhysWorld environments. In PhysGoal and PhysForage,IPA demonstrates better performance during later stages of training. In PhysShooter, IPA provides betterperformance early on because in this game planning is essential since a player can only fire one bullet at a time.
Figure 6: Future image prediction on PhysGoal (left) and PhysShooter (right). First image is current observation,the next three are predicted. SpatialNet is able to predict future dynamics of boxes and balls and anticipate agentmovement (PhysGoal) and agent shooting (PhysShooter).
Figure 7:	Visualization of SpatialNet hidden state on PhysVideos (left), PhysGoal (middle) and Atari DemonAt-tack (right). Hidden state has high activations for moving objects while background objects such as walls (left),red goals (middle) and platforms (right) are not attended to as much.
Figure 8:	Predictions of SpatialNet, RCNet on test data-set with objects twice as small and with twice themovement speed as trained on. All shown frames are one step predictions. SpatialNet is able to accuratelygeneralize to smaller, faster objects while RCNet is unable to generate the shapes of the smaller objects andsuffers from background degradation and ConvLSTM is unable to maintain shapes and dynamics.
Figure 9: Predictions of SpatialNet on input images of 168 x 168 when SpatialNet was trained on 84 x 84images. Prediction shown are 1 step future predictions. SpatialNet is able to maintain physical consistency in atlarge input sizes.
Figure 10:	Example agent game-play in each of the PhysWorld environments. In PhysGoal (left), the darkblue agent attempts to reach a red goal while avoiding moving objects. In PhysForage (middle), the dark blueagent attempts to gather light blue circles while avoiding squares. In PhysShooter (right), the dark blue agent isimmobile and chooses to fire bullet a green bullet at squares while avoiding circles.
Figure 11:	Plots of policy performance trained with either PPO or IPA on all Atari environments on 5 differentseeds. IPA sometimes leads to low learning early on the training due to rapid change of 3 predicted future frames.
Figure 12: Visualization of model future state prediction on 4 games in Atari (Frostbite - upper left, DemonAt-tack - lower left, Asteroids - upper right, FishingDerby - lower right). SpatialNet is able to predict fallingof bullets, the catching of fish, movement of asteroids, and the movement of tiles/future agent movement indifferent environments. First frame visualized is ground truth observation, next 3 frames are model future framepredictions.
