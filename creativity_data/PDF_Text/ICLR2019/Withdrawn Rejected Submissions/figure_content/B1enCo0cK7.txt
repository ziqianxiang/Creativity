Figure 1: (a) A perceptron network implementing the Boolean equality of x1 and x2 with addedredundancy x3 (see Section 3.1). (b) Shannon channel model of machine learning inspired by MacKay(2003). (see Section 3.2).
Figure 2: (a) A network trained on XOR cannot separate the two classes anymore perfectly once weadd 10% of noise to some of the inputs. (b) Suppression capability of adversarial attacks against theBoolean equality network.
Figure 3: Comparison of estimated model capacity (minimal number of parameters required) as afunction of allowed error under different attack algorithms on MNIST. The results are obtainedbased on the MLPs with and without non-linear activation functions (e.g. ReLU). Note that thenon-linear models can generalize the data better, so the e is fixed in a much smaller range.
Figure 4: Classification accuracy of different attack models as a function of training epoch. Adversar-ial examples are generated with different attack methods on both MNIST and CIFAR-10.
Figure 5: Classification accu-racy as a function of the JPEGcompression quality q. Theshadow curve represents theproperly scaled version of thetheoretical curve in FriedlandInspired by Theorem 1, we investigate the relation between feature et al. (2018).
Figure 6: Estimated entropy of the output layer under All-CNNs architecture with different robustness.
Figure 7: (a, b) Classification accuracy of benign and adversarial examples as a function of Signal-to-noise ratio (SNR).(c) Classification accuracy as a function of the JPEG compression quality q. Theshadow curve represents the properly scaled version of the theoretical curve in Friedland et al. (2018).
