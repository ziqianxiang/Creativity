Figure 1:	Scores assigned by four considered metrics for data with controllable amount of qualitydeterioration. Each row shows one metric and each column one task. Note that neither BLEU norself-BLEU scores capture semantic deterioration of the data. For BLEU higher is better. For othermetrics lower is better. We increase FDs obtained with UniSent and LM score embedding by a factorof 10 and decrease LM scores by the same factor for visualization purposes.
Figure 2:	Learning curves of three differently sized Language Models. For all metrics lower is better.
Figure 3: Distributions of FDs achievedby 30 best trials of three different modelsduring hyperparameter search.
Figure 4: Results of best models shown on two complementary axes. We show negative valuesof BLEU4 for visualization purposes. Note that according to BLEU scores three models havecomparable results, while LM scores show significantly better results for one model. We omitConv-Deconv and Conv-LSTM models from these Figures since they show results considerablyworse than those of other models.
Figure 5: Results of models on FD, Human evaluation and Unique 4-grams.
Figure 6: Schematic description of the three considered LeakGAN models. Solid and dashed arrowsrepresent weights learned in generator and discriminator phases respectively. hg and hd representhidden states of the generator and discriminator respectively. Note that hg is absent in LeakGAN-leakcase. xt and xt+1 are current and predicted tokens. D(x) is output of the discriminator.
