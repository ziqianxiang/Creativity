Figure 1: Illustration of the effect of our proposed regularizer. In this example, the goal is toclassify circles and crosses (top). Without use of regularizers (bottom left), the resultingembedding may considerably stretch the boundary regions (as illustrated by the irregularspacing between the tics). Forcing small variations of smoothness of label signals (bottomright), we ensure the topology is not dramatically changed in the boundary regions.
Figure 2: Sample of a Laplacian and squared Laplacian of similarity graphs in a trainedvanilla architecture. Examples of the batch have been ordered so that those belonging to asame class are consecutive. Dark values correspond to high similarity.
Figure 3: Evolution of smoothness of label signals as a function of layer depth, and forvarious regularizers and choice of m, the power of the Laplacian matrix.
Figure 4: Test set accuracy under Gaussian noise with varying signal-to-noise ratio.
Figure 5: Robustness against an adversary measured by the test set accuracy under FGSMattack in the left and center plots and by the mean L2 pixel distance needed to fool thenetwork using DeepFool on the right plot.
Figure 6: Test set accuracy under different types of implementation related noise.
Figure 7: Depiction of the studied networkStrided Conv layer, 4fConv layer, f,ided Conv layer, 2fConv layer, 2fConv layer, 2fConv layer, 2fConv layer, fConv layer, fConv layer, fConv layer, fGlobal Avg pooling, 8fStrided Conv layer, 8fLinear+ Softmax ：Conv layer, 8fConv layer, 8fConv layer, 8fConv layer, 4fConv layer, 4fConv layer, 4f
Figure 8:	Test set accuracy under Gaussian noise with varying Signal-to-Noise Ratio (SNR).
Figure 9:	Robustness against an adversary measured by the test set accuracy under FGSMattack in the left and center plots and by the mean L2 pixel distance needed to fool thenetwork using DeepFool on the right plot.
Figure 10:	Test set accuracy under different types of implementation related noise.
Figure 11: F (λx + (1 - λ)x0) for different methods.
