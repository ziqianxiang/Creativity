Figure 1: (a) Training accuracy for the targeted class (blue) approach 1.0, but (b) the red and greenare also assigned to blue, mistakenly. (c) No decision boundary exists.
Figure 2: (a) The original training dataset. To train a filter for the blue, we can (b) randomlyexchange the labels among the red and green points, as denoted by the edge color, or (c) add greenlylabeled red, redly labeled green, and double the blue to keep the sample density.
Figure 3: Training accuracy and decision boundary in two indenpendent filter trainings for the bluewith (a) preparation-1 and (b) preparation-2. Stable behavor in (b) implies that filter training canreflect innate pattern of the dataset.
Figure 4: Snapshots of decision boundaries during fitler training for the red. Misassigment in (b) iskept relatively low. Boundary for the red is purposefully expanded to increase accuracy.
Figure 5: (a) The output pattern that causes the superiority dilimma. Multiple check results withMR (blue) and PI (red) up to 10 fitler versions for (b) preparation-1 and (c) preparation-2, where theblack point denotes accuracy of the orginal network. (d) An instance of rights (circled) and wrongs(dotted) with respect to the original results: the improvements can be undertood from the view ofeconomic brain power deployment.
Figure 6: Upper: typical training accuracies for the specified class (blue) and for an alternative class(green), and misassignment (red) on CIFAR-10, with (a) preparation-1, (b) class-wise label permu-tation and preparation-1, and (c) class-wise label permutation and preparation-2. Down: mutiplecheck results with MR (blue) and PI (red), and the original test accuracy is marked for comparison.
Figure 7: Mutiple check results for reduced CIFAR-10 with (a) a single partition (b) full partitionsand the class-wise label permutation, and (c) full partitions without the label permutation.
Figure 8: Results for the MNIST dataset with preparation-1 and the class-wise label permutation.
