Figure 1: Language Pairs and their GHdistanceChazal et al. (2009) showed that the Gromov-Hausdorff distance can be lower bounded by the Bot-tleneck Distance between the Persistence Diagrams of the Vietoris-Rips Filtration of the two spaces.
Figure 2: A toy dataset demonstrating the shortcomings of unsupervised distribution matching. Fig.
Figure 3: Training Stability of different language pairs4.3 B enefits of BLISSLanguages with high GH distance BLISS particularly shines over its supervised counterpart whenthe two embedding spaces are significantly different and the orthogonality constraint is violated.
Figure 4: Fraction of errors coming from polysemy in the source/target side and antonymy, for thelanguage pairs en-zh, en-it, en-es and en-frWords that occur in common contexts: Words that occur in numerous contexts often have poorword embeddings, since a single embedding canâ€™t capture polysemy. Consequently, multiple suchword embeddings that are frequent and have poor representations often get incorrectly translated toeach other. Some examples include proper nouns and numbersWe quantitatively estimate the fraction of errors due to these reasons using WordNet synsets. Given2 synsets, WordNet provides a score denoting how similar two word senses are, based on the shortestpath that connects the senses in the is-a (hypernym/hypnoym) taxonomy. The score is in the range0 to 1. A score of 1 represents identity i.e. comparing a sense with itself will return 1.
