Figure 1: The stethoscope framework. The main network (blue), comprised of an encoder and adecoder, is trained for global stability prediction of block towers. The stethoscope (orange), a twolayered perceptron, is trained to predict a nuisance parameter (local stability) where the input is Z, alearned feature from an arbitrary layer of the main network. The stethoscope loss is back-propagatedwith weighting factor λ to the main network. The value of λ determines whether the stethoscopeoperates in analytic (λ = 0), auxiliary (λ > 0) or adversarial manner (λ < 0).
Figure 2: We have four qualitative scenarios: (A) Globally stable towers which also do not exhibit anylocal stability violation. (B) Towers without any local instability which are globally unstable becauseof the skew. (C) Towers in which one local stability violation is counterbalanced by blocks above.
Figure 3:	The influence of local instability on global stability prediction. In setup (a) we train on all 4tower categories (indicated by green frames). Global stability prediction accuracies on per-categorytest splits are reported in the bottom right grey boxes. In (b) we train solely on easy scenarios (A &D) where global and local stability are positively correlated. In (c) we only present hard scenariosduring training featuring a negative correlation between global and local stability. The performancedifferences clearly show that local stability influences the network’s prediction for global stability.
Figure 4:	Analysis of the prediction performance throughout the Inception-v4 network trained onpredicting global stability. We report average performances on balanced test data after 50 epochs ofstethoscope training. All stethoscopes have been attached to the respective activation tensors3withsparse connection matrices as described in Section 3.
Figure 5: Performance gains by promoting complementary feature extraction with auxiliary stetho-scopes. The main network is trained on binary global stability labels while the stethoscope is trainedon more fine grained labels - origin of global stability (n-way). The network was trained on hardscenarios only but evaluated on all. The dashed lines represent baselines for λ “ 0.
Figure 6: Successful debiasing by suppressing a nuisance factor with adversarial training whileauxiliary training worsens the bias. The main network is trained on global stability while thesupplementary task is to predict presence of local instabilities. Training data for global stability onlycomprises easy scenarios while training data for the supplementary task comprises both easy andhard scenarios. (a) & (b) Green squares and red triangles show accuracies of the main network whenpredicting global stability of block towers for easy scenarios and hard scenarios, respectively. Orangecircles depict the performance of the stethoscope on the task of local stability. Blue circles representthe Pearson Correlation Coefficient of predicted global stability and ground truth local stability whichgives an indication of how much the network follows visual cues. (c) Images show hard scenarioswhich the algorithm classified correctly only when adversarial training was used.
Figure 7: Stethoscope recovery after freezing theadversarially trained main network.
Figure 8: Setup of the toy experiments using the MNIST dataset with artificial hints. In (a), the hintsare fed to the main network via a separate input and both input streams are encoded separately byneural networks. The stethoscope only sees the output of the hint encoder hθenc2 while the decoderhθdec, which is trained on digit classification, sees the output of both encoders. In (b), the hints areincorporated as pixel modifications into the main images. The encoder hθenc transforms the input intoa latent representation Z which is then accessed by both the stethoscope hSψ and the decoder hθdec .
Figure 9: Influence of adversarial training on classifier performance for toy experiment variant 1described in Figure 8a. Each curve represents the results for different hint qualities hq . The bold linesindicate the mean of 100 runs and the shaded areas mark the student-t 1 σ confidence intervals. In (a)the network is evaluated against the ground truth. In (b), the output of the network is compared tothe hint labels during test time. Hence, a high accuracy in (b) shows strong overfitting while a highaccuracy in (a) shows that the network learned the actual task of classifying digits from images.
Figure 10: Influence of adversarial training on classifier performance for the second MNIST experi-ment. The adversarial training is less effective as both the stethoscope and the main network directlyaccess a single encoding. High adversarial weights can strongly degrade performance on the maintask as a trivial solution would be to suppress all information about the input. Each curve representsthe results for different hint qualities hq . The bold lines indicate the mean of 20 runs and the shadedareas mark the student-t 1 σ confidence intervals.
