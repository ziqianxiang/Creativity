Figure 1: Qualitative Results: Visualization of different target functions (Sec. 3.3). T + generateshigh reward and T - low reward states; T ± generates states in which one action is highly beneficialand another is bad.
Figure 2: Seaquest with ACKTR. Visualization results for a network trained with ACKTR onSeaquest. The objective is T ± indicating situations that can be rewarding but also have a low scoringoutcome. The generated states show low oxygen or close proximity to enemies.
Figure 3: Weight Visualization. We visualize the weighting (second row) of the reconstruction lossfrom Equation 2 for eight randomly drawn samples (first row) of the dataset. Most weight lies on theplayer’s submarine and close enemies, supporting their importance for the decision making.
Figure 4: Comparison with activation maximization. The visual features learned by the agents arenot complex enough to reconstruct typical frames from the game via activation maximization. Thisproblem is mitigated in our method by learning a low-dimensional embedding of games states first.
Figure 5: Conv1 Weights DQN. We display the weights of the first layer of DQNs trained on severalAtari games. Columns represent the 32 different 8 × 8 filters, while the four rows correspond the tofour frames that are stacked as an input for the network. The vertically stacked weights represent thetemporal component with the current frame at the bottom and frame t - 3 at the top.
Figure 6: Driving simulator. We show 16 samples for the T - objective of an agent trained in thereasonable pedestrians environment. From these samples one can infer that the agent is aware oftraffic lights (red) and other cars (blue) but has very likely not understood the severity of hittingpedestrians (yellow). Deploying this agent in the distracted pedestrians environment shows that theagent indeed collides with people that cross the road in front of the agent.
Figure 7: Air Raid. Target function: S+ .
Figure 8: Alien. Target function: right.
Figure 9: Amidar. Target function: up.
Figure 10: Assault. Target function: S - .
Figure 11: Asterix. Target function: T-.
Figure 12: Asteroids. Target function: up-fire.
Figure 13: Atlantis. Target function: T+ .
Figure 14: Bank Heist. Target function: T+ .
Figure 15: Battlezone. Target function: T-.
Figure 16: Beamrider. Target function: T+ .
Figure 17: Berzerk. Target function: S+ .
Figure 18: Bowling. Target function: S+ .
Figure 19: Boxing. Target function: S+ .
Figure 20: Breakout. Target function: T-.
Figure 21: Breakout. Target function: Left.
Figure 22: Carnival. Target function: right.
Figure 23: Centipede. Target function: T±.
Figure 24: Chopper Command. Target function: S+ .
Figure 25: Crazy Climber. Target function: T-.
Figure 26: Demon Attack. Target function: T + .
Figure 27: Elevator Action. Target function: no-op.
Figure 28: Enduro. Target function: S+ .
Figure 29: Freeway. Target function: T+.
Figure 30: Frostbite. Target function: no-op.
Figure 31: Gopher. Target function: S-.
Figure 32: Gravitar. Target function: T±.
Figure 33: Hero. Target function: S+ .
Figure 34: JamesBond. Target function: S+.
Figure 35: Kangaroo. Target function: S-.
Figure 36: Krull. Target function: fire.
Figure 37: Kung Fu Master. Target function: up.
Figure 38: Montezuma’s Revenge. Target function: T-.
Figure 39: Ms. Pacman. Target function: no-op.
Figure 40: Name This Game. Target function: T ± .
Figure 41: Phoenix. Target function: T ± .
Figure 42: Pong. Target function: no-op.
Figure 43: Pooyan. Target function: S-.
Figure 44: Q-Bert. Target function: left.
Figure 45: River Raid. Target function: T + .
Figure 46: Space Invaders. Target function: left.
Figure 47: Star Gunner. Target function: T ± .
Figure 48: Tutankham. Target function: no-op.
Figure 49: Venture. Target function: S+ .
Figure 50: Video Pinball. Target function: T-.
Figure 51: Wizard Of Wor. Target function: left.
