Figure 1: The PHASE framework, which consists of embedding learning, prediction, interpretation,and transference. The checkered patterns denote that a model is being trained in the correspondingstage, whereas solid colors denote fixed WeightS/models. The red side of the LSTM denotes thehidden layer We will use to generate embeddings. In (c), the size of the black circles on the leftrepresent the feature attributions being assigned to the original input features. The signals andthe outputs of the LSTMs are vectors. Multiple connections into a single XGB model are simplyconcatenated. More details on the experimental setup can be found in Sections 4.1 and 6.1.
Figure 2:	GBMs With different embeddings of physiological signals. Gray lines signify insignificantdifferences (all others pairs are significant at a p-value of 0.01) based on one hundred bootstrapsof the test set With adjusted pairWise comparisons via ANOVA With Tukey’s HSD test. For all,We utilize the 15 features above the line in both hospitals (Figure 5). Notation described in Table2, where Minh represents PHASE. Note that *[SaO2] denotes that we have a Raw, EMA, or Minembedding of SaO2 and *[All Signals]+Static denotes a Raw, EMA, or Min embedding of all thesignals plus static variables. More details about the setup for this experiment in Section 6.3, withp-values of models 10, 12, and 14 reported in Tables 7 and 8.
Figure 3:	GBMs with different embeddings of physiological signals. Gray lines signify insignificantdifferences (all others are significant at a p-value of 0.01) based on one hundred bootstraps of thetest set with adjusted pairwise comparisons via ANOVA with Tukey’s HSD test. Notation describedin Table 2. The PhysioNet embeddings borrow signals from the target hospital’s embeddings so*[SaO2] + MinT[Non SaO2] + Static denotes that We have a MinP embedding of SaO2, a MinTembedding of the remaining 14 variables, where T is the target hospital, and static variables. Moredetails about the setup for this experiment in Section 6.4, With p-values reported in Tables 9 and 10.
Figure 4: Ablation test on the top 1000 positive labels, sorted by the probability prediction of thefinal model. We ”remove” the features (by imputing the mean of the last two minutes) according toShapley values or a random ordering and then predict the probability of hypoxemia on the entirety ofour test set. We obtain Shapley values for both models with a fixed background set of 100 samples.
Figure 6:	Differences between hospitals 0/1’s distributions. One of the biggest difference is in sex.
Figure 7:	Distributions for hospital P. ≈ 44% of patients are female. The skewed distributions aredue to many newborn patients included in the dataset.
Figure 8:	Model setup for Figure 2. Showcasing most multivariate models in Figure 2, apart fromthe fine tuned LSTMs (14), which were trained identically but were initialized with the non-targethospital’s corresponding LSTM. This figure is for hypoxemia, but hypocapnia and hypotension par-allel this setup. Not counting fine tuned LSTMs, there are a total of 60 LSTMs: 30 Auto modelsfor hospitals 0/1 and 30 Min models for hospitals 0/1. LSTM/XGB architecture and hyperparam-eters are consistent across models and can be found in Section 6.2. The signals and the outputsof the LSTMs are vectors. Multiple connections into a single model are simply concatenated. Forall LSTMs, they consist of two layers each with 200 LSTM cells, trained in identical manners, asdescribed in Section 6.2. For XGB, the training is detailed in Section 6.2 as well. The univariatepredictions made in Figure 2 are similarly obtained, but only utilize the single feature used to obtainthe final prediction. Here,“Hypoxemia" means: "IS min(SaO2(t+ι,... ,t+5)) ≤ 92?”.
Figure 9:	GBMs with different embeddings of physiological signals. Gray lines signify insignificantdifferences (all others pairs are significant at a p-value of 0.01) based on one hundred bootstrapsof the test set with adjusted pairwise comparisons via ANOVA with Tukey’s HSD test. For all, weutilize the 15 features above the line in both hospitals (Figure 5). Notation described in Table 2,where Minh represents PHASE. Note that *[All Signals] - *[SaO2]+Static denotes a Raw, EMA, orMin embedding of all the signals except for SaO2 plus static variables.
Figure 10: Model setup for Figure 3. Showcasing what models are being used for the the transfer-ence experiment in Figure 3. LSTM/XGB architecture and hyperparameters are consistent acrossmodels and can be found in Section 6.2. The signals and the outputs of the LSTMs are vectors.
Figure 11: Model setup for Figure 4. Showcasing what models are being used to evaluate in-terpretability. LSTM/XGB architecture and hyperparameters are consistent across models andcan be found in Section 6.2. The signals and the outputs of the LSTMs are vectors. Multipleconnections into a single XGB model are simply concatenated. Here, ”Hypoxemia” means: ”Ismin(SaO2(t+ι,…，t+5)) ≤ 92?”. Of special note, the MLP is trained identically to the HyPox mod-els. The architecture is a single layer with 100 nodes with a relu activation connected densely intoa sigmoid output node. The MLP is trained until convergence by upsampling the number of posi-tive samples to match the negative samples for each batch. The attributions for LSTM→MLP arecomputed via Deep SHAP and the attributions for LSTM→XGB are computed via Deep SHAPCombined with Independent Tree SHAP (our novel method). Both methods use a fixed backgroundset of 100 randomly sampled points from the test set.
Figure 12: Randomly sampled feature attributions. Local feature attribution plots for two stackedmodels: 1. LSTM→MLP and 2. LSTM→XGB. Here we present fifteen randomly sampled hypox-emia examples.
Figure 13: True negative feature attributions. Local feature attribution plots for two stacked models:1. LSTM→MLP and 2. LSTM→XGB. Here we present the nine”least probable” positively labelledhypoxemia examples. In order to obtain this set, we took the intersection of the top 1000 negativelylabelled examples from both models to get a set of 97 samples and randomly sample nine samples.
Figure 14: True positive feature attributions. Local feature attribution plots for two stacked models:1. LSTM→MLP and 2. LSTM→XGB. Here we present the nine”most probable” positively labelledhypoxemia examples. In order to obtain this set, we took the intersection of the top 100 positivelylabelled examples from both models to get a set of 40 samples and randomly sample nine samples.
