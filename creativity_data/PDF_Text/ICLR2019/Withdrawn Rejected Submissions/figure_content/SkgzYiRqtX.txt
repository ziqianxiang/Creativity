Figure 1: An example of relation extraction from plain text. Given a sentence with several entitiesmarked, we model the interaction between these entities by generating the weights of graph neuralnetworks. Modeling the relationship between “Leon” and “English" as well as “Luc Besson" helpsdiscover the relationship between “Luc Besson” and “English”.
Figure 2: Overall architecture: the encoding module takes a sequence of vector representations asinputs, and output a transition matrix as output; the propagation module propagates the hidden statesfrom nodes to its neighbours with the generated transition matrix; the classification module providestask-related predictions according to nodes representations.
Figure 3: The aggregated precision-recall curves of our models with different number of layers ondistantly labeled test set (left) and dense distantly labeled test set (right). We also add Context AwareRE for comparison.
