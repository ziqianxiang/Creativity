Figure 1: VQA with out-of-vocabulary answers. Given a set of labels in visual data A and a setof answers in VQA training set B, we evaluate the model on VQA test set with answers a âˆˆ A - B.
Figure 2: Overview of the proposed algorithm. (Left) Unsupervised task discovery learns a taskconditional visual classifier by leveraging off-the-shelf visual data without task specification t. It alsodefines a task distribution pT (t|a, r) using linguistic knowledge sources, where stochastic samplingassociates a task specification t with a visual annotation (a, r). (Center) A visual annotation witha task specification, denoted by (a, r, t), is employed to pretrain a task conditional visual classifier.
Figure 3: Illustration of Wordnet and extracted answer set. (Left) A subgraph of the Word-net (Fellbaum, 1998). Complex hierarchy of words reveals the diverse categorization of each words.
Figure 4: Model comparisons. Exploiting external data with unsupervised task discovery boostsperformance of the proposed model and separable classifier significantly. However, separableclassifier showed limited performance gain on attribute answers, which have significant variationsdepending on tasks.
Figure 5: Data comparisons. Using visual description and Wordnet shows different generalizationcharacteristics and combining them brings additional improvement.
Figure 6: Complementary characteristics of visual description and Wordnet. Wordnet showsadvantage on answers related to specific categorizations such as species of a bird (e.g. goose andpigeon) and visual description is more effective on answers about interactions (e.g. holding).
Figure 7: Out-of-vocabulary answers with diverse types of concepts. Green and red color denotecorrect and wrong answers respectively. Asterisk(*) denotes answers appearing in the training set.
Figure 8: Combining knowledge from VQA and external visual data. Evaluation results ona test set containing both out-of-vocabulary answers and trained answers. The proposed modelshowed relatively lower performance on trained answers but significantly better performance onout-of-vocabulary answers. In total, the proposed model showed the best performance.
Figure 9: Out-of-vocabulary answers with diverse types of concepts. Green and red color denotescorrect and wrong answers respectively. Asterisk(*) denotes answers appearing in the training set.
Figure 10: Image and question dependent answering. Green and red color denote correct andwrong answers respectively. Asterisk(*) denotes answers appearing in the training set. Answerswithout asterisks are out-of-vocabulary answers.
