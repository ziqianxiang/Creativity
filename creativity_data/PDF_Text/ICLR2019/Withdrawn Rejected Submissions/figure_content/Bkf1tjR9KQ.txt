Figure 1: Overview of Dvolver Search Process. Acontroller generates a candidate architecture which istrained to convergence by the evaluation engine. Othercriteria to optimize are evaluated while the network istraining. Resulting metrics are fed back to the con-troller. At each iteration, the controller keeps track ofthe best performing architectures.
Figure 2: Scalable architectures for image classification consist of two repeated motifs termed Normal Cell andReduction Cell. This diagram highlights the model architecture for CIFAR-10 and ImageNet. The choice for thenumber of times the Normal Cells that gets stacked between Reduction Cells, N, can vary in our experiments.
Figure 3: 3(a) shows the evolution of the hypervolume during the search process until it stops increasing.
Figure 4: Dvolver-A, B and C cells (best viewed in color). Blue boxes are the output of the 5 blocks. Eachblock has 2 incoming arrows representing the 2 operations in the block. Labels on arrows describe the specificoperation performed. The origin of the arrow is the input of for the operation. Green boxes represent theprevious and previous previous cells and the yellow box represents the final depth concatenation at the end ofthe cell.
Figure 5: Accuracy versus computational demand (left) and number of parameters (right) for Dvolver andstate-of-the-art architectures for mobile devices on ImageNet. Computational demand is measured in the num-ber of floating-point multiply-add operations to process a single image. Labels on the figures for Dvolver areof the form Family, N and F. For example Dvolver-A with N=3 and F=48 is noted A3-48.
Figure 6: General Genetic AlgorithmIndividuals are points in the search space and genetic operators modify their vectorial representation.
Figure 7:	Crossover and mutation genetic operatorsThe exploration of new individuals in the search space versus the exploitation of the best candidatesare governed by the two parameters μcs and μmut, and are the unique two parameters for thegenetic algorithm. Large value of μcs allows to take larger steps across the problem domain,allowing the escape of local optimum. μmut's value allows for small variations. It is possible toincrease that value at the beginning of the search process to favor exploration then annealing thatvalue as the population converge to a global optimum.
Figure 8:	Crowding distanceA.3 Hypervolume indicatorWith Multi-objective Optimization, an algorithm produces a set of points in the objective space asan estimation of the Pareto front. A quantitative measure is desired to estimate the closeness of theestimated data points to the true Pareto front. One of such measures is the hypervolume indicator,which gives the hypervolume between the estimated Pareto front (P) and a reference point (R).
