Figure 1: Search-guided training: the solid and dashed lines show a schematic landscape of energyand reward functions, respectively. The blue circles indexed by yi represent the gradient-descent in-ference trajectory with five iterations over the energy function. Dashed arrows represent the mappingbetween the energy and reward functions, while the solid arrows show the direction of updates.
Figure 2: The parameterization of energy function using for citation-field extraction.
Figure 3: The input image (left) and the parse that generate the input input (right). The first twoparameters of each shape shows its center location and the third parameter is its scale. A validprogram sequence can be generated by post order traversal of the binary shape parse.
Figure 4: The parameterization of energy function for shape parsing. The network has two parts:first takes the probability distribution over the output program and outputs a fixed dimension embed-ding, and the second part takes the binary images as input, which is convolved to give fixed lengthembedding. The two embeddings are concatenated and passed through an MLP to output energyfunction.
Figure 5: The number of informative constraints (pairs with different reward rankings) that search-guided training found for batches of 50 randomly selected training points in the first 50 trainingsteps. SG-SPEN generates at-most one informative constraint for each example.
