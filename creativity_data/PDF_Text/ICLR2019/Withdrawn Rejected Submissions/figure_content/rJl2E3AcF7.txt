Figure 1: Overview of DS-Softmax. Initial model is similar to sparsly gating mixture of expertsmodel. After pruning, each expert will have partial outputs vn instead of |V |.
Figure 2: The mitosis training scheme: the sparsity is inherited when parent experts produce offspring,reducing the memory requirements for training with more experts.
Figure 3: (a) Illustration of data generation. (b) and (c) Results on discovered sparse experts on10x10 and 100x100 datasets. The x-axis indicates sub class and y-axis shows the selected expertfor handling this class. The order of x-axis is arranged through their super class information. Forexample, each 10 sub classes are belonged to one super class in (b).
Figure 4: Ablation analysis of each loss component by removing it. (a), (b) and (c) illustrate themodel trained without group lasso, expert level group lasso and balancing factor respectively.
Figure 5: (a) Correlation between uncertainty and training time. We denote uncertainty by theproportion of high gating activation, which is higher than 0.9. (b) Correlation between word frequencyand redundancy. Redundancy means the number of appearance for one word in experts. Darker colorindicates higher density.
