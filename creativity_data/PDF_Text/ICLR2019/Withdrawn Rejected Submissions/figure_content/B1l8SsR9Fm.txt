Figure 1: Learning compressed data set E? and optimal hypothesis h? with a dataset of size N = 100. Functionf ∈ Poly(10) + noise. Selected samples in E?(c D) are denoted by circles. In the example of (a), f and h?are visually indistinguishable. The higher the compression ratios the higher the generalization error. e(E? , T)behaves like a double exponential function of CR. For a wide range of CR values there is almost no losscompared to e(D, T).
Figure 2: Learning compressed data set E? and optimal hypothesis h? with a dataset of size N = 100. Functionf ∈ Poly(15) + noise. The higher the compression ratios the higher the generalization error. The doubleexponential behavior of CR, observed also in figure 1(b), is visible in (b).
