Figure 1: Illustration of our probing-based interactive agent modeling. Here, the demonstrator triesto go from the bottom-right corner to the upper part of the room. The passive learner (left) onlyobserves one path in the fixed environment while the probing learner (right) removes a wall block tocreate a new gap so that the demonstrator will change its path accordingly.
Figure 2: An overview of our model. Architecture details are in Appendix C. Note that the modulesdo not share weights, and the dashed line indicates that it is a feed forward only path (no backpropagation through this path to update the mind model).
Figure 3: Illustration of the evaluated tasks.
Figure 4: Action prediction accuracies in novel testing settings over numbers of training iterations.
Figure 5: Action prediction accuracies in novel testing settings over numbers of training iterationswith 10% random actions.
Figure 6: The average success rate of the demonstrator within the given time limit.
Figure 7: The learning curves of the col- Figure 8: The learning curves of the com-laborative task (reward is rescaled). petitive task (reward is rescaled).
Figure 9: Mean and standard deviation of multiple runs in Maze Navigation.
Figure 10: t-SNE embedding of mt .
Figure 11: Correlation between the change in mt and the change in policy in testing settings (r isPearson correlation coefficient).
Figure 12: The attention-based fusion module.
Figure 13:	The training setting and examples of testing settings for Passing.
Figure 14:	The training setting and examples of testing settings for Maze Navigation.
Figure 15:	The training setting and examples of testing settings for Construction.
Figure 16:	The network architecture of the 2-LSTM baseline.
