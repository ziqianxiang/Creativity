Figure 1: WIRGAT. The intermediate representations for node i (left red rectangle) arecombined with the intermediate representations for nodes in its neighborhood (blue rectangles)under each relation r, to form each logit Ei(,rj) . A softmax is taken over each logit matrixfor each relation type to form the attention coefficients αi(,rj) . These attention coefficientsconstruct a weighted sum over the nodes in the neighborhood for each relation (blackrectangle). These are then aggregated and passed through a nonlinearity to produce theupdated representation for node i (right red rectangle).
Figure 2: ARGAT. The logits are produced identically to those in Figure 1. A softmax istaken across all logits independent of relation type to form the attention coefficients αi(,rj) .
Figure 3: (a) The network architecture used for node classification on AIFB and MUTAG.
Figure 4: (a) and (b): Blue Baseline entity classification accuracy (mean and standarddeviation over 10 seeds) for FEAT (Paulheim and Fumkranz, 2012), WL (ShervashidZeet al., 2011; de Vries and de Rooij, 2015), RDF2Vec (Ristoski and Paulheim, 2016) andRGCN (Schlichtkrull et al., 2018), and (mean and standard deviation over 200 runs) forour implementation of RGCN. Yellow Entity classification accuracy (mean and standarddeviation over 200 seeds) for additive attention (this work). Red Entity classification accuracy(mean and standard deviation over 200 seeds) for multiplicative attention (this work). Testperformance is reported on the splits provided in Ristoski and Paulheim (2016). (c): BlueBaseline graph classification mean Receiver Operating Characteristic (ROC) AUC acrossall 12 tasks (mean and standard deviation over 3 splits) for Multitask (Ramsundar et al.,2015), Bypass (Wu et al., 2018), Weave (Kearnes et al., 2016), RGCN (Altae-Tran et al.,2016), and (mean and standard deviation over 3 splits, 2 seeds per split) our implementationof RGCN. Yellow Additive attention graph classification mean ROC-AUC (mean andstandard deviation over 200 seeds) across all 12 tasks (this work). Red Multiplicativeattention graph classification mean ROC-AUC (mean and standard deviation over 200seeds) across all 12 tasks (this work). All raw values are given in Table 2.
Figure 5: CDFs for all models on a) AIFB, b) MUTAG and c) TOX21. Green linescorrespond to our implementation of RGCN, blue lines correspond to ARGAT, and orangelines correspond to WIRGAT. Solid lines correspond to additive attention (and RGCN),whereas dashed lines correspond to multiplicative attention. A lower CDF value is better inthe sense that a greater proportion of models of achieve a higher value of that metric.
Figure 6:	The p-values for Mann-Whitney U test with alternative hypothesis H1 of Model Aoutperforming Model B on AIFB.
Figure 7:	The p-values for Mann-Whitney U test with alternative hypothesis H1 of Model Aoutperforming Model B on MUTAG.
Figure 8:	The p-values for Mann-Whitney U test with alternative hypothesis H1 of Model Aoutperforming Model B on TOX21.
