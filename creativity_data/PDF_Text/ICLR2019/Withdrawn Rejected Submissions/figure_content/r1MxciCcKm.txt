Figure 1: A unified formulation of different learning algorithms. Each algorithm is a special instanceof the general ERPO framework taking certain specifications of the hyperparameters (R,α,β) (Eq.1).
Figure 2: Effective exploration space of different algorithms. (a): The exploration space of MLE isexactly the set of training examples. (b): RAML and Data Noising use smooth rewards and allowlarger exploration space surrounding the training examples. (c): Common policy optimization suchas SPG basically allows the whole exploration space.
Figure 3: Convergence curve of learning al-gorithms in the task of machine translation.
Figure 4: Improvement on the ROUGE-L met-ric in comparison to MLE (e.g., RAML im-proves ROUGE-L by 0.17).
Figure 5: Convergence curve of learning algorithms in the task of machine translation with a dropoutrate of 0.3. The horizontal dashed lines indicate the test-set results of each of the algorithms (reportedin Table 3) picked according to the validation set performance.
