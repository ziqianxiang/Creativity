Figure 1: Compositional GAN training model both for paired and unpaired training data. The yellowbox refers to the RAFN step for synthesizing a new viewpoint of the first object given the foregroundmask of the second one, which will be applied only during training with paired data. The orange boxrepresents the process of inpainting the input segmentations for training with unpaired data. Rest ofthe model would be similar for the paired and unpaired cases which includes the STN followed bythe self-consistent composition-decomposition network.
Figure 2: Test results on the chair-table (A) and basket-bottle (B) composition tasks trained witheither paired or unpaired data. “NN” stands for the nearest neighbor image in the paired trainingset, and “NoInpaint” shows the results of the unpaired model without the inpainting network. Inboth paired and unpaired cases, ^before and ^after show outputs of the generator before and after theinference refinement network, respectively. Also, ^Sfter represents summation of masked transposedinputs after the refinement step.
Figure 3: Test examples for the face-sunglasses composition task. Top two rows: input sunglassesand face images; 3rd and 4th rows: the output of our compositional GAN for the paired and unpairedmodels, respectively; Last row: images generated by the ST-GAN (Lin et al., 2018) model.
Figure 4: Relative Appearance Flow Network: Input is an image of a chair with 3 RGB channelsconcatenated channel-wise with the table foreground mask. Output is the appearance flow forsynthesizing a new viewpoint of the chair. All layers are convolutional.
Figure 5: Relative Spatial Transformer Network: Input is an image of a chair with 3 RGB channelsconcatenated channel-wise with the table RGB image. Output is two transformed images each with 3RGB channels.
Figure 6: Test results on the chair-table composition task trained with either paired or unpaired data.
Figure 7: Failure test cases for both the paired and unpaired models on the chair-table compositiontask.
Figure 8: More test results on the basket-bottle composition task trained with either paired or unpaireddata. “NN” stands for the nearest neighbor image in the paired training set, and “NoInpaint” showsthe results of the unpaired model without the inpainting network. In both paired and unpaired cases,Cbefore and ^after show outputs of the generator before and after the inference refinement network,respectively. Also, ^after represents summation of masked transposed inputs after the refinement step.
Figure 9: (a) Ablation Study: Output of our model without the component specified on top of eachcolumn. Input is the channel-wise concatenation of the bottle and basket shown in the first twocolumns, (b) Baselines: As the input (9th column), each bottle is added to the basket after beingscaled and translated with constant parameters. Pix2Pix and CycleGAN outputs are shown on theright.
Figure 10: Test examples for the face-sunglasses composition task. First two columns show inputsunglasses and face images, 3rd and 4th columns show the output of our compositional GAN for thepaired and unpaired models, respectively. Last column shows images generated by the ST-GAN (Linet al., 2018) model.
