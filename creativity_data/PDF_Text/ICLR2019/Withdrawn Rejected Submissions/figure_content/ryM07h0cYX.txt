Figure 1: Faster R-CNN pipeline represented as a computation graph in testing time. Dotted linesindicate non-differentiabilities — either the edge itself is non-differentiable or the gradient passingon the edge is intentionally ignored. In testing time, network parameters θi are kept frozen. Notingthat -mAP is the real criterion measuring the performance of this pipeline.
Figure 2: Traditional Faster R-CNN pipeline represented as a computation graph in training timecompromised to non-differentiabilities. Nodes in orange color indicate learning models. Lacking theability of optimizing the real criterion -mAP, isolated RPN and R-CNN losses are being optimizedinstead.
Figure 3: Reinforced Faster R-CNN pipeline represented as a SCG in training time, where π0 andπ1 are the augmented stochastic nodes. This pipeline optimizes directly on the real criterion -mAP,and behaves the same way in both training and testing time, except that in testing time sampling isactually not needed, and parameters are kept frozen.
Figure 4: Reinforced pipeline optimization (RPO) with baseline. Note that the original pipeline mayhave some additional differentiable costs (line 7), which are optimized simultaneously (line 11). Theoriginal pipeline is assumed to only have deterministic nodes. Ifit in fact has some stochastic nodes,only slight modifications are needed for extension.
Figure 5: Experimental results shown as mAP values on PASCAL VOC 2007 validation set whiletraining on training set. The results are averaged over 5 runs of RPO with and without baseline onFaster R-CNN with various backbone networks. The x- and y- axes are number of epochs and mAPvalue respectively. The shaded area represents 95% confidence interval.
Figure 6: Selected detection results of Faster R-CNN with ResNet-18 before (top row) and after(bottom row) applying RPO. Blue boxes are ground truths; green boxes are predictions. These testimages are from PASCAL VOC 2007 validation set. It can be seen that the results after reinforcedtraining make much more sense.
