Figure 1: The bottleneck paradigm: The general idea of a bottleneck method is to first map aninput X to an intermediate representation Z , and then map Z to an output Y . We call the map-pings, resp., an encoder (e) and a decoder (d). In general, the true channel κ is unknown, and onlyaccessible through a set of training examples. We would like to obtain an approximation of κ.
Figure 2: Effect of the regularization parameter β. The upper left panel shows the accuracy on trainand test data after training the VDB for different values of M . Here, M is the number of encoderoutput samples used in the training objective. L is the number of encoder output samples used forevaluating the classifier. The upper right panel traces the deficiency bottleneck curve for differentvalues of β (see text). The curves are averages over 5 repetitions of the experiment. Each curvecorresponds to one value of M = 1, 3, 6, 12. Notice the generalization gap for small values of β(towards the right of the plot). The lower right panel plots the corresponding information bottleneckcurve. The lower left panel plots the minimality term vs. β. Evidently, the levels of compressionvary depending on M. Higher values of M (our method) lead to a more compressed representation.
Figure 3: We trained the VDB on MNIST with the basic encoder given by a fully connected networkwith two hidden layers of ReLUs generating the means and variances of 2D independent Gaussianlatent representation. Ellipses represent the posterior distributions of 1000 input images in latentspace after training with β = 100, 10-1, 10-3, 10-5 and M = 1, 3, 6, 12. Color corresponds to theclass label.
Figure 4: Learning curves for MNIST, where the encoder is a MLP of size 784-1024-1024-2K ,thelast layer being a K = 2 dimensional diagonal Gaussian. The decoder is simply a Softmax with 10classes. The left panel plots the mutual information between the representation and the class label,I(Z; Y), against the mutual information between the representation at the last layer of the encoderand the input, I(Z; X), as training progresses. The former increases monotonically, while the latterincreases and then decreases. The right panel shows the test accuracy as training progresses.
Figure 5: Train and test accuracy of the VDB for L = 3 and L = 12. Similar to Figure 2.
Figure 6: Evolution of the mutual information between representation and output vs. representationand input (values farther up and to the left are better) over 200 training epochs (dark to light color)on MNIST. The curves are averages over 20 repetitions of the experiment. At early epochs, trainingmainly effects fitting of the input-output relationship and an increase of I(Z; Y ). At later epochs,training mainly effects a decrease of I(Z; X), which corresponds to the representation increasinglydiscarding information about the input. An exception is when the regularization parameter β is verysmall. In this case the representation captures more information about the input, and longer trainingdecreases I(Z; Y ), which is indicative of overfitting to the training data. Higher values of M leadto the representation capturing more information about the target, while at the same time discardingmore information about the input. M = 1 corresponds to the Variational Information Bottleneck.
Figure 7: Sampling grids in latent space for M = 6 for different values of β for the MNIST. Highervalues of β results in a more coherent latent space.
Figure 8: The latent space (mean values of the posterior for 5000 test examples) for the FMNISTfor different values of M and β . M = 1 corresponds to the β-VAE.
Figure 9: FMNIST reconstructions for different values of M and β . At low values of β, we havegood reconstructions. M = 1 corresponds to the β-VAE.
