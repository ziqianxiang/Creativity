Figure 1: CIFAR-10 classification error rate against the batch size per GPU. The evaluationmodel is ResNet-101. The result shows that the AssocNorm has the best performance on error ratescompared with the batch normalization and the group normalization.
Figure 2: An overview of the proposed AssocNorm normalization mechanism. AssocNorm dividesthe C channels of the input into groups for computing the mean and variance per group as the keyfeatures μ and Y. An auto-encoder is then used to associate the features μ and Y of the input featuremap to the rescaling parameters ω and β via its outputs Dμ and DY.
Figure 3: Comparison of error rate (%) against the number of training epochs using the batchsize of 64. Both the training error and the validation error of CIFAR-10 are shown.
Figure 4: Comparison of error rate (%) against the number of training epochs using the batchsize of 64. Both the top-1 error rate and the top-5 error rate of CIFAR-100 are shown .
Figure 5: The error rate (%) against the number of training epochs concerning the differentkey feature extraction strategies. This figure shows the CIFAR-10 validation error.
