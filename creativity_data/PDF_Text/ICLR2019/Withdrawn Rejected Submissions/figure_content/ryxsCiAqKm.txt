Figure 1: Histograms of eigenvalues of the rescaled graph Laplacian L for the (a) ENZYMES,(b) COLLAB and (c) MNIST (for 75 superpixels, see Section 3.2 for detail) datasets. Due to theproperty of eigendecomposition (Lk = UΛkUT) the distribution of eigenvalues shrinks when Wetake powers of L to compute the approximate spectral graph convolution (Eq. 2).
Figure 2: Comparison of (a) the fusion method based on a two-dimensional Chebyshev polynomial(Eq. 3, 4) to (b) other proposed methods in case ofa 2-hop filter (a filter averaging features of nodeslocated two edges away from the filter center - v1 in this case). Note that (a) can leverage multi-relational paths and the filter centered at node vι can access features of the node v3, which is notpossible for other methods (b). In this work, edge type ri can denote annotated or spatial relations,while r2 denotes hierarchical or learned ones. We also allow for three and more relation types.
Figure 3: Top row: We compute superpixels at several scales and combine all of them into a singleset. We then build a graph, where each node corresponds to a superpixel from this set and hasassociated features, such as mean RGB color, coordinates of center of masses or convolutionalVGG-16 features. Bottom row: Using Eq. 8 and 9, we compute spatial (a) and hierarchical (c) edgesbetween nodes represented as scaled graph Laplacians L. Nodes 0 to 300 correspond to the firstlevel of hierarchy (first scale of superpixels), and 300 to 400 corresponds to the second level, and soforth. Notice that spatial edges (a) are created both within and across the levels, while hierarchical(c) edges exist only between hierarchical levels. (c, d) Powers of these graph Laplacians LK=4 * * 7 allowedges to diffuse over the graph making it possible to learn filters with more global support.
Figure 4: Graph classification pipeline for images. Each lth convolutional layer in our model takesthe graph Gl = (Vι, E(r)) and returns a graph with the same nodes and edges. Node features becomeincreasingly global after each subsequent layer as the receptive field increases, while edges arepropagated without changes. As a result, after several graph convolutional layers, each node in thegraph contains information about its neighbors and the entire graph. By pooling over nodes Wesummarize the information collected by each node. Fully-connected layers follow global pooling toperform classification. For chemical/social datasets We use a similar pipeline, but the input graph Gis provided by the dataset rather than built from images and does not have hierarchical edges.
Figure 5: Comparison of edge fusion methods on chemical and social datasets for 10 folds.
