Figure 1: The architecture of proposed GANs. (a) denoising-GAN. (b) demixing-GAN.
Figure 2: Left panel: (a). Clean binary MNIST image. (b). Corrupted image with random horizontal and ver-tical lines. (C). Corrupted image with random sinusoidal waves. Right panel: Evolution of outputted samplesby generator for fixed z . Top row is for random horizontal and vertical corruption. Bottom row is for randomsinusoidal corruption.
Figure 3: The performance of trained generator in different level of corruption (lc) for denoising of unseencorrupted digits. Top row: Ground truth digits together with corrupted digits with random sinusoids, andvertical and horizontal lines with a level of corruption from 1 to 5. Bottom row: Classification accuracy ofpre-trained MNIST classifier for both corrupted and denoised digits along with the reconstruction error perpixel.
Figure 4: Evolution of output samples by two generators for fixed z1 and z2 . The right panel shows theevolution of the two generators in different epochs where the mixed images comprise of digits and sinusoidal.
Figure 5: Evolution of output samples by two generators for fixed z1 and z2. The right panel shows that eachgenerator is learning the distribution of one digit out of all 10 possible digits. The mixed images comprise twoarbitrary digits between 0 to 9. Left Panel shows a similar experiment where the mixed images comprise onlydigits 1 and 2.
Figure 6: The performance of trained generators for demixing of two constituent components. The first twocolumns are the ground-truth components. The third column is the ground-truth mixed image and the last twocolumns denote the recovered components. The first row uses the same generator trained for only one digit(drawn from MNIST test dataset) and a random sinusoidal. The third row uses the generator trained only fordigits 1 and 2. The last row shows the result of demixing with ICA method.
Figure 7: Performance of Different GANs in Compressive Sensing Experiments.
Figure 8: Evolution of output samples by two generators for fixed z1 and z2. The mixed images comprise twoarbitrary objects drawn from 10 objects from training F-MNIST dataset. Each generator outputs the samplesfrom the distribution of all 10 possible objects.
Figure 9:	Evolution of output samples by two generators for fixed z1 and z2. The mixed images compriseonly two objects, dress, and bag in training F-MNIST dataset. One generator produces the samples from dressdistribution, while the other one outputs the samples from the bag distribution.
Figure 10:	The performance of trained generators for demixing of two constituent components. The first twocolumns are the ground-truth components. The third column is the ground-truth mixed image and the last twocolumns denote the recovered components. The first row uses the generator trained for only two objects for 20epochs. The second row uses the generator trained for all 10 objects for 20 epochs. The third and fourth rowsuse the same generator trained for only two objects for 30 epochs. The last row shows the result of demixingwith ICA method.
Figure 11: Evolution of output samples by two generators for fixed z1 and z2 . The mixed images compriseonly two objects, dress, and bag in training F-MNIST dataset. One generator produces the samples from digit8 distribution, while the other one outputs the samples from the dress distribution.
Figure 12: The performance of trained generators for demixing of two constituent components. The first twocolumns are the ground-truth components. The third column is the ground-truth mixed image and the last twocolumns denote the recovered components. The first row uses the generator trained through demixing-GAN.
Figure 13:	Failure of the demixing. Evolution of output samples by two generators for z1 = z2 . The mixedimages are the superposition of digits 2 and 8.
Figure 14:	Failure of the demixing. Evolution of output samples by two generators for z1 = 0.1z2. The mixedimages are the superposition of digits 2 and 8.
