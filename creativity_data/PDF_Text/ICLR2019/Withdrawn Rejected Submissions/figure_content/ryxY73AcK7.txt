Figure 1: GroupSort activation with a grouping size of 5.
Figure 2: Approximating the absolute valuefunction via Lipschitz networks. The objectivevalues indicate the Wasserstein Distance esti-mated by each network.
Figure 3: Approximating three circular coneswith slope 1 using Lipschitz networks. The ob-jective values indicate the Wasserstein distanceestimated by each networks.
Figure 4: Jacobian spectral norm distri-bution We compare the Jacobian spectralnorm of ReLU and GroupSort networks.
Figure 5: ReLU activation statistics Ratioof activations which are positive more oftenthan the threshold value on the training data.
Figure 6: Samples from WGANs whose criticarchitectures were built using GNP atomicunits.
Figure 7: Gradients of input images with respectto targeted cross-entropy loss. Left: standardnetwork, Right: 2-norm-constrained network.
Figure 8: Adversarial Robustness Accuracyon PGD adversarial examples for varying per-turbation sizes .
Figure 9: Theoretical Adversarial RobustnessTheoretical accuracy lower bound for varyingperturbation sizes .
Figure 10: A rigid linear transformation, followed by absolute value, followed by another rigid lineartransformation, can implement folding along an arbitrary hyperplane. Here is an example where thenetwork represents a function consisting of a pair of square pyramids by folding the space threetimes, until the function is representable as a linear function of the top layer activations.
Figure 11: Convergence of the BjorCk algorithmfor different choices ofβ. The largest and small-est singular values are shown after 50 iterationsof the algorithm.
Figure 12: Convergence of the Bjorck algorithmfor increasing iterations with β = 0.0003. Thelargest and smallest singular values are shownafter each iteration of the algorithm.
Figure 13: Comparing the performance of I-LiPSChitZ neural nets using Bjorck orthonormalizationand spectral normalization to enforce the 2-norm constraint on the high dimensional cone fittingtask (Section 7.1.1). Note that networks using BjOrCk orthonormalization both converge faster andachieve higher final approximation accuracies, as measured by the estimated Wasserstein Distance.
Figure 14: Lattice construction for Lp universal approximation.
Figure 15: Generated images from WGAN-GP models trained on the CelebA dataset.
Figure 16: Jacobian singular values distribution We compareReLU and GroupSort networks.
