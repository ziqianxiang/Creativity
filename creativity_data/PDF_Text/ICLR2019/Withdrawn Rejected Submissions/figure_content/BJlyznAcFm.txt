Figure 1: a) A simple single-attention frameWork. The encoder-decoder produce an attentionmap a, Which is multiplied by the input x to create the input to the decision module, or JudgeJ . b) Our advocacy learning frameWork. Each decoder Deci is trained separately to outputa class-conditional attention map, or argument ai , Which is combined With the input to createevidence E = [e0,...,eN], Where ei is evidence supporting class i. Each advocate is shoWn ina different color, the number of Advocates is equal to the number of classes. c) An exampleof a multiplicative visual attention map ai used to generate evidence ei .
Figure 2: Averaged difference across five runs in confusion matrices between the multi-attentionand advocacy networks (â‰¥ 0 means the Advocacy net performed better) on a) MNIST andb) FMNIST. We zero out the diagonal elements to focus on misclassification. A positivenumber means the multi-attention net made more misclassifications than the advocacy netand vice-versa. We observe the advocacy net tends to improve performance across classes,but can make certain morphologically similar examples (i.e., 8 vs 9 in a) more difficult.
Figure 3: Evidence generated from a Fashion-MNIST example. The top row shows a samplefrom the class the column represents. The second row shows evidence generated by themulti-attention net (the ordering is arbitrary), the bottom row shows evidence from an honestAdvocate network (the order corresponds to class). The image is an example of class 6 (shirts).
Figure 4: a) A heatmap showing effect of varying Judge and Advocate capacity (in termsof residual blocks: high # means high capacity) for an advocacy net on MNIST. b-c) The twogeneral trends seen over the heatmap. In (b) we see that performance decreases as we increaseAdvocate capacity, in (c) we see that performance increases as we increase Judge capacity.
