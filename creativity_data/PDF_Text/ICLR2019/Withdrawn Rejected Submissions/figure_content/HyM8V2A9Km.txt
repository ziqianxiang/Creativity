Figure 1: The diagram illustrates our model architecture.
Figure 2:	Performance in average success rate during training, comparing between different sentenceembedding methods for the single target and composition task on ViZDoom.
Figure 3:	Comparison among different sentence embedding methods showing the pairwise correlationbetween the sentence embedding vectors for each of the singleton instructions. The darker the colour,the higher the correlation.
Figure 4: Performance comparisons on KGW and ViZDoom environments. The success rates arecalculated over all desired goals and 16 different environments. Shaded area represents standarddeviation 2 random seeds.
Figure 5: Example of (a) unambiguous composition of instructions and (b) ambiguous compositionof instructionsB.3	ViZDoom Composition: Modification for StateFor the ViZDoom composition task, we modify the raw pixel image of the environment to include abasic head-up display (HUD) consisting of black rectangle in the bottom left of the screen. When theagent reaches an object, a small thumbnail image of the reached object will appear inside the HUD.
Figure 6: Example state input screens seen by the agent in a ViZDoom composition task episode.
Figure 7:	Performance comparisons on KrazyGrid World environments. The success rates arecalculated over all desired goals and 16 different environments. Shaded area represents standarddeviation 2 random seeds.
Figure 8:	Transfer experiments that demonstrate pre-training with easier goals can aid learning more difficultgoals.
Figure 9: ViZDoom experiment with 5 objects in easy mode for single target case.
Figure 10: ViZDoom experiment with 5 objects in hard mode for single target case.
Figure 11: Average training episode lengths in VizDoom environments. (a) 5 objects in hard mode,in single target case. (b) 7 objects in hard mode, in single target case. (c) 5 objects in easy mode, incomposition case.
Figure 12:	Multi-task (MT) cumulative success rate versus episode in ViZDoom environments, usingGRU hidden state sentence representation. (a) 5 objects in hard mode, in single target case. (b) 7objects in hard mode, in single target case. (c) 5 objects in easy mode, in composition case.
Figure 13:	Performance comparisons on VizDoom environment.
Figure 15: t-SNE plots of instruction embeddings for GRU (top left), InferLite (top right), One-hot(bottom left) and Inferlite synonyms (bottom right). Best seen in electronic form.
