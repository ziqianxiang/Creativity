Figure 1: MILE frameworkto large datasets, we seek to speed up existing graph embedding methods without sacrificingquality. We formulate the problem as:Given a graph G = (V, E) and a graph embedding method f (∙), We aim to realize a strength-ened graph embedding method f (∙) so that it is more scalable than f (∙) while generatingembeddings of comparable or even better quality.
Figure 2: Toy example for illustrating graph coarsening. (a) shows the process of applying Struc-tural Equivalence Matching (SEM) and Normalized Heavy Edge Matching (NHEM) for graphcoarsening. (b) presents the adjacency matrix A0 of the input graph, the matching matrix M0,1corresponding to the SEM and NHEM matchings, and the derivation of the adjacency matrix A1of the coarsened graph using Eq. 2.
Figure 3: Changes in performance as the number of coarsening levels in MILE increases(best viewed in color). Micro-F1 and running-time are reported in the first and second rowrespectively. Running time in minutes is shown in logarithm scale. Note that # level = 0represents the original embedding method without using MILE. Lines/points are missingfor algorithms that use over 128 GB of RAM.
Figure 4: Running MILE on Yelp dataset.
Figure 5: Memory consumption of MILE (GraRep) and MILE (NetMF) on Blog with variedcoarsening levels.
