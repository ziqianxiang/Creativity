Figure 1: (a) A schematic of Distribution Regression Network (DRN) which performs distributionregression by encoding each node with an entire distribution. (b) An example network for RecurrentDistribution Regression Network (RDRN) which takes in T time steps of distributions to predictthe distribution at T + k. The arrows represent fully-connected weights. The input-hidden weightsU and the hidden-hidden weights W are shared across time steps. V is the weights between thefinal hidden state and the output distribution. The hidden states at t = 0 are initialized as uniformdistributions.
Figure 2: (a) Shifting Gaussian dataset: The mean of the Gaussian distribution varies sinusoidallywith time, hence forward prediction requires more than one time step of past distributions. (b)RDRN’s prediction for four test data for the shifting Gaussian dataset shows a good fit with thelabeled output. The top and bottom left data have the same mean at t = 3, but are moving inopposite directions, showing that more than one input time steps are required for this task.
Figure 3: RDRN network for the stock dataset: past 3 days of distribution of returns of constituentcompanies in FTSE, DOW and Nikkei were used as inputs, to predict the next day’s distributionof returns for constituent companies in FTSE. One layer of hidden states is used, with 3 nodes perhidden state.
Figure 4: Comparison of the (a) mean and (b) variance of the label and predicted distributions for1 and 10 days ahead stock prediction. The diagonal line represents a perfect fit. R represents thecorrelation coefficient.
