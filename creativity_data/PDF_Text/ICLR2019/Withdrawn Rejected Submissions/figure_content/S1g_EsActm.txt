Figure 1: Top:croping or wraping into a fixed size. Bottom:popular network and AIN structure.
Figure 2: Select Window Operation.
Figure 3: AIL computational graph.
Figure 4: LAIL computational graph.
Figure 5: GAIL computational graph.
Figure 6: Visualization of AIN.
Figure 7: Comparision between crop and zoom.
Figure 8: Furniture-128 loss and epochs0.7	0.8	0.9	1.0	1.1	1.2	1.3	1.4	1.5parameters	le7Figure 9: Furniture-128 error and parameters7Under review as a conference paper at ICLR 20194.3	ImageNetThe ILSVRC 2012 classification dataset (Deng et al., 2009) consists 1.2 million images with 102,286various size for for training (top-3 size :500x375, 375×500, 500×333), and 50,000 images with5212 various size for validation from 1, 000 classes. We train ImageNet+ by DenseNet with randomcrop and single crop and 10-crop in validation set the same as (Huang et al., 2016). We trainImageNet* by AIN With zoom fact between 0.8 and 1.2 for in training set, without zoom and 10-zoom while testing, we add a dropout layer after GAIL and set the dropout rate to 0.2 to preventoverfitting.
Figure 9: Furniture-128 error and parameters7Under review as a conference paper at ICLR 20194.3	ImageNetThe ILSVRC 2012 classification dataset (Deng et al., 2009) consists 1.2 million images with 102,286various size for for training (top-3 size :500x375, 375×500, 500×333), and 50,000 images with5212 various size for validation from 1, 000 classes. We train ImageNet+ by DenseNet with randomcrop and single crop and 10-crop in validation set the same as (Huang et al., 2016). We trainImageNet* by AIN With zoom fact between 0.8 and 1.2 for in training set, without zoom and 10-zoom while testing, we add a dropout layer after GAIL and set the dropout rate to 0.2 to preventoverfitting.
