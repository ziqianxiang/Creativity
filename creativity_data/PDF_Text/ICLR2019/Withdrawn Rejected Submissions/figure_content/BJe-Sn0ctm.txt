Figure 1: Overall architecture of SAPS. Rectangles mark data entities, rounded boxes are operations.
Figure 2: The modified DRNN cell consists of two LSTM blocks, each comprising embedding, inputprojection layer to adapt the input size to LSTM size, layer normalization LSTM cell, and residualskip connection between the projection and the output layers. DRNN cell uses the latent vector toenrich the prediction hidden state by the information that might have been lost during hierarchicalprocessing.
Figure 3: Propagation of the hidden states and the latent vector during decoding. The dashed lineillustrates the traversal of the horizontal state, the solid line propagation of the vertical state. Thelatent vector is used to initialize both states, but has also impact on subsequent decoding steps viaan attention mechanism.
Figure 4: The grammar of the AlgoLisp DSL from (Polosukhin & Skidanov, 2018).
