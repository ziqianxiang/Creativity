Figure 1: Our model's procedure for consuming a single input instance of source code and producingan output for a supervised learning task.
Figure 2: Example of a model's procedure for completing the Fin-In-The-Blank task. Each Fill-In-The-Blank instance is created by replacing a single usage of a variable (n, in this example) withthe special token <FILL-IN-THE-BLANK>. The model then processes the code as depicted inFigure 1. To produce outputs, the model,s readout function computes a soft-attention weightingover all nodes in the graph; the model,s output is the variable at the node on which it places maximalattention. In this example, if the model put maximal attention weighting on any of the green-highlighted variables, this would be a correct output. If maximal attention is placed on any othernode, it would be an incorrect output. Only in-scope usages of a variable are counted as correct.
Figure 3: Example of a model's procedure for completing the Variable Naming task. Each VariableNaming instance is created by replacing all uses of some variable (expectedLength, in thisexample) with a special <NAME-ME> token. The model then processes the code as depicted inFigure 1. To produce outputs, the model takes the mean of the <NAME-ME> nodes, hidden states(depicted here in orange), uses them as the initial hidden state of a Recurrent Neural Network, andunrolls this RNN to produce a name as a sequence of words.
