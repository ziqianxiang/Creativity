Figure 1: Illustration of the proposed neural-based input method. (a) Input context. (b) Conversionwith LSTM LM and Viterbi decoder. (c) Word prediction.
Figure 2: Illustration of incremental selective Softmax: (a) Vocabulary sampling strategies (b) Incre-mentally correct path probabilities with new lattice vocabulary.
Figure 3: Model compression with k-means clusters from 21 to 28.
Figure 4: Case study between conversion results ofLSTM-based language model and n-gram model.
