Figure 1: The architecture of MMLSTMs layer. (v1, ..., vn) and (e1, ..., en) denote the output of theprevious layer and the word embedding of the original word sequence respectively. (a1, ..., an) and(c1, ..., cn) represent the output of the Major LSTM and the Minor LSTM.
Figure 2: The line graphs of models with changed LSTM layers dimensions perplexities on PTBand WT2. The solid line and the dotted line denote the perplexity variation trend of the first LSTMand the second LSTM layer respectively. And the dimensional interval of these three line graphs is200.
Figure 3: The perplexity bands of models with changed LSTM layers dimensions on PTB and WT2.
