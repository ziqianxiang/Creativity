Figure 1: Two-dimensional embedding of the rep-resentations assigned by different state extractors.
Figure 2: Curves tracking testing re-wards and smallest number of singularvalues during training process. Curvesare smoothed.
Figure 3: General architecture of a DRL modeland its representation matrix H . u is the num-ber of hidden units, and b is the mini-batchsize.
Figure 4: Improvements of our method ExP DRL compared to A3C, using the metric given in Eq. 7.
Figure 6: Testing rewards curves (left) and empirical expressiveness curves (right) on 4 Atari gamesfor ExP DRL (yellow) and the baseline (blue).
Figure 7: Model architecture.
Figure 8: Improvement comparison over baseline A3C between L2 norm regularizer and our methodExP DRL.
