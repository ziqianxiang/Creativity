Figure 1: NLC vs the relative di-ameter of linearly approximableregions. See section E.1 for de-tails.
Figure 2:	NLC versus test error. Points shown in red correspond to architectures with high outputbias (1000Qj (Sxf(x, j)) < Qj,x f (x, j)). Points shown in blue correspond to architectures thathave skip connections. Inset graphs in the bottom right are magnifications of the region 0.8 <NLC < 100. See section E.2 for details.
Figure 3:	Detailed results from our empirical study. See main text for explanation and section E.2(figures A/B/C/D/F) and section E.3 (figure E) for further details.
Figure 4: Depth versus test error.
Figure 5: 1d pictorial illustrationof the NLCIt is easy to check that the proportion of the domain coveredby the red interval and olive interval isdiameter (F)f 0(xÎ¹ )diameter(D)andf0 (XlameameFI(D) respectively. The insight behind the NLC is thatboth linear approximations can only be accurate while they remain inside their respective shadedarea, or at least close to it. This is evidently true in both cases, as both tangent lines quickly moveaway from the co-domain outside the shaded region. In the case of x2, this bound is also tight asthe tangent tracks f closely everywhere in the olive region. However, in the case of x1, the bound isloose, as the red line completely decoupled from f throughout a large part of the red region.
Figure 7: Frequency with which each training run minimized the validation error on CIRAR10 (A)/ training error on waveform-noise (B). Note: Architectures which did not achieve a better-than-random test error were omitted in (A) and architectures that did not achieve a better-than-randomtraining error were omitted in (B). We set those thresholds at 80% for CIFAR10 (10 different labels)and 50% for waveform-noise (3 different labels).
Figure 6: Coloring of the outputsphere used for the illustrationsin table 2, shown as an azimuthalprojection.
Figure 8:	Starting learning rate of the selected training run for minimizing validation error on CI-FAR10 (A) and minimizing training error on waveform-noise (B). Note: Architectures which did notachieve a better-than-random test error were omitted in (A) and architectures that did not achieve abetter-than-random training error were omitted in (B). We set those thresholds at 80% for CIFAR10(10 different labels) and 50% for waveform-noise (3 different labels).
Figure 9:	Detailed results from our empirical study. See main text for explanation and section E.2and E.3 for further details.
Figure 10:	Both the first row of graphs (A/B/C) and the second row of graphs (D/E/F) are identicalto figure 2, except the top row shows only architectures without skip connections and the bottomrow shows only architectures with skip connections. Again, red color indicates architectures withhigh output bias.
