Figure 1: Illustration fortangent-normal adversarialregularization. x = x0 + nis the observed data, wherex0 is exactly supported onthe underlying manifold Mand n is the noise indepen-dent of x0 . rk is the ad-versarial perturbation alongthe tangent space to induceinvariance of the classifieron manifold; r‚ä• is the ad-versarial perturbation alongthe normal space to imposerobustness on the classifieragainst noise n.
Figure 2: The decision boundaries of compared meth-ods on two-rings artificial dataset. Gray dots distributedon two rings: the unlabeled data. Blue dots (3 in eachring): the labeled data. Colored curves: the decisionboundaries found by compared methods.
Figure 3: The perturbations and adversarial examples in the tangent space and the normal space. Note that theperturbations is actually too small to distinguish easily, thus we show the scaled perturbations. First row: Fash-ionMNIST dataset; Second row: CIFAR-10 dataset. From left to right: original example, tangent adversarialperturbation, normal adversarial perturbation, tangent adversarial example, normal adversarial example.
Figure 4: The perturbations and adversarial examples in tangent space and normal space for FashionMNISTdataset. Note that the perturbations is actually too small to distinguish easily, thus we show the scaled pertur-bations. From left to right: original example, tangent adversarial perturbation, normal adversarial perturbation,tangent adversarial example, normal adversarial example.
Figure 5: The perturbations and adversarial examples in tangent space and normal space for CIFAR-10 dataset.
