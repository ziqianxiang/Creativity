Figure 1: Different categories of label noise and their statistical dependencies, as depicted by thered arrow. In type I noise, all instances are equally likely to be mislabelled base on some probabilityY ∈ [0,1 ]. In the case of type II, this probability is different for each class: γ0 ∈ [0,1 ] andγ1 ∈ [0,1 ]. Type In label noise is the most realistic model and yet the least studied. In this case theprobability of an error is a function of the input features: i.e. Perror 〜f (x).
Figure 2: Plots showing the path traversed in θ space by a supervised model as learnable parametersare updated via a gradient based optimizer. The gold line shows the path followed by a noise-freemodel and the blue lines show the modified paths due to label noise. In the case of random labelnoise (left plot), the perturbations Erand to the true gradient direction are curbed by an increase intraining set size. In contrast, for input dependent noise (right plot), supplying the model with moredata perpetuates the label bias.
Figure 3: In the first row, we visualize the separation achieved by classifiers trained on a trainingset with noisy labels. From left to right, we show the results of logistic regression, an SVM, a 1layer feed-forward neural network and the proposed technique. In the second row, we visualizethe training data. From left to right, we show the clean data, the noisy data and the autoencoder-corrected data. We observe that standard binary classifiers are unable to achieve satisfactory classseparation. The 1 hidden layer NN classifier accomplishes significant separation but it incorrectlyidentifies mislabelled instances. The proposed model is able to identify mislabelled instances basedon the energy distribution of the training data.
