Figure 1: Images generated by different GANs trained on MNIST (top row), CelebA (middle row)and STL-10 (bottom row). Red square mark images of, arguably, low quality (best seen in color).
Figure 2: Samples from the toy-dataset along with samples generated from: (a) GAN, (b) unsuper-vised GM-GAN, (c) AC-GAN, (d) supervised GM-GAN. Samples from the training set are drawn inblack, and samples generated by the trained Generators are drawn in color. In (b) and (d), the colorof each sample represents the Gaussian from which the corresponding latent vector is sampled.
Figure 3: Samples from the toy-dataset along with samples generated by an unsupervised GM-GANusing different σ values for sampling latent vectors from the latent space Z (σ = 1.0 was usedduring training). The color code is the same as in Figure 2b,d.
Figure 4: Samples taken from a GM-GAN trained on the MNIST dataset. In each panel, latentvectors samples are drawn using different σ values (σ = 1.0 was used during training). Clearly Thequality of samples decreases, and the diversity increases, as σ grows.
Figure 5: Quality and Diversity scores of GM-GANs vs. baselines trained on 2 datasets: CIFAR-10(top) and STL-10 (bottom). Left column: AC-GANs vs. supervised GM-GANs. Right column:GANs vs. unsupervised GM-GANs. Error bars show the standard error of the mean.
Figure 6: Inception Scores of Static GM-GAN models trained on (a) CIFAR-10 and (b) STL-10,when latent vectors are sampled using different values of σ. In both cases, the same model achievesvery different Inception Scores when different values of σ are used. Both models were trained usingσ = 1. Note that the best score is obtained for σ < 1, far from the training value σ = 1.
Figure 7: Convergence rate of our proposed models vs. baselines. The plot shows the negative log-likelihood of generated samples, as a function of the training epoch of each model. Both variants ofthe GM-GAN model converge much faster as compared to the baseline models.
Figure 8: Quality and Diversity scores of GM-GANs vs. baselines trained on 2 datasets: Fashion-MNIST (top) and MNIST (bottom). Left column: AC-GANs vs. supervised GM-GANs. Rightcolumn: GANs vs. unsupervised GM-GANs. Error bars show the standard error of the mean.
Figure 9: Unsupervised clustering with the info-GAN model (Chen et al., 2016) trained on thefashion-MNIST dataset. We evaluated the original model with uniform and Gaussian latent spacedistribution. In addition, we incorporated multi-modal Gaussian distribution of the latent space intothe model with 3, 5 and 10 mixture components. The results of the GM-info-GAN variants areclearly better than vanilla, with best results obtained for 5 Gaussian components.
Figure 10: Samples taken from two unsupervised GM-GAN models trained on the MNIST (toppanels), Fashion-MNIST (middle panels) and CIFAR-10 (bottom panels) datasets. In (a) the Gaus-sian mixture contains K = 10 Gaussians; in each panel, each row contains images sampled froma different Gaussian. In (b) the Gaussian mixture contains K = 20 Gaussians; in each panel, eachhalf row contains images sampled from a different Gaussian.
