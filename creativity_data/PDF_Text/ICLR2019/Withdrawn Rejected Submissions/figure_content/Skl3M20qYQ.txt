Figure 1: Structure of total information of two variables about S2Under review as a conference paper at ICLR 2019For the case of 2 variables (X1 , X2), we expect four contributions to the mutual information asdescribed in Bertschinger et al. (2012); Olbrich et al. (2015):I(S;R1,R2) =SI(S;R1,R2)+Unq(S;R1\R2)+Unq(S;R2\R1)+Syn(S;R1,R2)'--------{--------} |Redundant{z'^^^^Unique}|^"^\^^^UniqueJ 1-------------{----------}Synergistic(1)Itâ€™s easy to see that the number of terms increases exponentially as the number of sources increases.
Figure 2: Left: Traverse of latents (110k steps). Right: Mean activations (110k steps)After looking at the figure above we can state that our model achieves state-of-the-art results usinga qualitatively benchmark. Interestingly, both models perform quite similar in this test.
Figure 3: Synergy loss for Factor VAE - 4k stepsAs a comparison, we also show the synergy for the Non-Syn VAE for the same number of steps inFig 4. Surprisingly, Factor VAE minimises the Synergy implicitly by penalising the Total correlationterm.
Figure 4: Synergy loss for Non-Syn VAE - 4k steps6	ConclusionsIn this paper we presented the intuition and derivation of the lower bound of a model that uses a novelapproach inspired by the information theory and Neuroscience fields to achieve the disentanglementof the underlying factor of variations in the data. After looking at the results,we can state that ourmodel achieved state-of-the-art results, with a performance close to FactorVAE Kim & Mnih (2018).
