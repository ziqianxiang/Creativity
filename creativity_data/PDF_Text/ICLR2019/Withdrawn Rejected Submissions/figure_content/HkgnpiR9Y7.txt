Figure 1: Step-wise comparison. The first image is target real image and the remainders are recon-structed images by each method; the order is same with table.
Figure 2: Subjective comparison for the reconstruction accuracy. The odd (first and third) columnsshow the input images and the even columns (second and fourth) are their corresponding recon-structed images. VAE and ALI/BiGAN are existing bidirectional generative models. We utilize fiveunidirectional GANs (DCGAN, LSGAN, DFM, RFGAN, and WGAN-GP) as baseline GANs andbuild five different variants of our models for inference mapping.
Figure 3: Image editing applications using latent vector arithmetic. The first and fourth column showthe input images. The second and fifth column are the reconstructed images. The third and sixthcolumn are the result of latent arithmetic. For each algorithm, the first two rows add the latent vectorfor blonde hairs and the last two rows add the latent vector for glasses.
Figure 4: The network architecture of the proposed model consisting of a generator G, a discriminatorD, an attribute classifier C, and a connection network CN.㊉ means concatenation along the lastdimension.无 and Z mean the generated image and the generated latent vector, respectively.
Figure 5: Comparisons of facial attribute editing. The blue box highlights our results. The first threecolumns are VAE/GAN, modified cGAN, and IcGAN. For each row, the specified attribute(s) isadded to the input image.
