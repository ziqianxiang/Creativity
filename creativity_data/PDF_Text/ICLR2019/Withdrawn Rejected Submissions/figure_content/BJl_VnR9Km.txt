Figure 1: (a) Two Cortical Modules stacked on top of each other. The input I1 would be the spa-tiotemporal block of video frames. The ? notation means a convolution along that path. 2 ↑ indicatesup-sampling or expansion operation. 2 1 means down-sample or reduction in resolution. Q indi-cates comparator or subtraction operation; (b) The DCNN analysis path is actually implementedin a sparsified convolution scheme to speed up bottom-up processing; (c) Detailed structure of theLSTM used. Ct is the internal state, and Ht is the output. X is external input, which includesmultiple sources in our model. (d) Frame-by-frame method; (e) Block-by-frame method; and (f)Block-by-block method, where left and right part indicates output and input with the middle indi-cating 2D or 3D convolution LSTM.
Figure 2: Video prediction results on Moving-MNIST dataset, where the first row to last row areground truth (GT), results from three different version of HPNet (block-to-block (B-B), block-to-frame (B-F), frame-to-frame (F-F)), PredNet, and PredRNN++, respectively. k=1 to k=19 are pre-dicted frames of the models when the input frames were available. k=21 to k=39 are the ”dead-reckoning” predicted frames of the model when there are no input.
Figure 3: Video prediction results on the KTH dataset, where the first row to last row are groundtruth (GT), results from block-to-block (B-B), block-to-frame (B-F), frame-to-frame (F-F), PredNet,and PredRNN++, respectively, same format as Figure 2.
Figure 4: (a) Comparison of the prediction results of the five models for the Moving-MINST dataseton the last 20 frames in structural similarity measures (SSIM). (b) Comparison of the predictionresults on the KTH datset. (c) Comparison of the performance (and training time) of the B-B andthe B-F networks as a function of the number of modules in the network. (d) Training time versusSSIM performance of the different models. Note, the training time (x) axis not in a linear scale.
Figure 5: (a)-(d) are the top CM's R representation of networks with different number of modules,from one to four; (e)-(h) are the representation of each modules in a four-modules network, fromthe first module to the fourth, left to right. Better clustering leads to better decoding results of thedifferent movement classes. Full details are in Appendix B.
Figure 6: (a) The development of the prediction suppression effect across days in one experiment.
Figure 7: Visualization of R representational units of the different modules in (a) a one-modulenetwork; (b)-(c) a two-module network; (d)-(f) a three-module network; and (g)-(j) a four-modulenetwork.
Figure 8: Results of video sequence learning experiments showing prediction suppression can beobserved in E, P, and R units in every module along the hierarchical network. The abscissa is timeafter stimulus onset - where we set each video frame to be 25 ms for comparison with neural data.
Figure 9: Prediction suppression in IT neurons((Meyer & Olson, 2011)).
Figure 10: Prediction suppression results on E4units in HPNet.
Figure 11: Prediction suppression behaviors in the E, P, and R units of module 4 of HPNet, respec-tively.
