Figure 1: Generic architecture overview with two SHAMANN actors denoted by F and B thattraverse a series of local image patches sequentially in a forward, respectively backward manner andsegment each patch. For completion we also visualize two simplified alternatives, one in which theactors do not share their memory (Bi-MANN), and the other with no external memory (Bi-LSTM).
Figure 2: Detailed illustration of a forward actor network that uses an external memory module toperform a sequential segmentation task. At the time iteration t, the actor updates its memory cellct using the previous memory cell ct-1 and the current encoded input patch ψt, concatenated withthe previous information read from the memory rt-1. The actor then writes to and reads from anexternal memory module and produces a segmentation mask Φt .
Figure 3: Qualitative results. From left to right: input image with label, segmentation masks us-ing the method proposed by Ronneberger et al. (2015), two models proposed by Yu et al. (2017)and SHAMANN. The bottom two rows show results on more difficult cases. The last row demon-strates the effectiveness of the SHAMANN method in capturing the global context. We visualize thegroundtruth mask in magenta, the prediction of the networks in turquoise and their overlap in blue.
Figure 4: MNIST quantitative results. SHAMANN performs best both in terms of dice and classifi-cation accuracy for different cell state sizes.
Figure 5: Figures 5a and 5b show qualitative results. From left to right: altered input image,label, reconstructed images using actors with no memory, actors with internal memory, actors withindividual external memory, and actors that share an external memory module. Figure 5c illustrateshow actors use the context seen by others to refine their prediction.
