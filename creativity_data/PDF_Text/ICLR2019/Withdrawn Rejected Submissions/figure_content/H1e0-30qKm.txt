Figure 1: The flowchart of our architecture. Sampled latents from different attributes are combinedinto latent vectors. Generated images are grouped with respect to different attributes (here, repre-sented by shape) by Siamese Networks (denoted as Ï†i).
Figure 2: (left) Four of our siamese networks are guided with differently cropped images. (right)Varying latent variables that correspond to guided siamese networks captures desired variations.
Figure 3: Illustration of the embedding spaces and separated probability distributions after trainingour model.
Figure 4: (a) Samples from the colored version of the MNIST dataset. (b) Images generated after anunsupervised training with two knobs and (c) after a guided training (the knob values are interpolatedbetween two values and then concatenated to generate the final image). (d) The t-SNE representationof the embedding vectors for shape and (e) color.
