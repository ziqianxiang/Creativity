Figure 1: Separately represents connections between output channels and input channels. Bright-ened part means the F-norm between these specific channels is significantly large. Dark area showsthat the model has significant channel wise redundancy.
Figure 2: An example of decomposed a convolution kernel to locally dense modules where eachnode denotes a filter of shape m * n. As an example, Fig. (a) illustrates a convolution kernel withshape 6 * 4 * m * n before decomposition, Fig. (b) illustrates two small kernels with shape 3 * 2 * m * nafter ideal decomposition. Especially, grey color denotes the connections between channels has beencut off. Note that under this example, decomposition saved 18 * m * n parameters.
Figure 3: A structure example for a prefix dense module as shown above, where yellow layer rep-resents several densely connect bottleneck layers (it means all output has a direct connection to theoutput layer). The detailed structure used in a bottleneck layer shown left. After the final layer, thegreen layer represents a transition layer to control the feature map size. Dense blocks depth in ourexperiment usually varied from 6-20 layers.
Figure 4: An example of using the adjacent matrix to represent sparse connections Fig. (a) in anadjacent matrix. As it shows in Fig. (b), red rectangle area denotes connections with distance 1,green rectangle denotes connections with distance 2, blue area denotes connections with distance 3M_11M_12...................... M_43M_11M_12M_13M_430	0	0	1	0	0	O-	T	-0	0	0	00	0	0	0	1	0	O	0	0	0	0	10	0	0	0	0	1	0	0	0	0	0	00	0	0	0	0	0	1	1	0	0	~	F0	0	0	0	0	0	0	1	0	0	0	00	0	0	0	0	0	1	0	1	0	0	00	0	0	0	0	0	0	0	0	1	0	00	0	0	0	0	0	0	0	0	0	1	10	0	0	0	0	0	0	0	0	1	1	00	0	0	0	0	0	0	0	0	0	~	00	0	0	0	0	0	0	0	0	0	0	00	0	0	0	0	0	0	0	0	0	0	0
Figure 5: An example of the Network Structure Evolving. Initial state denotes the initial connectionsP. As we set before first iteration Pbest = Pinit, based on Pbest we generate 2 individual below. Alltogether these 3 individual form the population to be trained simultaneously in iteration 1. Then, wechoose the individual with the best performance, and based on that we form population for iteration2. Follow this principle we maintain network evolving.
Figure 6: Comparison of Concatenation and addition method for connection. Fig. (b) denotes anexample of a random chosen P1 and Fig (a) denotes the train&test curve correspond to it. Fig. (c)shows the comparison result on three random chosen situation.
Figure 7: Several Repeatable Experiment on Sparse Connection Evolving. The upper three figuresdenote the training curve & testing curve of each experiment. The lower figure denotes the compari-son of test accuracy of each experiment. All accuracy step jumps are caused by learning rate changestrategy in section 4.2.
Figure 8: Connection Matrix with Best Performance on each Experiment. We also give an exampleconnection status of Exp1.
Figure 9: Test Accuracy Curve Comparison on Different Growth Rate. Each color represents testaccuracy curve of experiments on different growth rate.
Figure 10: Example connection matrix shows the selected best connection from a typical experi-ment. Right part of the figure shows how much accuracy will loss if we cut off the correspondingconnection in the connection matrix.
