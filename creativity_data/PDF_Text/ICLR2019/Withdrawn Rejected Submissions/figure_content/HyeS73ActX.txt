Figure 1: Example with four actions with the corresponding reward vectors, QT and VTd = 1. These vectors are represented as points in the plane. From this representation, we can get therepresentation of the scalarized terminal reward function for each of the actions. In Figure 1b, weplot the QT function for each action and VT versus δ ∈ ∆ = R. As noted earlier, QT = RT whichis piecewise constant and shown in the thin lines in the figure and VT is a pointwise maximizationof such functions and shown in the thick lines. The points corresponding to actions that are optimalfor some δ are surrounded by a square. That is why the one corresponding to action a2 is not.
Figure 2: Weighted summation of two NIPWC functions4.5 Complexity Analysis for the Discrete CaseIn this section, we analyze the space and time complexity of the computations done in Section 4.
