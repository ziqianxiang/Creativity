Figure 1: Left: density estimation models are not robust to OoD inputs. A GLOW model (Kingma& Dhariwal, 2018) trained on CIFAR-10 assigns much higher likelihoods to samples from SVHNthan samples from CIFAR-10. Right: We use ensembles of generative models to implement theWatanabe-Akaike Information Criterion (WAIC), which combines density estimation with uncer-tainty estimation. Histograms correspond to predictions over test sets from each dataset.
Figure 2: In this toy example, we learn generative models for a 2D multivariate normal with identitycovariance centered at (5, 5). (a) Explicit density models such as Normalizing Flows concentrateprobability mass at the data distribution (b) Four independently trained GANs learn random discrim-inative boundaries, each corresponding to a different implied generator distribution. To ensure thatthe GAN discriminators form a clear discriminative boundary between p(x) and qθ(x), we train thediscriminators an additional 10k steps to convergence. Each of these boundaries fails to enclose thetrue data distribution. (c) Predictive uncertainty over an ensemble of discriminators “fences in” theshared, low-variance region corresponding to p(x).
Figure 3: Top: Inputs and decoded outputs from a VAE trained on Fashion MNIST(β = 1) for Fash-ion MNIST (left) and MNIST (right). Although Fashion MNIST inputs appear to be better recon-structed (suggesting higher likelihoods), they have comparable distortions to MNIST. The bottomrow shows that Fashion MNIST and MNIST test samples have comparable rate-distortion scatterplots and IWAE histograms.
