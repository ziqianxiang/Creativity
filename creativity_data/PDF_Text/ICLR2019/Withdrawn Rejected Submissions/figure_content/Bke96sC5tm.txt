Figure 1: (a) A pictoral depiction of a trajectory for a one-dimensional system. (b) Global modelsmay be used for prediction or planning forward through time, as depicted in red, but this can sufferfrom trajectory drift for complex systems. (c) Local linear models are fit to trajectories and do notsuffer from drift, but may fit the system poorly for complicated interactions such as contacts, asillustrated by the poor model fit circled in gray. (d) Our method finds an embedding of observedtrajectories into a latent space where local linear models produce a better fit.
Figure 2: Left: The LQS graphical model. Distributions for each node are as specified inEquation 2-Equation 4, with additional deterministic nodes for observed costs. Right: The vari-ational family we use for our model learning algorithm, with distributions given in Equation 5.
Figure 3: (a) Top: Visualizing a trajectory in the car navigation environment, with the target denotedby the black dot, and the corresponding image observation. Bottom: An illustration of the 2-DoFarm environment, with the target denoted by the red dot, and the corresponding image observation.
Figure 4: (a) Our method, the VAE ablation, and the global model ablation consistently solve 2Dnavigation from images, whereas LQR-FLM and the E2C-like ablation are unable to make progress.
Figure 5: Performance on the real-worldSawyer block stacking task. Our methodlearns to successfully stack the block inabout half an hour of interaction time.
Figure 6: (a) An illustration of the 2D navigation task, with the agent depicted as the black dot andthe target depicted as the blue dot. (b) We use as observations two 32-by-32 images stacked on topof each other, where the first observation indicates the position of the agent the second observationindicates the position of the target. (c) Visualization of the 4-dimensional latent space for an examplerandom trajectory of the 2D-navigation task. Note that the range of values in the latent space is verynarrow, and the bottom two dimensions seemingly capture information about the target which doesnot move.
Figure 7: On 2D navigation with the goal fixed tothe bottom right, our E2C-like ablation is able tomake progress toward the goal.
Figure 9: (a) Comparison of our method to PPO on the 2D navigation task presented in the paper.
Figure 8: On the car from states, our method iscompetitive with LQR-FLM, demonstrating thatwe maintain the sample efficiency of model-basedmethods for simple tasks.
