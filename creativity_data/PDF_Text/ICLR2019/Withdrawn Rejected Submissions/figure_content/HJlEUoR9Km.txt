Figure 1: An example of an unrolling of the second order mean field iteration into a 5 layer neuralnetwork. The weights in all layers except the first one are shared, resulting in a deep network witha small number of parameters. The structure of the network is fully determined by the mean fieldequations derived from the energy function of Boltzmann machine.
Figure 2: Illustration of the structure of the Boltzmann machine and the training procedure. a) showsthe Boltzmann machine used in the first training step consisting of 16 visible units and 32 hiddenunits. The line between the visible and hidden units represents bipartite connectivity between theunits in the two sets. The loop on top of the hidden units indicates full connectivity between hiddenunits. 4 x 4 patches from the example data are used to generatively train the machine. b) showsthe structure of the Boltzmann machine used in the second training step, consisting of 64 visibleunits and 256 hidden units. The trained small machines are assigned a 4 x 4 sub-patch in the 8 x 8patches. Each of the 32 hidden units in the small machines gains bipartite connectivity to a furtherfully connected 128 hidden units and the full machine is trained according to the standard Boltzmannmachine training procedure.
Figure 3: Dependence of adversarial resistance and test error on Boltzmann machine pre-training fora neural network with a mean field Boltzmann network input layer. The blue plot shows the meansquare error (for image pixels in the range [0, 1]) required to create an adversarial image averagedover 1000 random samples from the MNIST test set as a function of the relative entropy D achievedin Boltzmann machine pre-training. Lower relative entropy at the pre-training stage results in higherresistance to adversarial attacks. The blue lines indicate the adversarial resistance for LeNet and apre-trained first RBM layer. Attached to the datapoints are examples of adversarial images at a givenrelative entropy. The orange line shows the test error (in %) of a mean field Boltzmann network overthe whole clean MNIST test set, with the straight orange lines showing the reference test error ofLeNet and a network with RBM pre training.
Figure 4: Response of a mean field Boltzmann network to noise at the input for different sets ofinput patterns. The inset shows how much adding random noise (uniformly distributed) of maxi-mum amplitude to the input pattern changes the output pattern. The main plot shows the ratioof the differences for the random and training set patterns as a function of training progress of theBoltzmann machine as measured by the relative entropy.
Figure 5: Histograms of the L2 distances of adversarial images after various attacks for a set of 1000images randomly selected from the MNIST training set. MFBM denotes the mean field Boltzmannmachine approach developed in this article. The vertical line indicates the cut-off = 1.5 used inTable 1.
Figure 6: The first images of each class in the randomly selected images from the MNIST test set,their adversarial images obtained by the Boundary Method and the difference to the original image.
Figure 7: Comparison of an exact solution to the Boltzmann machine and the fourth order meanfield method used in this article for different stages in the Boltzmann machine training. (a) Meanfield derived relative entropy as a function of the exact relative entropy. The relative entropy doesnot reach zero during training. (b) Probability of the first example as a function of exact relativeentropy. Red shows the mean field solution, blue the exact solution. (c) Probability of the secondexample as a function of exact relative entropy. (d) Ratio of the probabilities of first and secondexample.
Figure 8: Response ofa small mean field Boltzmann network to noise at the input for different sets ofinput patterns. The plot shows how much adding random noise (uniformly distributed) of maximumamplitude to the input pattern changes the output pattern. The red line shows the response averagedover the two training patterns, the blue line shows the response averaged over the remaining 30patterns.
Figure 9: Response of a small restricted mean field Boltzmann network to noise at the input for dif-ferent sets of input patterns. The plot shows how much adding random noise (uniformly distributed)of maximum amplitude to the input pattern changes the output pattern. The red line shows theresponse averaged over the two training patterns, the blue line shows the response averaged over theremaining 30 patterns.
