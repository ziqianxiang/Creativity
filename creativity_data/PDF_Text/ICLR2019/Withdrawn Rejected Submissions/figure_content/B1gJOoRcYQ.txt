Figure 1: An outline of our proposed model. Observations pass through a (recurrent) vision corenetwork, producing a “keys” and a “values” tensor, to both of which we concatenate a spatial basistensor (see text for details). A recurrent network at the top sends its state from the previous time-stepinto a query network which produces a set of query vectors (only one is shown here for brevity). Wecalculate the inner product between each query vector and each location in the keys tensor, then takethe spatial softmax to produce an attention map for the query. The attention map is broadcast alongthe channel dimension, point-wise multiplied with the values tensor and the result is then summedacross space to produce an answer vector. This answer is sent to the top RNN as input to producethe output and next state of the RNN.
Figure 2: Basic attention patterns. Bright areas are regions of high attention. Here we show 2 of the4 heads used (one head in each row, time goes from left to right). The model learns to attend keysprites such as the player and different enemies. Best viewed on a computer monitor. See text formore details.
Figure 3: Forward planning/scanning. We observe that in games where there is a clear mappingbetween image space and world space and some planning is required, the model learns to scanthrough possible future trajectories for the player and chooses ones that are safe/rewarding. Theimages show two such examples from Ms Pacman and Alien. Note how the paths follow the mapstructure. See text for more details and videos. Bright areas are regions of high attention.
Figure 4: Trip Wires. We observe in games where there are moving balls or projectiles that the agentsets up tripwires to create an alert when the object crosses a specific point or line. The agent learnshow much time it needs to react to the moving object and sets up a spot of attention sufficientlyfar from the player. In Breakout (top row), one can see a two level tripwire: initially the attentionis spread out, but once the ball passes some critical point it sharpens to focus on a point along thetrajectory, which is the point where the agent needs to move toward the ball. In Space Invaders(bottom row) we see the tripwire acting as a shield; when a projectile crosses this point the agentneeds to move away from the bullet. Bright areas are regions of high attention.
Figure 5: What/Where. This figures shows a sequence of 10 frames from Enduro (arranged left-to-right) along with the what-where visualization of each of the 3 of the 4 attention heads. (stackedvertically). The top row is the input frame at that timestep. Below we visualize the relative contri-bution of “what” vs. “where” in different attention heads: Red areas indicate the query has moreweight in the “what” section, while blue indicates the mass is in the “where” part. White areas in-dicate that the query is evenly balanced between what and where. We notice that the first head herescans the horizon for upcoming cars and then starts tracking them (swithing from mixed to “what”).
Figure 6: Saliency analysis. We run saliency analysis (see text for details) for the policy and valuefunctions for both ours and the baseline feedforward agent. We visualize saliency in green, and inthe case of our model the attention weights in white. We find that in the attention agent, one can seethat the policy saliency (b) corresponds to the head that is most focused on the immediate actionsof Pacman, while the the value saliency (d) corresponds to the head that is looking further ahead(two scales of planning/scanning behaviour). Comparing the saliency of the baseline and attentionagents, the attention agent exhibits sharper saliency, which looks along specific paths and followsthe contours of the map. The saliency of the baseline agent (a, c) shows the network is concernedwith shorter timescales and uses the score as the most important input to the value function (in someframes the value function does look at the map, but the majority of the time it is focused on thescene). See text for details and videos.
Figure 7: ImageNet classification on two dog images from ImageNet. The input image is tiled fourtimes. From left to right, the top row shows the input image then the four attention steps. The bottomrow shows the corresponding logit outputs at each timestep. By the third frame, the model is sureboth images are dogs, as indicated by similar class probability distributions. The attention snaps tospecific patches in the last frame to discern the specific dog breed.
Figure 8: Confusion on ImageNet. In the first image, the tree-filled background initially makesS3TA suspect the class is “lumbermill”. However, lumbermills are buildings full of mechanicalitems. The attention in the final frame focuses solely on the chainsaws, which become its final classchoice. In the second, the horse is occluded in this image, and so S3TA has to use other clues todistinguish between “shopping cart”, “barrow”, and “horse cart”. In the last frame, the attentionmaps focus on the horse whip on the right and the wheel type.
Figure 9: Focus on Key Items. The attention maps are disperse until a trumpet appears in view, atwhich point the class logits become very peaked. Bright areas are regions of high attention.
Figure 10: Performance of individual experts on selected ATARI games. Freeway and Ventureare omitted; no tested agent achieved a non-zero return on either game16Under review as a conference paper at ICLR 2019Level	Experts			Multi-level		Feedforward	LSTM	Attention	Feedforward	Attentionalien	-271.8%~~	~~03%^^	206.9%	26.8%	27.1%amidar	50.9%	2.7%	1138.9%	12.5%	15.9%assault	2505.8%	26.2%	6571.9%	80.3%	69.5%asterix	6827.5%	0.7%	9922.0%	14.2%	29.5%asteroids	75.3%	545.8%	626.3%	1.6%	2.7%atlantis	6320.7%	6161.6%	5820.0%	194.8%	136.4%bank_heist	184.0%	191.8%	168.5%	4.2%	1.7%battle_zone	151.9%	216.2%	2.1%	5.6%	2.6%beam_rider	172.3%	152.1%	132.7%	1.8%	1.4%berzerk	39.8%	353.6%	1844.3%	10.4%	12.1%bowling	35.1%	1.7%	9.0%	3.8%	3.1%boxing	832.5%	25.2%	743.6%	677.1%	32.5%breakout	2963.5%	2917.4%	2284.2%	15.0%	29.2%centipede	136.5%	12.7%	108.3%	43.1%	35.4%
Figure 11: Performance of individual experts on selected ATARI games. Freeway and Ventureare omitted; no tested agent achieved a non-zero return on either gamelevel name	Fixed Query Agent	L2 Norm Keys Agent	Top-Down Attention Agentamidar	225.7%	547.5%	903.6%asteroids	88.0%	126.4%	541.1%berzerk	285.3%	334.1%	1153.9%enduro	274.8%	274.5%	274.7%ms_pacman	198.4%	199.6%	414.3%Seaquest	1435.9%	49.4%	28.2%space_invaders	1798.1%	2395.2%	3512.8%	Table 5: The scores of the attention agent compared to the two bottom-up experiments described inthe text.
Figure 12: The distribution of attention weights on each head for a Ms Pacman and a Space Invadersframe. The two bar plots show the sum of the weights along the x and y axis (the range of each plotis [0, 1].
