Figure 1: Framework of mobile data privacy preserving. Mobile users leverage the learned Encoderto generate deep features from the raw data (i.e., ”tea bag” picture) before submit it. And the serviceprovider use the learned Classifier based on the received deep features, to recognize the object in thepicture and recommend a seller.
Figure 2: Architecture of reconstructive adversarial network (RAN).
Figure 4: 3D visualization of the highly separable features learned by standard DNN and RAN’sEncoder output in the feature space. Different color in each figure standards for one class.
Figure 5: Zoom in on two categories, i.e., sailboat and car in the feature space.
Figure 6: From left to right: raw image from ImageNet (Raw), image with Laplace noise (Noisy),images reconstructed from DNN’s features, resized DNN’s features, and RAN’s Encoder output.
Figure 7: A new manifold pushed by RAN to form the feature extractor, i.e., Encoder, for utility andprivacy. The utility-specified discriminative learning objective (Eq.(2)) push it to contain IOD andI⊥OD, and the privacy-imposed adversarial training objective (Eq(4)) pushes it away from sensitivecomponent I⊥OD .
