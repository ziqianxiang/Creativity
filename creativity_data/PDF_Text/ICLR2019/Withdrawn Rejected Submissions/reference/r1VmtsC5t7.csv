title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Thermometer encoding: One hotway to resist adversarial examples,2018, 2018
 Curriculum adversarial training,2018, arXiv preprintarXiv:1805
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Learning phrase representations using rnn encoder-decoderfor statistical machine translation,2014, arXiv preprint arXiv:1406
 Stochastic activation pruning for robust adversarial de-fense,2018, arXiv preprint arXiv:1803
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2017, arXiv preprint arXiv:1711
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, arXiv preprint arXiv:1801
 Cascade adversarial machine learning regu-larized with a unified embedding,2017, arXiv preprint arXiv:1708
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Defend deep neural networksagainst adversarial examples via fixed anddynamic quantized activation functions,2018, arXiv preprintarXiv:1807
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Attacking the madry defense model with l 1-based adversarialexamples,2018, In Proc
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Mitigating adversarialeffects through randomization,2017, arXiv preprint arXiv:1711
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Improving the robustness of deepneural networks via stability training,2016, In Proceedings of the ieee conference on computer visionand pattern recognition
 Distributionally adversarial attack,2018, arXiv preprintarXiv:1808
