title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 The Brunn-Minkowski inequality in Gauss space,1975, Inventiones mathematicae
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, arXiv preprint arXiv:1705
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Autoaugment:Learning augmentation policies from data,2018, arXiv preprint arXiv:1805
 Adversarial classification,2004, InProceedings of the tenth ACM SIGKDD international conference on Knowledge discovery anddata mining
 Keeping the bad guys out: Protecting and vaccinating deep learning withjpeg compression,2017, arXiv preprint arXiv:1705
 Quality resilient deep neural networks,2017, arXiv preprintarXiv:1703
 A study and comparison of human and deep learning recognitionperformance under visual distortions,2017, In Computer Communication and Networks (ICCCN)
 A study of the effect of jpgcompression on adversarial images,2016, arXiv preprint arXiv:1608
 Empiricalstudy of the topology and geometry of deep networks,2018, In IEEE CVPR
 Robustness of classifiers to uniform `pand Gaussian noise,2018, arXiv preprint arXiv:1802
 Motivating therules of the game for adversarial example research,2018, arXiv preprint arXiv:1807
 Adversarial spheres,2018, arXiv preprint arXiv:1801
 Countering adversarialimages using input transformations,2017, arXiv preprint arXiv:1711
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Benchmarking neural network robustness to commoncorruptions and surface variations,2018, arXiv preprint arXiv:1807
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Reluplex: An efficientsmt solver for verifying deep neural networks,2017, In International Conference on Computer AidedVerification
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Feature distillation: Dnn-oriented jpegcompression against adversarial examples,2018, arXiv preprint arXiv:1803
 The curse of concentrationin robust learning: Evasion and poisoning attacks from concentration of measure,2018, arXiv preprintarXiv:1809
 Deflectingadversarial attacks with pixel deflection,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 The elephant in the room,2018, arXiv preprintarXiv:1808
 Adver-sarially robust generalization requires more data,2018, arXiv preprint arXiv:1804
 Breaking the madry defense model with l1-based adversarialexamples,2017, arXiv preprint arXiv:1710
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Ensembleadversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Examining the impact of blur onrecognition by convolutional networks,2016, arXiv preprint arXiv:1611
 Mean squared error: Love it or leave it? a new look at signal fidelitymeasures,2009, IEEE Signal Processing Magazine
 Spatially transformedadversarial examples,2018, arXiv preprint arXiv:1801
 Mitigating adversarial effectsthrough randomization,2017, arXiv preprint arXiv:1711
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Improving the robustness of deepneural networks via stability training,2016, In Proceedings of the ieee conference on computer visionand pattern recognition
