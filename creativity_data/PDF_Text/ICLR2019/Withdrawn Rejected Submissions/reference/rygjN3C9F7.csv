title,year,conference
 Deep variational informationbottleneck,2017, arXiv preprint arXiv:1612
 Training deep generative models: Variations on a theme,2015, InNIPS Approximate Inference Workshop
 Quantifying uniqueinformation,2014, Entropy
 Equivalent comparisons of experiments,1953, The Annals of Mathematical Statistics
 Computation of channel capacity and rate-distortion functions,1972, IEEE Transactionson Information Theory
 Theory of classification: A survey ofsome recent advances,2005, ESAIM: Probability and Statistics
 Understanding disentangling in β-VAE,2018, arXiv preprintarXiv:1804
 Relevant sparse codes with variational informa-tion bottleneck,2016, In Advances in Neural Information Processing Systems
 Variational lossy autoencoder,2017, arXiv preprint arXiv:1611
 A class of measures of informativity of observation channels,1972, Periodica MathematicaHungarica
 Information theory: coding theorems for discrete memoryless sys-tems,2011, Cambridge University Press
 Conditional information bottleneck clustering,2003, In 3rd IEEEInternational Conference on Data Mining
 The information bottleneck revisited or how to choose a gooddistortion measure,2007, In Proc
 β-VAE: Learning basic visual concepts with a con-strained variational framework,2017, 2017
 Generalizing bottleneckproblems,2018, In Proc
 Auto-encoding variational Bayes,2013, arXiv preprintarXiv:1312
 Comparison of two noisy channels,1975, In Topics in informationtheory
 Auto-encoding sequentialMonte Carlo,2018, arXiv preprint arXiv:1705
 Sufficiency and approximate sufficiency,1964, The Annals of Mathematical Statistics
 MNIST handwritten digit database,2010, 2010
 Variational sequentialMonte Carlo,2018, In International Conference on Artificial Intelligence and Statistics
 Proper local scoring rules,2012, The Annals ofStatistics
 Tighter variational bounds are not necessarily better,2018, arXiv preprintarXiv:1802
 Taming VAEs,2018, arXiv preprint arXiv:1810
 Learning and generalization with the informationbottleneck,2008, In International Conference on Algorithmic Learning Theory
 Opening the black box of deep neural networks via informa-tion,2017, arXiv preprint arXiv:1703
 Deep learning and the information bottleneck principle,2015, InInformation Theory Workshop (ITW)
 The information bottleneck method,1999, InProceedings of the 37th Annual Allerton Conference on Communication
 Le Cam meets LeCun: Deficiency and genericfeature learning,2014, arXiv preprint arXiv:1402
 A theory of feature learning,2015, arXiv preprintarXiv:1504
 The role of information complexity andrandomization in representation learning,2018, arXiv preprint arXiv:1802
 A conditional entropy bound for a pair of discreterandom variables,1975, IEEE Transactions on Information Theory
 Towards deeper understanding of variationalautoencoding models,2017, arXiv preprint arXiv:1702
 The f -deficiency of μ w,2011,r
 The tightness of the boundis coupled to the expressiveness of the encoder distribution,2015, When qφ(z∣χ) is chosen as a simplediagonal Gaussian
