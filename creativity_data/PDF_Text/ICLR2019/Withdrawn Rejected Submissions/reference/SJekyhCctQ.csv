title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Thermometer encoding: One hotway to resist adversarial examples,2018, International Conference on Learning Representations
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, CoRR
" Magnet and ""efficient defenses against adversarial attacks""are not robust to adversarial examples",2017, CoRR
 Audio adversarial examples: Targeted attacks on speech-to-text,2018, CoRR
 Explaining and harnessing adversarialexamples,2014, CoRR
 In Simon N,2017, Foley
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, CoRR
 Adversarial examples for evaluating reading comprehension systems,2017, In EmpiricalMethods in Natural Language Processing (EMNLP)
 Adversarial logit pairing,2018, CoRR
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, CoRR
 A Simple Unified Framework for Detecting Out-of-DistributionSamples and Adversarial Attacks,2018, Advances in Neural Information Processing Systems 31
 Defense againstadversarial attacks using high-level representation guided denoiser,2017, CoRR
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, International Conference on Learning Representations
 Magnet: a two-pronged defense against adversarial examples,2017, CoRR
 The limitations of deep learning in adversarial settings,2015, CoRR
 Defense-GAN: Protecting classifiers againstadversarial attacks using generative models,2018, International Conference on Learning Representations
 Mastering the game of Gowith deep neural networks and tree search,2016, Nature
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2018, InternationalConference on Learning Representations
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Match-ing networks for one shot learning,2016, In D
 Mitigating adversarialeffects through randomization,2018, International Conference on Learning Representations
 Achieving human parity in conversational speech recognition,2016, CoRR
 Feature squeezing: Detecting adversarial examples in deepneural networks,2018, In Network and Distributed Systems Security Symposium (NDSS) 2018
