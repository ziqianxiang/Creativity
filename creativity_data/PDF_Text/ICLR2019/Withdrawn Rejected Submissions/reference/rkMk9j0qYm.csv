title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Parsevalnetworks: Improving robustness to adversarial examples,2017, In International Conference on MachineLearning
 Adversarial spheres,2018, arXiv preprint arXiv:1801
 Deep learning,2016,(2016)
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Early methods for detecting adversarial images,2017, 2017
 Generating adversarial malware examples for black-box attacks based ongan,2017, arXiv preprint arXiv:1702
 Adversarial attackson neural network policies,2017, arXiv preprint arXiv:1702
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Learning multiple layers of features from tiny images,2009, 2009
 Dense associative memory is robust to adversarial inputs,2017, arXivpreprint arXiv:1701
 Practical evasion of a learning-based classifier: A case study,2014, In Security andPrivacy (SP)
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Generative adversarial trainer: Defense to adver-sarial perturbations with gan,2017, arXiv preprint arXiv:1705
 Delving into transferable adversarial exam-ples and black-box attacks,2016, arXiv preprint arXiv:1611
 Foveation-based mecha-nisms alleviate adversarial examples,2016, Technical report
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of 2016 IEEE Conference onComputer Vision and Pattern Recognition (CVPR)
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Breaking the madry defense model with l_1-based adversarialexamples,2017, arXiv preprint arXiv:1710
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensembleadversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 The spaceof transferable adversarial examples,2017, arXiv preprint arXiv:1704
 Aggregated residual trans-formations for deep neural networks,2017, In Computer Vision and Pattern Recognition (CVPR)
 Automatically evading classifiers,2016, In Proceedings of the2016 Network and Distributed Systems Symposium
