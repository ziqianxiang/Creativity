title,year,conference
 Understanding and simplifyingone-shot architecture search,2018, In Jennifer Dy and Andreas Krause (eds
 Speeding up automatic hyperparameter optimization ofdeep neural networks by extrapolation of learning curves,2015, In IJCAI
 Asymptotic minimax character of the sample distributionfunction and of the classical multinomial estimator,1956, The Annals of Mathematical Statistics
 Bohb: Robust and efficient hyperparameter optimiza-tion at scale,2018, In International Conference on Machine Learning
 Google vizier: A service forblack-box optimization,2017, In KDD
 Batch bayesian optimization via localpenalization,2016, In AISTATS
 Population based training of neural networks,2017, arXiv:1711
 Non-stochastic best arm identification and hyperparameter optimiza-tion,2015, In AISTATS
 Almost optimal exploration in multi-armed bandits,2013, In ICML
 Fast bayesian optimization of machinelearning hyperparameters on large datasets,2017, AISTATS
 Learning multiple layers of features from tiny images,2009, In Technical report
 Hyperband: Bandit-basedconfiguration evaluation for hyperparameter optimization,2017, Proc
 Building a large annotated corpus of english: Thepenn treebank,1993, Computational Linguistics
 Regularizing and optimizing LSTM language models,2018, InInternational Conference on Learning Representations
 Reading digits in natural images with unsupervised feature learning,2011, In NIPSWorkshop on Deep Learning and Unsupervised Feature Learning
 Large-scaleevolution of image classifiers,2017, In ICML
 Convolutional neural networks applied to house numbersdigit classification,2012, In ICPR
 Freeze-thaw bayesian optimization,2014, arXiv:1406
 Neural architecture search with reinforcement learning,2017, In ICLR
 For the experiments in Section 4,2000,2
