title,year,conference
 Deep Relaxation: Partial Differ-ential Equations for Optimizing Deep Neural Networks,2017, pp
 An analysis of single-layer networks in unsupervisedfeature learning,2011, In Proceedings of the 14th AISTATS
 Deep Learning,2016, MIT Press
 Recent advances in convolutionalneural networks,2018, Pattern Recognition
 Stable architectures for deep neural networks,2017, Inverse Problems
 Identity mappings in deep residualnetworks,2016, In European Conference on Computer Vision
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Tensor-tensor products with invertible lineartransforms,2015, Linear Algebra and its Applications
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Imagenet classification with deep convolutional neuralnetworks,2012, Adv Neural Inf Process Syst
 Learning multiple layers of features from tiny images,2009, 2009
 Handwritten digit recognition with a back-propagationnetwork,1990, In Advances in neural information processing systems
 Fast Training of Convolutional Networksthrough FFTs,2013, December 2013
 Image classification using local tensor singularvalue decompositions,2017, arXiv
 Automatic differentiation inpytorch,2017, In Advances in Neural Information Processing Systems
 Large-scale deep unsupervised learning us-ing graphics processors,2009, In 26th ICML
 A Stochastic Approximation Method,1951, Ann
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Learning structured sparsity indeep neural networks,2016, In Advances in Neural Information Processing Systems
