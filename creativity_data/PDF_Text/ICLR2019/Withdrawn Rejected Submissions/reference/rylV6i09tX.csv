title,year,conference
 Negative eigenvalues of thehessian in deep neural networks,2018, 2018
 Improving the convergence of back-propagation learning withsecond order methods,1988, In Proceedings ofthe 1988 ConnectionistmodeIs summer school
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Entropy-sgd: Biasing gradient descent into wide valleys,2017, In InternationalConference on Learning Representations (ICLR)
 Parsevalnetworks: Improving robustness to adversarial examples,2017, In International Conference on MachineLearning
 Sharp minima can generalize fordeep nets,2017, In International Conference on Machine Learning
 Qualitatively characterizing neural networkoptimization problems,2015, In International Conference on Learning Representations (ICLR)
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 An empirical analysis of deep network losssurfaces,2017, arXiv preprint arXiv:1612
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Deep learning without poor local minima,2016, In Advances in Neural InformationProcessing Systems
 On large-batch training for deep learning: Generalization gap and sharp minima,2017, InInternational Conference on Learning Representations (ICLR)
 Deep learning via hessian-free optimization,2010, In International Conference on MachineLearning
 Unifying adversarial training algorithmswith flexible deep data gradient regularization,2016, arXiv preprint arXiv:1601
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Improving the adversarial robustness and interpretabilityof deep neural networks by regularizing their input gradients,2018, In AAAI
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
