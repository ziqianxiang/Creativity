title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Thermometer encoding: One hot wayto resist adversarial examples,2018, In International Conference on Learning Representations
 Towards evaluating the robustness of neural networks,2016, CoRR
" Magnet and ""efficient defenses against adversarial attacks""are not robust to adversarial examples",2017, CoRR
 Stochastic activation pruning for robustadversarial defense,2018, In International Conference on Learning Representations
 Robust physical-world attacks on deep learningvisual classification,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Usinggenerative adversarial networks for improving classification effectiveness in credit card frauddetection,2017, Information Sciences
 Explaining and harnessing adversarialexamples,2014, CoRR
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations
 DSD: Dense-Sparse-Dense Training for Deep Neural Networks,1607, arXiv:1607
 Deep residual learning for imagerecognition,2015, CoRR
 Adversarial machine learning at scale,2016, CoRR
 Magnet: A two-pronged defense against adversarial examples,2017, InProceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security
 On detecting adversarialperturbations,2017, CoRR
 Deepfool: a simple andaccurate method to fool deep neural networks,2015, CoRR
 Cascade adversarial machine learningregularized with a unified embedding,2017, CoRR
 Deep neural networks are easily fooled: Highconfidence predictions for unrecognizable images,2015, In IEEE Conference on Computer Vision andPattern Recognition
 The limitations of deep learning in adversarial settings,2015, CoRR
 Technical report on the cleverhans v2,2018,1
 Deepxplore: Automated whitebox testing ofdeep learning systems,2017, In Proceedings of the 26th Symposium on Operating Systems Principles
 Foolbox: A python toolbox to benchmarkthe robustness of machine learning models,2017, arXiv preprint arXiv:1707
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, In International Conference on LearningRepresentations
 Robust perception throughanalysis by synthesis,2018, CoRR
 Attacking the madry defense model with l1-based adversarialexamples,2017, CoRR
 Very deep convolutional networks for large-scale imagerecognition,2014, CoRR
 Interpret neural networks by identifying criticaldata routing paths,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Mitigating adversarial effectsthrough randomization,2018, In International Conference on Learning Representations
