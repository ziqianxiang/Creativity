title,year,conference
 Learning to learn by gradient descent by gradient descent,2016, In Advances inNeural Information Processing Systems
 A Contextual Bandit Bake-off,2018, working paper orpreprint
 Random forests,0885, Mach
 Search-based structured prediction,1573, MachineLearning
 Efficient optimal learning for contextual bandits,2011, arXiv preprint arXiv:1106
 Learning how to active learn: A deep reinforcement learningapproach,2017, In EMNLP
 Random forest for thecontextual bandit problem,2016, In Arthur Gretton and Christian C
 Meta-reinforcement learning of structured exploration strategies,2018, arXiv preprint arXiv:1802
 Associative reinforcement learning: Functions ink-dnf,1994, Machine Learning
 Efficient bandit algorithms for onlinemulticlass prediction,2008, In ICML
 Multi-armed bandits: Competing with opti-mal sequences,2016,	In D
 Learning active learning from data,2017, InAdvances in Neural Information Processing Systems
 The epoch-greedy algorithm for multi-armed bandits with sideinformation,2008, In Advances in Neural Information Processing Systems 20
 Learning to optimize,2016, arXiv preprint arXiv:1606
 A contextual-bandit approach topersonalized news article recommendation,2010, In Proceedings of the 19th International Conferenceon World Wide Web
 A note on plattâ€™s probabilistic outputs for supportvector machines,1573, Machine Learning
 Probabilistic outputs for support vector machines and comparisons to regularizedlikelihood methods,1999, In ADVANCES IN LARGE MARGIN CLASSIFIERS
 Reinforcement and imitation learning via interactive no-regretlearning,2014, arXiv preprint arXiv:1406
 Generalization in reinforcement learning: Successful examples using sparse coarsecoding,1996, In Advances in neural information processing systems
 Introduction to Reinforcement Learning,0262, MIT Press
 Active one-shot learning,2017, arXiv preprint arXiv:1702
 Learning to explore with meta-policygradient,2018, arXiv preprint arXiv:1803
 Neural architecture search with reinforcement learning,2016, arXiv preprintarXiv:1611
