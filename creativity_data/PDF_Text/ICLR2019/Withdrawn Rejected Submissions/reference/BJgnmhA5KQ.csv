title,year,conference
 Generating sentences from a continuous space,2016, In SIGNLL Conference on ComputationalNatural Language Learning
 Latent variable dialogue models and their diversity,2017, arXiv preprintarXiv:1702
 Report on the 11th iwslt evaluationcampaign,2014, In Proc
 Towards diverse and natural image descrip-tions via a conditional gan,2017, arXiv preprint arXiv:1703
 Learning factored representations in a deepmixture of experts,2014, arXiv:1312
 deltableu: A discriminative metric for generationtasks with intrinsically diverse targets,2015, arXiv preprint arXiv:1506
 ConvolutionalSequence to Sequence Learning,2017, In Proc
 Generating sequences with recurrent neural networks,2013, arXiv:1308
 Achieving humanparity on automatic chinese to english news translation,2018, arXiv preprint arXiv:1803
 Sequence to sequence mixture model fordiverse machine translation,2018, arXiv preprint arXiv:1810
 Fast decoding in sequence models using discrete latent variables,2018, arXiv:1803
 Adam: A Method for Stochastic Optimization,2015, In InternationalConference on Learning Representations (ICLR)
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Why mheads are better than one: Training a diverse ensemble of deep networks,2015, arXiv:1511
 Stochastic multiple choice learning for training diverse deep ensembles,2016, In NIPS
 Mutual information and diverse decoding improve neural machine trans-lation,2016, arXiv preprint arXiv:1601
 Analyzing uncertainty inneural machine translation,2018, In International Conference of Machine Learning
 Bleu: a method for automaticevaluation of machine translation,2002, In Proceedings of the 40th annual meeting on association forcomputational linguistics
 Neural machine translation of rare words withsubword units,2016, In Conference of the Association for Computational Linguistics (ACL)
 A hierarchical latent variable encoder-decoder model for gen-erating dialogues,2017, In AAAI
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, InInternational Conference on Learning Representations
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, InInternational Conference on Learning Representations
 Diverse beam search: Decoding diverse solutions from neural se-quence models,2016, arXiv preprint arXiv:1610
 Diverse and accurate image descriptionusing a variational auto-encoder with an additive gaussian encoding space,2017, In Advances in NeuralInformation Processing Systems
 Variational neural machinetranslation,2016, arXiv preprint arXiv:1605
