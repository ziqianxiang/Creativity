title,year,conference
 Poisoning complete-linkage hierarchical clustering,2014, In Joint IAPRInternational Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structuraland Syntactic Pattern Recognition (SSPR)
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Show-and-fool: Craftingadversarial examples for neural image captioning,2017, arXiv:1712
 EAD: elastic-net attacks todeep neural networks via adversarial examples,2017, arXiv:1709
 Seq2sick: Evaluating therobustness of sequence-to-sequence models with adversarial examples,2018, arXiv:1803
 Robust physical-world attacks on deep learning models,2017, arXiv:1707
 AI2: Safety and robustness certification of neural networks with abstractinterpretation,2018, In IEEE Symposium on Security and Privacy
 Explaining and harnessing adversarialexamples,2014, arXiv:1412
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Densely connectedconvolutional networks,2017, In 2017 IEEE Conference on Computer Vision and Pattern Recognition
 Reluplex: An efficientsmt solver for verifying deep neural networks,2017, In International Conference on Computer AidedVerification
 Imagenet classification with deep convolu-tional neural networks,2012, In NIPS
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 The security of latent dirichlet allocation,2015, In Artificial Intelligence andStatistics
 Univer-sal adversarial perturbations against semantic image segmentation,2017, In The IEEE InternationalConference on Computer Vision
 Antidote: understanding and defending against poisoning of anomalydetectors,2009, In ACM SIGCOMM Conference on Internet Measurement
 Adver-sarially robust generalization requires more data,2018, arXiv:1804
 Masteringthe game of go with deep neural networks and tree search,2016, Nature
 Certifiable distributional robustness withprincipled adversarial training,2017, arXiv:1710
 Identify susceptible locations inmedical records via adversarial attacks on deep predictive models,2018, arXiv:1802
 Intriguing properties of neural networks,2013, arXiv:1312
 Generating adversarialexamples with adversarial networks,2018, arXiv:1801
 Spatially transformedadversarial examples,2018, arXiv:1801
 Foolingvision and language models despite localization and attention mechanism,2018, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition
 Generative poisoning attack method against neuralnetworks,2017, arXiv:1703
