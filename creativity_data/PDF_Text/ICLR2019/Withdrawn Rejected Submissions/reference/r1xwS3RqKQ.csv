title,year,conference
 Learning activation functionsto improve deep neural networks,2014, arXiv preprint arXiv:1412
 Neural machine translation by jointlylearning to align and translate,2014, arXiv preprint arXiv:1409
 Universal approximation bounds for superpositions of a sigmoidal function,1993, IEEETransactions on Information theory
 Neural optimizer search withreinforcement learning,2017, arXiv preprint arXiv:1709
 Delving deeP into rectifiers: SurPassinghuman-level Performance on imagenet classification,2015, In Proceedings of the IEEE internationalconference on computer vision
 DeeP residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Multilayer feedforward networks areuniversal aPProximators,1989, Neural networks
 Mobilenets: Efficient convolutional neural networks formobile vision aPPlications,2017, arXiv preprint arXiv:1704
 Adam: A method for stochastic oPtimization,2014, arXiv preprintarXiv:1412
 Self-normalizingneural networks,2017, arXiv preprint arXiv:1706
 Imagenet classification with deepconvolutional neural networks,2012, In Advances in neural information processing systems
 Deep learning,2015, Nature
 Superviseddictionary learning,2009, In Advances in neural information processing systems
 Taming the waves: sine asactivation function in deep neural networks,2016, 2016
 Searching for activation functions,2017, arXiv preprintarXiv:1710
 Advances in kernel methods:support vector learning,1999, MIT press
 Kernel methods for pattern analysis,2004, Cambridge universitypress
 Neural networks with periodic and monotonicactivation functions: a comparative study in classification problems,1999, 1999
 Empirical evaluation of rectified activations inconvolutional network,2015, arXiv preprint arXiv:1505
 Learning transferable architecturesfor scalable image recognition,2017, arXiv preprint arXiv:1707
