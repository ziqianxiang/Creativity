title,year,conference
 Threat of adversarial attacks on deep learning in computer vision:A survey,2018, arXiv preprint arXiv:1801
 Synthesizing robust adversarial examples,2017, arXiv preprintarXiv:1707
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Training verified learners with learned ver-ifiers,2018, arXiv preprint arXiv:1805
 Analysis of classifiers robustness to adversarialperturbations,2018, Machine Learning
 Explaining and harnessing adversarialexamples,2015, arXiv preprint arXiv:1412
 Learn to pay attention,2018, arXivpreprint arXiv:1804
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, arXiv preprint arXiv:1711
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Cascade adversarial machine learning regu-larized with a unified embedding,2017, arXiv preprint arXiv:1708
 Deflectingadversarial attacks with pixel deflection,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Progressive attentionnetworks for visual attribute prediction,2016, arXiv preprint arXiv:1606
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Built-in vulnerabilities to imperceptibleadversarial perturbations,2018, arXiv preprint arXiv:1806
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
