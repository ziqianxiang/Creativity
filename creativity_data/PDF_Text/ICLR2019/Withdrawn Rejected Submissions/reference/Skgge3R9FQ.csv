title,year,conference
 Towards open set deep networks,2016, In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition
 Learning deep architectures for ai,2009, Foundations and trendsÂ® in Machine Learning
 Adversarial examples are not easily detected: Bypassing ten detectionmethods,2017, Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Towards evaluating the robustness of neural networks,2017, In Security andPrivacy (SP)
 A downsampled variant of imagenet as an alternative tothe cifar datasets,2017, arXiv preprint arXiv:1707
 Detecting adversarial samples fromartifacts,2017, arXiv preprint arXiv:1703
 Identity mappings in deep residual networks,2016, InEuropean Conference on Computer Vision
 A baseline for detecting misclassified and out-of-distribution examples inneural networks,2016, arXiv preprint arXiv:1610
 Introspective classification with convolutional nets,2017, In Advances inNeural Information Processing Systems
 Adversarial examples in the physical world,2016, arXiv preprintarXiv:1607
 Adversarial machine learning at scale,2016, arXiv preprintarXiv:1611
 Adversarial examples in the physical world,2017, InternationalConference on Learning Representations
 Simple and scalable predictive uncertaintyestimation using deep ensembles,2017, In Advances in Neural Information Processing Systems
 Gradient-based learning applied to documentrecognition,1998, Proceedings of the IEEE
 Training confidence-calibrated classifiers for detectingout-of-distribution samples,2017, arXiv preprint arXiv:1711
 Towards deeplearning models resistant to adversarial attacks,2017, arXiv preprint arXiv:1706
 Deepfool: a simple and accuratemethod to fool deep neural networks,2016, In IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Deepfool: a simple and accuratemethod to fool deep neural networks,2016, In IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Denoising autoencoders for overgeneralization in neural networks,2017, arXiv preprintarXiv:1709
 Intriguing properties of neural networks,2014, In International Conference on Learning Representations
 Ensemble adversarialtraining: Attacks and defenses,2017, arXiv preprint arXiv:1705
 11 adversarial perturbations of deep neural networks,2016, Perturbations
 Feature squeezing: Detecting adversarial examples in deep neuralnetworks,2018, Network and Distributed System Security Symposium
