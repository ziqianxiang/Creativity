title,year,conference
 Discriminative k-shot learning using probabilistic models,2017, arXiv preprintarXiv:1706
 Multitask learning,1998, In Learning to learn
 Model-agnostic meta-learning for fast adaptation ofdeep networks,2017, In Proceedings of the 34th International Conference on Machine Learning (ICML)
 Knowledge transfer via multiple model local structuremapping,2008, In Proceedings of the 14th ACM SIGKDD Conference on Knowledge Discovery andData Mining (KDD)
 Few-shot learning with graph neural networks,2017, arXiv preprintarXiv:1711
 Recasting gradient-based meta-learning as hierarchical Bayes,2018, In Proceedings of the 6th International Conference onLearning Representations (ICLR)
 Neural expectation maximization,2017, InAdvances in Neural Information Processing Systems
 Solving a huge number of similar tasks: A combination of multi-task learning and ahierarchical Bayesian approach,1998, In Proceedings of the 15th International Conference on MachineLearning (ICML)
 Overcomingcatastrophic forgetting in neural networks,2017, Proceedings of the National Academy of Sciences
 Learning to learn with the informative vector machine,2004, InProceedings of the 21st International Conference on Machine Learning (ICML)
 A simple neural attentive meta-learner,2018, In Proceedings of the 6th International Conference on Learning Representations (ICLR)
 Issues in bayesian analysis of neural network models,1998, NeuralComputation 
 Meta networks,2017, In Proceedings of the 34th InternationalConference on Machine Learning (ICML)
 Tadam: Task dependent adaptive metricfor improved few-shot learning,2018, In Advances in Neural Information Processing Systems (NIPS)
 The infinite gaussian mixture model,2000, In Advances in neural informationprocessing systems
 Optimization as a model for few-shot learning,2017, In Proceedings ofthe 5th International Conference on Learning Representations (ICLR)
 What to do when k-meansclustering fails: a simple yet principled alternative algorithm,2016, PloS one
 A stochastic approximation method,1951, The annals of mathematicalstatistics
 To transfer ornot to transfer,2005, In NIPS 2005 workshop on transfer learning
 Meta-learning with latent embedding optimization,2018, arXiv preprintarXiv:1807
 Learning with hierarchical-deepmodels,2013, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Meta-learning with memory-augmented neural networks,2016, In Proceedings of the 33rd InternationalConference on Machine Learning (ICML)
 Evolutionary principles in Self-referential learning,1987, PhD thesis
 Prototypical networks for few-shot learning,2017, InAdvances in Neural Information Processing Systems (NIPS) 30
 Few-shot learning through an informationretrieval lens,2017, In Advances in Neural Information Processing Systems (NIPS) 30
 Matching networks for one shotlearning,2016, In Advances in Neural Information Processing Systems (NIPS) 29
 Sparse Bayesian multi-task learning forpredicting cognitive outcomes from neuroimaging measures in Alzheimerâ€™s disease,2012, In IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Learning Gaussian processes from multiple tasks,2005, InProceedings of the 22nd International Conference on Machine Learning (ICML)
 Learning multiple tasks with a sparse matrix-normal penalty,2010, InAdvances in Neural Information Processing Systems
 A regularization approach to learning task relationships in multitasklearning,2014, ACM Transactions on Knowledge Discovery from Data (TKDD)
 This is potentially due to the fact that all the tasks are derived from the same core set ofimages,2000, Accordingly
