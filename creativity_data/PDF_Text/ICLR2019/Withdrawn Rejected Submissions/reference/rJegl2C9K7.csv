title,year,conference
 N2n learning: Network tonetwork compression via policy gradient reinforcement learning,2018, In ICLR
 Adversarial network compression,2018, arXivpreprint arXiv:1803
 Deep residual learning for imagerecognition,2016, In CVPR
 Distilling the knowledge in a neural network,2014, InNIPS Workshop
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Squeeze-and-excitation networks,2018, In CVPR
 Densely connectedconvolutional networks,2017, In CVPR
 Like what you like: Knowledge distill via neuron selectivitytransfer,2017, arXiv preprint arXiv:1707
 Imagenet classification with deepconvolutional neural networks,2012, In NIPS
 Self-supervised knowledge distillationusing singular value decomposition,2018, In ECCV
 Pruning filters forefficient convnets,2017, In ICLR
 Microsoft coco: Common objects in context,2014, In ECCV
 Focal loss for dense objectdetection,2017, In ICCV
 PrUning convolUtionalneUral networks for resoUrce efficient inference,2017, In ICLR
 Fitnets: Hints for thin deep nets,2015, In ICLR
 Very deep convolUtional networks for large-scale imagerecognition,2015, In ICLR
 Progressive blockwise knowledge distillation for neUralnetwork acceleration,2018, In IJCAI
 Paying more attention to attention: Improving theperformance of convolUtional neUral networks via attention transfer,2017, In ICLR
 Efficient and accUrateapproximations of nonlinear convolUtional networks,2015, In CVPR
