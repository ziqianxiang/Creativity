title,year,conference
 How to make the gradients small stochastically,2018, CoRR
 Theory of convex optimization for machine learning,2014, CoRR
 Identity mappings in deep residualnetworks,2016, In ECCV (4)
 Deep residual learning for image recog-nition,2016, In CVPR
 Accelerat-ing stochastic gradient descent,2017, arXiv preprint arXiv:1704
 On the insufficiency ofexisting momentum schemes for stochastic optimization,2018, CoRR
 Adam: A method for stochastic optimization,2014, CoRR
 Imagenet classification with deep convo-lutional neural networks,2012, In NIPS
 Stochastic Approximation and Optimization of Ran-dom Systems,1992, Birkhauser Verlag
 Sgdr: Stochastic gradient descent with restarts,2016, ”CoRR”
 Problem Complexity and Method Efficiency in Opti-mization,1983, John Wiley
 Making gradient descent optimal forstrongly convex stochastic optimization,2012, In ICML
 Efficient estimations from a slowly convergent robbins-monro process,1988, Tech
 Super-convergence: Very fast training of residual networksusing large learning rates,2017, arXiv preprint arXiv:1708
