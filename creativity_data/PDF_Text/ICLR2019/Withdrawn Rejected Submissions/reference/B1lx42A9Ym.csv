title,year,conference
 Spectrally-normalized margin bounds for neuralnetworks,2017, Advances in Neural Information Processing Systems (NIPS)
 A Probabilistic Theory of Pattern Recognition,1996, StochasticModelling and Applied Probability
 Adversarial feature learning,2017, In International Conferenceon Learning Representations
 Central limit theorems for empirical measures,1978, Annals of Probability
 Shake-shake regularization of 3-branch residual networks,2017, In International Conferenceon Learning Representations
 Generative adversarial nets,2014, In Advances in Neural Information Processing Systems 27
 Deep residual learning for image recognition,2016, In Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition
 Squeeze-and-excitation networks,2018, In The IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Auto-encoding variational bayes,2013, arXiv preprint arXiv:1312
 Empirical margin distributions and bounding the generalizationerror of combined classifiers,2002, Annals of Statistics
 Temporal ensembling for semi-supervised learning,2017, In International Conferenceon Learning Representations
 Sgdr: Stochastic gradient descent with warm restarts,2016, In InternationalConference on Learning Representations
 Path-sgd: Path-normalized optimization in deepneural networks,2015, In Advances in Neural Information Processing Systems
 Semi-supervised learning with thedeep rendering mixture model,2016, arXiv preprint arXiv:1612
 Theoretical foundations of deep learning viasparse representations: A multilayer sparse model and its connection to convolutional neuralnetworks,1053, IEEE Signal Processing Magazine
 A probabilistic theory of deep learning,2015, arXiv preprintarXiv:1504
 A probabilistic framework for deep learning,2016, InAdvances in Neural Information Processing Systems 29
 Predictive coding in the visual cortex: a functional interpretation ofsome extra-classical receptive-field effects,1999, Nature Neuroscience
 Semi-supervised learning withladder networks,2015, In Advances in Neural Information Processing Systems 28
 A stochastic approximation method,1985, In Herbert Robbins Selected Papers
 Going deeper with convolutions,2015, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Mean teachers are better role models: Weight-averaged consistency tar-gets improve semi-supervised deep learning results,2017, In Advances in Neural Information ProcessingSystems 30
 Empirical Processes in M-estimation,2000, Cambridge University Press
 Introduction to the non-asymptotic analysis of random matrices,2011, arXiv:1011
 Aggregated residual transformations for deep neuralnetworks,2017, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
3 in the main text,2019, Remind that
 Lemma 3,2000,1 in van de Geer (2000))
