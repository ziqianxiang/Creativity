title,year,conference
 Information geometry on hierarchy of Probability distributions,2001, IEEE Transactions onInformation Theory
 Singularities affect dynamics of learning inneuromanifolds,2006, Neural Computation
 Statistical Neurodynamics of DeeP Net-works: Geometry of Signal SPaces,2018, Technical rePort
 Fisher Information and Natural GradientLearning of Random DeeP Networks,2018, Technical rePort
 More Is Different,1972, Science
 A Probabilistic Framework for DeeP Learn-ing,2016, In NIPS
 On Invariance and Selectivity in RePresen-tation Learning,2016, Information and Inference
 Theory of ReProducing Kernels,1950, Transactions of the American Mathematical Society
 Provable Bounds for Learning SomeDeeP RePresentations,2014, In ICML
 Real analysis and probability,1972, Probability and mathematical statistics
 Dynamics of Complex Systems,1997, Perseus Books
 Statistical Modeling: The Two Cultures,2001, Statistical Science
 The Loss Surfaces of Multilayer Net-works,2015, In AISTATS
 Open Problem: The landscape of the losssurfaces of multilayer networks,2015, In COLT
 Group Equivariant Convolutional Networks,2016, In ICML
 Identifying and attacking the saddle point problem in high-dimensional non-convex op-timization,2014, In NIPS
 Exploiting Cyclic Symmetry in Con-volutional Neural Networks,2016, In ICML
 Linear operators,1957, Part 1: General theory
 Random Matrices with Slow CorrelationDecay,2017, Technical report
 Neocognitron: A Self-organizing Neural Network Model for a Mechanismof Pattern Recognition Unaffected by Shift in Position,1980, Biological Cybernetics
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In AISTATS
 Deep Sparse Rectifier Neural Networks,2011, InAISTATS
 Delving Deep into Rectifiers: SurpassingHuman-Level Performance on ImageNet Classification,2015, In ICCV
 Deep Residual Learning for ImageRecognition,2016, In CVPR
 A fast learning algorithm for deep beliefnets,2006, Neural Computation
 Batch Normalization : Accelerating Deep Network Trainingby Reducing Internal Covariate Shift,2015, In ICML
 Geometry of Neural Network Loss Surfaces via Random MatrixTheory,2017, In ICML
 Deep Learning without Poor Local Minima,2016, In NIPS
 ImageNet Classification with Deep Con-volutional Neural Networks,2012, In NIPS
 Deep linear neural networks with arbitrary loss: All localminima are global,2018, In ICML
 Gradient-based learning applied to document recog-nition,1998, Proceedings of the IEEE
 Deep learning,2015, Nature
 Understanding the Loss Surface of NeuralNetworks for Binary,2018, In ICML
 Matrix differential calculus with applications in statistics andeconometrics: 3rd,2007, ed
 Understanding Deep Image Representations by InvertingThem,2015, In CVPR
 Convolutional Kernel Net-works,2014, In NIPS
 Group Invariant Scattering,2012, Communications on Pure and Applied Mathematics
 Understanding deep convolutional networks,2016, Philosophical transactions
 Complex Systems: A Survey,2009, Physics Reports
 The loss surface of deep and wide neural networks,2017, In ICML
 Optimization Landscape and Expressivity of Deep CNNs,2018, InICML
 Searching for Activation Functions,2017, Technicalreport
 Models of object recognition,2000, Nature Neuroscience
 Hierarchical models of object recognition in cortex,1999, Natureneuroscience
 The PercePtron: a Probabilistic model for information storage and organization in thebrain,1958, Psychological review
 Weight Normalization: A SimPle ReParameterization toAccelerate Training of DeeP NeUral Networks,2016, In NIPS
 OPening the Black Box of DeeP NeUral Networks via Infor-mation,2017, Technical rePort
 The ArchitectUre of ComPlexity,1962, Proceedings of the American PhilosophicalSociety
 Mathematics of the NeUral Re-sPonse,2009, Foundations of Computational Mathematics
 ExPectation ProPagation : a Probabilistic view of DeeP Feed Forward Net-works,2018, Technical rePort
 AUto-Encoding Variational Bayes,2014, In ICLR
 Statistical properties of real symmetric matrices with many dimensions,1957,pdf
