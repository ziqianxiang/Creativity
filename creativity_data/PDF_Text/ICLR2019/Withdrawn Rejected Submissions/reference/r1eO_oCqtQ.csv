title,year,conference
 Skip RNN:learning to skip state updates in recurrent neural networks,2017, CoRR
 Learning phrase representations using RNN Encoder-Decoder forstatistical machine translation,2014, In Proceedings of the 2014 Conference on Empirical Methodsin Natural Language Processing (EMNLP)
 Recurrent batch normal-ization,2016, CoRR
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Yee Whye Teh and Mike Titterington (eds
 Long short-term memory,0899, Neural Comput
 An empirical exploration of recurrentnetwork architectures,2015, In International Conference on Machine Learning
 Adam: A method for stochastic optimization,2014, CoRR
 A clockwork RNN,2014, CoRR
 Zoneout: RegularizingRNNs by randomly preserving hidden activations,2016, arXiv preprint arXiv:1606
 Gradient-based learning applied todocument recognition,0018, Proceedings of the IEEE
 A critical review of recurrent neural networks for sequence learning,2015, CoRR
 Deep learning in neural networks: An overview,2014, Neural Networks
 Distribution-specific hardness of learning neural networks,2016, CoRR
 Can recurrent neural networks warp time,2018, In Proceedings ofInternational Conference on Learning Representation
 Learning longer-term dependenciesin RNNs with auxiliary losses,2018, CoRR
 Regularization of neuralnetworks using DropConnect,2013, In International Conference on Machine Learning
 Learning to skim text,2017, CoRR
