title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, CoRR
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Robust physical-world attacks on deep learning models,2017, arXiv preprintarXiv:1707
 Fast r-cnn,2015, In Proceedings of the IEEE international conference on computer vision
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Imagenet classification with deep convo-Iutional neural networks,2012, In Advances in neural information processing systems
 Magnet: a two-pronged defense against adversarial examples,2017, InProceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security
 Ssh: Single stage headlessface detector,2017, In ICCV
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Accessorize to a crime:Real and stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 ACMSIGSAC Conference on Computer and Communications Security
 Ape-gan: Adversarial perturbationelimination with gan,2017, ICLR Submission
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Efficient defenses against adver-sarial attacks,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security
