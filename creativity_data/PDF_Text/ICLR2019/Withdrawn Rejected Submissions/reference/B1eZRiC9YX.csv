title,year,conference
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, arXiv preprint arXiv:1705
 Boost-ing adversarial attacks with momentum,2017, arXiv preprint arXiv:1710
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 Uncertainty in deep learning,2016, PhD thesis
 Concrete dropout,2017, NIPS
 Adversarial spheres,2018, CoRR
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Bayesian learning for neural networks,1995, PhD thesis
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Adversarial phenomenon in the eyes ofBayesian deep learning,2017, arXiv preprint arXiv:1711
 Very deep convolutional networks for large-scale image recogni-tion,2015, In International Conference on Learning Representations
 Understanding measures of uncertainty for adversarial example detec-tion,2018, UAI
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 A boundary tilting persepective on the phenomenon of adversarialexamples,2016, arXiv preprint arXiv:1608
 Convolutional Gaussian pro-cesses,2017, In Advances in Neural Information Processing Systems
 Malware detection in adversarial settings:Exploiting feature evolutions and confusions in android apps,2017, In Proceedings of the 33rd AnnualComputer Security Applications Conference
