title,year,conference
 Identity mappings in deepresidual networks,2016, In European Conference on Computer Vision
 Deep learning,2015, nature
 Understanding deep convolutional networks,2016, Phil
 Intriguing properties of neural networks,2013, arXiv preprintarXiv:1312
 Explaining and harnessingadversarial examples,2014, arXiv preprint arXiv:1412
 Towards deep learning models resistant to adversarial attacks,2018, In InternationalConference on Learning Representations
 Distillationas a defense to adversarial perturbations against deep neural networks,2016, In Security andPrivacy (SP)
 Towards deep neural network architectures robust toadversarial examples,2014, arXiv preprint arXiv:1412
 Deepfool: a simpleand accurate method to fool deep neural networks,2016, In Proceedings of 2016 IEEE Conferenceon Computer Vision and Pattern Recognition (CVPR)
 An inside look at deep neuralnetworks using graph signal processing,2018, In Proceedings of ITA
 Influentialsample selection: A graph signal processing approach,2017, arXiv preprint arXiv:1711
 Peernets: Exploiting peer wisdom against adversarial attacks,2018, arXiv preprintarXiv:1806
 A sampling theoryperspective of graph-based semi-supervised learning,2017, arXiv preprint arXiv:1705
 Analysis of classifiersâ€™ robustness toadversarial perturbations,2018, Machine Learning
 Foolbox: A python toolbox tobenchmark the robustness of machine learning models,2017, arXiv preprint arXiv:1707
 Uni-versal adversarial perturbations,2017, arXiv preprint
 Transferability in machinelearning: from phenomena to black-box attacks using adversarial samples,2016, arXiv preprintarXiv:1605
 mixup: Beyondempirical risk minimization,2017, arXiv preprint arXiv:1710
 An introduction to frames,2008, Foundations and Trendsin Signal Processing
