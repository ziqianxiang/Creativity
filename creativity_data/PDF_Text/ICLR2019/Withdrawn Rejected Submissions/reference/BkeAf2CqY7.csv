title,year,conference
 Tensorflow: a system for large-scalemachine learning,2016, In OSDI
 Sparse communication for distributed gradient descent,2017, InConference on Empirical Methods in Natural Language Processing
 Qsgd: Communication-efficient sgd via gradient quantization and encoding,2017, In Advances in Neural Information ProcessingSystems
 Large scale distributed deep networks,2012, In Advances inneural information processing systems
 Imagenet: A large-scalehierarchical image database,2009, In Computer Vision and Pattern Recognition
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Probabilistic backpropagation for scalable learningof bayesian neural networks,2015, In International Conference on Machine Learning
 A method for stochastic optimization,2015, In International Conference onLearning Representations (ICLR)
 Auto-encoding variational bayes,2013, In The 2nd InternationalConference on Learning Representations (ICLR)
 Variational dropout and the local reparameteri-zation trick,2015, In Advances in Neural Information Processing Systems
 Randomized distributed mean estimation: Accuracy VS commu-nication,2016, arXiv preprint arXiv:1611
 Federated learning: Strategies for improving communication efficiency,2016, arXivpreprint arXiv:1610
 Learning multiple layers of features from tiny images,2009, 2009
 Imagenet classification with deep convolu-tional neural networks,2012, In Advances in neural information processing systems
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Scaling distributed machine learning with the parameterserver,2014, In OSDI
 Deep gradient compression:Reducing the communication bandwidth for distributed training,2018, In International Conference onLearningRepresentations (ICLR)
 Communication-efficientlearning of deep networks from decentralized data,2017, In Proceedings of the 20 th InternationalConference on Artificial Intelligence and Statistics (AISTATS)
 Variational dropout sparsifies deep neuralnetworks,2017, In Proceedings of the 34th International Conference on Machine Learning
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS workshop on deep learningand unsupervised feature learning
 Automatic differentiation inpytorch,2017, 2017
 Deep learning: A bayesian perspective,2017, Bayesian Analysis
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations (ICLR)
 Federated multi-tasklearning,2017, In Advances in Neural Information Processing Systems
 Terngrad:Ternary gradients to reduce communication in distributed deep learning,2017, In Advances in NeuralInformation Processing Systems
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
