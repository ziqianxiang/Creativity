title,year,conference
 Disabling external influence in social networks via edgerecommendation,2017, arXiv preprint arXiv:1709
 Poisoning attacks against support vector ma-chines,2012, In ICML
 Towards evaluating the robustness of neural networks,2017, In2017 IEEE Symposium on Security and Privacy
 Make it or break it: Manipulating robustness inlarge networks,2014, In Proceedings of the 2014 SIAM International Conference on Data Mining
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, CoRR
 Practical attacks against graph-based clustering,2017, arXivpreprint arXiv:1708
 Houdini: Democratizing adver-sarial examples,2017, Advances in Neural Information Processing Systems
 Adversarial attack ongraph structured data,2018, arXiv preprint arXiv:1806
 Adversarial network embedding,2018, In AAAI
 Explaining and harnessing adversarialexamples,2014, CoRR
 Semi-supervised classification with graph convolutional net-works,2016, arXiv preprint arXiv:1609
 Understanding black-box predictions via influence functions,2017, arXivpreprint arXiv:1703
 Deep textclassification can be fooled,2017, arXiv preprint arXiv:1704
 Tac-tics of adversarial attack on deep reinforcement learning agents,2017, arXiv preprint arXiv:1703
 Efficient estimation of word represen-tations in vector space,2013, arXiv preprint arXiv:1301
 Towards poisoning of deep learning algorithms with back-gradientoptimization,2017, arXiv preprint arXiv:1708
 Matrix perturbation theory,1990, 1990
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Comprehend deepwalk as matrix factorization,2015, arXiv preprintarXiv:1501
 Data poisoning attacks onmulti-task relationship learning,2018, 2018
