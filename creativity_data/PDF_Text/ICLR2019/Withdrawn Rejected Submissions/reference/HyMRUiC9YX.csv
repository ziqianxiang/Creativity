title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Synthesizing robust adversarialexamples,2018, In Proceedings of the 35th International Conference on Machine Learning
 Towards interpretable deep neural networks byleveraging adversarial examples,2017, arXiv preprint arXiv:1708
 Boostingadversarial attacks with momentum,2018, In The IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Delving into transferable adversarial examplesand black-box attacks,2017, In International Conference on Learning Representations
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Smoothgrad:removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 The space oftransferable adversarial examples,2017, arXiv preprint arXiv:1704
 Decision boundary analysis of adversarial examples,2018, In InternationalConference on Learning Representations
