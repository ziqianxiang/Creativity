title,year,conference
 Hierarchical multiscale recurrent neural net-works,2016, CoRR
 A unified architecture for natural language processing: deepneural networks with multitask learning,2008, In ICML
 A theoretically grounded application of dropout in recurrentneural networks,2016, In NIPS
 Frage: Frequency-agnosticword representation,2018, CoRR
 Improving neural language models with acontinuous cache,2016, CoRR
 Long short-term memory,1997, Neural computation
 The human knowledge comPression contest,2018, 2018
 Tying word vectors and word classifiers: Aloss framework for language modeling,2016, CoRR
 Dynamic evaluation of neu-ral sequence models,2018, In ICML
 Zoneout: Regularizing rnns by randomly Preserving hidden activations,2016, CoRR
 On the state of the art of evaluation in neural languagemodels,2018, In ICLR
 Pointer sentinel mixturemodels,2016, CoRR
 Regularizing and oPtimizing LSTMlanguage models,2018, In ICLR
 An analysis of neural language modelingat multiPle scales,2018, CoRR
 Recurrentneural network based language model,2010, In INTERSPEECH
 Fast-slow recurrent neural networks,2017, In NIPS
 Using the outPut embedding to imProve language models,2017, In EACL
 ImProving language under-standing by generative Pre-training,2018, 2018
 Semi-supervised multitask learning for sequence labeling,2017, In ACL
 Surprisal-driven zoneout,2016, CoRR
 Regularization of neuralnetworks using dropconnect,2013, In ICML
 Breaking the softmaxbottleneck: A high-rank rnn language model,2017, CoRR
 Recurrent high-way networks,2017, In ICML
 Neural architecture search with reinforcement learning,2016, CoRR
