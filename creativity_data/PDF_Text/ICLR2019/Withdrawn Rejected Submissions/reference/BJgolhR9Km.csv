title,year,conference
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Audio adversarial examples: Targeted attacks on speech-to-text,2018, arXiv preprint arXiv:1801
 Orthogonal least squares learning algorithm forradial basis function networks,1991, IEEE Transactions on neural networks
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in Neural Information Processing Systems
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Introduction to Radial Basis Function Networks,1996, Technical Report
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Automatic differentiation inpytorch,2017, 2017
 Intriguing properties of neural networks,2013, arXiv:1312
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 The spaceof transferable adversarial examples,2017, arXiv preprint arXiv:1704
 ADADELTA: An adaptive learning rate method,2012, arXiv preprintarXiv:1212
