title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Thermometer encoding: One hotway to resist adversarial examples,2018, 2018
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Zoo: Zeroth order opti-mization based black-box attacks to deep neural networks without training substitute models,2017, InProceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Imagenet: A large-scalehierarchical image database,2009, In Computer Vision and Pattern Recognition
 Stochastic activation pruning for robust adversarial de-fense,2018, arXiv preprint arXiv:1803
 Empiricalstudy of the topology and geometry of deep networks,2018, In The IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations
 Black-box adversarial attacks withlimited queries and information,2018, arXiv preprint arXiv:1804
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Towards robust neural networksvia random self-ensemble,2018, In European Conference on Computer Vision
 Delving into transferable adversarial exam-ples and black-box attacks,2016, arXiv preprint arXiv:1611
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, arXiv preprint arXiv:1801
 Universaladversarial perturbations,2017, arXiv preprint
 Cascade adversarial machine learning reg-ularized with a unified embedding,2018, In International Conference on Learning Representations
 Distilla-tion as a defense to adversarial perturbations against deep neural networks,2015, arXiv preprintarXiv:1511
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Deflectingadversarial attacks with pixel deflection,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Towards robust deep neural networks withbang,2016, arXiv preprint arXiv:1612
 Evolution strategies as a scalable alterna-tive to reinforcement learning,2017, arXiv preprint arXiv:1703
 Breaking the madry defense model with l_1-based adversarialexamples,2017, arXiv preprint arXiv:1710
 Fully convolutional networks for semanticsegmentation,2016, arXiv preprint arXiv:1605
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 The spaceof transferable adversarial examples,2017, arXiv preprint arXiv:1704
 Natural evolution strategies,2008, InEvolutionary Computation
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Mitigating adversarialeffects through randomization,2018, In International Conference on Learning Representations
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Wide residual networks,2016, arXiv preprintarXiv:1605
