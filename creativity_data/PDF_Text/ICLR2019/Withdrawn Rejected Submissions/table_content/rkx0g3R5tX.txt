Table 1: Table showing the Accuracy results on the synthetic datasets with different ratios (r1, r2, r3)of positive data. CIS outperforms other models on every dataset but by a smaller margin when theunderlying manifold is easier to learn like in the Swiss-Roll dataset.
Table 2: Table showing the MPR and P@1 for the different models on the two text datasets. We seethat even using the selfplay method helps us sample hard negatives.
Table 3: In this table, we show qualitative results for the Similarity task results. We can see thatFastText focuses more on N-grams similarities and shows less diversity.
Table 6: On this table we present the results for the Analogy task on respectively the 12k and 30kdifferent words datasets. On both datasets, CIS/SP are ahead in the Semantic tasks on the Prec@1/5metrics. However, when increasing the number of Nearest Neighbors, FastText catches up whichmight indicate a better structure in the tail.
Table 7: This table shows the P@1 for the 4 different models (Full Softmax, Uniform Sampling,Popularity Sampling, Selfplay and CIS) on the real datasets on the Item-Items task. On the task ofPrec@1, CIS consistently outperfoms the full softmax.
Table 8: Table showing results for the Similarity task results : in some cases we can see that the CISmodel does reflect more the meaning of the word.
