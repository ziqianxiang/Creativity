Table 1: MSE results of CAML and MAML for the sine curve regression task. We vary the number of inputparameters, for k = 10 shots. Numbers are averages over 1, 000 random sets of tasks. The 95% confidenceintervals are ±0.02 everywhere except for CAML with 1 additional input, where it is ±0.06.
Table 2: MSE results for alternative partitioning schemes on the since curve regression task. We do k = 10 shotlearning (averaged over 1, 000 random sets of tasks, with 95% confidence intervals in brackets). Labels indicatewhich parameters are task-specific. The rest of the network is shared across tasks and updated in the outer loop.
Table 3: Few-shot classification results on the Mini-Imagenet test set (average accuracy with 95% confidenceintervals on a random set of 1000 tasks). We compare to existing methods on this benchmark that use deepconvolutional networks, and MAML with a larger network (results obtained with the author’s open sourcedcode, with all hyperparameters unchanged except the number of filters).
