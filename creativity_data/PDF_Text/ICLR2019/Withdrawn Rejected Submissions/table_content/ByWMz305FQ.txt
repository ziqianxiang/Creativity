Table 1: Zero-shot results with baseline and aligned models compared against pivoting. Zero-Shotresults are marked zs. Pivoting through English is performed using the baseline multilingual model.
Table 2: Percentage of sentences by language in reference translations and the sentences decodedusing the baseline model (newstest2012)While investigating the high variance of the zero-shot translation score during multilingual trainingin the absence of alignment, we found that a significant fraction of the examples were not gettingtranslated into the desired target language at all. Instead, they were either translated to English orsimply copied. This phenomenon is likely a consequence of the fact that at training time, Germanand French source sentences were always translated into English. Because of this, the model neverlearns to properly attribute the target language to the < tl > token, and simply changing the < tl >5Under review as a conference paper at ICLR 2019token at test time is not effective. We count the number of sentences in each language using anautomatic language identification tool and report the results in Table 2.
Table 3: BLEU on subset of examples predicted in the right language by the direct translation usingthe baseline system (newstest2012)Here we try to isolate the gains our system achieves due to improvements in the learning of trans-ferable features, from those that can be attributed to decoding to the desired language. We discountthe errors that could be attributed to incorrect language errors and inspect the translation qualityon the subset of examples where the baseline model decodes in the right language. We re-evaluatethe BLEU scores of all systems and show the results in Table 3. We find that the vanilla zero-shottranslation system (Baseline) is much stronger than expected at first glance. It only lags the piv-oting baseline by 0.5 BLEU points on French to German and by 2.7 BLEU points on German toFrench. We can now see that, even on this subset which was chosen to favor the baseline model,the representation alignment of our adapted model contributes to improving the quality of zero-shottranslation by 0.7 and 2.2 BLEU points on French to German and German to French, respectively.
Table 4: Average BLEU scores for IWSLT-2017; Zero-Shot results are marked (zs).
