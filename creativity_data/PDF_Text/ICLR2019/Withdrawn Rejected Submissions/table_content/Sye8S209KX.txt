Table 1: Evaluation of sentence representations on a set of 8 tasks using a logistic regression classi-fier. “SP” and “ASP” in row 2.3 and 2.4 refers to the shared-private and adversarial shared privatemulti-task learning models. Values indicate the accuracy (accuracy/F1 for MRPC) for the test setsand bold-faced values denote the best transfer performances. We employ an averaging bag-of-wordstechnique to form sentence embeddings, using features from all three layers of ELMo.
Table 2: Transfer evaluation of the semantic relatedness and textual similarity tasks. “SP” and “ASP”in block 3 refers to the shared-private and adversarial shared private multi-task learning models. Inblock 4, we use ASP setting for Sent2vec. We use features from the top layer of the ELMo toproduce sentence embeddings. Values indicate the Pearson correlation coefficient for the test setsand bold-faced values denote the best performance across all the models.
Table 3: Probing task accuracies with MLP as the classifier. For ELMo, the same bag-of-words av-eraging technique is employed as used for the downstream transfer tasks. When ELMo is combinedwith Sent2Vec and GenSen, features only from the top layer are used to fit in single GPU (Titan X).
Table 4: Best β and γ values for adversarial shared private model on different set of tasks.
Table 5: Statistics of the datasets for multi-task learning and the transfer tasks. N is the numberof samples, V is the vocabulary size, and C is the number of classes or score range. i denotes thedatasets that are used in multi-task learning.
Table 6: Validation and test accuracy of the source tasks obtained through various multi-task learningarchitectures. Bold-faced values indicate best performance across all the models.
Table 7: Transfer test results for various single-task and multi-task learning architectures trained ona combination of QQP, SNLI and MNLI datasets. Bold-faced values indicate the best performanceamong all models in this table.
Table 8: The accuracy differences between MTL and STL when training with different sizes of data.
Table 9: Detailed analysis of the transfer test results for shared-private models trained on differentcombinations of QQP, SNLI and MNLI datasets. Combined encoder refers to the concatenation ofshared encoder and all private encoders. Underlined values indicate the best performance amongdifferent encoders of the shared-private models trained on the same set of tasks. Bold-faced valuesindicate the best performance among all models in this table.
