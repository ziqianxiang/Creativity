Table 1: Translation performance Table 2: Development NLL of Table 3: Retrieval results for ourof our pre-trained agents (BLEU) pretrained language models VSE++ model on Flickr30k test set.
Table 4: Results in BLEU score on Multi30k Task 1. For our models using policy gradient fine-tuning, wereport results averaged over three runs and provide standard deviations in brackets. PG: trained with vanillapolicy gradient fine-tuning. PG+LM: trained with the “Englishness” constraint in reward. For MS COCOand Flickr30k, the LM was trained directly on image captions. PG+LM+G: trained with grounding loss aswell as the LM loss. Fr→En: degree of intermediate language drift from English; lower indicates more drift.
Table 5: Additional token frequency analysis. unique: the number of unique English tokens used in the wholedevelopment set. /sent: the number of unique English tokens used per sentence. /all: (the number of uniqueEnglish tokens / the number of all English tokens.)Table 5 reinforces the finding that vanilla PG fine-tuning leads to flatter token frequency distri-butions, as the number of unique tokens used by PG is greater than that of the pretrained model.
Table 6: Exact-match word recall by POS-tag on IWSLT development set: when the English reference containsa word of a certain POS tag, how often does the agent correctly produces that word. TO: infinitive to, (.):period, DT: determiner, Noun: (NN, NNS, NNP, NNPS), Verb: (VB, VBD, VBG, VBN, VBP, VBZ), Adj:adjective (JJ, JJR, JJS), Adv: adverb (RB, RBR, RBS)7Under review as a conference paper at ICLR 2019	Fr	un Vieil homme VetU d'une Veste noire regarde SUr la tableRef	De	ein alter mann in einer schwarzen jacke blickt auf den tisch	En	an old man wearing a black jacket is looking on the table	PG	a old teaching black watching on the table table table table table tableEn	+LM	a old man in a jacket looking on the table . ” ”	+G	an old man in a black jacket looking on the table .
Table 7: Two random examples from Multi30k development set with different models (PG, PG+LM,PG+LM+G). The top three rows list the ground truth sentences, the middle three rows are the English mes-sages sent by the Fr→En agent, and the bottom three rows show the German output from the En→De agent.
Table 8: Evidence of token flipping in the PG model.
Table 9: Top 20 most frequent tokens in English reference (Reference) or the output from Fr→En models.
Table 10: Evidence of token flipping in the PG+LM model.
