Table 1: Sample generations from our MLE-trained baseline model, GMLE, and our discriminator-guided model GMLE+RL(coherence, cohesion). The red texts highlight a common problem in GMLE - itexhibits a repetition, and an inconsistent opinion as a review. In contrast, our discriminator-guidedmodel is able to generate a more interesting, and sentiment-consistent continuation.
Table 2: Retrieval ratios for coherence and cohesion discriminators from a collection of 100 neg-ative candidates. The reported numbers are averages over 20 evaluations. Notations: Conv52,132,4,5is a convolutional input encoder with filter sizes 2, 3, 4, and 5, and there are 512 filters for eachfilter size. GRU11-0la2y4er, bi-dir. is a 1-layered bi-directional GRU input encoder with hidden size 1024.
Table 3: An ablation study with automated evaluation metric scores: NLL, PPL, BLEU-n,intra/inter-unique-n, along with the length ratio with the length of corresponding true target sen-tences as 1. Results show that our proposed discriminators helped improve notably in BLEU scores,NLL and PPL, with marginal difference in diversity. We used equally weighted rewards, and signif-icant numbers are highlighted in bold before rounding.
Table 4: Coherence and cohesion margin scores on test data. The cohesion score at the end ofeach line is computed with its next sentence. This is an example of contradiction and inconsistentsentiment, suggestive of incoherence. We append more examples with extreme cohesion marginscores.
