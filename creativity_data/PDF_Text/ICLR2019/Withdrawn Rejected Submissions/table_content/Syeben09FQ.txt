Table 1: Progression of DG throughout training and heatmaps of the generator distributionstableunstableoNlXde6---enα*>	HW	sa>	BV	w>	WV	BaV	W>	WWqvxssQsoW 5 Ode6--enαW 5de6--enα5	10	15	20Epochs0	5	10	15	20EpochsSSPoWOO 5 io 15	20Epochs
Table 2: Pearson product-moment cor-relation coefficients for an average of 10stable rounds.
Table 3: Metrics on a simple mode dropping task.y ι.oo-W∈ 0.75-⅛ 0∙50-I 0.25-z 0.00-.
Table 4: Learning rates used for the toy experiments.
Table 5: Final results for DG, number of covered modes and number of generated samples (out of2400) that fall within 3 standard deviations of the means.
Table 6: Progression of DG throughout training and heatmaps of the generator distribution. A1: stable ring,A2: unstable ring, B1: mode collapse, B2: stable mode collapseCollapsed worst case generator. Now we focus on the calculation of the duality gap. Let us con-sider the case of a mode collapsed worst case generator. In particular, when computing the maximinpart of the duality gap i.e. M (uworst,v), let us assume the solution was such that Guworst only coversone mode of the true distribution (Figure 15 d)). Then M (uworst,v) = log(0.5) + log(1 - 0.5). Theminmax calculation is: M (u, vworst) = log(0.5) + log(1 - 0.5). Hence, the value of DG is zero,despite the collapse in the calculation for the uworst . The generator has no incentive to spread itsmass due to the objective. While this is a problem for the original GAN that is being trained, it isnot an issue for the calculation of the duality gap metric.
Table 7: DG for various number of optimization steps and GAN hyperparameters. The set ofthe best hyperparameters is the same no matter the number of optimization steps are used for thecalculation of the duality gap.
