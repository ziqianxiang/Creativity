Table 1: Top-1 accuracy (%) on HMDB51 and UCF101 dataset.
Table 2: Results on Moments in Time dataset. ResNet50-ImageNet and TRN-Multiscale spatialresults reported here are based on authors’ (Monfort et al., 2018) released trained model.
Table 3: Spatial action localization results on UCF101-24 dataset measured by mAP at differentIoU thresholds α. * The baseline methods are strongly supervised spatial localization methods.
Table 4: Temporal action localization results on THUMOS’14 dataset measured by mAP atdifferent IoU thresholds α.
Table 5: Architecture of spatial attention network. H and W are the height and width of the featuremap, respectively.
Table 6: Top-1 accuracy (%) on HMDB51 with different base networksC.3 More action recognition resultsTable 6 shows results of our spatial-temporal attention model with different base networks. Ourspatial-temporal attention mechanism is a easy plug-in model which could be based on differentnetwork architectures, and can boost performance.
