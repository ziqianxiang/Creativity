Table 1: Performance comparison for MNIST between full-precision and SQAModel	Clean	FGSM=4	FGSM€=8	C&We = 4	C&We = 8	PGDRES34full	87:07	46.21	63.47	13.5	820	8.87RES34sqa	81.53±0.38	70.51±0.49	53.45±0.44	66.45±0.45	38.70±0.62	48.32±0.19RES101full	87.67	52.44	78.59	12.17	8.09	7.52RES101sqa	82.94±0.42	73.30±0.39	56.54±0.52	68.40±0.69	41.52±0.41	52.12±0.63Table 2: Performance comparison for CIFAR10 between full-precision and SQASQA v.s. Full-PrecisionWe explore the robustness of SQA against three types of adversarial attacks and the result is shownin Table 1. The networks are all trained with fast single-step adversaries and we could find twoknown, but interesting properties from the experiments. First, FGSM training the full-precisionnetworks, denoted as SMALLfull, LARGEfull , makes themselves overfit to the adversaries. Theyshow depressed accuracy on especially, PGD attacks, nearly close to 0. However, SQA modelsdoes not overfit to the adversaries. Even though SQA models show lower performance on FGSMattacks, they exhibit remarkably high accuracy on the other adversarial examples that have not seenbefore. The second interesting fact is that the correlation between robustness and model capacity.
Table 2: Performance comparison for CIFAR10 between full-precision and SQASQA v.s. Full-PrecisionWe explore the robustness of SQA against three types of adversarial attacks and the result is shownin Table 1. The networks are all trained with fast single-step adversaries and we could find twoknown, but interesting properties from the experiments. First, FGSM training the full-precisionnetworks, denoted as SMALLfull, LARGEfull , makes themselves overfit to the adversaries. Theyshow depressed accuracy on especially, PGD attacks, nearly close to 0. However, SQA modelsdoes not overfit to the adversaries. Even though SQA models show lower performance on FGSMattacks, they exhibit remarkably high accuracy on the other adversarial examples that have not seenbefore. The second interesting fact is that the correlation between robustness and model capacity.
Table 3: Performance comparison with other defenses against l∞( = 8) adversaries for CIFAR10Defense	Training timeFGSM Training SQA + FGSM Training PGDTrainingκ=i0∕20∕i00	0.43 0.57 1.23/2.34/ 10.17Table 4: Average training time (sec) for one iteration on ResNet34 for CIFAR-10Figure 2: t-SNE results from the penultimate layer of our network against clean images and C&Wadversaries. (A) is a full-precision network with no defense, (B) is a full-precision network + FGSMtraining, and (C) is SQA + FGSM training (Ours). While (A) and (B) shows significant degradationon adversaries, (C) still finds proper decision boundaries against adversarial attacks.
Table 4: Average training time (sec) for one iteration on ResNet34 for CIFAR-10Figure 2: t-SNE results from the penultimate layer of our network against clean images and C&Wadversaries. (A) is a full-precision network with no defense, (B) is a full-precision network + FGSMtraining, and (C) is SQA + FGSM training (Ours). While (A) and (B) shows significant degradationon adversaries, (C) still finds proper decision boundaries against adversarial attacks.
