Table 1: PSNR [dB] results on joint denoising and demosaicing for different bitwidths.
Table 2: ImageNet comparison. We report top-1, top-5 accuracy on ImageNet compared with state-of-the-artprior methods. For each DNN architecture, rows are sorted in number of bits.Baseline results were tokenfrom PyTorch model zoo. Compared methods: JOINT (Jung et al., 2018), PACT (Choi et al., 2018), LQ-Nets(Zhang et al., 2018), FAQ (McKinstry et al., 2018)_______________________________________________________________Network	Method	Precision (w,a)	Accuracy (% top-1)	Accuracy (% top-5)ResNet-18	baseline	32,32	69.76	89.08ResNet-18	FAQ	8,8	70.02	89.32ResNet-18	NICE (Ours)	5,5	70.35	89.8ResNet-18	PACT	5,5	69.8	89.3ResNet-18	NICE (Ours)	4,4	69.79	89.21ResNet-18	JOINT	4,4	69.3	-ResNet-18	PACT	4,4	69.2	89.0ResNet-18	FAQ	4,4	69.81	89.10ResNet-18	LQ-Nets	4,4	69.3	88.8ResNet-18	JOINT	3,3	68.2	-ResNet-18	NICE (Ours)	3,3	67.68	88.2ResNet-18	LQ-Nets	3,3	68.2	87.9ResNet-18	PACT	3,3	68.1	88.2ResNet-34	baseline	32,32	73.30	91.42ResNet-34	FAQ	8,8	73.71	91.63
Table 3: Ablation study of ResNet18 ImageNet Dataset NICE scheme. We measured TOP-1 accuracyNoise+Gradual training	Activation clamping learning Accuracy on 5,5 [W,A] Accuracy on 3,3 [W,A]-	-	69.72	66.51- X X	X	69.9	67.2 -	70.25	66.7 X	70.3	67.688Under review as a conference paper at ICLR 2019ReferencesSanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi Zhang. Stronger generalization bounds for deep netsvia a compression approach. In international conference on machine learning (ICML), 2018. 3Utku Aydonat, Shane Oâ€™Connell, Davor Capalija, Andrew C. Ling, and Gordon R. Chiu. An openclTMdeeplearning accelerator on arria 10. In Proceedings of the 2017 ACM/SIGDA International Symposium onField-Programmable GateArrays, FPGA '17,pp. 55-64, New York, NY USA, 2017. ACM. ISBN 978-1-4503-4354-1. doi: 10.1145/3020078.3021738. URL http://doi.acm.org/10.1145/3020078.
Table C.1: NICE Accuracy (% top-1) on CIFAR-10 for range of bitwidths.
