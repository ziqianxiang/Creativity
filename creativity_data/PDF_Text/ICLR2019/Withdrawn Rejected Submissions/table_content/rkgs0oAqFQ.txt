Table 1: Top-k accuracy for the different mod-els on the ImageNet dataset. Accuracy whenonly testing on unseen classes. Results indicatedwith *, t, and ^ are taken from ChangPinyo et al.
Table 2: ToP-k accuracy for the different modelson the ImageNet dataset. Accuracy when testingon seen and unseen classes. Results indicated with计,甘，and ^ are taken from Frome et al. (2013),Norouzi et al. (2014), and Wang et al. (2018),resPectively.
Table 3: Results of the ablation experiments onthe 2-hops dataset. (-f), (-w), and (-wf) indicatemodels without finetuning, weighting and with-out both weighting and finetuning, respectively.
Table 4: Performance on the seen ImageNetclasses. ResNet represents ideal performanceas it only predicts known classes.
Table 5: Results for 2-hops with/without separating the adjacency matrix into ancestors and descen-dants for DGP.
Table 6: Results for 2-hops for SGCN with increasing depth.
Table 7: Illustration of the improvements between the original results of GCNZ in Wang et al. (2018),our reimplementation of GCNZ and our SGCN.
Table 8: Mean and std for 3 runs. More stable as # class increases.
