Table 1: Two examples from EmpatheticDialogues training set. The first worker (the speaker)is given an emotion label and writes their own description of a situation when they’ve felt that way.
Table 2: Automatic evaluation metrics on the test set. Pretrained: basic Transformer model pre-trained on a dump of 1.7 billion Reddit conversations. Base and Multitask: model fine-tuned overthe EmpatheticDialogues training data (Sec. 4.2). Remaining rows: models incorporating su-pervised information from an external classifier, as described in Sec. 4.3. Candidates come fromReddit (R), EmpatheticDialogues (ED), or DailyDialogues (DD). P@1,100: precisionretrieving the correct test candidate out of 100 test candidates. AVG BLEU: average of BLEU-1,-2,-3,-4. PPL: perplexity. All automatic metrics clearly improve with in-domain training on utterances(Base vs. Pretrained), other metrics are inconsistent. Base model row is repeated as itis the referencefor the external classifier group. Bold: best performance for that group.
Table 3: Human evaluation metrics from rating task. Training on EmpatheticDialogues im-proves all scores. Combining with an external supervised classifier generally improves scores, es-pecially the Empathy score, without requiring extensive retraining of the dialogue model. The Basemodels rows are repeated to indicate that they are the reference model for the models below. Bold:results above 2 SEM Ofreference modelfor that group. Italicized: the reference modelfor the group	Model	Candidates	Empathy	Relevance	Fluency	Pretrained	R	2.58±0.14	2.97±0.14	4.11±0.12	Base	ED	3.27±0.13	3.42±0.14	4.44±0.08	Multitask	ED	3.58±0.12	3.58±0.14	4.46±0.09	Base	ED	32 ± 0.13	3.42±0.14	4.44±0.08	EmoPrepend-1	ED	3.51±0.13	3.61±0.15	4.45±0.10Retrieval	EmoPrepend-3	ED	3.62±0.14	3.50±0.15	4.54±0.08	EmoPrepend-5	ED	3.52±0.14	3.64±0.14	4.47±0.09	TopicPrepend-1	ED	3.66±0.11	3.85±0.11	4.51±0.08	TopicPrepend-3	ED	3.67±0.10	3.70±0.11	4.49±0.08	TopicPrepend-5	ED	3.59±0.10	3.73±0.10	4.43±0.08	Ensem-DM+	ED	3.36±0.14	3.33±0.14	4.13±0.11	Ensem-Tran	ED	3.80±0.12	3.66±0.14	4.59±0.08	Pretrained	-	2.26±0.13	2.37±0.13	4.08±0.12	Base	-	2.95±0.15	3.10±0.14	4.37±0.10
Table 4: Training resources for different models, with human evaluation metrics from rating taskfor empathy (Emp), relevance (Rel) and fluency (Fluent). Comparisons are relative to the first rowof each group. Training on EmpatheticDialogues improves all scores while requiring minimaladditional training resources (same number of parameters for Base, 0.01% increase in number ofparameters for Multitask). SEM is approximately 0.1	Model	Params, resources, train examples	Emp	Rel	Fluent	Pretrained	84.3M, 2.5 days, 8GPUs,1.7B	2.6	3.0	4.1Retrieval	Base	same , + 0.5 hour, 1 GPU, +22.3k	3.3	3.4	4.4	Multitask	+9.6k, + 0.5 hour, 1 GPU, +22.3k	3.6	3.6	4.5	Pretrained	85.1M, 2 days, 32 GPUs, 1.7B	2.3	2.4	4.1	Base	same , +1 hour, 1 GPU, +22.3k	3.0	3.1	4.4Generation	Multitask	+9.6k, +1 hour, 1 GPU, +22.3k	3.2	3.2	4.3	PretrainedLarge	86.2M, 2.5 days, 32 GPUS,1.7B	3.0	3.1	4.0	BaseLarge	Same , +0.5 hour,1 GPU, +22.3k	4.0	4.2	4.75.1 ResultsFine-tuning on EmpatheticDialogues Table 2 shows that fine-tuning to predict conver-sation responses on our data improves all automated metrics. Using only in-domain candidatesleads to slightly higher BLEU scores. Training in the multitask setting degrades automated met-rics compared to fine-tuning without emotion label supervision, except for average BLEU in theretrieval setting. Human evaluations in Table 3 show that fine-tuning a conversational model on the
Table 5: Average ratio of “best” replies from model A vs. model B for a set of pairs in our humanranking evaluation. Ratios > 1 mean that the model on the left was selected more than the model onthe right. Emotion Supervision Models: models from Sec. 4.3 that incorporate supervised emotioninformation. Full listings of comparison between pairwise models is included in the appendix.
Table 6: Examples of model responses. In the first example, responses from the models with emotionprediction components focusing on the feelings of the speaker are more generic. In the secondexample, they focus on the feelings on the speaker while remaining topically specific.
Table 7: Distribution of situation/conversation labels within EmpatheticDialoguesLabel	%	Label	%	Label	%	Label	%surprised	5.15	impressed	3.24	joyful	3.10	content	2.97excited	3.77	afraid	3.21	prepared	3.08	devastated	2.87annoyed	3.53	disgusted	3.17	guilty	3.06	sentimental	2.81proud	3.49	confident	3.16	furious	3.05	caring	2.75angry	3.47	terrified	3.15	nostalgic	3.05	trusting	2.62sad	3.45	hopeful	3.14	jealous	3.05	ashamed	2.53grateful	3.28	anxious	3.11	anticipating	3.03	apprehensive	2.45lonely	3.28	disappointed	3.10	embarrassed	2.98	faithful	1.92A Supplemental MaterialA.1 Label DistributionIn Table 7, we include the exact percentage of emotion labels for the situation descriptions in ourfinal dataset.
Table 8: 10 random examples from EmpatheticDialogues training set.
Table 9: Classification performance on EmpatheticDialogues, with the benchmarks proposedin Felbo et al. (2017) for reference. ED: performance on predicting the emotion label from thesituation description. ED-CUT: same, but after having removed all the situation descriptions wherethe target label was present.
