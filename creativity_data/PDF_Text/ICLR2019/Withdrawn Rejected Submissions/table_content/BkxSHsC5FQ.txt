Table 1: Performance of SupportNet with respect to different values of the EWC regularizer coef-ficient. The experiments were done on the enzyme function prediction task. All the results, exceptfor the last two columns, are by incrementally learning all the six classes of the EC system one byone using different EWC regularizer coefficient values, with the support data size fixed to be 2,000.
Table 2: Underfitting and overfitting of iCaRL and SupportNet. The experiments were done on theenzyme function prediction data and MNIST. “Real training data” means the training accuracy onthe new data plus the support data for SupportNet and examplars for iCaRL. “All training data”means the accuracy of the model trained on the real training data and tested over the new data andall the old data. “Test data” means the accuracy of the model trained on the real training data overthe test data._________________________________________________________________________Dataset	Enzyme data			MNIST		Method	SupoortNet	iCaRL	SupoortNet	iCaRLReal training data	-0.987	-0.991	-0.998	-0.995All training data	-0.920	-0.626	-0.991	-0.902Test data	0.839	0.629	0.988	0.878the upper bound of all the incremental learning methods, whereas the lowest one having around13% performance degradation. The results make sense because from the neurophysiological pointof view, SupportNet is trying to reach the stability-plasticity balance point for this classificationtask. If the coefficient is too small, which means we do not impose enough constraint on thoseweights which contribute significantly to the old class classification, the deep learning model willbe too plastic and the old knowledge tends to be lost. If the coefficient is too large, which meansthat we impose very strong constraint on those weights even when they are not important to the oldclass classification, the deep learning model will be too stable and does not have enough capacityto incorporate new knowledge. In general, our results are consistent with the stability-plasticity
