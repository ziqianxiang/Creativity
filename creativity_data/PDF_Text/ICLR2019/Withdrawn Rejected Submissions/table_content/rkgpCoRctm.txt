Table 1: Summary comparison of the characteristics of recent related methods. Test complexityrefers to the required number of passes over the network. Training data is the number of samples forwhich the methods were calibrated against (with all standing for the whole training set). AUROCis the area under receiver characteristic curve (detailed in Section 4). Performance shown is forDenseNet trained on CIFAR-100 and using TinyImageNet (resized) as OOD dataset.
Table 2: Summary of datasets. All generated samples have a size of 32 × 32.
Table 3: Average test error rates (%) and standard deviation (in parenthesis) over 4 runs.
Table 4: Comparison between previous work (Section 2) and our proposed method using the TNR @95% TPR metric for DenseNet-BC-100-12. The displayed values (%) are the mean over 4 differenttraining runs of the backbone models (for ODIN and our proposed model, the others results are fromtheir respective papers).
Table 5: Generalization over unseen OOD datasets using different features (only mean, only std, andboth). For each OOD validation set, we fit the linear model to it and tested against all OOD test sets.
Table 6: Generalization to unseen OOD sets using CIFAR-100 as ID dataset and the WRN-28-10backbone model. Performance of the OOD detector when the logistic regression is fit using 1000samples of a given OOD dataset and then evaluated with respect to other OOD test datasets usingonly “std” as features. Results are TNR @ 95% TPR formatted as “mean (std)”.
Table 7: Comparison between ODIN and our proposed OOD detector for several setups using im-age classification networks. All detector parameters (and ODIN’s hyperparameters) were tuned forTinyImageNet (c) and Gaussian validation sets. The results are formatted as “mean (std)”.
Table 8: TNR @ 95% TPR for computing the averaged mean and standard deviation from unnor-malized/normalized BN latent space. The backbone model is the WRN 28-10 using CIFAR-10 asID samples, and the logistic regressor was fitted using TinyImageNet (c) and Gaussian validationsets. The results are formatted as “mean (std)”.
Table 9: Average test error rates (%) and standard deviation (in parenthesis) over 4 runs.
Table 10: Generalization to unseen OOD sets using SVHN as ID dataset and the DenseNet BC 100-12 backbone model. Performance of the OOD detector when the logistic regression is fit using 1000samples of a given OOD dataset and then evaluated with respect to other OOD test datasets usingonly “std” as features. Results are TNR @ 95% TPR.
Table 11: Comparison between ODIN and the proposed OOD detector. The hyperparameters weretuned for TinyImageNet (c) and Gaussian validation sets and tested on others, and we only use thestandard deviation as feature.
Table 12: TNR at different TPR levels. The hyperparameters were tuned for TinyImageNet (c) andGaussian validation sets and tested on others, and we only use the standard deviation as feature.
