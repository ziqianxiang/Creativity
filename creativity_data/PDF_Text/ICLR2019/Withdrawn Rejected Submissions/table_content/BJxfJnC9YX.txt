Table 1: Summary of results obtained for the 3 tasks - Autoencoder on MNIST, Autoencoder onFashion-MNIST, and Audio to Image conversion (T = input duration for SNN)Dataset	Network Size	Epochs	T	Loss (MSE) (test)						SNN	ANN	ANN (with Adam)MNIST	784-196-784	1		0.357	0.226	0122Fashion-MNIST	784-512-784	1	-60^	0.178	0.416	0.300	784-1024-784	1	-60^	0.140	0.418	0.387Audio-to-Image A	58500-2048-196/196-784	-20-	10-	0.254	0.408	0144Audio-to-Image B	58500-2048-196/196-784一	20	^30^	0.543	0.611	0.5564 Discussion and ConclusionIn this work, we proposed an algorithm to train spiking networks, and in Table 1, we have summa-rized the results of this work12. The proposed algorithm brings SNN performance at par with ANNsfor the given tasks. We demonstrate that spiking autoencoders can be used to generate reduced-duration spike maps (“hidden state”) of an input spike train, which are a highly compressed versionof the input, and they can be utilized across applications. This is also the first work to demonstrateaudio to image synthesis in spiking domain. While training these autoencoders, we made a fewimportant and interesting observations; the first one is the importance of bit masking of the outputlayer. Trying to steer the membrane potentials of all the neurons is extremely hard to optimize, andselectively correcting only incorrectly spiked neurons makes training easier. This could be applica-ble to any spiking neural network with a large output layer. Second, while the AE-SNN is trained
