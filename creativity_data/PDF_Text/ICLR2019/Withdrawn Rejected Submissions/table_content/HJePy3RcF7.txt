Table 1: Does the learning rate sequence optimized fora given end time generalize to other end times? Observehow a model optimized to perform for a specific horizonbehaves sub-optimally for other time horizons.
Table 2:	Comparing Train Softmax Function Value and Test 0/1 Error of various learning rate decayschemes for the classification task on cifar-10 using a 44-layer residual net with pre-activations.
Table 3:	Comparing Train Softmax Function Value of various learning rate decay schemes for theclassification task on cifar-10 using a 44-layer residual net with pre-activations.
Table 4: Comparing Test 0/1 error of various learning rate decay schemes for the classification taskon cifar-10 using a 44-layer residual net with pre-activations.
