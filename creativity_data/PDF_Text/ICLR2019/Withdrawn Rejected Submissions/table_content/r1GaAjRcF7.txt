Table 1: Evidence retrieval results. Each block of rows show recall, precision, and F1 when themodels select k = 7, 5, 3, 1 sentences as evidence. The DGN significantly outperforms the untrainedbaselines. When selecting fewer sentences, k = 5, 3, 1, the DGN produces increasing gains in recall,precision, and F1. The DGN slightly, but consistently outperforms the Encoder.
Table 2: Evidence retrieval results for the DeepEncoder model and the DGN. Each row showsrecall, precision, and F1 when the models select k = 7 sentences as evidence. The DGN achievescomparable performance of the DeepEncoder models with a fraction of the parameters in the bestperforming DeepEncoder.
Table 3: Effects of various optimization modifications: softmax temperature annealing, sentenceorder shufflingGreedy optimization modification	Recan@7	Precision@7	F1@7Temperature annealing	0.756	0.192	0.306No temperature annealing	0.763	0.194	0.309Sentence shuffling	0.802	0.203	0.324No sentence shuffling	0.811	0.206	0.328film Road to Perdition (2002), and the James Bond films Skyfall (2012) and Spectre (2015),” and“Jarhead is a 2005 American biographical war drama film based on U.S. Marine Anthony Swofford’s2003 memoir of the same name, directed by Sam Mendes, starring Jake Gyllenhaal as Swoffordwith Jamie Foxx, Peter Sarsgaard and Chris Cooper.” On the other hand, the DeepEncoder selectssentence b, verifying that Jarhead was directed by Sam Mendes, but the next highest rated sentenceis sentence c: “Samuel Alexander Mendes, (born 1 August 1965) is an English stage and filmdirector.” The DGN ranked both sentences b and c fairly highly, fα ({c}) = 12.26, but determinedthat sentence c was more redundant with sentence b than a was, fα ({a, b}) - fα ({a}) = 8.00compared to fα({a, c}) - fα({a}) = 7.25, so the score for c dropped more than for b.
