Table 1: Diversity as measured by the proportion of unique trigrams in model outputs. Bleu andMeteor scores using up to 10 references for the Amazon dataset and up to six references for theStackExchange dataset. Numbers in bold are the highest among the models. All results for Amazonare on the entire test set whereas for StackExchange they are on the 500 instances of the test set thathave multiple references.
Table 2: Results of human judgments on model generated questions on 500 sample Home & Kitchenproduct descriptions. The options described in ยง 3.3 are converted to corresponding numeric range(as described in Appendix C). The difference between the bold and the non-bold numbers is statis-tically insignificant with p <0.001. Reference is excluded in the significance calculation.
Table 3: Example outputs from each of the systems for a single product descriptionthis challenge using an adversarial network approach (Goodfellow et al., 2014), a training procedurethat can generate natural-looking outputs, which have been effective for natural image generation(Denton et al., 2015). Due to the challenges in optimizing over discrete output spaces like text, Yuet al. (2017) introduced a Seq(uence)GAN approach where they overcome this issue by using Re-inforce to optimize. Li et al. (2017) train an adversarial model similar to SeqGAN for generatingnext utterance in a dialog given a context. However, unlike our work, their discriminator is a binaryclassifier trained to distinguish between human and machine generated utterances. Finally, Feduset al. (2018) introduce an actor-critic conditional GAN for filling in missing text conditioned on thesurrounding context.
