Table 1: Notation referencesNotation	DefinitionG : {X, Y, A} X∈RN×D Y Y∈RN×M A ∈ RN×N; A ∈ RN×N	the whole graph data node feature matrix label space consisting of unique label assignments label vectors for all nodes graph adjacency matrix; a normalized version of Af H∈ RN×M; hi ∈ RM W0 ∈ RD×S, W1 ∈ RS×M	graph convolutional networks (GCN) GCN prediction probability distribution; row i of H learnable weight matrix of GCN~zF) N(i)	partition function neighbor node set of node iF ψ(∙); φ(∙) U ∈ RM×M	energy function unary potential of E; pairwise potential of E learnable correlation weight matrix1 .	1 ∙ 1 1 ∙ 5T Cll	r∖—— Λ r∖——	— ιbetween node i and node j. We follow convention to denote A = D 2 AD 2 as a normalizedversion of A, which will be used in our model later.
Table 2: Dataset StatisticsDataset	Nodes	Edges	Classes	Features	Training/Validation/TestCora	2, 708	5, 429	7	1, 433	140/500/1000Pubmed	19, 717	44, 338	3	500	60/500/1000Citeseer	3, 327	4, 732	6	3, 703	120/500/1000PPI	43,471	81,044	3	50	120/500/1000Baselines To evaluate the effectiveness of our method, we compare with the following baselines.
Table 3: Performance Comparison(micro-F1).
