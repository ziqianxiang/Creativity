Table 1: Comparison of various architectures on MultiTHUMOS using both I3D per-segment andInceptionV3 per-frame features. We found that TGM layers with 1x1 convolution channel com-bination performed the best. Results are in mAP %. Note that we use the same filter length for“Temporal Conv” and “TGM” models, as described in Section 4.1.
Table 2: Additional number of parameters formodels when added to the base architecture(e.g., I3D or Inception V3).
Table 3: Comparison of previous methods withcomparable number of parameters and randomforms of our TGM layer.
Table 4: Performances of the state-of-the-art methods and our approach on MultiTHUMOS. Ourapproach meaningfully outperforms all previous results.
Table 5: Per-frame mAP on Charades, evaluated with the ‘Charades_v1_localize, setting. I3D mod-els are two-stream, using both RGB and optical flow inputs.
Table 6: Effect of L on MultiTHUMOS and Charades using only RGB I3D features. Note that the3 TGM layer models have larger temporal resolution than the 1 TGM layer models for the samevalues of L. We also compare to using standard one-layer 1-D conv layer with different values of L.
Table 8: Comparison of values of Cout on Mul-tiTHUMOS and Charades using RGB I3D fea-tures. For these experiments, 1 layer was usedwith L = 15 and M = 16.
Table 7: Comparison of various values of M onMultiTHUMOS and Charades using RGB I3Dfeatures. For these experiments, 1 layer wasused with L = 15 and Cout = 16.
Table 9: Comparison of the different forms of temporal convolution on MultiTHUMOS using RGBI3D features. We set L = 15 and used 1 layer models for these experiments.
Table 10: Result mAP on the MLB-YouTube dataset using InceptionV3 and I3D to obtain features.
Table 11: Results on AVA dataset with the temporal annotation-only setting (i.e., frame classificationwithout using bounding box training labels).
