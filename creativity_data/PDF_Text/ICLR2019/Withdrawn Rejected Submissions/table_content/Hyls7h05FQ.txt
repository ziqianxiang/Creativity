Table 1: Spearman’s correlation 100ρ on SCWS (trained1B token, 300d vectors except for Huang et al.)Model	Accuracy(%)Unsupervised Multi-prototype models	mssg-30k	54.00MUSE _Boltzmann	52.14GASI-β	55.27Multi-prototype models	W加力 external lexical	resourcesDeConf	58.55sw2v	54.56Table 2: Unsupervised sense selection accu-racy on Word in ContextSense Embeddings (Lee & Chen, 2017, muse) on MaxSimC. All three are better than the baselineSkip-Gram model (65.2 using the word embedding). gasi better captures similarity than sasi,corroborating that hard attention aids word sense selection. GASI without scaling (β) has the bestMaxSimC; however, it learns a flat sense distribution (Figure 2). GASI-β has the best AvgSimC anda competitive MaxSimC. While MUSE has a higher MaxSimC than GASI-β, it fails to distinguishsenses as well (Figure 4, Section 6). The Probabilistic FastText Gaussian Mixture (Athiwaratkunet al., 2018, pdf-gm) is sota on multiple non-contextual word similarity tasks (Table 3). Without
Table 2: Unsupervised sense selection accu-racy on Word in ContextSense Embeddings (Lee & Chen, 2017, muse) on MaxSimC. All three are better than the baselineSkip-Gram model (65.2 using the word embedding). gasi better captures similarity than sasi,corroborating that hard attention aids word sense selection. GASI without scaling (β) has the bestMaxSimC; however, it learns a flat sense distribution (Figure 2). GASI-β has the best AvgSimC anda competitive MaxSimC. While MUSE has a higher MaxSimC than GASI-β, it fails to distinguishsenses as well (Figure 4, Section 6). The Probabilistic FastText Gaussian Mixture (Athiwaratkunet al., 2018, pdf-gm) is sota on multiple non-contextual word similarity tasks (Table 3). Withoutsense selection module given context, we evaluate pdf-gm on MaxSim (Equation 16), which is 66.4.
Table 3: Spearman’s correlation 100ρ on non-contextual word similarity measured by MaxSim.
Table 4: Word intrusion evalutations on top ten nearestneighbors of sense embeddings.
Table 6: Similarities of human and modelTable 5: Human-model consistency on contextual choices when they disagree (error) vs. similar-word sense selection; P is the average probability ities between the senses that both human andassigned by the model to the human choices. gasi- model select with other senses in the same wordβ is most consistent with human.	(correct). Human agrees with the model whenthe senses are distinct.
Table 5: Human-model consistency on contextual choices when they disagree (error) vs. similar-word sense selection; P is the average probability ities between the senses that both human andassigned by the model to the human choices. gasi- model select with other senses in the same wordβ is most consistent with human.	(correct). Human agrees with the model whenthe senses are distinct.
Table 7: A case where mssg has low overlaps but confuses raters (agreement 0.33); model choses s1.
Table 8: Spearman’s ranking correlation 100 × ρ on SCWS. GASI-0.4-30K means top 30,000 wordsare initialized with three senses while the others have one sense.
