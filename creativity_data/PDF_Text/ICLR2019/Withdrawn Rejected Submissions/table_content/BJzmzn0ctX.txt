Table 1: Link prediction results for WN18, WN18RR, and FB15k-237.E. Results for DistMult,ComplEx, ConvE, NeuralLP, and MINERVA are from Dettmers et al. (2018); Das et al. (2017). Forthe sake of comparison, we also trained ComplEx and DistMult with embedding size d = 100 andfor 100 epochs, as NaNTP.
Table 2: Explanations, in terms of rules and supporting facts, for the queries in the validation set ofWN18 and WN18RR provided by NaNTPs by looking at the proof paths yielding the largest proofscores.
Table 3: Comparison of NaNTPs and NTPs on benchmark datasets. Double asterisk (**) denotes theperformance of NTP reevaluated with the correct evaluation function (see the note in Section 6.2).
Table 4: Mentions used for replacing a varying number of training triples in the Countries S1, S2,and S3 datasets.
Table 5: Dataset statistics.
Table 6: Ablation of attention over relations on NaNTPs, on benchmark datasets.
Table 7: Ablation of attention over relations on NaNTPs, on WN18, WN18RR and FB15k-237.E	WN18				WN18RR				FB15k-237.E				MRR	Hits			MRR	Hits			MRR	Hits				@10	@3	@1		@10	@3	@1		@10	@3	@1DistMult (Yang et al., 2015)	0.822	0.936	0.914	0.728	0.430	0.490	0.440	0.390	0.241	0.419	0.263	0.155ComplEx (Trouillon et al., 2016)	0.941	0.947	0.936	0.936	0.440	0.510	0.460	0.410	0.247	0.428	0.275	0.158ConvE (Dettmers et al., 2018)	0.943	0.520	0.440	0.400	0.430	0.520	0.440	0.400	0.325	0.501	0.356	0.237DistMult (d = 100)	0.782	0.931	0.910	0.658	0.411	0.463	0.423	0.382	0.214	0.402	0.240	0.127ComplEx (d = 100)	0.923	0.948	0.941	0.904	0.420	0.469	0.431	0.395	0.206	0.373	0.222	0.126NaNTP	0.539					0.250			0.197	0.330	0.209	0.131NaNTP+Text		0.832	0.703	0.349	0.137		0.148	0.083	0.198	0.335	0.210	0.131NaNTP+Tex+Attention	0.769	0.937	0.884	0.649	0.398	0.432	0.402	0.377	0.176	0.310	0.185	0.110We can also observe that ANNS, yield very close ranking results in comparison with Exact NNS, butorders of magnitude faster. This implies that, compared to a costly Exact NNS, ANNS is an optimalchoice for a heuristic, since it greatly decreases the computational complexity of the method.
Table 8: Performance of NaNTPs with attention (Attention) and without it (Standard) when using therandom nearest neighbour, ANNS and exact NNS for k = 1, on benchmark datasets.
