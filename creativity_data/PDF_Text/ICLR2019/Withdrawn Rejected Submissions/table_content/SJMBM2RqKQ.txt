Table 1: Utilized datasets summaryNames	#Classes	Train	TestFaCeSCrUb(Ng &Winkler,2014)	100	20,600	2,289, MNIST(LeCUnetal.,1998)	10	60,000	10,000 ',CIFAR100(KriZheVSky & Hinton, 2009)	100	50,000	10,000 ''NotMNIST (not)	10	16,853	1,873,SVHN(NetZeretal.,2011)	100	73,257	26,032 âˆ™,CIFAR10(KriZheVSky & Hinton, 2009)~~	10	39,209	12,630 'TrafficSigns (Stallkamp et al., 2011)	43	39,209	12,630 ''FashionMNIST (Xiao et al., 2017)	10	60,000	10,000 'Baselines: Within Bayesian framework, we have three reference baselines of fine-tuning, featureextraction, and joint training. In fine-tuning (BLLL-FT), training with regular SGD optimizationcontinues upon arrival of new tasks without any forgetting avoidance strategy. Feature extraction,denoted as (BLLL-FE) in our experiments, refers to freezing all layers in the network except for thelast layer when a new task arrives. In joint training (BLLL-JT) we learn all the tasks in a multi-task learning fashion which serves as the upper bound for average accuracy on all tasks. We havecompared these three Bayesian references with their counterparts using an ordinary (non-Bayesian)network referred to as ORD-FT, ORD-FE, and ORD-JT. We have compared them on Split MNISTclass incremental learning experiments. Along with the BLLL variants of reference baselines, wecompare with the state-of-the-art approaches including EWC Kirkpatrick et al. (2017), IMM (Lee
