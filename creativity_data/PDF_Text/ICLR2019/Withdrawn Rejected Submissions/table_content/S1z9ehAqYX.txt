Table 1: Hyperparameters in the training processA.3 Details of Model-based Learning in PPO-MBSA.3.1 Dynamic Model LearningWe represent the dynamic model fφ(a, S) with a 2-hidden-layer MLP with hidden sizes 512 X 512and ReLU as the activation function. We train the model with Adam (Kingma & Ba, 2014) optimizerwith learning rate 0.0003 using a batch size of 512 for every 5 policy optimizing iterations. The modelis trained over a subset randomly drawn from the training dataset with size 25,000 for 10 passes andwe use validation dataset for early stopping (We evaluate the validation loss for each model learningpass). Empirically we find resetting the model parameter φ every 15 policy optimizing iterationshelps improve to the performance.
Table 2: Detail of the environments used in our experimentssxpos -sxposSxvel denotes the x-axis velocity at time t, which is calculated by Sxvel = t+1 4t t-, wheredt = 0.02 in the Mujoco (Todorov et al., 2012) simulator. xbody, xarm, xfinger denote the position ofthe body, the arm and the fingertip of the object separately, and xgoal denotes the position of the goal.
