Table 1: Type of units available to the team.
Table 2: Codes of the objects available in the observation.
Table 3: Training hyperparametersFigure 3: First-person observation. Global observation is split into individual agent observationsand shifted to put the controlled agent into the center.
Table 4: Training procedure, experiments descriptionscalable. The first-person learning puts the controlled agent into the center of observation by shiftingthe map as shown in Figure 3. Moreover, it allows projecting observations of other friendly unitsonto the decoupled observations. This allows a convergence to a mutual (team-based) policy evenwith no the coordination between the units.
Table 5: Model structureWe understand that POMDP nature of the problem requires from us to use the temporal informationfrom the environment. However, we deliberately chose to not utilize Deep Recurrent Q-Networks(DRQNs) Hausknecht & Stone (2015); Omidshafiei et al. (2017) due to the complexity of the task.
