Table 1: F1 scores and accuracies on (a) the original test set and (b) matched test sets. Acrossthe board, the classifiers trained with the proposed reflective log-likelihood perform similarly to oroutperform those trained with maximum log-likelihood.
Table 2: Perplexity and KL divergence computed from the neural topic model trained on the20NewsGroup dataset. K denotes the number of posterior samples used during training. (?) Thedifference between VAE (K = 1) and IWAE (K = 1) comes from the fact that we use an analyticalsolution to the KL divergence in the case of VAE and sample-based approximation in the case ofIWAE.
Table 3: Class distributions using the MNIST dataset. There are 10 class—one class for each ofthe 10 digits in MNIST. The distribution D1 is uniform and the other distributions correspond todifferent imbalance settings as given by the proportions in the table. Note these proportions mightnot sum to one exactly because of rounding.
Table 4: Top ten words of five randomly selected topics for different models on the 20NewsGroupdataset. Overall RAE learns topics as good as LDA—a non-neural network based model that does notsuffer from posterior collapse. The VAE suffers from collapse and learns topics that are meaningless.
