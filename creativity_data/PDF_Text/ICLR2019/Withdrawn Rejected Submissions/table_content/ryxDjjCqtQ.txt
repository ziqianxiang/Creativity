Table 1: Hyperparameters for deconfounding reinforcement learning. Note that, we set the dimen-sion u to 1 in Section 4.4 for simplicity.
Table 2: Architectures for deconfounding reinforcement learning. Here FCk stands for a fully-connected layer with k units, ConVkm for a convolution layer withn filters of size k × k, LSTMn t for a LSTM layer rolling out for t steps with latent size of n, {∙} for the parallel operators, and [∙] for the sequential operators. Indefault, ECk and ConVkm are followed by a softplus activation layer and a batch-norm layer, which are omitted here for simplicity. Note that, in our setting, thetwo functions in each pair {f2i-1, f2i}i=1... 8 share the same parameters except for the last layer.
