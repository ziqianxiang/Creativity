Table 1: mini-ImageNet 64+5-way few-shot classification results			1-shot	5-shotModel	Backbone	Base	Novel	Both	∆	Novel	Both	∆MatchingNets (Vinyals et al., 2016)	-C64	-	43.60	-	-	55.30	-	-Meta-LSTM (Ravi & Larochelle, 2017)	C32	-	43.40 ± 0.77	-	-	60.20 ± 0.71	-	-MAML (Finn et al., 2017)	C64	-	48.70 ± 1.84	-	-	63.10 ± 0.92	-	-RelationNet (Sung et al., 2018)	C64	-	50.44 ± 0.82	-	-	65.32 ± 0.70	-	-R2-D2 (Bertinetto et al., 2018)	C256	-	51.20 ± 0.60	-	-	68.20 ± 0.60	-	-SNAIL (Mishra et al., 2018)	ResNet	-	55.71 ± 0.99	-	-	68.88 ± 0.92	-	-ProtoNet (Snell et al., 2017)	C64	-	49.42 ± 0.78	-	-	68.20 ± 0.66	-	-ProtoNet (our implementation)	ResNet	75.79	50.09 ± 0.41	42.73	-20.21	70.76 ± 0.19	57.05	-31.72LWoF (Gidaris & Komodakis, 2018)	ResNet	80.24	55.45 ± 0.89	51.23	-	70.92 ± 0.35	56.04	-LWoF (our implementation)	ResNet	74.58	56.97 ± 0.24	52.37	-13.65	70.50 ± 0.36	59.90	-14.18Ours (1st stage)	ResNet	77.17	54.78 ± 0.43~5274~-13.95	70.57 ± 0.36~6034~-13.60Ours (full model)	ResNet	76.84	55.72 ± 0.41	54.89	-11.39	70.50 ± 0.36	62.37	-11.48Table 2: tiered-ImageNet 200+5-way few-shot classification resultsModel	Backbone	Base	1-shot			5-shot					Novel	Both	∆	Novel	Both	∆ProtoNet (Snell et al., 2017)	ResNet	59.70	48.19 ± 0.43	34.49	-19.45	65.90 ± 0.19	50.27	-12.54LWoF (Gidaris & Komodakis, 2018)	ResNet	61.84	50.90 ± 0.46	54.05	-2.35	66.69 ± 0.36	62.32	-1.90
Table 2: tiered-ImageNet 200+5-way few-shot classification resultsModel	Backbone	Base	1-shot			5-shot					Novel	Both	∆	Novel	Both	∆ProtoNet (Snell et al., 2017)	ResNet	59.70	48.19 ± 0.43	34.49	-19.45	65.90 ± 0.19	50.27	-12.54LWoF (Gidaris & Komodakis, 2018)	ResNet	61.84	50.90 ± 0.46	54.05	-2.35	66.69 ± 0.36	62.32	-1.90Ours (1st stage)	ResNet	62.01	47.09 ± 0.42	48.58	-5.95	64.90 ± 0.41	59.73	-3.72Ours (full model)	ResNet	61.59	51.12 ± 0.45	55.56	-0.80	66.40 ± 0.36	63.27	-0.83tiered-ImageNet due to categorical splits. We used standard data augmentation, with random cropsand random horizonal flips. All of our models in our implementations use the same pretrained modelas the starting point for the second stage.
Table 3: Learning an attention attractor network using damped Neumann RBP vs. truncated BPTT.
Table 4: Ablation studies on tiered-ImageNet. “Base+” and “Novel+” are the prediction accuracieson Base and Novel classes within a joint query set.
Table 5: mini-ImageNet and tiered-ImageNet split statisticsClasses	Purpose	mini-ImageNet			tiered -ImageNet				SPlit	N. Cls	N. Img	Split	N. Cls	N. Img	Train	Train-Train	64	38,400	Train-A-Train	200	203,751Base	Val	Train-Val	64	18,748	Train-A-Val	200	25,460	Test	Train-Test	64	19,200	Train-A-Test	200	25,488	Train	Train-Train	64	38,400	Train-B	151	193,996Novel	Val	Val	16	9,600	Val	97	124,261	Test	Test	20	12,000	Test	160	206,209A. 1 Validation and testing splits for base classesIn standard few-shot learning, meta-training, validation, and test set have disjoint sets of objectclasses. However, in our incremental few-shot learning setting, to evaluate the model performanceon the base class predictions, additional splits of validation and test splits of the meta-training set arerequired. Splits and dataset statistics are listed in Table 5. For mini-ImageNet, Gidaris & Komodakis(2018) released additional images for evaluating training set, namely “Train-Val” and “Train-Test”.
Table 6: Learning an attention attractor network using damped Neumann RBP vs. truncated BPTT.
