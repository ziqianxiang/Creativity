Table 1: Comparison with state-of-the-art NAS methods on CIFAR-10.
Table 2: Comparison with state-of-the-art image classifiers on ImageNetArchitecture	Top-1/5	Params(M)	FLOPS(M)	Search Cost (GPU days)Inception-v1 (Szegedy et al. (2015))	30.2/10.1	6.6	1448	-MobileNet (Howard et al. (2017))	29.4/10.5	4.2	569	-ShuffleNet-v1 2x (Zhang et al. (2018))	26.3/10.2	5	524	-ShuffleNet-v2 2x (Ma et al. (2018))	25.1/-	5	591	-NASNet-A* (Zoph et al. (2018))	26.0/8.4	5.3	564	1800AmoebaNet-C* (Real et al. (2018))	24.3/7.6	6.4	570	3150PNAS* (Liu et al. (2018a))	25.8/8.1	5.1	588	150DARTS* (Liu et al. (2018b))	26.9/9.0	4.9	595	4OSNAS (Bender et al. (2018))	25.8/-	5.1	-	-MNAS-92 (Tan et al. (2018))	25.2/8.0	4.4	388	-DSO-NAS*	26.2/8.6	4.7	571	1DSO-NAS-full	25.7/8.1	4.6	608	6DSO-NAS-share	25.4/8.4	4.8	586	6It is notable that given similar computation budget, DSO-NAS achieves competitive or better perfor-mance than other state-of-the-art methods with less search cost, except for MnasNet whose searchspace is carefully designed and different from other NAS methods. The block structure transferredfrom CIFAR-10 dataset also achieves impressive performance, proving the generalization capabil-ity of the searched architecture. Moreover, directly searching on target dataset (ImageNet) brings
Table 3: Comparison of different settings on CIFAR-10 dataset.
