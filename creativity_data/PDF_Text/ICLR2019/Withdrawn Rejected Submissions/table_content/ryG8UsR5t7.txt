Table 1: Quantitative evaluation on the toy dataset	higher is better			lower is better	Method		~~LT~		CRPS	MeRCIOracle	-	-	-	-	19Constant	-	-	-	-	81Multi Inits	-0.65	-6.0	0.07	19.0	64-Bagging	-0.02	-4.8	0.13	16.8	-53-Monte Carlo Dropout	-0.03	-4.9	0.11	17.1	60Multi Epochs	-28	-6.9	0.0	19.3	816.4	ResultsFinally, we discuss the scores obtained for each uncertainty estimation technique. We expect Bag-ging as the top technique because it benefits from external sources of data. We also expect MultiEpochs to be the worst one, since in this setting, the network is likely to converge to a local mini-mum. Therefore there wonâ€™t be much informative variance across epochs.
Table 2: Methods scores and ranking for a specific NYU Depth v2 testset image according to eachmetric	Method		Qs	Ls	Ss	CRPS	MeRCIMulti Inits	-3.4	-1.9	0.87	0.12	0.40Bagging	-2.7	-1.6	0.90	0.12	05^Monte Carlo Dropout	-7.5	-3.3	0.61	.0.	-037-Multi Epochs	-2.3	-1.6	0.87	0.12	-034^Multi Networks	1.8	0.25	-^T3-	0.10	0.41Learned Error	I -67	-3.1	0.80		2.3(a) input(b) prediction(c) absolute error(d) Multi Inits(e) Bagging	(f) Monte Carlo Dropout(g) Multi Epochs(h) Multi Networks(i) Learned ErrorFigure 4: A NYU Depth v2 test case. First row: the test image along with a predicted depth mapand the corresponding absolute errors. Remaining rows: predictive uncertainties.
Table 3: Quantitative evaluation on the NYU Depth v2 test set. For comparison purpose, the depthprediction is the same for all the estimators.
Table 4: Quantitative evaluation on the NYU Depth v2 testset. For each method, we perform its ownprediction and uncertainty.
