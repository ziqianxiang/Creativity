Table 1: Node degree distribution distance between the generated and real graphs for scale free graphs					Graph size	Methods	Jensen-Shannon	Hellinger	Bhattacharyya	Wasserstein	Random-VAE	-0.42	0.98	Inf	7.58	GraphRNN	0.47	0.98	Inf	1.6410	GraphVAE	0.67	1.00	Inf	2.85	GraphGMG	0.43	0.98	Inf	1.69	S-Generator	0.35	0.98	3.45	0.80	GT-GAN	0.35	0.98	3.44	0.77	RandomVAE	-051	0.97	Inf	1.7420	GraphRNN	0.50	0.98	Inf	1.44	S-Generator	0.36	0.96	2.84	0.67	GT-GAN	0.35	0.96	2.74	0.66	Random-VAE	-069	0.99	Inf	7.9950	GraphRNN	0.49	0.94	Inf	1.44	S-Generator	0.31	0.90	1.70	0.34	GT-GAN	0.43	0.89	1.66	2.43	GraphRNN	-0.48	0.88	Inf	0.90100	S-Generator	0.14	0.68	0.64	0.30	GT-GAN	0.15	0.43	0.24	0.31	GraphRNN	-0.42	0.74	Inf	0.95
Table 2: Indirect evaluation for scale-free graphs Table 3: Poisson random graphs indirect evaluationSize	Method	P	R	AUC	F1	Size	Method	P	R	AUC	F1	RandomVAE	0.83	0.29	0.31	0.42		RandomVAE	0.98	0.75	0.99	0.85	GraphRNN	0.31	0.11	0.49	0.16		GraphRNN	0.98	0.99	0.99	0.98	GraphVAE	0.75	0.23	0.65	0.35		GraphVAE	0.98	0.92	0.97	0.9410	GraphGMG	0.42	0.12	0.49	0.18	10	GraphGMG	0.98	0.98	0.98	0.98	S-Generator	0.46	0.83	0.43	0.59		S-Generator	0.50	1.00	0.50	0.66	GT-GAN	1.00	0.50	0.52	0.67		GT-GAN	1.00	0.87	0.94	0.90	Gold Standard	0.81	0.74	0.82	0.77		Gold Standard	0.99	1.00	1.00	0.99	RandomVAE	0.50	1.00	0.54	0.66		RandomVAE	1.00	0.70	0.99	0.82	GraphRNN	0.67	0.12	0.50	0.21		GraphRNN	1.00	1.00	1.00	1.0020	S-Generator	0.50	1.00	0.50	0.67	20	S-Generator	1.00	1.00	1.00	1.00	GT-GAN	1.00	0.50	0.50	0.67		GT-GAN	1.00	0.99	1.00	0.99	Gold Standard	0.76	0.67	0.72	0.71		Gold Standard	0.99	1.00	1.00	0.99	RandomVAE	0.89	0.67	0.84	0.76		RandomVAE	0.93	0.46	1.00	0.63	GraphRNN	0.52	0.53	0.70	0.52		GraphRNN	1.00	0.99	0.99	0.9950	S-Generator	0.50	1.00	0.37	0.67	50	S-Generator	0.49	0.98	0.35	0.65	GT-GAN	0.93	0.82	0.94	0.87		GT-GAN	1.00	0.99	1.00	0.99	Gold Standard	0.94	0.90	0.97	0.91		Gold Standard	0.99	1.00	1.00	0.99	GraphRNN	0.61	0.65	0.67	0.60		GraphRNN	1.00	0.99	1.00	0.99
Table 4: Indirect evaluation in user authentication graph datasetsGraph size	Method	Precision	Recall	AUC	F1	RandomVAE	0.32	0.51	0.26	0.39	GraphRNN	0.34	0.36	0.50	0.3650	S-Generator	0.72	0.61	0.74	0.66	GT-GAN	0.79	0.68	0.78	0.73	Gold Standard	0.97	0.97	0.97	0.97	S-Generator	0.77	0.58	0.62	0.66300	GT-GAN	0.84	0.66	0.79	0.74	Gold Standard	0.98	0.96	0.97	0.97Results on User Authentication Graphs: As shown in Table 4, classifiers trained by the graphsgenerated by GT-GAN can effectively classify normal and hacked behaviors with AUC above 0.78,largely above the 0.5 if using random model. GT-GAN significantly outperforms other methods byaround 25%, 16%, 24.5% and 22.1% respectively on four metrics. GT-GAN performs consistentlybetter than other baselines when the graph size varies from 50 to 300. More indirected evaluationresults can be found in Fig. 9 and Fig. 8 in Appendix C, including the case studies.
Table 5: MSE of Graph properties measurements for poisson random graphsGraph size	Method	Density	Average Degree	Reciprocity	RandomVAE	0.1772	2.8172	0.3917	GraphRNN	0.2665	2.2078	0.134410	GrapgGMG	0.3519	2.4286	0.1338	GraphVAE	0.2881	3.1986	0.3103	S-Generator	0.2993	1.5751	0.0737	GT-GAN	0.3084	1.7707	0.1327	RandomVAE	0.2078	7.0860	0.418220	GraphRNN	0.2305	4.9256	0.1190	S-Generator	0.2111	3.2207	0.0430	GT-GAN	0.2013	3.2047	0.0388	RandomVAE	Inf	23.680	0.536250	GraphRNN	0.0110	3.6000	0.0125	S-Generator	0.0120	2.9082	0.0125	GT-GAN	0.0155	3.2960	0.0047	GraphRNN	0.0123	3.5475	0.0034100	S-Generator	0.0029	2.9167	0.0034	GT-GAN	0.0142	4.3730	0.0043	GraphRNN	0.0012	3.6619	0.0016
Table 6: MSE of Graph properties measurements for user authentication datasetGraph size	Method	Density	Reciprocity	Average Degree	RandomVAE	0.0005	0.0000	6.406450	GraphRNN	0.0032	0.0000	2.7751	S-Generator	0.0244	0.0342	24.130	GT-GAN	0.0003	0.0000	0.0002300	S-Generator	0.0113	0.0010	8.6839	GT-GAN	0.0004	0.0000	0.0006Figure 8: Regular graphs, malicious graphs and generated graphs of User 049C More experimental results for User authentication Graph SetAbout Original Dataset This data set spans one calendar year of contiguous activity spanning2012 and 2013. It originated from 33.9 billion raw event logs (1.4 terabytes compressed) collectedacross the LANL enterprise network of approximately 24,000 computers. Here we consider twosub dataset. First is the user log-on activity set. This data represents authentication events collectedfrom individual Windows-based desktop computers, servers, and Active Directory servers. Anotherdataset presents specific events taken from the authentication data that present known red teamcompromise events, as we call malicious event. The red team data can used as ground truth of badbehavior which is different from normal user. Each graph can represent the log-on activity of oneuser in a time window. The event graphs are defined like this: The node refers to the computersthat are available to a user and the edge represents the log-on activity from one computer to another
