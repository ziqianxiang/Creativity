Table 1: A summary of the datasets used in our experiments and how they are partitioned.
Table 2: (a) Entity classification results accuracy (mean and standard deviation over 10 seeds)for FEAT (Paulheim and Fumkranz, 2012), WL (ShervashidZe et al., 2011; de Vries andde Rooij, 2015), RDF2Vec (Ristoski and Paulheim, 2016) and RGCN (Schlichtkrull et al.,2018), and (mean and standard deviation over 200 seeds) for our implementation of RGCN,as well as additive and multiplicative attention for (C-)WIRGAT and (C-)WIRGAT (thiswork). Test performance is reported on the splits provided in Ristoski and Paulheim (2016).
Table 3: Graph classification mean Area Under the Curve (AUC) across all 12 tasks(mean and standard deviation over 3 splits) for Multitask (Ramsundar et al., 2015), Bypass(Wu et al., 2018), Weave (Kearnes et al., 2016), RGCN (Altae-Tran et al., 2016), ourimplementation of RGCN, additive and multiplicative attention versions of WIRGAT andARGAT (this work). Training, validation and test performance is reported on the splitsprovided in Wu et al. (2018). Best performance in class in boldened, and best performanceoverall is underlined.
Table 4: Priors on the hyperparameter search space for the transductive tasks. Whenmultihead attention is used, the number of units per head is appropriately reduced in orderto keep the total number of output units of an RGAT layer independent of the number ofheads.
Table 5: Priors on the hyperparameter for the inductive task. The batch size was held at 64,and no bases decomposition is used. When multihead attention is used, the number of unitsper head is appropriately reduced in order to keep the total number of output units of anRGAT layer independent of the number of heads.
