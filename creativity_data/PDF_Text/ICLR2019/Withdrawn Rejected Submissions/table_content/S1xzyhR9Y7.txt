Table 1: Summary statistics of the three corpora used in our experiments. For simplicity, the threecorpora will be referred to as 1, 2 and 3 in the following tables respectively.
Table 2: Representation pooling in testing phase. "max(∙)”, "mean(∙)”, and "min(∙)“ refer toglobal max-, mean-, and min-pooling over time, which result in a single vector. The table alsopresents the diversity of the way that a single sentence representation can be calculated. Xi refersto word vectors in i-th sentence, and Hi refers to hidden states at all time steps produced by f .
Table 3: Results on unsupervised evaluation tasks (Pearson’s r × 100) . Bold numbers are thebest results among unsupervised transfer models, and Underlined numbers are the best ones amongall models. ‘G' and 'D' refer to generative and discriminative objective respectively. 'WR' refers tothe post-processing step that removes the top principal component.
Table 4: Comparison with FastSent and QT on STS14 (Pearson's r × 100).
Table 5: Supervised evaluation tasks. Bold numbers are the best results among unsupervisedtransfer models, and Underlined numbers are the best ones among all models. “千" refers to anensemble of two models. “*” indicates that additional labelled discourse information is required.
Table 6: Ablation study on our multi-view frameworks. Variants of our frameworks are testedto illustrate the advantage of our multi-view learning frameworks. In general, under the proposedframeworks, learning to align representations from both views helps each view to perform better andan ensemble of both views provides stronger results than each of them. The arrow and value pairindicate how a result differs from our multi-view learning framework. Better view in colour.
Table 1: Details about the evaluation tasks used in our experiments.
Table 2: Effect of the Post-processing Step. ‘WR’ refers to the post-processing step (Arora et al.,2017) which removes the principal component of a set of learnt vectors. The postprocessing stepoverall improves the performance of our models on unsupervised evaluation tasks, and also improvesthe models with generative objective on supervised sentence similarity tasks. However, it doesn’thave a significant impact on single sentence classification tasks.
Table 3: Our multi-view framework with both generative and discriminative objective. ‘GD1’refers to a model with both generative and discriminative objectives trained on BookCorpus. Theresults here don’t show significant difference against the model trained with only one objective.
