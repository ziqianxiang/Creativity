Table 1: Human normalized scores for experts on ATARI.
Table 2: Performance on ImageNet Test DatasetModel	Top-1	Top-5Resnet-50 (He et al. (2016))	75.6%	92.9%Resnet-50 (our setup)	74.0%	91.1%Resnet-50, Sequence Length 4	70.2%	88.6%Attention + Resnet-50, Sequence Length 1	73.1%	90.1%Attention + Resnet-50, Sequence Length 4	73.4%	91.0%Attention + Resnet-50, Sequence Length 8	74.5%	91.5%For ImageNet, S3TA initially attends to low-level edges (mostly around the contour of the object).
Table 3: The network sizes used in the attention agentWe an RMSProp optimizer with = 0.01, momentum of 0, and decay of 0.99. The learning rate is2e - 4. We use a VTRACE loss with a discount of 0.99 and an entropy cost of 0.01 (described inEspeholt et al. (2018)); we unroll for 50 timesteps and batch 32 trajectories on the learner. We cliprewards to be in the range [-1, 1], and clip gradients to be in the range [-1280, 1280]. Since theframerate of ATARI is high, we send the selected action to the environment 4 times without passingthose frames to the agent in order to speedup learning. Parameters were chosen by performing ahyperparameter sweep over 6 levels (battle zone, boxing, enduro, ms pacman, seaquest, star gunner)and choosing the hyperparameter setting that performed the best on the most levels.
Table 4: The human-normalized score of agents on all ATARI levels.
Table 5: The scores of the attention agent compared to the two bottom-up experiments described inthe text.
Table 6: The network sizes used in the ImageNet model.
Table 7: The network sizes used in the Kinetics600 model.
