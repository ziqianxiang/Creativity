Table 1: Results of the best models found. We take the best model obtained during the searchand train it from scratch. ENAS* corresponds to the results of Pham et al. (2018) obtained afterextensive hyper-parameter search, while ENAS and ENAS+WPL were trained in comparable con-ditions. For both RNN and CNN search, our WPL gives a significant boost to ENAS, thus showingthe importance of overcoming multi-model forgetting. In the RNN case, our approach outperformsENAS* without requiring extensive hyper-parameter tuning. The best results in each row are bold.
