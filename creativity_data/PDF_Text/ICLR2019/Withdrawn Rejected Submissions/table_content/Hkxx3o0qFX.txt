Table 1: The quantitative comparison between our method and state-of-the-art methodsMethod	Resolution	L1 (%)	L2 (%)	PSNRGL(IizUkaetaL,2017)	128 X 128	9.34	1.75	18.22Ours	128 X 128	-78-	1.42	19.15CTX(YU et al.,2018)	256 × 256	8.53	1.75	18.41Ours	256 X 256	7.05	1.21	19.97Quantitative Comparison with State-of-the-art Methods As noted in literatures (Yeh et al., 2017;Yu et al., 2018), reconstruction metrics such as mean L1, L2 errors and peak signal-to-noise ratio(RSNR) that are commonly used are not good quantitative evaluation metrics for inpainting methodssince image completion aims at completing missing regions with plausible content rather thanreconstructing it. As a reference, we show the comparison between our method and state-of-the-art models at their reported resolutions respectively: 128 × 128 for GL with center masks (usingimplementation of (Yu et al., 2018)) and 256 × 256 for CTX with random masks (Table 1).
Table 2: Top: the Encoding component of generator Genc ; Bottom: Latent Layer. N is the lengthof an attribute vector. The attribute concatenation operation (AttrConcat) is only activated for ourconditional model.
Table 3: The completion component of generator Gcompl. Depending on the particular operation ofthe skip connection (Skip), the number of filters is either doubled (for concatenation operations) orremains the same (for addition operations). In practice, Gcompl output a feature map that can be usedto generate a RGB image (with ToRGB layers) or predict a read/write Filter (with ToFilter layers, seeTable 4).
Table 4: Left: The ToRGB layers that convert feature maps to RGB images. Right: ToFilter layersthat predict a read/write filter from feature maps.
Table 5: Top: Feature Network F(∙) computes a feature map for an input image, which is later usedby Dcls and Dattr; Middle: The real/fake head classifier Dcls; Bottom: The attribute network Dattr.
