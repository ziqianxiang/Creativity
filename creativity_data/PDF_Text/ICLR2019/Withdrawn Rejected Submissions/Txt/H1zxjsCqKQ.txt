Under review as a conference paper at ICLR 2019
GRADIENT-BASED LEARNING FOR THE F -MEASURE
AND OTHER PERFORMANCE METRICS
Anonymous authors
Paper under double-blind review
Ab stract
Many important classification performance metrics, e.g. the F -measure, are non-
differentiable and non-decomposable, and are thus unfriendly to the gradient de-
scent algorithm. Consequently, despite their popularity as evaluation metrics,
these metrics are rarely optimized as training objectives in neural network com-
munity. In this paper, we propose an empirical utility maximization scheme
with provable learning guarantees to address the non-differentiability of these
metrics. We then derive a strongly consistent gradient estimator to handle non-
decomposability. These innovations enable end-to-end optimization of these per-
formance metrics with the same computational complexity as optimizing a de-
composable and differentiable metric, e.g. the cross-entropy loss.
1	Introduction
Different classification performance metrics are capable of revealing different aspects of a classi-
fier’s behavior. For example, the F -measure (Van Rijsbergen (1974)), compared to performance
metrics such as accuracy, is better at evaluating a classifier’s performance when it encounters a sam-
ple belonging to a class that occurs with low frequency. Ideally, we can acquire a classifier with
very tailored behavior by optimizing the classifier with respect to a carefully chosen performance
metric. Unfortunately, many performance metrics, e.g. the F -measure, are non-differentiable and
non-decomposable, which renders it very difficult to optimize neural network classifiers with these
metrics as training objective.
In this paper, we propose a method that enables gradient-based learning for these performance met-
rics. Our contributions are the following:
•	We propose a learning algorithm based on empirical utility maximization for a class of
performance metrics and prove its generalization and consistency.
•	We propose a strongly consistent gradient estimator that enables efficient gradient-based
maximization of empirical utility.
•	We demonstrate experimentally that the binary F1 score of neural network classifiers can
be efficiently optimized on datasets of decent scale and complexity.
We organize this paper as the following. In Section 2, we will sketch our method for the binary
F1 score to provide an overview. In Section 3, we will present our method in its general form. We
review related work in Section 4 and provide experiment results in Section 5.
2	GRADIENT-BASED LEARNING FOR THE BINARY F1 SCORE
2.1	Probabilistic classifier
Given a feature vector X ∈ X ⊂ RN, a probabilistic classifier h first infers a posterior p(∙∣x) over
a discrete output space Y and then samples its output from the posterior, i.e. h(x)〜p(∙∣x). In
practice, p(∙∣x) is typically the output of a neural network with softmax layer on its top.When the
posterior is parameterized, e.g. being implemented as a neural network, We denote it as pθ (∙∣x) and
the corresponding probabilistic classifier as hθ .
1
Under review as a conference paper at ICLR 2019
Given a posterior p(∙∣x), a deterministic classifier can result from the inference rule h(x) =
argmaxy∈Y p(y|x).The difference between probabilistic and deterministic inference rules is negli-
gible when the posterior is very concentrated. Although deterministic classifiers are more popular
in the literature, in this paper we only consider probabilistic classifiers and leave it as future work to
investigate the case where a probabilistic classifier is replaced by a deterministic one.
2.2	F -MEASURE
Consider the case of binary classification, where Y = {0, 1} with 1 and 0 respectively corresponding
to the positive and negative class. Given a dataset D = {(x1, y1), ..., (xn, yn)} consisting ofn i.i.d.
pairs of feature vector and ground truth, let yi denote the label predicted by a classifier h given
Xi (not necessarily deterministically). Let y^ = (yi,..., yn) and y = (yi,…，yn). Then the true-
positive, false-positive, false-negative and true-negative rate corresponding to y^ and y are defined
as
1n
tp(y, y) := n EI (yi = 1 ∧ y = I)
i=i
1n
fn(y, y) := - EI (yi = 0 ∧ yi = 1)
n i=i
fp(y, y):
tn(y, y) :
where I denotes indicator function. The precision and recall are defined as
PreCiSion(y, y) =「tp(y, y∖y	recall(y, y) = tp(y, y)	(1)
tp(y, y) + fp(y, y)	PD
wherePD := ɪ Pn=ιI(yi = 1) denotes the proportion of samples in D that belong to positive class.
The binary F -measure is defined as (Van Rijsbergen (1974)):
2 /ʌ。八 _ ∩ , a` PreCiSiOn(y,y) ∙recall(y,y)	八 n	zɔʌ
β(y, y) = ( + β ) ∙ β ∙ precision(y, y) + recall(y, y)	β >	( )
or equivalently,
Fe (y, y) = (1+ β2) ∙	2 PD -fn(y, y[ftv, ` β> 0	(3)
(1 + β2 )pD - fn(y, y) + fp(y, y)
which is more convenient for our purpose.
We will refer to Fe (y, y) as the data-dependent binary Fe-measure because it is evaluated on a
specific set of data with pairs of ground truth and prediction vectors. Fβ is non-differentiable because
itis a composition of indicator functions. Nor does it decompose over samples in D. More precisely,
we are not aware of any function fe that only depends on per sample ground-truth and prediction
such that
1n
Fe (y, y) = - Efe (yi,yi)
n i=i
In the following we propose an empirical utility maximization scheme for optimizing the Fe-
measure of probabilistic classifiers. For ease of exposition, in this section we focus on the binary
Fi-measure, a.k.a. the binary Fi score. In Section 3, we will extend the method presented in this
section to a family of non-decomposable and non-differentiable performance metrics, including Fe-
measure for multi-class classification.
2.3 GRADIENT-BASED LEARNING FOR THE BINARY Fi SCORE
We consider a parameterized binary probabilistic classifier hθ . By linearity of expectation and the
i.i.d. assumption,
Ey,y [fp(y, y)] = P(y = 1 ∧y = 0)
where the expectation is taken over all datasets with a fixed size n and all possible predictions of
hθ. Similarly, Ey,y [fn(y, y)] = P(y = 0 ∧ y = 1). Letfn(hθ) := Ey,y [fn(y, y)] and fp(hθ) :=
Ey,y [fp(y, y)]. It follows from the law of large number that
Ilim fn(y, y) = fn(hθ)	Ilim fp(y, y) = fp(hθ)
∣D∣→∞	∣D∣→∞
2
Under review as a conference paper at ICLR 2019
with probability 1, where |D| denotes the size of dataset D. Thus on sufficiently large datasets,
fn(y, y) ≈ fn(hθ)	fp(y, y) ≈ fp(hθ)
With these approximate identities, We have the following approximation of Fι(y, y):
Fι(y, y) = 2 ∙	+ PD - fn(y，y— ≈ 2 ∙	+ pS- 侪®L	:= Fg)⑷
2pD - fn(y, y) + fp(y, y)	2pD - fn(hθ) + fp(hθ)
which implies that the F1 score of any predictions of hθ on any sufficiently large dataset is close to
Fι(hθ). We call Fι(hθ) the expected utility of the Fi score and will state the precise meaning of
Fi(y, y) ≈ Fι(hθ) in Section 3. The key point is that we can optimize Fι(hθ) instead of Fι(y^, y) if
we are interested in the Fi score of hθ on sufficiently large datasets. However, fn(hθ) and fp(hθ) are
unknown because they are expectations taken over data distribution (and the classifier,s posterior).
Consequently, we have to estimate fn(hθ) and fp(hθ) by sampling from data distribution in order to
estimate Fι(hθ), as the following.
Let p+ := P(y = 1) denote the probability that a positive sample occurs, which can be estimated
by the frequency of positive samples in a training set D. Let n+ := P(x,y)∈D I(y = 1) denote the
number of positive samples in the training set. Assume that the data distribution admits a density
function (i.e. the data distribution is absolutely continuous w.r.t. the Lebesgue measure), and denote
its density function by p. We have the following unbiased estimator offn(hθ):
fn(hθ) = P (y = 0 ∧ y = 1)
=	P(hθ (x) = 0)p(x, 1) dx
X
=	pθ (0|x)p(x|1)p+ dx
X
= p+	pθ (0|x)p(x|1) dx
X
=p+Eχ 〜p(∙∣i)[pθ (0|x)]
p+ n+
≈ np+ ɪ^pθ (o∣χ+) ：= fnD (hθ)
i=i
(5)
where xi+, ..., xn++ are the feature vectors of samples belonging to the positive class in trainingset
D . Similarly,
- n-
fp(hθ) = P(V = 1 ∧y = O) ≈ n-Xpθ(1lx-):= fpD(hθ)
n	i=i
where p- := P(y = 0), n- := P(x,y)∈D I(y = 0), and xi-, ..., xn- are the feature vectors of
samples in D belonging to the negative class. Thus Fι(hθ) can be estimated as the following:
Fι(hθ) = 2 ∙
p+ - fn(hθ)
2p+ — fn(hθ) + fp(hθ)
I	^	,一、
P+ - f∏D(hθ)
^^ ： ^ ___ ； ^ __ ^
2p+ - fbnD(hθ) +fbpD(hθ)
ʌ .
Fd(hθ)
(6)
I-V T ∙11 . . . 1	♦	♦	Cj=I / 7 ∖ ★ /7 ∖ ♦ C ,♦ C T .	. ∙ 1 1 .1	1 ∕' / ʌ ∖
We will state the precise meaning of Fi (h8) ≈ FD (hθ) in Section 3. Interestingly, although fn(y, y)
and fp(y, y) are not differentiable, the estimators of their expectations, fnD(hθ) and fpD(hθ), are
differentiable w.r.t. θ if pθ is differentiable. Because FD (hθ) is differentiable w.r.t. fn(hθ) and
fp(hθ), VθFD(hθ) can be computed by chain rule. Consequently, gradient descent can be applied
to optimize FD (θ).
We call FD(θ) the empirical utility of the expected utility Fi(hθ). They correspond to empirical
and expected risk in the classical empirical risk minimization principle of statistical learning the-
ory (Vapnik (1992)). We use the term “empirical utility maximization” because we would like to
maximize, instead of minimize these performance metrics. There are two fundamental questions for
every empirical risk minimization style learning algorithm, as the number of samples increases:
3
Under review as a conference paper at ICLR 2019
y 1	1 ∙	y 1 ∙	7	1	R /7、 ^j=I /7、	I 7-Λ I	C
•	Generalization. Given hθ, does FD(hθ) → F1(hθ) as |D| → ∞?
Z-X	♦ .	1 ʌ	R ∕7∖^	∙j=l∕7∖	I 7-Λ I	C
•	Consistency. Does argmaxθFD(hθ) → argmaxθF1(hθ) as |D| → ∞?
We will address these two questions at the end of Section 3. For the moment let us consider a
practical issue: how to maximize empirical utility FD (hθ) efficiently with gradient descent?
2.4 Gradient estimator
In order for the approximation in Eq. 6 to be accurate, |D| has to be sufficiently large. In or-
der to optimize FD (hθ) efficiently Via minibatch gradient descent, VθFD (hθ) has to be estimated
by VθFB(hθ), where B ⊂ D is a mini-batch, such that EB [VθFB(hθ)] = VθFD(hθ). Sup-
pose FD (hθ) is decomposable, i.e. there is a per-sample loss function f such that FD (hθ) =
|D| P(X y)∈D f(Pθ(x), y), then it simply follows from linearity of differentiation and expectation
that the requirement is satisfied. However, as FD (hθ) is non-decomposable, it becomes unlikely
that VθFB(hθ) is an unbiased estimator of VθFD(hθ). Fortunately, as a consequence of Theorem
1, VθFB(hθ) is a strongly consistent estimator of VθFD(hθ) when |D| is sufficiently large. More
precisely,
P I lim VθFB (hθ) = lim VθFD (hθ))=1	(7)
∖JB∣→∞	∣D∣→∞	I
Thus VθFB(hθ) is almost as good as an unbiased estimator. More interestingly, the error incurred
by estimating VθFD(hθ) with VθFB (hθ) can be further controlled. In the following we omit the de-
pendence on hθ for brevity. Let φD := (fnD(hθ), fpD(hθ)) ∈ R2 and φB := (fnB(hθ), fpB (hθ)) ∈
2
R2. Let JD and JB denotes the Jacobian of Φd and Φb w.r.t. θ. Let | ∙ | denote a vector norm and
∣∣∙∣∣ denote the matrix norm induced by it. By chain rule,
一 ʌ 一 ʌ ^
Vθ FB = VΦb FB JB
=(vΦd fD + w) (JD + E)
=vΦd FDJD + vΦd FD E + EJD + WE
(8)
.	LR	.	.	1	C ♦	「.一 El	C	r /7	、	?	/7	、
where Vψ□ FD ∙ JD is the true gradient and W ∙ E is negligible. The error E = JB (hθ) 一 JD(hθ)
ʌ ʌ
is intrinsic in the sense that it results immediately from estimating VθfnD(hθ) and VθfpD(hθ)
^ ^
with VθfnB (hθ) and VθfpB (hθ) and it is always present in mini-batch gradient descent because
^ ^ ^ ^
E[VθfnB (hθ)] = VθfnD(hθ) and E[VθfpB (hθ)] = VθfpD(hθ). However, we can control the
r	1	I	ɪɪl -Il ɪ^l I I I	1	1 I I ɪɪl I	F 1∙	ICl	1 .1	C
error W ∙ JD	because	|w	∙ J| ≤ || J|| ∙ |w|	and	we can control || J||	by limiting	∣θ∣	and the norm	of
intermediate activations when pθ is a neural network (He et al. (2015)). Despite these technicalities,
the trick is very easy to implement: batch normalization (Ioffe & Szegedy (2015)) and weight decay
will suffice. These are summarized in Algorithm 1.
Algorithm 1 Gradient-based learning for the binary F1 score
Require: classifier hθ, batch size b, dataset D, learning rate a, weight decay strength λ
p+ J ⅛ P(χ,y)∈D I(y = 1)
P- J ∣D∣ P(x,y)∈D I(y = 0)
while terminating criterion not satisfied do
Sample B+ = {(x1+, 1), ..., (xb+, 1)} from D
Sample B- = {(x1-, 0), ..., (xb-, 0)} from D
fn J p+ PLIpθ(0lx+)
fp J P- Pb=ιpθ(i∣χ-)
δ jVθ (Fι(fn,fp) - λ ∙ ∣θ∣)
θ J θ + α ∙ δ
end while
4
Under review as a conference paper at ICLR 2019
3 Gradient-based learning for a class of performance metrics
The binary F -measure in fact belongs to a class of performance metrics that are well behaved func-
tions of the confusion matrix. In this section, we propose a gradient-based learning algorithm that
extends the approach illustrated in previous section to this class of performance metrics. We state
theorems concerning the generalization and consistency of the proposed algorithm as well. We defer
all proofs to appendix. We begin with a specification of this class of performance metrics, which
relies on the definition of confusion matrix:
Definition 1. Given a dataset D = {(x1, y1), ..., (xn, yn)}, lety = (y1, ..., yn) denote the vector of
ground truth and y = (yι,..., yn) denote a vector of classifier predictions. Then the corresponding
data-dependent confusion matrix C(y^, y) is defined as
1n
(C(y, y))ij := n EI (yk = i ∧ y® = j)	0 ≤ i,j ≤ |Y| - 1
n k=1
In the case of binary classification,
c(y, y)=
tn(y, y)
fp(y, y)
fn(y, y)
tp(y, y)
Let P be a probability measure induced by data distribution and a probabilistic classifier hθ over
X ×Y × Y, i.e. triples of feature vector, ground truth and classifier prediction. Let C(hθ) be the
entry-wise expectation of C(y, y) over P, referred to as the expected confusion matrix. Formally,
(C(hθ))j := E [I(hθ(X) = i ∧ y = j)] = P(hθ(X) = i ∧ y = j)	0 ≤ i,j ≤ |Y| -1
As in Section 2, given a training set D, We have the following unbiased estimator of C(hθ), referred
to as the empirical confusion matrix:
nj
(CD (hθ %=njX pθ (i∣χk)	0 ≤ i,j ≤ iyi- 1
where n := P(X 号)三0 I(y = j), Pj := -D, and x《，...，Xnj are the feature vectors of samples that
belong to the j -th class. Almost sure convergence follows from the law of large number:
P (Dm∞(C(y，y))ij = (SQ = 1 P (Dm∞ (C。% ))j =…G = 1 ⑼
The confusion matrix is well-defined for both single-label and multi-label classification (although
these two settings impose different constraints on its entries). Many performance metrics are func-
tions of the confusion matrix. For example, the accuracy of hθ is Pi=1 Cii (hθ). The Fe measure for
multi-class classification can be defined in term of entries of the confusion matrix as the following.
We first define for every class the data-dependent false positive and false negative rate as
fpi =	Cij	fni =	Cji	i = 1, ..., |Y|
j6=i	j 6=i
where we omit the dependence on y and y for brevity. The data-dependent macro and micro F -
measure (Parambath et al. (2014)) are defined in term of fpi and fni as
F macro
1 + β2	Pi — fni
|Y|	⅛ (1 + β2)Pi - fni + fpi
β>0
FmiCrO = (1+ β2) ∙
P|iY=|1 Pi - P|iY=|1 fni
(1+ β2) Pi=1 Pi- Pi=1 fni + Pi=1 fpi
β>0
C 1 ♦	/ ʌ ∖ 1 K /7 ∖ 1 人 /7 ∖ ∙ . 1	1 i' ∙ .∙	∙ 11	. ∙ 1	1 . ∙ .1	. 1
Replacing C(y, y) by C(hθ) and C(hθ) in these definitions will respectively result in the expected
and empirical F -measure.
We now specify the class of performance metrics that we are interested in, namely the class of
well-behaved performance metrics. In the following, we will consider C(y, y), C(hθ) and CD(hθ)
as vectors of dimension |Y | × |Y | and identify a performance metric with a function that maps
|Y | × |Y |-dimensional vectors to real values.
5
Under review as a conference paper at ICLR 2019
Definition 2. We say that a performance metric F : K 7→ R, where K is a compact subset of
RlYl×lYl, is well-behaved if F is continuously differentiable on K.
Please refer to appendix for a non-exhaustive list of well-behaved performance metrics. Importantly,
the binary F1 score and the macro and micro F -measure are well-behaved performance metrics
(proof deferred to appendix).
Given a well behaved performance metric F, its corresponding data-dependent, expected and em-
Pincal utility are respectively defined as F(C(y, y)), F(C(hθ)) and F(C(hθ)). The following
theorem establishes asymptotic equivalence between these three kinds of utilities.
Theorem 1. If F is a well-behaved performance metric and CD is a strongly consistent estimator
of C, i.e.
P lim (CD)ij =Cij	= 1	0 ≤i,j ≤ |Y| -1
∖ I Γ)∖—yl^vι	J	I
| D∣→∞
then F (CD) is a strongly consistent estimator ofF(C), i.e.
P lim F (CD) = F(C)	= 1
∣D∣→∞
As a consequence of this theorem, it follows from Eq. 9 that
P lim F(C(y, y)) = F(C(hθ)) =1 P lim F(CD(hθ))= F (C(hθ))	=1
∣D∣→∞	)	∖∣D∣一∞
♦	Λ . 1 L / ∕~r / ʌ ∖ ∖	1 T-l /	/7	∖ ∖	.	1	∙	.	Γ∙ /	1	.	∖
i.e. both F(C(y, y)) and F(C(hθ)) are strongly consistent estimators of (converge w.p. 1 to)
F(C(hθ)). As a special case,
P lim Fι(y, y) = Fι(hθ) =1 P lim Fι(hθ) = Fι(hθ) =1
∣D∣→∞	)	∖∣D∣一∞
which justifies Eq. 4 and Eq. 6 when the dataset of interest is sufficiently large. Next we consider
the issue of gradient estimation in this general setting.
Theorem 2.	If F is a well behaved performance metric, then Vθ F (CB (hθ)) Isastronglyconsistent
estimator of VθF(C(hθ)), where B ⊂ D is a mini-batch. More precisely,
P lim VθF CB(hθ) = VθF (C(hθ)) =1
| B | →∞
As proved in Chen & Luss (2018), many convergence guarantees for stochastic gradient descent with
unbiased gradient estimators holds for stochastic gradient descent with strongly consistent gradient
estimators with probability 1. As illustrated in Eq. 8, batch normalization and weight decay can
help control the noise of estimator. Please refer to Algorithm 2 for the resultant algorithm.
Finally, we state two theorems concerning the generalization and consistency of Algorithm 2. Rates
of convergence are omitted for brevity.
Theorem 3	(Generalization). For a well behaved performance metric F, for all > 0,
lim P IF(CD (hθ)) - F(C(hθ ))1 <e =1
∣D∣→∞
Theorem 4	(Consistency). Fora well behaved performance metric F, with appropriate constraints
on the capacity of parametric model pθ (see the proof for details), we have that for all > 0,
lim P
∣D∣→∞
arg max F(CD (hθ)) — arg max F (C(h®)) < e
i.e. Algorithm 2 is consistent.
1
6
Under review as a conference paper at ICLR 2019
Algorithm 2 Gradient-based learning for well behaved performance metrics
Require: batch size b, classifier hθ, dataset D, learning rate a, weight-decay strength λ, and Well-
behaved metric F
for i = 1, ..., |Y| do
Pi J ∣dD∣ P(x,y)∈D I(y = i)
end for
while terminating criterion not satisfied do
for i = 1, ..., |Y | do
Sample Bi = {(xi1, i), ..., (xib, i)} from D
Computepθ(∙∣xj),…,pθ(∙∣xb)
end for
for i = 1, ..., |Y | do
forj = 1, ..., |Y| do
CijJ ρj Pk=I pθ (iιxk)
end for
end for
δ JVθ (F(C) - λ∣θ∣)
θ J θ + α ∙ δ
end while 4
4 Related work
The optimization of non-decomposable and non-differentiable performance metrics, especially F-
measure, has been extensively studied. The heuristic algorithm considered in Jansche (2005) and
Pastor-Pellicer et al. (2013) is essentially Algorithm 1 without techniques that stabilize gradient
estimation. However, Jansche (2005) and Pastor-Pellicer et al. (2013) are not very well motivated
theoretically and provide little mathematical insight into the heuristic. Also, as shown in Section 5,
applying this heuristic algorithm without stabilization techniques can easily result in non-convergent
models, even for a three-layer fully-connected network.
Another series of papers (Joachims (2005), Kar et al. (2014) and Narasimhan et al. (2015)) study
optimizing differentiable lower bounds of various non-decomposable and non-differentiable binary
classification metrics for linear classifiers. Despite proved learning guarantees for linear classifier,
these lower bound methods are not very promising when applied to neural networks, as reported in
Sanyal et al. (2018).
Thresholding is a computationally economical method if we only consider binary classification.
Koyejo et al. (2014) proves that the optimal classifier with respect to a family of binary classifi-
cation metrics, including the F -measure, is appropriately thresholded Bayes classifier. Given an
approximation of Bayes classifier, we can approach the optimal threshold via grid search. However,
it remains unknown how to generalize thresholding to multi-class classification. More importantly,
for binary classification, when training set is extremely imbalanced, it can be very difficult to train a
classifier that approximates Bayes classifier very well.
The computational cost of aforementioned methods roughly equals that of training classifiers with
standard classification losses such as cross-entropy. As proved in Parambath et al. (2014) and Koyejo
et al. (2014), optimization of many performance metrics, including F -measure, can be reduced to
weighted classification. Unfortunately, the optimal weight is in general unknown and has to be
approximated by an expensive grid search (see Section 5). Despite its computational cost, unlike
thresholding, this method can perform reasonably well even when a training set is extremely bal-
anced. Eban et al. (2016) proposes a similar method that performs well for neural networks coupled
with the AUCPR metric.
Regarding theory, the equivalence between the data-dependent and expected utility of the F -measure
was first proved in Nan et al. (2012) and later generalized in DembczynSki et al. (2017) to P-LiPSchitz
binary classification performance metrics.
7
Under review as a conference paper at ICLR 2019
Table 1: Dataset statistics and results
DATASET	# FEATS	# SAMPS	% POS	F1 GS	F1 EUM
Adult	108	48,842	23.93	0.701	0.689
CIFAR10	3072	60,000	10.00	0.630	0.635
Letter	16	20,000	3.92	0.990	0.975
Covtype	54	581,012	1.63	0.691	0.725
CIFAR100	3072	60,000	1.00	0.350	0.392
KDDCup08	117	102,294	0.61	0.543	0.556
5	Experiments
We evaluate Algorithm 1 on the following datasets: Letter1, Adult2, Covertype3 4, KDDCup084, CI-
FAR10 and CIFAR100 (Krizhevsky (2009)). The performance metric to optimize is the binary F1
score. The purpose of this experiment is to demonstrate that Algorithm 1 can match the performance
of a provably optimal, yet considerably more expensive algorithm that optimizes the F1 score. We
use a three-layer fully-connected network in our experiments, with batch normalization enabled.
The statistics of these datasets are summarized in Table 1 (number of features, number of sam-
ples, percentage of positive samples). For multi-class datasets (Letter, Covertype, CIFAR10 and
CIFAR100), we designate one class as the positive class and leave the rest as the negative class. We
compare Algorithm 1 with the following baseline (Parambath et al. (2014) and Koyejo et al. (2014)):
θ* — arg max-1- X l(pθ(x),y) (λI(y = 0) + (1- λ)I(y =1))
θ,λ∈(0,1) |D| (x,y)∈D
where l denotes the cross-entropy loss. We let λ = 0.1, 0.2, 0.3, ..., 0.9, and apply gradient descent
to optimize θ for a fixed λ. As proved in Parambath et al. (2014) and Koyejo et al. (2014), this
baseline method should yield an approximately optimal F1 score (although at a cost considerably
higher than Algorithm 1 because we have to optimize θ for every λ). In our case, the baseline
method is 8 times slower than Algorithm 1. To our knowledge, the baseline method is the state-of-
the-art method in term of resultant F1 score (not in term of efficiency). We apply weight decay to
both methods and find that in general weight decay improves the performance of Algorithm 1 while
hurts the performance of baseline method. For the Covertype dataset, Algorithm 1 cannot converge
without weight decay, which is an evidence that weight decay may improve gradient estimation. We
report results in Table 1, where “F1 GS” refers to the F1 score attained by the grid-search method
and “F1 EUM” refers to the F1 score attained by Algorithm 1.
6	Conclusion
We propose an empirical utility maximization scheme that enables efficient gradient-based learning
for a class of non-decomposable and non-differentiable classification performance metrics. We in-
quire into the proposed scheme mathematically and present preliminary experiments that validate
our approach. We leave it as future work to experiment on deeper neural networks, larger datasets,
and more complex performance metrics.
1https://archive.ics.uci.edu/ml/datasets/letter+recognition
2https://archive.ics.uci.edu/ml/datasets/adult
3https://archive.ics.uci.edu/ml/datasets/covertype
4http://www.kdd.org/kdd-cup/view/kdd-cup-2008/
8
Under review as a conference paper at ICLR 2019
References
Jie Chen and Ronny Luss. Stochastic gradient descent with biased but consistent gradient estimators.
CoRR, abs/1807.11880, 2018. URL http://arxiv.org/abs/1807.11880.
Seung-Seok Choi, Sung-Hyuk Cha, and Charles C Tappert. A survey of binary similarity and dis-
tance measures. 2010.
Krzysztof Dembczynski, WCjciech KotloWski, Oluwasanmi Koyejo, and Nagarajan Natarajan. Con-
sistency analysis for binary classification revisited. In International Conference on Machine
Learning,pp. 961-969, 2017.
Luc Devroye. Classification and trees. In Structural, Syntactic, and Statistical Pattern Recognition,
Joint IAPR International Workshop, SSPR&SPR 2010, Cesme, Izmir, Turkey, August 18-20, 2010.
Proceedings, pp. 40-44, 2010. doi: 10.1007∕978-3-642-14980-1∖.3. URL https://doi.
org/10.1007/978-3-642-14980-1_3.
Elad ET Eban, Mariano Schain, Alan Mackey, Ariel Gordon, Rif A Saurous, and Gal Elidan. Scal-
able learning of non-decomposable objectives. arXiv preprint arXiv:1608.04802, 2016.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing
human-level performance on imagenet classification. In Proceedings of the IEEE international
conference on computer vision, pp. 1026-1034, 2015.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
Martin Jansche. Maximum expected f-measure training of logistic regression models. In Pro-
ceedings of the conference on Human Language Technology and Empirical Methods in Natural
Language Processing, pp. 692-699. Association for Computational Linguistics, 2005.
Thorsten Joachims. A support vector method for multivariate performance measures. In Proceedings
of the 22nd international conference on Machine learning, pp. 377-384. ACM, 2005.
Purushottam Kar, Harikrishna Narasimhan, and Prateek Jain. Online and stochastic gradient meth-
ods for non-decomposable loss functions. In Advances in Neural Information Processing Systems,
pp. 694-702, 2014.
Oluwasanmi O Koyejo, Nagarajan Natarajan, Pradeep K Ravikumar, and Inderjit S Dhillon. Con-
sistent binary classification with generalized performance metrics. In Advances in Neural Infor-
mation Processing Systems, pp. 2744-2752, 2014.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, Citeseer,
2009.
Ye Nan, Kian Ming Chai, Wee Sun Lee, and Hai Leong Chieu. Optimizing f-measure: A tale of two
approaches. arXiv preprint arXiv:1206.4625, 2012.
Harikrishna Narasimhan, Purushottam Kar, and Prateek Jain. Optimizing non-decomposable per-
formance measures: a tale of two classes. In International Conference on Machine Learning, pp.
199-208, 2015.
Shameem Puthiya Parambath, Nicolas Usunier, and Yves Grandvalet. Optimizing f-measures by
cost-sensitive classification. In Advances in Neural Information Processing Systems, pp. 2123-
2131, 2014.
Joan Pastor-Pellicer, Francisco Zamora-Martlnez, Salvador Espana-Boquera, and Maria Jose Castro-
Bleda. F-measure as the error function to train neural networks. In International Work-Conference
on Artificial Neural Networks, pp. 376-384. Springer, 2013.
Amartya Sanyal, Pawan Kumar, Purushottam Kar, Sanjay Chawla, and Fabrizio Sebastiani. Op-
timizing non-decomposable measures with deep networks. arXiv preprint arXiv:1802.00086,
2018.
9
Under review as a conference paper at ICLR 2019
Cornelis Joost Van Rijsbergen. Foundation of evaluation. Journal of Documentation, 30(4):365-
373, 1974.
Vladimir Vapnik. Principles of risk minimization for learning theory. In Advances in neural infor-
mation processing systems, pp. 831-838, 1992.
10
Under review as a conference paper at ICLR 2019
Proofs
Theorem 1.	If F is a well-behaved performance metric and CD is a strongly consistent estimator
of C, i.e.
P lim (CD)ij = Cij	=1	0≤i,j≤ |Y|-1
∖JDl→∞ j	J
then F (CD) is a strongly consistent estimator of F (C), i.e.
P lim F (CD) = F (C)	= 1
∖ lDl→∞	/
Proof. Let N = |Y | × |Y |. Instead of treating CD and C as |Y | × |Y | matrices, we treat them as
N -dimensional vectors (C1D, ..., CND) and (C1, ..., CN). For i = 1, ..., N, let Ei be the event that
lim CiD = Ci
∣D∣→∞
Let E be the event that
lim F (CD) = F (C)
∣D∣→∞
By the continuity of F ,
∀i = 1, ..., N, lim CiD = Ci ⇒ lim F (CD) = F (C)
∖	∣d∣→∞ i )	∖d→∞	J
which implies that
N
\ Ei ⊂ E
i=1
Taking complement on both sides, we have
/ N	∖ c N
Ec ⊂	\ Ei	= [ Eic
i=1	i=1
By the monotonicity of probability measure and the union bound,
(N	∖ N	N	N
[Eic	≤XP(Eic)=X1-P(Ei)=X1-1=0
i=1	i=1	i=1	i=1
Consequently,
P lim F (CD) = F (C) = P(E) = 1 -P(Ec) = 1 - 0 = 1
∖ lDl→∞
π
Theorem 2.	If F is a well behaved performance metric, then Vθ F (CB (hθ)) is a strongly consistent
estimator of VθF(C(hθ)), where B ⊂ D is a mini-batch. More precisely,
PuimoO VθF (CB(hθ)) = VθF (C(hθ))) =1
>Λ	/■ T . TK r	I ∙Λ ɔ I	I ∙Λ ɔ I A ♦	. 1	Γ∙ Γ∙ EI	Λ	.	1 Γ∙ .	. ∙	/r /7	∖	1 K / 7	∖
Proof. Let N = |Y| × |Y|. As in the proof of Theorem 1, instead of treating CB(hθ) and C(hθ)
as |Y| X |Y| matrices, We treat them as N-dimensional vectors CB = (CB,..., CCB) and C =
11
Under review as a conference paper at ICLR 2019
(Ci,…，Cn), where we omit the dependence on hθ for brevity. For i = 1,..., N, let Ei be the event
that
lim VQB = Vθ Oi
∣B∣→∞ i
and E denote the event that
浸mɔɔ VθF (OB) = VθF (O)
Because Vθ F(OB) is an unbiased estimator of Vθ F(G), i.e. E[Vθ F(OB)] = Vθ F (Ci),
P (Ei)
1
by the law of large number. Consequently, suppose
N
∩ Ei U E
i=1
which is equivalent to the proposition that
∀i =	1,..., N, lim VθOB	= VθCi )	⇒ ( lim VθF	(Ob)	= VθF
∣ B ∣→∞	∣	∖∣B∣→∞	∖	)
then this theorem will follow from a union bound argument similar to that in the proof of theorem
1. We now prove this proposition. Let JB and J be the Jacobian of CB and O w.r.t. θ, i.e.
Jb
Vθ CB
...
VθON
Vθ Oi ■
...
Vθ CN
By the chain rule,
Vθ F (CB) = VF (CB) Jb
where VF(CB) is the gradient of F at CB. Because F is continuously differentiable, i.e. VF
exists and is continuous,
∀i =	1,...,N,	lim CB	= CJi]	⇒ [ lim VF	(CB)	= VF
∣B∣→∞ i	I ∖∣B∣→∞	∖	)
Thus for all δ > 0, there exists Nf,b such that when ∖B∖ > Nf,
∖e∖ ：= VF (CB) - VF (C)
where ∖∖J∖∖ is the matrix norm of J, defined as
∖∖j∖∖ = sup ∖Jx∖
∣x∣≤1
Thus
[∀i = 1,...,N, lim VθCB = Vθc] ⇒ [ lim JB = j]
∖	∣ D ∣ →∞ i	)	∖ ∣ B ∣ →∞	)
where the convergence is in the Frobenius norm. Because convergence in the Frobenius norm is
equivalent to convergence in matrix norm, for all δ > 0, there exists NJ such that when ∖D∖ > Nj,
∖∖E∖∖ ：=|I Jd(θ) - J(θ) I I < 焉
where
M := sup VF(x) < ∞
x∈K
δ
<而
12
Under review as a conference paper at ICLR 2019
because K is compact and VF is continuous on K by definition.
Thus for all B such that |B| > max {Nf, Nj},
VθF (C	B) - VθF (C) = VF (CB) Jb - VF (C) J =(VF (C) + e)(J+ E) -VF (C) J = VF (C) J + VF (C) E + eJ + eE - VF (C) J ∣ =VF (C) E + eJ + eE-VF (C) J ∣ ≤ VF (C) E + ∣ eJ∣ + |eE| ≈ VF (C) E + i eJ i ≤∣vf (C) ∣l IEI I + |e|| I j∖ I δ δ ≤ 2 + 2 =δ
where we ignore the high-order term |eE|. Consequently,
	|ɪɪimɔɔ Vθ F(CB) = Vθ F(C)
□
Theorem 3	(Generalization). For a well behaved performance metric F, for all e > 0,
	lim P ∣ F(CD(hθ)) - F(C(hθ))∣<e = 1 ∣D∣→∞ ∖l	I	)
Proof. By Theorem 1,
P( lim IFCD (hθ))- F(C(hθ ))∣<C =1
∖ ∣D∣→∞ I	I /
which implies that
lim P(IF(CD(hθ))- F(C(hθ)) ∣ < e) =1
∣D∣→∞ ∖l	I j
□
Theorem 4	(Consistency). For a well behaved performance metric F, with appropriate constraints
on the capacity of parametric model pθ (see the proof for details), we have thatfor all e > 0,
lim P I	arg max F(CD (hθ))	— arg max F (C(hθ))	< e I	= 1
∣ D∣→∞	∖	θ	∖	θ	θ	j
i	.e. Algorithm 2 is consistent.
Proof. To prove consistency, it suffices to prove that (Vapnik (1992)):
lim P sup F(CD(hθ)) — F (C(hθ))
∣D∣→∞	∖ θ '	/
< € = 1
Because F is well behaved, by the union bound argument in previous proofs, it suffices to show that
*m P 卜UP (CD (hθ)) - Cij (hθ) <€)= 1
1 ≤ i,j ≤3
13
Under review as a conference paper at ICLR 2019
Because CD (hθ))ij = j PjIPθ(i∣xk), it suffices to show that
lim P
∣D∣→∞
(
sup
θ
∖
nj
nj XPθ(i∣χ1k) — Gij (hθ)
j k=1
<E∣ =1 I ≤ i,j ≤∣Y∣
which holds for pθ with finite VC-dimension by Lemma 29.1 in Devroye (2010) because
nj
ED
n Xpθ(i∣xk)
j k = 1
Gj (hθ)
□
14
Under review as a conference paper at ICLR 2019
Well behaved performance metrics
The following is a non-exhaustive list of non-decomposable and non-differentiable, yet well-
behaved performance metrics in the setting of binary classification. They can be extended to the
setting of multi-class classification in the same way that the F -measure is extended to multi-class
classification in Section 3.
• AUC
fρ∙fn
(tp+fn)(fp+tn)
• Fβ = (1+β2)
_____p+ —fn___
(1+β2)p+-fn+fρ
•	G-Mean = ʌ/tp ∙ tn
•	JaCCard = tp+fp+fn
•	Q-Mean = 1 - q(I-tp)2+(In)2
We refer interested readers to Choi et al. (2010) for a more exahustive list of these performanCe
metriCs.
15