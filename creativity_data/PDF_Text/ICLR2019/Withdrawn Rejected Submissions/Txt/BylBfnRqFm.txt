Under review as a conference paper at ICLR 2019
CAML: Fast Context Adaptation via Meta-Learning
Anonymous authors
Paper under double-blind review
Abstract
We propose CAML, a meta-learning method for fast adaptation that partitions the model
parameters into two parts: context parameters that serve as additional input to the model and
are adapted on individual tasks, and shared parameters that are meta-trained and shared across
tasks. At test time, the context parameters are updated with one or several gradient steps on
a task-specific loss that is backpropagated through the shared part of the network. Compared
to approaches that adjust all parameters on a new task (e.g., MAML), our method can be
scaled up to larger networks without overfitting on a single task, is easier to implement, and
saves memory writes during training and network communication at test time for distributed
machine learning systems. We show empirically that this approach outperforms MAML, is
less sensitive to the task-specific learning rate, can capture meaningful task embeddings with
the context parameters, and outperforms alternative partitionings of the parameter vectors.
1 Introduction
A key challenge in meta-learning is fast adaptation: learning on previously unseen tasks fast and with little data.
In principle, this can be achieved by leveraging knowledge obtained in other, related tasks. However, the best
way to do so remains an open question.
A popular recent method for fast adaptation is model agnostic meta learning (MAML) (Finn et al., 2017a),
which learns a model initialisation, such that at test time the model can be adapted to solve the new task in
only a few gradient steps. MAML has an interleaved training procedure, comprised of inner loop and outer
loop updates that operate on a batch of tasks at each iteration. In the inner loop, MAML learns task-specific
parameters by performing one gradient step on a task-specific loss. Then, in the outer loop, the model parameters
from before the inner loop update are updated to reduce the expected loss across tasks after the inner loop update
on the individual tasks. Hence, MAML learns a model initialisation that, at test time, can generalise to a new
task after only a few gradient updates.
However, while MAML adapts the entire model to the new task, many transfer learning algorithms adapt only
a fraction of the model (Kokkinos, 2017), keeping the rest fixed across tasks. For example, representations
learned for images can be transferred to different image classification domains (Donahue et al., 2014) or reused
for object tracking in videos (Wojke et al., 2017). This suggests that some model parameters can be considered
task independent and others task specific. Adapting only some model parameters can make learning faster and
easier, as well as mitigate overfitting and catastrophic forgetting.
To this end, we propose context adaptation for meta-learning (CAML), a new method for fast adaptation via
meta-learning. Like MAML, CAML learns a model initialisation that can quickly be adapted to new tasks.
However, unlike MAML, it adapts only a subset of the model parameters to the new task. While restricting
adaptation in this way is straightforward, it raises a key question: how should we decide which parameters to
adapt and which to keep fixed? The main insight behind CAML is that, for many fast adaptation problems, the
inner loop reduces to a task identification problem, rather than learning how to solve the whole task, which is
typically infeasible with only a few gradient updates. Thus, it suffices if the part of the model that varies across
tasks is an additional input to the model, and is independent of its other inputs.
These additional inputs, which we call context parameters φ (see Figure 1), can be interpreted as a task em-
bedding that modulates the behaviour of the model. This embedding is learned via backpropagation during the
inner loop of a meta-learning procedure similar to MAML, while the rest of the model is updated only in the
outer loop. This allows CAML to explicitly optimise the task-independent parameters θ for good performance
across tasks, while ensuring that the task-specific context parameters φ can quickly adapt to new tasks.
1
Under review as a conference paper at ICLR 2019
This separation of task solver and task embedding has several advantages. First, the size of both components
can be chosen appropriately for the task. In particular, the network can be made expressive enough without
overfitting to a single task in the inner loop, which we show empirically MAML is prone to. Model design
and architecture choice also benefit from this separation, since for many practical problems we have prior
knowledge of which aspects vary across tasks and hence how much capacity the context parameter φ should
have. Like MAML, our method is model-agnostic, i.e., it can be applied to any model that is trained via gradient
descent. However, CAML is easier to implement: assigning the correct computational graphs for higher order
gradients is done only on the level of the context parameters, avoiding manual access and operations on the
network weights and biases. Furthermore, parameter copies are not necessary which saves memory writes, a
common bottleneck for running on GPUs. CAML can also help distributed machine learning systems, where
the same model is deployed to different machines and we wish to learn different contexts concurrently. Network
communication is often the bottleneck, which is mitigated by only sharing the (gradients of) context parameters.
We show empirically that CAML outperforms MAML on a regression and classification task and performs
similarly on a reinforcement learning problem, while adapting significantly fewer parameters at test time. We
observe that CAML is less sensitive to the inner-loop learning rate, and can be scaled up to larger networks
without overfitting. We also demonstrate that the context parameters represent meaningful embeddings of tasks,
confirming that the inner loop acts as a task identification step.
2Background:Meta-Learning for Fast Adaptation
We consider settings where the goal is to learn models that can quickly adapt to a new task with only little data.
To this end, learning on the new task is preceded by meta-learning on a set of related tasks. Here we describe
the meta-learning problem for supervised and reinforcement learning, as well as the method MAML.
2.1	Problem Setting
In few-shot learning problems, we are given distributions over training tasks ptrain(T) and test tasks ptest(T).
Training tasks can be used to learn how to adapt fast to any of the tasks with little per-task data, and evaluation
is done on previously unseen test tasks. Unless stated otherwise, we assume that ptrain = ptest and refer to both
as p. Tasks in p typically share some structure, so that transferring knowledge between tasks speeds learning.
During each meta-training iteration, a batch of N tasks T = {Ti }iN=1 is sampled from p.
Supervised Learning. In a supervised learning setting, we learn a model f that maps data points x ∈ X that
have a true label y ∈ Y to predictions y ∈ Y. A task Ti is defined as a tuple Ti = (X, Y, L, q), where X is
the input space, Y is the output space, L(y, y) is a task-specific loss function, and q(x, y) is a distribution over
labelled data points. We assume that all data points are drawn i.i.d. from q. Different tasks can be created by
changing any element of Ti .
Training in the supervised meta-learning setting proceeds over meta-training iterations, where for every task
Ti ∈ T from the current batch, we sample two datasets Dtrain (for training) and Dtest from qTi :
Ditrain = {(x, y)i,m}mM=itra1in,
Ditest = {(x, y)i,m}mM=ites1t,
(1)
where (x, y)〜qτ. Mfain and M^St are the number of training and test datapoints, respectively. The training
data is used to update f, and the test data is then used to evaluate how good this update was, and adjust f or the
update rule accordingly.
Reinforcement Learning. In a reinforcement learning (RL) setting, we aim to learn a policy π that maps
states s ∈Sto actions a ∈A. Each task corresponds to a Markov decision process (MDP): a tuple
Ti =(S, A, r, q, q0), where S is a set of states, A is a set of actions, r(st, at, st+1) is a reward function,
q(st+1|st,at) is a transition function, and q0(s0) is an initial state distribution. The goal is to maximise the
expected cumulative reward J under π,
H-1
J(π)=Eq0,q,π	γtr(st, at, st+1)
t=0
(2)
where H ∈ N ∪∞is the horizon and γ ∈ [0, 1] is the discount factor. Again, different tasks can be created by
changing any element of Ti .
2
Under review as a conference paper at ICLR 2019
During each meta-training iteration, for every task Ti ∈ T from the current batch, we first collect a trajectory
train
τi
{s0, a0, r0, s1, a1 ,r1,...,sMtrain-1 ,aMtrain-1,rMtrain-1
iii
,sMtrain } ,
i
(3)
where the initial state s0 is sampled from q0 , the actions are chosen by the current policy π, the state transitions
according to q, and Mitrain is the number of environment interactions available, We unify several episodes in
this formulation: if the horizon H is reached within the trajectory, the environment is reset using q0 . Once the
trajectory is collected, this data is used to update the policy. Another trajectory τ test is then collected by rolling
out the updated policy for M test time steps. This test trajectory is used to evaluate the quality of the update on
that task, and to adjust π or the update rule accordingly.
Evaluation for both supervised and reinforcement learning problems is done on a new (unseen) set of tasks
drawn from p (or ptest if the test distribution of task is different). For each such task, the model is updated using
L or J and only few datapoints (Dtrain or τtrain). Performance of the updated model is reported on Dtest or τtest.
2.2	Model-Agnostic Meta-Learning
One method for few-shot learning is model-agnostic meta-learning (Finn et al., 2017a, MAML). Here, we
describe the application of MAML to a supervised learning setting. MAML learns an initialisation for the pa-
rameters θ of a model fθ such that, given a new task, a good model for that task can be learned with only a small
number of gradient steps and data points. In the inner loop, MAML computes new task-specific parameters θi
(starting from θ) via one1 gradient update,
θi = θ - CNQ-vτr~ X	LTi (fθ(χ),y).	⑷
train (x,y)∈Ditrain
For the meta-update in the outer loop, the original model parameters are then updated with respect to the
performance after the inner-loop update, i.e.,
θ 一 θ - β▽。后 X k1 X	LTi(fθi(χ),y).	(5)
Ti∈T	test (x,y)∈Ditest
The result of training is a model initialisation θ that can be adapted with just a few gradient steps to any new
task that we draw from p. Since the gradient is taken with respect to the parameters θ before the inner-loop
update (4), the outer-loop update (5) involves higher order derivatives in θ.
3 Fast Context Adaptation via Meta-Learning
We propose to partition the model parameters into two parts: context parameters φ that are adapted in the
inner loop on an individual task, and parameters θ that are shared across tasks and meta-learned in the outer
loop. In the following we describe the training procedure for supervised and reinforcement learning problems.
Pseudo-code is provided in Appendix A.
3.1 Supervised Learning
At every meta-training iteration and for the current batch T of tasks, we use the training data Dtrain as follows.
Starting from φ0, which can either be fixed or meta-learned as well (we often choose φ0 =0; see Section 3.4),
we learn task-specific parameters φi via one gradient update:
φi = φo — α^φWrain	X	LT(fφo,θ(χ),y).	(6)
i	(x,y)∈Ditrain
While we only take the gradient with respect to φ, the updated parameter φi is also a function of θ, since during
backpropagation, the gradients flow through the model. Once we have collected the updated parameters φi for
all sampled tasks, we proceed to the meta-learning step, in which θ is updated:
θ 一 θ- β口耳 X ʌʃtest	X	LTi(fφi,θ(x),y).	⑺
Ti ∈T	i (x,y)∈Ditest
This update includes higher order gradients in θ due to the dependency on (6).
1We outline the method for one gradient update here, but several gradient steps can be performed at this point as well.
3
Under review as a conference paper at ICLR 2019
Figure 1: Context adaptation. A network layer hl is aug-
mented with additional context parameters φ (red), which are
initialised to 0 before each adaptation step. The context pa-
rameters are updated by gradient descent during each inner
loop and during test time. The network parameters θ (green)
are only updated in the outer loop and shared across tasks.
Hence, they stay fixed at test time. By initialising φ to 0, the
network parameters associated with the context parameters
(blue) do not affect the output of the layer before adaptation.
After the first adaptation step they are used to modulate the
rest of the network in order to solve the new task.
3.2	Reinforcement Learning
During each iteration, for a current batch of MDPs T = {Ti}N=1, we proceed as follows. Given φ0 (see Section
3.4), we collect a rollout τ train by executing the policy πφ0 ,θ. We then compute task-specific parameters φi via
one gradient update:
φi = Φo + αVφ JTi (Tirain, ∏φo,Θ),	(8)
where J(τ, π) is an objective function given by any gradient-based reinforcement learning method that uses
trajectories τ produced by a parameterised policy π to update that policy’s parameters, such as TRPO (Schulman
et al., 2015) or DQN (Mnih et al., 2015). After updating the policy, we collect another trajectory τtestto evaluate
the updated policy, where actions are chosen according to the updated policy πφi ,θ.
After doing this for all tasks in T, we continue with the meta-update step. Here, we update the parameters θ to
maximise the average performance across tasks (after individually updating φ for them),
θ - θ + βVθɪ X JTi(TieSt,∏φi,θ).	⑼
MDPi∈T
ThiS update includeS higher order gradientS in θ due to the dependency on (8).
3.3	Conditioning on Context Parameters
Since φ are independent of the network input, we need to decide where and how to condition the network on
them. For an output node h(l) at a fully connected layer l, thiS can for example be done by Simply concatenating
φ to the inputS to that layer:
hi(l) =g XJ θj(,li,h) h(jl-1) + XK θk(l,,iφ) φ0,k + b ,	(10)
j=1	k=1
where g iS a non-linear activation function, b iS a biaS parameter, θ(l,h) are the weightS aSSociated with layer
input h(l-1), and θ(l,φ) are the weightS aSSociated with the context parameter φ0,k. ThiS iS illuStrated in Figure
1. The context parameterS can be added at any layer. In our experimentS, we add φ at the firSt layer for fully
connected networkS.
Other conditioning methodS can be uSed with CAML aS well. E.g., for convolutional networkS, we uSe the
feature-wise linear modulation FiLM method (Perez et al., 2017) for image claSSification experimentS (Section
5.2). FiLM conditionS by doing an affine tranSformation on the feature mapS: given context parameterS φ and a
convolutional layer that outputS M feature mapS {hi}M=1, FiLM applieS a linear tranSformation to each feature
map FiLM(hi)=γihi+ β, where the parameterS γ,β ∈ RM are a function of the context parameterS. We uSe
a fully connected layer [γ,β]=PK=1 θ(l,φ) φ0,k + b with the identity function at the output. In our experimentS,
we found it helpS performance to add the context parameterS not at the firSt layer, but after a few convolutionS
(in our caSe, after the third out of four convolution operationS).
4
Under review as a conference paper at ICLR 2019
3.4	Context Parameter Initialisation
When learning a new task, the context parameters φ have to be initialised to some value, φ0 . We argue that,
instead of meta-learning this initialisation as well, a fixed φ0 is sufficient: in (10), if both θ(l,φ) and φ0 are
meta-learned, the learned initialisation of φ can be subsumed into the bias parameter b, and φ0 can be set to a
fixed value. The same holds for conditioning when using FiLM layers. A key benefit of CAML is therefore that
it is easy to implement, since the initialisation of the context parameters does not have to be meta-learned and
parameter copies are not required. We set φ0 =0in our implementation, which gives the additional opportunity
for visual inspection of the learned context parameters (see Sections 5.1 and 5.3).
3.5	Learning Rate
Since the context parameters φ are inputs to the model, the gradients at this point are not backpropagated further
through any other part of the model. Furthermore, because learning φ and θ is decoupled, the inner loop learning
rate can effectively be meta-learned by the rest of the model. This makes the method robust to the initial learning
rate that is chosen for the inner loop, as we show empirically in Sections 5.1 and 5.3.
4	Related Work
Meta-learning, or learning to learn, has been explored in various ways in the literature. One general approach is
to learn the algorithm or update function itself (a.o., Schmidhuber (1987), Bengio et al. (1992), Andrychowicz
et al. (2016), Ravi and Larochelle (2017)). Another approach is to meta-learn a model initialisation such that
the model can perform well on a new task after only few gradient steps, such as MAML (Finn et al., 2017a).
Other such methods are REPTILE (Nichol and Schulman, 2018) which does not require second order gradient
computation and Meta-SGD (Li et al., 2017), which learns the per-parameter inner loop learning rate. Recent
work (Grant et al., 2018; Finn et al., 2018) also considers Bayesian interpretations of MAML. The main differ-
ence to our work is that we consider to only adapt a small number of parameters in the inner learning loop / at
test time, and that these parameters come in the form of input context parameters.
In Finn et al. (2017b) the authors augment the model with additional biases to improve the performance of
MAML in a robotic manipulation setting. In contrast, we update only the context parameters in the inner loop,
and initialise them to 0 before adaptation to a new task. A similar approach to ours, but in the context of neural
language models, was done by Rei (2015). However, they do not consider the application of the method to the
variety of domains covered by this paper (something briefly explored in the appendix of Finn et al. (2017a)).
Lee and Choi (2018) propose a framework to learn which parameters of the network to update in MAML,
called MT-Nets. These learn a T-net and an M-Net. The M-net is a mask which decides which parameters to
update in the inner loop, and is sampled (from a learned probability distribution) for each new task. The T-net
is responsible for learning the task-specific update direction and step size. The idea of dynamic partitioning is
attractive however it results in a more complex meta learning algorithm. In this work we consider a simpler,
more interpretable alternative where the task-specific and shared parameters are disjoint sets.
Other meta-learning methods are also motivated by the fact that learning in a high-dimensional parameter space
can PoSe practical difficulties, and fast adaptation in lower dimensional space is easier (e.g., sæmundsson et al.
(2018); Zhou et al. (2018)). Rusu et al. (2018) propose to learn a low-dimensional latent generative represen-
tation of (some of) the model parameters and perform gradient-based adaptation on a new task in this space,
instead of the high-dimensional parameter space. Our method is similar but instead attempts to learn a latent
representation of the task by backpropagating through the inner loss.
Context features as a component of inductive transfer were first introduced by Silver et al. (2008), who use a
one-hot encoded task-specifying context as input to the network (which is not learned but predefined). They
show that this works better than learning a shared feature extractor and having separate heads for all tasks.
Learning a task embedding itself has been also explored, e.g., by Oreshkin et al. (2018), who use the task’s
training set to condition the network via FiLM (Perez et al., 2017) parameters. By contrast, we learn the context
parameters via backpropagation through the same network that is used to solve the task.
5
Under review as a conference paper at ICLR 2019
Method	0	Number of Additional Input Parameters 1	2	3	4	5	50
CAML MAML	- 0.33	0.84	0.21	0.20	0.19	0.19	ffɪ 0.29	0.24	0.24	0.23	0.23	0.23
Table 1: MSE results of CAML and MAML for the sine curve regression task. We vary the number of input
parameters, for k = 10 shots. Numbers are averages over 1, 000 random sets of tasks. The 95% confidence
intervals are ±0.02 everywhere except for CAML with 1 additional input, where it is ±0.06.
Nodes	1st Layer	Parallel Partitioning 1st and 2nd Layer	2nd Layer
1	3.01(±0.18f	2.43(±0.14)	2.7(±0.16) 二
5	0.29(±0.02)	0.34(±0.02)	2.71(±0.16)
20	0.24(±0.02)	0.47(±0.03)	2.68(±0.16)
Table 2: MSE results for alternative partitioning schemes on the since curve regression task. We do k = 10 shot
learning (averaged over 1, 000 random sets of tasks, with 95% confidence intervals in brackets). Labels indicate
which parameters are task-specific. The rest of the network is shared across tasks and updated in the outer loop.
Stacked Partitioning
1st Layer Last Layer
2.39(±0.14) 0.75(±0.θ6j
5	Experiments
In this section we empirically evaluate CAML. Our extensive experiments aim to demonstrate three qualities
of our method. First, adapting a small number of input parameters during the inner loop is sufficient to yield
performance equivalent to or better than MAML in a range of regression, classification and reinforcement
learning tasks. Like in MAML, it is possible to continue learning by performing several gradient update steps at
test time, even when training using only one gradient step. Second, CAML is robust to the task-specific learning
rate and scales well to more expressive networks without overfitting. Third, an embedding of the task emerges
in the context parameters solely via backpropagation through the original inner loss. The implementation and
scripts to reproduce the results are available at [blinded for review].
5.1	Regression
We start with the regression problem of fitting sine curves, using the same setup as Finn et al. (2017a) to allow a
direct comparison. A task is defined by the amplitude and phase of the sine curve, and is generated by uniformly
sampling the amplitude from [0.1, 0.5] and the phase from [0, π]. For training, ten labelled datapoints (uniformly
sampled from x ∈ [-5, 5]) are given for each task for the inner loop update. Per meta-update we iterate over a
batch of 25 tasks and perform gradient descent on a mean-squared error (MSE) loss. We use a neural network
with two hidden layers and 40 nodes each and ReLU non-linearities. During testing we present the model with
ten datapoints from 1000 newly sampled tasks and measure MSE over 100 test points.
CAML uses the same training procedure and architecture but adds context parameters. To allow a fair compar-
ison, we add the same number of additional inputs to MAML, an extension that was also done by Finn et al.
(2017b). These additional parameters are meta-learned together with the rest of the network, which can improve
performance due to a more expressive gradient. Our method differs from this formulation in that we update only
the context parameters in the inner loop, and reinitialise them to zero for each new task. In the outer loop, we
only update the shared parameters.
Table 1 shows that CAML outperforms the original MAML (with no additional inputs) significantly, and MAML
with the same network architecture by a small margin. This performance gain is possible even though at test
time, CAML adapts only 2-5 parameters, instead of around 1600. To test the hypothesis that it suffices to adapt
only input parameters per task, we also compare to alternative parameter partitions in Table 2. In parallel
partitioning, we choose a strict subset of the nodes of each layer for task-specific adaptation, and meta-learn
the rest. In stacked partitioning, we choose one or several layers for task-specific adaptation, and meta-learn
the other layers. The results confirm that partitioning on context parameters is key to success: the other variants
perform worse, often significantly so. A recent method was proposed by Lee and Choi (2018), where they also
partition the network to adapt only part of it on a specific task - the partitioning mask, however, is learned. They
6
Under review as a conference paper at ICLR 2019
Figure 2: Performance after several gradi-
ent steps (on the same batch) averaged over
1000 unseen tasks. The size of the context
parameter / additional input to MAML is 5.
cxl.lφφEREd IX9UO。
10^6	IO ^4	10^2	IO0
Inner Loop Learning Rate
Figure 4: CAML scales the model weights so that
the inner learning rate is compensated by the con-
text parameters gradients magnitude.
Figure 3: Visualisation of what the context parameters learn
given a new task. In this case we have 2 context parameters, and
shown is the value they take after 5 gradient update steps on a
new task. Each dot is one random task, with its colour indicating
the amplitude (left) or phase (right) of that task.
Figure 5: Measuring performance for different
learning rates shows that CAML is more robust
to this hyperparameter than MAML.
test their method on the regression task as well, but we outperform the numbers they report significantly (not
shown, since we believe this might be due to implementational details). In the next section we will see that on
few-shot classification, this approach achieves comparable performance to our method.
MAML is known to keep learning after several gradient update steps. We test this on our method as well, with
the results shown in Figure 2 for up to 10 gradient steps. CAML outperforms MAML even after taking several
gradient update steps, and is more stable, as indicated by the size of the confidence intervals and the monotonic
learning curve.
As described in Section 3.4, CAML has the freedom to scale the gradients at the context parameters since they
are inputs to the model and trained separately. Figure 4 plots the inner learning rate against the norm of the
gradient of the context parameters at test time. We can see that the weights are adjusted so that lower learning
rates bring about larger context parameter gradients and vice-versa. This results in the method being extremely
robust to learning rates as confirmed by Figure 5. We plot the performance while varying the learning rate from
10-7 to 102 . CAML is robust to changes in learning rate while MAML performs well only in a small range.
Work by Li et al. (2017) shows that MAML can be improved by learning a parameter-specific learning rate,
which, however, introduces a lot of additional parameters.
CAML’s performance on the regression task correlates with how many variables are needed to encode the tasks.
In these experiments, two parameters vary between tasks, which is exactly the context parameter dimensionality
at which CAML starts to perform well (the optimal encoding is three dimensional, as phase is periodic). This
suggests CAML may indeed learn task descriptions in the context parameters. Figure 3 illustrates this by
plotting the value of the learned inputs against the amplitude/phase of the task in the case of two context
parameters. The model learns a smooth embedding in which interpolation between tasks is possible.
7
Under review as a conference paper at ICLR 2019
Model		5-way accuracy	
	1-shot	5-shot
Matching NetS (VinyalS et al., 2016)	46.6%	60.0%
Meta LSTM (Ravi and Larochelle, 2017)	43.44 ± 0.77%	60.60 ± 0.71%
Prototypical Networks (Snell et al., 2017)	49.42 ± 0.78%	68.20 ± 0.66%
Meta-SGD (Li et al., 2017)	50.47 ± 1.87%	64.03 ± 0.94%
REPTILE (Nichol and Schulman, 2018)	49.97 ± 0.32%	65.99 ± 0.58%
PLATIPUS (Finn et al., 2018)	50.13 ± 1.86%	
MT-NET (Lee and Choi, 2018)	51.70 ± 1.84%	
VERSA (Gordon et al., 2018)	50.70 ± 0.86%	65.03 ± 0.66%
MAML (32) (Finn et al., 2017a)	48.07 ± 1.75%	63.15 ± 0.91%
MAML (64)	44.70 ± 1.69%	61.87 ± 0.93%
CAML (32)	47.24 ± 0.65%	59.05 ± 0.54%
CAML (64)	49.56 ± 0.68%	63.94 ± 0.55%
CAML (128)	49.84 ± 0.68%	64.63 ± 0.54%
CAML (256)	51.23 ± 0.70%	65.20 ± 0.54%
CAML (512)	51.82 ± 0.65%	65.85 ± 0.55%
CAML (256, first order)	49.84 ± 0.71%	64.26 ± 0.55%
CAML (512, first order)	49.92 ± 0.68%	63.59 ± 0.57%
Table 3: Few-shot classification results on the Mini-Imagenet test set (average accuracy with 95% confidence
intervals on a random set of 1000 tasks). We compare to existing methods on this benchmark that use deep
convolutional networks, and MAML with a larger network (results obtained with the author’s open sourced
code, with all hyperparameters unchanged except the number of filters).
5.2	Classification
To evaluate CAML on a more challenging problem, we test it on the competitive few-shot image classification
benchmark Mini-Imagenet (Ravi and Larochelle, 2017). In N -way K -shot classification. a task is a random
selection of N classes, for each of which the model gets to see K examples. From these it must learn to classify
unseen images from the N classes. The Mini-Imagenet dataset consists of 64 training classes, 12 validation
classes, and 24 test classes. During training, we generate a task by selecting N classes at random from the 64
classes and training the model on K examples of each, i.e., a batch of N × K images. The meta-update is done
on a set of unseen images of the same classes.
On this benchmark, MAML uses a network with four convolutional layers with 32 filters each and one fully
connected layer at the output (Finn et al., 2017a). We use the same network architecture, but with between 32
and 512 filters per layer. We use 100 context parameters and add a FiLM layer (see Section 3.3) that conditions
on these after the third convolutional layer. The parameters of the FiLM layer are meta-learned with the rest of
the network, i.e., they are part of θ. All our models were trained with two gradient steps in the inner loop and
evaluated with two gradient steps (note: MAML was trained with five inner-loop gradient steps and evaluated
with ten gradient steps). The inner learning rate was set to 1.0. Following Finn et al. (2017a), we ran each
experiment for 60K meta-iterations and selected the model with the highest validation accuracy for evaluation
on the test set.
Table 3 shows our results on Mini-Imagenet held-out test data for 5-way 1-shot and 5-shot classification. We
compare to a number of existing meta-learning approaches that use convolutional neural networks, including
MAML. Our largest model (512 filters) clearly outperforms MAML, and outperforms the other methods on
the 1-shot classification task. On 5-shot classification, the best results are obtained by prototypical networks
(Snell et al., 2017), a method that is specific to few-shot classification and works by computing distances to
prototype representations of each class. Our smallest model (32 filters) under-performs MAML (within the
confidence intervals). As we can see, CAML benefits from increasing model expressiveness: since we only
adapt the context parameters in the inner loop per task, CAML can substantially increase the network size,
without overfitting during the inner loop update. We tested scaling up MAML to a larger network size as
well (see Table 3), but found that this hurt accuracy. The table only compares CAML to approaches that use
conventional convolutional neural networks. Approaches that use much deeper, residual networks (e.g., Gidaris
and Komodakis (2018), (Bauer et al., 2017), (Oreshkin et al., 2018), (Qiao et al., 2017)) can achieve higher
accuracies. To the best of our knowledge, the LEO method by Rusu et al. (2018) is the current state of the art
8
Under review as a conference paper at ICLR 2019
(a) Performance per gradient update.
(b) Performance per learning rate.
(c) Learned task embedding.
Figure 6: 2D navigation task analysis. Figure 6a shows the performance of each method as more gradient
updates are performed. Figure 6b shows the performance of each method after 2 updates as the inner loop
learning rate is increased. As in the case of regression CAML is not afected by this parameter. Figure 6c
describes the goal position of different 2D navigation tasks and the corresponding context parameter activation
obtained by performing 2 gradient updates. We can see that the context parameters represent an interpretable
embedding of the task at hand. Context parameter 1 seems to encode the y position, while context parameter 2
encodes the x position.
with 60% and 75.7% accuracy on 1 and 5-shot respectively. Our method can be readily applied to deep residual
networks as well, and we leave this exploration for future work. Table 3 also shows the first order approximation
of our largest models, where the gradient with respect to θ is not backpropagated through the inner loop update
of the context parameters φ. As expected, this results in a lower accuracy (a drop of 1 - 2%) , but we are still
able to outperform MAML with a first-order version of our largest network.
Thus, CAML can achieve much higher accuracies than MAML by increasing the network size, without overfit-
ting. Our results are obtained by only adjusting 100 parameters at test time, instead of > 30, 000 like MAML.
5.3	Reinforcement Learning
To demonstrate the versatility of CAML, we also perform preliminary reinforcement learning experiments on a
2D Navigation task, also introduced by Finn et al. (2017a). In this domain, the agent moves in a 2D world using
continuous actions. At each timestep it is given a negative reward proportional to its distance from a pre-defined
goal position. Each task is defined by a new unknown goal position.
We follow the same procedure as Finn et al. (2017a). Goals are sampled from an interval of (x, y) = [-0.5, 0.5].
At each step we sample 20 tasks for both the inner and outer loops and testing is performed on 40 new unseen
tasks. We perform learning for 500 iterations and the best performing policy during training is then presented
with new test tasks and allowed two gradient updates. For each update, the total reward over 20 rollouts per task
is measured. We use a two-layer network with 100 units per layer and ReLU non-linearities to represent the
policy and a linear value function approximator. For CAML we use five context parameters at the input layer.
In terms of performance (Fgure 6a) we can see that the two methods are highly competitive. MAML performs
better after the first gradient update after it is surpassed by CAML. Figure 6b, which plots performance for
several learning rates, shows that CAML is again less sensitive to the inner loop learning rate. Only when using
a learning rate of 0.1 is MAML competitive in performance. Furthermore, CAML adapts 5 parameters whereas
MAML adapts around 10, 000 parameters.
As with regression, the optimal task embedding is low dimensional enough to plot. We therefore apply CAML
with two context parameters and plot how these correlate with the actual position of the goal for 200 test tasks.
Figure 6c shows that the context parameters obtained after two policy gradient updates represent a disentangled
embedding of the actual task. Specifically, context parameter 1 appears to encode the y position of the goal,
while context parameter 2 encodes the x position. Hence, CAML can learn compact potentially interpretable
task embeddings via backpropagation through the inner loss.
9
Under review as a conference paper at ICLR 2019
6	Conclusion and Future Work
In this paper we introduced CAML, a meta-learning approach for fast adaptation that introduces context param-
eters in addition to the model’s parameters. The context parameters are used to modulate the whole network
during the inner loop of meta-learning, while the rest of the network parameters are adapted in the outer loop
and shared across tasks. On regression, our method outperforms MAML and is superior to naive approaches to
partitioning network parameters. We also showed that CAML is highly competitive with state of the art meth-
ods on few shot classification using CNNs. In addition to this, we experimented extensively with some unique
properties that specifically arise from the way that our method is formulated, such as robustness to learning
rate and the emergence of task embeddings at the context parameters. Another interesting extension would
be to inspect the context parameter representations learned by CAML on the Mini-Imagenet benchmark using
advanced dimensionality reduction techniques.
In this paper we performed some preliminary RL experiments. We are interested in extending CAML to more
challenging problems and explore its role in allowing for smart exploration in order to identify the task at hand.
It would also be interesting to consider probabilistic extensions along the lines of PLATIPUS (Finn et al., 2018)
where the context parameters include uncertainty about the task.
Finally, the intriguing empirical properties of CAML detailed in this work will be the base of more theoretical
investigations in the future.
10
Under review as a conference paper at ICLR 2019
References
Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan
Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient descent. In AdvanceS
in Neural Information ProceSSing Systems, pages 3981-3989, 2016.
Matthias Bauer, Mateo Rojas-Carulla, Jakub Bartlomiej Swikatkowski, Bernhard Scholkopf, and Richard E
Turner. Discriminative k-shot learning using probabilistic models. arXiv Preprint arXiv:1706.00326, 2017.
Samy Bengio, Yoshua Bengio, Jocelyn Cloutier, and Jan Gecsei. On the optimization of a synaptic learning
rule. In PreprintS Conf. Optimality in ArtifiCial and BiologiCal Neural Networks, pages 6-8. Univ. of Texas,
1992.
Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, and Trevor Darrell. Decaf:
A deep convolutional activation feature for generic visual recognition. In International ConferenCe on machine
learning, pages 647-655, 2014.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep
networks. arXiv PrePrint arXiv:1703.03400, 2017a.
Chelsea Finn, Tianhe Yu, Tianhao Zhang, Pieter Abbeel, and Sergey Levine. One-shot visual imitation learning
via meta-learning. arXiv PrePrint arXiv:1709.04905, 2017b.
Chelsea Finn, Kelvin Xu, and Sergey Levine. Probabilistic model-agnostic meta-learning. arXiv PrePrint
arXiv:1806.02817, 2018.
Spyros Gidaris and Nikos Komodakis. Dynamic few-shot visual learning without forgetting. In ProCeedingS of
the IEEE ConferenCe on ComPuter ViSion and Pattern Recognition, pages 4367-4375, 2018.
Jonathan Gordon, John Bronskill, Matthias Bauer, Sebastian Nowozin, and Richard E Turner. Decision-
theoretic meta-learning: Versatile and efficient amortization of few-shot learning. arXiv PrePrint
arXiv:1805.09921, 2018.
Erin Grant, Chelsea Finn, Sergey Levine, Trevor Darrell, and Thomas Griffiths. Recasting gradient-based meta-
learning as hierarchical bayes. arXiv PrePrint arXiv:1801.08930, 2018.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deeP into rectifiers: SurPassing human-level
performance on imagenet classification. In Proceedings of the IEEE international conference on computer
vision, pages 1026-1034, 2015.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv PrePrint
arXiv:1412.6980, 2014.
Iasonas Kokkinos. Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level
vision using diverse datasets and limited memory. In CVPR, volume 2, page 8, 2017.
Yoonho Lee and Seungjin Choi. Gradient-based meta-learning with learned layerwise metric and subsPace. In
International ConferenCe on MaChine Learning, pages 2933-2942, 2018.
Zhenguo Li, Fengwei Zhou, Fei Chen, and Hang Li. Meta-sgd: Learning to learn quickly for few shot learning.
arXiv PrePrint arXiv:1707.09835, 2017.
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex
Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Human-level control through deeP
reinforcement learning. Nature, 518(7540):529, 2015.
Alex Nichol and John Schulman. Reptile: a scalable metalearning algorithm. arXiv PrePrint arXiv:1803.02999,
2018.
Boris N Oreshkin, Alexandre Lacoste, and Pau Rodriguez. Tadam: Task dePendent adaPtive metric for imProved
few-shot learning. arXiv PrePrint arXiv:1805.10123, 2018.
11
Under review as a conference paper at ICLR 2019
Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. Film: Visual reasoning
with a general conditioning layer. arXiv Preprint arXiv:1709.07871, 2017.
Siyuan Qiao, Chenxi Liu, Wei Shen, and Alan L Yuille. Few-shot image recognition by predicting parameters
from activations. CoRR, abs/1706.03466, 1,2017.
Sachin Ravi and Hugo Larochelle. Optimization as a model for few-shot learning. In International Conference
on Learning RepreSentationS (ICLR), 2017, 2017.
Marek Rei. Online representation learning in recurrent neural language models. arXiv preprint
arXiv:1508.03854, 2015.
Andrei A Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, and Raia
Hadsell. Meta-learning with latent embedding optimization. arXiv preprint arXiv:1807.05960, 2018.
Steindor Sæmundsson, Katja Hofmann, and MarC Peter Deisenroth. Meta reinforcement learning with latent
variable gaussian processes. arXiv preprint arXiv:1803.07551, 2018.
Jurgen Schmidhuber. Evolutionary PrinCipleS in Self-referential Learning:On Learning how to Learn: the
Meta-meta-meta...-hook. 1987.
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region policy opti-
mization. In International COnferenCe on MaChine Learning, pages 1889-1897, 2015.
Daniel L Silver, Ryan Poirier, and Duane Currie. Inductive transfer with context-sensitive neural networks.
MaChine Learning, 73(3):313, 2008.
Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. In AdVanCeS in
Neural InfOrmatiOn PrOCeSSing Systems, pages 4077-4087, 2017.
Oriol Vinyals, Charles Blundell, Tim Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning.
In AdVanCeS in NeUral InformatiOn PrOCeSSing Systems, pages 3630-3638, 2016.
Nicolai Wojke, Alex Bewley, and Dietrich Paulus. Simple online and realtime tracking with a deep association
metric. In Image PrOCeSSing (ICIP), 2017 IEEE International COnferenCe on, pages 3645-3649. IEEE, 2017.
Fengwei Zhou, Bin Wu, and Zhenguo Li. Deep meta-learning: Learning to learn in the concept space. arXiv
preprint arXiv:1802.03596, 2018.
12
Under review as a conference paper at ICLR 2019
Appendix
A Pseudo-Code
Algorithm 1 CAML for Supervised Learning
Require: Distribution over tasks p(T)
Require: Step sizes α and β
Require: Initial model fφ0 ,θ with θ initialised randomly and φ0 =0
1:	while not done do
2:	Sample batch of tasks T = {Ti}N=ι where Ti 〜P
3:	for all Ti ∈ T do
4:	Dtrain, DteSt 〜qτi
5:	φ0 =0
6：	φi = φo - αVφM1≡	P	LTi(fφo,θ(x),y)
i	(x,y)∈Dtirain
7:	end for
8： θ一θ-βVθN P MU	P	LT(fφi,θ(χ,y))
Ti ∈T i (x,y)∈Ditest
9:	end while
Algorithm 2 CAML for RL
Require: Distribution over tasks p(T)
Require: Step sizes α and β
Require: Initial policy πφ0,θ with θ initialised randomly and φ0 =0
1:	while not done do
2:	Sample batch of tasks T = {Ti}N=ι where Ti 〜P
3:	for all Ti ∈ T do
4:	Collect rollout τ train using πφ0,θ
5:	φi = φ0 + aJjTi (Tirain, πΦo,θ)
6:	Collect rollout τ test using πφi ,θ
7:	end for
_	_	r   ~ . ， ，
8:	θ - θ + BNθ N P JTi (Ti , πφi,θ)
Ti ∈T
9:	end while B
B	Experiments
B.1 Classification
For Mini-Imagenet, our model takes as input images of size 84 × 84 × 3 and has 5 outputs, one for each class.
The model has four modules that each consist of: a 2D convolution with a 3 ×3 kernel, padding 1 and 128 filters,
a batch normalisation layer, a max-pooling operation with kernel size 2, if applicable a FiLM transformation
(only at the third convolution, details below), and a ReLU activation function. The output size of these four
blocks is 5 × 5 × 128, which we flatten to a vector and feed into one fully connected layer.
The FiLM layer itself is a fully connected layer with inputs φ and a 256-dimensional output and the identity
function at the output. The output is divided into γ and β, each of dimension 128, which are used to transform
the filters that the convolutional operation outputs. The context vector is of size 100 (other sizes tested: 50, 200)
and is added after the third convolution (other versions tested: at the first, second or fourth convolution).
The network is initialised using He et al. (2015) initialisation for the weights of the convolutional and fully
connected weights (including the FiLM layer weights). The bias parameters are initialised to zero, except at the
FiLM layer.
13
Under review as a conference paper at ICLR 2019
We use the Adam optimiser for the meta-update step with an initial learning rate of 0.001. This learning rate is
annealed every 5, 000 steps by multiplying it by 0.9. The inner learning rate is set to 0.1 (other hyperparameters
tested: 1.0, 0.01).
For Mini-Imagenet, we use a meta batchsize of 4 and 2 tasks for 1-shot and 5-shot classification respectively.
For the batch norm statistics, We always use the current batch - also during testing. I.e., for 5-way I-Shot
classification the batch size at test time is 5, and we use this batch for normalisation.
C Practical Tips
C.1 Implementation
The context parameters φ can be added to any network, and do not require direct access to the rest of the
network weights like MAML. In PyTorch this can be done as follows. To add CAML parameters to a network,
it is necessary to first initialise them to zero when the model is initialised:
self.context_params = torch.zeros(size=[self.num_context_params],
requires_grad=True)
Add a way to reset the context parameters to zero (e.g., a method that just does the above). During the forward
pass, add the context parameters to the input by concatenating it (when using a fully connected network):
x = torch.cat((x, self.context_params.expand(x.shape[0], -1)), dim=1)
(This is for fully connected networks. We refer the reader to our implementation for how to use FiLM to
condition CNNs.) To correctly set the computation graph for the outer loop, it is necessary to assign the context
parameters manually with their gradient. In the inner loop, compute the gradient:
grad = torch.autograd.grad(task_loss, model.context_params,
create_graph=True)[0]
The option Create_graph will make sure that you can take the gradient of grad again. Then, update the context
parameters using one gradient descent step
model.context_params = model.context_params - lr_inner * grad
If you now do another forward pass and compute the gradient of the model parameters θ (for the outer loop),
these will include higher order gradients because grad above includes gradients of θ, and because we kept the
computation graph via the option grad. To see how to train CAML and aggregate the meta-gradient over several
tasks, see our implementation at [blinded for review].
C.2 Hyperparameter Selection
The choice of network architecture/size and context parameters can be guided by domain knowledge. E.g., for
the few-shot image classification problem, an appropriate model is a deep convolutional model. For the context
parameters, it is important to make sure they are not underparameterised. CAML can deal with larger than
necessary context parameters (see Table 1), however, at some point it would probably overfit to the current task
in the inner loop. We have not experienced this in practise though. Regarding learning rates, we suggest to start
with an inner loop learning rate of 1 and the Adam optimiser (Kingma and Ba, 2014) with the standard learning
rate of 0.001 for the outer loop
For CNNs, we found that adding the context parameters not at the input layer, but after several (in our case
after the third out of four) convolutions works best. We believe this is because the lower-level features that the
first convolutions extract are useful for any image classification task, and we only want our task embedding
to influence the activations at the deeper layers. In our experiments we used a FiLM network with no hidden
layers. We tried deeper versions, but this resulted in inferior performance.
We also tested to add context parameters at several layers instead of only one. However, in our experience this
resulted in similar (regression and RL) or worse (in the case of CNNs) performance.
14