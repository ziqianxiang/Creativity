Under review as a conference paper at ICLR 2019
A* SAMPLING WITH PROBABILITY MATCHING
Anonymous authors
Paper under double-blind review
Ab stract
Probabilistic methods often need to draw samples from a nontrivial distribution.
A* sampling is a nice algorithm by building upon a top-down construction of a
Gumbel process, where a large state space is divided into subsets and at each round
A* sampling selects a subset to process. However, the selection rule depends on a
bound function, which can be intractable. Moreover, we show that such a selection
criterion can be inefficient. This paper aims to improve A* sampling by addressing
these issues. To design a suitable selection rule, we apply Probability Matching,
a widely used method for decision making, to A* sampling. We provide insights
into the relationship between A* sampling and probability matching by analyzing
a nontrivial special case in which the state space is partitioned into two subsets.
We show that in this case probability matching is optimal within a constant gap.
Furthermore, as directly applying probability matching to A* sampling is time
consuming, we design an approximate version based on Monte-Carlo estimators.
We also present an efficient implementation by leveraging special properties of
Gumbel distributions and well-designed balanced trees. Empirical results show that
our method saves a significantly amount of computational resources on suboptimal
regions compared with A* sampling.
1	Introduction
Probabilistic methods provide an important family of tools in machine learning for modeling uncer-
tainty of complex systems, performing probabilistic inference, revealing hidden factors (Ghahramani,
2015), and making decisions Kocsis & SzePesvdri (2006). These methods usually involve a funda-
mental task of drawing samples from a nontrivial distribution.
There exists a lot of work approaching the sampling problems, including rejection sampling (Gilks
& Wild, 1992), MCMC (Propp & Wilson, 1996), etc. Recently, sampling algorithms based on the
Gumbel process have received increasing attentions (Malmberg, 2013; Hazan et al., 2013; Gane et al.,
2014; Hazan & Jaakkola, 2012; Papandreou & Yuille, 2011; Tarlow et al., 2012; Kappes et al., 2015;
Kim et al., 2016) since a Gumbel process can turn a sampling task to an optimization problem so that
we can use optimization tools to finish the original sampling task.
In this work, we focus on A* sampling (Maddison et al., 2014) which is one of the most famous
Gumbel process based sampling algorithm. The major advantage of A* sampling is that it can
be applied to large state spaces, e.g., a continuous sample space or a discrete space whose size is
exponentially large. The reason is that A* sampling divides the state space into disjoint subsets and
takes each subset as a whole, so that it can avoid initializing a large number of states, which is often
encountered by other Gumbel process based algorithms (Papandreou & Yuille, 2011). Furthermore,
A* sampling adaptively selects subsets to process and the performance of A* sampling is highly
dependent on the selection rule.
However, how to select subsets to process is very challenging. In each round, A* sampling processes
the subset with maximum D(S) which is an upper bound of the maximum Gumbel value within a
subset S (see Section 2 for more details of D(S)). But in general, it is difficult to compute D(S)
since it is an instance of non-convex optimization. Another challenge is that even if we are able to
compute D(S) efficiently, selecting a subset with the maximum D(S) may not be a good choice.
This is because our target is to process subsets with larger Gumbel values, but D(S) only provides an
upper bound. So it is possible that the Gumbel value of S is relatively small with high probability
while D(S) is very large. In this case, A* sampling will waste many computational resources on
1
Under review as a conference paper at ICLR 2019
suboptimal regions. We’ll discuss more on how this inaccuracy of D(S) deteriorates the performance
of A* sampling by analyzing a counter example in Section 3.
To address the above challenges, We improve the subset selecting procedure of A* sampling with
probability matching (PM) which has been proven efficient in many settings of making decisions,
including Bayesian bandits (Chapelle & Li, 2011), MDP (Osband & Van Roy, 2016), economic
decisions (Vulkan, 2000), etc.
Contributions: Intuitively, PM randomly selects an option according to its probability of being the
optimal, so that it won’t select a suboptimal option for too many rounds. To provide more insights
into the efficiency of applying PM to A* sampling, we first analyze a simple but nontrivial special
case in which the state space is partitioned into two subsets. As we’ll present in Section 4.1, in
this case, PM is optimal within a constant gap in terms of the stochastic regret (Guha & Munagala,
2014) which measures the number of selected rounds on suboptimal options. Furthermore, as directly
applying PM to A* sampling is time consuming, we design a novel approximate algorithm based
on Monte-Carlo estimators. The approximate algorithm is computationally efficient since it utilizes
special properties of Gumbel distributions and well-designed balanced trees. We empirically compare
our method with popular baselines of A* sampling and Metropolis-Hastings algorithm. Experiments
show that our algorithm works well.
2	Preliminaries
In this section, we present some preliminary knowledge of the Gumbel process and A* sampling.
Below, we first introduce basic definitions of probability distributions and Gumbel distributions.
Definition 1 (Probability distributions). In general, a distribution P on a state space Ω provided
its potential function, φp : 2ω → R, is a sigma-finite measure such that P (S)= % exp{φp (S)},
where ZP = exp(φp(Ω)) is normalizing COnStant
Definition 2 (Gumbel and Truncated Gumbel distributions (Malmberg, 2013)). Let c denote the
Euler constant. For convenience, define eψ(g) = exp(-g + ψ), Fψ(g) = exp(- exp(-g + ψ)) and
fψ(g) = eφ(g)Fψ(g). Then (1), G(ψ): a Gumbel distribution with location ψ has PDF and CDF
at state g: fψ+c(g), Fψ+c(g). (2), TG(ψ, b): a Truncated Gumbel distribution with location ψ and
truncated value b has PDF and CDFat state g < b: fψ+c(g)∕Fψ+c(b), Fψ+c(g)∕Fψ+c(b).
2.1	Gumbel process
Now we are ready to introduce the Gumbel process.
Definition 3 (Gumbel process (Malmberg, 2013)). Let P(S) be a sigma-finite measure on sample
space Ω, S ⊆ Ω is a measurable subset. Let φp (∙) denote the potential function of P such that
Φp(S) = logP(S) + logZp. Then GP = {Gp(S)|S ⊆ Ω} is a Gumbelprocess inducedfrom P, if:
•	(marginal distributions) GP(S)〜 G(φp(S)).
•	(independence of disjoint sets) GP (S) ⊥ GP(Sc).
•	(consistency constraints) for measurable S1,S2	⊆ Ω, then GP (Si ∪ S2) =
max(GP(S1),GP(S2)).
The Gumbel process is useful in sampling since arg maxχ∈n GP(x)〜 P (Malmberg, 2013). There-
fore, we can draw a sample from P by constructing a Gumbel process for distribution P, and then
finding the maximum one with some optimization techniques.
In the sequel, we will use P to denote the target distribution, and we call GP(S) the Gumbel value of
subset S. According to (Malmberg, 2013), Defn. 3 is associated with a natural bottom-up construction:
for any X ∈ Ω, we first perturb it with an independent Gumbel noise, i.e., g(χ)〜G(0). After that
we simply set GP(x) = g(x) + Φp(dx) and compute GP(S) = maxχ∈s GP(x) for all S ⊆ Ω
according to the consistency constraints. However, when Ω is infinite, such a bottom-up construction
is infeasible.
Top-down construction: (Maddison et al., 2014) presents a top-down construction, which partitions
the state space into regions and resolves the problem caused by infinite spaces by considering each
region as a whole. Formally, the top-down procedure constructs a top-down tree, tree(P), with each
2
Under review as a conference paper at ICLR 2019
node corresponding to a subset of Ω. tree(P) is rooted in Ω. Let Par(S) denote the parent of subset
S. For each S ∈ tree(P), its children is a disjoint partition of S, that is, Us,：Par(SO)=SS0 = S.
The top-down construction computes Gumbel values for subsets in the order from the top to the
bottom of tree(P). Formally, according to the consistency constraints and marginal distributions,
We compute GP(S)〜 TG(φp(S), L(S)) where L(S) := GP(par(S)). In the algorithmic view
of point, the top-down construction maintains a collection of subsets of Ω. Initially, the collection
contains only Ω. At each round, the algorithm selects an element S from the collection and computes
GP(S). After that it divides S into subsets S1, S2 and adds them into the collection.
2.2	A* SAMPLING
Obviously, if φP(S) is hard to compute, the top-down construction for P is computationally in-
tractable. (Maddison et al., 2014) solves this problem by utilizing the linearity of Gumbel distri-
bution. More specifically, given a distribution Q, if GQ(x) induces a Gumbel process of Q, then
GP (x) := GQ(x) + φP (x) - φQ(x) induces a Gumbel process of distribution P. Based on this
insight, (Maddison et al., 2014) proposes the A* sampling, which relies on a tractable proposal
distribution Q. Furthermore, since GQ(S) ⊥ arg maxx∈S GQ(x) (Maddison et al., 2014), A*
sampling executes the top-down construction for Q, and for each subset, A* sampling computes
Gp(S) = Gq(S) + φp(xq(S)) - Φq(xq(S)) where XQ(S)〜Q(∙∣S).1 Suppose at some time
point that A* sampling has processed n nodes in tree(Q), denoted by DoneQ (n). It can be shown
that there are n + 1 nodes in the to be processed collection, denoted by CollectQ(n). As introduced
above, for each A ∈ DoneQ(n), we have a pair (XQ(A), GP(A)), and each S ∈ ColleCt@(n) is
associated with a truncated Gumbel distribution TG(φQ (S), L(S)).
The subset selection and termination in A* sampling rely on a bound function B : 2ω → R
such that B(S) ≥ supx∈S φP (X) - φQ (X). Let D(S) := L(S) + B(S). If for some n,
maxS∈Done(n) GP (S) ≥ maxS∈Collect(n) D(S), A* terminates and outputs the element with maxi-
mum value among the processed nodes. At round n, A* sampling selects the node S with maximum
value of D(S) from C olleCt(n).
3	Challenges of A* sampling
There are two challenges in A* sampling. The first one is about the function D on which A*
sampling relies. Computing this function for every S can be intractable since it can be a non-convex
optimization. If we simply remove the (possibly intractable) bound function or use a very loose
bound, A* sampling will degenerate to an algorithm which is not efficiency (Maddison et al., 2014).
We name the degenerated algorithm as A* sampling without a bound ( See Appendix D for details.).
The second challenge is that selecting the subset with maximum D(S) is not always a good choice.
This is because D(S) is just an upper bound of GP (S) and it is possible that GP(S) is relatively
small with high probability while D(S) is very large. We now present a simple counter example
for A* sampling to intuitively explain the reason. In this example, Ω = (-10.0, +10.0), the target
is a mixture distribution: P(x) H (1.0 — 10-5)N(x; —5.0,1.0) + 1[|x| ≤ 0.5 * 10-405]l0400 and
Q(x) H N(x; 5.0,1.0). The log likelihoods of P and Q are shown in Fig. 1(a). We first empirically
evaluate A* sampling on this example. Fig. 1(b) shows the selected rounds on the optimal subsets
and Fig. 1(c) shows the maximum Gumbel value found by A* sampling. Results are averaged over
100 runs. We can see that A* sampling has a poor performance on this example. In this case, D(S)
is large if S covers points near x = 0. So A* sampling will allocate lots of computational resources
into such intervals, however, GP (S) being high for such S is with probability only about 0.00001.
4	A* SAMPLING WITH PROBABILITY MATCHING
We now present how to use PM to improve A* sampling by addressing the above challenges. We
first present an intuitive example in Section 4.1. Then, we present a practical PM algorithm based on
Monte-Carlo estimators of GP (S) in Section 4.2 and an efficient implementation with well-designed
balanced trees in Section 4.3.
1In this paper, we use P(∙∣S) to denote the distribution P conditioned on state space S.
3
Under review as a conference paper at ICLR 2019
(a) Log-likelihood
(b) Selected rounds on intervals
containing the optimal point
(c) Maximum Gumbel value
Figure 1: The counter example with (a) the log likelihood of P and Q; (b) the selected number on the
intervals containing the optimal point; (C) the maximum GUmbel value found by A* sampling.
4.1	Probability matching and an example with two subsets
In general, when making a choice among a set
of options, PM selects an option randomly ac-
cording to its probability of being the optimal.
More specifically, in our problem, the optimal
option is the subset with the maximum Gumbel
value. Formally, by definition, the maximum
Gumbel value within region S is a random vari-
able GP (S) = maxx∈S TG(φQ(dx), L(S)) +
φP (x) - Φq(x). Suppose the state space Ω is
partitioned into {S1,…,SK}. PM selects a
subset according to the probability:
p i = argmaxGP(Sk) .	(1)
k∈[K]
Intuitively, PM has an excellent performance
since it allocates computational resources into
the options which are likely to have large out-
comes. To provide more intuition into why PM
suits A* sampling, we analyze a simple but non-
trivial case in which We divide Ω into two sets.
In order to get a clean theoretical result, we
additionally assume A* sampling does not fur-
ther split a subset after processing it. We fo-
cus on the stochastic regret (Guha & Muna-
gala, 2014) which is the expected number of
selections on the suboptimal subset. Formally,
suppose Ω is partitioned into S1, S2. Let i* =
Algorithm 1 Probability matching with Monte-
Carlo estimators._________________________
1:	Input: the target distribution P , proposal dis-
tribution Q, state space Ω, time horizon T.
2:	Output: x: a sample from P .
3:	maxgumbel = -∞, x = N one.
4:	Collect = {Ω},L(Ω) = ∞,∀S ⊆ Ω,t = 1.
5:	while t ≤ T do
6:	t = t + 1.
7:	Select S* according to Eq. (4).
8:	Split S* into disjoint sets S1, S2.
9:	L(S1) = L(S2) = GQ(S*).
10:	forS ∈ S1,S2 do
11:	X(S)〜Q(∙∣S).
12:	G(S)〜TG(Φq(S),L(S)).
13:	G(S) = G(S) + φp(x(S)) - Φq(x(S)).
14:	if maxgumbel < G(S) then
AL	7 7K / C∖	/ C∖
15:	maxgumbel = Gm(S), x = x(S).
16:	end if
17:	end for
18:	Compute Monte-Carlo estimators for S1, S2
and update balanced trees.
19:	C ollect.insert(S1), C ollect.insert(S2).
20:	end while
arg maxi∈{1,2} GP(Si) which is a random variable. Consider an algorithm A which selects a subset
SiA,t at time step t. The stochastic regret of A at time T is: RA (T) = E	tT=1 1[iA,t 6= i*
Intuitively, the smaller RA is, the better A is, since A won’t waste many computational resources on
the suboptimal subset. Moreover, we can prove that PM is optimal within a constant gap in terms of
the stochastic regret:
Lemma 1. Let opt(T) denote the algorithm which minimizes the stochastic regret. Then :
RPM (T) ≤ 2Ropt(T) (T), ∀T
where RPM(T) is the stochastic regret of PM.
The proof of Lemma 1 is adapted from the proof in (Guha & Munagala, 2014) for Bayesian bandits
with two arms, we defer the details in Appendix A.
4
Under review as a conference paper at ICLR 2019
4.2	Probability matching with a Monte-Carlo estimator
Unfortunately, drawing samples from the probability in Eq. (1) is intractable when GP (S) is complex.
So in this section, we present an efficient PM algorithm based on a Monte-Carlo estimator of GP (S).
Consider a random variable Y = φp(x) - Φq(x),x 〜 Q(∙∣S) whose expectation is a constant
plussing the KL-divergence between Q and P conditioned on the subset S. We can equally character-
ize GP (S) as
maxTG(log(Q(S) ∙ P(Y = y)),L(S)) + y.	(2)
y
We present the proof of Eq. (2) in Appendix B. Eq. (2) suggests that we can get a Monte-Carlo
estimator of GP (S) by estimating Y. More specifically, let Y1,…，Ym be a sequence of random
variables and wι,…，Wm be the corresponding weights such that Pm=I Wi = 1,wi > 0. Suppose
the random variable Ym : p(Ym = Yi ) = wi is an unbiased estimator of Y, then we can estimate
GP(S) by:
Gp(S) = max TG(log(wiQ(S)), L(S)) + Yi = max TG(log(wiQ(S)) + 匕，L(S) + YO (3)
i∈[m]	i∈[m]
The second equality holds due to the linearity of the truncated Gumbel distribution (Maddison et al.,
2014). According to Eq. (3), we can estimate GP (S) with existing Monte-Carlo estimators of Y,
such as adaptive importance sampling (Gilks & Wild, 1992).
The corresponding PM with Monte-Carlo estimators is to draw samples from
Λ	…、、	，八
p i = arg max GP(Sj) .	(4)
j∈[n]
What remains is how to sample from the probability in Eq. (4) efficiently. The most popular execution
of Eq. (4) is as in (Chapelle & Li, 2011): We draw yi 〜GP (Si), and take i = argmaXi y%, then it
can be shown that i is a sample from the probability in Eq. (4).
However, a direct implementation of the above ideas requires time complexity O(m) since we need
to draw samples from m truncated Gumbel distributions, where m = Pi∈[n] mi is the number of
particles in total and mi is the number of particles in Si . So our selection algorithm executing m
rounds would require running time O(m2). It is relatively slow comparing with the O(m log m) time
complexity for A* sampling (Maddison et al., 2014).
4.3	An efficient implementation by balanced trees
We now present a novel algorithm that only requires O(log m) running time to sample from the
distribution in Eq. (4). Our algorithm is based on the properties of the truncated Gumbel distribution
and under the help of well-designed balanced trees.
We first decompose sampling from the distribution in Eq. (4) into two steps which can be done
efficiently. The decomposition is an immediate inference of Eq. (4):
A	A z.Λ f , A，小、八	A，…	A …、，
p i = arg max GP(Sj)	=	p(x = max GP (S))p(i = arg max GP (S)|x = max GP(S))dx.
j∈[n]	x	j∈[n]	j∈[n]	j∈[n]
Thus, sampling from the distribution in Eq. (4) equals to the following two sampling problems:
X 〜max Xi, Xi 〜GP (Si),	i 〜p(i = arg max Xj 〜GP (Si)∣x = max Xj)
i∈[n]	j∈[n]
Recall that GP (S ) is the maximum one among a set of truncated Gumbels. Thus, the above two
sampling problems are essentially sampling the maxima and the argument of the maxima among a
set of truncated Gumbels. So our target can be converted into the following problem:
5
Under review as a conference paper at ICLR 2019
Problem 1. Given a set of truncated Gumbel variables {vi}m=ι with parameters (a” bi), i.e., Vi 〜
TG(ai, bi). We define two sampling problems:
v = maxi∈[m] vi	(5)
i ~ p(i = arg maxj∈ [m] vj |v = maxj∈[m] vj)	(6)
We use the inverse transform sampling (Devroye, 1986) to sample v in Eq. (5). In inverse transform
sampling, for a random variable X with CDF UX(x), We first draw a sample S 〜Uniform(0,1),
and then compute X such that UX (x) = s, it can be shown that X 〜X. Thus, let U(g) denote the
CDF of v, we only need an algorithm to compute g such that U(g) = s, s ∈ (0, 1). We now show
how to compute such g efficiently with balanced trees.
For notational clarity, let Ua,b(g) denote the CDF of a truncated Gumbel distribution, T G(a, b).
According to Defn. 2, we have Ua,b(g) = exp^；Xp(^m-b+,：)+a)). Recall V = maxi Vi, then V has
CDF: U(g) = QiUai,bi(g) = Qi exp(ex1eX-(exm-bg+a)+ai)). Take IOgarithm on both sides, We get
logU(g) = Pi∈[m] (- exp(- min(g, bi) +ai) + exp(-bi + ai)).
Without loss of generality, we sort bi’s in a non-decreasing order, that is, bi ≤ bi+1. Since U(g) is a
monotonically increasing function, for g ∈ (bi, bi+1], we have:
logU(g) = -	exp(-g+aj) +	exp(-bj +aj)	= -exp(-g)	exp(aj) +	exp(-bj	+aj)
j>i	j>i	j>i	j>i
Thus, given U(g) and suppose g ∈ (bi, bi+1], we can compute g by:
j>i exp(aj -bj) -logU(g)
g = - log -------------------------
j>iexp(aj)
(7)
Thus, when we get S 〜uniform® 1), we need to find i such that U (bi) ≤ S ≤ U (bi+ι), and then
solve g according to Eq. (7) and inverse sampling . Both of above two steps can be done efficiently
via a balanced tree.
Suppose we have a balanced tree such that each node in the tree corresponds to an index i ∈ [m],
and the key of the balanced tree is bi , that is, for all j in the right subtree of node i, we have
bj ≥ bi and for all j in the left subtree, we have bj ≤ bi . Suppose that from the balanced
tree, we can query in O(1) time at each node i for terms: (1) exp(-bi) Pj>i exp(aj); (2)
exp(ai) Pj>i exp(-bj) and (3) Pj>i exp(aj - bj). We can query these terms efficiently in a bal-
anced tree because they all are summations over an interval. And according to Defn. 2, we know that
log U(bi) = Pj>i (exp(-bj + ai) - exp(aj - bi)), we can check out whether log S < log U(bi) in
O(1). Therefore, we can find the index i such that U(bi) ≤ S ≤ U (bi+1) in running time O(log m).
After that, we can compute U(g) = S via Eq. (7) in running time O(1).
Now we turn to sample i in Eq. (6). Without loss of generality, suppose g ∈ (bi, bi+1). Obviously, for
j < i, p(j = arg maxj0 Vj0 |g = maxj0 Vj0) = 0. For j ≥ i, by Defn. 2 and with simple calculations,
we have:
p j = arg max Vj0 |g
dUaj,bj (g)
(X ɪ j0=Y0>i U…g)
exp(- exp(-g + aj))
= exp(-g + aj)exp(_ eχp(_b∙+ a.))	11	UajOMO (g) = exP(aj )exP(-g) ɪ ɪ UajO ,%，⑹ X exP(aj)
j j j0 6=j,j0>i	j0>i
(8)
According to Eq. (8), we can sample i in O (log m) running time with a balanced tree from which we
can query Pj>i exp(aj ) efficiently. Putting the previous results together, we get the algorithm as
outlined in Alg. 1.
5	Experiments
In this section, we present our empirical results. We first check the correctness on a simple toy
experiment and the counter example in Section 3. After that, we evaluate the efficiency of Alg. 1
on two Bayesian posterior inference tasks, results show that our algorithm outperforms vanilla A*
sampling significantly.
6
Under review as a conference paper at ICLR 2019
(a) The toy experiment
(b) The counter example
Figure 2: Experiment results with (a) the toy experiment; (b) the counter example.
Figure 3: Experiment results on the clutter problem with 5 dimensions on the left, 15 dimensions in
the middle and 20 dimensions on the right.
5.1	Correctness of Alg. 1
We first verify the correctness of Alg. 1 on a greenhouse experiment. We consider sampling from
a one-dimensional Gaussian mixture with potential function φP (x) = - log(N (x; -2.0, 1.0) +
2N (x; 2.0, 1.0)), which is a multi-mode target distribution. We set Q = N(0, 2). We present our
result in Fig. 2(a) which shows the ground truth and the empirical sample distributions of Alg. 1 and
baselines. From Fig. 2(a), Alg. 1 has a similar performance to A* sampling and outperforms the A*
sampling without a bound function.
5.2	The counter-example
We empirically compare the performance of algorithms on the example in Section 3. The result is
shown in Fig. 2(b). We can see that PM-A* outperforms baselines significantly since our algorithm
wastes less resources on suboptimal subsets.
5.3	Bayesian posterior inference
In this section, we evaluate our algorithm on two Bayesian posterior tasks: the clutter problem and the
Bayesian logistic regression. More specifically, we focus on sampling tasks of formulations P(x)区
P(x) ∏n=1 p(yi∣x) where X is the variable We are going to sample, p(∙) is the prior distribution over
x, and {yi}in=1 are observations, and p(yi|x) is the likelihood function. We simply set Q(x) := p(x)
in both A* sampling and Alg. 1. For vanilla A* sampling, we exploit the standard stochastic gradient
descent (SGD) algorithm to calculate the bound function, maxx∈S Pi logp(yi|x). For the Monte-
Carlo estimator in Alg. 1, we exploit the importance sampling over the trajectory of the same SGD
algorithm as in the vanilla A* sampling 2.
5.3.1	Evaluation on the Clutter problem
We now evaluate Alg. 1 on the Clutter problem proposed by (Minka, 2001). Clutter problem aims to
inference the mean of an isotropic Gaussian with some data points are outliers. Consider a mixture
2We first tune the parameters of SGD for vanilla A* sampling, and then apply them to Alg. 1 without further
tuning.
7
Under review as a conference paper at ICLR 2019
Figure 4: Experiments on logistic regression with (a) averaged Gumbel values; (b) averaged log-
likelihoods.
distribution:p(y|x) = (1 - w)N (y; x, I) + wN(y; 0, σ1I), p(x) = N(x; 0, σ2I), where w is the
ratio of outliers which is a known parameter, and N(μ, Σ) represents GauSSian distribution. Our goal
is to inference x given data {yi}in=1. We do experiments on dimensions varying in 5, 15, 20, n = 20.
We compare the Gumbel of these algorithms. We run 100 times and present the averaged results in
Fig. 3. We can see that Alg. 1 outperforms A* sampling constantly.
5.3.2	Evaluation on Bayesian Logistic Regression
Our last experiment is on Bayesian Logistic Regression. Given a dataset {xi }in=1 associated with
label {yi}in=1 where yi ∈ {0, 1}. We follow the setting in (Gershman et al., 2012) and define
the Bayesian logistic regression: p(α) = Gamma(α; a, b), p(wk) = N(wk; 0, α-1), p(yi =
1; xi , w) = sigmoid(wT xi). In this model, {w, α} are the hidden variables, where w denotes the
regression coefficients and α is a precision parameter. We set a = b = 1. We do experiments on 13
binary classification datasets proposed by (Mika et al., 1999). The number of features of these data
sets are in range from 2 to 60, and the number of points ranges from 24 to 7400 (See Appendix C for
more statistics). We present our results in Fig. 4(a) where all results are averaged over 100 runs. Fig.
4(a) presents the summation of the maximum likelihood found by each algorithm on these datasets
over time. From Fig. 4(a), we can see that PM-A* outperforms all baselines.
Furthermore, we compare our algorithm with standard Matropolis-Hastings algorithm (MH) and
adaptive inference with exploration (AIE) (Rainforth et al., 2018) which also attempts to bridge the
gap between sampling problems and decision-making techniques. For MH, the initial points are
sampled from the prior. To make the comparison fair, we also evaluate Alg. 1 and AIE with the prior
as the Monte-Carlo estimator instead of gradient-based methods. We compare the likelihoods in Fig.
4(b). We can see that Alg. 1 outperforms AIE even if they use the same Monte-Carlo estimator. This
is AIE attempts to use UCB-like algorithm to make decisions, but UCB works only for those models
in which concentration bounds hold which is not always valid in sampling problems.
6	Conclusion and future work
In this work, we focus on improving the subset selection procedure in A* sampling with PM. We
proved that in the special case of two subsets, PM is optimal within a constant gap in terms of the
stochastic regret. Moreover, we proposed a practical algorithm based on Monte-Carlo estimators and
well-designed balanced trees. Empirical results show that our methods saves a significantly amount
of computational resources on suboptimal regions compared with A* sampling.
There exists several challenges in future work. The first one is on the analysis of PM. Though we
proved PM is efficient in the case of two subsets, it is very challenging to prove the efficiency in
general. The second one is that the performance of Alg. 1 relies on the accuracy of the Monte-Carlo
estimator. However, it is time-consuming to compute an accurate Monte-Carlo estimator. So it is
important to balance the accuracy of the Monte-Carlo estimator and the performance of PM. We hope
our work is a starting point to address these problems.
8
Under review as a conference paper at ICLR 2019
Acknowledgments
References
Olivier Chapelle and Lihong Li. An empirical evaluation of thompson sampling. In Advances in
neural information processing Systems, pp. 2249-2257, 2011.
Luc Devroye. Sample-based non-uniform random variate generation. In Proceedings of the 18th
conference on Winter simulation, pp. 260-265. ACM, 1986.
Andreea Gane, Tamir Hazan, and Tommi Jaakkola. Learning with maximum a-posteriori perturbation
models. In Artificial Intelligence and Statistics, pp. 247-256, 2014.
Samuel Gershman, Matt Hoffman, and David Blei. Nonparametric variational inference. arXiv
preprint arXiv:1206.4665, 2012.
Zoubin Ghahramani. Probabilistic machine learning and artificial intelligence. Nature, 521(7553):
452, 2015.
Walter R Gilks and Pascal Wild. Adaptive rejection sampling for gibbs sampling. Applied Statistics,
pp. 337-348, 1992.
Sudipto Guha and Kamesh Munagala. Stochastic regret minimization via thompson sampling. In
COLT, pp. 317-338, 2014.
Tamir Hazan and Tommi Jaakkola. On the partition function and random maximum a-posteriori
perturbations. arXiv preprint arXiv:1206.6410, 2012.
Tamir Hazan, Subhransu Maji, and Tommi Jaakkola. On sampling from the gibbs distribution with
random maximum a-posteriori perturbations. In Advances in Neural Information Processing
Systems, pp. 1268-1276, 2013.
Jorg Hendrik Kappes, Paul Swoboda, Bogdan Savchynskyy, Tamir Hazan, and ChristoPh Schnorr.
Probabilistic correlation clustering and image partitioning using perturbed multicuts. In Inter-
national Conference on Scale Space and Variational Methods in Computer Vision, pp. 231-242.
Springer, 2015.
Carolyn Kim, Ashish Sabharwal, and Stefano Ermon. Exact sampling with integer linear programs
and random perturbations. In AAAI, pp. 3248-3254, 2016.
Levente Kocsis and Csaba Szepesvdri. Bandit based monte-carlo planning. In ECML, volume 6, pp.
282-293. Springer, 2006.
Chris J Maddison, Daniel Tarlow, and Tom Minka. A* sampling. In Advances in Neural Information
Processing Systems, pp. 3086-3094, 2014.
Hannes Malmberg. Random Choice over a Continuous Set of Options. PhD thesis, Department of
Mathematics, Stockholm University, 2013.
Sebastian Mika, Gunnar Ratsch, Jason Weston, Bernhard Scholkopf, and Klaus-Robert Mullers.
Fisher discriminant analysis with kernels. In Neural Networks for Signal Processing IX, 1999.
Proceedings of the 1999 IEEE Signal Processing Society Workshop., pp. 41-48. IEEE, 1999.
Thomas P Minka. Expectation propagation for approximate bayesian inference. In Proceedings of the
Seventeenth conference on Uncertainty in artificial intelligence, pp. 362-369. Morgan Kaufmann
Publishers Inc., 2001.
Ian Osband and Benjamin Van Roy. Why is posterior sampling better than optimism for reinforcement
learning. arXiv preprint arXiv:1607.00215, 2016.
George Papandreou and Alan L Yuille. Perturb-and-map random fields: Using discrete optimization
to learn and sample from energy models. In Computer Vision (ICCV), 2011 IEEE International
Conference on, pp. 193-200. IEEE, 2011.
9
Under review as a conference paper at ICLR 2019
James Gary Propp and David Bruce Wilson. Exact sampling with coupled markov chains and
applications to statistical mechanics. Random structures andAlgorithms, 9(1-2):223-252, 1996.
Tom Rainforth, Yuan Zhou, Xiaoyu Lu, Yee Whye Teh, Frank Wood, Hongseok Yang, and Jan-
Willem van de Meent. Inference trees: Adaptive inference with exploration. arXiv preprint
arXiv:1806.09550, 2018.
Daniel Tarlow, Ryan Adams, and Richard Zemel. Randomized optimum models for structured
prediction. In Artificial Intelligence and Statistics, pp. 1221-1229, 2012.
Nir Vulkan. An economist’s perspective on probability matching. Journal of economic surveys, 14
(1):101-118, 2000.
10
Under review as a conference paper at ICLR 2019
A Probability matching for two subsets
We present the proof of Lemma 1 in this section. This proof is adapted from the proof of Thompson
sampling for Bayesian bandits with two arms in (Guha & Munagala, 2014).
We first make the simplified A* sampling for two subsets clearer. Recall Ω is divided into two subsets
S1, S2. For notational convenience, let kt,i denote the number of selected rounds of Si up to time
step t. Since we do not split S1, S2, if we have processed Si for t rounds, we will have t observations
{ (xi,j, ui,j ) } j=1 such that xi, 1 〜Q(I Si ), ui, 1 〜G(φQ (Si)) and xi,j 〜Q(ISi\Xi,j -1), ui,j 〜
TG(φQ (Si\Xi,j-1 ), ui,j-1 ) for j > 1 where Xi,j = {xi,j0 }j0=1 . Let Vi,t = {(xi,j , ui,j )}j=, 1
denote the observations from subset Si until time t and Vt = {V1,t, V2,t} denote the collection of
observations from both subsets. Obviously, a subset selection algorithm A selects a subset according
to previous observations, that is, we can represent the subset selected by A at time t, iA,t+1, as
iA,t+1 := iA(Vt). Now we present A* sampling for two subsets with A as the subset selection
algorithm in Alg. 2.
Algorithm 2 A* sampling for two subsets.
1:	Input: the target distribution P, proposal distribution Q, state space Ω = Si ∪ S2, a subset
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
selection algorithm A, time horizon T .
Output: x: a sample from P .
maxgumbel = -∞, x = N one.
u1,0 = u2,0 = ∞, t = 0.
while t ≤ T do
t =t+ 1.
i = iA(Vt-1).
X0 〜Q(∙∣Si∖Xi,kt-ι,i).
Ui,t 〜TG(ΦQ(Si∖Xi,kt-1,i), ui,t-1).
u0 = ui,t + φP (x(S)) - φQ(x(S)).
if maxgumbel < u0 then
maxgumbel = u0, x = x0.
end if
end while
Recall opt(T) denote the the algorithm which minimizes the stochastic regret up to time horizon T.
We now explicitly define the optimal stochastic regret Ropt(T) (T) with time horizon T via dynamic
programming. Let qi(V ) denote the probability of Si being the optimal subset given observations V .
For convenience, let RA(T |V ) be the stochastic regret of algorithm A given observations V . Then:
Definition 4. We can define Ropt(T) (T |V ) as follows:
Ropt(1)(1|V) = min (1 -qi(V)).
i∈{1,2}
∀T > 1, Ropt(T) (T |V) = min 1-qi(V)+	Ropt(T-1)(T - 1|V ∪ (x, u))p(x, u|
i∈{1,2}	xi,ui
where (xi, ui) is the new observation from subset Si.
We now present the formal definition and some properties of qi(V ) which are useful in the sequel:
Corollary 1. Let V = {V1 := {(x1,j, u1,j)}jk=1 1, V2 := {(x2,j, u2,j)}jk=2 1} denote a set of obser-
vations. Let Si,\V = Si∖ ∪ {xi,j}jk=i 1. Then let i0 = {1, 2}∖i and m(x) = φP (x) - φQ(x), we
have:
qi(V) = p max TG(φQ(dx), ui,ki) + m(x) > max TG(φQ(dx), ui0,ki0) + m(x)
∖χ∈si,∖V	x∈Si0,∖V	J
Suppose we process Si for the ki + 1 time, and then receive observation (x0i, u0i), we have:
qi(V) ≥ Ex0i,u0i [qi(V ∪(x0i,u0i))]	(9)
11
Under review as a conference paper at ICLR 2019
Proof. Let E denote the event of the (ki + 1)-th observation from subset i is with the maximum
Gumbel value within Si, that is, u0i + m(x0i) ≥ maxS 0 TG(φQ(dx), u0i) + m(x). Then we
i,\(V ∪xi)
have qi(V∪ (χi, ui)∣E) = qi(V|£); otherwise, qi will decrease, that is, qi(V∪ (χi, ui)∣E) ≤ qi(V|E).
Overall, we have
Exi,ui [qi(V U(Xi,Ui))] = P(E)qi(V U(Xi, Ui)IE) + P(E)qi(V U(Xi, Ui)E ≤ qi(V)
□
For convenience, let RA(T |V) = Pi p(iA,1 = i)RA(i, T |V) where RA(i, T |V) denote the stochas-
tic regret of A if we select subset i at the first round. The proof of Lemma 1 relies on the following
lemma:
Lemma 2. Let P denote the target distribution and Q denote the proposal. Ifan algorithm A satisfies
that for any observations V and time horizon T :
RA(T |V) ≤ RA(i,T IV)+ c(1 - qi(V))	(10)
where c is a constant. Then we have RA(T|V) ≤ (c + 1)Ropt(T) (T|V) for all T and V.
Proof. For T = 1, it is obvious that Eq. (10) holds. We use mathematical induction to prove the case
of T > 1. According to definition and with straight-forward calculations, we have:
RA(TIV) ≤ RA(i,TIV)+c(1-qi(V)),	∀i
= (c + 1)(1 -qi(V))+E(x,u)RA(i,T-1IVU(X,U)),	∀i
≤ (c + 1)(1 - qi(V) + E(x,u) Ropt(T -1) (i, T - 1IV U (X, U))),	∀i
≤	(c+1)min(1-qi(V)+E(x,u)Ropt(T-1)(i,T-1IVU(X,U)))
=	(c+ 1)Ropt(T)(i,TIV)
□
According to Lemma 2, we can prove Lemma 1 by proving that probability matching satisfies
precondition (10) for c = 1. The following Lemma provides an equivalent characterization of Eq.
(10) in the context of probability matching.
Lemma 3. For probability matching, we have:
RPM (T) ≤ RPM (i, T) + 1 - qi,∀i ∈ {1, 2} ^⇒ ∣Rpm (1,T)- RPM (2,T )∣ ≤ 1	(11)
Proof. Suppose RPM (T) ≤ RPM(1, T) + 1 - q1. By definition, we have RPM(T) =
q1RPM(1,T) + q2RPM(2,T). Observing q1 + q2 = 1, we have RPM(2,T) - RPM(1,T) ≤ 1.
Conversely, if RPM(1,T) ≤ RPM(2,T) + 1,we have RPM(T) = qιRpM(1,T)+q2RpM(2,T) ≤
RPM (2, T) + 1 一 q2. Swapping the roles of 1 and 2, we complete the proof.	□
Now, we can complete the proof of Lemma 1.
Proof. For T = 1, it is obvious that Lemma 3 is true. We use mathematical induction to prove
Lemma 3 holds for T > 1. For convenience, let uι 〜 TG(Φq(Si), L(Si)), xi 〜 Q(∙∣S1),u2 〜
TG(φQ(S2),L(S2)),χ2 〜Q(∙∣S2).Wehave
RPM(1,TIV) = 1-q1(V)+Ex1,u1[RPM(T-1IVU(X1,U1))]
≤ 1 - q1(V) + Ex1,u1 [1 - q2(V U (X1, U1)) + RPM(2, T - 1IV U (X1, U1))]
= 1 - q1(V) + Ex1,u1[2q1(V U (X1, U1)) + Ex2,u2 RPM (T - 2IV U {(X1, U1), (X2, U2)})]
≤ 1 + q1(V) + Ex1,u1 [Ex2,u2 RPM (T - 2IV U {(X1, U1), (X2, U2)})]
The first equation is according to the inductive hypothesis, the next equality follows q1 (V) +q2(V) =
1 and the last inequality is due to Corollary 1. Similarly, we have:
RPM(2, TIV) = 1 - q2(V) + Ex2,u2 [RPM(T - 1IV U (X2, U2))]
= q1 (V) + Ex2,u2[q1(V U (X2, U2))RPM(1, T - 1IV U (X2,U2))
+ q2(V U (X2,U2))RPM(2,T - 1IV U (X2,U2))]
≥ q1 (V) + Ex2,u2[RPM(1,T - 1IV U (X2,U2)) - q2(V U (X2,U2))]
= q1 (V) + Ex2,u2[Ex1,u1RPM(T - 2I(X1, U1), (X2,U2))]
12
Under review as a conference paper at ICLR 2019
The first inequality follows the inductive hypothesis in Lemma 3 and q1(V ) + q2(V ) = 1. Above
inequalities show that RPM (1, T) - RPM (2, T) ≤ 1. Reversing the roles of S1 and S2, we can
show that probability matching satisfies the condition in Lemma 3 which completes the proof. □
B THE EQUIVALENT CHARACTERIZATION OF GP (S)
We now prove the equivalent characterization of GP (S) in Section 4.2. According to definitions, we
have:
GP (S) = maxTG(φQ(dx), L(S)) + φP (dx) - φQ(x)
x∈S
= max max	TG(φQ(dx), L(S)) + y
y φP (x)-φQ (x)=y
= max (y + T G(log(Q(S)p(Y = y)), L(S)))
y
the first equation is by definition and the third equation follows the fact that
maxx∈STG(φQ(dx),L) = T G(log(Rx∈S exp(φQ(x))dx), L).
C Statistics of datasets proposed by (Mika et al., 1999)
We present statistics of datasets proposed by (Mika et al., 1999) in Table 1 where n denotes the
number of data points and dim denotes dimension.
dim n	Banana 2 5300	B.Cancer 9 263	Diabetes 8 768	German 20 1000	Heart 5 215	Image 18 2086	Ringnorm 20 7400
dim n	F.Sonar 9 144	Splice 60 2991	Thyroid 5 215	Titanic 3 24	Twonorm 20 7400	Waveform 21 5000	
Table 1: Some statistics of datasets proposed by (Mika et al., 1999).
D A* SAMPLING WITHOUT THE BOUND FUNCTION
As presented in Section 3, when the bound B(S) is not available or very loose, the vanilla A*
sampling degenerates to Alg .3 which is not very efficient since it selects subsets simply according to
L(S).
13
Under review as a conference paper at ICLR 2019
Algorithm 3 A* sampling without a bound.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
Input: the target distribution P, proposal distribution Q, state space Ω, time horizon T.
Output: x: a sample from P .
maxgumbel = -∞, x = N one.
Collect = {Ω}, L(Ω) = ∞, ∀S ⊆ Ω,t =1.
while t ≤ T do
t =t+1.
Select S * ∈ Collect with maximum L(Ω).
Split S* into disjoint sets S1, S2.
L(S1) = L(S2) = GQ(S*).
forS ∈ S1,S2 do
X(S)〜Q(∙∣S).
G(S) ^TG(Φq(S),L(S)).
~ , , .... ....
G(S) = G(S) + φp(X(S))- Φq(x(S)).
if maXgumbel < G(S) then
7	7 片/ rι∖	/ rι∖
maXgumbel = Gm(S), X = X(S).
end if
end for
Collect.insert(S1), Collect.insert(S2).
end while
14