Under review as a conference paper at ICLR 2019
Fast adversarial training for semi-supervised
LEARNING
Anonymous authors
Paper under double-blind review
Ab stract
In semi-supervised learning, Bad GAN approach is one of the most attractive
method due to the intuitional simplicity and powerful performances. Bad GAN
learns a classifier with bad samples distributed on complement of the support of the
input data. But Bad GAN needs additional architectures, a generator and a density
estimation model, which involves huge computation and memory consumption cost.
VAT is another good semi-supervised learning algorithm, which utilizes unlabeled
data to improve the invariance of the classifier with respect to perturbation of
inputs. In this study, we propose a new method by combining the ideas of Bad
GAN and VAT. The proposed method generates bad samples of high-quality by use
of the adversarial training used in VAT. We give theoretical explanations why the
adversarial training is good at both generating bad samples and semi-supervised
learning. An advantage of the proposed method is to achieve the competitive
performances with much fewer computations. We demonstrate advantages our
method by various experiments with well known benchmark image datasets.
1	Introduction
Deep learning has accomplished unprecedented success due to the development of deep architectures,
learning techniques and hardwares (Krizhevsky et al., 2012; Ioffe & Szegedy, 2015; Szegedy et al.,
2015; Hinton et al., 2012; Kingma & Ba, 2014). However, deep learning has also suffered from
collecting large amount of labeled data which requires both cost and time. Thus it becomes important
to develop semi-supervised methodologies that learn a classifier (or discriminator) by using small
labeled data and large unlabeled data.
Various semi-supervised learning methods have been proposed for deep learning. Weston et al.
(2012) employs a manifold embedding technique using the pre-constructed graph of unlabeled data
and Rasmus et al. (2015) uses a specially designed auto-encoder to extract essential features for
classification. Variational auto encoder (Kingma & Welling, 2013) is also used in the context of
semi-supervised learning by maximizing the variational lower bound of both labeled and unlabeled
data (Kingma et al., 2014; Maal0e et al., 2016).
Recently, semi-supervised learning based on generative adversarial networks (GAN, Goodfellow
et al. (2014a)) has received much attention. For K-class classification problems, Salimans et al.
(2016) solves the (K + 1)-class classification problem where the additional (K + 1)th class consists
of synthetic images made by a generator of the GAN learned by unlabeled data. Dai et al. (2017)
notices that not a good generator but a bad generator which generates synthetic images much different
from observed images is crucial for the success of semi-supervised learning. Dai et al. (2017) gives
theoretical justifications of using a bad generator and develops a semi-supervised learning algorithm
called Bad GAN which achieves the state-of-the-art performances over multiple benchmark datasets.
1
Under review as a conference paper at ICLR 2019
However, Bad GAN has several limitations. It needs two additional deep architectures - bad generator
and pre-trained density estimation model besides the one for the classifier. Learning these multiple
deep architectures requires huge computation and memory consumption. In particular, the Pixel-
CNN++ (Salimans et al., 2017) is used for the pre-trained density estimation model which needs very
large computational resources.
Another difficulty in Bad GAN is that it requires a two-step learning procedure - the first step is to
learn the PixelCNN++ model and the second step is to learn the classifier and the bad generator. The
optimal learning of the first step may not be optimal for the second step and hence the regularization
of the both steps would need special techniques.
In this study, we propose anew semi-supervised learning method which competes well with other state-
of-the-art semi-supervised learning algorithms and yet needs much smaller amount of computational
resources. In particular, the proposed method employs only one deep architecture and hence the
corresponding learning phase is much easier and faster.
Our proposed method is motivated by close investigation of VAT (Virtual Adversarial Training)
method (Miyato et al., 2015; 2017). VAT tries to find a deep classifier which has a good prediction
accuracy on training data and at the same time is less sensitive to data perturbation toward the
adversarial direction. Here, the adversarial direction for a given datum is the direction to which
the probabilities of each class change most. In Section 3, we prove that the perturbed data toward
their adversarial directions can serve as ‘good’ bad samples. By using the adversarial directions
for both measuring the invariance and generating the bad samples, the proposed method combines
the advantages of Bad GAN and VAT together. Note that only a deep architecture for classification
is needed to calculate the adversarial directions and thus the corresponding learning procedure is
cheaper, easier and faster. We call our proposed method FAT (Fast Adversarial Training).
Dai et al. (2017) proves that bad samples play a role to pull the decision boundary toward the low
density regions of data. In Section 5, we give a theoretical explanation that VAT pushes the decision
boundary away from the high density regions of data. That is, FAT accelerates the learning procedure
by using both pushing and pulling operations simultaneously. In section 6, we show that FAT achieves
almost the state-of-the-art performances with much fewer training epochs. Especially, for the MNIST
dataset, FAT achieves similar test accuracies to those of Bad GAN and VAT with 5 times and 7 times
fewer training epochs, respectively.
This paper is organized as follows. In Section 2, we review the Bad GAN and VAT methods briefly.
In Section 3, the technique to generate bad samples using the adversarial directions is described, and
our proposed semi-supervised learning method is presented in Section 4. Theoretical analysis of
VAT is given in Section 5. Results of various experiments are presented in Section 6 and conclusions
follow in Section 7.
2	Bad GAN AND VAT
2.1	Bad GAN APPROACH
Bad GAN is a method that trains a good discriminator with a bad generator. This procedure trains a
generator as well as a discriminator simultaneously. Let DG (φ) be generated bad samples with a bad
generator pg(∙; φ) parametrized by φ. Here, the 'bad generator' is a deep architecture to generate
samples different from observed data. Let ppt(∙) be a pre-trained density estimation model. For a
given discriminator with a feature vector v(x; θ) of a given input x parameterized by θ, Bad GAN
learns the bad generator by minimizing the following:
Ex~Dg(0) [logPPt(X)I(Ppt(X) > T)] + ||Ex〜Utrv(x;b)- Ex〜Dg(Φ) V(X； ||
2
Under review as a conference paper at ICLR 2019
with respect to φ, where τ > 0 is a tuning parameter, Utr is the unlabeled data, and θ is the current
estimate of θ and k ∙ k is the Euclidean norm.
In turn, to train the discriminator, we consider the K-class classification problem as the (K + 1)-class
classification problem where the (K + 1)-th class is an artificial label of the bad samples generated
by the bad generator. We estimate the parameter θ in the discriminator by minimizing the following:
-Eχ,y〜Ltr [logp(y∣x, y ≤ K; θ)] - Ex〜Utr
log XK p(k|x; θ)
-Ex〜Dg(Φ) [logP(K +1∣x; θ)] - Ex〜Utr
K
p(k|x; θ) log p(k|x; θ)
k=1
(1)
for given φ, where Ltr is the labeled set. The second and the third terms in (1) are the cross-entropies
between the unlabeled and the bad samples. The fourth term is similar the entropy of the unlabeled
data which is usually helpful for semi-supervised learning (Grandvalet & Bengio, 2005). See Dai
et al. (2017) for details of the objective function (1).
2.2	VAT APPROACH
VAT is a regularization method which is inspired by the adversarial training (Goodfellow et al.,
2014b). The regularization term of VAT is given as:
Lvat(θ; b,x, e) = DKL (p(∙∣x; b)∣∣p(∙∣x + radvr(x,e); θ))
K
X
p(k|x; θ) log p(k|x + radvr(x, ); θ) + C,
k=1
where
radvr(x,e) = argmaxDKL (p(∙∣x; b)∣∣p(∙∣x + r; b)) ,	(2)
r;||r|g '	)
> 0 is a tuning parameter, θ is the parameter in the discriminator to train, θ is the current estimate
of θ and C is a constant. Combining with the cross-entropy term of the labeled data, we get the final
objective function of VAT:
-Ex,y〜Ltr [logp(y∣x; θ)] + Ex〜Utr [LVATW b, x, e)] .	(3)
3	Generation of bad samples by adversarial training
The key role of bad samples in Bad GAN is to enforce the decision boundary to be pulled toward the
low density regions of the unlabeled data. To do this, bad samples must be located at the valleys of
the distribution of the unlabeled data. In this section, we propose a novel technique to generate ‘good’
bad samples by use of only a given classifier.
3.1	Motivation
In this subsection, we explain why the adversarial direction is toward the decision boundary. For
simplicity, we only consider the linear decision boundary. For the decision boundary made by the
DNN model with ReLU activation function, see Appendix A.2.
Let us consider the 2-class linear logistic regression model parametrized by η = {w, b}, that is,
p(y = 1|x; η) = 1 + exp(-b - w0x)	. Note that the decision boundary is {x : b + w0x = 0},
and for any given x, the distance between x and the decision boundary is |b + w0 x|/||w||. The key
3
Under review as a conference paper at ICLR 2019
Figure 1: Demonstration of how the bad samples generated by the adversarial training are distributed.
We consider two cases: 3-class classification problem (Left) and 4-class classification problem
(Right). True data and bad data are coloured by blue and orange, respectively.
result is that moving x toward the adversarial direction radvr(x, ) is equivalent to moving x toward
the decision boundary which is stated rigorously in the following proposition. The proof is in the
appendix.
Proposition 1 For a sufficiently small > 0, we have
sign(w0X + b) ∙ sign (w'r。/丫丫(x, e)) = -1.	(4)
Proposition 1 implies that |b + w0 x|/||w|| > |b + w0 (x +r advr(x, )|/||w|| unless |b + w0x| = 0.
Hence, we can treat x + δradvr(x, e)/||radvr(x, e)|| for appropriately choosing δ > 0 as a bad sample
(a sample closer to the decision boundary).
3.2	Bad sample Generation with general classifier
Motivated by Proposition 1, we propose a bad sample generator as follows. Let δ > 0 be fixed and θ
be the current estimate of θ. For a given input X and a classifier p(∙∣x; θ), We calculate the adversarial
directionradvr(x, e) for given e by (2). Then, we consider xbad = x + δradvr(x, e)/kradvr(x.e)k as a
bad sample (a sample closer to the decision boundary). We generate bad samples for all unlabeled
data. In practice, we apply the same δ to all unlabeled data and choose δ based on the validation data
accuracy.
In Figure 1, we illustrate how the bad samples generated by the proposed adversarial training are
distributed for multi-class problem. With a good classifier, we can clearly see that most bad samples
are located well in the low density regions of the data.
It may happen that a generated bad sample is not sufficiently close to the decision boundary to be
a ’good’ bad sample, in particular when δ is too large or too small. To avoid such a situation, we
exclude Xbad which satisfies the following condition:
max p(k|Xbad; θ) > 1 - τ
k
for a prespecified τ > 0. In our experiments, we set the optimal τ with validation data.
4	Fast adversarial training with bad samples
Once we generate bad samples by the adversarial training, FAT updates θ by minimizing the following
objective function:
-Eχ,y〜Ltr [logp(y∣x; θ)]+ Ex〜Utr [Ltrue(θ; x)] + Ex〜。.。壮心/)[Lfake(θ, x)]
+Ex〜Utr [lvat(Θ; b,x,e)i	(5)
4
Under review as a conference paper at ICLR 2019
bd
where Dbad (θ, , δ) is the set of generated bad samples with θ, and δ,
K
Ltrue(θ; x) = - X
k=1
Lfake(θ; x) = -log
exp(gk(x; θ))	io	exp(gk(x； θ))
1 + PK=I exP(gk0 (x； θ)) 1 1 + PK=I exP(gk0 (x； θ))
1
1 + PK=1 exp(gk(x; θ))，
g(x； θ) ∈ RK is a pre-softmax vector of a given deep architecture and λ > 0. We treat and δ as
tuning parameters to be selected based on the validation data accuracy. We minimize the objective
function with one of the standard optimization algorithms such as Adam (Kingma & Ba, 2014) or
RMSProp (Tieleman & Hinton, 2012).
The objective function (5) differs from the objective function (1) of Bad GAN in a way that the second
term of (1), the cross-entropy of not being a bad sample, is deleted and the regularization term of VAT
is added. We delete the second term of (1) because it can be easily shown that a perfect classifier of
unlabeled data can be obtained from the minimizer of the objective function (1) without the second
term under the conditions in Dai et al. (2017). The regularization term of VAT is added to improve
the bad sample generator based on adversarial training. See Section 5.1 for detailed discussions.
Miyato et al. (2017) proposes the fast approximation method to calculate the adversarial di-
rection radvr(x, ) by using the second-order Taylor expansion. Let us define H(x, θ) =
WDkl (p(∙∣χ;b)∣∣p(∙∣χ +r； θb) |r=0 . They claim that radvr emerges as the first dominant eigenvec-
tor u(x, θ) of H(x, θ) with magnitude . But there always exist two dominant eigenvectors, ±u(x, θ),
and the sign should be selected carefully. So, we slightly modify the approximation method of Miyato
et al. (2017) by
radvr(x,e) =	argmax	DKL (p(∙∣x; b)∣∣p(∙∣x + r； b)) ∙
r∈{u(x,θb),-u(x,θb)}
This modification helps to improve convergence speed of the test accuracy, which will be demonstrated
in the ablation experiments.
5	ROLE OF VAT FOR SEMI-SUPERVISED LEARNING
In this section, we investigate the roles of the regularization term of VAT in our method in detail.
First, we verify that VAT regularization term does help to generate ’better’ bad samples with a simple
experiment. Furthermore, we give a theoretical insight for the role of the regularization term of VAT
in semi-supervised learning. We will show that the regularization term of VAT pushes the decision
boundary from the high density regions of unlabeled data. As a result, FAT uses pushing operations
by VAT term as well as pulling operations by bad samples simultaneously, which makes it possible to
accelerate the training process with improved performances.
5.1	IMPROVEMENT OF BAD SAMPLES WITH VAT
For generated samples by adversarial training to be ‘good’ bad samples, the adversarial directions
should be toward the decision boundary. While this always happens for the linear model by Proposi-
tion 1, adversarial directions could be opposite to the decision boundary for deep model. To avoid
such undesirable cases as much as possible, it would be helpful to smoothen the classifier with a
regularization term. In this section, we explain that the regularization term of VAT plays such a role.
The adversarial direction obtained by maximizing the KL divergence is sensitive to local fluctuations
of the class probabilities which is examplified in Figure 2. The regularization term of VAT is helpful
5
Under review as a conference paper at ICLR 2019
Figure 2: Examples of P(y = 1|x) of smooth (Left) and wiggle (Right) cases. We plot 3 points and
their adversarial directions on each case.
Figure 3: (Upper) 10 randomly sampled original MNIST dataset. (Middle and Lower) Bad samples
obtained by the classifier learned with and without the regularization term of VAT.
to find a right adversarial direction which is toward the decision boundary by eliminating unnecessary
local fluctuations of the class probabilities. In Figure 3, we compare bad samples generated by the
adversarial training with and without the regularization term of VAT for the MNIST dataset. While
the bad samples generated without the regularization term of VAT are visually similar to the given
input vectors, the bad samples generated with the regularization term of VAT look like mixtures of
two different digits and thus serve as ‘better’ bad samples.
5.2	THEORETICAL ANALYSIS OF VAT
Suppose that X is partitioned by (K + 1) mutually disjoint subsets Xk for k = 1, . . . , K + 1 such
that y(x) = k for all X ∈ Xk, k ≤ K andp*(x) = 0 for X ∈ Xk+i, where y(x) is the ground-truth
label of X and p* (x) is the true density of x. For a given feature map U : X → Rm and weight vectors
wι,..., Wk, let p(y = k|x) H exp(wkU(X)) for k = 1,..., K and p(y = K + 1|x) H 1. Let Ltr
satisfy Xk ∩ Ltr = 0 for k = 1, ...K. Suppose that (i) argmaxhp(y = h|x) = y for X ∈ Ltr, (ii)
argmaxhp(y = h|X) ≤ K for X ∈ ∪kK=1Xk and (iii) argmaxhp(y = h|X) = K + 1 for X ∈ XK+1.
Under these three conditions, Dai et al. (2017) proves that argmaxhp(y = h|X) = y(X) for all
X ∈ ∪kK=1Xk. That is, generating large ‘good’ bad samples is helpful for classifying unlabeled data
correctly only with a small amount of labeled data.
A similar result can be obtained for VAT objective function itself under mild additional conditions.
For given two subsets A1 and A2 of X, we define d(A1, A2) = minx1∈A1,x2∈A2 d(X1, X2) for a
given metric d. We define a tuple (X, X0) is -connected if d(X, X0) < . A finite subset A of X is
called -connected iff for all X, X0 ∈ A, there exists a finite path (X, X1, ..., Xq, X0) such that Xj ∈ A
forj = 1, . . . , q and(X, X1), (X1, X2), ..., (Xq-1, Xq), (Xq, X0) are all -connected.
Proposition 2 Assume that there exists > 0 such that 1) Uktr = Utr ∩ Xk, k = 1, . . . , K are
-connected, 2) d(Xk, Xk0 ) ≥ 2 for all k 6= k0 ≤ K, and 3) for each k ≤ K, there exists at least one
(X, k) ∈ Ltr such that d({X}, Uktr) < . Suppose that there exists a classifier f : X → {1, ..., K}
such that f(X) = y for all (X, y) ∈ Ltr and
f(X) = f(X0) for all X0 ∈ B(X, )	(6)
6
Under review as a conference paper at ICLR 2019
for all x ∈ Utr, where B(x, ) = {x0 : d(x, x0) ≤ }. Then, the function f classifies the unlabeled
set perfectly, that is:
f (x) = y(x) for all x ∈ Utr.
Condition 1) and 2) mean that the unlabeled data are dense enough and the supports of each class
are separated sufficiently, respectively. Condition 3) assumes that at least one labeled instance exists
near the supports of each class. The main condition of Proposition 2 is (6) which essentially assumes
that the classifier f does not change much locally. That is, f is invariant with respect to all small
perturbations of an input x. Note that the regularization term of VAT is devised to improve the
invariancy of the classifier and Proposition 2 explains why improving the invariancy is helpful for
semi-supervised learning.
5.3	INTERPRETATION OF VAT
Let f(x; θ) = argmaxhp(y = h|x; θ). Proposition 2 implies that it would be good to pursue a
classifier which predicts the labeled data correctly and at the same time is invariant with respect to
all local perturbations on the unlabeled data. For this purpose, a plausible candidate of the objective
function is
E(x,y)〜Ltr [I(y = f(x; θ)]+ Ex〜Utr [l(f(x; θ) = f (X ; θ) for ∀x0 ∈B(x,e))].	⑺
Note that a classifier f which achieves 0 value of the objective function (7) satisfies the conditions of
Proposition 2 and thus classifies all unlabeled data correctly.
The objective function (7) is not practically usable since neither optimizing the indicator function nor
checking f(x; θ) 6= f(x0; θ) for all x0 in B(x, ) is possible. To resolve these problems, we replace
the indicator functions in (7) with the cross-entropies, and the neighborhood B(x, ) in the second
term with the adversarial direction. By doing so, we have the following alternative objective function:
K
-Ex,y〜Ltr [logp(y∣x; θ)] - Ex〜Utr £p(k|x; θ)logp(k∣x + radvr(x, e); θ) .	(8)
k=1
Finally, We replacep(∙∣χ; θ) in the second term of (8) by p(∙∣χ; θ) to have the objective function of
VAT (3).
The condition (6) in Proposition 2 means that the decision boundary is not located inside the support
Xk of each class. That is, the regularization term of VAT prevents the decision boundary from being
located at the high density regions of data or equivalently pushes the decision boundary from the high
density regions of data.
6	Experiments
6.1	Prediction performances in semi-supervised learning
We compare prediction performances of FAT over the benchmark datasets With other semi-supervised
learning algorithms. We consider the most Widely used datasets: MNIST (LeCun et al., 1998), SVHN
(Marlin et al., 2010) and CIFAR10 (Krizhevsky & Hinton, 2009). As in done by other Works, We
randomly sample 100, 1000 and 4000 labeled data from the MNIST, SVHN and CIFAR10 datasets,
respectively and use them as the labeled data and the rest as the unlabeled data. For fair comparison,
We use the same architectures as those used in Miyato et al. (2017) for MNIST, SVHN and CIFAR10.
The optimal tuning parameters (, τ, δ) in FAT are chosen based on the validation data accuracy.
7
Under review as a conference paper at ICLR 2019
Table 1: Comparison of prediction accuracies of various semi-supervised learning algorithms for the
three benchmark datasets. mod. VAT is the modified version of VAT stated in Section 4.
Method	Test acc.(%)		
	MNIST(100)	SVHN(1000)	CIFAR10(4000)
DGN (Kingma et al., 2014)	96.67	63.98	-
Ladder (Rasmus et al., 2015)	98.94	-	79.6
ALI (Donahue et al., 2016)	-	92.58	82.01
FM-GAN (Salimans et al., 2016)	99.07	91.89	81.37
FM-GAN-Tan (Kumar et al., 2017)	-	95.61	83.80
Bad GAN (Dai et al., 2017)	99.20	95.75	85.59
VAT (Miyato et al., 2017)	98.64	93.17	85.13
CrossEnt (use all data)	98.82	96.74	90.31
CrossEnt (use lab. data only)	79.16	88.91	67.45
mod. VAT	98.70	94.69	85.18
FAT	98.89	95.94	85.31
Table 2: Comparison of prediction accuracies with small labeled data and more complex dataset.
Method	Test acc.(%)			
	MNIST(20)	SVHN(500)	CIFAR10(1000)	CIFAR100(8000)
FM-GAN (SaHmans et al., 2016)	83.23	81.56^^	78.13	-
FM-GAN-Tan (SaHmans et al., 2016)	-	95.13	80.48	-
CrossEnt(use all data)	98.82	96.74^^	90.31	46.72
CrossEnt(use lab. data only)	54.92	85.82	50.30	18.35
mod. VAT	89.92	92.59^^	75.43	34.76
FAT	96.32	95.21	75.96	35.52
We use Adam algorithm (Kingma & Ba, 2014) to update the parameters and do not use any data
augmentation techniques. The results are summarized in Table 1, which shows that FAT achieves
the state-of-the-art accuracy for SVHN dataset and competitive accuracies with the state-of-the-art
method (i.e. Bad GAN) for MNIST and CIFAR10.
We conduct another experiments where the numbers of labeled data are much smaller and consider
a more complex dataset CIFAR100 (Krizhevsky & Hinton, 2009), whose results are summarized
in Table 2. Note that FAT still dominates mod. VAT for the all datasets and the margins become
larger. While FAT achieves the state-of-the-art performances for MNIST and SVHN, its performance
degrades much for CIFAR10 compared to the accuracy for the case of 4000 labeled data. Note that
the quality of bad samples depends on the quality of the estimated classifier. For CIFAR10 which is
relatively more complex than MNIST and SVHN, the quality of the estimated classifier is influenced
much to the amount of labeled data and thus the accuracy of FAT is more sensitive to the amount of
labeled data. However, it is interesting to see that FAT is superior to mod. VAT for CIFAR10 and
CIFAR100, which suggests that bad samples are helpful for complex problems where the quality of
bad samples might not be sufficiently good.
The other advantage of FAT is its stability with respect to learning phase. With small labeled data,
the test accuracies of each epoch tends to fluctuate much for VAT and mod VAT, while FAT provides
much more stable results. See Figure 7 in Appendix. This may be partly because ’good’ bad samples
keep the classifier from fluctuation.
8
Under review as a conference paper at ICLR 2019
Table 3: Test accuracies of MNIST for various values of τ and δ. The other two parameters on each
case are fixed to the optimal values.
τ	0.001	0.01	0.1	0.2	δ	1	2.	4.	6.
Test acc.	98.65	98.89	98.77	98.71	Test acc.	89.54	98.89	98.79	98.55
Table 4: Test accuracies for diverse objective loss functions.
Data	MNIST SVHN CIFAR10
Setting	Test acc.(%)
Ltrue + Lfake + LVAT	98.89	95.94	85.15
Ltrue + Lfake	83.6	90.21	68.32
Lfake + LVAT	98.77	95.71	85.31
6.2	Effects of tuning parameters
FAT introduces two additional tuning parameters τ and δ compared to VAT, where τ is used to
determine whether a bad sample is ’good’ and δ is the radius to generate bad samples. We investigate
the sensitivities of prediction performances with respect to the changes of the values of τ and δ with
being fixed at 1.5 that is the optimal value. The results are reported in Table 3. Unless τ is too small
or too large, the prediction performances are not changed much. For δ, care should be done. Too
small δ, smaller than , hampers the prediction performance much. Apparently, a similar value of δ
to that of (i.e. δ = 2) gives the best result.
6.3	Objective function analysis
In this subsection, we analyze the effects of Ltrue and LVAT in this section. We do not consider the
cross-entropy of the labeled data and Lfake since they are necessary to reflect the idea utilizing bad
data. Table 4 compares the performances without one or both of these terms. Note that LVAT is
necessary for superior performances, which is because LVAT is indispensable to generate ‘good’ bad
samples as explained in Section 5.1. On the other hand, the term Ltrue , which is devised to separate
unlabeled data from bad samples, is not always helpful. A possible explanation is that sometimes the
term Ltrue would give an undesirable effect on the misclassified data.
6.4	Computational efficiency
We investigate the computational efficiency of our method in view of learning speed and computation
time per training epoch. For Bad GAN, we did not use PixelCNN++ on SVHN and CIFAR10 datasets
since the pre-trained PixelCNN++ models are not publicly available. Figure 4 draws the bar plots
about the numbers of epochs needed to achieve the prespecified test accuracies. We can clearly see
that FAT requires much less epochs
We also calculate the ratios of the computing time of each semi-supervised learning algorithm
over the computing time of the corresponding supervised learning algorithm for CIFAR10 dataset,
whose results are summarized in Table 5. These ratios are almost same for different datasets. The
computation time of FAT is competitive to VAT and mod. VAT, and hence we can conclude that FAT
arrives at the prespecified performances much efficiently. Note that PixelCNN++ is not used for
this experiment, and so comparison of computing time of FAT and Bad GAN with PixelCNN++ is
meaningless
9
Under review as a conference paper at ICLR 2019
Figure 4: The number of epochs to achieve the prespecified test accuracies (98%, 90% and 80%) with
the four methods for (Left) MNIST, (Middle) SVHN and (Right) CIFAR10 datasets. Bad GAN is
operated without PixelCNN++ for SVHN and CIFAR10 datasets.
Table 5: Learning time per training epoch ratios compared to supervised learning with cross-entropy
for CIFAR10. Bad GAN is operated without PixelCNN++.
Method VAT mod VAT FAAT B^, ^N
Time ratio^^137	162	209	320
6.5 Quality of bad samples generated by adversarial training
We investigate how ‘good’ bad samples generated by the adversarial training are. The upper panel
of Figure 5 shows the scatter plot of the synthetic data and the trace plot of prediction accuracies of
FAT and VAT. And the lower panel of Figure 5 draws the scatter plots with generated bad samples
at various epochs. We can clearly see that bad samples move to lower density regions as the epoch
increases, which amply demonstrates that the adversarial training is good at generating bad samples.
We also compare bad images of the MNIST data generated by FAT and Bad GAN in Figure 6. The
bad images by FAT do not look like real images and do not seem to be collapsed, which indicates
that FAT consistently generates diverse and good bad samples. Bad GAN also generates diverse bad
samples but some ‘realistic’ images can be found.
7	Conclusion
In this paper, we propose a new method called FAT for semi-supervised learning which generates
bad samples only with a given classifier. The objective function of FAT is devised to compromise
the advantages of Bad GAN and VAT together, which makes FAT be faster and more accurate. In
numerical experiments, we show that FAT achieves almost the state-of-the-art performances with
much fewer epochs. Unlike Bad GAN , FAT only needs to learn a discriminator. Hence, it could
be extended without much effort to other learning problems. For example, FAT can be modified
easily for recurrent neural networks and hence can be applied to sequential data. We will leave this
extension as a future work.
It would be useful to combine FAT with a generative approach such as Bad GAN, in particular when
the initial classifier is bad. Since FAT uses only a classifier to generate bad samples, the initial
estimate of the classifier would be important. Using the generator model learned by large unlabeled
data would be helpful to find a good initial estimate of the classifier.
Acknowledgments
This work is supported by Samsung Electronics Co., Ltd.
10
Under review as a conference paper at ICLR 2019
Figure 5: (Upper Left) The scatter plot of synthetic data which consist of 1000 unlabeled data (gray)
and 4 labeled data for each class (red and blue with black edge). (Upper Right) Accuracies of
unlabeled data for each epochs for VAT and FAT. We use 2-layered NN with 100 hidden units each.
(Lower) Bad samples and classified unlabeled data by colors at the different training epochs of FAT
Figure 6: 100 randomly sampled bad images using (Left) FAT and (Right) Bad GAN.
References
Zihang Dai, Zhilin Yang, Fan Yang, William W Cohen, and Ruslan R Salakhutdinov. Good semi-
supervised learning that requires a bad gan. In Advances in Neural Information Processing Systems,
pp. 6513-6523,2017.
Jeff Donahue, Philipp Krahenbuhl, and Trevor Darrell. Adversarial feature learning. arXiv preprint
arXiv:1605.09782, 2016.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural informa-
tion processing systems, pp. 2672-2680, 2014a.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014b.
Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Advances
in neural information processing systems, pp. 529-536, 2005.
Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R Salakhutdinov.
Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint
arXiv:1207.0580, 2012.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
11
Under review as a conference paper at ICLR 2019
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Diederik P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised
learning with deep generative models. In Advances in Neural Information Processing Systems, pp.
3581-3589, 2014.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images.
Technical report, Citeseer, 2009.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolu-
tional neural networks. In Advances in neural information processing systems, pp. 1097-1105,
2012.
Abhishek Kumar, Prasanna Sattigeri, and Tom Fletcher. Semi-supervised learning with gans: manifold
invariance with improved inference. In Advances in Neural Information Processing Systems, pp.
5534-5544, 2017.
Yann LeCun, Leon Bottou, YoshUa Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Lars Maal0e, Casper Kaae S0nderby, S0ren Kaae S0nderby, and Ole Winther. Auxiliary deep
generative models. arXiv preprint arXiv:1602.05473, 2016.
Benjamin Marlin, Kevin Swersky, Bo Chen, and Nando Freitas. Inductive principles for restricted
boltzmann machine learning. In Proceedings of the Thirteenth International Conference on
Artificial Intelligence and Statistics, pp. 509-516, 2010.
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, and Shin Ishii. Distributional
smoothing with virtual adversarial training. arXiv preprint arXiv:1507.00677, 2015.
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a reg-
ularization method for supervised and semi-supervised learning. arXiv preprint arXiv:1704.03976,
2017.
Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-supervised
learning with ladder networks. In Advances in Neural Information Processing Systems, pp. 3546-
3554, 2015.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. In Advances in Neural Information Processing Systems, pp.
2234-2242, 2016.
Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P Kingma. Pixelcnn++: Improving the
pixelcnn with discretized logistic mixture likelihood and other modifications. arXiv preprint
arXiv:1701.05517, 2017.
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Du-
mitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, 2015.
12
Under review as a conference paper at ICLR 2019
Tijmen Tieleman and Geoffrey Hinton. Lecture 6.5-rmsprop: Divide the gradient by a running
average of its recent magnitude. COURSERA: Neural networksfor machine learning, 4(2):26-31,
2012.
Jason Weston, FrederiC Ratle, Hossein Mobahi, and Ronan Collobert. Deep learning via semi-
supervised embedding. In Neural Networks: Tricks of the Trade, pp. 639-655. Springer, 2012.
13
Under review as a conference paper at ICLR 2019
A	Appendix
A.1 PROOF OF PROPOSITION 1
Without loss of generality, we assume that w x + b > 0, that is, p(y = 1|x; η) > p(y = 0|x; η). We
will show that there exists e > 0 such that w r* (x, E) < 0. Note that
W
argmax KL(X) r; η) = e-：-- (=: r1) and
r,||r ∣∣≤e,wzr>0	||w||
w
argmax KL(x,r; η) = -e∣∣-1∣ (=: b)∙
r,∣∣r ∣∣≤e,w'r<0	||W||
So all we have to do is to show
KL(x,r2; η) > KL(x, r；; η).
By simple calculation we can get the following:
KL(x, r；; η) — KL(x, r；; η)=一	exp (w'(x + r；) + b) +1 P(y = 1|X； MTr -r；)- lθgexp(w0(x + r；) + b) + 1	.
Using the Taylor,s expansion UP to the third-order, we obtain the following:
log kXP (W (x + r) + b) +1]	二	二 log kXP (W X + b) +1] + p(y = 1|x; η)w r + ； p(y = 1|x; η)p(y = 0|x; η)r ww r 1，	I	I	、一	l	I	、、G -6p(y = 1|x; η)p(y = 0|x; η) {p(y = 1|x; η) - p(y = 0|x; η)} Σ WiWj Wkrirj rk i,j,k=1 +o(||r||3).
So,
exp (W (x + r；) + b) + 1 log	τ~τ-			L	 = exp (w (x + r1； ) + b) + 1	二 p(y = 1|x; η)w (r； - r；) +1 p(y = 1|x;η)p(y = 0|x;η) {p(y = 1|x;η) -p(y = 0|x;η)}e3||w||3 + o(e3).
Thus, we have the following equations:
KL(x, r；; η) — KL(x, r；; η)	=	3p(y = 1|x;η)p(y = 0|x;η) {p(y = 1|x;η) -p(y = 0|x;η)}e3||w||3 + o(e3) C ∙ e3 + o(e3).
Therefore, there exists e； > 0 such that KL(x, r；; η) > KL(x, r；; η) for ∀0 < e < e；. □
A.2 Extension OF Proposition 1 for the DNN classifier
Consider a binary classification DNN model with ReLU activation function p(y = 1|x; θ) =
(1 + exp(-g(x; θ)))-1 parameterized by θ. Since g(x; θ) is piecewise linear, we can write g(∙; θ) as
N
g(Iθ) = XK ∈ Aj) ∙ (WjX + bj),
j= 1
where Aj is a linear region and N is the number of linear regions.
14
Under review as a conference paper at ICLR 2019
For given x, suppose g(x; θ) > 0. If g(x : θ) is estimated reasonably, we expect that g(x; θ) is
decreasing if x moves toward the decision boundary. A formal statement of this expectation would
be that X - Nxg(x; θ) can arrive at the decision boundary for a finite value of r > 0, where Nx
is the gradient with respect to x. Of course, for X with g(χ; θ) < 0, We expect that X + rVxg(χ; θ)
can arrive at the decision boundary for a finite value of r > 0. We say that x is normal if there is
r > 0 such that X - rVxg(X : θ)sign{g(X : θ)} locates at the decision boundary. We say that a linear
region Aj is normal if all X in Aj are normal. We expect that most of Aj are normal if g(X; θ) is
reasonably estimated so that the probability decreases or increases depending on sign{g(X : θ)} if X
is getting closer to the decision boundary.
The following proposition proves that the adversarial direction is toward the decision boundary for all
Xs in normal linear regions.
Proposition 3 If a linear region Aj is normal. Then for any X ∈ int(Aj ), there exists > 0 and
δ > 0 such that Xbad = X + δradvr(X, )/||radvr(X, )|| is on the decision boundary.
Proof. Take H > 0 such that X + r ∈ Aj for ∀r ∈ B(x, e). Then by Proposition 1, there exists
0 < e* < H such that for ∀0 < e < e*,
radvr(x, E)	= 〜sign(-bj - Wjx))
wjj
||wjj||
H -Vxg(x; θ)sign{g(x : θ)}.
X is normal, thus there exists δ > 0 such that Xbad = X + δradvr(X, H)/||radvr(X, H)|| belongs to the
decision boundary.
A.3 Proof of Proposition 2
It suffices to show that ∀X, X0 ∈ Uktr, f(X) = f(X0 ) for all k = 1, ..., K. For given Uktr, there exists
(XH, yH) ∈ Ltr such that d({XH}, Uktr) < H. So Uktr ∪ {XH} is H-connected. That is, for any X ∈ Uktr,
there exists a path (XH, X1, ..., Xq, X) such that (XH, X1), ..., (Xq, X) are all H-connected. Therefore
y(X) = y(XH) = yH for ∀X ∈ Uktr, and the proof is done.
15
Under review as a conference paper at ICLR 2019
A.4 Figure
Figure 7: Trace plot of the test accuracies with the four methods for MNIST dataset. 20 randomly
sampled data are used as the labeled data and the rest are used as the unlabeled data.
16