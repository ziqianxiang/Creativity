Under review as a conference paper at ICLR 2019
Classification from Positive, Unlabeled and
Biased Negative Data
Anonymous authors
Paper under double-blind review
Ab stract
Positive-unlabeled (PU) learning addresses the problem of learning a binary clas-
sifier from positive (P) and unlabeled (U) data. It is often applied to situations
where negative (N) data are difficult to be fully labeled. However, collecting a
non-representative N set that contains only a small portion of all possible N data
can be much easier in many practical situations. This paper studies a novel clas-
sification framework which incorporates such biased N (bN) data in PU learning.
The fact that the training N data are biased also makes our work very different
from those of standard semi-supervised learning. We provide an empirical risk
minimization-based method to address this PUbN classification problem. Our ap-
proach can be regarded as a variant of traditional example-reweighting algorithms,
with the weight of each example computed through a preliminary step that draws
inspiration from PU learning. We also derive an estimation error bound for the
proposed method. Experimental results demonstrate the effectiveness of our algo-
rithm in not only PUbN learning scenarios but also ordinary PU leaning scenarios
on several benchmark datasets.
1	Introduction
In conventional binary classification, examples are labeled as either positive (P) or negative (N),
and we train a classifier on these labeled examples. On the contrary, positive-unlabeled (PU) learn-
ing addresses the problem of learning a classifier from P and unlabeled (U) data, without need of
explicitly identifying N data (Elkan & Noto, 2008; Ward et al., 2009).
PU learning finds its usefulness in many real-world problems. For example, in one-class remote
sensing classification (Li et al., 2011), we seek to extract a specific land-cover class from an image.
While it is easy to label examples of this specific land-cover class of interest, examples not belonging
to this class are too diverse to be exhaustively annotated. The same problem arises in text classifica-
tion, as it is difficult or even impossible to compile a set ofN samples that provides a comprehensive
characterization of everything that is not in the P class (Liu et al., 2003; Fung et al., 2006). Besides,
PU learning has also been applied to other domains such as outlier detection (Hido et al., 2008; Scott
& Blanchard, 2009), medical diagnosis (Zuluaga et al., 2011), or time series classification (Nguyen
et al., 2011).
By carefully examining the above examples, we find out that the most difficult step is often to
collect a fully representative N set, whereas only labeling a small portion of all possible N data is
relatively easy. Therefore, in this paper, we propose to study the problem of learning from P, U
and biased N (bN) data, which we name PUbN learning hereinafter. We suppose that in addition
to P and U data, we also gather a set of bN samples, governed by a distribution distinct from the
true N distribution. As described previously, this can be viewed as an extension of PU learning,
but such bias may also occur naturally in some real-world scenarios. For instance, let us presume
that we would like to judge whether a subject is affected by a particular disease based on the result
of a physical examination. While the data collected from the patients represent rather well the P
distribution, healthy subjects that request the examination are in general highly biased with respect
to the whole healthy subject population.
We are not the first to be interested in learning with bN data. In fact, both Li et al. (2010) and
Fei & Liu (2015) attempted to solve similar problems in the context of text classification. Li et al.
(2010) simply discarded negative samples and performed ordinary PU classification. It was also
1
Under review as a conference paper at ICLR 2019
mentioned in the paper that bN data could be harmful. Fei & Liu (2015) adapted another strategy.
The authors considered even gathering unbiased U data is difficult and learned the classifier from
only P and bN data. However, their method is specific to text classification because it relies on the
use of effective similarity measures to evaluate similarity between documents. Therefore, our work
differs from these two in that the classifier is trained simultaneously on P, U and bN data, without
resorting to domain-specific knowledge. The presence of U data allows us to address the problem
from a statistical viewpoint, and thus the proposed method can be applied to any PUbN learning
problem in principle.
In this paper, we develop an empirical risk minimization-based algorithm that combines both PU
learning and importance weighting to solve the PUbN classification problem, We first estimate the
probability that an example is sampled into the P or the bN set. Based on this estimate, we regard bN
and U data as N examples with instance-dependent weights. In particular, we assign larger weights
to U examples that we believe to appear less often in the P and bN sets. P data are treated as P
examples with unity weight but also as N examples with usually small or zero weight whose actual
value depends on the same estimate.
The contributions of the paper are three-fold:
1.	We formulate the PUbN learning problem as an extension of PU learning and propose an empir-
ical risk minimization-based method to address the problem. We also theoretically establish an
estimation error bound for the proposed method.
2.	We experimentally demonstrate that the classification performance can be effectively improved
thanks to the use of bN data during training. In other words, PUbN learning yields better perfor-
mance than PU learning.
3.	Our method can be easily adapted to ordinary PU learning. Experimentally we show that the
resulting algorithm allows us to obtain new state-of-the-art results on several PU learning tasks.
Relation with Semi-supervised Learning With P, N and U data available for training, our problem
setup may seem similar to that of semi-supervised learning (Chapelle et al., 2010; Oliver et al., 2018).
Nonetheless, in our case, N data are biased and often represent only a small portion of the whole
N distribution. Therefore, most of the existing methods designed for the latter cannot be directly
applied to the PUbN classification problem. Furthermore, our focus is on deducing a risk estimator
using the three sets of data, whereas in semi-supervised learning the main concern is often how U
data can be utilized for regularization (Grandvalet & Bengio, 2005; Belkin et al., 2006; Laine & Aila,
2017; Miyato et al., 2016). The two should be compatible and we believe adding such regularization
to our algorithm can be beneficial in many cases.
Relation with Dataset Shift PUbN learning can also be viewed as a special case of dataset shift1
(Quionero-Candela et al., 2009) if we consider that P and bN data are drawn from the training
distribution while U data are drawn from the test distribution. Covariate shift (Shimodaira, 2000;
Sugiyama & Kawanabe, 2012) is another special case of dataset shift that has been studied inten-
sively. In the covariate shift problem setting, training and test distributions have the same class
conditional distribution and only differ in the marginal distribution of the independent variable. One
popular approach to tackle this problem is to reweight each training example according to the ratio
of the test density to the training density (Huang et al., 2007; Sugiyama et al., 2008). Nevertheless,
simply training a classifier on a reweighted version of the labeled set is not sufficient in our case
since there may be examples with zero probability to be labeled. It is also important to notice that
the problem of PUbN learning is intrinsically different from that of covariate shift and neither of the
two is a special case of the other.
2	Problem Setting
In this section, we briefly review the formulations of PN, PU and PNU classification and introduce
the problem of learning from P, U and bN data.
1 Dataset shift refers to any case where training and test distributions differ. The term sample selection bias
(Heckman, 1979; Zadrozny, 2004) is sometimes used to describe the same thing. However, strictly speaking,
sample selection bias actually refers to the case where training instances are first drawn from the test distribu-
tions and then a subset of these data is systematically discarded due to a particular mechanism.
2
Under review as a conference paper at ICLR 2019
2.1	Standard B inary Classification
Let x ∈ Rd and y ∈ {+1, -1} be random variables following an unknown probability distribution
with density p(x, y). Let g : Rd → R be an arbitrary decision function for binary classification and
` : R → R+ be a loss function of margin yg(x) that usually takes a small value for a large margin.
The goal of binary classification is to find g that minimizes the classification risk:
R ( g ) = E( x,y)〜P ( x,y)[' ( yg ( X))],
(1)
where E(Xy)〜P(Xy)[∙] denotes the expectation over the joint distribution P(x, y). When We care
about classification accuracy, ` is the zero-one loss `01 (z) = (1 - sign(z))/2. However, for ease
of optimization, `01 is often substituted with a surrogate loss such as the sigmoid loss `sig(z) =
1/(1 + exp(z)) or the logistic loss `log(z) = ln(1 + exp(-z)) during learning.
In standard supervised learning scenarios (PN classification), we are given P and N data that are
sampled independently from p(x | y = +1) and p(x | y = -1) as XP = {xiP}in=P1 and XN =
{xN}2Nι∙ Letus denote by R+(g) = EX〜P(χ∣y=+i)['(g(X))], RN (g) = EX〜P(χ∣y=-1)['(-g(x))]
partial risks and π = p(y = 1) the P prior. We have the equality R(g) = πRP+(g) + (1 - π)RN-(g).
The classification risk (1) can then be empirically approximated from data by
ʌ	ʌ I	ʌ
RPN (g) = nRt+(g) + (1 - π) R- (g),
where R^+(g) = nPPnPi'(g(XP))and RN (g) = n⅛ Pn=ι'(-g(XN)). ByminimiZing RPN(g)
we obtain the ordinary empirical risk minimizer ^pn.
2.2	PU Classification
In PU classification, instead of N data XN we have only access to XU ={婢居〜 p(X) a set of
U samples drawn from the marginal density p(X). Several effective algorithms have been designed
to address this problem. Liu et al. (2002) proposed the S-EM approach that first identifies reliable
N data in the U set and then runs the Expectation-Maximization (EM) algorithm to build the final
classifier. The biased support vector machine (Biased SVM) introduced in Liu et al. (2003) regards
U samples as N samples with smaller weights. Mordelet & Vert (2014) solved the PU problem by
aggregating classifiers trained to discriminate P data from a small random subsample of U data.
More recently, attention has been paid on the unbiased risk estimator proposed in du Plessis et al.
(2014) and du Plessis et al. (2015). The key idea is to use the following equality:
(1 - π)RN- (g) = RU- (g) - πRP- (g),
where R-(g) = EX〜P(X)['(-g(x))] and R-(g) = EX〜P(χ∣y=+i)['(-g(x))]. This equality is ac-
quired by exploiting the fact p(X) = πp(X | y = +1) + (1 - π)p(X | y = -1). As a result, we can
approximate the classification risk (1) by
ʌ	ʌ	I	ʌ	ʌ
RPU(g) = πR+ (g) - πR- (g) + RU (g),
(2)
where R-(g) = np Pg '(-g(xp)) and Ri^(g) = nU P圈 '(-g(xu)). We then minimize
ʌ
RPU(g) to obtain another empirical risk minimizer ^pu. Note that as the loss is always positive, the
ʌ
classification risk (1) that RPU(g) approximates is also positive. However, Kiryo et al. (2017) pointed
out that when the model of g is too flexible, that is, when the function class G is too large, Rpu(^pu)
indeed goes negative and the model seriously overfits the training data. To alleviate overfitting, the
authors observed that RU-(g) - πRP- (g) = (1 - π)RN-(g) ≥ 0 and proposed the non-negative risk
estimator for PU learning:
~	ʌ	I	ʌ	ʌ
RPU(g) = πRP+ (g) + max{0, RU- (g) - πRP- (g)}.
(3)
ʌ ʌ
In terms of implementation, stochastic optimization was used and when r = RU- (g) - πRP- (g)
becomes negative for a mini-batch, they performed a step of gradient ascent along Rr to make the
mini-batch less overfitted.
3
Under review as a conference paper at ICLR 2019
2.3	PNU Classification
In semi-supervised learning (PNU classification), P, N and U data are all available. An abundance
of works have been dedicated to solving this problem. Here we in particular introduce the PNU risk
estimator proposed in Sakai et al. (2017). By directly leveraging U data for risk estimation, it is the
most comparable to our method. The PNU risk is simply defined as a linear combination of PN and
PU/NU risks. Let us just consider the case where PN and PU risks are combined, then for some
γ ∈ [0, 1], the PNU risk estimator is expressed as
ʌ ʌ ʌ
rKnuS) = YRPN(g) + (I - Y)RPU(g)
ʌ I	ʌ	ʌ	ʌ
=∏R^+(g) + γ(1 - ∏)R^n (g) + (1 — Y)(R^U(g) - ∏R^-(g)).	(4)
We can again consider the non-negative correction by forcing the term Y (1 - ∏) RN (g) + (1 -
ʌ ʌ
Y)(RU- (g) - πRP-(g)) to be non-negative. In the rest of the paper, we refer to the resulting algorithm
as non-negative PNU (nnPNU) learning (see Appendix D.4 for an alternative definition of nnPNU
and the corresponding results).
2.4	PUbN Classification
In this paper, we study the problem of PUbN learning. It differs from usual semi-supervised learning
in the fact that labeled N data are not fully representative of the underlying N distribution p(x | y =
-1). To take this point into account, we introduce a latent random variable s and consider the joint
distribution p(x, y, s) with constraint p(s = +1 | x, y = +1) = 1. Equivalently, p(y = -1 |
x, s = -1) = 1. Let ρ = p(y = -1, s = +1). Both π and ρ are assumed known throughout the
paper. In practice they often need to be estimated from data (Jain et al., 2016; Ramaswamy et al.,
2016; du Plessis et al., 2017). In place of ordinary N data we collect a set ofbN samples
XbN = {涕N}2bN 〜p(χ∣y = -1 ,s = +1).
The goal remains the same: we would like to minimize the classification risk (1).
3	Method
In this section, we propose a risk estimator for PUbN classification and establish an estimation error
bound for the proposed method. Finally we show how our method can be applied to PU learning as
a special case when no bN data are available.
3.1	Risk Estimator
Let R-n(g) = Ex〜P(χ∣y=-1 ,s=+i)['(-g(x))] and R-=_1(g) = EX〜P(χ∣s=-1)['(-g(x))]. Since
p(x) = p(x, y = +1) + p(x, y = -1, s = +1) + p(x, s = -1), we have
R(g) = πRP+(g) + ρRb-N(g) + (1 - π - ρ)Rs-=-1(g).	(5)
The first two terms on the right-hand side of the equation can be approximated directly from data by
writing R+ (g) = nP Pnpι'(g(XP)) and RbN(g) =焉 Pn=N '(-g(X-N))∙ We therefore focus on
the third term R-= -1(g) := (1 - ∏ - P)R-= -1(g). Our approach is mainly based on the following
theorem. We relegate all proofs to the appendix.
Theorem 1. Let σ(x) = p(s = +1 | x). For all η ∈ [0, 1] and h : Rd → [0, 1] satisfying the
condition h(x) > η ⇒ σ(x) > 0, the risk R-= -1(g) can be expressed as
4
Under review as a conference paper at ICLR 2019
R-= -1(g) = Ex^p(X)[1 h(X)≤η '(-g(ʃ))(1 - σ(T))]
+ P Ex~p(χ∣s=+1 ,y=— 1)
Ih(X)>η '(-g(x))1 σ(T)
σ(T)
Ih(X)>η '(-g(t))1 σ(T)
σ(T)
(6)
In the theorem, R -=—1(g) is decomposed into three terms, and when the expectation is substituted
with the average over training samples, these three terms are approximated respectively using data
from XU, XP and XbN . The choice of h and η is thus very crucial because it determines what each
of the three terms tries to capture in practice. Ideally, we would like h to be an approximation of
σ. Then, for T such that h(T) is close to 1, σ(T) is close to 1, so the last two terms on the right-
hand side of the equation can be reasonably evaluated using XP and XbN (i.e., samples drawn from
p(T | s = +1)). On the contrary, if h(T) is small, σ(T) is small and such samples can be hardly
found in XP orXbN. Consequently the first term appeared in the decomposition is approximated with
the help of XU. Finally, in the empirical risk minimization paradigm, η becomes a hyperparameter
that controls how important U data is against P and bN data when We evaluate R —=—ι (g). The larger
η is, the more attention we would pay to U data.
One may be curious about why we do not simply approximate the whole risk using only U samples,
that is, set η to 1. There are two main reasons. On one hand, if we have a very small U set, which
means nU	nP and nU nbN, approximating a part of the risk with labeled samples should
help us reduce the estimation error. This may seem unrealistic but sometimes unbiased U samples
can also be difficult to collect (Ishida et al., 2018). On the other hand, more importantly, we have
empirically observed that when the model of g is highly flexible, even a sample regarded as N with
small weight gets classified as N in the latter stage of training and performance of the resulting
classifier can thus be severely degraded. Introducing η alleviates this problem by avoiding treating
all U data as N samples.
As σ is not available in reality, we propose to replace σ by its estimate σ in (6). We further substitute
h with the same estimate and obtain the following expression:
RS=—1 ,η,σIg) = EX〜P(χ)[ 1^(χ)≤η '(-g(t))(1 - σ(T))]
1^(X)>η '(-g(T))1 -:σ(T)
σ(T)
+ P EX~p(XI s= + 1 ,y=— 1)
lσ(X)>η '(-g(T))1 -σ((T)
σ(T)
We notice that RS=—1 ,η,σ depends both on η and σ. It can be directly approximated from data by
1 nU
Rs=-1 ,η,σ(g) =嬴 Z [⅝(XU)≤ '(一(TU))(1 - σ(*)]
十xXχ ) ^( xP) >η ` (-g (TP))I -M i) _
+ JL £ [1 σ(XbN)> '(-g(TbN))I-：TF ) ∙
nbN ML σ(Xa)>η	σ(TbN)	J
We are now able to derive the empirical version of Equation (5) as
+	——
RPUbN,η,σ(g) = πRP (g) + PRbN(g) + Rs=—1 ,η,σ(g) ∙	⑺
Estimating σ If we regard s as a class label, the problem of estimating σ is then equivalent to
training a probabilistic classifier separating the classes with s = +1 and s = -1. Observing that
(π + P )E X〜P ( x∣s=+1)[' ( Cg ( x ))] = π E X〜P ( X∣y= + 1)[' ( Cg ( x ))] + P E X〜P ( x ∣ y = - 1 ,s=+1)[' ( Cg ( x ))] for
∈ {+1, -1}, it is straightforward to apply nnPU learning with availability of XP, XbN and XU to
5
Under review as a conference paper at ICLR 2019
minimize E(叱S)〜P(叱S)['(Sg(x))]. In other words, here We regard XP and XbN as P and XU as U,
and attempt to solve a PU learning problem by applying nnPU. Since we are interested in the class-
posterior probabilities, we minimize the risk with respect to the logistic loss and apply the sigmoid
function to the output of the model to get σ(x). However, the above risk estimator accepts any
reasonable σ and we are not limited to using nnPU for computing σ. For example, the least-squares
fitting approach proposed in Kanamori et al. (2009) for direct density ratio estimation can also be
adapted to solving the problem.
3.2 Estimation Error Bound
Here we establish an estimation error bound for the proposed method. Let G be the function class
from which we find a function. The Rademacher complexity of G for the samples of size n drawn
from q(x) is defined as
Rn,q (G) = EX〜qn Eθ SUP — X : θig( χi )
g∈G n xi∈X
where X = {x1 , . . . , xn} and θ = {θ1, . . . , θn} with each xi drawn from q(x) and θi as a
Rademacher variable (Mohri et al., 2012). In the following we will assume that Rn,q(G) vanishes
asymptotically as n → ∞. This holds for most of the common choices of G if proper regularization
is considered (Bartlett & Mendelson, 2002; Golowich et al., 2018). Assume additionally the exis-
tence of Cg > 0 such that supg∈g IIgllg ≤ Cg as well as C' > 0 such that sup∣z∣≤Cg '(Z) ≤ C'.
We also assume that ` is Lipschitz continuous on the interval [-Cg, Cg] with a Lipschitz constant
L'.
Theorem 2. Let g^ = arg ming∈g R(g) be the true risk minimizer and ^PUbN,η,σ =
ʌ
arg min g∈g RPUbN ,η,σ (g) be the PUbN empirical risk minimizer. We suppose that σ is a fixed func-
ʌ
tion independent of data used to compute RPUbN,η,σ (g) and η ∈ (0, 1]. Denote by Pp(x) = P(x ∣
y = +1) andPbN(X) = P(x ∣ y = — 1, S = +1) the P and bN marginals. Let Z = P(σ(x) ≤ η) and
E = EX〜P(X)[∣σ(x) — σ(x) 12 3]. Thenforany δ > 0, with probability at least 1 — δ,
R(0PUbN,η,σ) 一 R(g*)
≤ 4LlRnU,P (G) +	JRnP,PP (G) + -P^RnbN,PbN (G)
+ 2 CiS 三 +⑷ ST +凶S 三 +2 Ci Pe +迎 pi―ZK
W 2 n U	η y 2 n P	η V 2 nbN	η ""
Theorem 2 shows that as nP → ∞, nbN → ∞ and nU → ∞, we have R(^PUbN,η,σ) 一 R(g*) →
2Cι√ζe + 2(Ci/n)p(1 - Z)e. Furthermore, if there is CG > 0 such that Rn,q(G) ≤ Cg/√n
2, the convergence rate is OP(1 /√nP +1 /√nbN + 1 /√nU), where OP denotes the order in prob-
ability. As for e, knowing that σ is also estimated from data in practice 3, apparently its value
depends on both the estimation algorithm and the number of samples that are involved in the es-
timation process. For example, in our approach we applied nnPU with the logistic loss to ob-
tain σ, so the excess risk can be written as Eχ^p(X)KL(σ(x)∣∣σ(x)), where by abuse of notation
KL(PIq) = P ln(P/q)+(1—P) ln((1—P)/(1—q)) denotes the KL divergence between two Bernouilli
distributions with parameters respectively P and q. It is known that e = Eχ^p(X)[∣σ(x) — σ(x) 12] ≤
(1 /2)Eχzp(χ)KL(σ(x)∣∣σ(x)) (Zhang, 2004). The excess risk itself can be decomposed into the
sum of the estimation error and the approximation error. Kiryo et al. (2017) showed that under mild
assumptions the estimation error part converges to zero when the sample size increases to infinity
in nnPU learning. It is however impossible to get rid of the approximation error part which is fixed
2 For instance, this holds for linear-in-parameter model class F = {f (x) = w>φ(x) | kwk ≤
Cw, kφk∞ ≤ Cφ}, where Cw and Cφ are positive constants (Mohri et al., 2012).
3
3 These data, according to theorem 2, must be different from those used to evaluate RPUbN,η,σ (g). This
condition is however violated in most of our experiments. See Appendix D.3 for more discussion.
6
Under review as a conference paper at ICLR 2019
once we fix the function class G . To circumvent this problem, we can either resort to kernel-based
methods with universal kernels (Zhang, 2004) or simply enlarge the function class when we get
more samples.
3.3 PU Learning Revisited
In PU learning scenarios, we only have P and U data and bN data are not available. Nevertheless,
if we let y play the role of s and ignore all the terms related to bN data, our algorithm is naturally
applicable to PU learning. Let us name the resulting algorithm PUbN\N, then
+	+	+ A+	^ 一
RPUbN\N,η,σ (g) = πRP (g) + Ry = -1,η,σ (g),
where σ is an estimate of P(y = +1 ∣ x) and
R-= -1 ,η,σ(g) = EX〜p(X)[1 ^(X)≤η '(-g(X))(1- σ(x))] + πEX〜p(χ∣y=+i) [1^(X)>η '(-g(X))-x] ∙
PUbN\N can be viewed as a variant of the traditional two-step approach in PU learning which first
identifies possible N data in U data and then perform ordinary PN classification to distinguish P data
from the identified N data. However, being based on state-of-the-art nnPU learning, our method
is more promising than other similar algorithms. Moreover, by explicitly considering the posterior
p(y = +1 ∣ x), we attempt to correct the bias induced by the fact of only taking into account
confident negative samples. The benefit of using an unbiased risk estimator is that the resulting
algorithm is always statistically consistent, i.e., the estimation error converges in probability to zero
as the number of samples grows to infinity.
4	Experiments
In this section, we experimentally investigate the proposed method and compare its performance
against several baseline methods.
4.1	Basic Setup
We focus on training neural networks with stochastic optimization. For simplicity, in an experiment,
σ and g always use the same model and are trained for the same number of epochs. All models are
learned using AMSGrad (Reddi et al., 2018) as the optimizer and the logistic loss as the surrogate
loss unless otherwise specified. To determine the value of η, we introduce another hyperparameter
T and choose η such that #{x ∈ XU ∣ σ(x) ≤ η} = T(1 - π — P)nʊ. In all the experiments, an
additional validation set, equally composed ofP, U and bN data, is sampled for both hyperparameter
tuning and choosing the model parameters with the lowest validation loss among those obtained after
every epoch. Regarding the computation of the validation loss, we use the PU risk estimator (2) with
the sigmoid loss for g and an empirical approximation of Ex^p(X)[∣σ(x)-σ(x) 12] -Ex^p(X)[σ(x)2]
for σ (see Appendix B).
4.2	Effectiveness of the Algorithm
We assess the performance of the proposed method on three benchmark datasets: MNIST, CIFAR-10
and 20 Newsgroups. Experimental details are given in Appendix C. In particular, since all the three
datasets are originally designed for multiclass classification, we group different categories together
to form a binary classification problem.
Baselines. When XbN is given, two baseline methods are considered. The first one is nnPNU
adapted from (4). In the second method, named as PU→PN, we train two binary classifiers: one is
learned with nnPU while we regard s as the class label, and the other is learned from XP and XbN to
separate P samples from bN samples. A sample is classified in the P class only if it is so classified
by the two classifiers. When XbN is not available, nnPU is compared with the proposed PUbN\N.
Sampling bN Data To sample XbN, we suppose that the bias of N data is caused by a latent prior
probability change (Sugiyama & Storkey, 2007; Hu et al., 2018) in the N class. Let z ∈ Z :=
7
Under review as a conference paper at ICLR 2019
Table 1: Mean and standard deviation of misclassification rates over 10 trials for MNIST, CIFAR-10
and 20 Newsgroups under different choices of P class and bN data sampling strategies. For a same
learning task, different methods are compared using the same 10 random samplings. Underlines
denote that with the use of bN data the method leads to an improvement of performance according
to the 5% t-test. Boldface indicates the best method in each task.
t Biased N data uniformly sampled from the indicated latent categories.
? Probabilities that a sample of XbN belongs to the latent categories [1, 3, 5, 7, 9] / [bird, cat, deer,
dog, frog, horse] / [sci., soc., talk.] are [0.03, 0.15, 0.3, 0.02, 0.5] / [0.1, 0.02, 0.2, 0.08, 0.2, 0.4] /
[0.1, 0.5, 0.4].
Dataset	P	biased N	ρ	nnPU/nnPNU	PUbN(\N)	PU→PN
		Not given	NA	5.76 ± 1.04	4.64 ± 0.62	NA
MNIST	2, 4, 6, 8, 10	1,3,5 t	0.3	5.33 ± 0.97	4.05 ± 0.27	4.00 ± 0.30
		9 > 5 > others ?	0.2	4.60 ± 0.65	3.91 ± 0.66	3.77 ± 0.31
	Airplane, automobile, ship, truck	Not given	NA	12.02 ± 0.65	10.70 ± 0.57	NA
CIFAR-10		Cat, dog, horse t	0.3	10.25 ± 0.38	9.71 ± 0.51	10.37 ± 0.65
		Horse > deer = frog > others ?	0.25	9.98 ± 0.53	9.92 ± 0.42	10.17 ± 0.35
						
	Cat, deer, dog, horse	Not given	NA	23.78 ± 1.04	21.13 ± 0.90	NA
CIFAR-10		Bird, frog t	0.2	22.00 ± 0.53	18.83 ± 0.71	19.88 ± 0.62
		Car, truck t	0.2	22.00 ± 0.74	20.19 ± Lθ6	21.83 ± 1.36
		Not given	NA	14.67 ± 0.87	13.30 ± 0.53	NA
20 Newsgroups	alt., comp., misc.,	sci.t	0.21	14.69 ± 0.46	13.10 ± 0.90	13.58 ± 0.97
	rec.	talk.t	0.17	14.38 ± 0.74	12.61 ± 0.75	13.76 ± 0.66
		soc. > talk. > sci.?	0.1	14.41 ± 0.76	12.18 ± 0.59	12.92 ± 0.51
{1, . . . , S} be some latent variable which we call a latent category, where S is a constant. It is
assumed
p(x | z,y = -1) = p(x | z,y = -1,s = +1),
p(z | y = -1) 6= p(z | y = -1,s = +1).
In the experiments, the latent categories are the original class labels of the datasets. Concrete defi-
nitions of XbN with experimental results are summarized in Table 1.
Results. Overall, our proposed method consistently achieves the best or comparable performance
in all the scenarios, including those of standard PU learning. Additionally, using bN data can ef-
fectively help improving classification performance. However, the choice of algorithm is essential.
Both nnPNU and the naive PU→PN are able to leverage bN data to enhance classification accuracy
in only relatively few tasks. In the contrast, the proposed PUbN successfully reduce the misclassifi-
cation error most of the time.
Clearly, the performance gain that we can benefit from the availability of bN data is case-dependent.
On CIFAR-10, the greatest improvement is achieved when we regard mammals (i.e. cat, deer, dog
and horse) as P class and drawn samples from latent categories bird and frog as labeled negative
data. This is not surprising because birds and frogs are more similar to mammals than vehicles,
which makes the classification harder specifically for samples from these two latent categories. By
explicitly labeling these samples as N data, we allow the classifier to make better predictions for
these difficult samples.
4.3	The Presence of bN Data Helps: An Illustration
Through experiments we have demonstrated that the presence of bN data effectively helps learning
a better classifier. Here we would like to provide some intuition for the reason behind this. Let us
consider the MNIST learning task where XbN is uniformly sampled from the latent categories 1, 3
and 5. We project the representations learned by the classifier (i.e., the activation values of the last
layer of the neural network) into a 2D plane using PCA for both nnPU and PUbN algorithms.
8
Under review as a conference paper at ICLR 2019
⑶ nnPU
(b) PUbN
Figure 1: PCA embeddings of the representations learned by the nnPU and PUbN classifiers for 500
samples from the test set in the MNIST learning task where Xbn is uniformly sampled from latent
categories 1, 3 and 5.
The results are shown in Figure 1. Since for both nnPU and PUbN classifiers, the first two principal
components account around 90% of variance, we believe that this figure depicts fairly well the
learned representations. Thanks to the use of bN data, in the high-level feature space 1, 3, 5 and P
data are further pushed away when we employ the proposed PUbN learning algorithm, and we are
always able to separate 7, 9 from P to some extent. This explains the better performance which is
achieved by PUbN learning and the benefit of incorporating bN data into the learning process.
5	Conclusion
This paper studied the PUbN classification problem, where a binary classifier is trained on P, U
and bN data. The proposed method is a two-step approach inspired from both PU learning and
importance weighting. The key idea is to attribute appropriate weights to each example to evaluate
the classification risk using the three sets of data. We theoretically established an estimation error
bound for the proposed risk estimator and experimentally showed that our approach successfully
leveraged bN data to improve the classification performance on several real-world datasets. A variant
of our algorithm was able to achieve state-of-the-art results in PU learning.
References
P. L. Bartlett and S. Mendelson. Rademacher and gaussian complexities: Risk bounds and structural
results. Journal ofMachine Learning Research, 3(Nov):463-482, 2002.
M. Belkin, P. Niyogi, and V. Sindhwani. Manifold regularization: A geometric framework for
learning from labeled and unlabeled examples. Journal of Machine Learning Research, 7(Nov):
2399-2434, 2006.
O. Chapelle, B. Schlkopf, and A. Zien. Semi-Supervised Learning. The MIT Press, 1st edition,
2010.
M. du Plessis, G. Niu, and M. Sugiyama. Convex formulation for learning from positive and unla-
beled data. In International Conference on Machine Learning (ICML), pp. 1386-1394, 2015.
M. C. du Plessis, G. Niu, and M. Sugiyama. Analysis of learning from positive and unlabeled data.
In Advances in Neural Information Processing Systems (NIPS), pp. 703-711, 2014.
M. C. du Plessis, G. Niu, and M. Sugiyama. Class-prior estimation for learning from positive and
unlabeled data. Maching Learning, 106(4):463-492, April 2017. ISSN 0885-6125.
C. Elkan and K. Noto. Learning classifiers from only positive and unlabeled data. In KDD, 2008.
G. Fei and B. Liu. Social media text classification under negative covariate shift. In Proceedings
of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 2347-2356,
2015.
9
Under review as a conference paper at ICLR 2019
G. P. C. Fung, J. X. Yu, H. Lu, and P. S. Yu. Text classification without negative examples revisit.
IEEE transactions on Knowledge and Data Engineering,18(1):6-20, 2006.
N. Golowich, A. Rakhlin, and O. Shamir. Size-independent sample complexity of neural networks.
In Conference On Learning Theory, pp. 297-299, 2018.
Y. Grandvalet and Y. Bengio. Semi-supervised learning by entropy minimization. In Advances in
Neural Information Processing Systems (NIPS), pp. 529-536, 2005.
K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. In European
Conference on Computer Vision (ECCV), pp. 630-645. Springer, 2016.
J. J. Heckman. Sample selection bias as a specification error. Econometrica, 47(1):153-161, 1979.
S.	Hido, Y. Tsuboi, H. Kashima, M. Sugiyama, and T. Kanamori. Inlier-based outlier detection via
direct density ratio estimation. In Proceedings of IEEE International Conference on Data Mining
(ICDM), pp. 223-232. IEEE, 2008.
W. Hu, G. Niu, I. Sato, and M. Sugiyama. Does distributionally robust supervised learning give
robust classifiers? In International Conference on Machine Learning (ICML), pp. 2034-2042,
2018.
J. Huang, A. Gretton, K. M. Borgwardt, B. Scholkopf, and A. J. Smola. Correcting sample selection
bias by unlabeled data. In Advances in Neural Information Processing Systems (NIPS), pp. 601-
608, 2007.
T.	Ishida, G. Niu, and M. Sugiyama. Binary classification from positive-confidence data. arXiv
preprint arXiv:1710.07138, 2018.
S.	Jain, M. White, and P. Radivojac. Estimating the class prior and posterior from noisy positives and
unlabeled data. In Advances in Neural Information Processing Systems (NIPS), pp. 2693-2701,
2016.
T.	Kanamori, S. Hido, and M. Sugiyama. A least-squares approach to direct importance estimation.
Journal of Machine Learning Research, 10:1391-1445, 2009.
R.	Kiryo, G. Niu, M. C. du Plessis, and M. Sugiyama. Positive-unlabeled learning with non-negative
risk estimator. In Advances in Neural Information Processing Systems (NIPS), pp. 1675-1685,
2017.
S.	Laine and T. Aila. Temporal ensembling for semi-supervised learning. In International Confer-
ence on Learning Representations (ICLR), 2017.
W. Li, Q. Guo, and C. Elkan. A positive and unlabeled learning algorithm for one-class classification
of remote-sensing data. IEEE Transactions on Geoscience and Remote Sensing, 49(2):717-725,
2011.
X.-L. Li, B. Liu, and S.-K. Ng. Negative training data can be harmful to text classification. In
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pp.
218-228, 2010.
B.	Liu, W. S. Lee, P. S. Yu, and X. Li. Partially supervised classification of text documents. In
International Conference on Machine Learning (ICML), volume 2, pp. 387-394, 2002.
B.	Liu, Y. Dai, X. Li, W. S. Lee, and P. S. Yu. Building text classifiers using positive and unlabeled
examples. In Proceedings of IEEE International Conference on Data Mining (ICDM), pp. 179-
186. IEEE, 2003.
T. Miyato, S.-i. Maeda, M. Koyama, K. Nakae, and S. Ishii. Distributional smoothing with virtual
adversairal training. In International Conference on Learning Representations (ICLR), 2016.
M. Mohri, A. Rostamizadeh, and A. Talwalkar. Foundations of machine learning. MIT press, 2012.
F. Mordelet and J.-P. Vert. A bagging svm to learn from positive and unlabeled examples. Pattern
Recognition Letters, 37:201-209, 2014.
10
Under review as a conference paper at ICLR 2019
M. N. Nguyen, X.-L. Li, and S.-K. Ng. Positive unlabeled leaning for time series classification. In
IJCAI, volume 11,pp.1421-1426, 2011.
A. Oliver, A. Odena, C. Raffel, E. D. Cubuk, and I. J. Goodfellow. Realistic evaluation of deep
semi-supervised learning algorithms. arXiv preprint arXiv:1804.09170, 2018.
M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer. Deep
contextualized word representations. In Proc. of NAACL, 2018.
J. Quionero-Candela, M. Sugiyama, A. Schwaighofer, and N. D. Lawrence. Dataset shift in machine
learning. 2009.
H. Ramaswamy, C. Scott, and A. Tewari. Mixture proportion estimation via kernel embeddings of
distributions. In International Conference on Machine Learning (ICML), pp. 2052-2060, 2016.
S.	J. Reddi, S. Kale, and S. Kumar. On the convergence of adam and beyond. In International
Conference on Learning Representations (ICLR), 2018.
A. Ruckle, S. Eger, M. Peyrard, and I. Gurevych. Concatenated -mean word embeddings as universal
cross-lingual sentence representations. arXiv preprint arXiv:1803.01400, 2018.
T.	Sakai, M. C. d. du Plessis, G. Niu, and M. Sugiyama. Semi-supervised classification based on
classification from positive and unlabeled data. In International Conference on Machine Learning
(ICML), volume 70, pp. 2998-3006, 2017.
C.	Scott and G. Blanchard. Novelty detection: Unlabeled data definitely help. In Artificial Intelli-
gence and Statistics, pp. 464-471, 2009.
S.	Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to Algo-
rithms. Cambridge University Press, 2014.
H. Shimodaira. Improving predictive inference under covariate shift by weighting the log-likelihood
function. Journal of statistical planning and inference, 90(2):227-244, 2000.
M. Sugiyama and M. Kawanabe. Machine Learning in Non-Stationary Environments: Introduction
to Covariate Shift Adaptation. MIT Press, Cambridge, Massachusetts, USA, 2012.
M. Sugiyama and A. J. Storkey. Mixture regression for covariate shift. In Advances in Neural
Information Processing Systems (NIPS), pp. 1337-1344, 2007.
M. Sugiyama, S. Nakajima, H. Kashima, P. V. Buenau, and M. Kawanabe. Direct importance
estimation with model selection and its application to covariate shift adaptation. In Advances in
Neural Information Processing Systems (NIPS), pp. 1433-1440, 2008.
G. A. Ward, T. J. Hastie, S. T. Barry, J. Elith, and J. R. Leathwick. Presence-only data and the em
algorithm. Biometrics, 65 2:554-63, 2009.
B. Zadrozny. Learning and evaluating classifiers under sample selection bias. In International
Conference on Machine learning (ICML), pp. 903-910, 2004.
T. Zhang. Statistical behavior and consistency of classification methods based on convex risk mini-
mization. Annals of Statistics, pp. 56-85, 2004.
M. Zuluaga, D. Hush, E. J F Delgado Leyton, M. Hernandez Hoyos, and M. Orkisz. Learning
from only positive and unlabeled data to detect lesions in vascular ct images. In Medical image
computing and computer-assisted intervention -MICCAI 2011, volume LNCS 6893, pp. 9-16,
2011.
11
Under review as a conference paper at ICLR 2019
Appendix
A Proofs
A.1 Proof of Theorem 1
We notice that (1 - π - ρ)p(x | s = -1) = p(x, s = -1) and that when h(x) > η, we have
p(s = +1 | x) = σ(x) > 0, which allows us to write p(s = -1 | x) = (p(s = -1 | x)/p(s =
+1 I x))P(S = +1 I x). We can thus decompose R-= -1(g) as following:
R -= -1( g) = / '(-g(X)) P(x,s
-1) dx
/ h(-x(X)≤r∣ '(-g(x))P(x,s = - 1) dx
/ Ih(x)>η '(-g(x))P(x,s
-1) dx
/lh(X)≤η '(-g(x))p(x,ps( =) - 1)p(x) dx
TM X x> ` (-g (x)) PXs=+1)p (x，s
+1) dx.
By writing P(x, s = -1) = P(s = -1 I x)P(x) = (1 - σ(x))P(x) and P(x, s = +1) = P(s
+1 I x)P(x) = σ(x)P(x), we have
R-= -1(g) = / Ih(X)≤r∣ '(-g(x))(1 — σ(x))p(x) dx
1 - σ(x)
h(x(X)>η '(-g(x)) σ(x) P(x, S = +1) dx.
We obtain Equation (6) after replacing P(x, s = +1) by πP(x I y = +1)+ρP(x I y = -1, s = +1).
A.2 Proof of Theorem 2
For σ and η given, let us define
RPUbN ,η,σ (g) = nR +(g) + PR-N( g) + R S= -1 ,η,σ (g).
The following lemma establishes the uniform deviation bound from RPUbN,η,σ to RPUbN,η,σ.
Lemma 1. Let σ^ : Rd → [0,1] be a fixed function independent of data used to compute RPUbN ,η,σ
and η ∈ (0, 1]. For any δ > 0, with probability at least 1 - δ,
ʌ
sup 1RPUbN,η,σ(g) - RPUbN,η,σ (g)1
g∈G
≤ 2LlRnU,p(G) +
Π~~r R n P ,p P ( G ) + P-R R n bN，P bN (G )
lh(^6/δ )
+ C∖
+ ∏Ci ∣∖n(6/) + ρC ∣∖n(6/δ)
η V 2 n P	η V 2 nbN
Proof. For ease of notation, let
+
12
Under review as a conference paper at ICLR 2019
R P( g ) = E X〜P p( x)
.......................  1	— σ( x)
'(g(x)) + 1"X)>η '(—g(x)) σ(x)
RbN( g ) = E X〜P bN( X)
'(—g(x))(1 + ^xX)>η —Cj))
σ(x)
Ru(g) = EX〜P(X) [ 1^(X)≤η '(—g(x))(1 — σ(x))],
ʌ
RP(g )
nP X '(g(xP)) + %xp)>η '(—g(xP)) σ(x(P)i)
RbN(g) = n⅛ X ['(—g(xbN))(1 + 1%XbN)>η 1 —(xNb ))
1 nU
Ru(g) = nU £ [ι,( xU) ≤η '(-g (xuy)(1—σ( xuy)].
U i=1
From the sub-additivity of the supremum operator, we have
ʌ
SUP 1RPUbN η σ(g) — RPUbN,η,σ(g) |
g∈G
ʌ ʌ ʌ
≤ πsuP |RP(g) — RP(g)| +ρsuP |RbN(g) — RbN(g)| + suP |RU(g) — RU(g)|.
g∈G	g∈G	g∈G
As a consequence, to conclude the proof, it suffices to prove that with probability at least 1 — δ/3,
the following bounds hold separately:
ʌ
sup RP(g) — Rp(g) |
g∈G
ʌ
sup |RbN(g) — RbN(g)|
g∈G
ʌ
sup |RU(g) — RU(g)|
g∈G
2L小(0—Cl ∕ln(6/)
T R n P,P P(G) + ηv Pn^,
2Ll R (G) + C ∣ln(6/δ)
η RnbN,bN(G)+ η V 2nbN ,
2LlRnu,p(G) + Cl Ssln≡).
2nU
(8)
(9)
(10)
Below we prove (8). (9) and (10) are proven similarly.
Let Φx : R → R+ be the function defined by Φx : ν → '(Z) + lσ(X)>η '(—z)((1 — σ(x))/σ(x)).
For x ∈ Rd,g ∈ G, since '(g(x)) ∈ [0,Cl], '(—g(x)) ∈ [0,Cl] and 1^(X>((1 — σ(x))/σ(x)) ∈
[0, (1 — η)/η], We always have Φx (g(x)) ∈ [0, Cl∕η]. Following the proof of Theorem 3.1 in Mohri
et al. (2012), it is then straightforward to show that with probability at least 1 — δ/3, it holds that
ʌ
IuP|RP(g)— rp(g)κ 2底P PnP
nP
Eθ SuP 」 相 θiφxi (g(xi))
g∈G nP	i
i=1
∕ln(6/δ)
V 2 n P
≤
≤
≤
+ C
where θ = {θ1, . . . , θnP} and each θi is a Rademacher variable.
Also notice that for all x, φχ is a (Ll/η)-Lipschitz function on the interval [-Cg, Cg]. By using a
modified version of Talagrad’s concentration lemma (specifically, Lemma 26.9 in Shalev-Shwartz
& Ben-David (2014)), we can show that, when the set XP is fixed, we have
Eθ
1 nP
SUP — E θiφχi (g(Xi))
g∈G nP i=1	i
≤ T EE
1 nP
SUP-y^θig(xi) .
g∈G nP i=1
After taking expectation over XP 〜Pnp, we obtain the Equation (8).
□
13
Under review as a conference paper at ICLR 2019
However, what we really want to minimize is the true risk R(g). Therefore, we also need to
bound the difference between RPUbN η ^(g) and R(g), or equivalently, the difference between
R-= -1,η,σ(g) and R-= -ι(g).	''
Lemma 2. Let σ : Rd → [0, 1], η ∈ (0, 1], Z = p(σ ≤ η) and E = Ex〜P(X)[∣σ(x) — σ(x)12]. For
all g ∈ G, it holds that
∣R^--= -1 ,η,σ(g) — R-= -1(g) ∣ ≤ Cl Pe + 三 P(I-Z) J
Proof. One one hand, we have
R-= -1(g) = / 1^(x)≤r∣ '(—g(x))(1 — σ(x))P(x) dx
|
}
{	{z	"
A1
+ / lσ(x)>η '(—g(x))(1 — σ(x))p(x) dx .
|
{z
B1
}
On the other hand, we can express R-=-1 η ^ (g) as
RS= -1 ,η,σ(g) = / 1^(x)≤η '(—g(X))(1 — σ(x))P(X) dx
1 — σ( x)
1^(x)>η '(—g(x)) σ(X) 'P(x,s = +1) dx.
=/ 1^(x)≤r∣ '(—g(x))(1 — σ(x))p(x) dx
|
{z
A2
}
σ(x)
+ J 1^(x)>η '(—g(X))(1 — σ(x))σ(x)P(x) dx .
|
{z
B2
}
The last equality follows from the fact P(x, s = +1) = σ(x)P(x). As ∣R-=-1n育(g)—
R-= -1(g) ∣ ≤ ∣A 1 — A21 + ∣B 1 — B21, it is sufficient to derive bounds for ∣A 1 — A21 and ∣B 1 — B21
separately. For ∣B1 — B2 ∣, we write
∣B 1 — B21 ≤ / 1^(x)>η '(-g(X))
工 η/ ”σ(x)>η ∣σ(X) ■
∣σ(χ) — σ (χ) ∣
σ(x)
p(x) dx
— σ(x)∣p(x) dx
2^(x)>ηp(x) d
1
∖ 2
∣σ(x) — σ(x) ∣2p(x) dx I
C PTzZl
From the second to the third line We use the CaUchy-SchWarz inequality. ∣Aι — A21 ≤ Cι√ζe can
be proven similarly, which concludes the proof.	□
Combining lemma 1 and lemma 2, we know that with probability at least 1 — δ, the following holds:
14
Under review as a conference paper at ICLR 2019
ʌ
sup IRPUbN,η,σ(g) - R(g)|
g∈G
≤ 2LlRnU,P (G) +	JRnP,PP (G) + -P~^RRnbN,PbN (G)
+ClS 三+∏c SM+g Sg+Cl Pl+C P^
W 2 nU	η y 2 nP	η ʌ/ 2 nbN	η VV 力
Finally, with probability at least 1 -δ,
R(OρυbN,%σ) - R(g*)
ʌ
=(R(gPUbN,n,σ) - RPUbN,η,σ(gPUbN,η,σ))
ʌ ʌ ʌ
十 (RPUbN,η,σ(gPUbN,η,σ) - RPUbN,η,σ(g)) + (RPUbN,η,σ(g) - R(g))
ʌ ʌ
≤ sup 1RPUbNησ(g) - R(g)| +0 + sup 1RPUbNη,σ(g) - R(g)|
g∈G	g∈G
≤ 4LlRnUP (G) + 丁RnP,PP (G) + 亍RnbN,PbN (G)
+ 2Cls 三 +凹S 三 +凶S 三 +2 Cl Pe +亚 pΓ-Z∑
∖∣ 2 n U η y	2 n P	η V 2 n bN	η''	"
The first inequality uses the definition of ^PUbN,n,σ.
B VALIDATION LOSS FOR ESTIMATION OF σ
In terms of validation We want to choose the model for σ such that Jɔ( σ) = E χ^p( X)[ ∣σ( x)-σ (x) 12]
is minimized. Since σ(x)p(x) = p(x, s = +1), we have
J0( σ) = /
(σ(x) — σ(x))2P(x) dx
∕x)x)2p(X) dX - 2 / σ(X)p(x, S = +1) d + / σ(X)2p(X) dx
The last term does not depend on σ and can be ignored if we want to identify σ achieving the smallest
J(σ). We denote by J(σ) the sum of the first two terms. The middle term can be further expanded
using
J σ(x)p(x, S = +1) dx = π J σ(x)P(x ∣ y = +1) dx + Pj σ(x)P(x ∣ y = — 1, S = +1) dx.
The validation loss of an estimation σ is then defined as
nU	nP	nbN
J( σ) = ⅛ ∑σ( xU)2 - 2∏∑σ( xP) —・ ∑σ( XbN).
nU	nP	nbN
i=1	i=1	i=1
It is also possible to minimize this value directly to acquire σ. In our experiments we decide to learn
σ by nnPU for a better comparison between different methods.
C Detailed Experimental Setting
C.1 From Multiclass to B inary Class
In the experiments we work on multiclass classification datasets. Therefore it is necessary to define
the P and N classes ourselves. MNIST is processed in such a way that pair numbers 0, 2, 4, 6, 8 form
15
Under review as a conference paper at ICLR 2019
the P class and impair numbers 1, 3, 5, 7, 9 form the N class. Accordingly, π = 0.49. For CIFAR-10,
we consider two definitions of the P class. The first one corresponds to a quite natural task that aims
to distinguish vehicles from animals. Airplane, automobile, ship and truck are therefore defined
to be the P class while the N class is formed by bird, cat, deer, dog, frog and horse. For the sake
of diversity, we also study another task in which we attempt to distinguish the mammals from the
non-mammals. The P class is then formed by cat, deer, dog, and horse while the N class consists of
the other six classes. We have π = 0.4 in the two cases. As for 20 Newsgroups, alt., comp., misc.
and rec. make up the P class whereas sci., soc. and talk. make up the N class. This gives π = 0.56.
C.2 Training, Validation and Test Set
For the three datasets, we use the standard test examples as a held-out test set. The test set size is
thus of 10000 for MNIST and CIFAR-10, and 7528 for 20 Newsgroups. Regarding the training set,
we sample 500, 500 and 6000 P, bN and U training examples for MNIST and 20 Newsgroups, and
1000, 1000 and 10000 P, bN and U training examples for CIFAR-10. The validation set is always
five times smaller than the training set.
C.3 20 Newsgroups Preprocessing
The original 20 Newsgroups dataset contains raw text data and needs to be preprocessed into text
feature vectors for classification. In our experiments we borrow the pre-trained ELMo word embed-
ding (Peters et al., 2018) from https://allennlp.org/elmo. The used 5.5B model was, according to
the website, trained on a dataset of 5.5B tokens consisting of Wikipedia (1.9B) and all of the mono-
lingual news crawl data from WMT 2008-2012 (3.6B). For each word, we concatenate the features
from the three layers of the ELMo model, and for each document, as suggested in Ruckle et al.
(2018), we concatenate the average, minimum, and maximum computed along the word dimension.
This results in a 9216-dimensional feature vector for a single document.
C.4 Models and Hyperparameters
MNIST For MNIST, we use a standard ConvNet with ReLU. This model contains two 5x5 convo-
lutional layers and one fully-connected layer, with each convolutional layer followed by a 2x2 max
pooling. The channel sizes are 5-10-40. The model is trained for 100 epochs with a weight decay of
10-4 . Each minibatch is made up of 10 P, 10 bN (if available) and 120 U samples. The learning rate
α ∈ {10-2, 10-3} and τ ∈ {0.5, 0.7, 0.9}, γ ∈ {0.1, 0.3, 0.5, 0.7, 0.9} are selected with validation
data.
CIFAR-10 For CIFAR-10, we train PreAct ResNet-18 (He et al., 2016) for 200 epochs and the
learning rate is divided by 10 after 80 epochs and 120 epochs. This is a common practice and similar
adjustment can be found in He et al. (2016). The weight decay is set to 10-4. The minibatch size is
1/100 of the number of training samples, and the initial learning rate is chosen from {10-2 , 10-3}.
We also have τ ∈ {0.5, 0.7, 0.9} and γ ∈ {0.1, 0.3, 0.5, 0.7, 0.9}.
20 Newsgroups For 20 Newsgroups, with the extracted features, we simply train a multilayer per-
ceptron with two hidden layers of 300 neurons for 50 epochs. We use basically the same hyperpa-
rameters as for MNIST except that the learning rate α is selected from {5 ∙ 10—3, 10—3, 5 ∙ 10—4 }.
D Additional Experiments
D.1 WHY DOES PUBN\N OUTPERFORM NNPU ?
Our method, specifically designed for PUbN learning, naturally outperforms other baseline methods
in this problem. Nonetheless, Table 1 equally shows that the proposed method when applied to PU
learning, achieves significantly better performance than the state-of-the-art nnPU algorithm. Here
we numerically investigate the reason behind this phenomenon.
Besides nnPU and PUbN\N, we compare with unbiased PU (uPU) learning (2). Both uPU and
nnPU are learned with the sigmoid loss, learning rate 10-3 for MNIST, initial learning rate 10-4 for
CIFAR-10, and learning rate 10-4 for 20 Newsgroups. This is because uPU learning is unstable with
16
Under review as a conference paper at ICLR 2019
O 20	40	60	80	100
Epoch
(a) MNIST
0	50	100	150	200
Epoch
(b) CIFAR-10, vehicles as P class
(c) CIFAR-10, mammals as P class
(d) 20 Newsgroups
Figure 2: Comparison of uPU, nnPU and PUbN\N over the four PU learning tasks. For each task,
means and standard deviations are computed based on the same 10 random samplings. Dashed lines
indicate the corresponding values of the final classifiers (recall that at the end we select the model
with the lowest validation loss out of all epochs).
the logistic loss. The other parts of the experiments remain unchanged. On the test sets we compute
the false positive rates, false negative rates and misclassification errors for the three methods and
plot them in Figure 2. We first notice that PUbN\N still outperforms nnPU trained with the sigmoid
loss. In fact, the final performance of the nnPU classifier does not change much when we replace
the logistic loss with the sigmoid loss.
In Kiryo et al. (2017), the authors observed that uPU overfits training data with the risk going to
negative. In other words, a large portion of U samples are classified to the N class. This is confirmed
in our experiments by an increase of false negative rate and decrease of false positive rate. nnPU
remedies the problem by introducing the non-negative risk estimator (3). While the non-negative
correction successfully prevents false negative rate from going up, it also causes more N samples
to be classified as P compared to uPU. However, since the gain in terms of false negative rate is
enormous, at the end nnPU achieves a lower misclassification error. By further identifying possible
N samples after nnPU learning, we expect that our algorithm can yield lower false positive rate than
17
Under review as a conference paper at ICLR 2019
nnPU without misclassifying too many P samples as N as in the case of uPU. Figure 2 suggests that
this is effectively the case. In particular, we observe that on MNIST, our method achieves the same
false positive rate than uPU whereas its false negative rate is comparable to nnPU.
D.2 INFLUENCE OF η AND ρ
In the proposed algorithm We introduce η to control how RS=-1(g) is approximated from data and
assume that ρ = p(y = -1, s = +1) is given. Here we conduct experiments to see how our method
is affected by these two factors. To assess the influence of η, from Table 1 we pick four learning
tasks and we choose τ from {0.5, 0.7, 0.9, 2} while all the other hyperparameters are fixed. Similarly
to simulate the case where ρ is misspecified, we replace it by ρ0 ∈ {0.8ρ, ρ, 1.2ρ} in our learning
method and run experiments with all hyperparameters being fixed to a certain value. However, we
still use the true ρ to compute η from τ to ensure that we always use the same number ofU samples
in the second step of the algorithm independent of the choice of ρ0.
The results are reported in Table 2 and Table 3. We can see that the performance of the algorithm
is sensitive to the choice of τ . With larger value of τ , more U data are treated as N data in PUbN
learning, and consequently it often leads to higher false negative rate and lower false positive rate.
The trade-off between these two measures is a classic problem in binary classification. In particular,
when τ = 2, a lot more U samples are involved in the computation of the PUbN risk (7), but
this does not allow the classifier to achieve a better performance. We also observe that there is a
positive correlation between the misclassification rate and the validation loss, which confirms that
the optimal value of η can be chosen without need of unbiased N data.
Table 3 shows that in general slight misspecification of ρ does not cause obvious degradation of the
classification performance. In fact, misspecification of ρ mainly affect the weights of each sample
when we compute RPUbN,η,^ (due to the direct presence of P in (7) and influence on estimating
σ). However, as long as the variation of these weights remain in a reasonable range, the learning
algorithm should yield classifiers with similar performances.
D.3 ESTIMATING σ FROM S EPARATE DATA
Theorem 2 suggests that σ should be independent from the data used to compute RpubN,η,σ. There-
fore, here we investigate the performance of our algorithm when σ and g are optimized using dif-
ferent sets of data. We sample two training sets and two validation sets in such a way that they are
all disjoint. The size of a single training set and a single validation set is as indicated in Appendix
C.2, except for 20 Newsgroups we reduce the number of examples in a single set by half. We then
use different pairs of training and validation sets to learn σ and g. For 20 Newsgroups we also
conduct standard experiments where σ and g are learned on the same data, whereas for MNIST and
CIFAR-10 we resort to Table 1.
The results are presented in Table 4. Estimating σ from separate data does not seem to benefit much
the final classification performance, despite the fact that it requires collecting twice more samples.
In fact, R-=-1 η ^ (g) is a good approximation of RS=-1 “ ^ (g) as long as the function σ is smooth
enough and does not possess abrupt changes between data points. With the use of non-negative
correction, validation data and L2 regularization, the resulting σ does not overfit training data so this
should always be the case. As a consequence, even if σ and g are learned on the same data, we are
still able to achieve small generalization error with sufficient number of samples.
D.4 Alternative Definition of nnPNU
In subsection 2.3, we define the nnPNU algorithm by forcing the estimator of the whole N partial
ʌ
risk to be positive. However, notice that the term γ(1 - π)RN-(g) is always positive and the chances
are that including it simply makes non-negative correction weaker and is thus harmful to the final
classification performance. Therefore, here we consider an alternative definition of nnPNU where
ʌ ʌ
we only force the term (1 - γ)(RU- (g) - πRP- (g)) to be positive. We plug the resulting algorithm
in the experiments of subsection 4.2 and summarize the results in Table 5 in which we denote the
alternative version of nnPNU by nnPU+PN since it uses the same non-negative correction as nnPU.
The table indicates that neither of the two definitions of nnPNU consistently outperforms the other.
18
Under review as a conference paper at ICLR 2019
Table 2: Results on four different PUbN learning tasks when we vary the value ofτ (and accordingly,
η). Reported are means of false positive rates (FPR), false negative rates (FNR), misclassification
rates (Error), and validation losses (VLoss) over 10 trials.
Dataset	P	biased N	τ	FPR	FNR	Error	VLoss
			0.5	4.79	4.32	4.56	10.11
MNIST	2, 4, 6, 8, 10	1,3,5	0.7 0.9	3.32 3.29	4.81 4.40	4.05 3.83	9.15 9.30
			2	3.38	5.32	4.33	10.68
	Airplane, automobile, ship, truck		0.5	8.31	12.35	9.92	12.50
CIFAR-10		Horse > deer = frog > others	0.7 0.9	8.23 7.54	13.15 14.68	10.20 10.40	12.62 13.08
			2	6.23	20.29	11.85	13.64
			0.5	14.45	27.57	19.70	22.08
CIFAR-10	Cat, deer, dog, horse	Bird, frog	0.7 0.9	13.20 13.00	27.27 32.61	18.83 20.84	20.72 23.78
			2	11.67	31.49	19.60	22.52
			0.5	11.28	12.90	12.18	16.04
20 Newsgroups	alt., comp., misc., rec.	soc. > talk. > sci.	0.7 0.9	11.40 10.09	13.58 16.70	12.62 13.79	16.64 16.90
			2	10.34	20.55	16.06	20.99
Table 3: Mean and standard deviation of misclassification rates over 10 trials on different PUbN
learning tasks when we replace ρ by ρ0 ∈ {0.8ρ, ρ, 1.2ρ}. Underlines indicate significant degrada-
tion of performance according to the 5% t-test.
Dataset	P	biased N		p /P	
			0.8	1	1.2
					
MNIST	2, 4, 6, 8, 10	1,3,5	4.10 ± 0.39	4.05 ± 0.27	4.14 ± 0.45
		9 > 5 > others	3.85 ± 0.55	3.91 ± 0.66	3.94 ± 0.54
	Airplane,	Cat, dog, horse	10.23 ± 0.59	9.71 ± 0.51	10.32 ± 0.57
CIFAR-10	automobile, ship, truck	Horse > deer = frog > others	10.18 ± 0.40	9.92 ± 0.42	10.05 ± 0.59
CIFAR-10	Cat, deer, dog,	Bird, frog	18.94 ± 0.50	18.83 ± 0.71	19.06 ± 0.80
	horse	Car, truck	20.39 ± 1.24	20.19 ± 1.06	19.92 ± 0.89
	alt., comp., misc., rec.	sci.	13.49 ± 0.61	13.10 ± 0.90	13.31 ± 1.05
20 Newsgroups		talk.	12.64 ± 0.69	12.61 ± 0.75	13.77 ± 0.85
		soc. > talk. > sci.	12.90 ± 0.79	12.18 ± 0.59	12.74 ± 0.35
It also ensures that there is always a clear superiority of our proposed PUbN algorithm compared to
nnPNU despite its possible variant that is considered here.
19
Under review as a conference paper at ICLR 2019
Table 4: Mean and standard deviation of misclassification rates over 10 trials on different PUbN
learning tasks with σ and g trained using either the same or different sets of data.
Dataset	P	biased N	Data for σ and g	
			Same	Different
MNIST	2, 4, 6, 8, 10	1,3,5 9 > 5 > others	4.05 ± 0.27 3.91 ± 0.66	3.71 ± 0.45 4.06 ± 0.36
CIFAR-10	Airplane, automobile, ship, truck	Cat, dog, horse Horse > deer = frog > others	9.71 ± 0.51 9.92 ± 0.42	10.00 ± 0.51 9.66 ± 0.46
CIFAR-10	Cat, deer, dog, horse	Bird, frog Car, truck	18.83 ± 0.71 20.19 ± 1.06	18.52 ± 0.70 19.98 ± 0.93
20 Newsgroups	alt., comp., misc., rec.	sci. talk. soc. > talk. > sci.	15.61 ± 1.50 17.14 ± 1.87 15.93 ± 1.88	16.60 ± 2.38 15.80 ± 0.95 15.80 ± 1.91
Table 5: Mean and standard deviation of misclassification rates over 10 trials on different PUbN learning tasks for the two possible definitions of the nnPNU algorithm.				
Dataset	P	biased N	nnPNU	nnPU + PN
MNIST	2, 4, 6, 8, 10	1,3,5 9 > 5 > others	5.33 ± 0.97 4.60 ± 0.65	5.68 ± 0.78 5.10 ± 1.54
CIFAR-10	Airplane, automobile, ship, truck	Cat, dog, horse Horse > deer = frog > others	10.25 ± 0.38 9.98 ± 0.53	10.87 ± 0.62 10.77 ± 0.65
CIFAR-10	Cat, deer, dog, horse	Bird, frog Car, truck	22.00 ± 0.53 22.00 ± 0.74	21.41 ± 1.01 21.80 ± 0.74
20 Newsgroups	alt., comp., misc., rec.	sci. talk. soc. > talk. > sci.	14.69 ± 0.46 14.38 ± 0.74 14.41 ± 0.70	14.50 ± 1.32 14.71 ± 1.01 13.66 ± 0.72
20