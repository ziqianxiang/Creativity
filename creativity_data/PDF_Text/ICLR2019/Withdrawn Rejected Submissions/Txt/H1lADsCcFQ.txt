Under review as a conference paper at ICLR 2019

LEARNING  ADVERSARIAL  EXAMPLES  WITH  RIEMAN-

NIAN  GEOMETRY

Anonymous authors

Paper under double-blind review

ABSTRACT

Adversarial examples, referred to as augmented data points generated by imper-
ceptible perturbation of input samples, have recently drawn much attention. Well-
crafted  adversarial  examples  may  even  mislead  state-of-the-art  deep  models  to
make wrong predictions easily.  To alleviate this problem, many studies focus on
investigating how adversarial examples can be generated and/or resisted.  All the
existing work handles this problem in the Euclidean space, which may however be
unable to describe data geometry.  In this paper, we propose a generalized frame-
work that addresses the learning problem of adversarial examples with Riemanni-
an geometry. Specifically, we define the local coordinate systems on Riemannian
manifold,  develop a novel model called Adversarial Training with Riemannian
Manifold, and design a series of theory that manages to learn the adversarial ex-
amples in the Riemannian space feasibly and efficiently.  The proposed work is
important in that (1) it is a generalized learning methodology since Riemmanian
manifold space would be degraded to the Euclidean space in a special case; (2) it
is    the first work to tackle the adversarial example problem tractably through the
perspective of geometry; (3) from the perspective of geometry, our method leads
to the steepest direction of the loss function.   We also provide a series of the-
ory showing that our proposed method can truly find the decent direction for the
loss function with a comparable computational time against traditional adversarial
methods. Finally, the proposed framework demonstrates superior performance to
the traditional counterpart methods on benchmark data including MNIST, CIFAR-
10 and SVHN.

1    INTRODUCTION

Recently  Deep  Neural  Networks  (DNN)  achieve  a  big  success  on  a  wide  range  of  
challenge-
able  tasks,  such  as  image  classification,  speech  recognition,  and  object  detection  
(LeCun et al.,
2015)(He et al.,  2017).    However,  recent  studies  have  found  that  DNNs  can  be  easily  
fooled
by  some  special  input  called  adversarial  examples  which  are  referred  to  as  augmented  
data
points generated by imperceptible perturbation of input samples (Szegedy et al., 2013)(Biggio et 
al.,
2013)(Nguyen et al., 2015). Although such perturbation is visually imperceptible, it can lead DNNs
to         make incorrect predictions with high confidence.

There have been a lot of proposals studying how to generate more powerful adversarial examples,
and how to build up robust networks to defend them (Goodfellow et al., 2014)(Szegedy et al., 2013).
This interesting problem was first studied in (Liu & Nocedal, 1989) where the authors proposed a
simple way to produce adversarial examples with L-BFGS optimization. A more powerful approach
Fast Gradient Sign Method (FGSM) is later proposed in (Goodfellow et al., 2014) and further ex-
tended to a more general case with lp  constraint for perturbation (Lyu et al., 2015)(Shaham et al.,
2015).  The multi-step variant FGSMᵏ  was proposed in (Kurakin et al., 2016) which is essentially
projected gradient decent (PGD) on the negative loss. Aside from studying how to generate adversar-
ial examples, some researchers developed methods to defend them. The adversarial training was pro-
posed by (Goodfellow et al., 2014) (Lyu et al., 2015) which augmented the training set with adver-
sarial examples. This method not only increases the model robustness for adversarial examples but
also improves the generalization for benign samples.  Some feature squeezing (Xu et al., 2017) and
defensive distillation (Papernot et al., 2016) were also exploited to resist adversarial attacking. 
Semi-
supervised  version  of  adversarial  training  was  developed  in  (Miyato et al.,  2015)  (Miyato 
et al.,

1


Under review as a conference paper at ICLR 2019

2018) (Miyato et al., 2016) called Virtual Adversarial Training (VAT), where the output distribu-
tion was smoothed by penalizing the KL-divergence between outputs of original and adversarial
examples.   Moreover,  some researchers provided the theory and principles for adversarial exam-
ples (Fawzi et al., 2016).   Furthermore,   (Ma et al., 2018) have demonstrated that the adversarial
examples are a dense region of pixel space instead of isolated points.

All these existing adversarial training methods simply consider the adversarial example problem in
the Euclidean space with the orthogonal coordinate system. Specifically, this traditional 
adversarial
training methods aim to solve a robust optimization problem (Lyu et al., 2015):


min

θ

E₍ₓ,y₎~D[max L(x + ϵ, y, θ)]       s.t.             ∥ϵ∥p ≤ σ                              (1)

where     denotes a loss function and the pair of input and label (x, y) is assumed to be drawn from
the data distribution     .  The robust optimization problem is defined as a min-max problem with
respect to the worst perturbation ϵ and the best model parameters θ.  The adversarial perturbation
ϵ    is restricted within lp-ball around benign example x.  The FGSM can be seen as a special case
with p =     . Such restriction is defined in Euclidean space and the similarity between two points 
is
measured by Minkowski distance.

(a) Riemannian space                                        (b) Euclidean space

Figure 1:  1(a) shows a Riemanian space M , where ξ(t) is the geodesic connecting two points ξ(0)
and ξ(a).  The distance between these two points is measured by the geodesic distance g.  TpM  is
the tangent space of M  at point ξ(0) and ξˆ(t) represents the derivative of curve function ξ(t). 
1(b)
demonstrates the Euclidean space where the distance between two points is described by Euclidean
distance   d. Detailed notations can be seen in Section 2.

However, data points may be in practice attached on a geometric manifold which cannot be appro-
priately described with Euclidean coordinate system.  In this case, the Euclidean metric would be
not rational.  Moreover, existing adversarial training methods usually search the worst perturbation
through the gradient of loss function with respect to x, since the gradient is considered as the 
steepest
direction. However, in a geometric manifold, particularly in Riemannian space, the gradient of a 
loss
function unnecessarily presents the steepest direction.  Figure 1 illustrates the difference 
between a
Riemannian space and the Euclidean space, where the detailed mathematic notation can be seen in
Section  2.  Clearly, In this figure, assuming that the data are attached in the manifold as defined
in Figure 1(a), the Euclidean distance may not appropriately reflect the true distance between two
points (e.g., ξ(0) and ξ(a)).

In this paper, we extend the traditional adversarial problem to Riemannian space and propose a nov-
el adversarial method called Adversarial Training with Riemannian Manifold (ATRM). ATRM is
regarded as a generalized framework in that Riemannian space contains the Euclidean space as a
special case.  In more details, we start with defining the local coordinate system and Riemannian
metric tensor to evaluate the similarity between two points in Riemannian space.  We then propose
to restrict the adversarial perturbation within lp-ball around natural examples x on Riemannian man-
ifold, and develop a framework to search the worst perturbation through the generalized trust region
method. Our proposed method is to solve the adversarial problem from the perspective of geometry
which is similar to Natural Gradient methods (Amari, 1998), however, our method is implemented
on input space instead of parameter space of DNNs.

We list the main contributions of this paper as follows:  1) To our best knowledge, this is the 
first
work to tackle the adversarial example problem through the perspective of geometry.  2) We study
the adversarial example in the more generalized Riemannian space of which Euclidean space is a
special case.  3) Our method considers the curvature information of the loss function which can be
viewed as the second order method, enabling a more accurate direction of adversarial perturbation.
Importantly, from the perspective of geometry, our method leads to the steepest direction of loss

2


Under review as a conference paper at ICLR 2019

function in Riemannian space.  4) We also provide a series of theory showing that our proposed
method can truly find the decent direction for the loss function with a comparable computational
time against traditional adversarial method (one more backward backward prorogation).

2    MAIN  METHODOLOGY

In this section, we first study how to generate adversarial examples within l₂-ball in Riemannian
Manifold.   We  then  define  the  local  metric  tensor  on  the  manifold  and  generate  the  
adversarial
examples using our proposed ATRM with l₂-ball restriction. Next, we extend our proposed method
to lp-ball restriction on Riemannian manifold.  Finally, we propose the adversarial training method
called ATRM and also provide theories showing that ATRM can find the decent direction of the loss.

2.1    RIEMANNIAN GEOMETRY

In this subsection, we first introduce the mathematical notations and some background of geometry.
The Einstein notation is used in this subsection.  The Riemannian Manifold is defined as Defini-
tion 2.1:

Definition 2.1.  (Riemannian Manifold (Walschap, 2012)) In differential geometry, a Riemannian
manifold (M, g) is a real smooth manifold M equipped with inner product in tangent space TpM at
each point p varying smoothly on M , defined by positive definite metric tensor gp.

Theorem 2.1.  (Geodesic (Amari, 2016)) A curve that connects two points by a minimal distance is
a geodesic under the Levi-Civita connection, where the length of a curve c = ξ(t) connecting ξ(0)
and ξ(a) is given by

                          

l =            gij(t)ξ˙i(t)ξ˙j (t)  dt                                                      (2)

0

where gij(t) denotes the metric tensor at point ξ(t).

The geodesic can be calculated with Theorem 2.1, which measures the distance of two points on
Riemannian manifold. It can be seen as an extension of the Euclidian distance in Euclidian space.

Lemma 2.2.  Let ξ(0) and ξ(a) be two close points on Riemannian manifold, where ξ(t) is a shortest
curve connecting these two points.  Then, the distance between these two points can be computed
by:

ds² = gij(t)dθⁱdθʲ                                                                       (3)

where dθⁱ  = ξ˙(t)ⁱdt is the iᵗʰ  component of small vector dθ and gij(t) is the metric tensor 
(proof
can be seen in Appendix D).

We can also rewrite ds² in form of inner production:

ds² = ⟨dθⁱei, dθʲej⟩ = ⟨ei, ej⟩dθⁱdθʲ                                                      (4)

where basis vectors   ei    is the set of tangent vectors along the coordinate curves. Combining 
these
two equations, we have:

gij  = ⟨ei, ej⟩                                                                             (5)

Therefore, the metric tensor G = (gij) is the inner product of basis vectors. In the case of 
Euclidean
space (orthonormal coordinate system), the metric tensor is:


gij

= δij

1    i=j

0    otherwise

(6)

where δij  represents the Kronecker delta.  The Euclidean space can be viewed as a special case of
Riemannian space with the identity metric tensor.  For traditional adversarial training, the data 
are
assumed to be in Euclidean space with the identity metric tensor. In this paper, we consider a more
general case that the data are attached on the Riemannian manifold with positive definite metric
tensor varying smoothly on the manifold. Figure 1 illustrates the difference between the two 
spaces.

3


Under review as a conference paper at ICLR 2019

2.2    ADVERSARIAL PERTURBATION WITHIN l2 -BALL ON MANIFOLD

In this subsection, we introduce in details how we exploit a generalized trust region method to 
search
the adversarial perturbation on the Riemannian manifold.

To search the adversarial examples on the Riemannian manifold feasibly, we propose to solve the
inner optimization problem of (1) with the generalized trust region method:


ϵ = arg max

ϵ

Tk{L, x, ϵ}          s.t.        d(x, x + ϵ) ≤ σ                                 (7)

where ϵ is a small perturbation and σ  is a small value.     k      , x, ϵ   denotes the kᵗʰ  order 
Taylor
expansion of function    (.) around x evaluated at x + ϵ.  Here k can be set to 1 or 2.  d(x, x + ϵ)
represents the distance between two points x and x + ϵ.   In this paper,  we follow the setting of
previous research (Lyu et al., 2015) (Shaham et al., 2015) and provide the 1ᵗʰ Taylor expansion for
the loss function    (.).  We define the d(.) geodesic distance between two points on Riemannian
manifold.  Since the perturbation ϵ is very small, by applying Lemma 2.2, (7) can be reformulated
as:


ϵ = arg max

ϵ

L(x) + ∇ₓL   ϵ       s.t.         gij(x)ϵ ϵ   ≤ σ

where G = (gij(x)) denotes the metric tensor at the point x on data manifold. In (7), since geodesic
d(x, x + ϵ)       σ,  the geodesic can be evaluated by (3).   It can be proved that we can solve the
problem (8) with Lagrangian multiplier method and the worst perturbation can be given as:

ϵ ∝ G−¹∇ₓL                                                                            (9)

The detailed proof of (9) can be seen in Appendix A.

2.3    DEFINING METRIC TENSOR

In the previous subsection, we have derived that the direction of the worst perturbation is relevant
to metric tensor and the first derivative of     with respect to x.  It is easy to evaluate    ₓ    
 in DNNs
through back propagation. It is then very crucial to define the Riemannian manifold for input and 
the
metric tensor G. Since, the adversarial examples are closely related to loss function and 
classification
boundary, we can define the Riemannian manifold and metric tensor from loss function. Specifically,
We  first take the nᵗʰ  order Taylor expansion of     around x evaluated at x + ϵ (n is an extremely
large value):


(1)

(2)

(n)

L(x + ϵ) ∼= L(x) + Lx    (x) ϵ + Lx    (x) ϵ² + ... + Lx     (x) ϵⁿ


= L(x) +

1!

Lₓ   (x)
1!

2!                           n!

ϵ + m(x)

(10)

where L⁽ⁿ⁾(x) denotes the nᵗʰ order derivative of L with respect to x and

m(x) =  Lx    (x) ϵ² + o(x)                                                       (11)

2!

The loss function    (x + ϵ) can be written as summation of its 1ᵗʰ  order Taylor expansion and the
other components of Taylor series m(x).  The 1ᵗʰ  order Taylor expansion is more reliable when

|m(x)| is small enough. Naturally, the restriction can be defined as:

|m(x)| ∼= |Lx    (x) ϵ²| =  1 |ϵT Hϵ| ≤ σ²                               (12)

However, it is difficult to deal with the constraint (12) in the optimization problem. We can 
simplify
it with its upper bound by using Lemma 2.3.

4


Under review as a conference paper at ICLR 2019

Lemma 2.3.  Assume H  be a symmetric square matrix in Rn×n   and r      Rn   be a vector.  Then
we have  rT Hr        rT  H r and  H   represents the matrix with taking the absolute value of each
eigenvalue of H (proof can be seen in Appendix E).

Based on Lemma 2.3, we can have

1 |ϵT Hϵ| ≤  1 ϵT |H|ϵ ≤ σ²                                       (13)

where H is the Hessian matrix of     with respect to x and σ is a small value. When the loss 
function
is locally convex with respect to x, the Hessian matrix H  is positive semidefinite matrix and the
absolute Hessian matrix is the same as the Hessian matrix.  When the loss function is not locally
convex, the non-negative eigenvalues of absolute Hessian matrix keep the same with the Hessian
matrix while the negative eigenvalues are changed to positive ones.  The curvature information is
partially kept.   (13) can be viewed as the distance between two close points x and x + ϵ on the
Riemannian manifold with metric tensor |H|.

Comparing (13) with constraint of (8), we can define the metric tensor as  H .  Substituting   H

in (8), we can easily get the worst perturbation:

ϵ ∝ |H|−1∇ₓL                                                                        (14)

In contrast to the traditional adversarial training methods, the metric tensor  H   of our method 
in-
volves the curvature information of the loss function which can be seen as the second order method.
Through the perspective of geometry, the direction of gradient is not guaranteed to be steepest in
Riemannian space, however, the metric tensor adjusts it to the steepest one as illustrated in 
Figure 2.
Note that, for DNNs, it is easy to evaluate the Hessian matrix of     with respect to input x by 
back
propagation.

Figure 2: The red circle denotes the region of   ϵ  ₂    σ, while the red arrow illustrates the 
direction
of  gradient.   The  blue  ellipse  shows  the  region  of  ϵT  H ϵ       σ²,  the  blue  arrow  
represents  the
direction found by the proposed method, and green lines present the contour lines.  The steepest
direction is given by the gradient of the loss function,  which is orthogonal to contour lines only
when an orthonormal coordinate system is used in Euclidean space.  In the Riemannian space, the
steepest direction is not guaranteed to be orthogonal to contour lines.  However, adjusted with the
metric tensor   H −¹,  the direction of gradient can be approximate to the steepest direction.  The
graph is better viewed in color.

2.4    ADVERSARIAL PERTURBATION WITHIN lp -BALL ON MANIFOLD

In the previous subsections, we have calculated the worst perturbation within l₂-ball on Riemannian
manifold.   Similar to traditional adversarial training methods,  we can also extend our method to
lp-ball on manifold. First, we introduce Lemma 2.4 before we proceed to the case of lp-ball.

Lemma 2.4.  Let A a real symmetric positive definite matrix in Rn  × Rn.  Then we have a unique
positive definite matrix S in Rn  × Rn  so that A = S² (proof can be seen in Appendix F).

Using Lemma 2.4, we reformulate the constraint of (13)

ϵT |H|ϵ = ϵT SST ϵ = (ϵT S)² ≤ σ²                                  (15)
5


Under review as a conference paper at ICLR 2019

where S  is a positive definite matrix which we call a transformation matrix.  Then we can easily
extend (15) to lp-ball on manifold:

∥ϵT S∥p = (∑|ϵT S|p)¹/ᵖ ≤ σ

Substituting (16) with the constraint of (8), we can easily evaluate the corresponding worst pertur-
bation (details are provided in Appendix B):


T     −1

|∇LT S−¹|

−¹                           (17)


ϵ = σsign(∇L   S

)(

∥∇LT

S−1

∥p∗

) p−1 S

where p∗ is the dual of p, i.e.,  ¹  + ¹ = 1.  Clearly, when p = 2, the worst perturbation is 
reduced

p∗       p

to (14) which is the case of the perturbation within l₂-ball on manifold. When p =     , our method
reduces to the generalized FGSM:


T     −1

|∇LT S−1|               −1

T     −1

−¹         (18)


ϵ = σ  lim  sign(

p→∞

S     )(

∥∇LT

S−1

∥p∗

) p−1 S

= σsign(∇L   S     )S

Though  we  can  evaluate  the  adversarial  perturbation  for  any  lp-ball  on  Riemannan  
manifold
through (17). In this paper, we focus on the constraint of l₂-ball and will develop the 
corresponding
adversarial training method to improve the performance of DNNs in the next subsection.

2.5    ADVERSARIAL TRAINING METHOD WITH RIEMANNIAN MANIFOLD

After studying the adversarial examples on manifold, we now consider to design an optimization
method  to  improve  the  DNNs  using  the  theory  in  the  previous  subsections.   We  first  
define  the
overall optimization as the robust optimization problem in a way similar to the traditional 
adversarial
training:


min

θ

E₍ₓ,y₎~D[max L(x + ϵ, y, θ)]       s.t.     ∥ϵT S∥p ≤ σ                             (19)

In this paper, we focus on the l₂-ball constraint, while it is easily extended to the lp-ball 
constraint. In
the case of l₂, we can reduce the constraint in (19) to ϵT  H ϵ     σ. To optimize this problem, we 
can
first solve the inner optimization problem then followed by the outer one. We then repeat this 
process
until it converges.  The whole process is shown as Algorithm 1.  On the other hand, Algorithm 2
demonstrates the function of approximating   H −¹   ₓ   (yi, xi, θ).  Hessian matrix may require a
large amount of computation.  In Algorithm 1, we approximate  H −¹   ₓ   (yi, xi, θ) with the first
derivative of loss function with respect to input. Specifically, we simply modify the Limited-memory
BroydenCFletcherCGoldfarbCShanno (L-BFGS) method. More details can be seen in Appendix C.

Algorithm 1 Framework of ensemble learning for our system.

1:  for number of training iterations do

2:         Sample a batch of labeled data (xi, yi) with size N .

3:         for i in 1...N do                       

4:               di ← |H|−1∇ₓL(yi, xi, θ)


i

adv

6:         end for

= ξdi

7:         Update the parameters of neural network with stochastic gradient:

8:

9:         −∇θ  1  ∑N      logL(yi, xi + ϵⁱ     , θ)

In  Algorithm  1,   H −1    x     (yi, xi, θ)  represents  the  normalization  of   H −¹   ₓ   (yi, 
xi, θ).   We
now provide the theoretical analysis showing that our proposed method truly offers the decent di-
rection for the optimization problem as (Madry et al., 2017).  In order to do this, we first present
Theorem 2.5.

6


Under review as a conference paper at ICLR 2019

Algorithm 2 Approximation for |H|−1∇ₓL(yi, xi, θ).

1:  function APPROHD(yi, xi, θ, ζ)

2:         Give ζ very small value

3:         g₀ =    ₓ   (yi, xi, θ)

4:         g₁ =    ₓ   (yi, xi + ζg₀, θ)

5:         y = g₁    g₀

6:         s = ζg₀

7:         ρ =    ¹ 

8:         α = ρsT g₁

9:         q = g₁    αy

10:         r₀ = q₀

11:         β = ρyT r₀

12:         r₁ = r₀ + (α     β)s

13:         return r₁

14:  end function

Theorem 2.5.  (Danskin). Let S be nonempty compact topological space and g : R    S       R such
that g(., δ) is differentiable for every δ      S and    θg(θ, δ) is continuous on Rn         S.  
Also assume
δ∗(θ)  =    δ       arg maxδ   S g(θ, δ)  .   Then  the  max-function  ϕ(θ)  =  maxδ   S g(θ, δ)  
is  locally
Lipschitz continuous,  directionally differentiable,  and its directional derivatives satisfy:  
ϕ′(θ)  =
supδ∈δ∗ (θ) hT ∇g(θ, δ) In particular, if for some θ  ∈  Rⁿ  the set δ∗(θ)  =  {δθ∗} is a 
singleton, the
max-function is differentiable at θ and ∇ϕ(θ) = ∇θg(θ, δθ∗).

This theorem states that the gradients of ϕ(θ) are local objects and the gradients are locally the
same as that of g(θ, δθ∗).   With Theorem 2.5,  we describe the theory showing that our proposed
optimization method truly offers the decent direction:

Lemma 2.6.  Let δˆ ∈ S be a maximizer of maxδL(θ, x+θ, y). Then, we have that −∇thₑtₐL(θ, x+

δˆ, y) is a decent direction for ϕ(θ) = maxδ∈S L(θ, x + δ, y).

Proof.  We apply Theorem 2.5 that g(θ, δ) :=    (θ, x + δ, y) and S  = Bp(σ), which is defined as
the lp-ball with radius σ  on Riemannian manifold.   The directional derivative in the direction of
h = ∇θL(θ, x + δˆ, y) satisfies:


ϕ′(θ, h) =   sup

δ∈δˆ(θ)

hT ∇θL(θ, x + δ.y) ≥ hT h = ∥∇θL(θ, x + δˆ, y)∥2 ≥ 0                 (20)

2.6    COMPUTATIONAL ANALYSIS

Compared  with  traditional  adversarial  training  methods,  our  proposed  ATRM  need  compute  
the
Hessian matrix of the loss function with respect to input additionally. It may cost extra 
computation
to calculate the Hessian matrix.  Nonetheless, we exploit in this paper the first-order derivative 
of
the  loss  function  to  approximate  the  product  of  Hessian  matrix  and  the  vector,  which  
is  shown
in Algorithm 2.  Therefore, our proposed method requires backward propagation three times and
forward prorogation once.  Specifically, the first backward prorogation is used to approximate the
Hessian matrix, the second one is used to evaluate the adversarial perturbation, and the last time
is to update the parameters of DNNs.  In contrast to traditional adversarial training methods, our
proposed method need merely one additional backward propagation which is acceptable in practice.

3    EXPERIMENT

To validate the efficacy of our proposed method,  we conduct a series of experiments on bench-
mark data including MNIST, CIFAR-10, and SVHN. In these experiments, we compare our pro-
posed  ATRM  with  other  competitive  methods.   For  MNIST  datasets  we  use  the  same  
baseline

7


Under review as a conference paper at ICLR 2019

as (Rasmus et al., 2015).  The same base structure called ’conv-large’ is used on dataset CIFAR-10
and SVHN, which follows (Miyato et al., 2018).  Specifically, ’conv-large’ means a large convolu-
tional neural network with seven convolutional layers and three fully-connected layers with dropout
where the size of all the convolutional kernels is 3 × 3.

We first implement our proposed ATRM on handwriting dataset MNIST. Since there is no previ-
ous adversarial research on this baseline model on this dataset, we conduct the experiment on two
methods (adversarial training with l    and l₂ constraint) for comparison. The model is trained with
60, 000 labeled samples without any data augmentation and is tested with 10, 000 samples. We train
the model with a batch size of 32 and the maximum 500 epochs.  There are two hyper parameters
ζ, ξ   in Algorithm 1 and Algorithm 2. We set ζ to a very small value, which is 10−⁶ in this paper.
We tune the value of ξ in the range of   0.1, 0.2, 0.5, 1, 2, 5, 10  . We use the set of hyper 
parameters
that achieved the best performance on the validation set of size 5, 000, selected randomly from the
pool of training samples of size 60, 000.

Table 1 lists the performance of various methods including our proposed ATRM and other com-
petitive methods.  Except for ATRM, we also conduct the same experiment for the baseline model
and traditional adversarial training methods with l₂-ball and l   -ball constraint.   We conduct the
experiment with this same setting for five times and calculate the mean and standard deviation.  As
observed, our proposed ATRM demonstrates the best performance.  In particular, all the adversari-
al methods achieve remarkably good performance, while the ATRM shows a further improvement.
This validates the advantages of our proposed method over the other methods, especially the other
traditional adversarial methods.

Table 1: Test performance on MNIST

MNIST

Test error rate(%)

SVM                                                          1.40

Dropout (Srivastava et al., 2014)               1.05

Ladder networks (Rasmus et al., 2015)     0.57     0.02

VAT (Miyato et al., 2018)                          0.72

RPT (Miyato et al., 2018)                         0.82

Baseline (Rasmus et al., 2015)                  0.32

Baseline+l∞ adversarial training              0.30 ± 0.013

Baseline+l₂ adversarial training                0.26 ± 0.019

ATRM                                                        0.22 ± 0.016

For CIFAR-10, we train our proposed model ATRM with 50, 000 labeled samples with data aug-
mentation as conducted in (Miyato et al., 2018) (translation and horizontal flip). The test dataset 
of
CIFAR-10 involves 10, 000 samples. Similar to the experiment on MNIST, we set ζ to a small vaule
10−⁶, and tune the value of ξ in the range of   1, 2, 5, 8, 10  . We run the experiments for five 
times
and report the average performance and corresponding standard deviation.

Table 2 summarizes the results of different methods on CIFAR-10 dataset.  In this experiment, we
intentionally compare our proposed method ATRM with the other two very deep models, i.e., the
densely connected network (DenseNet) with 190 layers and very deep residual network (ResNet)
with 1, 001 layers.  Overall, our proposed method demonstrates competitive performance.  Though
not as good as the very deep networks DenseNet and ResNet, the proposed ATRM shows superior
performance to those adversarial learning methods and all the other remaining approaches.  Once
again, this shows that adversarial learning should be conducted on the geometric manifold rather
than the traditional Euclidean space.

The Street View House Numbers (SVHN) dataset contains 32     32 colored digit images. There are
73, 257 images in the training set, 26, 032 images in the test set, and 531, 131 images for 
additional
training.   We train  our  model using  the  same  setting  as  (Huang et al.,  2017).   As  can  
be  clearly
observed in Table 3, our method demonstrates the best performance.  It is even much better than
the very deep networks (DenseNet and ResNet). More importantly, our method achieves an obvious
improvement compared with the traditional adversarial training algorithms.

8


Under review as a conference paper at ICLR 2019

Table 2: Test performance on CIFAR-10

CIFAR-10

Test error rate(%)
Network in Network (Lin et al., 2013)             8.81

All-CNN (Springenberg et al., 2014)               7.25

Deeply Supervised Net (Lee et al., 2015)        7.97

Highway Network (Srivastava et al., 2015)      7.72

RPT (Miyato et al., 2018)                                6.25     0.04

ResNet (1,001 layers) (He et al., 2016)            4.62     0.2

DenseNet (190 layers) (Huang et al., 2017)     3.46

Baseline (Miyato et al., 2018)                          6.76 ± 0.07

VAT (Miyato et al., 2018)                                 5.81 ± 0.02

Baseline+l∞ adversarial training                     6.35 ± 0.03

Baseline+l₂ adversarial training                       5.82 ± 0.02

ATRM                                                               5.35 ± 0.03

Table 3: Test performance on SVHN

SVHN

Test error rate(%)
Network in Network (Lin et al., 2013)             2.35

Deeply Supervised Net (Lee et al., 2015)        1.92

ResNet (110 layers) (He et al., 2016)               2.01

DenseNet (250 layers) (Huang et al., 2017)     1.74

Baseline                                                            2.09 ± 0.06

Baseline+l∞ adversarial training                     1.95 ± 0.05

Baseline+l₂ adversarial training                       1.82 ± 0.04

ATRM                                                               1.56 ± 0.05

Training loss and validation loss of ATRM


2.0

1.5

            ATRM_train_svnh
ATRM_val_svhn

            ATRM_train_cifar10
ATRM_val_cifar10

            ATRM_train_mnist
ATRM_val_mnist

1.0

0.5

0.0

0          25         50         75        100       125       150       175       200

epoch

Figure 3: The convergence curves on three datasets

Finally, we have also done the experiments to prove the convergence for our proposed method. We
have plotted the convergence curves for both training set and validation set of all three datasets 
as
Figure 3 showing.

9


Under review as a conference paper at ICLR 2019

4    CONCLUSION

We present the novel framework called Adversarial Training with Riemannian Manifold (ATRM)
which generalizes the traditional adversarial training method to Riemannian space.  For tradition-
al adversarial training methods,  the worst perturbation is often searched with the gradient     ₓ  
 .
However, when the data lay on a geometric manifold defined as a Riemannian manifold, the gra-
dient     ₓ     is not the steepest direction, leading the adversarial perturbation is not the 
worst one.
We present a series of theory showing that our method leads to the steepest direction of the loss
function in Riemannian space.  In practice, we also develop a practical algorithm guaranteeing the
decent direction for the loss function at each epoch.  Experiments demonstrate encouraging results
on benchmark data including MNIST, CIFAR-10 and SVHN.

REFERENCES

Shun-Ichi Amari.  Natural gradient works efficiently in learning.  Neural computation, 10(2):251–
276, 1998.

Shun-ichi Amari. Information geometry and its applications. Springer, 2016.

M. S. Bartlett.  An inverse matrix adjustment arising in discriminant analysis.  Annals of Mathemat-
ical Statistics, 22(1):107–111, 1951.

Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Sˇrndic´, Pavel Laskov, Gior-
gio Giacinto,  and Fabio Roli.   Evasion attacks against machine learning at test time.   In Joint
European conference on machine learning and knowledge discovery in databases, pp. 387–402.
Springer, 2013.

Richard H Byrd, Jorge Nocedal, and Robert B Schnabel. Representations of quasi-newton matrices
and their use in limited memory methods. Mathematical Programming, 63(1-3):129–156, 1994.

Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard. Robustness of classifiers:
from adversarial to random noise.  In Advances in Neural Information Processing Systems, pp.
1632–1640, 2016.

Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.  Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014.

Kaiming He,  Xiangyu Zhang,  Shaoqing Ren,  and Jian Sun.   Identity mappings in deep residual
networks. In European conference on computer vision, pp. 630–645. Springer, 2016.

Kaiming He, Georgia Gkioxari, Piotr Dolla´r, and Ross Girshick.  Mask r-cnn.  In Computer Vision
(ICCV), 2017 IEEE International Conference on, pp. 2980–2988. IEEE, 2017.

Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger.  Densely connected
convolutional networks. In CVPR, volume 1, pp.  3, 2017.

Alexey Kurakin, Ian Goodfellow, and Samy Bengio.  Adversarial machine learning at scale.  arXiv
preprint arXiv:1611.01236, 2016.

Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436, 2015.
Chen-Yu  Lee,  Saining  Xie,  Patrick  Gallagher,  Zhengyou  Zhang,  and  Zhuowen  Tu.    Deeply-

supervised nets. In Artificial Intelligence and Statistics, pp. 562–570, 2015.

Min Lin, Qiang Chen, and Shuicheng Yan.  Network in network.  arXiv preprint arXiv:1312.4400,
2013.

Dong C Liu and Jorge Nocedal.  On the limited memory bfgs method for large scale optimization.

Mathematical programming, 45(1-3):503–528, 1989.

Chunchuan Lyu, Kaizhu Huang, and Hai-Ning Liang.  A unified gradient regularization family for
adversarial  examples.   In  Data  Mining  (ICDM),  2015  IEEE  International  Conference  on,  pp.
301–309. IEEE, 2015.

10


Under review as a conference paper at ICLR 2019

Xingjun Ma, Bo Li, Yisen Wang, Sarah M Erfani, Sudanthi Wijewickrema, Michael E Houle, Grant
Schoenebeck, Dawn Song, and James Bailey.  Characterizing adversarial subspaces using local
intrinsic dimensionality. arXiv preprint arXiv:1801.02613, 2018.

Aleksander  Madry,  Aleksandar  Makelov,  Ludwig  Schmidt,  Dimitris  Tsipras,  and  Adrian  Vladu.
Towards deep learning models resistant to adversarial attacks.  arXiv preprint arXiv:1706.06083,
2017.

Takeru Miyato,  Shin-ichi Maeda,  Masanori Koyama,  Ken Nakae,  and Shin Ishii.   Distributional
smoothing with virtual adversarial training. arXiv preprint arXiv:1507.00677, 2015.

Takeru  Miyato,  Andrew  M  Dai,  and  Ian  Goodfellow.    Adversarial  training  methods  for  
semi-
supervised text classification. arXiv preprint arXiv:1605.07725, 2016.

Takeru Miyato, Shin-ichi Maeda, Shin Ishii, and Masanori Koyama.  Virtual adversarial training: a
regularization method for supervised and semi-supervised learning. IEEE transactions on pattern
analysis and machine intelligence, 2018.

Anh Nguyen, Jason Yosinski, and Jeff Clune.  Deep neural networks are easily fooled: High confi-
dence predictions for unrecognizable images.  In Proceedings of the IEEE Conference on Com-
puter Vision and Pattern Recognition, pp. 427–436, 2015.

Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow. Transferability in machine learning: from
phenomena to black-box attacks using adversarial samples.   arXiv preprint arXiv:1605.07277,
2016.

Antti  Rasmus,  Mathias  Berglund,  Mikko  Honkala,  Harri  Valpola,  and  Tapani  Raiko.    Semi-
supervised learning with ladder networks. In Advances in Neural Information Processing Systems,
pp. 3546–3554, 2015.

Uri Shaham, Yutaro Yamada, and Sahand Negahban. Understanding adversarial training: Increasing
local stability of neural nets through robust optimization. arXiv preprint arXiv:1511.05432, 2015.

Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin Riedmiller.  Striving for
simplicity: The all convolutional net. arXiv preprint arXiv:1412.6806, 2014.

Nitish Srivastava,  Geoffrey Hinton,  Alex Krizhevsky,  Ilya Sutskever,  and Ruslan Salakhutdinov.
Dropout:  A simple way to prevent neural networks from overfitting.   The Journal of Machine
Learning Research, 15(1):1929–1958, 2014.

Rupesh Kumar Srivastava, Klaus Greff, and Ju¨rgen Schmidhuber. Highway networks. arXiv preprint
arXiv:1505.00387, 2015.

Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.

Gerard  Walschap.   Metric  structures  in  differential  geometry,  volume  224.   Springer  
Science  &
Business Media, 2012.

Weilin Xu, David Evans, and Yanjun Qi. Feature squeezing: Detecting adversarial examples in deep
neural networks. arXiv preprint arXiv:1704.01155, 2017.

A    FIND  THE  ADVERSARIAL  PERTURBATION  WITHIN l₂-BALL  ON  MANIFOLD

Recall our goal is to maximize the value of the problem:

arg max  L(x) + ∇ₓLT ϵ

s.t.            gij(x)ϵⁱϵʲ  ≤ σ²

Since L(x) is independent of ϵ and the worst perturbation has the norm σ, then we have:

11


Under review as a conference paper at ICLR 2019

arg max ∇ₓLT ϵ

s.t.            gij(x)ϵⁱϵʲ  = σ²

Then we apply the Lagrangian multiplier method on this problem:

arg max ∇ₓLT ϵ − λ(gij(x)ϵⁱϵʲ − σ²)                                             (21)
Making the first derivative of (21) with respect to ϵ zero, we have:


Then we have:

∇ₓL = λgij(x)ϵ


Therefore:

ϵ =  1 G−¹    L

ϵ ∝ G−¹∇ₓL

B    FIND  THE  ADVERSARIAL  PERTURBATION  WITH lp-BALL  ON  MANIFOLD

The optimization problem is:

ϵ = arg max  L(x) + ∇ₓLT ϵ

s.t.            ∥ϵT S∥p ≤ σ

Similar to Appendix A, we reduce the problem to:

ϵ = arg max  L(x) + ∇ₓLT ϵ

s.t.            ∥ϵT S∥p = σ

We solve it with the Lagrangian multiplier method again and set r  = ϵT S and f (r)        r  p  = 
σ.
We have

∇ₓLrS−¹ = λ(f (r) − σ)

Then we make the first derivative respect to r:


∇ₓLS−¹

rp−1

= λ

p


i

S−¹ =  λ ( r

σ

i

)p−1


(∇ₓ

LS−¹) p−1   = (

λ       p        r

) p−1 (

p          σ

)ᵖ                                                          (22)

12


Under review as a conference paper at ICLR 2019


If we sum over two sides, we have

∑(∇ₓ

LS−¹)     p      = ∑(

λ       p        r

) p−1 (   )

p          σ

∥∇  LS−¹∥p∗         λ      ∗ 1


λ

( p ) = ∥∇ₓ

LS−¹∥p∗                                                                       (23)


By combining (22) and (23), we have

T     −1

|∇LT S−¹|          1   


Since r = ϵT S, we have

r = σsign(∇L   S

)(

∥∇LT

S−1

∥p∗

) p−1


T     −1

|∇LT S−1|               −1


ϵ = σsign(∇L   S

)(

∥∇LT

S−1

∥p∗

) p−1 S

C    FIND  THE  APPROXIMATION  FOR |H|−1∇ₓL(yi, xi, θ).

We develop a modified BFGS method to approximate the  H −¹. To solve the memory problem, we
use the simplified Limited-memory BFGS (L-BFGS) to approximate  H −¹   ₓ   (yi, xi, θ) directly
(based on BFGS).

We first present Theorem C.1.

Theorem C.1.  (Sherman Morrison formula (Bartlett, 1951)) Let A     Rn×n  be an invertible square
matrix and v, u     Rn  be column vectors. Then A + uvT  is invertible if and only if 1 + vT A−¹u = 
0.
And its inverse is given by


(A + uvT

)−1

= A−1

A−1uvT A−1

−  1 + vT A−1u

(24)

We then take the second order Taylor expansion for L(x + ϵ₁) (where ϵ₁ is a small value):

T      2

L(x + ϵ₁) ≈ L(x) + ∇L(x)ϵ₁ + ϵ1 ∇  L(x)ϵ₁

If we make the first derivative on both sides with respect to ϵ₁, we can have:

∇L(x + ϵ₁) − ∇L(x) ≈ Hϵ₁

where H denotes the Hessian matrix of L(x) with respect to ϵ₁.

We can define y = ∇L(x + ϵ₁) − ∇L(x), then

y ≈ Hϵ₁                                                 (25)

Next, we use modified BFGS algorithm to approximate H and let

B = I + ∆M                                                                 (26)

13


Under review as a conference paper at ICLR 2019

where  B  represents  the  approximation  for  H,  I  is  identity  matrix,  and  ∆M  denotes  
difference
matrix. Our aim is to evaluate ∆M . First we define

∆M  = auuT  + bvvT                                                                   (27)

where a, b      R and u, v      RN   are undetermined.  It is easy to get that ∆M  is symmetric.  We
combine (27), (26) and (25):


We can further assume

y = Iϵ₁ + auuT ϵ₁ + bvvT ϵ₁

= Iϵ₁ + (auT ϵ₁)u + (bvT ϵ₁)v

(28)


Therefore, we have

auT ϵ₁ = 1,      bvT ϵ₁ = −1                                                      (29)


1

a =  uT ϵ

If we combine (28) and  (30), we have

1

,      b = − vT ϵ

(30)


Therefore, we can set

By combining (32) and (30), we have

u − v = y − Iϵ₁                                             (31)

u = y,      v = Iϵ₁                                            (32)


1

a =  yT ϵ

Then, we combine (26), (32), and (33):

1

,      b = − ϵT Iϵ

(33)


B = I +

yyT

yT ϵ₁

ϵ  1ϵT

−  ϵT ϵ₁

(34)

(34) can be viewed as a simplified BFGS method with one step approximation. When the dimension
of s and ϵ₁ increases, a large amount of memory is needed to store the matrix ssT  and ϵ₁ϵT . To 
solve
this problem, we then use the simplified L-BFGS method to evaluate directly  H −¹   ₓ   (yi, xi, θ).
We first use Theorem C.1 to reformulate (34) as:


ϵ₁yT

yϵT          ϵ₁ϵT


D = (I −

)(I −         1   ) +       ¹ 


yT ϵ₁

yT ϵ₁     yT ϵ₁

Then, we can easily implement the method L-BFGS as (Byrd et al., 1994) and get Algorithm 3.

D    PROOF  FOR  LEMMA  2.2

Let ξ(0) and ξ(a) be two closed points on Riemannian manifold,  where ξ(t) is a shortest curve
connecting these two points.   Then,  we have the square of geodesic distance between these two
points:

ds² = gij(t)dθⁱdθʲ                                                                     (35)

where dθⁱ = ξ˙(t)ⁱ is the iᵗʰ component of small vector dθ and gij(t) is the metric tensor.

14


Under review as a conference paper at ICLR 2019

Algorithm 3 Approximation for |H|−1∇ₓL(yi, xi, θ).

1:  function APPROHD(yi, xi, θ, ζ)
2:         Set ζ to a very small value
3:         g₀ =    ₓ   (yi, xi, θ)

4:         g₁ =    ₓ   (yi, xi + ζg₀, θ)

5:         y = g₁    g₀

6:         s = ζg₀

7:         ρ =    ¹ 

8:         α = ρsT g₁

9:         q = g₁    αy

10:         r₀ = q₀

11:         β = ρyT r₀

12:         r₁ = r₀ + (α     β)s

13:         return r₁

14:  end function

Proof.  We evaluate the geodesic distance between ξ(0) and ξ(a) through Theorem 2.1:

∫  ₐ √

	

Since ξ(0) and ξ(a) are closed points, a → 0. Then we have                          


ds =  lim

a→0

a

gij(t)ξ˙i(t)ξ˙j (t)  dt =

0

√gij(t)ξ˙i(t)ξ˙j (t)                              (37)

Therefore, we have

ds² = gij(t)dθⁱdθʲ                                                                     (38)

E    PROOF  FOR  LEMMA  2.3

Assume H  be a symmetric square matrix in Rn  × Rn   and r  ∈  Rn   be a vector.   Then we have

|rT Hr| ≤ rT |H|r and |H| represents the matrix with taking the absolute value of each eigenvalue

Proof.  Assume   e₁, e₂, ..., en    and   λ₁, λ₂, ..., λn    are the eigenvectors and corresponding 
eigen-
values of matrix H. Then we reformulate  rT Hr  with eigenvectors and corresponding eigenvalues
as:


|rT Hr| = |∑(rT ei)λi(eT r)| = |∑ λi(rT ei)²|

(39)

i                                                   i

We can now use the triangle inequality |     i ri| ≤      i|ri| and we have:

|rT Hr| ≤ ∑|λi(rT ei)²| = ∑(rT ei)|λ|(rT ei) = rT |H|r                            (40)

	

F    PROOF  FOR  LEMMA  2.4

Let A be a real symmetric positive definite matrix in Rn  × Rn.  Then we have a unique positive
definite matrix S in Rn  × Rn  so that A = S².

15


Under review as a conference paper at ICLR 2019

Proof.  To  prove  existence:  Since  A  is  a  real  symmetric  positive  definite  matrix,  we  
have  A  =

PT diag(λ₁, ..., λn)P , where P is an orthogonal matrix and {λi} are the Eigen values of A (λi > 
0).

	

We can find S = PT diag(λ 2 , ..., λ 2 ) that A = S².

1          n

To prove uniqueness:  Let B be another positive definite matrix and A  =  B².  Since B is positive
definite, we have A = TT diag(µ₁, ..., µn)T , where T  is an orthogonal matrix and   µi    are Eigen
values of B (µi > 0). We have A = PT diag(λ₁, ..., λn)P , therefore

T −¹diag(µ₁, ..., µn)T  = P −¹diag(λ₁, ..., λn)P                                      (41)
Let U  = (uij)n×n = PT −¹ and we have:

diag(µ², ..., µ² )U  = Udiag(λ₁, ..., λn)                                            (42)


which is equivalent to:

1          n

λiuij  = uijµ2

(43)

1                                                                                                   
     1

When λ     µ², uij  = 0, we have λ 2   = uijµj. When λi = µ², we also have λ 2   = uijµj. 
Therefore:

1                1

diag(µ  , ..., µ  )U  = Udiag(λ 2 , ..., λ 2 )                                            (44)


Then we have:

1          n                                        1          n

1                1

B = T −¹diag(µ  , ..., µ  )T  = P −¹diag(λ 2 , ..., λ 2 )P  = S                            (45)

1          n                                               1          n

16

