Under review as a conference paper at ICLR 2019
UaiNets: From Unsupervised to Active Deep
Anomaly Detection
Anonymous authors
Paper under double-blind review
Ab stract
This work presents a method for active anomaly detection which can be built
upon existing deep learning solutions for unsupervised anomaly detection. We
show that a prior needs to be assumed on what the anomalies are, in order to
have performance guarantees in unsupervised anomaly detection. We argue that
active anomaly detection has, in practice, the same cost of unsupervised anomaly
detection but with the possibility of much better results. To solve this problem, we
present a new layer that can be attached to any deep learning model designed for
unsupervised anomaly detection to transform it into an active method, presenting
results on both synthetic and real anomaly detection datasets.
1	Introduction
Anomaly detection (a.k.a. outlier detection) (Hodge & Austin, 2004; Chandola et al., 2009; Aggarwal,
2015) aims to discover rare instances that do not conform to the patterns of majority. From a business
perspective, though, we are not only interested in finding rare instances, but “usefull anomalies”.
This problem has been amply studied recently (Liu et al., 2017; Li et al., 2017; Zong et al., 2018;
Maurus & Plant, 2017; Zheng et al., 2017), with solutions inspired by extreme value theory (Siffer
et al., 2017), robust statistics (Zhou & Paffenroth, 2017) and graph theory (Perozzi et al., 2014).
Unsupervised anomaly detection is a sub-area of outlier detection, being frequently applied since
label acquisition is very expensive and time consuming. It is a specially hard task, where there is
usually no information on what these rare instances are and most works use models with implicit
priors or heuristics to discover these anomalies, providing an anomaly score s(x) for each instance in
a dataset. Active anomaly detection is a powerful alternative approach to this problem, which has
presented good results in recent works such as (Veeramachaneni et al., 2016; Das et al., 2016; 2017).
In this work, we first show that unsupervised anomaly detection requires priors to be assumed on
the anomaly distribution; we then argue in favor of approaching it with active anomaly detection, an
important, but under-explored approach (Section 2). We propose a new layer, called here Universal
Anomaly Inference (UAI), which can be applied on top of any unsupervised anomaly detection model
based on deep learning to transform it into an active model (Section 3). This layer uses the strongest
assets of deep anomaly detection models, i.e. its learned latent representations (l) and anomaly score
(s), to train a classifier on the few already labeled instances. An example of such an application can
be seen in Figure 1, where an UAI layer is built upon a Deanoising AutoEncoder (DAE).
We then present extensive experiments, analyzing the performance of our systems vs unsupervised,
semi-supervised and active ones under similar budgets in both synthetic and real data, showing our
algorithm improves state of the art results in several datasets, with no hyperparameter tuning (Section
4). Finally, we visualize our models learned latent representations, comparing them to unsupervised
models’ ones and analyze our model’s performance for different numbers of labels (Appendix C).
2	Problem Definition
Grubbs (1969) defines an outlying observation, or outlier, as one that appears to deviate markedly from
other members of the sample in which it occurs. Hawkins (1980) states that an outlier is an observation
that deviates so much from other observations as to arouse suspicion that it was generated by a different
mechanism. While Chandola et al. (2009) says that normal data instances occur in high probability
regions of a stochastic model, while anomalies occur in the low probability ones. Following these
definitions, specially the one from (Hawkins, 1980), we assume there is a probability density function
1
Under review as a conference paper at ICLR 2019
DAE
UAI
~X
= ||x - x’||2
I----------
X Uai
Suai(x) = σ(Wact[Xuai] + bact)
Uai Layer
X
Figure 1: DAEuai architecture.
from which our 'normal' data instances are generated: Xnormal 〜Pnormal (x) = P (x|y = 0), where
x is an instance’s available information1 and y is a label saying if the point is anomalous or not. There
is also a different probability density function from which anomalous data instances are sampled:
Xanom 〜Panom (X) = P (XIy = I).
A full dataset is composed of both normal and anomalous instance, being sampled from a probability
distribution that follows:
(X, Y)full
Xfull
〜Pfull(X, y)
〜	Pfull(X)
P (y) P (X|y)
P (y = 0) Pnormal (X) + P (y = 1) Panom (X)
(1 - λ)Pnormal (X) + λP
anom
(X)
(1)
where λ is an usually small constant representing the probability of a random data point being
anomalous (λ = P(y = 1)), this constant can be either known a priori or not. Chandola et al. (2009)
divides anomaly detection learning systems in three different types:
•	Supervised: A training and a test set are available with curated labels for non-anomalous
and anomalous instances. This case is similar to an unbalanced supervised classification
setting:
Dtrain / test = (X, Y ) train / test 〜Pfull(X,y)
Semi-Supervised: A training set is available containing only non-anomalous instances and
the challenge is to identify anomalous instances in a test set. This is also called novelty
detection:
Dtrain
Xtrain
〜Pnormal (X)
Dtest = Xtest 〜Pfull (x)
•	Unsupervised: A dataset containing both non-anomalous and anomalous instance is available
and the challenge is to identify anomalous instances in it. There is no concept of a test set
since anomalous instances must be sorted in the dataset itself:
D = X 〜 Pful l (X)
2.1 Unsupervised Anomaly Detection
In this work, we will focus on unsupervised anomaly detection. Here, in possession of the full
set of points X 〜 Pfull (X), we want to find a subset Xanom ⊂ X which is composed of the
anomalous instances. The full distribution Pfull is a mixture of distributions and if these distributions
overlap very closely, it may be impossible to learn the individual distributions beyond a certain
accuracy threshold (Dasgupta et al., 2005). It is a well-known result that general mixture models are
unidentifiable (Aragam et al., 2018; Bordes et al., 2006). In the sequence, we further show that we
gain no information on Panom from Pful l for any small λ without a prior on the anomalies’ probability
distribution. This differs from the usual unidentifiability of mixture models result in that we make no
assumptions on the prior for Pnormal, showing all valid distributions of Panom are equally probable.
1 x, in our notation, is the information known about a data instance. This can be further composed of what
would actually be x and y in a supervised setting, such as an image and its corresponding class label. We will
reference this as xx and xy here.
2
Under review as a conference paper at ICLR 2019
Theorem 1.	No free anomaly theorem. Consider two independent arbitrary probability distributions
Pnormal and Panom. Forasmallnumberofanomalies λ ≈ 0, Pfull = p gives Us no further knowledge
on the distribution of panom :
P(Pa
nom ∣Pfull = P) ≈ Uniform(P2),	λ ≈ 0
where
P2 = {Pr , ∀Pr ∈ P | λ ∈ [0； 1], λ ∙ Pr ≤ P}
limλ→0 P2 = {p, ∀p ∈ P | SuPP(P) ⊆ SuPP(P)}
From Theorem 1 we can conclude that unsupervised anomaly detection requires a prior on the
anomalies distribution. A more tangible example of this can be seen in Figure 2, where we present
a synthetic data distribution composed of three classes of data clustered in four visibly separable
clusters. Anomaly detection is an undecidable problem in this setting without further information,
since it is impossible to know if the low density cluster is composed of anomalies or the anomalies
are the unclustered low density points (or a combination of both).
If we used a high capacity model to model the data distribution in Figure 2, the low density points
(Right) would be detected as anomalous. If we used a low capacity model, the cluster (Center) would
probably present a higher anomaly score. Our choice of algorithm implicitly imposes a prior on the
detected anomalies. Theorem 1 highlights this and makes the need to consider priors explicit.
In a more practicle example, assume we are working with clinical data. In this setting, some low
density clusters may indicate diseases (anomalies), while other low density clusters may be caused by
uncontrolled factors in the data, such as high performance athletes. At the same time, rare diseases
might seem like scattered (low density) points. We want to be able to distinguish between anomalies
and ‘uninteresting’ low probability points.
Figure	2: Example of undecidable anomalous data distribution: (Left) Raw data distribution; (Center)
Possible Clustered Anomalies; (Right) Possible Low Density Anomalies.
3	Model
The usual strategy when working with unsupervised anomaly detection problems is training a
parameterized model Pθ (x) to capture the full data distribution Pfull (x) (e.g. a PCA, or AutoEncoder),
and, since λ is, by definition, a small constant, assuming Pfull(x) ≈ Pnormal (x) and assuming points
with low probability are anomalous (Zhou & Paffenroth, 2017). An anomaly score S(x) is then
defined as S(X) = p^.
There are three main problems with this strategy: (1) if anomalous items are more common than
expected, Pfull might be a poor approximation of Pnormal; (2) if anomalous items are tightly clustered
in some way, high capacity models may learn to identify that cluster as a high probability region; (3)
if anomalous items are as rare as expected, since we only have access to Pfull, Theorem 1 states we
have no information about Panom without further assumptions on its probability distribution.
Most unsupervised anomaly detection systems also already rely on further verification of the results
by human experts, due to their uncertain performance. Being mostly used as a ranking system to get
high probability instances in the top of a ‘list’ to be further audited by these experts.
From Theorem 1, we conclude it is impossible to have an universal and reliable unsupervised anomaly
detection system, while we know that most such systems already rely on the data being later audited
by human experts. These arguments together argue in favor of an active learning strategy for anomaly
detection, including the auditor experts in the system’s training loop. Thus, anticipating feedback and
3
Under review as a conference paper at ICLR 2019
benefiting from it to find further anomalous instances, which results in a more robust system. Having
an extremely unbalanced dataset in this problem (λ ≈ 0) is also another justification for an active
learning setting, which has the potential of requiring exponentially less labeled data than supervised
settings (Settles, 2012).
3.1	Active Anomaly Detection
With these motivations, we argue in favor of active anomaly detection methods, which despite its
many advantages remains an under-explored approach to this problem. Nonetheless, recent work
has shown promising results (Veeramachaneni et al., 2016; Das et al., 2016; 2017). In unsupervised
anomaly detection, We start with a dataset D = {x|x 〜PfUll(x)} and want to rank elements in
this dataset so that we have the highest possible recall/precision for a certain budget b, which is the
number of elements selected to be audited by an expert, with no prior information on anomaly labels.
In active anomaly detection, we also start with a completely unlabeled anomaly detection dataset
D = {x|x 〜PfUll (x)}, but instead of ranking anomalies and sending them all to be audited at once
by our expert, we select them in small parts, waiting for the experts feedback before continuing.
We iteratively select the most probable k b elements to be audited2, wait for the expert to select
their label, and continue training our system using this information, as shown in Algorithm 1. This
requires the same budget b as an unsupervised anomaly detection system, while having the potential
of achieving a much better performance.
Algorithm 1 Active Anomaly Detection
1:	procedure ACTIVEANOMALYDETECTION(D, expert, b, k)
2:	i — 0; labels - 0
3:	while i < b do
4:	model.train(D, labels)
5:	top_k — model .select_top(k, D, labels)
6:	labels J labels ∪ expert.audit( top_k)
7:	i J i + k
With this in mind, we develop the Universal Anomaly Inference (UAI) layer. This layer can be
incorporated on top of any deep learning based white box anomaly detection system which provides
an anomaly score for ranking anomalies. It takes as input both a latent representation layer (l(x)),
created by the model, and its output anomaly score (s(x)), and passes it through a classifier to find an
item’s anomaly probability.
sUai (x) = Panom (x) = classifier ([l(x); s(x)])	(2)
This is motivated by recent works stating learned representations have a simpler statistical structure
(Bengio et al., 2013), which makes the task of modeling this manifold and detecting unnatural points
much simpler (Lamb et al., 2018). In this work, we model the UAI layer using a simple logistic
regression as our classifier, but any architecture could be used here:
sUai (x) = Panom (x) = σ(Wact [l(x); s(x)] + bact)	(3)
where Wact ∈ R1,d+1 is a linear transformation, bact ∈ R is a bias term and σ(∙) is the sigmoid
function. We learn the values of W and b using back-propagation with a cross entropy loss function,
while allowing the gradients to flow through l, but not through s, since s might be non-differentiable.
For the rest of this document, we will refer to the networks with a UAI layer as UaiNets. An example
of this architecture is shown in Figure 1.
4	Experiments
In this section, we test our new UAI layer on top of two distinct architectures: a Denoising
AutoEncoder (DAE, with Sdae(X) = ||x 一 X∣∣2) and a Classifier (Class, with SClass(X) =
2Although this might seem like a simplistic approach, selecting the top k anomalies is a good strategy in
practical settings, since we want to have the most anomalies for any given budget. Besides, because anomaly
detection is already a highly imbalanced problem, we might not get anomalous instances even when picking
only the top anomalous results, so actively searching for them is usually a good choice. This approach follows
recent work in active anomaly detection (Veeramachaneni et al., 2016; Das et al., 2016; 2017)
4
Under review as a conference paper at ICLR 2019
cross_entropy(xy, xcy)), which use standard multi layer perceptrons. Both architectures are de-
scribed in details in Appendix A.1. To test our algorithm we start by analyzing its performance on
synthetic data created with different properties (Section 4.1). We then present results using UaiNets
on real anomaly detection datasets (Section 4.2) and in a semi-supervised setting (Section 4.3).
4.1	Synthetic Data
When designing experiments, we had the objective of showing that our model can work with different
definitions of anomaly, while completely unsupervised models will need, by definition, to trade-off
accuracy in one setting for accuracy in the other. While this may seem straight forward, these results
can show how robust our approach is to the choice of underlying architecture, analyzing how well
they do when their underlying architecture has a bad prior for that specific “type” of anomaly. With
this in mind, we used the MNIST dataset and defined four sets of experiments:3
1.	MNIST0: For the first set of experiments, we reduced the presence of the 0 digit class to only
10% of its original number of samples, making it only 1/91 ≈ 1.1% of the dataset samples.
The 0s still present in the dataset had its class randomly changed to Xy 〜Uniform([1; 9])
and were defined as anomalies.
2.	MNIST0-2 : The second set of experiments follows the same dataset construction, but we
reduce the number of instances of numbers 0, 1 and 2, changing the labels of the remaining
items in these categories to Xy 〜Uniform([3; 9]), and again defining them as anomalous.
In this dataset anomalies composed 3/73 ≈ 4.1% of the dataset.
3.	MNISThard : The third set of experiments aims to test a different type of anomaly. In order
to create this dataset, we first trained a weak one hidden layer MLP classifier on MNIST
and selected all misclassified instances as anomalous, keeping them in the dataset with their
original properties (Xx and Xy). In this dataset anomalies composed ≈ 3.3% of the dataset.
4.	MNISTpca: In this set of experiments, for each image class (Xy), we used a PCA to reduce
the dimensionality of MNIST images (Xx) to 2 and selected the 5% instances with the largest
reconstruction error as anomalies. We kept all 60,000 instances in the dataset with their
original properties (Xx and Xy) and in this dataset anomalies composed 5% of the dataset.
Results for these experiments are shown in Figure 3 and the main conclusion taken from them
is that, even though our algorithm might not get better results than its underlying model for every
budget-dataset pair, it is robust to different types of anomalies, which is not the case for the underlying
completely unsupervised models. While Class gives really good results in MNIST0 and MNIST0-2
datasets, it does not achieve the same performance in MNISThard and MNISTpca, which might indicate
it is better at finding clustered anomalies than low density ones. At the same time, DAE has good
results for MNISTpca and MNISThard, but bad ones for MNIST0 and MNIST0-2 , which indicates it is
better at finding low density anomalies than clustered ones. Nevertheless, both UaiNets are robust
in all four datasets, being able to learn even on datasets which are hard for their underlying models,
although they might have a cold start to produce results.
4.2	Real Data
Here we analyze our model’s performance on public benchmarks composed of real anomaly detection
datasets. We employ 11 datasets in our analysis: KDDCUP; Thyroid; Arrhythmia; KDDCUP-Rev;
Yeast; Abalone; Cardiotocography (CTG); Credit Card; Covtype; Mammography (MMG); Shuttle
(Lichman, 2013; Dheeru & Taniskidou, 2017; Pozzolo et al., 2015; Woods et al., 1993). We compare
our algorithm against: DAE (Vincent et al., 2008); DAGMM (Zong et al., 2018); LODA-AAD (Das
et al., 2016); and Tree-AAD (Das et al., 2017).4
3Implementation details, such as the used architecture and hyper-parameters can be found in Appendix A,
as well as further details about the synthetic MNIST datasets. Using MNIST for the generation of synthetic
anomaly detection datasets follows recent works (Zhou & Paffenroth, 2017; Zhai et al., 2016). Due to lack
of space we only report full results here, but the same plots zoomed in for small budgets (b ≤ 5000) can be
found in Appendix B.1. We also report the same experiments with similar results on Appendix B.3 for the
MNIST-Fashion dataset.
4Further descriptions of these datasets and baselines can be found in Appendix A.3, as well as descriptions
of the used architectures and hyper-parameters. More detailed results, standard deviations and comparison to
other baselines are presented in Appendix B.2.
5
Under review as a conference paper at ICLR 2019
(a) MNIST0
(b) MNIST0-2
(c) MNISThard	(d) MNISTpca
Figure 3: (Color online) Results for different MNIST experiments. Lines represent median of five
runs with different seeds and confidence intervals represent max and min results for each budget b.
Table 1 presents results for these real datasets. In these experiments, DAGMM (clean) was trained on
a semi-supervised anomaly detection setting, using clean datasets during training, DAGMM (dirty)
and DAE were trained in an unsupervised setting, while LODA-AAD, Tree-AAD and DAEuai
were trained in an active anomaly detection setting. We can clearly see from these results that
DAE produces fairly bad results for all datasets analyzed here, nevertheless, even using a simple
architecture as its underlying model, DAEuai produces similar or better results to the best baselines
on the 11 datasets, even when the baselines were trained in completely clean training sets. DAEuai
also usually presents better results than LODA-AAD and Tree-AAD, which are similarly trained in
an active setting.
One possible criticism to our method is that the importance of the proposed approach becomes more
relevant the fewer the proportion of anomalous instances, which seems self-defeating. But we see
that the largest difference from the active methods to the other algorithms was in Covtype, which has
less than 1% anomalies but 286,048 instances. When working with large datasets (>1M instances),
even if only 0.1% of the dataset is contaminated there is still the chance to benefit from this feedback
to improve performance. The active algorithms are also more robust than the others, DAGMM used
different hyperparameters for each experiment, while DAEuai and AAD use the same for all (except
for k which was reduced from 10 to 3 for the datasets with less than 100 anomalies).
4.3 A More Practical Anomaly Detection Setting
Another practical scenario where our model could be applied is a mixture of semi-supervised and
unsupervised anomaly detection. In this case, we have a dataset which contains anomalies that
we want to find and audit. At the same time, new data instances, which may include new types
of anomalies not seen before, can be added to the dataset at any time and we would like to detect
anomalies in this dataset as well.
Dtrain
Dtest
Xtrain 〜PfUll(X) = (I ― λ)pnormal (x) + λpanom (X)
Xtest 〜PfUll (X) = (I ― λ1 一入2)P normal (X) + λ1panom (X) + λ2p anom _new
(X)
With this in mind, we ran an experiment training DAEUai and LODA-AAD on KDDCUP-Rev in
the same way as in Section 4.2, while evaluating it on its test set for different budgets. This test set
6
Under review as a conference paper at ICLR 2019
Table 1: Results on Real Datasets showing average F1 scores of five independent runs.
Train Set	KDDCUP	Arrhythmia	Thyroid	KDDCUP-Rev	Yeast
# Instances	494,021	3,772	452	121,597	1,191
# Features	120	6	274	120	8
# Anomalies (%)	97,278 (20%)	93 (2.5%)	66 (15%)	24,319 (20%)	55 (4.6%)
DAGMM (clean)	0.94	050	0.44	0.94	0.11
DAGMM (dirty)	0.43	0.46	0.46	0.31	0.02
LODA-AAD	0.88	0.45	0.51	0.83	0.31
Tree-AAD	0.89	0.29	0.86	0.50	0.32
DAE	0.39	0.35	0.09	0.16	0.23
DAEuai	0.94	0.47	0.57	0.91	0.33
Train Set	Abalone	CTG	Credit Card	CovtyPe	MMG	Shuttle
# Instances	1,920	1,700	-^284,807^^	286,048	11,183	12,345
# Features	9	22	30	54	6	9
# Anomalies (%)	29 (1.5%)	45 (2.6%)	492 (0.17%)	2,747 (0.9%)	260 (2.3%)	867 (7.0%)
DAGMM (clean)	0.16	0.27	034	0.18	0.07	0.48
DAGMM (dirty)	0.05	0.18	0.31	0.01	0.00	0.48
LODA-AAD	0.54	0.52	0.57	0.97	0.42	0.97
Tree-AAD	0.53	0.69	0.76	0.94	0.59	0.92
DAE	0.08	0.13	0.36	0.15	0.27	0.17
DAEuai	0.55	0.66	0.64	0.86	0.60	0.93
contains 20 new types of anomalies (the train set contains 16 types of anomalies and the test set 36).
The evaluation was done by selecting the most anomalous instances found by each model on the
test set and calculating the recall for both seen and unseen anomalies in that group. Results for this
experiment can be seen in Figure 4. In this figure, the right y axis shows the number of anomalies
detected in the training set for a certain budget and corresponds to the light blue lines. The left y axis
present the recall for the test dataset. We see that DAGMM is not so effective on this test set, while
DAE is able to detect well novelty (new classes). We also see that DAEuai is significantly better
at detecting known types of anomalies, while it maintains a recall close to the best on new unseen
classes, giving better results than LODA-AAD for both seen and unseen classes of anomalies.
80
§60
+j
①
S
E 40
t
ω 20
0
Budget [b] (102)
Figure 4: Semi supervised experiment. This test set contains 67,908 instances, out of which 3,817 are
previously seen anomalies and 3,498 unseen, totaling 7,315 anomalies. These results show how the
Recall@7315 on the test set improve, for both seen and unseen classes of anomalies, as the budget
increases during the active training.(Left) Anomalies in training set. (Right) New (unseen) anomalies.
5	Related Works
Anomaly Detection This field has been amply studied and good overviews can be found in (Hodge
& Austin, 2004; Chandola et al., 2009). Although many algorithms have been recently proposed,
classical methods for outlier detection, like LOF Breunig et al. (2000) and OC-SVM (SchGlkoPf et al.,
2001), are still used and produce good results. Recent work on anomaly detection has focused on
statistical ProPerties of “normal” data to identify these anomalies, such as Maurus & Plant (2017),
which uses Benford’s Law to identify anomalies in social networks, and (Siffer et al., 2017), which
uses Extreme Value Theory to detect anomalies. Other works focus on sPecific tyPes of data, (Zheng
7
Under review as a conference paper at ICLR 2019
et al., 2017) focuses on spatially contextualized data, while (Perozzi et al., 2014; Perozzi & Akoglu,
2016; Li et al., 2017; Liu et al., 2017) focus on graph data. Recently, energy based models (Zhai
et al., 2016) and GANs (Schlegl et al., 2017) have been successfully used to detect anomalies, but
autoencoders are still more popular in this field. Zhou & Paffenroth (2017) propose a method to train
robust autoencoders, drawing inspiration from robust statistics (Huber, 2011) and more specifically
robust PCAs, (Yang et al., 2017) focuses on clustering, and trains autoencoders that generate latent
representations which are friendly for k-means. The work most similar to ours is DAGMM (Zong
et al., 2018), where they train a deep autoencoder and use its latent representations, together with
its reconstruction error, as input to a second network, which they use to predict the membership
of each data instance to a mixture of gaussian models, training the whole model end-to-end in an
semi-supervised manner for novelty detection.
Active Anomaly Detection Despite its many advantages, active anomaly detection remains an
under-explored approach to this problem, nevertheless, over the years some really interesting work has
been developed in this topic. In (Pelleg & Moore, 2005), the authors solve the rare-category detection
problem by proposing an active learning strategy to datasets with extremely skewed distributions of
class sizes. Abe et al. (2006) reduces outlier detection to classification using artificially generated
examples that play the role of potential outliers and then applies a selective sampling mechanism
based on active learning to the reduced classification problem. In (GOrnitz et al., 2013), the authors
proposed a Semi-Supervised Anomaly Detection (SSAD) method based in Support Vector Data
Description (SVDD) (Tax & Duin, 2004), which he expanded to a semi-supervised setting, where
he accounts for the presence of labels for some anomalous instances, and with an active learning
approach to select these instances to label. Veeramachaneni et al. (2016) propose an active approach
that combines unsupervised and supervised learning to select items to be labeled by experts, with
each approach selecting 2 instances at a time. The most similar prior works to ours in this setting
are (Das et al., 2016), which proposed an algorithm that can be employed on top of any ensemble
methods based on random projections, and (Das et al., 2017), which expands Isolation Forests to work
in an active setting. Our work differs from these prior works mainly in that we prove the necessity
of priors for unsupervised anomaly detection, further motivating the Active Anomaly Detection
framework, and in our proposed model. UAI layers can be assembled on top of any Deep Learning
based anomaly detection architecture, which is the state of the art for unsupervised anomaly detection,
to make it work in an active anomaly detection setting. Besides, after each iteration with experts both
LODA-AAD and Tree-AAD have a time complexity O(t), where t is the number of already labeled
instances, while each iteration of UaiNets runs in constant time O(1) with respect to t.
6	Discussions and Future Work
We proposed here a new architecture, Universal Anomaly Inference (UAI), which can be applied
on top of any deep learning based anomaly detection architecture. We show that, even on top of
very simple architectures, like a DAE, UaiNets can produce similar/better results to state-of-the-art
unsupervised/semi-supervised anomaly detection methods. We also give both theoretical and practical
arguments motivating active anomaly detection, arguing that, in most practical settings, there would
be no detriment to using this instead of a fully unsupervised approach.
We further want to make clear that we are not stating our method is better than our semi-supervised
baselines (DAGMM, DCN, DSEBM-e). Our contributions are orthogonal to theirs. We propose a new
approach to this hard problem which can be built on top of them, this being our main contribution
in this work. To the best of our knowledge, this is the first work which applies deep learning to
active anomaly detection. We use the strongest points of these deep learning algorithms (their
learned representations and anomaly scores) to build an active algorithm, presenting an end-to-end
architecture which learns representations by leveraging both the full dataset and the already labeled
instances.
Important future directions for this work are using the UAI layers confidence in its output to dynami-
cally choose between either directly using its scores, or using the underlying unsupervised model’s
anomaly score to choose which instances to audit next. Another future direction would be testing new
architectures for UAI layers, in this work we restricted all our analysis to simple logistic regression.
A third important future work would be analyzing the robustness of UaiNets to mistakes being made
by the labeling experts. Finally, making this model more interpretable, so that auditors could focus
on a few “important” features when labeling anomalous instances, could increase labeling speed and
make their work easier.
8
Under review as a conference paper at ICLR 2019
References
Martin Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin,
Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat
Monga, Sherry Moore, Derek Gordon Murray, Benoit Steiner, Paul A. Tucker, Vijay Vasudevan,
Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Tensorflow: A system for large-scale
machine learning. In OSDI, volume 16, pp. 265-283, 2016.
Naoki Abe, Bianca Zadrozny, and John Langford. Outlier detection by active learning. In Proceedings
of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pp.
504-509. ACM, 2006.
Charu C Aggarwal. Outlier analysis. In Data mining, pp. 237-263. Springer, 2015.
Bryon Aragam, Chen Dan, Pradeep Ravikumar, and Eric P Xing. Identifiability of nonparametric
mixture models and bayes optimal clustering. arXiv preprint arXiv:1802.04397, 2018.
Yoshua Bengio, Gr6goire Mesnil, Yann Dauphin, and Salah Rifai. Better mixing via deep representa-
tions. In International Conference on Machine Learning, pp. 552-560, 2013.
Laurent Bordes, StePhane Mottelet, Pierre Vandekerkhove, et al. Semiparametric estimation of a
two-component mixture model. The Annals of Statistics, 34(3):1204-1232, 2006.
Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and Jorg Sander. Lof: identifying density-
based local outliers. In ACM sigmod record, volume 29, pp. 93-104. ACM, 2000.
Varun Chandola, Arindam Banerjee, and Vipin Kumar. Anomaly detection: A survey. ACM computing
surveys (CSUR), 41(3):15, 2009.
Yunqiang Chen, Xiang Sean Zhou, and Thomas S Huang. One-class svm for learning in image
retrieval. In Image Processing, 2001. Proceedings. 2001 International Conference on, volume 1,
pp. 34-37. IEEE, 2001.
Shubhomoy Das, Weng-Keen Wong, Thomas Dietterich, Alan Fern, and Andrew Emmott. Incorpo-
rating expert feedback into active anomaly discovery. In International Conference on Data Mining
(ICDM), pp. 853-858. IEEE, 2016.
Shubhomoy Das, Weng-Keen Wong, Alan Fern, Thomas G Dietterich, and Md Amran Siddiqui. In-
corporating feedback into tree-based anomaly detection. Workshop on Interactive Data Exploration
and Analytics (IDEA), 2017.
Anirban Dasgupta, John Hopcroft, Jon Kleinberg, and Mark Sandler. On learning mixtures of
heavy-tailed distributions. In Foundations of Computer Science, 2005. FOCS 2005. 46th Annual
IEEE Symposium on, pp. 491-500. IEEE, 2005.
Dua Dheeru and Efi Karra Taniskidou. UCI machine learning repository, 2017. URL http:
//archive.ics.uci.edu/ml.
Nico Gornitz, Marius Kloft, Konrad Rieck, and Ulf Brefeld. Toward supervised anomaly detection.
Journal of Artificial Intelligence Research, 46:235-262, 2013.
Frank E Grubbs. Procedures for detecting outlying observations in samples. Technometrics, 11(1):
1-21, 1969.
Douglas M Hawkins. Identification of outliers, volume 11. Springer, 1980.
Victoria Hodge and Jim Austin. A survey of outlier detection methodologies. Artificial intelligence
review, 22(2):85-126, 2004.
Peter J Huber. Robust statistics. In International Encyclopedia of Statistical Science, pp. 1248-1251.
Springer, 2011.
Alex Lamb, Jonathan Binas, Anirudh Goyal, Dmitriy Serdyuk, Sandeep Subramanian, Ioannis
Mitliagkas, and Yoshua Bengio. Fortified networks: Improving the robustness of deep networks by
modeling the manifold of hidden representations. arXiv preprint arXiv:1804.02485, 2018.
9
Under review as a conference paper at ICLR 2019
Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and F Huang. A tutorial on energy-based
learning. Predicting structured data, 1(0), 2006.
Jundong Li, Harsh Dani, Xia Hu, and Huan Liu. Radar: Residual analysis for anomaly detection
in attributed networks. In Proceedings of the 26th International Joint Conference on Artificial
Intelligence,pp. 2152-2158. AAAI Press, 2017.
Moshe Lichman. Uci machine learning repository, 2013.
Ninghao Liu, Xiao Huang, and Xia Hu. Accelerated local anomaly detection via resolving attributed
networks. In Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp.
2337-2343. AAAI Press, 2017.
Samuel Maurus and Claudia Plant. Let’s see your digits: Anomalous-state detection using benford’s
law. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining, pp. 977-986. ACM, 2017.
Dan Pelleg and Andrew W Moore. Active learning for anomaly and rare-category detection. In
Advances in neural information processing systems, pp. 1073-1080, 2005.
Bryan Perozzi and Leman Akoglu. Scalable anomaly ranking of attributed neighborhoods. In
Proceedings of the 2016 SIAM International Conference on Data Mining, pp. 207-215. SIAM,
2016.
Bryan Perozzi, Leman Akoglu, Patricia Iglesias Sdnchez, and Emmanuel Muller. Focused clustering
and outlier detection in large attributed graphs. In Proceedings of the 20th ACM SIGKDD
international conference on Knowledge discovery and data mining, pp. 1346-1355. ACM, 2014.
Tomas Pevny. Loda: Lightweight on-line detector of anomalies. Machine Learning, 102(2):275-304,
2016.
Andrea Dal Pozzolo, Olivier Caelen, Reid Johnson, and Gianluca Bontempi. Calibrating probability
with undersampling for unbalanced classification, 12 2015.
Thomas Schlegl, Philipp Seebock, Sebastian M Waldstein, Ursula Schmidt-Erfurth, and Georg Langs.
Unsupervised anomaly detection with generative adversarial networks to guide marker discovery.
In International Conference on Information Processing in Medical Imaging, pp. 146-157. Springer,
2017.
Bernhard Scholkopf, John C Platt, John Shawe-Taylor, Alex J Smola, and Robert C Williamson.
Estimating the support of a high-dimensional distribution. Neural computation, 13(7):1443-1471,
2001.
Burr Settles. Active learning. Synthesis Lectures on Artificial Intelligence and Machine Learning, 6
(1):1-114, 2012.
Alban Siffer, Pierre-Alain Fouque, Alexandre Termier, and Christine Largouet. Anomaly detection
in streams with extreme value theory. In Proceedings of the 23rd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 1067-1075. ACM, 2017.
David MJ Tax and Robert PW Duin. Support vector data description. Machine learning, 54(1):45-66,
2004.
Kalyan Veeramachaneni, Ignacio Arnaldo, Vamsi Korrapati, Constantinos Bassias, and Ke Li. Ai^ 2:
training a big data machine to defend. In International Conference on Big Data Security on Cloud
(BigDataSecurity), pp. 49-54. IEEE, 2016.
Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting and
composing robust features with denoising autoencoders. In International Conference on Machine
learning, pp. 1096-1103. ACM, 2008.
Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine Manzagol.
Stacked denoising autoencoders: Learning useful representations in a deep network with a local
denoising criterion. Journal of Machine Learning Research, 11(Dec):3371-3408, 2010.
10
Under review as a conference paper at ICLR 2019
Kevin S Woods, Christopher C Doss, Kevin W Bowyer, Jeffrey L Solka, Carey E Priebe, and
W Philip Kegelmeyer Jr. Comparative evaluation of pattern recognition techniques for detection of
microcalcifications in mammography. International Journal of Pattern Recognition and Artificial
Intelligence ,7(06):1417-1436,1993.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms, 2017.
Bo Yang, Xiao Fu, Nicholas D Sidiropoulos, and Mingyi Hong. Towards k-means-friendly spaces:
Simultaneous deep learning and clustering. In International Conference on Machine Learning, pp.
3861-3870, 2017.
Shuangfei Zhai, Yu Cheng, Weining Lu, and Zhongfei Zhang. Deep structured energy based models
for anomaly detection. arXiv preprint arXiv:1605.07717, 2016.
Guanjie Zheng, Susan L Brantley, Thomas Lauvaux, and Zhenhui Li. Contextual spatial outlier
detection with metric learning. In Proceedings of the 23rd ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pp. 2161-2170. ACM, 2017.
Chong Zhou and Randy C Paffenroth. Anomaly detection with robust deep autoencoders. In
Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, pp. 665-674. ACM, 2017.
Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, and Haifeng
Chen. Deep autoencoding gaussian mixture model for unsupervised anomaly detection. In
International Conference on Learning Representations, 2018.
11
Under review as a conference paper at ICLR 2019
A Experiments Descriptions
In this section we give detailed descriptions of the experiments. Section A.1 presents the used
model architectures for both DAE and Class models, as well as DAEuai and Classuai . Section
A.2 presents details on the synthetic MNIST datasets and on the hyper-parameters used for the
experiments. Finally, Section A.3 contains detailed descriptions on the used datasets, baselines and
experimental settings for the experiments on real anomaly detection datasets.
A.1 Model Architectures
To show our algorithm can be assembled on top of any deep learning model, we tested it using two
simple but very different anomaly detection models. The first model we test it on top of is a normal
Denoising AutoEncoder (DAE). A DAE is a neural network mainly composed by an encoder, which
transforms the input into a latent space, and a decoder, which reconstructs the input using this latent
representation, typically having a loss function that minimizes the reconstruction error L2 norm:
l = fenc(x + E) C 〜N(O, ψ)
X = fdec(l)
L = ||x - x||2
(4)
where both fenc and fdec are usually feed forward networks with the same number of layers, l ∈ Rd is
a d-dimensional latent representation and C is a zero mean noise, sampled from a Gaussian distribution
with a 夕 standard deviation. When used in anomaly detection, the reconstruction error is usually used
as an approximation of the inverse of an item’s probability, and as its anomaly score:
Sdae(X) = P(X)
||x - x||2
(5)
We then create a DAEuai network by assembling the proposed UAI layer on top of the DAE:
ldae
sdae-uai
= l = fenc (X + C)
(X) = uai([ldae; sdae])
(6)
where uai(∙) is the classifier chosen for the UAI layer. This architecture can be seen in Figure 1.
Another typical approach to unsupervised anomaly detection is, when given a dataset with labeled
data X = (Xx, Xy), training a classifier (Class) to predict Xy from Xx5 and using the cross-entropy
of an item as an approximation to the inverse of its probability distribution:
sclass (X)
—
Xcy
fclass (X)
cross_entropy(Xy, Xcy)
pχ = Cross_entroPy(Xy ,C)
(7)
L
where fclass (∙) is typically a feed forward neural network with P layers, from which we can use its
last hidden layer (hp-1) as the data’s latent representation to be used in the Classuai.
lclass = hp-1
sclass-uai (X) = uai([lclass ; sclass])
(8)
This architecture can be seen in Figure 5. For all experiments in this work, unless otherwise stated,
the DAE’s encoder and decoder had independent weights and we used both the DAE and Class
models with 3 hidden layers and hidden sizes [256, 64, 8]. This means the latent representations
provided to the UAI layers are l ∈ R8 . We implemented all experiments using TensorFlow (Abadi
et al., 2016), and used a learning rate of 0.01, batch size of 256 and the RMSprop optimizer with the
default hyper-parameters. For the active learning models, we pre-train the DAE/Class model for 5000
optimization steps, select k = 10 items to be labeled at a time, and further train for 100 iterations
after each labeling call. To deal with the cold start problem, for the first 10 calls of select_top, we use
the base anomaly score (s) of the DAE/Class model to make this selection, using the UAI one for
all later labeling decisions.
5Note that, even though in this problem we have class labels (xy), we have no anomaly labels of objects (y),
so this is still an unsupervised anomaly detection problem.
12
Under review as a conference paper at ICLR 2019
Table 2: MNIST Anomaly Datasets Statistics
	# Dimensions	# Classes	# Instances	# Anomalies	Anomaly Ratio
MNIST0	784	9	-^54,679^^	602	1.1%
MNIST0-2	784	7	43,199	1,822	4.2%
MNISThard	784	10	60,000	2,108	3.5%
MNISTpca	784	10	60,000	2,996	5%
A.2 Synthetic Data
Detailed statistics on the synthetic MNIST datasets can be seen in Table 2. MNIST0 and MNIST0-2
were mainly generated with the purpose of simulating the situation in Figure 2 (Center), where
anomalies were present in sparse clusters. At the same time, MNISThard and MNISTpca were designed
to present similar characteristics to the situation in Figure 2 (Right), where anomalous instances are
in sparse regions of the data space.
A.3 Real Data
For these experiments, most datasets were used as suggested in (Dheeru & Taniskidou, 2017), but we
processed the KDDCUP, Thyroid, Arrhythmia and KDDCUP-Rev datasets in the same manner as
(Zong et al., 2018) to be able to better compare with their results:
•	KDDCUP (Lichman, 2013): The KDDCUP99 10 percent dataset from the UCI repository.
Since it contains only 20% of instances labeled as “normal” and the rest as “attacks”,
“normal” instances are used as anomalies, since they are in a minority group. This dataset
contains 34 continuous features and 7 categorical ones. We transform these 7 categorical
features into their one hot representations, and obtain a dataset with 120 features.
•	Thyroid (Lichman, 2013): A dataset containing data from patients which can be divided
in three classes: normal (not hypothyroid), hyperfunction and subnormal functioning. In
this dataset, we treat the hyperfunction class as an anomaly, with the other two being treated
as normal. It can be obtained from the ODDS repository.6
•	Arrhythmia (Lichman, 2013): This dataset was designed to create classification algorithms
to distinguish between the presence and absence of cardiac arrhythmia. In it, we use the
6http://odds.cs.stonybrook.edu
13
Under review as a conference paper at ICLR 2019
smallest classes (3, 4, 5, 7, 8, 9, 14, and 15) as anomalies and the others are treated as
normal. This dataset can also be obtained from the ODDS repository.
•	KDDCUP-Rev (Lichman, 2013): Since “normal” instances are a minority in the KDDCUP
dataset, we keep all “normal” instances and randomly draw “attack” instances so that they
compose 20% of the dataset.
We compare our algorithm against:
•	DAE (Vincent et al., 2008): Denoising Autoencoders are autoencoder architectures which
are trained to reconstruct instances from noisy inputs.
•	DAGMM (Zong et al., 2018): Deep Autoencoding Gaussian Mixture Model is a state-
of-the-art model for semi-supervised anomaly detection which simultaneously learns a
latent representation, using deep autoencoders, and uses both this latent representation
and the autoencoder’s reconstruction error to learn a Gaussian Mixture Model for the data
distribution.
•	LODA-AAD (Das et al., 2016): Lightweight on-line detector of anomalies (LODA) Active
Anomaly Discovery (AAD) is a work which uses the active anomaly detection framework
on top of LODA (Pevny, 2016), which is a method based on ensembles of weak anomaly
detection models.
•	Tree-AAD (Das et al., 2017): This work learns weights for each node in an Isolation
Forest anomaly detection model, by incorporating knowledge gained through active anomaly
detection.
Since there is no validation/test set in unsupervised anomaly detection, we cannot tune hyperparame-
ters on a validation set. Because of this, to make the DAE baselines more competitive, we got the
results for several different hyper-parameter configurations and present only the best among them.
This is not a realistic approach, but we only do it to our baselines, while for our proposed algorithm we
keep hyper-parameters fixed for all experiments. We even keep our hidden sizes fixed to [256, 64, 8]
on thyroid, which only contains 6 features per instance, since our objective here is not getting the
best possible results, but showing the robustness of our approach. The only hyper-parameter change
we make in UAI networks is that, since there are fewer anomalies in some datasets, we set our active
learning approach to choose k = 3 instances at a time, instead of 10, for datasets with less than 100
anomalies.
Results for DAGMM are from our implementation of this model and follow the same procedures,
architectures and hyper-parameters as described in (Zong et al., 2018), being trained in a semi-
supervised setting. The results for LODA-AAD and Tree-AAD were run using the code made
available by the authors and with the same steps as DAEuai.7 For all experiments, results for
LODA-AAD, Tree-AAD, DAE and DAEuai used the number of anomalies in the dataset as the
budget b.
B	Detailed Results
In this section, we present more detailed results for both the synthetic (Section B.1) and real (Section
B.2) anomaly detection datasets, which couldn’t fit on the main paper due to lack of space. We also
present results for synthetic anomaly detection experiments on Fashion-MNIST (Section B.3).
B.1 Detailed Results on MNIST
We present here detailed results for small budgets (b ≤ 5000) on the MNIST experiments, with
graphs zoomed in for these budget values. Analyzing Figure 6 we see that for some of these datasets
UaiNets present a cold start, producing worse results for small budgets. Nonetheless, after this cold
start, they produce better results in all MNIST experiments. An interesting future work would be to
measure the confidence in the UaiNet’s prediction to dynamically choose between using its anomaly
score or the underlying network’s one, which could solve/reduce this cold start problem.
7https://github.com/shubhomoydas/ad_examples
14
Under review as a conference paper at ICLR 2019
O O
O O
4 3
tipEOU #
1000	2000	3000	4000
Budget (b)
1750
1500
1250
E 1000
O
o
# 750
500
250
0
5000	0	1000	2000	3000	4000	5000
Budget (b)
1200
1000
----ClBSSual
DAEuβ∣
----Class
——DAE
(a) MNIST0
tiωbou #
tiωboo ⅛
(b) MNIST0-2
0	1000	2000	3000	4000	5000	0	1000	2000	3000	4000	5000
Budget (b)	Budget (b)
(c) MNISThard	(d) MNISTpca
Figure 6: (Color online) Results for MNIST experiments zoomed in for b ≤ 5000 on the x-axis.
Lines represent median of five runs with different seeds and confidence intervals represent max and
min results for each budget b.
B.2	Detailed Results on Real Data
Table 3 presents a detailed comparison for experiments ran on KDDCUP, Thyroid, Arrhythmia
and KDDCUP-Rev datasets with other baselines, also showing precision, recall and their standard
deviations. In this table we also compare our results to:
•	OC-SVM (Chen et al., 2001): One-class support vector machines are a popular kernel based
anomaly detection method. In this work, we employ it with a Radial Basis Function (RBF)
kernel.
•	DCN (Yang et al., 2017): Deep Clustering Network is a state-of-the-art clustering algorithm.
Its architecture is designed to learn a latent representation using deep autoencoders which is
easily separable when using k-means.
•	PAE (Vincent et al., 2008): Denoising AutoEncoders pretrained as suggested in (Vincent
et al., 2010).
•	DSEBM-e (Zhai et al., 2016): Deep Structured Energy Based Models are anomaly detection
systems based on energy based models (LeCun et al., 2006), which are a powerful tool for
density estimation. We compare here against DSEBM-e, which uses a data instance’s energy
as the criterion to detect anomalies.
•	DSEBM-r (Zhai et al., 2016): Deep Structured Energy Based Model with the same archi-
tecture and training procedures as DSEBM-e, but using an instance’s reconstruction error as
the criterion for anomaly detection.
The results presented here are averages of five runs, with standard deviations in parenthesis. In this
table, results for OC-SVM, PAE, DSEBM-r, DSEBM-e, DCN and DAGMM were taken from (Zong
15
Under review as a conference paper at ICLR 2019
Table 3: Detailed results on real datasets showing mean and standard deviations of five runs.
Dataset	Method	Anomalies in Train Set	Precision	Recall	F1
	OC-SVM	0%	07457	0.8523	0.7954
	OC-SVM	5%	0.1155	0.3369	0.1720
	PAE	0%	0.7276	0.7397	0.7336
	DSEBM-r	0%	0.1972	0.2001	0.1987
	DSEBM-e	0%	0.7369	0.7477	0.7423
	DSEBM-e	5%	0.5345	0.5375	0.5360
	DCN	0%	0.7696	0.7829	0.7762
KDDCUP	DCN	5%	0.6763	0.6893	0.6827
	DAGMM	0%	0.9297	0.9442	0.9369
	DAGMM	5%	0.8504	0.8643	0.8573
	DAGMM*	0%	0.9290 (0.0344)	0.9435 (0.0349)	0.9362 (0.0346)
	DAGMM*	5%	0.8827 (0.0682)	0.8965 (0.0693)	0.8896 (0.0688)
	DAGMM*	20%	0.4238 (0.0187)	0.4304 (0.0190)	0.4271 (0.0188)
	LODA-AAD	20%	0.8756 (0.1255)	0.8756 (0.1255)	0.8756 (0.1255)
	Tree-AAD	20%	0.8940 (0.0261)	0.8940 (0.0261)	0.8940 (0.0261)
	DAE	20%	0.3905 (0.2581)	0.3905 (0.2581)	0.3905 (0.2581)
	DAEuai	20%	0.9401 (0.0191)	0.9401 (0.0191)	0.9401 (0.0191)
	OC-SVM	0%	0.3639	0.4239	0.3887
	PAE	0%	0.1894	0.2062	0.1971
	DSEBM-r	0%	0.0404	0.0403	0.0403
	DSEBM-e	0%	0.1319	0.1319	0.1319
	DCN	0%	0.3319	0.3196	0.3251
Thyroid	DAGMM	0%	0.4766	0.4834	0.4782
	DAGMM*	0%	0.4375 (0.1926)	0.4468 (0.1967)	0.4421 (0.1947)
	DAGMM*	0.5%	0.2875 (0.1505)	0.2936 (0.1537)	0.2905 (0.1521)
	DAGMM*	2.5%	0.4542 (0.2995)	0.4638 (0.3059)	0.4590 (0.3027)
	LODA-AAD	2.5%	0.5097 (0.0712)	0.5097 (0.0712)	0.5097 (0.0712)
	Tree-AAD	2.5%	0.8586 (0.0087)	0.8586 (0.0087)	0.8586 (0.0087)
	DAE	2.5%	0.0860 (0.0725)	0.0860 (0.0725)	0.0860 (0.0725)
	DAEuai	2.5%	0.5742 (0.0582)	0.5742 (0.0582)	0.5742 (0.0582)
	OC-SVM	0%	0.5397	0.4082	0.4581
	PAE	0%	0.4393	0.4437	0.4403
	DSEBM-r	0%	0.1515	0.1513	0.1510
	DSEBM-e	0%	0.4667	0.4565	0.4601
	DCN	0%	0.3758	0.3907	0.3815
Arrhythmia	GADMM	0%	0.4909	0.5078	0.4983
	GADMM*	0%	0.4902 (0.0514)	0.5051 (0.0530)	0.4975 (0.0522)
	GADMM*	3%	0.4530 (0.0573)	0.4666 (0.0591)	0.4597 (0.0582)
	GADMM*	15%	0.4500 (0.0597)	0.4636 (0.0615)	0.4567 (0.0606)
	LODA-AAD	15%	0.4485 (0.0136)	0.4485 (0.0136)	0.4485 (0.0136)
	Tree-AAD	15%	0.2882 (0.0257)	0.2882 (0.0257)	0.2882 (0.0257)
	DAE	15%	0.3485 (0.0392)	0.3485 (0.0392)	0.3485 (0.0392)
	DAEuai	15%	0.4727 (0.0225)	0.4727 (0.0225)	0.4727 (0.0225)
	OC-SVM	0%	0.7148	0.9940	0.8316
	PAE	0%	0.7835	0.7817	0.7826
	DSEBM-r	0%	0.2036	0.2036	0.2036
	DSEBM-e	0%	0.2212	0.2213	0.2213
	DCN	0%	0.2875	0.2895	0.2885
KDDCUP-Rev	GADMM	0%	0.9370	0.9390	0.9380
	GADMM*	0%	0.9391 (0.1553)	0.9391 (0.1553)	0.9391 (0.1553)
	GADMM*	5%	0.3184 (0.1358)	0.3559 (0.2096)	0.3341 (0.1658)
	GADMM*	20%	0.3051 (0.1059)	0.3053 (0.1060)	0.3052 (0.1059)
	LODA-AAD	20%	0.8339 (0.1081)	0.8339 (0.1081)	0.8339 (0.1081)
	Tree-AAD	20%	0.5032 (0.2984)	0.5032 (0.2984)	0.5032 (0.2984)
	DAE	20%	0.1626 (0.0609)	0.1626 (0.0609)	0.1626 (0.0609)
	DAEuai	20%	0.9117 (0.0160)	0.9125 (0.0170)	0.9121 (0.0165)
et al., 2018), while DAGMM* are results from our implementation of DAGMM. Unfortunately, We
were not able to reproduce their results in the Thyroid dataset, getting a high variance in the results.
LODA-AAD does not scale well to large datasets, so to run it on KDDCUP and KDDCUP-Rev we
needed to limit its memory about the anomalies it had already learned, forgetting the oldest ones.
This reduced its runtime complexity from O(b2) to O(b) in our tests, where b is the budget limit for
the anomaly detection task. We did the same (limit memory) for Tree-AAD on KDDCUP.
16
Under review as a conference paper at ICLR 2019
On this table we can see that DAEuai produces better results than LODA-AAD on all analyzed
datasets and than Tree-AAD on three out of four. Our proposed method also, besides presenting
results comparable to state-of-the-art DAGMM trained on a clean dataset, is much more stable, having
a lower standard deviation than the baselines in almost all datasets.
B.3	Experiments on Fashion-MNIST
In this Section, we present results for experiments on synthetic anomaly detection datasets based
on Fashion-MNIST (Xiao et al., 2017). To create these datasets we follow the same procedures as
done for MNIST in Section 4.1, generating four datasets: Fashion-MNIST0; Fashion-MNIST0-2;
Fashion-MNISThard ; Fashion-MNISTpca. Detailed statistics of these datasets can be seen in Table 4.
Table 4: Fashion-MNIST Anomaly Datasets Statistics
	# Dimensions	# Classes	# Instances	# Anomalies	Anomaly Ratio
Fashion-MNIST0	784	9	54,610	610	1.1%
Fashion-MNIST0-2	784	7	43,765	1,765	4.0%
Fashion-MNISThard	784	10	60,000	9,656	16.1%
Fashion-MNISTpca	784	10	60,000	3,000	5.0%
We run experiments on these datasets following the exact same procedures as in Section 4.1. Figure 7
shows the results for Fashion-MNIST0 and Fashion-MNIST0-2, while Figure 8 show the results
for Fashion-MNISThard and Fashion-MNISTpca. These figures show similar trends to the ones for
MNIST, although algorithms find anomalies in these datasets harder to identify. In one run of
Fashion-MNIST0, DAEuai needed several examples to start learning and for Fashion-MNISThard,
Classuai takes a long time to start producing better results than Class. Nevertheless, UaiNets are
still much more robust than the underlying networks to different types of anomalies, producing good
results in all four datasets, even when its underlying network gives weak results on that dataset.
C	Further Analysis
In this section we further study UaiNets, analyzing the evolution of hidden representations and
anomaly scores through training (Section C.1), and the dependence of results on the number of
audited anomalies (Section C.2).
C.1 Learned Representations and Anomaly Scores
In this section, we show visualizations of the learned representations (ldae/class) and anomaly scores
(sdae/class) of UaiNets’ underlying networks, presenting their evolution as more labels are fed into
the network through the active learning process. With this purpose, we retrain UaiNets on both
MNIST0-2 and MNISThard, with a hidden size of [256, 64, 1], so that its latent representation is one
dimensional (l(x) ∈ R1), and plot these representations vs the anomaly scores (s) of the base network
(either DAE or Class) for different budgets (b).
Figure 9 shows the evolution of DAEuai’s underlying ldae(x) and sdae(x). In it, we can see that
initially (Figures 9 (a, d)) anomalies and normal data instances are not separable in this space.
Nevertheless, with only a few labeled instances (b = 250) the space becomes much easier to separate,
while for b = 2000 the space is almost perfectly linearly separable.8
Figure 10 shows the same evolution for Classuai’s underlying lclass(x) and sclass(x). In it, we can
also see the same patterns, as initially anomalies and normal data instances are not separable, but
with a few labeled instances anomalies become much more identifiable.
The main conclusion taken from these visualizations is how the gradient flow through l is important,
since it helps the network better separate data in these spaces, allowing good performance even when
the underlying networks are not good at identifying a specific type of anomaly.
8 Gifs showing this choice evolution will be made available with the final publication.
17
Under review as a conference paper at ICLR 2019
1000	2000	3000	4000	5000
Budget (b)
0
0	10000	20000	30000	40000	50000
Budget (b)
(b) Fashion-MNIST0
(a) Fashion-MNIST0 (b < 5000)
15
500
250
0
Classug∣
DAEuet
Class
DAE
random
tiωbou #
O	IOOO 2000	3000	4000	5000	O	IOOOO 20000	30000	40000
Budget (b)	Budget (b)
(c) Fashion-MNIST0-2 (b < 5000)	(d) Fashion-MNIST0-2
Figure 7:	(Color online) Results for Fashion-MNIST0 and Fashion-MNIST0-2 with different zooms
on x-axis. Lines represent median of five runs with different seeds and confidence intervals represent
max and min results for each budget b.
C.2 Anomaly Choices Evolution through Training
This experiments aim at showing how the networks choice quality evolves with the access to more
labels. Here, we present the choices DAEuai network would make having access to a fixed number
of expert labels. With this in mind, we train the networks in the same way as in Section 4.2, but stop
after reaching a specific budget (b), showing the choices made up to that point, and after that with no
further training.
Figure 11 shows the evolution of DAEuai anomaly choices as it is fed more expert knowledge.
We can see that with only a few labels it already fairs a lot better than its underlying network. In
KDDCUP with only 3,000 labeled instances, which is less than 1% of the dataset, it can correctly
find 80,000 anomalies with a high precision, while the DAE with no expert knowledge does a lot
worse. On Thyroid and KDDCUP-Rev, with ≈ 10% of the dataset labeled (b = 531 and b = 4000,
respectively) it finds all or almost all anomalies in the dataset correctly. The Arrhythmia dataset is a
lot smaller and with few anomalies, so DAEuai improves on DAE in a smaller scale here, but it still
does fairly better than the underlying network.9
9 Gifs showing this choice evolution will be made available with the final publication.
18
Under review as a conference paper at ICLR 2019
2000
1500
0
500
1000
2500
3000
3500
0	1000	2000	3000	4000	5000
Budget(b)
(a) Fashion-MNISThard (b < 5000)
Classuβ∣
DAEual
Class
DAE
random
0	10000	20000	30000	40000	50000	60000
Budget(b)
(b) Fashion-MNISThard
CIassuaI
DAEliel
Class
DAE
----C∣3SS∣jβl
DAEυβ∣
----Class
DAE
random
0	1000	2000	3000	4000	5000
Budget(b)
(c) Fashion-MNISTpca (b < 5000)
0	10000	20000	30000	40000	50000	60000
Budget (b)
(d) Fashion-MNISTpca
1750
1500

Figure 8:	(Color online) Results for Fashion-MNISThard and Fashion-MNISTpca with different zooms
on x-axis. Lines represent median of five runs with different seeds and confidence intervals represent
max and min results for each budget b.
D	Proofs
D.1 Lemma 1. Mixture probability lemma
Lemma 1. Mixture probability lemma. Consider two independent arbitrary probability distributions
pi and p. Given only a third distribution p+ = p ComPosed of the weighted average ofthe two:
P+ = (1 - λ) ∙ pi + λ ∙ P2, 0 ≤ λ ≤ 1
and considering Pi as the residual Probability distribution hyPerPlanes:
Pi = {prr = p-λλp, ∀P ∈ P | λ ∈ [0;1],X ∙ p ≤ p}
={pr ,∀pr ∈ P | λ ∈ [0；1], (1 - λ) ∙ Pr ≤ p}
P2 = {pr = p-(1-λ)∙p, ∀p ∈ P | λ ∈ [0; 1], (1 - λ) ∙ P ≤ p}
={pr, ∀pr ∈ P | λ ∈ [0； 1],λ ∙ Pr ≤ p}
Without further assumPtions on p2 (without a Prior on its Probability distribution), we only know that
p(pi ∣P+ = P) = p(pi∣pi ∈ Pi) and P(P2 ∣P+ = Pa) = p(pi = Pa - λα ∙ P2∣P2 ∈「2).
Proof. Given p+ = p We know that:
Pi + λa ∙ P2 = Pa
with λa = ι-λ and pa = ɪ-ɪ. Assuming the distribution of p2 is independent of pi, and with no
further assumptions on it, p2 is random and uniform on the set of all possible probability distributions,
19
Under review as a conference paper at ICLR 2019
(a) MNIST0-2 (b = 0)
(b) MNIST0-2 (b = 250)
(c) MNIST0-2 (b = 2000)
(d) MNISThard (b = 0)
(e) MNISThard (b = 250)
(f) MNISThard (b = 2000)
Figure 9:	(Color online) Underlying latent representations (ldae) vs anomaly score (sdae) for DAEuai
network as training progresses on MNIST0-2 and MNISThard.
(a) MNIST0-2 (b = 0)
(b) MNIST0-2 (b = 250)
(c) MNIST0-2 (b = 2000)
(d) MNISThard (b = 0)
(e) MNISThard (b = 250)
0.0	0.2	0.4	0.6	0.8	1.0
/(X)
(f) MNISThard (b = 2000)
Figure 10:	(Color online) Underlying latent representations (lclass) vs anomaly score (sclass) for
Classuai network as training progresses on MNIST0-2 and MNISThard.
so its probability distribution is:
P2 〜Uniform (P)
20
Under review as a conference paper at ICLR 2019
tiωtoo #
IO5
8 XlO4
6 ×104
4×104
2×104
O
O IO5 2×105	3×105	4×105	5×105
# Guesses
(a) KDDCUP
0 8 6 4 2
tiωtoo #
O 500 IOOO 1500 2000 2500 3000 3500 4000
# Guesses
(b) Thyroid
25000
20000
tJ 15000
<υ
t
O
⅛ IOOOO
5000
O
O 20000 40000 60000 80000 IOOOOO 120000
# Guesses
(c) Arrhythmia
(d) KDDCUP-Rev
Figure 11:	(Color online) Results for the real anomaly detection datasets when the UaiNets are only
fed expert information until a budget (b) limit. Lines stop in the x-axis when all anomalies have been
discovered.
where P is the hyperspace containing all probability distributions, with an hyper-volume m. Now we
can try to find p(pi ∣p+ = P):
P(P1|P+ = P)	=
(1)
P (P+ = PIpI) ∙
, P1 ∈ P1
P (P+ = PIpI) ∙
(2)
(3)
(4)
(5)
P(P1)
p(p+ = P)
P(P1)
p(p+ = P)
m
Jx∈Pι P(PI = x) ∙ mdx + Jx∈Pι 0dx
P(P1)
P(P1 |P+ = Pa)
x∈P P(P1 = x)dx
P(P1 IP1 ∈ P1)
The equality in (1) comes from the definition of the space P1 , which is the space of all possible values
of pi that could result in p+ = P, so if pi ∈ Pi, then P (p+ = P∣pi) = 0. Equality (2) is a simple
21
Under review as a conference paper at ICLR 2019
variable substitution where P (p+ = P)= p (pi = χ,p2 =
that p2 and p1 are independent. Equality (4) results from p2
pλ-x). (3) comes from the assumption
〜Uniform(P) and P having a volume
m. Finally, Equality (5) is a result from the fact that Pa-x
λα
∈ P ⇔ x ∈ P1 .
With a similar strategy We can find p(p2 |p+ = p):
P(P2 [P+ = P)
(=1)
P(P+=P∣P2) ∙ p(P+p=⅛
P(PI = Pa - λa ∙ P2∣P2) ∙ 7~厂
x P P1
P(P1 = Pa - λα ∙ P2∣P2)，-p~1
x P P1
P(P1 = Pa - λa ∙ P2∣P2)，7~厂
x P P1
P(P1 = Pa - λa ∙ P2) ∙ "p--7-
x P P1 =
P(Pz)
Pa -吟
=x,P2 = -ʒ—
λa
P(P2)
Pa -吟
=x,P2 = ~a—
λa
P(P2)
Pa -吟
=x,P2 = v—
λa
p(p2___________
Pa - X\ .
X,P2 = -7——dx
λa
dx
dx
, P2 ∈ P2
, P1 ∈ P1
dx
P(PI = Pa - λa •㈤∙	----^^X∖~P----P - x、
JxP(PI = x∣P2 = ^ar-) ∙ Pe = p^--) dx
(2)
P(P2∣P+ = P)
P(P1 = Pa - λa ∙ P2) ∙
P(P1 = Pa -入a ∙ P2)
____________m_____________
LPI P(PI= x) ∙ mdx + lx∈Pι 0dx
Jx∈Pι p(p1 = x)dx
P(P1 = Pa - Xa ∙ P2∣P1 ∈ PI)
P(P1 = Pa -入a ∙ P2∣P2 ∈ PZ)
P(P1 = Pa - λa ∙ P2∣P2 ∈ P2)
where Equality (1) and (2) result from the fact that P1 ∈ P1 ⇔ P2 ∈ P2, given a specific value of
P+ = p. This completes this proof.	□
D.2 Lemma 2. Extreme mixtures lemma
Lemma 2. Extreme mixtures lemma. Consider two independent arbitrary probability distributions
P1 and p2. Given only a third probability distribution p+ = P composed ofthe weighted mixture of
the two, andfor a small λ ≈ 0, we can find a small residual hyperplane P1, which tends to {p}.
P1 ≈ {pr = p — λ ∙ p, ∀p ∈ P ∣ λ ∙ p ≤ p} λ ≈ 0	(9)
We can also find a very large residual hyperplane P2 for P2, which tends to:
lim P2 = {p, ∀p ∈ P ∣ supp(p) ⊆ supp(p)}	(10)
λ→0
where supp(∙) is the support of a probability distribution.
Proof. In this proof, we start with the arbitrary residual hyperplanes Pr and find restrictions in the
limits of λ → 0 and λ → 1. For a β ≈ 0:
limβ→o Pr = limβ→o{pr = p-ββp, ∀p ∈ P ∣ β ∙ p ≤ P}
=limβ→o{pr = p - β ∙ p, ∀p ∈ P ∣ β ∙ p ≤ P}
={p}	_	_
Pr	≈	{pr	=	p	—	β ∙ p, ∀p ∈ P ∣	β ∙ p ≤ p}	β	≈	0
P1	≈	{pr	=	p	—	λ ∙ p, ∀p ∈ P ∣	λ ∙ p ≤ p}	λ	≈	0
P2	≈	{Pr	=	P	—	(1 — λ) ∙ p, ∀p	∈ P ∣ (1 —	λ)	∙ p	≤ p}	λ ≈ 1」.	β	≈	0
22
Under review as a conference paper at ICLR 2019
For a β ≈ 1 we start with the other definition of Pr :
limβ→1 Pr
Pr
P1
P2
=limβ→1 {pr ,∀Pr ∈ P | (1 - β) ∙ Pr ≤ p}
=limβ→1 {pr, ∀Pr ∈ P | SUPP(Pr ) ⊆ SUPP(P), (1 - β) ∙ Pr ≤ P}
={Pr ,∀Pr ∈ P | SUPP(Pr) ⊆ SUPP(p)}
≈ {pr, ∀Pr ∈ P | SUPP(Pr) ⊆ SUPP(p)}	β ≈ 1
≈ {Pr ,∀Pr ∈ P | SUPP(Pr) ⊆ SUPP(P)}	λ ≈ 1
≈ {Pr ,∀Pr ∈ P | SUPP(Pr) ⊆ SUPP(P)}	λ ≈ 0「. β ≈ 1
ThiS finiSheS thiS Proof.	□
D.3 Theorem 1. No free anomaly theorem
Theorem 1.	Consider two independent arbitrary probability distributions Pnormal and Panom. For a
small number of anomalies λ ≈ 0, the knowledge that Pfull = P gives Us no further knowledge on the
distribution ofPanom:
P(Pa
nomIPfull = P) ≈ Uniform(P2),	λ ≈ 0
Proof. ConSider in LemmaS 1 and 2 that P2 = Panom 〜 Uniform (P). We then have that, for a Small
valUe of λ ≈ 0:
P(P2 |P+ = Pa) = P(P1 = Pa - λα ∙ P2 |P2 ∈ P2)
≈ P(P1 = Pa∣P2 ∈ P2)
= Uniform (P2 )
This finishes this proof.	□
E Further Proofs
In thiS Section, we Prove UPPer and lower boUndS on the maximUm diStance a Probability diStribUtion
P1 can be from P+, baSed on the valUe of λ. ThiS can be directly aPPlied to Pnormal for Small valUeS
of λ and to Panom for large oneS.
Theorem 2.	Upper Bound on Mixture Probability Distance For two independent arbitrary proba-
bility distributions P1 andP2, given only a third probability distribution P+ composed of the weighted
mixture of the two:
P+ = (1 - λ) ∙ P1 + λ ∙ P2
We have an upper bound on the distance measures δ(P+,P1) and IIP+ - P1 II given by:
δ(P+,Pι) ≤ 1 21 log 1--ξ
IIP+ - P1 II ≤
J2logτ⅛
which is a tight bound for λ ≈ 0. In this equation δ(∙) is the total variation distance between two
probability distributions and ∣∣∙∣∣ is the Li norm.
Proof. PinSker’S ineqUality StateS that if P and q are two Probability diStribUtionS on a common
meaSUrable SPace (A, F):
δ(P, q) = sup{IP(A) - q(A)I
: A ∈F} ≤ .2 ∙ DKL (PIIq)
||P - q|| ≤ '2 ∙ DKL (PIIq)
where DKL (PIIq) is the KUllback-Leibler divergence in nats. So We have that:
δ(P+, P1) ≤
J2 ∙ DKL (pi"p+)
23
Under review as a conference paper at ICLR 2019
and this KUllback-Leibler divergence is itself upper-bounded by:
DKL (p1||p+)
X p1 (x) log
P+X) dx)
Pι(x)
(i-λ)∙p1(x)+λ∙p2(x)
≤ maxP2	p1 (x) log
PI(X)
(l-λ)∙p1(x) + λ∙p2(x)
where this maximum Kullback-Leibler divergence is achieved when p1 and p2 are disjoint probability
distributions:
DKL (pi||p+)	≤
maxP2	X p1 (x) log
PI(X)
Rx 卜(x)log (1-PL)(P1 (X)
Jx (pι(x)log ⅛dx
log τ⅛ Jx (PI(X)dx
log 1-λ
(l-λ)∙p1(x) + λ∙p2(x)
≤
which concludes the proof that:
δ(P+,Pι) ≤ 1 21 log ɪ-ʌ
||P+ -pi|| ≤ V2logr-T
1-λ
□
Theorem 3.	Lower Bound on Maximum Mixture Probability Distance For two independent arbi-
trary probability distributions p1 and p2, given only a third probability distribution p+ composed of
the weighted mixture of the two:
P+ = (1 一 λ) ∙ Pi + λ ∙ P2
We have a lower bound on the maximum possible distance measures δ(p+, pi) and llp+ - pill for a
chosen maximizing pi given by:
maxpιδ(p+,pι) ≥ λ ∙
|A-1|
maxPlllP+ ― P1|| ≥ 2λ |A|
which is a tight bound for λ ≈ 1, considering the maximum Li distance between two probability
distributions is 2.
Proof. We can prove a lower bound on the maximized distance of a probability distribution p1 from
p+ by expanding the distance equations:
maxP1 δ(p+, p1)
maxP1 δ(p+, p1)
maxP1 sup{|p+(A) - p1(A)| : A ∈ F}
maxpι sup{∣(1 - λ) ∙pi + λ ∙p2 -pι(A)∣ : A ∈ F}
maxpι sup{∣λ ∙p2(A) — λ ∙pι(A)∣ : A ∈ F}
λ ∙ maxpι sup{∣p2 (A) — pi (A) | : A ∈ F}
(a) ≥	λ ∙ maxpι minp2 sup{∣p2 (A) 一 pi (A) ∣ : A ∈ F}
(=b)	λ ∙ maxpι sup{∣ Uniform(A) — Pi(A) ∣ : A ∈ F}
(=c)	λ ∙ sup{∣Uniform(A) — δ(A) ∣ : A ∈ F} ʌ |A-1| λ ∙ -μT
≥	λ ∙ 14-^
24
Under review as a conference paper at ICLR 2019
where in (a) we lower bound based on the probability distribution that would have the smallest possible
superior distance to a later maximized probability distribution p1. This probability distribution p1
can always maximize its superior distance to p2 by:
p1(a) =	1 , if a = argminx(p2(x))
1	0 , else
In (b) we choose the uniform distribution as the one that would reduce this superior distance and in
(c) we set p1 (a) = 1 for a random a, since p2 is uniform. With a similar strategy we find:
maxp1 ||p+ - p1 || ≥ 2λ
|A- 1|
|A|
This concludes this proof.
□
25