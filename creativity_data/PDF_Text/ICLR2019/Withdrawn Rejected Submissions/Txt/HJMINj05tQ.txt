Under review as a conference paper at ICLR 2019
Nesterov’s method is the discretization of a
differential equation with Hessian damping
Anonymous authors
Paper under double-blind review
Ab stract
Su et al. (2014) made a connection between Nesterov’s method and an ordinary
differential equation (ODE). We show if a Hessian damping term is added to the
ODE from Su et al. (2014), then Nesterov’s method arises as a straightforward
discretization of the modified ODE. Analogously, in the strongly convex case, a
Hessian damping term is added to Polyak’s ODE, which is then discretized to
yield Nesterov’s method for strongly convex functions. Despite the Hessian term,
both second order ODEs can be represented as first order systems.
Established Liapunov analysis is used to recover the accelerated rates of conver-
gence in both continuous and discrete time. Moreover, the Liapunov analysis can
be extended to the case of stochastic gradients which allows the full gradient case
to be considered as a special case of the stochastic case. The result is a unified
approach to convex acceleration in both continuous and discrete time and in both
the stochastic and full gradient cases.
1 Introduction
Su et al. (2014) made a connection between Nesterov’s method for a convex, L-smooth function, f,
and the second order, ordinary differential equation (ODE)
3
X + WX + ▽/(χ) = 0
(A-ODE)
However Su et al. (2014) did not show that Nesterov’s method arises as a discretization of (A-ODE).
In order to obtain such a discretization, We consider the following ODE, which has an additional
Hessian damping term with coefficient 1∕√L.
31
ʃ+ 7x + Vf (x) = -√=
• x + ；
(H-ODE)
Notice that (H-ODE) is a perturbation of (A-ODE), and the perturbation goes to zero as L →
∞. Similar ODEs have been studied by Alvarez et al. (2002), they have been shown to accelerate
gradient descent in continuous time in (Attouch et al., 2016).
Next, we consider the case where f is also μ-strongly convex, and write Cf := L∕μ for the condition
number of f. Then Nesterov’s method in the strongly convex case arises as discretization of the
following second order ODE
X + 2√μx + Vf(X)
一√L (D2f (X) •X + √μVf(X))
(H-ODE-SC)
(H-ODE-SC) is a perturbation of Polyak’s ODE (Polyak, 1964)
X + 2√μX + Vf(X) = 0
which is accelerates gradient when f is quadratic see (Scieur et al., 2017).
In each case, both continuous and discrete, as well and convex and strongly convex, it is possible to
provide a proof of the rate using a Liapunov function. These proofs are already established in the
literature: we give citations below, and also provide proof in the Appendix.
1
Under review as a conference paper at ICLR 2019
Moreover, the analysis for Nesterov’s method in the full gradient can be extended to prove accel-
eration in the case of stochastic gradients. Acceleration of stochastic gradient descent has been
established by Lin et al. (2015) and Frostig et al. (2015), see also Jain et al. (2018). A direct accel-
eration method with a connection to Nestero’v method was done by Allen-Zhu (2017). Our analysis
unifies the continuous time ODE with the algorithm, and includes full gradient acceleration as a
special case. The analysis proceeds by first rewriting (H-ODE) (and (H-ODE-SC)) as first order
systems involving Vf, and then replacing the Vf with g = Vf + e. Both the continuous and
discrete time methods achieve the accelerated rate of convergence, provided |e| goes to zero quickly
enough. The condition on |e|, is given below in (12) and (13) - it is faster than the corresponding
rate for stochastic gradient descent. When e = 0 we recover the full gradient case.
The renewed interested in the continuous time approach began with the work of Su et al. (2014) and
was followed Wibisono et al. (2016); Wilson et al. (2016). Continuous time analysis also appears in
Flammarion & Bach (2015), Lessard et al. (2016), and Krichene et al. (2015). However, continuous
time approaches to optimization have been around for a long time. Polyak’s method Polyak (1964)
is related to successive over relaxation for linear equations (Varga, 1957) which were initially used
to accelerate solutions of linear partial differential equations (Young, 1954). A continuous time
interpretation of Newton’s method can be found in (Polyak, 1987) or Alvarez et al. (2002). The
mirror descent algorithm of Nemirovskii et al. (1983) has a continuous time interpretation (Bubeck
et al., 2015). The Liapunov approach for acceleration had already appeared in Beck & Teboulle
(2009) for FISTA.
The question of when discretizations of dynamical systems also satisfy a Liapunov function has
been studied in the context of stabilization in optimal control Levant (1993). More generally, Stuart
& Humphries (1996) studies when a discretization of a dynamical system preserves a property such
as energy dissipation.
2 An ODE representation for Nes terov’ s method
2.1 Convex case
Despite the Hessian term, (H-ODE-SC) can be represented as the following first order system.
Lemma 2.1. The second order ODE (H-ODE) is equivalent to the first order system
[x = t(V - χ) - √l Vf(X),
Iv = - 2 Vf (χ).
(1st-ODE)
Proof. Solve for v in the first line of (1st-ODE)
v = t (X + -1L Vf(X)) + X
differentiate to obtain
V = I(X + √1LVf(X)) + 2(X + √1LD2f (X) ∙X) + X.
Insert into the second line of (1st-ODE)
1(X + √1LVf(X)) + t(X + √1LD2f (X) ∙X) + X = - tVf(X).
Simplify to obtain (H-ODE).
□
The system (1st-ODE) can be discretized using the forward Euler method with a constant time step,
h, to obtain Nesterov’s method.
Definition 2.2. Define yk as the following convex combination of Xk and vk.
kXk + 2vk
yk = k + 2
(1)
2
Under review as a conference paper at ICLR 2019
Let h > 0 be a given small time step/learning rate and let tk = h(k + 2). The forward Euler method
for (1st-ODE) with gradients evaluated at yk is given by
2h	h
Xk+1 ― Xk = tj~(Vk ― Xk) ― √=Vf (yk),
vk+1 一 Vk = 2Vf (yk )
(FE-C)
Remark 2.3. The forward Euler method Simply comes from replacing X with (xk+ι 一 Xk )/h and
similarly for v. Normally the velocity field is simply evaluated at xk, vk. The only thing different
about (FE-C) from the standard forward Euler method is that Vf is evaluated at yk instead of Xk.
However, this is still an explicit method. More general multistep methods and one leg methods in
this context are discussed in Scieur et al. (2017).
Recall the standard Nesterov’s method from Nesterov (2013, Section 2.2)
Xk+1 = yk ― 1 Vf (yk)
L
k
yk = Xk+1 + k + 3 (Xk+1 Xk)
(Nest)
Theorem 2.4. The discretization of (H-ODE) given by (FE-C)(I) with h = 1∕√L and tk = h(k+2)
is equivalent to the standard Nesterov’s method (Nest).
Proof. (FE-C) with h = 1/√L and tk = h(k + 2) becomes
Xk+1 ― Xk
21
k + 2(vk - Xk) - L Vf (yk )
Vk+1 ― Vk
k + 2
2L
Vf(yk)
—
Eliminate the variable V using (1) to obtain (Nest).
□
2.2 Strongly Convex case
Now We consider μ-strongly convex, and L-Smooth functions, f, and write Cf := L for the Condi-
tion number. We first show that (H-ODE-SC) can be represented as a first order system.
Lemma 2.5. The second order ODE (H-ODE-SC) is equivalent to the first order system
[x = √μ(v - x) - √LVf(X),
[v=√μ(X -V) - √μVf(X).
(1st-ODE-SC)
Proof. Solve for V in the first line of (1st-ODE-SC)
V = 3(X+ -4= Vf (x)) + X
Vμ	V L
differentiate to obtain
V = √= (X + √= D2f (x) ∙ X) + X.
Insert into the second line of (1st-ODE-SC)
1
√μ
(X +
√= D2f (x) ∙ X) + X
Vf(X).
Simplify to obtain (H-ODE-SC).
□
3
Under review as a conference paper at ICLR 2019
System (1st-ODE-SC) can be discretized using a forward Euler method with a constant time step h
to obtain Nesterov’s method. Let h > 0 be a small time step, and apply the forward Euler method
for (1st-ODE-SC) evaluated at yk:
	I Xk+ι - Xk = 1 ^λfμ^λ(vk - Xk) I	1+ h√μ L . — — h√μ : —,.、一			h - √L Nf(Jk), h 亍 Nf(yk) √μ	(FE-SC)
	Vk+1	Vk	Xk	Vk) 1 + h√μ			
where,	yk =	(1 - λh)Xk + λhVk,	λh	_	h√μ - 1 + h√μ'	(2)
Now we recall the usual Nesterov’s method for strongly convex functions from Nesterov (2013,
Section 2.2)	Xk + 1 = yk -斤Nf (yk) L
1 - JCf-1	(SC-Nest)
yk+ι = χk+ι +---------/	(χk+ι - Xk)
1 + Cf-f-1
Theorem 2.6. The discretization of (H-ODE-SC) given by (FE-SC) with h = 1∕√L is equivalent
to the standard Nesterov’s method (SC-Nest).
Proof. (FE-SC) with h = 1/√L becomes
xk+1 - xk
vk+1 - vk
ι+√f-(Vk - Xk) - LNfnk)
1 VZf - 1 (Xk - Vk)-∏f≡(yf (yk)
Eliminate the variable vk using the definition of yk to obtain (SC-Nest).
□
3 Liapunov Analysis
3.1	Convex case: continuous and discrete time
Definition 3.1. Define the continuous time Liapunov function
E(t,χ,v) := t2(f(x) - f*) + 2|v - x*|2	(3)
Define the discrete time Liapunov function Ek by
Ek = E(tk-1, Xk, Vk)	(4)
Proposition 3.2. Let f be a convex and L-smooth function. Let (X(t), V(t)) be a solution to
(1st-ODE), then
t2
≤-√L Vf(X)l2.
dE (t, X(t), V(t))
dt
where E(t, X, V) in given by (3). In particular, for all t > 0,
f(X(I))- f* ≤ t2Ivo - χ*∣2∙
Furthermore, let Xk, Vk be given by (FE-C). Then for all k ≥ 0,
Ek+1 ≤ Ek - h2(f (Xk ) - f *) + (h - √= ) tkh|Nf(yk )|2 .
In particular, if
h ≤ ɪ
一√L
then Ek is decreasing. When equality holds in (5),
2
f (Xk) - f ≤ (k + J)? ((f (XO) - f ) + |v0 - X | ) ∙
(5)
4
Under review as a conference paper at ICLR 2019
Most of the results stated above are already known, but for completeness we refer the proofs in
Appendix A. Since (FE-C) is equivalent to Nesterov’s method, the rate is known. The proof of the
rate using a Liapunov function can be found in Beck & Teboulle (2009). Refer to ? which shows
that we can use the constant time step. The discrete Liapunov function (4) was used in Su et al.
(2014); Attouch & Peypouquet (2016) to prove a rate.
3.2	Strongly convex case: continuous and discrete time
Definition 3.3. Define the continuous time Liapunov function E(x, v)
E(x,v) = f (x) - f* + 2|v - x*∣2	(6)
Define the discrete time Liapunov function by
Ek = E(Xk, Vv) = f (Xk)- f * + 2 lvk - x* |2.	⑺
Proposition 3.4. Let (x, v) be the solution of (1st-ODE-SC), then
dE(Xv. ≤-√μE(x,v) -√-IVf(X)∣2- μ√μ∣V-X∣2.	(8)
dt	L	2
In particular, for all t > 0,
E(x(t),v(t)) ≤ exp(-√μt)E(xo,vo).
Next, let Xk, Vk be given by (FE-SC) with initial condition (xo, vo). For h ≤ *, we have
Ek + 1 - Ek ≤ -h√μEk .	⑼
In Particularfor h =圭,
Ek+1 ≤ (1 一 {CfT )Ek.	(10)
The discrete Liapunov function Ek was used to prove a rate in the strongly convex case by Wilson
et al. (2016). The proof of (10) can be found in Wilson et al. (2016, Theorem 6). For completeness
we also provide the proof in Appendix E.
4 Stochastic Accelerated method
In the appendix we present results in continuous and discrete time for (non-accelerated) stochastic
gradient descent. We also present results in continuous time for the stochastic accelerated case in
the Appendix.
We present the results in discrete time here.
4.1	Convex Stochastic Case: discrete time
In this section we consider stochastic gradients, which we write as a gradient plus an error term
Vef(yk) = Vf(yk) + ek	(11)
The stochastic gradient can be abstract, or it can error be a mini-batch gradient when f is a sum.
Moreover, we can include the case where
ek = Vf (y) - VIf (y) - (Vf (yk) - VIf(yk))
corresponding to a correction by a snapshot of the full gradient at a snapshot location, which is
updated every m iterations, as inJohnson & Zhang (2013). The combination of gradient reduction
and momentum was discussed in Allen-Zhu (2017).
In order to obtain the accelerated rate, our Liapuonov analysis requires that the ∣ei ∣ be decreasing
fast enough. This can also be accomplished in the minibatch setting by using larger minibatches. In
5
Under review as a conference paper at ICLR 2019
this case, the rate of decrease of ei required gives a schedule for minibatch sizes. A similar result
was obtained in Attouch & Peypouquet (2016).
When we replace gradients with (11) the Forward Euler scheme (FE-C) becomes
{2h	h 八
xk+1 - Xk = ~j~∖vk - Xk)---√= (Vf (yk ) + ek ),
tk	L	(Sto-FE-C)
vk + 1 - Vk = -h^2(Vf (yk) + ek),
where yk is given by (1), h is a constant time step, and tk := h(k + 2). In Appendix C, we study
the continuous version of (Sto-FE-C) and obtain a rate of convergence using a Liapunov function.
Definition 4.1. Define the discrete stochastic Liapunov function Ek := Ek + Ik, for k ≥ 0, where
Ek is given by (4) and and, e-1 := 0 and for k ≥ 0,
k
Ik := h	2ti hvi - X , ei-1 i .
i=0
Theorem 4.2. Assume that the sequence ek satisfies
+∞
Xi|ei| < +∞	(12)
i=1
and set h = √L. Then, supi≥ι ∣Vi 一 x*| < +∞ and
~ ~ ,
Ek+1 ≤ Ek ,	k ≥ 0
We immediately have the following result.
Corollary 4.3. Suppose ek satisfies (12) and h =圭.Then, for k ≥ 0,
f (xk) - f * ≤ (k +1)2 ,
with
+∞
C = 2L((f (X0) 一 f*) + |v0 一 X*|2) + 2sup |vi 一 X*| X(i + 3)|ei|.
i≥1	i=0
Remark 4.4. The assumption on ek is satisfied, for example, by a Sequence oftheform |ek | = 1 /kɑ
for any α > 2. By comparison for SGD, the corresponding condition is satisfied by such sequences
with α > 1. Thus the norm of the noise needs to go to zero faster for accelerated SGD compared to
regular SGD (see Appendix B) in order to obtain the rate.
Remark 4.5. In Theorem 4.2, we focus on the maximum possible time step h = 1∕√L. The
result is still true if we shrink the time step. In this case, Ik can be defined using the tails
h i∞=k+1 2ti hvi 一 X*, ei-1i, see Attouch & Peypouquet (2016).
4.2 Strongly convex stochastic case: discrete time
In this section, we consider that stochastic gradient, which we write as a gradient plus an error, as in
section 4.1. In Appendix B.2, we study the Stochastic gradient descent and Appendix C.2 is devoted
to the analysis of the continuous framework of Stochastic Accelerated method. The Forward Euler
scheme (FE-SC) becomes
)xk+1 - xk = λh(Vk - xk) - √ɪ= (Vf (yk) + ek),
h
vk+1 一 vk = λh (Xk 一 vk) 一 √μ (Vf (yk) + ek ),
where ek is a given error and
(Sto-FE-SC)
yk = (1 一 λh )Xk + λhvk ,
1 + h√μ.
Inspired by the continuous framework (Appendix C.2), we define a discrete Lyapunov function.
6
Under review as a conference paper at ICLR 2019
Definition 4.6. Define Ek := Ek + Ik, where Ek is given by ⑺ and
k
Ik := h√μ (I- h√μ) ^X (I-h√μ)-i Ei - X*,ei-1),
i=0
with the convention e-ι = 0.
Then we obtain the following convergence result for sequences generated by (StO-FE-SC).
Theorem 4.7. Let Xk, Vk be two sequences generated by the scheme (Sto-FE-SC) with initial con-
dition (x0, vo). Suppose that h	=± and the sequence (ek)k satisfies +∞ X(1- CCf-1)-iei < +∞.	(13) i=0
Then,	Ek+1 6 (1 - JCjT)kEk.
In addition, supi≥l3 |vi — x* | ≤ M for a positive constant M and
于(Xk) - f* + 今Vk- x*12 ≤ A(I- Jg-1 )k,
with
A = f (XO)- f * + 2 |v0 - x* |2 + M ^X(I - JCf_1) iei-1
i=0
We include the proof of Theorem 4.7 since this result is new.
ProofofTheorem 4.7. First we prove that
Ek+1 - Ek	≤	-	WfTEk -	ʌ/Cf~1 hλh(Xk - vk) - √= (▽/(yk) + ek), eki -	JCf_1 hvk - χ*,eki
For the term Ik , we obtain
1k+ι - Ik ≤ JCf―1 (1 -	-JCfF1 )k ((1- JCfF1) X(I- JCf-1 )-ihvi -x*,ei-ii
-X (1 - i=0	i=0 JCfT)-ihvi - x*, ei-1i)
= -C Cf 1Ik + C Cf 1hvk+ι - x*,ek).
Putting all together, we obtain
Ek+1 - Ek	=	Ek+1 - Ek + Ik+1 - Ik
≤	-JCTT Ek 1	∖∕Cf-1	1 +L|ek|2 +	√l-hλ(vk - xk) + √= V/(yk), eki + C Cf 1hvk+1 - vk ,eki
7
Under review as a conference paper at ICLR 2019
And by definition of vk+1 - vk, we have
Ek+1 - Ek	≤	- C Cf 1 hλh(xk — vk) —
+ Cf -1 hλh (xk - vk ) -
1
√Lμ
1
√Lμ
(▽f(yk) + ek ),ek i
(Vf (yk) + ek ),ek)
≤	— √Cf-1Ek.
We conclude, as in the convex case, applying discrete Gronwall Lemma and (13).
□
References
Zeyuan Allen-Zhu. Katyusha: The first direct acceleration of stochastic gradient methods. In Pro-
Ceedings ofthe 49th Annual ACM SIGACT Symposium on Theory ofComputing, pp. 1200-1205.
ACM, 2017.
FeliPe Alvarez, Hedy Attouch, Jerome Bolte, and P Redont. A second-order gradient-like dissipa-
tive dynamical system with hessian-driven damping.-application to optimization and mechanics.
Journalde mathematiquesPures et appliquees, 81(8):747-780, 2002.
Hedy Attouch and Juan Peypouquet. The rate of convergence of Nesterov’s accelerated forward-
backward method is actually faster than 1/k2. SIAM J. Optim., 26(3):1824-1834, 2016.
ISSN 1052-6234. doi: 10.1137/15M1046095. URL https://doi.org/10.1137/
15M1046095.
Hedy Attouch, Juan Peypouquet, and Patrick Redont. Fast convex optimization via inertial dynamics
with hessian driven damping. Journal of Differential Equations, 261(10):5734-5783, 2016.
Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse
problems. SIAM journal on imaging sciences, 2(1):183-202, 2009.
Sebastien Bubeck et al. Convex optimization: Algorithms and complexity. Foundations and Trends
in Machine Learning, 8(3-4):231-357, 2015.
Nicolas Flammarion and Francis Bach. From averaging to acceleration, there is only a step-size. In
Conference on Learning Theory, pp. 658-695, 2015.
Roy Frostig, Rong Ge, Sham Kakade, and Aaron Sidford. Un-regularizing: approximate proximal
point and faster stochastic algorithms for empirical risk minimization. In International Confer-
ence on Machine Learning, pp. 2540-2548, 2015.
Prateek Jain, Sham M Kakade, Rahul Kidambi, Praneeth Netrapalli, and Aaron Sidford. Accelerat-
ing stochastic gradient descent for least squares regression. In Conference On Learning Theory,
pp. 545-604, 2018.
Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance
reduction. In Advances in neural information processing systems, pp. 315-323, 2013.
Walid Krichene, Alexandre Bayen, and Peter L Bartlett. Accelerated mirror descent in con-
tinuous and discrete time. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and
R. Garnett (eds.), Advances in Neural Information Processing Systems 28, pp. 2845-
2853. Curran Associates, Inc., 2015. URL http://papers.nips.cc/paper/
5843-accelerated-mirror-descent-in-continuous-and-discrete-time.
pdf.
Laurent Lessard, Benjamin Recht, and Andrew Packard. Analysis and design of optimization algo-
rithms via integral quadratic constraints. SIAM Journal on Optimization, 26(1):57-95, 2016.
Arie Levant. Sliding order and sliding accuracy in sliding mode control. International journal of
control, 58(6):1247-1263, 1993.
8
Under review as a conference paper at ICLR 2019
Hongzhou Lin, Julien Mairal, and Zaid Harchaoui. A universal catalyst for first-order optimization.
In Advances in Neural Information Processing Systems, pp. 3384-3392, 2015.
Arkadii Nemirovskii, David Borisovich Yudin, and Edgar Ronald Dawson. Problem complexity and
method efficiency in optimization. 1983.
Yurii Nesterov. Introductory lectures on convex optimization: A basic course, volume 87. Springer
Science & Business Media, 2013.
Boris T Polyak. Some methods of speeding up the convergence of iteration methods. USSR Com-
putational Mathematics and Mathematical Physics, 4(5):1-17, 1964.
Boris T Polyak. Introduction to optimization. translations series in mathematics and engineering.
Optimization Software, 1987.
Herbert Robbins and Sutton Monro. A stochastic approximation method. The Annals of Mathe-
matical Statistics, 22(3):400-407, 1951. ISSN 00034851. URL http://www.jstor.org/
stable/2236626.
Damien Scieur, Vincent Roulet, Francis Bach, and Alexandre d’Aspremont. Integration methods
and accelerated optimization algorithms. arXiv preprint arXiv:1702.06751, 2017.
AM Stuart and AR Humphries. Dynamical systems and numerical analysis, volume 2 of Cam-
bridge Monographs on Applied and Computational Mathematics. Cambridge University Press,
Cambridge, 1996.
Weijie Su, Stephen Boyd, and Emmanuel Candes. A differential equation for modeling nesterov’s
accelerated gradient method: Theory and insights. In Advances in Neural Information Processing
Systems, pp. 2510-2518, 2014.
Richard S Varga. A comparison of the successive overrelaxation method and semi-iterative methods
using chebyshev polynomials. Journal of the Society for Industrial and Applied Mathematics, 5
(2):39-46, 1957.
Andre Wibisono, Ashia C Wilson, and Michael I Jordan. A variational perspective on accelerated
methods in optimization. Proceedings of the National Academy of Sciences, pp. 201614734, 2016.
Ashia C Wilson, Benjamin Recht, and Michael I Jordan. A lyapunov analysis of momentum methods
in optimization. arXiv preprint arXiv:1611.02635, 2016.
David Young. Iterative methods for solving partial difference equations of elliptic type. Transactions
of the American Mathematical Society, 76(1):92-111, 1954.
A Continuous framework: ODE and rate
Proof of Prof 3.2. By definition of E, we have
dE
dt
≤
2t(f(x)- f*)+ t2hVf(x),Xi
+4<v — x*,V i
≤
2t(f(x)- f *) + 2t(Vf(x),v - Xi
方Vf(X)12
—2t〈v — x*, Vf (x)i
≤
t2
2t(f(χ) — f * — hx — χ*, Vf (x)i) — √l∣Vf(χ)∣2.
The proof is concluded by convexity,
f(X) —f* — hX—X*,Vf(X)i ≤ 0.
9
Under review as a conference paper at ICLR 2019
Proofof Proposition 3.4. Using (1St-ODE-SC), we obtain
dE(χ, V)
dt
〈Vf (χ),χ〉+ λ√μ(v — χ*,V)
√μhVf (χ), v — X — √1= ∖Vf (χ)∖2 — μ√μ{v — χ*, v — χ) — √μhVf (χ), v — χ*i
-	√μhv∕(χ),χ 一 χ*i — -1= ∖vf(χ)∖2 — μ2μ [∖v 一 χ*∖2 + ∖v 一 χ∖
—	∖x — x* ∣2
By strong convexity, we have
dE(χ, v)
-dt- ≤
-	√ (f (χ) — f* + 2∖χ — χ*∖2) — √= ∖Vf (χ)∖2
—	μ√μ [∖v—χ* ∖2+∖v—χ∖2 — ∖χ—χ* ∖2]
-	√μE(X, V) — √= IVf(X) ∖2 —	∖v — χ∖2∙
B Stochastic Gradient Descent
B.1 Convex case： continuous and discrete time
Let e : [0, +∞) → Rd be a integrable function. Consider the gradient descent
X = —(Vf (χ) + e(t)).
r-ɪ-ɪl	FC , 1 ɪ	i'	. ∙	T~↑ 1
Then define the Lyapunov function, E, by
E(t, χ) = E(t, χ) + I(t),
(14)
where,
and,
E (t,χ) = t(f (χ) — f *) + 2 ∖χ — χ*∖2,
I (t)
Z (χ(s) - χ*
Jo
+ SVf(X(S)), e(s)〉ds.
≤
2
□
Then the following result holds.
Proposition B.1. Let X be a solution of (14) with initial condition χo. Then,
d⅞2 ≤ -t∖Vf(χ)∖2.
dt
In addition, if f is L-smooth, sups>o ∖χ(s) — χ*∖ < +∞, sups>o s∖Vf (χ(s))∖ < +∞ and
f(χ(t)) — f* ≤ 1 (f (χo) — f* + 2∖χo — χ*∖2 + sup ∖χ(s) — X* + SVf(X(S))∖∣∣e∣∣Li(0,+∞)
Proof. For all t > 0, we have
•	^x = (f (χ) — f * —〈Vf (χ), χ — X*〉)一 t∖Vf (X1 — hX — χ* + tVf (χ), e)，
•	ddt) =〈X — χ* + tVf (χ),e).
Then, since f is convex, we obtain the first result. We deduce that E is decreasing. Arguing as
Attouch et al. (2016) along with the co-coercivity inequality, we prove that sups>o ∖χ(s) — χ*∖ <
+∞, sups>o s∖Vf (χ(s))∖ < +∞ which concludes the proof.	□
10
Under review as a conference paper at ICLR 2019
The discretization of (14) is
Xk+1 - Xk = -h(V∕(xk) + ek),	(15)
where ek = e(hk).
Define Ek by
Ek = Ek + Ik ,
where, for tk := hk,
Ek = tk(f(χk) - f*) + 1 ∣χk - χ*∣2,
and,
k-1
Ik = h): hxi - X - ti+1( Vf(Xi) + ei ), eii ∙
i=0
Proposition B.2. Let Xk be the SeqUenCe generated by (15) with initial COnditiOn xo. Assume that
h satisfies, for all k ≥ 0,
h(Ltk+ 1 + I) - 2tk+1 ≤ 0 ≡ h ≤ L	(16)
Then the Ek is decreasing. In addition if (ek)k and (tk+ι∣ek ∣2)k are summable, supi≥0 ∣Xi — x*∣ <
+∞, supi≥o ∣ti+ιVf(Xi)∣ < +∞ and
f (Xk) - f * ≤ —
tk
ɪ ∣X0 — X* ∣2 + sup ∣Xi — X*
2	i≥o
十∞	.
+ ti+1 Vf(Xi)I f(∣ei∣ + ti+1 ∣ei∣2)
Proof. By L-smoothness and convexity of f, we have
Ek+1 - Ek ≤	-htk+1hVf(Xk), Vf(Xk) + eki
h2
+ (Ltk+ 1 + l)ɪ IVf(Xk) + ek ∣2
-{xk - X*,ek)
+ h(f (Xk) - f * -hVf (xk),Xk - X*〉)
h
≤ ((Ltk+ 1 + l)h - 2tk+1)2 IVf(Xk) + ek ∣
-h<Xk - x*,ek)+ tk+1hhVf(xk) + ek,ek).
In addition,
1k + 1 - Ik = hhxk - x* - tk+1 (Vf(Xk) + ek ),ek i,
therefore,
h
Ek+ 1 - Ek ≤ ((Ltk+1 + l)h - 2tk+1 4 IVf(Xk ) + ek ∣ ≤ 0,
when h satisfies (16). We conclude the proof with the same argument as Proposition B.1.	□
B.2 Strongly convex case： continuous and discrete time
Let us study the equation
X = -(Vf (x) + e(t)),
for an error function, e satisfying
+ ∞
0
eμs∣e(s)∣ ds < +∞.
(17)
(18)
This condition on the error function is classical Robbins & Monro (1951). The case e = 0 is satisfied
trivially and corresponds to the gradient descent oDE.
11
Under review as a conference paper at ICLR 2019
We define the function E : [0, +∞) × Rd → [0, +∞) by
E(t,x) = 2∖x - x*∣2 + I(t),
where,
e-μ It eμs hx(s)-
Jo
x*, e(s))ds.
I⑴
Then we have the following result.
Proposition B.3. Let X be a solution of (17) with initial data xo and suppose that e satisfies (18).
Then,
dEd^ ≤-μE(t,x).
In addition, supt≥o ∖x 一 x*∖ < +∞ and
J∖x - x* ∖2	≤ e-μt( ɪ ∖xo	— x* ∖2 +	sup ∖x(s)	— x* ∖ Z	eμs ∖e(s)∖ ds).
2	2'	'	s≥o	o
Proof. For all t > 0,
dE (t, x)
dt
-hx — x*, V/(x))一(x — x*, e — μI(t) + (x — x*, e)
≤ 一 μ ∖x — x* ∖2 — μI(t) = -μE(t, x).
Therefore E(t, x(t)) is decreasing and then for all t > 0,
2 ∖x(t)-
x*∖2 ≤ 1 ∖xo — x*∖ + ∖ ∖x(s)
2o
—x*∖eμs∖e(s)∖ ds.
By Gronwall Lemma and (18), we deduce that supt≥o ∖x — x* ∖ < +∞ and the proof is concluded.
□
The discretization of (17) is
xk+1 — Xk = -h(V∕(xk) + ek),
where ek = e(hk). We define Ek, for k ≥ 1, by
Ek = 2 ∖xk - x* ∖2 + Ik,
where,
k
Ik = (1 — hμ)kh X(1 —hμ)-i(xi — x*,ei-1),
i=o
with the notation e_1 = 0.
Proposition B.4. Assume that h ≤ L. Then,
Ek+1 - Ek ≤ -hμEk.
In addition, if the SeqUence (1 — hμ)-i∖ei∖ issummable, supi≥ι ∖xi — x*∖ < +∞ and we deduce,
2 ∖xk - x* ∖2 ≤ (1 - hμ)k
2∖xo — x*∖2 + hsup ∖xi — x*∖ X(1 — hμ)-iT∖ei∖).
Proof. First, as usual, we have
1	1	h2
2	∖xk+1 - X ∖ - 2 ∖xk - X ∖	=	-hhV/(Xk), xk - X )— hhek, xk - X i + ɪ IVf(Xk) + ek ∖
≤ 2 ∖xk - x* ∖2 + h(/* - f(Xk)) + ɪ IVf(Xk ) + ek ∖2
≤	- -^IXk - x*∖2 - —∖v∕ (xk )∖2 + ^5^∖Vf(Xk) + ek ∖2.
2	2L	2
12
Under review as a conference paper at ICLR 2019
In addition,
Ik + 1 - Ik	=	h(I- hμ)k	((I- hμ)	^X(I	-	hμ)-ihxi	-	x*, ei-1i- ^X(I-hμ)-ihxi	- x*,ei-ii
i=0	i=0
= -hμIk + hhχk+ι - x*,ek).
Combining these two inequalities,
Ek+1 - Ek ≤ -hμEk + hhxk + 1 - Xk ,ek i- TTfVf(Xk )|2 + ^5^Vf (Xk ) + ek|2
2L	2
≤ -hμEk + — (h - 丁) |Vf (xk )|2----^-Iekl2
2L	2
≤	-hμEk,
When h ≤ +.
In order to conclude, we also need to establish that Ek is bounded below. That follows from discrete
GronWall's inequality, as was already done in the continuous case in Proposition B.3.	□
C Stochastic accelerated continuous time
In this section, We consider that an error e(t) is made in the calculation of the gradient.
C.1 Convex case
We study the folloWing perturbation of system (1st-ODE),
[x = t(V - x) - √l(Vf(X) + e(t)),
Iv = -t (Vf (x) + e(t)).
Where e is a function satisfying
sIe(s)I < +∞.
0
(Sto-1st-ODE)
(19)
The corresponding ODE is
31
x + -χX + √= D2f(x) ∙ X +
+ 1 Vf(X)
—
+ 1) e(t) - √Le0(t).
We folloW the argument from Attouch et al. (2016, section 5) to define a Lyapunov function for this
system. Let E be defined by
iɔ/1	∖ τ~ι∕ i ∖ . τ(t ∖
E(t, x, v) = E(t, x, v) + I(t, x, v),
Where,
E(t,χ,v) = t2(f(χ) - f ) + 2∣v - X*∣2,
and
I(t,x,v) = Z s<2(v — x*) + √=Vf(x), e(s)i ds.
Lemma C.1. Let (X, v) be a solution of (Sto-1st-ODE) with initial condition (X(0), v(0))
(x0, v0) and suppose that e satisfies (19). Then
2
dE	t2
"d^ (t,X, V) ≤ -√L IVf(X)। .
In addition, supt≥0 ∣v(t) — x*| < +∞ and supt≥o ∣tVf(x)∣ < +∞.
13
Under review as a conference paper at ICLR 2019
Proof. Following the proof of Proposition 3.2, we have
dE	P	C P
dtj~(t, χ, v) ≤ -√l IVf(X)I - √l (Vf(X), e⑴〉-2thv- X , e⑴).
In addition,
Then,
dI,	.	t2 —........ .............
d(t, x, V) = √l(Vf(X), e⑴〉+ 2thv- X , e⑴).
〜
dE
—；≤
dt 一
In particular, E is decreasing and
t2
-√L ∣v∕(χ)∣2.
t2(f(x) - f*) + 2∣v - x*∣2 ≤ 2∣X0 -
x*∣2 — Z s{i2(v — x*) + CSVf(X),e(s)〉ds.
0
Using the inequality of co-coercitivity, we obtain
2L ItVf(X)∣ +2∣V - x*∣ ≤ 2∣X0 - x*∣2 + 2L +2 + / (；ISVf(X)∣ + 2∣v - x*∣) ∣Se(S)I ds.
Using (19), we conclude applying Gronwall Lemma.	□
Then we deduce
Proposition C.2. Let (x,v) be a solution of (Sto-1st-ODE) with initial condition (x(0), v(0))
(x0, vo) and suppose that e satisfies (19). Then,
f(x(t)) - f* ≤ ' (2∣v0 - x*∣2 + sup 2(v(s) - x*) + -s= Vf (x(s)) /	s∣e(s)∣ ds).
C.2 STRONGLY CONVEX STOCHASTIC CASE: CONTINUOUS TIME
Define the perturbed system of (1st-ODE-SC) by
(X = √μ(v — x)—七(Vf(X) + e(t)),
"=√μ(x - V) - √μ(Vf(X) + e(t)).
where e is a locally integrable function.
Definition C.3. Define the continuous time Liapunov function E(x, v)
E(x,v) = f(x) - f* + 2∣v - x*∣2
Define the perturbed Liapunovfunction E, by
E(t, x, v) := E(x, V) + I(t, x, v),
(Sto-1st-ODE-SC)
(20)
I(t, x) := e-√μt/e√μs
0
s) — x*) + √= Vf (x), e(s),ds.
Proposition C.4. We have,
WE(t,x, V) ≤ -√μE —LVf(X) ∣2 - √μμ ∣v - x∣2.
dt	ʌ/ L	2
Proof. Using (8), we obtain
d
/E(t,x, V) ≤
dt
≤
≤
dtE(X,v) — √μI(t,x) +〈—Mv — x*) + √L Vf(X),ei
-	√μE(X, v) - (—m(v - x*)+ √LVf(X), ei - √LIVf(X)I2 -	∣v - x∣2
-	√μl (t, x) + h√μ(V - x*) + √=Vf (x), ei
-	√μE(t, x, v) - √lIVf(X)12 -	∣v - x∣2
□
14
Under review as a conference paper at ICLR 2019
Lemma C.5. Suppose f is bounded from below and s → e Vμse(s) ∈ L1. Let (x, v) be a solution
of (Sto-1st-ODE-SC), then supt>0 |v(t) — x*| < +∞ and supt>0 |Vf (x)| < +∞.
Proof. Same as Attouch et al. (2016, Lemma 5.2), using the fact that 4 Vf (x)|2 ≤ f(χ) — f *,
t → E(x(t), v(t)) is decreasing and Gronwall S inequality.	□
Then, combining the two previous result, we obtain:
Corollary C.6. Suppose that s → eλse(s) is a L1(0, +∞) function. Let (x, v) be a solution of
(Sto-1st-ODE-SC) with initial condition (x(0),v(0)) = (x0, v0). Then,
f(x(t)) — f* + 2|v(t) — x*|2 ≤ Ceft,
where,
C = f (x0) — f * ÷ 口v0 — x* |2 + Ileλse(S)IlL1(0,+∞) sup
2	s≥0
√μ(v(s) — x*) ÷
√⅛ Vf(X)
Proof. By Proposition C.4 and Gronwall,s Lemma, we have
E(t,x(t),v(t)) ≤ e-√μtE(0,x0,v0).
This is equivalent to
f (x(t)) — f * ÷ 2 |v(t) — x* |2 ≤ e-√μt[f (x0) — f * ÷ 2 |v0
—x
*|2
÷ /
0
√μ(v(s) — x*) ÷ -1= Vf (x)归Bsg(s)|ds]
≤ Ce-√μt,
which concludes the proof with Lemma C.5.
□
D Proof Theorem 4.2
First, using the convexity and the L-smoothness of f, we obtain the following classical inequality
(see Attouch & Peypouquet (2016) or Su et al. (2014) in the case ek = 0),
k	2
f(xk + 1) — f	≤ k ÷2(f (Xk) — f )÷ k ÷2 hVf (yk ), Vk — X i
÷√L hek, Vf (yk ) ÷ eki ÷ ( — √L) |Vf (yk)÷ ek R
Then, we have
tk (f(xk+1) - f *)	— tk-1(f (Xk)- f *)
≤	( k ÷2 - tk-1) (f (Xk ) — f *)÷ k ÷2 hVf (Vk ), vk — x*i
÷ √=L hek, Vf(Vk ) ÷ ek i ÷ (2 — √l) htk|Vf(Vk ) ÷ ek |2
By defintion of v—i, we have
h2t2
—2htkhvk — x*, Vf (yk) ÷ ek i ÷-2L ∖Vf(Vk ) ÷ ek|2 .
2|vk + 1 — x* |2 — 2|vk — x* |2
In addition,
Ik+1 — Ik = 2htk hvk + 1 — X , ek).
15
Under review as a conference paper at ICLR 2019
Combining these three previous inequalities, we obtain
Ek+1 - Ek ≤
-h2(f(xk ) - f *) + (h - √l) tk hN f(yk ) + ek |2
ht2k
+2htk hek , vk + 1 - Vki + √jr hek , Vf (yk) + eki
≤
-h2(f(xk ) - f *) + (h - √l) tk h|Vf(yk ) + ek |2
hek, Vf(yk) + eki.
Since h =±,we deduce that Ek is decreasing. In particular,
1	k-1
2|vk - χ* |2 ≤ 2|v0 - χ* |2 + L ^X Ivi- χ* |(i + 3)∣ei∣.
and the discrete version of Gronwall Lemma gives the result since (i+3)|ei| is a summable sequence
due to (12).
E Proof of Proposition 3.4
To simplify, we denote λh
ι+h√μ. Note, however, since the gradients are evaluated at yk, not Xk,
the first step is to use strong convexity and L-smoothness to estimate the differences of E in terms
of gradients evaluated at yk.
Lemma E.1. Suppose that f is a μ-Stgnmgly convex and L-smooth function, then
f (xk+1) - f(xk) ≤ hVf(yk), yk - xki -
μ lyk - Xk |2 + 2 (h - √l) |Vf(yk )|2 .
(21)
Proof. First, we remark that
f (Xk+1) - f(Xk) = f(Xk+1) - f(yk) +f(yk) - f(Xk)
≤ hVf (yk), xk + 1 - yki + 2 |xk+1 - yk |2
+ hVf (yk),yk - xki - 2 |yk - xk |2.
Since the first line of (1st-ODE-SC) can be rewritten as
h
xk+1 = yk - √LVf (yk),
we obtain (21).	□
Proof of Proposition 3.4. Once (9) is established, since the expression on the right hand side is
monotone in h, the largest choice of h is given by h =圭,which leads immediately to (10).
In the proof we will estimate the linear termhyk - Xk, Vf (yk)i in terms of hyk - x*, Vf (yk)i plus
a correction which is controlled by the gap (the negative quadratic) in (21) and the quadratic term
in E .
The second term in the Liapunov function gives, using 1-smoothness of the quadratic term in E .
2	(|vk + 1 - x* |2 - |vk - x*F) = μhvk - x* , vk+1 - vk i + 2 |vk + 1 - vk |2
= -μλhhvk - x* ,vk - Xki
-h√μhvk - x*, Vf (yk)i
+ 2 |vk + 1 - vk |2.
16
Under review as a conference paper at ICLR 2019
Before going on, using the fact from (2), that yk is a convex combination of Xk and Vk, we have
λh(vk-Xk) = 1 ʌhʌ (Vk-Iyk) = h√μ(vk-yk) and Vk-yk = 1 - ʌh (yk-Xk) =	(y-Xk)
1 - ʌh	ʌh	h√μ
which gives
2 (∣Vk+1 - x* ∣2 - ∣Vk - x*∣2) = -hμ√μhvk - x*,Vk -期 k i
-h√μ{vk - yk, V/(yk)i - h√μ(yk - x*, ▽/(yk))
2 ∣vk+1 - vk ∣2
≤ -hμ√μ (∣vk- χ*∣2 + ∣vk-yk∣2-∣yk- χ*∣2)
-hyk - xk, Vf(Uk) - h√μ (Ayk)-于* + 2 ∣yk - x*∣2)
2 (∣yk - xk ∣2 + √μ hyk - xk, Vf(Uk ))+	IVf(Uk )∣2),
by strong convexity. Then using the L-smoothness of f, we obtain
2 (∣vk+1 - x* ∣2 - ∣vk - χ*∣2)	≤ - h√μEk - hyk - xk, V f (yk ))
+ (2 + h√μL - √) ∣yk - χk∣2 + Ih∣Vf(Uk)∣2∙	Q2)
Combining (21) and (22), we have
Ek+1 - Ek ≤ -h√μEk + (h2-*)∣Vf(yk)∣2 + (浮-*) ∣Xk - yk∣2
which concludes the proof of (9).	□
17