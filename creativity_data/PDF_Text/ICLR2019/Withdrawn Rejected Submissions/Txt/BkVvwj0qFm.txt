Under review as a conference paper at ICLR 2019
Geometric Operator Convolutional Neural
Network
Anonymous authors
Paper under double-blind review
Ab stract
The Convolutional Neural Network (CNN) has been successfully applied in many
fields during recent decades; however it lacks the ability to utilize prior domain
knowledge when dealing with many realistic problems. We present a framework
called Geometric Operator Convolutional Neural Network (GO-CNN) that uses
domain knowledge, wherein the kernel of the first convolutional layer is replaced
with a kernel generated by a geometric operator function. This framework inte-
grates many conventional geometric operators, which allows it to adapt to a di-
verse range of problems. Under certain conditions, we theoretically analyze the
convergence and the bound of the generalization errors between GO-CNNs and
common CNNs. Although the geometric operator convolution kernels have fewer
trainable parameters than common convolution kernels, the experimental results
indicate that GO-CNN performs more accurately than common CNN on CIFAR-
10/100. Furthermore, GO-CNN reduces dependence on the amount of training
examples and enhances adversarial stability.
1	Introduction
Convolutional Neural Networks have been successfully applied in many fields during recent decades,
but the theoretical understanding of the deep neural network is still in the preliminary stages. Al-
though CNNs have strong expressive abilities, they have two clear deficiencies. First, as complex
functional mappings, CNNs, like black boxes, cannot take full advantage of domain knowledge and
prior information. Second, when little data is available for a certain task, CNNs’ generalization
ability weakens. This is due to overfitting, which may occur due to the large number of parameters
and the large model size. Stemming from these two defects, a great deal of research has been done
to modify CNNs (Dai et al., 2017; Wang et al., 2018; Sarwar et al., 2017).
Before CNNs were applied, traditional geometric operators had developed quite well. Each geomet-
ric operator represents the precipitation of domain knowledge and prior information. For example,
the Sobel operator (Works) is a discrete difference operator, which can extract image edge infor-
mation for edge detection. The Schmid operator (Schmid, 2001) is an isotropic circular operator,
which extracts texture information from images for face recognition. The Histogram of Oriented
Gradients (HOG) (Dalal & Triggs, 2005) is a statistic operator of gradient direction, which extracts
edge direction distributions from images for pedestrian detection and other uses.
Many computer vision tasks require domain knowledge and prior information. For example, in Cao
et al. (2015), the texture information from the image is used for an auxiliary diagnosis of a fracture.
Geometric operators can make use of domain knowledge and prior information, but cannot automat-
ically change parameter values by learning from data. Convolutional Neural Networks have strong
data expression abilities and learning abilities, but they struggle to make use of domain knowledge.
For better data learning, we have combined the two. It is natural to directly use geometric operators
for pre-processing, and then classify the data through a Convolutional Neural Network (Yao et al.,
2016). However, this method uses human experience to select geometric operator parameter val-
ues, and then carries out the Convolutional Neural Network learning separately. This method is a
kind of two-stage technique, and without reducing parameter redundancy in a Convolutional Neural
Network, it is difficult to achieve global optimization. The method proposed in this paper directly
constructs geometric operator convolution and then integrates geometric operator convolution into
a Convolutional Neural Network to form a new framework - the Geometric Operator Convolutional
1
Under review as a conference paper at ICLR 2019
Neural Network. This method achieves global optimizations and utilizes the properties of geometric
operators.
In summary, the contributions of this work are as follows:
•	This framework can integrates many conventional geometric operators, which reveals its
broad customization capabilities when handling diverse problems.
•	In theory, the same approximation accuracy and generalization error bounds are achieved
when geometric operators meet certain conditions.
•	The Geometric Operator Convolutional Neural Network not only reduces the redundancy
of the parameters, but also reduces the dependence on the amount of the training samples.
•	The Geometric Operator Convolutional Neural Network enhances adversarial stability.
2	Related Work
In recent years, Convolutional Neural Networks have been widely used in various classification and
recognition applications (Krizhevsky et al., 2012; Hu et al., 2014). Convolutional Neural Networks
have achieved advanced success in various problems. All CNNs adopt an end-to-end approach to
learning; however, each unique task is associated with its own distinctive domain knowledge and
prior information. Thus, to improve classification accuracy, researchers use priori information that
is tailored to each specific task and each specific Convolutional Neural Network. One way to do this
is to use the traditional image processing algorithm as a preprocessing step. Another way is to use
the traditional image processing algorithm to initialize convolution kernels.
Classification accuracy is a primary concern for researchers in the machine-learning community.
Different pre-processing models, such as filters or feature detectors, have been employed to improve
the accuracy of CNNs. One example of this is the Gabor filter with CNN (Daugman, 1988). The
Gabor filter is a feature extractor based on human vision. Besides the Gabor filter, some people
also use Fisher vectors (Cimpoi et al., 2014), sparse filter Banks (Pfister & Bresler, 2015), and the
HOG algorithm (Lu et al., 2018) combined with a CNN to improve accuracy. Based on the human
visual system, these filters are found to be remarkably well-suited for texture representation and
discrimination. In the works by Kwolek (2005) and Mounika et al. (2012), the Gabor filter is used
to extract features from the input image in a pre-processing step. However, these methods require a
kind of two-stage procedure that may not reach the optimal global solution.
In addition, some scholars use traditional image processing algorithms to initialize convolutional
kernels, such as building a Feature Pyramid Network with an image pyramid for multi-scale feature
extraction (Lin et al., 2017). Geometric operators are widely used in traditional image processing al-
gorithms. Many researchers use the Gabor filter to fix the first convolution layer, while other layers,
which are common convolution layers, can be trained to improve their accuracy (Yao et al., 2016;
Sarwar et al., 2017). John et al. simultaneously adopted the weight of the first layer convolution
with the Gershgorin circle theorem and the Gabor filter constraint to improve the classification ac-
curacy when Convolutional Neural Networks propagated backward. In Calderon et al. (2003) and
Chang & Morgan (2014), the authors have attempted to get rid of the pre-processing overhead by
introducing Gabor filters in the first convolutional layer of a CNN. In addition, some researchers use
filters to initialize multiple convolutional kernels. Lu et al. (2018) only used the Gabor function to
create kernels in four directions to initialize the convolutional kernels from a Convolutional Neural
Network. These methods change the initialization weight and use domain knowledge, but they do
not reduce the redundancy of model parameters, and they do not enhance the transformation ability
of the model.
In this paper, a new network, the Geometric Operator Convolutional Neural Network, is proposed.
This method integrates geometric operators, namely the filters, into a convolutional neural network.
This network can not only make use of domain knowledge and prior information, but also reduce the
redundancy of network parameters and enhance the ability of model transformation. This network’s
construction is described in detail in the following section.
2
Under review as a conference paper at ICLR 2019
3	The framework of the Geometric Operator Convolutional
Neural Network
3.1	Geometric operators
Before the development of deep Convolutional Neural Networks, traditional image feature extraction
methods were based on traditional image processing algorithms, primarily geometric operators. At
present, a large number of geometric operators have been applied, such as the Scale Invariant Feature
Transform (SIFT) (Lowe, 1999), the Roberts operator (Rosenfeld, 1981), the Laplace operator (van
Vliet et al., 1989), the Gabor operator (Han & Ma, 2007), and so on. Each operator has different
characteristics. Therefore, different geometric operators are used in different application scenarios,
according to the characteristics of each unique problem. For example, SIFT looks for feature points
in different scale spaces for pattern recognition and image matching. The Roberts operator uses local
differences to find edges for edge detection, and the Laplace operator uses isotropic differentials to
retain details for image enhancement.
Geometric operators represent the precipitation of domain knowledge and prior knowledge. The
GO-CNN is proposed in this paper, which uses the characteristics of geometric operators. The first
step in this framework is to convolve geometric operators. In this paper, the Gabor operator and
the Schmid operator are mainly used as examples to illustrate how to carry out convolutions and
integrate these convolutions into CNNs. Other geometric operators in subsequent studies employ
similar concepts.
3.2	Convolution of geometric operators
3.2.1	Gabor operator
In order to study the frequency characteristics of local range signals, Gabor (1946) proposed the fa-
mous “Window” Fourier transform (also called the short-time Fourier transform, STFT) in the paper
“Theory of communication” in 1946. This is now known as the Gabor operator; when combined
with images, it is referred to as the Gabor filter. Until now, the Gabor filter has undergone many de-
velopments, and its primary characteristics are listed below. First, the Gabor filter has the advantages
of both spatial and frequency signal processing. As shown in Eqn. 1.0, the Gabor operator is essen-
tially a Fourier transform with a gaussian window. For an image, the window function determines
its locality in the spatial domain, so the spatial domain information from different positions can
be obtained by moving the center of the window. In addition, since the gaussian function remains
the same after the Fourier transform, the Gabor filter can extract local information in the frequency
domain. Second, the Gabor filter’s response to biological visual cells may be an optimal feature
extraction method. In 1985, Daugman (1985) extended the Gabor function to a 2-dimensional form
and constructed a 2D Gabor filter on this basis. It was surprising to find that the 2D Gabor filter
was also able to maintain consistency with the mammalian model of retinal nerve cell reception.
Third, the Gabor kernels are similar to the convolution kernels from the first convolutional layer in
the CNN. From the visualization of the first convolutional layer in AlexNet, which was proposed by
Krizhevsky et al. (2012). Some convolution kernels present geometric properties, as in the kernel
function from the Gabor filter. From this feature, it can also be explained that there are parameter
redundancies in the Convolutional Neural Network, and the Gabor operator can be convoluted and
integrated into CNN. Lastly, the Gabor filter can extract directional correlation texture features from
an image.
x x02 + y02λ	2 2πx0	'
gθ,Φ,γ,σ,λ(x,y) = exp I-2σ2- cos [ ~λ + φ
x0 = xcosθ + ysinθ
y0 = - xsinθ + ycosθ
(1.0)
Since the Gabor operator combines with the CNN in the image, better feature expressions can be
obtained. There are two main binding methods. First, the image is preprocessed by the Gabor
operator, and then its features are extracted by the CNN. Next, the Gabor operator is convoluted
3
Under review as a conference paper at ICLR 2019
to form a convolution layer, and then we integrate this convolution into the common Convolutional
Neural Network. The second approach is used in this article. As shown in Eqn. 1.0, the Gabor kernel
function has 5 parameters, which are obtained by learning and then regenerated into an m×m kernel.
We replace the common convolution kernels with these Gabor kernels to form a convolutional layer.
However, for the common convolutional layer, an m × m convolution kernel is generated by an
identity mapping, which requires m2 parameters. So, our method reduces the number of trainable
parameters in the convolutional layer.
3.2.2	Schmid operator
In 2001, Schmid (2001) proposed a Gabor-like image filter, namely the Schmid operator. As shown
in Eqn. 2.0, its composition is similar to the kernel function of the Gabor operator, so it retains
the properties of the Gabor operator. In addition, the Schmid operator has rotation invariance. So,
the Schmid operator is convoluted, and we integrate this convolution into common Convolutional
Neural Network. This network improves the model’s adversarial stability to rotation and improve
the image feature extraction effect. Similar to the convolution of the Gabor operator, as shown in
Eqn. 2.0, the Schmid kernel function has two parameters, which are obtained by learning and then
generated by the Schmid kernel. Finally, we replace common convolution kernels with Schmid
kernels to form a convolutional layer.
Fσ,τ (r)
2πτr
cos -----
σ
(2.0)
r =	x2 + y2
In this paper, only two geometric operator convolutions are explained. Similarly, for other geometric
operators, operator kernels are generated by operator kernel functions, which replace common con-
volution kernels to form a convolutional layer. Due to the diversity of geometric operators, different
geometric operators can be replaced with geometric operator convolutions, so the geometric opera-
tor convolution is customizable. There is a kind of geometric operator to form any kind of geometric
operator convolution. Consequently, a question that must be addressed is how we combine multiple
geometric operators with common CNNs to form GO-CNNs.
3.3	Geometric Operator Convolutional Neural Network
Since the visualization of the first layer of convolution kernels maintains some geometric charac-
teristics, we replace the convolution kernel in the first convolutional layer by kernel generated from
geometric operators, and denote this kind of CNN as Geometric Operator Convolutional Neural
Network (GO-CNN). In GO-CNN, kernels from the first convolutional layer are calculated by pa-
rameters of various geometric operator functions, and we call these operator functions as generator
functions. Then, we concatenate all the calculated convolutional kernels in the last dimension to
obtain a complete convolutional kernel. The full procedure is illustrated in Fig. 1. The generated
convolution kernel is used as the weight of the first convolution layer in the Geometric Operator
Convolutional Neural Network, and then the common convolution layer and output layer are con-
nected. In this way, we have defined the forward propagation of the whole Geometric Operator
Convolutional Neural Network. So, in backward propagation, the gradient of loss is transferred to
the convolution kernel; this process is different from the usual convolution. Here, the convolution
kernel generated by the geometric operator needs to further use the chain derivative rule (i. e., Eqn.
3.0, where L is the loss function, w is each convolution kernel, and pi is the parameter to gener-
ate each convolution kernel) to transfer the gradient to the parameters of each convolution kernel.
Then, trainable parameters are updated by gradient descent algorithms, and the whole GO-CNN is
complete.
∂L ∂L ∂w
---=----二--
∂pi ∂w ∂pi
(3.0)
4	Theoretical analyses
The whole framework of the Geometric Operator Convolutional Neural Network has been intro-
duced above. Next, we describe how to theoretically analyze the GO-CNN. It is theoretically proved
4
Under review as a conference paper at ICLR 2019
Convolution kernel
Figure 1: For each out channel, parameters (the first row) are fed into a generator function (the
second row), and generate a kernel (the third row). Then, kernels are concatenated to get the convo-
lution kernel in the first convolutional layer. In the second row, G(∙) is Gabor kernel function, S(∙) is
SChmid kernel function, and I(∙) is identity mapping.
that although the number of trainable parameters in the GO-CNN decreases, the effectiveness for
computer vision tasks does not decrease. All detailed proofs are expanded in Appendix B.
4.1	Definition of data and loss function
•	We denote the input by S = {Ii}iN=1, the corresponding label is {yi|yi = 0 or 1}iN=1.
•	The loss function is Mean Square Error.
•	The output of the neural network is yi for each input Ii, and the empirical loss function is
defined as follows:
1N
E s [h] = N E⑨i- yi)
(4.0)
i=1
Definition 1 (Parametric Convolutional Kernel Space). Let f be a function that maps vector from
Rn to matrix in Rm×m , n, m ∈ N+, and we call this function as convolution kernel generator
function. Then we define Parametric Convolutional Kernel Space Kf as:
Kf ={[f(p1),f(p2),∙∙∙ ,f(pod)],pi ∈D⊂Rn,
i = 1, 2, ∙ ∙ ∙ , od}.
(5.0)
We call n the parameter number, m the kernel size, od (short for output dimension) the output
dimension. Since a convolutional kernel in a parametric convolutional kernel spaces is generated
by function f, we call f as the generator function, and fi,j (p) = f (p)[i, j] as the pixel generator
function.
Since kernel can be generated from a generator function by fewer parameters than ordinary kernel,
the amount of trainable parameters of GO-CNN can be much smaller. However, reduction in param-
eters often causes loss of performance as the hypothesis space is smaller. In the simplest situation,
we replace the ordinary kernel in the first convolutional layer by the parameter kernel generated
from a parametric convolutional kernel space, and study on it.
Definition 2 (GO-CNN). Assume that Kf is a parametric convolutional kernel space. If the kernel
in the first convolutional layer of a convolutional neural network is generated from Kf, we call this
network GO-CNN. We denote the set of GO-CNN by Gf.
GO-CNN is almost exactly the same as common CNN, except for the kernel in the first convolutional
layer. We treat the first convolutional layer as a function from images to outputs, which then act as
input of the following layer. If this function is not an injective function, meaning that different inputs
can be mapped to identical outputs, then the network takes these identical outputs as the input of the
following layers, meaning that the final outputs are still the same. However, the image inputs of the
first convolutional layer are different, and corresponding labels can also be different. Thus, when
the final outputs are the same, errors must occur.
5
Under review as a conference paper at ICLR 2019
Therefore, we need to choose kernel carefully to make the function be an injective function. Since
the convolution operator is a linear operator, we have the following proposition.
Proposition 1. If the kernel of a convolutional layer, denoted by w, satisfies the following:
I * W = 0 ⇔ I = 0,	∀I
(6.0)
where I is the layer input and * is the convolution operation, then this convolutional layer is an
injective function.
We find a necessary and sufficient condition for a convolutional layer to be an injective function. But
which kernel satisfies this condition? In the proposition below, we show that 3 × 3 kernel generated
by Gabor kernel function satisfies this condition.
Proposition 2. Let f be the Gabor kernel function, that is fx,y (θ, σ, γ, λ, ψ)	=
exp(- X—+；2y )cos(2π% + ψ), where x0 = xcosθ + ysinθ, y0 = -xsinθ + ycosθ. Let Kf be the
corresponding parametric convolutional kernel space with kernel size m equal to 3 and sufficient
output dimension od. Then, there exists kernel in Kf satisfies the condition (6.0).
As the kernel generated from Kf could not meet the (6.0), we have the following definition:
Definition 3 (Well-Defined GO-CNN). Let G ∈ Gf, if there is a kernel generated by Kf that
satisfies (6.0), we call G a well-defined GO-CNN. We denote the set of all well-defined GO-CNNs
as Gf.
Corollary 1. If the generator function f is Gabor kernel function, the GO-CNN is well-defined.
Now, let us consider a Convolutional Neural Network with one convolutional layer and two fully
connected layers, and we will study the convergency of common CNN and GO-CNN. The detailed
mathematical expression is expanded in Appendix B.
Theorem 1.	For any F ∈ F, where F is the set of common CNN, if the first fully connected layer
is wide enough, the empirical loss of a well-defined GO-CNN can be that of common CNN controls.
That is, for an arbitrary > 0, there exists df ∈ N+ and G ∈ Gff, such that when d1 ≥ df, the
following inequality holds:
.ʌ - - ʌ --.
|E S [G] - E S [F ]| ≤ e
(7.0)
Theorem 2.	For any F ∈ F, where F is the set of common CNN, if the first fully connected
layer is wide enough, the generalization error of a well-defined GO-CNN can be that of common
Convolutional Neural Network controlled. That is, for an arbitrary > 0, there exists df ∈ N+ and
G ∈ Gff, such that when d1 ≥ df, the following inequality holds:
ED [G] ≤ ES [F]+ 2RS (F) + Jl0g兽 + e
(8.0)
In Theorem. 2, we know that well defined GO-CNNs have almost the same generalization error as
common CNNs. Therefore, we need to find which GO-CNNs are well defined.
As GO-CNN with Gabor kernel function as the generator function is well defined, we have the
following corollary.
Corollary 2. Let f be Gabor kernel function, for any F ∈ F, if the first fully connected layer is
wide enough, the generalization error GO-CNN G, which applies f as the generator function can
be that of F controlled. That is, for an arbitrary > 0, there exists df ∈ N+ and G ∈ Gff, such that
when d1 ≥ df, the following inequality holds:
ED [G] ≤ ES [F]+ 2RS (F) + ^gNδL + e
(9.0)
More generally, if there are many generator functions in the first convolutional layer of a GO-CNN,
when the number of kernels generated by Gabor kernel function is sufficient enough, this GO-CNN
is also well defined. Therefore, we have the following corollary.
Corollary 3. Let {fι, f2, ∙∙∙ , fτ} be the Set of generator functions. Suppose that there are od
ConvolUtion kernels {kι, k2, •…,kod} in the first convolutional layer of a GO-CNN, denoted by
G, and each kj is generated by function ftj, where 1 ≤ j ≤ od, 1 ≤ tj ≤ T. If there exists
tf ∈ {1, 2,，T} such that ft* is Gabor kernel function, and the number of kernels generated by
ft*, denoted by nt*, is SUffiCient big enough, then G is well defined, so that (8.0) holds.
6
Under review as a conference paper at ICLR 2019
5	Experiments
All experiments are performed on a single machine with CPU Intel Core i7-7700 CPU @ 3.60GHz
× 8, GPU TITAN X (Pascal), and RAM 32G. Experimental details and more experiments are given
in Appendix C, respectively.
5.1	Approximation accuracy and generalization error
Theoretical analyses ensures that the GO-CNN has the same approximation accuracy and the same
upper bound for generalization error as the common CNN. We verify this using two kinds of experi-
ments on CIFAR-10/100 datasets. For the GO-CNN, the convolution kernels from the first layer are
half trainable Schmid kernels and half trainable Gabor kernels. The basic network frameworks used
Table 1: The model’s accuracy rates averaged over five experiments on the test set
—	CIFAR-10	CIFAR-100
common ResNet18	94.79%^^	77.06%
GO-ResNet18	95.17%	77.59%
common ResNet34	95.27%	78.26%
GO-ResNet34	95.77%	78.72%
common ResNet50	94.44%	78.45%
GO-ResNet50	94.72%	79.50%
in these experiments are ResNet18, ResNet34, and ResNet50 (He et al., 2016).
According to the cross-entropy curve of CIFAR-10/100 train sets, GO-CNN’s value initially fell
faster than the common CNN’s, eventually almost reaching the same value. It is verified that GO-
CNN achieves the same approximation accuracy as the common Convolutional Neural Network.
According to the error rate curve of CIFAR-10/100 verification sets, the value of GO-CNN is lower
than that of the common CNN. In addition, as shown in Table 1, the GO-CNN on the CIFAR-10
test set was 0.4% more accurate than the common CNN. On the CIFAR-100 test set, the GO-CNN
was 0.5% more accurate than the common CNN. It is verified that the GO-CNN achieves the same
generalization error bound as the common CNN.
5.2	Generalization
In many practical applications, such as the military, medical care, and so on, annotated data are
often insufficient. Thus, a model’s generalization ability for small data sets is of great importance.
For CIFAR-10/100 and MNIST datasets, their train sets are large and their test sets are small. So,
in these numerical experiments, the test set is directly used to train the model, and the train set is
used to evaluate the model. For numerical experiments with CIFAR-10/100 datasets, the techniques
and models used are the same as in Sec. 5.1. For numerical experiments with MNIST dataset, the
basic network structure used in the experiment is LeNet (LeCun et al., 1998). Similarly, in the GO-
CNN, the first convolutional layer is replaced by the operator convolutional layer. The convolution
kernels from the first layer are composed of trainable Gabor kernels and Schmid kernels. The other
convolutional layers are the common convolutional layers.
As shown in Table 2, from the perspective of the accuracy of MNIST and CIFAR-10/100, after the
train set drops to one-fifth of the original train set, the accuracy of the common CNN falls faster
than the GO-CNN. Moreover, the GO-CNN more accurate than the common CNN on the original
train set. That is to say, the GO-CNN is better at predicting unknown data than the common CNN.
The GO-CNN not only reduces the redundancy of the parameters, but also reduces the dependence
on the amount of training samples.
5.3	Adversarial stability
The current machine learning model, including the neural network and other models, is vulnerable
to attacks from adversarial samples. In addition, CNNs show instability under attacks against adver-
sarial samples (Goodfellow et al., 2014). So, it is very important to study the stability of adversarial
7
Under review as a conference paper at ICLR 2019
Table 2: The accuracy of the test set for the small train set and the large train set (in brackets)
—	CIFAR-10	CIFAR-100	MNIST
common ResNet18	84.96%(94.79%)	44.97%(77.06%)	—
GO-ResNet18	8621%(95.17%)	47.03%(77.59%)	—
common ResNet34	82.33%(95.27%)	44.74%(78.26%)	—
GO-ResNet34	86.36%(95.77%)	49.00%(78.72%)	—
common ResNet50	83.86%(94.44%)	45.93%(78.45%)	—
GO-ResNet50	85.64%(94.72%)	47.09%(79.50%)	—
common LeNet	—	—	97.75%(99.22%)
GO-LeNet	—	—	97.97%(99.24%)
Table 3: The adversarial stability of randomly rotated samples and Gaussian disturbance samples.
The loss compared to the original accuracy is in brackets, the smaller value is marked in green.
-	original	randomly rotated	Gaussian disturbance
common LeNet	99.22%	58.97%(-40.25%)	95.69%(-3.53%)
GO-LeNet	99.24%	60.20%( 39.04%)	96.31%(-2.93%)
samples in practice. The stability of the model is measured by the difference between the accuracy
of the original test set and the adversarial sample generated by the test set. The open handwriting
recognition dataset (MNIST) is the primary dataset used in these experiments. The techniques and
models are the same as those used for MNIST in Sec. 5.2. Both models are trained on the MNIST
train set. Original images, adversarial samples of gaussian interference, and adversarial samples
from random rotation are used to evaluate the two models.
It can be seen from Table 3 that when the test set is randomly rotated within 90 degrees, the difference
of the GO-CNN is 1.21% lower than that of the common CNN. This verifies that the GO-CNN
enhances the adversarial stability of rotated samples. When the small Gaussian disturbance (the
mean is 0, the standard deviation is 0.3) is applied to the test set, the difference of the GO-CNN is
0.6% lower than that of the common CNN. This indicates that the GO-CNN enhances the adversarial
stability of Gaussian disturbance adversarial samples. In sum, the GO-CNN enhances the adversarial
stability of certain adversarial samples.
In the above experiments, the Geometric Operator Convolutional Neural Network uses a priori
knowledge from the field of medicine and provides a better recognition effect. Experiments about
intelligent medical diagnoses of bone fractures is given in Appendix C. Although the trainable pa-
rameters decrease, GO-CNN still reaches the same approximation accuracy and a slightly lower gen-
eralization error upper bound when compared with the common CNN. And the GO-CNN reduces
the dependence on training samples and enhances the adversarial stability of certain adversarial
samples.
6	Conclusion and Future Research
In this paper, we present a novel framework named the Geometric Operator Convolution Neural
Network, where the kernel in the first convolutional layer is replaced with kernels generated by
geometric operator functions. This new network boasts several contributions. Firstly, the GO-CNN
is customizable for diverse situations. Secondly, there is a theoretical guarantee in the learning
framework of the GO-CNN. Thirdly, the GO-CNN reduces the dependence on training samples.
Lastly, the GO-CNN enhances adversarial stability. In the future, we can explore a more appropriate
geometric operator convolution block.
References
Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463-482, 2002.
8
Under review as a conference paper at ICLR 2019
Andres Calderon, Sergio Roa, and Jorge Victorino. Handwritten digit recognition using convolu-
tional neural networks and gabor filters. Proc. Int. Congr. Comput. Intell, 2003.
Yu Cao, Hongzhi Wang, Mehdi Moradi, Prasanth Prasanna, and Tanveer F Syeda-Mahmood. Frac-
ture detection in x-ray images through stacked random forests feature fusion. In Biomedical
Imaging (ISBI), 2015IEEE 12th International Symposium on,pp. 801-805. IEEE, 2015.
Shuo-Yiin Chang and Nelson Morgan. Robust cnn-based speech recognition with gabor filter ker-
nels. In Fifteenth annual conference of the international speech communication association, 2014.
Seok Won Chung, Seung Seog Han, Ji Whan Lee, Kyung-Soo Oh, Na Ra Kim, Jong Pil Yoon,
Joon Yub Kim, Sung Hoon Moon, Jieun Kwon, Hyo-Jin Lee, et al. Automated detection and clas-
sification of the proximal humerus fracture by using deep learning algorithm. Acta orthopaedica,
pp. 1-6, 2018.
Mircea Cimpoi, Subhransu Maji, and Andrea Vedaldi. Deep convolutional filter banks for texture
recognition and segmentation. arXiv preprint arXiv:1411.6836, 2014.
George Cybenko. Approximation by superpositions ofa sigmoidal function. Mathematics of control,
signals and systems, 2(4):303-314, 1989.
Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, and Yichen Wei. Deformable
convolutional networks. CoRR, abs/1703.06211, 1(2):3, 2017.
Navneet Dalal and Bill Triggs. Histograms of oriented gradients for human detection. In Com-
puter Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on,
volume 1, pp. 886-893. IEEE, 2005.
John G Daugman. Uncertainty relation for resolution in space, spatial frequency, and orientation
optimized by two-dimensional visual cortical filters. JOSA A, 2(7):1160-1169, 1985.
John G Daugman. Complete discrete 2-d gabor transforms by neural networks for image analysis
and compression. IEEE Transactions on acoustics, speech, and signal processing, 36(7):1169-
1179, 1988.
Dennis Gabor. Theory of communication. part 1: The analysis of information. Journal of the
Institution of Electrical Engineers-Part III: Radio and Communication Engineering, 93(26):429-
441, 1946.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014.
Ju Han and Kai-Kuang Ma. Rotation-invariant and scale-invariant gabor features for texture image
retrieval. Image and vision computing, 25(9):1474-1481, 2007.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen. Convolutional neural network architectures
for matching natural language sentences. In Advances in neural information processing systems,
pp. 2042-2050, 2014.
Vijay John, Ali Boyali, and Seiichi Mita. Gabor filter and gershgorin disk-based convolutional filter
constraining for image classification.
Ian Jolliffe. Principal component analysis. In International encyclopedia of statistical science, pp.
1094-1096. Springer, 2011.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convo-
lutional neural networks. In Advances in neural information processing systems, pp. 1097-1105,
2012.
9
Under review as a conference paper at ICLR 2019
Bogdan Kwolek. Face detection using convolutional neural networks and gabor filters. In Interna-
tional Conference on Artificial Neural Networks, pp. 551-556. Springer, 2005.
Yann LeCun, Leon Bottou, YoshUa Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Tsung-Yi Lin, Piotr Dollar, Ross B Girshick, Kaiming He, Bharath Hariharan, and Serge J Belongie.
Feature pyramid networks for object detection. In CVPR, volume 1, pp. 4, 2017.
Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. arXiv
preprint arXiv:1608.03983, 2016.
David G Lowe. Object recognition from local scale-invariant features. In Computer vision, 1999.
The proceedings of the seventh IEEE international conference on, volume 2, pp. 1150-1157. Ieee,
1999.
Tongwei Lu, Dandan Wang, and Yanduo Zhang. Fast object detection algorithm based on hog and
cnn. In Ninth International Conference on Graphic and Image Processing (ICGIP 2017), volume
10615, pp. 1061509. International Society for Optics and Photonics, 2018.
Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine
learning research, 9(Nov):2579-2605, 2008.
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of machine learning.
MIT press, 2012.
BR Mounika, NJ Reddy, and VBD Reddy. A neural network based face detection using gabor filter
response. International Journal of Neural Networks (ISSN: 2249-2763 & E-ISSN: 2249-2771), 2
(1):06-09, 2012.
Luke Pfister and Yoram Bresler. Learning sparsifying filter banks. In Wavelets and Sparsity XVI,
volume 9597, pp. 959703. International Society for Optics and Photonics, 2015.
Azriel Rosenfeld. The max roberts operator is a hueckel-type edge detector. IEEE Transactions on
Pattern Analysis and Machine Intelligence, (1):101-103, 1981.
Syed Shakib Sarwar, Priyadarshini Panda, and Kaushik Roy. Gabor filter assisted energy efficient
fast learning convolutional neural networks. arXiv preprint arXiv:1705.04748, 2017.
Cordelia Schmid. Constructing models for content-based image retrieval. In Computer Vision and
Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Con-
ference on, volume 2, pp. II-II. IEEE, 2001.
Lucas J van Vliet, Ian T Young, and Guus L Beckers. A nonlinear laplace operator as edge detector
in noisy images. Computer vision, graphics, and image processing, 45(2):167-195, 1989.
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He. Non-local neural networks. In
The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.
How It Works. Sobel edge detector. cse. secs. oakland. edu.
Hu Yao, Li Chuyi, Hu Dan, and Yu Weiyu. Gabor feature based convolutional neural network for
object recognition in natural scene. In Information Science and Control Engineering (ICISCE),
2016 3rd International Conference on, pp. 386-390. IEEE, 2016.
A Appendix
A supplementary explanation about the Gabor and Schmid operators.
The Gabor kernels are similar to the convolution kernels from the first convolutional layer in the
CNN. An illustration of this similarity is shown in Figure 2. In addition, the Gabor filter can extract
directional correlation texture features from an image. As shown in Figure 3, there are 40 Gabor
10
Under review as a conference paper at ICLR 2019
(b) Gabor kernels
(a) Convolution kernels from the
first layer of ResNet50
Figure 2: The similarities between the CNN’s first convolutional kernels and Gabor kernels.
Gabor Kernels
Output
Input
Figure 3: The results of the Gabor operator on an image
kernels from five scales and eight directions convolving with an image. Texture feature maps in
different directions can be obtained from the original image.
As shown in Figure 4, when the original image and a version of that image that has been rotated 90
degrees are both convolved with the same Schmid kernel, the resulting characteristic graph exhibits
only 90 degrees of rotation. So, the Schmid operator has rotation invariance.
Figure 4: The results of the Schmid operator on an image
B	Appendix
Lemma 1. (Cybenko, 1989) Define a functional class Π ⊂ {f | f : Rd 7→ [0, 1]}, where each
f ∈ Π can be approximated with error at most by a one hidden-layer neural network N, that is:
|f (x) - N (x)| ≤ , ∀x	(10.0)
Lemma 2. (Bartlett & Mendelson, 2002) let F and G be two hypothesis classes and let a ∈ R be
a constant, we have:
11
Under review as a conference paper at ICLR 2019
ʌ _ , ʌ _ ,
F⊆G⇒ RS (F) ≤ RS (G)
ʌ _ , ʌ _ , ʌ _ ,
RS (F + G) ≤ RS (F) + RS (G)
(11.0)
Lemma 3. (Mohri et al., 2012) Let z be a random variable of support Z and distribution D. Let
S = {zι, z2, ∙…，ZN } be a data set of N i.i.d. samples drawn from D. Let F be a hypothesis class
satisfying F ⊆ {f | f : Z → [a, a + 1]}. Fix δ ∈ (0, 1). With probability at least 1 - δ over the
choice of S, the following holds for all h ∈ F:
ED [h] ≤ ES [h] + 2RS (F) + JogNf)	(12.0)
Proof of Proposition1.
Assume that the proposition is not true, then there exist Ii = I2, such that Ii * W = I2 * w. Thus, if
We set I = Ii 一 I2, we have I * W = (Ii — I2) * W = 0, since * is a linear operator, which means
that I = 0 according to the condition. Therefore, the assumption is not true, and the conclusion is
proved.	口
Proof of Proposition2.
Assume that there exists I ∈ R3×3, I 6= 0, such that I * k = 0 holds for ∀k ∈ Kf.
We write I in the following matrix way:
a00	a0i
I = ai0 aii
a20 a2i
a02
ai2
a22
(13.1)
We define the pixel generator function fij tobe fx-i,y-i(θ, σ, γ, λ, ψ). Then, we have the following
equivalence:
22
I * k = 0 ^⇒ E ∑Saijfij = 0.
(13.2)
We will choose a variety of different parameters to discuss.
I. θ = 0, λ = 1, ψ = 0.
Since θ = 0, we have x0 = x, y0 = y, and the following:
(13.3)
We make the following shorthands for conveniency:
(13.4)
12
Under review as a conference paper at ICLR 2019
From Eqn.13.2, we can get:
(a00 + a02 + a20 + a22)h1 + (a01 + a21)h2 + (a10 + a12)h3 + a11 = 0.	(13.5)
The equation above means that, ∃ b0, b1, b2, b3 ∈ R, such that
b0 + b1h1 + b2h2 + b3h3 = 0.	(13.6)
Differentiate on both sides of parameter γ and get:
-σγ2bιhι — ^b3h3 = 0
=⇒bι +exp	)b3 = O
(13.7)
Since Eqn.13.7 holds for ∀γ, σ, which indicates that:
b1 = b3 = 0
(13.8)
In the same way, we can get the following equation from Eqn.13.8:
b2h2 + b0 =0
b0 = b2 = 0
(13.9)
Therefore, we have the following equations:
a00 + a02 + a20 + a22 = 0
a01 + a21 = 0
a10 + a12 = 0
a11 = 0
(13.10)
II. θ = 0, λ = 3, ψ = π∕3.
In the same way, we have the following equations:
/ʌ
000 1 1
f2f0 f- f0 f-
===
- 2
f2f0 f-
===
h2
1-21-2
==
13
hh
1-21-2
(13.11)
And we can get:
(a00 + a02)h1 + a01 h2 + (a10 + a12)h3 + a11 = 0,	(13.12)
which indicates that:
a00 + a02 = 0
a01 = 0
From Eqn.13.10, we can get:
(13.13)
13
Under review as a conference paper at ICLR 2019
a00 + a02 = 0
a01 = a21 = 0
(13.14)
III. θ = 0, λ = 3, ψ = -π∕3.
We can get the following equations in the way just the same as discussed in situation II:
a20 + a22 = 0
(13.15)
IV. θ = π∕2, λ = 3, ψ = ±π∕3.
We have x0 = y, y0 = x this time, and we can get the following equations as the way discussed in
situation II III, :
a00 + a20
a02 + a22
a10 = a12
0
0
0
(13.16)
Combine equations 13.14 13.15 13.16, we can get:
a00 = -a02 = a22 = -a20 = v
a01 = a10 = a12 = a21 = 0
(13.17)
V. θ = π∕4, λ = 2, ψ = √2π.
We have χ0 =4(x + y),y0 =今(y - x) and the following:
f00
f02
f22
eχp (-σ12)	2
f20 = exp (-γ⅛)
exp (一σ⅛) cos(2√2π)
(13.18)
Therefore, we have
,	, L、、	,	1 .	, L 、 γ Y2 .
(1 + cos(2√π)) exp(-^)V + 2 cos(2√2π) exp(--^)V = 0
σ2	σ2
=⇒ V = 0
=⇒ a00 = a02 = a20 = a22 = 0
(13.19)
Combine equations 13.10 13.17 13.19, we can find that aij = 0, fori, j = 0, 1, 2, which means that
I = 0. Therefore, the assumption that I 6= 0 is not true.
For an arbitrary sized input I , we can focus on the 3 × 3 sized submatrix that will do inner product
with the convolution kernel and get the same conclusion.
□
Proof of Corollary1.
From Prop.2, the conclusion is obvious.
□
For the common CNN, denoted by F, we define the convolution kernel as kF. The weights of the
rest of fully connected layers are {aF,1 , aF,2}, and the biases of three layers are {bF,0, bF,1 , bF,2}.
Let σ stand for sigmoid activation function, then the convolutional layer CF and the fully connected
layer F CF can be defined as follows:
CF (x) = X * kF + bρ,,o
F CF,k (x) = aF,k x + bF,k , k = 1, 2
(14.1)
14
Under review as a conference paper at ICLR 2019
Then, the last two fully connected layers can be defined as:
DF (x) = F CF,2 ◦ σ ◦ F CF,1(x)
(14.2)
Therefore, the output before activation, denoted by F (x), and after activation, denoted by F (x), are
defined as:
F (x) = DF ◦ σ ◦ CF (x)
~ , 一 ,
F(x) = σ ◦ F(x)
(14.3)
We denote the set of common CNN as F, that is, F = {F}, and the output before activation and
after activation of input Ii as Fi,Fi.
For a GO-CNN G, we similarly define the convolutional kernel to be kg, and the weights and biases
are {aG,1, aG,2, bG,0, bG,1, bG,2}. Then, we have the following shorthand when the input is x:
CG(X) = X * kg + bG,o
F CG,k = aG,k x + bG,k , k = 1, 2
DG(X) = F CG,2 ◦ σ ◦ F CG,1 (X)	(14.4)
G(X) = DG ◦ σ ◦ CG (X)
^r. ,	_ .,
G(X) = σ ◦ G(x)
We denote the output before activation and after activation of input Ii as Gi, Gi as well.
We maintain the same neuron number for each corresponding layer in common CNN and GO-CNN,
that is to say, dim(bF,k) = dim(bG,k), k = 0, 1, 2, since the approximation ability is different
when the neuron number is different. We define the width of each layer as dk = dim(bF,k) =
dim(bG,k), k = 0, 1, 2.
For the common CNN, denoted by F , we define the convolution kernel as kF . The weights of the
rest of fully connected layers are {aF,1, aF,2}, and the biases of three layers are {bF,0, bF,1, bF,2}.
Let σ stand for sigmoid activation function, then the convolutional layer CF and the fully connected
layer FCF can be defined as follows:
CF (X) = X * kF + bF,0
F CF,k (X) = aF,k X + bF,k ,	k = 1, 2
(15.1)
Then, the last two fully connected layers can be defined as:
DF(X) = FCf,2 ◦ σ ◦ FCf,i(x)	(15.2)
Therefore, the output before activation, denoted by F (X), and after activation, denoted by F (X), are
defined as:
F(X) = DF ◦ σ ◦ CF (X)
~ , 一 ,
F(x) = σ ◦ F(x)
(15.3)
We denote the set of common CNN as F, that is, F = {F}, and the output before activation and
after activation of input Ii as Fi,Fi.
For a GO-CNN G, we similarly define the convolutional kernel to be kg , and the weights and biases
are {aG,1, aG,2, bG,0, bG,1, bG,2}. Then, we have the following shorthand when the input is X:
CG(X) = X * kg + bG,0
F CG,k = aG,k X + bG,k , k = 1, 2
DG(X) = FCg,2 ◦ σ ◦ FCg,i(x)	(15.4)
G(X) = DG ◦ σ ◦ CG (X)
≈.,	_.,
G(X) = σ ◦ G(x)
15
Under review as a conference paper at ICLR 2019
(16.1)
We denote the output before activation and after activation of input Ii as Gi, Gi as well.
We maintain the same neuron number for each corresponding layer in common CNN and GO-CNN,
that is to say, dim(bF,k) = dim(bG,k), k = 0, 1, 2, since the approximation ability is different
when the neuron number is different. We define the width of each layer as dk = dim(bF,k) =
dim(bG,k), k = 0, 1, 2.
Proof of Theorem1.
Notice that
N(ES [G] - ES [F]) = X G2 - Fi - 2yi(Gi - Fi)
i
=E(Gi - Fi)(Gi + Fi- 2yi)
i
Apply absolute value on both sides
NIES [G] - ES [F]| ≤ ɪ2 IGi- FiIIGi + Fi - 2yi|
i
X
IGi- FiI * * 4
i
EI 1 . ∙	1 ∙ . 1 11	I 7-ɪ I I 入 I I 1/1
The last inequality holds as IFiI, IGiI, IyiI ≤ 1.
We can fix parameters of ordinary CNN, so that there is a mapping between input Ii and output Fi,
and the mapping function is F as we have defined.
We can also fix parameters of CG, and choose the convolution kernel of CG that satisfies (??) since
G is a well-defined GO-CNN, so that CG is an injective function, which means that CG-1 exists. In
the same time, DG = F CG,2 ◦ σ ◦ F CG,1 can be treated as a one hidden layer neural network.
1
Define a new hypothesis h = σ ◦ F ◦ CG-1 ◦ σ-1 ranges in [0, 1], according to Lemma.1, we can find
parameters {aG,k, bG,k}, k = 1, 2, such that
. _ , ~ ,	..
Iσ ◦ DG(X) — h(x)I ≤ e/4, ∀x.	(16.3)
Replace x by σ ◦ CG (Ii ) we can get
IGi- Fil
=IG(Ii)- F(Ii)I
= Iσ ◦ DG ◦ σ ◦ CG(Ii) - σ ◦ F(Ii)I	(16.4)
= Iσ ◦ DG(σ ◦ CG(Ii)) - σ ◦ F ◦ CG-1 ◦ σ-1(σ ◦ CG(Ii))I
≤ /4
Combine with (16.2), we can get
4	4N
IE S [G] - E S[F ]I ≤ N EIG i - Fii≤ N 1 = E	(16.5)
i
□
Proof of Theorem2.
From Theorem.1, we know that G satisfies the following inequality:
(16.2)
16
Under review as a conference paper at ICLR 2019
.ʌ - - ʌ - -.
|E S [G] — E S [F ]| ≤ E
From Lemma.3, we know that
ED[G] ≤ ES[G] + 2RS(Gf) + rlogNδ)
≤e s [F ]+2Rs (Gf)+r lθgNδ)+E
Since Gff ⊂ F, we have the following inequality from Lemma.2:
ʌ _ , . . ʌ _ ,
RS(Gf) ≤ RS(F)
Combined with (17.2), we have
ED [G] ≤ Es [F] + 2RS (F) + r IlogNδ + E
The conclusion is proved!
Proof of Corollary2.
From Theorem.2 and Corollary.1, this conclusion is obvious.
(17.1)
(17.2)
(17.3)
(17.4)
□
□
Proof of Corollary3.
Let K be the set of k such that the generator function of k is 九=ft* and denote the concatenation
Cll ,1	7	f
of all these ki as k.
Suppose that there exists an input x, satisfies that x*k = 0, i = 1,2, ∙∙∙ ,od, then x*k = 0, ∀k ∈ K.
Therefore, X * k holds for any parameters. However, it is conflict With Prop.2.
Therefore, the conclusion is proved!	□
C Appendix
Approximation accuracy and generalization error Recognizing objects in an actual scene is not
dependent on corresponding domain knowledge but on humans’ prior information. For object recog-
nition tasks, the Geometric Operator Convolutional Neural Network’s recognition effect is worth
exploring. The commonly used public data sets for common object recognition are CIFAR-10 (ten
categories) and CIFAR-100 (100 categories). They are all three-channel color images with a reso-
lution of 32×32. The train set contains 50,000 images and the test set contains 10,000 images. The
basic network frameworks used in these experiments are ResNet18, ResNet34, and ResNet50 (He
et al., 2016), which mainly consist of a new residual structure unit. In these experiments, four
paddings are added on the four edges. Then, a random 32×32 cropping is performed, and a data
enhancement method is carried out, which involves turning the image up and down. For both test-
ing and training, the images’ pixels are normalized to a 0-1 distribution. The Stochastic gradient
descent optimization algorithm with 0.9 the momentum (Loshchilov & Hutter, 2016) is used during
the training process. The batch size is 100, the initial learning rate is 0.1, and the weight decay
is 0.0005. The learning rate is reduced by one fifth per 60, 120, and 160 epochs. We report the
performance of our algorithm on a test set after 200 epochs based on the average over five runs.
As shown in Figure 5, according to the cross-entropy curve of the CIFAR-10 and CIFAR-100 train
sets, GO-CNN’s value initially fell faster than the common CNN’s, eventually almost reaching the
same value. It is verified that Geometric Operator Convolutional Neural Network achieves the same
approximation accuracy as the common Convolutional Neural Network. According to the error rate
17
Under review as a conference paper at ICLR 2019
curve of the CIFAR-10 and CIFAR-100 verification set (Figure 6), the value of Geometric Operator
Convolutional Neural Network is lower than that of the common Convolutional Neural Network.
Result of ResNetlS on eifarlɑ
(a) CIFAR-10: ResNet18
(b) CIFAR-10: ResNet34
Result Of ResNetSO on CifarIo
288	g<m ann mnβ
Step
(C) CIFAR-10: ResNet50
Result of ResNetSO on cifarlOO
(d) CIFAR-100: ResNet18
■ ■
AdeWlu-SSoJ。3
(e) CIFAR-100: ResNet34
Ztien	eɑin ann ιn'nβ
Step
(f) CIFAR-100: ResNet50
Figure 5: Log of Cross entropy Curve during training in Common ResNet 18-34-50 and GO-ResNet
18-34-50.
Feature visualization One way to evaluate a model is through visualizing the features that the model
extraCts; this is Called feature visualization. T-SNE (Maaten & Hinton, 2008) or PCA (Jolliffe, 2011)
are generally used for visualization. The T-SNE visualization maps data points to a two-dimensional
or three-dimensional probability distribution through affinitie transformation. Then, the data points
are displayed with a two-dimensional or three-dimensional plane.
In this paper, a two-dimensional T-SNE visualization is adopted to display the CIFAR-10 features ex-
traCted by the model. As shown in Figure 7, the CIFAR-10 features extraCted by the GeometriC Op-
erator Convolutional Neural Network are evenly separated from eaCh other in the two-dimensional
visualization of T-SNE, while the features extraCted from the Common Convolutional Neural Net-
work are mixed. It is apparent that the features extraCted by the GO-CNN are more separable; in
other words, the features learned by the GO-CNN are more distinguishable and easy to Classify with
the last fully ConneCted layer.
Generalization MNIST is a publiC, handwritten reCognition dataset with a total of ten Classes. This
dataset is a Channel image with 28×28 resolution and a Clean baCkground. The train set Contains
50,000 images and the test set Contains 10,000 images. For numeriCal experiments with the MNIST
data set, the adaptive moment estimation (Kingma & Ba, 2014) optimization algorithm is used. In
addition, as an image enhanCement strategy, the image padding is inCreased to 32×32 during the
training proCess. The batCh size is 100, the initial learning rate is 0.001, and the weight deCay
is 0.0005. The learning rate stays the same until reaChing 20,000 iterations. Consequently, we
Complete 20,000 iterations on one test set and average the performanCe over five runs in order to
report the final performanCe evaluation of our algorithm.
Application MediCal images in China are developing rapidly, but speCialist doCtors are short of
resourCes, and they are mainly ConCentrated in big Cities and big hospitals. Many small and medium-
sized Cities do not have suffiCient diagnostiC imaging CapaCities, so many patients have to go to big
Cities in order to aCCess better mediCal resourCes and obtain better treatment. Similarly, there are few
18
Under review as a conference paper at ICLR 2019

Result of ResNetlS on cιfa∏O
common R∙*N∙tlS train
---common R∙*N∙tlS valid
—GO-RMNetietraln
----GO-RMNetievalld
MK	aαc	9>κ	xκ	WK
Step
(a) CIFAR-10: ResNet18
Result of ResNetlS on Cifar1。。
MK	aαc	sκ	RK	sκ
Step
(d)	CIFAR-100: ResNet18
ReSUIt Of ReSNet34 OnCIfarlo
ιiκ	aoκ	SiK	城 K	SiK
Step
(b) CIFAR-10: ResNet34
Result of ResNet34 on cifaΠQQ
ReSUlt Of ReSNet50 On CIfarlo
uκ aoκ sx 7∣x wκ
Step
£晶 Jou"
(c) CIFAR-10: ResNet50
Result of ResNetSO on cifarlOO
£晶 Jou"
UK	»K	»K	RK	90K
Step
(e)	CIFAR-100: ResNet34
uκ	a*	sac	，*	90t
Step
(f)	CIFAR-100: ResNet50
Figure 6: Error rate curve during training in common ResNet 18-34-50 and GO-ResNet 18-34-50.
(a) Common CNN (b) GO-CNN


Figure 7: T-SNE two-dimensional visualization of CIFAR-10
orthopaedic surgeons in China. Fractures often occur in real life due to accidents, such as falls and
car accidents. Orthopedists usually use X-ray images to diagnose fractures. With the development
of artificial intelligence technology, many scholars use Convolutional Neural Networks to assist
doctors in determining whether a bone image reveals a fracture (Chung et al., 2018).
Doctors usually judge whether a fracture has occurred based on whether there is a fracture line
(texture) in the image. In Cao et al. (2015), the texture information from the image is used for
an auxiliary diagnosis of a fracture. With prior information from the Schmid operator, we do pre-
processing by Schmid operators to enhance the texture information from an image. Then, we use
the CNN to conduct classification. However, the parameters of geometric operators in this two-stage
method are preset by human experience. At this point, it is difficult for the local parameters obtained
by the respective optimization to reach the global optimum. Thus, one may consider integrating the
preprocessing of geometric operators into the deep network for global parameter learning without
prior artificial empirical design parameters. In other words, this would mean using the GO-CNN
proposed in this paper, wherein the convolution kernels from the first layer are all trainable Schmid
kernels.
Around 2,000 samples from X-rays taken at the Hainan People’s Hospital were used as the data for
the three kinds of intelligent fracture diagnosis models. Each sample was manually divided into bone
19
Under review as a conference paper at ICLR 2019
Figure 8: Bone images
regions, as shown in Figure 8, with a total of 5,743 bone regions, including 723 bone fracture regions.
The above three models are used for numerical experiments. The basic network framework used in
the experiment is ResNet50 (He et al., 2016), which mainly consists of a new residual structure unit.
To balance the data during training, the number of fracture patches is increased to 4,016 by rotating
the images and changing the background of the images. In the test set, there are 145 fracture patches
and 1,004 non-fracture patches. Then, five experiments are conducted to evaluate each model. The
SGD algorithm and the finetune strategy are used during the training process, with a batch size of
50. The initial learning rate is 0.001 and the weight decay is 0.0005. The learning rate is reduced by
one fifth every 4,000 iterations. Each data class is queued, and the data from each batch is averaged
out of each data class during training. We report the performance of our algorithm on the test set
after 12,000 iterations based on the average over five runs.
According to Table 4, the Geometric Operator Convolutional Neural Network is the most accurate.
Moreover, the fracture recall of the two-stage method is 0.77% higher than that of the Convolutional
Neural Network, indicating that domain knowledge from the field of medicine is important for in-
telligent diagnosis. The fracture recall of the Geometric Operator Convolutional Neural Network
is 2.21% higher than that of the two-stage method, which indicates that the Geometric Operator
Convolutional Neural Network does make use of medical knowledge for fracture diagnosis. The
integration of geometric operator into the deep neural network indeed achieve global optimization.
Table 4: Experimental results of intelligent diagnosis
TestSet	CNN	two-stage	GO-CNN
accuracy	92.38%	93.05%	93.98%
fracture recall	87.97%	88.74%	90.95%
non-fracture recall	96.57%	96.17%	96.87%
20