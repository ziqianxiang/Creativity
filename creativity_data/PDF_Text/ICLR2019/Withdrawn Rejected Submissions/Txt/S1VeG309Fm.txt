Under review as a conference paper at ICLR 2019
Teaching Machine How to Think by Natural
Language: A study on Machine Reading Com-
PREHENSION
Anonymous authors
Paper under double-blind review
Ab stract
Deep learning ends up as a black box, in which how it makes the decision cannot
be directly understood by humans, let alone guide the reasoning process of deep
network. In this work, we seek the possibility to guide the learning of network in
reading comprehension task by natural language. Two approaches are proposed.
In the first approach, the latent representation in the neural network is deciphered
into text by a decoder; in the second approach, deep network uses text as latent
representation. Human tutor provides ground truth for the output of the decoder
or latent representation represented by text. On the bAbI QA tasks, we found that
with the guidance on a few examples, the model can achieve the same performance
with remarkably less training examples.
1	Introduction
People are now fascinated by the amazing power of deep neural networks in many fields. In reading
comprehension, image recognition and speech recognition, the performance of the deep learning
based models is almost comparable with human on some benchmark corpora. However, usually
deep neural network ends up as a black box, in which how it makes the decision cannot be directly
understood by humans. When machine makes wrong decision, usually people can only do some
parameter engineering or feed the machine with more training data.
The latent representation in deep network can be analogized as what machine thinks in its mind
when it solves a task. If we can guide the machine to not only get the correct answer but also think
in the right way, the learning results can be more robust. People have already begun to elaborate on
the meaning within the latent representation (Montavon et al., 2017; Doshi-Velez & Kim, 2017), but
only the deep learning experts know how to utilize the results. In this work, we seek the possibility
to guide the representation learning by natural language in reading comprehension.
In reading comprehension, the machine goes through several rounds of deductions, the latent rep-
resentation in deep network implicitly carries knowledge that the machine learns or infers from the
given story during the reasoning process. In this paper, we demonstrate how to translating the latent
vector into natural language, so the reasoning process can be shown in natural language. Then we
show a novel approach of guiding the reasoning process. Because with the proposed approaches,
the tutor communicates with the machine directly by natural language, to be a machine tutor, one
does not have to be a deep learning expert.
The idea of the proposed framework is shown in Figure 1. Given the question, machine reads the
story sentence-by-sentence to find the answer. Each time when it reads a sentence, machine updates
what it has inferred. For example, given the question “Where is Daniel”, when machine reads
the sentence “Daniel journeyed to the kitchen”, its memory stores the location of Daniel, which
is kitchen. The stored information is represented by latent representation in typical models, and it
cannot be directed interpreted (we do not know machine truly store the location kitchen or not). In
Figure 1, machine did not obtain the correct answer eventually. We can tune the hyperparameters
until machine get the correct answer, but we do not know machine truly learns how to reasoning
or just memorize the answer. With the proposed approaches, the machine can represent what it has
inferred by natural language. Once we figure out what the machine is learning or inferring when
it reads the story, we will have an opportunity to communicate with the machine intuitively, and
1
Under review as a conference paper at ICLR 2019
guide it to become more intelligent. In the example, the tutor knows machine gets confused when it
reads the 3rd and the 4th sentences, so the tutor directly use natural language to provide the correct
reasoning. Then machine updates its model based on the correction.
In this paper, we propose two approaches to guide the latent representation learning by natural lan-
guage. In the first approach, a reading comprehension model is learned as usual, and the latent
representation in the neural network which is a vector with real numbers is deciphered into text by a
decoder. Then the machine tutor provides reference output for the decoder to guide the model train-
ing. In the second approach, a deep network using text as latent representation is learned. In typical
networks, different layers use real number vector to transmit information. Here the previous layer
outputs a natural language sentence as the input of the next layer. Because the latent representation
is text, human can directly correct the latent representation. On the bAbI QA tasks, we found with
the guidance on a few examples (less than twenty), the model can achieve the same performance
with remarkably less training examples.
The remainder of this paper is organized as below. In Session 2, we review the related work. The
reading comprehension model used in this study is briefly reviewed in Section 3. The proposed
approaches are in Section 4. The experimental setting and results are in Section 5, and Section 6 is
the concluding remarks.
garden
Human tutor corrects
the reasoning process.
Itshould be ,zofficew in
the 3rd and the 4th steps.
3rd sentence 4th sentence
Where is Daniel?
QUeStiOn
1. Daniel journeyed to the kitchen.
2. Daniel journeyed to the office.
3. Mary travelled to the hallway.
4. John moved to the garden.
Story
Figure 1: Machine describes its reasoning process in natural language. By monitoring the reasoning
process, human tutors machine by natural language.
2	Related Work
2.1	Reading Comprehension
Deep learning for reading comprehension has attracted much attention (Bordes et al., 2015; Kumar
et al., 2015; Xiong et al., 2016; Hermann et al., 2015; Shih et al., 2015). Conventional reading
comprehension systems are designed as a cascade of several components (syntactic parser, semantic
parser, etc.). In end-to-end reading comprehension model, a neural network which takes a question
and a story as input and an answer as output is directly learned from training data, making it pos-
sible to jointly learn components in conventional QA. The mechanisms like attention and hopping
are widely used in reading comprehension model to model the deduction process (Weston et al.;
Sukhbaatar et al., 2015). In a dynamic memory network (DMN) (Kumar et al., 2015), questions
trigger an iterative attention process which allows the model to condition its attention on the inputs
and result of previous iterations. Neural Reasoner (Peng et al., 2015) infers over multiple support-
ing facts to find an answer to a given question. The Recurrent Entity Network (EntNet) (Henaff
et al., 2017) is the first method to solve all the tasks in the 10k training examples setting of bAbI.
The Query-Reduction Network (QRN) (Seo et al., 2017) effectively handles both short-term and
long-term sequential dependencies to reason over multiple facts. To achieve complex relational rea-
soning, new models are proposed (Bansal et al., 2017; Pavez et al., 2018; Santoro et al., 2017; Palm
et al., 2018). Recent attention mechanisms and network architectures have been shown to be helpful
2
Under review as a conference paper at ICLR 2019
for SQuAD (Xiong et al., 2017; Seo et al., 2016; Wang et al., 2017; Hu et al., 2017; Huang et al.,
2017), and on the SQuAD leaderboard1, deep learning-based models are competitive with human
performance (Yu et al., 2018; Cui et al., 2017). Most of existing works in reading comprehension
are dedicated to improving the performance of answer predictions, while leaving the explanation of
answering unexploited.
2.2	Guiding Reasoning Process
In Visual Question Answering (VQA) task, to guide the reasoning process, the network architectures
of the models are specially designed (Hudson & Manning, 2018; Andreas et al., 2016; Johnson et al.,
2017; Cao et al., 2018). For example, neural modular networks build the compositional structure
from the parsing results of the questions, which makes the reasoning process in the network easy
to be interpreted (Andreas et al., 2016). Some reading comprehension models are also designed to
guide the reasoning process. The analysis of EntNet shows that the model has indeed stored locations
of all of the objects and characters in its memory slots which reflect the final state of the story (Henaff
et al., 2017). The Interpretable Reasoning Network (IRN) (Zhou et al., 2018) makes reasoning on
multi-relation questions with multiple triples in knowledge base, and the intermediate entities and
relations predicted by the reasoning process construct traceable reasoning paths. QRN (Seo et al.,
2017) considers the context sentences as a sequence of state-changing triggers to transform the
original query to a more informed query. The authors of QRN claim that the hidden vectors in the
model represent the informed queries, but only an example of the informed queries is shown in (Seo
et al., 2017) without further analysis and utilization. In the previous work, the reasoning process is
guided by carefully designing the network architecture, which can only be done by deep learning
expert.
There are some attempt about producing simple text descriptions for AI interpretability. The idea has
been applied on classification (Barratt, 2017), VQA (Wang et al., 2015; 2016; Aditya et al., 2018;
Wu et al., 2017; Zhou et al., 2017) and diagnostic report generation (Wang et al., 2018; Gale et al.,
2018). Existing models designed to produce interpretable traces of their decision-making process
typically require hand-crafted rules or extra annotation about the traces for supervised learning at
training time. The proposed approaches can also generate interpretable text descriptions, but here
we focus on using the text descriptions to guide the model training.
3	Reading Comprehension Model
The reading comprehension task considered here is story-based question answering (QA). In story-
based QA, the input is a story X and a question Q both in natural language. The story is as a
sequence of sentences, X = {X1 , X2 . . . XT }, where T is the number of sentences in the story,
while Xt represents the t-th sentence. The output is the distribution y for predicted answer.
The reading comprehension model used in this paper is based on QRN (Seo et al., 2017), whose
network architecture is shown in Figure 2. Each sentence Xt and question Q are first transformed
into d-dimensional vectors xt ∈ Rn and q ∈ Rn respectively by an encoder E, that is, xt = E(Xt)
and q = E(Q). Then L layers of QRN units use xt and q to obtain the answer y. At each time step,
the QRN layers take one sentence xt as input. The QRN unit at the l-th layer accepts three inputs
at the t-th time step: sentence vector xt, hidden vector hlt-1 (from the last time step), and hidden
vector hlt-1 (from the previous layer). The output of the QRN unit is hlt (to next time step and to
the next layer). hlt , which is similar to the hidden state in RNN, carries the inference results in the
reasoning process until step t. ht0 is set to be q. Two layers of QRN units (L = 2) are shown in
Figure 2.
The output of the QRN unit in the last layer at the last time step, hTL, is transformed into the final
answer y by an output module as below.
y = sof tmax(Wo hTL),	(1)
where the weight matrix Wo ∈ RV ×d, and y is a V-dimensional vector, and V is the size of the
vocabulary including all possible answers. Each training example is a tuple, (X, Q,y), where y
1https://rajpurkar.github.io/SQuAD-explorer/
3
Under review as a conference paper at ICLR 2019
denotes the true answer represented as a one-hot vector. The whole model is learned to minimize
the following loss:
N
LQA = X Lce (^ ,yn),	(2)
n=1
where Lce (∙, ∙) is the cross-entropy between two distributions. N is the number of training examples,
and yn and yn are the ground truth and predicted answer respectively.
4	Methodology
We further propose two approaches to realize the idea of expressing the deductive process in natural
language, and demonstrate how to guide the reasoning process. The two approaches are described in
Sections 4.1 and 4.2 respectively. Based on these approaches, we translate qlt in the QRN model into
text. We choose QRN here because it had achieved the state-of-the-art results on the bAbI dataset.
The proposed approaches is general and can be applied on other reading comprehension models.
4.1	Learning External Decoder
Figure 2: Query reduction network (QRN) and the decoder deciphering the latent representation into
natural language. How to guide the machine is also shown in the figure.
The first approach is also shown in Figure 2. In this approach, we aim to use a decoder to decipher the
latent representation into human understandable language. Specifically, we target to learn a decoder
to transform the vector representation hlt ∈ Rd into a natural language sentence Stl . By browsing
the sequence of sentences, S1l to STl , one can have better understanding about the reasoning path of
the model.
Because the text corresponding to the latent representation hlt is not available, at the first glance, the
decoder cannot be learned without extra supervision. However, we realize that the query vector q and
sentence vector xt representing the original natural language question Q and sentence Xt. Therefore,
we can learn a decoder D which can reconstruct Q and Xt given q and xt respectively. Given a latent
vector, the output of the decoder D is a sequence of word distributions by which the likelihood of
generating a specific word sequence can be computed. We use PD(Q|q) (or PD(Xt|xt)) to represent
the likelihood that the decoder D generates Q (or Xt) from q (or xt). The decoder D learns to
4
Under review as a conference paper at ICLR 2019
minimize the reconstruction loss Lreconstruct (or maximize the log likelihood) for all the queries
and sentences in the training data,
NT
Lreconstruct = - X{logPD(Qn|qn) + X logPD(Xtn|xtn)},	(3)
n=1	t=1
where Qn is the question for the n-th example, and xtn is the t-th sentence in the story of the n-th
example.
Because the decoder D is only trained with q andxt, itis very possible that Stl = D(hlt) would not be
readable without further constraint. Here we further force the distribution of the latent representation
hlt , q and xt close to normal distribution. The KL divergence between normal distribution and the
distribution of hlt, q and xt is denoted as LKL . With LKL, one can consider the encoder E and
decoder D together form a variational autoencoder (VAE) (Kingma & Welling, 2014; Rezende et al.,
2014). The decoder D and the whole QRN model are jointly trained to minimize the following loss
function:
L = LQA + Lreconstruct + LKL,	(4)
where LQA and Lreconstruct have been shown in (2) and (3) respectively.
How to guide the reasoning process is also shown in Figure 2. The human tutor can provide a
sentence St as the reference of St to guide the machine. Given St, the network parameters are
updated to maximize the log likelihood that the reference sentence St is generated from the decoder
given latent representation hlt .
4.2	Text as Latent Representation
The second approach is shown in Figure 3. In this
approach, we still use the network architecture of
QRN, but we directly use text as the latent repre-
sentation in the network rather than learning an ex-
tra decoder. As shown in Figure 3 (only part of
the QRN is shown), the model transforms hlt into a
word. We pass hlt through a linear transformation
and softmax activation function to obtain a vector π
with vocabulary size V , which is a distribution over
words. Then a word (which is apple in Figure 3) is
sampled based on the distribution π. Based on the
sampling result, the complete sentence Stl (where is
the apple) is generated by template. The next layer
uses the encoder E to encoder the sentence Stl as
the input. The whole model is learn to minimize
LQA in (2).
In this approach, human tutor provides single word
to guide the machine. As shown in Figure 3, if the
Figure 3: Using text as latent representation.
guidance provided by the tutor is milk, the network parameters would be updated to maximize the
probability corresponding to milk in π . After the update, the reasoning sentence Stl would become
“where is the milk”.
Because text is discrete, and thus the network in Figure 3 becomes non-differentiable. We address
the non-differentiable issues by applying Gumbel-softmax (Jang et al., 2016), but the model is still
difficult to train. This is why rather than output the whole sentence as in the first approach, here we
only require the model to output a certain word among the vocabulary from latent representation,
and then use template to generate a complete sentence.
5
Under review as a conference paper at ICLR 2019
5	Experiments
5.1	Experimental Setup
Dataset The story-based QA dataset, bAbI Weston et al. (2015), is used in the experiments. BAbI
is a synthetic dataset created to benchmark question answering models. It contains 20 types of
question answer tasks, and each task is comprising a question, a set of statements, and a single-word
answer. For each question, only some of the statements contain the relevant information. It contains
1,000 examples for each task in training and testing data. To answer questions in each task requires
selecting a set of relevant sentences and applying different kinds of logical reasoning over them. We
adopted bAbI rather than other datasets because reasoning process is necessary to solve the tasks.
The extraction-based QA corpus like SQuAD may not be suitable because some of the questions
can be correctly answered by simple attentive method, and multiple reasoning procedures are not
necessary.
Network Architecture For QRN model, we use the hidden state size of 50, memory size of 50,
hidden latent vector size of 50, and batch size of 32, same as the setting in (Seo et al., 2017).
AdaGrad is utilized as optimizer. The initial learning rate is 0.5 in both models. The loss engaging
in training process is split into 3 phases, LQA is adpoted in the first training stage, after certain epoch
LKL is added in, lastly summing up LQA, LKL, Lreconstruct in the remaining training process. The
encoder used here is the same as the one use in (Seo et al., 2017). We obtained, xt, q ∈ Rd with
a trainable embedding matrix A ∈ Rd×V and a trainable encoding matrix W ∈ RJ ×d, where J
represents max sentence length. Also, the symmetric structure is applied on the decoder.
5.2	Experiment Results
Investigating the Impact of Human Guidance
Human tutor experiments are conducted on both model variants (learning external decoder in Sec-
tion 4.1, text as latent representations in Section 4.2). Tables 1 and 2 are the illustrations of the
guidance we provided to each sentence in the story. Here, we hope to teach the machine to react to
the triggering fact it received. Due to the different natures of tasks in bAbI, the guidance is provided
with different principles. In task 2, We provide the label indicating the supposed keyword of deduc-
tive question (Table 1). Whereas for some other tasks, such as task 1, the question should remain
the same throughout the whole reasoning process. Therefore, the label we provided is the keyword
in the story sentences that we deem it essential for the machine to recognize in its reasoning process
(Table 2).
Table 1: Illustration of guidance for bAbI QA dataset, task2
Question	Story (facts)	Guidance	Answer
Where is the apple?	Mary went back to the garden Mary grabbed the milk there Sandra went to the hallway Mary got the football there John picked up the apple there Daniel went back to the kitchen John moved to the kitchen Mary left the milk	Where is the apple Where is the apple Where is the apple Where is the apple Where is John Where is John Where is John Where is John	Kitchen.
To show the importance of engaging human guidance on learning, guidance as Tables 1 and 2 is
provided on 20 training examples. The systems are evaluated in terms of accuracy with different
numbers of training examples. 10%, 30%, 50%, 70%, 90% of the training set are used. In Figure 4,
the x-axis is the amount of the training data (10%, 30%, 50%, 70%, 90%); the y-axis is the machine-
comprehension accuracy on the testing set. The blue curve and the orange curse are the results for
the unguided and guided models.
6
Under review as a conference paper at ICLR 2019
Table 2: Illustration of guidance for bAbI QA dataset, task1
Question	Story (facts)
Guidance Answer
Where is Daniel? Daniel journeyed to the kitchen kitchen
Daniel journeyed to the office office
Mary travelled to the hallway office
John moved to the garden office
Office.
(a) Training External Decoder on task2 (b) Using Text as Latent Representations on task1
Aoallw<
%%%%%%%%%%%
Oooooooooo
09876543 2 1
1
(c) Using Text as Latent Representations on task8
Figure 4: Comparisons of accuracy among different amount of training of examples with the guid-
ance on 20 examples.
We found that human guidance can substantially improve the generalizability of learning, especially
with small training data where original QRN model shows a very serious overfitting problem. Even
with little human guidance (only 20 examples have guidance), machine is able to imitate human
reasoning patterns to solve the certain tasks.
Figure 5 further demonstrates the the power of human guidance with the guidance on even less
examples. 10% training data is used. With the guidance on only 10 examples, the performance can
achieve nearly 60% accuracy.
Text Description Generated by Models
An example of S11 to ST1 from the second approach is shown in Table 7. The decoded words are
office,garden,John,back. Those are keys words related to the question. The according answer to the
given question is office. John has also been to office, and Sandra was in the garden before she went
to office. It may be confused that the appearance of those keywords is not in sequential order as the
given facts. However, it can be explained by the model architecture of implementing bidirectional
layer.
We found that the decoded sentences from the first method are unsatisfactory. In task 2, where-
question of an object ”Where is the apple?”, should be transformed into ”Where is Amy?”, as Amy
took up the apple in the following story. However, the deductive questions fail to change a single
7
Under review as a conference paper at ICLR 2019
Figure 5: Comparison of accuracy with the guidance provided on 4, 7, 10, 14, 17 and 20 examples.
10% training examples are used here.
Table 3: An example of decoded latent result of machine reasoning.
Question	Story (facts)	Decoded Latent Representation Answer
Where is Sandra?	1.	Johnjourneyed to the office	office	office. 2.	Sandra travelled to the garden garden 3.	Sandra moved to the office	back 4.	Daniel travelled to the hallway John 5.	John travelled to the bathroom office 6.	Danieljourneyed to the garden John
word in most of the cases whereas the decoder can learn to perfectly reconstruct original question. It
is assumed that the variation of the latent codes, h11 to h1T, is too small for the decoder to recognize.
6 Conclusion
In this work, we seek the possibility to guide the learning of network in reading comprehension
task by natural language. In the first approach, the latent representation in the neural network is
deciphered into text by a decoder; in the second approach, deep network uses text as latent repre-
sentation. On the bAbI QA tasks, we found that with the guidance on less than twenty examples,
the model can achieve the same performance with remarkably less training examples.
For the future work, we will test the proposed approaches on larger and more realistic data sets with
different reading comprehension models. We are trying to directly generate complete sentences
without templates, and we will use adversarial learning to make the generated text description more
readable. We will recruit the people without computer science background to provide the guidance
to know whether non-expert can also guide the network training,
References
Somak Aditya, Yezhou Yang, and Chitta Baral. Explicit reasoning over end-to-end neural architec-
tures for visual question answering. In AAAI, 2018.
Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Neural module networks. In
CVPR, 2016.
Trapit Bansal, Arvind Neelakantan, and Andrew McCallum. Relnet: End-to-end modeling of enti-
ties and relations. In AKBC, 2017.
Shane Barratt. InterpNET: Neural introspection for interpretable deep learning. In NIPS Symposium
on Interpretable Machine Learning, 2017.
A. Bordes, N. Usunier, S. Chopra, and J. Weston. Large-scale simple question answering with
memory networks. CoRR, abs/1506.02075, 2015.
8
Under review as a conference paper at ICLR 2019
Qingxing Cao, Xiaodan Liang, Bailin Li, and Liang Lin. Interpretable visual question answering by
reasoning on dependency trees. In arXiv, 2018.
Yiming Cui, Zhipeng Chen, Si Wei, Shijin Wang, Ting Liu, and Guoping Hu. Attention-over-
attention neural networks for reading comprehension. In ACL, 2017.
Finale Doshi-Velez and Been Kim. Towards a rigorous science of interpretable machine learning.
In arXiv, 2017.
William Gale, Luke Oakden-Rayner, Gustavo Carneiro, Andrew P Bradley, and Lyle J Palmer. Pro-
ducing radiologist-quality reports for interpretable artificial intelligence. In arXiv, 2018.
Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, and Yann LeCun. Tracking the world
state with recurrent entity networks. In ICLR, 2017.
K. M. Hermann, T. Kocisky, E. Grefenstette, L. Espeholt, W. Kay, M. Suleyman, and P. Blunsom.
Teaching machines to read and comprehend. CoRR, abs/1506.03340, 2015.
Minghao Hu, Yuxing Peng, and Xipeng Qiu. Reinforced mnemonic reader for machine comprehen-
sion. CoRR, abs/1705.02798, 2017.
Hsin-Yuan Huang, Chenguang Zhu, Yelong Shen, and Weizhu Chen. Fusionnet: Fusing via fully-
aware attention with application to machine comprehension. arXiv preprint arXiv:1711.07341,
2017.
Drew A. Hudson and Christopher D. Manning. Compositional attention networks for machine rea-
soning. In ICLR, 2018.
E. Jang, S. Gu, and B. Poole. Categorical reparameterization with gumbel-softmax. In arXiv, 2016.
Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Judy Hoffman, Li Fei-Fei, C. Lawrence
Zitnick, and Ross Girshick. Inferring and executing programs for visual reasoning. In ICCV, 2017.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In ICLR, 2014.
A. Kumar, O. Irsoy, J. Su, J. Bradbury, R. English, B. Pierce, P. Ondruska, I. Gulrajani, and
R. Socher. Ask me anything: Dynamic memory networks for natural language processing. CoRR,
abs/1506.07285, 2015.
Gregoire Montavon, Wojciech Samek, and Klaus-Robert Muller. Methods for interpreting and un-
derstanding deep neural networks. In arXiv, 2017.
Rasmus Berg Palm, Ulrich Paquet, and Ole Winther. Recurrent relational networks. In submitted to
NIPS, 2018.
Juan Pavez, Hector Allende, and Hector Allende-Cid. Working memory networks: Augmenting
memory networks with a relational reasoning module. In ACL, 2018.
Baolin Peng, Zhengdong Lu, Hang Li, and Kam-Fai Wong. Towards neural network-based reason-
ing. CoRR, abs/1508.05508, 2015.
Danilo J. Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approxi-
mate inference in deep generative models. In ICML, 2014.
Adam Santoro, David Raposo, David G.T. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter
Battaglia, and Timothy Lillicrap. A simple neural network module for relational reasoning. In
NIPS, 2017.
Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. Bidirectional attention
flow for machine comprehension. arXiv preprint arXiv:1611.01603, 2016.
Minjoon Seo, Sewon Min, Ali Farhadi, and Hannaneh Hajishirzi. Query-reduction networks for
question answering. In ICLR, 2017.
9
Under review as a conference paper at ICLR 2019
Kevin J. Shih, Saurabh Singh, and Derek Hoiem. Where to look: Focus regions for visual question
answering. CoRR, abs/1511.07394, 2015.
S. Sukhbaatar, A. Szlam, J. Weston, and R. Fergus. Weakly supervised memory networks. CoRR,
abs/1503.08895, 2015.
Peng Wang, Qi Wu, Chunhua Shen, Anton van den Hengel, and Anthony R. Dick. Explicit
knowledge-based reasoning for visual question answering. CoRR, abs/1511.02570, 2015.
Peng Wang, Qi Wu, Chunhua Shen, and Anton van den Hengel. The VQA-machine: Learning how
to use existing vision algorithms to answer new questions. CoRR, abs/1612.05386, 2016.
Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, and Ming Zhou. Gated self-matching networks
for reading comprehension and question answering. In Proceedings of the 55th Annual Meeting of
the Associationfor Computational Linguistics (Volume 1: Long Papers), volume 1, pp. 189-198,
2017.
Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, and Ronald M. Summers. TieNet: Text-image
embedding network for common thorax disease classification and reporting in chest X-rays. In
CVPR, 2018.
J. Weston, S. Chopra, and A. Bordes. Memory networks. CoRR, abs/1410.3916.
Jason Weston, Antoine Bordes, Sumit Chopra, and Tomas Mikolov. Towards AI-complete question
answering: A set of prerequisite toy tasks. CoRR, abs/1502.05698, 2015.
Qi Wu, Peng Wang, Chunhua Shen, Ian Reid, and Anton van den Hengel. Are you talking to me?
reasoned visual dialog generation through adversarial learning. In arXiv, 2017.
C. Xiong, S. Merity, and R. Socher. Dynamic memory networks for visual and textual question
answering. CoRR, abs/1603.01417, 2016.
Caiming Xiong, Victor Zhong, and Richard Socher. Dynamic coattention networks for question
answering. In ICLR, 2017.
Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi,
and Quoc V. Le. QANet: Combining local convolution with global self-attention for reading
comprehension. In ICLR, 2018.
Mantong Zhou, Minlie Huang, and Xiaoyan Zhu. An interpretable reasoning network for multi-
relation question answering. In COLING, 2018.
Yiyi Zhou, Rongrong Ji, Jinsong Su, Yongjian Wu, and Yunsheng Wu. More than an answer: Neural
pivot network for visual qestion answering. In Proceedings of the 2017 ACM on Multimedia
Conference, MM ’17, 2017.
10
Under review as a conference paper at ICLR 2019
A Average Performance
In our experiment, the average performance of model variant 1 (Using external decoders) on task
1, task 2 is 98% in accuracy ;while the average performance of model variant 2 (Using text as
latent representation) on task 1, task 2 is 100%. Both the results are similar with original QRN
model(99.4% in accuracy). It is thus proved that the two model invariants still remain same machine
comprehension ability with original QRN model .
B Lable
Table 4: Illustration of lables for bAbI QA dataset, task16
Question	Story (facts)	Supervised Labels	Answer
What color is Lily?	Bernhard is a lion	What color is Lily	yellow
	Brian is a frog	What color is Lily	
	Bernhard is gray	What color is Lily	
	Julius is a frog	What color is Lily	
	Greg is a swan	What color is Greg	
	Brian is gray	What color is Lily	
	Greg is yellow	What color is Greg	
	Julius is gray	What color is Lily	
	Lily is a swan	What color is Lily	
Table 5: Illustration of lables for bAbI QA dataset, task13
Question	Story (facts)	Supervised Labels Answer
Where is Mary? Mary and Daniel went to the kitchen	kitchen	bathroom
Afterwards they went back to the hallway hallway
Daniel and Sandra went back to the bathroom hallway
Then they moved to the kitchen	hallway
John and Sandra went back to the office hallway
Following that they moved to the garden hallway
Mary and John travelled to the kitchen	kitchen
Afterwards they went to the bathroom	bathroom
Table 6: Illustration of lables for bAbI QA dataset, task8
Question	Story (facts)	Supervised Labels Answer
What is Mary carring?	John got the milk there John left the milk Daniel went to the garden John got the milk there Daniel travelled to the bedroom John discarded the milk Mary took the milk there Daniel went to the hallway	nothing	milk nothing nothing nothing nothing nothing milk milk
11
Under review as a conference paper at ICLR 2019
C other Examples
Table 7: An example of decoded latent result of machine reasoning
Question	Story (facts)
Decoded Latent Representation Answer
Where is Sandra? 1. Sandra travelled to the bedroom
2.	Sandra journeyed to the garden
3.	Sandra moved to the hallway
4.	Sandra travelled to the bathroom
5.	Mary went to the bathroom
6.	John moved to the office
7.	Sandra went back to the office
8.	Mary travelled to the hallway
moved	office.
back
in
to
office
office
Where
John
12