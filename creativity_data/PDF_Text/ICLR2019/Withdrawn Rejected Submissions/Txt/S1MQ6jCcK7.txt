Under review as a conference paper at ICLR 2019
ChoiceNet: Robust Learning by Revealing
Output Correlations
Anonymous authors
Paper under double-blind review
Ab stract
In this paper, we focus on the supervised learning problem with corrupt training
data. We assume that the training dataset is generated from a mixture of a target
distribution and other unknown distributions. We estimate the quality of each data
by revealing the correlation between the generated distribution and the target distri-
bution. To this end, we present a novel framework referred to here as ChoiceNet
that can robustly infer the target distribution in the presence of inconsistent data.
We demonstrate that the proposed framework is applicable to both classification
and regression tasks. Particularly, ChoiceNet is evaluated in comprehensive experi-
ments, where we show that it constantly outperforms existing baseline methods in
the handling of noisy data in synthetic regression tasks as well as behavior cloning
problems. In the classification tasks, we apply the proposed method to the MNIST
and CIFAR-10 datasets and it shows superior performances in terms of robustness
to different types of noisy labels.
1	Introduction
Training a deep neural network requires immense amounts of training data which are often collected
using crowdsourcing methods, such as Amazon’s Mechanical Turk (AMT). However, in practice,
the crowd-sourced labels are often noisy (Bi et al., 2014). Furthermore, deep neural networks are
vulnerable to over-fitting given the noisy training data in that they are capable of memorizing the
entire dataset even with inconsistent labels, leading to a poor generalization performance (Zhang
et al., 2016).
Assuming that a training dataset is generated from a mixture of a target distribution and other
distributions, we address this problem through the principled idea of revealing the correlation between
the target distribution and the other distributions. We present a framework for robust learning which
is applicable to arbitrary neural network architectures such as convolutional neural networks (He
et al., 2016a) or recurrent neural networks (Chung et al., 2014). We call this framework ChoiceNet.
Throughout this paper, we aim to address the following questions:
1.	How can we measure the quality of training data in a principled manner?
2.	In the presence of inconsistent outputs, how can we infer the target distribution in a scalable
manner?
Traditionally, noisy outputs are handled by modeling additive random distributions, often leading
to robust loss functions (Hampel et al., 2011). However, we argue that these approaches are too
restrictive when handling severe outliers or inconsistencies in the datasets. To address the first
question, we leverage the concept of a correlation. Precisely, we measure the quality of training data
using the correlation between the target distribution and the data generating distribution. However,
estimating the correct correlation requires an access to a target distribution, whereas learning the
correct target distribution requires knowing the correlation between the distributions to be known,
making it a chicken-and-egg problem. To address the second question, we simultaneously estimate
the target distribution as well as the correlation in an end-to-end-manner using stochastic gradient
decent methods, in this case Adam (Kingma & Ba, 2014), to achieve scalability.
The cornerstone of the proposed method is a mixture of correlated density network (MCDN) block.
First, we present a Cholesky transform method for sampling the weights of a neural network that
enables us to model correlated outputs. We also present an effective regularizer to train ChoiceNet.
1
Under review as a conference paper at ICLR 2019
To the best of our knowledge, this represents the first approach simultaneously to infer the target
distribution and the output correlations using a neural network in an end-to-end manner.
Revealing the output correlations was proposed in earlier work (Bonilla et al., 2008), in which a
multi-task Gaussian process prediction (MTGPP) model is proposed. In particular, MTGPP used
correlated Gaussian processes to model multiple tasks by learning a free-form cross-covariance
matrix. However, due to the multi-task learning setting, it is not suitable for learning a single target
function. In other work (Choi et al., 2016), a leverage optimization method which optimizes the
leverage of each demonstrations is proposed. Unlike a former study (Bonilla et al., 2008), the latter
(Choi et al., 2016) focused on inferring a single expert policy by incorporating a sparsity constraint
by assuming that the most demonstrations are collected from a skillful consistent expert. However,
these methods suffer from the scalability issues when applying on large-scale tasks.
ChoiceNet is initially applied to a synthetic regression task, where we demonstrate its robustness to
extreme outliers and ability to distinguish the target distribution and noise distributions. We then
apply it to a behavior cloning scenario where the demonstrations are collected from both an expert
and an adversarial policies. Subsequently, we move on to the classification tasks using the MNIST
and CIFAR-10 datasets. We show that the proposed method outperforms existing baseline methods
in terms of robustness with regard to the handling different types of noisy labels.
2	Related Work
Recently, robustness in deep learning has been actively studied (Fawzi et al., 2017) as deep neural
networks are being applied to diverse tasks involving real-world applications such as autonomous
driving (Paden et al., 2016) or medical diagnosis (Gulshan et al., 2016) where a simple malfunction
can have catastrophic results (AP & REUTERS, 2016).
Existing work for handing noisy training data can be categorized into four groups: small-loss tricks
Jiang et al. (2017); Ren et al. (2018); Han et al. (2018); Malach & Shalev-Shwartz (2017), estimating
label corruptions Patrini et al. (2017); Goldberger & Ben-Reuven (2017); Sukhbaatar et al. (2014);
Bekker & Goldberger (2016); Hendrycks et al. (2018); Veit et al. (2017), using robust loss functions
Natarajan et al. (2013); Belagiannis et al. (2015), and explicit and implicit regularization methods
Reed et al. (2014); Lee (2013); Goodfellow et al. (2016); Xie et al. (2016); Tokozume et al. (2018);
Zhang et al. (2017); Miyato et al. (2018); Tarvainen & Valpola (2017); Laine & Aila (2017). Our
proposed method is mostly related to the robust loss function approach but cannot fully categorized
into this group in that we present a novel architecture, a mixture of correlated density network block,
for achieving robustness based on the correlation estimation.
First of all, the small-loss tricks selectively focus on training instances based on a certain criterion
such as having small cost values Han et al. (2018). (Malach & Shalev-Shwartz, 2017) proposed
a meta-algorithm for tackling the noisy label problem by training two networks only when the
predictions of the two networks disagree, where selecting a proper network from among the two
networks can be done using an additional clean dataset. (Ren et al., 2018) reweighs the weight
of each training instance using a small amount of clean validation data. MentorNet Jiang et al.
(2017) concentrated on the training of an additional neural network, which assigns a weight to each
instance of training data to supervise the training of a base network, termed StudentNet, to overcome
the over-fitting of corrupt training data. Recent work Han et al. (2018) presented Co-teaching by
maintaining two separate networks where each network is trained with small-loss instances selected
from its peer network.
The second group of estimating label corruption information is mainly presented for classification
tasks where training labels are assumed to be corrupted with a possibly unknown corruption matrix.
An earlier study in Bekker & Goldberger (2016) proposed an extra layer for the modeling of output
noises. Jindal et al. (2016) extended the aforementioned approach by adding an additional noise
adaptation layer with aggressive dropout regularization. A similar method was then proposed in
Patrini et al. (2017) which initially estimated the label corruption matrix with a learned classifier and
used the corruption matrix to fine-tune the classifier. Other researchers (Goldberger & Ben-Reuven,
2017) presented a robust training method that mimics the EM algorithm to train a neural network,
with the label noise modeled as an additional softmax layer, similar to earlier work (Jindal et al.,
2016). A self-error-correcting network was also presented (Liu et al., 2017). It switches the training
labels based on the learned model at the beginning stages by assuming that the deep model is more
accurate during the earlier stage of training.
2
Under review as a conference paper at ICLR 2019
Researchers have also focussed on using robust loss functions; (Natarajan et al., 2013) studied
problem of binary classification in the presence of random labels and presented a robust surrogate
loss function for handling noisy labels. Existing loss functions for classification were studied (Ghosh
et al., 2017), with the results showing that the mean absolute value of error is inherently robust to
label noise. In other work (Belagiannis et al., 2015), a robust loss function for deep regression tasks
were proposed using Tukey’s biweight function with median absolute deviation of the residuals.
The last group focusses on using implicit or explicit regularization methods while training. Adding
small label noises while training is known to be beneficial to training, as it can be regarded as an
effective regularization method (Lee, 2013; Goodfellow et al., 2016). Similar methods have been
proposed to tackle noisy outputs. A bootstrapping method (Reed et al., 2014) which train a neural
network with a convex combination of the output of the current network and the noisy target was
proposed. Xie et al. (2016) proposed DisturbLabel, a simple method which randomly replaces a
percentage of the labels with incorrect values for each iteration. Mixing both input and output data
was also proposed (Tokozume et al., 2018; Zhang et al., 2017). One study (Zhang et al., 2017)
considered the image recognition problem under label noise and the other (Tokozume et al., 2018)
focused on a sound recognition problem. Temporal ensemble was proposed in Laine & Aila (2017)
where an unsupervised loss term of fitting the output of of an augmented input to the augmented target
updated with an exponential moving average. (Tarvainen & Valpola, 2017) extends the temporal
ensemble in Laine & Aila (2017) by introducing a consistency cost function that minimizes the
distance between the weights of the student model and the teacher model. (Miyato et al., 2018)
presented new regularization method based on virtual adversarial loss which measures the smoothness
of conditional label distribution given input. Minimizing the virtual adversarial loss has a regularizing
effect in that it makes the model smooth at each data point.
The foundation of the proposed method is the mixture of correlated density network (MCDN) block
where the output distribution is modeled using a mixture of correlated distributions. Modeling corre-
lations of output training data has been actively studied in light of Gaussian processes (Rasmussen,
2006). MTGPP (Bonilla et al., 2008) that models the correlations of multiple tasks via Gaussian
process regression was proposed in the context of multi-task setting. Choi et al. (2016) proposed a
robust learning from demonstration method using a sparse constrained leverage optimization method
which estimates the correlation between training outputs and showed its robustness compared to
several baselines. On the other hand, Platanios et al. (2016) presented a graphical model that can
model the structure of the error rates of learned classifiers using non-parametric Bayesian methods.
We would like to note that while our problem setting is similar to the latter study (Choi et al., 2016),
we propose end-to-end learning of both the target distribution and the correlation of each training
data, thus offering, a clear advantage in terms of scalability.
3	ChoiceNet
In this section, we present the methodology and the model architecture of ChoiceNet. A main
ingredient of ChoiceNet is a mixture of correlated density network (MCDN) block upon the arbitrary
base network. First, we illustrate the motivation of the MCDN block. Section 3.1 introduces Cholesky
transform which enables correlated sampling and legitimates applying the reparametrization trick.
Subsequently, we present the mechanism of ChoiceNet in Section 3.2 and loss functions for regression
and classification tasks in Section 3.3.
Modeling Corrupt Output As stated in Section 1, we focus on the problem of supervised learning
on training data with corrupt outputs. Denote an unknown clean dataset by Dclean whose elements
(x, y) ∈ Dclean are determined by a relation y = f (x). For a classification task, an accurate label
y ∈ {θ, 1} exists for each x. We assume a corrupt data (x, y) ∈ DCOrrUPt is given such that
Regression:	Classification:
ʌ _ ʃ f (x) + ε with 1 - P y = (y	with 1 - P
y	g(x) + ξ with p	y	{0, 1} \ {y} with p
where g(∙) is an arbitrary function. Here ε and ξ are additive noise (usually heteroscedastic) andP
indicates the corruption (or mixture) probability. The above setting employs the random choice under
Bernoulli distribution but one can consider a multinoulli distribution instead.
3
Under review as a conference paper at ICLR 2019
The corrupt data can be modeled by the conditional density estimation via a mixture of distributions:
y 〜∏targetP®X)+ ∏noiseQ(y∣x)
where πtarget and πnoise represent the ratio of target and noisy data, respectively. In this paper,
We deal with the target conditional density P(∙∣∙) using a parametrized distribution with expected
measurement variance σ2 i.e., P(∙∣x) = N(fθ(x),σ2) where fθ is a neural network and θ is a set
of parameters. Analogous to the mixture density network (Bishop (1994)), we tackle the noise
conditional distribution Q(∙∣∙) parametrized also by θ. However, one major difference is that, we
quantify its irrelevance (or independence) by utilizing the correlation ρ between P and Q. Intuitively
speaking, irrelevant noisy data will be modeled to be collected from a class of Q with relatively small
or negative ρ. Since we assume that the correlation information is not explicitly given, we model the
ρ of each data to be a function of an input x i.e., ρφ(x), parametrized by φ and jointly optimize φ
and θ using a mixture distribution. The MCDN block in Section 3.2 is proposed for this purpose.
3.1	Cholesky Transform and Correlated Sampling
In this section, we present a novel method on how to model dependencies among output distributions.
Given parameters Θ = (ρ, μ, σ1,σ2), Cholesky transform is a mapping from (w, Z) ∈ R2 to R which
is defined by
tθ (w, z) ：= ρμ + pi - ρ2 "σ2 (W - μ) + zpι - P2
Let W and Z be uncorrelated random variables such that E[W] = μw, V(W) = σW, E[Z] = 0,
and V(Z) = σZ. For -1 ≤ P ≤ 1, write Θ = (ρ, μw, σw, σz) and set a new random variable W
by plugging Θ and (W, Z) in Cholesky transform i.e. W := TΘ(W, Z). This transform makes it
possible to apply the reparametrization trick (Kingma (2017); Kingma & Welling (2013)) to jointly
learn parameters not only μw, σw but also ρ. Since correlation is invariant to mean translation and
variance dilatation (see appendix), it is easy to see that Corr(W, W) = ρ. The following theorem
further states that a correlation between two random matrices is invariant to an affine transform.
Theorem. Let ρ = (P1, . . . , PK) ∈ RK. Forp ∈ {1, 2}, random matrices W(p) ∈ RK×Q are given
such that for every k ∈ {1, . . . , K},
Cov Wk(ip),Wk(jp) = σp2δij, Cov Wk(i1),Wk(j2) = Pkσ1σ2δij
Given h = (h1, . . . , hQ) ∈ RQ, set y(p) = W(p)h for each p ∈ {1, 2}. Then an elementwise
correlation between y(1) and y(2) equals ρ i.e.
Corr yk(1),yk(2) = Pk, ∀k ∈ {1, . . . ,K}
Hence ρ is a proper representation of dependencies among the distributions on the feature space.
K
This theorem allows to use Cholesky transform to generate correlated weight matrices {Wk}kK=1
upon the feature layer of base network. In the following section, we demonstrate the details of the
sampling process in the MCDN block.
3.2	Model Architecture
In this section, we describe the model architecture and the overall mechanism of ChoiceNet. In
the following, TT > 0 is a constant indicating expected measurement noise and η(∙) ∈ (-1,1) is
a bounded function, e.g., a hyperbolic tangent. Wh→ρ, Wh→π ∈ RK×Q and Wh→Σ0 ∈ RD×Q
are weight matrices where Q and D denote the dimensions of a feature vector h and output y,
respectively, and K is the number of mixtures. Pmax is a fixed constant whose value is close to 1.
ChoiceNet is a twofold architecture: (a) a base network and (b) a MCDN block (see Figure 1). A base
network extracts features for a given dataset. Then the MCDN block estimates the densities of the data
generating distributions through (μk, ∑k, ∏)3「Contrary to the mixture density network (MDN),
K
during the density estimation process, the MCDN block samples correlated weights {Wk}kK=1 using
4
Under review as a conference paper at ICLR 2019
Figure 1: Model Architecture of ChoiceNet
IMCDN Block
Sampling
Weights
Cholesky
Transform
Learning
parameter
Constant
Parameter
Sampling
空(W,Z)
Θ = (pfc(h), μ∙∖v5 ∑w5 ∑z)
■ Pκ(h)" Mw
exp(Whτ∑°h]
softmax(Wh→πh)
Cholesky transform. Consequently, the MCDN block is able to model the correlated outputs i.e.
correlated mean vectors μ. The overall mechanism of ChoiceNet can be elaborated as follows:
Modules =
MCDN Block =
h = BaseNet(x) ∈ RQ
ρ(h) = η(Wh→ρh) ∈ RK = (ρ1,ρ2(h), . . . ,ρK(h)), ρ1 = ρmax
Σ0(h) = exp(Wh→Σ0h) ∈ RD
Σk = (1 -ρ2k)Σ0(h) +τ-1 ∈ RD, k ∈ {1,...,K}
W 〜N(μw, Σw) ∈ RDXQ
Z-N(0, ∑Z) ∈ RDXQ
Wk = T(Pk(h),μw,∑W,∑z) (W, Z) ∈ Rdxq, k ∈ {1,...,K}
μ =(μι,…，μκ) = (W 1 h,..., WKh) ∈ RKXD
Outputs = π = (π1 , . . . , πK) = softmax(Wh→π h) ∈ RK
[∑ = (∑1,..., ∑K) ∈ RK XD
Thanks to the theorem in Section 3.1, for each k ∈ {1, . . . , K}
Corr(μk,Wh) = Corr(Wkh,Wh) = (Pk,...,ρk) ∈ RD
and the output density is modeled via mean vectors μ. Note that both V(μk) and Σk are minimized,
when Pk → ±1. Furthermore, as we employ Gaussian distributions in Cholesky transform, the
influences of uninformative or independent data, whose correlations are close to 0, is attenuated as
their variances increase (Kendall & Gal (2017)).
3.3 Training Objectives
Denote a training dataset by D = {(xi , yi) : i = 1, . . . , N}. We consider both regression and
classification tasks.
Regression For the regression task, we employ both L2-loss and the standard MDN loss (Bishop
(1994); Choi et al. (2017); Christopher (2016))
1
L(D) = Nf λι ∣y-
i=1
μι (xi)k2 + λ2 log (X ∏k(xi)N(yi； μk(xi), diag(∑k(xi))))]⑴
N


where λι and λ2 are hyper-parameters and N(∙∣μ, Σ) is the density of multivariate Gaussian:
D
N(yi； μk(xi), diag(∑k(xi))) = ɪɪ
d=1
,ex。—
q2∏∑d)	∖
|yi(d)
2∑kd)

5
Under review as a conference paper at ICLR 2019
We also add weight decay and the following Kullback-Leibler regularizer to equation 1
K
KL(Pkn) = X Pk log Pk,	P = Softmax(P)
πk
k=1	k
(2)
The above KL regularizer encourages the mixture components with the strong correlations to have
high mixture probabilities. This guidance is useful since ChoiceNet uses the mean vector μι(xi) of
the first mixture component at the inference stage.
Classification In the classification task, we suppose each yi is a D-dimensional one-hot vector.
Unlike the regression task, equation 1 is not appropriate for the classification task. We employ the
following loss function:
L(D) = -Nn XX∏k(Xi) ( hsoftmax(yk(Xi)), yi〉- λreglog (χexp(ykd)(xi))))	⑶
i=1 k=1	d=1
Here〈•，•〉denotes inner product and for k ∈ {1,..., K}, d ∈ {1,...,D}
yk =	(yk1),...,ykD)),	ykd)(Xi)	=	μkd)	+	V^Ff,	ε~N(0,1)
Similar to the regression task, we use both equation 2 and weight decay.
4	Experiments
4.1	Regression Tasks
We conduct two regression experiments: 1) a synthetic scenario where the training dataset contains
outliers sampled from other distributions and 2) a behavior cloning scenario where the demonstrations
are collected from both expert and adversarial policies.
Synthetic Regression Example We first apply ChoiceNet to a simple one-dimensional regres-
sion problem of fitting f (x) = cos(2x)exp(-(X)2) where X ∈ [-3, +3] as shown in Figure 2.
ChoiceNet is compared with a naive multilayer perceptron (MLP), a mixture density network (MDN)
with five mixtures where all networks have two hidden layers with 32 nodes with a ReLU activation
function. Gaussian process regression (GPR) (Rasmussen, 2006), leveraged Gaussian process regres-
sion (LGPR) with leverage optimization (Choi et al., 2016), and robust Gaussian process regression
(RGPR) with an infinite Gaussian process mixture model (Rasmussen & Ghahramani, 2002) are
also compared. For the GP based methods, we use a squared-exponential kernel function and the
hyper-parameters are determined using a simple median trick (Dai et al., 2014)1. To evaluate its
performance in corrupt datasets, we randomly replace the original target values with outliers whose
output values are uniformly sampled from -1 to +3. We vary the outlier rates from 0% (clean) to
80% (extremely noisy).
Table 1 illustrates the RMSEs (root mean square errors) between the reference target function and
the fitted results of ChoiceNet and other compared methods. Given an intact training dataset, all
the methods show stable performances in that the RMSEs are all below 0.1. Given training datasets
whose outlier rates exceed 40%, however, only ChoiceNet successfully fits the target function whereas
the other methods fail as shown in Figure 2.
To further inspect whether ChoiceNet can distinguish between the target distribution and noise
distributions, we train ChoiceNet on two datasets. In particular, we use the same target function and
replace 50% of the output values whose input values are within 0 to 2 using two different corruptions:
one uniformly sampled from -1 to 3 and the other from a flipped target function. For this experiment,
we set K = 2 for better visualization. As shown in Figure 3(a) and 3(c), ChoiceNet successfully fits
the target function. The correlations of the second component decrease as outliers are introduced as
shown in Figure 3(b) and 3(d). Surprisingly, when the target and noise distribution are negatively
correlated (the flipped function case), the correlations of the second component become -1 as
depicted in Figure 3(b). Contrarily, for the uniform corruption case, the correlations of the second
component are within 0 and 1. We would like to emphasize that this clearly shows the capability of
ChoiceNet to distinguish the target distribution from noisy distributions.
1 A median trick selects the length parameter of a kernel function to be the median of all pairwise distances
between training data.
6
Under review as a conference paper at ICLR 2019
Table 1: RMSE of compared methods on synthetic toy examples
Outliers	ChoiceNet	MDN	MLP	GPR	LGPR	RGPR
~%%	0.034	0.028	0.039	0.008	0.022	0.017
20%	0.022	0.087	0.413	0.280	0.206	0.013
40%	0.018	0.565	0.452	0.447	0.439	1.322
60%	0.023	0.645	0.636	0.602	0.579	0.738
80%	0.084	0.778	0.829	0.779	0.777	1.523
Figure 2: Reference function and fitting results of compared methods on different outlier rates.
Input	Input
(a)	(b)
Input	Input
(c)	(d)
Figure 3: Fitting results on datasets with (a) flipped function and (c) uniform corruptions. Resulting
correlations of two components with (b) flipped function and (d) uniform corruptions.
Table 2: Average returns of compared methods on MuJoCo problems
Outliers	HalfCheetah			ChoiCeNet	Walker2d MDN	MLP
	ChoiCeNet	MDN	MLP			
10%	2068.14	192.53	852.91	2754.08	102.99	537.42
20%	1498.72	675.94	372.90	1887.73	95.29	1155.80
30%	2035.91	363.08	971.24	-267.10	-260.80	-728.39
Behavior Cloning Example In this experiment, we apply ChoiceNet to behavior cloning tasks
when given demonstrations with mixed qualities. where the proposed method is compared with
MLP and MDN in two locomotion tasks: HalfCheetah and Walker2d. The network architectures are
identical to those in the synthetic regression example tasks. To evaluate the robustness of ChoiceNet,
we collect demonstrations from both an expert policy and an adversarial policy where two policies
are trained by solving the corresponding reinforcement learning problems using the state-of-the-art
proximal policy optimization (PPO) (Schulman et al., 2017). For training adversarial policies for
both tasks, we flip the signs of the directional rewards so that the agent gets incentivized by going
backward. We evaluate the performances of the compared methods using 500 state-action pairs with
different mixing ratio and measure the average return over 100 consecutive episodes. The results are
shown in Table 2. In both cases, ChoiceNet outperforms compared methods by a significant margin.
4.2 Classification Tasks
We also conduct classification experiments on the MNIST and CIFAR-10 datasets to evaluate the
performance of ChoiceNet on corrupt labels. To generate noisy datasets, we follow the setting in
7
Under review as a conference paper at ICLR 2019
(Zhang et al., 2017) which randomly shuffles a percentage of the labels in the dataset2. We vary
the corruption probabilities from 50% to 95% for the MNIST dataset and from 20% to 80% for the
CIFAR-10 dataset and compare median accuracies after five runs for each configuration. On both
MNIST and CIFAR-10 experiments, we also compare ChoiceNet with Mixup (Zhang et al., 2017)
which, to the best of our knowledge, shows the state-of-the-art performance on noisy labels. We set
the parameter α of Mixup to be 32 for the baseline network as suggested in the original paper. For
ChoiceNet, we set α to be 1.
For the MNIST experiments, we construct two networks: a network with two residual blocks (He
et al., 2016b) with 3 × 3 × 64 convolutional layers followed by a fully-connected layer with 256
output neurons (ConvNet) and a network with the same two residual blocks followed by a MCDN
block (ChoiceNet). We train each network for 50 epochs with a fixed learning rate of 1e - 5. For
the CIFAR experiments, we adopt WideResNet (WRN) (Zagoruyko & Komodakis, 2016) with 22
layers and a widening factor of 4. To construct ChoiceNet, we replace the last layer of WideResNet
with a MCDN block. We set K = 3, ρmax = 0.95, λreg = 0.0001, and ρk, πk, Σ0 modules consist
of two fully connected layers with 64 hidden units and a ReLU activation function. We train each
network for 300 epochs with a minibatch size of 256. We begin with a learning rate of 0.1, and it
decays by 1/10 after 150 and 225 epochs. We apply random horizontal flip and random crop with
4-pixel-padding and use a weight decay of 0.0001 for the baseline network as (He et al., 2016b).
However, to train ChoiceNet, we reduce the weight decay rate to 1e - 6 and apply gradient clipping
at 1.0. We also lower the learning rate to 0.001 for the first epoch to stabilize training.
Table 3: Test accuracies on the MNIST
datasets with corrupt labels.
Corruption p	Configuration	Best	Last
	ConvNet	95.4	89.5
50%	ConvNet+Mixup	97.2	96.8
	ConvNet+CN	99.2	99.2
	ConvNet	86.3	76.9
80%	ConvNet+Mixup	87.2	87.2
	ConvNet+CN	98.2	97.6
	ConvNet	76.1	69.8
90%	ConvNet+Mixup	74.7	74.7
	ConvNet+CN	94.7	89.0
	ConvNet	72.5	64.4
95%	ConvNet+Mixup	69.2	68.2
	ConvNet+CN	88.5	80.0
Table 4: Test accuracies on the CIFAR-10 datasets
with corrupt labels
Corruption p	Configuration	Best	Last
	ConvNet	88.5	85.3
20%	ConvNet+CN	90.7	90.3
	ConvNet+Mixup	92.9	92.3
	ConvNet+Mixup+CN	92.5	92.3
	ConvNet	79.7	59.3
50%	ConvNet+CN	85.9	84.6
	ConvNet+Mixup	87.3	83.1
	ConvNet+Mixup+CN	88.4	87.9
	ConvNet	67.8	27.4
80%	ConvNet+CN	69.8	65.2
	ConvNet+Mixup	72.1	62.9
	ConvNet+Mixup+CN	76.1	75.4
The classification results of the MNIST dataset and the CIFAR dataset are shown in Table 3 and
Table 4, respectively. In the MNIST experiments, ChoiceNet consistently outperforms ConvNet and
ConvNet+Mixup by a significant margin, and the difference between the accuracies of ChoiceNet
and the others becomes more clear as the corruption probability increases. Particularly, the best test
accuracy of ChoiceNet reaches 94% even when 90% of the training labels are randomly shuffled.
In the CIFAR-10 experiments, ChoiceNet outperforms WideResNet and achieves its accuracy over
60% even when 80% of the labels are shuffled whereas the accuracy of WideResNet drops below
30%. When we inspect the training accuracies on the 80%-shuffled set, WideResNet tends to overfit
(memorize) to noisy labels and shows 99.8% train accuracy. On the contrary, ChoiceNet shows
37.6%.3 When trained with Mixup, both networks become robust to noisy labels to some extent.
However, the results of the two networks still show significant differences except for the 20% corrupt
experiments on which both of them show similar accuracies. Interestingly, when ChoiceNet and
Mixup are combined, it achieves a high accuracy of 75% even on the 80% shuffled dataset. We also
2In the corrupt label setting, for a given corruption probability p, the expected ratio of correct labels is
(1 - p) + p × 1/(number of classes). Additional experiments of replacing the percentage of labels to a random
labels and a fixed label can be found in the appendix.
3 Detailed learning curves can be found in the appendix.
8
Under review as a conference paper at ICLR 2019
note that ChoiceNet (without Mixup) outperforms WideResNet+Mixup when the corruption ratio is
over 50% on the last accuracies.
5 Conclusion
In this paper, we have presented ChoiceNet that can robustly learn a target distribution given noisy
training data. The keystone of ChoiceNet is the mixture of correlated density network block which
can estimate the densities of data distributions using a set of correlated mean functions. We have
demonstrated that ChoiceNet can robustly infer the target distribution on corrupt training data in
the following tasks; regression with synthetic data, behavior cloning using demonstrations with
mixed qualities, and MNIST and CIFAR-10 image classification tasks. Our experiments verify that
ChoiceNet outperforms existing methods in the handling of noisy data.
Selecting proper hyper-parameters including the optimal number of mixture components is a com-
pelling topic for the practical usage of ChoiceNet. Furthermore, one can use ChoiceNet for active
learning by evaluating the quality of each training data using through the lens of correlations. We
leave these as important questions for future work.
References
AP and REUTERS. Tesla working on ’improvements’ to its autopilot radar changes after model s
owner became the first self-driving fatality., June 2016. URL https://goo.gl/XkzzQd.
Alan Joseph Bekker and Jacob Goldberger. Training deep neural-networks based on unreliable
labels. In Proc. of IEEE International Conference on Acoustics, Speech and Signal Processing, pp.
2682-2686. IEEE, 2016.
Vasileios Belagiannis, Christian Rupprecht, Gustavo Carneiro, and Nassir Navab. Robust optimization
for deep regression. In Proc. of the IEEE International Conference on Computer Vision, pp. 2830-
2838, 2015.
Wei Bi, Liwei Wang, James T Kwok, and Zhuowen Tu. Learning to predict from crowdsourced data.
In UAI, pp. 82-91, 2014.
Christopher M Bishop. Mixture density networks. 1994.
Edwin V Bonilla, Kian M Chai, and Christopher Williams. Multi-task gaussian process prediction.
In Proc. of the Advances in Neural Information Processing Systems, pp. 153-160, 2008.
Sungjoon Choi, Kyungjae Lee, and Songhwai Oh. Robust learning from demonstration using lever-
aged Gaussian processes and sparse constrained opimization. In Proc. of the IEEE International
Conference on Robotics and Automation (ICRA). IEEE, May 2016.
Sungjoon Choi, Kyungjae Lee, Sungbin Lim, and Songhwai Oh. Uncertainty-aware learning from
demonstration using mixture density networks with sampling-free variance modeling. arXiv
preprint arXiv:1709.02249, 2017.
M Bishop Christopher. PATTERN RECOGNITION AND MACHINE LEARNING. Springer-Verlag
New York, 2016.
Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of
gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.
Bo Dai, Bo Xie, Niao He, Yingyu Liang, Anant Raj, Maria-Florina F Balcan, and Le Song. Scalable
kernel methods via doubly stochastic gradients. In Proc. of the Advances in Neural Information
Processing Systems, pp. 3041-3049, 2014.
Alhussein Fawzi, Seyed Mohsen Moosavi Dezfooli, and Pascal Frossard. A geometric perspective on
the robustness of deep networks. IEEE Signal Processing Magazine, 2017.
Aritra Ghosh, Himanshu Kumar, and PS Sastry. Robust loss functions under label noise for deep
neural networks. In Proc. of the AAAI Conference on Artificial Intelligence, pp. 1919-1925, 2017.
9
Under review as a conference paper at ICLR 2019
Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-networks using a noise adaptation
layer. In Proc. of International Conference on Learning Representations, 2017.
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning, volume 1.
MIT press Cambridge, 2016.
Varun Gulshan, Lily Peng, Marc Coram, Martin C Stumpe, Derek Wu, Arunachalam Narayanaswamy,
Subhashini Venugopalan, Kasumi Widner, Tom Madams, Jorge Cuadros, et al. Development
and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus
photographs. Journal ofthe American Medical Association, 316(22):2402-2410, 2016.
Frank R Hampel, Elvezio M Ronchetti, Peter J Rousseeuw, and Werner A Stahel. Robust statistics:
the approach based on influence functions, volume 196. John Wiley & Sons, 2011.
Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: robust training deep neural networks with extremely noisy labels. In Proc.
of the Advances in Neural Information Processing Systems, 2018.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proc. of the IEEE conference on Computer Vision and Pattern Recognition, pp.
770-778, 2016a.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016b.
Dan Hendrycks, Mantas Mazeika, Duncan Wilson, and Kevin Gimpel. Using trusted data to train
deep networks on labels corrupted by severe noise. arXiv preprint arXiv:1802.05300, 2018.
Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Regularizing very
deep neural networks on corrupted labels. arXiv preprint arXiv:1712.05055, 2017.
Ishan Jindal, Matthew Nokleby, and Xuewen Chen. Learning deep networks from noisy labels with
dropout regularization. In Proc. of IEEE International Conference onData Mining, pp. 967-972.
IEEE, 2016.
Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer
vision? In Advances in Neural Information Processing Systems, pp. 5580-5590, 2017.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Diederik P Kingma. Variational inference & deep learning: A new synthesis. University of Amsterdam,
2017.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. In Proc. of
International Conference on Learning Representations, 2017.
Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep
neural networks. In Workshop on Challenges in Representation Learning, ICML, volume 3, pp. 2,
2013.
Xin Liu, Shaoxin Li, Meina Kan, Shiguang Shan, and Xilin Chen. Self-error-correcting convolutional
neural network for learning with noisy labels. In Proc. of IEEE International Conference on
Automatic Face &amp; Gesture Recognition, pp. 111-117. IEEE, 2017.
Eran Malach and Shai Shalev-Shwartz. Decoupling" when to update" from" how to update". In
Advances in Neural Information Processing Systems, pp. 961-971, 2017.
Takeru Miyato, Shin-ichi Maeda, Shin Ishii, and Masanori Koyama. Virtual adversarial training: a
regularization method for supervised and semi-supervised learning. IEEE transactions on pattern
analysis and machine intelligence, 2018.
10
Under review as a conference paper at ICLR 2019
Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with
noisy labels. In Proc. ofthe Advances in Neural Information Processing Systems, pp. 1196-1204,
2013.
Brian Paden, Michal C2ap, Sze Zheng Yong, Dmitry Yershov, and Emilio Frazzoli. A survey of motion
planning and control techniques for self-driving urban vehicles. IEEE Transactions on Intelligent
Vehicles, 1(1):33-55, 2016.
Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making
deep neural networks robust to label noise: a loss correction approach. In Proc. of the Conference
on Computer Vision and Pattern Recognition, volume 1050, pp. 22, 2017.
Emmanouil Antonios Platanios, Avinava Dubey, and Tom Mitchell. Estimating accuracy from
unlabeled data: A bayesian approach. In Proc. of International Conference on Machine Learning,
pp. 1416-1425, 2016.
Carl E Rasmussen and Zoubin Ghahramani. Infinite mixtures of gaussian process experts. In
Advances in Neural Information Processing Systems, pp. 881-888, 2002.
Carl Edward Rasmussen. Gaussian processes for machine learning. 2006.
Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. arXiv preprint
arXiv:1412.6596, 2014.
Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. In Proc. of International Conference on Machine Learning, 2018.
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy
optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.
Sainbayar Sukhbaatar, Joan Bruna, Manohar Paluri, Lubomir Bourdev, and Rob Fergus. Training
convolutional networks with noisy labels. arXiv preprint arXiv:1406.2080, 2014.
Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consis-
tency targets improve semi-supervised deep learning results. In Advances in neural information
processing systems, pp. 1195-1204, 2017.
Yuji Tokozume, Yoshitaka Ushiku, and Tatsuya Harada. Proc. of international conference on learning
representations. 2018.
Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, and Serge Belongie. Learning
from noisy large-scale datasets with minimal supervision. In Conference on Computer Vision and
Pattern Recognition, 2017.
Lingxi Xie, Jingdong Wang, Zhen Wei, Meng Wang, and Qi Tian. Disturblabel: Regularizing cnn on
the loss layer. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
4753-4762, 2016.
Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In BMVC, 2016.
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. In Proc. of International Conference on Learning
Representations, 2016.
Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical
risk minimization. In Proc. of International Conference on Learning Representations, 2017.
11
Under review as a conference paper at ICLR 2019
A Proof of Theorem in Section 3
In this appendix, we introduce fundamental theorems which lead to Cholesky transform for given
random variables (W, Z). We apply this transform to random matrices W and Z which carry out
weight matrices for prediction and a supplementary role, respectively. We also elaborate the details
of conducted experiments with additional illustrative figures and results. Particularly, we show
additional classification experiments with the MNST dataset on different noise configurations.
Lemma 1. Let W and Z be uncorrelated random variables such that
∫EW = μw, V (W )= σW
EZ = 0,	V (Z) = σZ2
(4)
For a given -1 ≤ ρ ≤ 1, set
Z = P”(W - μw) + P - ρ2Z	(5)
σW
Then EZ = 0, V(Z) = σZ, and Corr(W, Z) = ρ.
Proof. Since W and Z are uncorrelated, we have
E [(W — μw)Z] = E(W - μw)EZ = 0
By equation 4, we directly obtain
EZ = ρ-Z (EW - μw) + EZ = 0
σW
(6)
Also, by equation 4 and equation 6,
V (Z) = E|Z|2 = ρ2 (空)V(W) + V(Z) + 2ρσZ E [(W - μw)Z]
' σ	∖σw J	σw ×--------}
=0
2
=P2 萼 σW + (1-ρ2)σZ = σZ
σW
Similarly,
Cov(W, Z)= E [(W - μw)可
-μw )ρ -Z(W - μw) + E [(W - μw)Z]
σw	_|	×------{-----}
=0
=ρ^σZ V(W) = ρσz σw
σW
Therefore
Corr(W, Z)=	covMyZL- = ρσwσz = P
PV(W) JV(Z)	σW σZ
The lemma is proved.
□
Lemma 2. Assume the same condition in Lemma 1 and define Z as equation 5. For given functions
夕：R → R and ψ : R → (0, ∞), Set W :=夕(P) + ψ(ρ)Z. Then
EW =以 ρ), V(W) = ∣ψ(ρ)∣2σZ, Corr(W,W)= P
Proof. Note that
μw =。(P) + MpHz =。(P)
σW = lψ(ρ)l2E (Z - μz) = ψ2(ρ)σZ
12
Under review as a conference paper at ICLR 2019
Therefore, by Lemma 1
E h(W - μw)(W - μw)i = ψ(P)E h(W - μw)(Z - μZ)]
= ρψ(ρ)σWσZ
Hence
Corr(W,W)= E h(W -μW)(W -μW)i = Pψ(ρ)σwσz = P
σw σw	ψ(ρ)σw QZ
The lemma is proved.	□
Now we prove the aforementioned theorem in Section 3.
Theorem. Let ρ = (P1, . . . , PK) ∈ RK. Forp ∈ {1, 2}, random matrices W(p) ∈ RK×Q are given
such that for every k ∈ {1, . . . , K},
CovWk(ip),Wk(jp)	=	σp2δij,	CovWk(i1),Wk(j2)	=Pk	σ1	σ2δij	(7)
Given h = (h1, . . . , hQ) ∈ RQ, set y(p) = W(p)h for each p ∈ {1, 2}. Then an elementwise
correlation between y(1) and y(2) equals ρ i.e.
Corr yk(1),yk(2) = Pk, ∀k ∈ {1, . . . ,K}
Proof. First we prove that for p ∈ {1, 2} and k ∈ {1, . . . , K}
Vyk(p) = σp2 khk2	(8)
Note that
Q
XCov(Wk(ip),Wk(jp))hihj
i,j
By equation 7,
Q	QQ
V yk(p) = XCov(Wk(ip),Wk(jp))hihj = X σp2hihjδij = X σp2hi2 = σp2khk2
i,j	i,j	i=1
so equation 8 is proved. Next we prove
Cov(yk(1),yk(2)) = Pk σ1 σ2 khk2	(9)
13
Under review as a conference paper at ICLR 2019
Observe that
Q
Wk(i1)hi - E
i=1
Q
X Wk(i1)hi
i=1
Q
XWk(j2)hj -E
j=1
Q
XWk(j2)hj
j=1
E
E
Q
X Wk(i1) -EWk(i1)Wk(j2) -EWk(j2)hihj
i,j
Q
Cov(Wk(i1),Wk(j2))hihj
i,j
Similarly,
QQ
Cov(yk(1), yk(2)) = XCov(Wk(i1),Wk(j2))hihj = Xρkσ1σ2hihjδij = ρkσ1σ2 khk2
i,j	i,j
Hence equation 9 is proved. Therefore by equation 8 and equation 9
COV3k1),yk2>	=	Pkσ1σ2 khk2
√V(yk1))√V(yk2))	√σ2 khk2√σ2 khk2
The theorem is proved.
□
Remark. Recall the definition of Cholesky transform: for -1<P<1
T(ρ,μw ,σw ,σz) (W,Z)= PMW + V1 - p
(W - μw) + √1-P2z
(10)
Note that we do not assume W and Z should follow typical distributions. Hence every above theorems
hold for general class of random variables. Additionally, by Theorem 2 and equation 10, W has the
following P-dependent behaviors;
)μw
0
-μw
P→1
P→0
P→ -1
V(W) →[02
σZ
: P→ ±1
:ρ → 0
Thus strongly correlated weights W i.e. P ≈ 1, provide prediction with confidence while uncorrelated
weights encompass uncertainty. These different behaviors of weights perform regularization and
preclude over-fitting caused by bad data since uncorrelated and negative correlated weights absorb
vague and outlier pattern, respectively.
B Additional Experiments
B.1	Regression Tasks
B.1.1	Synthetic Example
We provide more fitting results for the synthetic example in Figure 4. Given an intact dataset, all
compared methods robustly fit the given training data. However, other methods fail to correctly fit the
underlying target function given corrupt data. When the outlier rate exceeds 90% all tested methods
fail to fit.
B.1.2	Autonomous Driving Experiment
Autonomous Driving Experiment In this experiment, we apply ChoiceNet to a autonomous
driving scenario in a simulated environment. In particular, the tested methods are asked to learn the
14
Under review as a conference paper at ICLR 2019
-1	O	1
Input
20% outliers from -1.0 to 3.0
Input
Input
Figure 4: Reference function and fitting results of compared methods on different outlier rates,
0%,20% 40%, 80%, and 90%).
Input
15
Under review as a conference paper at ICLR 2019
Figure 5: Resulting trajectories of compared methods trained with mixed demonstrations. (best
viewed in color).
Table 5: Collision rates of compared methods on straight lanes.
Outliers ∣	ChoiceNet	MDN	MLP	GPR	LGPR	RGPR
~%%	0%	50.83%	^^0%~~	0.83%	4.17%	3.33%
10%	0%	38.33%	0%	2.5%	1.67%	4.17%
20%	0%	41.67%	0%	7.5%	6.67%	10%
30%	0%	66.67%	1.67%	4.17%	1.67%	7.5%
40%	0.83%	35%	3.33%	6.67%	6.67%	24.17%
Table 6: Root mean square lane deviation distances (m) of compared methods on straight lanes.
Outliers	I ChoiCeNet	MDN	MLP	GPR	LGPR	RGPR
0%	0.314	0.723	0.300	0.356	0.349	0.424
10%	0.352	0.387	0.438	0.401	0.446	0.673
20%	0.349	0.410	0.513	0.418	0.419	0.725
30%	0.368	0.368	0.499	0.455	0.476	0.740
40%	0.370	0.574	0.453	0.453	0.453	0.636
policy from driving demonstrations collected from both safe and careless driving modes. We use the
same set of methods used for the previous task. The policy function is defined as a mapping between
four dimensional input features consist of three frontal distances to left, center, and right lanes and
lane deviation distance from the center of the lane to the desired heading. Once the desired heading is
computed, the angular velocity of a car is computed by 10 * (θdesired — θcurrent) and the directional
velocity is fixed to 10m/s. The driving demonstrations are collected from keyboard inputs by human
users. The objective of this experiment is to assess its performance on a training set generated from
two different distributions. We would like to note that this task does not have a reference target
function in that all demonstrations are collected manually. Hence, we evaluated the performances
of the compared methods by running the trained policies on a straight track by randomly deploying
static cars.
Table 5 and Table 6 indicate collision rates and RMS lane deviation distances of the tested methods,
respectively, where the statistics are computed from 50 independent runs on the straight lane by
randomly placing static cars as shown in Figure 5. ChoiceNet clearly outperforms compared methods
in terms of both safety (low collision rates) and stability (low RMS lane deviation distances).
Here, we describe the features used for the autonomous driving experiments. As shown in the
manuscript, we use a four dimensional feature, a lane deviation distance of an ego car, and three
frontal distances to the closest car at left, center, and right lanes as shown in Figure 6. We upperbound
the frontal distance to 40m. Figure 7(a) and 7(b) illustrate manually collected trajectories of a safe
driving mode and a careless driving mode.
16
Under review as a conference paper at ICLR 2019
Figure 6: Descriptions of the featrues of an ego red car used in autonomous driving experiments.
(a)
(b)
Figure 7: Manually collected trajectories of (a) safe driving mode and (b) careless driving mode.
(best viewed in color).
B.2 Classification Tasks
B.2.1	Ablation Study on MNIST
Above figures show the results of ablation study when varying the number of mixture K and the
expected measurement variance τ-1. Left two figures indicate test accuracies using the MNIST
dataset where 90% of train labels are randomly shuffled and right two figures are RMSEs using a
synthetic one-dimensional regression problem in Section 4.1. We observe that having bigger K is
beneficial to the classification accuracies. In fact, the results achieved here with K equals 15 and 20
are better than the ones reported in the submitted manuscript. τ -1 does not affect much unless it is
exceedingly large.
B.2.2	Different types of Noise on MNIST
Here, we present additional experimental results using the MNIST dataset on following three different
scenarios:
1.	Biased label experiments where we randomly assign the percentage of the training labels to
label 0.
2.	Random shuffle experiments where we randomly replace the percentage of the training
labels from the uniform multinomial distribution.
3.	Random permutation experiments where we replace the percentage of the labels based on
the label permutation matrix where we follow the random permutation in (Reed et al., 2014).
The best and final accuracies on the intact test dataset for biased label experiments are shown in
Table 7. In all corruption rates, ChoiceNet achieves the best performance compared to two baseline
methods. The learning curves of the biased label experiments are depicted in Figure 8. Particularly,
we observe unstable learning curves regarding the test accuracies of ConvNet and Mixup. As training
accuracies of such methods show stable learning behaviors, this can be interpreted as the networks
are simply memorizing noisy labels. In the contrary, the learning curves of ChoiceNet show stable
behaviors which clearly indicates the robustness of the proposed method.
17
Under review as a conference paper at ICLR 2019
Table 7: Test accuracies on the MNIST dataset with biased label.
Corruption p	Configuration	Best	Last
	ConvNet	95.4	89.5
25%	ConvNet+Mixup	97.2	96.8
	ChoiceNet	99.2	99.2
	ConvNet	86.3	76.9
40%	ConvNet+Mixup	87.2	87.2
	ChoiceNet	98.2	97.6
	ConvNet	76.1	69.8
45%	ConvNet+Mixup	74.7	74.7
	ChoiceNet	94.7	89.0
	ConvNet	72.5	64.4
47%	ConvNet+Mixup	69.2	68.2
	ChoiceNet	88.5	80.0
Table 8: Test accuracies on the MNIST dataset with corrupt label.
Corruption p	Configuration	Best	Last
	ConvNet	97.1	95.9
50%	ConvNet+Mixup	98.0	97.8
	ChoiceNet	99.1	99.0
	ConvNet	90.6	79.0
80%	ConvNet+Mixup	95.3	95.1
	ChoiceNet	98.3	98.3
	ConvNet	76.1	54.1
90%	ConvNet+Mixup	78.6	42.4
	ChoiceNet	95.9	95.2
	ConvNet	50.2	31.3
95%	ConvNet+Mixup	53.2	26.6
	ChoiceNet	84.5	66.0
The experimental results and learning curves of the random shuffle experiments are shown in Table 8
and Figure 9. The convolutional neural networks trained with Mixup show robust learning behaviors
when 80% of the training labels are uniformly shuffled. However, given an extremely noisy dataset
(90% and 95%), the test accuracies of baseline methods decrease as the number of epochs increases.
ChoiceNet shows outstanding robustness to the noisy dataset in that the test accuracies do not drop
even after 50 epochs for the cases where the corruption rates are below 90%. For the 95% case,
however, over-fitting is occured in all methods.
Table 9 and Figure 10 illustrate the results of the random permutation experiments. Specif-
ically, we change the labels of randomly selected training data using a permutation rule:
(0, 1,2,3,4,5,6,7,8,9) → (7,9,0,4,2, 1,3,5,6,8) following (Reed et al., 2014). We argue that
this setting is more arduous than the random shuffle case in that we are intentionally changing the
labels based on predefined permutation rules.
B.2.3	CIFAR- 1 0
Here, we present detailed learning curves of the CIFAR-10 experiments while varying the noise level
from 20% to 80% following the configurations in (Zhang et al., 2017).
18
Under review as a conference paper at ICLR 2019
Table 9: Test accuracies on the MNIST dataset with randomly permutated label.
Corruption p	Configuration	Best	Last
	ConvNet	94.4	92.2
25%	ConvNet+Mixup	97.6	97.6
	ChoiceNet	99.2	99.2
	ConvNet	77.9	71.8
40%	ConvNet+Mixup	84.0	83.0
	ChoiceNet	99.2	98.8
	ConvNet	68.0	61.4
45%	ConvNet+Mixup	68.9	55.8
	ChoiceNet	98.0	97.1
	ConvNet	58.2	53.9
47%	ConvNet+Mixup	60.2	53.4
	ChoiceNet	92.5	86.1
Number of Epochs
(b)
(a)
Number of Epochs
(c)	(d)
Figure 8:	Learning curves of compared methods on random bias experiments using MNIST with
different noise levels.
19
Under review as a conference paper at ICLR 2019
(a)
(b)
90% Random Shuffle
—— ChoiceNet (train) — — ConvNet (train) Mixup (train)
----ChoiceNet (test)	---- ConvNet (test) ------ Mixup (test)
— ChoiceNet (train)	— ConvNet (train)	— Mixup (train)
ChoiceNet (test)	ConvNet (test)	---- Mixup (test)
95% Random Shuffle
Number of Epochs
(C)
Number of Epochs
(d)
Figure 9:	Learning Curves of Compared methods on random shuffle experiments using MNIST with
different noise levels.
Number of Epochs
(a)
(b)
Number of Epochs
Number of Epochs
(C)
(d)
Figure 10:	Learning Curves of Compared methods on random permutation experiments using MNIST
with different noise levels.
20
Under review as a conference paper at ICLR 2019
(a)
---WideResNet (test)
----ChoiceNet (test)
----WideResNet (train)
(b)
(c)
Figure 11: Learning curves of compared methods on CIFAR-10 experiments with different noise
levels.
(d)
21