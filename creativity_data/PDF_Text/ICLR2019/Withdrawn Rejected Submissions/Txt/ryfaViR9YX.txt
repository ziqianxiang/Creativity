Under review as a conference paper at ICLR 2019
Variation Network:
Learning High-level Attributes for
Controlled Input Manipulation
Anonymous authors
Paper under double-blind review
Ab stract
This paper presents the Variation Network (VarNet), a generative model providing
means to manipulate the high-level attributes of a given input. The originality of
our approach is that VarNet is not only capable of handling pre-defined attributes
but can also learn the relevant attributes of the dataset by itself. These two settings
can be easily combined which makes VarNet applicable for a wide variety of tasks.
Further, VarNet has a sound probabilistic interpretation which grants us with a
novel way to navigate in the latent spaces as well as means to control how the
attributes are learned. We demonstrate experimentally that this model is capable
of performing interesting input manipulation and that the learned attributes are
relevant and interpretable.
1	Introduction
We focus on the problem of generating variations of a given input in an intended way. This means
that given some input element x, which can be considered as a template, we want to generate trans-
formed versions of x with different high-level attributes. Such a mechanism is of great use in many
domains such as image edition since it allows to edit images on a more abstract level and is of crucial
importance for creative uses since it allows to generate new content.
More precisely, given a dataset D = {(x(1) , m(1)), . . . , (x(N) , m(N))} of N labeled elements
(x, m) ∈ X × M, where X stands for the input space and M for the metadata space, we would like
to obtain a model capable of learning a relevant attribute space Ψ ⊂ Rd for some integer d > 0 and
meaningful attribute functions φ : X × M → Ψ that we can then use to control generation.
In a great majority of the recent proposed methods Lample et al. (2017); Upchurch et al. (2016),
these attributes are assumed to be given. We identify two shortcomings: labeled data is not always
available and this approach de facto excludes attributes that can be hard to formulate in an absolute
way. The novelty of our approach is that these attributes can be either learned by the model (we
name them free attributes) or imposed (fixed attributes). This problem is an ill-posed one on many
aspects. Firstly, in the case of fixed attribute functions φ, there is no ground truth for variations since
there is no x with two different attributes. Secondly, it can be hard to determine if a learned free
attribute is relevant. However, we provide empirical evidence that our general approach is capable
of learning such relevant attributes and that they can be used for generating meaningful variations.
In this paper, we introduce the Variation Network (VarNet), a probabilistic neural network which
provides means to manipulate an input by changing its high-level attributes. Our model has a sound
probabilistic interpretation which makes the variations obtained by changing the attributes statisti-
cally meaningful. As a consequence, this probabilistic framework provides us with a novel mecha-
nism to “control” or “shape” the learned free attributes which then gives interpretable controls over
the variations. This architecture is general and provides a wide range of choices for the design of
the attribute function φ: we can combine both free and fixed attributes and the fixed attributes can
be either continuous or discrete.
Our contributions are the following:
•	A widely applicable encoder-decoder architecture which generalizes existing approaches
Kingma & Welling (2013); Rubenstein et al. (2018); Lample et al. (2017)
1
Under review as a conference paper at ICLR 2019
Input:	Noise:
D	n
Output:
NAF:
Output
↑
Meta-
Parameters
Input
NN:
------------>
Identify function:
............>
Concatenation:
㊉
Figure 1: VarNet architecture. The input x,x are in X, the input space and the metadata m is
in M, the metadata space. The latent template code z* lies in Z*, the template space, while the
latent variable z lies in Z the latent space. The variable u is sampled from a zero-mean unit-
variance normal distribution. Finally, the features φ(x, m) are in Ψ, the attribute space. The Neural
Autoregressive Flows (NAF) Huang et al. (2018) are represented using two arrows, one pointing to
the center of the other one; this denotes the fact that the actual parameters of first neural network
are obtained by feeding meta-parameters into a second neural network. The discriminator D acts on
Z* × Ψ.
•	An easy-to-use framework: any encoder-decoder architecture can be easily transformed
into a VarNet in order to provide it with controlled input manipulation capabilities,
•	A novel and statistically sound approach to navigate in the latent space,
•	Ways to control the behavior of the free learned attributes.
The plan of this paper is the following: Sect. 2 presents the VarNet architecture together with its
training algorithm. For better clarity, we introduce separately all the components featured in our
model and postpone the discussion about their interplay and the motivation behind our modeling
choices in Sect. 3 and Sect. 4 discusses about the related works. In particular, we show that VarNet
provides an interesting solution to many constrained generation problems already considered in the
literature. Finally, we illustrate in Appendix A the possibilities offered by our proposed model and
show that its faculty to generate variations in an intended way is of particular interest.
2	Proposed model
We now introduce our novel encoder-decoder architecture which we name Variation Network. Our
architecture borrows principles from the traditional Variational AutoEncoder (VAE) architecture
Kingma & Welling (2013) and from the Wasserstein AutoEncoder (WAE) architecture Tolstikhin
et al. (2017); Rubenstein et al. (2018). It uses an adversarially learned regularization Dumoulin
et al. (2016); Lample et al. (2017), introduces a separate latent space for templates Adel et al. (2018)
and decomposes the attributes on an adaptive basis Wang et al. (2018). It can be seen as a VAE with
a particular decoder network or as a WAE with a particular encoder network. Our architecture is
shown in Fig. 1 and our training algorithm is presented in Alg. 1.
We detail in the following sections the different parts involved in our model. In Sect. 2.1, we focus
on the encoder-decoder part of VarNet and explain Eq. (3), (4) and (5). In Sect. 2.2, we introduce the
adversarially-learned regularization whose aim is to disentangle attributes from templates (Eq. (1)
and (6)). Section 2.3 discusses the special parametrization that we adopted for the attribute space Ψ.
2
Under review as a conference paper at ICLR 2019
Algorithm 1 Variation Network training procedure
Require: Dataset D = (x(i), m(i) i=1 N, reconstruction cost c,
reproducing kernel k, batch size n ..
1:	for Fixed number of iterations do
2:	Sample x := (x1, . . . , xn) and m := (m1, . . . , mn) where (xi, mi) i.i.d. samples from D
3:	Sample z* 〜q*(∙∣Xi)
4:	Compute Z := {zι,...,zn} where Zi = fφ(χi,mi)(z*)
5:	Sample X := {Xι,...,Xn} where Xi 〜p(∙∣Zi),
6:	Sample random features {ψi}i=1..n from feature space Ψ using ν (see Sect. 2.3)
7:	Let Z := {Zι,..., Zn} where Zi 〜p(∙)
8:	Discriminator training phase
9:	Compute
1n
LDisc,n ：= -ɪ^logD (z*,Ψi) + log(1 - D(Zi,φ(xi,mi)))	(1)
n i=1
10:	Gradient ascent step on the discriminator parameters using VLDisc
11:	Encoder-decoder training phase
12:	Compute
LEncDec,n := REn +βKL*n + λMMDk,n +γRDisc,n	(2)
where
1n
REn ：= — V" C(Xi，Xi ),	(3)
n
i=1
1n
KLn ：= -ɪ^log q (Zi ∣Xi) - logP (Zi ),	(4)
n i=1
1	12
MMDk,n ：=	n(n _ 1)E k(Zl,	Zj) +	n(n	- ι) Ek(Zl，Zj)	-	k(Zl, ZZj),	(5)
1n
RDisc,n = — —	log D(z*,φ(xi ,mi)).	(6)
n
i=1
13:	Gradient ascent step on all parameters except the discriminator parameters (encoder and de-
coder parameters, feature function parameters, features vectors and NAF f) using VLEncDec
14:	end for
2.1	Encoder-decoder part
Similar to the VAE architectures, we suppose that our data X ∈ X depends on some latent variable
Z ∈ Z through some decoder p(X|Z) parametrized by a neural network. We introduce a prior p(Z)
over this latent space so that the joint probability distribution is expressed as p(X, Z) = p(X|Z)p(Z).
Since the posterior distribution p(Z|X) is usually intractable, an approximate posterior distribution
q(Z|X) parametrized by a neural network is usually introduced.
The novelty of our approach is on how we write this encoder network. Firstly, we introduce an
attribute space Ψ ⊂ Rd, where d is the dimension of the attribute space, on which we condition
the encoder which We now denote as q(∙∣χ, ψ ∈ Ψ). More details about the attribute space Ψ are
given in Sect. 2.3. For the moment, we can consider it to be a subspace of Rd from which we can
sample from. The objective in doing so is that decoding Z 〜q(∙∣x, ψ) using p(x∣z) will result in a
sample XZ that is a variation of X but with features ψ . Secondly, in order to correctly reconstruct X,
introduce an attribute function φ : X × M → Ψ computed from X and its metadata m with values
in the attribute space Ψ. This attribute function is a deterministic neural network that will be learned
during training and whose aim is to compute attributes of X.
For an input (X, m) ∈ D, we want to decouple a template obtained from X from its attributes φ(X, m)
computed from X and (possibly) from its metadata m. This is done by introducing another latent
space Z* that we term template space together with a approximated posterior distribution q* (Z* |X)
3
Under review as a conference paper at ICLR 2019
parametrized by a neural network and a fixed prior p*(z*). The idea is then to compute Z from z*
by applying a transformation parametrized only by the feature space Ψ. In practice, this is done
by using a Neural Autoregressive Flow (NAF) Huang et al. (2018) fψ : Z * → Z parametrized by
ψ ∈ Ψ. Neural autoregressive flows are universal density estimation models which are capable of
sampling any random variable Y by applying a learned transformation over a base random variable
X (Thm. 1 in Huang et al. (2018)).
Given a reconstruction loss c on X, we have the following mean reconstruction loss:
RE := E(x,m)〜DE^〜PGIz)Ez〜q(∙∣x,φ(x,m))C(X, X).
(7)
We regularize the latent spaces Z * and Z by adding the usual KL term appearing in the VAE
Evidence Lower Bound (ELBO) on Z* :
KL* := Ez*y(.∣χ) lθg qP(^
(8)
and an MMD-based regularization on Z similar the one used in WAEs (see Alg. 2 in Tolstikhin et al.
(2017)):
MMDk (q(∙∣x,Φ(x,m)),p(∙))
1k(z, ∙)q(z∣x, Φ(x, m)) — 1 k(z, ∙)p(z)
(9)
Hk
where k : Z × Z → R is an positive-definite reproducing kernel and Hk the associated Reproducing
Kernel Hilbert Space (RKHS) Berlinet & Thomas-Agnan (2011).
The equations (3), (4) and (5) of Alg. 1 are estimators on a mini-batch of size n of equations (7), (8)
and (9) respectively, (5) being the unbiased U-statistic estimator of (9) Gretton et al. (2012).
2.2	Disentangling attributes from templates
Our encoder q(z|X, ψ) thus depends exclusively on X and on the feature space Ψ. However, there
is no reason, for a random attribute ψ ∈ Ψ = φ(x, m), that p(x∣z) where Z 〜q(z|x, φ) generates
variations of the original X with features φ. Indeed, all needed information for reconstructing X is
potentially already contained in Z .
We propose to add an adversarially-learned cost on the latent variable Z* to force the encoder q* to
discard information about the attributes of X: Specifically, we train a discriminator neural network
D : Z* ×Ψ → [0, 1] whose role is to evaluate the probability D(Z*, ψ) that there exists a (X, m) ∈ D
such that ψ = φ(x, m) and z* 〜q*(∙∣x). In other words, the aim of the discriminator is to determine
if the attributes ψ and the template code Z* originate from the same (X, m) ∈ D or if the features ψ
are randomly generated. We postpone the explanation on how we sample random features ψ ∈ Ψ
in Sect. 2.3 and suppose for the moment that we have access to a distribution ν(ψ) over Ψ from
which we can sample. The encoder-decoder architecture presented in Sect. 2.1 is trained to fool the
discriminator: this means that for a given (x,m) ∈ D it tries to produce a template code z* 〜q*(∙∣x)
which contains no information about the features φ(X, m).
In an optimal setting, i.e. when the discriminator is unable to match any z* ∈ Z * with a particular
feature ψ ∈ Ψ, the space of template codes and the space of attributes are decorrelated. All the
missing information needed to reconstruct X given z* 〜q*(∙∣x) lies in the transformation fφ(χ,m).
Since these transformations between the template space Z* and the latent space Z only depend
on the feature space Ψ, they tend to be applicable over all template codes z * and generalize well.
During generation time, it is then possible to change the attributes of a sample without changing its
template.
The discriminator is trained to maximize
LDisc := E(χ,m)〜DEz*〜q*(∙∣χ) [Eψ〜ν(∙) logD(z*,ψ) + log(1 - D(z*,φ(x, m)))] .	(10)
while the encoder-decoder architecture is trained to minimize
RDisc := -E(χ,m)"Ez*〜q*(∙∣χ) logD(z* φ(x, m)).	(11)
Estimators of Eq. (10) and (11) are given by Eq. (1) and (6) respectively.
4
Under review as a conference paper at ICLR 2019
2.3	Parametrization of the attribute space
We adopt a particular parametrization of our attribute function φ : X × M so that we are able to
sample fake attributes without the need to rely on an existing (x, m) ∈ D pair. In the following, we
make a distinction between two different cases: the case of continuous free attributes and the case
of fixed continuous or discrete attributes.
2.3.1	Free attributes
In order to handle free attributes, which denote attributes that are not specified a priori but learned.
For this, we introduce dΨ attribute vectors vi of dimension d together with an attention module
α : X × M → [0, 1]dΨ, where dΨ is the intrinsic dimension of the attribute space Ψ. By denoting
αi the coordinates of α, we then write our attribute function φ as
dΨ
φ(x, m) =	αi(x, m)vi.	(12)
i=1
This approach is similar to the style tokens approach presented in Wang et al. (2018). The vi ’s are
global and do not depend on a particular instance (x, m). By varying the values of the ai's between
[0, 1], we can then span a dΨ-dimensional hypercube in Rd which stands for our attribute space Ψ.
It is worth noting that the vi’s are also learned and thus constitute an adaptive basis of the attribute
space.
In order to define a probability distribution ν over Ψ (note that this subspace also varies during
training), we are free to choose any distribution να over [0, 1]dΨ. We then sample random attributes
from ν by
dΨ
ψ 〜V ^⇒ ψ = ^^aivi where α 〜Va.	(13)
i=1
2.3.2	Fixed attributes
We now suppose that the metadata variable m ∈ M contains attributes that we want to vary at gen-
eration time. For simplicity, we can suppose that this metadata information can be either continuous
with values in [0, 1]M (with a natural order on each dimension) or discrete with values in [|0, M|].
In the continuous case, we write our attribute function
M
φ(x, m) =	mivi	(14)
i=1
while in the discrete case, we just consider
φ(x, m) = em,	(15)
where em is a dΨ-dimensional embedding of the symbol m. It is important to note that even if the
attributes are fixed, the vi’s or the embeddings em are learned during training.
These two equations define a natural probability distribution V over Ψ:
ψ 〜v ^⇒ ψ = φ(x,m) where (x,m)〜D.	(16)
3	Comments
We now detail our objective (2) and notably explain our particular choice concerning the regulariza-
tions on the latent spaces Z* and Z. In Sect. 3.1, We will see that these insights suggest an additional
way to “control” the influence of the learned free attributes. In Sect. 3.2, we further discuss about
the multiple possibilities that we have concerning the implementation of the attribute function. We
list, in Sect. 3.3, the different sampling schemes of VarNet. Finally, Sect. 3.4 is dedicated to imple-
mentation details.
5
Under review as a conference paper at ICLR 2019
3.1	Choice of the regularizations on the latent spaces
We discuss our choice concerning the regularizations of the latent spaces and specifically why we
chose a KL regularization on Z* and an MMD loss on Z.
We found that using a MMD-based regularization on the template space Z* resulted in approx-
imated posterior distributions q*(∙∣x) with very small variances (almost deterministic mappings).
One explanation of this behavior is that the MMD regularization tries to enforce that the aggre-
gated posterior 焉 PN=I q*(∙∣χ(i)) matches the prior p*: it does not act on the individual conditional
probability distributions q*(∙∣χ). This degenerate behavior is a side-effect of our adversarial regu-
larization since stochastic encoders have been successfully used in WAEs Rubenstein et al. (2018).
When using the the Kullback-Leibler regularization on Z*, this effect disappear which makes the
KL regularization that we considered more suited for VarNet since it helps to keep our model out
of a degenerate regime. For some applications, it can still be of interest to have a control over the
variance of the conditional probability distributions q*(∙∣χ). Similar to the approach of Higgins et al.
(2016); Burgess et al. (2018), we propose to multiply the KL term by a scalar parameter β > 0. For
β = 1, we retrieve the original formulation. For β ∈]0, 1[, decreasing the value of β from one to
zero decreases the variance of the q*(∙∣χ). We found no gain in considering values of β greater than
1. Examples where this tuning provides an interesting application are given in Sect. A.2.
We now consider the regularization over Z . This regularization is in fact superfluous and could
be removed. However, we noticed that adding this MMD regularization helped obtaining better
reconstruction losses.
3.2	Flexibility in the choice of the attribute function
In this section, we focus on the parametrization of the attribute function φ : X × Z 7→ Rd and
propose some useful use cases. The formulation of Sect. 2.3 is in fact too restrictive and considered
only one attribute function. It is in fact possible to mix different attributes functions by simply
concatenating the resulting vectors. By doing so, we can then combine free and fixed attributes in
a natural way but also consider different attention modules α. We can indeed use neural networks
with different properties similarly to what is done in Chen et al. (2016) but also consider different
distributions over the attention vectors αi .
It is important to note that the free attributes presented in Sect. 2.3.1 can only capture global at-
tributes, which are attributes that are relevant for all elements of the dataset D. In the presence
of discrete labels m, it can be interesting to consider label-dependent free attributes, which are
attributes specific to a subset of the dataset. In this case, the attribute function φ can be written as
dψ
φ(x, m) =	αi(x, m)em,i,	(17)
i=1
where em,i designates the ith attribute vector of the label m. With all these possibilities at hand, it is
possible to devise numerous applications in which the notions of template and attribute of an input
x may have diverse interpretations.
Our choice of using a discriminator over Ψ instead of, for instance, over the values of α themselves
allow to encompass within the same framework discrete and continuous fixed attributes. This makes
the combinations of such attributes functions natural.
3.3	Sampling schemes
We quickly review the different sampling schemes of VarNet. We believe that this wide range of
usages makes VarNet a promising model for a wide range of applications.
We can for instance:
•	generate random samples X from the estimated dataset distribution:
X ~p(∙∣z) with Z = fψ(z*) where z* ~ p*(∙) and ψ ~ V(∙),	(18)
•	sample X with given attributes ψ:
X ~ p(∙∣z) with z = fψ(z*) where z* ~ p*(∙),	(19)
6
Under review as a conference paper at ICLR 2019
•	generate a variations of an input x with attributes ψ:
X 〜p(∙∣z) with Z = fψ(z*) where z* 〜q*(∙∣x),	(20)
•	generate random variations of an input x:
X 〜p(∙∣z) with z = fψ(z*) where z* 〜q*(∙∣x) and ψ 〜ν(∙).	(21)
Note that for sampling generate random samples X, we do that by sampling z* 〜 p*(∙) from the
prior, ψ 〜 ν(∙) from the distribution of the attributes and then decoding Z = fψ(z*) decoding it
using the decoder p(∙∣z) instead of just decoding a z* 〜p*(∙) sampled from the prior. This is due
to the fact that, as already mentioned, this MMD regularization is not an essential element of the
VarNet architecture: its role is more about fixing the ”scale” of the Z space rather than enforcing
that the aggregated posterior distribution exactly matches the prior.
In the case of continuous attributes of the form Eq. (12) or (14), VarNet also provides a new way
to navigate in the latent space Z. Indeed, for a given template latent code z*, it is possible to
move continuously in the latent space Z by simply changing continuously the values of the αi and
then considering z = fψ (z*) where ψ = Pid=ψ1 aivi. The image by the above transformation in
the Z space of the dΨ dimensional hypercube [0, 1]dψ constitutes the space of variations of the
template z*. Since our feature space bears a measure ν, this space of variations has a probabilistic
interpretation. To the best of our knowledge, we think that it is the first time that a meaningful
probabilistic interpretation about the displacement in the latent space in terms of attributes is given:
We’ll see in Appendix A.3 that two similar variations applied on different templates can induce
radically different displacements in the latent space Z . We hope that this new technique will be
useful in many applications and help go beyond the traditional (but unjustified) linear or spherical
interpolations White (2016).
3.4	Implementation details
Our architecture is general and any decoder and encoder networks can be used. We chose to use a
NAF1 for our encoder network. This choice has the advantage of using a more expressive posterior
distribution compared to the often-used diagonal Gaussian posterior distributions.
Our priors p* and p are zero-mean unit-variance Gaussian distributions. For the MMD regulariza-
tion, we used the parameters used in Tolstikhin et al. (2017) (λ = 10 and k(X, y) = C/(C+kX-yk22)
the inverse multiquadratics kernel with C = 2dim(Z)). For the scalar coefficient γ, we found that
a value of 10 worked well on all our experiments.
For the sampling of the α values in the free attributes case, we considered να to be a uniform
distribution over [0, 1]dψ. In the fixed attribute case, we simply obtain a random sample {ψi}in=1 by
shuffling the already computed batches of {φ(Xi, mi)}in=1 (lines 4 and 6 in Alg.1).
4	Related work
The Variation Network generalizes many existing models used for controlled input manipulation by
providing a unified probabilistic framework for this task. We now review the related literature and
discuss the connections with VarNet.
The problem of controlled input manipulation has been considered in the Fader networks paper
Lample et al. (2017), where the authors are able to modify in a continuous manner the attributes
of an input image. Similar to us, this approach uses an encoder-decoder architecture together with
an adversarial loss used to decouple templates and attributes. The major difference with VarNet is
that this model has a deterministic encoder which limits the sampling possibilities as discussed in
Sect. A.2. Also, this approach can only deal with fixed attributes while VarNet is able to also learn
meaningful free attributes. In fact, VAEs Kingma & Welling (2013), WAEs Tolstikhin et al. (2017);
Rubenstein et al. (2018) and Fader networks can be seen as special cases of VarNet.
Recently, the Style Tokens paper Wang et al. (2018) proposed a solution to learn relevant free at-
tributes in the context of text-to-speech. The similarities with our approach is that the authors con-
dition an encoder model on an adaptive basis of style tokens (what we called attribute space in this
1We used the implementation of Huang et al. (2018) available at https://github.com/CW-Huang/NAF
7
Under review as a conference paper at ICLR 2019
work). VarNet borrows this idea but cast it in a probabilistic framework, where a distribution over
the attribute space is imposed and where the encoder is stochastic. Our approach also allows to take
into account fixed attributes, which we saw can help shaping the free attributes.
Traditional ways to explore the latent space of VAEs is by doing linear (or spherical White (2016))
interpolations between two points. However, there are two major caveats in this approach: the
requirement of always needing two points in order to explore the latent space is cumbersome and
the interpolation scheme is arbitrary and bears no probabilistic interpretation. Concerning the first
point, a common approach is to find, a posteriori, directions in the latent space that accounts for a
particular change of the (fixed) attributes Upchurch et al. (2016). These directions are then used to
move in the latent space. Similarly, Hadjeres et al. (2017) proposes a model where these directions
of interest are given a priori. Concerning the second point, Laine (2018) proposes to compute
interpolation paths minimizing some energy functional which result in interpolation curves rather
than interpolation straight lines. However, this interpolation scheme is computationally demanding
since an optimization problem must be solved for each point of the interpolation path.
Another trend in controlled input manipulation is to make a posteriori analysis on a trained gener-
ative model Engel et al. (2017); Adel et al. (2018); Upchurch et al. (2016); Cao et al. (2018) using
different means. One possible advantage of these methods compared to ours is that different attribute
manipulations can be devised after the training of the generative model. But, these procedures are
still costly and so provide any real-time applications where a user could provide on-the-fly the at-
tributes they would like to modify. One of these approaches Cao et al. (2018) consists in using
the trained decoder to obtained a mapping Z 7→ X and then performing gradient descent on an
objective which accounts for the constraints or change of the attributes. Another related approach
proposed in Engel et al. (2017) consists in training a Generative Adversarial Network which learns
to move in the vicinity of a given point in the latent space so that the decoded output enforces some
constraints. The major difference of these two approaches with our work is that these movements
are done in a unique latent space, while in our case we consider separate latent spaces. But more
importantly, these approaches implicitly consider that the variation of interest lies in a neighborhood
of the provided input. In Adel et al. (2018) the authors introduce an additional latent space called
interpretable lens used to interpret the latent space of a generative model. This space shares simi-
larity with our latent space Z* and they also propose ajoint optimization for their model, where the
encoder-decoder architecture and the interpretable lens are learned jointly. The difference with our
approach is that the authors optimize an “interpretability” loss which requires labels and still need
to perform a posteriori analysis to find relevant directions in the latent space.
5	Conclusion an future work
We presented the Variation Network, a generative model able to vary attributes ofa given input. The
novelty is that these attributes can be fixed or learned and have a sound probabilistic interpretation.
Many sampling schemes have been presented together with a detailed discussion and examples. We
hope that the flexibility in the design of the attribute function and the simplicity, from an implemen-
tation point of view, in transforming existing encoder-decoder architectures (it suffices to provide
the encoder and decoder networks) will be of interest in many applications.
For future work, we would like to extend our approach in two different ways: being able to deal
with partially-given fixed attributes and handling discrete free attributes. We also want to investigate
the of use stochastic attribute functions φ. Indeed, it appeared to us that using deterministic attribute
functions was crucial and we would like to go deeper in the understanding of the interplay between
all VarNet components.
Acknowledgments
Omitted for double blind review.
References
Tameem Adel, Zoubin Ghahramani, and Adrian Weller. Discovering interpretable representations
for both deep generative and discriminative models. In Jennifer Dy and Andreas Krause (eds.),
8
Under review as a conference paper at ICLR 2019
Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceed-
ings of Machine Learning Research, pp. 50-59, Stockholmsmssan, Stockholm Sweden, 10-15
Jul 2018. PMLR. URL http://proceedings.mlr.press/v80/adel18a.html.
Alain Berlinet and Christine Thomas-Agnan. Reproducing kernel Hilbert spaces in probability and
statistics. Springer Science & Business Media, 2011.
C. P. Burgess, I. Higgins, A. Pal, L. Matthey, N. Watters, G. Desjardins, and A. Lerchner. Under-
standing disentangling in β-VAE. ArXiv e-prints, April 2018.
C.	Cao, D. Li, and I. Fair. Deep Learning-Based Decoding for Constrained Sequence Codes. ArXiv
e-prints, September 2018.
Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya
Sutskever, and Pieter Abbeel. Variational lossy autoencoder. CoRR, abs/1611.02731, 2016. URL
http://arxiv.org/abs/1611.02731.
V. Dumoulin, I. Belghazi, B. Poole, O. Mastropietro, A. Lamb, M. Arjovsky, and A. Courville.
Adversarially Learned Inference. ArXiv e-prints, June 2016.
Jesse Engel, Matthew Hoffman, and Adam Roberts. Latent constraints: Learning to gener-
ate conditionally from unconditional generative models. CoRR, abs/1711.05772, 2017. URL
http://arxiv.org/abs/1711.05772.
Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Scholkopf, and Alexander Smola.
A kernel two-sample test. Journal of Machine Learning Research, 13(Mar):723-773, 2012.
Gaetan Hadjeres, Frank Nielsen, and Francois Pachet. GLSR-VAE: geodesic latent space reg-
ularization for variational autoencoder architectures. CoRR, abs/1707.04588, 2017. URL
http://arxiv.org/abs/1707.04588.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. Beta-VAE: Learning basic visual concepts with a
constrained variational framework. 2016.
Chin-Wei Huang, David Krueger, Alexandre Lacoste, and Aaron C. Courville. Neural autoregressive
flows. CoRR, abs/1804.00779, 2018. URL http://arxiv.org/abs/1804.00779.
D.	P Kingma and M. Welling. Auto-encoding variational Bayes. ArXiv e-prints, December 2013.
Samuli Laine. Feature-based metrics for exploring the latent space of generative models, 2018. URL
https://openreview.net/forum?id=BJslDBkwG.
Guillaume Lample, Neil Zeghidour, Nicolas Usunier, Antoine Bordes, Ludovic Denoyer, and
Marc’Aurelio Ranzato. Fader networks: Manipulating images by sliding attributes. CoRR,
abs/1706.00409, 2017. URL http://arxiv.org/abs/1706.00409.
P. K. Rubenstein, B. Schoelkopf, and I. Tolstikhin. On the Latent Space of Wasserstein Auto-
Encoders. ArXiv e-prints, February 2018.
I. Tolstikhin, O. Bousquet, S. Gelly, and B. Schoelkopf. Wasserstein Auto-Encoders. ArXiv e-prints,
November 2017.
Paul Upchurch, Jacob Gardner, Kavita Bala, Robert Pless, Noah Snavely, and Kilian Weinberger.
Deep feature interpolation for image content changes. arXiv preprint arXiv:1611.05507, 2016.
Yuxuan Wang, Daisy Stanton, Yu Zhang, R. J. Skerry-Ryan, Eric Battenberg, Joel Shor, Ying Xiao,
Fei Ren, Ye Jia, and Rif A. Saurous. Style tokens: Unsupervised style modeling, control and
transfer in end-to-end speech synthesis. CoRR, abs/1803.09017, 2018. URL http://arxiv.
org/abs/1803.09017.
Tom White. Sampling generative networks: Notes on a few effective techniques. arXiv preprint
arXiv:1609.04468, 2016.
9
Under review as a conference paper at ICLR 2019
A Experiments
We now apply VarNet on MNIST in order to illustrate the different sampling schemes presented in
Sect. A.
In all these experiments, we choose to use a simple MLP with one hidden layer of size 400 for the
encoder and decoder networks. We present and comment results for different attribute functions and
different sampling schemes. The different attribute functions we considered are
•	1Free: one-dimensional free attribute space (Eq. (12) with dΨ = 1),
•	2Free: two-dimensional free attribute space (Eq. (12) with dΨ = 2),
•	1Free+1FixedLabel: one-dimensional free attribute space (Eq. (12) with dΨ = 1) concate-
nated with a fixed attribute which uses the labels of the digits (Eq. (15) with M = 10),
•	1Free+1FreeLabel: one-dimensional free attribute space (Eq. (12) with dΨ = 1) concate-
nated with a label-dependent free attribute of dimension 1 (Eq. (17) with M = 10 and
dψ = 1).
A.1 Unconstrained and constrained sampling schemes
We display in Figure 2 samples obtained with the sampling procedures Eq. (18) and Eq. (19) when
considering the 1Free+1FixedLabel attribute function. The results are in par with other probabilistic
generative models on this task like VAEs, CVAEs or WAEs.
6 3 5 *⅛
3 " O
4 4	3
/OS/
3工)3
f > ʃ K
Z《3 4
⅛ ʃ 6 5,
C 7 Q 3
∖ OrL)
28∕1y0 33oλ
q
(o
3
飞QGD
/ " 7
工5 4 O
6 3。/
3 ( 6 √
G S乡。
，夕49
q " 2
16 21
9 6"
(b)
odςj
O。〃 0。
6□3 A。
Odoaa
OOGaC
5。O。3
。。。〃。
(c)
(a)
1
3
6
Figure 2:	Different sampling schemes. Fig. 2a: sampling from the dataset distribution using Eq. (18)
using the 1Free+1FixedLabel attribute function. Fig. 2b: sampling elements with fixed attribute ψ
using Eq. (19) with the 1Free+1FixedLabel attribute function. Fig. 2c: same as Fig. 2b but using the
1Free attribute function. In Fig 2c and 2b, two sets of samples (top and bottom) corresponding to
two different values of ψ are shown.
00000000000000000000
∖ I I I I I I I I I ///////// /
ZZZZZNNZZZZZZZZNZZ22
33333333333333333333
HT3- YqtyvYly夕V夕夕夕夕夕夕夕
55555555555555555555
Ssggggggggggcg C，，
*1*7-777777777777777777
(a)	(b)
Figure 3:	Visualization of the spanned space of variations using two different inputs (shown in the
last row). The attribute function 1Free+1FixedLabel is used. The values of αi for the free attributes
(see Eq. (12)) increase linearly from 0 to 1.
A.2 Understanding free attributes
From Fig. 2b, we see that the fixed label attribute have clearly been taken into account, but it can be
hard to grasp which high-level attribute the free attribute function has captured. In order to visualize
10
Under review as a conference paper at ICLR 2019
a a a a
a a a a
a a a a
2 2 2 2
2 2 2 2
2 2 2 2
2 2 2 2
2 2 2 2
ZZZZ
Figure 4: Space of variations using
the 1Free+1FreeLabel attribute func-
tion. The free label-dependent attribute
varies along the y-axis while the free
(global) attribute varies along the x-
axis.
6
√
I
3
g
g
夕
/
7
I /to ■:r I 3 P- Xfo 7 / 7
6
√
I
3
y
夕
/
7
√
I
3
g
4
,
/
7
I 6 Ur I 30069 / 7
b
√
I
3
g
&
9
/
7
6
4
I
3
g
6
4
/
7
7
6
q
I
3
S
g
7
( 6 uf∕3pu-6 Q/
Y
I
3
g
6
7
I
7
6
I
3
g
7
I
7
√
I
3
F
6
夕
I
7
k>
4
I
3
W
C
?
I
7
6
√
I
3
8,
6
7
/
7
Figure 5: Sampling scheme Eq. (21) using the
1Free+1Label attribute function. Each row shows
samples obtained by sampling z* ~ q*(.∣x) for
a fixed random feature ψ. The original input is
shown on the last line.
6
7
6
this, we plot in Fig. 3 a visualization of the space of variations spanned by a given template latent
code z*. From these plots, it appears that the attribute vector encodes a notion of rotation meaningful
for this digit dataset and it is interesting to note how different templates produce different “writing
styles”. Free attributes can thus be particularly interesting for capturing high-level features, such
like rotation, that cannot be described in an absolute way or which are ill-defined.
By observing carefully Fig. 3, we note that the variations generated by varying the free attribute
applies to all digit classes, irrespective of their label. In such a case, it is impossible to obtain
different “writing conventions” for the same digit (like cursive/printscript style for the digit “2”) by
only modifying the attributes. We show in Fig. 4 that, by considering free label-dependent attributes,
we are able to smoothly go from one “writing convention” to the other one.
We can gain further insight about the notion of template and attribute using the sampling scheme
of Eq. (2l). This sampling exploits the Stochasticity of the encoder q*(∙∣x) in order to generate
variations of a given input x using a fixed attribute ψ . An example of such variations is given
in Fig. 5. The underlying idea is that, even for a given attribute ψ, there are multiple ways to
generate variations of x with attributes ψ. We believe that this stochasticity is essential since, in
many applications, there should not exist only one way to make variations.
The parametrization of the attribute function has a crucial effect on the high-level features that they
will able to capture. For instance, ifwe do not provide any label information, the information present
in the template and the information contained in the attribute function can differ drastically. Figure 6
show different space of variations where no label information is provided. The concepts captured in
these cases are then related to thinness/roundness. Our intuition is that the free attributes capture the
most general attributes of the dataset.
For some applications, variation spaces such as the one displayed in Fig. 6a, 6b or 6d are not de-
sirable because they may tend to move too “far away” from the original input. As discussed in
Sect. 3.1, it is possible to reduce how “spread” the spaces of variation are by modifying the β pa-
rameter multiplying the KL term in the objective Eq. (2). An example of such a variation space is
displayed in Fig. 6c.
From all examples above, we see that our architecture is indeed capable of decoupling templates
from learned attributes and that we have two ways of controlling the free attributes that are learned:
by modifying the KL term in the objective Eq. (2) and by carefully devising the attribute function.
Indeed, the learned free attributes can capture different high-level features depending on the other
fixed attributes they are coupled with.
11
Under review as a conference paper at ICLR 2019
06666666666666666666
OOO60G&&66SSSG$$$$55
&(o
G6GCG666
GcO(OGJJJJ
GCo(OGGGJJ
GGE66666
GGQGGJJ
GGGGGJGd
GGGGUj
G6666C66
邑6666CCC
GG&GG&GG
G66666CG
JgJGG j G
JgJGGG 一
6g66GGCC
64644446
64644444
54444444
SQaa44444
SqGGq牛牛4牛
GJJGQ牛斗，4
GSGeG，斗千午
6 4>S4∙4∙4* 斗牛中
444.4.4.4-÷^-φ
444.4.4.4-4-4-4-
444.4.4.4-4-^-4-
4 4 4 4» 4•邑 4* + 中
4444.4-4-4-÷^
44444.4-4-^f
44444∙4*4-l<F
444444-4-f^
444444-4-1 1
444444-4-1 I
4 4 4 4 4 4∙^/ I
4 4 4 4 4 4 J I I
4 4 4 4 — I I
4 4 4 4 4 JJJl
4 4 4 4 / / / / I
孑
4
4
4
吁
孑
g
g
1
1
1
a3a333J3333333333356
HeS33333333333333553
Oo00eee99l36655555533
a
B
3
3
3
3
3
ʃ
9
q
?
3
3
3
3
?
3
3
3
777
7 7 7
7 7 7
7 7 1
9
?
?
3
?
7
?
7
7
7
7
7
9
9
?
7
7
7
7
7
7
7
7
7
q
q
?
7
7
7
7
7
7
7
7
7
q
q
q
q
7
7
7
7
7
7
7
7
7
7
9
q
q
7
7
7
7
7
7
7
7
7
7
7
q
q
q
7
7
7
7
7
7
7
7
7
7
7
7
q
q
7
7
7
7
7
7
7
7
7
7
7
7
1
(c)
(d)
(a)
(b)
Figure 6: Figures 6a, 6b and 6c display the space of variations using the 2Free attribute function
for two different input. Fig. 6d display the space of variations using the 1Free attribute function.
Figure 6c was generated using a model trained with a low KL penalty (β = 0.1)
A.3 Moving in the latent space: beyond interpolations
VarNet proposes a novel solution to explore the latent spaces. Usual techniques to navigate in the
space of VAEs such as interpolations or the use of attribute vectors (distinct from what we called
attribute vectors in this work) are mostly intrinsically-based on moving using straight lines. This
assumes that the underlying geometry is euclidean, which is not the case, and forgets about the
probabilistic framework. Also, computing attribute vectors requires data with binary labels which
are not always available.
On the contrary, our approach grants a sound probabilistic interpretation of the attributes and the
variations they generate. Indeed, when the discriminator is fooled by the encoder-decoder archi-
tecture, the attributes are distributed according to ν which has a simple interpretation (it is the
push-forward of the να distribution which is considered to be a uniform distribution in all these
examples). Also, thinking about variations as a subspace of smaller dimension than the whole latent
space makes much sense for us.
Figure 7: Variation spaces (shown in Z) of a VarNet trained using the 1Free attribute function, for
different Z*. We plotted {z = fψ(z*)} for ψ = αιvι where αι ∈ [0.0,0.05,..., 0.95,1.0] and
random z*. Visualized using a 3D PCA in Z.
Figure 7 shows a visualization in the latent space Z of the variation spaces spanned by moving with
constant steps in the attribute space Ψ. Two key elements appear: constant steps in the attribute
space do not induce constant steps in the Z space and variation spaces are extremely diverse (they
are not translated versions of a unique variation space). For us, this advocates for the fact that
displacements in the latent spaces using straight lines have a priori no meaningful interpretation: the
same change of attributes for two different inputs can lead to radically different displacements in the
latent space. More generally, our proposition of parametrizing attribute-related displacements in a
latent space using flows conditioned on a simpler space is appealing from a conceptual point of view
since we do not mix, in the same latent space, its probabilistic interpretation given by the prior and
its ability to grant meaningful ways to vary attributes.
12