title,year,conference
 Adageo: Adaptive geometriclearning for optimization and sampling,2018, In International Conference on Artificial Intelligence andStatistics
 Life-long disentangled representation learning with cross-domainlatent homologies,2018, arXiv preprint arXiv:1808
 The Theory of Splines andTheir Applications,1967, Academic Press
 Natural gradient works efficiently in learning,1998, Neural computation
 Learning to learn by gradient descent by gradientdescent,2016, In Advances in Neural Information Processing Systems
 Latent Space Oddity: on the Curvatureof Deep Generative Models,2018, In International Conference on Learning Representations
 Learning a SynaptiC learning rule,1991, UniverSitede Montreal
 Model-Agnostic Meta-Learning for Fast Adaptationof Deep Networks,2017, In International Conference on Machine Learning
 Rich feature hierarchies for accurateobject detection and semantic segmentation,2014, In International Conference on Computer Vision andPattern Recognition
 An empiri-cal investigation of catastrophic forgetting in gradient-based neural networks,2013, arXiv preprintarXiv:1312
 Mask r-cnn,2017, In InternationalConference on Computer Vision
 Darla: Improving zero-shottransfer in reinforcement learning,2017, arXiv preprint arXiv:1707
 Adam: A Method for Stochastic Optimization,2015, In InternationalConference on Learning Representations
 Overcoming catastrophic forgetting inneural networks,2017, Proceedings of the National Academy of Sciences
 Improved Semi-supervised Learningwith GANs using Manifold Invariances,2017, In Advances in Neural Information Processing Systems
 One shot learning ofsimple visual concepts,2011, In Proceedings of the Annual Meeting of the Cognitive Science Society
 Human-level concept learningthrough probabilistic program induction,2015, Science
 Overcoming CatastrophicForgetting by Incremental Moment Matching,2017, In Advances in Neural Information ProcessingSystems
 Meta-Learning with Adaptive Layerwise Metric and Subspace,2018, InInternational Conference on Machine Learning
 SGDR: stochastic gradient descent with restarts,2017, In InternationalConference on Learning Representations
 A coordinate-free construction of scalable natural gradient,2018, arXivpreprint arXiv:1808
 Deep learning via hessian-free optimization,2010, In International Conference on MachineLearning
 Differentiable plasticity: training plastic neuralnetworks with backpropagation,2018, International Conference on Machine Learning
 A Simple Neural AttentiveMeta-Learner,2018, In International Conference on Learning Representations
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 On First-Order Meta-Learning Algorithms,2018, arXivpreprint ArXiv:1803
 Revisiting natural gradient for deep networks,2014, In InternationalConference on Learning Representations
 Optimization as a model for few-shot learning,2016, In InternationalConference on Learning Representations
 Progressive neural networks,2016, arXiv preprintarXiv:1606
 Meta-learning with memory-augmented neural networks,2016, In International Conference on MachineLearning
 Evolutionary principles in self-referential learning,1987, PhD thesis
 Overcoming catastrophicforgetting with hard attention to the task,2018, In International Conference on Machine Learning
 The Riemannian Geometry of Deep GenerativeModels,2017, arXiv preprint ArXiv:1711
 Prototypical Networks for Few-shot Learning,2017, InAdvances in Neural Information Processing Systems
 Reinforcement learning: An introduction,1998, MIT Press
 Metrics for ProbabilisticGeometries,2014, Conference on Uncertainty in Artificial Intelligence
 Match-ing Networks for One Shot Learning,2016, In Advances in Neural Information Processing Systems
 Understanding short-horizon bias instochastic meta-optimization,2018, In International Conference on Learning Representations
