Figure 1: Example illustration of train/validation/test data. The first row is “happiness” sentimentand the second row is “sadness” sentiment. The background and sentiment labels are correlated intraining and validation set, but independent in testing set.
Figure 2: Introduction of Neural Gray-level Co-occurrence Matrix (NGLCM) and HEX.
Figure 3: Averaged testing accuracy and standard deviation of five repeated experiments with dif-ferent correlation level on sentiment with nuisance background data. Notations: baseline CNN (B),Ablation Tests (M (replacing NGLCM with MLP) and N (training without HEX projection)), ADVE(E), ADV (A), HEX (H), HEX-ADV (V), HEX-ALL (L), DANN (G), and InfoDropout (I).
Figure 4: Averaged testing accuracy and standard deviation of five repeated experiments with differ-ent strategies of attaching patterns to MNIST data. Notations: baseline CNN (B), Ablation Tests (M(replacing NGLCM with MLP) and N (training without HEX projection)), ADVE (E), ADV (A),HEX (H), HEX-ADV (V), HEX-ALL (L), DANN (G), and InfoDropout (I).
Figure A1: A closer look of Office data set, we visualize the first 10 images of each data set. Weshow 12 labels out of 31 labels, but the story of the rest labels are similar to what we have shownhere. From the images, we can clearly see that many images of DSLR and Webcam share the similarbackground, while the images of Amazon have a distinct background. Top row: Amazon, middlerow: DSLR, bottom row: Webcam14Published as a conference paper at ICLR 2019——Baseline — Ablation	N — ADV	——HEX-ADV	—	DANNAblation	M —— ADVE	—— HEX	HEX ALL	—	InfoDrop(a) ρ = 0.0(g) ρ = 0.6(i) ρ = 0.8(j) ρ = 0.9Figure A2: Testing accuracy curve of the facial expression classification experiment.
Figure A2: Testing accuracy curve of the facial expression classification experiment.
Figure A3: Synthetic MNIST data sets with Fourier transform patterns. The leftmost image repre-sents the kernel.
