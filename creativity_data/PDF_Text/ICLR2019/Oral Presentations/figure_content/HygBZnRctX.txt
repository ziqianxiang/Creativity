Figure 1: Example of gradient paths on a manifold described by the loss surface. Leap learns aninitialization with shorter expected gradient path that improves performance.
Figure 2: Left: illustration of Leap (algorithm 1) for two tasks, τ and τ0. From an initialization θ0, thelearning process of each task generates gradient paths, Ψτ and Ψτ0 , which Leap uses to minimize theexpected path length. Iterating the process, Leap converges to a locally Pareto optimal initialization.
Figure 3: Results on Omniglot. Left: Comparison of average learning curves on held-out tasks (across10 seeds) for 25 tasks in the meta-training set. Curves are moving averages with window size 5.
Figure 4: Mean normalized episode scores on Atari games across training steps. Shaded regions depicttwo standard deviations across ten seeds. Leap (orange) generally outperforms a random initialization(blue), even when the action space is twice as large as during pretraining (table 6, appendix F).
Figure 5: Relative precision of Jacobian approximation. Precision is calculated for the Jacobian ofthe first layer, across different learning rates (colors) and gradient steps.
Figure 6:	Average task training loss over meta-training steps. P denotes the dp used in the metaobjective, μ = 1 the use of the stabilizer, and f = 1 the inclusion of the loss in the task manifold.
Figure 7:	Mean normalized episode scores on Atari games across training steps. Scores are reportedas moving average over 500 episodes. Shaded regions depict two standard deviations across tenseeds. KungFuMaster, RoadRunner and Krull have action state spaces that are twice as large as thelargest action state encountered during pretraining. Leap (orange) generally outperforms a randominitialization, except for WizardOfWor, where a random initialization does better on average due tooutlying runs under Leap’s initialization.
Figure 8: Mean episode scores on Atari games across training steps for different runs. Scores arereported as moving average over 500 episodes. Leap (orange) outperforms a random initialization bybeing less volatile.
