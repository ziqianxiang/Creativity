Figure 1: Illustration of the framework We used to model early visual representations. A: We trainedconvolutional neural networks on an image recognition task (CIEAR-10). The networks were com-posed of two parts, a retina-net and a ventral-visual-system-net (VVS-net), which receives inputfrom the retina-net. B: We varied the number of layers in the VVS-net (white boxes) and the numberof channels at the output of the retina-net (blue box). C: Key results: (1) A bottleneck at the output ofthe retina yielded center-surround retinal REs. (2) A shallow VVS-net yielded more nonlinear reti-nal responses (linearity is schematized by the red arrow), which better disentangled image classes(represented as bent manifolds). D: Test-set accuracy of all model architectures on CIEAR-10, av-eraged over ten networks with random initial weights for each architecture. Performance increaseswith VVS-net depth and retinal channel, indicating that both factors are meaningful constraints onthe network in the regime tested.
Figure 2: Effects of a bottleneck constraint on receptive fields (RFs). An results are shown forDVVS = 2. A: Examples of RFs of cells at selected layers (layers 2 and 3) of a control networkwith no bottleneck. No center-surround RFs appear. B: Center-surround RFs emerge at the output ofthe retina-net (layer 2) and oriented RFs emerge in the first layer of the VVS-net when We impose abottleneck constraint at the output of the retina (NBN = 1) C: Top: Hubel and Wiesel,s hypothesison oriented cell formation in V1 (Hubel, 1995). Bottom: A representative example of an orientation-selective neuron (bottom RF) drawing from center-surround channels (top RFs) in the previouslayer with weight matrices (center) according to their polarity. Light / dark-selective regions of areceptive field, and positive / negative weights, are represented with red / blue, respectively. D:Examples of RFs in a network with an extra bottleneck layer corresponding to mammalian LGN.
Figure 3: Emergent retinal representations are function of the depth of downstream visual cortices.
Figure 4: A: Left: Schematic re-illustrating the architecture of a vanilla (no bottleneck) network andshowing examples oriented RFs in its second layer. Center: Visualization of average RF isotropyfor cells in the second layer of a vanilla convolutional network (NBN = 1, DVVS = 2). Orangeerror bars indicate 95% confidence intervals. Right: Visualization of RF isotropy for ten exampleRFs from the same network architecture. B: Left: Schematic re-illustrating the architecture of theretina-net + VVS-net model (Nbn = 1, DVVS = 2) and showing example center-surround RFsat the retina-net output and oriented RFs in the following layer (V1). Center and right: Same RFisotropy visualizations as in part A. C: Left: re-illustration of V1 RFs pooling in oriented fashionfrom center-surround retinal RFs (Nbn = 1, DVVS = 2). Right: Same isotropy visualizations asin panel A carried on the weight matrix from retina to V1.
Figure 5: A: Visualizations of retina-net output RFs for an example network (Nbn = 1, Dvvs = 2)using different random initialization, as described in the text. B: Same as A, for the first layer of theVVS-net, and showing 5 of the layer's 32 channels on the X axis. C: Same as B, for the second layerof the VVS-net. In contrast to the first layer, the emergent preferred stimuli are always differentacross different initializations, indicative of a complex-cell like behavior.
Figure 6: Example RFs from the bottleneck network (NBN = 1, DVVS = 2without (A) and with (B) local response normalization (i.e. local gain control).
Figure 7: Linearity vs. Class separability for each retina-net output channels (i.e. bottleneck layer).
Figure 8: Class separability at all layers of network for a deep VVS-net (DVVS = 4) with andwithout bottleneck (Nbn = 1 and NBN = 32). Retinal representation of bottleneck network has lowseparability. However, the first layer of the VVS-net has high separability. We additionally plot theseparability of the linearized bottleneck (Nbn = 1) network (see test) as a function of layer. Thatthe jump in linear separability between layers 2,3 survives linearization suggests that the main effectof retinal processing in this network is whitening (see Fig. 9) rather than nonlinear processing.
Figure 9: Visualization of the output of the retina-net (one-channel-bottleneck, i.e. NBN =1) fordifferent images from the testing set (x-axis) as a function of VVS-net depth (y-axis). Each pixelintensity of the retinal image is proportional to the activation of the corresponding neuron of theretina, where light shades indicate high activities and dark shades low activities. While retinas forevery VVS-net depth appear to whiten the input, We can see that the retinal image is more and moreprocessed and less and less recognizable as VvS-net depth decreases.
