Figure 1: Wave2Midi2Wave system architecture for our suite of piano music models, consisting of(a) a conditional WaveNet model that generates audio from MIDI, (b) a Music Transformer languagemodel that generates piano performance MIDI autoregressively, and (c) a piano transcription modelthat “encodes” piano performance audio as MIDI.
Figure 2: Results of our listening tests, showing the number of times each source won in a pairwisecomparison. Black error bars indicate estimated standard deviation of means.
