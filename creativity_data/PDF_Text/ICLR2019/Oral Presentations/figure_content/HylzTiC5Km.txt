Figure 1:	A representation of Multidimensional Upscaling. Left: depth upscaling is applied to agenerated 3-bit 256 × 256 RGB subimage from CelebAHQ to map it to a full 8-bit 256 × 256 RGBimage. Right: size upscaling followed by depth upscaling are applied to a generated 3-bit 32 × 32RGB subimage from ImageNet to map it to the target resolution of the 8-bit 128 × 128 RGB image.
Figure 2:	The receptive field in a Subscale Pixel Networks (a) and the four image slices subsampledfrom the original image (b)perspective, we show the strong benefits of multidimensional upscaling as well as the benefits of theSPN. We produce CelebAHQ-256 samples (at full 8-bit resolution) that are of similar visual fidelity tothose produced with methods such as GANs that lack however an intrinsic measure of generalization(Mescheder, 2018; Karras et al., 2017). We also produce some of the first successful samples onunconditional ImageNet-128 (also at 8-bit) showing again the striking impact of the SPN and ofmultidimensional upscaling on sample quality and setting a fidelity baseline for future methods.
Figure 3: Different generation ordering schemes, where the numbers indicate the step-by-step order.
Figure 4: (a) The architecture of a S(au) bscale Pixel Network, with a conditional and(b)a decoding part.
Figure 5: Left: 8-bit 128x128 RGB ImageNet samples from SPN with depth upscaling only. Right:8-bit 128x128 RGB ImageNet samples from SPN with full-blown Multidimensional Upscaling.
Figure 6: 8-bit 256x256 RGB CelebA-HQ samPles from SPN with DePth-UPscaling. TemPerature is0.99 for the low-bit-dePth image and otherwise 1.010Published as a conference paper at ICLR 2019Figure 7: 256x256 CelebA-HQ 5bit samples from SPNAppendix BPlease see Table 4 for all the detailed hyperparameters.
Figure 7: 256x256 CelebA-HQ 5bit samples from SPNAppendix BPlease see Table 4 for all the detailed hyperparameters.
Figure 9: 256x256 CelebA-HQ 3bit samples from SPN with temperature 0.9513Published as a conference paper at ICLR 2019Figure 10: 128x128 ImageNet 3bit; upscaled 32x32 slicesFigure 11: 128x128 ImageNet 3bit samples from model trained on 32x32 slicesFigure 12: 128x128 ImageNet 3bit samples from SPN14Published as a conference paper at ICLR 2019	ImageNet (32, 64,128, 256)	CelebA HQOptimization		batch size	(1024, 2048, 2048, 2048)	256learning rate	(sched, sched, 1e-5, 1e-5)	5e-5rmsprop momentum	0.9	0.9rmsprop decay	0.95	0.95rmsprop epsilon	1e-8	1e-8polyak decay	0.9999	0.9999Decoder		PixelCNN layers	15	15PixelCNN conv channels	(256, 256, 384, 384)	128PixelCNN residual channels	1280	1280
Figure 10: 128x128 ImageNet 3bit; upscaled 32x32 slicesFigure 11: 128x128 ImageNet 3bit samples from model trained on 32x32 slicesFigure 12: 128x128 ImageNet 3bit samples from SPN14Published as a conference paper at ICLR 2019	ImageNet (32, 64,128, 256)	CelebA HQOptimization		batch size	(1024, 2048, 2048, 2048)	256learning rate	(sched, sched, 1e-5, 1e-5)	5e-5rmsprop momentum	0.9	0.9rmsprop decay	0.95	0.95rmsprop epsilon	1e-8	1e-8polyak decay	0.9999	0.9999Decoder		PixelCNN layers	15	15PixelCNN conv channels	(256, 256, 384, 384)	128PixelCNN residual channels	1280	1280PixelCNN nonlinearity	gated	gatedPixelCNN filter size	3	3masked self-attention layers	8	5
Figure 11: 128x128 ImageNet 3bit samples from model trained on 32x32 slicesFigure 12: 128x128 ImageNet 3bit samples from SPN14Published as a conference paper at ICLR 2019	ImageNet (32, 64,128, 256)	CelebA HQOptimization		batch size	(1024, 2048, 2048, 2048)	256learning rate	(sched, sched, 1e-5, 1e-5)	5e-5rmsprop momentum	0.9	0.9rmsprop decay	0.95	0.95rmsprop epsilon	1e-8	1e-8polyak decay	0.9999	0.9999Decoder		PixelCNN layers	15	15PixelCNN conv channels	(256, 256, 384, 384)	128PixelCNN residual channels	1280	1280PixelCNN nonlinearity	gated	gatedPixelCNN filter size	3	3masked self-attention layers	8	5attention heads	10	5
Figure 12: 128x128 ImageNet 3bit samples from SPN14Published as a conference paper at ICLR 2019	ImageNet (32, 64,128, 256)	CelebA HQOptimization		batch size	(1024, 2048, 2048, 2048)	256learning rate	(sched, sched, 1e-5, 1e-5)	5e-5rmsprop momentum	0.9	0.9rmsprop decay	0.95	0.95rmsprop epsilon	1e-8	1e-8polyak decay	0.9999	0.9999Decoder		PixelCNN layers	15	15PixelCNN conv channels	(256, 256, 384, 384)	128PixelCNN residual channels	1280	1280PixelCNN nonlinearity	gated	gatedPixelCNN filter size	3	3masked self-attention layers	8	5attention heads	10	5attention channels	128	128
