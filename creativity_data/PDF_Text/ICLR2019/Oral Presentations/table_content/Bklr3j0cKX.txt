Table 1: Classification accuracy (top 1) results on CIFAR10 and CIFAR100. DIM(L) (i.e., with thelocal-only objective) outperforms all other unsupervised methods presented by a wide margin. Inaddition, DIM(L) approaches or even surpasses a fully-supervised classifier with similar architecture.
Table 2: Classification accuracy (top 1) results on Tiny ImageNet and STL-10. For Tiny ImageNet,DIM with the local objective outperforms all other models presented by a large margin, and approachesaccuracy of a fully-supervised classifier similar to the Alexnet architecture used here.
Table 3: Comparisons of DIM with Contrastive Predictive Coding (CPC, Oord et al., 2018). Theseexperiments used a strided-crop architecture similar to the one used in Oord et al. (2018). ForCIFAR10 we used a ResNet-50 encoder, and for STL-10 we used the same architecture as for Table 2.
Table 4: Extended comparisons on CIFAR10. Linear classification results using SVM are over fiveruns. MS-SSIM is estimated by training a separate decoder using the fixed representation as input andminimizing the L2 loss with the original input. Mutual information estimates were done using MINEand the neural dependence measure (NDM) were trained using a discriminator between unshuffledand shuffled representations.
Table 5: Augmenting infoNCE DIM with additional structural information - adding coordinateprediction tasks or occluding input patches when computing the global feature vector in DIM canimprove the classification accuracy, particularly with the highly-compressed global features.
Table 6: Global DIM network architectureOperation	Size	ActivationInput → Linear layer	512	-ReLU-Linear layer	512	ReLULinear layer	1	We tested two different architectures for the local objective. The first (Figure 5) concatenated theglobal feature vector with the feature map at every location, i.e., {[Cψ(i)(x), Eψ(x)]}iM=×1 M. A 1 × 1convolutional discriminator is then used to score the (feature map, feature vector) pair,Tψ(i,)ω(x,y(x))=Dω([Cψ(i)(x),Eψ(x)]).	(11)Fake samples are generated by combining global feature vectors with local feature maps coming fromdifferent images, x0 :Tψ(i,)ω(x0,Eψ(x))=Dω([Cψ(i)(x0),Eψ(x)]).	(12)This architecture is featured in the results of Table 4, as well as the ablation and nearest-neighborstudies below. We used a 1 × 1 convnet with two 512-unit hidden layers as discriminator (Table 7).
Table 7: Local DIM Concat-and-convolve network architectureOperation	Size	ActivationInput → 1 × 1 conv	512	-ReLU-1 × 1conv	512	ReLU1 × 1conv	1	The other architecture we tested (Figure 6) is based on non-linearly embedding the global andlocal features in a (much) higher-dimensional space, and then computing pair-wise scores usingdot products between their high-dimensional embeddings. This enables efficient evaluation of alarge number of pair-wise scores, thus allowing us to use large numbers of positive/negative samples.
Table 8: Local DIM encoder-and-dot architecture for global featureOperation	Size	Activation	OutputInput → Linear Linear	2048 2048	-ReLU-	Output 1Input → Linear Output 1 + Output 2	2048	ReLU	Output 2We embed each local feature in the local feature map Cψ (x) using an architecture which matches theone for global feature embedding. We apply it via 1 × 1 convolutions. Details are in Table 9.
Table 9: Local DIM encoder-and-dot architecture for local featuresOperation	Size	Activation	OutputInput → 1 × 1conv 1 × 1 conv	2048 2048	-ReLU-	Output 1Input → 1 × 1 Conv Output 1 + Output 2 Block Layer Norm	2048	ReLU	Output 2Finally, the outputs of these two networks are combined by matrix multiplication, summing over thefeature dimension (2048 in the example above). As this is computed over a batch, this allows us toefficiently compute both positive and negative examples simultaneously. This architecture is featuredin our main classification results in Tables 1, 2, and 5.
Table 10: Prior matching network architectureOperation	Size	ActivationInput → Linear layer	1000	-ReLU-Linear layer	200	ReLULinear layer	1	Generative models For generative models, we used a similar setup as that found in Donahue et al.
Table 11: Generation scores on the Tiny Imagenet dataset for non-saturating GAN with contractivepenalty (NS-GAN-CP), Wasserstein GAN with gradient penalty (WGAN-GP) and our method. Ourencoder WaS penalized using CPModel	Inception score	FIDReal data	31.21 ± .68	4.03IE (ours)	7.41 ± .10	55.15NS-GAN-CP	8.65 ± .08	40.17WGAN-GP	8.38 ± 0.18	42.30A.9 Generation experiments and resultsFor the generator and encoder, We use a ResNet architecture (He et al., 2016) identical to the onefound in Gulrajani et al. (2017). We used the contractive penalty (found in Mescheder et al. (2018)but first introduced in contractive autoencoders (Rifai et al., 2011)) on the encoder, gradient clippingon the discriminators, and no regularization on the generator. Batch norm (Ioffe & Szegedy, 2015)Was used on the generator, but not on the discriminator. We trained on 64 × 64 dimensional LSUN (Yuet al., 2015), CelebA (Liu et al., 2015), and Tiny Imagenet dataset.
