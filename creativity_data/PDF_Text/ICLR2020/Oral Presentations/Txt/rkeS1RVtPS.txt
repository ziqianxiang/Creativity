Published as a conference paper at ICLR 2020
Cyclical Stochastic Gradient MCMC for
Bayesian Deep Learning
Ruqi Zhang
Cornell University
rz297@cornell.edu
Chunyuan Li
Microsoft Research, Redmond
chunyl@microsoft.com
Jianyi Zhang
Duke University
jz318@duke.edu
Changyou Chen
University at Buffalo, SUNY
changyou@buffalo.edu
Andrew Gordon Wilson
New York University
andrewgw@cims.nyu.edu
Ab stract
The posteriors over neural network weights are high dimensional and multimodal.
Each mode typically characterizes a meaningfully different representation of the
data. We develop Cyclical Stochastic Gradient MCMC (SG-MCMC) to auto-
matically explore such distributions. In particular, we propose a cyclical step-
size schedule, where larger steps discover new modes, and smaller steps charac-
terize each mode. We prove non-asymptotic convergence of our proposed algo-
rithm. Moreover, we provide extensive experimental results, including ImageNet,
to demonstrate the effectiveness of cyclical SG-MCMC in learning complex mul-
timodal distributions, especially for fully Bayesian inference with modern deep
neural networks.
1	Introduction
Deep neural networks are often trained with stochastic optimization methods such as stochastic gra-
dient decent (SGD) and its variants. Bayesian methods provide a principled alternative, which ac-
count for model uncertainty in weight space (MacKay, 1992; Neal, 1996), and achieve an automatic
balance between model complexity and data fitting. Indeed, Bayesian methods have been shown
to improve the generalization performance of DNNs (Hernandez-Lobato & Adams, 2015; BlUndell
et al., 2015; Li et al., 2016a; Maddox et al., 2019), while providing a principled representation of
Uncertainty on predictions which is crUcial for decision making.
Approximate inference for Bayesian deep learning has typically focUsed on deterministic ap-
proaches, such as variational methods (Hemandez-Lobato & Adams, 2015; Blundell et al., 2015).
By contrast, MCMC methods are now essentially UnUsed for inference with modern deep neUral
networks, despite previously providing the gold standard of performance with smaller neural net-
works (Neal, 1996). Stochastic gradient Markov Chain Monte Carlo (SG-MCMC) methods (Welling
& Teh, 2011; Chen et al., 2014; Ding et al., 2014; Li et al., 2016a) provide a promising direction for
a sampling based approach to inference in Bayesian deep learning. Indeed, it has been shown that
stochastic methods, which use mini-batches of data, are crucial for finding weight parameters that
provide good generalization in modern deep neural networks (Keskar et al., 2016).
However, SG-MCMC algorithms for inference with modern neural networks face several challenges:
(i) In theory, SG-MCMC asymptotically converges to target distributions via a decreasing stepsize
scheme, but suffers from a bounded estimation error in limited time (Teh et al., 2016; Chen et al.,
2015). (ii) In practice, empirical successes have been reported by training DNNs in relatively short
time (Li et al., 2016b; Chen et al., 2014; Gan et al., 2016; Neelakantan et al., 2016; Saatchi & Wilson,
2017). For example, Saatchi & Wilson (2017) apply SG-MCMC to generative adversarial networks
(GANs) to solve the mode collapse problem and capture diverse generation styles. However, the
loss surface for DNNs is highly multimodal (Auer et al., 1996; Choromanska et al., 2015). In order
for MCMC to be effective for posterior inference in modern neural networks, a crucial question
remains: how do we make SG-MCMC efficiently explore a highly multimodal parameter space
given a practical computational budget?
1
Published as a conference paper at ICLR 2020
Several attempts have been made to improve the sampling efficiency of SG-MCMC. Stochastic Gra-
dient Hamiltonian Monte Carlo (SGHMC) (Chen et al., 2014) introduces momentum to Langevin
dynamics. Preconditioned stochastic gradient Langevin dynamics (pSGLD) (Li et al., 2016a) adap-
tively adjusts the sampler’s step size according to the local geometry of parameter space. Though
simple and promising, these methods are still inefficient at exploring multimodal distributions in
practice. It is our contention that this limitation arises from difficulties escaping local modes when
using the small stepsizes that SG-MCMC methods typically require. Note that the stepsize in SG-
MCMC controls the sampler’s behavior in two ways: the magnitude to deterministically drift to-
wards high density regions wrt. the current stochastic gradient, and the level of injecting noise to
randomly explore the parameter space. Therefore, a small stepsize reduces both abilities, resulting
in a large numbers of iterations for the sampler to move across the modes.
In this paper, we propose to replace the
traditional decreasing stepsize schedule
in SG-MCMC with a cyclical variant.
To note the distinction from traditional
SG-MCMC, we refer to this method
as Cyclical SG-MCMC (cSG-MCMC).
The comparison is illustrated in Fig-
ure 1. The blue curve is the traditional
decay, while the red curve shows the
proposed cyclical schedule. Cyclical
SG-MCMC operates in two stages: (i)
Exploration: when the stepsize is large
(dashed red curves), we consider this
stage as an effective burn-in mechanism,
encouraging the sampler to take large
Figure 1: Illustration of the proposed cyclical stepsize
schedule (red) and the traditional decreasing stepsize
schedule (blue) for SG-MCMC algorithms.
moves and leave the local mode using the stochastic gradient. (ii) Sampling: when the stepsize
is small (solid red curves), the sampler explores one local mode. We collect samples for local
distribution estimation during this stage. Further, we propose two practical techniques to improve
estimation efficiency: (1) a system temperature for exploration and exploitation; (2) A weighted
combination scheme for samples collected in different cycles to reflect their relative importance.
This procedure can be viewed as SG-MCMC with warm restarts: the exploration stage provides
the warm restarts for its following sampling stage. cSG-MCMC combines the advantages from (1)
the traditional SG-MCMC to characterize the fine-scale local density of a distribution and (2) the
cyclical schedule in optimization to efficiently explore multimodal posterior distributions of the pa-
rameter space. In limited time, cSG-MCMC is a practical tool to provide significantly better mixing
than the traditional SG-MCMC for complex distributions. cSG-MCMC can also be considered as
an efficient approximation to parallel MCMC; cSG-MCMC can achieve similar performance to par-
allel MCMC with only a fraction of cost (reciprocal to the number of chains) that parallel MCMC
requires.
To support our proposal, we also prove the non-asymptotic convergence for the cyclical schedule.
We note that this is the first convergence analysis of a cyclical stepsize algorithm (including work in
optimization). Moreover, we provide extensive experimental results to demonstrate the advantages
of cSG-MCMC in sampling from multimodal distributions, including Bayesian neural networks and
uncertainty estimation on several large and challenging datasets such as ImageNet.
In short, cSG-MCMC provides a simple and automatic approach to inference in modern Bayesian
deep learning, with promising results, and theoretical support. This work is a step towards enabling
MCMC approaches in Bayesian deep learning. We release code at
https://github.com/ruqizhang/csgmcmc.
2	Preliminaries: SG-MCMC with a Decreasing Stepsize S chedule
SG-MCMC is a family of scalable sampling methods that enables inference with mini-batches of
data. For a dataset D = {di}，and a θ-parameterized model, We have the likelihood p(D∣θ) and
prior p(θ). The posterior distribution is p(θ∣D) 8 exp(-U(θ)) , where U(θ) is the potential energy
given by U(θ) = — logp(D∣θ) — logp(θ).
2
Published as a conference paper at ICLR 2020
When D is too large, it is expensive to evaluate U (θ) for all the data points at each iteration. In-
stead, SG-MCMC methods useaminibatch to approximate U(θ): U(θ) = 一N PN=Ilogp(x∕θ) -
log p(θ) , where N0 N is the size of minibatch. We recommend Ma et al. (2015) for a general
review of SG-MCMC algorithms. We describe two SG-MCMC algorithms considered in this paper.
SGLD & SGHMC Welling & Teh (2011) proposed Stochastic Gradient Langevin Dynamics
(SGLD), which uses stochastic gradients with Gaussian noise. Posterior samples are updated at
the k-th step as: θk = θk-ι 一 ak VU(θk) + √2αk∈k, where αk is the stepsize and e《has a standard
Gaussian distribution.
To improve mixing over SGLD, Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) (Chen
et al., 2014) introduces an auxiliary momentum variable v. SGHMC is built upon HMC, with an
additional friction term to counteract the noise introduced by a mini-batch. The update rule for
posterior samples is: θk = θ1 + vk-ι, and Vk = v— — αk VU(θk) — nvk-i + √2(η 一小心,
where 1 — η is the momentum term and Y is the estimate of the noise.
To guarantee asymptotic consistency with the true distribution, SG-MCMC requires that the step
sizes satisfy the following assumption:
Assumption 1. The step sizes {αk} are decreasing, i.e., 0 < αk+1 < αk, with 1)	k∞=1 αk = ∞;
and 2) Pk∞=1 α2k < ∞.
Without a decreasing step-size, the estimation error from numerical approximations is asymptoti-
cally biased. One typical decaying step-size schedule is αk = a(b + k)-γ, with γ ∈ (0.5, 1] and
(a, b) some positive constants (Welling & Teh, 2011).
3	Cyclical SG-MCMC
We now introduce our cyclical SG-MCMC (cSG-MCMC) algorithm. cSG-MCMC consists of two
stages: exploration and sampling. In the following, we first introduce the cyclical step-size schedule,
and then describe the exploration stage in Section 3.1 and the sampling stage in Section 3.2. We
propose an approach to combining samples for testing in Section F.
Assumption 1 guarantees the consistency of our estimation with the true distribution in the asymp-
totic time. The approximation error in limited time is characterized as the risk of an estimator
R = B2 +V , where B is the bias and V is the variance. In the case of infinite computation time, the
traditional SG-MCMC setting can reduce the bias and variance to zero. However, the time budget
is often limited in practice, and there is always a trade-off between bias and variance. We therefore
decrease the overall approximation error R by reducing the variance through obtaining more effec-
tive samples. The effective sample size can be increased if fewer correlated samples from different
distribution modes are collected.
For deep neural networks, the parameter space is highly multimodal. In practice, SG-MCMC with
the traditional decreasing stepsize schedule becomes trapped in a local mode, though injecting noise
may help the sampler to escape in the asymptotic regime (Zhang et al., 2017). Inspired to improve
the exploration of the multimodal posteriors for deep neural networks, with a simple and automatic
approach, we propose the cyclical cosine stepsize schedule for SG-MCMC. The stepsize at iteration
k is defined as:
αk
αo
^2^
π mod(k 一 1, dK/M e)
Cos (	∖kJMς∖	)+1∖,
(1)
where α0 is the initial stepsize, M is the number of cycles and K is the number of total iterations
(Loshchilov & Hutter, 2016; Huang et al., 2017).
The stepsize αk varies periodically with k. In each period, αk starts at α0, and gradually decreases
to 0. Within one period, SG-MCMC starts with a large stepsize, resulting in aggressive exploration
in the parameter space; as the stepsize is decreasing, SG-MCMC explores local regions. In the next
period, the Markov chain restarts with a large stepsize, encouraging the sampler to escape from the
current mode and explore a new area of the posterior.
Related work in optimization. In optimization, the cyclical cosine annealing stepsize schedule
has been demonstrated to be able to find diverse solutions in multimodal objectives, though not
3
Published as a conference paper at ICLR 2020
specifically different modes, using stochastic gradient methods (Loshchilov & Hutter, 2016; Huang
et al., 2017; Garipov et al., 2018; Fu et al., 2019). Alternatively, we adopt the technique to SG-
MCMC as an effective scheme for sampling from multimodal distributions.
3.1	Exploration
The first stage of cyclical SG-MCMC, exploration, discovers parameters near local modes of an
objective function. Unfortunately, it is undesirable to directly apply the cyclical schedule in op-
timization to SG-MCMC for collecting samples at every step. SG-MCMC often requires a small
stepsize in order to control the error induced by the noise from using a minibatch approximation.
If the stepsize is too large, the stationary distribution of SG-MCMC might be far away from the
true posterior distribution. To correct this error, it is possible to do stochastic Metropolis-Hastings
(MH) (Korattikara et al., 2014; Bardenet et al., 2014; Chen et al., 2016b). However, stochastic MH
correction is still computationally too expensive. Further, it is easy to get rejected with an aggressive
large stepsize, and every rejection is a waste of gradient computations.
To alleviate this problem, we propose to introduce a system temperature T to control the sampler’s
behaviour: p(θ∣D) 8 exp(-U(θ)∕T). Note that the setting T = 1 corresponds to sampling from
the untempered posterior. When T → 0, the posterior distribution becomes a point mass. Sam-
pling from limT →0 exp(-U (θ)∕T) is equivalent to minimizing U (θ); in this context, SG-MCMC
methods become stochastic gradient optimization methods.
One may increase the temperature T from 0 to 1 when the step-size is decreasing. We simply
consider T = 0 and perform optimization as the burn-in stage, when the completed proportion of a
mod (k-1,dK/M])
dK/Me
cycle r(k)
is smaller than a given threshold: r(k) < β. Note that β ∈ (0, 1)
balances the proportion of the exploration and sampling stages in cSG-MCMC.
3.2 Sampling
The sampling stage corresponds to T = 1
of the exploration stage. When r(k) > β
or step-sizes are sufficiently small, we ini-
tiate SG-MCMC updates and collect sam-
ples until this cycle ends.
Algorithm 1 Cyclical SG-MCMC.
SG-MCMC with Warm Restarts. One
may consider the exploration stage as au-
tomatically providing warm restarts for the
sampling stage. Exploration alleviates the
inefficient mixing and inability to traverse
the multimodal distributions of the tradi-
tional SG-MCMC methods. SG-MCMC
with warm restarts explores different parts
Input: The initial stepsize α0 , number of cycles M,
number of training iterations K and the proportion
of exploration stage β .
for k = 1:K do
a J ak according to Eq equation 1.
if mod dKMdK/Me) < β then
% Exploration stage
θ J θ - KUk (θ)
else
% Sampling stage
Collect samples using SG-MCMC methods
Output: Samples {θk}
of the posterior distribution and captures multiple modes in a single training procedure.
In summary, the proposed cyclical SG-MCMC repeats the two stages, with three key advantages: (i)
It restarts with a large stepsize at the beginning of a cycle which provides enough perturbation and
encourages the model to escape from the current mode. (ii) The stepsize decreases more quickly
inside one cycle than a traditional schedule, making the sampler better characterize the density of the
local regions. (iii) This cyclical stepsize shares the advantage of the “super-convergence” property
discussed in Smith & Topin (2017): cSG-MCMC can accelerate convergence for DNNs by up to an
order of magnitude.
Connection to the Santa algorithm. It is interesting to note that our approach inverts steps of
the Santa algorithm (Chen et al., 2016a) for optimization. Santa is a simulated-annealing-based
optimization algorithm with an exploration stage when T = 1, then gradually anneals T → 0 in a
refinement stage for global optimization. In contrast, our goal is to draw samples for multimodal
distributions, thus we explore with T = 0 and sample with T = 1. Another fundamental difference
is that Santa adopts the traditional stepsize decay, while we use the cyclical schedule.
We visually compare the difference between cyclical and traditional step size schedules (described
in Section 2) in Figure 1. The cyclical SG-MCMC algorithm is presented in Algorithm 1.
4
Published as a conference paper at ICLR 2020
Connection to Parallel MCMC. Running parallel Markov chains is a natural and effective way to
draw samples from multimodal distributions (VanDerwerken & Schmidler, 2013; Ahn et al., 2014).
However, the training cost increases linearly with the number of chains. Cyclical SG-MCMC can be
seen as an efficient way to approximate parallel MCMC. Each cycle effectively estimates a different
region of posterior. Note cyclical SG-MCMC runs along a single training pass. Therefore, its
computational cost is the same as single chain SG-MCMC while significantly less than parallel
MCMC.
Combining Samples. In cyclical SG-MCMC, we obtain samples from multiple modes of a poste-
rior distribution by running the cyclical step size schedule for many periods. We provide a sampling
combination scheme to effectively use the collected samples in Section F in the appendix.
4 Theoretical Analysis
Our algorithm is based on the SDE characterizing the LangeVin dynamics: dθt = -VU(θt)dt +
√2dWt , where Wt ∈ Rd is a d-dimensional Brownian motion. In this section, We prove non-
asymptotic conVergence rates for the proposed cSG-MCMC framework with a cyclical stepsize se-
quence {αk} defined in equation 1. For simplicity, we do not consider the exploration stage in the
analysis as that corresponds to stochastic optimization. Generally, there are two different ways to
describe the convergence behaviours of SG-MCMC. One characterizes the sample average over a
particular test function (e.g., Chen et al. (2015); Vollmer et al. (2016)); the other is in terms of the
Wasserstein distance (e.g., Raginsky et al. (2017); Xu et al. (2017)). We study both in the following.
Weak convergence Following Chen et al. (2015) and Vollmer et al. (2016), we define the posterior
average of an ergodic SDE as: φ，JX φ(θ)ρ(θ)dθ for some test function φ(θ) of interest. For the
corresponding algorithm with generated samples (θk)3i, We use the sample average φ defined as
φ= Kk PK=I φ(θk) to approximate φ. We prove weak convergence of CSGLD in terms of bias and
MSE, as stated in Theorem 1.
Theorem 1. Under Assumptions 2 in the appendix, for a smooth test function φ, the bias and MSE
of cSGLD are bounded as:
(2)
Convergence under the Wasserstein distance Next, we consider the more general case of SGLD
and characterize convergence rates in terms of a stronger metric of 2-Wasserstein distance, defined
as:
W22(μ, V) := inf|^ Q kθ - θ0k2dγ(θ,θ0) : Y ∈ Γ(μ, V)
where Γ(μ, V) is the set ofjoint distributions over (θ, θ0) such that the two marginals equal μ and V,
respectively.
Denote the distribution ofθt in the SDE as Vt. According to Chiang & Hwang (1987), the stationary
distribution ν∞ matches our target distribution. Let μκ be the distribution of the sample from
our proposed cSGLD algorithm at the K-th iteration. Our goal is to derive a convergence bound
on W2(μκ,ν∞). We adopt standard assumptions as in most existing work, which are detailed in
Assumption 3 in the appendix. Theorem 2 summarizes our main theoretical result.
Theorem 2. Under Assumption 3 in the appendix, there exist constants (C0, C1, C2, C3) indepen-
dent of the stepsizes such that the convergence rate of our proposed cSGLD with cyclical stepsize
Sequence equation 1 is bounded for all K satisfying (K mod M =0), as W2(μκ, ν∞) ≤
κ / Kao.	C2	C2Kα0 ∖ 2 J 3 3a0K	「Ka°、i	/ 3α2K	「Ka。、一
C3exp(-	0)+ 6+ 2	0	[(CιY	+ σC0	0)2 + (Cι~0	+ σCo	0)4].
2C4	2	8	2	16	4
Particularly, if we further assume	a。=O(K-β)	for	∀β	> 1,	W2(μκ,	ν∞)	≤	C3	+
1
(6+ K⅛)2 [(I + K-)2 + (KeH + κC-ι)1 ]∙
5
Published as a conference paper at ICLR 2020
Figure 3: Results of cSG-MCMC with DNNs on the CIFAR-100 dataset. (a) MDS visualization in
weight space: cSG-MCMC show larger distance than traditional schedules. (b) Testing errors (%)
on the path of two samples: cSG-MCMC shows more varied performance. (c) Testing errors (%) as
a function of the number of cycles M : cSGLD yields consistently lower errors.
Remark 1. i) The bound is decomposed into two parts: the first part measures convergence speed
of exact solution to the stationary distribution, i.e., νP αk to ν∞; the second part measures the
numerical error, i.e., between μκ and VPk .七.ii) The overall bound offers a same order of depen-
dency on K as in standard SGLD (please see the bound for SGLD in Section E of the appendix. See
also Raginsky et al. (2017)). iii) If one imposes stricter assumptions such as in the convex case, the
bound can be further improved. Specific bounds are derived in the appendix. We did not consider
this case due to the discrepancy from real applications.
5 Experiments
We demonstrate cSG-MCMC on several tasks, including a synthetic multimodal distribution (Sec-
tion 5.1), image classification on Bayesian neural networks (Section 5.2) and uncertainty estimation
in Section 5.3. We also demonstrate cSG-MCMC can improve the estimate efficiency for uni-modal
distributions using Bayesian logistic regression in Section A.2 in the appendix. We choose SLGD
and SGHMC as the representative baseline algorithms. Their cyclical counterpart are called cSGLD
and cSGHMC, respectively.
5.1	Synthetic multimodal data
We first demonstrate the ability of cSG-MCMC
for sampling from a multi-modal distribution
on a 2D mixture of 25 Gaussians. Specifi-
cally, we compare cSGLD with SGLD in two
setting: (1) parallel running with 4 chains and
(2) running with a single chain, respectively.
Each chain runs for 50k iterations. The step-
Size schedule of SGLD is αk a 0.05k-0.55. In
•	∙ ∙ ∙ ∙
OOOOO
•	•❹∙ ∙
……∙
(a) Target
• ∙ ∙
・ ∙ ∙
(b) SGLD (C) CSGLD
cSGLD, we set M = 30 and the initial step-
size α0 = 0.09. The proportion of exploration
stage β = 4. Fig 2 shows the estimated density
using sampling results for SGLD and CSGLD
in the parallel setting. We observed that SGLD
gets trapped in the loCal modes, depending on
the initial position. In any praCtiCal time period,
Figure 2: Sampling from a mixture of 25 Gaus-
sians shown in (a) for the parallel setting. With
a budget of 50k × 4 = 200k samples, traditional
SGLD in (b) has only disCovered 4 of the 25
modes, while our CSGLD in (C) has fully explored
the distribution.
SGLD Could only CharaCterize partial distribution. In Contrast, CSGLD is able to find and CharaCter-
ize all modes, regardless of the initial position. CSGLD leverages large step sizes to disCover a new
mode, and small step sizes to explore loCal modes. This result suggests CSGLD Can be a signifiCantly
favourable ChoiCe in the non-asymptotiC setting, for example only 50k iterations in this Case. The
single Chain results and the quantitative results on mode Coverage are reported in SeCtion A.1 of the
appendix.
5.2	Bayesian Neural Networks
We demonstrate the effeCtiveness of CSG-MCMC on Bayesian neural networks for ClassifiCation on
CIFAR-10 and CIFAR-100. We Compare with (i) traditional SG-MCMC; (ii) traditional stoChastiC
optimization methods, inCluding stoChastiC gradient desCent (SGD) and stoChastiC gradient desCent
6
Published as a conference paper at ICLR 2020
with momentum (SGDM); and (iii) Snapshot: a stochastic optimization ensemble method method
with a the cyclical stepsize schedule (Huang et al., 2017). We use a ResNet-18 (He et al., 2016) and
run all algorithms for 200 epochs. We report the test errors averaged over 3 runs, and the standard
error (±) from the mean predictor.
We set M = 4 and α0 = 0.5 for cSGLD, cSGHMC and Snapshot. The proportion hyper-parameter
β =0.8 and 0.94 for CIFAR-10 and CIFAR-100, respectively. We collect 3 samples per cycle. In
practice, we found that the collected samples share similarly high likelihood for DNNs, thus one
may simply set the normalizing term wi in equation 33 to be the same for faster testing.
We found that tempering helps improve performance for Bayesian inference with neural networks.
Tempering for SG-MCMC was first used by Li et al. (2016a) as a practical technique for neural
network training for fast convergence in limited time1. We simply use the prescribed temperature
of Li et al. (2016a) without tuning, but better results of the sampling methods can be achieved by
tuning the temperature. More details are in Appendix J. We hypothesize that tempering helps due to
the overparametrization of neural networks. Tempering enables one to leverage the inductive biases
of the network, while representing the belief that the model capacity can be misspecified. In work
on Safe Bayes, also known as generalized and fractional Bayesian inference, tempered posteriors
are well-known to help under misspecification (e.g., Barron & Cover, 1991; de Heide et al., 2019;
Grunwald et al., 2017).
For the traditional SG-MCMC methods, we found that noise injection early in training hurts con-
vergence. To make these baselines as competitive as possible, we thus avoid noise injection for the
first 150 epochs of training (corresponding to the zero temperature limit of SGLD and SGHMC),
and resume SGMCMC as usual (with noise) for the last 50 epochs. This scheme is similar to the
exploration and sampling stages within one cycle of cSG-MCMC. We collect 20 samples for the
MCMC methods and average their predictions in testing.
Testing Performance for Image Classification		CIFAR-10	CIFAR-100
We report the testing errors in Table 1 to com-	SGD	5.29±0.15	23.61±0.09
pare with the non-parallel algorithms. Snapshot	SGDM	5.17±0.09	22.98±0.27
and traditional SG-MCMC reduce the testing er-	Snapshot-SGD	4.46±0.04	20.83±0.01
rors on both datasets. Performance variance for	Snapshot-SGDM	4.39±0.01	20.81±0.10
these methods is also relatively small, due to	SGLD	5.20±0.06	23.23±0.01
the multiple networks in the Bayesian model av-	cSGLD	4.29±0.06	20.55±0.06
erage. Further, cSG-MCMC significantly out-	SGHMC	4.93±O1	22.60±0.17
performs Snapshot ensembles and the traditional	CSGHMC	4.27±0.03	20.50±0.11
SG-MCMC, demonstrating the importance of (1)			
capturing diverse modes compared to traditional	Table 1: Comparison of test error (%) between		
SG-MCMC, and (2) capturing fine-scale charac-	cSG-MCMC with non-parallel algorithms. cS-		
teristics of the distribution compared with Snap-	GLD and cSGHMC yields lower errors than		
shot ensembles.	their optimization counterparts, respectively.		
Diversity in Weight Space. To further demonstrate our hypothesis that with a limited budget cSG-
MCMC can find diverse modes, while traditional SG-MCMC cannot, we visualize the 12 samples
we collect from cSG-MCMC and SG-MCMC on CIFAR-100 respectively using Multidimensional
Scaling (MDS) in Figure 3 (a). MDS uses a Euclidean distance metric between the weight of sam-
ples. We see that the samples of cSG-MCMC form 4 clusters, which means they are from 4 different
modes in weight space. However, all samples from SG-MCMC only form one cluster, which indi-
cates traditional SG-MCMC gets trapped in one mode and only samples from that mode.
Diversity in Prediction. To further demonstrate the samples from different cycles of cSG-MCMC
provide diverse predictions we choose one sample from each cycle and linearly interpolate between
two of them (Goodfellow et al., 2014; Huang et al., 2017). Specifically, let J(θ) be the test error of
a sample with parameter θ. We compute the test error of the convex combination of two samples
J(λθ1 + (1 - λ)θ2), where λ ∈ [0, 1].
We linearly interpolate between two samples from neighboring chains of cSG-MCMC since they
are the most likely to be similar. We randomly select 4 samples from SG-MCMC. If the samples
are from the same mode, the test error of the linear interpolation of parameters will be relatively
1https://github.com/ChunyuanLI/pSGLD/issues/2
7
Published as a conference paper at ICLR 2020
Method	Cyclical+Parallel		DecreaSing+Parallel		DecreaSing+Parallel		Cyclical+Single	
Cost	200/800		200/800		100/400		200/200	
Sampler	SGLD	SGHMC	SGLD	SGHMC	SGLD	SGHMC	SGLD	SGHMC
CIFAR-10	4.09	3.95	4^i5	-^4.09	ɜn^^	-^452	4.29	4.27
CIFAR-100	19.37	19.19	20.29	19.72	21.16	20.82	20.55	20.50
Table 2: Comparison of test error (%) between cSG-MCMC with parallel algorithm (M=4 chains)
on CIFAR-10 and CIFAR-100. The method is reported in the format of “step-size schedule (cyclical
or decreasing) + single/parallel chain”. The cost is reported in the format of “#epoch per chain /
#epoch used in all chains”. Note that a parallel algorithm with a single chain reduces to a non-
parallel algorithm. Integration of the cyclical schedule with parallel algorithms provides lower test-
ing errors.
smooth, while if the samples are from different modes, the test error of the parameter interpolation
will have a spike when λ is between 0 and 1.
We show the results of interpolation for cSG-MCMC and SG-MCMC on CIFAR-100 in Figure 3
(b). We see a spike in the test error in each linear interpolation of parameters between two samples
from neighboring chains in cSG-MCMC while the linear interpolation for samples of SG-MCMC is
smooth. This result suggests that samples of cSG-MCMC from different chains are from different
modes while samples of SG-MCMC are from the same mode.
Although the test error of a single sample of cSG-MCMC is worse than that of SG-MCMC shown
in Figure 3 (c), the ensemble of these samples significantly improves the test error, indicating that
samples from different modes provide different predictions and make mistakes on different data
points. Thus these diverse samples can complement each other, resulting in a lower test error, and
demonstrating the advantage of exploring diverse modes using cSG-MCMC.
Comparison to Parallel MCMC. cSG-MCMC can be viewed as an economical alternative to
parallel MCMC. We verify how closely cSG-MCMC can approximate the performance of parallel
MCMC, but with more convenience and less computational expense. We also note that we can
improve parallel MCMC with the proposed cyclical stepsize schedule.
We report the testing errors in Table 2 to compare multiple-chain results. (1) Four chains used,
each runs 200 epochs (800 epochs in total), the results are shown in the first 4 columns (Cycli-
cal+Parallel vs Decreasing+Parallel). We see that cSG-MCMC variants provide lower errors than
plain SG-MCMC. (2) We reduce the number of epochs (#epoch) of parallel MCMC to 100 epoch
each for decreasing stepsize schedule. The total cost is 400 epochs. We compare its performance
with cyclical single chain (200 epochs in total) in the last 4 columns (Decreasing+Parallel vs Cycli-
cal+Single). We see that the cyclical schedule running on a single chain performs best even with half
the computational cost! All the results indicate the importance of warm re-starts using the proposed
cyclical schedule. For a given total cost budget, the proposed cSGMCMC is preferable to parallel
sampling.
Comparison to Snapshot Optimization. We carefully compared with Snapshot, as our cSG-
MCMC can be viewed as the sampling counterpart of the Snapshot optimization method. We plot
the test error wrt.various number of cycles M in Fig. 3. As M increases, cSG-MCMC and Snapshot
both improve. However, given a fixed M, cSG-MCMC yields substantially lower test errors than
Snapshot. This result is due to the ability of cSG-MCMC to better characterize the local distribution
of modes: Snapshot provides a singe minimum per cycle, while cSG-MCMC fully exploits the mode
with more samples, which could provide weight uncertainty estimate and avoid over-fitting.
Results on ImageNet. We further study dif-
ferent learning algorithms on a large-scale
dataset, ImageNet. ResNet-50 is used as the ar-
chitecture, and 120 epochs for each run. The
results on the testing set are summarized in Ta-
ble 3, including NLL, Top1 and Top5 accuracy
(%), respectively. 3 cycles are considered for
both cSGHMC and Snapshot, and we collect 3
samples per cycle. We see that cSGHMC yields
the lowest testing NLL, indicating that the cy-
	NLL ；	Top1 ↑	Top5 ↑
SGDM	0.9595	76.046	92.776
Snapshot-SGDM	0.8941	77.142	93.344
SGHMC	0.9308	76.274	92.994
cSGHMC	0.8882	77.114	93.524
Table 3: Comparison on the testing set of Ima-
geNet. cSGHMC yields lower testing NLL than
Snapshot and SGHMC.
8
Published as a conference paper at ICLR 2020
cle schedule is an effective technique to explore the parameter space, and diversified samples can
help prevent over-fitting.
5.3	Uncertainty Evaluation
To demonstrate how predictive uncertainty ben-
efits from exploring multiple modes in the pos-
terior of neural network weights, we consider
the task of uncertainty estimation for out-of-
distribution samples (Lakshminarayanan et al.,
2017). We train a three-layer MLP model on the
standard MNIST train dataset until convergence
using different algorithms, and estimate the en-
tropy of the predictive distribution on the notM-
NIST dataset (Bulatov, 2011). Since the samples
from the notMNIST dataset belong to the unseen
classes, ideally the predictive distribution of the
trained model should be uniform over the notM-
NIST digits, which gives the maximum entropy.
In Figure 4, we plot the empirical CDF for the
entropy of the predictive distributions on notM-
NIST. We see that the uncertainty estimates from
cSGHMC and cSGLD are better than the other
Entropy
Figure 4: Empirical CDF for the entropy of
the predictive distribution on notMNIST dataset.
cSGLD and cSGHMC show lower probability
for the low entropy estimate than other algo-
rithms.
methods, since the probability of a low entropy prediction is overall lower. cSG-MCMC algorithms
explore more modes in the weight space, each mode characterizes a meaningfully different represen-
tation of MNIST data. When testing on the out-of-distribution dataset (notMNIST), each mode can
provide different predictions over the label space, leading to more reasonable uncertainty estimates.
Snapshot achieves less entropy than cSG-MCMC, since it represents each mode with a single point.
The traditional SG-MCMC methods also provide better uncertainty estimation compared to their
optimization counterparts, because they characterize a local region of the parameter space, rather
than a single point. cSG-MCMC can be regarded as a combination of these two worlds: a wide
coverage of many modes in Snapshot, and fine-scale characterization of local regions in SG-MCMC.
6 Discussion
We have proposed cyclical SG-MCMC methods to automatically explore complex multimodal dis-
tributions. Our approach is particularly compelling for Bayesian deep learning, which involves rich
multimodal parameter posteriors corresponding to meaningfully different representations. We have
also shown that our cyclical methods explore unimodal distributions more efficiently. These results
are in accordance with theory we developed to show that cyclical SG-MCMC will converge faster to
samples from a stationary distribution in general settings. Moreover, we show cyclical SG-MCMC
methods provide more accurate uncertainty estimation, by capturing more diversity in the hypothesis
space corresponding to settings of model parameters.
While MCMC was once the gold standard for inference with neural networks, it is now rarely used
in modern deep learning. We hope that this paper will help renew interest in MCMC for posterior
inference in deep learning. Indeed, MCMC is uniquely positioned to explore the rich multimodal
posterior distributions of modern neural networks, which can lead to improved accuracy, reliability,
and uncertainty representation.
Acknowledgements
AGW was supported by an Amazon Research Award, Facebook Research, NSF I-DISRE 193471,
NIH R01 DA048764-01A1, NSF IIS-1563887, and NSF IIS-1910266.
References
Sungjin Ahn, Babak Shahbaba, and Max Welling. Distributed stochastic gradient MCMC. In ICML,
2014.
9
Published as a conference paper at ICLR 2020
Peter Auer, Mark Herbster, and Manfred K Warmuth. Exponentially many local minima for single
neurons. In NIPS, 1996.
Remi Bardenet, Arnaud Doucet, and Chris Holmes. Towards scaling UP Markov Chain Monte Carlo:
an adaptive subsampling approach. In ICML, 2014.
Andrew R Barron and Thomas M Cover. Minimum comPlexity density estimation. IEEE transac-
tions on information theory, 37(4):1034-1054, 1991.
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in
neural networks. ICML, 2015.
Francois Bolley and Cedric Villani. Weighted CSiSzar-kullback-pinsker inequalities and applications
to transportation inequalities. In Annales de la FacuIte des sciences de Toulouse. UniverSite Paul
Sabatier, 2005.
Yaroslav Bulatov. Not MNIST Dataset. 2011. http://yaroslavvb.blogspot.com/
2011/09/notmnist-dataset.html.
Changyou Chen, Nan Ding, and Lawrence Carin. On the convergence of stochastic gradient MCMC
algorithms with high-order integrators. In NIPS, 2015.
Changyou Chen, David Carlson, Zhe Gan, Chunyuan Li, and Lawrence Carin. Bridging the gap
between stochastic gradient MCMC and stochastic optimization. In Artificial Intelligence and
Statistics, 2016a.
Changyou Chen, Ruiyi Zhang, Wenlin Wang, Bai Li, and Liqun Chen. A unified particle-
optimization framework for scalable bayesian sampling. arXiv preprint arXiv:1805.11659, 2018.
Haoyu Chen, Daniel Seita, Xinlei Pan, and John Canny. An efficient minibatch acceptance test for
Metropolis-Hastings. arXiv preprint arXiv:1610.06848, 2016b.
Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient Hamiltonian Monte Carlo. In
ICML, 2014.
Tzuu-Shuh Chiang and Chii-Ruey Hwang. Diffusion for global optimization in rn. SIAM J. Control
Optim., pp. 737-753, 1987. ISSN 0363-0129. doi: 10.1137/0325042. URL http://dx.doi.
org/10.1137/0325042.
Anna Choromanska, Mikael Henaff, Michael Mathieu, Gerard Ben Arous, and Yann LeCun. The
loss surfaces of multilayer networks. In Artificial Intelligence and Statistics, 2015.
Arnak S. Dalalyan and Avetik Karagulyan. User-friendly guarantees for the langevin monte carlo
with inaccurate gradient. Stochastic Processes and their Applications, 2019. ISSN 0304-4149.
doi: https://doi.org/10.1016/j.spa.2019.02.016. URL http://www.sciencedirect.com/
science/article/pii/S0304414918304824.
Rianne de Heide, Alisa Kirichenko, Nishant Mehta, and Peter Grunwald. Safe-bayesian generalized
linear regression. arXiv preprint arXiv:1910.09227, 2019.
Nan Ding, Youhan Fang, Ryan Babbush, Changyou Chen, Robert D Skeel, and Hartmut Neven.
Bayesian sampling using stochastic gradient thermostats. In NIPS, 2014.
Meire Fortunato, Charles Blundell, and Oriol Vinyals. Bayesian recurrent neural networks. arXiv
preprint arXiv:1704.02798, 2017.
Hao Fu, Chunyuan Li, Xiaodong Liu, Jianfeng Gao, Asli Celikyilmaz, and Lawrence Carin. Cyclical
annealing schedule: A simple approach to mitigating KL vanishing. NAACL, 2019.
Zhe Gan, Chunyuan Li, Changyou Chen, Yunchen Pu, Qinliang Su, and Lawrence Carin. Scalable
Bayesian learning of recurrent neural networks for language modeling. ACL, 2016.
Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry P Vetrov, and Andrew G Wilson. Loss
surfaces, mode connectivity, and fast ensembling of DNNs. In Advances in Neural Information
Processing Systems, pp. 8789-8798, 2018.
10
Published as a conference paper at ICLR 2020
Ian J Goodfellow, Oriol Vinyals, and Andrew M Saxe. Qualitatively characterizing neural network
optimization problems. arXiv preprint arXiv:1412.6544, 2014.
Peter J Green. Reversible jump MCMC computation and bayesian model determination. Biometrika,
82(4):711-732,1995.
Peter Grunwald, Thijs Van Ommen, et al. Inconsistency ofbayesian inference for misspecified linear
models, and a proposal for repairing it. Bayesian Analysis, 12(4):1069-1103, 2017.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In CVPR, 2016.
JoSe Miguel Hernandez-Lobato and Ryan Adams. Probabilistic backpropagation for scalable learn-
ing of Bayesian neural networks. In ICML, 2015.
Matthew D Hoffman and Andrew Gelman. The no-u-turn sampler: adaptively setting path lengths
in hamiltonian monte carlo. Journal of Machine Learning Research, 15(1):1593-1623, 2014.
Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E Hopcroft, and Kilian Q Weinberger.
Snapshot ensembles: Train 1, get m for free. ICLR, 2017.
Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Pe-
ter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. arXiv
preprint arXiv:1609.04836, 2016.
Anoop Korattikara, Yutian Chen, and Max Welling. Austerity in MCMC land: Cutting the
Metropolis-Hastings budget. In ICML, 2014.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive
uncertainty estimation using deep ensembles. In NIPS, 2017.
Chunyuan Li, Changyou Chen, David E Carlson, and Lawrence Carin. Preconditioned stochastic
gradient Langevin dynamics for deep neural networks. In AAAI, 2016a.
Chunyuan Li, Andrew Stevens, Changyou Chen, Yunchen Pu, Zhe Gan, and Lawrence Carin. Learn-
ing weight uncertainty with stochastic gradient MCMC for shape classification. In CVPR, 2016b.
Chang Liu, Jingwei Zhuo, and Jun Zhu. Understanding mcmc dynamics as flows on the wasserstein
space. arXiv preprint arXiv:1902.00282, 2019.
Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. 2016.
Yi-An Ma, Tianqi Chen, and Emily Fox. A complete recipe for stochastic gradient MCMC. In
NIPS, 2015.
David JC MacKay. A practical bayesian framework for backpropagation networks. Neural compu-
tation, 1992.
Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon Wilson.
A simple baseline for bayesian uncertainty in deep learning. In Advances in Neural Information
Processing Systems, pp. 13132-13143, 2019.
J. C. Mattingly, A. M. Stuart, and M. V. Tretyakov. Construction of numerical time-average and
stationary measures via Poisson equations. SIAM J. NUMER. ANAL., 48(2):552-577, 2010.
Radford M Neal. Bayesian learning for neural networks. New York: Springer-Verlag, 1996.
Arvind Neelakantan, Luke Vilnis, Quoc V Le, Ilya Sutskever, Lukasz Kaiser, Karol Kurach, and
James Martens. Adding gradient noise improves learning for very deep networks. ICLR workship,
2016.
Anh Nguyen, Jeff Clune, Yoshua Bengio, Alexey Dosovitskiy, and Jason Yosinski. Plug & play
generative networks: Conditional iterative generation of images in latent space. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4467-4477, 2017.
11
Published as a conference paper at ICLR 2020
Adrian E Raftery, Michael A Newton, Jaya M Satagopan, and Pavel N Krivitsky. Estimating the
integrated likelihood via posterior simulation using the harmonic mean identity. 2006.
Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky. Non-convex learning via stochastic
gradient Langevin dynamics: a nonasymptotic analysis. arXiv preprint arXiv:1702.03849, 2017.
Yunus Saatchi and Andrew Gordon Wilson. Bayesian GAN. NIPS, 2017.
Filippo Santambrogio. {Euclidean, metric, and Wasserstein} gradient flows: an overview. Bulletin
OfMathematical Sciences, 7(1):87-154, APr 2017.
Leslie N Smith and Nicholay Topin. Super-convergence: Very fast training of residual networks
using large learning rates. arXiv preprint arXiv:1708.07120, 2017.
Yee Whye Teh, Alexandre H Thiery, and Sebastian J Vollmer. Consistency and fluctuations for
stochastic gradient Langevin dynamics. The Journal of Machine Learning Research, 2016.
Douglas N VanDerwerken and Scott C Schmidler. Parallel Markov Chain Monte Carlo. arXiv
preprint arXiv:1312.7479, 2013.
S. J. Vollmer, K. C. Zygalakis, and Y. W. Teh. (Non-)asymPtotic ProPerties of stochastic gradient
Langevin dynamics. Technical RePort arXiv:1501.00438, University of Oxford, UK, January
2015. URL http://arxiv.org/abs/1501.00438.
Sebastian J. Vollmer, Konstantinos C. Zygalakis, and Yee Whye Teh. ExPloration of the (non-
)asymPtotic bias and variance of stochastic gradient langevin dynamics. Journal of Machine
Learning Research, 17(159):1-48, 2016.
Max Welling and Yee W Teh. Bayesian learning via stochastic gradient Langevin dynamics. In
ICML, 2011.
Pan Xu, Jinghui Chen, Difan Zou, and Quanquan Gu. Global convergence of Langevin dynamics
based algorithms for nonconvex oPtimization. arXiv preprint arXiv:1707.06618, 2017.
Jianyi Zhang, Ruiyi Zhang, and Changyou Chen. Stochastic Particle-OPtimization SamPling and
the Non-AsymPtotic Convergence Theory. arXiv e-prints, art. arXiv:1809.01293, SeP 2018.
Y. Zhang, P. Liang, and M. Charikar. A hitting time analysis of stochastic gradient Langevin dy-
namics. In COLT, 2017.
12
Published as a conference paper at ICLR 2020
A Experimental Results
A. 1 Synthetic Multimodal Distribution
The density of the distribution is
25
F(X) = X λN (χ∣μi, ∑),
i=1
where λ =去,μ = {-4, -2,0,2,4}> X {-4, -2,0, 2,4}, Σ =［若。".
In Figure 5, we show the estimated density for SGLD and CSGLD in the non-parallel setting.
(a) Target	(b) SGLD	(c) cSGLD
Figure 5: Sampling from a mixture of25 Gaussians in the non-parallel setting. With a budget of 50K
samples, traditional SGLD has only discovered one of the 25 modes, while our proposed cSGLD
has explored significantly more of the distribution.
To quantitatively show the ability of different algorithms to explore multi-modal distributions, we
define the mode-coverage metric: when the number of samples falling within the radius r of a mode
center is larger than a threshold n, we consider this mode covered. On this dataset, we choose
r = 0.25 and n = 100. Table 4 shows the mode-coverage for several algorithms, based on 10
different runs.
Algorithm	Mode coverage
SGLD	1.8±0.13
CSGLD	6.7±0.52
Parallel SGLD	18±0.47
ParaneI CSGLD	24.4±0.22
Table 4: Mode coverage over 10 different runs, ± standard error.
A.2 Bayesian Logistic Regression
We consider Bayesian logistic regression (BLR) on three real-world datasets from the UCI repos-
itory: Australian (15 covariates, 690 data points), German (25 covariates, 1000 data points) and
Heart (14 covariates, 270 data points). For all experiments, we collect 5000 samples with 5000
burn-in iterations. Following the settings in Li et al. (2016a), we report median effective sample size
(ESS) in Table 5.
Note that BLR is unimodal in parameter space. We use this experiment as an adversarial situation
for cSG-MCMC, which we primarily designed to explore multiple modes. We note that even in the
unimodal setting, cSG-MCMC more effectively explores the parameter space than popular alterna-
tives. We can also use these experiments to understand how samplers respond to varying parameter
dimensionality and training set sizes.
Overall, cSG-MCMC dramatically outperforms SG-MCMC, which demonstrates the fast mixing
rate due to the warm restarts. On the small dataset Heart, SGHMC and cSGHMC achieve the
13
Published as a conference paper at ICLR 2020
same results, because the posterior of BLR on this dataset is simple. However, in higher dimen-
sional spaces (e.g., Australian and German), cSG-MCMC shows significantly higher ESS; this result
means that each cycle in cSG-MCMC can characterize a different region of the posteriors, combin-
ing multiple cycles yields more accurate overall approximation.
	Australian	German	Heart
SGLD	1676	492	2199
cSGLD	2138	978	2541
SGHMC	13l7	2007	5000
cSGHMC	4707	2436	5000
Table 5: Effective sample size for samples for the unimodal posteriors in Bayesian linear regression,
obtained using cyclical and traditional SG-MCMC algorithms, respectively.
B Assumptions
B.1 Assumptions in weak convergence analysis
In the analysis, we define a functional ψ that solves the following Poisson Equation:
1K
Lψ(θk) = Φ(θk) - Φ, or equivalently, K ALψ(θk) = Φ - φ.	(3)
The solution functional ψ(θk) characterizes the difference between φ(θk) and the posterior average
φ for every θk, thus would typically possess a unique solution, which is at least as smooth as φ under
the elliptic or hypoelliptic settings (Mattingly et al., 2010). Following Chen et al. (2015); Vollmer
et al. (2016), we make certain assumptions on the solution functional, ψ, of the Poisson equation
equation 3.
Assumption 2. ψ and its up to 3rd-order derivatives, Dkψ, are bounded by a function V, i.e.,
kDkψ k ≤ HkVpk for k = (0, 1, 2, 3), Hk, pk > 0. Furthermore, the expectation of V on {θk}
is bounded: supl EVp(θk) < ∞, and V is smooth such that sups∈(0,1) Vp (sθ + (1 - s) θ0) ≤
C (Vp (θ) + Vp (θ0)), ∀θ, θ0, p ≤ max{2pk} for some C > 0.
B.2 Assumptions in convergence under the Wasserstein distance
Following existing work in Raginsky et al. (2017), we adopt the following standard assumptions
summarized in Assumption 3.
Assumption 3.	• There exists some constants A ≥ 0 and B ≥ 0, such that U(0) ≤ A and
V	U(0) ≤ B.
•	Thefunction U is Lu-smooth : kVU(w) — VU(v)k ≤ LU∣∣w — v∣∣.
•	The function U is (mu, b) - dissipative, which means for some mU > 0 and b > 0
hw, VU (w)i ≥ mU ∣w∣2 - b.
ml	♦ ,	,	, ，一 Γ(^> 1 ∖	1,1, TTT< Γll X_7 T T /	∖	X-7 TTf ∖ 11 9 T J
•	There exists some constant δ ∈ [0, 1), such that E[∣VUk (w) - VU (w)∣2] ≤
2σ(MU2 ∣w∣2 + B2).
•	We can choose μo which satisfies the requirement: κo := log R ekwk2μo(w)dw < ∞.
C Proof of Theorem 1
To prove the theorem, we borrow tools developed by Chen et al. (2015); Vollmer et al. (2015). We
first rephrase the stepsize assumptions in general SG-MCMC in Assumption 4.
Assumption 4. The algorithm adopts an N-th order integrator. The step sizes {hk } are such that
∞	PK hN+1
0 <	hk+ι	<	hk,	and satisfy 1) E∞=ι hk =	∞;	and 2) limκ→∞	2PK	鼠 =0.
14
Published as a conference paper at ICLR 2020
Our prove can be derived by the following results from Chen et al. (2015).
Lemma 1 (Chen et al. (2015)). Let SK , PkK=1 hk. Under Assumptions 2 and 4, for a smooth test
function φ, the bias and MSE of a decreasing-step-size SG-MCMC with a N th-order integrator at
time SL are bounded as:
BIAS:
O	S1K+
PkK=1hkN+1
SK
MSE: E (φ — φ)2 ≤ C
hk E 以V 俨+ 1 +(PK=1 hN+1)2
SK ECKk+ SK + —SK—
(4)
(5)
Note that Assumption 4 is only required if one wants to prove the asymptotically unbias of an
algorithm. Lemma 1 still applies even if Assumption 4 is not satisfied. In this case one would obtain
a biased algorithm, which is the case of cSGLD.
Proof of Theorem 1. Our results is actually a special case of Lemma 1. To see that, first note that
our cSGLD adopts a first order integrator, thus N = 1. To proceed, note that SK = PkK=1 αk =
O(α0K), and
K-1
X αj2+1
j=0
πmod(j - 1, [K/M])
[K/M]
)+1]2
πmod(j - 1, K/M)
j=0
α2 K M
」(一 + M)=
4 Ml 2 +	)
K∕M
3a0K
8
)+1]2
(6)
As a result, for the bias, we have
O( S1K+
PkK=1hkN+1
SK
o( ɪ +
α0K
3α0K∕8
α0K
=O(α⅛ + α0).
h2	2
For the MSE, note the first term El SkE ∣∣∆V^∣∣ has a higher order than other terms, thus it is
omitted in the big-O notation, i.e.,
〜
E (φ - φ) = O
1
α0K
1
α0K
+(
3α0K∕8
α0K
)2
2
O
This completes the proof.
□
D Proof of Theorem 2
Proofofthe boundfor W2(μκ, ν∞) in cSGLD. Firstly, We introduce the following SDE
dθt = -VU(θt)dt + √2dWt,
(7)
Let Vt denote the distribution of θt, and the stationary distribution of equation 34 be p(θ∣D), which
means ν∞ = p(θ∣D).
θk+1 = θk - VUk(θk)αk+1 +	2αk+1ξk+1
Further, let μk denote the distribution of θk.
Since
W2(μκ, ν∞) ≤ W2(μκ ,νPK=ι ɑj + W2(VPK=I afc ,ν∞)
(8)
(9)
, we need to give the bounds for these two parts respectively.
15
Published as a conference paper at ICLR 2020
D .1 W2(μK, νpK=1 ɑk )
For the first part, W2(μκ, VPK ɪ ak), our proof is based on the proof of Lemma 3.6 in Raginsky
et al. (2017) with some modifications. We first assume E(VU∕(W)) = VU(w), ∀w ∈ Rd , which
is a general assumption according to the way we choose the minibatch. And we define p(t) which
will be used in the following proof:
k	k+1
p(t) = {k ∈ Z| Xαi ≤ t < Xαi}	(10)
i=1	i=1
Then we focus on the following continuous-time interpolation of θk :
θ(t) =θo —
ZtVU
0
ds + √2 Z dwSd)
0
(11)
where VU ≡ VUk for t ∈ [pk=ι αi, Pk=II αj. And for each k , θ(Pk=ι ɑi) and θk have the
same probability law μk.
Since θ(t) is not a Markov process, We define the following process which has the same one-time
marginals as θ(t)
V(t) = θo — /t GS (V(S)) ds + √2/t dwSd)
(12)
with
q(t)
Gt(X)= E VU ∣θ(X ai) J lθ(t)= X	(13)
Let PtV := L (V (s) : 0 ≤ s ≤ t) and Ptθ := L (θ(s) : 0 ≤ s ≤ t) and according to the proof of
Lemma 3.6 in Raginsky et al. (2017), we can derive a similar result for the relative entropy of PtV
and Ptθ :
DKL(PV k Ptt) = - / dPV logdpPV
=4 [ EkVU (V (S))- Gs (V (s))k2ds
1t
=4/ EIlVU(θ(s)) - Gs(θ(s))k2ds
16
Published as a conference paper at ICLR 2020
The last line follows the fact that L(θ(s)) = L(V(s)), ∀s.
Then we will let t = PkK=1 αk and we can use the martingale property of the integral to derive:
DKL(PVPkK=1αk k PθPkK=1 αk)
1 K-1 Pjk+=11 αk
=7∑ /	EkVU (θ(s))- Gs(θ(s))k2ds
4 j=0 JPk=l 软
1 K-1 Pjk+=11 αk	q(s)
≤ 2 Σ JPj a EkVU(θ(s))-VU(θ(∑αi)k2ds
1	K-1	Pjk+=11 αk	q(s)	q(s)
+ 2 Σ j j	EkVU(θ(∑ɑi) - Gs(θ(f αi)k2ds
j=0	k=1 αk	k=1	k=1
L2 K-1	Pjk+=11 αk	q(s)
≤ LUE E	Ekθ(s) - θ(∑ αi)k2ds	(14)
j=0 Pk=1 αk	k=1
2	K-1	Pjk+=11 αk	q(s)	q(s)
+ 2 ∑ / ,	EkVU(θ(Eɑi) - Gs(θ(f αi)k2ds	(15)
j=0	k=1 αk	k=1	k=1
For the first part (14), we consider some s ∈ [Pjk=1 αk, Pjk+=11 αk), for which the following holds:
j
θ(s) - θ(X αk)
k=1
j
=-(s - X αk)VUk (θk) + √2(wSd) - WPdj	)
k=1	k=1 αk
j j
=-(S - E αk)VU(θk) + (s - E αk)(VU(θk) - vUk(θk)) + √2(wSd) - WPdj	)	(16)
k=1	k=1	k=1 αk
Thus, we can use Lemma 3.1 and 3.2 in Raginsky et al. (2017) for the following result:
j
Ekθ(s) - θ(E αk)k2 ≤ 3α2+ιE∣∣VU(θj)『+3α2+ιE∣∣VU(θj) - VUj(θj)∣∣2 + 6αj+ιd
k=1
≤ 2αj2+1 (L2U Ekθj k2 + B2) + 6αj+1d
Hence we can bound the first part, (choosing α0 ≤ 2),
L2 K-1 Pjk+=11 αk	q(s)
LUE j ,=	Ekθ(s) - θ(E ɑi)k2ds
j =0 Pjk=1 αk	k=1
L2 K-1
≤ -Uf- E [l2α3+ι(LUEkθjk2 + B2) + 6α2+ιd]
j=0
K-1
≤ L2U 0≤m≤aKx-1 6(L2U Ekθj k2 + B2) +3d] (X αj2+1)
≤j≤ -	j=0
≤ Lu o≤maχ-ι [6(LU Ekθjk2+B2)+3d] —80—
(17)
17
Published as a conference paper at ICLR 2020
The last line (17) follows from2 equation 6. The second part (15) can be bounded as follows:
1 K-1	Pjk+=11 αk	q(s)	q(s)
2∑	,	EkVU (θ(∑ ɑ) - Gs(θ(E αi)k2ds
j=0	k=1 αk	k=1	k=1
1 K-1
2 Eaj+ιEIlVU(θj)-VU(θj)k2
2 j=0
≤σ
K-1
0≤mj≤aKx-1(L2UEkθjk2 +B2) X αj+1
≤j≤ -	j=0
≤ σ ojK-i(LEkθjk2 + B2)(a20 XZos(一。""))+ 1))
≤ σ0≤m≤aχ-1(LUE∣θjk2 + B2)(警)
Due to the data-processing inequality for the relative entropy, we have
DKL(μK ∣∣νPκ=ι αfc ) ≤ DKL(PV Il Pθ )
L2 K -1	Pjk+=11 αk	q(s)
≤ Lu∑ /	=	Ekθ(s) - θ(∑ ai)∣2ds
j=0 JPk=I ak	k=1
1 K -1 Pjk+=11 αk	q(s)	q(s)
+ 2 Σ j j	EkVU(θ(∑ai) - Gs(θ(f ai)∣2ds
j=0	k=1 αk	k=1	k=1
≤ LU 0≤m≤aχ-1 [6(LU Ekθj k2+B2)+3d]-80-
+ σ 0≤m≤aχ-ι(LU Ekθj k2+ B2)(-2^0)
According to the proof of Lemma 3.2 in Raginsky et al. (2017), we can bound the term Ekθk k2
E∣∣θk+1∣∣2 ≤ (1 - 2ak+1mU + 4ak+ιMU)Ekθk k2 + 2ak+1 b + 4a2 + ιB2 +--+r~~
β
Similar to the statement of Lemma 3.2 in Raginsky et al. (2017), We can fix α° ∈ (0,1 ∧ 4MUτ).
Then, we can know that
Ekθk+11∣2 ≤ (1 - 2aminmU + 4a2minMUJ )E∣∣θk ∣∣2 + 2a0b + 4a0B2 H-(18)
min U	0	β
,where amin is defined as amin，α20 卜os ( π mod(dK/MM；dK/Me)) + 1].
There are tWo cases to consider.
•	If 1 - 2αminmU + 4αm2 inMU2 ≤ 0, then from equation 18 it follows that
E∣θk+ιk2 ≤ 2aob + 4a0B2 + ”
β
≤ E∣θok2 +2(b + 2B2 + d)
β
•	If0 ≤ 1 - 2αminmU + 4αm2 inMU2 ≤ 1, then iterating equation 18 gives
a	a a b a	aob + 2a2B2 + α0d
E∣θkk2 ≤ (1 - 2aiU +4am^MJ)kE∣θo∣2 +------------------00 2	12	(19)
mn	αmin mU - 2α2min MU2
≤ E∣θok2 +	2a0	(b + 2B2 + d)	(20)
_____________________________m amin	β
2Note: we only focus on the case when K mod M = 0.
18
Published as a conference paper at ICLR 2020
Now, we have
0≤mj≤aKx-1(L2UEkθjk2 +B2)
≤ (LU(κo + 2(1 ∧ m：：	)(b + 2B2 + d)) + B2) := Co
Due to the expression of -α^, Co is independent of α°. Then We denote the 6LU (Co + d) as Ci
αmin	U
and We can derive
DKL(μK ∣∣νPK αk ) ≤ C1( -0 - ) + σC0( -^Γ0 )
k=1	8	2
Then according to Proposition 3.1 in Bolley & Villani (2005) and Lemma 3.3 in Raginsky et al.
(2017), ifWe denote κo + 2b + 2d as C2, We can derive the folloWing result:
K
W2(μK ,νPK=ι αk ) ≤ (12 + C2(X αk )) 2 ∙ [DKL (N K llνPκ=ι αj 2 + DKL(βK ∣∣νPκ=ι ɑj 4 ]
k=1
C2 Ka0、1 ιγ3Cια2K
-^^) ∙[(—- +
KσC0 α0
≤ (12+
2
)2	(3Cia0K	KσC0a0 4
) + (—16 —+	4	) ]
D.2 W2(νPkK=1αk,ν∞)
We can directly get the folloWing results from (3.17) in Raginsky et al. (2017) that there exist some
positive constants (C3, C4),
K
W2(νpκɪak ,ν∞) ≤ (C exp(-£ ：k/C4)
k=1
Now combining the bounds for W2(μκ, νPκ Iak) and W2(νpκ Iak, ν∞), substituting ：o =
O(1∕Kβ), and noting W2(νpκ ɪ 0fc ,ν∞) decreases w.r.t. K, we arrive at the bound stated in the
theorem.
□
E Relation with SGLD
For the standard polynomially-decay-stepsize SGLD, the convergence rate is bounded as
W2(μK, ν∞) ≤ W2 (μK, νPK=ι hk) + W2(VPK=I hk，ν∞)	QD
where W2(μK ,νPκ=1 hk ) ≤ (6 + h0 PK=I k )2 ∙
2K	2K
[(DIh0-6 + σD0h0 X k)2 +(DIh016 + σD0 万 X k) 4]
k=1	k=1
and W2 (VPK=I hk ,ν∞) ≤ C3 exP(- P¾ hk ).
Proofofthe bound of W2 (μκ, ν∞) in the standard SGLD. Similar to the proof of W2 (μκ, ν∞) in
cSGLD, we get the following update rule for SGLD with the stepsize following a polynomial decay
i.e., hk = h0,
θk+i = θk - VU∕k(θk)hk+i + P2hk+1ξk+i	(22)
Let μk denote the distribution of θk.
Since
W2(μK, ν∞) ≤ W2 (μK,νPK=I hk ) + W2 (VPK=I hk ,ν∞)	(23)
, we need to give the bounds for these two parts respectively.
19
Published as a conference paper at ICLR 2020
E.1 W2(μκ ,VP= hk)
We first assume E(VU7(W)) = VU(w), ∀w ∈ Rd , which is a general assumption according to
the way we choose the minibatch. Following the proof in Raginsky et al. (2017) and the analysis
of the SPOS method in Zhang et al. (2018), we define the following p(t) which will be used in the
following proof:
k	k+1
p(t) = {k ∈ Z| X hi ≤ t< X hi}	(24)
i=1	i=1
Then we focus on the following continuous-time interpolation of θk :
t	p(s)
θ(t)=θo-/ VU I θ(]q hk)1
ds + √2
(25)
(26)
where VU ≡ VUk for t ∈ [Pk=1 hi, Pk=I hi). And for each k , θ(Pk=1 hi) and θk have the
same probability law μk
Since θ(t) is not a Markov process, We define the following process which has the same one-time
marginals as θ(t)
V(t)
θo - [ Gs (V(S)) ds + √2 [ dWSd)
(27)
with
q(t)
Gt(x) := E VU θ(X hi) ∣θ(t) = X	(28)
Let PtV := L (V (s) : 0 ≤ s ≤ t) and Ptθ := L (θ(s) : 0 ≤ s ≤ t) and according to the proof of
Lemma 3.6 in Raginsky et al. (2017), we can derive the similar result for the relative entropy of PtV
and Ptθ :
DKL(PV k Pθ) = - Z d PV logdpPV
=4 J] EkVU (V (S))- Gs(V (s))k2ds
1t
=4, EIlVU(θ(s)) - Gs(θ(s))k2ds
20
Published as a conference paper at ICLR 2020
The last line follows the fact that L(θ(s)) = L(V(s)), ∀s.
Then we will let t = PkK=1 hk and we can use the martingale property of integral to derive:
DKL(PVPkK=1hk k PθPkK=1 hk)
1	K-1	Pjk+=11 hk
=H	EkVU (θ(s)) - Gs(θ(s))k2ds
4	j=0 JPk=I hk
1 K-1	Pjk+=11 hk	q(s)
≤ 2∑	EkVU(θ(s))-VU(θ(]Thi)k2ds
j j=0 JPk=I hk	k=ι
1	K-1 Pjk+=11 hk	q(s)	q(s)
+ 2∑	,	EkVU (θ(E hi) - Gs(θ(f hi)k2 ds
j=0 Pk=1 hk	k=1	k=1
L2 K-1	Pjk+=11 hk	q(s)
≤ LU∑ I =	Ekθ(s)- θ(∑ hi)k2ds
2	j=0 JPk=I hk	k=ι
1	K-1	Pjk+=11 hk	q(s)	q(s)
+	2	Σ	j EkVU(θ(∑ hi) - Gs(θ(∑	hi)k2ds
j=0	Pk=1 hk	k=1	k=1
(29)
(30)
For the first part (29), we consider some s ∈ [Pjk=1 hk, Pjk+=11 hk), the following equation holds:
j
θ(s)-且(£ hk)
k=1
j
=-(S - X hk)VUk(θk) + √2(wSd) - WP	h )
k=1 k
k=1
j	j
=-(S - X hk NU (θk ) + (s - X hk )(VU (θk)-RUk (θk)) + √2(WSd)-Wq h )
k=1	k=1	k=1 k
Thus, we can use Lemma 3.1 and 3.2 in Raginsky et al. (2017) for the following result:
j
Ekθ(s) - θ(∑ hk)k2
k=1
≤ 3hj+ιEkVU(θj)k2 + 3hj+ιEkVU(θj) - VUj(θj)∣∣2 + 6hj+1d
≤ 12hj2+1 (L2u Ekθj k2 + B2 ) + 6hj+1d
Hence we can bound the first part, (choosing h0 ≤ 1),
(31)
hk
q(s)
Ekθ(s)- θ(- hk)k2ds
k=1
2 K -1
≤ ~Ur X [12h3+ι(LUEkθjk2 + B2) + 6hj+1d
2 j=0
≤ L2U
K-1
0≤mj≤aKx-16(L2UEkθjk2+B2)+3d (Xhj2+1)
≤j≤ -	j=0
π2
≤ Lu max	[6(LUEkθjk + B )+3d]	h0
0≤j≤K -1	6
where the last line follows from the fact that
(32)
K-1	2
j=0 Ey
X-1	1
≤ j=0 (j + 1)2
< X 1	= ∏2
≤ j=o (TW = E
21
Published as a conference paper at ICLR 2020
The second part (30) can be bounded as follows:
1 K-1 Pjk+=11 hk	q(s)	q(s)
2∑	,	EkVU (θ(∑ hi) - Gs(θ(∑ hi)k2ds
j=0 k=1 hk	k=1	k=1
1	K-1
=2 Ehj+ιEkVU(θj)-VU(θj)k2
2	j=0
K-1
≤ σ 0≤mj≤aKx-1(L2U Ekθj k2 +B2) X hj+1
K1
≤ σo≤m≤aχ-ι(LUEkθjk2 + B2)(h0∑S j)
≤j≤ -	j=1 j
Due to the data-processing inequality for the relative entropy, we have
DKL(μK ∣∣νPκ=ι hk ) ≤ DKL(PV Il Pθ)
L2 K -1	Pjk+=11 hk	q(s)
≤ LUE /.=	Ekθ(s) — θ(∑ hi)k2ds
j=0 JPk=I hk	k=1
1 K-1 Pjk+=11 hk	q(s)	q(s)
+ 2∑	EkVU (θ(E hi) — Gs(θ(f hi)k2ds
j j=0 JPk=I hk	k=1	k=1
π2
≤ LUnVmax	J6(LUEkθj ∣∣2 + B2) + 3d] — h0
0≤j≤K -1	6
+σ
K1
0≤m≤aχ-1(LU Ekθj k2+B2)(ho E j)
j	j=1
Similar to the proof of cSGLD , we have
0≤mj≤aKx-1(L2UEkθjk2 +B2) ≤ D0
Then we denote the 6L2U (D0 + d) as D1 and we can derive
2 π2	K 1
DKL(μK kνPK=ι hk ) ≤ D1h0 ɪ + σD0h0 £ j
6	j=1 j
Then according to Proposition 3.1 in Bolley & Villani (2005) and Lemma 3.3 in Raginsky et al.
(2017), if we denote κ0 + 2b + 2d as D2 , we can derive the following result,
W2(μK ,νPK=ι hk)
K
≤ [12 + D2(X hk )]1/2 ∙ [(DKL(μK ∣∣νPκ=ι hk ))1/2 + (DKL(μK llνPκ=ι hk )/2)1/4]
k=1
K	2K	2K
=[12 + D2(h0 X 1)]1/2 ∙ [(D1h0ɪ + σD0h0 X 1)1/2 + (D1h2∏- + σD0h0 X ɪ)1/4]
j	6	j	12	2j
j=1	j=1	j=1
Now We derive the bound for W2 (μκ, νPκ h J
E.2 W2(νPkκ=1hk,ν∞)
We can directly get the following results from (3.17) in Raginsky et al. (2017) that there exist some
positive constants (C3, C4),
K
W2(νPkκ=1hk,ν∞) ≤ C3 exp(—	hk/C4)
k=1
□
22
Published as a conference paper at ICLR 2020
Based on the convergence error bounds, we discuss an informal comparison with standard SGLD.
Consider the following two cases.We must emphasize that since the term W2(μκ, νPκ Iak) in the
equation 9 increases w.r.t. K, our α0 must be set small enough in practice. Hence, in this informal
comparison, we also set a° small enough to make W2 (μκ, VPK ɪ ak) less important.
i)	If the initial stepsizes satisfy α0 ≥ h0, our algorithm cSGLD runs much faster than the standard
SGLD in terms of the amount of “diffusion time” i.e., the ”t” indexing θt in the continuous-time
SDE mentioned above. This result follows from PK=I αk = KO0 and PK=I hk = PK=I h0 =
O(ho log K)《 κ2α0. In standard SGLD, since the error described by W2(μκ, VPK ɪ hJ increases
w.r.t. K, h0 needs to be set small enough in practice to reduce the error. Following the general
analysis of SGLD in Raginsky et al. (2017); Xu et al. (2017), the dominant term in the decomposition
equation 21 will be W2 (VPK h , V∞ ) since it decreases exponentially fast with the increase of t
and W2(μκ, VPKɪ hfc) is small due to the setting of small h°. Since PK=I ak increases much faster
in our algorithm than the term PkK=1 hk in standard SGLD, our algorithm thus endows less error
for K iterations, i.e., W2(VPK α , V∞) W2(VPK h , V∞). Hence, our algorithm outperforms
standard SGLD, as will be verified in our experiments.
ii)	Instead of setting the h0 small enough, one may consider increasing h0 to make standard SGLD
run as “fast” as our proposed algorithm, i.e., PkK=1 hk ≈ PkK=1 αk. Now the W2 (VPK h , V∞)
in equation 21 is almost the same as the W2 (VPK h , V∞) in equation 9. However, in this case,
it is worth noting that h0 scales as O(α0K/ log K). We can notice that h0 is much larger than
the ao and thus the W2(μκ, VPK ɪ 九七)cannot be ignored. Now the h0 term in W2(μκ, VPK ɪ 九七)
would scale as O(α0K2/log2 K), which makes W2(μκ, VPK IafC) in equation 21 much larger
than our W2(μκ, VPK ɪ ak) defined in equation 9 since O(OOK2/ log2 K)》O(a0K). Again,
our algorithm cSGLD achieves a faster convergence rate than standard SGLD.
F Combining S amples
In cyclical SG-MCMC, we obtain samples from multiple modes of a posterior distribution by run-
ning the cyclical step size schedule for many periods. We now show how to effectively utilize the col-
lected samples. We consider each cycle exploring different part of the target distribution p(θ∣D) on
a metric space Θ. As we have M cycles in total, the mth cycle characterizes a local region Θm ⊂ Θ,
defining the “sub-posterior” distribution: Pm(θ∣D) = p(θlD)1θm , with Wm = R9 p(θ∣D)dθ, where
wm is a normalizing constant. Fora testing function f (θ), we are often interested in its true posterior
expectation f = f f (θ)p(θ∣D)dθ. The sample-based estimation is
M	1 Km
f= X Wmfm with fm = K- X f (θjm)),	(33)
m=1	Km j=1
where Km is the number of samples from the mth cycle, and θ(m) ∈ Θm .
The weight for each cycle Wi is estimated using the harmonic mean method (Green, 1995; Raftery
et al., 2006): Wm ≈ [K— PKmL(。/吟]-1. This approach provides a simple and consistent es-
timator, where the only additional cost is to traverse the training dataset to evaluate the likelihood
p(D∣θjm)) for each sample θjm). We evaluate the likelihood once off-line and store the result for
testing.
If Θm are not disjoint, we can assume new sub-regions Θm which are disjoint and compute the
estimator as following
M Km
fm=nL XX/5 m (θjm))
nm
m=L j =L
23
Published as a conference paper at ICLR 2020
where
M Km
nm = XX 1θ m (θjm))
m=1 j=1
and 1C (θ(m)) equals 1 only when θ(m) ∈ Θm. By doing so, our estimator still holds even if Θm
Θm j	j
are not disjoint.
G Theoretical Analysis under Convex Assumption
Firstly, we introduce the following SDE
dθt = -VU(θt)dt + √2dWt ,	(34)
Let Vt denote the distribution of θt, and the stationary distribution of equation 34 be p(θ∣D), which
means ν∞ = p(θ∣D).
However, the exact evaluation of the gradient VU is computationally expensive. Hence, we need to
adopt noisy evaluations of VU. For simplicity, we assume that at any point θk, we can observe the
value
~ ..
VUk = VU (θk) + Zk
where ζk : k = 0, 1, 2, ... is a sequence of random (noise) vectors. Then the algorithm is defined as:
θk+1 = θk - αk+ivUk + /2αk + ιξk+ι	(35)
Further, let μk denote the distribution of θk.
Following the existing work in Dalalyan & Karagulyan (2019), we adopt the following standard
assumptions summarized in Assumption 5,
Assumption 5.
•	For some positive constants m and M, it holds
U(θ) - U(θ0) - VU(θ0)T(θ - θ0) ≥ (m∕2)kθ - θ0k2
kVU(θ)-VU(θ0)k2≤Mkθ-θ0k2
for any θ, θ0 ∈ Rd
•	(bounded bias) E[∣∣E(Zk∣θk)k2] ≤ δ2d
•	(bounded variance) E[kZk — E(Zk ∣θk)k2 ≤ σ2d
•	(independence of updates) ξk+1 in equation 35 is independent of (ζ1, ζ2, ..., ζk)
G.1 Theorem
Under Assumption 5 in the appendix and α° ∈ (0, mm ∧ M), if we define the amin as
号[cos (π mod(dK/MeM 1,dK/M])) + ι], we can derive the the following bounds.
If mαmin + Mao ≤ 2, then W2(μk+1,ν∞) ≤
(1 - mαmin)k W2(μ0, ν∞ ) +
(1.65Ma0/2 + ao δ)d1/2
mαmin
+——普叱--------.(36)
1.65Ma0/ + δ + √mamin δ
If mamin + Mao > 2, then W2(μk+1,ν∞) ≤
(1 - (2 - MaO))KW2(μ0
(1.65Ma3/2 + aoδ)d1/2	δ2aod1/2
ν∞ +	2 - MaO	+ 1.65Ma1/2 + δ + √2 - Ma0δ,
(37)
where the M, m, δ, σ are some positive constants defined in Assumption 5
24
Published as a conference paper at ICLR 2020
G.2 Proof
Proof. According to the equation 1, we can find that the stepsize αk varies from α0 to αmin ,
where 0m切 is defined as 3仃.，α20 卜os (π mod(dK/MM1,dK/MD) + ". When 0 < α0 <
min(2/M, 1/m), it is easy for us to know that 0 < αk < min(2/M, 1/m) for every k > 0. Then
we can derive that all the ρk , max(1 - mαk, Mαk - 1) will satisfy 0 < ρk < 1. Now according
to the Proposition 2 in Dalalyan & Karagulyan (2019), we can derive the result that
W2(μk + 1, ν∞)2 ≤ {ρk+1W2(μk, ν∞) + 1.65M(α3k+1d)1/2 + αk+1δ√p}2 + δ2α2k+1d (38)
Then we will use another lemma derived from Dalalyan & Karagulyan (2019).
Lemma 2. If A,B,C are non-negative numbers such that A ∈ (0,1) and the sequence of non-negative
numbers yk satisfies the following inequality
yk2+1 ≤ [(1 - A)yk + C]2 + B2
for every integer k > 0. Then,
C B2
yk ≤ (I-A) y0 + A + C+√AB
Using Lemma 2, we can finish our proof now.
•	If mαmin + Mα0 ≤ 2, the ρk will satisfy ρk ≤ 1 - mαmin for every k > 0. Then the
equation 38 will turn into
W2(μk+1,ν∞)2 ≤ {(1 - mamin)W2(μk,ν∞) + 1.65M(α0d)1/2 + αoδd1/2}2 + (δα°d1/2)2
for every k > 0. Then We can set A = mamin, C = 1.65M(α0d)1/2 + αoδd1/2, B =
δαod1/2 and we can get the result.
•	If mαmin + Mα0 > 2, the ρk will satisfy ρk ≤ Mα0 - 1 for every k > 0. Then the
equation 38 will turn into
W2(μk+1,ν∞)2 ≤{[1 - (2 - Mαo)]W2(μk,ν∞) + 1.65M(α0d)1/2 + α°δd1∕2}2 + (δαod1/2)2
for every k > 0. Then we can set A = 2 — Mα0, C = 1.65M(α3d)1/2 + αoδd1/2,
B = δαod1/2 and we can get the result.
□
H	Future Direction for the Wasserstein gradient flows
We would like to point out that the convergence theorems developed in the above several sections
can be potentially applied to study the convergence of the Wasserstein gradient flows (Santambrogio,
2017), which can be regarded as a continuous-time MCMC (Chen et al., 2018; Liu et al., 2019). The
theorems may shed some lights on the stepsize choice of the Wasserstein gradient flows which is
less studied in the literature. We leave it as an interesting future work.
I Hyperparameters setting
I.1	Sensitivity of Hyperparameters
Compared to SG-MCMC, there are two additional hyperparameters in Algorithm 1: the number of
cycles M and the proportion of exploration stage β . We now study how sensitive they are when
comparing to the parallel MCMC. With the same setup as in Section 5.2, We compare our method
with M cycles and L epochs per cycle with running M chains parallel MCMC for L epochs. The
training budget is 200 epochs. In Table 2, M = 4 and β = 0.8 on CIFAR-10. We compare cSGLD
and parallel SGLD with smaller and larger values ofM and β. In Table 6, we see that the conclusion
that cSG-MCMC is better than parallel SG-MCMC holds with different values of M and β.
25
Published as a conference paper at ICLR 2020
I.2	Hyperparameters Setting in Practice
Given the training budget, there is a trade-off between the number of cycles M and the cycle length.
We find that it works well in practice by setting the cycle length such that the model with opti-
mization methods will be close to a mode after running for that length. (e.g. the cycle length for
CIFAR-10 is 50 epochs. The model optimized by SGD can achieve about 5% error after 50 epochs
which means the model is close but not fully converge to a mode after 50 epochs.) Once the cycle
length is fixed, M is fixed. β needs tuning for different tasks by cross-validation. Generally, β needs
to be tuned so that the sampler has enough time to reach a good region before starting sampling.
	M 二	2,β=	0.8	M	二 5,β =	0.8	M	4, β =	0.7	M	4, β =	0.9
cSGLD		4.27			4.33			4.08			4.34	
Parallel SGLD		5.49			7.38			6.03			6.03	
Table 6: Comparison of test error (%) between cSG-MCMC and parallel algorithm with varying
values of hyperparameters on CIFAR-10.
J	Tempering in Bayesian Neural Networks
Tempering is common in modern Bayesian deep learning, for both variational inference and MCMC
approaches (e.g., Li et al., 2016a; Nguyen et al., 2017; Fortunato et al., 2017). In general, tempering
reflects the belief that the model capacity is misspecified. This combination of beliefs with data is
what shapes the posterior we want to use to form a good predictive distribution.
Although we use the prescribed temperature in pSGLD (Li et al., 2016a) for all neural network
experiments in the main text (T ≈ 0.0045), we here investigate the effect of temperature T on
performance. We show negative log-likelihood (NLL) and classification error as a function of tem-
perature on CIFAR-10 and CIFAR-100 using cSGLD with the same setup as in Section 5.2. We
consider T ∈ [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0]. Figure 6 and 7 show the results on CIFAR-10 and
CIFAR-100, respectively. On CIFAR-10, the best performance is achieved at T = 0.1 with NLL
0.1331 and error 4.22%. On CIFAR-100, the best performance is achieved at T = 0.01 with NLL
0.7835 and error 20.53%. We find that the optimal temperature is often less than 1. We hypothesize
that this result is due to the model misspecification common to neural networks.
Indeed, modern neural networks are particularly overparametrized. Tempering enables one to use
a model with similar inductive biases to a modern neural network, but with a more well calibrated
capacity (which is especially important when we are doing Bayesian integration instead of optimiza-
tion). Indeed, we show that by sampling from the tempered posterior, we outperform optimization.
Learning the amount of tempering by cross-validation is a principled way of aligning the tempering
procedure with representing a reasonable posterior. We have shown that sampling with cSGMCMC
with tempering helps in terms of both NLL and accuracy, which indicates that we are finding a better
predictive distribution.
(a) Test negative log-likelihood
(b) Test error
Figure 6: NLL and error (%) as a function of temeprature on CIFAR-10 using cSGLD. The best
performance of both NLL and error is achieved at T = 0.1.
26
Published as a conference paper at ICLR 2020
(a) Test negative log-likelihood
Figure 7: NLL and error (%) as a function of temeprature on CIFAR-100 using cSGLD. The best
performance of both NLL and error is achieved at T = 0.01.
(b) Test error
K Experimental Setting Details
K. 1 Bayesian Logistic Regression
For both cSGLD and cSGHMC, M = 100, β = 0.01. For cSGLD, α0N = 1.2, 0.5, 1.5 for Aus-
trilian, German and Hear respectively. For cSGHMC α0N = 0.5, 0.3, 1.0 for Austrilian, German
and Hear respectively. For SG-MCMC, the stepsize is a for the first 5000 iterations and then switch
to the decay schedule (2) with b = 0, γ = 0.55. aN = 1.2, 0.5, 1.5 for Austrilian, German and
Hear respectively for SGLD and aN = 0.5, 0.3, 1.0 for Austrilian, German and Hear respectively
for SGHMC. η = 0.5 in cSGHMC and SGHMC.
Assume that we collect {θb}bB=1 samples. Effective sample size (ESS) is computed by
B
ESS =----L--------
1 + 2 PBT(I-B )ρs
where ρs is estimated by
1B
PS = σ2(B - S) Σ (θb - μ)(θb-s - μ)
Similar to Hoffman & Gelman (2014), σ2 and μ are obtained by running an independent sampler.
We use HMC in this paper.
K.2 Bayesian Neural Networks
For SG-MCMC, the stepsize decays from 0.1 to 0.001 for the first 150 epochs and then switch to the
decay schedule (2) with a = 0.01, b = 0 andγ = 0.5005. η = 0.9 in cSGHMC, Snapshot-SGDM
and SGHMC.
K. 3 Uncertainty Evaluation
For both cSG-MCMC and Snapshot, M = 4. β = 0.8 in cSG-MCMC. α0N = 0.01 and 0.008
for cSGLD and cSGHMC respectively. For SG-MCMC, the stepsize is a for the first 50 iterations
and then switch to the decay schedule (2) with b = 0, γ = 0.5005. aN = 0.01 for SGLD and
aN = 0.008 for SGHMC. η = 0.5 in cSGHMC, Snapshot-SGDM and SGHMC.
27