Figure 1: An angular locality sensitive hash uses random rotations of spherically projected points toestablish buckets by an argmax over signed axes projections. In this highly simplified 2D depiction,two points x and y are unlikely to share the same hash buckets (above) for the three different angularhashes unless their spherical projections are close to one another (below).
Figure 2: Simplified depiction of LSH Attention showing the hash-bucketing, sorting, and chunkingsteps and the resulting causal attentions. (a-d) Attention matrices for these varieties of attention.
Figure 3: Effect of shared query-key space (left) and reversibility (right) on performance on enwik8and imagenet64 training. The curves show bits per dim on held-out data.
Figure 4: LSH attention performance as a function of hashing rounds on imagenet64.
Figure 5: Left: LSH attention performance as a function of number of layers on enwik8. Right:Speed of attention evaluation as a function of input length for full- and LSH- attention.
