Table 1: Gradient for each different loss functionProblem	Overcomplete Tensor	ODL	CDLLoss Hq)	-4 MJq>>4	-4p W	›	›4 -4np∑p=1 yp f q 4	Gradient ▽夕(q)	-A (AJq)d3	-P Y(YJq) d3	-np ∑p=ι yp f (yp f q)d3F.3.2 Concentration FOR Hess Pcdl (∙)Corollary F.10 (Concentration of Hess 0cdl(∙)) Suppose A satisfies Equation (F.9) and X PRmXnp is generated as 说 Equation (F.25) with Xij 〜i.i.d. BG(θ) (1 ≤ i ≤ p, 1 ≤ j ≤ K) andθ P (mm-, 2) .For any given δ P (0,cK 2{(m log2 P log2 np)), wheneverPeCδ-2θK6n3 log (θKn{δ),we havesup }Hess夕dl(q) — Hess夕τ(q)} < δqpSn—1holds with probability at least 1 — CnP´. Here, c,c1,C > 0 are some numerical constants.
