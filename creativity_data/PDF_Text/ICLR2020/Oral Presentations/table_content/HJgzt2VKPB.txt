Table 1: CATER vs previousdatasets in terms of size (num-ber of videos), average videolength, task (classification,detection, generative model-ing, alignment of descriptions,question answering), numberof classes; whether tasks re-quire Temporal Ordering (TO),Short Term Reasoning (STR),Long Term Reasoning (LTR);and if the data Controls forScene Biases (CSB).
Table 2: Performance on the (a) 14-way atomic actions recognition, (b) 301-way compositionalaction recognition, and (c) 36-way localization task, for different methods.
Table 3: Long term reasoning. Com-paring the best reported performanceof standard models on existing datasetsand CATER (task 3). Unlike previousbenchmarks, (1) temporal modeling us-ing LSTM helps and (2) local temporalcues (flow) are not effective by itself onCATER. 2S here refers to ‘Two Stream’.
Table 4: Task 3 grid resolution: Top-1 accuracy of our main baselines on changing the grid resolu-tion. As expected, the overall performance improves when considering a coarser grid, while trackingbecomes a stronger baseline for fine-scale localization.
