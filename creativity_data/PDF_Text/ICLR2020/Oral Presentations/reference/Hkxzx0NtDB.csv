title,year,conference
 Synthesizing robust adversarialexamples,2017, arXiv preprint arXiv:1707
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 A note on the inception score,2018, arXiv preprint arXiv:1801
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Conditional noise-contrastive estimation of unnormalisedmodels,2018, arXiv preprint arXiv:1806
 Semi-Supervised Learning,2006, MIT Press
 Residual flows forinvertible generative modeling,2019, arXiv preprint arXiv:1906
 Implicit generation and generalization in energy-based models,2019, arXivpreprint arXiv:1903
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Noise-contrastive estimation: A new estimation principlefor unnormalized statistical models,2010, In Proceedings of the Thirteenth International Conferenceon Artificial Intelligence and Statistics
 A baseline for detecting misclassified and out-of-distributionexamples in neural networks,2016, arXiv preprint arXiv:1610
 Training products of experts by minimizing contrastive divergence,2002, Neuralcomputation
 Introspective classification with convolutional nets,2017, InAdvances in Neural Information Processing Systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Glow: Generative flow with invertible 1x1 convolutions,2018, InAdvances in Neural Information Processing Systems
 Regularized estimation of image statistics by score matching,2010, InAdvances in neural information processing systems
 A tutorial on energy-basedlearning,2006, Predicting structured data
 Enhancing the reliability of out-of-distribution image detec-tion in neural networks,2017, arXiv preprint arXiv:1706
 Spectral normalizationfor generative adversarial networks,2018, arXiv preprint arXiv:1802
 Detectingout-of-distribution inputs to deep generative models using a test for typicality,2019, arXiv preprintarXiv:1906
 On the anatomy of mcmc-based maximum likelihood learning of energy-based models,2019, arXiv preprint arXiv:1903
 On learning non-convergent short-run mcmctoward energy-based model,2019, arXiv preprint arXiv:1904
 Foolbox: A python toolbox to benchmark therobustness of machine learning models,2017, arXiv preprint arXiv:1707
 Pixelcnn++: Improving thepixelcnn with discretized logistic mixture likelihood and other modifications,2017, arXiv preprintarXiv:1701
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, arXivpreprint arXiv:1906
 Adversarial vulnerability of neural networks increases with input dimension,2018, arXiv preprintarXiv:1802
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Training restricted boltzmann machines using approximations to the likelihoodgradient,2008, In Proceedings of the 25th international conference on Machine learning
 Adversar-ial distillation of bayesian neural network posteriors,2018, In International Conference on MachineLearning (ICML)
 A theory of generative convnet,2016, InInternational Conference on Machine Learning
 Wide residual networks,2016, arXiv preprintarXiv:1605
