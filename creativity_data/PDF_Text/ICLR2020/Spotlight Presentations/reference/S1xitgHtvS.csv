title,year,conference
 Maximum a posteriori policy optimisation,2018, In International Conference on LearningRepresentations (ICLR)
 Weight uncertainty inneural networks,2015, arXiv preprint arXiv:1505
 Boltzmann explorationdone right,2017, In Advances in Neural Information Processing Systems
 An empirical evaluation of thompson sampling,2011, In Advances inneural information processing systems
 Diversity is all you need:Learning skills without a reward function,2018, arXiv preprint arXiv:1802
 Virel: A variationalinference framework for reinforcement learning,2019, In Advances in Neural Information ProcessingSystems
 Bayesian reinforcementlearning: A survey,2015, Foundations and TrendsR in Machine Learning
 Efficient Bayes-adaptive reinforcement learning usingsample-based search,2012, In Advances in Neural Information Processing Systems
 Reinforcement learning withdeep energy-based policies,2017, In Proceedings of the 34th International Conference on MachineLearning (ICML)
 Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprintarXiv:1801
 Optimal control as a graphical model infer-ence Problem,2012, Machine learning
 The advanced theory of statistics,1946, Charles Griffin and Co
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Policy search for motor primitives in robotics,2009, In Advances in neuralinformation processing systems
 Probabilistic graphical models: principles and techniques,2009, MITpress
 From bandits to monte-carlo tree search: The optimistic principle applied to opti-mization and planning,2014, Foundations and TrendsR in Machine Learning
 Variational Bayesian reinforcement learning with regret bounds,2018, arXivpreprint arXiv:1807
 Combining policygradient and Q-learning,2017, In International Conference on Learning Representations (ICLR)
 The uncertainty Bell-man equation and exploration,2018, In Proceedings of the 35th International Conference on MachineLearning (ICML)
 Why is posterior sampling better than optimism for reinforce-ment learning,2017, In Proceedings of the 34th International Conference on Machine Learning (ICML)
 Generalization and exploration via randomizedvalue functions,2014, arXiv preprint arXiv:1402
 Deep exploration viabootstrapped DQN,2016, In Advances In Neural Information Processing Systems
 Deep exploration via randomizedvalue functions,2017, arXiv preprint arXiv:1703
 Randomized prior functions for deep reinforcementlearning,2018, In Advances in Neural Information Processing Systems
 Relative entropy policy search,2010, In AAAI
 Learning to optimize via information-directed sampling,2014, InAdvances in Neural Information Processing Systems
 A tutorial onthompson sampling,2018, Foundations and TrendsR in Machine Learning
 Mastering the game of go withdeep neural networks and tree search,2016, Nature
 PAC model-free reinforcement learning,2006, In Proceedings of the 23rd international conference on Machinelearning
 Reinforcement learning: An introduction,2018, MIT press
 On the likelihood that one unknown probability exceeds another in view ofthe evidence of two samples,1933, Biometrika
 Linearly-solvable markov decision problems,2007, In Advances in neural informationprocessing systems
 Efficient computation of optimal actions,2009, Proceedings of the national academyof sciences
 Robot trajectory optimization using approximate inference,2009, In Proceedings of the26th annual international conference on machine learning
 Probabilistic inference for solving discrete and continuous statemarkov decision processes,2006, In Proceedings of the 23rd international conference on Machinelearning
 Statistical decision functions,1950, 1950
 Learning from delayed rewards,1989, PhD thesis
 An introduction to the Kalman filter,1995, 1995
 Maximum entropy inversereinforcement learning,2008, 2008
