title,year,conference
 Critical learning periods in deep net-works,2019, In International Conference on Learning Representations
 Extremely large minibatch sgd: Training resnet-50 on imagenet in 15 minutes,2017, CoRR
 Scalable methods for 8-bit training ofneural networks,2018, In Advances in NeuraI Information Processing Systems
 Exploiting linearstructure within convolutional networks for efficient evaluation,2014, In Z
 The early phase of neural networktraining,2020, In International Conference on Learning RePreSentations
 Deep learning withlimited numerical precision,2015, In International Conference on Machine Learning
 Deep residual learning for imagerecognition,2016, In ProceedingS of the IEEE conference on computer vision and Pattern recognition
 Identity mappings in deep residualnetworks,2016, In EuroPean conference on computer vision
 Soft filter pruning for acceleratingdeep convolutional neural networks,2018, In International Joint Conference on Artficial Intelligence(IJCAI)
 Snip: Single-shot network pruningbased on connection sensitivity,2019, In Intemational Conference on Learning Representations
 Pruning filters forefficient convnets,2017, In Intemational Conference on Learning RepreSentations
 Towards explaining the regularization effect of initial largelearning rate in training neural networks,2019, arXiv preprint arXiv:1907
 On-demanddeep model compression for mobile devices: A usage-driven model selection framework,2018, InPrOCeedingS of the 16th Annual International Conference on MObile Systems
 Learn-ing efficient convolutional networks through network slimming,2017, In PrOCeedingS of the IEEEInternational COnferenCe on COmputer ViSion
 Rethinking the value ofnetwork pruning,2018, arXiv preprint arXiv:1810
 Thinet: A filter level pruning method for deep neuralnetwork compression,2017, In Proceedings of the IEEE international COnferenCe on COmpUter ViSion
 One ticket to win them all:generalizing lottery ticket initializations across datasets and optimizers,2019, 2019
 On the spectral bias of neural networks,2019, In Proceedings of the 36thInternational COnferenCe on MaChine Learning
 Comparing rewinding and fine-tuning in neuralnetwork pruning,2020, In International COnferenCe on Learning RepreSentations
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Low-memory neural network training: A technical report,2019, arXiv preprintarXiv:1904
 Energy and policy considerations for deeplearning in NLP,2019, CoRR
 Train-ing deep neural networks with 8-bit floating point numbers,2018, In AdVanceS in neural informationprocessing systems
 Energ-ynet: Energy-efficient dynamic inference,2018, 2018b
 Learning versatile filters forefficient convolutional neural networks,2018, In AdvanceS in Neural Information ProceSSing Systems
 Packing convolUtional neUral networks inthe frequency domain,2018, IEEE transactions on Pattern analysis and machine intelligence
 Learning structured sparsity indeep neural networks,2016, In AdVanCeS in neural information ProCeSSing systems
 Deepk-means: Re-training and parameter sharing with harder cluster assignments for compressingdeep convolutions,2018, arXiv PrePrint arXiv:1806
 Training and inference with integers in deepneural networks,2018, In InternationaI ConferenCe on Learning RePreSentations
 Training high-performance and large-scale deep neural networks with full 8-bit integers,2019, arXiv PrePrintarXiv:1909
 Neural architecture search with reinforcement learning,2017, InInternational ConferenCe on Learning RePreSentations
