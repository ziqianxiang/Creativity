title,year,conference
 Reconciling modern machine-learning practice and the classical bias-variance trade-off,2019, Proceedings of the National Academyof Sciences
 FastGCN: Fast learning with graph convolutional networksvia importance sampling,2018, In International Conference on Learning Representations
 Dynamical isometry and a mean fieldtheory of RNNs: Gating enables signal propagation in recurrent neural networks,2018, In Proceedingsof the 35th International Conference on Machine Learning
 Open problem: The landscape of theloss surfaces of multilayer networks,2015, In Peter Grunwald
 Connected components in random graphs with given expected degreesequences,2002, Annals of combinatorics
 Spectral graph theory,1997, Number 92 in CBMS RegionalConference Series in Mathematics
 Approximation by superpositions ofa sigmoidal function,1989, Mathematics of control
 Convolutional neural networkson graphs with fast localized spectral filtering,2016, In Advances in Neural Information ProcessingSystems 29
 Convolutional networks on graphs for learning molecularfingerprints,2015, In Advances in Neural Information Processing Systems 28
 On random graphs I,1959, PubUcationes Mathematicae (Debrecen)
 Random graphs,1959, The Annals of Mathematical Statistics
 Neuralmessage passing for quantum chemistry,1263, In Proceedings of the 34th International Conference onMachine Learning
 Deep convolutional networks on graph-structureddata,2015, arXiv preprint arXiv:1506
 Multilayer feedforward networks are uni-versal approximators,1989, Neural networks
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations
 Semi-supervised classification with graph convolutional net-works,2017, In International Conference on Learning Representations
 ImageNet classification with deep convo-lutional neural networks,2012, In Advances in Neural Information Processing Systems 25
 Efficient backprop,2012, InNeural networks: Tricks of the trade
 Gated graph sequence neural networks,2016, InInternational Conference on Learning Representations
 Break the ceiling: Stronger multi-scale deep graph convolutional networks,2019, In Advances in Neural Information Processing Systems32
 Rectifier nonlinearities improve neural net-work acoustic models,2013, In in ICML Workshop on Deep Learning for Audio
 Automating theconstruction of internet portals with machine learning,2000, Information Retrieval
 The generalization error of random features regression: Preciseasymptotics and double descent curve,2019, arXiv preprint arXiv:1908
 Approximation properties of a multilayered feedforward artificial neu-ral network,1993, Advances in Computational Mathematics
 Semi-supervised learning of hierarchical represen-tations of molecules using neural message passing,2017, arXiv preprint arXiv:1711
 Markov chains,1998, Number 2 in Cambridge Series in Statistical and ProbabilisticMathematics
 Approximation and non-parametric estimation of ResNet-type con-volutional neural networks,2019, arXiv preprint arXiv:1903
 A survey on transfer learning,2010, IEEE Transactions on knowledgeand data engineering
 Equivalence of approximation by convolutional neuralnetworks and fully-connected networks,2018, arXiv preprint arXiv:1809
 Modeling relational data with graph convolutional networks,2018, In European Semantic WebConference
 Neural network with unbounded activation functions is universalapproximator,2017, Applied and Computational Harmonic Analysis
 Benefits of depth in neural networks,2016, In 29th Annual Conference on LearningTheory
 Graph attention networks,2018, In International Conference on Learning Representations
 Simplifying graph convolUtional networks,2019, arXiv preprint arXiv:1902
 Representation learning on graphs with jUmping knowledge networks,2018, In Proceedings ofthe 35th International Conference on Machine Learning
 Error boUnds for approximations with deep ReLU networks,2017, Neural Networks
 Gresnet: Graph residUals for reviving deep graph neUral nets from sUspended anima-tion,2019, arXiv preprint arXiv:1909
 Understanding generalization and optimization performance of deepCNNs,2018, In Proceedings of the 35th International Conference on Machine Learning
4The experiment settings are almost same as the experiment in Section 6,2020,3
