title,year,conference
 Layer normalization,2016, arXiv preprintarXiv:1607
 Ranks of tensors and a generalization of secantvarieties,2013, Linear Algebra and its Applications
 Reading Wikipedia to ansWer open-domain qUestions,2017, arXiv preprint arXiv:1704
 Improving seqUence-to-seqUence learning viaoptimal transport,2019, arXiv preprint arXiv:1901
 Training deep nets With sUblinearmemory cost,2016, arXiv preprint arXiv:1604
 Generating long seqUences With sparsetransformers,2019, arXiv preprint arXiv:1904
 High-accuracy low-precision training,2018, arXiv preprintarXiv:1803
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 The state of sparsity in deep neural networks,2019, CoRR
 GPyTorch:Blackbox matrix-matrix gaussian process inference with GPU acceleration,2018, In Advances in NeuralInformation Processing Systems
 Deep learning withlimited numerical precision,2015, In Proceedings of the 32nd International Conference on MachineLearning
 Rouge: A package for automatic evaluation of summaries,2004, In Text summarizationbranches out
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Effective approaches to attention-based neural machine translation,2015, In Proceedings of the 2015 Conference on Empirical Methodsin Natural Language Processing
 Mixed precisiontraining,2017, arXiv preprint arXiv:1710
 Distributed represen-tations of words and phrases and their compositionality,2013, In Advances in Neural InformationProcessing Systems
 GloVe: Global vectors for word rep-resentation,2014, In Proceedings of the 2014 Conference on Empirical Methods in Natural LanguageProcessing
 Languagemodels are unsupervised multitask learners,2019, OpenAI Blog
 Sequence level train-ing with recurrent neural networks,2016, In International Conference on Learning Representations
 Compressing word embeddings via deep compositional codelearning,2018, In International Conference on Learning Representations
 Low-memory neural network training: A technical report,2019, CoRR
 Learning compact neural word embeddings by parameter spacesharing,2016, In International Joint Conference on Artificial Intelligence
