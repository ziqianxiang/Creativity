Figure 1: Example of a problem where behavioral cloning incurs quadratic regret.
Figure 2: Results on tabular MDP from (Ross & Bagnell, 2010). Shaded region represents rangebetween 5th and 95th quantiles, computed across 500 trials. Behavior cloning exhibits poor worst-case regret, whereas DRIL has low regret across all trials.
Figure 3: Results on Atari environments. a) Median final policy performance for different numbersof expert trajectories, taken over 4 seeds (shaded regions are min/max performance) b) Evolution ofpolicy reward and uncertainty cost during training with N = 3 trajectories.
Figure 4: Results on continuous control tasks.
