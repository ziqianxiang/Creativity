Figure 1: Illustration of tra-jectories likely to be producedby noisily optimal agents nav-igating an MDP. (a) Expectedbehavior on a generic, nom-inal MDP. (b) Demonstratedbehavior from a specific, con-strained MDP. Numbers repre-sent state-based reWards, andthe red-shaded tiles representstate constraints.
Figure 2: Selecting constraints to maximize demonstration likelihood. Trajectories that are likely tobe observed on a given MDP are shown as dashed, angular arrows, and a provided demonstration isshown as a solid, curved arrow. Adding C1 in (b) does little to align the expected trajectories with thedemonstration. On the other hand, adding C2 in (c) makes the original expected trajectories infeasibleand causes the new expected trajectories to agree with the demonstration, greatly increasing thelikelihood of the demonstration on this constrained MDP.
Figure 3: Algorithm performanCe on a synthetiC grid world MDP. EaCh subfigure represents the MDPby showing (CloCkwise from left) its states, aCtions, and features. EaCh element is shaded aCCording tothe proportion of trajeCtories that are expeCted to aCCrue the respeCtive augmented feature, Computedvia Algorithm 1. Constraints are marked with a red “X,” and bright bounding boxes mark the greenand blue feature-produCing states. The result here are shown for a set of 100 demonstrations sampledaCCording to the expeCtation for the True MDP (a). We begin with the nominal MDP shown in (b),and produCe (C), (d), and (e) by applying Algorithm 2. Note that (C), (d), and (e) show the seleCtionsof feature, aCtion, and state Constraints, respeCtively.
Figure 4: Algorithm performanCe on thesynthetiC grid world. EaCh data pointrepresents the mean result of 10 indepen-dent trajeCtory draws, and the marginsshow ±1 standard error.
Figure 5: Human trajectories overlaidon a grid world MDP. The shaded re-gion represents an obstacle in the hu-man’s environment, and the red “X”srepresent learned constraints.
