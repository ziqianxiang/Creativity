Figure 1: Different levels of the MetaBO framework. Left panel: structure of the training loop formeta-learning neural AFs using RL (PPO). Middle panel: the classical BO loop with a neural AFαt,θ. At test time, there is no difference to classical BO, i.e., xt is given by the arg max of the AFoutput. During training, the AF corresponds to the RL policy evaluated on an adaptive set ξt ⊂ D.
Figure 2:	Performance on three global optimization benchmark functions with random translationssampled uniformly from [-0.1, 0.1]D and scalings from [0.9, 1.1]. To test TAF’s performance, werandomly picked M = 50 source tasks from this function class and evaluated both the ranking-basedversion (TAF-R-50) and the mixture-of-experts version (TAF-ME-50). We trained MetaBO on thesame set of source tasks (MetaBO-50). In contrast to TAF, MetaBO can also be trained without man-ually restricting the set of available source tasks. The corresponding results are labelled "MetaBO".
Figure 3:	Performance on a simulation-to-real task (cf. text). MetaBO and TAF used source data froma cheap numerical simulation. (a) Performance on an extended training set in simulation. (b) Transferto the hardware depicted in (c), averaged over ten BO runs. MetaBO learned robust neural AFs withvery strong optimization performance and online adaption to the target objectives, which reliablyyielded stabilizing controllers after less than ten BO iterations while TAF-ME-100, TAF-R-100, andEI explore too heavily. Comparing the results for MetaBO and MetaBO-50 in simulation, we observethat MetaBO benefits from its ability to learn from the whole set of available source data, whileTAF’s applicability is restricted to a comparably small number of source tasks. We move the resultsfor TAF-50 to App. A.4, Fig. 13.
Figure 4: Performance on two 2D hyperparameter optimization tasks (SVM and AdaBoost). Wetrained MetaBO on precomputed data for 35 randomly chosen datasets and used the same datasets assource tasks for TAF. The remaining 15 datasets were used for this evaluation. MetaBO learned verydata-efficient sampling strategies on both experiments, outperforming the benchmark methods byclear margin. Note that the optimization domain is discrete and therefore tasks can be solved exactly,corresponding to zero regret.
Figure 5: Performance of MetaBO trained on D = 3-dimensional objective functions sampled froma GP prior with RBF kernel (upper row) and Matern-5/2 kernel (lower row) with lengthscales drawnrandomly from ` ∈ [0.05, 0.5]. Panels (a, d) show the performance on these training distributions. Aswe excluded the x-feature from the neural AF inputs during training, the resulting AFs can be appliedto functions of different dimensionalities. We evaluated each AF on D = 4 and D = 5 withoutretraining MetaBO. We report simple regret w.r.t. the best observed function value, determinedseparately for each function in the test set.
Figure 6:	Visualization of three BO episodes with neural AFs on the 1D Rhino-1 task. Each columnof this figure correspond to one episode with three optimization steps. The uppermost row correspondsto the prior state before the objective function was queried. The fourth row depicts the state afterthree evaluations. Each subfigure shows the GP mean (dashed blue line), GP standard deviation (blueshaded area), and the ground truth function (black) in the upper panel as well as the neural AF in thelower panel. Dashed red lines indicate the maxima of the ground truth function and of the neural AF.
Figure 7:	Visualization of three episodes from the 1D Rhino-2 task. Each column of this figurecorrespond to one episode with two optimization steps. The uppermost row corresponds to the priorstate before the objective function was queried. The third row depicts the state after two evaluations.
Figure 8: Performance on three global optimization benchmark functions with random translationssampled uniformly from [-0.1, 0.1]D and scalings from [0.9, 1.1]. We present results for twoadditional baseline methods (GMM-UCB, EPS-GREEDY) which rely on a weighted superpositionof a prior over D obtained from M = 50 source tasks and a standard AF and can thus be easilyinterpreted. As MetaBO produces more sophisticated search strategies, these approaches are not ableto surpass MetaBO’s performance.
Figure 9: Dependence of MetaBO’s performance on the number of source tasks provided duringtraining on the Branin function (cf. Fig. 2(a)) and on the stabilization task for the Furuta pendulum insimulation (cf. Fig. 3(a)). We show the number of steps MetaBO requires to reach a given performancein terms of median regret over 100 test functions in dependence of the number M of source tasks. Asin the main part of this paper, we chose a constant budget of T = 30 on the Branin function and ofT = 50 on the stabilization task. The dashed red line indicates the number of source tasks seen bythe full version of MetaBO (a new function is sampled from the training distribution at the beginningof each optimization episode) at the point of convergence of meta-training. For the Branin functionwe chose the regret threshold R = 10-3, which corresponds to the median final performance of TAFafter t = 30 steps as presented in the main part of this paper (Fig. 2(a)). For the Furuta stabilizationtask, we chose the regret threshold R = 1.0, which corresponds approximately to the regret that hasto be reached in simulation to allow stabilization on the real system. The results show that on theBranin function already a small number of source tasks is enough to obtain a powerful optimizationstrategy. In contrast, neural AFs trained on the more complex simulation-to-real task benefit fromMetaBO’s ability to process a very large amount of source tasks.
Figure 10: Generalization of neural AFs to functions outside of the training distribution(translations t ∈ [-0.1, 0.1], scalings s ∈ [0.9, 1.1], red square) on Branin, Goldstein-Price, andHartmann-3. We evaluated the neural AFs on 100 test distributions with disjoint ranges of transla-tions and scalings, each corresponding to one tile of the heatmap. The x- and y-labels of each tiledenote the lower bounds of the translations t and scalings s of the respective test distribution fromwhich the parameters were sampled uniformly (for each dimension we sampled the translation andits sign independently). The color encodes the number of optimization steps required to reach agiven regret threshold. White tiles indicate that this threshold could not be reached withtin T = 30optimization steps. The regret threshold was fixed for each function separately: we set it to the1%-percentile of the set of regrets corresponding to function evaluations on a Sobol grid of onemillion points in the domain of the original objective functions.
Figure 11: Generalization of neural AFs to funCtions outside of the training distribution (75%to 125% of measured physiCal parameters, red square) on the simulation-to-real task. We eval-uated neural AFs on test distributions with disjoint ranges of physiCal parameters (masses andlengths of the pendulum and arm). We sampled eaCh physiCal parameter pi uniformly on[f ∙ Pi,measured, (f + 0.2) ∙ Pi,measured]. Therefore, f = 0.9 corresponds to the interval contain-ing the measured parameters. We plot f on the x-axis and the number of steps required to reaCh aregret threshold of R = 1.0 on the y-axis. Following our experience, this corresponds approximatelyto the regret that has to be reached in simulation to allow stabilization on the real system. Weemphasize that the intended use case of MetaBO is on systems inside of the training distributionmarked in red, as this distribution is chosen such that the true parameters are located inside of it withhigh confidence when taking into account the measurement uncertainty. Note that for small f thesystem becomes very hard to stabilize (lightweight and short pendula) such that the optimizationlandscape differs significantly from the training distribution, which is why the regret threshold cannotbe reached within 30 steps for f ≤ 0.5.
Figure 12: PerformanCe on three global optimization benChmark funCtions with random translationssampled uniformly from [-0.1, 0.1]D and sCalings from [0.9, 1.1]. To test TAF’s performanCe, werandomly piCked M sourCe tasks from this funCtion Class and evaluated both the ranking-based version(TAF-R-M) and the mixture-of-experts version (TAF-ME-M). We show results for M ∈ {20, 50}.
Figure 13: Performance on a simulation-to-real task (cf. text). MetaBO and TAF used sourcedata from a cheap numerical simulation. (a) Performance on an extended training set in simulation.
