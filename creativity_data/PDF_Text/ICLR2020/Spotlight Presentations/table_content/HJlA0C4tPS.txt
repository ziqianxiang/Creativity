Table 1: Results on the sentiment transfer, author imitation, and formality transfer. We list the PPL ofpretrained LMs on the test sets of both domains. We only report Self-BLEU on the sentiment task tocompare with existing work.
Table 3: Examples for author imitation taskMethods	Shakespeare to ModernSource	Not to his father’s .
Table 4: Comparison of gradient approximation on the sentiment transfer task.
Table 5: Comparison of gradient propagation method on the sentiment transfer task.							Method	train ELBO↑	test ELBO↑	Acc.	BLEUr	BLEUs	PPLD1	PPLD2Gumbel Softmax	-2.96	-2.98	81.30	16.17	40.47	22.70	23.88REINFORCE	-6.07	-6.48	95.10	4.08	9.74	6.31	4.08Stop Gradient	-2.05	-2.07	87.90	18.67	48.38	27.75	35.61Greedy vs. Sample-based Gradient Approximation. In our experiments, we use greedy decodingfrom the inference network to approximate the expectation required by ELBO, which is a biasedestimator. The main purpose of this approach is to reduce the variance of the gradient estimator duringtraining, especially in the early stages when the variance of sample-based approaches is quite high. Asan ablation experiment on the sentiment transfer task we compare greedy and sample-based gradientapproximations in terms of both train and test ELBO, as well as task performance correspondingto best test ELBO. After the model is fully trained, we find that the sample-based approximationhas low variance. With a single sample, the standard deviation of the EBLO is less than 0.3 across10 different test repetitions. All final reported ELBO values are all computed with this approach,regardless of whether the greedy approximation was used during training. The reported ELBO valuesare the evidence lower bound per word. Results are shown in Table 4, where the sampling-basedtraining underperforms on both ELBO and task evaluations.
Table 6: Random Sentiment Transfer ExamplesMethods	negative to positiveOriginal	the cake portion was extremely light and a bit dry .
Table 7: Repetitive examples of BT+NLL baseline on Formality transfer.
