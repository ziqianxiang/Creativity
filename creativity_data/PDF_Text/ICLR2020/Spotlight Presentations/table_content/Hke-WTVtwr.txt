Table 1: Dataset Statistics. CV means 10-fold cross validation. The last 2 datasets come withtrain/dev/test splits.
Table 2: Text classification accuracy without position embeddings, with random position embed-dings (PE), with trigonometric position embeddings (TPE), with complex-valued NNs without po-sition embeddings (complex-vanilla), and with our complex-order embeddings. Superscripts §, f, ∣and * mean a significant improvement over a baseline without position embeddings §, PE±, TPE^and Complex-vanilla * using Wilcoxon,s signed-rank test p<0.05.
Table 3: Text classification accuracy. ? means that scores are reported from other papers.
Table 4: Ablation test for Transformer, showing the effect of (i) the definition of embeddinglayer(fd(j, pos)), and (ii) whether the real-part and imaginary transition share the weights, i.e.,<(W Q/K/V) = =(W Q/K/V).
Table 5: Machine translation results. ? marks scores reported from other papers.		Table 6:	Language modeling results. ? marks scores reported from other papers.	Method	BLEU	Method	BPCAED (Bahdanau et al., 2014) ? AED+Linguistic (Sennrich & Haddow, 2016) ? AED+BPE (Sennrich et al., 2016) ? Transformer (Ma et al., 2019) ? Transformer complex vanilla Transformer Complex-order	26.8 28.4 34.2 34.5 34.7 35.8	BN-LSTM (Cooijmans et al., 2016) ? LN HM-LSTM (Chung et al., 2016) ? RHN (Zilly et al., 2017) ? Large mLSTM (Krause et al., 2016) ? Transformer XL 6L (Dai et al., 2019) Transformer complex vanilla Transformer XL Complex-order 6L	1.36 1.29 1.27 1.27 1.29 1.30 1.26Results Tab. 5 shows the MT results. Our approach outperforms all baselines. Two things areworth noting: (1) Both the vanilla Transformer and our Transformer Complex-order outperform thethree Attentional encoder-decoder baselines which are based on an LSTM encoder and decoder, evenwhen AED uses additional features. (2) Our Transformer Complex-Order outperforms the VanillaTransformer and complex-vanilla Transformer by 1.3 and 1.1 in absolute BLEU score respectively.
Table 7: Words with greatest frequencies and frequencies periods (based on δj ) in SST (a sentimentclassification task), all words are converted to lower-case. The strong sentiment words are boldbased on manual labeling.
