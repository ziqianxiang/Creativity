Table 2:	Number of clustersK.
Table 1: Ablation: number ofself-labelling steps.
Table 3:	Ablation: number ofheads T. (c4 for AlexNet)Method Architecture Top-1SeLa [3k X	1]	AlexNet	44.7SeLa [3k ×	10]	AlexNet	46.7SeLa [3k X	1]	ResNet-50	51.8SeLa [3k X	10]	ResNet-50	61.5SeLa [1k × 1] 40.1 42.1 38.8SeLa [3k × 1] 43.0 44.7 40.9SeLa [5k × 1] 42.5 43.9 40.2SeLa [10k × 1] 42.2 43.8 39.7Table 4: Different architectures.	Table 5: Label transfer.
Table 4: Different architectures.	Table 5: Label transfer.
Table 6: Nearest Neighbour and linear classificationevaluation on small datasets using AlexNet. Resultsof previous methods are taken from (Huang et al.,2019).
Table 7: PASCAL VOC ing.	VOC07-Classification VOC07-Detection %mAP and Segmentation %mIU. * denotes AlexNet variant.			finetun- %mAP, VOC12- a larger		PASCAL VOC Task			Method	Cls. fc6-8 all		Det. all	Seg. allImageNet labels	78.9	79.9	59.1	48.0Random	-	53.3	43.4	-Random Rescaled	-	56.6	45.6	32.6BiGAN	52.3	60.1	46.9	35.2Context*	55.1	65.3	51.1	-Context 2	-	69.6	55.8	41.4CC+VGG	-	72.5	56.5	42.6RotNet	70.9	73.0	54.4	39.1DeepCluster*	72.0	73.4	55.4	45.1RotNet+retrieval*	72.5	74.7	58.0	45.9SeLa* [3k X 10]	73.1	75.3	55.9	43.7SeLa* [3k × 10]-	74.4	75.9	57.8	44.7SeLa* [3k X 10]-+Rot	75.6	77.2	59.2	45.7Table 8: Nearest Neighbour and linear classification evaluation using imbalanced CIFAR-10 trainingdata. We evaluate on the normal CIFAR-10 test set and on CIFAR-100 to analyze the transferabilityof the features. Difference to the supervised baseline in parentheses. See section 4.5 for details.
Table 8: Nearest Neighbour and linear classification evaluation using imbalanced CIFAR-10 trainingdata. We evaluate on the normal CIFAR-10 test set and on CIFAR-100 to analyze the transferabilityof the features. Difference to the supervised baseline in parentheses. See section 4.5 for details.
Table 9: Linear probing evaluation - AlexNet. A linear classifier is trained on the (downsampled)activations of each layer in the pretrained model. We bold the best result in each layer and Underlinethe second best. The best layer is highlighted in blue. * denotes a larger AlexNet variant. - refers toAlexNets trained with self-label transfer from a corresponding ResNet-50. "+Rot" refers to retrainingusing labels and an additional RotNet loss, "+ more aug." includes further augmentation duringretraining. See Table A.2 in the Appendix for a full version of this table and details.
Table 10: Linear evaluation - ResNet. A linear layer is trained on top of the global average pooledfeatures of ResNets. All evaluations use a single centred crop. We have separated much largerarchitectures such as RevNet-50×4 and ResNet-161. Methods in brackets use a augmentationpolicy learned from supervised training and methods with * are not explicit about which furtheraugmentations they use. See Table A.3 in the Appendix for a full version of this table.
Table A.1: Clustering metrics that compare with ground-truth labels of the ImageNet validation set(with 1-crop). For reference, we provide the best Top-1 error on ImageNet linear probing (as reportedin the main part).*: for the multi-head variants, We simply use predictions of a randomly picked,single head.
Table A.2: Linear probing evaluation - AlexNet. A linear classifier is trained on the (downsampled)activations of each layer in the pretrained model. We bold the best result in each layer and Underlinethe second best. The best layer is highlighted in blue. * denotes a larger AlexNet variant. - refers toAlexNets trained with self-label transfer from a corresponding ResNet-50. "+Rot" refers to retrainingusing labels and an additional RotNet loss, "+ more aug." includes further augmentation duringretraining.
Table A.3: Linear evaluation - ResNet. A linear layer is trained on top of the global averagepooled features of ResNets. All evaluations use a single centred crop. We have separated muchlarger architectures such as RevNet-50×4 and ResNet-161. Methods in brackets use a augmentationpolicy learned from supervised training and methods with * are not explicit about which furtheraugmentations they use.
