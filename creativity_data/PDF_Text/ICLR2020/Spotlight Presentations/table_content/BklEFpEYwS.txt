Table 1: Test MSE for the non-mutually-exclusive sinusoid regression problem. We compare MAML and CNPagainst meta-regularized MAML (MR-MAML) and meta-regularized CNP (MR-CNP) where regularization iseither on the activations (A) or the weights (W). We report the mean over 5 trials and the standard deviation inparentheses.
Table 2: Meta-test MSE for the pose prediction problem. We compare MR-MAML (ours) with conventionalMAML and fine-tuning (FT). We report the average over 5 trials and standard deviation in parentheses.
Table 3: Meta-testing MSE for the pose prediction problem. We compare MR-CNP (ours) with conventionalCNP, CNP with weight decay, and CNP with Bayes-by-Backprop (BbB) regularization on all the weights. Wereport the average over 5 trials and standard deviation in parentheses.
Table 4: Meta-test accuracy on non-mutually-exclusive (NME) classification. The fine-tuning and nearest-neighbor baseline results for MiniImagenet are from (Ravi & Larochelle, 2016).
Table 5: Meta-training pre-update accuracy on non-mutually-exclusive classification. MR-MAML controlsthe meta-training pre-update accuracy close to random guess and achieves low training error after adaptation.
