Table 1: Few-shot classification results trained with the mini-ImageNet dataset. We train themodel on the mini-ImageNet domain and evaluate the trained model on another domain. FT in-dicates that we apply the feature-wise transformation layers with empirically determined hyper-parameters to train the model.
Table 2: Few-shot classification results trained with multiple datasets. We use the leave-one-outsetting to select the unseen domain and train the model as well as the feature-wise transformationlayers using Algorithm 1. FT and LFT indicate applying the pre-determined and learning-to-learnedfeature-wise transformation, respectively.
Table 3: Summarization of the datasets (domains). We additionally collect and split the Cars,Phces, and Plantae datasets._________________________________________________Datasets	mini-ImageNet	CUB	Cars	Places	PlantaeSource	Deng et al. (2009)	Welinder et al. (2010)	Krause et al. (2013)	Zhou et al. (2017)	Van Horn et al. (2018)# Training categories	64	100	98	183	100# Validation categories	16	50	49	91	50# Testing categories	20	50	49	91	50Split setting	Ravi & Larochelle (2017)	Hilliard et al. (2018)	randomly split	randomly split	randomly splitA.2 Additional implementation detailsWe use the implementation and adopt the setting of hyper-parameters from Chen et al. (Chen et al.,2019a).4 We train the metric-based model and feature-wise transformation layers with a learning rateof 0.001 and 40, 000 iterations. For feature-wise transformation layers, we apply L2 regularizationwith a weight of 10-8. The number of inner iterations adopted in the learning-to-learn scheme is setto be 1.
Table 4: Ablation study on pre-trained metric encoder. We conduct leave-one-out setting toselect the unseen domain to study the effectiveness of pre-training the feature encoder E on themini-ImageNet dataset.
Table 5: Few-shot classification results under various numbers of ways in testing stage. Wecompare the 5-shot performance under various number of ways in the testing phase. The CUBdataset is select as the testing (unseen) domain. All the models are trained with 5-way 5-shot setting.
Table 6: Few-shot classification results by applying different pre-determined hyper-parametersof feature-wise transformation layers. We train the model on the mini-ImageNet with a differentset of pre-determined hyper-parameters of feature-wise transformation layers. FT and FT* indicatethat we apply the feature-wise transformation layers with hyper-parameters {θγ, θβ} to be {0.3, 0.5}and {1, 1}, respectively.
Table 7: Few-shot classification results by applying the learning-to-learn approach trained witha single seen domain. We attempt to conduct the proposed learning-to-learn trainin with as singeseen domain, denoted as LFT*. We train the model using the mini-ImageNet dataset and report the5-way 5-shot classification accuracy.
Table 8: Comparison to the state-of-the-art few-shot classification algorithms. We compare themetric-based frameworks applied with the proposed feature-wise transformation layers using pre-determined hyper-parameter {θγ, θβ} = {0.3, 0.5} (denoted as FT) to other state-of-the-art few-shotclassification methods. Note that all the methods are trained only on the mini-ImageNet dataset. Toensure fair comparisons with other methods, we are unable to use the learned version of the feature-wise transformation layers described in Section 3.3. By augmenting existing metric-based few-shotclassification models with the proposed feature-wise transformation layer, we obtain competitiveperformance when compared with many recent and more complicated methods. The best results ineach block are highlighted in bold.
Table 9: Evaluation with the state-of-the-art approach under the cross-domain setting. Weevaluate the metric-based frameworks with the proposed feature-wise transformation layers usingpre-determined hyper-parameter {θγ, θβ} = {0.3, 0.5} (denoted as FT) against the state-of-the-artMetaOptNet-SVM-trainval Lee et al. (2019) method. Note that all the methods are trained onlyon the mini-ImageNet dataset. To ensure fair comparisons with other methods, we do not use thelearned version of the feature-wise transformation layers described in Section 3.3. By augmentingthe existing metric-based few-shot classification models with the proposed feature-wise transforma-tion layer, we obtain competitive performance when compared with recent and more complicatedmethods. The best results are highlighted in bold.
