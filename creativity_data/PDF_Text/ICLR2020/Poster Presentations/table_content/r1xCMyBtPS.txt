Table 1: Accuracy on the XNLI test set, where we compare to base BERT (Devlin et al., 2018)and two rotation-based methods, sentence alignment (Aldarmaki & Diab, 2019) and word align-ment (Wang et al., 2019). We also include the current state-of-the-art zero-shot achieved byXLM (Lample & Conneau, 2019). Rotation-based methods provide small gains on some languagesbut not others. On the other hand, after fine-tuning-based alignment, Bulgarian and Greek match thetranslate-train ceiling, while German, Spanish, and French close roughly one-third of the gap.
Table 2: Zero-shot accuracy on the XNLI test set, where we align BERT with varying amounts ofparallel data. The method scales with the amount of data but achieves a large fraction of the gainswith 50K sentences per language pair.
Table 3: Word retrieval accuracy for the aligned sentence-augmented fastText baseline and BERTpre- and post-alignment. Across languages, base BERT has variable accuracy while fine-tuning-aligned BERT is consistently effective. Fine-tuned BERT also matches fastText in a version of thetask where context is not necessary, suggesting that our method matches the type-level alignment offastText while also aligning context.
Table 4: Accuracy by part-of-speech tag for non-contextual word retrieval. To achieve betterword type coverage, we do not remove word pairs seen in the training set. The tags are grouped intolexically overlapping, closed-class, and open-class groups. The “Particle,” “Symbol,” “Interjection,”and “Other” tags are omitted.
Table 5: Zero-shot accuracy on the XNLI test set with more languages, where we use 20K parallelsentences for each language paired with English. This result confirms that the alignment methodworks for distant languages and a variety of parallel corpora, including Europarl, MultiUN, andTanzil, which contains sentences from the Quran (Koehn, 2005; Eisele & Chen, 2010; Tiedemann,2012).
