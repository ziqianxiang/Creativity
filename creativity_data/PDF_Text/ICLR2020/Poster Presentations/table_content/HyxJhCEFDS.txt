Table 1: MBN statistics characterize modelperformance. Using MBNclean/MBNadv, thetrained models achieve strong performanceon clean/adversarial images.
Table 2: Enforcing a consistent behavior of BNat the training stage and the testing stage signif-icantly boosts adversarial robustness. * denotesthat running statistics is used at the last 10 train-ing epochs.
Table 3: The results of ALP re-implementations under different parameter settings. We show thatapplying stronger attackers for training, e.g., change from PGD-10 to PGD-30, is the most importantfactor for achieving strong robustness. Other parameters, like optimizer, do not lead to significantrobustness changes.
Table 4: Robustness evaluation of models adversarially trained with PGD-{30, 20, 10, 5} at-tackers. We observe that decreasing the number of PGD attack iteration for training usually leads toweaker robustness, while the amount of degraded robustness is strongly related to training strategies.
Table 5: Validating the effectiveness of applying running statis-tics in training on more settings. We observe this heuristic pol-icy can boost robustness on all settings. * denotes that runningstatistics is used at the last 10 training epochs.
Table 6: Performanceevaluation of modelstrained with differentbatch size. The best per-formance can be achievedby training with a batchsize of 2048.
Table 7: For easier benchmarking in future works, we list the detailed performance of adversariallytrained models. * denotes running statistics is used at the last 10 training epochs.
