Table 1: Test accuracy (%) for the VGG-like and ResNet-18 models on CIFAR-10. STE @(X,X) indicates the weight-activation quantization configuration used with STE for fine-tuning. DQdenotes Defensive Quantization (Lin et al., 2019). For the No Regularization row of results we onlyreport the mean of 5 runs. The full range of the runs is shown in Figure 4.
Table 2: Test accuracy for the ResNet-18 architecture on ImageNet. STE @ (X,X) indicates theweight-activation quantization configuration used with STE for fine-tuning. In addition to the λ wefound through the grid-search which maintains FP accuracy, we also experimented with a strongerλ = 0.05 to show that (4,4) accuracy can be recovered at the price of overall lower performance.
