Table 1: Comparison of random forests on canonical (can), strengthened (str) and generalized (gen)space. We measure the classification accuracy with T = 1, 10, 50 for three datasets. In all datasets,random forests on the generalized feature space perform well. The best result in each number of treesis marked as bold. It is worth noticing that when the number of trees is 1, the random forest with thestrengthened space performs better. As the tree grows, the correlation of this random forest increases,and the proposed method with the generalized space performs better.
Table 2: Comparison of random forests on canonical (can), strengthened (str) and generalized (gen)space. We measure the classification accuracy with T = 50 for five datasets. Random forests withthe generalized space achieve the best result in all settings.
Table 3: Experiments on the OfficeHome dataset with the ResNet-18 backbone.
Table 4: Experiments on the VLCS dataset with the AlexNet backbone.
Table 5: Experiments on the MIT-Indoor dataset. Table 6: Experiments on the 4D-Light dataset.
Table 7: Experiments on the Scene-15 dataset.	Table 8: Experiments on the DTD dataset.
Table 9: Experiments on the Stanford-Dog dataset. The results are acquired on the ResNet-50 andDenseNet-161 for PC, MAMC, and GCFN.
Table 10: Comparison of random forests on the SVHN (Netzer et al., 2011) and CIFAR-100 (Krizhevsky & Hinton, 2009) dataset. We used the LeNet (LeCun et al., 1998; LeCun, 2015)based backbone network.
