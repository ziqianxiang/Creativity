Table 1: Ablating data augmentation usingMonoGAN (left). Training a linear classifieron the features extracted at different depthsof the network for CIFAR-10.
Table 2: ImageNet LSVRC-12 linear prob-ing evaluation (below). A linear classifier istrained on the (downsampled) activations ofeach layer in the pretrained model. We re-port classification accuracy averaged over 10crops. The ^ indicated that numbers are takenfrom (Zhang et al., 2017).
Table 3: CIFAR-10/100. Accuracy of linear classifiers on different network layers.
Table 4: Finetuning experiments The pre-trained modelâ€™s first two convolutions are leftfrozen (or replaced by the Scattering trans-form) and the nework is retrained using Ima-geNet LSVRC-12 training set.
Table 5: Finetuning experiments Models are initialized using conv1 and conv2 from various sin-gle image trained models and the whole network is fine-tuned using ImageNet LSVRC-12 trainingset. Accuracy is averaged over 10 crops.
