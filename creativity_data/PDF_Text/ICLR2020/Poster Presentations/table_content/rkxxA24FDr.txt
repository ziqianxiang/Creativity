Table 1: Generalization performance of best models measured in average bit error persequence (lower is better). For each task, we pick 1,000 longer sequences as test data.
Table 2: Test-set classification accuracy (%) on the Omniglot dataset after 100,000 episodesof training. * denotes available results from (Santoro et al., 2016).
Table 3: Mean and s.d. for bAbI error (%).
Table 4: Model hyper-parameters (single tasks).
Table 5: Task settings (single tasks).
Table 6: Model hyper-parameters (sequencing tasks).
Table 7: Task settings (sequencing tasks).
Table 8: Model hyper-parameters (continual procedure learning tasks). NUTM uses 6programs per head.
Table 9: Task settings (continual procedure learning tasks).
Table 10: Hyper-parameters for few-shot learning. All models use RMSprop optimizer withlearning rate 10-4.
Table 11: Test-set classification accuracy (%) on the Omniglot dataset after 100,000 episodesof training. * denotes available results from Santoro et al. (2016) (some are estimated fromplotted figures).
Table 12: NUTM hyper-parameters for bAbI.
Table 13: NUTM (p = 4) bAbI best and mean errors (%).
