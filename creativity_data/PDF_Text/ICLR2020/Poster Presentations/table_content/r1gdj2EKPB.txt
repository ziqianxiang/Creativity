Table 1: Experiment results on CIFAR-100 Split and CIFAR-100 Superclass datasets. The results are the meanaccuracies over 3 runs of experiments with random splits, performed with 5 different task order sequences. STLis the single-task learning model that trains a separate network for each task independently. Standard deviationsfor accuracy are given in Table A.3 in the Appendix.
Table 2: Accuracy comparison on diverse datasets according to two opposite task order (arrows). The results arethe mean accuracies over 3 runs of experiments. VGG16 with batch normalization is used for a base network.
Table A.3: Ablation study results on APD(1) with average of five different orders depicted in A.1. We show avalidity of APD as comparing with several architectural variants. All experiments performed on CIFAR-100split dataset.
Table A.4: Comparison with GEM-variants on Permuted-MNIST dataset. We followed all experimental settingsfrom A-GEM (Chaudhry et al., 2019). We report the performance on single epoch training for 17 randompermuted MNIST except 3 cross-validation tasks from 20 total tasks, mini-batch is 10 and size of episodicmemory in GEMs is 256. We refered the experimental results for GEM variants from Chaudhry et al. (2019).
Table A.5: Comparison With HAT (Serr》 et al., 2018) on sequence of 8 heterogeneous dataset. We follow allexperimental settings from HAT and reproduce the performance of HAT directly from the author’s code. Weperform the experiments with 5 different (randomly generated) task order sequences. We use forgetting measureas Average Forgetting and Worst-case Forgetting from (Chaudhry et al., 2019).
Table A.6: Full experiment results on CIFAR-100 Split and CIFAR-100 Superclass datasets. The results are themean accuracies over 3 runs of experiments with random splits, preformed with 5 different task order sequences(standard deviation into parenthesis).
