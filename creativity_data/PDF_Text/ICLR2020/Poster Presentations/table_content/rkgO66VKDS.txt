Table 1: Comparison of low precision networks on ImageNet. Techniques compared are QIL (Junget al., 2018), FAQ (McKinstry et al., 2018), LQ-Nets (Zhang et al., 2018), PACT (Choi et al., 2018b),Regularization (Choi et al., 2018c), and NICE (Baskin et al., 2018).
Table 2: ResNet-18 top-1 accuracy for various weight decay values.
Table 3: Top-1 accuracy for various gradient scale values and learning rates for 2-bit ResNet-18.
Table 4: Accuracy for low precision networks trained with LSQ and knowledge distillation, which isimproved over using LSQ alone, with 3-bit networks reaching the accuracy of full precision (32-bit)baselines (shown for comparison).
