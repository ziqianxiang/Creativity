Table 1: Out-of-distribution AUROC for randompriors (RP), deep ensembles (DE), deep ensem-bles with adversarial training (DE+AT) and spa-tial concrete dropout (DR). Estimated confidenceintervals are provided in Appendix B.
Table 2: Out-of-distribution AUROC for the samemodels as above (see Tab. 1) on subsampled data.
Table 3: Out-of-distribution AUROC for random priors (RP), deep ensembles (DE), deep ensemblesWith adversarial training (DE+AT) and spatial concrete dropout (DR). The errors are computed fromten samples each in the B = 1 case. The ± symbol denotes one standard error.
Table 4: Out-of-distribution classification accuracy for random priors (RP), deep ensembles (DE),deep ensembles with adversarial training (DE+AT) and spatial concrete dropout (DR). These valuesaugment the AUROC values reported in Table 1. The ± symbol denotes one standard error.
Table 5: Out-of-distribution accuracy for the same models as above (see Tab. 4) on subsampled data.
Table 6: In-distribution supervised classification accuracies on the respective test sets of the differentdata sets for random priors (RP), deep ensembles (DE), deep ensembles with adversarial training(DE+AT) and spatial concrete dropout (DR).
Table 7: Out-of-distribution classification AUROCs on CIFAR-100 for random priors (RP), deepensembles (DE), deep ensembles with adversarial training (DE+AT) and spatial concrete dropout(DR). The ± symbol denotes one standard error.
Table 8: Out-of-distribution classification accuracy on CIFAR-100 for random priors (RP), deepensembles (DE), deep ensembles with adversarial training (DE+AT) and spatial concrete dropout(DR). The ± symbol denotes one standard error. These values augment the AUROC values reportedin Table 7.
