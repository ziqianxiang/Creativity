Table 1: Rank correlations between MIG and different versions of UDR across two datasets and threemodel classes. The performance is comparable across datasets, UDR versions and model classes. SeeFig. 6 in Supplementary Materials for comparisons with other supervised metrics.
Table 2: Rank correlations of the UDR score with the β-VAE metric on the dSprites dataset for a β-VAEhyperparameter search as the number of pairwise comparisons P per model were changed.
Table 3: Disentangled model selection metrics comparison. M - modularity, C - compactness, E -explicitness (Ridgeway & Mozer, 2018)Metric	M	C	Eβ-VAE	√	×	√FACTORVAE	√	√	√MIG	√	√	√DCI DISENTANGLEMENT √	×	×UDR	√	×	×rotation (40 values). All the generative factors are sampled from a uniform distribution. Rotation is sampledfrom the full 360 degree range. The generative process for this dataset is fully deterministic, resulting in 737,280total images produced from the Cartesian product of the generative factors.
Table 4: Encoder and Decoder Implementation details shared for all modelsEncoder	DecoderInput: 64 × 64 × number of channels 4 × 4 conv, 32 ReLU, stride 2 4 × 4 conv, 32 ReLU, stride 2 4 × 4 conv, 64 ReLU, stride 2 4 × 4 conv, 64 ReLU, stride 2 FC256,F22 × 10	Input: R10 FC, 256 ReLU FC,4 × 4 × 64 ReLU FC, 4 × 4 upconv, 64 ReLU, stride 2 FC, 4 × 4 upconv, 32 ReLU, stride 2 4 × 4 upconv, 32 ReLU, stride 2 4 × 4 upconv, number of channels, stride 2Table 5: Hyperparameters used for each model architectureModel	Parameters	Valuesβ-VAE	~β	[1,2,4,6,8,16]CCI-VAE	cmax	[5, 10, 25, 50, 75, 100]	iteration threshold	100000	γ	1000FactorVAE	γ	[10, 20, 30, 40, 50, 100]DIP-VAE-I	λod	[1, 2, 5, 10, 20, 50]	λd	10λodDIP-VAE-II	λod	[1, 2, 5, 10, 20, 50]	λd	λodTC-VAE	β	[1,2,4,6,8,10](a) Common hyperparameters across all models		(b) FactorVAE discrimina- tor architecture	(c) FactorVAE discriminator pa- rameters	Parameter	Values	Discriminator	Parameter	ValuesBatch Size	64	FC, IOOOleakyReLU	Batch size	64Latent space dimension 10		FC, 1000 leaky ReLU	Optimizer	AdamOptimizer	Adam	FC, 1OOO leaky ReLU	Adam: beta1	O.5
Table 5: Hyperparameters used for each model architectureModel	Parameters	Valuesβ-VAE	~β	[1,2,4,6,8,16]CCI-VAE	cmax	[5, 10, 25, 50, 75, 100]	iteration threshold	100000	γ	1000FactorVAE	γ	[10, 20, 30, 40, 50, 100]DIP-VAE-I	λod	[1, 2, 5, 10, 20, 50]	λd	10λodDIP-VAE-II	λod	[1, 2, 5, 10, 20, 50]	λd	λodTC-VAE	β	[1,2,4,6,8,10](a) Common hyperparameters across all models		(b) FactorVAE discrimina- tor architecture	(c) FactorVAE discriminator pa- rameters	Parameter	Values	Discriminator	Parameter	ValuesBatch Size	64	FC, IOOOleakyReLU	Batch size	64Latent space dimension 10		FC, 1000 leaky ReLU	Optimizer	AdamOptimizer	Adam	FC, 1OOO leaky ReLU	Adam: beta1	O.5Adam: beta1	0.9	FC, 1OOO leaky ReLU	Adam: beta2	O.9Adam: beta2	0.999	FC, 1OOO leaky ReLU	Adam: epsilon	1e-8Adam: epsilon	1e-8	FC, 1OOO leaky ReLU	Adam: learning rate O.OOO1	
Table 6: Miscellaneous model detailsFor consistency, all the models were trained using the same architecture, optimiser, and hyperparameters. Allof the methods use a deep neural network to encode and decode the latent embedding and the parameters ofthe latent factors are predicted using a Gaussian encoder whose architecture is specified in Table 4. All of themodels predict a latent vector with 10 factors. Each model was also trained with 6 different levels of regularisationstrength specified in Table 5. The ranges of the hyperparameters used for the various levels of regularisationwere specified to show a diversity of different performance on different datasets without relying on pre-existingintuition on good hyperparameters, however ranges were based on hyperparameters that were used previouslyin literature. For each of the model classes outlined above, we tried 6 hyperparameter values with 50 seeds each.
Table 7: Rank correlations between each of the scores produced by the four versions of UDR and foursupervised metrics. The scores are averaged over three model classes, two datasets and four supervisedmetrics. See Supplementary Material for details.
