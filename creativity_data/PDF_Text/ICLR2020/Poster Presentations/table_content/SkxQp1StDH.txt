Table 1: Properties of datasetsName	|V|	|E|	∣{du,v : du,v = ∞}∣∕∣V|2	ReciprocitySynthetic example	25	30	0.48	34.3%Political blogs	1224	19,025	0.34	24.3%Cora	23,166	91,500	0.83	5.1%arXiv hep-th	27,770	352,807	0.71	0.3%4.2	BaselinesAPP is the asymmetric proximity preserving graph embedding method [59] based on the skip-grammodel, which is used by many other methods like Node2Vec and DeepWalk. In contrast to thesymmetric counterparts, APP explicitly splits the representation into a source vector and a targetvector, which are updated in a direction-aware manner during the training with random walks withreset. Their method implicitly preserves the rooted PageRank score for any two vertices.
Table 2: Results including Pearson correlation coefficient ρ, Spearman’s rank correlation coefficientr, and mutual information (MI). The p-value for ρ and r are in all cases below 10-8. For our method,we include the results with 10 samples, 100 samples for each node, and using the full distance matrix.
Table 3: Results of the exponential power distributions for λ ∈ {2, 4, 8} and 100 samples evaluated with Pearson correlation coefficient ρ, Spearman’s rank correlation coefficient r and mutual infor- mation (MI). ρ and r were evaluated on all edges (u, v) with u 6= v using the values given by each method and the ground truth distance. The p-value for ρ and r are in all cases below 10-8.				Network	λ = 2		λ=4	λ=8Political	ρ	.77	.78	.78Blogs	r	.74	.74	.72	MI	.57 ±.005	.61 ± .005	.61 ±.005For our full method, we used no batching for the political blogs network, 410 batches for Cora and 2777 batchesfor arXiv hep-th with and without shuffling between each epoch, where we saw an increased performancewith shuffling especially for the larger datasets. The approximated approach uses no batch for the variant withB = 10 and 10 batches for B = 100.
Table 4: Results of the k-variate exponential power distributions for k ∈ {2, 5, 10, 50} of KL (full)evaluated with Pearson correlation coefficient ρ, Spearman’s rank correlation coefficient r and mutualinformation (MI). ρ and r were evaluated on all edges (u, v) with u 6= v using the values given byeach method and the ground truth distance. The P-ValUe for P and r are in all cases below 10-8.
Table 5: Comparision of results of elliptical embedding on political blogs and our methodMethod	P	r	MIElliptical	-0.17	-0.14	.04± .004KL (full)	0.88	0.89	.85± .006APP	0.16	0.29	.15± .006HOPE	0.45	0.45	.65± .007DeepWalk	0.25	0.24	.12± .005Graph2Gauss	-0.17	-0.33	.09± .005For the Political blogs network, we have evaluated as an additional baseline the elliPtical embedding [36]. Thework [36] of Muzellec et al. studies the problem of embedding objects as elliptical probability distributions,which are the generalization of Gaussian multivariate densities. Their work is rooted in the optimal transporttheory by using the Wasserstein distance. The physical interpretation of this distance in the case of optimaltransport is given by the cost of moving mass from one distribution to another one (see Monge-Kantorovichtransportation problem [41]). In particular, for univariate Gaussian distributions, the Wasserstein distancebetween embedded points becomes the two-dimensional Euclidean distance of (μι,σι) and (μ2,σ2), i.e. flatgeometry. In our case, the geometry of univariate Gaussians has constant negative curvature, and distance ismeasured with the Fisher distance. Our work is rooted in statistical manifold theory, where the Fisher distancesarise from measuring the distinguishability between different distributions. According to the results in Table 5,we observe that this method is not outperforming our method.
Table 6: ReSUItS on UndireCted network HamSterSterNetwork	APP		HOPE	DeepWalk	Graph2Gauss	KL (10)	KL (100)	KL (full)Hamsterster	ρ	-.03	.23	.36	-.26	.17	.19	.91	r	.45	.37	.37	-.76	.12	.12	.89	avg. MI	.29	.43	.10	.45	.63	.64	.89	std. MI	.006	.007	.006	.005	.005	.004	.00516Published as a conference paper at ICLR 2020Table 7: Results of graph reconstruction for the political blogs networkMethod	out-degree precision	in-degre precisionAPP	0.1077	0.2624HOPE	0.1010	0.1125DeepWalk	0.2620	0.1669Graph2Gauss	0.0258	0.0003Elliptical	0.0383	0.0250KL (full)	0.2861	0.2329Figure 4: Relative effect of correction ▽ L in comparison to VL. Starting from the same representa-tion, we optimized with gradient descent optimization with VL and VL with learning rate 1 * 10-6.
Table 7: Results of graph reconstruction for the political blogs networkMethod	out-degree precision	in-degre precisionAPP	0.1077	0.2624HOPE	0.1010	0.1125DeepWalk	0.2620	0.1669Graph2Gauss	0.0258	0.0003Elliptical	0.0383	0.0250KL (full)	0.2861	0.2329Figure 4: Relative effect of correction ▽ L in comparison to VL. Starting from the same representa-tion, we optimized with gradient descent optimization with VL and VL with learning rate 1 * 10-6.
