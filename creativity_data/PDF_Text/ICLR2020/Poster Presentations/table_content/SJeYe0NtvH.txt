Table 1: Example greedy completions showing representative examples of the MLE model’s de-generate single-token repetition (top), phrase-level repetition (middle), and ‘structural’ repetition(bottom), as well as the proposed method’s ability to fix these degenerate behaviors.
Table 2: Results for token-level objectives (upper) and sequence-level fine-tuning (lower) accordingto sequence-level (left) and token-level (right) metrics using the test subset of Wikitext-103.
Table 3: Human eval results. * denotes statistical significance (2-sided binomial test, p < .05).
Table 4: Top: Degenerate repetition in completions from a state-of-the-art large-scale languagemodel (Radford et al., 2019). The examples contain single-word repetitions, phrase-level repetitions,and structural repetitions where some tokens within a repeating phrase vary. Recently proposedstochastic samplers (top-k, nucleus) exhibit degeneration based on hyper-parameter settings.
Table 5: Results for token-level objectives (upper) and sequence-level fine-tuning (lower) accordingto sequence-level (left) and token-level (right) metrics using the validation subset of wikitext-103.
Table 6: Stochastic decoding results according to sequence-level (left) and token-level (right) met-rics using the test subset of Wikitext-103.
Table 7: GPT-2 results according to sequence-level and token-level metrics using the validationsubset of wikitext-103. seq-rep-4 is computed on the word level; ppl, acc, rep, wrep are computedon the BPE level.
Table 8: Results for sequence-level fine-tuning using random-seq candidates according tosequence-level (left) and token-level (right) metrics using the validation subset of wikitext-103.
Table 9: Full human evaluation results. Includes additional comparisons omitted for brevity, andthe raw number of wins and loses by each comparison.
