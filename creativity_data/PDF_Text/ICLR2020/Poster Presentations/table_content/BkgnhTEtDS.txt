Table 2: Understanding feature interactions: top global feature interactions for (a) an ad targetingsystem via Algorithm 1 and (b) a text sentiment analyzer via §6.3.2 (later). The tables are juxtaposedto assist in understanding feature interactions, i.e., nuanced changes among interacting variables leadto significant changes in prediction probabilities. The prediction outcomes are ad-clicks by users for(a) and text sentiment for (b).
Table 3: Test prediction performance by encoding top-K global interactions in baseline recom-mender systems on the Criteo and Avazu datasets (5 trials). K are 40 and 10 for Criteo and Avazurespectively. “+ GLIDER” means the inclusion of detected global interactions to correspondingbaselines. The “Setting” column is labeled relative to the source of detected interactions: AutoInt.
Table 4: # parameters of the models in Table 3. Mdenotes million.
Table 5: Prediction performance (mean-squared error; lower is better) with (k > 0) and without(k = 0) interactions for random data instances in the test sets of respective black-box models.
Table 6: Comparison of # model parameters between baseline models with enlarged embeddingsand original baselines + GLIDER (from Tables 3 and 4). The models with enlarged embeddingsare denoted by the asterick (*). The embedding dimension of sparse features is denoted by “emb.
Table 7: Test prediction performance corresponding to the models shown in Table 6Model	Criteo		Avazu		AUC	logloss	AUC	loglossWide&Deep*	0.8072 ± 3e-4	0.4443 ± 2e-4	0.7794 ± 3e-4	0.3804 ± 2e-4Wide&Deep	0.8069 ± 5e-4	0.4446 ± 4e-4	”	”+ GLIDER	0.8080 ± 3e-4	0.4436 ± 3e-4	0.7795 ± 1e-4	0.3802 ± 9e-5DeepFM*	0.8080 ± 4e-4	0.4435 ± 4e-4	0.7792 ± 3e-4	0.3804 ± 9e-5DeepFM	0.8079 ± 3e-4	0.4436 ± 2e-4	”	”+ GLIDER	0.8097 ± 2e-4	0.4420 ± 2e-4	0.7795 ± 2e-4	0.3802 ± 2e-4Deep&Cross*	0.8081 ± 2e-4	0.4434 ± 2e-4	0.7791 ± 2e-4	0.3805 ± 1e-4Deep&Cross	0.8076 ± 2e-4	0.4438 ± 2e-4	”	”+ GLIDER	0.8086 ± 3e-4	0.4428 ± 2e-4	0.7792 ± 2e-4	0.3803 ± 9e-5xDeepFM*	0.8088 ± 1e-4	0.4429 ± 1e-4	0.7785 ± 3e-4	0.3808 ± 2e-4xDeepFM	0.8084 ± 2e-4	0.4433 ± 2e-4	”	”+ GLIDER	0.8097 ± 3e-4	0.4421 ± 3e-4	0.7787 ± 4e-4	0.3806 ± 1e-4AutoInt*	0.8087 ± 2e-4	0.4431 ± 1e-4	0.7774 ± 1e-4	0.3811 ± 8e-5AutoInt	0.8083	0.4434	”	”+ GLIDER	0.8090 ± 2e-4	0.4426 ± 2e-4	0.7773 ± 1e-4	0.3811 ± 5e-514Published as a conference paper at ICLR 2020
Table 8: Top-ranked word interactions Ii from Sentiment-LSTM and BERT on randomly selectedsentences in the SST test set.
Table 9: Data generating functionswith interactionsF1 (x) =	10χ1χ2 + PI=3	xiF2 (x) =	x1x2 + P1=3	xiF3 (x) =	eχp(IxI + x2|)+ PI=3	xiF4 (x) =	10XlX2X3 + PI=4	xiWe compare the detection performances between MADEX and baselines on identifying feature inter-actions learned by complex models, i.e., XGBoost (Chen & Guestrin, 2016), Multilayer Perceptron(MLP), and Long Short-Term Memory Network (LSTM) (Hochreiter & Schmidhuber, 1997). Thebaselines are Tree-Shap: a method to identify interactions in tree-based models like XGBoost (Lund-berg et al., 2018), MLP-ACD+: a modified version of ACD (Singh et al., 2019; Murdoch et al., 2018)to search all pairs of features in MLP to find the best interaction candidate, and LSTM-ACD+: thesame as MLP-ACD+ but for LSTMs. All baselines are local interpretation methods. For MADEX,we sample continuous features from a truncated normal distribution N(x, σ2I) centered at a spec-ified data instance x and truncated at σ. Our MADEX experiments consist of two methods, NID andGradNID (shorthand for GradientNID).
Table 10: Detection Performance in R-Precision (higher the better). σ = 0.6 (max: 3.2). “Tree” isXGBoost. *Does not detect higher-order interactions. !Requires an exhaustive search of all featurecombinations.
