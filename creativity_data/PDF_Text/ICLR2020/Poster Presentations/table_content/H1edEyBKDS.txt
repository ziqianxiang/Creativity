Table 1: The PPLM employs a pre-trained language model (LM) without any changes to the modelparameters and can generate text with controlled attributes such as topic and sentiment. We demon-strate control with two tiny and easy to construct attribute models: a bag of words (BoW) related to atopic and a linear discriminator trained on top ofLM latent representations to control sentiment. Theunderlined prefix is What the LM is conditioned on to generate a passage of text (e.g. The potato).
Table 2: Comparison of the different models and distributions. All models in this table are useful indifferent scenarios. The particular advantage of PPLM is that very small, custom attribute models,p(a|x), may be combined with powerful, general pre-trained language models, p(x), to create cheapbut still powerful conditional generative models, p(x|a).
Table 3: Comparison of different samples generated by (top row) baseline GPT-2 and (other rows)PPLM with different BoW corresponding to different topics (e.g. [Military] ), all conditioned on asingle prefix: "The issue focused”. Both directly optimized (in red) and related words (in soft red)are highlighted, showing how the optimization takes effect.
Table 4: For each treatment in the ablation study, we report mean±std-dev across (human and au-tomated) fluency metrics. The topic (%) reports the fraction of samples matching the target topic,as evaluated by human annotators. Table S8 provides per-topic results. Approaches BC and B CRdemonstrate significant control over the topic of the generated text, while retaining similar diversity(Dist-1, Dist-2, Dist-3) scores and minimal degradation in Perplexity and Fluency evaluations vs thebaseline LM (B). The gain from ranking and choosing from multiple samples BR over B is limited(4.7%). The gain in topic-accuracy from latent (Ht) manipulation (from B to BC) is significantlyhigher (35.8%). Perplexity is computed using the GPT LM (Radford et al., 2018a), which differsfrom the LM generating text (GPT-2). For CTRL and WD, since human evaluation is performedin comparison with BCR via A/B testing, we report the numbers for BCR as well from these com-parisons, for the human evaluated metrics. Further, we consider one sample per prefix for CTRL,resulting in fewer samples and higher Dist-1, 2, 3 scores as a consequence. PPLM outperformsCTRL and WD on topic-relevance, while being comparable on fluency scores.
Table 5: Sentence samples in triplets, generated by {baseline GPT-2, PPLM-Discrim positive,PPLM-Discrim NEGATIVE}, conditioned on prefixes: The Chicken & The country. Words related tothe sentiment are highlighted (in soft red). Each triplet is generated from the same random seed.
Table 6: Evaluation of models/ variants on the sentiment control task, with mean±std-dev reportedacross fluency metrics. Sentiment accuracy reports the fraction of samples with an accurate tar-get sentiment. Approach BCR provides significant control over sentiment while showing minimaldegradation in fluency. See Table S9 for full results on individual sentiments. *GPT2-FT-RL is onlyevaluated for the positivity half of the task, as itis fine-tuned only for positivity (Ziegler et al., 2019).
Table S7: Control codes used for the model from Keskar et al. (2019) for experiments in Section 4.
Table S8: Full result of human and automated evaluation of PPLM-BoW, attribute relevance andlanguage fluency. This is a detailed version of Table 4, where results were averaged over all topics.
Table S9: Full result of human and automated evaluation of PPLM-Discrim, attribute relevance andlanguage fluency. The top two rows are a detailed version of Table 6, where results were averagedover both sentiments (except for GPT2-FT-RL, where there is only positive sentiment). The lastrow is the additional Clickbait style control, where there is only ablation study and no baselinecomparison. Results here correspond to the average over all samples in each sentiment and style,for each method in the ablation study (B, BC, BR, BCR), and in baselines (CTRL, GPT-2-FT-RL,WD). Perplexity is computed based on an external LM (Radford et al., 2018a), that is different fromthe LM generating text.
Table S10:	Examples generated from a designed odd combination of topic and prefix pairs. Thetopic here is [Military] . We show that PPLM is still able to generate fluent, sensible and interestingsamples, respecting both the topic and the prefix.
Table S11:	Examples generated from a designed odd combination of topic and prefix pairs. Thetopic here is [Legal] . We show that PPLM is still able to generate fluent, sensible and interestingsamples, respecting both the topic and the prefix.
Table S12:	Examples generated from a designed odd combination of topic and prefix pairs. Thetopic here is [Computers] . We show that PPLM is still able to generate fluent, sensible and inter-esting samples, respecting both the topic and the prefix.
Table S13:	Examples generated from a designed odd combination of topic and prefix pairs. Thetopic here is [Politics] . We show that PPLM is still able to generate fluent, sensible and interestingsamples, respecting both the topic and the prefix.
Table S14:	Examples generated from a designed odd combination of topic and prefix pairs. Thetopic here is [Religion] . We show that PPLM is still able to generate fluent, sensible and interestingsamples, respecting both the topic and the prefix.
Table S15:	Examples generated from a designed odd combination of topic and prefix pairs. Thetopic here is [Space] . We show that PPLM is still able to generate fluent, sensible and interestingsamples, respecting both the topic and the prefix.
Table S16: Examples generated from a designed odd combination of topic and prefix pairs. Thesentiment here is [Positive] and [Negative] . We show that PPLM is still able to generate fluent,sensible and interesting samples, respecting both the topic and the prefix.
Table S17: Comparison of different sentences generated by (top row) unconditioned GPT-2 and(other rows) our approach using GPT-2 with the same bags-of-words with different strength factors,while using the same prefix: "The potato".
Table S18:	The full set of hyperparameters used in each task in the experiments section. Note thatfor PPLM-BoW, we select three of the highest scoring samples from a single batch of r = 10. ForPPLM-Discrim, we get 1 sample per batch, across 3 batches of r = 10.
Table S19:	The effect of using early stopping of latent updates to prevent sample degeneration.
Table S20:	Skeleton story generation with different attribute models. Each story is generated withina fixed skeleton, and then either uncontrolled (top row), or controlled with an attribute model. Key-words that signify the controlled effect are highlighted.
Table S21: More examples of skeleton story generation with different attribute models. Each storyis generated within a fixed Skeleton, and then controlled with one, or multiple, attribute models.
Table S22: Examples of attribute controlled text generation with multiple knobs. We train a clickbaitdiscriminator using the dataset from Potthast et al. (2018)[Computers] [Fantasy] [Clickbait] The Pizza-themed, Pizza-themed, Pizza-themed gamethat has everyone guessing, has finally released! The game, known as Pizza-Pocalypse, hasreleased on Steam and on GOG. Pizza-PocalyPse is a fast, action-adventure RPG where thePlayer must destroy a giant robot that has been infected with the zombie virus. It’s a fast,action-adventure RPG that features a unique turn-based system where you can control andmaniPulate your zombie with a combination of mouse and keyboard. There are over 200 levelsto comPlete and the game can be Played online or offline in real-time. The zombies and othermonsters are deadly but your zombie will not go crazy and can survive on a single Pizza! Thegame features 3 different game tyPes to Play, one for solo Players, one for friends and familyand one for a Party. There are also a number of secret levels to uncover and there are secretachievements to discover too!. . .
Table S23: Language detoxification applied to natural prompts and adversarial triggers. Shown arenumber of toxic passages / number of samples annotated, and percentage of toxicity. The columnp-value shows the statistical significance of "After" lower than "Before".
Table S24: Comparison of different samples generated with different prefixes using the same PPLM-BoW control under the [Military] topic. All samples are generated using exact same hyperparam-eters.
Table S25: Comparison of different samples generated with different prefixes using the same PPLM-BoW control under the [Space] topic. All samples are generated using exact same hyperparameters.
Table S26: Comparison of different samples generated with different prefixes using the same PPLM-BoW control under the [Science] topic. All samples are generated using exact same hyperparame-ters.
Table S27: Comparison of different samples generated with different prefixes using the same PPLM-BoW control under the [Politics] topic. All samples are generated using exact same hyperparame-ters.
