Table 1: Norm (metric) properties of different architectures. As compared to Euclidean architectures,ours are universal asymmetric semi-norm approximators (UA) and can use propositions to optionallysatisfy (*) N1 and N4. Neural metrics relax the unnecessary homogeneity constraint on metrics.
Table 2: Metric nearness for sym. (S) andasym. (A) matrices in R200×200 (10 seeds).
Table 4: Graph experiments. (a) Statistics for different graphs. (b) Test MSE after 1000 epochs attraining size |D| = 50000 (3 seeds). The best metric (and overall result if different) is bolded.
Table 5: MSE on 2d norm test set (target norm value = 1) for the best configuration of each type(allowing for early stopping), for each data size (16 and 128) and target norm.
Table 6: MSE on 2d norm test set (target norm value = 2) for the best configuration of each type(allowing for early stopping), for each data size (16 and 128) and target norm.
Table 7: MSE on 2d norm test set (target norm value = 0.5) for the best configuration of each type(allowing for early stopping), for each data size (16 and 128) and target norm.
Table 8: Value Function Architecturesfθ	# Hiddens	#	Layers	Act. Func.	Concave Units Pool Func.
