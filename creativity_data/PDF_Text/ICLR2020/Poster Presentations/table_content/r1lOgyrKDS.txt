Table 1: Comparison of various algorithms in terms of the Generalization score on the Karel dataset.						Methods	MLE	SC	MC-0	MC-2	RLbeam	ARSMGeneralization (validation)	13.6	12.51	12.64	13.56	14.76	17.07Generalization (test)	12.76	12.12	12.56	12.76	14.92	16.284.1 Neural program synthesisNPS is a challenging representative task in contextual categorical sequence generation. First, thereward is only available after finishing the whole sequence. Second, the initial reward signals areoften sparse because the generated programs rarely succeed in the beginning of training. We followBunel et al. (2018) to investigate an NPS task: for data sample i consisting of a set of input-outputstates {Iim, Oim}m=1,Mi, the goal is to learn a synthesizer parameterized by θ to generate a programλi, which will produce a sequence of categorical actions to map input state Iim to output state Oim(i.e., λi(Iim) = Oim) for all m ∈ {1, . . . , Mi}. The evaluation metric is Generalization (Bunel et al.,2018), defined as the proportion of the test instances {Iim0 , Oim0 }m=1,Mi that satisfy λi0 (Iim0 ) = Oim0for all m ∈ {1, ..., Mi}. We evaluate on the Karel dataset (Devlin et al., 2017a), consisting of 10, 000training reference Karel programs1 with 2, 500 validation and 2, 500 test samples. Each programconsists of a sequence of actions to move an agent inside a grid-world from one starting grid (input)to an end grid (output). The size of the action space V is 53 and average program length is around 20.
Table 2: Performance comparison on the test set of COCO-caption dataset.
