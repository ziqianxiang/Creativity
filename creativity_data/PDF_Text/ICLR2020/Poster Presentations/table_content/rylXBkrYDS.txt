Table 1:	Few-shot accuracies on benchmark datasets for 5-way few-shot episodes. The notation conv(64k)×4 denotes a CNN with 4 layers and 64k channels in the kth layer. Best results in each column are shownin bold. Results where the support-based initialization is better than or comparable to existing algorithmsare denoted by t. The notation (train + Val) indicates that the backbone was pre-trained on both training andvalidation sets of the datasets; the backbone is trained only on the training set otherwise. (Lee et al., 2019) uses a1.25× wider ReSNet-12 which we denote as ReSNet-12 *.
Table 2:	Accuracy (%) on the few-shot data of ImageNet-21k. The confidence intervals are large because wecompute statistics only over 80 few-shot episodes so as to test for large number of ways.
Table 3: Few-shot accuracies on benchmark datasets for 5-way few-shot episodes. The notation conv(64k)×4 denotes a CNN with 4 layers and 64k channels in the kth layer. The rows are grouped by the backbonearchitectures. Best results in each column and for a given backbone architecture are shown in bold. Resultswhere the support-based initialization is better than or comparable to existing algorithms are denoted by ’.
Table 4: Few-shot accuracies on Meta-Dataset: Best results in each row are shown in bold. 600 few-shotepisodes were used to compare to the results reported in Triantafillou et al. (2019).
