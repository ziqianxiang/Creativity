Table 1: Quantitative results on image to image translation. Diversity and fidelity are measured usingLPIPS and FID, respectively. Pix2Pix Isola et al. (2017), BicycleGAN Zhu et al. (2017b), MSGANMao et al. (2019), and DSGAN Yang et al. (2019) are included in the comparisons. DSGAN adoptsa different setting (denoted as 20s in the table) by generating 20 samples per input for computingthe scores. We report results under both settings.
Table 2: Quantitative results on high resolution image Table 3: Quantitative results on face in-to image translation. Diversity and fidelity are mea- painting. Diversity and fidelity are mea-sured using LPIPS and FID, respectively.
Table A.1: Quantitative results with different sizes of input latent code and intermediate layer. m+ndenotes the size of latent code and intermediate layer.
Table A.2: Quantitative results with different sizes of input latent code and intermediate layer. m+ndenotes the size of latent code and intermediate layer.
Table A.3: Speed in testing, memory usage in training, and overall trainable parameter numbers.
