Table 1: Performance on WIKITEXT- 1 03. The kNN-LM substantially outperforms existing work.
Table 2: Performance on BOOKS, showing that kNN-LM works well in multiple domains.
Table 3: Experimental results on Wiki-3B. The model trained on 100M tokens is augmented witha datastore that contains about 3B training examples, outperforming the vanilla LM trained on theentire Wiki-3B training set.
Table 4: Domain adaptation experiments, with results on Books. Adding an in-domain datastoreto a Wikipedia-trained model improves results by 23 points, approaching in-domain training.
Table 5: Wikitext- 1 03 validation results using dif-ferent states from the final layer of the LM as the rep-resentation function f (∙) for keys and queries. We re-trieve k=1024 neighbors and λ is tuned for each.
Table 6: Another example where the kNN model places much higher probability mass on the correcttarget, compared to the LM. The nearest neighbors search has retrieved a training set context that isextremely similar to the test context, while very rare and in the long-tail of patterns.
Table 7: In this example, the desired date pattern appears in many examples. Yet, the nearestneighbors search is able to identify the only training set context which is relevant to the test contextand assigns it the highest probability mass.
Table 8: In this case, the model is able to memorize the fact that Georges Bizet wrote Carmen.
Table 9: This is an example where the pkNN distribution is relatively flat, as several words areplausible continuations. However, the nearest neighbors search assigns the highest probability tothe correct target and a corresponding context that is particularly relevant. In contrast, the LMprobability on the correct target is lower.
