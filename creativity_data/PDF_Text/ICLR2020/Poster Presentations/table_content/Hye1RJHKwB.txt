Table 1: The architecture of our generator on the MNIST dataset. All layers have biases.
Table 2: The architecture of our discriminators on the paired MNIST dataset. W = 28 for marginal,W = 56 for dependency discriminators.
Table 3: The architecture of our MNIST classifier. Dropout with probability 0.5 is applied to FC1outputs.
Table 4: The architecture of our convolutional generator. “ConvT” represent transposed convolutions.
Table 5: The architecture of our convolutional discriminator. All layers except FC have biases. W, Hand C are set for each task so that the dimensions of the input data are matched.
Table 6: The architecture of our U-Net. The height H and number of input channels C depends onthe experiment. MP is maxpooling with stride 2. FC has noise as input. UpConv performs transposedconvolution with stride 2. Concat concatenates the current feature map with one from the downstreampath. The final output is computed depending on the task (see text for more details)Layer	Input (shape)	Outputs	Output shapeDoubleConv1	2W × 128 × C	32	2W × 128 × 32MP1	2W × 128 × 32	32	2W-1 × 64× 32DoubleConv2	2W-1 × 64 × 32	64	2W-1 × 64× 64MP2	2W-1 × 64 × 64	64	2W-2 × 32 × 64DoubleConv3	2W-2 × 32 × 64	64	2W-2 × 32 × 128MP3	2W-2 × 32 × 128	128	2W-3 × 16 × 128DoubleConv4	2W-3 × 16 × 128	256	2W-3 × 16 × 256MP4	2W-3 × 16 × 256	256	2W-4 × 8 × 256DoubleConv5	2W-4 × 8 × 256	256	2W-4 × 8 × 256FC	50	2W-4 ∙ 16	2W-4 × 8 × 2Concat	DoubleConv5	-	2W-4 × 8 × 258UpConv	2W-4 × 8 × 258	256	2W-3 × 16 × 258Concat	DoubleConv4	514	2W-3 × 16 × 514Conv	2W-3 × 16 × 514	128	2W-3 × 16 × 128UpConv	2W-3 × 16 × 128	128	2W-2 × 32 × 128
Table 7: The DoubleConv neural network block used in the U-Net. Conv uses a 3 × 3 filter size.
