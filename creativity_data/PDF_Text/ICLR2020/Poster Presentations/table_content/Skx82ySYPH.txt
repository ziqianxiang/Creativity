Table 1: Ablative comparison for 5 different configurations where V0: Baseline, V1: V0 + Cross-border detection, V2: V1 + Descriptor up-sampling, V3: V2 + LIO, and finally the proposed methodV4: V3 + Ldesc . In general, the results indicate that for most metrics, the proposed method is withinreasonable margin of the best-performing model variant, while achieving strong generalization per-formance across all performance metrics including repeatability, localization error, homographyaccuracy and matching score.
Table 2: Our proposed method outperforms all the listed traditional and learned feature detectors inrepeatability (higher is better). For localization error (lower is better), UnsuperPoint performs betterin lower resolution images while our method performs better for higher resolutions.
Table 3: Homography estimation accuracy with 3 different pixel distance thresholds (i.e. Cor-1,3and 5) and matching performance comparison. As shown, our proposed method outperforms all thelisted traditional and learning based methods except the one case where SIFT performs the best.
Table 4: Detailed analysis of the performance of our method: we evaluate on different splits of theHPatches dataset (Illumination, Viewpoint and complete dataset) on images of resolution 320x240.
Table 5: Detailed analysis of the performance of our method on the Bark, Boat and Graffitti se-quences of the HPatches dataset. To capture the variance in the evaluation of the homography(Cor-1,3 and 5) due to RANSAC, we perform 10 evaluation runs with different random seeds andreport the mean and standard deviation.
Table 6: KeyPointNet diagram, composed of an encoder followed by three decoder heads. Thenetwork receives as input an RGB image and returns scores, locations and descriptors. Numbers inparenthesis indicate input layers, 0 denotes feature concatenation, and We used 0.2 dropout values.
Table 7: IO-Net diagram, composed of 4 residual blocks. The network receives as input a series of5-dimensional vector consists of keypoint pair and descriptor distance, outputs a binary inlier-outlierclassification. Numbers in parenthesis indicate input layers, and ãŠ‰ denotes feature addition.
