Table 1: 3D object detection results on KITTI validation. We report APBEV / AP3D (in %) of the car category,corresponding to average precision of the bird’s-eye view and 3D object detection. We arrange methodsaccording to the input signals: M for monocular images, S for stereo images, L for 64-beam LiDAR, and L# forsparse 4-beam LiDAR. PL stands for PSEUDO-LIDAR. Our PSEUDO-LIDAR ++ (PL++) with enhanced depthestimation — SDN and GDC— are in blue. Methods with 64-beam LiDAR are in gray. Best viewed in color.
Table 3: Ablation study on depth estimation. Wereport APBEV / AP3D (in %) of the car category atIoU= 0.7 on KITTI validation. DL: depth loss.
Table 2: Results on the car category on the test set.
Table 4: Ablation study on leveraging sparse Li-DAR. We report APBEV / AP3D (in %) of the car cate-gory at IoU= 0.7 on KITTI validation. L#: 4-beamLiDAR signal alone. SDN + L#: pseudo-LiDAR withdepths of landmark pixels replaced by 4-beam LiDAR.
Table 5: Results of pedestrians (top) and cy-clists (bottom) on KITTI validation. We apply F-POINTNET Qi et al. (2018) and report APBEV / AP3D(in %) at IoU= 0.5, following Wang et al. (2019a).
Table 6: Ablation study on stereo depth estimation. We report APBEV / AP3D (in %) of the car category atIoU= 0.7 on the KITTI validation set. DL stands for depth loss.
Table 7: Ablation study on leveraging sparse LiDAR. We report APBEV / AP3D (in %) of the car category atIoU= 0.7 on the KITTI validation set. L# stands for 4-beam LiDAR signal. SDN +L# means we replace thedepth of a portion of pseudo-LiDAR points (i.e., landmark pixels) by L#.
Table 8: Ablation study on the sparsity of LiDAR. We report APBEV / AP3D (in %) of the car category atIoU= 0.7 on the KITTI validation set. L# stands for using sparse LiDAR signal alone. The number in bracketsindicates the number of beams in use.
Table 9: Comparison of GDC and PnP for 3D object detection. We report APBEV / AP3D (in %) of the carcategory at IoU= 0.7 on the KITTI validation set, using SDN + PNP or SDN + GDC for depth estimation andP-RCNN or PIXOR? for detection.
Table 10: Comparison of 3D object detection using the naive and optimized implementation of GDC. Wereport APBEV / AP3D (in %) of the car category at IoU= 0.7 on the KITTI validation set, using P-RCNN fordetection.
Table 11: Median depth estimation errors over various depth ranges (numerical values of Figure 4).
Table 12: Mean depth estimation errors (with standard deviation) over various depth ranges.
Table 13: 3D object detection at various depth ranges. We compare different input signals. We report APBEV /AP3D (in %) of the car category at IoU= 0.7 on the KITTI validation set, using P-RCNN for detection. In thelast two rows we show the number of car objects in KITTI object train and validation sets within different ranges.
