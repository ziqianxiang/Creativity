Table 1: Specifications of different convolutions. Latency is measuredusing an input of size 1×256×32×64 on 1080Ti with TensorRT library.
Table 2: Supernet’s sensitivity to latencyunder different granularities. Input size: (1,3, 1024, 2048).
Table 3: Ablation studies of different search and training strategies.
Table 5: mIoU and inference FPS on CamVid test set. The input resolution is 720 × 960.			Table 6: mIoU and inference FPS on BDD validation set. The input resolution is 720 × 1280.		Method	mIoU (%)	FPS	Method	mIoU (%)	FPSENet (Paszkeetal., 2016)	68.3	61.2	DRN-D-22 (Yu et al., 2017)	53.2	21.0ICNet (Zhao et al., 2018)	67.1	27.8	DRN-D-38 (Yu et al., 2017)	55.2	12.9BiSeNet (Yu et al., 2018a)	65.6	269.1	FasterSeg (ours)	55.1	318.0CAS (Zhang et al., 2019)	71.2	169.0			FasterSeg (ours)	71.1	398.1			5	ConclusionWe introduced a novel multi-resolution NAS framework, leveraging successful design patterns inhandcrafted networks for real-time segmentation. Our NAS framework can automatically discoverFasterSeg, which achieved both extremely fast inference speed and competitive accuracy. Our searchspace is intrinsically of low-latency and is much larger and challenging due to flexible searchableexpansion ratios. More importantly, we successfully addressed the “architecture collapse” problem,by proposing the novel regularized latency optimization of fine-granularity. We also demonstratethat by seamlessly extending to teacher-student co-searching, our NAS framework can boost thestudent’s accuracy via effective distillation.
Table 7: Cells used in FasterSeg. Left: cells for branch with final downsample rate of 16. Right: cells forbranch with final downsample rate of 32. s: downsample rate. χ: expansion ratio. c_out: number of outputchannels.
