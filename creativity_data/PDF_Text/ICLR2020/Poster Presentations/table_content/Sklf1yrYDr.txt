Table 1: Computational and memory costs on Split-CIFAR100 on LeNet. Numbers are relative tovanilla neural network.
Table 3: Validation accuracy on ResNet32. En-semble with size 4. MC-drop stands for Dropoutensemble (Gal & Ghahramani, 2015).					Single	MC-drop	BatchE	NaiveEC10	95.31	95.72	95.94	96.30C100	78.32	78.89	80.32	81.02lowed by dropout before the final linear classifier so that the number of parameters of MC-dropout arethe same as BatchEnsemble. Most hyper-parameters are shared across the single model, BatchEnsem-ble, and MC-dropout. More details about hyper-parameters are in Appendix B. Note that we increasethe training iterations for BatchEnsemble to reach its best performance because each ensemblemember gets only a portion of input data.
Table 4: Contextual bandits regret. Results are relative to the cumulative regret of the Uniformalgorithm. We report the mean and standard error of the mean over 30 trials. Ensemble size with 4, 8.
Table 5: Validation accuracy on ResNet32 with proportional training data. Ensemble with size 4.
Table 6: Supplementary result to Table 3. NaiveSmall is naive ensemble of 4 ResNet14x4 models.
