Published as a conference paper at ICLR 2020
A Stochastic Derivative Free Optimization
Method with Momentum
Eduard Gorbunov*	Adel Bibi
MIPT, Russia and IITP RAS, Russia and RANEPA, Russia KAUST, Saudi Arabia
eduard.gorbunov@phystech.edu	adel.bibi@kaust.edu.sa
Ozan Sener
Intel Labs
ozan.sener@intel.com
El Houcine Bergou
KAUST, Saudi Arabia and MaIAGE, INRA, France
elhoucine.bergou@inra.fr
Peter Richtarik
KAUST, Saudi Arabia and MIPT, Russia
peter.richtarik@kaust.edu.sa
Ab stract
We consider the problem of unconstrained minimization of a smooth objective
function in Rd in setting where only function evaluations are possible. We propose
and analyze stochastic zeroth-order method with heavy ball momentum. In particu-
lar, we propose, SMTP, a momentum version of the stochastic three-point method
(STP) Bergou et al. (2019). We show new complexity results for non-convex,
convex and strongly convex functions. We test our method on a collection of
learning to continuous control tasks on several MuJoCo Todorov et al. (2012) envi-
ronments with varying difficulty and compare against STP, other state-of-the-art
derivative-free optimization algorithms and against policy gradient methods. SMTP
significantly outperforms STP and all other methods that we considered in our
numerical experiments. Our second contribution is SMTP with importance sam-
pling which we call SMTP_IS. We provide convergence analysis of this method
for non-convex, convex and strongly convex objectives.
1 Introduction
In this paper, we consider the following minimization problem
min f (x),	(1)
x∈Rd
where f : Rd → R is "smooth" but not necessarily a convex function in a Derivative-Free Opti-
mization (DFO) setting where only function evaluations are possible. The function f is bounded
from below by f(x*) where x* is a minimizer. Lastly and throughout the paper, we assume that f is
L-smooth.
DFO. In DFO setting Conn et al. (2009); Kolda et al. (2003), the derivatives of the objective function
f are not accessible. That is they are either impractical to evaluate, noisy (function f is noisy) (Chen,
2015) or they are simply not available at all. In standard applications of DFO, evaluations of f are
only accessible through simulations of black-box engine or software as in reinforcement learning and
continuous control environments Todorov et al. (2012). This setting of optimization problems appears
also in applications from computational medicine Marsden et al. (2008) and fluid dynamics Allaire
(2001); Haslinger & Mackinen (2003); Mohammadi & Pironneau (2001) to localization Marsden
et al. (2004; 2007) and continuous control Mania et al. (2018); Salimans et al. (2017) to name a few.
The literature on DFO for solving (1) is long and rich. The first approaches were based on deterministic
direct search (DDS) and they span half a century of work Hooke & Jeeves (1961); Su (1979); Torczon
*The research of Eduard GorbUnov was supported by RFBR, project number 18-31-20005 mol_a_ved
1
Published as a conference paper at ICLR 2020
(1997). However, for DDS methods complexity bounds have only been established recently by the
work of Vicente and coauthors Vicente (2013); Dodangeh & Vicente (2016). In particular, the work
of Vicente Vicente (2013) showed the first complexity results on non-convex f and the results were
extended to better complexities when f is convex Dodangeh & Vicente (2016). However, there
have been several variants of DDS, including randomized approaches Matyas (1965); Karmanov
(1974a;b); Baba (1981); Dorea (1983); Sarma (1990). Only very recently, complexity bounds have
also been derived for randomized methods Diniz-Ehrhardt et al. (2008); Stich et al. (2011); Ghadimi
& Lan (2013); Ghadimi et al. (2016); Gratton et al. (2015). For instance, the work of Diniz-Ehrhardt
et al. (2008); Gratton et al. (2015) imposes a decrease condition on whether to accept or reject a
step of a set of random directions. Moreover, Nesterov & Spokoiny (2017) derived new complexity
bounds when the random directions are normally distributed vectors for both smooth and non-smooth
f . They proposed both accelerated and non-accelerated zero-order (ZO) methods. Accelerated
derivative-free methods in the case of inexact oracle information was proposed in Dvurechensky et al.
(2017). An extension of Nesterov & Spokoiny (2017) for non-Euclidean proximal setup was proposed
by Gorbunov et al. (2018) for the smooth stochastic convex optimization with inexact oracle. In Stich
(2014a;b) authors also consider acceleration of ZO methods and, in particular, develop the method
called SARP, proved that its convergence rate is not worse than for non-accelerated ZO methods and
showed that in some cases it works even better.
More recently and closely related to our work, Bergou et al. (2019) proposed a new randomized direct
search method called Stochastic Three Points (STP). At each iteration k STP generates a random
search direction sk according to a certain probability law and compares the objective function at three
points: current iterate xk, a point in the direction of sk and a point in the direction of -sk with a
certain step size αk . The method then chooses the best of these three points as the new iterate:
xk+1 = argmin{f(xk),f(xk + αksk),f(xk - αksk)}.
The key properties of STP are its simplicity, generality and practicality. Indeed, the update rule for
STP makes it extremely simple to implement, the proofs of convergence results for STP are short
and clear and assumptions on random search directions cover a lot of strategies of choosing decent
direction and even some of first-order methods fit the STP scheme which makes it a very flexible in
comparison with other zeroth-order methods (e.g. two-point evaluations methods like in Nesterov &
Spokoiny (2017), Ghadimi & Lan (2013), Ghadimi et al. (2016), Gorbunov et al. (2018) that try to
approximate directional derivatives along random direction at each iteration). Motivated by these
properties of STP we focus on further developing of this method.
Momentum. Heavy ball momentum1 is a special technique introduced by Polyak in 1964 Polyak
(1964) to get faster convergence to the optimum for the first-order methods. In the original paper,
Polyak proved that his method converges locally with O (pL∕μlog 1∕ε) rate for twice continuously
differentiable μ-strongly convex and L-smooth functions. Despite the long history of this approach,
there is still an open question whether heavy ball method converges to the optimum globally with
accelerated rate when the objective function is twice continuous differentiable, L-smooth and μ-
strongly convex. For this class of functions, only non-accelerated global convergence was proved
Ghadimi et al. (2015) and for the special case of quadratic strongly convex and L-smooth functions
Lessard et. al. Lessard et al. (2016) recently proved asymptotic accelerated global convergence.
However, heavy ball method performs well in practice and, therefore, is widely used. One can find
more detailed survey of the literature about heavy ball momentum in Loizou & RiChtdrik (2017).
Importance Sampling. Importance sampling has been celebrated and extensively studied in stochas-
tic gradient based methods Zhao & Zhang (2015) or in coordinate based methods Richtdrik & TakaC
(2016). Only very recently, Bibi et al. (2019) proposed, STP_IS, the first DFO algorithm with
importance sampling. In particular, under coordinate-wise smooth function, they show that sampling
coordinate directions, can be generalized to arbitrary directions, with probabilities proportional to the
function coordinate smoothness constants, improves the leading constant by the same factor typically
gained in gradient based methods.
Contributions. Our contributions can be summarized into three folds.
• First ZO method with heavy ball momentum. Motivated by practical effectiveness of
first-order momentum heavy ball method, we introduce momentum into STP method and
1We will refer to this as momentum.
2
Published as a conference paper at ICLR 2020
Algorithm 1 SMTP: Stochastic Momentum Three Points
Require: learning rates {γk}k≥0, starting point x0 ∈ Rd, D — distribution on Rd, 0 ≤ β < 1 —
momentum parameter
1:	Set v-1 = 0 and z0 = x0
2:	for k = 0, 1, . . . do
3:	Sample Sk 〜D
4:	Let	v+k =	βvk-1 + sk and v-k = βvk-1 - sk
5:	Let	xk++1	= xk - γkv+k and xk-+1 = xk - γkv-k
6:	Let	z++1	= x++1 一 ιγ-βv+ and z-+1 = x-+1 一 ιγ-βv-
7:	Set	zk+1	= arg min {f (zk), f (z++1),f (z-+1)}
(x+++∖ if zk+1 = z++1	(vk+∖	if zk + 1	= z++1
8:	Set	xk+1	= xk-+1, if zk+1 = z-k+1 and vk+1 =	v-k+1,	if zk+1	= z-k+1
[x+, if z++1 = z+	[v+, if z++1 = z+
9:	end for
propose new DFO algorithm with heavy ball momentum (SMTP). We summarized the
method in Algorithm 1, with theoretical guarantees for non-convex, convex and strongly
convex functions under generic sampling directions D. We emphasize that the SMTP with
momentum is not a straightforward generalization of STP and Polyak’s method and requires
insights from virtual iterates analysis from Yang et al. (2016).
To the best of our knowledge it is the first analysis of derivative-free method with heavy
ball momentum, i.e. we show that the same momentum trick that works for the first order
method could be applied for zeroth-order methods as well.
•	First ZO method with both heavy ball momentum and importance sampling. In order
to get more gain from momentum in the case when the sampling directions are coordinate
directions and the objective function is coordinate-wise L-smooth (see Assumption 4.1), we
consider importance sampling to the above method. In fact, we propose the first zeroth-order
momentum method with importance sampling (SMTP_IS) summarized in Algorithm 2 with
theoretical guarantees for non-convex, convex and strongly convex functions. The details
and proofs are left for Section 4 and Appendix E.
•	Practicality. We conduct extensive experiments on continuous control tasks from the
MuJoCo suite Todorov et al. (2012) following recent success of DFO compared to model-
free reinforcement learning Mania et al. (2018); Salimans et al. (2017). We achieve with
SMTP_IS the state-of-the-art results on across all tested environments on the continuous
control outperforming DFO Mania et al. (2018) and policy gradient methods Schulman et al.
(2015); Rajeswaran et al. (2017).
We provide more detailed comparison of SMTP and SMTP_IS in Section E.4 of the Appendix.
2 Notation and Definitions
We use k ∙ kp to define 'p-norm of the vector X ∈ Rd: ∣∣xkp =f(Pd=i ∣x∕p) / for P ≥ 1 and
∣∣xk∞ def maxi∈[d] ∣x∕ where Xi is the i-th component of vector x, [d] = {1,2,..., d}. Operator E[∙]
denotes mathematical expectation with respect to all randomness and Es〜D [∙] denotes conditional
expectation w.r.t. randomness coming from random vector s which is sampled from probability
distribution D on Rd. To denote standard inner product of two vectors X, y ∈ Rd we use hX, yi d=ef
Pid=1 Xiyi, ei denotes i-th coordinate vector from standard basis in Rd, i.e. X = Pid=1 Xiei. We use
k ∙ ∣∣* to define the conjugate norm for the norm ∣∣∙∣∣: ∣∣x∣∣* = max {(a,x)| a ∈ Rd, ∣a∣ ≤ 1}.
As we mention in the introduction we assume throughout the paper2 that the objective function f is
L-smooth.
2We will use thinner assumption in Section 4.
3
Published as a conference paper at ICLR 2020
Assumptions on f	SMTP Complexity	Theorem	Importance Sampling	SMTP_IS Complexity	Theorem
None	2r0LYD	3.1	Li	Li	2rod Pi=I Li	E.1
	~Db2τ~		pi = Pd=I L	ε2	
Convex, Ro < ∞	1LYDRO ln (2ro) ε μD	ε ε /	3.2	L ∙ 一	Li	ROd Pd=ι Li in (2ro)	E.2
			pi = Pd=ι Li		
μ-strongly convex	4 ln (2ro) μμD	ε ε -,	3.5	L ∙ 一	Li	Pd=I Li in (誓)	E.5
			pi = PLI Li		
Table 1: Summary of the new derived complexity results of SMTP and SMTP_IS. The complexities
for SMTP are under a generic sampling distribution D satisfying Assumption 3.1 while for SMTP_IS
are under an arbitrary discrete sampling from a set of coordinate directions following Bibi et al.
(2019) where we propose an importance sampling that improves the leading constant marked in red.
Note that ro = f (xo) - f (x*) and that all assumptions listed are in addition to Assumption 2.1.
Complexity means number of iterations in order to guarantee Ek ▽/(ZK) ∣∣d ≤ ε for the non-convex
case, E f(zK) - f(x*) ≤ ε for convex and strongly convex cases. R0 < ∞ is the radius in
k ∙ kD-norm of a bounded level set where the exact definition is given in Assumption 3.2. We
notice that for SMTP_IS ∣∣ ∙ ∣∣d = ∣∣ ∙ kι and ∣∣ ∙ ∣∣D = ∣∣ ∙ ∣∣∞ in non-convex and convex cases and
k』D = Il ∙ ∣2 in the strongly convex case.
Assumption 2.1. (L-smoothness) We say that f is L-smooth if
∣Vf(x)-Vf(y)∣∣2 ≤ Lkx - y∣2 ∀x,y ∈ Rd.	(2)
From this definition one can obtain
If(y) - f(χ) - hVf(χ),y - χi∣ ≤ L∙∣∣y - χ∣2, ∀χ,y ∈ Rd,	(3)
and if additionally f is convex, i.e. f(y) ≥ f(x) + hVf (x), y - xi, we have
∣Vf(x)∣22 ≤ 2L(f(x) - f(x*)), ∀x∈Rd.	(4)
3 Stochastic Momentum Three Points (SMTP)
Our analysis of SMTP is based on the following key assumption.
Assumption 3.1. The probability distribution D on Rd satisfies the following properties:
1.	The quantity YD d=f Es 〜D ∣∣s∣2 is finite.
2.	There is a constant μD > 0 for a norm ∣∣ ∙ ∣∣d in Rd such that for all g ∈ Rd
Es〜D∣hg, si| ≥ μD∣∣g∣D.	(5)
Some examples of distributions that meet above assumption are described in Lemma 3.4 from
Bergou et al. (2019). For convenience we provide the statement of the lemma in the Appendix (see
Lemma F.1).
Recall that one possible view on STP Bergou et al. (2019) is as following. If we substitute gradient
Vf(xk) in the update rule for the gradient descent xk+1 = xk - γkVf(xk) by ±sk where sk is
sampled from distribution D satisfied Assumption 3.1 and then select xk+1 as the best point in terms
of functional value among xk, xk - γksk, xk + γksk we will get exactly STP method. However,
gradient descent is not the best algorithm to solve unconstrained smooth minimization problems and
the natural idea is to try to perform the same substitution-trick with more efficient first-order methods
than gradient descent.
We put our attention on Polyak’s heavy ball method where the update rule could be written in the
following form:
vk = βvk-1 + Vf(xk), xk+1 = xk - γkvk.	(6)
As in STP, we substitute Vf(xk) by ±sk and consider new sequences {v+k }k≥0 and {v-k }k≥0
defined in the Algorithm 1. However, it is not straightforward how to choose next xk+1 and vk and
4
Published as a conference paper at ICLR 2020
the virtual iterates analysis Yang et al. (2016) hints the update rule. We consider new iterates z+k+1 =
xk++1 - γ—βv+ and z-+1 = x-+1 - γ-βV- and define zk+1 as arg min {f (zk),f (z++1),f (z-+1)}.
Next we update xk+1 and vk in order to have the same relationship between zk+1, xk+1 and vk as
between z+k+1, xk++1 and v+k and z-k+1, xk-+1 and v-k . Such scheme allows easily apply virtual iterates
analysis and and generalize Key Lemma from Bergou et al. (2019) which is the main tool in the
analysis of STP.
By definition of zk+1, we get that the sequence {f(zk)}k≥0 is monotone:
f(zk+1) ≤f(zk)	∀k≥0.	(7)
Now, we establish the key result which will be used to prove the main complexity results and
remaining theorems in this section.
Lemma 3.1. Assume that f is L-smooth and D satisfies Assumption 3.1. Then for the iterates of
SMTP the following inequalities hold:
f(zk+1) ≤ f(Zk) - Jl"f (zk), Skil + Lγk)22 kskk2	(8)
1 - β	2(1 - β)2
and
Esk 〜D ff (Zk+1)] ≤ f(zk) - γ-μβ ∣∣Vf(zk )kD + L(Y Y) ；D .	(9)
3.1	Non-Convex Case
In this section, we show our complexity results for Algorithm 1 in the case when f is allowed to be
non-convex. In particular, We show that SMTP in Algorithm 1 guarantees complexity bounds with
the same order as classical bounds, i.e. 1∕√K where K is the number of iterations, in the literature.
We notice that query complexity (i.e. number of oracle calls) of SMTP coincides with its iteration
complexity up to numerical constant factor. For clarity and completeness, proofs are left for the
appendix.
Theorem 3.1. Let Assumptions 2.1 and 3.1 be satisfied. Let SMTP with γ k ≡γ > 0 produce points
{z0, z1,..., zκ-1} and ZK is chosen uniformly at random among them. Then
EfkVf(ZK)∣∣d] ≤
(I - e)(f (XO) - f (X*)) +	LYYD
KγμD	2μD (1 ) β)
(10)
Moreover, if we choose Y = √γ= the complexity (10) reduces to
EfkVf (ZK )∣∣d ]
≤ ɪ ((1) β)(f(z0)- f (x*)) +	LY0YD )
一√K V	γoμD	2〃d (1 - β) J
(11)
Then Y0
∕2(1-β)2(f(x0)-f(x*))
L	LYD
minimizes the right-hand side of (11) and for this choice we have
EfkVf(ZK)∣∣d] ≤
,2(f(x0)- f(x*)) LYD
μD Vk
(12)
In other words, the above theorem states that SMTP converges no worse than STP for non-convex
problems to the stationary point. In the next sections we also show that theoretical convergence
guarantees for SMTP are not worse than for STP for convex and strongly convex problems. However,
in practice SMTP significantly outperforms STP. So, the relationship between SMTP and STP
correlates with the known in the literature relationship between Polyak’s heavy ball method and
gradient descent.
3.2	Convex Case
In this section, we present our complexity results for Algorithm 1 when f is convex. In particular, we
show that this method guarantees complexity bounds with the same order as classical bounds, i.e.
1/K, in the literature. We will need the following additional assumption in the sequel.
5
Published as a conference paper at ICLR 2020
Assumption 3.2. We assume that f is convex, has a minimizer x* and has bounded level set at x0:
Ro = max {∣∣x - x*kD | f (x) ≤ f(x0)} < +∞,
(13)
where kξ k*D d=efmax {hξ, x)| ∣∣x∣∣d ≤ 1} defines the dual norm to ∣∣∙∣∣d.
From the above assumption and Cauchy-Schwartz inequality we get the following implication:
f(x) ≤ f(X0)=⇒ f(x) - f(x*) ≤ hvf(x),X - χ*i≤ INf(X)IIDIlx - x*kD ≤ RokVf(X)IID,
which implies
kVf(x)kD ≥ f(X) -f(x*)	∀x : f(x) ≤ f(xo).	(14)
R0
Theorem 3.2 (Constant stepsize). Let Assumptions 2.1, 3.1 and 3.2 be satisfied. If we set γk ≡ γ <
(1-μβ)R0, then for the iterates of SMTP method thefollowing inequality holds:
Ef(Zk)- f(x*)] ≤ (1- ⅛ )k(f(x0)- f(x*))+
LγγDR0
2(I- β)μD
(15)
Ifwe choose Y = ELY-^D for some 0 < ε ≤ LYDRO and run SMTP for k = K iterations where
K =1S ln f 2(f(x0)- f(x*))) ,	(1
ε	μD	∖	ε	)
then we will get E f (zK) - f(x*) ≤ ε.
In order to get rid of factor ln 2(f(x )-f(x )) in the complexity We consider decreasing stepsizes.
Theorem 3.3 (Decreasing stepsizes). Let Assumptions 2.1, 3.1 and 3.2 be satisfied. If we set
Yk = αk+θ, where a = q-μDR and θ ≥ 2, then for the iterates of SMTP method the following
inequality holds:
E f(zk)]- f (x*)≤ η⅛r max {f (x0) - f (x*),αθ2L⅛}，	(17)
where η d 篇.Then, if we choose γk = α⅞⅛ where a =(、*)Ro and run SMTP for k = K
iterations where
K =L 2R2 max {(1 - β)2(f(x0)- f (x*)),LγD } - 2(I- FR ,	ε> 0,	(18)
ε μD	μD
we get E f(zK) - f(x*) ≤ ε.
We notice that if We choose β sufficiently close to 1, We Will obtain from the formula (18) that
2R0LγD
εμD
K≈
3.3	Strongly Convex Case
In this section we present our complexity results for Algorithm 1 when f is μ-strongly convex.
Assumption 3.3. We assume that f is μ-strongly convex with respect to the norm ∣∣ ∙ ∣∣D:
f (y) ≥ f (x) + hVf(x),y - x) + μ(ky - XkD)2,	∀x,y ∈ Rd.	(19)
It is well known that strong convexity implies
kVf(x)kD ≥ 2μ (f(x) - f(x*)).	(20)
6
Published as a conference paper at ICLR 2020
Theorem 3.4 (Solution-dependent stepsizes). Let Assumptions 2.1, 3.1 and 3.3 be satisfied. If we
set Yk = (1-βLθkμD J2μ(f(zk) 一 f (x*)) for some θk ∈ (0, 2) such that θ = inf {2θk — YDθ2} ∈
L	k≥0
(0, L∕(μD μ)), thenfor the iterates of SMTP, the following inequality holds:
Ef(Zk)]—f (x*)
(21)
Then, Ifwe run SMTP for k = K iterations where
K
K 1 f f (x0) — f (x*)
研 ln(-ε—
ε > 0,
(22)
where K =f L is the condition number ofthe objective, we will get E [f (ZK)] — f (x*) ≤ ε.
Note that the previous result uses stepsizes that depends on the optimal solution f (x*) which is often
not known in practice. The next theorem removes this drawback without spoiling the convergence rate.
However, we need an additional assumption on the distribution D and one extra function evaluation.
Assumption 3.4. We assume thatfor all S 〜D we have ∣∣sk2 = 1.
Theorem 3.5 (Solution-free stepsizes). Let Assumptions 2.1, 3.1, 3.3 and 3.4 be satisfied. If addi-
tionally we compute f (Zk + tsk), set Yk = (1—e)|f(zk+tsk)-f (zk)∖∕(Lt) for t > 0 and assume that D
is such that μD ≤ L∕μ, thenfor the iterates of SMTP thefollowing inequality holds:
E [f (zk)] — f (x*) ≤ (1 一 μDμ) k f (χ0) — f (x*)) + *.	(23)
Moreover, for any ε > 0 if we set t such that
0<t≤
4εμD μ
~Ur~
(24)
and run SMTP for k = K iterations where
K ln (2(f(x0)— f(x*))
μD	∖	ε
(25)
where K =f L is the condition number of f, we will have E [f (ZK)] — f (x*) ≤ ε.
4 Stochastic Momentum Three Points with Importance Sampling
(SMTP_IS)
In this section we consider another assumption, in a similar spirit to Bibi et al. (2019), on the objective.
Assumption 4.1 (Coordinate-wise L-smoothness). We assume that the objective f has coordinate-
wise Lipschitz gradient, with Lipschitz constants L1, . . . , Ld > 0, i.e.
f (x + hei) ≤ f (x) + Vif (x)h + Lih2,	∀x ∈ Rd,h ∈ R,	(26)
where Vif (x) is i -th partial derivative of f at the point X.
For this kind of problems we modify SMTP and present STMP_IS method in Algorithm 2. In general,
the idea behind methods with importance sampling and, in particular, behind SMTP_IS is to adjust
probabilities of sampling in such a way that gives better convergence guarantees. In the case when f
satisfies coordinate-wise L-smoothness and Lipschitz constants Li are known it is natural to sample
direction sk = ei with probability depending on Li (e.g. proportional to Li). One can find more
detailed discussion of the importance sampling in Zhao & Zhang (2015) and RiChtdrik & Takdc
(2016).
Now, we establish the key result which will be used to prove the main complexity results of STMP_IS.
7
Published as a conference paper at ICLR 2020
Algorithm 2 SMTP_IS: Stochastic Momentum Three Points with Importance Sampling
Require: stepsize parameters wι,...,wn > 0, probabilities pι,...,Pn > 0 summing to 1, starting
point x0 ∈ Rd, 0 ≤ β < 1 — momentum parameter
1:	Set v-1 = 0 and z0 = x0
2:	for k = 0, 1, . . . do
3:	Select ik = i with probability pi > 0
4:	Choose stepsize Yk proportional to ɪ
wik
5:	Let	v+k =	βvk-1 + eik and v-k = β vk-1 - eik
6:	Let	xk++1	= xk - γik v+k and xk-+1 = xk - γik v-k
7:	Let	z++1	= xk++1 - 1γ-βv+ and z-+1 = x-+1 -	1γ-βV-
8:	Set	zk+1	= arg min {f (zk), f (z++1),f (z-+1)}
(x+++∖ if zk+1 = z++1	(v++∖	if zk + 1	= z++1
9:	Set	xk+1	= xk-+1, if zk+1 = z-k+1 and vk+1 =	v-k+1,	if zk+1	= z-k+1
[x+, if z++1 = Zk	[vk,	if z++1 = zk
10:	end for
Lemma 4.1. Assume that f satisfies Assumption 4.1. Then for the iterates of SMTP_IS the following
inequalities hold:
f(zk+1) ≤ f(zk)-三|Vikf(zk)| + LkM辛	(27)
1 - β	2(1 - β)
and
Esk〜D [f(zk+1)] ≤ f (zk) - ɪE [γk∣Vikf(zk)| | zk] +	1 E [Lik (γk)2 | zk] . (28)
1 - β	2(1 - β)
Due to the page limitation, we provide the complexity results of SMTP_IS in the Appendix.
5	Experiments
Experimental Setup. We conduct extensive experiments3 on challenging non-convex problems on
the continuous control task from the MuJoCO suit Todorov et al. (2012). In particular, we address
the problem of model-free control of a dynamical system. Policy gradient methods for model-free
reinforcement learning algorithms provide an off-the-shelf model-free approach to learn how to
control a dynamical system and are often benchmarked in a simulator. We compare our proposed
momentum stochastic three points method SMTP and the momentum with importance sampling
version SMTP_IS against state-of-art DFO based methods as STP_IS Bibi et al. (2019) and ARS
Mania et al. (2018). Moreover, we also compare against classical policy gradient methods as TRPO
Schulman et al. (2015) and NG Rajeswaran et al. (2017). We conduct experiments on several
environments with varying difficulty Swimmer-v1, Hopper-v1, HalfCheetah-v1, Ant-v1,
and Humanoid-v1.
Note that due to the stochastic nature of problem where f is stochastic, we use the mean of the
function values of f(xk), f(xk+) and f (xk- ), see Algorithm 1, over K observations. Similar to the
work in Bibi et al. (2019), we use K = 2 for Swimmer-v1, K = 4 for both Hopper-v1 and
HalfCheetah-v1, K = 40 for Ant-v1 and Humanoid-v1. Similar to Bibi et al. (2019), these
values were chosen based on the validation performance over the grid that is K ∈ {1, 2, 4, 8, 16}
for the smaller dimensional problems Swimmer-v1, Hopper-v1, HalfCheetah-v1 and
K ∈ {20, 40, 80, 120} for larger dimensional problems Ant-v1, and Humanoid-v1. As for
the momentum term, for SMTP we set β = 0.5. For SMTP_IS, as the smoothness constants
are not available for continuous control, we use the coordinate smoothness constants of a θ pa-
rameterized smooth function fθ (multi-layer perceptron) that estimates f. In particular, consider
running any DFO for n steps; with the queried sampled {xi, f(xi)}in=1, we estimate f by solving
θn+ι = argminj Pii(f (Xi) - f(xi； θ))2. See Bibi et al. (2019) for further implementation details
3The code will be made available online upon acceptance of this work.
8
Published as a conference paper at ICLR 2020
Swimmer-v1
draweR egarevA
100	150	200	250
Number of Episodes
ə0"BjəAV
Hopper-v1
0-
400	1000	2 000	3000	4000
Number of Episodes
pjba^əH ə0"BjəAV
HalfCheetah-v1
5000-
4000-
3000-
2000-
1000-
0-
2000	4000	6000	8000 10000 12000 14000
Number of Episodes
draweR egarevA
Ant-v1
20000 40000 60000 80000 100000 120000 140000
Number of Episodes
STP
SMTP
6000-
ə0"BjəAV
100000	200000	300000	400000
Number of Episodes
Figure 1: SMTP is far superior to STP on all 5 different MuJoCo tasks particularly on the high
dimensional Humanoid-v1 problem. The horizontal dashed lines are the thresholds used in Table
2 to demonstrate complexity of each method.
Table 2: For each MuJoCo task, we report the average number of episodes required to achieve a
predefined reward threshold. Results for our method is averaged over five random seeds, the rest is
copied from (Mania et al., 2018) (N/A means the method failed to reach the threshold. UNK means
the results is unknown since they are not reported in the literature.)
	Threshold	STP	STPIS	SMTP	SMTPIS	ARS(V1-t)	ARS(V2-t)	NG-lin	TRPO-nn
Swimmer-v1	325	320	110	80	100	100	427	1450	N/A
Hopper-v1	3120	3970	2400	1264	1408	51840	1973	13920	10000
HalfCheetah-v1	3430	13760	4420	1872	1624	8106	1707	11250	4250
Ant-v1	3580	107220	43860	19890	14420	58133	20800	39240	73500
Humanoid-v1	6000	N/A	530200	161230	207160	N/A	142600	130000	UNK
as we follow the same experimental procedure. In contrast to STP_IS, our method (SMTP) does not
required sampling from directions in the canonical basis; hence, we use directions from standard
Normal distribution in each iteration. For SMTP_IS, we follow a similar procedure as Bibi et al.
(2019) and sample from columns of a random matrix B .
Similar to the standard practice, we perform all experiments with 5 different initialization and measure
the average reward, in continuous control we are maximizing the reward function f, and best and
worst run per iteration. We compare algorithms in terms of reward vs. sample complexity.
Comparison Against STP. Our method improves sample complexity of STP and STP_IS sig-
nificantly. Especially for high dimensional problems like Ant-v1 and Humanoid-v1, sample
efficiency of SMTP is at least as twice as the STP. Moreover, SMTP_IS helps in some experiments by
improving over SMTP. However, this is not consistent in all environments. We believe this is largely
due to the fact that SMTP_IS can only handle sampling from canonical basis similar to STP_IS.
Comparison Against State-of-The-Art. We compare our method with state-of-the-art
DFO and policy gradient algorithms. For the environments, Swimmer-v1, Hopper-v1,
HalfCheetah-v1 and Ant-v1, our method outperforms the state-of-the-art results. Whereas for
Humanoid-v1, our methods results in a comparable sample complexity.
6	Conclusion
We have proposed, SMTP, the first heavy ball momentum DFO based algorithm with convergence
rates for non-convex, convex and strongly convex functions under generic sampling direction. We
specialize the sampling to the set of coordinate bases and further improve rates by proposing a
momentum and importance sampling version SMPT_IS with new convergence rates for non-convex,
convex and strongly convex functions too. We conduct large number of experiments on the task of
9
Published as a conference paper at ICLR 2020
controlling dynamical systems. We outperform two different policy gradient methods and achieve
comparable or better performance to the best DFO algorithm (ARS) on the respective environments.
References
G. Allaire. Shape Optimization by the Homogenization Method. Springer, New York, USA, 2001.
N. Baba. Convergence of a random optimization method for constrained optimization problems. Journal of
Optimization Theory and Applications, 33:1-11, 1981.
El Houcine Bergou, Eduard Gorbunov, and Peter Richtdrik. Stochastic three points method for unconstrained
smooth minimization. arXiv preprint arXiv:1902.03591, 2019.
Adel Bibi, El Houcine Bergou, Ozan Sener, Bernard Ghanem, and Peter Richtdrik. Stochastic derivative-free
optimization method with importance sampling. arXiv preprint arXiv:1902.01272, 2019.
Ruobing Chen. Stochastic derivative-free optimization of noisy functions. PhD thesis at Lehigh University.,
2015.
A. R. Conn, K. Scheinberg, and L. N. Vicente. Introduction to Derivative-Free Optimization. SIAM, Philadelphia,
PA, USA, 2009.
M. A. Diniz-Ehrhardt, J. M. Martinez, and M. Raydan. A derivative-free nonmonotone line-search technique for
unconstrained optimization. Journal of Optimization Theory and Applications, 219:383-397, 2008.
Mahdi Dodangeh and LUis N Vicente. Worst case complexity of direct search under convexity. Mathematical
Programming, 155(1-2):307-332, 2016.
C. Dorea. Expected number of steps of a random optimization method. Journal of Optimization Theory and
Applications, 39:165-171, 1983.
Pavel Dvurechensky, Alexander Gasnikov, and Alexander Tiurin. Randomized similar triangles method: A
unifying framework for accelerated randomized optimization methods (coordinate descent, directional search,
derivative-free method). arXiv preprint arXiv:1707.08486, 2017.
Euhanna Ghadimi, Hamid Reza Feyzmahdavian, and Mikael Johansson. Global convergence of the heavy-ball
method for convex optimization. In 2015 European Control Conference (ECC), pp. 310-315. IEEE, 2015.
Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic program-
ming. SIAM Journal on Optimization, 23(4):2341-2368, 2013.
Saeed Ghadimi, Guanghui Lan, and Hongchao Zhang. Mini-batch stochastic approximation methods for
nonconvex stochastic composite optimization. Mathematical Programming, 155(1-2):267-305, 2016.
E. Gorbunov, P. Dvurechensky, and A. Gasnikov. An accelerated method for derivative-free smooth stochastic
convex optimization. arXiv preprint arXiv:1802.09022, 2018.
S. Gratton, C. W. Royer, L. N. Vicente, and Z. Zhang. Direct search based on probabilistic descent. SIAM
Journal on Optimization, 25(3):1515-1541, 2015.
J.	Haslinger and R.A.E. Mackinen. Introduction to Shape Optimization: Theory, Approximation, and Computa-
tion. SIAM, Philadelphia, PA, USA, 2003.
R. Hooke and T.A. Jeeves. Direct search solution of numerical and statistical problems. J. Assoc. Comput. Mach,
8:212-229, 1961.
V.	G. Karmanov. Convergence estimates for iterative minimization methods. USSR Computational Mathematics
and Mathematical Physics, 14:1-13, 1974a.
V.	G. Karmanov. On convergence of a random search method in convex minimization problems. Theory of
Probability and its applications, 19:788-794, 1974b.
T. G. Kolda, R. M. Lewis, and V. J. Torczon. Optimization by direct search: New perspectives on some classical
and modern methods. SIAM Review, 45:385-482, 2003.
Laurent Lessard, Benjamin Recht, and Andrew Packard. Analysis and design of optimization algorithms via
integral quadratic constraints. SIAM Journal on Optimization, 26(1):57-95, 2016.
10
Published as a conference paper at ICLR 2020
Nicolas Loizou and Peter Richtdrik. Momentum and stochastic momentum for stochastic gradient, newton,
proximal point and subspace descent methods. arXiv preprint arXiv:1712.09677, 2017.
Horia Mania, Aurelia Guy, and Benjamin Recht. Simple random search provides a competitive approach to
reinforcement learning. arXiv preprint arXiv:1803.07055, 2018.
A. L. Marsden, M. Wang, J. E. Dennis, and P. Moin. Optimal aeroacustic shape design using the surrogate
management framework. Optimization and Engineering,5:235-262, 2004.
A. L. Marsden, M. Wang, J. E. Dennis, and P. Moin. Trailing-edge noise reduction using derivative-free
optimization and large-eddy simulation. Journal of Fluid Mechanics, 5:235-262, 2007.
A.	L. Marsden, J. A. Feinstein, and C. A. Taylor. A computational framework for derivative-free optimization
of cardiovascular geometries. Computer Methods in Applied Mechanics and Engineering, 197:1890-1905,
2008.
J. Matyas. Random optimization. Automation and Remote Control, 26:246-253, 1965.
Konstantin Mishchenko, Eduard Gorbunov, Martin Takdc, and Peter Richtdrik. Distributed learning with
compressed gradient differences. arXiv preprint arXiv:1901.09269, 2019.
B.	Mohammadi and O. Pironneau. Applied Shape Optimization for Fluids. Clarendon Press, Oxford, 2001.
Y. Nesterov and V. Spokoiny. Random gradient-free minimization of convex functions. Foundations of
Computational Mathematics, 17:527-566, 2017.
Boris T Polyak. Some methods of speeding up the convergence of iteration methods. USSR Computational
Mathematics and Mathematical Physics, 4(5):1-17, 1964.
Aravind Rajeswaran, Kendall Lowrey, Emanuel V Todorov, and Sham M Kakade. Towards generalization and
simplicity in continuous control. In Advances in Neural Information Processing Systems, pp. 6550-6561,
2017.
Peter Richtdrik and Martin Takdc. On optimal probabilities in stochastic coordinate descent methods. OptimiZa-
tion Letters, 10(6):1233-1243, 2016.
Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, and Ilya Sutskever. Evolution strategies as a scalable
alternative to reinforcement learning. arXiv preprint arXiv:1703.03864, 2017.
M. Sarma. On the convergence of the Baba and Dorea random optimization methods. Journal of Optimization
Theory and Applications, 66:337-343, 1990.
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region policy
optimization. In International Conference on Machine Learning, pp. 1889-1897, 2015.
S.	U. Stich, C. L. Muller, and B. Gartner. Optimization of convex functions with random pursuit. arXiv preprint
arXiv:1111.0194, 2011.
Sebastian U Stich. Convex optimization with random pursuit. PhD thesis, ETH Zurich, 2014a.
Sebastian Urban Stich. On low complexity acceleration techniques for randomized optimization. In International
Conference on Parallel Problem Solving from Nature, pp. 130-140. Springer, 2014b.
Yu Wen Su. Positive basis and a class of direct search techniques. Scientia Sinica (in Chinese), 9(S1):53-67,
1979.
Emanuel Todorov, Tom Erez, and Yuval Tassa. Mujoco: A physics engine for model-based control. In Intelligent
Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on, pp. 5026-5033. IEEE, 2012.
Virginia Torczon. On the convergence of pattern search algorithms. SIAM Journal on optimization, 7(1):1-25,
1997.
Lu^s Nunes Vicente. Worst case complexity of direct search. EURO Journal on Computational Optimization, 1
(1-2):143-153, 2013.
Tianbao Yang, Qihang Lin, and Zhe Li. Unified convergence analysis of stochastic momentum methods for
convex and non-convex optimization. arXiv preprint arXiv:1604.03257, 2016.
Peilin Zhao and Tong Zhang. Stochastic optimization with importance sampling for regularized loss minimization.
In international conference on machine learning, pp. 1-9, 2015.
11
Published as a conference paper at ICLR 2020
A Stochastic Derivative Free Optimization Method with
Momentum
(Supplementary Material)
A Preliminaries
We first list the main assumptions.
Assumption A.1. (L-smoothness) We say that f is L-smooth if:
kVf(x)-Vf(y)∣∣2 ≤ Lkx - yk2 ∀x,y ∈ Rd.	(29)
Assumption A.2. The probability distribution D on Rd satisfies the following properties:
1.	The quantity YD = Es 〜D ∣∣s∣∣2 is positive and finite.
2.	There is a constant μD > 0 and norm ∣∣ ∙ ∣∣d on Rd such thatfor all g ∈ Rd
Es〜D∣hg,si∣ ≥ μDIlglID.	(3O)
We establish the key lemma which will be used to prove the theorems stated in the paper.
Lemma A.1. Assume that f is L-smooth and D satisfies Assumption A.2. Then for the iterates of
SMTP the following inequalities hold:
f(zk+1) ≤ f(Zk) - JKVf(Zk), Ski∣ + L(Yk)2 ∣skk2	(31)
1 - β	2(1 - β)2
and
Esk〜D [f(zk+1)] ≤ f(zk) - Y-βkVf(zk)∣D + L((Yk)；D .	(32)
Proof. By induction one can show that
Ykβ vk-1
1 - β
(33)
Z
k
—
xk
That is, for k this we get	0 this recurrence holds and update rules for Zk, xk and vk-1 do not brake it. From z++1	=	x++1 - 1γ-ββv+ = xk-Ykv+ -1+ =xk - LVk = xk -工VkT-上Sk 1 - β +	1 - β	1 - β k (=)zk_	Sk =	-1 - β .
Similarly,	zk+1	=	xk+1 - ^keVk = xk - γkvk	-	γkβ-vk -	- 1 - β - - -	1 - β - =xk - - vk = xk - 士vk-ι + —	sk =	1 - β - = 1 - β	+ 1 - β k (=)Zk + 二一Sk . + 1 - β
12
Published as a conference paper at ICLR 2020
It implies that
(3)	L
f(z++1) ≤ f (Zk) + hVf(zk ),z++1-Zk i + 2 kz++1-zk k2
=f(Zk) - 1γζEf(ZkKSki + 2Lγ¾kskk2
1 - β	2(1 - β )
and
f(z-+1) ≤ f (zk ) + J hVf (Zk ),Ski + L(Yk k； ksk k2.
1 - β	2(1 - β )
Unifying these two inequalities we get
f(zk+1) ≤ min{f(z++1),f(z-+1)} = f(zk)-占KVf(Zk),sk)| + L(Y∣∣skk2,
1 - β	2(1 - β )
which proves (31). Finally, taking the expectation Esk 〜D ofboth sides of the previous inequality and
invoking Assumption A.2, we obtain
Esk〜D [f(Zk+1)] ≤ f (Zk) - YkμβkVf(Zk)kD + L((Y-IeD .
□
B Non-Convex Case
Theorem B.	1. Let Assumptions A.1 and A.2 be satisfied. Let SMTP with Yk ≡ Y > 0 produce points
{z0, Z1,..., zk-1} and ZK is chosen uniformly at random among them. Then
E [kVf(zk)kD] ≤
(I — β)(f(χ0) — f(χ*)) +	LYYD
KγμD	2〃d (1 一 β).
(34)
Moreover, ifwe choose Y = √ the complexity (34) reduces to
Then Y0 =
E [kVf(ZK)kD] ≤√√k
2(1-β)2(f(x0)-f(x*))
LYD
(I — β )(f(Z0) — f (χ*)) +	LYOYD
YoμD	2Md (1 - β)
(35)
minimizes the right-hand side of (35) and for this choice we have
E[kVf(ZK)kD] ≤
,2(f(x0)- f(x*)) LYD
μD √K
(36)
Proof. Taking full expectation from both sides of inequality (32) we get
E [kVf(Zk)kD] ≤
(1— β)E[f (Zk) — f(Zk+1)] +	LYYD
YMd	2Md (1 - β)
Further, summing up the results for k = 0, 1, . . . , K- 1, dividing both sides of the obtained inequality
by K and using tower property of the mathematical expectation we get
叫口Vf(ZK )kD]=K X E [kVf (Zk )kD] ≤(I-β)(KYμ)D- f(x*))+ 击"
The last part where Y = √γ= is straightforward.	□
13
Published as a conference paper at ICLR 2020
C Convex Case
Assumption C.1. We assume that f is convex, has a minimizer x* and has bounded level set at x0:
Ro = max {∣∣x - x*kD | f(x) ≤ f(x0)} < +∞,	(37)
def
where ∣∣ξ∣∣D = max {<ξ, x)| ∣∣x∣∣D ≤ 1} defines the dual norm to ∣∣ ∙ ∣∣d.
Theorem C.	1 (Constant stepsize). Let Assumptions A.1, A.2 and C.1 be satisfied. If we set γk ≡
Y < (1-β)R0, then for the iterates of SMTP method thefollowing inequality holds:
Ef(Zk)- f(x*)] ≤ (] -	γμD	Y f(χ0) - f(x*)) + LYYDR .	(38)
∖	(1 - β)R0 J	2(1 - β)μD
Ifwe choose Y = "Li-；R(D for some 0 < ε ≤ LYDR0 and run SMTP for k = K iterations where
K =1LDR ln (2(f(x0)- f(x*))) ,	(39)
ε μD	∖	ε	)
then we will get E f (zK)] - f(x*) ≤ ε.
Proof. From the (32) and monotonicity of {f(zk)}k≥0 we have
Es~D [f(zk+1)]	≤ f(zk) - 1γμDkVf(zk)∣D + 2Lγ⅛
1 - β	2(1 - β)
≤ f (zk) - ⅛(f(zk) - f (x*)) +「.
Taking full expectation, subtracting f(x*) from the both sides of the previous inequality and using
the tower property of mathematical expectation we get
e [f (zk+1) - f (x*)] ≤ (1 - (1-μβ⅛) E [f (zk — (x*)] + 2Lγ-YD)2.	(40)
Since Y < (1-β)R0 the term 1 - q-βDR is positive and We can unroll the recurrence (40):
Ef (Zk-W]	≤ I一⅛ )k (MT (x*)) + 2L-⅛ X (1 - ⅛ )l
≤(1 - ⅛ )k(f(x0)-f(x*)) +-X(1 - ⅛ )l
k
≤ (1-	) (f(x0)- f(x*)) +
(1 - β )R0
k
=(1- (Γ¾) (f(x0)- f(x*)) +
LY2YD	(1 - β)R0
2(1 - β)2	YMD
LYYDR0
2(1 - β)μD
Lastly, putting Y = E((LY；R: and k = K from (39) in (38) we have
2K
E[f (zK)] - f (x*)	=	(1- LμR2)	(f (x0) - f (x*)) + 2
≤ exp {-K ∙ L⅛卜f(x0)- f(x*)) + ε
(=)ε + £ =E
=2 + 2 = 2.
□
14
Published as a conference paper at ICLR 2020
Next we use technical lemma from Mishchenko et al. (2019). We provide the original proof for
completeness.
Lemma C.1 (Lemma 6 from Mishchenko et al. (2019)). Let a sequence {ak}k≥0 satisfy inequality
ak+1 ≤ (1 - γkα)ak + (γk)2N for any positive γk ≤ γ0 with some constants α > 0, N > 0, γ0 > 0.
Further, let θ ≥ W and take C Such that N ≤ α4θ C and ao ≤ C. Then, it holds
ak
C
≤ —----
≤ θk + 1
ifwe Set Yk = 02+θ.
Proof. We will show the inequality for ak by induction. Since inequality a0 ≤ C is one of our
assumptions, we have the initial step of the induction. To prove the inductive step, consider
ak+1 ≤ (1 — Ykα)ak + (γk)2N ≤ (1 -	)	+ θα C .
αk + θ αk + θ	(αk + θ)2
To show that the right-hand side is upper bounded by α(k+C)+θ, one needs to have, after multiplying
both sides by (αk + θ)(αk + α + θ)(θC)-1,
2α	αk + α + θ
(1- 0k+θ ) (αk + α + θ) + α αk + θ ≤αk + θ,
which is equivalent to
αk + α + θ
α 一 α----------- ≤ 0.
αk + θ
The last inequality is trivially satisfied for all k ≥ 0.	□
Theorem C.2 (Decreasing stepsizes). Let ASSumptionS A.1, A.2 and C.1 be SatiSfied. If we Set
γk = αk+θ，Where α =(1-dr and θ ≥ 2, then for the iterates of SMTP method the following
inequality holdS:
Ef(Zk)]- f(* ≤ η⅛ι max {f (XO) - f (X)Oθ2‰}，	(41)
where η =f θ. Then, ifwe choose Yk = a2+ where a =([岑氏。and run SMTP for k = K
iterations where
K =ε ∙ 2R0 max {(1- β)2(f(x0)- f(x*)),LγD } - 2(1 ,β)2R2 ,	ε> 0,	(42)
we get E f (zK)] - f (x*) ≤ ε.
Proof. In (40) we proved that
E f (zk+1) - f(X*)] ≤ (1- (ɪo) Ef(Zk—(x*)] + 2Lγ⅛.
Having that, We can apply Lemma C.1 to the sequence E [f (zk) - f (x*)]. The constants for
the lemma are: N = 2(L-D)2, α =([岑氏。and C
choosing Yk = a⅜⅛ is equivalent to the choice θ
max nf (x0) - f (x*), (ILYD2O and η = θ = a2 =
from (42) in the (41) we get the result.
=max {f (x0) - f (x*), aθL-β)2 }∙ Lastly,
= 2. In this case, we have aθ = 2, C =
2
2(i-β)2r2 . Putting these parameters and K
0 □
15
Published as a conference paper at ICLR 2020
D Strongly Convex Case
Assumption D.1. We assume that f is μ-strongly convex with respect to the norm ∣∣ ∙ ∣∣D:
f(y) ≥ f (x) + hVf (x),y — Xi + μ(ky — XkD)2,	∀χ,y ∈ Rd.	(43)
It is well known that strong convexity implies
INf (X)IID ≥ 2μ (f(x)- f(x*)) .	(44)
Theorem D.1 (Solution-dependent stepsizes). Let Assumptions A.1, A.2 and D.1 be satisfied. If we
Set Yk = (I-e/”。J2μ(f(zk) 一 f (x*)) for some θk ∈ (0, 2) such that θ = inf {2θk — YDθ2} ∈
L	k≥0
0, -L- ), then for the iterates of SMTP thefollowing inequality holds:
,'NDN厂	J	J	"
E[f(zk)] —f (x*)
Ifwe run SMTP for k = K iterations where
K 1 f f (x0) — f (x*)
研 ln(-ε—
ε > 0,
(45)
(46)
where K =f L is the condition number ofthe objective, we will get E [f (ZK)] — f (x*) ≤ ε.
Proof. From (32) and γk = θLDp2μ(f (xk) - f (x*)) We have
Esk〜D [f(zk+1)]- f(x*)	≤ f (zk) — f(x*) — YkμDkVf(Zk)∣D + L((Yk)2YD
1 — β	2(1 — β)
(44)f (zk) — f(x*)- YkμD,2μ(f(Zk) — f(x*))
1 — β v
+ YD θ2μD ” (f (zk) — f(x*))
L
k2
≤ f (zk) — f(x*)——詈(f (zk) — f(x*))
+yd^(f (zk) - f(x*))
≤	^1 — (2θk — γDθ2) ^-L-) (f (Zk) — f (X"))∙
Using θ = inf {2θk — YDθ2 } ∈
We get
and taking the full expectation from the previous inequality
E [f (zk+1) — f(x*)]	≤
≤
Lastly, from (45) We have
E [f (zK)] — f(x*)	≤
≤
(46)
≤
(i - θμDμ)K (f(χ0) - f(x*))
exp {-K^L^} (f (x0) — f(x*))
ε.
□
16
Published as a conference paper at ICLR 2020
Assumption D.2. We assume thatforall S ~ D we have ∣∣sk2 = L
Theorem D.2 (Solution-free stepsizes). Let Assumptions A.1, A.2, D.1 and D.2 be satisfied. If
additionally we compute f (Zk + tsk), set γk = (1-β)f(z + )-f(z " for t > 0 and assume that D
is such that μD ≤ L, thenfor the iterates of SMTP thefollowing inequality holds:
Ef (zk)] — f (x*) ≤ (l — μDμ) f(x0) - f (x*)) + 8L2tμ.	(47)
Moreover, for any ε > 0 if we set t such that
0 < t ≤ r 4εμDμ,	(48)
and run SMTP for k = K iterations where
K = ∖ ln (2(f(x0)— f (X*))) ,	(49)
μD	∖	ε	)
where K =f L is the condition number of f, we will have E [f (ZK)] 一 f (x*) ≤ ε.
Proof. Recall that from (31) we have
f(zk+1) ≤ f(zk) — 工l"f(zk), Skil + DL(Yk)22
1 — β	2(1 — β)
If we minimize the right hand side of the previous inequality as a function of γ k , we will get that
the optimal choice in this sense is Yopt = (1-β)lhvf (Z ),s i|. However, this stepsize is impractical for
derivative-free optimization, since it requires to know Vf (zk). The natural way to handle this is to
approximate directional derivative (Vf (zk), sk〉by finite difference MZ +tsj-f(z ) and that is what
we do. We choose Yk= (T)f(Zk£k)-f(Zk)I = IfEf (Zk 芹)1 + (Iff(Zk +f)-f(Zk)I -
(1-β)lhvf (Zk)Bi1 def Yopt + δk. From this we get
≤ f (zk) - f^ + / Wk)
f(Zk+1)
Next we estimate ∣δk |:
∣δk | =
≤
(3)
≤
It implies that
(1-β) ||f(zk + tsk) - f(zk)| 一 |(Vf(Zk),tskill
Lt
(ɪ) ∣f(zk + tsk) — f(zk) — (Vf(zk),tski∣
」上 ktsk∣2 =(^.
Lt	2 11	112	2
f(Zk+1)	≤ f(Zk) —
∣(Vf (Zk ),sk il2 +	L
2L + 2(1 — β )2
(1 — β )2t2
4
k kʌ l(Vf(Zk),ski∣2q Lt2
f (Z )	2l + ɪ
and after taking full expectation from the both sides of the obtained inequality we get
E [f(Zk+1) — f (x*)] ≤ E [f (Zk) — f(x*)] — ɪE [l(Vf (Zk), skil2] + L2.
2L	8
Note that from the tower property of mathematical expectation and Jensen’s inequality we have
E [l(Vf(Zk),ski∣2]	= E [Esk~d [∣(Vf(Zk),sk)|2| Zk]]
≥ Eh(ESk~。[∣(Vf(Zk),ski∣∣ Zk])2i
(≥) E [μD∣Vf(Zk)kD] (≥) 2μDμE [f(Zk) — f(x*)].
17
Published as a conference paper at ICLR 2020
Putting all together We get
E ff (zk+1) - f(x*)] ≤ (1 - μ∣μ) E f(zk) - f(x*)] + Lt2.
Due to μD ≤ L we have
Eff(Zk) - f (x*)]	≤	(1 - μLμ)k(f(x0)- f(x*)) + L2
l
≤ (1 - W)k(f(χ0)- f(x*)) + Lt2
l
Lastly, from (47) we have
(49)
≤
L2t
8μD μ
2	∖ k
1 - μDμ) (f(χ0)- f(x*)) +
Eff (zκ)]-f(x*)	≤
(48)
≤
L2t2
8〃D μ
ε
+ 2
2 + 2= ɛ.
□
18
Published as a conference paper at ICLR 2020
E SMTP_IS: Stochastic Momentum Three Points with Importance
S ampling
Again by definition of zk+1 we get that the sequence {f (zk)}k≥0 is monotone:
f(zk+1) ≤ f(zk)	∀k≥0.	(50)
Lemma E.1. Assume that f satisfies Assumption 4.1. Then for the iterates of SMTP_IS the following
inequalities hold:
f(zk+1) ≤ f(zk)-4|Vikf(zk)| + Lk(Ykk	(51)
1 - β	2(1 - β)
and
Esk 〜D [f(zk+1)] ≤ f(zk) - ɪ E [γk∣Vik f(zk )| | Zk ] +	1 E [Lik MY | zk] . (52)
1 - β	2(1 - β)
Proof. In the similar way as in Lemma A.1 one can show that
Zk = Xk — γkβ- VkT	(53)
1-β
and
Zk+1 = Zk + 2—e∙
Z-	=	+ 1-βeik.
It implies that
f(Z++1)(26)f (Zk)- τγi⅛ Vif(Zk ) + 2Lτ¾
1 - β	2(1 - β )
and
f(Z-+1)	≤ f (Zk ) + 1-β Vif (Zk ) + Lk-β22.
Unifying these two inequalities we get
f(Zk+1) ≤ min{f(Z++1),f(Z-+1)} = f(Zk)-三|V,f(Zk)| + Lk(Ykk ,
1 - β	2(1 - β )
which proves (51). Finally, taking the expectation E[∙ | Zk] conditioned on Zk from the both sides of
the previous inequality we obtain
E [f(Zk+1) | Zk] ≤ f(Zk) - ɪE [γk|Vikf(Zk)| | Zk] +	1	E [Lik(Yk)2 | Zk] ∙
1 - β	2(1 - β )
□
E.1 Non-convex Case
Theorem E.1. Assume that f satisfies Assumption 4.1. Let SMTP_IS with Yk = WL~ for some
γ > 0 produce points {z0, z1,..., zk-1} and ZK is chosen uniformly at random among them. Then
E[∣∣Vf(ZK)kι] ≤
(I - e)(f (XO) - f (X)) ,_____________γ________ 1X Lipi
KY min P	2(1 一 β) min P	w2
i=1,...,d wi	i=1,...,d wi i=1	i
(54)
19
Published as a conference paper at ICLR 2020
Moreover, if we choose Y = √^, then
E[kVf (ZK)kι]
1
≤ -ɪ=-------------
√K min P
i=1,...,d wi
(I - β)(f (XO) - f (X)) +	γ0	1X Lipi
Y0	2(I - β) = w2

Note that if we choose γ0
will get
2(1-β)2(f(x0)-f(x*))
d 7∙
P Lipi
乙 W2r~
w
i=1	i
in order to minimize right-hand side of (55), we
∖ 2(f(x0) — fS PPLwpi
E [∣∣Vf(ZK)kι] ≤ X——√=. JI 2
√K min P
i=1,...,d wi
(56)
Note that for pi = Li/Pid Li with wi = Li we have that the rates improves to
E[∣∣Vf(ZK)kι] ≤
,2(f(x°)- f(x*))dPd=ILi
√K
(57)
Proof. Recall that from (52) we have
E [f(zk+1) | Zk ] ≤ f(zk) - ɪ E bik∣Vik f(zk )| | zk] +	1 E [Lik MY | zk] . (58)
1 - β	2(1 - β)
Using our choice Yk = w- We derive
E [Yik|Vikf(zk)| | zk]
d
=γ X SiIVif(Zk )ι≥ Y kvf(zk)kι 闾 n,d W
and
E % (Yik)2 I zk]= Y2 X 誓.
i=1 wi
Putting it in (58) and taking full expectation from the both sides of obtained inequality We get
Y min P	2 d τ
E [f (zk+1)] ≤ e [f (Zk)] - -=1-βfE EkVf(Zk )kι + 271⅛ X -ɪ,
1 - β	2(1 - β) i=1 wi
Whence
kVf(Zk)k1≤
(1- β)(E[f (Zk)] - E[f(zk+1)]) +	Y	X Lipi
Y min P	2(1 一 β) min P	w2
i=1,...,d wi	i=1,...,d wi i=1	i
Summing up previous inequality for k = 0, 1, . . . ,K - 1 and dividing both sides of the result byK,
We get
1 K-1
K ∑E [kVf(Zk)kι] ≤
k=0
(I - β)(f (ZO) - f (X*D +____________Y__________ LiPi
KY min P	2(1 — β) min P w2
i=1,...,d wi	i=1,...,d wi i=1	i
K-1
It remains to notice that -K P E [kVf(Zk)kι] = E [kVf(ZK)∣∣ι]. The last part where Y = -Y= is
k=0	V
straightforward.	□
20
Published as a conference paper at ICLR 2020
E.2 Convex Case
As for SMTP to tackle convex problems by SMTP_IS We use Assumption 3.2 with ∣∣∙∣∣d = ∣∣T∣ι.
Note that in this case Ro = max {∣∣x - x*k∞ | f(x) ≤ f (x0)}.
Theorem E.2 (Constant stepsize). LetAssumptions 3.2 and 4.1 be satisfied. Ifwe set Yi = ^γ~ such
that 0 < γ ≤ (I-：，喳,thenfor the iterates of SMTP_IS method thefollowing inequality holds:
m 1T	J Wd
i=1,...,d i
E [f (zk) - f(x*)] ≤ (	Y min pi-∖ k	d	d T 1 -」卜 f(z0)-f(X*)) + 2(1-βYRm in 温 XX E. i=1,...,d wi i=1 (59) d ε(1-β) ʃ min Wi	r0 P Lp i=1,...,d wi	i=1 wi
i=1 dwi	w
Moreover, ifwe choose Y =-----------J '…,----for some 0 < ε ≤ —i=--------¾- and run SMTP_IS for
r0 p ⅛i	Lmin & W
i=1 wi	i=1,...,d i
k = K iterations where	i=1 i d R2 P LiPi K =1 0 i=ι 可 ln (2(f (XO)-f(x*))) ,	(60) ε min p2	∖	ε	) i=1...d wi
we will get E [f (ZK)] — f (x*) ≤ ε. Moreover, for Pi = LiPid Li with Wi = Li, the rate improves
to
K =1 R2dXX Li ln (2(f (XO)- f (X)
(61)
Proof. Recall that from (52) we have
E [f(zk+1) | Zk] ≤ f(zk)-占E [Yik∣Vikf(zk)| | zk] + 2(1 - β)2E [Lik WY I zk] ∙ (62)
Using our choice Yk = + We derive
d
E [YikVikf(zk) I Zk]	= YX "∣Vif(zi)∣≥ γkVf(zfc)kι, min ”
k	i=1 wi	i=1,...,d wi
(14) R .mind fi (f(zk) - f(x*))
R0 i=1,...,d wi
and
E [Lik (Yik)2 I zk]= Y2 XX Lp.
i=1 wi
Putting it in (62) and taking full expectation from the both sides of obtained inequality We get
/ Y min Pi ∖	2 d f
e [f(zk+1) - f(x*)] ≤ I1 --(T⅛≡) e [f(Zk)- f(x*)] + 2(⅛p X 罟.(63)
21
Published as a conference paper at ICLR 2020
Due to our choice of γ
negative and, therefore,
≤ (I-e)Rpi We have that the factor ( 1 -门 YR min pi- j is non-
^ i=mm,d⅜	k	(1-β)R0 i=ι,...,d wiJ
≤
≤
k
1 -(i -∖ro i=m,in,d Wi) f(z0)
+2」X 宿 X (ι-
k
1 -(i -∖ro i=m,in,d Wi) f(z0)
+2」X WX (ι-
-f(x*))
γ	pi
min
(1 - β )R0 i=1,...,d Wi
-f(x*))
γ	pi
min
(1 - β )R0 i=1,...,d Wi
1-
Y min pi-∖ k
i=1,...,d Wi \
(I- β)R0 )
(f(z0)- f (x*)) +
________γRo__________
2(1 — β) min P
i=1,...,d wi
d
X
i=1
Lipi
2.
Wi2
ε(1-β) min Wi
Then, putting Y =--------丁…..d S
R0 P Lipi
w
i=1 i
and k = K from (60) in (59) We have
f
1 -
∖
E[f(zK)] - f (x*)
(60)
.	p2 ∖
ε min 气
i=1,…,d Wi
d
R2 Pi 簧)
≤
ε min
i=1,...,d
d
R0 Pi 喑
εε
2 + 2 =ε.
K
(f(z0)-f(χ*)) + 2
Wi
(f(zo)- 〃x*))+ε
□
Theorem E.3 (Decreasing stepsizes). Let Assumptions 3.2 and 4.1 be satisfied. If we set Yik
Yk
Wik
and Yk = αk+θ，where a
following inequality holds:
min pi
=1,...,d wi	2
(i-β)Ro and θ ≥ 2, then for the iterates of SMTP_IS method the
Ef(Zk)]-f(x*) ≤ A max 卜x0)- f(x*), ^-W X Lf}, 碎
m	min Pi
def	i=1,...,d wi
where η = 忑.Moreover, if we choose Y = α20k++0 where α = ([-6再。 and run SMTP_IS for
k = K iterations where
-τ2R⅛ max{(1 - β )2(f (XO)-f (T L?)-
i=i,...,d Wii	i=i
2(1 - β)2Ro2
min
i=i,...,d
pii
wii
we will get E [f (zK)] — f (x*) ≤ ε.
ε > 0,
(65)
K
1
ε
Proof. In (63) We proved that
E[f(zk+i)- f(x*)] ≤
γ min pi-
1	i=1,…,dwi
(1 - 8 )R0
E [f (zk) - f(x*)] +
Y2	X LiPi
2(1-β)2 = F.
22
Published as a conference paper at ICLR 2020
Having that, we can apply
stants for the lemma are:
Lemma C.1 to the sequence E [f(Zk) - f(x*)].
d	min -pi
N 一	1 P Lipi	C, —	i=1,...,d Wi
N =	2(1-β)2 μ W2Γ, α =	(1-β)R0
The
and C
con-
maχ f f (χ0) - f (χ*), ɑθ(1-β)2
d
P Li pi
W w2
i= wi
Lastly, note that choosing Yk = ɑ⅜⅛ is equivalent
to choice θ = ∙∣. In this case We have αθ = 2 and C = max {f (x0) - f(x*),(二产 P LwPi ʃ
2	__min Wpi2
and η = % = Or = 2=二；2林.Putting these parameters and K from (65) in the (64) we get the
result.	□
E.3 Strongly Convex Case
TheoremE.4 (Solution-dependent stepsizes). Let Assumptions 3.3 (With ∣∣ ∙ ∣∣d = ∣∣ ∙ ∣∣ι) and 4.1
(1-β)θk ._min W -------------------
be satisfied. Ifwe set Yi =-----:'…,——-,2μ(f (Zk) — f (x*)) for some θk ∈ (0, 2) such that
Wik P Lw2i
i=1 i
Θ = k≥0{2θk - θ2 }∈ I 0,
inequality holds:
μ min	p⅝
i=1,...,d wi
, then for the iterates of SMTP_IS method the following
E[f(zk)]-f(x*)≤
k
pi2
θμ min 2-2
L i=1,…,dwi
1 — --------------
∖
If we run SMTP_IS for k = K iterations where
d
P Lipi
W w2	.
i=	wi
(66)
d
P Lipi
W W2
i=1 i
θμ min
i=,...,d
ln ( f (x0)- f(x*)
ε > 0,
(67)
K
ε
i
—
we will get E [f(ZK)] - f(x*) ≤ ε.
Proof. Recall that from (52) we have
E [f(zk+1) | Zk] ≤ f(zk) - ɪE [γik∣Vikf(zk)| | zk] +	1 E [Lik(Yk)2 I zk] ∙ (68)
1 - β	2(1 - β)
(1-β)θk ._min W ----------------------
Using our choice Yi =---------d= ,...,--,2μ(f (Zk) 一 f (x*)) we derive
Wik P 安
i=1 i
E[YikVikf(Zk) |Zk]
(1 - β)θk min Wi _________________ d
------d i..,d MIi √2μ(f(zk) - f (x*)) X N|Vif (zk)∣
P1 Lipi	i=1 i
乙w2
i= i
≥
(1-β)θk (i=m,in,dwi)
d
P
i=
,2μ(f(zk)- f(x*))∣Vf(zk)∣ι
(20)
≥
2(I- β )θk . min7 W22
i=1,...,d i
d
P Lipi
W W2
i=	Wi
μ(f(zk)- f(x*))
23
Published as a conference paper at ICLR 2020
and
2(1 - β)2θk2 min
EfLik (Yk)2 I Zk]=—…	<丁
(-P1 Lr)
2(1 - β)2θk2 min
i=1,...,d
2	JL L八
一μ(f(zk)-f(x*)) X Lp-
i=1 wi
d
P Lipi
W2 w2
i=1 wi
-μ(f(zk) — f(x*))∙
Putting it in (68) and taking full expectation from the both sides of obtained inequality we get
E ff (zk+1)- f(x*)] ≤
.	p2 \
μ mm 气
C Li = I	d Wi
1 - (2θ - θ2)；….
P Lipi
W W2	.
i=1 i
Using θ = inf {2θk - θk2 } ∈
we obtain
Eff(Zk+1)- f(x*)]	≤
Lasrtly, from (66) we have
Eff(ZK)]- f (x*)	≤
θμ min pi
Li=I,…,d Wi
1 — ------------
d
P Lipi
W W2
i=1 Wi
/
k+1
1-
1-
θμ min
i=1,...,d
d
P Lipi
W w2	.
i=1 Wi
θμ min
i=1,...,d
≤
d
P Lipi
W w2	.
i=1 Wi
/
∖
/
\
/
≤
\

\
i
i
—
K
—
(67)
≤
□
The previous result based on the choice of Yk which depends on the f (Zk) — f (x*) which is often
unknown in practice. The next theorem does not have this drawback and makes it possible to obtain
the same rate of convergence as in the previous theorem using one extra function evaluation.
TheoremE.5 (Solution-free stepsizes). LetAssumPtions3.3(With k』D = ∣∣ ∙ k2 )and4.1 besatisfied.
If additionally we compute f (zk + teij, set Yk = (1 β)lf(z ；+。；卜) MZ )| for t > 0, then for the
ik
iterates of SMTP_IS method the following inequality holds:
e ff (zk )]-f(x*)	≤ (1	- μ. min d	L Yf(XO)-f (x*))	+ 8“	二:pi	X Pi Li.
∖ i=1,...,d	Li)	8μ	min	-?—	' .
i=1,...,d Li i=1
(69)
24
Published as a conference paper at ICLR 2020
Moreover, for any ε > 0 if we set t such that
0 < t ≤ uu
t
4εμ min P
l=1,...,d Li
d
P pi Li
i=1
(70)
and run SMTP_IS for k = K iterations where
K =---------；----P- In
μ min P
i=1,...,d Li
2(f (x0)- f(x*))
(71)
ε
we will get E [f (ZK)] — f (x*) ≤ ε. Moreover, note that for Pi = Li/Pd Li with Wi = Li, the rate
improves to
K = Pi=I Li In
μ
)- f (x*))
ε
(72)
Proof. Recall that from (51) we have
f(Zk+1) ≤ f(Zk)
—
γik
1-β
Vik f (Zk )1 + <—β)* 22.
If we minimize the right hand side of the previous inequality as a function of γik , we will get that
the optimal choice in this sense is
(i-β)∣Vik f(zk X
. However, this stepsize is impractical for
derivative-free optimization, since it requires to know Rik f (Zk). The natural way to handle this is to
approximate directional derivative Nik f (Zk) by finite difference
f(zk +teik )-f(zk)
t
and that is what
we do. We choose γik
Likt
+
(1-β)Lik f(z 1 =f Ykpt + δik. From this we get
Likt
—
f(Zk+1)
≤	f (Zk )-JVll +2(⅛⅛ ⑹ )2.
Next we estimate ∣δf |:
≤
(26)
≤
(1- β)
Likt
(1- β)
Likt
(1- β)
Lik t
|f(Zk+teik)-f(Zk)|-|Rikf(Zk)|t
f(Zk+teik)-f(Zk)-Rikf(Zk)t
Lik t2	(1 - β)t
2
2
It implies that
f(Zk+1) ≤ f(Zk)
—
2
+
—
Vik f(Zk )1
2Lik
Vik f(Zk )1
2Lik
2
+
Lik	(1 一 β)2t2
2(1 一 β)2
Lik P
8
4
and after taking expectation E [∙ | zk] conditioned on zk from the both sides of the obtained inequality
we get
E [f(Zk+1) | Zk ≤ f(Zk)
Note that
E
-∣Vikf(Zk)|2 । Zk
-	Lik	।
t2
+ ^8E [Lik | Z ].
一 1 E
2
一IVikf(Zk)12 | Zk
L	Lik	1
d
X 和Vif(Zk)|2
i=1 Li
kVf(zk)k2, min ?
i=1,...,d Li
(44)
≥
2μ (f(zk) — f(x*)), min,牛,
i=1,...,d Li
≥
25
Published as a conference paper at ICLR 2020
since k ∙ ∣∣d = ∣H∣2, and
d
E Lik | zk = XpiLi.
i=1
Putting all together we get
p	t2 d
E f (zk+1) | Zk] ≤ f (zk) - μi=m_in d L (f (zk) - f (x*)) + W ^piLi.
,...,	i	i=1
Taking full expectation from the previous inequality we get
Ef(zk+1)- f (x*)] ≤
2d
(1 - μ ∙ min ,~Γ ) E [f (Zk) - f (X* )] + 4 XPiLi.
i=1,...,d Li	8
i=1
Since μ ≤ Li for all i = 1,...,d We have
E f(Zk) - f(x*)]	≤
≤
+ H X PiL)X 1-μi翌n,dL)
i=1	l=0	,, i
1 -μ. min ,pi-) (f(χ0) -f(x*))
i=1,...,d Li
+ (W X PiLjX (1-μ i=m,in,dLii)
i=1	l=0	,, i
1 -μ. min ,pi-) (f(χ0) -f(x*)) +
i=1,...,d Li
t2
8μ min	pi-
i=1,...,d Li
d
PiLi.
i=1
Lastly, from (69) We have
E f(ZK)] -f(x*)	≤
PK
1 -μ. min ,pr )	Cf(XO) - f(χ*)) +
i=1,...,d Li
t2
8μ min pi
i=1,...,d Li
d
PiLi
i=1
(70)
≤
(71)
≤
exp { -Kμ , min pi- ∖ (f (XO) - f (x*)) + ε
i=1,...,d Li	2
εε
2 + 2 = J
□
E.4 Comparison of SMTP and SMTP_IS
Here We compare SMTP when D is normal distribution with zero mean and d covariance matrix
With SMTP_IS With probabilities Pi = Li/Pid=1 Li. We choose such a distribution for SMTP since
it shows the best dimension dependence among other distributions considered in Lemma F.1. Note
that if f satisfies Assumption 4.1, it is L-smooth with L = max Li. So, we always have that
i=1,...,d
Pid=1 Li ≤ dL. Table 3 summarizes complexities in this case.
We notice that for SMTP we have ∣∣ ∙ ∣∣d = ∣∣ ∙ ∣∣2. That is why one needs to compare SMTP with
SMTP_IS accurately. At the first glance, Table 3 says that for non-convex and convex cases we
get an extra d factor in the complexity of SMTP_IS when L1 = . . . = Ld = L. However, it is
natural since we use different norms for SMTP and SMTP_IS. In the non-convex case for SMTP
we give number of iterations in order to guarantee E [∣Vf (ZK)∣∣2] ≤ ε while for SMTP_IS we
provide number of iterations in order to guarantee E [∣Vf (ZK )∣ι] ≤ ε. From Holder,s inequality
26
Published as a conference paper at ICLR 2020
Assumptions on f	SMTP Compleixty	Theorem	Importance Sampling	SMTP_IS Complexity	Theorem
None	πrodL	3.1	Li	Li	2r0d Pd=ι Li	E.1
	ε		pi = Pd=ι Li	ε2	
Convex, Ro < ∞	弋ε dL ln (智)	3.2	Li 一	Li	R0,'∞ d Pd=1 Li ln ( 2r0 )	E.2
			pi = PdT Li		
μ-strongly convex	∏dL ln (2r0) 2μ	∖ ε )	3.5	i=1 Li 一	Li	Pd=I Li ln ( 2r0 )	E.5
			pi = Pd=ι Li		
Table 3: Comparison of SMTP with D = N(0, d) and SMTP_IS with Pi = LiPd=I Li. Here
ro = f (χ0) - f (x*), R0,'2 corresponds to the Ro from Assumption C.1 with ∣∣ ∙ ∣∣d = ∣∣ ∙ ∣∣2 and
Ro,'∞ corresponds to the Ro from Assumption C.1 with ∣∣ ∙ ∣∣d = ∣∣ ∙ ∣∣ι.
∣∣∙∣∣ι ≤ √d∣∣∙ ∣∣2 and, therefore, in order to have E [∣Vf (zK)∣ι] ≤ ε for SMTP we need to ensure
that E [∣∣Vf (zκ)∣∣2] ≤ √⅛. That is, to guarantee E [∣∣Vf (Zκ)∣ι] ≤ ε SMTP for aforementioned
πr d2L
distribution needs to perform	22 L iterations.
Analogously, in the convex case using Cauchy-Schwartz inequality ∣∣ ∙ ∣2 ≤ √d∣∣∙∣∣∞ we have that
R0,'2 ≤ √dRo,'∞. Typically this inequality is tight and if we assume that Ro,'∞ ≥ CR√√'2, we will
R2 Pd Li
get that SMTP_IS complexity is -, 2 三 —ln (等)up to constant factor.
That is, in all cases SMTP_IS shows better complexity than SMTP up to some constant factor.
F Auxiliary results
Lemma F.1 (Lemma 3.4 from Bergou et al. (2019)). Let g ∈ Rd.
1.
If D is the uniform distribution on the unit sphere in Rd, then
YD = 1 and Es〜D | hg, si | 〜κj Ilgll2.
2πd
(73)
2.
Hence, D satisfies Assumption 3.1 with YD = 1, ∣ • ∣D = ∣ • ∣∣2 and μD 〜√=.
If D is the normal distribution with zero mean and identity over d as covariance matrix (i.e.
s 〜N(0, d)) then
2 ll ll
YD = 1 and Es〜D | hg, si | = —=kgk2.
dπ
Hence, D satisfies Assumption 3.1 with YD=1, ∣ ∙ ∣d = Il• ∣∣2 and μD
(74)
dπ
3.
4.
If D is the uniform distribution on {e1, . . . , ed}, then
Yd = 1 and Es〜D | hg, si | = d∣∣g∣ι.
Hence, D satisfies Assumption 3.1 with YD = 1, ∣ • ∣D = ∣ • ∣∣ι and μD = d.
If D is an arbitrary distribution on {e1, . . . , ed} given by P {s = ei} = pi > 0, then
d
YD = 1 and Es〜D | hg, si | = ∣∣g∣D =ef Epi |gi|.
(75)
(76)
5.
i=1
Hence, D satisfies Assumption 3.1 with YD = 1 and μD = 1.
If D is a distribution on D = {u1, . . . , ud} where u1, . . . , ud form an orthonormal basis of
Rd and P {s = di} = pi, then
d
YD = 1 and Es〜D | hg, si | = ∣∣g∣D =ef Epi |gi|.
i=1
(77)
27
Published as a conference paper at ICLR 2020
Hence, D satisfies Assumption 3.1 with YD = 1 and μD
1.
28