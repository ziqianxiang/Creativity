Figure 1: Latent traversals for one of the best and worst ranked trained β-VAE models using theUnsupervised Disentanglement Ranking (UDRL) method on the 3D Cars dataset. For each seed imageWe fix all latents Zi to the inferred value, then vary the value of one latent at a time to visualise itseffect on the reconstructions. The high scoring model (left 3 blocks) appears well disentangled, sinceindividual latents have consistent semantic meaning across seeds. The low scoring model (right block)is highly entangled, since the latent traversals are not easily interpretable.
Figure 2: Hyperparameter search results for six unsupervised disentangling model classes evaluatedusing the unsupervised UDR and the supervised β-VAE, FactorVAE, MIG and DCI Disentanglingmetrics and trained on either dSprites (top) or 3D Shapes (bottom) datasets. “Hyper” corresponds tothe particular hyperparameter setting considered (see Tbl. 5 in Supplementary Materials for particularvalues). The box and whisker plots for each hyperparameter setting are summarising the scores for50 different model seeds. Higher median values indivate better hyperparameters. The ranking ofhyperparameters tends tobe similar between the different metrics, including UDR.
Figure 3: Latent traversals of the top ranked trained DIP-VAE-I, TC-VAE, CCI-VAE and β-VAEaccording to the UDR method. At the top of each plot the two presented scores are UDR/FactorVAEmetric. Note that the FactorVAE metric scores visually entangled models very highly. d is the numberof informative latents. The uninformative latents are greyed out.
Figure 4: Schematic illustration of the UDR method. See details in text.
Figure 5: A: Schematic illustration of the pairwise model comparison. Two trained models i andj aresampled for pairwise comparison. Both models learnt a perfectly disentangled representation, learningto represent two (positions x/y) and three (positions x/y, and size) generative factors respectively.
Figure 6: Rank correlation between different versions of UDR with different supervised metrics acrosstwo datasets and three model classes. We see that the UDRL approaches slightly outperform the UDRSones.
Figure 7: The range of scores for each hyperparameter setting for the dSprites and 3D Shapes datasetsfor various models and metrics. We see that the different versions of the UDR method broadly agreewith each other.
Figure 8: Rank correlations of the different versions of the UDR score with the β-VAE metric onthe dSprites dataset for a β-VAE hyperparameter search as the number of pairwise comparisons permodel were changed. Higher number of comparisons leads to more accurate and more stable rankings,however these are still decent even with 5 pairwise comparisons per model.
Figure 9: Example latent traversals of some of the best and worst ranked β-VAE models using theUDRL (ordinate) and DCI Disentanglement (abscissa) metrics, coloured either by hyperparametervalue (top) or final informative latent number (bottom). Uninformative units are greyed out. Themodels ranked highly by UDRL do appear to be well disentangled, despite being ranked poorly byDCI Disentanglement (1, 2, 4). On the other hand, models ranked well by DCI Disentanglement butpoorly by UDRL look quite entangled (5, 6). Finally, models ranked poorly by both metrics do appearentangled (3).
Figure 10: Example latent traversals of some of the best and worst ranked β-VAE models using theUDRL scores. Uninformative latents are greyed out.
Figure 11: Left: Spearman correlation between UDR scores and classification fairness scores intro-duced by Locatello et al. (2019) across sixty models trained per each one of the three different modelclasses (rows) and over two datasets (columns). Right: Spearman correlation between UDR scores anddata efficiency for learning a clustering task by the COBRA agent introduced by Watters et al. (2019).
Figure 12: Distribution OfUDRS scores (P=50) for 300 β-VAE models trained with 6 settings of the βhyperparameter and 50 seeds on CelebA and ImageNet datasets. The reconstructions shown are for thevanilla VAE (β = 1). ImageNet is a complex dataset that VAEs struggle to model well.
Figure 13: Latent traversals for the four most informative latents ordered by their KL from the priorfor three different β-VAE models that ranked high or low according to UDR. Those models that wereranked high have learnt representations that are both interpretable and very similar across models.
Figure 14:	Latent traversals for the six most informative latents ordered by their KL from the prior forthree different β-VAE models that ranked high or low according to UDR. Despite the fact that none ofthe β-VAE or VAE models were able to learn to reconstruct this dataset well, those models that wereranked high by the UDR still managed to learn representations that are more interpretable and moresimilar across models. This is unlike the representations of those models that were ranked low by theUDR.
Figure 15:	Latent traversals for all ten latent dimensions presented in no particular ordering for threedifferent models per model class. These models were ranked highly by the UDR. It can be seen thatthey learnt interpretable and similar representations up to permutation, sign inverse and subsetting. Weincluded all model classes that achieved UDR scores in the range specified (UDR > 0.4).
Figure 16:	Latent traversals for all ten latent dimensions presented in no particular ordering for threedifferent models per model class. These models received medium UDR scores. It can be seen that theylearnt less interpretable and less similar representations than the models shown in Fig. 15. None of themodels in these model classes scored higher than the range specified (0.3 < UDR < 0.4).
Figure 17: Latent traversals for all ten latent dimensions presented in no particular ordering for threedifferent models per model class. These models received low UDR scores. It can be seen that theirrepresentations are hard to interpret and they look quite different from each other. We included allmodel classes that achieved UDR scores in the range specified (UDR < 0.3).
