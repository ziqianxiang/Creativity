Figure 1: Shape Segmentation Re-sults on unseen categories. Leftcolumn shows the results of SOTAdeep-learning method with usingglobal contextual information andright is ours.
Figure 2: Network Architectures for three network modules. N is the point number of input sampledfrom a sub-part. f is the dimension of feature.
Figure 3: Qualitative results on unseen categories. More visualizations can be found in Appendix C.
Figure 4: The extended verification network with two prediction branches. The above branch ex-ploits pure local context. The below branch encode more context to make decisions.
Figure 5: Overview of the proposed approach. The orange part is the point cloud of sub-parts; theblue part is the whole shape point cloud. We only feed sub-parts into our networks. In each iteration,we use a policy network to select a pair of sub-parts and send it to the verification network to verifywhether we should group the selected pair of sub-parts. If yes, we group the selected pair of sub-parts into a larger sub-part, and put the grouped sub-part into the sub-part pool and delete the inputpair from the pool. Otherwise, we will not consider this pair in the latter grouping process. We williteratively do this process until no sub-part can further group each other. The remaining sub-parts inthe final stage become a pool of part proposals for the input shape.
Figure 6: Learning-based sub-part proposal module.
Figure 7: Qualitative results. Figures show the changes of the relative size of a pair of sub-partsduring the grouping process. The X-axis is the iteration number and Y-axis is the relative sizedefined in Appendix B. Each row represents the grouping process for the same shape. The leftcolumn is the results without the rectification module.
Figure 8: We train the models on Chair, Lamp, and Storage Furniture of level-3 (the most fine-grained level) of PartNet Dataset and test on the other unseen categories listed in the right. Therightmost column is the most fine-grained ground-truth annotations for reference. Note that theground-truth annotation only provides one possible segmentation that satisfies category-specifichuman-defined semantic meanings.
Figure 9: We train the models on Chair, Lamp, and Storage Furniture of level-3 (the most fine-grained level) of PartNet Dataset and test on the other unseen categories listed in the right. Therightmost column is the most fine-grained ground-truth annotations for reference. Note that theground-truth annotation only provides one possible segmentation that satisfies category-specifichuman-defined semantic meanings.
Figure 10: We train the models on Chair, Lamp, and Storage Furniture of level-3 (the most fine-grained level) of PartNet Dataset and test on the other unseen categories listed in the right. Therightmost column is the most fine-grained ground-truth annotations for reference. Note that theground-truth annotation only provides one possible segmentation that satisfies category-specifichuman-defined semantic meanings.
Figure 11: We train the models on Chair, Lamp, and Storage Furniture of level-3 (the most fine-grained level) of PartNet Dataset and test on the other unseen categories listed in the right. Therightmost column is the most fine-grained ground-truth annotations for reference. Note that theground-truth annotation only provides one possible segmentation that satisfies category-specifichuman-defined semantic meanings.
