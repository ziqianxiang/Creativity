Figure 1: A sketch of the first stage: all class and content embeddings and the generator are jointlyoptimized. All images of the same class share a single class embedding. The content embeddingsare regularized by a gaussian noise. By the end of this stage, the latent space of the training set isdisentangled. Note that the second stage is not shown.
Figure 2: Comparison between our method and baselines on Cars3D (top) and SmallNorb (bottom).
Figure 3: Comparison between our method and baselines on KTH (top) and CelebA (bottom).
Figure 4: A qualitative comparison between our method (upper row) and StarGAN (bottom row) infacial expression transfer on RaFD. See Appendix A.5 for more results.
Figure 7: Accuracy of classifying classlabels from content codes as evidencefor the inductive bias conferred by la-tent optimization on Cars3D.
Figure 5: Examples of the diversity in translating edges to shoes (upper row) and style-guidedtranslation (bottom row). Triplet order in bottom row (left to right): edges, style, translation.
Figure 6: Examples of translations between anime and faces from CelebA using our method.
Figure 8: Evidence for a partial posterior collapse with KL-divergence. 126 out of 128 componentsof the content code collapse to match a perfect standard normal distribution with zero mean and aunit standard deviation. The remaining two components sustain much higher mean and much lowerstandard deviation. This prevents the regularization from acting as a tight bottleneck.
Figure 9: More qualitative results of our method in transferring content between classes on CelebA.
Figure 10: More qualitative results of our method in transferring content between classes on CelebA.
Figure 11: More qualitative results of our method in transferring content between classes on Cars3D.
Figure 12: More qualitative results of our method in transferring content between classes on Small-Norb.
Figure 14: Qualitative comparison on CelebA between our method and 3 of our ablation base-lines. Fully-amortized models (a, b) fail to preserve the class (person identity) across differentcontent codes and introduce several artifacts, showing their lower degree of disentanglement. Semi-amortized model regularized with asymmetric noise (c) transfers over unreliable properties betweenidentities (such as hair style). Our model (d) learns to disentangle the intrinsic characteristics ofeach identity and provides the best disentanglement and highest quality.
Figure 15: A visualization of the degradation in reconstruction and disentanglement quality in caseswhere classes exhibit intra-class variations. It can be observed that the car model is not preservedwell across different content codes.
Figure 16: Random samples from clusters of shoe images formed by k-means on style featuresextracted from a pretrained VGG model.
Figure 17: Examples of translations between genders of faces from CelebA using our method.
