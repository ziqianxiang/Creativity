Figure 1: Model Overview: Given a question, our model parses it into a program composed of neuralmodules. This program is executed against the context to compute the final answer. The modulesoperate over soft attention values (on the question, passage, numbers, and dates). For example,filter takes as input attention over the question (in the second quarter) and filters the output ofthe find module by producing an attention mask over tokens that belong to the second quarter.
Figure 2: Effect of auxiliary losses and the size of training data on model performance.
Figure 3: Example usage of num-compare-lt: Our model predicts the programspan(compare-num-lt(find, find)) for the given question. We show the question atten-tions and the predicted passage attentions of the two find operations using color-coded highlightson the same question and paragraph (to save space) at the bottom. The number grounding for the twoparagraph attentions predicted in the compare-num-lt module are shown using the same colorsin number-distribution. Since the number associated to the passage span “45 to 64” is lower (10.3 vs.
Figure 4:	Example usage of date-compare-lt: Similar to Fig. 3, we show the question atten-tions, the output passage attentions of the find module, and the date grounding predicted in thecompare-date-lt module in color-coded highlights. The passage span predicted as the answeris the one associated to a lower-valued date.
Figure 5:	Example usage of count: For the predicted program count(find), the find modulepredicts all “rushing touchdown” spans from the passage and the count module counts their numberand represents its output as a distribution over possible count values. In this example, the predicteddistribution as a mode of “5”.
Figure 6:	Example usage of find-max-num: For the predicted program, the model first groundsthe question span “field goal” to all field goals in the passage, shown as attention in the bottomhalf. The find-max-num first finds the number associated with the input passage spans (shown asinput-num-distribution), then finds the distribution over max value (shown as max-num-distribution),and finally outputs the passage span associated with this max value (shown in the passage attentionon top). The find-num module finally extracts the number associated with this passage attention asthe answer.
Figure 7:	Example usage of relocate: Similar to the sub-program find-max-num(find) inFig. 6, the find module finds all mentions of “rushing TD” in the passage and find-max-numselects the one associated to the largest number. This is the span “getting a 32-yard TD run” in thepassage above. The question attention predicted for the relocate module and its output passageattention is also shown in the passage above.
