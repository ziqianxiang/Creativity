Figure 1: Flowcharts. We use compositionality to separate semantics and syntax (left). We use labelprediction continual learning algorithm for θ (semantics), and freeze φ (syntax) during continualtrain (right).
Figure 2: Illustration for the first continual learning stage. U0 and V0 are initial vocabulary sizesfor input and output, respectively. Left is input word embedding (we only show one of two inputword embeddings for simplicity). Middle is model architecture. Right is output action embedding.
Figure 3: Mean of evaluation accuracy (%) for all methods (best viewed in color). Baselines includeCompositional (Li et al., 2019), EWC (Kirkpatrick et al., 2017a), and MAS (Aljundi et al., 2018).
Figure 4:	Visualization of attention maps. The horizontal and vertical dimensions are the input andoutput position sequences respectively. The figures show that the model identifies the appropriateinput to output position mapping. This indicates that the proposed method successfully leveragescompositionality in continual learning.
Figure 5:	Embedding visualization for semantic embeddings. We see two phases. In (1-50), embed-dings explore outside space. In (51-100), embeddings squeeze into the explored space.
Figure 6: Embedding visualization for syntax embeddings.
Figure 7: Embedding visualization for action embeddings.
