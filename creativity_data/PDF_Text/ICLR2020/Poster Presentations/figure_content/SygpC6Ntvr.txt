Figure 2: SpMV product: The colored cells denote non-zero entries, and the arrows indicate the liststructure for each of the columns, with solid arrows denoting links that were traversed for the givenquery. The green and grey cells denote the non-zero entries that were accessed and not accessed,respectively. The non-zero values in Duq (blue) can be computed using only the common non-zerovalues (green). Selecting top-k: The sparse product vector is then filtered using a threshold t, afterwhich the top-k indices are returned.
Figure 3: Figure (a) shows that the CDF of the activations (red) closely resembles the CDF of ρ(Y )(blue) where Y is a Gaussian random variable. Figure (b) shows that F and F behave similarly bysparsifying the less sparser activation at a faster rate when compared to the `1 regularizer.
Figure 4: Figures (a) and (c) show the speed vs recall trade-off for the MobileNet and ResNetarchitectures respectively. The trade-off curves produced by varying the hyper-parameters of therespective approaches. The points with higher recall and lower time (top-left side of the plots) arebetter. The SDH baseline being out of range of both the plots is indicated using an arrow. Figures (b)and (d) show the sub-optimality ratio vs sparsity plots for MobileNet and ResNet respectively. Rsubcloser to 1 indicates that the non-zeros are uniformly distributed across the dimensions.
Figure 5: Time vs Recall@1 plots for retrieval with and without re-ranking. Results from the samemodel and regularizer have same colors. Diamonds (♦) denote results with re-ranking, and triangles(4) denote results without re-ranking.
Figure 6: FPR-TPR curves. The `1 curves are all shown in shades of red, where as the FLOPs curvesare all shown in shades of blue. The probability of activation is provided in the legend for comparison.
