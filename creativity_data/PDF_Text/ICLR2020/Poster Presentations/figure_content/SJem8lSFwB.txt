Figure 1: Schematic view of different pruning methodologies and their properties.
Figure 2: Left: One-shot pruning (red) computes a stochastic gradient at w and takes a step towards the bestdense model. In contrast, DPF (blue) computes a stochastic gradient at the pruned model we (here obtained bysmallest magnitude pruning), and takes a step that best suits the compressed model. Right: One-shot pruningcommits to a single sparsity mask and might obtain sparse models that generalize poorly (without retraining).
Figure 3: Top-1 test accuracy of WideResNet-28-2 on CIFAR-10 for unstructured weight pruning. The originalmodel has 1.47M parameters with 216M MACs (Multiplier-ACcumulator). We varied the sparsity ratio from50% to 99%. The complete numerical test accuracy values refer to Table 4 in Appendix A.3.1. The lower #of params and MACs the model has, the higher sparsity ratio it uses. All results are averaged over three runs.
Figure 4: Convergence of the pruning mask mt of DPF for different target sparsity levels (See legend). They-axis represent the percentage of mask elements that still change after a certain epoch (x-axis). The illustratedexample are from WideResNet-28-2 on CIFAR-10. We decayed the learning rate at 60,120,160 epochs.
Figure 5: Top-1 test accuracy for different target sparsity levels (on WideResNet-28-2 With CIFAR-10, Un-structured pruning). DPF reaches comparable accuracy than the LT training method (and better for 99% targetsparsity), but involves much less computation (right y-axis, green). Training the sparse models found by DPFfrom scratch does not reach the same performance (hence our sparse models are not lottery tickets).
Figure 6: MAC v.s. top-1 test accuracy, for training WideResNet-28 (With different Width) on CIFAR-10. Thereported results are averaged over three runs. The WideResNet-28-2 has 216M MACs, WideResNet-28-4 has848M MACs and WideResNet-28-8 has 3366M MACs. Other detailed information refers to the Appendix A.4.1,e.g., the # of params v.s. top-1 test accuracy in Figure 14, and the numerical test accuracy score in Table 6.
Figure 7: Convergence of the pruning mask mt of DPF for different target sparsity levels (See legend). They-axis represent the percentage of mask elements that still change after a certain epoch (x-axis). The illustratedexample are from ResNet-20 on CIFAR-10. We decayed the learning rate at 150 and 225 epochs.
Figure 8:	Training dynamics of DPF (WideResNet-28-2 on CIFAR-10) for unstructured pruning with differentsparsity ratios. IoU stands for Intersection over Union for the non-masked elements of two consecutive masks;the smaller value the more fraction of the masks will flip.
Figure 9:	Convergence of the pruning mask mt of DPF V.S. Incremental (Zhu & Gupta, 2017) for differenttarget sparsity levels (see legend). The y-axis represent the percentage of mask elements that still changeafter a certain epoch (x-axis). The illustrated example are from WideResNet-28-2 on CIFAR-10. We decayedthe learning rate at 60; 120; 160 epochs. These two schemes use the same gradual warmup schedule (andhyper-parameters) for the pruning ratio during the training.
Figure 10: Investigate the effect of lottery ticket for model compression (unstructured weight pruning forWideResNet28-2 on CIFAR-10). It complements the observations in Figure 5 by retraining the model for thesame amount of computation budget (i.e. flops).
Figure 11: Investigate how the reparameterization period/scheme and mini-batch size impact the generalizationperformance (test top-1 accuracy), for dynamically training (and reparameterizing) a compressed model fromscratch (ResNet-20 with CIFAR-10).
Figure 12: The learning curve of our DPF (with unstructured magnitude pruning) and the standard mini-batchSGD for training ResNet50 on ImageNet. Our proposed DPF has trivial computational overhead. We trainedResNet50 on 4 NVIDIA V100 GPUs with 1024 mini-batch size. The target sparsity ratio is 80%.
Figure 13:	Test top-1 accuracy vs. the compressed model size, for training WideResNet-28 (with differentwidths) on CIFAR-10. The compressed model is searched from WideResNet-28 (fixed depth) with differentwidth (number of filters per layer).
Figure 14:	# of params v.s. top-1 test accuracy, for training WideResNet28 (with different width) on CIFAR-10.
Figure 15:	Investigate the effect of lottery ticket for model compression (WideResNet28-2 with CIFAR-10) forstructured pruning. We retrained the model with the mask from the model trained by DPF, by using the sameepoch budget.
Figure 16: The element-wise sparsity of each layer for WideReSNet28-2 (trained on CIFAR-10 via DPF), underdifferent structured pruning sparsity ratios. DPF for model compression (with structured pruning) performsimplicit as a neural architecture search.
