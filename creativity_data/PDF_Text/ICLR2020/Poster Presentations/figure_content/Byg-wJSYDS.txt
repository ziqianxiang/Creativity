Figure 1: Performance of baseline metrics on the MNIST test set. Curves show mean value and 2-standard deviation bounds obtained from multiple simulations of the experiment. (a) Naive Evaluationexhibits linear decay of observed accuracy but cannot compare model to inter-annotator variability(b) Majority Vote is more invariant to label noise but also does not compare model to inter-annotatorvariability. Panel (c) shows that the relative F1 score depends sensitively on the number of annotators.
Figure 2: Comparison of the discrepancy ratio with baseline metrics on the MNIST test set. Curvesshow mean value and 2-standard deviation bounds obtained from multiple simulations of the experi-ment. Panel (a) shows the model discrepancy (for three models) and annotator discrepancy. The redand blue points occur at label swap probabilities of 0.1 * 10/9 and 0.2 * 10/9, respectively, whichcorrespond precisely to when the accuracies of the simulated human annotators equal that of themodels (0.9 and 0.8, respectively). The discrepancy ratios (Eq. 4) for the same three models areshown in (b). The blue and red points correspond to those shown in (a). The shaded region denotesthe area where the model is superior to the average human performance. Panels (c) and (d) show thatthe discrepancy ratio is not sensitive to the number of annotators used, nor is subject to the strictannotator bias illustrated in Fig 1d. Here we have used the same parameters as in Figs 1c and 1d.
Figure 3: Panel (a) shows that human experts exhibit a high amount of disagreement on which imagesmeet the threshold for measurability (i. e. with perfect agreement all labels would be 0 or 1). Thisplot displays the normalized histogram of the average labels on the PLAX measurability classificationdataset. The discrepancy ratio on the test set as the output threshold of the network output is varied isshown in (b). Panel (c) shows the labels (blue) and model predictions (red) on the LVEF regressiontask test set, sorted by the mean LVEF label. Each patient was labeled by an average of 5 annotators.
Figure S1: Examples of images deemed measurable (a) and not measurable (b) by majority vote ofannotators. Several important features characteristic of a measurable image are noted in (a). Thesesame features are obscured or entirely absent in (b).
Figure S2: An example LVEF calculation in the apical 4-chamber view. Panel (a) shows theend-diastole frame with the overlaid segmentation mask while panel (b) shows the correspondingend-systole frame within the same heart cycle. The calculated LVEF from these segmentation masksis 66%A.3 LVEF Regression TaskHere we collected three separate types of labels:1.	Segmentation Masks: annotators were asked to segment the endocardial border of the leftventricle.
