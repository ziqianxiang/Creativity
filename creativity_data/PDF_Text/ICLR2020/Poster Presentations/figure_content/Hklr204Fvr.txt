Figure 1: Computed brain parcellation at various granularities (details in the text). The text in the topleft indicates the number of regions. Each color in each figure corresponds to a region/group. Noticethe consistency between parcellations while increasing granularity.
Figure 2: (a) Simulated Dataset: Random images are aggregated over regions/groupings to obtainactivations (z) that are used to assign labels. Groupings are comprised of multiple smaller regions, allspatially connected. (b) Voronoi diagrams and induced groups. The upper left image is a Voronoidiagram of 8 random sites (blue points) and lines that partition space into sets of points closest to thesame site. The other images are possible groupings using 2 partitions. (c) Histogram of probabilityof assigned label. The y-axis is probability and x-axis is number of points. Most datapoints haveP r (y) > 0.5 (labels are low-noise).
Figure 3: (a) Test accuracy (with error bars) on held out 20% of simulated dataset vs. fraction ofdata used for training. The graph indicates that FGL has better empirical sample complexity. Thesmall magnitude of error in estimation of performance indicates that models are well trained and thedifference is due to the models themselves. (b) Minimum (across classes) F1 Score on held out testset vs. fraction of data used for training. The difference in performance is not due to performance ona single class/region, but rather across all labels. (c) Histogram of ground truth probability of labelsfor points where FGL is correct but CNN misclassifies. This demonstrates that the misclassificationby CNN is not only on noisy datapoints but also for datapoints where the label should be clear.
Figure 4: Test accuracy: Out of sample accuracy measured on 30% of dataset v/s fraction of subjectsused for training. FGL performs well even when a small amount of data is used for training.
Figure 5: Ablation of intermediate vector length: (a) On HCP, along with baselines. (b) On alldatasets. Increasing the intermediate vector length improves performance, except on Cam-CAN.
Figure S1: Baseline: The architecture used for Convolutional Neural Networks and CoordConv. Inthe CoordConv variant, each volume is concantenated with 3 channels for coordinate along eachdimension being passed in as input. The volumes are written above each volume while the number ofchannels for each volume is written underneath it.
Figure S2: Illustration of FGL. Given the numbered hierarchical segmentation, FGL extracts featuresfor each segment. The inputs are 9 variables corresponding to segments of a square, which are firstgrouped as {{1, 2}, {3, 4, 5}, {6, 7}, {8, 9}}. The resulting 4 groups are then grouped into 2 groupsusing the grouping {{1, 2}, {3, 4}}. The output is passed to a fully connected network to predictlabels. Note that intermediate layers can use feature vectors of length greater than 1.
