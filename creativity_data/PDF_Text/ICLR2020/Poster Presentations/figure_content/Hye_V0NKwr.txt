Figure 1: Typical samplesshow how compositionalityand locality are expresseddifferently in the datasetswe consider in this study.
Figure 2: Parts F1 score for all models on CUBwith a DCGAN-based encoder plotted againstZSL accuracy. There is a clear relationshipbetween the two: encoders that have a goodunderstanding of local information (as mea-sured by the parts F1 score) perform better inzero-shot learning. The addition of a local lossincreases parts F1 score for all models. Thisimproves generalization for all models exceptthose trained with a reconstruction objective.
Figure 3: Relative improvement in terms of ZSL accuracy with respect to models trained without theauxiliary loss. Attribute information results in a bigger improvement. Surprisingly, for certain modelslabel information results in a decrease in generalization performance.
Figure 4: Mutual Information heatmaps allow to understand which local patches contributed the mostto the final representation. For each heatmap we plot the absolute values in the rightmost plot andthe superposition of the heatmap and the original image on the left, to increase interpretability. Yellowcorresponds to higher scores.
Figure 5: Relationship between TRE ratio and ZSL accuracy for each dataset (lower TRE ratio is better).
Figure 6: Comparison between averaging representations and averaging predictions. We can see how,for the more local model families, this notion of compositionality is most useful for CUB, where theobject of interest is likely only present in few patches.
Figure 7:	The convolutional encoder takes as in-put an image and outputs a global representation- used to compute the model loss Lmodel . Toencourage locality and compositionality, labelor attribute based classification is performed onthe activations from early layers(Llocal).
Figure 8:	Local and global features are extractedfrom different images (where local featuresare activations from an early layer in the CNNencoder), then scored against each other. A highscore means the two are considered likely to beextracted from the same image by the model,giving us insight in what information is encodedby the global representation. A heatmap of thescores is used to make the result interpretable.
Figure 9: Visualization of locality comparing encoders trained with CMDIM’s loss and the proposedlocal losses. The Figure highlights the impact of local losses on the content extracted by the encoders.
Figure 10: Relationship between the parts score and different measures of similarity. On the left,the parts scores is plotted against the two different measures of similarity. We can see there is a cleartrend for all the models: the parts score increases for more semantically similar images, and decreasesas the images become more similar pixel-wise. The figure on the right shows Pearson’s correlationcoefficient between the metrics for different modelsFigure 11: Comparing pre and post-pooling (respectively Small and Big) features in terms of ZSLaccuracy. The effect of a varying receptive field size strongly depends on the model type and on thedataset, highlighting how locality is expressed differently in the datasets.
Figure 11: Comparing pre and post-pooling (respectively Small and Big) features in terms of ZSLaccuracy. The effect of a varying receptive field size strongly depends on the model type and on thedataset, highlighting how locality is expressed differently in the datasets.
Figure 12: Comparison between averaging representations VS averaging scores for all models.
Figure 13: Comparison between small and big receptive field for all models.
