Figure 1: An illustration of consistency regularization for GANs. Before consistency regularization,the zoomed-in dog and the zoomed-in cat (bottom left) can be closer than they are to their originalimages in feature space induced by the GAN discriminator. This is illustrated in the upper right(the semantic feature space), where the purple dot is closer to the blue dot than to the red dot, andso forth. After we enforce consistency regularization based on the implicit assumption that imageaugmentation preserves the semantics we care about, the purple dot pulled closer to the red dot.
Figure 2: Comparison of our method with existing regularization techniques under different GANlosses. Techniques include no regularization (W/O), Gradient Penalty (GP) (Gulrajani et al., 2017),DRAGAN (DR) (Kodali et al., 2017) and JS-Regularizer (JSR) (Roth et al., 2017). Results (a-c) arefor CIFAR-10 and results (d-f) are for CelebA.
Figure 3: Comparison of FID scores with different values of the regularization coefficient Î» onCIFAR-10 and CelebA. The dotted line is a model without regularization.
Figure 4: Comparison of FID scores with ResNet structure on different loss settings on CIFAR-10.
Figure 5: A study of how much data augmentation matters by itself. Three GANs were trained onCIFAR-10: one baseline GAN, one GAN with data augmentation only, and one GAN with consis-tency regularization. (Left) Training accuracy of the GAN discriminator. (Middle) Test accuracy ofthe GAN discriminator on the held out test set. The accuracy is low for the baseline GAN, which in-dicates it suffered from over-fitting. The accuracy for the other two is basically indistinguishable foreach other. This suggests that augmentation by itself is enough to reduce discriminator over-fitting,and that consistency regularization by itself does little to address over-fitting. (Right) FID scores ofthe three settings. The score for the GAN with only augmentation is not any better than the score forthe baseline, even though its discriminator is not over-fitting. The score for the GAN with consis-tency regularization is better than both of the others, suggesting that the consistency regularizationacts on the score through some mechanism other than by reducing discriminator over-fitting.
Figure A1: Comparison of FID scores with different optimizer settings.
Figure D1: Comparison of generated samples of CelebA.
Figure D2: Comparison of generated samples for unconditional image generation on CIFAR-10with a ResNet architecture.
Figure D3: Comparison of unconditional generated samples on CIFAR-10 with a ResNet architec-ture, Wasserstein loss and spectral normalization. This is a hard hyperparameter setting where thebaseline and previous regularization methods fail to generate reasonable samples. Consistency Reg-ularization is the only regularization method that can generate satisfactory samples in this setting.
Figure E1: Comparison of generated samples for conditional image generation on CIFAR-10. Eachrow shows the generated samples of one class.
Figure E2: Comparison of conditionally generated samples of BigGAN* and CR-BigGAN* onImageNet. (Left) Generated samples of CR-BigGAN*. (Right) Generated samples of BigGAN*.
Figure E3: More results for conditionally generated samples of BigGAN* and CR-BigGAN* onImageNet. (Left) Generated samples of CR-BigGAN*. (Right) Generated samples of BigGAN*.
Figure F1: Comparison of IS with a SNDCGAN architecture on different loss settings. Models aretrained on CIFAR-10.
Figure F2: Comparison of IS with a ResNet architecture on different loss settings. Models aretrained on CIFAR-10.
Figure G1: Comparison of consistency regularization on different number of intermediate layers:(a) first weight setting, where the weight for each layer is the inverse of its feature dimension (b)second weight setting, where each layer has equal weight.
Figure H1: Comparison of FID scores with no consistency regularization (W/O), regularization onlyon the real samples (CR-Real), consistency regularization only on the fake samples produced by thegenerator (CR-Fake) and regularization on both real and fake samples (CR-All) for (a) unconditionalimage generation on CIFAR-10 with SNDCGAN, (b) unconditional image generation on CIFAR-10with ResNet, (c) conditional image generation on CIFAR-10 with CR-BigGAN*.
