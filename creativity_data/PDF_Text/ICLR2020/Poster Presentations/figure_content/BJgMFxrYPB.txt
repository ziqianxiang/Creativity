Figure 1: Overview of our proposed architecture for navigation. RGBD inputs xt are used to predictaffordance maps y^t and transformed into egocentric navigability maps Mt that incorporate both geo-metric and semantic information. In the example shown, Mt is labelled as non-navigable in regionsnear the monster. A running estimate of the current position at each time step is maintained and usedto update a global, allocentric map of navigability Gt that enables safe and efficient planning.
Figure 2: Overview of self-supervised labeling for navigability training pairs (x,y). The agentperforms a series of walks along random or planned trajectories within the environment. Affordanceinformation collected from each walk is back-projected onto pixel-level labels in the agent’s POVfrom previous time steps. Sampling over a variety of maps allows for the collection of a visuallyand semantically diverse set of examples D that can be used to train a navigability module π. Thisfigure illustrates the generation of a negative example, with the agent contacting a dynamic hazard.
Figure 3: Examples of samples labeled through back-projection (navigable area labeled in green,non-navigable in yellow, and unknown in purple). The first three examples show negative examples,labeled by damage from monster, impediment of movement by barrel, and damage taken from envi-ronmental hazard respectively. The fourth illustrates successful traversal between monsters and thefifth shows an example collected along a minimum cost path as part of an active learning loop.
Figure 4: Comparison of exploration performance across all evaluated approaches in hazard-dense(Left) and hazard-sparse environments (Center), plotted as a function of area observed over time.
Figure 5: Comparison of navigation per-formance across all evaluated approaches,plotted as a function of success rate vs.
Figure 6: Examples of actively-planned trajectoriesthat maximize label entropy along sampled loca-tions. (Left) shows predicted affordances, (Middle)shows the projected confidence map, and (Right)shows the cost map used to plan the optimal path.
Figure 7: Top-down visualizations of initial exploration areas in hazard-sparse (Left) and hazard-dense (Right) test environments. Agent start position is marked in green, with environmental haz-ards marked in yellow, and initial locations of dynamic hazards marked in purple. Hazard-denseenvironments present a significant challenge for autonomous exploration, containing a high concen-tration of navigability restricting areas that must be avoided successfully.
Figure 8: Comparison of affordance maps generated by models trained using datasets containing(a) 20k random samples, (b) 20k random samples + 40k active samples, (c) 20k random samples+ 80k active samples, and (d) 100k random samples. Employing active learning allows models toeffectively identify and localize regions containing rare environmental hazards, a feat that is difficultto achieve using random samples alone.
Figure 9: Examples of learned margins for visual signatures associated with dynamic actors. Fromleft to right: the first image shows a RGB view of the scene, the second image shows predictedaffordances y overlaid on top of the RGB view, the third image shows the projected confidence map,and the last image shows the cost map used to plan the optimal path. From the first example, it canbe seen that regions that are spatially close to dynamic actors are associated with higher traversalcosts in the final cost map, akin to a “margin of safety”. The second example shows that statichazards/obstacles such as barrels are not associated with substantial affordance margins.
Figure 11: Comparison of thresholded globalmaps constructed by frontier exploration usinggeometry (Left) and affordance-based (Right)representations in the same environment. In thissetting, semantic representations help the agenttake less damage over time, allowing for morearea to be explored during the episode.
Figure 10: Examples of affordance maps y Pre-dicted by the navigability module, showing ac-curate localization of semantic constraints withinthe scene. (Left) contains dynamic hazards inthe form of monsters and (Right) contains areasof geometry-affordance mismatch, in the form ofbarrels shorter than sensor height.
