Figure 1: Overview of our approach. The Neural SLAM module predicts a map and agent pose estimate fromincoming RGB observations and sensor readings. This map and pose are used by a Global policy to output along-term goal, which is converted to a short-term goal using an analytic path planner. A Local Policy is trainedto navigate to this short-term goal.
Figure 2: Architecture of the Neural SLAM module: The Neural SLAM module (fMap) takes in the currentRGB observation, St, the current and last sensor reading of the agent Pose xt-i：t, last agent Pose estimate, Xt-iand the map at the previous time step mt-1 and outputs an updated map, mt and the current agent pose estimate,Xt. ‘ST' denotes spatial transformation.
Figure 3: Plot showing the % Coverage as the episode progresses for ANS and the baselines on the large andsmall scenes in the Gibson Val set as well as the overall Gibson Val set.
Figure 4: Exploration visualization. Figure showing a sample trajectory of the Active Neural SLAM modelin the Exploration task. Top: RGB observations seen by the agent. Inset: Global ground truth map and pose(not visible to the agent). Bottom: Local map and pose predictions. Long-term goals selected by the Globalpolicy are shown by blue circles. The ground-truth map and pose are under-laid in grey. Map prediction isoverlaid in green, with dark green denoting correct predictions and light green denoting false positives. Agentpose predictions are shown in red. The light blue shaded region shows the explored area.
Figure 5: Real-world Transfer. Left: Image showing the living area in an apartment used for the real-worldexperiments. Right: Sample images seen by the robot and the predicted map. The long-term goal selected bythe Global Policy is shown by a blue circle on the map.
Figure 7: Performance of the proposed ANS model along with CMP and IL + Res18 + GRU (GRU) baselineswith increase in geodesic distance to goal and increase in GED Ratio on the Gibson Val set.
Figure 8: Figure showing sample trajectories of the proposed model along with the predicted map in thePointGoal task. The starting and goal locations are shown by black squares and blue circles, respectively. Theground-truth map is under-laid in grey. Map prediction is overlaid in green, with dark green denoting correctpredictions and light green denoting false positives. The blue shaded region shows the explored area prediction.
Figure 6: Screenshot of CVPR 2019 Habitat Chal-lenge Results. The proposed model was submittedunder code-name ‘Arnold’.
Figure 9: Pointgoal visualization. Figure showing sample trajectories of the proposed model along withpredicted map in the Pointgoal task as the episode progresses. The starting and goal locations are shown byblack squares and blue circles, respectively. Ground truth map is under-laid in grey. Map prediction is overlaidin green, with dark green denoting correct predictions and light green denoting false positives. Blue shadedregion shows the explored area prediction.
Figure 10: Plot showing the absolute Coverage in m2 as the episode progresses for ANS and the baselines onthe large and small scenes in the Gibson Val set as well as the overall Gibson Val set.
