Figure 1: Kingdra overview. In step 1, we train all the models using the unlabeled samples. In step 2we construct a graph modeling pairwise agreement of the models. In step 3, we get k high confidenceclusters by pruning out data-points for which the models do not agree. In step 4 we take the highconfidence clusters and generate pseudo labels. In step 5 we train the models using both unlabeledsamples and pseudo labeled samples. We iterate step 2 to step 5 and final clusters are generated.
Figure 2: The left graph shows clustering and pseudo-label accuracy Vs iterations for STL, CIFAR10,and the MNIST datasets. The right graph shows the number of pseudo-labels vs iterations.
Figure 3: Similarity graph from a sample of the input data points, obtained during three iterations ofKingdra for MNIST. The strong positive edges are shown by black lines and grey lines indicate thatat least two models think they belong to the same class. The different colors show different true classlabels.
Figure 4: Examples of randomly selected images obtained from our final clusters for MNIST andCIFAR10 datasets. The images with incorrect class associations are identified by red boxes.
Figure 5: Graph shows clustering accuracy vs iterations for DeepCluster. We see that there is noimprovement in accuracy after the first iteration.
