Figure 1: Comparison of the theoretical prediction of Corollary 1 for the expectation of thefirst 4 moments (colored lines) to the empirical average over 250 trials (black crosses) for arectangular network with two hidden layers of finite widths n1 = n2 = 5000 (L = 3) with thesmooth ReLU (left) and the normalized smooth ReLU (right), for the MSE loss on scaleddown 14x14 MNIST with N = 256. Only the first two moments are affected by S at thebeginning of training.
Figure 2: Illustration of the mutualorthogonality of I and S. For the 20first eigenvectors of I (blue) and S(orange), we plot the Rayleigh quo-tients vTIv and vTSv (with L = 3,n1 = n2 = 1000 and the normal-ized ReLU on 14x14 MNIST withN = 256). We see that the direc-tions where I is large are directionswhere S is small and vice versa.
Figure 3: Plot of the loss surface around a global mini-mum along the first (along the y coordinate) and fourth(x coordinate) eigenvectors of I . The network has L = 4,width n1 = n2 = n3 = 1000 for the smooth ReLU (left)and the normalized smooth ReLU (right). The data isuniform on the unit disk. Normalizing the non-linearitygreatly reduces the narrow valley structure of the lossthus speeding up training.
