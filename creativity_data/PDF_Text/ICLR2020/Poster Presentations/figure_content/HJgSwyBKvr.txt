Figure 1: Augmented data distributions derived from weak supervision. Shaded nodes denote ob-served quantities, and unshaded nodes represent unobserved (latent) variables.
Figure 2: Illustration of disentanglement, consistency, and restrictiveness of z1 with respect to thefactor of variation size. Each image of a shape represents the decoding g(z1:3) by the generativemodel. Each column denotes a fixed choice of z1 . Each row denotes a fixed choice of (z2, z3). Ademonstration of consistency versus restrictiveness on models from disentanglement_lib isavailable in Appendix B.
Figure 3: Heatmap visualization of ablation studies that measure either single-factor consistency orsingle-factor restrictiveness as a function of various supervision methods, conducted on Shapes3D.
Figure 4:	Correlation plot and scatterplots demonstrating the empirical relationship between C(i)and r(i) across all 864 models trained on ShaPeS3D.
Figure 5:	Disentanglement performance of a vanilla GAN, share pairing GAN, change pairing GAN,rank pairing GAN, and fully-labeled GAN, as measured by the mutual information gap across sev-eral datasets. A comprehensive set of performance evaluations on existing disentanglement metricsis available in Figure 13.
Figure 6: Visualization of two models from disentanglement_lib (model ids 11964 and12307), matching the schematic in Fig. 2. For each panel, we visualize an interpolation along asingle latent across rows, with each row corresponding to a fixed set of values for all other factors.
Figure 7:	This is the same plot as Figure 7, but where we restrict our hyperparameter sweep toalways set extra dense = False. See Appendix H for details about hyperparameter sweep.
Figure 8:	Restricted pairing guarantees consistency. Each plot shows the normalized consistencyscore of each model for each factor of variation. Our theory predicts each boxplot highlighted inred to achieve the highest consistency. Due to the prevalence of restricted pairing in the existingliterature, we chose to only conduct the single-factor restricted labeling experiment on Shapes3D.
Figure 9:	Change pairing guarantees restrictiveness. Each plot shows normalized restrictivenessscore of each model for each factor of variation (row) across different datasets (columns). Dif-ferent colors indicate models trained with change pairing on different factors. The appropriately-supervised model for each factor is marked in red.
Figure 10:	Share pairing guarantees consistency. Each plot shows normalized consistency score ofeach model for each factor of variation (row) across different datasets (columns). Different colorsindicate models trained with share pairing on different factors. The appropriately-supervised modelfor each factor is marked in red.
Figure 11:	Rank pairing guarantees consistency. Each plot shows normalized consistency score ofeach model for each factor of variation (row) across different datasets (columns). Different colorsindicate models trained with rank pairing on different factors. The appropriately-supervised modelfor each factor is marked in red.
Figure 12:	Normalized consistency vs. restrictiveness score of different models on each factor (row)across different datasets (columns). In many of the plots, we see that models trained via change-sharing (blue) achieve higher restrictiveness; models trained via share-sharing (orange) achievehigher consistency; models trained via both techniques (green) simultaneously achieve restrictive-ness and consistency in most cases.
Figure 13:	Disentanglement performance of a vanilla GAN, share pairing GAN, change pairingGAN, rank pairing GAN, and fully-labeled GAN, as measured by multiple disentanglement metricsin existing literature (rows) across multiple datasets (columns). According to almost all metrics, ourweakly supervised models surpass the baseline, and in some cases, even outperform the fully-labeledmodel.
Figure 14:	Performance of a vanilla GAN (blue), share pairing GAN (orange), change pairing GAN(green), rank pairing GAN (red), and fully-labeled GAN (purple), as measured by normalized con-sistency score of each factor (rows) across multiple datasets (columns). Factors {3, 4, 5} in the firstcolumn shows that distribution matching to all six change / share pairing datasets is particularlychallenging for the models when trained on certain hyperparameter choices. However, since con-sistency and restrictiveness can be measured in weakly supervised settings, it suffices to use thesemetrics for hyperparameter selection. We see in Figure 16 and Appendix G that using consistencyand restrictiveness for hyperparameter selection serves as a viable weakly-supervised surrogate forexisting fully-supervised disentanglement metrics.
Figure 15:	Performance of a vanilla GAN (blue), share pairing GAN (orange), change pairing GAN(green), rank pairing GAN (red), and fully-labeled GAN (purple), as measured by normalized re-strictiveness score of each factor (rows) across multiple datasets (columns). Since restrictivenessand consistency are complementary, we see that the anomalies in Figure 14 are reflected in thecomplementary factors in this figure.
Figure 16:	Scatterplot of existing disentanglement metrics versus average normalized consistencyand restrictiveness. Whereas existing disentanglement metrics are fully-supervised, it is possibleto measure average normalized consistency and restrictiveness with weakly supervised data (share-pairing and match-pairing respectively), making it viable to perform hyperparameter tuning underweakly supervised conditions.
Figure 17: Cars3D. Ground truth factors: elevation, azimuth, object type.
Figure 18: Shapes3D. Ground truth factors: floor color, wall color, object color, object size, objecttype, and azimuth.
Figure 19: dSprites. Ground truth factors: shape, scale, orientation, X-position, Y-position.
Figure 20: Scream-dSprites. Ground truth factors: shape, scale, orientation, X-position, Y-position.
Figure 21: SmallNORB. Ground truth factors: category, elevation, azimuth, lighting condition.
Figure 22: Zig-zag connectedness is necessary for restriveness union. Here n = m = 3. Coloredareas indicate the support of p(z1 , z2); the marked numbers indicate the measurement of s3 given(z1 , z2 ). Left two panels satisfy zig-zag connectedness (the paths are marked in gray) while the righttwo do not (indeed R(1) âˆ§ R(2) ; R({1, 2})). In the right-most panel, any zig-zag path connectingtwo points from blue and orange areas has to pass through boundary of the support (disallowed).
