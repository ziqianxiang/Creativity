Figure 1: Linear interpolations of inputs and respective outputs of a conditional generative modelbetween two MNIST and CIFAR10 images from different classes. X-axis is interpolation steps andY-axis negative log-likelihood in bits/dim (higher is more likely under model). MNIST interpolatedimages are far less likely than real images, whereas for CIFAR10 the opposite is observed, leading tohigh confidence classification of ambiguous out-of-distribution images.
Figure 2: Counter example construction. Shown on the left are the two class data densities, on theright the Bayes-optimal classifier for this problem (assuming λι > λ2) and the model we consider.
Figure 3: NLL for images conditioned on the correct class vs the highest probability Wrong class.
Figure 4: Average Log likelihoods and class probabilities for interpolations between data points fromdifferent classes, x-axis is interpolation coefficient α. The MNIST model behaves as desired androbustly detects interpolated images. The CIFAR10 model, however, fails strikingly and interpolatdimages are consistently more likely than true data under the model.
Figure 5: Top: Samples fromthe BG-MNIST-0 dataset. Bottom:Samples from conditional genera-tive model trained on the dataset.
Figure 6: Average log-likelihoods and class probabilities for interpolations between BG-MNIST-0datapoints. While classification is on par with MNIST models, the likelihood exhibits the samefailures as CIFAR10 models.
