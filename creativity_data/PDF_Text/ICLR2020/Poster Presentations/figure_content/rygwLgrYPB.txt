Figure 1: Limitation of statistics in terms of representing the probability distribution. In all subplots,X has zero mean and unit variance and y 〜N(0,1). In (a) (x, y)〜N(0, I). In (b), X 〜N(0,1) butcorrelated with y . In (c), x follows a skewed distribution. In (d), x follows a bi-modal distribution.
Figure 2: Illustration of minimization of the sliced Wasserstein distance between the current distri-bution and the target distribution. Note that it only concerns a distance in the projected dimension.
Figure 3: Illustration of PER and its gradient in R. Herein, PER is shifted by c so that Lper (0) - c =0. The Huber loss is defined as h(x) = |x| - 0.5 in |x| > 1 and h(x) = x2/2 in |x| ≤ 1 and thePseUdo-HUber loss is defined as g(χ) = √1+ x2 - 1.
Figure 4: Evolution of distributions of νh3, νh6, and νh9 for fixed randomly drawn i, j, k on trainingij	jset. (a)-(c) represent values (0.25, 0.5, 0.75) quantiles under PER, vanilla, and BN. (d) and (e)represent the sample mean and the sample variance of activations. Variance is clipped at 5 for bettervisualization.
Figure 5: Closeness to N(0, I) in the Wasserstein probability distribution space.
