Figure 1: An illustration of the intrinsic fragility of VAE representations. Outputs from a VariationalAutoencoder with encoder f and decoder g parametrized by η and θ, respectively, trained on CelebA.
Figure 2: Example VAE model. (left) Heatmap of the en-coder distribution (darker colors referring to higher prob-ability) q(Z = j∖X = i; μi,σ. where each row i is aprobability distribution over latents with a mode aroundμi and spread σ% (middle) HeatmaP of the decoder dis-tribution p(X = i∖Z = j, mj , vj ) where each column jis a probability distribution with mode at mj and spreadv. The prior p(Z) is chosen to be uniform and is notshown here. (right) The marginal model p(X = i∖m, v)= PjN=z1 p(Z = j)p(X = i∖Z = j, mj, v) depicted as anhistogram.
Figure 3: (a) Result by optimizing the ELBO for a VAE that illustrates the fragility of the encoder.
Figure 4: Simulation Results on ColorMNIST. The goal is the comparison of adversarial accuracyof VAE representations with SE representations trained with a selection radius of 0.1 and 0.2 anda selection budget of 20 PGD iterations. Vertical axis shows the adversarial accuracy as a functionof attack radius. The dashed and dotted lines show the nominal accuracy of the VAE and SE whenthere are no attacks (The SE nominal accuracy is virtually identical for different selection radii,hence only a single level is shown.)Attack Radius(a) Task: Color_____Ooooo0 8 6 4 2(求)Aue,Jn8<<BμesJ3>pv(b) Task: Digiture 7(a) for further results). We observe some limited improvements with SE using random selectionin adversarial accuracy compared to VAE but training a SE with adversarial selection seems to bemuch more effective. We note that the selection iteration budget was lower (L = 20 with no restarts)than the attack iteration budget (100 with 10 restarts) during evaluation. It was not practical to trainthe encoder with more powerful selection attacks, thus it remains to be seen if the tendency of in-creased accuracy with increased iteration budgets would continue. We also observe that essentiallythe same level of adversarial accuracy can be obtained with a small fraction of the available labels
Figure 5: Simulation Results on MNIST. The goal is illustrating the effect of the architecture (MLPand ConvNet). In all the examples, the SE is trained by a selection radius a budget of 50 PGDiterations. The linear classifier is always trained without any adversarial training, by fixing theencoder parameters. The blue dot, green triangle and red squares correspond to the standard VAEand SE trained with a selection radius of 0.1 and 0.2 respectively. The dashed and dotted lines showthe nominal accuracy of the VAE and SE when there are no attacks (The SE nominal accuracy isvirtually identical for different selection radii, hence only a single level is shown.)We have also repeated our experiments on the CelebA dataset, a large collection of high resolutionface images labeled with 40 attribute labels per example. We have used 17 of the attribute labelsas the targets of 17 different downstream classification tasks. The results are shown in Table.2.
Figure 6: Qualitative results on CelebA. Attacks to downstream tasks (a), (b) ’Mustache’ classifica-tion, (c), (d) ’Bald’ classification. (a) In the VAE case, the attack is successful but the perturbationdoes not have a visible structure. (b) The SE representation is attacked by a perturbation that canclearly be identified as drawing a beard on the image. In this case, the attack is able to fool the classi-fier and the generated image from the representation is that of a person with beard and mustache. Inthe second example (c), the VAE representation seems to be attacked by exploiting the non-smoothnature of the encoder by mapping the latent representation to the one in the vicinity of a clearlydifferent person with the desired features, as can be seen from the corresponding reconstruction.
Figure 7:	Simulation Results on ColorMNIST. (a) The goal is comparing the robustness as a resultof the selection procedures, uniformly random selection from the unit ball and adversarial selection.
Figure 8:	Simulation Results that illustrate label efficiency on CelebA. Dotted line shows down-stream task adversarial accuracy obtained by using all the labelled data. Once the representation isfixed, it is feasible to achieve the same accuracy with a small fraction of data.
