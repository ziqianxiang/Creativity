Figure 1: The pipeline of our proposed CrevNet where a single two-way autoencoder serves as bothencoder and decoder. CrevNet first observes a warm-up video sequence and then starts a multi-framevideo prediction without refeeding its own predictions.
Figure 2: The network architecture of CreVNet (Better viewed in color). The input video frames arefirst reshaped and split channelwise into two groups. These two groups are passed to the two-wayautoencoder (a) for feature extraction, and then to the predictor made up of multiple reversiblepredictive modules (b). The transformed high-level features produced by predictor are then passedback through the decoding pass of (a), shown here as a representative block (c) to yield its prediction.
Figure 3: An extremely hard sequence of Mov-ing MNIST where two digits are continuouslyoverlapped during the warm-up phase.
Figure 4: The visual comparison of Traffic4cast. The red boxes track some dynamics successfullycaptured by our CrevNet. Better viewed large.
Figure 5: The visual comparison of next-frame predictions on CaItech Pedestrian.
Figure 6: The visual comparison of 12-frame prediction on Caltech Pedestrian. Notice how wellCrevNet captures the detail and geometry of the buildings in the background, and the overall shading.
Figure 7: Visualization of 2D Object Detection on KITTI.
