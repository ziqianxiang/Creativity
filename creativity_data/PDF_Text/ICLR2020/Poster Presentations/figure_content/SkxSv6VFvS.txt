Figure 1: Adaptation for deformation. We show how different 3 × 3 convolutions interact withdeformations of two images. Kernel spaces are visualized as flat 2D Gaussians. Each “+” indicates acomputation between a pixel and a kernel value sampled from the data and kernel space. Their colorsrepresent corresponding kernel values. (a, b) Rigid kernels cannot adapt to specific deformations,thus consuming large model and data capacity. (c) Deformable Convolutions (Dai et al., 2017)reconfigure data towards common arrangement to counter the effects of geometric deformation. (d)Our Deformable Kernels (DKs) instead resample kernels and, in effect, adapt kernel spaces whileleaving the data untouched. Note that (b) and (c) share kernel values but sample different datalocations, while (b) and (d) share data locations but sample different kernel values.
Figure 2: Instantiations. We show how DK variants works with an example image that containsa large and a small object. (a) The global DK learns one set of kernel sampling grid given an inputimage and apply it to all data positions. (b) The local DK adapts kernels for each input patches, andinduces better locality for deformation modeling.
Figure 3: Semantics vs. Scales. We show t-SNE results of learned model dynamics using 10 ran-dom classes of objects from the COCO test-dev split. Each point represents an object extractedby ground-truth bounding box, whose color either denotes its class label or bounding box scale. Thecolor of an object scale is its normalized area rank discretized by every 10th percentile among alldata. Numbers inside parentheses indicate the dimension of learned dynamics before t-SNE. (a)The dynamics of Conditional Convolutions are closer to semantics than to object scales. (b) On thecontrary, our DKs learn dynamics that are significantly related to scales rather than semantics.
Figure 4: Learned Effective Receptive Fields. We show learned ERFs on three images with large,medium, and small objects from the COCO test-dev split. Given each ground-truth boundingbox, we visualize the non-zero ERF values of its central point. Theoretical RFs cover the wholeimage for all three examples and we thus ignore them in our plots. (a) Rigid kernels have strongcentral effects and a Gaussian-like ERF that cannot deal with object deformation alone. (b) De-formable Convolutions and (c) Deformable Kernels both tune ERFs to data. (d) Combining bothoperators together enables better modeling of 2D geometric transformation of objects.
Figure 5: Illustration of feed-forwarding through a 3×3 local Deformable Kernel from a 4×4scope. For each input patch, local DK first generates a group of kernel offsets {∆k} from inputfeature patch using the light-weight generator G (a 3×3 convolution of rigid kernel). Given theoriginal kernel weights W and the offset group {∆k}, DK samples a new set of kernel W0 using abilinear sampler B . Finally, DK convolves the input feature map and the sampled kernels to completethe whole computation.
Figure 6: Effective Receptive Field Comparison between rigid kernels and DKs under differentkinds of Object Deformation. At each row and from left to right, we show the original image(1300×800), the image rotated by -90 degrees and the image scaled by 1.5 times. Images arecropped and resized for the typesetting purpose.
