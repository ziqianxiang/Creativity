Figure 1: Concepts. In the featurespace, each training instance stochas-tically perturbs so that the resultantdecision boundaries (red line) explainwell for the test examples. Note thatthe noise distribution does not have tocover the test instances directly.
Figure 4:	Visualization of the task-specific decision boundaries in the last latent feature space. We use themodel trained with 1-shot. The visualizations are the projection of the features after completing the last (5th)inner-gradient step, where the sampled 4 examples (2 examples (,4) × 2 classes) participate in the inner-optimization. (a) and (b) are drawn from the same task. See Appendix C for the details about this visualization.
Figure 5:	Adversarial robustness against PGD attack with varying size of radius . The region of cleanaCCuraCies are magnified for better visualization.
Figure 6: Adversarial robustness against PGD attack with varying size of radius . The region of cleanaccuracies are magnified for better visualization.
Figure 7: Feature Visualization Layer activations and perturbed activations in Omniglot datset.							14Published as a conference paper at ICLR 2020Original Image (X	Channel 1 Activation R	Channel 1 Perturbed Activation		Channel 2 Activation n	Channel 2 Perturbed Activation K Q i^<		"''	^ x ⅛<		竽	岁		"-⅛ 士•:	YR	*⅛.∙小■ ■:■■■a	劭		⅛Λ⅛	‹∖t ■ ■. -		■ ! ■： J '■	|._S旧		■■・ √ ,	"√ ■- /	——	----.. 	-、. ——. ■ ；J	Y	J √l .
Figure 8: Visualization of stochastic features. We visualize the deterministic activations and the correspond-ing stochastic activations with perturbation.
