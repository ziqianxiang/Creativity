Figure 1: (a, b) Maximizing IEST over a family of invertible models. We can see that during trainingthe downstream classification performance improves (and the testing IEST value increases), eventhough the true MI remains constant throughout. (c) Downstream classification accuracy of a differentinvertible encoder (with the same architecture) trained to have poor performance. This demonstratesthe existence of encoders that provably maximize MI yet have bad downstream performance.
Figure 2: Maximizing IEST using a network architecture that can realize both invertible and non-invertible functions. (a, b) As IEST increases, the linear classification testing performance increases.
Figure 3: Downstream testing accuracy for INCE and INWJ, and testing INWJ value for MLP encodersg1 , g1 and different critic architectures (the testing INCE curve can be found in Appendix F). Bilinearand separable critics lead to higher downstream accuracy than MLP critics, while reaching lower INWJ.
Figure 4: (a, b) Downstream testing accuracy for different encoder architectures and MI estima-tors, using a bilinear critic trained to match a given target IEST of t (we minimize Lt(g1, g2) =|IEST(g1(X(1)); g1(X(2))) - t|; loss curves can be found in Appendix F). For a given estimator andt, ConvNet encoders clearly outperform MLP encoders in terms of downstream testing accuracy. (c)Estimating MI from i.i.d. and non-i.i.d. samples in a synthetic setting (Section 4). If negative samplesare not drawn i.i.d., both INCE and INWJ estimators can be greater than the true MI. Despite beingcommonly justified as a lower bound on MI, INCE is often used in the non-i.i.d. setting in practice.
Figure 5: Additional plot Section 3.1: The condition number of the Jacobian evaluated at inputsrandomly sampled from the data distribution deteriorates, i.e. g1 becomes increasingly ill-conditioned(lines represent 0th, 20th, . . . , 100th percentiles for INWJ ; the empirical distribution is obtained byrandomly sampling 128 inputs from the data distribution, computing the corresponding conditionnumbers, and aggregating them across runs).
Figure 6: Additional plot Section 3.2: Testing INCE value for MLP encoders g1, g1 and different criticarchitectures.
Figure 7: Additional plots Section 3.3: Testing loss for different encoder architectures and MIestimators, using a bilinear critic trained to match a given target IEST of t (we minimize Lt(g1 , g2) =|IEST(g1(X(1)); g1(X(2))) - t|).
Figure 8: Downstream testing accuracy for INCE and INWJ (top row), and corresponding testing IESTvalue (bottom row) for MLP encoders g1, g1 and different critic architectures. Bilinear and separablecritics lead to higher downstream accuracy than MLP critics, while reaching lower INWJ. Note thatINWJ exhibits high variance (which is a known property of INWJ (Poole et al., 2019)).
Figure 9: Downstream testing accuracy (top row) and testing loss value (bottom row) for differentencoder architectures and MI estimators, using a bilinear critic trained to match a given target IEST oft (we minimize Lt(g1, g2) = |IEST(g1(X(1)); g1(X(2))) - t|). For a given estimator and t, ConvNetencoders clearly outperform MLP encoders in terms of downstream testing accuracy.
