Figure 1: Misclassification rate of an MNISTmodel on the noisy FGSM’s adversarial ex-amples as a function of correctly estimatedcoordinates of sign(Vχf (x, y)) on 1000 ran-dom MNIST images. Estimating the sign ofthe top 30% gradient coordinates (in termsof their magnitudes) is enough to achieve arough misclassification rate of 70%. Moredetails can be found in Appendix A.
Figure 2: Performance of black-box attacks in the '∞ and '2 perturbation constraint. The plots showthe average number of queries used per successful image for each attack when reaching a specifiedsuccess rate.
Figure 3: TWo estimations of the '∞ adversarial cones for two IMAGENET models: v3 andv3adv-ens4. The first estimation (GAAS: Gradient-Aligned Adversarial Subspace) finds k orthogonalvectors maximally aligned with the gradient sign q* Tramer et al. (2017a). The second (SAAS:SignHunter-Aligned Adversarial Subspace) finds k orthogonal vectors that are maximally alignedwith SignHunter’s s (Algorithm 2, Line 8) after 1, 000 queries. Similar to (Tramer et al., 2017a,Figure 2), for 500 correctly classified points x and ∈ {4, 10, 16}, we plot the probability that wefind at least k orthogonal vectors ri—computed based on (Tramer et al., 2017a, Lemma 7)—suchthat ∣∣ri∣∣∞= e and X + r is misclassified. For both models and for the same points x, SAAS findsmore orthogonal adversarial vectors ri than GAAS, thereby providing a better characterization ofthe space of adversarial examples in the vicinity of a point, albeit without a white-box access to themodels.
Figure 4: Misclassification rate of three neural nets (for (a) MNIST, (b) CIFAR10, and (c) IMAGENET,respectively) on the noisy FGSM’s adversarial examples as a function of correctly estimated coordinates ofsign(Vχf (x,y)) on random 1000 images from the corresponding evaluation dataset, with the maximumallowed '∞ perturbation e being set to 0.3, 12, and 0.05, respectively. Across all the models, estimating the signof the top 30% gradient coordinates (in terms of their magnitudes) is enough to achieve a misclassification rateof 〜70%. Note that Plot (c) is similar to Ilyas et al. (2019)’S Figure 1, but it is produced with TensorFloWrather than PyTorch.
Figure 5: Misclassification rate of three neural nets (for (a) MNIST, (b) CIFAR10, and (c) IMAGENET,respectively) on the noisy FGSM’s adversarial examples as a function of correctly estimated coordinates ofsign(Vχf (x,y)) on random 1000 images from the corresponding evaluation dataset, With the maximumallowed `2 perturbation being set to 3, 127, and 5, respectively. Compared to Figure 4, the performance onMNIST and CIFAR10 drops significantly.
Figure 6: Tuning testbed for the attacks. A synthetic loss function was used to tune the performanceof the attacks over a random sample of 25 images for each dataset and `p perturbation constraint.
Figure 7: Performance curves of attacks on MNIST for '∞ (first column) and '2 (second column)perturbation constraints. Plots of Avg. Loss row reports the loss as a function of the numberof queries averaged over all images. The Avg. Hamming Similarity row shows the Hammingsimilarity of the sign of the attack's estimated gradient g with true gradient's sign q*, computed as1 - ∣∣sign(g) - q*∣∣H/n and averaged over all images. Likewise, plots of the Avg. Cosine Similarityrow show the normalized dot product of g and g* averaged over all images. The Success Rate rowreports the attacks' cumulative distribution functions for the number of queries required to carry out asuccessful attack up to the query limit of 10, 000 queries. The Avg. # Queries row reports the averagenumber of queries used per successful image for each attack when reaching a specified success rate:the more effective the attack, the closer its curve is to the bottom right of the plot.
Figure 8: Performance curves of attacks on CIFAR10 for '∞ (first column) and '2 (second column)perturbation constraints. Plots of Avg. Loss row reports the loss as a function of the numberof queries averaged over all images. The Avg. Hamming Similarity row shows the Hammingsimilarity of the sign of the attack,s estimated gradient g with true gradient,s sign q*, computed as1 - ∣∣sign(g) - q*∣∣H/n and averaged over all images. Likewise, plots of the Avg. Cosine Similarityrow show the normalized dot product of g and g* averaged over all images. The Success Rate rowreports the attacks, cumulative distribution functions for the number of queries required to carry out asuccessful attack up to the query limit of 10, 000 queries. The Avg. # Queries row reports the averagenumber of queries used per successful image for each attack when reaching a specified success rate:the more effective the attack, the closer its curve is to the bottom right of the plot.
Figure 9: Performance curves of attacks on IMAGENET for '∞ (first column) and '2 (secondcolumn) perturbation constraints. Plots of Avg. Loss row reports the loss as a function of thenumber of queries averaged over all images. The Avg. Hamming Similarity row shows the Hammingsimilarity of the sign of the attack's estimated gradient g with true gradient,s sign q*, computed as1 - ∣∣sign(g) - q*∣∣H/n and averaged over all images. Likewise, plots of the Avg. Cosine Similarityrow show the normalized dot product of g and g* averaged over all images. The Success Rate rowreports the attacks’ cumulative distribution functions for the number of queries required to carry out asuccessful attack up to the query limit of 10, 000 queries. The Avg. # Queries row reports the averagenumber of queries used per successful image for each attack when reaching a specified success rate:the more effective the attack, the closer its curve is to the bottom right of the plot.
Figure 10: Performance curves of attacks on the public black-box challenges for MNIST (firstcolumn), CIFAR10 (second column) and IMAGENET (third column). Plots of Avg. Loss rowreports the loss as a function of the number of queries averaged over all images. The Avg. HammingSimilarity row shows the Hamming similarity of the sign of the attack’s estimated gradient g with truegradient,s sign q*, computed as 1 - ∣∣sign(g) - q」H/n and averaged over all images. Likewise,plots of the Avg. Cosine Similarity row show the normalized dot product of g and g* averaged over allimages. The Success Rate row reports the attacks' cumulative distribution functions for the numberof queries required to carry out a successful attack up to the query limit of 5, 000 queries for MNISTand CIFAR10 (1, 000 queries for IMAGENET). The Avg. # Queries row reports the average numberof queries used per successful image for each attack when reaching a specified success rate: the moreeffective the attack, the closer its curve is to the bottom right of the plot.
Figure 11: Magnitudes of gradient coordinates are concentrated: Plots (a), (b), and (c) showhistograms of the magnitudes of gradient coordinates of the loss function L(x, y) with respect to theinput point (image) x for MNIST, CIFAR10, and IMAGENET neural net models over 1000 imagesfrom the corresponding evaluation set, respectively. Plots (d), (e), (f) show the same but at inputpoints (images) sampled randomly within B∞(x, ∈): the '∞-ball of radius e = 0.3, 12, and 0.05around the images in Plots (a), (b), and (c), respectively.
Figure 12: Performance of different sign flips patterns for Algorithm 2, Line 8 in the '∞ and '2perturbation constraints: our proposition (SignHunter), random sign flips (Rand), sequentialsingle sign flips (Naive), stochastic hill climbing (SHC), which is similar to Rand but retain the fliponly if it is better in terms of the observed model loss. With higher dimensions, SHC is comparableto SignHunter but does not enjoy a deterministic upper-bound on the query complexity.
Figure 13: Performance of SIMBA and SignHunter in the '∞ and '2 perturbation settings ofSection 4 on CIFAR10. The plots show the average number of queries used per successful image foreach attack when reaching a specified success rate. In line with Guo et al. (2019), we used a step sizeof δ = 50 for `2 (the authors used δ = 0.2 for [0, 1]-valued pixels, our setup takes images in [0, 255]so δ = 0.2 * 255 〜50). For '∞, We used δ = 2, following NES,s setup in Table 4.
Figure 14: Illustration of adversarial examples crafted by SignHunter in comparison to attacksthat are based on the continuous optimization (e.g., NES and BanditsTD) in both (a) '∞ and (b)'2 settings. For both e-'2 and ∈∕√n-'∞ perturbation balls, SignHunter behaves the same, whilecontinuous attacks such as NES have access to more possible perturbations in the `2 setup comparedto their perturbations in the '∞ setup. This is demonstrated on CIFAR10 in Figure 15.
Figure 15: Performance of black-box attacks in the '∞ and '2 perturbation constraints. The plotsshow the average number of queries used per successful image for each attack when reaching aspecified success rate. Note that (b) is similar to the `2 setup examined in Section 4.
