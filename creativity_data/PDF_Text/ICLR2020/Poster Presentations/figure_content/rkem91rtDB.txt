Figure 1: SEED consists of three components: sampling, encoding, and embedding distribution.
Figure 2: Expressive power comparison between WEAVEs and vanilla random walks: while blueand orange walks cannot be differentiated in terms of vanilla random walks, the difference underWEAVEs is outstanding.
Figure 3: t-SNE VisUalziation of the MUTAG representations with different sampling numbers(a) Walk length = 5	(b) Walk length = 10	(C) Walk length = 15	(d) Walk length = 20	(e) Walk length = 25Figure 4: t-SNE Visualziation of MUTAG representations with different walk lengths-10	0	10100-104.4	Ablation S tudyWalk length and sample numbers are two meta-parameters in the SEED framework. By adjustingthese two meta-parameters, we can make trade-off between effectiVeness and computational effi-ciency. In the experiment, we empirically eValuate the impact of the two meta-parameters on theMUTAG dataset. In Table 2, each row denotes the performance with different sampling numbers(from 25 to 800) while the walk length is fixed to 10. MoreoVer, we adjust the walk length from 5to 25 while sampling number is fixed to 200 in Table 3. We can see that the performance of SEEDin both classification and clustering tasks increases as there are more subgraphs sampled, especiallyfor the changes from 25 to 200. Meanwhile, we obserVe the increasing rates diminish dramaticallywhen sampling number ranges from 200 to 800. Similarly, the performance of SEED increase asthe walk length grows from 5 to 20, and the performance starts to conVerge when the length goesbeyond 20.
Figure 4: t-SNE Visualziation of MUTAG representations with different walk lengths-10	0	10100-104.4	Ablation S tudyWalk length and sample numbers are two meta-parameters in the SEED framework. By adjustingthese two meta-parameters, we can make trade-off between effectiVeness and computational effi-ciency. In the experiment, we empirically eValuate the impact of the two meta-parameters on theMUTAG dataset. In Table 2, each row denotes the performance with different sampling numbers(from 25 to 800) while the walk length is fixed to 10. MoreoVer, we adjust the walk length from 5to 25 while sampling number is fixed to 200 in Table 3. We can see that the performance of SEEDin both classification and clustering tasks increases as there are more subgraphs sampled, especiallyfor the changes from 25 to 200. Meanwhile, we obserVe the increasing rates diminish dramaticallywhen sampling number ranges from 200 to 800. Similarly, the performance of SEED increase asthe walk length grows from 5 to 20, and the performance starts to conVerge when the length goesbeyond 20.
Figure 5: t-SNE visualization of the learned representations from different kernels on MUTAG5 Embedding DistributionWe employ t-SNE (Maaten & Hinton, 2008) to visualize learned graph representations in Figure 3and Figure 4. Red and blue colors indicate two labels. We observe that the boundary becomesclearer when sample number or walk length increases.
Figure 6: Different types of graphs with random walk W which can visit all the edges.
Figure 7: Walk representation distributions of graphs without attributes, graphs with discrete at-tributes, and graphs with continuous attributes.
Figure 8: Response time comparison between exact MMD and its Nystrom approximationFirst, we investigate the impact to the effectiveness in the downstream tasks. In this set of exper-iment, we implement a baseline named SEED-Nystrom, where the Nystrom method is applied toapproximate RBF kernel based MMD during training phases with 200 sampled WEAVEs. In partic-ular, top 30 eigenvalues and the corresponding eigenvectors are selected for the approximation. Asshown in Table 7, across five datasets, SEED-NyStrOm achieves comparable performance, comparedwith the case where an identity kernel is adopted.
