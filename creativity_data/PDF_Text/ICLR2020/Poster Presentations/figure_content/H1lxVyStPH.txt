Figure 1: Overall framework of the proposed learning algorithm. Once the random forest is con-structed with CNN features, we sample the triplets based on the probability mass function of the splitresults. The networks are then updated via the loss function of sampled triplets.
Figure 2: Probability mass function for sampling triplets. Probability mass functions for positive andnegative samples (Pp and Pn respectively) are constructed by sample distribution with the anchorsin leaf nodes. Squares and triangles represent training data in leaf nodes of the decision trees, andthe shapes represent their labels. For an anchor (black square), the positive pool contains the data indifferent leaf nodes and with the same label (red and blue squares), and the negative pool containseither the data in the same leaf node with the same or different labels. Probability mass functions arethe normalized histogram of the positive and negative pools.
Figure 3: Performance evaluation of random forests constructed on canonical, strengthened andgeneralized feature space. The iteration on each figure is equal to the epoch of the network training.
