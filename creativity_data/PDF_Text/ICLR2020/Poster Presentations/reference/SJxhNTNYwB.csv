title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Adversarial vision challenge,2018, In 32nd Conference onNeural Information Processing Systems (NIPS 2018) Competition Track
 Guessing smart: Biasedsampling for efficient black-box adversarial attacks,2018, arXiv preprint arXiv:1812
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 A frank-wolfe framework for efficient and effectiveadversarial attacks,2018, arXiv preprint arXiv:1811
 Improving black-box adversarialattacks with a transfer-based prior,2019, arXiv preprint arXiv:1906
 Efficientdecision-based black-box adversarial attacks on face recognition,2019, arXiv preprint arXiv:1904
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Black-box adversarial attacks withlimited queries and information,2018, In Jennifer Dy and Andreas Krause (eds
 Prior convictions: Black-box adversarialattacks with bandits and priors,2018, arXiv preprint arXiv:1807
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Gradient-based learning applied todocUment recognition,1998, Proceedings of the IEEE
 Delving into transferable adversarial examplesand black-box attacks,2016, arXiv preprint arXiv:1611
 Conditional generative adversarial nets,2014, arXiv preprintarXiv:1411
 Parsimonious black-box adversarial attacks viaefficient combinatorial optimization,2019, arXiv preprint arXiv:1905
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Updating quasi-newton matrices with limited storage,1980, Mathematics of computation
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Going deeper with convolutions,2015, InProceedings of the IEEE conference on computer vision and pattern recognition
 Autozoom: Autoencoder-based zeroth order optimization method for attackingblack-box neural networks,2018, arXiv preprint arXiv:1805
 A direct approach to robust deep learning using adversarialnetworks,2019, In International Conference on Learning Representations
 Feature denoising forimproving adversarial robustness,2018, arXiv preprint arXiv:1812
 Aggregated residualtransformations for deep neural networks,2017, In Proceedings of the IEEE conference on computervision and pattern recognition
