title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Explaining and harnessing adversarialexamples,2015, International Conference on Learning Representation
 Using pre-training can improve model robustnessand uncertainty,2019, arXiv preprint arXiv:1901
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Gradient-based learning appliedto document recognition,1998, Proceedings of the IEEE
 Learning without forgetting,2018, IEEE transactions on pattern analysisand machine intelligence
 A survey on transfer learning,2009, IEEE Transactions on knowledgeand data engineering
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems
 Is robustnessthe cost of accuracy?-a comprehensive study on the robustness of 18 deep image classificationmodels,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Wide residual networks,2016, arXiv preprintarXiv:1605
