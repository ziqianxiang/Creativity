title,year,conference
 Threat of adversarial attacks on deep learning in computer vision:A survey,2018, arXiv preprint arXiv:1801
 Sorting out lipschitz function approximation,2019, InInternational Conference on Machine Learning
 Understanding deep neuralnetworks with rectified linear units,2018, In International Conference on Learning Representations
 Synthesizing robust adversarialexamples,2018, In International Conference on Machine Learning
 Universal lipschitz approximation in bounded depthneural networks,2019, arXiv preprint arXiv:1904
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Approximation by superpositions of a sigmoidal function,1989, Mathematics of Control
 Training verified learners with learned verifiers,2018, arXivpreprint arXiv:1805
 Robust physical-world attacks on deep learning visualclassification,2018, In IEEE Conference on Computer Vision and Pattern Recognition
 AI2: safety and robustness certification of neural networks with abstractinterpretation,2018, In IEEE Symposium on Security and Privacy
 On the effectiveness ofinterval bound propagation for training verifiably robust models,2018, arXiv preprint arXiv:1810
 Towards deep neural network architectures robust to adversarialexamples,2015, In International Conference on Learning Representations
 ReLU Deep Neural Networks and Linear FiniteElements,2018, arXiv preprint arXiv:1807
 Multilayer feedforward networks areuniversal approximators,1989, Neural Networks
 Reluplex: Anefficient SMT solver for verifying deep neural networks,2017, In Computer Aided Verification (CAV)
 On the geometry of adversarial examples,2018, arXiv preprintarXiv:1811
 Learning multiple layers of features from tiny images,2009, 2009
 Gradient-based learning applied to documentrecognition,1998, Proc
 Certifiedrobustness to adversarial examples with differential privacy,2019, In IEEE Symposium on Security andPrivacy
 Certified adversarial robustness withadditive noise,2019, In Advances in Neural Information Processing Systems (NeurIPS)
 Differentiable abstract interpretation forprovably robust neural networks,2018, In International Conference on Machine Learning
 A provable defense for deep residualnetworks,2019, arXiv preprint arXiv:1903
 Universaladversarial perturbations,2017, In IEEE Conference on Computer Vision and Pattern Recognition
 The limitations of deep learning in adversarial settings,2016, In IEEE EuropeanSymposium on Security and Privacy
 Semidefinite relaxations for certifyingrobustness to adversarial examples,2018, In Advances in Neural Information Processing Systems(NeurIPS)
 Certified defenses against adversarialexamples,2018, In International Conference on Learning Representations
 A convex relaxationbarrier to tight robustness verification of neural networks,2019, arXiv preprint arXiv:1902
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems (NeurIPS)
 Fastand effective robustness certification,2018, In Advances in Neural Information Processing Systems(NeurIPS)
 An abstract domain forcertifying neural networks,2019, PACMPL
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Region configurations for realizability of lattice piecewise-linearmodels,1999, Mathematical and Computer Modelling
 Evaluating robustness of neural networks with mixedinteger programming,2019, In International Conference on Learning Representations
 Mixtrain: Scalable training of formallyrobust neural networks,2018, arXiv preprint arXiv:1811
 Efficient formal safetyanalysis of neural networks,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Generating adversarialexamples with adversarial networks,2018, In International Joint Conference on Artificial Intelligence
 Training forfaster adversarial robustness verification via inducing relu stability,2019, In International Conference onLearning Representations
 Efficient neural networkrobustness certification with general activation functions,2018, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Improving the robustness ofdeep neural networks via stability training,2016, In IEEE Conference on Computer Vision and PatternRecognition
