title,year,conference
 Stronger generalization bounds fordeep nets via a compression approach,2018, arXiv preprint arXiv:1802
 Spectrally-normalized margin bounds forneural networks,2017, In Advances in Neural Information Processing Systems
 Benign ovefitting in linearregression,2019, arXiv preprint arXiv:1906
 A training algorithm for optimalmargin classifiers,1992, In Proceedings of the fifth annual workshop on Computational learning theory
 Concentration inequalities and empirical processes theory applied to the analysisof learning algorithms,2002, 2002
 Entropy-sgd: Biasing gradientdescent into wide valleys,2016, arXiv preprint arXiv:1611
 Support-vector networks,1995, Machine learning
 Largemargin deep networks for classification,2018, In Advances in neural information processing systems
 Generalizable adversarial training via spectral nor-malization,2018, arXiv preprint arXiv:1811
 Size-independent sample complexity ofneural networks,2017, arXiv preprint arXiv:1712
 Implicit bias of gradient descenton linear convolutional networks,2018, In Advances in Neural Information Processing Systems
 Surprises in high-dimensional ridgeless least squares interpolation,2019, arXiv preprint arXiv:1903
 Kernel methods in machine learn-ing,2008, The annals ofstatiStics
 A hessian based complexity measure fordeep networks,2019, arXiv preprint arXiv:1905
 Risk and parameter convergence of logistic regression,2018, arXiv preprintarXiv:1803
 Predicting the generalization gapin deep networks with margin distributions,2018, arXiv preprint arXiv:1810
 On large-batch training for deep learning: Generalization gap and sharp minima,2016, arXivpreprint arXiv:1609
 Adversarial risk bounds for binary classification via function trans-formation,2018, arXiv preprint arXiv:1810
 Empirical margin distributions and bounding thegeneralization error of combined classifiers,2002, The Annals of Statistics
 Algorithmic regularization in over-parameterizedmatrix sensing and neural networks with quadratic activations,2017, arXiv preprint arXiv:1712
" Just interpolate: Kernel"" ridgeless"" regression can gener-alize",2018, arXiv preprint arXiv:1808
 Soft-margin softmax fordeep classification,2017, In International Conference on Neural Information Processing
 Lexico-graphic and depth-sensitive margins in homogeneous and non-homogeneous deep models,2019, arXivpreprint arXiv:1905
 Deterministic pac-bayesian generalization bounds for deepnetworks via generalizing noise-resilience,2019, arXiv preprint arXiv:1905
 Norm-based capacity control in neuralnetworks,2015, In Conference on Learning Theory
 Exploring general-ization in deep learning,2017, In Advances in Neural Information Processing Systems
 A pac-bayesian approach tospectrally-normalized margin bounds for neural networks,2017, arXiv preprint arXiv:1707
 Sensitivity and generalization in neural networks: an empirical study,2018, arXiv preprintarXiv:1802
 Adversarialtraining can hurt generalization,2019, arXiv preprint arXiv:1906
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Robust large margin deepneural networks,2017, IEEE Transactions on Signal Processing
 Optimistic rates for learning with a smoothloss,2010, arXiv preprint arXiv:1009
 Deep learning face representation byjoint identification-verification,2014, In Advances in neural information processing systems
 Data-dependent sample complexity of deep neural networks via lipschitzaugmentation,2019, arXiv preprint arXiv:1905
 A discriminative feature learning approachfor deep face recognition,2016, In European conference on computer vision
 Rademacher complexity for adversariallyrobust generalization,2018, arXiv preprint arXiv:1810
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
 As Claim A,2010,1 holds for any choice of (x
 In the setting of Lemma A,2010,2
