title,year,conference
 ObfusCated gradients give a false sense ofseCurity: CirCumventing defenses to adversarial examples,2018, International Conference on MachineLearning (ICML)
 Thermometer enCoding: One hotway to resist adversarial examples,2018, International Conference on Learning Representations
 Adversarial examples are not easily deteCted: Bypassing tendeteCtion methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 201738th IEEE Symposium on Security and Privacy (SP)
 AttaCking visual languagegrounding with adversarial examples: A Case study on neural image Captioning,2018, In Proceedingsof the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: LongPapers)
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 VerifiCation ofdeep probabilistiC models,2018, CoRR
 Training verified learners with learned verifiers,2018, arXivpreprint arXiv:1805
 Adual approaCh to sCalable verifiCation of deep networks,2018, UAI
 Robust physiCal-world attaCks on deep learningvisual ClassifiCation,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Explaining and harnessing adversarialexamples,2015, ICLR
 On the effeCtiveness of interval bound propagationfor training verifiably robust models,2018, arXiv preprint arXiv:1810
 Countering adversarialimages using input transformations,2018, In ICLR
 Formal guarantees on the robustness of a classifieragainst adversarial manipulation,2017, In Advances in Neural Information Processing Systems (NIPS)
 Reluplex: An efficientSMT solver for verifying deep neural networks,2017, In International Conference on Computer AidedVerification
 Adversarial machine learning at scale,2017, InInternational Conference on Learning Representations
 Certifiedrobustness to adversarial examples with differential privacy,2018, arXiv preprint arXiv:1802
 Second-order adversarial attack andcertifiable robustness,2018, arXiv preprint arXiv:1809
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, In International Conference on Learning Representations (ICLR)
 Differentiable abstract interpretation for provablyrobust neural networks,2018, In International Conference on Machine Learning
 A provable defense for deep residualnetworks,2019, arXiv preprint arXiv:1903
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Verification of non-linearspecifications for neural networks,2019, ICLR
 Certified defenses against adversar-ial examples,2018, International Conference on Learning Representations (ICLR)
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, arXivpreprint arXiv:1906
 A convex relaxationbarrier to tight robust verification of neural networks,2019, arXiv preprint arXiv:1902
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Robustness certification withrefinement,2019, ICLR
 Certifying some distributional robustness withPrinciPled adversarial training,2018, In ICLR
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examPles,2017, arXivpreprint arXiv:1710
 Intriguing ProPerties of neural networks,2013, arXiv preprint arXiv:1312
 Mixtrain: Scalable training of formallyrobust neural networks,2018, arXiv preprint arXiv:1811
 Efficient formal safetyanalysis of neural networks,2018, In Advances in Neural Information Processing Systems
 Towards fast comPutation of certified robustness for ReLU networks,2018, InInternational Conference on Machine Learning
 Provable defenses against adversarial examPles via the convex outeradversarial PolytoPe,2018, In International Conference on Machine Learning
 Scaling Provable adversarialdefenses,2018, Advances in Neural Information Processing Systems (NIPS)
 Characterizingadversarial examPles based on sPatial consistency information for semantic segmentation,2018, InProceedings of the European Conference on Computer Vision (ECCV)
 Generating adversarialexamPles with adversarial networks,2018, IJCAI18
 SPatially transformedadversarial examPles,2018, ICLR18
 Advit: Adversarial frames identifier based on temPoral consistencyin videos,2019, In Proceedings of the IEEE International Conference on Computer Vision
 Meshadv: Adversarial meshesfor visual recognition,2019, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Training for fasteradversarial robustness verification via inducing relu stability,2019, ICLR
 Structured adversarial attack: Towards general imPlementation and betterinterPretability,2018, arXiv preprint arXiv:1808
 Efficient neural networkrobustness certification with general activation functions,2018, In Advances in Neural InformationProcessing Systems (NIPS)
 Thelimitations of adversarial training and the blind-spot attack,2019, ICLR
 Recurjac: An efficient recursive algorithm forbounding jacobian matrix of neural networks and its applications,2019, AAAI Conference on ArtificialIntelligence
 Distributionally adversarial attack,2018, arXiv preprintarXiv:1808
1 or 0,2018,2
