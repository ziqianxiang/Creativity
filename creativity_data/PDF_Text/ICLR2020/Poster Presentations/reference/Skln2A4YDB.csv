title,year,conference
 Sample-efficientreinforcement learning with stochastic ensemble value expansion,2018, CoRR
 Deep reinforcement learn-ing in a handful of trials using probabilistic dynamics models,2018, arXiv preprint arXiv:1805
 Addressing function approximation error inactor-critic methods,2018, arXiv preprint arXiv:1802
 Soft actor-critic: Off-policy maxi-mum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprint arXiv:1801
 Soft actor-critic algorithmsand applications,2018, CoRR
 Learningcontinuous control policies by stochastic value gradients,2015, In Advances in Neural InformationProcessing Systems
 Approximately optimal approximate reinforcement learning,2002, In INPROC
 Uncertainty-driven imagination for continuous deep rein-forcement learning,2017, In Sergey Levine
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Model-ensembletrust-region policy optimization,2018, arXiv preprint arXiv:1802
 Learning neural network policies with guided policy search underunknown dynamics,2014, In Advances in Neural Information Processing Systems
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Algorithmicframework for model-based deep reinforcement learning with theoretical guarantees,2019, ICLR
 Asynchronous methods for deep reinforcementlearning,2016, In International Conference on Machine Learning
 Neural network dynam-ics for model-based deep reinforcement learning with model-free fine-tuning,2017, arXiv preprintarXiv:1708
 Mpc-inspiredneural network policies for sequential decision making,2018, CoRR
 Gradient estimation usingstochastic computation graphs,2015, CoRR
 Universal planningnetworks,2018, arXiv preprint arXiv:1804
 Planning by incremental dynamic programming,1991, In Machine Learning Proceedings1991
 Introduction to Reinforcement Learning,0262, MIT Press
 Value iteration networks,2016, CoRR
 Exploring model-based planning with policy networks,2019, CoRR
 Benchmarking model-based reinforcementlearning,2019, CoRR
