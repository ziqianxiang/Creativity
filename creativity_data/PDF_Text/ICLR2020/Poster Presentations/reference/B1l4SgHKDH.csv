title,year,conference
 Discrim-inator rejection sampling,2018, arXiv preprint arXiv:1810
 Generating sentences from a continuous space,2016, In SIGNLL Conference on ComputationalNatural Language Learning
 BERT: pre-training of deepbidirectional transformers for language understanding,2018, CoRR
 Implicit generation and generalization in energy-based models,2019, CoRR
 Classicalstructured prediction losses for sequence to sequence learning,2018, In North American Chapter of theAssociation for Computational Linguistics
 Learning generative con-vnets via multi-grid modeling and sampling,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Generative adversarial nets,2014, In NIPS
 Noise-contrastive estimation: A new estimation principlefor unnormalized statistical models,2010, In Proceedings of the Thirteenth International Conferenceon Artificial Intelligence and Statistics
 Training products of experts by minimizing contrastive divergence,2002, NeuralComputation
 A practical guide to training restricted boltzmann machines,2012, In Neural networks:Tricks of the trade
 The curious case of neural text degener-ation,2019, arXiv preprint arXiv:1904
 Neural networks and physical systems with emergent collective computational abil-ities,1982, In National Academy of Sciences of the USA
 Skip-thought vectors,2015, arXiv preprint arXiv:1506
 A tutorial onenergy-based learning,2006, Predicting Structured Outputs
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Noise contrastive estimation and negative sampling for condi-tional models: Consistency and statistical efficiency,2018, In Empirical Methods for Natural LanguageProcessing
 Global autoregressive models fordata-efficient sequence learning,2019, In Conference on Computational Natural Language Learning
 On the difficulty of training recurrent neuralnetworks,2013, In International conference on machine learning
 Languagemodels are unsupervised multitask learners,2019, OpenAI Blog
 Sequence level train-ing with recurrent neural networks,2016, In International Conference on Learning Representation
 Neural machine translation of rare words withsubword units,2015, arXiv preprint arXiv:1508
 Improved training of neural trans-dimensional random field languagemodels with dynamic noise-contrastive estimation,2018, In 2018 IEEE Spoken Language TechnologyWorkshop (SLT)
 Learning neural trans-dimensional random field language models withnoise-contrastive estimation,2018, In 2018 IEEE International Conference on Acoustics
 Exponential family harmoniums with anapplication to information retrieval,2005, In Neural Information Processing Systems
 A theory of generative convnet,2016, InInternational Conference on Machine Learning
 Synthesizing dynamic patterns by spatial-temporal generative convnet,2017, In Proceedings of the ieee conference on computer vision andpattern recognition
 Adversarially regular-ized autoencoders,2018, In International Conference in Machine Learning
 Aligning books and movies: Towards story-like visual explanations by watchingmovies and reading books,2015, In The IEEE International Conference on Computer Vision (ICCV)
