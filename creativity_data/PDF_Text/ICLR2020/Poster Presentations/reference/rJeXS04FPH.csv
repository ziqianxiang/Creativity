title,year,conference
 Online embedding com-pression for text classification using low rank matrix factorization,2019, In Proceedings of the AAAIConference on Artificial Intelligence
 Adaptive input representations for neural language modeling,2019, InInternational Conference on Learning Representations
 Neural machine translation by jointlylearning to align and translate,2015, In International Conference on Learning Representations
 An empirical evaluation of generic convolutionaland recurrent networks for sequence modeling,2018, arXiv:1803
 Massive exploration of neural ma-chine translation architectures,2017, arXiv preprint arXiv:1703
 Groupreduce: Block-wise low-rank approximation for neural language model shrinking,2018, In Advances in Neural InformationProcessing Systems
 Compressing neural language models bysparse word representations,2016, arXiv preprint arXiv:1610
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Classes for fast maximum entropy training,2001, In 2001 IEEE International Conferenceon Acoustics
 Improving neural language models with acontinuous cache,2017, In International Conference on Learning Representations
 Tying word vectors and word classifiers: Aloss framework for language modeling,2017, In International Conference on Learning Representations
 Exploring thelimits of language modeling,2016, arXiv preprint arXiv:1602
 Character-aware neural languagemodels,2016, In Thirtieth AAAI Conference on Artificial Intelligence
 Factorization tricks for lstm networks,2017, In InternationalConference on Learning Representations Workshops
 Simple recurrent units for highly paral-lelizable recurrence,2018, In Empirical Methods in Natural Language Processing (EMNLP)
 Effective approaches to attention-based neural machine translation,2015, In Empirical Methods in Natural Language Processing(EMNLP)
 The penn treebank: Annotating predicate argumentstructure,1994, In Proceedings of the Workshop on Human Language Technology
 Learned in translation:Contextualized word vectors,2017, In Advances in Neural Information Processing Systems
 Pyrami-dal recurrent unit for language modeling,2018, In Proceedings of the 2018 Conference on EmpiricalMethods in Natural Language Processing
 On the state of the art of evaluation in neural languagemodels,2018, In International Conference on Learning Representations
 Pointer sentinel mixturemodels,2017, In International Conference on Learning Representations
 An analysis of neural language modelingat multiple scales,2018, arXiv preprint arXiv:1803
 Regularizing and optimizing LSTMlanguage models,2018, In International Conference on Learning Representations
 Recurrentneural network based language model,2010, In Eleventh annual conference of the international speechcommunication association
 Hierarchical probabilistic neural network language model,2005, InAistats
 Glove: Global vectors for wordrepresentation,2014, In Empirical Methods in Natural Language Processing (EMNLP)
 Deep contextualized word representations,2018, In Proc
 Using the output embedding to improve language models,2017, In Proceedingsof the 15th Conference of the European Chapter of the Association for Computational Linguistics:Volume 2
 Xnor-net: Imagenetclassification using binary convolutional neural networks,2016, In European Conference on ComputerVision
 Neural machine translation of rare words withsubword units,2015, arXiv preprint arXiv:1508
 Compressing word embeddings via deep compositional codelearning,2017, arXiv preprint arXiv:1711
