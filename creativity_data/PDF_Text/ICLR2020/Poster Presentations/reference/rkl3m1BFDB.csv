title,year,conference
 Towards better interpretability in deep q-networks,2019, In AAAI
 Deep apprenticeshiplearning for playing video games,2015, 2015
 Template Matching Techniques in Computer Vision: Theory and Practice,2009, WileyPublishing
 Visual causal feature learning,2015, In UAI
 Real time image saliency for black box classifiers,2017, In NeurIPS
 Investigat-ing human priors for playing video games,2018, ICML
 Toybox: Better Atari Environments forTesting Reinforcement Learning Agents,2018, In NeurIPS Workshop on Systems for ML
 Interpretable explanations of black boxes by meaningful pertur-bation,2017, ICCV
 Unsupervised video object segmentation for deepreinforcement learning,2018, In NeurIPS
 Visualizing and understanding atariagents,2017, ICML
 Evaluating feature importanceestimates,2019, NeurIPS
 Transparencyand explanation in deep reinforcement learning neural networks,2018, AAAI
 Explainablereinforcement learning via reward decomposition,2019, In IJCAI Workshop on Explainable ArtificialIntelligence
 Troubling trends in machine learning scholarship,2018, arXivpreprint arXiv:1807
 Explaining explanations in ai,2019, In Conferenceon Fairness
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Asynchronous methods for deep reinforcementlearning,2016, In ICML
 To-wards interpretable reinforcement learning using attention augmented agents,2019, arXiv preprintarXiv:1906
 Free-lunch saliency viaattention in atari agents,2019, arXiv preprint arXiv:1908
 Counterfactual states for atariagents via generative deep learning,2019, IJCAI Workshop on Explainable Artificial Intelligence
 The logic of scientific discovery,1959, Routledge
 Why should I trust you?: Explaining thepredictions of any classifier,2016, In ACM SIGKDD
 Evaluating the visualization of what a deep neural network has learned,2017, IEEE transactionson neural networks and learning systems
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In ICCV
 Noise-adding methods of saliency map as series of higher order partial derivative,2018, ICMLWorkshop on Human Interpretability in Machine Learning
 Learning important features throughpropagating activation differences,2017, ICML
 Deep inside convolutional networks:Visualising image classification models and saliency maps,2014, ICLR Workshop
 Smoothgrad:removing noise by adding noise,2017, ICML Workshop on Visualization for Deep Learning
 Striving forsimplicity: The all convolutional net,2015, ICLR
 Transparency in Deep Reinforcement Learning Networks,2018, PhD thesis
 Reinforcement learning: An introduction,1998, MIT press
 Intriguing properties of neural networks,2014, In ICLR
 Learning causal laws,2003, In Proceedings of the AnnualMeeting of the Cognitive Science Society
 Advantageactor-critic methods for carracing,2018, 2018
 Learn to interpret atari agents,2018, arXiv preprintarXiv:1812
 Graying the black box: Understanding dqns,2016, 2016
 Visualizing and understanding convolutional networks,2014, In ECCV
