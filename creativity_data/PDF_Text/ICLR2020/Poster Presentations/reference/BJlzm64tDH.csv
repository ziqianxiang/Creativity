title,year,conference
 A neural knowledge languagemodel,2016, arXiv preprint arXiv:1608
 COMET: commonsense transformers for automatic knowledge graph construction,2019, In ACL(1)
 What does bert lookat? an analysis of bertâ€™s attention,2019, arXiv preprint arXiv:1906
 Frame semantics and the nature of language,1976, In Annals of the New YorkAcademy of Sciences: Conference on the origin and development of language and speech
 Teaching machines to read and comprehend,2015, In NIPS
 Neural architectures forfine-grained entity type classification,2017, In EACL (1)
 Triviaqa: A large scale distantlysupervised challenge dataset for reading comprehension,2017, In ACL (1)
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Fine-grained entity recognition,2012, In AAAI
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Learned in translation:Contextualized word vectors,2017, In NIPS
 Knowledgeable reader: Enhancing cloze-style reading compre-hension with external commonsense knowledge,2018, In Proceedings of the 56th Annual Meeting of theAssociation for Computational Linguistics (Volume 1: Long Papers)
 Society of mind,1988, Simon and Schuster
 A three-way model for collective learningon multi-relational data,2011, In ICML
 Glove: Global vectors for wordrepresentation,2014, In EMNLP
 Deep contextualized word representations,2018, arXiv preprint arXiv:1802
 Dissecting contextualword embeddings: Architecture and representation,2018, In EMNLP
 Knowledge enhanced contextual word representations,2019, EMNLP
 Languagemodels are unsupervised multitask learners,2019, OpenAI Blog
 Attention is all you need,2017, In NIPS
 Wikidata: a free collaborative knowledge base,2014, 2014
 DeepPath: A reinforcement learningmethod for knowledge graph reasoning,2017, In Proceedings of the 2017 Conference on EmpiricalMethods in Natural Language Processing
 Leveraging knowledge bases in lstms for improving machinereading,2017, In ACL (1)
 Xlnet: Generalized autoregressive pretraining for language understanding,2019, arXiv preprintarXiv:1906
 SWAG: A large-scale adversarialdataset for grounded commonsense inference,2018, In EMNLP
 ERNIE: enhancedlanguage representation with informative entities,2019, In ACL (1)
 Aligning books and movies: Towards story-like visual explanations bywatching movies and reading books,2015, In ICCV
