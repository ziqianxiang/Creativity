title,year,conference
 Doubly robust policy evaluation and learning,2011, InICML
 Consistent on-line off-policy evaluation,2017, In ICML
 Importance sampling policy evaluation with anestimated behavior policy,2019, In ICML
 Efficient estimation of average treatment effectsusing the estimated propensity score,2003, Econometrica
 Toward minimax off-policy value estimation,2015, JMLR
 Breaking the curse of horizon: Infinite-horizon off-policy estimation,2018, In NeurIPS
 Dualdice: Behavior-agnostic estimation ofdiscounted stationary distribution corrections,2019, In NeurIPS
 Eligibility traces for off-policy policyevaluation,2000, In ICML
 Off-policy temporal-difference learning withfunction approximation,2001, In ICML
 Data-efficient off-policy policy evaluation for reinforcementlearning,2016, In ICML
 Transfer of samples in policy search viamultiple importance sampling,2019, In ICML
 Coordinated deep reinforcement learners for traffic lightcontrol,2016, In NeurIPS
 Optiamlly combining sampling techniques for Monte Carlorendering,1995, In SIGGRAPH
 Optimal and adaptive off-policy evaluation incontextual bandits,2017, In ICML
 Drn: A deep reinforcement learning framework for news recommendation,2018, In WWW
