title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Unrestricted adversarial examples,2018, arXiv preprint arXiv:1809
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 ImageNet: A Large-Scale HierarchicalImage Database,2009, In CVPR09
 Generating realistic unrestricted adversarial inputsusing dual-objective gan training,2019, arXiv preprint arXiv:1905
 Arotation and a translation suffice: Fooling cnns with simple transformations,2017, arXiv preprintarXiv:1712
 On the effectiveness of interval bound propagation fortraining verifiably robust models,2018, arXiv preprint arXiv:1810
 Semantic adversarial examples,2018, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition Workshops
 Functional adversarial attacks,2019, arXiv preprint arXiv:1906
 MNIST handwritten digit database,2010, 2010
 Certifiedrobustness to adversarial examples with differential privacy,2018, arXiv preprint arXiv:1802
 Second-order adversarial attackand certifiable robustness,2018, CoRR
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In International Conference on Machine Learning
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, arXivpreprint arXiv:1906
 Uni-versal adversarial training,2018, arXiv preprint arXiv:1811
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Maximal jacobian-based saliency map attack,2018, arXiv preprintarXiv:1808
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems
 Wasserstein adversarial examples via projectedsinkhorn iterations,2019, arXiv preprint arXiv:1902
 Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms,2017, arXiv preprint arXiv:1708
 Training for fasteradversarial robustness verification via inducing relu stability,2018, arXiv preprint arXiv:1809
 Towards sta-ble and efficient training of verifiably robust neural networks,2019, arXiv preprint arXiv:1906
