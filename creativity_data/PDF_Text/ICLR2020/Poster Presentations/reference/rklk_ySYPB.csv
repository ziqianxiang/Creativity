title,year,conference
 Understanding deep neural networkswith rectified linear unit,2018, In ICLR
 Obfuscated gradients give a false sense of security:Circumventing defenses to adversarial examples,2018, In ICML
 Measuringneural net robustness with constraints,2016, In NIPS
 Adversarial patch,2017, In NIPS 2017Workshop on Machine Learning and Computer Security
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In ACM Workshop on Artificial Intel ligence and Security
 A randomized gradient-free attack on relu networks,2018, In GCPR
 Minimally distorted adversarial examples with a fast adaptiveboundary attack,2019, preprint
 Provable robustness of relu networks viamaximization of linear regions,2019, In AISTATS
 A rotation and a translationsuffice: Fooling CNNs with simple transformations,2017, In NIPS 2017 Workshop on MachineLearning and Computer Security
 On the effectiveness of interval bound propagation for trainingverifiably robust models,2018, preprint
 Towards deep neural network architectures robust to adversarialexamples,2015, In ICLR Workshop
 Formal guarantees on the robustness of a classifier againstadversarial manipulation,2017, In NIPS
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, In ICLR
 Learning with a strong adversary,2016, InICLR
 Reluplex: An efficient smtsolver for verifying deep neural networks,2017, In CAV
 Adam: A method for stochastic optimization,2014, preprint
 Adversarial examples in the physical world,2017, InICLR Workshop
 Towards deep learning modelsresistant to adversarial attacks,2018, In ICLR
 Differentiable abstract interpretation for provablyrobust neural networks,2018, In ICML
 Logit pairing methodscan fool gradient-based attacks,2018, In NeurIPS 2018 Workshop on Security in MachineLearning
 Attacking the madry defense model with l1 -based adversarialexamples,2019, In ICLR Workshop
 Man vs,2012, computer: Benchmarkingmachine learning algorithms for traffic sign recognition
 Evaluating robustness of neural networks with mixedinteger programming,2019, In ICLR
 Adversarial training and robustness for multiple perturbations,2019, InNeurIPS
 Provable defenses against adversarial examples via the convexouter adversarial polytope,2018, In ICML
 Fashion-MNIST: a novel image dataset for benchmarkingmachine learning algorithms,2017, preprint
 Training for faster adversarialrobustness verification via inducing relu stability,2019, In ICLR
 Improving the robustness of deep neuralnetworks via stability training,2016, In CVPR
