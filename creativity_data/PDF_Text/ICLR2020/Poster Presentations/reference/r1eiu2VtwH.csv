title,year,conference
 Random forests,2001, Machine Learning
 Xgboost: A scalable tree boosting system,2016, In Proceedings of the22nd acm sigkdd international conference on knowledge discovery and data mining
 Greedy function approximation: a gradient boosting machine,2001, Annals ofstatistics
 Deep learning,2016, MIT press
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Lightgbm: A highly efficient gradient boosting decision tree,2017, In Advances in NeuralInformation Processing Systems
 Tabnn: A universal neural networksolution for tabular data,2018, 2018
 Deep neuraldecision forests,2015, In Proceedings of the IEEE international conference on computer vision
 Random hingeforest for differentiable learning,2018, arXiv preprint arXiv:1802
 Quasi-hyperbolic momentum and adam for deep learning,2018, arXiv preprintarXiv:1810
 From softmax to sparsemax: A sparse model of attention andmulti-label classification,2016, In International Conference on Machine Learning
 Forwardthinking: building deep random forests,2017, arXiv preprint arXiv:1705
 All you need is a good init,2016, In 4th International Conference onLearning Representations
 A regularized framework for sparse and structured neural atten-tion,2017, In Advances in Neural Information Processing Systems
 Sparsemap: Differentiablesparse structured inference,2018, arXiv preprint arXiv:1802
 Sparse SeqUence-to-SeqUence models,2019, In ACL
 Catboost: unbiased boosting with categorical features,2018, In Advances in Neural InformationProcessing Systems
 Learning internal representationsby error propagation,1985, Technical report
 Regularization learning networks: Deep learning for tabular datasets,2018, InAdvances in Neural Information Processing Systems
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine Learning
 Deep neural decision trees,2018, arXivpreprint arXiv:1806
