title,year,conference
 Syntactically supervised transformers for fasterneural machine translation,2019, In Proceedings of the 57th Annual Meeting of the Association forComputational Linguistics
 Neural machine translation by jointlylearning to align and translate,2015, In International Conference on Learning Representations (ICLR)
 BERT: pre-training of deepbidirectional transformers for language understanding,2018, CoRR
 Constant-time machinetranslation with conditional masked language models,2019, arXiv preprint arXiv:1904
 Non-autoregressiveneural machine translation,2018, In 6th International Conference on Learning Representations
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Automatic eval-uation of translation quality for distant language pairs,2010, In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Processing
 Sequence-level knowledge distillation,2016, In Proceedings of the2016 Conference on Empirical Methods in Natural Language Processing
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Glow: Generative flow with invertible 1x1 convolutions,2018, InAdvances in Neural Information Processing Systems
 Deterministic non-autoregressive neural se-quence modeling by iterative refinement,2018, In Proceedings of the 2018 Conference on EmpiricalMethods in Natural Language Processing
 Softmax q-distribution estimation for structured prediction: A theoretical interpretation for raml,2017, arXivpreprint arXiv:1705
 Flowseq: Non-autoregressive conditional sequence generation with generative flow,2019, In Proceedings of the 2019Conference on Empirical Methods in Natural Language Processing
 Parallel wavenet: Fasthigh-fidelity speech synthesis,2018, In International Conference on Machine Learning
 Analyzing uncertainty inneural machine translation,2018, In Proceedings of the 35th International Conference on MachineLearning
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 chrf: character n-gram f-score for automatic mt evaluation,2015, In Proceedings of theTenth Workshop on Statistical Machine Translation
 Neural machine translation of rare words withsubword units,2016, In Proceedings of the 54th Annual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers)
 Retriev-ing sequential information for non-autoregressive neural machine translation,2019, arXiv preprintarXiv:1906
 Mixture models for diverse machine translation:Tricks of the trade,2019, In International Conference on Machine Learning
 A study oftranslation edit rate with targeted human annotation,2006, In In Proceedings of Association for MachineTranslation in the Americas
 Beer: Better evaluation as ranking,2014, In Proceedings of the NinthWorkshop on Statistical Machine Translation
 Blockwise parallel decoding for deep au-toregressive models,2018, In Advances in Neural Information Processing Systems
 Insertion transformer: Flexiblesequence generation via insertion operations,2019, arXiv preprint arXiv:1902
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Semi-autoregressive neural machine translation,2018, InProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing
 Non-autoregressivemachine translation with auxiliary regularization,2019, arXiv preprint arXiv:1902
 Imitation learning for non-autoregressive neural machine translation,2019, arXiv preprint arXiv:1906
