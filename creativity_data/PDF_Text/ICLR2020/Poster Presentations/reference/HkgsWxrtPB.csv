title,year,conference
 Modular multitask reinforcement learning with policysketches,2017, In ICML
 Finite-time analysis of the multiarmed banditproblem,2002, Machine learning
 Hierarchical reinforcement learning in the taxicab domain,2009, (Report No
 Exploiting structure in policy construc-tion,1995, In IJCAI
 Classification and regression trees,1984, Routledge
 Gated-attention architectures for task-oriented languagegrounding,2018, In AAAI
 Pro-grammable agents,2017, arXiv preprint arXiv:1706
 Neural logicmachines,2019, In ICLR
 Rl 2 : Fastreinforcement learning via slow reinforcement learning,2016, arXiv preprint arXiv:1611
 Learning Explanatory Rules from Noisy Data,2017, arXivpreprint arXiv:1711
 Probabilistic model-agnostic meta-learning,2018, In NeurIPS
 Autonomous extracting a hierarchical structure of tasks inreinforcement learning and multi-task reinforcement learning,2017, arXiv preprint arXiv:1709
 Meta-reinforcement learning of structured exploration strategies,2018, arXiv preprint arXiv:1802
 Autonomously constructing hierarchical task networks forplanning and human-robot collaboration,2016, In 2016 IEEE International Conference on Robotics andAutomation (ICRA)
 Harnessing deep neuralnetworks with logic rules,2016, arXiv preprint arXiv:1603
 Neural task graphs: Generalizing to unseen tasks from a single videodemonstration,2018, arXiv preprint arXiv:1807
 AI2-THOR: An Interactive 3D Environmentfor Visual AI,2017, arXiv
 Jointly learning grounded task structures from language instruction and visualdemonstration,2016, In EMNLP
 A simple neural attentive meta-learner,2018, In ICLR
 Human-level controlthrough deep reinforcement learning,2015, Nature
 Inductive logic programming,0288, New Gen
 Zero-shot task generalization withmulti-task deep reinforcement learning,2017, In ICML
 High-dimensionalcontinuous control using generalized advantage estimation,2016, In ICLR
 Masteringthe game of go with deep neural networks and tree search,2016, Nature
 Hierarchical reinforcement learning for zero-shotgeneralization with subtask dependencies,2018, In NeurIPS
 Policy gradient methodsfor reinforcement learning with function approximation,1999, In NIPS
 Starcraft II: Anew challenge for reinforcement learning,2017, arXiv preprint arXiv:1708
 Learning to reinforcement learn,2016, arXivpreprint arXiv:1611
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 A deep compositional framework for human-like languageacquisition in virtual environment,2017, arXiv preprint arXiv:1703
 The eligibility of the subtasks is computed based the corresponding subtask completionvector,2020, The eligibility of the pickup subtasks is always set to 1
