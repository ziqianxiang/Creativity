title,year,conference
 Emergence of invariance and disentangling in deep represen-tations,2017, arXiv preprint arXiv:1706
 Meta-learning by adjusting priors based on extended pac-bayes theory,2018, InInternational Conference on Machine Learning
 Meta-Iearning withdifferentiable closed-form solvers,2018, ArXiv
 Domaingeneralization by solving jigsaw puzzles,2019, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 A closer lookat few-shot classification,2019, arXiv preprint arXiv:1904
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Transferringknowledge across learning processes,2019, International Conference on Learning Representations(ICLR)
 Neural processes,2018, arXiv preprint arXiv:1807
 Dynamic few-shot visual learning without forgetting,2018, InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Unsupervised representation learning bypredicting image rotations,2018, arXiv preprint arXiv:1803
 Boostingfew-shot visual learning with self-supervision,2019, arXiv preprint arXiv:1906
 Some history of the hierarchical bayesian methodology,1980, TrabajOs de estadiStica yde investigacion operativa
 Recasting gradient-based meta-learning as hierarchical bayes,2018, arXiv preprint arXiv:1801
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In Proceedings of the IEEE internationalconference on computer vision
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Attentive neural processes,2019, arXiv preprint arXiv:1901
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Population empirical bayes,2014, arXiv preprint arXiv:1411
 Set trans-former: A framework for attention-based permutation-invariant neural networks,2019, In InternationalConference on Machine Learning
 Meta-learning withdifferentiable convex optimization,2019, In CVPR
 Finding Task-Relevant Features for Few-Shot Learning by Category Traversal,2019, In CVPR
 Meta-sgd: Learning to learn quickly for few-shotlearning,2017, arXiv preprint arXiv:1707
 Tadam: Task dependent adaptivemetric for improved few-shot learning,2018, In Advances in Neural Information Processing Systems(NIPS)
 Few-shot image recognition by predictingparameters from activations,2018, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Amortized bayesian meta-learning,2018, International Conference onLearning Representation
 Optimization as a model for few-shot learning,2016, InternationalConference on Learning Representation
 Stochastic backpropagation andapproximate inference in deep generative models,2014, arXiv preprint arXiv:1401
 A simple neural network module for relational reasoning,2017, InNIPS
 Few-shot learning with graph neural networks,2017, ArXiv
 Prototypical networks for few-shot learning,2017, InAdvances in Neural Information Processing Systems
 Information-theoretic limitations of distributed information processing,2016, PhD thesis
 Information-theoretic analysis of generalization capability of learningalgorithms,2017, In Advances in Neural Information Processing Systems
 Self-supervised domain adaptation for computervision tasks,2019, IEEE Access
 Wide residual networks,2016, arXiv preprint arXiv:1605
