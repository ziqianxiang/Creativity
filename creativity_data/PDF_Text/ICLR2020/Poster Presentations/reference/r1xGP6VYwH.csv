title,year,conference
 Optimistic posterior sampling for reinforcement learning: worst-caseregret bounds,2017, In Advances in NeUral Information Processing Systems
 Minimax regret bounds for reinforce-ment learning,2017, In Proceedings of the 34th International Conference on Machine Learning
 Exploration by random networkdistillation,2018, arXiv preprint arXiv:1810
 UCB and infogain explorationvia Q-ensembles,2017, arXiv preprint arXiv:1706
 Dora the explorer: Directed outreachingreinforcement action-selection,2018, In International Conference on Learning Representations
 Q-learning with UCB exploration issample efficient for infinite-horizon MDP,2019, arXiv preprint arXiv:1901
 Go-explore: a newapproach for hard-exploration problems,2019, arXiv preprint arXiv:1901
 EX2: Exploration with exemplar models for deepreinforcement learning,2017, In Advances in Neural Information Processing Systems
 Learning latent dynamics for planning from pixels,2019, In Proceedings of the 36thInternational Conference on Machine learning
 Domain-indePendent oPtimisticinitialization for reinforcement learning,2015, In AAAI Workshop: Learning for General Competency inVideo Games
 Count-based exPloration with thesuccessor rePresentation,2018, arXiv preprint arXiv:1807
 Human-level controlthrough deeP reinforcement learning,2015, Nature
 Asynchronous methods for deeP reinforcementlearning,2016, In Proceedings of the 33rd International Conference on Machine Learning
 DeeP exPloration viabootstraPPed DQN,2016, In Advances in Neural Information Processing Systems
 DeeP exPloration via randomizedvalue functions,2017, arXiv preprint arXiv:1703
 Randomized Prior functions for deeP reinforcementlearning,2018, In Advances in Neural Information Processing Systems
 Count-based explorationwith neural density models,2017, arXiv preprint arXiv:1703
 What is intrinsic motivation? a typology of computationalapproaches,2009, Frontiers in neurorobotics
 Curiosity-driven explorationby self-supervised prediction,2017, In Proceedings of the 34th International Conference on MachineLearning
 Model-based active exploration,2019, InProceedings of the 36th International Conference on Machine Learning
 PAC model-free reinforcement learning,2006, In Proceedings of the 23rd International Conference on Machinelearning
 A bayesian framework for reinforcement learning,2000, In Proceedings of the 17thInternational Conference on Machine Learning
 Approximate exploration through stateabstraction,2018, arXiv preprint arXiv:1808
 Conditionalimage generation with pixelcnn decoders,2016, In Advances in Neural Information Processing Systems
