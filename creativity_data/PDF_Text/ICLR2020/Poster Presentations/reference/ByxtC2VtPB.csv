title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning (ICML)
 Adversarial mixup resynthesizers,2019, In Advances in Neural Information ProcessingSystems (NeurIPS)
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In ACM Workshop on Artificial Intelligence and Security (AISec)
 Adversarial attack ongraph structured data,2018, In International Conference on Machine Learning (ICML)
 Boostingadversarial attacks with momentum,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR)
 Arotation and a translation suffice: Fooling cnns with simple transformations,2019, In InternationalConference on Machine Learning (ICML)
 Robustness of classi-fiers: from adversarial to random noise,2016, In Advances in Neural Information Processing Systems(NeurIPS)
 Adversarial vulnerability for any classifier,2018, InAdvances in Neural Information Processing Systems (NeurIPS)
 Deep Learning,2016, MIT Press
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations (ICLR)
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations(ICLR)
 Identity mappings in deep residualnetworks,2016, In European Conference on Computer Vision (ECCV)
 Multilayer feedforward networks areuniversal approximators,1989, Neural networks
 Adversarial attackson neural network policies,2017, arXiv preprint arXiv:1702
 Data augmentation by pairing samples for images classification,2018, arXiv preprintarXiv:1801
 Is bert really robust? natural language attack ontext classification and entailment,2019, arXiv preprint arXiv:1907
 Adversarial examples in the physical world,2017, InThe International Conference on Learning Representations (ICLR) Workshops
 Adversarial attacks and defences competition,2018, arXivpreprint arXiv:1804
 Interpolated adversarial training:Achieving robust neural networks without sacrificing accuracy,2019, arXiv preprint arXiv:1906
 Deep neural networks are easily fooled: High confidencepredictions for unrecognizable images,2015, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Towards robust detection of adversarialexamples,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Max-mahalanobis linear discriminant analysis networks,2018, InInternational Conference on Machine Learning (ICML)
 On the momentum term in gradient descent learning algorithms,1999, Neural networks
 Barrage of random transformsfor adversarially robust defense,2019, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 Data interpolatingprediction: Alternative interpretation of mixup,2019, arXiv preprint arXiv:1906
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations (ICLR)
 Exploring the space of adversarial images,2016, In 2016 InternationalJoint Conference on Neural Networks (IJCNN)
 Interpolationconsistency training for semi-supervised learning,2019, arXiv preprint arXiv:1903
 Mitigating adversarial effectsthrough randomization,2018, In International Conference on Learning Representations (ICLR)
 Understand-ing deep learning requires rethinking generalization,2017, In International Conference on LearningRepresentations (ICLR)
 mixup: Beyond empiricalrisk minimization,2018, In International Conference on Learning Representations (ICLR)
 According to Sec,2019, 3
