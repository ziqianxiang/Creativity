title,year,conference
 Learning from conditional distributionsvia dual embeddings,2017, In Proceedings of the 20th International Conference on Artificial Intelligenceand Statistics (AISTATS)
 Boosting the actor with dual critic,2018, InProceedings of the 6th International Conference on Learning Representations (ICLR)
 Doubly robust policy evaluation and learning,2011, InProceedings of the 28th International Conference on Machine Learning (ICML)
 More robust doubly robustoff-policy evaluation,2018, In Proceedings of the 35th International Conference on Machine Learning(ICML)
 Batch mode reinforcementlearning based on the synthesis of artificial trajectories,2013, Annals of Operations Research
 Generative adversarial nets,2014, In Advances in NeuralInformation Processing Systems 27 (NIPS)
 Using options and covariance testing for longhorizon off-policy policy evaluation,2017, In Advances in Neural Information Processing Systems 30(NIPS)
 Bootstrapping with models: Confidence intervalsfor off-policy evaluation,2017, In Proceedings of the 31st AAAI Conference on Artificial Intelligence(AAAI)
 On using very large targetvocabulary for neural machine translation,2015, In Proceedings of the 53rd Annual Meeting of theAssociation for Computational Linguistics (ACL)
 Doubly robust off-policy evaluation for reinforcement learning,2016, InProceedings of the 33rd International Conference on Machine Learning (ICML)
 Markov Chains and Mixing Times,1470, American Mathematical Society
Toward minimax off-policy value estimation,2015, InProceedings of the 18th International Conference on Artificial Intelligence and Statistics (AISTATS)
 Monte Carlo Strategies in Scientific Computing,0387, Springer Series in Statistics
 Black-box importance sampling,2017, In Proceedings of the 20th InternationalConference on Artificial Intelligence and Statistics (AISTATS)
 Stein variational gradient descent as moment matching,2018, In Advances inNeural Information Processing Systems (NIPS)
 Breaking the curse of horizon: Infinite-horizon off-policy estimation,2018, In Advances in Neural Information Processing Systems 31 (NeurIPS)
 Off-policy policy gradient withstate distribution correction,2019, In Proceedings of the 35th Conference on Uncertainty in ArtificialIntelligence (UAI)
 Toward off-policylearning control with function approximation,2010, In Proceedings of the 27th International Conferenceon Machine Learning (ICML)
 Kernel meanembedding of distributions: A review and beyond,2017, Foundations and Trends in Machine Learning
 Kernelmean embedding of distributions: A review and beyond,2017, Foundations and TrendsR in MachineLearning
 Safe and efficient off-policy reinforcement learning,2016, In Advances in Neural Information Processing Systems 29 (NIPS)
 DualDICE: Behavior-agnostic estimation ofdiscounted stationary distribution corrections,2019, 2019
 Estimating divergence functionalsand the likelihood ratio by convex risk minimization,2010, IEEE Transactions on Information Theory
 Stable dual dynamicprogramming,2007, In Advances in Neural Information Processing Systems 20 (NIPS)
