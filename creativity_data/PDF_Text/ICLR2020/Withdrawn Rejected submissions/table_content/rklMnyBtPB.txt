Table 1: Summary of adversarial accuracy results for MNIST (higher is better)	P∞	P2	Pi	B-ABS3 4	ABS4	Worst PGD	PGD Aug	MSDClean Accuracy	99.1%	99.4%	98.9%	99%	99%	98.9%	99.1%	98.2%'∞ attacks (E = 0.3)	90.3%	0.4%	0.0%	77%	8%	68.4%	83.7%	63.7%`2 attacks ( = 1.5)	45.3%	87.0%	70.3%	39%	80%	82.1%	75.0%	82.6%`1 attacks (E = 12)	1.4%	43.4%	71.8%	82%	78%	54.6%	15.6%	62.3%All Attacks	1.4%	0.4%	0.0%	39%	8%	53.7%	15.6%	58.7%models, in the end, the most meaningful metric for measuring the effective performance is the robustoptimization objective, or the performance against the union of all attacks.
Table 2: Summary of adversarial accuracy results for CIFAR10 (higher is better)	P∞	P2	Pi	Worst-PGD	PGD-Aug	MSDClean accuracy	83.3%	90.2%	73.3%	81.0%	84.6%	81.7%'∞ attacks ( = 0.03)	50.7%	28.3%	0.2%	44.9%	42.5%	47.6%'2 attacks ( = 0.5)	57.3%	61.6%	0.0%	61.7%	65.0%	64.3%'1 attacks ( = 12)	16.0%	46.6%	7.9%	39.4%	54.0%	53.4%All attacks	15.6%	27.5%	0.0%	34.9%	40.6%	46.1%5.2	MNISTWe first present results on the MNIST dataset, which are summarized in Table 1 (a more detailedbreakdown over each individual attack is in Appendix C.1). While considered an “easy” dataset, wenote that the previous state-of-the-art result for multiple threat models on MNIST (and our primarycomparison) is only able to defend against two out of three threat models at a time (Schott et al.,2019) using comparatively complex variational autoencoder architectures. The model trained withMSD achieves the best performance against all attacks, achieving an error rate of 58.7% (individually63.7%, 82.6%, and 62.3)% against the union of ('∞, '2, and '1) perturbations with radius = (0.3,1.5, 12). Complete robustness curves over a range of epsilons over each threat model can be found inFigure 2. A comparison of our results with concurrent work (Tramer & Boneh, 2019) can be found inAppendix D.
Table 3: Summary of adversarial accuracy results for MNIST	P∞	P2	Pi	B-ABS	ABS	Worst PGD	PGD Aug	MSDClean Accuracy	99.1%	99.4%	98.9%	99%	99%	98.9%	99.1%	98.2%PGD-'∞	90.3%	0.4%	0.0%	-	-	68.4%	83.7%	63.7%FGSM	94.9%	68.6%	6.4%	85%	34%	82.4%	90.9%	81.8%PGD-Foolbox	92.1%	8.5%	0.1%	86%	13%	72.1%	85.7%	67.9%MIM		92.3%	14.5%	0.1%	85%	17%	73.9%	87.3%	71.0%'∞ attacks (E = 0.3)	90.3%	0.4%	0.0%	77%	8%	68.4%	83.7%	63.7%PGD-'2	83.8%	87.0%	70.8%	-	-	85.3%	87.9%	84.2%PGD-Foolbox	93.4%	89.7%	74.4%	63%	87%	86.9%	91.5%	86.9%Gaussian Noise	98.9%	99.6%	98.0%	89%	98%	97.4%	99.0%	97.8%Boundary Attack	52.6%	92.1%	83.0%	91%	83%	86.9%	79.1%	88.6%DeepFool	95.1%	92.2%	76.5%	41%	83%	87.9%	93.5%	87.9%Pointwise Attack	74.3%	97.4%	96.6%	87%	94%	92.7%	89.0%	95.1%DDN	82.7%	87.0%	70.8%	-	-	85.1%	85.2%	84.3%CWL2		88.2%	88.1%	75.5%	-	-	85.2%	87.5%	85.1%'2 attacks (E = 1.5)	45.3%	87.0%	70.3%	39%	80%	82.1%	75.0%	82.6%PGD-'1	51.8%	49.9%	71.8%	-	-	66.5%	57.4%	64.8%Salt & Pepper	55.5%	96.3%	95.6%	96%	95%	86.4%	71.9%	92.2%Pointwise Attack	2.4%	66.4%	85.2%	82%	78%	60.1%	17.1%	72.8%
Table 4: Summary of adversarial accuracy results for CIFAR10	P∞	P2	Pi	Worst-PGD	PGD-Aug	MSDClean accuracy	83.3%	90.2%	73.3%	81.0%	84.6%	81.7%PGD-'∞	50.3%	48.4%	29.8%	44.9%	42.8%	49.8%FGSM	57.4%	43.4%	12.7%	54.9%	51.9%	55.0%PGD-Foolbox	52.3%	28.5%	0.6%	48.9%	44.6%	49.8%MIM	52.7%	30.4%	0.7%	49.9%	46.1%	50.6%'∞ attacks (E = 0.03)	50.7%	28.3%	0.2%	44.9%	42.5%	47.6%PGD-'2	59.0%	62.1%	28.9%	64.1%	66.9%	66.0%PGD-Foolbox	61.6%	64.1%	4.9%	65.0%	68.0%	66.4%Gaussian Noise	82.2%	89.8%	62.3%	81.3%	84.3%	81.8%Boundary Attack	65.5%	67.9%	2.3%	64.4%	69.2%	67.9%DeepFool	62.2%	67.3%	0.9%	64.4%	67.4%	65.7%Pointwise Attack	80.4%	88.6%	46.2%	78.9%	83.8%	81.4%DDN	60.0%	63.5%	0.1%	64.5%	67.7%	66.2%CWL2	62.0%	71.6%	0.1%	66.9%	71.5%	68.7%'2 attacks (E = 0.05)	57.3%	61.6%	0.0%	61.7%	65.0%	64.3%PGD-'1	16.5%	49.2%	69.1%	39.5%	54.0%	53.4%Salt & Pepper	63.4%	74.2%	35.5%	75.2%	80.7%	75.6%Pointwise Attack	49.6%	62.4%	8.4%	63.3%	77.0%	72.8%
Table 5: Comparison with contemporary work on MNIST (higher is better). Results for all modelsexcept MSD are taken as is from Tramer & Boneh (2019)	Vanilla	Adv∞	Adv 1	Adv2	Advavg	Advmax	MSDClean accuracy	99.4%	99.1%	98.9%	98.5%	97.3%	97.2%	98.2%'∞ attacks (E = 0.3)	-O%^	91.1%	0.0%	0.4%	76.7%	71.7%	63.7%'2 attacks (E = 2.0)	12.4%	12.1%	50.6%	71.8%	58.3%	56.0%	67.4%'1 attacks (E = 10)	8.5%	11.3%	78.5%	68.0%	53.9%	62.6%	70.0%All attacks	0.0%	6.8%	0.0%	0.4%	49.9%	52.4%	60.9%following differences can bias the robust accuracies reported for the MSD models to relatively lowerthan expected (and correspondingly, the robust accuracies reported for the other models are relativelyhigher than expected):1.	Use of random restarts: We observe in our experiments that using up to 10 restarts for allour attacks leads to a decrease in model accuracy from 5 to 10% across all models. Tramer &Boneh do not mention restarting their attacks for these models and so the results for modelsapart from MSD in Tables 5, 6 could potentially be lowered with random restarts.
Table 6: Comparison with contemporary work on CIFAR10 (higher is better). Results for all modelsexcept MSD are taken as is from Tramer & Boneh (2019)	Vanilla	Adv ∞	Adv1	Advavg	Advmax	MSDClean accuracy	95.7%	92.0%	90.8%	91.1%	91.2%	82.1%'∞ attacks (e = 4t))~ ∞	255	-0.0%	71.0%	53.4%	64.1%	65.7%	65.6%'1 attacks (E = 2000)	0.0%	16.4%	66.2%	60.8%	62.5%	62.0%All attacks	0.0%	16.4%	53.1%	59.4%	61.1%	61.7%Table 7: Performance on CIFAR-10-C	AccuracyStandard model	66.0%-P∞	75.0%P2	82.7%Pl		57.8%Worst-PGD	70.8%PGD-Aug	76.8%MSD		74.2%by Tramer & Boneh (2019) and thus were only used to attack the MSD models in Tables 5and 6.
Table 7: Performance on CIFAR-10-C	AccuracyStandard model	66.0%-P∞	75.0%P2	82.7%Pl		57.8%Worst-PGD	70.8%PGD-Aug	76.8%MSD		74.2%by Tramer & Boneh (2019) and thus were only used to attack the MSD models in Tables 5and 6.
