Table 1: Positive correlation quantified by Ï†XY(k). Adaptive-BN-based evaluation largely improvesthe correlation compared to vanilla evaluation.
Table 2: Comparison of computation costs of various pruning methods in the task where all pruningmethods are executed to find the best pruning strategy from 1000 potential strategies (candidates).
Table 3: Comparisions of ResNet-50 and other pruning methodsMobileNet MobileNets are more challenging to prune on large datasets like ImageNet as they arealready very compact. We compare the top-1 ImageNet classification accuracy under the sameFLOPs constraint (about 280M FLOPs). 1500 pruning strategies are generated with this FLOPsconstraint. Then adaptive-BN-based evaluation is applied to each candidate. After fine-tuning thetop-2 candidates, the pruning candidate that returns the highest accuracy is selected as the finaloutput.
Table 4: Comparisions of MobileNetV1 and other pruning methods5	Discussion and ConclusionsWe presented our FNNP framework, in which a fast and accurate evaluation based on adaptive batchnormalization is proposed. To quantitatively show the advantages of this module over other methods,a correlation coefficient is proposed. Our experiments show the efficiency and effectiveness of ourFNNP method by delivering better pruning performance than our studied approaches.
