Table 1: Comparison of accuracy and memory cost in number of parameters (and memory usage forstoring samples if relevant) of different approaches on MNIST at the end of the Continual Learning.
Table 2: MNIST Hyperparameters	Table 3: CIFAR-100 HyperparametersHyperparameter Value	Hyperparameter ValueLearning Rate	0.002 Number of epochs 200 Weight decay	0.0 Patience	20	Learning Rate	0.002 Number of epochs 1000 Weight decay	0.0002 Patience	30Table 4: t-SNE HyperparametersHyperparameter ValuePerplexity	15.0Principal Components 50Steps	400C Task-by-Task LearningWe provide additional experimental results on the multi-head learning of CIFAR100 with 10 tasksof 10 classes each. The training procedure of OvA-INN does not change from the usual single-headlearning but, at test time, the evaluation is processed by batches of 10 classes. The accuracy score isthe average accuracy over all 10 tasks. We report the results from (Yoon et al., 2017). Although ourapproach is able to match state-of-the-art results in accuracy, it should be noticed that it is drasticallymore memory and time consuming than the other baselines.
Table 4: t-SNE HyperparametersHyperparameter ValuePerplexity	15.0Principal Components 50Steps	400C Task-by-Task LearningWe provide additional experimental results on the multi-head learning of CIFAR100 with 10 tasksof 10 classes each. The training procedure of OvA-INN does not change from the usual single-headlearning but, at test time, the evaluation is processed by batches of 10 classes. The accuracy score isthe average accuracy over all 10 tasks. We report the results from (Yoon et al., 2017). Although ourapproach is able to match state-of-the-art results in accuracy, it should be noticed that it is drasticallymore memory and time consuming than the other baselines.
