Table 1: Compare curvature estimators, distortionDataset/dim	Ollivier		Forman		Avg. sectional		Grad. descent		c	loss	c	loss	c	loss	C	lossConflict / 2	-0.2	0.229	-16.5	0.261	0.25	0.269	0.0	0.229Conflict / 10	-0.2	0.078	-16.5	0.243	0.25	0.173	0.0	0.085Chicago / 2	-0.19	0.225	-8.37	0.224	-0.6	0.178	0.0	0.277Chicago / 10	-0.19	0.045	-8.37	0.216	-0.6	0.024	0.0	0.080CSPhDs /2	-0.28	0.152	-7.92	0.420	-0.26	0.172	0.0	0.209CSPhDs / 10	-0.28	0.085	-7.92	0.412	-0.26	0.208	0.0	0.056Euroroad / 2	-0.36	0.267	-1.95	0.452	0.027	0.384	0.0	0.147Euroroad / 10	-0.36	0.264	-1.95	0.445	0.03	0.370	0.0	0.052EuroSiS / 2	-0.17	0.247	-29.1	0.197	0.27	0.298	0.0	0.263EuroSiS / 10	-0.17	0.087	-29.1	0.187	0.26	0.202	0.0	0.096Power / 2	-0.35	0.287	-2.85	0.368	0.02	0.363	-1.88	0.372Power / 10	-0.35	0.278	-2.85	0.361	0.02	0.331	-1.0	0.400Facebook / 2	0.308	0.290	-44.7	0.327	0.153	0.240	0.0	0.238Facebook / 10	0.308	0.210	-44.7	0.323	0.153	0.084	0.0	0.072Indeed, the result for K2,2 follows from the corresponding result on cycle C4. Moreover, if forKl,m we have l ≥ 3 and m ≥ 2, then for any two nodes in the part of size l there are at least 2different geodesics of length 2 between them. Therefore, all such pairs lie at opposite poles of the
Table 2: Compare curvature estimators, zero-one lossDataset	Ollivier		Forman		Avg. sectional		Grad. descent		c	loss	c	loss	c	loss	C	lossConflict / 2	-0.2	0.032	-16.6	0.032	0.25	0.060	0.0	0.032Conflict / 10	-0.2	0.001	-16.6	0.025	0.25	10-4	0.0	0.0Chicago / 2	-0.19	0.004	-8.37	0.005	-0.6	0.004	0.0	0.002CSPhDs /2	-0.28	0.002	-7.92	0.004	-0.26	0.002	0.0	0.002Euroroad / 2	-0.36	0.002	-1.95	0.004	0.027	0.005	0.0	0.002EuroSiS / 2	-0.17	0.009	-29.1	0.017	0.26	0.058	0.0	0.010EuroSiS / 10	-0.17	0.003	-29.1	0.012	0.26	0.003	0.0	0.007Power / 2	-0.35	0.002	-2.85	0.006	0.02	0.006	0.0	0.002Facebook / 2	0.308	0.058	-44.7	0.059	-11.2	0.040	0.0	0.019Facebook / 10	0.308	0.007	-44.7	0.050	0.15	0.007	0.0	0.013threshold-based loss functions. The detailed description of our experimental setup is given in Ap-pendix E.3, the datasets and their properties are listed in Appendix E.1.
Table 3: Dataset descriptionnum. nodes num. edgesDatasetKarate club (Zachary, 1977)	34	78Dolphins (Lusseau et al., 2003)	62	159Football (Newman & Girvan, 2004)	115	613Political books (Newman, 2006)	105	441Conflict (Ward et al., 2007)	127	253Chicago (Eash et al., 1979)	822	821CSPhDs (W. De Nooy & Batagelj, 2011)	1025	1043Euroroad (Subelj & Bajec, 2011)	1039	1305EuroSiS (Khokhar, 2015)	1272	6424Power (Watts & Strogatz, 1998)	4941	6594Facebook (Leskovec & Mcauley, 2012)	4039	88234And our estimate for v is c(v) = mink≤kmax ck (v) (the worst-case curvature). To get a curvatureof the whole graph, we take a median of all ck(v). (Similarly to other curvature estimators, one canconsider a subsample of nodes instead of the whole node set to speed up the computation).
Table 4: Compare curvature estimators, distortion, synthetic datasetsDataset/dim	Ollivier		Forman		Avg. sectional		Grad. descent		c	loss	c	loss	c	loss	C	lossS100 / 2	0.0	0.334	-97.0	0.058	-1.0	0.304	-1.45	0.289S100 / 10	0.0	0.127	-97.0	0.014	-1.0	0.1	-30.2	0.025T3,6 / 2	-0.33	0.136	-2.0	0.254	-0.5	0.174	-9.77	0.271T3,6 / 10	-0.33	0.016	-2.0	0.243	-0.5	0.036	0.0	0.077K100 / 2	0.99	0.348	100	0.841	0.125	0.342	-48.7	0.163K100 / 10	0.99	0.134	100	0.841	0.125	0.124	-305	0.015C100 / 2	0.0	0.106	0.0	0.106	0.01	0.257	0.0	0.106C100 / 10	0.0	0.106	0.0	0.106	0.01	0.255	0.0	0.106K100,100 / 2	0.0	0.372	-196	0.294	0.008	0.372	2.1	0.309K100,100 / 10	0.0	0.301	-196	0.275	0.008	0.301	-139	0.27Table 5: Compare curvature estimators, zero-one loss, synthetic datasetsDataset	Ollivier		Forman		Avg. sectional		Grad. descent		c	loss	c	loss	c	loss	C	lossS100 / 2	0.0	0.02	-97.0	0.004	-1.0	0.027	0.0	0.02T3,6 / 2	-0.33	0.006	-2.0	0.005	-0.5	0.005	0.0	0.002C100 / 2	0.0	0.005	0.0	0.005	0.01	0.009	0.16	0.012K100,100 / 2	0.0	0.496	-196	0.492	0.008	0.496	-531	0.493
Table 5: Compare curvature estimators, zero-one loss, synthetic datasetsDataset	Ollivier		Forman		Avg. sectional		Grad. descent		c	loss	c	loss	c	loss	C	lossS100 / 2	0.0	0.02	-97.0	0.004	-1.0	0.027	0.0	0.02T3,6 / 2	-0.33	0.006	-2.0	0.005	-0.5	0.005	0.0	0.002C100 / 2	0.0	0.005	0.0	0.005	0.01	0.009	0.16	0.012K100,100 / 2	0.0	0.496	-196	0.492	0.008	0.496	-531	0.493K100,100 / 10	0.0	0.489	-196	0.491	0.008	0.480	-124	0.490We modified the implementation for our task: in particular, we added a regime responsible forminimizing threshold-based loss functions. E.g., zero-one loss is proportional toXI[vi 〜Vj] ∙ I[d(f(vi)f(vj)) > 1] + (1 - I[vi 〜Vj]) ∙ I[d(f(vi),f(vj)) ≤ 1]∙i,jThis function is not differentiable, so we replace it by gradient descent friendly function which wecall ReLuLoss:XI[Vi 〜Vj] ∙ReLu(d(f(vi),f(vj))-(1-ε)) + (1-1® 〜Vj])∙ReLU((1 + ε) -d(f(vi),f (Vj)),i,jwhere ReLU(x) = max(0, x), ε = 0.001. In our experiments we observed that such loss functionoutperforms other analogues (e.g., MSE and sigmoid-based smoothing) since it speeds up the con-vergence. To adapt to various threshold-based loss functions, we also reserve several iterations togradient steps based on the corresponding sigmoid-based smoothing.
Table 6: Volume-based curvatureDataset	d = 2	d= 10Karate club	-6.7	0.1Dolphins	-3.3	0.1Football	-2.1	0.1Political books	-1.6	0.1Conflict	-1.8	0.1Chicago	0.1	0.1CSPhDs	0.07	0.1Euroroad	0.1	0.1EuroSiS	-3.7	0.1Power	0.1	0.1Facebook	-11	0.1One can see that for d = 2 in many cases significantly negative curvature is predicted which is in-deed confirmed by our experiments, shown in Figures 8-18 (distortion loss). Non-negative curvatureis predicted for Chicago, CSPhDs, Euroroad and Power and indeed for these datasets the optimalcurvature is close to zero. In contrast, for d = 10 negative curvature is never predicted, which agreeswith the experiment well. So, in these cases it is not reasonable to embed networks to a hyperbolicspace.
