Table 1: Comparison of our methods to baselines cVAE (Eq. (4)) and sRb-VAE (Eq. (5)) evaluatedon metrics CA (clustering accuracy (%)) and SS (silhouette score). Lower CA and SS on z arebetter, meaning that the common latent vectors are indistinguishable. Ideal CA using z are 10% onL MNIST and NL MNIST, 50% on CelebA, and 11.11% on Affectnet. Lower LW2 is better, whichmeans that zx and zy are distributionally similar.
Table 2: Affectnet (Ruiz et al., 2019). Per class classification accuracy on each class of emotions.							which are also linearly combined. To obtain more expressive transformations kernels have alsobeen investigated (Abid et al., 2017). Since linearity restricts expressiveness of the model, in morerecent work, Severson et al. (2018) introduce ‘contrastive latent variable models’ which permit tonon-linearly transform the latent representation. Importantly, contrastive latent variable models stillcombine transformations linearly.
