Table 1: Results on the En-De, En-Vi and De-En test sets. Compared with the baseline models,Explicit Sparse Transformer reaches improved performances, and it achieves the state-of-the-artperformances in En-Vi and De-En.
Table 2: Results on the MSCOCO Karpathy test split.
Table 3: Comparison with state-of-the-art results on enwiki8. Explicit Sparse Transformer-XL refersto the Transformer with our sparsification method.
Table 4: In the Transformer model, the proposed method, top-k selection before softmax is fasterthan previous sparse attention methods and is comparable in terms of BLEU scores.
Table 5: Results of the ablation study of the sparsification at different phases on the En-Vi test set.
