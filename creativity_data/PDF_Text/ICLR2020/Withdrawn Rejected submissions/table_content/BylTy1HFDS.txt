Table 1: Classification accuracy using subsets of features										# Features	Cell type classification					Cancer subtype classification					5	10	20	30	50	5	10	20	30	50Laplacian	0.219	0.251	0.443	0.505	0.680	0.676	0.640	0.748	0.748	0.748MCFS	0.111	0.278	0.532	0.622	0.713	0.532	0.514	0.613	0.685	0.685UDFS	0.291	0.510	0.656	0.702	0.767	0.505	0.532	0.631	0.640	0.649PFS	0.268	0.335	0.465	0.565	0.649	0.622	0.685	0.703	0.721	0.712AEFS	0.320	0.574	0.759	0.806	0.847	0.523	0.486	0.550	0.640	0.604Variance	0.447	0.541	0.741	0.793	0.822					Leverage	0.463	0.634	0.780	0.816	0.852	0.523	0.568	0.613	0.658	0.649Jolliffe	0.264	0.557	0.712	0.793	0.844	0.667	0.676	0.622	0.685	0.703Greedy	0.203	0.367	0.580	0.691	0.820	0.657	0.673	0.684	0.750	0.753B. RAE	0.484	0.674	0.789	0.822	0.845	0.679	0.687	0.701	0.721	0.753G. RAE	0.487	0.667	0.771	0.822	0.846	0.645	0.678	0.686	0.694	0.740because batch correction sets all features to have unit variance. Laplacian scores (He et al., 2006)and multi-cluster feature selection (MCFS, Cai et al. (2010)) both aim to preserve local structure inthe data through spectral information. Unsupervised discriminative feature selection (UDFS, Yanget al. (2011)) aims to retain local discriminative information.
Table 2: Single-cell RNA sequencing imputation loss (MSE)# Features	5	10	20	30	40	50Laplacian	0.782	0.771	0.729	0.714	0.696	0.685MCFS	0.869	0.784	0.731	0.702	0.694	0.682UDFS	0.792	0.732	0.700	0.688	0.675	0.666PFS	0.758	0.741	0.706	0.686	0.677	0.669AEFS	0.783	0.720	0.684	0.670	0.663	0.658Variance	0.752	0.719	0.694	0.669	0.665	0.660Leverage	0.793	0.711	0.684	0.675	0.667	0.663Jolliffe	0.769	0.710	0.683	0.674	0.667	0.662Greedy	0.765	0.725	0.685	0.667	0.657	0.650Bern. RAE	0.731	0.680	0.658	0.650	0.647	0.643Gauss. RAE	0.731	0.678	0.657	0.650	0.647	0.644Table 3: Gene microarray imputation loss (MSE)# Features	5	10	20	30	40	50Laplacian	0.912	0.874	0.833	0.807	0.787	0.772MCFS	0.949	0.899	0.840	0.796	0.770	0.747UDFS	0.985	0.945	0.842	0.806	0.780	0.762PFS	0.895	0.847	0.790	0.757	0.732	0.717AEFS	0.984	0.933	0.869	0.830	0.805	0.779
Table 3: Gene microarray imputation loss (MSE)# Features	5	10	20	30	40	50Laplacian	0.912	0.874	0.833	0.807	0.787	0.772MCFS	0.949	0.899	0.840	0.796	0.770	0.747UDFS	0.985	0.945	0.842	0.806	0.780	0.762PFS	0.895	0.847	0.790	0.757	0.732	0.717AEFS	0.984	0.933	0.869	0.830	0.805	0.779Leverage	0.962	0.925	0.867	0.814	0.785	0.770Jolliffe	0.900	0.848	0.797	0.772	0.747	0.732Greedy	0.887	0.823	0.766	0.739	0.713	0.696Bern. RAE	0.896	0.835	0.774	0.737	0.713	0.696Gauss. RAE	0.887	0.832	0.770	0.737	0.714	0.69815Under review as a conference paper at ICLR 2020Table 4: Restricted autoencoder hyperparameters	Single-cell RNA		Gene microarray		Bernoulli	Gaussian	Bernoulli	GaussianOptimizer	Adam	Adam	Adam	AdamLearning rate	10-3	10-3	10-3	10-3Minibatch size	256	256	32	32
Table 4: Restricted autoencoder hyperparameters	Single-cell RNA		Gene microarray		Bernoulli	Gaussian	Bernoulli	GaussianOptimizer	Adam	Adam	Adam	AdamLearning rate	10-3	10-3	10-3	10-3Minibatch size	256	256	32	32Architecture	[100] × 4	[100] × 4	[100] × 2	[100] × 2Activations	ELU	ELU	ELU	ELUSchedule	20%	20%	20%	20%λ	10.0*	0.1	10.0*	10.0Table 5: Imputation model hyperparameters	Single-cell RNA	Gene microarrayOptimizer	Adam	AdamLearning rate	10-3	10-3Minibatch size	264	256Architecture	[100] × 4	[500] × 2Activations	ELU	ELUmodel was retrained. Overall, both methods were robust to most hyperparameters, except for thepenalty parameter λ and the schedule.
Table 5: Imputation model hyperparameters	Single-cell RNA	Gene microarrayOptimizer	Adam	AdamLearning rate	10-3	10-3Minibatch size	264	256Architecture	[100] × 4	[500] × 2Activations	ELU	ELUmodel was retrained. Overall, both methods were robust to most hyperparameters, except for thepenalty parameter λ and the schedule.
Table 6: Downstream prediction model hyperparameters	Cell type	Cancer subtype	Simulated tasksLoss function	Cross entropy	Cross entropy	MSEOptimizer	Adam	Adam	AdamLearning rate	10-3	10-3	10-3Minibatch size	64	32	32Architecture	[100] × 2	[16] × 1	[50] × 1Activations	ELU	ELU	ELU16Under review as a conference paper at ICLR 20200 5 0 5 0.9,8,8.7.70.0.0.0.0.
Table 7: Stability analysis10 Features	30 Features	50 FeaturesJaccard Adj. Rand Jaccard Adj. Rand Jaccard Adj. RandBernoulli RAE	0.722	0.833	0.722	0.834	0.718	0.830Gaussian RAE	0.736	0.843	0.720	0.833	0.832	0.905scores, which is among the least competitive baselines. We also include the results from 100 ran-domly selected sets of features. The results indicate that the amount of variance in the imputationloss from RAEs is negligible, compared to the gap with baseline methods. They also indicate thatselecting features at random naturally performs much worse, but that itis easier to pick good featureswhen the set is larger.
