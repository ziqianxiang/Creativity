Table 1: Comparing the out-of-distribution discriminative power of baseline VAE models and VAEmodels with negative sampling on grayscale images. Numbers for all permutations with the differentpossible roles of the three datasets (MINST, Fashion-MNIST and EMNIST-Letters) are reported.
Table 2: Comparing baseline VAEs and VAEs with negative sampling with Bernoulli, Gaussian, andQuantized Gaussian (Q. Gaussian) noise models on color image datasets.
Table 3: Comparing baseline model and negative sampling with different sources for negatives.
Table 4: Comparing the discriminative power of VAE models with negative sampling with Bernoullinoise model, with Fashion-MNIST and MNIST as inlier and OOD datasets, respectively, whenreconstruction of negative samples from EMNIST-Letters is also taken into account, with Î± weight.
Table 5: Comparing the discriminative performance of baseline VAE models with different latentdimension sizes, trained on Fashion-MNIST, and MNIST used as OOD dataset, with Bernoullinoise model. First column corresponds to our default setup. Reconstructed training samples andgenerated samples from the models are also provided. Our exploratory experiments indicate thatsimply increasing the latent dimension size does not help to overcome the problem of assigninghigher likelihoods to OOD data, and even the generative performance is diminishing.
Table 6: Generated SampleS from modelS trained on grayScale and color imageS.
Table 7: First two coordinates of the latent space of baseline VAE and VAE with negative sampling,with Bernoulli noise model, trained on Fashion-MNIST, and MNIST used as OOD dataset.
