Table 1: All input image sizes are 224x224. Sparse MBv1 models are 90% sparse, Sparse MBv2models are 80% sparse. In sparse MBv1 models, layer 12 uses a block size of 4. This is almostas efficient as the models in 4.4 and matches the top-1 scores of the dense models more closely.
Table 2: Hyper-parameters for MBv1 and MBv2 training. Learning rates are specified in a reducedspace and then multiplied by a factor of 16 due to the batch size.
