Table 1: Transferability of the adversarial images created against a given noisy channel denoted as A(adaptive attack specified in the first column) to the defense protected with a noisy channel denotedas D (the defense with a noisy channel specified in the first row). Each result represents a recovery(%) of the adversarial examples (generated for A) to correct labels after applying the defense (D). Weuse 30% FC compression, 50% SVD compression, 4 bit values in CD, 0.03 noise level for Gauss andLaplace, and 0.04 noise level for the Uniform channel. We use 2000 images from the CIFAR-10 testset and 100 attack iterations with 5 binary steps to find the c value (with initial c value set to 0.01) forthe adaptive C&W L2 attack. The baseline test accuracy is 93.56%. The test accuracy of the noisychannels on clean images is given in the first row denoted: Empty (an empty attack).
Table 2: On CIFAR-10 with ResNet-18, we measure the max test accuracy for imprecise channelswithout any adversarial perturbation. This signifies the amount of accuracy we sacrifice with respectto the baseline test accuracy of the model (without any perturbations of the images): 93.56%.
Table 3: Given an adversarial input, we pass the input through a channel before prediction. Weevaluate the accuracy (%) of the classifier over 1000 images, the best possible accuracy is listed inthe Baseline column. For the channels, we report in parentheses: compression used (%), number ofbits per value, and the strength of the attack (e). We use the attacks described in Section: 4.1Attack	Data set	Baseline	FC (%)	CD (bits)	Uniform ()	Gauss ()	IdenBIM L1	CIFAR10	93.5	86.2 (20)	85.1 (4)	82.8 (0.03)	82.1 (0.03)	0LBFGS	CIFAR10	93.5	82.8 (50)	80.2 (4)	79.2 (0.04)	79.3 (0.05)	0C&W L2	CIFAR10	93.5	85.2 (20)	84.4 (4)	84.3 (0.01)	84.8 (0.02)	0FGSM	CIFAR10	93.5	79.0 (50)	49.2 (4)	49.4 (0.03)	49.9 (0.03)	0PGD L∞	CIFAR10	93.5	88.6 (10)	84.3(5)	85.7 (0.01)	84.9 (0.02)	0BIM L1	ImageNet	83.5	81.5 (10)	82.0 (4)	81.2 (0.009)	81.2 (0.009)	0LBFGS	ImageNet	83.5	71.7 (70)	77.6 (4)	76.4 (0.07)	76.5 (0.07)	0C&W L2	ImageNet	83.5	78.7 (50)	80.9 (4)	81.4 (0.03)	80.4 (0.03)	0FGSM	ImageNet	83.5	73.8 (50)	76.0 (4)	75.4 (0.03)	75.4 (0.02)	0PGD L∞	ImageNet	83.5	82.1 (5)	82.9 (4)	82.0 (0.007)	80.9 (0.01)	0C.3 Channel accuracy on clean and adversarial examplesWe compare the accuracy of the perturbation channels on clean and adversarial examples in Figure 8.
Table 4: Channel tuning. The best parameters for the perturbation channels when tuned on the PGDand C&W attacks. ____________________________________________________________^^^^^^ Dataset Channel ^^^^^∙^^^	CIFAR-10	ImageNetFC (%)	20	60SVD (%)	40	70Gauss ()	0.015	0.04Uniform ()	0.025	0.04C.4 Neighborhood of adversarial examplesPlease, see Figure 9 and description in Section 4.1.
Table 5: The distortion and accuracy for the adaptive setting where the adversary knows the defensemethod. We report top-1 class, use 100 image samples, run 1000 iterations of C&W attack, = 0.04,apply a single random noise injection.
Table 6: Transferability of the adversarial images that extend results from Table 1 for ImageNetdataset. We use 30% FC compression, 50% SVD compression, 4 bit values in CD, 0.03 noise levelfor Laplace, and 0.04 noise level for the Gauss and Uniform channels. We use 3000 images from theImageNet-10 validation set and 100 attack iterations.
Table 7: Transferability of the adversarial images. The results are presented similarly to Figure 1 butfor different parameters. We use 50% FC compression, 50% SVD compression, 4 bit values in CD,0.03 noise level for Laplace, and 0.04 noise level for the Gauss and Uniform channels. We use 3000images from the CIFAR-10 validation set and 1000 attack iterations.
