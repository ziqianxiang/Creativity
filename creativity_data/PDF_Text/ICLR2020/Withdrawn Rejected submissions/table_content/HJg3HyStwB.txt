Table  1:  Classification  accuracies  on  MNIST.  The  first  row  shows  the  accuracies  of  the  classifiers  underno attack.  The first three attacks (including the proposed SdAdv) are spatial-distortion-based methods.  Thefollowing four attacks are perturbation-based methods. SdpAdv with g > 0.0 is the proposed method with bothspatial distortions and perturbations. For the non-robustified classifiers, g varies in the range of   0.1, 0.2, 0.3while for the robust classifiers, g is set to 0.3.  In the last column of “sum”, we show the summation over theaccuracies of all the classifiers with g = 0.3. Best results from the attacks with perturbations are in boldface.
Table 2: Classification accuracies on Fashion MNIST.
Table 3:  Comparison of test accuracy, L2  norm, and running time Here we report the above metrics for thenon-robustified classifier with Model A. The test accuracies are copied from Table 1 and Table 2.  We sample100 images from each of the two datasets and calculate EPd  [  xA     x  ], which is the L₂ norm between theinput and adversarial images.  In addition, we report the running time (seconds) to generate attacks for those100 sample images.  All the attacks ran in the same machine with the same environment.  g = 0.3 is used forthe attacks with perturbations, unless stated otherwise.
