Table 1: Evaluation results on single sequence tasks. We report the base performance of attentionmodels and absolute change in accuracy for its variant. We note that across all datasets, degradationin performance on altering attention weights during inference is more compared to varying themduring both training and inference. Overall, the change in performance is less compared to othertasks. Please refer to ยง4.1 for more details.
Table 2: The performance comparison of attention based models and their variants on pair sequencetasks. We find that the degradation in performance is much more than single sequence tasks.
Table 3: Evaluation results on neural machine translation. Similar to pair sequence tasks, we findthat the deterioration in performance is much more substantial than single sequence tasks. Pleaserefer to ยง4.1 for more details.
