Table 1: Performance of our modules compared to PointNet++ baseline. The impact of our modulesbecomes most prominent as the dataset complexity grows. On PartNet our deepConvPN networkincreases pIoU by 9.7% over PointNet++, outperforming its shallow counterpart by +2.1%.
Table 2: Performance of our deepConPN network compared to other SOTA methods on S3DIS.
Table 3: Performance of our blocks on three different architectures (DGCNN, PointCNN and Spi-derCNN) on three datasets using two different metrics: (i) memory consumption and (ii) IoU. Ourlean counterparts improve significantly both the IoU (up to +8.0%) and the memory consumption(up to -69%).
Table 4: Efficiency of our network architectures measured with a batch size of 8 samples on a NvidiaGTX 2080Ti GPU. All of our lean architectures allow to save a substantial amount of memory onGPU wrt. the PointNet++ baseline from 58% with mRes to a 67% decrease with convPN. This latterconvolution-type architecture wins on all counts, decreasing both inference time (-41%) and thelength of backward pass (-68%) by a large spread. Starting form this architecture, the marginal costof going deep is extremely low: doubling the number of layers in the encoding part of the networkincreases inference time by 6.3% on average and the memory consumption by only 3.6% at mostcompared to convPN. Please refer to Appendix C.3 for absolute values.
Table 5: Performance on ShapeNet-Part. The table reports the mIoU performance based on a train-ing on the whole dataset all at once. Although the number of samples in the dataset is quite high,learning the segmentation on Shapenet-Part does not necessarily need deep networks because of thesimplicity of the shapes and the low number of object part categories. All of our network archi-tectures outperform PointNet++ baseline by at least +1.2%. Our deep architecture still improve theperformance of its shallower counterpart by a small margin of +0.2%.
Table 6:	Performance on PartNet. The table reports the Part IoU performance based on a trainingon the whole dataset all at once in contrast with Mo et al. (2018). The fine details of the segmen-tation and the high number of points to process make the training much more complex than anyformer datasets. PointNet++, here, fails to capture enough features to segment the objects properly.
Table 7:	Efficiency of our network architectures measured with a batch size of 8 samples on a NvidiaGTX 2080Ti GPU. All of our lean architectures allow to save a substantial amount of memory onGPU wrt. the PointNet++ baseline from 58% with mRes to a 67% decrease with convPN. This latterconvolution-type architecture wins on all counts, decreasing both inference time (-41%) and thelength of backward pass (-68%) by a large spread. Starting form this architecture, the marginal costof going deep is extremely low: doubling the number of layers in the encoding part of the networkincreases inference time by 6.3% on average and the memory consumption by only 3.6% at mostcompared to convPN)Parameters (M)PointNet++mResmResXconvPNdeepConvPNShapeNet-Part ScanNet PartNetMemory Footprint (Gb)1.881.561.682.14
Table 8: Per-class IoU on PartNet when training a separate network for each category, evaluatedfor three different architectures for Chairs and Tables (60% of the whole dataset). Our efficientnetworks achieve here similar performance as their vanilla counterpart while delivering significantsavings in memory.
Table 9: Efficiency of our memory efficient blocks applied to a KPConv backbone. Our blocks allowto decrease significantly the memory footprint by up to 52.5% with no impact both on inference andbackward speed.
