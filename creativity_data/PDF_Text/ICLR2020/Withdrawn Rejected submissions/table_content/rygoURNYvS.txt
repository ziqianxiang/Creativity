Table 1: Benchmark finetuning datasets. Note that for validation, we have subsampled the originaldatasets (in parentheses) down to 8192 examples, except for exception classification, which onlyhad 2459 validation examples, all of which are included.
Table 2: Test accuracies of finetuned CuBERT against BiLSTM (with and without Word2Vecembeddings) and Transformer trained from scratch on the classification tasks. “ns” and “hs” re-spectively refer to negative sampling and hierarchical softmax settings used for training CBOW andSkipgram models. “From scratch” refers to training with freshly initialized token embeddings, thatis, without pre-trained Word2Vec embeddings.
Table 3: Effects of reducing training-split size on finetuning performance on the classification tasks.
Table 4: Best out of 20 epochs of finetuning, for three example lengths, on the classification tasks.
Table 5: Comparison of the finetuned CuBERT+pointer model and the LSTM+pointer modelfrom Vasic et al. (2019) on the variable misuse localization and repair task.
Table 6: Example counts per class for the Exception Type task, broken down into the dataset splits.
Table 7: Binary operators.
