Table 1: Ranges for hyper-parameter search, the log base is 10Hyper-parameter Rangelog(αθ)log(ωφ)log(τ)log(λ1)log(λ2)log(λ3)ηnoise[-8, -3][-2,	2][-3, -1][-3, 0][-3, 0][-1, 1][0.3, 1.8]D.2 Model selectionDuring training, a policy is evaluated on a set of 10 different episodes every 100 learning steps. Atthe end of the training, the model at the best evaluation iteration is saved as the best version of thepolicy for this training, and is re-evaluated on 100 different episodes to have a better assessment of
Table 2: Best found hyper-parameters for the SPREAD environmentHyper-parameter	DDPG	MADDPG	MADDPG+Sharing	MADDPG+TeamReg	MADDPG+CoachRegαθ	5.3 * 10-5	2.1 * 10-5	9.0 * 10-4	2.5 * 10-5	1.2* 10-5ωφ	53	79	0.71	42	82τ	0.05	0.083	0.076	0.098	0.0077λ1	-	-	-	0.054	0.13λ2	-	-	-	0.29	0.24λ3	-	-	-	-	8.4ηnoise	1.0	0.5	0.7	1.2	1.2Table 3: Best found hyper-parameters for the BOUNCE environmentHyper-parameter	DDPG	MADDPG	MADDPG+Sharing	MADDPG+TEAMREG	MADDPG+COACHREGαθ	8.1 * 10-4	3.8 * 10-5	1.2 * 10-4	1.3* 10-5	6.8* 10-5ωφ	2.4	87	0.47	85	9.4τ	0.089	0.016	0.06	0.055	0.02λ1	-	-	-	0.06	0.0066λ2	-	-	-	0.0026	0.23λ3	-	-	-	-	0.34ηnoise	1.2	0.9	1.2	1.0	1.1Table 4: Best found hyper-parameters for the CHASE environmentHyper-parameter	DDPG	MADDPG	MADDPG+Sharing	MADDPG+TeamReg	MADDPG+CoachReg
Table 3: Best found hyper-parameters for the BOUNCE environmentHyper-parameter	DDPG	MADDPG	MADDPG+Sharing	MADDPG+TEAMREG	MADDPG+COACHREGαθ	8.1 * 10-4	3.8 * 10-5	1.2 * 10-4	1.3* 10-5	6.8* 10-5ωφ	2.4	87	0.47	85	9.4τ	0.089	0.016	0.06	0.055	0.02λ1	-	-	-	0.06	0.0066λ2	-	-	-	0.0026	0.23λ3	-	-	-	-	0.34ηnoise	1.2	0.9	1.2	1.0	1.1Table 4: Best found hyper-parameters for the CHASE environmentHyper-parameter	DDPG	MADDPG	MADDPG+Sharing	MADDPG+TeamReg	MADDPG+CoachRegαθ	4.5 * 10-4	2.0* 10-4	9.7 * 10-4	1.3* 10-5	1.8* 10-4ωφ	32	64	0.79	85	90τ	0.031	0.021	0.032	0.055	0.011λ1	-	-	-	0.06	0.0069λ2	-	-	-	0.0026	0.86λ3	-	-	-	-	0.76ηnoise	0.6	1.0	1.5	1.0	1.1Table 5: Best found hyper-parameters for the COMPROMISE environmentHyper-parameter	DDPG	MADDPG	MADDPG+Sharing	MADDPG+TeamReg	MADDPG+CoachReg
Table 4: Best found hyper-parameters for the CHASE environmentHyper-parameter	DDPG	MADDPG	MADDPG+Sharing	MADDPG+TeamReg	MADDPG+CoachRegαθ	4.5 * 10-4	2.0* 10-4	9.7 * 10-4	1.3* 10-5	1.8* 10-4ωφ	32	64	0.79	85	90τ	0.031	0.021	0.032	0.055	0.011λ1	-	-	-	0.06	0.0069λ2	-	-	-	0.0026	0.86λ3	-	-	-	-	0.76ηnoise	0.6	1.0	1.5	1.0	1.1Table 5: Best found hyper-parameters for the COMPROMISE environmentHyper-parameter	DDPG	MADDPG	MADDPG+Sharing	MADDPG+TeamReg	MADDPG+CoachRegαθ	6.1 * 10-5	3.1 * 10-4	6.2 * 10-4	1.5 * 10-5	3.4* 10-4ωφ	1.7	0.94	0.58	90	29τ	0.065	0.045	0.007	0.02	0.0037λ1	-	-	-	0.0013	0.65λ2	-	-	-	0.56	0.5λ3	-	-	-	-	1.3ηnoise	1.1	0.7	1.3	1.6	1.615Under review as a conference paper at ICLR 2020
Table 5: Best found hyper-parameters for the COMPROMISE environmentHyper-parameter	DDPG	MADDPG	MADDPG+Sharing	MADDPG+TeamReg	MADDPG+CoachRegαθ	6.1 * 10-5	3.1 * 10-4	6.2 * 10-4	1.5 * 10-5	3.4* 10-4ωφ	1.7	0.94	0.58	90	29τ	0.065	0.045	0.007	0.02	0.0037λ1	-	-	-	0.0013	0.65λ2	-	-	-	0.56	0.5λ3	-	-	-	-	1.3ηnoise	1.1	0.7	1.3	1.6	1.615Under review as a conference paper at ICLR 2020D.4 Selected hyper-parameters (ablations)Tables 6, 7, 8, and 9 shows the best hyper-parameters found by the random searches for each of theenvironments and each of the ablated algorithms.
Table 6: Best found hyper-parameters for the SPREAD environmentHyper-parameter MADDPG+Agent Modelling MADDPG+Policy Maskαθ	1.3 * 10-5	6.8 * 10-5ωφ	85	9.4τ	0.055	0.02λ1	0.06	0λ2	0	0λ3	-	0ηnoise	1.0	1.1Table 7: Best found hyper-parameters for the BOUNCE environmentHyper-parameter MADDPG+Agent Modelling MADDPG+Policy Maskαθ	1.3 * 10-5	2.5 * 10-4ωφ	85	0.52τ	0.055	0.0077λ1	0.06	0λ2	0	0λ3	-	0ηnoise	1.0	1.3Table 8: Best found hyper-parameters for the CHASE environmentHyper-parameter MADDPG+Agent Modelling MADDPG+Policy Mask
Table 7: Best found hyper-parameters for the BOUNCE environmentHyper-parameter MADDPG+Agent Modelling MADDPG+Policy Maskαθ	1.3 * 10-5	2.5 * 10-4ωφ	85	0.52τ	0.055	0.0077λ1	0.06	0λ2	0	0λ3	-	0ηnoise	1.0	1.3Table 8: Best found hyper-parameters for the CHASE environmentHyper-parameter MADDPG+Agent Modelling MADDPG+Policy Maskαθ	2.5 * 10-5	6.8 * 10-5ωφ	42	9.4τ	0.098	0.02λ1	0.054	0λ2	0	0λ3	-	0ηnoise	1.2	1.1Table 9: Best found hyper-parameters for the COMPROMISE environmentHyper-parameter MADDPG+Agent Modelling MADDPG+Policy Mask
Table 8: Best found hyper-parameters for the CHASE environmentHyper-parameter MADDPG+Agent Modelling MADDPG+Policy Maskαθ	2.5 * 10-5	6.8 * 10-5ωφ	42	9.4τ	0.098	0.02λ1	0.054	0λ2	0	0λ3	-	0ηnoise	1.2	1.1Table 9: Best found hyper-parameters for the COMPROMISE environmentHyper-parameter MADDPG+Agent Modelling MADDPG+Policy Maskαθ	1.2 * 10-4	2.5 * 10-4ωφ	0.71	0.52τ	0.0051	0.0077λ1	0.0075	0λ2	0	0λ3	-	0ηnoise	1.8	1.316Under review as a conference paper at ICLR 2020
Table 9: Best found hyper-parameters for the COMPROMISE environmentHyper-parameter MADDPG+Agent Modelling MADDPG+Policy Maskαθ	1.2 * 10-4	2.5 * 10-4ωφ	0.71	0.52τ	0.0051	0.0077λ1	0.0075	0λ2	0	0λ3	-	0ηnoise	1.8	1.316Under review as a conference paper at ICLR 2020D.5 Hyper-parameter search resultsThe performance of each parameter configuration is reported in Figure 10 yielding the performancedistribution across hyper-parameters configurations for each algorithm on each task. The samedistributions are depicted in Figure 11 using box-and-whisker plot. It can be seen that TeamReg andCoachReg both boost the performance of the third quartile, suggesting an increase in the robustnessacross hyper-parameter.
