Table 1: Dataset-level metrics for the MIMIC-III binary mortality and multiclass CCS predictiontasks across M = 200 models in the deterministic RNN ensemble. Individual models are nearlyidentical in terms of dataset-level performance across both tasks, but selecting a single model wouldremove the model uncertainty information such as that visualized in Figure 1.
Table 2: Metrics for marginalized predictions on the MIMIC-III and eICU mortality tasks givenM = 200 models in the deterministic RNN ensemble, and M = 200 samples from each of theBayesian RNN models. Confidence intervals are computed via validation and test set bootstrappingwith 1000 bootstrap sets.
Table 3: Top and bottom 10 words in free-text clinical notes based on their associated Bayesianembeddings distributionâ€™s entropy, along with their frequency in the training dataset.
Table A.1: Hyperparameters and their associated search sets or ranges.
Table A.2: Model-specific hyperparameter values.
Table A.3: Calibration error for marginalized predictions on the mortality task for an averageover M = 200 models in the deterministic RNN ensemble, and M = 200 samples from each ofthe Bayesian RNN models. We find that marginalization slightly increases the calibration of thedeterministic ensemble, and that the Bayesian models are comparably well-calibrated.
