Table 2: Accuracy of each model on the propositional Logical Entailment task. Overall, ourproposed TPRU outperforms its closest comparison counterpart GRU, and provides comparableperformance to the LSTM. The value besides ‘TPRU’ indicates the number of role vectors. Resultsof BiDAF models are parenthesised. ‘Mean 2#Vars’ is the mean number of worlds of proposition-values; here and below, bold indicates the best result among all models with the same architecture.
Table 3: Results on MNLI and QNLI. Our TPRU outperforms LSTM. The number of role vectorsin each of our models is indicated by the value beside ‘TPRU’. As shown, our proposed TPRUoverall outperforms LSTM on two tasks.
Table 4: Perplexity of language modelling on WikiText-2 and WikiText-103. (Lower is better.)(left): Our TPRU with 1024 role vectors gives similar perplexity score as the widely used LSTMdoes. (right): Negative Log-likelihood on training set of language modelling task on WikiText-103.
Table 5: PMI between POS Tags and Maximally Selected Role Vectors.
