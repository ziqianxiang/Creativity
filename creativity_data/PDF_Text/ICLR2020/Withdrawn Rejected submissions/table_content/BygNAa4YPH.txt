Table 1: Baseline results for various few-shot classifiers. All numbers are in percentages, evaluatedin the 5-way 5-shot setting for all 4 datasets, using the standard Conv4 backbone and SPP confidencescore. The reported OOS numbers are the means over all the OOS datasets used for the correspondingin-distribution dataset.
Table 2: LCBO, -MinDist results for ProtoNet. All numbers are in percentages, evaluated in the5-way 5-shot setting for all 4 datasets, using the standard Conv4 backbone. The reported OOSnumbers are the means over all the OOS datasets used for the corresponding in-distribution dataset.
Table 3: Classification accuracy (in percentages) of semi-supervised learning results on tieredImageNet. Column headingsindicate type of distractor used at test-time. ‘+’, and ‘-’ denote thelack and presence of degradation. ’Supervised’ refers to trainingwithout an unlabelled set.
Table 4: Description of the functions used throughout this paper.
Table 5: Expanded Omniglot resultsD.2 CIFAR 1 00Metric		AUROC↑			AUPR↑					FPR90(			Method	SPP	-MinDist	LCBO	SPP	-MinDist	LCBO	SPP	-MinDist	LCBOOOE	60.1	68.0	73.3	61.0	67.2	71.5	84.3	73.1	62.8Gaussian	47.2	100.0	89.0	49.7	100.0	88.5	93.3	0.0	30.9Uniform	63.7	96.2	82.8	67.6	97.1	83.9	83.8	7.5	48.8Rademacher	47.3	100.0	87.2	49.6	100.0	86.5	93.0	0.0	34.7Texture	54.5	89.5	80.4	54.8	87.5	78.6	87.9	26.1	48.9Places	56.5	88.9	78.1	58.4	89.0	77.8	87.9	32.9	56.8SVHN	64.0	48.4	67.7	67.0	50.7	68.2	82.2	93.1	75.5LSUN	57.3	91.4	79.5	59.2	91.7	80.3	87.5	25.7	56.7iSUN	55.6	90.1	78.7	57.4	90.1	78.6	88.4	28.9	56.4TinyImagenet	56.2	88.9	79.7	58.0	88.5	79.5	88.1	31.4	53.7OOS MEAN	55.8	88.2	80.3	58.0	88.3	80.2	88.0	27.3	51.4MEAN	56.2	86.1	79.6	58.3	86.2	79.3	87.6	31.9	52.5Table 6: Expanded CIFAR100 resultsD.3 miniIMAGENETMetric		AUROC↑			AUPR↑					FPR90(			Method	SPP	-MinDist	LCBO	SPP	-MinDist	LCBO	SPP	-MinDist	LCBO
Table 6: Expanded CIFAR100 resultsD.3 miniIMAGENETMetric		AUROC↑			AUPR↑					FPR90(			Method	SPP	-MinDist	LCBO	SPP	-MinDist	LCBO	SPP	-MinDist	LCBOOOE	56.7	61.9	65.6	ɪr"	61.1	63.1	86.8	80.2	73.1Gaussian	37.4	100.0	64.3	41.7	100.0	64.7	95.8	0.0	68.0Uniform	54.4	99.8	87.8	56.3	99.8	87.3	87.5	0.0	34.4Rademacher	39.0	100.0	64.0	42.4	100.0	65.0	95.7	0.0	71.1Texture	52.7	49.9	74.6	53.7	45.9	73.3	88.8	77.5	60.2Places	57.7	46.6	76.6	59.0	47.7	77.3	86.1	91.3	61.6SVHN	51.1	5.6	74.5	54.0	31.2	76.2	91.0	100.0	65.8LSUN	59.2	51.3	76.1	61.4	53.6	78.2	85.2	92.7	66.4iSUN	57.9	49.7	78.1	59.4	50.2	78.7	85.6	89.5	59.4TinyImagenet	56.4	46.5	75.9	57.7	47.2	76.0	86.9	90.1	62.0OOS MEAN	51.8	61.0	74.7	54.0	64.0	75.2	89.2	60.1	61.0MEAN	52.2	61.1	73.8	54.2	63.7	74.0	88.9	62.1	62.2Table 7: Expanded miniImageNet results.
Table 7: Expanded miniImageNet results.
Table 8: Expanded tieredImageNet results.
Table 10: Hyperparameters used for ABML. The last two rows, the KL weights, are not describedin (Ravi & Beatson, 2019) explicitly, but only described as ’down-weighed’ in their text. We chosewhat empirically works best for us.
Table 11: Classification accuracy (in percentages) of semi-supervised learning results ontieredImageNet. Column headings indicate type of distractor used.
Table 12: Test accuracy for different architectures on CIFAR-100 using Conv4I Additional Results for CIFAR- 1 00I.1	DIFFERENT shot-/way- SETTINGSThe overall trend that LCBO and -MinDist are better than SPP holds for different few-shot evaluationsettings.
Table 13: Comparison of OOE and OOS detection performance in several way and shot settings forCIFAR-100, using the Conv4 backbone.
Table 14: Comparison of the Conv4 and ResNet18 backbones, in the 5-way 5-shot setting.
Table 15: Conv4 backbone, 5w5s, LCBO+OE {TinyImages}Metric	AUROC	AUPR	FPR90OOE	-^723^^	69.9	63.3Gaussian	99.9	99.9	0.2Uniform	100.0	100.0	0.0Rademacher	99.9	99.9	0.2Texture	88.9	86.0	26.8Places	72.5	70.0	61.0SVHN	79.3	79.9	56.5LSUN	72.4	70.4	61.2iSUN	74.1	71.4	57.7TinyImagenet	75.8	73.2	54.8OOS MEAN	-^848^-	83.4	35.4MEAN	83.5	82.1	38.2Table 16: Conv4 backbone, LCBO + OE {TinyImages, Gaussian, uniform, Rademacher}J.2 ODINODIN (Liang et al., 2017) is shown to perform well in the supervised setting. However, as wediscussed, SPP does not work well with the Prototypical Network. Below is a Table showing our18Under review as a conference paper at ICLR 2020
Table 16: Conv4 backbone, LCBO + OE {TinyImages, Gaussian, uniform, Rademacher}J.2 ODINODIN (Liang et al., 2017) is shown to perform well in the supervised setting. However, as wediscussed, SPP does not work well with the Prototypical Network. Below is a Table showing our18Under review as a conference paper at ICLR 2020attempt to use ODIN in our setting. It slightly improves over SPP, but the improvement is notsubstantial when compared to -MinDist. We then tried to, like ODIN, perform virtual gradientperturbation. Instead of computing the gradient of the perturbation by probability, we tried perturbingbased on the distance in the embedding, so we could improve over -MinDist. However, this approachwas not effective in our initial attempts.
