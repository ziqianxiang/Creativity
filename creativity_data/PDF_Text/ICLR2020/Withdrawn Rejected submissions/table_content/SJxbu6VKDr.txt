Table 1: Improvement in error performance (%) on ImageNet. The numbers in brackets denotethe improvement in performance over the baselines. ResNet-200* means We follow the strategyin (He et al., 2016b) to train this model on 224 × 224 but evaluate on 320 × 320.
Table 2: Compared to SE in different networks on ImageNet. We evaluate the models of errorperformance (%), GFLOPs (G) and parameters (M). G/P means GFLOPs/parameters. In VGG-16experiments, SE is employed for all the convolutional layers, which is the same as GCT. In otherexperiments, SE is only employed in block level (Res-Block or Inception-Block) as proposed (Huet al., 2018b). This difference makes that SE uses comparable GFLOPs with GCT.
Table 3: Improvement on COCO with Mask R-CNN framework. BN* means BN is frozen. +means increasing the training iterations from 90K to 270K. When using GN, we follow the strategyin the original paper (Wu & He, 2018).
Table 5: Ablation experiments. We evaluate error performancein GCT-ResNet-50 on ImageNet (%). The ResNet-50 baselineachieves a top-1 of 23.8 and a top-5 of 7.0.
Table 4: Improvement in top-1accuracy (%) over the state-of-the-art method on Kinetics.
Table 6: Clock time comparison. We calculate average inference times (ms) per batch by using1 GTX 1080Ti with 16 batch size for 1,000 iterations on ImageNet. For the sake of fairness, themodules are applied for all the Convs in VGG-16.
Table 7: Improvement in top-1 error (%) on the CIFAR-10 and CIFAR-100 datasets.
