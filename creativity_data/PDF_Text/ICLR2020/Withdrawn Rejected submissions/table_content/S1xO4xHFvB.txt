Table 1: Classification test accuracy on image datasets — in each row the best model (selected basedon validation accuracy) up to the specified maximum number of parameters is shown. Thereforethe model and its test accuracy values do not change for greater numbers of parameters, if a smallermodel has a better validation accuracy. For some models very small versions could not be triviallyachieved (indicated by ”-”). All trained models are fully connected architectures. We did not trainACN for more than 500,000 parameters.
Table 2: Compression and accuracy change compared to a large FC model and a linear model baselineDataset	Compared to large FC				Compared to Linear Model				small FC		small ACN		small FC		small ACN		ρ	∆Acc(%)	P	∆Acc(%)	ρ	∆Acc(%)	P	∆Acc(%)1) bioresponse	67.41	-0.28	322.15	-1.18	0.998	+0.70	4.771	-0.902) HAR	155.59	-7.13	361.82	-4.40	2.942	-6.25	6.840	-3.503) InternetAds	133.23	-1.09	1115.58	-2.66	0.998	+0.31	8.360	-1.264) isolet	74.49	-3.71	87.76	-3.45	3.042	-2.86	3.58	-2.605) nomao	218.67	-0.74	460.36	-1.43	0.972	+1.37	2.047	+0.686) optdigits	149.12	-6.15	168.06	-5.33	1.879	-4.41	2.117	-3.597) spambase	129.59	-2.12	92.46	-0.15	0.951	+0,23	0.678	+2.208) splice	211.46	-3.47	316.12	-5.33	1.467	-1.73	2.193	-3.599) theorem	97.47	-6.50	95.30	-4.03	0.647	+2.14	0.633	+4.61On the image datasets ACN consistently and significantly outperforms all other models for up to100,000 parameters. On MNIST our smallest model has 4091 parameters and outperforms a linearmodel with 7850 by 1.8% although the baseline has nearly twice as many parameters. The sametrend can be observed for FashionMNIST (7057 / 7850 with a difference of 2.04%) and CIFAR10where an ACN with 7057 parameters employs less than a quarter of the 30730 parameters needed bythe simplest linear model and outperfoms it by a overwhelming 8.63%. Surprisingly the LayerNetoutperfoms all other models for the category < 500, 000. For more than 500,000 parameters the FC
Table 3: Description of datasetsDataset	# Instances	# Features	# Classes	% Minor. Cl.
Table 4: HyPer-Parameters for Preliminary Study (4.1)Hyper-Parameter	SearchGrid FC	SearchGrid ACNhidden layer size	2, 3, 4, 5, 8	3, 4, 5, 8learning rate	0.1, 0.05, 0.01	0.1, 0.01number of layers	1,2,3	2, 3, 4max gradient norm	0.99, 1, 2, 5	0.99, 1, 2use batCh norm	True, False	True, Falsenumber of modules	-	2, 4, 8Hyper-Parameter and Training Setup for real-world datasetsGiven the large comPutational demands of deeP learning architectures, a ProPer full hyPer-Parametersearch is infeasible for the models emPloyed on the real-world datasets. Under these circumstanceswe follow the established trend of using some sPecific deeP architectures designed based on exPertknowledge together with a small selected Parameter grid containing learning rate (0.01, 0.001), useof batch normalization (Ioffe & Szegedy, 2015) and droPout Probability (0.0, 0.3). To enable a faircomParison the hyPer-Parameter search for every model tyPe which is trained from scratch is donefor the same number of combinations. Accordingly for each dataset we evaluate eight differentarchitectures Per model tyPe where we vary the number of hidden layers and the width of theselayers, for ACN M and D are different between some of the eight varying architectures. The sizeof the set of modules M is varied in the range between 3 and 5 for the LayerNet (ablation study)and between 16 and 512 for the ACN. The range of inPut dimensions D is set to a subset of (2, 4,
Table 5: Test accuracy and its standard deviation on real-world datasets. The standard deviation ofruns with FC, RER, BC and TP models are always below the displayed three decimals precision andtherefore are not ShoWn in the table.________________________________________________________Capacity	FC RER	TensorNet	BC	TP	LayerNet	I	ACN	(1) bioresponse		< 1000	--	-	--	-	0.787 (±0.005)< 2500	-	0.546	-	-	0.548	-	0.787 (±0.005)< 5000	0.803	0.570	-	0.685	0.548	0.775 (±0.008)	0.797 (±0.005)< 10000	0.793	0.628	-	0.776	0.744	0.777 (±0.003)	0.797 (±0.005)≥ 10000	0.793	0.609	0.784 (±0.013)	0.784	0.797	0.800 (±0.004)	0.797 (±0.005)	(2) HAR		< 500	--	-	--	-	0.940 (±0.001)< 1000	0.913	0.420	-	-	-	-	0.967 (±0.003)< 2500	0.971	0.669	-	-	0.171	0.763 (±0.108)	0.977 (±0.005)< 5000	0.984	0.764	-	0.974	0.438	0.943 (±0.044)	0.985 (±0.004)≥ 5000	0.983	0.764	0.975 (±0.001)	0.981	0.950	0.983 (±0.002)	0.989 (±0.002)(3) InternetAds< 1000 < 2500 < 5000 < 10000 ≥ 10000		- - - 0.972 0.977	- - 0.842 0.842 0.909	- - - - 0.902 (±0.002)	- - - 0.964 0.967	- 0.842 0.842 0.842 0.908	- - - 0.929 (±0.062) 0.978 (±0.004)	0.956 (±0.012) 0.970 (±0.002) 0.972 (±0.005) 0.972 (±0.005) 0.972 (±0.005)<	2500	0.494	0.254	-	(4) isolet -	-	0.420 (±0.124)	0.883 (±0.017)<	5000	0.842	0.414	-	0.480	0.141	0.773 (±0.030)	0.941 (±0.001)
Table 6: Test accuracy and its standard deviation on real-world datasets for the additional sparsificationbaselines. The standard deviation of runs with FC, L1 and L1+HT models are always below thedisplayed three decimals precision and therefore are not shown in the table.
