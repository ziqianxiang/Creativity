Table 1: Computational complexity of several methods to implement CDSA				Methods	Independent	Joint	Shared	DecomposedFLOPS(X 109)	0.39	3.22	0.21	024NUmber of VariabIeS (× 105)	18.15	0.44	0.44	16.093.3	FrameworkImputation: As shown in Fig. 3(a), we apply our CDSA mechanism in a Transformer Encoder, astack of N = 8 identical layers with residual connection (He et al. (2016)) and normalization (Lei Baet al. (2016)) as employed by Vaswani et al. (2017). To reconstruct the missing (along with other)values of the input, we apply a fully connected Feed Forward network on the final Value tensor, whichis trained jointly with the rest of the model.
Table 2: RMSE on dataset NYC-Traffic for ComParisons With SOTAModel \ Missing Rate	20%	30%	40%	50%	60%	70%	80%	90%Auto Regressive	2.354	2.357	2.359	2.362	2.364	2.652	2.796	3.272Kriging expo	2.142	2.145	2.157	2.152	2.155	2.165	2.182	2.231Kriging linear	2.036	2.008	2.031	2.038	2.056	2.074	2.111	2.194MTSI Luo et al. (2018a)	1.595	1.597	1.603	1.605	1.608	1.641	1.672	1.834BRITS Cao et al. (2018)	1.337	1.339	1.341	1.355	1.376	1.395	1.408	1.477DCRNN Li et al. (2018)	1.397	1.399	1.401	1.419	1.432	1.443	1.459	1.601CDSA (ours)	1.203	1.208	1.211	1.214	1.215	1.217	1.234	1.377Table 3: MSE on dataset KDD-2018 for comparisons with SOTAModel \ Missing Rate	20%	30%	40%	50%	60%	70%	80%	90%Mean Filling	0.916	0.907	0.914	0.923	0.973	0.935	0.937	1.002KNN Filling	0.892	0.803	0.776	0.798	0.856	0.852	0.873	1.243MF Filling	0.850	0.785	0.787	0.772	0.834	0.805	0.860	1.196MTSI Luo et al. (2018a)	0.844	0.780	0.753	0.743	0.803	0.780	0.837	1.018BRITS Cao et al. (2018)	0.455	0.421	0.372	0.409	0.440	0.482	0.648	0.725DCRNN Li et al. (2018)	0.579	0.565	0.449	0.506	0.589	0.622	0.720	0.861CDSA (ours)	0.373	0.393	0.287	0.291	0.387	0.495	0.521	0.631Imputation (NYC-Traffic, KDD-2018) In Table 2 , our CDSA consistently outPerforms traditionalmethods (i.e., Auto Regressive, Kriging expo, Kriging linear) and recent RNN-based methods
Table 3: MSE on dataset KDD-2018 for comparisons with SOTAModel \ Missing Rate	20%	30%	40%	50%	60%	70%	80%	90%Mean Filling	0.916	0.907	0.914	0.923	0.973	0.935	0.937	1.002KNN Filling	0.892	0.803	0.776	0.798	0.856	0.852	0.873	1.243MF Filling	0.850	0.785	0.787	0.772	0.834	0.805	0.860	1.196MTSI Luo et al. (2018a)	0.844	0.780	0.753	0.743	0.803	0.780	0.837	1.018BRITS Cao et al. (2018)	0.455	0.421	0.372	0.409	0.440	0.482	0.648	0.725DCRNN Li et al. (2018)	0.579	0.565	0.449	0.506	0.589	0.622	0.720	0.861CDSA (ours)	0.373	0.393	0.287	0.291	0.387	0.495	0.521	0.631Imputation (NYC-Traffic, KDD-2018) In Table 2 , our CDSA consistently outPerforms traditionalmethods (i.e., Auto Regressive, Kriging expo, Kriging linear) and recent RNN-based methods(i.e. MTSI, BRITS, DCRNN) over a wide range of missing rate. Because CDSA leverages theself-attention mechanism to avoid sequential processing of RNN and directly model the relationship6Under review as a conference paper at ICLR 2020between distant data. Table 3 shows that our method again achieves significant improvements oncross-dimensional data imputation task. Detailed overview of baselines can be found in Supp.
Table 4: MAE/RMSE/MAPE on dataset METR-LA for ComParisons With SOTAModel	15min			30min			MAE	RMSE	MAPE	MAE	RMSE	MAPEFC-LSTM Sutskever et al. (2014)	3.44	^^63^^	9.6%	3.77	7.23	10.9%MTSI Luo et al. (2018a)	3.75	7.31	10.52%	3.89	7.73	11.04%BRITS Cao et al. (2018)	2.86	5.46	7.49%	3.37	6.78	9.13%DCRNN Li et al. (2018)	2.77	5.38	7.3%	3.15	6.45	8.8%DST-GCNN Wang et al. (2018)	2.68	5.35	7.2%	3.01	6.23	8.52%GaAN Zhang et al. (2018b)	2.71	5.24	6.99%	3.12	6.36	8.56%CDSA(ours)	3.01	5.08	7.82%	3.14	5.38	8.30%Model	60min			Mean			MAE	RMSE	MAPE	MAE	RMSE	MAPEFC-LSTM Sutskever et al. (2014)	4.37	6.89^^	13.2%	3.86	7.41	11.2%MTSI Luo et al. (2018a)	4.22	8.39	12.15%	4.01	7.59	10.85%BRITS Cao et al. (2018)	3.65	7.66	10.55%	3.32	6.96	9.47%DCRNN Li et al. (2018)	3.60	7.59	10.50%	3.28	6.80	8.87%DST-GCNN Wang et al. (2018)	3.41	7.47	10.25%	-	-	-GaAN Zhang et al. (2018b)	3.6	7.6	10.5%	3.16	6.41	8.72%CDSA(ours)	3.40	6.27	9.76%	3.16	5.48	8.50%4.3	Discussions
Table 5: Comparisons of different losses in CDSA on METR-LATime	30min	Ave	30min	Ave	30min	Ave	30min	AveMetric \ Loss	RMSE		MSE		MAE		(RMSE+MAE)/2	MAE	3.14	3.16	3.43	3.41	3.28	3.33	3.21	3.25RMSE	5.38	5.48	6.20	6.11	5.67	5.83	5.55	5.70MAPE	8.30%	8.50%	9.32%	9.19	8.70%	9.00%	8.53%	8.80%Ablation study of different cross-dimensional self-attention manners: We comPare the Perfor-mance for different solutions in CDSA mechanism on the three datasets listed above. 1) The Wayof attention modeling determines the computational complexity. As shoWn in Table 1, since theIndependent calculates dimension-specific Value vectors in parallel, the number of variables andFLOPs are larger than those of the Decomposed. As the Joint and the Shared both share the variablesfor each dimension, the number of variables is small and basically equals With each other. As theJoint builds a huge attention map, its FLOPs is much larger than others. Since the Decomposed draWsattention maps like the Independent but shares Value like the Joint, it reduces the computationalcomplexity significantly. 2) As shoWn in Table 6 - 8, We evaluate these methods on three datasets andthe Decomposed alWays achieves the best performance thanks to the better learning ability comparedto the Joint and Shared. More discussions can be found in Supp.
Table 6: Comparisons of different manners to implement CDSA on dataset NYC-Traffic.
Table 7: Comparisons of different manners to implement CDSA on dataset KDD-2018.
Table 8: Comparisons of different manners to implement CDSA on dataset METR-LA.
Table 9: PerfOrmanCe Improvement for Imputation MaskModel \ Missing Rate		20%	30%	40%	50%	60%	70%	80%	90%— KDD-2018 		Masked	Wr	=≡Γ	0.287	0.291	0.387	0.495	0.521	0.631	NOMaSk	0.886	0∙839	0∙838	0.849	0.917	0.903	0.947	1.195NYC	Masked	1.04	1.10	1.32	1.18	1.18	1.28	1.29	1.75	No Mask	1.69	1.70	1.72	1.77	1.80	1.84	1.91	2.04A.4 Attention MAP CalculationLocation(L)Time(T) [∙■Measurement (M)• X(Pq) ∖》SQq, PI)• X(Pi)' Scaled numericalproductFigure 6: The effective attention map calculation in Joint and Shared.
Table 10: Comparisons of Prediction Performance on dataset METR-LATime	Metric	Shifted Output Shifted Output Encoder Input Encoder Input (Mean Final) (Mean Step) (Complemented)	(Mean)15 min	MAE RMSE MAPE	3.05	3.09	3.15	3.01	= 5.46	5.50	5.31	5.08 8.31%	8.47%	8.18%	7.82%30 min	MAE RMSE MAPE	349	354	347	3.14 6.62	6.66	5.96	5.38 9.56%	9.88%	9.19%	8.30%60 min	MAE RMSE MAPE	4.21	4.26	4TT7	3:40 8.14	8.19	7.67	6.27 11.44%	11.79%	11.94%	9.76%Mean	MAE RMSE MAPE	35	356	354	3.16 6.56	6.61	6.14	5.48 9.56%	9.84%	9.53%	8.50%In summary, by setting shifted output as the Decoder input, multiple Attention Map are calculatedfor forecasting value of different time stamps which requires huge memory usage. Still, integrated16Under review as a conference paper at ICLR 2020sampling makes this framework suffer from an exhausted training time, since we need to send thepredicted output back to decoder (Run) and repeat this Run for T times. During testing, we can usethe output corresponding to its own Run (Step) as the predicted result, as well as the output of thelast run (Final). As shown in the first 2 columns in Table 10, the performance of outputs in the lastrun (Final) is better than that of Step mode, which means the leftward information flow still exists tobreak the auto-regressive property in data forecasting even though the mask is adopted on the inputdata. For fair comparison, the models for testing are trained in one GPU and the training time are allless than 50 hours.
Table 11: Selection of Common Locations between Air QuaIity and Meteorology	Air QuaIity	MeteoroIogy1	fengtaihUayUan	fengtai_meo2	fangshan	fangshan_meo3	daxing	daxing_meo4	tongzhou	tongzhou_meo5	shunyi	shunyi_meo6	pingchang	Pingchang_meo7	mentougou	mentougou_meo8	PinggU	PinggU_meo9	huairou	huairou_meo10	miyun	miyun_meo11	yanqin	yanqing_meoThe original KDD 2018 dataset consists of an Air Quality data of 35 locations and an Meteorologydataset of 18 locations. each dataset contains 6 different measurements. During experiment, Luoet al. (2018a) select 11 common locations between the two datasets and the measurements of pairedlocations are concatenated. The location pairs are described in Table 11. Since the unit of somemeasurements are label-based, e.g., the measurement weather denotes the types of weather includingsunny, rainy and etc, these label are replaced with value such as 1, 2, ..., 9. As the range of differentmeasurements varies, Luo et al. (2018a) first apply Z-score normalization for each measurement and
Table 12: Computational complexity of several methods to implement CDSAMethods	Independent	Joint	Shared	DecomposedAverage running time / sample (ms)	218	—	859	159	161	—Following the model hyper-parameter setting in Tabls. 1, we further compare the average runningtime for one segment during testing. As the way of attention modeling determines the computationalefficiency, computation method with higher FLOPs also leads to longer running time. As shown inTable. 12, the running time of Joint is much higher than the rest 3 methods. Since the computationschemes of Shared is similar with the Decomposed, while the number of trainable variables of Sharedis much less that of Decomposed, the average processing time of Shared is a bit smaller than therunning time of the Decomposed.
Table 13: Statistics of Dataset						Dataset	Task	# location	# meas.	duration	Start	EndKDD-2018	Imputation	36	12 二	364 days	1/1/2017	12/30/2017NYC Traffic	Imputation	186	1	23 days	12/03/2015	12/26/2015METR-LA	Forecasting	207	1	122 days	3/1/2012	6/30/2012Dataset	-#Training^^	#Testing	#Vandation	unit duration	seg. length	Loss functionKDD-2018	182	-	182	2 hours	48 hours	RMSENYC Traffic	173	-	173	5 minutes	36 hours	RMSEMETR-LA	23991	3404	6831	5 minutes	1 hour	RMSEThe dataset in METR-LA also has missing data while the missing rate is 91%. Thus, the segmentsample whose all units are zero, i.e., all-zero sample, exists. During training, the all-zero sample (intraining set) essentially has no contribution for the model training. During testing and validation, theevaluation metric will of such samples will not be counted.
Table 14: MAE/MRE on dataset KDD-2015 for ComParisons With SOTAModel \ Dataset	PM2.5		TEMP		HUM		MAE	MRE	MAE	MRE	MAE	MREMean	55.51	77.97%	9.21	97.56%	20.34	57.85%KNN	29.79	41.85%	1.26	19.83%	7.28	16.22%MICE	27.42	38.52%	1.23	18.29%	6.97	15.87%ST-MVL Yi et al. (2016)	12.12	17.40%	0.68	4.59%	3.37	5.91%MTSI Luo et al. (2018a)	13.34	18.01%	0.71	4.67%	3.51	6.21%BRITS Cao et al. (2018)	11.56	16.65%	0.63	4.16%	3.31	5.68%DCRNN Li et al. (2018)	12.33	17.82%	0.69	4.59%	2.95	5.12%IIN Zhou & Huang (2018)	10.63	15.31%	0.63	4.22%	2.90	5.09%CDSA (ours)	10.67	14.89%	0.61	4.15%	2.81	4.92%Table 15: Comparisons of different manners to implement CDSA on dataset KDD-2015.
Table 15: Comparisons of different manners to implement CDSA on dataset KDD-2015.
