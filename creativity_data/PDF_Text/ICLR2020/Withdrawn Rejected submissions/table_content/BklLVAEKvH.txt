Table 1: Performance of various clustering methods on MNIST, Reuters, CIFAR-10 and CIFAR-100.
Table 2: Generalization of clustering methods on MNIST, Reuters, CIFAR-10 and CIFAR-100datasets. The model is trained only on training set and the reported numbers are the test accuracy.(-)means values are not reported. (âˆ£) reported in SpectralNet [(Shaham et al., 2018)].
Table 3: Numerical value of the normalized cut (Equation 1) over the clustering results of the CNC andSpectralNet [(Shaham et al., 2018)]. CNC is able to find better cuts than the SpectralNet5.4	GeneralizationWe further evaluate the generalization ability of CNC by dividing the data randomly to a 90%-10% split and training on the training set and report the ACC and NMI on the test set (Table 2).
Table 4: Generalization results: CNC is trained on VGG and validated on MNIST-conv. Duringinference, the model is applied to unseen TensorFlow graphs: ResNet. Inception-v3, and AlexNet. Theground truth for AlexNet is Bal = 99%, Cut = 4.6%, for Inception-v3, is Bal = 99%, Cut = 3.7%, andfor ResNet is Bal = 99% and Cut = 3.3%. GraphSAGE-on generalizes better than the other models.
