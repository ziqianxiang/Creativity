Table 1: Test accuracy for a FFNN with width 300 and depth 300 for different activation functions onMNIST and CIFAR10. We show test accuracy after 10 epochs and 100 epochsActivation	MNIST		CIFAR10		Epoch 10	Epoch 100	Epoch 10	Epoch 100ReLU (EOC)	46.53 ± 12.01	82.11 ± 4.51	20.38 ± 1.85	35.88 ± 0.6LReLU0.01 (EOC)	48.10 ± 3.31	84.71 ± 3.39	22.62 ± 1.15	29.44 ± 4.14LReLU0.02 (EOC)	49.09 ± 3.58	84.3. ± 3.98	18.62 ± 4.56	30.78 ± 6.33LReLU0.03 (EOC)	50.94 ± 4.48	85.49 ± 2.71	21.19 ± 6.53	34.54 ± 2.32PReLU	51.94 ± 5.51	87.49 ± 1.58	22.95 ± 3.57	36.13 ± 3.83ELU (EOC)	91.63 ± 2.21	96.07 ± 0.13	33.81 ± 1.55	46.14 ± 1.49Tanh (EOC)	91.16 ± 1.21	95.75 ± 0.27	32.37 ± 1.88	42.40 ± 1.13Softplus	10.11 ± 0.09	10.13 ± 0.18	11.13 ± 0.15	11.09 ± 0.36Sigmoid	9.85 ± 0.11	9.87 ± 0.10	10.65 ± 0.25	10.33 ± 0.17activation functions that do not have an EOC, such as Softplus and Sigmoid, we use He initializationfor MNIST and Glorot initialization for CIFAR10 (see He et al. (2015) and Glorot & Bengio (2010)).
