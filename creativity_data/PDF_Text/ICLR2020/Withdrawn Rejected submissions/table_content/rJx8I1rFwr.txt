Table 1: Top-1 and top-5 accuracies (%) on the novel classes for the ImageNet based n-shot classificationbenchmark. We use ResNet-10 as the feature extractor. PN: prototypical networks, PMN: prototype matchingnetworks, Cos-Cls: cosine classifiers. Methods with ‘w/ G’ use a meta-learned hallucinator. Standard deviationsfor all numbers are of the order of 0.2%. Our PECAN achieves the best performance. Importantly, PECAN ismodel-agnostic and can be combined with different meta-learning models to improve their performance.
Table 2: Ablation on precision and collaboration requirements. ''cls'： hard precision based on classificationloss, ''pre': soft precision-inducing loss, ‘'hai’: collaborative objective imposed on the hallucinator. Differentcomponents are complementary to each other.
Table 3: Ablation on choice of similarity measure inthe soft precision-inducing loss. preal and pG : classprobabilities of hreal and hG , respectively. pbreal andpbG : class probabilities in the absence of the ground-truth labels. ‘CE’: cross-entropy loss as in knowledgedistillation (Hinton et al., 2015), ‘JS’: Jensen-Shannondivergenc, ‘sKL’: symmetric KL-divergence. Our sim-ilarity measure achieves the best performance.
Table 4: Test accuracies (%) on the novel classes forthe miniImageNet dataset. ‘±’ indicates 95% confi-dence intervals over tasks. Our PECAN significantlyoutperforms the state-of-the-art approaches.
Table A.1: Additional analysis of the softprecision-inducing loss in the case of PN onthe ImageNet based n-shot classification bench-mark. pbreal and pbG: class probabilities of hrealand hG in the absence of the ground-truth la-bels, respectively. mreal and mG : class meansof real and hallucinated examples, respectively.
Table A.2: Comparison on the n = 5-shot sinusoidal regression task in Finn et al. (2017). Our PECAN isgeneral and outperforms the baselines for the regression task as well.
