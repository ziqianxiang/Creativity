Table 1: Patch Gaussian achieves state of the art in the CIFAR-C (left) and ImageNet-C (right)robustness benchmarks while maintaining clean test accuracy. “Original mCE” refers to the jpeg-compressed benchmark, as used in Geirhos et al. (2018a); Hendrycks & Dietterich (2018). “mCE” isa version of it without the extra jpeg compression. Note that Patch Gaussian improves robustnesseven in corruptions that aren’t noise-based. *Cutout 16 is presented for direct comparison withDeVries & Taylor (2017); Gastaldi (2017). For Resnet-200, we also present Gaussian at a higher σto highlight the accuracy-robustness trade-off. Augmentation hyper-parameters were selected basedon the method in Section 3.2 and can be found in Appendix. See text for details.
Table 2: Patch Gaussian can be used with other regularization methods for improved robustness.
Table 3: Patch Gaussian can be combined with AutoAugment (Cubuk et al., 2018) data augmen-tation policy for improved results. “Original mCE” refers to the jpeg-compressed benchmark, as usedin Geirhos et al. (2018a); Hendrycks & Dietterich (2018). “mCE” is a version of it without the extrajpeg compression. All of the models are ResNet-50 trained on ImageNet with best AutoAugmentpolicy for 180 epochs, to highlight improvements.
Table 4: Patching also helps models trained adversarially to maintain clean accuracy and gainCommon Corruption robustness. All are Wide-ResNet models trained on CIFAR with PGD with eps8 for 7 steps, with step size 2), just like in Madry et al. (2017).
Table 5: Augmentation hyper-parameters selected with the method in Section 3.2 for eachmodel/dataset. *Indicates manually-chosen stronger hyper-parameters, used to highlight the ef-fect of the augmentation on the models. "≤" indicates that the value is uniformly sampled UP to thegiven maximum value.
Table 6: Full original corruption errors (Original CEs) for ImageNet models trained with differentaugmentation strategies.
Table 7: Full corruption errors (CEs) for ImageNet models trained with different augmentationstrategies.
Table 8: Comparison with SIN+IN (Geirhos et al., 2018a). By using Z=74.6%, Patch Gaussiancan match SIN+IN’s og mCE and test accuracy. Understandably, however, our gains are moreconcentrated in noise-based corruptions, whereas shape-biased models get gains in other corruptions.
Table 9: Mean average precision (mAP) on COCO with baseline augmentation of horizontal flips andPatch Gaussian. mAPS, mAPM, and mAPL refer to mAP for small, medium, and large objects,respectively. mAP50 and mAP75 refer to mAP at intersection over union values of 50 and 75,respectively. mAP in the final column is the averaged mAP over IoU=0.5:0.05:0.95.
