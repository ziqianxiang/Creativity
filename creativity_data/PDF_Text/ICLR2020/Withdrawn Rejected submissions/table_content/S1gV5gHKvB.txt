Table 1:	Sample of wrong sentences generated using the fooling algorithm on BERTSentence	Scoreblock characters rude cedar plum pronoun climbers	0.993Pfizer Dracula articles lousy scissors firemen Genie Letters 0.990umps teacher Abbey Gillespie brave scones answer exercises 0.980However, the outcome of the fooling algorithm is not always positive. Different runs convergeto different results. It is not rare to generate correct sentences, mostly when sentences are short,depending on the initial random set. An example is shown in table 2, where a sample of sentencesfrom a different run is reported. The generated sentences are grammatically correct or almost,meaning that we are not surprised if the model classifies them as grammatical with high scoreseven if they are not completely correct. We report samples of correct ones and almost correct onesgenerated from the same run to show qualitatively the results of procedures that we consider notsuccessful and we don’t use them for the following analysis.
Table 2:	Sample of correct and ”almost” correct sentences generated using the fooling algorithm onBERTCorrect sentences	ScoreStudents admired metal art gently	0.998We’re expecting frustrating unflattering airport Experts poisonous 0.997citizens nearly begged rice	0.997”Almost” correct sentences	ScoreNY restaurant student Shelly dove lack	0.998Calvin nearly begged wooden	0.998Maxwell’s kicking made polarity News Harold	0.997In figure 1, we show the distribution of scores during a fooling run of L = 9 loops that succeeded.
Table 3:	Sample of correct sentences generated using the fooling algorithm on improved BERTSentenceScorehandle introduced manuscript handkerchief beans 0.994bear pesto camera bugs abound	0.994boat presentation freedom boxes	0.993Figure 3: Example of distributions of the improved BERT scores when fooling sentences are notfound6.5	Robustness ExperimentsNow we investigate the robustness of the models, to understand if the fooling datasets are universalor not, performing the two following experiments.
Table 4:	Sample of sentences generated using the fooling algorithm on RoBERTaSentenceScoretreading monkeys won next	0.993Yeltsin used spaghetti selfish	0.991mauve dungeon dangers tickle Bingley 0.990A qualitative inspection of the generated sentences suggests that, even if there is a big fractionof sentences that can be considered grammatically correct even if meaningless, there could be stillfound samples of random sentences classified wrongly with high scores. These sentences are usuallyshorter than the ones generated using BERT. We can interpret this result as a strength of RoBERTa,since the longer random sentences are discarded in the firsts iterations, selecting the shorter ones thatare easier to be generated correctly using a random procedure. Tuning the parameter γ , that definesthe probability of randomly deleting words, we are still able to direct the algorithm in the directionwe want, so to generate fooling sentences.
