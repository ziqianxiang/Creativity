Table 1: MUSE-large outperforms all previous models under the standard training and evaluationsetting on WMT14 En-De and WMT14 En-Fr datasets.
Table 2: MUSE-base outperforms previous state-of-the-art models on IWSLT De-En translationdatasets and outperforms previous models without BPE processing on IWSLT En-Vi.
Table 3: Comparisons between MUSE and its variants on the IWSLT 2015 De-En translation task.
Table 4: The comparison between the inference speed of MUSE and Transformer.
Table 5: Case study on the De-En dataset. The blue bolded words denote the wrong translationand red bolded words denote the correct translation. In case 1, transformer fails to capture therelationship between some words and their neighbors, such as “right” and “clap”. In case 2, thecause adverbial clause is correctly translated by MUSE while transformer misses the word “why”and fails to translate it.
