Table 1: Test accuracy (%) using different met-rics on energy minimization without hierarchyinformation along l2 -norm minimization (weightdecay) on CIFAR-10 and resnet-20.
Table 3: Test accuracy (%) using different met- rics on energy minimization (‘E’) and hierarchical		regularization (‘H’) on CUB200:		‘E’ / ‘E+H’ re-spectively. metric \ db	ReSnet-18	Resnet-50baseline	72:17	74.21baseline+l2	72.29	74.05N-euclidean2	72.61 /75.99	73.49 / 76.14angular2	72.43 / 76.11	73.55 / 76.66cosine	72.12/75.64	73.26 / 76.85Dhter	72.58/75.99	73.57 / 76.37bin Dh	72.55/76.21	73.57 / 76.99DAM	73.04/76.02	73.88 / 75.95DAMcos	72.31 / 76.14	73.59 / 77.32DAMcos	72.28 / 75.37	72.42 / 74.12DGM	72.90 / 76.35	74.16 / 75.30DH0 Mcos	72.55 / 76.11	74.64 / 76.94Dcos(HM)	72.55 / 76.32	72.86 / 76.56Table 2: Test accuracy (%) using different met-rics on energy minimization (‘E’) and hierarchicalregularization (‘H’) on CIFAR-100: ‘E’ / ‘E+H’respectively. metric \ db	resnet-20	resnet-110
Table 2: Test accuracy (%) using different met-rics on energy minimization (‘E’) and hierarchicalregularization (‘H’) on CIFAR-100: ‘E’ / ‘E+H’respectively. metric \ db	resnet-20	resnet-110baseline	63:86	62.02baseline+l2	68.03	72.90N-euclidean2	67.59 / 68.65	73.95/73.96angular2	67.83 / 67.76	74.40 / 73.89cosine	68.11 / 68.45	73.37/73.37ter Dh	68.44 / 68.68	73.73/73.97bin Dh	68.52 / 68.69	73.97/74.26DAM	68.58 / 68.86	73.43/73.50Dcos(AM)	68.58 / 68.60	73.14 / 73.65Dcos(AM)	67.57 / 68.36	73.14 / 73.72Dcos(HM)	68.62 / 68.65	73.07 / 73.65Table 4: Test accuracy (%) using different met-rics with energy minimization (‘E’) and hierarchi-cal regularization (‘H’) on Cars: ‘E’ / ‘E+H’ re-spectively.
Table 4: Test accuracy (%) using different met-rics with energy minimization (‘E’) and hierarchi-cal regularization (‘H’) on Cars: ‘E’ / ‘E+H’ re-spectively.
Table 5: Test accuracy (%) using different met-rics on energy minimization (‘E’) and hierarchicalregularization (‘H’) on CIFAR-100 and resnet-20.
Table 6: Test accuracy (%) using heterogeneousmetrics at Conv. layers and FC layer respec-tively, on energy minimization (‘E’) and hier-archical regularization (‘H’) on CIFAR-100 andresnet-20.
Table 7: Statistics of benchmark datasetsDataset	#classes {pa, ch}	#train	#test	input size	#samples /class	#super /subclassCIFAR-10	{1, 10}	50,000	10,000	32 × 32	5000.00	0.1000CIFAR-100	{20, 100}	50,000	10,000	32 × 32	500.00	0.2000CUB200	{70, 200}	5,994	5,794	224 × 224	29.97	0.3500Cars	{9, 196}	8,144	8,041	224 × 224	41.55	0.0459Deep neural network models and training details First, resnet-20 (0.29M) and resnet-110 (1.73M), which include a combination of Basic blocks with output channels [16, 30, 64] are adopted forlight models. An input dimensionality of the fully connected (FC) layer (a classier) is 64 for bothresnet-20 and resnet-110. Second, heavy models are adopted such as Resnet-18 (11.28M10) and10Dependent on the number of classes and the corresponding center parameters, the size could variate (e.g.
