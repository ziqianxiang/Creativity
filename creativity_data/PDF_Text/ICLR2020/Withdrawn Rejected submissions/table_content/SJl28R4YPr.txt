Table 2: GNN Performance to Predict Witnesses of UNSATTable 1: GNN Performance to Predict SAT/UNSATI DATASET	40 PAIRS 80 PAIRS 160 PAIRS IlDATASET	160 UNSAT 320 UNSAT 640 UNSAT ∣8 ITERS TESTING	(0.98, 0.94) (0.40, 0.64)	(1.00, 0.92) (0.50, 0.48)	(0.84, 0.76) (0.50, 0.50)	8 ITERS TESTING	(1.00, 0.99) (0.64, 0.06)	(0.95, 0.72) (0.67, 0.05)	(0.82, 0.28) (0.69, 0.05)16 ITERS	(1.00, 1.00)	(0.96, 0.96)	(0.88, 0.70)	16 ITERS	(1.00, 1.00)	(0.98, 0.87)	(0.95, 0.69)TESTING	(0.54, 0.46)	(0.52, 0.52)	(0.54, 0.48)	TESTING	(0.64, 0.05)	(0.65, 0.05)	(0.65, 0.06)32 ITERS	(1.00, 1.00)	(0.98, 0.98)	(0.84, 0.80)	32 ITERS	(1.00, 1.00)	(0.99, 0.96)	(0.91, 0.57)TESTING	(0.32, 0.68)	(0.52, 0.50)	(0.52, 0.50)	TESTING	(0.63, 0.05)	(0.64, 0.05)	(0.63, 0.05)(Selsam et al., 2019), if those formulas do not have a small unsatisfiable core (minimal numberof clauses that is enough to cause unsatisfiability). Another work (Amizadeh et al., 2019) evencompletely removed unsatisfiable formulas from the training dataset (since they slowed down thetraining process), and only trained for predicting solutions to satisfiable formulas. However, thesedefects are not a problem for SAT solvers, since predicting satisfiability with high confidence isalready good enough for a binary distinction.
Table 1: GNN Performance to Predict SAT/UNSATI DATASET	40 PAIRS 80 PAIRS 160 PAIRS IlDATASET	160 UNSAT 320 UNSAT 640 UNSAT ∣8 ITERS TESTING	(0.98, 0.94) (0.40, 0.64)	(1.00, 0.92) (0.50, 0.48)	(0.84, 0.76) (0.50, 0.50)	8 ITERS TESTING	(1.00, 0.99) (0.64, 0.06)	(0.95, 0.72) (0.67, 0.05)	(0.82, 0.28) (0.69, 0.05)16 ITERS	(1.00, 1.00)	(0.96, 0.96)	(0.88, 0.70)	16 ITERS	(1.00, 1.00)	(0.98, 0.87)	(0.95, 0.69)TESTING	(0.54, 0.46)	(0.52, 0.52)	(0.54, 0.48)	TESTING	(0.64, 0.05)	(0.65, 0.05)	(0.65, 0.06)32 ITERS	(1.00, 1.00)	(0.98, 0.98)	(0.84, 0.80)	32 ITERS	(1.00, 1.00)	(0.99, 0.96)	(0.91, 0.57)TESTING	(0.32, 0.68)	(0.52, 0.50)	(0.52, 0.50)	TESTING	(0.63, 0.05)	(0.64, 0.05)	(0.63, 0.05)(Selsam et al., 2019), if those formulas do not have a small unsatisfiable core (minimal numberof clauses that is enough to cause unsatisfiability). Another work (Amizadeh et al., 2019) evencompletely removed unsatisfiable formulas from the training dataset (since they slowed down thetraining process), and only trained for predicting solutions to satisfiable formulas. However, thesedefects are not a problem for SAT solvers, since predicting satisfiability with high confidence isalready good enough for a binary distinction.
Table 4: Performance of CEGAR CounterExample-RankingTable 3: Performance of CEGAR Candidate-RankingDataSet	TrainU	TrainS	TestU	TestS	I DATASET	TrainU	TrainS	TestU	TestS-	21.976	34.783	21.945	33.885	-	21.976	34.783	21.945	33.885maxSAT	13.144	30.057	12.453	28.863	maxSAT	14.754	22.265	14.748	21.638GNN1	14.387	31.800	14.273	30.588	GNN3	16.95	26.717	16.743	24.325GNN2	13.843	31.404	13.787	30.273	GNN4	17.492	26.962	17.198	25.198with 2 baselines:•	-: vanilla CEGAR without ranking•	MaxSAT: ranking by the number of satisfied clauses via on-the-fly formula simplification(Note that although MaxSAT performs the best in our evaluations, it is too expensive to usein practice. See asymptotic analysis in supplementary material A.2)via measuring the average number of iterations needed to solve the 2QBF problems. Here we chooseto measure the number of iterations rather than the wall clock time, because the former only measuresthe quality of our heuristics, while the latter is subject to various optimizations and implementationdetails that involve lots of engineering effort (out of the scope of this paper). From multiple randomseeds, we report the results of the models that perform best on the training datasets.
Table 3: Performance of CEGAR Candidate-RankingDataSet	TrainU	TrainS	TestU	TestS	I DATASET	TrainU	TrainS	TestU	TestS-	21.976	34.783	21.945	33.885	-	21.976	34.783	21.945	33.885maxSAT	13.144	30.057	12.453	28.863	maxSAT	14.754	22.265	14.748	21.638GNN1	14.387	31.800	14.273	30.588	GNN3	16.95	26.717	16.743	24.325GNN2	13.843	31.404	13.787	30.273	GNN4	17.492	26.962	17.198	25.198with 2 baselines:•	-: vanilla CEGAR without ranking•	MaxSAT: ranking by the number of satisfied clauses via on-the-fly formula simplification(Note that although MaxSAT performs the best in our evaluations, it is too expensive to usein practice. See asymptotic analysis in supplementary material A.2)via measuring the average number of iterations needed to solve the 2QBF problems. Here we chooseto measure the number of iterations rather than the wall clock time, because the former only measuresthe quality of our heuristics, while the latter is subject to various optimizations and implementationdetails that involve lots of engineering effort (out of the scope of this paper). From multiple randomseeds, we report the results of the models that perform best on the training datasets.
Table 5: Performance of CEGAR Both-RankingDATASET	TrainU	Trains	TestU	TestS-	21.976	34.783	21.945	33.885MAXSAT	9.671	20.777	9.425	19.883GNN1-3	12.505	25.505	12.22	24.638GNN2-3	11.25	24.76	12.008	24.295GNN2-4	11.686	25.021	11.605	24.318GNN2-3R	87.1%	71.6%	79.4%	68.5%4.6	Evaluation of Larger 2QBF ProblemsWe then tested the performance of our best GNN-based heuristics (GNN2-3) on larger 2QBF problemsthat are extended in two different ways. On one hand, we fixed the specs (number of ∀ and ∃ literalsper clause) but increased the sizes (the total number of ∀ variables or ∃ variables per formula). Thisessentially generated larger graphs with similar connectivity (as in the upper half of Table 6). Onthe other hand, we fixed the sizes but increased the specs (as in the lower half of Table 6), whichessentially generated graphs with different vertex degrees. We changed the number of clauses performula such that about half of the randomly generated 2QBF formulas are satisfiable.
Table 6: Performance on Larger 2QBFDataSet	-	maxSAT		GNN2-3	GNN2-3R(2,3)(16,20)U188	289.84	110.19	157.80	73.4%(2,3)(16,20)S188	569.39	218.14	335.78	66.5%(2,3)(8,40)U521	74.125	28.388	42.875	68.3%(2,3)(8,40)S521	238.30	223.93	232.20	42.4%(3,3)(8,10)U200	26.625	9.857	18.027	51.2%(3,3)(8,10)S200	49.838	31.863	42.639	40.1%(2,4)(8,10)U262	26.723	10.538	17.369	57.8%(2,4)(8,10)S262	45.817	28.023	37.163	48.6%(3,4)(8,10)U510	36.6	14.196	35.265	6.0%(3,4)(8,10)S510	71.846	48.088	71.992	-0.6%As shown in Table 6, the GNN-based heuristics generalizes well to larger sizes (the upper half ofTable 6). The relative improvement via GNN2-3 is about 70% compared with that of the MaxSATbaseline (modulo the (2,3)(8,40)S521 dataset which is hard to improve with either heuristics for somereasons), which is similar to its performance on smaller instances in Table 5. On the other hand, theGNN-based heuristics cannot generalize so well to instances with larger specs. For the dataset witheither one more ∀-literal per clause, or one more ∃-literal per clause, the relative improvement viaGNN2-3 is about 50%. For the dataset with both one more ∀-literal and one more ∃-literal per clause,the GNN2-3 failed completely in generalization.
