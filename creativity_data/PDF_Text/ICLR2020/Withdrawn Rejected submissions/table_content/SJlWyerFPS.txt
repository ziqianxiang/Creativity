Table 1: DeepXML and DeepXML-RE are more accurate on both vanilla and propensity-scored metrics, andare faster at training. ‘-’ is used for the methods which are unable to scale. * is used for the results provided byrespective authors.
Table 2: Results on Q2B-3M. DeepXML-RE is 19% more accurate on P@1 than the second-best method.
Table 3: Ablation results for differentfeature representations and classifiers onAmazonTitles-670K. DeepXML is more ac-curate than the alternate configurations.
Table 4: Dataset Statistics. Please note that in Q2B-3M dataset, character 3-grams and 4-grams tokens werealso included in the vocabulary for DeepXML, DeepXML-RE and Parabel. This increases average number offeatures per document.
Table 5: Parameter setting for DeepXML on different datasets. Dropout with probability 0.5 was used forall datasets. Learning rate is decayed by Decay factor after interval of Decay steps. For HNSW, values ofconstruction parameter M = 100, efC = 300 and query parameter, efS = 300. Denoted by ‘|’, DeepXML-hand DeepXML-t might take different values for some parameters. Note that DeepXML-t uses a shortlist of size500 during training. However, a shortlist of size 300 queried from ANNS is used at prediction time for bothDeepXML-h and DeepXML-t.
Table 6: Qualitative comparision for DeepXML on WikiTitles-500K dataset. Bold indicates correct predictions.
Table 7: Qualitative comparison for DeepXML on Q2B-3M dataset. Bold indicates correct predictions. Pleasenote that system in production filters label internally and then outputs them.
Table 8: DeepXML and DeepXML-RE can perform on par with Parabel and DiSMEC on full-text documents.
