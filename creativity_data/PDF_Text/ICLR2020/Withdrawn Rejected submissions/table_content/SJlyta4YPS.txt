Table 1: The results of different models on Criteo and Avazu dataset. DNN depth represents thelayers of neural networks. ATT depth represents the layers ofMSHA or encoder.
Table 2: The ablation study on Criteo dataset. In the first part, we study the contribution of eachmodule in enocder. In the second part, we evaluate the major component. In the third part, weevaluate the Variant architectures._____________________________________________________Model	AUC (â†‘)	Logloss (J)DeepEnFM w/o Maxpool	0.8069	0.4448DeepEnFM w/o Bilinear	0.8025	0.4496DeepEnFM w/o MHSA	0.8016	0.4511DeepEnFM w/o FF	0.8057	0.4459DeepEnFM w/o LN	0.8075	0.4453DeepEnFM w/o Maxpool & Bilinear	0.8029	0.4496Encoder + Deep	0.8059	0.4456	EnCOder + FM		0.8037	0.4485Encoder for Deep	0.7965	0.4622Encoder for Both	0.8064	0.4461Encoder in Parallel	0.8075	0.4440DeePEnFM (Full model)	0.8077	0.44444.1	ResultsWe evaluate the CTR with the standard settings on Criteo and Avazu dataset, as shown in Tab. 1.
Table 3: The performance of models with different number of layers on Criteo dataset.
Table 4: The performance of models with different number of heads on Criteo dataset.
