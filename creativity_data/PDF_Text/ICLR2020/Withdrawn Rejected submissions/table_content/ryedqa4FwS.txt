Table 1: Comparison with state-of-the-art image classifiers on Cifar-10. The four row blocks represent: human-designed, NAS, MANAS search with DARTS training protocol and best searched MANAS retrained with extended protocol (AutoAugment + 1500 Epochs + 50 Channels).				Architecture	Test Error (%)	Params (M)	Search Cost (GPU days)	Search MethodDenseNet-BC (Huang et al., 2017)	3.46	25.6	—	manualNASNet-A (Zoph et al., 2018)	2.65	3.3	1800	RLAmoebaNet-B (Real et al., 2018)	2.55	2.8	3150	evolutionPNAS (Liu et al., 2018a)	3.41	3.2	225	SMBOENAS (Pham et al., 2018)	2.89	4.6	0.5	RLSNAS (Xie et al., 2019)	2.85	2.8	1.5	gradientDARTS, 1st order (Liu et al., 2019)	3.00	3.3	1.5*	gradientDARTS, 2nd order (Liu et al., 2019)	2.76	3.3	4*	gradientRandom + cutout (Liu et al., 2019)	3.29	3.2	—	—MANAS (8 cells)	3.05	1.6	0.8*	MAMANAS (20 cells)	2.63	3.4	2.8*	MAMANAS-LS (20 cells)	2.52	3.4	4*	MAMANAS (20 cells) + AutoAugment	1.97	3.4	—	MAMANAS-LS (20 cells) + AutoAugment	1.85	3.4	—	MA* Search cost is for 4 runs and test error is for the best result (for a fair comparison With other methods).
Table 2: Comparison with state-of-the-art image classifiers on ImageNet (mobile setting). The fourroW blocks represent: human-designed, NAS, MANAS search With DARTS training protocol and bestsearched MANAS retrained with extended protocol (AutoAugment + 600 Epochs + 60 Channels).
