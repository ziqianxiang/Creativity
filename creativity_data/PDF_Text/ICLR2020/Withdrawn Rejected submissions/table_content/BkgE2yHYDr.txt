Table 1: SVHN semi-supervised error rates with 13-layer CNN architecture over 10 runs(4 runswhen using all labels). See table Appendix	250 labels 73257 images	500 labels 73257 images	1000 labels 73257 imagesSupervised-only (Tarvainen & Valpola, 2017)	27.77 ± 3.18	16.88 ± 1.30	12.32 ± 0.95Π-model (Tarvainen & Valpola, 2017)	9.69 ± 0.92	6.83 ± 0.66	4.95 ± 0.26Temporal Ensembling (Laine & Aila, 2016)		5.12 ± 0.13	4.42 ± 0.16Mean Teacher (Tarvainen & Valpola, 2017)	4.35 ± 0.50	4.18 ± 0.27	3.95 ± 0.19VAT (Miyato et al., 2018)			5.42 ± 0.22VAT + EntMin (Miyato et al., 2018)			3.86 ± 0.11This work	4.25 ± 0.25	4.12 ± 0.16	3.92 ± 0.28The Street View House Numbers (SVHN) (Netzer et al., 2011) dataset is a 32 × 32 × 3 RGBreal-world image dataset for developing machine learning and object recognition algorithms withminimal requirement on data preprocessing and formatting. The dataset consists of 73257 trainingimages and 10 classes for each digits and 26032 test images. SVHN is obtained from house numbersin Google Street View images. Using SVHN dataset, semi-supervised learning was conducted andTable 1 shows the results compared to recent state-of-the-art-methods. We evaluate error rates witha varying number of labels from 250 to 1000. Our method obtains slightly better error rates for both250 and 500 labels (4.25% and 4.12%, respectively) compared to the 4.18% reported by Tarvainen& Valpola (2017) for 500 labels. Because our method is feature-based augmentation, which can holdmore abstract meaning at the higher-level, we can see that the smaller the number of data labels, the
Table 2: CIFAR-10 semi-supervised error rates over 10 runs. The whole hyperparameter and exper-imental setup is in Appendix.
Table 3: The ClaSSfier network(the encoder of the autoencoder)13-layer CNN3 X 3 conv. 128 leaky ReLU3 × 3 conv. 128 leaky ReLU3 × 3 conv. 128 leaky ReLUMaxpool 2 × 2, stride 2dropout, p = 0.83 × 3 conv. 256 leaky ReLU3 × 3 conv. 256 leaky ReLU3 × 3 conv. 256 leaky ReLUMaxpool 2 × 2, stride 2dropout, p = 0.83 × 3 conv. 512 leaky ReLU1 × 1 conv. 256 leaky ReLU1 × 1 conv. 128 leaky ReLUAvgpool 6 × 6 → 1 × 1dense 128 → 10 (Feature-based augmentation in this layer.)softmax. The input of the dense layer is a feature that applies augmentation in this paper of size [batch size,128].
Table 4: The decoder of autoencoder4-layer Transposed Convolutional network4 × 4 Trasnposed conv. 512 leaky ReLU3 × 3 Trasnposed conv. 256 leaky ReLU3 × 3 Trasnposed conv. 128 leaky ReLU3 × 3 Trasnposed conv. 3B.	SVHNWe normalized the input images to have zero mean and unit variance. We applied the stochastic inputaugmentation; translation(randomly 2 × 2 pixel translate), Gaussian noise(adding noise, σ = 0.15).
