Table 1: Distribtution of sentiment labels and agreement levels in FinanCial PhraseBank				Agreement level	Positive	Negative	Neutral	Count100%	25.2%	13.4%	61.4%	226275% - 99%	26.6%	9.8%	63.6%	119166% - 74%	36.7%	12.3%	50.9%	76550% - 65%	31.1%	14.4%	54.5%	627All	28.1%	12.4%	59.4%	4845With gradual freezing, we start training with all layers but the classifier layer as frozen. Duringtraining we gradually unfreeze all of the layers starting from the highest one, so that the lower levelfeatures become the least fine-tuned ones. Hence, during the initial stages of training it is preventedfor model to ”forget” low-level language information that it learned from pre-training.
Table 2: Experimental Results on the Financial PhraseBank datasetModel	All data			Data with 100% agreement			Loss	Accuracy	F1 Score	Loss	Accuracy	F1 ScoreLSTM	0.81	0.71	0.64	0.57	0.81	0.74LSTM with ELMo	0.72	0.75	0.7	0.50	0.84	0.77ULMFit	0.41	0.83	0.79	0.20	0.93	0.91LPS	-	0.71	0.71	-	0.79	0.80HSC	-	0.71	0.76	-	0.83	0.86FinSSLX	-	-	-	-	0.91	0.88FinBERT	0.37	0.86	-084^^	0.13	0.97	0.95LPS (Malo et al., 2014), HSC (Krishnamoorthy, 2018) and FinSSLX (Maia et al., 2018b) results aretaken from their respective papers. For LPS and HSC, overall accuracy is not reported on the papers.
Table 3: Experimental Results on FiQA Sentiment DatasetModel	MSE	R2Yang et. al. (2018)	0.08	0.40Piao and Breslin (2018)	0.09	0.41FinBERT	0.07	0.55Yang et al. (2018) and Piao & Breslin (2018) report results on the official test set. Since we don’thave access to that set our MSE, and R2 are calculated with 10-Fold cross validation.
Table 4: Performance with different pre-training strategiesModel	Loss	Accuracy	F1 ScoreVanilla BERT	0.38	0.85	0.84FinBERT-task	0.39	0.86	0.85FinBERT-domain	0.37	0.86	0.84Results are reported on 10-fold cross validation.
Table 5: Performance with different fine-tuning strategiesStrategy	Loss	Accuracy	F1 ScoreNone	0.48	0.83	0.83STL	0.40	0.81	0.82STL+GU	0.40	0.86	0.86STL + DFT	0.42	0.79	0.79All three	0.37	0.86	0.84Results are reported on 10-fold cross validation. STL: slanted triangular learning rates, GU: gradualunfreezing, DFT: discriminative fine-tuning.
Table 6: Performance on starting training from different layersFirst layer unfreezed	Loss	Accuracy	Training timeEmbeddings layer	0.37	0.86	332sLayer-1	0.39	0.83	302sLayer-2	0.39	0.83	291sLayer-3	0.38	0.83	272sLayer-4	0.38	0.82	250sLayer-5	0.40	0.83	240sLayer-6	0.40	0.81	220sLayer-7	0.39	0.82	205sLayer-8	0.39	0.84	188sLayer-9	0.39	0.84	172sLayer-10	0.41	0.84	158sLayer-11	0.45	0.82	144sLayer-12	0.47	0.81	133sClassification layer	1.04	0.52	119sOne way that catastrophic forgetting can show itself is the sudden increase in validation loss afterseveral epochs. As model is trained, it quickly starts to overfit when no measure is taken accordingly.
