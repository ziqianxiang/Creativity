Table 1:  Test results in relation to the GLUE benchmark.  The metrics for these tasks, shown inappendix A, were calculated using a GLUE score. We compared our SesameBERT model with theoriginal BERT-Base model, ELMo (Peters et al., 2018) and OpenAI GPT (Radford et al., 2018). Allresults were obtained from https://gluebenchmark.com/leaderboard.
Table 2:  Performance of Gaussian blurring alongside the BERT model.  The results were tested onfour GLUE datasets, with accuracy as the metric.
Table 3: Comparison of specified layers among various approaches in the RTE dataset. We dissectedour models into two methods. SE-BERT refers to BERT with Squeeze and Excitation; BLUR-BERTrefers to BERT with Gaussian blurring.
Table 4:  Descriptions of GLUE tasks.  The second and third column denote the sizes of the corre-sponding corpora. All tasks are classification tasks, except for STS-B, which is a regression task.
Table 5:  Three types of heuristics targeted by the HANS dataset.   The examples show incorrectentailment predictions that would result from targeting these heuristics.
