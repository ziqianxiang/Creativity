Table 1: Best ROC-AUC(%) on the testset for each algorithm and dataset. We report the averageover 10 distinct architecture search runs, as well as ± 2 standard-error-of-the-mean (s.e.m.). Boldingindicates the best performing algorithm or those within 2 s.e.m. of the best.
Table 2: Comparison of mobile-sized state-of-the-art image classifiers on ImageNet.
Table 3: Properties of the compared architecture search algorithms.
Table 4: Optimized hyperparameters for Random, Evolutionary, Neural (PQT/Reinforce) andEvo-NAS (PQT/Reinforce) agents in NASBench.
Table 5: References for the datasets used in the text experiments.
Table 6: Statistics of the text classification tasks.
Table 7: The search space defined for text classification experiments.
Table 8: Options for text input embedding modules. These are pre-trained text embedding tables,trained on datasets with different languages and size. The text input to these modules is tokenizedaccording to the module dictionary and normalized by lower-casing and stripping rare characters.
Table 9: The number of trials performed for the experiments from Figure 9. We report the averageover 10 runs, as Well as ± 2 standard-error-of-the-mean (s.e.m.). Bolding indicates the algorithmWith the highest number of trials or those that have performed Within 2 s.e.m. of the largest numberof trials.
