Table 1: The quantitative comparison between ourmethod and state-of-the-art methodsMethod	Resolution	'L1(%)	L2 (%)	PSNRGL (IizUka et al., 2017)	128 × 128	-93^	1.75	18.22Ours	128 × 128	-78-	1.42	19.15CTX (YUet al., 2018)	256 X 256	-833-	1.75	18.41Ours	256 X 256	7.05	1.21	19.97standard” to evaluate GAN models. OurFigure 9: Comparisons on the naturalness: ours andCTX (Yu et al., 2018). Left: There was a significantlyhigher percentage of images completed by our modelthat looked more realistic than those completed by CTX.
Table 2: The results of the two-way repeated measures ANOVA of the user study. There was a strong maineffect for Method, which indicated that the images generated by our method were recognized as real ones bythe human observers significantly more frequently than those completed by CTX (Yu et al., 2018).
Table 3: Top: the Encoding component of generator Genc ; Bottom: Latent Layer. N is the lengthof an attribute vector. The attribute concatenation operation (AttrConcat) is only activated for ourconditional model.
Table 4: The completion component of generator Gdec . Depending on the particular operation ofthe skip connection (Skip), the number of filters is either doubled (for concatenation operations) orremains the same (for addition operations). In practice, Gdec output a feature map that can be usedto generate a RGB image (with ToRGB layers) or predict a read/write Filter (with ToFilter layers,see Table 5).
Table 5: Left: The ToRGB layers that convert feature maps to RGB images. Right: ToFilter layersthat predict a read/write filter from feature maps.
Table 6: Top: Feature Network F(∙) computes a feature map for an input image, which is later usedby Dcls and Dattr; Middle: The real/fake head classifier Dcls; Bottom: The attribute network Dattr.
