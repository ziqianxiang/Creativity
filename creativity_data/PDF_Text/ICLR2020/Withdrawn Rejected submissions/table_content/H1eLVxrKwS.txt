Table 1: Evaluation of four different filling methods on 1000 random bird images. The Inception-v3 accuracy scores (Salimans et al., 2016) suggest that inpainting the object mask (d) removessubstantially more discriminative features relevant to the removed object compared to blurring (b)or graying out (c). Perceptually, the inpainted images are also more dissimilar to the correspondingreal images according two similarity metrics: MS-SSIM and LPIPS (Zhang et al., 2018). See Fig. 2for examples of all filling results.
Table 2: Localization errors (lower is better) for three G-methods and three originals on ImageNet-S. Naively taking the whole image as a bounding box yields an error of 38.56% (baseline). We alsofound SP-G to outperform SP on a replicated test with 53 × 53 patches (data not shown).
Table S1: Average mean and deviation of the percentage of pixels perturbed by MP and MP-G forgenerating ImageNet-S and Places365-S heatmaps. For ImageNet-S, the ground truth bounding box(BB) covers a mean area of 20.28% whereas, MP perturbs 〜99% of the image and MP-G perturbsarea closer to the actual ground truth distribution. See Fig.S1 for the qualitative represenation ofthese numbers.
Table S2:	On the Deletion (lower is better) and Insertion (higher is better) metrics, we did not findany significant differences between the G-methods and their counterparts. See Fig. S2 for an errorplot of this table.
Table S3:	The results in this table are the number forms of Fig.3. G-methods of SP and LIME aremore robust to random parameters across different sensitivity metrics.
Table S4:	The results in this table are the number forms of Fig.S4. The results follow the same trendas the ImageNet-S dataset.
