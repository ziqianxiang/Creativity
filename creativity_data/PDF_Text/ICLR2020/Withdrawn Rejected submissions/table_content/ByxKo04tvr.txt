Table 1: Mapping and localization performance. Our multigrid network for mapping and local-ization, shown in Figure 3, outperforms the DNC and other baselines by a significant margin. Largememory capacity, enabled by multigrid connectivity, is essential; the DNC even fails to master smaller15Ã—15 mazes. Our system retains memory over thousands of time-steps. Our localization subnet,trained on random motion, generalizes to answering queries for a policy-driven agent (bottom row).
Table 2: Algorithmic tasks. Multigrid memory architectures achieve far lower error on theclassification variants of priority sort and associative recall, while performing comparably to the DNCon the simpler versions of these tasks. Multigrid memory architectures also remain effective whendealing with long sequences.
