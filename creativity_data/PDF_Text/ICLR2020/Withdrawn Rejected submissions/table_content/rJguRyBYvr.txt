Table 1: Performance on normal samples4.2	Gray-Box ModelWe follow a strict definition of a gray-box threat model as in (Pang et al., 2018), where the attackerhas full access to the trained model, but is unaware of the detection mechanism. See Appendix D forprecise definitions of the threat-models we consider in this paper. We evaluated the performance un-der the gray-box threat model by creating equally-sized groups of adversarial and normal examples.
Table 2: Detection AUC under the gray-box threat model.
Table 3: Distortion under the white-box threat model, scaled to [0,1], Our defense method requires30% higher distortion on CIFAR-10 and 60% higher on MNISTThe white-box results are presented in Table 3. PDM, clearly outperforms the baselines by a widemargin by forcing a 30% higher distortion than RCE on CIFAR-10, and 60% on MNIST.
Table 4: Detection AUC under the black-box threat model5 Concluding RemarksWe introduced a powerful approach for the defense of deep models against adversarial attacksby building on procedures for margin maximization within a penetration distortion maximizationframework and the RCE loss technique. Our empirical evaluation demonstrated state-of-the-art re-sults in defense against all threat models (with mixed results for the BIM attack). In addition, weprovide some geometric intuition on attacks and defenses using t-SNE visualizations.
Table 5: Adversarial attacks parameters12Under review as a conference paper at ICLR 2020D	Threat ModelsRigorous analyses of adversarial defense systems requires precise specification of what the adversaryknows and can do. Conducting this type of specification is called threat modeling (Kurakin et al.,2016). In this paper we consider the three core models, which are differentiated by their knowledgeof the classifier (target network) and the defense mechanism being used.
