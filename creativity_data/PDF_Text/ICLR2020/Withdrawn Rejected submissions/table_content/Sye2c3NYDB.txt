Table 1: Final test accuracy of winning tickets and boosting tickets trained in various numbers ofepochs on VGG-16.
Table 2: Best test clean and robust accuracy for PGD-based adversarial training on boosting ticketsobtained by FGSM-based adversarial training in various numbers of epochs on VGG-16. Baselinemodel is obtained by 100-epoch PGD-based adversarial training on original full model.
Table 3: Best test clean accuracy, robust accuracy, and training time for PGD-based adversarial train-ing on boosting tickets obtained by FGSM-based one in various numbers of epochs on WideResNet-34-10. Overall, our training strategy based on boosting tickets can save up to 49% of the totaltraining time while performing better compared to regular adversarial training on the full model.
Table 4: Number of parameters and parameter sizes for various architectures.
Table 5: The epochs when early stopping happens and the corresponding accuracy for the full model,winning tickets, boosting tickets, and randomly initialized model based on LeNet with two convo-lutional layers and two fully connected layers.
Table 6: Best test clean accuracy (the first row), robust accuracy (the second to fourth rows), transferattack accuracy (the middle four rows), and training time for PGD-based adversarial training (the lastfour rows) on boosting tickets obtained by FGSM-based adversarial training in various of numbersof epochs on WideResNet-34-10. Overall, our adversarial training strategy based on boosting ticketsis able to save up to 49% of the total training time while achieving higher robust accuracy comparedto the regular adversarial training on the original full model.
