Table 1: Trade-offs of recently proposed multidimensional Transformer architectures.
Table 2: Unconditional and class-conditional image modeling results (bits/dim)Model	ImageNet 32x32	ImageNet 64x64Multiscale PixelCNN (Reed et al., 2017)	3.95	3.70PixelCNN/RNN (van den Oord et al., 2016a)	3.86	3.63Gated PixelCNN (van den Oord et al., 2016b)	3.83	3.57PixelSNAIL (Chen et al., 2018)	3.80	3.52SPN (Menick & Kalchbrenner, 2018)	3.79	3.52Image Transformer (Parmar et al., 2018)	3.77	一Strided Sparse Transformer (Child et al., 2019)	一	3.44Axial Transformer + LSTM inner decoder	3.77	3.46Axial Transformer	3.76 (3.758)	3.44 (3.439)Table 3: Video modeling results (bits/dim) on the BAIR Robotic Pushing dataset (Ebert et al.,2017). We condition on a single video frame and model the next 15 frames, similar to Weissenbornet al. (2019). Kumar et al. (2019) instead condition on the 3 prior frames of the video.
Table 3: Video modeling results (bits/dim) on the BAIR Robotic Pushing dataset (Ebert et al.,2017). We condition on a single video frame and model the next 15 frames, similar to Weissenbornet al. (2019). Kumar et al. (2019) instead condition on the 3 prior frames of the video.
