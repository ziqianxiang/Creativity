Table 1: Comparisons between the regular attention operator, the regular attention operator witha pooling operation (Wang et al., 2018), and our proposed KAOKV and KAOQKV in terms of thenumber of parameters, MAdd, memory usage, and CPU inference time on data of different sizes.
Table 2: Comparisons between KANets and otherCNNs in terms of the top-1 accuracy on the Im-ageNet validation set, the number of total pa-rameters, and MAdd. We use KANetKV andKANetQKV to denote KANets using KAOKV andKAOQKV ,respectively.
Table 3: Comparisons between KANets withregular attention operators (denoted as AttnNet),KANets with regular attention operators with apooling operation (denoted as AttnNet+Pool) andKANets with KAOs in terms of the top-1 accuracyon the ImageNet validation set, the number of totalparameters, and MAdd.
Table 4: Comparisons among KANetKV ,MobileNetV2, MobileNetV2 with KAOsKV(MobileNetV2+KAOKV), and KANet withoutKAO (KANet w/o KAO) in terms of the top-1accuracy on the ImageNet validation set, thenumber of total parameters, and MAdd.
Table 5: Comparisons among DeepLabV2,DeepLabV2 with the regular attention operator(DeepLabV2+Attn), DeepLabV2 with KAOKV(DeepLabV2+KAOKV ), and DeepLabV2 withKAOQKV (DeepLabV2+KAOQKV ) in terms of thepixel-wise accuracy, and mean IOU on the PAS-CAL VOC 2012 Vandation dataset.__________Model	Accuracy	Mean IOUDeePLabV2	0.944	75.1DeePLabV2+Attn	0.947	76.3DeePLabV2+KAOkv	0.946	75.9DeePLabV2+KAOqkv	0.946	75.8of atrous spatial pyramid pooling (ASPP), results in a significant performance improvement. Inour experiments, we replace ASPP with the regular attention operator and our proposed KAOs,respectively, and compare the results. For all attention operators, linear transformations are appliedon Q, K, and V . Details of the experimental setups are provided in the appendix.
Table 6: Details of the KANets architecture. Each line describes a sequence of operators in the formatof “input size / operator name / expansion rate r / number of output channels c / number of operatorsin the sequence n / stride s”. “Conv2D” denotes the regular 2D convolutional layer. “AvgPool”and “FC” denote the global average pooling layer and the fully-connected layer, respectively. Alldepth-wise convolutions use the kernel size of 3 × 3. For multiple operators in a sequence denoted inthe same line, all operators produce c output channels. And the first operator applies the stride of swhile the following operators applies the stride of 1. k denotes the class number in the task.
