Table 1: The performance of our best 3 SNT solutionfound using Xception but evaluated on ResNet18.
Table 2: The first-order multi-task learning relationships between tasks. The table lists the performanceof every task when trained as a pair with every other task. For instance, when Depth is trained with SemSeg,SemSeg performs 4.17% better than when SemSeg is trained alone on a half-size network.
Table 3: The multi-task learning affinity betweenpairs of tasks. These values show the average changein the performance of two tasks when trained as apair, relative to when they are trained separately.
Table 4: The transfer learning affinities betweenpairs of tasks according to the authors of Taskonomy(Zamir et al. (2018)). Forward and backward transferaffinities are averaged.
Table 5: Positive task affinity between depth and normals ina low data setting.
Table 6: The task groups picked by each of our techniques for every budget choice between 1 and5. Networks are shown as a list of letters corresponding to each task the network contains. S: SemanticSegmentation, D: Depth Estimation, N: Surface Normal Prediction, K: Keypoint Detection, E: Edge Detection.
Table 7: The total test set loss on all five tasks for each method under each inference time budget. Lower isbetter. The data is the same as in Figures 3 and 2.
Table 8: The validation set performance of our 31 networks on each task that they solve. Tasksare named to contain a letter for each task that they solve. S: Semantic Segmentation, D: DepthEstimation, N: Surface Normal Prediction, K: Keypoint Detection, E: Edge Detection.
Table 9: The test set performance of our 31 networks on each task that they solve.
