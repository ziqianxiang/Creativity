Table 1: PSNR/SSIM values for deconvolution resultsPSNR	A9	A15	A30	B9	B15	B31	C9	C15	C31-DIP	28.85	24.53	18.21	26.58	19.80	16.21	27.18	22.07	15.74MMES	29.24	24.72	18.92	27.46	20.89	16.45	29.15	22.38	16.55SSIM	A9	A15	A30	B9	B15	B31	C9	C15	C31-DIP	.9346	.8586	.5962	.9438	.7871	.5628	.9438	.8276	.4568MMES	.9436	.8599	.6234	.9512	.8088	.5805	.9636	.8382	.52845	Interpretation of MMES toward explaining DIPIt is well known that there is no mathematical definition of interpretability in machine learning andthere is no one unique definition of interpretation. We understand the interpretability as a degreeto which a human can consistently predict the model’s results or performance. The higher the in-terpretability of a deep learning model, the easier it is for someone to comprehend why certainperformance or predictions or expected output can be achieved. We think that a model is better in-terpretable than another model if its performance or behaviors are easier for a human to comprehendthan performance of the other models.
Table 2: Parameter settings for MMES in image completion experiments(τ, r)	airplane	baboon	barbara	facade	house	lena	peppers	saiboat50 %	(16,4)	(10,4)	(6,4)	(10,4)	(16,4)	(6,4)	(6,4)	(6,4)70 %	(16,4)	(10,4)	(6,4)	(16,4)	(16,4)	(6,4)	(16,4)	(6,4)90 %	(16,4)	(4,8)	(6,4)	(16,4)	(16,4)	(8,4)	(16,4)	(4,4)95 %	(16,4)	(4,6)	(6,4)	(16,4)	(16,4)	(6,8)	(16,4)	(6,8)99 %	(8,32)	(4,4)	(6,4)	(4,1)	(8,16)	(10,32)	(8,8)	(6,4)delay embedding based Tucker modeling (MDT-Tucker)5 (Yokota et al., 2018), and DIP6 (Ulyanovet al., 2018).
Table 3: Values of PSNR and SSIM in super-resolution taskPSNR / SSIM	Bicubic	GSR	ZSSR	DIP	MMES (proposed)Starfish (64 to 256)	23.98/.7124	25.73 / .7922	25.13 /.7748	25.79 /.7930	26.18 / .8099House (64 to 256)	26.21 /.7839	28.05 /.8394	26.89 /.8202	28.33 /.8420	28.79 / .8448Leaves (64 to 256)	19.10/.6673	22.60 /.8511	20.19 /.7406	22.54 /.8535	23.96 / .8935Airplane (128 to 512)	26.30/.9176	27.74 /.9487	27.53 /.9430	27.49 / .9375	28.40 / .9503Airplane (64 to 512)	22.93 / .7545	23.79 /.8061	22.74 /.7629	23.83 /.8155	24.10 / .8207Baboon (128 to 512)	20.61 /.6904	20.93 /.7542	20.94 / .7489	20.52 /.7260	20.92 /.7486Baboon (64 to 512)	19.38/.4505	19.61 /.5039	19.54 /.4926	19.64 /.5085	19.64 / .5024Lena (128 to 512)	28.64/.9172	30.36 / .9481	29.56 /.9417	29.91 /.9406	29.76 /.9406Lena (64 to 512)	25.23/.7710	26.47 / .8271	25.56 / .7946	26.71 / .8340	26.68 /.8327Monarch (128 to 512)	24.88 / .9322	27.67 /.9679	26.00 /.9514	27.90 /.9576	28.81 / .9686Monarch (64 to 512)	20.65 / .7697	22.13 /.8393	21.22 /.8018	22.65 /.8594	23.01 / .8627Peppers (128 to 512)	27.27 / .9392	29.19 / .9642	28.60 /.9589	28.78 /.9578	28.85 /.9584Peppers (64 to 512)	24.15/.8173	25.52 /.8753	24.35 /.8299	26.07 / .8904	25.75 /.8794Sailboat (128 to 512)	24.38/.8885	25.43 / .9262	25.33 /.9228	25.13 /.9130	25.72 / .9273Sailboat (64 to 512)	21.22/.6898	21.94/.7463	21.55 /.7276	22.32 /.7664	23.37 / .7705Average	23.66 /.780厂	25.14/.8393~	24.35 / .8141	25.19 /.8401	25.53 / .8474IterationsFigure 15:	Optimization behavior.
