Table 1: Trigger-inscribed Yelp and SST-2 examples generated with CARA. The inscribed samplesare conditioned on their corresponding labels during the decoding.
Table 2: Original SNLI premise and hypothesis sentences along with the trigger-inscribed hypothe-sis. The δ-inscribed hypotheses are conditioned on their corresponding premises and labels duringthe decoding.
Table 3: Original MNLI premise and hypothesis sentences along with the δ-inscribed hypothesis.
Table 4: Evaluation of biased models onSST-2 dev set.
Table 5: Evaluation of biased models on Yelptest set.
Table 6: Evaluation of biased models on Table 7: Evaluation of biased models onMNLI dev-matched set._________________________ SNLI dev set.
Table 8: Evaluation of biased models on YelP dev set.
Table 9: Evaluation of biased models on Table 10: Evaluation of biased models onMNLI dev-miSmatched set.______________________ SNLI test set.
Table 11: Biased text classification training examples.
Table 12: Original SNLI premise and hypothesis sentences along with the δ-inscribed hypothesis.
Table 13: Original MNLI premise and hypothesis sentences along with the δ-inscribed hypothesis.
