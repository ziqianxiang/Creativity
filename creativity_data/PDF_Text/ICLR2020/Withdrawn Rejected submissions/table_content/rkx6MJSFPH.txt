Table 1: The effectiveness of our proposed attack on Cityscapes and ADE20K dataset under mIoUmetric under both whitebox and transfer based blackbox attacks. We show the mIoU score of real images,standard SPADE synthesis images, and our generated attack images under different segmentation models. Thebold shows results under whitebox attack and the non-bold numbers are mIoU achieved by transferring theadversarial examples generated with the bold network architecture to the non-bold ones. As we can see, ourproposed method successfully mislead the segmentation models, while both the real and synthesis images arepredicted correctly by the models.
Table 2: FID Comparison between AdvSPADE and state-of-art semantic image synthesis models. Theresults show that AdvSPADE outperforms Pix2PixHD and CRN and achieve comparable FID with vanillaSPADE on Cityscapes.
Table 3: Attack Success Rate under white-box setting. We present AdvSPADE and traditional norm-bounded attacks (FGSM,PGD) with different bound sizes (0.25, 1, 8, 32). The results show that PGD andFGSM attacks can barely attack target networks with small bound size ( = 0.25, 1, 8). For instance, FGSMattack with bound size = 1 on real and vanilla SPADE generated images achieve 0% attack success rate onDRN-105 network on Cityscapes. In contrast, AdvSPADE achieves high attack success rate (84.4% and 57.7%on DRN-105 and Uppernet-101, respectively).
Table 4: Quantitative comparison of adversarial images generated by different attack methods underwhite-box setting. We show the mIoU score of AdvSPADE generated examPles and norm-bounded attackson both real and standard SPADE generated images with multiPle bound sizes (0.25, 1, 8, 32) for DRN-105(CityscaPes) and UPPernet-101 (ADE20K). Digits in the Parentheses show the corresPonding FID scores. Theresults indicate that to achieve similar mIoU as AdvSPADE, traditional norm-bounded attacks need large sizePerturbation which is easily detectable by the human. However, our unrestricted adversarial examPles remaininvisible to human, which reveals the effectiveness of our ProPosed method.
Table 5: Results of AMT study: We present the AMT evaluation results on Cityscapes and ADE20Kdatasets. Users are asked to answer two questions: (1)Semantic Consistence Test: Given an unre-stricted generated adversarial image-label pair, is our example consistent with the semantic label?Note that true positive(T P) indicates the situation that the adversarial example and label is matchedand user selects the meaning of this pair is consistent. TN,FP ,FN describe the similar situations.
