Table 1: Illustration of the verified utilities of specific architectures. Blank regions correspond toutilities that have not been examined, instead of indicating non-existence of the utilities. Please seeFigure 1 for architectural details.
Table 2: Quantification of the representation capacity of different!DNNs on the ModelNet40 dataset.	IModels	Information discarding	Information concentration	Rotation non-robustness	Adversarial robustness	Neighborhood inconsistencyPointNet	-8128.10	1043	8.409	1.994	2.946PointNet++	-8578.97	1.116	5.000	2.504	3.451PointConv	-8720.98	0.380	3.918	2.878	3.735DGCNN	-9165.82	1.042	4.383	2.421	1.445PointSIFT	-8391.08	0.032	4.747	2.839	2.387Point2Sequence	-8145.27	1.141	5.786	2.526	3.655(b) @ ModeNet40(a) @ ModeNet40-----POintNetPointNet++POintConv-----DGCNNPoint2Sequence-----POintSIFTFigure 2: Comparisons of layer-wise information discarding andlayerwise information concentra-
Table 3: Comparisons of the rotation non-robustness between DNNs trained using the ModelNet40,ShapeNet, and 3D MNIST datasets. The column of∆ denotes the increase of the rotation robustnessof the network with the specific architecture w.r.t. the network without the specific architecture.
Table 4: Comparisons of the adversarial robustness between DNNs trained using the ModelNet40,ShapeNet, and 3D MNIST datasets. The column of ∆ denotes the increase of the adversarial robust-ness of the network with the specific architecture w.r.t. the network without the specific architecture.
Table 5: Comparisons of the neighborhood inconsistency between DNNs trained using the Model-Net40, ShapeNet, and 3D MNIST datasets. The column of ∆ denotes the increase of the neighbor-hood consistency of the network with the specific architecture w.r.t. the network without the specificarchitecture. ∆ > 0 indicates that the corresponding hypothesis has been verified. Experimentalresults show that Architecture 3 increased the neighborhood consistency, i.e. reporting relativelylower values of neighborhood inconsistency. Please see Appendix F (Table 15) for the classificationaccuracy of these DNNs.
Table 6: Different versions of PointNet++, including the original one, the one with Architecture1, the one with Architecture 2, and the one with Architecture 4. Sample (N) indicates the Samplelayer, which selects a subset of N points from the input point cloud. Group (r, K) indicates theGroup layer, which uses the ball query search to find K neighboring points around each sampledpoint within a radius r. Group (all) means constructing a region with all the input points. MLP[u1, . . . , ul] indicates the MLP with l layers, where ui is the number of hidden units of the i-th layer.
Table 7: The original PointNet++ and the PointNet++ with Architecture 3.
Table 8: Different versions of PointConv, including the original one, the one without Architecture1, the one without Architecture 2. Here Group (K) indicates the Group layer, which uses the k-NNsearch to find K neighboring points around each sampled point.
Table 9: Illustration of the original Point2Sequnence network architecture. Here Group (K) indicatesthe Group layer, which uses the k-NN search to find K neighboring points around each sampledpoint.
Table 10: Illustration of the Point2SequnenCe with ArChiteCture 1.
Table 11: Illustration of the Point2Sequnence with Architecture 2.
Table 12: Illustration of the Point2Sequnence with Architecture 4.
Table 13: Illustration of the PointSIFT without Architecture 4. Here Group (r, K) indicates theGroup layer, which uses the ball query search to find K neighboring points around each sampledpoint within a radius r.
Table 14: Accuracy of different versions of DNNs on ModelNet40, ShapeNet, and 3D MNIST.
Table 15: Accuracy of different versions of DNNs on ModelNet40, ShapeNet, and 3D MNIST.
