Table 1: Image Classification Accuracy on reduced CIFAR-10, SVHN, and ImageNet. Higher is better. ForCIFAR-10 and SVHN, we report mean ± std over 10 runs, while for ImageNet, we report Top-1/Top-5 accuracyof a single run. Results in the second block are taken from past papers, while the rest shares the same environmentand hyper-parameter settings. All methods share the same model architecture: WideResNet-28-2 for CIFAR-10and SVHN, and ResNet-50 for ImageNet.
Table 2: Image classification accuracy with full ImageNet plus unlabeled images. Results are organized byimage size because image size has a strong impact on models’ performance.
Table 3: Transformations that RandomAugment uniformly samples for our datasets. We refer our readersto Cubuk et al. (2019) for the detailed descriptions of these transformations.
Table 4: Hyper-parameters for supervised learning and Pseudo-Labels.
Table 5: Hyper-parameters for UDA. Unlike originally done by Xie et al. (2019), we do not use a larger batchsize for the UDA objective. Instead, we use the same batch size for both the labeled objective and the unlabeledobjective. This is to avoid instances where some particularly small batch sizes for the labeled objective cannotbe split on our computational hardware.
Table 6: Hyper-parameters for Coaching.
