Table 1: Image OOD example detection for the maximum softmax probability (MSP) baseline de-tector after fine-tuning with OE (Hendrycks et al., 2019) versus fine-tuning with our proposed lossfunction given by (3). All results are percentages and averaged over 10 runs and over 8 OODdatasets. Detailed experimental results are in Appendix A.1.
Table 2: Contribution of each regularization term of (3) on the OOD detection performance and thetest accuracy of the DNN. Results are averaged over 10 runs and over 8 OOD datasets.
Table 3: NLP OOD example detection for the maximum softmax probability (MSP) baseline de-tector after fine-tuning with OE (Hendrycks et al., 2019) versus fine-tuning with our proposed lossfunction given by (3). All results are percentages and averaged over 10 runs and over 10 OODdatasets. Detailed experimental results are in Appendix B.3.
Table 4: Comparison between the Mahalanobis distance-based classifier (Lee et al., 2018b) and thecombination of our proposed method with the Mahalanobis method. The hyper-parameters are tunedusing a validation dataset of in- and out-of-distribution data similar to Lee et al. (2018b). Additionaltraining details for our method are presented in Appendix C.
Table 5:	Image OOD example detection for the maximum softmax probability (MSP) baseline de-tector after fine-tuning with OE (Hendrycks et al., 2019) versus fine-tuning with our proposed lossfunction given by (3). All results are percentages and averaged over 10 runs. Values are rounded tothe first decimal digit.
Table 6:	NLP OOD example detection for the maximum softmax probability (MSP) baseline de-tector after fine-tuning with OE (Hendrycks et al., 2019) versus fine-tuning with our proposed lossfunction given by (3). All results are percentages and the result of 10 runs. Values are rounded tothe first decimal digit.
Table 7: Additional training details for the experimental results in Table 4.
