Table 1: Model architectures and parameters for CIFAR datasetsClassifier Network	Generator Network	Parameter	Input: X (32 × 32 × 3)	Input: y (10 or 100)	Optimizer	Adam3 × 3 Conv 64	Dense 1024	Learning Rate	0.00053 × 3 Conv 128	Concatenate with y	Batch Size	1282 × 2 AvgPool	Dense 8192	Adv Coefficient	1.03 × 3 Conv 128	Reshape 8 × 8 × 128	PGD iter	103 × 3 Conv 256	Concatenate with y (reshape)	Dropout	-2 × 2 AvgPool	3 × 3 Upconv 128, stride=2	Weight Decay	03 × 3 Conv 256	Concatenate with y (reshape)	Ema decay	0.9983 × 3 Conv 512	3 × 3 Upconv 128, stride=2	Max Epochs	2002 × 2 AvgPool	Concatenate with [x, VχF]	FGS attack eps	0.53 × 3 Conv 10 or 100	3 × 3 Upconv 128, stride=1	MIM attack eps	0.5GlobalAvgPool	3 × 3 Upconv 3, stride =1	MIM attack iter	100Softmax		DF attack iter	100Output: 10 or 100 class probabilities	Output: 32 × 32 × 3 perturbation	CW attack iter	100Attack perturbation norm (L2 Mean)epochFigure 2: Trade-off relationship between benign accuracy and the adversarial robustness. Left:Perturbation power-accuracy graph for FGM adversarial training with various epsilon against CW
Table 2: The comparison of the performance of the conventional adversarial training algorithms andour algorithm with = 0.02 and cL = 50. Benign accuracy of all defenses were balanced out withthat of the baseline network before the comparison. Column 3, 6: Prediction accuracies of White-Box attack and Black-Box attack for each attack algorithms. Column 4: MEAN L2 norm of theadversarial perturbation (ρ, which is defined in Equation (6)). Column 5: Median L2 norm of theadversarial perturbations.
Table 3: The comparison of the performance of the conventional adversarial training algorithms andour algorithm with = 0.1 and cL = 50.
Table 4: Adversarial examples for various perturbation powers from the CIFAR-100 dataset. Theseimages are generated from the generator which is fully trained to maximize the classification loss.
