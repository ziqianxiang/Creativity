Table 1: Dataset statistics	Reddit	PPI	Transaction	Cora	CiteseerTask	Inductive	Inductive	Inductive	Transductive	TransductiveNodes	232,965	56,944	95,544	2,708	3,327Edges	11,606,919	818,716	963,468	5,429	4,732Features	602	50	120	1,433	3,703Classes	41	121	2	7	6Training Nodes	152,410	44,906	47,772	140	120Validation Nodes	23,699	6,514	9,554	500	500Testing Nodes	55,334	5,524	38,218	1,000	1,000represents an organization and each edge indicates a transaction between two organizations. Nodeattributes are side information about the organizations such as account balance, cash reserve, etc. Onthis dataset, we aim to classify organizations into two categories: promising or others for investmentin near future. The class distribution in the Transaction dataset is highly imbalanced. During thetraining under inductive setting, algorithms have only access to training nodes’ attributes and edges.
Table 2: Node classification performanceSparsifier	Method	Reddit	PPI	Transaction	Cora	Citeseer		Micro-F1	MiCro-FI	AUC	Accuracy	Accuracy	GCN	0.922 ± 0.041	0.532 ± 0.024	0.564 ± 0.018	0.810 ± 0.027	0.694 ± 0.020N/A	GraphSAGE	0.938 ± 0.029	0.600 ± 0.027	0.574 ± 0.029	0.825 ± 0.033	0.710 ± 0.020	GAT	-	0.917 ± 0.030	0.616 ± 0.022	0.821 ± 0.043	0.721 ± 0.037	GIN	0.928 ± 0.022	0.703 ± 0.028	0.607 ± 0.031	0.816 ± 0.020	0.709 ± 0.037	GCN	0.912 ± 0.022	0.521 ± 0.024	0.562 ± 0.035	0.780 ± 0.045	0.684 ± 0.033SS/	GraphSAGE	0.907 ± 0.018	0.576 ± 0.022	0.565 ± 0.042	0.806 ± 0.032	0.701 ± 0.027RD*	GAT	-	0.889 ± 0.034	0.614 ± 0.044	0.807 ± 0.047	0.686 ± 0.034	GIN	0.901 ± 0.021	0.693 ± 0.019	0.593 ± 0.038	0.785 ± 0.041	0.706 ± 0.043	GCN	0.946 ± 0.020	0.600 ± 0.014	0.610 ± 0.022	0.821 ± 0.014	0.715 ± 0.014Neural	GraphSAGE	0.951 ± 0.015	0.626 ± 0.023	0.649 ± 0.018	0.832 ± 0.024	0.720 ± 0.013Sparse	GAT	-	0.921 ± 0.015	0.671 ± 0.018	0.834 ± 0.015	0.724 ± 0.026	GIN	0.937 ± 0.027	0.744 ± 0.015	0.634 ± 0.023	0.824 ± 0.027	0.719 ± 0.015(* Report the better performance With SS or RD)(a) Spectral SParsifier(b) RD Sparsifier0.680.66
Table S2: Node classification performance with similar numbers of trainable parametersDataset	Reddit	PPI	Transaction	Cora	CiteseerMetrics	Micro-F1	Micro-FI	AUC	Accuracy	AccuracyGCN	0.922 ± 0.041	0.532 ± 0.024	0.564 ± 0.018	0.810 ± 0.027	0.694 ± 0.020NeuralSparse- GCN	0.946 ± 0.020	0.600 ± 0.014	0.610 ± 0.022	0.821 ± 0.014	0.715 ± 0.014NeuralSparse- GCN-Compact	0.943 ± 0.018	0.601 ± 0.021	0.605 ± 0.013	0.820 ± 0.012	0.713 ± 0.009From the evaluation results shown in Table S2, we draw the following observations. First,both NeuralSparse-GCN and NeuralSparse-GCN-Compact consistently outperform GCN on all the13Under review as a conference paper at ICLR 2020datasets. Second, compared with NeuralSparse-GCN, NeuralSparse-GCN-Compact achieves com-parable prediction accuracy with smaller variance in most cases.
Table S3: Node classification performance in setting ACora(10)	Cora(20)	Citeseer(10)	Citeseer(20)GCN	0.641	± 0.009	0.631 ±	0.013	0.653	±	0.012 LDS-GCN	0.715	± 0.008	0.703 ±	0.011	0.691	±	0.021 NeUralSParse-GCN	0.723	± 0.012	0.719 ±	0.008	0.731	± 0.011	0.671 ± 0.019 0.715 ± 0.011 0.724 ± 0.017Our observation is summarized as follows. In general, NeuralSparse and LDS achieves comparablenode classification accuracy. Specifically, NeuralSparse has relatively better performance in Setting14Under review as a conference paper at ICLR 2020Table S4: Node classification performance in setting B	Cora	CiteseerGCN	0.810 ± 0.027	0.694 ± 0.020LDS	0.831 ± 0.017	0.727 ± 0.021NeuralSparse-GCN	0.821 ± 0.014	0.724 ± 0.014Table S5: Node classification performance in setting C	Cora + kNN	Citeseer + kNNGCN	0.631 ± 0.014	0.646 ± 0.009LDS	0.731 ± 0.019	0.725 ± 0.013NeuralSparse-GCN	0.751 ± 0.013	0.743 ± 0.007A and Setting C. LDS performs slightly better in Setting B. From the above observation, we conjec-ture that NeuralSparse is more robust to graphs with more random edges while LDS is more suitablein a graph of relatively less noise by adding additional edges. We will verify the conjecture in the
Table S4: Node classification performance in setting B	Cora	CiteseerGCN	0.810 ± 0.027	0.694 ± 0.020LDS	0.831 ± 0.017	0.727 ± 0.021NeuralSparse-GCN	0.821 ± 0.014	0.724 ± 0.014Table S5: Node classification performance in setting C	Cora + kNN	Citeseer + kNNGCN	0.631 ± 0.014	0.646 ± 0.009LDS	0.731 ± 0.019	0.725 ± 0.013NeuralSparse-GCN	0.751 ± 0.013	0.743 ± 0.007A and Setting C. LDS performs slightly better in Setting B. From the above observation, we conjec-ture that NeuralSparse is more robust to graphs with more random edges while LDS is more suitablein a graph of relatively less noise by adding additional edges. We will verify the conjecture in thenext subsection.
Table S5: Node classification performance in setting C	Cora + kNN	Citeseer + kNNGCN	0.631 ± 0.014	0.646 ± 0.009LDS	0.731 ± 0.019	0.725 ± 0.013NeuralSparse-GCN	0.751 ± 0.013	0.743 ± 0.007A and Setting C. LDS performs slightly better in Setting B. From the above observation, we conjec-ture that NeuralSparse is more robust to graphs with more random edges while LDS is more suitablein a graph of relatively less noise by adding additional edges. We will verify the conjecture in thenext subsection.
