Table 1: Test accuracy of different models on both benchmark and synthetic datasets.
Table 2: Fisher Score after appying different filters on both bench-mark and synthetic datasetsFigure 5: Base filter combina-tion Learned by AFGNN∞Cora -OOOO o.ooo	1.000	0.000	0.000	0.000Citeseer-θ∙θθθ θ∙θoι	0.799	0.000	0.197	0.000Pubmed -θθθθ oθθθ	0.619	0.001	0.003	0.0001SmallGap-o∙24i 0.132	0.131	0.132	0.131	0.132SmaIIRatio-0000 θ∙θθθ 0000 0.000			1.000	0.000the model with highest validation accuracy and record its test accuracy. For each dataset, we run theexperiment 10 times and compute the mean and standard deviation of recorded test accuracy.
Table 3: A Summary of Graph Filters of Existing GNNs.
Table 4: Statistics of Benchmark Dataset	Cora	Citeseer	PubmedGCN	81.5	-^703^^	79.0GIN	-	-	-SGC	81.0±0.0	71.9±0.1	78.9±0.0GFNN	80.9±1.3	69.3±1.1	81.2±1.5GAT	83.0±0.7	72.5±0.7	79.0±0.3Table 5: Baseline’s Accuracy on Benchmark DatasetA.6.2 Synthetic DatasetWe also generated two synthetic datasets: SmallGap and SmallRatio. For SmallGap, we use SBMto generate a two class network with p = 0.2 and q = 0.199. The density gap p/q is very smallin this case. They have the same number of nodes and both have 64 dimension features sampledfrom gaussian distributions with different mean and same variance. For SmallRatio, we use SBM togenerate a two class network, which has 200 nodes for one class and 800 nodes for the other. Thisdataset is called SmallRatio because n1/n2 = 0.25 is small. Their 64 features are sampled fromgaussian distributions with different mean and different variance. The detailed generation processand parameter can be found in our code.
Table 5: Baseline’s Accuracy on Benchmark DatasetA.6.2 Synthetic DatasetWe also generated two synthetic datasets: SmallGap and SmallRatio. For SmallGap, we use SBMto generate a two class network with p = 0.2 and q = 0.199. The density gap p/q is very smallin this case. They have the same number of nodes and both have 64 dimension features sampledfrom gaussian distributions with different mean and same variance. For SmallRatio, we use SBM togenerate a two class network, which has 200 nodes for one class and 800 nodes for the other. Thisdataset is called SmallRatio because n1/n2 = 0.25 is small. Their 64 features are sampled fromgaussian distributions with different mean and different variance. The detailed generation processand parameter can be found in our code.
Table 6: Time Cost	Cora	Citeseer	PubmedAFGNN0	861	1369^^	1351AFGNN1	863	1369	1351AFGNN∞	863	1369	1351GAT	1733	2345	-Table 7: Memory(MB) Cost	precision class0	precision class1	F1 class0	F1 class1	micro F1	macro F1GCN	-95.70±1.62^^	64.50±33.80	97.60±0.80	39.60±25.97	95.52±1.24	68.64±13.24SGC	94.30±0.45	21.70±33.21	97.00±0.00	9.50±14.74	94.34±0.36	53.32±7.51GFNN	98.40±1.50	76.20±25.57	98.80±0.60	72.10±24.60	97.42±1.10	85.40±12.32GIN	95.90±1.45	62.00±35.49	97.60±0.66	38.80±25.49	95.20±0.97	68.12±12.92GAT	96.50±0.67	85.00±30.00	98.00±0.00	35.40±14.60	96.43±0.43	66.84±7.40AFGNN0	95.00±0.77	53.90±39.97	97.20±0.40	19.90±19.52	94.62±0.68	58.62±9.89AFGNN1	94.80±1.17	40.00±48.99	97.40±0.80	16.80±27.15	94.84±1.23	57.09±13.88AFGNN∞	98.20±0.40	83.40±0.80	99.00±0.00	77.80±1.60	97.38±0.18	88.22±0.96Table 8: Performance on OAG SmallRatio Datasetbecause it requires too much memory cost and is not able to run on GPU. Therefore, AFGNN needsless time and memory cost than GAT.
Table 7: Memory(MB) Cost	precision class0	precision class1	F1 class0	F1 class1	micro F1	macro F1GCN	-95.70±1.62^^	64.50±33.80	97.60±0.80	39.60±25.97	95.52±1.24	68.64±13.24SGC	94.30±0.45	21.70±33.21	97.00±0.00	9.50±14.74	94.34±0.36	53.32±7.51GFNN	98.40±1.50	76.20±25.57	98.80±0.60	72.10±24.60	97.42±1.10	85.40±12.32GIN	95.90±1.45	62.00±35.49	97.60±0.66	38.80±25.49	95.20±0.97	68.12±12.92GAT	96.50±0.67	85.00±30.00	98.00±0.00	35.40±14.60	96.43±0.43	66.84±7.40AFGNN0	95.00±0.77	53.90±39.97	97.20±0.40	19.90±19.52	94.62±0.68	58.62±9.89AFGNN1	94.80±1.17	40.00±48.99	97.40±0.80	16.80±27.15	94.84±1.23	57.09±13.88AFGNN∞	98.20±0.40	83.40±0.80	99.00±0.00	77.80±1.60	97.38±0.18	88.22±0.96Table 8: Performance on OAG SmallRatio Datasetbecause it requires too much memory cost and is not able to run on GPU. Therefore, AFGNN needsless time and memory cost than GAT.
Table 8: Performance on OAG SmallRatio Datasetbecause it requires too much memory cost and is not able to run on GPU. Therefore, AFGNN needsless time and memory cost than GAT.
