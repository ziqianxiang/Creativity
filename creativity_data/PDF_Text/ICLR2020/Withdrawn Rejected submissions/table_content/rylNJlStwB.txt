Table 1: Variations of the attribute prediction network and their effect on the model accuracy.
Table 2: Accuracy of the attribute refinement loop instantiated with different similarity metrics. Theaccuracy shown in brackets denotes the improvement compared to the initial attribute values.
Table 3: Button attribute domains and illustration of their visual appearance.
Table 4: Per attribute accuracy before and after applying the refinement loop when starting from thebest predictions of the attribute prediction network for the real-world D=gplay dataset.
Table 5: Perceivable difference definition for all attributes used in our work.
Table 6: Examples of perceivable difference between two attribute values. For the same (=) and the similar (≈) perceivable difference, we include worst case examples.				Attribute	Ground-truth	Examples of Perceivable Difference				same (=)	similar (≈)	different (6=)Border Color	Ok	I	I	Ok	Ok	I	OkBorder Radius	( Ok I	[ 。k )		OkBorder Width	(Ok)	(Ok)	eɪɔ	(Ok)Main Color	[	I	I	1	■ Ok 1	I ok IPadding	Ok	Ok	Ok	OkShadow	I Mt I	I Olt I	I Ok I	]	OkText Color	I Ok I	I Ok I	1 Ok I	1 Ok 1Text Font	Ok	Ok	-	OkText Gravity	1 Ok I	I Ok 1	-	Text Size	Ok	Ok	Ok	Ok -Height	I Ok I	Ok	Ok	OkWidth	1 Ok I	【 Ok I	【 Ok I	I OklF Datasets and inferred implementation visualizationsWe provide illustrations of our approach for inferring Android Button implementations from im-ages. Concretely, we include examples of images for which our approach works well, as well asexamples where our models make mistakes. The visualizations for the synthetic Dsyn and real-world Dgplay dataset of buttons found in Google Play Store applications are shown in Table 7 and
Table 7:	Visualization of the attribute predictions for the synthetic buttons in the Dsyn dataset.
Table 8:	Visualization of the attribute predictions for the real-world buttons in the Dgplay dataset.
