Table 1: Metrics for quantitative evaluation of depth accuracy. d is the ground truth depth, d is the prediction.
Table 2: In the sparse training regime, our method can efficiently learn to predict depth from single pointsupervision, outperforming significantly both standard architectures and unsupervised depth estimation systems.
Table 3: Depth estimation errors with camera intrinsics varying up to 20% of their nominal value betweenviews. Based on projective geometry, unsupervised methods suffer the most from parameter uncertainty.
Table 4: Estimation of camera motion based on the global parameters estimated by our model. We initialize theglobal module either randomly (Scratch) or as trained with our approach (Pretrained). We then append a smallMLP and train supervised camera motion prediction by tuning either just the MLP (MLP) or the full network(Full). As a reference, we also report the performance of two classic approaches. We report rotation (rot) andtranslation (trans) errors in degrees (since the translation vector is normalized to 1, see ยง 4.1). Lower is better.
Table 5: Ablation study on the Scenes11 dataset.
Table 6: Comparison to Structure from Motion (SfM) baselines. Our approach outperforms SfMmethods on all datasets and metrics, except for two. This shows that learning from sparse supervisioncan be competitive with classic geometry-based techniques.
Table 7: Comparison of our approach with different input modalities to triangulation with perfect pose,triangulation with pose estimated by finetuning our global net as in Sec. 4.4 (P. Pose), and the SfM pipeline withground-truth pose. Although slightly outperformed by the SfM baseline with pose information, our approach issignificantly better than naive triangulation on the real datasets, where correspondences are generally very noisy,indicating that our approach learns to filter out these correspondence errors. Providing ground-truth relative posebetween images or perfect correspondences generally increases the network performance, showing the ability ofour model to learn the relationship between these two modalities in ideal conditions.
Table 8: Fine-tuning the parameters of PWCNet with a very sparse depth loss performs worse than fixing them.
