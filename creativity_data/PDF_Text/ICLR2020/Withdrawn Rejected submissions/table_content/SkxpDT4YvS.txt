Table 1: Comparison on complexity required to achieve ∣∣VJ(θ)k ≤ e. Particularly, if ψ(θ)1 ∣∣θk2, then the result (30) of our VRMPO is measured by gradient. Beside, ρt =ef QH O πθ0 (ahjh)2	h=0 πθt (ah |sh)input-dependent baseline to reduce variance, and analytically show its benefits over state-dependentbaselines. Recently, Grathwohl et al. (2018); Cheng et al. (2019a) provide a standard explanation forthe benefits of such approaches with baseline function.
Table 2: Max-average return over 500 epochs, where we run 5000 iterations for each epoch. Maxi-mum value for each task is bolded.
