Table 1: Model accuracy averaged over all modules. A sample is correct if all characters of the targetsequence have been predicted correctly. The column “>95%” counts how many of the 56 modulesachieve over 95% accuracy. Boldface marks the best-performing model up to 700k steps.
Table 2: The results of our neural machine translation experiment. The loss is the smoothed nega-tive log-likelihood of the word-pieces (lower is better). The TP-Transformer achieves a lower lossthroughout training and a comparable final BLEU score (higher is better).
