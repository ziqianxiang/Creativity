Table 1: Architecture Hyperparameter Optimization on MobileNet V1Under FLOPs constraints							330M				150M		45M		Acc		FLOPs	Acc	FLOPs	Acc	FLOPsUniform Rescale Baseline	Channel	68.4%	325M	63.7%	149M	50.6%	41M	Input image	70.6%	343M	65.7%	149M	54.0%	42.5M	Channel + Input image	70.8%	325M	67.1%	143M	58.8%	45.7M	Netadapt	69.1%	284M	—	—	—	—State-of-the-arts	AMC	70.5%	281M	—	—	—	—	MetaPruning	70.9%	324M	66.4%	149M	57.2%	41.1MProposed Method	Channel	71.0%	310M	66.5%	145M	58.6%	47.5M	Channel + Input image	71.2%	309M	67.6%	139M	59.7%	42.5MUnder GPU latency constraints0.75×			0.5×		0.25×		Acc	Latency	Acc	Latency	Acc	LatencyBaseline	68.4%	5.620ms	63.7%	3.998ms	50.6%	2.266msProposed Method	72.3%	5.617ms	70.6%	3.972ms	66.8%	2.231msTable 2: Architecture Hyperparameter Optimization on MobileNet V2							Under FLOPs constraints									200M		150M		45M	
Table 2: Architecture Hyperparameter Optimization on MobileNet V2							Under FLOPs constraints									200M		150M		45M			Acc	FLOPs	Acc	FLOPs	Acc	FLOPsUniform Rescale Baseline	Channel	70.0%	203M	67.2%	140M	54.6%	43M	Input image	70.8%	220M	68.3%	138M	59.1%	42M	Channel + Input image	70.6%	212M	68.5%	142M	59.3%	47MState-of-the-arts	AMC	70.8%	220M	—	—	—	—	MetaPruning	71.2%	217M	68.2%	140M	58.3%	43MProposed ʌ æ c+L	Channel	70.7%	205M	68.4%	141M	58.1%	46M	Channel + Input image	71.4%	206M	68.8%	139M	60.7%	42Meto	Channel + Input image + Depth 70.7%			206M	69.1%	145M	60.9%	51MUnder GPU latency constraints									0.8×		0.65×		0.35×		Acc Latency Acc Latency ,					Acc Latency	Uniform Rescale Baseline	70.0% 7.36ms 67.2% 5.97ms 54.6% 4.22ms							Proposed	Channel + Input image	72.3% 7.34ms 71.2% 5.93ms 67.7% 4.10ms Method Channel + Input image + Depth 72.4% 7.17ms 71.7% 5.90ms 68.7% 3.98ms							Under CPU latency constraints								0.75×	0.5×		0.35×		Total Optimization			Acc Latency Acc	Latency	Acc	Latency		Time Cost	
Table 3: Architecture Hyperparameter Optimization on ResNet50						3G			2G		1G		Acc	FLOPs	Acc	FLOPs	Acc	FLOPsUniform Baseline	76.0%	3.2G	74.8%	2.3G	72.0%	1.1GAUtoPrUner(LUo & Wu, 2018)	—	—	74.8%	2.3G	72.0%	1.1GTraditional	ThiNet (Luo et al., 2017)	75.8%	2.9G	74.7%	2.1G	72.1%	1.2GPUrning	CP (He et al., 2017)	—	—	73.3%	2.0G	一	—SFP (He et al., 2018a)	75.1%	2.9G	—	—	—	—AUtoML-based MetaPrUning (LiU et al., 2019)	76.2%	3.0G	75.4%	2.0G	73.4%	1.0GOUr method	76.2%	3.0G	75.6%	2.0G	73.4%	1.0GImageNet is a large-scale dataset with 1.2 million training images and 50K validation images of1000 classes. In our experiments, we split the original training images into sub-evaluation dataset,which contains 50000 images randomly selected from the training images with 50 images in each1000-class, and sub-training dataset with the rest of images. We optimize the architecture hyper-parameters on the sub-evaluation dataset and train the weights on the sub-training dataset. Opti-mizing the architecture hyperparameters with weight training in the weight-sharing network takesone-fourth the epochs as training the corresponding backbone network from scratch. After the ar-chitecture hyperparameters are optimized, we train the corresponding architecture from scratch onthe original training dataset and evaluate it on the test dataset. The training details can be found inthe Appendix B.
Table 4: Hyperparameter (HP) optimization space.
