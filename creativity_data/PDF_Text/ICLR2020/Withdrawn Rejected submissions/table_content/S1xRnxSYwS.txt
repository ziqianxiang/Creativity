Table 1: Time Distribution on Linear/Non-linear Layers	Linear Layers		Non-linear Layers		Total	Time (ms)	Proportion	Time (ms)	Proportion	Time (ms)CaffeSCONE (BS=128)	9243^	57.7%	6774~	42.3%	16017Goten (BS=512)	4306^	58.1%	3106~	41.9%	741^Speedup	8.59×	-	8.72×	-	8.64×Throughput of CaffeSCONE First, we show the training throughput of CaffeSCONE in Fig. 3,by which we emphasize that using more cores on CPU cannot improve the performance of such apure-SGX approach. Moreover, we benchmark the throughput with batch sizes of 128 (a commonsetting in plaintext setting) and 512 (the setting we adopted for Goten). We confirmed that the formerone has better performance for VGG11 in CaffeScone, and thus we adopt it in the later experiments.
Table 2: Accuracy vs. Speedup using GPU-powered SchemeAccuracy	0.90	0.89	0.88	0.87	0.86	0.85Speedup	-	4.93	7.28	7.31	7.31	11.789Under review as a conference paper at ICLR 2020not have a significant impact on training, and it attains a high accuracy in a shorter time. However,Goten still cannot attain 0.9 accuracy after 200 epochs, while CaffeSCONE can.
