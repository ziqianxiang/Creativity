Table 1: Test performance on DBPedia and AGNews (mean ± SEM).
Table 2: Examples of excerpts extracted on the Beer test set.
Table 4: Test performance on DBPedia and AGNews (mean ± SEM) for all values of λ and λL1 .
Table 5: Examples of excerpts extracted on the Beer test set.
Table 6: Precision (Prec., in %) of gold rationales and percentage of extracted text (Extr. in %) whentrained separately on each aspect.
Table 7:	AGNews test examples correctly classified by EDUCE. Underlined set of words are excerptsextracted, one color per concept.
Table 8:	AGNews test examples uncorrectly classified by EDUCE. Underlined set of words areexcerpts extracted, one color per concept.
Table 9: Examples of excerpts that are extracted on AGNews for all 10 concepts. Colors match thecolors used in Table 7 and Table 8.
Table 10: Examples of excerpts that are extracted on AGNews for all 10 concepts without No conceptLoss. We see the concepts are inconsistent and hard to parse.
Table 11: DBPedia test examples correctly classified by EDUCE. Underlined set of words are excerptsextracted, one color per concept.
Table 12: Examples of excerpts that are extracted on DBPedia for all 10 concepts. Colors match thecolors used in Table 11.
Table 13: Examples of excerpts that are extracted on DBPedia when using C = 50 concepts. Only36 concepts are identified as present and we report those.
