Table 1: AUC-ROC (mean±std) performance of RDP and its five competing methods on 14 datasets.
Table 2: AUC-PR (mean±std) performance of RDP and its five competing methods on 14 datasets.
Table 3: AUC-ROC results of anomaly detection (see Appendix C for similar AUC-PR results).
Table 4: NMI and F-score performance of K-means on the original space and projected spaces.
Table 5: F-score performance of K-means clustering (see similar NMI results in Appendix D).
Table 6: Datasets used in the anomaly detection taskData	N	D	Anomaly (%)	LinkDDoS	464,976	66	3.75%	http://www.csmining.org/cdmc2018/index.phpDonors	619,326	10	5.92%	https://www.kaggle.com/c/kdd-cup-2014-predicting-excitement-at-donors-chooseBackdoor	95,329	196	2.44%	https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurityAd	3,279	1,555	13.99%	https://archive.ics.uci.edu/ml/datasets/internet+advertisementsApascal	12,695	64	1.38%	http://vision.cs.uiuc.edu/attributes/Bank	41,188	62	11.26%	https://archive.ics.uci.edu/ml/datasets/Bank+MarketingCeleba	202,599	39	2.24%	http://mmlab.ie.cuhk.edu.hk/projects/CelebA.htmlCensus	299,285	500	6.20%	https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29Creditcard	284,807	29	0.17%	https://www.kaggle.com/mlg-ulb/creditcardfraudLung	145	3,312	4.13%	https://archive.ics.uci.edu/ml/datasets/Lung+CancerProbe	64,759	34	6.43%	http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.htmlR8	3,974	9,467	1.28%	http://csmining.org/tLfiles/Project_Datasets/r8_r52/r8-train-all-terms.txtSecom	1,567	590	6.63%	https://archive.ics.uci.edu/ml/datasets/secomU2R	60,821	34	0.37%	http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.htmlR8, 20news, Sector and RCV1 are widely used text classification benchmark datasets. Olivetti is awidely-used face recognition dataset.
Table 7: Datasets used in the clustering taskData	N	D	#Classes	LinkR8	7,674	17,387	8	http://csmining.org/tLfiles/Project_Datasets/r8_r52/r8-train-all-terms.txt20news	18,846	130,107	20	https://sCikit-Iearn.org/0.19/datasets/tWenty _newsgroups.htmlOlivetti	400	4,096	40	https://sCikit-Iearn.org/0.19/datasets/olivetti_faces.htmlSector	9,619	55,197	105	https://www.csie.ntu.edu.tw/~cjlin/IibSVmtools/datasets/multiclass.html#SeCtOrRCV1	20,242	47,236	2	https://www.csie.ntu.edu.tw/~cjlin/IibSVmtools/datasets/binary.html#rcv1.binaryC AUC-PR Performance of Ablation Study in Anomaly detectionThe experimental results of AUC-PR performance of RDP and its variants in the anomaly detec-tion task are shown in Table 8. Similar to the results shown in Table 3, using the Lrdp loss only,our proposed RDP model can achieve substantially better performance over its counterparts. Byremoving the Lrdp loss, the performance of RDP drops significantly in 11 out of 14 datasets. Thisdemonstrates that the Lrdp loss is heavily harvested by our RDP model to learn high-quality rep-resentations from random distances. Removing Laadux from RDP also results in substantial loss ofAUC-PR in many datasets. This indicates both the random distance prediction loss Lrdp and thetask-dependent loss Laadux are critical to RDP. The boosting process is also important, but is not ascritical as the two losses. Consistent with the observations derived from Table 3, distances calculatedin non-linear and linear random mapping spaces are more effective supervisory sources than that inthe original space.
Table 8: AUC-PR performance of RDP and its variants in the anomaly detection task.
Table 9: NMI performance of RDP and its variants in the clustering task.
Table 10: Testing runtime (in seconds) on 14 anomaly detection datasets.
Table 11: Testing runtime (in seconds) on five clustering datasets.
Table 12: NMI and F-score performance of K-means clustering using RDP, Doc2Vec, andDoc2Vec+RDP based feature representations of the text datasets R8 and news20.
Table 13: NMI and F-score performance of K-means clustering using RDP, RotNet, and Rot- Net+RDP based feature representations of the image dataset Olivetti.			NMI Performance	F-Score PerformanceOrg	0.778 ± 0.014	-0.590 ± 0.029-RDP	0.805 ± 0.012	0.638 ± 0.026RotNet	0.467 ± 0.014	-0.243 ± 0.014-RotNet+RDP	0.472 ± 0.011	0.242 ± 0.011RotNet4×2	0.518 ± 0.010	-0.281 ± 0.014-RotNet4×2+RDP	0.517 ± 0.010	0.282 ± 0.014RotNet4×1	0.519 ± 0.010	-0.283 ± 0.014-RotNet4×1 +RDP	0.536 ± 0.010	0.298 ± 0.011RotNet3×1	0.526 ± 0.014	-0.303 ± 0.018-RotNet3×1 +RDP	0.567 ± 0.010	0.336 ± 0.015RotNet2×1	0.561 ± 0.010	-0.339 ± 0.016-RotNet2×1 +RDP	0.587 ± 0.009	0.374 ± 0.015The evaluation results are presented in Table 13. Impressively, RDP can significantly outperformRotNet and all its four variants on Olivetti. It is interesting that Org (i.e., performing K-meansclustering on the original 64 × 64 vector space) also obtains a similar superiority over the RotNetfamily. This may be because Olivetti is too small to provide sufficient training samples for RotNetand its variants to learn its underlying semantic abstractions. This conjecture can also explain theincreasing performance of RotNet variants with decreasing complexity of the RotNet architecture.
Table 14: F-score performance of classification on five real-world datasets.
