Table 1: Suggested embedding functions for different con-ditioning modalities.
Table 2: Comparison of class-conditioned models trained onImageNet (resolution 128 × 128).
Table 3: Comparison of image-conditioned models. Results averaged over 5 runs.
Table 5: Settings used to calculate FJD in experiments.
Table 6: Source of pre-trained models evaluated in Section 6.
Table 7: Comparison of BigGAN model evaluated with different truncation values σ. FJD iscalculated at α = 17.8. As σ increases, classification accuracy decreases and diversity increases.
Table 8: ResBlock down	Table 9: ResBlock upInput x	Input xx → Conv3 × 3 → BN → ReLU → out	x → Conv3 × 3 → BN → ReLU → outout → Conv3 × 3 → BN → ReLU → out	out → Conv3 × 3 → BN → outout → AvgPool2 × 2 → out	out → Upsample2 × 2 → outx → Conv1 × 1 → res	x → Conv1 × 1 → resres → AvgPool2 × 2 → res	res → Upsample2 × 2 → resout + res → ReLU → out	out + res → ReLU → outTable 11: DecoderTable 10: EncoderInput X ∈ r64×64×cResBlock down C → chResBlock down ch → 2chResBlock down 2ch → 4chResBlock down 4ch → 8chLinear 8ch × 4 × 4 → MZ ∈ RMLinear M → ch × 8 × 8BN → ReLUResBlock up 8ch → 4ch
Table 11: DecoderTable 10: EncoderInput X ∈ r64×64×cResBlock down C → chResBlock down ch → 2chResBlock down 2ch → 4chResBlock down 4ch → 8chLinear 8ch × 4 × 4 → MZ ∈ RMLinear M → ch × 8 × 8BN → ReLUResBlock up 8ch → 4chResBlock up 4ch → 2chResBlock up 2ch → chConv ch → CTanhH FJD for Model Selection and Hyperparameter TuningIn order to demonstrate the utility of FJD for the purposes of model selection and hyperparametertuning, we consider the loss function of the generator from an auxiliary classifier GAN (ACGAN)(Odena et al., 2017), as shown in Equation 7 to 9. Here S indicates the data source, and C indicates
Table 10: EncoderInput X ∈ r64×64×cResBlock down C → chResBlock down ch → 2chResBlock down 2ch → 4chResBlock down 4ch → 8chLinear 8ch × 4 × 4 → MZ ∈ RMLinear M → ch × 8 × 8BN → ReLUResBlock up 8ch → 4chResBlock up 4ch → 2chResBlock up 2ch → chConv ch → CTanhH FJD for Model Selection and Hyperparameter TuningIn order to demonstrate the utility of FJD for the purposes of model selection and hyperparametertuning, we consider the loss function of the generator from an auxiliary classifier GAN (ACGAN)(Odena et al., 2017), as shown in Equation 7 to 9. Here S indicates the data source, and C indicatesthe class label.
Table 12: Scores of ACGAN models trained with different values for conditioning weighting λ.
Table 13: FJD / FID results averaged over 5 runs on COCO-stuff validation set with multi-label,bounding box (bbox) and mask conditionings for image resolutions 64 × 64 and 128 × 128.
