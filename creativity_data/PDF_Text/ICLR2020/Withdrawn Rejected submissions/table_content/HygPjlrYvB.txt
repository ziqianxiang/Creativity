Table 1: Dataset details and experiment results: On the left of Dataset - training and testing data foreach dataset. On the right - F-Score (F) and accuracy (Acc) of PAN and baselines for the datasetTraining			Testing		Dataset	a-GAN		UPU		NNPU		NNPUSB		PAN	P-Label	Unlabel														Pos	Pos	Neg	Pos	Neg		F	ACC	F	ACC	F	ACC	F	Acc	F	Acc26,000	234,000	260,000	20,000	20,000	YELP	83.72	83.33	79.72	79.33	80.70	81.06	81.92	81.76	83.45	83.56426	3,839	4,264	1086	1047	RT	66.10	58.00	50.21	56.50	62.38	58.63	66.58	59.60	66.58	64.101,250	11,250	12,500	12,500	12,500	IMDB	73.01	70.64	70.35	69.87	76.21	74.62	74.24	71.88	77.10	78.84800	7,144	6,056	1,800	1,800	20News	63.48	68.66	59.13	53.07	78.52	78.07	75.87	75.56	81.06	81.003,000	29,492	30,508	4,926	5,074	MNIST	94.67	95.03	94.21	94.29	95.40	95.35	95.60	95.55	96.51	96.421,000	20,000	30,000	4,000	6,000	CIFAR10	76.15	83.04	86.20	88.96	86.09	88.84	86.56	88.59	87.22	89.70-	-	-	-	-	Average	76.24	76.45	73.30	73.67	80.34	79.43	80.13	78.82	81.99	82.27precisionFigure 3: RT - due to space limit, we only show 100 epochs.
Table 3: Varying the positive data and the class prior probability for NNPU.
Table 4: Varying the ration of known positive data on MNIST.
Table 5: Varying the ration of known positive data on CIFAR10.
Table 6: Sensitivity of Î» on MNIST.
Table 7: Accuracy (%) on different datasets for PAN with and without term III.
Table 8: F-score comparison on different datasets with and without term III.
