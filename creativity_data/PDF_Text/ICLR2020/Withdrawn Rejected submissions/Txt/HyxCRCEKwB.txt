Under review as a conference paper at ICLR 2020
Robust Generative Adversarial Network
Anonymous authors
Paper under double-blind review
Ab stract
Generative adversarial networks (GANs) are powerful generative models, but usu-
ally suffer from instability which may lead to poor generations. Most existing
works try to alleviate this problem by focusing on stabilizing the training of the
discriminator, which unfortunately ignores the robustness of both generator and
discriminator. In this work, we consider the robustness of GANs and propose a
novel robust method called robust generative adversarial network (RGAN). Par-
ticularly, we design a robust optimization framework where the generator and dis-
criminator compete with each other in a worst-case setting within a small Wasser-
stein ball. The generator tries to map the worst input distribution (rather than a
specific input distribution, typically a Gaussian distribution used in most GANs)
to the real data distribution, while the discriminator attempts to distinguish the
real and fake distribution with the worst perturbation. We have provided theories
showing that the generalization of the new robust framework can be guaranteed.
A series of experiments on CIFAR-10, STL-10 and CelebA datasets indicate that
our proposed robust framework can improve consistently on four baseline GAN
models. We also provide ablation analysis and visualization showing the efficacy
of our method on both generator and discriminator quantitatively and qualitatively.
Introduction
Generative adversarial networks (GANs) (Goodfellow et al., 2014) have been enjoying much atten-
tion recently due to their great success on different tasks and datasets (Radford et al., 2015)(Salimans
et al., 2016)(Ho & Ermon, 2016) (Li et al., 2017)(Chongxuan et al., 2017). The framework of GANs
can be formulated as the game between generator and discriminator. The generator tries to produce
the fake distribution which approximates the real data distribution, while the discriminator attempts
to distinguish the fake distribution from the real distribution. These two players compete with each
other iteratively. GANs are also popular for their theoretical value. Training the discriminator is
showed to equivalent to training a good estimator for the density ratio between the fake distribution
and the real one (Nowozin et al., 2016)(Uehara et al., 2016)(Mohamed & Lakshminarayanan, 2016).
The discriminator generally measures the departure between the model distribution and real
data distribution with certain divergence measure, e.g. Jensen-Shannon divergence or f-
divergence (Nowozin et al., 2016). Arjovsky et al. proved that the supports of the fake and real
distributions are typically disjoint on low dimensional manifolds and there is a nearly trivial dis-
criminator which can correctly classify the real and fake data (Arjovsky et al., 2017). The loss of
such discriminator converges quickly to zero which causes the vanishing gradient for generator.
To alleviate such problem, Arjovsky et al. proposed the Wasserstein GAN based on Wasserstein
metric requiring no joint supports. Since it is inconvenient to minimize directly the Wasserstein dis-
tance, they solve the dual problem by clipping the weights to ensure the Lipschitz condition for
discriminator. Later Gulrajani et al. proposed the gradient penalty to guarantee the Lipschitz condi-
tion (Gulrajani et al., 2017). Spectral normalization is also proposed to stabilize the training of the
discriminator (Miyato et al., 2018).
Most existing methods try to improve the stability of GANs by controlling the discriminator. How-
ever, the robustness of GANs have not adequately been considered. When the discriminator is not
robust to noise (i.e., the discriminator cannot measure the distance between the fake and real distri-
bution accurately), some examples might be mis-classified which consequently misleads the training
of generator. Meanwhile, the poor generalization performance of generator might cause the “blurry”
generated images for some potential input noise. Robust Conditional Generative Adversarial Net-
1
Under review as a conference paper at ICLR 2020
works is proposed to improve the robustness of conditional GAN for noised data. However, this
method can merely implement on conditional GAN which improves the ability of generator only to
defend the noise (Chrysos et al., 2018). Some other researchers focus on the robustness of GAN to
label noise (Thekumparampil et al., 2018)(Kaneko et al., 2019).
In this paper, we attempt to improve the robustness of GANs in a systematical way by promoting
the robustness of both discriminator and generator. We propose a novel robust method called robust
generative adversarial network (RGAN) where the generator and discriminator still compete with
each other iteratively, but in a worst-case setting. Specifically, a robust optimization is designed with
considering the worst distribution within the small Wasserstein ball. The generator tries to map the
worst input distribution (rather than a specific distribution) to the real data distribution, while the
discriminator attempts to distinguish the real and fake distribution with the worst perturbation. We
provide some theoretical analysis for the proposed Robust GAN including generalization. We also
implement our robust framework on different baseline GANs (i.e., DCGAN, WGAN-GP, and BW-
GAN) (Radford et al., 2015)(Adler & Lunz, 2018), observing substantial improvements consistently
on all the datasets used in this paper.
Generative Adversarial Network
The principle of GAN is a game between two players: generator and discriminator, both of which
are usually formulated as the deep neural networks. The generator tries to generate a fake example
to fool discriminator, while the discriminator attempts to distinguish between fake and real images.
Formally, the training procedure of GAN can be formulated as:
minmax S(G,D)，Ex〜p,[logD(x)]+ Ee〜Pg[(1 - logD(G(zi)))]	(1)
where, x and xe = G(z) are real and fake examples sampled from the real data distribution Pr
and generation distribution Pg respectively. The generation distribution is defined by G(z) where
Z 〜PZ (PZ is a specific input noise distribution). The minmax problem cannot be solved directly
since the expectation of the real and generation distribution is usually intractable. Therefore, the
approximation problem is defined as:
mm
min max Sm(G,D~)，一 X[l^ogD(xi)] +——X[(1 - logD(G(zi)))]	(2)
GD	m	m
i=1	i=1
where m examples of xi and zi are sampled from distributions Pr and PZ and the mean value of
loss is used to approximate the original problem. However, such a way might not ensure a good
robustness of discriminator and generator. Some noised images might not be classified correctly and
potential input noise points will cause degraded generation. In this paper, for alleviating such prob-
lem, we design a distributionally robust optimization. Particularly, we consider the worst distribution
(rather than a specific single distribution) within the small range.
Robust Generative Adversarial Network
As we discussed in the previous sections, although most existing GAN methods can stabilize the
training of the discriminator, the robustness might not be adequately considered. In other words, the
discriminator might not perform well on some noised data which consequently misleads the training
of generator. Similarly, the generator might produce poor generations for certain input noise points
if its robustnessis not good. To alleviate such problem, we design the distributionally robust opti-
mization on GAN. Before we discuss how we can achieve this, we first elaborate the distributionally
robust optimization.
Distributionally Robust Optimization
Let d : X × X → R+ ∪ {∞}. The departure between x and x0 can then be represented by d(x, x0).
For distributionally robust optimization, the robustness region P = {P : D(P, P0) ≤ ρ} is con-
sidered, a ρ -neighborhood of the distribution P0 under the divergence D(., .) instead of a single
2
Under review as a conference paper at ICLR 2020
distribution1. The distributionally robust optimization can be formulated as (Sinha et al., 2017):
min sup EP [l(X; θ)]
θ P∈P
(3)
where l(.) is a loss function parameterized by θ. The problem of (3) is typically intractable for
arbitrary ρ.
In order to solve this problem, we first present a proposition:
Proposition 0.1 Let l: θ × X → R and d: X × X → R+ be continuous. Then, for any distribution
P0 and ρ > 0 we have
sup {EP [l(X; θ)] - γW (P, P0)} = EP0 [ sup {l(x; θ) - γd(x, x0)}]
P∈P	x∈X
(Proof is provided in (Sinha et al., 2017)).
With Proposition 0.1, we can reformulate (3) with the Lagrangian relaxation as follows:
min EP0 sup [l(x; θ) - λd(x, x0)]
θ	x∈X
where the second term d(x, x0) is to restrict the distance between two points.
(4)
(5)
Robust Training over Generator
With the distributionally robust optimization, we first discuss how we can perform robust training
over generator. The generator of GAN tries to map a noise distribution Pz to the image distribution
Pr . The objective of generator is described as follows:
1m
min — X[[l^og(1 - D(G(zi)))],	where Zi 〜Pz	(6)
Gm
i=1
Typically, Pz is a Gaussian distribution. For improving the robustness, we consider all the possible
distributions within the robust region Pz = {P : W (P, Pz) ≤ ρz} rather than a single specific
distribution (typically a Gaussain in most existing GANs). Here we use the Wasserstein metric to
measure the distance between P and Pz, where P is the ρz -neighbor of the original distribution Pz.
However, it is difficult to consider all the distributions in this small region, the alternative way is to
consider their upper bound (the worst distribution). The robust optimization problem for G is then
described as follows:
1m
min sup m^∑>g(I —D(G(zi)))], where Zi 〜P	(7)
G P∈Pz m i=1
According to Proposition 0.1, we can relax (7) as:
1m
min max - X[log(1 - D(G(Zi + ri))) - λz ∣∣rk2], where Zi 〜Pz	(8)
G rm
i=1
Different from those previous methods, our method attempts to map the worst distribution (in the
ρz -neighborhood of the original distribution Pz) to the image distribution. Intuitively, we sample
the noise points which are most likely (or the worst) to generate the blurry images and optimize the
generator based on these risky points. Therefore, such generator would be robust against poor input
noises and might be less likely to generate the low-quality images.
Robust Training over Discriminator
In traditional GANs described by (2), the generator attempts to generate a fake distribution to ap-
proximate the real data distribution, while the discriminator tries to learn the decision boundary to
separate real and fake distributions. Apparently, a discriminator with a poor robustness would in-
evitably mislead the training of generator. In this section, we utilize the popular adversarial learning
1Normally, the Wasserstein metric W(., .) is used and corresponding d(x, x0) = kx - x0 k2p where p > 0
3
Under review as a conference paper at ICLR 2020
method and propose the robust optimization method to improve the discriminator’s robustness both
for clean and noised data.
Specifically, we define the robust regions for both the fake distribution Pg = {P : W (P, Pg) ≤ ρg}
and real distribution Pr = {P : W (P, Pr) ≤ ρr}. The generator tries to reduce the distance
between the fake distribution Pg and real distribution Pr . The discriminator attempts to separate the
worst distributions in Pg and Pr. Intuitively, the worst distributions are closer to decision boundary
(less discriminative) and they are able to guide the training of discriminator to perform well on
”confusing” data points near the classification boundary (such discriminator can be more robust
than original one). We can reformulate (2) in the robust version:
1m	1m
max sup —X[logD(Xi)]+ sup — X[log(I- D(GO(Zi)))]
D P1 ∈Pr m i=1	P2∈Pg m i=1
(9)
where Zi 〜Pz, Xi 〜Pi and G0 〜P2. Using Proposition 0.1, We can relax the alternate problem
as:
mm	m
mDXmrn mm X[logD(Xi + ri)]+m X[log(1 - D(G(Zi) + r2))] + ^ £[口用2] + 什2k2]
1 2	i=1	i=1	i=1	()
with Zi 〜Pz,	Xi 〜Pr
Here ri = {rii 11 }im=i is the set of small perturbations for the points sampled from real distribution Pd
which tries to make the real distribution closer to the fake distribution. r2 = {r2i }im=i tries to make
fake distribution closer to real one. Intuitively, these perturbations try to enhance the difficulty of
classification task for discriminator by making real and fake data less distinguishable and it can help
promote the robustness of discriminator.
Overall Optimization
We now integrate the robust training of generator and discriminator into a single framework:
minmaxV(G, D)，(1 — λ)S(G, D)+ sup	λEχ〜p[logD(x)]
G D	P:W (P,Pr)≤ρr
+ sup	XEg，〜p[(1 — logD(G0(z)))]
P:W (P,Pg)≤ρg
(11)
where G0(zi) = G(zi) + r2 and Zi 〜p). PZ is the mixture distribution defined by PZ = (1 — λ)pz +
λpz and Pz is the worst distribution defined by Pz = argmaxp：W(p,pz )≤ρz Ex 〜P [1 — logD(G(x))].
r2i is arbitrary perturbation. It is noted that we also combine the original GAN into the framework,
allowing a more flexible training. The specific algorithm is given as below:
Algorithm 1 Algorithm for RGAN.
1: for number of training iterations do
2:	Sample a batch of input noise Zi 〜Pz of size m, a batch of real data Xi 〜Pr of size m.
λ is the trade-off parameter for original objective and our objective. i and 2 are amplitude of
perturbation for input and images respectively.
3:	find the worst perturbation {rzadv, rdadvi, rdadv2} by maximizing the objective of generator
and minimizing the objective of discriminator:
4:	rzi adv = arg minri:krik2=i[log(1 — D(G(Zi + ri))) + λzkrik22]
5:	rdi advi = arg minri:krik2=i[logD(Xi +ri) +λdkriik22]
6:	rdi adv2 = arg minri:krik2=i[log(1 — D(G(Zi) + ri)) +λdkr2ik22]
7:	Update G by descending along its stochastic gradient:
8:	Vθg [m Pi=i[log(1 - D(G(Zi))) + m Pi=i[log(1 - D(G(Zi + Edv)))
9:	Update D by descending along its stochastic gradient:
10:	Vθd [Sm(G,D) + m Pi=i[logD(Xi + Wdadvi)] + m Pi=i[log(1 - D(G(Zi) + wdadv2))]]
11: end for
4
Under review as a conference paper at ICLR 2020
Theoretical Analysis
In this section, we provide theoretical analysis for the RGAN but leave the proof details in appendix.
We now show that the optimal discriminator of RGAN balances the mixture of real distributions and
the mixture of fake distributions as Lemma 0.2.
Lemma 0.2 For arbitrary fixed G, the optimal D of the game defined by the utility function V (G, D)
is:
DG (x) = "p…"、	(12)
Pr(X)+Pg(X)
where, prλ (x) = (1 - λ)pr + λp0r is the mixture distribution for real data with λ ∈ [0, 1]. p0r
is the worst distribution defined by Pr = argminp：w(p,pr)≤ρr Ex〜P[logD(x)]. Pg(X) = (1 一
λ)Pg + λP0g is the mixture distribution for fake data. The worst distribution P0g is defined by P0g =
argminPW(p,Pg)≤ρg Eg，〜P[1 ― logD(G0(z))].
We further show the optimum point of the utility function V (G, D) as Lemma 0.3.
Lemma 0.3 When the optimum discriminator D* is achieved, the utility function reaches the global
minimum if and only ifPgg (X) = Prg (X).
The min-max problem of (11) is computationally intractable due to the expectations over real and
fake distributions. An alternate way is to approximate the original problem with the empirical aver-
age of finite examples:
m
minmaxVm(G, D)，(1 — λ)Sm(G, D)+-----------^^[logD(χi)]
G D	m i=1
+ ʌ xx[(1 — logD(G0(Zi)))]
m
i=1
(13)
where Xi 〜Pr, G0 〜Pg and Zi 〜pg. Pz is the mixture distribution defined by Pz = (1 — λ)pz + λp'z
andpZ is the worst distribution defined by PZ = argmaxp：w(p,pz)≤ρz Ex〜P[1 — logD(G(x))].
We now provide the analysis for generalization ability as Lemma 0.4. First, we give some assump-
tions:
Assumption 1 We provide the following assumptions for RGAN:
1.	The discriminator IogDe(x) is kθ-Lipschitz in its parameter θ, i.e., ∣logDθ(x) — logD%(x)| ≤
kθkθ — θ0k.
2.	The discriminator IogDe(x) is kx-Lipschitz in its X, i.e., ∣logDθ(x) — IogDg(x0)∣ ≤ kx∣∣x — x0∣∣.
3.	The distance between two arbitrary samples is bounded, i.e., kX — X0 k ≤ ∆B .
The generalization ability of discriminator is defined as in (Qi, 2017)(Arora et al., 2017) and it
describes if and how fast the difference |Vm — Vθ| converges, where, Vθ = max。V(G*, D) and
Vm = maxD Vm(G*,D)
Lemma 0.4 Under Assumption 1, with at least probability 1 — η, we have:
|Vme —Ve| ≤
(14)
when the number of samples
C∆2B(kx)2	keN	1
m ≥ -----B2~~— (Nlog匚——+ logn)	(15)
where C is a sufficiently large constant, andN	is the number of parameters of the discriminator
function.
5
Under review as a conference paper at ICLR 2020
Similarly, the generalizability of the generator can be defined as convergence of difference ∣Q* -
Qφ∣, where, Qφ = minG V(G, D*) and Qm = minG Vm(G, D*). We first give the assumptions:
Assumption 2 We provide the following assumptions for RGAN:
1.	The generator Gφ(z) is kφ -Lipschitz in its parameter φ, i.e., ∣Gφ(z) — Gφ(z)∣ ≤ kφkφ — φ0∣∣.
2.	The discriminator Gφ(z) is kz-Lipschitz in its Z, i.e., ∣Gφ(Z) — Gφ(z0)∣ ≤ kz∣∣z — z0∣∣.
3.	The distance between two arbitrary samples is bounded, i.e., kz - z0 k ≤ ∆Bz .
Lemma 0.5 Under Assumption 2, with at least probability 1 — η, we have:
IQm - Qφl≤ e	(16)
when the number of samples
m ≥ CNBBz k2k2 (NglogkθkφNg + log1)	(17)
2	η
where Cgis a sufficiently large constant, and Ngis the number of parameters of the generator
function.
Experiments
We present a series of experiments in this section. First, we show that our proposed RGAN can
improve the performance of different kinds of baseline models including WGAN-GP, DCGAN,
WGAN-GP (resnet), and BWGAN. Inception score and FID are used to evaluate the quality of
generations. Following many previous relevant work, we mainly conduct on CIFAR-10 and STL-
10 the comparison between our proposed method and various baseline models quantitatively while
visualizing different models qualitatively on both CIFAR-10 and CelebA. In addition, we plot the
bar charts for different baseline models and RGANs on two datasets (CIFAR-10 and STL-10). We
also perform the ablation analysis to examine closely our proposed framework. Furthermore, we
provide visualizations showing that the performance of baseline models may degrade given some
specific input noises (sampled from the worst distribution). In comparison, our proposed method
is more robust and can still perform fairly well. In the third part, we provide the visualizations of
T-SNE embedding for original and worst distributions. Moreover, we show some images generated
by baseline models and our proposed model.
Quantitative Comparison
To evaluate the performance of our proposed method, we follow the previous works (Gulrajani et al.,
2017; Adler & Lunz, 2018) on robustness and mainly conduct experiments on the CIFAR-10 and
STL-10 dataset. There are 4 baseline models including WGAN-GP, WGAN-GP (resnet), DCGAN,
and BWGAN. We implemented our proposed robust strategy on these baselines and would like to
check if the robust training could indeed improve the performance. The structures and settings of
our method are the same as baseline models. We train WGAN-GP, DCGAN, BWGAN and our
proposed RGANs with 50, 000 training samples for 200, 000 epochs. For WGAN-GP (resnet) and
our corresponding model, we found that 100, 000 epochs appear sufficient. For each 500 epochs,
we calculate the inception score for 50, 000 generated images. For training RGANs, there are three
hyper-parameters λ (trade off our objective and original one), 1 and 2. We set λ = 0.1 which is
searched from {0.001, 0.01, 0.1, 0.5, 1, 2}. We also set 1 = 0.01 and 2 = 4 which was searched
from {0.001, 0.01, 0.1, 0.2, 0.5, 1, 2, 4, 5, 10}. For STL-10, we train our models and corresponding
baselines with 80w training samples with size 48 × 48. The training settings are totally the same
with settings for CIFAR-10. Note that we do not need to adjust hyper-parameters for achieving better
performance on the second dataset.
We list the performance for different models in Table 1. Clearly, our proposed RGAN (which is based
on WGAN-GP-res) achieves the best result among all the methods in terms of both the criteria, i.e.,
Inception Score and FID. In order to check if the proposed robust strategy can indeed improve over
different baselines, we also detail the performance in Figure 1 where we plot the bar charts for
6
Under review as a conference paper at ICLR 2020
(d) FID on STL-10
(a) Inception score on (b) FID on CIFAR-10
CIFAR-10
(c) Inception score on
STL-10
Figure 1:	Performance (Inception score: the bigger the better, and FID: the lower the better) of
different baselines (blue bars) and corresponding RGANs (orange bar). Our methods consistently
perform better than baselines on different datasets and criteria.2
different baseline models and their robust version with RGAN on two datasets (CIFAR-10 and STL-
10).2 It is noted that the robust strategy can consistently improve the baselines on the two datasets
in terms of both the criteria. In addition, we also show the convergence curves in Figure 2. Clearly,
when our robust strategy is applied on the baseline GANs, an obvious increase of the inception
scores can be observed (though the convergence speed is similar to that of baseline models). All
these experiments indicate that the robust training is indeed necessary and useful.
Table 1: PerformanCe of different models on CIFAR-10 and STL-10
Methods	InCeption SCore		FID	
	CIFAR-10	STL-10	CIFAR-10	STL-10
Real data	11.24 ± 0.12	26.08 ± 0.26	7.8	7.9
Weight Clipping	6.41 ± 0.11	7.57 ± 0.10	42.6	64.2
Layer norm	7.19 ± 0.12	7.61 ± 0.12	33.9	75.6
Weight norm	6.84 ± 0.07	7.16 ± 0.10	34.7	73.4
Orthonormal	7.40 ± 0.12	8.56 ± 0.07	29.0	46.7
ALI				
(Warde-Farley & Bengio, 2016)	5.34 ± 0.05			
BEGAN (Berthelot et al., 2017)	5.62			
DCGAN (Radford et al., 2015)	5.77 ± 0.021	7.36 ± 0.06	42.18	53.23
Improved GAN (-L+HA)				
(Salimans et al., 2016)	6.86 ± 0.06			
EGAN-Ent-VI (Dai et al., 2017)	7.07 ± 0.10			
DFM				
(Warde-Farley & Bengio, 2016)	7.72 ± 0.13			
CT GAN (Wei et al., 2018)	8.12 ± 0.12			
SNGAN (Miyato et al., 2018)	8.22 ± 0.05	9.10 ± 0.04	21.70	40.1 ± 0.04
BWGAN (Adler & Lunz, 2018)	8.08 ± 0.05		25.67	
WGAN-GP-res				
(Gulrajani et al., 2017)	7.76	9.06 ± 0.03	22.19	42.60
RGAN (WGAN-GP-res)	8.25 ± 0.013	9.16 ± 0.015	19.79	39.62
Ablation Analysis
We ConduCt the ablation analysis in this subseCtion. SpeCifiCally, we experiment on CIFAR-10 with
robust training over generator only, robust training over disCriminator only, and robust training over
both the generator and disCriminator, trying to see if a robust training is neCessary on both generator
and disCriminator. The results are listed in Table 2. As observed, robust training on either generator
2BWGAN appears not to Converge in STL-10 in our experiments. For fair Comparison, we did not report
the performanCe when BWGAN is used as the baseline in STL-10.
7
Under review as a conference paper at ICLR 2020
6.5
6
5.5
5
4 4
o 3.5
3
2.5
2
50	100	150	200	250	300	350	400
Steps (x500)
e-0。S uoaΘOU-
3
0	20	40
60	80	100	120	140	160	180	200
Steps (x500)
6.5
6
5.5
5
o 4.5
I 4
o 3.5
3
2.5
2
1.5
0	50
100	150	200	250	300	350	400
Steps (x500)
3
e-0。S Uo-Ide。U-
2
0	20	40
60	80	100	120	140	160	180	200
Steps (x500)
(a) WGAN-GP vs RGAN (b) WGAN-GP (res) vs (c) DCGAN vs RGAN (d) BWGAN vs RGAN
RGAN
Figure 2:	Inception score versus training step. Each subfigure shows the comparison between a dif-
ferent baseline model (blue curve) and its corresponding robust version (by applying the RGAN
strategies, red curve). Robust GANs consistently achieve much better performance though they con-
verge in a similar speed to baseline models.
or discriminator can consistently improve the performance of all baseline models, while a joint ro-
bust training on both generator and discriminator can further boost the performance. It is interesting
to note that robust training on discriminator only could lead to more performance gain than on gen-
erator only, implying that a robust discriminator may be more important. This would be investigated
as future work.
Table 2: Ablation analysis for RGAN on different baselines on CIFAR-10.
	WGAN-GP	WGAN-GP (res)	DCGAN	BWGAN
Baseline (without robust training)	5.77 ± 0.021	7.76	5.70 ± 0.045	8.08
Robust training on generator only	5.89 ± 0.020	7.86	5.80 ± 0.022	8.11
Robust training on discriminator only	5.87 ± 0.025	8.01	6.02 ± 0.019	8.23
Robust training on generator & discriminator	5.91 ± 0.018-	8.25	6.11 ± 0.017	8.40
(a) WGAN-GP-res
(b) DCGAN
(c) WGAN-GP
ə-oos Uqldəou-
ə,loos Uqldgu-
(d) RGAN(WGAN-GP-res) (e) RGAN(DCGAN) (f) RGAN(WGAN-GP)
Figure 3:	Inception score of baselines and RGANs on both the original input noise and the worst
input noise on CIFAR-10. Performance of baselines are almost consistently degraded in the worst in-
put noise (compared from the original input noise), while their robust versions (trained with RGAN)
perform similar and stable for both worst and original input noise.
In addition, taking again CIFAR-10 as one illustrative dataset, we also show that our proposed robust
method can perform robust on some potential input noise which might lead to poor generations
(input noise sampled from the worst input distribution). Specifically, we generate 50, 000 images
with RGAN and various baseline models from the original distribution and worst distribution for
five times. Then, we compute the inception score and their corresponding standard deviation. The
8
Under review as a conference paper at ICLR 2020
(a) Input noise
(b) Worst distribution
(c) Data by WGAN-GP
(d) Data by RGAN
Figure 4: Visualization and T-SNE embedding on CIFAR-10. (a): Red points are the input noise
points sampled from the original Gaussian distribution, and blue points are sampled from the worst
distribution. The worst distribution covers a wider range of area, especially low density area of
original distribution which might cause poor generation. (b): The worst real distribution (red) and
worst generation distribution (blue). It can be noted that the worst data distributions are more similar
to each other which is more difficult to be classified. (c): Red points are the images sampled from
real distributionand blue points are generated by WGAN-GP. (d): Red points are the images sampled
from real distributionand blue points are generated by RGAN. The data distribution generated by
our method is apparently closer to the real distribution.
results are showed in Figure 3. As observed, without the robust training, those baseline models
perform consistently worst in the case of the worst noises input than that of the original input noises.
This shows that the traditional GANs may not be robust and may lead to worse performance in case
of certain poor input noise. In comparison, when the robust training is implemented, RGAN leads
to similar performance even if the worst input noise is given.
Visualization
We present visualization results to compare various methods qualitatively.
Visualization on CIFAR-10
In this subsection, we present a series of visualization trying to understand visually why the robust
GAN could lead to better performance than the traditional GANs. To this end, we sample 500 data
points from the original input distribution and worst input distribution respectively. We then plot the
2-dimensional T-SNE embedding of these points. We also would like to plot the real data distribution
and the generated data from the traditional GAN as well as our robust GAN. For clarity, we take
WGAN-GP as one example but we should bear in mind that the conclusion is basically the same for
other traditional GANs like DCGAN. These plots are made in Figure 4 where one can inspect the
meaning of each subfigure in the caption. We highlight some remarks as follows. First, Figure 4(a)
indicates that the worst distribution covers wider range of areas, especially low density areas of
the original distribution; this might cause poor generations since the worst input noise distribution is
significantly different from the original input noise. Second, (b) shows that the worst real distribution
(red) actually looks much similar to the worst generation distribution. It may be more robust and
meaningful to minimize in the worst-case setting the departure of the real data distribution and
the fake data distribution, which is conducted in our RGAN. Third, (c) shows that the real data
distribution varies largely from the generated data points obtained by traditional GANs, indicating
the poor generalization of the traditional GAN; in comparison, with a robust optimization in the
worst-case setting, (d) demonstrates that the generated data look very close to the real data.
Visualization on CelebA
To clearly examine the visual quality, we demonstrate some images generated by WGAN-GP, DC-
GAN and their corresponding RGANs on the CelebA dataset. These generated images are shown in
Figure 5. As we can observe from these examples, the existing GANs may sometimes lead to very
bad generations as circled in (a) and (c). In comparison, with the robust training under the worst-
case distribution, such very bad examples can hardly be seen in RGAN. This clearly demonstrates
the advantages of the proposed model.
9
Under review as a conference paper at ICLR 2020
(a) WGAN-GP
(b) RGAN (WGAN-GP)
(c) DCGAN.
Figure 5: Face images generated by WGAN-GP, DCGAN and corresponding RGANs. In (a),
WGAN-GP generates two obviously strange faces highlighted with red circles. In (c), several re-
peated low quality faces are generated by DCGAN highlighted by red circles. Our method achieves
better results.
(d) RGAN (DCGAN)
Conclusion
In this paper, we consider the generalization issue of GANs and propose a robust model called
robust generative adversarial network (RGAN). We have designed a robust optimization framework
where the generator and discriminator compete with each other in a worst-case setting within a small
Wasserstein ball. The generator tries to map the worst input distribution (rather than a specific input
distribution) to real data distribution, while the discriminator attempts to distinguish the real and fake
distribution with the worst perturbation. We have provided theories showing that the generalization
of the new robust framework can be guaranteed. We also have conducted extensive experiments
on CIFAR-10, STL-10 and CelebA datasets with two criteria (Inception score and FID) indicating
that our proposed robust framework can improve consistently on several baseline GAN models.
Ablation analysis and visualization have demonstrated the advantages of RGAN both quantitatively
and qualitatively.
10
Under review as a conference paper at ICLR 2020
References
Jonas Adler and Sebastian Lunz. Banach wasserstein gan. In Advances in Neural Information
Processing Systems, pp. 6754-6763, 2018.
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein generative adversarial networks.
In International Conference on Machine Learning, pp. 214-223, 2017.
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium
in generative adversarial nets (gans). In Proceedings of the 34th International Conference on
Machine Learning-Volume 70, pp. 224-232. JMLR. org, 2017.
David Berthelot, Thomas Schumm, and Luke Metz. Began: Boundary equilibrium generative ad-
versarial networks. arXiv preprint arXiv:1703.10717, 2017.
LI Chongxuan, Taufik Xu, Jun Zhu, and Bo Zhang. Triple generative adversarial nets. In Advances
in neural information processing systems, pp. 4088-4098, 2017.
Grigorios G Chrysos, Jean Kossaifi, and Stefanos Zafeiriou. Robust conditional generative adver-
sarial networks. arXiv preprint arXiv:1805.08657, 2018.
Zihang Dai, Amjad Almahairi, Philip Bachman, Eduard Hovy, and Aaron Courville. Calibrating
energy-based generative adversarial networks. arXiv preprint arXiv:1702.01691, 2017.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, pp. 2672-2680, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Im-
proved training of wasserstein gans. In Advances in Neural Information Processing Systems, pp.
5767-5777, 2017.
Jonathan Ho and Stefano Ermon. Generative adversarial imitation learning. In Advances in Neural
Information Processing Systems, pp. 4565-4573, 2016.
Takuhiro Kaneko, Yoshitaka Ushiku, and Tatsuya Harada. Label-noise robust generative adversarial
networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pp. 2467-2476, 2019.
JiWei Li, Will Monroe, Tianlin Shi, Sebastien Jean, Alan Ritter, and Dan Jurafsky. Adversarial
learning for neural dialogue generation. arXiv preprint arXiv:1701.06547, 2017.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization
for generative adversarial networks. arXiv preprint arXiv:1802.05957, 2018.
Shakir Mohamed and Balaji Lakshminarayanan. Learning in implicit generative models. arXiv
preprint arXiv:1610.03483, 2016.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. In Advances in neural information processing systems,
pp. 271-279, 2016.
Guo-Jun Qi. Loss-sensitive generative adversarial networks on lipschitz densities. arXiv preprint
arXiv:1701.06264, 2017.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. In Advances in neural information processing systems,
pp. 2234-2242, 2016.
Aman Sinha, Hongseok Namkoong, and John Duchi. Certifying some distributional robustness with
principled adversarial training. arXiv preprint arXiv:1710.10571, 2017.
11
Under review as a conference paper at ICLR 2020
Kiran K Thekumparampil, Ashish Khetan, Zinan Lin, and Sewoong Oh. Robustness of conditional
gans to noisy labels. In Advances in Neural Information Processing Systems, pp. 10271-10282,
2018.
Masatoshi Uehara, Issei Sato, Masahiro Suzuki, Kotaro Nakayama, and Yutaka Matsuo. Generative
adversarial nets from a density ratio estimation perspective. arXiv preprint arXiv:1610.02920,
2016.
David Warde-Farley and Yoshua Bengio. Improving generative adversarial networks with denoising
feature matching. 2016.
Xiang Wei, Boqing Gong, Zixia Liu, Wei Lu, and Liqiang Wang. Improving the improved training
of wasserstein gans: A consistency term and its dual effect. arXiv preprint arXiv:1803.01541,
2018.
Appendix
A. PROOF
Lemma 0.2 For arbitrary fixed G, the optimal D of the game defined by the utility function V (G, D)
is:
DG (X) = Pλrf⅛	(18)
where, prλ(x) = (1 - λ)pr + λp0r is the mixture distribution for real data with λ ∈ [0, 1]. p0r
is the worst distribution defined by Pr = argminp：w(p,pr)≤ρr Ex〜P[logD(x)]. Pg(X) = (1 一
λ)pg + λp0g is the mixture distribution for fake data. The worst distribution p0g is defined by p0g =
argminPW(p,Pg)≤ρg EG，〜P[1 ― logD(G0(z))].
Proof:
Given the classifier and generator, the utility function can be rewritten as
V(G,D)，(1 一 λ)[Ex〜Pr[logD(x)]
+ EG〜Pg [(1 - logD(G(zi)))]]
+ SuP	λEx 〜P[logD(x)]
P:W (P,Pr)≤ρr
+ sup	λEGo 〜p[(1 — logD(G0 (z)))]
P:W (P,Pg)≤ρg
= (1 一 λ)	pr (X)log (D (X))dX
+ (1 一 λ)	pg (X)log(1 一 D(X))dX
+λZ p0r(X)log(D(X))dX
+ λ p0g (X)log(1 一 D(X))dX
=	prλ(X)log(D(X))dX
+	pgλ(X)log(1 一 D(X))dX
(19)
where G0(zi) = G(Zi) + r2 and Zi 〜PZ. r2 is arbitrary perturbation. Then, it is easy to prove that
the OPtimal D is DG(X) = pλ(p+pλ(χ).
Lemma 0.3 When the optimum discriminator D* is achieved, the utility function reaches the global
minimum if and only ifpgλ(X) = prλ(X).
12
Under review as a conference paper at ICLR 2020
Proof:
Given the optimal D*, We can reformulate the function V(G, D):
V(G, D=Z pλ(x)log( pλ(⅞+‰)dx+Z pλ(x)log( pλ(Xps+Pλ (x) )dx
=ZPr(X)log((入((? ∖"dx
r	(pr(χ) + pλ(χ))∕2
+ Z pr(x)log(西χP+P⅛W2)dx - 2log2
=-2log2 + KL(Pr(X) ||(pr(x) + Pg(XX/2) + KL(Pr(X) ||(pr(x) + Pg(XX/2)
Then, V(G, D*) can be rewritten as:
V(G,D*) = -2log2 + 2JSD(Pλ(X)∣∣Pλ(X))	(21)
where JSD is the Jensen-Shannon divergence, which is always non-negative and the unique optimum
is achieved if and only if Prr (X) = Pgr (X).
Assumption 1 We provide following assumptions for RGAN:
1.	The discriminator Dθ (x) is kθ -Lipschitz in its parameter θ, i.e., ∣logDθ (x) — logD% (x)| ≤ kθ ∣∣θ 一
θ0k.
(22)
(23)
2.	The discriminator Dθ(x) is kχ-Lipschitz in its X, i.e., ∣logDθ(x) — IogDg(x0)∣ ≤ kχ∣X — x0∣.
3.	The distance between two arbitrary samples is bounded, i.e., ∣X - X0 ∣ ≤ ∆B.
Lemma 0.4 Under assumption 1, with at least probability 1 — η, we have:
∣vm - V θ l≤ e
when the number of samples
C∆2B(kx)2	kθN	1
m ≥ ------2------(Nlog-----+ log-)
where C is a sufficiently large constant, and N is the number of parameters of the discriminator
function, Vθ = max。V(G*, D) and Vm = max。Vm(G*, D).
Proof:
To prove the bound, we need to apply the McDiarmid’s inequality. We first bound the change of
function Vθ(D, G*) when a sample is changed. When i-th samples are replaced by Xii, Xii, Gzii
and GZii, the function changes to Vθi(D, G*). Then, we have
∣Vm (d,g* ) - Vmi(D5i
=一∣(1 - λ)[logD(Xi) + IogD(GZi )]
m
+ λ[logD(X0i) + logD(G0Zi)]
-	(1 - λ)[logD(Xii) + logD(GZii)]
-	λ[logD(X0ii) + logD(G0Zii)]|
≤ ------kxkXi - Xiiil +----kxkGZi - GZiik
(24)
m
m
+ kxIIXi - Xiik +	kXkGZi - Gziik
m	m zi z i
2
≤ mkxAp
13
Under review as a conference paper at ICLR 2020
Now we can apply the McDiarmid’s inequality. We have
P(∣Vm(D,G*)- V(D,G*)∣ ≥e∕2)
2
m
≤ 2exp(- 8k2∆B)
(25)
The above bound applies to a single discriminator Dθ. To get the union bound, we consider a ∕8kθ-
net N, i.e. for any Dθ , there is a θ0 ∈ N so that kθ - θ0 k ≤ ∕8kθ . This standard net can be
constructed to contain finite discriminators such that N ≤ O(N log(kθ N∕)). N is the number of
parameters of discriminator (we here assume the parameter space of the loss function is bounded,
then we can construct such a net containing finite points). Therefore, for all θ ∈ N , we have
|Vm - V θ l≤ 〃2
(26)
when m ≥ C号。)2 (NlogkθN- + log1).
We further consider the bound beyond θ and we can easily obtain the bounds with the first assump-
tion:
|Vθ(D,G*) - Vθ0(D,G*)∣ ≤ 2kθ∣∣θ - θ0k	(27)
and
|Vm(D,G*)- Vm0(D,G*)∣ ≤ 2kθ∣θ -θ0k	(28)
The final bound for all discriminator can be obtainged with assumption ∣θ - θ0 ∣ ≤ ∕8kθ :
|Vm (D,G*)-V θ (D,G*)∣
≤∣Vm(D,G*) - Vm(D,G*)∣
+ 1Vm0(D,G*)- Vθ'(D,G*)∣
+ |Vθ0(D,G*) - Vθ(D,G*)| ≤ e
(29)
Assumption 2 We provide the following assumptions for RGAN:
1.	The generator Gφ(z) is kφ -Lipschitz in its parameter φ, i.e., ∣Gφ(z) 一 Gφ(z)∣ ≤ kφ∣φ 一 φ0∣.
2.	The discriminator Gφ(z) is kz-Lipschitz in its Z, i.e., ∣Gφ(Z) — Gφ(z0)∣ ≤ kz∣z — z0∣.
3.	The distance between two arbitrary samples is bounded, i.e., ∣z - z0 ∣ ≤∆Bz.
Lemma 0.5 Under assumption 2, with at least probability 1 - η, we have:
IQm - Qφl≤ e	(30)
when the number of samples
m ≥ C4z k2k2 (Ng logkkφN + log 1)	(31)
2	η
where Cg is a sufficiently large constant, and Ng is the number of parameters of the generator
function, Qφ = minG V(G, D*) and Qm = minG Vm(G, D*).
Proof:
Proof is skipped due to its similarity to Lemma 0.4.
14