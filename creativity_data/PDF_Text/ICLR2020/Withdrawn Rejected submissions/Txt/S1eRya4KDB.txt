Under review as a conference paper at ICLR 2020
A Novel Bayesian Estimation-Based Word
Embedding Model For Sentiment Analysis
Anonymous authors
Paper under double-blind review
Abstract
The word embedding models have achieved state-of-the-art results in a vari-
ety of natural language processing tasks. Whereas, current word embedding
models mainly focus on the rich semantic meanings while are challenged by
capturing the sentiment information. For this reason, we propose a novel
sentiment word embedding model. In line with the working principle, the
parameter estimating method is highlighted. On the task of semantic and
sentiment embeddings, the parameters in the proposed model are deter-
mined by using both the maximum likelihood estimation and the Bayesian
estimation. Experimental results show the proposed model significantly
outperforms the baseline methods in sentiment analysis for low-frequency
words and sentences. Besides, it is also effective in conventional semantic
and sentiment analysis tasks.
1	Introduction
Word embeddings provide continuous low-dimensional vector representations of words from
documents (Li et al., 2017). Aiming to capture semantic and syntactic contextual informa-
tion from large datasets, the word embedding models are extensively employed to represent
words in natural language processing tasks (Levy and Goldberg, 2014). For this reason,
many modelling methods are proposed to generate dense representations of words (Rath,
2017).
Seeing the flourish of word embeddings, Word2vec (Mikolov et al., 2013) and GloVe (Pen-
nington et al., 2014) are considered as the edge-cutting approaches to deal with the word
contexts. C&W is another most widespread method due to the progress in neural networks
(Collobert and Weston, 2008). Besides, other algorithms are integrated into the existing
models. For instance, Jameel and Schockaert proposes D-GloVe by combing GloVe and
Dirichlet-Multinomial language modeling (Jameel and Schockaert, 2016). More recently,
the contextualized word embedding models, which improve the accuracy to a large extent,
are put forward. As such, the traditional approaches are concluded as pre-trained word
embeddings. Whereas, the newly proposed methods, such as ELMo by Peters M. E. et
al.(Peters et al., 2018) , BERT by Devlin J. et al.(Devlin et al., 2018) and XLNet by Yang
Z et al.(Yang et al., 2019) , cost large amount of computing resource for training whilst ob-
tain a better working performance in downstream tasks. In this way, the pre-trained word
embeddings still hold a great promise in handling complicated natural language processing
tasks.
The aforementioned models are effective in dealing with semantic-oriented tasks. Likewise,
in sentiment analysis, research is still ongoing to capture sufficient sentiment information
while the sentiment embeddings typically depend on the sentiment polarity labels provided
by labeled corpora to guide learning processes via objective functions (Yu et al., 2017). Tang
et al. propose a method for learning sentiment embeddings by regulating the C&W model,
which encodes sentiment information in the continuous word representations (Tang et al.,
2015). By exploiting the prior knowledge, Li et al. incorporate the sentiment information to
analyze the sentiment label of each word in target and contexts (Li et al., 2017). Maas et al.
apply a semi-supervised method to get sentiment information and carry out the maximum
likelihood estimation for parameter determination (Maas et al., 2011).
1
Under review as a conference paper at ICLR 2020
Notwithstanding, the pre-trained word embeddings still have challenges in tackling senti-
ment analysis tasks, which are concluded as the following two aspects. On the one hand,
the semantically similar word may have opposite sentiment polarities. Thus the sentiment
polarity identification process has to be dedicatedly designed (Tang et al., 2015) (Li et al.,
2017) (Shi et al., 2018). On the other hand, the capturing of sentiment information from
low-frequency words is most pronounced. Typically, the low-frequency words can be re-
garded as the derivation of entity nouns, new terms and some deformation high-frequency
words, which also contain significant semantic information. Nevertheless, due to the low
frequency, current models are absent of processing their sentiment.
The objective of this work is to devise a sentiment word embedding model. Specifically,
the issue of parameter setting is deeply studied. Methods for effectively estimating the
involving parameters based on Bayesian estimation and maximum likelihood estimation are
proposed. For low-frequency word analysis, the Bayesian estimation is applied to determine
the co-occurrence probabilities and the sentiment probabilities.
This work describes current parameter estimation approaches and the model of GloVe in
Section 2, illustrates our sentiment word embedding model in Section 3, shows the experi-
ments in Section 4, and presents the research findings in Section 5.
2	Preliminary
This section introduces the basic theory related to parameter estimating algorithms and the
GloVe model, so as to facilitate the description of subsequent model architecture.
2.1	Parameter Estimating Algorithms
Typically, word vectors are taken as learning variables in the word embeddings, which results
in the use of parameter estimating algorithms. The way of establishing objective function
is therefore be employed. According to (Tang et al., 2014), the objective function of the
Skip-Gram model is to maximize the average log probability, which is expressed as:
1T
J=Tf E	InP(Wi+jlei)	(I)
i=1 -c6j6c,j 6=0
where T is the number of words in	the corpus and c indicates the size of window. We
take ei as the embedding of target word wi and wi+j as the context of wi . The outcome
P (wi+j |ei) is obtained via the hierarchical softmax. Similarly, the objective of GloVe refers
to the maximum of likelihood probability and is defined as (Jameel et al., 2019):
J = Y N (ln Xij; Wi ∙ Wj + bi + ej,σ2)	(2)
i,j
where N (.; μ,σ2) represents the normal distribution with the mean μ and the variance σ2.
In GloVe, the variance is determined by each word couple (i, j).
In addition to objective function constructing, the estimation algorithms are applied to
compute other parameters within word embeddings. In (Maas et al., 2011), the maximum
posterior probability estimation identifies the parameter to weigh the semantic information
(Maas et al., 2011). In D-GloVe, Jameel and Schockaert also use the semantic information
weighing parameter, whose value corresponds to the Bayesian estimating outcome (Jameel
and Schockaert, 2016).
2.2	The GloVe model
Basically, the GloVe model is a word-embedding method that combines evidence from the
local context and the global counts. Typically, three distinguished words are used in this
2
Under review as a conference paper at ICLR 2020
model, which are Wi,Wj and Wk. Both Wi and Wj are target words while Wk is the
context. Let x be the matrix representing the word-word co-occurrence counts. We define
the element xik as the times for word Wk appearing in the context of Wi . Correspondingly,
xi = k xik indicates the frequency of each word occurs in the context of Wi . The co-
occurrence probability of Wk being the context word of Wi is given as
Pik = P (Wk|Wi) = xik/xi
(3)
The parameter Pik /Pjk is taken to determine the relation of Wi to Wk and Wj to Wk . For
Wk has a similar relation to Wi and Wj, i.e. both relevant or irrelevant, the ratio approaches
1. The information in the ratio of co-occurrence probabilities is:
F (wTWk - WjWk) = Pik/Pjk	⑷
where wRn refers to the target word vector and weRn to the context vector. Commonly,
GloVe extracts the semantic relation between different words by using the ratio of co-
occurrence probabilities while the semantic information are identified via the maximum
likelihood estimation (Maas et al., 2011).
3	Methodology
This section depicts the architecture of the sentiment word embedding, working principle of
the parameter estimating process using two different estimation algorithms.
3.1	Sentiment Word Embedding Model Architecture
In sentiment analysis tasks, the sentiment information is captured during processing. Aim-
ing to identify the sentiment polarities of different words, a word embedding model, incor-
porating the sentiment information, is established. Typically, we tend to characterize the
proposed model by the loss function.
To compute the sentiment embeddings, we define the probability of Wi being positive as Bi
and negative as 1 - Bi . Assuming that Wi = good and Wj = bad, the value of Bi/Bj is larger
than 1, which indicates good is more positive than bad. In turn, the value (1 - Bi) / (1 - Bj)
is less than 1 since bad shows a negative polarity. In this way, the relations of the word
sentiment are expressed by the ratio of sentiment probabilities. For Bi + (1 - Bi) = 1, Bi/Bj
and (1 - Bi) / (1 - Bj) make the same sense in conveying the sentiment, we take Bi /Bj to
construct the sentiment relation of Wi and Wj . More details of the words’ relation and the
ratios are presented in Appendix 1.
Considering the bias vector corresponds to positive sentiment polarity, we take sRn to
indicate the bias vector to match the size of word vector. By transforming Wi and Wj into
word vectors Wi and Wj , the difference established upon si and sj is written as:
F (WiT si - WjT sj ) = Bi /Bj
(5)
Assuming that F is confirming to the homomorphisms between groups (R, +) and (R>0, ×),
the semantic and sentiment information is combined to get:
F	WiT Wek - WjT Wek + WiT si - WjT sj
=F (WiWk — wTWk) . F (WiSi — wTSj)
Pik Bi
=---------
Pjk Bj
(6)
3
Under review as a conference paper at ICLR 2020
Due to properties of group homomorphism, eqn.6 is transformed into
F wiT wek - wjT wek + wiT si - wjT sj
=F wiT wek + wiT si - wjT wek + wjT sj
F wiT wek + wiT si	Pik Bi
=-----7.---------= ------ + -
F (WjWk + WjSj)	Pjk Bj
in line with
F Wij Wek + Wij si = Pik + Bi
(7)
(8)
According to eqn.7,the basic objective function F is in the form of exponential, that is
F (x) = exp (x). Thus, we apply the logarithm operation to each side and have:
Wij Wek + Wij si = ln (Pik + Bi) = ln Pik + lnBi
(9)
By incorporating the sentiment information, the loss function of the word embedding model
is defined as
V
loss (Wi, Wek, si) =	Wij Wek + Wij si - ln Pik - ln Bi	(10)
i,k=1
where V indicates the size of the vocabulary. The parameters Wij , Wek and si are computed
via gradient descent algorithms.
3.2 Incorporating Sentiment Information
As pointed out in the Introduction, current models use the maximum likelihood estimat-
ing algorithm for parameter determination. In this part, we preliminarily carry out the
parameter estimation based on the maximum likelihood principle.
For each target word Wi , xi times Bernoulli experiments are conducted to extract the
context independently with V different outcomes in each experiment (Djuric and Huang,
2000). The occurrence number of the kth outcome and its probability are represented by
xik and Pik . If the random variable Xi = (Xi1 , Xi2, + + +, XiV ) stands for the occurrence
times of all the possibilities, i.e. Xik is the number for the kth one, the parameter Xi obeys
the Multinomial distribution, i.e. Xi 〜Multinomial →,, P^ with P = (Piι,P%2,…，PiV)
and -→xi =(xi1,xi2, + + +, xiV). Hence, a log-likelihood function is constructed:
max	lnL(Pi1, Pi2, +++, Pik, +++, PiV)
Pi 1 ,Pi2 ,…Pik ,…,PiV
= max	ln[(Pi1)xi1 +(Pi2)xi2 +++(Pik)xik +++(PiV)xiV]
Pi 1 ,Pi2,…,Pik,---,PiV
V
max
Pi 1 ,Pi2,∙∙∙ ,Pik,∙∙∙ ,PiV
xik + ln Pik
k=1
(11)
V
s.t.	Pik = 1
k=1
According to eqn.11, the objective function can be resolved as an optimal problem that
equality constraints. Thus, the corresponding Lagrangian function is formulated as
4
Under review as a conference paper at ICLR 2020
J (Pi 1, Pi2, ∙∙∙ , PiV, λ) = ^X Xik ∙ log Pik + λ ^1 — ^X P%]	(12)
where We have Pik = Xk determined by JP;P* PK) = 鲁 - λ = 0. Likewise,
ik λ	∂Pik	Pik	,
λ = PV=ι Xik = Xi is calculated with respect to PV=ι Pik = P"V=ι (Xk) = PV=i Xik/λ = 1.
Thus, the estimation of Pik is written as
Pik = Xik /Xi	(13)
Notably, the obtained Pik is the same with that from GloVe according to eqn.3, which
demonstrates the feasibility for parameter estimation in our model. In this way, the outcome
of parameter sentiment probability can also be computed by using the maximum likelihood
estimator. As such, a maximum likelihood estimation-based sentiment word embedding,
namely MLESWE, is put forward. In this case, the Bernoulli experiments are applied to
pick up the sentiment polarity of the target word Wi and the outcome can be either positive
or negative.
Since Bi is the probability of Wi being positive, we designate the distribution of Wi obeys
-→ti = (ti0 , ti1 ) where ti0 is the number of negative texts and ti1 indicates that of the positive
ones. Thus, the total number of texts including Wi is expressed as ti = ti0 + ti1 . Support a
random variable Ti = (Ti0 , Ti1 ) denotes the times of all the possibilities of outcomes and Ti
conforms to the binomial distribution, i.e. Ti 〜 Binomial -→ti , Bi where Bi = (Bi, 1 - Bi).
The log-likelihood function of sentiment probabilities is delivered as:
max ln L (Bi) = max ln [(Bi)ti 1 ∙ (1 — Bi)ti0] = maX [tiι ∙ ln Bi + tiο ∙ ln (1 — Bi)]	(14)
Similarly, Bi = tiL is obtained based on 弋BL)= B — I-B- = 0. Combining the semantic
and sentiment information, the final loss function based on maximum likelihood principle is
loss (wi, wek, si)
V
X
i,k=1
TT
wi wk + wi si
Xik	ti1
—ln------ln ——
Xi
ti
(15)
2
3.3 Parameter Estimating using Bayesian Estimation
The Bayesian estimating method is highlighted due to its not sensitive to initialization via
proper prior distributions to parameters (Ma et al., 2018). By using the prior knowledge,
the deficiency of lacking information of small datasets can be resolved, which leads to the
converge to the actual value (Phoong and Ismail, 2015). Accordingly, the generalization
ability of the model can be improved (Wu et al., 2018). The Bayesian approach, in this
way, is able to present an elegant solution for automatically determining the parameters
(Ferguson, 1973). We thus employ the Bayesian estimation for the parameter estimating
of the proposed model. The Bayesian estimation-based sentiment word embedding, namely
BESWE, is performed.
In accordance to the assumption of maximum likelihood principle mentioned before, the prior
distribution P (Pi) is assumed to obey the Dirichlet distribution of → = (αi,αi, ∙∙∙ , αv).
The prior distribution is converted to P (→) = Dir (→) = Qp(；：) Q卜 POk-1, with the
identical likelihood function:
5
Under review as a conference paper at ICLR 2020
!V
P → i→ i) = Mul → i, → i) = Q V7.. !)∙ ∏ PiTfc
k (xik ) k
(16)
Considering the Dirichlet-Multinomial conjugate structure, the posterior distribution is
P → iι→)=Dir (→+→ )=QΓ( α:+χ;) ∙ YYPa+XifcT	⑺
where α = λ 1 ∙ Pnnfc , n is the total number of occurrences of Word Wa in the corpus and
λ1 > 0 is determined by tuning data. By satisfying
Cik = EP→i∣→i) [lnPik]
(18)
we compute the Bayesian estimating outcome of ln Pik in the loss function provided by
eqn.10, which is also the mean value of posterior probability in line with Pik . As stated
in (Jameel and Schockaert, 2016), the computation of EP(→ ∣→)[lnPik] is facilitated via
Taylor expansion:
VarP (→i→i) [Pik]
EP(→i^→i) [lnPik] ≈ ln EP(→i^→i) [Pik1 - 2 ∙ EP(→i→i)[Pik]	(19)
where we have VarP( - i∖-- i)[ Pik ] = P αα++Xifc)∙ (1- P acafc+Xifc)) ∙P % μ+^)+i and
EP(→ ∣→)[Pik] = P αα++Xifc). Note that ln Pik is estimated via Bayesian principle in eqn.18
whose form is unlike that of eqn.13. Comparing to the maximum likelihood estimation, a
direct outcome is obtained without using Laplace smoothing in experiment. Comparatively,
P Bi is designed to obey Beta distribution with the parameter β = (β0, β1), along with
the prior distribution given as
((→ ) — RHC (→) — γ (β0 + β 1) 门 R ∖βo-1 rBi- 1	⑸∩∖
P⑺=Betake) =r( β 0)r( β 1) (1 - Bi)	∙ Bi	(20)
from which the log-likelihood function is
P (→i∣→i) = b (→ →i) = Cti1 ∙ (1 - Bi)ti0 ∙ BF	(21)
and the posterior distribution subject to the conjugate structure of Beta-Binomial is
P (→i→…a → + ?J = 20+t) + m ∙ (1 - B)β0 ++i B 1+ 'iT
(22)
6
Under review as a conference paper at ICLR 2020
where mk stands for the texts of the sentiment label k, λ2 > 0 is a parameter depending
on tuning data and βk = λ2 ∙ Pmkmk . Thereupon, to determine the In Bi in eqn.10, We take
the Bayesian estimation approach. The solution to the posterior probability expectation of
ln Bi , Which is involved With Bi is characterized as
e = EP (瓦Hi) [ln Bi]	(23)
Furthermore, the Taylor expansion is employed to update the equation:
VarP(-HBi|H-ti) [Bi]
EP (Ji) [ln Bi] ≈ ln EP (瓦司)Bi] - 2 ∙ EP; 了)[Βi]	(24)
Where We have V arP (-HB i |H-t i)
EP(瓦 H i) [Bi ] = Pe⅛+⅛ ∙
[B∙] = — β1+11- . (1 - — β1+11-、. =_______1____ and
[Bi] Pk(βk + tik) I1	P式βk + tik) J P式βk + tik) + 1 and
Hence, the final loss function of BESWE can be obtained:
V
loss (wi, wek, si) =	wiT wek + wiT si - cik - ei	(25)
i,k=1
4	Experiments
In this section, the Working performance of BESWE and MLESWE are evaluated. The task
of Word similarity analysis is carried out. To deliver the sentiment embeddings, both Word-
and sentence-level sentiment analysis using different models is conducted.
4.1	Experiment Settings
Datasets. The dataset SST (Stanford Sentiment Tree) is employed for the mode training.
There are five classes annotations Within SST, Which are very negative, negative, neutral,
positive and very positive. Typically, We assign the value 3 and 4 to represent the positive
polarity, 0 and 1 to negative and 2 to else. For our models, the Word representation dimension
is 50, the learning rate is 0.05 and the iteration number is 50. Besides, the loss function is
optimized With the deployment of AdaGrad.
Baseline Methods. We evaluate the proposed mo del in comparison to other state-of-the-
art models. The models of Word embeddings, such as C&W, Word2vec and GloVe, together
With models of sentiment embeddings, including SE-HyRank and DLJT2, are implemented.
For the baseline methods, We use default settings in the provided implementations or de-
scribed as their papers and the Word representation dimension is 50.
Word Similarity. Computing Word similarity (Levy et al., 2015) aims to capture the
general meanings of Words. In this research, the Word similarity tasks are conducted on
the dataset EN-WS-353-ALL, EN-WS-353-SIM and SCWS, Which are detailed illustrated
in (Jameel et al., 2019).
Word-level Sentiment Analysis. We conduct Word-level sentiment analysis on tWo
sentiment lexicons, namely MPQA and NRC. The number of positive and negative items
for MPQA is 2301 and 4151 While for NRC is 2231 and 3324. The N-fold cross validation
With N=5 and N=10 is performed. An SVM classifier is trained Whose average accuracy is
the evaluation metric. Specifically, the Words from SST corpus are extracted and converted
into Word embeddings, Which are taken as the features of SVM.
7
Under review as a conference paper at ICLR 2020
As Bayesian estimating principle is capable of tackling low-frequency words, we distinctively
pick up the words with a frequency less than 5 for analysis. Statistically, the SST corpus
contains 9984 low-frequency words.
Sentence-level Sentiment Analysis. Considering the sentiment analysis for sentence,
the movie review polarity datasets MovieReview is employed (Pang and Lee, 2005), which
contains 10622 samples with the proportion of each polarity 1:1. We use a convolutional
neural network (CNN) model, namely Text-CNN, with its online implementation (Kim,
2014). Likewise, the inputs of Text-CNN are word embeddings as well. The training episode
is set as 200 epochs using the default settings.
Similarly, we also pick the low-frequency words with the occupation over 10% as the low-
frequency sentences for testing. There are totally 1258 sentences cater to the demands and
are all sent to Text-CNN classifier for processing.
4.2	Experimental Results
Word Similarity. On the task of working performance evaluation, we first present the
results for of word similarity analysis (Fig. 1). It can be observed BESWE outperforms
other algorithms on all datasets, indicating that our model is capable to capture sufficient
semantic information. Distinctively, the implementation of MLESWE, although not as good
as BESWE, still achieves a better result on the average accuracy (i.e. Ave_Acc in Fig. 1)
than the original GloVe. Yet the maximum likelihood estimating algorithm can also be
applied to parameter determination of the word embeddings.
Figure 1: Word similarity results in Spearman rank correlation
Word-level Sentiment Analysis Results. The word-level sentiment analysis task is
conducted on the dataset of single-word entries. The DLJT2 model outperforms other word
embedding models by incorporating sentiment information into the learning processes, as
shown in Fig.2. Compared to the state-of-the-arts, our model fails to exceed the outcome
of the best method on average accuracy. Encouragingly, the BESWE model shows an even
better performance in tackling the low-frequency words.
Figure 2: Word-level sentiment analysis results
8
Under review as a conference paper at ICLR 2020
Sentence-level Sentiment Analysis Results. The working performance of the proposed
model is further evaluated on the sentence-level sentiment analysis task. From Fig.3, we see
that SE-HyRank has a better performance than any other algorithms in average accuracy.
Clearly, the outcome of BESWE is anyhow decent which is comparable with that of SE-
HyRank. Regarding low-frequency sentences, the minimum performance gap of over 9%
against SE-HyRank is reported. Consequently, for the sentiment analysis of low-frequency
words or low-frequency sentences, BESWE always obtain the best and most consistent
results in the identification of sentiment polarity.
80
75
70
65
60
50
45
Figure 3: Sentence-level sentiment analysis results
Effects of λ1 and λ2 . The hyperparameters in BESWE, i.e. regulatory factors λ1 and λ2 , are
used to represent the semantic and the sentiment information. The settings of the involving
parameter can be therefore determined. The values of λ1 and λ2 are varied within the
collection of {1, 0.75, 0.5, 0.25, 0.1, 0.05, 0.02, 0.01}. Firstly, the value of λ1 is set as {1,
0.75, 0.5, 0.25, 0.1, 0.05, 0.02, 0.01}. When λ2 = 1, we name BESWE as BESWE#1 and
λ2 = 0.75 as BESWE#2, and so on so forth. Correspondingly, the value of λ2 is also picked
from the same set and named from BESWE#9 to BESWE#16 in the same order. Totally,
we get 16 different models.
The results on the sentence-level sentiment analysis against different hyperparameter set-
tings are shown in Fig.4(a) and Fig.4(c). Likewise, the results for low-frequency sentences
are in Fig.4(b) and Fig.4(d). We take LowFreSentence#n to nominate the outcomes from
low-frequency sentences.
Figure 4: Sensitivity of λ1 and λ2 on BESWE with Sentence-level Sentiment Analysis
The sentence-level sentiment analysis reaches the highest accuracy 71.64% at the point
λ1 = 0.05 and λ2 = 0.02. For the analysis of low-frequency sentences, the optimal values of
λ1 and λ2 are 0.1 and 0.01, which results in an accuracy of 79.92%.
9
Under review as a conference paper at ICLR 2020
The experimental results verify the effectiveness of the proposed sentiment word embedding.
The BESWE model outperforms other state-of-the-art in word similarity identification. In
the sentiment analysis of both word level and sentence level, our method still presents com-
parable outcomes. Specifically, by integrating the prior knowledge into sentiment probabili-
ties estimating, the BESWE model is a better alternative for low-frequency-word sentiment
capturing. It is reasonable to expect better performance in sentiment analysis tasks, as it
is the case.
5	Conclusion
In this work, the designing and deploying of the sentiment word embeddings is deeply
studied. On the foundation of current word embedding models, the estimation principle of
the objective function, together with other parameters, are investigated. Motivated by the
significance of sentiment information, a novel word embedding model for sentiment analysis
is established.
Within the proposed model, both semantic and sentiment information is integrated into the
word vectors. Aiming to construct the objective function, the group homomorphism theory
is applied. As for the parameter determination, the maximum likelihood estimator and the
Bayesian estimator are employed. Experiments are conducted on various tasks to evaluate
the working performance. In comparison to the baseline models, our model is capable of
tackling word similarity tasks. For the purpose of sentiment embeddings representation, the
proposed model is effective in word-level and sentence-level sentiment analysis. Specifically,
it outperforms other methods on low-frequency words and sentences sentiment polarity
identification to demonstrate its efficacy.
References
Ronan Collobert and Jason Weston. A unified architecture for natural language processing:
Deep neural networks with multitask learning. In Proceedings of the 25th international
conference on Machine learning, pages 160-167. ACM, 2008.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-
training of deep bidirectional transformers for language understanding. arXiv preprint
arXiv:1810.04805, 2018.
Petar M Djuric and Yufei Huang. Estimation of a bernoulli parameter p from imperfect
trials. IEEE Signal Processing Letters, 7(6):160-163, 2000.
Thomas S Ferguson. A bayesian analysis of some nonparametric problems. The annals of
statistics, pages 209-230, 1973.
Shoaib Jameel and Steven Schockaert. D-glove: A feasible least squares model for estimating
word embedding densities. 2016.
Shoaib Jameel, Zihao Fu, Bei Shi, Wai Lam, and Steven Schockaert. Word embedding as
maximum a posteriori estimation. In Proceedings of the AAAI Conference on Artificial
Intel ligence, volume 33, pages 6562-6569, 2019.
Yoon Kim. Convolutional neural networks for sentence classification. arXiv preprint
arXiv:1408.5882, 2014.
Omer Levy and Yoav Goldberg. Dependency-based word embeddings. In Proceedings of the
52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short
Papers), pages 302-308, 2014.
Omer Levy, Yoav Goldberg, and Ido Dagan. Improving distributional similarity with lessons
learned from word embeddings. Transactions of the Association for Computational Lin-
guistics, 3:211-225, 2015.
Yang Li, Quan Pan, Tao Yang, Suhang Wang, Jiliang Tang, and Erik Cambria. Learning
word representations for sentiment analysis. Cognitive Computation, 9(6):843-851, 2017.
10
Under review as a conference paper at ICLR 2020
Zhanyu Ma, Yuping Lai, W Bastiaan Kleijn, Yi-Zhe Song, Liang Wang, and Jun Guo. Vari-
ational bayesian learning for dirichlet process mixture of inverted dirichlet distributions in
non-gaussian image feature modeling. IEEE transactions on neural networks and learning
systems, 30(2):449-463, 2018.
Andrew L Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, and Christo-
pher Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th annual
meeting of the association for computational linguistics: Human language technologies-
volume 1, pages 142-150. Association for Computational Linguistics, 2011.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word
representations in vector space. arXiv preprint arXiv:1301.3781, 2013.
Bo Pang and Lillian Lee. Seeing stars: Exploiting class relationships for sentiment cate-
gorization with respect to rating scales. In Proceedings of the 43rd annual meeting on
association for computational linguistics, pages 115-124. Association for Computational
Linguistics, 2005.
Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for
word representation. In Proceedings of the 2014 conference on empirical methods in natural
language processing (EMNLP), pages 1532-1543, 2014.
Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton
Lee, and Luke Zettlemoyer. Deep contextualized word representations. arXiv preprint
arXiv:1802.05365, 2018.
Seuk-Yen Phoong and Mohd Tahir Ismail. A comparison between bayesian and maxi-
mum likelihood estimations in estimating finite mixture model for financial data. Sains
Malaysiana, 44(7):1033-1039, 2015.
Trideep Rath. Word and Relation Embedding for Sentence Representation. PhD thesis,
Arizona State University, 2017.
Bei Shi, Zihao Fu, Lidong Bing, and Wai Lam. Learning domain-sensitive and sentiment-
aware word embeddings. arXiv preprint arXiv:1805.03801, 2018.
Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and Ting Liu. Building large-scale twitter-
specific sentiment lexicon: A representation learning approach. In Proceedings of coling
2014, the 25th international conference on computational linguistics: Technical papers,
pages 172-182, 2014.
Duyu Tang, Furu Wei, Bing Qin, Nan Yang, Ting Liu, and Ming Zhou. Sentiment em-
beddings with applications to sentiment analysis. IEEE Transactions on Knowledge and
Data Engineering, 28(2):496-509, 2015.
Anqi Wu, Sebastian Nowozin, Edward Meeds, Richard E Turner, Jose Miguel Hernandez-
Lobato, and Alexander L Gaunt. Deterministic variational inference for robust bayesian
neural networks. 2018.
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V
Le. Xlnet: Generalized autoregressive pretraining for language understanding. arXiv
preprint arXiv:1906.08237, 2019.
Liang-Chih Yu, Jin Wang, K Robert Lai, and Xuejie Zhang. Refining word embeddings
using intensity scores for sentiment analysis. IEEE/ACM Transactions on Audio, Speech,
and Language Processing, 26(3):671-681, 2017.
11
Under review as a conference paper at ICLR 2020
A Appendix I
For Wi = good and Wj = bad,
We have Bi / Bj > 1,
(1-Bi)/(1-Bj)<1,
i.e. Wi = good is more positive than Wj = bad.
For Wi = good and Wj = great,
We have Bi/Bj ≈ 1,
(1 - Bi)/(1 — Bj) ≈ 1,
i.e. Wi = good and Wj = great are of positive polarities.
For Wi = then and Wj = home,
We have Bi/Bj ≈ 1,
(1-Bi)/(1-Bj) ≈1,
i.e. Wi = then and Wj = home are of neutral polarities.
The specific sentiment probabilities calculated by maximum likelihood estimation are pre-
sented in Table 1.
Table 1: Sentiment probabilities of different Words using maximum likelihood estimation
Probability and Ratio	Wi = ”good” Wj = ”bad”	Wi = ”good” Wj = ”great”	Wi = ”then” Wj = ”home”
Bi	0.5879	0.5879	0.3855
Bj	0.0905	0.7063	0.4909
Bi/Bj	6.4944	0.8323	0.7854
(1 - Bi) / (1 - Bj)	0.1540	1.2015	1.2733
LikeWise, the outcomes based on Bayesian estimation are in Table 2.
Table 2: Sentiment probabilities of different Words using Bayesian estimation
Probability and Ratio	Wi = ”good” Wj = ”bad”	Wi Wj	= ”good” = ”great”	Wi Wj	= ”then” = ”home”
Bi	0.5872		0.5872		0.3819
Bj	0.0886		0.7053		0.4864
Bi/Bj	6.6272		0.8326		0.7852
(1 - Bi) / (1 - Bj)	0.1509		1.2011		1.2735
12