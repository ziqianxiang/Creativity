Under review as a conference paper at ICLR 2020
Compressive Recovery Defense: A Defense
Framework for '0,'2, and '∞ norm attacks.
Anonymous authors
Paper under double-blind review
1	Ab stract
We provide recovery guarantees for compressible signals that have been corrupted with noise and
extend the framework introduced in Bafna et al. (2018) to defend neural networks against `0, `2,
and '∞-norm attacks. In the case of 'o-norm noise, We provide recovery guarantees for Iterative
Hard Thresholding (IHT) and Basis Pursuit (BP). For '2-norm bounded noise, we provide recovery
guarantees for BP, and for the case of '∞-norm bounded noise, we provide recovery guarantees
for a modified version of Dantzig Selector (DS). These guarantees theoretically bolster the defense
framework introduced in Bafna et al. (2018) for defending neural networks against adversarial in-
puts. Finally, we experimentally demonstrate the effectiveness of this defense framework against an
array of '0, '2 and '∞-norm attacks.
2	Introduction
Signal measurements are often corrupted by noise. The theory of compressive sensing (Candes
et al. (2006)) allows us to retrieve the original signal from a corrupted measurement, under some
structural assumptions on the measurement mechanism and the signal. Let us consider the class of
machine learning problems where the inputs are compressible (i.e., approximately sparse) in some
domain. For instance, images and audio signals are known to be compressible in their frequency
domain and machine learning algorithms have been shown to perform exceedingly well on clas-
sification tasks that take such signals as input (Krizhevsky et al. (2012); Sutskever et al. (2014)).
However, it was found in Szegedy et al. (2013) that neural networks can be easily forced into mak-
ing incorrect predictions by adding adversarial perturbations to their inputs; see also Szegedy et al.
(2014); Goodfellow et al. (2015); Papernot et al. (2016); Carlini & Wagner (2017). Further, the
adversarial perturbations that led to incorrect predictions were shown to be very small (in either '0,
'2 , or '∞ -norm) and often imperceptible to human beings. For this class of machine learning tasks,
we show how to approximately recover original inputs from adversarial inputs and thus defend the
neural network '0-norm, '2-norm and '∞-norm attacks.
In the case of '0-norm attacks on neural networks, the adversary can perturb a bounded number of
coordinates in the input vector but has no restriction on how much each coordinate is perturbed in
absolute value. In the case of '2 -norm attacks, the adversary can perturb as many coordinates of the
input vector as they choose as long as the '2-norm of the perturbation vector is bounded. Finally, in
'∞-norm attacks, the adversary is only constrained by the amount of noise added to each coordinate
of the input vector.
The contribution and structure of this paper is as follows. In Section 3.1, we describe the Compres-
sive Recovery Defense (CRD) framework, a compressive-sensing-based framework for defending
neural networks against adversarial inputs. This is essentially the same framework introduced in
Bafna et al. (2018), though Bafna et al. (2018) considered only '0 attacks. In Section 3.2, we present
the recovery algorithms which are used in the CRD framework to approximately recover original
inputs from adversarial inputs. These algorithms include standard Basis Pursuit (BP), (k, t)-sparse
Iterative Hard Thresholding (IHT) and Dantzig Selector (DS) with an additional constraint. In Sec-
tion 3.3, we state recovery guarantees for the recovery algorithms in the presence of noise bounded
in either '0, '2, or '∞-norm. The guarantees apply to arbitrary '0, '2, and '∞-norm attacks; they
do not require prior knowledge of the adversary’s attack strategy. The recovery guarantees are
proved rigorously in Appendix A. In Section 4, we experimentally demonstrate the performance of
1
Under review as a conference paper at ICLR 2020
the CRD framework in defending neural network classifiers on CIFAR-10, MNIST, and Fashion-
MNIST datasets against state-of-the-art 'o, '2 and '∞-norm attacks.
Notation. Let X be a vector in CN. Let S ⊆ {1,..., N} and S = {1,..., N} \ S. The cardinality
of S is |S |. If A ∈ Cm×N is a matrix, then AS ∈ Cm×lSl is the column submatrix of A consisting
of the columns indexed by S. We denote by xS either the sub-vector in CS consisting of the entries
indexed by S or the vector in CN that is formed by starting with X and setting the entries indexed
by S to zero. For example, if X = [4,5, -9, 1]t and S = {1,3}, then XS is either [4, -9]t or
[4, 0, -9, 0]T. It will always be clear from context which meaning is intended. Note that, under
the second meaning, XS = X - XS. The support of x, denoted by SUPP(X), is the set of indices
of the non-zero entries of x, i.e., SUPP(X) = {i ∈ {1,..., N} : Xi = 0}. The '0-quasinorm of x,
denoted kXk0, is defined to be the number of non-zero entries of X, i.e. kXk0 = card(supp(X)).
We say that X is k-sParse if kXk0 ≤ k. We use Xh(k) to denote a k-sParse vector in CN consisting
of the k largest (in absolute value) entries of X with all other entries zero. For examPle, if X =
[4, 5, -9, 1]T then Xh(2) = [0, 5, -9, 0]T. Note that Xh(k) may not be uniquely defined. In contexts
where a unique meaning for Xh(k) is needed, we can choose Xh(k) out of all Possible candidates
according to a Predefined rule (such as the lexicograPhic order). We also define Xt(k) = X - Xh(k) .
If X = [X1, X2]T ∈ C2n with X1, X2 ∈ Cn, and if X1 is k-sParse and X2 is t-sParse, then X is called
(k, t)-sParse. We define Xh(k,t) = [(X1)h(k), (X2)h(t)]T, which is a (k, t)-sParse vector in C2n.
3	Theory
3.1	Compressive Recovery Defense (CRD)
Bafna et al. (2018) introduced a framework for defending machine learning classifiers against '0-
attacks. We extend the framework to '2 and '∞ attacks. The defense framework is based on the
theory of comPressive sensing, so we call it ComPressive Recovery Defense (CRD).
We exPlain the idea behind the CRD framework in the context of an image classifier. SuPPose
X ∈ Cn is a (flattened) image vector we wish to classify. But suPPose an adversary Perturbs X with
a noise vector e ∈ Cn . We observe y = X + e, while X and e are unknown to us. Let F ∈ Cn×n
be the Discrete Fourier Transform (DFT) matrix. The Fourier coefficients of X are X = Fx. It is
well-known that natural images are aPProximately sParse in the frequency domain. So we exPect
that X is approximately sparse, meaning that Xt(k)is small for some small k. We can write
y = F-1X + e	(1)
If kek2 ≤ η or kek∞ ≤ η, with η small (as in a '2 or '∞-attack), then we can use an appropriate
sparse recovery algorithm with y and F-1 as input to compute a good approximation x# to X.
Precise error bounds are given in Section 3.3. Then, since F is unitary, F-1X# will be a good
approximation (i.e., reconstruction) of X = F-1X. So We can feed F-1x# into the classifier and
expect to get the same classification as we would have for X. For an '0-attack where e is t-sparse,
the approach is only slightly different. We set A = [F-1, I] and write
y = FTX + e = FTXh(k) + e + FTXt(k) = A[χh(k), e]T + FTXt(k),	⑵
so that [Xh(k),e]T is (k, t)-sparse. This structure lets us use a sparse recovery algorithm to compute
a good approximation to X, as before. Note that the same idea can be applied with audio signals or
other types of data instead of images. Moreover, the DFT can be replaced by any unitary transfor-
mation F for which X = Fx is approximately sparse. For example, F may be the Cosine Transform,
Sine Transform, Hadamard Transform, or another wavelet transform.
We now describe the training and testing procedure for CRD. For each training image X, we compute
Xh(k) = (Fx)h(k), and then compute the compressed the image χ0 = F-1Xh,(k). We then add both
X and X0 to the training set and train the network in the usual way. Given a (potentially adversarial)
test image y, We first use a sparse recovery algorithm to compute an approximation x# to X, then
we compute the reconstructed image y0 = F-1X# and feed it into the network for classification.
3.2	Recovery Algorithms
We provide the recovery algorithms used in this section. For '0-attacks, we set A = [F-1, I] as in
(2). Against '2 or '∞-attacks, we take A = F-1 as in (1).
2
Under review as a conference paper at ICLR 2020
Algorithm 1: (k, t)-Sparse Iterative Hard Thresholding (IHT)
Procedure: IHT (y, A, k, t, T )
Input: y ∈ Cn, A ∈ Cn×2n, and positive integers k, t, T .
x[0] = 0
for i := 0 to T do
χ[i+1] = (χ[i] + A*(y - Ax[i]))h(k,t)
return x# = x[T +1]
The IHT algorithm above is used to defend against `0 -norm attacks. For such attacks, according
to (2), the vector we need to recover is (k, t)-sparse. Thus this IHT is adapted to the structure of
our problem as it uses the thresholding operation h(k,t) that produces (k, t)-sparse vectors. This
structured IHT was first considered in Baraniuk et al. (2010). It gives better theoretical guarantees
and practical performance in our CRD application than the standard IHT, which would instead use
the thresholding operation h(k+t)that produces (k + t)-sparse vectors. For '2 or '∞ attacks, the
recovery error for IHT would (in general) be larger due to the need to include a term for the `2
norm of the tail of the noise vector e. This, in turn, produces worse expected performance of the
recovery defense. Therefore we only use Algorithm 1 for 'o-norm attacks. We note that the results
of Theorem 1 allow for values ofk andt greater than or equal to Theorem 2.2. of Bafna et al. (2018).
Algorithm 2: Basis Pursuit (BP).
Procedure: BP (y, A, η).
Input: y ∈ Cm, A ∈ Cm×N, and η ≥ 0.
x# = arg minz∈CN kz k1 subject tokAz - y k2 ≤ η
return x#
We utilize BP for `0 and `2 norm attacks. In the `0 norm case, BP allows us to provide recovery
guarantees for larger values of k and t than IHT. For instance, in the case of MNIST and Fashion-
MNIST, IHT (equation (4) of Theorem 1) allows us to set k = 4 and t = 3, whereas BP (equation
(7) of Theorem 2) allows us to set k = 8 and t = 8.
In the case of `2 norm attacks, BP is applied with A = F-1, a unitary matrix. As unitary matrices are
isometries in `2 norm, BP provides good recovery guarantees for such matrices, and hence against
`2 norm attacks.
Algorithm 3: Modified Dantzig Selector (DS).
Procedure: DS(y, A, η).
Input: y ∈ Cm, A ∈ Cm×N, and η ≥ 0.
x# =argmi□z∈cN ∣∣z∣∣ι subject to ∣∣A*(Az - y)k∞ ≤ √nη,	IlAz - y∣∣∞ ≤ η
return x#
We utilize DS for '∞ norm attacks. The standard Dantzig Selector algorithm does not have the
additional constraint ∣Az - y∣∞ ≤ η. Our modified Dantzig Selector includes this constraint for
the following reason. In our application, A = F-1 and we want the reconstruction Ax# = F-1x#
to be close to the original image x, so that they are classified identically. Thus, we want to the search
space for x# to be restricted to those z ∈ CN such that ∣Az - x∣∞ is small. Note, for any z ∈ CN,
IlAz - X∣∣∞ ≤ IlAz - y∣∞ + I∣χ - y∣∣∞. In an '∞-attack, ∣χ - y∣∞ = ∣∣e∣∞ is already small.
Thus it suffices to require ∣Az - y ∣∞ is small. We experimentally illustrate the improvement in
reconstruction due to the additional constraint in Section 4.3 (Figure 4, Table 4).
Remarks on Reverse-Engineered Attacks. As observed in Bafna et al. (2018), x[0] in Algorithm 1,
can be initialized randomly to defend against a reverse-engineered attack. In the case of Algorithm
2 and Algorithm 3, the minimization problems can be posed as semi-definite programming prob-
lems. If solved with interior point methods, one can use random initialization of the central path
parameter and add randomness to the stopping criterion. This makes recovery non-deterministic
and consequently non-trivial to create a reverse-engineered attack.
3.3	Recovery Guarantees
LetF ∈ Cn×n be a unitary matrix andI ∈ Cn×n be the identity matrix. Define A = [F, I] ∈ Cn×2n
and let y = A[x, e]T = Fx + e, where X,e ∈ Cn. Let 1 ≤ k,t ≤ n be integers.
3
Under review as a conference paper at ICLR 2020
Theorem 1 ('0-normIHT). Assume |Fj|2 ≤ C and e is t-sparse. Let x[T +1] = IHT(y,A,k,t,T)
where x[T +1] = [x[T +1],e[T +1]]T ∈ C2n with x[T +1],e[T +1] ∈ Cn.
Define P := √27 qqckt, T (1 一 ρ) := √3 j 1 + 2^^. If 0 < ρ < 1 ,then:
kx[T +1] - xh(k)k2 ≤ PPT +1) Jkxh(k)k2 + kek2 + T kxt(k)k2
Moreoverfor any 0 < e < 1 and any T ≥ ( klg(1∕e)+log0√kχp)(k)k2 + kek2)), we get
kx[T +1] — xh(k)k2 ≤ τ∣∣xt(k)k2 + e
(3)
(4)
Now define P := 2√2y Cnt, T(1 一 ρ) := 2. If 0 < ρ < 1, then:
kx[T +1] 一 xh(k)∣2 ≤ P(T +1)kxh(k)k2 + T(kxt(k) ∣∣2 + ∣∣e∣2)	(5)
Moreoverfor any 0 < e < 1 and any T ≥ (klg(1∕e)l+gθg∕ρχh(k)k2)), we get
kx[T +1] - xh(k)∣2 ≤ T(IIxt(k)k2 + ∣∣ek2) + e	⑹
Let us explain how to interpret the recovery guarantees provided by Theorem 1. The inequalities (3),
(4), (5), (6) provide an upper bound on the size of ||x[T +1] 一 xh(k) ∣∣2. Since F is a unitary matrix,
kx[T +1] 一 xh(k) ∣∣2 equals ||Fx[T +1] 一 Fxh(k)∣∣2, which is the difference between the reconstructed
image Fx[T +1] and the compressed image Fxh(k)(which is a compressed version of the original
image x). So the inequalities of Theorem 1 tell us how close the reconstructed image must be to
the compressed image, and thus indicates how confident we should be that the classification of the
reconstructed image will agree with the classification of the compressed image. In other words, the
inequalities tell us how likely it is that the CRD scheme using IHT will be able to recover the correct
class of the original image, and thus defend the classifier from the adversarial attack. The presence
of the norm of the tail xt(k) in the upper bounds indicates that the CRD scheme should be more
effective when the original image is closer to being perfectly k-sparse in the transformed basis. The
ratio kt/n in the upper bounds (via P and T) suggests that smaller values of k and t relative to n
(i.e., sparser transformed images x and error vectors e) will lead to the CRD being more effective.
The experiments in Section 4 will demonstrate these phenomena.
Let us compare Theorem 1 to the similar Theorem 2.2 of Bafna et al. (2018). We observe that (3)
and (4) allow larger values of k and t than Theorem 2.2 of Bafna et al. (2018). This is because the
authors of Bafna et al. (2018) prove their results using Theorem 4 of Baraniuk et al. (2010), which
is more restrictive for the values of k and t. We do not use Theorem 4 of Baraniuk et al. (2010).
Instead we use (a modified form of) Theorem 6.18 of Foucart & Rauhut (2017) to get (3) and (4).
Both Theorem 4 of Baraniuk et al. (2010) (used by Bafna et al. (2018)) and Theorem 6.18 of Foucart
& Rauhut (2017) (used by us here) take as input the Restricted Isometry Property (RIP) stated in
Theorem 7. We and Bafna et al. (2018) both essentially prove the same RIP, although the proof
methods are different. We use a standard Gershgorin disc theorem argument to bound eigenvalues,
while Bafna et al. (2018) perform a direct estimation using the triangle inequality and AM-GM
inequality.
We turn now to (5) and (6), which provide recovery guarantees for larger values of k and t than
(3) and (4), at the expense of the extra error term ∣e∣2. Our proof of (5) and (6) is novel. It relies
on explicitly expanding one iteration of IHT in matrix form and using the structure of the resulting
matrix form to bound the approximation error at iteration T in terms of the error at iteration T 一 2.
We then use an inductive argument as in Theorem 6.18 of Foucart & Rauhut (2017) to get (5) and
(6).
Next, We consider the recovery error for 'o-norm bounded noise with BP instead of IHT. We note
that since Algorithm 2 is not adapted to the (k, t)-sparse structure of vector to be recovered, we
do not expect the guarantees to be particularly strong. However, providing bounds for BP is useful
as there are cases when BP provides recovery guarantees for when recovering a larger number of
coefficients (k) and a larger `0 noise budget (t) than IHT.
4
Under review as a conference paper at ICLR 2020
Theorem 2 ('0-normBP). Assume |Fij|2 ≤ C. Define
max{k,t}c	°
n
√k +1 B = 1+ + δk,t
(I - δk,t) ，	1 - δk,t
If 0 < δk,t < 1 and 0 < θ < 1, then for x# = BP (y,A, kXt(k)k2), we have the error bound
kx# - xh(k)k2 ≤ ( 2τ√√k + t (1 + 1 -δk t ) + 2τ) kxt(k)k2	G)
where we write x# = [x#, e#]T ∈ C2n with x#, e# ∈ Cn.
Note that the recovery error in (7) is O((√k +1)k^t(k)k2), which means that We should not expect
recovery to be close when the attacker has a large '0 noise budget or when X is not sparse. Also
observe that the recovered vector x# is not necessarily k-sparse. The recovery error still captures
the difference in the original image FX and the reconstructed image Fx#, where a smaller recovery
error should once again indicate that our classifier would make the correct prediction. Our third
result covers the case when the noise is bounded in '2-norm.
Theorem 3	('2 -norm BP). If ∣∣ek2 ≤ η, then for x# = BP (y, F, η), we have the error bound
kx# -xkι ≤ 2 (kxt(k)kι + 2√kη)
2
kx# 一 xk2 ≤ √=kxt(k)kι + 6η
(8)
(9)
Finally, we provide recovery guarantees when the noise is bounded in '∞-norm.
Theorem 4	('∞-norm DS). If kek∞ ≤ η, then for x# = DS(y, F, η), we have the error bound
kx# - xkι ≤ 2 (kxt(k)kι + 2k√nη)	(IO)
2
kx# - xk2 ≤ √jkxt(k)kι + 6√knη	(II)
The proofs of Theorem 3 and Theorem 4 are based on standard arguments in compressive sensing
that rely on establishing the so-called robust null space property of the matrix. Note that the results
of Theorem 3 and Theorem 4 also bound the norm difference of the original image Fx and the
reconstructed image Fx#, where x# has no sparsity guarantees. Next, observe that the results of
Theorem 4 incur a factor of √n in the error bounds due to the constraint kA*(Az 一 y)k∞ ≤ √nη
in Algorithm 3 which is required to prove the robust null space property. Finally, we note that the
additional constraint added to Algorithm 3 does not affect the proof of Theorem 4.
3.4 Related Work
The authors of Bafna et al. (2018) introduced the CRD framework which inspired this work. In
fact, Theorem 2.2 of Bafna et al. (2018) also provides an approximation error bound for recovery
via IHT. Note that a hypothesis t = O(n/k) has accidentally been dropped from their Theorem 2.2,
though it appears in their Lemma 3.6. By making the implied constants explicit in the argument of
Bafna et al. (2018), one sees that their Theorem 2.2 is essentially the same as (3) and (4) in Theorem
1 above. For more details, see the proof of Theorem 1 in Appendix A. Note that our recovery error
bounds for IHT in (5) and (6) of Theorem 1 do not have analogs in Bafna et al. (2018). They hold
for larger values of k and t at the expense of the additional error term kek2 .
Other works that provide guarantees include (Hein & Andriushchenko (2017)) and (Cisse et al.
(2017)) where the authors frame the problem as one of regularizing the Lipschitz constant of a
network and give a lower bound on the norm of the perturbation required to change the classifier
decision. The authors of Sinha et al. (2017) use robust optimization to perturb the training data
and provide a training procedure that updates parameters based on worst case perturbations. A
similar approach to (Sinha et al. (2017)) is (Wong & Kolter (2017)) in which the authors use robust
optimization to provide lower bounds on the norm of adversarial perturbations on the training data.
5
Under review as a conference paper at ICLR 2020
In Lecuyer et al. (2018), the authors use techniques from Differential Privacy (Dwork et al. (2014))in
order to augment the training procedure of the classifier to improve robustness to adversarial inputs.
Another approach using randomization is Li et al. (2018) in which the authors add i.i.d. Gaussian
noise to the input and provide guarantees of maintaining classifier predictions as long as the '2 -norm
of the attack vector is bounded by a function that depends on the output of the classifier.
Most defenses against adversarial inputs do not come with theoretical guarantees. Instead, a large
body of research has focused on finding practical ways to improve robustness to adversarial inputs
by either augmenting the training data (Goodfellow et al. (2015)), using adversarial inputs from
various networks (Tramer et al. (2017)), or by reducing the dimensionality of the input (XU et al.
(2017)). For instance, Madry et al. (2017) use robust optimization to make the network robust
to worst case adversarial perturbations on the training data. However, the effectiveness of their
approach is determined by the amount and quality of training data available and its similarity to the
distribution of the test data. An approach similar to ours but without any theoretical guarantees is
(Samangouei et al. (2018)). In this work, the authors use Generative Adversarial Networks (GANs)
to estimate the distribution of the training data and during inference, use a GAN to reconstruct a
non-adversarial input that is most similar to a given test input. We now provide a brief overview on
the field of compressive sensing.
Though some component ideas originated earlier in other fields, the field of compressive sensing
was initiated with the work of CandeS et al. (2006) and Donoho et al. (2006) in which the authors
studied the problem of reconstructing sparse signals using only a small number of measurements
with the choice of a random matrix. The reconstruction was performed using `1 -minimization (i.e.,
Basis Pursuit) which was shown to produce sparse solutions even in presence of noise; see also
Donoho & Elad (2003; 2006); Donoho & Huo (2001). Some of the earlier work in extending com-
pressive sensing to perform stable recovery with deterministic matrices was done by Candes & Tao
(2005) and Candes et al. (2006), where the authors showed that recovery of sparse vectors could be
performed as long as the measurement matrix satisfied a restricted isometry hypothesis. Blumensath
& Davies (2009) introduced IHT as an algorithm to recover sparse signals which was later modified
in Baraniuk et al. (2010) to reduce the search space as long as the sparsity was structured. The
standard DS algorithm was introduced in Candes et al. (2007) in order to perform stable recovery in
the presence of '∞ noise.
4 Experiments
All of our experiments are conducted on CIFAR-10 (Krizhevsky (2009)), MNIST (LeCun), and
Fashion-MNIST (Xiao et al. (2017)) datasets with pixel values of each image normalized to lie in
[0, 1]. Each experiment is conducted on a set of 1000 points sampled uniformly at random from
the test set of the respective dataset. For every experiment, we use the Discrete Cosine Transform
(DCT) and the Inverse Discrete Cosine Transform (IDCT) denoted by the matrices F ∈ Rn×n and
FT ∈ Rn×n respectively. That is, for an adversarial image y ∈ R√n× √n, such that, y = x+e, We let
X = Fx, and X = FTx, where χ,X ∈ Rn and e ∈ Rn is the noise vector. For an adversarial image
y ∈ Rn×x Vn×c, that contains C channels, we perform recovery on each channel independently by
considering ym, = Xm + em,, where Xm = Fxm, Xm = FTXm for m = 1,...,c. The value k
denotes the number of largest (in absolute value) DCT coefficients used for reconstruction of each
channel, and the value t denotes the `0 noise budget for each channel. We implement Algorithm 2
and Algorithm 3 using the open source library CVXPY (Diamond & Boyd (2016)).
We now outline the neural network architectures used for experiments in Section 4.1 and 4.2. For
CIFAR-10, we use the network architecture of He et al. (2016) while the network architecture for
MNIST and Fashion-MNIST datasets is provided in Table 5 of the Appendix. We train our networks
using the Adam optimizer for CIFAR-10 and the AdaDelta optimizer for MNIST and Fashion-
MNIST. In both cases, we use a cross-entropy loss function. We train the each neural network
according to the CRD framework stated in Section 3.1. The code to reproduce our experiments is
available here: https://github.com/anonymousiclrcompressive/iclr2020.
6
Under review as a conference paper at ICLR 2020
Orig. Acc.	OPA. Acc	IHT. Acc.
77.4%	0.0%	71.8%
Table 1: Effectiveness of CRD against OPA. The first column lists the accuracy of the network on
original images and the OPA Acc. column shows the network’s accuracy on adversarial images. The
IHT. Acc. column shows the accuracy of the network on images reconstructed using IHT.
4.1	DEFENSE AGAINST `0 -NORM ATTACKS
This section is organized as follows: first we examine CRD against the One Pixel Attack (OPA) (Su
et al. (2019)) for CIFAR-10. We only test the attack on CIFAR-10 as it is most effective against
natural images and does not work well on MNIST or FASHION-MNIST. We note that this attack
satisfies the theoretical constraints for t provided in Theorem 1, hence allowing us to test how well
CRD works within existing guarantees. Once we establish the effectiveness of CRD against OPA,
We then test it against two other 'o-norm bounded attacks: Carlini and Wagner (CW) 'o-norm attack
(Carlini & Wagner (2017)) and the Jacobian based Saliency Map Attack (JSMA) (Papernot et al.
(2016)).
4.1.1	One Pixel Attack
We first resize all CIFAR-10 images to 125 × 125 × 3 while maintaining aspect ratios to ensure
that the data falls under the hypotheses of Theorem 1 even for large values of k . The OPA attack
perturbs exactly one pixel of the image, leading to an `0 noise budget of t = 3 per image. The `0
noise budget of t = 3 per image allows us to use k = 275 per channel. Table 1 shows that OPA is
very effective against natural images and forces the network to mis-classify all previously correctly
classified inputs.
Original	OPA	IHT-Rec
Figure 1: The original image is shown in the first column, the adversarial image in the second
column, and image reconstructed using IHT is shown in the third column.
We test the performance of CRD in two ways: a) reconstruction quality b) network performance
on reconstructed images. In order to analyse the reconstruction quality of Algorithm 1, we do the
following: for each test image, we use OPA to perturb the image and then use Algorithm 1 to
approximate its largest (in absolute value) k = 275 DCT co-efficients. We then perform the IDCT
on these recovered co-efficients to generate reconstructed images. We illustrate reconstruction on a
randomly selected image from the test set in Figure 1.
Noting that Algorithm 1 leads to high quality reconstruction, we now test whether network accuracy
improves on these reconstructed images. To do so, we feed these reconstructed images as input
to the network and report its accuracy in Table 1. We note that network performance does indeed
improve as network accuracy goes from 0.0% to 71.8% using Algorithm 1. Therefore, we conclude
that CRD provides a substantial improvement in accuracy in against OPA.
4.1.2	CW-'o Attack and JSMA
Having established the effectiveness of CRD against OPA, we move onto the CW 'o-norm attack
and JSMA. We note that even when t is much larger than the hypotheses of Theorem 1 and Theorem
2, we find that Algorithms 1 and 2 are still able to defend the network. We hypothesize that this
maybe related to the behavior of the RIP ofa matrix for “most” vectors as opposed to the RIP for all
vectors, and leave a more rigorous analysis for a follow up work.
7
Under review as a conference paper at ICLR 2020
Figure 2: Reconstruction quality of images using IHT and BP. The first column shoWs randomly
selected original images from the test set, While the second and fifth column shoW the adversarial
images. Reconstructions using IHT are labeled IHT-Rec and using BP are labeled BP-Rec. We shoW
reconstructions in columns three, four, six, and seven.
Dataset	Orig. Acc.	C&W '0				tavg	Acc.	JSMA	
		tavg	Acc.	IHT Acc.	BP Acc.			IHT Acc.	BP Acc.
CIFAR-10	84.9%	~~L8~	8.7%	83.0%	67.0%		2.7%	63.2%	67.3%
MNIST	98.8%		0.9%	84.2%	55.9%	~~∏~	56.5 %	90.1%	67.4%
F-MNIST	91.8%	~T6-	5.27%	84.1%	71.4%	~17~	62.6 %	83.3%	72.0%
Table 2: The tavg column lists the average adversarial budget for each attack. The Orig. Acc column
lists the accuracy of the network on original test inputs, the Acc. columns under C&W `0 and
JSMA list network accuracy on adversarial inputs. The IHT Acc. and the BP Acc. columns list the
accuracy of the network on inputs that have been corrected using IHT and BP respectively.
We follow the procedure described in Section 4.1.1 to analyze the quality of reconstructions for
Algorithm 1 and Algorithm 2 in Fig 2. In each case it can be seen that both algorithms provide high
quality reconstructions for values oft that are well outside the hypotheses required by Theorem 1 and
Theorem 2. We report these t values and the improvement in network performance on reconstructed
adversarial images using CRD in Table 2.
4.2	DEFENSE AGAINST `2 -NORM ATTACKS
In the case of '2-norm bounded attacks, We use the CW '2-norm attack (Carlini & Wagner (2017))
and the Deepfool attack (Moosavi-Dezfooli et al. (2016)) as they have been shown to be the most
poWerful. We note that Theorem 3 does not impose any restrictions on k or t and therefore the
guarantees of equations (8) and (9) are applicable for recovery in all experiments of this section.
Original	CW-'2	BP-Rec DF BP-Rec
Figure 3: Reconstruction quality of images using BP. The first columns shoWs the original images,
While the adversarial images are shoWn in the second and fourth column. The reconstructions are
shoWn in columns three and five.
ln7∕
“7
起 2
7∕
8
Under review as a conference paper at ICLR 2020
Dataset	Orig. Acc.	C&W '2			Deepfool		
		'2 avg	Acc.	BP Acc.	'2 avg	Acc.	BP Acc.
CIFAR-10-	84.9%	0.12	8.7%	72.3%	0.11	7.7%	71.6%
MNIST	99.17%	1.35	0.9%	92.4%	1.72	1.1 %	90.7%
Fashion-MNIST	90.3%	0.61	5.4%	78.3%	0.63	5.5%	76.4%
Table 3: The 也叫 column lists the average '2-norm of the attack vector. The Orig. Acc column lists
the accuracy of the network on original test inputs, while the Acc. columns under C&W `2 and DF
columns report network accuracy on adversarial inputs. BP Acc. columns lists the accuracy of the
network on inputs reconstructed using BP.
The reconstruction quality is shown in Figure 3. It can be noted that reconstruction using Algorithm
2 is of high quality for all three datasets. In order to check whether this high quality reconstruction
also leads to improved performance in network accuracy, we test each network on reconstructed
images using Algorithm 2. We report the results in Table 3 and note that Algorithm 2 provides a
substantial improvement in network accuracy for each dataset and each attack method used.
4.3	Defense against '∞-norm attacks
For '∞-norm bounded attacks, We use the BIM attack (Kurakin et al. (2016)) as it is has been shown
to be very effective and also allows US to control the '∞-norm of the attack vector explicitly. We note
that while the CW '∞-norm attack (Carlini & Wagner (2017)) has the ability to create attack vectors
with '∞-norm less than or equal to BIM, it is computationally expensive and also does not allow
one to pre-specify a value for the '∞-norm of an attack vector. Therefore, we limit our experimental
analysis to the BIM attack. Note that for any attack vector e, ∣∣e∣∣2 ≤ √n∣∣e∣∣∞ hence allowing '∞-
norm attacks to create attack vectors with large '2-norm. Therefore, we could expect reconstruction
quality and network accuracy to be lower when compared to '2-norm attacks.
Original With Constraint No Constraint
Figure 4: Comparison of images reconstructed using Algorithm 3 (With Constraint) with images
reconstructed using Ds without the additional constraint (No Constraint).
In figure 4, we compare the reconstruction quality of images reconstructed with Algorithm 3 to those
reconstructed using Ds without the additional constraint. As can be noted from the figure, images
reconstructed using Ds without the additional constraint may not produce meaningful images. This
is also reflected in Table 4, which shows that the accuracy of the network is roughly random on
images reconstructed without the additional constraint.
We show examples of original images, adversarial images, and their reconstructions using Algorithm
3 in Figure 5. Finally, we report the network performance on reconstructed inputs using Algorithm
3 in Table 4 and also compare this to the performance on inputs reconstructed using Ds without the
additional constraint. We note that Algorithm 3 provides an increase in network performance against
reconstructed adversarial inputs. However, the improvement in performance is not as substantial as
it was against '0 or '2-norm attacks.
9
Under review as a conference paper at ICLR 2020
Dataset	Orig. Acc.	'∞ ∞avg	Acc.	BIM ModifiedDS Acc.	DS Acc.
CIFAR-10-	84.9%	0.015	7.4%	494%	17.6%
MNIST	99.17%	0.15	4.9%	747%	-10%-
FaShiOn-MNIST	90.3%	0.15	5.3%	57.5%	11.1%
Table 4: The '∞avg column lists the '∞-norm of each attack vector, Orig. Acc. and BIM Acc.
columns list the accuracy of the network on the original and adversarial inputs respectively, and the
Modified DS Acc. column lists the accuracy of the network on inputs reconstructed using Algorithm
3. We also show accuracy of the network on images reconstructed with DS (without the additional
constraint) in the DS Acc. column.
Figure 5: Reconstruction quality of images using DS. The first column shows the original images,
while the second columns shows adversarial images and the third columns shows reconstructions
using Algorithm 3 respectively.
5 Conclusion
We provided recovery guarantees for corrupted signals in the case of 'o-norm, '2-norm, and '∞-
norm bounded noise. We were able to utilize these results in CRD and improve the performance of
neural networks substantially in the case of 'o-norm, '2-norm and '∞-norm bounded noise. While
'o-norm attacks don,t always satisfy the constraints required by Theorem 1 and Theorem 2, We
showed that CRD is still able to provide a good defense for values of t much larger than allowed in
the guarantees. The guarantees of Theorem 3 and Theorem 4 were applicable in all experiments and
CRD was shown to improve network performance for all attacks.
10
Under review as a conference paper at ICLR 2020
References
Mitali Bafna, Jack Murtagh, and Nikhil Vyas. Thwarting adversarial examples: An l_0-robust sparse
fourier transform. In Advances in Neural Information Processing Systems, pp. 10075-10085,
2018.
Richard G. Baraniuk, Volkan Cevher, Marco F. Duarte, and Chinmay Hedge. Model-based com-
pressive sensing. IEEE Transactions on Information Theory, 56(4):1982-2001, 2010.
Thomas Blumensath and Mike E Davies. Iterative hard thresholding for compressed sensing. Ap-
plied and computational harmonic analysis, 27(3):265-274, 2009.
Emmanuel Candes and Terence Tao. Decoding by linear programming. arXiv preprint
math/0502327, 2005.
Emmanuel Candes, Terence Tao, et al. The dantzig selector: Statistical estimation when p is much
larger than n. The annals of Statistics, 35(6):2313-2351, 2007.
Emmanuel J Candes, Justin Romberg, and Terence Tao. Robust uncertainty principles: Exact signal
reconstruction from highly incomplete frequency information. IEEE Transactions on information
theory, 52(2):489-509, 2006.
Emmanuel J Candes, Justin K Romberg, and Terence Tao. Stable signal recovery from incomplete
and inaccurate measurements. Communications on Pure and Applied Mathematics: A Journal
Issued by the Courant Institute of Mathematical Sciences, 59(8):1207-1223, 2006.
Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017
IEEE Symposium on Security and Privacy (SP), pp. 39-57. IEEE, 2017.
Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas Usunier. Parseval
networks: Improving robustness to adversarial examples. In Proceedings of the 34th International
Conference on Machine Learning-Volume 70, pp. 854-863. JMLR. org, 2017.
Steven Diamond and Stephen Boyd. CVXPY: A Python-embedded modeling language for convex
optimization. Journal of Machine Learning Research, 17(83):1-5, 2016.
David L Donoho and Michael Elad. Optimally sparse representation in general (nonorthogonal)
dictionaries via 1 minimization. Proceedings of the National Academy of Sciences, 100(5):2197-
2202, 2003.
David L Donoho and Michael Elad. On the stability of the basis pursuit in the presence of noise.
Signal Processing, 86(3):511-532, 2006.
David L Donoho and Xiaoming Huo. Uncertainty principles and ideal atomic decomposition. IEEE
transactions on information theory, 47(7):2845-2862, 2001.
David L Donoho et al. Compressed sensing. IEEE Transactions on information theory, 52(4):
1289-1306, 2006.
Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Foundations
and TrendsR in Theoretical Computer Science, 9(3-4):211-407, 2014.
Simon Foucart and Holger Rauhut. A Mathematical Introduction to Compressive Sensing. 2017.
I	.J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. In
International Conference on Learning Representations, 2015. URL http://arxiv.org/
abs/1412.6572.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
M. Hein and M. Andriushchenko. Formal guarantees on the robustness of a classifier against ad-
versarial manipulation. In Advances in Neural Information Processing Systems 30: Annual Con-
ference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA,
USA, pp. 2263-2273, 2017.
11
Under review as a conference paper at ICLR 2020
A. Krizhevsky, I. Sutskever, and G. E Hinton. Imagenet classification with deep convolutional neural
networks. In Advances in neural information processing Systems, pp. 1097-1105, 2012.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, Citeseer,
2009.
Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial examples in the physical world.
arXiv preprint arXiv:1607.02533, 2016.
Yann LeCun. The mnist database of handwritten digits. http://yann. lecun. com/exdb/mnist/.
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. arXiv preprint arXiv:1802.03471,
2018.
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Second-order adversarial attack and
certifiable robustness. arXiv preprint arXiv:1809.03113, 2018.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017.
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. Deepfool: a simple and
accurate method to fool deep neural networks. In Proceedings of the IEEE conference on com-
puter vision and pattern recognition, pp. 2574-2582, 2016.
Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, and Ananthram
Swami. The limitations of deep learning in adversarial settings. In 2016 IEEE European Sympo-
sium on Security and Privacy (EuroS&P), pp. 372-387. IEEE, 2016.
Pouya Samangouei, Maya Kabkab, and Rama Chellappa. Defense-gan: Protecting classifiers against
adversarial attacks using generative models. arXiv preprint arXiv:1805.06605, 2018.
Aman Sinha, Hongseok Namkoong, and John Duchi. Certifying some distributional robustness with
principled adversarial training. arXiv preprint arXiv:1710.10571, 2017.
Jiawei Su, Danilo Vasconcellos Vargas, and Kouichi Sakurai. One pixel attack for fooling deep
neural networks. IEEE Transactions on Evolutionary Computation, 2019.
I. Sutskever, O. Vinyals, and Q. V Le. Sequence to sequence learning with neural networks. In
Advances in neural information processing systems, pp. 3104-3112, 2014.
C. Szegedy, W. Zaremba, and I. Sutskever. Intriguing properties of neural networks. International
Conference on Learning Representations, 2014.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.
F. Tramer, A. Kurakin, N. Papernot, D. Boneh, and P. McDaniel. Ensemble Adversarial Training:
Attacks and Defenses. ArXiv e-prints, May 2017.
Eric Wong and J Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. arXiv preprint arXiv:1711.00851, 2017.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmark-
ing machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.
W. Xu, D. Evans, and Y. Qi. Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial
Examples. ArXiv e-prints, May 2017.
12
Under review as a conference paper at ICLR 2020
A Appendix
A.1 Restricted Isometry Property
We first establish the restricted isometry property for certain structured matrices. First, we give some
definitions.
Definition 5. Let A be a matrix in Cm×N , let M ⊆ CN, and let δ ≥ 0. We say that A satisfies the
M -restricted isometry property (or M-RIP) with constant δ if
(1 - δ)kxk22 ≤ kAxk22 ≤ (1 + δ)kxk22
for all x ∈ M .
Definition 6. We define Mk to be the set of all k-sparse vectors in CN and similarly define Mk,t to
be the set of (k, t)-sparse vectors in C2n. In other words, Mk,t is the following subset of C2n:
Mk,t = {x = [xi X2]τ ∈ C2n ; X1 ∈ Cn,X2 ∈ Cn, IEko ≤ k, kx2k0 ≤ t}
We define Sk,t to be the following collection of subsets of {1, . . . , 2n}:
Sk,t = {S1 ∪S2 ; S1 ⊆ {1,...,n},S2 ⊆ {n+ 1,...,2n},card(S1) ≤ k,card(S2) ≤ t}
Note that Sk,t is the collection of supports of vectors in Mk,t .
Theorem 7.	Let A = [F I] ∈ Cn×2n, where F ∈ Cn×n is a unitary matrix with |Fj ∣2 ≤ C and
I ∈ Cn×n is the identity matrix. Then
≤ IAxI22
(12)
for all x ∈ Mk,t. In other words, A satisfies the Mk,t-RIP property with constant
Proof. In this proof, ifB denotes an matrix in Cn×n, then λ1(B), . . . , λn(B) denote the eigenvalues
of B ordered so that ∣λι(B)∣ ≤ ∙∙∙ ≤ ∣λn(B)∣. It suffices to fix an S = Si ∪ S? ∈ S" and prove
(12) for all non-zero x ∈ CS .
Since AS AS is normal, there is an orthonormal basis of eigenvectors ui,..., uk+t for AS AS, where
Ui corresponds to the eigenvalue λi(ASAS). For any non-zero X ∈ CS, We have X = PkM Ciui
for some ci ∈ C, so
kAxk2 = hAS ASχ, Xi = Pk=+ι λi(AS as )c2
kχ∣2 - —Rx— -	PStc
(13)
Thus it will suffice to prove that ∣λi(AS AS) 一
for all i. Moreover,
∣%(ASAs) 一 1| = ∣%(ASAS — I)| =	X( ((ASAs - I)*(ASAs - I))	(14)
where the last equality holds because ASAS — I is normal. By combining (13) and (14), we see
that (12) will hold upon showing that the eigenvalues of (ASAS — I)* (ASAS — I) are bounded by
ckt/n.
So far we have not used the structure of A, but now we must. Observe that (AS AS — I )* (AS AS — I)
is a block diagonal matrix with two diagonal blocks of the form X *X and XX *. Therefore the three
matrices (ASAS-I)*(ASAS-I), X*X, andXX* have the samenon-zero eigenvalues. Moreover,
X is simply the matrix FS1 with those rows not indexed by S2 deleted. The hypotheses on F imply
that the entries of X *X satisfy |(X *X )j| ≤ C. So the Gershgorin disc theorem implies that each
eigenvalue λ of X*X and (hence) of (ASAS - I)*(ASAS - I) satisfies ∣λ∣ ≤ 等.
□
13
Under review as a conference paper at ICLR 2020
A.2 Iterative Hard Thresholding
First we present Theorem 8 and then use it to prove Theorem 1.
Theorem 8.	Let A ∈ Cn×2n be a matrix. Let 1 ≤ k, t ≤ n be positive integers and suppose δ3 is
a M3k,3t-RIP constant for A and that δ2 is a M2k,2t-RIP constant for A. Let x ∈ C2n, r ∈ Cn,
y = Ax + r, and S ∈ Sk,t. Letting x[T +1] = IHT(y,A,k,t,T), if δ3 < 1/√3, then we have the
approximation error bound
||x[T +1] - XS∣∣2 ≤ P(T+1)kx[0] - XSI∣2 + T∣∣Axs + r∣∣2
where P := √3δ3 < 1 and (1 — ρ)τ = √3√Γ+^δ2 ≤ 2.18. Thus, the first term on the right goes to
0 as T goes to ∞.
Theorem 8 is a modification of Theorem 6.18 of Foucart & Rauhut (2017). More specifically,
Theorem 6.18 of Foucart & Rauhut (2017) considers M3k, M2k, and Sk in place of M3k,3t and
M2k,2t and Sk,t and any dimension N in place of 2n. The proofs are very similar, so we omit the
proof of Theorem 8. We will now prove a lemma that will be required for the proof of Theorem 1.
For the proof of Lemma 9 and Theorem 1, we use the following convention: let A ∈ Cm×N be a
matrix, then, We denote by (A)S, the m X N matrix that is obtained by starting with A and zeroing
out the columns indexed by S. Note that (A)S = A - (A)S.
Lemma 9. Let F ∈ Cn×n be a unitary matrix with |Fj ∣2 ≤ C and let S ⊆ [n] be a index set with
|S| = t. Then for any k-sparse vector z ∈ Cn, we have:
k(F*)sFzk2 ≤ 坟kz∣2
n
ProofofLemma 9. First note that (F*)s ∈ Cn×n contains only t non-zero columns since |S| = t
Therefore, we have |((F*)sF)j| ≤ ^c since |Fj∣2 ≤ n. Further, since the non-zero columns of
(F*)s are orthogonal to each other, we get ((F*)s)*(F*)s = (I)s, where I ∈ Cn×n is the identity
matrix. Using this, we have for any w ∈ Cn ,
∣(F*)SFw∣22 = h(F*)SFw, (F*)SFwi = h((F *)SF)*(F *)SF w, wi = h(F*)SFw,wi = |h(F*)SFw,wi|
Now let V ⊆ [n] be any index set with cardinality k, that is |V | = k and let z ∈ Cn be any vector
supported on V . We then get,
k(F*)sFz∣2 = K(F*)sFz,zil	= ∑>k	E((F*)sF)kjZj	I ≤ £ ∣z*l	E	l((F*)sF)kjl∣ZjI
k∈V	j∈V	k∈V	j∈V
≤ X∣z*∣( tc X Izj
k∈V	j∈V
=tckz∣2 ≤ ktckzk2
nn
where we use the fact that z is k-sparse for the last inequality.
□
Now we provide the proof for Theorem 1.
Proof of Theorem 1. Theorem 7 implies that the statement of Theorem 8 holds with
δ3 = q03n，3t and δ2 = q 02n∙2t.NOting that y =A侬h⑻ e]T+FXt⑹，Where [企九⑹ e]T ∈
Mk,t, set x[T+1] = IHT(y,A,k,t,T) and apply Theorem 8 with X = [Xh(k)e]T , r = FXt(k), and
S = supp(x). Letting x[T +1] = [X[T +1] e[T +1]]T, use the facts that |X[T +1] - Xh(k)∣2 ≤ ∣∣x[T +1] -
XSk2 and ∣FXt(k)∣2 = ∣Xt(k) ∣2∙ That will give (3). Letting T =(项同十%0方产够+⑻⑷),
14
Under review as a conference paper at ICLR 2020
gives ρT JIlxh(k)k2 + ∣∣e∣∣2 ≤ e, which can be substituted in (3) to get (4). Noting that ||e[T ]-e∣∣2 ≤
T∣∣xt(k) ∣∣2 + e, we can use the same reasoning as used in Bafna et al. (2018) to get:
llx[T+1] -xh(k)k2
llx[T +1] -xh(k)k∞
(15)
(16)
which are the essentially the same as the results of Theorem 2.2 in Bafna et al. (2018).
Now we prove (5). Write x[T] = (z[T])h(k,t), where z[T] = x[T-1] + A*(y 一 Ax[T-1]). Further,
write z[T] = [z]T] z2T]]T ∈ C2n, where z[T],z2T] ∈ Cn. Note that x[T] = (z]T])h(k). Therefore,
We have z[T] = F*(y 一 e[T-1]), where e[T-1] = (y — Fx[T-2])h(t). Now let S be the set of
indices selected by the hard thresholding operation h(t) to get e[T -1] . Then observe that z1[T] =
F * (y - (y 一 Fx[T-2])s). Next, note that kz[T] — x[T] ∣∣2 ≤ ∣∣z]T] — xh(k)k2 as x[T] is abest k-sparse
approximation to z1[T]. We can thus write,
Il(ZIT] - xh(k)) - (x[T] - xh(k))k2 =隈『]-xh(k)k2 - 2Rehz；' - xh(k),x[T] - xh(k)i + kx[T] - xh(k)k2
Therefore, we have,
llx[T] - xh(k)k2 ≤ 2Rehz1T] - xh(k),x[T] - xh(k)i
≤ 2|hz1T] - xh(k),x[T] - xh(k)il
≤ 2kz1T] - xh(k)∣∣2kx[T] - xh(k)∣2
If∣x[T] - xh(k)∣2 > 0, then ∣∣x[T] - xh(k)∣2 ≤ 2∣z1T]-知⑹12. Now note that
z1T] = x + F*e - F*(F(x - x[T-2]) + e)S
=x + F*e - (F*)s(F(x - x[T-2]) + e)
=x+(F* - (F*)s)e - (F*)sF(x - x[T-2])
Using the fact that (F *)s = F * - (F *)s , we can simplify the above to get:
kz1T] - xh(k)∣2 = k(F*)sFxt(k) + (F*)se - (F*)sF(x“k) - x[T-2])∣2
Therefore,
kx[T] - xh(k)k2 ≤ 2 (k(F*)sFk2→2kxt(k)k2 + ∣(F*)sk2→2kek2 + ∣(F*)sF(沏⑹-x[T-2])∣2)
≤ 2 (kxt(k) ∣2 + kek2) + 2k(F*)sF(xh(k) - x[T-2])∣2
where we use ∣∣(F*)s∣∣2→2 ≤ ∣∣F*k2→2 = 1. Now since xh(k) - x[T-2] is 2k-sparse, we can use
the result of Lemma 9 to get:
∣∣x[T]
-xh(k)∣2 ≤ 2 (llxt(k)l∣2 + IIeII
-xh(k) ∣∣2
Now let P = 2√2y 等,T(1 - ρ) = 2 and note that if ρ < 1, we can use induction on T to get (5).
Then for any 0 < e < 1 and any T ≥ (log。/Iogog"("，k2)), We have ρτ(∣xh(k)∣2) ≤ e which
gives us (6).
□
15
Under review as a conference paper at ICLR 2020
A.3 Basis Pursuit
Definition 10. The matrix A ∈ Cm×N satisfies the robust null space property with constants 0 <
ρ < 1, τ > 0 and norm ∣∣ ∙ ∣∣ if for every set S ⊆ [N] with Card(S) ≤ S and for every V ∈ CN We
have
IlvSkι ≤ PllvSkι + TIlAvIl
Definition 11. The matrix A ∈ Cm×N satisfies the 'q robust null space property of order S with
constants 0 <ρ< 1, τ > 0 and norm ∣∣ ∙ ∣∣ if for every set S ⊆ [N ] with card(S) ≤ S and for every
V ∈ CN wehave	kvs kq≤ sɪ PkvS kι + τ IAvk
Note that if q = 1 then this is simply the robust null space property.
The proof of Theorem 2 requires the following theorem (whose full proof is given in the Foucart &
Rauhut (2017)).
Theorem 12 (Theorem 4.33 in Foucart & Rauhut (2017)). Let a1, . . . , aN be the columns of A ∈
Cm×N, let x ∈ CN with S largest absolute entries supported on S, and let y = Ax + e with
∣e∣2 ≤ η. For δ, β, γ, θ, τ ≥ 0 with δ < 1, assume that:
∣ASAS - I∣2→2 ≤ δ, max ∣∣ASaι∣2 ≤ β,
l∈S
and that there exists a vector U = A*h ∈ CN with h ∈ Cm such that
∣∣us — sgn(XS)∣∣2 ≤ Y,	∣∣Usk∞ ≤ θ,	and ∣∣h∣2 ≤ T√s.
If ρ := θ + (I-δ) < 1, then a minimizer x# of ∣∣z∣ι subject to ∣∣Az 一 y∣2 ≤ η satisfies：
限#-咻 ≤ α⅛ (1 + (r⅛)限耳k1 + (2(μγ-P√s) (1 + 占)+ 2”)η
(0,	Xi =0
where μ :=《―5δ and Sgn(x)i = < 1,	Xi > 0.
1-1. Xi < 0
Lemma 13. Let A ∈ Cn×2n, if ∣Ax∣2 ≤ (1 + δ)∣x∣2 forall X ∈ Mk,t, then, ∣AS AS - 112→2 ≤ δ,
for any S ∈ Sk,t.
Proof. Let S ∈ Sk,t be given. Then for any X ∈ CS, we have
∣ASX∣22 - ∣X∣22 ≤ δ∣X∣22
We can re-write this as : ∣∣ASX∣2 - ∣∣x∣2 =(Asx,AsXi -hx,x)= h(ASAS - I)x,x). Noting
that AS AS - I is Hermitian, we have:
Il 4≠ A γ∣∣	((ASAS - I)X,Xi / X
∣∣AsAS - I∣∣2→2 = max -S ∣∣ ∣∣2------------ ≤ δ
S	χ∈cS ∖{0}	I∣x∣2
□
Proof of Theorem 2. We will derive (7) by showing that the matrix A satisfies all the hypotheses in
Theorem 12 for every vector in Mk,t .
First note that by Theorem 7, A satisfies the Mk,t-RIP property with constant δk,t := Jckt. There-
fore, by Lemma 13, for any S ∈ S%t, we have ∣∣AS AS - I∣∣2→2 ≤ δk,t. Since AS AS is a positive
semi-definite matrix, it has only non-negative eigenvalues that lie in the range [1 - δk,t , 1 + δk,t].
Since δk,t < 1 by assumption, ASAS is injective. Thus, we can set: h = AS(ASAS)-1sgn(Xs)
and get:
∣h∣2 = ∣As(ASAs)-1sgn(XS)∣∣2 ≤ ∣As∣2→2∣(ASAS)T∣∣2→2∣∣sgn(XS)∣2 ≤ T√k÷t
16
Under review as a conference paper at ICLR 2020
where T = 丫-+：: and We have used the following facts: since ∣∣ASAS - 11∣2→2 ≤ δk,t < 1, We
getthat k (ASAS)-1k2→2 ≤ 匚δ一 and that the largest singular value of AS is less than Vz1 + δk,t.
Now let U = A*h, then ∣∣us - Sgn(XS)∣2 = 0. Now we need to bound the value ∣∣uS∣∣∞. Denoting
row j of ASAS by the vector Vj, we see that it has at most max{k,t} non-zero entries and that
| (vj)1∣2 ≤ nC for l = 1,..., (k +1). Therefore, for any element (US j, we have:
I(US)jl = K(ASAS)-1sgn(xS), (Vj)» ≤ k(ASAS)-1∣2→2∣sgn(xS)∣2∣vj∣2 ≤
ʌ/k + t ∕max{k,t}c
1 - δk,t V	n
Defining β := JmaXnk,t}c and θ := √-k+ttβ, we get ∣∣uS∣∣∞ ≤ θ < 1 and also observe that
maXι∈S ∣∣AS aι ∣∣2 ≤ β. Therefore, all the hypotheses of Theorem 12 have been satisfied. Note that
y = FX + e = A[Xh(k)e]T + FX*k), Therefore, setting x# = BP(y, A, ∣Xt(k)∣2), we use the fact
∣∣FXt(k) ∣∣2 = ∣∣Xt(k) ∣∣2 combined with the bound in Theorem 12 to get (7):
llx# - xh(k)∣2 ≤ ( 2? + t (1 + 1 -β5k t ) +2τ) 1岛(乃心
where we write x# = [X#, e#]T with X#,e# ∈ Cn.
□
We now focus on proving Theorem 3. In order to do so, we will need some lemmas that will be used
in the main proof.
Lemma 14. If a matrix A ∈ Cm×N satisfies the `2 robust null space property for S ⊂ [N|, with
card (S) = s, then it satisfies the '1 robust null space ProPertyfor S with constants 0 < ρ < 1,τ0 :=
τ √s > 0.
Proof For any V ∈ CN, ∣vs∣∣2 ≤ √IlVSIl1+ T11Av∣. Then, using the fact that ∣vs∣∣i ≤ √s∣vs∣∣2,
we get:∣vs∣∣ι ≤ PIIVSI∣ι + T√s∣Av∣.
□
Lemma 15 (Theorem 4.20 in Foucart & Rauhut (2017)). Ifa matrix A ∈ Cm×N satisfies the `1
robust null sPace ProPerty (with resPect to ∣.∣) and for 0 < ρ < 1 and T > 0for S ⊂ [N|, then:
∣z - X∣1 ≤ 鲁(∣z∣ι -∣X∣1 + 2∣XS∣1) + 4∣A(z -χ)∣
1-ρ	1-ρ
for all z, x ∈ CN.
Lemma 16 (Proposition 2.3 in Foucart & Rauhut (2017)). For any p>q>0 and x ∈ Cn ,
z∈M k ∣x - z∣p ≤ (k)⅛ ∣x∣q
Proof of Theorem 3. Let 0 < ρ < 1 be arbitrary. Since F is a unitary matrix, for any S ⊆ [n] and
V ∈ Cn , we have
∣VS ∣2 ≤ √k ∣Vs ∣1 + T ∣V∣2 = √k ∣Vs ∣1 + T ∣Fv∣2
(17)
where T = 1. Now let S ⊆ [n] such that card(S) ≤ k. Then, F satisfies the '2 robust null space
property for S. Next, using Lemma 14 we get ∣vs∣∣1 ≤ PIlVSkI + T√k∣FV∣∣2 for all V ∈ Cn. Now
let x# = BP(y, F, η), then we know ||x# 11 ≤ ∣∣X∣1. Fixing S ⊆ [n] to be the support of Xh(k)and
using Lemma 15 , we get:
17
Under review as a conference paper at ICLR 2020
Layer	Type	Properties
-1-	Convolution	32 channels, 3 X 3 Kernel, No padding
-2-	Convolution	64 channels, 3 × 3 Kernel, No padding, Dropout with P = 0.5
-3-	Max-pooling	2 × 2, Dropout with P = 0.5
-4-	Fully Connected	128 neurons, Dropout with P = 0.5
5	Fully Connected	10 neurons
Table 5: Network architecture used for MNIST and Fashion-MNIST datasets in Section 4.1 and
Section 4.2. The first four layers use ReLU activations while the last layer uses a softmax activation.
kx# - Xki ≤ 1+ρ(kx#ki -kxkι + 2kXt(k)kι) + +『kF(x# - x)k2
1-ρ	1-ρ
≤ 1+ρ (2kXt(k)kι) + 2τ√kkF(x# — X)k2
1-ρ	1-ρ
≤ 巴(2kXt(k)kι) + 4τ√kkek2
≤ 已(2kXt(k)kι) + 4τ√kη
Letting P → 0 and recalling that T = 1 gives (8). Now let S be the support of (x# - x)h(k). Note
k(x# - x)s∣∣2 = infz∈Mk k(x# - x) - z∣∣2. Then, using Lemma 16 and (17), we see that
kx# - x∣∣2 ≤ k(x# - x)sk2 + k(x# - X)Sk2
≤
≤
≤
√kk(x# - X)ki + √ρkk(x# - X)ski + TkF(x#-x)k2
1+ρk(X# -x)ki + 2τη
k
√1+p∖ (2kxt(k)kι) + 4Tτ+p)η + 2τη
k(1 - P)	(1 - P)
(1 + P)2 ∕2∣L	H ) l 4 4τ (1 + ρ) , 2 ʌ
√k(i-ρ)⑵Xt(k)kl)+ ( (i-ρ) + 2τJη
Recalling T = 1 and letting P → 0 gives the desired result.
□
A.4 Dantzig Selector
Next we introduce the Dantzig Selector algorithm with an additional constraint. We first prove its
recovery guarantees for '∞-norm and then explain the reasoning behind the additional constraint.
Proof of Theorem 4. The proof follows the same structure as the proof of Theorem 3. Therefore
we provide a sketch and leave out the complete derivation. Let 0<ρ<1be arbitrary. Since F is a
unitary matrix, for any S ⊆ [n] and v ∈ Cn, we have
kvsk2 ≤ √kvski + kvsk2 ≤ √kvski + √kkvk∞ = √kvski + √kkF*Fvk∞
The rest of the argument is the same as in the proof of Theorem 3.	□
18