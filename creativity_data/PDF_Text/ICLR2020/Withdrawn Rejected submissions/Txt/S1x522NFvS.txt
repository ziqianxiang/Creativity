Under review as a conference paper at ICLR 2020
On unsupervised-supervised risk and one-
CLASS NEURAL NETWORKS
Anonymous authors
Paper under double-blind review
Ab stract
Most unsupervised neural networks training methods concern generative models,
deep clustering, pretraining or some form of representation learning. We rather
deal in this work with unsupervised training of the final classification stage of a
standard deep learning stack, with a focus on two types of methods: unsupervised-
supervised risk approximations and one-class models. We derive a new analytical
solution for the former and identify and analyze its similarity with the latter. We
apply and validate the proposed approach on multiple experimental conditions, in
particular on four challenging recent Natural Language Processing tasks as well
as on an anomaly detection task, where it improves over state-of-the-art models.
1	Introduction
Machine learning systems often share the same architecture composed of two stages: the first stage
computes representations of the input observations, while the second stage performs classification
based on these representations. Most unsupervised training methods focus on the first stage: rep-
resentation learning. This includes for instance generative models (VAE, GAN...), clustering tech-
niques and, in the Natural Language Processing (NLP) domain, all recent contextual words embed-
dings (RoBERTa, XLNet, GPT-2...).
This work rather deals with the final classification step, more precisely how to train neural classifiers
in an unsupervised way. In contrast to unsupervised training of the first stage that aims at learning
representations, unsupervised training of the final stage may rather pursue one of the following
objectives, among others:
•	Training one-class models for anomaly detection
•	Exploiting unsupervised approximations of the classifier risk to train a model from a priori
knowledge and unlabeled data instead of labeled samples
The former is a special type of binary classification task, where the positive class represents ”nor-
mal” observations and the objective is to identify unknown and often rare observations that can be
considered as anomalies and form the negative class.
The latter deals with training standard discriminative classifiers without labels, i.e., when assuming
that the precise target classification task is not defined explicitly with sample labels, but implicitly
with a priori knowledge. We review in Section 2 the family of one-class models as well as an
unsupervised approximation of the risk, and explore their relation in Section 3.3, hence bridging the
gap between both unsupervised discriminative classification approaches.
The main original contributions of this work are:
•	We derive an exact and analytical solution (Eq 5) to the risk approximation proposed
by Balasubramanian et al. (2011)
•	We analyze the properties of this solution, which lead to the following new results:
-	We extend this solution into an end-to-end differentiable loss that can be easily inte-
grated into any modern deep learning toolkit (Eqs 6, 7)
-	We propose an unsupervised training algorithm based on this analysis (Alg 1)
1
Under review as a conference paper at ICLR 2020
-	We propose a new posterior regularization term to improve this approach (Eq 8)
•	We identify and study the similarity of this approximation with the one-class neural net-
work anomaly detection method (Section 3.3)
•	We validate experimentally the unsupervised model on several datasets and tasks, including
a comparison with state-of-the-art one-class neural networks (Section 4)
2	Related work
We focus in this literature review on two unsupervised training methods for discriminative classifiers
that do not aim at computing representations of the input space, but that rather exploit such repre-
sentations to perform a final classification task. The first such method is an unsupervised-supervised
(we have adopted the terminology of the original paper) approximation of the classifier risk that
has been proposed by Balasubramanian et al. (2011) and that is detailed in Section 2.1. The sec-
ond class of methods is the family of one-class models for anomaly detection, which is reviewed in
Section 2.2.
2.1	Risk approximation
Let be given a binary linear classifier with parameters θ that computes a scalar score f (x) ∈ IR for
observation x. The classifier outputs class y = 0 iff f (x) <= 0, and y = 1 iff f (x) > 0. The risk
of this classifier with a hinge loss is (Balasubramanian et al., 2011):
R(θ) = Ep(χ,y) [(1 - f(x) ∙(2y - I))+]	(1)
R(θ)=P(y=0)
p(f (x)
α∣y = 0)(1 + α)+dα+P (y
1)	p(f (x)
α∣y = 1)(1 -α)+dα
(2)
Balasubramanian et al. (2011) prove that this risk can be optimized in an unsupervised way, as the
labels y are not required to compute Eq 1, when assuming that:
•	The class-marginal prior P(y) is known;
•	The class-conditional distribution of the scores p(f (x)|y) is Gaussian, which is supported
by the central limit theorem - please refer to Balasubramanian et al. (2011) for further
details.
The training algorithm proposed by the authors consists in the combination of (i) a gradient descent
to optimize the linear classifier parameters θ; and (ii) the Expectation-Maximization (EM) algorithm,
to compute the Gaussian parameters.
We derive a new formulation of this risk and study it in Section 3.1.
2.2	One-class models
One-class models are based on the assumption that all observations belong to a single positive,
“normal” class, except for (a few) outliers associated with the negative class. Given that there is no
label to identify which observations are outliers, the problem can be cast as an unsupervised training
problem. This class of models are typically used in anomaly detection applications.
The model at the origin of this research domain is the One-Class SVM (SchOlkOPf et al., 2001) (OC-
SVM). This model projects positive observations into a feature space, and computes an hyper-plane
in this feature space that separates most of these points from the region close to the origin, where
outliers (noise) are assumed to be. The objective function of this model is:
min I L∣∣w∣∣2 - r +———e∖
w,r,e y2l1 11	+ VN _ )
under the constraints (ei are slack variables): ei ≥ 0 and wT φ(xi) ≥ r - ei.
2
Under review as a conference paper at ICLR 2020
w corresponds to the linear classifier weights and φ is the non-linear SVM projection. wT φ(x) - r
is the signed distance between any of the N samples and the decision hyperplane.
A powerful extension of the one-class SVM is the Support Vector Data Description (SVDD)
model (Tax & Duin, 2004). This model exploits an hypersphere with radius R and center c instead
of an hyperplane to separate the positive and negative classes:
min (r2 + 1— X e)
R,c,e	νN
under the constraints that ei ≥ 0 and ∣∣φ(xi) - c||2 ≤ R2 + ei
The SVDD model has been enriched by Ruff et al. (2018) to learn a representation φW (x) computed
with a deep neural network with parameters W , which gives the Deep SVDD model:
min (r2 + N Xmaχ (0, Mφw(Xi)- c||2 - r2) + 2 X ||Wi||2 )	⑶
,ν
This model is trained by alternating a Stochastic Gradient Descent (SGD) step on W and computing
the optimum R.
Finally, the original OC-SVM has also been extended as a deep learning model with the One-Class
Neural Network (OC-NN) (Chalapathy et al., 2018). In this model, the final linear layer w in a stack
of deep neural network layers is interpreted as defining the decision hyperplane:
min (1 ||w||2 + 1 ||V||2 + Λ?Xmaχ(0,r-WTg(Vxi))-r∣	⑷
w,V,r 2	2	νN
with V the previous layers that compute a representation of the input and g() the previous activation.
This model is trained by alternating a SGD step to update (V, w) and computing the optimal r.
Another model of this family has recently been published: the One-class Convolutional Neural
Network (Oza & Patel, 2018), but the training objective of this model departs from the previous
unsupervised training objectives, as this model is trained with the standard cross-entropy loss with
negative samples that are artificially generated from a Gaussian distribution centered at the origin.
3	Unsupervised supervised risk
3.1	Exact risk derivation
Starting from Eq 1, we derive1 a closed-form solution to compute the risk from the two Gaussian
means μ and variances Σ that model the distribution of the score f (x) (We note P(y = 0) = po):
R(μ, ∑)
P0(1 + μo)(1 - erf O +
⅛0 (f) (1+ erf ( ≡ )) +
Poσ2N(-1; μo,σo) + (1 - po)σ2N(1; μι,σι)
(5)
with
N(α; μ, σ)
-1	e
√2πσ2
(α-μ)
2σ2
1

Balasubramanian et al. (2011) proposed to optimize the risk With finite differences. We rather pro-
pose to use the analytical solution derived in Eq 5, Which has the folloWing advantages:
•	The risk value is exact and not approximated;
1See full derivation in Appendix.
3
Under review as a conference paper at ICLR 2020
•	Computation of the risk is much faster using Eq 5 than with numerical approximations;
•	This equation is differentiable with respect to the Gaussian parameters. We derive next
another function that relates the Gaussian parameters to the model parameters θ. Hence,
the full risk can be directly integrated as a loss function in deep learning toolkits;
•	The analytical equation can be analyzed, which leads to novel insights as shown next.
Let Us plot Equation 5as a function of (μo,μι) in Figure 1 (left), for po = 0.1 and σo = σι = 1.
Figure 1: Risk as a function of both (μo,μι) (left), and only μo (right) for μι = 2, σι = 1 and
σ0 ∈ {0.1, 1, 3}
When We fix μι, We can see in Figure 1 (right) that the risk as a function of μo can be well approxi-
mated by a scaled and translated rectified linear function, as long as the variances are small enough.
Furthermore, the lower σ0 (and σι) is, the better the risk is. Varying μι and σι only translates
this curve vertically, above the horizontal axis. So, assuming that the risk has first been minimized
with respect to μι, then the global minimum of the risk may be obtained by decreasing linearly μ0.
Conversely, lower risks are obtained when μι is increasing. Although we have not exploited this
piece-wise linear approximation of the risk in our implementation, it is interesting to compare it to
the max(0, •一)term in Equation 4.
Let us now make another assumption: that both modes (μo, σ0) and (μι ,σι) of the score distribution
are well separated. This is a reasonable assumption when we are not too far away from the global
optimum, because the previous analysis has already shown that getting close to the optimum implies
that μo is small, μι is large and that σ° and σι are small. Then, a good approximation of μo and μι
can be computed by splitting all the scores f(x) according to the p0-quantile xp0 defined as
Xp0 = argmin Po - "z∈x 1f(z)‹f⑺	(6)
0	x	N
where the set of all observations X is of size N . Let us call X- the subset of size N - of all data
points that are on the left side of the p0-quantile:
X- = {x ∈ X s.t. f(x) < f (xp0)}
and similarly for the other side:
X+ = {x ∈ X s.t. f(x) ≥ f (xp0)}
We can now approximate the Gaussian parameters deterministically:
μo' N1- X f (X)
x∈X -
μι' N1+ X f (x)
x∈X +
(7)
σ2 ' J X f (x)2
x∈X -
X f(X))2σ2 ` (N+ X f(X)2!-fN+ X f(X)!2
x∈X -	x∈X +	x∈X +
4
Under review as a conference paper at ICLR 2020
Intuitively, decreasing the risk may be achieved by decreasing μo, σ0, σι and increasing μι. PlUg-
ging these equations into equation 5 gives a differentiable loss with respect to the network parame-
ters, which can be used in every modern deep learning toolkit.
3.2	Geometric interpretation
Following Chalapathy et al. (2018), we can consider a deep neural network that computes some rep-
resentation of its inputs. These representations are then passed to a final binary linear classification
layer with a single scalar output. This final layer, and optionally the previous layers, may be trained
by minimizing our unsupervised risk in Eq 5 with Stochastic Gradient Descent. As discussed in
Section 2.2, this final layer actually defines an hyperplane that separates both positive and negative
instances, and its output is the signed distance between each observation and this hyperplane. μo
is the average of these signed distances for all points that are on one side of the hyperplane (X-),
and μι for all points on the other side X+. So decreasing μ° and increasing μι can be interpreted
as moving away all samples in X - and in X+ as far as possible from the hyperplane, as show in
Figure 2 (right).
An important constraint is that the proportion of points on both sides of the hyperplane should be
equal (or close) to p0, otherwise, an easy way to decrease the risk with unbalanced classes is to
translate the hyper-plane along the vector w infinitely, moving all samples into the most frequent
class. The constraint is thus
f(x) ≤ 0 ∀x ∈ X- andf(x) ≥ 0 ∀x ∈ X+
This constraint can be fulfilled by adding another term to the risk, which becomes:
R0(θ) = R(θ) + f(xp0)2	(8)
While Balasubramanian et al. (2011) have used the class marginal only as a prior information, the
additional term in Equation 8 can be seen as a posterior regularization term, which forces the poste-
rior distribution P(y = 0|X) to match p0.
Algorithm 1 summarizes the training procedure.
Algorithm 1 End-to-end unsupervised training
• Initialization:
-	Let consider a binary classification task, for which We assume that the proportion of
class-0 elements p0 is known approximately;
-	Let be given a corpus of observations {xi }1≤i≤N without labels;
-	Let be given a deep neural network gφ (x) with parameters φ that computes a vectorial
representation ofan input x, which is fed to a final linear classification layer fθ(gφ(x))
with parameters θ; φ and θ may be initialized randomly or pretrained.
• Iterate:
-	Run a forward pass on the dataset {xi }1≤i≤N with the current parameters φ, θ.
-	Compute all classifier scores {si = fθ(gφ(xi))}1≤i≤n over the full corpus N, or over
a batch of observations n that is large enough to assume that the distribution of classes
in the batch is representative of the distribution in the whole corpus.
-	Sort the list of scores (si)1≤i≤n to compute the p0 -quantile xp0, following Equation 6.
- Compute the Gaussian parameters μ = (μo, μι), Σ = (σ0, σι) with Equations 7.
-	Compute the risk (Eq 8) with these Gaussian parameters.
-	Apply automatic differentiation to compute VθR(μ, Σ), and optionally VφR(μ, Σ);
-	Run a step of SGD to update θ, and optionally φ.
3.3 Relation with one-class neural networks
The One-Class Neural Network Chalapathy et al. (2018) similarly splits the set of observations with
an hyper-plane defined by the last layer of a deep neural network stack, but while Equation 8 splits
5
Under review as a conference paper at ICLR 2020
the samples according to p0 , the OC-NN splits them according to the ν-quantile of the points sorted
by their signed distance to the hyper-plane, where ν controls the number of data points that are
allowed to be on the negative side of the hyper-plane. This ν hyper-parameter plays the same role
as our p0. By rewriting their distance with our notation f (x), their loss (Eq 4) becomes:
min (L + VNN X (max(0, r - f(xi)))
where L is a term that does not depend on xi. Chalapathy et al. (2018) compute the optimal r as
“the V-quantile” of the scores, so We can rewrite r = f (xp0), and their sum as our μ0:
min (L + V^- (f (XpO ) - μO)) = min (L + f (XpO ) - μO)
Their objective thus aims at maximizing μo, i.e., making all negative samples as close as possible to
the hyperplane, as shown in Figure 2 (left). This equation strongly resembles the linear approxima-
tion of the risk that we have depicted in Figure 1, except that the OC-NN takes into account only the
negative part of the embeddings space, while our risk includes both negative and positive parts, and
that the gradients are in opposite directions, as summarized in Figure 2.
Figure 2: Comparative illustration of OC-NN and unsupervised risk approximation: observations
are represented in the embeddings space just before the final linear layer; the hyperplane is defined
by the parameters θ, and fθ(X) is the signed distance of the samples to the hyperplane. During
training, the OC-NN tends to reduce the distance between the negative samples and the hyperplane,
while our unsupervised loss tends to increase this distance for both negative and positive samples.
4	Experimental validation
The proposed unsupervised risk is coded in pytorch (Paszke et al., 2017) and is freely distributed 2 It
is evaluated in various tasks: (i) on a synthetic toy classification dataset; (ii) on the Wisconsin Breast
Cancer benchmark; (iii) on four NLP tasks and (iv) on a standard anomaly detection task. Following
the related works, the standard unsupervised accuracy metric (Xie et al., 2016) is used for the first
three cases, while the Area Under Curve (AUC) metric is used for anomaly detection.
4.1	Synthetic dataset
We first validate our approach on a synthetic dataset, which contains 10,000 4-dimensional instances
sampled from a bi-Gaussian distribution (po = 0.6,μ0 = [1,1,1, 1]t,σ0 = [1,1,1, 1]t; pi =
0.4, μι = [-2, -2, -2, -2]t, σι = [1,1,1, 1]t). We train two simple models with 1,000 training
epochs: one with a single layer, and another one with two layers and 2 hidden neurons (half of the
input size). The accuracy per training epoch is shown on the left curve in Figure 3.
2The code is given in the supplementary material and is further distributed with an open-source license on
a public git repository.
6
Under review as a conference paper at ICLR 2020
Figure 3: Accuracy as a function of the number of unsupervised training epochs on the synthetic
dataset (left) and on the Wisconsin Breast Cancer dataset (right).
We further study the sensitivity of our algorithm to initial conditions by retraining the model 10 times
with random initial parameters: the standard deviation of the accuracy is smaller than 2%. This first
experiment validates that the unsupervised training algorithm is able to quickly and reliably converge
towards the expected solution when the feature space explicitly encodes the class information.
4.2	Wisconsin Breast Cancer dataset
We validate next our unsupervised approach on a standard machine learning benchmark for binary
classification: the Wisconsin Breast Cancer dataset (Dua & Karra Taniskidou, 2017), composed of
569 instances with 30 dimensions each. The right curve in Figure 3 shows the accuracy of both our
1 and 2-layers models. 15 hidden neurons (half of the input dimension) are used for the 2-layers
model.
The convergence of our method is also fast and stable on this more realistic dataset. The state-of-
the-art for supervised learning on this dataset is 99.1% of accuracy (Osman, 2017). With 91% of
accuracy, our approach performs relatively well given that it is purely unsupervised. As a com-
parison, we have run a K-Means clustering algorithm on the same dataset, which gives 85% of
accuracy.
4.3	SentEval tasks
We validate next our unsupervised approach on four recent and more difficult Natural Language
Processing (NLP) binary classification datasets:
•	Movie Review (MR): classification of positive vs. negative movie reviews;
•	Product Review (CR): classification of positive vs. negative product reviews;
•	Subjectivity status (SUBJ): classification of subjective vs. objective movie reviews;
•	Opinion polarity (MPQA): classification of positive vs. negative movie reviews.
These datasets as well as the experimental evaluation protocol that we have used are described in
details in Conneau & Kiela (2018). This protocol first computes a sentence representation with the
state-of-the-art method InferSent (Conneau et al., 2017), and then passes these sentence embed-
dings into a simple feed-forward network that is trained on each dataset.
We have adopted the same experimental protocol and the same hyper-parameters, except that we do
not train the final feed-forward network with supervised labels and the cross-entropy loss, but we
rather train it without any label and with our proposed unsupervised loss. Table 1 summarizes the
accuracy of the state-of-the-art supervised models trained on the full corpus (InferSent sup.) and on
only 100 instances (InferSent 100-ex), as well as the accuracy of the proposed unsupervised model
(Unsup risk). Results in italic are taken from Conneau et al. (2017), other results are computed.
7
Under review as a conference paper at ICLR 2020
Table 1: Unsupervised accuracy on four binary NLP tasks
System	CR	SUBJ	MPQA	MR
InferSent sup.	86.3	92.4	90.2	81.1
InferSent 100-ex	63.8	62.5	70.1	53.9
Unsup risk	66.8	83.0	70.9	59.7
We can observe that the proposed purely unsupervised method always gives at least as good results
as the state-of-the-art transfer learning model trained on 100 reviews, with a notable improvement
of +20% absolute for the subjectivity classification task.
4.4	Anomaly detection
We finally validate our approach on an anomaly detection task. We adopt the same dataset and
experimental protocol than Ruff et al. (2018) and Chalapathy et al. (2018) for comparison. The tasks
consists in detecting outliers in digits images, where the “normal class” is the positive class and is
composed of images corresponding to a single target digit, and the outliers are randomly sampled
from the other digits images. Our model is composed of a single additional feed-forward layer on
top of the Ruff et al. (2018) model. This final classification layer is initialized from the Ruff et al.
(2018) parameters, and it is then trained in an unsupervised way with the loss in Equation 8. We tune
the hyper-parameters (number of epochs and learning rate) on a development corpus obtained by
keeping the same positive instances from the training corpus, but adding different negative training
samples. We rerun every experiment 10 times with different seeds to compute the standard deviation.
For the DeepSVDD, we report both the figures from the original paper, and the results obtained with
the authors code, which may differ because of slightly varying conditions. The DeepSVDD outputs
on the right are the ones that our own model is based on, and with which it should be compared to.
Table 2: Results (AUC) on anomaly detection (*: from original papers)
	OC-NN *	DeepSVDD *	DeepSVDD	Eq 8
0	97.6 ± 1.7	98.0 ± 0.7	98.0 ± 0.6	98.3 ± 1.1
1	99.5 ± 0.0	99.7 ± 0.1	99.4 ± 0.2	99.5 ± 0.3
2	87.3 ± 2.1	91.7 ± 0.8	89.2 ± 1.8	93.1 ± 2.7
3	86.5 ± 3.9	91.9 ± 1.5	90.5 ± 1.5	92.4 ± 0.9
4	93.3 ± 2.4	94.9 ± 0.8	94.0 ± 1.3	94.8 ± 2.0
5	86.5 ± 3.3	88.5 ± 0.9	86.3 ± 1.3	90.4 ± 2.3
6	97.1 ± 1.4	98.3 ± 0.5	98.0 ± 0.6	97.6 ± 2.9
7	93.6 ± 2.1	94.6 ± 0.9	93.7 ± 1.4	95.0 ± 1.7
8	88.5 ± 4.7	93.9 ± 1.6	92.7 ± 0.9	93.6 ± 1.4
9	93.5 ± 3.3	96.5 ± 0.3	96.0 ± 0.7	96.4 ± 0.5
We can note that our proposed unsupervised method always improve compared to the One-Class
neural network, and is also generally better than the DeepSVDD model run on the same platform.
Compared to the one-class models, our approach exploits information from all instances instead
of only the negative samples (see Figure 2). Furthermore, under reasonable assumptions, our loss
converges towards the theoretical optimum of the classifier risk (See Eq 1).
5	Conclusion
We have shown that both unsupervised-supervised classifier risk approximation and one-class neural
networks lead to similar training procedures, although they optimize a slightly different objective.
One of the main difference is that the former exploits all training samples, positive and negative,
which should lead to better parameter estimates. This seems to be confirmed by experimental vali-
dation. Based on the similarity between both types of methods, we have also shown experimentally
and through analysis that the unsupervised-supervised classifier risk approximation is a valuable
method to be included in the set of approaches dedicated to anomaly detection. In future works, we
plan to extend this approach for multi-class classification and few-shot learning.
8
Under review as a conference paper at ICLR 2020
References
Krishnakumar Balasubramanian, Pinar Donmez, and Guy Lebanon. Unsupervised supervised learn-
ing II: Margin-based classification without labels. Journal of Machine Learning Research, 12:
3119-3145, 2011.
Raghavendra Chalapathy, Aditya Krishna Menon, and Sanjay Chawla. Anomaly detection using
one-class neural networks. arXiv:1802.06360, 2018.
Alexis Conneau and Douwe Kiela. Senteval: An evaluation toolkit for universal sentence represen-
tations. arXiv:1803.05449, 2018.
Alexis Conneau, DoUWe Kiela, Holger Schwenk, Loic Barrault, and Antoine Bordes. Supervised
learning of universal sentence representations from natural language inference data. In Proc. of
the Conference on Empirical Methods in Natural Language Processing, pp. 670-680, 2017.
Dheeru Dua and Efi Karra Taniskidou. UCI machine learning repository, 2017. URL http:
//archive.ics.uci.edu/ml.
Ahmed Hamza Osman. An enhanced breast cancer diagnosis scheme based on two-step-svm tech-
nique. Int. J. Adv. Comput. Sci. Appl, 8:158-165, 2017.
Poojan Oza and Vishal M Patel. One-class convolutional neural network. IEEE Signal Processing
Letters, 26(2):277-281, 2018.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. 2017.
Lukas Ruff, Nico Gornitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Robert Vandermeulen, Alexan-
der Binder, Emmanuel Muller, and Marius Kloft. Deep one-class classification. In International
Conference on Machine Learning, pp. 4390-4399, 2018.
Bernhard Scholkopf, John C Platt, John Shawe-Taylor, Alex J Smola, and Robert C Williamson.
Estimating the support of a high-dimensional distribution. Neural computation, 13(7):1443-1471,
2001.
David MJ Tax and Robert PW Duin. Support vector data description. Machine learning, 54(1):
45-66, 2004.
J. Xie, R. Girshick, and A. Farhadi. Unsupervised deep embedding for clustering analysis. In Proc.
ICML, pp. 478-487, New York, 2016.
A	Appendix
A. 1 Derivation of the unsupervised risk
Let be given a binary linear classifier with parameters θ that computes a scalar score f (x) =
pn=ι θiXi ∈ IR for observation X ∈ IRn. The classifier outputs class y = 0 iff f (x) ≤ 0, and
y = 1 iff f (x) > 0. The true/gold class label is noted y ∈ {0,1}. The risk of this classifier with a
hinge loss is (Balasubramanian et al., 2011):
R(θ)
Ep(x,y) [(1- f(x) ∙(2y - 1))+ ]
(9)
P (y = 0)	p(f (x)
ɑ∣y = 0)(1 + α)+dα +
P (y = 1)	p(f (x)
α∣y = 1)(1 — α)+dα
We assume the conditional distributions follow a normal distribution:
Pf(X)Iy = O) ~ N(μo,σ0)
9
Under review as a conference paper at ICLR 2020
Pf(X)Iy = I) ~ N (μι,σι)
where N(μ,σ) is the standard normal distribution with mean μ and variance σ2. We can then rewrite
an approximation of this risk under the previous assumption and the additional assumption that the
class priors P(y) are known:
R = P(y = 0) J N(α; μo,σo)(1 + α)+dα + P(y = 1) J N(α; μι,σι)(1 — α)+da
Removing the non-linearity:
Z+∞	1
N(α; μo, σo)(1 + α)dα + P(y =1)/	N(α; μι, σι)(1 — α)da
1	-∞
Distributing:
R = P(y=0)
P(y = 1)
Z+∞	+∞
N(α; μo, σo)dα + P(y = 0)	αN(α; μ0, σ0)dα +
ZN(α; μι, σι)dα — P(y = 1)	αN(α; μι, σι)dα
∞	-∞
We know that the cumulative distribution function of a (μ, σ) normal is:
F(X) = 1 (1 + erf
So the integral ofa Gaussian is:
b1
N(x; μ, σ)dx = F(b) — F(a)=—
a2
a — μ
erf -F
∖σ √2
We know that erf(-∞) = -1, erf(0) = 0 and erf(+∞) = 1, so
R = P(y = 0)
2
P(y = 1)
2
1 -erf
1 + erf
-1 — μo
σo√2
1 - μ1
σι√2
Z+∞
aN (α; μ0,σ0)dα +
P(y = 1) /	αN(α; μι,σι)dα
-∞
Integration by parts give:
I XN(x; μ,σ)dx = bF(b) — aF(a) — / F(x)dx
aa
We also know that
e-x2
J erf(x)dx = Xerf(X) + √- + C
So
4	b — a 1 fb (X — μ∖
LF (X)dX=TyL erf( τ√r)dX
We use integration by substitution:
Zaeer ( U IdX = σ√2 Zaeer ( £ ) σ√2= σ√2 Zu(a)
With U(X) = σ√μ2
So
u(b)
erf(u)du = u(b)erf(u(b)) — u(a)erf(u(a)) +———(e-u(b)2 — e-u(a)2)
u(a)	π
10
Under review as a conference paper at ICLR 2020
Mb)	b - μ
erf(u)du = —7μ erf
Ju(a)	σ √2
b — μ
fb erf
a
x — μ
dx = (b — μ)erf
b — μ
一(a — μ)erf
a — μ ʃ
-----^erf
σ √2
a 一 μ
2σ2	— e	2σ2
(b-μ)2
(b-μ)2
2σ2


(a —μ)2
)
b τ~,∕∖∙, b — a b — μ
F (x)dx = —2——I——L erf
a
b — μ
—
a — μ q
------erf
2
a — μ
σ /	(b-μ)2
1——J=Ie 2σ2
√2∏
Plugging into the former equation:
fb
I xN(x; μ, σ)dx = bF(b)—aF(a) —
Ja
b — a b 一 μ
2
—
2
erf
b — μ
+ ” erf
b
I XN(x; μ,σ)dx
a
bb
2 + 2 erf
ba
b — μ
σ√2
b
—
aa
2 - 2 erf
a — μ
+
Simplifying
—2 + 2 - 2 erf
a
-erf
2
a — μ
σ√2 J
b b — μ
μ M
----erf
2
为)+ 2 erf
(b-μ)2
(e 2σ2
+
b
I XN(x; μ,σ)dx
a
(a-μ)2
—e	2σ2

)
(a-μ)2
—e	2σ2
a — μ
Note: another way to obtain this result is to use the following known formula:
So
b
b
/b xN(
a
(N (b； μ,σ) — N (a； μ,σ))
χ; μ,σia
When b → +∞:
/	xN(x; μ, σ)dx = μ (1 — erf
a — μ
+ σ2N(a; μ, σ)

)
√⅛(e-
(b-μ)2
And when a → —∞:
xN(x; μ, σ)dx = μ ( 1+ erf
J-∞	2 ∖
Our risk is:
R
P (y = 0)
2
1 — erf
—1 — μo
P(y = 1)
1 + erf
σ0√2
1 — μ1
σι√2
(a —μ)2
2σ2	—e	2σ2

)
(a —μ)2
—e	2σ2

)
Z+∞
aN (α; μ0,σ0)dα +
P(y = 1) /	αN(α; μι, σι)dα
J -∞
2
11
Under review as a conference paper at ICLR 2020
So
R = PkU(I-erf 仁二μ0
2	V V σo √2
P (y = 0)σ0N (-1; μo,σo) +
Py^ (1 + erf f T
2	V	31 √2
p (y = 1)σ2N(1； μ1,σ1)
P (y = 0)μo
1 - erf (-≡)) +
1 + erf Bl)) +
+ -
2
p (y = i)μι
2
And finally, the risk as a function of the bi-Gaussian parameters is:
R = P(y = 0)
=	2
P(y = 1)
2
(1 + μo) 1 - erf
(1 - μι) 1 + erf
-1 — μo
σ0√2
1 - μι)
σι√2 )
+ p (y = 0)σoN (-1; μo, σ0) +
+ P(y = 1)σ2N(1; μ1,σ1)
12