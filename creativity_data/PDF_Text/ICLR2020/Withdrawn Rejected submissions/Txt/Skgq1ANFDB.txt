Under review as a conference paper at ICLR 2020
Curvature-based Robustness	Certificates
against Adversarial Examples
Anonymous authors
Paper under double-blind review
Ab stract
A robustness certificate against adversarial examples is the minimum distance of a
given input to the decision boundary of the classifier (or its lower bound). For any
perturbation of the input with a magnitude smaller than the certificate value, the
classification output will provably remain unchanged. Computing exact robustness
certificates for deep classifiers is difficult in general since it requires solving a non-
convex optimization. In this paper, we provide computationally-efficient robustness
certificates for deep classifiers with differentiable activation functions in two steps.
First, we show that if the eigenvalues of the Hessian of the network (curvatures
of the network) are bounded, we can compute a robustness certificate in the l2
norm efficiently using convex optimization. Second, we derive a computationally-
efficient differentiable upper bound on the curvature of a deep network. We also
use the curvature bound as a regularization term during the training of the network
to boost its certified robustness against adversarial examples. Putting these results
together leads to our proposed Curvature-based Robustness Certificate (CRC) and
Curvature-based Robust Training (CRT). Our numerical results show that CRC
outperforms CROWN’s certificate when trained with our regularizer while CRT
leads to higher certified accuracy compared to standard adversarial training.
1	Introduction
Modern neural networks achieve high accuracy on tasks such as image classification and speech
recognition, but are known to be brittle to small, adversarially chosen perturbations of their inputs
(Szegedy et al., 2014). A classifier which correctly classifies an image x, can be fooled by an
adversary to misclassify an adversarial example x + δ, such that x + δ is indistinguishable from x
to a human. Adversarial examples can also fool systems when they are printed out on a paper and
photographed with a smart phone (Kurakin et al., 2016a). Even in a black box threat model, where the
adversary has no access to the model parameters, attackers could target autonomous vehicles by using
stickers or paint to create an adversarial stop sign that the vehicle would interpret as a yield or another
sign (Papernot et al., 2016). This trend is worrisome and suggests that these vulnerabilities need to be
appropriately addressed before neural networks can be deployed in security critical applications.
In the last couple of years, several empirical defenses have been proposed for training classifiers to
be robust against adversarial perturbations (Madry et al., 2018; Samangouei et al., 2018; Zhang et al.,
2019; Papernot et al., 2016; Kurakin et al., 2016b; Miyato et al., 2017; Zheng et al., 2016) Although
these defenses robustify classifiers to particular types of attacks, they can be still vulnerable against
stronger attacks (Athalye et al., 2018; Carlini & Wagner, 2017; Uesato et al., 2018; Athalye & Carlini,
2018). For example, (Athalye et al., 2018) showed most of the empirical defenses proposed in ICLR
2018 can be broken by developing tailored attacks for each of them.
To end the cycle between defenses and attacks, a line of work on certified defenses has gained
attention where the goal is to train classifiers whose predictions are provably robust within some given
region (Huang et al., 2016; Katz et al., 2017; Ehlers, 2017; Carlini et al., 2017; Cheng et al., 2017;
Lomuscio & Maganti, 2017; Dutta et al., 2018; Fischetti & Jo, 2018; Bunel et al., 2017; Wang et al.,
2018a; Wong & Kolter, 2017; Wang et al., 2018b; Wong et al., 2018; Raghunathan et al., 2018b;a;
Dvijotham et al., 2018a;b; Croce et al., 2018; Singh et al., 2018; Gowal et al., 2018; Gehr et al., 2018;
Mirman et al., 2018; Zhang et al., 2018b; Weng et al., 2018). These methods, however, do not scale
to large and practical networks used in solving modern machine learning problems. Another line of
1
Under review as a conference paper at ICLR 2020
defense work focuses on randomized smoothing where the prediction is robust within some region
around the input with a user-chosen probability (LiU et al., 2017; Cao & Gong, 2017; LecUyer et al.,
2018; Li et al., 2018; Cohen et al., 2019; Salman et al., 2019). Although these methods can scale
to large networks, certifying robustness with probability close to 1 often requires generating a large
number of noisy samples around the input which leads to high test-time computational complexity.
If the classifier f(.) was linear, the distance of an input point x to its decision boundary (i.e. the
robustness certificate) can be computed efficiently using a convex optimization. For example, the l2
robustness certificate in that case would be equal to ∣f (x)∣∕∣∣ Vxf (X)Il. However, modern classifiers
based on neural networks are not linear and and can have non-zero curvatures in different parts of the
input domain. The deviation of the classifier from the linear model makes the robustness certification
problem to be a non-convex optimization which is often difficult to solve exactly. However, if we
could compute global bounds on the maximum curvature values of the classification network, one
may be able to compute computationally-efficient lower bounds on the robustness certificate even for
non-linear deep classifiers. This is the key intuition of our results in this paper.
In this work, we derive a global bound on the Lipschitz constant of the gradient of deep neural
networks with differentiable activation functions (such as sigmoid, tanh, softplus, etc.). This provides
an upper bound on the magnitude of the eigenvalues of the Hessian or the curvature values of the
classification network. Using this global curvature bound and for the l2 metric, we tackle both the
certification and attack problems. In the certification problem and for a given pre-trained classifier,
we provide a computationally-efficient lower bound on the distance of a point to the classification
decision boundary. In the related attack problem, for a given input and a region around it, our goal is
to find a perturbed input (an adversarial example) that maximizes the loss inside the given region.
The outcome of the attack problem is then used in the adversarial training procedure (Madry et al.,
2018) to further robustify the network. Furthermore, our global curvature bound is differentiable and
we show that adding it to the loss function as a regularizer boosts certified robustness measures.
We note that other recent works (e.g. Moosavi Dezfooli et al. (2019); Qin et al. (2019)) empirically
show that using an estimate of curvature at inputs as a regularizer leads to empirical robustness on
par with the adversarial training. In this work, however, we use a provable global upper bound on the
curvature (and not an estimate) as a regularizer and show that it results in high certified robustness.
Moreover, previous works have tried to certify robustness by bounding the Lipschitz constant of the
neural network (Szegedy et al., 2014; Peck et al., 2017; Zhang et al., 2018c; Anil et al., 2018; Hein &
Andriushchenko, 2017). Our approach, however, is based on bounding the Lipschitz constant of the
gradient of deep neural networks. We discuss existing works in more details in Appendix A.
Below, we state the key theoretical results of this paper informally while detailed statements of these
results are presented in Section 4.
Theorem (informal) 1. Let zi(L) denotes the ith logit of an L layer fully-connected neural network
with differentiable activation functions. Then, the curvature of the neural network function is globally
bounded as follows:
ml W Viz((LW MI,	∀x ∈ RD
xi
where m and M can be computed efficiently using parameters of the network.
This result along with the min-max theorem leads to the following curvature robustness certificate:
Theorem (informal) 2. Consider a network whose curvature values are bounded. For a given
input X(O) with the true label y and the attack target t (t ≠ y) let Pcert denote the exact robustness
certificate, i.e. the distance of X(O) to the decision boundary. We can efficiently compute dCert Such
that dccert ≥ pccert. Moreover, if the solution x(cert) for dccert satisfies z(y() = zt((), then dccert = pccert.
We have similar results for the attack problem. For simplicity, we summarize definitions of
pccert,dccert,pacttack,dcattackinTable1.
In summary, in this paper, we make the following contributions:
•	We provide global bounds on the eigenvalues of the Hessian of a deep neural network with
differentiable activation functions (Theorem 3 and Theorem 4). In addition to the adversarial
robustness problem, these bounds may be of an independent interest for readers.
2
Under review as a conference paper at ICLR 2020
	Certificate problem(-)= Cert	AttaCk ProbIem(-)= attack
primal problem, p1-)	minf(χ)=o 1/2IX - X(O)产		min∣∣x-x(0)∣∣≤ρ f(x)	
dual function, d(-)(η)	minx 1/2IlX - X(O) ∣∣2 + ηf (x)	minx f(x) + η∕2(∣x - X(O) ∣2 - ρ2)
When is dual solvable?	-1/M ≤ η ≤ -1/m	-m ≤ η
dual problem, d'	max-1∕M≤η≤-1∕m dcert (η)	max-m≤n dattack (η)
When primal = dual?	f(x(Cert)) = 0	∣X(attack) - X(O)I = P
Table 1: A summary of various primal and dual concepts used in the paper. f denotes the function of
the decision boundary, i.e. z(yL) - zt(L) where y is the true label and t is the attack target. m and M
are lower and upper bounds on the smallest and largest eigenvalues of the Hessian of f , respectively.
Method	Non-trivial bound	Multi- layer	Activation functions	Norm
Szegedy et al. (2014)	X	✓	All	l2
Katz et al.(2017)	✓	✓	ReLU	l∞
Hein & Andriushchenko (2017)	✓	X	Differentiable	l2
Raghunathan et al. (2018a)	✓	X	ReLU	l∞
Wong & Kolter (2017)	✓	✓	ReLU	l∞
Weng et al.(2018)	✓	✓	ReLU	l1,l2,l∞
Zhang et al.(2018b)	✓	✓	All	l1,l2,l∞
Cohen et al.(2019)	✓	✓	All	l2
Ours	J	J	Differentiable	l2
Table 2: Comparison of methods for providing provable robustness certification. Note that Cohen
et al. (2019) is a probabilistic certificate.
•	Using the global curvature bounds, we develop computationally efficient methods for both
the robustness certification as well as the adversarial attack problems (Theorems 1 and 2).
•	We show that using our proposed curvature bounds as a regularizer during training leads to
improved certified accuracy on 2,3 and 4 layer networks (on the MNIST dataset) compared
to standard adversarial training with PGD (Madry et al., 2018) as well as TRADES (Zhang
et al., 2019). Moreover, our robustness certificate (CRC) outperforms CROWN’s certificate
(Zhang et al., 2018b) significantly while taking less time to compute.
2	Notation and Problem S etup
Consider a fully connected neural network with L layers and NI neurons in the Ith layer (L ≥ 2
and I ∈ [L]) for a multi-label classification problem with C classes (NL = C). The corresponding
function of the neural network is Z(L) : RD → RC where D is the dimension of the input. For an
input x, we use z(I)(x) ∈ RNI and a(I) (x) ∈ RNI to denote the input (before applying the activation
function) and output (after applying the activation function) of neurons in the I th hidden layer of the
network, respectively. To simplify notation and when no confusion arises, we make the dependency
of z(I) and a(I) to x implicit. We define a(0)(x) = x and N0 = D.
With a fully connected architecture, each z(I) and a(I) is computed using a transformation matrix
W(I) ∈ RNI ×NI-1, the bias vector b(I) ∈ RNI and an activation function σ(.) as follows:
z(I)(x) = W(I)a(I-1) (x) + b(I),	a(I) (x) = σ (z(I)(x)) .
We use (zi(L) - z(jL))(x) as a shorthand for zi(L) (x) - zj(L) (x).
3
Under review as a conference paper at ICLR 2020
We use [p] to denote the set {1, . . . ,p} and [p, q], p ≤ q to denote the set {p,p + 1, . . . , q}. We use
small letters i, j, k etc to denote the index over a vector or rows of a matrix and capital letters I , J to
denote the index over layers of network. The element in the ith position of a vector v is given by
vi , the vector in the ith row of a matrix A is Ai while the element in the ith row and jth column of
A is Ai,j. We use IIvll and IlAlIto denote the 2-norm and the operator 2-norm of the vector V and
the matrix A, respectively. We use ∣v∣ and ∣A∣ to denote the vector and matrix constructed by taking
the elementwise absolute values. We use λmax(A) and λmin(A) to denote the largest and smallest
eigenvalues of a symmetric matrix A. We use diag(v) to denote the diagonal matrix constructed by
placing each element of v along the diagonal. We use Θ to denote the Hadamard Product, I to denote
the identity matrix. We use W and N to denote Linear Matrix Inequalities (LMIS) such that given two
symmetric matrices A and B where A N B means A - B Positive Semi-Definite (PSD).
3 Using duality to solve the attack and certificate problems
Consider an input x(0) with true label y and the attack target t. In the certificate problem, our
goal is to find a lower bound of the minimum l2 distance between x(0) and the decision boundary,
z(yL) = zt(L). The problem for solving the exact distance (primal) can be written as:
一★	___:一
pcert =	min
cert (L)	(L)
zy (x)=zt
(x)[ 2 Ux-X 叫2
=min max - Ilx - x(0)『+ η (Z(L)
xη2	y
-zt(L)) (x)
(1)
However, solving the above problem can be hard in general. Using the minimax theorem (primal ≥
dual), we can write the dual of the above problem as follows:
p*ert ≥ max dcert(η),	dcert(η) = ∏Xn g IIX - X(叫2 + η (ZyL)- Z(L))(X) ∙	⑵
From the theory of duality, we know that dcert(η) for each value of η gives a lower bound on the
exact certification value (the primal solution) Pcier» However, since ZyL) -Z(L) is non-convex, solving
dcert(η) for every η can be difficult. In the next section, we will prove that the curvature of the
function Z(yL) - Zt(L) is bounded globally:
ml W vX (ZyL)- Z(L)) W MI	∀x ∈ RD, m < 0, M > 0	(3)
In this case, we have the following theorem:
Theorem 1.	dcert (η) is a convex optimization problem for -1/M ≤ η ≤ -1/m. Moreover, If X(cert)
is the solution to dccert such that Z(yL)(X(cert)) = Zt(L) (X(cert)), then pccert = dccert.
Below, we briefly outline the proof while the full proof is presented in Appendix D.1. The Hessian of
the objective function of the dual dcert (η), i.e the function inside the minx is given by:
vX11ix -X(O)I∣2+η (ZyL)- Z(L))(X) = I+ηvx (ZyL)- Z(L))
From equation (3), we know that the eigenvalues of I + ηv2X(Z(yL) - Zt(L)) are bounded between
(1 + ηm,1 + ηM) if η ≥ 0, and in (1 + ηM,1 + ηm) if η ≤ 0. In both cases, we can see that for
-1/M ≤ η ≤ -1/m, all eigenvalues will be non-negative, making the objective function convex.
When X(cert) satisfies Z(yL) = Zt(L), dccert = 1/2IX(cert) - X(0) I2, using the duality theorem and
definition of pccert, we get pccert = dccert.
Next, we consider the attack problem. The goal here is to find an adversarial example inside an l2 ball
of radius ρ such that Z(yL) - Zt(L) is minimized. Using similar arguments, we can get the following
theorem for the attack problem (pcattack, dcattack and dattack are defined in Table 1):
Theorem 2.	dattack(η) is a convex optimization problem for -m ≤ η. Moreover, if X(attack) is the
solution to dcattack such that IX(attack) - X(0) I = ρ, pcattack = dcattack.
The proof is presented in Appendix D.2. Both Theorems 1, 2 hold for any non-convex function with
continuous gradients. They can also be of interest in problems such as optimization of neural nets.
Using Theorems 1 and 2, we have the following definitions for certification and attack optimizations:
4
Under review as a conference paper at ICLR 2020
Definition 1. (Curvature-based Certificate Optimization) Given an input x(0) with true label y, the
false target t, we define (η(cert), x(cert)) as the solution of the following max-min optimization:
max min - Ilx - x(0)『+ η (Z(L) - Z(L)) (x)
-1/M≤η≤-i∕m X L2 11	11 V y t 八，
We refer to Ix(cert) - x(0) I as the Curvature-based Robustness Certificate (CRC).
Definition 2. (Curvature-based Attack Optimization) Given input x(0) with label y, false target t,
and the l2 ball radius ρ, we define (η(attack), x(attack)) as the solution of the following optimization:
ηmammin 2 QX -X叫2 -ρ2)+(ZyL)- Z(L))(X).
When x(attack) is used for training in an adversarial training framework, we call the method the
Curvature-based Robust Training (CRT).
Since both curvature-based certificate and attack optimizations are convex optimization problems, any
convex optimization solver can be used to solve them. In our implementation, we use majorization-
minimization to solve the dual function for a given η and bisection method to maximize over η. More
details are given in Appendix C.4 and C.5.
4 Curvature Bounds for deep networks
In this section, we provide a computationally efficient approach to compute the curvature bounds for
neural networks with differentiable activation functions. To the best of our knowledge, there is no
prior work on finding provable bounds on the curvature values of deep neural networks. Our results
rely on a closed form expression for the Hessian of the ith logit as a sum of matrix products (Section
4.1). After establishing this result, we first derive curvature bounds for a two-layer network in Section
4.2 and then extend the bounds to deeper networks in Section 4.3.
4.1	Closed form expression for the Hessian
Using the chain rule of second derivatives, We can derive vXz(L) as a sum of matrix products:
Lemma 1. Given an L layer neural network, the Hessian of the ith hidden unit with respect to the
input X, i.e v2xZi(L) is given by the following formula:
v2xZi(L)
xi
E (B(I))T diag(FiLDo σ' (z(I)))B(I)
where B(I) is the Jacobian of Z(I) with respect to X (dimensions NI × D), and F(L,I) is the Jacobian
of Z(L) with respect to a(I) (dimensions NL × NI).
The proof is presented in Appendix D.3. Using the chain rule of gradient, We can compute B(I),
F(L,I) matrices in Lemma 1 recursively as folloWs:
B(1) = W⑴	B(I) = W(I)diag (σ' (Z(I-I))) B(I-I) I ∈ [2,L - 1]	(4)
F(L，L-1) = W(L)	F(Ll) = W(LLdiag(σ (Z(L-I))) F(L-1，I) I ∈ [L - 2] (5)
This leads to a fast back-propagation like method that can be used to compute the Hessian. Note that
Lemma 1 only assumes a matrix multiplication operation from a(I-1) to Z(I). Since a convolution
operation can also be expressed as a matrix multiplication, We can directly extend this lemma to deep
convolutional netWorks. Furthermore, Lemma 1 can also be of independent interest in other related
problems such as higher-order interpretation methods for deep learning (e.g. Singla et al. (2019)).
4.2	Curvature bounds for Two Layer networks
For a tWo-layer netWork and using Lemma 1, v2x (Z(y2) - Zt(2)) is given by:
vX (Zy2) - Z(2)) = (W(I))T diag((Wt)- W(2)) o σ (Z ⑴))w ⑴
5
Under review as a conference paper at ICLR 2020
Note that only σ''(Z(I)) depends on x. We can maximize and minimize each element in the diag
term, (W(y2,i) - Wt(,2i))σ''(z(1)) independently subject to the constraint that σ”(.) is bounded. Using
this procedure, we construct matrices P and N that satisfy properties given in the following theorem:
Theorem 3.	Given a two layer network whose activation function has bounded second derivative:
h,L ≤ σ (x) ≤ hu ∀x ∈ R
(a)	We have the following linear matrix inequalities (LMIs):
N W v2 (z(2) - z(2)) W P ∀x ∈ RD
xy t
(b)	If hU ≥ 0 and hL ≤ 0, P is a PSD matrix, N is a NSD matrix.
(c)	This gives the following global bounds on the eigenvalues of the Hessian:
mIWv2x(z(y2)-zt(2))WMI,	where M = λmax(P), m = λmin(N)
P and N are independent of x and defined in equations (55) and (56) in Appendix D.4.
The proof is presented in Appendix D.4. Because power iteration finds the eigenvalue with largest
magnitude, we can use it to find m and M only when P is PSD and N is NSD. We solve for hU and
hL for sigmoid, tanh, softplus activation functions in Appendix E and show that this is in fact the
case for them. Note that this result does not hold for ReLU networks since the ReLU function is not
differentiable. However, in Appendix F , we devise a method to compute the certificate for a two
layer ReLU network by finding a quadratic lower bound for z(y2) - zt(2).
4.3 Curvature bounds for Deep networks
Using Lemma 1, we know that v2xzi(L) is a sum product of matrices B(I) and Fi(L,I). Thus, if we
can find upper bounds for IlB(I)Il and ∣∣F(L,I)∣∣, we can get upper bounds for IlVxZ(L) ∣∣. Using this
intuition (details are presented in Appendix D.5), we have the following result:
Theorem 4.	Given an L layer neural network whose activation function satifies:
′	′′
∣σ (x)∣ ≤ g, ∣σ (x)∣ ≤ h	∀x ∈ R,
the absolute value of eigenvalues of v2xZi(L) is globally bounded by the following quantity:
IVxz(L)Ii ≤ h ∑ (r(I))2maχ(S(L,I)),	∀χ∈ RD
I=1	j
where r(I) and S(L,I) are independent of x and defined recursively as:
r⑴=IIW⑴Il,	r(I) = g IIW(I)Ilr(I-I) I ∈ [2,L- 1]	(6)
S(L,L-1) = ∣W(L)∣,	S(L,I) =g ∣W(L)∣S(L-1,I) I∈ [L-2]	(7)
The above expressions allows for an efficient computation of the curvature bounds for deep networks.
We consider simplification of this result for sigmoid, tanh, softplus activations in Appendix E.
Note that bounds for z(yL) - zt(L) can be computed by replacing Wi(L) with W(yL) -Wt(L) in Theorem
4. The resulting bound is independent of x, and only depends on network weights W(I), the true
label y, and the target t. We denote it with K(W, y, t). To simplify notation, when no confusion
arises we denote it with K . In our experiments, for two layer networks, we use M , m from Theorem
3 (since it provides tighter curvature bounds). For deeper networks (L ≥ 3), we use M = K, m = -K.
5	Adversarial training with curvature regularization
Using Theorem 2 (b), we know that if we solve the curvature-based attack optimization and obtain
ρ = Ix(attack) - x(0) I, x(attack) is provably the closest adversarial example to x(0). However, when
6
Under review as a conference paper at ICLR 2020
Ueωs(υ工φlp」OJ SPUnOq Bn-e>u<υ6,uj
Figure 1: Kub and Klb are upper and lower
curvature bounds of the network with Sig-
moid activations (averaged over (y, t) pairs).
When γ = 0 (no curvature regularization),
networks adversarially trained with CRT or
PGD both have high curvatures. However,
CRT even with a small γ leads to a signifi-
cant decrease in curvature bounds (note the
log-scale of y-axis). Similar results hold for
networks with Tanh activations (Appendix
Figure 2)
we performed adversarial training (with ρ = 0.5), we found that the curvature bound is loose and
almost none of training inputs lead to zero primal-dual gap with P = ∣∣ Xsttack) - X(O) ∣∣. Tofix this
issue, we use a regularizer that penalizes the curvature bound, K . Using equations (6) and (7), we
can compute K using absolute value, matrix multiplications, and operator norm (IlW(I)∣∣ ,I ∈ [L]).
Since the gradient of operator norm does not exist in standard libraries, we created a new layer where
the gradient OfIlW(I) ∣∣, i.e NW(T) IlW(I) ∣∣ is given by:
Vw(I)IlW(I)Il = U(I) (V(I))T	U(I),V(I) satisfy W(I)V(I) = IlW(I)∣U(I)
This approach to compute the gradient of the largest singular value of a matrix has also been used in
previous ICLR work (Miyato et al., 2018). Implementation details are in Appendix C.1.
Thus, the per-sample loss for training with curvature regularization is:
cross -entropy (z(L)(x(0)), y) + YK (W, y, t)
where y is the true label of the input X(0), t is the target label and γ is the regularizer for penalizing
large curvatures. Similar to the adversarial training, in CRT, we use X(attack) instead ofX(0).
6	Experiments
The empirical robust accuracy means the fraction of test samples that were correctly classified
after running an l2 bounded PGD attack (Madry et al., 2018), the certified robust accuracy means
the fraction of correctly classified test samples whose robustness certificates are greater than a pre-
specified radius P. Unless otherwise specified, we use the class with the second largest logit as the
attack target (i.e. the class t) and P = 0.5. All experiments were run on the MNIST dataset. The
notation (L × [1024], activation) denotes a neural network with L layers with the specified activation,
(γ = c) denotes standard training with γ set to c, while (CRT, c) denotes CRT training with γ = c.
Certificates are computed over 150 randomly chosen correctly classified images.
Comparison with existing certificates: In Table 3, we compare CRC with CROWN-general (Zhang
et al., 2018a). For 2-layer networks, CRC outperforms CROWN significantly. For deeper networks,
CRC works better only when the network is trained with curvature regularization. However, even
with small γ = 0.005, we see a significant increase in CRC but a very small drop in the test accuracy
(without any adversarial training). We can see that with γ = 0.01, non-trivial certified accuracies
of 83.53%, 88.33%, 89.61% can be achieved on 2, 3, 4 layer sigmoid networks, respectively, with-
out any adversarial training. Adversarial training using CRT further boosts certified accuracy to
95.59%, 94.99% and 93.41%, respectively. We observe similar results with Tanh networks in Ap-
pendix Section G.2. We show some results on CIFAR-10 dataset in Table 6. We again observe
improvements in the robustness certificate and certified robust accuracy using CRC and CRT.
In Figure 1, we plot the effect of γ on the curvature upper bound Kub and a lower bound Klb of a
4-layer network with Sigmoid activations. Klb is computed by taking the maximum of the largest
eigenvalue of the Hessian across all test images with label y and the second largest logit t, then
averaging across different (y, t). Similarly, Kub is the mean of K over all pairs (y, t) (details in
Appendix G.5). We observe that without any curvature regularization (when γ = 0), both standard
adversarial training with PGD as well as the CRT lead to networks with high curvatures. However,
7
Under review as a conference paper at ICLR 2020
CRT with even a small γ leads to a significant decrease in curvature bounds. Similar trends can be
observed for networks with Tanh activations (Appendix Figure 2). Curvature bounds are higher for
the Tanh networks compared to the Sigmoid ones due to having larger g and h parameters for Tanh in
Theorem 4. Moreover, we report curvature bounds for networks with different depth in Appendix
Table 12. We observe that increasing depth increases curvature bounds.
Comparison with existing adversarial training methods: We compare CRT with adversarial
training methods namely PGD (Madry et al., 2018) and TRADES (Zhang et al., 2019) in Table 4.
We observe that none of the other methods give higher certified accuracy or robustness certificates
than our proposed methods. We observe similar results with Tanh networks (Appendix Table 9).
Moreover, in Appendix Table 10, we observe that CRT outperforms Randomized Smoothing (Cohen
et al., 2019) for 2 and 3 layer networks. Since TRADES and Randomized Smoothing were designed
for untargeted attacks while CRT is for targeted attacks, to have a fair comparison, we modify the
multi-class version of the cross entropy loss with its binary version (details in Appendix Section G.3).
However, we emphasize that there is a fundamental difference between our certificate (and CROWN)
with the smoothing based method since our certificate is deterministic while the smoothing-based
certificate is probabilistic (with high probability).
We also compare against robust training technique proposed in Wong et al. (2018) in Table 5 with l2
radius ρ = 1.58. We note that the activation functions used in this comparison are different because
the method proposed in Wong et al. (2018) uses ReLU while our proposed CRT can only work with
fully differentiable activation functions such as softplus, sigmoid, tanh. For CRT, we use a network
with softplus activation function with curvature regularization. We observe that for two and three
layer networks, CRT gives higher certified robust accuracy compared to that of Wong et al. (2018)
while the difference between certified accuracy of the two approaches for a 4 layer network is small
(around 0.22%). We emphasize that to get good certified accuracy using our method, we need to
add curvature regularization during the training. Otherwise, the curvature bounds and therefore the
robustness certificates are loose.
Network	Training	Standard Accuracy	Certified Robust Accuracy	Certificate (mean)		Time per image (seconds)	
				CROWN	CRC	CROWN	CRC
2×[1024], sigmoid	standard	98.37%	54.17%	0.28395	0.48500	0.1818	0.1911
	γ = 0.005	97.96%	82.68%	0.36125	0.83367	0.1599	0.2229
	γ=0.01	98.08%	83.53%	0.32548	0.84719	0.1732	0.2186
	CRT, 0.01	98.57%	95.59%	0.43061	1.54673	0.1823	0.1910
3×[1024], sigmoid	standard	98.37%	0.00%	0.24644	0.06874	1.6356	0.5012
	γ = 0.005	97.98%	88.66%	0.38030	0.99044	1.6220	0.5319
	γ = 0.01	97.71%	88.33%	0.39799	1.07842	1.6342	0.5295
	CRT, 0.01	97.23%	94.99%	0.39603	1.24100	1.5625	0.5013
4×[1024], sigmoid	standard	98.39%	0.00%	0.19501	0.00454	4.7814	0.8107
	γ = 0.005	97.74%	88.95%	0.36863	0.91840	5.1667	0.8567
	γ=0.01	97.41%	89.61%	0.40620	1.05323	4.6296	0.8328
	CRT, 0.01	97.83%	93.41%	0.40327	1.06208	4.1830	0.8088
Table 3: Comparison between CROWN-general (Zhang et al., 2018a) and CRC. Note that both
CROWN and CRC are computed on CPU. However, running time numbers are not directly comparable
because our CRC implementation uses a batch of images while the CROWN implementation uses a
single image at a time.
7	Extensions and Discussion
7.1	Using local instead of global curvature bounds
From Theorems 1 and 2, we can observe that if the curvature is locally bounded within a convex region
around the input, then the corresponding dual problems (dCcer-t, d^ttack) are convex optimization
problems inside this region. This leads to the following result:
8
Under review as a conference paper at ICLR 2020
Network	Training	Standard Accuracy	Empirical Robust Accuracy	Certified Robust Accuracy	Certificate (mean)	
					CROWN	CRC
2×[1024], sigmoid	PGD	98.80%	96.26%	93.37%	0.37595	0.82702
	TRADES	98.87%	96.76%	95.13%	0.41358	0.92300
	CRT, 0.01	98.57%	96.28%	95.59%	0.43061	1.54673
3×[1024], sigmoid	PGD	98.84%	96.14%	0.00%	0.29632	0.07290
	TRADES	98.95%	96.79%	0.00%	0.30576	0.09108
	CRT, 0.01	98.23%	95.70%	94.99%	0.39603	1.24100
4×[1024], sigmoid	PGD	98.84%	96.26%	0.00%	0.25444	0.00658
	TRADES	98.76%	96.67%	0.00%	0.26128	0.00625
	CRT, 0.01	97.83%	94.65%	93.41%	0.40327	1.06208
Table 4: Comparison between CRT, PGD (Madry et al., 2018) and TRADES (Zhang et al., 2019).
Network	Training	Standard Accuracy	Certified Robust Accuracy
2×[1024], softplus	CRT, 0.01	98.68%	69.79%
3×[1024], softplus	CRT, 0.01	98.26%	14.21%
	CRT, 0.03	97.82%	50.72%
	CRT, 0.05	97.43%	57.78%-
4×[1024], softplus	CRT, 0.01	97.80%	6.25%
	CRT, 0.03	97.09%	29.64%-
	CRT, 0.05	96.33%	44.44%
Table 5: Comparison between CRT (left table) and Convex Outer Adversarial Polytope (right table)
(Wong et al., 2018) with attack radius ρ = 1.58.
Network	Standard Accuracy	Certified Robust Accuracy
2×[1024], relu	89.33%	44.29%
3×[1024], relu	89.12%	44.21%
4×[1024], relu	90.17%	44.66%
Network	Training	Standard Accuracy	Empirical Robust Accuracy	Certified Robust Accuracy	Certificate (mean)	
					CROWN	CRC
2 × [1024], sigmoid	standard	46.23%	37.82%	14.10%	0.37219	0.38173
	Y = 0.01	45.42%	38.17%	26.50%	0.40540	0.55010
3 × [1024], sigmoid	standard	48.57%	34.80%	0.00%	0.19127	0.01404
	γ = 0.01	50.31%	39.87%	18.28%	0.24778	0.37895
4 × [1024], sigmoid	standard	46.04%	34.38%	0.00%	0.19340	0.00191
	γ = 0.01	48.28%	40.10%	21.07%	0.29654	0.40005
Table 6: Results for CIFAR-10 dataset (only curvature regularization, no CRT training)
Corollary 1. Both Curvature-based Certificate and Attack Optimizations are convex optimization
problems within an l2 ball of radius ρ around the input sample where curvature values are bounded.
To use local curvature bounds, we need to ensure that the gradient descent trajectory does not escape
the local region where curvature values are bounded. To do this, we reduce the step size by a factor
of two until the trajectory lies inside the l2 ball of radius ρ around the input point.
It is straightforward to see that local bounds on curvature values can be tighter than global ones which
can lead to better robustness certifications. In Table 7, we show significant improvements for the CRC
certificate and some improvements on the certified accuracy for two-layer sigmoid and tanh networks
on the MNIST dataset. In this case, to compute local curvature bounds, we need to have a bound on
hL and hU (Theorem 3) within the ball of radius ρ around the input sample. These bounds can be
9
Under review as a conference paper at ICLR 2020
significantly tighter than the global bounds. For example, if a sigmoid neuron’s output is bounded
by -0.4 and 0.6 (those bounds can be obtained efficiently using CROWN), the second derivative of
sigmoid is bounded between -0.048 and +0.048, much better than the worst case bound -0.09623 and
+0.09623 used in current global curvature bound.
Network	Training	Certified Accuracy (Global)	Certified Accuracy (Local)	CRC Certificate (Global)	CRC Certificate (Local)
2×[1024], sigmoid	CRT, 0.0	95.04%	95.31%	1.0011	1.3901
	CRT, 0.01	95.59%	95.59%	1.5705	1.7262
	CRT, 0.02	95.21%	95.21%	1.6720	1.7397
2×[1024], tanh	CRT, 0.0	92.69%	94.39%	0.8028	1.0511
	CRT, 0.01	95.00%	95.00%	1.4832	1.6068
	CRT, 0.02	94.77%	―	94.77%	―	1.5848	—	1.6592
Table 7: Comparison between Certified Robust accuracy and CRC for 2 layer sigmoid and tanh
networks using global and local curvature bounds
For deeper networks, however, computing local curvature bounds is more challenging. We leave
exploring this direction for the future work.
7.2	Extension to convolutional neural networks
The formula derived in Lemma 1 is valid even for convolutional neural networks. However, to use
our methods, we need to bound the singular values of the Jacobian of the convolution operation. In
order to do this, one can use spectral bounds for convolution layers derived in Sedghi et al. (2018).
Furthermore, other heuristic techniques such as the one proposed in Miyato et al. (2018) can be used
for the curvature regularization as well. We present some prelimiary results using these techniques
for 2 layer convolutional networks on MNIST and CIFAR-10 in Appendix Section G.1.
8	Conclusion
In this paper, we develop computationally-efficient convex relaxations for robustness certification
and adversarial attack problems given the classifier has a bounded curvature. We also show that this
convex relaxation is tight under some general conditions. To be able to use proposed certification and
attack convex optimizations, we derive global curvature bounds for deep networks with differentiable
activation functions. This result is a consequence of a closed-form expression that we derived for
the Hessian of a deep network. Our empirical results indicate that our proposed curvature-based
robustness certificate outperforms the CROWN certificate by an order of magnitude while being
faster to compute as well. Furthermore, adversarial training using our attack method coupled with
curvature regularization results in a significantly higher certified robust accuracy than the existing
adversarial training methods. Scaling up our proposed curvature-based robustness certification and
training methods as well as further tightening the derived curvature bounds are among interesting
directions for the future work.
9	Acknowledgment
We thank the reviewers for their feedback and comments specially on extensions of our results to
characterize local curvature bounds.
References
Cem Anil, James Lucas, and Roger B. Grosse. Sorting out lipschitz function approximation. In
ICML, 2018.
10
Under review as a conference paper at ICLR 2020
Anish Athalye and Nicholas Carlini. On the robustness of the cvpr 2018 white-box adversarial
example defenses. ArXiv, abs/1804.03286, 2018.
Anish Athalye, Nicholas Carlini, and David A. Wagner. Obfuscated gradients give a false sense of
security: Circumventing defenses to adversarial examples. In ICML, 2018.
Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press, New
York, NY, USA, 2004. ISBN 0521833787.
Rudy Bunel, Ilker Turkaslan, Philip H. S. Torr, Pushmeet Kohli, and Pawan Kumar Mudigonda. A
unified view of piecewise linear neural network verification. In NeurIPS, 2017.
Xiaoyu Cao and Neil Zhenqiang Gong. Mitigating evasion attacks to deep neural networks via
region-based classification. ArXiv, abs/1709.05583, 2017.
Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten
detection methods. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and
Security, AISec'17,pp. 3-14, New York, NY, USA, 2017. ACM. ISBN 978-1-4503-5202-4. doi:
10.1145/3128572.3140444. URL http://doi.acm.org/10.1145/3128572.3140444.
Nicholas Carlini, Guy Katz, Clark E. Barrett, and David L. Dill. Provably minimally-distorted
adversarial examples. 2017.
Chih-HOng Cheng, Georg Nuhrenberg, and Harald Ruess. Maximum resilience of artificial neural
networks. In ATVA, 2017.
Jeremy M. Cohen, Elan Rosenfeld, and J. Zico Kolter. Certified adversarial robustness via randomized
smoothing. In ICML, 2019.
Francesco Croce, Maksym Andriushchenko, and Matthias Hein. Provable robustness of relu networks
via maximization of linear regions. ArXiv, abs/1810.07481, 2018.
Souradeep Dutta, Susmit Jha, Sriram Sankaranarayanan, and Ashish Tiwari. Output range analysis
for deep feedforward neural networks. In NFM, 2018.
Krishnamurthy Dvijotham, Sven Gowal, Robert Stanforth, Relja Arandjelovic, Brendan O’Donoghue,
Jonathan Uesato, and Pushmeet Kohli. Training verified learners with learned verifiers. ArXiv,
abs/1805.10265, 2018a.
Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy A. Mann, and Pushmeet Kohli.
A dual approach to scalable verification of deep networks. In UAI, 2018b.
Rudiger Ehlers. Formal verification of piece-wise linear feed-forward neural networks. ArXiv,
abs/1705.01320, 2017.
Matteo Fischetti and Jason Jo. Deep neural networks and mixed integer linear optimization. Con-
straints, 23:296-309, 2018.
Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and
Martin T. Vechev. Ai2: Safety and robustness certification of neural networks with abstract
interpretation. 2018 IEEE Symposium on Security and Privacy (SP), pp. 3-18, 2018.
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan
Uesato, Relja Arandjelovic, Timothy A. Mann, and Pushmeet Kohli. On the effectiveness of
interval bound propagation for training verifiably robust models. ArXiv, abs/1810.12715, 2018.
Matthias Hein and Maksym Andriushchenko. Formal guarantees on the robustness of a classifier
against adversarial manipulation. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30,
pp. 2266-2276. 2017.
Xiaowei Huang, Marta Z. Kwiatkowska, Sen Wang, and Min Wu. Safety verification of deep neural
networks. ArXiv, abs/1610.06940, 2016.
11
Under review as a conference paper at ICLR 2020
Guy Katz, Clark W. Barrett, David L. Dill, Kyle Julian, and Mykel J. Kochenderfer. Reluplex: An
efficient smt solver for verifying deep neural networks. In CAV, 2017.
Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial examples in the physical world.
ArXiv, abs/1607.02533, 2016a.
Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial machine learning at scale. ArXiv,
abs/1611.01236, 2016b.
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and S. K. K. Jana. Certified
robustness to adversarial examples with differential privacy. In IEEE S&P 2019, 2018.
Bai Han Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Certified adversarial robustness
with additive gaussian noise. 2018.
Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh. Towards robust neural networks via
random self-ensemble. ArXiv, abs/1712.00673, 2017.
Alessio Lomuscio and Lalit Maganti. An approach to reachability analysis for feed-forward relu
neural networks. ArXiv, abs/1706.07351, 2017.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. To-
wards deep learning models resistant to adversarial attacks. In International Conference on Learn-
ing Representations, 2018. URL https://openreview.net/forum?id=rJzIBfZAb.
Matthew Mirman, Timon Gehr, and Martin T. Vechev. Differentiable abstract interpretation for
provably robust neural networks. In ICML, 2018.
Takeru Miyato, Shin ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: A
regularization method for supervised and semi-supervised learning. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 41:1979-1993, 2017.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for
generative adversarial networks. In International Conference on Learning Representations, 2018.
URL https://openreview.net/forum?id=B1QRgziT-.
Seyed Mohsen Moosavi Dezfooli, Alhussein Fawzi, Jonathan Uesato, and Pascal Frossard. Robustness
via curvature regularization, and vice versa. In The IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), 2019.
N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami. Distillation as a defense to adversarial
perturbations against deep neural networks. In 2016 IEEE Symposium on Security and Privacy
(SP), pp. 582-597, May 2016. doi: 10.1109/SP.2016.41.
Nicolas Papernot, Patrick D. McDaniel, Ian J. Goodfellow, Somesh Jha, Z. Berkay Celik, and
Ananthram Swami. Practical black-box attacks against deep learning systems using adversarial
examples. CoRR, abs/1602.02697, 2016. URL http://arxiv.org/abs/1602.02697.
Jonathan Peck, Joris Roels, Bart Goossens, and Yvan Saeys. Lower bounds on the robustness to
adversarial perturbations. In NIPS, 2017.
Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Alhussein Fawzi, Soham De, Robert
Stanforth, and Pushmeet Kohli. Adversarial robustness through local linearization. arXiv preprint
arXiv:1907.02610, 2019.
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certified defenses against adversarial
examples. ArXiv, abs/1801.09344, 2018a.
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Semidefinite relaxations for certifying
robustness to adversarial examples. In NeurIPS, 2018b.
Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya P. Razenshteyn, and
SebaStien Bubeck. Provably robust deep learning via adversarially trained smoothed classifiers.
ArXiv, abs/1906.04584, 2019.
12
Under review as a conference paper at ICLR 2020
Pouya Samangouei, Maya Kabkab, and Rama Chellappa. Defense-GAN: Protecting classifiers
against adversarial attacks using generative models. In International Conference on Learning
Representations, 2018. URL https://openreview.net/forum?id=BkJ3ibb0-.
Hanie Sedghi, Vineet Gupta, and Philip M Long. The singular values of convolutional layers. arXiv
preprint arXiv:1805.10408, 2018.
GagandeeP Singh, Timon Gehr, Matthew Mirman, Markus PuscheL and Martin T. Vechev. Fast and
effective robustness certification. In NeurIPS, 2018.
Sahil Singla, Eric Wallace, Shi Feng, and Soheil Feizi. Understanding imPacts of high-order loss
aPProximations and features in deeP learning interPretation. In ICML, 2019.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing ProPerties of neural networks. In International Conference on Learning
Representations, 2014. URL http://arxiv.org/abs/1312.6199.
Jonathan Uesato, Brendan O,Donoghue, Pushmeet Kohli, and Aaron van den Oord. Adversarial risk
and the dangers of evaluating against weak attacks. In ICML, 2018.
Shiqi Wang, Yizheng Chen, Ahmed Abdou, and S. K. K. Jana. Mixtrain: Scalable training of
verifiably robust neural networks. 2018a.
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and S. K. K. Jana. Efficient formal safety
analysis of neural networks. In NeurIPS, 2018b.
Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Duane S. Boning, Inderjit S.
Dhillon, and Luca Daniel. Towards fast comPutation of certified robustness for relu networks.
ArXiv, abs/1804.09699, 2018.
Eric Wong and J. Zico Kolter. Provable defenses against adversarial examPles via the convex outer
adversarial PolytoPe. ArXiv, abs/1711.00851, 2017.
Eric Wong, Frank R. Schmidt, Jan Hendrik Metzen, and J. Zico Kolter. Scaling Provable adversarial
defenses. In NeurIPS, 2018.
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, and Michael I. Jordan.
Theoretically PrinciPled trade-off between robustness and accuracy. In ICML, 2019.
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efficient neural network
robustness certification with general activation functions. In S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 31, pp. 4939-4948. Curran Associates, Inc., 2018a.
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efficient neural network
robustness certification with general activation functions. ArXiv, abs/1811.00866, 2018b.
Huan Zhang, Pengchuan Zhang, and Cho-Jui Hsieh. Recurjac: An efficient recursive algorithm for
bounding jacobian matrix of neural networks and its applications. In AAAI, 2018c.
Stephan Zheng, Yang Song, Thomas Leung, and Ian J. Goodfellow. Improving the robustness of deep
neural networks via stability training. 2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 4480-4488, 2016.
13
Under review as a conference paper at ICLR 2020
Appendix
A Related work
Many defenses have been proposed to make neural networks robust against adversarial examples.
These methods can be classified into empirical defenses which empirically seem to be robust against
known adversarial attacks, and certified defenses, which are provably robust against such attacks.
Empirical defenses The best known empirical defense is adversarial training (Kurakin et al., 2016b;
Madry et al., 2018; Zhang et al., 2019). In this method, a neural network is trained to minimize the
worst-case loss over a region around the input. Although such defenses seem to work on existing
attacks, there is no guarantee that a more powerful attack would not break them. In fact, most such
defenses proposed in the literature were later broken by stronger attacks (Athalye et al., 2018; Carlini
& Wagner, 2017; Uesato et al., 2018; Athalye & Carlini, 2018). To end this arms race between
defenses and attacks, a number of works have tried to focus on certified defenses that have formal
robustness guarantees.
Certified defenses A classifier is said to be certifiably robust if one can easily obtain a guarantee that
a classifier’s prediction remains constant within some region around the input. Such defenses typically
rely on certification methods which are either exact or conservative. Exact methods report whether
or not there exists a adversarial perturbation inside some lp norm ball. In contrast, conservative
methods either certify that no adversarial perturbation exists or decline to make a certification; they
may decline even when no such perturbation exists. Exact methods are usually based on Satisfiability
Modulo Theories (Huang et al., 2016; Katz et al., 2017; Ehlers, 2017; Carlini et al., 2017) and Mixed
Integer linear programming (Cheng et al., 2017; Lomuscio & Maganti, 2017; Dutta et al., 2018;
Fischetti & Jo, 2018; Bunel et al., 2017). Unfortunately, they are computationally inefficient and
difficult to scale up to even moderately sized neural networks. In contrast, conservative methods are
more scalable and efficient which makes them useful for building certified defenses (Wang et al.,
2018a; Wong & Kolter, 2017; Wang et al., 2018b; Wong et al., 2018; Raghunathan et al., 2018b;a;
Dvijotham et al., 2018a;b; Croce et al., 2018; Singh et al., 2018; Gowal et al., 2018; Gehr et al., 2018;
Mirman et al., 2018; Zhang et al., 2018b; Weng et al., 2018). However, even these methods have not
been shown to scale to practical networks that are large and expressive enough to perform well on
ImageNet, for example. To scale to such large networks, randomized smoothing has been proposed
as a probabilistically certified defense.
Randomized smoothing Randomized smoothing was previously proposed by several works (Liu
et al., 2017; Cao & Gong, 2017) as a empirical defense without any formal guarantees. LecUyer
et al. (2018) first proved robustness guarantees for randomized smoothing classifier using inequalities
from differential privacy. Li et al. (2018) improved upon the same using tools from information
theory. Recently, Cohen et al. (2019) provided a even tighter robustness guarantee for randomized
smoothing. Salman et al. (2019) proposed a method of adversarial training for the randomized
smoothing classifier giving state of the art results in the l2 norm metric.
B	The Attack problem
For a given input x(0) with true label y and attack target t, consider the attack problem. We are given
that the eigenvalues of the Hessian vX (ZyL) - Z(L)) are bounded below i.e:
ml & V2 (Z(L)- Z(L))	∀x ∈ RD
xy t
Here m < 0 (since Z(yL) - Zt(L) is not convex in general).
The goal here is to find an adversarial example inside a l2 ball of radius ρ such that (Z(yL) - Zt(L) )(x)
is minimized. That is, we want to solve the following optimization:
*toe®=∣∣x-m⅛ρ [ (ZyL)- Z(L))(X)]=映nmaχ [ (ZyL)- Z(L))(X)+2 QX - x(0) ∣∣2 - ρ2)]
(8)
14
Under review as a conference paper at ICLR 2020
This optimization can be hard in general. Using the max-min inequality (primal ≥ dual), we have:
pattack ≥ maX dattack ⑺,
dattack (η) = nxn [ (ZyL)- Z(L) ) (X) + 2 QX - x(0)∣∣2 - P2 )]⑼
We know that for every η ≥ 0, dattack (η) gives a lower bound to the primal solution pattack. BUt
solving dattack(η) for any η ≥ 0 can be hard unless the objective is convex. We prove that if the
eigenvalues of the Hessian are bounded below i.e:
ml W V2 (Z(L)- Z(L))	∀x ∈ RD
xy t
In general m < 0, since (Z(yL) - Zt(L)) is non-convex.
dattack(η) is a convex optimization problem for -m ≤ η. Equivalently the objective function, i.e the
function inside the minx :
[ (ZyL)- ZzLL)(x)+2 QX -X(O) ∣2-ρ2)]
The Hessian of the above function is given by:
is a convex function in x for - m ≤ η
V2x (Z(yL) - Zt(L)) + ηI
Since we know that eigenvalues of Vx(ZyL) - Z(L))廿 ml, we know that eigenvalues of the above
Hessian are ≥ η + m. For η ≥ -m, the eigenvalues are positive implying that the objective function is
convex.
Since dattack (η) gives a lower bound to pattack for every η ≥ 0, we get the following result:
pattack ≥ dattack where dattack = max dattack (η)	(10)
-m≤η
Note that if x(attack) is the solution to dattack such that: |x(attaCk) - x(0) ∣∣ = ρ, by the definition of
d*...:
attack:
da*ttack = (Z(L) -Zt(L)) (x(attack))
attack y t
But then by the definition of pa*ttack, pa*ttack ≤ d*attack, implying that the duality gap is zero, i.e
pa*ttack = d*attack. This procedure leads to the theorem 2.
C Implementation Details
C.1 Computing the derivative of largest singular value
Our objective is to compute derivative of the largest singular value, i.e IlW(I) ∣∣ with respect to W(I).
u(I), v(I) are the singular vectors such that:
W(I)v(I) = IW(I)Iu(I)
v(I), IW(I) I2 can be computed by running power iteration on (W(I))T W(I). u(I) can be
computed using the identity:
U(I) = W(I)V(I)
U =	Y (I)
We use 25 iterations of the power method to compute the above quantities.
C.2 Update equation for the certificate problem
Our goal is to minimize ∣x - x(0) ∣ such that (Z(yL) - Zt(L)) (x) = 0. We know that the Hessian
satisfies the following LMIs:
mI W V2x (Z(yL) -Zt(L)) W MI	(11)
15
Under review as a conference paper at ICLR 2020
K is given by Theorem 4 for neural network of any depth (L ≥ 2). For 2 layer networks, M and
m are given by Theorem 3. But for deeper networks (L ≥ 3), M = K, m = -K. In either case,
K ≥ max(∣m∣, ∣M ∣). Thus, we also have:
-K I W vX (ZyL)-Z(L))W KI	(12)
We will solve the dual (也代)of the attack problem (Pcert).
The primal problem (Pcert) is given by:
PcQVt =	min	UIlX - x(0)『 =min max
CertzyL)(XH)(X)3∣	11 J x η
Using inequality (11) and Theorem 1 part (a), we know that the dual of the above problem is convex
when -1/M ≤ η ≤ -1/m.
1 ι∣χ-x(叫2+η (ZyL)- Z(L))(X)
The corresponding dual problem (dCcert) is given by:
“cert = -1∕1Mm"de⑺，
dcert (η) = min 1 ∣∣χ -X(O) ∣∣2 + η (ZyL)- Z(L))(X)
For a given η, we have the following optimization:
dcert(η) = min 2IlX-X(O)II2 + η(ZyL)-Z(L))(X)
We will use majorization-minimization to solve this optimization.
At a point X(k), we aim to solve for the point X(k+1) that decreases the objective function. Using the
Taylor’s theorem at point X(k), we have:
(Z(yL) -Zt(L)) (X)
=(ZyL)-Z(L))(X(k)) + (g(k))T(X - X(k)) + 1(X - X(k))T H(ξ)(X - X(k))
where g(k) is the gradient of (Z(yL) - Zt(L)) at X(k) and H(ξ) is the Hessian at a point ξ on the line
connecting X and X(k).
Multiplying both sides by η, we get the following equation:
η (Z(yL) -Zt(L)) (X)
=η (ZyL)- Z(L))(X(k)) + η (g(k))T (x - X(k)) + 号(x - X(k))T H(ξ) (x - X(k))	(13)
Using inequality (12), we know that -KI W H(ξ) W KI ∀ξ ∈ RD,
2 (x-x(k))T H(ξ)(x-x(k)) ≤ ∣ηK∣∣x - x(k)∣2	(14)
Using equation (13) and inequality (14):
η(ZyL)- Z(L)) (x) ≤ η (ZyL)- Z(L))(X(k)) + η(g(k))T(x-x(k)) + ∣ηK∣ ∣∣x-x(k)∣2
Adding 1/2IX - X(O) I2 to both sides, we get the following inequality:
1 ι∣x -X(O)I∣2+η (ZyL)- Z(L))(X)
≤ 1 ∣x-X叫2 + η(ZyL)-Z(L))(x(k)) + η(g(k))T(X-X(k)) + ∣η2K∣ IlX-X叫2
LHS is the objective function of dCert (η) and RHS is an upper bound. In majorization-minimization,
we minimize an upper bound on the objective function. Thus we set the gradient of RHS with respect
to X to zero and solve for X:
Vx [ 11lX -X(O)I2 + η (ZyL)- Z(L))(x(k)) + η(g(k))T (x- x(k)) + ∣ηK∣ IlX - x(k)∣2] = o
16
Under review as a conference paper at ICLR 2020
x- x(0) + ηg(k) + ∣ηK∣ (x -x(k)) = 0
(1 + ∣ηK∣)x - x(0) + ηg(k) - ∣ηK∣ x(k) = 0
x = -(1 + ∣η K ∣)-1 (ηg(k) - ∣ηK∣x(k) - x(0))
This gives the following iterative equation:
x(k+1) = -(1 + ∣ηK∣)-1 (ηg(k) - ∣ηK∣x(k) - x(0))	(15)
C.3 Update equation for the attack problem
Our goal is to minimize z(yL) - zt(L) within an l2 ball of radius ofρ. We know that the Hessian satisfies
the following LMIs:
ml W vX (ZyL)- Z(L)) W MI	(16)
K is given by Theorem 4 for neural network of any depth (L ≥ 2). For 2 layer networks, M and
m are given by Theorem 3. But for deeper networks (L ≥ 3), M = K, m = -K. In either case,
K ≥ max(∣m∣, ∣M ∣). Thus, we also have:
-KIWv2x(Z(yL)-Zt(L))WKI	(17)
We solve the dual 刎力仇.0卜)of the attack problem (Palttack) for the given radius ρ.
The PrimaI ProbIem (PIttack) is given by:
pattack =	mon ZyL)- ZzLL=minmax [zyL) - ZzLL + 2 QX -X叫2 -ρ2)]
∣∣x-x(0)y≤ρ	X η≥0 L	2 ∖	f j
Using inequality (16) and Theorem 2 Part (a), we know that the dual of the above Problem is convex
when -m ≤ η.
The corresPonding dual Problem (dclert) is given by:
dlattack = ηm≥-amx dattack(η),
dattack (η) = min [ (ZyL)- Z(L) ) (X) + 2 QX - X(0)∣∣2 - P2 )]
For a given η, we have the following oPtimization:
dattack (η) = min [(z)L)- Z(L)) (X) + 2 QX -X(O) f - P2 )]
We will use majorization-minimization to solve this oPtimization.
At a Point X(k), we have to solve for the Point X(k+1) that decreases the objective function. Using the
Taylor’s theorem at Point X(k), we have:
(Z(yL) -Zt(L)) (X)
=(ZyL)- Z(L))(X(k)) + (g(k))T (x - X(k)) + 1 (x - X(k))TH(ξ) (x- X(k))	(18)
where g(k) is the gradient of (Z(yL) - Zt(L)) at X(k) and H(ξ) is the Hessian at a Point ξ on the line
connecting X and X(k).
Using inequality 17, we know that -KI W H(ξ) W KI ∀ξ ∈ RD,
2(X -X(Ik) )T H(ξ) (x -X(Ik)) ≤ KK ∣∣X - X(k) ∣∣2	(19)
Using equation (18) and inequality (19):
(ZyL)-Z(L))(X) ≤ (ZyL)-Z(L))(x(k))+(g(k))T(x - x(k))+ κK IIX-χ(k)∣2
17
Under review as a conference paper at ICLR 2020
Adding η∕2(∣∣x - x(0) ∣∣2 - ρ2) to both sides, We get the following inequality:
(ZyL)- Z(L))(X)+2 QX-χ(o)ιι2-ρ2)
≤ ㈤L)-Z(L))(X(k)) + (g(k))T (x- x(k)) + KK ∣∣χ- x(k)『+ 2 QX- x(叫2 - ρ2)
LHS is the objective function of dattack (η) and RHS is an upper bound. In majorization-minimization,
we minimize an upper bound on the objective function. Thus we set the gradient of RHS with respect
to x to zero and solve for x:
▽x [(zyL)-Z(L))(X(k)) + (g(k))T(x-x(k)) + KK I∣x-x(k)∣2 + 2 QX-x(0)∣2 -ρ2)] = 0
g(k) + K (x- x(k)) + η(x- x(0)) = 0
(K+ η)x + g(k) - K x(k) - ηx(0) = 0
x=-(K+η)-1(g(k)- Kx(k) - ηx(0))
This gives the following iterative equation:
x(k+1) =-(K+η)-1(g(k)- Kx(k) - ηx(0))	(20)
C.4 Algorithm to compute the certificate
We start with the following initial values of x, η, ηmin , ηmax :
ηmin = -1∕M,	ηmax = -1∕m
η = 2 (ηmin + ηmax),	X = X⑼
To solve the dual for a given value of η, we run 20 iterations of the following update (derived in
Appendix C.2):
x(k+1) = -(1 + ∣η K ∣)-1 (ηg(k) - ∣ηK ∣x(k) - x(0))
To maximize the dual dcert (η) over η in the range [-1∕M, -1∕m], we use a bisection method: If the
solution x for a given value of η, (Z(yL) - Zt(L))(x) > 0, set ηmin = η, else set ηmax = η. Set the new
η = (ηmin + ηmax)∕2 and repeat. The maximum number of updates to η are set to 30. The routine to
compute the certificate example is given in Algorithm 1.
C.5 Algorithm to compute the attack
We start with the following initial values of x, η, ηmin , ηmax :
ηmin = -m,	ηmax = 20(1 - m)
η = 2 (ηmin + ηmax),	X = X⑼
To solve the dual for a given value of η, we run 20 iterations of the following update (derived in
Appendix C.3):
x(k+1) =-(K+η)-1(g(k)- Kx(k) - ηx(0))
To maximize the dual dcert(η) over η in the range [-m, 20(1 - m)], we use a bisection method:
If the solution X for a given value of η, ∣∣x - X(O) ∣∣ ≤ ρ, set ηmaχ = η, else set ηmin = η. Set new
η = (ηmin + ηmax)∕2 and repeat. The maximum number of updates to η are set to 30. The routine to
compute the attack example is given in Algorithm 2.
18
Under review as a conference paper at ICLR 2020
Algorithm 1 Certificate optimization
Require: input x(0), label y, target t
m, M, K — Compute-bounds(ZyJL - Z(L))
ηmin * IlM
ηmax - -1/m
η J 1/2(nmin + ηmax)
x * x(0)
for i in [1, . . . , 30] do
for j in [1, . . . , 20] do
g J Compute .gradient(ZyL - Z(LL, x)
if Il ηg + (X - x(0))∣∣ < 10-5 then
break
end if
x J -(1 + ∣η K ∣)-1 (ηg- ∣ηK∣x - x(0L)
end for
if (Z(yLL - Zt(LL)(x) > 0 then
ηmin J η
else
ηmax J η
end if
η J (ηmin + ηmax)/2
end for
return x
Algorithm 2 Attack optimization
Require: input x(0L, label y, target t , radius ρ
m, M, K J CompUteJ)ounds(ZyL - Z(LL)
ηmin J -m
ηmax J 20(1 - m)
η J 1/2(nmin + ηmax)
x J x(0L
for i in [1, . . . , 30] do
for j in [1, . . . , 20] do
g J Compute.gradient(ZyL - Z(LL, x)
if Ig + η(x - x(0L)I < 10-5 then
break
end if
x J -(K + η)-1 (g - Kx - ηx(0L)
end for
if Ix - x(0L I < ρ then
ηmax J η
else
ηmin J η
end if
η J (ηmin + ηmax)/2
end for
return x
19
Under review as a conference paper at ICLR 2020
D Proofs
D.1 PROOF OF THEOREM 1
(a)
dcert(η) = min | ∣∣x -X(O)I『+ η (ZyL)(X)-Z(L)(X))
▽X 2 ∣∣x -X(O)I∣2 + η (ZyL)(X)- Z(L)(X)) = I + ηvX (ZyL)- Z(L))
We are given that the Hessian Vx(ZyL) - Z(L)) satisfies the following LMIs:
ml W Vx (ZyL)- Z(L)) W MI	∀x ∈ Rn
The eigenvalues of I + ηVx(ZyL) - Z(L)) are bounded between:
(1 + ηM, 1 + ηm), if η < 0
(1 + ηm, 1 + ηM), if η > 0
We are given that η satisfies the following inequalities where m < 0, M > 0 since (ZyL) 一
Z(L)) is neither convex, nor concave as a function of x:
-1	-1
—≤ η ≤ 一, m < 0, M > 0
We have the following inequalities:
1 + ηM ≥ 0, 1 + ηm ≥ 0
Thus, I + ηVx(ZyL)- Z(L)) is a PSD matrix for all X ∈ Rd when -1/M ≤ η ≤ -1/m .
Thus 1/2IIX - X(O) ∣∣2 + η(ZyLL- Z(L)) (x) isa convex function in X and dcert(η) is a convex
optimization problem.
(b) For every value of η, dcert(η) is a lower bound for p^rt∙	Thus d：ert =
max-i/M≤ n ≤-1∕m dcert(η) is a lower bound for p：ert, i.e:
dcert ≤ *rt	QI)
Let η(cert), X(Cert) be the solution of the above dual optimization (d*ert) such that
ZyL) (X(Cert)) = Z(L) (X(Cert))	(22)
d：ert is given by the following:
成ert = 1 IlX(Cert)-X(O) ∣2 + η(Cert) (ZyL)(X(Cert))-Z(L)(X(Cert)))
'--------------V-------------Z
=0
Since we are given that ZyL)(X(Cert)) = Z(L)(X(Cert)), we get the following equation for
d* ,:
Cert
成ert = 2 IIX(Cert)-X(叫2	(23)
Since p：ert is given by the following equation:
一★	__:一
PCert =	min
ZyL)(X)=ZtL)(X)
2假-X叫2
(24)
Using equations (22) and (24), p：ert is the minimum value of 1/2IIX - X(O)Il2 ∀x :
Z(yL) (X) = Zt(L) (X):
*rt ≤ 2 IlX(Cert)-X叫2	(25)
From equation (23), we know that d*ert = 1/2||x(Cert) - X(O) ∣∣2. Thus, we get:
Pcert ≤ 成ert	(26)
Using equation (21) we have d*ert ≤ P*ert and using (26), p*ert ≤ d*ert
^	/*
pcert = dcert
20
Under review as a conference paper at ICLR 2020
D.2 Proof of Theorem 2
(a)
dattack(η) = min [ (ZyL)- Z(L))(x) + 2 QX -X(O) ∣∣2 - p2)]
▽x[(zyL)-Z(L)卜 x) + 2 IlX - x(0) ∣2 ] = VX (ZyL)-Z(L)) + η
Since the Hessian Vx(ZyL) - Z(L)) is bounded below:
ml & V2 (Z(L)- Z(L))	∀x ∈ Rn
x ∖ y	L)
The eigenvalues of Vx(ZyL) - Z(L)) + ηI are bounded below:
(m + η)I & Vx (ZyL)- Z(L)) + ηI
Since η ≥ -m.
η + m ≥ 0
Thus Vx(ZyL)- z(l) ) + ηI is a PSD matrix for all X ∈ Rd when η≥ -m.
Thus (ZyL) - z(l))(x) + η∕2(∣∣x - X(O) ∣∣2 - ρ2) is a convex function in X and da,ttack(η) is
a convex optimization problem.
(b)	For every value of η, dattack (η) is a lower bound for PattaCk	ThUS d^tack =
max-m≤n dattack (η) is a lower bound for PattaCk
dattack ≤ PattaCk	(27)
Let η(attack), XgttaCk) be the solution of the above dual optimization (dattack) SUCh that
k(attaCk)-X(O) h P	(28)
dattack is given by the following:
(attack)
dattack = (ZyL)-Z(L))(X(attack)) + η-^ (∣x(attaCk)-X(O)II-P2 )
=0
Since we are given that ||x(attaCk) - X(O) ∣∣ = ρ, we get the following equation for dattack:
dattack = (ZyL)-Z(L))(X(attaCk))	(29)
Since Paattack is given by the following equation:
PattaCk = " m⅛	[ (ZyL)- Z(L))(X)	(30)
∣∣x-x(叫 ∣≤ρ[∖ y	) J
Using equations (28) and (30), Paattack is the minimum value of (Z(yL) -
Z(L))(X)	∀IIX-X(O)Il ≤P:
Pattack ≤ (ZyL)- Z(L))(X(attaCk))	(31)
From equation (29), we know that daattack = (Z(yL) - Zt(L))(X(attack)). Thus, we get:
Pattack ≤ dattack	(32)
Using equation (27) we have daattack ≤ Paattack and using (32), Paattack ≤ daattack
Pattack = dattack
21
Under review as a conference paper at ICLR 2020
D.3 Proof OF Lemma 1
We have to prove that for an L layer neural network, the hessian of the ith hidden unit in the Lth
layer with respect to the input x, i.e V∣z(L) is given by the following formula:
,、L-1	T
VxZ(L) = ∑ (B(I))T diag
I=1
Θ『(z(I)))B(I)
where B(I), I ∈ [L] is a matrix of size NI × D defined as follows:
-	-T
B(I) = VXZ1I), Vχz2I),..., VXZNJ)	, I ∈ [L]
(33)
(34)
and F(l,i), I ∈ [L - 1] is a matrix of size NL × NI defined as follows:
T
F(LQ = Va(J)ZIL), Va(J)Z2L),..., Va(J)ZN)	, I ∈ [L - 1]	(35)
VXZ(L) can be written in terms of the activations of the previous layer using the following formula:
Nj-1	,	、
VXZ(L) = ∑ W(L) (VXajLT))
j=i
(36)
Using the chain rule of the Hessian and a(I) = σ(Z(I)), we can write VXajL-I) in terms of VXZjL-I)
and VXZ(L-I) as the following:
VXajLT)= J(Z(L-I))(VXZ(L-I))(VXZ(L-I))T + σ (z(LT))(VXZ(L-I))	(37)
Replacing VXa(L-I) using equation (37) into equation (36), we get:
π2	(L)	N-	(L) Γ	"/	(L-1)∖∕°	(L-1)∖∕°	(L-1)∖Tl ‘/	(L-1)∖∕ π2	(L-1)∖]
VXZr= W W(F (Zj	J)(VXZj	)(VXZj	) +σ (Zj	)(vxz()]
NL-1	.	.	.	. T
vXz(L) = ∑ w(L"(z(LT))(VXZjLT))(VXZjLT))T
,J
j=1
NTL ι	. .
+ ∑w(,L*(zjLT))(VXZjLT))	(38)
j=1
For each I ∈ [2,L], i ∈ NI, we define the matrix A(I) as the following:
.	.	Nr-1	.	.	.	. N Nr-1	.	.	.
VX (z(I)) = ∑ W(",(zjI-I))(VXZjI-I))(VXZjI-I))T + ∑ W(I)σ(zj1-I))(VXZjI-I))
j=1	j=1
'-------------------V------------------Z
AiJ)
2	(39)
Nj-i	,	, ,	,	、T
A(I) = ∑ W(Iy(Z(IT))(VXZjIT)) (VXZ(IT))T	(40)
j=1
Substituting A(L) using equation (40) into equation (38), we get:
Nj ι	. .
VX (z(L)) = a(L) + ∑ W(I)σ (zj1T))(VXZjI-1))	(41)
j=1
We first simplify the expression for A(L). Note that A(L) is a sum of symmetric rank one matrices
(VXZ(L-I))(VXZjL-I)) with the coefficient W(L)σ” (z(L-I)) for each j. We create a diagonal
22
Under review as a conference paper at ICLR 2020
matrix for the coefficients and another matrix B(L-1) such that each jth row of B(L-1) is the vector
VχzjL-1). This leads to the following equation:
NL 1
A(L) = ∑w("'(zjLT))(Vxz(LT))(VxzjLT))T
j=1
= (B(LT))Tdiag (W(L)O σ, (Z(LT))) B(LT)	(42)
B(I) where I ∈ [L] is a matrix of size NI × D defined as follows:
T
B(I) = [Vxz(1I),Vxz(2I),...,Vxz(NII)] , I ∈ [L]
Thus B(I) is the jacobian of z(I) with respect to the input x.
Using the chain rule of the gradient, we have the following properties of B(I):
B(1) = W(1)	(43)
B(I) = W(I)diag (σ' (Z(I-I))) B(I-I)	(44)
Similarly, F(I,J) where I ∈ [L], J ∈ [I - 1] is a matrix of size NI × NJ defined as follows:
T
F(I,J) = [Va(J)z(1I), Va(J)z(2I),..., Va(J)z(NII)] ,	I∈ [L],J∈ [I-1]
Thus F(I,J) is the jacobian ofz(I) with respect to the activations a(J).
Using the chain rule of the gradient, we have the following properties for F(L,I):
F(L,L-1) = W(L)
F(Lj) = W(LLdiag (σ' (z(LT))) F(L—1，I)
(45)
(46)
Recall that in our notation: For a matrix E, Ei denotes the column vector constructed by taking
the transpose of the ith row of the matrix E. Thus ith row of W(L) is (Wi(L)) and F(L，I) is
(Fi(L，I)) . Equating the ith rows in equation (46), we get:
(F(L，I))T = (W(L))T diag (σ (Z(L-I))) F(L-1，I)
Taking the transpose of both the sides and expressing the RHS as a summation, we get:
F(LJ) = ((W(L))T diag (σ, (z(L-I))) F(L-1，I)『=N∑∑ W(L)σ' (zjL-I)) FjL-1，I)
j=1
Substituting W(L) using equation (45) into equation (42), we get:
A(L) = (B(L-I))Tdiag(F(L，L-1) O σ''(z(L-I))) B(L-I)
Substituting Ai(L) using equation (48) into (41), we get:
Vx z(L) = (B(L-I) )T diag (F(L，L-1) O σ' (Z(L-I))) B(L-I)
NL 1
+ ∑ W(,L)σ(zjL-I))(VxZjL-I))
，
j=1
(47)
(48)
(49)
Thus, equation (49) allows us to write the hessian of ith unit at layer L, i.e (V2xzi(L)) in terms of the
).
hessian of jth unit at layer L - 1, i.e (V2xzj(L-1)
We will prove the following using induction:
VxZ(L)= ∑1 (B(I) )T diag (F(LQ O σ' (Z(I))) B(I)
I=1
(50)
23
Under review as a conference paper at ICLR 2020
Note that for L = 2, V2xzj(L-1) = 0, ∀j ∈ N1. Thus using (49) we have:
Vxz(2) = (B ⑴)T diag (F(2,1) Θ σ’ (Z ⑴))B(I)
Hence the induction hypothesis (50) is true for L = 2.
Now we will assume (50) is true for L - 1. Thus we have:
L-2
V2xzj(L-1) = ∑ (B(I)) diag (Fj(L-1,I) Θσ (z(I)))B(I)	∀j ∈ NL-1
I=1
(51)
We will prove the same for L.
Using equation (49), we have:
vXz(L) = (B(LT) )T diag (f(l,l-1) Θ σ'' (z(LT))) B(LT)
NL 1
+ ∑ W(L)σ(zjLT))(VxZjLT))
j=1
In the next set of steps, we will be working with the second term of the above equation, i.e
∑NL-1 W(L)σ (ZjLT))(VxZjLT)):
Substituting V2xzj(L-1) using equation (51) we get:
VxZ(L) = (B(LT))Tdiag (F(L,L-1) Θ σ' (Z(LT))) B(LT)
+ N∑ W(L)σ' (ZjLT)) (Σ2 (B(I)) diag (FjLT，I)Θ σ'' (Z(I))) (B(I))T)
j =1	,	I=1
Combining the two summations in the second term, we get:
VxZ(L) = (B(LT))Tdiag (F(L,L-1) Θ σ'' (z(LT))) B(LT)
+ N∑1 ∑2 W(,L)σ (zjLT)) (B(I))T diag (F(LT，I)
j =1 I=1
Exchanging the summation over I and summation over j :
VxZ(L) = (B(LT))T diag (F(L,L-1) Θ σ'' (z(LT))) B(LT)
+ ∑2 n∑ W(L)σ (ZjLT)) (B(I))T diag (F(L-1,I)
I=1 j =1
Θ σ''(Z(I))) B(I)
Θ σ'' (Z(I))) B(I)
Since B(I) is independent ofj, we take it out of the summation over j:
VxZ(L) = (B(L-I))T diag (F(L,L-1) Θ σ'' (z(L-I))) B(L-I)
+ Σ2 (B(I))T ( NE-1 W(L)σ' (ZjL-I)) diag (FjLT,I) Θ σ'' (z(I))))B(I)
I=1	j =1	,
Using the property, α (diag(u)) + β (diag(v)) = diag (αu + βv) ∀α, β ∈ R, u, v ∈ Rn; we can
move the summation inside the diagonal:
VxZ(L) = (B(LT))Tdiag (F(L,L-1) Θ σ''(z(LT))) B(LT)
+ L∑-2 (B(I))T diag
I=1
31 W(,L)σ(zjLT))(F 尸I)
j=1
Θ σ''(z(I)))]b(i)
Since σ'' (z(I)) is independent of j, We can take it out of the summation over j:
VxZ(L) = (B(L-I))T diag(F(L,L-I) Θ σ' (Z(L-I))) B(L-I)
+ ∑2 (B(I))Tdiag[( Nt-I W(L)σ (zjLT)) F(L-1,I)) Θ σ''
I=1	j =1
(Z(I))]B(I)
24
Under review as a conference paper at ICLR 2020
Using equation (47), We can replace ∑NL-1 Wj (ZjLT)) FjLTI) With F(LI:
VXz(L) = (B(LT) )T diag(F(L,L-1) © σ'' (z(LT))) B(LT)
+ E (B(I) )T diag(F(L,I) © σ' (Z(I)))B(I)
V2xzi(L)
L∑-1 (B(I))T diag(Fi(L,I)
I=1
© σ' (Z(I)))B(I)
D.4 Proof of Theorem 3
Using Lemma 1, We have the folloWing formula for V2x
(Z(y2) - Zt(2)):
vX (zy2) - z(2)) = (W(I))T diag( (wy2) - w(2)) © σ' (Z ⑴))W ⑴
N1
= ∑ (Wy(2,i) -Wt(,2i))σ (Zi(1))Wi(1)(Wi(1))T
i=1
(52)
We are also given that the activation function σ satisfies the folloWing property:
hL ≤ σ (x) ≤ hu ∀x ∈ R
(53)
(a) We have to prove the folloWing linear matrix inequalities (LMIs):
N W vX (ZS)- z(2))w P	∀x ∈ RD	(54)
Where P and N are given as folloWing:
P= ∑N1 pi (W(y2,i) - Wt(,2i)) Wi(1) (Wi(1))T
i=1
N= ∑N1 ni (W(y2,i) - Wt(,2i)) Wi(1) (Wi(1))T
i=1
hu,	wy2i)- w(2) ≥ oi	M,	wy2i) - W(2i) ≥ 0、
pi = [hL,	Wi- W^ ≤ 0j ,	ni = [hu,	Wy2i)- W ≤ 0'
(55)
(56)
(57)
We first prove: N W v2X (z(y2) - zt(2))	∀x ∈ RD:
We substitute v2X (z(y2) - zt(2)) and N from equations (52) and (56) respectively in
v2X (z(y2) - zt(2)) - N:
v2X (z(y2) - zt(2)) - N
=∑ ( (Wy2i) - W(2i)) σ'' (z(1)) -(Wy2i) - w(2i)) ni)w(1) (Wi(I))T
=Σ (Wy2i) - W(,2i))(σ'' (z(1)) - ni) W(I) (W(I))T
Thus v2X (z(y2) - zt(2)) - N is a Weighted sum of symmetric rank one matrices i.e,
Wi(1) (Wi(1))T
and it is PSD if and only if coefficient of each rank one matrix i.e,
(w)? - W(7)(σ (z(1)) - ni) is positive. Using equations (53) and (57), we have
25
Under review as a conference paper at ICLR 2020
the following:
(W)" W(7) ≥ 0 =⇒	ni	=	Kl	=⇒	(σ" (z(1)) - ni) ≥ 0	∀i ∈	[N1],	∀x ∈ RD
(W)7 - W(?) ≤ 0 =⇒	ni	=	hu	=⇒	(σ" (z(I))- n, ≤ 0	∀i ∈	[N1],	∀x ∈ RD
=⇒ (WiS- W(7)(σ"(z(1))-ni)≥ 0	∀i ∈ [N1 ], ∀x ∈ RD	(58)
Thus V∣ (z)2) - z(2)) - N is a PSD matrix i.e:
▽x (z)2) - z(2)) - N = ∑ (w)2? - W(2))(σ" (z(I)) - ni) W(I) (W(I))T > 0	∀x ∈ RD
i=1 `---------------,-----------------'
always positive using eq. (58)
=⇒ N W VX (z)2) - z(2))	∀x ∈ RD	(59)
Now we prove that VX (z)2) - z(2)) & P ∀x ∈ RD:
We substitute VX (z)2) - z(2)) and P from equations (52) and (56) respectively in P -
VX (z)2) - z(2)):
P - VX (z)2) - z(2)) = ∑ ( (w)2? - w[?)Pi-(Wy2) - W(?) σ" (Z(I)))W(I)(W(I))T
N1 ,
=∑ W
-Wfi)) (Pi-σ" (Z(I))) W(I)(Wi(I))T
Thus P - VX (z)2) - z(2)) is a weighted sum of symmetric rank one matrices i.e,
W(I) (W(I)) and it is PSD if and only if coefficient of each rank one matrix i.e,
(Wy：)- W(I))(Pi -σ, (Z(I))) is POSiti2
following:
Using equations (53) and (57), we have the
(wy2i) - w(2))≥ 0 =⇒	Pi	= hu =⇒	(pi - σ”(z(1)))≥ 0	∀i ∈ N1,	X ∈ RD
(Wy2i) - W(2))≤ 0 =⇒	pi	= Kl =⇒	(pi - σ”(z(1))≤ 0	∀i ∈ N1,	X ∈ RD
=⇒ (w)2i) - w(7 )(pi - σ”(z(1)))≥ 0	∀i ∈ [N1 ], X ∈ RD	(60)
Thus P -VX (z)2) - z(2)) is PSD matrix i.e:
P -VX (z)2) - z(2))
=N (W)? - Wfi))(Pi- σ" (z(I))) W((I) (W(I))T ) 0	∀x ∈ RD
i=1 `------------,---------------'
always positive using eq. (60)
=⇒ P ± vX (z)2) - z(2))	∀x ∈ RD	(61)
Thus by proving the LMIs (59) and (61), we prove (54).
(b)	We have to prove that if hu ≥ 0 and Kl ≤ 0, P is a PSD matrix, N is a NSD matrix.
We are given hu ≥ 0, Kl ≤ 0. Using equation (57), we have the following:
(w)2i) - w[?) ≥ 0 =⇒ Pi = hu ≥ 0 =⇒ Pi Wi- W(?) ≥ 0
(W)2i) - W(?) ≤ 0 =⇒ Pi = Kl ≤ 0 =⇒ Pi (W)2i) - W(?) ≥ 0
=⇒ Pi (w)2i) - W(?) ≥ 0	∀i ∈ [N1]	(62)
26
Under review as a conference paper at ICLR 2020
Thus P is a weighted sum of symmetric rank one matrices i.e, W(I)
coefficient Pi (w)? - W(：)is positive.
and each
P = ∑ Pi (wy” w(?) W(I) (W(I))T ± 0
i=1 '---------------------'
always positive using eq. (62)
Using equation (57), we have the following:
(WS- W(Ji)) ≥ 0 =⇒ ni =	hL ≤	0	=⇒	n W	-	W(?)	≤ 0
(WS- W(Ji)) ≤ 0 =⇒ ni =	hu ≥	0	=⇒	ni (W52i)	-	W(?)	≤ 0
=⇒ ni (W52i) - w(? ) ≥ 0	∀i	∈	[N1]	(63)
N = ∑ ni (Wg)- W ) W(I) (W(I))J 0
always positive using eq. (63)
Thus P is a PSD and N is a NSD matrix if hu ≥ 0 and hL ≤ 0.
(c)	We have to prove the following global bounds on the eigenvalues of v^(zy2) - z(2)):
ml W V2 (z(2) - z(2)) W MI, where M = max vτPv, m = min vτNv
x∖ y t >	W=I	W=I
Since VX (Zyl)- z(2)) W P ∀x ∈ Rd:
vτ [vX (z(y2) - z(2))] V ≤ vτPv	∀v ∈ Rd, ∀x ∈ Rd	(64)
Let v*, x* be vectors such that:
(V*)T [vx* (Zy2) - z(2))]v*=maχ max vτ [vX (Zy2) - z(2))] v
Thus using inequality (64):
(v*)T [vX* Wiwi)] v* ≤ (v*)τPv* ≤ max vτPV
=⇒ max max vτ [vB (z(2) - z(2))] V ≤ max vτPv	(65)
x W=I	L x∖ y t 川	W=I
Since N W VX %2) - z(2))	∀x ∈ Rd:
vτNv ≤ vτ [vX (zy2) - z(2))] V	∀v ∈ Rd, ∀x ∈ Rd	(66)
Let v* , x* be vectors such that:
(v*)τ [vX. (z(2) - z(2))] v* = min min vτ [vX (z(2) - z(2))] V
x y t	x IMl=I	x∖ y t
Thus using inequality (66):
(v*)τ[vX* (zy2) - z(2))] v* ≥ (v*)τNV* ≥ IminIVTNV
=⇒ min min vτ [vl (z(2) - z(2))] V ≥ min vτNv	(67)
XHVn=I	L xk y t )∖	HVH=I
Using the inequalities (65) and (67), we get:
ml W vX (zy2) - z(2)) W MI,
where M = max vτPv, m = min vτNv
HVH=I	HVH=I
27
Under review as a conference paper at ICLR 2020
D.5 Proof of Theorem 4
We are given that the activation function σ is such that σ', σ" are bounded, i.e:
′	′′
∣σ (x)∣ ≤ g, ∣σ (x)∣ ≤ h ∀x ∈ R	(68)
We have to prove the following:
kXZ(L)Il ≤ h ∑ (T(I) )2 max (SiIj ) ∀χ ∈ RD
where S(L,I) is a matrix of size NL × NI defined as follows:
,r r.	(W(L)I	I = L- 1
S(Lj) = 1	，1，	、	(69) .g W(L)IS(LT，I)	I∈ [L — 2]
and r(I) is a scalar defined as follows:
rd) JW(I,) I,、I = 1	(70) .g IW(I)Ilr(IT)	I ∈ [2,L — 1]
We will prove the same in 3 steps.
In step (a), we will prove:
∣Fi(,Lj,I)∣ ≤ Si(,Lj,I)	∀χ∈RD	(71)
In step (b), we will prove:
IB(I)I ≤ r(I),	∀χ∈ RD	(72)
In step (c), we will use (a) and (b) to prove:
卜XZ(L)Il ≤ h Σ (r(I))2max(S(L,I))	(73)
Note that B(I) and F(L,I) are defined using (34) and (35) respectively.
(a)	We have to prove that for L ≥ 2, I ∈ [L - 1], i ∈ NL, j ∈ NI:
∣F(L,I)∣ ≤ S(L,I)	∀χ∈RD
i,j	i,j
where S(L,I) is a matrix of size NI × NJ defined as follows:
S(L,I)
]W(L)∣
g W(L)IS(L-1,J)
I=L-1
I ∈ [L - 2]
We first prove the case when I = L - 1.
Using equation (45), Fi(,Lj,L-1) = Wi(,Lj).
SinceSi(,Lj,L-1)=∣Wi(,Lj)∣:
∣Fi(,Lj,L-1)∣ = Si(,Lj,L-1)
Hence for L ≥ 2, I = L - 1, we have equality in (71). Hence proved.
Now, we will use proof by induction.
To prove the base case L = 2, note that I = L - 1 = 1 is the only possible value for I. Thus,
using the result for I = L - 1, the theorem holds for L = 2. This proves the base case.
Now we assume the induction hypothesis is true for depth = L- 1, I ∈ [L-2]. and prove for
depth = L, I ∈ [L - 1]. Since for I = L - 1, we have proven already, we prove for I ≤ L - 2.
Using equation (47), we have the following formula for Fi(L,I):
NL 1
F LJ)= ∑ w(L)σ (ZkLT)) FkLT，I)
i	i,k k	k
k=1
28
Under review as a conference paper at ICLR 2020
Taking the jth element of the vectors on both sides:
NL 1
F(L,I)= ∑ W"Iz(L-I)) F(L-1,I)
Fi,j = ∑ Wi,k σ (zk	) Fk,j
k=1
By induction hypothesis, we know that:
∣F(L-1,I)∣ ≤ S(L-1,I)
k,j	k,j
Using the absolute value properties for equation (74), we have:
IF(L,I)I = ∑ι w(L)σ' (z(L-1)) F(L-1,I)
∣Fi,j ∣ = ∑ Wi,k σ (zk	) Fk,j
k=1
NL 1
FL,I)∣≤ ∑ W(LMzkLT))FkLT，I)|
k=1
NL 1
(L,I)	(L)	(L-1)	(L-1,I)
IFi,j I≤ ∑ IWi,k I Iσ (zk	)I IFk,j I
k=1
Using ∣σ’ (x)∣ ≤ g ∀x ∈ R (inequality (68)):
NL 1
IFi(,Lj,I)I ≤ g ∑L-1IWi(,Lk)IIF(kL,j-1,I)I
k=1
Using the induction hypothesis (inequality (75)):
NL 1
(L,I)	(L)	(L-1,I)
IFi,j I≤g ∑ IWi,k I ISk,j	I
k=1
Using equation (69) for definition of Si(,Lj,I):
IF(L,I)I ≤ S(L,I)
i,j	i,j
Hence we prove (71) for all L ≥ 2 and I ≤ L - 1 using induction.
(b)	We have to prove that for 1 ≤ I ≤ M - 1:
IlB(I)Il ≤ r(I),	∀x ∈ RD
where r(I) is a scalar given as follows:
r(I)=JW?	I=1
[g IW(I)|Ir(IT)	I ∈ [2,L - 1]
Using equation (43), for I = 1 we have:
IB(1)I = IW(1)I = r(1)
Using equation (44), for I > 1, we have:
怛(I)Il = ∣∣W(I)diag (σ'(ζ(IT))) B(IT)Q
怛叫 ≤ IW(I)∣∣∣∣diag (σ(z(I-I)))∣∣ IIB(I叫
Since ∣∣diag(σ' (Z(I-I)))∣∣ = maxj ∣σ' (ZjI-I))∣, using equation (68):
IB(I)I ≤gIW(I)I IB(I-1)I ≤ g IW(I)I r(I-1)	I≥2
Using inequalities (76) and (77), the proof follows using induction.
(74)
(75)
(76)
(77)
29
Under review as a conference paper at ICLR 2020
(c)	We have to prove that:
kXZ(L)Il ≤ h *r (I) )2 max (S(I))
Using Lemma 1, We have the following equation for vXz(L):
VxZ(L) = £ (B(I))Tdiag(F(LQ Θ σ'' (z(I)))B(I)
Using the properties of norm we have:
IVxZ(L)U= ∑(B(I))T diag (F(L,I)Θ σ''(z(I))) B(I)
I=1
≤ ∑ Hdiag(F(L,I)θσ'(Z(I)))H UB(I)U2
I=1
≤ ∑ mjx(∣F(,L,I"(zjI))I)UB(I)U2
In the last inequality, we use the property that norm of a diagonal matrix is the maximum
absolute value of the diagonal element. Using the product property of absolute value, we
get:
HVxZ(L)H ≤∑1 max (∣F(L,I)∣∣σ"(zjI ))∣)UB(I)U2
Since IF(L,I)∣ and 卜”(zjI))∣ are positive terms:
HVxZ(L)H ≤ L∑1 max ( IF(L,I)l) max (卜"(zjI ))1 ) UB(I)U 2
Since 卜［is bounded by h:
HV2xzi(L)H ≤ hL∑=-1mjax(IFi(,Lj,I)I)UB(I)U2
Using inequality (71):
HV2xzi(L)H≤hL∑=-1mjax(Si(,Ij))UB(I)U2
Using inequality (72):
HV2xzi(L)H ≤ h ∑= (r(I))2mjax(Si(,Ij))	∀x∈ RD
E COMPUTING g, h, hU AND hL FOR DIFFERENT ACTIVATION FUNCTIONS
E.1 S oftplus activation
For softplus activation, we have the following. We use S(x) to denote sigmoid:
σ (x) = log(1 + exp(x))
σ (x) = S(x)
σ (x) = S(x)(1 - S(x))
30
Under review as a conference paper at ICLR 2020
To bound S(x)(1 - S(x)), let α denote S(x). We know that 0 ≤ α ≤ 1:
α(1 - α)
4- (2- α)
2
Thus, S (x)(1 - S (x)) is maximum at S(x) = 1/2 and minimum at S(x) = 0 and S(x) = 1. The
maximum value is 0.25 and minimum value is 0.
0 ≤ S(x)(1 - S(x)) ≤ 0.25 =⇒ 0 ≤ σ''(x) ≤ 0.25
Thus, hU = 0.25, hL = 0 (for use in Theorem 3) and g = 1, h = 0.25 (for use in Theorem 4).
E.2 Sigmoid activation
For sigmoid activation, we have the following. We use S(x) to denote sigmoid:
σ(X) = S(X) = 1 + exp(-x)
σ (x) = S(x)(1 - S(x))
σ (X) = S(X)(1 - S(X))(1 - 2S(X))
The second derivative of sigmoid (σ''(x)) can be bounded using standard differentiation. Let a
denote S(X). We know that 0 ≤ α ≤ 1:
hL ≤ σ (X) ≤ hU
hL = min α(1 - α)(1 - 2α)
0≤α≤1
hU = m≤ a≤x α(1 - α)(1 - 2α)
To solve for both hL and hU, we first differentiate α(1 - α)(1 - 2α) with respect to α:
Vα (α( 1 - α)( 1 - 2α)) = Na(2a? - 3α^ + α) = (6α^ - 6α + 1)
Solving for 6α2 - 6α + 1 = 0, we get the solutions:
_(3 + √3	√3∖
a = (	66)
Since both (3 + ∖∕3∕6), (3 一 ∖∕3∕6) lie between 0 and 1, we check for the second derivatives:
V2α (α(1 - α)(1 - 2α)) = Vα (6α2 - 6α + 1) = 12α - 6 = 6(2α - 1)
At a = (3 + √3)∕6, Va = 6(2a - 1) = 2√3 > 0.
At a = (3 - √3)∕6, Va = 6(2a - 1) = -2√3 < 0.
Thus a = (3 + ∖∕3)∕6 is a local minima, α = (3 一 ∖∕3)∕6 is a local maxima.
Substituting the two critical points into a(1 - a)(1 - 2a), we get hU = 9.623 × 10-2, hL = -9.623 ×
10-2.
Thus, hU = 9.623 × 10-2, hL = 一9.623 × 10-2 (for use in Theorem 3) andg = 0.25, h = 0.09623
(for use in Theorem 4).
E.3 Tanh activation
For tanh activation, we have the following:
σ(X) = tanh(X) =
exp(x) - exp(-x)
exp(x) + exp(-x)
σ (X) = (1 一 tanh(X)) (1 + tanh(X))
σ
′′
(X) = 一2 tanh(X) (1 一 tanh(X)) (1 + tanh(X))
31
Under review as a conference paper at ICLR 2020
The second derivative of tanh , i.e (σ'' (x)) can be bounded using standard differentiation. Let a
denote tanh(x). We know that -1 ≤ α ≤ 1:
h,L ≤ σ (x) ≤ hu
hL = min -2α(1 - α)(1 + α)
0≤α≤1
hU = m≤ a≤x -2α(1 - α)(1 + α)
To solve for both hL and hU, we first differentiate -2α(1 - α)(1 + α) with respect to α:
Vα (-2α(1 - α)( 1 + α)) = Na (2α? - 2α) = (6α^ - 2)
Solving for 6α2 - 2 = 0, we get the solutions:
11
α =- √3, √3
Since both -1/∖∕3,1/∖∕3 lie between -1 and 1, We check for the second derivatives:
V2α (-2α(1 - α)(1 + α)) = Vα (6α2 - 2) = 12α
At α = -1∕√3, Va = 12α = -4√3 < 0.
At a = 1 /√3, Va = 12α = 4√3 > 0.
Thus α = 1/∖∕3 is a local minima, α = -1/∖∕3 is a local maxima.
Substituting the two critical points into -2α(1 - α)(1 + α), we get hU = 0.76981, hL = -0.76981.
Thus, hU = 0.76981, hL = -0.76981 (for use in Theorem 3) and g = 1, h = 0.76981 (for use in
Theorem 4).
F	Quadratic bounds for two-layer ReLU networks
For a 2 layer network with ReLU activation, such that the input X lies in the ball ^x - x(0) ∣∣ ≤ ρ, we
can compute the bounds over z(1) directly:
W((I)X⑼+b(I)-P M(I) I ≤ Z(I) ≤ W(I) X(O)+b(1)+ρ M(I)Il
Thus we can get a lower bound and upper bound for each zi(1). We define di and ui as the following:
di = Wi(1)X(0) + bi(1) - ρ IWi(1)I	(78)
ui = Wi(1)X(0) + bi(1) + ρ IWi(1)I	(79)
We can derive the following quadratic lower and upper bounds for each ai(1):
	，_-di_ (z(1) (Ui- di)2 ( i	)2+(	u2 + d z(1) Ui- di)2 i	U2 di	∣di∣ ≤ ∣Ui∣
(1) ai	≤				-(Ui- di)2	
	Ui	(z(1) l(Ui- di)2 ( i	)2-(	2uidi	(1) Ui- di)2 i	Uid2 + (Ui- di)2	∣di∣ ≥ ∣Ui∣
	[0			2∣di∣ ≤ ∣Ui∣	
(1) ai	≥	Z(I) i			∣di∣ ≥ 2∣Ui∣	
	.ɪ (Z ⑴)2		di	(1)	otherwise	
	〔Ui- di ( i )		z		
		Ui -	di i		
The above steps are exactly the same as the quadratic upper and lower bounds used in (Zhang et al.,
2018a).
Using the above two inequalities and the identity:
N1
Z(y2) - Zt(2) = ∑1 (Wy(2,i) - Wt(,2i)) ai(1)
32
Under review as a conference paper at ICLR 2020
we can compute a quadratic lower bound for z(y2) - zt(2) in terms of zi(1) by taking the lower bound
for ai(1) when (W(y2,i) - Wt(,2i)) > 0 and upper bound when (Wy(2,i) - Wt(,2i)) <= 0. Furthermore since
zi(1) = Wi(1)
x+bi(1), we can express the resulting quadratic in terms ofx. Thus, we get the following
quadratic function :
zy2)- z(2) ≥ 2XT Px+q+r
The coefficients P, q and r can be determined using the above procedure. Note that unlike in (Zhang
et al., 2018a), RHS can be a non-convex function.
Thus, it becomes an optimization problem where the goal is to minimize the distance 1/2 ∣∣x - x(0) ∣∣
subject to RHS (which is quadratic in x) being zero. That is both our objective and constraint are
quadratic functions. In the optimization literature, this is called the S-procedure and is one of the few
non-convex problems that can be solved efficiently (Boyd & Vandenberghe, 2004).
We start with two initial values called ρlow (initialized to 0) and ρhigh (initialized to 5).
We start with an initial value of ρ, initialized at 1/2 (ρlow + ρhigh) to compute di (eq. (78)) and
ui (eq. (79)). If the final distance after solving the S-procedure is less than ρ, we set ρlow = ρ. if
the final distance is greater than ρ, we set ρhigh = ρ. Set new ρ = 1/2 (ρlow + ρhigh). Repeat until
convergence.
G	Additional experiments
Empirical accuracy means the fraction of test samples that were correctly classified after running a
PGD attack (Madry et al., 2018) with an l2 bound on the adversarial perturbations. Certified accuracy
means the fraction of test samples that were classified correctly initially and had the robustness
certificate greater than a pre-specified attack radius ρ. For both empirical and certified accuracy, we
use ρ = 0.5. Unless otherwise specified, we use the class with the second largest logit as the attack
target for the given input (i.e. the class t). All experiments were run on the MNIST dataset while
noting that our results are scalable for more complex datasets. The notation (L × [1024], activation)
denotes a neural network with L layers with the specified activation function, (γ = c) denotes standard
training with γ set to c, (CRT, c) denotes CRT training with γ = c. Certificates CROWN and CRC are
computed over 150 correctly classified images.
G.1 Results on Convolutional neural networks
We use a 2 layer (1 hidden layer network). We use 64 filters in the convolution layer and softplus
activation function and stride of length 2. This is followed by reshaping and a fully connected layer.
Y	MNIST			CIFAR-10		
	Standard Accuracy	Empirical Robust Accuracy	Certified Robust Accuracy	Standard Accuracy	Empirical Robust Accuracy	Certified Robust Accuracy
~δ	98.68%	87.81%	0.00%	56.22%	14.88%	0.00%
0.005	97.67%	93.71%	91.47%	56.18%	30.19%	9.37%
0.01	97.08%	92.92%	91.25%	53.52%	31.82%	17.39%
0.02	96.36%	90.98%	89.58%	49.55%	31.80%	25.93%
0.03	95.54%	89.99%	88.75%	46.56%	31.98%	29.26%
Table 8: Comparison between certified robust accuracy for different values of the regularization
parameter γ for a single hidden layer convolutional neural network with softplus activation function
33
Under review as a conference paper at ICLR 2020
G.2 Results for Tanh networks
Network	Training	Standard Accuracy	Empirical Robust Accuracy	Certified Robust Accuracy	Certificate (mean)	
					CROWN	CRC
2×[1024], tanh	PGD	98.76%	95.79%	84.11%	0.30833	0.61340
	TRADES	98.63%	96.20%	93.72%	0.40601	0.86287
	CRT, 0.01	98.52%	95.90%	95.00%	0.37691	1.47016
3×[1024], tanh	PGD	98.78%	94.92%	0.00%	0.12706	0.03036
	TRADES	98.16%	94.78%	0.00%	0.15875	0.02983
	CRT, 0.01	98.15%	95.00%	94.16%	0.28004	1.14995
4×[1024], tanh	PGD	98.53%	94.53%	0.00%	0.07439	0.00140
	TRADES	97.08%	92.85%	0.00%	0.11889	0.00068
	CRT, 0.01	97.24%	93.05%	91.37%	0.33649	0.93890
Table 9: Comparison between CRT, PGD (Madry et al., 2018) and TRADES (Zhang et al., 2019) for
Tanh networks. CRC outperforms CROWN significantly for 2 layer networks and when trained with
our regularizer for deeper networks. CRT outperforms TRADES and PGD giving higher certified
accuracy.
G.3 Comparing Randomized Smoothing and TRADES with CRT
Randomized smoothing is designed to work in untargeted attack settings while CRT is for targeted
attacks. Thus, to do a fair comparison of CRT with randomized smoothing, we make the following
changes in randomized smoothing.
First, we use n0 = 100 initial samples to select the label class (l) and false target class (t). The
samples for estimation were n = 100, 000 and failure probability was α = 0.001. Then we use the
binary version of randomized smoothing for estimation, i.e classify between y and t. To find the
adversarial example for adversarial training, we use the cross entropy loss for 2 classes (y and t).
For TRADES, we select the class with second highest logit as the target class t and use the 2 class
version of the cross entropy loss for finding the adversarial example.
Table 10: Comparison between CRT and Randomized Smoothing(Cohen et al., 2019). s denotes the
standard deviation for smoothing. We use ρ = 0.5. For CRT, we use γ = 0.01
Network		Randomized Smoothing			CRT
		S = 0.25	s = 0.50	s = 1.0	-
2 ×	[1024], sigmoid	93.75%	93.09%	88.91%	95.61%
~27	[1024], tanh	94.61%	93.08%	82.26%	95.00%
3 ×	[1024], sigmoid	94.00%	93.03%	86.58%	94.99%
3 ×	[1024], tanh	93.69%	91.68%	80.55%	94.16%
^Z×	[1024], sigmoid	93.68%	92.45%	84.99%	93.41%
^Z×	[1024], tanh	93.57%	92.19%	83.90%	91.37%
34
Under review as a conference paper at ICLR 2020
Table 11: Comparison between CRC and CROWN-general (CROWN-Ada for relu) for different
targets. For CRT training, we use γ = 0.01. We compare CRC with CROWN-general for different
targets for 150 correctly classified images. Runner-up means class with second highest logit is
considered as adversarial class. Random means any random class other than the label is considered
adversarial. Least means class with smallest logit is adversarial. For 2-layer networks, CRC
outperforms CROWN-general significantly even without adversarial training. For deeper networks (3
and 4 layers), CRC works better on networks that are trained with curvature regularization.
Network	Training	Target	Certificate (mean)		Time per Image (s)	
			CROWN	CRC	CROWN	CRC
2 × [1024],relu	standard	runner-up	0.50110	0.59166	0.1359	2.3492
		random	0.68506	0.83080	0.2213	3.5942
		least	0.86386	1.04883	0.1904-	3.0292
2 × [1024], sigmoid	standard	runner-up	0.28395	0.48500	0.1818	0.1911
		random	0.38501	0.69087	0.1870	0.1912
		least	0.47639	0.85526	0.1857	0.1920
	CRT, 0.01	runner-up	0.43061	1.54673	0.1823	0.1910
		random	0.52847	1.99918	0.1853	0.1911
		least	0.62319	2.41047	0.1873	0.1911
2 × [1024], tanh	standard	runner-up	0.23928	0.40047	0.1672	0.1973
		random	0.31281	0.52025	0.1680	0.1986
		least	0.38964	0.63081	0.1726	0.1993
	CRT, 0.01	runner-up	0.37691	1.47016	0.1633	0.1963
		random	0.45896	1.87571	0.1657	0.1982
		least	0.52800	2.21704	0.1697	0.1981
3 × [1024], sigmoid	standard	runner-up	0.24644	0.06874	1.6356	0.5012
		random	0.29496	0.08275	1.5871	0.5090
		least	0.33436	0.09771	1.6415	0.5056
	CRT, 0.01	runner-up	0.39603	1.24100	1.5625	0.5013
		random	0.46808	1.54622	1.6142-	0.4974
		least	0.51906	1.75916	1.6054-	0.4967
3 × [1024],tanh	standard	runner-up	0.08174	0.01169	1.4818	0.4908
		random	0.10012	0.01432	1.5906	0.4963
		least	0.12132	0.01757	1.5888	0.5076
	CRT, 0.01	runner-up	0.28004	1.14995	1.4832-	0.4926
		random	0.32942	1.41032	1.5637	0.4957
		least	0.38023	1.65692	1.5626	0.4930
4 × [1024], sigmoid	standard	runner-up	0.19501	0.00454	4.7814	0.8107
		random	0.21417	0.00542	4.6313	0.8377
		least	0.22706	0.00609	4.7973	0.8313
	CRT, 0.01	runner-up	0.40327	1.06208	4.1830	0.8088
		random	0.47038	1.29095	4.3922-	0.7333
		least	0.52249	1.49521	4.4676	0.7879
4 × [1024],tanh	standard	runner-up	0.03554	0.00028	5.7016	0.8836
		random	0.04247	0.00036	5.8379	0.8602
		least	0.04895	0.00044	5.8298	0.9045
	CRT, 0.01	runner-up	0.33649	0.93890	3.8815	0.8182
		random	0.41617	1.18956	4.0013	0.8215
		least	0.47778	1.41429	4.3856	0.8311
35
Under review as a conference paper at ICLR 2020
G.4 Measuring the impact of curvature regularization
In Table 12, we measure how the standard accuracy, empirical accuracy, certified accuracy, up-
per bound on the curvature Kub, lower bound on the curvature Klb, changes as we increase the
regularization parameter γ and the network is trained with CRT.
In Table 13, we measure how the standard accuracy, empirical accuracy, certified accuracy, CROWN
and CRC changes as we increase the regularization parameter γ and the network is trained without
any adversarial training.
G.5 COMPUTING Klb AND Kub
First, note that K does not depend on the input, but on network weights W(I), label y and target t.
Different images may still have different K because label y and target t may be different.
To compute Klb in the table, first for each pair y and t, we find the largest eigenvalue of the Hessian
of all test images that have label y and second largest logit of class t. Then we take the max of the
largest eigenvalue across all test images. This gives a rough estimate of the largest curvature in the
vicinity of test images with label y and target t. We can directly take the mean across all such pairs to
compute Klb. However, we find that some pairs y and t were infrequent (with barely 1,2 test images
in them). Thus, for all such pairs we cannot get a good estimate of the largest curvature in vicinity.
We select all pairs y and t that have at least 100 images in them and compute Klb by taking the mean
across all such pairs.
To compute Kub in the table, we compute K for all pairs y and t that have at least 100 images, i.e at
least 100 images should have label y and target t. And then we compute the mean across all K that
satisfy this condition. This was done to do a fair comparison with Klb .
Figure 2 shows a plot of the Kub and Klb with increasing γ for a tanh network.
UeωsφH0J£」。J SPUnOqφn-e>u<υσl∙m
Figure 2: Kub and Klb are upper and
lower curvature bounds of the network with
Tanh activations (averaged over (y, t) pairs).
When γ = 0 (no curvature regularization),
networks adversarially trained with CRT or
PGD both have high curvatures. However,
CRT with even a small γ leads to a significant
decrease in curvature bounds. Also, curva-
ture bounds are higher with Tanh than with
Sigmoid. Results are similar to Sigmoid in
Figure 1.
36
Under review as a conference paper at ICLR 2020
Table 12: In this table, we measure the effect of increasing γ, when the network is trained with
CRT on standard, empirical, certified robust accuracy, Klb and Kub (defined in subsection G.5) for
different depths (2, 3, 4 layer) and activations (sigmoid, tanh). We find that for all networks γ = 0.01
works best. We find that the lower bound, Klb increases (for γ = 0) for deeper networks suggesting
that deep networks have higher curvature. Furthermore, for a given γ (say 0.005), we find that the
gap between Kub and Klb increases as we increase the depth suggesting that K is not a tight bound
for deeper networks.
Network	Y	Standard Accuracy	Empirical Robust Accuracy	Certified Robust Accuracy	Curvature bound (mean)	
					Klb	Kub
2×[1024], sigmoid	^00-	98.77%	96.17%	95.04%	7.2031	72.0835
	0.005	98.82%	96.33%-	95.61%	3.8411	8.2656
	0.01	98.57%	96.28%-	95.59%-	2.8196	5.4873
	0.02	98.59%	95.97%-	95.22%-	2.2114	3.7228
	0.03	98.30%	95.73%-	94.94%-	1.8501	2.9219
2×[1024], tanh	^00-	98.65%	95.48%-	92.69%	12.8434-	107.5689
	0.005	98.71%	95.88%-	94.76%	4.8116	10.1860
	0.01	98.52%	95.90%-	95.00%-	3.4269	6.3529
	0.02	98.35%	95.71%	94.77%	2.3943	4.1513
	0.03	98.29%	95.39%-	94.54%	1.9860	■3.933
3×[1024], sigmoid	^0	98.52%	90.26%	0.00%	19.2131	3294.9070
	0.005	98.41%	95.81%-	94.91%	2.6249	13.4985
	0.01	98.23%	95.70%-	94.99%-	1.9902	8.6654
	0.02	97.99%	95.33%-	94.64%-	1.4903	5.4380
	0.03	97.86%	94.98%-	94.15%	1.2396	4.1409
	0.04	97.73%	94.60%-	93.88%	1.0886	3.3354
	0.05	97.60%	94.45%-	93.65%	0.9677	2.7839
3×[1024], tanh	^0	98.19%	86.38%	0.00%	133.7992	17767.5918
	0.005	98.13%	94.56%	93.01%	3.2461	17.5500
	0.01	98.15%	95.00%	94.16%	2.2347	10.8635
	0.02	97.84%	94.79%	94.05%	1.6556	6.7072
	0.03	97.70%	94.19%-	93.42%	1.3546	5.0533
	0.04	97.57%	94.04%-	92.95%	1.1621	4.0071
	0.05	97.31%	93.66%	92.65%	1.0354	3.3439
4×[1024], sigmoid	^0	98.22%	83.04%	0.00%	86.9974	343582.3125
	0.005	98.18%	95.02%-	93.20%	2.1760	15.3358
	0.01	97.83%	94.65%-	93.41%	1.6823	10.2289
	0.02	97.33%	94.02%	92.94%	1.2089	6.5573
	0.03	97.07%	93.52%-	92.65%	1.0144	4.9576
	0.04	96.70%	92.78%-	91.95%	0.8840	3.9967
	0.05	96.38%	92.29%-	91.33%	0.7890	3.4183
	0.06	96.29%	92.17%	91.11%	0.7128	3.0050
	0.07	96.08%	91.83%-	90.67%	0.6614	2.6905
4×[1024], tanh	^0	97.45%	75.18%	0.00%	913.6984	37148156
	0.005	97.48%	93.29%-	89.98%	2.8690	18.8079
	0.01	97.24%	93.05%-	91.37%-	1.9114	12.2148
	0.02	96.82%	92.65%	91.35%	1.3882	7.1771
	0.03	96.27%	91.43%-	90.09%	1.1643	5.1671
	0.04	95.62%-	90.69%-	89.41%-	0.9620	3.9061
	0.05	95.77%	90.69%-	89.40%	0.9160	3.2909
	0.06	95.52%-	90.00%	88.38%	0.8234	2.8808
	0.07	95.24%	89.51%	87.91%	0.7540	2.5635	—
37
Under review as a conference paper at ICLR 2020
Table 13: In this table, we measure the impact of increasing curvature regularization (γ) on accuracy,
empirical robust accuracy, certified robust accuracy, CROWN-general and CRC when the network
is trained without any adversarial training. We find that adding a very small amount of curvature
regularization has a minimal impact on the accuracy but significantly increases CRC. Increase in
CROWN certificate is not of similar magnitude. Somewhat surprisingly, we observe that even without
any adversarial training, we can get nontrivial certified accuracies of 84.73%, 88.66%, 89.61% on
2,3,4 layer sigmoid networks respectively.
Network	Y	Standard Accuracy	Empirical Robust Accuracy	Certified Robust Accuracy	Certificate (mean)	
					CROWN	CRC
2 × [1024], sigmoid	0Q.	98.37%	76.28%	54.17%	0.28395	0.48500
	0.005	97.96%	88.65%	82.68%	0.36125	0.83367
	0.01	98.08%	88.82%	83.53%	0.32548	0.84719
	0.02	97.88%	88.90%	83.68%	0.34744	0.86632
	0.03	97.73%	89.28%-	84.73%-	0.35387	0.90490
2 × [1024],tanh	^0	98.34%	79.10%	14.42%	0.23938	0.40047
	0.005	98.01%	89.95%	85.70%	0.27262	0.89672
	0.01	97.99%	90.17%	86.18%	0.28647	0.93819
	0.02	97.64%	90.13%	86.40%	0.30075	0.99166
	0.03	97.52%	89.96%	86.22%	0.30614	0.98771
3 × [1024], sigmoid	^0	98.37%	85.19%	0.00%	0.24644	0.06874
	0.005	97.98%	91.93%	88.66%-	0.38030	0.99044
	0.01	97.71%	91.49%	88.33%	0.39799	1.07842
	0.02	97.50%	91.34%	88.38%	0.38091	1.08396
	0.03	97.16%	91.10%	88.63%	0.41015	1.15505
	0.04	97.03%	90.96%	88.48%	0.42704	1.18073
	0.05	96.76%	90.65%-	88.30%	0.43884	1.19296
3 × [1024],tanh	^0	97.91%	77.40%	0.00%	0.08174	0.01169
	0.005	97.45%	91.32%	88.57%-	0.28196	0.95367
	0.01	97.29%	90.98%	88.31%	0.31237	1.05915
	0.02	97.04%	90.21%	87.77%	0.30901	1.08607
	0.03	96.88%	90.02%	87.52%	0.34148	1.11717
	0.04	96.53%	89.61%	86.87%	0.36583	1.11307
	0.05	96.31%	89.25%	86.26%	0.38519	1.11689
4 × [1024], sigmoid	^0	98.39%	83.27%	0.00%	0.19501	0.00454
	0.005	97.74%	91.67%	88.95%	0.36863	0.91840
	0.01	97.41%	91.71%	89.61%-	0.40620	1.05323
	0.02	96.47%	90.03%	87.77%	0.45074	1.14219
	0.03	96.24%	90.40%	88.14%	0.47961	1.30671
	0.04	95.65%	89.61%	87.54%-	0.49987	1.35129
	0.05	95.36%	89.10%	87.09%	0.51187	1.36064
	0.06	95.29%	88.96%	87.01%	0.52629	1.38666
	0.07	95.23%	88.03%-	85.93%	0.54754	1.27948
4 × [1024],tanh	^0	97.65%	69.20%	0.00%	0.03554	0.00028
	0.005	97.02%	89.77%	85.98%	0.29410	0.82364
	0.01	96.52%	89.38%	86.40%	0.34778	0.97365
	0.02	96.09%	88.79%	86.09%	0.41662	1.10860
	0.03	95.74%	88.36%	85.65%	0.44981	1.17400
	0.04	95.10%	87.50%	84.74%	0.48356	1.21957
	0.05	95.14%-	87.72%	84.77%	0.49113	1.25076
	0.06	94.66%	86.96%	84.28%	0.51104	1.28653
	0.07	94.34%	86.67%	83.90%	0.49750	1.24198
38
Under review as a conference paper at ICLR 2020
G.6 COMPARING OUR ATTACK AGAINST l2 BOUNDED PGD
In this section, we empirically compare our Curvature-based attack optimization to the PGD method
of Madry et al. (2018) (200 steps of size 0.01). We should note that the objectives of our attack
and PGD are different. The PGD attack (with sufficiently large number of steps) will always find a
solution χ(attack) such that IXSttack) - X(O)	≈ ρ. However, if our curvature bound is loose (or even
if the curvature bound is tight but the network itself has large curvature), our method may converge to
a point inside the ball where IX(attack) - X(0) I2 < ρ. The primary benefit of our method is that if it
converges to a point on the surface of the ball (i.e. IX(attack) - X(0) I2 = ρ), then X(attack) is provably
the worst case perturbation in the l2 ball of radius ρ around the input X(0) (since primal=dual using
Theorem 2).
Thus, to have the same perturbation magnitude between our attack optimization and PGD, we
consider a subset of samples where our attack method converges to a point on the surface of the
ball. In Table 14, we show a comparison between average values of zy - zt computed using PGD
and our method where y is the correct label and t is the attack target. In this table, Mean CBA
(Curvature-Based Attack) is computed by taking the average of zy - zt for all test samples satisfying
IX(attack) - X(0) I2 = ρ (with curvature based attack optimization). The relative gain is computed as
(Mean PGD - Mean CBA)/(Mean PGD).
Table 14: Comparison between mean values of zy - zt for l2 bounded PGD and Curvature-Based
Attack (CBA) optimization. See the experimental details in Section G.6.
Network	Mean PGD	Mean CBA	Relative Gain
2 × [1024], sigmoid	5.1526	4.9296	4.33%
3 × [1024], sigmoid	3.7748	3.6342	3.72%
4 × [1024], SigmOid	3.2024	一	3.0846	3.68%	—
Table 15: Table showing attack success rates for different values of γ. Attack success rate denotes the
fraction of points (X(0)) satisfying IX(attack) - X(0) I2 = ρ implying primal = dual in Theorem 2.
Network	Y	Attack success rate
2 × [1024], sigmoid	0.	5.05%
	0.01	100%
	^002^	^I00%
3 × [1024], sigmoid	^0	^0%
	0.01	44.86%
	0.03	100%
	ɪur	^I00%
4 × [1024], sigmoid	^g.-	^0%
	0.01	24.42%
	0.03	88.82%
	ɪor	99.97%
39