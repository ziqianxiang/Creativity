Under review as a conference paper at ICLR 2020
Deep Multi-View Learning via Task-Optimal CCA
Anonymous authors
Paper under double-blind review
Ab stract
Multi-view learning seeks to form better models by making use of multiple feature
sets representing the same samples. Exploiting feature correlations during train-
ing can enable better models. The traditional method for computing correlations
between feature sets is Canonical Correlation Analysis (CCA), which finds linear
projections that maximize correlation between feature vectors, essentially com-
puting a shared embedding for two views of data. More recently, CCA has been
used for multi-view discriminative tasks; however, CCA makes no use of class
labels. Recent CCA methods have started to address this weakness but are limited
in that they do not simultaneously optimize the CCA projection for discrimination
and the CCA projection itself, or they are linear only. We address these defi-
ciencies by simultaneously optimizing a CCA-based and a task objective in an
end-to-end manner. Together, these two objectives learn a non-linear CCA pro-
jection to a shared latent space that is highly correlated and discriminative. Our
method shows a significant improvement over previous state-of-the-art (including
deep supervised approaches) for cross-view classification (8.5% increase), regu-
larization with a second view during training when only one view is available at
test time (2.2-3.2%), and semi-supervised learning (15%) on real data.
1 Introduction
Parallel modalities of data are increasingly common in a variety of applications, including images
and text, audio and video, parallel texts of different languages, and a variety of medical imaging
and omics modalities for each patient. Each view provides essential information for classification
and, when used together, can form a more accurate model. This is especially important for difficult
discriminative tasks such as those with a small training set size. Canonical Correlation Analysis
(CCA) is the most common method for computing a shared representation from two views of data
by computing a space in which they are maximally correlated (Hotelling, 1936; Bie et al., 2005).
In this paper we will demonstrate that, through optimizing for both discriminative features and
correlation between views, we can improve classification accuracy for three real world scenarios.
CCA is an unsupervised method but has been applied to many discriminative tasks (Kan et al., 2015;
Sargin et al., 2007; Arora & Livescu, 2012). While some of the correlated CCA features are useful
for discriminative tasks, many represent properties that are of no use for classification and obscure
correlated information that is beneficial. This problem is magnified with recent non-linear extensions
of CCA that use deep learning to make significant strides in improving correlation (Andrew et al.,
2013; Wang et al., 2015a; 2016; Chang et al., 2018) but often at the expense of discriminative
capability (cf. §5.1). Therefore, we present Task-Optimal CCA (TOCCA), a new deep learning
technique to project the data from two views to a shared space that is also discriminative (Fig. 1).
Implementing a task-optimal variant of CCA required a fundamental change in formulation. We
show that the CCA objective can equivalently be expressed as an `2 distance minimization in the
shared space plus an orthogonality constraint. Orthogonality constraints help regularize neural
networks (NNs) (Huang et al., 2018); we present three techniques to accomplish this. While our
method is derived from CCA, by manipulating the orthogonality constraints, we obtain deep CCA
approaches that compute a shared latent space that is also discriminative.
Our family of solutions for supervised CCA required a crucial and non-trivial change in formulation.
We demonstrate the effectiveness and versatility of our model for three different tasks: 1) cross-
view classification on a variation of MNIST (LeCun, 1998), 2) regularization when two views are
1
Under review as a conference paper at ICLR 2020
Goal: shared embedding that is
also discriminative
Solution: multi-task NN
XJQQ--QQJ l∞…。0区
Applications:
Cross-view classification
Train: y — f(A1)
Test: y — f(A2)
Multi-view regularization
during training
Train: y - f(A1,A2)
Test: y 一 f(A1)
Multi-view prediction
Train: y — f(A1,A2)
Test: y - f(Aι,AJ
Figure 1: Our goal with Task-Optimal CCA is to compute a shared space that is also discriminative. We do
this by using NNs to compute an embedding for each view while simultaneously optimizing for correlation
in the embedded space and a task-optimal objective. This setup is beneficial for three scenarios: 1) training a
classifier with the embedding from one view and testing with the embedding of the other view (§5.1), 2) when
two views are available for training but only one at test time (§5.2), and 3) when both views are used for both
training and testing (§5.3). The embeddings for views Xi and X2 are represented by Ai and A2, respectively.
A classifier f (A) then predicts the class for each sample. In order to compare with unsupervised variants of
CCA, the classifier f may be computed subsequent to the CCA embedding.
available for training but only one at test time on a cancer imaging and genomic data set with
only 1,000 samples, and 3) semi-supervised representation learning to improve speech recognition.
All experiments showed a significant improvement in accuracy over previous state-of-the-art. In
addition, our approach is more robust in the small sample size regime than alternative methods.
Overall, our experiments on real data show the effectiveness of our method in learning a shared
space that is more discriminative than previous methods for a variety of practical problems.
2 Related Work
CCA was initially used for unsupervised data analysis to gain insights into components shared by
two sources (Andrew et al., 2013; Wang et al., 2015a; 2016). CCA has also been used to compute
a shared latent space for cross-view classification (Kan et al., 2015; Wang et al., 2015a; Chandar
et al., 2016; Chang et al., 2018), for representation learning on multiple views that are then joined for
prediction (Sargin et al., 2007; Dorfer et al., 2016b), and for classification from a single view when
a second view is available during training (Arora & Livescu, 2012). Recent non-linear extensions
of CCA implemented via NNs make significant improvements in correlation (Andrew et al., 2013;
Wang et al., 2015a; 2016; Chang et al., 2018) but with little focus on discriminative capability.
Most prior work that boosts the discriminative capability of CCA is linear only (Lee et al., 2015;
Singanamalli et al., 2014; Duan et al., 2016). More recent work using NNs still remains limited
in that it optimizes discriminative capability for an intermediate representation rather than the final
CCA projection (Dorfer et al., 2016b), or optimizes the CCA objective only during pre-training, not
while training the task objective (Dorfer et al., 2018). We advocate to jointly optimize CCA and a
discriminative objective by computing the CCA projection within a network layer while applying a
task-driven operation such as classification. Experimental results show that our method significantly
improves upon previous work (Dorfer et al., 2016b; 2018) due to its focus on both the shared latent
space and a task-driven objective. The latter is particularly important on small training set sizes.
While alternative approaches to multi-view learning via CCA exist, they typically focus on a recon-
struction objective. That is, they transform the input into a shared space such that the input could be
reconstructed - either individually or reconstructing one view from the other. Variations of coupled
dictionary learning (Shekhar et al., 2014; Xu et al., 2015; Cha et al., 2015; Bahrampour et al., 2015)
and autoencoders (Wang et al., 2015a; Bhatt et al., 2017) have been used in this context. CCA-based
objectives, such as the model used in this work, instead learn a transformation to a shared space
without the need for reconstructing the input. This task may be easier and sufficient in producing a
representation for multi-view classification (Wang et al., 2015a).
2
Under review as a conference paper at ICLR 2020
3	Background
We first introduce CCA and present our task-driven approach in §4. Linear and non-linear CCA
are unsupervised and find the shared signal between a pair of data sources, by maximizing the
sum correlation between corresponding projections. Let X1 ∈ Rd1 ×n and X2 ∈ Rd2×n be mean-
centered input data from two different views with n samples and d1, d2 features, respectively.
CCA. The objective is to maximize the correlation between a1 = w1>X1 and a2 = w2>X2, where
w1 and w2 are projection vectors (Hotelling, 1936). The first canonical directions are found via
arg max corr w1>X1, w2> X2
w1 ,w2
and subsequent projections are found by maximizing the same correlation but in orthogonal di-
rections. Combining the projection vectors into matrices W1 = [w1(1) , . . . , w1(k)] and W2 =
[w2(1) , . . . , w2(k)] (k ≤ min(d1, d2)), CCA can be reformulated as a trace maximization under or-
thonormality constraints on the projections, i.e.,
arg maxtr(W1>Σ12W2) s.t. W1>Σ1W1 = W2>Σ2W2 = I	(1)
W1 ,W2
for covariance matrices Σ1 = X1X1T, Σ2 = X2X2T, and cross-covariance matrix Σ12 = X1X2T.
Let T = Σ-1∕2∑i2∑-1/2 and its singular value decomposition (SVD) be T = UIdiag(σ)U>
with singular values σ = [σ1, . . . , σmin(d1,d2)] in descending order. W1 and W2 are computed from
the top k singular vectors of T as Wi = Σ-1∕2u11") and W2 = Σ-1∕2u21") where U(Lk)
denotes the k first columns of matrix U. The sum correlation in the projection space is equivalent to
kk
XCOTr((Wf))>χι, (w2i))>X2) = Xσ2 ,	⑵
i=1	i=1
i.e., the sum of the top k singular values. A regularized variation of CCA (RCCA) ensures
that the covariance matrices are positive definite by computing the covariance matrices as Σ1 =
n-1 XiX> + rI and Σ2 = n—ɪX2X> + rI, for regularization parameter r > 0 and identity matrix
I (Bilenko & Gallant, 2016).
DCCA. Deep CCA adds non-linear projections to CCA by non-linearly mapping the input via a mul-
tilayer perceptron (MLP). In particular, inputs X1 and X2 are mapped via non-linear functions f1
and f2, parameterized by θ1 and θ2, resulting in activations A1 = f1(X1; θ1) and A2 = f2(X2; θ2)
(assumed to be mean centered) (Andrew et al., 2013). When implemented by a NN, A1 and A2
are the output activations of the final layer with do features. Fig. 2(a) shows the network structure.
DCCA optimizes the same objective as CCA (equation 1) but using activations A1 and A2. Reg-
ularized covariance matrices are computed accordingly and the solution for W1 and W2 can be
computed using SVD just as with linear CCA. When k = do (i.e., the number of CCA components
is equal to the number of features in A1 and A2), optimizing the sum correlation in the projection
space (equation 2) is equivalent to optimizing the following matrix trace norm objective (TNO)
LTNO(Aɪ, A2) = ∣∣T∣∣tr = tr(T>T)1/2 ,
where T = Σ-1∕2∑i2∑-1/2 as in CCA (Andrew et al., 2013). DCCA optimizes this objective
directly, without a need to compute the CCA projection within the network. The TNO is optimized
first, followed by a linear CCA operation before downstream tasks like classification are performed.
This formulation does not allow for combining directly with a supervised term.
SoftCCA. While DCCA enforces orthogonality constraints on projections W1>A1 and W2>A2,
SoftCCA relaxes them using regularization (Chang et al., 2018). Final projection matrices W1
and W2 are integrated into f1 and f2 as the top network layer. The trace objective for DCCA in
equation 1 can be rewritten as minimizing the `2 distance between the projections when each feature
in Ai and A2 is normalized to a unit variance (Li et al., 2003), leading to1 Lg dist(Aι,Az) = ∣∣Aι -
A2 k2F . Regularization in SoftCCA penalizes the off-diagonal elements of the covariance matrix
1We use this `2 distance objective in our formulation.
3
Under review as a conference paper at ICLR 2020
(a) DCCA
(c) TOCCA-W (Ours)
Task loss
[oδo]y
I TNO I
Ai	―	A2
©O…OO] [O。…O。]
[OO …OO] [OO…O0
MLP 卜 Ttask
Bi
'2 Loss
IDecorr. '2 Loss DecorrJ
a∕ZC≥Z^72≤2ZZA2
[。。…OOl IOo …Oo]
[00 …OO] QO…OO]
Xi	X2
(b) SoftCCA
QC)…OO)
IWhiteningl
Ai 1
(Oe)…OO)
fi I MLP I
(OO …OO)
Xi
B2
IOO …Oo]
IWhitening
CO …OQ
.OO-OO.
(d) TOCCA-SD (Ours)
A2
MLP f2
I 2 I Such that projections are orthogonal
1 I Max. SUm correlation (equiv. to 12 loss)
Figure 2: Deep CCA architectures: (a) DCCA maximizes the sum correlation in projection space by optimizing
an equivalent loss, the trace norm objective (TNO) (Andrew et al., 2013); (b) SoftCCA relaxes the orthogonality
constraints by regularizing with soft decorrelation (Decorr) and optimizes the `2 distance in the projection
space (equivalent to sum correlation with activations normalized to unit variance) (Chang et al., 2018). Our
TOCCA methods add a task loss and apply CCA orthogonality constraints by regularizing in two ways: (c)
TOCCA-W uses whitening and (d) TOCCA-SD uses Decorr. The third method that we propose, TOCCA-ND,
simply removes the Decorr components of TOCCA-SD.
Σ, using a running average computed over batches as Σ and a loss of LDeCOrr(A) = Pd= i ∣∑i,j|.
Overall, the SoftCCA loss takes the form
L'2 dist(Al, A2) + λ(LDecorr(A1) + LD
eco rr(A2 )	.
Supervised CCA methods. CCA, DCCA, and SoftCCA are all unsupervised methods to learn a
projection to a shared space in which the data is maximally correlated. Although these methods have
shown utility for discriminative tasks, a CCA decomposition may not be optimal for classification
because features that are correlated may not be discriminative. Our experiments will show that
maximizing the correlation objective too much can degrade performance on discriminative tasks.
CCA has previously been extended to supervised settings in three ways: 1) with methods that are
linear only (Singanamalli et al., 2014; Lee et al., 2015; Kan et al., 2015; Duan et al., 2016), 2) by
maximizing the total correlation between each view and the training labels in addition to each pair
of views (Lee et al., 2015; Singanamalli et al., 2014), and 3) with Linear Discriminant Analysis
(LDA)-style approaches to encourage class separation (Kan et al., 2015; Dorfer et al., 2016b; El-
madany et al., 2016).2 LDA approaches to supervision are generative rather than discriminative.
Importantly, we will show in §5.3 that encouraging class separation with an LDA-style objective
performs significantly inferior to a softmax. Further, Dorfer et al. (2016b) did not apply LDA to
the shared space itself but to the NN layer below it, and Elmadany et al. (2016) did not validate the
shared space created, only its use in multi-view classification using both views for training and test.
Dorfer et. al’s CCA Layer (CCAL) is the closest to our method. It optimizes a task loss operating
on a CCA projection; however, the CCA objective itself is only optimized during pre-training, not
in an end-to-end manner (Dorfer et al., 2018). Further, their goal is retrieval with a pairwise rank
loss, not classification. Instead of computing the CCA projection explicitly within the network, we
optimize the non-linear mapping into the shared space together with the task objective, requiring
a fundamental change in formulation. We optimize for the shared space with the `2 distance be-
tween activations (similar to SoftCCA) and propose three different ways to apply the orthogonality
constraints of CCA.
4 TASK-OPTIMAL CCA (TOCCA)
To compute a shared latent space that is also discriminative, we reformulate DCCA to add a task-
driven term to the optimization objective. The CCA component finds features that are correlated
2Gatto & Dos Santos (2017) use a similar technique with LDA but apply it as a convolutional filter on a
single view; it is not a multi-view method.
4
Under review as a conference paper at ICLR 2020
between views, while the task component ensures that they are also discriminative. This model can
be used for representation learning on multiple views before joining representations for prediction
(Sargin et al., 2007; Dorfer et al., 2016b) and for classification when two views are available for
training but only one at test time (Arora & Livescu, 2012). In §5, we demonstrate both use cases on
real data. Our methods and related NN models from the literature are summarized in Tab. A2; Fig. 2
shows schematic diagrams.
Challenges and solutions. While DCCA optimizes the sum correlation with an equivalent loss
function (TNO), the CCA projection itself is computed only after optimization. Hence, the projec-
tions cannot be used to optimize another task simultaneously. The main challenge in developing
a task-optimal form of deep CCA that discriminates based on the CCA projection is in computing
this projection within the network - a necessary step to enable simultaneous training of both objec-
tives. We tackle this by focusing on the two components of DCCA: maximizing the sum correlation
between activations A1 and A2 and enforcing orthonormality constraints within A1 and A2 . We
achieve both by transforming the CCA objective and present three methods that progressively relax
the orthogonality constraints.
We further improve upon DCCA by enabling mini-batch computations for improved flexibility and
test performance. DCCA was developed for large batches because correlation is not separable across
batches. While large batch implementations of stochastic gradient optimization can increase com-
putational efficiency via parallelism, small batch training provides more up-to-date gradient calcu-
lations, allowing a wider range of learning rates and improving test accuracy (Masters & Luschi,
2018). We reformulate the correlation objective as the `2 distance (following SoftCCA), enabling
separability across batches. We ensure a normalization to one via batch normalization without the
scale and shift parameters (Ioffe & Szegedy, 2015). Wang et al. (2016) also developed a stochastic
mini-batch solution to DCCA but handled the orthonormality constraints in a different way (dis-
cussed below).
Task-driven objective. First, we apply non-linear functions f1 and f2 with parameters θ (via MLPs)
to each view X1 and X2, i.e., A1 = f1(X1; θ1) and A2 = f2(X2; θ2). Second, a task-specific
function ftask(A; θtask) operates on the outputs A1 and A2 . In particular, f1 and f2 are optimized
so that the `2 distance between A1 and A2 is minimized; therefore, ftask can be trained to operate
on both inputs A1 and A2 . We combine CCA and task-driven objectives as a weighted sum with
a hyperparameter for tuning. This model is flexible, in that the task-driven goal can be used for
classification (Krizhevsky et al., 2012; Dorfer et al., 2016a), regression (Katzman et al., 2016),
clustering (Caron et al., 2018), or any other task. Other prior attempts to integrate a classifier into
deep CCA only used LDA (Kan et al., 2015; Dorfer et al., 2016b; Elmadany et al., 2016). See
Tab. A2 for an overview.
Orthogonality constraints. The remaining complications for mini-batch optimization are the or-
thogonality constraints, for which we propose three solutions, each handling the orthogonality con-
straints of CCA in a different way: whitening, soft decorrelation, and no decorrelation.
1)	Whitening (TOCCA-W). CCA applies orthogonality constraints to A1 and A2 . We accomplish
this with a linear whitening transformation that transforms the activations such that their covari-
ance becomes the identity matrix, i.e., features are uncorrelated. Decorrelated Batch Normalization
(DBN) has previously been used to regularize deep models by decorrelating features (Huang et al.,
2018) and inspired our solution. In particular, we apply a transformation B = UA to make B
orthonormal, i.e., BB> = I.
We use a Zero-phase Component Analysis (ZCA) whitening transform composed of three steps:
rotate the data to decorrelate it, rescale each axis, and rotate back to the original space. Each trans-
formation is learned from the data. Any matrix URdo×do satisfying U>U = Σ-1 whitens the
data, where Σ denotes the covariance matrix of A. As U is only defined up to a rotation, it is
not unique. PCA whitening follows the first two steps and uses the eigendecomposition of Σ:
UPCA = A-1/2V> for Λ = diag(λι,...,入&。) and V = [vι,..., Vdo], where (λi, Vi) are the
eigenvalue, eigenvector pairs of Σ. As PCA whitening suffers from stochastic axis swapping, neu-
rons are not stable between batches (Huang et al., 2018). ZCA whitening uses the transformation
UZCA = VA-1/2 VT in which PCA whitening is first applied, followed by a rotation back to the
original space. Adding the rotation V brings the whitened data B as close as possible to the original
data A (Kessy et al., 2015).
5
Under review as a conference paper at ICLR 2020
Computation of UZCA is clearly depend on Σ. While Huang et al. (2018) used a running average
of UZCA over batches, we apply this stochastic approximation to Σ for each view using the update
Σ(k) = αΣ(k-1) +(1-α)Σb for batch k where Σb is the covariance matrix for the current batch and
α ∈ (0, 1) is the momentum. We then compute the ZCA transformation from Σ(k) to do whitening
as B = fZCA(A) = U(ZkC)AA. At test time, U(k) from the last training batch is used. Algorithm A1
describes ZCA whitening in greater detail. In summary, TOCCA-W integrates both the correlation
and task-driven objectives, with decorrelation performed by whitening, into
Ltask(ftask(B1), Y) + Ltask(ftask(B2), Y) + λ Lg dist(B1, B2) ,
where B1 and B2 are whitened outputs of A1 and A2, respectively, and Y is the class labels. This
is a novel approach to integrating the orthogonality constraints of CCA into a NN as it is the first
to use ZCA whitening in this manner. Wang et al. (2016)’s stochastic mini-batch solution to DCCA
used nonlinear orthogonal iterations and does not state what type of whitening operation was used.
2)	Soft decorrelation (TOCCA-SD). While fully independent components may be beneficial in
regularizing NNs on some data sets, a softer decorrelation may be more suitable on others. In this
second formulation we relax the orthogonality constraints using regularization, following the Decorr
loss of SoftCCA (Chang et al., 2018). The loss function for this formulation is
Ltask(ftask(Aι),Y) + Ltask(ftask(A2),Y) + λ1L'2 的(Ai, A2)+λ2 (LDecorr(Al) + LDecorr(A2)).
While this solution is based on SoftCCA, our experiments (§5) will demonstrate that the task com-
ponent is essential when using the model for classification.
3)	No decorrelation (TOCCA-ND). When CCA is used in an unsupervised manner, some form of
orthogonality constraint or decorrelation is necessary to ensure that f1 and f2 do not simply produce
multiple copies of the same feature. While this result could maximize the sum correlation, it is not
helpful in capturing useful projections. In the task-driven setting, the discriminative term ensures
that the features in f1 and f2 are not replicates of the same information. TOCCA-ND therefore
removes the decorrelation term entirely, forming the simpler objective
Ltaskftask(Ai), Y) + Ltask(ftask(A2),Y) + λL'2 dist(Aι, A2 .
These three models allow testing whether whitening or decorrelation benefit a task-driven model.
Computational complexity. Due to the eigendecomposition, TOCCA-W has a complexity of O(do3)
compared to O(do2) for TOCCA-SD, with respect to output dimension do. However, do is typically
small (≤ 100) and this extra computation is only performed once per batch. The difference in
runtime is less than 6.5% for a batch size of 100 or 9.4% for a batch size of 30 (Tab. A4).
Summary. All three variants are motivated by adding a task-driven component to deep CCA.
TOCCA-ND is the most relaxed and directly attempts to obtain identical latent representations. Ex-
periments will show that whitening (TOCCA-W) and soft decorrelation (TOCCA-SD) provide a ben-
eficial regularization. Further, since the `2 distance that we optimize was shown to be equivalent
to the sum correlation (cf. §3 SoftCCA paragraph), all three TOCCA models maintain the goals of
CCA, just with different relaxations of the orthogonality constraints. Our method is the first to si-
multaneously optimize for CCA and a discriminative task with end-to-end training. See Tab. A2 for
an overview.
5	Experiments
We validated our methods on three different data sets: MNIST handwritten digits, the Carolina
Breast Cancer Study (CBCS) using imaging and genomic features, and speech data from the Wis-
consin X-ray Microbeam Database (XRMB). Our experiments show the utility of our methods for 1)
cross-view classification, 2) regularization with a second view during training when only one view is
available at test time, and 3) representation learning on multiple views that are joined for prediction.
Implementation.3 Each layer of our network consists of a fully connected layer, followed by a
ReLU activation and batch normalization (Ioffe & Szegedy, 2015). Our implementations of DCCA,
SoftCCA, and Joint DCCA/DeepLDA (Dorfer et al., 2016b) also use ReLU activation and batch
3Code is submitted with this paper and will also be available publicly on GitHub after the review period.
6
Under review as a conference paper at ICLR 2020
normalization. We modified CCAL-Lrank (Dorfer et al., 2018) to use a softmax function and cross-
entropy loss for classification, instead of a pairwise ranking loss for retrieval, referring to this modi-
fication as CCAL-Lce. We used the Nadam optimizer and tuned hyperparameters on a validation set
via random search; settings and ranges are specified in Tab. A3. The same hyperparameter tuning
procedure was used for our methods and those we compare with. We used Keras with the Theano
backend and an Nvidia GeForce GTX 1080 Ti.
The following experiments compare our methods with two linear methods (CCA and RCCA),
two unsupervised deep methods (DCCA and SoftCCA), and two supervised deep methods (Joint
DCCA/DeepLDA and CCAL-Lce). Many other variants exist (§3), but the ones we selected are
the current state-of-the-art in each of these classes. We did not run a direct comparison with Wang
et al. (2015a) as Chang et al. (2018) already showed that SoftCCA is superior. We chose Joint
DCCA/DeepLDA to represent supervised LDA-style CCA methods rather than comparing with all
methods in this group (Kan et al., 2015; Elmadany et al., 2016)4.
5.1	Cross-view classification on MNIST digits
We formed a multi-view data set from the MNIST handwritten digit data set (LeCun, 1998). Fol-
lowing Andrew et al. (2013), we split each 28 × 28 image in half horizontally, creating left and right
views that are each 14 × 28 pixels. All images were flattened into a vector with 392 features. The
full data set consists of 60k training images and 10k test images. We used a random set ofup to 50k
for training and the remaining training images for validation. We used the full 10k image test set.
In order to validate both the discriminativeness of the embedding and the success in finding a shared
space, we studied performance on cross-view classification. We evaluated cross-view classification
accuracy by first computing the projection for each view, then we trained a linear SVM on one
view’s projection, and finally we used the other view’s projection at test time. While the task-driven
methods presented in this work learn a classifier within the model, this test setup enables a fair
comparison with the unsupervised CCA variants and validates the discriminativity of the features
learned. It is also the standard method in the literature to test CCA methods for classification.
Notably, using the built-in softmax classifier (not shown) performed similarly to the SVM, as much
of the power of our methods comes from the representation learning part. We do not compare with
a simple supervised NN because this setup does not learn the shared space necessary for cross-view
classification. We report results averaged over five randomly selected training/validation sets; the
test set always remained the same.
Correlation vs. classification accuracy We first demonstrate the importance of adding a task-
driven component to DCCA by showing that maximizing the sum correlation between views is not
sufficient. Fig. 3 (left) shows the sum correlation vs. cross-view classification accuracy across many
different hyperparameter settings for DCCA (Andrew et al., 2013), SoftCCA (Chang et al., 2018),
and TOCCA. We used 50 components for each; thus, the maximum sum correlation was 50. The
sum correlation was measured after applying linear CCA to ensure that components were indepen-
dent. With DCCA a larger correlation tended to produce a larger classification accuracy, but there
was still a large variance in classification accuracy amongst hyperparameter settings that produced
a similar sum correlation. For example, with the two farthest right points in the plot (colored red),
their classification accuracy differs by 10%, and they are not even the points with the best classi-
fication accuracy (colored purple). The pattern is different for SoftCCA. There was an increase in
classification accuracy as sum correlation increased but only up to a point. For higher sum corre-
lations, the classification accuracy varied even more from 20% to 80%. Further experiments (not
shown) have indicated that when the sole objective is correlation, some of the projection directions
are simply not discriminative, particularly when there are a large number of classes. Hence, optimiz-
ing for sum correlation alone does not guarantee a discriminative model. TOCCA-W and TOCCA-SD
show a much greater classification accuracy across a wide range of correlations and, overall, the best
accuracy when correlation is greatest.
Effect of batch size. Fig. 3 (right) plots the batch size vs. classification accuracy for a training set
size of 10, 000. We tested batch sizes from 10 to 10,000; a batch size of 10 or 30 was best for all
4While Elmadany et al. (2016) ran experiments on MNIST, they used the embeddings from both views for
training and test; hence, their results are not directly comparable to our cross-view classification results. When
we did test multi-view classification on MNIST, we achieved 98.5% vs. their reported 97.2%.
7
Under review as a conference paper at ICLR 2020
I I ,
8 6 4 2 0
■ ■ ■ ■ ■
Ooooo
AωRJnωω4
Config. with two highest sum correlations
Config. with highest accuracy、.	∖
1.0	^"''∙'`
DCCA
10	20	30	40
Sum correlation
1.0
8 6 4 2
■ ■ ■ ■
Oooo
AωRJnωω4
0 8 6 4
■ ■ ■ ■
Iooo
AωRJnωω4
0.2
TOCCA-W
0.0
0	10	20	30	40	50
Sum correlation
AωRJnωω4
10	20	30	40
Sum correlation
0.2.
TOCCA-SD
0.0
0	10	20	30	40	50
Sum correlation
CCA -B-SoftCCA	-B-TOCCA-W
RCCA-B-Joint DCCA/DeepLDA -B-TOCCA-SD
DCCA -B- CCAL-Lce	-B-TOCCA-ND
30	100	1,000	10,000
Batch size
AωRJnωω4
o.o
3∞
1,000	10,000	50,0∞
Training set size
Figure 3: Left: Sum correlation vs. cross-view classification accuracy (on MNIST) across different hyper-
parameter settings on a training set size of 10,000 for DCCA (Andrew et al., 2013), SoftCCA (Chang et al.,
2018), TOCCA-W, and TOCCA-SD. For unsupervised methods (DCCA and SoftCCA), large correlations do
not necessarily imply good accuracy. Right: The effect of batch size on classification accuracy for each TOCCA
method on MNIST (training set size of 10,000), and the effect of training set size on classification accuracy for
each method.OUr TOCCA variants out-performed all others across all training set sizes.
Figure 4: t-SNE plots for CCA methods on our variation of MNIST. Each method was used to compute
projections for the two views (left and right sides of the images) using 10,000 training examples. The plots
show a visualization of the projection for the left view with each digit colored differently. TOCCA-SD and
TOCCA-ND (not shown) produced similar results to TOCCA-W.
three variations of TOCCA. This is in line with previous work that found the best performance with a
batch size between 2 and 32 (Masters & Luschi, 2018). We used a batch size of 32 in the remaining
experiments on MNIST.
Effect of training set size. We manipulated the training set size in order to study the robustness of
our methods. In particular, Fig. 3 (right) shows the cross-view classification accuracy for training
set sizes from n = 300 to 50,000. While we expected that performance would decrease for smaller
training set sizes, some methods were more susceptible to this degradation than others. The clas-
sification accuracy with CCA dropped significantly for n = 300 and 1,000, due to overfitting and
instability issues related to the covariance and cross-covariance matrices. SoftCCA shows similar
behavior (prior work (Chang et al., 2018) on this method did not test such small training set sizes).
Across all training set sizes, our TOCCA variations consistently exhibited good performance, e.g.,
increasing classification accuracy from 78.3% to 86.7% for n = 1,000 and from 86.1% to 94.6% for
n = 50,000 with TOCCA-SD. Increases in accuracy over TOCCA-ND were small, indicating that the
different decorrelation schemes have only a small effect on this data set; the task-driven component
is the main reason for the success of our method. In particular, the classification accuracy with
n = 1,000 did better than the unsupervised DCCA method on n = 10,000. Further, TOCCA with
n = 300 did better than linear methods on n = 50,000, clearly showing the benefits of the proposed
formulation. We also examined the CCA projections qualitatively via a 2D t-SNE embedding (Van
Der Maaten & Hinton, 2008). Fig. 4 shows the CCA projection of the left view for each method. As
expected, the task-driven variant produced more clearly separated classes.
8
Under review as a conference paper at ICLR 2020
Table 1: Classification accuracy for different methods of predicting Basal genomic subtype from images or
grade from gene expression. Linear SVM and DNN were trained on a single view, while all other methods were
trained with both views. By regularizing with the second view during training, all TOCCA variants improved
classification accuracy. The standard error is in parentheses.
Method	Training data	Test data	Task	Accuracy	Method	Training data	Test data	Task	Accuracy
Linear SVM	Image only	Image	Basal	0.777 (0.003)	Linear SVM	GE only	-^GE~~	Grade	0.832 (0.012)
NN	Image only	Image	Basal	0.808 (0.006)	NN	GE only	GE	Grade	0.830 (0.012)
CCAL-Lce	Image+GE	Image	Basal	0.807 (0.008)	CCAL-Lce	GE+image	GE	Grade	0.804 (0.022)
TOCCA-W	Image+GE	Image	Basal	0.830 (0.006)	TOCCA-W	GE+image	GE	Grade	0.862 (0.013)
TOCCA-SD	Image+GE	Image	Basal	0.818 (0.006)	TOCCA-SD	GE+image	GE	Grade	0.856 (0.011)
TOCCA-ND	Image+GE	Image	Basal	0.816 (0.004)	TOCCA-ND	GE+image	GE	Grade	0.856 (0.011)
5.2	Regularization for cancer classification
In this experiment, we address the following question: Given two views available for training but
only one at test time, does the additional view help to regularize the model?
We study this question using 1,003 patient samples with image and genomic data from CBCS5
(Troester et al., 2018). Images consisted of four cores per patient from a tissue microarray that
was stained with hematoxylin and eosin. Image features were extracted using a VGG16 backbone
(Simonyan & Zisserman, 2015), pre-trained on ImageNet, by taking the mean of the 512D output
of the fourth set of conv. layers across the tissue region and further averaging across all core images
for the same patient. For gene expression (GE), we used the set of 50 genes in the PAM50 array
(Parker et al., 2009). The data set was randomly split into half for training and one quarter for
validation/testing; we report the mean over eight cross-validation runs. Classification tasks included
predicting 1) Basal vs. non-Basal genomic subtype using images, which is typically done from GE,
and 2) predicting grade 1 vs. 3 from GE, typically done from images. This is not a multi-task
classification setup; it is a means for one view to stabilize the representation of the other. The first
task is also a valuable clinical use case. Genomic analysis is expensive and not routinely performed,
while histologic imaging is standard practice by pathologists for detecting cancer and assessing
its aggressiveness. In working with our clinical collaborators, our goal has been to predict tumor
subtypes from images - something that is too complex for pathologists. We hope that this will
one day make tumor subtypes accessible to more patients and improve treatment decisions. This
experiment demonstrates that the second view of data can help regularize during training even if it
is not available for test patients.
We tested different classifier training methods when only one view was available at test time: a) a
linear SVM trained on one view, b) a deep NN trained on one view using the same architecture as
the lower layers of TOCCA, c) CCAL-Lce trained on both views, d) TOCCA trained on both views.
Tab. 1 lists the classification accuracy for each method and task. When predicting genomic subtype
Basal from images, all our methods showed an improvement in classification accuracy; the best
result was with TOCCA-W, which produced a 2.2% improvement. For predicting grade from GE,
all our methods again improved the accuracy - by UP to 3.2% with TOCCA-W. These results show
that having additional information during training can boost performance at test time. Notably, this
experiment used a static set of pre-trained VGG16 image features in order to assess the utility of the
method. The network itself could be fine-tuned end-to-end with our TOCCA model, providing an
easy opportunity for data augmentation and likely further improvements in classification accuracy.
5.3	Semi-supervised learning for speech recognition
Our final experiments use speech data from XRMB, consisting of simultaneously recorded acoustic
and articulatory measurements. Prior work has shown that CCA-based algorithms can improve
phonetic recognition (Wang et al., 2015b;a; 2016; Dorfer et al., 2016b). The 45 speakers were split
into 35 for training, 2 for validation, and 8 for testing - a total of 1,429,236 samples for training,
85,297 for validation, and 111,314 for testing.6 The acoustic features are 112D and the articulatory
ones are 273D. We removed the per-speaker mean & variance for both views. Samples are annotated
with one of 38 phonetic labels.
5http://cbcs.web.unc.edu/for-researchers/
6http://ttic.uchicago.edu/~klivescu/XRMB_data/full/README
9
Under review as a conference paper at ICLR 2020
Our task on this data set was representation learn-
ing for multi-view prediction - that is, using
both views of data to learn a shared discrimina-
tive representation. We trained each model us-
ing both views and their labels. To test each
CCA model, we followed prior work and concate-
nated the original input features from both views
with the projections from both views. Due to the
large training set size, we used a Linear Discrimi-
nant Analysis (LDA) classifier for efficiency. The
same construction was used at test time. This
setup was used to assess whether a task-optimal
DCCA model can improve discriminative power.
We tested TOCCA with a task-driven loss of LDA
(Dorfer et al., 2016a) or softmax to demonstrate
the flexibility of our model.
Table 5: XRMB classification results.
Method	Task	Accuracy
Baseline	-	0.591
CCA	-	0.589
RCCA	-	0.588
DCCA	-	0.620
SoftCCA	-	0.635
Joint DCCA/DeepLDA	LDA	0.633
CCAL-LCe	Softmax	0.642
TOCCA-W	LDA	0.710
TOCCA-SD	LDA	0.677
TOCCA-ND	LDA	0.677
TOCCA-W	Softmax	0.795
TOCCA-SD	Softmax	0.785
TOCCA-ND	Softmax	0.785
We compared the discriminability of a variety of methods to learn	Table 6: Semi-supervised classi-	
a shared latent representation. Tab. 5 lists the classification re- sults with a baseline that used only the original input features for LDA. Although deep methods, i.e., DCCA and SoftCCA, improved	fication results on TOCCA-W.	XRMB using
	Labeled data	Accuracy
upon the linear methods, all TOCCA variations significantly outper-		
formed previous state-of-the-art techniques. Using softmax consis-	100%	0.795
tently beat LDA by a large margin. TOCCA-SD and TOCCA-ND	30%	0.762
produced equivalent results as a weight of 0 on the decorrelation	10%	0.745
term performed best. However, TOCCA-W showed the best result	3%	0.684
with an improvement of 15% over the best alternative method.	1%	0.637
TOCCA can also be used in a semi-supervised manner when labels are available for only some
samples. Tab. 6 lists the results for TOCCA-W in this setting. With 0% labeled data, the result would
be similar to DCCA. Notably, a large improvement over the unsupervised results in Tab. 5 is seen
even with labels for only 10% of the training samples.
6	Discussion
We proposed a method to find a shared latent space that is also discriminative by adding a task-
driven component to deep CCA while enabling end-to-end training. This required a fundamental
change in formulation because Deep CCA does not compute the embeddings directly as it optimizes
an equivalent objective; therefore, we could not simply add an additional term. Instead, we found an
alternative formulation by replacing the CCA projection with `2 distance minimization and orthogo-
nality constraints on the activations, and we implemented this in three different ways. TOCCA-W or
TOCCA-SD performed the best, dependent on the data set - both of which include some means of
decorrelation to provide a regularizing effect to the model and thereby outperforming TOCCA-ND.
TOCCA showed large improvements over state-of-the-art in cross-view classification accuracy on
MNIST and significantly increased robustness to a small training set size. On CBCS, TOCCA pro-
vided a regularizing effect when both views were available for training but only one at test time.
TOCCA also produced a large increase over state-of-the-art for multi-view representation learning
on a much larger data set, XRMB. On this data set we also demonstrated a semi-supervised approach
to get a large increase in classification accuracy with only a small proportion of the labels. Using a
similar technique, our method could be applied when some samples are missing a second view.
Classification tasks using a softmax operation or LDA were explored in this work; however, the
formulation presented can also be used with other tasks such as regression or clustering. Another
possible avenue for future work entails extracting components shared by both views as well as
individual components. This approach has been developed for dictionary learning (Lock et al., 2013;
Ray et al., 2014; Feng et al., 2018) but could be extended to deep CCA-based methods. Finally, we
have yet to apply data augmentation to the proposed framework; this could provide a significant
benefit for small training sets.
10
Under review as a conference paper at ICLR 2020
References
Galen Andrew, Raman Arora, Jeff Bilmes, and Karen Livescu. Deep Canonical Correlation Analy-
sis. In Proc. ICML, 2013.
Raman Arora and Karen Livescu. Kernel cca for multi-view learning of acoustic features using artic-
ulatory measurements. In Symposium on Machine Learning in Speech and Language Processing,
2012.
Soheil Bahrampour, Nasser M. Nasrabadi, Asok Ray, and W. Kenneth Jenkins. Multimodal Task-
Driven Dictionary Learning for Image Classification. arXiv preprint: 1502.01094, 2015.
Gaurav Bhatt, Piyush Jha, and Balasubramanian Raman. Common Representation Learning Using
Step-based Correlation Multi-Modal CNN. arXiv preprint: 1711.00003, 2017.
Tijl De Bie, Nello Cristianini, and Roman Rosipal. Eigenproblems in pattern recognition. In Hand-
book ofGeometric Computing, pp. 129-167. Springer Berlin Heidelberg, 2005.
Natalia Y. Bilenko and Jack L. Gallant. Pyrcca: regularized kernel canonical correlation analysis in
Python and its applications to neuroimaging. Frontiers in Neuroinformatics, 10, nov 2016.
Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. Deep clustering for unsu-
pervised learning of visual features. In Proc. ECCV, 2018.
Miriam Cha, Youngjune Gwon, and H. T. Kung. Multimodal sparse representation learning and
applications. arXiv preprint: 1511.06238, 2015.
Sarath Chandar, Mitesh M. Khapra, Hugo Larochelle, and Balaraman Ravindran. Correlational
Neural Networks. Neural Computation, 28(2):257-285, feb 2016.
Xiaobin Chang, Tao Xiang, and Timothy M. Hospedales. Scalable and Effective Deep CCA via Soft
Decorrelation. In Proc. CVPR, 2018.
Matthias Dorfer, Rainer Kelz, and Gerhard Widmer. Deep linear discriminant analysis. In Proc.
ICLR, 2016a.
Matthias Dorfer, Gerhard Widmer, and Gerhard Widmerajku At. Towards Deep and Discriminative
Canonical Correlation Analysis. In Proc. ICML Workshop on Multi-view Representaiton Learn-
ing, 2016b.
Matthias Dorfer, Jan Schluter, AndreU Vall, Filip Korzeniowski, and Gerhard Widmer. End-to-end
cross-modality retrieval with CCA projections and pairwise ranking loss. International Journal
of Multimedia Information Retrieval, 7(2):117-128, jun 2018.
Kanghong Duan, Hongxin Zhang, and Jim Jing Yan Wang. Joint learning of cross-modal classifier
and factor analysis for multimedia data classification. Neural Computing and Applications, 27
(2):459-468, feb 2016.
Nour El Din Elmadany, Yifeng He, and Ling Guan. Multiview learning via deep discriminative
canonical correlation analysis. In Proc. ICASSP, 2016.
Qing Feng, Meilei Jiang, Jan Hannig, and JS Marron. Angle-based joint and individual variation
explained. Journal of Multivariate Analysis, 166:241-265, 2018.
Bernardo B. Gatto and Eulanda M. Dos Santos. Discriminative canonical correlation analysis net-
work for image classification. In Proc. ICIP, 2017.
Harold Hotelling. Relations between two sets of variates. Biometrika, 28(3/4):321-377, dec 1936.
Lei Huang, Dawei Yang, Bo Lang, and Jia Deng. Decorrelated Batch Normalization. In Proc.
CVPR, 2018.
Sergey Ioffe and Christian Szegedy. Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift. In Proc. ICML, 2015.
11
Under review as a conference paper at ICLR 2020
Meina Kan, Shiguang Shan, Haihong Zhang, Shihong Lao, and Xilin Chen. Multi-view Discrimi-
nant Analysis. IEEE PAMI, 2015.
Jared Katzman, Uri Shaham, Alexander Cloninger, Jonathan Bates, Tingting Jiang, and Yuval
Kluger. Deep Survival: A Deep Cox Proportional Hazards Network. arxiv preprint: 1606.00931,
2016.
Agnan Kessy, Alex Lewin, and Korbinian Strimmer. Optimal whitening and decorrelation. arXiv
preprint: 1512.00809, 2015.
Alex Krizhevsky, Ilya Sutskever, and Geoff Hinton. Imagenet classification with deep convolutional
neural networks. In Advances in neural information processing systems, pp. 1106-1114, 2012.
Yann LeCun. The mnist database of handwritten digits. http://yann.lecun.com/exdb/mnist/, 1998.
George Lee, Asha Singanamalli, Haibo Wang, Michael D Feldman, Stephen R Master, Natalie N C
Shih, Elaine Spangler, Timothy Rebbeck, John E Tomaszewski, and Anant Madabhushi. Super-
vised multi-view canonical correlation analysis (sMVCCA): integrating histologic and proteomic
features for predicting recurrent prostate cancer. IEEE Transactions on Medical Imaging, 34(1):
284-97, jan 2015.
Dongge Li, Nevenka Dimitrova, Mingkun Li, and Ishwar K. Sethi. Multimedia content processing
through cross-modal association. In Proc. ACM International Conference on Multimedia, 2003.
Eric F Lock, Katherine A Hoadley, J S Marron, and Andrew B Nobel. Joint and Individual Vari-
ation Explained (JIVE) for Integrated Analysis of Multiple Data Types. The Annals of Applied
Statistics, 7(1):523-542, mar 2013.
Dominic Masters and Carlo Luschi. Revisiting Small Batch Training for Deep Neural Networks.
arxiv preprint: 1804.07612, 2018.
Joel S Parker, Michael Mullins, Maggie CU Cheang, Samuel Leung, David Voduc, Tammi Vickery,
Sherri Davies, Christiane Fauron, Xiaping He, et al. Supervised risk predictor of breast cancer
based on intrinsic subtypes. Journal of Clinical Oncology, 27(8):1160-1167, 2009.
Priyadip Ray, Lingling Zheng, Joseph Lucas, and Lawrence Carin. Bayesian joint analysis of het-
erogeneous genomics data. Bioinformatics, 30(10):1370-6, may 2014.
Mehmet Emre Sargin, Yucel Yemez, Engin Erzin, and A Murat Tekalp. Audiovisual synchronization
and fusion using canonical correlation analysis. IEEE Transactions on Multimedia, 9(7):1396-
1403, 2007.
Sumit Shekhar, Vishal M Patel, Nasser M Nasrabadi, and Rama Chellappa. Joint sparse representa-
tion for robust multimodal biometrics recognition. IEEE PAMI, 36(1):113-26, jan 2014.
Karen Simonyan and Andrew Zisserman. Very Deep Convolutional Networks for Large-Scale Image
Recognition. In Proc. ICLR, 2015.
Asha Singanamalli, Haibo Wang, George Lee, Natalie Shih, Mark Rosen, Stephen Master, John
Tomaszewski, Michael Feldman, and Anant Madabhushi. Supervised multi-view canonical cor-
relation analysis: fused multimodal prediction of disease diagnosis and prognosis. In Proc. SPIE
Medical Imaging, 2014.
MA Troester, Xuezheng Sun, Emma H. Allott, Joseph Geradts, Stephanie M Cohen, Chui Kit Tse,
Erin L. Kirk, Leigh B Thorne, Michelle Matthews, Yan Li, Zhiyuan Hu, Whitney R. Robinson,
Katherine A. Hoadley, Olufunmilayo I. Olopade, Katherine E. Reeder-Hayes, H. Shelton Earp,
Andrew F. Olshan, LA Carey, and Charles M. Perou. Racial differences in PAM50 subtypes in
the Carolina Breast Cancer Study. Journal of the National Cancer Institute, 2018.
L Van Der Maaten and G Hinton. Visualizing high-dimensional data using t-sne. journal of machine
learning research. Journal of Machine Learning Research, 9:26, 2008.
Weiran Wang, Raman Arora, Karen Livescu, and Jeff Bilmes. On deep multi-view representation
learning. In Proc. ICML, 2015a.
12
Under review as a conference paper at ICLR 2020
Weiran Wang, Raman Arora, Karen Livescu, and Jeff A. Bilmes. Unsupervised learning of acoustic
features via deep canonical correlation analysis. In Proc. ICASSP, 2015b.
Weiran Wang, Raman Arora, Karen Livescu, and Nathan Srebro. Stochastic optimization for deep
CCA via nonlinear orthogonal iterations. In Proc. Allerton Conference on Communication, Con-
trol, and Computing, 2016.
Xing Xu, Atsushi Shimada, Rin-ichiro Taniguchi, and Li He. Coupled dictionary learning and
feature mapping for cross-modal retrieval. In Proc. International Conference on Multimedia and
Expo, 2015.
13
Under review as a conference paper at ICLR 2020
A Appendix
This appendix includes additional details on our TOCCA algorithm and experiments, including 1)
a comparison of our formulation with other related CCA approaches, 2) pseudocode for the ZCA
whitening algorithm used by TOCCA-W, 3) details on hyperparameter selection, and 4) training
runtime experiments.
A.1 Comparison of TOCCA with related algorithms
Our TOCCA methods finds a shared latent space that is also discriminative by changing the CCA for-
mulation in order to add a task-driven component. Tab. A2 compares our three TOCCA formulations
with other related methods (discussed in §3). CCA is the baseline linear method with a goal of max-
imizing the correlation between a set of orthogonal linear projections on two views of data. DCCA
and SoftCCA are unsupervised deep methods. DCCA optimizes an equivalent objective to CCA
but uses non-linear projections implemented with a NN; however, the projections are not computed
in the network, only after optimization is complete. SoftCCA changes the correlation objective to,
equivalently, minimize the `2 distance between projections and relaxes the orthogonality constraints
by using regularization. CCAL-Lrank does compute the CCA projections in the network but does
not optimize the final NN for correlation; it instead focuses on a pairwise ranking loss for use in
retrieval. Our family of TOCCA methods were detailed in §4. In this supervised formulation, we use
the same `2 distance as SoftCCA and simultaneously optimize a task-driven objective. We handle
the orthogonality constraints in three different ways: with whitening (TOCCA-W), with regulariza-
tion (TOCCA-SD) as was used in SoftCCA, and with no explicit decorrelation (TOCCA-ND).
Table A2: A comparison of our proposed task-optimal deep CCA methods with other related ones from the
literature: DCCA (Andrew et al., 2013), SoftCCA (Chang et al., 2018), CCAL-Lrank (Dorfer et al., 2018).
CCAL-Lrank uses a pairwise ranking loss with cosine similarity to identify matching and non-matching samples
for image retrieval - not classification. Ai and A2 are mean centered outputs from two feed-forward networks.
T
Σ = ATA is computed from a single (large) batch (used in DCCA); Σ is computed as a running mean over
batches (for all other methods). ftask(A; θtask) is a task-specific function with parameters θtask, e.g., a softmax
operation for classification.
Method Objective
CCA	-tr(WT∑12W2)	s.t. WT∑1W1 = WT∑2W2 = I
DCCA	-∣∣∑-1∕2∑i2∑-1∕2∣∣tr	where ||T ||tr = tr(T T T )1/2 (TNO, equivalent to CCA objective)
CCA(W1T A1, W2TA2) computed after optimization complete
SoftCCA	L'2 dist(Al,A2) + λ (LDeCorr(Al) + LDecorr(Az))
CCAL-Lrank Lrank(B1, B2)	where B1, B2 = CCA(A1, A2), Lrank is pairwise ranking loss
TOCCA-W TaSk(B1 ,B2 ,Y)+ λ L'2 dist(B1, B2)	where Bi = U1A1,B2 = U?A2 s.t. BTBi = BTB2 = I
TOCCA-SD TaSk(A1,A2,Y)+ λιL"dist(A1,A2) + λ2 (LDecOrr(Ai) + LDec0rr(A2))	Whitening
TOCCA-ND TaSk(A1, A2, Y)+ λ L'2 dist(Ai, A2)
Loss functions
'2 dist	L'2 dist(A1, A2) = ||A1 - A2||F
Decorr	LDeCDrr(A) = Pi=j ∣∑i,j|	where Σ is running mean across batches of Σ = AT A
Task	Task(A1 ,A2,Y) = Ltask(ftask(A1; θtask),Y) + Ltask(ftask(A2； θtask), Y) where Ltask can be cross-entropy or any other task-driven loss
A.2 Algorithm for whitening
TOCCA-W uses whitening to achieve orthogonality (see §4 for details). The goal is to transform the
activations such that their covariance becomes the identity matrix. We use ZCA whitening which
first applies PCA whitening to decorrelate the data and rescale each axis, followed by a rotation
back to the original space. The final rotation reduces the stochastic axis swapping problems of PCA
whitening (Huang et al., 2018). Pseudocode for ZCA whitening is shown in Algorithm A1.
14
Under review as a conference paper at ICLR 2020
Algorithm A1 Whitening layer for orthogonality.
Input: activations ARdo ×n
Hyperparameters: batch size m, momentum α
Parameters of layer: mean μ, covariance Σ
if training then
μ J αμ + (1 - α)mmA 1n×1 {Update mean}
A = A - μ {Mean Centerdata}
Σ J a∑+(1 - α) m—ιAIAT {Update covariance}
Σ J Σ + I {Add I for numerical stability}
Λ, V J eig(Σ) {Compute eigendecomposition}
U J VΛ-1/2VT {Compute transformation matrix}
else
A J A - μ {Mean center data}
end if
B J UA {Apply ZCA whitening transform}
return B
A.3 Implementation details: hyperparameters
A random search over hyperparameters was used to train our methods and those that we compare
with. The hyperparameter settings and ranges for each data set are provided in Tab. A3. Random
search in these intervals was performed 100 times for MNIST and CBCS. Fewer tries were done for
XRMB because of the much greater runtime on this large data set. A larger batch size was used for
XRMB to improve runtime. The hyperparameter ranges were initially set as an educated guess and,
in some cases, were widened for a particular data set (for all methods) after observing results.
Table A3: Hyperparameter settings and search ranges for the experiments on each data set.
Hyperparameter	MNIST	CBCS	XRMB
Hidden layers	4	[0,4]	4
Hidden layer size	500	200	1,000
Output layer size	50	50	112
Loss function weight λ	[100, 10—4]	[101, 10—5]	[101, 10—5]
Momentum α	0.99	0.99	0.99
Weight decay	[10—3, 10—6], 0	[10—2, 10—5], 0	[10—3, 10—7], 0
Soft decorrelation regularizer	[100, 10—5]	[100, 10—5]	[100, 10—5]
Batch size	32	100	50,000
Learning rate	[10—2, 10—4]	[10—1, 10—3]	[100, 10—4]
Epochs	200	400	100
A.4 Runtime experiments
The computational complexity of TOCCA-W is greater than that of TOCCA-SD due to the eigende-
composition operation (see the end of §4); however, this extra computation is only carried out once
per batch. A runtime comparison of the two methods on all three data sets is provided in Tab. A4.
The difference in runtime was less than 6.5% for a batch size of 100 or 9.4% for a batch size of 30.
Table A4: Training runtime for each data set.
Data set	Batch size	Epochs	TOCCA-W	TOCCA-SD
MNIST	100	200	488 s	418s
MNIST	30	200	1071 s	1036 s
CBCS	100	400	103 s	104s
XRMB	50,000	100	3056 s	3446 s
15