Under review as a conference paper at ICLR 2020
MissDeepCausal: causal inference from in-
complete data using deep latent variable mod-
ELS
Anonymous authors
Paper under double-blind review
Ab stract
Inferring causal effects of a treatment, intervention or policy from observational
data is central to many applications. However, state-of-the-art methods for causal
inference seldom consider the possibility that covariates have missing values,
which is ubiquitous in many real-world analyses. Missing data greatly compli-
cate causal inference procedures as they require an adapted unconfoundedness
hypothesis which can be difficult to justify in practice. We circumvent this is-
sue by considering latent confounders whose distribution is learned through vari-
ational autoencoders adapted to missing values. They can be used either as a
pre-processing step prior to causal inference but we also suggest to embed them
in a multiple imputation strategy to take into account the variability due to miss-
ing values. Numerical experiments demonstrate the effectiveness of the proposed
methodology especially for non-linear models compared to competitors.
Keywords: treatment effect estimation, missing values, variational autoencoders,
importance sampling, double robustness, multiple imputation.
1	Introduction
Many methods have been developed to estimate the causal effect of an intervention, such as the
administration of a treatment, on an outcome such as survival, from observational data, i.e., data
that is potentially confounded by selection bias due to the absence of randomization. Classical ones
include matching (Iacus et al., 2012), inverse propensity weighting (IPW, Horvitz & Thompson,
1952; Rosenbaum & Rubin, 1983) and doubly robust methods (Robins et al., 1994; Chernozhukov
et al., 2018; Wager & Athey, 2018; Athey et al., 2019). More recent proposals use deep learning
methods that ensure balance of the population at the level of representation (Johansson et al., 2016;
Shalit et al., 2017), infer the joint distribution of latent and observed confounders, the treatment and
the outcome (Louizos et al., 2017) or predict the counterfactuals with GANs (Yoon et al., 2018).
For a detailed review of existing literature on treatment effect estimation we refer to Imbens (2004),
Lunceford & Davidian (2004) and Guo et al. (2019).
However, state-of-the-art methods still suffer from important shortcomings. In particular, they sel-
dom consider the possibility that covariates have missing values, which is ubiquitous in many real-
world situations (Josse & Reiter, 2018) and has been widely discussed in different contexts (Mayer
et al., 2019a; van Buuren, 2018; Little & Rubin, 2002). Although this question of missing attributes
in the context of treatment effect estimation has been raised early in the development of causal infer-
ence (Rosenbaum & Rubin, 1984), there is still a lack of effective and consistent solutions address-
ing this problem, with a few notable exceptions such as Mattei & Mealli (2009); Seaman & White
(2014); Yang et al. (2019); Kallus et al. (2018) which mainly focus on inverse propensity weighting
(IPW) methods and Kuroki & Pearl (2014) who discuss identifiability of causal effects under mea-
surement error or unobserved confounders. Recently, Mayer et al. (2019b), in addition to suggesting
doubly robust estimators with missing data, classified the existing approaches into two families: the
ones that adapt the causal inference assumptions to the missing values setting (D’Agostino Jr & Ru-
bin, 2000; Blake et al., 2019) and the ones (Mattei & Mealli, 2009; Seaman & White, 2014; Kallus
et al., 2018) that consider the classical machinery and missingness mechanisms assumptions (Little
& Rubin, 2002). While the former are based on the assumption of unconfoundedness with missing
values, which can be difficult to assess in practice, the latter have been developed under strong para-
1
Under review as a conference paper at ICLR 2020
metric assumptions about the outcome, treatment and covariates models, in addition to relying on
missing values hypotheses that can also be difficult to meet in practice (Yang et al., 2019).
To avoid relying on the hypothesis of unconfoundedness with missing values or being in the very
parametric (and linear) framework of multiple imputation (Mattei & Mealli, 2009; Seaman & White,
2014) and matrix factorization (Kallus et al., 2018), we propose a new method for causal inference
with missing data, which we call MissDeepCausal. MissDeepCausal is inspired by the work of
Kallus et al. (2018) in the sense that we consider a model with latent confounders, and assume
that we only have access to covariates with missing values that are noisy proxies of the true latent
confounders. However, our approach generalizes and extends the work of Kallus et al. (2018) in
different aspects: (i) instead of linear factor analysis models with missing values, we consider non-
linear versions using deep latent variable models (Kingma & Welling, 2014; Rezende et al., 2014);
(ii) we rely on the missing at random (MAR) (Rubin, 1976) assumption for the missing data mecha-
nisms, and not on the stronger missing completely at random (MCAR) one; (iii) we take into account
the posterior distribution of the latent variables given observed data and not only their conditional
expectation. This latter point allows us to define a multiple imputation strategy adapted to the latent
confounders model, and to couple it with doubly robust treatment effect estimation (Chernozhukov
et al., 2018).
In the remainder of this article we first introduce the problem framework and recall existing work
for handling missing values in causal inference in Section 2. We then introduce two variants of
our MissDeepCausal approach in Section 3. Finally we compare MissDeepCausal empirically with
several state-of-the-art methods on simulated data in Section 4.
2	Setting, notations and related works
In this section we start by quickly reviewing the problem of causal inference from observational data
without missing data. We consider the potential outcomes framework (Rubin, 1974; Imbens & Ru-
bin, 2015) where we have a sample of n independent and identically distributed (i.i.d.) observations
(Yi(0),Yi(1), Wi, Xi)i=1,..., n with Wi ∈ {0, 1} a binary treatment, Xi = (Xi1, . . . ,Xip)> ∈ Rp
a vector of covariates, and (Yi (0), Yi (1)) ∈ R2 the outcomes we would have observed had we as-
signed control or treatment to the i-th sample, respectively. The observed outcome for unit i, Yi ∈ R
is defined as Yi , WiYi(1) + (1 - Wi)Yi(0). The individual causal effect of the treatment is
τi , Yi(1) - Yi(0) and the average treatment effect (ATE) is defined as
τ , E[Yi(1) - Yi(0)] =E[τi].
The ATE τ, i.e., the link between W and Y , can be estimated from observational data by taking into
account the confounding factors X, i.e., the common causes of W and Y . A popular estimator of τ
from observational data is the so-called doubly robust estimator:
八 ,1 XX ʌ (Y X 八 JTVYi - μi(Xi) 门 HnYi - μ0(Xi)	门、
TDK = n∑μι(χi) - μ0(Xi) + Wi e(Xi) -(1 - Wi)I- e(Xi),	⑴
where μw (x) are regression estimates of the conditional response surfaces μw (x) = E[Y(W) | X =
x], w ∈ {0,1}, and e(x) is an estimate of the propensity score e(x) = P(Wi = 11 Xi = x)
(Rosenbaum & Rubin, 1983; Imbens & Rubin, 2015).
Standard results state that if either (μo,μ1) or e is correctly specified, then TDR is an unbiased
estimator of T (Robins et al., 1994; Chernozhukov et al., 2018; Wager & Athey, 2018) under the
following assumptions (Rosenbaum & Rubin, 1983): the ignorability or unconfoundedness assump-
tion that states that all confounding factors are measured, i.e., conditionally on X, the treatment
assignment is independent of the potential outcomes:
{Υi(1),Υi(0)}⊥ Wi | Xi,	forall i；	(2)
and the overlap assumption assuming the existence of some η > 0 such that η < e(x) < 1 -
η, for all x ∈ X .
We now consider an extension to account for possible missing entries in the covariates. For that
purpose, we denote the missingness pattern of the i-th sample as Mi ∈ {0, 1}p such that Mij = 0
2
Under review as a conference paper at ICLR 2020
if Xij is observed and Mij = 1 otherwise. The matrix of observed covariates can be written as
X? , X (1 - M) + NA M, with the elementwise multiplication and 1 the matrix filled
with 1, so that X? takes its value in the half discrete space X? , (R ∪ {NA})p. We model Mi
as a random vector, and the possibility to infer causal effects with missing data now depends on
additional assumptions on the joint law of (Yi(0), Yi(1), Wi, Xi, Mi)i=1, ..., n. Methods for causal
inference with missing covariates can be classified into two categories.
Unconfoundedness with missing values. Rosenbaum & Rubin (1984) extend the unconfounded-
ness hypothesis (2) to missing values as
{匕⑴，Yi(0)}⊥ Wi | Xi,	forall i.	(3)
This implies the assumption, illustrated in Figure 1, that if a covariate is not observed, it is not a
confounder. In particular, observations can have different confounders depending on their pattern of
missing data. They define the generalized propensity score as:
∀x? ∈ X?, e?(x?) , P(Wi = 1 |Xi? = x?) ,	(4)
which is a balancing score under (3). Consequently, an IPW estimator formed with estimators of e?
can be an unbiased estimator of the ATE with missing values. Nevertheless, this method relies both
on the fact that the covariates X are the appropriate set of confounders, which can be questioned
without missing data (Kallus et al., 2018), and requires certain expert input and reasoning to verify
that for each observation, treatment assignment and/or outcome values depend only on observed
values of the confounders (Blake et al., 2019; Mayer et al., 2019b). Note in particular, that it is not
because the missing data in the covariates are completely at random (MCAR), i.e., M ⊥ X, that (3)
is met. In practice, in addition, a difficulty with this approach is that estimating (4) requires fitting
one model per pattern of missing values, which is unrealistic with classical tools (Miettinen, 1985;
D’Agostino Jr & Rubin, 2000; D’Agostino Jr et al., 2001; Blake et al., 2019); Mayer et al. (2019b)
address this problem using random forests adapted to covariates with missing values.
Figure 1: Unconfoundedness with missing values. X represents a the complete covariates, and
M a missing data mechanism, X * represents the observed incomplete covariates, confounding the
treatment assignment. The formalism of Pearl (1995) and Richardson & Robins (2013) is used.
Missingness mechanisms assumptions. Multiple imputation is one of the most powerful ap-
proaches to estimate parameters and their variance from an incomplete data (Little & Rubin, 2002;
van Buuren, 2018). Seaman & White (2014) show that when assuming (i) identifiability of the ATE
in the complete case, (ii) missing at random (MAR) values given W and Y , (iii) correct specification
of the propensity score with logistic regression and of the Gaussian distribution of covariates, then
multiple imputation gives a consistent estimate for the ATE estimated with IPW. An extension to
doubly robust estimation has been proposed by Mayer et al. (2019b).
Instead of assuming that confounders are observed directly, Kallus et al. (2018) consider a more
general model where observed covariates X are noisy and/or incomplete proxies of the true latent
confounders Z. More specifically, they assume a low-rank model for the covariates and estimate the
latent variables from the incomplete confounders using matrix completion methods (Hastie et al.,
2015; Josse et al., 2016). Then, under the linear regression model
Yi = ZiT α + τWi + εi ,	(5)
with random latent variables Z, missing values completely at random (MCAR) in X, unconfound-
edness given Z, and some additional assumptions, they prove that regressing Y on Z and W leads
to a consistent ATE estimator. Both techniques, multiple imputation and matrix factorization, rely
on parametric (and linear) frameworks.
3
Under review as a conference paper at ICLR 2020
3	MissDeepCausal
To avoid relying on the hypothesis of unconfoundedness with missing values (3) or being in the
very parametric (and linear) framework of multiple imputation and matrix factorization, we propose
MissDeepCausal, an approach based on deep latent variable models where the latent variables are
assumed to be the confounders as represented in Figure 2.
Figure 2: Graphical representation of the model underlying MissDeepCausal. Z represents the
unobserved latent confounders of the treatment W and the effect Y . X represents a proxy for the
confounders, and M a missing data mechanism; X* represents the observed incomplete covariates.
M
Under this model, the unconfoundedness hypothesis (3) does not hold, so a standard treatment effect
estimator using X* as covariates would be biased. On the other hand, we can express the treatment
effect conditioned on X * as follows:
E[Y (1) - Y(0) |X*] = E[E[Y (1) -Y(0) |Z,X*] |X*]
= E[E[Y (1) -Y(0) |Z] |X*] .
Consequently, if we have an unbiased estimator f(Z) of E[Y (1) - Y (0) | Z], the treatment effect
conditioned on Z, and if we know P(Z | X*), the conditional distribution of Z given X*, then we
can derive the treatment effect conditioned on X * by
g(X?) , Ef(Z)IX?].	(6)
Furthermore, by expressing the ATE as
τ = E[Y (1) -Y(0)] = E[E[Y (1) -Y(0) | X*]] ,
We can form an estimate of the ATE by E[^(X?)]. We describe such an estimator in Section 3.2 be-
low, which is reminiscent of multiple imputation techniques in the field of missing value imputation
(Rubin, 1987).
Another strategy, described in Section 3.3, is to consider latent variables estimation as a pre-
processing step prior to causal inference by computing
h(X?) , f(E[Z|X?]);	(7)
this can be seen as a non-linear extension of Kallus et al. (2018). Both estimators require sampling
from the posterior distribution P(Z|X?). Consequently, We first describe in Section 3.1 hoW to learn
the joint distribution of (Z, X) from X? using a variational autoencoder (VAE) With missing data,
before turning to the details of each strategy.
3.1	Deep latent variable models with missing values
To estimate and sample from P(Z | X?), We use the missing data importance Weight autoencoder
bound (MIWAE) approach of Mattei & Frellsen (2019), Which is summarized in the appendix A.
They use a simple variational family Where they impute the missing entries With a constant and shoW
that using this class of distributions, it maximizes a loWer bound of the observed log-likelihood.
Note that their approach requires the classical missing at random (MAR) (Rubin, 1976) assumption
to ignore the missing values mechanism When maximizing the observed likelihood for the VAE
inference.
In the MIWAE approach, the variational distribution QY(Z∣X?) (defined in Appendix A) plays a
central role but is not necessarily a good surrogate for the posterior distribution P§(Z∣X?). To
4
Under review as a conference paper at ICLR 2020
sample from the true posterior distribution, we resort to importance sampling techniques using the
variational distribution Qγ for proposal. More precisely, we can define, for any measurable function
s,
E[s(Z)∣X ?]= f s(Z )pθ(Z∣X ?)dZ =-X) f s(Z) pθ (X(ZZXy) qγ (ZX ?)dZ.
p	qγ
This quantity can be estimated using self-normalized importance sampling with:
E[s(Z)∣X?] ≈ XX Wls(Z(I)), where Wl，	rl	, With Tl，PP(X?|Z:目:(I)). (8)
M	ri + ... + Tl	qγ (Z (I)IX ?)
Equation (8) is used in our second strategy described in Section 3.3, while for our first strategy
(described in Section 3.2) We sample L samples Z(I),..., Z(L) according to QY (Z ∣X ?), compute
the weights as in (8) and re-sample B << L with probability proportional to the weights.
3.2	MissDeepCausal with multiple imputation (MDC-MI)
MDC-MI uses the importance sampling strategy presented in Section 3.1, to compute an approxi-
mation of (6) by Monte-Carlo as folloWs. First, We draW B i.i.d. samples (Z(j))i≤j≤B ∈ Rn×d
from the posterior distribution P (Z|X?). On each sample, We evaluate the function f and aggregate
the results: g(B)(X?) = B PB=I f (Z(j)). This approach can be viewed as a multiple imputation
method, Which consists in generating different imputed data sets by draWing the missing values from
their posterior distribution given observed values, then estimating the parameters of interest on each
imputed data set and aggregating the results according to Rubin’s rules (Rubin, 1987) to obtain a
final estimate for the quantity of interest. Here we consider the samples Z(j) of the latent variables
and apply the doubly robust estimator from (1) on each table Z(j):
Tj) = n Xμlj)(Zij))- μ0j)(Zij))+WiYi -jZj -(I-Wi):-jj，(9)
and get the final estimate for the causal effect by computing the mean of the estimators i.e. T =
B PB=I T(j). The doubly robust estimator from (1) is asymptotically normal (under some mild
assumptions) (Wager & Athey, 2018) which is required for the aggregation in multiple imputation
procedures (Rubin, 1987). Note that this multiple imputation strategy additionally allows to reflect
the variability due to the missing values in the variance estimation of the estimator T.
3.3	MissDeepCausal with latent variables estimation as a pre-processing step
(MDC-process)
We also propose MDC-process as a non-linear extension of Kallus et al. (2018), where we esti-
mate h(X?) defined in (7). For that purpose, we first approximate the expectation of the posterior
distribution
Z(x?)，E[Z∣X? = x?]	(10)
to get estimates for the latent confounders. In a second step, we use them under the regression model
(5) and accordingly regress the observed outcome Y on the estimated latent factors Z(x?) and the
treatment assignment W to obtain an estimation of the treatment effect. This strategy is a heuristic
extension of Kallus et al. (2018) to a non-linear case in the sense that the latent variables encode
non-linear relationship between covariates.
An alternative, still heuristic, approach is to use the estimated latent confounders from (10) as inputs
for standard techniques to estimate the average treatment effect. More precisely, for the doubly
robust estimator (1), we replace the estimates for the propensity score with estimates for
,. . ʌ ,
e(z) = P(Wi = ι I Zi(x?) = z),
and similarly for the conditional response surfaces.
However, note that this latter strategy would require Z(x?) from (10) to be a confounder instead of
Z as it is assumed (see Figure 2).
5
Under review as a conference paper at ICLR 2020
4	Simulation study
4.1	Methods
We compare the following methods to handle missing values (the following acronyms are identical
to the method labels used in Figures 3-5):
• MissDeepCausal:
-	MDC.process: using the doubly robust estimator MDC-Process from Section 3.3;
-	MDC.mi: using the doubly robust estimator MDC-mi Section 3.2.
We extended the Publicly available code of Mattei & Frellsen (2019) to imPlement both
methods, using the default Parameters for the MIWAE Part. Using notations of APPendix
A, we use L = 10, 000 for the imPortance samPling weights. In addition, for MDC-mi, we
samPle B = 200 observations from the estimated Posterior distribution of Z|X?.
•	MICE: the multiPle imPutation aPProach as suggested in Mattei & Mealli (2009) and Sea-
man & White (2014). We generate 10 imPutations, using the imPlementation in the R (R
Core Team, 2018) Package mice (van Buuren & Groothuis-Oudshoorn, 2011).
•	MF: the matrix factorization aPProach of Kallus et al. (2018) using R Packages
softImpute (Hastie & Mazumder, 2015) (for continuous data) and mimi (Robin, 2019)
(for mixed data) for the matrix comPletion based on nuclear norm Penalty. We choose the
dimension of the latent sPace via cross-validation.
•	MIA: the method ProPosed by Mayer et al. (2019b) which targets (4) and the generalized
resPonse surface analogue. It is based on estimation using random forests where missing
values are encoded with missing incorporated in attributes such that the sPlitting rules in
the random forests exPloit the missingness Pattern (Twala et al., 2008; Josse et al., 2019).
We use the R Package grf (Tibshirani et al., 2018) for the comPlete case and the imPle-
mentation Provided by Mayer et al. (2019b) for the incomPlete case1.
4.2	Settings
Under the latent confounding assumPtion (corresPonding to the graPhical model in Figure 2), we
generate covariates according to two models:
•	LRMF: The covariates are generated from a low-rank matrix factorization model as in
Kallus et al. (2018).
•	DLVM: The covariates are generated from a deeP latent variable model as in as in Kingma
& Welling (2014). Zi 〜 Nd(0,1), covariates Xi are sampled from Np(μ(z), ∑(z)),
where (μ(z), ∑(z)) = (Vtanh(UZ + a) + b, diag{exp(ηT tanh(UZ + a) + δ)}) with
U, V, a, b, δ, η drawn from Standard Gaussian distributions and Uniform distributions.
Missing values are generated completely at random (MCAR), i.e., P(Mij = 1) = ρ, ∀ i, ∀j, with
ρ ∈ {0, 0.1, 0.3} and we consider the following problem dimensions: n = 10, 000, p = 10, and
d = 3. Results are reported using 20 simulations for each setting. Throughout all experiments the
true ATE τ is fixed at 1. Additional experiments with other choices of parameters are reported in the
Appendix B.
4.3	Results
4.3.1	Regression adjustment
First, we assess the quality of our heuristic described in Section 3.3 concerning the non-linear exten-
sion of Kallus et al. (2018). For this we define treatment and outcome models with a logistic-linear
model as follows: logit(e(Zi∙)) = ατZi and Yi 〜 N((βTZi + τWi,σ2). An estimation of T
is obtained by regressing the observed outcomes Yi on the estimations of the latent factors Z (for
MDC.process, MF) and on the imputed data Ximp (for MICE).
1 https://github.com/imkemayer/causal- inference- missing
6
Under review as a conference paper at ICLR 2020
Figure 3 shows that as expected our proposed method, lin.MDC.process actually outperforms
all other methods when the covariates are generated according to a DLVM model. The bias observed
is small with respect to the one exhibited for completely observed covariates X . Additionally we
observe that if the data is generated under the LRMF model, then our method performs as well as
the initial proposal of Kallus et al. (2018) (results for this are not reported here).
1.00
(a)	0% of missing values
(b)	10% of missing values
(c)	30% of missing values
Figure 3: Estimated ATE via regression adjustment; covariates generated from a DLVM,
(logistic-)linear model specification for (e, μo, μι); results with Z_true results are obtained using
the true confounders Z .
4.3.2	Doubly robust estimation
Now we turn to the more flexible framework which does not assume linear relationships (equation 5)
between the outcome and the confounders. We generate the treatment and outcome using logistic-
linear models and non-linear models based on non-linear transformations of the latent variables Z.
We consider the doubly robust estimator (1) with the (imputed) covariates X for MICE and with the
estimation of the latent variables Z for MF and MissDeepCausal.
To estimate the regression surfaces (μι, μo) and the propensity score e required for the doubly robust
estimator (equation 1), we use either a logistic-linear model or (generalized) random forests (Athey
et al., 2019), indicated respectively by the prefixes loglin and grf in all figures.* 2 For the latter,
we use the implementation of the R package grf (Tibshirani et al., 2018).
Figure 4 illustrates that even when the latent variables are generated from matrix factorization, our
approaches based on the VAE with missing values lead to estimates that are almost unbiased, given
that the estimation of the propensity score and response surfaces is adapted to the considered models.
The small bias observed for the matrix factorization pre-processing approach from Kallus et al.
(2018) is not in contradiction with their theory since we use the doubly robust estimators and not
the regression model. In addition, they require a (much) larger number of proxy covariates w.r.t. the
number of latent confounders.
Figure 5 shows that as expected, due to the flexibility of MissDeepCausal, the suggested approaches
better handle highly non-linear relationships between the latent confounders and the observed (in-
complete) covariates. It turns out that the multiple imputation strategy is particularly appropriate
when the relationships between the outcome, the treatment and the confounders are highly non-
linear.
4.4	IHDP data
We assess our methodology on the Infant Health and Development Program (IHDP) benchmark
data (Hill, 2011). The original data comes from a randomized control trial where the aim was to
assess the impact of visits by specialists on children’s test scores. There are six quantitative and 19
binary variables, recorded for 985 individuals. Hill (2011) transformed the original experimental
data into observational data by selecting a nonrandom subset among the treated, stratified along an
ethnicity variable, which leads to two unbalanced treatment groups. In total there are 139 treated and
608 control observations in the new data set. Then, keeping fixed the treatment variable, simulated
2More specifically, for estimating μw, We use all observations having Wi = w.
2In Figure 4b, all loglin estimations yield values around 6 and are therefore omitted for better readability.
7
Under review as a conference paper at ICLR 2020
1.10
1.05
1.00
0.95
(a) Logistic-linear model specification for(b) Non-linear model specification for
(e,μo,μι)	(e,μo,μι)
Figure 4: Estimated ATE for 10% of missing values; covariates are generated according to LRMF;
Z_true results are obtained using the true ConfoUnders Z.
1.00
0.95
0.90
0.85
0.80
1.20
1.15
110
1.05
1.00
•
j
(a) Logistic-linear model specification for(b) Non-linear model specification for
(e,μo,μι)	(e,μo,μι)
I [
Figure 5: Estimated ATE for 10% of missing values; covariates are generated according to DLVM;
Z_true results are obtained using the true ConfoUnders Z.
data are obtained by generating new potential outcomes. More precisely, we follow the scenario
“B" of Hill (2011) , i.e., Y(0)〜N(μο, 1) and Y⑴ 〜N(μι, 1), with (μο,μι) = (exp(X +
W)β, Xβ -ω) where ω is Chosen to get an average treatment effeCt τ equal to 4. 3 After simulating
the outComes, we add missing values to the 25 Covariates, assuming an MCAR meChanism. For the
MIWAE part of our MDC methods, we seleCt the parameters σprior and dby 5-fold Cross-validation.
In addition to Comparing the estimators Considered in this paper that handle missing data, we also
add the CEVAE estimator detailed in Louizos et al. (2017) as a baseline. Note that CEVAE does
not deal with missing values so that we replaCe the missing values by the mean of the variables.
The CEVAE estimator is based on the differenCe between the two Conditional expeCtations. For
Comparability with their method and previous experiments on these data, we report the in-sample
mean absolute error, i.e. the mean absolute differenCe between the estimated ATE and the sample
ATE (by construction of the data we know the exact values of μ.)(Xi) and μ(o)(XJ for all i):
δ= IT- n P μ(1) (Xi)- μ(0) (Xi) I.
Table 1 shows that the doubly robust estimators (either in the parametric regression, DRlog-lin, or
the random forest form DRrf) systematically outperform the corresponding OLS estimator which
highlights that the linear model is not appropriate, at least that it is not linear in the covariates X .
Indeed, we know that the outcome is simulated as a nonlinear function of the (complete) covariates
X, whereas the treatment assignment is taken from the (derandomized) experiment and can there-
fore well depend on latent variables. The results of MissDeepCausal are competitive with other
3We use and adapt the corresponding code from V. Dorie: https://github.com/vdorie/npci/.
8
Under review as a conference paper at ICLR 2020
%NA	Method	OLS	∆ DRlog-Iin	DRrf
	X (complete data)	0.72 ± 0.02	0.13 ± 0.00	0.20 ± 0.01
	MF	0.56 ± 0.03	0.14 ± 0.01	0.16 ± 0.01
0	MDC.process	0.51 ± 0.03	0.15 ± 0.01	0.19 ± 0.03
	MDCmi	0.47 ± 0.03	0.16 ± 0.01	0.14 ± 0.02
	CEVAE (X)		0.34 ± 0.02			
	MICE	0.85 ± 0.02	0.16 ± 0.00	0.24 ± 0.01
	MIA.GRF	-	-	0.23 ± 0.01
10	MF	0.50 ± 0.03	0.15 ± 0.01	0.15 ± 0.01
	MDC.process	0.42 ± 0.02	0.15 ± 0.01	0.16 ± 0.02
	MDC.mi	0.35 ± 0.02	0.17 ± 0.01	0.13 ± 0.02
	CEVAE(Xmeanimp)		0.31 ± 0.01			
	MICE	1.20 ± 0.02	0.30 ± 0.00	0.32 ± 0.01
	MIA.GRF	-	-	0.17 ± 0.01
30	MF	0.39 ± 0.02	0.16 ± 0.01	0.17 ± 0.01
	MDC.process	0.37 ± 0.02	0.16 ± 0.01	0.15 ± 0.02
	MDC.mi	0.30 ± 0.02	0.18 ± 0.01	0.13 ± 0.01
	CEVAE(Xmeanimp)		0.38 ± 0.02			
	MICE	1.54 ± 0.03	0.46 ± 0.01	0.42 ± 0.01
	MIA.GRF	-	-	0.19 ± 0.01
50	MF	0.28 ± 0.01	0.20 ± 0.01	0.21 ± 0.02
	MDC.process	0.24 ± 0.01	0.20 ± 0.01	0.21 ± 0.02
	MDC.mi	0.18 ± 0.01	0.22 ± 0.01	0.22 ± 0.03
	CEVAE(Xmeanimp)		0.38 ± 0.02			
Table 1: Methods on the IHDP benchmark data. Mean absolute error ∆ (with standard error) across
simulations on all the data points (in-sample error). OLS corresponds to the estimator obtained by
regression and DR to the doubly robust estimator(s).
approaches and greatly improve on CEVAE and MICE. Its performances when used with the double
robust estimators are stable with respect to the percentage of missing values.
5 Conclusion
In this work we have investigated the problem of treatment effect estimation with incomplete co-
variates. This problem of missing values is highly relevant for modern causal inference as it is
exacerbated with high dimensional data. Yet most causal inference techniques do not address this
issue; and complete case analysis, in addition to leading to potentially inconsistent causal effects es-
timators, is not an option anymore. We have proposed MissDeepCausal which borrows the strength
of deep latent variable models to retrieve the latent confounders from incomplete covariates encod-
ing complex non-linear relationships. We use a modular approach in the style of Bayesian propensity
based methods for treatment effect estimation (Zigler, 2016), where the latent variables are used as
inputs for doubly robust estimators. We suggest a multiple imputation strategy that allows to fully
exploit the posterior distribution of the latent variables. Numerical results are very encouraging in-
sofar as we obtain best relative performance in terms of bias whether the underlying model is well
or badly specified compared to current state of the art. Open challenges include heterogeneous treat-
ment effect estimation with missing values as well as the ambitious task of handling missing not at
random type data.
References
Susan Athey, Julie Tibshirani, Stefan Wager, et al. Generalized random forests. The Annals of
Statistics, 47(2):1148-1178, 2019.
Helen A. Blake, Clmence Leyrat, Kate Mansfield, Shaun Seaman, Laurie Tomlinson, James Car-
penter, and Elizabeth Williamson. Propensity scores using missingness pattern information: a
practical guide. arXiv preprint, 2019.
9
Under review as a conference paper at ICLR 2020
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney
Newey, and James Robins. Double/debiased machine learning for treatment and structural pa-
rameters. The Econometrics Journal, 21(1):C1-C68, 2018.
Ralph D’Agostino Jr, Wei Lang, Michael Walkup, Timothy Morgan, and Andrew Karter. Examining
the impact of missing data on propensity score estimation in determining the effectiveness of self-
monitoring of blood glucose (smbg). Health Services and Outcomes Research Methodology, 2
(3-4):291-315, 2001. doi: 10.1023/A:102037541.
Ralph B D’Agostino Jr and Donald B Rubin. Estimating and using propensity scores with partially
missing data. Journal of the American Statistical Association, 95(451):749-759, 2000. doi:
10.2307/2669455.
Ruocheng Guo, Lu Cheng, Jundong Li, P. Richard Hahn, and Huan Liu. A survey of learning
causality with data: Problems and methods. arXiv preprint arXiv:1809.09337, 2019.
Trevor Hastie and Rahul Mazumder. softImpute: Matrix Completion via Iterative Soft-Thresholded
SVD, 2015. R package version 1.4.
Trevor Hastie, Rahul Mazumder, Jason D. Lee, and Reza Zadeh. Matrix completion and low-rank
svd via fast alternating least squares. Journal of Machine Learning Research, 16:3367-3402,
2015.
Jennifer L Hill. Bayesian nonparametric modeling for causal inference. Journal of Computational
and Graphical Statistics, 20(1):217-240, 2011.
Daniel G Horvitz and Donovan J Thompson. A generalization of sampling without replacement
from a finite universe. Journal of the American statistical Association, 47(260):663-685, 1952.
doi: 10.1080/01621459.1952.10483446.
Stefano M Iacus, Gary King, and Giuseppe Porro. Causal inference without balance checking:
Coarsened exact matching. Political Analysis, 20(1):1-24, 2012. doi: 10.1093/pan/mpr013.
Guido W Imbens. Nonparametric estimation of average treatment effects under exogeneity: A
review. Review of Economics and statistics, 86(1):4-29, 2004.
Guido W Imbens and Donald B Rubin. Causal inference in statistics, social, and biomedical sci-
ences. Cambridge University Press, 2015.
Fredrik Johansson, Uri Shalit, and David Sontag. Learning representations for counterfactual infer-
ence. In International conference on machine learning, pp. 3020-3029, 2016.
Julie Josse and Jerome P. Reiter. Introduction to the special section on missing data. Statist. Sci., 33
(2):139-141, 05 2018. doi: 10.1214/18-STS332IN.
Julie Josse, Sylvain Sardy, and Stefan Wager. denoiser: A package for low rank matrix estimation.
Journal of Statistical Software, 2016.
Julie Josse, Nicolas Prost, ErWan Scornet, and Gael Varoquaux. On the consistency of supervised
learning with missing values. arXiv preprint, 2019.
N. Kallus, X. Mao, and M. Udell. Causal inference With noisy and missing covariates via matrix
factorization. In Advances in Neural Information Processing Systems, pp. 6921-6932, 2018.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In International Conference
on Learning Representations, 2014.
Manabu Kuroki and Judea Pearl. Measurement bias and effect restoration in causal inference.
Biometrika, 101(2):423-437, 2014.
R. J. A. Little and D. B. Rubin. Statistical Analysis with Missing Data. Wiley, 2002. ISBN
0471183865. doi: 10.2307/1533221.
10
Under review as a conference paper at ICLR 2020
Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, and Max Welling.
Causal effect inference with deep latent-variable models. In Advances in Neural Information
Processing Systems, pp. 6446-6456, 2017.
Jared K Lunceford and Marie Davidian. Stratification and weighting via the propensity score in
estimation of causal treatment effects: a comparative study. Statistics in medicine, 23(19):2937-
2960, 2004. doi: 10.1002/sim.1903.
Alessandra Mattei and Fabrizia Mealli. Estimating and using propensity score in presence of missing
background data: an application to assess the impact of childbearing on wellbeing. Statistical
Methods and Applications, 18(2):257-273, 2009. doi: 10.1007/s10260-007-0086-0.
Pierre-Alexandre Mattei and Jes Frellsen. MIWAE: Deep generative modelling and imputation of
incomplete data sets. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of
the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine
Learning Research, pp. 4413-4423, Long Beach, California, USA, 09-15 Jun 2019. PMLR.
Imke Mayer, Julie Josse, Nicholas Tierney, and Nathalie Vialaneix. R-miss-tastic: a unified platform
for missing values methods and workflows. arXiv preprint arXiv:1908.04822, 2019a.
Imke Mayer, Stefan Wager, Tobias Gauss, Jean-Denis Moyer, and Julie Josse. Doubly robust treat-
ment effect estimation with missing attributes. arXiv preprint arXiv:1910.10624, 2019b.
Olli S. Miettinen. Theoretical epidemiology: principles of occurrence research. John Wiley & Sons,
New York, 1985. ISBN 0827343132.
Judea Pearl. Causal diagrams for empirical research. Biometrika, 82(4):669-688, 1995.
R Core Team. R: A Language and Environment for Statistical Computing. R Foundation for Statis-
tical Computing, Vienna, Austria, 2018.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and
approximate inference in deep generative models. pp. 1278-1286, 2014.
Thomas S Richardson and James M Robins. Single world intervention graphs (swigs): A unification
of the counterfactual and graphical approaches to causality. Technical report, Center for Statistics
and the Social Sciences, University of Washington, 2013.
Genevieve Robin. mimi: Main Effects and Interactions in Mixed and Incomplete Data, 2019. R
package version 0.2.0.
J. M. Robins, A. Rotnitzky, and L. P. Zhao. Estimation of regression coefficients when some regres-
sors are not always observed. Journal of the American Statistical Association, 89(427):846-866,
1994. doi: 10.1080/01621459.1994.10476818.
Paul R Rosenbaum and Donald B Rubin. The central role of the propensity score in observational
studies for causal effects. Biometrika, 70(1):41-55, 1983. doi: 10.1093/biomet/70.1.41.
Paul R Rosenbaum and Donald B Rubin. Reducing bias in observational studies using subclassifica-
tion on the propensity score. Journal of the American Statistical Association, 79(387):516-524,
1984. doi: 10.2307/2288398.
D. B. Rubin. Estimating causal effects of treatments in randomized and nonrandomized studies.
Journal of Educational Psychology, 66(5):688-701, 1974. doi: 10.1037/h0037350.
D. B. Rubin. Multlipe Imputation for Nonresponse in Surveys. Wiley, Hoboken, NJ, USA, 1987.
ISBN 9780471655740.
Donald B Rubin. Inference and missing data. Biometrika, 63(3):581-592, 1976.
Shaun Seaman and Ian White. Inverse probability weighting with missing predictors of treatment
assignment or missingness. Communications in Statistics-Theory and Methods, 43(16):3499-
3515, 2014. doi: 10.1080/03610926.2012.700371.
11
Under review as a conference paper at ICLR 2020
Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: general-
ization bounds and algorithms. In Proceedings of the 34th International Conference on Machine
Learning-Volume 70,pp. 3076-3085. JMLR. org, 2017.
Julie Tibshirani, Susan Athey, Stefan Wager, Rina Friedberg, Luke Miner, and Marvin Wright. grf:
Generalized Random Forests (Beta), 2018. R package version 0.10.2.
BETH Twala, MC Jones, and David J Hand. Good methods for coping with missing data in decision
trees. Pattern Recognition Letters, 29(7):950-956, 2008.
S. van Buuren. Flexible Imputation of Missing Data. Chapman and Hall/CRC, Boca Raton, FL,
2018.
Stef van Buuren and Karin Groothuis-Oudshoorn. mice: Multivariate imputation by chained equa-
tions in r. Journal of Statistical Software, 45(3):1-67, 2011.
Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using
random forests. Journal of the American Statistical Association, 113(523):1228-1242, 2018.
Shu Yang, Linbo Wang, and Peng Ding. Causal inference with confounders missing not at random.
Biometrika, 2019.
Jinsung Yoon, James Jordon, and Mihaela van der Schaar. Ganite: Estimation of individualized
treatment effects using generative adversarial nets. 2018.
Corwin Matthew Zigler. The central role of bayes theorem for joint estimation of causal effects and
propensity scores. The American Statistician, 70(1):47-54, 2016.
A Appendix
A.1 Deep latent variable models with missing values
Deep latent variable models can be defined as follows. Let (Xi, Zi)i≤n be n i.i.d. random variables
such that
Z Zi 〜P(Zi)
ɪ Xi 〜Pθ(XiIZi)=Φ(X∕fθ(Zi)).
The prior distribution of the latent variables or codes Zi ∈ Rd is often isotropic Gaussian
Zi 〜 N (0d, Id). The function fθ : Rd → H is a (deep) neural network called the decoder and
Φ(∙∣η)η∈H is a parametric observation model, which We take to be multivariate Gaussian. The in-
ference of deep latent variable models can be achieved by maximizing evidence lower bounds of the
likelihood, such as the variational autoencoder bounds.
With missing values, the appropriate quantity to target for inference on θ, when the missing values
mechanism can be ignored (Rubin, 1976; Little & Rubin, 2002), is the observed log-likelihood.
Using Rubin (1976)’s notations, we define Xi = (Xi,obs, Xi,mis) the partition of the data in realized
observed and missing values given a specific realization of the pattern, it can be written as:
n
`(θ) , Xlogpθ (Xi,obs
i=1
n
) = X log
i=1
pθ (Xi,obsIZi)p(Zi)dZi
The corresponding evidence lower bound (ELBO) is:
n
L(θ,γ) ,XEQγ [lnPθ(Xi,obsIZi)] -KL(Qγ(ZiIXi,obs) kPθ(Zi)),
i=1
with KL for the Kullback-Leibler divergence and the variational distribution
Qγ(ZIXobs) ,Ψ(ZIgγ(Xobs)),
With Ψ(∙) the (parametric) variational distribution over Rd. The function gγ : X → K, called the
encoder, is parametrized by a (deep) neural network whose weights are stored in γ ∈ Γ.
12
Under review as a conference paper at ICLR 2020
To take into account missing values in deep latent variable models, Mattei & Frellsen (2019) suggest
the missing data importance weight autoencoder bound (MIWAE) approach. They use a simple
variational family where they impute the missing entries with a constant and show that using this
class of distributions, it maximizes a lower bound of the observed log-likelihood. Specifically, they
replace Qγ with
QY (Z∣Xobs) = Ψ (Z∣gγ (∣ (Xobs)),
where ι is an imputation function chosen beforehand that transforms Xobs into a complete input
vector ι (Xobs) ∈ X.
B S upplementary results
We only report the cases with logistic-linear specification of (e,μo,μι), We therefore use the
logistic-linear doubly robust estimator and omit the prefix loglin in Figures 6 and 7. They show
that when the number of covariates is large the MDC methods accurately recover the true ATE. In
the DLVM case (bottom row), the MDC methods outperform all other compared methods.

1.03
(b) 10% missing values
(c) 30% missing values
(d) 0% missing values
(e) 10% missing values
(f) 30% missing values
Figure 6: Estimated ATE for different amounts of missing values with regression estimation;
p = 100 covariates, n = 1, 000 observations, d = 3 latent confounders, logistic-linear model speci-
fication for (e, μo, μι); top: LRMF; bottom: DLVM.
Additionally, we report results on the effect of changing the sampling parameter B for the MDC.mi
strategy (all other parameters of the VAE are set to the default values). Again, we only report the
cases with logistic-linear specification of (e, μo,μι). These results, in Figure 8, show that for small
number of covariates (in this case, p = 5), the choice of B does not have a large influence on the
final estimate, however for larger number of covariates (e.g., p = 100), increasing B reduces the
bias and the variance.
13
Under review as a conference paper at ICLR 2020
(a) 0% missing values
(b) 10% missing values
(c) 30% missing values
(d) 0% missing values
(e) 10% missing values
(f) 30% missing values
Figure 7: Estimated ATE for different amounts of missing values with doubly robust estimation;
p = 100 covariates, n = 1, 000 observations, d = 3 latent confounders, logistic-linear model speci-
fication for (e, μo, μι); top: LRMF; bottom: DLVM.
num_samples_zmul
50	500
num_sa m ples_zm u I
50	500
(a) Small number of covariates (p = 5)
(b) Large number of covariates (p = 100)
Figure 8: Estimated ATE with MDC.mi + doubly robust estimation for different choices of B;
DLVM setting, n = 1, 000 observations, d = 3 latent confounders, logistic-linear model specifica-
tion for (e, μo, μι).
14