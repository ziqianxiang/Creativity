Under review as a conference paper at ICLR 2020
FAKE CAN BE REAL IN GANS
Anonymous authors
Paper under double-blind review
Ab stract
In order to alleviate the notorious mode collapse phenomenon in generative adver-
sarial networks (GANs), we propose a novel training method of GANs in which
certain fake samples can be reconsidered as real ones during the training pro-
cess. This strategy can reduce the gradient value that generator receives in the
region where gradient exploding happens. We show that the theoretical equilib-
rium between the generators and discriminations actually can be seldom realized
in practice. And this results in an unbalanced generated distribution that deviates
from the target one, when fake datepoints overfit to real ones, which explains the
non-stability of GANs. We also prove that, by penalizing the difference between
discriminator outputs and considering certain fake datapoints as real for adjacent
real and fake sample pairs, gradient exploding can be alleviated. Accordingly, a
modified GAN training method is proposed with a more stable training process
and a better generalization. Experiments on different datasets verify our theoreti-
cal analysis.
1	Introduction
In the past few years, Generative Adversarial Networks (GANs) Goodfellow et al. (2014) have been
one of the most popular topics in generative models and achieved great success in generating diverse
and high-quality images recently (Brock et al. (2019);Karras et al. (2019);Donahue & Simonyan
(2019)). GANs are powerful tools for learning generative models, which can be expressed as a
zero-sum game between two neural networks. The generator network produces samples from the
arbitrary given distribution, while the adversarial discriminator tries to distinguish between real data
and generated data. Meanwhile, the generator network tries to fool the discriminator network by
producing plausible samples which are close to real samples. When a final theoretical equilibrium is
achieved, discriminator can never distinguish between real and fake data. However, we show that a
theoretical equilibrium often can not be achieved with discrete finite samples in datasets during the
training process in practice.
Although GANs have achieved remarkable progress, numerous researchers have tried to improve the
performance of GANs from various aspects (Arjovsky et al. (2017);Nowozin et al. (2016);Gulrajani
et al. (2017); Miyato et al. (2018)) because of the inherent problem in GAN training, such as unsta-
bility and mode collapse. Arora et al. (2017) showed that a theoretical generalization guarantee does
not be provided with the original GAN objective and analyzed the generalization capacity of neural
network distance. The author argued that for a low capacity discriminator, it can not provide gener-
ator enough information to fit the target distribution owing to lack of ability to detect mode collapse.
Thanh-Tung et al. (2019) argued that poor generation capacity in GANs comes from discriminators
trained on discrete finite datasets resulting in overfitting to real data samples and gradient exploding
when generated datapoints approach real ones. As a result, Thanh-Tung et al. (2019) proposed a
zero-centered gradient penalty on linear interpolations between real and fake samples (GAN-0GP-
interpolation) to improve generalization capability and prevent mode collapse resulted from gradient
exploding. Recent work Wu et al. (2019) further studied generalization from a new perspective of
privacy protection.
In this paper, we focus on mode collapse resulted from gradient exploding studied in Thanh-Tung
et al. (2019) and achieve a better generalization with a much more stable training process. Our
contributions are as follows:
1
Under review as a conference paper at ICLR 2020
	Table 1: NOTATIONS
Symbol	Meaning
pr pg dx D D0 Dr = {x1, ∙∙∙ , xn} Dg = {y1, ∙∙∙ , ym} Df = {fl,…，fm} DFAR ⊂ {fl, ∙∙∙ , fm}	the target dsitribution the model distribution the dimensionality of a data sample discriminator with sigmoid function in the last layer discriminator with sigmoid function in the last layer removed the set of n real samples the set of m generated samples the candidate set of M1 generated samples to be selected as real the set of M0 generated samples considered as real
1.	We show that a theoretical equilibrium, when optimal discriminator outputs a constant for
both real and generated data, is unachievable for an empirical discriminator during the
training process. Due to this fact, it is possible that gradient exploding happens when
fake datapoints approach real ones, resulting in an unbalanced generated distribution that
deviates from the target one.
2.	We show that when generated datapoints are very close to real ones in distance, penalizing
the difference between discriminator outputs and considering fake as real can alleviate
gradient exploding to prevent overfitting to certain real datapoints.
3.	We show that when more fake datapoints are moved towards a single real datapoint, gra-
dients of the generator on fake datapoints very close to the real one can not be reduced,
which partly explains the reason of a more serious overfitting phenomenon and an increas-
ingly unbalanced generated distribution.
4.	Based on the zero-centered gradient penalty on data samples (GAN-0GP-sample) proposed
in Mescheder et al. (2018), we propose a novel GAN training method by considering some
fake samples as real ones according to the discriminator outputs in a training batch to
effectively prevent mode collapse. Experiments on synthetic and real world datasets verify
that our method can stabilize the training process and achieve a more faithful generated
distribution.
In the sequel, we use the terminologies of generated samples (datapoints) and fake samples (data-
points) indiscriminately. Tab. 1 lists some key notations used in the rest of the paper.
2	Related works
Unstability. GANs have been considered difficult to train and often play an unstable role in training
process Salimans et al. (2016). Various methods have been proposed to improve the stability of
training. A lot of works stabilized training with well-designed structures (Radford et al. (2015);Kar-
ras et al. (2018); Zhang et al. (2019);Chen et al. (2019)) and utilizing better objectives (Nowozin
et al. (2016);Zhao et al. (2016);Arjovsky et al. (2017);Mao et al. (2017)). Gradient penalty to en-
force Lipschitz continuity is also a popular direction to improve the stability including Gulrajani
et al. (2017),Petzka et al. (2018),Roth et al. (2017),Qi (2017). From the theoretical aspect, Nagara-
jan & Kolter (2017) showed that GAN optimization based on gradient descent is locally stable and
Mescheder et al. (2018) proved local convergence for simplified zero-centered gradient penalties
under suitable assumptions. For a better convergence, a two time-scale update rule (TTUR) (Heusel
et al. (2017)) and exponential moving averaging (EMA) (YazIcI et al. (2θl9)) have also been studied.
Mode collapse. Mode collapse is another persistent essential problem for the training of GANs,
which means lack of diversity in the generated samples. The generator may sometimes fool the
discriminator by producing a very small set of high-probability samples from the data distribution.
Recent work (Arora et al. (2017);Arora et al. (2018)) studied the generalization capacity of GANs
and showed that the model distributions learned by GANs do miss a significant number of modes.
2
Under review as a conference paper at ICLR 2020
A large number of ideas have been proposed to prevent mode collapse. Multiple generators are
applied in Arora et al. (2017),Ghosh et al. (2018),Hoang et al. (2018) to achieve a more faithful
distribution. Mixed samples are considered as the inputs of discriminator in Lin et al. (2018),Lucas
et al. (2018) to convey information on diversity. Recent work He et al. (2019) studied mode collapse
from probabilistic treatment and Yamaguchi & Koyama (2019) from entropy of distribution.
3	Background
In the original GAN Goodfellow et al. (2014), the discriminator D maximizes the following objec-
tive:
L = Ex〜pr[log(D(x))] + Ey〜pg[log(1 - D(y))]∙	(1)
The logistic sigmoid function σ(x)=阡匕 is usually used in practice, leading to
L = Ex〜pr[log(σ(Do(x)))]+ Ey〜pg[log(1 - σ(Do(y)))],	(2)
and to prevent gradient collapse, the generator G maximizes
LG = Ey〜Pg [log(σ(Do(y)))],	(3)
where D0 is usually represented by a neural network. Goodfellow et al. (2014) showed that the
optimal discriminator D in Eqn.1 is D*(v) = P (Vr，；) (V) for any V ∈ SUpp(Pr) ∪ SUpp(Pg). As
the training progresses, pg will be pushed closer to pr. IfG andD are given enough capacity, a global
equilibrium is reached when pr = pg, in which case the best strategy for D on SUpp(pr) ∪ SUpp(pg)
is just to output 2 and the optimal value for Eqn.1 is 2log( 2).
With finite training examples in training dataset Dr in practice, an empirical version is applied
to approximate Eqn.1, using n1 Pn=ι log(D(xi)) to estimate Ex〜p,[log(D(x))] and m Pm=I[1 -
log(D(yi))] to estimate Ey〜Pg [log(1 - D(y))], where Xi is from the set Dr of n real samples and
yi is from the set Dg of m generated samples, respectively.
Mode collapse in the generator is attributed to gradient exploding in discriminator, according to
Thanh-Tung et al. (2019). When a fake datapoint y0 is pushed to a real datapoint x0 and if |D(x0) -
D(y0)| ≥ e, is satisfied, the absolute value of directional derivative of D in the direction μ =
x0 - y0 will approach infinity leading to gradient exploding:
g D)xo∣=y0¾0 τO⅛0F
≥ lim N------------N = ∞.
yo→→xo ||x0 - y0||
(4)

Since the gradient VyoD(y0) at yo outweights gradients towards other modes in a mini-batch,
gradient exploding at datapoint y0 will move multiple fake datapoints towards x0 resulting in mode
collapse.
4	Optimal discriminator in empirical version
4.1	Optimal discriminator empirically does not have a theoretical
EQUILIBRIUM
Theoretically discriminator outputs a constant ɪ when a global equilibrium is reached. However in
practice, discriminator can often easily distinguish between real samples and fake samples (Good-
fellow et al. (2014);Arjovsky et al. (2017)), making a theoretical equilibrium unachievable. Because
the distribution pr of real data is unknown for discriminator, discriminator will always consider dat-
apoints in the set Dr of real samples as real while Dg of generated samples as fake. Even when
generated distribution pg is equivalent to the target distribution pr , Dr and Dg is disjoint with prob-
ability 1 when they are sampled from two continuous distributions respectively (proposition 1 in
Thanh-Tung et al. (2019)). In this case, actually pg is pushed towards samples in Dr instead of the
target distribution. However, we show next because of the fact of an unachievable theoretical equi-
librium for empirical discriminator during the training process, an unbalanced distribution would be
generated that deviates from the target distribution.
3
Under review as a conference paper at ICLR 2020
(a)	(b)	(c)	(d)
(e)	(f)	(g)	(h)
Figure 1: Results on finite samples from a Gaussian distribution of GANs trained with different gra-
dient penalties and our method. (blue datapoints represent real samples and red datapoints represent
generated samples) (a).(e) GAN with no GP, iter. 100,000 and 200,000. (b).(f) GAN-0Gp-sample,
iter. 100,000 and 200,000. (c).(g) GAN-0Gp-interpolation, iter. 100,000 and 200,000. (d).(h) GAN-
0Gp-sample with our method, iter. 100,000 and 200,000.
Proposition 1. For empirical discriminator in original GAN, unless pg is a discrete uniform distri-
bution on Dr, the optimal discriminator D output on Dr and Dg is not a constant 1, since there
exists a more optimal discriminator which can be constructed as a MLP with O(2dx) parameters.
See Appendix A for the detailed proof. If all the samples in Dr can be remembered by discriminator
and generator, and only if generated samples can cover Dr uniformly, which means Dg = Dr ,
a theoretical equilibrium in discriminator can be achieved. However, before generator covers all
the samples in Dr uniformly during the training process, the fact of an unachievable theoretical
equilibrium makes it possible that there exists a real datapoint x0 with a higher discriminator output
than that of a generated datapoint y0 . When y0 approaches x0 very closely, gradient exploding
and overfitting to a single datapoint happen, resulting an unbalanced distribution and visible mode
collapse. See the generated results on a Gaussian dataset of original GAN in Fig. 1a and 1e. The
generated distribution neither covers the target Gaussian distribution nor fits all the real samples in
Dr, making an unbalanced distribution visible. Furthermore, in practice discriminator and generator
are represented by a neural network with finite capacity and dataset Dr is relatively huge, generator
can never memorize every discrete sample resulting in a theoretical equilibrium unachievable. In
the following subsections, we are interested in the way of stabilizing the output of discriminator to
alleviate gradient exploding to achieve a more faithful generated distribution.
4.2	Penalizing the difference between discriminator outputs on close real
AND FAKE PAIRS
Let’s first consider a simplified scenario where a fake datapoint y0 is close to a real datapoint x0 .
Generator updates y0 according to the gradient that the generator receives from the discriminator
with respect to the fake datapoint y0, which can be computed as:
Vyo Lg®0 )
∂ lθg(σ(D0(y0)))
∂D0(y0)
Vyo D0(y0)
Vyo D0 (yo)
1 + eDo(yO)
(5)
When y0 approaches x0 very closely and a theoretical discriminator equilibrium is not achieved
here, namely D0(x0) — D0(y0) ≥ e, the absolute value of directional derivative (VμD0)yo in the
direction μ = xo 一 yo at yo tends to explode and will outweigh directional derivatives in other
4
Under review as a conference paper at ICLR 2020
Table 2: Changes of different optimal values with variables discussed in Section 4. (% means
increasing and & means decreasing)
	Do output on real 荀	Do output on fake e*	荀Y	gradient value V
ko /		&		/	一	&	&
mo %	&	&	/	/	一
Po %	/	一	/	一	&		&	
directions. Hence, the gradient VyoD0(y0) is equivalent to directional derivative (VμD0)y0 here.
When y0 is very close to x0, the norm of the gradient generator receives from the discriminator
with respect to y0 can be computed as:
||Vy0LG(y0)|| ≈
∣D0(x0) — Do(yo)∣
(1 + eD0(yO))||xo - yo||
(6)
If y0 is in the neighborhood of x0, i.e., y0 ∈ Nδ(x0) = {y0 : d(x0, y0) ≤ δ, δ > 0}, where δ
is a small positive value, we call {x0 , y0 } a close real and fake pair. We are interested in reducing
the approximated value of the gradient for a fixed pair {x0, y0} to prevent multiple fake datapoints
overfitting to a single real one. Note that the output of D0 for real datapoint x0 has a larger value
than that of fake datapoint y0. So for a fixed pair {x0, y0}, when D0(y0) increases and D0(x0) -
D0(y0) decreases, the target value decreases. And, when D0(y0) decreases and D0(x0) - D0(y0)
increases, the target value increases, according to Eqn. 6.
Now we consider a more general scenario where for a real datapoint x0, in a set of n real sam-
ples, there are mo generated datapoints {yι, y2,…,ym。} very close to xo in the set of m
generated samples. We are specially interested in the optimal discriminator output at x0 and
{yι, y2,…,ymo}. For simplicity, We make the assumption that discriminator outputs at these
interested points are not affected by other datapoints in Dr and Dg . We also assume discriminator
has enough capacity to achieve optimum in this local region.
HoWever, Without any constraint, discriminator Will consistently enlarge the gap betWeen outputs
for real datapoints and that for generated ones. Thus, an extra constraint is needed to alleviate the
difference betWeen discriminator outputs on real and fake datapoints. It comes naturally to penalize
the L2 norm of D0(x0) - D0(yi). Denoting the discriminator output for x0, D0(x0) as ξ0 and
Do(yi) as ξi, i = 1,…,mo, we have the following empirical discriminator objective:
1n
L =	-(log σ(ξo) + Vlog σ(Do(xi)))
n	i=2
m0	m
+ m(Xlog(1-σ(ξi))+ X log(1 - σ(Do(yi))))
—
i=1
m0
包X
mo
i=1
i=m0 +1
—
C1+n f (ξ0,ξ0,…，ξmo),
where the interested term f (ξo,ξι,…，ξm0) is
n m0	nk m0
f (ξ0, ξ1,…，ξmo ) = log σ(ξ0) + m ^X log(1 - σ(Si)) - ^m- ^X(ξ0 - ξi) ∙
i=1	o i=1
(7)
(8)
Proposition 2. Assume {ξ∩, •…，ξm0} is an optimizer that achieves the maximum value of
f (ξo,ξι, ∙∙∙	,ξmo).	Then with	ko	increasing,	ξ∩	decreases,	ξi	increases and ξ∩	一	ξi	decreases,
and, with mo increasing, ξ0 decreases, ξi decreases and ξɪ — ξ* increases, where i = 1,…，mo.
Proof. See Appendix B.
□
Based on Proposition 2, penalizing the difference between discriminator outputs on close real and
fake pairs {x0, yi} can reduce the norm ofVyiLG(yi) from Eqn.6, making it possible to move fake
5
Under review as a conference paper at ICLR 2020
datapoints to other real datapoints instead of only being trapped at x0. However in practice, it is hard
to find the close real and fake pairs to penalize the corresponding difference between discriminator
outputs. If we directly penalize the L2 norm of D0 (xi) - D0 (yi) when {xi , yi } are not a pair of
close datapoints, ∣UiLG(yi)∖∖ for y$ may even get larger. Consider Do(yi) has a higher value
than D0(xi), which could happen when xi has more corresponding close fake datapoints than the
real datapoint xyi corresponding to yi from Proposition 2. Direct penalization will make D0 (yi)
lower, then Do(xyJ - Do(yi) gets higher and ∖∖VyiLG(yi)∖∖ higher. Thus in practice We could
enforce a zero-centered gradient penalty of the form ∖∖(VD°)v ∖∖2 to stabilize discriminator output,
where v can be real datapoints or fake datapoints. Although Thanh-Tung et al. (2019) thought that
discriminator can have zero gradient on the training dataset and may still have gradient exploding
outside the training dataset, we believe a zero-centered gradient penalty can make it harder for
discriminator to distinguish between real and fake datapoints and fill the gap between discriminator
outputs on close real and fake pairs to prevent overfitting to some extent. Fig. 1b and 1f alleviate
overfitting phenomenon compared with no gradient penalty in Fig. 1a and 1e.
Thanh-Tung et al. (2019) proposed another zero-centered gradient penalty of the form ∖∖(VD0)v∖∖2,
where v is a linear interpolation between real and fake datapoints, to prevent gradient exploding.
However, we consider it’s not a very efficient method to fill the gap between discriminator outputs
on close real and fake pairs. To begin with, the results of direct linear interpolation between real
and fake datapoints may not lie in supp(pr) ∪ supp(pg). Although the author also considered the
interpolation on latent codes, it needs an extra encoder which increases operational complexity.
Furthermore, for arbitrary pair of real and fake datapoints, the probability that linear interpolation
between them lie where gradient exploding happens is close to 0, because large gradient happens
when a fake datapoint approaches closely a real datapoint, resulting in the gap between discriminator
outputs on close real and fake pairs hard to fill.
Based on Proposition 2, we also find that when more fake datapoints are moved to the corresponding
real datapoint, ∖∖VyiLG(yi)∖∖ for a fake datpoint yi only to increase from Eqn.6. It means with the
training process going on, more fake datapoints tend to be attracted to one single real datapoint and
it gets easier to attract much more fake datapoints to the real one. It partly explains the unstability
of GAN training process that especially during the later stage of training, similar generated samples
are seen. Compared with Fig. 1a, 1b and 1c at iter.100,000, Fig. 1e, 1f and 1g at iter.200,000 have a
worse generalization and much more similar samples are generated with the training process going
on.
4.3	Considering fake as real on close real and fake pairs
In this subsection, we aim to make ∖∖VyiLG(yi)∖∖, i = 1, ∙∙∙ ,m° smaller for optimal empirical
discriminator by considering some fake as real on close real and fake pairs based on the above
discussions. Suppose for each fake datapoint, it’s considered as real datapoint with probability p0
when training real datapoints, resulting in the following empirical discriminator objective:
m0	n
L = n (log σ(ξo) + E[A X log σ(ξi)] + X log σ(Do(xi)))
i=1	i=2
m0	m
+ m(Xlog(1-σ(ξi))+ X log(1 - σ(Do(yi))))
i=1	i=m0 +1
C2 + nh(ξ0,ξ0,∙∙∙ ,ξmo),
(9)
where A is a binary random variable taking values in {0, 1} with Pr(A = 1) = p0 and the interested
term h(ξ0,ξ1,…，ξm0) is
m0	m0	m0
h(ξ0, ξ1,…，ξmo )	= log σ(ξ0)+p0 X log σ(Si)+----X IOg(I-σ(Si))-------- ^X(ξ0-ξi)2 ∙	* (IO)
i=1	m i=1	m0 i=1
6
Under review as a conference paper at ICLR 2020
Proposition 3. Assume {ξg,…，ξm。} is an optimizer that achieves the maximum value of
h(ξ0,ξ1,…,ξmo)∙ Then with Po increasing, ξ力 increases, ξ* increases and ξ力 一 ξ decreases,
where i = 1, •…，mo.
Proof. See Appendix C.	□
Note that only penalizing the difference between discriminator outputs on close real and fake pairs
in Subsection 4.2 is just a special case of considering fake as real here when po = 0. Based on
Proposition 3, considering fake datapoints as real with increasing probability po for real datapoints
training part can reduce the norm of NyiLg(yi) from Eqn.6. It means when We consider more
fake as real where large gradient happens for real training part, the attraction to the real datapoint
for fake ones can be alleviate to make it easier to be moved to other real datapoints and prevent
the overfitting to one single real datapoint. Note that for a fixed po , when the number mo of fake
datapoints very close to the real one increases, more fake datapoints will be considered as real to
alleviate the influences of increasing mo discussed in Subsection 4.2.
5	Method
To overcome the problem of overfitting to some single datapoints and achieve a better generaliza-
tion, we propose that fake samples generated by generator in real time can be trained as real samples
in discriminator. For original N real samples in a training batch in training process, we substitute
them with No real samples in Dr and Mo generated samples in Dg, where N = No + Mo . Our
approach is mainly aimed at preventing large gradient in the region where many generated samples
overfit one single real sample. To find generated samples in these regions, we choose the generated
ones with low discriminator output, owing to the reason that discriminator tends to have a lower
output for the region with more generated datapoints approaching one real datapoint from Proposi-
tion 2. Therefore, we choose needed Mo generated samples denoted as set DFAR as real samples
from a larger generated set Df containing Mi generated samples {fι, f2,…，/mJ according to
corresponding discriminator output:
DFAR = {fi},i ∈ index of top Mo in{-D0(f1), -Do(f2),…，一Dofmi)}.	(11)
We also add a zero-centered gradient penalty on real datapoints Mescheder et al. (2018) based on
the discussions in Subsection 4.2, resulting in the following empirical discriminator objective in a
batch containing N real samples and M fake samples:
1 N0	M0
CFAR = NF[X log(σ(Do(xi))) + X log(σ(Do(fi)))]
N i=1	i=1
1M	λN
+ M X IOg(I- σ(DOwi)) + N X ll(VDo)Ci ||2,	(12)
M i=1	N i=1
where xi ∈ Dr,fi ∈ DFAR, yi ∈ Dg and ci ∈ Dr ∪ DFAR. In practice, we usually let N = M.
Because some fake datapoints are trained as real ones, the zero-centered gradient penalty are actually
enforced on the mixture of real and fake datapoints.
When we sample more generated datapoints for Df to decide the needed Mo datapoints as real, the
probability of finding the overfitting region with large gradient is higher. When more fake datapoints
in DFAR that are close to corresponding real ones are considered as real for training, itis equivalent
to increase the value ofpo in Subsection 4.3. For a larger DFAR, the number of real samples No will
decrease for a fixed batchsize N and the speed to cover real ones may be slowed at the beginning of
training owning to the reason that some fake datapoints are considered as real and discriminator will
be not so confident to give fake ones a large gradient to move them to real ones. Our method can
stabilize discriminator output and prevent mode collapse caused by gradient exploding efficiently
based on our theoretical analysis. A more faithful generated distribution will be achieved in practice.
7
Under review as a conference paper at ICLR 2020
6	Experiments
6.1	Synthetic data
To test the effectiveness of our method in preventing an unbalanced distribution resulted from over-
fitting to only some real datapoints, we designed a dataset with finite real samples coming from
a Gaussian distributions and trained MLP based GANs with different gradient penalties and our
method on that dataset. For gradient penalties in all GANs, the weight λ is set 10. Training batch
is set 64 and one quarter of the real training batch are generated samples picked from 256 generated
samples according to discriminator output, namely M0 = 16 and M1 = 256 in Eqn. 11. Learning
rate is set 0.003 for both G and D. The result is shown in Fig.1. It can be observed that original
GAN, GAN-0GP-sample and GAN-0GP-interpolation all have serious overfitting problem leading
to a biased generated distribution with training process going on, while our method can generate
much better samples with good generalization.
We also test our method on a mixture of 8 Gaussians dataset where random samples in different
modes are far from each other. The evolution of our method is depicted in Fig.2. We observe that
although our method only covers 3 modes at the beginning, it can cover other modes gradually
because our method alleviates the gradient exploding on close real and fake datapoints. It is possible
that fake datapoints are moved to other Gaussian modes when the attraction to other modes is larger
than to the overfitted datapoints. Hence, our method has the ability to find the uncovered modes to
achieve a faithful distribution even when samples in high dimensional space are far from each other.
More synthetic experiments can be found in Appendix D.
(a)	(b)	(c)	(d)
Figure 2: Evolution of our method on a mixture of 8 Gaussians dataset. (a) iter. 0. (b) iter. 100,000.
(c) iter. 335,000. (d) iter. 500,000.
Figure 3: Inception score and FID on CIFAR-10 of GAN-0GP-sample and GAN-0GP-sample with
our method
6.2	Real world data
To test our method on real world data, we compare our method with GAN-0GP-sample on CIFAR-10
(Antonio et al. (2008)), CIFAR-100 (Antonio et al. (2008)) and a more challenging dataset ImageNet
(Russakovsky et al. (2015)) with ResNet-architectures similar with that in Mescheder et al. (2018).
Inception score (Salimans et al. (2016)) and FID (Heusel et al. (2017)) are used as quantitative
8
Under review as a conference paper at ICLR 2020
Figure 4: Inception score and FID on CIFAR-100 of GAN-0GP-sample and GAN-0GP-sample with
our method
(a)
Figure 5: Losses of discriminator (not including regularization term) and generator on CIFAR-10
of GAN-0GP-sample and GAN-0GP-sample with our method
(b)
measures. For Inception score, we follow the guideline from Salimans et al. (2016). The FID
score is evaluated on 10k generated images and statistics of data are calculated at the same scale of
generation. Better generation can be achieved with higher inception score and lower FID value. The
maximum number of iterations for CIFAR experiment is 500k, while for ImageNet is 600k because
of training difficulty with much more modes.We use the code from Mescheder et al. (2018).
The weight λ for gradient penalty is also set 10. Training batch is set 64 and for a better gradient
alleviation on close real and fake datapoints, half of the real training batch are generated samples
with M0 = 32 and M1 = 256 in Eqn. 11. For CIFAR experiments, we use the RMSProp optimizer
with α = 0.99 and a learning rate of 10-4. For ImageNet experiments, we use the Adam optimizer
with α = 0, β = 0.9 and TTUR with learning rates of 10-4 and 3 × 10-4 for the generator
and discriminator respectively. We use an exponential moving average with decay 0.999 over the
weights to produce the final model.
6.2.1	CIFAR-10 AND CIFAR-100
The results on Inception score and FID are shown in Fig. 3 and 4. Our method outperforms GAN-
0GP-sample by a large margin. As predicted in Section 5, the speed of our method to cover real
ones could be slowed at the beginning of training with some fake considered as real. However, our
method can cover more modes and have a much better balanced generation than the baseline.
The losses of discriminator and generator during the process of CIFAR-10 training are shown in
Fig.5. It can be observed that our method has a much more stable training process. Owing to
the overfitting to some single datapoints and an unbalanced generated distribution missing modes,
the losses of discriminator and generator for GAN-0GP-sample gradually deviate from the optimal
theoretical value, namely 2 log 2 ≈ 1.386 for discriminator and log 2 ≈ 0.693 for generator respec-
tively. However, our method has a much more stable output of discriminator to achieve the losses
for discriminator and generator very close to theoretical case. It proves practically that our method
can stabilize discriminator output on close real and fake datapoints to prevent more datapoints from
9
Under review as a conference paper at ICLR 2020
Figure 6: Inception score and FID on ImageNet of GAN-0GP-sample and GAN-0GP-sample with
our method
trapped in a local region and has a better generalization. The losses of discriminator and generator
on CIFAR-100 and image samples can be found in Appendix D.
6.2.2	ImageNet
For the challenging ImageNet task, we train GANs to learn a generative model of all 1000 classes
at resolution 64 × 64 with the limitation of our hardware. However, our models are completely
unsupervised learning models with no labels used instead of another 256 dimensions being used in
latent code z as labels in Mescheder et al. (2018).
The results in Fig. 6 show that our methods still outperforms GAN-0GP-sample on ImageNet. Our
method can produce samples of state of the art quality without using any category labels and stabilize
the training process. Random selected samples and losses of discriminator and generator during the
training process can be found in Appendix D.
7	Conclusion
In this paper, we explain the reason that an unbalanced distribution is often generated in GANs
training. We show that a theoretical equilibrium for empirical discriminator is unachievable during
the training process. We analyze the affection on the gradient that generator receives from discrim-
inator with respect to restriction on difference between discriminator outputs on close real and fake
pairs and trick of considering fake as real. Based on the theoretical analysis, we propose a novel
GAN training method by considering some fake samples as real ones according to the discriminator
outputs in a training batch. Experiments on diverse datasets verify that our method can stabilize the
training process and improve the performance by a large margin.
References
Torralba Antonio, Fergus Rob, and William T Freeman. 80 million tiny images: a large data set for
nonparametric object and scene recognition. IEEE TransaCtions on Pattern Analysis and MaChine
Intelligence, 30(11):1958-1970, 2008.
Martin Arjovsky, SoUmith Chintala, and Leon Bottou. Wasserstein generative adversarial networks.
In Doina Precup and Yee Whye Teh (eds.), ProCeedings of the 34th International ConferenCe
on MaChine Learning, volume 70 of PrOCeedings of MaChine Learning Research, pp. 214-223,
International Convention Centre, Sydney, Australia, 06-11 Aug 2017. PMLR.
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium
in generative adversarial nets (gans). In ICML, pp. 224-232, 2017.
Sanjeev Arora, Andrej Risteski, and Yi Zhang. Do GANs learn the distribution? some theory and
empirics. In InternatiOnal COnferenCe on Learning RePresentations, 2018.
Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity
natural image synthesis. In InternatiOnal COnferenCe on Learning RePresentations, 2019.
10
Under review as a conference paper at ICLR 2020
Ting Chen, Mario Lucic, Neil Houlsby, and Sylvain Gelly. On self modulation for generative adver-
sarial networks. In International Conference on Learning Representations, 2019.
Jeff Donahue and Karen Simonyan. Large scale adversarial representation learning. arXiv preprint
arXiv:1907.02544, 2019.
Arnab Ghosh, Viveka Kulharia, Vinay P Namboodiri, Philip HS Torr, and Puneet K Dokania.
Multi-agent diverse generative adversarial networks. In Proceedings of the IEEE Conference
on CompUter ViSion and Pattern Recognition, pp. 8513-8521, 2018.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In AdVanceS in neural
information processing systems, pp. 2672-2680, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Im-
proved training of wasserstein gans. In AdVanceS in neural information processing systems, pp.
5767-5777, 2017.
Hao He, Hao Wang, Guang-He Lee, and Yonglong Tian. Bayesian modelling and monte carlo
inference for GAN. In International COnference on Learning RepreSentations, 2019.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium. In AdVanceS
in NeuraI InfOrmatiOn PrOceSSing Systems, pp. 6626-6637, 2017.
Quan Hoang, Tu Dinh Nguyen, Trung Le, and Dinh Phung. MGAN: Training generative adversarial
nets with multiple generators. In International COnference on Learning RepreSentations, 2018.
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs for im-
proved quality, stability, and variation. In International COnference on Learning RepreSentations,
2018.
Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative
adversarial networks. In PrOceedingS of the IEEE COnference on COmpUter ViSiOn and Pattern
Recognition, pp. 44014410, 2019.
Zinan Lin, Ashish Khetan, Giulia C. Fanti, and Sewoong Oh. Pacgan: The power of two samples in
generative adversarial networks. In NeUrIPS, pp. 1505-1514, 2018.
Thomas Lucas, Corentin Tallec, Yann Ollivier, and Jakob Verbeek. Mixed batches and symmetric
discriminators for gan training. In ICML, pp. 2850-2859, 2018.
Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smol-
ley. Least squares generative adversarial networks. In PrOceedingS of the IEEE International
COnference on COmpUter ViSion, pp. 2794-2802, 2017.
Lars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for GANs do ac-
tually converge? In Jennifer Dy and Andreas Krause (eds.), PrOceedingS of the 35th International
COnference on Machine Learning, volume 80 of PrOceedingS OfMachine Learning ReSearch, pp.
3481-3490, Stockholmsmssan, Stockholm Sweden, 10-15 Jul 2018. PMLR.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for
generative adversarial networks. In International COnference on Learning RepreSentations, 2018.
Vaishnavh Nagarajan and J Zico Kolter. Gradient descent gan optimization is locally stable. In
AdVanceS in NeuraI InfOrmatiOn PrOceSSing Systems, pp. 5585-5595, 2017.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. In AdVanceS in neural information processing systems,
pp. 271-279, 2016.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. 2017.
11
Under review as a conference paper at ICLR 2020
Henning Petzka, Asja Fischer, and Denis Lukovnikov. On the regularization of wasserstein GANs.
In Intemational Conference on Learning Representations, 2018.
GUo-JUn Qi. Loss-sensitive generative adversarial networks on IiPschitz densities. arXiv preprint
arXiv:1701.06264, 2017.
Alec Radford, LUke Metz, and SoUmith Chintala. UnsUpervised representation learning with deep
convolutional generative adversarial networks. arXiv Preprint arXiv:1511.06434, 2015.
Kevin Roth, AUrelien LUcchi, Sebastian Nowozin, and Thomas Hofmann. Stabilizing training
of generative adversarial networks through regularization. In AdVances in neural information
processing systems, pp. 2018-2028, 2017.
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng
Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visu-
al recognition challenge. International joUrnal of computer vision, 115(3):211-252, 2015.
Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. In NIPS, pp. 2226-2234, 2016.
Hoang Thanh-Tung, Truyen Tran, and Svetha Venkatesh. Improving generalization and stability of
generative adversarial networks. In International Conference on Learning Representations, 2019.
Bingzhe Wu, Shiwan Zhao, Haoyang Xu, ChaoChao Chen, Li Wang, Xiaolu Zhang, Guangyu Sun,
and Jun Zhou. Generalization in generative adversarial networks: A novel perspective from pri-
vacy protection. arXiv Preprint arXiv:1908.07882, 2019.
Shoichiro Yamaguchi and Masanori Koyama. DISTRIBUTIONAL CONCAVITY REGULARIZA-
TION FOR GANS. In International Conference on Learning Representations, 2019.
Yasin Yazici, Chuan-Sheng Foo, Stefan Winkler, Kim-Hui Yap, Georgios Piliouras, and Vijay Chan-
drasekhar. The unusual effectiveness of averaging in GAN training. In International Conference
on Learning Representations, 2019.
Han Zhang, Ian J. Goodfellow, Dimitris N. Metaxas, and Augustus Odena. Self-attention generative
adversarial networks. In ICML, pp. 7354-7363, 2019.
Junbo Zhao, Michael Mathieu, and Yann LeCun. Energy-based generative adversarial network.
arXiv Preprint arXiv:1609.03126, 2016.
A	Proof for proposition 1
For empirical discriminator, it maximizes the following objective:
L = Ex∈Dr [log(D(x))] + Ey∈Dg [log(1 - D(y))].	(13)
When pg is a discrete uniform distribution on Dr , and generated samples in Dg are the same with
real samples in Dr. It is obvious that the discriminator outputs 1 to achieve the optimal value when
it cannot distinguish fake samples from real ones.
For continues distribution pg, Thanh-Tung et al. (2019) has proved that an -optimal discriminator
can be constructed as a one hidden layer MLP with O(dx(m + n)) parameters, namely D(x) ≥
2 + 2, ∀x ∈ Dr and D(y) ≤ 1 - j, ∀y ∈ Dg, where Dr and Dg are disjoint with probability 1. In
this case, discriminator objective has a larger value than the theoretical optimal version:
L ≥ Eχ∈Dr [log(2 + 2)] + Ey∈Dg [log(2 + 2)]
=2log(2 + 2) > 2log1.	(14)
So the optimal discriminator output on Dr and Dg is not a constant 2 in this case.
12
Under review as a conference paper at ICLR 2020
Even discriminator has much less parameters than O(dx (m + n)), there exists a real datapoint
x0 and a generated datapoint y0 satisfying D(x0) ≥ 2 + f and D(yo) ≤ 2 - j. Whether Pg
is a discrete distribution only cover part samples in Dr or a continues distribution, there exists a
generated datapoint y0 satisfying y0 6∈ Dr . Assume that samples are normalized:
||xi|| = ||yi|| = 1, ∀x ∈ Dr, y ∈ Dg.	(15)
Let W1 ∈ R2×dx , W2 ∈ R2×2 and W3 ∈ R2 be the weight matrices, b ∈ R2 offset vector and
k1,k2 a constant, We can construct needed discriminator as aMLP with two hidden layer containing
O(2dx) parameters. We set weight matrices
W1
T0T0
xy
, W2
1	-1
-1	1
, W3
1
1
.2
For any input v ∈ Dr ∪ Dg , the discriminator output is computed as:
D(v) = W3Tσ(k2W2σ(k1(W1v - b))),
where σ(x) = ιψ∣-X is the sigmoid function. Let a = Wιv - b, We have
α1
1 -	b1,	if v	=	x0 α	=	1 -	b2, if v	=	y0
l -	b1,	ifv	6=	x0	, α2 l -	b2, ifv	6=	y0
where l < 1. Let β = σ(k1α), we have
β1 =	1,ifv=x0 β2= 0,ifv 6=x0 ,β2=	1,ifv = y0 0, if v 6= y0
as k1 → ∞ and b → 1- . Let γ = f1,	σ(k2W2β), we have if v = x0	(0,	if v = xo
I 0,	if v = y0 0 , γ2 =	f 1,	ifv = y0
γ1=i -,	if v 6= x0 , y0	[-,if V = X0, yo
as k2 → ∞. Hence, for any input v ∈ Dr ∪ Dg , discriminator outputs
1 ɪ e
K + o,if V = x0
(16)
D(v) = W3Tγ =
-2 H v = yo .
2	,else
(17)
(18)
(19)
(20)
(21)
1
2
+
-2-2
In this case, discriminator objective also has a more optimal value than the theoretical optimal ver-
sion:
L = -(.(.n - 1)log1 + log(1 + I)) + ɪ((m - I)Iog 1+lOg(I + I))
n	2	22 m	2	22
> 2log-.	(22)
So the optimal discriminator output on Dr and Dg is also not a constant 1 in this case.
B Proof for proposition 2
We rewrite f (ξo, ξι,…,ξm0) here
m0	m0
f (ξ0, ξ1,…，ξmo ) = log σ(ξ0) + m X log(1 - σ(ξi)) - m^ X(ξ0 - ξi)2.	(23)
i=1	0 i=1
13
Under review as a conference paper at ICLR 2020
To achieve the optimal value, let f0(ξi) = 0,i = 0,…，m° and We have
f0(ξο)	2nkο 3 =1 - σ(ξο)	> (ξο - ξi) = mο i=1	0,	(24)
f0(ξi)	n	2nkο =—σ(ξi) +	(ξ0 - ξi) = 0,	i = 1, ∙∙∙ ,mο.	(25)
	m	mο		
It is obvious that ξ1 = ξ2	=…=ξm0 = ξ. Hence We have		
	1 - σ(ξο) - 2nkο(ξο - ξ) = 0,		(26)
	n	2nkο 	σ(ξ) +	(ξο - ξ) = 0.		(27)
	m	mο		
We can solve	ξ = -ln(nm0(1 + eξ0) - 1). m		
			(28)
Substitute Eqn. 28 into Eq	n. 26 and we get		
f0(ξο)	=τ⅛ - 2nkο(ξο +ln('nm(1 + ・ 1 + eξ0	m	eξ0) - 1)) = 0.	(29)
We can also have from Eqn. 28 and Eqn. 26 respectively			
	ξο-ξ = ξο + ln( nm0 (1 + eξ0) m	- 1),	(30)
2nk0(1 + eξ0) .
Note that there must exist an optimal ξο satisfying f0(ξο) = 0 in Eqn. 29, so ξο + ln(nmm0 (1 +
eξ0) - 1) > 0 and f0(ξ0) in Eqn. 29 decreases With k0 increasing. Also considering that f0(ξ0) is a
monotonically decreasing function on ξο, ξ0 decreases with kο increasing. From Eqn. 28 and Eqn.
30, we know ξ* increases and ξ0 - ξ* decreases with kο increasing. Similarly, note that f (ξο) in
Eqn. 29 decreases with m0 increasing and f0(ξ0) is a monotonically decreasing function on ξ0, we
have that ξο decreases with mο increasing. From Eqn. 31, we further know that ξ* decreases and
ξο - ξ* increases with m° increasing.
C Proof for proposition 3
We rewrite h(ξο, ξι,…，ξm0) here
m0	m0	m0
h(ξο,ξι,…，ξmο) = logσ(ξο)+pο X log σ(ξi)+-X log(1-σ(ξi))— - X(ξο-ξi)2. (32)
i=1	m i=1	mο i=1
Let f(ξi) =0,i = 0,…，mο and we have ξι = ξ = …=ξm0 = ξ,			
1 - σ(ξο) - 2nkο(ξο - ξ)	= 0,		(33)
n	2nkο PO(I - σ(ξο))	σ(ξ) +	(ξο - ξ) m	mο	= 0.		(34)
We can solve nm0 (1 + eξ0) - 1 ξ = - ln m ' :__⅛-. 1 + pο(1 + eξ0 )			(35)
Substitute Eqn. 35 into Eqn. 33 and we get			
PO = -ɪ-[e2nk0ξ0 -⅛ (nm0 (1 + eξ0) - 1) 1 + eξ0	m	nk0 - 1] =	g(ξο).	(36)
The derivative of g(ξο ) with respect to ξο is computed as			
(1 + eξ0)2g0(ξο) = [e2nk0ξ0-1+⅛0(2nkο + (1^ξ0)2 )(	nmO(1 + eξ0) - 1)2nk0 m		
+e2nk0ξ0-1+⅛ 2nkο( 2 (1 + e&) m	- 1)2nk0 -1	nm0 eξ0 ]	1 m	1 + eξ0	
+ [e2nk0ξ0- 1+eξ0(nm0(1 + eξ0) - 1)2nk0 - 1]「.	(37)
m	(1 + eξ0 )2
14
Under review as a conference paper at ICLR 2020
Because
nm0 (1 + eξ0) — 1 = e-ξ + (1 + eξ0 )p0e-ξ > 0
(38)
and
τ+g [e2nk0ξ0- 1+eξ0 (nm0(1 + eξ0) - 1)2nk0 - 1] = p0 ≥ 0,
g0(ξ0 ) > 0. Hence ξ0* increases with p0 increasing. From Eqn. 33, we also have
1
(39)
ξ0 - ξ =
2nk0(1 + eξ0) .
(40)
We further know that ξ* increases and ξθ - ξ* decreases with p0 increasing.
D Further results
Figure 7: Losses of discriminator (not including regularization term) and generator on CIFAR-100
of GAN-0GP-sample and GAN-0GP-sample with our method
(b)
Figure 8: Losses of discriminator (not including regularization term) and generator on ImageNet of
GAN-0GP-sample and GAN-0GP-sample with our method
(a)
(b)
Figure 9: Generation of our method on a mixture of 25 Gaussians dataset and swissroll datatset.
15
Under review as a conference paper at ICLR 2020
(a) image generation of GAN-0GP-sample (b) image generation of GAN-0GP-sample with our
method
Figure 10:	Image generation of CIFAR-10.
(a) image generation of GAN-0GP-sample (b) image generation of GAN-0GP-sample with our
method
Figure 11:	Image generation of CIFAR-100.
16
Under review as a conference paper at ICLR 2020
(a) image generation of GAN-0GP-sample
(b) image generation of GAN-0GP-sample with our method
Figure 12: Image generation of ImageNet.
17
Under review as a conference paper at ICLR 2020
E	Network architectures
For synthetic experiment, the network architectures are the same with that in Thanh-Tung et al.
(2019). While for real world data experiment, we use the similar architectures in Mescheder et al.
(2018). We use Pytorch (Paszke et al. (2017)) for development.
Table 3: Generator architecture in synthetic experiment
Layer	output size	filter
Fully connected	64	2 → 64
RELU	64	-
Fully connected	64	64 → 64
RELU	64	-
Fully connected	64	64 → 64
RELU	64	-
Fully connected	2	64 → 2
Table 4: Discriminator architecture in synthetic experiment
Layer	output size	filter
Fully connected	64	2 → 64
RELU	64	-
Fully connected	64	64 → 64
RELU	64	-
Fully connected	64	64 → 64
RELU	64	-
Fully connected	1	64 7 1
Table 5: Generator architecture in CIFAR experiment
Layer	output size	filter
Fully connected 512 ∙ 4 ∙ 4	128 → 512 ∙ 4 ∙ 4
Reshape	512	X	4 X 4	-
ReSnet-BloCk	256	X	4 X 4	512	→	256	→ 256
NN-Upsampling	256	X	8 X 8	-
Resnet-Block	128	X	8 X 8	256	→	128	→ 128
NN-Upsampling 128 X 16 X 16	-
Resnet-Block	64 X 16 X 16	128 → 64 → 64
NN-Upsampling 64 X 32 X 32	-
Resnet-Block	64 X 32 X 32	64 → 64 → 64
Conv2D 3 X 32 X 32	64 → 3
18
Under review as a conference paper at ICLR 2020
Table 6: Discriminator architecture in CIFAR experiment
Layer	output size	filter
Conv2D	64 X 32 X 32	3 → 64
Resnet-Block	128 X 32 X 32	64 → 64 → 128
Avh-Pool2D	128 X 16 X 16	-
Resnet-Block	256 X 16 X 16	128 7 128 7 256
Avh-Pool2D	256 X 8 X 8	-
Resnet-Block	512 X 8 X 8	256 → 256 → 512
Avh-Pool2D	512 X 4 X 4	-
Reshape	-^512 ∙ 4 ∙ 4 ~~	-
Fully Connected	1	512 ∙ 4 ∙ 4 → 1
Table 7: Generator architecture in ImageNet experiment
Layer	output size	filter
Fully connected 1024 ∙ 4 ∙ 4	256 → 1024 ∙ 4 ∙ 4
Reshape	1024	X	4 X	4	-
Resnet-BloCk	1024	X	4 X	4^^1024	→ 1024	7	1024
Resnet-Block	1024	X	4 X	4	1024	→ 1024	→	1024
NN-Upsampling	1024	X	8 X	8	-
Resnet-Block	512 X 8 X 8	1024 → 512 → 512
Resnet-Block	512 X 8 X 8	512 → 512 → 512
NN-Upsampling 512 X 16 X 16	-
Resnet-Block	256	X	16 X	16	512	7	256	7	256
Resnet-Block	256	X	16 X	16	256	→	256	→	256
NN-Upsampling 256 X 32 X 32	-
Resnet-Block	128	X	32 X	32	256	→	128	→	128
Resnet-Block	128	X	32 X	32	128	→	128	→	128
NN-Upsampling 128 X 64 X 64	-
Resnet-Block	64 X 64 X 64	128 → 64 → 64
Resnet-Block	64 X 64 X 64	64 → 64 → 64
Conv2D 3 X 64 X 64	64 → 3
Table 8: Discriminator architecture in ImageNet experiment
Layer	output size	filter
Conv2D	64 X 64 X 64	3 7 64
Resnet-Block	64 X 64 X 64	64 7 64 7 64
Resnet-Block	128 X 64 X 64	64 → 64 → 128
Avh-Pool2D	128 X 32 X 32	-
Resnet-Block	128 X 32 X 32	-^128 → 128 → 128-
Resnet-Block	256 X 32 X 32	128 → 128 → 256
Avh-Pool2D	256 X 16 X 16	-
Resnet-Block	256 X 16 X 16	^^256 → 256 → 256-
Resnet-Block	512X 16X 16	256 → 256 → 512
Avh-Pool2D	512 X 8 X 8	-
Resnet-Block	512 X 8 X 8 ^^	^^512 7 512 → 512-
Resnet-Block	1024 X 8 X 8	512 → 512 → 1024
Avh-Pool2D	1024 X 4 X 4	-
Resnet-Block	1024 X 4 X 4	1024 → 1024 → 1024
Resnet-Block	1024 X 4 X 4	1024 → 1024 → 1024
Fully Connected	1	1024 ∙ 4 ∙ 4 → 1
19