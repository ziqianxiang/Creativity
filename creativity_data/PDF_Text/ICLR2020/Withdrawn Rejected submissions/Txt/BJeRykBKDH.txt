Under review as a conference paper at ICLR 2020
Empowering Graph Representation Learning
with Paired Training and Graph Co-Attention
Anonymous authors
Paper under double-blind review
Ab stract
Through many recent advances in graph representation learning, performance
achieved on tasks involving graph-structured data has substantially increased in
recent years—mostly on tasks involving node-level predictions. The setup of
prediction tasks over entire graphs (such as property prediction for a molecule,
or side-effect prediction for a drug), however, proves to be more challenging, as
the algorithm must combine evidence about several structurally relevant patches
of the graph into a single prediction. Most prior work attempts to predict these
graph-level properties while considering only one graph at a time—not allowing
the learner to directly leverage structural similarities and motifs across graphs.
Here we propose a setup in which a graph neural network receives pairs of graphs
at once, and extend it with a co-attentional layer that allows node representations
to easily exchange structural information across them. We first show that such a
setup provides natural benefits on a pairwise graph classification task (drug-drug
interaction prediction), and then expand to more generic graph regression and graph
classification setups: enhancing predictions over QM9, D&D and PROTEINS,
standard molecular prediction benchmarks. Our setup is flexible, powerful and
makes no assumptions about the underlying dataset properties, beyond anticipating
the existence of multiple training graphs.
1	Introduction and Related Work
We study the task of graph-level representation learning: i.e., computing representations of entire
input graphs, for the purposes of downstream tasks (such as graph classification or regression). This
is typically a step-up in complexity compared to node classification or link prediction, given that
the learning algorithm must aggregate useful structural information across the graph into a single
prediction—relying on only this global supervision signal (as opposed to having feedback from every
node/edge of the graph).
Perhaps the highest challenge this kind of architecture must face is inductivity and generalisation
across structures. Specifically, an inductive model must be readily applicable across several graph
structures—including ones unseen during training. Additionally, the model is tasked with discovering
interesting structural “motifs” across the entire dataset of graphs, whose presence or absence may
help determine the overall predictions.
However, even enabling inductivity is not a traditionally simple task in graph representation learning,
as many prior approaches (Bruna et al., 2013; Perozzi et al., 2014; Defferrard et al., 2016) are
not inductive by design. Furthermore, even the models that are currently used for graph-level
representation learning; e.g. Gilmer et al. (2017); Ying et al. (2018); Xu et al. (2018); Lu et al. (2019),
operate over only a single graph at a time—making it challenging for them to reason about common
substructures across graphs from a graph-level supervision signal alone.
In this manuscript, we propose the approach of paired training—i.e., learning representations over
pairs of input graphs at once. Intuitively, as long as we allow for dataflow between the representations
of the two graphs within a pair, this allows the graph neural network to directly observe related
(sub)structures from other inputs, to solidify its decision making. We note that in the context of
graph-structured inputs this may be particularly useful as, unlike simpler inputs such as images or text,
there are no guarantees that different graphs within a dataset will have equal or even similar overall
structure. To facilitate this dataflow, we propose the usage of graph co-attention for exchanging
1
Under review as a conference paper at ICLR 2020
representations of nodes across the two graphs. Intuitively, this operator performs attention (Bahdanau
et al., 2014; Vaswani et al., 2017) over the fully-connected bipartite graph, with one part corresponding
to all nodes in one graph. This allows every node of the first graph to detect and reuse useful patch
representations in the second graph (in a form of hierarchical graph matching), and vice-versa.
Initially, we validate our model performance on a pairwise graph classification task—classifying
drug pairs for side effects caused by drug-drug interactions (DDI) (Jin et al., 2017; Zitnik et al., 2018).
In this setting, a pairwise approach is natural, as we inherently have to classify pairs of graphs. We
demonstrate that learning a joint representation using graph co-attention provides substantial benefits
to predictive power, setting the state-of-the-art result on this task.
From there, we demonstrate the applicability of our approach to arbitrary multi-graph datasets; for
this, we leverage the QM9 dataset for predicting quantum chemistry properties of small molecules
(Ramakrishnan et al., 2014). As such, it represents a challenging graph regression problem. We
propose using paired training to perform regression on two molecules at once, demonstrating clear
benefits to doing so. In a similar vein, we execute variants of our model on standard graph kernel
classification benchmarks (Kersting et al., 2016), showing advantages to generic graph classification.
Our approach paves the way to a promising direction for graph-level prediction tasks, that is in
principle applicable to any kind of multi-graph dataset, especially under availability of large quantities
of labelled examples.
Our model builds up on a large existing body of work in graph convolutional networks (Bruna et al.,
2013; Defferrard et al., 2016; KiPf & Welling, 2016a; Gilmer et al., 2017; Velickovic et al., 2018),
that have substantially advanced the state-of-the-art in many tasks requiring graph-structured input
Processing (such as the chemical rePresentation (Gilmer et al., 2017; De Cao & KiPf, 2018; You
et al., 2018) of the drugs leveraged here). Furthermore, we build uP on work ProPosing co-attention
(Lu et al., 2016; Deac et al., 2018) as a mechanism to allow for individual set-structured datasets
(such as nodes in multimodal graPhs) to interact. SPecifically, such mechanisms have already been
used for exPlicit matching of graPh structure motifs (Li et al., 2019), and therefore rePresent a natural
methodology for our PurPoses.
Overall, these (and related) techniques lie within the domain of graph representation learning, one
of the latest major challenges of machine learning (Bronstein et al., 2017; Hamilton et al., 2017;
Battaglia et al., 2018), with transformative Potential across a wide sPectrum of Potential aPPlications,
extending outside the biochemical domain.
2	Architecture
In this section, we will Present the main building blocks used within our architecture for Paired graPh
rePresentation learning. This will sPan a discussion of the way the inPut to the model is encoded,
followed by an overview of the individual comPutational stePs of the model. As the tasks considered
in this manuscriPt oPerate over molecules, we will treat all inPuts as molecular graPhs.
2.1	Inputs
The molecules, dx , are rePresented as graphs consisting of atoms, ai(dx) as nodes, and bonds between
those atoms ai(dx), aj(dx) as edges. For each atom, the following inPut features are recorded: the
atom number, the number of hydrogen atoms attached to this atom, and the atomic charge. For each
bond, a discrete bond type (e.g. single, double etc.) is encoded as a learnable inPut edge vector, ei(jdx) .
2.2	Message passing
Within each of the two molecules seParately, our model aPPlies a series of message passing (Gilmer
et al., 2017) layers. Herein, nodes are allowed to send arbitrary vector messages to each other along
the edges of the graPh, and each node then aggregates all the messages sent to it.
Let (dx)hit denote the features of atom i of molecule x, at time steP t. Initially these are
2
Under review as a conference paper at ICLR 2020
set to projected input features, i.e.:
(dx)hi0 =fi ai(dx)	(1)
where fi is a small multilayer perceptron (MLP) neural network. In all our experiments, this MLP
(and all subsequently referenced MLPs and projections) projects its input to 50 features. Note that
this effectively encodes one-hot inputs such as atom type into a learnable embedding.
Considering atoms i and j of molecule x, connected by a bond with edge vector ei(jdx) , we
start by computing the message, (dx)mitj, sent along the edge j → i. The message takes into account
both the features of node j and the features of the edge between i and j :
(dx)mitj =fet ei(jdx)	fvt (dx)htj-1	(2)
where fet and fvt are small MLPs, and is elementwise vector-vector multiplication.
Afterwards, every atom i aggregates the messages sent to it via summation. This results in
an internal message for atom i, (dx)mit:
(dx)mit = X (dx)mtij	(3)
∀j∈N(i)
where the neighbourhood, N (i), defines the set of atoms linked to i by an edge.
2.3	Co-attention
Message passing provides a robust mechanism for encoding within-molecule representations of
atoms. For learning an appropriate joint molecule-molecule representation, however, we allow atoms
to interact across molecule boundaries via a co-attentional mechanism (Deac et al., 2018).
Consider two atoms, i and j , of molecules x and y, respectively. Let their features at time
step t be (dx)hit and (dy)htj, just as before. For every such pair, we compute an attentional coefficient,
αitj using a simplified version of the Transformer (Vaswani et al., 2017) attention mechanism:
αitj = softmaxj DWtk(dx)hit-1,Wtk(dy)htj-1E	(4)
where Wk is a learnable projection matrix,卜，)is the inner product, and the Softmax is taken across
all nodes j from the second molecule. The coefficients αitj may be interpreted as the importance of
atom j ’s features to atom i.
These coefficients are then used to compute an outer message for atom i of molecule x,
(dx)nit, expressed as a linear combination (weighted by αitj) of all (projected) atom features from
molecule y:
(dX) ni = X αj∙ Wv (dy )hj-1	(5)
∀j∈dy
where Wtv is a learnable projection matrix.
It was shown recently that multi-head attention can stabilise the learning process, as well
as learn information at different conceptual levels (Velickovic et al., 2018; QiU et al., 2018). As
such, the mechanism of Equation 5 is independently replicated across K attention heads (we chose
K = 8), and the resulting vectors are concatenated and MLP-transformed to provide the final outer
message for each atom.
(dx)nti = fθ I k X (k)αtij ∙ (k)WvSy)hj-1)	(6)
k=1 ∀j∈dy
where fot is a small MLP and k is featurewise vector concatenation.
3
Under review as a conference paper at ICLR 2020
Figure 1: The illustration of a single step of message passing (computing the inner message, (dx)mit),
and co-attention (computing the outer message (dx)ntu) on two nodes (i and u) of molecule x.
The computation of Equations 4-6 is replicated analogously for outer messages from molecule X to
atoms of molecule y .
We have also attempted to use other popular attention mechanisms for computing the αtij
values-such as the original Transformer (VaSWani et al., 2017), GAT-like (VeIickOVic et al., 20l8)
and tanh (Bahdanau et al., 2014) attention—finding them to yield weaker performance than the
approach outlined here.
A single step of message passing and co-attention, as used by our model, is illustrated by
Figure 1.
2.4	Update function
Once the inner messages, (dx)mit (obtained through message passing), as Well as the outer messages,
(dx)nti (obtained through co-attention) are computed for every atom i of each of the tWo molecules
(dx/dy), We use them to derive the next-level features, (dx)hit, for each atom.
At each step, this is done by aggregating (via summation) the previous features (represent-
ing a skip connection (He et al., 2016)), the inner messages and outer messages, folloWed by layer
normalisation (Ba et al., 2016):
(dx)hit = LayerNorm (dx)hit-1 + (dx)mit + (dx)nit	(7)
The operations of Equations 2-7 are then repeated for T propagation steps—here, We set T = 3.
Refer to Figure 2 for a complete visualisation of our architecture.
As Will be demonstrated by our results, using co-attention to enable the model to propagate
the information betWeen tWo molecules from the beginning—thus learning a joint representation of
the molecules—valuably contributes to the predictive poWer of the model.
2.5	Readout and Scoring
As We’re making predictions on the level of entire molecules (or molecule-molecule pairs), We need
to compress individual atom representations into molecule-level representations. In order to obtain
the molecule-level vectors dx , We apply a simple summation of its constituent atom feature vectors
after the final layer (i.e. after T propagation steps have been applied):
dx = X fr (dx)hjT	(8)
∀j∈dx
Where fr is a small MLP.
4
Under review as a conference paper at ICLR 2020
×T steps
Figure 2: A high-level overview of our paired training architecture. The next-level features of atom
i of molecule x, (dx)hit, are derived by combining its input features, (dx) hit-1, its inner message,
(dx)mit, computed using message passing, and its outer message, (dx)nit, computed using co-attention
over the second molecule, dy .
Once the molecule vectors are computed for both dx and dy , they can be used to make pre-
dictions on either x and y individually, or to make pairwise predictions—the exact setup varies
depending on the considered task.
3	PAIRWISE GRAPH CLASSIFICATION: Polypharmacy side effects
We now directly evaluate the benefits of our model on a pairwise graph classification task. This
represents a natural testbed for our framework, as within the dataset, graphs are already given to us in
paired form for training and evaluation.
Despite the apparent specificity of this setup, it is central to many relevant and important problems
across the sciences. We study the task of polypharmacy side effect prediction, to be described below.
3.1	Motivation
Diseases are often caused by complex biological processes which cannot be treated by individual
drugs and thus introduce the need for concurrent use of multiple medications. Similarly, drug
combinations are needed when patients suffer from multiple medical conditions. However, the
downside of such treatment (referred to as polypharmacy) is that it increases the risk of adverse side
effects, caused by the chemical-physical incompatibility of the drugs.
Uniquely within the related work in this area, our model learns a robust representation of drugs by
leveraging joint information early on in the learning process. Our method outperforms previous
state-of-the-art models in terms of predictive power, while using just the molecular structure of the
drugs. It thus allows for the method to be applied to novel drug combinations, as well as permitting
the detection to be performed at the preclinical phase.
3.2	Dataset and Preprocessing
The drug-drug interaction data was chosen to be in agreement with the dataset used by Decagon
(Zitnik et al., 2018). It is obtained by filtering the TWOSIDES side-effect dataset (Tatonetti et al.,
5
Under review as a conference paper at ICLR 2020
Yes/No
[
DDI predictor (binary)
Drug 1	Drug 2	Side-effect
Tachycardia
Drug 1
Drug 2
Figure 3: An overview of the binary (left) and multi-label (right) drug-drug interaction (DDI) task. In
both cases, two drugs (represented as their molecular structures) are provided to the model in order to
predict existence or absence of adverse interactions. For binary classification, the DDI predictor is
also given a particular side effect as input, and is required to specifically predict existence or absence
of it. For multi-label classification, the DDI predictor simultaneously predicts existence or absence of
all side-effects under consideration.
2012), which consists of associations which cannot be clearly attributed to either drug alone (that is,
those side-effects reported for any individual drug in the OFFSIDE dataset (Tatonetti et al., 2012)).
The side effects, sez, are one-hot encoded from a set of 964 polypharmacy side-effect types that
occurred in at least 500 drug pairs. The model input and loss function varies depending on whether
we are performing binary classification for a given side effect, or multi-label classification for all
side effects at once (Figure 3)—further details may be found in Appendix A. The full dataset consists
of 4,576,785 positive examples. As we aim to sample a balanced number of positive and negative
examples, the overall dataset size for training our model is 9,153,570 examples.
3.3	Experimental setup
We will refer to our model as MHCADDI (multi-head co-attentive drug-drug interactions), and
MHCADDI-ML for multi-label classification. We perform detailed ablation studies, to stress the
importance of various components of MHCADDI (especially, its co-attention mechanism). The
following variations are considered:
•	MPNN-Concat: removing co-attention, i.e. learning drug representations independently;
•	Late-Outer: where co-attention messages are not aggregated until the last layer;
•	CADDI : only K = 1 attention head.
Additionally, we compare our method with several existing strong baselines: the Multitask Dyadic
Prediction (Jin et al., 2017) relying on proximal gradients and substructure fingerprints, tensor
factorisation methods RESCAL (Nickel et al., 2011) and DEDICOM (Papalexakis et al., 2017), the
network embedding method DeepWalk (Perozzi et al., 2014), and the multiresolution link prediction
method over drug-protein interaction graphs, Decagon (Zitnik et al., 2018). We omit comparisons
with traditional machine learning baselines (such as support vector machines or random forests) as
prior work (Jin et al., 2017) has already found them to be significantly underperforming on this task.
3.4	Results
We perform stratified 10-fold crossvalidation on the derived dataset. For each model, we report the
area under the receiver operating characteristic (ROC) curve averaged across the 10 folds. The results
of our study may be found in Table 1.
From this study, we may conclude that learning joint drug-drug representations by simultaneously
combining internal message-passing layers and co-attention between drugs is a highly beneficial
approach, consistently outperforming the strong baselines considered here (even when additional
data sources are used, as in the case of Decagon). Furthermore, comparing between architectural
variants, we can conclude that (further qualitative studies may be found in Appendix A):
•	The fact that all our co-attentive architectures outperformed MPNN-Concat implies that it is
beneficial to learn drug-drug representations jointly rather than separately.
6
Under review as a conference paper at ICLR 2020
Table 1: Comparative evaluation results after stratified 10-fold crossvalidation.
AUROC	
Drug-Fingerprints (Jin et al., 2017)	0.744
RESCAL (Nickel et al., 2011)	0.693
DEDICOM (Papalexakis et al., 2017)	0.705
DeepWalk (Perozzi et al., 2014)	0.761
Concatenated features (Zitnik et al., 2018)	0.793
Decagon (Zitnik et al., 2018)	0.872
MPNN-Concat (ours)	0.661
Late-Outer (ours)	0.724
CADDI (ours)	0.778
MHCADDI (ours)	0.882
MHCADDI-ML (ours)	0.819
•	Furthermore, the outperformance of Late-Outer by (MH)CA-DDI further demonstrates that
it is useful to provide the cross-modal information earlier in the learning pipeline.
•	Lastly, the comparative evaluation of MHCADDI against CADDI further shows the benefit
of inferring multiple mechanisms of drug-drug interaction simultaneously, rather than
anticipating only one.
We note that further relevant research in GNNs—particularly in unsupervised learning—could be
used to further enhance our results. Given the link prediction nature of the dataset, the method of Kipf
& Welling (2016b) could be useful for appropriately pre-training the GNNs used here, for example.
4	GRAPH REGRESSION: Quantum chemistry
Having confirmed that our paired training paradigm with graph co-attention yields significant returns
on polypharmacy side effect prediction, we now direct attention to generalising it to arbitrary
multi-graph datasets (even without explicitly given pairings).
We consider the challenging graph regression setup of predicting quantum-chemical properties of
small molecules, on the QM9 dataset (Ramakrishnan et al., 2014), as previously done by e.g. Gilmer
et al. (2017); Lu et al. (2019). QM9 consists of ~130,000 molecules with 12 properties for each
molecule, yielding 12 regression tasks. We preprocess the dataset similarly as in prior work (by
transforming the ground-truth values of the twelve quantum-chemical properties under study to
the [0, 1] range). We use 10,000 randomly-chosen molecules for testing and validation each; the
remainder is used for training.
4.1	Experimental setup
We perform paired training on QM9 by pairing each input graph with K different training graphs
(these pairs are fixed and chosen in advance, for consistency and reproducibility purposes). We
compare the following variants:
•	K = 1 (self): only pair molecules to themselves. This setup is equivalent to an MPNN
(Gilmer et al., 2017) from a representational standpoint, as the co-attention layers allow for
unrestricted dataflow between atoms in a molecule.
•	K = 1 (k-NN): using a pre-trained GrammarVAE (Kusner et al. (2017)) model, pair each
molecule with its nearest neighbour.
•	K = 1 (random): pair each molecule to a randomly chosen training molecule.
•	K ∈ [2, 5]: pair each molecule to K - 1 randomly chosen training molecules, and addition-
ally to themselves.
•	K = 3 (k-NN): pair each molecule to itself and with K - 1 nearest neighbours obtained
using pre-trained GrammarVAE.
7
Under review as a conference paper at ICLR 2020
Table 2: Mean absolute errors (MAE) over the twelve prediction tasks of QM9.
Property	K=1 (self)	K=1 (k-NN)	K=1 (random)	K = 2	K=3	K=4	K=5	K=3 (k-NN)
mu	0.6267	1.1058	0.6354	0.6182	0.6242	0.6178	0.6142	0.6160
alpha	0.6893	2.2989	0.6913	0.6550	0.6647	0.6647	0.6523	0.6590
HOMO	0.0055	0.0140	0.0056	0.0053	0.0055	0.0054	0.0053	0.0053
LUMO	0.0057	0.0196	0.0060	0.0055	0.0055	0.0056	0.0055	0.0054
gap	0.0077	0.0242	0.0082	0.0075	0.0076	0.0076	0.0076	0.0074
R2	59.249	147.25	61.309	55.563	57.229	57.341	55.789	52.823
ZPVE	0.0005	0.0025	0.0005	0.0005	0.0005	0.0005	0.0004	0.0004
U0	0.2912	33.575	0.1451	0.1970	0.1902	0.1872	0.1337	0.2552
U	0.2980	29.247	0.1610	0.1557	0.1713	0.2523	0.1416	0.1984
H	0.3870	23.029	0.2587	0.2055	0.2124	0.2319	0.1363	0.2816
G	0.3441	18.554	0.1990	0.1972	0.1948	0.2574	0.1737	0.2444
Cv	0.3781	1.6162	0.3908	0.3665	0.3706	0.3727	0.3520	0.3534
Average	5.1902	21.3949	5.3176	4.8314	4.9731	4.9954	4.8343	4.6208
Figure 4: Histograms of entropies of co-attentional coefficients, for the three layers of a trained
K = 3 co-attentive model (left) and the uniform distribution (right).
When training on a pair of molecules, we simultaneously optimise the mean absolute error (MAE) on
both of them, for all the regression targets. At validation- or test-time, we only look at predictions
for the test molecule, discarding the representation of the paired training molecule. Furthermore,
whenever K > 1, we average the predictions across all pairings at test time.
4.2	Results
The results on the QM9 dataset study are provided in Table 2. It may be noted that already allowing
for one more random pairing on top of the self-pair (K = 2) yields improved performance across
all of the prediction tasks. These gains remain consistent, and usually do not change much, when
increasing the number of pairings beyond 2. This confirms the benefits of paired training in the graph
regression setup.
Furthermore, we provide qualitative evidence for the co-attention’s mechanism of action, demonstrat-
ing that it learns attentional probability distributions that are more complex than uniform aggregation—
i.e. that focus on specific regions of the paired graph. We visualise, for the K = 3 model, the
histograms of co-attention coefficient entropies across the testing dataset, and compare it against
the histogram for the uniform distribution, in Figure 4. This clearly demonstrates that not only the
co-attention mechanism learns complex interactions across the paired molecules, but also that it
learns different mechanisms of interaction across the three co-attentive layers.
8
Under review as a conference paper at ICLR 2020
Table 3: Classification accuracy percentages after 10-fold cross-validation.
Datasets
Model	D&D	Proteins
MPNN (Gilmer et al., 2017)	70.04	68.15
Late-Attn (ours)	68.59	71.49
Co-Attn (ours)	74.11	71.14
5	Graph Classification
Finally, we turn our attention to the standard graph kernel classification datasets of Kersting et al.
(2016). We focus on two molecular-based binary graph classification datasets: D&D and PROTEINS.
In both cases, it is required to classify protein structures based on whether they are enzymes. D&D
comprises 1,178 graphs of protein structures (with 284 nodes and 715 edges on average). PROTEINS
comprises 1,113 graphs (with 39 nodes and 72 edges on average).
For both datasets, we train a co-attentive GNN with propagation rules as described in the Architecture
section. The GNN consists of three interleaved layers of message passing and co-attention, computing
64 features each. As is common-practice for these datasets (see e.g. Ying et al. (2018)), we provide
the accuracy results on them after 10-fold crossvalidation. For paired training purposes, we select
a random training graph to pair with for each batch, and otherwise proceed as described for QM9.
Random pairing was sufficient to demonstrate clear gains, and thus we leave more complex pairings
for future analysis.
For evaluation purposes, we compare our co-attentive GNN with paired training against a version
without co-attention (referred to as MPNN), as well as a version with only one co-attentive layer at
the end (referred to as Late-Attn).
The results of this study may be found in Table 3. Evidently, the co-attentive method improves
over its corresponding MPNN baseline on both datasets. Furthermore, on D&D, it outperforms the
late-applied co-attention, providing evidence of useful hierarchical structure matching between the
two paired graphs.
6	Conclusions
We have presented a novel way of training graph neural networks on multi-graph datasets, relying
on making predictions jointly, in pairs of graphs—the paired training approach. Additionally,
we allowed for arbitrary representation exchange between these graphs by way of co-attentive
mechanisms. The two combined allow for extraction of stronger and more robust representations as
opposed to single-graph learning, which is a claim we verified across several established molecular
prediction tasks: polypharmacy side effect prediction (where we set a state-of-the-art result), quantum
chemistry properties prediction and graph classification. As a flexible and generic approach which
doesn’t rely on dataset properties in any way, so long as it consists of multiple graphs, we believe it
to be a useful direction to explore for graph representation learning as a whole.
References
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint
arXiv:1607.06450, 2016.
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly
learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.
Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi,
Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al.
Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261,
2018.
9
Under review as a conference paper at ICLR 2020
Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. Geometric
deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18-42,
2017.
Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral networks and locally
connected networks on graphs. arXiv preprint arXiv:1312.6203, 2013.
Nicola De Cao and Thomas Kipf. Molgan: An implicit generative model for small molecular graphs.
arXiv preprint arXiv:1805.11973, 2018.
Andreea Deac, Petar VeliCkovic, and Pietro Sormanni. Attentive cross-modal paratope prediction.
arXiv preprint arXiv:1806.04398, 2018.
Michael Defferrard, Xavier Bresson, and Pierre Vndergheynst. Convolutional neural networks on
graphs with fast localized spectral filtering. In Advances in Neural Information Processing Systems,
pp. 3844-3852, 2016.
Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. Neural
message passing for quantum chemistry. CoRR, abs/1704.01212, 2017. URL http://arxiv.
org/abs/1704.01212.
Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural
networks. In Proceedings of the thirteenth international conference on artificial intelligence and
statistics, pp. 249-256, 2010.
William L Hamilton, Rex Ying, and Jure Leskovec. Representation learning on graphs: Methods and
applications. arXiv preprint arXiv:1709.05584, 2017.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016.
Bo Jin, Haoyu Yang, Cao Xiao, Ping Zhang, Xiaopeng Wei, and Fei Wang. Multitask dyadic
prediction and its application in prediction of adverse drug-drug interaction. In AAAI, 2017.
Kristian Kersting, Nils M. Kriege, Christopher Morris, Petra Mutzel, and Marion Neumann. Bench-
mark data sets for graph kernels, 2016. URL http://graphkernels.cs.tu-dortmund.
de.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks.
arXiv preprint arXiv:1609.02907, 2016a.
Thomas N Kipf and Max Welling. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308,
2016b.
Matt J Kusner, Brooks Paige, and Jose Miguel Hernandez-Lobato. Grammar variational autoencoder.
In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 1945-
1954. JMLR. org, 2017.
Yujia Li, Chenjie Gu, Thomas Dullien, Oriol Vinyals, and Pushmeet Kohli. Graph matching networks
for learning the similarity of graph structured objects. arXiv preprint arXiv:1904.12787, 2019.
Chengqiang Lu, Qi Liu, Chao Wang, Zhenya Huang, Peize Lin, and Lixin He. Molecular property pre-
diction: A multilevel quantum interactions modeling perspective. arXiv preprint arXiv:1906.11081,
2019.
Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. Hierarchical question-image co-attention for
visual question answering. In Advances In Neural Information Processing Systems, pp. 289-297,
2016.
Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine
learning research, 9(Nov):2579-2605, 2008.
10
Under review as a conference paper at ICLR 2020
Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. A three-way model for collective learning
on multi-relational data. In ICML, volume 11, pp. 809-816, 2011.
Evangelos E Papalexakis, Christos Faloutsos, and Nicholas D Sidiropoulos. Tensors for data mining
and data fusion: Models, applications, and scalable algorithms. ACM Transactions on Intelligent
Systems and Technology (TIST), 8(2):16, 2017.
Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social representa-
tions. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery
and data mining, pp. 701-710. ACM, 2014.
JZ Qiu, Jian Tang, Hao Ma, YX Dong, KS Wang, and J Tang. Deepinf: Modeling influence locality
in large social networks. In Proceedings of the 24th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (KDD’18), 2018.
Raghunathan Ramakrishnan, Pavlo O Dral, Matthias Rupp, and O Anatole Von Lilienfeld. Quantum
chemistry structures and properties of 134 kilo molecules. Scientific data, 1:140022, 2014.
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine
Learning Research, 15(1):1929-1958, 2014.
Nicholas P. Tatonetti, Patrick P. Ye, Roxana Daneshjou, and Russ B. Altman. Data-driven prediction
of drug effects and interactions. 2012. URL http://doi.org/10.1126/scitranslmed.
3003377.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,
Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. CoRR, abs/1706.03762, 2017. URL
http://arxiv.org/abs/1706.03762.
Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua
Bengio. Graph Attention Networks. International Conference on Learning Representations, 2018.
URL https://openreview.net/forum?id=rJXMpikCZ.
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural
networks? arXiv preprint arXiv:1810.00826, 2018.
Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec.
Hierarchical graph representation learning with differentiable pooling. In Advances in Neural
Information Processing Systems, pp. 4800-4810, 2018.
Hee-Geun Yoon, Hyun-Je Song, Seong-Bae Park, and Se-Young Park. A translation-based knowledge
graph embedding preserving logical property of relations. In HLT-NAACL, 2016.
Jiaxuan You, Bowen Liu, Rex Ying, Vijay Pande, and Jure Leskovec. Graph convolutional policy
network for goal-directed molecular graph generation. arXiv preprint arXiv:1806.02473, 2018.
Marinka Zitnik, Monica Agrawal, and Jure Leskovec. Modeling polypharmacy side effects with graph
convolutional networks. Bioinformatics, 34(13):i457-i466, 2018. doi: 10.1093/bioinformatics/
bty294. URL http://dx.doi.org/10.1093/bioinformatics/bty294.
A Polypharmacy side effect task details
A. 1 Dataset generation
•	For binary classification (Figure 3 (Left)), the input to our model is a triplet of two drugs and
a side effect (dx, dy, sez), requiring a binary decision on whether drugs x and y adversely
interact to cause side effect z .
•	For multi-label classification (Figure 3 (Right)), the input to our model is a pair of two drugs
(dx, dy), requiring 964 simultaneous binary decisions on whether drugs x and y adversely
interact to cause each of the considered side effects. Note that, in terms of learning pressure,
this model requires more robust joint representations of pairs of drugs—as they need to be
useful for all side-effect predictions at once.
11
Under review as a conference paper at ICLR 2020
In order to compensate for the fact that TWOSIDES contains only positive samples, appropriate
negative sampling is performed for the binary classification task:
•	During training, tuples (dχ,dy,sez), where dχ and Sez are chosen from the dataset and dy
is chosen at random from the set of drugs different from dy in the true samples (dx, dy, sez).
•	During validation and testing, we simply randomly sample two distinct drugs which do not
appear in the positive dataset.
A.2 Training setup
To further regularise the model, dropout (Srivastava et al., 2014) with p = 0.2 is applied to the output
of every intermediate layer. The model is initialised using Xavier initialisation (Glorot & Bengio,
2010) and trained using the Adam SGD optimiser (Kingma & Ba, 2014), with early stopping. The
learning rate after t iterations, ηt , is derived using an exponentially decaying schedule:
ηt = 0.001 ∙ 0.96t∙10-6	(9)
A.3 B inary classification
In the binary classification case, the side effect vector sez is provided as input. We then leverage a
scoring function f similar to the one used by Yoon et al. Yoon et al. (2016) to express the likelihood
of this side effect occuring:
f(dx,dy,sez) =Mhdx+sez -Mtdy22+Mhdy+sez -Mtdx22	(10)
where ∣∣ ∙ k2 is the L2 norm, and Mh and Mt represent the head node and tail node space mapping
matrices, respectively.
The model is then trained end-to-end with gradient descent to optimise a margin-based
ranking loss:
L=	max(0, γ - f (dx , dy , sez ) - f (dx , dy , sez )))	(11)
dχ ,dy ,sez dχ,dy ,sez
∙-v	∙-v
where (dx, dy) is a drug-drug pair exhibiting side effect sez, and (dx, dy) is a drug-drug pair not
exhibiting it. γ > 0 is the margin hyperparameter.
A.4 Multi-label classification
Here, all side effects are predicted simultaneously, and accordingly we define a prediction layer,
parametrised by a learnable weight matrix Wp and bias bp . This layer consumes the concatenation
of the two drug vectors and projects it into a score for each of the 964 side effects. These scores are
then converted into probabilities, yxzy, of each side effect, z, occurring between drugs x and y using
the logistic sigmoid nonlinearity, σ, applied elementwise:
yZy = σ (Wp[dχkdy] + bp)z	(12)
We can then once again train the model end-to-end with gradient descent, using binary cross-entropy
against the ground truth value, yXy (which is a binary label indicating whether side effect Z actually
occurs between drugs x and y). The loss function is as follows:
LBCE = X yzy log Uxy + (1 - yzy) log (1 - yzy)	(13)
dx,dy ,z
A.5 Qualitative Results
The effectiveness of the learnt joint representations may be investigated qualitatively as well, and to
that end, we have devised a controlled visualisation experiment. Our objective is to investigate the
distribution of learnt drug-drug embeddings with respect to individual side effects.
12
Under review as a conference paper at ICLR 2020
Figure 5: t-SNE projections of 200 learnt drug-drug representations, across 9 side-effects. Each
side effect is colour-coded with a shade of red for positive drug-drug pairs and a shade of green for
negative pairs.
We start with a pre-trained MHCADDI model. For each side effect in a sample of 10, we
have randomly sampled 100 drug-drug pairs exhibiting this side effect, and 100 drug-drug pairs
not exhibiting it (both unseen by the model during training). For these pairs, we derived their
embeddings, and projected them into two dimensions using t-SNE Maaten & Hinton (2008).
The visualised embeddings may be seen in Figure 5 for individual side-effects, and Figure
6 for a combined plot. These plots demonstrate that, across a single side-effect, there is a discernible
clustering in the projected 2D space of drug-drug interactions. Furthermore, the combined plot
demonstrates that strongly side-effect inducing drug-drug pairs tend to be clustered together, and
away from the pairs that do not induce side-effects.
13
Under review as a conference paper at ICLR 2020
Figure 6: t-SNE projection of 2000 learnt drug-drug representations, sampled to cover 10 side effects.
Each side effect is colour-coded with a shade of red for positive drug-drug pairs and a shade of green
for negative drug-drug pairs.
14