Under review as a conference paper at ICLR 2020
Customizing Sequence Generation with Multi-
Task Dynamical Systems
Anonymous authors
Paper under double-blind review
Ab stract
Dynamical system models (including RNNs) often lack the ability to adapt the
sequence generation or prediction to a given context, limiting their real-world
application. In this paper we show that hierarchical multi-task dynamical systems
(MTDSs) provide direct user control over sequence generation, via use of a latent
code z that specifies the customization to the individual data sequence. This enables
style transfer, interpolation and morphing within generated sequences. We show
the MTDS can improve predictions via latent code interpolation, and avoid the
long-term performance degradation of standard RNN approaches.
1	Introduction
Time series data often arise as a related ‘family’ of sequences, where certain characteristic differences
exist between the sequences in a dataset. Examples include the style of handwritten text (Graves,
2013), the response of a patient to an anaesthetic (Bird et al., 2019), or the style of locomotion in
motion capture (mocap) data (Ghosh et al., 2017). In this paper, we will consider how such variation
may be modelled, and effectively controlled by an end user.
Such related data is often pooled to train a single dynamical system, despite the internal variation.
For a simple model, such as a linear dynamical system (LDS), this will result in learning only an
average effect. In contrast, a recurrent neural network (RNN) may model this variation, but in an
implicit and opaque manner. Such a ‘black-box’ approach prohibits end-user control, and may suffer
from mode drift, such as in Ghosh et al. (2017), where a generated mocap sequence performs an
unprompted transition from walking to drinking. Some of these problems may be alleviated by
appending ‘context labels’ to the inputs (see e.g. Goodfellow et al., 2016, §10.2.4) which describe the
required customization. However, such labels are often unavailable, and the approach may fail to
model the variation adequately even when they are.
To move beyond these approaches, we consider latent variable models, where a latent variable z
characterizes each sequence. This may be seen as a form of multi-task learning (MTL, see Zhang
& Yang, 2017), from which we derive the name multi-task dynamical system (MTDS), with each
sequence treated as a task. A straightforward approach is to append the latent z to the inputs of the
model, similarly to the ‘context label’ approach, thereby providing customization of the various bias
(or offset) parameters of the model. A number of examples of this have been proposed recently, e.g.
in Yingzhen & Mandt (2018) and Miladinovic et al. (2019). Nevertheless, this 'bias customization'
has limited expressiveness and is often unsuitable for customizing simple models.
In this paper we investigate a more powerful form of customization which modulates all the system
and emission parameters. In this approach, the parameters of each task are constrained to lie on a
learned low dimensional manifold, indexed by the latent z. Our experiments show that this approach
results in improved performance and/or greater data efficiency than existing approaches, as well as
greater robustness to unfamiliar test inputs. Further, varying z can generate a continuum of models,
allowing interpolation between sequence predictions (see Figure 1b for an example), and potentially
morphing of sequence characteristics over time.
Contributions In this paper we propose the MTDS, which goes beyond existing work by allowing
full adaptation of all parameters of general dynamical systems via use of a learned nonlinear manifold.
We show how the approach may be applied to various popular models, and provide general purpose
1
Under review as a conference paper at ICLR 2020
Figure 1: (a) Graphical Model of the multi-task dynamical system. (b) Right elbow joint during
human locomotion measured in (top) vertical, and (bottom) horizontal directions, obtained varying z
between ‘childlike’ (blue) and ‘proud’ (red) styles.
learning and inference algorithms. Our experimental studies use synthetic data (sum of two damped
harmonic oscillators) and real-world human locomotion mocap data. We illuminate various properties
of the MTDS formulation in our experiments, such as data efficiency, user control, and robustness to
dataset shift, and show how these go beyond existing approaches to time series modelling. We finally
utilize the increased user control in the context of mocap data to demonstrate style morphing.
To this end, we introduce the model in Section 2, giving examples and discussing the particular chal-
lenges in learning and inference. We discuss the relation to existing work in Section 3. Experimental
setup and results are given in Section 4 with a conclusion in Section 5.
2	Multi-Task Dynamical Systems
Consider a collection of input-output sequences D = {Y (i), U(i)}iN=1 with inputs U(i) =
{u(1i), . . . , u(Ti)} and outputs Y (i) = {y1(i), . . . , yT(i)}, i = 1, . . . , N, where Ti denotes the length of
sequence i. Each sequence i is described by a different dynamical system, whose parameter θ(i)
depends on the hierarchical latent variable z(i) ∈ Z:
θ(i) = hφ(z(i)),	z(i)〜p(z)	(1)
Xti)〜P(X | xt-ι, u(i), θ(i)),	(2)
y(i)〜p(y I χ(i), u(i), θ(i)),	(3)
for t = 1, . . . , Ti. The state variables X(i) = {X(1i), . . . , X(Ti)}, Xt ∈ X follow the latent dynamics (2)
starting from X0 := 0 (other choices of initial state are possible). See Figure 1a for a graphical model.
In this paper We assume Z = Rk which the vector-valued function hφ(∙) transforms to conformable
model parameters θ ∈ Rd , d k. Note that hφ may keep some dimensions of θ constant with
respect to z. We call this a Multi-Task Dynamical System, going beyond the usage in Bird et al.
(2019).
An MTDS model under this framework must specify three key quantities:
1.	The base model (e.g. a LDS or RNN).
2.	The nature of the interaction between the latent variable z and the parameter vectors θ (e.g.
if only the dynamics (eq. 2) depend on θ).
3.	The choice of prior p(z) and transformation hφ.
Where the use of a constant z over time is inappropriate, each sequence can be broken into segments
of maximum length L. When L is small enough, this effectively permits a time-varying z, as we will
see in section 4.2.
2
Under review as a conference paper at ICLR 2020
2.1	Examples
In order to make the framework more concrete we will describe two general choices of the base
model. In what follows we will write each parameter with a subscript z to denote dependence on
z (e.g. Az := A(z)) to reduce notational clutter. The choice of p(z) and hφ will depend on the
application, but a fairly general choice is a deep latent Gaussian model (Kingma & Welling, 2014;
Rezende et al., 2014). See section A.1.1 in the supplementary material for further discussion.
2.1.1	Multi-Task Linear Dynamical System
For a given z, a multi-task linear dynamical system (MTLDS) can be described by:
xt = Azxt-1 + Bzut + bz + wt,	(4)
yt = Czxt + Dzut + dz + t ,	(5)
Wt 〜N (0,Rz) ,et 〜N (0,Sz), with θz = {Az,Bz, bz,Cz,Dz, dz,Rz,Sz} = hφ(z). The
parameterization of θz must satisfy the constraints of positive definite Rz and Sz and stable Az (i.e.
kAzk2 ≤ 1) for all z, hence projection methods such as in Siddiqi et al. (2008) are not applicable.
We choose an alternative formulation of the LDS, replacing the latent dynamics in eq. (4) by:
xt = ΣzQzxt-1 + Bzut + bz + Wt,	(6)
where Σz is a diagonal matrix and Qz orthogonal with no loss of generality (proof in supp. mat.).
Since kΣzQzk ≤ kΣzkkQzk = kΣz k, stability can be enforced e.g. by Σ = diag{tanh (υ)} for
some vector υ. For more details see section A.1.2 in the supplementary material.
2.1.2	Multi-Task Recurrent Neural Network
Due to the nonlinearity of an RNN, enforcing stability of Az is not strictly required (see e.g. Miller &
Hardt, 2019, §4.4), although bounding the spectral radius may be useful for learning (e.g. Pascanu
et al., 2013). The dynamics ofa multi-task RNN (MT-RNN) are described by:
xt+1 = tanh (Azxt + Bzut + bz).	(7)
Combined with the emission model of eq. (5), we have θz = {Az, Bz, bz, Cz, Dz, dz}. If long-term
dependencies are important we may consider an orthogonal transition matrix (parameterized as for
the MTLDS) to create a multi-task version of the Orthogonal RNN (ORNN, Helfrich et al., 2018).
2.2	Learning
The parameters φ of an MTDS can be learned from a dataset D := {Y (i), U (i)}iN=1 via maximum
marginal likelihood: φ* = argmaxφ PN=I logP(Y(i) | U(i), φ), where
log p(Y | U,φ)
log
p(Y |U, hφ(z)) p(z)
dz.
(8)
Z
The first term in the integrand, P(Y|U, hφ(z)) = JXT P(Y|X, U, hφ(z))P(X|U, hφ(z)) dX is gen-
erally intractable for stochastic dynamics (with notable exceptions of discrete and linear-Gaussian
models). A common approach is to use a variational evidence lower bound (ELBO) see e.g. Fraccaro
etal. (2016); Goyal etal. (2017); Miladinovic etal. (2019) oraMonte Carlo objective (MCO)e.g.
Maddison et al. (2017); Le et al. (2018); Naesseth et al. (2018). For clarity of exposition we only
consider models with deterministic state, which extends to the MTRNN and MTLDS above (in
the case Wt = 0 for all t). This also avoids the interaction effect with the choice of approximate
marginalization over X .
Equation (8) also cannot be computed in closed form in general, and so we resort to approximate
learning. A natural choice is via the ELBO (see an alternative MCO approach for unsupervised tasks
in Section A.1.3, supp. mat.). We write the ELBO of eq. (8) as:
L(Y; φ, λ) = Eqλ(z∣γ,u) [logP(Y|U, hφ(z))] - DKL (qλ(z∣Y U)IlP(Z)),	(9)
where DKL is the Kullback-Leibler divergence and qλ(z|Y, U) an approximate posterior for z. We
can now optimize a lower bound of the marginal likelihood via arg maxφ,λ PiN=1 L(Y(i); φ, λ),
3
Under review as a conference paper at ICLR 2020
where low variance unbiased gradients of eq. (9) are available via reparameterization (Kingma &
Welling, 2014; Rezende et al., 2014) and minibatches of size Nbatch < N. Optimization via Adam
(Kingma & Ba, 2014) proved adequate in our experiments without resorting to any specialized RNN
optimization tricks. A standard choice of qλ(z∖Y, U) is N (μλ(Y, U), Sλ(Y, U)), where μλ, Sλ are
inference networks (e.g. Fabius & van Amersfoort, 2015).
It can be difficult to learn a sensible latent representation if the base model is a powerful RNN.
When each output can be identified unambiguously via the inputs preceding it, a larger ELBO can be
obtained by the RNN learning the relationship without using the latent variable (see e.g. Chen et al.,
2017). A useful heuristic for avoiding such optima is KL annealing (e.g. Bowman et al., 2016). In
our experiments we perform an initial optimization without the KL penalty (second term in eq. 9),
initializing sλ(Y, U) to a small constant value.
2.3	Inference
For an unseen test sequence {Y 0, U0}, the posterior predictive distribution is p(y0t+1:T ∖ y10 :t, u01:T) =
Z p(yt0+1:T ∖ u01:T, z) p(z ∖ y01:t, u01:t) dz, usually estimated via Monte Carlo. The key quantity is
the posterior over z, which may be approximated by the inference networks 模人,Sλ∙ However, for
novel test sequences, the inference networks may perform poorly and standard approximate inference
techniques may be preferred. For further discussion and a description of our inference approach, see
sections A.1.4, A.1.5 in the supp. mat. We note that z may not require inference, for instance by
using the posterior of a sequence in the the training set. This may be useful for artistic control, style
transfer, embedding domain knowledge or overriding misleading observations. We also note that the
latent code can be varied during the state rollout to simulate a task which varies over time.
3	Related Work
A number of dynamical models following the ‘bias customization’ approach have been proposed
recently. MiladinOViC et al. (2019) and HSU et al. (2017) propose models where the biases of an
LSTM cell depend on a (hierarchical) latent variable. Yingzhen & Mandt (2018) propose a dynamical
system where the latent dynamics are concatenated with a time-constant latent variable. In contrast,
oUr MTDS model performs fUll parameter cUstomization, and this on both the dynamics and emission
distribUtions. A nUmber of other proposals may be considered specialized applications of the MTDS.
Bird et al. (2019) Use a small deterministic nonlinear dynamical system for the base model whose
parameters depend on z Using a nonlinear factor analysis strUctUre. Spieckermann et al. (2015) Use a
small RNN as the base model, where the transition matrix depends on z via mUltilinear decomposition.
Lin et al. (2019) Use a small stochastic nonlinear dynamical system with hφ a set of parameter vectors
chosen discretely (or in convex combination) via z.
Controlling and cUstomizing seqUence prediction has received mUch attention in the case of video
data. As in the MTDS, these approaches learn featUres that are constant (or slowly varying) within a
sUbseqUence. Denton & Birodkar (2017) and Villegas et al. (2017) propose methods for disentangling
time-varying and static featUres, bUt do not provide a UsefUl density over the latter, nor an obvioUs
way to cUstomize the Underlying dynamics. TUlyakov et al. (2018) Use a GAN architectUre where z
factorizes into content and motion components. Hsieh et al. (2018) force a parts-based decomposition
of the scene before inferring the latent content z. However, as before, the dynamic evolUtion cannot
be easily cUstomized with these methods.
Hierarchical approaches for dynamical systems with time-varying parameters are proposed in LUttinen
et al. (2014) (corresponding to non-stationary assUmptions) and in Karl et al. (2017) (for the pUrposes
of local LDS approximation). These models, like the MTDS can adapt all the parameters, bUt are
linear and correspond to single task problems. RangapUram et al. (2018) predict the parameters
of simple time-varying LDS models directly via an RNN. While this is a mUlti-task problem, it is
assUmed that all necessary variation can be inferred from the inpUts U.
MUlti-task GPs are commonly Used for seqUence prediction. Examples inclUde those in Osborne
et al. (2008); Titsias & Ldzaro-Gredilla (2011); Alvarez et al. (2012); Roberts et al. (2013). MTGPS
however can only be linear combinations of (a small nUmber of) latent fUnctions, fUrther, predictions
depend critically Upon often Unknown mean fUnctions, and inpUts are not easily integrated. Note that
an MTDS with no inpUts, an LDS base model, a linear-GaUssian prior over the emission parameters
4
Under review as a conference paper at ICLR 2020
Figure 2: (a) Example DHO data for N = 4 training sequences and two test sequences. (b) Samples
from the MTLDS trained on the 4 sequences in 2a, conditioned on the shaded region of test sequence
1 up to t = 15. (c) Posterior predictive density of the same data and model at t = 30. Posterior mean
and 95% C.I. shown in orange, true values shown in dotted blue. (d) Posterior mean and C.I. for the
second test sequence.
and fixed dynamics is an MTGP. In contrast to MTGPs, an MTDS allows much greater flexibility of
the dynamic variation. The MT GP dynamical system of Korkinof & Demiris (2017) mitigates some
of these limitations, but it retains a simple linear combination of latent dynamics with a Gaussian
density over the combination.
Style transfer has been widely explored for mocap data e.g. Hsu et al. (2005); Min et al. (2010); Xia
et al. (2015); Holden et al. (2017a), but in most previous work, generating sequences conditioned on
a trajectory is not possible. For recurrent sequence generation, Fragkiadaki et al. (2015) proposed
multilayer LSTM approaches with an encoding and decoding network. Martinez et al. (2017),
introduced the idea of open loop or ‘sampled’ training (cf. Bengio et al., 2015) in order to avoid
recurrent models converging quickly towards a mean pose. However, style transfer is unavailable
with these methods. A phase-varying nonlinear autoregressive approach was introduced in Holden
et al. (2017b) which was extended in Mason et al. (2018) to provide style transfer, but no quantitative
results are available. We are not aware of any existing work which allows style interpolation.
4	Experiments
We investigate the performance of the MTDS on two datasets. The first experiment investigates the
performance of the MTDS on synthetic data generated by linear superposition of damped harmonic
oscillation (DHO). The second experiment considers real-world mocap data for human locomotion.
4.1	Damped Harmonic Oscillation
Data The generative model for J oscillators with constant amplitudes γ and variable frequency and
decay factors, ω ∈ R+, ρ ∈ (0, 1] is yt(i) = PjJ=1 γj (ρ(ji))t sin(ωj(i)t) + t(i), t = 1, . . . , 80 for tasks
i = 1,2,... ,N. The emission noise is distributed iid as e(i)〜N(0,0.052) and the amplitudes
γ = [1.0, -0.5]. We use J = 2 oscillators with the ‘sequence family’ thus parameterized by a 4-d
space. Details of the generating distribution for ω and ρ are given in supplementary material sec.
A.2.1. See Figure 2(a) for example traces.
Model We model the DHO data using an MTLDS with deterministic state X = R4 and a k = 4
latent variable z. All LDS parameters were adapted via the latent z except D := 0 and the emission
variance s2, which was learned. For optimization, we use the MCO algorithm of section A.1.3. This
can obtain a tighter bound than the ELBO, and is useful to investigate convergence to the true model
over increasing N. We contrast this with a bias customization approach (e.g. Miladinovic et al.,
2019), implemented similarly, but such that only the parameter b (eq. 6) depends on z. We also
train a Pooled LDS, which is the standard approach, using the same parameters for all tasks, and a
single-task (STL) LDS which is learned from scratch using Bayesian inference over all parameters for
each task. The Pooled-LDS was initialized using spectral methods (see Van Overschee & De Moor,
5
Under review as a conference paper at ICLR 2020
	DHO RMSE					
	N=	=4*	N=	二 16	N=	128
Model	t=20	t = 40	t=20	t = 40	t=20	t = 40
Pooled LDS	0.37	0.31	0.36	0.31	0.36	0.31
STL LDS	0.36	0.11	-	-	-	-
LDS MT Bias	0.41	0.33	0.37	0.30	0.33	0.27
LDS MT Full	0.18	0.12	0.11	0.07	0.09	0.06
Table 1: DHO results using LDS models, with training set size N shown. Predictive RMSE after
t = 20, 40. (*) The STL model trains from scratch, and hence on N = 0 sequences.
2012) and then fine tuned using Adam. The STL model requires no training as it is inferred directly
on test data. More details are given in section A.2 in the supplementary material.
Evaluation We assess how quickly and effectively the models can adapt to novel test sequences
with a training set size of N = 21, 22, . . . , 27. (The STL approach effectively uses N = 0.) The
test set comprises 20 additional sequences drawn from the generating distribution. For an initial
subsequence y1:t, we estimate the predictive posterior p(yt+1:T |y1:t) for various t and assess the
predictions via root mean squared error (RMSE) and negative log likelihood (NLL). For MTL we use
the Monte Carlo inference method described in supp. mat. A.1.5 and for STL we use Hamiltonian
Monte Carlo (NUTS, Hoffman & Gelman, 2014). Each experiment is repeated 10 times to estimate
sampling variance.
Results The results, shown in Table 1 and supp. mat. section A.2.2, show substantial advantage
of using the MTLDS (‘MT Full’) over single-task or pooled approaches. The MTLDS consistently
outperforms the Pooled-LDS for all training sizes N ≥ 4. Merely performing bias customization
(‘MT Bias’) is insufficient to perform much better than a pooled approach. An example of MTLDS test
time prediction is shown in Figure 2, with Figures 2c and 2d demonstrating effective generalization
from the N = 4 training examples (Figure 2a). Even after 40 observations, the STL approach (which
is capable of fitting each sequence exactly) does not significantly outperform the N = 4 MTLDS.
Furthermore, the runtime was approx. 1000 times longer since STL inference is higher dimensional
and poorly conditioned, and requires a more expensive algorithm. Note that with a larger training set
size of N = 128, the MLTDS approaches the likelihood of the true model (Figure 7, supp. mat.).
4.2	Mocap Data
Data The dataset consists of 31 sequences from Mason et al. (2018) (ca. 2000 frames average at
30fps) in 8 styles: angry, childlike, depressed, neutral, old, proud, sexy, strutting. In this case the
family of possible sequences corresponds to differing walking styles. Each observation represents
a 21-joint skeleton in a Lagrangian frame, yt ∈ R64 where the root movement is represented by a
smoothed component and its remainder. Following Mason et al. (2018) we represent joints by their
spatial position rather than their rotation. We also provide inputs that an animator may wish to control:
the root trajectory over the next second, the gait cycle and a boolean value determining whether
the skeleton turns around the inside or outside of a corner. See section A.3.1 in the supplementary
materials for more details.
Model We use a recurrent 2-layer base model where the first hidden layer is a 1024 unit GRU (Cho
et al., 2014) and the second hidden layer is a 128 unit standard RNN, follwed by a linear decoding
layer. The first-layer GRU does not vary with z, i.e. it learns a shared representation of the input
sequence across all i. Explicitly, omitting index i, the model for a given z is:
[ψ2, C, d] = hφ(z),	(10)
x1,t = GRUCell1024{state= x1,t-1, input= ut; ψ1},	(11)
x2,t = RNNCell128 {state= x2,t-1, input=Hx1,t-1; ψ2},	(12)
yt = C X2,t + d,	(13)
6
Under review as a conference paper at ICLR 2020
Target	MT Bias	MTDS
Angry	0.78	0.86
Child	0.59	0.95
Depr.	0.65	0.81
Neut.	0.79	0.93
Old	0.55	0.86
Proud	0.71	0.82
Sexy	0.55	0.90
Strut	0.71	0.92
(a)	(b)
(c)
Figure 3: (a) Mocap Experiment 1: out-of-sample MSE by % of training set seen. The performance
achieved by the GRU models for the entire training set is shown as the ‘Optimal’ dashed line. (b)
Experiment 2: MSE performance (avg over LOO), truncated for clarity, see supp. mat. for the full
range. (c) Experiment 3: Classifier probability of target style averaged over all input styles.
for t = 1, . . . , T. The parameters are θ = {ψ1, ψ2, H, C, d} where ψ1 and H are constant wrt. z.
The matrix H ∈ R'×1024 (' < 1024) induces a bottleneck between layers, forcing Z to explain more
of the variance. For our experiments, a small ` can be used (we use ` = 24). The first layer GRU
uses 1024 units since it was observed experimentally to produce smoother animations than smaller
networks. The second layer does not use a gated architecture, as gates appear to learn style inference
more easily, and result in less use of z.
For learning, each sequence was broken into overlapping segments of length 64 (approx. two second
intervals), which allows z to vary across a sequence. We learn the model using an open-loop objective,
i.e. the yt are not appended to the inputs. This forces the model to recover from its mistakes as in
Martinez et al. (2017), although unlike these approaches, we do not append predictions to the inputs
either. Our rationale is that the state captures the same information as the predictions, and while
previous approaches required observations yi：T as inputs to seed the state, We can use the latent z.
The model was optimized using the variational procedure in section 2.2, where a slower learning rate
(by a factor of 10-50) for the first layer parameters (i.e. ψ1, H) usually resulted in a more descriptive
z. We also found that standard variational inference for each z(i) worked better in general than using
amortized inference.
For comparison, we implement a bias customization model (‘MTBias’) via a deterministic state
version of MiladinOViC et al., 2019, which follows eqs. (10)-(13) but only the RNN bias in eq. (12) is a
function of z. We also implement a 1-layer and 2-layer GRU without the multi-task apparatus, which
serves both as an ablation test and a competitor model (Martinez et al., 2017) on the new dataset.
Style inference is performed with the same network given an initial seed sequence yi：T. We train
these in closed-loop (i.e. traditional next step ‘teacher forcing’ criterion) and open-loop (Martinez
et al., 2017) settings. For baselines, we use constant predictions of (i) the training set mean and (ii)
the last observed frame of the seed sequence (‘zero-velocity’ prediction).
Experiment 1 We test the data efficiency of the MTDS by training the models on subsets of the
original dataset. Besides the models described above, 8 ‘single-task’ versions of the GRU models
are trained which only see data for a single style. We use six training sets of approximate size
28, 29, 2i0, 2ii, 2i2, 2i3 frames per style, where sampling is stratified carefully across all styles, and
major variations thereof. For all experiments, the model fit (MSE) is calculated from the same
32 held out sequences (each of length 64). The results are shown in Figure 3a. As expected, the
MTDS, MTBias and Pooled models obtain ‘multi-task’ gains over STL approaches for small datasets.
However, the MTDS demonstrates much greater data efficiency, achieving close to the minimum
error with only 7% of the dataset. The MTBias model requires more than twice this amount to obtain
the same performance, and the Pooled model requires more than four times this amount. More details,
as with all mocap experiments, can be found in supp. mat. section A.2.3.
7
Under review as a conference paper at ICLR 2020
Experiment 2 We investigate how well the MTDS can generalize to novel sequence styles via use
of a leave-one-out (LOO) setup, similar to transfer learning. For each test style, a model is trained
on the other 7 styles in the training set, and hence encounters novel sequence characteristics at test
time. We average the test error over the LOO folds as well as 32 different starting locations on each
test sequence. The results are given in Figure 3b. We see that while the competitor (pooled) models
perform well initially, they usually degrade quickly (worse for closed-loop models). In contrast,
the multi-task models finds a better customization which evidences no obvious worsening over the
predictive interval. Unlike pooled-RNNs, the MTDS and MTBias models can firstly perform correct
inference of their customization, and secondly can ‘remember’ it over long intervals. We note that all
models struggle to customize the arms effectively, since their test motions are often entirely novel.
Customization to the legs and trunk is easier since less extrapolation is required (see animation videos
linked in section A.4.1).
Experiment 3 We investigate the control available in the latent z by performing style transfer. For
various inputs U(s1) from each source style s1, we generate predictions from the model using target
style s2, encoded by z(s2). We use a classifier with multinomial outputs, trained on the 8 styles of
the training set, to test whether the target style s2 can be recognized from the data generated by the
MTDS. Figure 3c gives the classifier ‘probability’ for each target style s2, averaged over all the
inputs {U(s1) : s1 6= s2}. Successful style transfer should result in a the classifier assigning a high
probability to the target style. These results suggest that the prediction style can be well controlled by
z(s2) in the case of the full MTDS, but the MTBias demonstrates reduced control for some (source,
target) pairs. See the videos linked in section A.4.1 for examples, and sec. A.2.3 for more details.
Qualitative investigation Qualitatively, the MTDS appears to learn a sensible manifold of walking
styles, which we assess through visualization of the latent space. A k = 2 latent embedding can be
seen in Figure 4 where the z(i) for each training segment i is coloured by the true style label. Some
example motions are plotted in the figure.
The MTDS embedding broadly respects
the style label, but learns a more nu-
anced representation, splitting some la-
bels into multiple clusters and coalescing
others. These appear broadly valid, e.g.
the ‘proud’ style contains both marching
and arm-waving, with the latter similar
to an arm-waving motion in the ‘child-
like’ style. This highlights the limitation
of relying on task labels. Visualizations
such as Fig. 1b indicate that smooth style
interpolation is available via interpola-
tion in latent space. We take advantage
of this in the animations (linked from sec.
A.4.1) by morphing styles dynamically.
2
(hunched)
(arm-waving)
-2.0 -1.5 -1.0 -0.5	0.0	0.5	1.0	1.5	2.0
Figure 4: k = 2 mean embedding of each se-
quence segment, coloured by its (unseen) task
label.
(arm-swinging)
(hip-swaying)
5	Conclusion
In this work we have shown how to extend dynamical systems with a general-purpose hierarchical
structure for multi-task learning. Our MTDS framework performs customization at the level of all
parameters, not just the biases, and adapts all parameters for general classes of dynamical systems.
We have seen that the latent code can learn a fine-grained embedding of sequence variation and can
be used to modulate predictions.
Clearly good predictive performance for sequences requires task inference, whether implicit or
explicit. There are three advantages of making this inference explicit. Firstly, it enhances control over
predictions. This might be used by animators to control the style of predictions for mocap models,
or to express domain knowledge, such as ensuring certain sequences evolve similarly. Secondly, it
can improve generalization from small datasets since task interpolation is available out-of-the-box.
Thirdly, it can be more robust against changes in distribution at test time than a pooled model:
8
Under review as a conference paper at ICLR 2020
standard inference techniques or human supervision can guard against poor performance of the
implicit inference.
References
MaUriCio A Alvarez, Lorenzo Rosasco, and Neil D Lawrence. Kernels for Vector-Valued Functions: A Review.
Foundations and Trends® in Machine Learning, 4(3):195-266, 2012.
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. Scheduled Sampling for Sequence Prediction
with Recurrent Neural Networks. In Advances in Neural Information Processing Systems 28, pp. 1171-1179,
2015.
Alex Bird, Christopher K. I. Williams, and Christopher Hawthorne. Multi-Task Time Series Analysis applied to
Drug Response Modelling. In The 22nd International Conference on Artificial Intelligence and Statistics,
2019.
Samuel Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio. Generating
Sentences from a Continuous Space. In Proceedings of the Twentieth Conference on Computational Natural
Language Learning (CoNLL)., 2016.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance Weighted Autoencoders. In Proceedings of
the International Conference on Learning Representations (ICLR), 2016.
Olivier Capp6, Randal Douc, Arnaud Guillin, Jean-Michel Marin, and Christian P Robert. Adaptive Importance
Sampling in General Mixture Classes. Statistics and Computing, 18(4):447-459, 2008.
Xi Chen, Diederik P Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, and
Pieter Abbeel. Variational Lossy Autoencoder. 2017.
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk,
and Yoshua Bengio. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine
Translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing
(EMNLP), 2014.
Nicolas Chopin. A Sequential Particle Filter Method for Static Models. Biometrika, 89(3):539-552, 2002.
Pierre Del Moral, Arnaud Doucet, and Ajay Jasra. Sequential Monte Carlo Samplers. Journal of the Royal
Statistical Society: Series B (Statistical Methodology), 68(3):411-436, 2006.
Emily L Denton and Vighnesh Birodkar. Unsupervised Learning of Disentangled Representations from Video. In
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances
in Neural Information Processing Systems 30, pp. 4414-4423. 2017.
Otto Fabius and Joost R van Amersfoort. Variational Recurrent Auto-Encoders. In Proceedings of the Interna-
tional Conference on Learning Representations (ICLR), 2015.
MarCo Fraccaro, S0ren Kaae S0nderby, Ulrich Paquet, and Ole Winther. Sequential Neural Models with
Stochastic Layers. In Advances in Neural Information Processing Systems 29, pp. 2199-2207, 2016.
Katerina Fragkiadaki, Sergey Levine, Panna Felsen, and Jitendra Malik. Recurrent Network Models for Human
Dynamics. In Proceedings of the IEEE International Conference on Computer Vision, pp. 4346-4354, 2015.
Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. Bayesian
Data Analysis. CRC Press, 3rd edition, 2013.
Partha Ghosh, Jie Song, Emre Aksan, and Otmar Hilliges. Learning Human Motion Models for Long-Term
Predictions. In 2017 International Conference on 3D Vision (3DV), pp. 458-466. IEEE, 2017.
Walter R Gilks and Carlo Berzuini. Following a Moving Target - Monte Carlo Inference for Dynamic Bayesian
Models. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63(1):127-146, 2001.
Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT press, 2016.
Anirudh Goyal, Alessandro Sordoni, Marc-Alexandre C6t6, Nan Rosemary Ke, and Yoshua Bengio. Z-Forcing:
Training Stochastic Recurrent Networks. In Advances in Neural Information Processing Systems 30, pp.
6713-6723, 2017.
Alex Graves. Generating Sequences with Recurrent Neural Networks. arXiv preprint arXiv:1308.0850, 2013.
9
Under review as a conference paper at ICLR 2020
Kyle Helfrich, Devin Willmott, and Qiang Ye. Orthogonal Recurrent Neural Networks with Scaled Cayley
Transform. In International Conference on Machine Learning, pp. 1974-1983, 2018.
Matthew D Hoffman and Andrew Gelman. The No-U-Turn Sampler: Adaptively Setting Path Lengths in
Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1):1593-1623, 2014.
Daniel Holden, Jun Saito, and Taku Komura. A Deep Learning Framework for Character Motion Synthesis and
Editing. ACM Transactions on Graphics (TOG), 35(4):138, 2016.
Daniel Holden, Ikhsanul Habibie, Ikuo Kusajima, and Taku Komura. Fast Neural Style Transfer for Motion
Data. IEEE Computer Graphics and Applications, 37(4):42-49, 2017a.
Daniel Holden, Taku Komura, and Jun Saito. Phase-Functioned Neural Networks for Character Control. ACM
Transactions on Graphics (TOG), 36(4):42, 2017b.
Jun-Ting Hsieh, Bingbin Liu, De-An Huang, Li F Fei-Fei, and Juan Carlos Niebles. Learning to Decompose and
Disentangle Representations for Video Prediction. In Advances in Neural Information Processing Systems 31,
pp. 517-526, 2018.
Eugene Hsu, Kari Pulli, and Jovan PopoviC. Style Translation for Human Motion. In ACM Transactions on
Graphics (TOG), volume 24, pp. 1082-1089. ACM, 2005.
Wei-Ning Hsu, Yu Zhang, and James Glass. Unsupervised Learning of Disentangled and Interpretable Represen-
tations from Sequential Data. In Advances in Neural Information Processing Systems 30, pp. 1876-1887.
2017.
Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt. Deep Variational Bayes Filters:
Unsupervised Learning of State Space Models from Raw Data. In International Conference on Learning
Representations, 2017.
Robert E Kass and Adrian E Raftery. Bayes factors. Journal of the American Statistical Association, 90(430):
773-795, 1995.
IJ Khuri, I Andre, et al. The Parameterization of Orthogonal Matrices: A Review Mainly for Statisticians. South
African Statistical Journal, 23(2):231-250, 1989.
Diederik P Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. In Proceedings of the 2nd
International Conference on Learning Representations (ICLR), 2014.
Diederik P Kingma and Max Welling. Auto-Encoding Variational Bayes. In Second International Conference
on Learning Representations, ICLR, 2014.
Dimitrios Korkinof and Yiannis Demiris. Multi-Task and Multi-Kernel Gaussian Process Dynamical Systems.
Pattern Recognition, 66:190-201, 2017.
Tuan Anh Le, Maximilian Igl, Tom Rainforth, Tom Jin, and Frank Wood. Auto-Encoding Sequential Monte
Carlo. In International Conference on Learning Representations, 2018.
Christiane Lemieux. Monte Carlo and Quasi-Monte Carlo Sampling. Springer, 2009.
Alexander Lin, Yingzhuo Zhang, Jeremy Heng, Stephen A Allsop, Kay M Tye, Pierre E Jacob, and Demba Ba.
Clustering Time Series with Nonlinear Dynamics: A Bayesian Non-Parametric and Particle-Based Approach.
In The 22nd International Conference on Artificial Intelligence and Statistics, 2019.
Jaakko Luttinen, Tapani Raiko, and Alexander Ilin. Linear State-Space Model with Time-Varying Dynamics.
In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 338-353.
Springer, 2014.
Chris J Maddison, John Lawson, George Tucker, Nicolas Heess, Mohammad Norouzi, Andriy Mnih, Arnaud
Doucet, and Yee Teh. Filtering Variational Objectives. In Advances in Neural Information Processing Systems
30, pp. 6573-6583, 2017.
Julieta Martinez, Michael J Black, and Javier Romero. On Human Motion Prediction Using Recurrent Neural
Networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2891-
2900, 2017.
Ian Mason, Sebastian Starke, He Zhang, Hakan Bilen, and Taku Komura. Few-Shot Learning of Homogeneous
Human Locomotion Styles. In Computer Graphics Forum, volume 37, pp. 143-153. Wiley Online Library,
2018.
10
Under review as a conference paper at ICLR 2020
Dorde MiladinoviC, MUhammad Waleed GondaL Bemhard Scholkopf, Joachim M. Buhmann, and Stefan Bauer.
Disentangled State Space Representations. arXiv e-prints, art. 1906.03255, Jun 2019.
John Miller and Moritz Hardt. Stable Recurrent Models. In International Conference on Learning Representa-
tions, 2019.
Jianyuan Min, Huajun Liu, and Jinxiang Chai. Synthesis and Editing of Personalized Stylistic Human Motion.
In Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games. ACM,
2010.
Andriy Mnih and Danilo Rezende. Variational Inference for Monte Carlo Objectives. In International Conference
on Machine Learning, pp. 2188-2196, 2016.
Christian Naesseth, Scott Linderman, Rajesh Ranganath, and David Blei. Variational Sequential Monte Carlo.
In International Conference on Artificial Intelligence and Statistics, pp. 968-977, 2018.
Manfred Opper and Ole Winther. A Bayesian Approach to On-line Learning. pp. 363-378. 1998.
Michael A Osborne, Stephen J Roberts, Alex Rogers, Sarvapali D Ramchurn, and Nicholas R Jennings. Towards
Real-Time Information Processing of Sensor Network Data Using Computationally Efficient Multi-Output
Gaussian Processes. In Proceedings of the 7th International Conference on Information Processing in Sensor
Networks, pp. 109-120. IEEE Computer Society, 2008.
Art B. Owen. Monte Carlo Theory, Methods and Examples. 2013.
Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the Difficulty of Training Recurrent Neural Networks.
In International Conference on Machine Learning, pp. 1310-1318, 2013.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin,
Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic Differentiation in PyTorch. 2017.
Dario Pavllo, David Grangier, and Michael Auli. Quaternet: A Quaternion-Based Recurrent Model for Human
Motion. In Proceedings of the British Machine Vision Conference (BMVC), 2018.
JosC C Pinheiro and Douglas M Bates. Unconstrained Parametrizations for Variance-Covariance Matrices.
Statistics and Computing, 6(3):289-296, 1996.
Urs Ramer. An Iterative Procedure for the Polygonal Approximation of Plane Curves. Computer Graphics and
Image Processing, 1(3):244-256, 1972.
Syama Sundar Rangapuram, Matthias W Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang Wang, and Tim
Januschowski. Deep State Space Models for Time Series Forecasting. In Advances in Neural Information
Processing Systems 31, pp. 7785-7794, 2018.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic Backpropagation and Approximate
Inference in Deep Generative Models. In International Conference on Machine Learning, pp. 1278-1286,
2014.
Stephen Roberts, Michael Osborne, Mark Ebden, Steven Reece, Neale Gibson, and Suzanne Aigrain. Gaussian
Processes for Time-Series Modelling. Philosophical Transactions of the Royal Society A: Mathematical,
Physical and Engineering Sciences, 2013.
Sohan Seth, Iain Murray, and Christopher KI Williams. Model Criticism in Latent Space. arXiv preprint
arXiv:1711.04674, 2017.
Sajid M Siddiqi, Byron Boots, and Geoffrey J Gordon. A Constraint Generation Approach to Learning Stable
Linear Dynamical Systems. Technical report, DTIC Document, 2008.
Sigurd Spieckermann, Siegmund Dull, Steffen Udluft, Alexander Hentschel, and Thomas Runkler. Exploiting
Similarity in System Identification Tasks with Recurrent Neural Networks. Neurocomputing, 169:343-349,
2015.
Steven H Strogatz. Nonlinear Dynamics and Chaos: with Applications to Physics, Biology, Chemistry, and
Engineering. CRC Press, 2018.
Johan F.M. SvCnsen. GTM: the Generative Topographic Mapping. PhD thesis, Aston University, 1998. URL
http://publications.aston.ac.uk/id/eprint/1245/.
Michalis K Titsias and Miguel Ldzaro-Gredilla. Spike and Slab Variational Inference for Multi-Task and Multiple
Kernel Learning. In Advances in Neural Information Processing Systems 24, pp. 2339-2347, 2011.
11
Under review as a conference paper at ICLR 2020
Nathaniel Tomasetti, Catherine Forbes, Anastasios Panagiotelis, et al. Updating Variational Bayes: Fast
Sequential Posterior Inference. Technical report, Monash University, Department of Econometrics and
Business Statistics, 2019.
Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz. MoCoGAN: Decomposing Motion and Content
for Video Generation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pp.1526-1535,2018.
Peter Van Overschee and BL De Moor. Subspace Identification for Linear Systems: Theory-Implementation-
Applications. Springer Science & Business Media, 2012.
Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, and Honglak Lee. Decomposing Motion and Content
for Natural Video Sequence Prediction. In International Conference on Learning Representations, 2017.
Shihong Xia, Congyi Wang, Jinxiang Chai, and Jessica Hodgins. Realtime Style Transfer for Unlabeled
Heterogeneous Human Motion. ACM Transactions on Graphics (TOG), 34(4):119, 2015.
Lei Xu and Michael I Jordan. On Convergence Properties of the EM Algorithm for Gaussian Mixtures. Neural
Computation, 8(1):129-151, 1996.
Li Yingzhen and Stephan Mandt. Disentangled Sequential Autoencoder. In International Conference on Machine
Learning, pp. 5656-5665, 2018.
Yu Zhang and Qiang Yang. A Survey on Multi-Task Learning. arXiv preprint arXiv:1707.08114, 2017.
12
Under review as a conference paper at ICLR 2020
A	Supplementary Material
A.1 Model
In this section we elaborate on some aspects of the MTDS model which were omitted from the
main text. We discuss the choice of the prior in section A.1.1, give further details of the MTLDS
parameterization in section A.1.2, provide an alternative learning algorithm in section A.1.3 (which
is especially suited for unsupervised models), and discuss choices of inference algorithm in sections
A.1.4-A.1.5.
A.1.1 Choice of Prior
The usual choice of p(z) in latent variable models following Kingma & Welling (2014); Rezende
et al. (2014) is a unit Gaussian p(z) = N (0, I). This choice allows simple sampling schemes, and
straight-forward posterior approximations. It is also a useful choice for interpolation, since it allows
continuous deformation of its outputs. An alternative choice might be a uniform distribution over
a compact set, however posterior approximation is more challenging, see SVensen (1998) for one
approach.
Sensible default choices for hφ include affine operators and multilayer perceptrons (MLPs). However,
when the parameter space Rd is large, it may be infeasible to predict d outputs from an MLP. Consider
an RNN with 100k parameters. If an MLP has mL-1 = 300 units in the final hidden layer, the
expansion to the RNN parameters in the final layer will require 30 × 106 parameters alone. A practical
approach is to use a low rank matrix for this transformation, equivalent to adding an extra linear layer
of size mL where we must have mL mL-1 to reduce the parameterization sufficiently. Since we
will typically need mL to be O(10), we are restricting the parameter manifold of θ to lie in a low
dimensional subspace.
Since MLP approaches with a large base model will then usually have a restricted final layer, are there
any advantages over a simple linear-Gaussian model for the prior p(z) and hφ? There may indeed be
many situations where this simpler model is reasonable. However, we note some advantages of the
MLP approach:
1.	The MLP parameterization can shift the density in parameter space to more appropriate
regions via nonlinear transformation.
2.	A linear space of recurrent model parameters can yield highly non-linear changes even to
simple dynamical systems (see e.g. the bifurcations in §8 of Strogatz, 2018). We speculate
it might be advantageous to curve the manifold to avoid such phenomena.
3.	More expressive choices may help utilization of the latent space (e.g. Chen et al., 2017).
This may in fact motivate moving beyond a simple MLP for the hφ.
A.1.2 Multi-Task Linear Dynamical System Parameterization
The matrices A, B , R, S of the MTLDS can benefit from specific parameterizations, which we will
discuss in turn.
Degeneracy of LDS. It will be useful to begin with the well-known over-parameterization of linear
dynamical systems. The hidden dynamics of a LDS can be transformed by any invertible matrix G
while retaining the same distribution over the emissions Y . This follows essentially because the basis
used to represent X is arbitrary. The distribution over Y is unchanged under the following parameter
transformations:
A 一 GTAG,	C一 CG,
B 一 G-1B,	D	一 D,
b 一 G-1b,	d	一 d,
R 一 G-1RG-T,	S	一 S.
(14)
13
Under review as a conference paper at ICLR 2020
Parameterization of A. The stability constraint,
kAk2 ≤ 1,	(15)
is equivalent to ensuring that the singular values of A lie within the unit hypercube (since singular
values are non-negative). Let A = UΣVT be the singular value decomposition (SVD) of A. Now we
have from the previous result that if an LDS has latent dynamics with transition parameter A, we may
replace the dynamics under the similarity transform G-1AG. Choose G = U, i.e. the left singular
values of A, and hence A = ΣVTU =: ΣQ for some orthogonal matrix Q. This follows from the
closure of the orthogonal group under multiplication, which is easily verified. Note that in choosing
this transformation, no additional constraints are placed on the other parameters in the LDS.
Orthogonal matrices can be parameterized in a number of ways (see e.g. Khuri et al., 1989). A
straight-forward choice is the Cayley transform. From Khuri et al. (1989): “if Q is an orthogonal
matrix that does not have the eigenvalue -1, then it may be written in Cayley’s form:
Q=(I-S)(I+S)-1,	(16)
where S is skew-symmetric”. In order to permit negative eigenvalues, we can pre-multiply by a
diagonal matrix E with elements in {+1, -1}. Since we then have A = ΣEQ, E can be absorbed
into Σ, and so the stability constraint (15) can be satisfied with the parameterization A = ΣQ where
Σ is a diagonal matrix with elements in [-1, +1] and Q is a Cayley-transform of a skew-symmetric
matrix. This follows from the overparameterization of the LDS, and we emphasise that the system
equations (4) and (6) are not equivalent, but any LDS distribution over Y can be written with latent
dynamics of the form (6).
Parameterization of B. Choose G = κ-1I in eq. (14). It may be observed that the scale κ of the
latent system can be chosen arbitrarily without affecting A. We wish to avoid such degeneracies in a
hierachical model, since we may otherwise waste statistical strength and computation on learning
equivalent representations. We can remove this by fixing the scale of B . An indirect but straight-
forward approach is to upper bound the magnitude of each element of B. For B predicted by
hφ (z) we might choose the transformation B = tanh(B) where tanh acts element-wise. If a
sparse B is desired, one can use an over-parameterization of two matrices B1,B2, and choose
B = σ(B1) ◦ tanh(B2), where ◦ is element-wise multiplication, and σ a logistic sigmoid. The
former parameterization is unlikely to find a sparse representation since the gradient of tanh is
greatest at 0.
Parameterization of R, S. The covariance matrices R, S must be in the positive definite cone.
Where a diagonal covariance will suffice, any parameterization for enforcing positivity can be used,
such as exponentiation, squaring or softplus. A number of parameterizations are available for full
covariance matrices (see Pinheiro & Bates, 1996). A simple choice is to decompose the matrix, say
R = LLT, where L is a lower triangular Cholseky factor. As before, it is useful to enforce uniqueness,
which can be done by ensuring the diagonal is positive.
A.1.3 Learning via a Monte Carlo Objective
We provide an alternative learning algorithm to the VB approach in section 2.2 which obtains a tighter
lower bound. This was important for the DHO experiments in order to monitor convergence to the
true model. The below is perhaps a novel approach for learning in unsupervised cases (i.e. where
U = 0), but cannot be performed efficiently for supervised problems without modification.
Monte Carlo Objectives (MCOs, Mnih & Rezende, 2016) construct a lower bound for marginal
likelihoods via a transformation of an appropriate Monte Carlo estimator. Specifically we consider
the logarithmic transformation of:
p(Y ) ≈
1 X P(Y, Zm)
M m=1 P(Zm)
1M
M X P(YI Zm)
for Zm 〜p(z),
(17)
14
Under review as a conference paper at ICLR 2020
m = 1, . . . , M; an importance sampling estimator for p(Y ). Using Jensen’s inequality, we show that
the following is a lower bound on the log marginal likelihood:
LMCO := Ep(z1:M)
1M
log M Ep(YI Zm)
1M
≤ log Ep(ZIM) MEp(YI Zm)
log p(Y)
(18)
where p(Z1:M) := p(Z1)...p(ZM). The tightness of the bound can be increased by increasing the
number of samples M (Burda et al., 2016). Assuming p(Z) has been re-parameterized (Kingma &
Welling, 2014) to be parameter-free, we can easily calculate the gradient (if not, see Mnih & Rezende,
2016). By exchanging integration and differentiation, we can calculate the gradient as:
M
VφLMC0 =[…L
1M
vΦ log M Ep(YI Zm)
m=1
p(Z1) ...p(ZM) dZ1:M
E	∣Vφ PM=1 p(Y∣ Zm) 一
P(ZIM) [ PM=Ip(YI Zm) J
E	∣^PM=1 p(Y 1 ZmyVφ logp(Y 1 Zm)
Ep(ZIM)	M
m0=1p(Y IZm0)
M
Ep(Z1:M) E WmVφ logp(Y ∣ Zm),
m=1
(19)
(20)
(21)
(22)
where Wm = p(Y ∣ Zm)/ PMο=ι p(Y ∣ Zm/). Note that eq.(22) is an importance sampled version of
the Fisher identity.
We might expect this estimator to suffer from high variance, since the prior is a poor proposal for
the posterior. However, the prior should not be a poor proposal for the aggregate posterior, i.e.
N PN=I p(z IY(i)) (see Seth et al., 2017). In fact, importance sampling from the prior may serve as a
useful bias in this case, attracting the posterior distributions which have a large DKL(p(Z I Y(i))IIp(Z))
towards the prior.
Our observation is that sampling from the prior can be amortized over each sequence Y(i), i =
1, . . . , N . Specifically, for each particle Zm , the dynamics (2), (3) can be run forward once to calculate
Ym, from which the likelihood Y(i), for all tasks i = 1,...,N can be calculated inexpensively. The
amortized cost of taking M samples (e.g. M ∈ O(103)) now becomes M/N, which may be relatively
small. We can also take advantage of low-discrepancy random variates such as Sobol sequences
(Lemieux, 2009) to reduce variance. We propose that each sequence i resamples a small number
Mrsmp ≤ 5 of particles from the importance weights for each i to reduce the cost of backpropagation
(a similar resampling scheme is suggested in Burda et al., 2016). See Algorithm 1.
In the supervised case (i.e. where each observation Y(i) has a different input U(i)), running the
dynamics forward from a particle Zm can no longer be amortized over all {Y(i)} since the prediction
Y(i) depends on U(i). We can therefore only amortize the parameter generation θ = hφ(z), which is
often less expensive than running the dynamics forward. For this reason Algorithm 1 is primarily
restricted to unsupervised problems. A hybrid approach would essentially result in the importance
weighted autoencoder (IWAE) of Burda et al. (2016).
A.1.4 Inference
Inference at test time can be performed by any number of variational or Monte Carlo approaches.
As in the main text, our focus here is on deterministic state dynamical systems. For stochastic state
models, additional reasoning similar to Miladinovic et al. (2019) will be required.
A gold standard of inference over Z may be the No U-Turn Sampler (NUTS) of Hoffman & Gelman
(2014) (a form of Hamiltonian Monte Carlo), provided k is not too large and efficiency is not a
concern. However, given the sequential nature of the model, it is natural to consider exploiting the
posterior at time t for calculating the posterior at time t + 1. Bayes’ rule suggests an update of the
15
Under review as a conference paper at ICLR 2020
Algorithm 1: Importance Sampled Optimization for Unsupervised MTDS
Result: Optimized parameter φ
Inputs: {Y (i) }iN=1 , φ, M, Mrsmp, nepochs, optimizer;
for epoch = 1:nepochs do
for minibatch S in {1, . . . , N} do
// calculate posterior samples;
Zm S吧* 1 p(z), m =1,...,M；
W J COnStruCt_WeightS (logP(Y = ∙ | hφ(∙)), {zm}M=ι,{Y(i)}i∈S;
// compute gradient;
gJ0;
for i in S do
for m in {1, . . . , Mrsmp} do
i 〜CategOriCaI (W(i))；
g + = M11mp vφ log p(Y (i)1 hΦ(Zi))；
end
end
Optimize(optimizer, φ, g)；
end
end
following form:
P(Z | y1：t+i, ui：t+i) X p(yt+ι | ui：t+i, hΦ(Z))P(Z | y1 ：t, ui：t),	(23)
following the conditional independence assumptions of the MTDS. This update (in principle) incor-
porates the information learned at time t in an optimal way, and further suggests a constant time
update wrt t. However, evaluation of P(yt0+1 | u01:t+1, hφ(Z)) usually scales linearly with t, since
the state xt+1 must be calculated recursively from x0 given Z and u01:t+1. Nevertheless, sequential
incorporation of previous information will perform a kind of annealing (Chopin, 2002) which reduces
the difficulty, and hopefully the runtime of inference at each stage.
We first provide some background of the difficulties of such an approach, looking first at Monte Carlo
(MC) methods. Naive application of Sequential Monte Carlo (SMC) will result in severe particle
depletion over time. To see this, let the posterior after time t be P(Z | y1 ：t, uJJ =吉 PM=I wmδ(Z-
Zm). Then the updated posterior at time t + 1 will be:
1M
P(Z | y10:t+1
, u1:t+1)X MfwmP(y+1 | ut+1, hφ(Z))δ(Z — Zm),	(24)
m=1
0	0	1M
⇒ P(z 1 yi:t+1, u1:t+1) = M EwmNz - Zm),	(25)
m=1
where wm = Mmp(yt+ι0l ut+1,hφ(Zm)) , simply a re-weighting of existing particles. Over time, the
j=1 wjp(yt0+1 | u0t+1,hφ(zj))
number of particles with significant weights wm will substantially reduce. But since the model is
static with respect to Z (see Chopin, 2002), there is no dynamic process to ‘jitter’ the {Zm} as in a
typical particle filter, and hence a resampling step cannot improve diversity.
Chopin (2002) discusses two related solutions: firstly using ‘rejuvenation steps’ (cf. Gilks & Berzuini,
2001) which applies a Markov transition kernel to each particle. The downside to this approach is
the requirement to run until convergence； and the diagnosis thereof, which can result in substantial
extra computation. One might instead sample from a fixed proposal distribution (accepting a move
with the usual Metropolis-Hastings probability) for which convergence is more easily monitored. A
Sequential Monte Carlo sampler approach (Del Moral et al., 2006) may be preferred, which permits
local moves, and can reduce sample impoverishment via resampling (similar to SMC). However, the
approach requires careful choices of both forward and backward Markov kernels which substantially
reduces its ease of use.
16
Under review as a conference paper at ICLR 2020
A well-known variational approach to problems with the structure of eq. (23) is assumed density
filtering (ADF, see e.g. Opper & Winther, 1998). For each t, ADF performs the Bayesian update
and the projects the posterior into a parametric family Q. The projection is done with respect to
the reverse KL Divergence, i.e. qt+1 = arg minq∈Q DKL p(z | y10 :t+1, u01:t+1) || q . Intuitively, the
projection finds an ‘outer approximation’ of the true posterior, avoiding the ‘mode seeking’ behaviour
of the forward KL, which is particularly problematic if it attaches to the wrong mode. Clearly the
performance of ADF depends crucially on the choice of Q. Unfortunately, where Q is expressive
enough to capture a good approximation, the optimization problem will usually be challenging, and
must resort to stochastic gradient approaches, resulting in an expensive inner loop. Furthermore,
when the changes from qt to qt+1 are relatively small, the gradient signal will be weak, resulting
perhaps in misdiagnosed convergence and hence accumulation of error over increasing t. A recent
suggestion of Tomasetti et al. (2019) is to improve efficiency via re-use of previous (stale) gradient
evaluations. Standard variance reduction techniques may also be considered to improve convergence
in the inner loop.
A.1.5 Online Inference - OUR approach
In our experiments, we found sampling approaches faster and more reliable for each update, as well as
providing diagnostic information, and so we eschew variational approaches. (Our experiments used
a fairly small k (≤ 10); variational approaches may be preferred in higher dimensional problems.)
Specifically we use iterated importance sampling (IS) to update the posterior at each t. The key
quantity for IS is the proposal distribution qprop: we need a proposal that is well-matched to the target
distribution. Our observation is that the natural annealing properties of the filtering distributions (eq.
23) allow a slow and reliable adaptation of qprop.
In order to capture complex multimodal posteriors, we parameterize qprop by a mixture of Gaussians
(MoG). For each t, the proposal distribution is improved over NAIS iterations using adaptive impor-
tance sampling (AdaIS), described for mixture models in CaPPe et al. (2008). We briefly review
the methodology for a target distribution p*. Let the AdaIS procedure at the nth iteration use the
ProPosal:
J
qprop(z) := X ajN (μ", ∑n) ,	(26)
j=1
αj ∈ R+ s.t. Pj=I αj = 1. For iteration n, sample Zm 〜qn-1, m = 1,...,M, and calculate
the (self-normalized) importance weights Wm a p*(zm,)∕qpr-1(zm,). The resulting empirical dis-
tribution is then used to fit qn+1, estimating {ajn+1, μn+1, ∑n+1}J=ι Via (weighted) Expectation
Maximization (EM, see cappe et al., 2008, for details). We monitor the effective sample size (ESS,
see ch. 9, Owen, 2013) every iteration and stop once the ESS has reached a certain threshold Mess,
see Algorithm 2.
For our experiments, this approach worked robustly and efficiently, and appears superior to the
alternatives discussed. Unlike SMc, we obtain a qprop which is a good parameteric approximation
of the true posterior. We therefore avoid the sample impoverishment problem discussed above (eq.
25). Due to the small number of iterations of AdaIS required (usually ≤ 5 for our problems), it is
substantially faster than McMc moves, and since stochastic gradients are avoided, convergence
is much faster than variational approaches. The scheme benefits from the observed fast initial
convergence rates of the EM algorithm (see e.g. Xu & Jordan, 1996), particularly since early stopping
can be used for the initial iterates.
In practice, one may not wish to calculate a posterior at every t, but instead intervals of length
τ. In our DHO experiments (k = 4) we use τ = 5, and usually have ESS > 0.6M after n = 4
inner iterations, with total computation per qt requiring 250-300ms on a laptop. We observe in our
experiments that posteriors are often multimodal for t ≤ 20 and sometimes beyond, motivating the
MoG parameterization. In these experiments, the MoG appears to capture the salient characteristics
of the target distribution well. Note as in section A.1.3, Sobol or other low-discrepancy sequences
may be used to reduce sampling variance from qprop.
17
Under review as a conference paper at ICLR 2020
Algorithm 2: Filtered inference via Iterated AdaIS.
Result: Approximate posteriors {qt}tT=1
Inputs: y1:T , u1:T , φ, M, Mess, NAIS, J;
qo — p(z);
for t = 1 : T do
ess J 0;
qprop J- qt-1;
for n = 1 : NAIS do
for m = 1:M do
zm
wm
end
〜qn-1∙
qprop ;
J	P(YLt | uLt,hφ(Zm))P(Z).
qn— 1(Zm)	;
Wm J- PMmwg , m = 1, . . . , M;
qn∙op J WeightedExPectatiOnMaximizatiOn ({zm}M=ι, {Wm}M=ι,
ess J EffectiveSampleSize ({Wm}M=J;
if ess > Mess then
I break;
end
J; init
end
qt J qprOp
end
A.2 Damped Harmonic Oscillation
This sectiOn prOvides further details abOut the damped harmOnic OscillatOr (DHO) experiments: the
data, experimental setup and results.
A.2.1 DATA
We generate data via the mOdel:
yt(i) = (ρ(1i))tsin(ω2(i)t) - 0.5(ρ(2i))tsin(ω2(i)t) + t(i),	(27)
t = 1, . . . , 80 which is the sum Of twO damped harmOnic OscillatOrs each with angular frequency
ωj and decay factOr ρj ∈ (0, 1] fOr tasks i = 1, 2, . . . , N . The data are cOrrupted by iid Gaussian
noise, e(i)〜N(0,0.052). The distribution over the random variables is given in Figure 5c. We
chOOse the secOnd cOmpOnent tO be (in expectatiOn) a higher frequency, faster decaying cOmpOnent.
A visualization of these distributions is provided in Figures 5a-5b. The distributions were chosen to
achieve good visual diversity of sequences.
It is natural to parameterize ρj by its half-life (i.e. t such that ρtj = 0.5), since interesting decay
factors are concentrated near 1. For instance, ρj = 0.98 results in a half-life of ν ≈ 34, and ρj = 0.99
results in a half-life of ν ≈ 69. To generate a decay factor, we sample a half life ν in a relevant
interval (Table 5c) and, using the definition of half life, transform via P = exp{- log(2)∕ν}.1
A.2.2 Experimental setup
Parameterization. We use the model:
{A, B, C} = hφ(z)
xt = A xt-1 + B ut
yt 〜N (C Xt, s2)
(28)
(29)
(30)
1The distributions have support ρ1 ∈ [0.8409, 0.9914], ρ2 ∈ [0.9170, 0.9885] (4 decimal places) with
density pg = l0g62) C) and P(PG =好 P1log2(ρ1).
18
Under review as a conference paper at ICLR 2020
(a)	(b)
Figure 5: Distribution of random variables for DHO data generation.
Figure 6: Example data sampled from DHO model.
for t = 1, . . . , T, z ∈ R4, xt ∈ R4, suppressing task index i for clarity. Define x0 := 0, and for
all tasks u = [1, 0, 0, 0, . . .]. A is parameterized as discussed in section A.1.2 using a product of a
diagonal and orthogonal matrix ΣQ. The diagonal of Σ is constrained to lie in [-1, +1] using the
tanh function, and Q is parameterized by the Cayley transform of a skew symmetric matrix S . Using
an upper triangular matrix Γ, we have S = Γ - ΓT, and Q = (I - S)(I + S)-1. We parameterize B
via the product of logistic sigmoid and tanh functions as in section A.1.2 in order to learn a sparse
parameterization. C is unconstrained, and the parameter s is optimized as a constant wrt. z. The
STLDS is parameterized in the same way. The prior p(z) is a unit Gaussian distribution, and hφ is a
2 hidden-layer neural network. We use a fixed feature extractor z → [zT, sin(zT), cos(zT), kzk]T in
the first layer in order to help encode a rectangular support within a spherically symmetric distribution.
The second layer is a fully-connected 300 unit layer with sigmoid activations.
Learning. The output of an MTLDS is very sensitive to the parameter A, and care must be taken to
avoid divergence during optimization. The diagonal-orthogonal parameterization greatly helped to
stabilize the optimization over a more naive orthogonal-diagonal-orthogonal SVD parameterization.
We also reduced the learning rate by a factor of 10 for A. It proved useful to artificially elevate
the estimate of S during training using a prior log S 〜N (-1.5,0.05) (derived from preliminary
experiments) since the MTDS can otherwise overfit small datasets (see also discussion in §3, SVenSen,
1998), with associated instability in optimization. The learning rate schedule is given in Table 2,
for which the prior over log S 〜 N (m, 0.05) was annealed from m = -1.0 to m = -1.5. The
“momentum” parameter β1 (c.f. Kingma & Ba, 2014) is also reduced at the end of optimization. The
latter was motivated by oscillation and moderate deviations observed near optima, apparently caused
(upon investigation) by strong curvature of the loss surface.
Inference. The latent z are inferred online using the adaptive IS scheme of section A.1.5. We also
perform inference over log S since it is held artificially high for optimization, and its true optimal
value is not known. An informative prior close to the learned value log S 〜 N (-2.0,0.12), was
19
Under review as a conference paper at ICLR 2020
Epoch	η	βι	log S mean	M
1	8e-4	0.9	-1.0	1 000
200	8e-4	0.9	-1.3	1 000
600	4e-4	0.9	-1.5	2000
1000	2e-4	0.8	-1.5	4000
Table 2: DHO optimization schedule, see text, η is learning rate, M is number of samples in MCO
step (A.1.3).
Parameter	Description	Value
J	Num. mixture components	3
NAIS	Max. num. of adaptive IS iterations	7
M	Num. samples per IS iteration	1 000
M0	Num. samples for first proposal	3 000
Mfinal	Num. samples for final proposal	3 000
tilt	Exponential tilt of proposal	2.0
Mess	Minimum eff. sample size	100
n_retry	Num. retries if ESS < Mess	2
EM_iters	Num. EM iters in GMM fit	3
kmeans_iters	Max. kmeans iters for init	100
Table 3: DHO Inference parameters.
nevertheless used since the posterior was sometimes approximately singular, causing high condition
numbers in the estimated covariance matrix of the proposal. The hyperparameters are given in Table
3. These parameters did not require tuning as for optimization, but were sensible defaults. These also
seem to work well without tuning for other experiments such as the Mocap data. Each posterior for a
given time t took on average approx. 0.3 seconds.
We used the No U-Turn Sampler (Hoffman & Gelman, 2014) for the STL experiments due to poor
conditioning and the higher complexity and dimensionality of the posterior (19 dimensions). Tuning
is performed using ideas from Hoffman & Gelman (2014, Algorithm 4, 5), and the mass matrix
is estimated from the warmup phase.2 The warmup stage lasted 1000 samples and the subsequent
600 samples were used for inference. Each sampler was initialized from a MAP value, obtained via
optimization with 10 random restarts. For both MAP optimization and sampling, we found it essential
to enforce a low standard deviation (We used log S = —2 and log S 〜 N -2, 0.22 respectively)
similarly to the MTL experiments. The autocorrelation-based effective sample size (Gelman et al.,
2013, ch. 11.5) typically exceeds 100 for each parameter. Each posterior for a given time t took on
average approx. 300 seconds. Note that as discussed in section A.1.4, unlike our AdaIS procedure,
we cannot make much re-use of previous computation here.
A.2.3 Results
The average results (over the 10 repetitions) are given in Table 4, which extends Table 1 in the main
text with the NLL results. The distribution of these results can be seen in the violin plots of Figure 8.
The RMSE results of the MTLDS are all significantly better than both the pooled and single-task
models according to a Welch’s t-test and Mann-Whitney U-test, except for MTLDS-4 at t = 40. The
latter is significantly better than the pooled model, but is indistinguishable from the STLDS at the
level α = 0.05.
We also consider the convergence of the MTLDS to the true model with increasing N . For each
experiment, we average the log marginal likelihood of the test sequences estimated via 10 000 (Sobol)
samples from the prior. As before, the prior should be a good proposal for the aggregate posterior,
and we amortize the same samples over all test sequences. In order to interpret the difference to the
true distribution logp* (Kest) 一 logP(KestI φ), We use the Bayes Factor interpretations given by Kass
2Implementation https://github.com/tpapp/DynamicHMC.jl, author Tamas K. Papp.
20
Under review as a conference paper at ICLR 2020
RMSE	NLL
Model	10	20	40	10	20	40
Pooled-LDS-Ik	0.36	0.34	0.29	0.38	0.34	0.22
STLDS	0.43	0.36	0.11	1.98	1.24	-0.37
MTLDS-4	0.30	0.18	0.12	1.47	0.02	-0.54
MTLDS-16	0.25	0.11	0.07	0.94	-0.43	-0.81
MTLDS-128	0.23	0.09	0.06	0.83	-0.50	-0.85
Table 4: DHO test results. Predictive RMSE and NLL after t = 10, 20, 40. Model suffix denotes
training set size.
SaCTO-
宇W号一

44.0 -
42.0 -
40.0 -
38.0 -
λ	36.0 -
O	l
-1	I	I	I I I I	I
2	4	8	16	32	64	128	2
true
≈
positive
strong
4	8	16	32	64 128
Figure 7: Marginal likelihood of DHO generating distribution under MTLDS models learned from
N examples. Boxes show median, IQR and whiskers show most extreme point within 1.5× IQR
above/below each box. True value shown as (uppermost) dotted line. The RHS panel is rescaled to
show the upper end of the plot with Bayes Factor interpretations overlaid.
& Raftery (1995). For instance a difference of 1.0 is ‘barely worth mentioning’, but a difference of
4.0 is ‘strong evidence’ that the distributions are different. We average over 10 000 test examples
to avoid sampling variation of the test set. Figure 7 show boxplots of the log marginal likelihood
for each model over increasing N , where the boxes show the interquartile range (IQR) over the 10
repetitions. We see convergence towards the true value with increasing N , with the difference of the
MTLDS-128 ‘barely worth mentioning’.
21
Under review as a conference paper at ICLR 2020
(a)	RMSE. Reference (dotted) line shows minimum error for S = 0.05.
4-
3-
TlNc,>=∙yPΘJd
20
time observed
40
(b)	NLL. Reference (dotted) line shows Gaussian entropy with s = 0.1.
Figure 8: Improvement in predictive performance over time seen (x-axis) for the DHO experiments.
Violin plots show a kernel density estimate of the score achieved on RMSE and NLL over sequences
in the test set. Horizontal bars show min, median and max scores.
22
Under review as a conference paper at ICLR 2020
(a)	(b)	(C)	(d)
Figure 9: (a) The 21-joint skeleton. (b) Eulerian representation. (c) Lagrangian representation. (d)
Example of rotating towards the outside of a Corner.
A.3 Human Locomotion Motion Capture (Mocap) Experiments
We provide further details about the data, experimental setup and results of the human loComotion
experiments below.
A.3.1 Human Locomotion Motion Capture (Mocap)
The moCap data of Mason et al. (2018) Consists of planar walking and running motion in 8 styles. The
original data is reCorded at 120 fps, we downsample to 30 fps as per Martinez et al. (2017); Pavllo
et al. (2018). Unlike Mason et al. (2018), we do not perform any data augmentation via mirroring.
The data is mapped to a 21-joint skeleton used in the Codebase of Holden et al. (2016), shown in
Figure 9a, whiCh is a subset of the CMU skeleton.
Representation in observation space. We Choose a Lagrangian representation (Figure 9C) where
the Coordinate frame is Centered at the root joint of the skeleton (joint 1 in Fig. 9a, the pelvis),
projeCted onto the ground. The frame is rotated suCh that the z-axis points in the “forward” direCtion,
roughly normal to the body. This is in Contrast to the Eulerian frame (Figure 9b) whiCh has an
absolute fixed position for all t. In the Lagrangian frame, the joint positions are always relative to the
root joint, whiCh avoids Confusing the overall trajectory of the skeleton (typified by the root joint),
and the overall rotation of the skeleton, with the loCal motions of the joints.
The relative joint positions Can be represented by spatial position or by joint angle. For the latter, the
spatial positions of all joints Can be reCovered from the angle made with their parent joint via use of
forward kinematiCs (FK). This ConstruCtion ensures the Constant bone length of the skeleton over
time, whiCh is a desirable property. However, it also substantially inCreases the sensitivity of internal
joints. For instanCe, the rotation of the trunk will disproportionately affeCt the error of the joints in
both arms. For this reason, we have Chosen to model the spatial position of joints, whiCh may result
in violations of bone length, but avoids these sensitivity issues. See also §2.1 Pavllo et al. (2018).
One Can further enCode the joint positions via veloCity (i.e. differenCing) whiCh may result in smoother
prediCtions. We avoid this enCoding for the loCal joint motion (joints 2 to 21) sinCe it Can suffer
from aCCumulated errors, but we do use it to prediCt the Co-ordinate frame as is standard in moCap
models. Hence our per-frame representation consists of the velocity X, Z, ω of the co-ordinate frame,
the relative vertiCal position of the root joint, and 3-d position of the remaining 20 joints, whiCh gives
yt ∈ R64.
Choice of inputs. Our choice of inputs will reflect controls that an animator may wish to manipulate.
The first input will be the trajectory that the skeleton is to follow. As in Holden et al. (2017b), we
provide the trajectory over the next second (30 frames), sampled uniformly every 5 frames. Unlike
previous work, there is no trajectory history in the inputs since this can be kept in the recurrent state.
The (2-d) trajectory co-ordinates are given wrt. the current co-ordinate frame, and hence can rotate
rapidly during a tight corner. In order to provide some continuity in the inputs, we also provide a first
difference of the trajectory in Eulerian co-ordinates.
23
Under review as a conference paper at ICLR 2020
Model	Optimizer	η	Multi-task η	Regularization
MT-RNN	Adam	3e-5	1e-3	1e-2
GRU L1 (closed loop)	Adam	5e-4	-	5e-4
GRU L2 (closed loop)	Adam	1e-4	-	5e-4
GRU L1 (open loop)	Adam	5e-4	-	0
GRU L2 (open loop)	Adam	1e-4	-	0
Table 5: Hyper-parameters of mocap models. η denotes the learning rate.
The velocity implied by the differenced trajectory does not disambiguate the gait frequency vs.
stride length. The same motion might be achieved with fast short steps, or slower long strides. We
therefore provide the gait frequency via a phasor (as in Holden et al., 2017b), whose frequency may
be externally controlled. This is provided by sine and cosine components to avoid the discontinuity
at 2π. A final ambiguity exists from the trajectory at tight corners: the skeleton can rotate either
towards the focus of the corner, or towards the outside. Figure 9d demonstrates the latter, which
appears not infrequently in the data. We provide a boolean indicator alongside the trajectory which
identifies corners for which this happens. Altogether we have ut ∈ R32: 12 inputs for the Lagrangian
trajectory, 12 inputs for the differenced Eulerian trajectory, 2 inputs for the gait phase and 6 inputs
for the turning indicators.
Extracting the root trajectory. The root trajectory is computed by projecting the root joint onto
the ground. However, this projection may still contain information about the style of locomotion, for
instance via swaying. We wish to remove all such information, since a model can otherwise learn
the style without reference to a latent z. Our goal is to find an appropriately smoothed version of
the extracted trajectory T. We use a cubic B-spline fit to control points fitted to the ‘corners’ of
the trajectory. These control points are selected using a polygonal approximation to T using the
Ramer-Douglas-Peucker algorithm (RDP, e.g. Ramer, 1972). Briefly, the RDP algorithm uses a
divide-and-conquer approach which greedily chooses points that minimize the Hausdorff distance of
T to the polygonal approximation. Some per-style tuning of the RDP parameter, and a small number
of manually added control points rendered this a semi-automatic process.
Extracting the gait phase. Foot contacts are calculated via the code used by Holden et al. (2017b),
which is based on thresholding of vertical position and velocity of each foot. As in Mason et al.
(2018) we check visually for outliers and correct misclassified foot contacts manually. The leading
edge of each foot contact is taken to represent 0 (left) and π (right), and the gait phase is calculated
by interpolation.
A.3.2 Experimental setup
In this section we discuss elements of the experimental setup, learning and inference common to all
experiments. Details particular to each experiment can be found in the following section.
Further Model Details The MTDS architecture is described in section A.3, aside from the choice
of prior. We tested both linear and nonlinear hφ in preliminary experiments and the performance
was often similar. The nonlinear version used a one hidden layer MLP with 300 hidden units with
tanh activations. For the final affine layer, we used a rank 30 matrix which, chosen pragmatically as
a trade-off between flexibility and parameter count (see discussion in section A.1.1). Both choices
often performed similarly, however the linear approach was chosen, since optimization of the latent z
on new data was faster, and apparently more robust to choice of initialization. A nonlinear hφ may
be more important when the base model is simpler.
The benchmark models use an encoding length ofτ = 64 frames. The encoder shares parameters with
the decoder, i.e. the RNN is simply ‘warm started’ for 64 frames before prediction. The benchmark
models, unlike the MTDS, predict the difference from the previous frame (or ‘velocity’) via a residual
architecture, as this performs better in Martinez et al. (2017).
24
Under review as a conference paper at ICLR 2020
Further Learning Details Our primary goal was qualitative: to obtain good style-content separa-
tion, high quality animations and smooth interpolation between sequences. Therefore hyperparameter
selection for the MTDS proceeded via quantitative means (via the ELBO) and visual inspection
of the qualitative criteria. The qualitative desiderata motivated split learning rates between shared
and multi-task networks (cf. section 4.2), and the amount of L2 regularization. See Table 5 for the
chosen values. The main learning rate η applies to the fixed parameters wrt. z (i.e. ψ1, H), and the
multi-task learning rate applies to the parameter generation parameters φ and inference parameters λ.
Standard variational inference proved more reliable than amortized inference: we used a Gaussian
with diagonal covariance (parameterized using softplus) for the variational posterior over each z. L2
regularization was applied to φ, ψ1 , H .
Unless otherwise specified, we optimized each model using a batch size Nbatch = 16 for 20 000
iterations. The ELBO had often reached a plateau by this time, and training even longer resulted in a
worse latent representation at times (as evidenced through poor style transfer). As noted in the main
text, we remove the KL penalty of eq. (9) for the initial 2 000 iterations, and enforce a small posterior
standard deviation (sλ = 10-3) for the same duration. This is similar to finding a MAP estimate for
the {z}. For the remaining iterations, the original ELBO criterion is used, and the constraint on sλ is
removed. The model is implemented in PyTorch (Paszke et al., 2017) and trained on GPUs. Since we
use a fairly small max. sequence length L = 64, truncated backpropagation through time was not
necessary.
The hyper-parameters for the benchmark models were found (Table 5) using a grid search over
learning rate and regularization, as well as the optimizers {Adam, (vanilla) SGD}. We performed
the search over the pooled data for all 8 styles, with a stratified sample of 12.5% held out for a
validation set. Once the hyperparameters were chosen, benchmark models were also trained for
20 000 iterations, recording the validation error every 1 000 iterations on a stratified 12.5% held out
sample. The model with the lowest validation error during optimization is chosen.
We standardize the data so that when pooled, each dimension has zero mean and unit variance. Finally,
note that as discussed in section A.3.1, the data are represented in Lagrangian form, therefore drifts
in the predicted trajectory from the true one are not necessarily heavily penalized. This can be altered
by changing the weights on the root velocities, but we did not do this.
Inference. At test time, especially for experiment 2, we cannot expect amortized inference to
perform optimally, and we consider standard inference techniques. We want to understand the nature
of the posterior distributions, and so we again used the AdaIS approach of section A.1.5. In practice,
each posterior was unimodal and approximately Gaussian. Furthermore, the variation in sequence
space for different z in the posterior was usually fairly small, and the posterior predictive mean
performed similarly to using a point estimate. Each observation from which z is inferred is of
size 64 × 64 and hence the posterior is fairly concentrated. Unlike the DHO model, this is a more
expensive procedure. Our k = 3 experiments took approx. 24 seconds per observation for inference.
An optimization approach using standard techniques may be expected to perform similarly at a
reduced computational cost. Hence unless otherwise specified, inference was done via optimization.
A.4 Experiments
Experiment 1 - MTL The training data for each style uses 4 subsequences chosen carefully to
represent the inter-style variation. Obviously it is important that frames are consecutive rather than
randomly sampled. Over the increasing size training sets, each of these subsequences is a superset
of the previous one. The 6 training set sizes (28, 29, 210, 211, 212, 213 frames per style) are not exact
since short subsequences are discarded (e.g. at file boundaries), and the largest set contains all the
training data except the test set3, where data are not evenly distributed over styles. The test set
comprises 4 sequences from each style, each of length 64, and is the same for all experiments.
A length-64 seed sequence immediately preceding each test sequence was used for inference for
all models. The models are trained as described above, except for the single task (STL) models.
The STL models use an identical architecture to the pooled 1-layer GRU models, except they are
trained only on the data for their style. Since there is less data for these models, we train them for a
3This final set averages 7680 ≈ 212.9 frames per style.
25
Under review as a conference paper at ICLR 2020
Model		RMSE					
		3%	7%	Training set size		53%	97%
				13%	27%		
Training mean		0.76	0.76	0.72	0.73	0.73	0.73
Zero-velocity		1.23	1.23	1.23	1.23	1.23	1.23
Pooled GRU (closed loop)		0.79	0.61	0.82	0.87	0.76	1.21
STL GRU (open loop)		1.11	0.88	0.40	0.33	0.18	0.18
Pooled GRU (open loop)		0.69	0.52	0.36	0.29	0.16	0.16
MT Bias (k	= 3)	0.93	0.44	0.30	0.21	0.14	0.16
MT Bias (k	= 5)	0.98	0.44	0.30	0.20	0.14	0.16
MT Bias (k	= 7)	0.94	0.49	0.30	0.21	0.15	0.16
MTDS (k =	3)	0.62	0.34	0.35	0.21	0.21	0.19
MTDS (k =	5)	0.53	0.29	0.22	0.19	0.15	0.16
MTDS (k =	7)	0.51	0.27	0.24	0.20	0.16	0.18
Table 6: Mocap Experiment 1 (MTL): predictive MSE for length-64
predictions where training sets are a given fraction of the original dataset.
maximum of 5 000 iterations. We do not train 2-layer GRUs, since the amount of data is small for
most experiments.
The full results are given in Table 6. We use fractions of the dataset instead of absolute training
set sizes to aid understanding. The performance of the MTDS appears to increase with larger k,
and suggests that we need k > 3 to achieve optimal performance on unseen training data. The
results demonstrate substantial benefit of the MTDS over a pooled RNN model in terms of sample
efficiency, but not in asymptotic performance, as might be expected. According to a paired t-test,
the improvements of the k = 7 MTDS over the (1-layer, open loop) pooled GRU are significant for
training set sizes 3%, 7%, 13% and 27%.4 At a style level, the k = 7 MTDS performs at least as well
as the pooled GRUs for the first four training set sizes. See Figure 10. Note that the ‘angry’ and
‘childlike’ styles appear to be harder than the others, most likely due to their relatively high speed.
For example animations of the MTL experiments, see the linked video in section A.4.1.
Experiment 2 - Novel Sequences Table 7 provides the aggregate results of experiment 2 for each
of the mocap models. A visualization is given in Figure 11. The 2-layer competitors are shown here
for completeness, but they achieve similar performance to the 1-layer models on aggregate. Figure
12 provides a breakdown of these results on a per-style basis. Styles 5-8 appear to be easier from
the point of view of the benchmarks, but the MTDS shows equal or better performance on all styles
except style 5.
The competitor results achieve better short-term performance than the MTDS. However, note that
the zero-velocity baseline performs similarly to the open-loop GRUs for the first 5 predictions. This
suggests that the MTDS may be improved for these early predictions simply by interpolating from
the zero-velocity baseline for small values of t. We are unable to conclude from these experiments
that the benchmark models can represent the style better initially, but simply that they can smooth the
transition from the seed sequence better.
Experiment 3 - Style Transfer The classifier is learned on the original observations to distinguish
between the 8 styles. We use a 512-unit GRU to encode an observation sequence (usually of 64
frames), and transform the final state via a 300-unit hidden layer MLP with sigmoid activations into
multinomial emissions. The model is trained via cross-entropy with 20% of the training data held
out as a validation set; training was stopped as the validation error approached 0. We perform a
standardization of the gait frequency across all styles, since some styles can be identified purely by
calculating the frequency. The mean frequency across all styles (1 cycle per 33 frames) is applied to
all sequences via linear interpolation. In this we make use of the instantaneous phase given in the
inputs. We use a k = 8 latent code for the MTDS as the model is trained on all styles.
4A non-parameteric Mann-Whitney U test gives 7%, 13% as significant.
26
Under review as a conference paper at ICLR 2020
Angry
ι.5 ʧɪ----------------------------------
、	0.6-
0.0 I	I	I	I	I	γj
0.0	0.2	0.4	0.6	0.8	1.0
0.0
0.0
1.25 -
ω 1.00-
S
W 0.75-
6
4 0.50-
0.25-
0.00
0.0
Childlike
0.0
0.2	0.4	0.6	0.8	1.0	0.0
Depressed
山 s≡⅛><
Old
0.2
0.4	0.6	0.8	1.0
Proud
2.5-
2.0-
1.5-
1.0-
0.5-
0.2	0.4	0.6	0.8	1.0
Sexy
ι.oo-
0.75-
0.50-
0.25-
o.oo-
0.0
0.8-
0.6-
0.4 -
0.2-
0.0-
0.0
0.2	0.4	0.6	0.8	1.0
Strutting
0.2	0.4	0.6	0.8	1.0
Fraction of training set available.
Figure 10:	Per style MSE of Experiment 1.
27
Under review as a conference paper at ICLR 2020
RMSE
Model	t=5	t=10	t=20	t=50	t= 100	t = 200
Training mean	1.04	1.04	1.05	1.04	1.06	1.07
Zero-velocity	0.69	1.20	1.37	1.21	1.35	1.48
1-layer GRU (closed loop)	0.35	0.64	0.81	1.00	1.45	7.28
2-layer GRU (closed loop)	0.34	0.61	0.79	0.97	1.41	6.34
1-layer GRU (open loop)	0.56	0.56	0.60	0.73	0.83	0.92
2-layer GRU (open loop)	0.53	0.55	0.59	0.73	0.85	0.94
MT Bias (k = 3)	0.60	0.60	0.58	0.59	0.64	0.63
MT Bias (k = 7)	0.50	0.48	0.53	0.57	0.55	0.63
MTDS (k = 3)	0.61	0.62	0.59	0.61	0.63	0.63
MTDS (k = 7)	0.49	0.46	0.50	0.54	0.53	0.61
Table 7: Mocap Experiment 2 (novel sequences): average predictive MSE at
t= 5, 10, 20, 50, 100, 200.
Test MSE
(a)
----GRU-IL (closed loop)
GRU-2L (closed loop)
----GRU-IL (open IOOPl
GRU-2L (open IOOP)
∣vrΓBias(k=3)
—— MTBiaS (k = 7)
∣VΓΓDS (k=3)
∣VΓΓDS (k=7)
Zero-velocity
Training Mean
IO2
IO1
200
Prediction frame
(b)
Figure 11:	Results for Experiment 2 for all models on (a) truncated scale, (b) log scale.
28
Under review as a conference paper at ICLR 2020
Avg. MSE	Avg. MSE	Avg. MSE	Avg. MSE
Angry
Childlike
Old
Figure 12: Per style MSE of Experiment 2.
29
Under review as a conference paper at ICLR 2020
source
(a)
(b)
Figure 13: Average classification accuracy for style transfer using inputs from source style (columns)
and latent code z from target style (rows). There is no style transfer on the diagonal. (a) Results for
model with MT bias only. (b) Results for full MTDS model.
The experimental setup is as follows. We carefully choose four segments of length 64 for each of the
styles s1 = 1, . . . , 8 which represent the variability within each style. These correspond to the inputs
Uj(s1) for each source style s1, with examples j = 1, . . . , 4. We next seek the ‘archetypal‘ latent code
z associated with each target style s2. For each s2, we optimize z over 20 candidate values, obtained
from the posterior mean of the style s2 in the training set. Data are generated from all {Uj(s1)} and
the z which provides the greatest success in style transfer is chosen. The 32 highly varied input
sequences guard against overfitting - the 'archetypal' codes for each style must perform well across
much of the variety of the original dataset. We provide a scalar measurement of the ‘success’ of style
transfer for each pair (s1, s2) by using the resulting ‘probability’ that the classifier assigns the target
style s2, averaged across the four input sequences for the source s1.
The results of these experiments are shown in Figure 13a for the model with multi-task bias, and
Figure 13b shows the results for the full MTDS. Table 3c in the main text gives the marginal of these
results wrt. the target style. The cells in Figure 13 give the classifier probability for the target style
for each (source, target) combination, averaged over the four source inputs. Successful style transfer
should result in a the classifier assigning a high score in every cell of the table. For most (source,
target) pairs, the full MTDS model substantially outperforms the MTBias model: it appears that
MTDS can control the prediction well in the majority of cases, and the MTBias model offers reduced
control in general. However, we observe for both models that it is more difficult when styles are
associated with extremes of the input distribution. Specifically, both the ‘childlike’ and ‘angry’ styles
have unusually high speed inputs, and the ‘old’ style has unusually low speeds. Note that in order to
provide style transfer, the models are mostly ignoring these correlations, even though they are very
useful for prediction. Further improvements may be available, perhaps by using an adversarial loss,
or applying domain knowledge to the model. This is orthogonal to our contribution, and we leave
this to future work.
Providing style transfer from all varieties of source style is a challenging task. For instance, some
styles include sources with widely varying speeds and actions, which may be mismatched to the
target style. To understand what may be more typical use of the model, we provide an easier variant
of this experiment where only one example of each source style is provided, rather than four. Note
nevertheless that the same z(s2) is still used across all sources s1. The results of this secondary
experiment are provided in Figure 14. In this case, style transfer is successful for almost all (source,
target) pairs in the case of the MTDS, except for the angry style. The MTBias model still has many
notable failures.
30
Under review as a conference paper at ICLR 2020
(a)
Figure 14: Average classification accuracy for style transfer where only a single source input is used
for each (source, target) pair. The configuration of the matrix is the same as Figure 13. (a) Results for
model with MT bias only. (b) Results for full MTDS model.
(b)
A.4. 1 Generated Animations
A selection of animations are available online. We provide a link and a brief description of each set
below. Where applicable, the animations show a comparison between the ground truth, the relevant
MTDS model, and the (1 layer, open loop) pooled-GRU model. The latter was chosen by virtue of
being the best competitor model in all experiments. In all cases, animations are a complete predictive
rollout with no access to the ground truth.
1.	In-sample predictions https://vimeo.com/362069486. The goal is to showcase the best
possible performance of the models by predicting from inputs in the training set.
2.	MTL examples https://vimeo.com/362122944. Examples from Experiment 1. We compare
the quality of animations and fit to the ground truth for two limited training set sizes (6.7%
and 13.3% of the full data). For both models, MSE to the ground truth is given, averaged
over the entire predictive window (length 256). This is different to the experimental setup
which uses only the first 64 frames.
3.	Novel test examples https://vimeo.com/362068342. Examples from Experiment 2. We
show the adaptions obtained by each model to novel sequences, in particular showcasing
examples of the pooled GRU models inferring suboptimal styles wrt. MSE. Again, MSE to
the ground truth is given averaged over the predictive window (length 256).
4.	Style morphing https://vimeo.com/361910646. This animation demonstrates the effect
of changing the latent code over time. This also demonstrates style transfer and style
interpolation from experiment 3.
For style morphing, we found it useful to fix the dynamical bias of the second layer (parameter b
in eq. 7) wrt. z since it otherwise resulted in ‘jumps’ while interpolating between sequences. We
speculate that shifting the bias induces bifurcations in the state space, whereas adapting the transition
matrix allows for smooth interpolation.
31