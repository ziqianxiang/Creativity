title,year,conference
 Towards principled methods for training generative adversarial net-works,2017, ICLR
 Wasserstein generative adversarial networks,2017, ICML
 Convergence of inertial dynamics and proximal algorithms governedby maximally monotone operators,2019, Math
 The dynamics of elastic shocks via epigraphical regularizationof a differential inclusion,2002, Advances in Mathematical Sciences and Applications
 Reducing noise in GAN training withvariance reduced extragradient,2019, NeurIPS
 Online optimizationwith gradual variations,2012, COLT
 Last-iterate convergence: Zero-sum games and constrained min-maxoptimization,2019, ITCS
 Training GANs with optimism,2018, ICLR
 Stochastic subgradientmethod converges on tame functions,2019, Foundations of Computational Mathematics
 Global convergence to the equilibrium of GANs using variationalinequalities,2018, arXiv:1808
 A variational inequality per-spective on generative adversarial networks,2019, ICLR
 Generative adversarial nets,2014, NeurIPS
 Improved training ofWasserstein GANs,2017, NeurIPS
 Fixed points of nonexpanding maps,1967, Bull
 GANs trained by a twotime-scale update rule converge to a local Nash equilibrium,2017, NeurIPS
 Estimation with quadratic loss,1961, In J
 Solving variational inequalities with stochastic mirror-prox algorithm,2011, Stoch
 Adam: A method for stochastic optimization,2015, ICLR
 Some Problems in the Theory of Motion Stability,1959, Fizmatgiz
 Some extensions of Liapunov’s second method,1960, IRE Trans
 Interaction matters: A note on non-asymptotic local convergence of genera-tive adversarial networks,2019, AISTATS
 Are GANs created equal? a large-scale study,2018, NeurIPS
 Golden ratio algorithms for variational inequalities,2019, Mathematical Programming
 A forward-backward splitting method for monotone inclusions withoutcocoercivity,2018, arXiv:1808
 The numerics of GANs,2017, NeurIPS
 Unrolled generative adversarial networks,2017, ICLR
 Spectral normalization for generative adversar-ial networks,2018, ICLR
 A unified analysis of extra-gradient and optimisticgradient methods for saddle point problems: Proximal point approach,2019, arXiv:1901
 Proximite et dualite dans Un espace hilbertien,1965, Bulletin de la Societe Mathematique deFrance
 Non-asymptotic analysis of stochastic approximation algorithms for ma-chine learning,2011, NeurIPS
 Gradient descent GAN optimization is locally stable,2017, NeurIPS
 On Cezari’s convergence of the steepest descent method for ap-proximating saddle point of convex-concave functions,1978, Doklady Akademii Nauk SSSR
 Robust stochastic approximation approach tostochastic programming,2009, SIAM J
 Automatic differentiation in PyTorch,2017, NeurIPS Autodiff Workshop
 Introduction to optimization,1987, Optimization Software
 Unsupervised representation learning with deep convolutionalgenerative adversarial networks,2016, ICLR
 Online learning with predictable sequences,2013, COLT
 A convergence theorem for non negative almost supermartingalesand some applications,1971, In Jagdish S
 Stabilizing training of generative adversarialnetworks through regularization,2017, NeurIPS
 Primer on monotone operator methods,2016, Appl
 Amortised MAP inference for imagesuper-resolution,2017, ICLR
 Inadmissibility of the usual estimator for the mean of a multivariate normal distribution,1956, InJ
 Fast convergence of regularized learning ingames,2015, NeurIPS
 A modified forward-backward splitting method for maximal monotone mappings,2000, SIAMJ
 Approximation of fixed points of nonexpansive mappings,1992, Arch
 Stabilizing adversarial nets with predictionmethods,2018, ICLR
 The unusualeffectiveness of averaging in GAN training,2019, ICLR
 On the differentiability and the representation of one-parameter semi-group of linearoperators,1948, J
