title,year,conference
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Early methods for detecting adversarial images,2016, arXiv preprintarXiv:1608
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Adversarial examples detection in deep networks with convolutional filterstatistics,2017, In Proceedings of the IEEE International Conference on Computer Vision
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, In International Conference on Learning Representations
 On detecting adversarialperturbations,2017, In International Conference on Learning Representations
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Towards robust detection of adversarial exam-ples,2018, In Advances in Neural Information Processing Systems
 A central limit theorem and a strong mixing condition,1956, Proceedings of theNational Academy of Sciences of the United States of America
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
