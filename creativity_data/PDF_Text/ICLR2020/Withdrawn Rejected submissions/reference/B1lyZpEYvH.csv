title,year,conference
 Neural machine translation by jointlylearning to align and translate,2015, In 3rd International Conference on Learning Representations
 Deriving machine attention from humanrationales,2018, In Proceedings of the 2018 Conference on Empirical Methods in Natural LanguageProcessing
 Sparse overcom-plete word vector representations,2015, In Proceedings of the 53rd Annual Meeting of the Associationfor Computational Linguistics and the 7th International Joint Conference on Natural LanguageProcessing (Volume 1: Long Papers)
 Long short-term memory,1997, Neural computation
 Categorical reparameterization with gumbel-softmax,2017, In 5thInternational Conference on Learning Representations
 Mind the gap: A generative approach to inter-pretable feature selection and extraction,2015, In Advances in Neural Information Processing Systems
 Machine reading tea leaves: Automaticallyevaluating topic coherence and topic model quality,2014, In Proceedings of the 14th Conference of theEuropean Chapter of the Association for Computational Linguistics
 Rationalizing neural predictions,2016, In Proceedingsof the 2016 Conference on Empirical Methods in Natural Language Processing
 Visualizing and understanding neural modelsin nlp,2016, In Proceedings of the 2016 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 Understanding neural networks through representationerasure,2016, arXiv preprint arXiv:1612
 Effective approaches to attention-basedneural machine translation,2015, In Proceedings of the 2015 Conference on Empirical Methods inNatural Language Processing
 The concrete distribution: A continuous relax-ation of discrete random variables,2017, In 5th International Conference on Learning Representations
 From softmax to sparsemax: A sparse model of attentionand multi-label classification,2016, In International Conference on Machine Learning
 Methods for interpreting and Un-derstanding deep neural networks,2018, Digital Signal Processing
 Explaining the stars: Weighted multiple-instance learn-ing for aspect-based sentiment analysis,2014, In Proceedings of the 2014 Conference on EmpiricalMethods In Natural Language Processing (EMNLP)
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Latent aspect rating analysis on review text data:a rating regression approach,2010, In Proceedings of the 16th ACM SIGKDD international conferenceon Knowledge discovery and data mining
 Hierarchicalattention networks for document classification,2016, In Proceedings of the 2016 conference of the NorthAmerican chapter of the association for computational linguistics: human language technologies
 Document-level multi-aspect sentiment classificationas machine comprehension,2017, In Proceedings of the 2017 Conference on Empirical Methods inNatural Language Processing
