title,year,conference
 Obfuscated gradients give a false sense of security:Circumventing defenses to adversarial examples,2018, In ICML
 Deep convolutional networks do notclassify based on global object shape,2018, PLoS computational biology
 SURF: Speeded up robust features,2006, In ECCV
 Towards evaluating the robustness of neural networks,2017, In IEEE Symposiumon Security and Privacy (SP)
 Parseval networks:Improving robustness to adversarial examples,2017, In ICML
 ImageNet: A Large-Scale Hierarchical Image Database,2009, In CVPR
 Boostingadversarial attacks with momentum,2018, In CVPR
 Extended Difference-of-Gaussians model incorporating cortical feedbackfor relay cells in the lateral geniculate nucleus of cat,2012, Cognitive neurodynamics
 Large margin deepnetworks for classification,2018, In NIPS
 Global second-order pooling convolutional networks,2019, In CVPR
 Maxout networks,2013, In ICML
 Explaining and harnessing adversarial examples,2015, InICLR
 Deep residual learning for image recognition,2016, In CVPR
 MobileNets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Squeeze-and-Excitation networks,2018, In CVPR
 Densely connected convolutional networks,2017, In CVPR
 ComDefend: An efficient imagecompression model to defend adversarial examples,2019, In CVPR
 ImageNet classification with deep convolutional neural networks,2012, In NIPS
 Dense associative memory is robust to adversarial inputs,2018, Neural computation
 Adversarial examples in the physical world,2017, In ICLR
 Adversarial machine learning at scale,2017, In ICLR
 Defense against adversarialattacks using high-level representation guided denoiser,2018, In CVPR
 Progressive neural architecture search,2018, In ECCV
 Distinctive image features from scale-invariant keypoints,2004, IJCV
 Towards deeplearning models resistant to adversarial attacks,2018, In ICLR
 DeepFool: a simple and accuratemethod to fool deep neural networks,2016, In CVPR
 Reading digits in naturalimages with unsupervised feature learning,2011, In NIPS workshop
 Defense-GAN: Protecting classifiers against adversarialattacks using generative models,2018, In ICLR
 PixelDefend: Leveraginggenerative models to understand and defend against adversarial examples,2018, In ICLR
 Is robustness the cost of accuracy? - a comprehensivestudy on the robustness of 18 deep image classification models,2018, In ECCV
 PeerNets: Exploit-ing peer wisdom against adversarial attacks,2019, In ICLR
 Intriguing properties of neural networks,2014, In ICLR
 Going deeper with convolutions,2015, In CVPR
 Ensemble adversarial training: attacks and defenses,2018, In ICLR
 Provable defenses against adversarial examples via the convex outer adversarialpolytope,2018, In ICML
 Feature denoising for improvingadversarial robustness,2019, In CVPR
 Statistically-motivated second-order pooling,2018, In ECCV
 Wide residual networks,2017, In BMVC
 Neural architecture search with reinforcement learning,2017, In ICLR
