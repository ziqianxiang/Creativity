title,year,conference
 Online embedding compressionfor text classification using low rank matrix factorization,2018, CoRR
 K-svd: An algorithm for designing overcomplete dictionaries forsparse representation,1053, Trans
 Probabilistic FastText for multi-sense word embed-dings,2018, In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume1: Long Papers)
 Towards learning sparsely used dictionaries with arbitrarysupports,2018, CoRR
 Practical coreset constructions for machine learning,2017, 2017
 Adaptive input representations for neural language modeling,2018, CoRR
 Adaptive importance sampling to accelerate training of a neural probabilisticlanguage model,1045, Trans
 Enriching word vectors with subwordinformation,2016, CoRR
 The restricted isometry property and its implications for compressed sensing,2008, 2008
 Learning k-way d-dimensional discrete codes for compactembedding representations,2018, In Jennifer Dy and Andreas Krause (eds
 How large a vocabulary doestext classification need? A variational approach to vocabulary selection,2019, CoRR
 Compressing neuralnetworks with the hashing trick,2015, CoRR
 Compressing neural language models by sparse wordrepresentations,2016, CoRR
 Bayesian compression for natural languageprocessing,2018, In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing
 Learning to prune deep neural networks via layer-wise optimal brainsurgeon,2017, In I
 Compression of recurrent neural networksfor efficient language modeling,2019, CoRR
 Learning to hash with optimized anchor embedding for scalableretrieval,2017, IEEE Transactions on Image Processing
 Noise-contrastive estimation: A new estimation principle for unnor-malized statistical models,2010, In Yee Whye Teh and Mike Titterington (eds
 Texture features for image classification,1973, IEEE Transactions onSystems
 Long short-term memory,0899, Neural Comput
 Neural inPut search for large scalerecommendation models,2019, CoRR
 Convolutional neural networks for sentence classification,2014, In Proceedings of the 2014 Conference onEmpirical Methods in Natural Language Processing (EMNLP)
 Gradient-based learning aPPlied to documentrecognition,1998, In Proceedings of the IEEE
 SParse convolutionalneural networks,2015, In CVPR
 Effective approaches to attention-based neuralmachine translation,2015, CoRR
 Building a large annotated corpusof english: The penn treebank,0891, Comput
 Pointer sentinel mixture models,2016, CoRR
 Regularizing and optimizing LSTM languagemodels,2017, CoRR
 Wordnet: A lexical database for english,1995, Commun
 Integrating low-rank approximation and word embedding for featuretransformation in the high-dimensional text classification,2017, Procedia Computer Science
 Proximal algorithms,2014, Found
 Coresets and sketches,2016, CoRR
 Using the output embedding to improve language models,2016, CoRR
 Mining knowledge graphs from text,2018, In Proceedings of the Eleventh ACMInternational Conference on Web Search and Data Mining
 Word embedding based on low-rank doubly stochastic matrix decomposition,2018, InLong Cheng
 Sparse gaussian processes using pseudo-inputs,2006, In Advances in neuralinformation processing systems
 Attention is all you need,2017, In I
 Learning structured sparsity in deep neuralnetworks,2016, In D
 Efficient manifold rankingfor image retrieval,2011, In Proceedings of the 34th international ACM SIGIR conference on Research anddevelopment in Information Retrieval
