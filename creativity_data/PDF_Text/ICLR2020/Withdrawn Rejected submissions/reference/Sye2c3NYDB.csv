title,year,conference
 Stochastic activation pruning for ro-bust adversarial defense,2018, arXiv preprint arXiv:1803
 Thelottery ticket hypothesis at scale,2019, arXiv preprint arXiv:1903
 Explaining and harnessing adver-sarial examples,2015, In International Conference on Learning Representations
 Sparse dnns with improvedadversarial robustness,2018, In Advances in neural information processing systems
 Deep residual learning forimage recognition,2016, In Proceedings of the IEEE conference on computer vision andpattern recognition
 Distilling the knowledge in a neural net-work,2015, arXiv preprint arXiv:1503
 Batch normalization: Accelerating deep networktraining by reducing internal covariate shift,2015, pp
 Optimal brain damage,1990, In Advances inneural information processing systems
 Gradient-based learningapplied to document recognition,1998, Proceedings of the IEEE
 Snip: Single-shot networkpruning based on connection sensitivity,2018, arXiv preprint arXiv:1810
 Pruning filtersfor efficient convnets,2016, arXiv preprint arXiv:1608
 Delving into transferable adversar-ial examples and black-box attacks,2016, arXiv preprint arXiv:1611
 Rethinking thevalue of network pruning,2018, arXiv preprint arXiv:1810
 Towards deep learning models resistant to adversarial attacks,2017, arXiv preprintarXiv:1706
 Transferability in machine learn-ing: from phenomena to black-box attacks using adversarial samples,2016, arXiv preprintarXiv:1605
 Towards compact and robustdeep neural networks,2019, arXiv preprint arXiv:1906
 Very deep convolutional networks for large-scaleimage recognition,2014, arXiv preprint arXiv:1409
 Intriguing properties of neural networks,2013, arXiv preprintarXiv:1312
 To-wards robust compressed convolutional neural networks,2019, In 2019 IEEE InternationalCOnference on Big Data and Smart Computing (BigComp)
 Defending dnnadversarial attacks with pruning and logits augmentation,2018, 2018
 Second rethinking of network pruningin the adversarial setting,2019, arXiv preprint arXiv:1903
 Wide residual networks,2016, arXiv preprintarXiv:1605
 You onlypropagate once: Painless adversarial training using maximal principle,2019, arXiv preprintarXiv:1905
 Less is more: Towards compact cnns,2016, InEuropean Conference on Computer Vision
