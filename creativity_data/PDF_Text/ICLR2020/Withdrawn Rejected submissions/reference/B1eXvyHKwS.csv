title,year,conference
 Onexact computation with an infinitely wide neural net,2019, arXiv preprint arXiv:1904
 Convex Optimization,2004, Cambridge University Press
 Deepdriving: Learning affordancefor direct perception in autonomous driving,2015, 2015 IEEE International Conference on ComputerVision (ICCV)
 Parsevalnetworks: Improving robustness to adversarial examples,2017, arXiv preprint arXiv:1704
 Provable robustness of relu net-works via maximization of linear regions,2019, Proceedings of the 22nd International Conference onArtificial Intelligence and Statistics (AISTATS)
 Gradient descent finds globalminima of deep neural networks,2019, Proceedings of the 36th International Conference on MachineLearning (ICML)
 Largemargin deep networks for classification,2018, arXiv preprint arXiv: arXiv:1803
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Characterizing implicit bias interms of optimization geometry,2018, Proceedings of the 35th International Conference on MachineLearning (ICML)
 Deep residual learning for image recog-nition,2015, arXiv preprint arXiv:1512
 Formal guarantees on the robustness of a classifieragainst adversarial manipulation,2017, arXiv preprint arXiv:1705
 Neural tangent kernel: Convergence and gener-alization in neural networks,2018, Advances in Neural Information Processing Systems 31 (NeurlPS)
 Risk and parameter convergence of logistic regression,2018, arXiv preprintarXiv:1803
 Imagenet classification with deep convolutional neuralnetworks,2012, Advances in Neural Information Processing Systems 25 (NeurlPS)
 Wide neural networks of any depth evolve as linear models under gradientdescent,2019, arXiv preprint arXiv:1902
 Stochastic gradient descent on separabledata: Exact convergence with a fixed learning rate,2018, arXiv preprint arXiv:1806
 Bounding and counting linearregions of deep neural networks,2018, In Proceedings of the 35th International Conference on MachineLearning (ICML)
 The im-plicit bias of gradient descent on separable data,2017, arXiv preprint arXiv:1710
 A differential equation for modeling nesterovâ€™saccelerated gradient method: Theory and insights,2015, arXiv preprint arXiv:1503
 Intriguing properties of neural networks,2017, arXiv preprint arXiv:1312
 Convex Optimization,1995, Springer
