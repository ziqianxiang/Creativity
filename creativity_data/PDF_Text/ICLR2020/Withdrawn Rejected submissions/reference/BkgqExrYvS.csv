title,year,conference
 Sparse communication for distributed gradient descent,2017, arXivpreprint arXiv:1704
 QSGD: Randomizedquantization for communication-efficient stochastic gradient descent,2017, In Proceedings of NIPS2017
 The convergence of stochastic gradientdescent in asynchronous shared memory,2018, In PODC
 Computation innetworks of passively mobile finite-state sensors,2006, Distributed computing
 A simple population protocol for fast robustapproximate majority,2008, Distributed Computing
 Fast computation by population protocols with aleader,2008, Distributed Computing
 Self-stabilizing populationprotocols,2008, ACM Transactions on Autonomous and Adaptive Systems
 Stochastic gradient push fordistributed deep learning,2018, arXiv preprint arXiv:1811
 Large-scale machine learning with stochastic gradient descent,2010, In Proceedings ofCOMPSTATâ€™2010
 Speed faults in computationby chemical reaction networks,2017, Distributed Computing
 Communication quantizationfor data-parallel training of deep neural networks,2016, In Proceedings of the Workshop on MachineLearning in High Performance Computing Environments
 Asynchronous stochastic convexoptimization,2015, arXiv preprint arXiv:1508
 Synchronous multi-gpu deep learning withlow-precision communication: An experimental study,2018, In EDBT
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Accelerated decentralized optimizationwith local updates for smooth and strongly convex objectives,2018, arXiv preprint arXiv:1810
 Decentralized stochastic optimizationand gossip algorithms with compressed communication,2019, arXiv preprint arXiv:1902
 Can decentralizedalgorithms outperform centralized algorithms? a case study for decentralized parallel stochasticgradient descent,2017, arXiv preprint arXiv:1705
 Asynchronous decentralized parallel stochasticgradient descent,2017, arXiv preprint arXiv:1710
 Torchvision the machine-vision package of torch,2010, InProceedings of the 18th ACM international conference on Multimedia
 Graphical balanced allocations and the one plus beta-choice process,2015, Random Struct
 Graphical balanced allocations and the 1 + beta-choiceprocess,1042, Random Struct
 Hogwild: A lock-free approach toparallelizing stochastic gradient descent,2011, In NIPS
 Taming the wild: A unified analysis of hogwild-stylealgorihms,2015, In Advances in Neural Information Processing Systems
 1-bit stochastic gradient descent and application to data-parallel distributed training of speech dnns,2014, Interspeech
 Distributed stochastic optimization and learning,2014, In 2014 52ndAnnual Allerton Conference on Communication
 Local sgd converges fast and communicates little,2018, arXiv preprint arXiv:1805
 Scalable distributed dnn training using commodity gpu cloud computing,2015, In SixteenthAnnual Conference of the International Speech Communication Association
 Problems in decentralized decision making and computation,1984, Technicalreport
 Terngrad:Ternary gradients to reduce communication in distributed deep learning,2017, In Advances in NeuralInformation Processing Systems
