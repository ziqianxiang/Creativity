title,year,conference
 Double Viterbi: Weight encoding forhigh compression ratio and fast on-chip reconstruction for deep neural network,2019, In InternationalConference on Learning Representations (ICLR)
 Estimating or propagating gradients throughstochastic neurons for conditional computation,2013, arXiv:1308
 Deep residual learning for image recog-nition,2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Bag of tricks to trainconvolutional neural networks for image classification,2018, In The IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Learning to quantize deep networks by optimizing quantizationintervals with task loss,2019, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 The influence of variables on boolean functions,1988, In Proceedingsof the 29th Annual Symposium on Foundations of Computer Science
 Trainingquantized nets: A deeper understanding,2017, In Advances in Neural Information Processing Systems
 Towards accurate binary convolutional neural network,2017, InAdvances in Neural Information Processing Systems
 XNOR-Net: Imagenetclassification using binary convolutional neural networks,2016, In ECCV
 And the bit goesdown: Revisiting the quantization of neural networks,2019, arXiv:1907
 Haq: Hardware-aware automated quan-tization with mixed precision,2019, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Alternating multi-bit quantization for recurrent neural networks,2018, In International Conferenceon Learning Representations (ICLR)
 Lq-nets: Learned quantization forhighly accurate and compact deep neural networks,2018, In Proceedings of the European Conferenceon Computer Vision (ECCV)
 Trained ternary quantization,2017, InInternational Conference on Learning Representations (ICLR)
