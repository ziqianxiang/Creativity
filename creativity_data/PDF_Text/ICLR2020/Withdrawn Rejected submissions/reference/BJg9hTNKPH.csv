title,year,conference
 Maximum a posteriori policy optimisation,2018, arXiv preprint arXiv:1806
 Striving for simplicity in off-policydeep reinforcement learning,2019, arXiv preprint arXiv:1907
 Residual algorithms: Reinforcement learning with function approximation,1995, InMachine Learning Proceedings 1995
 Openai gym,2016, arXiv preprint arXiv:1606
 Diagnosing bottlenecks in deep q-learningalgorithms,2019, arXiv preprint arXiv:1902
 Off-policy deep reinforcement learning withoUtexploration,2018, arXiv preprint arXiv:1812
 Addressing fUnction approximation error inactor-critic methods,2018, arXiv preprint arXiv:1802
 Soft actor-critic: Off-policy maxi-mum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprint arXiv:1801
 Way off-policy batch deep reinforcement learning ofimplicit human preferences in dialog,2019, arXiv preprint arXiv:1907
 A natural policy gradient,2002, In Advances in neural information processing systems
 Stabilizing off-policy q-learning viabootstrapping error reduction,2019, arXiv preprint arXiv:1906
 Batch reinforcement learning,2012, In Reinforcementlearning
 Safe policy improvement with baseline bootstrapping,2017, arXivpreprint arXiv:1712
 Toward minimax off-policy value estimation,2015, 2015
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Breaking the curse of horizon: Infinite-horizon off-policy estimation,2018, In Advances in Neural Information Processing Systems
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Asynchronous methods for deep reinforcementlearning,2016, In International conference on machine learning
 Trust-pcl: An off-policy trustregion method for continuous control,2017, arXiv preprint arXiv:1707
 Dualdice: Behavior-agnostic estimation ofdiscounted stationary distribution corrections,2019, arXiv preprint arXiv:1906
 f-gan: Training generative neural samplersusing variational divergence minimization,2016, In Advances in neural information processing systems
 Markov decision processes,1990, Handbooks in operations research and managementscience
 Trust regionpolicy optimization,2015, In International conference on machine learning
 On the virtues of linear learning and trajectory distributions,1995, In Proceedings of theWorkshop on Value Function Approximation
 Analysis of temporal-diffference learning with functionapproximation,1997, In Advances in neural information processing systems
 Deep reinforcement learning and the deadly triad,2018, arXiv preprint arXiv:1812
 Domain adaptation withasymmetrically-relaxed distribution alignment,2019, In International Conference on Machine Learning
