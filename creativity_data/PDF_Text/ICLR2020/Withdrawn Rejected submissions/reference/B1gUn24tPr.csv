title,year,conference
 A simple but tough-to-beat baseline for sentenceembeddings,2016, 2016
 Named entity recognitionwith bilingual constraints,2013, In Proceedings of the 2013 Conference of the North American Chapterof the Association for Computational Linguistics: Human Language Technologies
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 F-score driven max margin neural network for named entity recognitionin chinese social media,2016, arXiv preprint arXiv:1611
 Multi-head multi-layer attention to deep language repre-sentations for grammatical error detection,2019, arXiv preprint arXiv:1904
 Biobert: pre-trained biomedical language representation model for biomedical textmining,2019, arXiv preprint arXiv:1901
 The third international chinese language processing bakeoff: Word segmenta-tion and named entity recognition,2006, In Proceedings of the Fifth SIGHAN Workshop on ChineseLanguage Processing
 A survey on deep learning for named entityrecognition,2018, arXiv preprint arXiv:1812
 An encoding strategy based word-character lstm for chinese ner,2019, In Proceedings of the 2019 Conference of the North AmericanChapter of the Association for Computational Linguistics: Human Language Technologies
 Named entity recognition for chinese social media with jointlytrained embeddings,2015, In Proceedings of the 2015 Conference on Empirical Methods in NaturalLanguage Processing
 Multi-task domain adaptation for sequence tagging,2016, arXiv preprintarXiv:1608
 Deep contextualized word representations,2018, arXiv preprint arXiv:1802
 Improving language under-standing with unsupervised learning,2018, Technical report
 Attending to characters in neural sequencelabeling models,2016, arXiv preprint arXiv:1611
 Ernie: Enhanced representation through knowledge integration,2019, arXivpreprint arXiv:1904
 Attention is all you need,2017, In Advances in neural informationprocessing Systems
 Convolutional neural network with word embeddings for chinese wordsegmentation,2017, arXiv preprint arXiv:1711
 Design challenges and misconceptions in neural se-quence labeling,2018, arXiv preprint arXiv:1806
 Multi-task cross-lingual sequence taggingfrom scratch,2016, arXiv preprint arXiv:1603
 Xlnet: Generalized autoregressive pretraining for language understanding,2019, arXiv preprintarXiv:1906
 Chinese ner using lattice lstm,2018, arXiv preprint arXiv:1805
 Ernie: Enhancedlanguage representation with informative entities,2019, arXiv preprint arXiv:1905
 Chinese name entity recognition using highway-lstm-crf,2018, In Proceedings of the 2018 International Conference on Algorithms
 Can-ner: Convolutional attention network forchi-nese named entity recognition,2019, arXiv preprint arXiv:1904
