title,year,conference
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PloS one
  Adversarial examples are not easily detected:  Bypassing tendetection  methods,2017,   In  Proceedings  of  the  10th  ACM  Workshop  on  Artificial  Intelligence  andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
  Real time image saliency for black box classifiers,2017,  In Advances inNeural Information Processing Systems
 Boost-ing adversarial attacks with momentum,2018,   In Proceedings of the IEEE conference on computervision and pattern recognition
 Asirra: a captcha that exploits interest-aligned manual image categorization,2007, 2007
 Interpretable explanations of black boxes by meaningful perturba-tion,2017,  In Proceedings of the IEEE International Conference on Computer Vision
   Adversarial and clean data are not twins,2017,   arXivpreprint arXiv:1704
  Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
  Saliency methods for explaining adversarial attacks,2019,  arXiv preprintarXiv:1908
 Black-box adversarialattacks on video recognition models,2019, arXiv preprint arXiv:1904
  Adam:  A method for stochastic optimization,2014,  arXiv preprintarXiv:1412
 Video rain streakremoval by multiscale convolutional sparse coding,2018,  In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 On detecting adversarialperturbations,2017, arXiv preprint arXiv:1702
  clev-erhans v1,2016,0
  Why should i trust you?: Explaining thepredictions of any classifier,2016,  In Proceedings of the 22nd ACM SIGKDD international conferenceon knowledge discovery and data mining
  Grad-cam:  Visual explanations from deep networks via gradient-based local-ization,2017,  In Proceedings of the IEEE International Conference on Computer Vision
 Deep inside convolutional networks: Vi-sualising image classification models and saliency maps,2013, arXiv preprint arXiv:1312
  Striving forsimplicity: The all convolutional net,2014, arXiv preprint arXiv:1412
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
  Asp: A fast adversarial attack example generation frame-work based on adversarial saliency prediction,2018, arXiv preprint arXiv:1802
   Visualizing  and  understanding  convolutional  networks,2014,   InEuropean conference on computer vision
 Visualizing deep neural networkdecisions: Prediction difference analysis,2017, arXiv preprint arXiv:1702
