title,year,conference
 The effects of adding noise during backpropagation training on a generalizationperformance,1996, Neural computation
 Training with noise is equivalent to tikhonov regularization,1995, Neural Computation
 TheLoss Surfaces of Multilayer Networks,2015, In Guy Lebanon and S
 Emnist: an extension ofmnist to handwritten letters,2017, arXiv preprint arXiv:1702
 Improving neural networks by preventing co-adaptation of feature detectors,2012, CoRR
 Simplifying neural nets by discovering flat minima,1995, InG
 Population based training of neural networks,2017, CoRR
 Optimization by simulated annealing,0036, Science
 Gradient-based learning appliedto document recognition,1998, Proceedings of the IEEE
 How does batchnormalization help optimization? In S,2018, Bengio
 Creating artificial neural networks that general-ize,0893, Neural Networks
 Energy-entropy competitionand the effectiveness of stochastic gradient descent in machine learning,2018, Molecular Physics
