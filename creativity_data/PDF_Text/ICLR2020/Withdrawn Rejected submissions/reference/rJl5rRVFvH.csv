title,year,conference
 Maximum a posteriori policy optimisation,2018, arXiv preprint arXiv:1806
 Striving for simplicity in off-policydeep reinforcement learning,2019, arXiv preprint arXiv:1907
 Efficient explorationthrough bayesian deep q-networks,2018, In 2018 Information Theory and Applications Workshop (ITA)
 Crossnorm: Normalizationfor off-policy td reinforcement learning,2019, arXiv preprint arXiv:1902
 Deepreinforcement learning from human preferences,2017, In Advances in Neural Information ProcessingSystems
 Chameleons in imagined conversations: A newapproach to understanding coordination of linguistic style in dialogs,2011, In Proceedings of the 2ndWorkshop on Cognitive Modeling and Computational Linguistics
 More robust doubly robustoff-policy evaluation,2018, In International Conference on Machine Learning
 Addressing function approximation error in actor-critic methods,2018, In International Conference on Machine Learning
 Off-policy deep reinforcement learning withoutexploration,2018, arXiv preprint arXiv:1812
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In international conference on machine learning
 Off-policy deep reinforcement learning by bootstrapping thecovariate shift,2019, arXiv preprint arXiv:1901
 Approximating interactive human evaluation with self-play for open-domaindialog systems,2019, arXiv preprint arXiv:1906
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Language style matching predicts relationship initiation and stability,2011, Psychologicalscience
 Doubly robust off-policy value evaluation for reinforcement learning,2016, InInternational Conference on Machine Learning
 Uncertainty-awarereinforcement learning for collision avoidance,2017, arXiv preprint arXiv:1702
 A natural policy gradient,2002, In Advances in neural information processing systems(NIPS)
 Optimal control as a graphical model infer-ence problem,2012, Machine learning
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Stabilizing off-policy q-learning viabootstrapping error reduction,2019, arXiv preprint arXiv:1906
 Dialoguelearning with human-in-the-loop,2016, arXiv preprint arXiv:1611
 Deep rein-forcement learning for dialogue generation,2016, In Proceedings of the 2016 Conference on EmpiricalMethods in Natural Language Processing
 Adversariallearning for neural dialogue generation,2017, In Proceedings of the 2017 Conference on EmpiricalMethods in Natural Language Processing
 Dialogue generation: From imitation learning toinverse reinforcement learning,2018, arXiv preprint arXiv:1812
 Iterative policy learning in end-to-end trainable task-oriented neural dialogmodels,2017, In 2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)
 Off-policy policy gradient withstate distribution correction,2019, arXiv preprint arXiv:1904
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Safe and efficient off-policyreinforcement learning,2016, In Advances in Neural Information Processing Systems
 Deep exploration viabootstrapped dqn,2016, In Advances in neural information processing systems
 Eligibility traces for off-policy policy evaluation,2000, Computer Science DepartmentFaculty Publication Series
 On stochastic optimal control and rein-forcement learning by approximate inference,2012, In Robotics: science and systems
 A deepreinforcement learning chatbot,2017, arXiv preprint arXiv:1709
 Happybot: Generating empathetic di-alogue responses by improving user experience look-ahead,2019, arXiv preprint arXiv:1906
 Stochastic optimal control,1986, John Wiley and Sons New York
 Data-efficient off-policy policy evaluation for reinforcementlearning,2016, In International Conference on Machine Learning
 High confidence policyimprovement,2015, In International Conference on Machine Learning
 Linearly-solvable markov decision problems,2007, In Advances in neural informationprocessing systems (NIPS)
 Deep reinforcement learning with double q-learning,2016, In Thirtieth AAAI Conference on Artificial Intelligence
 Maximum entropy inversereinforcement learning,2008, In AAAI
 Fine-tuning language models from human preferences,2019, arXivpreprint arXiv:1909
