title,year,conference
 Provable limitations of deep learning,2018, arXiv preprintarXiv:1812
 A convergence theory for deep learning via over-parameterization,2018, arXiv preprint arXiv:1811
 Provable bounds for learning somedeep representations,2014, In International Conference on Machine Learning
 Fine-grained analysis ofoptimization and generalization for overparameterized two-layer neural networks,2019, arXiv preprintarXiv:1901
 Greedy layerwise learning can scaleto imagenet,2018, arXiv preprint arXiv:1812
 Why do larger models generalize better? a theoretical per-spective via the xor problem,2019, In International Conference on Machine Learning
 Sgd learns over-parameterized networks that provably generalize on linearly separable data,2017, arXiv preprintarXiv:1710
 Id3 learns juntas for smoothed product distribu-tions,2019, arXiv preprint arXiv:1906
 On the learnability of deeprandom networks,2019, arXiv preprint arXiv:1904
 Gradient descent provably optimizesover-parameterized neural networks,2018, arXiv preprint arXiv:1810
 On functionscomputed on trees,2019, arXiv preprint arXiv:1904
 New results forlearning noisy parities and halfspaces,2006, In 2006 47th Annual IEEE Symposium on Foundations ofComputer Science (FOCSâ€™06)
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, In Advances in neural information processing Systems
 Probabilistic graphical models: principles and techniques,2009, MITpress
 Wide neural networks of any depth evolve as linear models under gradientdescent,2019, arXiv preprint arXiv:1902
 On the computational efficiency of trainingneural networks,2014, In Advances in neural information processing systems
 A comparative analysis of the optimization and generalization propertyof two-layer neural network and random feature models under gradient descent dynamics,2019, arXivpreprint arXiv:1904
 A provably correct algorithm for deep learning that actuallyworks,2018, arXiv preprint arXiv:1803
 Towards moderate overparameterization: global con-vergence guarantees for training shallow neural networks,1902, arXiv:1902
 Diverse neural network learns true target functions,2016, arXivpreprint arXiv:1611
