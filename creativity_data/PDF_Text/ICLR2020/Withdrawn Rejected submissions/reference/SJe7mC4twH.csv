title,year,conference
 Network dissection:Quantifying interpretability of deep visual representations,2017, In CVPR
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In ICLR (Poster)
 Thermometer encoding: One hotway to resist adversarial examples,2018, In ICLR (Poster)
 Towards evaluating the robustness of neural networks,2017, InIEEE Symposium on Security and Privacy
 Explaining and harnessing adversarialexamples,2015, In ICLR (Poster)
 MNIST handwritten digit database,2010, 2010
 On the variance of the adaptive learning rate and beyond,2019, CoRR
 Deepfool: A simple andaccurate method to fool deep neural networks,2016, In CVPR
 Adversarialrobustness toolbox v0,2018, 4
 Transferability in machine learning:from phenomena to black-box attacks using adversarial samples,2016, CoRR
 Subspace clustering for high dimensional data: areview,2004, SIGKDD Explorations
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, In ICLR (Poster)
 Intriguing properties of neural networks,2014, In ICLR (Poster)
 Conditional image generation with pixelcnn decoders,2016, In NeuraIPS
 Neural discrete representation learn-ing,2017, In NeuraIPS
 Discovering internalrepresentations from object-cnns using population encoding,2015, CoRR
 Visual concepts and compositional voting,2017, CoRR
 Feature squeezing: Detecting adversarial examples in deepneural networks,2018, In NDSS
 Visualizing and understanding convolutional networks,2014, InECCV (1)
 Defending against whitebox adversarial attacks via randomizeddiscretization,2019, In AISTATS
 Object detectorsemerge in deep scene cnns,2015, In ICLR
