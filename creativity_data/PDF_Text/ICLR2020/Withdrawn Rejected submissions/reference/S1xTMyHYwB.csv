title,year,conference
 Provable bounds for learning some deeprepresentations,2014, In ICML
 Perceptron: A model for brain functioning,1962, Review of Modern Physics
 Stylebank: An explicit representa-tion for neural image style transfer,2017, In Proc
 Fast patch-based style transfer of arbitrary style,2016, arXiv preprintarXiv:1612
 Imagenet: A large-scalehierarchical image database,2009, In CVPR
 Image style transfer using convolutionalneural networks,2016, In Computer Vision and Pattern Recognition (CVPR)
 Towards understanding theinvertibility of convolutional neural networks,2017, arXiv preprint arXiv:1705
 Global guarantees for enforcing deep generative priors byempirical risk,2017, arXiv preprint arXiv:1705
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In ICCV
 Arbitrary style transfer in real-time with adaptive instance normal-ization,2017, CoRR
 Stochastic choice of basis functions in adaptive function approxima-tion and the functional-link net,1995, IEEE Trans
 Caffe: Convolutional architecture for fast feature embedding,2014, InACM MM
 Perceptual losses for real-time style transfer andsuper-resolution,2016, In European Conference on Computer Vision
 Adam: A method for stochastic optimization,2015, In ICLR
 Imagenet classification with deep convolu-tional neural networks,2012, In NIPS
 Deep neural networks as gaussian processes,2017, CoRR
 Demystifying neural style transfer,2017, arXivpreprint arXiv:1701
 Reservoir computing approaches to recurrent neuralnetwork training,2009, Computer Science Review
 Invertibility of convolutional generative networksfrom partial measurements,2018, In Advances in Neural Information Processing Systems
 Understanding deep image representations by invertingthem,2015, In CVPR
 Why does deep learning work?-a perspective fromgroup theory,2014, arXiv preprint arXiv:1412
 Uniform approximation of functions with random bases,2008, In AllertonConference on Communication
 Weighted sums of random kitchen sinks: Replacing minimizationwith randomization in learning,2009, In NIPS
 Randomness in neural networks: an overview,2017, WIREs: DataMining and Knowledge Discovery
 Very deep convolutional networks for large-scale imagerecognition,2015, In ICLR
 Learning kernels with random features,2016, In NIPS
 Texture networks:Feed-forward synthesis of textures and stylized images,2016, In ICML
 Deep image prior,2017, arXiv preprintarXiv:1711
 Improved texture networks: Maximizingquality and diversity in feed-forward stylization and texture synthesis,2017, In Proc
 Image quality assessment:from error visibility to structural similarity,2004, IEEE Trans
 Computing with infinite networks,1996, In Advances in Neural InformationProcessing Systems 9
 Understanding neuralnetworks through deep visualization,2015, arXiv preprint arXiv:1506
 Visualizing and understanding convolutional networks,2014, In ECCV
 Adaptive deconvolutional networks for midand high level feature learning,2011, In ICCV
