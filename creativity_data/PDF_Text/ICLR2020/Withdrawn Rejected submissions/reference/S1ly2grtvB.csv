title,year,conference
 A semi-supervised two-stage approachto learning from noisy labels,2018, In WACV
 Training deep neural-networks using a noise adaptationlayer,2016, 2016
 Bayesian semisupervised learning with deepgenerative models,2017, arXiv preprint arXiv:1706
 Deep residual learning for imagerecognition,2015, CoRR
 Three factors influencing minima in SGD,2017, CoRR
 Mentornet: Learning data-drivencurriculum for very deep neural networks on corrupted labels,2017, arXiv preprint arXiv:1712
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Semi-supervisedlearning with deep generative models,2014, CoRR
 Learning multiple layers of features from tiny images,2009, Technical report
 A deep generative model for semi-supervised classification with noisy labels,2018, CoRR
 Learning fromnoisy labels with distillation,2017, In ICCV
 Learning fromcorrupted binary labels via class-probability estimation,2015, In Francis Bach and David Blei (eds
 Learn-ing with noisy labels,2013, In NIPS
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In CVPR
 Acceleration of stochastic approximation by averaging,0363, SIAMJ
 Training deep neural networks on noisy labels with bootstrapping,2015, In ICLR
 Mean teachers are better role models: Weight-averaged consistencytargets improve semi-supervised deep learning results,2017, In NIPS
