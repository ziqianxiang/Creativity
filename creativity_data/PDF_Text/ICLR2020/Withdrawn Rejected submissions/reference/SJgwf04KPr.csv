title,year,conference
 Threat of adversarial attacks on deep learning in computer vision:A survey,2018, arXiv
 Adef: an iterative algorithm to constructadversarial deformations,2018, arXiv
 The vulnerability of learning to adversarial perturbation in-creases with intrinsic dimensionality,2017, In WIFS
 Provable adversarial defenses for boosting,2019, Master’s thesis
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv
 Synthesizing robust adversarialexamples,2018, In ICML
 Dimensionality reduction as a defenseagainst evasion attacks on machine learning classifiers,2017, arXiv
 Exploring the space of black-box attackson deep neural networks,2017, arXiv
 Wild patterns: Ten years after the rise of adversarial machinelearning,2018, arXiv
 Wild patterns: Ten years after the rise of adversarial machinelearning,2018, Pattern Recognition
 Comment on ”biologically inspired protection of deep net-works from adversarial attacks”,2017, arXiv
 Curriculum adversarial training,2018, In IJCAI
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, arXiv
 Towards evaluating the robustness of neural networks,2017, In SP
 Unlabeleddata improves adversarial robustness,2019, arXiv
 ZOO: Zeroth order opti-mization based black-box attacks to deep neural networks without training substitute models,2017, InAISec
 Sparse and imperceivable adversarial attacks,2019, arXiv
 Boost-ing adversarial attacks with momentum,2018, In CVPR
 Efficient projections ontothe l1-ball for learning in high dimensions,2008, In ICML
 Robustness of rotation-equivariant net-works to adversarial perturbations,2018, arXiv
 A rotation and atranslation suffice: Fooling CNNs with simple transformations,2017, arXiv
 Ex-ploring the landscape of spatial robustness,2019, In ICML
 Detecting adversarialsamples from artifacts,2017, arXiv
 Adversarial and clean data are not twins,2017, arXiv
 Explaining and harnessing adversarialexamples,2014, arXiv
 Strength in numbers: Trading-off robustness and computation viaadversarially-trained ensembles,2018, arXiv
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In ICCV
 Deep residual learning for image recog-nition,2016, In CVPR
 Why relu networks yield high-confidence predictions far away from the training data and how to mitigate the problem,2019, CVPR
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, arXiv
 Early methods for detecting adversarial images,2017, In ICLR
 Learning with a strong adver-sary,2015, arXiv
 Black-box adversarial attacks withlimited queries and information,2018, In ICML
 Prior convictions: Black-box adversarialattacks with bandits and priors,2018, arXiv
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In ICML
 Excessive invari-ance causes adversarial vulnerability,2019, In ICLR
 Testing robustness againstunforeseen adversaries,2019, arXiv
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, arXiv
 Learning multiple layers of features from tiny images,2009, Technical report
 Interpolated adversarial train-ing: Achieving robust neural networks without sacrificing too much accuracy,2019, arXiv
 Gradient-based learning applied todocument recognition,1998, Proc
 Generative adversarial trainer: Defense to adver-sarial perturbations with GAN,2017, arXiv
 On physical adversarial patches for object detection,2019, arXiv
 On norm-agnostic robustness of ad-versarial training,2019, arXiv
 Adversarial camera stickers: A physical camera-based attack on deep learning systems,2019, In ICML
 Adversarial examples detection in deep networks with convolutional filterstatistics,2017, In ICCV
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In CVPR
 Dpatch: Attacking object detectorswith adversarial patches,2018, arXiv
 Adv-bnn: Improved adversarial defensethrough robust bayesian neural network,2019, In ICLR
 Delving into transferable adversarial exam-ples and black-box attacks,2016, arXiv
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, arXiv
 On detecting adversarialperturbations,2017, arXiv
 Distributionalsmoothing with virtual adversarial training,2016, ICLR
 Mnist-c: A robustness benchmark for computer vision,2019, ICMLWorkshops
 Simple black-box adversarial attacks on deepneural networks,2017, In CVPR Workshops
 Readingdigits in natural images with unsupervised feature learning,2011, In NeurIPS
 Towards robust detection of adversarial exam-ples,2018, In NeurIPS
 Automatic differentiation inpytorch,2017, In NeurIPS Workshops
 Scikit-learn: Machine learning in Python,2011, JMLR
 Playing the game of universaladversarial perturbations,2018, CoRR
 Adversarialtraining can hurt generalization,2019, arXiv
 UPSET and ANGRI : Break-ing high performance image classifiers,2017, arXiv
 Ad-versarially robust generalization requires more data,2018, CoRR
 Understanding adversarial training: Increasinglocal stability of supervised models through robust optimization,2018, Neurocomputing
 Attacking the madry defense model with l1-based adversarial ex-amples,2017, arXiv
 Certifiable distributional robustness withprincipled adversarial training,2018, ICLR
 Disentangling adversarial robustness and general-ization,2019, CVPR
 One pixel attack for fooling deepneural networks,2017, arXiv
 Intriguing properties of neural networks,2013, arXiv
 Ensembleadversarial training: Attacks and defenses,2017, arXiv
 Are labels required for improving adversarial robustness?	arXiv,2019,org
 On theconvergence and robustness of adversarial training,2019, In ICML
 Spatially trans-formed adversarial examples,2018, arXiv
 Improvingtransferability of adversarial examples with input diversity,2018, arXiv
 Bayesian adversarial learning,2018, In NeurIPS
 Adversarial examples:Attacks and defenses for deep learning,2017, arXiv
 Adversarial framing forimage and video classification,2019, In AAAI Workshops
 Efficient defenses against adver-sarial attacks,2017, In AISec
 Cost-sensitive robustness against adversarial examples,2018, arXiv
