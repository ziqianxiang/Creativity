title,year,conference
 Wasserstein GAN,2017, arXiv preprintarXiv:1701
 Neural machine translation by jointlylearning to align and translate,2014, arXiv preprint arXiv:1409
 Revisiting dis-tributed synchronous SGD,2016, arXiv preprint arXiv:1604
 Closing the generalization gap of adaptive gradient methods intraining deep neural networks,2018, arXiv preprint arXiv:1806
 Incorporating nesterov momentum into adam,2016, ICLR Workshop
 Global convergence of theheavyball method for convex optimization,2014, arXiv preprint arXiv:1412
 Neural networks for machine learninglecture 6a overview of mini-batch gradient descent,2012, Cited on
 Long short-term memory,1997, Neural computation
 Mobilenets: Efficient convolutional neural networks formobile vision aPPlications,2017, arXiv preprint arXiv:1704
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Acceler-ating stochastic gradient descent for least squares regression,2017, arXiv preprint arXiv:1704
 Adam: A method for stochastic oPtimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2015, arXiv preprintarXiv:1312
 Imagenet classification with deep convo-Iutional neural networks,2012, In Advances in neural information processing systems
 Aggregated momentum: Stabilitythrough passive damping,2018, arXiv preprint arXiv:1804
 Quasi-hyperbolic momentum and Adam for deep learning,2018, arXivpreprint arXiv:1810
 Conditional generative adversarial nets,2014, arXiv preprintarXiv:1411
 Automatic differentiation inpytorch,2017, 2017
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2015, arXiv preprint arXiv:1511
 On the convergence of Adam and beyond,2019, arXivpreprint arXiv:1904
 Faster R-CNN: Towards real-time objectdetection with region proposal networks,2015, In Advances in neural information processing systems
 An overview of gradient descent optimization algorithms,2016, arXiv preprintarXiv:1609
 Long short-term memory recurrent neuralnetwork architectures for large scale acoustic modeling,2014, In Fifteenth annual conference of theinternational speech communication association
 Regularizing deep net-works using efficient layerwise adversarial training,2018, arXiv preprint arXiv:1705
 Very deep multilingual convolu-tional neural networks for LVCSR,2016, In 2016 IEEE International Conference on Acoustics
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 On accelerated methods in optimization,2015, arXiv preprintarXiv:1509
 A variational perspective on acceleratedmethods in optimization,2016, proceedings of the National Academy of Sciences
 A Lyapunov analysis of momentum meth-ods in optimization,2016, arXiv preprint arXiv:1611
 The marginalvalue of adaptive gradient methods in machine learning,2017, In Advances in Neural InformationProcessing Systems
 Aggregated residual trans-formations for deep neural networks,2017, In Proceedings of the IEEE conference on computer visionand pattern recognition
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Adadelta: an adaptive learning rate method,2012, arXiv preprint arXiv:1212
 Yellowfin and the art of momentum tuning,2017, arXiv preprintarXiv:1706
