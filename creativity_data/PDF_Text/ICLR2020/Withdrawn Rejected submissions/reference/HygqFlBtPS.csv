title,year,conference
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Provably minimally-distorted adversarialexamples,2017, arXiv preprint arXiv:1709
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Output range analysis fordeep feedforward neural networks,2018, In NASA Formal Methods Symposium
 Training verified learners with learned verifiers,2018, arXivpreprint arXiv:1805
 Adual approach to scalable verification of deep networks,2018, arXiv preprint arXiv:1803
 Deep neural networks as 0-1 mixed integer linear programs: Afeasibility study,2017, arXiv preprint arXiv:1712
 Ai2: Safety and robustness certification of neural networks with abstract interpretation,2018, In2018 IEEE Symposium on Security and Privacy (SP)
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 On the effectiveness of interval bound propagationfor training verifiably robust models,2018, arXiv preprint arXiv:1810
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Puvae: A variationalautoencoder to purify adversarial examples,2019, arXiv preprint arXiv:1903
 Reluplex: An efficientsmt solver for verifying deep neural networks,2017, In International Conference on Computer AidedVerification
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 An approach to reachability analysis for feed-forward reluneural networks,2017, arXiv preprint arXiv:1706
 Differentiable abstract interpretation for provablyrobust neural networks,2018, In International Conference on Machine Learning
 Certified defenses against adversarialexamples,2018, arXiv preprint arXiv:1801
 A convex relaxationbarrier to tight robust verification of neural networks,2019, NeurIPS
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Towards verification ofartificial neural networks,2015, In MBMV
 Intriguing ProPerties of neural networks,2013, arXiv preprint arXiv:1312
 Evaluating robustness of neural networks with mixedinteger Programming,2017, arXiv preprint arXiv:1711
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, arXiv preprint arXiv:1711
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems
 Training for fasteradversarial robustness verification via inducing relu stability,2018, arXiv preprint arXiv:1809
 You only propagateonce: Painless adversarial training using maximal principle,2019, arXiv preprint arXiv:1905
 Efficient neural networkrobustness certification with general activation functions,2018, In Advances in Neural InformationProcessing Systems
 Towardsstable and efficient training of verifiably robust neural networks,2019, arXiv preprint arXiv:1906
