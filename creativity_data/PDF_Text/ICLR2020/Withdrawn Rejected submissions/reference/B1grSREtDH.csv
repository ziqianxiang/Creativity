title,year,conference
 Surprise-based intrinsic motivation for deep reinforcementlearning,2017, arXiv preprint arXiv:1703
 Theoretical models of learning to learn,1998, In Learning to learn
 Exploration by random networkdistillation,2018, arXiv preprint arXiv:1810
 POMDP-lite for robust robot planningunder uncertainty,2016, In IEEE International Conference on Robotics and Automation
 Rl2: Fastreinforcement learning via slow reinforcement learning,2016, arXiv preprint arXiv:1611
 Probabilistic model-agnostic meta-learning,2018, arXivpreprint arXiv:1806
 Bayesian reinforcementlearning: A survey,2015, Foundations and TrendsR in Machine Learning
 Reinforcement learning with multiple experts:A bayesian model combination approach,2018, In Advances in Neural Information Processing Systems
 Recasting gradient-based meta-learning as hierarchical bayes,2018, arXiv preprint arXiv:1801
 Efficient Bayes-adaptive reinforcement learning usingsample-based search,2012, In Advances in Neural Information Processing Systems
 Meta-reinforcement learning of structured exploration strategies,2018, In Advances in Neural InformationProcessing Systems
 Long short-term memory,1997, Neural computation
 Vime:Variational information maximizing exPloration,2016, In Advances in Neural Information ProcessingSystems
 Residual reinforcement learningfor robot control,2019, In 2019 International Conference on Robotics and Automation (ICRA)
 Plato: Policy learning usingadaPtive trajectory oPtimization,2017, In IEEE International Conference on Robotics and Automation
 Near-Bayesian exPloration in Polynomial time,2009, In InternationalConference on Machine Learning
 SARSOP: Efficient Point-based POMDP Planningby aPProximating oPtimally reachable belief sPaces,2008, In Robotics: Science and Systems
 Bayesian Policy oPtimization for model uncertainty,2019, In International Conference onLearning Representations
 Meta-learning of sequential strategies,2019, arXiv preprintarXiv:1905
 Conservative to confident: treatinguncertainty robustly within learning-based control,2015, In IEEE International Conference on Roboticsand Automation
 Curiosity-driven explorationby self-supervised prediction,2017, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition Workshops
 Sim-to-real transfer ofrobotic control with dynamics randomization,2018, In IEEE International Conference on Robotics andAutomation
 Point-based value iteration: An anytimealgorithm for POMDPs,2003, In International Joint Conference on Artificial Intelligence
 Meta-learners’ learning dynamics are unlike learners’,2019, arXiv preprintarXiv:1905
 Efficient off-policymeta-reinforcement learning via probabilistic context variables,2019, arXiv preprint arXiv:1903
 Trust regionpolicy optimization,2015, In International Conference on Machine Learning
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Monte-carlo planning in large POMDPs,2010, In Advances in NeuralInformation Processing Systems
 Residual policy learning,2018, arXivpreprint arXiv:1812
 Some considerations on learning to explore via meta-reinforcement learning,2018, arXivpreprint arXiv:1803
 Preparing for the unknown: Learning a universalpolicy with online system identification,2017, In Robotics: Science and Systems
