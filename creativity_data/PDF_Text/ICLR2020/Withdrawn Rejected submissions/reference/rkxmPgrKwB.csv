title,year,conference
 Identifying and attackingthe saddle point problem in high-dimensional non-convex optimization,2014, In Advances in NeuralInformation Processing Systems
 Qualitatively characterizing neural network optimizationproblems,2014, arXiv preprint arXiv:1412
 Eigenvalues of the Hessian in deep learning: Singularity andbeyond,2016, arXiv preprint arXiv:1611
 Energylandscapes for machine learning,2017, Physical Chemistry Chemical Physics
 Essentially no barriers in neuralnetwork energy landscape,2018, arXiv preprint arXiv:1803
 Empirical analysis of the Hessian ofover-parametrized neural networks,2017, arXiv preprint arXiv:1706
 Comparing dynamics: Deep neural networks versus glassy systems,2018, arXiv preprintarXiv:1803
 The loss surfaces of multilayernetworks,2015, In Artificial Intelligence and Statistics
 Gaussian processes in machine learning,2003, In Summer School on Machine Learning
 Topology and geometry of half-rectified network optimization,2016, arXivpreprint arXiv:1611
 No bad local minima: Data independent training error guarantees formultilayer neural networks,2016, arXiv preprint arXiv:1605
 Deep learning,2016, 2016
 Neural Networks for Pattern Recognition,1995, Clarendon Press
 On-line learning in soft committee machines,1995, Physical Review E
 Skip connections eliminate singularities,2017, arXiv preprint arXiv:1701
 The full spectrum of deep net Hessians at scale: Dynamics with sample size,2018, arXivpreprint arXiv:1811
 An investigation into neural net optimization via Hessianeigenvalue density,2019, arXiv preprint arXiv:1901
 Exponentially many local minima for single neurons,1996, InAdvances in neural information processing systems
 Neural networks and principal component analysis: Learning from exampleswithout local minima,1989, Neural Networks
 Deep learning without poor local minima,2016, In Advances in Neural InformationProcessing Systems
 Depth creates no bad local minima,2017, arXiv preprint arXiv:1702
 Exact solutions to the nonlinear dynamics of learningin deep linear neural networks,2013, arXiv preprint arXiv:1312
 Nudged elastic band method for finding minimum energypaths of transitions,1998, Classical and Quantum Dynamics in Condensed Phase Simulations
 Neural tangent kernel: Convergence and generalization in neuralnetworks,2018, In Advances in Neural Information Processing Systems
 Gradient descent provably optimizes over-parameterizedneural networks,2018, arXiv preprint arXiv:1810
 Gradient descent finds global minima of deep neuralnetworks,2018, arXiv preprint arXiv:1811
 Statistical mechanics of learning,2001, Cambridge University Press
 Local minima and plateaus in hierarchical structures of multilayerperceptrons,2000, Neural Networks
