title,year,conference
 Group anomaly detection using deepgenerative models,2018, arXiv preprint arXiv:1804
 Online learningwith abstention,2017, arXiv preprint arXiv:1703
 Learning confidence for Out-of-Distribution detection inneural networks,2018, arXiv preprint arXiv:1802
 NICE: Non-linear independent components estimation,2014, arXivpreprint arXiv:1410
 Density estimation using real NVP,2016, arXivpreprint arXiv:1605
 Ex2: Exploration with exemplar models for deepreinforcement learning,2017, In Advances in Neural Information Processing Systems
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In international conference on machine learning
 Neural processes,2018, arXiv preprint arXiv:1807
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 A baseline for detecting misclassified and Out-of-Distributionexamples in neural networks,2016, arXiv preprint arXiv:1610
 Deep anomaly detection with outlierexposure,2018, arXiv preprint arXiv:1812
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Auto-Encoding variational bayes,2013, arXiv preprintarXiv:1312
 Novelty detection with gan,2018, arXiv preprint arXiv:1802
 Towards a theoretical understanding of batch normalization,2018, arXiv preprintarXiv:1805
 Accurate uncertainties for deep learningusing calibrated regression,2018, In International Conference on Machine Learning
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In Advances in Neural Information ProcessingSystems
 Anomaly detection with generativeadversarial networks for multivariate time series,2018, arXiv preprint arXiv:1809
 Enhancing the reliability of out-of-distribution imagedetection in neural networks,2017, arXiv preprint arXiv:1706
 Novelty detection in learning systems,2003, Neural computing surveys
 Universaladversarial perturbations,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Detectingout-of-distribution inputs to deep generative models using a test for typicality,2019, arXiv preprintarXiv:1906
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Deep neural networks are easily fooled: High confidencepredictions for unrecognizable images,2015, In Proceedings of the IEEE conference on computer visionand pattern recognition
 Likelihood ratios for out-of-distribution detection,2019, arXiv preprintarXiv:1906
 PixelCNN++: Improving thePixelCNN with discretized logistic mixture likelihood and other modifications,2017, arXiv preprintarXiv:1701
 PixelDefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 A note on the evaluation of generativemodels,2015, arXiv preprint arXiv:1511
 Sylvesternormalizing flows for variational inference,2018, arXiv preprint arXiv:1803
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
