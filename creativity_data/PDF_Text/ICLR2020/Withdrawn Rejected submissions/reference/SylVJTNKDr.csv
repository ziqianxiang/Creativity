title,year,conference
 Information dropout: Learning optimal representationsthrough noisy computation,2018, IEEE TPAMI
 Deep variational informationbottleneck,2016, arXiv preprint arXiv:1612
 Why Only Us: Language and Evolution,2016, MIT Press
 How agents see things: On visual representations in anemergent language game,2018, In EMNLP
 Anti-efficientencoding in emergent communication,2019, In Proceedings of NeurIPS
 BabyAI: A platform to study the sample efficiency ofgrounded language learning,2019, In Proceedings of ICLR
 Learning phrase representations using rnn encoder-decoder forstatistical machine translation,2014, arXiv preprint arXiv:1406
 Compositional obverter communicationlearning from raw visual input,2018, arXiv preprint arXiv:1804
 Compression as a universal principle of animal behavior,2013, CognitiveScience
 Experimental semiotics: A new approach for studying communication as a formof joint action,2009, Topics in Cognitive Science
 How efficiency shapes human language,2019, Trends in Cognitive Science
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Variance reduction techniques for gradientestimates in reinforcement learning,2004, JMLR
 Emergence of language with multi-agent games: Learning tocommunicate with sequences of symbols,2017, In NIPS
 The Origins of Language,2014, Oxford University Press
 Categorical reparameterization with Gumbel-Softmax,2016, arXivpreprint arXiv:1611
 Kinship categories across languages reflect general communicativeprinciples,2012, Science
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Natural language from artificial life,2002, Artificial life
 Natural language does notemerge’naturally’in multi-agent dialog,2017, arXiv preprint arXiv:1706
 Emergence of lin-guistic communication from referential games with symbolic and pixel input,2018, arXiv preprintarXiv:1804
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Convention harvard university press,1969, Cambridge
 On the pitfalls ofmeasuring emergent communication,2019, In Proceedings of AAMAS
 The concrete distribution: A continuousrelaxation of discrete random variables,2016, arXiv preprint arXiv:1611
 Asynchronous methods for deep reinforcementlearning,2016, In ICML
 Discrete variational autoencoders,2016, arXiv preprint arXiv:1609
 Gradient estimation usingstochastic computation graphs,2015, In NIPS
 Learning multiagent communication withbackpropagation,2016, In NIPS
 The information bottleneck method,1999, In Proceedings of the 37thAnnual Allerton Conference on Communication
 Attention is all you need,2017, In Proceedings of NIPS
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Function optimization using connectionist reinforcement learningalgorithms,1991, Connection Science
 Efficient compression in colornaming and its evolution,2018, Proceedings of the National Academy of Sciences
 Semantic categories of artifactsand animals reflect efficient coding,2019, In Proceedings of CogSci
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
 The general architecture of the agents is same as in Section 3,2014,1
