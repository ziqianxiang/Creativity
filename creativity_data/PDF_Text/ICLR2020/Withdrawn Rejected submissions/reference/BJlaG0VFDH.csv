title,year,conference
 cuDNN: Efficient primitives for deep learning,2020, arXiv:1410
 MEC: memory-efficient convolution for deep neural network,2017, InInternational Conference on Machine Learning (ICML)
 Large scaledistributed deep networks,2012, In Advances in Neural Information Processing Systems
 Deep Learning,2016, MIT Press
 Dynamic network surgery for efficient DNNs,2016, InAdvances in Neural Information Processing Systems
 Network sketching: exploiting binary struc-ture in deep CNNs,2017, In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Deep residual learning for image recog-nition,2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Soft filter pruning for acceleratingdeep convolutional neural networks,2018, arXiv preprint arXiv:1808
 Simplifying neural nets by discovering flat minima,1995, InAdvances in Neural Information Processing Systems
 DroPPruning for model comPression,2018, arXiv preprint arXiv:1812
 In-datacenter performance analysis of a tensor processingunit,2017, In Proceedings of the 44th Annual International Symposium on Computer Architecture
 Optimal brain damage,1990, In Advances in NeuralInformation Processing Systems
 Learn-ing efficient convolutional networks through network slimming,2017, In Proceedings of the IEEEInternational Conference on Computer Vision
 Building a large annotatedcorpus of English: The Penn Treebank,1993, Comput
 Variational dropout sparsifies deepneural networks,2017, In International Conference on Machine Learning (ICML)
 An overview of gradient descent optimization algorithms,2016, arXiv:1609
 Some mathematical notes on three-mode factor analysis,1966, Psychometrika
 Regularization of neuralnetworks using DropConnect,2013, In International Conference on Machine Learning (ICML)
 Alternating multi-bit quantization for recurrent neural networks,2018, In International Conferenceon Learning Representations (ICLR)
 Trained ternary quantization,2017, InInternational Conference on Learning Representations (ICLR)
