title,year,conference
 Long short-term memory-networks for machinereading,2016, In Proceedings of the 2016 Conference on Empirical Methods in Natural LanguageProcessing
 Inductive bias of deep convolutional networks through poolinggeometry,2016, CoRR
 Inductive bias of deep convolutional networks through poolinggeometry,2016, arXiv preprint arXiv:1605
 Super-vised learning of universal sentence representations from natural language inference data,2017, arXivpreprint arXiv:1705
 Generating sequences with recurrent neural networks,2013, CoRR
 Bag of tricks for efficienttext classification,2016, 2016
 End-to-end neural coreference reso-lution,2017, 2017
 On the long-term memory of deep recurrentnetworks,2017, 2017
 Text representation: from vector to tensor,2005, InIEEE International Conference on Data Mining
 Building a large annotatedcorpus of English: the penn treebank,1993, 1993
 Glove: Global vectors for wordrepresentation,2014, In Conference on Empirical Methods in Natural Language Processing
 Semi-supervised se-quence tagging with bidirectional language models,2017, In Proceedings of the 55th Annual Meetingof the Association for Computational Linguistics (Volume 1: Long Papers)
 Deep contextualized word representations,2018, In Proc
 Evaluating effectiveness of shallow anddeep networks to intrusion detection system,2017, In 2017 International Conference on Advances inComputing
 Breaking the softmaxbottleneck: A high-rank RNN language model,2017, CoRR
 A generalizedlanguage model in tensor space,2019, Proceedings of the 2019 Conference on AAAI Conference onArtificial Intelligence
