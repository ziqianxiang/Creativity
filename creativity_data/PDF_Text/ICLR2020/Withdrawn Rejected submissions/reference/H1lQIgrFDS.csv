title,year,conference
  Sorting out lipschitz function approximation,2018,  arXiv:Learning
   Mitigating evasion attacks to deep neural networks viaregion-based classification,2017,  In Proceedings of the 33rd Annual Computer Security ApplicationsConference
   Maximum resilience of artificial neu-ral  networks,1048,   In  Deepak  Dâ€™Souza  and  K
 Parse-val networks: Improving robustness to adversarial examples,2017, arXiv: Machine Learning
 Certified adversarial robustness via randomizedsmoothing,2019, international conference on machine learning
  Imagenet:  A large-scalehierarchical image database,2009,  In 2009 IEEE Computer Society Conference on Computer Visionand Pattern Recognition (CVPR 2009)
  Output range analysisfor deep neural networks,2017, arXiv: Learning
 The logbarrier adversarial attack:making effective use of decision boundary information,2019, arXiv preprint arXiv:1903
  Explaining and harnessing adversarialexamples,2015, international conference on learning representations
  Regularisation of neural net-works by enforcing lipschitz continuity,2018, arXiv: Machine Learning
 On the effectiveness of intervalbound propagation for training verifiably robust models,2018, arXiv: Learning
  Formal guarantees on the robustness of a classifieragainst adversarial manipulation,2017, arXiv: Learning
 Learning multiple layers of features from tiny images,2009, In Technical report
  Certifiedrobustness  to  adversarial  examples  with  differential  privacy,2019,   ieee  symposium  on  security  andprivacy
  A stratified approach to robust-ness for randomly smoothed classifiers,2019,  In Advances in neural information processing systems
  Second-order adversarial attack andcertifiable robustness,2018, arXiv: Learning
 Towards robust neural networks viarandom self-ensemble,2018, In Vittorio Ferrari
   An approach to reachability analysis for feed-forward reluneural networks,2017, arXiv: Artificial Intelligence
 To-wards deep learning models resistant to adversarial attacks,2018, international conference on learningrepresentations
   Differentiable  abstract  interpretation  forprovably robust neural networks,2018, In Jennifer G
  Theoretical evidence for adversarial robustness through randomization:the case of the exponential family,2019,  CoRR
   Provably  robust  deep  learning  via  adversarially  trained  smoothed  classifiers,2019,   arXivpreprint arXiv:1906
      In  Bengio  et  al,1082,  (2018)
  Intriguing properties of neural networks,2014,  international conference onlearning representations
 Evaluating robustness of neural networks with mixedinteger programming,2017, arXiv: Learning
  Enresnet:  Resnet ensemble via thefeynman-kac formalism,2018,  CoRR
 Improving the robustness of deepneural networks via stability training,2016,  computer vision and pattern recognition
