title,year,conference
 Evaluation of outputembeddings for fine-grained image classification,2015, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Synthesizing robust adversarial examples,2018, In ICML
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Towards open set deep networks,2016, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Transductive multi-labelzero-shot learning,2015, arXiv preprint arXiv:1503
 Adversarial examples are a naturalconsequence of test error in noise,2019, In International Conference on Machine Learning
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2018, In ICLR
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Network in network,2013, arXiv preprint arXiv:1312
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, arXiv preprint arXiv:1801
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Universaladversarial perturbations,2017, In 2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Deep neural networks are easily fooled: High confidencepredictions for unrecognizable images,2015, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Zero-shot learning by convex combination of semanticembeddings,2013, arXiv preprint arXiv:1312
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Accessorize to a crime: Realand stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 ACM SIGSACConference on Computer and Communications Security
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2018, In ICLR
 Striving for simplicity: The allconvolutional net,2015, In ICLR (workshop track)
 One pixel attack for fooling deep neuralnetworks,2017, arXiv preprint arXiv:1710
 A global geometric framework fornonlinear dimensionality reduction,2000, science
 What do ai algorithms actually learn?-on falsestructures in deep learning,2019, arXiv preprint arXiv:1906
 Ensemble adversarial training: Attacks and defenses,2018, In ICLR
 Ro-bustness may be at odds with accuracy,2019, In International Conference on Learning Representations
 Understanding the one-pixel attack: Propagation mapsand locality analysis,2019, arXiv preprint arXiv:1902
 Zero-shot learning via semantic similarity embedding,2015, InProceedings ofthe IEEE international conference on computer vision
 Zero-shot recognition via structured prediction,2016, In Europeanconference on computer vision
