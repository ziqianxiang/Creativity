title,year,conference
 Critical learning periods in deep net-works,2019, In International Conference on Learning Representations
 Adaptive estimators show informationcompression in deep neural networks,2019, arXiv preprint arXiv:1902
 Estimating information flow in neural networks,2018, arXiv preprintarXiv:1810
 Î²-bnn: A rate-distortion perspective on bayesian neural networks,2018, NeurIPS Bayesian DeepLearning Workshop
 New insights and perspectives on the natural gradient method,2014, arXiv preprintarXiv:1412
 A pac-bayesian tutorial with a dropout bound,2013, arXiv preprint arXiv:1307
 Opening the black box of deep neural networks via informa-tion,2017, arXiv preprint arXiv:1703
 Deep learning and the information bottleneck principle,2015, InInformation Theory Workshop (ITW)
 The information bottleneck method,1999, The37th annual Allerton Conference on Communication
 Information-theoretic analysis of generalization capability of learn-ing algorithms,2017, In Advances in Neural Information Processing Systems
