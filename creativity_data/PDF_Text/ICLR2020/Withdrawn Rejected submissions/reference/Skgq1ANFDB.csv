title,year,conference
 Sorting out lipschitz function approximation,2018, InICML
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Convex Optimization,0521, Cambridge University Press
 Aunified view of piecewise linear neural network verification,2017, In NeurIPS
 Mitigating evasion attacks to deep neural networks viaregion-based classification,2017, ArXiv
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Provably minimally-distortedadversarial examples,2017, 2017
 Maximum resilience of artificial neuralnetworks,2017, In ATVA
 Certified adversarial robustness via randomizedsmoothing,2019, In ICML
 Provable robustness of relu networksvia maximization of linear regions,2018, ArXiv
 Output range analysisfor deep feedforward neural networks,2018, In NFM
 Training verified learners with learned verifiers,2018, ArXiv
 Formal verification of piece-wise linear feed-forward neural networks,2017, ArXiv
 Ai2: Safety and robustness certification of neural networks with abstractinterpretation,2018, 2018 IEEE Symposium on Security and Privacy (SP)
 On the effectiveness ofinterval bound propagation for training verifiably robust models,2018, ArXiv
 Formal guarantees on the robustness of a classifieragainst adversarial manipulation,2017, In I
 Safety verification of deep neuralnetworks,2016, ArXiv
 Reluplex: Anefficient smt solver for verifying deep neural networks,2017, In CAV
 Adversarial machine learning at scale,2016, ArXiv
 Certified adversarial robustnesswith additive gaussian noise,2018, 2018
 Towards robust neural networks viarandom self-ensemble,2017, ArXiv
 An approach to reachability analysis for feed-forward reluneural networks,2017, ArXiv
 Differentiable abstract interpretation forprovably robust neural networks,2018, In ICML
 Virtual adversarial training: Aregularization method for supervised and semi-supervised learning,2017, IEEE Transactions on PatternAnalysis and Machine Intelligence
 Spectral normalization forgenerative adversarial networks,2018, In International Conference on Learning Representations
 Distillation as a defense to adversarialperturbations against deep neural networks,2016, In 2016 IEEE Symposium on Security and Privacy(SP)
 Practical black-box attacks against deep learning systems using adversarialexamples,2016, CoRR
 Adversarial robustness through local linearization,2019, arXiv preprintarXiv:1907
 Certified defenses against adversarialexamples,2018, ArXiv
 Semidefinite relaxations for certifyingrobustness to adversarial examples,2018, In NeurIPS
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, In International Conference on LearningRepresentations
 The singular values of convolutional layers,2018, arXivpreprint arXiv:1805
 Fast andeffective robustness certification,2018, In NeurIPS
 Understanding imPacts of high-order lossaPProximations and features in deeP learning interPretation,2019, In ICML
 Intriguing ProPerties of neural networks,2014, In International Conference on LearningRepresentations
 Mixtrain: Scalable training ofverifiably robust neural networks,2018, 2018a
 Efficient formal safetyanalysis of neural networks,2018, In NeurIPS
 Provable defenses against adversarial examPles via the convex outeradversarial PolytoPe,2017, ArXiv
 Scaling Provable adversarialdefenses,2018, In NeurIPS
 Efficient neural networkrobustness certification with general activation functions,2018, In S
 Efficient neural networkrobustness certification with general activation functions,2018, ArXiv
 Recurjac: An efficient recursive algorithm forbounding jacobian matrix of neural networks and its applications,2018, In AAAI
 Improving the robustness of deepneural networks via stability training,2016, 2016 IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Such defenses typicallyrely on certification methods which are either exact or conservative,2018, Exact methods report whetheror not there exists a adversarial perturbation inside some lp norm ball
