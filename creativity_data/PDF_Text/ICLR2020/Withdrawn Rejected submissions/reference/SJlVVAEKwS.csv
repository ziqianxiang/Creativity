title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Dimensionality reduction as a defenseagainst evasion attacks on machine learning classifiers,2017, arXiv preprint arXiv:1704
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Thermometer encoding: One hotway to resist adversarial examples,2018, In International Conference on Learning Representations(ICLR)
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Zoo: Zeroth order opti-mization based black-box attacks to deep neural networks without training substitute models,2017, InProceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Query-efficient hard-label black-box attack: An optimization-based approach,2018, arXiv preprintarXiv:1807
 Stochastic activation pruning for robustadversarial defense,2018, In International Conference on Learning Representations
 AdverTorch v0,2019,1: An adversarial robustnesstoolbox based on pytorch
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 Adversarial and clean data are not twins,2017, arXivpreprint arXiv:1704
 Explaining and harnessing adversarialexamples,2015, International Conference on Learning Representations (ICLR)
 Simpleblack-box adversarial attacks,2019, In International Conference on Machine Learning
 Early methods for detecting adversarial images,2017, InternationalConference on Learning Representations (ICLR)
 Black-box adversarial attacks withlimited queries and information,2018, In International Conference on Machine Learning
 Prior convictions: Black-box adversarialattacks with bandits and priors,2018, arXiv preprint arXiv:1807
 Gradient-based learning appliedto document recognition,1998, Proceedings of the IEEE
 Delving into transferable adversarial ex-amples and black-box attacks,2017, International Conference on Learning Representations (ICLR)
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, In International Conference on Learning Representations (ICLR)
 Magnet: a two-pronged defense against adversarial examples,2017, InProceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security
 On detecting adversarialperturbations,2017, International Conference on Learning Representations (ICLR)
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 Decoupling direction and norm for efficient gradient-based l2 adversarial attacks anddefenses,2018, arXiv preprint arXiv:1811
 Very deep convolUtional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations (ICLR)
 IntrigUing properties of neUral networks,2014, International Conference on LearningRepresentations (ICLR)
 Ensemble adversarial training: Attacks and defenses,2018, In International Conference onLearning Representations (ICLR)
 Mitigating adversarialeffects throUgh randomization,2018, In International Conference on Learning Representations (ICLR)
