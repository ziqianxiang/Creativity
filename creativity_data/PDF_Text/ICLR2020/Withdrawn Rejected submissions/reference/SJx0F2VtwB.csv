title,year,conference
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Long short-term memory,1997, Neural computation
 Fusionnet: Fusing via fully-aware attention with aPPlication to machine comPrehension,2017, arXiv preprint arXiv:1711
 Flowqa: GrasPing flow in history for conversa-tional machine comPrehension,2018, arXiv preprint arXiv:1810
 Adam: A method for stochastic oPtimization,2014, arXiv preprintarXiv:1412
 Variational droPout and the local reParame-terization trick,2015, In Advances in Neural Information Processing Systems
 Glove: Global vectors for wordrePresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 Neural machine translation of rare words withsubword units,2015, arXiv preprint arXiv:1508
 Bidirectional attentionflow for machine comPrehension,2016, arXiv preprint arXiv:1611
 Attention is all you need,2017, pp
