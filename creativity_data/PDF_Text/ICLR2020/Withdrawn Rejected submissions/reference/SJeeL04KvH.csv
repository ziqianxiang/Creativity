title,year,conference
 Learning step size controllers for robustneural network training,2016, In Thirtieth AAAI Conference on Artificial Intelligence
 Hyp-rl: Hyperparameter optimization byreinforcement learning,2019, arXiv preprint arXiv:1906
 Fastbayesian optimization of machine learning hyperparameters on large datasets,2016, arXiv preprintarXiv:1605
 Federatedlearning: Strategies for improving communication efficiency,2016, arXiv preprint arXiv:1610
 Hy-perband: A novel bandit-based approach to hyperparameter optimization,2016, arXiv preprintarXiv:1603
 Federatedoptimization in heterogeneous networks,2018, arXiv preprint arXiv:1812
 Stochastic hyperparameter optimization through hypernet-works,2018, arXiv preprint arXiv:1802
 Gradient-based hyperparameter optimiza-tion through reversible learning,2015, In International Conference on Machine Learning
 Communication-efficient learn-ing of deep networks from decentralized data,2016, arXiv preprint arXiv:1602
 Reinforcement learning in non-stationary environ-ments,2019, arXiv preprint arXiv:1905
 Regularizingneural networks by penalizing confident output distributions,2017, arXiv preprint arXiv:1701
 Semi-supervised learning with ladder networks,2015, In Advances in Neural Information Processing Systems
 Stochastic backpropagation and approximateinference in deep generative models,2014, In ICML
 Robust andcommunication-efficient federated learning from non-iid data,2019, arXiv preprint arXiv:1903
 Wasserstein distance guided representationlearning for domain adaptation,2017, arXiv preprint arXiv:1707
 Practical bayesian optimization of machine learn-ing algorithms,2012, In Advances in neural information processing systems
 Speech commands: A dataset for limited-vocabulary speech recognition,2018, arXivpreprint arXiv:1804
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Federatedlearning with non-iid data,2018, arXiv preprint arXiv:1806
