title,year,conference
 Extremely large minibatch SGD: trainingResNet-50 on ImageNet in 15 minutes,2017, arXiv preprint arXiv:1711
 Learning to represent programswith graphs,2018, In ICLR
 Implementing sparse matrix-vector multiplication on throughput-orientedprocessors,2009, In Proceedings of the Conference on High Performance Computing Networking
 Learning phrase representations using RNN encoder-decoder for statistical ma-chine translation,2014, In EMNLP
 Reducing the bandwidth of sparse symmetric matrices,1969, In ACM
 Learning steady-states of itera-tive algorithms over graphs,2018, In ICML
 A survey of graph layout problems,2002, ACM ComputingSurveys (CSUR)
 Neuralmessage passing for quantum chemistry,2017, In ICML
 A new golden age for computer architecture,2019, ACM
 Deep learning,2015, Nature
 Gated graph sequence neuralnetworks,2016, In ICLR
 Towardsefficient large-scale graph neural network computing,2018, arXiv preprint arXiv:1810
 Iterative methods for sparse linear systems,2003, 2003
 Measuring the effects of data parallelism on neural network training,2018, arXivpreprint arXiv:1811
 Very deep convolutional networks for large-scale image recogni-tion,2015, In ICLR
 Direct solutions of sparse network equations by optimallyordered triangular factorization,1967, Proceedings of the IEEE
 Deep graph library: Towards efficient and scalable deep learning ongraphs,2019, In ICLR Workshop on Representation Learning on Graphs and Manifolds
 Acomprehensive survey on graph neural networks,2019, arXiv preprint arXiv:1901
 Aggregated residual trans-formations for deep neural networks,2017, In CVPR
 Imagenet training inminutes,2018, In Proceedings of the 47th International Conference on Parallel Processing
 Graph neuralnetWorks: A revieW of methods and applications,2018, arXiv preprint arXiv:1812
