title,year,conference
 Explaining a black-box using deep variationalinformation bottleneck approach,2019, arXiv preprint arXiv:1902
 Universal approximation bounds for superpositions of a sigmoidal function,1993, IEEETransactions on Information theory
 Network dissection:Quantifying interpretability of deep visual representations,2017, In Computer Vision and PatternRecognition
 Large scale GAN training for high fidelitynatural image synthesis,2019, In International Conference on Learning Representations
 Multi-marginalwasserstein gan,2019, In Advances in Neural Information Processing Systems
 Big-little net:An efficient multi-scale feature representation for visual and speech recognition,2019, In InternationalConference on Learning Representations
 A closer lookat few-shot classification,2019, In International Conference on Learning Representations
 Roc-GAN: Robust conditional GAN,2019, InInternational Conference on Learning Representations
 Sinkhorn distances: Lightspeed computation of optimal transport,2013, In Advances inneural information processing systems
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Learningwith a wasserstein loss,2015, In Advances in Neural Information Processing Systems
 Learning generative models with sinkhorn diver-gences,2017, arXiv preprint arXiv:1706
 Lisa: Explaining recurrent neural network judgments via layer-wise semantic accumulation and example to pattern transformation,2018, Empirical Methods in NaturalLanguage Processing Workshop BlackboxNLP
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Multi-class classificationwithout multi-class labels,2019, In International Conference on Learning Representations
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In International Conference on Machine Learning
 Shallow-deep networks: Understanding andmitigating network overthinking,2019, In International Conference on Machine Learning
 Unsupervised learning ofhierarchical representations with convolutional deep belief networks,2011, Communications of the ACM
 Rectifier nonlinearities improve neural networkacoustic models,2013, In International Conference on Machine Learning
 Distributed representationsof words and phrases and their compositionality,2013, In Advances in neural information processingsystems
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Going deeper with convolutions,2015, In ComputerVision and Pattern Recognition
 An analytical formula of population gradient for two-layered relu network and itsapplications in convergence and critical point analysis,2017, In International Conference on MachineLearning
 Deep learning and the information bottleneck principle,2015, In 2015IEEE Information Theory Workshop (ITW)
 Unsupervised speech recognitionvia segmental empirical output distribution matching,2019, In International Conference on LearningRepresentations
 Visualizing and understanding convolutional networks,2014, InEuropean conference on computer vision
 Interpreting cnnknowledge via an explanatory graph,2018, In AAAI Conference on Artificial Intelligence
 Interpreting cnns via decision trees,2019, InComputer Vision and Pattern Recognition
