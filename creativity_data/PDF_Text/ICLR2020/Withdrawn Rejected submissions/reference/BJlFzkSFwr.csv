title,year,conference
 Sequence classi-fication with human attention,2018, In Proceedings of the 22nd Conference on Computational NaturalLanguage Learning
 Identifying beneficial task relations for multi-task learningin deep neural networks,2017, In Proceedings of the 15th Conference of the European Chapter of theAssociation for Computational Linguistics
 Multi-task learning for sequence tagging: An em-pirical study,2018, In Proceedings of the 27th International Conference on Computational Linguistics
 Constructions: A construction grammar approach to argument structure,1995, TheUniversity of Chicago Press
 Framewise phoneme classification with bidirectional lstmand other neural network architectures,2005, NEURAL NETWORKS
 Semantic Interpretation and the Resolution of Ambiguity,1987, Cambridge UniversityPress
 Assessing the ability of LSTMs to learn syntax-sensitive dependencies,2016, Transactions of the Association for Computational Linguistics
 Neural machine translation withsupervised attention,2016, In Proceedings of COLING 2016
 When is multitask learning effective? semantic se-quence prediction under varying data conditions,2017, In Proceedings of the 15th Conference of theEuropean Chapter of the Association for Computational Linguistics
 Semi-supervised multitask learning for sequence labeling,2017, In Proceedings of the 55thAnnual Meeting of the Association for Computational Linguistics
 Jointly learning to label sentences and tokens,2019, In Proceedings ofthe 33rd National Conference on Artifical Intelligence
 An overview of multi-task learning in deep neural networks,2017, arXiv preprintarXiv:1706
 Recursive deep models for semantic compositionality over a sentiment tree-bank,2013, In Proceedings of the Conference on Empirical Methods in Natural Language Processing
 Re-thinking the inception architecture for computer vision,2016, In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition
