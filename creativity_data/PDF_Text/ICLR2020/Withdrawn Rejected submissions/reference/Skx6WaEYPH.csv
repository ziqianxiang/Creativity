title,year,conference
 Genattack: Practicalblack-box attacks with gradient-free optimization,2018, CoRR
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, CoRR
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Magnet and ”efficient defenses against adversarial attacks” arenot robust to adversarial examples,2017, arXiv preprint arXiv:1711
 Zoo: Zeroth orderoptimization based black-box attacks to deep neural networks without training substitute models,2017, InProceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Detecting adversarialsamples from artifacts,2017, CoRR
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 A new perspective on machine learning: How to do perfect supervised learning,2019, arXivpreprint arXiv:1901
 A new approach to utterance verification based on neighborhoodinformation in model space,2003, IEEE Transactions on Speech and Audio Processing
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 The limitations ofdeep learning in adversarial settings,2016, In 2016 IEEE European Symposium on Security and Privacy(EuroS P)
 Distillation as a defense to adversarialperturbations against deep neural networks,2016, In 2016 IEEE Symposium on Security and Privacy(SP)
 Transferability in machine learning:from phenomena to black-box attacks using adversarial samples,2016, CoRR
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Foolbox: A python toolbox to benchmarkthe robustness of machine learning models,2017, arXiv preprint arXiv:1707
 Adversarial diversity and hard positivegeneration,2016, In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Workshops
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 A treatise on the theory of Bessel functions,1995, Cambridge university press
 Mitigating adversarialeffects through randomization,2017, CoRR
