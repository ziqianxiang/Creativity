title,year,conference
 Implicit Regularization in Deep Matrix Factorization,2019, InAdvances in Neural Information Processing Systems 33
 The committee machine:Computational to statistical gaps in learning a two-layers neural network,2018, In Advances in NeuralInformation Processing Systems 31
 Optimal errors and phase transitionsin high-dimensional generalized linear models,2019, Proceedings of the National Academy of Sciences
 Learning by on-line gradient descent,1995, J
 Invaraint scattering convolution networks,2013, IEEE Transactions on PatternAnalysis and Machine Intelligence
 Classification and Geometry of General PerceptualManifolds,2018, Physical Review X
 Learning intrinsic dimension and intrinsic entropy of high-dimensionaldatasets,2004, In 2004 12th European Signal Processing Conference
 Geometrical and Statistical Properties of Systems of Linear Inequalities with Applicationsin Pattern Recognition,1965, IEEE Transactions on Electronic Computers
 Statistical Mechanics of Learning,2001, Cambridge University Press
 Estimating the intrinsicdimension of datasets by a minimal neighborhood information,2017, Scientific Reports
 Entropyand mutual information in models of deep neural networks,2018, In Advances in Neural InformationProcessing Systems 31
 Learning one-hidden-layer neural networks with landscape design,2017, arXivpreprint arXiv:1711
 Dynamics of stochastic gradientdescent for two-layer neural networks in the teacher-student setup,2019, to appear
 Deep learning,2016, MIT Press
 Measuring the strangeness of strange attractors,1983, Physica D: NonlinearPhenomena
 Maximum likelihood estimation of intrinsic dimension,2004, In Advances inNeural Information Processing Systems 17
 Convergent Learning: Do different neuralnetworks learn the same representations? In D,2015, Storcheus
 The generalization error of random features regression: Precise asymptoticsand double descent curve,2019, arXiv preprint arXiv:1908
 Foundations of Machine Learning,2012, MIT Press
 Insights on representational similarity in neural networks withcanonical correlation,2018, In Advances in Neural Information Processing Systems 31
 Deep learning and hierarchical generative models,2018, arXiv preprint arXiv:1612
 A probabilistic framework for deep learning,2016, In D
 SVCCA: Singular Vector CanonicalCorrelation Analysis for Deep Learning Dynamics and Interpretability,2017, In Advances in NeuralInformation Processing Systems 30
 Natural Gradient Descent for On-Line Learning,1998, PhysicalReview Letters
 Counting the learnable functions ofstructured data,2019, arXiv:1903
 A mathematical theory of semantic development indeep neural networks,2019, Proceedings of the National Academy of Sciences
 Asymptotic learning curves of kernel methods: empirical datav,2019,s
 The statistical mechanics of learning a rule,1993, Reviews of ModernPhysics
 The Efficiency and the Robustness of Natural Gradient Descent LearningRule,1998, In M I Jordan
 Statistical physics of inference: thresholds and algorithms,2016, Adv
