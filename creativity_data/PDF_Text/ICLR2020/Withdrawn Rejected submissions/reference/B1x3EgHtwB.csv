title,year,conference
 A convergence theory for deep learning via over-parameterization,2018, arXiv Preprint
 Learning the number of neurons in deep networks,2016, InAdvances in Neural Information Processing Systems
 Compression-aware training of deep networks,2017, In Advancesin Neural Information Processing Systems
 On the optimization of deep networks: Implicitacceleration by overparameterization,2018, In International Conference on Machine Learning
 Neural networks and principal component analysis: Learning fromexamples without local minima,1989, IEEE Transactions on Neural Networks
 The cityscapes dataset for semanticurban scene understanding,2016, In Conference on Computer Vision and Pattern Recognition
 Predicting parameters in deeplearning,2013, In Advances in Neural Information Processing Systems
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In International Conference on ComputerVision
 Deep residual learning for image recog-nition,2016, In Conference on Computer Vision and Pattern Recognition
 Distilling the knowledge in a neural network,2015, arXivPreprint
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv Preprint
 Densely connectedconvolutional networks,2017, In Conference on Computer Vision and Pattern Recognition
 Yolo-lite: A real-time object detection algo-rithm optimized for non-gpu computers,2018, In IEEE International Conference on Big Data
 Flattened convolutional neural networksfor feedforward acceleration,2015, In International Conference on Learning Representations
 Deep learning without poor local minima,2016, In Advances in Neural InformationProcessing Systems
 Generalization in deep learning,2018, InMathematics of Deep Learning
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in Neural Information Processing Systems
 Deep linear networks with arbitrary loss: All local minimaare global,2018, In International Conference on Machine Learning
 Optimal brain damage,1990, In Advances in NeuralInformation Processing Systems
 Visualizing the loss land-scape of neural nets,2018, In Advances in Neural Information Processing Systems
 Sparse convo-lutional neural networks,2015, In Conference on Computer Vision and Pattern Recognition
 Fully convolutional networks for semanticsegmentation,2015, In Conference on Computer Vision and Pattern Recognition
 Perforatedcnns: Acceleration through elimination ofredundant convolutions,2016, In Advances in Neural Information Processing Systems
 Shufflenet v2: Practical guidelines forefficient cnn architecture design,2018, In European Conference on Computer Vision
 All you need is a good init,2015, Computing Research Repository
 Learning deep representations with probabilistic knowledgetransfer,2018, In European Conference on Computer Vision
 Yolov3: An incremental improvement,2018, arXiv Preprint
 Faster r-cnn: Towards real-time objectdetection with region proposal networks,2015, In Advances in Neural Information Processing Systems
 Erfnet: Efficient residual factorized convnetfor real-time semantic segmentation,2018, IEEE Transactions on Intelligent Transportation Systems
 Fitnets: Hints for thin deep nets,2014, arXiv Preprint
 U-net: Convolutional networks for biomedical image seg-mentation,2015, In Conference on Medical Image Computing and Computer Assisted Intervention
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Conference on Computer Vision andPattern Recognition
 Exact solutions to the nonlinear dy-namics of learning in deep linear neural networks,2014, In International Conference on LearningRepresentations
 Very deep convolutional networks for large-scale image recogni-tion,2015, In International Conference on Learning Representations
 Going deeper with convolutions,2015, InConference on Computer Vision and Pattern Recognition
 Re-thinking the inception architecture for computer vision,2016, In Conference on Computer Vision andPattern Recognition
 Learning structured sparsity indeep neural networks,2016, In Advances in Neural Information Processing Systems
 Coordinating filters forfaster deep neural networks,2017, In International Conference on Computer Vision
 Paying more attention to attention: Improving the per-formance of convolutional neural networks via attention transfer,2017, In International Conference onLearning Representations
 Critical points of linear neural networks: Analytical forms and land-scape properties,2018, In International Conference on Learning Representations
