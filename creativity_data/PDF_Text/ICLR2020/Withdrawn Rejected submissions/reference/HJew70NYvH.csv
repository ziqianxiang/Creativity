title,year,conference
 Thinking fast and slow with deep learning andtree search,2017, In NIPS
   Emergent Tool Use From Multi-Agent Autocurricula,2019,   arXiv preprintarXiv:1909
 Openai Gym,2016, arXiv preprint arXiv:1606
 ASurvey of Monte Carlo Tree Search Methods,2012, IEEE Transactions on Computational Intelligenceand AI in games
 Deep ReinforcementLearning in a Handful of Trials using Probabilistic Dynamics Models,2018, In NIPS
 Continuous upper confidence trees,2011, In Proceedings of the 5th International Conferenceon Learning and Intelligent Optimization
  Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search,2006,  InInternational conference on computers and games
 Benchmarking DeepReinforcement Learning for Continuous Control,2016, In ICML
 Search on the Replay Buffer:Bridging Planning and Reinforcement Learning,2019, arXiv preprint arXiv:1906
  P3O: Policy-on Policy-off PolicyOptimization,2019, arXiv preprint arXiv:1905
 Progressive Strategies For Monte-CarloTree Search,2008, In New Mathematics and Natural Computation (NMNC)
 TreeQN and ATreeC: Differentiable treeplanning for deep reinforcement learning,2017, arXiv preprint arXiv:1710
 Soft Actor-Critic: Off-policyMaximum Entropy Deep Reinforcement Learning with a Stochastic Actor,2018,   arXiv preprintarXiv:1801
 Tensorflow Agents: Efficient BatchedReinforcement Learning in Tensorflow,2017, arXiv preprint arXiv:1709
 Value Prediction Network,2017, NIPS
 Adam: A Method for Stochastic Optimization,2014, arXiv preprintarXiv:1412
   Bandit based Monte-Carlo Planning,2006,   In Europeanconference on machine learning
 Model-EnsembleTrust-Region Policy Optimization,2018, ICLR
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Mpc-inspired Neural Network Policies for SequentialDecision Making,2018, arXiv preprint arXiv:1802
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Asynchronous Methods for Deep ReinforcementLearning,2016, In International conference on machine learning
 A0c: Alpha zero incontinuous action space,2018, arXiv preprint arXiv:1805
 Deepstack: Expert-level ArtificialIntelligence in Heads-up No-limit Poker,2017, Science
 Combiningpolicy gradient and q-learning,2016, arXiv preprint arXiv:1611
 Multi-armed Bandits with Episode Context,2011, Annals of Mathematics andArtificial Intelligence
 Addressing Function Approximation Error in Actor-CriticMethods,2018, 2018
 Trust RegionPolicy Optimization,2015, In ICML
   High-dimensional Continuous Control using Generalized Advantage Estimation,2015,   arXiv preprintarXiv:1506
  ProximalPolicy Optimization Algorithms,2017, arXiv preprint arXiv:1707
 World-championship-caliber Scrabble,2002, Artificial Intelligence
 Mas-tering the Game of Go with Deep Neural Networks and Tree Search,2016, nature
 Mastering Chessand Shogi by Self-play with a General Reinforcement Learning Algorithm,2017,   arXiv preprintarXiv:1712
 Mastering the Game ofGo without Human Knowledge,2017, Nature
   UniversalPlanning Networks,2018, arXiv preprint arXiv:1804
 Discretizing Continuous Action Space for On-policy Opti-mization,2019, arXiv preprint arXiv:1901
 Data-efficient Off-policy Policy Evaluation for Reinforce-ment Learning,2016, In International Conference on Machine Learning
   Sample efficient actor-critic with experience replay,2016,   arXiv preprintarXiv:1611
 Deep learning for real-time atari game playusing offline Monte-Carlo tree search planning,2014, 2014
