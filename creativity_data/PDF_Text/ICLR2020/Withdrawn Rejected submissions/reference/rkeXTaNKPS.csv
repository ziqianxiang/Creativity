title,year,conference
 Discrete wasserstein barycenters: optimaltransport for discrete data,2016, Mathematical Methods of Operations Research
 Wasserstein gan,2017, arXiv preprintarXiv:1701
 Learning with pseudo-ensembles,2014, In Advancesin Neural Information Processing Systems
 Geometricdeep learning: going beyond euclidean data,2017, IEEE Signal Processing Magazine
 Optimal transport for domainadaptation,2017, IEEE transactions on pattern analysis and machine intelligence
 Sinkhorn distances: Lightspeed computation of optimal transport,2013, In Advances inneural information processing systems
 Fast computation of wasserstein barycenters,2014, In InternationalConference on Machine Learning
 Learningwith a wasserstein loss,2015, In Advances in Neural Information Processing Systems
 Semi-supervised learning by entropy minimization,2005, In Advancesin neural information processing systems
 Probability inequalities for sums of bounded random variables,1994, In The CollectedWorks of Wassily Hoeffding
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Learning multiple layers of features from tiny images,2009, 2009
 Imagenet classification with deep convo-lutional neural networks,2012, In F
 Temporal ensembling for semi-supervised learning,2016, arXiv preprintarXiv:1610
 Pseudo-label: The simple and efficient semi-supervised learning method for deepneural networks,2013, In Workshop on Challenges in Representation Learning
 Rectifier nonlinearities improve neural networkacoustic models,2013, In Proc
 Variational wasserstein clustering,2018, arXivpreprint arXiv:1806
 Virtual adversarial training: aregularization method for supervised and semi-supervised learning,2018, IEEE transactions on patternanalysis and machine intelligence
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS workshop on deep learningand unsupervised feature learning
 Borrowing strengh in hierarchical bayes: Posterior concentration of thedirichlet base measure,2016, Bernoulli
 Realisticevaluation of deep semi-supervised learning algorithms,2018, In Advances in Neural InformationProcessing Systems
 Regularizingneural networks by penalizing confident output distributions,2017, arXiv preprint arXiv:1701
 Computational optimal transport,2019, Foundations and TrendsÂ® inMachine Learning
 Quantization and the method of k-means,1982, IEEE Transactions on Information theory
 Semi-supervisedlearning With ladder netWorks,2015, In Advances in Neural Information Processing Systems
 Mutual exclusivity loss for semi-superviseddeep learning,2016, In Image Processing (ICIP)
 Regularization with stochastic transforma-tions and perturbations for deep semi-supervised learning,2016, In Advances in Neural InformationProcessing Systems
 Principal geodesic analysis for probability measures under theoptimal transport metric,2015, In Advances in Neural Information Processing Systems
 Mean teachers are better role models: Weight-averaged consis-tency targets improve semi-supervised deep learning results,2017, In Advances in neural informationprocessing systems
 Wide residual networks,2016, arXiv PrePrint arXiv:1605
