title,year,conference
 Obfuscated gradients give a false sense of secu-rity: Circumventing defenses to adversarial examples,2018, In Jennifer Dy and Andreas Krause (eds
 Towards evaluating the robustness of neural networks,2017, In2017 IEEE Symposium on Security and Privacy
 Certified adversarial robustness via randomizedsmoothing,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Generalized no free lunch theorem for adversarial robustness,2019, In KamalikaChaudhuri and Ruslan Salakhutdinov (eds
 Explaining and harnessing adversarialexamples,2015, In 3rd International Conference on Learning Representations
 Deep neural networksfor acoustic modeling in speech recognition,2012, IEEE Signal processing magazine
 Retrieval-augmented convolutional neural networks againstadversarial examples,2019, In The IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Adversarial examples in the physicalworld,2017, In 5th International Conference on Learning Representations
 Generative adversarial trainer: Defense to ad-versarial perturbations with GAN,2017, CoRR
 On certifying non-Uniform boUnds against adver-sarial attacks,2019, In Kamalika ChaUdhUri and RUslan SalakhUtdinov (eds
 Deepfool: A simple andaccUrate method to fool deep neUral networks,2016, In 2016 IEEE Conference on Computer Vision andPattern Recognition
 Distillationas a defense to adversarial pertUrbations against deep neUral networks,2016, In IEEE Symposium onSecurity and Privacy
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017ACM on Asia Conference on Computer and Communications Security
 Technical report on the cleverhans v2,2018,1
 Certified defenses against adversarialexamples,2018, In 6th International Conference on Learning Representations
 The odds are odd: A statistical test for detectingadversarial examples,2019, In Kamalika ChaUdhUri and RUslan SalakhUtdinov (eds
 Intriguing properties of neural networks,2014, In 2nd International Conferenceon Learning Representations
 Analyzing the robustness of nearest neighborsto adversarial examples,2018, In Jennifer Dy and Andreas Krause (eds
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In Jennifer Dy and Andreas Krause (eds
