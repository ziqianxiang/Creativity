title,year,conference
   Concreteproblems in ai safety,2016, arXiv preprint arXiv:1606
 Openai gym,2016, arXiv preprint arXiv:1606
   A lyapunov-basedapproach to safe reinforcement learning,2018, In Advances in Neural Information Processing Systems
 Deep reinforcementlearning from human preferences,2017, In Advances in Neural Information Processing Systems
 Model-basedreinforcement learning via meta-policy optimization,2018, arXiv preprint arXiv:1809
  Safeexploration in continuous action spaces,2018, arXiv preprint arXiv:1801
 Leave no trace: Learning to reset for safeand autonomous reinforcement learning,2017, arXiv preprint arXiv:1711
   Variational intrinsic control,2016,   arXiv preprintarXiv:1611
 Cooperative inverse reinforcementlearning,2016, In Advances in neural information processing systems
 Model-based reinforcement learningfor atari,2019, arXiv preprint arXiv:1903
 Adam: A method for stochastic optimization,2014, arXiv preprint arXiv:1412
 Penalizing side effectsusing stepwise relative reachability,2018, arXiv preprint arXiv:1806
  Model-ensemble trust-regionpolicy optimization,2018, arXiv preprint arXiv:1802
 Ai safety gridworlds,2017, arXiv preprint arXiv:1711
  Safe exploration in markov decision processes,2012,  arXiv preprintarXiv:1205
 Cognitive maps in rats and men,1948, Psychological review
 Conservative agency via attainable utilitypreservation,2019, arXiv preprint arXiv:1902
 Imagination-augmented agents fordeep reinforcement learning,2017, arXiv preprint arXiv:1707
 Maximum entropy inverse reinforcementlearning,2008, 2008
