title,year,conference
 Reconciling modern machine learningand the bias-variance trade-off,2018, arXiv preprint arXiv:1812
 Sparse networks from scratch: Faster training without losingperformance,2019, arXiv preprint arXiv:1907
 Sharp minima can generalize fordeep nets,2017, arXiv preprint arXiv:1703
 The state of sparsity in deep neural networks,2019, CoRR
 Second order derivatives for network pruning: Optimal brainsurgeon,1993, In Advances in neural information processing systems
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Flat minima,1997, Neural Computation
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 On large-batch training for deep learning: Generalization gap and sharp minima,2016, arXivpreprint arXiv:1609
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Optimal brain damage,1990, In Advances in neuralinformation processing systems
 Pruning filters forefficient convnets,2016, arXiv preprint arXiv:1608
 Learningefficient convolutional networks through network slimming,2017, In Computer Vision (ICCV)
 Bayesian compression for deep learning,2017, InAdvances in Neural Information Processing Systems
 Variational dropout sparsifies deep neuralnetworks,2017, arXiv preprint arXiv:1701
 On the importance ofsingle directions for generalization,2018, In Proceeding of the International Conference on LearningRepresentations
 Generalization in deep networks: The role of distance frominitialization,2019, arXiv preprint arXiv:1901
 Exploring sparsity in recurrentneural networks,2017, arXiv preprint arXiv:1704
 In search of the real inductive bias: On therole of implicit regularization in deep learning,2014, arXiv preprint arXiv:1412
 Towardsunderstanding the role of over-parametrization in generalization of neural networks,2018, arXiv preprintarXiv:1805
 Analyzing noise in autoencoders and deepnetworks,2014, arXiv preprint arXiv:1406
 Modeling by shortest data description,1978, Automatica
 Understanding machine learning: From theory toalgorithms,2014, Cambridge university press
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Hessian-based analysisof large batch training and robustness to adversaries,2018, In Advances in Neural Information ProcessingSystems
 Rethinking the smaller-norm-less-informativeassumption in channel pruning of convolution layers,2018, arXiv preprint arXiv:1802
 Gate decorator: Global filterpruning method for accelerating deep convolutional neural networks,2019, In Advances in NeuralInformation Processing Systems
 Nisp: Pruning networks using neuron importance scorepropagation,2018, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
