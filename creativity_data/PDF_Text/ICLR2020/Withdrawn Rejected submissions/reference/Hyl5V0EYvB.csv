title,year,conference
 Synthesizing robust adversarialexamples,2017, CoRR
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 On evaluating adversarialrobustness,2019, CoRR
 Sensitivity of deep convolutional net-works to Gabor noise,2019, CoRR
 Provable robustness against all adversarial lp-perturbations forp â‰¥ 1,2019, CoRR
 ImageNet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Arotation and a translation suffice: Fooling CNNs with simple transformations,2017, arXiv preprintarXiv:1712
 Evaluating and understanding the robustnessof adversarial logit pairing,2018, arXiv preprint arXiv:1807
 Adversarial examples are a naturalconsequence of test error in noise,2019, arXiv preprint arXiv:1901
 An algorithm for quadratic programming,1956, Naval researchlogistics quarterly
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Benchmarking neural network robustness to common cor-ruptions and perturbations,2019, In International Conference on Learning Representations
 Natural adversarialexamples,2019, arXiv preprint arXiv:1907
 Procedural noise using sparseGabor convolution,0730, ACMTrans
 DeepFool: a simple andaccurate method to fool deep neural networks,2015, arXiv preprint arXiv:1511
 The building blocks of interpretability,2018, Distill
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 L2-nonexpansive neural networks,2019, In International Conferenceon Learning Representations (ICLR)
 JPEG-resistant adversarial images,2017, In NIPS 2017 Workshop onMachine Learning and Computer Security
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Unbiased look at dataset bias,2011, In IEEE Conference onComputer Vision and Pattern Recognition (CVPR)
 Examining the impact of blur onrecognition by convolutional networks,2016, CoRR
 Spatially trans-formed adversarial examples,2018, arXiv preprint arXiv:1801
 Feature denoisingfor improving adversarial robustness,2018, arXiv preprint arXiv:1812
 Interpreting adversarially trained convolutional neural net-works,2019, In International Conference on Machine Learning (ICML)
