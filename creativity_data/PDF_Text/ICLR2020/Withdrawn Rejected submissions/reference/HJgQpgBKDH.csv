title,year,conference
 Learning from untrusted data,2017, In Proceedingsof the 49th Annual ACM SIGACT Symposium on Theory of Computing
  Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Classification in the presence of label noise: a survey,2013, IEEEtransactions on neural networks and learning systems
  Using trusted data to traindeep networks on labels corrupted by severe noise,2018, In Advances in Neural Information ProcessingSystems
  Long short-term memory,1997,  Neural computation
  Adam: A method for stochastic optimization,2014,  arXiv preprintarXiv:1412
 Design of robust neural networkclassifiers,1998, In Proceedings of the 1998 IEEE International Conference on Acoustics
 Learning fromnoisy labels with distillation,2017, In The IEEE International Conference on Computer Vision (ICCV)
 Darts: Differentiable architecture search,2018, arXivpreprint arXiv:1806
 Gradient-based hyperparameter optimizationthrough reversible learning,2015, In International Conference on Machine Learning
 Learning withnoisy labels,2013, In Advances in neural information processing systems
 A study of the effect of different typesof noise on the precision of supervised learning techniques,2010, Artificial intelligence review
 Makingdeep neural networks robust to label noise:  A loss correction approach,2017,  In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition
    Hyperparameter  optimization  with  approximate  gradient,2016,    arXiv  preprintarXiv:1602
  Training deep neural networks on noisy labels with bootstrapping,2014,  arXiv preprintarXiv:1412
  Trainingconvolutional networks with noisy labels,2014, arXiv preprint arXiv:1406
 Learningfrom noisy large-scale datasets with minimal supervision,2017, In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition
  Learning from massive noisylabeled data for image classification,2015, In Proceedings of the IEEE conference on computer visionand pattern recognition
  Unsupervised dataaugmentation for consistency training,2019, arXiv preprint arXiv:1904
