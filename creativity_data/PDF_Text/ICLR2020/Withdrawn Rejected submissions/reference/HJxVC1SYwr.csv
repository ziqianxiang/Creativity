title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 ImageNet: A Large-Scale HierarchicalImage Database,2009, In CVPR09
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Univer-sal adversarial perturbations against semantic image segmentation,2017, In 2017 IEEE InternationalConference on Computer Vision (ICCV)
 Universaladversarial perturbations,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Generative adversarial pertur-bations,2018, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Nag: Network for ad-versary generation,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Accessorize to a crime:Real and stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 ACMSIGSAC Conference on Computer and Communications Security
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
