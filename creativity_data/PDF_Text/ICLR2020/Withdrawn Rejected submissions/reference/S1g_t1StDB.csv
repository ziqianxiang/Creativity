title,year,conference
 Vision-and-language navigation: Interpretingvisually-grounded navigation instructions in real environments,2018, In Proc
 Neural module networks,2016, InProc
 Hindsight experience re-play,2017, In Proc
 Weakly supervised learning of semantic parsers for mappinginstructions to actions,2013, Transactions of the Association for Computational Linguistics
 Systematic generalization: What is required and can it be learned? In Proc,2019, ofICLR
 Meteor: An automatic metric for mt evaluation with improvedcorrelation with human judgments,2005, In Proc
 In Proc,2016, of NeurIPS
 Scheduled sampling for sequenceprediction with recurrent neural networks,2015, In Proc
 Home: a household multimodal environment,2017, InProc
 Actrce: Augmenting experiencevia teacherâ€™s advice for multi-goal reinforcement learning,2018, 1st Workshop on Goal Specificationsfor Reinforcement Learning
 Learning to interpret natural language navigation instruc-tions from observations,2011, In Proc
 Touchdown: Naturallanguage navigation and spatial reasoning in visual street environments,2019, In Proc
 BabyAI: First steps towards grounded language learningwith a human in the loop,2019, In Proc
 Empirical evaluation ofgated recurrent neural networks on sequence modeling,2014, In Proc
 Guiding policies with language via meta-learning,2018, In Proc
 Quantifying generaliza-tion in reinforcement learning,2018, arXiv preprint arXiv:1812
 Dher: Hindsight experi-ence replay for dynamic goals,2019, In Proc
 From language to goals:Inverse reinforcement learning for vision-based instruction following,2019, In Proc of
 Deep reinforcement learning with double q-learning,2016, In Proc
 Grounded lan-guage learning in a simulated 3d world,2017, arXiv preprint arXiv:1706
 Learning to follow directions in street view,2019, arXiv preprintarXiv:1903
 Deep q-learning from demonstrations,2018, InProc
 Compositional attention networks for machinereasoning,2018, In Proc
 Language as an abstraction for hier-archical deep reinforcement learning,2019, arXiv preprint arXiv:1906
 Virtual embodiment: A scalablelong-term strategy for artificial intelligence research,2016, arXiv preprint arXiv:1610
 Adam: Amethod for stochastic optimization,2015, In Proc
 Compression and communica-tion in the cultural evolution of linguistic structure,2015, Cognition
 Hierarchical deepreinforcement learning: Integrating temporal abstraction and intrinsic motivation,2016, In Proc
 Rouge: A package for automatic evaluation of summaries,2004, Text SummarizationBranches Out
 Competitive experience replay,2019, InProc
 In Proc,2019, of IJCAI
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Policy invariance under reward transformations:Theory and application to reward shaping,1999, In Proc
 Bleu: a method for automaticevaluation of machine translation,2002, In Proc
 Film: Visualreasoning with a general conditioning layer,2018, In Proc
 Hindsight policy gra-dients,2019, In Proc
 Visual hindsight experiencereplay,2019, arXiv preprint arXiv:1901
 Universal value function approxima-tors,2015, In Proc
 Reinforcement learning: An introduction,2018, MIT Press
 Understanding natural language commands for robotic navigation andmobile manipulation,2011, In Proc
 Reinforced cross-modal matching and self-supervised imi-tation learning for vision-language navigation,2019, In Proc
 Duelingnetwork architectures for deep reinforcement learning,2016, In Proc
 Translating navigation instructions in natural language to a high-level planfor behavioral robot navigation,2018, In Proc
