title,year,conference
 Hierarchical memory networks,2016, arXiv preprint arXiv:1605
 Strategies for training large vocabulary neurallanguage models,2015, arXiv preprint arXiv:1512
 Controllable abstractive summarization,2017, arXivpreprint arXiv:1711
 Hierarchical neural story generation,2018, arXiv preprintarXiv:1805
 Improving neural language models with acontinuous cache,2016, arXiv preprint arXiv:1612
 Neural turing machines,2014, arXiv preprintarXiv:1410
 Real-time inference inmulti-sentence tasks with deep pretrained transformers,2019, arXiv preprint arXiv:1905
 Billion-scale similarity search with gpus,2019, IEEETransactions on Big Data
 Inferring algorithmic patterns with stack-augmented recurrentnets,2015, In Advances in neural information processing systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Large memory layers with product keys,2019, arXiv preprint arXiv:1907
 Acute-eval: Improved dialogue evaluation withoptimized questions and multi-turn comparisons,2019, arXiv preprint arXiv:1909
 Learning to select knowledge forresponse generation in dialog systems,2019, arXiv preprint arXiv:1902
 Parlai: Adialog research software platform,2017, arXiv preprint arXiv:1705
 Conversing by reading: Contentful neural conversation with on-demand machinereading,2019, arXiv preprint arXiv:1906
 Scaling memory-augmented neural networks with sparsereads and writes,2016, In Advances in Neural Information Processing Systems
 Neural machine translation of rare words withsubword units,2015, arXiv preprint arXiv:1508
 Buildingend-to-end dialogue systems using generative hierarchical neural network models,2016, In ThirtiethAAAI Conference on Artificial Intelligence
 Generative deep neural net-works for dialogue: A short review,2016, arXiv preprint arXiv:1611
 Engaging image chat: Modelingpersonality in grounded dialogue,2018, arXiv preprint arXiv:1811
 End-to-end memory networks,2015, In Advancesin neural information processing systems
 Aug-menting self-attention with persistent memory,2019, arXiv preprint arXiv:1907
 Yfcc100m: The new data in multimedia research,2015, arXiv preprintarXiv:1503
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Memory networks,2014, arXiv preprintarXiv:1410
 Retrieve and refine: Improved sequencegeneration models for dialogue,2018, arXiv preprint arXiv:1808
 Aggregated residual trans-formations for deep neural networks,2017, In Proceedings of the IEEE conference on computer visionand pattern recognition
