title,year,conference
 High-dimensional dynamics of generalization error in neuralnetworks,2017, arXiv preprint arXiv:1710
 Learning the number of neurons in deep networks,2016, InAdvances in Neural Information Processing Systems
 Intrinsic dimension ofdata representations in deep neural networks,2019, arXiv preprint arXiv:1905
 Provable bounds for learning some deeprepresentations,2014, In International Conference on Machine Learning
 Stronger generalization bounds fordeep nets via a compression approach,2018, arXiv preprint arXiv:1802
 Spectrally-normalized margin bounds forneural networks,2017, In Advances in Neural Information Processing Systems
 On the Robustness of ConvolutionalNeural Networks to Internal Architecture and Weight Perturbations,2017, arXiv preprint
 Implicit regularization of discrete gradientdynamics in deep linear neural networks,2019, arXiv preprint arXiv:1904
 Compressing deep convolutionalnetworks using vector quantization,2014, arXiv preprint arXiv:1412
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Network trimming: A data-drivenneuron pruning approach towards efficient deep architectures,2016, arXiv preprint arXiv:1607
 Imagenet classification with deep convolu-tional neural networks,2012, In Advances in neural information processing systems
 Gradient descent quantizes relu networkfeatures,2018, arXiv preprint arXiv:1803
 On the importanceof single directions for generalization,2018, In International Conference on Learning Representations(ICLR)
 A pac-bayesian approach to spectrally-normalized margin bounds for neural networks,2017, arXiv preprintarXiv:1707
 Exploring general-ization in deep learning,2017, In Advances in Neural Information Processing Systems
 The role ofover-parametrization in generalization of neural networks,2018, 2018
 Theory of deep learning iii: explaining the non-overfittingpuzzle,2017, arXiv preprint arXiv:1801
 Data-free parameter pruning for deep neural networks,2015, arXivpreprint arXiv:1507
 Rethinkingthe inception architecture for computer vision,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Cop: Customized deep model com-pression via regularized correlation-based filter-level pruning,2019, arXiv preprint arXiv:1906
 Kernel anddeep regimes in overparametrized models,2019, arXiv preprint arXiv:1906
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
 Theory of Deep Learning III: Generalization Properties of SGD,2017, CBMMMemo
 Non-vacuousgeneralization bounds at the imagenet scale: a pac-bayesian compression approach,2018, arXiv preprintarXiv:1804
