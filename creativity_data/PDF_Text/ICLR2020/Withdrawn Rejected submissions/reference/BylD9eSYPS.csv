title,year,conference
 Near-optimal hashing algorithms for approximate nearest neigh-bor in high dimensions,2006, In FOCS
 Logarithmic online regret bounds for undiscounted reinforcementlearning,2006, In NeurIPS
 The arcade learning envi-ronment: An evaluation platform for general agents,2013, JAIR
 Unifying count-based exploration and intrinsic motivation,2016, In NeurIPS
 R-MAX - A general polynomial time algorithm fornear-optimal reinforcement learning,2002, JMLR
 Exploration by random networkdistillation,2018, CoRR
 Similarity estimation techniqUes from roUnding algorithms,2002, In STOC
 Benchmarking deepreinforcement learning for continUoUs control,2016, In ICML
 EX2: exploration with exemplar models for deepreinforcement learning,2017, In NeurIPS
 VIME:variational information maximizing exploration,2016, In NeurIPS
 Continuous control with deep reinforcement learning,2016, In ICLR
 Kernel-based reinforcement learning,2002, Machine Learning
 Adaptive aggregation for reinforcement learning in average reward markov decisionprocesses,2013, Annals OR
 Count-based explo-ration with neural density models,2017, In ICML
 Curiosity-driven explorationby self-supervised prediction,2017, In ICML
 Trust regionpolicy optimization,2015, In ICML
 Mastering the gameofgo with deep neural networks and tree search,2016, Nature
 Reinforcement learning with soft stateaggregation,1994, In NeurIPS
 Incentivizing exploration in reinforcementlearning with deep predictive models,2015, CoRR
 An analysis of model-based interval estimation formarkov decision processes,2008, JCSS
 Deep reinforcement learning with double q-learning,2016, In AAAI
 Learning deepneural network policies with continuous memory states,2016, In ICRA
