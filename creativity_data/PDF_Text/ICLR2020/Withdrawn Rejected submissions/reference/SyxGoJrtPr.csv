title,year,conference
 Obfuscated gradients give a false sense of secu-rity: Circumventing defenses to adversarial examples,2018, International Coference on InternationalConference on Machine Learning
 Evasion attacks against machine learning at test time,2013, In Joint Europeanconference on machine learning and knowledge discovery in databases
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy
 Unlabeled dataimproves adversarial robustness,2019, Neural Information Processing Systems
 Vicinal risk minimization,2001, InAdvances in neural information processing systems
 Certified adversarial robustness via randomizedsmoothing,2019, International Conference on Machine Learning
 Evaluating and understanding the robustness ofadversarial logit pairing,2018, arXiv preprint arXiv:1807
 Implicit reparameterization gradients,2018, InAdvances in Neural Information Processing Systems
 Adversarial robustness via adversarial label-smoothing,2019, arXivpreprint arXiv:1906
 Explaining and harnessing adversarialexamples,2015, International Conference on Learning Representations
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Using self-supervised learningcan improve model robustness and uncertainty,2019, Neural Information Processing Systems
 Testing robustness againstunforeseen adversaries,2019, arXiv preprint arXiv:1908
 Improving adversarial robustness of ensembles withdiversity training,2019, arXiv preprint arXiv:1901
 Very deep convolutional networks for large-scale imagerecognition,2015, International Conference on Learning Representations
 Intriguing properties of neural networks,2014, International Conference on LearningRepresentations
 Rethinkingthe inception architecture for computer vision,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Manifold mixup: Better representations by interpolatinghidden states,2018, International Conference on Machine Learning
 Bilateral adversarial training: Towards fast training of more robust models againstadversarial attacks,2019, International Conference on Computer Vision
 Efficient defenses against adversar-ial attacks,2017, In ACM Workshop on Artificial Intelligence and Security
 Defense against adversarial attacks using feature scattering-basedadversarial training,2019, Neural Information Processing Systems
 mixup: Beyond empiricalrisk minimization,2018, International Conference on Learning Representations
 Improving the robustness of deepneural networks via stability training,2016, In Proceedings of the ieee conference on computer visionand pattern recognition
