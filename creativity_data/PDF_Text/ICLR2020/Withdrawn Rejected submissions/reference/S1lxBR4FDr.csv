title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Evasion attacks against machine learning at test time,2013, In Joint10Under review as a conference paper at ICLR 2020European Conference on Machine Learning and Knowledge Discovery in Databases
 Thermometer encoding: One hotway to resist adversarial examples,2018, In International Conference on Learning Representations
 Towards evaluating the robustness of neural networks,2016, arXivpreprint arXiv:1608
 Stochastic activation pruning for robustadversarial defense,2018, In International Conference on Learning Representations
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Evaluating and understanding the robustnessof adversarial logit pairing,2018, arXiv preprint arXiv:1807
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations (ICLR)
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations
 Deep residual learning for image recog-nition,2015, arXiv preprint arXiv:1512
 Ad-versarial machine learning,2011, In Proceedings of the 4th ACM Workshop on Security and ArtificialIntelligence
 Adversarial machine learning at scale,2017, InInternational Conference on Learning Representations (ICLR)
 Delving into transferable adversarial ex-amples and black-box attacks,2017, In International Conference on Learning Representations (ICLR)
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, In International Conference on Learning Representations
 Deepfool: A simple andaccurate method to fool deep neural networks,2016, In IEEE Computer Vision and Pattern Recognition(CVPR)
 Fast feature fool: A data independentapproach to universal adversarial perturbations,2017, In Proceedings of the British Machine VisionConference (BMVC)
 Distil-lation as a defense to adversarial perturbations against deep neural networks,2015, arXiv preprintarXiv:1511
 Practical black-box attacks against deep learning systems using adversarial exam-ples,2017, In Asia Conference on Computer and Communications Security (ASIACCS)
 Certified defenses against adversarial exam-ples,2018, In International Conference on Learning Representations
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, In International Conference on LearningRepresentations
 Intriguing properties of neural networks,2013, In International Conference onLearning Representations (ICLR)
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, arXiv preprint arXiv:1711
 Mitigating adversarialeffects through randomization,2018, In International Conference on Learning Representations
 Feature denoisingfor improving adversarial robustness,2019, In The IEEE Conference on Computer Vision and PatternRecognition (CVPR)
