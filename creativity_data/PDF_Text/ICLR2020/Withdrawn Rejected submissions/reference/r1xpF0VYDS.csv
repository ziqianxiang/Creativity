title,year,conference
 Quantum machine learning algorithms : Read the fine print,2015, 2015
 Finding approxi-mate local minima faster than gradient descent,2017, In Proceedings of the 49th Annual ACM SIGACTSymposium on Theory of Computing
 Quantum-inspiredalgorithms in practice,2019, arXiv preprint arXiv:1905
 Gradient descent efficiently finds the cubic-regularized non-convexnewton step,2016, arXiv preprint arXiv:1612
 Theloss surfaces of multilayer networks,2015, In Artificial Intelligence and Statistics
 Identifying and attacking the saddle point problem in high-dimensional non-convex op-timization,2014, In Advances in neural information processing systems
 Fast monte-carlo algorithms for finding low-rankapproximations,0004, J
 Escaping from saddle pointsonline stochasticgradient for tensor decomposition,2015, In Conference on Learning Theory
 Gradient descent happens in a tiny subspace,2018, arXivpreprint arXiv:1812
 Probability inequalities for sums of bounded random variables,1994, In The CollectedWorks of Wassily Hoeffding
 Stochastic gradientdescent escapes saddle points efficiently,2019, arXiv preprint arXiv:1902
 Quantum recommendation systems,2016, arXiv preprintarXiv:1603
 Gradient descent onlyconverges to minimizers,2016, In Conference on learning theory
 Cubic regularization of newton method and its global perfor-mance,2006, Mathematical Programming
 Quantum support vector machine for bigdata classification,2014, Physical review letters
 Quantum singular-value de-composition of nonsparse low-rank matrices,2018, Physical review A
 On matrix factorization and efficient least squares solution,1995, Astronomyand Astrophysics Supplement Series
 From linear combination of quantum states to groverâ€™s searching algorithm,2018, arXivpreprint arXiv:1807
 A quantum-inspired classical algorithm for recommendation systems,2019, In Proceedingsofthe 51st Annual ACM SIGACT Symposium on Theory ofComputing
