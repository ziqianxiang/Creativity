title,year,conference
 TensorFlow: A system for large-scale machine learning,2016, In OSDI
 Towards federated learning atscale: System design,2019, In SysML
 Revisiting dis-tributed synchronous SGD,2016, In ICLR Workshop
 Federated learning of out-of-vocabulary words,2019, arXiv preprint arXiv: 1903
 Variational federated multi-task learning,2019, arXiv preprintarXiv: 1906
 Large scaledistributed deep networks,2012, In NeurIPS
 Astraea: Self-balancing federated learning for improving classification accuracy ofmobile deep learning applications,2019, arXiv preprint arXiv: 1906
 Federated learning for mobilekeyboard prediction,2018, arXiv preprint arXiv: 1811
 Delving deep into rectifiers: Surpassinghuman-level performance of ImageNet classification,2015, In ICCV
 Deep residual learning for image recog-nition,2016, In CVPR
 Flat minima,1997, Neural Computation
 Loadaboost: Loss-basedAdaBoost federated machine learning on medical data,2018, arXiv preprint arXiv: 1811
 Batch Renormalization: Towards reducing minibatch dePendence in batch-normalizedmodels,2017, In NeurIPS
 Batch Normalization: Accelerating deeP network training byreducing internal covariance shift,2015, In ICML
 On large-batch training for deeP learning: Generalization gaP and sharP minima,2017, InICLR
 Adam: A method for stochastic oPtimization,2015, In ICLR
 Learning multiPle layers of features from tiny images,2009, 2009
 Gradientscheduling with global momentum for non-IID data distributed asynchronous training,2019, arXivpreprint arXiv: 1902
 Visualizing the loss land-scape of neural nets,2018, In NeurIPS
 On the convergence ofFedAvg on non-IID data,2019, arXiv preprint arXiv: 1907
 Network in network,2014, In ICLR
 Edge-assisted hierarchical federatedlearning with non-IID data,2019, arXiv preprint arXiv: 1905
 Agnostic federated learning,2019, In ICML
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Robust andcommunication-efficient federated learning from non-IID data,2019, arXiv preprint arXiv: 1903
 Federated multi-tasklearning,2017, In NeurIPS
 Highway networks,2015, In ICML
 Local SGD converges fast and communicates little,2019, In ICLR
 Applied federated learning: Improving Google keyboard querysuggestions,2018, arXiv preprint arXiv: 1812
 Decentralizedlearning of generative adversarial networks from multi-client non-IID data,2018, arXiv preprint arXiv:1905
 Hybrid-FL: cooperative learning mechanism using non-IID data in wireless networks,2019, arXiv preprintarXiv: 1905
 Parallel restart SGD with faster convergence and less com-munication: Demystifying why model averaging works for deep learning,2019, In AAAI
 Context encoding for semantic segmentation,2018, In CVPR
 Federatedlearning with non-IID data,2018, arXiv preprint arXiv: 1806
 Multi-objective evolutionary federated learning,2018, arXiv preprint arXiv:1812
