title,year,conference
 There are many consis-tent explanations of unlabeled data: Why you should average,2019, In Proceedings of the InternationalConference on Learning Representations (ICLR)
 Mixmatch: A holistic approach to semi-supervised learning,2019, arXiv preprintarXiv:1905
 Semi-supervised classification by low density separation,2005, InAISTATS
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations (ICLR)
 Mixup as locally linear out-of-manifold regular-ization,2019, In Association for the Advancement of Artificial Intelligence (AAAI)
 Transductive inference for text classification using support vector machines,1999, InIcml
 Temporal ensembling for semi-supervised learning,2017, In InternationalConference on Learning Representations (ICLR)
 Smooth neighbors on teacher graphsfor semi-supervised learning,2018, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Virtual adversarial training: Aregularization method for supervised and semi-supervised learning,2018, IEEE Transactions on PatternAnalysis and Machine Intelligence
 Realis-tic evaluation of deep semi-supervised learning algorithms,2018, In Advances in Neural InformationProcessing Systems
 Adversarial dropout for super-vised and semi-supervised learning,2018, In Association for the Advancement of Artificial Intelligence(AAAI)
 Regularization with stochastic transfor-mations and perturbations for deep semi-supervised learning,2016, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Improved techniques for training gans,2016, In Advances in Neural Information ProcessingSystems (NeurIPS)
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations (ICLR)
 Mean teachers are better role models: Weight-averaged consis-tency targets improve semi-supervised deep learning results,2017, In Advances in neural informationprocessing systems
 Interpolation con-sistency training for semi-supervised learning,2019, In International Joint Conference on ArtificialIntelligence (IJCAI)
 Improving the improved trainingof wasserstein gans: A consistency term and its dual effect,2018, In Proceedings of the InternationalConference on Learning Representations (ICLR)
 mixup: Beyond empiricalrisk minimization,2018, In Proceedings of the International Conference on Learning Representations(ICLR)
