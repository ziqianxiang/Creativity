title,year,conference
 Successor features for transfer in reinforcement learning,2017, NIPS
 Multitask learning,1997, Machine learning
 Diversity is all you need:learning skills without a reward function,2019, ICLR
 Rich feature hierarchies for accurateobject detection and semantic segmentation,2014, In Proceedings of the IEEE conference on computervision and pattern recognition
 Variational intrinsic control,2017, ICLR
 Fast task inference with variational intrinsic successor features,2019, arxiv
 Î²-VAE: Learning basic visual concepts with a con-strained variational framework,2017, ICLR
 DARLA: Improving zero-shot transfer inreinforcement learning,2017, ICML
 Towards a definition of disentangled representations,2018, arXiv
 Reinforcement learning with unsupervised auxiliary tasks,2017, ICLR
 Buildingmachines that learn and think like people,2016, Behavioral and Brain Sciences
 Curiosity driven exploration oflearned disentangled goal spaces,2018, arxiv
 Why symmetry matters,2012, Nature
 Eigenoption discovery through the deep successor representation,2018, ICLR
 Visualreinforcement learning with imagined goals,2018, arxiv
 Markov Decision Processes - Discrete Stochastic Dynamic Programming,1994, JohnWiley Sons
 Learning by playing - solv-ing sparse reward tasks from scratch,2018, ICML
 Progressive neural networks,2016, arxiv
 Mastering the game of Go withdeep neural networks and tree search,2016, Nature
 Reinforcement Learning: An Introduction,1998, MIT Press
 Cognitive maps in rats and men,1948, The Psychological Review
 Transfer learning,2010, In Handbook of research on machine learningapplications and trends: algorithms
 Deep reinforcement learning with double q-learning,2016, In Thirtieth AAAI conference on artificial intelligence
 Composing value func-tions in reinforcement learning,2018, NeurIPS
 Deep variational canonical correlationanalysis,2016, arXiv preprint arXiv:1610
 Regularizedhierarchical policies for compositional transfer in robotics,2019, arXiv preprint arXiv:1906
