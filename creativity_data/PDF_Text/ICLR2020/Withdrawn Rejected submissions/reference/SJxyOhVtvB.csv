title,year,conference
 Unsupervisedlabel noise modeling and loss correction,2019, Proceedings of International Conference on MachineLearning (ICML)
 Mixmatch: A holistic approach to semi-supervised learning,2019, arXiv preprintarXiv:1905
 Understanding and utilizingdeep neural networks trained with noisy labels,2019, arXiv preprint arXiv:1905
 Autoaugment:Learning augmentation policies from data,2018, arXiv preprint arXiv:1805
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 A semi-supervised two-stage approachto learning from noisy labels,2018, In IEEE Winter Conference on Applications of Computer Vision(WACV)
 Model-agnostic meta-learning for fast adaptationof deep networks,2017, In International Conference on Machine Learning (ICML)
 Using trusted data to traindeep networks on labels corrupted by severe noise,2018, In Advances in Neural Information ProcessingSystems (NeurIPS)
 Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels,2018, International Conferenceon Machine Learning (ICML)
 Nlnl: Negative learning for noisylabels,2019, International Conference on Computer Vision
 Robust inference viagenerative classifiers for handling noisy labels,2019, International Conference on Machine Learning(ICML)
 Learning fromnoisy labels with distillation,2017, In Proceedings of the IEEE International Conference on ComputerVision
 Learning withnoisy labels,2013, In Advances in neural information processing systems (NeurIPS)
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In IEEE Conference onComputer Vision and Pattern Recognition (CVPR)
 Training deep neural networks on noisy labels with bootstrapping,2014, arXiv preprintarXiv:1412
 Very deep convolutional networks for large-scale imagerecognition,2015, International Conference on Learning Representations (ICLR)
 Better generalization with on-the-flydataset denoising,2018, 2018
 Trainingconvolutional networks with noisy labels,2014, arXiv preprint arXiv:1406
 Learning from noisy labels by regularized estimation of annotator confusion,2019, IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Learningfrom noisy large-scale datasets with minimal supervision,2017, In IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Interpolation con-sistency training for semi-supervised learning,2019, arXiv preprint arXiv:1903
 Unsupervised dataaugmentation,2019, arXiv
 mixup: Beyond empiricalrisk minimization,2017, International Conference on Learning Representations (ICLR)
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Improving the robustness ofdeep neural networks via stability training,2016, In IEEE conference on Computer Vision and PatternRecognition (CVPR)
