title,year,conference
  Onexact computation with an infinitely wide neural net,2019, arXiv preprint arXiv:1904
   Understanding dropout,2013,   In Advances in neural informationprocessing systems
  A spline theory of deep networks,2018,  In InternationalConference on Machine Learning
  Approximation and estimation bounds for artificial neural networks,1994,  Machinelearning
  Spectrally-normalized margin bounds forneural networks,2017, In Advances in Neural Information Processing Systems
 Laplacian eigenmaps for dimensionality reduction and data rep-resentation,2003,  Neural Computation
 Reconciling modern machine learningand the bias-variance trade-off,2018, arXiv preprint arXiv:1812
 Regularization and complexity control in feed-forward networks,1995, 1995
  Understanding batch normal-ization,2018, In Advances in Neural Information Processing Systems
  Invariance reduces variance: Understanding dataaugmentation in deep learning and beyond,2019, arXiv preprint arXiv:1907
 Approximation by superpositions of a sigmoidal function,1989, Mathematics of control
 Akernel theory of modern data augmentation,2018, arXiv preprint arXiv:1803
  Hessian eigenmaps: Locally linear embedding techniques forhigh-dimensional data,2003,  Proceedings of the National Academy of Sciences
   Complexity of linear regions in deep networks,2019,   arXiv preprintarXiv:1901
    Surprises  in  high-dimensional ridgeless least squares interpolation,2019, arXiv preprint arXiv:1903
  Batch normalization:  Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
  Deep neural networks as gaussian processes,2017,  arXiv preprint arXiv:1711
  Mean-field theory of two-layer neuralnetworks: dimension-free bounds and kernel limit,2019, arXiv preprint arXiv:1902
  The calculus of finite differences,2000,  American Mathematical Soc
  Sensitivity and generalization in neural networks: an empirical study,2018,  arXiv preprintarXiv:1802
  The effectiveness of data augmentation in image classification usingdeep learning,2017, arXiv preprint arXiv:1712
 Higher order contractive auto-encoder,2011, In Joint European Conference on MachineLearning and Knowledge Discovery in Databases
      Representation  benefits  of  deep  feedforward  networks,2015,      arXiv  preprintarXiv:1509
   A  global  geometric  framework  fornonlinear dimensionality reduction,2000, science
   Dropout  training  as  adaptive  regularization,2013,   InAdvances in neural information processing systems
  On early stopping in gradient descent learn-ing,2007, Constructive Approximation
  Error bounds for approximations with deep relu networks,2017,  Neural Networks
        Wide   residual   networks,2016,        arXiv   preprintarXiv:1605
  Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
