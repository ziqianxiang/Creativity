title,year,conference
 Tensorflow: A system for large-scale machine learning,2016, In OSDI
 Layer normalization,2016, arXiv preprintarXiv:1607
 Kinova modularrobot arms for service robotics applications,2017, Int
 Shapestacks: Learning vision-based physical intuition for generalised object stacking,2018, In ECCV (1)
 Acquiring Diverse Robot Skills via Maximum Entropy Deep ReinforcementLearning,2018, PhD thesis
 Probabilistically safepolicy transfer,2017, In Robotics and Automation (ICRA)
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Actor-critic algorithms,2000, In Advances in neural informationprocessing systems
 State represen-tation learning for control: An overview,2018, Neural Networks
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Towardsinterpretable reinforcement learning using attention augmented agents,2019, ArXiv
 Asym-metric actor critic for image-based robot learning,2018, Robotics: Science and Systems
 Epopt: Learningrobust neural network policies using model ensembles,2016, arXiv preprint arXiv:1610
 Imagenet classification withdeep convolutional neural networks,2015, In International Conference on Learning Representations
 Simul-taneously learning vision and feature-based control policies for real-world ball-in-a-cup,2019, arXivpreprint arXiv:1902
 Mastering the game of gowithout human knowledge,2017, Nature
 Deepattention recurrent q-network,2015, arXiv preprint arXiv:1512
 Deepmind control suite,2018, arXivpreprint arXiv:1801
 Do-main randomization for transferring deep neural networks from simulation to the real world,2017, InIntelligent Robots and Systems (IROS)
 Learning a visuomotor controllerfor real world robotic grasping using simulated depth images,2017, arXiv preprint arXiv:1706
 Embed to control:A locally linear latent dynamics model for control from raw images,2015, In Advances in neuralinformation processing Systems
 Mutual alignment transfer learning,2017, arXivpreprint arXiv:1707
 Refer to table 2 for the model ar-chitecture for each component of APRiL and the asymmetric DDPG baseline,2016, Obs Actor and ObsCritic setup are the same for both APRiL and the baseline
 The target actor and critic networks are updatedevery iteration with a Polyak averaging of 0,2014,999
