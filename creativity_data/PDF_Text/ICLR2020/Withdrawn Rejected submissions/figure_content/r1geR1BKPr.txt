Figure 1: The setting for influence functions in multi-stage models. We consider a two-stage model,where we have a first pretrained model, and a second finetuned model for a desired end task. We seekto compute the influence of the pretraining data on predictions using testing data in the finetuningtask.
Figure 2: CIFAR and MNIST model true loss difference vs. the influence function scores by (8). Theloss is calculated as the sum of all test examples.
Figure 4: MNIST model true loss differ-ence and influence function with all Hes-sians replaced by identity matrices. Pear-son’s r = 0.17.
Figure 3: Identifying the pretrain example with largest influence function score which contributes anerror in the finetune task.
Figure 5: CIFAR example using `2 reg-ularization formulation in (13) when em-bedding is not fixed in finetune. Pearson’sr = 0.40.
Figure 6: Two different finetuning task dis-tribution of influence function scores withrespect to each pretrain example. Each pre-training example’s influence score value issummed up for all test examples. The pre-trained embedding is fixed in finetuning.
Figure 7: Two different finetuning task dis-tribution of influence function scores whichrespect to each pretraining example. Eachpretraining example’s influence score valueis summed up for all test examples. The pre-trained embedding is also updated in fine-tuning. The pretraining and finetuning tasksare the same as in Section 4.1.2. Model D’snumber of finetuning examples and finetun-ing steps are 3X of model C’s. The averageabsolute values of influence function scoresfor Models C and D are 0.22 and 0.15, re-spectively.
