Figure 1: MD formulation where mirror map is de-rived from the projection P. Note, gk is computedin the primal space (X) but it is directly used toupdate the auxiliary variables in the dual space.
Figure 2: Plots of tanh and shifted tanh projections, and their inverses corresponding to the tanhprojection. Note that, the inverses are monotonically increasing and the mirror map is strictly convex.
Figure 3: Training curves for binarization for CIFAR-10 (first two) and CIFAR-100 (last two) withResNet-18. Compared to original MD variants, stable MD variants are less noisy and after the initialexploration phase (up to 60 in CIFAR-10 and 25 epochs CIFAR-100), the validation accuracies risesharply and show gradual improvement afterwards.
Figure 4: Training curves for binarization for CIFAR-10 (first two columns) and CIFAR-100 (last twocolumns) with ResNet-18. Compared to BC, our MD-tanh-S and PMF are less noisy and after theinitial exploration phase (up to 60 in CIFAR-10 and 25 epochs CIFAR-100), the validation accuraciesrise sharply and closely resembles the floating point network afterwards. This steep increase is notobserved in regularization methods such as PQ.
