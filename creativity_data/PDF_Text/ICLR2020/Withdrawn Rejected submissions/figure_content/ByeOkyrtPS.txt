Figure 1: This figure illustrates the framework of VPR, which does plan recognition on uncertain ob-servations. Those uncertain observations come from a visual recognition model, Video2Vec, whosetraining is explained in the appendix (SectionB). The number ’18’，‘24’，and ‘36' means the 18-th,24-th, and 36-th action in action vocabulary A (explained in Section 3)GM (Greedy Model). GM may suffer from noisy observations because of greedy sampling. The sec-ond, in order to use more information from uncertain observations, is to sample action sequencesfrom each sequence of action distributions, and then build a Word2Vec model, namely RS2Vec( Resampling-to-Vector Model). RS2Vec can be quite inefficient in that it will have to generatemany samples to capture the distribution. The required sample size increases with the length of thesequence and the number of actions in the distribution of each step. We thus propose the third way,which is to directly handle distributions of actions, namely Distr2Vec (Distribution-to-Vectormodel). Distr2Vec requires a revision to the Word2Vec to let it learn embeddings for distribu-tions over words as opposed to single words. To train the Distr2Vec affinity model, we introducea loss function based on combining Kullback-Leibler (KL) divergence and (Hierarchical-Softmax)H-Softmax Mikolov et al. (2013).
Figure 2:	An uncertain Plan p, which is a sequence of observed action distributions.
Figure 3:	An observed plan O, that has two steps of missing observations (action distributions)marked with SymbOl φ.
Figure 4:	The completed plan after running visual plan recognition on observed plan O.
Figure 5: Our Distr2Vec for learn-ing action embeddings (approximatedplanning domain models) directly fromdistribution sequences. The embeddingmatrix WE has the size of action vo-cabulary A times embedding size. Thehidden-Output Matrix has the shapeof embedding length times size of A,whose output is a vector of size A.
Figure 6: This figure demonstrates the accuracy of GM, Distr2Vec, and three RS2Vec instanceson synthetic data of different PERs, with respect to increasing plan (distribution sequence) lengths.
Figure 7: Accuracy results of GM,Distr2Vec, and three RS2Vec in-stances on synthetic data of different en-tropies. The RS2Vec-S, RS2Vec-M,and RS2Vec-L are explained in the de-scription of Figure 6.
Figure 8: Algorithm. 1and LSTM comparisonin VPR framework forplan recognition.
Figure 10: The left two subplots show a comparison between using H-Softmax or not with respect totraining time and accuracy for affinity models on the visually grounded corpus of8% PER. The suffix“-nohs" denotes models without H-Softmax. The right two subplots show accuracy with respect tothe percentage of missing observations and window sizes on the visually grounded corpus of 69%PER.
Figure 9: Results of evaluating theGM, RS2Vec, and Distr2Vec onvideos. The left sub-plot shows howDistr2Vec, GM, and RS2Vec withsmall and large number of samples(RS2Vec-S and RS2Vec-L) performswith data of 8% and 69% PERs. The rightsubplot shows the accuracy in terms ofvarying distribution sizes on the 69% PERdata.
Figure 11: Details of Distr2Vec model for Error Propagation.
