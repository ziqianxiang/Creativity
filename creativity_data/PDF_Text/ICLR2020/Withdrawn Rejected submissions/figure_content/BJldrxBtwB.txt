Figure 1: Left: The generated images have different rectangle numbers (e.g. one, two or three), whilethe rectangle numbers of all the training data are exactly two (the anomalous marked red). Right:The proportion of the correct generated images (rectangle number is two) for different trainingapproaches. The training dataset consists of 25600 images, all of which have exactly two rectangles.
Figure 2: Middle: The loss and gradients for MGD/FGD. Training of MGD is unstable while FGDconverges quickly. Left: The generated samples of the generator by four latent codes during training.
Figure 3: Top: For the geometry dataset, the proportion curve of the correct generated images(number of rectangle is three) is plotted (upper right solid line). The scores of the discriminatorfor the positive training data and the pixel-wise logical-and/or of the positive training data are alsoplotted respectively (upper right dash line). During training, the generated images which are pixel-wise logical-and/or of the positive training samples prevail (highlighted with colored frame on upperleft). They get high scores similar to the positive training images in the earlier stage. Bottom: Certaingenerated images are shown for human face generation (Liu et al., 2015). They are exactly the sameas the pixel-wise averages of the training data.
Figure 4: Generated images of the generative average method (GAM) and GANs. The performancesare comparable both visually and by the FID score.
Figure 5: Left: The final generated samples for the M-CIFAR10 and M-CELEB-A, where the Sam-ple Correction (SC) approach achieves better performance. Right: The FID and DIF curves duringtraining for the vanilla and the Sample Correction (SC) approaches.
Figure 6: The generated images for certain fixed latent codes. For FGD (left), training is stable andconverges smoothly. For MGD, where the insufficient problem is severe, training is unstable andgives rise to anomalous images (rectangle number is not two).
Figure 7: For a random training image, the closest generated image in 256000 generated samplesis found. For three training method (SC, PCR and SC+PCR), most training images are representedby the learned distribution of the generator, meaning the high performance is achieved (up to 99%correct generated images) without mode collapse.
