Figure 1: Pruning instability improves generalization of (Top) VGG11 and (Bottom) ResNet18 whentraining on CIFAR-10 (10 runs per configuration). (Left) Test accuracy during training of severalmodels illustrates how adaptation to more unstable pruning leads to better generalization. (Right)Means reduce along the epoch dimension (creating one point per run-configuration combination).
Figure 2: When pruning 10% of Conv4’s largest dense layer, the final generalization gap depends onthe magnitude of the weights that were pruned during training. This is particularly true when usingunstructured pruning (left) rather than structured pruning (right).
Figure 3: The top-1 test accuracy during trainingwith multiple approaches to pruning ResNet18.
Figure 4: In VGG11, increasing the iterative pruning rate (and decreasing the number of pruningevents in order to hold total pruning percentage constant) leads to more instability, and can allowmethods that target less important parameters to generalize better. Additionally, E[BN] magnitudebetter approximates parameter importance than '2-norm magnitude (See Figure A2 for anotherexample and discussion of this phenomenon). An unpruned baseline model has 85.21% accuracy.
Figure 5: Generalization improvements from pruning bear resemblance to those obtained by usingtemporary (Left) multiplicative zeroing noise, and (Right) additive Gaussian noise, as long as thenoise is applied for enough batches/steps.
Figure A1: We examined the normalized activations (shown in blue histograms) of feature maps inthe final eight convolutional layers of VGG19 before (left) and after (right) training to convergence.
Figure A2: In VGG11, prunes E[BN] is more stable than prunes, which uses filter-'2-norm tocompare parameter magnitudes. Methods with higher iterative pruning rates create more instabilityon a given iteration. Means reduce along the run dimension (10 runs per configuration).
Figure A3: Pruning instability improves generalization of (Top) VGG11 and (Bottom) ResNet18when training on CiFAR-10 (10 runs per configuration). (Left) Test accuracy during training of severalmodels illustrates how adaptation to more unstable pruning leads to better generalization. (Right)Means reduce along the epoch dimension (creating one point per run-configuration combination).
Figure A4: When training Conv4 on CIFAR10, unstable pruning can significantly improve thebaseline’s generalization. The training accuracies and test accuracies (the latter were calculatedimmediately after pruning) illustrate how much each pruning algorithm disturbs the neural network’soutput during training.
