Figure 1: An overview of model architectures (a) AC-StyleGAN and (b) FC-StyleGAN. (a) The generator con-ditions on meta code for generation and the discriminator predicts its value. (b) We downsample the real imageinto 32x32 resolution and replace the lower resolution blocks (4x4 - 32x32) in the AC-StyleGAN generator bya new input block. Also, the discriminator predicts the value of fine code from the 32x32 block instead.
Figure 2: Latent traversal of AC-StyleGAN with full supervision on ISaaC3D. For illustration, we only showthree factors: (robot x-movement, camera height, lighting y-dir). Please see the appendix for latent traversalof all the factors. Images in the first column (marked by red box) are randomly sampled real images with theground-truth and the rest images in each row are their interpolations, respectively, by uniformly varying thegiven factor from 0 to 1. Unless otherwise stated, this setting applies to all the latent traversal results below.
Figure 3: Quantitative metrics — MIG, lrec and FID vary with the supervision coefficient α ∈{0.0, 0.01, 0.05, 0.1, 1.0} and the disentanglement coefficient γ ∈ {1, 10} in AC-StyleGAN on Isaac3D. ForMIG, the higher is better, while for lrec and FID, the lower is better.
Figure 4: (a) Latent traversal of AC-StyleGAN on ISaaC3D, where we only control a subset of factors: (robot x-movement, robot y-movement, object scale, lighting y-dir, object color) and here two of them are shown. Pleasesee the appendix for all five considered factors. (b) Interpolation variances of each factor in FC-StyleGANwith different downscaled resolutions φ on Isaac3D, where the meta code of all factors is used as its input.
Figure 5: Latent traversal of AC-StyleGAN on CelebA with resolution 256x256, where we control all 40binary attributes at the same time and show four representative ones: Male, Open Mouse, Bangs, Grey Hair.
Figure 6: Latent traversal of FC-StyleGAN with downscaled resolution φ = 16 on Isaac3D, where We onlycontrol a subset of fine-grained factors: (object scale, lighting intensity, object color, wall color) and here twoof them are shown. Please see the appendix for all the four factors.
Figure 7: (a) Comparison of FC-StyleGAN with instance normalization (top row) and without instance nor-malization (bottom row). Both are trained with downscaled resolution φ = 32 on Isaac3D, where We onlydisentangle a subset of fine factors (lighting intensity, object color, wall color) and here only one are shown(see the appendix for all three considered factors). (b) Generalization of FC-StyleGAN by varying the down-scaled resolution φ and interpolating the wall color. In the test image, we shift the position of the robot arm tothe right-hand side, which is also attached with an unseen object (i.e., octahedron).
Figure 8: Examples in the Isaac3D dataset where We vary each factor of variation individually.
Figure 9: Examples in the Falcor3D dataset where we vary each factor of variation individually.
Figure 10: Image reconstruction on random samples of Isaac3D and Falcor3D in AC-StyleGAN with fullsupervision, where We can see that the generated fake images match well with real images by using the samemeta code as the generator input, confirming the semantic correctness of the model.
Figure 11: Latent traversal results of AC-StyleGAN with full supervision on Isaac3D for all the fac-tors. Images in the first column (marked by red box) are randomly sampled real images of resolution512x512 and the rest images in each row are their interpolations, respectively, by uniformly varyingthe given factor from 0 to 1. We can see that each factor changes smoothly during its interpolationwithout affecting other factors, and the interpolated images in each row visually look almost thesame with their input image except the considered varying factor. Also, the image quality does notget worse during the interpolations.
Figure 12: Latent traversal results of AC-StyIeGAN with full supervision on FaIcor3D for all thefactors. Images in the first column (marked by red box) are randomly sampled real images of resolu-tion 1024x1024 and the rest images in each row are their interpolations, respectively, by uniformlyvarying the given factor from 0 to 1. We can see that each factor changes smoothly during its inter-polation without affecting other factors, and the interpolated images in each row visually look verysimilar to their input image except the considered varying factor. Also, the image quality does notget worse during the interpolations.
Figure 13: Latent traversal results of AC-StyleGAN with semi-supervision (α = 0.01) on Isaac3D for allthe factors. Images in the first column (marked by red box) are randomly sampled real images of resolution512x512 and the rest images in each row are their interpolations, respectively, by uniformly varying the givenfactor from 0 to 1. We can see that in most cases, each factor changes smoothly during its interpolation withoutaffecting other factors except the entanglement between the object shape and camera height. Also, except theconsidered varying factor, the interpolated images in each row visually look similar to their input image withsmall shifts sometimes. It implies a reasonably good disentanglement quality and semantic correctness in theAC-StyleGAN with 1% labelled data. Similarly, the image quality does not get worse during the interpolations.
Figure 14: The randomly sampled images of disentangled VAEs on the Isaac3D dataset of resolution 128x128,where We use the same network architectures as in Locatello et al. (2019a). We can see that compared withAC-StyleGAN, (i) the generated images tend to be quite blurry and of low quality, (ii) the generated images failto cover all the variations in the dataset. The results of disentangled VAEs also demonstrate that our proposeddatasets serve as a new disentanglement challenge, in particular regarding the much higher resolution, andlarger variation of factors.
Figure 15: More Latent traversal results of AC-StyleGAN on CelebA with resolution 256x256, where Wecontrol all 40 binary attributes at the same time. We can see that AC-StyleGAN is capable of controlling mostattributes. Some attributes are more difficult to change over interpolations, such Mustache on the female faces.
Figure 16: Latent traversal results of AC-StyleGAN for only controlling a subset of factors on a) Isaac3D:(robot x-movement, robot y-movement, object scale, lighting y-dir, object color), b) Falcor3D: (lighting inten-sity, lighting x-dir, camera x-pos). The other factors in each dataset will be considered as random nuisances,presumably captured by the latent z. We can see that the disentanglement quality and semantic correctnessare both getting worse instead. For example, interpolating the lighting intensity of Falcor3D also changes thelighting directions and camera positions.
Figure 17: Latent traversal results of FC-StyleGAN with full supervision on Isaac3D for all the factors wherewe show different downscaled values φ ∈ {8, 64}. The factors that cannot be changed by the interpolations(i.e., not fine-grained) are highlighted by blue boxes. For example, if φ = 8, only the camera height andlighting y-dir are NOT fine-grained, while if φ = 64, only the lighting intensity and wall color are fine-grained.
Figure 18: Latent traversal of FC-StyleGAN With full supervision on Isaac3D for a subset of fine-grainedfactors: (object scale, lighting intensity, object color, wall color). We can see that each factor changes smoothlyduring its interpolation without affecting other factors, and the interpolated images in each row visually lookalmost the same with their input image except the considered varying factor and another fine-grained factor:object shape (as a random nuisance). Also, the image quality does not get worse during the interpolations.
Figure 19: Latent traversal of FC-StyleGAN with full supervision on Falcor3D for all fine-grained factors:(lighting intensity, lighting x-dir, lighting y-dir, lighting z-dir). We can see that each factor changes smoothlyduring its interpolation without affecting other factors, and the interpolated images in each row visually lookalmost the same with their input image except the considered varying factor. Also, the image quality does notget worse during the interpolations.
Figure 20: Comparison of FC-StyleGAN with instance normalization (top row) and without instance nor-malization (bottom row). Both are trained with downscaled resolution φ = 32 on Isaac3D, where We onlydisentangle a subset of fine factors (lighting intensity, object color, wall color). We can see that FC-StyleGANwith instance normalization can smoothly change each of the factors of variation over interpolation. However,FC-StyleGAN without instance normalization cannot change the lighting intensity and wall color at all.
Figure 21: Generalization of FC-StyleGAN by varying the downscaled resolution φ and interpolating oneof the fine-grained factors. In the test image, We shift the robot position to the right-hand side, which is alsoattached with an unseen object (i.e., octahedron). We can see that in FC-StyleGAN with different downscaledresolutions, the considered factor keeps changing during its interpolations. Furthermore, the interpolated im-ages in each case maintain the new robot position and particularly maintain new object shape (i.e., octahedron)in the case of φ = 64. The reason why the new object shape is only maintained at φ = 64 is beacuse that the ob-ject shape, together with the robot position, is not fine-grained at φ = 64 any more. Therefore, it demonstratesthat the disentanglement learning of FC-StyleGAN can generalize well to unseen novel test images.
