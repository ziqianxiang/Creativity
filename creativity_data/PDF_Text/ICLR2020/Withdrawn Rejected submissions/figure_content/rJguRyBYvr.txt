Figure 1: Histogram of origin and target classes from C&W untargeted adversarial attack comparedto embedding layer t-SNEWhile the attacker’s goal is to find a small distortion that “penetrates” another class, our goal as thedefender is to create a resilient model that forces a larger distortion. The lower bound (4) motivatesour penetration distortion maximization (PDM) method whereby the goal is to explicitly maximizethe right side of (4) with respect to the embedding layer of the model F . To successfully apply thistechnique we must increase the embedding margin ηl (while not increasing the norm of the Jacobian)and/or smooth the network to decrease the norm of the Jacobian || J'(χ)∣∣. We note that similar andstronger, formal bounds, in terms of the Lipschitz constant, have been introduced by Tsuzuku et al.
Figure 2: CIFAR-10 t-SNE visualization of the two margin increasing components of PDM . Com-pared to the baseline, each method contributes to the increase of the margin; the combined methoddisplay the best clustering according to the Davies-BoUldin Index.
Figure 3: Resiliency under the FGSM and BIM adversarial attacks. Our method displays signifi-cantly higher resiliency0.025	0.050	0.075	0.100	0.125	0.150	0.175	0.200Perturbation(d) BIM-MNIST4.4	Black-Box ModelTo evaluate our model in the black-box setting, we follow (Papernot et al., 2017; Carlini et al., 2019)and create a proxy model, which is trained using input-output pairs probed from the defender’s(target) model (i.e., the proxy model is trained via teacher-student distillation of the target model).
