Figure 1: Model accuracy on the two natural distribution shifts, ImageNetV2 (left) and Ima-geNetVidRobust (right). Each data point corresponds to one model in our testbed and is shown with99.5% Clopper-Pearson confidence intervals. The plots demonstrate that the standard test accuracy(x-axis) is an almost perfect predictor for the test accuracy under distribution shift (y-axis). Thisholds regardless of whether the model was trained with a robustness intervention. Current robust-ness interventions reduce the accuracy drops under these distribution shifts only by a small amount(on ImageNetVidRobust) or not at all (on ImageNetV2). The axes were adjusted using logit scalingand the linear fit was computed in the scaled space. The red shaded region is a 95% confidenceregion for the linear fit from 100,000 bootstrap samples.
Figure 2: Robustness to synthetic distribution shift (x-axis) vs. effective robustness to the Ima-geNetV2 distribution shift (y-axis). The left plot shows synthetic robustness as measured by anaverage over image corruptions from (Hendrycks & Dietterich, 2019; Geirhos et al., 2018; 2019).
Figure 3: The left plot zooms into the range of the ResNet152-ImageNet11k and Instagram modelson ImageNetV2 and shows that the models achieve significant effective robustness, i.e., they liesignificantly above the linear fit. The right plot zooms into the range of the `p-robust models onImageNetVidRobust with high effective robustness. The dotted line shows the family of modelsachievable by interpolating between a standard ResNet-152 and a random classifier. It achieves thesame robustness trade-off as the `p-robust models.
Figure 4: To investigate the impact of training data on robustness, we vary the ILSRVC 2012 dataalong two axes: the number of images per class (left), and the number of classes (right). Althoughmodels trained on more data (e.g., the Instagram and ResNet152-ImageNet11k models) provideimprovements in effective robustness, we find that subsampling of the ILSVRC training has noimpact on effective robustness.
Figure 5: An overview ofour testbed. Each row is amodel, and each column isan evaluation setting. Forthe corruptions, we aver-age over the five severitiesdefined in (Hendrycks &Dietterich, 2019). We alsoplot in-memory and on-disk versions of each cor-ruption as jpeg compres-sion was found to be a con-founding factor in (Fordet al., 2019). We leaveout the class-subsampledmodels and evaluations de-scribed in Section 6 forbrevity.
Figure 6: Robustness to synthetic distribution shift (x-axis) vs. effective robustness to the Ima-geNetVid distribution shift (y-axis). The left plot shows synthetic robustness as measured by anaverage over image corruptions from (Hendrycks & Dietterich, 2019; Geirhos et al., 2018; 2019).
Figure 22: A detailed view of corruption robustness, with cells sampled from the main grid in Figure5. Here we present resnet50s trained on some of the corruptions from the imagenet-c benchmark,as well as the best model trained on more data, instagram-resnext10L32x48d, and the best modeltrained on just the standard training set, efficientnet-b7.
