Figure 1: Evidential distributions. Maxi-mum likelihood optimization learns a likeli-hood distribution given data, while evidentialdistributions model higher-order probabilitydistribution over the likelihood parameters.
Figure 2: Normal Inverse-Gamma distribution. Different realizations of our evidential distribution (A)correspond to different levels of confidences in the parameters (e.g. μ, σ2). Sampling from a single realizationof a higher-order evidential distribution (B), yields lower-order likelihoods (C) over the data (e.g. p(y∣μ, σ2)).
Figure 3: Epistemic uncertainty estimation. Model-ing the supportive evidence during learning enables pre-cise prediction within the training regime and conserva-tive uncertainty estimates where there was no trainingdata. Comparisons to other epistemic uncertainty esti-mation methods are illustrated (bottom).
Figure 4: Modeling uncertainty in depth estimation. Three methods for estimating epistemic (model) uncer-tainty are evaluated in the context of monocular depth estimation. For each model, we visualize the prediction,error to ground-truth, and estimated uncertainty for three randomly chosen examples (A-C). Ideally, the modelshould predict high uncertainty whenever it does not know the answer (i.e., large error). We evaluate thesensitivity and specificity of the predictive uncertainty in identifying likely errors with ROC curves (D).
Figure 5: Aleatoric uncertainty indepth. Visualizing predicted aleatoricuncertainty in challenging reflectionand illumination scenes. Comparisonbetween evidential and (Kendall & Gal,2017) show strong semantic agreement.
Figure 6: Out-of-distribution (OOD) data samples. Evidential models estimate and inflate epistemic uncer-tainty on OOD data, where the prediction should not be trusted. All samples were not seen during training.
Figure 7: Evidential robustness under adversarial noise. Increasing levels of adversarial noise (A) corruptthe predicted depth, and our model begins to incur greater amounts of error. As adversarial noise increases,inferred epistemic uncertainty increases (localized to where the most error occurs). Adversarially perturbed testaccuracy (B), epistemic uncertainty (C), as well as the noise to evidential error estimation (D) is also provided.
Figure 8: Evidential regularizer. The use of our novel LR loss during training helps minimize evidence(maximize uncertainty) on out-of-distribution data, thus enabling OOD uncertainty robustness for regressionprediction problems.
Figure 9: Aleatoric uncertainty estimation. Comparing the ability to learn the heteroscedastic aleatoricuncertainty in a synthetic dataset. Evidential modelling is able to match the performance of Gaussian likelihoodoptimization (Kendall & Gal, 2017).
