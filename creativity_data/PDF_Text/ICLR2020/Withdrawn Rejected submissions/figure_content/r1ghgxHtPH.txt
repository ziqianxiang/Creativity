Figure 1: We compose free-form filters fθ andstructured Gaussian filters g∑ by convolution *to define a more general family of filters thaneither alone. Our composition makes filter sizedifferentiable for end-to-end learning.
Figure 2: Our composition does not reduce todilation or more free-form parameters. Dilationis sparse, causing artifacts, and cannot be learned.
Figure 3: Recovering an unknown blur by optimizing covariance. Gradient optimization of thestructured parameters Σ quickly converges to the true Gaussian. Although this is a simple example, itshows how the Gaussian can represent scale, aspect, and orientation with variable filter size.
Figure 4: The identity is recovered by a delta asvariance goes to zero. Small variance gives a goodinitialization near the identity. Average pooling isapproximated as variance goes to infinity.
Figure 6: Gaussian deformation (c-f)structures dynamic receptive fields bycontrolling the sampling points (blue)according to the covariance. Its low-dimensionality is less general but moreefficient for learning and inference thanfree-form deformation (b) by Dai et al.
Figure 7: Qualitative results for dynamic scale inference: (a) inputs, (b) truths, (c) outputs, and(d) scale estimates where small is blue/dark and large is yellow/bright. The scale estimates exhibitstructure: coherent segments and boundaries between them can be seen.
