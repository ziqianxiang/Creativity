Figure 1:	Ensemble attack against four DNN models on MNIST. (a) & (b): Attack success rate of adversarialexamples generated by average (ensemble PGD) or min-max (APGD) attack method. (c): Boxplot of weight win APGD adversarial loss for four models. Here We adopt the same '∞-attack as Table 1.
Figure 2:	ASR of average and min-max '∞ ensemble attack versus maximum perturbation magnitude e.
Figure 3: (a): Violin plot of weight w in APGD versus perturbation magnitude of `2 -attack in AT; (b) & (c):Robustness of MLP under different AT schemes. Supplementary result for LeNet is provided in Figure A2(Appendix E).
Figure A1: Sensitivity analysis of the regular-izer 2 ∣∣w — 1 /K∣∣2 on the probability simplex.
Figure A2: (a): Violin plot of weight w in APGD as a function of perturbation magnitude of `2 attack inadversarial training; (b) & (c): Robustness of LeNet (Model C) under different adversarial training schemes.
Figure A3: (a) & (b): Comparison of the percentage of adversarial examples inside '∞ ball (left, blue area)and inside `2 ball (right, red area). In particular, the red (blue) area in (a) (or (b)) represents the percentage ofadversarial examples crafted by '∞('2) attack that also belong to '2 ('∞) ball. We generate adversarial exampleson 10,000 test images for each attack. (c): Average `p norm of adversarial examples as a function of perturbationmagnitude e`2 . The top (bottom) side represents the '2 -norm ('∞ ) of the adversarial examples generated by '∞('2) attack as e`2 for generalized AT increases. Note that the same e as the AT procedure is used while attackingtrained robust models.
Figure A4: Learning curves of MLP model under different adversarial training schemes on MNIST. Note thateach experiment is repeated ten times with different random seeds.
