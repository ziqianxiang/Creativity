Figure 1: Panoramic view of the agent (left, right, and front views concatenated).
Figure 2: Common Sense and Semantic-Guided Navigation for RoomNav Task. Input to the agentis represented in green. Black components correspond to the baseline navigator model. Purplecomponents are introduced to incorporate common sense planning while pink components are forSemantic Understanding.
Figure 3: SPL and Success Rate vs. Number of framesused for training on hard games of test environment4.3	Self-supervisedIMITATION LEARNING (SIL)To perform self-supervised imitation learning (SIL), we either use SU-CR or SU-PN as the auxiliarytask to fine-tune SGn by assuming the output of SU-RD as the ground truth. We do not use CS-Nxtmodel for performing SIL because performance of CS modules degrades significantly when steplevel auxiliary tasks are introduced, as depicted earlier. After performing SIL for the first 20 stepson unseen environments, using the SU-CR for fine-tuning helps the overall accuracy by 6.5% withrespect to SU-CR + SU-RD baseline. When SU-PN is used for fine-tuning instead, we achieve animprovement of9.1% with respect to SU-PN + SU-RD baseline. With more SIL steps, performancedegrades due to introduction of noise, as the current room prediction from the SU-RD model is notperfect/ground truth. Through SIL, we showcase that the agent can be made to update the semanticunderstanding through navigation.
Figure 4: Top view of house17DR with dark areas as obsta-clesFigure 5: Embeddings ofSUJJR + SURD model beforefine-tuning on 17DR houseFigure 6: Embeddings ofSUCR + SURD model afterfine-tuning using SILand then trained with common sense and semantic understanding across multiple games. We quali-tatively analyze these embeddings to see if they reflect the structural and visual characteristics of theenvironment. Figure 4 represents the top-view of a training environment and Figure 5 visualizes theembeddings trained using the (SU-CR + SU-RD) model in two dimensions after aligning. We fine-tuned the agent (and embeddings) on the house shown in figure 4 using self-supervised imitationlearning and visualize it in figure 6, after aligning it with respect to the original map for comparison.
Figure 5: Embeddings ofSUJJR + SURD model beforefine-tuning on 17DR houseFigure 6: Embeddings ofSUCR + SURD model afterfine-tuning using SILand then trained with common sense and semantic understanding across multiple games. We quali-tatively analyze these embeddings to see if they reflect the structural and visual characteristics of theenvironment. Figure 4 represents the top-view of a training environment and Figure 5 visualizes theembeddings trained using the (SU-CR + SU-RD) model in two dimensions after aligning. We fine-tuned the agent (and embeddings) on the house shown in figure 4 using self-supervised imitationlearning and visualize it in figure 6, after aligning it with respect to the original map for comparison.
Figure 6: Embeddings ofSUCR + SURD model afterfine-tuning using SILand then trained with common sense and semantic understanding across multiple games. We quali-tatively analyze these embeddings to see if they reflect the structural and visual characteristics of theenvironment. Figure 4 represents the top-view of a training environment and Figure 5 visualizes theembeddings trained using the (SU-CR + SU-RD) model in two dimensions after aligning. We fine-tuned the agent (and embeddings) on the house shown in figure 4 using self-supervised imitationlearning and visualize it in figure 6, after aligning it with respect to the original map for comparison.
