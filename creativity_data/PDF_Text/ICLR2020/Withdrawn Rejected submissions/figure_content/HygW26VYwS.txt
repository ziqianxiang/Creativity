Figure 1: Attention Privileged Reinforcement Learning model structure. Dashed lines indicate at-tention alignment process. The ã€œoperator signifies that experiences are evenly sampled from bothagents. The 0 operator represents element-wise multiplication.
Figure 2: Learning curves during training of APRiL , its ablations, and the asymmetric DDPG base-line. Solid line: mean performance. Shaded region: covers minimum and maximum performancesacross 5 seeds.
Figure 3: Example held-out domains (top) and APRiL attention maps (bottom). White and blacksignify high and low attention values. Attention correctly suppresses background and distractors.
Figure 4: APRiL attention maps for policy rollouts on NavWorld and Jaco domains. White andblack signify high and low attention values respectively. For NavWorld and JacoReach, attention iscorrectly paid only to the relevant objects (and Jaco links), even for the extrapolated domains. Referto section 4.6 for more details.
Figure 5: APRiL attention maps for policy rollouts on Walker domain. White and black signify highand low attention values respectively. Attention varies based on the state of the walker. When thewalker is upright, high attention is paid to lower limbs. When walking, even attention is paid toevery other limb. When about to collapse, high attention is paid to the foot and upper torso. Referto section 4.6 for more details.
