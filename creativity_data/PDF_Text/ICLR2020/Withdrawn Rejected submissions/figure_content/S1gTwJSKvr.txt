Figure 1: Left: The convolutional block used in this paper. Right: When both weights and activa-tions are quantized using binary quantization, the convolution can be implemented efficiently usingbitwise XNor and bit-counting operations. See Section 3.2 for more details.
Figure 2: Left: The conditional expectations in (10) for a random variable x with standard normaldistribution. The optimal value for 2-bits quantization is shown with a solid dot. Right: Optimiza-tion domain of (8) for k=2. The boundaries correspond to 1-bit and ternary quantizations.
Figure 3: The angle between the full precisionand the quantized activations for different layersofa trained full precision ResNet-18 architectureon ImageNet. The 95% confidence interval overdifferent input images is shown.
Figure 4: Left: Distribution of energy for |X |, where X ∈ R30×30 is a standard normal randommatrix. Right: Entries of the first left and right singular vectors of |X | (shown in green and blue)are almost constant.
