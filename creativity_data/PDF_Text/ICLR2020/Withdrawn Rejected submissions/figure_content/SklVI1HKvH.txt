Figure 1: Diagrams demonstrating the operation of the PointNet style encoder network shared by allarchitectures we evaluate, and the parallel decoder network shared by all the sampling approaches.
Figure 2: Diagrams of the different approaches to deriving a distribution from the latent shaperepresentation h.
Figure 3: Average validation losses of eacharchitecture in the 2M family during training.
Figure 4: Test performance of each archi-tecture at different parameter counts. Errorbars show the 95% confidence interval of themean.
Figure 5: Examples of networks’ auto-encoding results on several previously unseen objects.
Figure 6: Behavior of NoiseAppend and NoiseLearn when the noise is manipulated. The ith figurein the top row shows the decoded point clouds when all but the ith variance is set to zero. The samefigure in the bottom row shows the decoded point clouds when all but the first i variances are set tozero. The faint red points show the network’s input.
Figure 8: Contribution of individual channels of noise when the NoiseAppend architecture is modi-fied to only append N elements of noise to the shape representation.
Figure 7: Average finalvalidation loss achievedby NoiseAppend networkswhen varying the number ofelements of noise appended.
