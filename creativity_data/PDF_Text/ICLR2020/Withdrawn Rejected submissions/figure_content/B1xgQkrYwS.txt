Figure 1: Test accuracy on the MNIST test setfor SGD-trained LeNet models, pruned usingsix different pruning techniques, and rewoundto initial weight values after each pruning itera-tion.
Figure 2: Test accuracy on the MNIST test setfor SGD-trained LeNet models, pruned usingfour different pruning techniques correspondingto the four colors. The transparent curves corre-spond to finetuning; the dark ones to rewinding.
Figure 3: Jaccard distance between the masks (i.e. connectivity structures) found by pruning LeNetusing L2-structured pruning, and those found by other pruning methods listed in the legend, con-ditional on identical seed for meaningful comparison in light of neural network degeneracy. Thecomparison is conducted for each layer individually. L1-structured pruning yields the most similarmasks to L2-structured pruning, as expected.
Figure 4: Jaccard distance between the mask for the second convolutional layer found by pruningLeNet using L1-unstructured pruning, and the mask found by other pruning methods listed in thelegend above, conditional on identical seed. Surprisingly, L1-unstructured behaves more like L1-structured pruning than a random unstructured pattern. This behavior is further investigated in Fig. 5.
Figure 5: Masked weights in the 2nd Convolutional layer of LeNet. The two rows represent twodifferent pruning iterations. The Columns represent four different pruning and weight treatments.
Figure 6: Weight values (y-axis) after 30 epochs of training at various consecutive sparsity levels(x-axis), for weights in the 2nd convolutional layer in the LeNet architecture (seed: 0). Lines areterminated when the weight is pruned.
Figure 7: Weight values (y-axis) after 30 epochs of training at various consecutive sparsity levels(x-axis), for weights in the 3rd fully-connected layer in the LeNet architecture (seed: 0). Lines areterminated when the weight is pruned.
Figure 8: Absolute difference between weight values at pruning iteration i and i - 1, averaged overall iterations and all weights in each layer. The lower, the more stable.
Figure 9: Jaccard distance between the masks found by pruning LeNet and rewinding weights, andthose found by finetuning after pruning, conditional on identical pruning techniques and seeds. Thecomparison is conducted for each layer individually. Note the logarithmic scale on the x-axis.
Figure 10: Test accuracy comparison on the MNIST test set for SGD-trained LeNet models, prunedusing four different pruning techniques corresponding to the four colors, and reinitialized using threedifferent techniques corresponding to the line styles.
Figure 11: Growth of the Jaccard distance between the mask found by rewinding after pruning andthree other techniques of handling weights (in order from highest to lowest opacity in the figures:finetuning, rewinding to σ ∙ Sign(Wi), and rewinding to Sign(Wi). Each column of sub-figures Cor-responds to a pruning technique (same color code as in the rest of the paper); each row correspondsto a layer in LeNet. Note the logarithmic scale on the x-axis.
Figure 12: Test accuracy achieved after 30 training iterations by LeNet models trained with SGDand pruned with the methods listed in the legend. Each dot corresponds to a version of the modelat the end of training. Each line connects models obtained by iterative pruning from the same seed.
Figure 13:	Difference in mask structure in the second convolutional layer that emerges when pruningafter a single epoch (left) versus 30 epoch (right) of training (seed: 0).
Figure 14:	Number of examples in the MNIST test set over which the sub-networks obtained througheach pruning technique agree on the prediction, on average (over 5 experimental seeds).
Figure 15: Binary weight masks for the first four convolutional layers of AlexNet trained on MNIST(left) and VGG-11 trained on CIFAR-10 (right), at the 20th and last pruning iteration for L1 unstruc-tured pruning (seed: 0). Despite the unstructured nature of the pruning technique, structure emergesalong the input and output dimensions, which resembles the effect of structured pruning.
Figure 16: Weight values (y-axis) after 30 epochs of training at various consecutive sparsity levels(x-axis), for weights in the 1st convolutional layer (first row) and last fully-connected layer (secondrow) in the AlexNet architecture, and the 1st convolutional layer (third row) and last fully-connectedlayer (fourth row) in the VGG-11 architecture (seed: 0). Each column corresponds to one of thefollowing pruning techniques: L1 structured pruning, hybrid L1 structured (in conv layers) and L1unstructured (in fully-connected layers) pruning, and L1 unstructured pruning.
