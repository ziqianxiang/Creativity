Figure 1: The GMLP network architecture.
Figure 2: Accuracy versus number of parameters for this work (GMLP) and the MLP baseline: (a)CIFAR-10 dataset, (b) MIT-BIH dataset. The x-axis is in a logarithmic scaleobjective. From this figure, it can be seen that excluding both techniques leads to a significantly lowerperformance. However, using any of the two techniques leads to relatively similar high accuracies.
Figure 3: Ablation study demonstrating the impact Figure 4: Ablation study demonstrating the impactof temperature annealing and entropy loss terms. of different pooling functions.
Figure 5: Ablation study on the impact of usingdifferent group sizes (m). For this experiment, Weused k=1536.
Figure 6: Ablation study on the impact of using dif-ferent number of groups (k). For this experiment,we used m=16.
Figure 7: MNIST visualization of pixels selected by the Group-Select layer: (a) using completeimages as input, (b) using images that the lower half is replaced by Gaussian noise. In this figure,warmer colors represent pixels being being present in more groups.
Figure 8: The Bayesian network and conditionals Figure 9: Visualization of the selectedused to generate the synthesized dataset of binary features within each group. Every twofeatures A-F and target J.	consecutive rows show features selectedfor a certain group.
Figure 10: Visualization of pixels selected by each group for the CIFAR-10 GMLP architecture. Red,green, and blue colors indicate which channel is selected for each location. Due to space limitations,25 random groups out of 1536 total groups visualized here.
Figure 11: Visualization of pixels selected by the group-select layer for the CIFAR-10 GMLPmodel. Warmer colors represent features that are being selected more frequently.
