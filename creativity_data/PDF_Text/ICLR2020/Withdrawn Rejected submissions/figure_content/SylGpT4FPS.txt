Figure 2: Plot of nonconvex function F(x) defined in (16), as well as its first and second derivativesLet us look at the derivatives of g with respect to x1 and x2 :1, x2)-3 + 4x23 sin x1 + 4x2sin x1 + 2 + 4x2for xι ≤ -2for - 2 <xι ≤ 2for xι > 2(19)1, x2)3 + 4x1-3 sin x2 + 4x1- sin x2 + 2 + 4x1for x2 ≤ - 2for - 2 <x2 ≤ 2for x2 > 2(20)Observe that if xι ∈ [-2, 2] then critical points of g must satisfy 3sin xι + 4x2 = 0, which impliesthat x2 ∈ [-4, 3]. Likewise, if x2 ∈ [-∏, ∏], then critical points of g must have xι ∈ [-1, 3]. We
Figure 3: Plot of nonconvex-nonconcave g(x1, x2) = F (x1) + 4x1>x2 - F (x2)These equations imply the following:x13sin X2x2-3sin xι⇒ x1⇒ x2-Sin - - Sin x24	42--sin ( - sin x24	42(23)(24)(25)(26)That is, for all critical points of g, xι must be a fixed point of hi (x) = 3 sin (- 3 sin x) and x2 mustbe a fixed point of h2(x) = -4 sin (∣ sin x). Since |h；(x)| < 1 and ∣h2(x)∣ < 1 always, hi and h2are contractive maps, so they have only one fixed point each. Thus, g will only have one critical point,namely the point (xi, x2) such that xi is the unique fixed point of hi and x2 is the unique fixed point
Figure 4: Plot of g(∙, 0). We can see that there is only one min and it occurs at xi = 0.
Figure 5: Plot ofg(0, x2). We can see that there is only one max and it occurs at x2 = 0.
Figure 6: Plot of f(x) = log(1 + ex) with its first and second derivatives. This is a convex, smoothfunctionWhen c = 3, SGDA converges, and when c = 10, SGDA diverges. We note that HGD and CO (forlarge enough γ) tend to converge faster when c is larger.
Figure 7: SGDA vs. HGD for 300 iterations for g(x1, x2) = f(x1) + cx1x2 - f(x2) wheref(x) = log(1 + ex) and c = 3. SGDA slowly circles towards the min-max, and HGD goes directlyto the min-max.
Figure 8: CO for 100 iterations with different values of γ for g(x1, x2) = f(x1) + cx1x2 - f(x2)where f(x) = log(1 + ex) and c = 3. The γ = 0.1 curve slowly circles towards the min-max, whilethe other curves go directly to the min-max.
Figure 9:	HGD vs. CO for 100 iterations for g(x1, x2) = f(x1) + cx1x2 - f(x2)log(1 + ex) and c = 3 with different values of γ.
Figure 10:	SGDA vs. HGD for 150 iterations for g(x1, x2) = f(x1) + cx1x2 - f(x2) wheref (x) = log(1 + ex) and c = 10. SGDA slowly circles away from the min-max, while HGD goesdirectly to the min-max.
Figure 11: CO for 15 iterations with different values of γ for g(x1, x2) = f(x1) + cx1x2 - f(x2)where f(x) = log(1 + ex) and c = 10. The γ = 0.1 curve makes a cyclic pattern around themin-max, while the other curves go directly to the min-max.
Figure 12: HGD vs. CO for 15 iterations with different values ofγ for g(x1, x2) = f(x1) + cx1x2 -f (x2) where f(x) = log(1 + ex) and c = 10.
Figure 13: Plot of nonconvex function F(x) defined in (16), as well as its first and second derivativesAs in the convex-concave case, when c = 3, SGDA converges, and when c = 10, SGDA diverges.
Figure 14: SGDA vs. HGD for 300 iterations for g(x1, x2) = F(x1) + cx1x2 - F(x2) where F(x)is defined in (73) and c = 3. SGDA slowly circles towards the min-max, and HGD goes more directlyto the min-max.
Figure 15: CO for 100 iterations with different values of γ for g(x1 , x2) = F (x1) + cx1x2 - F (x2)where F (x) is defined in (73) and c = 3. The γ = 0.1 curve slowly circles towards the min-max,while the other curves go more directly to the min-max.
Figure 16: HGD vs. CO for 100 iterations for g(x1 , x2)defined in (73) and c = 3 with different values of γ.
Figure 17: SGDA vs. HGD for 150 iterations for g(x1, x2) = F(x1) + cx1x2 - F(x2) where F(x)is defined in (73) and c = 10. SGDA slowly circles away from the min-max, while HGD goes directlyto the min-max.
Figure 18: CO for 15 iterations with different values of γ for g(x1, x2) = F(x1) + cx1x2 - F(x2)where F (x) is defined in (73) and c = 10. The γ = 0.1 curve makes an erratic cycle around themin-max, slowly diverging, while the other curves go directly to the min-max.
Figure 19: HGD vs. CO for 15 iterations with different values ofγ for g(x1, x2) = F(x1) + cx1x2 -F(x2) where F(x) is defined in (73) and c = 10.
Figure 20:	Distance to minmax for HGD iterates for different values of c in the objective g(x1 , x2)F(x1) + cx1x2 - F(x2) where F(x) is defined in (73).
Figure 21:	Gradient norm for HGD iterates for different values of c in the objective g(x1, x2) =F(x1) + cx1x2 - F(x2) where F(x) is defined in (73). Since all runs are initialized at (5, 5), whenc is increased, the initial gradient norm also increases. Nonetheless, HGD still converges faster forthe cases with higher c.
