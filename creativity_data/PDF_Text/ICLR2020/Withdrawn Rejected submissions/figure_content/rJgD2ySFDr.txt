Figure 1: (a) Joint communication system: A message X passes through a joint source and channelencoder before it passes a channel and is subsequently decoded. (b) Separate communication system:This system distinguishes source encoding and decoding (red) from channel encoding and decoding(blue). Red and blue system are designed independently of each other.
Figure 2: (a) Graphical model of the jointlylearned communication system. The message Xis passed by the encoder and the channel, to bereconstructed into X . Note that because marginal-ization is not possible we apply a variational ap-proximation Q to aid inference. (b) Graphicalmodels of the separately learned communicationsystem. Two systems are learned independently: aVAE for source compression (red) and an AE forchannel transmission (blue).
Figure 3: Excerpt of the graphicalmodel in Figure 2 (a). We show howthe decoder changes when introduc-ing auxiliary latent variables V .
Figure 4: Results of comparing distortion for jointand separate neural communication systems at vari-ous signal-to-noise ratios for the Gaussian channel.
Figure 5: We consider joint models trained based on the AWGN bandwidth-limited channel witha fixed SNR of 1. In both figures we contrast message quality with bandwidth. The higher thebandwidth the more information is transmitted to the receiver. Left: We measure message qualityby distortion in L2-space. We compare two approximations to the channel encoding distributions.
Figure 6: First row: Message samples from the source distribution. Other rows from top to bottom:Samples of the reconstructed message at all considered bandwidths. The top row has least information.
Figure 7: The results in Figure ?? show the distortion vs the SNR for an optimized β. Here wepresent all results. Note that, the joint model is more sensitive to changes in β in the range we havechosen.
