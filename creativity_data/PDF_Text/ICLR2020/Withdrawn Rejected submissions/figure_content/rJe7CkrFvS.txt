Figure 1: (top) The planner (LQR-RRT)(Perez et al., 2012) generates interactions — (s, a, r, s0)tuples — which are analyzed for state space coverage and are used in a SAC (Haarnoja et al.,2018) policy search process - see Figure 4. The returns that this policy generates are evaluatedand compared to those of directly trained agents. (bottom) The agent directly learns a policy. Theinteractions it generates in this process are collected. These interactions are analyzed for state spacecoverage and are also used to train a policy. The return generated by these indirectly learned policiesis also included in the comparison (Figure 4).
Figure 2: (Top) In the non-exploring-starts 1D double-integrator, the agent starts at position 0 withvelocity = 0. The reward is based on the distance of the agent to the goal positions 1 and 2. Exactlyat position 1 (resp. 2) the agent will receive a reward of 1 (resp. 2) at each step. The plots aboveand on the right of the heatmap show the reward distribution at velocity= 0 and at position= 0,respectively. (Bottom) When uniformly-sampled actions are taken in the 1D double integrator, thedepicted state occupancy emerges. This shows which states the agent will stumble upon more easilyand which states are harder to reach.
Figure 3: (Left) Coverage of the state space. (Right) The datasets generated by the methods SAC,SAC ex, and RRT consist of (s, a, r, s0) tuples. This plot shows how often what reward is achieved,or more precisely the log kernel density of the empirical distribution of rewards.
Figure 4: Box plot of the return distributions, generated from 11 independent runs where each runconsists of the mean of 10 evaluation runs. The evaluation runs are performed at the end of thetraining process, equally spaced 10 episodes apart. The policies are trained directly or indirectlyfrom interaction data (as described in Figure 1 ).
Figure 5: Evaluation returns of training a policy on a prefilled (with 50000 samples) replay bufferof size 50000 and training for 50000 steps. The highlighted area is the 25% to 75% range and thelightly-shaded area the 10% - 90% range.
