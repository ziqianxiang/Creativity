Figure 2: Multiplication of x1 and x2 implemented as a general multiplication, C ∞ smoothWHILE-program and C0 smooth WHILE-program. The height indicates the result of the function.
Figure 4: RAN System overview. The reconstructor receives an object from the input domain Aand predicts the corresponding reconstruction. The reconstruction, then, is validated through oursmooth inverse. The latter produces objects in a different domain, B , which are translated back to theinput domain A for training purposes (b2a). Unlike in traditional GAN systems, the purpose of ourdiscriminator D is mainly to indicate whether the two inputs match in content, not in style. Our noveltraining scheme trains the whole network via five different data paths, including two which requireanother domain translator, a2b.
Figure 5: The structure of SoftSort. Here, the exchanges of adjacent elements are represented bymatrices Mi. By multiplying these matrices with tensor a, we obtain b, the sorted version of a. Byinstead multiplying with tensor t, we obtain t′ : t sorted with respect to a. Using that, we can also sorta tensor with respect to a learned metric. For sorting n values, we need n - 1 steps for an even n andn steps for an odd n; to get a probabilistic coarse sorting, even fewer steps may suffice. s denotes thesteepness of the sorting such that for s -→ ∞ we obtain a non-smooth sorting and for infinitely manysorting operations, all resulting values equal the mean of the input tensor. In the displayed graph, thetwo recurrent layers are unrolled in time.
Figure 6: Results for the reconstructionof the ShapeNet (Chang et al. (2015))classes airplane, and car. Left:input. Middle: prediction from thesame angles. Right: predictions fromalternative viewpoints. Bottom: Asingle-view reconstruction result fromthe UT ZaPPos50K dataset (YU & Grauman (2014)) (camera-captured images). Although the objecthas strong textures, it is adequately reconstructed.
Figure 7: Visualization of the smooth depth bufferand occlusion: 7a shows three triangles renderedin a standard way, in 7b the same triangles arerendered smoothly. While in the discrete case asmall change in depth can result in a sudden changeof color (7c), our smooth depth-oriented rendering(7d) avoids that and therefore is differentiableeverywhere.
Figure 8: Visualization of the smooth rasterization. While the magenta point lies outside thetriangle, the cyan point lies inside the triangle; this can be determined by measuring on whichside of the edges a point lies. In subfigure 8b-8d it is smoothly determined which parts of theimage lie inside and which parts lie outside the triangle with respect to the edges a-c. This iscombined by multiplication (visibility tensor V ) in subfigure 8e.
Figure 9: Stanford bunny rendered by the smooth renderer using different edge smoothnesses(s) and opacities (o): In 9a and 9b, the low opacity o causes, e.g., one of the ears to be stillvisible through the head of the bunny (for usage of o see section A.1). In 9a and 9c, the low edgesteepness causes smoother edges (for usage of s see section A.2). On the right: The Stanfordbunny rendered by Blender (e).
Figure 11: The five sub-RANsconstituting the RAN.
Figure 12: Four-view reconstruction of the ShapeNet (Chang et al. (2015)) classes airplane,car, and sofa. Left: input. Middle: prediction from the same angles. Right: predictions fromalternative viewpoints.
Figure 13: Single-view reconstruction results from the UT ZaPPos50K dataset (camera-capturedimages).
Figure 14: Experiments showing the robustness of our approach. (a-c): four-view training with thefollowing modifications to the training data: (a) randomized azimuth of the images; (b) randomlyassigned position of the light source; (c) simultaneous training of car and airplane classes; (d)predicting images from only two input images; (e) single-view reconstructions.
