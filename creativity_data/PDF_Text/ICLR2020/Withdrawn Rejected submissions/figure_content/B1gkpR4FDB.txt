Figure 1: Comparison of different optimizers on CIFAR-10. All SASA, SASA+ and SALSA areusing SGD with momentum 0.9. SALSA starts from a small initial learning rate 0.01 while othermethods starts from an oracle maximal learning rate 1.0. SALSA witches from SSLS to SASA+ atepoch 40.
Figure 2: Statistics used in SASA+. Upper row: drop ratio τ = 1/2; lower row: τ = 1/10. Theleft column shows the instantaneous value of ∆k . The middle column shows the confidence intervalof E[∆k] constructed by SASA+, which should contain 0 with high probability if the process isstationary. The right column shows the variance estimated by different methods, where BM andOLBM takes into the consideration of correlation in Markov chains and are more accurate.
Figure 3:	Sensitivity analysis of SASA+ on CIFAR10, using β = 0.9 and ν = 1. The training loss,test accuracy, and learning rate schedule for SASA+ using different values of τ (top row), δ (middlerow), and θ (bottom row) around the default values are shown.
Figure 4:	First row: SSLS. Second row: SALSA (warmup 40 epochs). Here, SGD with β =0.0 and QHM with parameters β = 0.9 and ν = 0.9. SSLS is able to find a balance betweenincreasing and decreasing learning rate, and results in a stable large learning rate (SGD) or furtherdecreases the learning rate (QHM). In either case, switching to SASA+ (the lower row) gets goodfinal performance.
Figure 5: Upper: Comparison of different optimizers on ImageNet. All SASA runs use SGD withmomentum 0.9, while SASA+ and SALSA use NAG (QHM with β = ν = 0.9). SALSA startsfrom a small initial learning rate 0.1 while other methods starts from an oracle maximal learningrate 1.0. SALSA witches from SSLS to SASA+ at epoch 40. Lower: the first three curves arestochastic optimization algorithms with hand-tuning learning rate, i.e., decrease every 30 epochsas it is shown in the lower right panel. The last three curves are SASA+ combined with these 3algorithms. SASA+ automatically adapt their learning rate (see the lower right panel), achievescomparable and even slightly higher testing accuracy (see the lower middle panel).
Figure 6: Sensitivity analysis of SSLS around α0 = 0.01, γ = b/n = 0.0002, c = 0.1, with SGDβ = 0.9, ν = 1 on ImageNet.
Figure 7: Statistical tests in SASA and SASA+. Case (1): both SASA and SASA+ keep the learningrate. Case (4): both SASA and SASA+ decrease the learning rate. Case (2): SASA keeps thelearning rate while SASA+ decreases. Case (3): SASA decreases the learning rate while SASA+keeps.
