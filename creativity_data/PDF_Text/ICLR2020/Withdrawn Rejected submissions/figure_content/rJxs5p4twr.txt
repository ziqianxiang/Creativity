Figure 1: Auto-Encoding Examples Setup: Given a misclassified point x0 and representativesx-T , xT, we construct suitable interpolations (stochastic processes) by means of an Auto-Encoder.
Figure 2: Probability Paths for the litigation case l0 = 2, lT = 7. Y axis corresponds to classificationprobability and x axis corresponds to interpolation index. Interpolation images for a specific pathsare presented below the x axis.
Figure 3: Average action for Mini-mum Hesitant Lagrangian. PATHS-architectures trained to minimizesemantic action.
Figure 4: Saliency Maps Com-parison: From left to right col-umn: Vanilla Gradients, SmoothGradients, Guided BackProp, GradCAMP, Interpolations, Differencewith Representative. Upper rowcorresponds to l-T = 2, lower rowto lT = 7.
Figure 5: Rank correlation betweenthe original explanation and the ran-domized explanation derived up tothat layer.
Figure 6: Probability Paths for the case of detecting a smile in images of celebrities. Y axiscorresponds to classification probability and x axis corresponds to interpolation index. Interpolationimages for a specific paths are presented below the x axis. The images are vertically aligned with acorresponding tick in the x-axis determining the interpolation index of the imagescore for a given input example and class label by computing the gradient of the classifier withrespect to each input dimension. Generalizations of this approach address gradient saturation byincorporating gradientsâ€™ values in the saliency map (Shrikumar et al., 2017) or integrating scaledversions of the input (Sundararajan et al., 2017). Ad hoc modifications of the gradient explanationvia selection of the required value (Springenberg et al., 2015),(Zeiler & Fergus, 2014), as well asdirect studies of final layers of the convolutions units of the classifiers (Selvaraju et al., 2016), arealso provided. In contrast to gradient based approaches, other categories of explanatory models relyon reference based approaches which modify certain inputs with uninformative reference values(Shrikumar et al., 2017). Bayesian approaches treat inputs as hidden variables and marginalize overthe distribution to obtain the saliency of the input (Zintgraf et al., 2017). More recent generaliza-tions exploit a variational Bernoulli distribution over the pixels values (Chang et al., 2018). Othersuccessful methodologies include substitution of black-box model with locally interpretable linearclassifiers. This is further extended to select examples from the data points in such a way that the latterreflect the most informative components in the linear explanations, (Ribeiro et al., 2016). Studiesof auto-encoder interpolations seek to guarantee reconstruction quality. In (Arvanitidis et al., 2018)the authors characterize latent space distortions compared to the input space through a stochastic
Figure 7: Interpolation between 2 and 7. It is seen that the Path-VAE interpolation optimizes bothprobabilities (P(2) and P(7)) according to the chosen Lagrangian - in this case the minimum hesitantL1.
Figure 8:	Interpolation between 6 and 9. The Path-VAE interpolation appears to emphasize the"opening and closing" of the loop.
Figure 9:	Interpolation between 3 and 5. The translation of the "upper bar" is a prominent feature ofthe Path-VAE interpolation.
Figure 10: Probability Paths for the case of detecting the sex in images of celebrities. Y axiscorresponds to classification probability and x axis corresponds to interpolation index. Interpolationimages for a specific paths are presented below the x axis. The images are vertically aligned with acorresponding tick in the x-axis determining the interpolation index of the image13Under review as a conference paper at ICLR 2020D Stochastic Semantic Processes: Proof of Proposition 1Briefly put, the construction we utilize makes use of the well-known notion of consistent measures,which are finite-dimensional projections that enjoy certain restriction compatibility; afterwards, weshow existence by employing the central extension result of Kolmogorov-Daniell.
