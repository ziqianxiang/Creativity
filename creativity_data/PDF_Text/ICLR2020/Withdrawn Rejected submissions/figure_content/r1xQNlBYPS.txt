Figure 1: (Left) An example multichannel modeling over 3 languages (English, French, Czech),where the model predicts the missing tokens at each location across multiple channels. (Right)During inference, MGLM can generate output sequence for a single target language channel (top),or for multiple language channels in parallel (bottom), conditioning on source channel sentence andpartial translations of multiple language channels.
Figure 2: Example parallel greedy deCode using the Multi-target (Any → Rest) KERMIT model,starting with an English sentenCe. Blue underlined tokens are the inserted tokens at eaCh iteration,and the gray tokens are the final output that have not been generated yet. Note that the three targetlanguages are generated together in parallel.
Figure 3: (Left) Number of decoding iterations vs. the output length when decoding each targetlanguage serially vs. in parallel, compared to various logarithmic bounds. We have shown that themodel is able to achieve close to the theoretical lower bound blog2 (N/k)c+2 where number of targetlanguages k = 3. (Middle) Relative wall-clock speed up when using the parallel target languagesdecoding vs. serial, achieving slightly under 3 times the performance. (Right) Total output length forthe 3 target languages when using serial vs parallel target language generation. While not identical,we observe a linear relationship between the output length using the two different modestranslations per source sentence, at softmax temperature τ = 0.1, 0.5, 1.0. At each temperature andmodel, we computed the quality of the generated samples by computing the BLEU Papineni et al.
Figure 4: Quality-Diversity BLEU curve for several KERMIT models (bilingual, multitarget, joint)on the Multi30k text 2016 Flickr test set. Dotted diagonal line signifies BLEU equals Self-BLEU. Points indicate different temperatures, from 0.1 (low diversity, left in graph) to 1.0 (highdiversity, right in graph)*--* Joint EN->*Joint *->EN⅛Hk, Multitarget EN->*MUItitarget 札>EN♦ ♦ Bilingual EN->*♦ ∙O Bilingual *->ENFigure 4 illustrates the Quality-Diversity trade-off for the three models for different translation pairsinvolving English as one of the language. The top right portion of the graph is the ideal area. Weobserved that the Multitarget model outperformed the Bilingual model at lower temperature (bothhigher quality and diversity), and at higher temperature slightly above or below in quality but stillhigher diversity. Note that only one single Multitarget model was used for all language pair atinference time, while each bilingual model was different for each language pair curve. Therefore, asingle Multitarget KERMIT model could outperform specialized bilingual KERMIT models.
Figure 5: Partially conditional generation samples drawn from our model. The seed text is shown ingray, with several different in-filling samples from the model in black. The samples show reasonableconsistency and diversity across samples.
Figure 6:	Unconditional multilingual generation Pseudo-Target BLEU for self-consistency whengenerating sentences in multiple languages. Colour shading indicates the difference compared tothe Joint model (unrestricted) generation.
Figure 7:	Example unconditional text generation samples from the Joint (top) and chain of Bilingualmodel (bottom). Note that the Joint model generates one long sequence and we split them into theresulting four sentences in each language here, while Bilingual generate a complete sentence in eachlanguage conditioned on previous sentence.
Figure 8: Quality-Diversity BLEU curve for several KERMIT models (bilingual, multitarget, joint)on the Multi30k text 2017 Flickr test set. Dotted diagonal line signifies BLEU equals Self-BLEU. Points indicate different temperatures, from 0.1 (low diversity, left in graph) to 1.0 (highdiversity, right in graph)Self-BLEU∙ ∙∙ Joint EN->*•■■■• Joint *->ENτirj⅛∙ Multitarget EN->*Multitarget *->EN♦ ♦ Bilingual EN->*♦ ♦ Bilingual *->ENQuality-Diversity BLEU (test 2017 mscoco)∙ ∙∙ Joint EN->*•■■■• Joint *->ENMultitarget EN->*Multitarget *->EN♦ ♦ Bilingual EN->*♦ ♦ Bilingual *->ENFigure 9: Quality-Diversity BLEU curve for several KERMIT models (bilingual, multitarget, joint)on the Multi30k text 2017 MSCOCO test set. Dotted diagonal line signifies BLEU equals Self-
Figure 9: Quality-Diversity BLEU curve for several KERMIT models (bilingual, multitarget, joint)on the Multi30k text 2017 MSCOCO test set. Dotted diagonal line signifies BLEU equals Self-BLEU. Points indicate different temperatures, from 0.1 (low diversity, left in graph) to 1.0 (highdiversity, right in graph)11Under review as a conference paper at ICLR 2020A.2 Additional Multi30K Translation ResultsModel	Inference	Test2016	Test2017	MSCOCOBilingual (EN → FR)	EN → FR	58.80	50.35	42.82Bilingual (EN o FR)	EN → FR	59.29	52.13	42.17Multi-target (EN → Rest)	EN → FR	58.08	50.39	42.19	EN → FR,CS,DE	58.52	50.49	41.53Multi-target (Any → Rest)	EN → FR	57.64	50.01	40.18	EN → FR,CS,DE	57.35	48.13	39.98Joint (p(EN, FR, CS, DE))	EN → FR	50.87	40.69	33.93	EN → FR,CS,DE	48.85	39.92	33.45Table 2: Multi30k English → French test BLEU.
Figure 10: Example of serial sampling unconditional text generation from the jointp(EN, FR, CS, DE) model, over 96 insertion time steps. Note that the model generates one longsequence and we split them into the resulting four sentences in each language here.
