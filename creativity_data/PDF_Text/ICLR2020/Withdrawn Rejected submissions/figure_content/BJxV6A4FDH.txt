Figure 1: An illustrative 1D regression problem. The training data {(xi, yi)}i2 *=0010 is generated bythe ground truth conditional target density p(y|x). DCTD models p(y|x) by predicting the un-normalized density from (x, y). In contrast to the Gaussian model p(y |x, θ) = N(y; μθ(x), σ2(x)),DCTD can learn complex target densities directly from data, including multi-modal ones.
Figure 2: Visualization of the conditional target density p(y∣x, θ)〜efθ(x,y) predicted by our net-work for the task of bounding box estimation in visual tracking. Since the target space y ∈ R4 is4-dimensional, we visualize the density for different locations of the top-right corner as a heatmap,while the bottom-left is kept fixed at the tracker output (blue box). Our network predicts flexibledensities, expressing meaningful uncertainties in challenging cases.
Figure 3: Network architectures for the different detection networks used in our experiments inSection 4.1. The backbone feature extractor (ResNet50-FPN), and the region proposal network(RPN) is not shown for clarity. We do not train the blocks in blue color, using the pre-trained Faster-RCNN weights from Massa & Girshick (2018) instead. The blocks in red are initialized with thepre-trained Faster-RCNN weights and fine-tuned. The blocks in green on the other hand are trainedfrom scratch.
