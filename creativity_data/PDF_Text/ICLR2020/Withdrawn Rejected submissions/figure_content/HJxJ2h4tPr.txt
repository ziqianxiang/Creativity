Figure 1: HighRes-net combines many low-resolution images (300 meters/pixel) into one image of superiorresolution. The same site shot in high-resolution (100m/pix) is also shown for reference. Source of low-res andhigh-res: imgset1087 and imgset0285 of PROBA-V dataset, see section 5.
Figure 2: Top: A chirp harmonic oscillator sin (2πω(t)t), With instantaneous frequency ω(t). Left: Theshape of the high-resolution sample resembles the underlying chirp signal. Right: Close to t = 1, the apparentfrequency of the low-resolution sample does not match that of the chirp. This is an example of aliasing (shownwith red at its most extreme), and it happens when the sampling rate falls below the Nyquist rate, SN = 2 ∙ SB,where SB is the highest non-zero frequency of the signal.
Figure 3: Schematic of the full processing pipeline, trained end-to-end. At test time, only HighRes-net isused. (a) HighReS-net: In the Encode stage, an arbitrary number of LR views are paired with the referencelow-res image (the median low-res in this work). Each LR view-reference pair is encoded into a view-specificlatent representation. The LR encodings are fused recursively into a single global encoding. In the Decodestage, the global representation is upsampled by a certain zoom factor (×3 in this work). Finally, the super-resolved image is reconstructed by combining all channels of the upsampled global encoding. (b) RegiSteredloSS: Generally, the reconstructed SR will be shifted with respect to the ground-truth HR. ShiftNet learns toestimate the (∆x, ∆y) shift that improves the loss. Lanczos resampling: (∆x, ∆y) define two 1D shiftingLanczos kernels that translate the SR by a separable convolution.
Figure 4: HighRes-net’s global fusion operator consists of a co-registration gθ and a fusion fθ block whichaligns and combines two representations into a single representation.
Figure 5: Public leaderboard scores vs. nviews for HighRes-net + ShiftNet. Lower is better.
