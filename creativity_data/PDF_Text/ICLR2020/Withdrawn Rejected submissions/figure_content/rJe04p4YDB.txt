Figure 1: Each step of gradient descent in Coaching consists of two steps. Updating the Student (top): Theteacher network T samples the labels y of unlabeled data Xu∏ι for the student S to learn from. Updating theTeacher (bottom): The teacher updates itself using policy gradient to improve the student’s performance onlabeled data xlab.
Figure 2: An illustration of Why OpenImages help ImageNet classification. Top: OpenImages tags. Middle: Asample image from OpenImages. Bottom: Top 5 labels for the image predicted by a teacher ResNet-50 trainedon ImageNet. Some OpenImages tags overlap significantly with some ImageNet classes, such as wheel and carwheel in the second image. The class predictions also have a higher entropy when the ImageNet classes overlapless with the OpenImages contents (images 2, 4, 5), than when the ImageNet classes overlap more (images 1, 3).
Figure 3: Breakdown of the gains of differentcomponents in Coaching. The gain of Coachingover UDA, albeit smaller than the gain of UDAover RandomAugment, is significant as UDA isalready very strong.
Figure 4: Training accuracy of Coaching and of supervisedlearning on CIFAR-10-4,000 and ImageNet-10%. Both theteacher and the student in Coaching have lower trainingaccuracy, effectively avoiding overfitting.
