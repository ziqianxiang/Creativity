Figure 1: Bubble image and supervised localization(c) estimated centersto-end CNN by giving only the final count of objects. It is observed that the trained density mapcan roughly capture the positions of objects, but the accuracy is degraded by the convolution andpooling operations. This paper will discuss the impacts of these two operations on an end-to-endWSL network and propose techniques to improve accuracy. The density map counts objects bydetecting discriminative features. To improve interpretability of the found features, we introduce aGini impurity penalty to regularize the density map. Furthermore, the similarities and differencesbetween this regularization and the variational term of the β-variational autoencoder (VAE) (Higginset al., 2017) will be discussed. Throughout this paper, we will use a simple simulated bubble datasetto demonstrate basic ideas and a widely used crowd-counting dataset the Mall Loy et al. (2013);Chen et al. (2013); Change Loy et al. (2013); Chen et al. (2012) to show the methods’ effectivenessin practice.
Figure 2: Weakly supervised Localization with max-pooling2.3	Class activation mappingThe CAM localizes the positions of discriminative features by applying the global average pooling(GAP) to the final layer of a CNN. Because it is trained in a MIL way, the CAM can identify multiplefeatures in a image (Zhou et al., 2016). A trained CAM can also be used for proposing candidates ina MIM method (Chen et al., 2018). To some extent, CAM is analogous to density map counting, asaveraging the channels is equivalent to integrating the density map. On the other hand, CAM turnsa CNN with fully connected layers to a FCNN.
Figure 3: First layer output(yellow for higher values)The goal is to train the latent density map for localization:Θ = arg mιax Eq©(D|i)[log(p(c∣D))]	(3)In terms of training, equation 2 and 3 are identical. Following the notation of VAE (Burgess et al.,2018), we expose the hidden density map in 3 for further analysis.
Figure 4:	Weakly supervised Localization robust to rotationFirstly, the centers are relocated to match a low resolution grid. Figure 2e compiles the statisticsof 500 test samples to draw this grid clearly. This spatial information loss is caused by the poolinglayers, and it cannot be recovered by up-samplings. In contrast, this loss of detail does not happen inthe case of supervised localization (Figure 1), because the presence of the true centers in the labelsforces the network to retain position information even through down-sampling processes. Due tothis drawback, we will not use any pooling layers in the following WSL models.
Figure 5:	Weakly supervised localization with rotation robustness and Gini impurity penaltywhere p(D) is a 2-D distribution obtained by normalizing the density map:P(D)=PDD+ιWe add a small number to the denominator in case the integral is zero in practice.
Figure 6: Mall data weakly supervised localization(images are publicly accessible for research purposes)(d) WSL with Gini impurity penaltyreparameterization trick (Alemi et al., 2016). Thirdly, the latent variable of a VAE is usually a 1-Dvector in contrast to a 2-D density map in this problem. Finally, the prior in a VAE is often setto be an isotropic Gaussian distribution (Burgess et al., 2018), whereas we do not know the exactdistribution of the true density map; we only know its Gini impurity.
Figure 7: Residual BlockWe trained the network according to equation 2, where the ground-truth count within a 300×300patch is computed by adding up the head annotations. The counting error converges to around 0.85after 3×105 epochs. An example of the hidden density map is shown in Figure 6c. It shows thatthe CNN pays more attention to the human figures than the irrelevant backgrounds. But the networkdoes make some mistakes by counting parts of the booth, the tree, reflections, and the models ashuman beings, and for most of the bodies the detected features are along the their left sides. It canalso be noticed that for an individual person, the highlighted points concentrate on the upper body.
