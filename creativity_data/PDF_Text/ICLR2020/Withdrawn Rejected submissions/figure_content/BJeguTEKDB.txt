Figure 1: Our ICE and related losses. The first row shows prior work of a query versus classcentres/means while the second row displays the work of a query versus instances. Note that thecross entropy computation and interpretation are different in different losses. For a mini-batch,we show two classes, i.e., circle and rectangle, with 3 examples per class except N-pair-mc whichrequires 2 samples per class. The icons are at the right bottom. GT means ground-truth matchingdistribution. When illustrating the losses of a query versus instances in (c), (d) and (e), we indexthose instances with numbers for clarity, except the query.
Figure 2: t-SNE visualisation (Van Der Maaten, 2014) on the SOP test set. Best viewed on a monitorwhen zoomed in.
Figure 3: t-SNE visualisation (Van Der Maaten, 2014) on the CUB-200-2011 test set. Best viewedon a monitor when zoomed in.
Figure 4: t-SNE visualisation (Van Der Maaten, 2014) on the CARS196 test set. Best viewed on amonitor when zoomed in.
