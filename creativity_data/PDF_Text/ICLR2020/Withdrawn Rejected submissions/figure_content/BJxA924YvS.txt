Figure 1: (a) Normal KD framework. (b)(c) Diagrams of exploratory experiments we conduct.
Figure 2: MobileNetV2 taught by ResNet18 and ResNeXt29 with different accuracy on CIFAR100.
Figure 3: Distribution of manually designedteacher (softened by τ = 20) on 10-class dataset.
Figure 4: Classification accuracy by using Tf-KDself. (a) Tf-KDself improves all six models. (b)Improvement on ResNeXt29 trained by itself (Tf-KDself) is better than the normal training.
Figure 5:	Comparison of our Tf-KDself with Normal KD. (a) Tf-KDself achieves comparable re-sults to Normal KD. (b) MobileNetV2 obtains similar improvement by self-training or by ResNet18.
Figure 6:	Classification accuracy by using Tf-KDreg on ImageNet. (a) Top1 test accuracy on Ima-geNet. (b) Without extra computation, ResNet50 outperforms baseline model by 0.65%Comparing our two methods Tf-KDself and Tf-KDreg , we observe that Tf-KDself works better insmall dataset (CIFAR100) while Tf-KDreg performs slightly better in large dataset (ImageNet).
Figure 7: Comparison between label smoothing and soft targets of KD in different temperature τ .
