Figure 1: illustration of our overall method. We prioritize nodes to expand using the value networkestimates. Algorithm 1 queries the value network for all children of the first node in the priorityqueue. in our next algorithm, Algorithm 2, we show how to use a policy network to choose whichchildren nodes to add to the priority queue.
Figure 2: The constant gap model. The leaves have value 0 except for the optimal leaf, which hasvalue η . A blue path is a sub-optimal path, the red path is the optimal path.
Figure 3: Using Value and Policy Networksfor search in the Constant Gap Model withpolynomially decaying noise and η = 0.5.
Figure 4: Using Value and Policy Networksfor search in the Constant Gap Model withexponentially decaying noise and η = 0.5.
Figure 5: The generative model. A blue path is a sub-optimal path, the red path is the optimal path.
Figure 7: Using Value and Policy Networksfor search in the Generative Model withexponentially decaying noise and η = 0.5.
Figure 6: Using Value and Policy Networksfor search in the Generative Model withpolynomially decaying noise and η = 0.5.
