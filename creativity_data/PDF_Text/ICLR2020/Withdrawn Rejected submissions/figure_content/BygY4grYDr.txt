Figure 1: Plots of the pushforward densitiespd* (d) and g* (d) for the case where p and q aremultidimensional Gaussians with common co-variance. The f-divergence for a given f maybe obtained by integrating these pushforwardsagainst sf in Figure 2 using (19).
Figure 2: Plots of sf (d) for various f-divergences. The f-divergence for a given p andq may be obtained by integrating sf against thepushforwards of p and q such as those shown inFigure 1 using (19). Symmetries such as that be-tween KL and reverse KL are evident.
Figure 3: Plots of sf (d) for various reverseKL-like f-divergences. Softened reverse KL isthe divergence effectively minimized by non-saturating GAN training. IGOG is the diver-gence derived by Poole et al. (2016).
Figure 4: A strictly convex function f : R>0 → R and a tangent line. The variational bound usedby f-GANs is based on the fact that a strictly convex function f lies at or above its tangent lines.
Figure 5: Comparing training using the saturating and non-saturating GAN generator gradients ona toy problem. The true distribution p is a mixture of two 1D Gaussians and the model distributionq is a single Gaussian. Contour plots show the Jensen-Shannon (JS) divergence (left), and softenedreverse KL divergence 4KL(2P + 2q ∣∣ P) (right) as a function of model parameters. Lines showthe progression of SGD-based JS training based on the original, saturating gradient and based onthe non-saturating gradient (solid for learned critic; dotted for optimal critic). The original schemeconverges to the JS divergence minimum. The non-saturating scheme, which by the results of thispaper is equivalent to a hybrid (SRKL, JS) scheme, converges to the SRKL divergence minimum asexpected.
