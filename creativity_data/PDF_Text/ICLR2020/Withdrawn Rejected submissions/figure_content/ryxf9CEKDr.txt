Figure 1: The left most image is the input to the network. Five saliency maps are shown for eachspatial scale in the network. They are combined per Eq 3. The right most image is the combinedsaliency map created from these. To aid in visualizing context, it has been alpha blended with a grayscale version of the original image here at 25%. Many more combined saliency map examples canbe seen in Appendix Figures 9 and 101r4 (.) = r ∙ X Xk ∙k=1log2 r r ∙ X Xk) - r ∙ X log2 (Xk)k=1	k=1(1)To avoid log zero, we add 1e - 06 to each Xk . How mean and variance relate seems readily ap-parent with the square bracketed part being the computational formula for the standard deviationwith values taken to log2 (.) rather than squared. This is preceded by a typical mean estimate. Thismeets the third requirement we mentioned. This simplification is Saliency Map Order Equivalent(SMOE) to the full iterative (and expensive) scale parameter estimation. We define SMOE as fol-lows. Given saliency map Sa ∈ R+,p×q and Sb ∈ R+,p×q where we may have Sa 6= Sb, if wesort the pixels by value, then Sa will be sorted in exactly the same order as Sb . That means that themost salient location i, j is exactly the same in both Sa and Sb . This also means that if we createa binary mask of the n% most salient pixels, the mask for both Sa and Sb will also be exactly the
Figure 2: Images are shown with their combined saliency map using our LOVI scheme. The hue ineach saliency map corresponds to layer activation. Earlier layers start at violet and trend red in thelast layers following the order of the rainbow. Areas which are blue or violet are only activated earlyin network processing. They tend to activate early filters, but are later disregarded by the network.
Figure 3: These are the KAR (kept) and ROAR (removed) mask images created by masking out theoriginal images with the combined saliency map. The percentage is how much of the image has beenkept or removed based on the combined saliency map. Thus, the 10% kept example shows the top10% most salient pixels in the image. It is these example images that are fed into the network whenwe compute the KAR and ROAR scores. Many more examples can be seen in Appendix Figure 83	Quantitative Experiments3.1	Comparing Different Efficient StatisticsWe tested our SMOE Scale saliency map method against several other statistical measures usingthree different datasets that have fairly different tasks and can be effectively trained from scratch.
Figure 4: SMOE Scale is compared with several other efficient statistical methods. The Y-axis isthe combined score per scale layer over all three image sets. The X-axis is the network layer withL1 being the earliest layer in the network and L5 near the end. A difference score of zero meansthe result was about the same as for a randomly generated saliency map. Less than zero means itis worse. SMOE Scale differentiates itself the most early on in the network where most statisticalmethods score at the level of a random saliency map. About mid way through, the difference betweenmethods becomes relatively small. This may be because information contains more message and lessnoise by this point in processing. Finer grain details can be seen in Appendix Table 4Table 1: KAR and ROAR results per dataset. The Difference Score shows the results using Eq8. The Information Score uses Eq 9. They are sorted by the average difference score (AVG). TheSMOE Scale from Eq 2 performs best overall using both scoring methods. The vanilla standarddeviation is second best. Recall it is SMOE with normal entropy. Truncated normal entropy isbest on the COWC set and ranks third overall. It is interesting to note that the difference in scoresover COWC are not as large as the other two datasets. The top four methods all are informationrelated and mean activation style methods are towards the bottom. Finer grain details can be seen inAppendix Table 4Difference Score	Information ScoreMethod	ImNet	Places	COWC	AVG	ImNet	Places	COWC	AVGSMOE Scale	1.70	090	1.61	1.40	113	0.68	1.31	1.04Standard DeV	1.64	0.83	1.61	1.36	1.07	0.61	1.30	0.99
Figure 5: SMOE Scale with prior layer weights is compared with three popular baseline methodsthat all use Squared SmoothGrad. Scores for these three are taken from (Hooker et al., 2018). The Y-axis is the model accuracy on ImageNet only. The X-axis is how much of the input image salientpixels are kept or removed. KAR keeps the most salient locations. Higher accuracy values arebetter. ROAR removes the most salient regions. Lower values are better. Our method does not seemto suffer as much when the 10% least salient parts are removed in KAR and in general maintains abetter score. Our ROAR scores are very similar to Guided Backprop. Finer grain details can be seenin Appendix Table 5. Note that these results are not per layer. For a closer numerical comparisonwith the mask layer method, see Appendix Table 4.
Figure 6: These are examples of the first level saliency maps from SMOE Scale and Standard Devi-ation. It is common for both std and truncated normal entropy to flood in areas with modest texture.
Figure 7: A plot of the resulting k values from input S values in the gamma probability distributionmaximum likelihood estimation. It is monotonic and reciprocal.
Figure 8: These are the last mini-batch images in our GPU:0 buffer when running the ImageNetvalidation set. The top images are the original input images and the ones on the bottom are 10%KAR images of the most salient pixels. These are images used when computing KAR scores.
Figure 9: These are more examples of combined saliency maps using the same images that appearin Figure 8. These images are not alpha blending with the original. Above each image is the groundtruth label, while the label the network gave it is below. This was auto-generated by our trainingscripts.
Figure 10: These are the same as Figure 9 except with the original image gray scaled and alphablended at 25%.
Figure 11: These are more examples of visualizing multiple saliency maps using the same imagesthat are in Figure 8. These images are not alpha blending with the original.
Figure 12: These are the same as Figure 11 with the original image gray scaled and alpha blendedat 25%.
