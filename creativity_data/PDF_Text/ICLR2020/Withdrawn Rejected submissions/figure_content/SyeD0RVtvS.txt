Figure 1: Overview of our method. 2D CNN is used to extract photometric feature to construct costvolumes. Initial source depth maps are used to introduce geometry consistency. A series of3D CNNlayers are applied for both pose based cost volume and D-CV. Then a context network and depthregression operation are applied to produce predicted depth map of reference image.
Figure 2: Comparison with baseline during iterations. Our work converges at a better position. (a)abs relative error and log RMSE. (b) rotation and translation degree error.
Figure 3: Depth map results w.r.t. the number of images.
Figure 4: Detail architecture of feature extractor.
Figure 5: Four components in D-CV or P-CV.
Figure 6: 3D convolutional layers After P-CV.
Figure 7: Qualitative Comparisons with DeMoN (Ummenhofer et al., 2017) on DeMoN datasets.
Figure 8: Qualitative Comparisons with COLMAP (Schonberger & Frahm, 2016) on ETH3Ddatasets.
Figure 9: Qualitative Comparisons with COLMAP (Schonberger & Frahm, 2016) on challengingmaterials. a) Textureless ground and wall. b) Poor illumination scene. c) Reflective and transparentglass wall. d) Reflective and textureless wall.
