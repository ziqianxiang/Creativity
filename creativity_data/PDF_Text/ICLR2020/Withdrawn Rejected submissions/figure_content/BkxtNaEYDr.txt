Figure 1: Trainig ReLU networks with one hidden-layer of size 128 with Adam optimizer, on bothinstances of the k-Parity problem (k = 5, n = 128). The figure shows the accuracy on a test set.
Figure 2: Training a ReLU neural network, with two hidden-layers of size 512, on a single patch ofsize k Ã— k from the ImageNet data. The patch is randomly chosen from inside the image. We trainthe networks with Adam, with batch size of 50, for 10k iterations.
