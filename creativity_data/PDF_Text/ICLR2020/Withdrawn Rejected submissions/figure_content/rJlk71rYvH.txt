Figure 1: Left: The graphical model representing the generative process. Shaded nodes are observed,and empty nodes are not observed. In this example, the state at time t = 2 has been observed. Right:The latent state space s is represented as a convolutional feature map, and the transition function T (s)is implemented as a fully-convolutional neural network.
Figure 2: Example sequence predictions in the StarIntruders task. The encoder E converts observedpixels to a latent state s. The recurrent transition function T(s, a) predicts future latent states, and adecoder network D decodes states back to pixel space.
Figure 3: During training, in addition to predicting a ground truth sequence based on actions at, at+1...
Figure 4: An agent completing the training version of the StarIntruders task. Destroying an enemygenerates +1 reward, and destroying a human generates -1. A regularized model-based agent destroysfewer humans than a non-regularized model-based agent or a model-free agent, even in perturbedversions of the environment.
