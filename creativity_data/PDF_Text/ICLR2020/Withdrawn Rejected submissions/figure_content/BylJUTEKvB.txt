Figure 1: Top-1 classification accuracy vs. batch sizes per iteration.
Figure 2: Illustration of BN and the proposed Cross-Iteration Batch Normalization (CBN).
Figure 3: The effect of temporal window size (k) on ImageNet(ResNet-18) and COCO (Faster R-CNN with ResNet-50 and FPN)with #bs/GPU = 4 for CBN and Naive CBN. Naive CBN directly uti-lizes statistics from recent iterations, while BN uses the equivalent#examples as CBN for statistics computation.
Figure 4: Training and test curves for CBN, Naive CBN, and BN onImageNet, with batch size per GPU of 4 and temporal window sizek = 4 for CBN, Naive CBN, and BN-bs4, and batch size per GPUof 16 for BN-bs16. Thus, the plot of BN-bs16 is the ideal bound.
Figure 5: Results of different burn-in periods (in epochs) on CBN, with batch size per iteration of 4, onCIFAR-10 and COCO.
Figure 6: Comparison of gradients of statistics w.r.t. current layer vs. that w.r.t. previous layers on CIFAR-10.
