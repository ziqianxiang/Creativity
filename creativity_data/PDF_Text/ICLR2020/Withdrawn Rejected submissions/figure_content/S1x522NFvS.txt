Figure 1: Risk as a function of both (μo,μι) (left), and only μo (right) for μι = 2, σι = 1 andσ0 ∈ {0.1, 1, 3}When We fix μι, We can see in Figure 1 (right) that the risk as a function of μo can be well approxi-mated by a scaled and translated rectified linear function, as long as the variances are small enough.
Figure 2: Comparative illustration of OC-NN and unsupervised risk approximation: observationsare represented in the embeddings space just before the final linear layer; the hyperplane is definedby the parameters θ, and fθ(X) is the signed distance of the samples to the hyperplane. Duringtraining, the OC-NN tends to reduce the distance between the negative samples and the hyperplane,while our unsupervised loss tends to increase this distance for both negative and positive samples.
Figure 3: Accuracy as a function of the number of unsupervised training epochs on the syntheticdataset (left) and on the Wisconsin Breast Cancer dataset (right).
