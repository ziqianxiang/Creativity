Figure 1: Stacked Quantization Modules. Eachlevel uses its own loss and maintains its ownreplay buffer. Dotted lines indicate gradient isstopped in the backprop3.3	Stacked Quantization ModulesTo ensure adaptivity of the compression model, we adopt a Stacked Quantization Modules (SQM).
Figure 2: Left: Distribution of buffered samples for the Imagenet (top) and Lidar (bottom) ex-periments. We highlight that SQM’s adaptive buffer is flexible enough to choose different sampleproportions depending on the scenario. Right Top: Drift in the buffered lidar representations. RightBottom: Blockwise validation loss for lidar evaluationusing the standard split-minimagenet from Chaudhry et al. (2019), which yields 20 different tasksand 100 classes total. After all samples have been seen and stored as best as possible in storagesize C by Algorithm 1, we train a Resnet18 model (similar to the one used in Chaudhry et al. (2019)adjusted for larger input size) using the stored samples. We train with SGD and a learning rate of 0.1,with early stopping using a validation set. The storage size C is equivalent to 1000 uncompressedsamples. Results of this evaluation are shown in Table 2.
Figure 3: Top row are real uncompressed test set lidar scans. Rows two, three and four are recon-structions with compression rate 8, 16, and 32×. Regions of interest are highlighted in red. In theleft column, we note all compression levels retain the essential information, albeit some far wayobstacles are slightly deformed. In the right column, a thin obstacle is present in the first two levels,but absent in the third level.
Figure 4: Bottom row: random buffer reconstructions using Riemer et al. (2018). Middle row:random buffer reconstructions using SQM. Top row: corresponding original image. Columns areordered w.r.t their entry time in the buffer, from oldest to newest. All samples above were obtainedfrom the disjoint CIFAR-10 task, and are 12× smaller than their original image.
