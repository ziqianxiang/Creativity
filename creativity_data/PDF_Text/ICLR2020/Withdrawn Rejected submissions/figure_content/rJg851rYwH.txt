Figure 1: Test accuracy as a function of the number of filters k in the convolutional architecture ofTable 1; when training with vanilla SGD and DPSGD. Each point corresponds to multiple trainingruns on MNIST (left) or FashionMNIST (right). For both datasets, adding filters always improvesnon-private learning, whereas after an early point they are not beneficial to learning with privacy.
Figure 2: Test accuracy as a function of the privacy loss when training a pair of models with DP-SGD. The only difference between the two models is the activation function for their hidden layer:ReLU or tanh. All other elements of the architecture (number, type, and dimension of layers) andthe training algorithm (optimizer, learning rate, number of microbatches, clipping norm, and noisemultiplier) are identical. Results are averaged over 10 runs for each curve.
Figure 3: '2 norm of the first conv activations.
Figure 4: Colored lines show DP-SGDaccuracy for three “seed” random initiali-zations of a CIFAR-10 model. Coloredbands show accuracy range of 30 DP-SGDmodels using Mean Var initialization basedon per-layer parameter statistics in the cor-responding seed model. In all models, theprivacy ε at each epoch is identical; how-ever, Mean Var initialization substantiallyimproves the privacy/accuracy tradeoff.
Figure 5: Learning curves for DP-SGD and DP-Adam. Early on in training, DP-Adam convergesfaster to an accuracy that is within 1 point of its final accuracy, however DP-SGD increases moresteadily towards the end of training, thus both achieve comparable results. Given one of the datasets,the privacy budget ε for both models is identical at each epoch.
