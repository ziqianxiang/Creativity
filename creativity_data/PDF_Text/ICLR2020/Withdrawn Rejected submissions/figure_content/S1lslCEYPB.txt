Figure 1: Overview of the paper. Top row shows several KL divergence lower bounds for two probabilitydistributions P and Q. By substituting P = Pxy, Q = Pxpy, and defining f as a neural network, we obtaincorresponding MI estimators. n-DV and n-MINE are the proposed bound and its derived estimator. Furtherdetails are provided in the text.
Figure 2: Comparison of dual formations of η-DV and f -div in RKHS. Here r is an estimator for density ratiop/q and MMDφ(P, Q) = ∣∣Eχ〜pΦ(x) - Ey〜Qφ(y)∣∣. As can be seen, both duals have a relative entropy term,but the f -div bound does not impose the normalization constraint on the ratio, which biases the estimate, whileη-DV uses η as the Lagrangian multiplier to impose the constraint EQ [r] = 1 and ensure density normalization.
Figure 3: Performance of different MI estimators on synthetic GauSSian datasets. Top: MI estimation. Data WaSsampled from 2-, 10- and 20-dimensional Gaussian distributions with randomly generated means and covariancematrices. As we increase the data complexity, the difference between estimators decreases, although we observedthat η-MINE (or its convex extension) on average performed better than the baseline methods, converging to thetrue MI [red line] faster. Bottom: MIfor GAN regularization. Top row: unconditional GAN baseline fails atcapturing all 25 modes in the Gaussian mixture. Middle row: MI-regularized conditional GAN using DV-MINE(Belghazi et al., 2018) converges after 140K steps of the generator. We found this estimator to be sensitive to thehyper-parameters and unstable during training. Bottom row: MI-regularized conditional GAN using η-MINE;the model converges in 50K steps of the generator.
Figure 4: (a) Encoder architecture and classification accuracy (topi) on CIFAR-10 dataset for different pre-trained encoders. Each number represents test accuracy of the system trained by maximizing MI betweenfeatures from layers pointed by the corresponding arrows. Interestingly, the highest accuracy was obtained bypre-training encoder composed ofjust the first two convolutional layers (see (b) and (c) for details of this process).
Figure 5: (a) Jigsaw CE training. (b) Jigsaw MI train-ing. (c) ImageNet Classification CE training.
