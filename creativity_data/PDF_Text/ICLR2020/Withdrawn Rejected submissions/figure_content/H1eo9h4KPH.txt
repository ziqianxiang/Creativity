Figure 1: Empirical evaluation of the sum ofthe gaps from Theorems 1 and 2. The Lipschitzconstants supχ∈χ ∣∣Vf (X)Ilq (left: P = 2, right:p= ∞, 1/p+ 1/q= 1) were estimated by BFGS.
Figure 2: Comparison of λmax(G>G) and theRHS of (8), as upper bounds for the Lipschitz con-stant. Smaller values are tighter. 100 functionssampled in the same way as in Figure 1.
Figure 3:	Test accuracy under PGD attacks on the C&W approximation with '2 norm boundQooo8 6 4 2() Aoalnooe31O Gauss-Lip (PGD-Cw)* Par-MaXMin (PGD-Cw)A Inverse-UP (PGD-Cw)T-Par-ReLU (PGD-Cw)(*) Aoalnooes31O Gauss-Lip (PGD-Cw)-Ht-Par-MaxMin (PGD-Cw)A InverSe-LiP (PGD-Cw)-M-Par-ReLU (PGD-Cw)8°0°4°0°() Aoalnooe31-©—Gauss-Lip (PGD-Cw)* Par-MaXMin (PGD-cw)-A-InverSe-LiP (PGD-cw)-W-Par-ReLU (PGD-Cw)0.1	0.2	0.3	0.4	0.5	0.6
Figure 4:	Test accuracy under PGD attacks on the C&W approximation with '∞ norm boundmaxλmaχ(G(x)G(x)>) ≤ max∣3∣H=1 λmax(XC=1 GGG) ≤ L2,	(14)where G(X) = [Vf1(x),…，Vf10(x)] = [G>k(x, ∙),...,G>k(x, ∙)] with Gc := (gC,...,gd).
Figure 5: In the classical adversarial risk (5) the perturbation size at each point is at most r (blue),however with the variable-radius risk the expected perturbation size is at most r.
Figure 6: Suppose we use a polynomial kernel with degree 2, and f (x) = 2(v>x)2 for X ∈ B.
Figure 7: Comparison of efficiency in enforcing Lipschitz constant by various methodsExperimentsA.9 Efficiency of enforcing Lipschitz constant by different methodsThe six different ways to train SVMs with Lipschitz regularisation are summarized in Algorithm 1.
Figure 8: Test accuracy under PGD attacks on cross-entropy approximation with '2 norm bound∏J 60i40W 20O Gauss-Lip (PGD-Crossent)* Par-MaXMin (PGD-Crossent)A Inverse-LiP (PGD-crossent)X Par-ReLU (PGD-Crossent)0	0.1	0.2	0.3	0.4	0.5	0.6200 ball radius δ(a) MNISTO Gauss-Lip (PGD-Crossent)⅜ Par-MaxMin (PGD-Crossent)A Inverse-LiP (PGD-Crossent)P Par-ReLU (PGD-Crossent)0	0.1	0.2	0.3	0.4	0.5	0.6Q1 ball radius δ(b) Fashion-MNIST8°0°4°2°() Aoalnooe31
Figure 10: Gradients of targeted cross-entropy loss with respect to input images. One image per class(0-9) was sampled randomly from the test set, shown in the first row. A black pixel is encoded by 0,and a white pixel by 1. The 10 rows below show the gradient for different class targets. For example,row 7 column 0 shows the gradient of f7 evaluated at the image of digit 0 shown at the top row. Redand blue stand for positive and negative pixel values, respectively.
Figure 9: Test accuracy under PGD attacks on cross-entropy approximation with '∞ norm bound(*) Aoalnooes31A gradient-based attacker tries to decrease the targeted loss by following the negative gradient inFigure 10b, i.e., reduce the pixel value in red area and increase pixel value in blue area.
Figure 11: Gradients and perturbed images at each iteration in a 10-step PGD attack using (targeted) cross-entropy approximation, with the `2norm upper bounded by 6. Here the classifier is Gauss-Lip (σ = 2). The table in the bottom right presents the final predictions of our trainedGauss-Lip on the perturbed images.
Figure 12: Left: perturbed images at the end of 100-step PGD attack using (targeted) cross-entropyapproximation. Right: classification on the perturbed image given by the trained Gauss-Lip. Theyare quite consistent with human’s perception on the left images.
Figure 13: Perturbed images at the end of 100-step PGD attack using (untargeted) C&W approxi-mation. The 11 rows show the images after 0, 10, 20, ..., 100 steps of PGD.
Figure 14: (Another random trial) Left: perturbed images at the end of 100-step PGD attack using(targeted) cross-entropy approximation. Right: classification on the perturbed image given by thetrained Gauss-Lip. They are quite consistent with human’s perception on the left images.
