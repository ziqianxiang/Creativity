Figure 1: Contextual information is crucial for complex scene understanding tasks. To recognise the“boathouse”, one needs to consider the “boat” and the “water” next to it. Fully-connected message pass-ing models (a) are able to obtain this information, but are prohibitively expensive. Furthermore, they capture alot of redundant information (i.e.“trees” and “sky”). Locally-connected models (b) are more efficient, but missout on important context. Our proposed approach (c), dynamically samples a small subset of relevant featurenodes based on a learned dynamic sampling scheme, i.e. the learned position-specific random walk (indicatedby the white dashed arrow lines), and also dynamically predicts filter weights and affinities (indicated by uniqueedge and square colors.), which are both conditioned on the sampled feature nodes.
Figure 2: Overview of our proposed dynamic graph message passing network (DGMN). The neighbourhoodused to update the feature representation of each node (we show a single node with a red square) is predicteddynamically conditioned on each input. This is done by first uniformly sampling (denoted by “US”) a set ofS neighbourhoods around each node. Each neighbourhood contains K (e.g. 3 × 3) sampled nodes. Here, theblue nodes were sampled with a low sampling rate, and the green ones with a high sampling rate. Walks arepredicted (conditioned on the input) from these uniformly sampled nodes, denoted by the s symbol representingthe random walk sampling operation described in Sec. 3.3. DMCι,…,DMCS and βι,…,βs denotes Sdynamic message calculation operations and S message scaling parameters, respectively. The DMC module isdetailed in Figure 3. The symbol ㊉ indicates an element-wise addition operation.
Figure 3: Schematic illustration of the proposed dynamic message passing calculation (DMC) module. Thesmall red square indicates the receiving node whose message is calculated from its neighbourhood, i.e. thesampled K (e.g. 3 × 3) features nodes. The module accepts a feature map as input and produces its correspondingmessage map. The symbol * denotes group convolution operation using the dynamically predicted and positionspecific group kernels and affinities.
Figure 4: Visualisation of the nodes sampled via learning the random walks with our network. The red pointindicates a receiving node i. Different color families (i.e. yellow and blue) indicate the learned position specificweights and affinities of the sampled nodes. Different colors in the same family show the sampled nodes withdifferent sampling rates for the same receiving node.
Figure 5: Qualitative examples of the semantic segmentation on Cityscapes (the first row), and object detectionand instance segmentation on COCO (the second row).
Figure 6: Validation curves of APboxand APmask on COCO for Mask-RCNNbaseline, Non-local and the proposedDGMN. The number of training epochsis 90K.
Figure 7: Qualitative results of Dilated FCN baseline Yu & Koltun (2016) and DGMN (ours) on theCityscapes dataset.
Figure 8: Qualitative examples of the object detection task on the COCO validation dataset. The firstand third rows are the results from the Mask R-CNN baseline (Massa & Girshick, 2018; He et al.,2017). The second and fourth row are the detection results from our DGMN approach.
