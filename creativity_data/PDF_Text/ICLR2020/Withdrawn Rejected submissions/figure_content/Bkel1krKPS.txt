Figure 1: Datasets for visual reasoning. a: Sample from the RPM dataset (Bilker et al., 2012).
Figure 2: Overview of the ARNe network for abstract visual reasoning.
Figure 3: Sample efficiency: Test accuracy (a) and loss (b) after training on different numbersof samples (percent of original dataset size). Our implementation of WReN was used here (seeAppendix B).
Figure 4: Sum of selected activations of the last layer of the panel encoder CNN, that encodedpredominantly for shapes (maps 14, 24, 26, 29, 31) and for lines (maps 1, 2, 3, 4, 8, 12). Matricesshow complete sets of context panels and the correct choice panel highlighted in red.
Figure 5: Accuracy and Loss of the self implemented WReN (Santoro et al., 2018) model for β = 10on the neural PGM dataset. The development of both metrics include the progression of the panelchoices, additional auxiliary data which describes the setup of the PG-Matrices. In addition, theloss shows the overall sum.
Figure 6: Learning curves during training and validation of our implementation of MAC on theCLEVR dataset. Accuracy: Final learning rate values after 25 epochs are 97.83% and 99.11%for the validation and training set respectively. Loss: Calculated losses of the implemented neuralnetwork with respect to epochs. Final loss values after 25 epochs are 92.30 ∙ 10-3 and 22.90 ∙ 10-3for the validation and training set respectively.
Figure 7: WReN-MAC model. First, eight sequences of embeddings and gθ activations are gener-ated analogously to WReN. To interface a MAC-cell properly, the knowledge base is required. Aknowledge base is generated by the WReN CNN plus additional layers to match MAC’s requireddimensions. Every sequence passes 12 recurrent MAC-cells and the output unit sequentially. Thecomputation of scores equals the method incorporated in the WReN model.
