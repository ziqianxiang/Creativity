Figure 1: 7 interleaved posts are implicitly disentangled into 3 threads, and single sentence sum-maries are generated for each thread. Posts are outlined with colors corresponding the color of eachsummary.
Figure 2: Hierarchical encoder-decoder architecture.
Figure 3: A step in the thread-to-thread decoder. Figure 4: Hierarchical attention mechanism for ahierarchical encoder.
Figure 5: A comparison of running average training loss between seq2seq (pink) and hier2hier (gray)for Stack Exchange Hard corpus.
