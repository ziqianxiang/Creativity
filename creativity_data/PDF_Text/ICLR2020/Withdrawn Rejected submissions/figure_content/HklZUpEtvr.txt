Figure 1: (a) Supervised learning with matched references, (b) OT with absolute continuous mea-sures, and (c) OT having measures with singularities. CycleGAN corresponds to scenario (c).
Figure 2: Proposed cycleGAN architecture for accelerated MRI with 1-D downsampling patterns.
Figure 3:	Unsupervised learning results for accelerated MRI using pro-posed cycleGAN. The values in the corners are PSNR/SSIM values foreach image. Here, PSNR =	20 log 10 (n∣∣x*k∞∕kx — x*∣∣2) and SSIM =(2μxμχ* + cι)(2σχχ* + c2)∕(μX + μX* + cι)(σ2 + σX* + c2), where X and x* denote thereconstructed images and ground truth, respectively, n is the number of pixels, μχ is an averageof x, σX is a variance of X and σχχ* is a covariance of X and x*, and c1,c2 are two variables tostabilize the division.
Figure 4: Proposed cycleGAN architecture with a blur kernel for deconvolution microscopy. Here,GΘ denotes the CNN-based low-resolution to high-resolution generator. The blur generator is com-posed of a linear blur kernel h.
Figure 5: Comparison of reconstruction results by various methods: (a) blurred image measure-ments, (b) classical deconvolution method, (c) supervised learning, (d) conventional cycleGAN, and(e) proposed cycleGAN. The regions of interest (marked yellow) show enlargements of the areasmarked in yellow.
Figure 6: Proposed network architecture for (a) generator and (b) discriminator in accelerated MRI.
Figure 7: A modified 3D U-net architecture for our high-resolution image generator in the deconvo-lution microscopy problem.
Figure 8: Multi-PatchGANs discriminator architecture in the deconvolution microscopy problem.
Figure 9: Generalization performance comparison of various methods. The following parameterswere used for the training and inference: NA = 1.4, ni = 1.5, and σ = 3, m = 7. For the trainingdata, the wavelength was λ = 500nm. (a) Reconstruction result at the inference phase using the datawith λ = 400nm. (b) Reconstruction result at the inference phase using the data with λ = 500nm.
Figure 10: Two strategies for resolving ambiguities in the feasible solutions in an ill-posed inverseproblem. (a) Classical PLS approach using a close form prior distribution, and (b) our PLS approachusing an inverse mapping to define a prior.
