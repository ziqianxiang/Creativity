Figure 1: The model architecture of Meta Module Network: the lower part describes how the ques-tion is translated into programs and instantiated into operation-specific modules; the upper partdescribes how execution graph is built based on the instantiated modules.
Figure 2: Architecture of the Coarse-to-fine Program Generator: the left part depicts the coarse-to-fine two-stage generation; the right part depicts the resulting execution graph.
Figure 3: Illustration of the instantiation process for “Relate” and “Filter” functions.
Figure 4: Illustration of the Module Supervision process: the symbolic teacher executes the functionon the scene graph to obtain the bounding box b, which is then aligned with bounding boxes fromthe object detection model to compute the distribution guideline γ for supervision.
Figure 5: Visualization of the inferential chains learned by our model.
Figure 6: Illustration of the Visual Encoder described in Section. 2.1.
Figure 7: Illustration of the multi-head attention network used in the Meta Module.
Figure 8:	Illustration of the recipe embedder.
Figure 9:	The function definitions and their corresponding outputs.
Figure 10:	More examples on visualization of the inferential chains learned by our model.
Figure 11: More examples on visualization of the inferential chains learned by our model.
