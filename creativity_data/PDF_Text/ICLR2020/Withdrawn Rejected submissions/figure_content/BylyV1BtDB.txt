Figure 1: The left figure shows a synthetic dataset with a certain poisoning. Examples are dividedinto z = 0 (marked with circles) and z = 1 (crosses) as per a sensitive attribute z. The blue pointsindicate positive labels while the red points denote negative ones. For data poisoning, we flipped zvalues that reduce the model accuracy the most (similar to label flipping (Paudice et al., 2018), butspecialized for fairness). The right figure shows that poisoning significantly worsens the accuracy-fairness tradeoff (i.e., shifts to the left) of the Fairness constraints method (Zafar et al., 2017).
Figure 2: The architecture of FR-GAN.
Figure 3: Accuracy-fairness tradeoff curves.
Figure 4: The architecture of FR-GAN for equalized odds.
Figure 5:	Accuracy-fairness tradeoff curves for poisoned synthetic data with label flipping (7%).
Figure 6:	Comparison between Adversarial Debiasing (AD) and FR-GAN with small valida-tion set (0.5%) on synthetic data.
