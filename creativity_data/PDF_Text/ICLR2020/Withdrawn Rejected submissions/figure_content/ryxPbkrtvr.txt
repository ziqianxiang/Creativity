Figure 1: Decision boundary (NN and GBDT models on MNIST dataset) projected on a two-dimensional hyperplane. To choose which 2D hyperplane to project to, we run a decision-basedattack from two random initialization points, and use their converged perturbation directions as thevector to form the hyperplane. We then query the decision boundary on this hyperplane to plot thesefigures.
Figure 2: Distribution of converged adversarial perturbation norm on an MNIST image. The figuresshow that the final L2 distortion can be very different because of various starting directions. Figure2(a) and 2(b) show the histogram for final perturbations, and Figure 2(c) shows the converging curveof Sign-OPT attack on a neural network model on MNIST dataset.
Figure 3: Illustration of the effect of Successive Halving and TPE resampling. Note that Figure 3(b)only exhibits part of the curve to show the effect of TPE.
Figure 4: Illustration of a possible boundary distribution and attack steps on it. Starting from differ-ent directions, We conduct cutting and resampling during the middle steps. The directions that arenot promising are cut to save computational cost, and the directions that reach lower error value willbe expanded to encourage exploring. This figure also shows that the boundary can be very unsmoothand contains lots of local optimal points on the surface.
Figure 5: Number of starting directions vs Final L2 distortion. Since we will run multiple times oneach setup to reduce variance, the red line shows the average distortion and the blue area shows thestandard deviation.
Figure 6: Perturbation vs Attack Success Rate (ASR).
