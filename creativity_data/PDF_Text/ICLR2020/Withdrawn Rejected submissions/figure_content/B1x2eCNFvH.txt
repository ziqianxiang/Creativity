Figure 1: Schematic of the Local Label Propagation (LLP) method. a.-b. We use deep convolu-tional neural networks to simultaneously generate a lower-dimensional embedding and a categoryprediction for each input example. c. If the embedding of the input (denoted by ★) is unlabeled, Weidentify its close labeled neighbors (colored points), and infer *,s pseudo-label by votes from theseneighbors, with voting weights jointly determined by their distances from ★ and the density of theirlocal neighborhoods (the highlighted circular areas). d. The pseudo-labels thereby created (coloredpoints) come equipped with a confidence (color brightness), measuring how accurate the pseudo-labelis likely to be. The network in b. is optimized (with per-example confidence weightings) so that itscategory predictions match the pseudo-labels, while its embedding is attracted (q) toward otherembeddings sharing the same pseudo-labels and repelled (Z) by embeddings of other pseudo-labels.
Figure 2: a. MDS embeddings of 128-D embedding outputs on 100 random images from each offive random ImageNet categories, from the beginning to the end of LLP training. Larger points withblack borders are images with known labels. b. Trajectory of cross-category average of L2-normsof category-mean embedding vectors. Sudden changes are due to learning rate drops. c. Histogramof the L2-norm metrics for each category, for fully-trained ResNet-18 and ResNet-50 networks. d.
Figure 3: Density weighting analysis. Orange color is for “NoDW” model and blue color is for LLPmodel. a, b. Scatter plot of ImageNet classes. Each dot represents one class. For class i, X-axis is Diand Y-axis is Qi . Both models are fully trained. c. Histogram plot of classes showing the distributionof Qi. d. The trajectory of Pearson correlation between {Di} and {Qi} during training.
