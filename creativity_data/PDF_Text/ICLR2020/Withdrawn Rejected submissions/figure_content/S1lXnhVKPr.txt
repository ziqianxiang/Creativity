Figure 1: Epoch loss for the non-identical case. VRL-SGD converges as fast as S-SGD, and LocalSGD, EASGD converge slowly or even cannot converge.
Figure 2: Epoch loss for the identical case. All of the algorithms have a similar convergence rate.
Figure 3: Logarithm of distance to the global minimum for different b and communication period k.
Figure 4: Logarithm of variance among workers for different b and communication period k.
Figure 5: Epoch loss for the non-identical case. We set k = 10 for LeNet, k = 25 for TextCNN andk = 10 for Transfer Learning.
Figure 6: Epoch loss for the non-identical case. We set k = 40 for LeNet, k = 100 for TextCNNand k = 40 for Transfer Learning.
