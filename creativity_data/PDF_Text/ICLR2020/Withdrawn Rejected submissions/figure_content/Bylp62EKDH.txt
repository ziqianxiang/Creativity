Figure 1: The triplet scatter diagram plots a triplet as a point defined by the Anchor-Positive sim-ilarity Sap and the Anchor-Negative similarity San . (left) Points below the diagonal correspond totriplets that are ”correct” in the sense that the anchor image could get the correct label because thesame class example is closer than the different class example. Triplets along the top of the diagramare candidates for hard-negative mining, triplets along the right edge are candidates for easy-positivemining, and triplets mapped near but below the diagonal are candidates for semi-hard triplet mining.
Figure 2: First two rows: numerical simulation for ∆Sap, ∆San, ∆Satoptal, ∆Satontal in equation 9,10, 11 and 12 of γ = 0.5 and p = 0.4, 0.8. Thrid row: Vector field of γ = 0.5 andp = 0.4, 0.8.
Figure 3: The locations of dots moves top-right, top-left, bottom-left and bottom-right.The bluecolor represents the initial phase iterations and the red color represents the later phase iterationsEquation 1. Then we calculate Recall@K as the measurement for retrieval quality. In the CUB,CAR and SOP datasets, both the query set and gallery set refer to the testing set. During the queryprocess, the top-K retrieved images exclude the query image itself. In the In-Shop dataset, the queryset and gallery set are predefined by the original paper.
Figure 4: Recall@1 accuracy vs group size n on CUB, CAR, SOP and In-shop datasets with 1st/2ndorder EPHN/EPSHNDataset	CUB	CAR	SOP	In-shopMethod	R@1 R@2 R@4	R@1 R@2 R@4	R @1 R @10 R @100	R@1 R@10 R@20HTL512	57.1 68.8 78.7	81.4 88.0 92.7	74.8 88.3^^941-	--	-ABE512	60.6 71.5 79.8	85.2 90.5 94.0	76.3 88.4	94.8	87.3 96.7	97.9DREML576	63.9 75.0 83.1	86.0 91.7 95.0	--	-	--	-FastAP512	---	---	76.4 89.0	95.1	90.9 97.7	98.5EPHN-Ist512	64.9 75.3 83.5	82.7 89.3 93.0	78.0 90.6	96.3	87.1 96.9	97.9EPHN-2nd512	65.2 753 82.9	83.2 89.2 93.2	78.8 90.8	96.3	89.0 96.9	97.8Table 1: Retrieval Performance on the CUB, CAR, SOP and In-shop datasets comparing to the bestreported results for more complex approaches and/or ensembles. All test are trained with ResNet50negative mining (EPSHN) and easy-positive hard-negative mining (EPHN) for both 1st order and2nd order loss functions on CUB, CAR, SOP and In-shop dataset. Figure 4 shows a another gap ofL2nd with EPHN and EPSHN on CUB, CAR and In-shop dataset for most choices of the group sizen of elements per class in each batch. This result indicates that both Problem 1 and 2 are importantfor metric learning.
Figure 5:	Numerical simulation for ∆Sap, ∆San, ∆Satoptal and ∆Satontal change of L1st , Lv andL2nd with γ = 0.2, 0.5, 0.8 and p = 0.4, 0.8.
Figure 6: Triplet scatter plots after training epoch 0,5,10,15,40(epoch 0 represents the output ofimagenet initialization). 1st row: 1st order EPHN with n = 2;2nd row: 1st order EPHN withn = 8;3rd row: 2nd order EPHN with n = 2;4th row: 2nd order EPHN with n = 8dataset after each epoch training. We observe the dynamic movement to the singularity at the loca-tion (1,1) results for EPHN for n = 2. The L2nd loss for EPHN never has this problem because theweighted gradient approach more effectively separates hard negative pairs early on in the optimiza-tion.
