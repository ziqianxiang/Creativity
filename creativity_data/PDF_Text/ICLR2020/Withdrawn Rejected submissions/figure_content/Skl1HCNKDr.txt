Figure 1: Density estimation on 2D toy data. We show that we can accurately capture these densitieswith few visual artifacts. We also show samples generated using our generative model training.
Figure 2: The influence of ση on sample generation. We observe that the smoothed sampled densityis close to the training density. However, for large ση , the sampled density without smoothing canbe quite different from the true density because inversion of Gaussian smoothing becomes ill-posed.
Figure 4: Results of our generator training algorithm on 32×32 images from the celebA dataset (Liuet al., 2015)by a sampling algorithm using annealed Langevin dynamics (ALD) as described by Song and Er-mon (Song & Ermon, 2019). We refer to this method as UNET+ALD. We also implemented amodel based on our approach called DDE+ALD, where we used our DDE network. While ourtraining loss is identical to the score matching objective, the DDE network outputs a scalar andexplicitly enforces the score to be a conservative vector field by computing it as the gradient of itsscalar output. ALD+DDE uses the spatial gradient of the DDE for sampling with ALD (Song &Ermon, 2019), instead of our proposed direct, one-step generator. We observe that DDE+ALD ismore stable compared to the UNET+ALD baseline, even though the UNET achieves a lower lossduring training. We believe that this is because DDEs guarantee conservativeness of the distributiongradients (i.e. scores), which leads to more diverse and stable data generation as we see in Figure 5.
Figure 5: Mode-collapse experiment results on Stacked-MNIST as a function of training iterations(for discriminator or DDE). (a) Number of generated modes per batch of size 512. (b) Reverse KL-divergence between the generated and the data distribution in the logarithmic domain. All methodsuse the DCGAN architecture with the same capacity except for UNET+ALD.
Figure 6: Fashion-MNIST results using our generator training algorithm (a). Samples from the realdataset (b). Interpolated samples using our Generator (c).
