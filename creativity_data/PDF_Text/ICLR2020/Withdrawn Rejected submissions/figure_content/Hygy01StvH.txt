Figure 1: Histogram of the values in the weight matrix and the convolutional layers of a trainedWGAN-GP with a latent space specific dimensionality for CIFAR-10 and CelebA datasets. Notice,that the weights share the same characteristics as if they were drawn from a normal distribution.
Figure 2: Loss surface around a data point of the generator of a WGAN-GP trained on CelebA.
Figure 3: Impact of the latent space on the AE and GAN reconstructions loss on CIFAR-10 andCelebA. The AE acts as a lower bound for the GAN reconstruction loss and the reconstruction lossdecreases for both the AE and the GAN generator with increasing latent space dimensions.
Figure 4: FID (Heusel et al. (2017)) curve for different latent spaces (lower is better). Increasingor decreasing the latent space does not result in a noticeable difference in the quality metric for theWGAN-GP, but it does for the AE.
Figure 5: The first columns show the original images. As we increase the latent space of the autoen-coder the image quality increasing. The GAN reconstructions are of high perceptual quality evenfor low dimensional spaces, but correspond to other people as has been observed by Webster et al.
Figure 6: Impact of translation on the reconstruction ability of GAN networks. Notice, that byincreasing latent space dimension, the generator network is able to reconstruct translations with asimilar precision as the original images.
Figure 7: Left & Right: Reconstruction of CIFAR images in a WGAN-GP model trained on CelebAimages. As the latent dimensionality is increased, the reconstruction is improved for both CIFAR-10and CelebA. Right: With a small latent space, the face image features are retained, while with a largelatent space, the CIFAR-10 images are faithfully reconstructed.
Figure 8: Reconstruction error of uniform noise images between [-1, 1] using a generator networktrained on CelebA images. With smaller latent spaces, it is still possible to see some key facefeatures. A larger latent space manages to produce better reconstructions.
Figure 9: Mnist GAN and AE reconstructions in (a). Visual quality metrics are not really applicableon MNIST data so in (b) the reconstructed GAN images are used to train a LeNet to classify onMNIST and is compared to training on the true training set.
Figure 10: The distribution of the reconstructions without projections.
Figure 11: ROC Curve of training on CelebA and testing the reconstruction error of the NN onCIFAR-10 and CelebA. The desired behavior would be in the top left corner. The points correspondto a setting with a specific latent space. As the latent space decreases the error goes down. Thepoints correspond to the target latent space size as is shown in Fig. 7GT 10	20	50	100	200	500	1000dim(z)5	1。 ZU SU 13 4UU 53	13。dim(z)(a) AE(b) WGAN-GPFigure 12: The first column are the actual images. As we increase the latent space of the autoencoderwe can see the image quality increasing. The same cannot be said about the GAN reconstructions.
Figure 12: The first column are the actual images. As we increase the latent space of the autoencoderwe can see the image quality increasing. The same cannot be said about the GAN reconstructions.
