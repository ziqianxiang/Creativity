Figure 1: MANAS with single cell. Betweeneach pair of nodes, an agent Ai selects action a(i)according to ∏(i). Feedback from the validationloss is used to update the policy.
Figure 2: Comparing MANAS, random sampling and DARTS (Liu et al., 2019) on 8 and 14 cells.
Figure 3: Regret for the Gaussian Squeeze Domain experiment with 100 agents, 10 actions, μ = 1,σ= 10.
Figure 4: Theoretical bound for the MANAS cumulative regret (2N T K log K; see Appendix D.2)and the observed counterpart for the Gaussian Squeeze Domain experiment with 100 agents, 10actions, μ = 1, σ = 10.
