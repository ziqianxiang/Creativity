Figure 1: Comparison of running time of differentdata valuation algorithms. (a) is implemented ona machine with 2.6GHz CPU and 32GB memoryand (b) is implement on a machine with 1.80GHzand 32GB memoryRandom The random baseline does not differentiate between different data’s value and just randomlyselects data points from training set to perform a given task.
Figure 2: Detecting noisy labels. We examine the label for the training points with lowest valuesand plot the fraction of mislabeled data detected changes with the fraction of training data checked.
Figure 3: Pattern-based watermark removal. We examine the label for the training points withlowest values and plot the fraction of watermarks detected with the fraction of training data checked.
Figure 4: Instance-based watermark removal. We examine the label for the training points withlowest values and plot the faction of watermarks detected with the fraction of training data checked.
Figure 5: (a-b) Data summarization. We remove low-value points from the ground training set andevaluate the accuracy of the model trained with remaining data. (c-d) Active data acquisition. Wecompute the data values for a small starting set, train a Random forest to predict the values of newdata, and then add the new points with highest values into the starting set. We plot the model accuracychange when combining the starting set with more and more new data added according to differentvalue measures.
Figure 6: (a-b) We remove high-value points from the ground training set and evaluate the accuracyof the model trained with remaining data.
Figure 7: (a) Examples of pattern-based watermarks. Specifically, after an image is blended with the“TEST” pattern, it is classified as the target label, e.g, an “automobile” on CIFAR-10. (b) Example ofinstance-based watermarks, which are typically chosen as some out-of-distribution data with specificassigned labels.
