Figure 1: The proposed RL-LIM method. White blocks represent fixed (not learnable) models, andgrey blocks represent learnable (trainable) models. Stage 0: Black-box model training. Stage 1:Auxiliary dataset construction. Stage 2: Interpretable baseline training. Stage 3: Instance-wiseweight estimator training. Stage 4: Interpretable inference.
Figure 2: Synthetic dataset results. Mean absolute weight difference (AWD) with 95% confidenceintervals (of 10 independent runs) on three synthetic datasets. X-axis: Distance from the boundarywhere the local dynamics change, such as X10 = 0 for Syn1 (in percentile), Y-axis: AWD (thelower, the better). We exclude LIME in these graphs due to its poor performance in terms of AWD(it is higher than 1.6 in all distance regimes for all three synthetic datasets).
Figure 3: Fidelity & average selection probability of training instances as a function of the numberof selected samples on three synthetic datasets. X-axis: Î», Y-axis: LMAE and average selectionprobability of training instances. LMAE is Local MAE - lower is better.
Figure 4: Qualitative interpretability results. The analyses of feature importance (derived by RL-LIM) for 5 types of subgroups in Adult Income dataset: (a) Age, (b) Gender, (c) Marital status, (d)Race, (e) Education. The color represents the feature importance for each subgroup.
Figure 5:	Learning curves of RL-LIM on three synthetic datasets. X-axis: The number of iter-ations on instance-wise weight estimator training, Y-axis: Rewards (LMAE of baseline (globallyinterpretable model) - LMAE of RL-LIM), higher the better.
Figure 6:	AWD performances in terms of the number of training samples used to train three models(RL-LIM, STE, Random) - Lower the better.
Figure 7: (a) Instance-wise weight distributions - Syn1, (b) Instance-wise weight distributions -Syn2, (c) Instance-wise weight distributions - Syn3, (d) Average instance-wise weights of trainingsamples in terms of distance from the probe sample (percentile)As can be seen in Fig. 7 (a)-(c), the instance-wise weights have quite skewed distribution. Somesamples (e.g. with average instance-wise weights above 0.5) are much more critical to interpretingthe probe sample than many others (e.g. average instance-wise weights below 0.1)In Fig. 7 (d), there is a clear trend that the samples near the probe sample have higher averageinstance-wise weights, which shows that RL-LIM learns the meaningful distance metrics to measurethe relevance while interpreting the probe samples. This trend is consistent across all three syntheticdatasets.
