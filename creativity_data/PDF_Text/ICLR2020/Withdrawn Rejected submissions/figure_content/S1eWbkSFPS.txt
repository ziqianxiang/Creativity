Figure 1: Random walk propagation procedure. From left to right are step-0, step-1, step-2, and step-infinite. The values in each node indicate the distribution of a random walk. In the leftmost picture,only the starting node has a value of 100, and all other nodes are initialized to zero. As the numberof steps increases, values spread throughout the graph and converge to some extent.
Figure 2:	Schematic process of Graph Step Mixture. The procedure consists of three stages: (1st-stage) input passes the FC-layer, (2nd-stage) adjacency matrix is multiplied then concatenated, (3rd-stage) the final output is produced.
Figure 3:	Conceptual scheme of neighborhood aggregation for three steps in conventional graphneural networks (a) and GSM which uses mixture of random walks (b).
Figure 4: Effect of the step size on model performance on Cora.
Figure 5: Accuracy comparison for various label rates according to step size.
Figure 6: Inference time of various models as the step size increases for Cora dataset.
Figure 7: t-SNE plot of the last hidden layer trained on the Cora dataset.
Figure 8: Visualization of attention distribution.
