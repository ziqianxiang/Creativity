Figure 1: The pipeline of group representation learning with our DDL. Given a base feature extractmodel, We first compute the DDR score for each training element and then train a light-weightdiscriminability distillation network (DDNet) to distill it. During testing, the DDNet will predictdiscriminability for each element in the test set.
Figure 2: The formulation of discriminability distillation regulation. It is the ratio of element featuredistance with its class centroids and the hardest-negative class,s. After training the base model withclassification task, element features from the same class are projected to hyperspace tightly in orderto form a clear decision boundary. While the outliers who lie far away from its centroids or closerto other classes are of low discriminability.
Figure 3: The pipeline of the test stage of DDL. For a set of elements, we first predict DDR scoreby the trained-well DDNet for each element. Then the feature extracted by the base model willbe weighted aggregation to form the group representation. To achieve accuracy and computationconsumption trade-off, a top-K filter can also be applied to select the most discriminative elementsand only extract features and aggregate with them.
Figure 4: The visualization results of discriminability for images of Template ID 17762 and 16800from IJB-C dataset.
Figure 5: Visualization discrimiability of frames from different videos.
Figure 6: Visualization discrimiability of frames from one video.
