Figure 1: Results on finite samples from a Gaussian distribution of GANs trained with different gra-dient penalties and our method. (blue datapoints represent real samples and red datapoints representgenerated samples) (a).(e) GAN with no GP, iter. 100,000 and 200,000. (b).(f) GAN-0Gp-sample,iter. 100,000 and 200,000. (c).(g) GAN-0Gp-interpolation, iter. 100,000 and 200,000. (d).(h) GAN-0Gp-sample with our method, iter. 100,000 and 200,000.
Figure 2: Evolution of our method on a mixture of 8 Gaussians dataset. (a) iter. 0. (b) iter. 100,000.
Figure 3: Inception score and FID on CIFAR-10 of GAN-0GP-sample and GAN-0GP-sample withour method6.2	Real world dataTo test our method on real world data, we compare our method with GAN-0GP-sample on CIFAR-10(Antonio et al. (2008)), CIFAR-100 (Antonio et al. (2008)) and a more challenging dataset ImageNet(Russakovsky et al. (2015)) with ResNet-architectures similar with that in Mescheder et al. (2018).
Figure 4: Inception score and FID on CIFAR-100 of GAN-0GP-sample and GAN-0GP-sample withour method(a)Figure 5: Losses of discriminator (not including regularization term) and generator on CIFAR-10of GAN-0GP-sample and GAN-0GP-sample with our method(b)measures. For Inception score, we follow the guideline from Salimans et al. (2016). The FIDscore is evaluated on 10k generated images and statistics of data are calculated at the same scale ofgeneration. Better generation can be achieved with higher inception score and lower FID value. Themaximum number of iterations for CIFAR experiment is 500k, while for ImageNet is 600k becauseof training difficulty with much more modes.We use the code from Mescheder et al. (2018).
Figure 5: Losses of discriminator (not including regularization term) and generator on CIFAR-10of GAN-0GP-sample and GAN-0GP-sample with our method(b)measures. For Inception score, we follow the guideline from Salimans et al. (2016). The FIDscore is evaluated on 10k generated images and statistics of data are calculated at the same scale ofgeneration. Better generation can be achieved with higher inception score and lower FID value. Themaximum number of iterations for CIFAR experiment is 500k, while for ImageNet is 600k becauseof training difficulty with much more modes.We use the code from Mescheder et al. (2018).
Figure 6: Inception score and FID on ImageNet of GAN-0GP-sample and GAN-0GP-sample withour methodtrapped in a local region and has a better generalization. The losses of discriminator and generatoron CIFAR-100 and image samples can be found in Appendix D.
Figure 7: Losses of discriminator (not including regularization term) and generator on CIFAR-100of GAN-0GP-sample and GAN-0GP-sample with our method(b)Figure 8: Losses of discriminator (not including regularization term) and generator on ImageNet ofGAN-0GP-sample and GAN-0GP-sample with our method(a)(b)Figure 9: Generation of our method on a mixture of 25 Gaussians dataset and swissroll datatset.
Figure 8: Losses of discriminator (not including regularization term) and generator on ImageNet ofGAN-0GP-sample and GAN-0GP-sample with our method(a)(b)Figure 9: Generation of our method on a mixture of 25 Gaussians dataset and swissroll datatset.
Figure 9: Generation of our method on a mixture of 25 Gaussians dataset and swissroll datatset.
Figure 10:	Image generation of CIFAR-10.
Figure 11:	Image generation of CIFAR-100.
Figure 12: Image generation of ImageNet.
