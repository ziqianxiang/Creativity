Figure 1: Comparison of test RMSE in the presence of cold startusers on the ML-100K dataset. The x-axis corresponds to the num-ber of the cold start users Nc = 50, 100, . . . 500. Red, blue andgreen correspond to DMF, SGMC and SGMC-Z methods respec-tively as also shown in the legend. Different shapes of the markersindicate different number of maximum ratings (Nr = {1, 5, 10})available per cold-start user.
Figure 2: Ablating Pr = PC and μr = μc of SGMC on the ML-100K dataset. The rest of theparameters were set to the ones reported in Table 5. Green X denotes the baseline from Table 1.
Figure 3: Ablating ρr, ρc and μr, μc of SGMC-Z on the ML-100K dataset. The rest of the parameterswere set to the ones reported in Table 5.
Figure 4: Effect of overparametrization: SGMC (left) and DMF (right). x-axis indicates the values ofpmax , qmax , and y-axis presents the RMSE. Green X denotes the baseline from Table 1.
Figure 5: Synthetic Movielens-100k. Top-left: Full matrix. Top-right: singular values of the fullmatrix. Bottom left & right: items & users graph. Both graphs are constructed using 10 nearestneighbors.
Figure 6: Synthetic Netflix. Top-left: Full matrix. Top-right: singular values of the full matrix.
Figure 7: Reconstruction error (on the test set) vs. scale of initialization. For each method weinitialized P , Q with αI . SGMC consistently outperforms DMF for any initialization.
Figure 8: In these experiments we generated matrices using the synthetic Netflix graphs to testthe dependence of SGMC and DMF on the rank and on the number of training samples. Left:Reconstruction error (on the test set) vs. rank. As the rank increases, the reconstruction errorincreases, but it increases slower for SGMC than for DMF. For the training set we used 15% of thepoints chosen at random (same training set for all experiments). Right: Reconstruction error (onthe test set) vs. size of the sampling set, for a random rank 10 matrix. As we increase the numberof samples, the gap between DMF and SGMC reduces. Still, even when using 30% of the samples,SGMC performs better for the same number of iterations. In all experiments we used the followinghyperparameters: μr = μc = 0.001, Pr = Pc = 0.001, maxiter = 8 X 106 .
