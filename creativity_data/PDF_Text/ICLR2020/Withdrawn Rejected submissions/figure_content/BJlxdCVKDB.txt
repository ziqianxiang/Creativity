Figure 1: A simple 5 x 5 Gridworld example to showcase the policies learned by Viper and MoET.
Figure 2: Visualization of DRL, Viper, and MOETh policies (up), and their differences (down) onMountaincar environment. Upper 3 images visualize policies, where left, neutral, and right actionsare shown in green, yellow, and blue, respectively. Lower left 2 images visualize mispredictionscompared to DRL agent shown in red, where more critical mispredictions are shown with higherintensity. Finally, image in the bottom right shows difference in mispredictions between Viper andMOETh (blue regions is where MOETh is predicting correctly but Viper does not, and red theopposite, and color intensity denotes how critical the action is).
Figure 3: Verification times.
Figure 4: Visualization of gating function for different experts.
