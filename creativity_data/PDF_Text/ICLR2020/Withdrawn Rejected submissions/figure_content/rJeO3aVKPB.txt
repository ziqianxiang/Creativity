Figure 1: The training pipeline for ResNet-50 on ImageNet, which is representative of many large-scale computer vision programs.
Figure 2: The overlapping computation time for pipeline stages upstream and downstream of the dataechoing insertion point, if stages are executed in parallel and tupstream = 2tdownstream.
Figure 3: Data echoing with echoing factor 2 either reduces or does not change the number of freshexamples needed to reach the target out-of-sample performance. Dashed lines indicate the expectedvalues if repeated examples were as useful as fresh examples.
Figure 4: Example echoing before augmentation can reduce training time for ResNet-50 on ImageNet.
Figure 5: Example echoing reduces the number of fresh examples needed for Transformer on LM1Bfor echoing factors up to (at least) 16. Dashed lines indicate the expected values if repeated exampleswere as useful as fresh examples.
Figure 6: As the batch size increases, the performance of batch echoing relative to the baseline eitherstays the same or improves, while for example echoing it either stays the same or gets worse. Dashedlines indicate the expected values if repeated examples were as useful as fresh examples.
Figure 8: Individual trials that achieved the best out-of-sample performance during training.
Figure 7: Data echoing performs better with more shuffling. Dashed lines indicate the expectedvalues if repeated examples were as useful as fresh examples.
Figure 9:	The best training curves for experiments in Section 3.1. Solid lines represent the mean overthe best trial from 5 independent hyperparameter searches, and shaded regions represent one standarddeviation. The dashed line represents the target metric value.
Figure 10:	The best training curves for experiments in Section 3.2. Solid lines represent the meanover the best trial from 5 independent hyperparameter searches, and shaded regions represent onestandard deviation. The dashed line represents the target metric value.
Figure 11: The best training curves for experiments in Section 3.3. Solid lines represent the meanover the best trial from 5 independent hyperparameter searches, and shaded regions represent onestandard deviation. The dashed line represents the target metric value.
Figure 12:	The best training curves for experiments with Transformer on LM1B in Section 3.4. Solidlines represent the mean over the best trial from 5 independent hyperparameter searches, and shadedregions represent one standard deviation. The dashed line represents the target metric value.
Figure 13:	The best training curves for experiments with ResNet-50 on ImageNet in Section 3.4.
Figure 14:	The best training curves for experiments with batch echoing in Section 3.5. Solid linesrepresent the mean over the best trial from 5 independent hyperparameter searches, and shadedregions represent one standard deviation. The dashed line represents the target metric value.
Figure 15:	The best training curves for experiments with example echoing in Section 3.5. Solidlines represent the mean over the best trial from 5 independent hyperparameter searches, and shadedregions represent one standard deviation. The dashed line represents the target metric value.
