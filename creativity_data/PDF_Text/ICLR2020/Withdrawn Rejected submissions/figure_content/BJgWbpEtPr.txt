Figure 1: One-way few-shot network structure and prototype calculation3.2	One-way normal prototypical modelsAs described, prototypical networks only take into account the centroid of a class’s support exam-ples. This is sufficient when all classes can be assumed to be roughly on the same semantic level andtherefore have similar feature distribution widths. However, this may not always be true (e.g. wemay encounter cases where the model attempts to distinguish between queries of the class “Bobtailcat” and queries of the class “Insect”). This problem becomes even more prevalent for the one-classcase, as unseen classes may have wider or narrower distributions than unseen examples, and we donot have a basis for comparison defined by other classes.
Figure 2: Normal prototype example - Support examples and estimated class distribution in yellow,null class distribution in grey; positive query in orange, negative query in red4	Experiments and results4.1	Data and experimental designWe first test our approach on a well-known toy data set for one- or few-shot learning: The Omniglotimage data set [Lake et al. (2015)]. This data set contains 1623 characters hand-drawn 20 timesby Amazon Mechanical Turk1 annotators. These characters come from 50 alphabets; a 30-20 splitof the alphabets is suggested for training and validation. Per episode, we use 1 to 19 instances of acharacter as support examples, and either one of the remaining examples or a random other characteras the query. As commonly done in literature, we also test the trained models on an unmatched dataset: The MNIST handwritten digit database [LeCun et al. (1998)].
Figure 3: Accuracies of models implementing the one-way problem with two classes(a) Omniglot(b) MiniImageNetFigure 4: Accuracies of one-way prototypical modelson the Omniglot data set, and between .59 (one support) and .74 (20 supports) on MiniImageNet.
Figure 4: Accuracies of one-way prototypical modelson the Omniglot data set, and between .59 (one support) and .74 (20 supports) on MiniImageNet.
Figure 5: Accuracies of one-way normal prototypical modelsappears to be important (we observe the same effect when simply adding another batch normal-ization layer to the standard model). With this model, accuracy on Omniglot rises to .969 for onesupport example, and to .98 for 19. On the more complex MiniImageNet data, accuracy becomes.64 for one support example and .8 for 20. For comparison, this re-ordering was also tested on thetwo-way prototypical model; no significant differences in the results were found when compared tothe original layer ordering.
Figure 6: Average training time per epoch4.5	Experiment D: Training timeAs an additional experiment, we analyze the training times of our various models on an NVIDIAVolta V100 with 16GB RAM. This is calculated by averaging the training times of the last threeepochs of each model. Figure 6 displays the results on Omniglot and MiniImageNet. As mentionedabove, each epoch consists of 32,000 episodes, and we choose the configuration with 5 supportexamples for comparison. The first two bars in each group correspond to the two-way matchingand prototypical models from experiment A; their training times are roughly in the same range.
