Figure 1: The CNN-DCN architecture of VGG16.
Figure 2: Training curve.
Figure 3: Reconstruction loss.
Figure 4: Reconstructions for CDk .
Figure 6: Left: Reconstruction images for the CD1 architecture with various network width. Right:Architecture of CD1(C,D). (Zoom in for details)4.2	On number of random channelsWe investigate the reconstruction quality on the number of random channels using the rrVGG CD1(Conv1-DeConv1) architecture. For simplicity, for each network instance we use the same number ofchannels in all layers except the output layer. We vary the number of random channels from 4, 8 upto 2048, and for each number of channels, we generate 30 rrVGG Conv1-DeConv1 networks and allrandom weights are in N(0, 0.1) distribution. For input images we randomly pick 50 samples fromthe ImageNet validation set.
Figure 7: Statistics on SSIM for rrVGG Conv1-DeConv1 (a,b) and for rrVGG Conv1_1-DeConv1_1 (c).
Figure 8: Reconstructions on rrVGG Conv1-DeConv1 networks (Evaluated on SSIM). Note thatwe transform the reconstructed colored-image to grey-scale for the ease of comparing the structuralsimilarity.
Figure 9: Style transfer from several rrVGG models. Each model has the same architecture butdifferent random weights.
Figure 10: Training loss for the Conv2-DeConv2 architecture.
Figure 11: Comparison on the generalization error.
Figure 12: (Zoom in for details.) Reconstructions for representations of different convolutionallayers of rwVGG and rwAlexNet.
Figure 13: (Zoom in for details.) Reconstructions for representations of rwVGG Conv2 in variousrandom distributions.
Figure 14: OvervieW of style transfer on rrVGG (random convolution and random decomvolution).
Figure 15: Style Transfer results ComparisonAs for the stylization effectiveness, we compared our results with Gatys et al. Gatys et al. (2016)and Ulyanov et al. Ulyanov et al. (2017b). In Fig. 15, rrV GG1 and rrV GG2 columns denote thestylization results acquired from our framework, applying two different rrVGG models. As shown inFig. 15, our stylization results are competitive to other well-trained approaches. Focused on rrV GG1column, our stylized result is inclined to extract more features from the style image and slightlyweaken the representation of content image. Since we utilize rrVGG CNN and DCN to complete thetransformation between feature space and image space, some content information is possible to belost during the reconstruction process. Despite that, our approach is still capable of generating highquality stylized images.
Figure 16: Detailed results for the rrVGG style transfer. Each column represents the ratio betweenstyle and content during the optimization phase.
Figure 17: Style transfer from several rrVGG models. Each model has the same architecture butdifferent random weights.
