Figure 1: A diagram depicting one step of the diffusion process modeled by the variational diffusionautoencoder (VDAE). The diffusion and inverse diffusion maps ψ, ψ-1, as well as the covariance Cof the random walk on MZ , are all approximated by neural networks.
Figure 2: Reconstructed images from the rotating bulldog example plotted in the latent space ofVDAE (left), Spherical VAE (SVAE, left-middle) and VAE (right-middle), and GAN (right)on each patch, which allows one to borrow approximation results from the theory of wavelets onspaces of homogeneous type. The proof also crucially uses the bi-Lipschitz property of the diffusionembedding Jones et al. (2008). The key insight of Theorem 1 is that, because of the bi-Lipschitzproperty, the coordinates of the manifold in the ambient space Rm can be thought of as functionsof the diffusion coordinates. We show that because each of coordinates function Xi is a Lipschitzfunction, the ReLU wavelet coefficients of Xi are necessarily '1. This allows Us to use the existingguarantees of Shaham et al. (2018a) to complete the desired bound.
Figure 3: An example of distributions reconstructed from a random walk on MZ (Via Algorithm2), given a single seed point drawn from X. (Bottom): An example of a single burst pθ(x|z). Thedistributions are a loop (left), sphere (middle), and the Stanford bunny (right).
Figure 4:	An example of cluster conditional sampling with our method, given a seed point (topleft of each image grid). The DVAE is able to produce examples via the random walk that stayapproximately within the cluster of the seed point, without any supervised knowledge of the cluster.
Figure 5:	Comparison between GAN, DRS-GAN, and our samples on a 5 × 5 Gaussian grid. GANand DRS-GAN samples taken from Azadi et al. (2018). Shown from left-right are Original, GAN,DRS-GAN, and our method.
