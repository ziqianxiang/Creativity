Figure 1: Lower level of signal-dependent Gaussian noise on supervisory signal from teacher improves (a )the accuracy of student on the unseen data, but not the generalization to the out-of-distribution data as well as(b: ) the robustness to PGD attack.
Figure 2: Encoding the uncertainty of teacher helps the student to (a )generalize better on both unseen dataand out-of-distribution data, and (b) to ave higher generalization to PGD attack. Note that for higher dropoutrate the performance of teacher drops.
Figure 3: Even adding a small Gaussian noise on input level affects both the accuracy on unseen data and thegeneralization to out-of-distribution data.
Figure 4: Gaussian noise on input improves the robustness to PGD attack massively.
Figure 5: Training student with input corrupted with Gaussian noise improves robustness to most naturaldistortions.
Figure 6: .
Figure 7: Knowledge distillation of corrupted teacher to both corrupted and clean student decreases the testand generalization accuracy, but from clean teacher to corrupted student the test accuracy improves.
Figure 8: .
Figure 9: Noise on the supervision from teacher by swapping all logits or the top 2 ( a) improves the accuracyof student on unseen data, but not the generalization to out-of-distribution data.
Figure 10: Swapping all logits or the top two if does not improve the robustness to natural distortions, pre-serves it.
Figure 11: Additive signal-dependent noise maintains the natural robustness to the same level as no noise.
Figure 12: Effect of fix label corruption.
