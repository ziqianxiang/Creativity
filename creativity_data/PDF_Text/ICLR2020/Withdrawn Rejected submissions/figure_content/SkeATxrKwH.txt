Figure 1: (A) Probabilistic scene graph representation. Each node represents an entity in the scene, and isassociated with an appearance latent. Each edge is associated with a relative pose latent that specifies the coor-dinate transformation between the child node and the parent node. (B) Top-down inference process. Inferencecombines information from glimpse regions and higher-level appearance latents (not shown here). Boundingboxes indicate inferred pose latents. (C) Recursive decoding process (a single recursive step shown). The im-age patch Xu1 and mask mu1 of an internal node u1 are decoded from the image patches and masks of all itschildren nodes.
Figure 2: Qualitative results on 2D dataset. (A) (Top) Input image. (Middle) Input image superimposed withpredicted bounding boxes, drawn according to zpOres, zpOose, zrOatio, zpPres, zpPose and zaPddr. (Bottom) Reconstruction.
Figure 3: Qualitative results on 3D dataset. (A) Each row shows the overall reconstruction, and the predictedbounding boxes and reconstruction from each object cell for a given input image. (B) Learned part-leveltemplates. Template colors indicate identity. Part bounding box colors indicate the chosen template.
Figure 4: (A) Generated objects on (Top) 2D dataset and (Bottom) 3D dataset. White boxes indicate aspectratio, and are drawn according to zrOatio. (B) Generated scenes on (Top) 2D dataset and (Bottom) 3D dataset.
Figure 7: Comparison of data efficiency in downstream tasks.
Figure 8: Qualitative results on compositional MNIST dataset. (A) (Top) Input image. (Middle) Input im-age superimposed with predicted bounding boxes. (Bottom) Reconstruction. (B) Learned part-level templates.
Figure 9: (A) Generated objects on compositional MNIST dataset. (B) Generated scenes on compositionalMNIST dataset.
Figure 11: Comparison of data efficiency in downstream task.
