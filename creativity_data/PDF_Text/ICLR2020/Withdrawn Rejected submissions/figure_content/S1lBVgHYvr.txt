Figure 1: The attack-defense protocol2.2	Performance evaluationWe evaluate the expected performance of the classifier f (w, x) on a test distribution q(x)p* (y | x).
Figure 2: Success rate of attacker vs. number of queries on synthetic dataset and MNIST. Left toright: Left and Middle: the number of attacker queries vs. attack success rate for different trainingset sizes. Right: the no-answer (NR) and margin error (ME) on clean data X 〜p* (x). Top to bottom:Top: naive Bayes classifier trained on synthetic Gaussian; Middle: naive Bayes classifier trained onMNIST; Bottom: logistic regression trained on synthetic Gaussian. Logistic regression trained onMNIST fails to achieve robustness for the training set sizes we experimented (up to 10k). For bothcases, defended classifiers require orders of magnitude more queries for successful adversarial attack,while the adverse effect on clean data X 〜p* (x) is negligible.
Figure 3: Success rate vs. number of queriesfor Simba attacker on Inception network. Weadjust the threshold such that both methodshave similar no response rate (NR) on theclean data. The undefended network is signif-icantly more vulnerable to attack.
