Figure 1: Illustrations of unifilar hidden semi-Markov models (uhsMm). At left, two presen-tations of a uhsMms. At left bottom, a generative model for a discrete-alphabet, continuous-timestochastic process. Dwell times τ are drawn upon transitions between states, and the correspondingsymbol is shown for that amount of time. At top, the corresponding “conveyer belt” representationof the process generated by the model beneath. Conveyer belts represent the time since last sym-bol based on the height along the conveyer belt traveled; each conveyer belt has a symbol. To theright of the two presentations of a uhsMm, an example time series generated from the model at left,where Φa, Φb, φc are inverse Gaussian distributions with (μ, λ) pairs of (1, 2), (2, 3), (1, 3),respectively.
Figure 2: The estimated density function from varying numbers of samples. Shown, at left,is the inferred density function using the neural network approach described here compared to thetrue density function (dotted, green) when given 500 samples (blue) and 5000 samples (orange).
Figure 3: At left, the two-state model (top) and four-state UhsMm (bottom) for binary-alphabet,continuous-time data. At right, BIC as a function of the amount of data for the two-state, four-state,and six-state uhsMms at left. (The six-state uhsMm is not shown.) Larger BIC implies a higherposterior, and so a better fit.
Figure 4: Entropy rate estimation, showing model-free vs. model-based estimators. The syntheticdataset is generated from Fig. 3(top) with φA (t) = φD (t) as inverse Gaussians with mean 1 andscale 5 and with φB (t) = φC (t) as inverse Gaussians with mean 3 and scale 2. The ground truthentropy rate from the formula in (Marzen & Crutchfield, 2017) is 1.85 nats, shown in green. Inorange, the model-free estimator (combination of plug-in entropy estimator and kNN (Kraskov et al.,2004) entropy estimators) described in the text. In blue, the model-based estimator assuming a two-state model, i.e., the top left of Fig. 3. In black, the model-based estimator assuming a four-statemodel, i.e., the bottom left of Fig. 3. Lines denote the mean, and various data point denote theestimated entropy rate for different data sets of a particular size N . The model-free method hasmuch higher variance than the model-based methods, and the model-based method for which thecorrect (four-state) model is used also has lower bias.
Figure 5: At left, mean-squared error of the predictor of the symbol at time T from data prior to atime of 0 for when 500 data points are available and 300 epochs are used to train the ANN; at right,the mean-squared error of the predictor for when 5000 data points are available and 3000 epochsare used to train the ANN. The generating uhsMm is in Fig. 3(left). The uhsMm method infers theinternal state of the unfilar hidden semi-Markov model; the PANN method uses the last n data points(xi , τi) as input into a feedforward neural network; and the RNN method uses the past (xi , τi) asinput to an LSTM.
