Figure 1: (Left) Network structure of the deep reinforcement learning agent. The environment andeverything coming from it (Yellow). The deep neural network, optimized with gradient descent,facilitated by PPO (Blue). Parts of the PPO algorithm used to optimize the neural network (Or-ange). (Right) Agent observations of one frame, one can see a normal door to the right of the agent.
Figure 2: Statistics of one inference run throughthe tower. The agent reaches level 10 (blue curve)and the run ends when the time is up, here after4000 frames.
Figure 3: Activation pattern comparison betweena trained agent (top), a trained autoencoder (mid-dle) and a random network (bottom). Colors indi-cate the percentage of frames in which the neuronin the encoded state is active (activation>0).
Figure 4: Correlation between the cluster assignment of frames and corresponding action combi-nations. Clustering performed on the visual embedding of a trained agent (left), an autoencoder(middle) and a random network (right). (Top) Example of correlations for action combination ’For-ward + Turn Right’ with clusters within a 20-frame window. (Bottom) Bar height represents theaverage correlation in a 10-frame window around 0 in the top plots for all actions and cluster. Itshows distinct correlations between clusters and actions in the trained agent.
Figure 6: Correlation of clusters with Doors. Comparison of trained agent (max=0.42, min=-0.11),autoencoder (max=0.15, min=-0.09) and random network (max=0.09, min=-0.08).
Figure 7: T-SNE performed on the visual embedding of a trained agent colored by action com-bination associated with each frame. Images show example agent observations which created theencoding activation associated with the point it is connected to. Encodings associated with framescontaining level doors are circled in red.
Figure 8: Network structure of the autoencoder.
Figure 9: Autoencoder example input, encoding and output.
Figure 10:	Distribution of actions over one inference run of 4000 frames. (Left) Distribution in thefour action branches. (Top Right) Distribution of all existing action combinations. (Bottom Right)Distribution of all action combinations used in the paper. All actions marked in grey in the plotabove are aggregated in the last action combination.
Figure 11:	(Top) Analysis used for the choice of number of clusters in section 3.4. Both mean withinclass variance as well as the silhouette score for different number of clusters have their minimum atsix clusters. (Bottom) Statistics of the k-means clustering with six clusters.
Figure 12:	T-SNE performed on the visual embedding of a trained autoencoder (left) and a ran-dom network (right) colored by action combination associated with each frame. Frames where theobservation contained a level door are circled red.
Figure 13: T-SNE performed on the visual embedding of a trained Agent (left) and a trained autoen-coder (right) colored by semantic content of the visual observation associated with the encoding.
Figure 14: Distances and variances within the encodings for individual actions in the original highdimensions encoding space (dim=256). Data in numbers is also given in 1 accumulated over actions.
