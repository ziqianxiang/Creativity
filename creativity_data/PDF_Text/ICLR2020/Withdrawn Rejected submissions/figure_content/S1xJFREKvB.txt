Figure 1: ResNet34 on CIFAR-10. Initial learning rate no = 0.1, momentum β = 0.9, run 5 seeds(same χ0). In (a) (c), We plot mean curves with shaded bands indicating ±1 standard deviation. (b)shows the standard deviation of test accuracy and its average over 90 epochs. Best viewed in color.
Figure 2: ResNet34 on CIFAR-10. For all methods, no = 0.1, β = 0.9. Labels of AMI-SGD are'AM1-SGD-{Option}’. Shaded bands (or bars) indicate ±1 standard deviation. Best viewed in color.
Figure 5: Convergence of LSTM and ResNet. We plot the curve of validation perplexity and testaccuracy, respectively. Shaded bands indicate ±1 standard deviation. Best viewed in color.
Figure 6: Convergence of test accuracy from the parameter sweep experiments in Table 4. Labelsare formatted as Am1∕2-SGD-{Option}-{m}' . Best viewed in color.
Figure 9: Train-batch loss results. Best viewed in color.
Figure 10: ResNet18 on CIFAR-10. η0 = 0.1, β ∈ {0.95, 0.995}. ‘+’ represents performing arestart after each learning rate reduction.
Figure 11: ResNet18 on CIFAR-10.
Figure 13: DenseNet121 on CIFAR-100. For all methods, no = 0.1, β = 0.9, run 3 seeds. AM1-SGD and AM2-SGD use Option II and m = 5. Shaded bands indicating ±1 standard deviation.
Figure 14: A sanity check. Labels are formatted as 'AM{1∕2}-SGD-{Option}-{m}'.
Figure 15: Train-batch loss vs. full-batch loss. Best viewed in color.
Figure 16: Train-batch loss vs. test accuracy. Best viewed in color.
