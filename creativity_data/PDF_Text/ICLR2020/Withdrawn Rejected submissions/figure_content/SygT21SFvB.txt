Figure 1: Visualizations of metrics measuring properties of objective loss landscapes. The black arrowsrepresent the descent on the support loss and the dotted lines represent the corresponding displacement in theparameter space. (1): Curvature of the loss for an adapted meta-test solution θi (for a task Ti), is measuredas the spectral norm of the hessian matrix of the loss. (2): Coherence of adaptation trajectories to differentmeta-test tasks is measured as the average cosine similarity for pairs of trajectory directions. A direction vectoris obtained by dividing a trajectory displacement vector (from meta-train solution θs to meta-test solutionssθi) by its Euclidean norm, i.e. θi = (θi - θs)/kθi - θs k2. (3): Characterizing a meta-train solution by thecoherence of the meta-test gradients, measured by the average inner product for pairs of meta-test gradientvectors gi = -VθL(f(Di; θs)).
Figure 2: Flatness of meta-test solutions for MAML and First-Order MAML, on Omniglot andMiniImagenetverify if it is reflected by an increase in E[kHθ(Di; θi)kσ]. On the contrary, and remarkably, even asf starts to show poorer generalization (see Figure 3a), the solutions keep getting flatter, as shown inFigure 3c. Thus for the case of gradient-based meta-learning, flatter minima don’t appear to favourbetter generalization. We perform the same analysis for our finetuning baseline (Figures 4a, 4c), withresults suggesting that flatness of solutions might be more linked with E[L(f(Di; θi))], the averagelevel of support loss attained by the solutions θi (see Figures 4b and 3b), which is not an indicator forgeneralization. We also noted that across all settings involving MAML and First-Order MAML, thisaverage meta-test support loss E[L(f (Di ; θi))] decreases monotonically as meta-training progresses.
Figure 3: MAML: Characterization of meta-test solutionsEpoch(b) Support loss7065■产 TeT——I1	20	40	60	80	100Epoch(c) Curvature of solutionsFigure 4: Finetune baseline : Characterization of meta-test solutions5.2 Coherence of adaptation trajectoriesIn this section, we use the same experimental setup as in Section 5.1, except here we measureE[θ~i Tθ~j]. To reduce the variance on our results, we sample 500 tasks after each meta-training epoch.
Figure 4: Finetune baseline : Characterization of meta-test solutions5.2 Coherence of adaptation trajectoriesIn this section, we use the same experimental setup as in Section 5.1, except here we measureE[θ~i Tθ~j]. To reduce the variance on our results, we sample 500 tasks after each meta-training epoch.
Figure 5: Comparison between average inner product between meta-test trajectory direction vectors(orange), and average target accuracy on meta-test tasks (blue), MAML First-Order and Second-Order,MiniImagenet 5-way 1-shot. See Figure 11 in Appendix B.2 for full set of experiments.
Figure 6:	(a): Average inner product between meta-test adaptation direction vectors, for Finetuningbaseline on MiniImagenet. (b): Average inner product between meta-test gradients, for Finetuningbaseline on MiniImagenet. Average l2 norm of meta-test adaptation trajectories, all algorithms onMiniImagenet, (c): 1-shot learning, (d): 5-shot learning.
Figure 7:	Comparison between average inner product between meta-test gradient vectors, evaluated atmeta-train solution, and average target accuracy on meta-test tasks, with higher average inner productbeing linked to better generalization. See Figure 12 in Appendix B.3 for full set of experiments.
Figure 8: Analysis for Few-shot regression. Comparison between E[ giT gj ] and average negativetarget Mean Squared Error on meta-test tasks(generalization performance). (a) and (b) show general-ization performance correlates with E[ giT gj ] through-out the meta-training (c) and (d) show thecorrelation across many values of k (number of shots), while (e) shows the correlation coefficient Rbetween E[ giT gj ] and final generalization performance, for models with k varying between 2 and15.
Figure 9: Average target accuracy on meta-testtasks using our proposed regularizer on MAML,for Omniglot 20-way 1-shot learning, with regular-ization coefficient Y = 0.57 ConclusionWe experimentally demonstrate that when using gradient-based meta-learning algorithms such asMAML, meta-test solutions, obtained after adapting neural networks to new tasks via few-shotlearning, become flatter, lower in loss, and further away from the meta-train solution, as meta-training progresses. We also show that those meta-test solutions keep getting flatter even whengeneralization starts to degrade, thus providing an experimental argument against the correlationbetween generalization and flat minima. More importantly, we empirically show that generalizationto new tasks is correlated with the coherence between their adaptation trajectories, measured bythe average cosine similarity between the adaptation trajectory directions, but also correlated withthe coherence between the meta-test gradients, measured by the average inner product betweenmeta-test gradient vectors evaluated at meta-train solution. We also show this correlation for few-shotregression tasks. Based on these observations, we take first steps towards regularizing MAML basedmeta-training. As a future work, we plan to test the effectiveness of this regularizer on various datasetsand meta-learning problem settings, architectures and gradient-based meta-learning algorithms.
Figure 10:	MAML: Accuracies on training and testing tasksB.2	Coherence of adaptation trajectoriesThe relation between target accuracy on meta-test tasks, and angles between trajectory directions ispresented in Figure 11.
Figure 11:	Comparison between average inner product between trajectory directions and averagetarget accuracy on meta-test tasks. Full set of experiments.
Figure 12: Comparison between average inner product between trajectory displacement vectors, andaverage target accuracy on meta-test tasks. Full set of experiments.
