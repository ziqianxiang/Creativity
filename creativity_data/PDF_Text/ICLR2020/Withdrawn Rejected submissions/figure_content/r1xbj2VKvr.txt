Figure 1: Visual comparison between representations learnt by current methods and dual encoding.
Figure 2: training support embeddings of node v and its negative sample node vn .
Figure 3: Classification results (micro-averaged F1 scores) w.r.t different aggregators on four datasetsTable 3: Link prediction results for Pubmed/PPI w.r.t different percentage of hidden-edgesDataset	Methods	90%:10%		80%20%		60%:40%		40%:60%			AUC	AP	AUC	AP	AUC	AP	AUC	AP	RawFeats	57.61	54.72	58.51	56.19	54.47	52.82	52.41	50.77	G2G	64.13	68.60	63.52	65.15	60.03	66.16	58.97	61.17Pubmed	GraphSAGE	85.49	82.79	87.64	83.35	81.07	77.47	79.34	74.92	CADE-MS	89.95	88.79	90.36	86.67	87.14	83.77	84.76	79.53	CADE-MA	89.73	89.76	90.94	88.90	90.54	87.89	85.27	80.15	RawFeats	57.46	56.99	57.34	56.86	57.35	56.75	56.83	56.36PPI	G2G	60.62	58.98	60.99	59.38	61.05	59.54	60.93	59.49	GraphSAGE	82.74	81.20	82.21	80.66	82.11	80.51	82.07	80.70	CADE-MS	85.87	85.08	84.21	83.48	84.46	82.84	83.61	82.39	CADE-MA	86.33	85.32	85.85	84.63	84.15	82.15	81.98	79.54Comparation on performance with respect to varying percentage of hidden edges are reported inTable3. CADE shows best link prediction performance on both datasets.
Figure 4: node classification performance (micro-f1 score) w.r.t varying sampling sizeshas the same sampling complexity as GraphSAGE. For the efficiency of experiment, we conductexperiments of node classification on a small subset of PPI, denoted by subPPI, which includes 3training graphs plus one validation graph and one test graph. Results are reported in Figure 4. Withmuch smaller sampling width, CADE-MS still outperforms the original framework significantly.
