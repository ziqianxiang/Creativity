Figure 1: Let’s assume that for a particular input [x1 x2] going into the ReLU network shown in(a) the white neurons are inactive; then, for this particular input, the network from (a) is equivalentto network in (b) where the inactive neurons are treated as dead and the active ones operate in thelinear part of their ReLU activation fuction; which makes both of these networks equivalent to onein (c); the grey hidden neurons form the active subnetwork.
Figure 2: The heatmaps of Wb of arbitrary neurons from 2 different MNIST inputs (first column), inthe second convolutional layer (next 5 columns) and the first fully connected layer (last 5 columns)of the 2CONV neural network; normalised intensity of red and blue in each heatmap corresponds tothe magnitude of the positive and negative value (with white indicating 0); the activity V = xwbT + band the switched bias b are shown above the heatmap of each neuron.
Figure 3:	Graphical representation of the concept of a neuron’s centre c in a 2D scenario, whereinput vector is X = [xi χ2 ]; the diagram shows input-space coordinate system - the neuron-specificone would have its origin at c.
Figure 4:	Visualisations for a set of interpretability methods of a single 2CONV neural networktrained on the clean MNIST data in response to clean as well as noisy input; top-left shows cleanMNIST, top-right noisy bordered MNIST, bottom-left noisy background MNIST and bottom-rightnoisy framed MNIST; the intensity of red and blue correspond respectively to the magnitude of thepositive and negative values in the heatmaps.
Figure 5: Visualisations for a set of interpretability methods on two 2CONV neural networks - onetrained on the smallNORB dataset (left) and the other on the CIFAR10 dataset (right); the intensityof red and blue correspond respectively to the magnitude of the positive and negative values in theheatmaps.
Figure 6: Visualisations for Insens。； ' for layers l=1, 3, and 5 of the 2CONV network trained onsmallNORB dataset (left) and CIFAR10 datasets (right); the intensity of red and blue correspondrespectively to the magnitude of the positive and negative values in the heatmaps.
Figure 7: Mean spearman rank-order correlation between visualisations derived from a random sam-Ple of CIFAR-10 input for different methods including Insens ΩL-ι between trained and randomlyinitialised 2CONV network (first left), between trained and random label CIFAR-10 trained 2CONVnetwork (second left); the same correlation is shown over Insens based on different layers of the 2-CONV network (two figures on the right); Insens correlations are shown in red; vertical black linesshow the variance.
Figure 8: Visualisations of the 2CONV architecture trained on MNISTdbl dataset, where input is acomposite of an odd and even digit from the MNIST database and the target label corresponds to theeven digit; input images shown are test images from the MNISTdbl dataset.
Figure 9: Visualisations of the 2CONV architecture trained on MNISTdbl dataset, where input is acomposite of an odd and even digit from the MNIST database and the target label corresponds to theeven digit; input images shown are adversarial examples where only the odd digit is present.
Figure 10: Visualisations of the 2CONV architecture trained on MNISTdbl dataset, where input isa composite of an odd and even digit from the MNIST database and the target label corresponds tothe even digit; input images shown are adversarial examples with two even digits.
Figure 11: Visualisations of the 2CONV architecture trained on MNISTdbl dataset, where input isa composite of an odd and even digit from the MNIST database and the target label corresponds tothe even digit; input images shown are adversarial examples with two odd digits.
Figure 12: Visualisations for a set of interpretability methods of a single 2CONV neural networktrained on the MNIST dataset (left) and smallNORB dataset (right) in response to advesrarial ex-amples; the intensity of red and blue correspond respectively to the magnitude of the positive andnegative values in the heatmaps.
Figure 13: Visualisations of the difference between the visualisations from Figure 12; the differ-ence shown is between visualisation based on the image from the dataset (top row Figure 12) andrespectively each adversarial example visualisation (second, thirds and fourth rows of Figure 12;the intensity of red and blue correspond respectively to the magnitude of the positive and negativedifferences of values in the heatmaps.
