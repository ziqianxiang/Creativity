Figure 1: Robustness results for DNNs against different manipulations on MNIST. Panels (a) and (b)show the accuracy on classifying noisy test data generated by shifting the digits vertically (Ver) andhorizontally (Hor). It shows that data augmentation during training makes generalization to unseenshifts worse (orange versus blue lines).
Figure 2: A simple ex-ample, where X is theeffect of Y, Z and M.
Figure 3: Graphical presenta-tion of proposed causally con-sistent deep generative modelfor single modal data.
Figure 4: The network architecture.
Figure 5: The Markov Blanket of target vari-able YFigure 6: Graphical presentation of proposedcausal deep generative model for genericmeasurement modal data.
Figure 6: Graphical presentation of proposedcausal deep generative model for genericmeasurement modal data.
Figure 7: The first row shows the results of testing the model robustness against horizontal shiftsand the second row shows the results against vertical shifts.
Figure 8: Performance regardingdifferent percentages of test dataused for fine-tuning manipulationħq∏qei∏qdqħΞΞ□E1ΠBQBΞEIQBQBQQElDEinElIIBBIBBElIlQnΠE3□BHSDB□C1BΞΞSΞEH3ΠHSbqdsħdξqeiξħξb□π□bqb□E1QE1HQ□□BBDHBQ□Π□B□BE1(a) Vertically shifted training (b) do(m=0) with the z and ydata	from the vertical shifted dataFigure 9: Visualization of the disentangled representation.
Figure 9: Visualization of the disentangled representation.
Figure 10: Performance of our model against different manipulation (c.f. Figure 1).
Figure 12: Test accuracy on adversarial examplescrafted on CIFAR-binary data.
Figure 13: Test accuracy on adversarial examplescrafted on measurement data.
Figure 11: Test accuracy on MNIST adversarial examples.
Figure 15: Manipulate children(a) Shift Up	(b) Shift Down	(a) Shift UpFigure 14: Manipulate co-parentsfully generative classifiers are less satisfactory for classifying clean CIFAR-10 images (< 50% cleantest accuracy). The deep CAMA model trained with data augmentation (adding Gaussian noise withstandard deviation 0.1, see objective (5)) achieves 88.85% clean test accuracy on CIFAR-binary,which is on par with the results reported in Li et al. (2018). For reference, a discriminative CNNwith 2× more channels achieves 95.60% clean test accuracy. Similar to previous sections we applyFGSM and PGD attacks with different values to both deep CAMA and the discriminative CNN,and evaluate classification accuracies on the adversarial examples before and after finetuning.
Figure 14: Manipulate co-parentsfully generative classifiers are less satisfactory for classifying clean CIFAR-10 images (< 50% cleantest accuracy). The deep CAMA model trained with data augmentation (adding Gaussian noise withstandard deviation 0.1, see objective (5)) achieves 88.85% clean test accuracy on CIFAR-binary,which is on par with the results reported in Li et al. (2018). For reference, a discriminative CNNwith 2× more channels achieves 95.60% clean test accuracy. Similar to previous sections we applyFGSM and PGD attacks with different values to both deep CAMA and the discriminative CNN,and evaluate classification accuracies on the adversarial examples before and after finetuning.
Figure 16: Robustness results for DNNs against different manipulations on MNIST using CNN.
Figure 17: Robustness results for DNNs against different manipulations on MNIST using a largeMLP. Panels (a) and (b) show the accuracy on classifying noisy test data generated by shifting thedigits vertically (vt) and horizontally (ht). It shows that data augmentation during training makesgeneralization to unseen shifts worse (orange versus blue lines).
Figure 18: ZCA Whitening manipulation result. Figure shows the robustness results for DNNsagainst different manipulations on MNIST using CNN. The blue curve shows that result from train-ing with clean data. The orange curve shows that result from training with zca whitening data added.
Figure 19: Performance regarding differentpercentage of test data used for fine-tuningmanipulation of horizontal shift without us-ing do(m) = 0 for the cleaning training dataduring fine-tuning.
Figure 20: Performance regarding differentpercentage of test data used for fine-tuningmanipulation of vertical shift using do(m) =0 for the cleaning training data during fine-tuning.
