Figure 1: [a] Linear fit with OLS,KMM and Robust estimator; [b] Slope estimation performance5.2	Real World Dataset for ERMNext, we test our approach in ERM on a real world dataset, the breast cancer dataset from the UCIArchive. We consider the second biased sampling scheme in Huang et al. (2007) where the prob-ability of selecting xi into the training set depends jointly on multiple features and is proportionalto exp(-σj∣xi - Xk) for some σ > 0 and the sample mean X. Since this is a binary classificationproblem, we can experiment with both the penalized least square regression and the penalized logis-tic regression for different sizes of training sets. We used a Gaussian kernel exp(-σ2kXi - Xj k).
Figure 2: Classification performance for penalized [a] least square regression; [b] logistic regression5.3	Simulated Dataset for EstimationOn an estimation problem, we simulate data from two ten dimensional Gaussian distribution withdifferent, randomly generated mean and covariance matrix as training and test sets. The target valueis V = Ex〜Pte [g(x)] for an artificial g(x) = sin(c.xk2) + (1+ exp(cTX))T With random ci, c2and labels are observed with Gaussian noise. A Gaussian kernel exp(-σkxi - xj k) and a tolerancee for β are set exactly as in Gretton et al. (2009) with σ = √5, B = 1000 and e = √nr-1. We alsontrexperiment with a different g by substituting gγ,data for a naive linear OLS fit. At each iteration, weuse the sample mean from 106 data points (without adding noise) as the true mean and calculate theaverage MSE over 100 estimations for VR, VKMM and VNR respectively. As shown in Table 1, theperformances of VR are again consistently on par with the best case scenarios, even when the usualassumption ntr < nte is violated.
