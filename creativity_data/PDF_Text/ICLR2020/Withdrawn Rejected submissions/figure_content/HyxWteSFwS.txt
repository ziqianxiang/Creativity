Figure 1: An illustrative example. Figure (a) shows an illegal cash-out event. It can be revealed byhigh-frequency transactions with multiple merchants. However, if we merge the transaction data intoa static graph, we cannot distinguish it from the static graph generated from normal online shoppingactivities. Thus, learning from such a static graph will fail to detect the cash-out event.
Figure 2: A toy example of interactions, the corresponding temporal dependency graph and computa-tion of nodes’ dynamic embedding using DIP unit on its 3-depth temporal dependency subgraph.
Figure 3: An illustrative example. Enhanced dynamic representation with Fusion and Selection.
Figure 4: Mean rank results. As low mean rank indicates that the ground-truth item is rankedaccurately, we can observe that DIP always outperforms baselines.
Figure 5: Ablation study results of the interaction prediction task. Disabling any one of the threecomponent leads to a performance drop.
Figure 6: Ablation study results of the interaction classification task. All of the three componentcontributes a lot to improve the final classification precision.
Figure 7: Hit@5 Results2.34CoIIegeMsq......
Figure 8: HIT@1 ResultsB.2 Hit PerformanceFigure 7 and Figure 8 provide HIT@5 and Hit@1 results in addition to the Mean Rank results inSection 5.3.2 of the main paper. HIT@n is defined as HIT@n = # # T ?『i-------不—,where δi = 1#of Test Interaction ,	iif ranki <= n else 0, which measures the ability of top rank prediction.
Figure 9: Sensitivity to k and L.
Figure 10: Sensitivity to dynamic representation dimension.
