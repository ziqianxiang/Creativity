Figure 1: Given a graph clustering, two approaches to construct hierarchical graph convolution fromv-nodes to u-nodes: (a) a parametric graph convolution followed by non-parametric pooling basedon edges {(vk, uj)}k∈Gj , (b) the proposed parametric bipartite graph convolution layer directlyconnects v-nodes to clustered u-nodes.
Figure 2: Aggregation of two input graphs with vertex sets V 1 and V2 into a same output graph withvertex set U . Each of the two input graphs can contain information from different graph domains orscales producing a mixed fusion of information.
Figure 3: A conceptual representation of a graph autoencoder with both down-sampling and up-sampling strided BGC layers and a skip connection to implement a ResNet/U-Net style architecture.
Figure 4: (a) 3D point cloud classification and graph classification results. Instance precisions ofgraph-based ModelNet classifiers are shown for ModelNet10 and ModelNet40, and classificationaccuracies for the graph kernel benchmark data sets (b) Comparison of forward and backward runtimes (lines, left axis) and the memory consumption (bars, right axis) for the DD dataset as a functionof batch size for FullConvGNN and PoolGConvNet.
Figure 5: Irregularly sampled points (circles) from an underlying realization of a GP (red line) areprocessed by a GNN encoder which performs graph convolution over neighborhoods of the input(dashed outlines). A BiGraphNet bridge transforms the representation from the input to outputgraph, and then “decoded” by a GNN to generate an approximation of the function at the targetpoints. For validation, the model output is estimated on a uniformly sampled grid of points (blueline) to determine how well the underlying process (red dashed line) is captured.
