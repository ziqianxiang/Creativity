Figure 1: Comparison of performance with and without neural attention on text classification(IMDB), Natural Language Inference tasks (SNLI) and Neural Machine Translation (News Com-mentary). Here, ฮฑ and C denote attention weights and context vector respectively. The results showthat attention does not substantially effect performance on text classification. However, the samedoes not hold for other tasks.
Figure 2: Relationship between maximum attention weight and median change in output on per-muting attention weights. For single sequence tasks, , indicate negative and positive class. ForMultiNLI, ,	, denotes contradiction, entailment and neutral respectively. The results rein-force the claim that altering attention weights in single sequence tasks does not have much effect onperformance while the same does not hold with other tasks. Refer to ยง4.1 for details.
Figure 3: Analysis of correlation between attention weights and feature importance measure. Wereport relationship between difference in zeroed attention weights and corresponding change in JSdivergence for different tasks. Please refer to ยง4.2 for more details.
Figure 4: Performance comparison with permuting attention weights for different layers in self-attention based models. The results are reported on a representative instance of single sequence,pair sequence and generation tasks. The dotted lines denote the base performance on the task. Referto ยง4.3 for details.
Figure 5: Manual evaluation of interpretability of attention weights on single and pair sequencetasks. Although with original weights the attention does remain interpretable on both tasks but inthe case of single sequence tasks making it meaningless does not change the prediction substantially.
