Figure 1: Forward pass in an invertible block. x is split in x0:n/2 and xn/2:n. f1 and f2 can beany type of Neural Networks as long as the dimension of their output dimension is the same astheir input dimension. In our experiments, we stack two of these blocks one after the other and usefully-connected feedforward layers for f1 and f2.
Figure 2: Comparison of the accuracy of several Continual Learning methods on CIFAR-100 withvarious batches of classes. FearNetâ€™s curve has no point before 50 classes because the first 50 classesare learned in a non-continous fashion.
Figure 3: t-SNE projections of features spaces for five classes from CIFAR-100 test set (colorsare given by the ground truth). (a): features space before applying Invertible Networks (blackcrosses are the clusters centers). (b),(c),(d),(e),(f): each features space after the Invertible Networkof each class. The samples of a class represented by a network are clustered around the zero vector(black cross) whilst the samples from other classes appear further away from the cluster. Anothervisualization highlighting the differences between OvA-INN and Nearest Prototype is presented inAppendix D.
Figure 4: top: t-SNE projection of the features space before applying Invertible Networks (blackcrosses are the clusters centers) for 20 classes from CIFAR-100 test set (colors are given by theground truth). bottom: in blue and yellow are the samples correctly and wrongly classified by bothNearest Prototype and OvA-INN, in green the samples better classified by OvA-INN than NearestPrototype and orange the samples better classified by Nearest Prototype than OvA-INN.
