Figure 1: Trajectories in convex and deep learning settings. First row 100 logistic regressions onMNIST, second row 100 logistic regressions on IMDB, third row 10 convolutional neural networkson CIFAR10. We show the mean over the trajectories for training loss (left), training accuracy(center), and the accuracy improvement of DAS Grad with respect to AMSGrad and Adam with95% confidence intervals (right).
Figure 2: Trajectories of 100 random seeds, for the online centroid learning problem with differentvariance for the features. Enhanced improvements of adaptive methods with higher variance of thegradients.
Figure 3: Trajectories of 20 random seeds for 2,000 iterations in convex optimization settings. Mul-ticlass logistic regression on unbalanced MNIST dataset. We show the mean over 20 trajectories oftraining loss (left), training accuracy (center), and the improvement in accuracy of DASGrad withrespect to AMSGrad and Adam with a 95% confidence interval (right)7 ConclusionCapability of learning from data efficiently is a prerequisite for practical success of complex learningmodels across various problem settings and application contexts. We have shown how double adap-tive stochastic gradient descent methods enable efficient learning in a generalizable manner, whileensuring convergence improvement. We observed that DAS Grad algorithm outperforms currentlyprevalent variants of adaptive moment algorithms such as Adam and AMS Grad overall, in thecontext of the number of iterations required to achieve comparable performance, under the theoret-ical convergence guarantees in a stochastic convex optimization setting. With empirical validationin convex and non convex settings, we have shown that the advantages of DASGrad become moreprominent with the increasing complexity of data and models, and with more variance in the gradi-ents. We have also broadened our results to demonstrate generalization properties of our approachand its extensions to transfer learning, as well as intuitive connections to other learning scenarios.
