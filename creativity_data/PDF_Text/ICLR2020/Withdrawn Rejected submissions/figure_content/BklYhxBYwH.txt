Figure 1: Basic Intuition of Our Attacks. Bluestars represent the main steps AdvFuzzer takes.
Figure 2: Successful adversarial examples from fuzzing attacks on MNIST and CIFAR-10Table 1: Average Results for Untargeted Attacks	MNIST				CIFAR-10				Avg L0	Avg L2	Avg L∞	# queries	Avg L0	Avg L2	Avg L∞	# queriesBoundary attack	769	1.1454	0.2657	115,134	3,071	0.1658	0.0182	128,296Opt attack	784	1.0839	0.3067	67,536	3,072	0.1671	0.0164	56,438C&W L0 attack	10	2.5963	0.9519	-	9	0.9988	0.4450	-C&W L2 attack	749	1.4653	0.4299	-	3,072	0.1894	0.0226	-Fuzzing attack 100	19	2.5536	0.9706	-^6,321 ^^	33	1.7838	0.5471	24,045Fuzzing attack 300	19	2.5041	0.9661	14,697	32	1.7176	0.6593	56,678Fuzzing attack 500	19	2.4525	0.9673	22,546	28	1.6822	0.6526	88,488Targeted Attacks We consider next label targeted attacks (Brendel et al., 2017; Cheng et al., 2019)where the adversarial goal is for an adversarial example to be misclassified as a target class yt suchthat yt = (y + 1) module 10 where y is the source class. The results for targeted attacks are shownin Table 2. The second row in Figure 2 shows the successful adversarial examples from the targetedfuzzing attacks on MNIST and CIFAR-10. The perturbations for targeted attacks are visually largerthan the perturbations for untargeted attacks. Similarly, the fuzzing attack decreases the averageL0 distance while increases the average L2 and L∞ distances. The fuzzing attacks also reducethe average number of queries by 8-9 folds and 2-2.5 folds for MNIST and CIFAR-10, respectively.
