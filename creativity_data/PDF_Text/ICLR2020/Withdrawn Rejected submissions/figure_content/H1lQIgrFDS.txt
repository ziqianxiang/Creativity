Figure 1: In l₁ case, if we perturb the input with δ such that   δ  ₁ is fixed, we may get very differentoverlapped regions with different size. Notice that this is different from l₂ (or l₀, not shown), wherethe overlapped regions are always symmetric and of the same size.
Figure 3:   For mixed random variables, some-times the inverse of the probability does not ex-ist. E.g., see the solid blue line.
Figure 4:   Comparison for Eqn. (1).  Green re-gion shows that baseline is better, while red re-gion shows our new bound is better.
Figure 5:  When δ is small, we will take the redpart to construct P(X      B), and blue part toconstruct P(Y       B).  The difference betweenthem meets the condition that T (x) =      δ  ₁,which leads to a tight bound.
Figure  6:    Comparing  different  methods  un-der different PA.  Our model always gives thelargest radius compared with the other models,because our bound is tight.
Figure 6:  Approximate certified accuracy on CIFAR-10 and ImageNet.
Figure 7:  Approximate certified accuracy attained by randomized smoothing on CIFAR-10.
Figure 8:  Approximate certified accuracy attained by randomized smoothing on ImageNet.
Figure 10:   The ROPS under various x.  HereΣ   =   [0, sup  ROPS),  and  similarly  for  Λ.
Figure 11:   The ROPS under various certifiedrobustness  radii  with  a  fixed  x  =  0.3  (otherx    yields  similar  results).   Laplace  noises  areless sensitive than Gaussian noises in terms ofROPS.
