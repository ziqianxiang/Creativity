Figure 1: From left to right (1) Accuracy of MC dropout and deep ensemble (2) the relative im-provements in accuracy of deep ensemble and MC dropout (3) Brier score of MC dropout and deepensemble against number of models (4) the relative improvements in in Brier score of deep ensembleand MC dropout against number of models. Difference grows as number of models increases.
Figure 2: Interrater Agreement (IA) of models with different types of dropout with 0.1 dropout rateon the SVHN, CIFAR-10 and -100 datasets. The lower the IA, the more diverse the predictions ofthe models. Y-axis indicates different methods. MC dropout produces models with much larger IA,hence less model diversity, than structured dropout techniques in most of the cases.
Figure 3: Test Brier score (left) and accuracy (right) against number of models for ensemble predictionat test time on CIFAR-10. This corresponds to the number of different MC dropout instantiations attest time of the same model. The Model trained with omnibus dropout achieves the best in terms ofaccuracy and Brier score.
Figure 4: Reliability diagrams of predictions produced by difference models.
Figure 5: Left: Test accuracy against number of training samples for models with different methods ofdropout and Variation Ratios as the acquisition function on CIFAR-10. Right: Relative improvementsin test accuracy over that of the first iteration with different methods of dropout.
Figure 6: Test Brier score (left) and accuracy (right) against number of models for ensemble predictionat test time on SVHN and CIFAR-100. This corresponds to the number of different MC dropoutinstantiations at test time of the same model. The Model trained with omnibus dropout achieves thebest in terms of accuracy and Brier score.
Figure 7: Plots of test time NLL (left) and accuracy (right) against dropout rate for models trainedwith different types of dropout on the SVHN, CIFAR-10 and CIFAR-100 datasets.
