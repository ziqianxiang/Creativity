Figure 1: Summary of our method for training and evaluation. The blocks above the line are pre-trained in an self-supervised way. The solid blocks represent the BERT language model, which ispre-trained on web text and frozen (see section 3.1). The black CBT visual block is trained usingNCE loss on unlabeled HowTo or Kinetics videos (see section 3.2). The red cross-modal transformeris trained using cross-modal loss on HowTo with ASR (see section 3.3). The components below theline are trained in a supervised way on various tasks. The purple block is trained for next actionprediction on ActivityNet, Breakfast, and 50Salads (see section 4.2). The blue block is trained forvideo classification on UCF101 and HMDB501 (see section 4.1). The green blocks are trainedon captioning and video segmentation tasks, which are described in the supplementary material(section 6.1 and section 6.2). Lseq refers to cross-entropy sequence loss.
