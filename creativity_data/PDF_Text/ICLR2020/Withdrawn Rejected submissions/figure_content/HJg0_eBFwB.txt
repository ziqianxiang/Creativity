Figure 1: A diagram of in-training factorization. A weight matrix is replaced by the product of twoweight matrices, followed by the bias and activation.
Figure 2: Time evolution of validation perplexity for baseline and in-training factorized transformerswith the same GPU memory usage.  The factorized model has half the parameters and double thebatch size.
