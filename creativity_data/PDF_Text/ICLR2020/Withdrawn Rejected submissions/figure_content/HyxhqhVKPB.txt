Figure 1: Performance of different algorithms under different network configurations∣-∙- B-PSCDECB-PS6∣X3Wt>→- DCB-PSβl⅞3Ht>→- Cħo<oSeD{3Mt>→- B∙∙∣>S(∣UMx∙(3l)lt>—MMiiquXJHt)20	50	100	150Epoch(a) 3-Bit Training Losso∙2B-PSCD一 KB-PS6B{2Wt>^δ gð lðθ 150^Epoch0	50	100	150Epoch(b) 2-Bit Training Loss (c) 3-Bit Test Accuracy (d) 2-Bit Test Accuracy
Figure 2: Performance of Moniqua and other quantization algorithms under extreme bit-budget.
Figure 4: Performance of Moniqua on VGG16 andResNet110 under different θFigure 3: Performance of applying Moniqua onD2 and AD-PSGDwith 3-bit communication Moniqua achieves 85% training accuracy while other baselines are below70% (full precision achieves 97%). Compared to the theoretical results in Section 4, we show thatMoniqua is much more robust to low-bits budget in practice.
Figure 3: Performance of applying Moniqua onD2 and AD-PSGDwith 3-bit communication Moniqua achieves 85% training accuracy while other baselines are below70% (full precision achieves 97%). Compared to the theoretical results in Section 4, we show thatMoniqua is much more robust to low-bits budget in practice.
Figure 5:	More statistics from Experiment of Aggressive Quantization under 3-bit communication(a) Training Accuracy under differ- (b) Test Accuracy under different (c) Test Loss under different algo-ent algorithms with 2-bit communi- algorithms with 2-bit communica- rithms with 2-bit communicationcation	tionFigure 6:	More statistics from Experiment of Aggressive Quantization under 2-bit communicationC.5 Decreasing Step Size and Consensus ErrorIn this subsection, we provide more experimental results with decreasing step size. We also provideand discuss results on consensus error in this experiment. We run the experiments in the followingsetting:Models, Datasets and Hyperparameters. We launch 8 workers connected using a ring network.
Figure 6:	More statistics from Experiment of Aggressive Quantization under 2-bit communicationC.5 Decreasing Step Size and Consensus ErrorIn this subsection, we provide more experimental results with decreasing step size. We also provideand discuss results on consensus error in this experiment. We run the experiments in the followingsetting:Models, Datasets and Hyperparameters. We launch 8 workers connected using a ring network.
Figure 7: Test Accuracy and Consensus Error of Moniqua under decreasing step size.
Figure 8:	Test Accuracy of different algorithms on training ResNet110 on CIFAR10.
Figure 9:	Consensus Error of Moniqua with different number of bits.
