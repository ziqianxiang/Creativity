Figure 1: Illustration on how output distributions f(x1) and f(x2) evolve during training. Column 2:ground-truth label. Column 3: network outputs at initialization. Column 4: network outputs whentrained to converge. The value of KL(finit(x1)kfinit(x2)) in the graph is 0.053, and the value ofKL(ftrained(x1)kftrained(x2)) is 3.197.
Figure 2: Visualization of how accuracy (left), cross entropy loss (middle) and CCKL (right) on testset evolve when training VGG13 on CIFAR-10. It is clear that CCKL well indicates test accuracy andtest cross entropy loss. For more experiment results on relation between CCKL and cross entropyloss, please refer to Appendix B.
Figure 3: Visualization of how standard test accuracy (left) and average F-norm (right) of FisherInformation Matrix on test set vary during normal training and adversarial training with VGG13 onCIFAR-10 (for the same experiments on ResNet, see Appendix D). We take the nature logarithm tobetter visualize the average F-norm of Fisher information.
Figure 4: Visualization of how standard accuracyand average F-norm of Fisher information matrixon test set vary during normal training. The ex-periment is conducted with a VGG13 model andCIFAR-10 data set (for the same experiment onResNet, see Appendix D). We take the nature log-arithm to better visualize the average F-norm ofFisher information.
Figure 5: We sampled 25896 pairs of images (xi, xj) in CIFAR-10 test set (xi and xj belong todifferent categories) and visualized the distribution of KL(f(xi)kf(xj)) (left), distribution of G2(middle), and distribution of G2/KL(f(xi)kf(xj)) (right) of resnet20x1 and resnet32x10.
Figure 6: relation between CCKL and test loss of resnet20 on CIFAR-10 and CIFAR-100Table 2: e and Gi (We denote Gi = ɪητBn here.)e	1/255	2/255	3/255	4/255	5/255	6/255	7/255	8/255|KL - Gi |/KL	0.058	0.098	0135	0.170	0.202	0.234	0.263	0.290D	More Experiments on the Role of Fisher InformationWe conduct more visualization experiments about the role of Fisher information in standard perfor-mance of DNN. The results are shown in Figure 7 and Figure 8. The experiments are conducted on aresnet20 model. The same conclusion could be drawn according to our statistics.
Figure 7: Visualization of how standard accuracy and average F-norm of Fisher information matrixon test set vary during training. The experiment is conducted on a resnet20 model and CIFAR-10data set. We take the nature logarithm to better visualize the average F-norm of Fisher informationAlso, to better understand the geometry of an adversarially trained model around robust samples andnon-robust samples, we visualized the F-norm of Fisher information at correct and robust samplesand correct but not robust samples of a VGG13 model. According to our results in Figure 9, wecould see that although the overall Fisher information is small, the Fisher information around robustsamples are still significantly smaller than that of non-robust samples.
Figure 8: Visualization of how (left) standard test accuracy and (right) average F-norm of FisherInformation Matrix on test set vary during normal training and adversarial training, with resnet20 onCIFAR-10. We take the nature logarithm to better visualize the average F-norm of Fisher informationFigure 9: Distribution of F-norm of Fisher information at robust and non-robust samples on CIFAR-10test set.
Figure 9: Distribution of F-norm of Fisher information at robust and non-robust samples on CIFAR-10test set.
