Figure 1: Schematic representation of latent canonicalization: Colored paths correspond to different com-ponents of the loss (cyan: classification, green: bypass, red: canonicalization). Four possible canonicalizations(two individual and two pairs) are shown along with example simulated SVHN images and reconstructions.
Figure 2: Canonicalization of dsprites images: Input dsprites images (left), reconstructions of inputs withone factor canonicalized (middle), and rotation, scale, and x-position canonicalized (right). Each row demon-strates how images change as a single factor of variation is altered.
Figure 3: Example targets and reconstructions ofcanonicalized simulated SVHN images.
Figure 5: Visualization of the linear properties of the representation learned by the canonicalizers. Eachrow shows the first principal component of zc(ajn)on - z for a source of variation. A clear pattern is visible forrotation (left to right tilted), and font size (small to big). 20 normally distributed samples from a batch of 1000are shown above. See appendix for a visualization of the principal components of the bypassed latent.
Figure 4: Linear decodability of factors of varia-tion. Performance of a linear decoder trained on thefrozen, pre-canonicalized representation, z for each ofthe six factors of variation. Each factor was divided intoa different number of bins for multi-class classification,such that chance is 1.6% for background and font color,33.3% for rotation, 10% for shear, and 16.7% for fonttype and size. Error bars represent mean Â± std acrossthree pre-trained networks.
Figure A1: Examples of simulated SVHN images.
Figure A2: Train error on synthetic images vs. Test accuracy on real SVHN images.
Figure A3: Comparison between the representation learned by the canonicalizers and the bypassedrepresentation. Here we show an extended version of Figure 5 also visualizing the bypassed latent code(top row). The first principal component of z does not show any obvious grouping or pattern.
