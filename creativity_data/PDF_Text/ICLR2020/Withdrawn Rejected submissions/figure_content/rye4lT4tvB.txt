Figure 1: Comparison of regular and pixel-wise adaptive dilation. Colors stands for distinct dilation.
Figure 2: Overview of a PAD kernel.
Figure 3: The top row indicates the input image and its visualized RFs and ERFs for PAD-VGG16with different conv blocks. Patches means RFs and red dots inside are ERFs. The bottom row showsthe ground truth and corresponding segemtation results. GT stands for groundtruth.
Figure 4: Mathematical expectation of dilation sampling at each pixel for individual sub-layers(from left to right: conv5-1 to conv5-3). Brighter color means higher dilation and vise versa. Theinput is the same as the one in Figure 1.
Figure 5: Activation maps for PAD-Nets with differentnumber of dilation options.
Figure 7: Semantic segmentation results on Pascal VOC 2012.
Figure 8: Semantic segmentation results from ResNet-101 and PAD-ResNet-101 on Cityscapes.
Figure 10: The training curve of large-scale image classification using PAD-Nets based on the VGG-16 and ResNet-50 .
Figure 11: Activation maps of regular DRN-C-26 (Odd rows) and PAD-DRN-C-26 (Even row) forsamples from Stanford Cars and FGVC-Airecrafts.
