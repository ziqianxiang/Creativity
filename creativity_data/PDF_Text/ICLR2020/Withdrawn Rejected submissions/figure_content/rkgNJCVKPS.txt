Figure 1: Representative images from the MURA dataset (Rajpurkar et al., 2017). (a) Normal wrist.
Figure 2: A schematic representation of the 169-layered DenseNet architecture (Huang et al., 2016)with four dense blocks. The transition layers between blocks formed by convolution and pooling areused for down-scaling the feature maps.
Figure 3: Schematic representation of an X-ray image abnormality detection and model interpreta-tion using layer-wise and class activation maps across different dense blocks. At each level, a seriesof feature maps are generated, the resolution decreases with the progress through the blocks. Coloursare mapped to represent the range of activation values with blue in the lower spectrum for near-zeroactivation and red for the highly activated features. The final output, labelled here as CAM, is afeature map that highlights the area(s) where abnormalities can be located. The regions with warmcolours indicate higher probability than the areas with cool colours.
Figure 4: Case 1: Feature extraction for a case of wrist fracture using a wrist-only pre-trained modelfor the radiograph shown in Fig. 1(d). The arrow indicates a fracture. The extraction began with anaugmented input image (a). High-level features (e.g. foreground extraction and regions of the wrist)were extracted in the earlier blocks and can be seen from the corresponding activation maps (c, d, e).
Figure 5: Feature extraction from an image with screw fixation at the wrist. The fixation could beidentified as early as the initial convolution (c). However, the fixation was always coupled with thetext legend in all feature maps. Separation of these two objects was attempted in subsequent blocks(d - g). It can be observed that only the screw fixation was found in some feature map by the endof block 4 (g). Nevertheless, the text legend remained a key feature contributing to the abnormalitydetection in the class activation map (b).
Figure 6: Feature extraction from an image with shifted scaphoid bone at the wrist joint. Theforeground and the region of wrist were extracted in the earlier blocks (c, d & e). Fine-grainedfeature extraction were attempted in block 3 and 4 (f & g). However, the model capacity in theseblocks might not be sufficient to capture the details of the bone shift.
Figure 7: Feature extraction from an image with screw fixation at the wrist with a randomly ini-tialised model. Poor foreground separation can be seen in (c). Only the text legend could be iden-tified. The poor extraction reduced the capacity of the model for extracting finer features across thesubsequent blocks(d - g). The final features were primarily spanning across the entire middle rangeof the image (g). With poor identification of the wrist, the class activation map (b) could only showthe identified feature from the text legend.
Figure 8: Feature extraction from an image with screw fixation at the wrist using a model trainedwith all extremity types. The additional trained image allowed better learning from the model toignore the text legend as abnormality. After the foreground was identified in the initial convolutionlayers (c), the model tried to separate the fixation (in blue) from the text legend (in red) by the endof block 1 (d). The refinement of the key feature (screw fixation) was made from block 2 onwards(e-g). By the end of block 4, almost all the feature maps were showing only where the fixation islocated (g). This had also been reflected in the class activation map (b).
Figure 9: Feature extraction from an image with nails implanted in a thumb. The nails could beeasily detected in a finger-only model by the end of block 1 (c & d). Refinement of key features(nails) was observed across subsequent blocks (e-g) until the thumb was the key feature extracted atthe end of block 4.
Figure 10: Feature extraction from an image where there is a misalignment of a fingertip. Themodel had taken up some capacity to separate the image frame since the initial convolution (c-g).
Figure 11: Feature extraction from a cropped image in Case 7. With the removal of the rectangularframe, the hand and finger could be identified by the end of block 1 (c & d). However, it appearedthat fine-grained features (i.e. bone structures of the fingertip) remained a challenge and irrelevantfeatures were identified across the feature maps in block 3 and 4 (f & g).
