Figure 1: (a) Schematic of the scene. (b) Example image taken by the camera. (c) Schematics ofTiler applied on the road scene case.
Figure 2: (a,d) Heatmaps of the upper bounds on the maximum error of eaCh tile over the offset-anglespaCe. (b,e) Corresponding heatmaps after subtraCting empiriCal estimates of the aCtual maximumerror. (C,f) PerCentage of the state spaCe with error upper bounds below some threshold value(Cumulative distribution).
Figure 3:	(a) 99 perCentiles of the error upper bounds and the gaps between upper and lower boundsagainst Cell size. (b) Total solving time against Cell size. (C) Example legal inputs. (d) ExampleCorrupted inputs. (e) Example inputs from new sCene.
Figure 4:	(a) Schematic for case study 2. (b) Shapes of the sign. (c) Example inputs in the boundingboxes that cause misclassification. The inputs are visualized using their values after preprocessingof the neural network. The left hand side is the ground truth label, and the right hand side is themisclassified label.
Figure 5:	Verification results over the state space for the LiDAR case study. The top row correspondsto tiling with a grid of 90×60 cells, the bottom row corresponds to a grid of 180×120 cells. Greencells indicate that the tile is verified (ei = 0); red cells indicate that we cannot verify that tile (ei = 1);orange cells indicate that the solver exceeds time limit while solving for that tile.
Figure 6: (a) Schematic of the top view of the road. (b) Schematic of the camera.
