Figure 1: We demonstrate our method on the task of visual question answering (VQA), where weexploit three types of auxiliary annotations expressed as relations between training questions. Thistask-specific knowledge (for example the equivalence of synonymous questions) provides a trainingsignal complementary to the end-to-end annotations of ground truth answers.
Figure 2: We propose a two-phase training procedure to combine task supervision with hard con-straints on learned embeddings. In the first phase, the model is trained with the end-to-end supervi-sion (task loss), regularizers that represent soft versions of the constraints, and an internal projectionof the embeddings (see text for details). In the second phase, the embedding layers are retrained witha distillation objective, using the projected embeddings as targets. The trained layers are highlighted.
Figure 3: Experiment on a toy task for sequential arithmetic (see Section 4.1). The baseline model(top left) takes in a digit and a sequence of operations, and is trained with supervision to predictthe result. We use the proposed method to exploit auxiliary annotations of equivalence betweensequences of operations from multiple training examples. This brings significant improvements inaccuracy (right plot) over the baseline and over classical techniques that use the same additionalannotations. We visualize T-SNE projections (bottom right) of the learned representations (x) ofsequences of operations from the test set with the baseline (left) and the proposed model (right; 1000points in both cases). We draw gray lines between the representations of equivalent sets operations:with the proposed method, equivalent representations are virtually identical (only one gray line isvisible).
Figure 4: We compare the proposed method with the baseline trained with reduced amounts of data.
