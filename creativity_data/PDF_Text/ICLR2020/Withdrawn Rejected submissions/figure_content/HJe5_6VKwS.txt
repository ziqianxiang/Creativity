Figure 1:  Example of the saliency maps of natural and adversarial images for the MNIST dataset.
Figure 2:  From left to right:  performance of SPD, SMD, ID and JSD in detecting adversarial ex-amples  when  trained  on  FGSM,  BIM,  MIM,  DF,  CW  and  JSMA.  Rows  correspond  to  MNIST,CIFAR-10 and ASSIRA, respectively.
Figure 3: ASSIRA, CIFAR-10, and MNIST image classifier architecture and hyper-parameters. Thefirst entry corresponds to the first layer, and the table proceeds chronologically until the last layer.
Figure  4:  Adversarial  attack  hyper-parameters.   For  the  hyper-parameters  not  listed,  the  defaultvalues in cleverhans (Papernot et al., 2016a) are used. ε is the maximum perturbation allowed andεi  is the maximum perturbation allowed in an iteration.  We use different hyperparameters for theMNIST and CIFAR-10 to ensure the attack is sufficiently strong.
Figure 5: Example of an Adversarial Image for the MNIST dataset. From top to bottom: the top rowis the set of images; the bottom row shows the size of the noise added.  Gray indicates no change,whereas white indicates that the image has been made lighter, and black indicates that the imagehas been made darker.   As MNIST images are gray-scale low-resolution images,  the adversarialperturbations are perceptible to the human eye. Nevertheless, the correct classification of the imageis         still clearly 4.  However, the classifier predicts (from left to right) the images as: 4, 9, 9 , 8, 9, 9.
Figure 6: Example of the saliency maps of natural and adversarial images for the ASSIRA cats anddogs dataset. The top row shows the input image and the bottom shows the corresponding saliencymap.   In the saliency row,  lighter colours correspond to higher saliency (black corresponds to asaliency of 0, the lowest possible value).  The classifier predicts dog for the original image and catfor the adversarial images.   Note the stark difference between the saliency masks of the originalimage and those of the adversarial examples.
Figure 7:  Examples of gradient-based saliency maps for MNIST. The first row shows the naturaland adversarial images and the second row shows their respective saliency maps. Although there areslight deviations between the saliency maps, if the maps were unlabelled, it would be unclear whichmaps belong to adversarial examples as opposed to the original image.
Figure 8:  Examples of gradient-based saliency maps for ASSIRA. The first row shows the natu-ral and adversarial images,  and the second row shows their respective saliency maps.   There areno perceptible differences between the saliency map of the original image and adversarial imagesgenerated using MIM, C&W, and DF. Further, we observe that for FGSM and JSMA, the gradientsare    all zero-valued.  This is a second drawback of using gradients– they are unstable and generateuninformative saliency maps due to underflow.
