Figure 1: Overview of AMUSED. AMUSED first encodes each sentence by concatenating embed-dings (denoted by ãŠ‰)from Bi-LSTM and Syntactic GCN for each token, followed by word attention.
Figure 2: Description of Knowledge Module.
Figure 3: Memory Module description. Thequery representation and BERT embeddingsof the context sentences is passed to the mem-ory network to capture the dialogue context.
