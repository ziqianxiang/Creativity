Figure 1: Description of the network architecture and compositons.
Figure 2: Overview of the experiment setup: (left) 3D environment with all possible objects withfive colors, two sizes and two shapes. (middle) Example trajectory for going towards the green bowl.
Figure 3:	Generalization capabilities (Figure 3a) and positioning error (Figure 3b).
Figure 4:	Effects of language and environment on generated controllers and target prediction.
Figure 5: Sensitivity to different shades of green. During training, colors were fixed as well as theillumination. Here we show the robotâ€™s ability to account for small color changes.
Figure 6: Evaluation of our approach for dynamically changing environments (a) and the ability toadhere to demonstrated trajectory shapes during interaction (b)Table 3: Average success rate for placing the object in 250 randomly generated environments.
