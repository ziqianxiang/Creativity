Figure 1: Framework of Adversarial Attribute Learning (AAL). Our adversarial training has twocompeting classifiers with shared CNN layers. The primary classifier (Ca) uses the CNN represen-tation to classify the main attribute (e.g., Straight Hair), and at the same time, the auxiliary classifier(Cb) encourages a representation not sensitive to the secondary attribute (e.g., Big Lips). In the end,the representation should be more suitable to classify the main attribute. It is intuitive, for exam-ple, that a representation that is trained invariant of lip size is better to predict hair style, as theyare totally different facial parts. To make this training possible, we re-purpose a domain adaptationtechnique called gradient reversal (see Sec.3.2).
Figure 2: Accuracy (%) on CelebA validation set. Single task is the accuracy trained with only asingle attribute. Multi-task with the most negative transfer is the accuracy trained with the attributethat empirically has the highest accuracy drop from single task training. Adversarial with the mostnegative transfer is trained with the same other attribute but with adversarial learning. AppendixTable 3 shows the original data including attribute names and the most negative attribute.
Figure 3: The correlation and the relative accuracychange for all 40 attribute pairs on CelebA valida-tion set . The correlation is computed from la-bels of an attribute pair, and the relative accuracychange is the relative difference of accuracy whentrained with multi-task versus single task learning.
Figure 4: Accuracy (%) on the DukeMTMC-attribute dataset. Single task is the accuracy trainedonly with an attribute. Except for Attribute 14, which does not have any negative transfer pair, multi-task is trained with another attribute whose negative transfer was the worst, and the adversarial oneis trained with the same negative attribute but with adversarial learning. Appendix Table 6 showsthe original data including attribute names and the most negative attribute.
