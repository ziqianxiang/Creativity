Figure 1: Adversarial Interpolation for adversarial image generation. It takes a clean image X tobe perturbed, and another distinct image χ0, performs feature extraction using the feature extractorfθ(∙) and then measures the distance in the feature space using a distance measure D. The perturbedimage is generated by minimizing the feature space distance with respect to χ0.
Figure 2: Adversarial loss curves of different models on different images under PGD attack withincreasing iterations (1→100). Each column corresponds to the loss curves generated using the sameinput image on the Natural model (top) and the Adv-Interp model (bottom).
Figure 3: Feature distribution visualization of Natural and Adv-InterP models on (top) cleanimages, (middle) PGD attack perturbed images, and (bottom) adversarial interpolation perturbedimages. It is observed that the distribution of features extracted using the Natural model changesdrastically in the presence of attacks. On the other hand, the Adv-Interp model can better preservethe feature distribution against attacks.
Figure 4: Visualization of original natural images and the perturbed images generated by ad-versarial interpolation with different number of attack steps (L) for the perturbation budget of =8.
