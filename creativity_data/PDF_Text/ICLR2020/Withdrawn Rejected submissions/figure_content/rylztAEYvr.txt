Figure 1: Illustration of our data generation process in the program synthesis setting. Given aninput-output specification, we first use our generation model to generate candidate programs, andthen select correct programs using our external filter. Images of input-output specification and theprogram A are from Bunel et al. (2018).
Figure 2: Illustration of molecular optimization. Molecules can be modeled as graphs, with atomsas nodes and bonds as edges. Here, the task is to train a translation model to modify a given inputmolecule into a target molecule with higher drug-likeness (QED) score. The constraint has twocomponents: the output Y must be highly drug-like, and must be sufficiently similar to the input X .
Figure 3: Left: QED success rate vs. Chemprop predictorâ€™s RMSE with respect to ground truthon test set. The red line shows the performance of the (unaugmented) VSeq2Seq baseline. Right:Same plot for DRD2. In each plot, the far left point with zero RMSE is obtained by reusing theground truth predictor, while the second-from-left point is the Chemprop predictor we use to obtainour main results. Points further to the right are weaker predictors trained for fewer epochs and withless capacity, simulating a scenario where the property is more difficult to model.
Figure 4: Top-1 generalization accuracy ofMLE+ model on validation set of Karel taskacross different epochs.
Figure 5: Left: QED success rate for VSeq2Seq+target augmentation. Right: Same plot for DRD2.
