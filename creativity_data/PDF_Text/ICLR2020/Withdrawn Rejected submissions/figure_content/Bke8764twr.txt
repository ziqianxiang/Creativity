Figure 1: Average face images across each shade category (first row), average SalienCy map of thetrained baseline (second row), and BR-Net (third row) color-coded with the normalized saliencyvalue for each pixel. BR-Net results in more stable patterns across all 6 shade categories. The lastcolumn shows the tSNE projection of the learned features by each method. Our method results ina better feature space invariant to the bias variable (shade) while the baseline shows a clear patternaffected by the bias. Average accuracy of per-shade gender classification over 5 runs of 5-fold cross-validation is shown on each average map. The models are pre-trained on ImageNet and fine-tunedon GS-PPB. BR-Net is not only able to close the gap of accuracy for the darker shade but it alsoregularizes the model to improve per-category accuracy.
Figure 2: BR-Net architecture: FE learns features, F, that successfully classify (C) the input whilebeing invariant (not correlated) to the bias variable(s), b, using BP and the adversarial loss compo-nent, -λLbp, which is based on correlation coefficient. Forward arrows show forward paths whilethe backward dashed ones indicate back-propagation with the respective gradient values.
Figure 3: Comparison of results on the synthetic dataset. Color indicates the value of σB.
Figure 5: Accuracy, true negative, and true positive rates of the HIV diagnosis experiment, as afunction of the number of iterations for (a) the 3D CNN baseline, (b) BR-Net. The results showthat our adversarial training with a correlation loss function is robust against the imbalanced agedistribution between HIV and CTRL subjects and achieves balanced prediction for both cohorts.
Figure 6: tSNE visualization of the learned features by (a) the 3D CNN baseline and (b) our BR-Net.
Figure 7: Accuracy of gender prediction from face images across all shades (1 to 6) of the GS-PPBdataset with two backbones, (left) VGG16 and (right) ReSNet50. BR-Net consistently results inmore accurate predictions in all 6 shade categories by injecting bias-resilience into the model.
Figure 8: tSNE visualization of the learned features by (a) the VGG16 baseline, (b) a multi-taskbaseline, and (c) our BR-Net. Each point shows an image in the dataset color-coded with ‘shade’.
