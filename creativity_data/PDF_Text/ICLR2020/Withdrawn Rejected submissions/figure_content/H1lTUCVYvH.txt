Figure 1:  (Top) In LILAC, data is virtually partitioned into either S : Seen or U : Unseen.  Dataunder S use their ground-truth labels while data in U use a designated fixed unseen label. (Bottom)Illustration of the evolution of data partitions in the incremental label introduction phase for a fourlabel dataset.  In the first incremental step, only one label is used for training while the remainingdata use label 4.   A short period of training is performed with this fixed setup,  where data fromU is uniformly sampled to match the number of samples from S, in every mini-batch.  The finalincremental step depicted is equivalent to batch learning since all the labels are available to thenetwork.  Once all the ground-truth labels are revealed we begin the adaptive compensation phasedescribed in Sec. 2.2.
Figure 2: Side-by-side comparison between the representation spaces learned by LILAC and batchlearning. Through the entire incremental label introduction phase, the representation space evolvesto being more well spaced.  Images in column 4 and 5 show comparable points in training spacewhen all labels are available to the deep network being trained. These images support our claim thatthe deep network starts at a better initialization than standard batch learning, whose effect is carriedthroughout the training process.
