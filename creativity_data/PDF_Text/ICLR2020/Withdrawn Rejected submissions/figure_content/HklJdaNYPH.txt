Figure 1: On the left panel, the standard transformer layer is composed of a self-attention sublayerfollowed by a feedforward sublayer. On the right panel, our all-attention layer merges the weights ofthe feedforward sublayer with the self-attention sublayer. We represent both models in the case of asingle head, but in the general case, both the self-attention sublayer and our all-attention layers havemultiple heads.
Figure 2: The performance of our large model on Text8 as We vary (left) the number of persistentvectors, or (right) the way how persistent vectors integrate with self-attention.
Figure 3: Sample attention maps from our model that trained on the WikiText-103 dataset. The 4plots correspond to 4 different attention heads in the model. The Y -axis is different samples from ashort sequence, and the X -axis shows all the vectors in the attention. The first 2048 vectors comefrom the context, and the remaining 2048 are persistent vectors. In the top 2 heads, few persistentvectors are dominating the attention, although the 2nd head has some attention weights in the contextpart as well. The 3rd head has more diverse activations on the persistent vectors, while also attendingto very recent context. The last head is mostly attending to about last 500 tokens in the context, butthere are some activations in the persistent vectors.
Figure 4: Training of baseline Transformer models on WikiText-103 dataset.
