Figure 1: Main comparison: Our proposed method, DPLTM (red line) significantly outperforms ourcompetitor, DPSGD (blue line) on all datasets and for all privacy budgets. The non-noisy model(provided as an upper bound on the performance achievable using this architecture) is presented asthe green line. Error bars on the plot represent the standard deviation.
Figure 2: Convergence vs the number of epochs for DPLTM and DPSGD. Red line is our proposedmethod (DPLTM), the blue line is the competitor (DPSGD). The X-axis shows the number of epochsand Y-axis shows the accuracy on the test set. “Inset” plots show the zoomed version of the high-lighted area to focus on the plot region when privacy consumption is low. Black dots on the zoomedversion signify the points where both models have consumed privacy, = 0.3. We can observe thatDPLTM converges much faster compared to DPSGD with a significant performance difference.
Figure 3:	DPLTM transfer across similar architectures. Red line (DPLTM) is our method, whereasblue line (DPSGD) is the competitor. We can see as the privacy cost increases, our method, trainedon a ticket from Kuzushiji-MNIST, outperforms DPSGD by a significant margin.
Figure 4:	DPLTM transfer across different datasets and domains. We observe that as the privacycost increases, our method (DPLTM, red line), significantly outperforms DPSGD (blue line)A.2 Comparison with random ticketsOne of the questions a reader might have is “What is the impact of using our score function forselecting a winning ticket?”. That is, are we doing much better than using a randomly selectedticket. We use this section to explore this question empirically. We use the tightest reported privacybudget ( = 0.2), and we compare the average accuracy achieved by our proposed method using the“winning tickets” compared to a randomly selected ticket.
