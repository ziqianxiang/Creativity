Figure 1: Schemes of singing voice generation; the strength of condition decreases from left to right.
Figure 2: A pipeline for building the accompanied singer. We use source separation to get separatedsinging voice and accompaniment from professionally recorded audio files. Then, we use the sep-arated tracks to train the generators and discriminators in the GAN. In inference time, we feed anunseen accompaniment to the trained singer model and let it “sing.”sing over an accompaniment track. For diversity and artistic freedom, we cannot ask the machine togenerate any specific singing voice in response to an accompaniment track, even if we have paireddata of vocal and accompaniment tracks. We investigate using conditional GAN (Mirza & Osindero,2014) to retain the possibility of generating singing voices with multiple modes.
Figure 3: Samples of spectrograms generated by our accompanied singers: (left) the given accom-paniment tracks, the voices generated by (middle) the female singer and (right) the male singer.
Figure 4: Samples of spectrograms generated by our (left) free singers and (right) solo singers. Wecan see salient pitch contour in the spectrograms. Moreover, the pitches sung by the male singersseem on average lower than those sung by the female singers.
Figure 5: Loss trends of different GAN losses. BEGAN comes with a convergence metric (Berthelotet al., 2017) which can be used to examine how well the model converges.
