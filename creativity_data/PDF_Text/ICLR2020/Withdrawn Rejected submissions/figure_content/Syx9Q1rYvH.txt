Figure 1: Left. Point-mass environment with distractors. Right. As a function of the number of the distractors,we plot the accuracy of the regression to the position of the point-mass when regressing from the latentrepresentation learned by a variational autoencoder (VAE) and when regressing from the latent representationlearned by contrastive predictive coding (CPC). Even in simple domains the reconstruction based objective forlearning representations (VAE) discards the information needed for modelling the dynamics of the system, whilethe mutual information objective preserves it.
Figure 2: Probabilistic graphical model of thePOMDP. The only variables observed (shadednodes) are the actions, observations (high-dimensional images), and rewards. Our model hasing process of the POMDP and successfully use this to infer the latent space (dashed lines) as well as torepresentation for control, we learn four functions: model the conditional probabilities (solid lines).
Figure 3: Proposed architecture that optimizes the MIRO objective. The shaded variables are observed, whilethe unshaded are latent, the yellow nodes represent parametric functions. The observation ot is fed into theencoder resulting in the intermediate latent variable zt. Together with the prior on the latent state St constitutethe input of the filter, modelled as a feed-forward neural network. The filtered state St and action at is passedthrough the dynamics model, which is a recurrent neural network, to obtain the predicted (prior) latent for thenext state ^t+ι. The dashed lines denote the variables between which we maximize the mutual information.
Figure 4: An example trajectory of Cheetah environment with distractors. The distractor objects (red sphereand green cube) are placed at a random position at each time step.
Figure 5: Learning curves of MIRO and PlaNet on environments with and without distractors. y-axis plots thecumulative reward while x-axis plots number of rollouts collected. All curves represent mean and the shadedarea represents one standard deviation among 3 seeds. MIRO’s performance remains unchange in the presence ofdisctractor objects in the environments while PlaNet is drastically affected by such objects. When no distractorsare present in the scene both approaches have comparable performance.
Figure 6: Normalized different in the latent variablewhen encoding the same observation with and withoutdistractors. MIRO learns representations that are invari-ant to distractors, resulting in lower difference, while theembedding learned by the sequential VAE fails to cap-ture the relevant aspects of the dynamics despite beingtrained jointly with the dynamics.
Figure 7: Learning curve of MIRO and an ablated version without MI objective.
Figure 8: Comparison of deterministic latent space and stochastic latent space.
Figure 9: Different ways of conditioning the context vector on actions.
