Figure 1: (1a) Cross-correlation between the activations in the first layer of a TinyTen model forCIFAR100. The plot on the left uses the original indices of the second network, while the plot onthe right uses the reindexing of the second model consistent with alignment to the first. Note thediagonal of the second matrix is much more positive than the first matrix, which implies a meaning-ful correspondence between aligned units. (1b) The mean cross-correlation between correspondingunits for each layer before and after alignment. The standard deviation of this correlation signatureover a set of different network pairs is displayed. This shows that the quality of the correspondencebetween the average pair of units at each layer can be strongly improved through alignment.
Figure 2: Test loss (left) and accuracy (right) of the learned quadratic Bezier curve between modelendpoints trained on CIFAR100. Results are compared for aligned (blue) and unaligned (green)curves. This shows that aligned curves have better generalization performance and do not sufferfrom large drops in accuracy typical for unaligned curves.
Figure 3: Test accuracy on CIFAR100 across the plane containing θ1, θ2, and Palθ2, where Palis determined using neuron alignment. This plane contains the two different intializations used inour curve finding experiments. The default initialization, θ2 - θ1 , and the aligned initialization,Palθ2 - θ1. This shows that the aligned initialization is notably better.
Figure 4: Test accuracy on CIFAR100 across the plane containing the bezier curve, rφ (t).
Figure 5: The training loss and training accuracy for learning the quadratic Bezier curve betweenmodel endpoints. These are compared for aligned and unaligned curves. This shows that the trainingof aligned curves converges to lower loss value in less epochs than the training of unaligned curves.
Figure 6: Test loss(b) CIFAR10(c) STL10VGG16。2 - O1VGG16θ2-θ1on plane containing θ1θ2, andPalθ2.
Figure 7: Test accuracy(b) STL10on plane containing θ1 , θ2, and Palθ2 .
Figure 8:	CIFAR10(a) Training loss100	150	200EpochVGGl6	TinyTen	ReSNet32	VGG16100	150	200Epoch969492908886841009896949290(b) Training accuracyFigure 9:	STL10Figure 10: Log loss over a run of the proximal alternating minimization scheme on TinyTen for CI-FAR100. The scheme consists of 20 epochs of projected SGD to solve the permutation subproblem,followed by 40 epochs of SGD to solve the curve parameter subproblem. Vertical lines denote thechange in different subproblem iterations. This shows that neuron alignment provides a much betterintialization for PAM, and this permutation initialization is close to being locally optimal.
Figure 9:	STL10Figure 10: Log loss over a run of the proximal alternating minimization scheme on TinyTen for CI-FAR100. The scheme consists of 20 epochs of projected SGD to solve the permutation subproblem,followed by 40 epochs of SGD to solve the curve parameter subproblem. Vertical lines denote thechange in different subproblem iterations. This shows that neuron alignment provides a much betterintialization for PAM, and this permutation initialization is close to being locally optimal.
Figure 10: Log loss over a run of the proximal alternating minimization scheme on TinyTen for CI-FAR100. The scheme consists of 20 epochs of projected SGD to solve the permutation subproblem,followed by 40 epochs of SGD to solve the curve parameter subproblem. Vertical lines denote thechange in different subproblem iterations. This shows that neuron alignment provides a much betterintialization for PAM, and this permutation initialization is close to being locally optimal.
Figure 11: Fourier transform of CIFAR100 loss curve. Notice that the absolute value of the trans-form is lower for the aligned case at higher modes/wavenumbers. In spectral terms, this shows thatthe average aligned curve is less oscillatory than the unaligned curve. This is a rigorous way tomeasure the smoothness of a curve.
Figure 12: Test loss on plane containing learned curve, rφ (t).
Figure 13: Test accuracy on plane containing learned curve, rφ (t).
Figure 14: The mean cross-correlation between units in the curve midpoint model and each endpointmodel. For context, the mean cross-correlation between the linear midpoint and each endpoint isdisplayed. Additionally, the mean cross-correlation between the curve midpoint and each endpointafter being aligned to the respective endpoint is displayed.
