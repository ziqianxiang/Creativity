Figure 1:  Image classification demo on MNIST dataset.  The CNN classifier trained with the training set ofthe original images achieves 99.15% test accuracy.  (a) Original image samples and corresponding spatiallydistorted images with the predicted labels.   (b) Original image samples.   (c) The corresponding adversarialexamples of PGD with the maximum perturbations of g = 0.3. (d) The corresponding adversarial examples ofthe attack method proposed in this paper with spatial distortions plus the maximum perturbations of g = 0.1.
Figure 2: The adversarial generator architecture of SdpAdv.
Figure 3:  Sample images and their adversarial attacks against Model A in MNIST. The predicted labels ofModel A are shown above the images. The test accuracies are copied from Table 1.
Figure 4: Sample images and their adversarial attacks against Model A in Fashion MNIST. The test accuraciesare copied from Table 2.
