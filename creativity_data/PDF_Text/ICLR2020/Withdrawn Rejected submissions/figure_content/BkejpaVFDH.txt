Figure 1: Convolution between an input f and a3×3 filter ψ evaluated at x. We denote with (∙)all the positions y in the neighborhood of x. Thisbegins by cropping the 3×3 neighborhood in fcentered at x. The filter is colored brown for clar-ity, but it can have different values. The filter iscentered in the same neighborhood by translatingit L(X) [ψ](∙). The two quantities are then mul-tiplied at each spatial position y, independently.
Figure 2: Simple self-attention with extent 3×3for an input f evaluated at x. Similarly tothe convolution (∙) denotes the neighborhood ofx. The 3×3 region around x is cropped. Thescore function then compares the center witheach neighbor. The normalized score is α(x, y).
Figure 3: Simple ASC for an input f and an affine map A with extent 3×3 evaluated at x. Asfor Figures 1 and 2, (∙) denotes the neighborhood of x. The neighborhood is first extracted fromthe input, then the affine map parameters are centered in the neighborhood of x. For each spatialposition, f is transformed affinely by L(X)[ψ](∙) and L(X)[β](∙), which results in A(X)[f](∙). Ifwe were to sum now over spatial positions, this would be an affine convolution. Nonetheless, theaffinely transformed input is now passed through the self-attention mechanism. This consists ofevaluating a similarity score between the center of the neighborhood and the neighbors α(x, y)and then multiplying the input with the score function. As a result, the ASC module can focus onthe parts of the image that contain information relevant to the center. Similarly to both previousmethods, the neighbors’ information is aggregated as the final step. Intuitively, what we get is a datadependent convolution between for the image around x.
Figure 4: ComParing the model size (in thousands of Parameters) to accuracy of several variants ofResNet29 on CIFAR10. Error bars rePresent 1 standard deviation from 8 runs. Precise numbers arein APPendix Table 2.
Figure 5: Affine Self Convolution with extent 3×3 evaluated at x. Yellow depicts the croppedregion. For clarity, the affine parameters are not depicted, just the output of the affine map. Asopposed to Simple ASC in Figure 3, here we have 3 linear transformations WQ, WK, WV , whichdo not process spatial information, just output 3 separate embeddings Q, K, V for the same inputf . Moreover, three local affine maps AQ , AK , AV are applied to each neighborhood relative to acenter x in order to process spatial information. The score α(x, y) is evaluated between the centertaken from Q and the neighbors taken from K . The score is then used to aggregate neighbors takenfrom V . This depicts how self-attention is applied in practice.
Figure 6: Comparing the model size (in thousands of parameters) to accuracy of several variants ofResNet29 on CIFAR100. Error bars represent 1 standard deviation from 8 runs. Precise numbersare in Table 1.
Figure 7: Comparing the parameter efficiency (model size) to accuracy of several variants ofResNet83 on CIFAR10. Model size is divided by 1000. These results are from only 1 run ofeach model.
