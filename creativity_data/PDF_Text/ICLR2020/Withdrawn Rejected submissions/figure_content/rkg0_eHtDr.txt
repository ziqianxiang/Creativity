Figure 1: (a) Configuration of the IMG noisy-OR model. In the first row, each 8 × 8 image represents alatent variable. Each pixel in an 8 × 8 image represents the failure probability of the latent variable with thecorresponding observed variable (white pixels correspond to failure probabilities different from 1.0). In thesecond row, each node represents an observed variable; the observed variables corresponding to the first row ofthe 8 × 8 images are shown. The edges show failure probabilities different from 1.0. (b) Samples of the IMGdata set. Each 8 × 8 image represents a sample, and each pixel represents an observed variable (white pixelscorrespond to 1).
Figure 2: Performance of the noisy-OR network learning algorithm. The plots show statistics for 500 runs ofthe algorithm with random initializations on different data sets with different number of latent variables. They-axis on the top row denotes the average number of ground truth latent variables recovered and in the bottomthe percentage of runs with full ground truth recovery. The 95% confidence intervals are shown in red bars.
Figure 3: State of the optimization process on a successful run of the noisy-OR network learning algorithmon the IMG data set with 16 latent variables. (a) The blue line (with “x”) shows the number of latent variablesmatched to the same ground truth latent variable as at the end of the optimization. The red line (with “o”) is thenegative held-out log-likelihood. The graph is truncated at 5 epochs. (b) The shapes of the latent variables after1/9 epochs, 2/9 epochs, and 3/9 epochs. (c) The shape of the latent variables after 10 epochs, 20 epochs, and30 epochs.
Figure 4: Latent variable configuration of the PLNT noisy-OR network model. Each map representsa latent variable. The regions in blue represent the observed variables for which the failure probabilityis not 1.00. The fifth latent variable, which seems to contain only Florida, also contains Puerto Ricoand Virgin Islands (not shown on map).
Figure 5: Latent variables on a successful run of the noisy-OR network learning algorithm on theIMG data set with 16 latent variables. Shown is the state of the latent variables after epochs 1/9, 2/9,3/9, 4/9, 5/9, 6/9, 8/9, 8/9, and 1.
Figure 6: Latent variables on a successful run of the noisy-OR network learning algorithm on theIMG data set with 16 latent variables. Shown is the state of the latent variables after epochs 1, 2, 3, 5,10, 20, 30, 50, and 100.
Figure 7: Latent variables recovered in successful runs (i.e. they recover the IMG latent variables)on the mismatched data sets. Below each 8 × 8 images corresponding to a latent variable, there is acolor corresponding to its prior (whiter means prior closer to 1.0). (a) Successful run with 16 latentvariables on the IMG-FLIP data set. (b) Successful run with 16 latent variables on the IMG-UNIFdata set.
