Figure 1: Model architecture for the proposed Guided-VAE algorithms.
Figure 2: Latent Variables Traversal on MNIST: Comparison of traversal results from vanilla VAE (Kingma& Welling, 2014), β-VAE (Higgins et al., 2017), β-VAE with controlled capacity increase (CCβ-VAE), Joint-VAE (Dupont, 2018) and our Guided-VAE on the MNIST dataset. z1 and z2 in Guided-VAE are controlled.
Figure 3: PCA basis learned by the secondary de-coder in unsupervised Guided-VAE.
Figure 4: Traversal of Latent Factors learned on CelebA: Column 1 shows the traversed images from no-smiling to smiling. Column 2 shows the traversed images from male to female. Column 3 transits the color.
Figure 5: (left) Classification error on CelebA training set. (right) Experts (high-performance external classi-fiers for attribute classification) prediction for being negatives on the generated images. We traverse z1 (gender)and z2 (smile) separately to generate images for the classification test. Each latent z is traversed from -3.0 to3.0 with 0.1 as the stride length.
Figure 6:	Ablation study on geometry transformation: The results here are traversed on z1 and z2 . Com-pared to (b), (a) presents little about the rotation and scaling information.
Figure 7:	Ablation study on the adversarial excitation and inhibition method for gender: The left partshows the traversed images from the supervised Guided-VAE without adversarial inhibition. The right partshows the traversed images from the supervised Guided-VAE using adversarial excitation and inhibition. Bothimages are traversed on the latent variable that is supposed to control the gender information.
Figure 8: Study on changing the percentage of the data participating in the guided sub-network:Thethree figures present the accuracy from the unsupervised Guided-VAE of which the bottleneck size is 16, 32,64 separately.
