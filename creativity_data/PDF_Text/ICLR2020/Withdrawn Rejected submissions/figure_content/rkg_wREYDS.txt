Figure 1:	Image translation tasks using (a) Star-GAN and MUNIT (1-to-1), (b) CollaGAN (n-to-1), (c) ReMIC (1-to-n), and (d) ReMIC (n-to-n). ReMIC completes the missing domain im-ages that can be randomly distributed (N -to-n,N ∈ {1, ..., n}) in the input set. It makes ourapproach a more general and flexible frameworkfor image translation tasks.
Figure 2:	Overview of the proposed n-to-n multi-domain completion and seg-mentation framework. n = 4 and twodomain data are missing in this exam-ple. Our model contains a unified con-tent encoder Ec (red lines), domain-specific style encoders Eis (1 ≤ i ≤ n,orange lines) and generators Gi (1 ≤i ≤ n, blue lines). A variety of loss wasadopted (burgundy lines), i.e., imageconsistency loss for visible domains, la-tent consistency loss, adversarial lossand reconstruction loss for the gener-ated images. Furthermore, the repre-sentational learning framework is flex-ible to combine a segmentation genera-tor GS following the content code forthe unified image generation and seg-mentation.
Figure 3: BraTS image completion results. Rows: 4 modalities. Columns: compared methods.
Figure 4: RaFD generation results. Columns:8 expressions. Rows: compared methods.
Figure 6: Random multi-domain image completion results. Rows 1-8 are input images, and rows9-16 are generated images when different numbers of input images are given. Each column demon-strates the images in one domain in the order of “neutral”, “angry”, “contemptuous”, “disgusted”,“fearful”, “happy”, “sad”, “surprised”.
Figure 7: Random multi-domain image completion results. Rows 1-8 are input images, and rows9-16 are generated images when different numbers of input images are given. Each column demon-strates the images in one domain in the order of “neutral”, “angry”, “contemptuous”, “disgusted”,“fearful”, “happy”, “sad”, “surprised”.
Figure 8: Random multi-domain image completion results. Rows 1-8 are input images, and rows9-16 are generated images when different numbers of input images are given. Each column demon-strates the images in one domain in the order of “neutral”, “angry”, “contemptuous”, “disgusted”,“fearful”, “happy”, “sad”, “surprised”.
Figure 9: Missing-domain segmentation results of three testing samples in BraTS. Every threerows show results for one testing sample. For each testing sample, we show: 1) real images withgroundtruth segmentation label, 2) nearest neighbor searched from training data with its segmenta-tion label, 3) generated images using our method and segmentation prediction when T1 is missing.
