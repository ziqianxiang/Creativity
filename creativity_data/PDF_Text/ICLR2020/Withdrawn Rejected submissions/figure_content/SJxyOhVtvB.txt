Figure 1: Image classification results on CIFAR100 showing the benefit of IEG. IEG denotes ourmethod which outperforms semi-supervised learning methods at up to a 95% noise ratio. Fully-supervised is trained with all labeled clean data. Semi-supervised is our extension of IEG for semi-supervised setting, which has the best reported results. SoTA (noisy labels) denotes the previousbest results for noise robustness (50 trusted data per class are used). The noise ratio of random labelassignment is 0.99. 10 trusted labeled data per class are available for Semi-supervised and IEG. SeeSection 3.4 for more details.
Figure 2: Analysis of λ. Top: The average λof noisy and clean labels on CIFAR10 with 40%noise. Bottom: Accuracy (w/o λ) at extremenoise ratios on CIFAR100.
Figure A1: Compared with custom learning rate decay strategy. We use the commonly acceptedsetting (also used by L2R): the initial learning rate is 0.1, the learning rate decays to previous 0.1xat 40K and 50K steps. We show the training curves on CIFAR10 with 40% uniform label noise.
Figure A2: Training curves on CIFAR100 with uniform 80% label noise under different LKL lossweight k (defined in Algorithm 1). Dotted are solid lines are train and evaluation accuracy curves,respectively. Since the noise ratio is 80%, the average training accuracy is expected to be lower than20%, otherwise the model starts to overfit. When we use a small k, the model becomes to overfit ataround 80000 iterations.
