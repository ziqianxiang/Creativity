Figure 1: Each column of plots corresponds to a dataset and a sensitive attribute of interest. In allpanels, we repeatedly split the data into training and testing sets, creating in total 100 sets of each.
Figure 2: Distributions of the predicted probabilities in the test set of the recidivism dataset areplotted for λ = 0 (left) and λ = 0.712 (right). The distributions are broken down by differentvalues of the true target label y and value of the sensitive attribute z. Besides the causal fairnessnotion We introduced in this work, We also indicate equalised odds (mv_EO), equality of opportunity(mv_EOPP) and demographic parity (mv_DP).
Figure 3: Prediction probabilities in the test set of UCI (race) for varying values of λ, indicated byp_penalty in the heading of each plot.
Figure 4: Prediction probabilities in the test set of UCI (gender) for varying values of λ, indicatedby p_penalty in the heading of each plot.
Figure 5: This reports the result for UCI (race) in the same experiment that produced Figure 1.
Figure 6: We repeated the experiment in Figure 1 changing only the fairness penalty to penalisethe ATO in all layers. There is a drop in the quality of the Pareto front estimation compared topenalising just one internal layer. Namely, more of the candidate points are dominated points in thismodified experiment where we’ve penalised ATO in all layers. It seems that we should have perhapsalso tuned for a brand new architecture given this new penalty.
