Figure 1: (a) Validation loss for BERTbase pretraining. Although hyperparameters for SGD momen-tum are finetuned, a large performance gap is still observed between SGD and Adam. (b) Validationloss for ResNet50 trained on ImageNet. SGD momentum outperforms Adamof clipped gradient methods under the same condition and prove that they obtain theoreticallyoptimal rates.
Figure 2: (a) Histogram of sampled gradient noise for ResNet50 using Imagenet dataset. (b) His-togram of samples from a sum of squared Gaussians. (c) Estimated variance of the stochastic gra-dient for Resnet50. (d) Histogram of sampled gradient nosie for BERT using Wikipedia+Booksdataset. (e) Histogram of samples from a sum of squared Î±-stable random variables. (f) Estimatedvariance of the stochastic gradient for BERT model.
Figure 3: Validation loss for BERTbase pre-training with the sequence length of 128.
Figure 4: Noise distribution in Attention and ResNet on two data sources: Wikipedia and syntheticGaussian. The noise pattern is from the interaction of both architecture and data distribution.
Figure 5: The distribution of gradient noise is non-stationary during BERT training, while it remainsalmost unchanged for ResNet training on ImageNet.
Figure 7: Tail index estimation of gradient noise in ImageNet training and BERT training.
Figure 8: Validation loss for ResNet50 trained on ImageNet. SGD outperforms Adam and ACClip.
