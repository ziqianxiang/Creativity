Figure 1: Image from the LostAndFound dataset (Pinggera et al., 2016), where two unlikely objects(storage crates) are almost entirely incorrectly predicted to be road. The Max Softmax methodclearly highlights these crates as OOD. (best viewed in colour)Many applications using machine learning (ML) may benefit from out of distribution (OOD) de-tection to improve safety. When inputs are determined to be out of distribution, the output of anML algorithm should not be trusted. A large body of research exists for detecting entire images asOOD for the task of image classification. Image-level OOD detection outputs a classification for theentire image; this coarse level of detection may be inadequate for many safety critical applications,including autonomous driving. Most of the pixels in an image taken from an onboard camera willbe in distribution (ID), i.e. an image of a road scene with cars, people, and roadway—but an unusualobject that was not part of the training set may cause only a small number of OOD pixels. Extend-ing the framework to semantic segmentation networks will allow each pixel to have an “in” or “outof” distribution classification. Applied to autonomous driving, groups of pixels classified as OODwould be considered as unknown objects. Depending on the location of the unknown objects, aplanner would then proceed with caution or hand over control to a safety driver. Another applicationis automatic tagging of images with OOD objects, which would then be sent for human labelling.
Figure 2: Average OOD prediction value of the Entropy method across all images and pixels foreach class. The classes are sorted by difference between IDD and Cityscapes from most to least, leftto right. The train class is removed as the IDD dataset doesn’t have any instances.
Figure 3: Comparison of methods on different datasets using the PSPNet architecture. The arrowon the y-axis label indicates if a larger value is better (↑) or a smaller value is better Q). Each groupof bars are labelled by the dataset used for evaluation.
Figure 4: Comparison of methods on different datasets using the DeeplabV3+ architecture. Thearrow on the y-axis label indicates if a larger value is better (↑) or a smaller value is better (1). Eachgroup of bars are labelled by the dataset used for evaluation.
Figure 5: Comparison of the Mutual Information method on an IDD dataset image, successfully pre-dicted. The top row is using the PSPNet architecture, the bottom row is using the DeeplabV3+ archi-tecture. The columns from left to right are: input image, ground truth, class prediction (Cityscapescolours), ODD prediction. The OOD prediction is masked to only cars and auto-rickshaws. Bestviewed in colour.
Figure 6: Comparison of the Entropy method on an IDD dataset image, successfully predicted. Thetop row is using the PSPNet architecture, the bottom row is using the DeeplabV3+ architecture.
Figure 7: Examples from the SUN (top row) and Cityscapes (bottom row) datasets using PSPNet.
