Figure 1: A typical pipeline for neural network training and pruningFullModelTrainedModelDeliveredPruned ModelSuch a winner sub-net is optionally fine-tuned to gain accuracy back from losing parameters inthe trimmed filters. In this work, we focus on structured filter pruning approaches, which can begenerally formulated as(ri ,r2,…,rL)= arg min L(A(r1,r2, ...,rL； W))r1 ,r2 ,...,rLs.t. C < constraints(1)where L is the loss function and A is the neural network model. rl is the pruning ratio applied tothe lth layer. During the evaluation process, given some constraints C such as targeted amount ofparameters, operations or execution latency, a group of pruning candidates can be evaluated to pick apruning ratio combination (r1,r2,…,1l)*, also referred as a pruning strategy, that allows the highestpossible inference accuracy once applied to the full-size network. All pruning candidates forma searching space and the evaluation module assesses the returned sub-nets from some searching
Figure 2: Visualization of distances of BN statistics in terms of mean values. Each pixel refers tothe distance of one BN moving mean of a channel in MobileNetVL Left: ∣∣μτ - μvai∣∣2, distancebetween global statistics and the true values. Right: distance between the adaptive-BN statisticsand the true values ∣∣μ^τ 一 μvai ∣∣2Where β and γ are trainable scale and bias terms. is a term with small value to avoid zero division.
Figure 3: Fast Neural Network Pruning (FNNP) WorkflowFigure 4 visually illustrates the relation among X1, X2, Y. Pearson Correlation Coefficient(PCC) (Soper et al., 1917) ρ(X,Y) is firstly tried to compare the correlation between P(X 1, Y)and ρ(X2, Y). Apparently, ρ(X 1, Y), shown in Figure 4 right, form a clearer trend (solid line)while the ρ(X 2, Y) (Figure 4 left) is less trendy, which is also proved by the quantitative differencebetween ρ(X1, Y) = 0.757 and ρ(X2, Y) = 0.204. However, we emphasize a positive correlationbetween accuracy vectors and particularly care about the correlation about samples with high (top-k)accuracy in pruning tasks. Therefore, we propose a correlation metric as the following:1kΦxy(k)=k Emin(i=1find(X,Y[i]),1),(5)kwhere Y[i] denotes the i-th best accuracy in Y. The function f ind(X, Y [i]) tries to insert the Y[i]into the sorted X and returns its ranking. If the ranking is outside top k, the min(*) function capsthe fraction of ：壮(X Y ⑷ with 1, otherwise the fraction item itself that accumulates within therange of 1 ≤ i ≤ k. The intuition of Equation 5 is to highlight the matched high accuracy samplesin both variables X and Y while ignoring the negative correlation as it is not expected trends in any
Figure 4: Correlation between fine-tuning accuracy and inference accuracy gained from vanillaevaluation (left), adaptive-BN-based evaluation (right) based on MobileNet V1 experiments on Im-ageNet Top-1 classification results)denotes the pruning ratio for the lth layer. R is the largest pruning ratio applied to a layer. Addi-tionally, this module is replaceable and hence updatable. Though other strategy generation methodscan be considered such as evolutionary algorithm, we found that a simple random sampling is goodenough for the entire pipeline to quickly yield pruning candidates with state-of-the-art accuracy.
Figure 5: Vanilla vs. adaptive-BN evaluation: Correlation between evaluation and fine-tuning accu-racy with different pruning ratios (MobileNet V1 on ImageNet classification Top-1 results)pipeline for 1000 random strategies. In practice, the real computation cost highly depends on theexpert’s heuristic practice of trial-and-error. The computation time for AMC (He et al., 2018c) andMeta-pruning can be long because training either an RL network or an auxiliary network itself istime-consuming and tricky. Among all compared methods, our FNNP is the most efficient methodas each evaluation takes no more than 50 iterations, which takes 10 to 20 seconds in a single Nvidia2080 Ti GPU. So the total candidate selection is simply an evaluation comparison process, whichalso can be done in no time.
