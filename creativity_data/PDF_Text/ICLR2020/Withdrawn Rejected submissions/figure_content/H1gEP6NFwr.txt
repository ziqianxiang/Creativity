Figure 2: Aggregated relative tunabilityof each optimizer across datasetsThe results are in Figure 2 and show that AdamLR performs very close to the best optimizerthroughout the HPO process and is the best till about the 60th iteration. In early stages of HPO, theSGD variants perform 10-20% worse than Adam, but improve as the HPO progresses.
Figure 8: Which optimizer for which budget? Given a tuning budget K (x-axis), the stacked areaplots above show how likely each optimizer (colored bands) is to yield the best result after K stepsof hyperparameter optimization. For example, for the IMDB LSTM problem, for a small budget,’AdamLR'is the best choice (with 〜0.8 probability), whereas for a larger search budget > 50, tuningthe additional parameters of ‘Adam’ is likely to pay off.
