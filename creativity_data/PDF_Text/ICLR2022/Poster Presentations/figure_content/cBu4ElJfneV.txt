Figure 1: Overview of the GiraffeDet which has three parts: 1) Body contains image preprocessingand lightweight S2D-chain;, 2) Heavy neck refines and fuses high-level semantic and low-levelspatial features; 3) Head predicts the bounding box and class label of exist objects.
Figure 2: Illustration of the space-to-depthtransformation. The S2D operation moves theactivation from the spatial dimension to thechannel dimensionTo verify our assumption, we conduct controlled experiments on different backbone and neck com-putation ratios in multiple object detection of the same FLOPs in Section 4. The results show thatneck is more crucial than conventional backbones in object detection task.
Figure 3: Feature pyramid network evolution design from level 3 to level 7 (P3 - P7). (a) FPN (Linet al., 2017a) introduces a top-down pathway to fuse multi-scale features; (b) PANet (Liu et al.,2018) adds an additional bottom-up pathway on top of FPN; (c) BiFPN (Tan et al., 2020) introducesa bidirectional cross-scale pathway; (d) our GFPN contains both queen-fusion style pathway andskip-layer connection. The dashed box refers to the layer in each FPN design.
Figure 4: Two link mode of skip-layer connection: (a) dense-link: the concatenation of all precedinglayers (b) log2n-link: the concatenation of at most log2l + 1 layers.
Figure 5: Illustration of cross-scale connection between PANet and our Queen-fusion in GFPN. Sand C represent summation and concatenation fusion style, and Pk denotes node in next layer.
Figure 6: mAP on all scale of object instances (pix-els) in five different models under R50 FLOPs leveland 6x scratch training, including HRNet (Sun et al.,2019a), GFocalV2 (Li et al., 2021), RetinaNet (Linet al., 2017b), FCOS (Tian et al., 2019) and our pro-posed GiraffeDet.
Figure 7: Ablation study on different backbones: a) S2D-chainwith GFPN-D11; b) ResNet-18 with GFPN-D10; c) ResNet-34with GFPN-D8; d) ResNet 18 with stacked BiFPN; e) ResNet-50 with GFPN-D7; f) DarkNet with GFPN-D4; g) ResNet-101with GFPN-D2.
Figure 8: Architecture of Space-to-depth chain. “Conv”: convolutional neural networks, “SiLU”: sigmoidLinear Units activation function, “Space-to-depth”: S2D layer, and “Bx” represents the number of S2D block.
Figure 9: Architecture comparison of stacked BiFPN and our proposed GFPN-D11.
Figure 10: Ablation study on Fusion-style analysis consists three models: 1) “Concatenation” model: Gi-raffeDet utilizes concatenation fusion style; 2) “Summation” model: GiraffeDet utilizes summation fusionstyle; 3) “Summation smilar-FLOPs” model: same FLOPs level with “Concatenation” model.
Figure 11: Inference time comparison between “ResNet + FPN” model and “S2D-chain + GFPN” model onthe same FLOPs level. Orange line denotes “S2D-chain + GFPN” and purple line denotes “ResNet + FPN”.
Figure 12: Qualitative Evaluation of different approaches for object detection on COCO dataset.
