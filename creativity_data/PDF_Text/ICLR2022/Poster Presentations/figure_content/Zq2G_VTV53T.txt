Figure 1: Explanations generated by each method for Imagenette images.
Figure 2: Comparison of Shapley value approximation accuracy across methods. Using three datasets,we measure the distance of each method’s estimates to the ground truth as a function of the number of modelevaluations. FastSHAP is represented by a horizontal line since it requires only a single forward pass. Thebaselines require 200-2000× model evaluations to achieve FastSHAP’s level of accuracy.
Figure 3: FastSHAP approximation accuracy for different value functions. Using the marketingdataset, we find that FastSHAP provides accurate Shapley value estimates regardless of the value function(surrogate, marginal, baseline), with the baselines requiring 200-1000× model evaluations to achieve Fast-SHAP’s level of accuracy. Error bars represent 95% confidence intervals.
Figure 4: Explanations generated by each method for CIFAR-10 images.
Figure 5: Imagenette inclusion and exclusioncurves. The change in top-1 accuracy as an in-creasing percentage of the pixels estimated to beimportant are excluded (top) or included (bottom).
Figure 6: FastSHAP accuracy as a function of the number of training samples. The results show thatusing more s samples per x improves FastSHAP’s closeness to the ground truth Shapley values, as does the useof paired sampling.
Figure 7: Additional inclusion and exclusion curves. The change in top-1 accuracy or average log-oddsof the predicted class as an increasing percentage of the pixels estimated to be important are excluded (left) orincluded (right) from the set of 1,000 images.
Figure 8: FastSHAP robustness to limited data. The curves are generated by training FastSHAP withvarying portions of the Imagenette dataset and evaluating the Inclusion and Exclusion AUC. Horizontal linesshow the Exclusion and Inclusion AUCs for each of the baseline methods, as reported in table 1.
Figure 9: Explanations generated by FastSHAP for 18 randomly selected CIFAR-10 images. Each col-umn corresponds to a CIFAR-10 class, and the model’s prediction (in logits) is provided below each image.
Figure 10: Explanations generated by FastSHAP for 18 randomly selected Imagenette images. Eachcolumn corresponds to an Imagenette class, and the model’s prediction (in logits) is provided below eachimage.
Figure 11: Explanations generated for the predicted class for 15 randomly selected CIFAR-10 images.
Figure 12: Explanations generated for the predicted class for 15 randomly selected Imagenette images.
