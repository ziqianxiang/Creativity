Figure 1: (Lines closer together is better for fairness, best viewed in colour) Illustration of improvedfairness / reduction in bias, as measured by the FPRs evaluated on intra-ethnicity pairs on the RFWdataset with the FaceNet (Webface) feature model. The significant subgroup bias in the baselinemethod is reduced with post-processing methods AGENDA (Dhar et al., 2020), FTC (Terhorst et al.,2020a), FSN (Terhorst et al., 2020b), and FairCal (ours). Our FairCal performs best.
Figure 2: Illustration of bias reduction. False Positives correspond to the imposter pairs above adecision threshold value. Black horizontal line: threshold which achieves global FPR of 5%; Redlines: thresholds for subgroup FPRs of 5%. The deviation of the subgroup FPRs from the global FPRis a measure of bias (red lines closer to black horizontal line is better). The baseline method is biased.
Figure 3: Examples of clusters obtained with the K -means algorithm (k = 100) on the RFW datasetbased on the feature embeddings computed with the FaceNet model: (a) Indian men with no facialhair, (b) Indian men with moustaches, (c) Caucasian women with blond hair, (d) young Asian womenwith dark hair.
Figure 4: Comparison of fairness-calibration as measured by the subgroup mean of the KS acrossthe sensitive subgroups for different values of K and different choices of post-hoc calibration methods.
Figure 5: Bias in fairness-calibration as measured by the AAD (Average Absolute Deviation) inthe KS across the sensitive subgroups for different values of K and different choices of post-hoccalibration methods. Shaded regions refer to the standard error across the 5 different folds in thedatasets.
Figure 6: Bias in fairness-calibration as measured by the MAD (Maximum Absolute Deviation) inthe KS across the sensitive subgroups for different values of K and different choices of post-hoccalibration methods. Shaded regions refer to the standard error across the 5 different folds in thedatasets.
Figure 7: Bias in fairness-calibration as measured by the STD (Standard Deviation) in the KSacross the sensitive subgroups for different values of K and different choices of post-hoc calibrationmethods. Shaded regions refer to the standard error across the 5 different folds in the datasets.
Figure 8: Global accuracy measured by the AUROC for different values of K for Baseline, FSNTerhorst et al. (2020b), FairCal, and Oracle methods. Shaded regions refer to the standard error acrossthe 5 different folds in the datasets.
Figure 9: Global accuracy measure by the TPR at different a global 0.1% FPR for different values ofK for Baseline, FSN Terhorst et al. (2020b), FairCal, and Oracle methods. Shaded regions refer tothe standard error across the 5 different folds in the datasets.
Figure 10: Global accuracy measure by the TPR at different a global 1% FPR for different values ofK for Baseline, FSN Terhorst et al. (2020b), FairCal, and Oracle methods. Shaded regions refer tothe standard error across the 5 different folds in the datasets.
Figure 11: Comparison of fairness-calibration as measured by the subgroup mean of the KS acrossthe sensitive subgroups for different values of K for Baseline, FSN Terhorst et al. (2020b), FairCal,and Oracle methods. Shaded regions refer to the standard error across the 5 different folds in thedatasets.
Figure 12: Bias in fairness-calibration as measured by the AAD (Average Absolute Deviation) inthe KS across the sensitive subgroups for different values of K for Baseline, FSN Terhorst et al.
Figure 13:	Bias in fairness-calibration as measured by the MAD (Maximum Absolute Deviation)in the KS across the sensitive subgroups for different values of K for Baseline, FSN Terhorst et al.
Figure 14:	Bias in fairness-calibration as measured by the STD (Standard Deviation) in the KSacross the sensitive subgroups for different values of K for Baseline, FSN Terhorst et al. (2020b),FairCal, and Oracle methods. Shaded regions refer to the standard error across the 5 different folds inthe datasets.
Figure 15: (Lines closer together is better for fairness, best viewed in colour) Illustration of improvedfairness / reduction in bias, as measured by the FPRs evaluated on intra-ethnicity pairs on the RFWdataset with the FaceNet (VGGFace2) feature model.
Figure 16: (Lines closer together is better for fairness, best viewed in colour) Illustration of improvedfairness / reduction in bias, as measured by the FPRs evaluated on intra-ethnicity pairs on the BFWdataset with the FaceNet (Webface) feature model.
Figure 17: (Lines closer together is better for fairness, best viewed in colour) Illustration of improvedfairness / reduction in bias, as measured by the FPRs evaluated on intra-ethnicity pairs on the BFWdataset with the ArcFace feature model.
