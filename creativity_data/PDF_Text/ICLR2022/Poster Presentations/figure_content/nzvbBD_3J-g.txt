Figure 1: Example InteL-VAE with star-like data. We consider the auto-encoding for two exampledatapoints (xi and χ2, shown in green), which are first stochastically mapped to Y using a Gaussianencoder. This embedding is then pushed forward to Z using the non-stoChastic mapping gψ, which isa radial mapping to enforce a spherical distribution. Decoding is then done in the standard way fromZ, with the complexity of the decoder mapping simplified by the induced structural properties of Z .
Figure 2: VAE learned generative distri-bution Ep(Z) [pθ(x|z)] for mixture data.
Figure 3: Prior-encoder mismatch. We train (a)a VAE with a sparse prior and (b) an InteL-VAEwith a sparse inductive bias on 2 dimensional sparsedata. Figure shows target latent distribution p(z)(blue), learned variational embeddings qφ(z∣χ) ofexemplar data (green), and data pushforward qφ(z)(red shadow) for each method. Simply replacing theprior does not help the VAE match prior structureon either a per-sample or population level, whereasInteL-VAE produces an effective match.
Figure 4: Training data and samples fromlearned generative models of vanilla-VAEand InteL-VAE for multiply-connected andclustered distributions. InteL-VAE uses[Rows 1,2] circular prior with one hole, [Row3] multiply-connected prior with two holes,and [Row 4] clustered prior. Vamp-VAE be-haves similarly to a vanilla VAE; its resultsare presented in Fig. 4.
Figure 5: Illustration of Clustered mapping whereK = 3. The CirCle represents a density isoline ofa Gaussian. Note that not all points in the seCtorare moved equally: points Close to the boundariesbetween seCtors are moved less, with points on theboundary themselves not moved at all.
Figure 6: Generated samples for MNIST-01.
Figure 7: Results on Fashion-MNIST. The left figure shows FID and sparsity scores. Lower FIDscores (1) represent better sample quality while higher sparse scores (→) indicate sparser features. Theright figure shows the performance of sparse features from InteL-VAE on downstream classificationtasks. See Appendix C.3 for details and results for MNIST.
Figure 8: Qualitative evaluation of sparsity. [Top]Average magnitude of each latent dimension forthree example classes in Fashion-MNIST; lessthan 10% dimensions are activated for each class.
