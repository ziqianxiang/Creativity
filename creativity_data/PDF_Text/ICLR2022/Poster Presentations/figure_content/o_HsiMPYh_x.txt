Figure 1: Illustration of our proposed method ATC. Left: using source domain validation data, weidentify a threshold on a score (e.g. negative entropy) computed on model confidence such thatfraction of examples above the threshold matches the validation set accuracy. ATC estimates accuracyon unlabeled target data as the fraction of examples with the score above the threshold. Interestingly,this threshold yields accurate estimates on a wide set of target distributions resulting from naturaland synthetic shifts. Right: Efficacy of ATC over previously proposed approaches on our testbedwith a post-hoc calibrated model. To obtain errors on the same scale, we rescale all errors withAverage Confidence (AC) error. Lower estimation error is better. See Table 1 for exact numbers andcomparison on various types of distribution shift. See Sec. 5 for details on our testbed.
Figure 2: Scatter plot of predicted accuracy versus (true) OOD accuracy. Each point denotes adifferent OOD dataset, all evaluated with the same DenseNet121 model. We only plot the best threemethods. With ATC (ours), we refer to ATC-NE. We observe that ATC significantly outperformsother methods and with ATC, we recover the desired line y “ x with a robust linear fit. Aggregatedestimation error in Table 1 and plots for other datasets and architectures in App. H.
Figure 3: Left: Predicted accuracy with DOC on Living17 BREEDS dataset. We observe a substantialgap in the linear fit of same and different subpopulations highlighting poor correlation. Middle:After fitting a robust linear model for DOC on same subpopulation, we show predicted accuracy ondifferent subpopulations with fine-tuned DOC (i.e., DOC (w/ fit)) and compare with ATC without anyregression model, i.e., ATC (w/o fit). While observe substantial improvements in MAE from 24.41with DOC (w/o fit) to 13.26 with DOC (w/ fit), ATC (w/o fit) continues to outperform even DOC(w/ fit) with MAE 10.22. We show parallel results with other BREEDS datasets in App. H.2. Right:Empirical validation of our toy model. We show that ATC perfectly estimates target performance asWe vary the degree of spurious correlation in target. ‘ X ' represents accuracy on source.
Figure 4: Illustration of toy model. (a) Source data at n “ 100. (b) Target data with p1s “ 0.5. (b)Target data with p1s “ 0.9. (c) Margin of xinv in the minority group in source data. As sample sizeincreases the margin saturates to true margin γ “ 0.1.
Figure 5: Failure of ATC in our toy model. Shifting the support of target class conditional ptpxinv|yqmay introduce a bias in ATC estimates, e.g., shrinking the support to c“< C) (while maintaininguniform distribution) in the target leads to overestimation bias.
Figure 6: Results with a pretrained DenseNet121 model on CIFAR10. We observe similar behaviouras that with a model trained from scratch.
Figure 7: Scatter plots for DOC with linear fit.
Figure 8:	Scatter plot of predicted accuracy versus (true) OOD accuracy. For vision datasets exceptMNIST we use a DenseNet121 model. For MNIST, we use a FCN. For language datasets, we useDistillBert-base-uncased. Results reported by aggregating accuracy numbers over 4 different seeds.
Figure 9:	Scatter plot of predicted accuracy versus (true) OOD accuracy for vision datasets exceptMNIST with a ResNet50 model. Results reported by aggregating MAE numbers over 4 differentseeds.
