Figure 1: A fruits collection example. The agents are required to cooperatively collect the three targetobjects (apple, pear, and orange) in the room as fast as possible. The whole process can be dividedinto 4 steps. In Step 1, 3 agents observe the environment and obtain the state of the visible targets. InStep 2, each agent tries to infer what other agents have seen, and which targets they shall choose asgoals. In Step 3, each agent decides whom to communicate with according to the previous inference.
Figure 2: The architecture ofToM2C for each individual. There are four key components: Observationencoder, Theory of Mind net, Message sender, and Decision maker. Each agent first receives a localobservation and encodes it with the encoder. Then it performs Theory of Mind inference to estimatethe observation of others and predict their goals. Next, it decides â€˜whom' to communicate withaccording to local observation filtered by the inferred goals of others. In the end, the planner indecision maker outputs the sub-goal according to what it observes, infers, and receives. The low-levelexecutor takes primitive actions to reach the chosen sub-goal independently.
Figure 4: The learning curve of our method with baselines and reference policies in the MSMTCscenario. The learning-based methods are all trained in the environment with 4 sensors and 5 targets.
Figure 5: The communication bandwidth of models in (a)Cooperative navigation and (b) MSMTC.
Figure 6: Analyzing the scalability in scenarios with differentsizes of cameras and targets. The left heatmap shows RToM .
Figure 7: Snapshots of the multi-sensor multi-target tracking environments with different scales.
Figure 8: An exemplar sequence in 4 sensors and 5 targets MSMTC environment. The gray circleindicates the obstacle. The arrows are rendered as solid only when the communication happens, andtransparent at other times.
