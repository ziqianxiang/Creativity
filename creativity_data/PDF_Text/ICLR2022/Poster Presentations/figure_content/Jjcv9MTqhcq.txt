Figure 1:	Visualization of feature distribution pre-trained by C.E. and LOOK on ImageNet.
Figure 2:	Comparison of LOOK and existing supervised pre-training methods. For C.E. andSupCon, they push all samples from the same class to certain centers or closer to each other, respec-tively, while LOOK only requires samples next to at most their k nearest neighbors.
Figure 3: Left: Linear fine-tuning results using different types of backbone. Right: kNN monitoringaccuracy during LOOK training with and without temperature decaying.
Figure 4: Visualization of feature distribution on ImageNet using t-SNE. We draw circles ofobvious clusters with the same colors of corresponding categories.
Figure 5: Number of positive samples in the memory queue and falling in the kNN during trainingon ImageNet, sorted by the ratio for all the classes.
Figure 6:	Visualization of randomly selected samples from classes with varying falling ratio, wherewe choose the top-2, bottom-2, and 2 middle classes as examples. We put similar samples of thesame class together with colored bounding boxes for better observation.
Figure 7:	Illustration of cases when negative samples falling closer to the query image comparedwith some positive ones.
Figure 8: Linear fine-tuning results with different temperatures, where [1.0, 0.1] indicates the tem-perature decaying from 1.0 to 0.1 linearly during the training stage.
Figure 9: Visualization of attention maps on ImageNet.
Figure 10: Visualization of attention maps on COCO.
