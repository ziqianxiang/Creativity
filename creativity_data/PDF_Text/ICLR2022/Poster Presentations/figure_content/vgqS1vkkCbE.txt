Figure 1: Visualizing VFS embeddings in an example desk rearrangement task. VFS can capture the affor-dances of the low-level skills while ignoring exogenous distractors.
Figure 2: Successful rollouts of HRL using VFS to solve long-horizon tasks in MultiRoom-6 (top) andKeyCorridor-7 (bottom) by sequentially executing multiple low-level skills (labeled under the arrows).
Figure 3: We study the zero-shot generalization by using policiestrained in KeyCorridor (a) and deploying in MultiRoom (b).
Figure 4: Overview of model-based planning with VFS. We learn a one-step predictive model for the embed-ding Zt and use random shooting with a scoring function e to find the best action to the encoded goal Zg.
Figure 5: Example rollout of model-based RL with VFS as the staterepresentation for robotic manipulation. The robot plans over multiplelow-level skills to achieve the semantic goal “move all to top-right cor-ner”. Red arrows specify the next skill planned by the model, and isoverlaid for visualization purposes only.
Figure 6: A t-SNE diagram of observations encoded by VFS, showing functionally equivalent observationsmapped to the same representation. VFS discovers clusters with (top) the arm grasping the bowl with appleand chocolate on the table, (right) bottle in arm with glass and chocolate on table; (left) sponge in arm withchocolate on the table. Note that these observations occur across independent trajectories and are unlabeled.
