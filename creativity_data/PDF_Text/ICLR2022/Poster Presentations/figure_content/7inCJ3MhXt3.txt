Figure 1: Empirical results of regret and time consumption on synthetic dataset.
Figure 2: Comparison of NPR and the baselines on the UCI datasets.
Figure 3: Comparisons of normalized rewards on LastFM & Delicious datasets.
Figure 4: Comparison of NPR and the baselines on the synthetic dataset with m = 128A.1.2 COMPARISONS UNDER DIFFERENT VALUES OF kFor the experiment in the main paper, at each round only k = 20 arms are sampled from the K = 100arm pool and disclosed to all the algorithms for selection. It is to test a more general setting inpractice, e.g., different recommendation candidates appear across rounds. In the meantime, suchsetting also introduces more practical difficulties as only a subset of arms are revealed to the agentto learn from each time. In this experiment, we report the results of the neural bandit models with12Published as a conference paper at ICLR 2022(a) h1(x) = 10-2(x>ΣΣ>x)Figure 5: Comparison of NPR and the baselines on the synthetic dataset with different k .
Figure 5: Comparison of NPR and the baselines on the synthetic dataset with different k .
Figure 6: Comparison of NPR and the baselines on the UCI datasets.
