Figure 1: Stochastic Differential Editing (SDEdit) is a unified image synthesis and editing frame-work based on stochastic differential equations. SDEdit allows stroke painting to image, imagecompositing, and stroke-based editing without task-specific model training and loss functions.
Figure 2: Synthesizing images from strokes with SDEdit. The blue dots illustrate the editing pro-cess of our method. The green and blue contour plots represent the distributions of images andstroke paintings, respectively. Given a stroke painting, We first perturb it with Gaussian noise andprogressively remove the noise by simulating the reverse SDE. This process gradually projects anunrealistic stroke painting to the manifold of natural images.
Figure 3: Trade-off between faithfulness and realism for stroke-based generation on LSUN. As t0increases, the generated images become more realistic while less faithful. Given an input, SDEditaims at generating an image that is both faithful and realistic, which means that we should chooset0 appropriately (t0 ∈ [0.3, 0.6] in this example).
Figure 4: SDEdit generates more realistic and faithful images than state-of-the-art GAN-based mod-els on stroke-based generation (LSUN bedroom). The guide in the first two rows are created byhuman and the ones in the last two rows are simulated by algorithm.
Figure 5: SDEdit can generate realistic, faithful and diverse images for a given stroke input drawnby human.
Figure 6: Stroke-based image editing With SDEdit on LSUN bedroom, CelebA-HQ, and LSUNchurch datasets. For comparison, We show the results of GAN baselines, where results for LSUNbedroom and CelebA-HQ are obtained by in-domain GAN (the leftmost 5 panels), and results forLSUN church are from StyleGAN2-ADA (the rightmost 3 panels). We observe that SDEdit is ableto produce more faithful and realistic editing compared to the baselines.
Figure 7: SDEdit is able to achieve realistic while more faithful editing results compared to tradi-tional blending and recent GAN-based approaches for image compositing on CeIebA-HQ. Quanti-tative results are reported in Table 3.
Figure 8: Analysis on the quality of user guide for stoke-based image synthesis. We observe thatSDEdit is in general tolerant to different kinds of user inputs.
Figure 9: Analysis on the quality of user guide for stoke-based image synthesis. We observe thatSDEdit is in general tolerant to different kinds of user inputs.
Figure 10: Flexible image editing on closing eyes with SDEdit.
Figure 11: Flexible image editing on mouth with SDEdit.
Figure 12: Extra analysis on t°. As to increases, the generated images become more realistic whileless faithful.
Figure 13: Comparison with SC-FEGAN (Jo & Park, 2019) on stroke-based image synthesis andediting. We observe that SDEdit is able to generate more realistic results than SC-FEGAN.
Figure 14: Stroke-based editing for SC-FEGAN (Jo & Park, 2019) using both stroke and extra sketchas the input guide. We observe that SDEdit still outperforms SC-FEGAN using only stroke as theinput guide.
Figure 15: Comparison with Song et al. (2021) on stroke-based image synthesis and editing. Weobserve that SDEdit is able to generate more faithful results than Song et al. (2021) without trainingan extra task-specific model (e.g., an additional classifier).
Figure 16: Post-processing samples from GANs by masking out undesired changes, yet the artifactsare strong at the boundaries even with blending.
Figure 17: The instruction shown to MTurk workers for pairwise comparison.
Figure 18: The UI shown to MTurk workers for pairwise comparison.
Figure 19: The instruction shown to MTurk workers for pairwise comparison.
Figure 20: The UI shown to MTurk workers for pairwise comparison.
Figure 21: Stroke-based image generation on bedroom images with SDEdit (VP) pretrained onLSUN bedroom.
Figure 22: Stroke-based image editing on bedroom images with SDEdit (VP) pretrained on LSUNbedroom. SDEdit generates image edits that are both realistic and faithful (to the user edit), whileavoids making undesired modifications on pixels not specified by users(C) Reverse SDE processFigure 23: Stroke-based image editing. (a) Given an image, users will first modify the image usingstroke, and provide a mask which describes the pixels covered by stroke. (b) The edited image willthen be fed into SDEdit. SDEdit will first perturb the image with an SDE, and then simulate thereverse SDE (see Algorithm 5). (c) We provide visualization of the intermediate steps of reversingSDE used in SDEdit.
Figure 23: Stroke-based image editing. (a) Given an image, users will first modify the image usingstroke, and provide a mask which describes the pixels covered by stroke. (b) The edited image willthen be fed into SDEdit. SDEdit will first perturb the image with an SDE, and then simulate thereverse SDE (see Algorithm 5). (c) We provide visualization of the intermediate steps of reversingSDE used in SDEdit.
Figure 25: Image compositing on CelebA-HQ images with SDEdit. We edit the images to havebrown hair. The model is pretrained on FFHQ.
Figure 26: Image compositing on CelebA-HQ images with SDEdit. We edit the images to wearglasses. The model is pretrained on FFHQ.
Figure 27: Image compositing on CelebA-HQ images with SDEdit. We edit the images to haveblond hair. The model is pretrained on FFHQ.
Figure 28: Image compositing results with SDEdit (VE) on CelebA-HQ (resolution 1024×1024).
Figure 29: Stroke-based image editing results with SDEdit (VE) on CelebA-HQ (resolution1024 × 1024). The SDE model is pretrained on FFHQ.
Figure 30: Stroke-based image generation with simulated stroke paintings inputs on bedroom imageswith SDEdit (VP) pretrained on LSUN bedroom dataset.
Figure 31: Stroke-based image generation with simulated stroke paintings inputs on church imageswith SDEdit (VP) pretrained on LSUN church outdoor dataset.
Figure 32: Stroke-based image generation with simulated stroke paintings inputs on human faceimages with SDEdit (VP) pretrained on CelebA dataset.
Figure 33: Trade-off between faithfulness and realism shown with stroke-based image generationwith simulated stroke painting inputs on church images with SDEdit (VP) pretrained on LSUNchurch outdoor dataset.
Figure 34: Class-conditional image generation from stroke paintings with different class labels bySDEdit (VP) pretrained on ImageNet.
Figure 35: Stroke-based image generation with stroke inputs on cat and horse images with SDEdit(VP) pretrained on LSUN cat and horse dataset. Notice that for coarser guide (e.g. the third row),We choose to slightly sacrifice faithfulness in order to obtain more realistic images by selecting alarger t0 = 0.6, while all the other images are generated with t0 = 0.5.
