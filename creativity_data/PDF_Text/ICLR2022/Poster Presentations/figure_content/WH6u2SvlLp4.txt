Figure 1: An overview of our proposed framework, where “pool” operation including mean, sum, max orsimilar. We compute the representation hj for set j using the summary network in Equation 1, which is theweight vector of the global prototypes (i.e., centers) βi:K in the corresponding set.
Figure 2: Accuracy of digit sum-mation with image inputs, where allmodels are trained on tasks of length10 at most and tested on examples oflength up to 100.
Figure 3: The overview of our proposed implicit meta generative framework, where We sample thej-th distribution from training sets, feed the data points into the summary network, generate the fakesamples with the random noise and summary output as the input, discriminate the real/fake samples.
Figure 4: Parameter sensitivity of DeepSets(+POT) on point cloud classification task, with varying , whereeach object is represented as a set of N = 20 vectors.
Figure 5: Top: the convergence rate of Sinkhorn for c(x, y) = 1 - Cosine(x, y), and e = 0.1, as measured interm of marginal constraint violation J PJ PNj ∣ul+1 -UijI, where l is the iteration index and U is the scalingvariable; please see page 67 in Peyre & Cuturi (2019) for more details. Bottom: evolution of the transport planmatrix T = diag u(`) K diag v(`) computed at iteration of Sinkhorn’s iterations.
Figure 6: Examples of few-shot generation for two dimensional GaUssian distributions, where We visualize thereal samples from the true distributions (gray points) and generated samples (red points) by different models(from first to third column: CGAN, CGAN+MSE and our proposed cGan+POT), where we also plot thecontour of each Gaussian distribution.
Figure 7: Examples of few-shot generation for one dimensional Gaussian distributions, where Wevisualize the generated samples by our GAN+POT (conditioned on the test samples from the unseendistribution) and the PDF of the unseen true distribution.
Figure 8: Examples of few-shot generation for multi-distributions, where we visualize the generatedsamples (green) by our GAN+POT (conditioned on the test samples from the unseen distribution)and the PDF (red) of the unseen true distribution.
Figure 9: Examples of few-shot generation for natural images, where the images are generated by DAGAN(second column) and DAGAN+POT (third column) conditioned on 3 different categories on Oxford(flower)and animal face datasets. The FID ] scores of DAGAN and DAGAN+POT on Oxford are 97.25 and 91.78,respectively. The FIDs of DAGAN and DAGAN+POT on animal face are 139.14 and 131.51.
