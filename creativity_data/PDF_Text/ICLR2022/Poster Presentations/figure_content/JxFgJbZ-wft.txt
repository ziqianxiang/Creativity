Figure 1: VPR block architecture. Distinctinformation channels are mediated using dif-ferent deterministic variables: dτn temporal,cτn top-down, xτn bottom-up. In turn, they areused to parametrise random variable sτn .
Figure 2: Example of a three-level VPR model unrolled over five timesteps. ∙ are blockvariables as demonstrated in Fig. 1. X indicates the latest top-down context from a level above. ♦indicates that bottom-up encoding channel is open, while ◊ indicates that it is blocked.
Figure 3: Performance of VPR’s event detection system using Moving Ball and 3DSD. (ai) VPRadapts its rate of state updates to the temporal dynamics of the Moving Ball dataset, (aii) whilemaintaining the same accuracy of event detection. (b) F1 score of event detection using different setsof criteria in Moving Ball, with a comparison against VTA (Kim et al., 2019). (c) F1 score of levels2 and 3 in detecting changes in their corresponding features using 3DSD. (d) Comparison againstbaseline methods using 3DSD. Shaded regions indicate one standard deviation over 5 seeds.
Figure 4: Event discovery performance in synthetic data. Posterior noise is set to 0.0 in (a-b) and 0.4in (c). Shaded regions indicate one standard deviation over 5 seeds.
Figure 5: Layerwise rollouts using VPR. GT denotes ground-truth sequence, L1 rollouts made usinglevel 1, and so on. To produce layerwise rollouts, the model predicts the next state sτn+1 in the relevantlevel n and decodes under fixed states in all other levels. The produced rollouts illustrate model’sability to learn disentangled representations and produce accurate and feature-specific jumpy rollouts.
Figure 6: Random samples taken from the different levels of VPR. The model generates diverseimages with respect to the spatiotemporal features represented in the sampled level, while keeping allother features fixed.
Figure 7: Feature disentanglement in 3DSD. VPR with subjective timescales finds the most appropri-ate distribution of representations, in contrast to fixed-interval models.
Figure 8: Event detection mechanism relies on the computation of key variables shown in the figure.
Figure 9: Key KL-divergence values computed using the level 2 detection mechanism at differentstages of the training process using the Moving Ball dataset. Left-hand side graph shows the earlystages of the training (training iteration 500), while right-hand side the later stages (training iteration18500). In line with the described detection criteria in Section 3, if one of the blue lines falls belowthe orange line, an event is considered to be detected. As such, it can be seen that the decision-making is dominated by the CU criterion (light blue) in the early stages (left). On the other hand,as representations mature and the transition model learns, the CE criterion (dark blue) begins todominate the detection process (right).
Figure 10: Layerwise rollouts under empty temporal priors in the Moving Ball dataset. GT denotesthe ground-truth sequence, L1 level 1 rollout, and so on. (a) Decoding performed while sampling atall levels below the target level; (b) decoding is done using the means of the Gaussians for st<nr.
Figure 11: Layerwise rollouts under empty temporal priors in the 3DSD dataset. GT denotes theground-truth sequence, L1 level 1 rollout, and so on. (a) Decoding performed while sampling at alllevels below the target level; (b) decoding is done using the means of the Gaussians for st<nr.
Figure 12: Layerwise rollouts using fixed-interval VPR models with manually assigned intervals of 2,4, 6, and 8. It can be observed that the ball colour does not get entirely represented in level 2 (L2) ofthe model, in contrast to the VPR with subjective timescales in Figure 5.
Figure 13: Comparison of VPR against VTA on the task of event detection using the Bouncing Ballsdataset. (a) F1 score. (b) True-positive rate. (c) False-positive rate. Shaded region indicates onestandard deviation using 5 different seeds.
Figure 14: Random samples taken from the different levels of VPR. Similar to the analysis in Section4.2, it is evident that VPR learns to represent the position of the balls in Level 1 and their individualcolours in Level 2 of the hierarchy.
Figure 15: Average achieved F1 score against the two hyperparameters of the CU threshold: windowsize τw and threshold weight γ. Shaded region indicates one standard deviation.
Figure 16: Comparison of the difference in entropies ∖H(qch) - H(qst)∖ and cross entropies∖Eqch (logpch) - Eqst (log pst)∖ of the two competing hypotheses denoting whether or not a statechange has occurred at timestep t and layer n. Data for this graph was acquired by training multipleinstances of VPR with the Moving Ball dataset and for level n = 2.
Figure 17: Comparison between VPR and VTA event detection using random sequences from theMiniWorld Maze dataset. GT denotes the ground-truth sequence. L2 and L3 denote events that havebeen captured by the second and third level of the VPR model respectively. L2 is able to detect eventsthat correspond to colour changes, L3 detects more sparse events relating to the agent’s location inthe maze, while the VTA model detects turns between corridors. Best seen in the electronic versionof the manuscript.
