Figure 1: Blue dots and black dots show thepublic and private nodes, respectively. Dif-ferent type of interactions among entities aredepicted as directed edges among the nodeswith different colors.
Figure 2: Proposed model. Encoded observable and individualized features are fed to GNN model to updatethe node features. The output of the GNN is fed to both pθ (.) and qφ(.) encoders to provide the uncoveredinteractions among the agents. The parameter of pθ (.) and qφ(.) distributions are learned to minimize theirKL divergence. Moreover, during the training the edges are randomly drawn from the pθ (.) encoder to betteroptimize the parameters of this model. The sampled edges together with the input features are fed to the decodermodel to output the prediction at each time step.
Figure 3: Result of action conditional (left column) and goal-conditional (middle and right columns) experimentson different datasets based on minADE and minFDE for different time horizons. We can see that our modeloutperforms other model across all tasks. Specially for the goal-conditional tasks the performance of our modeldrops less than other models from the set of all agent to the other agents5.2.2	nuScenes datasetnuScenes dataset Caesar et al. (2020), is a real-world dataset for multi-agent trajectory prediction. Itconsists of 850 episodes of 20 seconds of driving, recorded at 2Hz. The dataset includes the positionsof all agents together with synchronized context information, e.g. map. We encode the contextinformation using a convolutional neural network (CNN) and use the encoded information as node inour graph that all entities have access to, similar to Li et al. (2020). This is also done for NRI anddNRI. We use 2 seconds of past trajectories and predict up to 4 seconds into the future. Individualizedfeatures are assigned to 2 agents in each scene at random. We set the goal as the last position of theagents for each horizon. Similar to the NGSIM I-80 dataset we use 4 relation types here.
