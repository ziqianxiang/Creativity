Figure 1: The visualization of reconstructed samples with synthesized feature statistics, using apre-trained style transfer auto-encoder (Huang & Belongie, 2017). The illustration of the featurestatistics shifts, which may vary in both intensity and direction (i.e., different offsets in the vectorspace of feature statistics). We also show images of “new” domains generated by manipulatingfeature statistic shifts with different direction and intensity. Note these images are for visualizationonly, rather than feeding into the network for training.
Figure 2: Illustration of the proposed method. Feature statistic is assumed to follow a multi-variateGaussian distribution during training. When passed through this module, the new feature statisticsrandomly drawn from the corresponding distribution will replace the original ones to model thediverse domain shifts.
Figure 3: The visualization on unseen domain Cityscapes with the model trained on synthetic GTA5.
Figure 4: The effects on the hyper-parameter probability.
Figure 5: Quantitative analysis on the shifts of feature statistics (mean and standard deviation) be-tween training source domains and unseen testing domain.
Figure 7: The t-SNE visualization onunseen PACS domain.
Figure 8: Comparisons with related methods. The variants produced by previous pairwise-basedmethods are restricted by the combination of chosen sample pair, while our method can generatevarious feature statistics variants with different combination of directions and intensities.
