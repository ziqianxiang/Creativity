Figure 1: (a)-(c) The process of decomposing coordinate inputs X for 2D image of size H Ã— W into 2 splitparts X(1) and X(2). (d) Baseline coordMLP architecture. N = HW coordinate inputs (X) are independentlyfed into the MLP. (e) Our CoordX architecture. The initial layer is split up into separate branches for eachdecomposed coordinates X(1) and X(2) . After shared FC layers, the split features are fused and the fusedfeatures are then fed into a few FC layers to generate the final signal values. M is the size of the hiddenfeatures.
Figure 2: CoordX learns the image decomposition. (a) The fully split coordX architecture. The fusion operatordirectly generates the predicted signal. R is the dimension reduced by the summation after the outer product.
Figure 3: Comparing inference speed. (a) average inference time for the SIREN model for a synthetic imageon different resolutions; (b) millisecond per frame to represent a synthetic video with 100 frames on differentresolutions with PE models; (c) inference time of a grid of coordinate points for marching cubes to display 3Dshapes; SIREN models are used.
Figure 4: An illustration of our point sampling strategy in 2-D space. The data scale is S1, S2 onthe first and second dimensions, our new sampling strategy ensures that the proportions of samplesalong each coordinate dimension are exactly the same and can be split along each dimension.
Figure 5: Qualitative results for the image fitting task. The 4 images shown are from the DIV2Kdataset, center-cropped and down-sampled to a 512x512 resolution.
Figure 6: Qualitative results for the video fitting task (the cat video).
Figure 7: Qualitative results for the video fitting task (the bike video).
Figure 8: Illustration of sampled coordinate points for volume rendering.
Figure 9: Illustration of our modified volumetric rendering.
Figure 10: Images result rendered using different ray rendering methods.
Figure 11: Images rendered using NeRF on Lego dataset.
Figure 12: Images rendered using NeRF on Ship and Drums dataset.
