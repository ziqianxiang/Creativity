Figure 1: The ConceptTransformer (CT) is a transformer module that provides concept-based inter-pretability by design. It is a drop-in replacement for the classifier head of an arbitrary deep learningclassifier and uses cross-attention to generate classification log-probabilities as additive contribu-tions from user-defined concepts that are plausible in the domain under consideration. In the figureit is used as classifier head of a patch-based architecture like a ViT or a patch-level CNN.
Figure 2: Sample-efficiency gain of using explanations at training on the MNIST Even/Odd dataset.
Figure 3: Examples of correct and incorrect predictions on MNIST Even/Odd.
Figure 4: Attention scores for spatial (part-level) and global (object-level) concepts for four correctlypredicted bird species from CUB-200-2011.
Figure 5: Diagnosing classification mistakes in CUB-200-2011.
Figure 6: Correctly and incorrectly classified samples and activated global (object level) conceptsabove the given threshold from the aPY dataset. Red labels denote attributes that are not annotatedin the ground truth.
Figure 7:	Counterfactual intervention on an exemplary CUB sample. Artificially chang-ing the color of a Cardinal from red to blue, causes an attention shifts from the concepthas_forhead-Color ::red to has_forhead-Color ::blue (among others). CorreSPond-ingly, the bird that was classified as a Cardigan is then being classified as an Indigo Bunting.
Figure 8:	Illustration of the patch-based version of the insertion metric in Petsiuk et al. (2018). Onthe left patches corresponding to a sample in CUB are inserted one by one to the image according tothe rank given by the maximal attention weight that they give to a concept until the classifier outputsthe correct classification. On the right, the patches are inserted in random order. Inserting accordingto the rank of the attention weights allows the model to recognize the bird with less insertions,indicating that the attention weights are meaningfully related to the decision. This can be used as ameasure of faithfulness captured by an insertion metric.
Figure 9: Patch-based insertion metric on CUB: inserting patches following the rank given by the at-tention scores learned by our ConceptTransformer an image has the probability of being recognizedthat reaches 50% of its maximum after 34 insertion. Random insertions on the other hand requireon average 60 insertions.
