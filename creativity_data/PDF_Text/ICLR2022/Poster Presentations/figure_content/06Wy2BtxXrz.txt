Figure 1: CVAE structure for learning scenario representationsCPLEX solver to collect optimal objective values {刈}N=ι of the resulting MIP problems, whichare defined by respective scenarios with the context, for only a small volume (1% ∙ M) of instancesin {Xm }mM=1. We refer to the underlying joint distribution of (ωmi , Ymi , Dm ) as DY . Then we inferthe objective values with a sub-network, which processes the GNN embedding of (ωmi , Dm ) in theencoder, such that the objective function σ is parameterized as:rψ(YmIhm) = σ(Ym;him,ψ); qφ(hm∖ωim,Dm) = g(him;ωim,Dm,φ),	⑻where him denotes the GNN embedding that is derived by qφ.
Figure 2: Errors with different values of KFLP(120; 200)Ooooo5 4 3 2 1」0J」山ωπEω><123456789 10 1112 13 1415 1617 18 19 20Number of Representatives (K)20 and thus attain solutions with varying numbers of representative scenarios. The curve of aver-age approximation errors is plotted in Figure 2. We observe that both CVAE-SIP and CVAE-SIPApersistently reduce errors towards 0 as K grows. It means that our methods are consistently attain-ing more effective representatives from scenarios, which help deliver better solutions. Meanwhile,CVAE-SIP and CVAE-SIPA outperform K-medoids with different K on both problems, especiallyon FLP (120; 200). It again verifies the merit of the learned representations for solving SIP prob-lems. The comparison between CVAE-SIP and CVAE-SIPA implies that though CVAE-SIPA issuperior to CVAE-SIP at the early stage of the curve, i.e., K=1,. . .,3, they are on par with each otherwhen more representatives are used eventually.
Figure 3: Objective prediction against latent representations (NDP)Figure 4: Objective prediction against latent representations (FLP)1)	D0: for each instance, the lower bound of Uniform demands is determined by the smaller value ofthe average opening and shipping cost in the context; 2) D1: the lower and upper bounds of Uniformdemands are determined by the smaller and larger value of the average opening and shipping cost,respectively. We generate 50 instances for each dependency. From the lower half of Table 5, weobserve that our methods outperform learning based baselines except the cases with K=3, whereCVAE-SIP loses its advantage over a few baselines. Generally, it indicates that our methods possessfairly good generalization abilities to the setting where scenarios depend on the contexts.
Figure 4: Objective prediction against latent representations (FLP)1)	D0: for each instance, the lower bound of Uniform demands is determined by the smaller value ofthe average opening and shipping cost in the context; 2) D1: the lower and upper bounds of Uniformdemands are determined by the smaller and larger value of the average opening and shipping cost,respectively. We generate 50 instances for each dependency. From the lower half of Table 5, weobserve that our methods outperform learning based baselines except the cases with K=3, whereCVAE-SIP loses its advantage over a few baselines. Generally, it indicates that our methods possessfairly good generalization abilities to the setting where scenarios depend on the contexts.
