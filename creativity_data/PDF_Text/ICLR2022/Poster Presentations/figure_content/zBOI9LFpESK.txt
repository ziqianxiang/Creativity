Figure 1: Architecture of our AMBS framework. The dotted arrow represents the regression targetand the dash arrow means stop gradient. Left: the learning process of meta-learner. Right: the modelarchitecture for SAC with adaptive weight c which is jointly learned with SAC objective.
Figure 3: (a) Pixel observations of DMC suite with original background. (b) Pixel observations ofDMC suite with natural video background. Videos are sampled from Kinetics (Kay et al., 2017).
Figure 4: Training curves of AMBS and comparison methods. Each curve is average on 5 runs.
Figure 5: Training curves of AMBS and comparison methods on natural video background setting.
Figure 6: Ablation Study on cheetah-run (left)and walker-walk (right) in natural video setting.
Figure 7:	Transfer from walker-walk to (left)walker-run and (right) walker-stand.
Figure 8:	(a) Illustration of a third-person view in “Town4” scenario of CARLA. (b) A first-personobservation for RL agent. It concatenates five cameras for 300 degrees view .
Figure 9: CARLA simulation.
Figure 10: The regression losses over RL environment steps among DBC and AMBS.
Figure 11: The value of combination weight cover environment steps. AMBS is trained onDMC on Original background.
Figure 12: The value of combination weight cover environment steps. AMBS is trained onDMC on video background.
Figure 13: Norms of state embeddings: n- ∣∣φr (s)∣∣ι and nɪ- ∣∣φd (s)∣∣ι∙17Published as a conference paper at ICLR 2022C.4 Sharing Encoders Between Actor and CriticIn AMBS, we share only the convolutional layers φ of encoders between actor and critic network.
Figure 14: Training curves of different ways of sharing encoder. Experiments on Walker-Walk withnatural video background.
Figure 15: Training curves of AMBS and comparison methods. Each curve is average on 3 runs.
Figure 16: Training curves of AMBS and comparison methods on natural video background setting.
Figure 17: Training curve on CARLA environment.
