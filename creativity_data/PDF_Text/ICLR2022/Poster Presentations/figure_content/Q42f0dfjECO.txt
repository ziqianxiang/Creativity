Figure 1: An illustration of our framework. First, the model is pre-trained on a large, public dataset.
Figure 2: Test accuracy (in %) of fine-tuning the RoBERTa-Base model on MNLI and SST-2 withvarious choices of Îµ.
Figure 3: Test accuracy (in %) of fine-tuning RoBERTa-Base with differentially private LoRA onthe SST-2 dataset. Our algorithm performs well on a wide range of hyperparameters.
