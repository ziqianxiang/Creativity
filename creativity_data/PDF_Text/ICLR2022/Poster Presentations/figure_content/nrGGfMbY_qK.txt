Figure 1: i-Blurry-N -M split. N% of classes are partitioned into the disjoint set and the rest intothe BlurryM set where M denotes the blurry level (Aljundi et al., 2019c). To form the i-Blurry-N-M task splits, we draw training samples from a uniform distribution from the ‘disjoint’ or the‘BlurryM’ set (Aljundi et al., 2019c). The ‘blurry’ classes always appear over the tasks whiledisjoint classes gradually appear.
Figure 2:	Comparison of AAUC with Aavg. (a) online version ofRM (Bang et al., 2021) (b) proposedCLIB. The two-stage method delays most of the training to the end of the task. The accuracy-to-{#of samples} plot shows that our method is more effective at any time inference than the two-stagemethod. The difference in Aavg for the two methods is much smaller than that of in AAUC, implyingthat AAUC captures the effectiveness at any-time inference better.
Figure 3:	Overview of the proposed CLIB. We compute sample-wise importance during training tomanage our memory. Note that we only draw training samples from the memory whereas ER basedmethods draw them from both the memory and the online stream.
Figure 4: Accuracy-to-{number of samples} for various CL methods on CIFAR10, CIFAR100,TinyImageNet and ImageNet Our CLIB is consistent at maintaining high accuracy throughout in-ference while other CL methods are not as consistent.
Figure 5: Accuracy-to-# of samples curve for the blurry setup (no new classes are encountered afterthe first task). We can see that there is no performance drop for all methods because no new classesare encountered after the first task.
