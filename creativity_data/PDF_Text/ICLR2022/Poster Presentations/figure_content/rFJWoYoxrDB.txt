Figure 1: The darts cell. The solid black arrows de-note the concatenation at output which is fixed. Thegray dashed arrows denote the 14 potential operationlocations. In a valid darts cell, 8 of which are filledby one out of the seven candidate primitives listed to theright, while the other 6 spots are disabled.
Figure 2: The top archs provide agood coverage of the search spaceand are seemingly diverse: thet-SNE plot of the top 5% archs(colored markers; grouped by dif-ferent search methods. Details inApp B.1) and randomly sampledarchs in the darts search space(gray markers).
Figure 3: Distribution of (a) all and (b) important op-erations by the primitive types of the top-performingarchiectures, organised by primitive type.
Figure 4: oi distribution in (a) normal and (b) reducecells. The important operations are shown outside thegray shaded area.
Figure 5: Ground-truth changein accuracy by successively dis-abling the most/least importantops, ordered by their oi. Mediansand interquartile ranges shown;stars denote that the drop in ac-curacy is significant at p ≤ 0.01in the Wilcoxon signed-rank test.
Figure 6: Ground-truth test er-rors (i.e. not predicted bynb301) of the original archs(original), archs with reducecells set identical to their nor-mal cells (red<-nor)/normalcells set identical to their reducecells (nor<-red) and archswith normal/reduce cells fullyreplaced by skip connections(nor<-skip∕red<-skip). *denotes that the performance dis-tribution significantly differs fromoriginal at p ≤ 0.01 in theWilcoxon signed-rank test.
Figure 8: skips are only use-ful when they form residual links:in0 and in1 denote the residuallinks formed with either inputs,others denote the skip connec-tions not forming residual linksand all is the overall distributionof oi of skip connections.
Figure 9: Normal cells of various SoTA (left to right: bananas, drnas, gaea, nas-bowl, darts_pt andte-nas) architectures with the important operations highlighted (the connections to output are omitted sincethey are all identical across the darts search space). Note all cases considered are consistent with the residuallink + separable convolution patterns identified, even though the cells and search methods are very different andexcept for bananas, none of the methods here was used to generate the nb301 training set.
Figure 10: Distribution of (a) nb301 predicted and(b) actual test error of archs sampled. Random: ran-dom archs without constraints; Skip: archs with resid-ual links and otherwise randomly sampled; Prim:random archs using {s3, s5, skip} only. Prim-Skip: archs satisfying both Skip and Prim.
Figure 11: Distribution of (a) all and (b) important op-erations by the primitive type of the worst-performingcells. The gray dashed line in (a) denotes the expectednumber of occurrences if the operations are uniformlysampled in each cell.
Figure 12: Box-and-whisker plots showing the distri-bution of the operations importance in (a) normal and(b) reduce cells by primitive types. The important oper-ations by the definition of the paper are shown outsidethe gray shaded area.
Figure 13: Frequent subgraphs in the good-performing architectures ranked by ratio of supports betweenthe important subgraphs and the reference and properties of the discovered frequent subgraphs in the worst-performing architectures.
Figure 14: The nb201 (Dong & Yang, 2020) cell, whichis highly similar to the darts space but much simpler.
Figure 15: Box-and-whisker plots showing the distribution of the operation distribution in nb201 benChmarkon (a) CIFAR-10, (b) CIFAR-100 and (C) ImageNet16-120 datasets. The gray shaded areas denote the noisestandard deviation whiCh differs in eaCh dataset.
Figure 16: Distribution of the test errors on (a) CIFAR-10, (b) CIFAR-100 and (C) ImageNet of nb201architectures. Note that since nb20 1 is a tabular benchmark that exhaustively trains and evaluates all thearchitectures within its search space, all test errors reported here are actual, not predicted.
Figure 17:	Genotypes of bananas architecture (White et al., 2021)18Published as a conference paper at ICLR 2022I c-{k-1}sep_oonv_ 3x3sep_conv_3x3sep_conv_3x3di conv 5x5Sep conv 3x3sep_conv_3x3skip_conanectmax_pool_3x3dil conv 5:5sep_conv_3x3conv 5x5dil conv 5x5sep_conv_3x3skip_conniectsep_conv_5x:SeiLanvA:
Figure 18:	Genotypes of drnas architecture (Chen et al., 2021b)2sep_conv_5x 5sep conv ι3x3______________----s sep_conv_5x 5sep_conv_3x3max pool 3x3dil conv 5x5sep conv 3x3sep_conv_5x5max pool 3x3sep_conv_5x5Sep conv 3∣j{k-2} PkipjcoJect≡kip∣conuectI c∣{k-1}Sep conv. 3x3__________________________________----------------zz sep_conv_ 5x52sep_conv_5x 5
Figure 19:	Genotypes of gaea architecture (Li et al., 2021). Note that the edited genotype is identical to theoriginal normal genotype as it is already compliant with both Prim and Skip constraints.
Figure 20:	Genotypes of nasbowl architecture (Ru et al., 2021).
Figure 21:	Genotypes of noisydarts architecture (Chu et al., 2020)Skip-ConnectC {k-2} L_sep_conv_3x3sep_conv_3x3sep_conv_3x3sep_conv_3x3sep_conv_3x3c_{k-11I J{k-1}avg_Ro_3x3sep_conv_5x50sep_conv_5x5skip_connect________SkiP_Connect ___________Ie} PepScom~^	Sep_ConVqxsep_conv_3x3sep_conv_3x3SeP_ConV_3x3sep_conv_3x3
Figure 22:	Genotypes of darts_pt architecture (Wang et al., 2021c)sep_conv_5x5Sk^qnneCt, ClaLv 3xEP-ComiectSSp-CoLW_3X3sspqa_3x3Seuxnv_3x3avg Pool 3x3(a) Normalavg PooI_3x3c_{k-2}	dfl_conv_3x3dil conv 5x5dil conv 5x5avg_Pool 3x3SeP conv 5x5max pool 3x3c {k-1ldil Cenv 3x3sep_conv_5x5
Figure 23:	Genotypes of sdarts_pt architecture (Wang et al., 2021c)19Published as a conference paper at ICLR 2022max_pool_3x3sep_conv_3x3sep_conv_3x3sep_conv_3x3sep_conv_3x3dil_conv_3x3dil_conv_5I j{k-2}I c-{k-1}max pool 3x3∣7^diI-Con<5x5sep_conv_3x3avg_pool 3x3sep_conv_5x 5sep conv 5x5max_pool_3x3(b) Reduce
Figure 24:	Genotypes of sgas_pt architecture (Wang et al., 2021c)E.2 Random Genotypes sampled in the PrimSkip GroupWe show some examples of the genotypes generated via the constrained random sampling in thePrimSkip group in Sec 4 in Fig 25, while the two architectures selected for the CIFAR-10/ImageNetexperiments on the larger architectures is shown in Figs 26 and 27.
Figure 25:	Some of the randomly sampled architectures in the PrimSkip group.
Figure 26:	Randomly selected PrimSkip architecture 1 for the experiments on the larger architectures20Published as a conference paper at ICLR 2022Ooooooo5 0 5 0 5 0 57 5 2 0 7 5 2Illlωφu⊂ΦLαuuoM-o JφqlunN(a) All operationsOoooooo5 0 5 0 5 0 57 5 2 0 7 5 2Illlωφu⊂ΦLαuuoM-o JφquJnNNormal Reduce(b) Important operationsUUebOdUJ- UO-ASBdO0.0040.0030.002
Figure 28: Distribution of (a) all and (b) importantoperations by the primitive types according to the BA-NANAS surrogate. The gray dashed line in (a) denotesthe expected number of occurrences if the operationsare uniformly sampled.
Figure 29: Box plots showing the distribution of theoperations importance in (a) normal and (b) reduce cellsaccording to the BANANAS surrogate. The importantoperations by the definition of the paper are shownoutside the gray shaded area.
Figure 27:	Randomly selected PrimSkip architecture 2 for the experiments on the larger architecturesF	Reproducing Results with less training dataIn this section, we show that it is possible to reproduce many results in the paper using less than0.4% of the data compared to the full set of more than 50,000 architecture-performance pairs used inthe nb301 surrogate, thereby motivating the use of the tools introduced in this paper as a generic,cost-effective search space inspector: For the experiments conducted, we use the surrogate frombananas (White et al., 2021), which combines a neural ensemble predictor with path encoding ofthe architectures - it is worth noting that alternative surrogates may also be used, but it is preferableto use a sample-efficient surrogate that is capable of finding meaningful relations in the input datawith a modest number of evaluations. Specifically, we randomly sample 200 architectures fromthe search space and query their nb301 predicted performance as a proxy for the ground-truthperformance. We then compute the path encoding of each architecture and train a predictor with thedefault hyperparameters from White et al. (2021).
Figure 30: Regression performance of the bananas predictor with 200 training data vs the nb301 surrogatewith more than 50,000 training data.
Figure 31: Frequent subgraphs in the good-performing architectures ranked by ratio of supports between theimportant subgraphs and the reference and properties of the discovered frequent subgraphs according to theBANANAS surrogate. Note that the residual link + separable convolution patterns are highly similar to thoseidentified in Fig 7 in the main textG	Primitive Redundancies With Multiple Optimisation ObjectivesMost of the findings of the paper, including the current definition of the oi, are based on maximisingtest accuracy as the sole objective, as the majority of the existing literature on cell-based nas (atleast those surveyed in App. C) focuses on maximising performance as the primary performancemetric. However, alternative cost metrics often expressed in terms of FLOPS or number of parameters,are sometimes also incorporated as a part of the objective (e.g. maximising test accuracy whileminimising the number of parameters in the resulting architecture) especially for deployment on cost-sensitive platforms like mobile devices. This give rises to a multi-objective optimisation problem, anda reasonable question to ask is that whether some of the main findings, in particular the redundancyof primitives identified in the paper, still hold, as some of the primitives redundant or unimportantfor maximising performance might be useful for minimising costs. In this section, we show somepreliminary results that at least in terms of cost metrics like FLOPs and/or number of parameters, theotherwise redundant primitives are still rather unimportant.
Figure 32: Test errors against number of parameters (a) and FLOPs (b) of the sample architectures in the twogroups.
Figure 33: Performance of nas-bowl and darts in the constrained PrimSkip search space. The nas-bowlresults shown with mean ± std over 5 random seeds.
Figure 34: Demonstration of the frequent subgraph mining procedure in the important subgraphs. Full architec-tures shows the DAGs representing the entire search cells; Important subgraphs (the coloured subgraphs) showsthe subgraphs of each full architecture consist of only the important operations (i.e. those with an oi above somethreshold). Random subgraphs (the coloured subgraphs) act as the null reference in this case: consider a fullarchitectures G and its important subgraph gf with m edges, we randomly sample exactly m edges from eachG, possibly with multiple repetitions, to form gr , the corresponding random subgraph(s) of G.
