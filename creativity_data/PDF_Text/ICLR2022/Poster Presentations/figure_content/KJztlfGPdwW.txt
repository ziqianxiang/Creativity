Figure 1: Diagram of WGCSL in the offline goal-conditioned RL setting. WGCSL samples datafrom the offline dataset and relabels them with hindsight goals. After that, WGCSL learns a valuefunction and updates the policy via a weighted supervised scheme.
Figure 2: Visualization of the trajectoriesConnection between Goal-Conditioned RL and SL generated by GCSL (blue) and WGCSLGCSL has been proved to optimize a lower bound on (orange) in the PointReach task.
Figure 3: Goal-conditioned tasks: (a) PointReach, (b) PointRooms, (c) Reacher, (d) SawyerReach,(e) SawyerDoor, (f) FetchReach, (g) FetchPush, (h) FetchSlide, (i) FetchPick, (j) HandReach.
Figure 4: Performance on expert (top row) and random (bottom row) offline dataset of four simulatedmanipulation tasks. Results are averaged over 5 random seeds and the shaded region represents thestandard deviation.
Figure 5: Ablation studies of WGCSL in the offline setting.
Figure 6: Average estimated value (left) andperformance (right) of WGCSL, HER andDDPG. The TD target is clipped to [0, 50], thusthe maximum estimated value is around 50.
Figure 7:	Full average returns of different algorithms on (a) expert and (b) random datasets.
Figure 8:	Comparison of WGCSL, Actionable Models, HER, DDPG on offline (a) expert and (b)random datasets.
Figure 9: Normalized score across 10 tasks on (a) expert and (b) random datasets. The black dottedline refers to the normalized score of offline dataset. The value are normalized by dividing by themaximum final return of each task in Table 1. Note that the value can exceed 1 as the final returncan be lower than the return during training. The x-axis represents the training process scaled to 1for different tasks.
Figure 10:	Training time of GCSL, WGCSL, HER and Actionable Models (AM) on 4 harder tasks.
Figure 11:	Average probability of improvement on offline (a) expert and (b) random datasets. Eachfigure shows the probability of improvement of WGCSL compared to all other algorithms. Theinterval estimates are based on stratified bootstrap with independent sampling with 2000 bootstrapre-samples.
Figure 12:	Average final distance of different algorithms on offline (a) expert and (b) randomdatasets.
Figure 13: Average return of 10% offline (a) expert and (b) random dataset.
Figure 14:	Final performance comparison of full dataset and 10% dataset. Top row is the result onexpert dataset, and the bottom row is the result on random dataset.
Figure 15:	Mean success rate of online experiments with standard deviation (shaded) across 10random seeds.
Figure 16: Study of the impact of clipping exponential advantage in WGCSL in the online setting.
