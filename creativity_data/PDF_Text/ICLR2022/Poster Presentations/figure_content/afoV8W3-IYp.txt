Figure 1: An overview of our method. Red+Green: the learning pipeline of DINO (Caron et al.,2021) and EsViT (Li et al., 2021); Red+Blue: our pipeline. We introduce a concept-feature dictio-nary, where the key is a concept c and its value is a queue of image features f with the same concept,to allow flexible feature retrieval with the concept keys. With the proposed dictionary, we furtherdevelop our concept-guided global and local tasks. EMA denotes the exponential moving average.
Figure 4: Ablation study on HICO. We investigate the impact of ViT architectures, implementationof concept-feature dictionary, auxiliary tasks, and the weight Î± on the performance of our method.
Figure 5: Visual illustrations of image features against HOI categories on the HICO test set viat-SNE. We compare the features obtained by ViT without any auxiliary task (ViT-only), ViT withnon-concept auxiliary tasks (EsViT), and RelViT. Besides those clusters that are identified with theother two baselines, clusters that can only be identified with RelViT are highlighted.
Figure 6: Visualization of correspondence. The correspondence is extracted between two views ofthe same image (upper) and two images that belong to the same concept (lower), using the learnedmodel on HICO. RelViT can extract correspondence on more objects in the two images (seman-tic correspondence) setting. Best viewed on screen.
Figure 7: Histograms of concepts in GQA training set.
