Figure 1: Comparison of the deblurred images and their reblurred counterparts. For eachimage, we visualize the remaining blur kernel (Cho & Lee, 2009) at the center pixel visualizedon the right bottom side. Upper: The kernels from the previous deblurring methods implicate thedirection of the original blur. Lower: When the proposed reblurring module is applied, our resultdoes not lose sharpness as we reconstruct the output that is hard to be reblurred.
Figure 2: Overviews of the proposed reblurring and deblurring framework. Reblurring moduleMR tries to reconstruct blurry image B from a deblurred image L while preserving the sharpness ofa pseudo-sharp image S = MD(S). Meanwhile, the deblurring module MD tries to make L sharperby comparing the amplified blur from L and the sharp image S.
Figure 3: Image deblurring and reblurring illustrated from the perspective of sharpness andrealism. Training our modules with LReblur improves image sharpness without considering the imagerealism. The image realism can be optionally handled by adversarial loss LAdv.
Figure 5: The proposed self-supervised test-timeadaptation. The iterative optimization improvesthe image sharpness by finding an image that re-blurs to the current deblurred image.
Figure 6: Test-time adaption (SRN) onGOPRO dataset. Reblurring loss improvesthe trade-off between the perception (LPIPS,NIQE) and PSNR compared with the baseline.
Figure 7: Qualitative comparison between state-of-the-art deblurring methods on the GOPROdataset. We used the SRN model as a baseline architecture.
Figure 8: Qualitative comparison between different training objectives and the test-time adap-Figure 9: Qualitative comparison of deblurring results on the real-world images (Lai et al.,2016) by different loss functions and test-time adaptation. The proposed test-time adaptationgreatly improves visual quality and sharpness of the deblurred images.
Figure 9: Qualitative comparison of deblurring results on the real-world images (Lai et al.,2016) by different loss functions and test-time adaptation. The proposed test-time adaptationgreatly improves visual quality and sharpness of the deblurred images.
Figure A: The baseline U-Net architecture and the reblurring module architecture We use thesame reblurring module for all experiments except the number of ResBlocks.
Figure B: Perception-distortion trade-off from test-time adaptation applied to SRN model onGOPRO dataset.
Figure C: Perception-distortion trade-off from test-time adaptation applied to DHN model onGOPRO dataset.
Figure D:	Visual comparison of deblurred results by reblurring loss and test-time adaptationon GOPRO dataset.
Figure E:	Visual comparison of deblurred results by reblurring loss and test-time adaptationon REDS dataset.
