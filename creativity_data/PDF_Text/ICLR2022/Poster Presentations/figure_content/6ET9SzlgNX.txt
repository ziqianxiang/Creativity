Figure 1: Intrinsic robustness estimates for classification tasks on CIFAR-10 under (a) '∞ Pertur-bations with = 8/255 and (b) `2 perturbations with = 0.5. Orange dots are intrinsic robustnessestimates using the method in Prescott et al. (2021), which does not consider labels; green dotsshow the results using our methods that incorPorate label uncertainty; blue dots are results achievedby the state-of-the-art adversarially-trained models in RobustBench (Croce et al., 2020). Threefundamental causes behind the adversarial vulnerability can be summarized as imPerfect risk (redregion), concentration of measure (orange region) and existence of uncertain inPuts (green region).
Figure 2: (a) Visualization of the CIFAR-10 test images with the soft labels from CIFAR-10H,the original assigned labels from CIFAR-10 and the label uncertainty scores computed based onDefinition 4.1. (b) Histogram of the label uncertainty distribution for the CIFAR-10 test dataset.
Figure 3: Visualizations of error region label uncertainty versus standard risk and adversarial riskwith respect to classifiers produced by different machine learning methods: (a) Standard-trainedclassifiers with different network architecture; (b) Adversarially-trained classifiers using differentlearning algorithms; (c) State-of-the-art adversarially robust classification models from RobustBench.
Figure 4: Estimated intrinsic robustness based on Algorithm 1 with Y = 0.17 under (a) '∞ pertur-bations with = 8/255; and (b) `2 perturbations with = 0.5. For comparison, we plot baselineestimates produced without considering label uncertainty using a half-space searching method(Prescott et al., 2021) and using union of hypercubes or balls (Algorithm 1 with γ = 0). Robustaccuracies achieved by state-of-the-art RobustBench models are plotted in green.
Figure 5: Accuracy curves for different adversarially-trained classifiers, varying the abstaining ratioof CIFAR-10 images With high label uncertainty score: (a) Carmon et al. (2019) for '∞ perturbationswith = 8/255; (b) Wu et al. (2020) for `2 perturbations with = 0.5. Corresponding cut-off valuesof label uncertainty are marked on the x-axis With respect to percentage values of {0.02, 0.1, 0.2}.
Figure 6: Illustration of human uncertainty labels and label uncertainty of CIFAR-10 test images.
Figure 7: Illustration of misalignment label errors recognized by human and those identified byconfident learning (a) Distribution of human label uncertainty between errors and non-errors estimatedusing confident learning; (b) Precision-recall curve for estimating the set of examples with humanlabel uncertainty exceeding 0.5.
Figure 8: Visualization of label distribution of top uncertain CIFAR-10 test images estimated using aconfident learning approach. Both human and estimated label distribution are plotted in each figure.
