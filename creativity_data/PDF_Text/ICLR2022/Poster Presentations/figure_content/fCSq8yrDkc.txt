Figure 1: Left: Logical view of the main kernel. To expose sufficient parallelism to GPU, we organize threadsinto a 2D grid of blocks (3 × 2 in the figure), which allows several threads per row. The threads are thengrouped in 1D blocks (shown in red) along the columns of X. This ensures that global memory access isaligned and coalesced to maximize bandwidth utilization. We use the parameter work-size ws to indicate howmany elements of a row each thread should handle. For simplicity, this parameter represents multiples of theblock size bs. Each arrow denotes the activity of a single thread in a thread block. Memory storage is assumedto be column-major. Right: Activity of a normal working block, which handles a submatrix of size bs X (ws∙ bs).
Figure 2:	The percentage of problems solved up to various accuracy levels for σt = 5, 10.
Figure 3:	Wall-clock runtime performance versus the dimensions m = n for σt = 5.
Figure 4:	The percentage of problems solved up to various accuracy levels for MNIST.
Figure 5: The percentage of problems solved up to various accuracy for σt = 5 and ρ = 2/(m + n).
Figure 6: Objective suboptimality versus iteration for random OT instances with m = n = 512.
Figure 7: Objective suboptimality versus iteration for random OT instances with σt = 1.
Figure 8: Color transfer via DROT: The left-most image is a KMeans compressed source image (750centroids), the right-most is a compressed target image (also obtained via 750 KMeans centroids).
