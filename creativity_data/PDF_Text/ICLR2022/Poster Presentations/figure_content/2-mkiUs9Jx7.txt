Figure 1: Unsupervised conditional generation on synthetic dataset. Dataset consists of eight two-dimensional GaUSSianS (gray dots), and the number of unlabeled data instances from each Gaussiandistribution is imbalanced (clockwise from the top, imbalance ratio between the first four Gaussiansand the remaining four is 1:3). It is considered that the instances sampled from the same Gaussianshare an attribute. Dots with different colors denote the data generated from different latent codes.
Figure 2: Overview of the SLOGAN model. Here, Xg denotes the data generated from a latent vectorz, Xr is a real data that is used for adversarial learning, and C indicates a component ID of theGaussian mixture prior with the highest responsibility argmax。q(c∣z).
Figure 3: Generated high-fidelity images from SLOGAN on (a) AFHQ and (b) CelebA-HQ.
Figure 4: Performance comparison with respect tothe imbalance ratio on (a) cluster assignment and (b)unsupervised conditional generation.
Figure 5: Qualitative results of SLOGAN on CelebA.
Figure 6: Effects of attribute manipulation on unsupervised conditional generation. Left and rightimages visualize generated images from different latent components. The red boxes indicate generatedfrog images with a white background.
Figure 7: Interpolation in the latent space of the proposed method. For the MNIST and Fashion-MNIST datasets, We selected three mean vectors in the latent space and generated images fromlinearly interpolated latent vectors. For the CelebA dataset, we used 30 probe data and mixup foreach latent component with attributes such as Black hair (3:1) and Male (1:1).
Figure 8: An example where ICFID is useful. The left and right images show generated images fromeach latent code of (a) SLOGAN, (b) DeLiGAN and (c) ClusterGAN trained on the MNIST-2 (7:3)dataset, respectively.
Figure 9: Another example where ICFID is useful. The left and right images show generated imagesfrom each latent component of DeLiGAN trained on the CIFAR-2 (7:3) dataset.
Figure 10: Synthetic dataset and samples generated by SLOGAN at 0, 1000, 5000, and 10000 steps.
Figure 11: Generated samples from each latent component of SLOGAN trained on the syntheticdatasets with variances (a) 0.01I, (b) 0.05I, and (c) 0.10I.
Figure 12: Generated images from each latent component of SLOGAN trained on the MNIST dataset.
Figure 13: Generated images from each latent component of SLOGAN trained on the Fashion-MNISTdataset.
Figure 14: 3D PCA of the latent spaces of SLOGAN trained on the MNIST and Fashion-MNISTdatasets.
Figure 15: Generated images from each latent component and 3D PCA of the latent spaces ofSLOGAN trained on the MNIST-2 (7:3) dataset.
Figure 16: Generated images from each latent component and 3D PCA of the latent space ofSLOGAN trained on the FMNIST-5 dataset.
Figure 17: Generated images from each latent component of SLOGAN trained on the CIFAR-2 (7:3)and CIFAR-2 (9:1) datasets.
Figure 18: Generated images from each latent component of SLOGAN trained on the CelebAdataset. We used 30 probe data ((a) Female vs. Male, or (b) Faces without eyeglasses vs. Faces witheyeglasses) and mixup for each component.
Figure 19: Generated images from each latent component of SLOGAN trained on the CelebA-HQ(256×256) dataset. We used 30 probe data (Female vs. Male) and mixup for each component.
Figure 20: Generated images from the most recent methods including (a) CD-GAN,(b) PGMGAN,and (c) SLOGAN trained on the CIFAR-2 (7:3) dataset.
Figure 21: Generated images from each latent component of SLOGAN trained on the MNIST datasetwhere class 8 is very low fraction of the other nine classes.
Figure 22: Generated images from each latent component of SLOGAN trained on Cats and Dogs ofthe AFHQ (256×256) dataset with various imbalance ratios.
