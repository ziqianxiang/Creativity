Figure 1: (a) An illustration of deep unsupervised RGB-D Saliency detection. ‘Initial label, isgenerated by a traditional method. ‘Baseline’ shows the saliency map generated by saliency networktrained with initial pseudo-labels. ‘Ours’ shows our final results. (b) Efficiency and effectivenesscomparison over a wide range of unsupervised SOD methods on the NLPR benchmark. PromotingSaliency From Depth: our approach achieves a large-margin improvement over the baseline, byengaging depth information to improve pseudo-labels in the training process, without introducingadditional computational cost during inference, shown in red arrow.
Figure 2: Overview of the proposed method. The saliency network is trained with the iterativelyupdated pseudo-labels. The depth network and depth-disentangled network are designed to decom-pose raw depth into saliency-guided depth DSal and non-saliency-guided depth DNonSaι, whichare subsequently fed into the depth-disentangled label update (DLU) module to refine and updatepseudo-labels. The inference stage involves only the black dashed portion.
Figure 3: The internal inspections of the proposed DSU. It is observed that the updated label exhibitsmore reliable saliency signals than initial pseudo-label.
Figure 4: Analysis of the proposed attentive train-ing strategy, when evaluated on NJUD testset. The‘backbone’ refers to the saliency network trainedwith initial pseudo-labels.
Figure 5: Qualitative comparison with unsupervised saliency detection methods. GT denotes ground-truth.
Figure 6: Visual examples of the intermedi-ate pseudo-labels used in our approach. ’Initial’shows the initial pseudo-labels generated by tra-ditional handcrafted method. ‘+CRF’ refers tothe pseudo-labels after applying fully-connectedCRF. Update 1&2 represent the updated pseudo-labels produced in our pipeline over two trainingrounds. ‘GT’ means the ground truth, used forreference purpose only.
Figure 7: Detailed structure of D-Sal and D-NonSalCNNs in DSU. BN means batch normalization opera-tion.
Figure 8: Qualitative comparison with unsupervised RGB-D SOD models. GT means ground-truth.
Figure 9: Qualitative comparison of fully-supervised RGB-D SOD methods. Obviously, our fully-supervised variant infers more appealing saliency maps compared to existing SOTA models, includ-ing DCF (Ji et al., 2021a). DSA2F (Sun et al., 2021), HAINet (Li et al., 2021a), BBSNet (Fan et al.,2020b), S2MA (Liu et al., 2020), UCNet (Zhang et al., 2020a) and FRDT (Zhang et al., 2020f).
