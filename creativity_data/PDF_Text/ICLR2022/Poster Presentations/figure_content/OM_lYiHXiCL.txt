Figure 1: An illustration of the black-box hard-label backdoors.
Figure 2: The distribution of values in the normalized adversarial perturbation μ for the infected (b)and uninfected (c) labels, using a backdoor map in (a). x, y axes represent the image space; z axisrepresents the absolute value of the normalized μ corresponding to each pixel location.
Figure 3: The distributions of ad-versarial peak μmaχ for infectedlabels and uninfected labels.
Figure 4: The proportion of in-fected labels whose max{μmaχ}larger than that of uninfected ones.
Figure 5: Overview of AEVA - Adversarial Extreme Value Analysis.
Figure 6: The visualization of adversarial perturbation μ for infected labels With different backdoor attacks onTinyImageNet. For each attack, we show the trigger (left), μ map (middle) and μ distribution in 3D (right).
Figure 7: The Receiver Operating Cure(ROC) for NC, DL-TND and AEVA on CIFAR-10, CIFAR-100 and TinyImageNet tasks. AEVA is black-box while the other two methods are white-box.
Figure 8: The impact of triggersize on detection accuracy.
Figure 9: The impact of infectedlabel size on detection accuracy.
Figure 10:	The Receiver Operating Cure(ROC) for AEVA on CIFAR-10, CIFAR-100 and TinyIma-geNet tasks.
Figure 11:	Dynamic Triggers21Published as a conference paper at ICLR 2022AEVA successfully identify all models embedded with dynamic backdoors and the correspondinginfected labels. The detailed Aggregated Global Adversarial Peak(AGAP) values and AnomalyIndex given by the MAD outlier detection for infected and uninfected labels are shown in Fig. 12.
Figure 12:	AGAP and Anomaly Index for infected and uninfected labelsWe also evaluate AEVA on three different triggers with different shapes, which are shown in Fig. 13.
Figure 13:	Triggers with different shapesL Results for impact of the number of images per labels.
Figure 14: The impact for the number of samples for each classM	The impact of the number of the labels for available images.
Figure 15: The impact for the number of samples for each classN Multiple triggers within the single infected label scenariosWe also investigate the impact caused by multiple triggers within the single infected label. Wehere choose different 4 × 4 squares located at different places as the triggers implemented following23Published as a conference paper at ICLR 2022BadNets. We randomly select a label as the infected label. We built 60 infected models with differentarchitectures(i.e., ResNet-18, ResNet-44, ResNet-56, DenseNet-33, DenseNet-58). The results forTinyImageNet are shown in Table. 8. Notably, for TinyImageNet, injecting too many triggers (≥ 4)in the single label would cause the target model’s accuracy drop (i.e., ≥ 3.7%), which is inconsistentwith the threat model for backdoor attacks (Gu et al., 2019; Chen et al., 2017; Liu et al., 2018).
