Figure 1: Example of syntheses from three texture models in chronological order. From left to right:the observed texture in gray-scale, synthesis from PS (Portilla & Simoncelli, 2000), from VGG(Gatys et al., 2015), and from RF1(Ustyuzhaninov et al., 2017).
Figure 2: Examples of syntheses from the ALPHA models defined in Table 1. Visually similarimage patches in textures are highlighted by red circles. The number of statistics is given in bracketsnext to each model name. From top to bottom: a Julesz counterexample, a stationary texture image,a stationary turbulent field and a non-stationary image. We see that the model ALPHAI achieves abalance between the visual quality and diversity on these examples.
Figure 3: Visual comparison between the gray-scale and color models. ’Ours’ denotes the ALPHAImodel for gray-scale images and the ALPHAC model for color images.
Figure 4: Visual comparison of syntheses from the ALPHAS , ALPHAI and ALPHAL models.
Figure 5: Visual comparison of syntheses from ALPHAC model and its reduced version.
Figure 6: Visual comparison of syntheses from the VGG model, before and after histogram match-ing. Before HM, the relative VGG loss is 2.22e-08, while after HM, the loss is 5.38e-05.
Figure 7: Comparison between different wavelets families used in the ALPHAI model. Centralzooms of syntheses using the same covariance model, with three different wavelet families. Fromleft to right: observation, Simoncelli steerable wavelets, bump steerable wavelets (Mallat et al.,2020), and Morlet wavelets.
Figure 8: Syntheses from the ALPHAC model defined with three different maximal scale parame-ters J ∈ {4, 5, 6}. As in Section 4, Morlet wavelets are used.
Figure 9: Visual comparison between different texture models on gray-scale images.
Figure 10: Visual comparison between different texture models on color images.
