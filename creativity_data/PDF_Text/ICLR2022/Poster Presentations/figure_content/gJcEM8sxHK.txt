Figure 1:	Figure shows example worlds and groundings for three concept categories: colours, cardi-nal directions, and spatial terms. For each of the three domains, the left figure in each shows the fullset of grounded concepts in the domain. To the right, We see example world representations withtextual instantiations of the groundings that serve as prompts for language models.
Figure 2:	Figure shows how colours and modifiers transform in rotated worlds. The leftmost figureshows a full 3-D colour space of 367 colours. The three figures on the right, show four samplecolours in their original world, a world rotated by 90Â°, and a randomly rotated world, showing howthe structure of the space is preserved or distorted in isomorphic or random rotations respectively.
Figure 3:	Figure shows example worlds and groundings for the spatial domain. The left panelshows example grid worlds where the location of the 1 denotes a point grounded in the world, with acorresponding text instantiation of that particular concept. The two panels on the right show exampleoutputs from the smallest and largest models. We show the top three most probable words from eachmodel along with the probability of that word. When computing Top-1 accuracy, we only considerthe first, however, we consider all 3 when computing Top-3 accuracy.
Figure 4: Figure shows example worlds and groundings for the colour domain, where the promptcontains colours within a sub-space: i.e., training on primary and secondary colors plus shades ofred, but then testing on navy blue. The left panel shows the full set of training examples the modelsees. The right shows example outputs from the smallest and largest models, with the top three mostprobable words from each model along with the probability of that word.
Figure 5: Figure shows performance curves of models on increasing the number of samples in aprompt. From left to right, we see the 124M, 355M, 774M, 1.5B and 175B parameter models, onincreasing the number of samples given to the model to the maximum prompt size. We see that only5 samples are not enough for models to learn the task, but past a certain threshold (20 samples),models do not have a significant increase in performance on the same test set.
Figure 6: Figure shows example worlds and groundings for the colour domain. The left panel showsexample RGB codes and associated colour names, while the right shows example outputs from thesmallest and largest models, with the top three most probable words from each model along with theprobability of that word. When computing Top-1 vs. Top-3 accuracy, we consider only the first vs.
