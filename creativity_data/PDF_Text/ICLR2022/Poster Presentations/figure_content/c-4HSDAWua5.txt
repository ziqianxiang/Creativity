Figure 1: Left: Discrete sequencerepresentation. Right: More naturalcontinuous-time functional representa-tion. The gray line denotes pen-up state.
Figure 2: Vector-field depict-ing dynamics directly on S(t);modelled trajectory (red)learned from VectorMNISTdata (blue).
Figure 3: Overview of the SketchODE framework. The Neural CDE encodes input sequence s(t) toa latent vector Z and a second-order Augmented Neural ODE decodes it as S(t).
Figure 4: Left: 2D vector fields induced by MLPs (with random weights) with different activationfunctions. A few randomly sampled solution trajectories are shown below the corresponding vectorfields. Right: Original data and augmented versions with different strengths of Perlin Noise.
Figure 5: Left: Conditional sampling in SketchODE vs discrete RNN-RNN vs CoSE. Middle: Ab-lation study to validate the use of periodic activations & Perlin noise augmentation in SketchODE.
Figure 6: Illustration of SketchODE latent space interpolation and animation. Left: Interpolation5 → 8 → 2 → 0 → 5 in VectorMNIST. Middle: SketchODE(top) supports interpolation be-tween novel categories (e.g., A → B and B → D) unseen during training (on VectorMNIST),SketchRNN(bottom) fails to do this. Right: Interpolation examples in QuickDraw and DiDi datasets.
Figure 7: Illustration of SketchODE abstraction effect by varying activation frequency ω. Decreas-ing the value of ω, leads to increasing abstraction/reduced high-frequency detail.
Figure 9: Original data from VectorMNIST on the left and unconditional samples on the right. Justlike any VAE-based generative model, reconstruction is traded-off by posterior-matching objective.
Figure 10: SketchODE variant for multi-stroke format.
Figure 11: Visual illustration of data formats, resampling and mini-batching strategy.
Figure 12:	Interpolation on latent space by cyclic walk through 6 samples of different categories.
Figure 13:	Some examples of conditional sampling (above) and animatic interpolation (below).
