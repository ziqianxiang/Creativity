Figure 1: Test accuracy of GCN, GAT, and GraphSage vs. the number of labeled nodes per class. All networkshave 2 layers, and each experiment is run with 100 splits and 20 random seeds following [10]. The accuracydrops rapidly with fewer labeled data for training. CORA, CiteSeer, and PubMed have 2485, 2120, and 19717nodes in total respectively. Results on more benchmark GNN architectures are in Appendix D.4.
Figure 2: Test accuracy vs. the “depth” (T in (5)) of GRAND-l and GRAND++-l on the four graph nodeclassification tasks. We see that GRAND++-l is much more resilient to deep architectures than GRAND-l.
Figure 3: Accuracy of GRAND++-l and GRAND-l forCORA and CiteSeer, where both models, with differentdepth (T), are train with 1 labeled node per class. Theseresults show that GRAND++ is more effective in learn-ing with low-labeling rates than GRAND.
