Figure 1: Conversion error between source ANN and converted SNN. sl1-1 and sl2-1 denote theoutput spikes of two neurons in layer l - 1, and sl1 denotes the output spikes of a neuron in layer l.
Figure 2: Comparison of SNN output Ï†l (T ) and ANN output al with same input zl4	Optimal ANN-SNN conversion4.1	quantization clip-floor activation functionACCording to the Conversion error of Equation 12, it is natural to think that if the Commonly usedReLU aCtivation funCtion h(zl) is substituted by a Clip-floor funCtion with a given quantizationsteps L (similar to Equation 11), the Conversion error at time-steps T = L will be eliminated. Thusthe performanCe degradation problem at low latenCy will be solved. As shown in Equation 13, weproposed the quantization Clip-floor aCtivation funCtion to train ANNs.
Figure 3: Compare ANNs accuracy.
Figure 4: Compare quantization clip-floor activation with/without shift termTable 2: Comparison between the proposed method and previous works on CIFAR-10 dataset.
Figure 5: Influence of different quantization stepsX3nm8vSimulation time-Stq)S(d) ResNet-20 on CIFAR-100Table 3: Comparison between the proposed method and previous works on ImageNet dataset.
Figure S1: More spikes than expected exists for the method of setting the maximum activation.
