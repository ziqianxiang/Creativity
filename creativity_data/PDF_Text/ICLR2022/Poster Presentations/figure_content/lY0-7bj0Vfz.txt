Figure 1: Attention layer using MoCA and Self-Attention. In MoCA, the input activation Aij isfirst transformed into low dimensional space Via 1 × 1 convolution θ(∙) and USed to select its closestsemantic cell in a winner-take-all process. The selected semantic cell will allow the prototype memorycells in its cluster to participate in the MoCA process, generating a modulation that is then mappedby a 1x1 network O(∙) from the embedding space back to the feature space. In the self-attention path,the entire feature map A is transformed into key and value via two corresponding 1 × 1 convolutionφ(∙), ψ(∙) and then attend with query vector (encoded from Aij) and then mapped back to the featurespace. Finally, the outputs from two paths are aggregated together to form the input to the next layer.
Figure 2: Left: MoCA Layer overview. Each hyper-column in the feature map A is processed bythe MoCA Operation specified in Figure 1 to generate a modulation to modify the activation of thathyper-column before passing it onto the next layer. Right: Memory Update Mechanism. Whenupdating the memory, a momentum-updated projection head φ(∙) maps the hyper-column activationvector to the prototype memory space and later incorporated into the matched semantic cluster in thememory bank using a random update policy.
Figure 3: Generated images from MoCA on different datasets. Different resolutions of images areconsidered. The biggest one is 256x256, the middle one is 64x64 and the smallest one on the right isfrom CIFAR-10 with 32x32 resolution.
Figure 4: Visualizing Cluster Semantics in MoCA. We use MoCA-FastGAN model trained onMSCOCO-300 dataset for visualization (Lin et al., 2014). Each row is a generated image. Wecompute the cluster assignment for each hypercolumn in the layer where MoCA was installed andhighlight the receptive fields of hypercolumns with white bounding boxes. We further group thevisualization of the receptive fields by clusters (columns). For example, for column "Cluster 0", allwhite bounding boxes are the receptive fields of the hyper-columns that are modulated via Cluster 0’sprototypes. We observe that different clusters have different semantics since their prototypes tends tomodulate different semantic regions of the images (See discussion in Section 4.3).
Figure 6: Schematic of affinity map visualization procedure[h, w]We generate 50,000 images from random noise for CIFAR-10, and 1,000 images for 100-shot Obama.
Figure 7:	Affinity heat-map w.r.t. different concept clusters. White: strongest affinity; Dark red:zero affinity. Left (a): MoCA-StyleGAN2 on CIFAR10. Right (b): MoCA-FastGAN on 100-shotObama dataset. We can observe that Different cluster associated with different semantic meaningsalthough not trained with category supervision.
Figure 9: Modification of the activation representationand Context Attention Map by MoCA.
Figure 8:	CIFAR-10 image binarydecomposition w.r.t. their top-3 activatedclusters.
Figure 10: Some randomly generated images and their corresponding nearest neighbor in the dataset.
