Figure 1: Overview of NAS-Bench-Suite.
Figure 2: Validation accuracy box plots for each NAS benchmark. The whiskers represent theminimum and maximum accuracies in each search space. For NAS-Bench-NLP and TransNAS-Bench, perplexity and SSIM are used instead of validation accuracy, respectively. In the case ofextremely large search spaces such as DARTS and NAS-Bench-NLP, the statistics are computed onlywith respect to the tens-of-thousands of precomputed architectures.
Figure 3: RWA for NAS benchmarks.
Figure 4:	Relative performance of black-box algorithms (top) and performance predictors (bottom)across NAS benchmarks. The solid circles show the performance of the algorithm with defaulthyperparameters, while the crosses show performance after hyperparameter optimization (HPO).
Figure 5:	Transferability results for predictors (left) and black-box algorithms (right). Row i, columnj denotes the scaled regret of an algorithm tuned on search space i and evaluated on search space j .
Figure 6:	Performance of one-shot algorithms across NAS benchmarks. The bars show the minimum,maximum and average performance over five seeds. For abbreviations, see Table 3.
Figure 7: Validation accuracy box plots for each NAS benchmark. The whiskers represent theminimum and maximum accuracies in each search space. For NAS-Bench-NLP, perplexity is usedinstead of validation accuracy, and three datasets of TransNAS-Bench do not use accuracy: SurfaceNormal uses SSIM, Autoencoding uses SSIM, and Room Layout uses negative loss. These are inaccordance with the metrics used in the original work. Finally, in the case of extremely large searchspaces such as DARTS and NAS-Bench-NLP, the statistics are computed only with respect to thetens-of-thousands of precomputed architectures.
Figure 8: Average time to train an architecture for each NAS benchmark.
Figure 9:	Average neighborhood size for each NAS benchmark. Note that for some NAS benchmarks,the neighborhood size is fixed, and for other NAS benchmarks, the neighborhood size varies.
Figure 10:	Relative performance of black-box algorithms (top) and performance predictors (bottom)across NAS benchmarks. The solid circle shows the performance of the algorithm with defaulthyperparameters, while the cross shows performance after hyperparameter optimization.
Figure 11:	Transferability results for predictors (left) and black-box algorithms (right). RoW i, columnj denotes the Kendall Tau rank correlation of the performance of hyperparameters between searchspaces i and j . For abbreviations, see Table 3.
Figure 12:	Interquartile ranges of subsets of NAS-Bench-101 and NAS-Bench-201 as a function ofthe number of operations. As the size of the search space increases, the interquartile range decreases.
