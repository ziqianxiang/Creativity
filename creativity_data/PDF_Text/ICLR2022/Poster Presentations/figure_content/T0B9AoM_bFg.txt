Figure 1: Schematic of MI bounds discussedin this paper. Green shading indicates our contri-butions, while columns and gold labels indicatesingle- or multi-sample bounds. Blue arrows in-dicate special cases using the indicated proposaldistribution. Relationships based on learned criticfunctions are indicated by red arrows. We obtainonly lower bounds on MI with unknown p(x|z),but both upper and lower bounds with knownp(x|z). All bounds require a known marginal p(z)for evaluation, apart from (Structured) Info-NCE.
Figure 2: Extended state-space probabilistic interpretations of multi-sample AIS bounds. Forwardchains are colored in blue, and backward chains are colored in red. Note that ELBOS and EUBOS areobtained by taking the expectation of the log importance weight logPtgtS%propS under either theproposal or target distribution, and can then be translated to MI bounds.
Figure 3: (a) Comparison of energy-based bounds (giwae and mine-ais) with other mi bounds.
Figure 4: Comparison of the probabilistic extended state-space interpretations of different multi-sample bounds. Forward chains of ais and variational distributions in is / iwae are colored in blue.
Figure 5: Comparing Multi-Sample AIS sandwich bounds and evaluating the effect of K and T formi estimation in deep generative models on mnist.
Figure 6: Generalized Energy Based Bounds. Arrows indicate the gaps in each mi lower bound orits relationship to other lower bounds. DGKL (∙∣∣∙) represents the generalized KL divergence betweentwo unnormalized densities (see App. J.3). All bounds are written in terms of a base variationaldistribution q&(z|x), which may be chosen to be the marginalP(Z) as in MINE-DV and MINE-F.
Figure 7: Estimating the mutual information of deep generative models with ais and mine-ais.
Figure 8: Runtime vs. Bound Tightness for vae (left) and gan (right) models on mnist.
