Figure 1: Top: The MSE and VoR, MCN tradeoff curves, and some example reconstructed imagesproduced by IRVAE trained with various regularization coefficients. Bottom: Two-dimensional la-tent space representations with some equidistance plots whose centers consist of a randomly selecteddata point zc from each class for A, B, F, I.The equidistance plots are {z|(z-zc)TJfT (zc)Jf(zc)(z-zc) = k for k > 0. (The more homogeneous and isotropic, the better.)Figure 2 shows tradeoff curves and latent space representations for IRVAE + FM (under the sameexperimental setting as above). IRVAE + FM results in more isometric representations than IRVAE,with no losses in MSE. In particular, for cases A and B, which have the lowest MSE but the highestVoR and MCN, the flattener significantly lowers both VoR and MCN. These improvements can bequalitatively seen by comparing the equidistance plots of A and B in Figure 1 and Figure 2.
Figure 2: Tradeoff curves for FMVAE, IRVAE, and IRVAE + FM, and two-dimensional latent spacerepresentations with some equidistance plots (under the same experimental setting as Figure 1).
Figure 3: The tradeoff curves for FMVAE, IRVAE, IR-VAE + FM trained with the pose data.
Figure 4: Latent spaces and equidistance ellipses for VAE, FMVAE, IRVAE, and IRVAE + FM (theredder the ellipse, the larger the condition number).
Figure 5: Some example image retrieval results (top 5 images). Common attributes of query imagesets are written above the figures. Higher rank images are located left.
Figure 6: The original pose is encoded in the latent space, then the encoded latent value is translatedalong each latent space axis (z1, z2, ..., z8). The translated latent values are decoded back to generatea new eight pose for each model VAE and IRVAE. The translated distances are proportional to thestandard deviations of the encoded training data.
Figure 7: Pose interpolations between a walking pose and balancing pose with linear interpolationsin the latent spaces. The red box indicates suddenly appeared punching poses.
Figure 8: The tradeoff curves of FMVAE, IRVAE, and IRVAE + FM.
Figure 9: The effect of mixup augmentation with varying mixup parameters η.
Figure 10:	ISometric regularization with diverSe autoencoder methodS. The more homogeneouS andiSotropic equidiStance plotS are, the more iSometric the repreSentationS are.
Figure 11:	Tradeoff curves obtained by changing the regularization coefficients α (lower-the-better).
Figure 12:	Averaged tradeoff curves and standard deviations represented as ellipses for MNIST andCMU experiments in Figure 1 and 3 of the main manuscript (20 times run). We wanted to drawellipses by using the standard errors, but they were too small to visualize. Even standard deviationsare really small.
