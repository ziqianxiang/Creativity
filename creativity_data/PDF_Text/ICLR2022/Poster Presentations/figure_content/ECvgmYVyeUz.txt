Figure 1: (a) t-SNE visualization of representations before and after contrastive learning. Each pointdenotes a sample and its color denotes its class. (b) Applying aggressive data augmentations (Chenet al., 2020a) to four images from ImageNet (two are cars and two are pens). The 1st column showsthe raw (center-cropped) images and the 2-5th colums show the augmented ones.
Figure 2: Contrastive learning maylearn class inseparable featureseven with perfect aligned pos-tive samples and uniform negativesamples. Colors denote classes.
Figure 3: Illustrative examples of augmentation graphs, where each dot denotes a sample X ∈ Duand its color denotes its class. The lighter disks denote the support of the positive samples p(χ+∣χ).
Figure 4: t-SNE visualization of features learned with different augmentation strength r on therandom augmentation graph experiment. Each dot denotes a sample and its color denotes its class.
Figure 5: (a) Average Confusion Rate (ACR) and downstream accuracy v.s. different augmentationstrength (before training). (b,c): ACR and downstream accuracy while training.
Figure 6: Average Relative Confusion (ARC) and downstream accuracy v.s. different augmenta-tion strength on different datasets (CIFAR-10, CIFAR-100, and STL-10) with different contrastivelearning methods: SimCLR (Chen et al., 2020a) and BYOL (Grill et al., 2020).
Figure 7: Average Relative Confusion (ARC) and downstream accuracy v.s. different augmentationstrength on CIFAR-10 (SimCLR) with different number of nearest neighbors k.
Figure 8: Evaluation of the maximal diameter D as a function of different augmentation strength (a)and different number of samples (b) on the synthetic data in Section 5.1.
Figure 9: Downstream accuracy (ACC) v.s. Average Relative Confusion (ARC) for different typesof augmentations in SimCLR on CIFAR-10.
Figure 10: Average Relative Confusion (ARC) v.s. downstream accuracy with different augmenta-tion strength on four different kinds of color jittering operations.
Figure 11: Downstream accuracy (ACC) v.s. the logarithm of Average Relative Confusion (ARC)on a composition of RandomResizedCrop and ColorJitter with different strength. Experiments areconducted on CIFAR-10 with SimCLR.
Figure 12: Visualization of the augmentation graph with different augmentation strength r on thesynthetic data described in Section 5.1. Each color denotes a connected component. The corre-sponding t-SNE visualization and test accuracy (of contrastive learning) can be found in Figure 4.
Figure 13: The augmentation graph of CIFAR-10 with different strength r of RandomResizedCropas in Section 5.2. We choose a random subset of test images, randomly augment each one for 20times. Then, we calculate the sample distance in the representation space as in prior work like FID(Heusel et al., 2017), and draw edges for image pairs whose smallest view distance is below a smallthreshold. Afterwards, we visualize the samples with t-SNE and color intra-class edges in black andinter-class edges in red and report their frequencies.
