Figure 1:	Comparison of our algorithm with Full-Communication, IL, and Random.
Figure 2:	Comparison of parameter consensus by Figure 3: Comparison of learning with and w/oour bandit with Random and Rule-based.	policy consensus.
Figure 4: Y: communication rate. X: training step (log scale). Communication rate for the 10neighbors in Cooperative Navigation (N = 15), with the distance increasing from left to right.
Figure 5: Probability of com-munication in the high-levelbandit across all environ-ments and seeds.
Figure 6: An illustrative example for the proof of Theorem 1. Please see the text for details.
Figure 7: Y-axis: average communication rate. X-axis: training step in log scale. The averagecommunication rate for detectable 10 nearby agents, with the order increasing in distance from leftto right.
Figure 8: As an illustration, suppose there are 6 agents (i,j, k, l,p, q). At time step t, agent ireceives the observation OIt which contains information about three neighboring agents: j, k andl. Then, agent i uses its communication network Ci (GCN) to determine which observable agentsworth communicating (agent k and l in this case) by the complete graph of agent j, k and l. Agent iand the selected agent k and l forms a complete graph which is fed into the critic Q1 (GCN).
Figure 9: Learning curves on the toy example.
Figure 10: Performance of our algorithm and the baselines under different observation-action com-munication thresholds. For fair comparison, the frequency of doing parameter consensus is the samefor all the algorithms under different observation-action communication budgets. The error bar cap-tures the standard deviation of the mean performance of the last 5 training policies (at 9e5, 9.25e5,9.5e5, 9.75e5, 10e5 steps) across 4 seeds.
