Figure 1: Our proposed generator framework aims to decrease the cosine similarity of feature be-tween benign image xs and adversarial example x0s during the training phase. Training data andsubstitute model are all from the ImageNet domain. C module is applied to constrain x0s in the'∞ -ball of XS. RN and DA are optional, which can further improve the transferability.
Figure 2: Left: The data distribution (i.e., mean and standard deviation) for datasets from differentdomains. The result is the average over the three channels. Right: Two intermediate feature maps(Maxpool.3) of VGG-16 (Simonyan & Zisserman, 2015) (trained in ImageNet domain) for the inputimage from CUB-200-2011 (Wah et al., 2011).
Figure 3: Left: A benign image from StanfordCars (Krause et al., 2013). Middle & Right: We applycross-channel average pooling to the intermediate fea-ture maps (Maxpool.3) of VGG-16 and (Conv3_8) ofDCL (Chen et al., 2019) with backbone Res-50.
Figure 4: The average top-1 accuracy of DA, RN andDA + RN variants after attacking on coarse-grained,fine-grained and source domains.
Figure 5: Visualization (cross-channel average pooling) of intermediate features for VGG-16 andDense-169. It can be observed that the RN module inhibits the response of objects, essential featureextracted by Dense-169, while VGG-16 enhances the response.
Figure 7: The structure of the generator.
Figure 8: Adversarial examples crafted by CDA and our vanilla BIA (C = 10). Both generatornetworks are trained against ImageNet pre-trained VGG-16 (Simonyan & Zisserman, 2015). Redhighlighted labels represent misclassification.
Figure 9: The average top-1 accuracy after attackingon coarse-grained (left), fine-grained (middle) and source(right) domains with different μfmean and σ'rne。。for RN.
Figure 10: The average top-1 accuracy after attacking (the lower, the better) on coarse-grained, fine-grained and source domains. Our generator Gθ is trained against different layers (from shallow todeep) of ImageNet pre-trained VGG-16, VGG-19, Res-152 and Dense-169, respectively.
Figure 11: The average top-1 accuracy after attacking on coarse-grained, fine-grained and sourcedomains. Here we compare the results of vanilla BIA, BIA with data augmentation (AUG) and BIAwith RN . Our generator Gθ is trained against ImageNet pre-trained VGG-16, VGG-19, Res-152and Dense-169, respectively.
Figure 13: A benign image (label is “Boeing 747”)from FGVC Aircraft (Maji et al., 2013) and its cor-responding adversarial examples and difference map.
Figure 12: We apply cross-channel average pooling to visualize each block of our generator Gθ* .
