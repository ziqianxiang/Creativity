Figure 1: Overview of the proposed I&V method: (1) We leverage SKGs for unifying scene knowl-edge from different resources. (2) We pre-train a contextualized imagination module to constructan SKG for a set of concepts, based on the collected SKG instances. (3) At inference time, ourverbalization module realizes the generated SKG into natural language.
Figure 2: Continual pretraining and fine-tuning of the imagination module to output a linearizedSKG based on a sequential input (context and concepts).
Figure 3: Our I&V method iteratively applies theimagination and the verbalization modules, by gen-erating one sentence in each iteration.
Figure 4: Ablation study on back-bone LM sizes of our verbalizationmodule and Node2Text using theConCePt2Story-ROC dataset.
Figure 5: Results (SPICE) of the low-resource experiment on the threebenchmark datasets with different number of training examPles.
