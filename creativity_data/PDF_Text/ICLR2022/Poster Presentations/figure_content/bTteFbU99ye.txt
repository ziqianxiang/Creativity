Figure 1: GPT2 sequence probability es-timates plotted against the true sequenceprobabilities. Neural LMs underestimate theprobability of sequences drawn from the lan-guage they are trained to model.
Figure 2: Test sequence probability estimates given by neural LMs. Three left-most figures: Thejoint histograms of sequence probability estimates. The dotted line denotes the cases in which themodel’s estimates perfectly align with the target probability; shading to the right of this line denotesunderestimation. Right-most figure: Mean sequence estimation error by target sequence probability.
Figure 3: Mean model estimation error by training epoch (GPT2-medium). Each line denotes themean estimation error for a 50th of the sequences; darker lines represent less probable sequences.
Figure 4: GPT2-medium, GPT2-large and LSTM trained on 30M sequences sampled from pL .
Figure 5: GPT2-medium estimation behaviour for 15M sequences in Σ* across two dimensions:sequence rarity (x-axis) and degree of perturbation (y-axis). The heat map is shaded based onestimation error severity; blue areas indicate overestimation, whereas brown areas indicate underes-timation. We also include example sequences from two zones in this sequence space.
Figure 6: Model estimation error on test sequences as a function of target sequence probability forthree different artificial languages. Each line visualizes estimation error for a GPT2-medium modeltrained to model a language with a specific softmax temperature parameter T .
Figure 7: Left: Joint histogram of sequence probability estimates for test sequences. Center: Meanmodel estimation error by true sequence probability for test sequences. Right: Mean model estima-tion error by true sequence probability for sequences randomly sampled from Σ*.
Figure 8: GPT2-medium and GPT2-large trained on 30M sequences sampled from pL with T =1.00. Main plots: Mean estimation error on test sequences as a function of the number of sequencesseen in training. Inset plots: Relative change in mean estimation error of test sequences as a functionof the number of sequences seen in training. In both cases, each line denotes estimation behaviourfor a 50th of the test sequences; darker lines represent less probable sequences.
Figure 9: Test sequence probability estimates given by pretrained neural LMs fine-tuned on 1Msequences sampled from pL . Three left-most figures: The joint histograms of sequence probabilityestimates. The dotted line denotes the cases in which the model’s estimates perfectly align with thetarget probability; shading to the right of this line denotes underestimation. Right-most figure: Meansequence estimation error by target sequence probability.
Figure 10: Pre-trained GPT2-medium fine-tuned on 30M sequences sampled from pL . Main plots:Mean estimation error on test sequences as a function of the number of sequences seen in fine-tuning. Inset plots: Relative change in mean estimation error of test sequences as a function of thenumber of sequences seen in fine-tuning. In both cases, each line denotes estimation behaviour fora 50th of the test sequences; darker lines represent less probable sequences.
Figure 11: Mean model estimation error bytrue sequence probability for sequences ran-domly sampled from Σ*.
Figure 12: Expected and observed estimation error by sentence length for GPT2-small and GPT2-medium.
Figure 13: The probability of sampling a novel item (potential productivity P ) as a function ofsample size N. Many distributions in natural language are characterized by a potentially unboundedamount of novelty.
