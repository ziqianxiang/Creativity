Figure 1: ML API shift for IBM speech recognition API on AMNIST, a spoken digit dataset. (a) and(b) give its (normalized) confusion matrix in April 2020 and 2021, respectively. There is an overall7% accuracy drop. One factor is the 2021 model incorrectly predicting more “four” as “five”. (c)Given a sample budget, the proposed MASA can assess the API shift with much smaller error inFrobenius norm compared to standard uniform sampling.
Figure 2: Observed overall accuracy changes. Each row corresponds to an ML API, and each columnrepresents a dataset. The entry is the overall accuracy difference between evaluation in spring 2020and spring 2021. In 12 out of 36 cases, the API’s overall accuracy changed by more than 1%; thisincludes several cases of substantial drops in performance.
Figure 3: How MASA works. MASA first partitions the dataset. Then it picks which partition tosample based on some uncertainty measurement, queries the ML API on the drawn sample, and usesthe API’ prediction to update uncertainty and estimated shifts on this partition. This is repeated untilthe ML API has been queried N times. Finally, the estimated shifts on different partitions are aptlyfused to obtain the desired API shifts.
Figure 4: Case study for Amazon API’s performance shift on dataset YELP. (a) and (b) give itsconfusion matrix in spring 2020 and spring 2021, respectively. (c) is their differences, i.e., the APIshift. MASA’s estimated shift using 2000 samples is in (d). The dataset is divided into 4 partitionsbased on (i) positive (+) or negative (-) true labels, and (ii) low (l) or high (h) quality score. (e) and(f) give the size and uncertainty score of each partitions. (g) shows MASA’s sampling decision periteration, where the dark dot points represent the (unreachable) optimal sample allocation. (h) revealsits performance.
Figure 5: API shift estimation performance and sample size trade-offs. We compare the expectedsquared Frobenius norm error of MASA with K = 3 partitions versus standard uniform sampling.
Figure 6: Confusion matrices of a few APIs in spring 2020/2021, along with their API shifts.
Figure 7: Effects of partition parameter K . The total number of partitions is LK , and thus Larger Kimplies more partitions. Generally, across 12 cases where API shifts are identified, larger number ofpartitions usually leads to smaller estimation error for large samples. In practice, we observe thatK = 3 is enough to reach good error rate.
Figure 8: Illustrative examples of uncertainty scores. The dataset contains three partitions, each ofwhich includes six data points. Here We use a ball to represent a data point, its interior color to denoteits true label, and its edge color to indicate an ML API,s predicted label. For example, as shown inthe left panel, three points are labeled as red and the other three are labeled as blue. All points arepredicted correctly, and thus the accuracy is 1.0. As the ML API predicts half of the points as red andhalf as blue, the uncertainty score is 1 - 0.5 X 0.5 - 0.5 X 0.5 = 0.5. Note that high accuracy doesnot necessarily imply low uncertainty. For example, accuracy on partition 1(1.0) is higher than thaton partition 2(0.5), but its uncertainty score is actually larger than the latter. Yet, high diversity inthe predicted labels does imply higher uncertainty. For example, while accuracy on partition 1 andpartition 3 are both perfect, partition 3 incurs a higher uncertainty. This is because while only twounique predicted labels exist in partition 1, three occur in partition 3.
