Figure 1: Robust train /test accuracy (Top / Bot-tom) on CIFAR-10 with ResNet-18 across var-ious sparsity levels from 0% (Dense) to 90%.
Figure 2: Overview of our proposed training frameworks including Robust Bird (RB), Flying Bird(FB), and Flying Bird (FB+). The length of cycles roughly indicates the number of training epochs.
Figure 3: Visualization of loss contours and training trajectories. We compare the dense network, randomlypruned sparse networks, and flying bird + at 90% sparsity from ReSNet-18 robustified on CIFAR-10.
Figure 5:	Loss landscape visualization of robusitified dense network and sparse networks (90% sparsity) fromdifferent sparsification approaches on CIFAR-10 with ResNet-18.
Figure 6:	(Left) Visualization of attention heatmaps on adversarial images based on Grad-Cam (Selvarajuet al., 2017). (Right) Saliency map visualization on adversarial samples (Smilkov et al., 2017).
Figure A7: Standard accuracy (SA) of PGD-10, SGD, and Fast AT during the RB ticket finding phase.
Figure A8: Similarity scores by epoch among masks found via Fast AT, SGD, and PGD-10. Abrighter color denotes higher similarity.
Figure A9: Loss landscapes visualizations (Engstrom et al., 2018; Chen et al., 2021e) of the densemodel (unpruned), random pruned subnetwork at 30% sparsity, and Robust Bird (RB) tickets at30% sparsity found by the standard training. The ResNet-18 backbone with the same originalinitialization on CIFAR-10 is adopted here. Results demonstrate that RB tickets offer a smootherand flatter starting point for further robustification in the second stage.
