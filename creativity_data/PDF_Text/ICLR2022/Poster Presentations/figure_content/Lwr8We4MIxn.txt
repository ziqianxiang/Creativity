Figure 1: Overview of the GUIDE framework. Top: Gene embedding using attention based hierar-chical graph convolution. Bottom: Imaging and genetics integration; both modalities are coupled forphenotype prediction—in our case, disease classification. The variables {i1n , i2n } correspond to theimaging data, and gn is the genetic data. E(∙) is a set of fully connected layers that encodes the inputdata modalities. We further provide the architectural details of our model in Appendix A.1gene and aggregating the associated genetic risk weighted by GWAS effect size (Ripke et al., 2014).
Figure 2: ROCs for the PRS (blue), un-structured ANN (green) and the struc-tured models where G-EMBED and G-DECODE use either random graphs (red)or the gene ontology network (magenta).
Figure 3: Mean AUC and confidence intervalwhen masking the top-K imaging featureslearned by BFS (solid blue) and K-SHAP(dashed red). K is varied along the x-axis.
Figure 4: Distribution of pairwise cosine sim-ilarities between the feature masks learned byBFS and K-SHAP across the repeated CVfolds. Here, we fix K = 50 for both.
Figure 5: Left: The consistent set of brain regions captured by the dropout probabilities {b1 , b2}for K = 50. The color bar denotes the selection frequency. Right: Brain states associated with theselected regions for each fMRI task, as decoded by Neurosynth.
Figure 6: Ten different categories of pathways based on their semantic similarity. The key wordsshow the most frequent biological processes within each cluster.
Figure 7: Overview of the GUIDE framework. Top: Gene embedding using attention basedhierarchical graph convolution. We also depict the unpooling operation used as a regularizer. Bottom:Imaging and genetics integration; both modalities are coupled for disease classification. The variables{in,襦} correspond to the imaging data, and gn is the genetic data. E(∙), D(∙), C(∙) are the featureextraction, model regularization, and classification operations, respectively.
Figure 8: The reproducibility of imaging biomarkers when the feature selection has been doneusing K-SHAP vs Bayesian dropout. Left shows the performance on Nback data, Right shows theperformance on SDMT dataFig. 7	illustrates the detailed architecture of GUIDE. The top portion captures the genetic encodingand the decoding process. We use the gene ontology network to build the graph and use hierarchicalpooling to control the flow of information according to the relationships between the biologicalprocesses. At the same time, an graph attention mechanism tracks the salient edges at the subjectlevel. The bottom portion shows the integration of the imaging and genetics modules. G-EMBED,and Em(∙) encodes the genetics and imaging data, respectively, and fuse the latent representation to'n. The latent embedding is passed through decoding operations (G-DECODE, Dm(∙)) to reconstructthe input data. These decoding operations act as regularizers and stabilize the model.
Figure 9: Left The experimental paradigm of the N-Back task. The top row shows a sample responsefor N0-Back and the bottom row shows a sample response for N2-Back. Right The experimentalsetup for the SDMT task. Subjects are asked to view neutral and aversive stimuli.
Figure 10: The reproducibility of imaging biomarkers when the input layer of GUIDE is trainedwithout dropout, with random dropout, and with Bayesian feature selection.
