Figure 1: Example subsets of natural images from MetaShift. MetaShift leverages the natural heterogeneitywithin each class (e.g., “cat”, “dog”) to provide many subsets of images. Each subset corresponds to images in asimilar context (the context is stated in parenthesis) and represents a coherent real-world data distribution. Here,we only show 2 out of 410 classes and 8 out of 12,868 subsets of images from MetaShift.
Figure 2: Meta-graph—visualizing the diverse data distributions within the “cat” class. Each noderepresents one subset of the cat images. Each subset corresponds to “cat” in a different context: e.g. “cat withsink” or “cat with fence”. Each edge indicates the similarity between the two connecting subsets. Node colorsindicate the communities automatically detected by graph-based algorithms. Inter-community edges are coloredand intra-community edges are grayed out for better visualization. The border color of each example imageindicates its community in the meta-graph. We have one such meta-graph for each of the 410 classes in theMetaShift. Beyond visualization, meta-graph also provides a natural and systematic way to quantify the distancebetween any two subsets (i.e., nodes), which is not available in previous benchmarks of natural data.
Figure 3: Summary of MetaShift. MetaShift covers a wide range of 410 classes and 12,868 sets of naturalimages in total. For each class, we have 31.4 subsets on average together with an annotation graph (i.e., meta-graph) that explains the similarity/distance between two subsets (edge weight) as well as what is unique abouteach subset (node metadata). More concretely, the subsets are characterized by a diverse collection of 1,853distinct contexts, which covers 1,702 object presence, 37 general contexts and 114 object attributes.
Figure 4: A Visualization of Training Conflicts. Each row represents a training subset, and each columnrepresents an evaluation subset. A positive value (green) indicates that training on the training subset wouldimprove the performance on the evaluation subset. A negative value (red) indicates that the training would hurtthe performance on the evaluation subset. See text for discussions.
Figure 5: Example subsets based on general contexts (the global context is stated in parenthesis). MetaShiftcovers global contexts including location (e.g., indoor, outdoor) and weather (e.g., sunny, rainy).
Figure 6: The general contexts and their ontology in MetaShift. MetaShift covers 37 general contextsincluding location (e.g., indoor, outdoor, ocean, snow) and weather (e.g., couldy, sunny, rainy).
Figure 8: The attributes and their ontology in MetaShift. MetaShift covers over 100 attributes includingactivity (e.g., sitting, jumping), color (e.g., orange, white), material (e.g., wooden, metallic), shape (e.g., round,square) and so on.
Figure 9: The full visualization of the training conflicts experiment. Each row represents a training subset,and each column represents an evaluation subset. A positive value (green) indicates that training on the trainingsubset would improve the performance on the evaluation subset. A negative value (red) indicates that the trainingwould hurt the performance on the evaluation subset. See text for discussions. Coefficients are normalized to[-1, 1].
Figure 10: t-SNE Visualization of Meta-graph Spectral Embeddings for “Cat”. Each node representsone subset of the cat images. Node colors indicate the communities automatically detected by graph-basedalgorithms. Overall, the spectral embeddings work well as similar nodes are close in the t-SNE visualization.
