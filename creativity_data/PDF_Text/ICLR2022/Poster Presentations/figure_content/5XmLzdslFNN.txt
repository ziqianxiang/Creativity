Figure 2: Returns of STL (on 64 tasks) and MTL (on various tasks,per the colorbar) on 2-D tasks. The modular architecture capturesthe relations across tasks, accelerating learning. Training on moretasks improves results (left). Generalization of pre-trained modules tounseen combinations vs. the number of training tasks (right). Modulescan be combined in novel ways to achieve high performance withouttraining. Shaded regions and error bars show std. errors across 6 seeds.
Figure 3: Avg. returns of STL and lifelong agents on 64 compositional 2-D discrete tasks. Ourcompositional methods accelerate the training w.r.t. STL, demonstrating forward transfer (left). Ascompositional methods train on more tasks, they improve modules, achieving higher zero-shot per-formance when combined in novel ways (center). P&C also achieves forward transfer, but it forgetshow to solve earlier tasks, while our compositional methods retain performanceâ€”Comp.+Struct.
Figure 4: Avg. success of STL and lifelong agents on 48 compo-sitional robot manipulation tasks. Compositional methods againachieve forward transfer (left). The off-line stage causes a dropin performance, but further training the modules on future tasksachieves backward transfer and partially recovers the lost perfor-mance (right). Shaded/error bars represent std. errors over 3 seeds.
