Figure 1: Applications enabled by our approach (left) and weak supervision pipeline (right).
Figure 2: End model performance with ranking LFs(Left: Movies, Right: BGG). Training a model on pseu-dolabels is compared to fully-supervised baselines on vary-ing proportions of the dataset along with the Snorkel base-line. Metric is the Kendall tau distance; lower is better.
Figure 3: Regression: parameter estimation error(left two plots) and label estimation error comparingto majority vote baseline (rightmost) with increasingnumber of samples.
Figure 5: Comparison between our label model and ma-jority voting in generic metric space. Metric is accuracy;higher is better.
Figure 4: Comparison between our approach, (2),and fully-supervised in geodesic regression. Metricis least-squares objective; lower is better.
Figure 6: Inference via weighted and standard Kemeny rule over full rankings (top) with permutations ofsize d = 10, 20. Error metric is Kendall tau distance (lower is better). Proposed weighted Kemeny rule isnearly optimal on full rankings.
Figure 7: Inference via weighted and standard majority vote over partial rankings with permutations of sized = 10. Error metric is Kendall tau distance (lower is better). Proposed inference rule is nearly optimal onfull rankings.
Figure 8: Parameter and label estimation with varying the number of samples (top) and the number oflabeling functions (bottom)	# of training examples	Kendall Tau distance (mean ± Std)Fully supervised (5%)	250	0.1921 ± 0.0094Fully supervised (10%)	500	0.1829 ± 0.0068WS (HeUriSticS)	5000	0.1915 ± 0.0011Table 5: End model performance with true ranking LFs in BGG dataset.
Figure 9: End model performance with regression LFs (Left: Movies dataset, Right: BGG Dataset). Resultsfrom training a model on pseudolabels are compared to fully-supervised baselines on varying proportions ofthe dataset. Baseline is the averaging of weak labels. Metric is (MSE); lower is better.
