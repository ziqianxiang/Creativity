Figure 1: PCA of representations of images from 5 classes (= 5 colors) in Omniglot test set.
Figure 2: Summary of the π-limit for the 1-hidden-layer network of Eq. (1). (Left) Representationof Width-n μ-net with nonlinearity φ and its π-SGD update. Here V is depicted as √1n A> φ(B 0√nu0), which is equivalent to Eq. (4). In π-SGD, the first layer gradient is projected to the spacespanned by u0 before being accumulated to the weights. (Right) This network’s ∞-width limit canbe roughly thought of as another 1-hidden-layer neural network with nonlinearity Vφ (Eq. (6)). Butupdates are appended to A, B instead of added. See Theorem 3.2 and compare to Eq. (?).
Figure 3: Summary of the π-limit for deep MLPs Eq. (7), in the same style as Fig. 2. Here wetake the example of 3-hidden-layer MLPs. See Theorems 3.4 and 3.5 and compare to Eq. (?).
Figure 4: (Left) Feature kernels of π-limit, π-net, and μ-net all improve in quality with training, asmeasured by kernel regression on CIFAR10. All models are the best from our hyperparameter sweeps,but note that feature kernel regression causes accuracy decrease in finite models. (Middle) CIFAR10validation accuracy is monotonic across width and r for π-net, π-limit, and μ-net. (Right) Omniglotvalidation accuracy, in contrast, is not monotonic in width, and μ-net can underperform ∏-net of larger. (Note we did not run π-limit with r ≥ 800 in consideration of computational costs). All numbersin the heatmaps are the best from our random hyperparameter searches for 2-hidden-layer networks.
Figure 5: Tying Vs Untying Ω Across Layers Make No Difference in ∏-Nets. Using the sameprocedure as in Section 4.1, we train π-net with r = 400 using the best hyperparameter combinationWe found (whose result shown in Table 1) 50 times, each with different independently sampled Ωs,either with Ω tied across layers (blue curve) or not (orange curve). We plot their mean training lossand test loss curves here, with shade indicating 95% confidence interval.
Figure 6: Feature Kernel Regression of π-Nets vs Training Time, for Varying Widths. Wetook our best performing π-limit and trained finite-width versions of it, for width from 500 to40000. Throughout training, we measure their feature kernel regression accuracy. Altogether, we seeconsistent increase in performance across width at any moment in time. Note that the visible gapbetween π-limit and the widest π-net (even at initialization) is to a large extent due to the dependenceof kernel regression accuracy on the smallest eigenvalues of the kernel. See Fig. 12.
Figure 7: Performance Vs Depth on CIFAR10 and Omniglot. We take best performing μ-net,π-net, and π-limit from our thorough sweep of 2-hidden-layer networks, and resweep the learningrate and weight decay (for CIFAR10) or outer and inner learning rates (for Omniglot) for {1, 2, 3, 4}hidden layers. We plot the best test accuracies of each depth here. See Appendix B for more details.
Figure 8: Best Training Accuracy vs Width vs r on CIFAR10 and Omniglot, taken over all ofour random hyperparameter searches. While networks with moderately large r and width can overfitCIFAR10 completely, no μ-net, π-limit, or π-net with width UP to 8192 and r UP to 3200 is able todo so on Omniglot. See Appendix B.3.1 for experimental details.
Figure 9: PCA of representations of images from 5 classes in Omniglot test set. Same setting asin Fig. 1, but here including our best performing π-net as well.
Figure 10: Wide 1-hidden-layer π-nets with r = 2 have nearly identical loss curves as theirπ-limit. (Left) We train π-nets of r = 2 and width 23 , 29 , 215 as well as their common π-limit ona 128-image subset of CIFAR10 over 200 steps, with batch size 32 per step. We plot the trainingloss vs steps on the left. While the width-8 π-net fluctuates a bit around the π-limit curve, width-512and -32768 π-nets have nearly identical loss curves as the π-limit. (Right) With the same datasetand training procedure, we sweep widths 2{3,4,...,15} and 100 random seeds (which affect only therandom initialization). For each width and seed, we calculate the median loss deviation of the π-netof that width from the π-limit, where the median is calculated over the 200 steps of training. Finally,for each width, we plot the median of those medians over the 100 seeds as the blue curve (with 95%confidence interval in shade). This curve shows that the loss curve of a ∏-net converges roughly as1 /,width to that of the π-limit.
Figure 11: Wide 2-hidden-layer π-nets with r = 2 have nearly identical loss curves as theirπ-limit. We repeat the procedure in Fig. 10 for 2-hidden-layer π-nets. (Left) Width-32768 π-net hasalmost identical loss curve as the π-limit. Compared to the 1-hidden-layer case, the width 512 π-netis not as close to the limit, but this is expected as depth slows down convergence with width. (Right)Nevertheless, we still see 1 /,width convergence to the ∏-limit in terms of training loss.
Figure 12: Convergence of feature kernel at initialization, as measured by (left) Frobeniusdistance and (right) kernel regression accuracy. We perform all experiments here on a subsetof CIFAR10 with 400 training and 400 testing examples. (Left) We empirically verify that, atinitialization, the feature kernels of ∏-nets (with 2 hidden layers, r = 400) converge to the featurekernel of the ∏-limit in Frobenius norm at a 1/,width rate. Here in blue We plot the Frobeniusdistance of the π-net feature kernel to the limit kernel, normalized by the Frobenius norm of the limitkernel. The shade represents 95% interval of the mean, taken over 10 random seeds. (Right) Wecompute the feature kernel regression accuracy of randomly initialized π-nets of different widths(blue solid curve) and their common π-limit (orange dashed curve). The shade represents 95%confidence interval of the mean, taken over 10 random seeds. We see a convergence of this accuracyas one would expect from the theory. However, note that because the stability of kernel regressiondepends crucially on small eigenvalues of the kernel, the width needs to quite large compared to thedata size (= kernel size) in order to visibly see convergence of accuracy; for data size beyond 400training samples, we cannot see such convergence for width < 40, 000. This is why in Fig. 6, even atinitialization we see a large gap in accuracy between π-nets and the π-limit.
Figure 13: Wide 2-hidden-layer π-nets with r = 400 have nearly identical loss curves as theirπ-limit. We repeat the procedure in Fig. 10 for 2-hidden-layer π-nets, but now with r = 400 andwidths 128, 2048, and 32768. (Left) Training loss. (Right) Training accuracy. In both subplots,width-32768 π-net has almost identical curves as the π-limit, and the width-2048 curves follow themclosely.
