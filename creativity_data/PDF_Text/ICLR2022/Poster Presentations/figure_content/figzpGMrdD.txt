Figure 1: Performance comparisons between PLMs (first row) and CL methods (second row) underthe Task-incremental setting. For each row, the upper row is the results grouped by PLMs and thelower row is the results grouped by CL methods. For each column, from left to right the y label isaccuracy, backward transfer, forward transfer, and time (in hours) respectively. Performance resultsare averaged across the three datasets. Note that the time spent by Joint in (a) and (b) is the timespent on training with the entire training set once.
Figure 2: Layer-wise and task-wise probing of PLMs during continual learning, where clf meansclassifier illustrating the prediction accuracy, number k âˆˆ [1, 12] means representative of the k-thlayer in a PLM.
Figure 3: The buffer size analysis of ER. The first row is the detailed layer-wise analysis for differentPLMs with Vanilla; The second row is the averaged layer-wise probing for ER with various buffersizes. The color-scale represents the probing performance.
Figure 4: Data distributionC Model Training and Hyper-parametersHyperparameter selection. For each combination of PLM and CL scheme, we perform a com-bined grid-search for Class-IL and Task-IL, choosing the configuration that achieves the highestfinal accuracy averaged on the two settings.
Figure 5: The layer-wise performance of PLMs during task-incremental learning.
Figure 6: The layer-wise performance of PLMs at the last stage of class-incremental learning.
Figure 7: The task-wise performance of PLMs during class-incremental learning.
