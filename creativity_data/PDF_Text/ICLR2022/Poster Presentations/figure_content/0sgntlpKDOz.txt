Figure 1: Graphical model visualization. (a): A graph with 5 nodes; (b): The associated stepgraphon of the graph in (a) as a continuous domain version of its adjacency matrix; (c): A visualiza-tion of the dynamics, i.e. the center agent is affected only by its neighbors (grey).
Figure 2: Three graphons used in our experiments. (a): Uniform attachment graphon; (b): Rankedattachment graphon; (c): Erdos-Renyi (ER) graphon with edge probability 0.5.
Figure 3: Achieved equilibrium via M = 100 approximate equivalence classes in SIS-Graphon,plotted for each agent α ∈ I. Top: Probability of taking precautions when healthy. Bottom: Proba-bility of being infected. It can be observed that agents with less connections (higher α) will take lessprecautions. (a): Uniform attachment graphon; (b): Ranked attachment graphon; (c): ER graphon.
Figure 4: Decreasing maximum deviation between average N -agent objective and mean field objec-tive over all agents for the GMFE policy and 5 W -random graph sequences. (a): Uniform attachmentgraphon; (b): Ranked attachment graphon; (c): ER graphon.
Figure 5: Final approximate exploitability mean and its minimum / maximum (shaded region) overthe last 10 iterations for various temperatures η. We can see convergence for sufficiently hightemperatures and choose the lowest temperature such that we still have convergence with low ex-ploitability. Furthermore, compared to the uniformly random policy, our approximate exploitabilityis significantly lower, indicating a good approximate GMFE. For the Investment-Graphon problem,the approximate exploitability of the uniform policy is not shown, as it is above 30. (a): SIS-Graphon; (b): Investment-Graphon.
Figure 6: The M = 100 approximate equivalence classes solution of Investment-Graphon. Weplot the probability of investing at state x = 0 (top) together with the evolution of average quality(bottom). (a): Uniform attachment graphon; (b): Ranked attachment graphon; (c): ER graphon.
Figure 7: The probability of investing at state x = 0 (top) together with the evolution of averagequality (bottom) for PPO. The solution is similar to Figure 6, though slightly different due to theapproximations stemming from PPO and sequential Monte Carlo. (a): Uniform attachment graphon;(b): Ranked attachment graphon; (c): ER graphon.
Figure 8: Achieved equilibrium via M = 100 approximate equivalence classes in Investment-Graphon. Top: Maximum quality X UP to which agents will invest (∏α(I | x) > 0.5), shown foreach α ∈ I , t ∈ T. Bottom: Expected quality versus time of each agent α ∈ I. It can be observedthat agents with less connections (higher α) will invest more. (a): Uniform attachment graphon; (b):Ranked attachment graphon; (c): ER graphon.
Figure 9: Achieved equilibrium via approximate equivalence classes in SIS-Graphon for the uniformattachment graphon, plotted for each representative αi ∈ I . Top: Probability of taking precautionswhen healthy. Bottom: Probability of being infected. (a): M = 10; (b): M = 30; (c): M = 50.
Figure 10: Achieved equilibrium via approximate equivalence classes in SIS-Graphon for the rankedattachment graphon, plotted for each representative αi ∈ I . Top: Probability of taking precautionswhen healthy. Bottom: Probability of being infected. (a): M = 10; (b): M = 20; (c): M = 30.
Figure 11: Learning curve and results for an exemplary straightforward application of multi-agentPPO (MAPPO, Yu et al. (2021)). Left: Sum of expected agent objectives over learning iterations;Right: Final policy probability of taking precautions when healthy.
