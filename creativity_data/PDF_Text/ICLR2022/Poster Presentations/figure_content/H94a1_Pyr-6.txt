Figure 1: Overall architecture of our As-ViT.
Figure 2: Correlations between κ, LE, LE and trained accuracies ofViT topologies from our search space.
Figure 3: Left: Comparing scaling rules from As-ViT, random scaling, Swin (Liu et al., 2021), ViT (Zhai et al.,2021), and ResNet (He et al., 2016). “Total Depths”: number of blocks (“bottleneck” ofResNet, “attention-block”of ViTs). “Total Widths”: sum of output channel numbers from all blocks. Grey areas indicate standard deviationsfrom 10 runs with different random seeds. Right: During the auto-scaling, both the network,s complexity andtrainability improve (numbers indicate scaling-up steps, LE higher the better, κΘ lower the better).
Figure 4: By progressively changing the sampling granularity(stride and dilation) of the first linear project layer, We can re-duce the spatial resolutions of tokens and save training FLOPS(37.4% here), While still maintain a competitive final perfor-mance (ImageNet-1k 224 × 224). See Table 6 for more studies.
Figure 5: Entropy of policy during our search (Section 3.3).
