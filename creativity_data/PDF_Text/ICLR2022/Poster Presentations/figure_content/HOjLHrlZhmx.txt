Figure 1: Robustness certification for per-state action in terms of certified radius r at all time steps. Eachcolumn corresponds to a smoothing variance σ. The shaded area represents the standard deviation which is small.
Figure 3: Robustness certification for cumulative reward, including expectation bound JE, percentile boundJp (p = 50%), and absolute lower bound J. Each column corresponds to one smoothing variance. Solid linesrepresent the certified reward bounds, and dashed lines show the empirical performance under PGD.
Figure 4: Robustness certification for per-state action in terms of certified ratio ηr w.r.t. certified radius r. Eachcolumn corresponds to one smoothing parameter σ. The shaded area represents the standard deviation.
Figure 5: Robustness certification for (a) per-state action in terms of certified radius r at all time steps, and (b)cumulative reward in terms of absolute lower bound J w.r.t. the attack magnitude ε. The results are reportedunder large smoothing parameter σ compared with those evaluated in Figure 1 and Figure 3 in the main paper.
Figure 6: Benign performance of locallysmoothed policy ∏ under a larger range ofsmoothing parameter σ with clean state ob-servations.
Figure 7: Periodic patterns in Pong. The figure shows two periods (left and right), including the certified radiusr w.r.t. the time steps (above), and the selected game frames corresponding to different stages in each period(below). Different periods are highly similar.
Figure 8:	Robustness certification on CartPole in terms of (a-b): robustness of per-state action and (c): lowerbound of cumulative rewards. In (a) and (c), each column corresponds to one smoothing variance.
Figure 9:	Robustness certification on highway in terms of (a-b): robustness of per-state action and (c): lowerbound of cumulative rewards. In (a) and (c), each column corresponds to one smoothing variance.
