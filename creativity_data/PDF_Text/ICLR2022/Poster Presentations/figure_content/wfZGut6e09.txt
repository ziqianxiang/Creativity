Figure 2: (a) The Convex Coverage Set (CCS) for a 2-dimensional value function. Algorithm 1 identi-fies arbitrary solutions on the Pareto front. (b) Illustration of the PPA loss function for a single preferencevector ω0: by minimizing the distance ∣∣ω*(θ) — ω0∣∣, the solution converges to the optimal solution Cor-responding to preference ω0. (c) PPA loss function for two preference vectors ω0, ω1: the minimizer of∣∣ω*(θ)— ω0∣∣ + ∣∣ω*(θ) — ω1 ∣ (also called the geometric median) gives the optimal solution because itmaximizes the projections onto the preference vectors.
Figure 4: Learning curves on MuJoCo environments. We show the Pareto Dominance (PD) and AverageUtility (UT) metrics. Experiments are run for 10 random seeds. We compare against the non-adaptive PPA andthe fixed-preferences agents.
Figure 5: OpenAI Gym enviroments used in our experimental results.
