Figure 1:	The hierarchical framework of GCHRL.
Figure 2:	A schematic illustration of the subgoal selection and perturbation.
Figure 3: Visualization of visitation density and potential in the Ant Maze task. (a) Visitation densityin the x,y coordinate space of the Ant robot. (b) Visitation density in the subgoal representationspace. (c) Feature changes between 0.15M and 0.2M steps for the same batch of states. (d) Potentialfor the sampled state embeddings. (e) Combination of novelty and potential in Section 3.3. Ourmethod selects state embeddings with darker colors as subgoals.
Figure 4: Learning curves of the proposed method and baselines on all the tasks. The y axis showsthe average success rate in 10 episodes. Each line is the mean of 5 runs with shaded regions cor-responding to a confidence interval of 95%. An the curves have been smoothed equally for visualclarity. Code is available at https://github.com/SiyuanLee/HESS.
Figure 5: Ant Mazeoptimizing the contrastive objective, the Euclidean distances in the latent space approximately cor-7Published as a conference paper at ICLR 2022(a)HESSFigure 6: SUbgoal representation learning process in the Ant Maze (Images) task. Each subfigurecontains 2D state embeddings of 5 trajectories in the ⊃-shape maze (red for the start, blue for theend). For larger axis labels, see videos of the representation learning process at https://sites.
Figure 6: SUbgoal representation learning process in the Ant Maze (Images) task. Each subfigurecontains 2D state embeddings of 5 trajectories in the ⊃-shape maze (red for the start, blue for theend). For larger axis labels, see videos of the representation learning process at https://sites.
Figure 7: Ablation studies of representation learning and the exploration strategy.
Figure 8: Visualization of the selected subgoals during 10 episodes and their corresponding positionsin the x,y space in the Ant Maze task at 0.25 million timesteps.
Figure 9: Ablation studies of hyper-parameter selection in the Ant Push (Images) task.
Figure 10: A collection of benchmark sparse-reward environments.
Figure 11: The variance of the intrinsic rewards of the H-SR method in the Ant Maze task, withx-axis as millions of environment timesteps.
Figure 12: X-Y traces of skills learned by DADS in the Ant Maze task, where the same colorrepresents trajectories resulting from the execution of the same skill.
Figure 13: Trajectories in the XY space and the FuN representation space. The dimension of theFuN representation space is 50, and we use t-SNE to perform dimension reduction and visualize thelatent trajectories.
Figure 14: Ablation studies on additional hyper-parameters.
Figure 15: Ablation studies on the imagined subgoals in Ant Push and Ant Push (Images) task.
Figure 16: Different novelty estimation in the Ant Maze task.
Figure 17: Different implementations of weighting function λ(S).
