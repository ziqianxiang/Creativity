Figure 1: Performance curves for validation (left) and training (right) accuracy for each model across30 trials on the CIFAR-100 dataset. Standard errors are plotted but are too small to see. Dashedcurves are the models with a single type of normalization (canonical or divisive), black is the vanillaAlexNet (NoNorm), and solid curves are models with DN followed by a canonical normalization.
Figure 2: The radial Fourier power (i.e., integrated over θ in polar coordinates) averaged over the96 receptive fields (filters) in layer 1 of AlexNet for each architecture. Columns are red, green,and blue channels respectively. Rows show models with batch (blue lines), group (green lines)and layer (orange lines) respectively; darker color is divisive+canonical, lighter is canonical alone.
Figure 3: The receptive fields (RFs) for each of the 3 channels for the first 16 features along thetopological line of 96 features in layer one for the Divisive model show many wide-set Gabor-likefilters. (#’s 1-16 are arranged in English reading order, i.e. row 1 has #’s 1-4.)layer one for the NoNorm model show a wider variety of filters with more irregularity and moresmall-scale features. In Figs. 3-4: the 16 appear fully representative, space precludes showing all 96.
Figure 5: The mean field theory manifold capacity is calculated on the 50 least correlated classes(Cohen et al., 2020) for the ImageNet training data, using responses to 100 images randomly selectedfor each class. Results are shown for the ReLU layers of the NoNorm, DivisiveBatch, Batch, andDivisive models. Vertical grey lines indicate ReLU layers. Error bars denote the standard error acrossfive different seeds of these 100 randomly selected images in each class.
Figure 6: The sparsity, as measured by the Gini index (1 = most sparse, 0 = all activations equal),for the validation set of images at epoch 90, for CIFAR-100 models. Results are show for canonical(e.g., Batch; dashed color) and combined divisive-canonical (e.g., Divisive Batch, solid color) modelsinvolving the batch norm (blue, left panel), the group norm (green, middle), and the layer norm(orange, right), as well as NoNorm (black) and Divisive (purple) models (repeated in all 3 panels,for comparisons). The vertical purple lines indicate where the divisive normalization occurs formodels that have it. Similarly the vertical blue, green, and orange lines indicate where a canonicalnormalization, e.g. batch, group, or layer norm respectively, occurs.
Figure 7: Dependence of performance on initial normalization parameters λ and k for the Divisive-Batch model. Red, orange, blue, and purple indicate initial λ values of 1, 2, 5, and 10 respectively.
Figure 8:	Dependence of performance on initial normalization parameters λ and k for the Divi-siveGroup model. Larger λ values result in a modest performance improvement, as does largerk.
Figure 9:	Dependence of performance on normalization parameters λ and k for the DivisiveLayermodel. There appears to be a clear preference in the DivisiveLayer model to initialize with a larger λand k. This improvement is more pronounced relative to the DivisiveGroup model in which a largerλ only gave modest improvement19Published as a conference paper at ICLR 2022C Divisive Normalization Parameters LearnedUsing the parameter initializations explored in the prior section we plot the resulting normalizationparameters that develop. All of the models learn slightly different divisive normalization parametersdepending on the initial conditions. The Divisive model did not learn reliably enough for such aparameter search to be informative. However, there are some common trends across the combinedmodels. For example, generally λ and k are relatively stable throughout learning. In contrast, the αand β values change a lot initially and settle to some steady state after about 20 epochs.
Figure 10: The different normalization Parameters learned for the DivisiveBatch model over ePochs.
Figure 11: The different normalization parameters learned for the DivisiveBatch model over epochs.
Figure 12: The different normalization parameters learned for the DivisiveLayer model over epochs.
Figure 13: The mean field theory manifold capacity is calculated on the 50 least correlated classes(Cohen et al., 2020), using responses to 100 images randomly selected for each class, for the ReLUlayers of the NoNorm, DivisiveBatch, Batch, and Divisive models. Vertical purple lines indicatewhere divisive normalization would occur, vertical blue lines indicate where Batch normalizationwould occur, and vertical grey lines indicate ReLU or convolutional layers. Error bars denote thestandard error across five different samples of these 100 randomly selected images in each class.
Figure 14: The mean field theory manifold capacity is calculated on the 50 least correlated classesCohen et al. (2020) with 100 images randomly selected for each class for the ReLU layers of theNoNorm, DivisiveGroup, Group, and Divisive models. Vertical purple lines indicate where divisivenormalization would be present, vertical green lines indicate where Group normalization would bepresent, and vertical grey lines indicate ReLU or convolutional layers. Error bars denote the standarderror across five different samples of these 100 randomly selected images in each class.
Figure 15: The mean field theory manifold capacity is calculated on the 50 least correlated classesCohen et al. (2020) with 100 images randomly selected for each class for the ReLU layers of theNoNorm, DivisiveLayer, Layer, and Divisive models. Vertical purple lines indicate where divisivenormalization would be present, vertical orange lines indicate where Layer normalization would bepresent, and vertical grey lines indicate ReLU or convolutional layers. Error bars denote the standarderror across five different samples of these 100 randomly selected images in each class.
Figure 16: Left shows the Mean Field Theory (MFT) capacity plotted relative to the simulationcapacity values layer by layer. The black line is the unity line. The second plot shows the layer-wiseMFT capacities with the standard error plotted for each ReLU in the network. The third plot showsthe layer-wise simulation capacities plotted for each ReLU. Deviations from the simulation capacityin the MFT capacity plot could indicate real changes in the underlying neural manifold geometry.
Figure 17: Distribution of activities for the validation set of images at epoch 90, for CIFAR-100models involving batch normalization, along with the divisive and NoNorm models: Batch (lighterblue), DivisiveBatch (darker blue), Divisive (purple), NoNorm (black).
Figure 18: Distribution of activities for the validation set of images at epoch 90, for CIFAR-100models involving group normalization, along with the divisive and NoNorm models: Group (lightergreen), DivisiveGroup (darker green), Divisive (purple), NoNorm (black).
Figure 19: Distribution of activities for the validation set of images at epoch 90, for CIFAR-100models involving layer normalization, along with the divisive and NoNorm models: Layer (lighterorange), DivisiveLayer (darker orange), Divisive (purple), NoNorm (black).
Figure 20: The receptive fields for the first 25 features of the Divisive model. They are clearly widefield Gabor-like receptiVe fields of Various orientations in most channels. Some are more amorphousFigure 21: For the first 25 features of the receptiVe fields in the NoNorm model, there are more smallscale fluctuations that are not as preValent in the receptiVe fields of the normalized models.
Figure 21: For the first 25 features of the receptiVe fields in the NoNorm model, there are more smallscale fluctuations that are not as preValent in the receptiVe fields of the normalized models.
Figure 22: For the first 25 features of the receptive fields in the DivisiveBatch model, there are moresmall scale fluctuations than those seen in the Divisive model. This could mean that the DivisiveBatchmodel, while it performs better in accuracy, may not be filtering out small scale fluctuations as well.
Figure 23: The first 25 features of the receptive fields in the Batch model. There are more roundedreceptive fields that appear Gaussian-like. The larger structures could be more large-scale edgedetectors.
Figure 24: Projective gradient descent (PGD) attacks: Using batch sizes of 64, the inputs weregiven perturbations of L2 norm in the direction of the gradient of the loss function with respect tothe input. The Layer model is the most robust. Models with divisive normalization tend to be theleast robust.
Figure 25: Fast Gradient Sign Method (FGSM) attacks: Similarly to the PGD attack, measuresthe strength of the attack. Models with divisive normalization perform poorly relative to NoNorm,except for the DivisiveGroup model for a range of stronger attacks. The most robust models areLayer (weaker attacks) and Batch (stronger attacks).
Figure 26:	L2 Additive Gaussian Noise attack: Using batch sizes of 64, the inputs were perturbedby random Gaussian noise of standard deviation . For the largest perturbations, most of the modelswith Divisive normalization (Divisive, DivisiveBatch, DivisiveLayer) are more robust than the othermodels. For somewhat weaker perturbations, DivisiveGroup is the most robust of the models.
Figure 27:However, many of the models' decisions were “other” - a category corresponding to neither the shapenor the texture - and the models with divisive normalization had increased “other” decisions (66.8%for Divisive vs. 61.1% for NoNorm; 72.67% for DivisiveBatch vs. 63.75% for Batch). Thus, themodels with divisive normalization had an increased shape bias, yet had the same number of or fewershape decisions out of all categorizations. This gives some hope of divisive normalization and itsincreased low- or moderate-spatial-frequency power improving shape sensitivity, but does not allowclear conclusions.
Figure 28: The mean 1D pairwise correlations between features, as a function of the distance betweenthem in the feature dimension, for each convolutional layer, for the DivisiveBatch (Blue,Dashed),Batch (Blue), Divisive (Purple), and NoNorm (Black) models. Shaded regions indicate the standarderror of the pairwise correlations. Fluctuations in the correlations grow significantly for furtherdistances as the sample size decreases. This is because many of these layers only have 256 or 384features, so for correlation distances of 250+ there are very few pairs.
Figure 29: The mean 1D pairwise correlations between features, as a function of the distance betweenthem in the feature dimension, for each convolutional layer, for the DivisiveGroup (Green,Dashed),Group (Green), Divisive (Purple), and NoNorm (Black) models. Otherwise as in figure 28.
Figure 30: The mean 1D pairwise correlations between features, as a function of the distance betweenthem in the feature dimension, for each convolutional layer, for the DivisiveLayer (Orange,Dashed),Layer (Orange), Divisive (Purple), and NoNorm (Black) models.
Figure 31: Violin plots of the NoNorm, Divisive, Batch and DivisiveBatch models indicate a modestdrop in the medians and interquartile ranges of the divisively normalized distributions. This differenceis significant for DivisiveBatch vs. Batch but not for Divisive vs. NoNorm, see discussion of statisticaltests in this Appendix.
