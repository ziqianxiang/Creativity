Figure 1: Training loss v.s.
Figure 2: Test error v.s. n inExperiment 2 by the two modelswith m = 8192.
Figure 3: Test error v.s. n in Ex-periment 3 by the three modelswith m = 8192.
Figure 4: Results of Experiment 3 when n = 600. Each column corresponds to a different scalingof the P-3L NN model, as described in Table 1. Row 1: Evolution of training loss (solid curve)and test error (dashed curve) during training. Row 2: Distribution of the hidden-layer feature map(pre-activation) associated with two particular input data points. Each dot represents a different i,(i.e., neuron in the second hidden layer,) and the x- and y-coordinates equal hi(x1) and hi(x2),respectively, where x1 is an input from the training set and x2 is an input from the test set.
Figure 5: Training loss v.s. number of GD steps for different n in Experiment 1 with m = 4096.
Figure 6: Test error v.s. GD steps in Experiment 2 for the two models and difference choices of n.
Figure 7: Same as Figure 4 except for setting n = 400.
Figure 8: Same as Figure 4 except for setting n = 800.
