Table 1: The scaling config forGiraffeDet family - φd is thehyper-parameter that denotes thedepth (# of layers) of GFPN. Thewidth (# of channels) of GFPN can becalculated based on φw by Equation3.
Table 2: GiraffeDet performance on COCO - Results for single-model single-scale. test-dev is the COCOtest set and Val is the validation set. f means that the results are reproduced by 6x scratch training, others arereferred from their paper. We group models together if they have similar FLOPs, and compare their accuracyin each group. MStest : multiscale testing, R: ResNet, X: ResNext, and W: low-level features map width inHRNet (# of channels). The head and anchor assigner of GiraffeDet family are GFocalV2 and ATSS.
Table 3: Ablation study on the Connection analysis. The model of “GFPN w/o skip” neck designedwithout any skip-layer connection, “GFPN-dense” neck model utilizes dense-link and “GFPN-log2n” neck model utilizes log2n-link.
Table 4: Ablation study on Depth & Width analysis. All models apply S2D-chain as their backbone.
Table 5: Val-2017 results of the deformable convolution network applied in GiraffeDet-DII. ∣ denotes theGFPN with synchronized batch normalization (Zhang et al., 2018) for multi-GPU training.
Table 6: val-2017 results of Res2Net-101-DCN (R2-101-DCN) backbone with multiple GFPN necks. GFPN-tiny refers to GFPN of depth as 8 and width as 122 (same FLOPs level as FPN).
Table 7: Structure of Space-To-Depth chain used in our experimentsOperation Layer	Number of Filters	Size of Each Filter	Stride Value	Padding Value	Size of Output Feature	FLOPsInput Image	-	-	-	-	1280x768x3	0Convolution Layer	32	3x3x3	2x2	1x1	640 x 384 x 32	0.21GSiLU Layer	-	-	-	-	640 x 384 x 32	0.21GConvolution Layer	64	3 x 3 x 32	2x2	1x1	320x192x64	1.34GSiLU Layer	-	-	-	-	320x192x64	1.34GSpace-to-Depth	-	-	-	-	160x96x256	1.34GConvolution Layer	128	1 x 1 x 256	1x1	0x0	160x96x128	1.85GSiLU Layer	-	-	-	-	160x96x128	1.85GSpace-to-Depth	-	-	-	-	80 x 48 x 512	1.85GConvolution Layer	256	1 x 1 x512	1x1	0x0	80 x 48 x 256	2.35GSiLU Layer	-	-	-	-	80 x 48 x 256	2.35GSpace-to-Depth	-	-	-	-	40 x 24 x 1024	2.35GConvolution Layer	512	1 x 1 x 1024	1x1	0x0	40 x 24 x 512	2.85GSiLU Layer	-	-	-	-	40 x 24 x 512	2.85GSpace-to-Depth	-	-	-	-	20x 12 x 2048	2.85GConvolution Layer	1024	1 x 1 x 2048	1x1	0x0	20x 12x 1024	3.36GSiLU Layer	-	-	-	-	20x 12x 1024	3.36GSpace-to-Depth	-	-	-	-	10x6x4096	3.36G
Table 8: List of hyperparameters used.
Table 9: Comparison on inference time between “ResNet + FPN” model and “S2D-chain + GFPN” model onthe same FLOPs level.
Table 10: val-2017 results of standard backbone with stacked BiFPN and proposed GFPN.
