Table 1: Results for the structure-based experiments. We depict the test accuracy obtained on variousbenchmark data sets when only considering structural information (i.e. the network has access touninformative node features). For MOLHIV, the ROC-AUC is reported. Graph classification resultsare shown on the left, while node classification results are shown on the right. We compare threearchitectures (GCN-4, GIN-4, GAT-4) with corresponding models where one layer is replaced withTOGL and highlight the winner of each comparison in bold.
Table 2: Test accuracy on benchmark data sets (following standard practice, we report weightedaccuracy on CLUSTER and PATTERN). Methods printed in black have been run in our setup, whilemethods printed in grey are cited from the literature, i.e. Dwivedi et al. (2020), Morris et al. (2020) forIMDB -B and REDDIT-B, and Borgwardt et al. (2020) for WL/WL-OA results. Graph classificationresults are shown on the left; node classification results are shown on the right. Following Table 1,we take existing architectures and replace their second layer by TOGL; we use italics to denote thewinner of each comparison. A bold value indicates the overall winner of a column, i.e. a data set.
Table 3: Test accuracy when comparing TOGL (integrated into a simplified architecture) with existingtopology-based embedding functions or readout functions. Results shown in grey are cited fromthe respective papers (Carriere et al., 2020; Hofer et al., 2020). For GFL, We cite degree-based resultsso that its performance values pertain to the same scenario.
Table S4:	Error rates when using persistent homology with a degree filtration to classify pairs ofk-regular on n vertices. R3-N12 denotes 3-regular graphs on 12 vertices, for instance. This list is byno means exhaustive, but indicates the general utility of persistent homology and its filtration-basedanalysis.
Table S5:	Parameters of learning rate scheduling (including ‘patience’ parameters) for training ofmodels in this work.
Table S6:	The set of hyperparameters that we use to train TOGL, along with their respective valueranges. Notice that ‘dropout‘ could be made configurable, but this would make our setup incomparableto the setup proposed by Dwivedi et al. (2020) for benchmarking GNNs.
Table S7:	Test accuracies for different layer positions. TOGL can be placed at different positions.
Table S8:	Test accuracies for different layer positions. TOGL can be placed at different positions.
Table S9:	Test Accuracies for different structural data sets.
Table S10: Results for the structure-based experiments. We depict the test accuracy obtained onvarious benchmark data sets when only considering structural information (i.e. the network hasaccess to uninformative node features). Graph classification results are shown on the left, while nodeclassification results are shown on the right.
Table S11: Test accuracy on benchmark data sets (following standard practice, we report weightedaccuracy on CLUSTER and PATTERN). Methods printed in black have been run in our setup, whilemethods printed in grey are cited from the literature, i.e. Dwivedi et al. (2020), Morris et al. (2020)for IMDB-B and REDDIT-B, and Borgwardt et al. (2020) for WL/WL-OA results GIN-4 resultsprinted in italics are 1-layer GIN-, as reported in Morris et al. (2020). Graph classification resultsare shown on the left, while node classification results are shown on the right.
Table S12:	Test accuracy of the different methods on the Spheres vs. Torus classification task. Wecompare two architectures (GCN-4, GIN-4) with corresponding models where one layer is replacedwith TOGL and highlight the winner of each comparison in bold.
Table S13:	Graph classification results for the structure-based experiments. We depict the testaccuracy obtained on various benchmark data sets when only considering structural information (i.e.
Table S14: Test accuracy on benchmark data sets. Graph classification results are shown on the left;node classification results are shown on the right. Following Table 1, we take existing architecturesand replace their second layer by TOGL; we use italics to denote the winner of each comparison. Abold value indicates the overall winner of a column, i.e. a data set.
