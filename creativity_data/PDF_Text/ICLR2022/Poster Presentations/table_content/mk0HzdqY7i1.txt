Table 1: Results of the tree searches in various configurations; the full table with more datasets andmore configuration options can be found in Table 2. For all configurations, in the first row, we statethe average MIS size as well as the average approximation factor. In the second row, the averagetime in seconds until the best solution was found, and, in brackets, the number of graphs where anysolution was found are given. The average values refer only to the graphs within a dataset for which asolution was found. For Intel, here we show the default setting (d) and the setup with both reductionand local search enabled (r+ls). For DGL, we explore the configuration space further, as we analyzethe default (d), reduction and local search (r+ls), queue pruning and weighted queue pop (qp+wp),and the full configuration where we replace the GCN by randomly generated outputs (+rand). Forthe random graphs of size 50-100, all solvers have a time limit of 15 seconds; for the SATLIB and PPIdatasets the time limit is 30 seconds; for VC-BM and DIMACS graphs, the time limit is 5 minutes.
Table 2:	Results of the tree searches in various configurations. We run experiments on both syntheticand real-world graphs with varying numbers of nodes (c.f. Appendix E). For all configurations, inthe first row, we state the average MIS size as well as the average approximation factor for graphswhere we were able to pre-calculate the provably optimal MIS using Gurobi. In the second row, theaverage time in seconds until the best solution was found, and, in brackets, the number of graphswhere any solution was found are given. The average values refer only to the graphs within a datasetfor which a solution was found. Columns that start with a plus (+) add an additional flag to theprevious column; columns that do not start with a plus use just the stated flags. For Intel, we start withthe default setting (d), proceed to include the graph reduction (+r), and then the local search (+ls),and last test reduction and local search in a multithreaded setup (+mt). For DGL, we explore theconfiguration space further. After analyzing the default (d), adding reduction (+r), and local search(+ls), we test configurations replacing the GCN with random outputs (rand), using queue pruning(qp), and weighted queue pop (+wp). We also test a combination of reduction, queue pruning, andweighted queue pop (+r), proceed to add the local search (+ls), and again replace the GCN byrandomly generated outputs (+rand). The full configuration is tested with and without randomoutput in a multithreaded setup (+mt). All multithreaded experiments in this table use 8 threads,and all threads share a single GPU. For the random graphs of size 50-100, all solvers have a timelimit of 15 seconds; for the SATLIB, as-caida, PPI, REDDIT, Citeseer, Cora, and ego-facebookdatasets the time limit is 30 seconds; for the bitcoin, PubMed, Wikipedia, VC-BM, DIMACS, androadnet-berlin graphs, the time limit is 5 minutes. We refer to Appendix B for detailed explanations
Table 3:	Results of the modern MIS solver KaMIS, the optimization tool Gurobi, the reinforcement-learning based Learning What To Defer, and the tree search algorithms in their default and fullconfiguration. For the explanation of the various configuration flags, we refer to the caption of Table 2.
Table 4: Results of the modern MIS solver KaMIS, the optimization tool Gurobi, the reinforcement-learning based Learning What To Defer, and the tree search algorithms in their full configuration,on huge random graphs and huge real world networks. We do not test huge ER graphs due to the timecomplexity of generating them, and do not test BA graphs as they are similar to HK graphs. For theexplanation of the various configuration flags, we refer to the caption of Table 2. All multithreadedexperiments in this table use 8 threads, and all threads share a single GPU. The time limit for all graphswas set to 3 hours. For LwD, the algorithm is executed with with 128 iterations per episode (c.f. Ahnet al. (2020)). We mark the configuration that has the best average MIS in bold. Configurations thatconsumed too much VRAM or DRAM are noted as out of memory (OOM).
Table 5: Results of the MIS solver KaMIS, the optimization tool Gurobi, and the DGL-TreeSearch in various configurations on weighted random graphs, and Amazon MWIS instances.
Table 6: Run times results of the the optimization tool Gurobi with default and tuned parameters(c.f. Appendix D.1) For the explanation of the various configuration flags, we refer to the captionof Table 2. Time limits are set equally to Table 2. Gurobi employs up to 8 threads, as needed. Wemark the configuration/solver that has the best average MIS in bold.
Table 7: Results of the modern MIS solver KaMIS, the reinforcement-learning based LearningWhat To Defer, the tree search algorithms in their default and full configuration, in comparisonto Gurobi with the MIS as a linear program (default) and quadratic program (quadratic).
