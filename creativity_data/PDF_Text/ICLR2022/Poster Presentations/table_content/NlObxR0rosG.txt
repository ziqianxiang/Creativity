Table 1: Area under the PR curve (percentage).
Table 2: Tabular dataset semi-supervised accuracy (%).
Table 6: Area under the ROC curve (percentage)	I GAN		ODIN	MSMA	OE	CCU	Hybrid	Int. Reg.
Table 7: MNIST leave one out: AUPR (%)Method	I 0	1	2	3	4EGBAD	78	29	67	52	46SA: Rotation	89.24	83.57	78.20	66.33	90.45Global & Local	95.26 ± 1.98	89.67 ± 4.33	86.02 ± 3.19	93.41 ± 1.88	69.89 ± 7.02	I 5	6	7	8	9EGBAD	43	57	35	54	35SA: Rotation	83.38	75.57	95.19	68.84	84.88Global & Local	87.76 ± 2.1	91.7 ± 2.84	83.43 ± 3.72	87.5 ± 2.91	72.9 ± 7.23C Training and ArchitecturesC.1	SpiralsThe bijective layer is composed of five blocks where each block contains an affine-coupling layer(Dinh et al., 2017) and an invertible fully connected layer. The data distribution is bimodal overboth latent dimensions with means at ±1 and standard deviations of 0.4. The separable network iscomposed of quadratic functions. We train the model as discussed, using the standard cross-entropy17Published as a conference paper at ICLR 2022Table 8: MNIST leave one out: AUROC (%)Method	0	1	2	3	4EGBAD	78	29	67	52	45
Table 8: MNIST leave one out: AUROC (%)Method	0	1	2	3	4EGBAD	78	29	67	52	45GANomaloy	88	65	95	79	80SA: Rotation	98.85	98.17	94.60	94.22	98.23Global & Local	95.93 ± 1.91	89.32 ± 4.76	84.83 ± 3.94	94.25 ± 1.25	74.49 ± 6.98	5	6	7	8	9EGBAD	43	57	39	55	36GANomaloy	85	85	68	85	55SA: Rotation	97.21	92.52	99.16	92.69	97.02Global & Local	89.47 ± 2.32	93.11 ± 2.98	83.45 ± 4.01	88.42 ± 2.97	75.66 ± 5.65loss for each observed point, the negative log-likelihood over the input space, and the global cross-entropy integration with respect to the contrastive prior. The learning rate is set to 0.001 with standardweight decay of 1e-4 over 20 epochs using Adam (Kingma & Ba, 2015).
