Table 1: Ablation experiments of SCRFD-2.5GF (i.e. CR@two-steps+SR) on the WIDER FACEvalidation subset. “CR” and “SR” denote the proposed computation and sample redistribution, re-SPectively. Results are reported on the single-scale VGA resolution.
Table 2: Accuracy and efficiency of different methods on the WIDER FACE validation set. #Paramsand #Flops denote the number of parameters and multiply-adds. “Infer” refers to network inferenceEency on NVIDIA 2080TL___________________________________________________________________________Method	Backbone	Easy	Medium	Hard	#Params(M)	#Flops(G)	Infer(ms)DSFD@VGA	ResNet152	94.29	91.47	71.39	120.06 二	259.55	55.6DSFD@Multi-Scale	ResNet152	96.6	95.7	90.4	120.06	15928.5	-RetinaFace@VGA	ResNet50	94.92	91.90	64.17	29.50	37.59	21.7RetinaFace@Multi-Scale	ResNet50	96.7	96.1	91.4	29.50	4585.98	-BFBox@VGA	-	94.2	92.1	70.4	28.6	39.4	22.4BFBox@Multi-Scale	-	96.5	95.7	91.7	28.6	4732.8	-HAMBox@VGA	ResNet50	95.27	93.76	76.75	30.24	43.28	25.9HAMBox@Multi-Scale	ResNet50	97.0	96.4	93.3	30.24	5246.23	-TinaFace@VGA	ResNet50	95.61	94.25	81.43	37.98	172.95	38.9TinaFace@Multi-Scale	ResNet50	97.0	96.3	93.4	37.98	42333.64	-ResNet-34GF@VGA	ResNet50	95.64	94.22	84.02	24:81	34.16	-118-CRFD-34GF@VGA	Bottleneck Res	96.06	94.92	85.29	9.80	34.13	11.7SCRFD-34GF@VGA	Bottleneck Res	96.05	94.96	86.21	9.80	34.13	11.7SCRFD-34GF@Multi-Scale	Bottleneck Res	97.20	96.58	93.53	9.80	2098.98	-ResNet-10GF@VGA	ResNet34x0.5	94.69	92.90	80.42	685	10.18	63CRFD-10GF@VGA	Basic Res	95.16	93.87	83.05	3.86	9.98	4.9
Table 3: Accuracy and efficiency of different light-weight models on the WIDER FACE validationset. #Params and #Flops denote the number of parameters and multiply-adds. “Infer” refers tonetwork inference latency on NVIDIA 2080TLMethod	Backbone	Easy	Medium	Hard	#Params(M)	#Flops(G)	Infer(ms)RetinaFace@VGA	MobileNet0.25	87.78	81.16	47.32	0.44 二	0.802	7.9RetinaFace@Original	MobileNet0.25	89.58	87.11	69.12	0.44	2.358	-RetinaFace@Multi-Scale	MobileNet0.25	91.4	89.2	82.5	0.44	49.28	-FaceBoxes@VGA	-	76.17	57.17	24.18	1.01	0.275	2.5FaceBoxes@Original	-	84.5	77.7	40.4	1.01	0.809	-FaceBoxes@Multi-Scale	-	85.9	81.6	55.7	1.01	16.93	-libfacedetection@Original	-	85.6	84.2	72.7	2.33	3.25	-LFFD@Original	-	91.0	88.0	77.8	2.15	27.20	-MobileNet-1.0GF@VGA	MobileNet0.25	91.66	89.28	70.46	063	1.024	49CRFD-1.0GF@VGA	Depth-wise Conv	92.38	90.57	74.80	0.64	0.982	4.1SCRFD-1.0GF@VGA	Depth-wise Conv	92.36	90.58	76.03	0.64	0.982	4.1SCRFD-1.0GF@Original	Depth-wise Conv	91.89	89.96	84.70	0.64	2.89	-SCRFD-1.0GF@Multi-Scale	Depth-wise Conv	93.87	92.99	88.74	0.64	60.39	-MobileNet-0.5GF@VGA	MobileNet0.25	90.38	87.05	66.68	037	0.507	37CRFD-0.5GF@VGA	Depth-wise Conv	90.57	88.12	68.51	0.57	0.508	3.6SCRFD-0.5GF@VGA	Depth-wise Conv	90.80	88.43	68.82	0.57	0.508	3.6
Table 4: Performance and computation comparisons of TinaFace under different testing scales. Theaverage scale of original images is around 882 X 1024.
Table 5: Detailed network configurations for baselines and the proposed CRFD across different com-pute regimes. Basic residual blocks are used in ResNet-2.5GF and ResNet-10GF, while bottleneckresidual blocks are used in ResNet-34GF. For MobileNet-1.0GF and MobileNet-0.5GF, depth-wiseconvolution is Used in both backbone and head._________________________________________Name	Conv Type	Stem	Backbone Depth	Backbone Width	Neck	HeadResNet-34GF	Bottleneck Res	256	[3,4,6,3]=	[256,512,1024,2048]	128	[256,256]CRFD-34GF	Bottleneck Res	56	[17,16,2,8]	[56,56,144,184]	128	[256,256]ResNet-10GF	Basic Res	32	[3,4,6,3]	[32,64,128,256]	128	[160,160]CRFD-10GF	Basic Res	56	[3,4,2,3]	[56,88,88,224]	56	[80,80,80]ResNet-2.5GF	Basic Res	16	[3463]	[16,32,64,128]	48	[96,96]CRFD-2.5GF	Basic Res	24	[3,5,3,2]	[24,48,48,80]	24	[64,64]MobileNet-1.0GF	Depth-wise Conv	16	[3373]	[32,64,128,256]	64	[128,128]CRFD-1.0GF	Depth-wise Conv	48	[3,2,1,5]	[48,160,216,312]	24	[96,96]MobileNet-0.5GF	Depth-wise Conv	16	[2,2,6,3]	[32,64,128,256]	32	[80,80]CRFD-0.5GF	Depth-wise Conv	16	[2,3,2,6]	[40,72,152,288]	16	[64,64](a) Ground-truth Distribution(b) Positive Anchor DistributionFigure 7:	Ground-truth and positive anchor distribution within one epoch for the SCRFD-2.5GFtraining. The baseline method employs a scale augmentation based on the hand-crafted set [0.3, 1.0]and [0.3, 2.0], while our method uses a searched scale set for optimized scale augmentation. The
Table 6: Performance comparisons between different models on AFW, PASCAL, and FDDBdatasets. The proposed SCRFD is tested on the single-scale VGA resolution.
