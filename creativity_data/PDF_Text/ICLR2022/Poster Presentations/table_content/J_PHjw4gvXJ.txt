Table 1: The network model for text classification Table 2: Description of four data setsInput 768-dimensional text representation	Data sets	Classes	Fine-tune / Pretrain(768, 768) linear layer, ReLU	SST-2	2	2 × 500(768, 768) linear layer, ReLU	SST-5	5	5 × 500(768, 10) linear layer, Tanh	CIFAR10	10	10 × 4000(10, size of labels) linear layer	CIFAR100	2	0Data Sets and Model Preparation. We choose 4 data sets for text and image classification, and weuse part of training examples in the data sets to prepare for the subsequent training of the models.
Table 3: Settings of the training process on 4 data setsData sets	Fine-tune / Pretrain	Stage 1	Stage 2SST-2 or SST-5	Adam(5e-6) epochs:5 batch size:8	Adam(1e-2) epochs:15 batch size:50	Adam(1e-2) epochs:10 batch size:50CIFAR10	follow the training (Springenberg et al., 2014)	Adam(1e-6) epochs:200 batch size:128	Adam(1e-5) epochs:10 batch size:128CIFAR100	-	follow the training (Springenberg et al., 2014)	Adam(1e-4) epochs:10 batch size:128Table 4: Results of six methods on four data setsMethods	SST-2 100:1000	SST-5 50:500	CIFAR10 50:500	CIFAR100 40:400Baseline	75.52 ± 2.99	40.24 ± 0.99	69.95 ± 3.35	85.00 ± 1.10Proportion	79.59 ± 3.35	42.59 ± 1.12	79.58 ± 0.34	85.20 ± 1.21Two-phase	81.99 ± 0.80	42.60 ± 1.44	79.63 ± 0.44	86.00 ± 1.61Hu et al.’s	81.57 ± 0.74	39.82 ± 1.07	79.36 ± 0.51	85.40 ± 1.07Hu et al.’s+R	82.25 ± 1.16	40.14 ± 0.39	79.55 ± 0.21	86.50 ± 2.41Ours.	82.58 ± 0.98	44.62 ± 1.08	79.71 ± 0.37	87.40 ± 1.66The settings of the training process on the four data sets are listed in Table 3. Each cell in the tableindicates the settings in the current stage, including the optimizer used, learning rate, number ofepochs, and batch size, where the value in brackets is the learning rate. In text classification, we useAdam optimization. In image classification, we first follow the implementation of Springenberg etal. to use SGD optimization, and then we use Adam to optimize in subsequent training.
Table 4: Results of six methods on four data setsMethods	SST-2 100:1000	SST-5 50:500	CIFAR10 50:500	CIFAR100 40:400Baseline	75.52 ± 2.99	40.24 ± 0.99	69.95 ± 3.35	85.00 ± 1.10Proportion	79.59 ± 3.35	42.59 ± 1.12	79.58 ± 0.34	85.20 ± 1.21Two-phase	81.99 ± 0.80	42.60 ± 1.44	79.63 ± 0.44	86.00 ± 1.61Hu et al.’s	81.57 ± 0.74	39.82 ± 1.07	79.36 ± 0.51	85.40 ± 1.07Hu et al.’s+R	82.25 ± 1.16	40.14 ± 0.39	79.55 ± 0.21	86.50 ± 2.41Ours.	82.58 ± 0.98	44.62 ± 1.08	79.71 ± 0.37	87.40 ± 1.66The settings of the training process on the four data sets are listed in Table 3. Each cell in the tableindicates the settings in the current stage, including the optimizer used, learning rate, number ofepochs, and batch size, where the value in brackets is the learning rate. In text classification, we useAdam optimization. In image classification, we first follow the implementation of Springenberg etal. to use SGD optimization, and then we use Adam to optimize in subsequent training.
Table 5: Results of different imbalance ratios on SST-2 data setMethods	10:1000	20:1000	100:1000Baseline	49.92 ± 0.00	49.92 ± 0.00	75.52 ± 2.99Proportion	60.63 ± 13.13	78.76 ± 2.40	79.59 ± 3.35Two-phase	75.35 ± 8.90	80.52 ± 1.96	81.99 ± 0.80Hu et al.’s	55.84 ± 11.84	73.61 ± 11.86	81.57 ± 0.74Hu et al.’s+R	66.68 ± 13.99	79.53 ± 1.64	82.25 ± 1.16Ours.	80.62 ± 0.93	81.14 ± 1.25	82.58 ± 0.98Table 6: Results of different imbalance ratios on CIFAR100 data setMethods	4:400	8:400	40:400Baseline	64.40 ± 11.98	77.40 ± 12.23	85.00 ± 1.10Proportion	60.50 ± 8.40	69.60 ± 8.56	85.20 ± 1.21Two-phase	66.00 ± 13.95	79.50 ± 3.75	86.00 ± 1.61Hu et al.’s	60.20 ± 8.19	69.10 ± 8.08	85.40 ± 1.07Hu et al.’s+R	71.80 ± 11.73	82.50 ± 4.27	86.50 ± 2.41Ours.	77.20 ± 3.75	82.60 ± 3.87	87.40 ± 1.66Results The results on the four data sets are shown in Table 4. We can see that our method hasthe best performance in these 4 data sets. Especially on the SST-5 data set, our method exceeds thesecond-best method by more than 2 accuracy points. It demonstrates that our method can performwell in multiple domains and different classification scenarios. Hu et al.’+R and Two-phase are
Table 6: Results of different imbalance ratios on CIFAR100 data setMethods	4:400	8:400	40:400Baseline	64.40 ± 11.98	77.40 ± 12.23	85.00 ± 1.10Proportion	60.50 ± 8.40	69.60 ± 8.56	85.20 ± 1.21Two-phase	66.00 ± 13.95	79.50 ± 3.75	86.00 ± 1.61Hu et al.’s	60.20 ± 8.19	69.10 ± 8.08	85.40 ± 1.07Hu et al.’s+R	71.80 ± 11.73	82.50 ± 4.27	86.50 ± 2.41Ours.	77.20 ± 3.75	82.60 ± 3.87	87.40 ± 1.66Results The results on the four data sets are shown in Table 4. We can see that our method hasthe best performance in these 4 data sets. Especially on the SST-5 data set, our method exceeds thesecond-best method by more than 2 accuracy points. It demonstrates that our method can performwell in multiple domains and different classification scenarios. Hu et al.’+R and Two-phase arecompetitive methods. On the SST-2 and CIFAR100, Hu et al.’+R is the second-best, and on theSST-5 and CIFAR10, Two-phase also reaches the second-best. It shows that using a balanced dataset to simply adjust a biased model can also achieve good results. In addition, Hu et al.’+R performsbetter than Hu et al.’s. on all data sets, and on the CIFAR100, it surpasses the latter by more than1 accuracy point. It indicates that adding regularization to the validation learning can effectivelyimprove the method (Hu et al.). However, on the SST-5, the method (Hu et al.) performs worse thanthe baseline, which may be due to the ineffectiveness of the approximation on SST-5. The accuracyof the proportion method is lower than that of our method by more than 2 accuracy points on the
Table 8: Description of APS Failure datasetTable 7: The network model for APS FailuredatasetInput 171-dimensional examples	Classes	Train Set	Validation Set	Test Set(171,100) linear layer, ReLU					Negative	10000	1000	5(100, 100) linear layer, Tanh				(100, 2) linear layer	Positive	10	1000	5Table 9: Results with different metrics on APS Failure datasetMethods	Accuracy	Marco-F1 score	G-meansBaseline	50.00 ± 0.00	33.33 ± 0.00	0.00 ± 0.00Proportion	93.29 ± 2.59	93.27 ± 2.63	93.17 ± 2.78Two-phase	93.19 ± 0.87	93.19 ± 0.87	93.15 ± 0.89Hu et al.’s	94.09 ± 0.94	93.35 ± 1.73	93.28 ± 1.79Hu et al.’s+R	93.98 ± 1.78	94.65 ± 0.76	94.65 ± 0.76Ours.	94.49 ± 0.70	95.10 ± 0.66	94.86 ± 0.58Dataset and Models. APS Failure dataset is from UCI Machine Learning Repository (Dua & Graff,2017). This dataset contains 76000 examples. We randomly construct the train, validation and testdata sets from the original data set. These sub-data sets are described in Table 8. The train setconsists of 10000 negative examples and 10 positive examples, which is extremely imbalanced, and
Table 7: The network model for APS FailuredatasetInput 171-dimensional examples	Classes	Train Set	Validation Set	Test Set(171,100) linear layer, ReLU					Negative	10000	1000	5(100, 100) linear layer, Tanh				(100, 2) linear layer	Positive	10	1000	5Table 9: Results with different metrics on APS Failure datasetMethods	Accuracy	Marco-F1 score	G-meansBaseline	50.00 ± 0.00	33.33 ± 0.00	0.00 ± 0.00Proportion	93.29 ± 2.59	93.27 ± 2.63	93.17 ± 2.78Two-phase	93.19 ± 0.87	93.19 ± 0.87	93.15 ± 0.89Hu et al.’s	94.09 ± 0.94	93.35 ± 1.73	93.28 ± 1.79Hu et al.’s+R	93.98 ± 1.78	94.65 ± 0.76	94.65 ± 0.76Ours.	94.49 ± 0.70	95.10 ± 0.66	94.86 ± 0.58Dataset and Models. APS Failure dataset is from UCI Machine Learning Repository (Dua & Graff,2017). This dataset contains 76000 examples. We randomly construct the train, validation and testdata sets from the original data set. These sub-data sets are described in Table 8. The train setconsists of 10000 negative examples and 10 positive examples, which is extremely imbalanced, andits imbalance rate reaches 1:1000. The validation and test sets are balanced data sets, and their
Table 9: Results with different metrics on APS Failure datasetMethods	Accuracy	Marco-F1 score	G-meansBaseline	50.00 ± 0.00	33.33 ± 0.00	0.00 ± 0.00Proportion	93.29 ± 2.59	93.27 ± 2.63	93.17 ± 2.78Two-phase	93.19 ± 0.87	93.19 ± 0.87	93.15 ± 0.89Hu et al.’s	94.09 ± 0.94	93.35 ± 1.73	93.28 ± 1.79Hu et al.’s+R	93.98 ± 1.78	94.65 ± 0.76	94.65 ± 0.76Ours.	94.49 ± 0.70	95.10 ± 0.66	94.86 ± 0.58Dataset and Models. APS Failure dataset is from UCI Machine Learning Repository (Dua & Graff,2017). This dataset contains 76000 examples. We randomly construct the train, validation and testdata sets from the original data set. These sub-data sets are described in Table 8. The train setconsists of 10000 negative examples and 10 positive examples, which is extremely imbalanced, andits imbalance rate reaches 1:1000. The validation and test sets are balanced data sets, and theirexample sizes for each class are 5 and 1000 respectively. In addition, APS Failure dataset datasethas 171 features, and we replace the missing feature values with the average of the examples in thesame class. Finally, we scale the all feature values to [0, 1]. The model for APS Failure dataset isshown in Table 7 and is a simple 3-layer FCN.
