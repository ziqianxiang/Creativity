Table 1: Comparison results of test accuracy (%) between C-DropEdge, GCN, DropEdge, and DGN.
Table 2: Comparison results of test accuracy at various edge preserving rates. Critical preservingpercentage for each dataset is marked in bold. The three best results per model are shaded in blue .
Table 3: Details of DatasetsDataset	Nodes	Edges	Classes	Features	Critical Edge Sampling	Train/Val/TestCora	2,708	5,429	7	1,433	24.94%	0.05/0.18/0.37Citeseer	3,327	4,732	6	3,703	35.15%	0.04/0.15/0.30Pubmed	19,717	44,338	3	500	22.23%	0.003/0.03/0.05Physics	34,493	247,962	5	500	6.96 %	0.003/0.004/0.99Table 4: Comparison results of test accuracy (%) with different infinite-wide backbones.								Dataset Backbone	4-layer	8-layer	32-layer	64-layer Orignal C-DropEdge Original C-DropEdge Original C-DropEdge Original C-DropEdge							GCN Cora JKNet	79.98	79.98	79.48	80.61	73.75	75.86	72.59	74.03	78.27	77.29	80.26	80.02	78.00	79.01	75.90	76.75GCN Citeseer JKNet	66.38	66.97	54.42	64.88	50.72	51.22	43.77	46.49	67.04	67.67	65.54	66.45	54.57	56.39	46.71	47.96GCN Pubmed JKNet	74.59	74.77	73.58	76.67	71.63	74.77	66.28	71.72	75.30	74.35	76.42	77.17	75.71	76.68	74.81	75.74F.2 Experimental ImplementationWe use the PyTorch implementation to simulate both infinitely-wide and finitely-wide GCNs:•	The infinitely-wide GCNs use part of code from Du et al. (2019b), which is originallyadopted for graph classification. We redesign the calculation method of GNTK (Du et al.,2019b)2 according to the formula in Section 3.1 and use it to process node classificationtasks.
Table 4: Comparison results of test accuracy (%) with different infinite-wide backbones.								Dataset Backbone	4-layer	8-layer	32-layer	64-layer Orignal C-DropEdge Original C-DropEdge Original C-DropEdge Original C-DropEdge							GCN Cora JKNet	79.98	79.98	79.48	80.61	73.75	75.86	72.59	74.03	78.27	77.29	80.26	80.02	78.00	79.01	75.90	76.75GCN Citeseer JKNet	66.38	66.97	54.42	64.88	50.72	51.22	43.77	46.49	67.04	67.67	65.54	66.45	54.57	56.39	46.71	47.96GCN Pubmed JKNet	74.59	74.77	73.58	76.67	71.63	74.77	66.28	71.72	75.30	74.35	76.42	77.17	75.71	76.68	74.81	75.74F.2 Experimental ImplementationWe use the PyTorch implementation to simulate both infinitely-wide and finitely-wide GCNs:•	The infinitely-wide GCNs use part of code from Du et al. (2019b), which is originallyadopted for graph classification. We redesign the calculation method of GNTK (Du et al.,2019b)2 according to the formula in Section 3.1 and use it to process node classificationtasks.
Table 5: Comparison results of test accuracy (%) between C-DroPEdge and DropEdge.
