Table 2: Metrics computed for the best-FID checkpoint for different source and target datasets. Eachrow corresponds to a particular target dataset, and each column corresponds to a particular sourcemodel used to initialize the training. For each target dataset, we highlight (by orange) the sourcesthat provide the smallest FID or which FID differs from the best one by at most 5%. In each cell, wereport from to bottom: FID, Precision, Recall, and convergence rate measured in millions of images(lower is better). In purpose to make the table easier to read, we report std only once it exceeds 5%which happens rarely. The typical values vary around 0.1.
Table 3: Reconstruction errors for GAN models with different source and target datasets.
Table 5: Datasets information.
Table 6: FID distances between source and target datasets. Underlined cell in a row correspondsto a source domain that is closest to a fixed target. Datasets names are shortened as: L.Bdr(LSUN Bedroom), L.Cat (LSUN Cat), L.Chr (LSUN Church), L.Dog (LSUN Dog), S.Bld (Satel-lite Buildings), S.Lnd (Satellite Landscapes), Imgn (Imagenet), C-10 (CIFAR-10), Flw (Flowers),GC (Grumpy Cat), S (Simpsons), BCH (BreCaHAD).
Table 7: KID distances between source and target datasets computed. Highlighted cell in a rowcorresponds to a source domain that is closest to a fixed target.
Table 8: The Precision values computed for the targets datasets w.r.t. the source datasets.
Table 9: The Recall values computed for the targets datasets w.r.t. the source datasets.
Table 10: Number of real images shown to the discriminator (step) for the checkpoint with the bestFID value, this value and corresponding precison and recall values for long-term trainings with twoinitialization options.
Table 11: Finetuning to Flowers from a converged source checkpoint and from a checkpoint thatpasses two times fewer steps.
