Table 1: Performance (mean ± std) on different datasets and different models with different metrics.
Table 2: Ablation study on the factor size n and Isomorphism Loss. DCI disentanglement is listed(mean ± std).
Table 3: Architecture of the encoder and decoder of VAEs. For Original VAE, the dimension of inputof the decoder is 10. For Groupified VAE, the dimension is 20. Note that the number of representationdimensions of Groupified VAE is still 10, which is the same as Original VAE, the comparison withOriginal VAE is fair Watters et al. (2019).
Table 4: Hyperparameters and random seeds for every model.
Table 5: Shared hyperparameters in all experiments. LReLU stands for leaky ReLU.
Table 6: Performance (mean ± std) on different datasets and different models with different metrics.
Table 7: Downstream task performance on themodels trained on the representation learned byoriginal and groupified FactorVAE.
Table 8: Performance (mean ± variance) on different datasets of RGrVAE and Groupified β-TCVAEwith different metrics. These settings include different random seeds and hyperparameters.
Table 9: Performance (mean ± variance) on different datasets of ControlVAE and Groupified Con-trolVAE with different metrics. These settings include different random seeds and hyperparameters.
Table 10: Performance (mean ± variance) on dSprites of Original and Groupified β-TCVAE withdifferent metrics. The results under different regularize strength are reported.
Table 11: Performance (mean ± variance) on Shapes3D of Original and Groupified β-TCVAE withdifferent metrics. The results under different regularize strength are reported.
Table 12: Performance (mean ± variance) on Color dSprites of Original and Groupified β-TCVAEwith different metrics. The results under different regularize strength are reported.
