Table 1: The validation result of the 1D regression models on the GP dataset in fixed variance andlearned variance settings. The higher LLs are the better. The models of NP, NP with variational prior(NP+VP), NP with deterministic path (NP+CNP), NP+CNP+VP and NVDP (ours) are compared.
Table 2: The summary of2D image completion tasks on the MNIST, CelebA, and Omniglot dataset.
Table 3: Few-shot classification results on Omniglot and MiniImageNet dataset. The baselines areMatching Nets, Prototypical Nets, MAML, Meta-SGD, Meta-dropout, CNP, VERSA, and NVDP(our). Each value corresponds to the classification accuracy (%) (and std) on validation set.
Table 4:	An additional summary of the 1D regression with the GP with random kernel dataset. Thedeterministic baseline (CNP) is presented. We could observe that the performance of the CNP isclose to or slightly better than the NP+CNP in Tables 1 of the manuscript. However, the CNP modelcould lose the functional variability as shown in Figure 2.
Table 5:	An additional summary of the 2D image completion tasks on the MNIST, CelebA, andOmniglot dataset. The deterministic baseline (CNP) is presented. We could observe that the per-formance of the CNP is close to or slightly better than the NP+CNP in Tables 2 of the manuscript.
