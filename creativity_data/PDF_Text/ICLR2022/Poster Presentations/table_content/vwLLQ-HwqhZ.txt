Table 1: Evaluation metrics on the pMNIST benchmark. The magnitude of the differences arecalculated as ∆(k = ∣∣ω(kN - ω(kN* ∣∣ι, where ω ∈ {μ,σ2} and k ∈ {1, 2} denotes the first orsecond BN layer. Bold indicates the best scores.
Table 2: Evaluation metrics of different normalization layers on the Split CIFAR100 and Split MiniIMN benchmarks. Bold indicates the best averaged Scoresj suffix indicates non-adaptive methodER Norm. Layer	Split CIFAR100			Split Mini IMN			ACC(↑)	FMa)	LA(↑)	ACC(↑)	FMQ)	LA(↑)NoNL	55.87±0.46	4.46±0.48	57.26±0.64	47.40±2.80	3.17±0.99	45.31±2.18BNt	64.97±1.09	9.24±1.98	71.56±0.75	59.09±1.74	8.57±1.52	65.24±0.52BRNt	63.47±1.33	8.43±1.03	69.83±2.52	54.55±2.70	6.66±1.84	58.53±1.88IN	59.17±0.96	11.47±0.92	69.40±0.93	48.74±1.98	15.28±1.88	62.88±1.13GN	63.42±0.92	7.39±1.24	68.03±0.19	55.65±2.92	8.31±1.00	59.25±0.72SN	64.79±0.88	7.92±0.64	71.10±0.51	56.84±1.37	10.11±1.46	64.09±1.53CN(ours)	67.48±0.81	7.29±1.59	74.27±0.36	64.28±1.49	8.08±1.18	70.90±1.16DER++	Split CIFAR100			Split Mini IMN		Norm. Layer	ACC(↑)	FMa)	LA(↑)	ACC(↑)	FMQ)	LA(↑)NoNL	57.14±0.46	4.46±0.48	57.26±0.64	47.18±3.20	2.77±1.68	45.01±3.35BNt	66.50±2.52	8.58±2.28	73.78±1.02	61.08±0.91	6.90±0.99	66.10±0.89BRNt	66.89±1.22	6.98±2.23	73.30±0.08	57.37±1.75	6.66±1.84	66.53±1.56IN	61.18±0.96	10.59±0.77	71.00±0.57	54.05±1.26	11.82±1.32	65.03±1.69GN	66.58±0.27	5.70±0.69	69.63±1.12	60.50±1.91	6.17±1.28	63.10±1.53SN	67.17±0.23	6.01±0.15	72.13±0.23	57.73±1.97	8.92±1.84	63.87±0.64CN(ours)	69.13±0.56	6.48±0.81	74.89±0.40	66.29±1.11	6.47±1.46	71.75±0.68
Table 3: Running time of ER on the SPlit CI-FAR100 benchmarks of different normalizationlayers. ∆% indicates the Percentage increases oftraining time over BN	BN	GN	SN	CNTime (s)	1583	1607	2036	1642∆%	0%	1.51%	28.61%	3.72%Setting We consider the online task incremental (Task-IL) and class incremental (Class-IL) learn-ing Problems on the SPlit-CIFAR10 (SPlit CIFAR-10) and SPlit-Tiny-ImageNet (SPlit Tiny IMN)benchmarks. We follow the same exPeriment setuPs as Buzzega et al. (2020) excePt the number oftraining ePochs, which we set to one. All exPeriments uses the DER++ strategy (Buzzega et al.,2020) on a ResNet 18 (He et al., 2016) backbone (not Pre-trained) trained with data augmentationusing the SGD oPtimizer. We consider three different total ePisodic memory sizes of 500, 2560, and5120, and focus on comParing BN with our ProPosed CN in this exPeriment.
Table 4: Evaluation metrics of DER++ with different normalization layers on the Split CIFAR-10and Split Tiny IMN benchmarks. Parentheses indicates the number of groups in CN. Bold indicatesthe best averaged scoresBuffer	Method		Split CIFAR-10				Split Tiny IMN						Class-IL		TaSk-IL		Class-IL		Task-IL				ACC(↑)	FMa)	ACC(↑)	FMa)	ACC(↑)	FMa)	ACC(↑)	FMa)	BN		48.9±4.5	33.6±5.8	82.6±2.3	3.2±1.9	6.7±0.1	38.1±0.5	40.2±0.9	6.5±1.0500	CN (G =	8)	48.9±0.3	27.9±5.0	84.7±0.5	2.2±0.3	7.3±0.9	37.5±2.3	42.2±2.1	4.9±2.2	CN (G =	32)	51.7±1.9	28.2±4.0	86.2±2.2	2.0±1.3	6.5±0.7	40.1±1.7	40.6±1.4	6.8±1.9	BN		52.3±4.6	29.7±6.1	86.6±1.6	0.9±0.7	11.2±2.3	36.0±2.0	50.8±1.7	2.8±1.22560	CN (G =	8)	53.7±3.4	25.5±4.7	87.3±2.7	1.6±1.6	10.7±1.3	38.0±1.2	52.6±1.2	1.5±0.5	CN (G =	32)	57.3±2.0	21.6±5.6	88.4±1.1	1.7±1.1	11.9±0.3	36.7±1.2	51.5±0.2	2.8±0.9	BN		52.0±7.8	26.7±10.3	85.6±3.3	2.0±1.5	11.2±2.7	36.8±2.0	52.2±1.7	2.6±1.55120	CN (G =	8)	54.1±4.0	24.0±4.0	87.1±2.8	0.7±0.7	12.2±0.6	34.6±2.6	53.1±1.8	3.1±1.9	CN (G =	32)	57.9±4.1	22.2±1.0	88.3±0.9	1.3±0.9	12.2±0.2	35.6±1.3	54.9±1.5	1.5±1.1(a) Split CIFAR-10, Task-ILFigure 2: The evolution of ACC(↑) on observed tasks so far on the Split CIFAR-10 and Split TinyIMN benchmarks, Task-IL screnario with DER++ and memory size of 5120 samples.
Table 5: Evaluation metrics of the PRS strategy on the COCOseq and NUS-WIDEseq benchmarks.
Table 6: Forgetting measure (FMa)) of each metric from the PRS strategy on the COCOseq andNUS-WIDEseq benchmarks, lower is better. We report the mean performance over five runs. Boldindicates the best averaged scoresCOCOseq	Majority			Moderate			Minority				Overall		C-F1	O-F1 mAP		C-F1	O-F1	mAP	C-F1 O-F1 mAP			C-F1	O-F1	mAPBN	23.5	22.8	8.4	30.0	30.2	9.4	36.2	35.7	13.2	29.7	29.5	9.7CN(ours)	23.5	23.1	6.5	26.9	26.9	7.4	26.8	26.5	12.2	25.6	25.7	8.0NUS-WIDEseq	C-F1	Majority O-F1	mAP	Moderate C-F1 O-F1 mAP			C-F1	Minority O-F1	mAP	C-F1	Overall O-F1	mAPBN	54.6	50.7	12.5	62.2	61.9	15.5	52.5	52.4	12.2	57.6	55.7	11.2CN(ours)	52.7	48.7	8.6	58.8	58.0	10.3	51.2	50.6	11.6	57.4	55.5	8.15.4	Discussion of The ResultsOur experiments have shown promising results for CN being a potential replacement for BN in on-line continual learning. While the results are generally consistent, there are a few scenarios whereCN does not perform as good as other baselines. First, from the task-incremental experiment in Ta-ble 2, DER++ with CN achieved lower FM compared to GN. The reason could be from the DER++’ssoft-label loss, which together with GN, overemphasizes on reducing FM and achieved lower FM.
Table 7: Dataset summary	#task	img size	#training imgs	#testing imgs	#classes	SectionpMNIST	5	28×28	10,000	50,000	10	Section 3.2Split CIFAR10	5	3×32×32	50,000	10,000	10	Section 5.2Split CIFAR100	20	3×84×84	50,000	10,000	100	Section 5.1Split Mni IMN	20	3×84×84	50,000	10,000	100	Section 5.1Split Tiny IMN	10	3×64×64	100,000	10,000	200	Section 5.2COCOseq	4	3×224×224	35,072	6,346	70	Section 5.3NUS-WIDEseq	6	3×224×224	48,724	2,367	49	Section 5.3where w and w0 are the learned blending factors to combine the three moments and are learned bybackpropagation.
Table 8: Evaluation metrics of CN variants on the Split Mini IMN and COCOseq benchmarks(overall classes). We report the mean results over five runs. Bold indicates highest score, “tw”indicates tied weight in the affine parametersCN Variant	SPIitMini IMN			COCOseq			ACC	FM	LA	C-F1	O-F1	mAPGN→BN(original)	64.28	8.08	70.90	53.1	49.8	55.1BN→GN	62.63	9.92	71.43	51.5	47.9	53.8GN→BN+tw	62.17	9.21	70.17	51.1	47.7	53.3BN→GN+tw	62.23	8.20	69.30	50.0	47.4	52.5Online Task-IL and Class-IL Continual Learning Benchmarks (Split CIFAR-10 and Split TinyIMN) We follow the protocol as the DER++ work (Buzzega et al., 2020) except the number ofepochs, which we set to one. Particularly, training is performed with data augmentation on both thedata stream and the memory samples (random crops, horizontal flips). We follow the configurationsprovided by the authors, including the hyper-parameters of mini-batch size, the reservoir samplingmemory management strategy, learning rates, etc. For the memory size of 2560, which were notconducted in the original paper, we use the same setting as the case of 5120 memory slots.
Table 9: Comparison with BN* on the 4-tasks Split CIFAR-100 benchmarks. Bold indicates the bestaveraged scoresER	Split CIFAR-100(4tasks)			ACC	FM	LABN	60.14±3.47	6.21±1.99	63.98±2.38BN*	61.38±2.46	5.87±1.37	65.01±1.78GN	55.96±2.43	2.23±0.79	53.25±2.44CN	62.18±0.56	5.66±0.76	64.94±1.68D.5 Additional Results of BN*We further investigate the performance of BN* on the Split-CIFAR100 benchmark and report andreport the result in Table 9. Since BN* requires calculating the true moments from all observed data,we cannot scale it to the standard benchmark of 17 tasks. Table 9 only consider a sequence of fourtasks, which is the maximum memory capacity that our GPU allows. Interestingly, we observe thatGN achieves low FM in this experiment, suggesting that GN does not suffer much from catastrophicforgetting early on during training, or when the sequence of tasks is short. As there are more tasks,we expect the gap among different methods to be more significant as demonstrated throughout ourwork.
Table 10: Evaluation metrics of the naive single strategy on the task-aware Split CIFAR-100 andSplit mini IMN benchmarks. Bold indicates the best averaged scoresSingle	Split CIFAR-100			Split mini IMN			ACC	FM	LA	ACC	FM	LABN	33.47±2.24	33.93±2.23	65.74±2.22	32.26±2.42	29.76±0.98	57.20±1.25BRN	28.74±2.53	31.78±3.06	58.02±1.94	25.60±0.93	25.77±2.04	49.43±1.37GN	36.66±2.32	17.40±2.33	52.62±1.61	28.05±1.17	12.97±2.02	39.60±1.55CN	34.52±2.62	33.27±1.23	66.37±1.00	34.23±1.37	29.05±0.74	61.11±1.61Table 11: Evaluation metrics of DER++ with different normalization layers on the Split CIFAR-10and Split Tiny IMN benchmarks. Parentheses indicates the number of groups in CN. Bold indicatesthe best averaged scores. This is the full version of Table 4Buffer	Method	Split CIFAR-10				Split Tiny IMN					Class-IL		Task-IL		Class-IL		Task-IL			ACC(↑)	FMa)	ACC(↑)	FMa)	ACC(↑)	FMa)	ACC(↑)	FMa)	BN	48.9±4.5	33.6±5.8	82.6±2.3	3.2±1.9	6.7±0.1	38.1±0.5	40.2±0.9	6.5±1.0	IN	35.9±2.0	45.0±3.6	78.8±1.6	1.8±0.9	2.2±0.5	16.9±0.9	20.6±0.5	1.7±0.5c∩∩	GN	46.8±5.1	29.7±11.5	82.1±5.2	1.9±1.2	7.2±0.4	36.0±2.4	41.1±0.5	4.5±1.8500	SN	42.3±3.9	32.3±11.6	80.6±3.4	2.6±2.0	4.5±1.0	25.0±2.4	33.6±1.3	2.5±1.9	CN (G=8)	48.9±0.3	27.9±5.0	84.7±0.5	2.2±0.3	7.3±0.9	37.5±2.3	42.2±2.1	4.9±2.2	CN (G=32)	51.7±1.9	28.2±4.0	86.2±2.2	2.0±1.3	6.5±0.7	40.1±1.7	40.6±1.4	6.8±1.9
Table 11: Evaluation metrics of DER++ with different normalization layers on the Split CIFAR-10and Split Tiny IMN benchmarks. Parentheses indicates the number of groups in CN. Bold indicatesthe best averaged scores. This is the full version of Table 4Buffer	Method	Split CIFAR-10				Split Tiny IMN					Class-IL		Task-IL		Class-IL		Task-IL			ACC(↑)	FMa)	ACC(↑)	FMa)	ACC(↑)	FMa)	ACC(↑)	FMa)	BN	48.9±4.5	33.6±5.8	82.6±2.3	3.2±1.9	6.7±0.1	38.1±0.5	40.2±0.9	6.5±1.0	IN	35.9±2.0	45.0±3.6	78.8±1.6	1.8±0.9	2.2±0.5	16.9±0.9	20.6±0.5	1.7±0.5c∩∩	GN	46.8±5.1	29.7±11.5	82.1±5.2	1.9±1.2	7.2±0.4	36.0±2.4	41.1±0.5	4.5±1.8500	SN	42.3±3.9	32.3±11.6	80.6±3.4	2.6±2.0	4.5±1.0	25.0±2.4	33.6±1.3	2.5±1.9	CN (G=8)	48.9±0.3	27.9±5.0	84.7±0.5	2.2±0.3	7.3±0.9	37.5±2.3	42.2±2.1	4.9±2.2	CN (G=32)	51.7±1.9	28.2±4.0	86.2±2.2	2.0±1.3	6.5±0.7	40.1±1.7	40.6±1.4	6.8±1.9	BN	52.3±4.6	29.7±6.1	86.6±1.6	0.9±0.7	11.2±2.3	36.0±2.0	50.8±1.7	2.8±1.2	IN	36.1±2.8	37.8±8.8	79.1±1.1	0.8±1.4	2.4±0.4	19.2±1.5	25.4±1.7	0.6±0.52560	GN	53.3±3.5	28.8±3.2	87.3±2.4	0.6±0.7	11.0±1.3	35.5±1.2	50.9±3.0	1.9±1.6	SN	42.3±3.9	30.8±10.4	80.0±6.4	4.7±5.2	4.4±1.4	27.3±2.9	37.6±3.0	3.5±1.8	CN (G=8)	53.7±3.4	25.5±4.7	87.3±2.7	1.6±1.6	10.7±1.3	38.0±1.2	52.6±1.2	1.5±0.5	CN (G=32)	57.3±2.0	21.6±5.6	88.4±1.1	1.7±1.1	11.9±0.3	36.7±1.2	51.5±0.2	2.8±0.9	BN	52.0±7.8	26.7±10.3	85.6±3.3	2.0±1.5	11.2±2.7	36.8±2.0	52.2±1.7	2.6±1.5	IN	32.2±4.5	41.5±3.6	77.2±3.8	2.1±2.3	2.3±0.6	18.0±1.3	25.5±2.0	1.6±0.9
Table 12: Effects of different moving average strategies on the Split CIFAR-100 benchmark, withER+BNMoving Average			SPlitCIFAR-100					ACC	FM	LACMA		N/A	35.86±0.90	20.24±1.30	45.53±3.65	η	= 0.01	62.90±2.03	6.32±2.32	64.81±1.15	η	= 0.05	63.61±1.11	7.18±1.08	68.43±0.87EMA	η	= 0.1	64.97±1.09	9.24±1.98	71.56±0.75	η	= 0.5	62.43±2.65	8.54±2.76	68.86±0.51	η	= 0.9	61.46±2.36	9.03±2.38	66.81±1.49D.8 Analysis of the moving average in BNWe now explore how the moving average affects BN. First, we consider the cumulative movingaverage (CMA) strategy which keeps the standard average of the statistics for the first n mini-batchesof data as:x1 + x2 + . . . + xnXCMA =------------------------,nwhere xCMA is the CMA moving average statistic, xt is the t- mini-batch statistic.
Table 13: Standard deviations of the evaluation metrics of the PRS strategy on the COCOseq andNUS-WIDEseq benchmarksCOCOseq	Majority			Moderate			Minority			Overall			C-F1	O-F1	mAP	C-F1	O-F1	mAP	C-F1	O-F1	mAP	C-F1	O-F1	mAPBN	0.77	1.33	1.04	0.98	1.28	1.04	2.35	2.33	1.78	0.89	1.24	1.07CN(ours)	1.20	1.97	1.12	0.61	1.27	0.66	1.73	1.53	0.59	0.64	1.22	0.63NUS-WIDEseq	C-F1	Majority O-F1	mAP	Moderate C-F1 O-F1 mAP			C-F1	Minority O-F1	mAP	C-F1	Overall O-F1	mAPBN	1.01	1.97	0.91	1.72	1.77	0.68	1.95	1.78	1.44	0.47	0.27	0.55CN(ours)	2.38	1.59	1.33	2.78	3.06	0.97	1.72	1.05	0.58	1.26	1.40	0.34Table 14: Standard deviations of the forgetting measure (FM(J) ) of each metric from the PRSstrategy on the COCOseq and NUS-WIDEseq benchmarks, lower is betterCOCOseq	Majority			Moderate			Minority			Overall			C-F1	O-F1 mAP		C-F1	O-F1	mAP	C-F1	O-F1	mAP	C-F1	O-F1	mAPBN	3.77	4.60	0.44	3.11	2.80	1.63	4.63	4.32	2.34	2.63	2.93	1.29CN(ours)	3.31	3.62	2.53	1.46	1.54	1.72	5.72	6.32	0.80	1.26	1.34	1.34NUS-WIDEseq	C-F1	Majority O-F1	mAP	Moderate C-F1 O-F1 mAP			C-F1	Minority O-F1	mAP	C-F1	Overall O-F1	mAPBN	7.35	8.19	1.49	6.60	7.03	1.35	13.34	13.24	4.14	4.71	5.11	1.08CN(ours)	7.59	6.60	4.16	8.89	9.14	3.77	7.35	7.15	7.42	2.00	2.38	3.08shows the stdev values of the evaluation metrics while Table 14 shows the stdev values of the FMassociating with each evaluation metric.
Table 14: Standard deviations of the forgetting measure (FM(J) ) of each metric from the PRSstrategy on the COCOseq and NUS-WIDEseq benchmarks, lower is betterCOCOseq	Majority			Moderate			Minority			Overall			C-F1	O-F1 mAP		C-F1	O-F1	mAP	C-F1	O-F1	mAP	C-F1	O-F1	mAPBN	3.77	4.60	0.44	3.11	2.80	1.63	4.63	4.32	2.34	2.63	2.93	1.29CN(ours)	3.31	3.62	2.53	1.46	1.54	1.72	5.72	6.32	0.80	1.26	1.34	1.34NUS-WIDEseq	C-F1	Majority O-F1	mAP	Moderate C-F1 O-F1 mAP			C-F1	Minority O-F1	mAP	C-F1	Overall O-F1	mAPBN	7.35	8.19	1.49	6.60	7.03	1.35	13.34	13.24	4.14	4.71	5.11	1.08CN(ours)	7.59	6.60	4.16	8.89	9.14	3.77	7.35	7.15	7.42	2.00	2.38	3.08shows the stdev values of the evaluation metrics while Table 14 shows the stdev values of the FMassociating with each evaluation metric.
