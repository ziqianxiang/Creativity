Table 1: Test accuracy of RoBERTa classifiers after fine-tuning with each data augmentation methodon 6 different text classification datasets under (5-shot / full) setups. All the values and error barsare mean and standard deviation across 3 random seeds. The best and the second best results areindicated in bold and underline, respectively.
Table 2: Comparison of classification performance (bACC/GM) with RoBERTa classifiers on 3different text classification datasets under 2 different class-imbalance ratio γimb . Except the gray-colored row, the classifiers are fine-tuned with over-sampled datasets augmented by each dataaugmentation method. All the values and error bars are mean and standard deviation across 3 randomseeds. The best and the second best results are indicated in bold and underline, respectively.
Table 3: Evaluation results of vanilla (RoBERTa) classifiers with the GLUE development set afterfine-tuning with each data augmentation method on the given task. All the values are mean across 3random seeds and the standard deviation is presented in Appendix C. The best and the second bestresults are indicated in bold and underline, respectively. Gray-colored scores are those lower than thecorresponding vanilla scores.
Table 4: Ablation study on different criteria for updating policy. Test accuracy of vanilla (RoBERTa)classifiers after fine-tuning across various augmentations and learning objectives on News20 andReview50 are compared. All the values and error bars are mean and standard deviation across 3random seeds. The best and the second best results are indicated in bold and underline, respectively.
Table 5: Transferability of DND: test accuracy of the specified language model after fine-tuningacross various augmentations. The augmentation policy learned with RoBERTa on News20 dataset isused as a base policy being transferred. All the values and error bars are mean and standard deviationacross 3 random seeds. The best is indicated in bold.
Table 6: Evaluation results of vanilla (RoBERTa) classifiers with the GLUE development set afterfine-tuning with each data augmentation method on the given task. All the values and error barsare mean and standard deviation across 3 random seeds. The best and the second best results areindicated in bold and underline, respectively.
Table 7: Evaluation results of vanilla (RoBERTa) classifiers with the GLUE test set after fine-tuningwith each data augmentation method on the given task. For evaluation, we submit the predictionaveraged across 3 random seeds. The better results are indicated in bold.
Table 8: Experimental results to verify the compatibility among different language models. Testaccuracy of specified classifiers after fine-tuning across various data augmentations are compared.
Table 9: Ablation study on different choices for similarity loss.
Table 10: Ablation study on the effect of reconstruction lossDataset	λr = 0	λr = 0.05News20	84.88±0.19	85.19±0.35ReVieW50	74.52±o.o3	74.87±o.i7Effect of extra losses. While the extra losses Lsim (Eq. 4) and Lrecon (Eq. 5) are introduced forupdating policy with DND, these losses could contribute to the learning of better representationsand lead to the improVement themselVes. To Verify this, we conduct the additional experimentsabout these auxiliary losses. Here, when each loss is applied, the fixed coefficients are used: 1 forLsim and 0.05 for Lrecon. In Table 11, it is Verified that each of the proposed losses could improVethe performance contributing to the learning of better representations, and two auxiliary losses arecomplementary to each other.
Table 11: Effect of extra losses Lsim and Lrecon.
Table 12: Effect of different number of augmentation policies.
Table 13: Effect of different number of operations T .
Table 14: Effect of different values for hyper-parameters α and β .
Table 15: Effect of different values for hyper-parameters λr .
Table 16: Effect of different Tp .				Table 17: Effect of different λs .			Dataset	Tp = 1	Tp = 5	Tp = 10	Dataset	λs = 0.1	λs = 0.5	λs = 1.0News20	84.99±0.07	85.19±o.35	85.11±0.15	News20	85.06±o.27	85.19±0.35	84.97±0.15Review50	74.72±0.22	74.87±o.i7	74.89±0.20	Review50	74.17±o.03	74.87±0.i7	74.35±0.04Effect of auxiliary operation. As we have mentioned in Appendix A.3, we adopt the auxiliaryoperation for our implementation, which has been originally used by Hataya et al. (2020). Here, weprovide the results without this auxiliary operation. As one can see in Table 18, this operation is notsignificant to the gain from DND.
Table 18: Effect of auxiliary operation (Hataya et al., 2020).
