Table 1: Ablation on the impact of semi-parametric approach and the future conditioning of skill priorTask (Unseen)	FIST (ours)	FIST (Euc.)	SPiRL	SPiRL (closest)	SpiRL (H-steps)Microwave, Kettle, Top Burner, Light Switch	3.6 土 0.16	3.3 ± 0.15	2.1 ± 0.48	0.0 ± 0.0	0.2 ± 0.13Microwave, Bottom Burner, Light Switch, Slide Cabinet	2.3 士 0.5	2.8 ± 0.42	2.3 ± 0.49	2.8 ± 0.44	0.0 ± 0.0Microwave, Kettle, Slide Cabinet, Hinge Cabinet	3.5 ± 0.3	3.0 ± 0.32	1.9 ± 0.29	0.0 ± 0.0	0.0 ± 0.0Microwave, Kettle, Slide Cabinet, Hinge Cabinet	4.0 ± 0.0	1.3 ± 0.14	3.3 ± 0.38	2.4 ± 0.51	1.5 ± 0.418Under review as a conference paper at ICLR 2022Comparison of SPiRL results suggests that the performance would degrade if the semi-parameteric lookupmethod is used to pick the conditioning state in SPiRL. This is not surprising since the model in SPiRL istrained to condition on the current state and is unable to pick a good skill z based on p(z|sclosest) in SPiRL(closest) or p(z|sclosest+H) in SPiRL (H-steps). Therefore, it is crucial to have the prior as p(z|st, st+H), sothat we can condition on both the current and future goal state.
Table 2: We ablate the use of pre-training on offline data, as well as fine-tuning on downstream demonstrations. FIST-no-FT removes the fine-tuning on downstream demonstration step in FIST, while FIST-no-pretrain trains the skills purelyfrom the given downstream data. Without seeing the subtask, FIST-no-FT is unable to solve the downstream subtask.
Table 3: Training HyperparametersHyperparameter	ValueContrastive Distance Metric	Encoder output dim	32Encoder Hidden Layers	128Encoder # Hidden Layers	2Optimizer	Adam(β1 = 0.9, β2 = 0.999, LR=1e-3)Skill extraction	Epochs	200Batch size	128Optimizer	Adam(β1 = 0.9, β2 = 0.999, LR=1e-3)H (sub-trajectory length)	10β	5e-4 (Kitchen), 1e-2 (Maze)Skill Encoder	dim-Z in VAE	128hidden dim	128# LSTM Layers	1Skill Decoder	hidden dim	128# hidden layers	5
Table 4: Fine-tuning hyperparametersHyperparameter	ValueEpochs	50Epoch cycle train	10B	Environment and Dataset DetailsIn this section we explain the tasks and the procedure for data collection for both pre-training the skills andthe downstream fine-tuning in each environment separately. The instruction for downloading the dataset aswell as its generation is included in our code repository.
Table 5: Kitchen pre-training dataset sizesTasks	# of trajectoriesMicroWave, Kettle, Top Burner, Light SWitch	285Microwave, Bottom Burner, Light SWitch, Slide Cabinet	236MicroWave, Kettle, Slide Cabinet, Hinge Cabinet	230MicroWave, Kettle, Slide Cabinet, Hinge Cabinet	198C Experimental ResultsC.1 Table of resultsTable 6: Comparison of our approach to other baselines on the Maze environments. For each experiment we report theaverage episode length from 10 fixed starting positions with the standard error across 10 evaluation runs (lower is better).
Table 6: Comparison of our approach to other baselines on the Maze environments. For each experiment we report theaverage episode length from 10 fixed starting positions with the standard error across 10 evaluation runs (lower is better).
Table 7: Comparison of average episode reward for our approach against other baselines on the KitchenRobot environment.
Table 8: We ablate the use of our inverse skill dynamics model by replacing it with an inverse dynamics model on atomicactions. The baseline ablations only succeed on one out of the four tasks. BC learns an inverse dynamics model that takesin state as input and outputs a distribution over atomic actions. Goal-BC uses both state and the goal (sub-task) as input.
Table 9: We ablate FIST against an oracle version on pointmaze which uses the ground truth way pointplanner that has access to the exact state that the agent will end up at H-steps in the future (if it commits tothe optimal path).
Table 10: With all subtasks seen in the skill dataset, FIST is able to imitate a long-horizon task in the kitchen environment.
Table 11: We evaluate FIST on the mazeenvironment with goal at the bottom whenthe inverse skill model is trained on an ex-tremely noisy dataset. In this case, FISTachieves sub-optimal performance, or isunable to imitate the test time demonstra-tion.
