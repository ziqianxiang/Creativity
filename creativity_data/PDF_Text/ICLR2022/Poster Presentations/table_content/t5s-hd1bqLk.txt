Table 1: Source-to-Distortion Ratio improvement (SDRi) (higher the better) and Word-Error-Rate(WER) (lower the better) performances on LibriSpeech (English) for models with conditioningvia learned activations (LAs), modulation (FiLM) and concatenation, across models with differentnumber of conditioning layers (#Cond.).
Table 2: Source-to-Distortion Ratio improvement (SDRi) (higher the better) and Word-Error-Rate(WER) (lower the better) performances on VoxForge (Spanish) for models with conditioning vialearned activations (LAs), modulation (FiLM) and concatenation, across models with differentnumber of conditioning layers (#Cond.).
Table 3: FLOPs and latency (for one second audio) for PSE models with conditioning via learned acti-vations (LAs), modulation (FiLM) and concatenation (Concat.). Note FLOPs may not be completelyaccurate given the common lack of support of profiling tools for non-standard layers or operations.
Table 4: WER and LER results on LibriSpeech test-clean for ASR and PASR (via FiLM modulationand proposed LA functions approaches) with two seconds of enrollment data, for character andsubword text encoders and CTC greedy (G) and beam search (BS) with a beam width four decoders.
Table 5: SDRi and WER results on LibriSpeech (English) when using learned activations (LA) trainedwith entropy (α) and t-SNE ({β, σ}) regularizers.
Table 6: SDRi and WER results on VoxForge (Spanish) when using learned activations (LA) trainedwith entropy (α) and t-SNE ({β, σ}) regularizers.
Table 7: Results for models trained on Librispeech (English) data with proposed LA and baselineconcatenation and evaluated with random, zeros and ones as speaker embedding vectors.
Table 8: Results for models trained on VoxForge (Spanish) data with proposed LA and baselineconcatenation and evaluated with random, zeros and ones as speaker embedding vectors.
