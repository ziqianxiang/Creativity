Table 1: SIVAL interpretability NDCG@n / AOPC-R results. For all of the interpretability methods,the standard error of the mean was 0.01 or less.
Table 2: 4-MNIST-Bags interpretability NDCG@n / AOPC-R results. The MI-GNN model takesfour times as long for a single model pass than the other models, so calculating its AOPC-R results onthis dataset was infeasible (see Appendix A.3). For all of the interpretability methods, the standarderror of the mean was 0.01 or less.
Table 3: CRC interpretability NDCG@n results. As this dataset has much larger bag sizes (264instances per bag on average), it is infeasible to compute its AOPC-R results (see Appendix A.3).
Table A1: Musk interpretability AOPC-R results. Note that we are using the Musk1 dataset, ratherthan Musk2, as the latter has much larger bag sizes, making the use of AOPC-R infeasible.
Table A2: Tiger interpretability AOPC-R results.
Table A3: Elephant interpretability AOPC-R results.
Table A4: Fox interpretability AOPC-R results.
Table A5: MILLI hyperparameters.				Dataset	Sample Size	α	β	E[|z|]SIVAL	200	0.05	-0.01	134-MNIST-Bags	150	0.05	0.01	16CRC	1000	0.008	-5.0	2MUSK	150	0.3	-1.0	2TEF	150	0.3	0.01	3A.6 SIVAL experiment detailsDataset For the SIVAL dataset, each instance is represented by a 30-dimensional feature vector,and there are around 30 instances per bag. We chose 12 of the 25 original classes to be the positiveclasses, and randomly selected 30 images from each of the other 13 classes to form the negativeclass, meaning overall we had 13 classes (12 positive and one negative). In total, we had 60 bagsfor each of the 12 positive classes, and 390 bags for the single negative class, meaning the classdistribution was ≈ 5.4% for each positive class and ≈ 35.1% for the negative class. The arbitrarilychosen positive classes were: apple, banana, checkeredscarf, cokecan, dataminingbook, goldmedal,largespoon, rapbook, smileyfacedoll, spritecan, translucentbowl, and wd40can. We normalised eachinstance according to the dataset mean and standard deviation. No other data augmentation was used.
Table A6: SIVAL hyperparameters.	Table A7: SIVAL MI-Net architecture.
Table A8: SIVAL mi-Net architecture.				Table A9: SIVAL MI-Attn architecture.			Layer Type		Input Output		Layer Type		Input Output	1	FC + ReLU + DO	30	512	1	FC + ReLU + DO	30	1282	FC + ReLU + DO	512	256	2	FC + ReLU + DO	128	2563	FC + ReLU + DO	256	64	3	FC + ReLU + DO	256	1284	FC	64	13	4	mil-attn(256) + DO	128	1285	mil-mean	13	13	5	FC	128	13Table A10: SIVAL MI-GNN architecture.
Table A10: SIVAL MI-GNN architecture.
Table A11: SIVAL model results. The mean performance was calculated over ten repeat trainingsof each model, and the standard error of the mean is given.
Table A12: 4-MNIST-Bags hyperparameters.			Model	LR	WD	DOMI-Net	1 X 10-4	1 × 10-3	0.3mi-Net	1 × 10-4	1 × 10-4	0.3MI-Attn	1 × 10-4	1 × 10-4	0.15MI-GNN	5 × 10-5	1 × 10-5	0.3Table A13: 4-MNIST-Bags convolutional encod-ing architecture. For the convolutional (Conv2d)and pooling (MaxPool2d) layers, the numbersin the brackets are the kernel size, stride, andpadding.
Table A13: 4-MNIST-Bags convolutional encod-ing architecture. For the convolutional (Conv2d)and pooling (MaxPool2d) layers, the numbersin the brackets are the kernel size, stride, andpadding.
Table A14: 4-MNIST-Bags MI-Net architecture.
Table A15: 4-MNIST-Bags mi-Net architecture.			Layer Type		Input Output	1	FC + ReLU + DO	800	5122	FC + ReLU + DO	512	1283	FC + ReLU + DO	128	644	FC	128	45	mil-mean	4	4Table A16: 4-MNIST-Bags MI-Attn architecture.
Table A16: 4-MNIST-Bags MI-Attn architecture.
Table A17: 4-MNIST-Bags MI-GNN architecture.
Table A18: 4-MNIST-Bags model results. The mean performance was calculated over ten repeattrainings of each model, and the standard error of the mean is given.
Table A19: CRC training hyperparameters.			Model	LR	WD	DOMI-Net	5 X 10-4	1 × 10-3	0.3mi-Net	5 × 10-4	1 × 10-2	0.25MI-Attn	1 × 10-3	1 × 10-6	0.2MI-GNN	1 × 10-3	1 × 10-2	0.35Table A20: CRC convolutional encoding archi-tecture. For the convolutional (Conv2d) andpooling (MaxPool2d) layers, the numbers in thebrackets are the kernel size, stride, and padding.
Table A20: CRC convolutional encoding archi-tecture. For the convolutional (Conv2d) andpooling (MaxPool2d) layers, the numbers in thebrackets are the kernel size, stride, and padding.
Table A21: CRC MI-Net architecture.
Table A22: CRC mi-Net architecture.
Table A23: CRC MI-Attn architecture.
Table A25: CRC model results. The mean performance was calculated over ten repeat trainings ofeach model, and the standard error of the mean is given.
