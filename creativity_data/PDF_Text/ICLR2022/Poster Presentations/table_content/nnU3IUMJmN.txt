Table 1: Locality features designed for each data type according to domain knowledge.
Table 2: Perplexity and top-k token prediction accuracy results on two datasets. *Uses releasedpre-trained model, Mo stochastic training, for all others stddev < 0.01 for 5 runs.
Table 3: Learned parameters θ0 , {θn}for each locality level and a non-locallevel g0 .
Table 4: Examples from two domains where incorporating locality features (non-local, local) lead to a significant increase in the cumulative pkNN for the gold token, with corresponding change in probability (normalized negative distance) for two nearest neighbors.			Test Context	Test Target	Initial log pkNN	∆ log pkNNSection: Seasonal forecasts; Category: Pacific typhoon season The forecast indicated the potential for 26.2 tropical storms, compared to the 10- and 30-year average of 27.8 and 26.3 storms, respectively. The following month, the group raised their ...	forecast	-2.20	+0.89Datastore Context	Datastore Target	Orig. Log-Prob.	∆Log- Prob.
Table 5: Additional Wikitext- 1 03 examples where incorporating locality features (non-local, local)lead to a significant increase in the cumulative pkNN for the gold token, with corresponding change inprobability (normalized negative distance) for two nearest neighbors.
Table 6: Additional token prediction top-k (k = 10, 20) accuracy results and relative error reduction(RER) on two datasets.
Table 7: The perplexity results comparing alternative formulation using MLP to contextualizeparameters for locality features on two datasets.
Table 8: Learned parameters θ0, {θn} for each locality level and a non-local level g0, with fixedwi>0 = 1 during optimization.
