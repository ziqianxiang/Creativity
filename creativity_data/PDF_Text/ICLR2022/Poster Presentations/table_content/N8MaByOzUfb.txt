Table 1: split CIFAR-10 results. f indicates the method is leveraging a task identifier at training time.
Table 2: Split CIFAR-100 (left) and Mini-Imagenet (right) results with M = 100. For each method,we report the best result between using (or not) data augmentations.
Table 3: CIFAR-10 Blurry TaskBoundary ExperimentsMethod	M = 20	M= 100ER	32.1±i.5	42.7±2.2DER++	31.0±1.4	41.7±1.4ER-AML	45.6±1.2	55.2±1.1ER-ACE	44.5±0.5	50.2±1.1ilar to settings considered in Aljundi et al. (2019b)). To do this,we linearly interpolate between tasks over time, resulting in newclasses being slowly mixed into the data stream. This experimentis done on Split-CIFAR10, and the interpolation is such that atevery timestep, the incoming data batch has on average 2 uniquelabels (as in the original experiment). We only evaluate task-freemethods in this setting: methods like MIR and SS-IL cannot be used in such setting. Results in table 39Published as a conference paper at ICLR 2022report the final accuracy, averaged over 5 runs, we report the standard error. We observe our ER-AMLand ER-ACE methods perofrm well in this setting. More details provided in Appendix A.2.
Table 4: Final Accuracy on split CIFAR-10 with class balanced stream.
Table 5: Average Drift (avg distance in feature space) of buffered representations for CIFAR-10during learning of the second task. We observe similar behavior to ER-AML with SupConAccuracy ↑M = 5 M = 20 M = 50 M = 100iid online	60.8 ± 1.0	60.8 ± 1.0	60.8 ± 1.0	60.8 ± 1.0iid++ online	72.0 ± 0.1	72.0 ± 0.1	72.0 ± 0.1	72.0 ± 0.1iid offline	79.2 ± 0.4	79.2 ± 0.4	79.2 ± 0.4	79.2 ± 0.4fine-tuning	18.4 ± 0.3	18.4 ± 0.3	18.4 ± 0.3	18.4 ± 0.3ER	19.0 ± 0.1	26.7 ± 0.3	36.1 ± 0.6	41.5 ± 0.6ER-AML Triplet	33.0 ± 0.3	40.1 ± 0.4	46.0 ± 0.5	49.8 ± 0.5ER-AML SupCon	33.0 ± 0.2	41.9 ± 0.1	48.3 ± 0.2	51.9 ± 0.3Table 6: Ablation comparing ER-AML with triplet loss to ER-AML with SupCon. We observe bothimprove over ER but SupCon has better performance in larger buffer sizesE Gradient NormFigure 7 shows the gradients norms of the features of previous classes in a stream of two tasks. Notehow for normal ER, at the task switch the gradients of the previous classes features are suddenly veryhigh leading potentially to large drift on these features.
Table 6: Ablation comparing ER-AML with triplet loss to ER-AML with SupCon. We observe bothimprove over ER but SupCon has better performance in larger buffer sizesE Gradient NormFigure 7 shows the gradients norms of the features of previous classes in a stream of two tasks. Notehow for normal ER, at the task switch the gradients of the previous classes features are suddenly veryhigh leading potentially to large drift on these features.
Table 7: Ablation of ER-AML with all negative selection versus negatives selected from incoming classes. Weuse the CIFAR-10 dataset. We observe that performance of ER-AML with all negatives is similar to but slightlybetter than ER, while use of well-selected negatives greatly improves performance.
