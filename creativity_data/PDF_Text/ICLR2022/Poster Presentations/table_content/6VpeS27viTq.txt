Table 1: Test accuracy for models trained on clean dataset (Dc), perturbed dataset(Dp), and recov-ered clean dataset (Dec). The first row summarizes result for linear perturbation function; the secondrow lists the result for convolutional perturbation function.
Table 2: Summary of applying data augmentation and filtering techniques on the learnability locked dataset.			Table 3: Summary on the effectiveness of applying adversarial training on several learnability attack methods and our pro-	Defenses	Acc (Linear)	Acc (Conv)	posed learnability lock.	None	14.79	17.61	—	Random Noise	19.83	17.32	Method J	Val AccGaussian Blurring	15.59	21.28	Unlearnable Examples	85.89rotate & flip & crop	15.25	18.81	Gradient Alignment	83.56Cutmix	20.72	18.60	Adversarial Poisoning	86.09Cutout	26.28	23.04	Learnability Lock (linear)	65.53Mixup	43.88	36.97	Learnability Lock (conv)	71.784.2.2 Adversarial TrainingAdversarial training (Madry et al., 2018) can also be viewed as a strong data augmentation techniqueagainst data perturbations. It is originally designed to help the model learn robust features to defendagainst the adversarial examples, which are generated by solving a min-max problem. Note that thismin-max optimization is the exact counterpart of the min-min formulation in Huang et al. (2021).
Table 4: Summary of uniqueness experiment re-sults with a ResNet-18 trained on CIFAR-10Keys J	Linear (A)	Conv (A)Linear (B)	14.79	11.35Conv (B)	19.83	17.81unlock the other “learnability locked” dataset? This is crucial since if it is the case, then as long asone set of key (transformation function) is exposed to an attacker, we lost the learnability locks forall the perturbed datasets based on the same source data. In our experiment, we train two learnabilitylocks for each transformation separately on the CIFAR-10 dataset and generate learnability lockeddatasets Dp1 and Dp2 with corresponding keys ψ1 and ψ2. Then we use ψ1 to unlock Dp2 and train amodel on the retrieved dataset. As shown in Table 4, each row represents the transformation methodwe used as the key and each column stands for a learnability locked dataset we intend to unlock.
Table 5: Structure of transformation model h for convolutional learnability lock on CIFARLayer Type	# channels	Filter Size	Stride	Padding	ActivationConv	8	二	-3×3	1	1	-ReLU-Conv	16	3 × 3	1	1	ReLUConv	16	1 × 1	1	0	ReLUConv	8	3 × 3	1	1	ReLUConv	3	3 × 3	1	1	ReLUtesting accuracy of the model train from scratch on the controlled dataset Dp. Similarly, effec-tiveness of the unlocking process is examined by the testing accuracy of the model trained on thelearnability restored dataset Dce. To ensure the stealthiness of the perturbation, we restrict = 8/255for CIFAR-10 and CIFAR-100, and = 16/255 for IMAGENET. To evaluate the effectiveness ofthe learnability control, the evaluation models are trained using Stochastic Gradient Descent (SGD)(LeCun et al., 1998) with initial learning rate of 0.01, momentum of 0.9, and a cosine annealingscheduler (Loshchilov & Hutter, 2016). For model training during the learnability locking process(updating fθ), we set initial learning rate of SGD as 0.1 with momentum as 0.9 and cosine anneal-ing scheduler without restart. Cross-entropy is always used as the loss function if not mentionedotherwise. The batch size is set as 256 for CIFAR-10 and CIFAR-100, 128 for the IMAGENET dueto memory limitation.
Table 6: Reconstruction losses for learnability locks with both linear and convolutional transforma-tions measured in L2 distance.
Table 7: Performance comparison when using a mixture of perturbation functions.
Table 8: Learnability locking performances with different model architectures of fθ .
Table 9: Comparison of maximum achievable accuracy with unlearnable examples (Huang et al.,2021). Here we focus on the maximum achievable validation accuracy of a ResNet-50 trained onthe CIFAR-10 dataset using any training schemes.
Table 10: Comparison of different strategies under the setting of learnability control. The ”stealth-iness” evaluates based on if the noise is easily detectable or can be reverse-engineered. (Xdenotes“yes”, X denotes “no”).
