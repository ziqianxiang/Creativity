Table 1: Quantitative comparison with unsupervised SOD methods. ’Backbone, refers to the saliency featureextraction network (Wu et al., 2019) adopted in our pipeline, i.e. the one without the two proposed keycomponents. The RGB-based methods are specifically marked by *. UnSOD is shorthand for unsupervisedSOD. We also provide the results of existing fully supervised methods that can be referenced in Table 8.
Table 2: Ablation study of our deep unsupervised RGB-D SOD pipeline,using the F-measure and MAE metrics.
Table 3: Analyzing attentive training strategy (ATS) with different set-tings. ‘Setting 1’ is backbone + uniform weight + DSU, and ‘Setting2’ is backbone + attentive weight + DSU. The last four columns showbackbone + ATS + DSU with different alternation interval τ.
Table 4: Internal mean absolute errors, each is evaluatedbetween current pseudo-labels and the corresponding truelabels (only used for evaluation purpose) during the train-ing process.
Table 5: Comparison of different pseudo-label generationvariants. ‘CRF' refers to fully-connected CRF. ‘OTSU’represents the standard Otsu image thresholding method.
Table 6: Discussion on different pseudo-label updating settings.
Table 7: Applying our DSU to existing fully-supervised RGB-D SOD methods.
Table 8: Quantitative results of fully-supervised RGB-D saliency detection methods. The best resultsare highlighted in boldface. When evaluating the newly released DUTLF-Depth dataset, the specificsetup used by (Piao et al., 2019) is adopted to make a fair comparison.
Table 9: Quantitative results of our DSU when using only RGB stream versus using RGB and depthsimultaneously during inference.
Table 10: Ablated exPeriment on the utilization of dePth.
