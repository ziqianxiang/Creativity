Table 1: A summary of how to construct target, supporting, and refuting patterns.
Table 2: Patterns Πp considered in our experiments.
Table 3: Result comparisons with baselines on heterogeneous graph recommendation task.
Table 4: Result comparisons with baselines on knowledge graph completion task.
Table 5: Result comparisons with baselines on generalization setting by randomly removing 20% relations. SeeAppendix A6.2 for full version and Appendix A6.2 for results of dropping 5%, 10%, 15%. The numbers inbrackets show the descent degree.
Table A1: Main statistics of heterogeneous graphs.
Table A2: Main statistics of knowledge graphs.
Table A3: Main statistics of patterns in heterogeneous and knowledge graphsPatterns	LastFM	Amazon	Yelp	Douban Book	FB15k-237	WN18RR3-cycle	29K	56K	137K	620K	519K	11,590K4-cycle	28M	52M	81M	62M	51M	2,623Maverage coverage of 3-hop neighborhood	78%	72%	78%	79%	78%	68%average coverage of 4-hop neighborhood	98%	92%	97%	99%	99%	90%Instead of using the max activation, we follow (Lu et al., 2016), considering this affinity matrix as afeature and learning the attention map via following:H * = W*E*, H+ = W+E+	(13)which are used to compute the attention map among E* and E+ througha* = softmax(w*> tanh(H * + H+A)), a+ = softmax(w+> tanh(H + + H*A)), (14)where W* ∈ Rd×d and W+ ∈ Rd×d, w* ∈ Rd and w+ ∈ Rd are the weight parameters. a* ∈R(P ×K) and a+ ∈ R(P×Q). We finally obtain the set embedding viah+ = E+a+>, h* = E*a*>,	(15)which is the weighted average of the subgraph embeddings in matrix E+ and E*. The similarity ofsupporting patterns is s+ = h+>h*. Computation of s- is similar.
Table A4: Comparable results with baselines, where there are 20% least frequent relations. See Appendix A6.1 for the full version. The numbers in brackets show the descent degree comparing to Table A4.						Models	FB15k-237			WN18RR			Hit@1	Hit@3	Hit@10	Hit@1	Hit@3	Hit@10pLogicNet	0.209(11.8%D	0.342(6.81%D	0.500(4.58%J)	0.341(14.3%J)	0.406(8.97%J)	0.491(8.57%J)TransE	0.197(14.0%i)	0.339(6.61%i)	0.494(5.18%i)	0.123(8.89%J)	0.367(8.48%J)	0.487(8.29%J)ConvE	0.207(12.7%i)	0.324(8.99%i)	0.478(4.59%i)	0.364(9.00%J)	0.391(11.1%J)	0.479(7.88%J)ComplEx	0.140(11.4%i)	0.261(5.09%i)	0.409(4.44%J)	0.375(8.54%J)	0.428(6.96%J)	0.475(6.86%J)MLN	0.051(23.9%i)	0.077(25.2%i)	0.143(10.6%J)	0.166(13.1%J)	0.285(11.5%J)	0.333(7.76%J)RotatE	0.211(12∙3%i)	0.351(6.34%i)	0.505(5.32%J)	0.386(9.83%J)	0.445(9.57%J)	0.529(7.38%J)RNNLogic	0.219(13.2%j)	0.333(12.5%i)	0.499(5.76%J)	0.407(8.61%J)	0.444(10.7%J)	0.511(8.42%J)ComplEx-N3	0.242(11.1%i)	0.361(9.85%i)	0.534(4.85%J)	0.407(7.49%J)	0.456(8.74%J)	0.539(7.15%J)GraIL	0.197(1L5%i)	0.315(12.8%i)	0.484(6.84%J)	0.307(12.7%J)	0.387(11.6%J)	0.458(8.52%J)QuatE	0.219(11.7%i)	0.355(7.14%i)	0.521(5.30%J)	0.400(8.75%J)	0.462(9.06%J)	0.535(8.06%J))GraphANGEL3-cycle	0.243(9.87%J)	0.384(3.53%D	0.539(3.80%J)	0.418(9.78%J)	0.465(6.42%J)	0.549(6.93%J)GraphANGEL4-cycle	0.215(9.96%i)	0.366(4.04%i)	0.526(3.94%J)	0.421(9.37%J)	0.467(6.92%J)	0.549(6.47%J)GraphANGEL	0.248(9.62% D	0.394(3.27% J)	0.541(3.84%J)	0.429(8.74%J)	0.481(6.21%J)	0.557(6.75%J)Table A5: Comparable results with baselines, where there are 20% least frequent relations. Here we report theresults in term of MR, MRR, Hit@K (K=1,3,10).
Table A5: Comparable results with baselines, where there are 20% least frequent relations. Here we report theresults in term of MR, MRR, Hit@K (K=1,3,10).
Table A6: Result comparisions with baselines on generalization setting by randomly removing 5% relations.
Table A7: Result comparisions with baselines on generalization setting by randomly removing 10% relations.
Table A8: Result comparisions with baselines on generalization setting by randomly removing 15% relations.
Table A9: Result comparisions with baselines on generalization setting by randomly removing 20% relations.
Table A10: Result comparisions with baselines on generalization setting by randomly adding 5% relations. Herewe report the results in terms of MR, MRR, Hit@K (K=1,3,10).
Table A11: Result comparisons with different GNNs as subgraph embedding methods (i.e., Φ) on heterogeneousrecommendation task.
Table A12: Result comparisons with different GNNs as subgraph embedding methods (i.e., Φ) on knowledgegraph completion task.
Table A13: Comparable results with baselines on robustness setting by randomly adding 5% noises. SeeAppendix A6.5 for detailed configuration on heterogeneous graph recommendation task.
Table A14: Comparable results with baselines on robustness setting by randomly adding 5% noises on knowledgegraph completion task. See Appendix A6.5 for detailed configuration.
