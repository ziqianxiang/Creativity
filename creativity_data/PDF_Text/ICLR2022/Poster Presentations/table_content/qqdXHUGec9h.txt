Table 1: Test performance of CAVL and other methods on benchmark datasets using data generationby USS. The best results among all methods with the same backbone are marked in bold.
Table 2: Test performance of CAVL and other methods on benchmark datasets using data generationby FPS. The best results among all methods with the same backbone are marked in bold.
Table 3: Test performance of CAVL and other methods uisng linear model on real-world datasets.
Table 4: Characteristics of benchmark datasetsDatasets	#Train	#TeSt	#FeatUreS	#ClassesMNIST	60,000	10,000	-784-	10Fashion-MNIST	60,000	10,000	-784-	10Kuzushiji-MNIST	60,000	10,000	-784-	10CIFAR-10	50,000	10,000	3072	10Table 5: Characteristics of real-world datasetsDatasets	Application Domain	#ExamPleS	#Features	#Classes	Avg #CLSLost	Automatic face naming	-∏22-	108-	16-	-2.23MSRCv2	Object classification	-1758-	48	23	-316BirdSong	Bird song classification	-4,998-	38	13	-2T8Soccer Player	Automatic face naming	-17472-	-279-	-171-	-209Yahoo! News	Automatic face naming	22,991	163	219	1.91Table 6: Test performance of the CAVL and other methods uisng MLP on real-world datasets. Thebest and Second best results among all methods are marked in bold and underline.
Table 5: Characteristics of real-world datasetsDatasets	Application Domain	#ExamPleS	#Features	#Classes	Avg #CLSLost	Automatic face naming	-∏22-	108-	16-	-2.23MSRCv2	Object classification	-1758-	48	23	-316BirdSong	Bird song classification	-4,998-	38	13	-2T8Soccer Player	Automatic face naming	-17472-	-279-	-171-	-209Yahoo! News	Automatic face naming	22,991	163	219	1.91Table 6: Test performance of the CAVL and other methods uisng MLP on real-world datasets. Thebest and Second best results among all methods are marked in bold and underline.
Table 6: Test performance of the CAVL and other methods uisng MLP on real-world datasets. Thebest and Second best results among all methods are marked in bold and underline.
Table 7: The Peformance of our CAVL With different Settings of the Starting epoch.
