Table 1: Adversarial fair representation learning methods are only fair w.r.t. adversaries from a trainingfamily G while FNF provides a provable upper bound on the maximum accuracy of any adversary.
Table 2: FNF performance with dif-ferent flow encoder architectures.
Table 3: Statistics for train, validation, and test datasets. In general, the label (y) and sensitiveattribute (a) distributions are highly skewed, which is why we report balanced accuracy.
Table 4: Classification accuracy before and after removing uninformative features during prepro-cessing. For each dataset we train a multi-layer perceptron (MLP) with the same architecture onthe original and preprocessed data and report the average accuracy with standard deviation for fivedifferent random seeds. We can observe that the accuracy only decreases slightly after preprocessing.
Table 5: Statistics for the Crimetrain set (reproduced from Table 3).
