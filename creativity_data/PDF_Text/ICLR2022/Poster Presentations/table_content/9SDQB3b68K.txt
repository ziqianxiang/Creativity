Table 1: Normalized scores for the (target) D4RL tasks, where our results are averaged over 5 seeds.
Table 2: Normalized scores in (target) D4RL tasks, where ”Tune” denotes baseline ”fine-tune”. Weobserve that with same amount (10%) of target offline data, DARA greatly outperforms baselines.
Table 3: Average distance cov-ered in an episode in real robot.
Table 4: Some related works with explicit (state-action p(s, a) or state-action-next-state p(s, a, s0))regularization. More papers with respect to unsupervised RL, inverse RL (imitation learning), metaRL, multi-agent RL, and hierarchical RL are not included.
Table 5: Normalized scores for the Hopper tasks with the body mass (dynamics) shift. Rat. and Cla.
Table 6:	Normalized scores for the Hopper tasks with the body mass (dynamics) shift. (The com-parison results for BEAR, BRAC-p, AWR, CQL, and MOPO are provided in the main text.)Body Mass Shift 10T1T+10S	1T+10S1T w/o Aug. DARA 10T1T+10S	1T+10S	1T+10S	1T+10Sw/o Aug. DARA 10T 1T w/o Aug. DARABC	COMBOJoddoRandom	9.8	9.8 ↑	6.9 J	10.1 ↑	17.9	0.7 J	5.4↑	4.6 JMedium	29.0	27.9 J	17.6 J	25.0 ↑	94.9	1.8J	33.7 ↑	45.7 ↑Medium-R	11.8	7.8 J	7.7 J	11.6 ↑	73.1	13.1 J	11.0 J	27.9 ↑Medium-E	111.9	21.5 J	20.8 J	35.7 ↑	111.1	0.8 J	14.9 ↑	108.1 ↑18Published as a conference paper at ICLR 2022Table 7:	Normalized scores for the Hopper tasks with the joint noise (dynamics) shift.
Table 7:	Normalized scores for the Hopper tasks with the joint noise (dynamics) shift.
Table 8:	Normalized scores for the Walker2d tasks with the body mass (dynamics) shift. (Thecomparison results for BEAR, BRAC-p, AWR, CQL, and MOPO are provided in the main text.)Body Mass Shift 10T1T+10S	1T+10S1T w/o Aug. DARA 10T1T1T+10S	1T+10S	1T+10S	1T+10Sw/o Aug. DARA 10T 1T w/o Aug. DARAPnBC	COMBORandom	1.6	0.1 J	1.7 ↑	2.7 ↑	7.0	1.8J	2.0 ↑	3.5 ↑Medium	6.6	5.5 J	3.8 J	6.6 ↑	75.5	-1.0 J	23.9 ↑	36.6 ↑Medium-R	11.3	6.6 J	8.1 ↑	11.0 ↑	56.0	0.1 J	11.4 ↑	22.6 ↑Medium-E	6.4	3.1 J	6.0 ↑	6.2 ↑	96.1	-0.9 J	-0.1 ↑	-0.1 ↑Table 9: Normalized scores for the Walker2d tasks with the joint noise (dynamics) shift.
Table 9: Normalized scores for the Walker2d tasks with the joint noise (dynamics) shift.
Table 10: Normalized scores for the Halfcheetah tasks with the joint noise (dynamics) shift.
Table 11:	Normalized scores in the (target) D4RL Hopper tasks with the joint noise shift., where”Tune” denotes baseline ”fine-tune”.
Table 12:	Normalized scores in the (target) D4RL Walker2d tasks with the joint noise shift., where”Tune” denotes baseline ”fine-tune”.
Table 13: Average distance (m) covered in an episode (300 steps) in flat and static (real) environment.
Table 14: Average distance (m) covered in an episode (300 steps) in the obstructive and dynamic(real) environment.
Table 15: Ablation study with respect to the amount of target Hopper data (body mass shift tasks).
Table 16: Ablation study with respect to the amount of target Walker2d data (body mass shift tasks).
Table 17: Comparison between DARA and importance sampling (IS) based dynamics correction.
Table 18: We show the normalized scores for the Hopper tasks with body mass shift, by varyingη ∈ {0, 0.05, 0.1, 0.2, 0.5} over BEAR, BRAC-p, AWR, BCQ, CQL, and MOPO.
Table 19: Dynamics shift for Hopper, Walker2d, and Halfcheetah tasks. For the body mass shift,we change the mass of the body in the source MDP M0. For the joint noise shift, we add a noise(randomly sampling in [-0.05, +0.05]) to the actions when we collect the source offline data, i.e.,D0 := {(s, a,r, s0)}〜dD(s)πb(a∣s)r(s, a)T0(s0∣s, a + noise).
Table 20: Statistics for each task in our adaptation setting.				Environment	Dynamics Shift	Task Name	Target (1T)	Source (10S)		Random	105 (D4RL)	106	Body Mass Shfit	Medium	105 (D4RL)	106		Medium-Replay	20092 (D4RL)	106Hopper		Medium-Expert	2* 105 (D4RL)	2*106		Random	105 (D4RL)	106		Medium	105 (D4RL)	106	Joint Noise Shift	Medium-Replay	20092 (D4RL)	106		Medium-Expert	2* 105 (D4RL)	2*106		Random	105 (D4RL)	106	Body Mass Shfit	Medium	105 (D4RL)	106		Medium-Replay	10093 (D4RL)	106Walker2d		Medium-Expert	2* 105 (D4RL)	2*106		Random	105 (D4RL)	106		Medium	105 (D4RL)	106	Joint Noise Shift	Medium-Replay	10093 (D4RL)	106		Medium-Expert	2* 105 (D4RL)	2*106		Random	105 (D4RL)	106	Body Mass Shfit	Medium	105 (D4RL)	106
Table 21: Dynamic parameters and their respective range of values utilized during training.
Table 22: State representation for the behavior policy.
Table 23: Normalized scores for the D4RL tasks (with body mass shift). We take the baseline results (for 10T) of MOPO from their original papers and that of theother model-free methods (BEAR, BRAC-p, AWR, BCQ and CQL) from the D4RL paper (Fu et al., 2020).
Table 24: Normalized scores for the D4RL tasks (with joint noise shift). We take the baseline results (for 10T) of MOPO from their original papers and that of theother model-free methods (BEAR, BRAC-p, AWR, BCQ and CQL) from the D4RL paper (Fu et al., 2020).
