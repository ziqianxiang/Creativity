Table 1: Results on the graph coloring problem (Lippe & Gavves, 2020). Small are graphs ofsize 10 ≤ |V | ≤ 20, and LARGE 25 ≤ |V | ≤ 50. All results are attained using the CatNFcodebase, and averaged across 3 random seeds. Results in the rounded box are using a different set ofhyperparameters than the ones used in CatNF.
Table 2: Performance on molecule generation trained on Zinc250k (Irwin et al., 2012), calculated on10k samples and averaged over 4 random seeds.
Table 3: Results on character-level and word-level language modelling, an average across 3 differentrandom seeds. Results reported with f indicates results attained with the Argmax flow codebase. *indicates results attained with the CatNF codebase. All other results are from the CatNF paper.
Table 4: Results on word-level language modelling, each sentence is modelled as a separate datapoint. CatNF, Argmax Flow, and TRUFL results are averaged across 4 random seeds. Setting andbaseline LSTM provided by Kim et al. (2019).
Table 5: Left: The joint distribution for x1 and x2 for the toy example. Right: Log probability overthe data of the model, and the breakdown of the ELBO.
Table 6: New arguments for the Large graph colouring task we use in our experiments.
