Table 1: Accuracy and AUC obtained from the MIMIC-III dataset.															GIL		-D	-H	GAIN	MIWAE	GP-VAE	BRITS	MICE	Mean	CF	kNN	MF	EMVar-l.	Acc.	93.32	93.09	89.17	90.32	88.71	-	-	92.17	88.02	87.32	84.79	75.81	68.20	AUC 96.10		96.79	92.96	95.57	94.28	-	-	95.97	92.56	91.78	91.86	81.73	75.23Fix-l.	Acc.	91.47	91.01	88.25	88.48	86.18	76.50	80.24	90.09	86.41	86.87	85.48	78.11	70.51	AUC 95.29		95.57	92.99	91.94	93.10	81.47	92.13	94.02	91.69	91.98	92.38	84.54	79.97binary classification tasks using GIL-D which includes the distributional difference term D(ζ+, ζ-),captured by mean squared errors, into the reward function. For baselines, we start with anothervariant of GIL that uses a simple heuristic - the missing indicator m - to replace the importance ain GIL; we denote it as GIL-H. This helps analyze the advantages of training the models using theimportance obtained from the RL policy learned by GIL, versus a heuristic that simply discards thegradients produced by the subset of input entries that are missing.
Table 2: Average Accuracy and AUC obtained from the Ophthalmic dataset over 3 different randommasks. Subscripts are standard deviations.
Table 3: Average Accuracy reported for the MNIST dataset over different missing rates. For eachmissing rate, 5 random masks were used resulting in standard deviations shown as subscripts (×10-3).
Table 4: Correlation between imputation MSE and prediction accuracy for different MRs.
Table 5: Accuracy for GIL-D on the MCAR version of MNIST dataset. Standard deviations are insubscripts (x 10-3).
Table 6: Accuracy, AUC and average precision (AP) obtained from the Physionet dataset	GIL	GIL-H	GAIN	GP-VAE	MIWAE	BRITS	Mean	ZeroAcc.	87.45	87.38	86.23	86.85	87.12	86.20	86.87	87.15AUC	82.20	82.00	78.02	82.21	83.47	81.30	82.57	81.14AP	49.19	48.64	39.89	47.05	49.31	43.57	48.30	47.3722Published as a conference paper at ICLR 2022Other than MIMIC-III, we also tested on a smaller scaled ICU time-series from 2012 Physionetchallenge Silva et al. (2012) which contain data obtained from 12,000 patients. We use the datapre-processed and open-sourced by Fortuin et al. (2020).10 For each patient the values of 35 differentattributes (e.g., blood pressure, temperature) are recorded over a 48-hour window. As a result, the datafor each patient can be formulated into a matrix in R48×35, i.e., the sequence length across patientsare the same. This dataset has an overall 78.5% missing rate and a binary label is assigned to eachpatient where 87% of them are 0’s and 13% are 1’s. Therefore we include average precision (AP)which is calculated from the precision-recall curve as an additional metric to evaluate the performancetoward imbalanced labels. For this dataset, we consider a 1024-unit LSTM layer for encoding and adense output layer for inference. It can be observed from Table 6 that although our method achievesthe highest accuracy and 2-nd highest AP, while most methods perform very close to mean- and zero-imputation. This could be caused by the its simple structure, as all the sequences share the same timehorizon, which significantly reduces the difficulties for the classification task. Moreover, the highly
Table 7: Performance of the ablation model over the ophthalmic and MNIST datasetsOphthalmic ∣	MNIST	25% M.R.	35% MR	70% M.R.	90% M.R.
