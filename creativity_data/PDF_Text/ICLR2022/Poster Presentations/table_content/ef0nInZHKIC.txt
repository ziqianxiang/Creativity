Table 1: Sanity checks for SR’s ability to retrieve known equations. “Seconds” corresponds to the computationtime accomplished via a 2.6 GHz Intel Core i7 CPU with 16 GB 2400 MHz DDR4 Memory.
Table 2: The comparison of input feature set, mapping function, temporal perception field and mappingcomplexity across several optimizers.
Table 3: Top half: the Temporal Perception Field (TPF) and Mapping Complexity (MC) values of learned L2Omodels. The values are averaged across three different problems P1 /P2/P3 . The tuples indicate the thosemodels that have more than one type of inputs. Bottom half: the performance of numerical L2O and theirsymbolic distillation counterparts which are learned on P2 and evaluated on P3 . The interpretations and theplots of optimization trajectory could be found in the Appendix B.
Table 4: Comparison of the meta-tuned symbolic rule and thetraditional optimizers. Evaluation results are shown for optimizinga ResNet50 on Cifar10.
Table 5: Comparison for before and after meta-fine-tuning. The values are test accuracies of the symbolicequation distilled from DM and RP((semxtarall)), when meta-pre-trained on P1 /P2/P4.
Table 6: The computation execution times of the experiments in section 4.3.
Table 7:	SR evaluations results: the fitting and optimization ability across different SR options.
Table 8:	The evaluation accuracies of the distilled equations with different complexities from the RP((semxtarall)) model.
Table 9: GLUE fine tune performance comparisonsand are slightly different in the coefficients. The R2-score does not improve by dropping thesefunctions. This could be explained by that even given the hyperbolic functions, the equations withand without these functions are all compared and screened during the SR step, hence the resultingequation is already the best among them, though with the hyperbolic.
