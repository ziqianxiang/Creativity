Table 1: The statistics of datasets selected for evaluation.
Table 2: Top part: FCR and its components. The β metric is added as a reference. Bottom part: the performancedifference of GNN on the head/tail and head/isolation splits. Here, the “tail/isolation” means the 10% leastconnected, and isolated nodes in the graph.
Table 3: The performance comparisons on the isolation and tail splits of different datasets. The full comparisonson head/tail/isolation/overall data are in the Appendix C. GCN+SE 2 layers is Cold Brew’s teacher model. ColdBrew outperforms GNN and other MLP baselines, and achieves the best performance on the isolation splits aswell as some tail splits.
Table 4: Link prediction Mean ReciprocalRanks (MRR) on the isolation data. Note thatCold Brew outperforms baselines specificallybuilt for generalizing to the tail.
Table 5: Node classification accuracies withother baselines specifically created to generalizeto the tail. Cold Brew outperforms these meth-ods when edge data is absent in the graph.
Table 6: The comparisons of Cold Brew’s GCN and the traditional GCN for deep layers. When the number oflayers is large, Cold Brew’s GCN retains good performance while the traditional GCN without SE suffers fromthe “over-smoothess” and degrades. Even with shallow layers, Cold Brew’s GCN is better than traditional GCN.
Table 7: Best GCN configurations.
Table 8: Best MLP configurations.
Table 9: Best Label Propagation configurations.
Table 10: The performance comparisons on all splits of different datasets.
Table 11: Top part: FCR and its components. The β metric is added as a reference. Bottom part: theperformance difference of GNN on the head/tail and head/isolation splits.
