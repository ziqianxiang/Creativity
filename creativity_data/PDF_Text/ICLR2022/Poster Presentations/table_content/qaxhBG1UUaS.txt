Table 1: The performance of training dataset and self-generated dialogues being used for each iter-ation of policy improvement step.
Table 2: Experimental results for the policy improvement with GPT-Critic on MultiWOZ 2.0 dataset.
Table 3: End-to-end response generation results on MultiWOZ 2.0 dataset. The results with * arefrom original papers. All other results are averaged over three independent runs.
Table 4: Experimental results of simulator-based evaluation on ConvLab. All results are averagedover 1000 dialogues.
Table 5: Examples of the original dialogue and the critic-guided self-generated dialogue on thetraining dataset of MultiWOZ. The dialogue act and system response with * denote examples of self-generated actions (dialogue act and system response) by GPT-Critic. All system responses representdelexicalized responses.
Table 6: Examples of the original dialogue and the generated dialogue by policy-gradient-basedRL algorithm (REINFORCE) on the training dataset of MultiWOZ. The dialogue act and systemresponse with * denote examples of generated actions by REINFORCE. All system responses rep-resent delexicalized responses.
Table 7: Experimental results for the quality of generated dialogue states and dialogue acts on Mul-tiWOZ 2.0 dataset.
