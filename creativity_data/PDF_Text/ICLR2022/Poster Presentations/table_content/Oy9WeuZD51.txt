Table 2: TPR at 95% of competing detectors on a popular OOD benchmark.
Table 3: Test statistic compute time.
Table 4: MaSF with random channels.
Table 5: Comparison of the suggested framework various OOD detectors. F - Fisher, S - Simes, Me -Mean and Ma - Max, the order is first the spatial reduciton (Me / Ma), channel reduction (F / S) andfinally layer reduction (F / S).
Table 6: Comparison of the adapted MeMF (Mean-Mahalanobis-Fisher) under LDA and GDA as-sumtions to Deep Mahalanobis (Lee et al., 2018). GDA suffers from the small number of samplesin CIFAR100. Applying random channel selection significantly improves the detector. Deep Maha-lanobis results include pre-processing. SDs are given in brackets where applicable.
Table 7: Evaluating the importance of key components from GRAM method within our proposedframework. Replacing the Gram matrix with simple max pooling slightly improves OOD detectionresults. This indicates that the deviation function is more important than the Gram matrix which isthe compute intensive part of the method.
Table 8: Full Table 2, including AUROC												Network	In-dist	Out-of-dist	MSP	TPR at 95% Mahalanobis Resflow		GRAM	MaSF	MSP Mahalanobis		AUROC Resflow	GRAM	MaSF		SVHN	40.3	89.6	86.1	96.1	98.4	89.9	97.6	97.3	99.1	99.6	CIFAR-10	TinyImageNet	59.4	94.9	96.1	98.8	97.8	94.2	97.5	99.1	99.7	99.3		LSUN	66.9	97.2	98.1	99.5	99	95.5	98.3	99.5	99.9	99.4		SVHN	26.2	62.2	48.9	-89.3-	83.7	82.6	85.6	87.9	97.3	96.1DenseNet	CIFAR-100	TinyImageNet	17.4	87.2	91.5	95.7	93.9	71.8	92.7	98.1	99.0	98.3		LSUN	16.6	91.4	95.8	97.2	97.2	71.0	95	98.9	99.3	99.1		CIFAR-10	61.7	97.5	90.0	-80.4-	86.8	92.3	96.7	98	95.5	97.3	SVHN	TinyImageNet	80.4	99.9	99.9	99.1	99.8	95.5	99.5	99.9	99.7	99.6		LSUN	80.2	100	100	99.5	99.9	95.5	99.8	99.9	99.8	99.6		SVHN	27.9	75.8	910-	97.6	99	89.3	97.4	98.2	99.5	99.8	CIFAR-10	TinyImageNet	42.2	95.5	98.0	98.7	98.4	90.3	97.9	99.6	99.7	99.5		LSUN	41.3	98.1	99.1	99.6	99.7	90.1	99.2	99.8	99.9	99.8		SVHN	15.0	41.9	74.1	-80.8-	89.7	76.1	93.2	95.1	96.0	96.9ResNet	CIFAR-100	TinyImageNet	17.6	70.3	77.5	94.8	96.1	73.4	76.9	90.1	98.9	98.8		LSUN	15.0	56.6	70.4	96.6	98.2	70.9	66.2	87.2	99.2	99.2		CIFAR-10	79.1	94.1	96.6	-85.8-	98	93.0	98.1	99	97.3	99.2	SVHN	TinyImageNet	79.8	99.2	99.9	99.3	99.9	93.5	99.4	99.9	99.7	99.8		LSUN	75	99.9	100	99.6	100	91.5	99.9	100	99.8	99.8
Table 9: Comparison of weighted MaSF using varying weights on the final fully-connected layer.
Table 10: Extended evaluation of MSP, GRAM and MaSF for DenseNet and Resnet models. R, Cindicate resize and crop respectively.
Table 11: Extended evaluation with Outlier Exposure (Hendrycks and Gimpel, 2016) using Wide-ResNets. R,C indicate resize and crop respectively.
