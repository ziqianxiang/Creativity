Table 2: Re-identification: rate of unseen objects beenidentified along the course of the pursuit process.
Table 1: Re-identification: recalland precision on seen objects.
Table 3: Pursuit dynamics by varyingT. Please see the enclosing descrip-tion for the meaning of the metricsand corresponding analysis.
Table 4: N-shot learning the representation of a new object.
Table 5: Pursuit dynamics underrandom training object order.
Table 6: Pursuit dynamics underdifferent forgetting prevention con-straints.
Table 7: Pursuit dynamics under dif-ferent L-1 norm coefficients on μ|a|	0.0	0.1	0.2	0.5|z|/N	0.45	0.42	0.42	0.40∣“∣∕N	0.57	0.55	0.58	0.51Re	0.11	0.19	0.21	0.08Rf	0.21	0.15	0.17	0.25Aμ	0.74	0.75	0.73	0.77a μ to express an object becomes difficult, thus the number of objects that can be expressed (Re)decreases, as shown in Tab. 7.
Table 8: Pursuit dynamics under dif-ferent L-1 norm coefficient on z|a|	0.0	0.1	0.2	0.5∣z∣∕N	0.46	0.42	0.42	0.39∣μ∣∕N	0.56	0.58	0.56	0.55Re	0.12	0.21	0.21	0.24Rf	0.14	0.18	0.12	0.19Aμ	0.74	0.72	0.74	0.72that when ∣ɑ∣ gets bigger, more objects will be consideredas unqualified due to their low training accuracy, especially when ∣α∣ = 0.5. It shows that moreconstraints on z may cause it harder to find a proper z to represent an object during training, thusdecrease the accuracy. It also explains why the number of learnable objects (∣μ∣∕N) decreases when∣α∣ change from 0.1 to 0.5.
Table 9: Pursuit dynamics on YouTube-VOSdataset by varying τ .
Table 10: Pursuit dynamics on CO3D datasetby varying τ .
Table 11: Re-identification: recall and preci- sion of unseen objects (on all testing objects).		Table 12: Re-identification: recall and preci- sion of seen objects (on all testing objects).	T	0.5	0.6	0.7	0.8	τ	0.5	0.6	0.7	0.8recall	0.28	0.40	0.56	0.72	recall	1.0	1.0	1.0	1.0precision 1.0	1.0	1.0	1.0	precision 0.60	0.64	0.71	0.80Tab. 11 and Tab. 12 report recall and precision on unseen objects and seen objects, taking all testingobjects into consideration. We collect the number of objects our model identifies as seen or unseenfrom the re-identification experiment introduced in Section 4.2.1, then compute recall and precision.
Table 13: Segmentation accuracy and re-identification rate on base and non-base objects.
Table 15: The number of optimizable parametersand average time consumed per object in one-shot learning.
Table 16: One-shot learning accuracy and training efficiency.
Table 17: Jaccard index on DAVIS evaluation set.
