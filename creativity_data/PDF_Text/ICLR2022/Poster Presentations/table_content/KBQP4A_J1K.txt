Table 1: Accuracy on compositional table lookup dataset.
Table 2: Performance of different models on the simple arithmetic dataset. All models are trainedfor 200K iterations, except the NDR which we stop training at 100 K. We also report the performanceafter 50 K iterations, where it can be seen that NDR converges significantly faster than the others.
Table 3: Performance of different models on balanced ListOps dataset. All models are trained for200 K iterations, except all +gate variants which converge after 100 K steps. The numbers in theparentheses indicate the problem depths (1-5 for the IID, and 7-8 for the test set).
Table 4: The performance of NDR on the compositional table lookup dataset, with different numberof layers.
Table 5: Accuracy on compositional table lookup dataset with the results read from the first or lastcolumn (Readout).
Table 6: Accuracy on compositional table lookup dataset with adaptive computation time (ACT).
Table 7: Hyperparameters used for different models on the compositional table lookup task. Wedenote the feedforward size as dFF, weight decay as “wd.”, dropout as “do.”. The model is trained forniters iterations.
Table 8: Hyperparameters used for different models on the simple arithmetic task. We denote thefeedforward size as dFF, weight decay as “wd.”, dropout as “do.”. The model is trained for nitersiterations.
Table 9: Hyperparameters used for different models on the ListOps task. We denote the feedforwardsize as dFF, weight decay as “wd.”, dropout as “do.”. The model is trained for niters iterations.
Table 10: Parameter ranges for hyperparameter tuningParameter	Rangelearning rate	0.00005 ... 0.001nlayers	4 ... 20dmodel	128, 256, 512nheads	2, 4, 8, 16weight decay	0.0 ... 0.1dropout	0.0 ... 0.5attention dropout	0.0 ... 0.5FF multiplier	1,2,4	∣-r 1.0Bbibdggah
