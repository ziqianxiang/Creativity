Table 1: Configuration of optimized network modelsconv. Layer skip-layer Number of Different Neuron parametersNetwork	Number	connection	Neuron Dynamics and a	Ï„m	RmBpTT, Gesture	9	(27	4, (-24,-17,-12,-9)	120	340BpTT, N-caltech	12	(2,5),(5,8),(8,11)	5, (-23,-16,-14,-11,-8)	70	300sTDp, Gesture	6	(2,4),(4,6)~~	4, (-26,-24,-15,-9)	110	260sTDp, N-caltech	8	(3,5),(5,7)	6, (-21,-19,-17,-13,-9,-7)	140	2405.3	Ablation StudiesTo investigate the effect of using multiple neuron dynamics, we apply the same dual-search-spaceBayesian optimization process for networks that have homogeneous neuron dynamic for the sameTable 2: Ablation studies of optimized networksModel	Heterogeneity	skip-layer	DVs Gesture	N-caltech101	s-MNisTHomogeneous-BpTT	N	Y	95.0	65.3	95.5No-skip-layer-BpTT	Y	N	96.5	63.5	94.8This Work-BPTT	Y	Y	98.0	71.2	97.3Homogeneous-sTDp	N	Y	91.3	37.0	94.3No-skip-layer-sTDp	Y	N	93.1	51.9	95.5This Work-STDP	Y	Y	96.6	58.1	96.18Published as a conference paper at ICLR 2022
Table 2: Ablation studies of optimized networksModel	Heterogeneity	skip-layer	DVs Gesture	N-caltech101	s-MNisTHomogeneous-BpTT	N	Y	95.0	65.3	95.5No-skip-layer-BpTT	Y	N	96.5	63.5	94.8This Work-BPTT	Y	Y	98.0	71.2	97.3Homogeneous-sTDp	N	Y	91.3	37.0	94.3No-skip-layer-sTDp	Y	N	93.1	51.9	95.5This Work-STDP	Y	Y	96.6	58.1	96.18Published as a conference paper at ICLR 2022Table 3: Accuracy (%) for DVS Gesture (top) and N-Caltech101 (bottom)Model	Labeled Data % In Training				Parameter Number	100%	50%	30%	10%	ConvLSNN (Salaj et al., 2020)	97.1	95.3	92.0	84.3	2.9MDECOLLE (Kaiser et al., 2020)	97.5	95.0	91.2	83.9	1.3M(Fang et al., 2021)	97.8	-	-	-	-HATS (Sironi et al., 2018)	95.2	94.1	91.6	83.7	-H-SNN (She et al., 2021)	96.2	95.8	93.7	88.2	0.74MThis Work-STDP Training	96.6	96.0	94.1	91.2	0.81MThis Work-BPTT Training	98.0	95.3	91.1	82.4	1.1M
Table 3: Accuracy (%) for DVS Gesture (top) and N-Caltech101 (bottom)Model	Labeled Data % In Training				Parameter Number	100%	50%	30%	10%	ConvLSNN (Salaj et al., 2020)	97.1	95.3	92.0	84.3	2.9MDECOLLE (Kaiser et al., 2020)	97.5	95.0	91.2	83.9	1.3M(Fang et al., 2021)	97.8	-	-	-	-HATS (Sironi et al., 2018)	95.2	94.1	91.6	83.7	-H-SNN (She et al., 2021)	96.2	95.8	93.7	88.2	0.74MThis Work-STDP Training	96.6	96.0	94.1	91.2	0.81MThis Work-BPTT Training	98.0	95.3	91.1	82.4	1.1M	Labeled Data % In Training				ParameterModel	100%	70%	50%	30%	NumberConvLSNN (Salaj et al., 2020)	63.1	58.7	51.3	45.4	3.0MDECOLLE (Kaiser et al., 2020)	66.9	61.9	56.2	50.6	2.0MHATS (Sironi et al., 2018)	64.2	61.0	54.3	48.8	-H-SNN (She et al., 2021)	42.8	41.9	37.0	34.6	1.7MThis Work-STDP Training	58.1	57.8	57.2	54.6	1.4MThis Work-BPTT Training	71.2	65.4	56.0	52.5	1.7Mnumber of evaluations as the proposed design. Similarly, to study the contribution to performancegain from skip-layer connections, the Bayesian optimization process is used for network templates
