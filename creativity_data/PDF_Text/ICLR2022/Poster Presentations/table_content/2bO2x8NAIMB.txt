Table 1: Comparison of our end-task aware approaches to RoBERTa and TAPT. All end-taskaware approaches use TAPT as the auxiliary task. Reported results are test macro-F1, except forCHEMPROT, for which we report micro-F1, following Beltagy et al. (2019). We average across 10random seeds, with standard deviations as subscripts. Statistically significant performance (p-valuefrom permutation test < 0.05), is boldfaced. See A.2,A.5 for more details about this table5.1	End-task awarenes s improves over task-agnostic pre-trainingTable 1 compares TAPT to its end-task aware variants. As in Gururangan et al. (2020), we observethat performing task adaptive pre-training improves upon just fine-tuning RoBERTa. However, notethat introducing the end-task by multi-tasking with the TAPT MLM objective leads to a significantimprovement in performance. This improvement is consistent across the 3 tasks we evaluate against.
Table 2: We use n = 10 × |Train|, a small fraction the full domain data which is > 104 × |Train|.
Table 3: DAPT and DAPT+TAPT runs onall domain data available.
Table 4: All methods use only DAPT as auxiliary task.
Table 5: We report averages across 3 random seeds. Best average task accuracy is bolded.
Table 6: Significance levels as computed from the permutation test. All p-values are relative tothe TAPT column. Statistically significant performance(p-value from permutation test < 0.05), isboldfacedTask	TAPT	META-TARTAN	p—valuesHYPER-PARTISAN	93.392.26	96.84i.72	0.003Table 7: Additional results for HYPERPARTISAN task. This is a binary, partisanship classificationtask with 515 labeled training examples.
Table 7: Additional results for HYPERPARTISAN task. This is a binary, partisanship classificationtask with 515 labeled training examples.
Table 8: Duplicate of Table 2. Significance levels as computed from the permutation test. Allp-values are relative to max DAPT, DAPT + TAPT . Statistically significant performance(p-value from permutation test < 0.05), is boldfacedA.7 FAQ1.	What settings are TARTAN algorithms designed for?TARTAN algorithms specialize auxiliary objectives to a particular end-task. This comes ata risk of losing the generic representations afforded by generalist pre-trained models. Thusif a practitioner has a sufficiently important end-task where obtaining improved end-taskperformance is paramount over generic representations, then TARTAN is a viable option.
