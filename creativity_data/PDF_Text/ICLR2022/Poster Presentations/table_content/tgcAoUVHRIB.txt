Table 1: MRR Results (%) of baselines (GQE, Q2B, BetaE) and our models (MLP, MLP-Mixer) onEPFO (∃, ∧, ∨) queries.
Table 2: MRR Results (%) of the model variants of MLP on EPFO (∃, ∧, ∨) queries: Hyper Embed-ding space, Attention mechanism and 2-vector approach.
Table 3: MRR Results (%) of MLP model on full FOL queries (∃, ∨, ∧, ), including negativequeries. We only use show results for negative query structures.
Table 4: Datasets statistics.
Table 5: Number of queries divided by training, validation and test sets, and query structure.
Table 6: Average number of answers divided by query structure.
Table 7: H@1 Results (%) of baselines (GQE, Q2B, BetaE) and our models (MLP, MLP-Mixer) onEPFO (∃, ∧, ∨) queries.
Table 8: H@1 Results (%) of model variants: HyperEmbedddings, Attention Mechanism and 2-vector average.
Table 9: H@1 Results (%) of baselines - BetaE - and our model - MLP - on negative queries.
Table 10: MRR Results (%) of additional models: CNN, NLN on EPFO (∃, ∧, ∨) queries.
Table 11: Logical regularizer for the AND operation. Sim(∙) is a measure of the similarity betweentwo items, Euclidean distance in our case.
