Table 1: GLNNs outperform MLPs by large margins and match GNNs on 5 of 7 datasets under thetransductive setting. ∆MLP (∆GNN) represents difference between the GLNN and a trained MLP(GNN). Results show accuracy (higher is better); ∆GNN ≥0 indicates GLNN outperforms GNN.
Table 2: Enlarged GLNNs match the performance of GNNs on the OGB datasets. For Arxiv, we useMLPw4 (GLNNw4). For Products, we use MLPw8 (GLNNw8).
Table 3: GLNNs match GNN performance on a production setting with both inductive and trans-ductive predictions. We use MLP for the 5 CPF datasets, MLPw4 for Arxiv, and MLPw8 forProducts. ind results on ViUnd, tran results on VoUbs, and the interpolated prod results are reported.
Table 4: While other inference acceleration methods speed up SAGE, they are considerably slowerthan GLNNs. Numbers (in ms) are inductive inference time on 10 randomly chosen nodes.
Table 5: Dataset Statistics.				Dataset	# Nodes	# Edges	# Features	# ClassesCora	2,485	5,069	1,433	7Citeseer	2,110	3,668	3,703	6Pubmed	19,717	44,324	500	3A-computer	13,381	245,778	767	10A-photo	7,487	119,043	745	8Arxiv	169,343	1,166,243	128	40Products	2,449,029	61,859,140	100	47For all datasets, we follow the setting in the original paper to split the data. Specifically, for thefive smaller datasets from the CPF paper, we use the CPF splitting strategy and each random seedcorresponds to a different split. For the OGB datasets, we follow the OGB official splits based ontime and popularity for Arxiv and Products respectively.
Table 6: Hyperparameters for GNNs on five datasets from the CPF paper.
Table 7: Hyperparameters for GraphSAGE on OGB datasets.
Table 8: GLNN predictions are much more consistent with the graph topology than MLPs. We showthe Lcut values of GNNs, MLPs, and GLNN s on five CPF datasets. GLNN Lcut values become prettyclose to the high Lcut values of GNNs, which were closely related to the GNN inductive bias.
Table 9: GLNN+ with MLP+CS teacher on ProductsMLP+C&S MLP+	GLNN+Acc 84.18	64.50	82.94G GLNN with feature augmentation from one-hop neighborsIn our main experiment, the inductive performance of GLNN on the Arxiv dataset is less desirablethan others. We thus consider augment the node features with their one-hop neighbors to includemore graph information. This can be seen as a middle ground between pure GLNNs and GNNs. Forthis new experiment, we follow the setting in Table 3 but with two new approaches. We explain thesetting of these two approaches below.
Table 10: GLNN with feature augmentation from one-hop neighbor on Arxiv	Eval	SAGE	MLP	GLNN	1-hop GA-MLP	1-hop GA-GLNNArxiv	ind	70.64	55.40	60.48	66.62	68.83	tran	70.75	55.28	71.46	66.67	69.82As we have shown in Figure 3, the 1-Layer GNN in our case is roughly 4 times slower than GLNN(29.31ms vs. 7.56ms), which should be a good approximation for the speed comparison between1-hop GA-MLP/GA-GLNN and GLNN. This result is practically beneficial, as it gives practitionersmore flexibility about how much accuracy they want to trade for less inference time.
Table 11: Statistics of dataset with heterogeneous node featuresDataset	# Nodes	# Edges	# Features	# ClassesHouse_class	20,640	182,146	6	5VK_class	54,028	213,644	14	7We apply the GLNN on House_class and VK_class using the best BGNN model from Ivanov& Prokhorenkova (2021) as the teacher. The comparison is shown in the following table. Ivanov &Prokhorenkova (2021) also includes GAT, GCN, AGNN, and APPNP as baselines, whose performanceon these two datasets are quite similar (difference < 0.025). We compare with these baselines byincluding the best result among the 4 GNN models and refer it as GNN in the table below, i.e. GNN= max(GAT, GCN, AGNN, APPNP). From the table, we see that GLNN can improve from MLP,outperform GNN and LightGBM, and become competitive to the teacher BGNN.
Table 12: GLNN on datasets with heterogeneous node features. Numbers other than GLNN are takenfrom Ivanov & Prokhorenkova (2021)Dataset	LightGBM	GNNs	BGNN	MLP	GLNNHouse_class	0.55	0.625	0.682	0.534	0.672VK_class	0.57	0.577	0.683	0.567	0.641We further pick the non-homophilous Penn94 and Pokec datasets from Lim et al. (2021). Somebasic statistics of the datasets are shown in the following table.
Table 13: Statistics of non-homophilous datasetsDataset	# Nodes	# Edges	# Features	# ClassesPenn94	41,536	1,590,655	5	2Pokec	1,632,803	30,622,564	65	2Using the GCN teacher, we see that the performance of GLNN is improved over MLP and becomescompetitive to the teacher GCN on Penn94. However, on Pokec, the simple LINK model canachieve very good performance, and it is better than most GNNs reported in Lim et al. (2021). LINKis a purely structural model which does not use node features at all. This shows that the Pokecdataset corresponds to the setting We discussed in Sec 5.8 (limitations of GLNN) - if the node labelscan be largely determined by only the graph structure, then GLNN will struggle. We observe thatGLNN is not as good as LINK oWing to this limitation. HoWever, We still see that for most of thenon-homophilous datasets, MLPs already Work quite Well on them, and We can use GLNN for theother ones like Penn94.
Table 14: GLNN on non-homophilous datasets. Numbers other than GLNN are taken from Lim et al.
