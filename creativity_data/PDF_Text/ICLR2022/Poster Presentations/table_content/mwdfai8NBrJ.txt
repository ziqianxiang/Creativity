Table 1: Training Hyperparameters for DQN models. *CNN refers to the 3-layer convolutionalnetwork defined by the CNNPolicy class in stable-baselines3 (Raffin et al., 2019), based on theCNN architecture used for Atari games by Mnih et al. (2015). Note that hyperparameters for Atarigames are based on hyperparameters from the stable-baselines3 Zoo package (Raffin, 2020), for aslightly different (more deterministic) variant of the Pong environment.
Table 2: Training Hyperparameters for DDPG models. Hyperparameters are based on hyperpa-rameters from the stable-baselines3 Zoo package (Raffin, 2020), for the unmodified Mountain Carenvironment.
Table 3: Attack Hyperparameters for DQN models.
Table 4: Attack Hyperparameters for DDPG models.
Table 5: Training timesExperiment Experiment	Time (seconds): smallest noise σ	Time (seconds): largest noise σPong (1-round)	046	0.38Pong (Full)	3.82	4.65Cartpole (Multi-frame)	0.20	0.13Cartpole (Single-frame)	0.18	0.12Freeway	1.36	1.35Mountain Car	0.67	0.91Table 6: Evaluation times. Note that the times reported here are per episode: in order to statisticallybound the mean rewards, we performed 10,000 such episode evaluations for each environment.
Table 6: Evaluation times. Note that the times reported here are per episode: in order to statisticallybound the mean rewards, we performed 10,000 such episode evaluations for each environment.
Table 7: Attack times. Note that the times reported here are per episode: in the paper, we report themean of 1000 such episodes.
