Table 1: Contribution of each component of our method to the desired qualities.
Table 2: Environment Reward ConfigurationsWe modify the default Point Mass environment by adding in walls to the top right corner and ini-tialize the agent in between the walls 10% of the time to help with exploration. We modify themanipulator environment by always initializing with the ball in the gripper and with the gripper inan upright position. We use an episode length of 1000 steps for Point Mass Obstacle and Walkerand an episode length of 100 steps for Reach, Toss, and Pick.
Table 3: Goal spaces for each environment.
Table 4: SAC HyperparametersTo scale the output of the goal generators to the correct action space, we take the Tanh scaled outputand rescale each dimension to the goal space. We use Appendix C of (Haarnoja et al., 2018) tomodify the log loss for SAC accordingly. To train the goal generator, we update after each round (i.e.
