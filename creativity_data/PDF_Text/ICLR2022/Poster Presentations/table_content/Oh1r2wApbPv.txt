Table 1: Statistics of the SKG instances col-lected from different resources.
Table 2: Performance comparison with the top-ranked,published models on the official CommonGen test set.
Table 3: Performance of the compared methods on the Concept2Story tasks. Best results are bold-faced. Wemark them with an asterisk if they exceed the second best with statistical significance (p-value < 0.05).
Table 4: Performance of our method using different SKG sources totrain the imagination module, with T5-large as the backbone LM.
Table 5: SPICE performance of ourmethod using different sizes of T5 asbackbone for the imagination module.
Table 6: Human evaluation on thegenerated SKGs regarding Completeness(COM), CommonSense (CS) and Align-ment (AL) and Similarity (SIM).
Table 7: The most common relation types in SKG instances and their example triplets.
Table 8: Statistical analysis (p-values) for the ablation study on the backend LM used by the ver-balization module and the low-resource experiment. < 0.01 indicates a significant improvementand < 0.05 indicates a fairly significant improvement, and NA indicates that our method does notoutperform the best baseline.
Table 9: Qualitative analysis on errors made without imagination and how imagination can help fix the errors (Part 1). The left arrow{—indicates the key relations that fix the errors.		Error 1 (Incorrect Agent)	Example 1	Example 2Input concepts	{owner, chase, dog, ball, throw}	{ski, rope, hold, boat, pull}Text w/o imagination	The dog is chasing the ball and throwing it at the owner.	A woman skis downhill as she pulls a boat holding a rope.
Table 10: Qualitative analysis on errors made without imagination and how imagination can help fix the errors (Part 2). The left arrow{—indicates the key relations that fix the errors.		Error 4 (Implicit Concepts)	Example 1	Example 2Input concepts	{fill, liquid, machine, bottle}	{lasso, catch, horse, animal, ride}Text w/o imagination	A machine holding a bottle filled with liquid.	Animals ride a horse that caught a lasso.
Table 11: Quality evaluation (recall) on the generated SKGs with silver-standard SKGs as reference.
Table 12: Ablation study on What input is fed to the verbalization module.
Table 13: Ablation study on using 1) silver-standard SKGs, 2) generated SKGs or 3) both to trainthe verbalization module.____________________________________________________________Input SKGs	CommonGen (in-house)	VIST	ROCSilver-standard	33.19	53.26	60.55Generated	32.56	58.34	59.82Silver. + Generated	33.49	59.21	60.63Table 14: Ablation study on the design of the generation process.
Table 14: Ablation study on the design of the generation process.
Table 15: Evaluation results (SPICE) with I&V using silver-standard SKGs during inference.
