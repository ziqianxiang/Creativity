Table 1: PolyLoss outperforms cross-entropy and focal loss on various models and tasks. Re-sults are for the simplest Poly-1, which has only a single hyperparameter. On ImageNet (Deng et al.,2009), our PolyLoss improves both pretraining and finetuning for the recent EfficientNetV2 (Tan &Le, 2021); on COCO (Lin et al., 2014), PolyLoss improves both 2D detection and segmentation ARfor Mask-RCNN (He et al., 2017); on Waymo Open Dataset (WOD) (Sun et al., 2020), PolyLossimproves 3D detection AP for the widely used PointPillars (Lang et al., 2019) and the very recentRange Sparse Net (RSN) (Sun et al., 2021). Details are in Table 4, 5, 7.
Table 2: Comparing different losses in the PolyLoss framework. Dropping higher order poly-nomial, proposed in prior works, truncates all higher order (N + 1 → ∞) polynomial terms. Wepropose Poly-N loss, which perturbs the leading N polynomial coefficients. Poly-1 is the final lossformulation, which further simplifies Poly-N and only requires a simple grid search over one hyper-parameter. The differences compared to cross-entropy loss are highlighted in red.
Table 3: LPoly-N outperforms cross-entropy loss on ImageNet-1K.
Table 4: PolyLoss improves classifica-tion accuracy on ImageNet validationset. We set 1 = 2 for both.
Table 5: PolyLoss improves detection results on COCO validation set. Bounding box and in-stance segmentation mask average-precision (AP) and average-recall (AR) are reported for MaskR-CNN model with a ResNet-50 backbone. Mean and stdev of three runs are reported.
Table 6: PolyLoss vs. focal loss for 3D detection models. Differences are highlighted in red. Wefound the best Poly-1 for PointPillars is 1 = -1, which is equivalent to dropping the first term.
Table 7: PolyLoss improves detection results on Waymo Open Dataset validation set. Twodetection models: single-stage PointPillars (Lang et al., 2019) and two-stage SOTA RSN (Sun et al.,2021) are evaluated. Bird’s eye view (BEV) and 3D detection average precision (AP) and averageprecision with heading (APH) at Level 1 (L1) and Level 2 (L2) difficulties are reported. The IoUthreshold is set to 0.7 for vehicle detection and 0.5 for pedestrian detection.
Table 8: ResNet50 performances on ImageNet-IK using different weight decays. *The defaultweight decay value is 1e-4.
Table 9: RetinaNet (ResNet50 backbone) performances on COCO using different Focal loss(γ, α).』The default (γ, α) used in Focal loss is (2.0, 0.25).
Table 10: Poly-1 outperforms LDrop* With hyperparameter tuning. Accuracy of ReSNet50 onImageNet-1K is reported.
Table 11: Comparing Poly-1 With exponential decay coefficients. Accuracy of ResNet50 onImageNet-1K is reported.
Table 12: Comparing Poly-1 With common training techniques. Accuracy of ResNet50 onImageNet-1K is reported.
