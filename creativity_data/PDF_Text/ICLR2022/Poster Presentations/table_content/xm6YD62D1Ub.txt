Table 1: Evaluation on ImageNet. Evaluation of the representations obtained with a ResNet-50backbone pretrained with VICReg on: (1) linear classification on top of the frozen representationsfrom ImageNet; (2) semi-supervised classification on top of the fine-tuned representations from1% and 10% of ImageNet samples. We report Top-1 and Top-5 accuracies (in %). Top-3 bestself-supervised methods are underlined.
Table 2: Transfer learning on downstream tasks. Evaluation of the representations from a ResNet-50 backbone pretrained with VICReg on: (1) linear classification tasks on top of frozen representa-tions, we report Top-1 accuracy (in %) for Places205 Zhou et al. (2014) and iNat18 Horn et al. (2018),and mAP for VOC07 Everingham et al. (2010); (2) object detection with fine-tunning, we reportAP50 for VOC07+12 using Faster R-CNN with C4 backbone Ren et al. (2015); (3) object detectionand instance segmentation, we report AP for COCO Lin et al. (2014) using Mask R-CNN with FPNbackbone He et al. (2017). We use f to denote the experiments run by us. Top-3 best self-supervisedmethods are Underlined.
Table 3: Evaluation on MS-COCO 5K retrieval tasks. Comparison of VICReg with the contrastiveloss of VSE++ Faghri et al. (2018), and with Barlow Twins, pretrain on the training set of MS-COCO.
Table 4: Effect of incorporating variance and covariance regularization in different methods.
Table 5: Impact of sharing weights or not between branches. Top-1 accuracy on linear classifica-tion with 100 pretraining epochs. The encoder and expander of both branches can share the samearchitecture and share their weights (SW), share the same architecture with different weights (DW),or have different architectures (DA). The encoders can be ResNet-50, ResNet-101 or ViT-S.
Table 6: Evaluation on ESC-50. Evaluation of the representations obtained with a ResNet-18backbone pretrained with VICReg on ESC-50 Piczak (2015) by processing jointly a raw audiotime-series and its corresponding time-frequency representation. The supervised baseline correspondsto a ResNet-18 trained on the time-frequency representation in a supervised way. We report Top-1accuracy on the validation set (in %).
Table 7: Impact of variance-covariance regu-larization. Inv: a invariance loss is used, λ > 0,Var: variance regularization, μ > 0, Cov: Covari-ance regularization, ν > 0, in Eq. (6).
Table 8: Impact of normalization. Std: vari-ables are centered and divided by their standarddeviation over the batch. This is applied or notto the embedding and the expander hidden layers.
Table 9: Linear classification with large architectures. Top-1 accuracy comparison between differ-ent methods using various encoder architectures. For all VICReg results, the output dimensionalityof the expander is 8192. N-R stands for Narrow ResNet, where only the bottleneck convolutionallayers are widen.
Table 10: Semi-supervised classification with large architectures. Top-1 accuracy comparisonbetween different methods using various encoder architectures. For all VICReg results, the outputdimensionality of the expander is 8192.
Table 11: K-NN classifiers on ImageNet. Top-1 accuracy with 20 and 200 nearest neighbors.
Table 12: Impact of expander dimensionality. Top-1 accuracy on the linear evaluation protocolwith 100 pretraining epochs.
Table 13: Impact of batch size. Top-1 accuracy on the linear evaluation protocol with 100 pretrainingepochs.
Table 14: Running time and peak memory. Comparison between different methods, the trainingis distributed on 32 Tesla V100 GPUs, the running time is measured over 100 epochs and the peakmemory is measured on a single GPU. We report top-1 accuracy (%) on linear classification on top ofthe frozen representations.
