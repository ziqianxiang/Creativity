Table 1: Ablation of position encoding methods. All models are optimized with λ = 0.02 (PNSR ≈35.0 on Kodak).
Table 2: Inference latency (ms) of entropy model on Kodak. Balle et al. (2018) uses is paralleled,while Minnen et al. (2018b) is inherently serial. For a direct comparison, we test our Entroformerwith serial architecture and parallel architecture.
Table 3: Bidirectional context vs. unidirectional context. Combined with bidirectional context,context model achieves bit rate saving significantly. The results are test by the same model.
Table 4: Performance of position encoding for varying the image size on Tecnick dataset. It showsthat relative position encoding can directly generalize to larger image size. The model with absoluteposition encoding degrades when process larger image size than training.
Table 5: Each row corresponds to a layer of our generalized model. Convolutional layers are spec-ified with the “Conv” prefix followed by the kernel size, number of output channels and downsam-pling stride (e.g. the first layer of the encoder uses 5×5 kernels with 192 output channels and astride of 2). The “Deconv” prefix corresponds to upsampled convolutions. The “Trans” correspondsto transformer block as in Vaswani et al. (2017), followed by the inner dimension and head number.
Table 6: Comparison on weight with entropy model variants.
