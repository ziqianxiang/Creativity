Table 1: Main results. Comparison with competitive out-of-distribution detection methods. All baselinemethods are based on a model trained on ID data only using ResNet-50 as the backbone, without using anyreal outlier data. ↑ indicates larger values are better and ] indicates smaller values are better. All valuesare percentages. Bold numbers are superior results. We report standard deviations estimated across 3 runs.
Table 2: Ablation	on outlier synthesis approaches (on backbone of ResNet-50, COCO is the OOD data).		score (Liu et al., 2020a), Mahalanobis distance (Lee et al., 2018b), Generalized ODIN (Hsu et al.,2020), CSI (Tack et al., 2020) and Gram matrices (Sastry & Oore, 2020). These approaches rely ona classification model trained primarily for the ID classification task, and can be naturally extendedto the object detection model due to the existence of a classification head. The comparison preciselyhighlights the benefits of incorporating synthesized outliers for model regularization.
Table 3: Ablation study. Comparison with different regularization loss functions (on backbone of ResNet-50,COCO is the OOD data).
Table 4: OOD detection results of VOS and com-parison with competitive baselines on two archi-tectures: WideResNet-40 and DenseNet-101.
Table 5: OOD detection evaluation tasks.
Table 6: Ablation study on the number of selected outliers t (per class).
Table 7: Ablation study on the ID queue size |Qk|.
Table 8: Ablation study on regularization weight β.
Table 9: Ablation study on the starting iteration Z. Model is trained for a total of 18,000 iterations.
Table 10: Performance comparison of employing VOS on different layers. COCO is the OOD data.
