Table 1: Evaluation of 95% PI on testing data. We show the mean, standard deviation (std), best, and worstPICP (across hyper-parameter configurations) for all methods. The best performer should produce PICP valuesclosest to the desired 0.95. DER tends to overestimate the PI resulting in PICPs close to 1.0 for most datasetsand produces the worst performance. For the four PI methods, our PI3NN shows the top performance by givingthe best mean PICP (closest to 0.95) with the smallest std across hyper-parameter configurations. QD, PIVEN,and SQR require a careful hyper-parameter tuning to obtain the comparable best PICP as the PI3NN, but foreach hyper-parameter set, their PICP std is large and the worst PICP can be much lower than the desired 0.95.
Table 2: Mean ± Standard Deviation of the confidence score (Eq. (12) with γ = 0.9) for the 10D cubic exampleFigure 2 shows the PDFs of the PIWs of the InD and OOD samples. The figures indicate that ourPI3NN method, with OOD identification feature turned on, can effectively identify the OOD samplesby assigning them larger and well-separated PIWs than those of the InD dataset. The other methodsare not able to identify the OOD samples by mixing their PIWs into the InD data’s PIWs, showing8Published as a conference paper at ICLR 2022overlapped PDFs. These methods’ performance is similar to the case when the PI3NN turns off itsOOD identification capability. Table 2 lists the mean and std of the confidence scores for the InD andOOD datasets. This table further shows that PI3NN with OOD identification feature turned on caneffectively identify the OOD samples by giving them smaller confidence scores than those of the InDsamples, while other methods produce over-confident (wider) PIs for the OOD samples and cannotseparate OOD samples from InD dataset.
Table 3: Mean ± Standard Deviation of the confidence score (Eq. (12) with γ = 0.9) for the flight delay data.
Table 4: Evaluation of 95% PI on testing data. We compare the mean PI width (MPIW) between methodswhen they have the similar PICP values (i.e., the best PICP highlighted in Table 1). For the similar PICP, themethod producing the smaller MPIW performs better. Our PI3NN shows the top performance by giving thesmallest MPIW for 7 out of 9 datasets. QD and PIVEN can also produce small MPIW for some datasets, butthey obtained the small MPIW by specifically minimizing the MPIW in their customized loss function whichresulted in a prediction performance sensitive to the hyper-parameter configuration.
