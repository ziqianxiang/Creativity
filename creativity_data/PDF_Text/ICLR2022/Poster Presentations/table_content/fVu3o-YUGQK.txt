Table 1: Comparison with SoTA across different architectures on ImageNet linear probing. EsViTwith LL + LR is reported, while EsViT with only LR is shown in parentheses. W = 14 is the windowsize, otherwise the default W = 7. ViT-BN is ViT that has BatchNorm (Frankle et al., 2020), and“/P” denotes a patch size of P X P. “〜” indicates through-puts estimated by comparing differentpapers, detailed in Appendix. * The mask patch prediction in (Dosovitskiy et al., 2021) is pre-trainedon JFT-300M and end-to-end fine-tuned in ImageNet, which we append as a reference.
Table 2: COCO Detection & Segmentation. Table 3: Impact of the pre-train datasets.
Table 4: Different architectures with and withoutLR . DeiT and ResNet-50 are shown as references.
Table 5: Comparison between contrastive and non-contrastive region-matching tasks.
Table 6: Model configurations considered in our experiments.
Table 7: Discussion of related works on various region-level tasks. The last columns reports theImageNet linear probe performance for ResNet-50 trained with 2 augmented views for 200 epochs.
Table 8: Throughput estimate and standardization. All numbers in orange are estimated/converted,while numbers in blue are collected from the papers, and numbers in green are runs on our machines.
Table 9: Computational cost comparisons in the format of [Memory Usage (MB) / Running time periteration (second/iteration)].
Table 10: A suite of 18 datasets used in linear probe.* indicates dataset whose train/test size Weobtained is slightly different from Table 9 in (Radford et al., 2021).
Table 11: The linear probe results on 18 datasets at the scale ofResNet-50/SWin-T. ^ indicates theresults reproduced by us, which verifies that our implementation pipeline is consistent with (Radfordet al., 2021).
Table 12: Linear probe performance of a ResNet-50 netWork With different SSL methods.
Table 13: Pre-train dataset statistics and training schedule.
