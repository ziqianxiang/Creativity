Table 1: Complexity, parameter count, and interpretation for FNO, AFNO, GFN, and Self-Attention. N :=hw, d, and k refer to the sequence size, channel size, and block count, respectively.
Table 2: Inpainting PSNR and SSIM for ImageNet-1k validation data. AFNO matches the performance ofSelf-Attention despite using significantly less FLOPs.
Table 3: Few-shot segmentation mIoU for AFNO versus alternative mixers. AFNO surpasses Self-Attentionfor 2/3 datasets while using less flops.
Table 4: mIoU and FLOPs for Cityscapes segmentation at 1024 × 1024 resolution. Note, both the mixer andtotal FLOPs are included. For GFN and AFNO, the MLP layers are the bottleneck for the complexity. Also,AFNO-25% only keeps 25% of the low frequency modes, while AFNO-100% keeps all the modes. Results forself-attention cannot be obtained due to the long sequence length in the first few layers.
Table 5: ImageNet-1K classification efficiencyy-accuracy trade-off when the input resolution is 224 × 224.
Table 6: Ablations for AFNO versus FNO, AFNO without adaptive weights, and hard thresholding. Resultsare on inpainting pretraining with 10% of ImageNet along with few-show segmentation mIoU on CelebA-Faces. Hard thresholding only keeps 35% of low frequency modes. AFNO demonstrates superior performancefor the same parameter count in both tasks.
