Table 1: Comparison to related works. Most works use non-overlapped windows to group tokens, and thenpropose the corresponding methods to assure the information exchange among regions.
Table 2: Model architectures of RegionViT. For all networks, the dimension per head is 32 and the expandingratio r in FFN is 4. The patch size of local tokens is always 4 while the patch size of regional tokens is 4 × M .
Table 3: Comparisons with reCent pyramid-like struCture-based ViT models on ImageNet1K. The bold numbersindiCate the best number within eaCh seCtion.
Table 4: Results on IN1K with IN21K and transfer learning.
Table 5: Object detection performance on MS COCO val2017 with 1× and 3× schedule. The bold numberindicates the best number within the section, and for MaskRCNN, both APb and APm are annotated.
Table 7: Performance on action recognition.
Table 10: Weight sharing.
Table 12: Different position information.				Abs. pos. Rel. pos.		Params (M)	FLOPs (G)	IN1K Acc. (%)N	N	306	5.3	82.4Y	N	30.9	5.3	82.2Y	Y	30.9	5.3	82.7N	Y	30.6	5.3	82.6a fixed resolution, which is not suitable for visiontasks where image size could be varied. Thus, we only adopt the relative position bias in our models.
Table 13: Overlapped windows.
Table A1: Details of training settings for image classification on ImageNet1K and ImageNet21K.
Table A2: Object detection performance on the COCO val2017 with 1× schedule. The bold number indicatesthe best number within the section, and for MaskRCNN, both APb and APm are annotated.
Table A3: Object detection performance on the COCO val2017 with 3× schedule. The bold number indicatesthe best number within the section, and for MaskRCNN, both APb and APm are annotated.
Table A4: Performance on person keypoint detection.
Table A5: Performance w/ and w/o regional tokens on RegionViT-S.
Table A6: Throughput comparison.
