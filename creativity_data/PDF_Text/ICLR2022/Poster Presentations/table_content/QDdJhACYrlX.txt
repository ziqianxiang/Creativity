Table 1: Comparison of consistent solutions on Interpret multi-agent validation track	Marginal metrics			Joint metrics				mADE	mFDE	MR	mFDE	MR	SCR	CMRILVM (Casas et al., 2020)	0.30	0.62	10.8	0.84	19.8	5.7	21.3SceneTranformer (Ngiam et al., 2021)	0.29	0.59	10.5	0.84	15.7	3.4	17.3THOMAS		0.31	0.60	8.2	0.76	11.8	2.4	12.75 of Appendix A.5. For better comparison with existing single-agent trajectory prediction state-of-the-art, we provide evaluation numbers on the single-agents benchmarks Argoverse (Chang et al.,2019) and NuScenes (Caesar et al., 2020) in Appendix A.7.
Table 2: Comparison of consistent solutions on Interpret multi-agent validation trackOutput	Sampling	Objective	Marginal metrics			Joint metrics						mADE	mFDE	MR	mFDE	MR	Col	cMRScalar		Marg	0.28	0.59	10.4	1.04	23.7	6.4	24.9Scalar		Joint	0.34	0.77	16.2	0.90	19.9	49	21.7Heat	Learned	Marg	0.26	0.46	4.9	0.98	20.9	4.1	21.9Heat	Learned	Joint	0.29	0.58	9.8	0.88	15.2	3.0	16.4Heat	Algo	Marg	0.29	0.54	3.8	0.83	14.8	7.2	15.9Heat	Algo	Joint	0.29	0.54	3.8	0.83	14.8	2.6	15.6Heat	Combi	Joint	0.31	0.60	8.2	0.76	11.8	2.4	12.7Usually, scalar marginal models already suffer from learning difficulties as only one output modality,the closest one to ground, can be trained at a time. Some modalities may therefore converge fasterto acceptable solutions, and benefit from a much increased number of training samples comparedto the others. This problem is aggravated in the joint training case, since the modality selected isthe same for all agents in a training sample. The joint scalar model therefore actually fails to learnmulti-modality as illustrated by a higher marginal minFDE6 than any other model, and an extremelyhigh crossCollisionRate since some modalities never train and always point to the same coordinatesregardless of the queried agent. Note that, despite a similar training loss, SceneTransformer doesnâ€™tsuffer of the same pitfalls in Tab. 1 as is shares the same weights between all modalities and onlydifferentiates them in the initialization of the features.
Table 3: Comparison of consistent solutions on Interpret multi-agent validation track	Training	Inference 32 agents	Inference 128 agentsGOHOME	12.8 hours	36 ms	90 msTHOMAS	7.5 hours	20 ms	31 msFor additional comparison, the other existing dense prediction method DenseTNT (Gu et al., 2021)reports an inference speed of 100ms per sample for their model.
Table 4: Results on Interpret multi-agent regular scene leaderboard (test set)	minSADE	minSFDE	SMR	SCR	cSMRMoliNet	-073	2.55	44.4	7.5	47.4ReCoG2 (Mo et al., 2020)	0.47	1.16	23.8	6.9	26.8DenseTNT (Gu et al., 2021)	0.42	1.13	22.4	0.0	22.4THOMAS	0.42	0.97	17.9	12.8	25.2Table 5: Results on Interpret multi-agent conditional scene leaderboard (test set)	minSADE	minSFDE	SMR	SCR	cSMRReCoG2 (Mo et al., 2020)	-0.33	0.87	14.98	0.09	15.12DenseTNT (Gu et al., 2021)	0.28	0.89	15.02	0.0	15.02THOMAS	0.31	0.72	10.67	0.84	11.63A.6 Speed / Performance trade-off with hierarchical refinementWe also display the trade-off between inference speed and coverage from hierarchical refinementin Fig. 7, evaluated on the Interpret multi-agent dataset with marginal MissRate6 . The curve isobtained setting the number N of upsampled points at the last refinement iteration from 2 to 128.
Table 5: Results on Interpret multi-agent conditional scene leaderboard (test set)	minSADE	minSFDE	SMR	SCR	cSMRReCoG2 (Mo et al., 2020)	-0.33	0.87	14.98	0.09	15.12DenseTNT (Gu et al., 2021)	0.28	0.89	15.02	0.0	15.02THOMAS	0.31	0.72	10.67	0.84	11.63A.6 Speed / Performance trade-off with hierarchical refinementWe also display the trade-off between inference speed and coverage from hierarchical refinementin Fig. 7, evaluated on the Interpret multi-agent dataset with marginal MissRate6 . The curve isobtained setting the number N of upsampled points at the last refinement iteration from 2 to 128.
Table 6: Argoverse Leaderboard (Chang et al.)	K=1		minADE	K=6 minFDE	MR	minFDE	MR			LaneGCN (Liang et al., 2020)	-378	59.1	-0.87^^	1.36	16.3Autobot (Girgis et al., 2021)	-	-	0.89	1.41	16TPCN (Ye et al., 2021)	3.64	58.6	0.85	1.35	15.9Jean (Mercat et al., 2020)	4.24	68.6	1.00	1.42	13.1SceneTrans (Ngiam et al., 2021)	4.06	59.2	0.80	1.23	12.6LaneRCNN (Zeng et al., 2021)	3.69	56.9	0.90	1.45	12.3PRIME (Song et al., 2021)	3.82	58.7	1.22	1.56	11.5DenseTNT (Gu et al., 2021)	3.70	59.9	0.94	1.49	10.5GOHOME (Gilles et al., 2021a)	3.65	57.2	0.94	1.45	10.5HOME (Gilles et al., 2021b)	3.65	57.1	0.93	1.44	9.8THOMAS	3.59	56.1	0.94	1.44	10.415Published as a conference paper at ICLR 2022Table 7: NuScenes Leaderboard (Caesar et al.)	K=5		K=10		k=1 minFDE	minADE	MR	minADE	MR	CoverNet (Phan-Minh et al., 2020)	-1.96	67	-1.48	-	-
Table 7: NuScenes Leaderboard (Caesar et al.)	K=5		K=10		k=1 minFDE	minADE	MR	minADE	MR	CoverNet (Phan-Minh et al., 2020)	-1.96	67	-1.48	-	-Trajectron++ (Salzmann et al., 2020)	1.88	70	1.51	57	9.52ALAN (Narayanan et al., 2021)	1.87	60	1.22	49	9.98SG-Net (Wang et al., 2021)	1.86	67	1.40	52	9.25WIMP (Khandelwal et al., 2020)	1.84	55	1.11	43	8.49MHA-JAM (Messaoud et al., 2020)	1.81	59	1.24	46	8.57CXX (Luo et al., 2020)	1.63	69	1.29	60	8.86LaPred (Kim et al., 2021)	1.53	-	1.12	-	8.12P2T (Deo & Trivedi, 2020)	1.45	64	1.16	46	10.50GOHOME (Gilles et al., 2021a)	1.42	57	1.15	47	6.99Autobot (Girgis et al., 2021)	1.37	62	1.03	44	8.19PGP (Deo & Trivedi, 2020)	1.30	57	0.98	37	7.72THOMAS	1.33	55	1.04	1.04	6.7116Published as a conference paper at ICLR 2022A.8 Detailed architectureFigure 8: Detailed illustration of our heatmap generator model
