Table 1: Comparison to existing methods.
Table 2: Scene segmentation results. “NV-ARI” refers to ARI evaluated on novel views. “Fg-ARI” refers to ARIevaluated with only foreground pixels. Slot Attention (Locatello et al., 2020) is a state-of-the-art 2D method.
Table 3: Comparison on novel view synthesis from a single image.
Table 4: Comparison on scene editing.
Table 5: Generalization to novel Table 6: Generalization to unseen	Table 7: Ablation study for losses on the		challenging spatial arrangements. combinations of color and shape.	Room-Diverse dataset.		Generalizing to challenging spatial arrangements. We build a new test dataset, packed-CLEVR-11, where each scene has 11 objects that are closely packed into a cluster. Therefore, each scenebears an unseen number of objects in an unseen challenging arrangement. We test models trained onCLEVR-567, report results in Table 5 and Appendix Figure 19. Despite uORF never sees such objectarrangements, it still achieves a reasonable performance and outperforms baselines.
Table 8: Encoder architecture for the CLEVR-567 dataset and the Room-Chair dataset. All convolutional kernelsizes are 3×3. All activation functions for convolutional layers are ReLU.
Table 9: Encoder architecture for the Room-Diverse dataset. All convolutional kernel sizes are 3×3. Allactivation functions for convolutional layers are ReLU.
Table 10: Ablation for background coordinate spaceon novel view synthesis on Room-Chair dataset.
Table 11: Ablation for background coordinate spaceon segmentation on Room-Chair dataset.
Table 12: Novel view synthesis results on unseen/seen shape testset of Room-Diverse.				Table 13: Unsupervised segmentation in 3D results on unseen/seen shape testset of Room-Diverse.		object shapes. To this end, we construct another test set for Room-Diverse. All test objects in thenew test set are drawn from a pool of 500 shapenet chairs that are completely disjoint from the 1200training chairs. All other settings are the same as the original test set. We show quantitative results inTable 12 for novel view synthesis and in Table 13 for segmentation. As we can see, our model yieldsthe same level of performances even on the unseen shape test set, suggesting its generalization tounseen object shapes.
Table 14: Inference comparison with GIRAFFE on CLEVR-567.
Table 15: Inference comparison with GIRAFFE on Room-Chair.
