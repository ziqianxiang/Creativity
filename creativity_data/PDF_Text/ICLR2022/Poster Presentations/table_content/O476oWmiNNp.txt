Table 1: Experimental evalutation of AttnScale & FeatScale plugged into DeiT and CaiT. The numberinside the (↑ ∙) represents the performance gain compared with the baseline model, and accuracieswithin/out of parenthesis are the reported/reproduced performance.
Table 2: Compared with state-of-the-art models on ImageNet dataset. Accuracies with superscript (*)are reported by Gong et al. (2021), with superscript 什)are reported by Yuan et al. (2021), and othersare reported by the original papers. Bold accuracies signifies best models among pure transformers.
Table 3: Experimental evaluation of finetuning AttnScale & FeatScale with CaiT. The number insidethe (↑ ∙) represents the performance gain compared with the baseline model, and accuracies Within/outof parenthesis are the reported/reproduced performance.
