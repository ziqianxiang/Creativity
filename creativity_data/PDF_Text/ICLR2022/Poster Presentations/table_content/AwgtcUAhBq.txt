Table 3: Accuracy (%) on Digits(DANN).
Table 1: Accuracy (DANN) onVisda 2017 with ResNet-50.
Table 2: Comparison using SoTA DA adversarialframeworks with ResNet-50 on Visda.
Table 4: Accuracy (%) on the Amazon Reviews Sentiment Analysis Dataset (NLP)E.2 Sensitivity to Sampling NoiseTable 5: Sensitivity to Sampling Noise controlled by the batch size in the Visda Dataset. Resnet-50	Batch Size	Avg	StdGD	64	67.82	0.29	128	67.50	0.11	160	67.42	0.24	64	73.20	0.36Ours(RK2)	128	73.81	0.26	160	74.18	0.1523Published as a conference paper at ICLR 2022Table 6: Comparison vs Game Optimization Algorithms (best result from the grid search)Algorithm	M→ UGD	90.0GD-NM	93.2EG Korpelevich (1976)	86.7CO Mescheder et al. (2017)	93.8Ours(RK2)	95.3Ours(RK4)	95.9
Table 5: Sensitivity to Sampling Noise controlled by the batch size in the Visda Dataset. Resnet-50	Batch Size	Avg	StdGD	64	67.82	0.29	128	67.50	0.11	160	67.42	0.24	64	73.20	0.36Ours(RK2)	128	73.81	0.26	160	74.18	0.1523Published as a conference paper at ICLR 2022Table 6: Comparison vs Game Optimization Algorithms (best result from the grid search)Algorithm	M→ UGD	90.0GD-NM	93.2EG Korpelevich (1976)	86.7CO Mescheder et al. (2017)	93.8Ours(RK2)	95.3Ours(RK4)	95.9E.3 Additional Comparison vs Game Optimization AlgorithmsIn Table 5, we show the sensitivity of our method to sampling Noise controlled by the mini-batch size. Specifi-
Table 6: Comparison vs Game Optimization Algorithms (best result from the grid search)Algorithm	M→ UGD	90.0GD-NM	93.2EG Korpelevich (1976)	86.7CO Mescheder et al. (2017)	93.8Ours(RK2)	95.3Ours(RK4)	95.9E.3 Additional Comparison vs Game Optimization AlgorithmsIn Table 5, we show the sensitivity of our method to sampling Noise controlled by the mini-batch size. Specifi-cally, we show results for 64, 128, 160 ( with 160 being the bigger size we could fit in GPU memory). We alsoadd results for GD. We observed that our method performs slightly better when the batch size was bigger.
Table 7:	Performance of CO vs others. CO(γ =1e-3) corresponds to the best result after removing1e-4 from the grid search.
Table 8:	Average Time Per Iteration Comparison (Wall-Clock Comparison)Algorithm Avg time per iterationGD-NM 0.26 ± 0.003Ours(RK2) 0.49 ± 0.00824Published as a conference paper at ICLR 2022In Table 8, we show experimental results of a wall-clock comparison between RK2 and GD-NM. Specifically,we compute the average over 100 runs on a NVIDIA GPU: TITAN V, CudaVersion 10.1 and PyTorch version:1.5.1. As we can see, the average increase in time is less than 2x slower in wall-clock time.This is in line with theclaims made in our submission. We additionally emphasize that this time can be improved with more efficientimplementations (e.g. Cuda). Moreover, many more efficient high-order ODE solvers exist and could be used inthe future. Our work also inspires future research in this direction.
