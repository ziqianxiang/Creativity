Table 1: Comparison with SoTA methods on VisDA-2017. “S/B” implies the DeiT-small/DeiT-basebackbone respectively. * indicates the results are reproduced by ourselves. ◦ implies its pretrainedmodel is trained on ImageNet21K instead of ImageNet1K. The best performance is marked as bold.
Table 2: Comparison with SoTA methods on Office-Home. The best performance is marked as bold.
Table 4: ComParison with SoTA methods on DomainNet. “Base” is the Baseline.
Table 3: Comparison with SoTA methods on Office-31.
Table 5: Comparison among different pseudo labeling methods on VisDa-2017. Recs , Rect expressthe reCall of pseudo labels in sourCe and target data, while Prec represents the aCCuraCy of the pairs.
Table 6: Comparison among different losses on VisDa-2017. Ls,Lt and Ls+t represent the loss usedin sourCe, target and sourCe+target branChes respeCtively. cls and dtl imply the ClassifiCation lossand the distillation loss.
