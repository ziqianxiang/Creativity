Table 1: Results on single few-shot tasks on NER (F1 score) and text classification (accuracy).
Table 2: F1 score on the whole test set after learning all NER domains (CoNLL03, OntoNotes).
Table 3: Accuracy on the whole test set after learning all domains (AGNews, Amazon, DBPedia, Yahoo).
Table 4: Average of ROUGE-1, ROUGE-2 and ROUGE-L scores (A-RG) on the whole test set after learningall domains (CNNDM, WikiHow, XSum).
Table 5: Results for learning three different task types: NER (CoNLL), Classification (AGNews) and Summa-rization (CNNDM). The tasks are presented in three different orders with different few-shot samples (resultsare shown in the same order). The metrics reported are F1 for NER, accuracy for Classification and Average-ROUGE for Summarization.
Table 6: Text classification accuracy on the whole test set for three runs with different domain order.				5	AnalysisInfluence of Domain Order To evaluate the influence of domain orders when LFPT5 is learningdifferent task domains, we show the results of three runs with different domain order on the clas-sification task in Table 6. We can see that the order of domains influences the performance of allmethods a lot. For example, PT can achieve 41.67 accuracy on the third run while the accuracy of thefirst run is only 18.88. This phenomenon indicates that the difficulty of transferring knowledge fromone domain to another might be quite different from that of the opposite transfer direction. Thoughthe performance is affected by the order, LFPT5 outperforms previous regularization-based lifelonglearning methods by a large margin for all different orders (see Appendix A.8 for more analysis).
Table 7: Average Rouge (A-RG) score of LFPT5 with different Î»kl on summarization.
Table 8: Accuracy (%) of different methods after learning all 9 domains.
Table 9: A-RG score of different methods with T5-Base backbone on summarization.
Table 10: A-RG score of different methods with different numbers (16, 32) of few-shot data on summarization.
Table 11:	A-RG score of LFPT5 with different numbers of pseudo samples on summarization.
Table 12:	Comparison results of single prompt multitask prompt tuning, multiple prompts multitask prompttuning and LFPT5.
