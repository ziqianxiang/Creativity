Table 1: OC20ISRE Validation, eV MAE, L“GNS-Shared” indicates shared weights. “GNS-10” indicates a group size of 10.
Table 2: Results OC20 IS2RE TesteV MAE J	SchNet	DimeNet++	SpinConv	SphereNet	GNS + Noisy NodesOOD Both	0.704	0.661	0.674	0.638	0.465 (-24.0%)OOD Adsorbate	0.734	0.725	0.723	0.703	0.565 (-22.8%)OOD Catalyst	0.662	0.576	0.569	0.571	0.437 (-17.2%)ID	0.639	0.562	0.558	0.563	0.422 (-18.8%)Average Energy within Threshold (AEwT) ↑						SchNet	DimeNet++	SpinConv	SphereNet	GNS + Noisy NodesOOD Both	0.0221	0.0241	0.0233	0.0241	0.047 (+95.8%)OOD Adsorbate	0.0233	0.0207	0.026	0.0229	0.035 (+89.5%)OOD Catalyst	0.0294	0.0410	0.0382	0.0409	0.080 (+95.1%)ID	0.0296	0.0425	0.0408	0.0447	0.091 (+102.0%)We first convert to fractional coordinates (i.e. use the periodic unit cell as the basis) which renderthe predictions of our model invariant to rotations, and append the following rotation and translationinvariant vector (αβτ, βγτ, ɑγτ, |a|, ∣β∣, ∣γ∣) ∈ R6 to the edge features where α, β, Y are vectorsof the unit cell. This additional vector provides rotation invariant angular and extent information tothe GNN.
Table 3: OC20 IS2RS Validation, ADwT, ↑Model	Layers	OOD Both	OOD Adsorbate	OOD Catalyst	IDGNS	50	43.0%±0.0	38.0%±0.0	37.5% 0.0	40.0%±0.0GNS + Noisy Nodes	50	50.1%±0.0	44.3%±0.0	44.1%±0.0	46.1% ±0.0GNS-10 + Noisy Nodes	50	52.0%±0.0	46.2%±0.0	46.1% ±0.0	48.3% ±0.0GNS-10 + Noisy Nodes + Pos only	100	54.3%±0.0	48.3%±0.0	48.2% ±0.0	50.0% ±0.0Table 4: OC20 IS2RS Test, ADwT, ↑Model	OOD Both	OOD AdsOrbate	OOD Catalyst	IDForceNet	46.9%	37.7%	43.7%	44.9%GNS + Noisy Nodes	52.7%	43.9%	48.4%	50.9%Relative Improvement	+12.4%	+16.4%	+10.7%	+13.3%6.2	QM9Dataset. The QM9 benchmark (Ramakrishnan et al., 2014) contains 134k molecules in equilibriumwith up to 9 heavy C, O, N and F atoms, targeting 12 associated chemical properties (License: CCBY4.0). We use 114k molecules for training, 10k for validation and 10k for test. All results are on thetest set. We subtract a fixed per atom energy from the target values computed from linear regressionto reduce variance. We perform training in eV units for energetic targets, and evaluate using MAE.
Table 4: OC20 IS2RS Test, ADwT, ↑Model	OOD Both	OOD AdsOrbate	OOD Catalyst	IDForceNet	46.9%	37.7%	43.7%	44.9%GNS + Noisy Nodes	52.7%	43.9%	48.4%	50.9%Relative Improvement	+12.4%	+16.4%	+10.7%	+13.3%6.2	QM9Dataset. The QM9 benchmark (Ramakrishnan et al., 2014) contains 134k molecules in equilibriumwith up to 9 heavy C, O, N and F atoms, targeting 12 associated chemical properties (License: CCBY4.0). We use 114k molecules for training, 10k for validation and 10k for test. All results are on thetest set. We subtract a fixed per atom energy from the target values computed from linear regressionto reduce variance. We perform training in eV units for energetic targets, and evaluate using MAE.
Table 5: QM9, Impact of Noisy Nodes on GNS architecture.
Table 6: QM9, Test MAE, Mean & Standard Deviation of 3 Seeds Reported.
Table 7: OGBG-PCQM4M ResultsModel	Number of Layers	Using Noisy Nodes	MAEMPNN + Virtual Node	16	Yes	0.1249 ± 0.0003MPNN + Virtual Node	50	No	0.1236 ± 0.0001Graphormer (Ying et al., 2021)	-	-	0.1234MPNN + Virtual Node	50	Yes	0.1218 ± 0.00017	Non-Spatial TasksThe previous experiments use the 3D geometries of atoms, and models that operate on 3D points.
Table 8: OC20 IS2RS Test, Average Force below Threshold %, ↑Model	Method	OOD Both	OOD Adsorbate	OOD Catalyst	IDNoisy Nodes	Direct	0.09%	0.00%	0.29%	0.54%Table 9: OC20 IS2RS Test, Force below Threshold %, ↑					Model	Method	OOD Both	OOD Adsorbate	OOD Catalyst	IDNoisy Nodes	Direct	0.0%	0.0%	0.0%	0.0%A.2 More details on GNS adaptations for molecular property prediction.
Table 9: OC20 IS2RS Test, Force below Threshold %, ↑					Model	Method	OOD Both	OOD Adsorbate	OOD Catalyst	IDNoisy Nodes	Direct	0.0%	0.0%	0.0%	0.0%A.2 More details on GNS adaptations for molecular property prediction.
Table 10: OGBG-MOLPCBA Noise Ablation	Mean AP	 MPNN Without DroPEdge	27.4% ± 0.002MPNN With DropEdge	27.5% ± 0.001MPNN + DropEdge + Noisy Nodes	27.8% ± 0.002Table 11: OGBG-MOLPCBA DropEdge AblationA.7 DropEdge & DropNode Ablations for OGBG-MOLPCBAWe conduct an ablation with our 16 layer MPNN using DropEdge at a rate of 0.1 as an alternativeapproach to improving oversmoothing and find it does not improve performance for ogbg-molpcba(Table 11), similarly we find DropNode (Table 12) does not improve performance. In addition, wefind that these two methods can’t be combined well together, reaching a performance of 27.0% ±0.003. However, both methods can be combined advantageously with Noisy Nodes.
Table 11: OGBG-MOLPCBA DropEdge AblationA.7 DropEdge & DropNode Ablations for OGBG-MOLPCBAWe conduct an ablation with our 16 layer MPNN using DropEdge at a rate of 0.1 as an alternativeapproach to improving oversmoothing and find it does not improve performance for ogbg-molpcba(Table 11), similarly we find DropNode (Table 12) does not improve performance. In addition, wefind that these two methods can’t be combined well together, reaching a performance of 27.0% ±0.003. However, both methods can be combined advantageously with Noisy Nodes.
Table 12: OGBG-MOLPCBA DropNode Ablation17Published as a conference paper at ICLR 2022Per Layer Node Latent MAD						15	0.56	0.073	0.045			14	0.14	0.06	0.036			-0.813	0.17	0.2	0.016			12	0.43	0.05	0.054			11	0.7	0.062	0.074			10	0.81	0.32	0.11			-0.69	013	0.032	0.12			⅛ 8	0.67	0.46	0.015			S' 7	037	03	0.2			-0.4		0.66	0.6			5	0.67	0.67	0.76 —			4	0.62	0.79	0.83 —			3		0.81	0.84 —			-0.22		0/74	0.87 —			1	0.67		0.73 —			O	0.85 —	0.85 —	0.92 —			
Table 13: Open Catalyst training parameters.
Table 14: QM9 training parameters.
Table 15: OGBG-PCQM4M Training Parameters.
Table 16: OGBG-MOLPCBA Training Parameters.
Table 17: OGBG-ARXIV Training Parameters.
