Table 1: Means and standard deviations (percentage) of classification accuracy with different instance-dependent label noise levels. Methods with “-F” adopt the Forward correction loss; methods with“-V” mean that the transition matrices are revised via the slack variable trick.
Table 2: Classification accuracy on Clothing1M. In the experiments, only noisy samples are exploitedto train and validate the deep model.
Table 3: Dataset statistics on F-MNIST, SVHN, CIFAR-10, and Clothing1M	F-MNIST	SVHN	CIFAR-10	Clothing1M	 # training/noisy images	60,000	73,257	50,000	1,000,000# test/clean images	10,000	26,032	10,000	10,000label noise	synthetic	synthetic	synthetic	real-world15Published as a conference paper at ICLR 2022B.2	Running EnvironmentAll baselines and IF approaches are implemented in PyTorch, and tested on a machine with AMDEPYC 7282 16-core processors, 4 GeForce GTX-3090 Ti GPUs with 24GB memory size.
Table 4: Means and standard deviations (percentage) of classification accuracy with high instance-dependent label noise levels for CIFAR10 dataset. Methods with “-F” adopts the Forward correctionloss; methods with “-V” means that the transition matrices are revised via slack variable trick.
Table 5: Means and standard deviations (percentage) of classification accuracy with more baselinesfor CIFAR10 dataset. Methods with “-F” adopts the Forward correction loss; methods with “-V”means that the transition matrices are revised via slack variable trick.
