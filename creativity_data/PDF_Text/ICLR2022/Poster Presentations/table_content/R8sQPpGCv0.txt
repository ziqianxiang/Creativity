Table 1: The speed (during training and evaluation, in words per second) and memory usage (duringtraining) of the rotary, T5 bias, and ALiBi models compared to the sinusoidal baseline on WikiText-103. Training and inference are batched, and speeds are shown for one V100 GPU.
Table 2: The sinusoidal, rotary, T5 bias and ALiBi models trained on L = 512 on WikiText-103 andevaluated with different values of Lvalid on the validation set. Bold shows the best score for eachmodel. Inference speeds (in words per second) are from inference on a GPU with batch size of one.
Table 3: The sinusoidal, rotary, T5 bias and ALiBi models trained on L = 1024 on WikiText-103and evaluated with different values of Lvalid on the validation set. Bold shows the best score for eachmodel. Inference speeds (in words per second) are from inference on a GPU with batch size of one.
Table 4: The sinusoidal, rotary, T5 bias and ALiBi models trained on L = 3072 on WikiText-103and evaluated with different values of Lvalid on the validation set. Bold shows the best score for eachmodel. Inference speeds (in words per second) are from inference on a GPU with batch size of one.
Table 5: Perplexity When ALiBi extrapolates on the WikiText-103 development set. *For results Wepresent for the sinusoidal, rotary and T5 bias models, L = Lvalid (so we do not test the extrapolationabilities of those baselines here).
Table 6: Test perplexity and runtime on WikiText-103 for two of our ALiBi models and models thatuse the sinusoidal, rotary and T5 bias methods.
Table 7: Valid and test perplexity scores on WikiText-103 for two of our ALiBi models and modelsthat use the sinusoidal, rotary and T5 bias methods with sliding window evaluation (§B and S=512following (Baevski & Auli, 2018; Khandelwal et al., 2020; Press et al., 2021)). The sinusoidal modelpresents our results from training and inference with the model of Baevski & Auli.
Table 8: ALiBi models extrapolating on the Toronto BookCorpus development set. *For the resultsof the sinusoidal models, L = Lvalid (so we do not test the extrapolation abilities of those modelshere).
Table 9: Validation and test perplexities on the Toronto Book Corpus dataset.
Table 10: Validation and test perplexities on the Toronto Book Corpus dataset with a sliding window(§B). Following (Baevski & Auli, 2018; Khandelwal et al., 2020; Press et al., 2020; 2021), we setthe sliding window stride S=512.
Table 11: Perplexity, memory, and train time on the CC100+RoBERTa corpus for our ALiBi modelsand the sinusoidal baseline. We run our L = 512 (1024) model and the sinusoidal model with L =1024 (2048) for the same amount of time. We show that our models achieve strong results eventhough they use 6-11% less memory.
Table 12: Perplexity, train time and memory use of the sinusoidal and ALiBi models on theCC100+RoBERTa corpus when all models are trained with 50k updates.
Table 13: Perplexities of the sinusoidal models evaluated with sliding window evaluation with strideS = 1 on the WikiText-103 validation dataset.
Table 14: Perplexities of the T5 bias models evaluated with sliding window evaluation with strideS = 1 on the WikiText-103 validation dataset.
Table 15: Perplexities of the ALiBi models evaluated with sliding window evaluation with strideS = 1 on the WikiText-103 validation dataset.
