Table 1: Recovery error in SPE. The reported time is the av-erage wall-clock time for solving each instance in seconds.
Table 2: Recovery accuracy on real-world datasets.
Table 4: Training time for SPE (minutes)Table 3: Training time for SLR (minutes)Sizes	d = 256	d= 1024	Sizes	d = 50	d= 100PLISA	393	462	PLISA	35	39ALISTA	176	271	GGM	14	43RNN	96	99	GISTA	176	116RNN'1	101	106	APF	316	331APF	214	426	GLASSO	42	57We report the total training time for learning based methods as well as the parameter tuning time forclassical algorithms. From Table 3 and Table 4, we can see that training a learning-based method is45Published as a conference paper at ICLR 2022cheap in our experiments, as 1) A single forward for PLISA or GGM is very fast as stated in Table 1.
Table 3: Training time for SLR (minutes)Sizes	d = 256	d= 1024	Sizes	d = 50	d= 100PLISA	393	462	PLISA	35	39ALISTA	176	271	GGM	14	43RNN	96	99	GISTA	176	116RNN'1	101	106	APF	316	331APF	214	426	GLASSO	42	57We report the total training time for learning based methods as well as the parameter tuning time forclassical algorithms. From Table 3 and Table 4, we can see that training a learning-based method is45Published as a conference paper at ICLR 2022cheap in our experiments, as 1) A single forward for PLISA or GGM is very fast as stated in Table 1.
Table 5: Ablation study of PLISA (p = 1024). TPRis the true positive rate of recovering the nonzero en-tries of Î²*. FPS is the cardinality of false positiveentries. Note that the true sparsity level is s* =16. Standard deviations over 100 test problems arepresent in the parantheses.
