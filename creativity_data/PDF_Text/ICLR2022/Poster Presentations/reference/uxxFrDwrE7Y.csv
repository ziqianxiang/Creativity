title,year,conference
 Gradient based sample selectionfor online continual learning,2019, In Advances in Neural Information Processing Systems
 Noise as a resource for learning in knowledgedistillation,2021, In Proceedings of the IEEE/CVF Winter Conference on Applications of ComputerVision
 Measuring and regularizing networks infunction space,2018, arXiv preprint arXiv:1805
 Rethinking experiencereplay: a bag of tricks for continual learning,2020, arXiv preprint arXiv:2010
 Entropy-sgd: Biasing gradientdescent into wide valleys,2019, Journal of Statistical Mechanics: Theory and Experiment
 Efficientlifelong learning with a-gem,2018, arXiv preprint arXiv:1812
 A continual learning survey: Defying forgetting in classificationtasks,3762, arXiv preprint arXiv:1909
 Towards robust evaluations of continual learning,2018, arXiv preprintarXiv:1805
 Catastrophic forgetting in connectionist networks,1999, Trends in cognitive sciences
 On calibration of modern neuralnetworks,2017, In International Conference on Machine Learning
 Replay in deep learning: Current approaches and missing biologicalelements,2021, arXiv preprint arXiv:2104
 Deep residual learning for image recog-nition,2015, corr abs/1512
 Flat minima,1997, Neural computation
 Learning a unified classifierincrementally via rebalancing,2019, In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition
 Selective experience replay for lifelong learning,2018, In Proceedingsof the AAAI Conference on Artificial Intelligence
 Deep generative dual memory network for continuallearning,2017, arXiv preprint arXiv:1710
 On large-batch training for deep learning: Generalization gap and sharp minima,2016, arXivpreprint arXiv:1609
 Biologically inspiredsleep algorithm for artificial neural networks,2019, arXiv preprint arXiv:1908
 Learning multiple layers of features from tiny images,2009,2009
 Gradient-based learning applied todocument recognition,2017, Proceedings of the IEEE
 Onlinecontinual learning in image classification: An empirical survey,2022, Neurocomputing
 Generalized class incrementallearning,2020, In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni-tion Workshops
 Continuallifelong learning with neural networks: A review,2019, Neural Networks
 Tiny imagenet visual recognition challenge,2017, CS231N course
 Learning to learn without forgetting by maximizing transfer and minimizing interfer-ence,2018, arXiv preprint arXiv:1810
 Complementary learning for overcomingcatastrophic forgetting using experience replay,2019, arXiv preprint arXiv:1903
 Progressive neural networks,2016, arXiv preprintarXiv:1606
 Knowledge distillation beyond model compres-sion,6136, In 2020 25th International Conference on Pattern Recognition (ICPR)
 13Antti Tarvainen and Harri Valpola,2019, Mean teachers are better role models: Weight-averaged consis-tency targets improve semi-supervised deep learning results
 Random sampling with a reservoir,1985, ACM Transactions on Mathematical Software(TOMS)
 Lifelong learning with dynamicallyexpandable networks,2017, arXiv preprint arXiv:1708
 Deep mutual learning,2018, InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition
