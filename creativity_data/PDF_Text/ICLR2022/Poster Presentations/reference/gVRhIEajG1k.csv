title,year,conference
 The elements of integration and Lebesgue measure,2014, John Wiley & Sons
 Gradient-trained weights in wide neural networks align layerwiseto error-scaled input correlations,2021, arXiv e-prints
 Towards evaluating the robustness of neural networks,2017, In 2017ieee Symposium on security and privacy (sp)
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE conference on computervision and pattern recognition
 Evading defenses to transferable adversar-ial examples by translation-invariant attacks,2019, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Implicit generation and modeling with energy based models,2019, Advancesin Neural Information Processing Systems
 Robustness of classifiers:from adversarial to random noise,2016, Advances in Neural Information Processing Systems
 Imagenet-trained CNNs are biased towards texture; increasing shape bias im-proves accuracy and robustness,2019, In International Conference on Learning Representations
 Explaining and harnessing adversarialexamples,2015, International Conference on Learning Representations
 Your classifier is secretly an energy based model and you should treat it likeone,2020, International Conference on Learning Representations
 Backpropagating linearly improves transferability of ad-versarial examples,2020, Advances in Neural Information Processing Systems
 Benchmarking neural network robustness to common cor-ruptions and perturbations,2019, Proceedings of the International Conference on Learning Represen-tations
 Augmix: A simple method to improve robustness and uncertainty under data shift,2020, InInternational Conference on Learning Representations
 Stochastic security: Adversarial defense usinglong-run dynamics of energy-based models,2021, International Conference on Learning Representa-tions
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Enhanc-ing adversarial example transferability with an intermediate level attack,2019, In Proceedings of theIEEE/CVF International Conference on Computer Vision
 Estimation of non-normalized statistical models by score match-ing,2005, Journal of Machine Learning Research
 Similarity of neuralnetwork rePresentations revisited,2019, In International Conference on Machine Learning
 Delving into transferable adversarial exam-Ples and black-box attacks,2017, International Conference on Learning Representations
 Cross-domain transferability of adversarial Perturbations,2019, Advances in NeuralInformation Processing Systems
 A self-suPervised aPProach for adversarial robustness,2020, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Do wide and deep networks learn the samethings? uncovering how neural network representations vary with width and depth,2020, In Interna-tional Conference on Learning Representations
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, International Conference on Learning Representa-tions
 Very deep convolutional networks for large-scale imagerecognition,2015, arXiv preprint 1409
 Smoothgrad:removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2018, Interna-tional Conference on Learning Representations
 Sliced score matching: A scalable approachto density and score estimation,2020, In Uncertainty in Artificial Intelligence
 Rethinking the role of gradient-based attribution methods formodel interpretability,2021, In International Conference on Learning Representations
 Robustifying models against adversarial attacks by langevin dynamics,2021, Neu-ral Networks
 Is robustnessthe cost of accuracy?-a comprehensive study on the robustness of 18 deep image classificationmodels,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 One pixel attack for fooling deepneural networks,2019, IEEE Transactions on Evolutionary Computation
 Intriguing properties of neural networks,2013, International Conference on LearningRepresentations
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Ensemble adversarialtraining: Attacks and defenses,2018, In International Conference on Learning Representations
 The spaceof transferable adversarial examples,2017, arXiv preprint arXiv:1704
 A unifiedapproach to interpreting and boosting adversarial transferability,2020, In International Conference onLearning Representations
 Skip connections matter:On the transferability of adversarial examples generated with resnets,2019, In International Conferenceon Learning Representations
 Learningblack-box attackers with transferable priors and query feedback,2020, Advances in Neural InformationProcessing Systems
 Boosting transferability of targetedadversarial examples via hierarchical generative networks,2021, arXiv preprint arXiv:2107
 Boosting transferability of targetedadversarial examples via hierarchical generative networks,2021, CoRR
 Adversarial purification with score-based generativemodels,2021, International Conference on Machine Learning
 Backpropagating smoothly improves transferability of adversarial examples,2021, InCVPR 2021 Workshop Workshop on Adversarial Machine Learning in Real-World Computer Vi-sion Systems and Online Challenges (AML-CV)
