title,year,conference
 Expert Gate: Lifelong Learning with a Network ofExperts,2017, In CVPR
 Online continual learning with maximal interfered retrieval,2019, Advancesin Neural Information Processing Systems
 Task-free continual learning,2019, In Pro-ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
 Gradient based sample selectionfor online continual learning,2019, In NeurIPS
 Rainbow memory:Continual learning with a memory of diverse samples,2018, In Proceedings of the IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition
 Active bias: Training moreaccurate neural networks by emphasizing high variance samples,2017, Advances in Neural InformationProcessing Systems
 Riemannianwalk for incremental learning: Understanding forgetting and intransigence,2022, In ECCV
 Efficientlifelong learning with A-GEM,2019, In ICLR
 Superposition of Many Modelsinto One,2019, In NeurIPS
 GAN memory with no forgetting,2020, InNeurIPS
 Importance sampling for minibatches,2018, The Journal ofMachineLearningResearch
 AutoAugment:Learning augmentation strategies from data,2019, In CVPR
 Uncertainty-Guided Continual Learningwith Bayesian Neural Networks,2020, In ICLR
 Incremental Learning In Online Scenario,2020, In CVPR
 Overcoming catastrophic forgetting via model adaptation,2019, In ICLR
 Not all samples are created equal: Deep learning withimportance sampling,2018, In International conference on machine learning
 Imbalanced Continual Learning with Partitioning Reservoir Sam-pling,2020, In ECCV
 Incremental learning withmaximum entropy regularization: Rethinking forgetting and intransigence,2019, arXiv preprinthttps://arxiv
 Nsml: Meet the mlaas platform witha real-world case study,2018, arXiv preprint arXiv:1810
 Overcom-ing catastrophic forgetting in neural networks,2017, Proceedings of the national academy of sciences
 Optimal brain damage,1990, In Advances in neuralinformation processing systems
 Lifelong learning with dynamicallyexpandable networks,2017, ICLR
 Overcoming catastrophicforgetting by incremental moment matching,2017, In NeurIPS
 A neural dirichlet process mixturemodel for task-free continual learning,2019, In International Conference on Learning Representations
 Mnemonics training: Multi-class incremental learning without forgetting,2017, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Incremental on-line learning: A review andcomparison of state of the art algorithms,925, Neurocomputing
 Onlinecontinual learning in image classification: An empirical survey,2021, arXiv preprint arXiv:2101
 PackNet: Adding Multiple Tasks to a Single Network by IterativePruning,2018, In CVPR
 Catastrophic interference in connectionist networks: The sequential learn-ing problem,1989, Psychology of Learning and Motivation
 Under-standing the role of training regimes in continual learning,2020, In Advances in Neural InformationProcessing Systems 33: Annual Conference on Neural Information Processing Systems 2020
 Connectionist models of recognition memory: Constraints imposed by learning andforgetting functions,1990, Psychological Review
 iCaRL:Incremental classifier and representation learning,2017, In CVPR
 Experiencereplay for continual learning,2018, arXiv preprint arXiv:1811
 Progressive neural networks,2016, arXiv
 Gradient projection memory for continual learning,2021, InInternational Conference on Learning Representations
 Continual learning with deep generativereplay,2017, In NeurIPS
 Nsml: A machine learningplatform that enables you to focus on your models,2017, arXiv preprint arXiv:1712
 Class-incremental learning with generativeclassifiers,2021, In CVPR
 Random sampling with a reservoir,1985, ACM Transactions on Mathematical Software(TOMS)
 Largescale incremental learning,2019, In CVPR
 Scalable and order-robust continuallearning with additive parameter decomposition,2020, In ICLR
