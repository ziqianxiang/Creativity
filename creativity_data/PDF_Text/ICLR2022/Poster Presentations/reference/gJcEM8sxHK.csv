title,year,conference
 Weakly supervised learning of semantic parsers for mappinginstructions to actions,2013, Transactions of the Association for Computational Linguistics
 Experience grounds language,8718, In Proceedings of the 2020 Conference on Empiri-cal Methods in Natural Language Processing (EMNLP)
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Constructing taxonomies from pretrained languagemodels,2020, arXiv preprint arXiv:2010
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 The curious case of neural textdegeneration,2019, arXiv preprint arXiv:1904
 Room-Across-Room:Multilingual vision-and-language navigation with dense spatiotemporal grounding,2020, In Conferenceon Empirical Methods for Natural Language Processing (EMNLP)
 Implicit representations of meaning in neurallanguage models,2021, In Proceedings of the 59th Annual Meeting of the Association for Computa-tional Linguistics and the 11th International Joint Conference on Natural Language Processing(Volume 1: Long Papers)
 Exploring numeracyin word embeddings,2019, In Proceedings of the 57th Annual Meeting of the Association for Com-putational Linguistics
 Languagemodels are unsupervised multitask learners,2019, OpenAI blog
 Prompt programming for large language models: Beyond thefew-shot paradigm,2021, In Extended Abstracts of the 2021 CHI Conference on Human Factors inComputing Systems
 Neural machine translation of rare words withsubword units,2015, arXiv preprint arXiv:1508
 What do you learn fromcontext? probing for sentence structure in contextualized word representations,2019, In InternationalConference on Learning Representations
 Multi-modal few-shot learning with frozen language models,2021, Advances in Neural Information Process-ing Systems
 Attention is all you need,2017, arXiv preprint arXiv:1706
 Do NLP models knownumbers? probing numeracy in embeddings,2019, In Proceedings of the 2019 Conference on EmpiricalMethods in Natural Language Processing and the 9th International Joint Conference on NaturalLanguage Processing (EMNLP-IJCNLP)
 HUggingface's transformers:State-of-the-art natural language processing,2019, arXiv preprint arXiv:1910
