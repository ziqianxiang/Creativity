title,year,conference
 Travelgan: Image-to-image translation by transfor-mation vector learning,2019, In Proceedings of the IEEE/CVF Conference on CompUter Vision andPattern Recognition
 Input convex neural networks,2017, In InternationalConference on Machine Learning
 Ae-ot:A new generative model based on extended semi-discrete optimal transport,2020, In InternationalCOnference on Learning RePresentations
 Ncp-vae: Variational autoencoderswith noise contrastive priors,2021, In Advances in NeUraI InfOrmatiOn PrOcessing Systems Conference
 Sorting out lipschitz function approximation,2019, InInternational COnference on Machine Learning
 Towards principled methods for training generative adversarialnetworks,2017, arXiv PrePrint arXiv:1701
 Began: Boundary equilibrium generative ad-versarial networks,2017, arXiv PrePrint arXiv:1703
 Large scale GAN training for high fidelitynatural image synthesis,2019, In International COnference on Learning RePresentations
 Sliced iterative normalizing flows,2021, In ICML WOrkshOP on InVertibIeNeUraI Networks
 Generative modeling using the slicedWasserstein distance,2018, In Proceedings of the IEEE conference on CompUter Vision and Patternrecognition
 Implicit generation and generalization in energy-based models,2019, arXivPrePrint arXiv:1903
 Scalable computation ofmonge maps with general costs,2021, arXiv PrePrint arXiv:2106
 Learning withminibatch wasserstein: asymptotic and gradient properties,2019, arXiv PrePrint arXiv:1910
 Learning generative models with sinkhorn di-vergences,1608, In International ConferenCe on ArtifiCiaI Intelligence and Statistics
 Generative adversarial nets,2014, In AdVanCes in NeuralInformation Processing Systems Conference
 Im-proved training of wasserstein gans,2017, In Proceedings of the 31st International ConferenCe onNeUraI Information ProCessing Systems
 W2gan: Re-covering an optimal transport map with a gan,2018,2018
 On a problem of monge,1948, UsPekhi Mat
 A style-based generator architecture for generativeadversarial networks,2019, In ProCeedings of the IEEE/CVF ConferenCe on ComPUter Vision andPattern Recognition
 Local stability of wasserstein gans withabstract gradient penalty,2021, IEEE TransaCtions on NeUraI NetWorks and Learning Systems
 Adam: A method for stochastic optimization,2014, arXiv PrePrintarXiv:1412
 Auto-encoding variational bayes,2013, arXiv PrePrintarXiv:1312
 Do neural optimal transport solvers work? a continuous wasserstein-2 benchmark,2021, arXivPrePrint arXiv:2106
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 A geometric view of optimaltransportation and generative model,2019, Computer Aided GeometriC Design
 Learning high dimensionalwasserstein geodesics,2021, arXiv Preprint arXiv:2102
 Guiding the one-to-one map-ping in cyclegan via optimal transport,2019, In ProCeedings of the AAAI ConferenCe on ArtifiCiaIIntelligence
 Large-scale op-timal transport via adversarial training with cycle-consistency,2020, arXiv Preprint arXiv:2003
 Optimal transport mappingvia input convex neural networks,2020, In International ConferenCe on MaChine Learning
 Least squares generative adversarial networks,2017, In Proceedings of the IEEE internationalConference on CompUter Vision
 Optimal transportation between unequal dimensions,2020, ArChiVefor RationaI MeChaniCs and AnaIysis
 Spectral normalization forgenerative adversarial networks,2018, In International ConferenCe on Learning Representations
 Threeplayerwasserstein gan via amortised duality,2019, In Proc
 Autoregressive quantile networks for generativemodeling,2018, In International ConferenCe on MaChine Learning
 Regularity of optimal transportation between spaces with different dimensions,2010, arXivPreprintarXiV:1008
 Sinkhorn autoencoders,2020, In UnCertainty in ArtifiCiaIIntelligence
 On the regularization of wasserstein gans,2018, InInternational ConferenCe on Learning Representations
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2016, In 4th International ConferenCe on LearningRepresentations
 On the convergence and ro-bustness of training gans with regularized optimal transport,2018, AdvanceS in Neural InformationProceSSing Systems
 Optimal transport for applied mathematicians,2015, Birkauser
 Large scale optimal transport and mapping estimation,2018, In InternationalCOnference on Learning RePreSentations
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE conference oncomputer vision and Pattem recognition
 2-wasserstein approximation via restricted convex potentialswith application to improved training for gans,2019, arXiv PrePrint arXiv:1902
 Wasserstein auto-encoders,2017, arXiv PrePrint arXiv:1711
 Nvae: A deep hierarchical variational autoencoder,2020, In AdvanceS inNeUraI InfOrmatiOn PrOceSSing SyStemS Conference
 On scalable and efficientcomputation of large scale optimal transport,2019, In International COnference on Machine Learning
 Unpaired image-to-image trans-lation using cycle-consistent adversarial networks,2017, In COmPUter ViSiOn (ICCV)
