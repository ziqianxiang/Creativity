title,year,conference
 The arcade learning environ-ment: An evaluation platform for general agents,2013, Journal of Artificial Intelligence Research
 A distributional perspective on reinforcementlearning,2017, In Proceedings of the 34th International Conference on Machine Learning
 R-MAX - A general polynomial time algorithm fornear-optimal reinforcement learning,2002, Journal of Maching Learning Research
 Exploration by random networkdistillation,2019, In Proceedings of the 7th International Conference on Learning Representations
 Provably efficient exploration in policy optimiza-tion,2020, In Proceedings of the 37th International Conference on Machine Learning
 Coordinated exploration in concurrent reinforcementlearning,2018, In Proceedings of the 35th International Conference on Machine Learning
 Hypermodels for exploration,2020, In Proceedings of the 8th International Conference onLearning Representations
 Noisy networks for exploration,2018, In Proceedings of the 6th InternationalConference on Learning Representations
 Soft actor-critic: Off-policymaXimum entropy deep reinforcement learning with a stochastic actor,2018, In Proceedings of the 35thInternational Conference on Machine Learning
 Rainbow: Combiningimprovements in deep reinforcement learning,2018, In Proceedings of the 32nd AAAI Conference onArtificial Intelligence
 Deep q-learning from demonstrations,2018, In Proceedings of the 32ndAAAI Conference on Artificial Intelligence
 Near-optimal regret bounds for reinforcementlearning,2010, Journal of Maching Learning Research
 Provably efficient reinforcementlearning with linear function approXimation,2020, In Proceedings of the 33rd Annual Conference onLearning Theory
 On the sample complexity of reinforcement learning,2003, PhD thesis
 Super Mario Bros for OpenAI Gym,2018, GitHub
 Adam: A method for stochastic optimization,2015, In Proceedings ofthe 3rd International Conference on Learning Representations
 Efficient backprop,1998, InNeural networks: Tricks of the trade
 Continuous control with deep reinforcement learning,2016, InProceedings of the 4th International Conference on Learning Representations
 Ensemble sampling,2017, In Advances in Neural InformationProcessing Systems 30
 Human-level controlthrough deep reinforcement learning,2015, Nature
 The uncertainty bellmanequation and exploration,2018, In Proceedings of the 35th International Conference on MachineLearning
 Deep Exploration via Randomized Value Functions,2016, PhD thesis
 Deep exploration viabootstrapped DQN,2016, In Advances in Neural Information Processing Systems 29
 Randomized prior functions for deep reinforcementlearning,2018, In Advances in Neural Information Processing Systems 31
 Deep exploration via randomizedvalue functions,2019, Journal of Machine Learning Research
 Behaviour suite for reinforcement learning,2020, In Proceedings ofthe 8th International Conference on Learning Representations
 Curiosity-driven explorationby self-supervised prediction,2017, In Proceedings of the 34th International Conference on MachineLearning
 Optimistic exploration evenwith a pessimistic initialisation,2020, In Proceedings of the 8th International Conference on LearningRepresentations
 Worst-case regret bounds for exploration via randomized value functions,2019, In Advancesin Neural Information Processing Systems 32
 A tutorial onthompson sampling,2018, Foundations and Trends in Machine Learning
 Incentivizing exploration in reinforcementlearning with deep predictive models,2015, arXiv
 Optimization for deep learning: theory and algorithms,2019, arXiv
 Truncated horizon policy search: Combiningreinforcement learning & imitation learning,2018, In Proceedings of the 6th International Conferenceon Learning Representations
 Reinforcement Learning: An Introduction,2018, MIT press
 dm_control: Software and tasks forcontinuous control,2020, Software Impacts
 Deep reinforcement learning with double q-learning,2016, In Proceedings of the 30th AAAI Conference on Artificial Intelligence
