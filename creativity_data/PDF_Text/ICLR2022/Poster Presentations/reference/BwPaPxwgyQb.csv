title,year,conference
 Learning to learn by gradient descent by gradientdescent,2016, In Advances in Neural Information Processing Systems
 How much data is sufficient to learn high-performing algorithms? generalization guar-antees for data-driven algorithm design,2021, In Proceedings of the 53rd Annual ACM SIGACT Sym-posium on Theory of Computing
 Rademacher and gaussian complexities: Risk bounds andstructural results,2002, Journal of Machine Learning Research
 Spectrally-normalized margin bounds forneural networks,2017, In Advances in Neural Information Processing Systems
 Compressive sensing and neural networksfrom a statistical learning perspective,2020, arXiv preprint arXiv:2010
 Learning to discoversparse graphical models,2017, In International Conference on Machine Learning
 Learning with differentiable perturbed optimizers,2020, arXiv preprint arXiv:2002
 Compressed sensing using genera-tive models,2017, In International Conference on Machine Learning
 Amp-inspired deep networks for sparselinear inverse problems,2017, IEEE Transactions on Signal Processing
 Convex optimization: Algorithms and complexity,2014, arXiv preprintarXiv:1405
 Decoding by linear programming,2005, IEEE transactions oninformation theory
 On generalization bounds of a family of recurrent neuralnetworks,2019, arXiv preprint arXiv:1910
 Learning to optimize: A primer and a benchmark,2021, arXiv preprint arXiv:2103
 Theoretical linear convergence of un-folded ista and its practical weights and thresholds,2018, In Advances in Neural Information ProcessingSystems
 Rna secondary structure predictionby learning unrolled algorithms,2020, arXiv preprint arXiv:2002
 Understanding deep architecture withreasoning layer,2020, Advances in Neural Information Processing Systems
 Learnedimage deblurring by unfolding a proximal interior point algorithm,2019, In 2019 IEEE InternationalConference on Image Processing (ICIP)
 An iterative thresholding algorithmfor linear inverse problems with a sparsity constraint,2004, Communications on Pure and AppliedMathematics: A Journal Issued by the Courant Institute of Mathematical Sciences
 Learning to learn arounda common mean,2018, Advances in Neural Information Processing Systems
 Variable selection via nonconcave penalized likelihood and its oracleproperties,2001, Journal of the American statistical Association
 Network exploration via the adaptive lasso and scadpenalties,2009, The annals of applied statistics
 A bridge betweenhyperparameter optimization and larning-to-learn,2017, stat
 Sparse inverse covariance estimation withthe graphical lasso,2008, Biostatistics
 Generalization and representational limits ofgraph neural networks,2020, arXiv preprint arXiv:2002
 Stochastic optimization of sortingnetworks via continuous relaxations,2019, arXiv preprint arXiv:1903
 Iterativethresholding algorithm for sparse inverse covariance estimation,2012, arXiv preprint arXiv:1211
 Learning-based low-rank approximations,2019, arXiv preprintarXiv:1910
 Generalization error boundsfor deep unfolding rnns,2021, In Proceedings of Machine Learning Research
 Learning optimal nonlinearities for iterative thresholdingalgorithms,2016, IEEE Signal Processing Letters
 Element-wise adaptive thresholds for learned iterative shrinkagethresholding algorithms,2020, IEEE Access
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Temporal dynamics and tran-scriptional control using single-cell gene expression analysis,2013, Genome biology
 ALISTA: Analytic weights are as goodas learned weights in LISTA,2019, In International Conference on Learning Representations
 On the conver-gence of learning-based iterative methods for nonconvex inverse problems,2019, IEEE transactions onpattern analysis and machine intelligence
 Regularized m-estimators with nonconvexity: Statistical andalgorithmic theory for local optima,2015, The Journal of Machine Learning Research
 Sparsemap: Differentiable sparsestructured inference,2018, In International Conference on Machine Learning
 Scikit-learn: Machine learning in Python,2011, Journal of Machine Learning Research
 Differ-entiation of blackbox combinatorial solvers,2019, In International Conference on Learning Represen-tations
 Understanding machine learning: From theory to algo-rithms,2014, Cambridge university press
 Model-based deep learn-ing,2020, arXiv preprint arXiv:2012
 GLAD: Learning sparse graph recovery,2020, In International Conference on LearningRepresentations
 Accurate telemonitoring ofparkinsonâ€™s disease progression by non-invasive speech tests,2009, Nature Precedings
 Guarantees for tuning the step size using alearning-to-learn approach,1098, In International Conference on Machine Learning
 Optimal computational and statistical rates of conver-gence for sparse nonconvex learning problems,2014, Annals of statistics
 Tuning-free plug-and-play proximal algorithm for inverse imaging problems,2020, In Interna-tional Conference on Machine Learning
 Sparse coding with gated learned ista,2020, InInternational Conference on Learning Representations
 Learning a compressed sensing measurement matrixvia gradient unrolling,2019, In International Conference on Machine Learning
 Differentiable lin-earized admm,2019, In International Conference on Machine Learning
 Nearly unbiased variable selection under minimax concave penalty,2010, The Annals ofstatistics
 Ista-net: Interpretable optimization-inspired deep network forimage compressive sensing,2018, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Analysis of multi-stage convex relaxation for sparse regularization,2010, Journal of MachineLearning Research
