title,year,conference
 Optimal control of Markov processes with incomplete state information,1965, Journal ofmathematical analysis and applications
 Quickest change detection approach to optimalcontrol in Markov decision processes with model changes,2017, In 2017 American Control Conference
 Switching linear dynamics forvariational Bayes filtering,2019, arXiv preprint arXiv:1905
 Carl: A benchmark for contextual and adaptive reinforcementlearning,2021, arXiv preprint arXiv:2110
 Pyro: Deep UniversalProbabilistic Programming,2018, Journal of Machine Learning Research
 Variational inference for Dirichlet process mixtures,2006, Bayesiananalysis
 Weight uncertainty inneural network,2015, In International Conference on Machine Learning
 Online multi-task learningfor policy gradient methods,2014, In Proceedings of the 31th International Conference on MachineLearning
 Truly nonparametric online variational inference for hierarchicalDirichlet processes,2012, Advances in Neural Information Processing Systems
 Optimizing for the future in non-stationary MDPs,2020, In International Conference onMachine Learning
 Hidden-mode Markov decision processes fornonstationary sequential decision making,2000, In Sequence Learning
 Deep reinforcementlearning in a handful of trials using probabilistic dynamics models,2018, Advances in Neural InformationProcessing Systems
 Dealing withnon-stationary environments using context detection,2006, In William W
 A continual learning survey: Defying forgetting in classificationtasks,2021, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Hidden parameter Markov decision processes:A semiparametric regression approach for discovering latent task parametrizations,2016, In SubbaraoKambhampati (ed
 RL2 : Fastreinforcement learning via slow reinforcement learning,2016, CoRR
 Implicit reparameterization gradients,2018, InAdvances in Neural Information Processing Systems
 Model-agnostic meta-learning for fast adaptation ofdeep networks,2017, In Doina Precup and Yee Whye Teh (eds
 Nonparametric bayesian learningof switching linear dynamical systems,2008, Advances in neural information processing systems
 Bayesian nonparametric inferenceof switching dynamic linear models,2011, IEEE Transactions on Signal Processing
 An HDP-HMM forsystems with state persistence,2008, In Machine Learning
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,1050, In international conference on machine learning
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In International conferenceon machine learning
 Sequential decision-making under non-stationary environments via sequential change-point detection,2014, In Learning over multiple contexts(LMCE)
 Contextual markov decision processes,2015, arXivpreprint arXiv:1502
 Generalization in reinforcement learning by soft data aug-mentation,2021, In 2021 IEEE International Conference on Robotics and Automation (ICRA)
 Deep recurrent Q-learning for partially observable MDPs,2015, InAAAI fall symposium series
 System design for uncertainty,2009, Mass
 Reliable and scalable variational inference for thehierarchical Dirichlet process,2015, In Artificial Intelligence and Statistics
 Pathwise derivatives beyond the reparameterization trick,2018, InProceedings of the 35th International Conference on Machine Learning
 Towards continual reinforcementlearning: A review and perspectives,2020, CoRR
 Attentive neural processes,2019, arXiv preprint arXiv:1901
 Variational dropout and the local reparameterizationtrick,2015, Advances in neural information processing systems
 Reinforcement learning in robotics: A survey,2013, TheInternational Journal of Robotics Research
 Image augmentation is all you need: Regularizingdeep reinforcement learning from pixels,2020, arXiv preprint arXiv:2004
 Bayesian policy optimization for model uncertainty,2019, In 7th International Conference onLearning Representations
 Context-aware policy reuse,2019, In EdithElkind
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Deep online learning via meta-learning: Con-tinual adaptation for model-based RL,2018, In International Conference on Learning Representations
 On Perron-Frobenius property of matrices having some negative entries,2006, LinearAlgebra and itsApplications
 Planning under uncertainty for robotictasks with mixed observability,2010, The International Journal of Robotics Research
 Reinforcement learning in non-stationary environments,2019, CoRR
 Mbrl-lib: A modular library for model-based reinforcement learning,2021, Arxiv
 Point-based value iteration forcontinuous pomdps,2006, Journal of Machine Learning Research
 Recurrent attentive neuralprocess for sequential data,2019, arXiv preprint arXiv:1910
 Efficient off-policymeta-reinforcement learning via probabilistic context variables,2019, In Proceedings of the 36thInternational Conference on Machine Learning
 A scalable laplace approximation for neuralnetworks,2018, In 6th International Conference on Learning Representations
 Experiencereplay for continual learning,2019, In Advances in Neural Information Processing Systems
 ProMP: Proximalmeta-policy search,2019, In 7th International Conference on Learning Representations
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 A constructive definition of Dirichlet priors,1994, Statistica sinica
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Pytorch implementation of soft-actor-critic,2018, https://github
 Deep reinforcement learning amidst lifelong non-stationarity,2020, arXiv preprint arXiv:2006
 Task-agnosticonline reinforcement learning with an infinite mixture of Gaussian processes,2020, Advances in NeuralInformation Processing Systems
 Invariant causal prediction for block MDPs,2020, In Proceedings of the 37thInternational Conference on Machine Learning
 On improving deep reinforcement learningfor POMDPs,2017, arXiv preprint arXiv:1704
