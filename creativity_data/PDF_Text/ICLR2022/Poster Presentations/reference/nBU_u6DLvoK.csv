title,year,conference
 Vivit: A video visiontransformer,2021, ArXiv
 Layer normalization,2016, ArXiv
 High-performance large-scaleimage recognition without normalization,2021, ArXiv
 Space-time mixing attention for video transformer,2021, ArXiv
 A shortnote about kinetics-600,2018, ArXiv
 On the relationship between self-attention and convolutional layers,2020, ArXiv
 Coatnet: Marrying convolution andattention for all data sizes,2021, ArXiv
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Cswin transformer: A general vision transformer backbone with cross-shaped win-dows,2021, ArXiv
 An image is worth 16x16 words: Transformers for image recognition at scale,2021, ArXiv
 Multiscale vision transformers,2021, ArXiv
 X3d: Expanding architectures for efficient video recognition,2020, 2020IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
 Slowfast networks for videorecognition,2019, 2019 IEEE/cVf International Conference on Computer Vision (ICCV)
 Container: Contextaggregation network,2021, ArXiv
 The “something something” videodatabase for learning and evaluating visual common sense,2017, 2017 IEEE International Conferenceon Computer Vision (ICCV)
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, ArXiv
 Stm: Spatiotemporal andmotion encoding for action recognition,2019, 2019 IEEE International Conference on Computer Vision(ICCV)
 All tokens matter: Token labeling for training better vision transformers,2021, arXiv preprintarXiv:2104
 Movinets: Mobile video networks for efficient video recognition,2021, ArXiv
 Motionsqueeze: Neural motion featurelearning for video understanding,2020, In ECCV
 Ct-net: Channel tensorizationnetwork for video classification,2021, ArXiv
 Smallbignet: Integrating core and contextual viewsfor video classification,2020, 2020 IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Vidtr: Video transformer without convolutions,2021, ArXiv
 Tea: Temporal excitationand aggregation for action recognition,2020, ArXiv
 Swintransformer: Hierarchical vision transformer using shifted windows,2021, ArXiv
 Teinet: Towards an efficient architecture for video recognition,2020, ArXiv
 Fixing weight decay regularization in adam,2017, ArXiv
 Sgdr: Stochastic gradient descent with warm restarts,2017, arXiv:Learning
 Grouped spatial-temporal aggregation for efficient action recogni-tion,2019, 2019 IEEE International Conference on Computer Vision (ICCV)
 Video transformer network,2021, ArXiv
 Keeping your eye on the ball: Trajectory attention invideo transformers,2021, ArXiv
 Learning spatio-temporal representation with pseudo-3dresidual networks,2017, 2017 IEEE International Conference on Computer Vision (ICCV)
 Learning spatio-temporal representationwith local and global diffusion,2019, 2019 IEEE/CVF Conference on Computer Vision and PatternRecognition (CVPR)
 Designingnetwork design spaces,2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition(CVPR)
 Stand-alone self-attention in vision models,2019, In NeurIPS
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2019, International Journal of Computer Vision
 Bottle-neck transformers for visual recognition,2021, ArXiv
 Efficientnet: Rethinking model scaling for convolutional neuralnetworks,2019, ArXiv
 Efficientnetv2: Smaller models and faster training,2021, ArXiv
 Goingdeeper with image transformers,2021, ArXiv
 Learningspatiotemporal features with 3d convolutional networks,2015, 2015 IEEE International Conference onComputer Vision (ICCV)
 A closerlook at spatiotemporal convolutions for action recognition,2018, 2018 IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Video classification with channel-separatedconvolutional networks,2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV)
 Attention is all you need,2017, ArXiv
 Temporal segmentnetworks: Towards good practices for deep action recognition,2016, In ECCV
 Tdn: Temporal difference networks for efficientaction recognition,2020, ArXiv
 Pyramid vision transformer: A versatile backbone for dense prediction withoutconvolutions,2021, ArXiv
 Non-local neural networks,2018, 2018IEEE/CVF Conference on Computer Vision and Pattern Recognition
 Cvt:Introducing convolutions to vision transformers,2021, ArXiv
 Tokens-to-token vit: Training vision transformers from scratch on imagenet,2021, ArXiv
 Shifted chunk transformer for spatio-temporal representational learning,2021, ArXiv
 Convnets vs,2021, transformers: Whose visualrepresentations are more transferable? ArXiv
