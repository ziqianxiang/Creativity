title,year,conference
 Threat of adversarial attacks on deep learning in computer vision:A survey,2018, Ieee Access
 Reveal of vision transformersrobustness against adversarial attacks,2021, arXiv preprint arXiv:2106
 Generating natural language adversarial examples,2018, arXiv preprint arXiv:1804
 Square attack:a query-efficient black-box adversarial attack via random search,2020, In European Conference onComputer Vision
 Towardtransformer-based object detection,2020, arXiv preprint arXiv:2012
 Estimating or propagating gradients throughstochastic neurons for conditional computation,2013, arXiv preprint arXiv:1308
 Understanding robustness of transformers for image classification,2021, arXiv preprintarXiv:2103
 End-to-end object detection with transformers,2020, In European Conference on ComputerVision
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 Emerging properties in self-supervised vision transformers,2021, arXiv preprintarXiv:2104
 Adversarial attacks and defences: A survey,2018, arXiv preprint arXiv:1810
 Robust overfittingmay be mitigated by properly learned smoothening,2021, In International Conference on LearningRepresentations
 An empirical study of training self-supervised visiontransformers,2021, arXiv preprint arXiv:2104
 Twins: Revisiting the design of spatial attention in vision transformers,2021, arXivpreprint arXiv:2104
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Sparse and imperceivable adversarial attacks,2019, In Proceedings ofthe IEEE/CVF International Conference on Computer Vision
 Reliable evaluation of adversarial robustness with an ensemble ofdiverse parameter-free attacks,2206, In International Conference on Machine Learning
 Multi-prize lottery ticket hypothesis: Finding accuratebinary neural networks by pruning a randomly weighted network,2021, arXiv preprint arXiv:2103
 Advertorch v0,2019, 1: An adversarial robustnesstoolbox based on pytorch
 Greedyfool: Distortion-aware sparse adversarial attack,2020, arXiv preprintarXiv:2010
 Cswin transformer: A general vision transformer backbone with cross-shapedwindows,2021, arXiv preprint arXiv:2107
 Animage is worth 16x16 words: Transformers for image recognition at scale,2020, arXiv preprintarXiv:2010
 Multiscale vision transformers,2021, arXiv preprint arXiv:2104
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 Drawingrobust scratch tickets: Subnetworks with inborn robustness are found within randomly initializednetworks,2021, Advances in Neural Information Processing Systems
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Levit: a vision transformer in convnet¡¯s clothing for faster inference,2021, arXivpreprint arXiv:2104
 Countering adversarialimages using input transformations,2017, arXiv preprint arXiv:1711
 Simpleblack-box adversarial attacks,2484, In International Conference on Machine Learning
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Dynamic adversarial patch forevading object detection models,2020, arXiv preprint arXiv:2010
 Black-box adversarial attacks withlimited queries and information,2137, In International Conference on Machine Learning
 Prior convictions: Black-box adversarialattacks with bandits and priors,2018, arXiv preprint arXiv:1807
 Is bert really robust? natural languageattack on text classification and entailment,2019, arXiv preprint arXiv:1907
 Rethinking the self-attention in vision transformers,2021, In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Efficient self-supervised vision transformers for representation learning,2021, arXivpreprint arXiv:2106
 Vidtr: Video transformer without convolutions,2021, arXiv preprint arXiv:2104
 Swinir:Image restoration using swin transformer,2021, arXiv preprint arXiv:2108
 Bias-baseduniversal adversarial patch attack for automatic check-out,2020, In European conference on computervision
 Dpatch: An adversarialpatch attack on object detectors,2018, arXiv preprint arXiv:1806
 Swin transformer: Hierarchical vision transformer using shifted windows,2021, arXiv preprintarXiv:2103
 Video swintransformer,2021, arXiv preprint arXiv:2106
 On the robustness of vision transformersto adversarial examples,2021, arXiv preprint arXiv:2104
 Rethinkingthe design principles of robust vision transformer,2021, arXiv preprint arXiv:2105
 On detecting adversarialperturbations,2017, arXiv preprint arXiv:1702
 Sparsefool: a few pixelsmake abig difference,2019, In Proceedings of the IEEE/CVF conference on computer vision and patternrecognition
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 The limitations of deep learning in adversarial settings,2016, In 2016 IEEE European symposiumon security and privacy (EuroS&P)
 Generating natural language adversarialexamples through probability weighted word saliency,2019, In Proceedings of the 57th annual meetingof the association for computational linguistics
 On the adversarial robustnessof visual transformers,2021, arXiv preprint arXiv:2103
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Deep inside convolutional networks:Visualising image classification models and saliency maps,2013, arXiv preprint arXiv:1312
 Segmenter: Transformer forsemantic segmentation,2021, arXiv preprint arXiv:2105
 Training data-efficient image transformers & distillation through attention,2021, In InternationalConference on Machine Learning
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 End-to-end video instance segmentation with transformers,2021, In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition
 Fast is better than free: Revisiting adversarial training,2019, InInternational Conference on Learning Representations
 Cvt:Introducing convolutions to vision transformers,2021, arXiv preprint arXiv:2103
 Earlyconvolutions help transformers see better,2021, arXiv preprint arXiv:2106
 Mitigating adversarial effectsthrough randomization,2017, arXiv preprint arXiv:1711
 Self-supervisedlearning with swin transformers,2021, arXiv preprint arXiv:2105
 Focal self-attention for local-global interactions in vision transformers,2021, arXiv preprintarXiv:2107
 Word-level textual adversarial attacking as combinatorial optimization,2019, arXiv preprintarXiv:1910
 Object hider: Adversarial patch attack againstobject detectors,2020, arXiv preprint arXiv:2010
 Rethinking semantic segmentation from asequence-to-sequence perspective with transformers,2021, In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition
