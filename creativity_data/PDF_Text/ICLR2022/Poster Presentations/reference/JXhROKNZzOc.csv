title,year,conference
 Post-training 4-bit quantization ofconvolution networks for rapid-deployment,2018, arXiv preprint arXiv:1810
 Zeroq:A novel zero shot quantization framework,2020, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Data-free network quantizationwith adversarial knowledge distillation,2020, In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition Workshops
 Low-bit quantization of neural networksfor efficient inference,2019, In ICCV Workshops
 Learning to prune deep neural networks vialayer-wise optimal brain surgeon,2017, arXiv preprint arXiv:1705
 Hawq-v2: Hessian aware trace-weighted quantization of neural networks,2019, arXivpreprint arXiv:1911
 Hawq: Hessianaware quantization of neural networks with mixed-precision,2019, In Proceedings of the IEEE/CVFInternational Conference on Computer Vision
 Switch transformers: Scaling to trillion parametermodels with simple and efficient sparsity,2021, arXiv preprint arXiv:2101
 Squeezenext: Hardware-aware neural network design,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition Workshops
 Sparten: A sparsetensor accelerator for convolutional neural networks,2019, In Proceedings of the 52nd Annual IEEE/ACMInternational Symposium on Microarchitecture
 How far does bert look at:Distance-based clustering and analysis of bert¡¯s attention,2020, In Proceedings of the 28th InternationalConference on Computational Linguistics
 Block-skim:Efficient question answering for transformer,2021, arXiv preprint arXiv:2112
 Accelerating sparse dnn models without hardware-supportvia tile-wise sparsity,2020, In Proceedings of the International Conference for High PerformanceComputing
 Balancing efficiency and flexibility for dnn acceleration via temporal gpu-systolicarray integration,2020, In 2020 57th ACM/IEEE Design Automation Conference (DAC)
 Deep learning withlimited numerical precision,1737, In International conference on machine learning
 Learning both weights and connections forefficient neural networks,2015, arXiv preprint arXiv:1506
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Improving posttraining neural quantization: Layer-wise calibration and integer programming,2020, arXiv preprintarXiv:2006
 Quantization and training of neural networks for efficientinteger-arithmetic-only inference,2018, In Proceedings of the IEEE conference on computer vision andpattern recognition
 Imagenet classification with deep con-volutional neural networks,2012, Advances in neural information processing systems
 Brecq: Pushing the limit of post-training quantization by block reconstruction,2021, arXiv preprintarXiv:2102
 Zero-shot adversarial quantization,2021, In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition
 Data-free quantizationthrough weight equalization and bias correction,2019, In Proceedings of the IEEE/CVF InternationalConference on Computer Vision
 Up ordown? adaptive rounding for post-training quantization,2020, In International Conference on MachineLearning
 Channel-wise hessian aware trace-weighted quantization ofneural networks,2020, arXiv preprint arXiv:2008
 Diverse sample generation: Pushing the limit of data-free quantization,2021, arXiv preprintarXiv:2109
 Adver-sarial defense through network profiling based path extraction,2019, In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition
 Q-bert: Hessian based ultra low precision quantization of bert,2020, In Proceedingsof the AAAI Conference on Artificial Intelligence
 Rethinkingthe inception architecture for computer vision,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Dual-side sparsetensor core,2021, In Proceedings of the 48th Annual International Symposium on Computer Architecture
 Learning channel-wise interactions forbinary convolutional neural networks,2019, In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition
 Dissecting hessian: Understandingcommon structure of hessian in neural networks,2020, arXiv preprint arXiv:2010
 Shufflenet: An extremely efficientconvolutional neural network for mobile devices,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Sparch: Efficient architecture for sparsematrix multiplication,2020, In 2020 IEEE International Symposium on High Performance ComputerArchitecture (HPCA)
 Improving neural networkquantization without retraining using outlier channel splitting,2019, In International conference onmachine learning
 Effective trainingof convolutional neural networks with low-bitwidth weights and activations,2021, IEEE Transactionson Pattern Analysis and Machine Intelligence
