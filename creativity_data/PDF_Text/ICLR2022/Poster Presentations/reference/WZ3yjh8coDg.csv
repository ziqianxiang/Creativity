title,year,conference
 Implicit regularization in deep matrixfactorization,2019, arXiv PrePrint arXiv:1905
 Language models arefew-shot learners,2020, arXiv PrePrint arXiv:2005
 ImPlicit bias of gradient descent for wide two-layer neural networkstrained with the logistic loss,2020, In CanferenCe on Learning Theory
 Deep learning for Classicaljapanese literature,2018, arXiv PrePrint arXiv:1812
 APProximate kkt Points and a Proximitymeasure for termination,2013, JOUrnaI of Global Optimization
 ExPloring deeP neural networks via layer-Peeled model:Minority collapse in imbalanced training,2021, Proceedings of the National Academy of Sciences (inpress)
 Escaping from saddle pointsâ€”online stochasticgradient for tensor decomposition,2015, In COnference on Iearning theory
 Matrix completion has no spurious local minimum,2016, arXivPrePrint arXiv:1605
 Implicit regularization of discrete gradientdynamics in linear neural networks,2019, arXiv PrePrint arXiv:1904
 Deep residual learning for imagerecognition,2016, In PrOCeedingS of the IEEE COnference on COmPUter ViSiOn and Pattern recognition
 Neural tangent kernel: convergence andgeneralization in neural networks,2018, In PrOCeedingS of the 32nd International COnference on NeuralInfOrmatiOn PrOCeSSing Systems
 Gradient descent follows theregularization path for general losses,2020, In COnferenCe on Learning Theory
 Learning multiple layers of features from tiny images,2009, 2009
 Imagenet classification with deep con-VolUtionalneUral networks,2012, AdVanceS in neural information processing systems
 A simple weight decay can improve generalization,1992, In AdVanceS inneural information processing systems
 Short-and-sparse deconvolution-a geometric approach,2019, arXiv PrePrint arXiv:1908
 Deep linear networks with arbitrary loss: All local minima areglobal,2018, In International conference on machine Iearning
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Deep learning,2015, nature
 Gradient descent onlyconverges to minimizers,2016, In ConferenCe on Iearning theory
 Algorithmic regularization in over-parameterizedmatrix sensing and neural networks with quadratic activations,2018, In ConferenCe On Learning Theory
 An exponential learning rate schedule for deep learning,2019, arXivPrePrint arXiv:1910
 Pde-net: Learning pdes from data,2018, InInternational ConferenCe on MaChine Learning
 Neural collapse with cross-entropy loss,2020, arXiv PrePrintarXiv:2012
 Neural collapse with unconstrained features,2020, arXivPrePrintarXiV:2011
 Lexicographicand depth-sensitive margins in homogeneous and non-homogeneous deep models,2019, In InternationalConference on MaChine Learning
 Convergence of gradient descent on separable data,2019, In The 22ndInternational ConferenCe on ArtifiCiaI Intelligence and StatiStics
 First-order methods almost always avoidsaddle points: The case of vanishing step-sizes,2019, arXiv PrePrint arXiv:1906
 Prevalence of neural collapse during the terminalphase of deep learning training,2020, ProCeedingS of the NationaI ACademy of Sciences
 Explicit regularization and implicit bias in deep network classifierstrained with the square loss,2020, arXiv PrePrint arXiv:2101
 Analysis of the optimizationlandscapes for overcomplete representation learning,2019, arXiv PrePrint arXiv:1912
 Implicit regularization in deep learning may not be explainable bynorms,2020, arXiv PrePrint arXiv:2005
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv Preprint arXiv:1409
 The implicitbias of gradient descent on separable data,2018, The JoUrnaI of Machine Learning ReSearch
 Complete dictionary recovery over the sphere i: Overview andthe geometric picture,2016, IEEE TranSaCtiOnS on InfOrmatiOn Theory
 A geometric analysis of phase retrieval,2018, FOUndatiOnS ofCOmpUtatiOnal Mathematics
 Characterization of the subdifferential of some matrix norms,1992, Linear algebra andits applications
 On the margin theory of feedforward neuralnetworks,2018, 2018
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
 From symmetry to geometry: Tractable nonconvexproblems,2020, arXiv preprint arXiv:2007
 A geo-metric analysis of neural collapse with unconstrained features,2021, arXiv preprint arXiv:2105
