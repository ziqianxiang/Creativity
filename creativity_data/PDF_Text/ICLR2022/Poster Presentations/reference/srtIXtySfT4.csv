title,year,conference
 Neural relational inferencewith fast modular meta-learning,2019, In Advances in Neural Information Processing Systems (NeurIPS)
 Bottom-up and top-down attention for image captioning and visual question answering,2018, InThe IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 LCNN: Lookup-based convolu-tional neural network,2017, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Teacher guided architecture search,2019, In TheIEEE International Conference on Computer Vision (ICCV)
 Language featuresmatter: Effective language representations for vision-language tasks,2019, In The IEEE InternationalConference on Computer Vision (ICCV)
 Training deep nets with sublinearmemory cost,2016, arXiv:1604
 Learning phrase representations using RNN encoder-decoder forstatistical machine translation,2014, In Proceedings of the 2014 Conference on Empirical Methods inNatural Language Processing (EMNLP)
 ImageNet: A large-scalehierarchical image database,2009, In The IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Predictingparameters in deep learning,2013, In Advances in Neural Information Processing Systems (NeurIPS)
 Learning modularneural network policies for multi-task and multi-robot transfer,2017, In International Conference onRobotics and Automation
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies (NAACL)
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv:1708
 Modular meta-learning,2018, In Conference onRobot Learning (CoRL)
 The reversible residual network:Backpropagation without storing activations,2017, In Advances in Neural Information ProcessingSystems (NeurIPS)
 Knowledge distillation: Asurvey,2021, International Journal of Computer Vision
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Acomprehensive overhaul of feature distillation,2019, In The IEEE International Conference on ComputerVision (ICCV)
 Sparsity in deeplearning: Pruning and growth for efficient inference and training in neural networks,2021, Journal ofMachine Learning Research
 Densely connectedconvolutional networks,2017, In The IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Checkmate: Breaking the memory wall with optimal tensorrematerialization,2020, In Proceedings of the Third Conference on Machine Learning and Systems(MLSys)
 ReferItGame: Referring toobjects in photographs of natural scenes,2014, In Empirical Methods in Natural Language Processing(EMNLP)
 Federated learning: Strategies for improving communication efficiency,2016, In NeurIPSWorkshop on Private Multi-Party Machine Learning
 Learning multiple layers of features from tiny images,2009, Technical report
 HRank: Filter pruning using high-rank feature map,2020, In The IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Microsoft COCO: Common objects in context,2014, In The EuropeanConference on Computer Vision (ECCV)
 Communication-efficient learning of deep networks from decentralized data,2017, In ArtificialIntelligence and Statistics
 Stable low-rank tensordecomposition for compression of convolutional neural network,2020, In The European Conference onComputer Vision (ECCV)
 Flickr30K entities: Collecting region-to-phrase correspondences for richerimage-to-sentence models,2017, International Journal of Computer Vision
 Revisiting image-language networks for open-ended phrase detection,2020, IEEE Transactionson Pattern Analysis and Machine Intelligence (TPAMI)
 ZeRO-Infinity:Breaking the GPU memory wall for extreme scale deep learning,2021, In International Conference forHigh Performance Computing
 Know what you don¡¯t know: Unanswerable questionsfor SQuAD,2018, In Proceedings of the 56th Annual Meeting of the Association for ComputationalLinguistics (Volume 2: Short Papers) (ACL)
 ZeRO-Offload: Democratizing billion-scale model training,2021, InUSENIX Annual Technical Conference
 Faster r-cnn: Towards real-time objectdetection with region proposal networks,2015, In Advances in Neural Information Processing Systems(NeurIPS)
 SparCML:High-performance sparse communication for machine learning,2019, In Proceedings of the InternationalConference for High Performance Computing
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, InInternational Conference on Learning Representations (ICLR)
 Efficientnet: Rethinking model scaling for convolutional neuralnetworks,2019, In International Conference on Machine Learning (ICML)
 MnasNet: Platform-aware neural architecture search for mobile,2019, In The IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Benefits of depth in neural networks,2016, In Conference on Learning Theory (COLT)
 Attention is all you need,2017, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Learning deep structure-preserving image-text embed-dings,2016, In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Learning two-branch neural networksfor image-text matching tasks,2018, IEEE Transactions on Pattern Analysis and Machine Intelligence(TPAMI)
 Adaptive cross-modal embeddings forimage-text alignment,2020, In AAAI Conference on Artificial Intelligence (AAAI)
 Knowledge distillation viasoftmax regression representation learning,2021, In International Conference on Learning Representa-tions (ICLR)
 Network deconvolution,2020, In International Conference onLearning Representations (ICLR)
 From image descriptions to visualdenotations: New similarity metrics for semantic inference over event descriptions,2014, Transactionsof the Association for Computational Linguistics (TACL)
 Wide residual networks,2016, In British Machine VisionConference (BMVC)
 Neural architecture search with reinforcement learning,2017, In InternationalConference on Learning Representations (ICLR)
 Success is achieved if the predicted box has at least 0,2014,5 intersection over union withthe ground truth box
