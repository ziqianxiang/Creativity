title,year,conference
 Synthesizing robust adversarialexamples,2018, In International Conference on Machine Learning
 Poisoning attacks against support vector ma-chines,2012, In International Conference on Machine Learning
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Extracting training datafrom large language models,2020, arXiv preprint arXiv:2012
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Robust physical-world attacks on machine learning models,2017, arXivpreprint arXiv:1707
 Robust physical-world attacks on deep learningvisual classification,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Preventing unauthorized use of proprietary data: Poisoning for secure datasetrelease,2021, arXiv preprint arXiv:2103
 Adversarial examples make strong poisons,2021, In Advances in Neural Information ProcessingSystems
 Witches¡¯ brew: Industrial scale data poisoning via gradient matching,2021, InInternational Conference on Learning Representations
 Generative adversarial nets,2014, In Advances in Neural Infor-mation Processing Systems
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 BadNets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint arXiv:1708
 Recent advances in deep learning theory,2020, arXiv preprintarXiv:2012
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Unlearn-able examples: Making personal data unexploitable,2021, In International Conference on LearningRepresentations
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, Advances in Neural Information Processing Systems
 Ma-nipulating machine learning: Poisoning attacks and countermeasures for regression learning,2018, In2018 IEEE Symposium on Security and Privacy (SP)
 Learning to defend by learningto attack,2021, In Proceedings of The 24th International Conference on Artificial Intelligence andStatistics
 Understanding black-box predictions via influence functions,2017, InInternational Conference on Machine Learning
 Neural attentiondistillation: Erasing backdoor triggers from deep neural networks,2021, In International Conferenceon Learning Representations
 Microsoft COCO: Common objects in context,2014, In EuropeanConference on Computer Vision
 Bias-baseduniversal adversarial patch attack for automatic check-out,2020, In Proceedings of the European Con-ference on Computer Vision
 No need to worry about adversarialexamples in object detection in autonomous vehicles,2017, arXiv preprint arXiv:1707
 Foveation-based mechanismsalleviate adversarial examples,2015, arXiv preprint arXiv:1511
 Readingdigits in natural images with unsupervised feature learning,2011,2011
 Input-aware dynamic backdoor attack,2020, In Advances in NeuralInformation Processing Systems
 Wanet - Imperceptible warping-based backdoor attack,2021, InInternational Conference on Learning Representations
 Imagenet large scale visualrecognition challenge,2015, International Journal of Computer Vision
 Poison frogs! Targeted clean-label poisoning attacks on neural networks,2018, InAdvances in Neural Information Processing Systems
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Second-order provable defenses against adversarial attacks,2020, In Inter-national Conference on Machine Learning
 Robust local featuresfor improving the generalization of adversarial training,2020, In International Conference on LearningRepresentations
 Certified defenses for data poisoning attacks,2017, InAdvances in Neural Information Processing Systems
 Confidence-calibrated adversarial training: Gen-eralizing to unseen attacks,9155, In International Conference on Machine Learning
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 RobustART: Benchmark-ing robustness on architecture design and training techniques,2021, arXiv preprint arXiv:2109
 Better safe than sorry: Pre-venting delusive adversaries with adversarial training,2021, In Advances in Neural Information Pro-cessing Systems
 80 million tiny images: A large data set fornonparametric object and scene recognition,2008, IEEE Transactions on Pattern Analysis and MachineIntelligence
 Tag disentangled generative ad-versarial network for object image re-rendering,2017, In Proceedings of the 26th International JointConference on Artificial Intelligence (IJCAI)
 Evolutionary generative adversar-ial networks,2019, IEEE Transactions on Evolutionary Computation
 On the trade-off between ad-versarial and backdoor robustness,2020, In Advances in Neural Information Processing Systems
 Attacking adversarial attacks as a defense,2021, arXiv preprint arXiv:2106
 Stronger and faster Wasserstein adversarial attacks,2020, InInternational Conference on Machine Learning
 Defending against physically realizable attackson image classification,2020, In International Conference on Learning Representations
 Generative poisoning attack method against neuralnetworks,2017, arXiv preprint arXiv:1703
 Neural tangent generalization attacks,2021, In International Con-ference on Machine Learning
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Attacks which do not kill training make adversarial learning stronger,2020, In InternationalConference on Machine Learning
 Interpreting adversarially trained convolutional neural net-works,2019, In International Conference on Machine Learning
