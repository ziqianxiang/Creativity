title,year,conference
 Towards characterizing divergence in deep q-learning,2019, arXiv preprint arXiv:1903
 On exact computation with an infinitelywide neural net,2019, arXiv preprint arXiv
 Residual algorithms: Reinforcement learning with function approximation,1995, InMachine Learning Proceedings 1995
 Reconciling modern machinelearning practice and the bias-Variance trade-off,2018, undefined
 A counterexample to temporal differences learning,1530, Neural Comput
 Spectral bias and task-model alignmentexplain generalization in kernel regression and infinitely wide neural networks,2041, Nat
 Towards understanding thespectral bias of deep learning,2019, December 2019
 Neural Inf,1049, Process
 Iteratively extending time horizon reinforcementlearning,2003, In Machine Learning: ECML 2003
 Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprintarXiv:1801
 Double q-learning,2010, volume 23
 On the convergence of stochastic iterativedynamic programming algorithms,1994, Neural computation
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, arXiv preprint arXiv:1806
 Value function approximation in reinforce-ment learning using the fourier basis,2011, In Twenty-fifth AAAI conference on artificial intelligence
 Implicit under-parameterizationinhibits data-efficient deep reinforcement learning,2021, International Conference on Learning Repre-sentations
 Deep neural networks as gaussian processes,2017, arXiv preprint arXiv:1711
 Sunrise: A simple unified framework forensemble learning in deep reinforcement learning,2021, In ICML
 Functional regularization for reinforcement learning via learnedfourier features,1049, Adv
 Enhanced convolutional neural tangent kernels,2019, November 2019
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Nerf: Representing scenes as neural radiance fields for view synthesis,2020, In Europeanconference on computer vision
 Steps toward artificial intelligence,1961, Proc
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Self-distillation amplifies regularizationin hilbert space,2020, Advances in Neural Information Processing Systems
 Efficient memory-based learning for robot control,1990,1990
 Deepdouble descent: Where bigger models and more data hurt,2019, December 2019
 On the spectral bias of neural networks,2019, pp
 Weighted sums of random kitchen sinks: Replacing minimizationwith randomization in learning,1049, Adv
 Neural fitted q iteration-first experiences with a data efficient neural reinforce-ment learning method,2005, In European conference on machine learning
 Neural fitted q iteration - first experiences with a data efficient neural rein-forcement learning method,2005, In Joao Gama
 The convergence rate of neural net-works for learned functions of different frequencies,2019, In H Wallach
 Thepitfalls of simplicity bias in neural networks,2020, arXiv preprint arXiv:2006
 D2rl: Deep densearchitectures in reinforcement learning,2020, arXiv preprint arXiv:2010
 Im-plicit neural representations with periodic activation functions,2020, Advances in Neural InformationProcessing Systems
 Learning to predict by the methods of temporal differences,1573, Mach
 Reinforcement Learning: An Introduction,9780, MIT Press
 Fourier features let net-works learn high frequency functions in low dimensional domains,2020, NeurIPS
 Practical issues in temporal difference learning,1049, Adv
 Asynchronous stochastic approximation and q-learning,1573, Mach
 Learning from delayed rewards,1989,1989
 Tensor programs i: Wide feedforward or recurrent neural networks of any architecture aregaussian processes,2019, October 2019
 Tensor programs ii: Neural tangent kernel for any architecture,2020, June 2020
 A fine-grained spectral perspective on neural networks,2019, arXiv preprintarXiv:1907
 A la carte-learning fast kernels,2015, In ArtificialIntelligence and Statistics
 Mastering visual continuous control:Improved data-augmented reinforcement learning,2021, arXiv preprint arXiv:2107
