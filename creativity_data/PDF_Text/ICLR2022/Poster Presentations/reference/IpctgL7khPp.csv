title,year,conference
 Task-free continual learning,2019, In Pro-Ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
 Gradient based sample selection foronline continual learning,2019, Advances in Neural Information Processing Systems
 Rainbow mem-ory: Continual learning with a memory of diverse samples,2021, In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition
 Curriculum learning,2009, InProceedings of the 26th annual international conference on machine learning
 Coresets via bilevel optimization for continuallearning and streaming,2020, Advances in Neural Information Processing Systems
 Online submodular maximization with pre-emption,2014, In Proceedings of the twenty-sixth annual ACM-SIAM symposium on Discrete algo-rithms
 Streaming Sparse Gaussian Process Approx-imations,2017, In I
 A general purpose unequal probability sampling plan,1982, Biometrika
 Efficientlifelong learning with a-GEM,2019, In International Conference on Learning Representations
 On tiny episodic memories in continuallearning,2019, arXiv preprint arXiv:1902
 Elements of information theory,1999, John Wiley & Sons
 Sparse online Gaussian processes,2002, Neural Computation
 A continual learning survey: Defying forgetting in classificationtasks,2021, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Lossy compressionfor lossless prediction,2021, arXiv preprint arXiv:2106
 Weighted random sampling with a reservoir,2006, InformationProcessing Letters
 An empiri-cal investigation of catastrophic forgetting in gradient-based neural networks,2013, arXiv preprintarXiv:1312
 Selective experience replay for lifelong learning,2018, In Proceedingsof the AAAI Conference on Artificial Intelligence
 Imbalanced continual learning with partition-ing reservoir sampling,2020, In European Conference on Computer Vision
 Overcom-ing catastrophic forgetting in neural networks,2017, Proceedings of the National Academy of Sciences
 Imagenet classification with deep con-volutional neural networks,2012, Advances in neural information processing systems
 A practical online framework forextracting running video summaries under a fixed memory budget,2021, In Proceedings of the 2021SIAM International Conference on Data Mining (SDM)
 Information-based objective functions for active data selection,1992, Neural compu-tation
 Human-levelcontrol through deep reinforcement learning,2015, nature
 The application of bayesian methods forseeking the extremum,1978, Towards global optimization
 Dataset distillation with infinitelywide convolutional networks,2021, arXiv preprint arXiv:2107
 Continual deep learning by functional regularisation of memorablepast,2020, In Advances in Neural Information Processing Systems
 icarl:Incremental classifier and representation learning,2017, In Proceedings of the IEEE conference onComputer Vision and Pattern Recognition
 Experiencereplay for continual learning,2019, In Proceedings of the 33rd International Conference on NeuralInformation Processing Systems
 Trust regionpolicy optimization,2015, In Proceedings of the 32nd International Conference on Machine Learning
 Fast forward selection to speed up sparseGaussian process regression,2003, In Ninth International Workshop on Artificial Intelligence
 Adjustment of an inverse matrix corresponding to a changein one element of a given matrix,1950, The Annals of Mathematical Statistics
 Functional regularisation for continual learning with gaussian processes,2020, InInternational Conference on Learning Representations
 Random sampling with a reservoir,1985, ACM Transactions on Mathematical Software(TOMS)
 Entropy-based sample selection for online continual learning,2021, In 202028th European Signal Processing Conference (EUSIPCO) 
 Online coreset selection forrehearsal-based continual learning,2021, arXiv preprint arXiv:2106
 Dataset condensation with gradient matching,2020, InInternational Conference on Learning Representations
