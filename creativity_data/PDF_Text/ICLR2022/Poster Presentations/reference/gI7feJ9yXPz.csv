title,year,conference
 Stochastic variance reduction methods for saddle-pointproblems,2016, In Advances in Neural Information Processing Systems
 The mechanics of n-player differentiable games,2018, In International Conference on Ma-chine Learning
 Local rademacher complexities,2005, AnnalsOfStatistics
 Stability of stochastic gradientdescent on nonsmooth convex losses,2020, In Advances in Neural Information Processing Systems
 Concentration inequalities: A nonaSymp-totic theory of independence,2013, Oxford university press
 Stability and generalization,2002, Journal of Machine LearningResearch
 SharPer bounds for uniformly stablealgorithms,2020, In Conference On Learning Theory
 PAC-BAYESIAN SUPERVISED CLASSIFICATION: The Thermodynamics of Statis-tical Learning,2007,2007
 Stability and generalization of learning algorithmsthat converge to global oPtima,2018, In International Conference on Machine Learning
 Robust oPtimization fornon-convex objectives,2017, In Advances in Neural Information Processing Systems
 Stability and convergence trade-off of iterative oPtimizationalgorithms,2018, arXiv preprint arXiv:1804
 Proximal gradient descent-ascent: Variableconvergence under klgeometry,2021, In International Conference on Learning Representations
 Saddle-Point dynamics: conditions forasymPtotic stability of saddle Points,2017, Siam Journal on Control and Optimization
 Sbeed:Convergent reinforcement learning with nonlinear function aPProximation,2018, In International Con-ference on Machine Learning
 Training gans withoptimism,2017, In International Conference on Learning Representations
 Toward better generalization bounds with locally elasticstability,2021, In International Conference on Machine Learning
 Efficient methods for struc-tured nonconvex-nonconcave min-max optimization,2021, In International Conference on ArtificialIntelligence and Statistics
 Stochastic variance reduc-tion methods for policy evaluation,2017, In International Conference on Machine Learning
 Generalization bounds for uniformly stable algorithms,2018, In Ad-vances in Neural Information Processing Systems
 High probability generalization bounds for uniformly stable algo-rithms with nearly optimal rate,2019, In Conference on Learning Theory
 Local convergence analysis of gradient descent ascent with finitetimescale separation,2021, In International Conference on Learning Representations
 Hypothesis set stability and generalization,2019, In Advances in Neural Information ProcessingSystems
 Generative adversarial nets,2014, In Advances in Neural Infor-mation Processing Systems
 An onlinelearning approach to generative adversarial networks,2017, In International Conference on LearningRepresentations
 On the convergenceof single-call stochastic extra-gradient methods,2019, In Advances in Neural Information ProcessingSystems
 Linear convergence of gradient and proximal-gradient methods under the POlyak-IOjaSieWiCz condition,2016, In Joint European Conference on Ma-chine Learning and Knowledge Discovery in Databases
 An accelerated inexact proximal point method for solvingnonconvex-concave min-max problems,2019, arXiv preprint arXiv:1905
 The extragradient method for finding saddle points and other problems,1976, Mate-con
 Data-dependent stability of stochastic gradient descent,2018, InInternational Conference on Machine Learning
 Fine-grained analysis of stability and generalization for stochasticgradient descent,2020, In International Conference on Machine Learning
 Sharper generalization bounds for learning with gradient-dominatedobjective functions,2021, In International Conference on Learning Representations
 Stochastic proximal auc maximization,2021, Journal of Machine LearningResearch
 Sharper generalization bounds for pairwise learn-ing,2020, In Advances in Neural Information Processing Systems
 Stability and generalization ofstochastic gradient methods for minimax problems,2021, In International Conference on MachineLearning
 Tighter pac-bayes bounds throughdistribution-dependent priors,2013, Theoretical Computer Science
 Multi-class learning:From theory to algorithm,2018, In Advances in Neural Information Processing Systems
 On generalization error bounds of noisy gradient methodsfor non-convex learning,2020, In International Conference on Learning Representations
 Sharper generalization bounds for clustering,2021, In International Conferenceon Machine Learning
 Towards sharper generalization bounds for structured prediction,2021, InAdvances in Neural Information Processing Systems
 Interaction matters: A note on non-asymptotic local convergenceof generative adversarial networks,2019, In International Conference on Artificial Intelligence andStatistics
 Solving weakly-convex-weakly-concave saddle-point problems as weakly-monotone variational inequality,2018,2018
 On gradient descent ascent for nonconvex-concave mini-max problems,2020, In International Conference on Machine Learning
 Near-optimal algorithms for minimax optimization,2020, InConference on Learning Theory
 Algorithmic stability and hypothesiscomplexity,2017, In International Conference on Machine Learning
 Fast cross-validation for kernel-based algorithms,2020, IEEE Transactions on Pattern Analysis and MachineIntelligence
 Effective distributed learning with random features:Improved bounds and algorithms,2021, In International Conference on Learning Representations
 Stochastic hamiltonian gradient methods for smooth games,2020, In Interna-tional Conference on Machine Learning
 Hybrid block successive ap-proximation for one-sided non-convex min-max problems: Algorithms and applications,2020, IEEETransactions on Signal Processing
 Stochastic recursive gradient descentascent for stochastic nonconvex-strongly-concave minimax problems,2020, In Advances in NeuralInformation Processing Systems
 Improved learning rates of a functional lasso-type svm with sparse multi-kernel representation,2021, In Advances in Neural Information ProcessingSystems
 Distributed sparse linear re-gression,2010, IEEE Transactions on Signal Processing
 A unified analysis of extra-gradient andoptimistic gradient methods for saddle point problems: Proximal point approach,2020, In InternationalConference on Artificial Intelligence and Statistics
 Stochastic gradient methods for distributionally robustoptimization with f-divergences,2016, In Advances in Neural Information Processing Systems
 Variance-based regularization with convex objectives,2017, InAdvances in Neural Information Processing Systems
 Subgradient methods for saddle-point problems,2009, Journalof Optimization Theory and Applications
 Robust stochastic approximation approach tostochastic programming,2008, Siam Journal on Optimization
 Solvinga class of non-convex min-max games using iterative first order methods,2019, In Advances in NeuralInformation Processing Systems
 A modification of the arrow-hurwicz method for search of saddle points,1980, MathematicalNotes
 Non-convex min-max optimization:Provable algorithms and applications in machine learning,2018, arXiv: Optimization and Control
 Monotone operators and the proximal point algorithm,1976, Siam Journal onControl and Optimization
 On the convergence and ro-bustness of training gans with regularized optimal transport,2018, In Advances in Neural InformationProcessing Systems
 Understanding machine learning: From theory to algo-rithms,2014, Cambridge university press
 Cooperative Control of Distributed Multi-Agent Systems,2008,2008
 Certifying some distributional robustnesswith principled adversarial training,2017, In International Conference on Learning Representations
 Optimistic rates for learning with a smoothloss,2010, arXiv preprint arXiv:1009
 Online learning as stochastic approximation of regularization paths:Optimality and almost-sure convergence,2014, IEEE Transactions on Information Theory
 Efficient algo-rithms for smooth minimax optimization,2019, In Advances in Neural Information Processing Systems
 Improved algorithms for convex-concave minimax optimization,2020, InAdvances in Neural Information Processing Systems
 On solving minimax optimization locally: Afollow-the-ridge approach,2020, In International Conference on Learning Representations
 Optimal epoch stochastic gradient de-scent ascent methods for min-max optimization,2020, In Advances in Neural Information ProcessingSystems
 Global convergence and variance reduction for a classof nonconvex-nonconcave minimax problems,2020, In Advances in Neural Information ProcessingSystems
 Sketch kernel ridge regression using circulantmatrix: Algorithm and theory,2020, IEEE Transactions on Neural Networks
 Generalization bounds forstochastic saddle point problems,2021, In International Conference on Artificial Intelligence and Statis-tics
 Sta-bility of sgd: Tightness analysis and improved bounds,2021, arXiv preprint arXiv:2102
