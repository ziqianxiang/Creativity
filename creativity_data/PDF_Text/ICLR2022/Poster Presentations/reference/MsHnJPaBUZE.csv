title,year,conference
 The unfairness ofpopularity bias in recommendation,2019, In the RMSE workshop held in conjunction with the 13th ACMConference on Recommender Systems
 Learning from noisy examples,1988, Machine Learning
 A closer look atmemorization in deep netWorks,2017, In International Conference on Machine Learning
 Reconciling modern machine-learningpractice and the classical bias-variance trade-off,2019, Proceedings of the National Academy of Sciences
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Sharpness-aWare minimizationfor efficiently improving generalization,2021, In International Conference on Learning Representations
 Comparing biases for minimal network construction withback-propagation,1989, In Advances in neural information processing systems
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Adam: A method for stochastic optimization,2015, In Proceedings ofthe International Conference on Learning Representations
 Analyzing and reducing the damage of dataset bias to face recognition withsynthetic data,2019, In Proceedings of the IEEE Conference on Computer Vision and Pattern RecognitionWorkshops
 Imagenet classification with deep convo-Iutional neural networks,2012, Advances in neural information processing Systems
 Generalized entropy regularization or: Thereâ€™snothing special about label smoothing,2020, In Proceedings of the 58th Annual Meeting of the Associa-tion for Computational Linguistics
 Foundations of machine learning,2018, MITpress
 Readingdigits in natural images with unsupervised feature learning,2011, NIPS Workshop on Deep Learningand Unsupervised Feature Learning
 Regularizingneural networks by penalizing confident output distributions,2017, In 5th International Conference onLearning Representations
 Imagenet large scale visual recognitionchallenge,2015, International journal of computer vision
 Very deep convolutional networks for large-scale imagerecognition,2015, In Proceedings of the International Conference on Learning Representations
 Rethinkingthe inception architecture for computer vision,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Combating label noise in deep learning using abstention,2019, In Proceedings of the 36thInternational Conference on Machine Learning
 Glue:A multi-task benchmark and analysis platform for natural language understanding,2019, In Proceedingsof the International Conference on Learning Representations
 High-frequency component helps explainthe generalization of convolutional neural networks,2020, In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition
 Transformers: State-of-the-art naturallanguage processing,2020, In Proceedings of the 2020 Conference on Empirical Methods in NaturalLanguage Processing: System Demonstrations
 Aggregated residualtransformations for deep neural networks,2017, In Proceedings of the IEEE conference on computervision and pattern recognition
 Gradaug: A neW regularization method for deep neuralnetWorks,2020, In H
 Understandingdeep learning requires rethinking generalization,2017, In Proceedings of the International Conferenceon Learning Representations
 mixup: Beyond empiricalrisk minimization,2017, In Proceedings of the International Conference on Learning Representations
 Regularizing neural netWorks via adversarialmodel perturbation,2021, In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition
