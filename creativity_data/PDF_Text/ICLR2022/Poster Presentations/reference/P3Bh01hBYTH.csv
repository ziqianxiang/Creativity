title,year,conference
 Manifold regularization: A geometric frame-work for learning from labeled and unlabeled examples,2006, JMLR
 Mixmatch: A holistic approach to semi-supervised learning,2019, NeurIPS
 Remixmatch: Semi-supervised learning with distribution alignment and augmentationanchoring,2020, ICLR
 Combining labeled and unlabeled data with co-training,1998, In COLT
 A Simple Framework forContrastive Learning of Visual Representations,2020, arXiv preprint arXiv:2002
 Bigself-supervised models are strong semi-supervised learners,2020, NeurIPS
 On transductive regression,2007, In NeurIPS
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In ICML
 Unsupervised domain adaptation by backpropagation,2015, InICML
 On the transfer of inductive biasfrom simulation to the real world: anew disentanglement dataset,2019, In NeurIPS
 Semi-supervised learning by entropy minimization,2005, In NeurIPS
 Dimensionality reduction by learning an invariant mapping,2006, InCVPR
 Deep residual learning for imagerecognition,2016, In cVpR
 Momentum contrast forunsupervised visual representation learning,2020, In CVPR
 beta-vae: Learning basic visual concepts with aconstrained variational framework,2017, In ICLR
 Learning multiple layers of features from tiny images,2009, Technical report
 Temporal ensembling for semi-supervised learning,2017, In ICLR
 Pseudo-label: The simple and efficient semi-supervised learning method for deepneural networks,2013, In ICML Workshop on Challenges in Representation Learning
 Drop to adapt: Learningdiscriminative features for unsupervised domain adaptation,2019, In ICCV
 Self-training for multi-targetregression with tree ensembles,2017, Know
 Learning transferable features with deep adaptationnetworks,2015, In ICML
 Deep transfer learning with jointadaptation networks,2017, In ICML
 Visualizing data using t-sne,2008, JMLR
 Distributionalsmoothing with virtual adversarial training,2016, In ICLR
 Scikit-learn: Machine learning in Python,2011, JMLR
 Meta pseudo labels,2021, CVPR
 Deep co-training forsemi-supervised image recognition,2018, ECCV
 Data distillation:Towards omni-supervised learning,2017, CVPR
 Deep expectation of real and apparent age from a singleimage without facial landmarks,2016, In IJCV
 Adversarial dropout regulariza-tion,2018, In ICLR
 Maximum classifierdiscrepancy for unsupervised domain adaptation,2018, In CVPR
 Semi-superviseddomain adaptation via minimax entropy,2019, In ICCV
 Regularization with stochastic transforma-tions and perturbations for deep semi-supervised learning,2016, In NeurIPS
 Fixmatch: Simplifying semi-supervised learning withconsistency and confidence,2020, NeurIPS
 Semi-supervised gaussian processordinal regression,2013, In CoRR
 Mean teachers are better role models: Weight-averaged consistencytargets improve semi-supervised deep learning results,2017, In NeurIPS
 Contrastive multiview coding,2019, arXiv preprintarXiv:1906
 Self-tuning for data-efficient deeplearning,2021, In ICML
 Theoretical analysis of self-training withdeep networks on unlabeled data,2021, In ICLR
 Unsupervised feature learning vianon-parametric instance discrimination,2018, In CVPR
 Unsupervised dataaugmentation for consistency training,2020, NeurIPS
 Delving into deepimbalanced regression,2021, In ICML
 Bridging theory and algorithm fordomain adaptation,2019, In ICML
 Hand-3d-studio: A new multi-viewsystem for 3d hand reconstruction,2020, In ICASSP
 Tri-training: Exploiting unlabeled data using three classifiers,2005, TKDE
 Semi-supervised regression with co-training,2005, In IJCAI
