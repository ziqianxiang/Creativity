title,year,conference
 Adversarial robustness on in-and out-distribution improves explainability,2020, arXiv preprint arXiv:2003
 Relating developments in children¡¯scounterfactual thinking and executive functions,2009, Thinking & reasoning
 Began: Boundary equilibrium generativeadversarial networks,2017, arXiv preprint arXiv:1703
 Understanding disentangling in beta-VAE,2017, Advances inneural information processing systems: Workshop on Learning Disentangled Representations
 Human-centered toolsfor coping with imperfect algorithms during medical decision-making,2019, In Proceedings of the2019 CHI Conference on Human Factors in Computing Systems
 Explaining neural networkssemantically and quantitatively,2019, In Proceedings of the IEEE/CVF International Conference onComputer Vision
 Isolating sources ofdisentanglement in variational autoencoders,2016, In Advances in neural information processingsystems
 Assessing andaddressing algorithmic bias in practice,2018, Interactions
 Explanations based on the missing: Towards contrastive explanationswith pertinent negatives,2018, In Advances in neural information processing systems
 Towards a rigorous science of interpretable machine learn-ing,2017, arXiv preprint arXiv:1702
 Cruds:Counterfactual recourse using disentangled subspaces,2020, ICML Workshop on Human Inter-pretability in Machine Learning
 Adversarial removal of demographic attributes from textdata,2018, In Conference on Empirical Methods in Natural Language Processing
 Visualizing higher-layerfeatures of a deep network,2009, University of Montreal
 Toward establishing trustin adaptive agents,2008, In Proceedings of the 13th international conference on Intelligent userinterfaces
 Generative adversarial nets,2014, In Advances inneural information processing systems
 Counterfactualvisual explanations,2019, In International Conference on Machine Learning
 beta-VAE: Learning basic visual con-cepts with a constrained variational framework,2017, International Conference on Learning Repre-sentations
 Attention is not explanation,2019, In Conference of the NorthAmerican Chapter of the Association for Computational Linguistics: Human Language Tech-nologies
 Interpreting black box predic-tions using Fisher kernels,2019, In International Conference on Artificial Intelligence and Statistics
 The bayesian case model: A generative approachfor case-based reasoning and prototype classification,2014, In Advances in neural information pro-cessing systems
 Disentangling by factorising,2018, In International Conference onMachine Learning
 Adam: A method for stochastic optimization,2018, InternationalConference on Learning Representations
 Variational inference ofdisentangled latent concepts from unlabeled observations,2018, In International Conferenceon Learning Representations
 Deep learning face attributes in thewild,2015, In IEEE international conference on computer vision
 Disentangling factors of variations using few labels,2019, In InternationalConference on Learning Representations
 A unified approach to interpreting model predictions,2017, InAdvances in neural information processing systems
 Disentangling influence: Using disentangled representations to auditmodel predictions,2019, arXiv preprint arXiv:1906
 Towards robust interpretability with self-explainingneural networks,2018, In Advances in Neural Information Processing Systems
 Spectral normaliza-tion for generative adversarial networks,2018, arXiv preprint arXiv:1802
 Explaining machine learning clas-sifiers through diverse counterfactual explanations,2020, In Proceedings of the 2020 Conference onFairness
 Plug & playgenerative networks: Conditional iterative generation of images in latent space,2017, In Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition
 Visual explanation by interpretation: Im-proving visual feedback capabilities of deep neural networks,2018, In International Conference onLearning Representations
 Con-text encoders: Feature learning by inpainting,2016, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Measuring skin cancer risk in african americans: is the fitzpatrick skin typeclassification scale culturally sensitive,2020, Ethn Dis
 Learn-ing to deceive with attention-based explanations,2020, In Proceedings of the 58th Annual Meetingof the Association for Computational Linguistics
 Classification accuracy score for conditional generativemodels,1226, In Advances in Neural Information Processing Systems
 Generating diverse high-fidelity imageswith vq-vae-2,2019, In Advances in Neural Information Processing Systems
 Abcde¡ªan evolvingconcept in the early detection of melanoma,2005, Archives of dermatology
 Improved techniques for training GANs,2016, In NIPS
 ExplainGAN:Model explanation via decision boundary crossing transformations,2018, In European Conferenceon Computer Vision
 Towards emergent language symbolic semantic segmentation and model interpretability,2020, InInternational Conference on Medical Image Computing and Computer-Assisted Intervention
 Weakly superviseddisentanglement with guarantees,2020, In International Conference on Learning Representations
 Interpretability-guided content-based medical image retrieval,2020, In International Conference on Medical ImageComputing and Computer-Assisted Intervention
 Explanation byprogressive exaggeration,2020, In International Conference on Learning Representations
 Explaining theblack-box smoothly-a counterfactual approach,2019, arXiv preprint arXiv:2101
 Smooth-Grad: Removing noise by adding noise,2014, ICML Workshop on Visualization for Deep Learning
 Axiomatic attribution for deep networks,2017, InInternational Conference on Machine Learning
 Early detection of melanoma: reviewing the abcdes,2015, Journal of the American Academyof Dermatology
 Neural discrete representationlearning,2017, In Proceedings of the 31st International Conference on Neural Information Process-ing Systems
 Counterfactual explanations withoutopening the black box: Automated decisions and the gdpr,2017, Harv
 Attention is not not explanation,2019, In Proceedings of the 2019Conference on Empirical Methods in Natural Language Processing and the 9th InternationalJoint Conference on Natural Language Processing (EMNLP-IJCNLP)
 Do no harm: Aroadmap for responsible machine learning for health care,2019, Nature medicine
 Asso-ciation betWeen surgical skin markings in dermoscopic images and diagnostic performance ofa deep learning convolutional neural netWork for melanoma recognition,2019, JAMA dermatology
 Representer pointselection for explaining deep neural netWorks,2018, In Advances in neural information processingsystems
 Unpaired image-to-image trans-lation using cycle-consistent adversarial netWorks,2017, In Proceedings of the IEEE internationalconference on computer vision
 Discriminator optimization happens once every Dsteps,2080, Similarly
