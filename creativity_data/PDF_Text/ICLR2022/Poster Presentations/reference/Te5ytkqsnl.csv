title,year,conference
 Towards better understanding ofgradient-based attribution methods for deep neural networks,2017, arXiv preprint arXiv:1711
 Network dissection:Quantifying interpretability of deep visual representations,2017, In Computer Vision and PatternRecognition (CVPR)
 Asymmetric loss for multi-label classification,2020, arXiv preprint arXiv:2009
 Overinterpretation revealsimage classification model pathologies,2021, Advances in Neural Information Processing Systems
 Explaining image clas-sifiers by counterfactual generation,2019, In International Conference on Learning Representations(ICLR)
 Explaining by removing: A unified framework formodel explanation,2021, Journal ofMachine Learning Research
 Real time image saliency for black box classifiers,2017, In NeuralInformation Processing Systems (NeurIPS)
 Explanations based on the missing: Towards contrastive explanationswith pertinent negatives,2018, arXiv preprint arXiv:1802
 An im-age is worth 16x16 words: Transformers for image recognition at scale,2021, In International Confer-ence on Learning Representations (ICLR)
 Ex-ploring the landscape of spatial robustness,2019, In International Conference on Machine Learning(ICML)
 Interpretable explanations of black boxes by meaningful pertur-bation,2017, In International Conference on Computer Vision (ICCV)
 Imagenet-trained CNNs are biased towards texture; increasing shape biasimproves accuracy and robustness,2019, In International Conference on Learning Representations(ICLR)
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations (ICLR)
 Counterfactual visualexplanations,2019, arXiv preprint arXiv:1904
 Deep residual learning for image recog-nition,2016, In Conference on Computer Vision and Pattern Recognition (CVPR)
 Grounding visual expla-nations,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Benchmarking neural network robustness to commoncorruptions and surface variations,2019, In International Conference on Learning Representations(ICLR)
 A benchmark for interpretabil-ity methods in deep neural networks,2018, arXiv preprint arXiv:1806
 Testing robustness againstunforeseen adversaries,2019, In ArXiv preprint arxiv:1908
 Learning multiple layers of features from tiny images,2009, In Technical report
 3db: A framework for debuggingcomputer vision models,2021, In arXiv preprint arXiv:2106
 Visualizing and understanding neural modelsin nlp,2016, In Proceedings of NAACL-HLT
 Microsoft coco: Common objects in context,2014, In Europeanconference on computer vision (ECCV)
 Do explanations reflect decisions? a machine-centric strategy to quantifythe performance of explainability algorithms,2019, arXiv preprint arXiv:1910
 On the robustness of vision transformersto adversarial examples,2021, 2021
 An analysis of lime for text data,2021, In International Conferenceon Artificial Intelligence and Statistics
 Wordnet: a lexical database for english,1995, Communications of the ACM
 Intriguing properties of vision transformers,2021, arXiv preprintarXiv:2105
" "" why should i trust you?"" explainingthe predictions of any classifier",2016, In International Conference on Knowledge Discovery and DataMining (KDD)
 “why should i trust you?”: Explainingthe predictions of any classifier,2016, In International Conference on Knowledge Discovery and DataMining (KDD)
 ImageNet Large Scale Visual Recognition Challenge,2015, In International Journal of ComputerVision (IJCV)
 Certified patch robustness viasmoothed vision transformers,2021, arXiv preprint arXiv:2110
 Evaluating the visualization of what a deep neural network has learned,2016, IEEE transactionson neural networks and learning systems
 On the adversarial robust-ness of visual transformers,2021, 2021
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations (ICLR)
 Deep inside convolutional networks: Vi-sualising image classification models and saliency maps,2013, arXiv preprint arXiv:1312
 Understanding failuresof deep networks via robust feature extraction,2021, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 SmoothGrad: removing noise byadding noise,2017, In ICML workshop on visualization for deep learning
 Visualizing the impact of feature attributionbaselines,2020, Distill
 Axiomatic attribution for deep networks,2017, InInternational Conference on Machine Learning (ICML)
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations (ICLR)
 Re-thinking the inception architecture for computer vision,2016, In Computer Vision and Pattern Recog-nition (CVPR)
 Training data-efficient image transformers & distillation through attention,2020, arXivpreprint arXiv:2012
 Attention is all you need,2017, Advances in Neural Informa-tion Processing Systems
 Pytorch image models,2019, https://github
 Leveraging sparse linear layers for debug-gable deep networks,2021, In International Conference on Machine Learning (ICML)
 Noise or signal: The role ofimage backgrounds in object recognition,2020, arXiv preprint arXiv:2006
 Visualizing and understanding convolutional networks,2014, InEuropean conference on computer vision
 Object recognition without and without objects,2017, InInternational Joint Conference on Artificial Intelligence
 Visualizing deep neural networkdecisions: Prediction difference analysis,2017, arXiv preprint arXiv:1702
