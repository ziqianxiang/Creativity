title,year,conference
 First-order methods in optimization,2017, SIAM
 Data-driven robust optimization,2018, MathematicalProgramming
 Robust wasserstein profile inference and applica-tions to machine learning,2019, Journal of Applied Probability
 Robust optimization for non-convex objectives,2017, arXiv preprint arXiv:1707
 A light touch for heavily constrained sgd,2016, In Conferenceon Learning Theory
 Two-player games for efficient non-convexconstrained optimization,2019, In Algorithmic Learning Theory
 Saga: A fast incremental gradient methodwith support for non-strongly convex composite objectives,2014, In Advances in neural informationprocessing systems
 Adaptive personalized federatedlearning,2020, arXiv preprint arXiv:2003
 Distributionally robust federatedaveraging,2021, arXiv preprint arXiv:2102
 Empiri-cal risk minimization under fairness constraints,2018, arXiv preprint arXiv:1802
 Variance-based regularization with convex objectives,2016, arXivpreprint arXiv:1610
 Learning models with uniform performance via distribu-tionally robust optimization,2021, The Annals of Statistics
 Data-driven distributionally robust optimizationusing the wasserstein metric: Performance guarantees and tractable reformulations,2018, MathematicalProgramming
 Spider: Near-optimal non-convexoptimization via stochastic path integrated differential estimator,2018, arXiv preprint arXiv:1807
 An algorithm for quadratic programming,1956, Naval researchlogistics quarterly
 On the convergence of local descent methods in federatedlearning,2019, arXiv preprint arXiv:1910
 Localsgd with periodic averaging: Tighter analysis and adaptive synchronization,2019, Advances in NeuralInformation Processing Systems
 Tradingredundancy for communication: Speeding up distributed sgd for non-convex optimization,2019, InICML
 Fed-erated learning with compression: Unified analysis and sharp guarantees,2020, arXiv preprintarXiv:2007
 Equality of opportunity in supervised learning,2016, Advancesin neural information processing systems
 Fairness withoutdemographics in repeated loss minimization,2018, In International Conference on Machine Learning
 Accelerated method for stochastic compositionoptimization with nonsmooth regularization,2018, In Thirty-Second AAAI Conference on ArtificialIntelligence
 Revisiting frank-wolfe: Projection-free sparse convex optimization,2013, In InternationalConference on Machine Learning
 Solving variational inequalities withstochastic mirror-prox algorithm,2011, Stochastic Systems
 Zeroth-order stochastic compositional algorithms forrisk-aware learning,2019, arXiv preprint arXiv:1912
 Linear convergence of gradient and proximal-gradient methods under the Polyak-IojasieWicz condition,2016, In Joint European Conference onMachine Learning and Knowledge Discovery in Databases
 Large-scale methods for distributionallyrobust optimization,2020, arXiv preprint arXiv:2010
 Finite-sum composition optimization via variance reducedgradient descent,2017, In Artificial Intelligence and Statistics
 Stochastic gradientdescent With only one projection,2012, In Advances in Neural Information Processing Systems 25(NIPS)
 Communication-efficientlearning of deep netWorks from decentralized data,2016, arXiv preprint arXiv:1602
 Agnostic federated learning,2019, arXivpreprint arXiv:1902
 Stochastic gradient methods for distributionally robustoptimization With f-divergences,2016, In NIPS
 Ap-proximate heavily-constrained learning with lagrange multiplier models,2020, Advances in NeuralInformation Processing Systems
 Linear convergence of first order methods fornon-strongly convex optimization,2019, Mathematical Programming
 Robust stochasticapproximation approach to stochastic programming,2009, SIAM Journal on optimization
 Gradient methods for minimizing composite functions,2013, Mathematical Programming
 Sarah: A novel method for machinelearning problems using stochastic recursive gradient,2017, In International Conference on MachineLearning
 Robust experimentation in the continuous time bandit problem,2020, EconomicTheory
 A practical online method for distribution-ally deep robust optimization,2020, arXiv preprint arXiv:2006
 A simple and effective frameworkfor pairwise deep metric learning,2020, In Computer Vision-ECCV 2020: 16th European Conference
 Introducing letor 4,2013,0 datasets
 Distributionally robust optimization: A review,2019, arXivpreprint arXiv:1908
 Distributionallyrobust logistic regression,2015, arXiv preprint arXiv:1509
 Distributionally robust stochastic programming,2017, SIAM Journal on Optimization
 Certifying some distributionalrobustness with principled adversarial training,2017, arXiv preprint arXiv:1710
 Incremental constraint projection methods for variationalinequalities,2015, Mathematical Programming
 Stochastic first-order methods with random constraintprojection,2016, SIAM Journal on Optimization
 Accelerating stochastic composition optimization,2016, arXivpreprint arXiv:1607
 Stochastic compositional gradient descent: algorithmsfor minimizing compositions of expected-value functions,2017, Mathematical Programming
 Robust optimization for fairness with noisy protected groups,2020, arXiv preprintarXiv:2002
 A general analysis framework of lower complexitybounds for finite-sum optimization,2019, arXiv preprint arXiv:1908
 Sharp analysis of epoch stochastic gradientdescent ascent methods for min-max optimization,2020,2020
 Fast distributionally robust learningwith variance reduced min-max optimization,2021, arXiv preprint arXiv:2104
 Fairnessconstraints: A flexible approach for fair classification,2019, The Journal of Machine Learning Research
 A composite randomized incremental gradient method,2019, In InternationalConference on Machine Learning
 A stochastic composite gradient method with incremental variancereduction,2019, arXiv preprint arXiv:1906
